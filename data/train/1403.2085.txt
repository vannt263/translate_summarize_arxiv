{
  "article_text": [
    "it is well known that for a cross - section data set , the ordinary least squares ( ols ) estimator is typically consistent for the coefficient vector of the best linear approximation to the conditional mean , even if the conditional mean is not necessarily linear @xcite .",
    "such a `` robust '' nature of ols is one of the reasons why ols is popular in empirical studies ( * ? ? ?",
    "* chapter 3 ) .",
    "suppose now that a panel data set is available .",
    "in such a case , we are typically interested in estimating the partial effects of the observed explanatory variables , @xmath5 , on the conditional mean of the dependent variable , @xmath6 , conditional on @xmath5 and the unobservable individual effect @xmath7 , where @xmath8 denotes the index for individuals and @xmath9 denotes the index for time . for that purpose ,",
    "a popular strategy is to model the conditional mean @xmath10 $ ] as additive in both @xmath7 and @xmath5 , and linear in @xmath5 .",
    "the focus is then on estimating the coefficient vector of @xmath5 .",
    "the fixed effects ( fe ) estimator , which is identical to the ols estimator treating the individual effects as parameters to be estimated , is often used to estimate the coefficient vector .",
    "while for models without strict exogeneity , such as dynamic panel data models , the fe estimator is generally inconsistent when @xmath0 ( the number of individuals ) goes to infinity and @xmath1 ( the number of time periods ) is fixed because of the incidental parameters problem @xcite , it is still a fundamental estimator .",
    "in particular , when @xmath0 and @xmath1 jointly go to infinity , the fe estimator becomes consistent .",
    "furthermore , after the incidental parameters bias is properly corrected , the fe estimator is known to have a centered limiting normal distribution provided that @xmath11 , which restricts @xmath1 to be mildly large but allows @xmath1 to be small relative to @xmath0 .",
    "such asymptotic properties of the fe estimator under large @xmath0 and @xmath1 asymptotics have been extensively studied in the econometrics literature , especially for panel autoregressive ( ar ) models , partly motivated by the fact that panel data sets with mildly large @xmath1 have become available in empirical studies .",
    "the previous discussion presumes that the model is correctly specified , that is , the conditional mean @xmath10 $ ] is truly additive in @xmath7 and @xmath5 , and linear in @xmath5 .",
    "the goals of this paper are twofold .",
    "the first objective is to study the asymptotic properties of the fe estimator under possible model misspecification when both @xmath0 and @xmath1 are large .",
    "the asymptotics used is the joint asymptotics where @xmath0 and @xmath1 jointly go to infinity ( more precisely , we index @xmath1 by @xmath0 and let @xmath12 as @xmath13 ) .",
    "assume that @xmath14 is independent and identically distributed ( i.i.d . ) , and for each @xmath15 , conditional on @xmath7 , @xmath16 is stationary and weakly dependent .",
    "suppose that @xmath17 $ ] may not be additive in @xmath7 and @xmath5 , nor linear in @xmath5 . under this setting , we show that the probability limit of the fe estimator is identical to the coefficient vector on @xmath5 of the best _ partial _ linear approximation to @xmath18 $ ] , which gives some rational to use the fe estimator ( and its variant ) even when the model is possibly misspecified .",
    "we regard this probability limit as a pseudo - true parameter ( see section [ sec : interpretation ] for the discussion on interpretation  or plausibility  of this probability limit ; especially if @xmath18 $ ] is indeed additive in @xmath7 and @xmath5 , and linear in @xmath19 , then the pseudo - true parameter coincides with the `` true '' coefficient on @xmath19 in @xmath20 $ ] ) .",
    "we then establish the asymptotic distributional properties of the fe estimator around the pseudo - true parameter when @xmath0 and @xmath1 jointly go to infinity .",
    "we demonstrate that , as in the correct specification case , the fe estimator suffers from the incidental parameters bias of which the top order is @xmath21 .",
    "moreover , we show that , after the incidental parameters bias is completely removed , the rate of convergence of the fe estimator depends on the degree of model misspecification and is either @xmath3 or @xmath4 .",
    "the second goal of the paper is to establish asymptotically valid inference on the ( pseudo - true ) parameter vector .",
    "since the fe estimator has the bias of order @xmath21 , the first step is to reduce the bias to @xmath22 . for that purpose , one can use existing general - purpose bias reduction methods proposed in the recent nonlinear panel data literature .",
    "for example , one can use the half - panel jackknife ( hpj ) proposed by @xcite .",
    "we refer to @xcite and @xcite for alternative approaches on bias correction for fixed effects estimators in panel data models .",
    "after the bias is properly reduced , the fe estimator has the centered limiting normal distribution provided that @xmath11 or @xmath23 depending on the degree of model misspecification .",
    "we are then interested in estimating the covariance matrix or quantiles of the centered limiting normal distribution . to this end , we study the asymptotic properties of the clustered covariance matrix ( ccm ) estimator @xcite and the cross section bootstrap @xcite under the prescribed setting . we show that the ccm estimator ( with an appropriate estimator of the parameter vector ) is consistent in a suitable sense and can be used to make asymptotically valid inference on the parameter vector provided that @xmath11 or @xmath23 .",
    "this shows that inference using the ccm estimator is `` robust '' to model misspecification .",
    "also the cross section bootstrap can consistently estimate the centered limiting distribution of the fe estimator without any knowledge on the degree of model misspecification and hence is robust to model misspecification , and moreover , interestingly , _ without any growth restriction on @xmath1_. the second feature of the cross section bootstrap is notable and shows ( in a sense ) that the incidental parameters bias does not appear in the bootstrap distribution .",
    "allowing for potential model misspecification is of importance in practice . in particular , this paper is of practical importance because it provides an interpretation for the fe estimator under potential misspecification , and additionally , it proposes methods for inference in linear panel data model with large @xmath0 and @xmath1 that are robust to model misspecification .",
    "however , the study of estimation and inference for linear panel data models that are robust to model misspecification is scarce .",
    "an exception is @xcite where he considered the lag order misspecification of panel ar models and established the asymptotic properties of the fe estimator under possible misspecification of the lag order .",
    "however , his focus is on the incidental parameters bias and he did not study the inference problem on the pseudo - true parameter .",
    "moreover , @xcite did not cover a general form of model misspecification .",
    "this paper fills this void .",
    "furthermore , the asymptotic properties of the ccm estimator and the cross section bootstrap when model misspecification and the incidental parameters bias ( in the coefficient estimate ) are present have not been studied in a systematic form and hence is under - developed .",
    "@xcite investigated the asymptotic properties of the ccm estimator when @xmath0 and @xmath1 are large but did not allow the case where the incidental parameters bias appears , nor did he cover model misspecification .",
    "@xcite studied the asymptotic properties of the cross section bootstrap when @xmath0 and @xmath1 are large , but ruled out the case where the incidental parameters bias appears , nor did he cover model misspecification as well .",
    "hence we believe that this paper is the first one that establishes a rigorous theoretical ground on the use of the ccm estimator and the cross section bootstrap when model misspecification and the incidental parameters bias are present .",
    "it is important to notice that , even without model misspecification , these asymptotic properties of the ccm and cross section bootstrap when the incidental parameters bias is present are new .",
    "we conduct monte carlo simulations to evaluate the finite sample performance of the estimators and inference methods under misspecification .",
    "we are particularly interested in the empirical coverage of the 95% nominal confidence interval .",
    "the empirical coverage probability using the ccm and cross - section bootstrap , especially the cross section bootstrap applied to pivotal statistics , is good .",
    "we also apply the procedures discussed in this paper to a model of unemployment dynamics at the u.s .",
    "state level .",
    "the results generate speed of adjustment of the unemployment rate towards the state specific equilibrium of about 17% .",
    "in addition , the analysis of estimates indicates that increments in economic growth are associated with smaller unemployment rates .",
    "the organization of this paper is as follows . in section [ sec : interpretation ] , we discuss the interpretation of fe estimator under misspecification . in section [ sec : asymptotics ] , we present the theoretical results on the asymptotic properties of the fe estimator under misspecification . in section [ sec :",
    "inference ] , we presents the results on the inference methods . in section [ sec : mc ] , we report a monte carlo study to assess the finite sample performance of the estimators and inference methods , together with a simple application to a real data .",
    "section [ sec : conclusion ] concludes .",
    "we place all the technical proofs to the appendix .",
    "we also include additional theoretical and simulation results in the appendix .",
    "* notation * : for a generic vector @xmath24 , let @xmath25 denote the @xmath26-th element of @xmath24",
    ". for a generic matrix @xmath27 , let @xmath28 denote its @xmath29-th element .",
    "for a generic vector @xmath30 with index @xmath31 , @xmath32 .",
    "let @xmath33 denote the euclidean norm .",
    "for any matrix @xmath27 , let @xmath34 denote the operator norm of @xmath27 .",
    "for any symmetric matrix @xmath27 , let @xmath35 denote the minimum eigenvalue of @xmath27 .",
    "we also use the notation @xmath36 for a generic vector @xmath24 .",
    "* note on asymptotics * : in what follows , we consider the asymptotic framework in which @xmath12 as @xmath13 , so that if we write @xmath13 , it automatically means that @xmath37 .",
    "the limit is always taken as @xmath13 .",
    "this asymptotic scheme is used to capture the situation where @xmath0 and @xmath1 are both large .",
    "in this section we clarify the probability limit , which we will regard as a pseudo - true parameter , of the fe estimator under the joint asymptotics and discuss interpretation ( or plausibility ) of the pseudo - true parameter .",
    "the discussion is to some extent parallel to the linear regression case but there is a subtle difference due to the appearance of individual effects .",
    "suppose that we have a panel data set @xmath38 , where @xmath7 is an unobservable individual - specific random variable taking values in an abstract ( polish ) space , @xmath6 is a scalar dependent variable and @xmath5 is a vector of @xmath39 explanatory variables .",
    "typically , the random variable @xmath7 , which is constant over time , represents an individual characteristic such as ability or firm s managerial quality which we would include in the analysis if it were observable ( see * ? ? ?",
    "* chapter 10 ) .",
    "assume that @xmath40 is i.i.d .",
    ", and for each @xmath41 , conditional on @xmath7 , @xmath42 is a realization of a stationary weakly dependent process . here",
    "the marginal distribution of @xmath43 is invariant with respect to @xmath31 .",
    "typically , we are interested in estimating the partial effects of @xmath5 on the conditional mean @xmath18 $ ] with keeping @xmath7 fixed .",
    "a `` standard '' linear panel data model assumes that the conditional mean is of the form @xmath44 with unknown function @xmath45 and vector @xmath46 , and redefines @xmath7 by @xmath47 since , in any case , @xmath7 is unobservable and modeling a functional form for the individual effect is virtually meaningless ( see * ? ? ?",
    "* chapter 5 ) . in this paper",
    ", the `` correct '' specification refers to that the conditional mean @xmath10 $ ] is written in the form @xmath48 , and `` model misspecification '' signifies any violation of this condition . for instance",
    ", this can happen if there are omitted variables or if nonlinearity occurs in the model .",
    "we discuss more details below ( see examples 1 and 2 below for concrete examples ) .",
    "the fe estimator defined by @xmath49 is consistent for the coefficient vector on @xmath5 as @xmath0 goes to infinity and @xmath1 is fixed if the specification is correct ( for the moment , assuming that @xmath50 exists ) and additionally the strict exogoneity assumption @xmath51 = { \\mathbb{e}}[y_{it } \\mid { \\bm{x}}_{it},c_{i}]$ ] is met .",
    "if the strict exogoneity assumption is violated , then the fe estimator is not fixed-@xmath1 consistent , but as @xmath37 with @xmath0 , the fe estimator becomes consistent for the coefficient vector on @xmath5 provided that the specification is correct .",
    "suppose now that the specification is not correct , i.e. , @xmath18 $ ] may not be written in the form @xmath44 , and consider the probability limit of the fe estimator when @xmath0 and @xmath1 jointly go to infinity .",
    "proposition [ prop1 ] ahead shows that , subject to some technical conditions , we have , as @xmath13 and @xmath12 , @xmath52^{-1 } { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{it } { \\widetilde}{y}_{it } ] = : { \\bm{\\beta}}_{0 } , \\label{ptrue}\\ ] ] where @xmath53 $ ] and @xmath54 $ ] ( for a moment , assume that some moments exist ) . to gain some insight",
    ", we provide a heuristic derivation of this probability limit under the sequential asymptotics where @xmath37 first and then @xmath13 . by definition ,",
    "we have @xmath55 since @xmath42 is weakly dependent conditional on @xmath7 , as @xmath37 first , we have @xmath56 , \\ \\bar{{\\widetilde}{{\\bm{x}}}}_{i } \\stackrel{{\\mathbb{p}}}{\\to } \\bm{0 } , \\ t^{-1 } \\sum_{t=1}^{t } { \\widetilde}{{\\bm{x}}}_{it } { \\widetilde}{y}_{it } \\stackrel{{\\mathbb{p}}}{\\to } { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{i1 } { \\widetilde}{y}_{i1 } \\mid c_{i}]$ ] and @xmath57 , so that @xmath58 \\}^{-1 } \\ { n^{-1 } \\sum_{i=1}^{n } { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{i1 } { \\widetilde}{y}_{i1 } \\mid c_{i } ] \\}$ ] . by the law of large numbers",
    ", the right side converges in probability to @xmath59 as @xmath13 . in what follows ,",
    "we discuss an interpretation of @xmath59 defined in ( [ ptrue ] ) .",
    "a direct interpretation is that @xmath59 is the coefficient vector of the best linear approximation to @xmath60 $ ] , but this interpretation does not explain the connection with the primal object of estimating the partial effects of @xmath5 on @xmath18 $ ] .",
    "however , the link emerges from the following discussion .",
    "let @xmath61 be the best partial linear predictor of @xmath6 on @xmath62 , i.e. , @xmath63 = \\min_{g \\in l_{2}(c_{1 } ) , \\bm{b } \\in \\mathbb{r}^{p } } { \\mathbb{e } } [ ( y_{it } - g(c_{i})-{\\bm{x}}_{it}'\\bm{b})^{2}],\\ ] ] where @xmath64",
    "< \\infty \\}$ ] . by a simple calculation ,",
    "the explicit solution @xmath65 is given by @xmath66 - { \\mathbb{e}}[{\\bm{x}}_{it } \\mid c_{i}]'\\bm{b}_{0 } , \\ \\bm{b}_{0 } = { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{it}{\\widetilde}{{\\bm{x}}}_{it}']^{-1}{\\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{it } { \\widetilde}{y}_{it } ] = { \\bm{\\beta}}_{0},\\ ] ] and hence @xmath59 is the coefficient vector on @xmath5 of the best partial linear predictor .",
    "moreover , it is not difficult to see that @xmath61 is indeed the best partial linear approximation to @xmath18 $ ] , i.e. , @xmath67   - g_{0}(c_{i } ) - { \\bm{x}}_{it}'\\bm{b}_{0})^{2 } ] = \\min_{g \\in l_{2}(c_{1 } ) , \\bm{b } \\in \\mathbb{r}^{p } } { \\mathbb{e } } [ ( { \\mathbb{e}}[y_{it } \\mid { \\bm{x}}_{it},c_{i } ] - g(c_{i})-{\\bm{x}}_{it}'\\bm{b})^{2 } ] .",
    "\\label{papprox}\\ ] ] therefore , the vector @xmath59 defined by ( [ ptrue ] ) is identical to the coefficient vector on @xmath5 of the best partial linear approximation to @xmath18 $ ] in ( [ papprox ] ) . just as the coefficient vector of the best linear approximation to the conditional mean is a parameter of interest in the cross section case , as discussed in chapter 3 of @xcite , the vector @xmath59 here can be regarded as a plausible parameter of interest in the panel data case .",
    "hence , in this paper , we consider @xmath59 to be a parameter of interest and treat @xmath59 as a pseudo - true parameter .",
    "clearly if @xmath17 $ ] is indeed additive in @xmath7 and @xmath5 , and linear in @xmath5 , then @xmath59 coincides with the `` true '' coefficient on @xmath5 in @xmath17 $ ] .    as in the cross section case , letting the approximation error denote @xmath68 , we have a regression form @xmath69 = 0 , \\ { \\mathbb{e } } [ { \\bm{x}}_{it } \\epsilon_{it } ] = 0",
    ". \\label{regression}\\ ] ] importantly , the `` error term '' @xmath70 here may not satisfy the conditional mean restriction @xmath71 = 0 $ ] due to possible model misspecification .    in ( [ regression ] )",
    ", there are two scenarios on violation of the conditional mean restriction @xmath71 = 0 $ ] .",
    "one is the case where @xmath71 \\neq 0 $ ] with positive probability but @xmath72 = \\bm{0}$ ] a.s .",
    "the other is the case where @xmath72 \\neq \\bm{0}$ ] with positive probability . depending on these two cases ,",
    "the asymptotic properties of the fe estimator _ do _ change drastically ( see section 3 ) .",
    "generally , both cases can happen .",
    "we give three simple examples to fix the idea .    _",
    "example 1_. panel ar model with misspecified lag order .",
    "suppose that the true data generating process follows a panel ar(2 ) model @xmath73 = 0,\\ ] ] where @xmath74 is such that @xmath75 and @xmath76 .",
    "conditional on @xmath7 , @xmath77 is stationary and typically weakly dependent . by a simple calculation",
    ", we have @xmath78 = c_{i}/(1-\\phi_{1}-\\phi_{2})$ ] . letting @xmath79 $ ] , we have @xmath80 . hence @xmath81 is independent of @xmath7 .",
    "suppose now that we incorrectly fit a panel ar(1 ) model .",
    "note that in this case , we have @xmath82 = c_{i } + \\phi_{1 } y_{i , t-1 } + \\phi_{2 } { \\mathbb{e } } [ y_{i , t-2 } \\mid y_{i , t-1},c_{i } ]",
    ". \\end{aligned}\\ ] ] hence @xmath83 $ ] is generally a nonlinear function of @xmath7 and @xmath84 except for the cases where @xmath85 or the distribution of @xmath86 is normal .",
    "here the solution of the equation @xmath87 = 0 $ ] is the first order autocorrelation coefficient of @xmath88 , i.e. , @xmath89 . letting @xmath90",
    ", we have @xmath91 , i.e. , @xmath92 . by the independence of @xmath88 from @xmath7",
    ", we have @xmath93 = { \\mathbb{e } } [ { \\widetilde}{y}_{i , t-1 } \\epsilon_{it } ] = 0 $ ] a.s .",
    "@xcite studied such panel ar models with misspecified lag order in detail .",
    "this paper covers lag order misspecification as a special case .    _",
    "example 2_. static panel with a mismeasured regressor .",
    "suppose the true data generating process is as following @xmath94 = 0.\\ ] ] in addition , @xmath95 = 0.\\ ] ] suppose that @xmath96 and @xmath97 are independent , and we incorrectly fit a model using @xmath98 instead of @xmath99 . here",
    "we have @xmath100= x_{it}^ { * } + v_{it } - { \\mathbb{e } } [ x_{it}^ { * } \\mid c_{i } ] = { \\widetilde}{x}_{it}^ { * } + v_{it},\\ ] ] where @xmath101 $ ] , and @xmath53 = \\phi { \\widetilde}{x}_{it}^ { * } + u_{it}$ ] .",
    "hence the solution to the equation @xmath102 = 0 $ ] is given by @xmath103^{-1 } { \\mathbb{e } } [ { \\widetilde}{y}_{it } { \\widetilde}{x}_{it } ] = \\frac{{\\mathbb{e } } [ ( { \\widetilde}{x}_{it}^{*})^{2}]}{{\\mathbb{e } } [ ( { \\widetilde}{x}_{it}^{*})^{2 } ] + { \\mathbb{e } } [ v_{it}^{2 } ] } \\phi.\\ ] ] finally , by @xmath104 , we have @xmath105 =   { \\mathbb{e } } [ ( { \\widetilde}{x}_{it}^{*})^{2 } \\mid c_{i } ] \\phi - ( { \\mathbb{e } } [ ( { \\widetilde}{x}_{it}^{*})^{2 } \\mid c_{i } ] + { \\mathbb{e } } [ v_{it}^{2 } ] ) \\beta_{0}$ ] , which is generally non - zero .",
    "example 3_. random coefficients ar model .",
    "suppose that the true data generating process follows the following random coefficients ar(1 ) model : @xmath106 in this case , @xmath107 = c_{i } y_{i , t-1}$ ] .",
    "it is routine to verify that @xmath108 suppose that we incorrectly fit a panel ar(1 ) model . here",
    "= y_{it}$ ] and the solution of the equation @xmath109 = 0 $ ] is given by @xmath110}{{\\mathbb{e } } [ y_{i , t-1}^{2 } ] } = \\frac{{\\mathbb{e } } [ c_{i}/(1-c_{i}^{2})]}{{\\mathbb{e } } [ 1/(1-c_{i}^{2})]}.\\ ] ] here @xmath111 , and @xmath112 = { \\mathbb{e } } [ c_{i } y_{i , t-1}^{2 } - \\beta_{0 } y_{i , t-1}^{2 } \\mid c_{i } ] = \\frac{c_{i}-\\beta_{0}}{1-c_{i}^{2}},\\ ] ] which is non - zero a.s .",
    "if @xmath7 obeys a continuous distribution .",
    "the results in this paper could be interpreted as corresponding to the pseudo - likelihood model . under the additional assumptions of independence and normality ,",
    "the resulting ( conditional ) maximum likelihood estimator ( mle ) of @xmath113 ( given @xmath114 ) is identical to the fe estimator .",
    "thus , the fe estimator defined in ( [ fe ] ) can be viewed as a pseudo - mle .",
    "@xcite made an interesting observation about the pseudo - true parameter when the link function is misspecified for the generalized linear model ( see their corollary 1 ) .",
    "that is , the pseudo - true parameter is proportional to the true one up to nonzero scalar .",
    "however , their setting is significantly different from ours ; first of all in corollary 1 they assumed that the true model satisfies a generalized linear model but only the link function is misspecified , and only cross section data are available . in our case basically",
    "no `` model '' is assumed ( and hence the `` true parameter '' is not well - defined in general ) , so that their result does not extend to our setting .    in this paper",
    "we focus on the fe estimator .",
    "this is because the fe estimator is widely used in practice and , as we have shown , the probability limit of the fe estimator under misspecification admits a natural and plausible interpretation , parallel to the linear regression case .",
    "there could be alternative estimators ; for example , we could consider the average of the individual - wise ols estimators , i.e. , let @xmath115 denote the ols estimator obtained by regressing @xmath6 on @xmath116 with each fixed @xmath8 , and consider the estimator @xmath117 . however , this estimator does not share the interpretation that the fe estimator possesses . in some cases",
    "the probability limit of @xmath118 happens to be identical to @xmath59 , but not in general . to keep tight focus , we only consider the fe estimator in what follows .",
    "in this section , we study the asymptotic properties of the fe estimator under possible model misspecification ( i.e. , @xmath10 $ ] is not assumed to be additive in @xmath7 and @xmath5 , nor linear in @xmath5 ) .",
    "we make the following regularity conditions .",
    "( a1 ) : :    @xmath119 ,    where @xmath120 is a polish space .",
    "@xmath14    is i.i.d . , and",
    "for each @xmath15 , conditional on    @xmath7 ,    @xmath16 is a    stationary @xmath121-mixing process with mixing    coefficients @xmath122 .",
    "assume that there    exists a sequence of constants @xmath123 such that    @xmath124 a.s .",
    "for all    @xmath125 , and    @xmath126    for some @xmath127 .",
    "( a2 ) : :    define    @xmath79 $ ]    and    @xmath128 $ ]    ( assume that @xmath129 $ ] and    @xmath130 $ ] exist ) .",
    "there    exists a constant @xmath131 such that    @xmath132 \\leq m$ ]    a.s . and    @xmath133 \\leq m$ ]    a.s . , where @xmath127 is given in ( a1 ) .",
    "( a3 ) : :    define the matrix    @xmath134 $ ] .",
    "assume that the matrix @xmath27 is nonsingular .    in condition ( a1 )",
    ", @xmath7 is an unobservable , individual - specific random variable allowed to be dependent with @xmath5 in an arbitrary form .",
    "condition ( a1 ) assumes that the observations are independent in the cross section dimension , but allows for dependence in the time dimension conditional on individual effects .",
    "we refer to section 2.6 of @xcite for some basic properties of mixing processes .",
    "condition ( a1 ) is similar to condition 1 of @xcite , and allows for a flexible time series dependence .",
    "the mixing condition is also similar to assumption 1 ( iii ) of @xcite , while she allowed for cross section dependence .",
    "the mixing condition is used only to bound covariances and moments of sums of random variables , and not crucial for the central limit theorem .",
    "therefore , in principle , it could be replaced by assuming directly such bounds .",
    "we assume the mixing condition to make the paper clear .",
    "note that because of stationarity assumption made in ( a1 ) , the marginal distribution of @xmath43 is invariant with respect to @xmath31 , i.e. , @xmath135 .",
    ", is drawn from the stationary distribution , conditional on @xmath7 . ]",
    "the stationary assumption rules out time trends , but is needed to well - define the pseudo - true parameter @xmath136 , and maintained in this paper .",
    "extensions to non - stationary cases will need different analysis and are not covered in this paper .",
    "condition ( a2 ) is a moment condition . as usual",
    ", there is a trade - off between the mixing condition and the moment condition .",
    "condition ( a2 ) implies that @xmath137 \\leq m'$ ] a.s .",
    "for some constant @xmath138 . condition ( a3 ) is a standard full rank condition .",
    "now we introduce some notation .",
    "recall the fe estimator : @xmath139 where @xmath140 and @xmath141 . under conditions ( a1)-(a3 ) , the matrix @xmath142 on the right side is nonsingular with probability approaching one ( see lemma [ lem2 ] in appendix [ appendix a ] ) .",
    "recall that @xmath59 is defined by ( [ ptrue ] ) and @xmath70 is defined by @xmath143 ( see the previous section ) .",
    "define @xmath144 , \\",
    "d_{t } =   \\sum_{| k | \\leq t-1 } \\left ( 1 - \\frac{|k|}{t } \\right ) { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{1,1 } { \\widetilde}{{\\bm{x}}}_{1,1+k } ' ] .\\ ] ] here and in what follows , for the notational convenience , terms like @xmath145 $ ] for @xmath146 are understood as @xmath147 $ ] , i.e. , @xmath148 : = { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{1,1-k } \\epsilon_{1,1 } ] , \\ k < 0.\\ ] ] we shall obey the same convention to other such terms .",
    "for example , @xmath149 : = { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{1,1-k } { \\widetilde}{{\\bm{x}}}_{1,1 } ' ] $ ] for @xmath146 . we first note that under conditions ( a1)-(a3 ) , both @xmath150 and @xmath151 are well behaved in the following sense .",
    "[ lem1 ] under conditions ( a1)-(a3 ) , we have @xmath152 \\| < \\infty$ ] and @xmath153 \\|_{\\operatorname{op } } < \\infty$ ] .    all the technical proofs for section 2 are gathered in appendix [ appendix a ] .",
    "we now state the asymptotic properties of the fe estimator .",
    "define @xmath154 = \\bm{0}$ a.s .",
    "n , \\ & \\text{otherwise } ,   \\end{cases } \\qquad \\text{and } \\qquad \\sigma_{nt } = { \\mathbb{e}}\\left [ \\left ( \\frac{1}{nt } \\sum_{i=1}^{n } \\sum_{t=1}^{t } { \\widetilde}{{\\bm{x}}}_{it } \\epsilon_{it } \\right ) ^{\\otimes 2 } \\right],\\ ] ] where recall that @xmath36 .",
    "[ prop1 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "letting @xmath12 as @xmath13 , we have : @xmath155 .",
    "\\label{bahadur}\\end{aligned}\\ ] ] therefore , we have : @xmath156 \\stackrel{d}{\\to } n(\\bm{0},a^{-1 } \\sigma a^{-1}),\\ ] ] where @xmath157 ( the limit on the right side exists ) .",
    "we stress that proposition [ prop1 ] holds without any specific growth condition on @xmath1 . also note that this proposition implies that @xmath158 as long as @xmath12",
    "we discuss some implications of proposition [ prop1 ] .",
    "first , proposition [ prop1 ] shows that the fe estimator has the bias term of the form @xmath159 which , following the literature , we call the `` incidental parameters bias ''",
    ". there are two sources that contribute to the incidental parameters bias .",
    "the main source is conditional correlation between @xmath160 and @xmath70 for @xmath161 conditional on @xmath7 , which arises from using @xmath162 instead of @xmath163 $ ] in @xmath164 .",
    "another source , which only contributes to higher order terms , is conditional correlation between @xmath160 and @xmath5 for @xmath161 conditional on @xmath7 , which arises from using @xmath162 instead of @xmath163 $ ] in @xmath142 .",
    "proposition [ prop1 ] makes explicit the incidental parameters bias of any order , which appears to be new even in the correct specification case ( but under the current set of assumptions ) .",
    "the expansion ( [ bahadur ] ) is important in investigating the asymptotic properties of the cross section bootstrap in section 4 .",
    "second , proposition [ prop1 ] shows that , aside from the incidental parameters bias , the rate of convergence of the fe estimator depends on the degree of model misspecification , i.e. , after the incidental parameters bias is completely removed , the fe estimator is @xmath165-consistent if @xmath166 = \\bm{0}$ ] a.s . and",
    "@xmath167-consistent otherwise .",
    "in fact , the rate of convergence of the fe estimator ( after the incidental parameters bias is removed ) depends on the order of the covariance matrix of the term @xmath168 ) + \\frac{1}{n } \\sum_{i=1}^{n } { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{i1 } \\epsilon_{i1 } \\mid c_{i}].\\ ] ] by this decomposition , @xmath169 ) \\right \\}^{\\otimes 2 } \\right ] + { \\mathbb{e}}\\left [ \\left ( \\frac{1}{n } \\sum_{i=1}^{n } { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{i1 } \\epsilon_{i1 } \\mid c_{i } ] \\right ) ^{\\otimes 2 } \\right ] \\\\ & = \\frac{1}{nt } { \\mathbb{e}}\\left [ \\left \\ { \\frac{1}{\\sqrt{t } } \\sum_{t=1}^{t }",
    "( { \\widetilde}{{\\bm{x}}}_{1 t } \\epsilon_{1 t } - { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{i1 } \\epsilon_{i1 } \\mid c_{1 } ] ) \\right \\}^{\\otimes 2 } \\right ] + \\frac{1}{n } { \\mathbb{e}}[{\\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1 } \\epsilon_{1,1 } \\mid c_{1}]^{\\otimes 2}].\\end{aligned}\\ ] ] since @xmath16 is weakly dependent conditional on @xmath7 , the first term is @xmath170 . on the other hand ,",
    "the second term is zero if @xmath171 = \\bm{0}$ ] a.s . , but @xmath172 otherwise , which shows that @xmath173 if @xmath171 = \\bm{0}$ ] a.s . and",
    "@xmath174 otherwise .",
    "intuitively , unless @xmath171 = \\bm{0}$ ] a.s .",
    ", @xmath175 is unconditionally equicorrelated across @xmath9 , so that @xmath176 has the slow rate @xmath177 ( if @xmath171 = \\bm{0}$ ] a.s . , by condition ( a1 ) , the covariance between @xmath178 and @xmath179 converges to zero sufficiently fast as @xmath180 , so @xmath176 has the faster rate @xmath181 ) .    in some cases , at least theoretically , it may happen that @xmath171 \\neq \\bm{0}$ ] with positive probability but for some nonzero @xmath182 , @xmath183 = 0 $ ] a.s . , which corresponds to the case where the matrix @xmath184^{\\otimes 2}]$ ] is nonzero but degenerate .",
    "in such a case , we have the expansion @xmath185 \\notag \\\\ & = \\bm{r}'a^{-1 } \\left \\ { \\frac{1}{nt } \\sum_{i=1}^{n } \\sum_{t=1}^{t } ( { \\widetilde}{{\\bm{x}}}_{it } \\epsilon_{it } - { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{i1 } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } +   o_{{\\mathbb{p}}}[n^{-1/2}\\max \\",
    "{ n^{-1/2 } , t^{-1 } \\ } ] , \\label{expansion2}\\end{aligned}\\ ] ] where the leading term of the right side multiplied by @xmath165 is asymptotically normal with mean zero and variance @xmath186 < \\infty$ ] .",
    "this shows that , after subtracting the incidental parameters bias , the fe estimator may have different rates of convergence within its linear combinations .",
    "moreover , the remainder term in the expansion ( [ expansion2 ] ) has the constant term of order @xmath177 , so that the extra bias term of order @xmath177 appears in such a case .",
    ", it is shown that the remainder term in the expansion ( [ expansion2 ] ) is in fact further expanded as @xmath187 a^{-1}{\\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{1,1}\\epsilon_{1,1 } ' \\mid c_{1 } ] ] + o_{{\\mathbb{p } } } [ n^{-1/2 } \\max \\ { n^{-1},t^{-1 } \\}]$ ] . ] by this , if additionally @xmath188 goes to some positive constant , the limiting normal distribution of the right side on ( [ expansion2 ] ) multiplied by @xmath165 has a nonzero bias in the mean of which the size is proportional to @xmath189 .",
    "however , such a case seems to be rather exceptional and we mainly focus on the case where the matrix @xmath190 is always nonsingular ( i.e. @xmath190 is nonsingular in either case of @xmath171 = \\bm{0}$ ] a.s . or not ) .",
    "it is possible to have an alternative expression of the bias term of order @xmath21 .",
    "[ cor1 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "then we have : @xmath191 + o(t^{-1 } ) = : b+o(t^{-1}).\\ ] ] in particular , the bias term of order @xmath21 in the expansion ( [ bahadur ] ) is rewritten as @xmath192 .",
    "finally , we provide some comments on the relation to the previous work .",
    "proposition [ prop1 ] is a nontrivial extension of theorem 2 of @xcite , in which he established the asymptotic properties of the fe estimator for panel ar models with exogenous variables allowing for lag order misspecification .",
    "proposition [ prop1 ] allows for a more general form of model misspecification , including lag order misspecification as a special case , and exhausts the incidental parameters bias of any order .",
    "[ rem : hansen ] proposition [ prop1 ] is related to @xcite .",
    "@xcite considered a model @xmath193 with @xmath194=0 $ ] for all @xmath195 or @xmath196 = \\bm{0}$ ] , and showed that the ols estimator is @xmath167-consistent if there is no condition on time series dependence and @xmath165-consistent if a mixing condition is satisfied for time series dependence .",
    "what matters for the rate of convergence of the ols estimator in @xcite is the order of the covariance matrix of the term @xmath197 , which is @xmath198 in the `` no mixing '' case and @xmath170 in the mixing case .",
    "while there is a similarity , proposition [ prop1 ] is not nested to his results in several aspects .",
    "first , in proposition [ prop1 ] , the rate of convergence of the fe estimator ( after the incidental parameters bias is removed ) depends on the degree of model misspecification ( i.e. , @xmath199 = \\bm{0}$ ] a.s . or not ) , rather than the assumption on time series dependence .",
    "second , while his model covers panel data models with individual effects by considering @xmath200 to be transformed variables @xmath201 , the mixing assumption is not satisfied for the transformed variables as he admitted in footnote 3 , so that his theorem 3 does not apply to models with individual effects .",
    "additionally , his assumption 3 essentially requires that @xmath202 = \\bm{0}$ ] for all @xmath203 under our setting ( if we think of @xmath200 as transformed variables @xmath201 ) , so that his results do not cover the case where the incidental parameters bias appears . on the other hand , while we exclusively assume that @xmath16 is mixing conditional on @xmath7 , @xcite covered the case where no such mixing condition is satisfied .",
    "therefore , the two papers are complementary in nature .",
    "@xcite obtained a general incidental parameters bias formula for nonlinear panel data models , allowing for potential model misspecification , when @xmath204 is going to some constant .",
    "their general result could be applied to the present setting in the case where @xmath171=\\bm 0 $ ] .",
    "however , the stochastic expansion ( [ bahadur ] ) is not derived in @xcite ; ( [ bahadur ] ) exhausts the incidental parameters bias up to infinite order , and covers the case where @xmath171 \\neq \\bm 0 $ ] .",
    "this expansion is also the key for studying the properties of cross section bootstrap .",
    "by proposition [ prop1 ] , the fe estimator has the bias of order @xmath21 . in many econometric applications ,",
    "@xmath1 is typically smaller than @xmath0 , so that the normal approximation neglecting the bias may not be accurate in either case of @xmath72 = \\bm{0}$ ] or @xmath205 \\neq \\bm{0}$ ] .",
    "therefore , the first step to make inference on @xmath59 is to remove the bias of order @xmath21 and reduce the order of the bias to @xmath206 . under model misspecification ,",
    "bias reduction methods that depend on specific models ( such as panel ar models ) may not work properly .",
    "instead , we can use general - purpose bias reduction methods proposed in the recent nonlinear panel data literature .",
    "for example , the half - panel jackknife ( hpj ) proposed by @xcite is able to remove the bias of order @xmath21 even under model misspecification .",
    "suppose that @xmath1 is even .",
    "let @xmath207 and @xmath208 .",
    "for @xmath209 , construct the fe estimator @xmath210 based on the split sample @xmath211 .",
    "then the hpj estimator is defined by @xmath212 . using the expansion ( [ bahadur ] ) and corollary [ cor1 ] , as @xmath12",
    ", we have the expansion @xmath213 ,   \\label{bahadurh}\\ ] ] so that the bias is reduced to @xmath22 in either case .",
    "therefore , we have @xmath214 provided that @xmath215 .",
    "@xcite proposed other automatic bias reduction methods applicable to general nonlinear panel data models .",
    "their bias reduction methods are basically applicable to the model misspecification case .",
    "is large . ]    alternatively , a direct approach to bias correction is to analytically estimate the bias term . in this case",
    ", we typically estimate the first order bias term @xmath216 by using the technique of hac covariance matrix estimation ( see * ? ? ?",
    "moreover , another alternative approach is to use bias reducing priors on individual effects ( see , for example , * ? ? ? * and references therein ) .",
    "see also @xcite for a review on bias correction for fixed effects estimators in nonlinear panel data models .      by the previous discussion ,",
    "a bias corrected estimator @xmath217 typically has the expansion @xmath218 . \\label{expansion3}\\ ] ] given this expansion , provided that @xmath215 , the distribution of @xmath217 can be approximated by @xmath219 . statistical inference on @xmath59",
    "can be implemented by using this normal approximation . as usual , since the matrices @xmath27 and @xmath176 are unknown , we have to replace them by suitable estimators .",
    "a natural estimator of @xmath27 is @xmath142 defined in ( [ fe2 ] ) , which is in fact consistent ( i.e. , @xmath220 ) as long as @xmath12 ( see lemma [ lem2 ] in appendix [ appendix a ] ) .",
    "we thus focus on the problem of estimating the matrix @xmath176 .",
    "we consider the estimator suggested by @xcite : @xmath221 where @xmath222 and @xmath217 is a suitable estimator of @xmath59 .",
    "proposition [ prop2 ] establishes the rate of convergence of @xmath223 .",
    "all the technical proofs of this section are gathered in appendix [ appendix b ] .",
    "[ prop2 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "let @xmath217 be any estimator of @xmath59 such that @xmath224 $ ] .",
    "letting @xmath12 as @xmath13 , we have : @xmath225.\\ ] ] in particular , as long as @xmath12 , we have @xmath226 .    in proposition [ prop2 ] , @xmath217 can be the fe estimator . actually , using a bias corrected estimator instead does not change the rate of convergence of @xmath223 . however , in the case where @xmath1 is relatively small , the fe estimator can be severely biased , which may affect the finite sample performance of @xmath223 .",
    "thus , it is generally recommended to use a bias corrected estimator of @xmath59 in the construction of @xmath223 .",
    "the results of @xcite are not directly applicable to the asymptotic properties of @xmath223 described in proposition [ prop2 ] .",
    "this is because the individual dummies that control for fixed effects are not included in the model of @xcite ( see also previous remark [ rem : hansen ] ) .",
    "thus , in contrast with @xcite , @xmath227 is not asymptotically normal with mean zero unless @xmath228 .",
    "the main reason is that @xmath223 has a bias of order @xmath229 due to using @xmath162 instead of @xmath230 $ ] .",
    "this bias appears even if we could use @xmath70 in place of @xmath231 . however , for inference purposes , the rate of convergence given in proposition [ prop2 ] is sufficient , and we do not consider the bias correction to @xmath223 .",
    "assume now that @xmath190 is nonsingular in either case of @xmath72 = \\bm{0}$ ] a.s . or not .",
    "consider testing the null hypothesis @xmath232 , where @xmath233 is a @xmath234 matrix with rank @xmath235 ( @xmath236 ) , and @xmath237 is a constant vector .",
    "suppose that we have a bias corrected estimator @xmath217 having the expansion ( [ expansion3 ] ) . then under the null hypothesis ,",
    "the @xmath9-type ( for @xmath238 ) and wald - type statistics @xmath239^{-1}(r{\\widetilde}{{\\bm{\\beta } } } - \\bm{r } ) , \\label{wald}\\ ] ] converge in distribution to @xmath240 and @xmath241 , respectively , provided that @xmath215 .",
    "for example , for @xmath238 , provided that @xmath215 , @xmath242 where the second equality is due to the fact that @xmath243 and @xmath244 .",
    "the same machinery applies to the wald - type statistic .",
    "importantly , in the construction of @xmath9-type or wald - type statistics , we do not need any knowledge on the degree of model misspecification .    the resulting estimator @xmath245 of the covariance matrix @xmath246 is often called the clustered covariance matrix ( ccm ) estimator in the literature .",
    "the ccm estimator is popular in empirical studies .",
    "the appealing point of the ccm estimator , as discussed in @xcite , is the fact that it is free from any user - chosen parameter such as a bandwidth .",
    "the previous discussion shows that inference using a suitable bias corrected estimator and the ccm estimator is `` robust '' to model misspecification .",
    "bootstrap is generally used as a way to estimate the distribution of a statistic ( see * ? ? ? * for a general reference on bootstrap ) . for panel data , how to implement bootstrap",
    "is not necessarily apparent .",
    "see @xcite for some possibilities in bootstrap resamplings for panel data .",
    "we here study , among them , the cross section bootstrap .",
    "let @xmath247 with @xmath248 .",
    "the cross section bootstrap randomly draws @xmath249 from @xmath250 with replacement .",
    "the bootstrap fe estimator @xmath251 is defined by @xmath50 in ( [ fe ] ) with @xmath252 replaced by @xmath249 . by this definition",
    ", we can express @xmath251 as the following form : @xmath253 where @xmath254 is the number of times that @xmath255 is `` redrawn '' from @xmath250 .",
    "the vector @xmath256 is independent of @xmath257 and multinomially distributed with parameters @xmath0 and ( probabilities ) @xmath258 .",
    "we need to prepare some notation and terminology .",
    "let @xmath259 denote the probability measure with respect to @xmath260 .",
    "let @xmath261 $ ] denote the expectation under @xmath259 . given a vector valued statistic @xmath262 depending on both @xmath263 and @xmath260 , and a deterministic sequence @xmath264 , we write `` @xmath265 in probability '' if for every @xmath266 and @xmath127 , @xmath267 as @xmath13 , and `` @xmath268 in probability '' if for every @xmath127 and @xmath269 , there exists a constant @xmath270 such that @xmath271 for all @xmath272 ( recall that @xmath273 ) .",
    "we are now in position to state the main result of this section .",
    "[ prop3 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "letting @xmath12 as @xmath13 , we have : @xmath274 , \\label{bahadurb}\\ ] ] in probability .",
    "therefore , provided that @xmath190 is nonsingular , we have : @xmath275 where the inequalities are interpreted coordinatewise .",
    "interestingly , proposition [ prop3 ] shows that despite the fact that the original fe estimator has the incidental parameters bias of which the top order is @xmath21 , as shown in proposition [ prop1 ] , the bootstrap distribution made by applying the cross section bootstrap to the fe estimator does not have the incidental parameters bias . as a consequence , the bootstrap distribution approaching the centered normal distribution holds without any specific growth condition on @xmath1 .",
    "in fact , this is not surprising .",
    "the main source of the incidental parameters bias comes from the term @xmath276 , which is linear in the cross section dimension .",
    "the bootstrap analogue of this term is thus @xmath277 , so that the difference of these terms has mean zero with respect to @xmath259 .",
    "the same machinery applies to the term @xmath278 , so that the incidental parameters bias is completely removed in the bootstrap distribution .",
    "the previous discussion also has the following implication : the cross section bootstrap can not be used as a way to correct the incidental parameter bias .",
    "recall that in the cross section case , the bootstrap can be used to correct the second order bias coming from the quadratic term ; here the incidental parameters bias comes from the terms linear in the cross section dimension , so that the cross section bootstrap does not work as a way to correct the bias .",
    "proposition [ prop3 ] shows that , for @xmath279 fixed and @xmath280 , @xmath281 we have @xmath282 where @xmath283 is the distribution function of the standard normal distribution ( recall that @xmath25 is the @xmath26-th element of a vector @xmath24 and @xmath28 denotes the @xmath29-element of a matrix @xmath27 ) .",
    "suppose that we have a bias corrected estimator @xmath217 having the expansion ( [ expansion3 ] ) . then by a standard argument , we can deduce that @xmath284 provided that @xmath215 .",
    "note that @xmath285 can be computed with any precision by using simulation .",
    "moreover , the computation of @xmath285 does not require any knowledge on the speed of @xmath286 , and in this sense the cross section bootstrap is robust to model misspecification .",
    "an analogous result holds for the hpj estimator ( see section 4.1 ) .",
    "[ cor4 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "let @xmath287 denote the hpj estimator based on the bootstrap sample @xmath288 .",
    "letting @xmath12 as @xmath13 , we have : @xmath289,\\ ] ] in probability .",
    "therefore , provided that @xmath190 is nonsingular , we have : @xmath290    this corollary follows directly from the definition of the hpj estimator and proposition [ prop3 ] , and hence we omit the proof . basically , the conclusion of corollary [ cor4 ] holds for other reasonable bias corrected estimators .",
    "we do not attempt to encompass generality in this direction .",
    "analogous results hold for pivotal statistics .",
    "because of the space limitation , we push the formal results on pivotal statistics to the appendix ( appendix [ appendix ] )",
    ".    the higher order properties of the cross section bootstrap will be very complicated in this setting and we do not attempt to study them here .",
    "however , it is of interest to quantify the order of the convergence in , say , ( [ bootb ] ) in appendix [ appendix ] , which is left to future research .",
    "there are some earlier works on the bootstrap for panel data .",
    "@xcite called the cross section bootstrap in this paper the `` block bootstrap '' and studied its numerical properties by using simulations , but did not study its theoretical properties .",
    "@xcite developed the asymptotic properties of the cross section bootstrap when the strict exogeneity is met , hence excluding the possibility that the incidental parameters bias appears .",
    "@xcite studies the asymptotic properties of the moving block bootstrap for panel data , which resamples the data in the time series dimension and hence is different from the cross section bootstrap .",
    "importantly , while @xcite allowed for cross section dependence which we exclude here , she assumed that the number of time periods , @xmath1 , is sufficiently large ( typically @xmath291 ) so that the incidental parameters bias does not appear .",
    "lastly , @xcite proposed to use the cross section bootstrap for inference for nonlinear panel data models such as panel probit models , but did not give any theoretical result .",
    "the asymptotic properties of the cross section bootstrap were largely unknown when the incidental parameters bias appears , even without model misspecification , and the results in this section contribute to filling this void and give useful suggestions to empirical studies .    in ( [ bfe ] ) ,",
    "the weights @xmath260 are multinomially distributed .",
    "it is possible to consider other weights .",
    "a perhaps simplest variation is to draw independent weights @xmath292 from a common distribution with mean @xmath293 and variance @xmath294 , which corresponds to the _ weighted bootstrap _ ( see , for example , * ? ? ?",
    "let @xmath295 denote ( [ bfe ] ) with @xmath254 replaced by these independent weights @xmath296 .",
    "then the conclusion of proposition [ prop3 ] holds with @xmath251 replaced by @xmath295 and @xmath297 replaced by @xmath298 .",
    "since the proof is completely analogous , we omit the details for brevity .",
    "so far , we have discussed the distributional properties of the cross section bootstrap . given proposition [ prop3 ] ,",
    "it is natural to estimate the asymptotic covariance matrix @xmath299 by the conditional covariance matrix of @xmath300 .",
    "however , since convergence in distribution does not imply moment convergence , proposition [ prop3 ] does not guarantee that @xmath301 \\to a^{-1}\\sigma a^{-1}$ ] in probability .",
    "see @xcite for some examples of inconsistency of bootstrap variance estimators . in linear regression models with pure cross section or time series data",
    ", @xcite discussed bootstrap - based covariance matrix estimation . in @xcite",
    ", they made a modification to the bootstrap least square estimator , to guarantee the bootstrap estimator to satisfy a uniform integrability condition .",
    "their modification is a sort of `` trimming '' to the second moment matrix . by doing so , they established the consistency of the bootstrap covariance matrix estimator . in the present panel data case , while their modification is straightforward to adapt to the fe estimator , it is not clear whether it actually works at the proof level . in proposition",
    "[ prop3 ] , what we have done are : ( i ) to implement higher order stochastic expansions to the fe estimator to exhaust the incidental parameters bias of any order ; ( ii ) to implement ( i ) to the bootstrap analogue ; ( iii ) to eliminate the incidental parameters bias by taking the difference . in step ( ii )",
    ", we need expansions of @xmath302 , or more precisely @xmath303 .",
    "simply bounding @xmath304 from above , as @xcite did in step 3 of the proof of their theorem 1 , will leave the bias in the bootstrap distribution and cause a problem in establishing uniform integrability .",
    "we leave this as an open problem .",
    "in this section , numerical examples to illustrate the methods discussed in this paper are provided .",
    "both monte carlo experiments and a real data analysis are presented .",
    "all the numerical experiments were performed on the statistical software r @xcite .",
    "computer programs to replicate the numerical analyses are available from the authors .",
    "we use several different designs of simulation experiments to assess the finite sample performance of the estimates and inference procedures discussed in the previous sections . in the first design , as a benchmark , we analyze the estimates and inference procedures under correct specification . the true data generating process ( dgp ) in the first design follows a panel ar(1 ) model and we ( correctly ) fit panel ar(1 ) .",
    "the next four models are designed to study the estimates and inference procedures under misspecification .. ] in the second design , the true dgp follows a panel ar(2 ) model ( see example 1 in section [ sec : interpretation ] ) ; in the third design we extend the true ar(2 ) dgp and include two lags of exogenous regressors ; and in the last design , the true dgp follows a random coefficient ar(1 ) model ( see example 2 in section [ sec : interpretation ] ) . in each of these cases ,",
    "we incorrectly fit a panel ar(1 ) model and estimate the slope parameter .",
    "note that the first three cases correspond to `` @xmath305 = \\bm{0}$ ] '' case and the last case corresponds to `` @xmath305 \\neq \\bm{0}$ ] '' case .",
    "the following sample sizes are considered : @xmath306 and @xmath307 .",
    "the number of monte carlo repetitions is 2,000 .",
    "we consider four different estimates : the fe , gmm @xcite , hpj estimates , and the bias corrected estimate proposed by ( * ? ? ?",
    "* equation ( 6 ) ) ( hk ) .",
    "more precisely , the gmm estimate we compare is the one - step gmm estimate formally defined in equation ( 8) in @xcite .",
    "we also investigate the small sample properties of the inference procedures , paying particular attention to the empirical coverage probability .",
    "the nominal coverage is 95% .",
    "note that we are trying to construct a 95% confidence interval for the pseudo - true parameter .",
    "we consider and compare the following options for inference on the pseudo - true parameter :    [ cols=\"^,^,^\",options=\"header \" , ]     in the hk option , we use a simple consistent estimate of the asymptotic variance based on the formula in @xcite . here",
    "csb refers to `` cross section bootstrap '' .",
    "the number of bootstrap repetitions in each case is 1,000 .",
    "note that the bias and variance formula in @xcite are not valid under the misspecified settings below ( nevertheless the hk estimate is consistent for the pseudo - true parameter when @xmath0 and @xmath1 jointly go to infinity as the difference between the fe and hk estimates are @xmath2 ) , hence it is natural to expect the hk option does not perform well in those cases ( as it is not designed for covering model misspecification ) .",
    "also it is expected that the fe estimate suffers from the incidental parameters bias and hence the fe - ccm option will not work well .",
    "the gmm estimate is formally not known to be consistent for the pseudo - true parameter here , but the result of @xcite suggests that it is the case ( and hence comparison with the gmm estimate makes some sense ) .",
    "first and then @xmath37 , so his result is not directly transferred to our case .",
    "it is of interest to study the asymptotic properties of the gmm estimate under misspecification when @xmath0 and @xmath1 jointly go to infinity , which is left to future research .",
    "] however , it is expected that the gmm option will not perform well as it is not designed for covering model misspecification . the last",
    "four options are expected to work reasonably well at least when @xmath1 is moderately large .",
    "the precise description of the hpj - hpjpb option is the following : in the hpj - hpjpb , we use the hpj estimate as the center , and apply the cross section bootstrap to the @xmath9-statistic . the @xmath9-statistic here is constructed by using the hpj estimate together with the ccm estimate , and the initial estimate in construction of the ccm estimate is the hpj estimate .      in the first example , the true data generating process ( dgp ) is a panel ar(1 ) model : @xmath308 where @xmath309 ( @xmath9 distribution with @xmath310 degrees of freedom ) , @xmath311 , and @xmath312 . in generating @xmath6 we set @xmath313 and discard the first 500 observations , using the observations @xmath314 through @xmath1 for estimation . in this case",
    ", we correctly fit panel ar(1 ) and there is no misspecification in the model . the results are collected in table [ table.mc.0 ] .",
    "* table [ table.mc.0 ] * : the fe estimate has large bias . the hk and gmm estimates are biased when @xmath1 and @xmath0 are small , but the bias decreases as @xmath1 and @xmath0 are large , respectively . the hpj estimate is approximately unbiased . regarding inference , the empirical coverage of fe - ccm is close to zero , likely due to the large bias in the fe estimate .",
    "hk is under coverage .",
    "gmm , as expected , has a good coverage property in this case , especially for large @xmath0 .",
    "it is important to notice that the robust inference procedures , especially hpj - hpjb and hpj - hpjpb , also have good coverage under no model misspecification .    in the next example",
    ", the true dgp follows a panel ar(2 ) model : @xmath315 where @xmath309 and @xmath311 .",
    "two cases for the parameters @xmath316 and @xmath317 are considered : @xmath318 and @xmath319 . despite that the true dgp is a panel ar(2 ) model , suppose that we incorrectly fit a panel ar(1 ) model and estimate the slope parameter .",
    "when @xmath318 , the pseudo - true parameter is @xmath320 , and when @xmath319 , @xmath321 .",
    "the results for these two cases are presented in tables [ table.mc.1 ] and [ table.mc.2 ] , respectively .",
    "* table [ table.mc.1 ] * : the fe and gmm estimates are severely biased .",
    "the hk estimate is also biased as it is not designed for handling the case where misspecification is present .",
    "the hpj estimate is able to reduce the bias substantially .",
    "the bias is small even for modest @xmath1 , such as @xmath322 and @xmath323 .",
    "regarding the standard deviations , the hpj estimate has slight variance inflation relative to the fe estimate in the finite sample ( which is also observed in @xcite in a different context of estimation of nonlinear panel data models such as panel probit models ) .    as for the empirical coverage , the fe - ccm , hk , and gmm options perform poorly due to the fact that the fe , hk , and gmm estimates are largely biased .",
    "the other options , namely , hpj - ccm , hpj - feb , hpj - hpjb and hpj - hpjpb , perform reasonably well , but the hpj - hpjpb option , as expected , seems to be the best .",
    "the coverage of hpj - hpjpb is about 92% for @xmath324 and @xmath323 , and close to the nominal @xmath325 .",
    "* table [ table.mc.2 ] * : in this case , the incidental parameters bias is small and all the options perform relatively well .",
    "however , regarding coverage , as @xmath0 grows , the performance of the fe - ccm , hk , and gmm options deteriorates since the ratio between the bias and the standard deviation becomes larger in each case . on the other hand , the other options , hpj - ccm , hpj - feb , hpj - hpjb and hpj - hpjpb , perform well regardless of the combination of @xmath326 .",
    "* table [ table.mc.5 ] * : to extend the ar(2 ) example , we include exogenous regressors in the true dgp . in this case",
    ", the true dgp is as following : @xmath327 where @xmath309 , @xmath311 , and @xmath328 . finally , the parameters @xmath329 and @xmath330 . in this case",
    ", we incorrectly fit a panel model with regressors @xmath331 and report estimates of the slope parameter of the autoregressive term .",
    "this pseudo - true parameter value on the autoregressive term is @xmath332 .",
    "the results for this case are presented in tables [ table.mc.5 ] .",
    "the results in table [ table.mc.5 ] show evidence that the proposed methods are effective in finite sample .",
    "the bias of the hpj estimator is small , on the other hand the bias of other estimators are large . regarding inference , given the bias in the fe , hk and gmm ,",
    "their respective coverage rates are poor .",
    "but , the empirical coverage of hpj - hpjb and hpj - hpjpb are close to the nominal .      in the fourth example",
    ", the true dgp is @xmath333 where @xmath334 , @xmath335 .",
    "this model appears in example 3 in section [ sec : interpretation ] .",
    "as before , we incorrectly fit a panel ar(1 ) model and estimate the slope parameter .",
    "the value of the pseudo - true parameter is @xmath336 .",
    "the simulation results for this case are presented in table [ table.mc.4 ] .",
    "* table [ table.mc.4 ] * : as in the previous cases , the fe estimate is largely biased and fe - ccm performs poorly due to the bias .",
    "note that the decreasing speed of the standard deviation for the fe estimate as @xmath1 grows is relatively slow , which would reflect the fact that the convergence rate of the fe estimate ( without the bias part ) under this dgp is @xmath4 and not @xmath3 ( the asymptotic variance of the fe estimate consists of the part decreasing like @xmath198 and also the part decreasing like @xmath170 , so even in this case , it is not surprising that the standard deviation of the fe estimate in the finite sample slowly decreases as @xmath1 increases ) .",
    "the hpj estimate is able to largely remove the bias , nevertheless there is slight variance inflation in the finite sample . in this example , the hk and gmm estimates are able to reduce the bias , to some extent , for large time series .",
    "however , the empirical coverage of the hk and gmm options is still poor .",
    "lastly , among the inference procedures , hpj - hpjpb works particularly well .      in this section",
    ", we apply the procedures discussed in the previous sections to a model of unemployment dynamics at the u.s .",
    "state level . @xcite and @xcite studied this subject using a dynamic panel data model .",
    "in particular , @xcite modeled the current unemployment rate @xmath337 as a function of both lagged unemployment rate and economic growth rate @xmath338 .",
    "in addition , to capture state specific effects , the model includes state individual intercepts @xmath339 .",
    "the model can be written as follows : @xmath340 or equivalently @xmath341 where @xmath342 and @xmath343 is an innovation term .",
    "the model described in equation ( [ eq.app2 ] ) shows that changes in unemployment rate are determined by two observable components .",
    "the first is an adjustment of the unemployment rate towards a `` natural '' or `` equilibrium '' rate of unemployment , @xmath344 .",
    "this rate of unemployment equilibrium is allowed to vary across states . moreover ,",
    "the speed of adjustment of the unemployment rate towards the state specific equilibrium is equal to @xmath345 .",
    "similarly , the second factor determining changes in unemployment rate is a deviation of the economic growth rate around a constant equilibrium .",
    "the data for the unemployment rate are taken from the u.s .",
    "bureau of labor statistics for the 19762010 period .",
    "data for the state product are per capita personal income ( thousands of dollars ) from the u.s .",
    "bureau of economic analysis deflated by annual implicit price deflator .",
    "the economic growth rate is taken to be the relative growth of the state product .",
    "data are available for all 50 u.s .",
    "states and washington d.c .",
    "we have a panel data set of 51 subjects over 35 years ( @xmath346 and @xmath347 ) .",
    "we consider and compare several different inference procedures : the fe estimate with its associated ccm estimate ( fe - ccm ) ; and the hpj estimate with inference using its associated ccm estimate and pivotal cross - section bootstrap , which we denote by hpj - ccm and hpj - hpjpb , respectively . for comparison , we also report the results for the one - step gmm , and the two - stage least squares ( tsls ) @xcite estimates . and",
    "@xmath348 as instruments . ]",
    "we present 90% and 95% confidence intervals in all cases .",
    "note here that the hpj - ccm and hpj - hpjpb options are misspecification robust , so they provide meaningful inference even when misspecification is present .",
    "the results for point estimates and confidence intervals are collected in table [ t.app ] panel a for 1976 - 2010 .",
    "the hpj estimate of @xmath349 ( columns hpj - ccm and hpj - hpjpb ) is 0.830 , which implies that the speed of adjustment is approximately 17% per year .",
    "the fe estimate is 0.790 , implying a speed of convergence around 21% , and the gmm estimate is 0.80 with speed of approximately 20% . finally , the tsls estimate for @xmath349 is smaller than other estimates , and the speed of adjustment is larger , close to 67% . regarding confidence intervals for @xmath349 , fe - ccm , hpj - ccm , hpj - hpjpb and gmm have confidence intervals with similar length , while the confidence intervals of tsls are substantially larger than the other options .",
    "the results for hpj - ccm and hpj - hpjpb are very similar .",
    "now we move our attention to the economic growth rate variable .",
    "the hpj estimate of @xmath350 is @xmath351 , which in absolute value is slightly smaller than the fe - ccm and gmm estimates but larger than the tsls estimate .",
    "the confidence intervals of hpj - ccm and hpj - hpjpb are similar .",
    "the fe estimate of @xmath350 is @xmath352 .",
    "this estimate is accompanied with relatively narrow confidence intervals and zero is not included in the intervals . however , the tsls estimate of @xmath350 @xmath353 , and zero is inside both the 90% and 95% confidence intervals in the tsls option . for robustness purposes we use different subsamples to estimate the model .",
    "we consider two subsamples : ( i ) 19762001 ; and ( ii ) 19761991 .",
    "the results are , respectively , collected in panels b and c of table [ t.app ] .    in the first robustness exercise we drop the last 9 years of observations and consider a subsample of 26 years , from 1976 to 2001 .",
    "these results are displayed in panel b. they show point estimates for both @xmath349 and @xmath350 close to those in panel a , although slightly larger in absolute value .",
    "confidence intervals are also similar to those in panel a.",
    "lastly , we consider an even smaller subsample with 19 years , from 1976 to 1991 .",
    "the results are presented in table [ t.app ] panel c. except for tsls , the point estimates of @xmath349 are smaller than those in the full sample case and the confidence intervals shift to the left .",
    "in particular , the fe and gmm estimates of @xmath349 decrease substantially , from 0.790 and 0.800 in the full sample case to 0.676 and 0.669 , respectively .",
    "the hpj estimate also decrease to 0.721 from 0.830 in the full sample case , but not so largely as gmm . moreover , fe - ccm , hpj - ccm and hpj - hpj - hpjpb have substantially narrower confidence intervals than tsls . regarding the results on @xmath350 , the point estimates are not larger in absolute value than in the full sample case ( except for tsls ) with wider confidence intervals than those using the full sample .",
    "this paper has considered fixed effects ( fe ) ( or within group ) estimation for linear panel data models under possible model misspecification , where the conditional mean @xmath354 $ ] may not be additive in @xmath7 and @xmath5 , nor linear in @xmath5 , when both the number of individuals , @xmath0 , and the number of time periods , @xmath1 , are large .",
    "we make several contributions to the literature .",
    "first , we have shown that the probability limit of the fe estimator is identical to the coefficient vector on @xmath5 of the best partial linear approximation to @xmath354 $ ] which we regard as the pseudo - true parameter .",
    "moreover , we have established the asymptotic distributional properties of the fe estimator around the pseudo - true parameter when @xmath0 and @xmath1 jointly go to infinity , and shown that after subtracting the incidental parameters bias , the rate of convergence of the fe estimate depends on the degree of model misspecification and is either @xmath3 or @xmath4 .",
    "secondly , we have developed asymptotically valid inference on the pseudo - true parameter vector .",
    "we have established the asymptotic properties of the clustered covariance matrix estimator and the cross section bootstrap when both model misspecification and the incidental parameters bias ( in the coefficient estimate ) are present .",
    "finally , we have conducted monte carlo simulations and evaluated the finite sample performance of the fe and its bias corrected estimators , and several inference methods and confirmed that the cross section bootstrap to pivotal statistics works particularly well .",
    "these inference methods were applied to a study of the unemployment dynamics in the u.s . state level .",
    "the authors would like to express their appreciation to ivan fernandez - val , kazuhiko hayakawa , seojeong lee , ryo okui , and participants in the 2013 econometric society north america summer meeting , and the ny camp econometrics viii , for useful comments and discussions regarding this paper .",
    "we also would like to thank the editor , the associate editor , and three anonymous referees for their careful reading and comments to improve the manuscript .",
    "99 alvarez , j. and arellano , m. ( 2003 ) .",
    "the time series and cross section asymptotics of dynamic panel data estimators .",
    "_ econometrica _ * 71 * 1121 - 1159 .",
    "an , h.z . and huang , f.c .",
    "the geometric ergodicity of nonlinear autoregressive models .",
    "_ statistica sinica _ * 6 * 943 - 956 .",
    "anderson , t.w . and hsiao , c. ( 1982 ) : formulation and estimation of dynamic models using panel data .",
    "_ journal of econometrics _ * 18 * 47 - 82",
    ". angrist , j. d. and pischke , j .- s .",
    "_ mostly harmless econometrics : an empiricist s companion_. princeton university press .",
    "arellano , m. ( 1987 ) .",
    "computing robust standard errors for within - groups estimators . _",
    "oxford bulletin of economics and statistics _ * 49 * 431 - 434 .",
    "arellano , m. and bond , s. ( 1991 ) .",
    "some tests of specification for panel data : monte carlo evidence and an application to employment equations .",
    "_ review of economic studies _ * 58 * 277 - 279 .",
    "arellano , m. and bonhomme , s. ( 2009 ) .",
    "robust priors in nonlinear panel data models .",
    "_ econometrica _ * 77 * 489 - 536 .",
    "arellano , m. and bover , o. ( 1995 ) .",
    "another look at the instrumental variable estimation of error - component models .",
    "_ journal of econometrics _ * 68 * 29 - 51 .",
    "arellano , m. and hahn , j. ( 2006 ) . a likelihood - based approximate solution to the incidental parameter problem in dynamic nonlinear models with multiple effects .",
    "arellano , m. and hahn , j. ( 2007 ) .",
    "understanding bias in nonlinear panel models : some recent development . in : _ advanced in economics and econometrics _ , vol .",
    "iii . econometric society , ed . by r.w .",
    "blundell , w.k .",
    "newey , and p. torsten , pp .",
    "381 - 409 , cambridge university press .",
    "baglan , d. ( 2010 ) .",
    "efficient estimation of a partially linear dynamic panel data model with fixed effects : application to unemployment dynamic in the u.s .",
    "bertrand , m. , duflo , e. and mullainathan , s. ( 2004 ) .",
    "how much should we trust difference in differences estimates ?",
    "_ quarterly journal of economics _ * 119 * 249 - 275 .",
    "bun , m.j.g . and carree , m.a .",
    "bias - corrected estimation in dynamic panel data models",
    ". _ journal of business and economic statistics _ * 23 * 200 - 210 .",
    "bun , m.j.g . and kiviet , j.f .",
    "the effects of dynamic feedbacks on ls and mm estimator accuracy in panel data models .",
    "_ journal of econometrics _ * 132 * 409 - 444 .",
    "cheng , g. and huang , j. ( 2010 ) .",
    "bootstrap consistency for general semiparametric @xmath355-estimation .",
    "_ annals of statistics _ * 38 * 2884 - 2915 .",
    "davidov , y. a. ( 1968 ) .",
    "convergence of distributions generated by stationary stochastic processes .",
    "_ theory of probability and its applications _ * 13 * 691 - 696 .",
    "dhaene , g. and jochmans , k. ( 2009 ) . split - panel jackknife estimation of fixed - effect models .",
    "dhaene , g. and jochmans , k. ( 2010 ) .",
    "an adjusted profile likelihood for non - stationary panel data models with fixed effects .",
    "preprint . fan , j. and yao , q. ( 2003 ) .",
    "_ nonlinear time series_. springer .",
    "gonalves , s. ( 2011 ) . the moving bootstrap for panel linear regression models with individual fixed effects .",
    "_ econometric theory _ * 27 * 1048 - 1082 .",
    "gonalves , s. and white , h. ( 2005 ) .",
    "bootstrap standard error estimates for linear regression . _ journal of the american statistical association _ * 100 * 970 - 979 .",
    "hahn , j. and kuersteiner , g. ( 2002 ) .",
    "asymptotically unbiased inference for a dynamic panel model with fixed effects when both @xmath0 and @xmath1 are large .",
    "_ econometrica _ * 70 * 1639 - 1657 .",
    "hahn , j. and kuersteiner , g. ( 2011 ) .",
    "bias reduction for dynamic nonlinear panel models with fixed effects .",
    "_ econometric theory _ * 27 * 1152 - 1191 .",
    "hansen , c.b .",
    "( 2007a ) .",
    "generalized least squares inference in multilevel models with serial correlation and fixed effects .",
    "_ journal of econometrics _ * 140 * 670 - 94 .",
    "hansen , c.b .",
    "( 2007b ) .",
    "asymptotic properties of a robust variance matrix estimator for panel data when @xmath1 is large .",
    "_ journal of econometrics _ * 141 * 597 - 620 .",
    "horowitz , j.l .",
    "( 2001 ) . _",
    "the bootstrap_. in : _ handbook of econometrics _ , vol .",
    "5 , ed . by j.j . heckman and e.e .",
    "leamer , pp .",
    "3159 - 3228 , elsevier .",
    "kapetanios , g. ( 2008 ) . a bootstrap procedure for panel data sets with many cross - sectional units .",
    "_ econometrics journal _ * 11 * 375 - 395 .",
    "kiviet , j.f .",
    "( 1995 ) . on bias , inconsistency , and efficiency of various estimators in dynamic panel data models .",
    "_ journal of econometrics _ * 68 * 53 - 78 .",
    "lancaster , t. ( 2000 ) .",
    "the incidental parameter problem since 1948 .",
    "_ journal of econometrics _ * 95 * 391 - 413 .",
    "lee , y. ( 2012 ) .",
    "bias in dynamic panel models under time series misspecification",
    ". _ journal of econometrics _ * 169 * 54 - 60 .",
    "lu , w. , goldberg , y. and fine , j.p .",
    "( 2012 ) . on the robustness of the adaptive lasso to model misspecification .",
    "_ biometrika _ * 99 * 717 - 731 .",
    "ma , s. and kosorok , m. ( 2005 ) .",
    "robust semiparametric @xmath355-estimation and the weighted bootstrap . _ journal of multivariate analysis _ * 96 * 190 - 217 .",
    "neyman , j , and scott , e. ( 1948 ) .",
    "consistent estimates based on partially consistent observations .",
    "_ econometrica _ * 16 * 1 - 31 .",
    "nickell , s. ( 1981 ) .",
    "biases in dynamic models with fixed effects .",
    "_ econometrica _ * 49 * 1417 - 1425 .",
    "okui , r. ( 2008 ) .",
    "panel ar(1 ) estimators under misspecification . _",
    "economics letters _ * 101 * 210 - 213 .",
    "okui , r. ( 2010 ) .",
    "asymptotically unbiased estimation of autocovariances and autocorrelations with long panel data .",
    "_ econometric theory _ * 26 * 1263 - 1304 .",
    "ozaki , t. ( 1985 ) .",
    "non - linear time series models and dynamical systems . in : _",
    "handbook of statistics 5 _ ( edited by e. j. hannan , p. r. krishnaiah and m. m. rao ) , elsevier science .",
    "phillips , p.c.b . and",
    "sul , d. ( 2007 ) .",
    "bias in dynamic panel estimation with fixed effects , incidental trends and cross section dependence .",
    "_ journal of econometrics _ * 137 * 162 - 188 .",
    "r development core team .",
    "r : a language and environment for statistical computing .",
    "r foundation for statistical computing .",
    "shao , j. ( 1992 ) .",
    "bootstrap variance estimators with truncation . _ statistics and probability letters _ * 15 * 95 - 101 .",
    "white , h. ( 1980 ) .",
    "using least - squares to approximate unknown regression functions . _ international economic review _ * 21 * 149 - 170 .",
    "white , h. ( 1982 ) . maximum likelihood estimation of misspecified models .",
    "_ econometrica _ * 50 * 1 - 25 .",
    "wooldridge , j.m .",
    "_ econometric analysis of cross section and panel data_. mit press .",
    "yokoyama , r. ( 1980 ) .",
    "moment bounds for stationary mixing sequences .",
    "_ z. wahrscheinlichkeitstheorie verw .",
    "gebiete _ * 52 * 45 - 57 .",
    "in this appendix , we consider bootstrapping pivotal statistics . we keep the notation used in section [ sec : inference ] .",
    "we first consider the bootstrap version of the ccm estimator ( here and in what follows , `` bootstrap '' means `` cross section bootstrap '' ) .",
    "let us write @xmath356 then the bootstrap ccm estimator is defined by @xmath357 where @xmath358 and @xmath359 is the bootstrap version of a suitable estimator of @xmath59 ( we formally assume that @xmath359 can be written as a statistic of @xmath252 and @xmath260 ) , for example , @xmath360 or @xmath361 .",
    "note that @xmath362 where @xmath363 .",
    "then we have the following proposition .    [ prop4 ]",
    "suppose that conditions ( a1)-(a3 ) are satisfied .",
    "let @xmath359 be such that @xmath364 $ ] in probability .",
    "letting @xmath12 as @xmath13 , we have : @xmath365,\\ ] ] in probability .",
    "in particular , as long as @xmath12 , we have @xmath366 in probability .",
    "proposition [ prop4 ] establishes the rate of convergence of @xmath367 .",
    "this result is parallel to that in proposition [ prop2 ] .",
    "note that the condition that @xmath364 $ ] in probability is satisfied with @xmath360 or @xmath368 .",
    "assume now that @xmath190 is nonsingular in either case of @xmath72 = \\bm{0}$ ] a.s . or not .",
    "consider , for the sake of simplicity , testing the null hypothesis @xmath369 , where @xmath279 is fixed , and consider the @xmath9-statistic and its bootstrap version based on either the fe or hpj estimate : @xmath370 where @xmath371 is the @xmath372 vector such that @xmath373 and @xmath374 for @xmath375 . here because @xmath376 ( see lemma [ lem3 ] ) and @xmath377 in probability , we can deduce that under conditions ( a1)-(a3 ) , @xmath378 this holds as long as @xmath12 and does not require any specific growth restriction on @xmath1 .",
    "moreover , when @xmath379 , under conditions ( a1)-(a3 ) , we have @xmath380 provided that @xmath215 .",
    "in order to shed more light on the performance of the proposed methods , figure [ fig1 ] presets the bias and rmse of the fe and hpj estimators from a fixed cross - section when varying the time series @xmath1 . in these simulations , we only considered the ar(2 ) model given in the second example with @xmath318 .",
    "we fix the cross - section dimension at @xmath381 .",
    "the left panel shows the bias of the estimators as a function of @xmath1 .",
    "the results show that the hpj estimator has a small bias for small @xmath1 , but the bias disappears even for relatively small @xmath1 . on the contrary , the bias in the fe is large , and it remains relatively substantial even for large time series .",
    "the right panel displays the rmse for the estimators .",
    "it shows a good performance of the hpj estimator for moderate time dimensions .",
    "increases for @xmath381 . _ [ fig1 ] ]      here we consider the case where the true dgp is @xmath382 where @xmath334 , @xmath311 , @xmath383 and @xmath384 . this model is a panel - data version of exponential ar ( expar ) models ( see * ? ? ?",
    "note that by ( * ? ? ?",
    "* example 3.2 ) , for each @xmath15 , the process @xmath385 ( which is independent of @xmath7 ) is geometrically ergodic , so that condition ( a1 ) is satisfied . as in the previous case ,",
    "we incorrectly fit a panel ar(1 ) model and estimate the slope parameter .",
    "the value of the pseudo - true parameter is @xmath386 .",
    "the simulation results for this case are presented in table [ table.mc.3 ] .",
    "* table [ table.mc.3 ] * : the fe estimate is severely biased and the fe - ccm option performs poorly because of the presence of large bias . on the other hand , the hpj estimate is able to largely remove the bias at the cost of slight variance inflation relative to the fe estimate in the finite sample . in this case , the hk and gmm estimates are able to reduce the bias to some extent , although gmm still presenting larger bias .",
    "the empirical coverage of the hk option is reasonably well ( which is partly due to the fact that the panel expar model is `` close '' to the panel ar(1 ) model ) .",
    "gmm is under coverage .",
    "in addition , the empirical coverage of the hk and gmm options worsen as @xmath0 becomes large . among the other options , hpj - hpjpb works particularly well .",
    "we shall recall here the notational convention . for a generic vector @xmath24",
    ", @xmath25 denotes the @xmath26-th element of @xmath24 , and for a generic matrix @xmath27 , @xmath28 denotes the @xmath29-th element of @xmath27 .",
    "moreover , for a sequence @xmath387 indexed by @xmath31 , we write @xmath388 .      in this section , we introduce some inequalities for @xmath121-mixing processes , which will be used in the proofs below .",
    "let @xmath389 denote a stationary process taking values in some polish space @xmath120 , and let @xmath390 denote its @xmath121-mixing coefficients .",
    "[ thma1 ] let @xmath391 denote the @xmath392-field generated by @xmath393 ( @xmath394 ) .",
    "pick any integer @xmath125 .",
    "let @xmath395 and @xmath396 be real - valued random variables measurable with respect to @xmath397 and @xmath398 , respectively . if @xmath399 < \\infty$ ] and @xmath400 <",
    "\\infty$ ] for some @xmath401 and @xmath402 such that @xmath403 , then we have @xmath404 - { \\mathbb{e } } [ \\xi ] { \\mathbb{e } } [ \\eta ] | \\leq 12",
    "( { \\mathbb{e } } [ | \\xi |^{q } ] ) ^{q^{-1}}({\\mathbb{e } } [ | \\eta |^{r } ] ) ^{r^{-1 } } \\alpha(k)^{1-q^{-1}-r^{-1}}.\\ ] ]    to illustrate an application of davidov s inequality , suppose that @xmath405 , and assume that @xmath406 < \\infty$ ] and @xmath407 for some @xmath408 .",
    "then by davidov s inequality , we have @xmath409 with @xmath410^{2/q } \\sum_{k=0}^{\\infty } \\alpha(k)^{1 - 2/q}$ ] . for bounding higher order moments ,",
    "we make use of yokoyama s ( 1980 ) theorem 3 .",
    "[ thma2 ] suppose that @xmath405 .",
    "assume that @xmath411 = 0 $ ] and for some constants @xmath127 and @xmath412 , @xmath413 < \\infty$ ] .",
    "if @xmath414 , then there exists a constant @xmath415 independent of @xmath1 such that @xmath416 \\leq c t^{r/2}.\\ ] ]              [ lem2 ] suppose that conditions ( a1)-(a3 ) are satisfied . as @xmath13 ( and automatically @xmath12 ) , we have : ( i ) @xmath142 is nonsingular with probability approaching one , and + @xmath422 ; ( ii ) @xmath423 = t^{-1 } b_{t } = o(t^{-1})$ ] ; ( iii ) @xmath424 = o_{{\\mathbb{p } } } ( n^{-1/2 } t^{-1 } ) $ ] ; ( iv ) @xmath425 ) \\stackrel{d}{\\to } n(\\bm{0},v_{1})$ ] , where @xmath426)({\\widetilde}{{\\bm{x}}}_{1,1+k}\\epsilon_{1,1+k}-{\\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1+k}\\epsilon_{1,1+k } \\mid c_{1}])']$ ] ( the right side is absolutely convergent in @xmath427 ) .    * part ( i ) * : recall that @xmath428 $ ] .",
    "observe that @xmath429 $ ] and @xmath430 ) \\\\",
    "& \\quad + \\frac{1}{n } \\sum_{i=1}^{n } ( { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{i1 } { \\widetilde}{{\\bm{x}}}_{i1 } ' \\mid c_{i } ] - { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1 } { \\widetilde}{{\\bm{x}}}_{1,1 } ' ] ) - \\frac{1}{n } \\sum_{i=1}^{n } ( \\bar{{\\widetilde}{{\\bm{x}}}}_{i}\\bar{{\\widetilde}{{\\bm{x}}}}_{i } ' - { \\mathbb{e } } [ \\bar{{\\widetilde}{{\\bm{x}}}}_{1}\\bar{{\\widetilde}{{\\bm{x}}}}_{1 } ' ] ) \\\\ & = : { \\widehat}{d}_{1 } + { \\widehat}{d}_{2 } - { \\widehat}{d}_{3}.\\end{aligned}\\ ] ] fix any @xmath431 .",
    "we wish to show that @xmath432 , @xmath433 and @xmath434 .",
    "we make use of theorems [ thma1 ] and [ thma2 ] .",
    "put @xmath435 $ ] . then @xmath436 and @xmath437 = n^{-1}t^{-2 }   { \\mathbb{e } } [   ( \\sum_{t=1}^{t } \\xi_{1 t } ) ^{2 } ] = n^{-1 } t^{-2 } { \\mathbb{e}}[{\\mathbb{e}}[(\\sum_{t=1}^{t } \\xi_{1 t } ) ^{2 } \\mid c_{1}]].\\ ] ] using theorem [ thma1 ] to bound @xmath438 $ ] , we have @xmath439 , which implies that @xmath432 .",
    "the fact that @xmath433 is deduced from a direct evaluation of the variance .",
    "we next show that @xmath440 . by the cross section independence and the cauchy - schwarz inequality",
    ", we have @xmath441 =   \\frac{1}{n^{2 } } \\sum_{i=1}^{n } \\operatorname{var}(\\bar{{\\widetilde}{x}}_{i}^{a } \\bar{{\\widetilde}{x}}_{i}^{b } ) = n^{-1 } \\operatorname{var}(\\bar{{\\widetilde}{x}}_{1}^{a } \\bar{{\\widetilde}{x}}_{1}^{b } ) \\leq n^{-1 }   ( { \\mathbb{e } } [ { \\mathbb{e } } [ ( \\bar{{\\widetilde}{x}}_{1}^{a})^{4 } \\mid c_{1}]])^{1/2 } ( { \\mathbb{e } } [ { \\mathbb{e } } [ ( \\bar{{\\widetilde}{x}}_{1}^{b})^{4 } \\mid c_{1 } ] ] ) ^{1/2}.\\ ] ] using theorem [ thma2 ] to bound @xmath442 $ ] and @xmath443 $ ] , we have @xmath444 = o(n^{-1}t^{-2})$ ] , which implies that @xmath445 .",
    "therefore , we have @xmath446 . by condition ( a3 )",
    ", there exists a constant @xmath447 such that @xmath448 . by lemma [ lem1 ] , @xmath449 , which implies that @xmath142 is nonsingular with probability approaching one .",
    "we wish to obtain the expansion of @xmath142 . by condition ( a3 ) and",
    "lemma [ lem1 ] , @xmath450 is nonsingular for large @xmath0 , and @xmath451 . put @xmath452 so that @xmath453 . since @xmath454",
    ", applying the taylor expansion to the term @xmath455 , we have @xmath456 since @xmath457 , applying the taylor expansion to the term @xmath458 , we have @xmath459 where the right side is absolutely convergent in @xmath427 for large @xmath0 .      * part ( iii ) * : fix any @xmath279 .",
    "it suffices to show that @xmath460 . by the cross section independence and the cauchy - schwarz inequality ,",
    "we have @xmath461 = n^{-1 } { \\mathbb{e } } [ ( \\bar{{\\widetilde}{x}}_{1}^{a } \\bar{\\epsilon}_{1})^{2 } ] \\leq n^{-1 }   ( { \\mathbb{e } } [ { \\mathbb{e } } [ ( \\bar{{\\widetilde}{x}}_{1}^{a})^{4 } \\mid c_{1}]])^{1/2 } ( { \\mathbb{e } } [ { \\mathbb{e } } [ ( \\bar{\\epsilon}_{1})^{4 } \\mid c_{1 } ] ] ) ^{1/2}.\\ ] ] using theorem [ thma2 ] to bound @xmath442 $ ] and @xmath462 $ ] , we have @xmath463 .    *",
    "part ( iv ) * : the fact that @xmath464 is absolutely convergent is deduced from theorem [ thma1 ] .",
    "we wish to show the asymptotic normality . by the cramr - wald device",
    ", it suffices to show that for any fixed @xmath182 , @xmath465 ) \\stackrel{d}{\\to } n(0,\\bm{r}'v_{1}\\bm{r})$ ] .",
    "define @xmath466)$ ] .",
    "then , @xmath467 ) = \\frac{1}{\\sqrt{n } } \\sum_{i=1}^{n } u_{ni}.\\ ] ] since @xmath468 are i.i.d .",
    ", we can apply the lyapunov central limit theorem to the right sum .",
    "since @xmath469 , it suffices to show that @xmath470 = o(n^{1/2})$ ] . here , using theorem [ thma2 ] to bound @xmath471 $ ] , we have @xmath470 = { \\mathbb{e } } [ { \\mathbb{e } } [ | u_{n1 } |^{3 } \\mid c_{1 } ] ] = o(1 ) = o(n^{1/2})$ ]",
    ". therefore , we obtain the desired result .",
    "the expansion ( [ bahadur ] ) follows from lemma [ lem2 ] ( note that we use the fact that @xmath472 ) .",
    "suppose that @xmath171 = \\bm{0}$ ] a.s .",
    "then @xmath473 $ ] , so that by lemma [ lem2 ] ( iv ) , @xmath474 .",
    "suppose now that @xmath171 \\neq \\bm{0}$ ] with positive probability .",
    "then we have @xmath475 + \\sqrt{n } ( { \\widehat}{s}_{1}-{\\mathbb{e}}[{\\widehat}{s } \\mid \\ { c_{i } \\}_{i=1}^{n } ] ) \\\\ & = \\sqrt{n } { \\mathbb{e}}[{\\widehat}{s}_{1 } \\mid \\ { c_{i } \\}_{i=1}^{n } ] + o_{{\\mathbb{p}}}(t^{-1/2 } ) \\\\ & \\stackrel{d}{\\to } n(\\bm{0},v_{2}),\\end{aligned}\\ ] ] where @xmath476^{\\otimes 2}]$ ] .",
    "the asymptotic normality follows from the fact that @xmath477 if @xmath171 = \\bm{0}$ ] a.s . and @xmath478 otherwise .",
    "by lemma [ lem1 ] , we have @xmath479   + o(t^{-1})$ ] .",
    "observe that @xmath480 \\| & =   \\sum_{|k| \\geq t } |k|^{-1 } \\cdot |k|\\|   { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1 } \\epsilon_{1,1+k } ] \\| \\\\ & \\leq \\frac{1}{t }   \\sum_{|k| \\geq t } |k| \\| { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1 } \\epsilon_{1,1+k } ] \\| \\\\ & \\leq \\frac{1}{t }   \\sum_{k=-\\infty}^{\\infty } |k| \\| { \\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1 } \\epsilon_{1,1+k } ] \\| = o(t^{-1}).\\end{aligned}\\ ] ] therefore , we have @xmath481 , which implies the desired result .        since @xmath482",
    ", we have @xmath483 where @xmath484 by definition",
    ", we have @xmath485 by theorems [ thma1 ] and [ thma2 ] , we can show that @xmath486 \\leq c nd_{nt}^{-1}$ ] , @xmath487 \\leq ( { \\mathbb{e } } [ \\| \\bar{{\\widetilde}{{\\bm{x}}}}_{i } \\|^{4}])^{1/2 } ( { \\mathbb{e } } [ \\bar{\\epsilon}_{i}^{4}])^{1/2 } \\leq c t^{-2}$ ] and @xmath488 \\leq c$ ] for some constant @xmath489 .",
    "therefore , we have @xmath490.\\ ] ] in what follows , we wish to show that @xmath491 . fix any @xmath431 . by definition , we have @xmath492 ) ( { \\widetilde}{x}_{it}^{b } \\epsilon_{it } - { \\mathbb{e } } [ { \\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad + \\frac{1}{n^{2 } } \\sum_{i=1}^{n } { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{a } \\epsilon_{i1 } \\mid c_{i } ] \\left \\ { \\frac{1}{t } \\sum_{t=1}^{t } ( { \\widetilde}{x}_{it}^{b } \\epsilon_{it } -{\\mathbb{e}}[{\\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad + \\frac{1}{n^{2 } } \\sum_{i=1}^{n } { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] \\left",
    "\\ {   \\frac{1}{t } \\sum_{t=1}^{t } ( { \\widetilde}{x}_{it}^{a } \\epsilon_{it}-{\\mathbb{e}}[{\\widetilde}{x}_{i1}^{a } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad -   \\frac{1}{n^{2 } } \\sum_{i=1}^{n } { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{a}\\epsilon_{i1 } \\mid c_{i } ] { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{b}\\epsilon_{i1 } \\mid c_{i } ] \\\\ & = : ( i ) + ( ii ) + ( iii ) - ( iv ) . \\end{aligned}\\ ] ] it suffices to show that the variance of each term in ( i)-(iv ) is @xmath493 . letting @xmath494 $ ] and @xmath495 $ ] , we have @xmath496 \\\\ & = \\frac{1}{n^{3}t^{2 } } \\left ( \\frac{1}{t^{2 } } \\sum_{s=1}^{t } \\sum_{t=1}^{t } \\sum_{u=1}^{t }",
    "\\sum_{v=1}^{t } { \\mathbb{e}}[\\xi_{1s}\\eta_{1t}\\xi_{1u}\\eta_{1v } ] \\right ) .\\end{aligned}\\ ] ] using the same argument as in the proof of ( * ? ? ?",
    "* theorem 1 ) , we can show that the parenthesis on the right side is @xmath497.| \\leq c t^{2}$ ] for some constant @xmath415 .",
    "when @xmath498 , so that @xmath499 , the assertion directly follows from the proof of ( * ? ?",
    "* theorem 1 ) with @xmath500 .",
    "the proof for the @xmath501 case is almost the same as that for the @xmath498 case . ]",
    "therefore , we have @xmath502 . if @xmath171",
    "= \\bm{0}$ ] a.s .",
    ", ( ii)-(iv ) are zeros a.s .",
    ", so that @xmath503 .",
    "suppose now that @xmath171 \\neq \\bm{0}$ ] with positive probability . clearly , @xmath504 .",
    "likewise , we have @xmath505^{2 }   { \\mathbb{e}}\\left [   \\left ( \\frac{1}{\\sqrt{t } } \\sum_{t=1}^{t } \\eta_{1 t } \\right ) ^{2 } \\mid c_{1 } \\right ]   \\right ] .\\ ] ] by theorem [ thma1 ] , we have @xmath506 \\leq c$ ] a.s .",
    "for some constant @xmath489 , so that @xmath507 .",
    "similarly , we have @xmath508 .",
    "therefore , we have @xmath509 .          by lemma [ lemb1 ]",
    ", it suffices to evaluate the remainder term in the expansion ( [ bahadurb ] ) unconditionally since it is translated to the evaluation under the conditional probability without changing rates .",
    "[ lem3 ] suppose that conditions ( a1)-(a3 ) are satisfied .",
    "as @xmath13 ( and automatically @xmath12 ) , we have : ( i ) @xmath302 is nonsingular with probability approaching one , and @xmath515 ; ( ii ) @xmath516   = t^{-1}b_{t } = o(t^{-1})$ ] ; ( iii ) @xmath517 = o_{{\\mathbb{p } } } ( n^{-1/2 } t^{-1 } ) $ ] .    in the proof of lemma [ lem3 ] ,",
    "we use some elementary properties of multinomial distributions . recall that @xmath256 is multinomially distributed with parameters @xmath0 and ( probabilities ) @xmath258 .",
    "then @xmath518 = 1 $ ] and , for any fixed @xmath519 , @xmath520 = \\sum_{i=1}^{n } a_{i}^{2 } - n(n^{-1}\\sum_{i=1}^{n } a_{i})^{2}$ ] ( which can be directly deduced from the fact that @xmath260 are nonparametric bootstrap weights ) .      * part ( i ) * : by lemma [ lem2 ] ( i ) , it suffices to show that @xmath521 .",
    "decompose @xmath302 as @xmath522 similarly , decompose @xmath142 as @xmath523 we wish to show that @xmath524 and @xmath525 , which implies the desired result .",
    "fix any @xmath431 .",
    "observe that @xmath526 & \\leq \\frac{1}{n^{2}t^{2 } } \\sum_{i=1}^{n } \\left ( \\sum_{t=1}^{t } { \\widetilde}{x}_{it}^{a } { \\widetilde}{x}_{it}^{b } \\right ) ^{2 } \\\\ & \\leq \\frac{2}{n^{2}t^{2 } } \\sum_{i=1}^{n } \\left ( \\sum_{t=1}^{t } { \\widetilde}{x}_{it}^{a } { \\widetilde}{x}_{it}^{b } - { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{a } { \\widetilde}{x}_{i1}^{b } \\mid c_{i } ] \\right ) ^{2 } + \\frac{2}{n^{2 } } \\sum_{i=1}^{n } { \\mathbb{e } } [ { \\widetilde}{x}_{i1}^{a } { \\widetilde}{x}_{i1}^{b } \\mid c_{i}]^{2}.\\end{aligned}\\ ] ] by the proof of lemma [ lem1 ] ( i ) , the expectation of the first term is @xmath170 , while the expectation of the second term is @xmath527 .",
    "therefore , we have @xmath528 .",
    "it remains to show that @xmath529 .",
    "observe that @xmath530    \\leq \\frac{1}{n^{2 } } \\sum_{i=1}^{n }   ( \\bar{{\\widetilde}{x}}^{a}_{i } \\bar{{\\widetilde}{x}}^{b}_{i})^{2}.\\ ] ] by the proof of lemma [ lem2 ] ( i ) , the expectation of the right side is @xmath531 , which implies the desired result .      *",
    "part ( iii ) * : since @xmath533 = { \\mathbb{e } } [ { \\widehat}{s}_{2 } ] $ ] , we have @xmath534 & = { \\widehat}{s}_{2}^ { * } -{\\widehat}{s}_{2 } + { \\widehat}{s}_{2 } - { \\mathbb{e } } [ { \\widehat}{s}_{2 } ] \\\\ & = \\frac{1}{n } \\sum_{i=1}^{n } ( w_{ni}-1 ) \\bar{{\\widetilde}{{\\bm{x}}}}_{i } \\bar{\\epsilon}_{i } + ( { \\widehat}{s}_{2 } - { \\mathbb{e } } [ { \\widehat}{s}_{2 } ] ) .\\end{aligned}\\ ] ] by lemma [ lem2 ] ( iii ) , the second term is @xmath535 . it remains to show that the first term is @xmath535 .",
    "fix any @xmath279 . observe that @xmath536 \\leq \\frac{1}{n^{2}}\\sum_{i=1}^{n } ( \\bar{{\\widetilde}{x}}^{a}_{i } \\bar{\\epsilon}_{i})^{2}.\\ ] ] by the proof of lemma [ lem2 ] ( iii ) , the expectation of the right side is @xmath537 , which implies the desired result .",
    "[ lem4 ] under conditions ( a1)-(a3 ) , we have : @xmath538 ) \\leq { \\bm{x}}\\ } - { \\mathbb{p}}\\ { n(\\bm{0 } , v_{1 } ) \\leq { \\bm{x}}\\ } | \\stackrel{{\\mathbb{p}}}{\\to } 0,\\ ] ] where @xmath426)({\\widetilde}{{\\bm{x}}}_{1,1+k}\\epsilon_{1,1+k}-{\\mathbb{e}}[{\\widetilde}{{\\bm{x}}}_{1,1+k}\\epsilon_{1,1+k } \\mid c_{1}])']$ ] , provided that @xmath464 is nonsingular .",
    "* step 2 * : ( second assertion of ( [ event ] ) ) fix any @xmath431 .",
    "we wish to show that @xmath544 .",
    "observe first that @xmath545 \\to v_{1}^{ab}$ ] .",
    "thus , it suffices to show that @xmath546 as @xmath13 . by the cross section independence , @xmath547 .",
    "\\label{moment}\\ ] ] as in the proof of proposition [ prop2 ] , we can show that @xmath548 = o(1)$ ] , so that the right side on ( [ moment ] ) is @xmath198 , which implies the desired result .",
    "* step 3 * : ( third assertion of ( [ event ] ) ) from the proof of lemma [ lem2 ] part ( @xmath549 ) above , one can show that @xmath550 = o(1 ) = o(n^{1/2})$ ] for any @xmath279 , which in turn implies the desired result .",
    "we are now in position to prove the lemma .",
    "define @xmath551 in such a way that @xmath552 if @xmath553 for some @xmath554 for @xmath41 .",
    "letting @xmath555 , we have @xmath556 ) = n^{-1/2 } \\sum_{i=1}^{n}{\\widetilde}{\\bm{u}}_{ni}^{*}$ ] .",
    "observe that @xmath557 are i.i.d .",
    "with mean zero and covariance matrix @xmath558 conditional on @xmath257 .",
    "we use the following fact : let @xmath559 be a sequence of random variables and let @xmath560 be a constant ; if for any subsequence @xmath561 of @xmath562 there exists a further subsequence @xmath563 such that @xmath564 almost surely , then @xmath565 . recall that @xmath273 is indexed by @xmath0 . take any subsequence @xmath561 of @xmath562",
    ". then there exists a further subsequence @xmath563 such that along with the subsequence @xmath563 , ( [ event ] ) holds almost surely .",
    "this means that for almost every realization of @xmath566 , along with the subsequence @xmath567 , @xmath568 and the lyapunov condition is satisfied for @xmath569 .",
    "therefore , along with the subsequence @xmath563 , conditional on @xmath257 , @xmath556 ) \\stackrel{d}{\\to } n(\\bm{0},v_{1})$ ] for almost every realization of @xmath566 . by the above fact",
    ", we obtain the desired result .",
    "we wish to verify that @xmath570 .",
    "observe that @xmath571 ) \\notag \\\\ & \\quad + \\frac{1}{n } \\sum_{i=1}^{n } ( w_{ni}-1 )    { \\mathbb{e } } [ { \\widetilde}{{\\bm{x}}}_{i1 } \\epsilon_{i1 } \\mid c_{i } ] .",
    "\\label{expansion}\\end{aligned}\\ ] ] here the first term is @xmath572 and the second term is zero if @xmath573 = \\bm{0}$ ] and is @xmath574 otherwise . hence we conclude that @xmath570 .      for ( [ bootd ] )",
    ", suppose first that @xmath171 = \\bm{0}$ ] .",
    "then the second term in ( [ expansion ] ) vanishes , and the assertion ( [ bootd ] ) follows from lemma [ lem4 ] .",
    "suppose that @xmath171 \\neq \\bm{0}$ ] with positive probability .",
    "then the second term dominates the first term in ( [ expansion ] ) , it is routine to verify that @xmath576 \\leq { \\bm{x}}\\ } - { \\mathbb{p}}\\ { n(\\bm{0 } , v_{2 } ) \\leq { \\bm{x}}\\ } | \\stackrel{{\\mathbb{p}}}{\\to } 0,\\ ] ] where @xmath577^{\\otimes 2 } ] $ ] .",
    "this completes the proof .",
    "the proof is similar to that of proposition [ prop2 ] . since @xmath578 , we have @xmath579 where @xmath580 by the proof of proposition [ prop2 ] , together with the assumption that @xmath581 $ ] , and lemma [ lemb1 ] , we have @xmath582,\\ ] ] in probability .",
    "let @xmath583 by the proof of proposition [ prop2 ] , we have @xmath584 , and hence we only need to show that @xmath585 in probability .",
    "fix any @xmath431 , and observe that @xmath586 ) ( { \\widetilde}{x}_{it}^{b } \\epsilon_{it } - { \\mathbb{e } } [ { \\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad + \\frac{1}{n^{2 } } \\sum_{i=1}^{n } ( w_{ni}-1){\\mathbb{e}}[{\\widetilde}{x}_{i1}^{a } \\epsilon_{i1 } \\mid c_{i } ] \\left \\ { \\frac{1}{t } \\sum_{t=1}^{t } ( { \\widetilde}{x}_{it}^{b } \\epsilon_{it } -{\\mathbb{e}}[{\\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad + \\frac{1}{n^{2 } } \\sum_{i=1}^{n } ( w_{ni}-1){\\mathbb{e}}[{\\widetilde}{x}_{i1}^{b } \\epsilon_{i1 } \\mid c_{i } ] \\left \\ {   \\frac{1}{t } \\sum_{t=1}^{t } ( { \\widetilde}{x}_{it}^{a } \\epsilon_{it}-{\\mathbb{e}}[{\\widetilde}{x}_{i1}^{a } \\epsilon_{i1 } \\mid c_{i } ] ) \\right \\ } \\\\ & \\quad -   \\frac{1}{n^{2 } } \\sum_{i=1}^{n } ( w_{ni}-1){\\mathbb{e}}[{\\widetilde}{x}_{i1}^{a}\\epsilon_{i1 } \\mid c_{i } ] { \\mathbb{e}}[{\\widetilde}{x}_{i1}^{b}\\epsilon_{i1 } \\mid c_{i } ] \\\\ & = : ( i ) + ( ii ) + ( iii ) - ( iv ) . \\end{aligned}\\ ] ] by the proof of proposition [ prop2 ] , we can deduce that @xmath587 = { \\mathbb{e } } [ { \\mathbb{e}}_{w } [ ( i)^2 ] ] = o(n^{-3}t^{-2})$ ] , and when @xmath171 \\neq \\bm{0}$ ] with positive probability , @xmath588 = o(n^{-3}t^{-1 } ) , { \\mathbb{e } } [ ( iii)^{2 } ] = o(n^{-3}t^{-1})$ ] and @xmath589 = o(n^{-3})$ ] .",
    "therefore , we obtain the desired assertion .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.1829 & -0.0482 & -0.0898 & -0.0023 & 0.0005 & 0.6610 & 0.7580 & 0.7870 & 0.7420 & 0.9145 & 0.8995 + & & ( 0.0366 ) & ( 0.0397 ) & ( 0.0717 ) & ( 0.0605 ) & & & & & & & + & & [ 1.0337 ] & [ 1.2365 ] & [ 1.0423 ] & [ 1.5825 ] & & & & & & & + & 16 & -0.1351 & -0.0311 & -0.0756 & 0.0073 & 0.0025 & 0.7550 & 0.6910 & 0.7845 & 0.7430 & 0.9255 & 0.8970 + & & ( 0.0299 ) & ( 0.0318 ) & ( 0.0497 ) & ( 0.0470 ) & & & & & & & + & & [ 1.0455 ] & [ 1.2048 ] & [ 1.0134 ] & [ 1.5672 ] & & & & & & & + & 20 & -0.1064 & -0.0218 & -0.0649 & 0.0087 & 0.0070 & 0.8115 & 0.6350 & 0.7910 & 0.7515 & 0.9305 & 0.8980 + & & ( 0.0257 ) & ( 0.0270 ) & ( 0.0390 ) & ( 0.0387 ) & & & & & & & + & & [ 1.0458 ] & [ 1.1849 ] & [ 1.0103 ] & [ 1.5475 ] & & & & & & & + & 24 & -0.0870 & -0.0156 & -0.0581 & 0.0091 & 0.0230 & 0.8485 & 0.5815 & 0.7840 & 0.7575 & 0.9210 & 0.8965 + & & ( 0.0226 ) & ( 0.0236 ) & ( 0.0330 ) & ( 0.0329 ) & & & & & & & + & & [ 1.0453 ] & [ 1.1663 ] & [ 1.0355 ] & [ 1.5169 ] & & & & & & & + 100 & 12 & -0.1814 & -0.0465 & -0.0471 & -0.0008 & 0.0000 & 0.4685 & 0.8500 & 0.7865 & 0.7490 & 0.9310 & 0.9250 + & & ( 0.0256 ) & ( 0.0278 ) & ( 0.0521 ) & ( 0.0423 ) & & & & & & & + & & [ 1.0095 ] & [ 1.2262 ] & [ 1.0330 ] & [ 1.5654 ] & & & & & & & + & 16 & -0.1342 & -0.0301 & -0.0417 & 0.0069 & 0.0000 & 0.6340 & 0.8255 & 0.7575 & 0.7385 & 0.9375 & 0.9105 + & & ( 0.0214 ) & ( 0.0228 ) & ( 0.0357 ) & ( 0.0343 ) & & & & & & & + & & [ 1.0412 ] & [ 1.2222 ] & [ 0.9890 ] & [ 1.6165 ] & & & & & & & + & 20 & -0.1046 & -0.0199 & -0.0361 & 0.0098 & 0.0000 & 0.7430 & 0.7730 & 0.7640 & 0.7440 & 0.9265 & 0.9075 + & & ( 0.0180 ) & ( 0.0189 ) & ( 0.0289 ) & ( 0.0277 ) & & & & & & & + & & [ 1.0192 ] & [ 1.1760 ] & [ 1.0191 ] & [ 1.5633 ] & & & & & & & + & 24 & -0.0863 & -0.0148 & -0.0335 & 0.0094 & 0.0000 & 0.7870 & 0.7240 & 0.7705 & 0.7525 & 0.9190 & 0.9050 + & & ( 0.0157 ) & ( 0.0163 ) & ( 0.0233 ) & ( 0.0232 ) & & & & & & & + & & [ 1.0145 ] & [ 1.1422 ] & [ 0.9861 ] & [ 1.5131 ] & & & & & & & + 200 & 12 & -0.1815 & -0.0466 & -0.0258 & -0.0007 & 0.0000 & 0.2195 & 0.9000 & 0.7875 & 0.7515 & 0.9340 & 0.9330 + & & ( 0.0185 ) & ( 0.0201 ) & ( 0.0359 ) & ( 0.0303 ) & & & & & & & + & & [ 1.0203 ] & [ 1.2507 ] & [ 0.9874 ] & [ 1.5811 ] & & & & & & & + & 16 & -0.1329 & -0.0287 & -0.0219 & 0.0075 & 0.0000 & 0.4295 & 0.8880 & 0.7775 & 0.7555 & 0.9295 & 0.9130 + & & ( 0.0143 ) & ( 0.0152 ) & ( 0.0254 ) & ( 0.0232 ) & & & & & & & + & & [ 0.9776 ] & [ 1.1576 ] & [ 0.9765 ] & [ 1.5514 ] & & & & & & & + & 20 & -0.1045 & -0.0198 & -0.0189 & 0.0095 & 0.0000 & 0.5930 & 0.8510 & 0.7440 & 0.7300 & 0.9085 & 0.8995 + & & ( 0.0128 ) & ( 0.0134 ) & ( 0.0209 ) & ( 0.0194 ) & & & & & & & + & & [ 1.0191 ] & [ 1.1802 ] & [ 1.0226 ] & [ 1.5466 ] & & & & & & & + & 24 & -0.0858 & -0.0144 & -0.0177 & 0.0088 & 0.0000 & 0.6890 & 0.8250 & 0.7560 & 0.7445 & 0.9150 & 0.9025 + & & ( 0.0108 ) & ( 0.0113 ) & ( 0.0174 ) & ( 0.0160 ) & & & & & & & + & & [ 0.9808 ] & [ 1.1181 ] & [ 1.0198 ] & [ 1.4731 ] & & & & & & & +    notes : monte carlo experiments based on 2,000 repetitions .",
    "the standard deviations are inside parenthesis . inside brackets",
    "are the ratio of the averages of the standard errors to the simulation of the standard deviations .",
    "the dgp is @xmath590 with true parameter @xmath312 .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.3534 & -0.2437 & -0.5201 & -0.0943 & 0.0000 & 0.0025 & 0.0000 & 0.6000 & 0.5615 & 0.7230 & 0.7960 + & & ( 0.0587 ) & ( 0.0636 ) & ( 0.1213 ) & ( 0.0862 ) & & & & & & & + & & [ 1.0592 ] & [ 1.6464 ] & [ 1.4145 ] & [ 1.4177 ] & & & & & & & + & 16 & -0.2719 & -0.1845 & -0.4207 & -0.0500 & 0.0005 & 0.0070 & 0.0000 & 0.7440 & 0.7180 & 0.8525 & 0.8770 + & & ( 0.0492 ) & ( 0.0523 ) & ( 0.0977 ) & ( 0.0704 ) & & & & & & & + & & [ 1.0309 ] & [ 1.6146 ] & [ 1.4062 ] & [ 1.3855 ] & & & & & & & + & 20 & -0.2205 & -0.1480 & -0.3500 & -0.0285 & 0.0000 & 0.0150 & 0.0000 & 0.7810 & 0.7660 & 0.8800 & 0.8910 + & & ( 0.0444 ) & ( 0.0467 ) & ( 0.0811 ) & ( 0.0633 ) & & & & & & & + & & [ 1.0570 ] & [ 1.6543 ] & [ 1.4037 ] & [ 1.4390 ] & & & & & & & + & 24 & -0.1852 & -0.1234 & -0.2984 & -0.0162 & 0.0005 & 0.0235 & 0.0000 & 0.8245 & 0.8145 & 0.9175 & 0.9175 + & & ( 0.0377 ) & ( 0.0393 ) & ( 0.0663 ) & ( 0.0536 ) & & & & & & & + & & [ 0.9921 ] & [ 1.5584 ] & [ 1.3460 ] & [ 1.3665 ] & & & & & & & + 100 & 12 & -0.3531 & -0.2433 & -0.5241 & -0.0951 & 0.0000 & 0.0000 & 0.0000 & 0.4230 & 0.3945 & 0.5985 & 0.6535 + & & ( 0.0408 ) & ( 0.0442 ) & ( 0.0922 ) & ( 0.0598 ) & & & & & & & + & & [ 1.0240 ] & [ 1.6167 ] & [ 1.4195 ] & [ 1.3820 ] & & & & & & & + & 16 & -0.2716 & -0.1842 & -0.4260 & -0.0500 & 0.0000 & 0.0000 & 0.0000 & 0.6545 & 0.6350 & 0.7920 & 0.8200 + & & ( 0.0343 ) & ( 0.0364 ) & ( 0.0743 ) & ( 0.0497 ) & & & & & & & + & & [ 0.9987 ] & [ 1.5902 ] & [ 1.4024 ] & [ 1.3721 ] & & & & & & & + & 20 & -0.2191 & -0.1466 & -0.3556 & -0.0278 & 0.0000 & 0.0000 & 0.0000 & 0.7340 & 0.7220 & 0.8645 & 0.8770 + & & ( 0.0316 ) & ( 0.0332 ) & ( 0.0647 ) & ( 0.0457 ) & & & & & & & + & & [ 1.0415 ] & [ 1.6647 ] & [ 1.4574 ] & [ 1.4550 ] & & & & & & & + & 24 & -0.1839 & -0.1220 & -0.3067 & -0.0152 & 0.0000 & 0.0010 & 0.0000 & 0.7995 & 0.7970 & 0.9060 & 0.9125 + & & ( 0.0280 ) & ( 0.0292 ) & ( 0.0554 ) & ( 0.0391 ) & & & & & & & + & & [ 1.0268 ] & [ 1.6383 ] & [ 1.4494 ] & [ 1.4042 ] & & & & & & & + 200 & 12 & -0.3518 & -0.2420 & -0.5212 & -0.0929 & 0.0000 & 0.0000 & 0.0000 & 0.2200 & 0.1990 & 0.3795 & 0.4220 + & & ( 0.0282 ) & ( 0.0305 ) & ( 0.0652 ) & ( 0.0414 ) & & & & & & & + & & [ 0.9874 ] & [ 1.5791 ] & [ 1.3727 ] & [ 1.3457 ] & & & & & & & + & 16 & -0.2714 & -0.1840 & -0.4277 & -0.0494 & 0.0000 & 0.0000 & 0.0000 & 0.5080 & 0.4880 & 0.6705 & 0.7050 + & & ( 0.0246 ) & ( 0.0262 ) & ( 0.0560 ) & ( 0.0361 ) & & & & & & & + & & [ 1.0091 ] & [ 1.6156 ] & [ 1.4378 ] & [ 1.4059 ] & & & & & & & + & 20 & -0.2187 & -0.1461 & -0.3603 & -0.0268 & 0.0000 & 0.0000 & 0.0000 & 0.6890 & 0.6790 & 0.8340 & 0.8515 + & & ( 0.0219 ) & ( 0.0230 ) & ( 0.0481 ) & ( 0.0308 ) & & & & & & & + & & [ 1.0143 ] & [ 1.6281 ] & [ 1.4588 ] & [ 1.3852 ] & & & & & & & + & 24 & -0.1837 & -0.1218 & -0.3116 & -0.0152 & 0.0000 & 0.0000 & 0.0000 & 0.7710 & 0.7670 & 0.8935 & 0.9020 + & & ( 0.0198 ) & ( 0.0207 ) & ( 0.0406 ) & ( 0.0278 ) & & & & & & & + & & [ 1.0164 ] & [ 1.6395 ] & [ 1.4264 ] & [ 1.4035 ] & & & & & & & +    notes : monte carlo experiments based on 2,000 repetitions .",
    "the standard deviations are inside parenthesis . inside brackets",
    "are the ratio of the averages of standard errors to simulation of the standard deviations .",
    "the dgp is @xmath591 with true parameter @xmath318 .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.0201 & 0.0374 & 0.0364 & 0.0065 & 0.8555 & 0.9180 & 0.9775 & 0.9170 & 0.9040 & 0.9245 & 0.9350 + & & ( 0.0268 ) & ( 0.0290 ) & ( 0.0307 ) & ( 0.0290 ) & & & & & & & + & & [ 1.0289 ] & [ 0.7480 ] & [ 0.6187 ] & [ 1.0853 ] & & & & & & & + & 16 & -0.0151 & 0.0283 & 0.0255 & 0.0038 & 0.8830 & 0.9435 & 0.9900 & 0.9230 & 0.9170 & 0.9300 & 0.9435 + & & ( 0.0226 ) & ( 0.0240 ) & ( 0.0250 ) & ( 0.0240 ) & & & & & & & + & & [ 1.0096 ] & [ 0.7137 ] & [ 0.5954 ] & [ 1.0522 ] & & & & & & & + & 20 & -0.0107 & 0.0242 & 0.0199 & 0.0045 & 0.9040 & 0.9515 & 0.9900 & 0.9225 & 0.9105 & 0.9290 & 0.9350 + & & ( 0.0209 ) & ( 0.0219 ) & ( 0.0227 ) & ( 0.0217 ) & & & & & & & + & & [ 1.0543 ] & [ 0.7275 ] & [ 0.6117 ] & [ 1.0772 ] & & & & & & & + & 24 & -0.0081 & 0.0212 & 0.0159 & 0.0046 & 0.9100 & 0.9650 & 0.9950 & 0.9390 & 0.9320 & 0.9415 & 0.9530 + & & ( 0.0182 ) & ( 0.0190 ) & ( 0.0197 ) & ( 0.0187 ) & & & & & & & + & & [ 1.0066 ] & [ 0.6881 ] & [ 0.5893 ] & [ 1.0189 ] & & & & & & & + 100 & 12 & -0.0206 & 0.0369 & 0.0421 & 0.0057 & 0.7925 & 0.8005 & 0.8960 & 0.9145 & 0.9005 & 0.9230 & 0.9330 + & & ( 0.0192 ) & ( 0.0208 ) & ( 0.0221 ) & ( 0.0206 ) & & & & & & & + & & [ 1.0344 ] & [ 0.7598 ] & [ 0.6246 ] & [ 1.0830 ] & & & & & & & + & 16 & -0.0147 & 0.0288 & 0.0328 & 0.0043 & 0.8350 & 0.8530 & 0.9310 & 0.9295 & 0.9165 & 0.9335 & 0.9355 + & & ( 0.0162 ) & ( 0.0172 ) & ( 0.0181 ) & ( 0.0170 ) & & & & & & & + & & [ 1.0184 ] & [ 0.7236 ] & [ 0.6017 ] & [ 1.0508 ] & & & & & & & + & 20 & -0.0110 & 0.0239 & 0.0269 & 0.0042 & 0.8675 & 0.8875 & 0.9475 & 0.9315 & 0.9255 & 0.9325 & 0.9340 + & & ( 0.0144 ) & ( 0.0152 ) & ( 0.0158 ) & ( 0.0149 ) & & & & & & & + & & [ 1.0156 ] & [ 0.7113 ] & [ 0.5954 ] & [ 1.0344 ] & & & & & & & + & 24 & -0.0086 & 0.0206 & 0.0227 & 0.0040 & 0.8915 & 0.9065 & 0.9675 & 0.9320 & 0.9280 & 0.9340 & 0.9385 + & & ( 0.0129 ) & ( 0.0134 ) & ( 0.0139 ) & ( 0.0134 ) & & & & & & & + & & [ 0.9987 ] & [ 0.6898 ] & [ 0.5782 ] & [ 1.0225 ] & & & & & & & + 200 & 12 & -0.0210 & 0.0364 & 0.0446 & 0.0053 & 0.6475 & 0.5475 & 0.6295 & 0.9185 & 0.9105 & 0.9325 & 0.9315 + & & ( 0.0133 ) & ( 0.0144 ) & ( 0.0153 ) & ( 0.0141 ) & & & & & & & + & & [ 1.0078 ] & [ 0.7440 ] & [ 0.6046 ] & [ 1.0382 ] & & & & & & & + & 16 & -0.0144 & 0.0291 & 0.0365 & 0.0046 & 0.7530 & 0.6240 & 0.6705 & 0.9160 & 0.9065 & 0.9215 & 0.9205 + & & ( 0.0113 ) & ( 0.0120 ) & ( 0.0127 ) & ( 0.0119 ) & & & & & & & + & & [ 1.0002 ] & [ 0.7146 ] & [ 0.5927 ] & [ 1.0359 ] & & & & & & & + & 20 & -0.0106 & 0.0243 & 0.0308 & 0.0046 & 0.8190 & 0.6935 & 0.7225 & 0.9205 & 0.9090 & 0.9205 & 0.9230 + & & ( 0.0101 ) & ( 0.0106 ) & ( 0.0109 ) & ( 0.0105 ) & & & & & & & + & & [ 1.0011 ] & [ 0.7024 ] & [ 0.5797 ] & [ 1.0266 ] & & & & & & & + & 24 & -0.0084 & 0.0208 & 0.0267 & 0.0043 & 0.8475 & 0.7465 & 0.7570 & 0.9140 & 0.9090 & 0.9120 & 0.9195 + & & ( 0.0093 ) & ( 0.0097 ) & ( 0.0100 ) & ( 0.0096 ) & & & & & & & + & & [ 1.0103 ] & [ 0.7022 ] & [ 0.5852 ] & [ 1.0275 ] & & & & & & & +    notes : monte carlo experiments based on 2,000 repetitions .",
    "the standard deviations are inside parenthesis . inside brackets",
    "are the ratio of the averages of the standard errors to the simulation of the standard deviations .",
    "the dgp is @xmath591 with true parameter @xmath319 .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.3161 & -0.1476 & -0.3222 & -0.0649 & 0.0000 & 0.0765 & 0.1395 & 0.6760 & 0.6480 & 0.8020 & 0.9470 + & & ( 0.0518 ) & ( 0.0557 ) & ( 0.1365 ) & ( 0.0767 ) & & & & & & & + & & [ 1.4428 ] & [ 1.5008 ] & [ 1.3745 ] & [ 1.4312 ] & & & & & & & + & 16 & -0.2415 & -0.1005 & -0.2524 & -0.0329 & 0.0000 & 0.1600 & 0.0910 & 0.7705 & 0.7580 & 0.8775 & 0.9650 + & & ( 0.0422 ) & ( 0.0437 ) & ( 0.0961 ) & ( 0.0617 ) & & & & & & & + & & [ 1.4489 ] & [ 1.4195 ] & [ 1.3400 ] & [ 1.4107 ] & & & & & & & + & 20 & -0.1931 & -0.0703 & -0.2074 & -0.0154 & 0.0000 & 0.3180 & 0.0610 & 0.8210 & 0.8025 & 0.9100 & 0.9695 + & & ( 0.0366 ) & ( 0.0373 ) & ( 0.0748 ) & ( 0.0532 ) & & & & & & & + & & [ 1.4951 ] & [ 1.3995 ] & [ 1.3368 ] & [ 1.4228 ] & & & & & & & + & 24 & -0.1632 & -0.0531 & -0.1791 & -0.0112 & 0.0000 & 0.4380 & 0.0395 & 0.8015 & 0.7965 & 0.9030 & 0.9690 + & & ( 0.0336 ) & ( 0.0341 ) & ( 0.0601 ) & ( 0.0480 ) & & & & & & & + & & [ 1.5805 ] & [ 1.4346 ] & [ 1.3171 ] & [ 1.4633 ] & & & & & & & + 100 & 12 & -0.3138 & -0.1455 & -0.2227 & -0.0620 & 0.0000 & 0.0040 & 0.2885 & 0.5865 & 0.5690 & 0.7205 & 0.9215 + & & ( 0.0366 ) & ( 0.0392 ) & ( 0.1084 ) & ( 0.0548 ) & & & & & & & + & & [ 1.4146 ] & [ 1.4938 ] & [ 1.2980 ] & [ 1.4406 ] & & & & & & & + & 16 & -0.2394 & -0.0984 & -0.1682 & -0.0309 & 0.0000 & 0.0295 & 0.2305 & 0.7245 & 0.7175 & 0.8530 & 0.9600 + & & ( 0.0302 ) & ( 0.0313 ) & ( 0.0776 ) & ( 0.0449 ) & & & & & & & + & & [ 1.4477 ] & [ 1.4367 ] & [ 1.3110 ] & [ 1.4475 ] & & & & & & & + & 20 & -0.1932 & -0.0703 & -0.1388 & -0.0172 & 0.0000 & 0.0970 & 0.1855 & 0.7945 & 0.7835 & 0.9020 & 0.9690 + & & ( 0.0264 ) & ( 0.0269 ) & ( 0.0585 ) & ( 0.0382 ) & & & & & & & + & & [ 1.5053 ] & [ 1.4262 ] & [ 1.2883 ] & [ 1.4448 ] & & & & & & & + & 24 & -0.1607 & -0.0505 & -0.1175 & -0.0078 & 0.0000 & 0.2265 & 0.1635 & 0.8030 & 0.7950 & 0.9215 & 0.9775 + & & ( 0.0236 ) & ( 0.0237 ) & ( 0.0478 ) & ( 0.0340 ) & & & & & & & + & & [ 1.5410 ] & [ 1.4149 ] & [ 1.2828 ] & [ 1.4585 ] & & & & & & & + 200 & 12 & -0.3128 & -0.1447 & -0.1126 & -0.0604 & 0.0000 & 0.0000 & 0.6185 & 0.4285 & 0.4050 & 0.6100 & 0.8805 + & & ( 0.0253 ) & ( 0.0268 ) & ( 0.0828 ) & ( 0.0381 ) & & & & & & & + & & [ 1.3624 ] & [ 1.4475 ] & [ 1.1826 ] & [ 1.4054 ] & & & & & & & + & 16 & -0.2387 & -0.0979 & -0.0749 & -0.0299 & 0.0000 & 0.0000 & 0.6560 & 0.6550 & 0.6505 & 0.8255 & 0.9515 + & & ( 0.0214 ) & ( 0.0220 ) & ( 0.0570 ) & ( 0.0308 ) & & & & & & & + & & [ 1.4342 ] & [ 1.4296 ] & [ 1.1797 ] & [ 1.4002 ] & & & & & & & + & 20 & -0.1923 & -0.0693 & -0.0577 & -0.0159 & 0.0000 & 0.0095 & 0.6360 & 0.7580 & 0.7485 & 0.8855 & 0.9675 + & & ( 0.0188 ) & ( 0.0193 ) & ( 0.0444 ) & ( 0.0271 ) & & & & & & & + & & [ 1.5034 ] & [ 1.4465 ] & [ 1.2020 ] & [ 1.4456 ] & & & & & & & + & 24 & -0.1607 & -0.0505 & -0.0444 & -0.0087 & 0.0000 & 0.0475 & 0.6585 & 0.7950 & 0.7915 & 0.9175 & 0.9765 + & & ( 0.0167 ) & ( 0.0169 ) & ( 0.0362 ) & ( 0.0236 ) & & & & & & & + & & [ 1.5366 ] & [ 1.4254 ] & [ 1.2127 ] & [ 1.4285 ] & & & & & & & +    notes : monte carlo based on 2,000 repetitions .",
    "standard deviations are inside parenthesis .",
    "inside brackets are ratios of averages of the standard errors to simulation of the standard deviations .",
    "dgp is @xmath592 with true parameter @xmath318 and @xmath330 .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.2076 & -0.0949 & -0.1267 & -0.0411 & 0.0750 & 0.3740 & 0.4210 & 0.7225 & 0.7250 & 0.8375 & 0.8570 + & & ( 0.0609 ) & ( 0.0660 ) & ( 0.0795 ) & ( 0.0844 ) & & & & & & & + & & [ 1.0806 ] & [ 1.7323 ] & [ 1.3986 ] & [ 1.5547 ] & & & & & & & + & 16 & -0.1591 & -0.0715 & -0.1087 & -0.0241 & 0.1720 & 0.4460 & 0.3815 & 0.7935 & 0.8090 & 0.8780 & 0.8990 + & & ( 0.0541 ) & ( 0.0574 ) & ( 0.0654 ) & ( 0.0733 ) & & & & & & & + & & [ 1.0101 ] & [ 1.7774 ] & [ 1.4647 ] & [ 1.4632 ] & & & & & & & + & 20 & -0.1290 & -0.0575 & -0.0956 & -0.0158 & 0.3155 & 0.4660 & 0.3550 & 0.7945 & 0.8205 & 0.8885 & 0.9090 + & & ( 0.0541 ) & ( 0.0568 ) & ( 0.0622 ) & ( 0.0712 ) & & & & & & & + & & [ 1.0530 ] & [ 1.9933 ] & [ 1.6559 ] & [ 1.4994 ] & & & & & & & + & 24 & -0.1099 & -0.0494 & -0.0888 & -0.0125 & 0.4295 & 0.4930 & 0.3420 & 0.8235 & 0.8365 & 0.8975 & 0.9180 + & & ( 0.0530 ) & ( 0.0552 ) & ( 0.0580 ) & ( 0.0660 ) & & & & & & & + & & [ 1.0572 ] & [ 2.1466 ] & [ 1.7639 ] & [ 1.4307 ] & & & & & & & + 100 & 12 & -0.2060 & -0.0932 & -0.1075 & -0.0379 & 0.0015 & 0.1715 & 0.3070 & 0.7095 & 0.7280 & 0.8430 & 0.8615 + & & ( 0.0421 ) & ( 0.0456 ) & ( 0.0565 ) & ( 0.0590 ) & & & & & & & + & & [ 1.0136 ] & [ 1.6894 ] & [ 1.3783 ] & [ 1.4919 ] & & & & & & & + & 16 & -0.1583 & -0.0707 & -0.0917 & -0.0233 & 0.0320 & 0.2700 & 0.2690 & 0.7730 & 0.8055 & 0.8805 & 0.8985 + & & ( 0.0395 ) & ( 0.0420 ) & ( 0.0493 ) & ( 0.0527 ) & & & & & & & + & & [ 1.0111 ] & [ 1.8367 ] & [ 1.5291 ] & [ 1.4531 ] & & & & & & & + & 20 & -0.1276 & -0.0559 & -0.0789 & -0.0135 & 0.0950 & 0.3310 & 0.2770 & 0.8085 & 0.8370 & 0.9005 & 0.9135 + & & ( 0.0380 ) & ( 0.0399 ) & ( 0.0447 ) & ( 0.0494 ) & & & & & & & + & & [ 1.0051 ] & [ 1.9788 ] & [ 1.6517 ] & [ 1.4253 ] & & & & & & & + & 24 & -0.1079 & -0.0474 & -0.0724 & -0.0093 & 0.1680 & 0.3700 & 0.2615 & 0.8340 & 0.8635 & 0.9195 & 0.9290 + & & ( 0.0366 ) & ( 0.0382 ) & ( 0.0407 ) & ( 0.0470 ) & & & & & & & + & & [ 1.0008 ] & [ 2.0981 ] & [ 1.7193 ] & [ 1.4012 ] & & & & & & & + 200 & 12 & -0.2051 & -0.0922 & -0.0955 & -0.0374 & 0.0000 & 0.0365 & 0.1610 & 0.6450 & 0.6750 & 0.8145 & 0.8370 + & & ( 0.0291 ) & ( 0.0315 ) & ( 0.0394 ) & ( 0.0411 ) & & & & & & & + & & [ 0.9832 ] & [ 1.6532 ] & [ 1.3494 ] & [ 1.4615 ] & & & & & & & + & 16 & -0.1575 & -0.0699 & -0.0817 & -0.0217 & 0.0005 & 0.0995 & 0.1415 & 0.7370 & 0.7710 & 0.8685 & 0.8815 + & & ( 0.0287 ) & ( 0.0305 ) & ( 0.0355 ) & ( 0.0391 ) & & & & & & & + & & [ 1.0241 ] & [ 1.8885 ] & [ 1.5463 ] & [ 1.5043 ] & & & & & & & + & 20 & -0.1258 & -0.0541 & -0.0693 & -0.0114 & 0.0085 & 0.1780 & 0.1640 & 0.7760 & 0.8080 & 0.8935 & 0.9050 + & & ( 0.0283 ) & ( 0.0297 ) & ( 0.0332 ) & ( 0.0371 ) & & & & & & & + & & [ 1.0488 ] & [ 2.0891 ] & [ 1.7197 ] & [ 1.5009 ] & & & & & & & + & 24 & -0.1071 & -0.0465 & -0.0630 & -0.0089 & 0.0160 & 0.2255 & 0.1655 & 0.8175 & 0.8455 & 0.9155 & 0.9310 + & & ( 0.0265 ) & ( 0.0276 ) & ( 0.0303 ) & ( 0.0336 ) & & & & & & & + & & [ 1.0112 ] & [ 2.1444 ] & [ 1.7938 ] & [ 1.4004 ] & & & & & & & +    notes : monte carlo experiments based on 2,000 repetitions .",
    "the standard deviations are inside parenthesis . inside brackets",
    "are the ratio of the averages of the standard errors to the simulation of the standard deviations .",
    "the dgp is @xmath593 .",
    "+ @xmath0 & @xmath1 & fe & hk & gmm & hpj & fe - ccm & hk & gmm & hpj - ccm & hpj - feb & hpj - hpjb & hpj - hpjpb + & & & + 50 & 12 & -0.1750 & -0.0538 & -0.1056 & -0.0063 & 0.0540 & 0.6400 & 0.6525 & 0.7695 & 0.7835 & 0.9005 & 0.8955 + & & ( 0.0489 ) & ( 0.0530 ) & ( 0.0765 ) & ( 0.0710 ) & & & & & & & + & & [ 1.0552 ] & [ 1.4596 ] & [ 1.1175 ] & [ 1.6163 ] & & & & & & & + & 16 & -0.1299 & -0.0361 & -0.0888 & 0.0002 & 0.1415 & 0.6750 & 0.5820 & 0.7875 & 0.8020 & 0.9120 & 0.9100 + & & ( 0.0424 ) & ( 0.0451 ) & ( 0.0594 ) & ( 0.0588 ) & & & & & & & + & & [ 1.0391 ] & [ 1.4749 ] & [ 1.1636 ] & [ 1.5574 ] & & & & & & & + & 20 & -0.1050 & -0.0288 & -0.0789 & 0.0016 & 0.2165 & 0.7045 & 0.5190 & 0.8040 & 0.8230 & 0.9200 & 0.9270 + & & ( 0.0384 ) & ( 0.0404 ) & ( 0.0496 ) & ( 0.0513 ) & & & & & & & + & & [ 1.0296 ] & [ 1.5015 ] & [ 1.2033 ] & [ 1.5004 ] & & & & & & & + & 24 & -0.0857 & -0.0213 & -0.0707 & 0.0031 & 0.3425 & 0.7200 & 0.4760 & 0.7940 & 0.8205 & 0.9160 & 0.9190 + & & ( 0.0372 ) & ( 0.0388 ) & ( 0.0444 ) & ( 0.0480 ) & & & & & & & + & & [ 1.0691 ] & [ 1.6044 ] & [ 1.2667 ] & [ 1.5075 ] & & & & & & & + 100 & 12 & -0.1721 & -0.0506 & -0.0746 & -0.0039 & 0.0015 & 0.5060 & 0.6745 & 0.7635 & 0.7785 & 0.9165 & 0.9205 + & & ( 0.0344 ) & ( 0.0373 ) & ( 0.0563 ) & ( 0.0510 ) & & & & & & & + & & [ 1.0268 ] & [ 1.4532 ] & [ 1.1218 ] & [ 1.6227 ] & & & & & & & + & 16 & -0.1297 & -0.0359 & -0.0654 & 0.0002 & 0.0095 & 0.5795 & 0.5835 & 0.7915 & 0.8205 & 0.9265 & 0.9240 + & & ( 0.0302 ) & ( 0.0321 ) & ( 0.0446 ) & ( 0.0420 ) & & & & & & & + & & [ 1.0174 ] & [ 1.4837 ] & [ 1.1899 ] & [ 1.5444 ] & & & & & & & + & 20 & -0.1022 & -0.0258 & -0.0572 & 0.0042 & 0.0390 & 0.6515 & 0.5285 & 0.7970 & 0.8275 & 0.9350 & 0.9330 + & & ( 0.0270 ) & ( 0.0283 ) & ( 0.0368 ) & ( 0.0367 ) & & & & & & & + & & [ 0.9925 ] & [ 1.4936 ] & [ 1.2130 ] & [ 1.4868 ] & & & & & & & + & 24 & -0.0846 & -0.0202 & -0.0506 & 0.0039 & 0.1075 & 0.6570 & 0.5060 & 0.8100 & 0.8370 & 0.9265 & 0.9320 + & & ( 0.0261 ) & ( 0.0272 ) & ( 0.0333 ) & ( 0.0337 ) & & & & & & & + & & [ 1.0329 ] & [ 1.5900 ] & [ 1.2918 ] & [ 1.4699 ] & & & & & & & + 200 & 12 & -0.1721 & -0.0506 & -0.0591 & -0.0052 & 0.0000 & 0.2680 & 0.6205 & 0.7835 & 0.8065 & 0.9270 & 0.9300 + & & ( 0.0241 ) & ( 0.0261 ) & ( 0.0418 ) & ( 0.0352 ) & & & & & & & + & & [ 1.0084 ] & [ 1.4413 ] & [ 1.1601 ] & [ 1.5806 ] & & & & & & & + & 16 & -0.1276 & -0.0337 & -0.0487 & 0.0024 & 0.0000 & 0.4325 & 0.5700 & 0.8000 & 0.8345 & 0.9390 & 0.9395 + & & ( 0.0209 ) & ( 0.0222 ) & ( 0.0307 ) & ( 0.0297 ) & & & & & & & + & & [ 0.9847 ] & [ 1.4549 ] & [ 1.1398 ] & [ 1.5331 ] & & & & & & & + & 20 & -0.1011 & -0.0247 & -0.0436 & 0.0043 & 0.0005 & 0.5260 & 0.4985 & 0.8175 & 0.8500 & 0.9405 & 0.9405 + & & ( 0.0195 ) & ( 0.0205 ) & ( 0.0270 ) & ( 0.0260 ) & & & & & & & + & & [ 1.0041 ] & [ 1.5272 ] & [ 1.2305 ] & [ 1.4792 ] & & & & & & & + & 24 & -0.0843 & -0.0199 & -0.0402 & 0.0042 & 0.0050 & 0.5590 & 0.4365 & 0.8135 & 0.8445 & 0.9390 & 0.9435 + & & ( 0.0186 ) & ( 0.0194 ) & ( 0.0241 ) & ( 0.0238 ) & & & & & & & + & & [ 1.0302 ] & [ 1.6044 ] & [ 1.2930 ] & [ 1.4541 ] & & & & & & & +    notes : monte carlo based on 2,000 repetitions .",
    "the standard deviations are inside parenthesis .",
    "inside brackets are ratios of averages of the standard errors to simulation of the standard deviations .",
    "the dgp is @xmath594 , with true parameter @xmath383 and @xmath384 .",
    "+ [ t.app ] +   + & fe - ccm & hpj - ccm & hpj - hpjpb & gmm & tsls + @xmath595 & @xmath596&@xmath597&@xmath597&@xmath598&@xmath599 + @xmath325 ci & @xmath600    $ ] & @xmath601    $ ] & @xmath602    $ ] & @xmath603    $ ] & @xmath604    $ ] + @xmath605 ci & @xmath606    $ ] & @xmath607    $ ] & @xmath608    $ ] & @xmath609    $ ] & @xmath610    $ ] + @xmath611 & @xmath612&@xmath613&@xmath613&@xmath614&@xmath615 + @xmath325 ci & @xmath616 $ ] & @xmath617 $ ] & @xmath618 $ ] & @xmath619 $ ] & @xmath620   $ ] + @xmath605 ci & @xmath621 $ ] & @xmath622 $ ] & @xmath623 $ ] & @xmath624 $ ] & @xmath625   $ ] +   + & fe - ccm & hpj - ccm & hpj - hpjpb & gmm & tsls + @xmath595 & @xmath626&@xmath627&@xmath627&@xmath628&@xmath629 + @xmath325 ci & @xmath630    $ ] & @xmath631    $ ] & @xmath632    $ ] & @xmath633    $ ] & @xmath634    $ ] + @xmath605 ci & @xmath635    $ ] & @xmath636    $ ] & @xmath637    $ ] & @xmath638    $ ] & @xmath639    $ ] + @xmath611 & @xmath640&@xmath641&@xmath641&@xmath642&@xmath643 + @xmath325 ci & @xmath644 $ ] & @xmath645 $ ] & @xmath646 $ ] & @xmath647 $ ] & @xmath648   $ ] + @xmath605 ci & @xmath649 $ ] & @xmath650 $ ] & @xmath651 $ ] & @xmath652 $ ] & @xmath653   $ ] +   + & fe - ccm & hpj - ccm & hpj - hpjpb & gmm & tsls + @xmath595 & @xmath654&@xmath655&@xmath655&@xmath656&@xmath657 + @xmath325 ci & @xmath658    $ ] & @xmath659    $ ] & @xmath660    $ ] & @xmath661    $ ] & @xmath662    $ ] + @xmath605 ci & @xmath663    $ ] & @xmath664    $ ] & @xmath665    $ ] & @xmath666    $ ] & @xmath667    $ ] + @xmath611 & @xmath668&@xmath669&@xmath669&@xmath670&@xmath671 + @xmath325 ci & @xmath672 $ ] & @xmath673    $ ] & @xmath674 $ ] & @xmath675 $ ] & @xmath676   $ ] + @xmath605 ci & @xmath677 $ ] & @xmath678    $ ] & @xmath679 $ ] & @xmath680 $ ] & @xmath681   $ ] +"
  ],
  "abstract_text": [
    "<S> this paper considers fixed effects ( fe ) estimation for linear panel data models under possible model misspecification when both the number of individuals , @xmath0 , and the number of time periods , @xmath1 , are large . </S>",
    "<S> we first clarify the probability limit of the fe estimator and argue that this probability limit can be regarded as a pseudo - true parameter . </S>",
    "<S> we then establish the asymptotic distributional properties of the fe estimator around the pseudo - true parameter when @xmath0 and @xmath1 jointly go to infinity . </S>",
    "<S> notably , we show that the fe estimator suffers from the incidental parameters bias of which the top order is @xmath2 , and even after the incidental parameters bias is completely removed , the rate of convergence of the fe estimator depends on the degree of model misspecification and is either @xmath3 or @xmath4 . </S>",
    "<S> second , we establish asymptotically valid inference on the ( pseudo - true ) parameter . specifically , we derive the asymptotic properties of the clustered covariance matrix ( ccm ) estimator and the cross section bootstrap , and show that they are robust to model misspecification . </S>",
    "<S> this establishes a rigorous theoretical ground for the use of the ccm estimator and the cross section bootstrap when model misspecification and the incidental parameters bias ( in the coefficient estimate ) are present . </S>",
    "<S> we conduct monte carlo simulations to evaluate the finite sample performance of the estimators and inference methods , together with a simple application to the unemployment dynamics in the u.s . </S>"
  ]
}