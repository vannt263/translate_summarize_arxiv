{
  "article_text": [
    "there is a growing sense of excitement that in the near future prototype quantum computers might be able to outperform any classical computer .",
    "that is , they might demonstrate supremacy over classical devices  @xcite .",
    "this excitement has in part been driven by theoretical research into the complexity of intermediate quantum computing models , which over the last 15 years has seen the physical requirements for a quantum speedup lowered while increasing the level of rigour in the argument for the difficulty of classically simulating such systems .",
    "these advances are rooted in the discovery by terhal and divincenzo @xcite that sufficiently accurate classical simulations of even quite simple quantum computations could have significant implications for the interrelationships between computational complexity classes  @xcite . since then",
    "the theoretical challenge has been to demonstrate such a result holds for levels of precision commensurate with what is expected from realisable quantum computers .",
    "a first step in this direction established that classical computers can not efficiently mimic the output of ideal quantum circuits to within a reasonable multiplicative ( or relative ) error in the frequency with which output events occur without similarly disrupting the expected relationships between classical complexity classes  @xcite . in a major breakthrough aaronson and",
    "arkhipov laid out an argument for establishing that efficient classical simulation of linear optical systems was not possible , even if that simulation was only required to be accurate to within a reasonable total variation distance .",
    "their argument revealed a deep connection between the complexity of sampling from quantum computers and conjectures regarding the average - case complexity of a range of combinatorial problems .",
    "the linear optical system they proposed was the class of problems called @xmath0 which is the production of samples from fock basis measurements of linearly scattering individual bosons .",
    "using the current state of the art of classical computation an implementation of @xmath0 using 50 photons would be sufficient to demonstrate quantum supremacy .    since then many experimental teams have attempted to implement aaronson and arkhipov s @xmath0 problem  @xcite while theorists have extended their arguments to apply to a range of other quantum circuits , most notably commuting quantum gates on qubits , a class known as @xmath1  @xcite .",
    "these generalizations give hope that experimental demonstration of quantum supremacy on sufficiently high fidelity systems of just 50 qubits  @xcite .    in this review",
    "we will present the theoretical background behind @xmath0 and its generalizations , while also reviewing recent experimental demonstrations of @xmath0 . from a theoretical perspective we focus on the connections between the complexity of counting problems and the complexity of sampling from quantum circuits .",
    "this is of course not the only route to determining the complexity of quantum circuit sampling , and recent work by aaronson and chen explores several interesting alternative pathways @xcite .",
    "60mmccx class & type & definition +  & _ d _ & deterministic with polynomial runtime on a classical computer + & _ d _ & deterministic with polynomial runtime on a quantum computer + & _ d _ & random with classical statistics and an error probability less than @xmath2 + & _ d _ & random with quantum statistics and an error probability less than @xmath2 + & _ d _ & outputs can be verified using an algorithm from  + & _ d _ & random with classical statistics and an error probability less than @xmath3 + & _ c _ & counts the number of accept outputs for circuits from  + & _ z _ & difference between the number of accept and reject outputs for circuits from  + & _ d _ & polynomial memory requirements on a classical computer    the challenge in rigorously arguing for quantum supremacy is compounded by the difficulty of bounding the ultimate power of classical computers .",
    "many examples of significant quantum speedups over the best - known classical algorithms have been discovered , see @xcite for a useful review .",
    "the most celebrated of these results is shor s polynomial time quantum algorithm for factorisation  @xcite .",
    "this was a critically important discovery for the utility of quantum computing , but was not as satisfying in addressing the issue of quantum supremacy due to the unknown nature of the complexity of factoring .",
    "the best known classical factoring algorithm , the general number field sieve , is exponential time ( growing as @xmath4 where @xmath5 is the number of bits of the input number ) .",
    "however , in order to prove quantum supremacy , or really any separation between classical and quantum computational models , it must proven for _ all _ possible algorithms and not just those that are known .    the challenge of bounding the power of classical computation is starkly illustrated by the persistent difficulty of resolving the @xmath6 versus @xmath7 question , where the extremely powerful non - deterministic turing machine model can not be definitively proven to be more powerful than standard computing devices . the study of this question has led to an abundance of nested relationships between classes of computational models , or complexity classes .",
    "some commonly studied classes are shown in table  [ decision - table ] .",
    "many relationships between the classes can be proven , such as @xmath8 , @xmath9 and @xmath10 , however , strict containments are rare . questions about the nature of quantum supremacy are then about what relationships one can draw between the complexity classes when introducing quantum mechanical resources .",
    "a commonly used technique in complexity theory is to prove statements relative to an `` oracle '' .",
    "this is basically an assumption of access to a machine that solves a particular problem instantly .",
    "using this concept one can define a nested structure of oracles called the `` polynomial hierarchy''@xcite of complexity classes . at the bottom of",
    "the hierarchy are the classes @xmath6 and @xmath7 which are inside levels zero and one respectively . then there is the second level which contains the class @xmath11 which means problems solvable in @xmath7 with access to an oracle for problems in @xmath7 . if @xmath12 then this second level is at least as powerful the first level and possibly more powerful due to the ability to access the oracle .",
    "then the third level contains @xmath13 , and so on .",
    "higher levels are defined by continuing this nesting .",
    "each level of the hierarchy contains the levels below it .",
    "though not proven , it is widely believed that every level is strictly larger than the next .",
    "this belief is primarily due to the relationships of this construction to similar hierarchies such as the arithmetic hierarchy for which higher levels are always strictly larger .",
    "if it turns out that two levels are equal , then one can show that higher levels do not increase and this situation is called a polynomial hierarchy collapse .",
    "a polynomial hierarchy collapse to the first level would mean that @xmath14 .",
    "a collapse at a higher level is a similar statement but relative to an oracle .",
    "it is the belief that there is no collapse of the polynomial hierarchy at any level that is used in demonstrating the supremacy of quantum sampling algorithms .",
    "effectively one is forced into a choice between believing that the polynomial hierarchy of classical complexity classes collapses or that quantum algorithms are more powerful than classical ones .",
    "\\(a ) ( a ) an example probability distribution over 8 symbols . ( b ) 100 random samples from the probability distribution .",
    "the objective of a sampling problem is the compute samples like the sequences shown in ( b ) whose complexity may be different to the complexity of computing the underlying probability distribution ( a).,title=\"fig:\",width=302 ] + ( b ) ( a ) an example probability distribution over 8 symbols .",
    "( b ) 100 random samples from the probability distribution .",
    "the objective of a sampling problem is the compute samples like the sequences shown in ( b ) whose complexity may be different to the complexity of computing the underlying probability distribution ( a).,title=\"fig:\",width=302 ]    sampling problems are those problems which output random numbers according to a particular probability distribution ( see fig .  [ sampdemo ] ) . in the case of a classical algorithm",
    ", one can think of this class as being a machine which transforms uniform random bits into non - uniform random bits according to the required distribution .",
    "when describing classes of sampling problems the current convention is to prefix `` samp- '' to the class in which computation takes place .",
    "so @xmath15 is the class described above using an efficient classical algorithm and @xmath16 would be those sampling problems which are efficiently computable using a quantum mechanical algorithm with bounded error .",
    "all quantum computations on @xmath5 qubits can be expressed as the preparation of an @xmath5-qubit initial state @xmath17 , a unitary evolution corresponding to a uniformly generated quantum circuit @xmath18 followed by a measurement in the computational basis on this system . in this picture",
    "the computation outputs a length @xmath5 bitstring @xmath19 with probability @xmath20 in this way quantum computers produce probabilistic samples from a distribution determined by the circuit @xmath18 . within this model @xmath21 is those decision problems solved with a bounded error rate by measuring a single output qubit .",
    "@xmath16 is the class of problems that can be solved when we are allowed to measure all of the output qubits .",
    "it is known that quantum mechanics produces statistics which can not be recreated classically as in the case of quantum entanglement and bell inequalities .",
    "however , these scenarios need other physical criterion to be imposed , such as sub - luminal signaling , to rule out classical statistics .",
    "is there an equivalent `` improvement '' in sampling quantum probability distributions when using complexity classes as the deciding criterion ?",
    "that is , does @xmath16 strictly contain @xmath15 ?",
    "the answer appears to be yes and there is a ( almost ) provable separation between the classical and quantum complexity .",
    "key to these arguments is understanding the complexity of computing the output probability of a quantum circuit from eq .",
    "( [ qu - prob ] ) . in the 1990s",
    "it was shown that there are families quantum circuits for which computing @xmath22 is @xmath23-hard in the _ worst - case _ @xcite .",
    "the suffix `` -hard '' is used to indicate that the problem can , with a polynomial time overhead , be transformed into any problem within that class .",
    "@xmath23-hard includes all problems in @xmath7 .",
    "also , every problem inside the polynomial hierarchy can be solved inside the class of decision problems within @xmath23-hard , which is written @xmath24  @xcite .",
    "importantly this @xmath23-hardness does not necessarily emerge only from the most complicated quantum circuits , but rather can be established even for non - universal , or intermediate , families of quantum circuits such as @xmath1 @xcite and those used in @xmath0 @xcite .",
    "this is commonly established by demonstrating that any quantum circuit can be simulated using the ( non - physical ) resource of postselection alongside the intermediate quantum computing model @xcite .",
    "in fact it is possible to show that computing @xmath22 for many , possibly intermediate , quantum circuit families is actually @xmath25-complete , a property that helps to establish their complexity under approximations .",
    "@xmath25 is a slight generalization of @xmath23 that contains all of the problems inside @xmath23 ( see table [ decision - table ] ) .",
    "note that the suffix `` -complete '' indicates that the problem is both -hard and a member of the class itself .",
    "an estimate @xmath26 of a quantity @xmath27 is accurate to within a _ multiplicative _ error @xmath28 when @xmath29 or alternatively , as @xmath28 small is the usual case of interest , @xmath30 . when a problem is @xmath25-complete it can be shown that multiplicative approximations of the outputs from these problems are still @xmath25-complete .",
    "it is important to recognize that quantum computers are not expected to be able to calculate multiplicative approximations to @xmath25-hard problems , such as computing @xmath22 , in polynomial time .",
    "this would imply that quantum computers could solve any problem in @xmath7 in polynomial time , which is firmly believed to not be possible .",
    "however , an important algorithm from stockmeyer  @xcite gives us the ability to compute good multiplicative approximations to @xmath23-complete problems by utilizing an @xmath7 oracle and by sampling from polynomial - sized classical circuits .",
    "the stark difference in complexity under approximations between @xmath23 and @xmath25 can be used to establish a separation between the difficulty of sampling from classical and quantum circuits .",
    "if there were an efficient classical algorithm for sampling from families of quantum circuits with @xmath25-hard output probabilities , then we could use stockmeyer s algorithm to find a multiplicative approximation to these probabilities with complexity that is inside the third level of the polynomial hierarchy , however this causes a contradiction because @xmath31 contains the entire polynomial hierarchy ( and it is assumed to not collapse ) . with such arguments it can be shown that it is not possible to even sample from the outputs to within a constant multiplicative error of many intermediate quantum computing models without a collapse in the polynomial hierarchy @xcite .",
    "such results suggest quantum supremacy can be established easily , however , quantum computers can only achieve _ additive _ approximations to their own ideally defined circuits .",
    "an estimate @xmath26 of a quantity @xmath27 is accurate within an additive error @xmath32 if @xmath33 .",
    "implementations of quantum circuits are approximate in an additive sense because of the form of naturally occurring errors , our limited ability to learn the dynamics of quantum systems , and finally because quantum circuits use only finite gate sets . in order to demonstrate quantum supremacy we need a fair comparison between what a quantum computer can achieve and what can be achieved with classical algorithms . following the above line of reasoning",
    ", we would need to demonstrate that if a classical computer could efficiently produce samples from a distribution which is close in an additive measure , like the total variation distance , from the target distribution then we would also see a collapse in the polynomial hierarchy .",
    "being close in total variation distance means , with error budget @xmath34 , samples from a probability distribution @xmath35 satisfying @xmath36 are permitted .",
    "an error of this kind will tend to generate _ additive _ errors in the outputs .",
    "the key insight of aaronson and arkhipov was that for some special families of randomly chosen quantum circuits an overall additive error budget causes stockmeyer s algorithm to give an additive estimate @xmath26 that might _ also _ be a good multiplicative approximation .",
    "aaronson and arkipov  @xcite describe a simple model for producing output probabilities that are @xmath23-hard .",
    "their model uses bosons that interact only by linear scattering .",
    "the bosons must be prepared in a fock state and measured in the fock basis .",
    "linear bosonic interactions , or linear scattering networks , are defined by dynamics in the heisenberg picture that generate a linear relationship between of the annihilation operators of each mode .",
    "that is , only those unitary operators @xmath37 which act on the fock basis such that @xmath38 where @xmath39 is the @xmath40-th mode s annihilation operator and the @xmath41 form a unitary matrix which for @xmath42 modes is a @xmath43 matrix .",
    "it is important to make a distinction from the unitary operator @xmath37 which acts upon the fock basis and the unitary matrix defined by @xmath41 which describes the linear mixing of modes . for optical systems",
    "the matrix @xmath41 is determined by how linear optical elements , such as beam - splitters and phase shifters , are laid out .",
    "in fact all unitary networks can be constructed using just beam - splitter and phase shifters  @xcite .",
    "the class @xmath0 is defined as quantum sampling problems where a fiducial @xmath42-mode @xmath5-boson fock state @xmath44 is evolved through a linear network with the output being samples from the distribution that results after a fock basis measurement of all modes .",
    "the linear interaction is then the input to the algorithm and the output is the sample from the probability distribution .",
    "[ bsamp ] shows a schematic representation of this configuration .",
    "the set of events which are then output by the algorithm is a tuple of @xmath42 non - negative integers whose sum is @xmath5 .",
    "this set is denoted @xmath45 .",
    "the probability distribution of output events is related to the matrix permanent of sub - matrices of @xmath41 .",
    "the matrix permanent is defined in a recursive way like the common matrix determinant , but without the alternation of addition and subtraction .",
    "for example @xmath46 @xmath47 or in a more general form @xmath48 where @xmath49 represents the elements of the symmetric group of permutations of @xmath5 elements . with this , we can now define the output distribution of the linear network with the input state from eq .",
    "[ eq : bsinput ] . for an output event @xmath50 , the probability of @xmath51 is then @xmath52 where the matrix @xmath53 is a @xmath54 sub - matrix of @xmath41 where",
    "row @xmath40 is repeated @xmath55 times and only the first @xmath5 columns are used .",
    "one critical observation of this distribution is that all events are proportional to the square of a matrix permanent derived from the original network matrix @xmath41 .",
    "also , the fact that each probability is derived from a permanent of a sub - matrix of the same unitary matrix ensures all probabilities are less than @xmath56 and the distribution is normalised .",
    "the complexity of computing the matrix permanent is known to be @xmath23-complete for the case of matrices with entries that are @xmath57 or @xmath56  @xcite .",
    "it is also possible to show that for a matrix with real number entries is @xmath23-hard to multiplicatively estimate  @xcite .",
    "therefore , using the argument presented above , the case of sampling from this exact probability distribution implies a polynomial hierarchy collapse .",
    "the question is then if sampling from approximations of @xmath0 distributions also implies the same polynomial hierarchy collapse .",
    "the answer that aarsonson and arkipov found  @xcite is that the argument does hold because of a feature that is particular to the linear optical scattering probabilities . when performing the estimation of the matrix permanent for exact sampling , the matrix is scaled and embedded in @xmath41 .",
    "the probability of one particular output event , with @xmath5 ones in the locations of where the matrix was embedded , is then proportional to the matrix permanent squared .",
    "the matrix permanent can then be estimated multiplicatively in the third level of the polynomial hierarchy . but",
    "any event containing @xmath5 ones in @xmath45 could have been used to determine the location of the embedding .",
    "this means that , if the estimation is made on a randomly chosen output event , and that event is hidden from the algorithm implementing approximate @xmath0 , then the expected average error in the estimation will be the overall permitted error divided by the total number of events which could have been used to perform the estimation .",
    "an important consideration of the approximate sampling argument is that the input matrix appears to be drawn from gaussianly distributed random matrices .",
    "this ensures that there is a way of randomly embedding the matrix into @xmath41 so that there is no information accessible to the algorithm about where that embedding has occurred .",
    "this is possible when the unitary network matrix is sufficiently large ( strictly @xmath58 but @xmath59 is likely to be ok ) .",
    "also , under this condition , the probability of events detected with two or more bosons in a single detector tends to zero for large @xmath5 ( the so - called `` bosonic birthday paradox '' ) .",
    "there are @xmath60 events in @xmath45 with only @xmath5 ones and so the error budget can be evenly distributed over just these events .",
    "there are exponentially many of these events and so the error in the probability of an individual event does not dominate but is as small as the average expected probability itself .    with this assumption about the distribution of input matrices , the proof for hardness of approximate sampling relies on the problem of estimating the permanents of gaussian random matrices still being in @xmath23-hard .",
    "furthermore , as the error allowed to the sampling probabilities is defined in terms of total variation distance , the error in estimation becomes additive rather than multiplicative .",
    "this changes the situation from the hardness proof for exact sampling enough to be concerned that the proof may not apply .",
    "aaronson and arkipov therefore isolated the requirements for the hardness proof to still apply down to two conjectures that must hold for additive estimation of permanents for gaussian random matrices to be @xmath23-hard .",
    "they are the permenants of gaussian conjecture ( pgc ) and the permenant anti - concentration conjecture ( pacc ) .",
    "the pacc conjecture says that if the matrix permanents of gaussian random matrices are not too concentrated around zero .",
    "if this holds then additive estimation of permanents for gaussian random matrices is polynomial - time equivalent to multiplicative estimation .",
    "the pgc is that multiplicative estimation of permanents from gaussian random matrices is @xmath23-hard . in both of these conjectures",
    "there are related proofs that seem close , but do not exactly match the conditions required .",
    "nevertheless , both of these conjectures are highly plausible .",
    "several small scale implementations of @xmath0 have been performed with quantum optics .",
    "implementing @xmath0 using optics is an ideal choice as the linear network consists of a large multi - path interferometer .",
    "then the inputs are single photon states which are injected into the interferometer and single photon counters are placed at all @xmath42 output modes and the arrangement of photons at the output , shot - by - shot , is recorded . due to the suppression of multiple photon counts under the conditions for approximate @xmath0 ,",
    "single photon counters can be replaced by detectors that detect the presence or absence of photons ( e.g. avalanche photo diodes ) .    within these optical implementations ,",
    "the issues of major concern are photon loss , mode - mismatch , network errors and single photon state preparation and detection imperfections .",
    "some of these issues can be dealt with by adjusting the theory and checking that the hardness proof still holds . in the presence of loss",
    "one can post - select on events where all @xmath5 photons make it to the outputs .",
    "this provides a mechanism to construct proof of principle devices but does incur an exponential overhead which prevents scaling to large devices .",
    "rohde and ralph studied bounds on loss in bosonsampling by finding when efficient classical simulation of lossy bosonsampling is possible in two simulation strategies : gaussian states and distinguishable input photons  @xcite .",
    "aaronson and brod  @xcite have shown that in the case where the number of photons lost is constant , then hardness can still be shown . however",
    ", this is not a realistic model of loss as the number of photons lost will be proportional to the number of photons input .",
    "leverrier and garcia - patron have shown that it is a necessary condition for errors in the network to be tolerable provided the error in the individual elements scales as @xmath61  @xcite .",
    "later arkipov showed the sufficient condition is element errors scaling as @xmath62  @xcite .",
    "rahimi - keshari , et al . showed a necessary condition for hardness based on the presence of negativity of phase - space quasiprobability distributions  @xcite .",
    "this give inequalities constraining the overall loss and noise of a device implementing @xmath0 .",
    "the majority of the initial experiments were carried out with fixed , on - chip interferometers @xcite , though one employed a partially tunable arrangement using fibre optics @xcite .",
    "the largest network so far was demonstrated by n.  spagnolo , et al , where 3 photons were injected into 5 , 7 , 9 and 13 mode optical networks  @xcite . in this experiment the optical networks were multi - mode integrated interferometers fabricated in glass chips by femtosecond laser writing .",
    "the photon source was parametric down - conversion with four photon events identified via post - selection , where 3 of the photons were directed through the on - chip network and the 4th acted as a trigger .",
    "single photon detectors were placed at all outputs , enabling the probability distribution to be sampled .",
    "for the 13 mode experiment there are 286 possible output events from @xmath63 consisting of just zeros and ones . to obtain the expected probability distributions the permanents for the sub - matrices corresponding to all configurations were calculated .",
    "comparing the experimentally obtained probabilities with the predictions showed excellent agreement for all the chips .",
    "such a direct comparison would become intractable for larger systems  both because of the exponentially rising complexity of calculating the probabilities , and because of the exponentially rising amount of data needed to experimentally characterise the distribution .",
    "n.  spagnolo , et al demonstrated an alternative approach whereby partial validation of the device can be obtained efficiently by ruling out the possibility that the distribution was simply a uniform one @xcite , or that the distribution was generated by sending distinguishable particles through the device @xcite . in both cases , only small sub - sets of the data were needed and the tests could be calculated efficiently .    the bosonsampling problem is interesting because , as we have seen , there are very strong arguments to suggest that medium scale systems , such as 50 bosons in 2,500 paths , are intractable for classical computers .",
    "indeed , even for smaller systems , say 20 bosons in 400 paths , no feasible classical algorithms are currently known which can perform this simulation .",
    "this suggests that quantum computations can be carried out in this space without fault tolerant error correction that may rival the best current performance on classical computers .",
    "in addition , there is a variation of the problem referred to as scatter - shot , or gaussian bosonsampling which can be solved efficiently by directly using the squeezed states deterministically produced by down converters as the input ( rather than single photon states ) @xcite which has been experimentally demonstrated on a small scale using up to six independent sources for the gaussian states  @xcite .",
    "thus the major challenge to realising an intermediate optical quantum computer of this kind is the ability to efficiently ( i.e. with very low loss and noise ) implement a reconfigurable , universal linear optical network over hundreds to thousands of modes . on",
    "- chip designs such as the 6 mode reconfigurable , universal circuit demonstrated by j.  carolan , et al  @xcite are one of several promising ways forward .",
    "another interesting approach is the reconfigurable time - multiplexed interferometer proposed by motes et al .",
    "@xcite and recently implemented in free - space by y.  he , et al  @xcite .",
    "this latter experiment is also distinguished by the use of a quantum dot as the single photon source which have also be utilised in the spatial multiplexed interferometers  @xcite .",
    "finally , it is possible to construct a theory for realistic interferometers including polarisation and temporal degrees of freedom can be considered and also give rise to probabilities proportional to matrix permanents  @xcite .",
    "last year bremner , montanaro , and shepherd extended the @xmath0 argument to @xmath1 ( instantaneous quantum polynomial - time ) circuits , arguing that if such circuits could be classically simulated to within a reasonable additive error , then the polynomial hierarchy would collapse to the third level @xcite .",
    "crucially , these hardness results rely only on the conjecture that the average - case and worst - case complexities of quantum amplitudes of @xmath1 circuits coincide .",
    "only the one conjecture is needed as the @xmath1 analogue of the pacc was proven to be true . as this argument is native to the quantum computing circuit model , any architecture for quantum computation can implement @xmath1 sampling .",
    "it also means that error correction techniques can be used to correct noise in such implementations .",
    "furthermore , the @xmath1 sampling and the related results on fourier sampling by fefferman and umans @xcite demonstrate that generalizations of the aaronson and arkhipov argument @xcite could potentially be applied to a much wider variety of quantum circuit families , allowing the possibility of sampling arguments that are both better tailored to a particular experimental setup and for their complexity to be dependent on new theoretical conjectures .",
    "@xmath1 circuits @xcite are an intermediate model of quantum computation where every circuit has the form @xmath64 , where @xmath65 is a hadamard gate and @xmath66 is an efficiently generated quantum circuit that is diagonal in the computational basis .",
    "_ sampling _ then simply corresponds to performing measurements in the computational basis on the state @xmath67 . in @xcite",
    "it was argued that classical computers could not efficiently sample from @xmath1 circuits where @xmath66 is chosen uniformly at random from circuits composed of : ( 1 ) @xmath68 ( square - root of controlled - z ) , and @xmath69 gates ; or ( 2 ) @xmath70 , @xmath71 , and @xmath72 ( doubly controlled - z ) gates .",
    "this argument was made assuming that it is @xmath23-hard to multiplicatively approximate a constant fraction of instances of ( the modulus - squared of ) : ( c1 ) the complex - temperature partition function of a random 2-local ising model ; or ( c2 ) the ( normalized ) gap of a degree-3 polynomial ( over @xmath73 ) .",
    "these conjectures can be seen as @xmath1 analogues of boson sampling s pgc . in the case of ( 1 ) these circuits",
    "correspond to random instances of the ising model drawn from the complete graph , as depicted in fig .",
    "[ iqpfig ] .",
    "five qubit random ising model with commuting @xmath74 interactions with random strengths is an example of a problem within the class @xmath1 .",
    "qubits are prepared and measured in the computational basis.,width=325 ]    the worst - case complexity of the problems in both ( c1 ) and ( c2 ) can be seen to be @xmath23-hard as these problems are directly proportional to the output probabilities of the @xmath1 circuit families ( 1 ) and ( 2 ) .",
    "these families are examples of sets that become universal under postselection and as a result their output probabilities are @xmath23-hard ( as mentioned in section [ secsampling ] ) .",
    "this is shown by noting that for either of the gate sets ( 1 ) or ( 2 ) , the only missing ingredient for universality is the ability to perform hadamard gates at any point within the circuit .",
    "in @xcite it was shown that such gates can be replaced with a  hadamard gadget \" , which requires 1 postselected qubit and controlled - phase gate per hadamard gate .",
    "it can be shown that the complexity of computing the output probabilities of iqp circuits , @xmath75 , is @xmath23-hard in the worst case and this also holds under multiplicative approximation @xcite .",
    "the hardness of @xmath1-sampling to within additive errors follows from the observation that stockmeyer s algorithm combined with sufficiently accurate classical additive simulation returns a very precise estimate to the probability @xmath76 for a wide range of randomly chosen circuits @xmath77 .",
    "a multiplicative approximation to @xmath78 can be delivered on a large fraction of choices of @xmath79 when both : ( a ) for a random bitstring @xmath80 , the circuit @xmath81 is a hidden subset of the randomly chosen circuits @xmath77 ; and ( b ) @xmath78 anti - concentrates on the random choices of circuits @xmath77 .",
    "both of these properties hold for the randomly chosen @xmath1 circuit families ( 1 ) and ( 2 ) above , and more generally hold for any random family of circuits that satisfies the porter - thomas distribution @xcite .",
    "classical simulations of samples from @xmath77 implies a polynomial hierarchy collapse if a large enough fraction of @xmath78 are also @xmath23-hard under multiplicative approximations - and definitively proving such a statement remains a significant mathematical challenge .",
    "as mentioned above in @xcite the authors could only demonstrate sufficient _ worst - case _",
    "complexity for evaluating @xmath78 for the circuit families ( 1 ) and ( 2 ) , connecting the complexity of these problems to key problems in complexity theory .",
    "the @xmath1 circuit families discussed above allow for gates to be applied between any qubits in a system .",
    "this means that there could be @xmath82 gates in a random circuit for ( 1 ) and @xmath83 gates for ( 2 ) , with many of them long - range . from an experimental perspective this is challenging to implement as most architectures have nearest - neighbour interactions .",
    "clearly these circuits can be implemented with nearest - neighbour gates from a universal gate set , however many swap gates would need to be applied .",
    "given that many families of quantum circuits can have @xmath23-hard output probabilities this suggests it is worthwhile understanding if more efficient schemes can be found .",
    "it is also important to identify new average - case complexity conjectures that might lead to a proof that quantum computers can not be classically simulated .",
    "the challenge in reducing the resource requirements for sampling arguments is to both maintain the anti - concentration property and the conjectured @xmath23-hardness of the average - case complexity of the output probabilities .",
    "recently it was shown that _ sparse _",
    "@xmath1-sampling , where @xmath1 circuits are associated with random sparse graphs , has both of these features @xcite .",
    "it was proved that anticoncentration can be achieved with only @xmath84 long - range gates or rather in depth @xmath85 with high probability in a universal 2d lattice architecture .",
    "if we take as a guiding principle that in the worst - case output probabilities should not have a straightforward sub - exponential algorithm , then the 2d architecture depth can not be less than @xmath86 as there exist classical algorithms for computing any quantum circuit amplitude for a depth @xmath87 circuit on a 2d - lattice that scale as @xmath88 .",
    "this suggests that there might be some room still to optimize the results of @xcite , and is further evidenced by a recent numerical study suggesting that anti - concentration , and subsequently quantum supremacy , could be achieved in systems where gates are chosen at random from a universal gate set on a square lattice with depth scaling like @xmath86 .",
    "such arguments give hope that a quantum experiment on approximately 50 qubits could be performed , assuming that the rate of error can be kept low enough .",
    "recently it has also been proposed that sampling from 2d `` brickwork '' states can not be classically simulated @xcite .",
    "such states have depth @xmath89 and as such their output probabilities are thought not to anticoncentrate and can be classically computed in sub - exponential @xmath90 time .",
    "however , the authors argue that there are some output probabilities that are @xmath25-complete , yet might be reliably approximated via stockmeyer s algorithm without anticoncentration .",
    "this is possible under considerably stronger average - case complexity conjectures than those appearing in @xcite , and also requires polynomially more qubits .",
    "finally it should be remarked that the level of experimental precision required to definitively demonstrate quantum supremacy , even given generous constant total variation distance bound ( such as required in @xcite ) , is very high .",
    "asymptotically this typically requires the precision of each circuit component must improve by an inverse polynomial in the number of qubits .",
    "this is likely hard to achieve with growing system size without the use of fault tolerance constructions .",
    "more physically reasonable is to assume that each qubit will at least have a constant error rate , which corresponds to a total variation distance scaling like @xmath91 .",
    "recently it was shown that if an @xmath1 circuit has the anti - concentration property , and it suffers from a constant amount of depolarizing noise on each qubit then there is an classical algorithm that can classically simulated it to within a reasonable total variation distance @xcite .",
    "however , it should be remarked for a constant number of qubits this algorithm will likely still have a very large run - time . by contrast",
    ", @xmath1 remains classically hard under the error model for multiplicative classical approximations @xcite .",
    "intriguingly , this class of errors can be corrected without the full arsenal of fault tolerance , retrieving supremacy for additive error approximations requiring only operations from @xmath1 albeit with a cost in terms of gates and qubits @xcite .",
    "this suggests that unambiguous quantum supremacy may yet require error correction , though the level of error correction required remains a very open question .",
    "quantum sampling problems have provided a path towards experimental demonstration of the supremacy of quantum algorithms with significantly lower barriers than previously thought necessary for such a demonstration .",
    "the two main classes of sampling problems demonstrating quantum supremacy are @xmath0 and @xmath1 which are intermediate models of optical and qubit based quantum information processing architectures .",
    "even reasonable approximations to the outputs from these problems , given some highly plausible conjectures , are hard for classical computers to compute .",
    "some future directions for research in this area involve a deeper understanding of these classes as well as experimentally addressing the technological challenges towards implementations that outperform the current best known classical algorithms . theoretical work on addressing what is possible within these classes , such as detecting and correcting with errors within the intermediate models will both aid understanding and benefit experimental implementations .",
    "there has been some study of the verification of limited aspects of these devices  @xcite but more work is required . as @xmath0 and @xmath1 are likely outside the polynomial hierarchy , an efficient reconstruction of the entire probability distribution which is output from these devices will likely be impossible .",
    "however , one can build the components , characterise them and their interactions , build and run such a device to within a known error rate . beyond this multiplayer games based on sampling problems in @xmath1",
    "have been proposed to test whether a player is actually running an @xmath1 computation @xcite .",
    "recently the complexity of @xmath1 sampling has been connected to the complexity of quantum algorithms for approximate optimization problems @xcite , suggesting further applications of @xmath1 and closely related classes .",
    "applications of bosonsampling to molecular simulations  @xcite , metrology  @xcite and decision problems  @xcite have been suggested , though more work is needed in this space .",
    "nevertheless , the results from quantum sampling problems have undoubtedly brought us closer to the construction of a quantum device which definitively displays the computational power of quantum mechanics .",
    "all authors contributed equally to this work .",
    "apl and tcr received financial support from the australian research council centre of excellence for quantum computation and communications technology ( project no .",
    "ce110001027 ) .",
    "mjb has received financial support from the australian research council via the future fellowship scheme ( project no .",
    "ft110101044 ) .",
    "the authors declare no competing financial interests .",
    "efficient experimental validation of photonic boson sampling against the uniform distribution , n.  spagnolo , c.  vitelli , m.  bentivegna , d.  j.  brod , a.  crespi , f.  flamini , s.  giacomini , g.  milani , r.  ramponi , p.  mataloni , r.  osellame , e.  f.  galvao , f.  sciarrino , nature photonics * 8 * , 615 ( 2014 )          universal linear optics , jacques carolan , chris harrold , chris sparrow , enrique martn - lpez , nicholas j. russell , joshua w. silverstone , peter j. shadbolt , nobuyuki matsuda , manabu oguma , mikitaka itoh , graham d. marshall , mark g. thompson , jonathan c. f. matthews , toshikazu hashimoto , jeremy l. obrien , anthony laing , science * 349 * , 711 ( 2015 )"
  ],
  "abstract_text": [
    "<S> there is a large body of evidence for the potential of greater computational power using information carriers that are quantum mechanical over those governed by the laws of classical mechanics . </S>",
    "<S> but the question of the exact nature of the power contributed by quantum mechanics remains only partially answered . </S>",
    "<S> furthermore , there exists doubt over the practicality of achieving a large enough quantum computation that definitively demonstrates quantum supremacy . </S>",
    "<S> recently the study of computational problems that produce samples from probability distributions has added to both our understanding of the power of quantum algorithms and lowered the requirements for demonstration of fast quantum algorithms . </S>",
    "<S> the proposed quantum sampling problems do not require a quantum computer capable of universal operations and also permit physically realistic errors in their operation . </S>",
    "<S> this is an encouraging step towards an experimental demonstration of quantum algorithmic supremacy . in this paper </S>",
    "<S> , we will review sampling problems and the arguments that have been used to deduce when sampling problems are hard for classical computers to simulate . </S>",
    "<S> two classes of quantum sampling problems that demonstrate the supremacy of quantum algorithms are @xmath0 and @xmath1 sampling . </S>",
    "<S> we will present the details of these classes and recent experimental progress towards demonstrating quantum supremacy in @xmath0 . </S>"
  ]
}