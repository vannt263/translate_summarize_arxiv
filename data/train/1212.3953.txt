{
  "article_text": [
    "in the independent component ( ic ) model we assume that the components of the observed @xmath0-variate random vector @xmath1 are linear combinations of the components of a latent @xmath0-vector @xmath2 such that @xmath3 are mutually independent .",
    "then @xmath4 where @xmath5 is a full - rank @xmath6 mixing matrix .",
    "the model is semiparametric as we do not make any assumptions on the marginal distributions of @xmath3 . in order to be able to identify a mixing matrix one has to assume that at most one of the components @xmath3 is normally distributed , @xcite .",
    "still after this assumption , the parameter matrix @xmath5 is not uniquely defined : let @xmath7 be the set of @xmath6 matrices with exactly one non - zero element in each row and in each column . if @xmath8 then also @xmath9 has independent components and the model can be rewritten as @xmath10 where @xmath11 .",
    "there are several possible , but not always satisfactory , solutions to this identifiability problem .",
    "one then fixes @xmath12 by fixing either @xmath9 or @xmath11 in some way .",
    "first , the random vector @xmath9 can be fixed by requiring , for example , that the components of @xmath13 satisfy ( i ) @xmath14 , @xmath15 , ( ii ) @xmath16 , @xmath15 , and ( iii ) @xmath17 where @xmath18 and @xmath19 are classical moment - based skewness and kurtosis measures , respectively .",
    "the above idea was extended in @xcite by fixing the random vector @xmath20 using two different location vectors and two different scatter matrices with the so called independence property . in these approaches ,",
    "some indeterminacy still remains for random vectors with identical or symmetrical marginal distributions , for example .",
    "second , the transformation matrix @xmath11 can be fixed by requiring , for example , that @xmath21 is minimized .",
    "@xcite used a unique representation @xmath22 such that all the diagonal elements of @xmath22 are one . in this paper",
    "we accept the ambiguity in the model ( [ model ] ) , and try to define our concepts and analysis tools so that they are independent of the model specification , that is , of the specific choices of @xmath23 and @xmath5 .    in the independent component analysis ( ica )",
    "the aim is to find an estimate for an unmixing matrix @xmath24 such that @xmath25 has independent components .",
    "again , if @xmath24 is a mixing matrix then so is @xmath26 for all possible matrices @xmath27 .",
    "thus @xmath28 in the model ( [ model ] ) is just one possible unmixing matrix and the ica problem reduces to estimating an unmixing matrix @xmath29 only up to the order , signs and scales of the rows of @xmath29 . in the signal processing and computer science communities ica procedures are usually seen as algorithms rather than estimates with their statistical properties .",
    "the most popular algorithms , if formulated with random variables , then often proceed as follows .    1 .   in the model ( [ model ] )",
    ", one can assume without loss of generality that @xmath30 .",
    "then , after whitening , we get the random vector @xmath31 with some orthogonal matrix @xmath32 .",
    "2 .   using @xmath33 ,",
    "find a orthogonal matrix @xmath34 with the rows @xmath35 , @xmath15 , chosen to maximize ( or minimize ) a criterion function , say @xmath36|$ ] .",
    "the optimization may be conducted one by one or simultaneously .",
    "the function @xmath37 ( measure of non - gaussianity , negentropy , kurtosis measure , log - likelihood function , etc . )",
    "is chosen so that the solution is @xmath38 up to possible sign changes and permutations of the rows .",
    "the final ica solution is then @xmath39 .    the fastica algorithms described in @xcite for example works in this way . the rows of @xmath40",
    "are then found either one after another ( deflation - based fastica ) or simultaneously ( symmetric fastica ) .",
    "the sample versions are naturally obtained by replacing the expectations by corresponding sample averages . for detailed descriptions of the fastica procedures and several other estimates and algorithms ,",
    "see @xcite and @xcite .",
    "for other type of estimates , see @xcite and @xcite .",
    "due to the vast amount of different ica estimates and algorithms , asymptotic as well as finite sample criteria are needed for their comparisons . while results on asymptotic statistical properties ( convergence , asymptotic normality , etc . )",
    "are usually missing in the literature , several finite - sample performance indices have been proposed for the comparisons in simulation studies .",
    "let @xmath41 be an unmixing matrix estimate based on the random sample @xmath42 from the distribution in model ( [ model ] ) .",
    "first , one can compare the `` true '' sources @xmath43 ( which are of course known in the simulations ) and the estimated sources @xmath44 , @xmath45 .",
    "second , one can measure the closeness of the `` true '' unmixing matrix @xmath29 ( used in the simulations ) and the estimated unmixing matrix @xmath46 . in both cases",
    "the problem is that @xmath46 is typically not an estimate for @xmath29 .",
    "however , for any reasonable estimate @xmath41 , either ( i ) there exists a @xmath27 such that @xmath41 is a consistent estimate of @xmath22 , or ( ii ) there exists a ( possibly unknown or unspecified ) matrix @xmath47 such that @xmath48 is a consistent estimate of @xmath29 .",
    "therefore , for a good estimate , the gain matrix @xmath49 tends to be close to some matrix @xmath27 . in this paper",
    "we discuss performance indices that are based on the use of @xmath50 .",
    "a new index is proposed that finds the shortest distance ( using frobenius norm ) between the identity matrix and the set of matrices equivalent to the gain matrix @xmath51 .",
    "we organize the paper as follows .",
    "first , in section [ icfunctionals ] , we give a formal ( mathematical ) definition of the ic functional which is independent of the model formulation .",
    "we consider two families of ic functionals , ( i ) the family based on two scatter matrices with independence property , and ( ii ) the family of deflation - based fastica functionals .",
    "we review limiting behavior of the corresponding estimates and we prove the asymptotic normality of the deflation - based fastica under certain general assumptions .",
    "previous attempts to prove the asymptotic normality of the deflation - based fastica that have been presented in the literature contain severe faults . in section [ index ]",
    "we consider the use of the gain matrix in the comparison of different ic estimates .",
    "several approaches are discussed in detail . in section [ newindex ] a new index for the comparison",
    "is introduced .",
    "the computation of the new index is shown to be straightforward and easy .",
    "we also consider the limiting behavior of the index as the sample size approaches infinity ; the asymptotic properties of the index are in a natural way determined by the asymptotic properties of the estimate @xmath46 .",
    "the finite sample vs. asymptotic behavior of the index for several different ica estimates with known asymptotics is illustrated in a small simulation study .",
    "most proofs of the theorems are placed in the appendix .",
    "in this section we give a formal ( mathematical ) definition of an independent component ( ic ) functional .",
    "the definition is independent of the model formulation , that is , of the choice of @xmath5 and @xmath23 . as an example we consider the family of ic functionals based on two scatter matrices with independence property , and the family of deflation - based fastica functionals .",
    "let @xmath52 be the set of all full - rank @xmath6 matrices .",
    "then naturally all unmixing matrices @xmath53 .",
    "let @xmath54 denote a permutation matrix ( obtained from @xmath55 by permuting its rows or columns ) , @xmath56 a sign - change matrix ( a diagonal matrix with diagonal elements @xmath57 ) , @xmath58 a rescaling matrix ( a diagonal matrix with positive diagonal elements ) .",
    "for the definition of an ic functional we need the subset @xmath59 if @xmath27 , each row and each column of @xmath12 has exactly one nonzero element .",
    "then @xmath7 gives a group of affine transformations ( with respect to matrix multiplication ) as it satisfies ( i ) if @xmath60 then @xmath61 , ( ii ) @xmath62 , ( iii ) if @xmath8 then there exists @xmath63 such that @xmath64 . the group is not commutative ( abelian ) as @xmath65 may not be true .",
    "we say that two matrices @xmath66 and @xmath67 in @xmath52 are equivalent if @xmath68 for some @xmath8 . we then write @xmath69 and give the following definition .",
    "[ icdef ] let @xmath70 denote the cdf of @xmath71 the functional @xmath72 is an ic functional in the ic model ( [ model ] ) if ( i ) @xmath73 and if ( ii ) it is affine equivariant in the sense that @xmath74 for all nonsingular @xmath75 matrices @xmath76 .",
    "[ icremark ] the first condition says that @xmath77 and @xmath29 are equivalent matrices and that there exists @xmath78 such that the `` adjusted '' ic functional @xmath79 .",
    "note that , if the second condition ( ii ) is replaced by a weaker condition ( iii ) @xmath80 for all nonsingular matrices @xmath76 , then one can often find a new functional @xmath81 with @xmath82 satisfying condition ( ii ) .",
    "if the fourth moments exist , functional @xmath83 may be defined by requiring , for example , that @xmath84 , @xmath15 , @xmath85 , @xmath15 , and @xmath86 where @xmath18 and @xmath19 are classical moment - based skewness and kurtosis measures , respectively .",
    "then @xmath87 for all nonsingular @xmath88 matrices @xmath76 .",
    "other criteria for constructing @xmath89 can be easily found .",
    "[ icremark2 ] in practice , the ic functional is often seen rather as a set of vectors @xmath90 than as a matrix @xmath91 .",
    "if @xmath92 is the projection matrix to the subspace spanned by @xmath93 , @xmath15 , then the functional can also be defined as a set of projection matrices @xmath94 .",
    "note that , for an ic functional @xmath24 in model ( [ model ] ) @xmath95 for all @xmath96 . therefore the definition of the ic functional does not depend on the specific formulation of the model ( the choices of @xmath5 and @xmath23 ) .",
    "also , @xmath97 where @xmath98 is in @xmath7 .",
    "if we choose @xmath99 and @xmath100 , then @xmath101 .",
    "this formulation of the model is then most natural ( canonical ) for functional @xmath102 .      a _ scatter functional _",
    "@xmath103 is a @xmath6 -matrix - valued functional which is positive definite and affine equivariant in the sense that @xmath104 for all nonsingular @xmath6 matrices @xmath76 and for all @xmath0-vectors @xmath105 .",
    "a scatter functional @xmath106 is said to possess the _ independence property _ if @xmath103 is a diagonal matrix for all @xmath71 with independent components . naturally , the usual covariance matrix @xmath107 is a scatter matrix with the independence property .",
    "another scatter matrix with the independence property is the matrix based on fourth moments , namely , @xmath108 for any scatter matrix @xmath109 , its symmetrized version @xmath110 where @xmath111 and @xmath112 are independent copies of @xmath71 , has the independence property , @xcite . for symmetrized m - estimators and s - estimators ,",
    "see @xcite . the ic functional @xmath102 based on the scatter matrix functionals @xmath113 and @xmath114",
    "is defined as a solution of the equations @xmath115 where @xmath116 is a diagonal matrix with diagonal elements @xmath117 .",
    "one of the first solutions for the ica problem , the fobi functional , @xcite , is obtained if the scatter functionals @xmath118 and @xmath119 are the scatter matrices based on the second and fourth moments , respectively . the use of two scatter matrices in ica has been studied in @xcite ( real data ) and in @xcite ( complex data ) .",
    "assume now ( wlog ) that @xmath120 and that @xmath121 and @xmath122 where @xmath123 .",
    "assume also that both @xmath124 and @xmath119 have the independence property .",
    "write @xmath125 and @xmath126 ( values of the functionals at the empirical cdf @xmath127 ) .",
    "we then have the following result , @xcite .",
    "assume that @xmath128 with @xmath129 , and the estimates @xmath46 and @xmath130 are given by @xmath131 then , there exists a sequence of estimators such that @xmath132 , @xmath133 where @xmath134 is a @xmath6 matrix with elements @xmath135    above @xmath136 where @xmath137 is a diagonal matrix with the same diagonal elements as @xmath24 , and @xmath138 denotes the hadamard ( entrywise ) product .",
    "@xcite considered the limiting distribution of the fobi estimate ( with limiting covariance matrix ) in more detail .",
    "it is interesting to note that the asymptotic behavior of the diagonal elements of @xmath41 does not depend on @xmath139 at all .",
    "approaches such as jade , @xcite , or the matrix - pencil approach , @xcite , ( approximately ) jointly diagonalize two or more data matrices ( not necessarily scatter matrices ) .",
    "the asymptotic properties of these estimates are typically however still unknown .",
    "our second example on families of ic functionals is given by the deflation - based fastica algorithm .",
    "fastica is one of the most popular and widespread ica algorithms .",
    "detailed examination of fastica functionals are provided for example in @xcite and @xcite . in @xcite , the asymptotic covariance structure of the row vectors of deflation - based fastica estimate @xmath41",
    "is given in closed form .",
    "no rigorous proof of the asymptotic normality of the fastica estimate has been presented in the literature so far ; see for example @xcite . in this section",
    "we discuss the conditions needed for the asymptotic normality of the deflation - based fastica estimate .",
    "assume that @xmath140 as in model ( [ model ] ) with finite first and second moments @xmath141 and @xmath142 .",
    "in this approach the first row of @xmath24 is obtained when a criterion function @xmath143 is maximized under the constraint @xmath144 .",
    "if we wish to find more than one source then , after finding @xmath145 , the @xmath146th source maximizes @xmath143 under the constraint @xmath147    if @xmath37 satisfies the condition @xmath148 for all independent @xmath149 and @xmath150 such that @xmath151 and @xmath152 and for all @xmath153 and @xmath154 such that @xmath155 , then the independent components are found using the above strategy .",
    "it is easy to check that the condition is true for the classical kurtosis measure @xmath156 , for example @xcite .",
    "write @xmath157 for the mean vector ( functional ) and @xmath158 for the covariance matrix ( functional ) .",
    "the @xmath146th fastica functional @xmath159 then optimizes the lagrangian function @xmath160|-\\frac { \\lambda_{kk } } 2(\\gamma_k^t s(f ) \\gamma_k-1)- \\sum_{j=1}^{k-1 } \\lambda_{jk } \\gamma_j^t s(f ) \\gamma_k,\\ ] ] where @xmath161 are the lagrangian multipliers .",
    "if @xmath162 then one can easily show that ( under general assumptions ) the functional @xmath91 satisfies the @xmath0 estimating equations @xmath163   = s(f ) \\sum_{j=1}^k \\gamma_j\\gamma_j^t   e[g(\\gamma_k^t(x - t(f))(x - t(f)))],\\ ] ] @xmath164 .",
    "if @xmath165 has independent components then @xmath24 solves the above estimating equations .",
    "note , however , that the estimating equations do not fix the order of sources @xmath166 anymore .",
    "as mentioned before , the ica procedures are often seen as algorithms rather than estimates with statistical properties .",
    "the popular choices of @xmath167 for practical calculations are _ pow3 _ : @xmath168 , _ tanh _ : @xmath169 , and _ gauss _ : @xmath170 , for example . if @xmath171 then the fastica algorithm for @xmath172 uses the iteration steps    1 .",
    "@xmath173-e[g'(\\gamma_k^tx)]\\gamma_k$ ] 2 .",
    "@xmath174 3 .",
    "@xmath175    the sample version is naturally obtained if the expected values are replaced by the averages in the above formula .",
    "it is important to note that it is not known in which order the components are found in the above algorithm .",
    "the order depends strongly on the initial value in the iteration .",
    "we next consider the limiting behavior of the sample statistic @xmath41 based on a random sample @xmath176 .",
    "we assume that @xmath177 and @xmath178 and that the true value is @xmath179 .",
    "write @xmath180 and @xmath181 for the sample mean vector and sample covariance matrix , respectively .",
    "if the fourth moments exist then @xmath182 have a limiting multivariate normal distribution ( clt ) .",
    "write @xmath183 for the fastica estimate of @xmath24 .",
    "write also @xmath184 , \\",
    "\\ \\lambda_k = e[g(e_k^tx_i)e_k^tx_i]\\ ] ] and @xmath185 , \\   \\",
    "\\delta_k = e[g'(e_k^tx_i)],\\ ] ] @xmath164 .",
    "we need later the assumption that @xmath186 , @xmath187 .",
    "( if @xmath168 , for example , this assumption rules out the normal distribution . ) for sample statistics @xmath188 we need the assumption that , using the taylor expansion , @xmath189 where @xmath190 $ ] , @xmath164 .",
    "again , if @xmath168 and the sixth moments exist , then ( [ fasticaass ] ) is true and @xmath191 has a limiting multinormal distribution .",
    "the estimating equations for the fastica solution @xmath183 are then given by @xmath192\\hat t_k,\\ \\ \\",
    "k=1, ... ,p.\\ ] ] if ( [ fasticaass ] ) is true and @xmath193 then @xmath194+o_p(1)\\end{aligned}\\ ] ] and we get the following result .    [ fasticaas ]",
    "let @xmath176 be a random sample from the model ( [ model ] ) with @xmath120 , @xmath177 , and @xmath178 .",
    "let @xmath183 be the solution for estimating equations in ( [ esteq ] ) , and the estimate satisfies @xmath132 . then , under the general assumptions given above , @xmath195+o_p(1 ) ,",
    "\\ \\ \\ \\ \\mbox{for    $ l > k$ } \\\\",
    "\\sqrt{n } ( \\hat{\\gamma}_{kk}-1 ) & = & -\\frac 12   \\sqrt{n } ( \\hat s_{kk}-1)+o_p(1 ) , \\ \\ \\ \\ \\mbox{and }   \\\\",
    "\\sqrt{n } \\hat{\\gamma}_{kl } & = & \\sqrt{n } \\hat{\\gamma}_{lk}- \\sqrt{n } \\hat s_{kl}+o_p(1 )    \\ \\ \\ \\ \\mbox { for $ l < k$}\\end{aligned}\\ ] ]    theorem [ fasticaas ] implies that , if @xmath196 , @xmath164 , and @xmath197 have a joint limiting multivariate normal distribution then also the limiting distribution of @xmath198 is multivariate normal .",
    "interestingly enough , the limiting distribution of the estimated sources @xmath199 depends on the order in which they are found .",
    "the limiting behavior of the diagonal elements of @xmath41 does not depend on the choice of the function @xmath200 .",
    "the initial value for @xmath41 in the fastica algorithm fixes the asymptotic order of the sources . for more details , see @xcite .",
    "let @xmath42 be a random sample from the model ( [ model ] ) with some choice of @xmath5 and @xmath23 .",
    "an estimate of the population quantity @xmath77 is obtained if the functional is applied to the sample cdf @xmath127 .",
    "we then write @xmath41 or @xmath201 or @xmath202 .",
    "the _ gain matrix _",
    "@xmath203 is then generally used to compare the performances of different estimates . for any reasonable estimate , @xmath204 for some @xmath205 .",
    "how can one then compare matrices @xmath206 converging to a different population value @xmath12 that depend on functional @xmath24 and the specific choice of @xmath5 and @xmath23 in the model ( [ model ] ) ?      for a comparison of different estimates @xmath41 choose , separately for each ic functional @xmath24 , the corresponding canonical parametrization @xmath207 note that @xmath208 does not depend on the model formulation ( the original choices of @xmath5 and @xmath23 ) at all and that @xmath209 .",
    "a correctly adjusted gain matrix @xmath210 can then be used for a fair comparison of different estimates @xmath41 as in the model ( [ model ] ) @xmath211 for all @xmath24 .",
    "a natural performance index can then be defined as @xmath212 where @xmath213 if @xmath214 ( as is true with the estimates in sections [ ics ] and [ fastica ] ) then we get the following result .",
    "[ main - canonical ] assume that , for the correctly adjusted gain matrix @xmath215 it holds that @xmath216 .",
    "then the limiting distribution of @xmath217 is that of @xmath218 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath221 .",
    "it is often hoped that the independent components in @xmath222 are standardized in a similar way and/or given in a certain order . to formalize this step , we then need the following auxiliary functional to standardize ( rescale and reorder ) the components .",
    "let @xmath70 denote the cdf of @xmath71 the functional @xmath223 is a _ standardizing functional _ if it satisfies @xmath224    [ icremark3 ] if the fourth moments exist , functional @xmath83 may be defined by requiring , for example , that @xmath225 , @xmath15 , @xmath226 , @xmath15 , and @xmath227 where @xmath18 and @xmath19 are , as before , classical moment - based skewness and kurtosis measures , respectively . of course",
    ", the functional is not well defined if the components have the same distribution .",
    "note , however , that the corresponding sample statistic is uniquely defined ( with probability one ) .",
    "other standardizing functionals can be easily found .",
    "let @xmath70 denote the cdf of @xmath71 , and @xmath77 an ic functional .",
    "then the adjusted ic functional @xmath228 based on @xmath89 is @xmath229    note that adjusted ic functionals are directly comparable as they all estimate the same population quantity .",
    "the estimate is @xmath230 and the gain matrix reduces to @xmath231    the standardizing functional @xmath232 is thus needed to fix the scales , the signs , and the order of the estimated independent components .",
    "the rescaling part @xmath233 of the functional @xmath232 is a diagonal matrix with positive diagonal elements , and it is often determined by a scatter functional @xmath158 so that @xmath234 the rescaled ic functional is then @xmath235 with the sample version @xmath236 we next consider the effect of the rescaling functional .",
    "[ adjest ] assume ( w.l.o.g . ) that @xmath120 and @xmath237 .",
    "assume that @xmath238 and @xmath239 for some diagonal matrix @xmath58 with positive diagonal elements .",
    "write @xmath240 where @xmath241",
    ". then @xmath242    the gain matrix for the comparisons is thus @xmath243 with the limiting distribution given by theorem [ adjest ] . as , for all the estimates @xmath244 ,",
    "the limiting behavior of the diagonal elements of @xmath206 is similar , one can use @xmath245 in the comparisons . if @xmath246 then we get the following result .",
    "[ main - adjest ] assume that , for the gain matrix of the adjusted estimate @xmath247 it holds that @xmath248 .",
    "then the limiting distribution of @xmath249 is that of @xmath218 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath250 with @xmath251 .",
    "note that the first two approaches above do not depend on how we fix @xmath5 and @xmath23 in the model ( [ model ] ) . in these two approaches",
    "it is assumed , however , that @xmath253 is a root-@xmath254 consistent estimate of some @xmath27 . among other things , this means that the order , signs , and scales of the independent component functional are fixed in some way . in practice ,",
    "the solution in the ica problem is often seen rather as a set @xmath252 than a matrix @xmath255 .",
    "the vectors @xmath256 , @xmath15 , span corresponding univariate linear subspaces ; thus the order , signs and lengths of @xmath256 are not interesting .",
    "finally , in the comparisons , one is usually only interested in the set of gain vectors @xmath257 where @xmath258 , @xmath15 , not in the gain matrix @xmath259 itself .",
    "a common way to standardize the lengths of the rows of the gain matrix is to transform @xmath260 where @xmath261 is a diagonal matrix with diagonal elements @xmath262 we then have the following result .    [ stand2_th ]",
    "assume that @xmath120 and that @xmath263 where @xmath58 is a diagonal matrix with positive diagonal elements .",
    "let @xmath261 be a diagonal matrix given ( [ stand2 ] ) .",
    "then @xmath264    the inference - to - signal ( isr ) ratio and inter - channel inference ( ici ) , @xcite , uses this row - wise consideration and is given by @xmath265 this index is invariant under permutations and sign changes of the rows ( and columns ) of @xmath206 , and it is also naturally invariant under heterogeneous rescaling of the rows .",
    "it depends on the choice of @xmath5 but no adjustment of @xmath41 is needed .",
    "theorem [ stand2_th ] can be used to find asymptotical properties of this criterion .",
    "one of the most popular performance indices , the amari index , @xcite , is defined as @xmath266 - 2.\\ ] ] the index is invariant under permutations and sign changes of the rows and columns of @xmath206 . however , heterogeneous rescaling of the rows ( or columns ) on @xmath206 changes its value .",
    "therefore , the rows of @xmath41 should be rescaled in a suitable way and use @xmath267 .",
    "( a general practice in the signal processing community is that @xmath5 and @xmath23 are chosen so that @xmath30 and that the sample covariance matrix of @xmath268 is @xmath55 as well . ) however , as the index is based on the @xmath269 norm , its limiting distribution is quite complicated .",
    "the intersymbol interference ( isi ) , @xcite , is similar to the amari index in that it is also based on similar row - wise and column - wise considerations and that similar adjusting is needed for @xmath41 .",
    "@xcite for example use an invariant criterion by computing the norm @xmath270 , after suitable rescaling , sign changing , and permutation of the rows of @xmath41 and columns of @xmath5 .",
    "let @xmath76 be a @xmath6 matrix .",
    "the shortest squared distance between the set @xmath271 of equivalent matrices ( to @xmath76 ) and @xmath55 is given by @xmath272 where @xmath273 is the matrix ( frobenius ) norm .",
    "[ remark ] note that @xmath274 for all @xmath27 .",
    "[ fourcond ] let @xmath76 be any @xmath6 matrix having at least one nonzero element in each row .",
    "the shortest squared distance @xmath275 fulfils the following four conditions :    1 .",
    "@xmath276 , 2 .",
    "@xmath277 if and only if @xmath278 , 3 .",
    "@xmath279 if and only if @xmath280 for some @xmath0-vector @xmath281 , and 4 .",
    "the function @xmath282 is increasing in @xmath283 $ ] for all matrices @xmath76 such that @xmath284 , @xmath285 .",
    "let @xmath286 be a random sample from a distribution @xmath70 where @xmath71 obeys the ic model ( [ model ] ) with unknown mixing matrix @xmath5 .",
    "let @xmath287 be an ic functional . then clearly @xmath288 .",
    "if @xmath127 is the empirical cumulative distribution function based on @xmath289 then @xmath290 is the unmixing matrix estimate based on the functional @xmath102 .",
    "the shortest distance between the identity matrix and the set of matrices @xmath291 equivalent to the gain matrix @xmath292 is as given in the following definition .",
    "the minimum distance index for @xmath46 is @xmath293    it follows directly from theorem [ fourcond ] , that @xmath294 , and @xmath295 if and only if @xmath296 . the worst case with @xmath297 is obtained if all the row vectors of @xmath298 point to the same direction .",
    "thus the value of the minimum distance index is easy to interpret .",
    "note that @xmath299 for all @xmath8 . also , @xmath300 note also the nice and natural local behavior described in theorem [ fourcond ] , condition 4 .",
    "@xcite proposed an index called the generalized crosstalking error which is defined as the shortest distance @xmath301 between the mixing matrix @xmath5 and its adjusted estimate @xmath302 , @xmath303 .",
    "the generalized crosstalking error is then defined as @xmath304 where @xmath273 denotes a matrix norm .",
    "clearly , @xmath305 for all @xmath306 but @xmath307 is not necessarily true .",
    "if the frobenius norm is used , the new index may be seen as a standardized version of the generalized crosstalking error as @xmath308 note that , unlike the minimum distance index , the values of the amari index for @xmath253 and @xmath309 ( with a diagonal matrix @xmath58 ) may differ .",
    "the amari index thus silently assumes that the rows of @xmath41 are prestandardized in a specific way .",
    "the minimum distance index is compared to other indices in more detail in @xcite .      at first glance",
    "the index @xmath310 seems difficult to compute in practice as the minimization is over all choices @xmath27 .",
    "however , the minimization can be done by two easy steps .",
    "[ trace ] let @xmath311 denote the set of all @xmath6 permutation matrices .",
    "let @xmath312 , and let @xmath313 , @xmath314 .",
    "now the minimum distance index can be written as @xmath315    the maximization problem @xmath316 over all permutation matrices @xmath317 can be expressed as a linear programming problem where the constraints are that all rows and all columns must add up to 1 . in a personal communication ravi varadhan pointed out that it can be seen also as a linear sum assignment problem ( lsap ) .",
    "that lsap , which is a special case of linear programming , is equivalent to finding a minimizing permutation matrix as is stated for example in ( * ? ? ?",
    "* chapter 8.5 ) .",
    "the cost matrix @xmath318 of the lsap in this case is given by @xmath319 , @xmath320 , and many solvers exist for the computation .",
    "we used the hungarian method ( see e.g. @xcite ) to find the maximizer @xmath321 , and in turn compute @xmath261 itself .",
    "the ease of computations is demonstrated in table [ computation times ] where we give the computation time of thousand indices for randomly generated @xmath6 matrices in different dimensions .",
    "the computations were performed on an intel core 2 duo t9600 , 2.80 ghz , 4 gb ram using matlab 7.10.0 on windows 7 .",
    ".computation time in seconds for 1000 indices for different dimensions @xmath0 . [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     an r - implementation of the index is available in the r - package jade , @xcite .",
    "let the model be written as @xmath322 where now @xmath23 is standardized such that @xmath323 .",
    "then @xmath324 , and without any loss of generality we can assume that @xmath325 we then have the following .    [ main ] assume that the model is fixed such that @xmath326 and that @xmath327 .",
    "then @xmath328 and the limiting distribution of @xmath329 is that of @xmath330 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath331 with @xmath251 .",
    "note that , for the theorem , we fix the model in a specific way ( canonical formulation , @xmath332 ) to find the limiting distribution",
    ". then , for all choices of of @xmath5 and @xmath23 , @xmath333 where @xmath334 is as in theorem [ main ] . note also that the mean of the limiting distribution of @xmath335 is equal to @xmath336 which is a regular global measure of the asymptotic accuracy of the estimate @xmath46 in a model where it is estimating the identity matrix . furthermore , to calculate this limiting value , it is enough to know the asymptotic variances of elements of @xmath41 only .",
    "recall that the variances of diagonal elements are not used .",
    "it is also important to note that similar asymptotical results for the amari index can not be found since ( i ) it is not invariant in the sense that the values for @xmath253 and @xmath309 may differ , and ( ii ) it is based on the use of @xmath269 norms .",
    "[ other ] the new performance index presented in this paper is based on @xmath337 this formulation can be seen as a method that fixes the mixing matrix @xmath5 and transforms @xmath46 to optimally adjusted @xmath338 .",
    "the index is not invariant under the transformations @xmath339 .",
    "one could alternatively base the index on @xmath340 this alternative formulation can be seen as a method that fixes the unmixing matrix estimate @xmath46 and transforms @xmath5 to optimally adjusted ( random ) @xmath341 .",
    "asymptotical behavior of this index is similar to that of the minimum distance index @xmath261 but it is not invariant under transformations @xmath342 .",
    "it seems more natural to us to fix @xmath5 and @xmath23 and allow transformations to @xmath41 .",
    "still another interesting possibility is to define the criterion index as @xmath343 this index is naturally invariant under both @xmath344 and @xmath345 and is fully model independent .",
    "unfortunately , it does not seem to work in practice . in the bivariate case , for example",
    ", it is easy to see that , for all choices of @xmath346 , @xmath347 and @xmath348 , the gain matrices @xmath349 all give the optimal index value zero .",
    "the finite - sample behavior of the new index @xmath261 is now considered for three estimates , namely , ( i ) the fobi estimate , and ( ii ) the deflation based fastica with @xmath168 ( pow3 ) , and ( iii ) the deflation based fastica with @xmath169 ( tanh ) .",
    "the asymptotic normality of the fobi estimate is proven in @xcite .",
    "see @xcite also for the limiting covariance matrix of the fobi estimate . the asymptotic covariance matrix of the deflation based fastica estimate is given in @xcite .",
    "asymptotic normality was proven in this paper .",
    "if the parametric marginal distibutions were known , it is possible to find the maximum likelihood estimate ( mle ) of the unmixing matrix ; @xcite found its limiting covariance matrix .",
    "as a general reference value we can then compute the cramer - rao type lower bound for @xmath350 .",
    "the simulation setup consists of three ( @xmath351 ) independent components with laplace , logistic and @xmath352 distributions .",
    "they were all standardized to have expected value 0 and variance 1 . in the simulations , the mixing matrix @xmath5 was the identity matrix @xmath353 .",
    "the sample sizes were @xmath354 , @xmath355 , @xmath356 , @xmath357 , @xmath358 , @xmath359 with @xmath355 repetitions , and for each repetition the value of @xmath261 was computed for all the estimates .",
    "as shown for the fastica estimates in section [ fastica ] , the limiting distribution of the estimated sources @xmath199 depends on the order in which the algorithm finds them . in practice",
    ", the order can be controlled with the initial value of the algorithm .",
    "using the identity matrix as initial value , for example , finds the sources in the order they are given above , and a permuted identity matrix as a starting value finds the sources in a similarly permuted order . to illustrate this property in our simulations , we extracted the sources in two different orders , ( a ) @xmath352 , logistic and laplace , and ( b ) laplace , logistic and @xmath352 .",
    "the estimates are then denoted by pow3(a ) , pow3(b ) , tanh(a ) , and tanh(b ) , respectively . using the results in @xcite ,",
    "one can calculate the limiting variances of the components of @xmath360 . as a matrix form ,",
    "the variances then are @xmath361 where @xmath362 is the limiting variance of @xmath363 , @xmath364",
    ". then @xmath365 similarly , using results in @xcite , @xmath366 and then @xmath367 and @xmath368 finally , @xmath369 which gives @xmath370 and @xmath371 there are quite big differences in the asymptotic behavior of the fastica estimates only depending on the order in which the sources are found .",
    "note also that the variances of the diagonal elements of @xmath41 are equal for all the estimates studied here .",
    "they are simply the limiting variances of the sample variances of the standardized independent components divided by @xmath372 as , in all the cases , the regular covariance matrix is used to whiten the data .",
    "the variances of the diagonal elements of @xmath41 are then not used in the comparison .",
    "based on the fobi estimate for different sample sizes @xmath254 and 10000 repetitions on log scale .",
    "the three independent components have laplace , logistic and @xmath352 distributions .",
    "the horizontal line gives the limiting mean value.,scaledwidth=60.0% ]     based on the fastica estimates pow3(a ) and pow3(b ) for different sample sizes @xmath254 and 10000 repetitions on log scale .",
    "the three independent components have laplace , logistic and @xmath352 distributions .",
    "the horizontal line gives the limiting mean value .",
    ", scaledwidth=60.0% ]     based on the fastica estimates tanh(a ) and tanh(b ) for different sample sizes @xmath254 and 10000 repetitions on log scale .",
    "the three independent components have laplace , logistic and @xmath352 distributions .",
    "the horizontal line gives the limiting mean value .",
    ", scaledwidth=60.0% ]     for the estimates fobi , pow3(a ) , pow3(b ) , tanh(a ) and tanh(b ) .",
    "the dashed horizontal lines give the corresponding limiting mean values .",
    "the solid horizontal line is the limiting mean for the mle ( with known marginal distributions).,scaledwidth=55.0% ]    boxplots in figures [ boxplots1 ] , [ boxplots2 ] and [ boxplots3 ] illustrate the finite - sample behavior of the index for different estimates .",
    "the horizontal lines give the limiting mean values on a log scale .",
    "the fobi estimate is known to converge in distribution to a multivariate normal distribution , but the convergence is very slow .",
    "the distributional convergence of @xmath373 is then also slow as is seen from figure [ boxplots1 ] .",
    "what is interesting , is that the speed of convergence of the distribution ( not only the covariance structure ) of the fastica estimate seems to depend on the order of the found sources , see figure [ boxplots2 ] and figure [ boxplots3 ] .",
    "the distributional convergence of @xmath373 for tanh(b ) seems to be faster than that for tanh(a ) , see figure [ boxplots3 ] . the same is true for pow3(b ) and pow3(a ) as well , see figure [ boxplots2 ] .",
    "the estimated means of @xmath373 for different estimates @xmath41 are compared in figure [ boxplotsall ] again with asymptotic horizontal lines .",
    "the performance of the fobi estimate is clearly worst .",
    "the mle with the assumption that the marginal distributions are known provides the cramer - rao lower bound for the limiting mean , see @xcite .",
    "the order in which the sources are found seems to have a huge effect on the performance of the fastica estimate .",
    "if the sources are found in the order @xmath352 , logistic , and laplace , there is no big difference between choices pow3 : @xmath168 and tanh : @xmath169 . if the order is laplace , logistic , and @xmath374 the estimate tanh perform very well while the estimate pow3 gets worse .",
    "independent component analysis ( ica ) has gained increasing interest in various fields of applications in recent years . as far as we know , this paper provides the first rigorous ( mathematical ) definition of the ic functional .",
    "the functional is defined in a general semiparametric ic model and is independent from the parametrization of the model .",
    "the deflation - based fastica algorithm is one of the most popular ica algorithms .",
    "several superficial attempts to find the limiting distribution and limiting covariance matrix of the fastica mixing matrix estimate can be found in the literature ( see e.g. @xcite , @xcite , @xcite ) .",
    "the correct limiting covariance matrix was found however quite recently in @xcite . in this paper",
    "we provide the assumptions needed for the limiting multivariate normality .    for several popular ica procedures ,",
    "the statistical properties are still unknown , and their performances are compared using different performance criteria in simulation studies . in this paper we discuss several criteria in detail and suggest a new performance index with an easy interpretation .",
    "the asymptotic behavior of the new index depends in a natural way on the eigenvalues of the limiting covariance matrix of an unmixing matrix estimate .",
    "this is illustrated in a small simulation study with some deflation - based fastica estimates and with fobi estimate .",
    "we did not use other ica procedures in our study as , for other estimates proposed in the literature , the limiting properties are still unknown and/or their implementations can not deal with the sample sizes of our study .",
    "note also that the new index can also be computed using the correlation matrix between the estimated and true sources . in that case",
    "the index has a nice connection to the mean - squared error as discussed in @xcite .",
    "the theory presented in this paper has also important practical implications .",
    "for example , @xcite introduces a new reloaded deflation - based fastica algorithm that , using a preliminary estimate and the results here , extracts the sources in an optimal order to minimize the trace of the limiting covariance matrix .",
    "assume that @xmath216 .",
    "now it follows directly from ( * ? ? ?",
    "* theorem 3.1 ) that the limiting distribution of @xmath217 is that of @xmath218 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath221 .",
    "assume that @xmath248 , and let @xmath251 .",
    "now @xmath381 and thus @xmath382 now it follows from ( * ? ? ?",
    "* theorem 3.1 ) that the limiting distribution of @xmath249 is that of @xmath218 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath383          let @xmath386 be a @xmath6 matrix having at least one nonzero element in each row and let @xmath387 let @xmath388 denote the set of all nonsingular @xmath6 diagonal matrices and let @xmath389 now @xmath390 and @xmath391 the derivatives are zero with choices @xmath392 and the value of @xmath393 is then @xmath394 let @xmath311 denote the set of all @xmath6 permutation matrices .",
    "now it follows that if @xmath312 , and @xmath313 , @xmath314 , then the minimum distance index can be written as @xmath395      let @xmath386 be a @xmath6 matrix having at least one nonzero element in each row .",
    "let @xmath396 with @xmath397 let @xmath311 denote the set of all @xmath6 permutation matrices . now the shortest squared distance @xmath398 ( see the proof of lemma [ trace ] . ) consider now @xmath399 where @xmath400 for all @xmath401 and @xmath402 now clearly the maximum value of @xmath403 is @xmath0 and it is attained if and only if @xmath404 is a permutation matrix . since @xmath404 is a permutation matrix if and",
    "only if @xmath405 we have now proven that @xmath406 for all @xmath76 and that @xmath277 if and only if @xmath278 .    for the minimum value of @xmath403 note that @xmath407 if @xmath408 then @xmath409 for all permutation matrices @xmath410 since all row sums of @xmath404 are one , if rows @xmath411 of @xmath404 are different , there have to exist indices @xmath412 such that @xmath413 and that @xmath414 let now @xmath415 and @xmath416 denote permutation matrices which are identical in all rows @xmath417 and in all columns @xmath418 and let the elements @xmath419 and @xmath420 of @xmath415 be equal to one , and let the elements @xmath421 and @xmath422 of @xmath416 be equal to one . then @xmath423 contradicting the fact that @xmath424 is identical for all permutation matrices @xmath410 hence @xmath280 for some @xmath0-vector @xmath281 . we have now proven that @xmath425 for all @xmath76 and that @xmath279 if and only if @xmath280 for some @xmath0-vector @xmath281 .",
    "assume now that @xmath426 and let @xmath427 where @xmath283 $ ] and let @xmath428 .",
    "then @xmath429 now clearly @xmath430 decreases when @xmath431 increases .",
    "this proves that the function @xmath282 is increasing in @xmath283 $ ] for all matrices @xmath76 such that @xmath284 , @xmath285 .",
    "we have @xmath433 let @xmath434 @xmath435 and for all @xmath436 let @xmath437 and @xmath438 now for all @xmath439 @xmath440 where @xmath441 and @xmath442 where @xmath443 ( see the proof of lemma [ trace ] ) .",
    "let @xmath444 since @xmath445 it now follows from the continuous mapping theorem that also @xmath446 and thus @xmath447 since @xmath448 holds for all @xmath439 it follows that @xmath449 and @xmath450 as well .",
    "clearly @xmath451 since @xmath452 and @xmath453 are discrete , we now have , by using slutsky s theorem , that @xmath454      consider now the @xmath462 element of the matrix @xmath463 we have @xmath464 it now follows from our assumptions and discreteness of @xmath453 and @xmath452 that each @xmath465 converges to normal distribution with zero mean .",
    "now each @xmath466 converges in distribution to a @xmath467 variable and thus each @xmath468 converges in probability to zero and @xmath469 @xmath470 converges in probability to zero as well .",
    "now since @xmath471 it follows from slutsky s theorem that @xmath472 since @xmath473 , we now have by slutsky s theorem and discreteness of @xmath453 that @xmath474 since @xmath475 we conclude , using slutsky s theorem again , that @xmath476 where @xmath477 with @xmath251 .",
    "thus @xmath328 and it follows from ( * ? ? ? * theorem 3.1 ) , that the limiting distribution of @xmath329 is that of @xmath330 where @xmath219 are independent chi squared variables with one degree of freedom , and @xmath220 are the @xmath146 nonzero eigenvalues ( including all algebraic multiplicities ) of @xmath478                                  ilmonen , p. , nordhausen , k. , oja , h. and ollila , e. ( 2010b ) a new performance index for ica : properties , computation and asymptotic analysis , _ latent variable analysis and signal processing _ ( ieee proceedings of 9th international conference on latent variable analysis and signal separation ) , 229236 .",
    "nordhausen , k. , oja , h. and ollila , e. ( 2011a ) multivariate models and the first four moments . in hunter , d.r . ,",
    "richards , d.s.r . and rosenberger , j.l .",
    "( editors ) _ nonparametric statistics and mixture models : a festschrift in honor of thomas p. hettmansperger _ , 267287 , world scientific , singapore .",
    "nordhausen , k. , ollila , e. and oja , h. ( 2011b ) on the performance indices of ica and blind source separation . in proceedings of 2011 ieee 12th international workshop on signal processing advances in wireless communications ( spawc 2011 ) , 171175 .",
    "nordhausen , k. , ilmonen , p. , mandal , a. , oja , h. and ollila , e. ( 2011d ) deflation - based fastica reloaded . in the proceedings of 19th european signal processing conference 2011 ( eusipco 2011 ) , 18541858 .",
    "shimizu , s. , hyvrinen , a. , kano , y. , hoyer , p.  o. and kerminen , a.  j. ( 2006 ) testing significance of mixing and demixing coefficients in ica .",
    "proceedings of international symposium on independent component analysis and blind signal separation ( ica2006 ) , charleston , sc , usa .",
    "tichavsky , p. , koldovsky , z. and oja , e. ( 2005 ) asymptotic performance of the fastica algorithm for independent component analysis and its iprovements , in proceedins of 2005 ieee / sp 13th workshop on statistical signal processing , 10841089 .",
    "yeredor , a. ( 2009 ) on optimal selection of correlation matrices for matrix - pencil - based separation .",
    "lecture notes in computer science ( lncs 5441 ) : independent component analysis and signal separation , 8th international conference on ica , paraty , brazil , springer - verlag , berlin heidelberg ."
  ],
  "abstract_text": [
    "<S> independent component analysis ( ica ) has become a popular multivariate analysis and signal processing technique with diverse applications . </S>",
    "<S> this paper is targeted at discussing theoretical large sample properties of ica unmixing matrix functionals . </S>",
    "<S> we provide a formal definition of unmixing matrix functional and consider two popular estimators in detail : the family based on two scatter matrices with the independence property ( e.g. , fobi estimator ) and the family of deflation - based fastica estimators . </S>",
    "<S> the limiting behavior of the corresponding estimates is discussed and the asymptotic normality of the deflation - based fastica estimate is proven under general assumptions . </S>",
    "<S> furthermore , properties of several performance indices commonly used for comparison of different unmixing matrix estimates are discussed and a new performance index is proposed . </S>",
    "<S> the proposed index fullfills three desirable features which promote its use in practice and distinguish it from others . </S>",
    "<S> namely , the index possesses an easy interpretation , is fast to compute and its asymptotic properties can be inferred from asymptotics of the unmixing matrix estimate . </S>",
    "<S> we illustrate the derived asymptotical results and the use of the proposed index with a small simulation study .    </S>",
    "<S> keywords : independent component analysis ; performance indices ; fastica ; fobi ; asymptotic normality . </S>"
  ]
}