{
  "article_text": [
    "the term optimization , in the field of mathematics , refers to the study of problems in which we are looking for optimal solutions , minimum or maximum , for a given function .",
    "these solutions are obtained through systematic changes in the values of the variables .",
    "when we want to optimize systematically and simultaneously various objective functions ( usually conflicting between themselves ) , we will have the process known as multiobjective optimization .",
    "a good algorithm created for solving multiobjective optimization problems must : 1 ) find multiple pareto optimal solutions and 2 ) find a good diversity of solutions on the obtained pareto front ( close to an uniform distribution)@xcite .",
    "variations of evolutionary algorithms , known as multiobjective evolutionary algorithms ( moeas ) , are the metaheuristic best known for solving multiobjective optimization problems . due to the characteristics inherited from the evolutionary computing , these algorithms have operators with parameters that need to be configured . moreover , the performance of a moea is crucially dependent on the parameter setting of these operators .",
    "the most desired control of such parameters presents the characteristic of adaptiveness , i.e. , the capacity of changing the value of the parameter , in distinct stages of the evolutionary process , using feedbacks from the search for determining the direction and/or magnitude of changing .",
    "however , moeas usually employs stochastic operators with static parameters .    according to eiben and smith @xcite",
    "a run of an evolutionary algorithm is a process intrinsically dynamic and adaptive .",
    "then , this static approach can result in an inefficient convergence to the pareto optimal solutions and a failure for creating an ( almost ) uniform distribution of final solutions on the obtained pareto front .",
    "given the great popularity of the algorithm _ non - dominated sorting genetic algorithm ii _ ( nsga - ii ) @xcite , we propose to create adaptive controls for each parameter existing in this moea for increasing even more its ability for reaching the pareto optimal front and for getting a better diversity among the final solutions .    within the context",
    "presented , we propose in this work an adaptive mutation operator which uses information about the diversity of candidate solutions for controlling the magnitude of the mutation .    the rest of this paper is organized as follows .",
    "section 2 presents the concept of _ crowding distance _",
    "@xcite , a density estimator that will provide information for controlling the magnitude of the mutation .",
    "section 3 describes the adaptive mutation operator proposed .",
    "the experiments and the statistical validation of the results are described in section 4 .",
    "finally , section 5 summarizes the results of this work and proposes additional topics for further research .",
    "the crowding distance is an important concept proposed by deb _ et .",
    "@xcite in his algorithm nsga - ii .",
    "it serves for getting an estimate of the density of solutions surrounding a particular solution in the population .",
    "more specifically , the crowding distance for a point @xmath0 ( called @xmath1 ) is an estimate of the size of the largest cuboid enclosing @xmath0 without including any other point in the population .",
    "it is calculated by taking the average distance of the two points on either side of @xmath0 along each of the objectives .",
    "the algorithm used for calculating the crowding distance for each point in a population @xmath2 is :    crowding - distance - assignment(@xmath2 ) : + @xmath3 + for = each @xmath4 + @xmath5_{distance } = 0 $ ] + for = each objective @xmath6 + @xmath7 + @xmath8_{distance}=l[l]_{distance } = \\infty $ ] + for = @xmath9 to @xmath10 + @xmath5_{distance } \\mbox{+=}$ ] = @xmath11 + @xmath12    in the first line , it is assigned the size of the population @xmath2 to the variable @xmath13 . following this operation",
    ", there is a loop responsible for initializing with @xmath14 the @xmath1 of each element @xmath0 of the population @xmath2 .    in the fourth line ,",
    "each objective @xmath6 is selected at a time and the population is sorted in a ranking according to the value for @xmath6 .",
    "the @xmath1 value for solutions in the first and in the last position is assigned as infinity ( @xmath15 ) for preserving solutions with extreme values .",
    "the inner loop presents in the seventh line updates the @xmath1 value for each remaining solution _",
    "i _ from position @xmath16 to @xmath17 .",
    "first , it is calculated the @xmath6-th objective function value for the neighbors of _",
    "i_. thereafter , it is calculated the difference between the highest and the lowest value .",
    "finally , the @xmath1 value for @xmath0 is updated by the sum of its previous value with the normalized result of that subtraction .",
    "figure 1 shows an illustration of this calculation for a given solution @xmath0 . in this scenario ,",
    "the @xmath1 value for @xmath0 will be @xmath18 where :    @xmath19",
    "according to eiben and smith @xcite , an adaptive parameter control uses feedback from the search for serving as input to a mechanism used for determining the direction and/or magnitude of changing . using the well known static mutation operator proposed by deb and goyal @xcite together with an adaptive parameter control for updating its parameter",
    ", this section presents the adaptive mutation operator created for improving even more the performance of the algorithm nsga - ii .    in the original ( static ) version of the mutation operator ,",
    "the current value of a continuous variable is changed to a neighboring value using a polynomial probability distribution .",
    "this distribution has its mean at the current value of the variable and its variance as a function of a parameter @xmath20 .",
    "this parameter will define the strength of the mutation and we are interested in adaptively changing its value .",
    "besides this parameter , the polynomial probability distribution depends on a factor of disturbance @xmath21 for calculating the mutated value as can be seen in the following equation :    @xmath22    where @xmath23 $ ] .",
    "figure 2 shows this distribution for some values of @xmath20 .",
    "initially , for creating a mutated value we need to generate a random number @xmath24 $ ] .",
    "thereafter , the equation 2 ( obtained from equation 1 ) can be used for calculating the factor of disturbance @xmath25 corresponding to @xmath26 :    @xmath27^\\frac{1}{n+1 } & \\mbox{if } u \\ge 0.5\\\\ \\end{array } \\right.\\ ] ]    in the end , the mutated valued is calculated using the following equation :    @xmath28    where @xmath29 is the mutated value , @xmath30 is the original value and @xmath31 is the maximum disturbance allowed in the value of @xmath30 ( it was defined here as the difference between the maximum and the minimum value for the decision variable ) .    to change the variance of the probability distribution ( the parameter @xmath20 in equation 1 ) in an adaptive way , we will use two empirical facts observed .",
    "first , the initial solutions are dispersed in the search space and distant from the pareto optimal front .",
    "furthermore , the difference between the greatest @xmath1 value not infinite and the lowest @xmath1 value is lifted . in this scenario , it is necessary to apply a strong mutation for ensuring a quicker convergence to the pareto optimal front and a fast attainment of distinct solutions .",
    "second , at the end of the evolutionary process it will be expected solutions closer to the pareto optimal front due to the efficacy of the nsga - ii .",
    "moreover , the difference between the greatest ( not infinite ) and the lowest @xmath1 value is reduced .",
    "now , it is necessary to apply a soft mutation for avoiding destroying solutions previously generated and for trying to approximate them to the pareto optimal front .",
    "so , the main ideas exploited by the adaptive control are to use information about the difference between the greatest ( not infinite ) and the lowest @xmath1 value and about the current stage of the evolutionary process . due to the fact that the nsga - ii calculates the @xmath1 for all individuals in the current population before applying evolutionary operators",
    ", it will not be necessary to re - calculated it again .",
    "so , we just have to calculate @xmath32 , the difference between the greatest ( different of @xmath15 ) and the lowest @xmath1 value :    @xmath33    the next step is to use information about the current generation @xmath34 of the evolutionary process . for ensuring that it will have an acceptable weight in the update of the parameter",
    ", we applied on it a logistic function .",
    "so , the second step taken by the controller is to calculate the function :    @xmath35    where @xmath34 is the current generation .",
    "the inspiration for using such function is the fact that it would fit perfectly into our proposal because we would like to apply a strong mutation in the early stages of the evolutionary process and gradually reduce its value during the process .",
    "the constant value @xmath36 is used because the value of @xmath37 will be approximately @xmath14 when @xmath38 .",
    "actually , when @xmath34 is greater than @xmath39 , the function @xmath40 will practically stop influencing the mutation because its value will be equals to @xmath41 .",
    "it is useful to cite that the new value for the parameter @xmath20 has to be inversely proportional to @xmath32 .",
    "this happens due to the fact that for higher values of @xmath32 it will be necessary to apply a strong mutation and , consequently , it will be needed a lower value for @xmath20 to increase the variance of the probability distribution .",
    "furthermore , the new value for @xmath20 has to be directly proportional to the @xmath40 due to the fact that for higher values of @xmath34 it will be needed a soft mutation and , consequently , it will be needed a higher value for @xmath20 to reduce the variance of the probability distribution . in the end ,",
    "the last step taken by the controller is to update @xmath20 , before applying a mutation in the current generation , as follows :    @xmath42",
    "in order for evaluating the performance of the proposed adaptive mutation operator , this section provides a comparative study among different settings for the nsga - ii .",
    "the first one uses the original mutation operator proposed by deb and goyal @xcite with @xmath43 ( for representing a strong mutation ) .",
    "the second configuration also uses this mutation operator , but this time with @xmath44 ( for representing a smooth mutation ) .",
    "at least , the third configuration is represented by the adaptive mutation operator proposed here .",
    "the remaining parameters are the same for all settings .",
    "we used a population size of @xmath45 individuals ( this small value was chosen for making the mutation more valorous ) , a crossover probability of @xmath46 , a mutation probability of @xmath47 ( where @xmath20 is the number of variables ) .",
    "the variables were treated as real numbers and the simulated binary crossover operator ( sbx ) @xcite was used . for all experiments ,",
    "the implementation used as reference was proposed by durillo _ et al _ @xcite .",
    "the problems used in experiments were chosen based on characteristics usually present in real problems @xcite : continuous pareto optimal front vs. discontinuous pareto optimal front ; convex pareto optimal front vs. non - convex pareto optimal front ; uniformly represented pareto optimal front vs. non - uniformly represented pareto optimal front .",
    "the first problem used was proposed by fonseca and fleming @xcite ( called here as fon2 ) .",
    "the next four problems used ( zdt1 , zdt2 , zdt3 , zdt6 ) were proposed by zitzler _",
    "et al _ @xcite and belong to a test suite called zdt .",
    "due to the fact that the convergence to the pareto optimal front and the maintenance of a diverse set of solutions are two different goals of the multiobjective optimization , it will be need two different metrics for deciding the performance of a setting in an absolute manner @xcite .",
    "the first metric used , called generational distance ( gd ) @xcite , is responsible for finding the closeness of the obtained set of solutions to the pareto optimal front as follows :    @xmath48    where @xmath49 is the set of the obtained solutions and @xmath50 is the euclidean distance between the solution @xmath51 and the nearest member of the pareto optimal front as exhibited below :",
    "@xmath52    where @xmath53 is the pareto optimal front and @xmath54 is the _ m_-th objective function value of the _ k_-th member of @xmath53 .",
    "this metric has the constraint that it is necessary the pareto optimal front . here",
    ", for each problem utilized in the experiments we used the front provided by coello _ et al _ @xcite .",
    "it is useful to note that before calculating this distance measure , it is necessary to normalize the objective function values .",
    "the second metric used measures the spread of the obtained set of solutions calculating the non - uniformity in the distribution .",
    "it was proposed by deb _",
    "et al _ @xcite as follows :    @xmath55    where @xmath50 is any distance metric between neighboring solutions , @xmath56 is the mean value of these distance measures and @xmath57 and @xmath58 are the distances between boundary solutions from the set of obtained solutions and the pareto optimal front . for both metrics , a lower value implies in a better result .    in the end",
    ", we run each configuration @xmath39 independent times until the @xmath39-th generation in each problem .",
    "the obtained results according to the metrics spread and generational distance are shown respectively in table 1 and table 2 . in each row of these tables , we have the upper cell containing the mean for the @xmath39 runs ( the lower value is highlighted with bold font ) and below it a cell containing the standard deviation .",
    "moreover , for the rows representing the settings @xmath43 and @xmath44 we have a bottom cell containing the results of the use of the statistical test called _ test t _ with a confidence level of @xmath59 .",
    "this test is applicable for comparing two samples of two populations normally distributed , not necessarily of the same size , where the mean and the variance of the population are unknown .",
    "we used this test for understanding whether there is a statistically significant difference between the results produced by the setting @xmath43 or @xmath44 and the results obtained by the adaptive approach .",
    "the value `` @xmath60 '' indicates that the adaptive approach will have a lower value with @xmath59 of confidence , the value `` @xmath61 '' represents that the adaptive approach will have a higher value with @xmath59 of confidence and the value `` @xmath62 '' means that there is not statistically significant difference between the approaches .",
    "[ table1 ]    .results obtained by the metric spread [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     as can be seen from the tables , the adaptive mutation operator got the lowest means for both metrics in all problems . furthermore , in 3 of 5 problems the adaptive approach obtained the lowest standard deviation for the metric spread and in all problems it got the lowest standard deviation for the metric generational distance .",
    "looking for the results of the _ test t _ , the adaptive approach was superior to the setting with @xmath43 in 3 problems for the metric spread and in 4 problems for the metric generational distance . in relation to the setting @xmath44 , the adaptive approach was better in 4 problems for both metrics .",
    "this paper presented the first step for creating adaptive controls for each parameter present in the algorithm nsga - ii to improve even more its performance .",
    "we proposed an adaptive mutation operator that uses information about the diversity of the population , through the concept of crowding distance , for controlling the strength of the mutation .    running the algorithm nsga - ii on five different problems , we compared the results obtained by the adaptive approach with the results obtained by two different static settings : a setting that applied a strong mutation and a setting that applied a smooth mutation .",
    "the experimental results have shown that the approach proposed outperformed both settings in convergence to the pareto optimal front and in diversity of the final solutions .",
    "a statistical test was done to prove the relevance of the results .",
    "while the approach seems interesting , it is clear that more work will be necessary to understand its impact on the search .",
    "moreover , a clear empirical study is required to demonstrate its significance .",
    "it is useful to cite that this approach can also be used for controlling parameters of other operators .",
    "for instance , the parameter that controls the proximity of the offspring from the parents in the crossover operator ( sbx ) proposed by deb @xcite can be controlled in such way that new solutions staying closer of parents with higher crowding distance .",
    "this would help in increasing diversity .",
    "j.  j. durillo , a.  j. nebro , f.  luna , b.  dorronsoro , and e.  alba . .",
    "technical report iti-2006 - 10 , departamento de lenguajes y ciencias de la computacin , university of mlaga , e.t.s.i .",
    "informtica , campus de teatinos , december 2006 .      c.  m. fonseca and p.  j. fleming .",
    "multiobjective genetic algorithms made easy : selection , sharing and mating restriction . in _ proceedings of the first international conference on genetic algorithms in engineering systems : innovations and applications _",
    ", pages 4552 , 1995 ."
  ],
  "abstract_text": [
    "<S> the performance of a multiobjective evolutionary algorithm ( moea ) is crucially dependent on the parameter setting of the operators . </S>",
    "<S> the most desired control of such parameters presents the characteristic of adaptiveness , i.e. , the capacity of changing the value of the parameter , in distinct stages of the evolutionary process , using feedbacks from the search for determining the direction and/or magnitude of changing . </S>",
    "<S> given the great popularity of the algorithm nsga - ii , the objective of this research is to create adaptive controls for each parameter existing in this moea . with these controls </S>",
    "<S> , we expect to improve even more the performance of the algorithm .    in this work </S>",
    "<S> , we propose an adaptive mutation operator that has an adaptive control which uses information about the diversity of candidate solutions for controlling the magnitude of the mutation . </S>",
    "<S> a number of experiments considering different problems suggest that this mutation operator improves the ability of the nsga - ii for reaching the pareto optimal front and for getting a better diversity among the final solutions .    </S>",
    "<S> [ heuristic methods ] </S>"
  ]
}