{
  "article_text": [
    "there are two types of microarray experiments . in the first type",
    ", samples are not labeled , but gene expression levels are followed with time . the goal is to find genes whose expression levels move together . in the second type , samples are labeled as either normal or diseased tissues .",
    "the goal is to find genes whose expression levels can distinguish different labels . using terminology from machine learning ,",
    "the data analysis of the first type of experiment is  unsupervised \" , whereas that of the second type is  supervised \" ( see , e.g. , [ haghighi , banerjee , li , 1999 ] ) .",
    "the prototype of the first type of analysis is cluster analysis , whereas that of the second type is discriminant analysis .",
    "we focus on the data analysis of the second type , using the leukemia data from whitehead / mit s group [ golub et al , 1999 ] .",
    "the question we are addressing is how many gene expressions are needed for a discriminant analysis . in this data",
    "set , 7129 gene expressions are measured on 38 sample points . in the original analysis",
    "[ golub et al , 1999 ] , 50 out of more than 7000 gene expressions are used for discriminant analysis .",
    "we ask whether 50 genes are still too large a number , considering that the sample size is only 38 .",
    "this seemingly simple question may receive two answers from two different perspectives : model selection ( see , e.g. , [ burnham , anderson , 1998 ] ) and model averaging ( see , e.g. , [ geisser , 1974 ] ) .",
    "we will address the two separately below .",
    "the goal of model selection is to pick the model among many possible models that achieves the best balance between data - fitting and model complexity .",
    "a perfect data - fitting performance by a complicated model with many parameters can well be an example of overfitting .",
    "on the other hand , a simplistic model with few parameters that fits the data poorly is an example of underfitting .",
    "there are two proposals for achieving the balance between data - fitting and model complexity : akaike information criterion ( aic ) [ akaike , 1974 ; parzen , tanabe , kitagawa , 1998 ; burnham , anderson , 1998 ] and bayesian information criterion ( bic ) [ schwarz , 1976 ; raftery , 1995 ] .",
    "these two quantities are defined as : @xmath0 where @xmath1 is the maximized likelihood , @xmath2 the number of free parameters in the model , and @xmath3 the sample size .",
    "high - order terms of @xmath4 ( for aic ) and @xmath5 ( for bic ) are ignored here for simplicity .",
    "the model with the lowest aic or bic is considered to be the preferred model .",
    "selecting genes relevant to a discriminant microarray data analysis may become an issue of model selection .",
    "but we have to be clear in what context this is the case .",
    "model selection adjusts the number of parameters in the model , not the number of variables . nevertheless , if we plan to combine variables ( additively or any other functional form )",
    ", each variable has one or perhaps more coefficient .",
    "removing a variable removes the corresponding coefficient . in this context",
    ", variable selection is a special case of model selection .",
    "we illustrate this by the logistic regression / discrimination for our data set : @xmath6 where @xmath7 is the ( log , normalized ) gene expression level of gene @xmath8 among the top performing genes , and aml ( acute myeloid leukemia ) is one type of leukemia ( all , the acute lymphoblastic leukemia , is another type ) . using a linear combination of all 7129 genes in logistic discrimination requires 7130 parameters , whereas using one gene requires only 2 parameters .",
    "aic / bic defined in eq.([aic - bic ] ) will then compare multiple - gene models with single - gene models , and determine which scenario is better .",
    "our results are summarized in table 1 , where we list the type of model ( which variables are additively combined in the logistic regression ) , number of parameters in the model , -2log of the maximum likelihood , aic / bic ( absolute and relative ) , prediction rate in training set , and that in the testing set .",
    "the most striking result from this data set is that many genes are strong predictors for the leukemia class , consistent with the observation in [ golub et al , 1999 ] .",
    "this observation is confirmed by the following facts in table 1 : logistic regressions using the top 2 , 5 , 10 , 22,and 37 genes all fit the data almost perfectly ( as measured by the @xmath9 value ) ( note that the model is saturated when the number of variables used in the logistic regression is 37 , since the number of parameters is then equal to the number of sample points ) ; stepwise variable selection leads to only two genes ( note that stepwise variable selection fails to find the best model , a single - gene model , because it is a local minimization / maximization procedure ) ; the no.10 best - performing gene is only slightly worse than the no.1 performing gene : 35 vs. 36 correct predictions on the training set ( though the no.100 and no.200 best - performing genes predict only 30 and 29 correctly on the training set ) ; etc .",
    "this situation of strong prediction or easy classification is in contrast with the epidemiology and pedigree data used in human complex diseases , where strong predictors are rather rare [ li , sherriff , liu , 2000 ; li , nyholt , 2001 ] .",
    "thest two rows in table 1 are predictors / classifiers that do not use any gene expression levels .",
    "these are random guesses or null models .",
    "the first null model ( # 1 ) uses the proportion of aml in all samples as prob(aml ) ( 11/38 in our training set ) as the guessing probability for aml .",
    "the second null model ( # 0 ) uses half - half probabilities .",
    "it is interesting to note that to beat both null , the number of genes in logistic regression can not exceed some upper limits : for null model 1 , since we require aic / bic to be smaller ( where @xmath10 is the number of genes used in logistic regression , and @xmath9 is assumed to be zero for the best - case scenario ) : @xmath11 it sets @xmath12 , and @xmath13 , respectively .",
    "similarly , to beat the random - guess model , we require : @xmath14 which are @xmath15 , and @xmath16 , respectively .",
    "these specific upper limits are directly related to the fact that the sample size is 38 .",
    "they will move up and down with the sample size .    .",
    "logistic regression results ( sample size n=38 , log(n)=3.637568 ) .",
    "@xmath2 : number of free parameters in the logistic regression ( lr ) ( number of genes included plus 1 ) ; @xmath17aic ( @xmath17bic ) is the aic ( bic ) value relative to that of the best model ( single - gene lr using g4847 , zyxin ) ; @xmath18 ( @xmath19 ) is the prediction rate on the training ( testing ) set ;  top 37 \" is the lr using 37 best genes by their single - variable lr performance",
    ". notes ( a ) since this model / predictor fits the data perfectly , @xmath1 should be 1 , and @xmath9 should be 0 . in a real optimization procedure , the actual value may depend on the number of iterative steps .",
    "( b ) this lr is selected by a stepwise variable selection ( by either aic or bic ) from the starting group of top 22 genes ( top 22 @xmath20 a / bic @xmath20 2 ) ; ( c ) similar to ( b ) , but the starting group of genes in the lr containing the top 10 genes ( top 10 @xmath20 a / bic @xmath20 2 ) ; ( d ) this null model uses 11/38 @xmath21 0.29 as the probability for aml for any sample data . since 0.29 @xmath22 0.5 , any sample will be predicted as all type , which is correct 27 times in the training set , and 20 times in the testing set .",
    "the @xmath9 is equal to @xmath23 $ ] ; ( e ) the @xmath9 , @xmath18 , and @xmath19 for the random guess model is expected to be : @xmath24 , 0.5 , and 0.5 . [ cols=\"^,^,^,^,^,^,^,^,^\",options=\"header \" , ]",
    "in the model selection framework , we can not use a logistic regression with too many genes because it may not improve the data - fitting performance enough to compensate for the increase of model complexity .",
    "this conclusion is correct when one model ( e.g. a logistic regression that uses one gene ) is compared to other alternative models ( e.g. a logistic regression that uses , say , 10 genes ) .",
    "nevertheless , it is possible to average / combine many different models each involving one gene .",
    "the restriction on model complexity during the model selection process does not apply to model averaging .",
    "model averaging has also been discussed under names such as  committee machines \" ,  boosting weak predictors \" ,  mixture of experts \" ,  stacked generalization \" ( see , e.g. , [ ripley , 1996 ] ) .    without guidance from the model selection framework on the number of models ( number of genes ) to be included , we have tried several empirical approaches .",
    "we first examine whether there is a gap in data - fitting performance among top genes .",
    "genes that do not fit the data should not be considered in model averaging . for this purpose",
    ", fig.1 shows the @xmath25 for the top 1000 genes on the training set , as a function of the ( log ) rank .",
    "a linear fitting of @xmath9 on @xmath26(rank ) seems to fit the points well , and it is hard to see  better - than - average \" genes except the first gene .",
    "this is not surprising since g4847 discriminates the 38 training sample points perfectly .",
    "note that the linear trend in fig.1 is equivalent to a power - law function in likelihood vs. rank plot ( @xmath27 ) .",
    "such power - law is similar to the power - law rank - frequency plots observed in many social and natural data , also known as zipf s law [ zipf , 1949 ; li , 1997 - 2001 ] . in any case",
    ", there is no discernible gap in fig.1 that separates relevant and irrelevant genes .",
    "we then check how the prediction rate on the training set correlates with that on the testing set .",
    "fig.2 shows the error rates on both training ( x - axis ) and testing sets ( y - axis ) for the top 500 performing genes .",
    "the left plot in fig.2 shows the mean square error , and the right plot shows the prediction errors .",
    "the left plot contains both information on the success rate of prediction and that of confidence of prediction , whereas the right plot contains only information on the success rate of prediction .",
    "points along the diagonal line in fig.2 exhibit similar error rates in the training and testing set , and thus are reasonable predictors . on the other hand , points well above the diagonal line indicate overtraining . the most reasonable predictor based on both",
    "the training and testing set is g1882 ( on the other hand , the best predictor based on training set is g4847 ) .",
    "finally we examine the model averaging performance with various numbers of models included , each being a single - gene logistic regression : @xmath28 we have chosen three weighting schemes : the first is proportional to the prediction rate on the training set ( @xmath29 ) , the second is the equal weight ( @xmath30 ) , and the last one is proportional to the maximum likelihood as obtained from the training set ( @xmath31 ) .",
    "fig.3 - 4 shows the behavior of all three weighting schemes on both the training and the testing sets , using either the mean square error or the prediction error , up to 200 genes .",
    "the maximum likelihood weight is equivalent to the akaike weight ( @xmath32 ) [ parzen , tanabe , kitagawa , 1998 ] and bayesian weight ( @xmath33 ) [ raftery , 1995 ] , since all models being averaged in eq.([model - ave ] ) have the same number of parameters and same sample size ( assuming high - order terms are ignored ) . using bayesian weight in model averaging is essentially a derivation of the posterior predictive distribution [ gelman , et al , 1995 ] :  posterior \" because data in a training set is used , and  predictive \" because unknown new data in the testing set is to be predicted .    for our data set",
    ", this weighting scheme is nevertheless uninteresting : the mean square error only decreases slightly with the number of models used , while the error in prediction rate is unchanged .",
    "the reason for this is very simple : the best model ( the single - gene logistic regression using the g4847 ) discriminates the training set perfectly .",
    "its likelihood is much higher than any other models . as a result , the weight of other models is negligible , and the model averaging essentially remains as one model",
    ". the equal weight can be potentially incorrect since models that do not fit the data should not contribute as equally as models that fit the data better . in our data set , however , the equal weight scheme is actually similar to the weighting scheme that uses the prediction rate , because many genes ( up to 200 ) exhibit similar prediction rates on the training set .",
    "it is difficult from fig.3 - 4 to determine a cutoff on the number of models ( number of genes ) to be included .",
    "fig.3 - 4 , however , clearly shows that a lower number of models ( genes ) is typically better ( except the maximum likelihood weight , which is insensitive to the number of genes included ) .",
    "fig.3 , in particular , indicates that it is possible to perform better ( in term of mean square error ) on the testing set than using just one model if the number of models is less than around 25 .",
    "of course , this result is obtained from the specific testing set we have at hand .",
    "a more conclusive result may require a combining of the training and testing set , or requires more sample points than are currently available .",
    "due to the weight in a model averaging , the apparent number of terms ( models , genes ) included does not reflect on the true number of genes involved .",
    "for this reason , we may introduce a quantity called  effective number of genes ( terms , models ) \" .",
    "the leading term in a model averaging contributes a number of 1 to this quantity , but the contribution from the term j is equal to @xmath34 .",
    "for example , with the maximum likelihood weight , the relative weights of the first ten terms are 1 , 0.031 , 0.0043 , 0.0034 , 0.0032 , 0.0024 , 0.0022 , 0.0014 , 0.0014 , and 0.0006 . the effective number of terms when the top ten genes are included is 1.05 , a far less number than 10 .",
    "the discrimination used in [ golub et al , 1999 ] is a model averaging instead of a model selection .",
    "the number of genes used is 50 . to quote from [ golub , et al , 1999 ] ,",
    " the number was well within the total number of genes strongly correlated with the class distinction , seemed likely to be large enough to be robust against noise , and was small enough to be readily applied in a clinical setting . \" our fig.3 - 4 shows that although the prediction rate on the training set stays close to 100% even as the number of models ( genes ) is increased , the prediction rate on the testing set decreases with more genes .",
    "the only exception is the maximum likelihood weight , where the prediction rate is almost unchanged due to the dominance of the best gene .",
    "it seems that we should not increase the number of models ( genes ) in model averaging arbitrarily .    in conclusion , due to the small sample size and the presence of strong predictors",
    ", we believe the number of genes used in a discriminant analysis in this data set can be much smaller than 50 .",
    "although we can not give a definite answer as to the exact number of genes to be used , one proposal is to use only one or two genes , and other exploratory data analyses indicate an upper limit of 10 - 20 genes .",
    "similar analysis of other data sets for cancer classifications using microarray will be discussed in [ li , et al .",
    "2001 ] and zipf s law in these data sets will be discussed in [ li , 2001 ] .",
    "w.lis work was supported by nih grant k01hg00024 and y. yang s work was supported by the grant mh44292 .",
    "h akaike ( 1974 ) ,  a new look at the statistical model identification \" , ieee transactions on automatic control , 19:716 - 723 .",
    "tr golub , dk slonim , p tamayo , c huard , m gaasenbeek , jp mesirov , h coller , ml loh , jr downing , ma caligiuri , cd bloomfield , es lander ( 1999 ) ,  molecular classification of cancer : class discovery and class prediction by gene expression monitoring \" , science , 286:531 - 537 .",
    "f haghighi , p banerjee , w li ( 1999 ) ,  application of artificial neural networks in whole - genome analysis of complex diseases \" ( meeting abstract ) , cold spring harbor meeting on genome sequencing & biology , page 75 .",
    "w li , a sherriff , x liu ( 2000 ) ,  assessing risk factors of complex diseases by akaike information criterion and bayesian information criterion \" ( meeting abstract ) , american journal of human genetics , 67 ( supp 2 ) , page 222 ."
  ],
  "abstract_text": [
    "<S> the analysis of the leukemia data from whitehead / mit group is a discriminant analysis ( also called a supervised learning ) . among thousands of genes </S>",
    "<S> whose expression levels are measured , not all are needed for discriminant analysis : a gene may either not contribute to the separation of two types of tissues / cancers , or it may be redundant because it is highly correlated with other genes . </S>",
    "<S> there are two theoretical frameworks in which variable selection ( or gene selection in our case ) can be addressed . </S>",
    "<S> the first is model selection , and the second is model averaging . </S>",
    "<S> we have carried out model selection using akaike information criterion and bayesian information criterion with logistic regression ( discrimination , prediction , or classification ) to determine the number of genes that provide the best model . </S>",
    "<S> these model selection criteria set upper limits of 22 - 25 and 12 - 13 genes for this data set with 38 samples , and the best model consists of only one ( no.4847 , zyxin ) or two genes . </S>",
    "<S> we have also carried out model averaging over the best single - gene logistic predictors using three different weights : maximized likelihood , prediction rate on training set , and equal weight . </S>",
    "<S> we have observed that the performance of most of these weighted predictors on the testing set is gradually reduced as more genes are included , but a clear cutoff that separates good and bad prediction performance is not found . </S>"
  ]
}