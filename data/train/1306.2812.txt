{
  "article_text": [
    "the literature on missing data is not entirely clear with respect to the assumptions required for different types of analysis to be valid .",
    "first , although the term `` missing at random '' ( mar ) has been widely regarded as central to the theory underlying missing data methods since the seminal paper of rubin ( 1976 )  @xcite , it has not always been used in a consistent manner .",
    "there has often been a lack of detail about whether the mar condition is a statement only about the realised missingness pattern or about all possible patterns and whether it is only about the realised values of the observed data or all possible observable data values .",
    "second , the distinction between direct - likelihood and frequentist inference using the likelihood function is not always made clear .",
    "third , it is sometimes said that `` missing completely at random '' ( mcar ) is needed for frequentist inference ; at other times mar is said to be sufficient .",
    "while it is clear that some researchers writing on the theory of missing data have known what they intended , the omission of details by many authors , together with the seemingly different conditions assumed by different authors , make it difficult for readers to know precisely what was meant , and also to compare the work of different authors .",
    "this confusion has implications for statistical practice , since data analysts are encouraged to consider the plausibility of the mar assumption before applying certain methods of analysis ( e.g. , @xcite ) , but if the conscientious analyst consults the theoretical literature they will struggle to find a clear consensus on definitions and on how they relate to the validity of possible analytic approaches .",
    "further confusion surrounds the concept of `` ignorability '' , which does not seem to be well understood by practitioners and may be misinterpreted as providing a broad licence to ignore the fact that not all the desired data have been observed .    in the present article ,",
    "our objectives are to:(1 )  draw attention to the various gaps and inconsistencies in some definitions of mar used in the literature ; ( 2 )  provide unambiguous formulations of relevant mar definitions ; and ( 3 ) explain the relation between mar and ignorability under different frameworks of statistical inference and , in so doing , identify the need for more than one definition of mar .",
    "the structure of the paper is as follows . in section  [ sectmydefinitions ]",
    "we provide definitions of two distinct mar conditions , one stronger than the other , and likewise for mcar .",
    "the inconsistency in previous usage of the terms `` mar '' and `` mcar '' is documented in section  [ sectreview ] .",
    "the definitions of mar and mcar are central to the concept of ignorability , the definition of which varies according to the chosen framework of statistical inference . in section  [ sectinferencetypes ] we distinguish between direct - likelihood inference , bayesian inference , frequentist inference using the likelihood function and the frequentist properties of bayesian estimators .",
    "section  [ sectignorability ] contains an explanation of which mar / mcar conditions are needed for the missingness mechanism to be ignorable for each of these types of inference .",
    "section  [ sectconditional ] covers the use of conditional likelihood and repeated sampling .",
    "we end with a discussion .",
    "we use @xmath0 to denote the vector of potentially observable data values ( on all sample units ) , which for modelling purposes we treat as a random variable .",
    "let @xmath1 denote a vector of missingness indicators of the same length as @xmath0 .",
    "the @xmath2th element of @xmath1 equals one if the @xmath2th element of @xmath0 is observed and zero if it is missing .",
    "let @xmath3 , a function of @xmath0 and @xmath1 , denote the subvector of @xmath0 consisting of elements whose corresponding elements of @xmath1 equal one .",
    "so , @xmath3 contains the observed elements of @xmath0 .",
    "let @xmath4 denote the length of @xmath3 .",
    "so , @xmath4 is a random variable and is equal to the sum of the elements of @xmath1 .",
    "when no elements of @xmath0 are observed , @xmath3 is the empty set and @xmath5 .",
    "the reader may be familiar with the notation @xmath6 and @xmath7 .",
    "we choose not to use this notation because it is ambiguous , as we explain in section  [ sectreview ] . however , our notation @xmath3 is equivalent to @xmath6 as usually interpreted .",
    "when we consider a specific sample , it is convenient to have notation for the realised values of the random variables @xmath1 and @xmath0 ; we denote these realised values as @xmath8 and @xmath9 , respectively .",
    "`` realised '' and `` observed '' values should not be confused .",
    "the observed value , @xmath3 , of @xmath0 is a random variable and has a realised value , @xmath10 .",
    "the values of @xmath8 and @xmath10 are known , but that of @xmath9 is only known if all elements of @xmath8 equal one .    in the special case where the data are modelled as a set of @xmath11 random variables measured on each of @xmath12 units , as is often the case , @xmath0 is a vector of length @xmath13 .",
    "although in this special case one might alternatively define @xmath0 as a matrix with @xmath12 rows and @xmath11 columns , for the sake of generality we do not do this .",
    "for example , suppose that @xmath0 consists of two random variables , @xmath14 and @xmath15 , measured on each of two units , that the realised value of @xmath16 is @xmath17 for the first unit and @xmath18 for the second , and that @xmath14 is observed for both units but @xmath15 is only observed for the second .",
    "then @xmath19 , @xmath20 and @xmath21 .",
    "note that @xmath22 can not be interpreted without the accompanying value of  @xmath23 .    consider a hypothesised `` missingness model '' , that is , a model for the conditional distribution of @xmath1 given  @xmath0 .",
    "let @xmath24 denote the probability that @xmath25 given that @xmath26 according to this model , where @xmath27 is an unknown parameter .",
    "we now present two definitions of mar .",
    "[ defin1 ] the data are realised mar if  @xmath28 , @xmath29 ( where @xmath30 represents a value of @xmath0 ) .",
    "this means that the hypothesised missingness model always ( i.e. , for all values of @xmath27 ) assumes that the conditional probability that the missingness pattern @xmath1 is its realised value @xmath8 , given the realised values of the elements of the data @xmath0 that are observed when @xmath31 and the values of the remaining , missing , elements , does not depend on these missing elements .",
    "rubin  @xcite expressed this as follows : `` the missing data are missing at random if for each possible value of the parameter @xmath27 , the conditional probability of the observed pattern of missing data , given the missing data and the value of the observed data , is the same for all possible values of the missing data '' .",
    "there are several things to note about this definition .",
    "first , it is a statement only about the realised missingness pattern and realised observed data , not about missingness patterns or observed data that could have been realised but were not .",
    "second , it is a statement about a hypothesised missingness model , rather than necessarily the true missingness process .",
    "[ defin2 ] the data are everywhere mar if  @xmath28 , @xmath32 ( where @xmath30 and @xmath33 represent a pair of values of @xmath0 ) .",
    "this means that the hypothesised missingness model always assumes that , for any value of the data , the probability of any possible missingness pattern , given the values of the corresponding observed elements and missing elements of the data , does not depend on the values of the missing elements . in order to make more obvious",
    "the difference between realised and everywhere mar , note that definition  [ defin1 ] can be rewritten as follows .",
    "the data are realised mar if @xmath28 , @xmath34 @xmath35 such that @xmath36 . unlike realised mar , everywhere mar is a statement about all possible missingness patterns and values of the observed data .",
    "note that everywhere mar implies realised mar .    to illustrate and clarify the notation that we have used here ,",
    "consider the example given above , that is , @xmath19 , @xmath20 and @xmath37 .",
    "the data are realised mar if @xmath28 , @xmath38 @xmath35 such that the first , second and fourth elements of both @xmath39 and @xmath40 equal , respectively , 10 , 4 and 2 .",
    "that is , the data are realised mar if , for any @xmath27 , @xmath41 for all @xmath42 in the sample space of the second element of  @xmath0 .",
    "now consider the special case of independent identically distributed ( i.i.d . )",
    "data , that is , @xmath43 and @xmath44 , where @xmath45 ( @xmath46 are i.i.d .",
    "let @xmath47 denote the subvector of @xmath48 consisting of elements of @xmath48 whose corresponding elements of @xmath49 equal one .",
    "[ note that the function @xmath50 is analogous to the previously defined @xmath51 , but whereas @xmath51 is a function of all the data , @xmath50 is a function of only the data for a single unit . ]",
    "so , @xmath48 , @xmath49 and @xmath47 denote the data , the missingness pattern and the observed data , respectively , for the @xmath52th of @xmath12 units .",
    "consider a hypothesised model for the conditional distribution of @xmath49 given @xmath48 , and let @xmath53 denote the probability that @xmath54 given that @xmath55 according to the model .",
    "in this case , definitions  [ defin2 ] and  [ defin3 ] are equivalent .",
    "[ defin3 ] the data are everywhere mar if @xmath56 , @xmath57    definition  [ defin3 ] may only be applied when @xmath58 are i.i.d . if , for example , @xmath59 were i.i.d .",
    "and @xmath60 were identically distributed but with @xmath49 depending on @xmath61 and/or @xmath62 for @xmath63 , then @xmath64 would not be i.i.d . and",
    "so definition  [ defin3 ] could not apply .",
    "the data might nevertheless still be everywhere mar by definition  [ defin2 ] .",
    "finally , we present two definitions of mcar .",
    "[ defin4 ] the data are realised mcarif  @xmath28 , @xmath65    [ defin5 ] the data are everywhere mcar if  @xmath28 , @xmath66    realised mcar means that the probability of the realised missingness pattern given the data does not depend on the data .",
    "realised mcar implies realised mar but not everywhere mar .",
    "everywhere mcar means that the probability of _ any _ missingness pattern given the data does not depend on the data , that is , @xmath1 is independent of @xmath0 .",
    "everywhere mcar implies realised mcar , realised mar and everywhere mar .",
    "historically , the first definition of mar was that of rubin ( 1976 )  @xcite .",
    "this is definition  [ defin1 ] , that is , the definition for realised mar ( apart from minor differences in notation and the fact that rubin s definition begins `` the missing data are mar '' rather than `` the data are mar '' ) .",
    "rubin ( 1987 )  @xcite largely avoided the term `` mar '' , preferring instead theterms `` ignorable sampling '' and `` ignorable response '' .",
    "however , he did ( page 53 ) briefly discuss the relation between these three terms .",
    "it is evident from that discussion that he was using the rubin ( 1976 )  @xcite definition .",
    "heitjan and colleagues , in a series of papers ( e.g. , @xcite ) , consistently used `` mar '' tomean realised mar . harel and",
    "schafer  @xcite also defined realised mar .",
    "most other authors have used `` mar '' to mean everywhere mar .",
    "several authors ( schafer  @xcite ; kenward and molenberghs  @xcite ; lu and copas  @xcite ; jaeger  @xcite ) provided definitions of everywhere mar but accompanied this definition with a citation of rubin ( 1976 ) @xcite ( which defines realised , rather than everywhere , mar ) .",
    "in fact , most of these authors said explicitly that their definition was an expression of rubin s ( 1976 )  @xcite definition .",
    "the potential of the variety of definitions of mar to cause confusion was illustrated by an exchange of letters between heitjan  @xcite and diggle  @xcite . note that according to rubin s ( 1976 )  @xcite definition ( i.e. , realised mar ) , if all the data are observed , they can not fail to be mar ( although one might alternatively say that his definition is a statement about _ the missing data _ and in this situation there are no missing data , so there are no missing data to be mar ) .",
    "heitjan gave an example in which a single variable @xmath14 is measured on @xmath12 individuals and could potentially be missing on some of these individuals .",
    "however , he supposed that in the data set actually observed , @xmath14 is observed on all @xmath12 individuals , so there are no missing data .",
    "he stated that the data are mar .",
    "diggle responded by saying that the data are not mar , since the probability that @xmath14 is observed depends on @xmath14 , which could be missing .",
    "the reason for this disagreement is that heitjan was using the definition of realised mar whereas diggle was using that of everywhere mar .",
    "in addition to the problems caused by this dual use of the term `` mar '' , definitions of mar found in some of the key literature on missing data , including textbooks , contain certain ambiguities .",
    "many authors ( little and rubin  @xcite ; schafer  @xcite ; kenward and molenberghs  @xcite ; harel and schafer  @xcite ; fitzmaurice et al .",
    "@xcite ) used the problematic notation @xmath6 and @xmath7 mentioned in section  [ sectmydefinitions ] .",
    "little and rubin @xcite , for example , said that @xmath6 denotes the observed components or entries of @xmath0 , that @xmath7 denotes the missing components , and that the missing data mechanism is called mar if @xmath67 [ where @xmath68 denotes a conditional distribution ] .",
    "the notation @xmath69 is somewhat confusing , because @xmath6 is itself a function of @xmath1 .",
    "interpreted literally , @xmath70 .",
    "hence , if @xmath6 is known , then @xmath4 is also known , and so @xmath69 should equal zero unless the number of nonzero elements of @xmath1 equals  @xmath4 . nevertheless , we presume that equation ( [ eqmarrubin2002 ] ) was intended to mean definition  [ defin2 ] ( i.e. , everywhere mar ) .",
    "fitzmaurice et al .",
    "@xcite gave a definition similar to equation ( [ eqmarrubin2002 ] ) , but added that this means @xmath1 is conditionally independent of @xmath7 given @xmath6 .",
    "this is rather difficult to interpret , given that @xmath7 is a function of @xmath1 .",
    "another source of ambiguity concerns the parameter @xmath27",
    ". definitions  [ defin1][defin3 ] require a particular equality to hold for all values of @xmath27 .",
    "several authors ( robins and gill  @xcite ; kenward and molenberghs  @xcite ; tsiatis  @xcite ; fitzmaurice et al .",
    "@xcite ) omitted the parameter @xmath27 when defining mar , with the result that it is not obvious whether equality is required to hold for all @xmath27 or just for its `` true '' value .",
    "schafer  @xcite did include @xmath27 , but was also unclear about whether equality must hold for all @xmath27 .",
    "judging from the use that these authors made of their mar assumptions , most of them seem implicitly to have meant that the equality should hold for all @xmath27 . however , fitzmaurice et al .",
    "@xcite seem to require equation ( [ eqmarrubin2002 ] ) to hold only for the true value of @xmath27 : they appear to be referring to the `` true '' missingness mechanism , rather than to a model for the missingness .",
    "we shall return to this point in section  [ sectdiscussion ] .    just as there can be ambiguity about @xmath27 , it is sometimes not entirely clear whether a definition of mar requires an equality to hold for all @xmath0 or just for @xmath0 compatible with @xmath71 .",
    "see , in particular , equation ( [ eqmarrubin2002 ] ) .",
    "we have concentrated on mar , but there is also ambiguity about the definition of mcar . in his original 1976 paper",
    "@xcite , rubin did not mentionmcar .",
    "he instead introduced the concept of the observed data being `` observed at random '' . the realisedmcar definition ( definition  [ defin4 ] ) is equivalent to the combination of the missing data being realised mar and the observed data being observed at random  @xcite ( see also little  @xcite ) .",
    "heitjan and colleagues have used `` mcar '' to mean realised mcar .",
    "many other authors ( e.g. , little and rubin  @xcite and @xcite ) have used `` mcar '' to mean everywhere mcar .",
    "in the situation of repeated - measures outcome data with fully observed covariates , molenberghs and kenward  @xcite used `` mcar '' to mean that missingness in the outcomes can not depend on the outcomes but can depend on the covariates .",
    "elsewhere this has been called `` covariate - dependent mcar ''  @xcite .",
    "in section  [ sectignorability ] we shall discuss ignorability .",
    "the definition of ignorability depends on the framework of inference adopted .",
    "here we review the distinctions between four types of inference : bayesian inference , direct - likelihood inference ( also known as pure - likelihood inference ) , general frequentist inference and frequentist likelihood inference . for simplicity of exposition",
    ", we describe inference when the data @xmath0 are fully observed . in section  [ sectignorability ]",
    "we describe the generalisation to incomplete data .    in bayesian and direct - likelihood inference a probability distribution function",
    "is specified for thedata  @xmath0 .",
    "this function involves a finite set of unknown parameters , @xmath72 .",
    "some of these are of interest and the aim is to make inference about their values ; others may be nuisance parameters .",
    "the likelihood is defined as any multiple of this probability distribution function where the multiplier does not depend on any of the parameters . whereas the probability distribution function is regarded as a function of the data with the values of the parameters considered fixed , the likelihood is regarded as a function of the parameters with the data considered fixed .    in direct - likelihood inference",
    "@xcite , the value of the parameters at which the likelihood is a maximum ( the maximum likelihood estimate ) is used as a point estimate and the ratio of the value of the likelihood at different parameter values is used to judge which parameter values are plausible .",
    "the normalised likelihood is defined as the likelihood divided by the value of the likelihood at the maximum likelihood estimate ( so that the normalised likelihood takes value one at the maximum likelihood estimate ) . when there is only one parameter , a likelihood interval is defined as the set of parameter values within which the values of the normalised likelihood are greater than some threshold .",
    "different thresholds have been proposed , for example , fisher  @xcite suggested @xmath73 and royall @xcite suggested @xmath74 .",
    "when there is more than one parameter , a likelihood interval for any one of them can be obtained by first eliminating the others .",
    "two commonly used ways to eliminate parameters are the profile likelihood method and the conditional likelihood method .",
    "suppose , without loss of generality , that @xmath75 , where @xmath76 are the parameters to be eliminated .",
    "the profile likelihood for @xmath77 is defined as the function obtained , for each possible value of @xmath77 , by fixing @xmath77 at that value and then maximising the likelihood for @xmath72 over the space of @xmath76 . in the profile likelihood method , a likelihood interval for @xmath77",
    "is calculated using the profile likelihood for @xmath77 in place of the likelihood for @xmath72 . in the conditional likelihood method ,",
    "a  conditional probability distribution function is specified for @xmath0 given a ( possibly vector ) function of @xmath0 .",
    "the resulting conditional likelihood contains fewer parameters than the unconditional likelihood , that is , that based on the unconditional probability distribution function for @xmath0 . if the conditional likelihood contains only @xmath77 , it can be used to construct a likelihood interval for @xmath77 .",
    "if it contains additional parameters , these can be eliminated using the profile likelihood method .",
    "there is no clear theoretical basis for choosing between the profile likelihood and conditional likelihood approaches , and each appear to have their merits for different situations .",
    "in bayesian inference , uncertainty about parameters is represented directly by probability models , requiring a prior distribution to be specified .",
    "the posterior distribution of the parameters is obtained by bayes theorem . for any of the parameters in the model ,",
    "the mean of its posterior distribution is typically used as a point estimate and @xmath78 used as an interval of uncertainty ( a credible interval ) , where @xmath79 and @xmath80 are the @xmath81th and @xmath82th centiles ( e.g. , 2.5th and 97.5th ) of that parameter s marginal posterior distribution .",
    "this interval is interpretable as meaning that the posterior probability that the parameter lies within @xmath83 is @xmath84 .",
    "the use of the marginal posterior distribution means that all other parameters are eliminated by integrating them out of the joint posterior distribution of all the parameters .    in direct - likelihood inference and bayesian inference as described above , only the realised value of @xmath0 is of interest ; there is no consideration of other values of @xmath0 that could have been realised but which were not .",
    "frequentist inference , on the other hand , is concerned with the ( hypothetical ) repeated sampling of @xmath0 and with the properties of inferential summaries such as point and interval estimates under this repeated sampling .",
    "it is only when repeated sampling is considered that the concepts of bias , standard error , efficiency , power and confidence interval become meaningful .",
    "the bias of an estimator of a parameter , for example , is defined as the difference between the mean of the sampling distribution of the estimator and the true value of the parameter ; the standard error is the standard deviation of the sampling distribution of the estimator ; a  confidence interval is an interval obtained using a rule that has a stated probability of producing an interval containing the true value of the parameter in a repeated sample",
    ". one important example of a rule for constructing confidence intervals is the rule used in direct - likelihood inference to construct likelihood intervals , that is , a likelihood interval becomes , in the framework of frequentist inference , a confidence interval .    in frequentist inference , a function @xmath85 of @xmath0 is chosen and its realised value , @xmath86 , is compared with the sampling distribution of @xmath85 , that is , the distribution of @xmath85 in repeated samples .",
    "this sampling distribution may be conditional on the realised value of a ( possibly vector ) function of @xmath0 .",
    "we distinguish between general frequentist inference , where @xmath85 can be any function of @xmath0 , and frequentist likelihood inference , where @xmath85 depends on @xmath0 only through the likelihood of @xmath0 .",
    "frequentist likelihood inference includes using the observed or expected information to estimate the standard error of the maximum likelihood estimator ( mle ) , using this mle and standard error to construct a confidence interval , using likelihood intervals as confidence intervals , and using likelihood - ratio , wald and score tests .",
    "frequentist likelihood inference is like direct - likelihood inference , in that it also uses the mle and likelihood intervals , but goes beyond it , in that it involves claims about the behaviour of the mle and likelihood intervals in repeated samples .",
    "frequentist likelihood inference is often referred to simply as `` likelihood inference '' .",
    "often even statisticians using bayesian methods are interested in frequentist properties of their estimators , for example , the bias of the posterior mean or the coverage of a credible interval @xcite .",
    "the distinction between direct - likelihood inference and frequentist likelihood inference has not always been made clear in the literature .",
    "for example , heitjan and rubin  @xcite and harel and schafer  @xcite referred to direct - likelihood inference simply as `` likelihood inference '' .",
    "molenberghs et al .",
    "@xcite appear to use the term `` direct - likelihood analysis '' when writing about repeated sample properties of the likelihood .",
    "also , the potential interest in frequentist properties of bayesian estimators has rarely been mentioned in the literature on missing data , except in the context of multiple imputation .",
    "in this section we clarify which missingness assumption suffices for the missingness mechanism to be ignorable for each of the types of inferences described in section  [ sectinferencetypes ] .",
    "intuitively , `` ignorable '' means that inferences obtained from a parametric model for the data alone are the same as inferences obtained from a joint model for the data and missingness mechanism . to serve as a workable definition , one needs to say what is meant by `` the same '' , and in the literature authors have not always been explicit on this point .",
    "we endeavour to be clear , but defer specification of our definitions to the relevant subsections below .",
    "consider a joint parametric model for the complete data @xmath0 and missingness pattern @xmath1 .",
    "let@xmath87 denote the joint distribution of @xmath0 and @xmath1 according to this model , and let @xmath88 denote the joint parameter space for @xmath89 .",
    "let @xmath9 and @xmath8 be a given realisation of @xmath0 and @xmath1 .",
    "let @xmath90 and @xmath91 be the parameter spaces for @xmath72 and @xmath27 , respectively , corresponding to the joint parameter space @xmath88 .",
    "following heitjan and basu  @xcite , we avoid measure - theoretic difficulties by assuming that @xmath92 is discrete . because in reality all data are measured to finite precision ,",
    "this assumption is not restrictive .",
    "reference to continuous distributions should be interpreted as meaning discrete distributions on a fine grid , and integrals can be interpreted as sums .",
    "the _ joint likelihood for @xmath89 _ is the function with domain @xmath88 given by @xmath93 where @xmath94 equals one if @xmath95 and zero otherwise .",
    "note that the integral here integrates out the missing data .",
    "the _ likelihood for @xmath72 ignoring the missing - data mechanism _ is the function with domain @xmath96 given by @xmath97 for any fixed @xmath98 , the _",
    "fixed-@xmath27 likelihood for @xmath72 _ is the function with domain @xmath99 given by @xmath100\\\\[-8pt ] & & { } \\cdot \\int f_{\\theta } ( \\mathbf y ) g_{\\phi } ( { \\tilde{\\mathbf m}}\\mid\\mathbf y ) r ( \\mathbf y , { \\tilde{\\mathbf y } } , { \\tilde{\\mathbf m } } ) \\,d \\mathbf y,\\nonumber\\end{aligned}\\ ] ] where @xmath101 equals one if @xmath102 and zero otherwise . the _ profile likelihood for @xmath72",
    "_ is the function with domain @xmath96 given by @xmath103\\\\[-8pt ] & & \\hspace*{25.5pt}{}\\cdot\\int f_{\\theta } ( \\mathbf y ) g_{\\phi } ( { \\tilde{\\mathbf m}}\\mid\\mathbf y ) r(\\mathbf y , { \\tilde{\\mathbf y } } , { \\tilde{\\mathbf m } } ) \\,d \\mathbf y \\biggr].\\nonumber\\end{aligned}\\ ] ] in section  [ sectconditional ] we shall consider the use of conditional likelihoods .      the main work on ignorability for direct - likelihood inference can be summed up in the following theorem . after giving a proof",
    ", we shall discuss why this theorem has been considered to justify the use of @xmath104 , the likelihood for @xmath72 ignoring the missing - data mechanism , when the data are realised mar and the parameters are distinct .",
    "[ theo1 ] if realised mar holds and @xmath105 , then : @xmath106 factorises into two components , such that each parameter appears in only one component ; for any @xmath98 satisfying @xmath107 , @xmath108 is proportional to @xmath109 ; and if @xmath110 such that @xmath111 , then @xmath112 is a special case of @xmath108 and , hence , @xmath112 is proportional to @xmath109 .    as @xmath113",
    ", it follows that whenever @xmath98 and @xmath114 , then @xmath115 , and so @xmath116 .",
    "so , for @xmath98 and @xmath114 , @xmath117 where @xmath118 is a function of @xmath27 only . hence , ( i ) is true .",
    "note that line ( [ eqneedsmar1 ] ) follows because of realised mar .",
    "if realised mar holds and @xmath105 , line ( [ eqneedsmar1 ] ) is equal to @xmath119 . since @xmath120 is not a function of  @xmath72 , it then follows that @xmath108 is proportional to @xmath109 for any @xmath98 such that @xmath111 .",
    "so , ( ii ) is true .    likewise ,",
    "when the data are realised mar and @xmath121 , @xmath122 the function @xmath123 does not depend on  @xmath72 .",
    "moreover , it is nonzero when @xmath124 such that @xmath111 .",
    "so , @xmath125 , where @xmath126 is the value of @xmath27 that maximises @xmath120 .",
    "hence , ( iii ) is true .    in the literature , this factorisation of the joint likelihood and this proportionality of likelihoods have been used as a basis for defining when the missingness mechanism can be ignored when performing direct - likelihood inference .",
    "rubin  @xcite , for example , used the proportionality of likelihoods to write : `` when making direct - likelihood or bayesian inferences about @xmath72 , it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `` distinct '' from  @xmath72 '' .",
    "anscombe  @xcite wrote that when the joint likelihood for a parameter of interest @xmath72 and a nuisance parameter @xmath27 factorises into two components , such that each parameter appears in only one component , information on each factor can be considered separately .",
    "the same was written by hinde and aitkin  @xcite .",
    "royall  @xcite called the component involving @xmath72 the `` likelihood for @xmath72 '' and said that the relative support for any two values of @xmath72 is given by the ratio of the values of this likelihood evaluated at those two @xmath72 values .",
    "edwards  @xcite supported the use of the profile likelihood when the joint likelihood factorises .",
    "he wrote : `` since the value of @xmath27 is irrelevant to our inference on @xmath72 , replacing @xmath27 in [ the joint likelihood ] by its maximum likelihood estimate will not invalidate the likelihood '' .",
    "kalbfleisch and sprott  @xcite agreed with edwards . when comparing inference for @xmath72 using @xmath127 and @xmath104 in situations where the two may give different answers , heitjan @xcite , pages 1103 and 2249 , interpreted inference for @xmath72 using @xmath127 as meaning inference using the profile likelihood .",
    "tsou and royall  @xcite considered the strength of evidence in the presence of a nuisance parameter as being the strength of evidence that would be in the data if the value of the nuisance parameter were known .",
    "that is , they considered the strength of evidence to be the particular fixed-@xmath27 likelihood for @xmath72 corresponding to the true value of @xmath27 .",
    "all these authors , therefore , provide justification for interpreting theorem  [ theo1 ] as meaning that direct - likelihood inference about @xmath72 can be performed using @xmath104 when the data are realised mar and @xmath72 and @xmath27 are distinct parameters .    to picture the effect of realised mar and distinctness of parameters on the joint likelihood @xmath128 , it is helpful to consider a joint model where @xmath72 and @xmath27 are both scalar parameters .",
    "the graph of @xmath127 is then a surface in three dimensions lying above a @xmath129 plane .",
    "the realised mar condition imposes geometric structure on this surface [ evident from equations ( [ eqneedsmar1 ] ) and ( [ eqfactorises ] ) ] such that curves obtained from the surface by fixing @xmath130 at various values are all proportional , simply being copies of @xmath104 scaled by the conditional probability of realising the observed missingness pattern under the given @xmath27 value .",
    "the function @xmath127 is , however , only defined for values of @xmath131 in @xmath132 .",
    "hence , the curve formed from the @xmath127 by fixing @xmath27 may be undefined for some values of @xmath72 where the @xmath104 curve is defined .",
    "so , one can think of each curve formed from @xmath127 by fixing @xmath27 as being a proportional copy of @xmath104 with , potentially , one or more sections omitted .",
    "the assumption of distinct parameters ensures that such `` omitted '' sections do not exist , and therefore that the curves are proportional at all @xmath72 values in @xmath96 .",
    "so far , we have considered the elimination of @xmath27 as a nuisance parameter . as discussed in section  [ sectinferencetypes ] ,",
    "when a likelihood interval is required for a single element ,  @xmath77 , of a vector parameter , @xmath72 , the other parameters , @xmath76 , are also nuisance parameters and must be eliminated . if @xmath76 is eliminated from @xmath109 and @xmath112 using the profile likelihood method , the proportionality of @xmath112 and @xmath133 also ensures the proportionality of the profile likelihoods for @xmath77 derived from @xmath109 and @xmath112 .",
    "hence , the likelihood intervals for @xmath77 obtained from @xmath104 and @xmath134 will be the same .",
    "we discuss the use of conditional likelihood in section  [ sectconditional ] .      consider bayesian inference accounting for the missingness mechanism .",
    "let @xmath135 denote the joint prior distribution of @xmath89 and let @xmath136 denote the corresponding marginal prior distribution of @xmath72 .",
    "the missingness mechanism is said to be ignorable for bayesian inference if the marginal posterior distribution of @xmath72 obtained from modelling both the complete data , @xmath0 , and the missingness pattern , @xmath1 , is equal to the posterior for @xmath72 obtained by modelling @xmath0 alone .",
    "the main work in this area can be summed up by the following theorem .",
    "[ theo2 ] suppose that ( 1 ) the data are realised mar and ( 2 ) @xmath72 and @xmath27 are a priori independent .",
    "the posterior distribution of @xmath72 that results from using the likelihood @xmath109 and the prior @xmath137 is the same as the posterior distribution that results from using likelihood @xmath138 and prior @xmath135 .",
    "when @xmath106 and @xmath139 are used , the posterior distribution of @xmath89 is proportional to @xmath140 . if @xmath72 and @xmath27 are a priori independent , @xmath141 factorises as @xmath142 , where @xmath143 is the marginal prior for @xmath27 .",
    "if , furthermore , the data are realised mar , it follows from equation ( [ eqfactorises ] ) that the posterior distribution of @xmath89 is proportional to @xmath144 .",
    "since @xmath145 is a function of @xmath27 only , the marginal posterior distribution of @xmath72 is proportional to @xmath146 .",
    "this is the same posterior distribution that is obtained if @xmath133 and @xmath136 are used .      from the joint model , for any @xmath98 for which @xmath147 such that @xmath148 , the conditional distribution of @xmath3 given @xmath31 is @xmath149\\\\[-8pt ] & & \\quad\\hspace*{0pt}{}\\big/\\int f_{\\theta } ( { \\mathbf u } ) g_{\\phi } ( { \\tilde{\\mathbf m}}\\mid { \\mathbf u } ) \\,d { \\mathbf u}.\\nonumber\\end{aligned}\\ ] ] in general , this distribution may depend on @xmath27 .",
    "let @xmath150 be a function of @xmath3 and @xmath1 .",
    "rubin  @xcite called the distribution of @xmath151 given @xmath152 implied by the distribution of @xmath153 given @xmath152 in expression ( [ eqconditionaldist ] ) the `` correct conditional sampling distribution '' of @xmath151 . in general , the distribution given by ( [ eqconditionaldist ] ) is not equal to @xmath154 and so , in general , the conditional distribution of @xmath3 given @xmath31 is not that given by expression ( [ eqmarginaldist ] ) . nevertheless , the latter distribution is the distribution that corresponds to likelihood @xmath109 .",
    "heitjan and basu  @xcite called the distribution of@xmath151 given @xmath31 implied by the distribution in ( [ eqmarginaldist ] ) the `` potentially incorrect sampling distribution '' of @xmath151 .",
    "[ theo3 ] when the data are realised mcar and @xmath147 such that @xmath148 , the potentially incorrect sampling distribution is equal to the correct conditional sampling distribution .",
    "if the data are realised mcar , then for each value of @xmath27 the value of @xmath155 does not depend on @xmath30 .",
    "hence , expression ( [ eqconditionaldist ] ) reduces to expression  ( [ eqmarginaldist ] ) .    note",
    "that in theorem  [ theo3 ] repeated sampling is conditional on the realised missingness pattern , that is , conditional on @xmath31 .",
    "little  @xcite argued that it is wrong to condition on @xmath31 , as @xmath1 is not an ancillary statistic for @xmath72 unless the stronger condition of everywhere mcar is satisfied .",
    "rubin  @xcite disagreed , saying that `` the usual definition of ancillary ( cox and hinkley  @xcite , page 35 ) is incorrect for inference about @xmath72 and should be modified to be conditional on the observed value of the ancillary statistic '' .",
    "heitjan  @xcite continued this discussion , introducing the concept of an observed ancillary statistic and agreeing with rubin s assertion that the missingness pattern can be conditioned upon when the data are realised mcar .",
    "as rubin noted , although theorem  [ theo3 ] might be regarded as a statement about when the missingness mechanism can be ignored , the realised missingness pattern itself is not ignored , because the repeated sampling is conditional on it .",
    "as mentioned in section  [ sectinferencetypes ] , repeated sampling may be conditional on a function of @xmath0 .",
    "we discuss this in section  [ sectconditional ] .",
    "since frequentist likelihood inference is a special case of general frequentist inference , theorem  [ theo3 ] still applies .",
    "however , for frequentist likelihood inference a further result can be obtained when the data are everywhere mar and @xmath72 and @xmath27 are distinct .",
    "when the data are not realised mcar , @xmath1 is not observed ancillary , and so repeated sampling should not be conditional on @xmath1 .",
    "however , if the data are everywhere mar and @xmath156 , it follows from theorem  [ theo1 ] that @xmath109 , @xmath108 and @xmath112 are proportional not only in the realised sample but also in repeated samples .",
    "therefore , the mle of @xmath72 , the estimated variance of this mle calculated from the observed information matrix , likelihood intervals for  @xmath72 , and likelihood - ratio , wald and score test statistics for hypotheses concerning @xmath72 will be the same in both the realised and repeated samples whether calculated using @xmath104 or @xmath127 .",
    "that is , the same frequentist likelihood inference for @xmath72 will be made whether one uses @xmath104 or @xmath127 .",
    "a similar result applies for bayesian point estimators and credible intervals .",
    "suppose that the data are everywhere mar and , for every possible data vector @xmath0 and missingness pattern @xmath1 , the prior for @xmath89 in the joint model can be written as @xmath157 , where @xmath137 is the prior for @xmath72 in the model that ignores the missingness pattern .",
    "then , for every possible @xmath158 , the posterior distribution for @xmath72 derived from the likelihood @xmath127 and prior @xmath159 of the joint model is the same as that derived from the likelihood @xmath104 and prior @xmath137 of the model that ignores the missingness pattern .",
    "consequently , under these assumptions , the repeated - sampling properties of bayesian point estimators and credible intervals for @xmath72 in repeated samples will be the same whether one uses @xmath127 and @xmath160 and integrates over @xmath27 or one uses @xmath104 and @xmath137 .",
    "one important caveat needs to be stated .",
    "standard errors can , in general , be calculated using either the expected or the observed information .",
    "when the data are everywhere mar and @xmath72 and @xmath27 are distinct , the expected information from @xmath104 should not be used naively  @xcite .",
    "using this expected information is only appropriate under the stronger assumption that the data are everywhere mcar .",
    "it is recommended that the observed information be used instead @xcite .",
    "we now consider ( 1 ) conditional likelihoods and ( 2 ) repeated sampling conditional not only on @xmath31 but also on some function of @xmath0 .",
    "let @xmath161 denote the function of @xmath0 being conditioned on and @xmath162 denote the realised value of @xmath163 .    first , consider the use of conditional likelihood .",
    "one example of the use of a conditional likelihood is where data @xmath0 consist of a set of covariates and an outcome for a sample of individuals and this outcome is regressed on the covariates .",
    "when the covariates are fully observed , there is no need to specify a likelihood for all of @xmath0 ; instead , a likelihood for the outcomes conditional on the covariates is sufficient . here , @xmath163 consists of the covariates .",
    "a  second example is conditional logistic regression for matched case - control data , where the likelihood is conditional on the number of cases and controls in each matched set .",
    "so here , @xmath163 consists of these numbers of cases and controls .",
    "assume that either @xmath162 is observed or @xmath164 does not depend on the value of the missing part of @xmath162 . in equations ( [ eql1])([eql4 ] ) ,",
    "@xmath165 should be replaced by @xmath166 , the conditional probability distribution of @xmath0 given @xmath167 .",
    "theorem  [ theo1 ] then still applies . moreover , if the data are everywhere mar , then @xmath109 and @xmath112 [ both with @xmath165 replaced by @xmath168 will be proportional not only in the realised sample but also in repeated samples .",
    "note that this repeated sampling is conditional on @xmath169 but not on @xmath31 .",
    "second , consider repeated sampling conditional on @xmath169 and @xmath31 .",
    "assume that either @xmath162 is observed or the distribution of @xmath170 , given @xmath31 and @xmath171 implied by the distribution @xmath172 , does not depend on the value of the missing part of @xmath162 .",
    "in equations ( [ eql1])([eql4 ] ) and ( [ eqmarginaldist ] ) , @xmath165 should be replaced by @xmath173 , and @xmath174 in equation ( [ eqconditionaldist ] ) should be replaced by @xmath175 .",
    "theorem  [ theo3 ] then continues to apply if `` @xmath176 '' is replaced by `` @xmath177 and @xmath178 '' .",
    "moreover , the realised mcar condition in theorem  [ theo3 ] can be replaced by the following weaker condition : @xmath28 , @xmath34 @xmath35 such that @xmath179 . in the special case of repeated - measures data with fully observed covariates and @xmath163 being these covariates ,",
    "the everywhere version of this weaker condition has been called``covariate - dependent mcar '' @xcite .",
    "in this article we have highlighted inconsistencies in the use of the terms `` missing at random '' and `` likelihood inference '' , and clarified the conditions required for ignorability of the missingness mechanism .",
    "we urge those writing about missing data to be clearer with respect to the assumptions being used and to employ clear terminology when describing approaches to inference , in particular , to make the distinction between direct - likelihood and frequentist likelihood concepts .",
    "rubin  @xcite used the term `` ignorable '' to mean that two likelihoods , one derived from a model for the data alone and one derived from a joint model for the data and the missingness pattern , are proportional or that two sampling distributions , the `` potentially incorrect '' and correct conditional distributions , are equal . in section  [ sectignorability ]",
    "we explained how this implies that certain inferences for @xmath72 from the two models are the same . in this interpretation , ignorability is a property of the _ assumed _ missingness model .",
    "whether this assumed model is correctly specified is not relevant .",
    "this interpretation of `` ignorability '' may not be universal , however .",
    "as we saw in section  [ sectreview ] , some writers have omitted the parameter @xmath27 from their definition of mar . rather than refer to a model for the missingness mechanism , they appear to have been referring to the `` true '' missingness mechanism ( which is usually unknown ) .",
    "such writers may have interpreted ignorability to mean that using @xmath133 for frequentist likelihood ( or frequentist bayesian ) inference will be valid , that is , will yield consistent mles ( or posterior modes ) , consistent variance estimators , confidence ( or credible ) intervals with asymptotic nominal coverage , etc .",
    "theorem  [ theo1 ] implies the following result .",
    "suppose that the `` true '' missingness mechanism is @xmath180 and that @xmath181 @xmath182 such that @xmath183 . a  hypothetical analyst who knew this `` true '' missingness mechanism and wanted to make inference for @xmath72 taking missingness into account would use the likelihood @xmath184 and , by so doing , obtain valid frequentist likelihood ( or frequentist bayesian ) inference .",
    "theorem  [ theo1 ] implies that @xmath109 is proportional to this likelihood , and hence that valid frequentist likelihood ( or frequentist bayesian ) inference would also be obtained using  @xmath104 . despite mar plus distinctness of parameters being presented in little and rubin  @xcite as the definition of ignorability ( definition 6.4 ) , theorems",
    "[ theo1 ] and  [ theo2 ] only give _ sufficient _ conditions for when it is appropriate to ignore the missingness mechanism when making direct - likelihood and bayesian inferences , respectively . in the case of direct - likelihood inference ,",
    "theorem  [ theo1 ] is concerned with sufficient conditions for @xmath108 , the fixed-@xmath27 likelihood for @xmath72 , to be proportional to @xmath109 , the likelihood for @xmath72 ignoring the missing data mechanism .",
    "it is conceivable that , even in the absence of realised mar , there may be a restricted set of @xmath27 values for which @xmath185 is proportional to @xmath186 , and for this restricted set to contain the `` true '' @xmath27 value .",
    "if so , it would be appropriate to ignore the missingness mechanism even though realised mar does not hold .",
    "lu and copas  @xcite showed that , when @xmath72 and @xmath27 are distinct _ and _ the family of distributions @xmath187 form a complete class , everywhere mar is necessary and sufficient for ignorability in frequentist likelihood inference .",
    "it is straightforward to adapt their proof to show that when @xmath72 and @xmath27 are distinct and the family of distributions @xmath188 form a complete class , then realised mar is necessary and sufficient for ignorability in direct likelihood inference ( we include a proof in the ) .",
    "furthermore , there may conceivably be other ways , apart from that of using a fixed-@xmath27 likelihood , to extract a likelihood for @xmath72 from @xmath127 , ways which may not require realised mar and parameter distinctness in order for the extracted likelihood to be proportional to @xmath104 . in the case of theorem  [ theo2 ] , it is conceivable that independence of the posterior distributions for @xmath72 and @xmath27 may be a stronger condition than is necessary , and it seems to still be an open question whether there are substantially weaker conditions under which it is appropriate to ignore the missingness mechanism when performing bayesian inference .",
    "note that the concept of missing data has been generalised to that of `` coarsened '' data  @xcite .",
    "when data are coarsened , data values are not necessarily either observed or missing , instead one observes a set of values that is known to contain the realised values . censored survival data",
    "are an example of coarsened data : a survival time may be known to be greater than a given ( censoring ) time but not known exactly .",
    "we conclude with some brief remarks on the potential practical implications of this work . our review of the literature on the theory of missing data methods has highlighted a number of inconsistencies and a lack of clarity with respect to key definitions such as mar and ignorability .",
    "we believe that these issues have clouded the development and broader understanding of methods in this area , partly because they intersect in considerable measure with issues in the foundations of statistical inference .",
    "although the original definition of mar ( our `` realised mar '' ) provides a clear basis for thinking about direct likelihood and bayesian inferences , the majority of statistical practice is concerned with frequentist evaluations .",
    "even those who emphasise the bayesian interpretation of particular analyses are generally interested in repeated - sampling performance of procedures .",
    "incomplete data methods that do not explicitly model the missing data mechanism ( i.e. , that assume ignorability ) can not be guaranteed to perform validly in repeated samples except under an `` everywhere '' mar assumption .",
    "the restrictiveness of this assumption does not seem to be well understood , especially in complex problems with nonmonotone patterns of missingness  @xcite .",
    "more importantly , further work is needed on methods to more effectively and systematically characterise the potential sensitivity of inferences to departures from the mar assumption .",
    "meanwhile , users of missing data methods need to be reminded that methods that assume ignorability provide tractable analyses only at the cost of untestable assumptions .",
    "it is also important to consider that when there are missing data , there is more than one possible target of inference .",
    "diggle et al .",
    "@xcite discuss alternative possible study objectives and targets of inference that are relevant to those objectives .",
    "much recent research in methods for handling missing data has considered issues that are specific to the structure of the problem .",
    "for example , missingness in outcomes poses different challenges than does missingness in covariate values , and longitudinal ( repeated measures ) data present specific issues of their own .",
    "we believe that it should be possible to tackle these problems with greater clarity if the fundamental assumptions about missing data mechanisms and their connection with the concept of ignorability are better understood .",
    "here we show that when @xmath72 and @xmath27 are distinct and the family of distributions @xmath188 form a complete class , then realised mar is necessary and sufficient for ignorability .",
    "let @xmath189 denote the subvector of @xmath0 consisting of the elements whose corresponding elements of @xmath1 equal zero .",
    "so , @xmath190 contains the missing elements of @xmath0 . for any fixed value @xmath191 of @xmath1 ,",
    "@xmath165 can be written as    @xmath192    thus , choosing @xmath193 in equation ( [ eqfactorisewithm ] ) , @xmath127 can be written as @xmath194 and @xmath104 can be written as @xmath195 .",
    "suppose that @xmath196 , that @xmath197 is complete , and that @xmath198 for all @xmath98 .",
    "then @xmath106 is proportional to @xmath109 for any @xmath98 if and only if realised mar holds .",
    "the `` if '' argument holds because of theorem  [ theo1 ] .",
    "so , consider the `` only if '' argument .",
    "suppose that @xmath106 is proportional to @xmath109 for any @xmath98",
    ". then it must be true that for all @xmath98 , @xmath199 can not depend on @xmath72 .",
    "hence , we can denote expression ( [ eqqdefinition ] ) as @xmath200 .    by definition ,",
    "@xmath201 so , @xmath202 for all @xmath98 .",
    "it then follows that @xmath203 r(\\mathbf y , { \\tilde{\\mathbf y } } , { \\tilde{\\mathbf m } } ) \\,d \\mathbf y = 0\\end{aligned}\\ ] ] for all @xmath98 .",
    "so , if @xmath204 is complete , then @xmath205 for all @xmath206 and for all @xmath207 such that @xmath208 .",
    "therefore , @xmath155 can not depend on @xmath209 , that is , the data are realised mar .",
    "we thank professor mike kenward for very useful discussions and for comments on a draft manuscript , and anonymous reviewers for their helpful suggestions .",
    "s. r. seaman is funded by mrc grants u1052 60558 and mc_us_a030_0015 .",
    "d. jackson is funded by u1052 60558 .",
    "j. b. carlin and j. c. galati wish to acknowledge the support of research grant 607400 from the australian national health and medical research council , and support provided to the mcri from the victorian government s operational infrastructure support program ."
  ],
  "abstract_text": [
    "<S> the concept of missing at random is central in the literature on statistical analysis with missing data . in general , inference using incomplete data </S>",
    "<S> should be based not only on observed data values but should also take account of the pattern of missing values . </S>",
    "<S> however , it is often said that if data are missing at random , valid inference using likelihood approaches ( including bayesian ) can be obtained ignoring the missingness mechanism . </S>",
    "<S> unfortunately , the term `` missing at random '' has been used inconsistently and not always clearly ; there has also been a lack of clarity around the meaning of `` valid inference using likelihood '' . </S>",
    "<S> these issues have created potential for confusion about the exact conditions under which the missingness mechanism can be ignored , and perhaps fed confusion around the meaning of `` analysis ignoring the missingness mechanism '' . here </S>",
    "<S> we provide standardised precise definitions of `` missing at random '' and `` missing completely at random '' , in order to promote unification of the theory . using these definitions </S>",
    "<S> we clarify the conditions that suffice for `` valid inference '' to be obtained under a variety of inferential paradigms .    ,    , </S>"
  ]
}