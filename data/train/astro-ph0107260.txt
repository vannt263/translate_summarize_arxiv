{
  "article_text": [
    "the detection of neutrinos from supernova sn 1987a in the large magellanic cloud by the kamiokande ii ( kii ) @xcite irvine - michigan - brookhaven ( imb ) @xcite and baksan @xcite detectors was a landmark event in astrophysics .",
    "although only about two dozen of the @xmath3 supernova neutrinos that passed through the earth were detected , they provide us with our first glimpse of the collapsing core of a dying star , and hence deserve careful scrutiny .",
    "there is an extensive literature analyzing these epochal detections , both qualitatively and quantitatively .",
    "these previous studies use a wide variety of methods , and although there is some agreement among their conclusions , there are also important and troubling differences . unfortunately",
    ", no criteria have been presented with which one could evaluate and compare the various studies .",
    "in addition , there are technical deficiencies in many of the studies , including inaccurate modeling of the detection process , and consideration of unnecessarily restricted classes of models for the neutrino signal .",
    "a consequence of these weaknesses is that the literature analyzing the supernova neutrinos appears inconclusive or even contradictory .",
    "some would argue that this is an inevitable consequence of the analysis of a sparse data set .",
    "we assert that it is a consequence only of weaknesses in the analyses , and that probability theory is able to precisely and consistently quantify the information in a data set , even when the data set is small . indeed , it is in just such cases that a careful quantification of our uncertainty is most necessary .",
    "the years since the detection of the supernova neutrinos have seen significant advances in our understanding of the supernova mechanism and in our ability to analyze sparse data . in 1987 , the prompt scenario for supernovae was favored , and almost all of the most sophisticated analyses of the sn 1987a neutrino data used models based on this scenario .",
    "but in the intervening years , more careful calculations have shown that the prompt mechanism probably fails to create explosions , and that the delayed mechanism  relatively new in 1987is more likely to be the cause of supernova explosions . through the same decade",
    "there has been a parallel development in the application of likelihood and bayesian methods to the analysis of inhomogeneous poisson processes in astrophysics .",
    "these theoretical and analytical advances motivated us to undertake a new analysis of the supernova neutrinos that significantly improves on previous analyses both in its statistical methodology and in the variety of models considered .",
    "our methodological improvements stem from consistent and straightforward application of the principles of bayesian inference . the likelihood function  the probability for the data given some hypothesis for their origin  plays a key role in bayesian inference , so aspects of our analysis bear some similarity to earlier analyses based on likelihood functions that used more conventional `` frequentist '' techniques , such as our own earlier work @xcite .",
    "but there are crucial differences both in the form of the likelihood function we use , and in the manner in which we use it to make inferences .",
    "our derivation of the likelihood function reveals errors in previous attempts to account for the energy dependence of the efficiencies of the neutrino detectors ; we show that these errors significantly corrupted previous inferences .",
    "in addition , our likelihood accounts for the possibility that each event could have arisen from background sources by using empirically measured detector background spectra .",
    "previous studies either ignored the detector background , or tried to account for its effects by censoring the data . we show that correct treatment of the background is crucial for proper analysis of the baksan data , and that it noticeably affects the implications of the kii data .",
    "additionally , we include the effects of dead time in the imb detector , which has also been ignored in most previous analyses .",
    "once the likelihood is available , bayesian calculations use it in a different manner than frequentist likelihood analyses .",
    "in particular , the bayesian methodology allows us to accurately summarize the implications of the data for interesting subsets of the parameters needed to model the data , in a way that fully accounts for the strong correlations between inferred values of neutrino emission model parameters .",
    "these correlations must be taken into account in order to fully compare the implications of the data with the predictions of theory .",
    "also , bayesian model comparison implements an automatic `` ockham s razor '' that takes into account model complexity when comparing rival signal models ; this assures that complicated models are preferred only when there is significant evidence in the data favoring them .    complementing these methodological improvements are the improved scientific insights gained by our use of a much wider variety of neutrino emission models than was explored previously .",
    "earlier studies explored either a single model or an unnecessarily restricted class of models , almost always presuming the prompt supernova mechanism to be true .",
    "we explore a variety of single - component models designed to mimic neutrino emission from a cooling nascent neutron star ( the principle detectable component in the prompt scenario ) , and a variety of two - component models that add to this cooling emission a component arising from material that is heated upon passing through the stalled accretion shock expected in delayed scenarios for supernova explosions .",
    "we find that all single component models lead to unacceptably large inferred neutron star radii and binding energies .",
    "we further show that the data unambiguously prefer two component models , and that such models lead to quite reasonable inferred radii and binding energies for the nascent neutron star .",
    "the wide variety of models we consider insures that our conclusions are robust .",
    "this paper is organized as follows .",
    "we begin with a brief review of bayesian inference in sec .",
    "[ sec : bayes ] .",
    "we then devote two sections to the derivation of the likelihood function .",
    "[ sec : dtxn]derives the probability for data from a neutrino detector , given some parameterized form for the production rate of energetic charged leptons in the detector ; some details of the derivation appear in appendix  a. sec .",
    "[ sec : lepton ]  describes how we derive the lepton production rate from general models for the emission of neutrinos from the supernova and their eventual interaction with earthbound detectors .    in sec .",
    "[ sec : models ]  we describe the wide variety of parameterized models we have analyzed . included among these are phenomenological models based on both the prompt and delayed mechanisms for supernovae .",
    "we present the best fit parameter values for each model in sec .",
    "[ sec : results ] , and we compare the models to one another in light of the data , finding a definite preference for two - component models .",
    "the most tenable of the single - component models is one with an exponentially decaying neutrinosphere temperature at a constant radius ; this model is also the one most extensively studied in earlier analyses . in sec .",
    "[ sec : exp ]  we analyze this single - component model in greater detail .",
    "we present joint credible regions for the model parameters that display the strong correlations between parameters , and that reveal an inconsistency between the neutron star radius and binding energy implied by this model and those predicted by current equations of state for neutron star matter . in sec .",
    "[ sec : acn ]  we analyze the best two - component model in greater detail .",
    "we find the constraints implied by the data on parameters describing both the cooling and accretion components of the emission , and we demonstrate the consistency between the neutron star properties implied by this model and those predicted by current equations of state . in sec .  [",
    "sec : theory ]  we provide a brief review of theoretical expectations for neutrino emission during and immediately after stellar collapse , and compare these expectations with the observed characteristics of the emission .    in the analyses presented in sec .",
    "[ sec : results ]  through sec .",
    "[ sec : theory ] , we assume that the rest mass of the electron antineutrino , @xmath4 , is zero . in sec .",
    "[ sec : mass ]  we treat @xmath4 as an additional parameter to be inferred .",
    "we find no significant evidence for a nonzero mass , and we determine the upper limits implied by single - component and two - component signal models .    throughout the text we note technical differences between our work and earlier work , particularly in regard to the form of the likelihood function and the detector model . in sec .",
    "[ sec : comp ]  we elaborate on some of the weaknesses of earlier work , including our own earlier frequentist likelihood analysis @xcite .",
    "we summarize our principle conclusions in sec .",
    "[ sec : conc ] .",
    "we carefully distinguish between the problems of ( 1 ) estimating the value of parameters in a model for the neutrino signal , and ( 2 ) assessing the adequacy of a particular parameterized model .",
    "a major weakness of most previous analyses of the supernova signal is the failure of investigators to distinguish between these complementary statistical tasks , leading many to use model assessment methods incorrectly to calculate `` confidence regions '' for parameters .",
    "we address both parameter estimation and model assessment problems with bayesian methods . in bayesian inference ,",
    "the viability of each member of a set of rival hypotheses , @xmath5 , is assessed in the light of some observed data , @xmath6 , by calculating the probability for each hypothesis , given the data and any background information , @xmath7 , we may have regarding the hypotheses and data . following a notation introduced by jeffreys @xcite ,",
    "we write such a probability as @xmath8 , explicitly denoting the background information by the proposition , @xmath7 , to the right of the bar . at the very least",
    ", the background information must specify the class of alternative hypotheses being considered , and the relationship between the hypotheses and the data ( the statistical model ) . in cases where the hypotheses of interest are labeled by the possible values of a continuous parameter , @xmath9 , the quantity @xmath10 is a probability _ density _ : @xmath11 is the probability that the true value of the parameter is in the interval @xmath12 $ ] , given the data and the background information .",
    "we use the same symbol , @xmath13 , for densities and probabilities ; the nature of the argument will identify which use is intended .",
    "bayes s theorem gives @xmath8 in terms of other probabilities , @xmath14 the probabilities @xmath15 for the hypotheses in the absence of @xmath6 are called their prior probabilities , and the probabilities @xmath8 including the information @xmath6 are called their posterior probabilities . the quantity @xmath16",
    "is called the sampling probability for @xmath6 , or the likelihood for @xmath17 , and the quantity @xmath18 is called the prior predictive probability for @xmath6 , or the ( global ) likelihood for the entire class of hypotheses .    the rules of bayesian inference lead one to use bayes s theorem both to estimate signal parameters and to assess a model as a whole by comparing it to rival models .",
    "but different types of calculations are required to implement these two complementary tasks . in this section",
    "we describe these applications of bayes s theorem , which we use freely throughout the remainder of this work ; bayesian model comparison in particular has so far seen little use in physics , motivating this brief pedagogical introduction .",
    "we also briefly describe the computational techniques we use to implement the calculations .",
    "more complete derivations of the results in this section , with simple examples and further references , are available in recent reviews @xcite .",
    "the _ bayesian inference in the physical sciences _ web site @xcite provides access to a variety of reviews and tutorials .",
    "many readers may be familiar with the use of bayes s theorem to estimate parameters in a model . given some proposition , @xmath19 , specifying a model with parameters denoted collectively by @xmath9 , and a proposition , @xmath6 , specifying data relevant to the model , one calculates the posterior distribution for the parameters , @xmath20 , according to the continuous version of equation  ( [ bt ] ) , @xmath21 of the factors in this equation , the likelihood function , @xmath22 , is probably the most familiar .",
    "it is the probability for the _ data _ , assuming the parameters have values given by @xmath9 .",
    "we often denote the likelihood by the symbol @xmath23 ; this notation emphasizes that its dependence on the parameters is what is important in bayes s theorem , but that it is not by itself a probability for the parameters .",
    "the remaining terms in equation  ( [ bt - param ] )  are the prior for @xmath9 and the prior predictive probability . for the most part , in this work",
    "we adopt uniform ( constant ) priors for all parameters .",
    "when the data are informative , the posterior is robust to changes in the prior ; we note those cases where the data are uninformative as they arise .",
    "the prior predictive , @xmath24 , is independent of @xmath9 and merely plays the role of a normalization constant whose value is given by integrating the product of the prior and the likelihood : @xmath25 thus the essential content of equation  ( [ bt - param ] )  may be summarized by the statement that the posterior density is proportional to the product of the prior and the likelihood .",
    "frequently a parameterized model will have more than one parameter , but we will want to focus attention on a subset of the parameters .",
    "for example , at one point in this work we will want to focus on the implications of the data for the binding energy and radius of the neutron star formed by the supernova , independent of the remaining parameters describing the neutrino signal .",
    "the uninteresting parameters are known as _ nuisance parameters_. the posterior distribution for the parameters of interest can be calculated by integrating out the nuisance parameters .",
    "explicitly , if model @xmath19 has two parameters , @xmath9 and @xmath26 , and we are interested only in @xmath9 , then it is a simple consequence of the sum and product rules of probability theory that , @xmath27 the procedure of integrating out nuisance parameters is called _ marginalization _ , and @xmath28 is called the marginal posterior distribution for @xmath9 . in frequentist statistics",
    "there is no generally acceptable way to eliminate nuisance parameters .",
    "the ability to marginalize parameters is thus an important advantage of the bayesian approach .",
    "the bayesian solution to the parameter estimation problem is the full distribution , @xmath28 , and not just a single point in parameter space . of course",
    ", it is often useful to summarize this distribution for textual , graphical , or tabular display in terms of a `` best - fit '' value and `` error bars , '' indicating the location and width of the posterior .",
    "possible choices of summarizing best - fit values are the posterior mode ( the value of @xmath9 with largest posterior density ) or the posterior mean , @xmath29 . if the mode and mean are very different , the posterior distribution is probably too complicated for its location to be adequately summarized by a single number .",
    "an allowed range for a parameter with probability content @xmath30 is provided by a _ credible region _ , @xmath31 , defined so that @xmath32 if @xmath31 is chosen so that the posterior density inside @xmath31 is everywhere greater than that outside it , then @xmath31 is a highest posterior density ( hpd ) credible region ; all of the credible regions we display in this work are hpd credible regions .",
    "( credible regions are not called `` confidence regions '' to distinguish them from frequentist confidence regions , which are calculated in a very different manner @xcite . )    in this work we present as a best - fit summary the posterior mode .",
    "since we are using flat priors , these estimates are identical to those a frequentist maximum likelihood analysis would produce .",
    "but bayesian and frequentist uses of the likelihood for finding allowed regions differ ( especially when nuisance parameters are present ) , so more complete summaries ( , credible regions ) will differ from their frequentist counterparts . to find the credible regions reported in this work , we use _",
    "posterior sampling_the use of monte carlo methods to obtain a set of samples of parameter values from the full joint posterior .",
    "the `` cloud '' of such samples nicely summarizes the full posterior ; but more importantly , once the samples are available , any marginal distribution can be easily estimated by simple manipulations of the samples .",
    "for example , samples from the marginal distribution for any function of the parameters can be found simply by evaluating the function on the samples .",
    "a simple special case is when we seek samples from the marginal distribution for a subset of the parameters ; they can be found simply by ignoring the nuisance parameter coordinates of each sample from the full posterior .",
    "we obtain the samples using the rejection method @xcite , and for plotting smooth contours of one- and two - dimensional marginals we fit the cloud of points to simple parameterized functions ( exponentials of polynomials ) .",
    "loredo @xcite provides further discussion of posterior sampling and pointers to the literature .      in bayesian inference ,",
    "the success of a model is assessed by comparing it to explicit alternative models . to compare rival models",
    ", we again use bayes s theorem .",
    "this use of bayes s theorem is probably less familiar to most readers , though it is analogous to use of bayes s theorem for parameter estimation .",
    "we begin by specifying a set of competing models .",
    "we use the symbol @xmath33 to denote a proposition asserting that model @xmath34 describes the data , and the symbol @xmath7 to denote a proposition asserting that one of the models being considered describes the data ( @xmath35 or @xmath36 or @xmath37  ) .",
    "then we use bayes s theorem to calculate the probability for model @xmath33 , assuming that one of the models being considered describes the data : @xmath38 this is very much like equation  ( [ bt - param ] ) , with @xmath33 now playing the role of the parameter , and @xmath7 now playing the role of the model .",
    "the term @xmath39 is the prior probability for model @xmath33 .",
    "the proposition @xmath40 ( `` @xmath33 _ and _ @xmath7 '' ) is true if and only if model @xmath33 is true , that is , it is equivalent to the proposition @xmath33 itself .",
    "thus @xmath41 , the quantity calculated in equation  ( [ gl - def ] ) .",
    "this quantity plays the uninteresting role of a normalization constant in parameter estimation , but it plays a key role in model comparison : it is the likelihood for model @xmath33 in equation  ( [ bt - mod ] ) .",
    "equation  ( [ gl - def ] ) reveals the likelihood for a model to be equal to the _ average _ likelihood of its parameters ( averaged with respect to the prior for the parameters ) .",
    "this is in stark contrast to frequentist measures of model quality , which typically maximize rather than average the likelihood for the parameters . to help distinguish the likelihood for a model s parameters from the likelihood for the model as a whole",
    ", we use the term `` likelihood function '' ( a function of the parameters ) for the former , and `` model likelihood '' or `` average likelihood '' ( a single real number ) for the latter .",
    "it is sometimes more convenient to work with ratios of model probabilities , particularly when there is a special `` default '' model .",
    "the ratio of the probability for model @xmath33 to that for model @xmath42 is called the odds in favor of @xmath33 over @xmath42 .",
    "we denote it by @xmath43 . using bayes s theorem ,",
    "we can write the odds as @xmath44 where the first factor is the prior odds ratio , and the second factor is called the _",
    "bayes factor_. the bayes factor is simply the ratio of the likelihoods of the models .",
    "note that the normalization constant in equation  ( [ bt - mod ] ) , @xmath18 , drops out of the odds ratio .",
    "when the prior odds does not strongly favor one model over another , the bayes factor can be interpreted just as one would interpret an odds in betting ; table  [ table : b ] summarizes the interpretation recommended in the extensive review of bayes factors by kass and raftery @xcite .",
    "an important aspect of bayesian model comparison is that the calculation of model likelihoods implements an automatic and objective posterior `` ockham s razor , '' leading one to prefer simpler models unless the data provide substantial evidence in favor of a more complicated alternative , even when the rival models are assigned _ equal _ prior probabilities . in frequentist statistics ,",
    "one commonly uses ratios of maximum likelihoods to compare models . however ,",
    "more complicated models almost always have higher likelihoods than simpler models , so more complicated models are only accepted if the maximum likelihood ratio in their favor exceeds some subjectively specified critical amount , expressing a subjective _ prior _ preference for simplicity .",
    "but bayesian methods compare averaged likelihoods , not maximum likelihoods , and tend to favor simpler models even when simple and complicated models are assigned equal prior probabilities @xcite .",
    "we can better understand the distinction between bayesian and frequentist model comparison and the nature of the bayesian posterior preference for simplicity by writing the model likelihood as the product of the maximum parameter likelihood used in frequentist model comparison , and an additional _ ockham factor_. we thus implicitly define the ockham factor @xmath45 associated with the parameters @xmath9 of model @xmath19 by writing @xmath46 , where @xmath47 is the maximum value of the likelihood function , @xmath48 .",
    "recalling equation  ( [ gl - def ] )  for the average likelihood , this implies @xmath49 assuming , as is generally the case , that the prior varies slowly compared to the likelihood , the integral in this equation is approximately equal to @xmath50 , where @xmath51 is the maximum likelihood value of @xmath9 .",
    "if we write the integral of the likelihood function as the maximum likelihood value times a characteristic width of the likelihood , @xmath52 , we find that , @xmath53 we can write the value of the prior at @xmath51 as @xmath54 , where @xmath55 is a characteristic width of the prior ( if the prior is flat over some range of size @xmath55 , the approximation is exact ) . then we find that @xmath56 the ratio of the posterior range for the parameter to its prior range .",
    "this quantity will be less than one , and in this manner the ockham factor penalizes the maximum likelihood .",
    "this penalty generally grows with the number of parameters , and in this way model likelihoods implement a posterior preference for simpler models with fewer parameters , even when the models are considered equally probable a priori . in this way",
    "bayesian model comparison favors models that best predict the data , not only for the best - fit parameters ( which after all are known only a posteriori ) , but taking into account uncertainty in the parameters .",
    "it is worth emphasizing that these bayesian calculations provide probabilities for _ models _ ( or ratios of such probabilities ) , in contrast to the `` false alarm '' probabilities provided by conventional frequentist significance tests , which are probabilities for _ data _",
    "( i.e. , probabilities for data more extreme than observed ) .",
    "this fundamental difference leads to different interpretations for the probabilities these procedures report . in frequentist statistics , it is common to consider a departure from the null hypothesis at a 5% significance level to be barely significant .",
    "in contrast , if a bayesian calculation gives the null hypothesis a probability of 5% ( i.e. , a bayes factor of 19 against the null ) , this is considered quite significant evidence against the null ( see table  [ table : b ] ) .",
    "indeed , one often finds that a bayesian analysis of data discrepant at the 5% significance level produces a bayes factor of order unity ",
    "the bayesian calculation is confirming the conventional interpretation of this significance level by providing a quantity with a more straightforward and intuitive interpretation .",
    "sellke , bayarri , and berger @xcite provide further discussion of this issue , with guidelines for a bayesian interpretation of significance tests .",
    "the integrals needed to calculate average likelihoods for bayes factors are often challenging . in this work , we often use an asymptotic approximation to the bayes factor applicable when comparing two nested models ( i.e. , the simpler model corresponds to the more complicated one when additional parameters are set at default values ) .",
    "the approximation is known as the bayesian information criterion ( bic ) or the schwarz criterion @xcite .",
    "the bic uses a gaussian approximation for calculating average likelihoods , and an `` automatic '' prior with a width roughly corresponding to the width of the individual data factors in the likelihood .",
    "the result is that the log bayes factor can be approximated as @xmath57     - { 1\\over 2 } m_\\phi \\ln n,\\label{bic}\\ ] ] where model 2 is the more complicated model , with additional parameters @xmath26 , @xmath58 is the dimension of @xmath26 , and @xmath59 is the number of data .",
    "when the approximate results warrant interest in an accurate bayes factor , we use adaptive quadrature to calculate average likelihoods @xcite .",
    "the key ingredient in bayesian parameter estimation and model comparison is the likelihood function .",
    "we now turn to calculation of the likelihood function based on the neutrino data .",
    "this requires us to model the production of neutrinos at the supernova , their propagation to earth , their interaction with terrestrial detectors , and the detection of the energetic charged lepton produced upon such interaction .",
    "the last step of this modeling chain is the most complicated one , and the place where the differences between our likelihood function and those appearing in some earlier analyses are greatest .",
    "we therefore treat it first .",
    "our task in this section is to calculate the probability for the data produced by a neutrino detector , given the charged lepton production rate throughout the detector . before beginning the calculation",
    ", we first introduce a number of notational conventions that will streamline the derivation .",
    "we also review some basic results on inhomogeneous poisson processes ( poisson processes with varying event rates ) that play an important role in the derivation .",
    "we presume the reader is familiar with the basic setup of neutrino detectors ( see , e.g. , @xcite for a detailed description of the kamiokande ii detector ) .",
    "the `` input '' to our calculation is specification of the charged lepton production rate throughout a detector .",
    "this rate has two components .",
    "first , there is a background component due to particles entering the detector from cosmic ray interactions or radioactive decay in the surrounding rock .",
    "we also formally include other sources of false triggers ( such as noise in the detectors ) in the background rate .",
    "second , there is the physically interesting signal component due to astrophysical neutrinos .",
    "we presume here that both rates are given . in practice",
    ", the background rate is inferred from measurements , and the signal rate is the result of modeling , as we describe in the following section .",
    "the kii , imb , and baksan detectors most efficiently detect neutrinos through capture of electron antineutrinos on protons , resulting in the production of an energetic positron .",
    "thus throughout this work we will refer to the charged leptons produced by the astrophysical neutrino signal as positrons , even though many of our results apply equally well to detection of energetic electrons .",
    "the background component may be due to positrons , electrons , or muons . to simplify the discussion",
    ", we will refer to the production of a charged lepton of any type as an `` event . ''",
    "one must be careful to distinguish occurrence of an event from detection of an event : not every event that occurs is detected .",
    "we use @xmath60 to denote the differential background rate , so that @xmath61 is the probability that a background event will occur in an infinitesimal time interval @xmath62 in a volume @xmath63 at position @xmath64 in the detector , with a direction in the solid angle @xmath65 about the unit vector @xmath66 , and with an energy in the interval @xmath67 $ ] .",
    "we presume the background rate is constant in time over the duration of the observations .",
    "it is not constant in space , however , because background events due to sources in the surrounding rock appear preferentially near the detector walls .",
    "we use @xmath68 to denote the differential signal rate : the rate of production of positrons in the detector per unit time , energy , and steradian due to interactions with neutrinos from the supernova . unlike the background rate , it is time - dependent . however , it is constant throughout the detector volume since the detectors are optically thin to neutrinos .",
    "when we need the signal rate per unit volume , it is thus simply given by @xmath69 where @xmath70 denotes the detector volume .",
    "the signal rate will depend on some parameters , which we collectively denote by @xmath71 .",
    "the number and type of parameters depends on the model for the signal rate ; later sections describe the various models we consider .",
    "we are seeking the dependence of the likelihood on @xmath71 ( and , implicitly , on the choice of a parameterized signal model ) .",
    "we will often need quantities such as the background rate for events of any direction and at any position , but with energy in @xmath72 .",
    "this requires integration over the other intervals . for brevity",
    ", we simply collapse the argument list to indicate the necessary integrations .",
    "for example , @xmath73 and an unadorned @xmath74 is the total background rate per unit time .",
    "we adopt similar conventions for the signal rate , so that @xmath75 , and @xmath76 is the total signal rate per unit time at time @xmath77 .    our earlier work , and that of others using likelihood functions , attempted to calculate the likelihood by considering the data to be the inferred energies and arrival times of detected positrons ( i.e. , the `` best fit '' values as reported by the detector teams ) .",
    "however , the actual data is not a set of time - tagged energy values , but is instead a more complicated time series of pulse heights in the thousands of photomultipliers surrounding each detector that allows us to infer ( with uncertainty ) the properties of detected positrons .",
    "although this time series is not publicly available , a more accurate likelihood calculation results if we imagine it were available and try to calculate the probability for such a time series given the signal and background rates and detailed knowledge of the detector .",
    "accordingly , we let @xmath6 denote all the available data , reported as a time series specifying the state of the instrument at regular intervals separated in time by @xmath78 .",
    "the duration of @xmath78 is unimportant , so long as it is small enough that no more than one event is ever seen in an interval .",
    "we separate the data into two groups , _ detection data _ , @xmath79 , specifying all the data associated with detected event number @xmath34 ; and _ nondetection data _ , @xmath80 , specifying that no triggered event happened in time intervals indexed by @xmath81",
    ". we always use @xmath34 to index quantities associated with detected events .",
    "in particular , @xmath82 denotes the time of event @xmath34 .",
    "similarly , we always use @xmath81 to index quantities associated with nondetections . in particular , we use @xmath83 to denote the time interval @xmath84 $ ] associated with @xmath80 .    we will presume that , given the signal and background rates , the probability for a detection in some interval @xmath78 is independent of whether an event was detected in other time intervals",
    ". this implies that the likelihood function is simply the product of independent probabilities for the detections and nondetections , @xmath85\\ ;       \\prod_{j } p(\\bar d_j | \\pars , m),\\label{l - dnd}\\ ] ] where @xmath86 is the number of detected events and @xmath81 runs over all intervals for which no event was detected .",
    "as will become apparent , the number of nondetection intervals has no bearing on the analysis ; only their total duration matters .",
    "here we use the symbol @xmath19 to denote all of the modeling assumptions needed to calculate the required probabilities , including specification of the signal model discussed in the next section .",
    "we presume that , given the rates , the probability for an event occurring in any specified infinitesimal interval of time , volume , direction , and energy is independent of whether or not an event occurred in some other interval .",
    "this implies that the probability for @xmath87 events occurring in an interval of finite size is given by the poisson probability , @xmath88 where @xmath89 is the expected number of events in the interval , found by integrating the relevant differential rate over the interval .",
    "let us focus attention on a particular @xmath78 interval , and let @xmath90 denote the proposition asserting that no signal events occurred in the time interval .",
    "the probability for @xmath90 is given by equation  ( [ poisson ] ) , with @xmath89 equal to the signal rate integrated over @xmath78 : @xmath91\\nonumber\\\\    & \\approx & e^{-r(t)\\delta t}.\\label{pois-0}\\end{aligned}\\ ] ] to get the last line , we have assumed that @xmath78 is much smaller than the timescale over which the rate varies , so that the integral over @xmath78 is well approximated by @xmath92 , with @xmath77 equal to any time in @xmath78 .",
    "similar equations hold for the probability for no background event ; since the background rate is presumed constant , there is no @xmath77 dependence and the @xmath78 product form is exact .",
    "let us now focus attention on some specified time interval , and let @xmath93 denote the proposition asserting that a single signal event occurred in the @xmath78 interval under consideration , and that it had a position , direction , and energy in @xmath94 about the point @xmath95 .",
    "we write the probability for this proposition as @xmath96 so that @xmath97 is a probability _ density_. this proposition is the conjunction ( logical `` and '' ) of two simpler propositions : ( 1 ) one signal event occurred in @xmath98 ; and ( 2 ) no other signal event occurred in @xmath78 with a different position , direction , or energy .",
    "the poisson probability for the first of these propositions is @xmath99 .",
    "\\label{pois-1 - 1}\\ ] ] the poisson probability for the second is @xmath100.\\label{pois-1 - 2}\\ ] ] the probability ( density ) for @xmath93 is the product of these , divided by the differential @xmath94 , giving @xmath101 we can write the probability for occurrence of a single , specific background event similarly , substituting @xmath74 for @xmath31 .    we now have all the ingredients we need to derive the form of the likelihood function . but before doing so for realistic data , we will do so for ideal data produced by a fictional detector that detects every positron whose energy is above some threshold , @xmath102 , and that measures the locations , directions , and energies of detected events with negligible uncertainty .",
    "we will also presume there is no background rate in this detector .",
    "this calculation will make clear the origin of the most important terms in the more accurate likelihood function .",
    "we begin by calculating the probability for ideal nondetection data .",
    "this is simply the poisson probability for seeing no events when the expected number of events is @xmath103 here @xmath104 is the unit step function , equal to 1 when its argument is nonnegative , and 0 otherwise .",
    "thus @xmath105 is the efficiency for detecting events of energy @xmath106 , which is either 1 or 0 for this idealized detector .",
    "the efficiency assures that only the _",
    "detectable _ positron rate  that above the threshold  contributes to @xmath89 . with these definitions ,",
    "the nondetection probability is @xmath107 .",
    "\\label{pnd - ideal}\\ ] ]    to calculate the detection probability , we will presume that the nearly ideal detection data specifies that one event occurred in @xmath108 with energy @xmath109 , direction @xmath110 , and position @xmath111 , each measured with negligible uncertainties @xmath112 , @xmath113 , and @xmath114 .",
    "the probability for such a datum is simply the poisson probability that one positron is produced in a time interval @xmath78 at @xmath82 with properties in the specified ranges , multiplied by the probability that no other positron be produced in the same interval but at another detectable energy , direction , or position .",
    "we derived such a probability above , although with infinitesimal ranges ( see equation ( [ pois-1 ] ) ) .",
    "thus we can write down the result , @xmath115 .   \\label{pd - ideal}\\ ] ]    assembling the detection and nondetection probabilities according to equation  ( [ l - dnd ] )  gives the idealized likelihood function , @xmath116\\ ;         \\prod_{i=1}^\\nd { r(\\drxn_i,\\epos_i , t_i ) \\over v}.   \\label{l - ideal}\\ ] ] the time integral in the exponent is over the entire duration of the data and arose from combining the integrals in equation  ( [ pnd - ideal ] )  from all the nondetection intervals with the integrals in the exponents of the detection probabilities .",
    "the exponent is thus the total expected number of detectable positrons . in general , this is different from the ( integer - valued ) number of positrons actually detected . when the parameters of the model specifying @xmath68 allow its amplitude to be freely adjusted , one can show that the parameter values that maximize the likelihood make the expected number of positrons equal the actually detected number .",
    "realistic data differs from the idealized data in three important respects .",
    "first , the threshold for detection is not an energy threshold , but is instead specified in terms of the number of triggered photomultipliers . in terms of positron energy ,",
    "the threshold is thus `` blurry , '' since the number of photomultipliers triggered by a lepton of a particular energy can not be precisely predicted .",
    "second , the energies of detected leptons are inferred with considerable uncertainty .",
    "finally , the kii and baksan detectors have nonnegligible background rates , so that triggers occasionally result even when no energetic lepton has been produced by a neutrino .",
    "we present a detailed derivation of the likelihood , accounting for these complications , in appendix  a. though the calculation is somewhat lengthy , its result is easy to understand in the light of the idealized calculation described above .",
    "the full likelihood function can be written , @xmath117 \\nonumber \\\\    & \\quad\\times & \\prod_{i=1}^\\nd     \\left[b_i + \\int d\\drxn \\int d\\epos\\,\\like_i(\\drxn,\\epos)\\ ,               r(\\drxn,\\epos , t_i)\\right ] .",
    "\\label{ltot}\\end{aligned}\\ ] ] comparing this likelihood function with the likelihood based on idealized data given by equation  ( [ l - ideal ] ) reveals three important differences , each associated with a new factor in the likelihood .",
    "first , the integral of the signal rate appearing in the exponent ( i.e. , the effective rate ) here has the _ volume - averaged detection efficiency _ , @xmath118 , in place of @xmath105 .",
    "the sharp energy threshold is replaced by a smooth threshold , due to the fact that the detector trigger criteria are not simple functions of the actual event energy .",
    "there is a possible directional dependence in this factor .",
    "second , the product term has a weighted integral of the signal rate in place of the signal rate evaluated at the direction , energy , and time of the event .",
    "the weighting function , @xmath119 , is the _ event energy and direction likelihood_the probability for seeing the event data , presuming the positron that produced the data came from direction @xmath66 with energy @xmath106 .",
    "this integral accounts for uncertainty in the inferred directions and energies of events",
    ".    finally , the _ event background rate _ ,",
    "@xmath120 , appears in the product terms .",
    "this quantity is just a weighted integral of the background spectrum , the weighting function being @xmath121 .",
    "it is the rate of background events resembling event @xmath34 .",
    "recall that we are ultimately interested in the functional dependence of @xmath122 on @xmath71 , determined by the dependence of the signal rate on @xmath71 .",
    "if , for a particular event , @xmath120 is much larger than the signal rate ( for any interesting choice of @xmath71 ) , then that event s term in the likelihood will remain nearly constant  the event is effectively eliminated from consideration .",
    "but the full likelihood function does this `` background subtraction '' in a smooth way , reducing the weight of information from potential background events according to the relative probability that they are due to the background rather than the signal .",
    "we must add one further complication to the likelihood function .",
    "each of the detectors has a fixed , known dead time , @xmath123 , associated with every detected event . the likelihood function corrected for dead time",
    "is found simply by subtracting @xmath124\\tau$ ] for each event from the exponent in equation  ( [ ltot ] ) . since the @xmath125 parts of these terms are constants ( independent of the choice of model or parameters for the signal ) , for simplicity we drop them from the likelihood .",
    "a further dead time correction is required for the imb experiment .",
    "this experiment actually triggers on many more events than are reported as neutrino events .",
    "characteristics of these events allow them to be justifiably neglected as background events ( essentially , the experiment team eliminates events with a very high @xmath120 from the reported data )",
    ". however , they each have dead time associated with them , and they are numerous enough that this dead time must be taken into account . in principle , we could subtract @xmath126\\tau$ ] for each such event from the exponent in equation  ( [ ltot ] ) . in practice ,",
    "the times of these events are not reported , and they are numerous enough that it is adequate to simply multiply the exponent by the live time fraction , @xmath127 , where @xmath128 is the rate of background events that are not reported . for the imb detector , @xmath129 s@xmath130 and @xmath131 s , so that @xmath132 . for the kii and baksan detectors",
    "@xmath133 , since all events are reported .",
    "the likelihood function corrected for dead time is thus , @xmath134 \\nonumber \\\\    & \\quad&\\times \\prod_{i=1}^\\nd e^{\\reff(t_i)\\tau}\\ ,     \\left[b_i + \\int d\\drxn \\int d\\epos \\,\\like_i(\\drxn,\\epos)\\ ,             r(\\drxn,\\epos , t_i)\\right ] .",
    "\\label{ldt}\\end{aligned}\\ ] ] this is the complete likelihood function based on data from a single detector . to combine the information from different detectors , we simply calculate @xmath122 for each and multiply .",
    "the complete likelihood function is somewhat more general than what we need .",
    "as we note in the following section , the signal rate due to neutrinos from sn1987a is essentially isotropic .",
    "thus we can perform some of the volume integrals above , simplifying the likelihood function .",
    "we calculated the more general likelihood above both in order to illustrate some of the complications hiding behind the isotropic form we are about to find , and because it should prove useful in analyzing data from future supernova neutrino observations , for which the anisotropic component of the signal may not be negligible",
    ". the complete likelihood function may also be useful for analyzing other data , such as that produced by observing solar neutrinos .",
    "for an isotropic signal rate ,",
    "@xmath135 inserting this into equation  ( [ ldt ] )  allows us to write the likelihood for isotropic signals as @xmath136 \\\\    & \\quad&\\times \\prod_{i=1}^\\nd e^{\\reff(t_i)\\tau}\\ ,     \\left[b_i + \\int d\\epos \\,\\like_i(\\epos)\\ ,             r(\\epos , t_i)\\right ] ,    \\label{ldt - iso}\\end{aligned}\\ ] ] where the volume- and direction - averaged efficiency ( hereafter simply the _ average efficiency _ ) is given by @xmath137 and the volume- and direction - averaged event likelihood function ( hereafter the _ event energy likelihood _ ) is given by @xmath138 this is the likelihood function used in the calculations reported here .",
    "it is simpler than equation  ( [ ldt ] )  in the sense that the experiment teams need only report the one - dimensional functions , @xmath139 and @xmath140 , rather than their more detailed two - dimensional versions .",
    "similarly , the analyst needs to perform simpler integrals for the analysis .",
    "but it is important to realize that these functions are intrinsically more complicated than they appear ; the apparent simplification here simply reflects the fact that the experiment team can perform some of the required integrals once and for all .",
    "we have derived the form of the likelihood function presuming that the entire data set , in the form of a complicated time series , is available .",
    "however , the final likelihood function depends only on some summaries of this data .",
    "the nondetection data are summarized in the efficiency function .",
    "the detection data are summarized in the form of an event likelihood function for each detected event . for making inferences about isotropic signal models ,",
    "all that is required is the average efficiency , @xmath139 , and the event energy likelihood functions , @xmath140 .",
    "in addition , the data duration , @xmath141 , the equivalent water mass , @xmath19 , the dead - time , @xmath123 , and live fraction , @xmath142 , must be specified for each detector .",
    "finally , the event - averaged background rate , @xmath120 , must be specified for each event .    for our calculations",
    ", we use the reported detector efficiencies for @xmath143 . in figure 1",
    "we plot the average efficiencies for the kii , imb , and baksan detectors @xcite .",
    "it is clear that the three detectors sample the signal quite differently .",
    "it is perhaps worth emphasizing that we are interpreting these as the volume- and direction - averaged efficiencies for the detectors .",
    "this implies that , in principle , these are _ not _ the efficiencies one should use when analyzing signal models with an anisotropic component ( as would arise if there were a significant electron scattering component ) .",
    "but in practice , symmetries may make the differences between the direction - averaged and direction - dependent efficiencies negligibly small .",
    "for example , electron scattering events produced near the side of the detector closest to the source are more likely to be detected than those produced near the far side , since the latter will produce cerenkov photons preferentially directed out of the tank ( thus hitting few photomultipliers ) .",
    "but the symmetry of the shapes of detectors may result in near cancellation of the resulting variations of the full efficiency upon integration over the detector volume ( this symmetry was broken for the imb detector at the time of the sn1987a observations , since power for a large number of photomultipliers had failed ) .",
    "note that all of the reported average efficiency functions vanish below some energy , @xmath144 , that differs for each detector .",
    "formally , the efficiency probably never identically vanishes ( e.g. , there is a small probability that a low energy neutrino can trigger a large number of photomultipliers ) , but it presumably becomes negligibly small at the energy where the reported efficiency vanishes .",
    "we also presume that the event energy likelihood functions can be well - approximated by gaussians , @xmath145     \\,\\theta(\\epos-\\epsilon_0),\\label{li - gauss}\\ ] ] where @xmath109 is the reported `` best - fit '' energy for event @xmath34 , @xmath146 is the reported uncertainty for the energy , and @xmath147 is a normalization constant .",
    "the @xmath148 function appears for consistency with @xmath143 ; it ensures that the event likelihood vanishes at energies below the energy , @xmath144 , where the reported @xmath143 vanishes ( @xmath144 is never closer to the peak than two standard deviations ) .",
    "the actual @xmath119 function , resulting from detailed fitting of the pattern of triggered photomultipliers , is certainly not precisely a gaussian .",
    "but it must be approximately gaussian near its peak , since the leading order term in the logarithm of @xmath119 will be the second order , or gaussian , term .",
    "the extent of the region over which this approximation is adequate is impossible to ascertain without being provided the precise likelihoods .",
    "since the detection teams have summarized their event energy estimates with means and standard deviations , we have presumed the approximation to be adequate to @xmath149 standard deviations .",
    "we note that normalization of @xmath119 is simply a convention ; @xmath147 can be changed to any value without affecting inferences , so long as its value does not depend on the model parameters , @xmath71 .",
    "we choose to normalize @xmath119 with respect to @xmath106 ( i.e. , @xmath150 ) .",
    "the only use we have made of this normalization convention is in interpretation of @xmath120 in equation  ( [ bi - def ] )  as the rate of background events `` like '' event @xmath34 .",
    "finally , we calculate @xmath120 for each event by integrating the product of @xmath140 and an estimate of the background rate spectrum @xmath151 .",
    "the kii and baksan teams have provided us with measurements of @xmath151 that we have used for this purpose ; the imb experiment has a negligible background rate for events as energetic as the reported events , so for the imb events @xmath152 .    in table  [",
    "table : det ] we list the total background rates in the detectors , as well as other detector characteristics required for the likelihood calculation . in table  [ table : data ] we list the @xmath109 , @xmath146 , and @xmath120 values for each event reported in each detector . for the kii and baksan detectors ,",
    "events are listed that have not been included in other analyses .",
    "most earlier analyses could not properly account for the background component , and so had to exclude events suspected of being background events .",
    "as already noted , the correct likelihood function weights events according to the probability they come from the signal component , and so more smoothly and consistently `` subtracts '' the background component from the data .",
    "the calculation of @xmath120 requires use of previously unpublished information , and is based on some simplifying assumptions about the background rate .",
    "figure  2 shows the background rate measurements for the kii and baksan detectors that we use in the calculations .",
    "figure  2a shows the kii empirical background rate spectrum @xcite , which is nonzero only at low energies where the imb efficiency is zero .",
    "figure  2b shows the empirical background rate spectrum for the baksan detector @xcite ; it is significant even at high energies .",
    "most of the structure in the baksan background rate spectrum can be attributed to counting statistics , so the background spectrum we actually use is the smooth curve in the figure , obtained by successively performing a 3-point smoothing on the raw data points until a @xmath153 measure of the misfit between the data and the curve ( a parabolic interpolation of the smoothed data ) is near its expected value ( two smoothings were used ) .",
    "in fact , changing from the smooth curve to the raw data has a negligible effect on our results , so the uncertainty in the baksan background spectrum need not be more carefully accounted for .",
    "no 3-point smoothing of the kii spectrum could be tolerated , so we simply interpolated between the measured values ; again , the resulting background uncertainty has a negligible effect on our results .",
    "note that both background spectra extend below the energies where @xmath154 for each detector ( c.f .",
    "fig .  1 ) .",
    "the @xmath120 calculation requires knowledge of @xmath60 _ before _",
    "`` filtering '' by the detection efficiency .",
    "thus it is best inferred by taking data with no threshold criterion , resulting in background spectra extending below the nominal instrumental cutoff .",
    "finally , a rigorous calculation requires the background rate and event likelihoods as functions of @xmath64 , @xmath66 , and @xmath106 .",
    "the available information is only a function of @xmath106 .",
    "we have thus been forced to approximate equation  ( [ bi - def ] )  by @xmath155 this approximation ignores the position and direction information , and thus could lead to over- or underestimation of @xmath120 , depending on the event location and direction , and the inhomogeneity and anisotropy of the background . without detailed information about the full event likelihoods and background rate , we can not provide a quantitative assessment of the quality of this approximation .",
    "nevertheless , it should be far superior to simple elimination of the background events , which corresponds to the assumption of a very high ( formally infinite ) @xmath120 value for the censored events .",
    "in this section we describe how we model the lepton production rate that was presumed given in the previous section .",
    "as already noted , the detectors most efficiently detect neutrinos through capture of electron antineutrinos on protons , resulting in the production of an energetic positron .",
    "thus we explicitly model only the emission of electron antineutrinos by the supernova , and the production of positrons in the detector ( we later take into account the presence of neutrinos of other species when inferring the total energy emitted by the supernova ) .",
    "there are three steps in this modeling process .",
    "first , we model the electron antineutrino emission at the supernova .",
    "next , we model the propagation of this signal to earth . finally , we model the interaction of these neutrinos with neutrino detectors , leading to the production of energetic leptons whose detection we have already modeled .",
    "all of our signal models contain a component arising from the cooling of the newly formed neutron star at the center of the supernova .",
    "we refer to this part of the signal as the cooling component .",
    "in addition to the cooling component , there may be a contribution to the signal from hot , shocked accreting matter .",
    "such a contribution arises in the delayed supernova mechanism .",
    "we describe our models for these two components in turn .      motivated by the results of numerical calculations of stellar collapse",
    ", we assume that the newly formed neutron star emits electron antineutrinos from a neutrinosphere with a ( possibly time - dependent ) radius @xmath76 , and that the instantaneous neutrino energy spectrum is well described by a thermal fermi - dirac spectrum with time dependent temperature , @xmath156 , and constant , nonnegative ( usually zero ) effective `` degeneracy parameter '' , @xmath157 @xcite .",
    "the rate of emission of electron antineutrinos with energies in the infinitesimal range @xmath158 $ ] is then @xmath159 , with @xmath160 r^2(\\tem),\\label{dn - emit}\\ ] ] where @xmath161 is a constant with the value , @xmath162 @xmath163 is the observed initial neutrinosphere radius ; @xmath142 is the fermi - dirac function , @xmath164 @xmath165 is the neutrino energy ; @xmath166 is the emission time ; and @xmath167 .",
    "the quantity , @xmath168 , is the spin weight of the neutrino species in question ; @xmath169 for both massless and massive neutrinos @xcite . here and throughout this paper , temperature",
    "is measured in energy units .",
    "we are presuming here that neutrinos are emitted isotropically .",
    "although this is not expected to be rigorously true , current numerical simulations indicate the anisotropy of the emission resulting from the collapse of a nonrotating star is not likely to be larger than of order 10% .",
    "the effect of rotation on the neutrino emission ( and on other features of the collapse ) remains an open question .",
    "as accreted material flows through the stalled shock in the delayed supernova mechanism , it is heated and produces @xmath170 pairs .",
    "the accreted material is neutron - rich ( with neutron fraction @xmath171 ) ; as a result , positron capture on neutrons produces electron antineutrinos through the reaction @xmath172 .",
    "protons produced by this reaction ( and those already in the flow ) can capture the thermal electrons to produce electron neutrinos through the reaction @xmath173 .",
    "these two reactions proceed in local thermal equilibrium .",
    "the resulting electron antineutrino emission rate spectrum per unit mass of emitting material is @xcite @xmath174 where @xmath175 is the mass of hot accreted material emitting the neutrinos , and @xmath176 is a constant with the value @xmath177 here @xmath178 ( @xmath179 ) is the coupling constant for axial vector weak interactions , @xmath180 is the neutron rest mass , and @xmath181 ( @xmath182 ) is the standard weak interaction cross section .",
    "this emission rate differs from equation  ( [ dn - emit ] )  primarily through the factor @xmath183 arising from the size and energy dependence of the capture cross sections .",
    "we always set @xmath184 for the accretion component .    to calculate the emitted spectrum",
    ", we must multiply equation  ( [ acn - ndotm ] )  by the mass of hot material emitting at any particular time , which we write as @xmath185 where @xmath186 is the maximum mass emitting during the event , and @xmath187 is a dimensionless function describing the temporal behavior of the accretion emission , with @xmath188 .",
    "we assume that the temperature of the emitting material is constant in time , so that the electron antineutrino number spectrum due to accretion can be written @xmath189      if the distance to the neutron star is @xmath6 , the neutrino number flux per unit energy incident on detectors at the earth is @xmath190 the times , @xmath166 and @xmath191 , are related by @xmath192 where @xmath193 for the first detected event , @xmath194 is the ( unknown ) offset time between @xmath195 and the time of arrival of the first neutrinos incident on the earth , @xmath196 is the rest mass of the electron antineutrino , and @xmath197 a constant offset of @xmath198 has been dropped from equation  ( [ delay ] ) .    in our model , the flux of neutrinos at the earth as a function of detector time is determined by specifying @xmath199 , @xmath31 , and @xmath200 for the cooling component ; @xmath201 , @xmath202 , and @xmath203 for the accretion component ; and @xmath196 , and @xmath194 . if every detector had an accurate clock , we would need to specify only a single @xmath194 parameter ; it would represent the time between the detection of the first neutrino detected by any detector and the unknown time of arrival of the first neutrinos reaching the earth",
    ". however , accurate absolute times are available only for those events detected by the imb detector .",
    "thus , a separate @xmath194 parameter must be considered for each detector . with the exception of abbott , der ' ujula , and walker @xcite ,",
    "previous investigators have included at most only one such parameter @xcite .",
    "once emitted neutrinos reach the earth , their detection involves two distinct processes .",
    "first , a neutrino must somehow produce an energetic charged lepton in the detector .",
    "second , the cernkov light produced in the detector by this charged lepton must be detected .",
    "we refer to these processes as the lepton production and detection processes , respectively .",
    "we have already discussed the detection process in detail in the previous section ; we thus conclude this section by describing charged lepton production .",
    "often , these two processes have not been distinguished .",
    "the dominant charged lepton production process is positron production resulting from the absorption of electron antineutrinos ( @xmath204 ) on free protons through the reaction , @xmath205 all other processes have cross sections at least an order of magnitude below the @xmath206 absorption cross section @xcite , and so we neglect them , confining our analysis to this single species of neutrino .",
    "the angular distribution of positrons produced by proton capture is nearly isotropic @xcite . to a good approximation",
    ", we treat it as being isotropic , allowing us to use the likelihood function for isotropic rates described in the previous section .",
    "the energy - dependent cross section for equation ( 10.12 ) has been calculated by , for example , tubbs and schramm @xcite .",
    "it can be written as , @xmath207 where @xmath208 is the electron rest mass , and @xmath209 is a dimensionless function describing corrections to the @xmath210 energy dependence .",
    "this function is @xmath211^{1/2},\\label{k - def}\\ ] ] where @xmath212 ( @xmath213 mev ) is the neutron - proton mass deficit ; note that we have ignored small terms due to neutron recoil , and coulomb and radiative corrections @xcite .",
    "if there are @xmath214 free protons in a detector , then its total cross section is @xmath215 . using equation  ( [ dn - inc ] )  for the incident neutrino flux , and considering first the cooling component emission given by equation  ( [ dn - emit ] )",
    ", the capture rate per unit energy is @xmath216 \\kappa(\\enu )          r^2(\\tem).\\label{dn - cap1}\\ ] ] to parameterize the amplitude we introduce the quantity , @xmath217 other investigators have parameterized the amplitude in a more complicated way .",
    "the choice of @xmath218 , rather than the energy flux @xmath219 @xcite , the total emitted number of electron antineutrinos @xmath59 @xcite , or the total neutrino luminosity @xmath220 @xcite , permits straightforward inferences about the neutrinosphere radius @xmath31 .",
    "the parameter @xmath218 , or its equivalent , is as important as the remaining parameters that describe the neutrino detection rate .",
    "unfortunately , this parameter , or its equivalent , was fixed at its best - fit value in some studies @xcite , thereby artificially constraining the allowed values of the remaining parameters .    using @xmath218 , equation  ( [ dn - cap1 ] )",
    "can be written as @xmath221 where @xmath222 is the effective water mass of the detector .",
    "we can calculate the capture rate for electron antineutrinos from an accretion component in exactly the same manner as we did for the neutrinos produced by cooling , starting with the spectrum given by equation  ( [ acn - ndot ] ) .",
    "the resulting capture rate is @xmath223 where @xmath224 is a dimensionless parameter setting the amplitude of the accretion emission given by @xmath225 the total capture rate in a model with such an accretion component is simply the sum of the rates given in equations ( [ dn - cap ] )  and ( [ dn - cap - acn ] ) .",
    "ignoring a small ( angle dependent ) term due to neutron recoil @xcite , each captured electron antineutrino produces a positron with energy @xmath226 .",
    "the positron production rate per unit energy is thus the capture rate evaluated at @xmath227 , @xmath228 this is the function needed to evaluate the likelihood function using the formula developed in the previous section .",
    "we have considered fourteen different models for electron antineutrino emission from the supernova . these fall into three groups .",
    "first are seven single - component cooling models inspired by numerical collapse calculations studying the prompt supernova mechanism @xcite . these models have either constant or monotonically decreasing neutrinosphere temperature , constant or monotonically decreasing neutrinosphere radius , and a possibly nonzero neutrino degeneracy parameter , @xmath157 .",
    "next are five models inspired by collapse calculations that produce delayed supernovae by means of shocks that are revived by neutrino heating @xcite .",
    "these models include both a cooling component and a component due to material accreting through the stalled supernova shock . finally , we consider two _ ad hoc _ models with a distinctly different structure that could be implied by the data : temperatures and fluxes that first increase and then decrease .",
    "these models have from three to six parameters describing the neutrino emission , in addition to the required detector offset times .",
    "we emphasize that our models are phenomenological , and are not meant to reproduce in detail the behavior of any particular numerical calculation .",
    "given the sparseness of the data , excessive detail in the models seems unwarranted .",
    "nevertheless , our analysis demonstrates that the data are capable of distinguishing among the models we have studied , some of which are considerably more structured than those studied previously .      _",
    "( a ) constant temperature . _",
    "the simplest model we consider is emission from a constant temperature , constant radius neutrinosphere over a time @xmath229 , after which emission ceases : @xmath230 @xmath231 this is the simplest model that can fully characterize the data .",
    "it has a single energy scale that is determined by the energy distribution of the events , a single time scale that is determined by their temporal extent , and an amplitude , @xmath218 , that is determined by the number of events seen .",
    "_ ( b ) exponential dilution .",
    "_ next we consider a model with constant neutrinosphere temperature , but exponentially decreasing neutrinosphere radius : @xmath232 @xmath233 here @xmath123 is the luminosity time constant . as with the constant temperature model , this model has the smallest number of parameters that can fully characterize the data .",
    "however , this model allows us to test the hypothesis that the flux of the emitted neutrinos decreased in time .",
    "moreover , the flux produced by this model bears some similarity to that of some collapse calculations in which the color temperature of the emitted neutrinos stays roughly constant over timescales @xmath234 s , with the flux decreasing due to dilution as the opacity in the layers below the neutrinosphere gradually shifts from being absorption dominated to being scattering dominated @xcite . in this case , @xmath200 is more correctly interpreted as a dilution factor than an actually decreasing physical radius ; this is why we term this model `` exponential dilution . ''",
    "_ ( c ) exponential cooling . _",
    "the next model we consider is an exponential cooling model described by the equations , @xmath235 @xmath236 again , @xmath123 is the luminosity time constant . as with the previous two models ,",
    "this model has the smallest number of parameters that can fully characterize the data .",
    "however , this model allows us to test the hypothesis that the characteristic energy of the emitted neutrinos varied in time .",
    "this model exhibits the most basic characteristics of those numerical calculations of the cooling of the neutron star that show smoothly decaying neutrinosphere temperatures and a neutrinosphere radius that falls to within @xmath237% of its asymptotic value within about 0.5 sec @xcite .    _",
    "( d ) exponential cooling and dilution . _",
    "our next model combines exponential dilution and exponential temperature decay : @xmath238 @xmath239 this model , with four parameters , allows us to test whether the data provide evidence for evolution of both the characteristic energy of the neutrinos and the radius of the neutrinosphere .    _",
    "( e ) displaced power - law cooling .",
    "_ for the exponential cooling model , the cooling timescale , @xmath240 , is constant in time . as a next level of complexity",
    ", we consider a model with constant radius for which the cooling timescale increases linearly in time , that is , we set @xmath241 here @xmath242 is the timescale on which the cooling _ rate _ changes , in units of the initial cooling timescale @xmath123 . the temperature remains roughly constant for a time @xmath243 , and then decreases like a power law afterward .",
    "such a model is capable of qualitatively describing the results of several cooling calculations , including both those that show neutrino emission with a temperature that decays monotonicly from early times @xcite , and those that show a roughly constant temperature for times @xmath244 , followed by a monotonic decrease .",
    "also , such a growing timescale might better account for the three late events detected by kii . solving for @xmath156 , the functions defining this model are , @xmath245 @xmath246 this is the `` displaced power law '' cooling model of bludman and schinder @xcite .",
    "it has one more parameter than the exponential cooling model , @xmath242 .",
    "as @xmath247 , this model becomes simple exponential cooling .",
    "we exclude values of @xmath242 less than @xmath248 as unphysical , because they imply an infinite number of emitted neutrinos .    _",
    "( f ) nonzero degeneracy parameter .",
    "_ monte carlo calculations of neutrino radiation transport in the cooling neutron star @xcite indicate that the emitted neutrino spectrum is nonthermal and well modeled by a fermi - dirac distribution with positive neutrino `` degeneracy parameter , '' @xmath157 . thus we consider an additional model , the exponential cooling model described by equations ( [ t - expc])and ( [ r - expc ] ) , but with @xmath157 allowed to vary .",
    "this fourth parameter allows us to test whether there is evidence in the data for a nonthermal neutrino spectrum .    _",
    "( g ) delayed exponential cooling . _ finally , we consider emission at a constant temperature for a time @xmath249 , followed by exponential decay , with a constant neutrinosphere radius throughout : @xmath250      & { \\rm for\\ } t > t_{\\rm dur } ;    \\end{array}\\right .",
    "\\label{t - dexp}\\ ] ] @xmath251 this model has only one more parameter than the exponential cooling model , the duration , @xmath249 , of the constant temperature period .",
    "it has a `` plateau '' period that might account for enhanced emission at early times without requiring an accretion component .",
    "the above models were inspired by calculations studying the prompt supernova mechanism , which produce neutrinosphere temperatures and neutrino luminosities that decrease monotonically in time .",
    "in contrast , in the delayed scenario neutrino emission arises both from the cooling core , and from material that is heated as it passes through the stalled shock that will eventually produce the supernova explosion . to see if there is significant evidence in the data for such behavior , we considered five models that combine a cooling flux modeled with one of the behaviors described above , with an accretion flux described by one of two alternative models .      for four of our two - component models ,",
    "we model the accretion flux as that from accreted matter with constant temperature , @xmath252 , with the amount of emitting matter proportional to @xmath253 \\over            1 + { t \\over 0.5s}}. \\label{a - trunc}\\ ] ] the denominator is meant to mimic the properties of the accretion signal observed in numerical calculations of the delayed scenario , in which accretion is roughly constant for a few tenths of a second , and then decreases like @xmath254 until the supernova shock is revived and the accretion ceases .",
    "the form of the exponential factor is chosen to be nearly constant for times less than @xmath255 , and then drop exponentially very quickly thereafter , thus implementing a smooth truncation of the accretion .",
    "we add to this accretion flux a variety of cooling fluxes , as follows .    _",
    "( h ) exponential cooling and truncated accretion .",
    "_ we will find the exponential cooling model to be the most interesting single component model , so our first accretion model has a cooling flux with an exponentially decreasing temperature , @xmath199 , at constant radius , @xmath256 @xmath257 this model is thus a `` bridge '' between the single component models and models with accretion .    _",
    "( i  k ) displaced power - law dilution / cooling and truncated accretion . _",
    "a more accurate model for the cooling behavior observed in numerical calculations of the delayed scenario is a displaced power law , with the temperature or dilution factor roughly constant for a timescale of order 10 s , and then falling .",
    "accordingly , we model the cooling component with the following temperature and radius factor time dependences : @xmath258 @xmath259 we consider three such models . for model",
    "( _ i _ ) , we set @xmath260 and @xmath261 . for model ( _ j _ ) , we set @xmath262 and @xmath263 . for model ( _ k _ ) we set @xmath260 and @xmath263 .",
    "these models let us explore to what extent the cooling component in two component models can be explained by decreasing temperature or increasing dilution .      _",
    "( l ) exponential cooling and power - law accretion .",
    "_ in some recent calculations , the accretion rate decays smoothly , and is roughly proportional to @xmath254 during the first several tenths of a second after collapse@xcite . to model emission from these calculations ,",
    "we add to an exponential cooling flux like that in model ( _ c _ ) an accretion flux with temperature @xmath252 and temporal behavior given by @xmath264 thus the mass of emitting material is roughly constant over a timescale @xmath255 , after which it decreases like a power law with index @xmath265 .",
    "we fix @xmath266 at @xmath267 .",
    "this shallow value gives temporal behavior roughly consistent with the @xmath254 behavior observed at early times in calculations , but avoids the logarithmic integral divergence associated with a pure @xmath254 power law .      _",
    "( m ) thermal rise and fall .",
    "_ all of the models described above have temperatures and fluxes that never rise .",
    "our final two models are single component models that depart from this pattern .",
    "the first has a linear temperature rise , followed by exponential cooling , with the neutrinosphere radius constant throughout : @xmath268 & { \\rm for\\ } t > t_{\\rm rise } ;    \\end{array}\\right .",
    "\\label{t - rf}\\ ] ] @xmath269    _ ( n ) thermal rise and fall with contraction .",
    "_ the second has the same thermal evolution as the first , and a neutrinosphere radius that contracts linearly during the period of rising temperature , and remains constant thereafter : @xmath270 & { \\rm for\\ } t > t_{\\rm rise } ;    \\end{array}\\right .",
    "\\label{t - rfc}\\ ] ] @xmath271    in these models , the neutrino number flux can rise and sharply peak at some time @xmath272 with a temperature @xmath273 , and fall slowly afterward , potentially accounting for the large number of low energy events seen within the first second of the kii burst without requiring an accretion component .",
    "in this section we briefly summarize some of the results of our analysis of the models just described .",
    "we present best - fit parameter values for all the models .",
    "we identify the exponential cooling model as the most successful single - component model , and the displaced power law cooling plus truncated accretion model as the most successful two - component model ; we consider these models further in the following two sections .",
    "we also discuss the consistency of the baksan data with the kii and imb data , and the effect of proper treatment of background on our inferences .",
    "we list the best - fit values for the parameters of our single component cooling models in table  [ table : one ] .",
    "also listed are the values of the neutron star binding energy implied by the best fit parameters , calculated according to @xmath274 this expression assumes three flavors ( six species ) of neutrinos and antineutrinos , with each carrying away an equal part of the binding energy ; numerical calculations show this to be a reasonable approximation @xcite .",
    "the tabulated values of @xmath275 and @xmath276  km were calculated assuming @xmath277 , a value consistent with recent measurements of the distance to sn 1987a based on observations of its circumstellar ring @xcite .    in table  [ table : one ] , four cooling models are not listed because they have best - fit parameter values that make them identical to one of the listed models .",
    "the model combining exponential cooling and exponential dilution has a best - fit temperature timescale of @xmath278 ; this corresponds to the pure exponential dilution model .",
    "the remaining unlisted models all have best - fit parameters that make them equivalent to the exponential cooling model .",
    "that is , all additional parameters have best - fit values of zero .",
    "these models are : the exponential decay model with neutrino degeneracy parameter , @xmath157 ; the delayed exponential decay model ( equations ( [ t - dexp ] )  and ( [ r - dexp ] ) ) ; and the linear temperature rise , exponential temperature decay model ( equations [ t - rf ]  and [ r - rf ] ) .",
    "also , the best - fit values of the detector offset times for models with neutrino fluxes and temperatures that never increase are necessarily zero , and are not listed in table  [ table : one ] .",
    "we present the best - fit values for the parameters of our two - component models in table  [ table : two ] . the radii listed are those associated with the cooling component , so that @xmath276  km , as in table  [ table : one ] .",
    "the binding energies are the sum of the binding energy associated with the cooling component ( given by equation [ [ eb - def ] ] ) and the energy of the neutrinos emitted by the accretion component , calculated according to @xmath279 the @xmath280 contribution is also listed separately , in parentheses .",
    "equation ( [ ea - def ] )  assumes that equal energy is emitted in electron neutrinos and electron antineutrinos , and that negligible energy is emitted in neutrinos of other flavors since thermal production of mu and tau particles in the accreted matter is suppressed due to the large masses of these leptons .",
    "this suppression is not complete , so the actual accretion energy may be slightly higher than @xmath280 .",
    "since the neutrino flux and temperature never increase for any of the two - component models , the best - fit offset times are necessarily zero , and are not listed in table  [ table : two ] .    in table",
    "[ table : two ] , we have set @xmath281 for all accretion models . as we will demonstrate in sec .",
    "[ sec : acn ] , the likelihood function for the two - component models varies rather weakly with @xmath224 , and has a very broad maximum at values of @xmath224 significantly larger than one .",
    "the maximum likelihood values are significantly larger than expected theoretically , and imply an amount of accreted material that would lead to formation of a black hole on the timescale of @xmath282 , which is clearly incompatible with the detection of neutrinos at later times .",
    "we thus set @xmath281 for these models , this being a characteristic value in numerical calculations .",
    "this value is not excluded by the broad likelihood function ; in essence , we are using prior information to fix a parameter not usefully constrained by the data .",
    "two sets of best - fit parameters are presented in each table : values resulting from a joint analysis of all three data sets , and values resulting from a joint analysis of only the kii and imb data .",
    "the latter are included for comparison with previous studies that did not include the baksan data , and to give an indication of the consistency of the baksan data with the kii and imb data ; we comment further on this later in this section . since we find all the data to be consistent , all of our discussion of parameter values and model choice will be based on results from the kii - imb - baksan analysis , except where noted .",
    "we defer comparison of the parameter values with theoretical expectations until after the best models are identified and further studied .",
    "tables  [ table : one ] and [ table : two ] also list the value of the maximized likelihood function for each model . the actual value of the maximum likelihood is not directly meaningful ; however , when models are nested , the ratio of the maximum likelihoods of competing models can be used to evaluate the bic approximation to the bayes factor , and it can be used for a frequentist likelihood ratio significance test . for convenience ,",
    "the likelihood values have been scaled to the value found for the exponential cooling model .",
    "note that the bic penalizes models according to the number of their parameters , so that the ( approximate ) bayes factor can favor a complicated model only if its maximum likelihood is larger than that of a simpler competitor .",
    "likelihoods for calculations with and without the baksan data have been scaled separately ; these two classes of calculations can not be compared with each other because they use different sets of data .",
    "all of the models have scaled likelihoods of order unity or greater , with the exception of the constant temperature and radius model , whose scaled maximum likelihood is @xmath283 .",
    "further , models with phases of constant or increasing luminosity all have best fit parameters indicating that the duration of any such phase is short , @xmath284  s. thus there is strong evidence in the data for a neutrino luminosity that monotonically decreases throughout most of the burst , and the constant temperature and radius model can be rejected .",
    "the simplest of the remaining single - component cooling models are the exponential dilution model and the exponential cooling at constant radius model , each of which describe the neutrino emission with three parameters .",
    "the likelihood of the dilution model is slightly larger than that of the cooling model .",
    "also , the model combining cooling and dilution has a best - fit cooling timescale @xmath285 , indicating a preference for dilution over cooling .",
    "however , this preference is weak ; the maximum likelihood for the dilution model is only @xmath286 times higher than that for the cooling model .",
    "thus although the data indicate a neutrino flux that decreases significantly over timescales @xmath234 s , they can not conclusively distinguish dilution from cooling as the cause for the flux decrease in a single - component model .",
    "we consider the exponential cooling model to be the more viable of these models because the characteristic radius and luminosity timescale associated with the dilution model are much more difficult to reconcile with theoretical expectations than are the characteristics of the cooling model .",
    "the remaining two cooling models ( displaced power law cooling , and thermal rise and fall with contraction ) have maximum likelihoods larger than that of the exponential cooling model .",
    "however , they are both more complicated than this model , requiring four or more parameters ( in addition to the three offset times ) to describe the neutrino emission . the bic penalty for additional parameters ( see eqn .",
    "[ bic ] ) corresponds to a factor of @xmath287 per extra parameter for the kii - imb - baksan fits , and @xmath288 per extra parameter for the kii - imb fits .",
    "the approximate bayes factors for the two more complicated models are thus approximately unity or less .",
    "in addition , more careful accounting of our prior information about properties of the neutron star formed by the supernova would likely decrease the bayes factors for the complicated models even further .",
    "this can be seen as follows .",
    "the likelihood for each model is the prior - weighted average of the likelihood function for its parameters .",
    "the exponential cooling model has best - fit parameter values that imply binding energies and radii significantly in excess of those expected for a neutron star , even presuming the stiffest acceptable equation of state and substantial expansion due to the high temperature and lepton fraction of the nascent neutron star .",
    "( we assess this discrepancy more fully in the following section . )",
    "its model likelihood will therefore be small , since the prior probability in the vicinity of the maximum likelihood peak will be negligible .",
    "but the best - fit radii and binding energies for the two remaining cooling models are significantly larger still .",
    "we thus expect their model likelihoods to be smaller even than that for the exponential cooling model , both because their prior probabilities are spread out over more dimensions , and because the prior in the vicinity of the mode for each model will be smaller than that in the vicinity of the subspace of each model corresponding to exponential cooling . essentially , the exponential cooling model is the model among those single - component models with large maximum likelihoods that has the most reasonable implications for the parameters of the nascent neutron star .",
    "we explore it more thoroughly in the following section .",
    "all of the accretion models have maximum likelihoods over 100 times greater than that for the exponential cooling model .",
    "the two - component model with the highest maximum likelihood is the displaced power law cooling and truncated accretion model .",
    "we have used adaptive quadrature methods to calculate the bayes factor in favor of this model over the single - component exponential cooling model ; we find @xmath289 ( with @xmath224 fixed at 0.5 for the two - component model ) .",
    "this indicates strong evidence for an accretion component .",
    "this calculation used flat priors for the model parameters over fairly broad ranges @xcite .",
    "one might additionally consider the effect of our prior knowledge of the nascent neutron star s possible size and binding energy on the bayes factor .",
    "all of the two - component models that have a cooling component with decreasing temperature have best - fit parameters implying neutron star radii and binding energies much closer to expected values than any single - component cooling model .",
    "accounting for this should more strongly favor the two - component models .",
    "this is borne out by calculations .",
    "we inserted a lognormal prior factor chosen to qualitatively account for our expectations of the radius and binding energy of the neutron star .",
    "the ( log ) mean radius was set to 11  km , and the ( log ) mean binding energy to @xmath290  erg ; the ( log ) standard deviations were chosen corresponding to a @xmath291% variation in radius and @xmath292% variation in binding energy , reflecting uncertainties in equations of state of neutron stars of mass @xmath293 ( see the discussion of figure  5 in the following section ) .",
    "this prior increases the bayes factor favoring the two - component model to @xmath294 .",
    "we conclude that there is compelling evidence in the data for an accretion component in the neutrino flux .",
    "the two - component model with the highest maximum likelihood is the displaced power law cooling and truncated accretion model .",
    "we analyze it in greater detail in sec .",
    "its likelihood is not significantly greater than that of the model combining exponential cooling and truncated accretion .",
    "the latter model acts as a `` bridge '' between our best cooling model and the models with accretion components .",
    "but we focus instead on the accretion model with displaced power - law cooling , not only because its likelihood is larger , but also because it offers us the opportunity to explore different cooling behavior , and because displaced power - law cooling more closely resembles the cooling behavior exhibited in recent supernova calculations .    a common",
    ", approximate frequentist significance test also indicates a significant preference for two - component models .",
    "twice the logarithm of the ratio of the maximum likelihoods of two nested models has an asymptotic @xmath295 distribution , with @xmath296 equal to the difference in the number of parameters of the models being fit to the data @xcite .",
    "for example , the model combining displaced power law cooling and truncated accretion has two more fitted parameters than the exponential cooling model , and a likelihood 624 times greater .",
    "the chance of seeing an improvement this large or larger by chance if the exponential cooling model is the true model is asymptotically given by the tail area beyond @xmath297 in the @xmath298 distribution .",
    "this probability is @xmath299 .",
    "this probability is approximate , in that it is based on an asymptotic distribution .",
    "also , it ignores the size of the parameter space searched and the extent to which the inferred parameter values agree or disagree with expectations .",
    "nevertheless , it indicates significant evidence for an accretion component , even from a frequentist perspective .",
    "note that , in contrast to the single - component models , the accretion models show a definite preference for a decrease in temperature of the cooling component over an increase in dilution .",
    "for example , the truncated accretion model with displaced power law cooling has a maximum likelihood over five times larger than that for the model with displaced power law dilution . without more complete study of the parameter dependence of the likelihood ( i.e. , rigorous calculation of the model likelihood )",
    "it is not clear how strong this preference is .",
    "we comment further on the characteristics of these models in sec .",
    "9 .      as noted above , tables  [ table : one ] and [ table : two ] present results both from joint analysis of the kii - imb - baksan data , and from joint analysis of only the kii and imb data .",
    "nearly all previous analyses have ignored the baksan data .",
    "when these data were first reported , there was a discrepancy between the time of the pulse observed at baksan and that reported by imb , the baksan data having been detected approximately 30 s after the pulse observed by imb @xcite ( the kii detector has an absolute time uncertainty of @xmath300 m and thus could not settle the issue ) .",
    "but within a month of the supernova , the baksan group discovered a subtle , cumulative error in their clock , rendering their absolute timescale uncertain over @xmath301 to @xmath302 s , and eliminating the discrepancy @xcite .",
    "nevertheless , the baksan data has been largely ignored , perhaps because no methodology existed that could consistently account for the relatively large background rate in the baksan detector .",
    "an exception is the work of piran and spergel@xcite .",
    "but though they find exponential cooling models for which the kii , imb , and baksan data are consistent , they had to presume all baksan events were signal events , leading to acceptable models with unnecessarily large neutrino fluxes .",
    "our analysis easily accounts for strong , energy - dependent backgrounds , and demonstrates that the baksan data are fully consistent with the kii and imb data .",
    "this is partly apparent in the tables , where the deviations between kii - imb - baksan estimates and kii - imb estimates appear relatively small . as will become apparent in the following sections , these deviations are indeed small compared to the uncertainties in the parameter values .",
    "more formally , we can quantitatively assess the consistency simply by setting the offset time for the baksan detector to be large ( negative or positive ) , so that the data are considered to be entirely due to background , and comparing the likelihood of such a case to the likelihood when the baksan events are allowed to be coincident with the supernova signal .",
    "the likelihood associated with the hypothesis that the baksan data is entirely background will just be the likelihood listed in the kii - imb column in the tables , multiplied by a constant factor arising from the baksan data .",
    "this factor is @xmath303 , and once introduced allows comparison across columns of the table .",
    "for example , for the exponential cooling model a model attributing the baksan data entirely to background has a maximum likelihood @xmath303 smaller than the likelihood of a model attributing part of the baksan data to the supernova signal .",
    "these results leave little question about the presence of a supernova neutrino signal in the baksan data consistent with that detected by the kii and imb experiments .",
    "proper treatment of background spectra plays a key role in settling the issue of the consistency of the baksan data with the other supernova neutrino data .",
    "the kii detector also has a significant background rate .",
    "to assess the effect that our inclusion of the kii background rate has on our results , we performed the following calculation , designed to mimic how other investigators dealt with the kii background .",
    "we analyzed the kii and imb data jointly , but we set all kii event background rates , @xmath120 , equal to zero . duplicating the efforts of others who attempted to account for background by introducing an artificial energy threshold and censoring the data , we also made the kii detection efficiency vanish for energies below @xmath304 mev , and we omitted event 6 and events 1316 from the kii data .",
    "analysis of the exponential cooling model then gives the following best - fit values : @xmath305 , @xmath306 mev , and @xmath307 s , implying a binding energy of @xmath308 erg and a neutrinosphere radius of 43.1 km .",
    "comparing these results to the kii - imb results in table  [ table : one ] reveals little change in @xmath218 or @xmath309 , but a more substantial change ( over 15% ) in @xmath123 .",
    "this is because there is a nonnegligible probability that kii events 1012 are due to background .",
    "it is not likely that _ all _ of these events are background events , but it is likely that at least one of them is a background event .",
    "the analysis incorporating background information accounts for this , and thus prefers a shorter neutrino signal . the small change in the inferred temperature",
    "is also easily understood . that found with background",
    "is somewhat higher because the kii background spectrum peaks at low energy , which relaxes the constraint imposed on the model neutrino spectrum by the low - energy kii events .",
    "it is interesting to note that the best - fit duration for the constant temperature model is 10.43  s , thus excluding event no .  12 from the neutrino signal .",
    "this timescale is roughly five times more likely than the 12.44  s timescale that would include this event .",
    "this is because there is a reasonable probability that event no .  12 is a background event .",
    "previous analyses that ignored the background spectrum would assign our best - fit constant temperature model _",
    "zero _ likelihood .",
    "finally , we note that our results are insensitive to the removal of events 1316 from the kii data because the likelihood function finds it overwhelmingly likely that these events are background events .",
    "for example , the best - fit @xmath123 for the exponential cooling model inferred from an analysis of the kii and imb data ignoring these late events is less than 4% smaller than that found including them ; this is the parameter most affected by their inclusion .",
    "table  [ table : bg ] gives the probability that each kii and baksan event is a background event for the best - fit exponential cooling model and for the best - fit displaced power law cooling plus truncated accretion model .",
    "these are obtained simply by dividing @xmath120 by the sum of @xmath120 and the predicted signal rate for events like event @xmath34 , @xmath310 this is just the ratio of the background part of event @xmath34 s contribution to the likelihood to its total contribution . the formal ( model dependent ) probability that each event is a background event requires integration over the model parameters ; the tabulated values are thus merely indicative .",
    "most striking is how the brief , low temperature component of the accretion model and the resulting higher temperature for the cooling component reduces the background probabilities for kii events 16 and baksan events 13 to roughly half the values implied by the exponential cooling model .",
    "we now explore more fully the implications of the data in the context of the exponential cooling model .",
    "first , we determine the allowed ranges for the parameters of this model .",
    "then we examine the implications of this model for the radius and binding energy of the neutron star presumably created by the stellar collapse .",
    "then we graphically demonstrate how the best - fit model accounts for the data .",
    "we defer most discussion of the comparison of these inferences with theory to sec .",
    ". a frequentist assessment of the goodness - of - fit of the best - fit model appears in appendix  b.      a few previous investigators noted that their best - fit values for the radius and binding energy of the neutron star were somewhat higher than those predicted by current equations of state @xcite .",
    "our best - fit parameter values imply a radius and binding energy significantly greater than those found by previous investigators , indicating an even more serious discrepancy .",
    "it is therefore important to determine , not only the best - fit parameter values , but the entire region in parameter space allowed by the data .",
    "the exponential cooling model has three physical parameters , @xmath218 , @xmath309 , and @xmath123 .",
    "additionally , there is an unknown offset time , @xmath194 , for each detector . in an analysis of the kii - imb - baksan data ,",
    "there are thus six parameters .",
    "we summarize the full , six - dimensional joint posterior by presenting marginal credible regions for various interesting subsets of the parameters . here and elsewhere",
    "we use `` 68% '' and `` 95% '' to denote the probability content of credible regions formally including 68.3% and 95.4% of the posterior probability ; our calculations are based on monte carlo sampling and are accurate to @xmath311% .",
    "figure 3 shows the one - dimensional marginal distributions for each of the six parameters .",
    "each of the six curves shown in the figure summarizes the implications of the data for one of the parameters without regard to the values of the other parameters .",
    "in particular , one should not quote credible regions from these marginal distributions jointly , since correlations between inferred values of the parameters are ignored in these plots .    figures 3a3c show marginal distributions for the three cooling model parameters , @xmath218 , @xmath309 , and @xmath123 , with dashed lines indicating the value of the marginal distribution bounding 68% and 95% credible regions .",
    "the modes and 95% credible regions for these marginal distributions are as follows : @xmath312 , @xmath313 mev , @xmath314 s. here and elsewhere we plot distributions as a function of @xmath315 rather than of @xmath218 itself .",
    "the distribution as a function of @xmath218 is broad and very skew ; working in terms of @xmath315 simplifies the appearance of the posterior , particularly later when we show joint credible regions .",
    "note that the modes of the marginal distributions are at somewhat different locations than is the mode of the joint distribution .",
    "this is simply a consequence of the integration involved in the marginal distribution : there is a greater volume of parameter space with high probability at the mode of the marginal than at the joint mode , due to asymmetry in the full distribution .",
    "the changes in location are small compared to the size of the credible regions , however .",
    "figure 3d shows the marginal distributions for the three offset times , with the location of the endpoint of a 95% credible region for each offset time noted by a dot",
    ". the lower boundary of these credible regions is at zero for all three offset times .",
    "the credible regions are as follows : @xmath316 s , @xmath317 s , @xmath318 s.    the most interesting parameters are the three parameters , @xmath218 , @xmath309 , and @xmath123 , describing the cooling model .",
    "figure 4 shows three two - dimensional marginal distributions that reveal how strongly the inferred values of these parameters are correlated .",
    "the dots show the coordinates of 500 samples from the marginal distributions to illustrate our use of posterior sampling to find the marginals ; the contours show 68% ( dashed ) and 95% ( solid ) joint credible regions .",
    "the inferred values of @xmath218 and @xmath309 are particularly strongly correlated ( note that the vertical coordinate is logarithmic , so that @xmath218 and @xmath309 exhibit a semilogarithmic rather than a linear correlation ) .",
    "this is because the expected number of neutrinos increases strongly and nonlinearly with @xmath309 : the incident number grows with the standard thermal dependence of @xmath319 , but the @xmath320 dependence of the capture cross section and the energy dependence of the detection efficiency make the detectable number grow more quickly than @xmath321 . to keep the expected number , which is also proportional to @xmath322 , near the observed number",
    ", @xmath218 must therefore decrease strongly with @xmath309 , as shown in the plot .",
    "each choice of @xmath218 , @xmath309 , and @xmath123 implies a radius and binding energy for the nascent neutron star .",
    "the joint probability distribution for the model parameters thus implies a joint distribution for @xmath31 and @xmath275 .",
    "figure 5 shows the 68% and 95% joint credible regions of the marginal posterior for @xmath323 and @xmath324 .",
    "also shown are @xmath275 vs.  @xmath31 curves for a representative set of equations of state from the compendium of `` classic '' neutron star models compiled by arnett and bowers @xcite  ( dashed curves labeled p@xmath325 , bjv , and ps(tensor ) following arnett and bowers ) and state - of - the art models calculated by akmal , pandharipande , and ravenhall @xcite ( solid curves labeled apr ) . the classic models span the softest and hardest models that have been seriously considered in the past ; the two apr curves are believed to bound the truth . for these models ,",
    "the observed radius @xmath31 was calculated from the proper radius @xmath326 according to @xmath327 , where @xmath328 is the gravitational mass of the neutron star .",
    "there is a significant discrepancy between the data and all but the stiffest ( and currently disfavored ) equations of state .",
    "a number of effects might work in the direction to reduce the discrepancy .",
    "one must first keep in mind that the neutrinosphere radius ( the quantity we actually infer ) is in general distinct from the radius of the nascent neutron star .",
    "however , the kelvin - helmholtz cooling calculations of burrows and lattimer @xcite  show that the neutrinosphere falls to within 10% of the radius of the neutron star within @xmath329 s , and that the neutron star radius changes by only 10% as it cools after this time , even though significant neutrino emission continues for @xmath234 s. the work of gudmundsson and buchler @xcite elucidates this somewhat curious behavior",
    ". in their study of the effects of lepton fraction on neutron star structure , they found that neutron stars with masses of order @xmath330 m@xmath331 or greater shrink by less than 30% as their lepton fraction @xmath332 decreases from @xmath333 .",
    "there is significant rearrangement of mass , but in a manner that keeps the overall radius roughly constant .",
    "this behavior is a consequence of the fact that the leptons in the neutron star are relativistic , while the nuclei are nonrelativistic and by themselves exhibit a very stiff equation of state .",
    "the loss of leptons from the star stiffens the dense regions of the star where nuclear effects dominate the equation of state , but softens those regions where coulomb effects are important ( i.e. , the inner crust ) .",
    "thus as @xmath332 decreases , the core expands and the crust shrinks .",
    "the overall result is that high mass neutron stars ( which have large cores ) expand as @xmath332 decreases , but low mass neutron stars shrink . by coincidence , for masses near @xmath330  m@xmath331 the two effects nearly cancel , and the radius of the star suffers little change as the lepton fraction decreases .",
    "thus the relatively large lepton fraction of the nascent neutron star can not account for its large inferred radius .",
    "another effect that might reduce the discrepancy is rotation . if the star is born as a fast rotator , its observed radius might be larger than expected from nonrotating models .",
    "indeed , cook et al .",
    "@xcite find that rotation can increase the equatorial radius of a cold neutron star by @xmath334% .",
    "however , they find that the effect is strong only for angular velocities very near the breakup velocity .",
    "further , we would have to be observing the neutron star along its spin axis to see the full enhancement .",
    "thus , even allowing for the high temperature and lepton fraction of the nascent neutron star and the effects of rotation , there is a significant discrepancy between the inferred neutron star radius and the predictions of current equations of state , especially for realistic equations of state which would require @xmath335% expansion just to reach the boundary of the 95% credible region .",
    "figure 6 provides an informal , graphical display of how the best - fit exponential cooling model compares with the observed data .",
    "the figure shows contours of the detectable event rate , @xmath336 for the three detectors .",
    "integrals of this rate give the expected number of events in the region of integration .",
    "the plotted contours bound regions that include 68% ( dashed curve ) and 95% ( solid curve ) of the total number of detected events predicted by the best - fit model . also shown are the energies and times of the detected events .",
    "the `` ridge '' at low energies in the kii plot in figure 6a is due to the detector background , as is the ragged structure in the baksan plot in figure 6c ( c.f .",
    "figure 2 ) .",
    "the striking contrast between the shapes of the kii , imb , and baksan contours illustrates how differently the efficiency functions of the three detectors filter the neutrino signal .",
    "roughly two thirds of the events lie within the 68% contours for all three detectors and all of the events except for kii event 11 lie within the 95% contours , indicating broad compatibility of the model with the data .",
    "a two - dimensional generalization of the kolmogorov - smirnov test , a frequentist test of goodness of fit , can be used to attempt to quantify the graphical comparison we present in figure 6 ; several earlier investigations employed such tests .",
    "we present the results of such tests in appendix  b along with a critique of them .",
    "such tests are rather weak .",
    "they verify the adequacy of the exponential cooling model , but they fail to display the level of improvement offered by this model over the constant temperature model , or by accretion models over this model , to the degree it is displayed by an explicit model comparison using the likelihood function ( bayesian or frequentist ) .    from a purely statistical point of view , the exponential cooling model appears adequate to account for the data when viewed in isolation from reasonable alternative models .",
    "however , its implications for the parameters of the nascent neutron star conflict strongly with prior expectations , and argue against acceptance of this model .",
    "as noted in sec .  [ sec : results ] , models with an accretion component not only have much larger maximum likelihoods than single component models , but they also lead to inferred neutron star parameters much closer to those expected based on theoretical and observational knowledge of neutron stars .",
    "thus , these models have much higher probabilities than single component models . here",
    "we explore more fully the implications of the data for the best accretion model : that combining displaced power law cooling with truncated accretion ( hereafter referred to simply as the cooling plus accretion model ) .",
    "as we did with the exponential cooling model , we first present credible regions for model parameters , and then discuss how well the best - fit model accounts for the data .",
    "comparison of our inferences with theoretical expectations appears in the following section .",
    "the cooling plus accretion model has nine parameters : three describing the displaced power law cooling component @xmath337 , three describing the accretion component @xmath338 , and three detector offset times .",
    "the sparsity of the data , combined with the complicated structure of the emitted rate and spectrum , result in a posterior distribution that is significantly more complicated than the unimodal posterior found for the exponential cooling model .",
    "this is illustrated in figure 7 , which presents simple summaries of our inferences for the three accretion parameters .",
    "figure 7a shows the profile likelihood for the accreted mass parameter , @xmath224 .",
    "the profile likelihood , @xmath339 , is found by calculating , for each @xmath224 , the maximum value of the likelihood ( maximized over all the remaining parameters ) .",
    "the plotted value has been normalized so that it gives directly the maximum likelihood ratio between a model with specified @xmath224 and the exponential cooling model .",
    "a profile likelihood can provide an approximate marginal distribution .",
    "in particular , for posteriors that are multidimensional gaussians ( with arbitrary amounts of correlation ) , normalized profile posteriors are identical to the corresponding marginal distributions .",
    "more generally , the approximation can range from excellent to very poor , depending on how strongly the characteristic scale of variation of the posterior varies with the parameters .",
    "while we have not quantified how accurately these profile posteriors approximate the corresponding marginals , our investigations of the behavior of the likelihood as a function of the maximized parameters indicate that these curves adequately display the regions of parameter space where most of the posterior probability lies .",
    "figure 7a shows that the likelihood varies rather weakly with @xmath224 , with values over the entire range we searched , from @xmath340 to @xmath341 , having profile likelihoods that vary by less than a factor of 8 ( roughly the range of variation across two standard deviations of a gaussian distribution ) .",
    "as already noted , we focus attention on models with @xmath281 as being representative of those found in supernova calculations based on the delayed scenario . the point on the curve corresponding to this model",
    "is indicated by a dot .",
    "figure 7b displays the @xmath342 dependence of the posterior for the @xmath281 model . for each value of @xmath342",
    ", we maximized the posterior with respect to the @xmath218 and @xmath343 cooling parameters .",
    "the cooling timescale @xmath344 was fixed at its best - fit value of 14.7 s for this calculation because maximization with respect to this parameter proved problematical away from the peaks ( extreme values were preferred ) ; the most probable @xmath344 values in the vicinity of the peaks are near this best - fit value .",
    "this figure clearly reveals the complicated structure of the posterior .",
    "three local modes are apparent .",
    "one is at very small values of @xmath255 corresponding to accretion components that account only for the first event in each detector .",
    "another is near @xmath345 s , giving a duration just sufficient to include the second kii event .",
    "the global mode at @xmath346  mev and @xmath347  s has a peak density about twenty times greater than that at @xmath348  s and thus contains most of the posterior probability ; the 0.74  s duration includes the first six kii events .",
    "the posterior density falls very steeply with increasing temperature , setting a firm upper limit on @xmath252 of @xmath349  mev for the most probable values of @xmath255 ( @xmath350 s ) .",
    "it falls less steeply with decreasing temperature , but @xmath351 mev is strongly excluded .",
    "there is an additional very small mode , not shown , at @xmath352  s , due to the late , soft kii events , nos .",
    "the complicated structure of the posterior has prevented us from calculating rigorous marginal credible regions for the parameters of this model using the rejection method described earlier . in the remainder of this section , we present inferences conditioned on @xmath281 and on the resulting best - fit values of @xmath252 and @xmath255 , listed in table  [ table : two ] .",
    "more rigorous calculations ( for example , using markov chains instead of the rejection method ; see @xcite ) should result in somewhat broader credible regions than those we will show here , as a result of averaging over other values of the accretion parameters .",
    "but since @xmath252 and @xmath255 are fairly well determined for the global mode , and since their best - fit values do not change greatly with @xmath224 , we do not believe more rigorous credible regions would be substantially larger than those displayed here .",
    "figure 8 displays marginal distributions for the three parameters of the cooling component and for the three offset times , conditioned on the best - fit accretion temperature and timescale for @xmath281 .",
    "it is instructive to compare these inferences with those displayed in figure 3 , based on the exponential cooling model .",
    "the inferred value of @xmath218 when an accretion component is present is substantially smaller , because a significant number of the earliest , softest events is attributed to the accretion component .",
    "the temperature of the cooling component is significantly higher than that in a single - component model because the constraint placed on the temperature by those early , soft events has been relaxed .",
    "inferences for the cooling timescale must be more cautiously compared , since the cooling components of these models have different temporal behavior . in particular , for the exponential cooling model , @xmath123 was the _",
    "timescale , so that @xmath353 is the temperature timescale . in the two - component model",
    "studied here , @xmath344 is the temperature timescale .",
    "its inferred value is somewhat smaller than @xmath353 for the exponential cooling model , but the rate of cooling is significantly less in this model ( with its displaced power - law cooling component ) than in the exponential cooling model .",
    "the timescales are thus comparable .",
    "finally , the offset times are better constrained in the accretion model , in order to keep the early events of all three detectors coincident with the brief accretion component .",
    "the modes and 95% credible regions for these marginals are as follows : @xmath354 , @xmath355 mev , @xmath356 s , @xmath357 s , @xmath358 s , @xmath359 s.    figure 9 displays two - dimensional marginal distributions for the cooling component parameters ( again , conditional on the parameters for the accretion component ) .",
    "these illustrate the correlations between the inferred values of the parameters , which show the same qualitative behavior as that displayed in figure  4 for the exponential cooling model .",
    "figure 10 shows the implications of this model for the radius and binding energy of the nascent neutron star .",
    "these results are conditional on the best - fit @xmath252 and @xmath282 for @xmath281 , so by assumption there is an accretion contribution to the binding energy given by equation  ( [ ea - def ] ) ; this contribution is @xmath360 erg .",
    "added to this is an uncertain contribution due to the cooling component ; the figure shows the joint distribution for logarithms of the total binding energy , @xmath275 , and the observed radius , @xmath276 km . also shown are the same representative @xmath275 vs.  @xmath31 curves shown in figure  5",
    ". clearly , the radius and binding energy implied by this two - component model are easily compatible with the values predicted by all viable equations of state .",
    "figure 11 graphically illustrates how the best - fit accretion model ( with @xmath281 ) compares with the observed data .",
    "comparison with figure  6 ( for the exponential cooling model ) reveals how this model can so substantially increase the probability for the data .",
    "the brief , low temperature accretion component accounts for the early , soft kii events , nos .",
    "this relaxes the constraint these events placed on the temperature of the cooling component , allowing it to be higher .",
    "the higher temperature cooling component better accounts for the remaining early kii events ( that have significantly higher energies than events 2 - 6 ) , and also better accounts for the energetic events seen in imb and baksan . results of a two - dimensional kolmogorov - smirnov ( ks ) test further demonstrating the adequacy of the best - fit model appear in appendix  b.",
    "here we review the basic predictions of supernova theory for the characteristics of the neutrino emission , and then compare these with the characteristics inferred above .",
    "several reviews describe the collapse of a massive ( @xmath361 ) star , such as the progenitor of sn 1987a , and the subsequent birth of a neutron star . here",
    "we summarize the basic features of the supernova event and the resulting neutrino signal , following closely the descriptions of woosley and weaver @xcite and of arnett , bahcall , kirshner , and woosley @xcite .",
    "once the massive progenitor of the supernova begins fusing oxygen , its neutrino luminosity exceeds its photon luminosity .",
    "neutrinos thus play a dominant role in the evolution of the star well before the drama of stellar collapse begins , though the neutrino luminosity is far below the limit of detectability .",
    "nuclear burning proceeds in the progenitor core until an iron core is produced with mass @xmath362 , radius @xmath363 few @xmath364 , central density @xmath365 , and central temperature @xmath366 mev .",
    "the pressure in the iron core is dominated by the degeneracy pressure of relativistic electrons ( @xmath367 ) , so the core resembles a degenerate dwarf star with an equation of state with effective adiabatic index , @xmath368 , near that of an ideal , relativistic electron gas , and therefore only slightly above the critical value @xmath369 at which gravitational collapse will occur .",
    "since iron is at the peak of the nuclear binding energy curve , at this point the progenitor has exhausted its supply of thermonuclear fuel .",
    "the core contracts and heats , causing photodissociation of the iron nuclei through the reaction @xmath370 .",
    "this reaction is endothermic , requiring @xmath371 per dissociation , which depletes the kinetic energy of the electrons , reducing their pressure support of the star .",
    "additionally , electron captures on nuclei in the core occur through reactions of the form , @xmath372 initially , the neutrinos produced by these reactions leave the core , carrying away most of the kinetic energy of the captured electrons , and further reducing the electron pressure support .    through the combined effect of these two processes , the effective adiabatic index in the core falls below @xmath373 and dynamical collapse ensues .",
    "the inner @xmath374 of the core remains partially pressure supported ( , the infall velocity remains subsonic ) and collapses homologously with velocity proportional to radius . outside the inner core ,",
    "the infall velocity is supersonic , and is approximately the free fall velocity .",
    "the neutrinos produced by electron capture have energies typical of the electrons that produced them , @xmath375 . their wavelengths ( @xmath376 fm ) are thus long compared with nuclear sizes , so they scatter coherently from nuclei , with a cross section proportional to the number of nucleons squared @xcite .",
    "the mean free path for elastic scattering of a neutrino of energy @xmath377 consequently becomes much smaller than the radius of the core @xcite .",
    "initially , the neutrino diffusion timescale , @xmath378 ( where @xmath379 is the neutrino mean free path ) , is shorter than the dynamical timescale , and the neutrinos leave the collapsing core , carrying away entropy .",
    "but once the density exceeds @xmath380 , the diffusion timescale exceeds the dynamical timescale , and the neutrinos are trapped in the collapsing material .",
    "thus soon after collapse begins , the lepton fraction of the core is frozen at @xmath381 , and the collapse proceeds adiabatically .",
    "the degenerate electrons and electron neutrinos in the core store the gravitational energy of the collapse .    on the dynamical timescale of a few milliseconds , the density reaches @xmath382 , at which point degenerate , nonrelativistic nucleons become the dominant source of pressure in the inner core .",
    "the resultant stiffening of the equation of state abruptly halts the collapse of the inner core .",
    "pressure waves propagating outward coalesce into a shock @xmath383 beyond the edge of the inner core .",
    "the shock begins moving outward and dissociating the outer core material , so that the post - shock material consists mostly of neutrons and protons .",
    "in this environment of free nucleons , the electron capture rate rises and the neutrino cross section decreases , causing electron neutrinos to pile up behind the shock .",
    "several milliseconds later , the shock reaches a density of @xmath384 , where the optical depth outward is of order unity , and the electron neutrinos behind the shock are released in a dynamical timescale of a few milliseconds .",
    "this is the first significant neutrino signal produced during collapse .",
    "the electron neutrinos released during this `` breakout '' phase have a spectrum like that of the degenerate electrons that produced them ( @xmath385 mev ) .",
    "a small number of thermally produced pairs of electron neutrinos and antineutrinos and other neutrino flavors are also emitted .    as the shock propagates through the outer core",
    ", it weakens due to neutrino emission and photodisintegration of heavy nuclei .",
    "the temperature of the shocked material is so high that destruction of iron down to free nucleons occurs , releasing an energy @xmath386 erg for each @xmath387 of matter that is photodisintegrated .",
    "the shock can not endure such losses for long , and will die unless it quickly reaches the edge of the outer core , where the density is low and the heat capacity is high .",
    "here the shock temperature falls , becoming less effective in producing neutrinos and too low to disintegrate iron .",
    "in order for the shock to survive the energy losses due to photodissociation of the outer core , the total mass of the core must be small .",
    "thus an iron core as large as @xmath388 almost certainly can not produce a supernova by a hydrodynamical bounce , but cores smaller than @xmath389 might . even in this case , however , a successful explosion is problematical and depends on the equation of state used and details of the hydrodynamic and neutrino transport codes employed .",
    "thus hillebrandt et al .",
    "@xcite  get a strong explosion for an 8.8-@xmath390 star , wilson et al .",
    "@xcite  get a weak one , and burrows and lattimer @xcite  get none at all . while hillebrandt @xcite  obtains a marginal hydrodynamic explosion for a 10-@xmath390 star , wilson et al . , bruenn , and burrows and lattimer do not @xcite ; and while baron et al .",
    "@xcite , using a `` softer '' nuclear equation of state than hitherto accepted , obtain prompt explosions for 12-@xmath390 and 15-@xmath390 stars , wilson et al .",
    "@xcite , using a more standard equation of state , do not .",
    "if a prompt explosion occurs , the shock moves outward rapidly upon reaching the edge of the outer core , ejecting the mantle and envelope of the star .",
    "electron neutrinos gradually diffuse out of the inner core on a diffusion timescale @xmath391 .",
    "electron captures at first replenish them , and through this diffusion process the lepton fraction of the core begins to decrease .",
    "these electron neutrinos are created with energies of the order of the fermi energy of the captured electrons ( @xmath392 ) , but do not leave the core until they have down - scattered to energies for which the scattering mean free path is of order the size of the core ( @xmath393 ) . as a result of this `` deleptonization '' phase ,",
    "the outer core is _ heated _ , leading to thermal production of neutrinos of all flavors in the outer core through electron - positron annihilation .",
    "for a few tenths of a second after shock breakout , production of electron neutrinos in the optically thin region just behind the shock dominates that of other species .",
    "but soon the neutrino emitting region becomes optically thick and pairs of all flavors of neutrinos are produced in roughly equal numbers .",
    "these thermal pairs cool the core , which has now reached its final radius @xmath394 .",
    "the integrated energy of these thermal neutrinos is very nearly equal to the full binding energy of the collapsed core , @xmath395 .    to summarize , in the prompt explosion picture",
    ", the neutrino signal is expected to consist of two principle phases .",
    "first , there is a brief , intense burst of electron neutrinos from shock breakout , with a degenerate spectrum of high energy .",
    "though intense , this burst is so brief that very little of the binding energy and lepton number of the collapsed core is carried away by it . following",
    "this burst is a much weaker signal of thermally produced neutrinos of all flavors with lower energies , but lasting for a much longer time , @xmath234s .",
    "the separate timescales for shock breakout ( @xmath396 s ) and kelvin - helmholtz cooling ( @xmath397  s ) may be discernible in the neutrino signal .",
    "the integrated energy of the later , thermal signal equals the binding energy of the neutron star , and the integrated number of neutrinos in this phase of emission exceeds the number of leptons originally contained in the collapsing core by an order of magnitude .",
    "the signal in water c ` erenkov detectors , whose cross sections for interaction with @xmath398 ( and neutrinos of other flavors ) is an order of magnitude lower than that for absorption of @xmath204 , is expected to be dominated by thermally produced @xmath204 s .",
    "if the prompt explosion fails , as all recent numerical simulations find , the deposition behind the shock of a small amount of energy by neutrinos streaming out of the core may produce a delayed explosion .",
    "following the failure of the shock , a nearly stationary `` neutrinosphere '' develops at about 40 km , where the density @xmath399 g @xmath400 and the neutrino emission temperature @xmath401 mev . the stalled shock lies at @xmath402 km , well beyond the neutrinosphere , where the post - shock temperature ( @xmath403 mev ) and density ( @xmath404 gm @xmath400 ) are much smaller .",
    "capture of a small fraction ( @xmath405% ) of the @xmath406 erg s@xmath130 neutrino luminosity by neutrons and protons and , later , by scattering off electron - positron pairs behind the shock heats the matter , and eventually revives the shock .",
    "after @xmath407 or more of matter has accreted onto the core over a period of @xmath0 sec , the outward motion of the shock resumes , ejecting the mantle and envelope of the star . during this accretion phase ,",
    "the hot material behind the shock copiously emits electron neutrinos and antineutrinos ; the production of neutrinos of other flavors is suppressed because they can be produced only in neutral current interactions .",
    "the amount of material finally accreted is uncertain , but may be as much as @xmath408 in order to leave behind a neutron star with a mass near the typical observed value of 1.4 @xmath390 .    to summarize , in the delayed explosion picture , the neutrino signal is expected to consist of three principal components .",
    "two of these , the emission of electron neutrinos at breakout , and the diffusion of neutrinos out of the inner core , which heats the outer core and produces neutrino - antineutrino pairs of all flavors , are identical to those of the prompt explosion picture . in addition , there is a third component , lasting @xmath0 sec , during which the flow of accreting matter through the stalled shock at @xmath409 - 200  km produces electron neutrino - antineutrino pairs , possibly with a luminosity @xmath410  erg  s@xmath130 and temperature @xmath411 to 5  mev .",
    "the inferred values for the neutrino cooling timescale and characteristic cooling temperature , both for single component cooling models and for the cooling component of models including an accretion component , are in remarkable agreement with that expected in the above scenario , which had developed in the absence of direct observations .",
    "the @xmath204 energy , @xmath412 , is typical of that expected for the neutral current diffusion of @xmath204 out of the hot outer core .",
    "finally , the cooling time scale @xmath413  s is of the order of the expected timescale for deleptonization of the inner core .",
    "however , for single component models , the inferred values of @xmath31 , @xmath275 , and the total number of @xmath204 are all well above theoretical expectations .",
    "this is most clearly displayed by the @xmath414 credible regions for the exponential cooling model plotted in figure  5 .",
    "all other single component cooling models we explored had best - fit @xmath414 values even more excessive than those found with the exponential cooling model .    when an accretion component is added to the signal , not only",
    "does the fit substantially improve , but the inferred values for @xmath31 , @xmath275 , and the number of thermally emitted @xmath204 are all in agreement with theoretical expectations .",
    "figure  10 displays the agreement between inferred and expected @xmath31 and @xmath275 values .",
    "the implied number of @xmath204 from the cooling component ( @xmath415 ) is comparable to that expected from @xmath398 diffusing out of the inner core and heating the outer core by neutral current scattering and absorption .",
    "approximately @xmath416 additional @xmath204 are emitted by the accreted material .",
    "the inferred timescale of the accretion component ( @xmath417 s ) is in agreement with the timescales @xmath418 - 1  s observed in numerical calculations .",
    "the best - fit temperature of the accretion component is 2 mev , and there is a sharp upper limit of @xmath349 mev .",
    "the temperatures observed in current numerical calculations are 1 to 3 mev higher , but are highly uncertain .",
    "finally , the data prefer large values for the amount of accreted material ( @xmath419 ) .",
    "however , this preference is not of great statistical significance , and models with @xmath420 to @xmath421 of accreted material all make the data substantially more probable than single - component models .    surprisingly , then",
    ", these relatively sparse data are able to discern between models with and without an accretion component , due to broad spectral and temporal features in the data . however , the data have proved too sparse to discern some interesting details about the spectral evolution of the neutrino signal .",
    "detailed studies of the transport of neutrinos through the core during the deleptonization and cooling phases show that the emitted spectrum is significantly nonthermal @xcite .",
    "the strong energy dependence of neutrino scattering cross sections ( @xmath422 ) leads to a spectrum that is well modeled by a fermi - dirac spectrum with positive chemical potential @xmath423 ( or effective degeneracy parameter , @xmath424 ) , with @xmath425 to 4 .",
    "but the data are too sparse to provide a significant measure of these transport effects : when the @xmath157 parameter is added to the exponential cooling model , its best - fit value is zero , and its 95% credible region extends to @xmath426 .",
    "similar conclusions were reported earlier by hillebrandt  @xcite .",
    "in addition , there is some ambiguity among the calculations regarding the evolution of the spectrum of the cooling component .",
    "calculations that treat the neutrino transport in a limited way by considering only a `` luminosity temperature '' for the neutrinos necessarily find a neutrino temperature that decreases in time as the luminosity decreases @xcite .",
    "more sophisticated calculations seem to indicate that the neutrino temperature stays roughly constant over @xmath234 s ( perhaps even rising slightly during the first few tenths of a second @xcite ) , with the luminosity decreasing as the opacity just below the neutrinosphere becomes more and more scattering - dominated , leading to dilution of the neutrino spectrum @xcite . in our study of single - component models , the data were not able to discern between cooling and dilution , although a slight preference for dilution appeared . in our study of models including an accretion component , the initial temperature was larger than in single component models , with the result that models with a decreasing temperature for the cooling component are preferred over models with pure dilution .",
    "this preference is not decisively strong , however .",
    "the calculations of the preceding sections all presume that the electron antineutrino rest mass , @xmath4 , is zero .",
    "we derived the likelihood function allowing for nonzero @xmath4 , so it is straightforward to test this assumption . for several of the models we considered ,",
    "the likelihood is maximized with @xmath427 , indicating no evidence for a nonzero rest mass in the supernova neutrino data .",
    "this is true for the exponential cooling model that was the focus of sec .",
    "[ sec : exp ] . for others ,",
    "the likelihood is maximized for small values of @xmath4 ( a few ev ) , but the likelihood is increased only slightly above its @xmath427 value , indicating no significant evidence for a nonzero mass .",
    "this is true for the cooling plus accretion model that was the focus of sec .",
    "[ sec : acn ] ; table  [ table : m ] provides the best - fit parameters for this model found using the kii - imb - baksan data .",
    "the @xmath428 entry gives the ratio of the maximum likelihood to that found with @xmath427 .",
    "these results are representative of models with nonzero best - fit @xmath4 : best - fit masses of a few ev ; best - fit detector offset times @xmath429  s ; negligible changes in other parameters ; and insignificant improvement in the maximum likelihood .    presuming that there is nevertheless a small nonzero rest mass , we can calculate marginal posterior distributions for @xmath4 for any model of interest to obtain constraints on the mass .",
    "figure  12 shows such marginal distributions for the exponential cooling model ( dashed curve ) and the cooling plus accretion model ( solid curve ; here @xmath224 , @xmath252 , and @xmath255 were fixed as in sec .  [ sec : acn ] ) .",
    "the dots indicate the upper bounds of 95% credible regions and are at @xmath430  ev for the exponential cooling model and @xmath431  ev for the cooling plus accretion model .",
    "it is interesting to note that these upper limits for @xmath4 are substantially better than the laboratory limits that were available at the time of the supernova neutrino detections ( and comparable to current limits ) .",
    "formally , a complete summary of the implications of the data for @xmath4 would additionally marginalize over the choice of signal model , essentially producing a weighted average of the individual marginals shown in the figure ( this is called bayesian model averaging @xcite ) .",
    "but the cooling plus accretion model is so much more probable than single - component models that model averaging would essentially reproduce the solid curve , which we thus consider to summarize our results for @xmath4 .",
    "note that the marginal posterior based on the exponential cooling model peaks at positive @xmath4 , even though the joint posterior based on that model peaks at @xmath427 . also , for the cooling plus accretion model , the ratio of the peak of the marginal to its value at @xmath427 is greater than the likelihood ratio of 2.3 listed in table  [ table : m ] .",
    "these differences between the joint distributions and their marginals are further examples of the phenomenon discussed in sec .",
    "[ sec : exp ] ( see the discussion of figure  3 ) .",
    "there is somewhat more allowed volume in the parameter space for slightly positive values of @xmath4 , and the integration yielding the marginal for @xmath4 accounts for this , increasing the marginal density for @xmath4 in that region .",
    "such effects are common , and provide an illustration of the difference between using profile likelihoods and true marginal distributions .",
    "we have reached substantially different conclusions than previous studies of the supernova neutrinos .",
    "one of the major improvements of this work is our more thorough exploration of the space of alternative signal models , and thus it may not seem surprising that we might discover a signal component missed by others .",
    "however , this alone does not account for the differences between our results and those of others .",
    "for example , the exponential cooling model has been studied by several investigators , yet the best - fit radius we find is 70% larger than that found by spergel et al .",
    "@xcite based on a likelihood analysis , and our best - fit binding energy is over 40% larger than that found both by these investigators and by bludman and schinder @xcite , who also used a likelihood function .",
    "previous analyses of the neutrino data are extremely diverse , using a wide variety of statistics and methods",
    ". a detailed comparison of all these methods with the present analysis would be lengthy .",
    "we here choose instead to emphasize two points of departure between our analysis and earlier ones that appear to us to offer the most important lessons for analysis of data like the sn  1987a neutrino data .",
    "it is clear that there are important differences between our likelihood function and those used by others , since our best - fit parameter values ( equivalent to maximum likelihood estimates ) are significantly different from those found earlier .",
    "comparing our likelihood function , equation  ( [ ldt - iso ] ) , with those used by other investigators , several differences are apparent .",
    "most obvious , perhaps , is the presence of the background term that allows us to correctly incorporate information about the energy - dependent background rates of detectors .",
    "we have already noted , in sec .  6 ,",
    "how important such terms are for incorporating the baksan data .",
    "but we also noted that their effect on inferences using only the kii and imb data , although noticeable , is not significant compared to the uncertainties in inferred parameter values .",
    "thus these terms do not explain the differences between our results and those of others .",
    "another difference is the presence of terms to correct for deadtime .",
    "but for the most part , these terms affect only the overall amplitude of the effective signal in imb ( decreasing it by roughly 10% ) , and thus also do not account for the significant differences .",
    "the remaining difference is the absence of a factor of @xmath432 from inside each event integral in the likelihood function .",
    "that is , all previous studies replaced the integral in the product term of equation  ( [ ldt - iso ] )  with a term proportional to @xmath433 we have verified that inclusion of such an additional , incorrect @xmath434 factor indeed results in best - fit exponential cooling parameter estimates very close to those found in earlier studies .",
    "this factor reduces the low energy contribution to the integral , so that somewhat larger temperatures are needed to make the likelihoods of the events reasonably large .",
    "the expected number of detectable neutrinos varies very strongly with @xmath141 ( more strongly than @xmath435 , due to the @xmath320 dependence of the capture cross section and the strong energy dependence of @xmath436 ) , so the value of the amplitude parameter @xmath218 ( i.e. , of the neutron star radius ) found in the fit is strongly affected by the presence or absence of the @xmath434 factor , as is the binding energy , which scales like @xmath437 .",
    "the detection probability is already built into the @xmath119 function ; insertion of an additional @xmath436 factor represents an attempt to take into account a selection already accounted for in @xmath438 .",
    "this is perhaps most easily seen by considering a simple situation in which detection occurs only if the number of photomultiplier ( pmt ) `` hits '' exceeds a threshold value , @xmath439 , and the detection data for event @xmath34 is simply the number of photomultipliers hit , @xmath440 .",
    "suppose also that the probability for @xmath87 hits is a poisson distribution with a mean that is an increasing function of the event energy .",
    "the detection efficiency is the probability for hitting more than @xmath439 pmts , given the event energy .",
    "it would be calculated by summing poisson probabilities for @xmath441 .",
    "the event likelihood for event @xmath34 is the poisson probability for seeing exactly @xmath440 hits .",
    "it is _ not _ the product of this probability and the efficiency ; this product has no meaningful interpretation .",
    "we could multiply it by the product of detection , _ given _ that @xmath440 pmts were hit ( since the poisson factor already takes that into account ) .",
    "but since @xmath440 must have been larger than @xmath442 for the event to have been detected , this extra conditional probability is equal to unity .",
    "the inclusion of an @xmath443 factor in the detection likelihoods is thus incorrect .",
    "it is worth noting that straightforward application of the rules of probability theory led us to the correct likelihood in a more - or - less automated way , once we set out to calculate the probability for the data from first principles , and not merely write it down based on our intuition .",
    "the derivation is bayesian in that we freely assigned probability distributions to the energies ( and directions and positions ) of detected events , despite the fact that these quantities can not be considered to be `` random variables . ''      as noted in sec .",
    "ii , frequentist and bayesian statistics both divide questions about parameterized models into two classes . first is the class of _ estimation _ questions that assess the implications of assuming the truth of a particular model , usually by estimating values or allowed ranges for the model parameters .",
    "second is the class of _ model assessment _ questions that assess the viability of a model .",
    "we have outlined bayesian methods for treating these questions in sec .",
    "[ sec : bayes ] . a clear discussion of the application of frequentist methods for estimation and model assessment to problems in the physical sciences is available in the text by eadie ,  @xcite .",
    "frequentist procedures used for estimation are fundamentally different from those used for model assessment .",
    "unfortunately , nearly every previously published statistical analysis of these data has incorrectly used model assessment procedures to address estimation problems . in particular , a number of studies used goodness - of - fit ( gof ) procedures to specify `` confidence '' regions , based either on statistics of the kolmogorov - smirnov type @xcite , a likelihood statistic @xcite , or an ad hoc `` @xmath153 '' type statistic @xcite . in these studies , the boundary of the calculated `` confidence region '' was determined by finding parameters for which the significance level of a gof test is equal to the desired confidence level ( i.e. , significance levels were confused with confidence levels ) .",
    "such misapplication of gof procedures to parameter estimation problems is commonplace in astrophysics ; we have been guilty of it ourselves in the past .",
    "loredo and wasserman discuss the problem in detail in the context of the analysis of gamma ray burst data ( see appendix  a of @xcite ) . using a simple example based on inferring the mean of a gaussian distribution ,",
    "they show that use of a @xmath153 gof test to determine `` confidence '' regions in the manner of earlier studies not only fails to reproduce the familiar `` @xmath444 '' 68.3% confidence region , but produces an erroneous region whose average size is larger than the correct region , with an error that _ grows _ as the amount of data increases .",
    "it is interesting to speculate about why such a basic mistake is so frequently made .",
    "one reason is that , for the familiar case of gaussian statistics , the same function  the @xmath153 statistic ",
    "is used both to define the statistic used in a gof test ( the minimum value of @xmath153 ) , and the interval - valued statistic used for a confidence region ( the parameter range for which @xmath153 is within some critical value , @xmath445 , of its minimum value ) .",
    "this may have motivated those investigators who attempted to use the ks gof statistic to define confidence regions , although we know of no statistical literature suggesting that this statistic is useful for estimation problems .",
    "more fundamentally , the confusion may arise because there are several qualitatively different probabilities in frequentist statistics .",
    "covering probabilities for confidence regions , type i error probabilities , type ii error probabilities  all of these are quantities that span @xmath446 $ ] that scientists can use to assess the reasonableness of hypotheses . but",
    "none of them are probabilities _ for hypotheses _ , so it is easy for nonexperts to confuse which is most closely related to the question they are asking .",
    "this confusion is exacerbated by the fact that all frequentist probabilities must condition on a particular point hypothesis , even those that refer to an entire class of hypotheses .",
    "for some problems ( particularly for confidence region calculations ) , the hope is that the final result is independent of the particular hypothesis used .",
    "but this is seldom true in real problems , so that one hypothesis must inevitably be chosen to represent a class of hypotheses ( , approximate confidence regions are found using calculations conditioning on the best - fit hypothesis ) .",
    "this confusion can not arise in the bayesian approach .",
    "one always calculates probabilities for hypotheses , so there is never ambiguity over what kind of hypothesis a probability is associated with : one must explicitly state it in order even to start the calculation . if one seeks a measure of how plausible it is for a parameter to lie in some region , one simply calculates the probability that it is in that region ( parameter estimation ) .",
    "if instead one wishes to assess an entire model , one calculates the probability for that model as a whole ( model comparison ) . the formalism forces one to distinguish between these options .",
    "using the tools of bayesian inference , we have performed an analysis of the neutrinos from sn  1987a that differs significantly from previous analyses , both in its methodology and in its results .    methodologically , the key ingredient in our analysis is the likelihood function , and our likelihood function differs from those used in previous studies in several important respects .",
    "it more consistently accounts for the energy - dependent efficiencies of neutrino detectors , it incorporates detailed information about the background spectra of the detectors , and it accounts for dead time .",
    "our methodology allows us to carefully quantify the uncertainty in our inferences in a way that fully displays the strong correlations between inferred parameter values .",
    "also , we have studied a much wider variety of neutrino emission models than were studied previously .",
    "the bayesian approach lets us use the likelihood function to calculate probabilities for rival models that account for parameter uncertainty and implement an automatic penalty for model complexity .",
    "these features of our approach insure that our conclusions are robust with respect to model uncertainty .",
    "our calculations indicate that the neutrino data strongly favor signal models that have two components : a long timescale component due to kelvin - helmholtz cooling of the nascent neutron star , and a brief ( @xmath284  s ) , softer component due to emission from material accreting through a stalled supernova shock , as expected in the delayed scenario for supernova explosions .",
    "such models make the data significantly more probable than single - component cooling models motivated by the prompt scenario for supernova explosions .",
    "in addition , the radius and binding energy of the nascent neutron star implied by single - component models deviates significantly from the values predicted by current neutron star models , whereas those implied by models with an accretion component are in complete agreement with the predictions . as a result ,",
    "two - component models are hundreds to thousands of times more probable than single - component models .",
    "the neutrino data thus provide the first direct observational evidence in favor of the delayed scenario over the prompt scenario .",
    "furthermore , the inferred characteristics of the signal are in spectacular agreement with the salient features of the theory of gravitational collapse and neutron star structure , particularly when correlations between parameters are fully taken into account in the comparison of theory with observation .",
    "in addition to studying the implications of the neutrino data for the formation of the nascent neutron star , we have also used the data to find model - dependent upper limits on the rest mass of the electron antineutrino that are competitive with laboratory limits .",
    "the detection of neutrinos from supernova sn 1987a initiated a new era in astrophysics , the era of extrasolar neutrino astronomy .",
    "years later , the supernova neutrinos detected by the kamiokande - ii , imb , and baksan detectors are still offering us important lessons , not only about the physics of supernovae and neutrinos , but also about the potential of bayesian methods for improving the analysis of complicated astrophysical data .",
    "we would like to express our thanks to the many colleagues who have provided us with technical assistance and encouragement with respect to the work reported here .",
    "we thank yoji totsuka , al mann , soo - bong kim , weiping zhang , and the kamiokande - ii collaboration for providing unpublished information about the background rate and spectrum of the kii detector and for many valuable conversations .",
    "we similarly thank jim matthiu and jack van der velde for providing unpublished information about the irvine - michigan - brookhaven detector , and alexandar chudakov for providing unpublished information about the baksan detector .",
    "we are very grateful to h .-",
    "thomas janka for bringing us up to date on the results of supernova calculations based on the delayed explosion scenario , for guiding our development of accretion models , and for his enthusiasm for our work .",
    "we thank arya akmal for providing detailed information about recent neutron star structure calculations in electronic form .",
    "we would also like to thank the institutions whose resources have helped make this work possible . during some of this work , tjl was supported by farr , mccormick , and harper fellowships from the university of chicago , by a nasa graduate student researchers program grant ( ngt-50189 ) , and by a nasa compton gamma ray observatory fellowship ( nag 5 - 1758 ) .",
    "much of our code development , and many initial calculations , were performed with the resources of the national center for supercomputing applications at the university of illinois at urbana - champaign .",
    "additional support for this work was provided by nasa under grants nag 5 - 2762 , nag 5 - 2868 , nag 5 - 3097 , nag5 - 3427 , and by the nsf under grants ast 91 - 19475 and ast 93 - 15375 .",
    "we present here a derivation of the full likelihood function for the supernova neutrino data , equation  ( [ ltot ] ) in the main text .",
    "the calculation is straightforward and the result is easy to understand , as explained in sec .",
    "however , we make some effort here to go through it in detail , both to reveal several errors that were made in previous studies , and to demonstrate how straightforward the calculation of such likelihoods is from a bayesian perspective .",
    "loredo and wasserman @xcite  used similar methods to derive likelihood functions for bayesian analyses of gamma - ray burst data .",
    "as with the derivation of the idealized likelihood in sec .",
    "iii , we first consider the probability for nondetections . to do this , we will use a standard `` trick '' from probability theory that frequently arises in bayesian calculations .",
    "when we can not directly calculate @xmath447 , we introduce an exhaustive , exclusive set of auxiliary propositions , @xmath448 ( one and only one of the @xmath120 must be true ) , such that we can calculate @xmath449 .",
    "then we can find the the desired probability from @xmath450 provided we can calculate or specify @xmath451 . if the @xmath120 form a continuum , the sum becomes an integral .",
    "this trick is sometimes referred to as `` extending the conversation . ''    to apply this trick to calculate @xmath452 , we begin by noting that there are many situations that can result in a nondetection .",
    "if neither a signal nor background event occurs , no detection will be reported .",
    "but even if one or more signal or background event occurs , it is possible no event will be reported , because of the instrument threshold . if we let @xmath453 denote the proposition that @xmath454 signal events occurred in the time interval under consideration , and @xmath455 denote the proposition that @xmath87 background events occurred , then we can write the nondetection probability as @xmath456 each term will involve poisson probabilities for @xmath454 signal events , proportional to @xmath457 , and @xmath87 background events , proportional to @xmath458 . since the @xmath78 intervals are small ( in the sense that @xmath459 and @xmath460 ) , we can neglect possibilities involving more than one event occurring in @xmath78 .",
    "this leaves three possibilities .",
    "@xmath461    to calculate the first term , we first apply the product rule , writing",
    "@xmath462 here we have dropped @xmath71 from the right of the bar in the first probability , since it is irrelevant to @xmath80 once we specify that no events have occurred . also , we factored the joint probability of @xmath463 as the product of their independent probabilities to get the last two factors .",
    "the first factor  the probability for reporting no detection if neither a signal nor a background event occurs  is simply equal to 1 .",
    "the second and third factors are simply given by the poisson probability for no event , given the expected number in @xmath78 ( c.f .",
    "equation  ( [ pois-0 ] ) ) .",
    "thus @xmath464\\delta t}. \\label{pnd-1}\\ ] ]    to calculate the second term in equation  ( [ pnd3 ] ) , we extend the conversation , resolving @xmath465 into a continuum of @xmath93 propositions .",
    "this gives @xmath466 the first factor in the integrand is the probability that a signal event occurring at a specified position , with a specified energy and direction , will lead to a nondetection .",
    "we presume that the experiment team can calculate this probability by detailed modeling of the detector ( perhaps including results of calibration measurements ) .",
    "it is simply the probability that the specified event will produce triggers that do not satisfy the detection criterion .",
    "we write this probability as @xmath467 where @xmath468 is the detection efficiency for events with the specified position , energy and direction ; we call this the _ full _ detection efficiency",
    ".    the second factor in the integrand of equation  ( [ pnd-2 - 1 ] )  is the probability for detecting the specified signal event , and no other , in @xmath83 .",
    "it is simply given by the poisson distribution : @xmath469    the third factor in the integrand of equation  ( [ pnd-2 - 1 ] )  is the probability for no background events that we needed for the first term in the nondetection probability , equal to @xmath470 .",
    "we thus have all the factors needed to calculate equation  ( [ pnd-2 - 1 ] ) .",
    "since only the full efficiency factor depends on @xmath64 , we can pull the signal rate through the volume integral , writing @xmath471\\delta t } \\int d\\drxn \\int d\\epos\\ ;        r(\\drxn,\\epos , t_j)[1-\\bar\\eta(\\drxn,\\epos ) ] \\nonumber \\\\    & = & e^{-[b + r_\\epos(t_j)]\\delta t }       \\left [ r(t_j)\\delta t -               \\delta t \\int d\\drxn\\int d\\epos\\ ;                     r(\\drxn,\\epos , t_j)\\bar\\eta(\\drxn,\\epos)\\right ] .",
    "\\label{pnd-2 - 3}\\end{aligned}\\ ] ] here we have defined the _ volume - averaged _ detection efficiency according to @xmath472 we can write equation  ( [ pnd-2 - 3 ] )  more succinctly by introducing an effective ( detectable ) signal rate , @xmath473 using this , equation  ( [ pnd-2 - 3 ] )  becomes @xmath474\\delta t}\\ , \\delta t         [ r(t_j ) - \\reff(t_j)].\\label{pnd-2 - 3-eff}\\ ] ]    the last probability we need in order to calculate the nondetection probability  the last term in equation  ( [ pnd3])is very similar to the one we have just calculated . we can get it simply by switching the roles of background and signal , taking into account the fact that the background rate may depend on position and direction . this gives @xmath475\\delta t}\\ ,       \\delta t ( b - \\beff ) ,     \\label{pnd-3}\\ ] ] where the effective background rate is given by @xmath476 we can not use @xmath477 here because @xmath60 is a function of position in the detector ( e.g. , due to radioactivity in the rock surrounding the detector ) .",
    "we have presumed here that the full efficiency for detecting a background event with specified position , direction , and energy is the same as that for detecting a signal event with the same properties .",
    "that is , we are assuming that the detector does not distinguish background and signal events by some other property .",
    "assembling all of the ingredients , we can now write down the full nondetection probability : @xmath478\\delta t }    \\left(1 + \\delta t[r(t_j ) + b ] -       \\delta t[\\reff(t_j ) + \\beff]\\right).\\label{pnd}\\ ] ] since we will need the product of many such probabilities , its logarithm is easier to work with .",
    "taking advantage of the fact that @xmath479 and @xmath460 , and using @xmath480 for small @xmath481 , we find @xmath482    \\approx - \\delta t[\\reff(t_j ) + \\beff].\\label{log - pnd}\\ ] ] the product of all the nondetection probabilities will thus be an exponential with sums of the effective rates over all nondetection intervals .",
    "this sum is just the integral of the effective rates over the nondetection intervals , so the product of nondetection probabilities can be written @xmath483,\\label{pnd - prod}\\ ] ] where @xmath484 denotes integration of the ( disjoint ) intervals of time without detections .",
    "now we turn to the detection probabilities .",
    "a reported event can be either a signal or a background event , so we have @xmath485 as with the nondetection probability , we ignore possibilities that are higher than first order in @xmath78 .",
    "we can calculate the first term by introducing @xmath93 and applying the product rule , just as we did in equation  ( [ pnd-2 - 1 ] ) .",
    "the result is @xmath486\\delta t\\right).\\label{pd-1}\\ ] ] here we have defined the _",
    "individual event likelihood function _ according to @xmath487",
    "this is just the probability for observing the detection data , presuming the location , direction , and energy of the lepton producing the data have the specified values .",
    "it is the likelihood function we would use to infer the properties of a particular detected event .",
    "detailed knowledge of the detector should allow experimenters to calculate this function for each detected event ( by fitting the pmt data ) . since @xmath488 is a probability for @xmath79 , it need not be normalized when integrated over @xmath95 .",
    "however , @xmath119 can be multiplied by any constant without affecting our inferences ( since the constant will drop out in bayes s theorem ) , and we will find it convenient to adopt the convention that the reported individual likelihood functions include a constant that makes them normalized when integrated over @xmath95 .    the second term in equation  ( [ pd2 ] )  can be calculated in exactly the same way , switching the roles of the signal and background rates .",
    "combining this term with equation  ( [ pd-1 ] ) gives us the detection probability , @xmath489\\delta t }    \\int d\\epos \\int dv \\int d\\drxn\\ ;   \\like_i(\\rvec,\\drxn,\\epos)\\ ,       \\left[{r(\\drxn,\\epos , t_i)\\over v } +               b(\\rvec,\\drxn,\\epos)\\right].\\label{pd - full}\\ ] ] we can take advantage of the homogeneity of the signal rate to replace the signal - dependent integral with @xmath490 where the volume - averaged event likelihood function is given by @xmath491 . we retain the simple likelihood notation for this and other averaged likelihoods , because this is in fact the likelihood for the direction and energy : @xmath492 taking the prior density for the event position to be uniform throughout the tank reveals @xmath121 to be the volume - averaged event likelihood , as claimed .    to further simplify the appearance of our equations , we introduce the event - averaged background rate , @xmath120 , according to @xmath493 with our convention of normalizing @xmath119 ,",
    "this can be interpreted as the rate of background events `` like '' event number @xmath34 in the sense of having positions , directions , and energies consistent with the data for that event .",
    "these definitions let us write the detection probability as @xmath494\\delta t\\right )    \\left[b_i\\delta t + \\int d\\epos \\int d\\drxn\\,\\like_i(\\drxn,\\epos)\\ ,        r(\\drxn,\\epos , t_i)\\right ] .",
    "\\label{pd - simp}\\ ] ]    combining the detection and nondetection probabilities gives us the full likelihood function , @xmath495 \\nonumber \\\\    & \\quad\\times \\prod_{i=1}^\\nd     \\left[b_i + \\int d\\epos \\int d\\drxn\\,\\like_i(\\drxn,\\epos)\\ ,               r(\\drxn,\\epos , t_i)\\right ] .",
    "\\label{ltot - b}\\end{aligned}\\ ] ] here we have combined the exponentials in the detection factors appearing in equation  ( [ pd - simp ] )  with the exponents in the nondetection probabilities to give an integral over the _ entire _ duration of the data . in doing so",
    ", we have neglected the difference between the full and effective rates in the @xmath59 detection intervals ; but this difference is very small provided that @xmath496 , and one can easily demonstrate that it has a negligible effect on inferences .",
    "one last simplification can be made . since scaling by a parameter - independent factor",
    "does not affect our inferences , we can drop the @xmath497 factor and the @xmath498 exponent from the likelihood .",
    "this leads to equation  ( [ ltot ] ) , the full likelihood used in the main text .",
    "in table  [ table : ks ] we present the results of two - dimensional kolmogorov - smirnov ( ks ) goodness - of - fit tests applied to the constant temperature / radius model , the exponential cooling model , and the model combining displaced power - law cooling and truncated accretion , each with parameters fixed at their best - fit values .",
    "we used the version of the test devised by fasano and franceschini @xcite .",
    "this test compares the fraction of the expected rate in four quadrants about the point @xmath499 associated with each event with the fraction of the number of detected events in that quadrant .",
    "the largest difference between the observed and expected values is the ks statistic , @xmath6 .",
    "the model is rejected if @xmath6 is too large , the typical critical value being that associated with a 95% false rejection rate .",
    "this test ignores the uncertainty in @xmath500 for each event , and the quoted significance values are approximate ( they are based on an approximate expression for the distribution for @xmath6 ) .",
    "we performed the test separately for each detector ( using the best - fit parameters from a joint fit ) , and then combined the test results using standard methods to find the significance associated with the joint fit @xcite .",
    "these results indicate moderate incompatibility of the data with the constant temperature model , and compatibility with the other models .",
    "bayesian inference does not include such a thing as an alternative - free goodness - of - fit test ; we provide these tests for those readers who find them useful .",
    "ks tests have several limitations that must be kept in mind when interpreting their results .",
    "first , the one - dimensional and two - dimensional ks tests are sensitive only to the shape of a distribution , not its amplitude . the test may be straightforwardly extended to include the amplitude , but the resulting test then becomes insensitive to the shape of the distribution for the supernova neutrino data because poisson fluctuations in the number of events detected , rather than the positions of the events in the time - energy plane , dominate @xmath6 .",
    "second , the two - dimensional test lacks the distribution - free property that makes the one - dimensional test attractive .",
    "in fact , there are different generalizations of the test to two dimensions , each with different sensitivity to the parent distribution @xcite .",
    "thus , the test should ideally be calibrated with extensive monte carlo calculations .",
    "finally , the reliance of the test on the cumulative distribution of events , rather than the differential distribution , can make it insensitive to local structure present in the model ( e.g. , it can accept a model even if there are data in regions of zero probability ) .    on a more subjective level ,",
    "our extensive experience with application of this test to these data has led us to be skeptical of its value .",
    "we have found it to be quite insensitive , accepting models that seem clearly unacceptable on other grounds ( either to the trained eye or based on tests with likelihood functions ) . some evidence of this behavior is obvious here : the best - fit cooling and accretion models have comparable values of @xmath501 , despite the fact that the latter model makes the data over 600 times more probable than the former .",
    "finally , we note that some earlier studies attempted to assess joint fits by applying a single ks test to a fictitious `` sum '' detector whose expected rate is the sum of the rates of the considered detectors , and whose data is the collected data of the detectors @xcite .",
    "this procedure corrupts the test , as it ignores information about which events to associate with which expected rate .",
    "we have found that some models that are accepted with a ks test based on such a `` sum '' detector can be rejected by a combination of tests applied to the individual detectors , and vice versa .",
    "this is because no detected event represents a sample of the summed detector rates , leading to erroneous results when the test is performed with the `` sum '' detector .",
    "t. piran and d. n.spergel , in _ proceedings of the xxiiird moriond astrophysics meeting on dark matter _ ,",
    "edited by j. audouze and j. tran thanh van ( editions frontieres , france , 1988 ) , p. 453 .",
    "janka and w. hillebrandt ,  _ suppl . _ * 78 * , 375 ( 1989 ) .",
    "t. j. loredo , in _ astronomical data analysis software and systems viii _",
    "( asp conf .",
    "172 ) , edited by d. m. mehringer , r. l. plante , and d. a. roberts ( astronomical society of the pacific , san francisco ) , 297 ( 1999 ) .",
    "the bayes factor depends on the prior ranges for the parameters ( see eqn .",
    "[ ockham - app2 ] ) .",
    "for the parameters common to both models , the ranges used were : @xmath502 $ ]  km for @xmath218 ; @xmath503 $ ]  s for offset times . for the exponential model ,",
    "the ranges were : @xmath504 $ ]  mev for @xmath309 ; @xmath505 $ ]  s for @xmath123 .",
    "for the cooling plus accretion model , the ranges were : @xmath504 $ ]  mev for @xmath343 ; @xmath506 $ ]  s for @xmath344 ; @xmath507 $ ]  mev for @xmath252 ; @xmath508 $ ]  s for @xmath255 . in the light of theoretical expectations , these are generous ( and thus conservative ) prior ranges for the individual parameters .",
    "w. hillebrandt , p. h \" oflich , h .- th .",
    "janka , and r. m \" onchmeyer , in _ big bang , active galactic nuclei , and supernovae _ , proceedings of the 20th yamada conference , edited by s. hayakawa and k. sato , ( universal academy press , 1989 ) , p. 441 .",
    "rdddc & @xmath82 & @xmath509 & @xmath146 & @xmath120 + event & ( s ) & ( mev ) & ( mev ) & ( s@xmath130 ) +   + 1 & @xmath510 0.0 & 20.0 & 2.9 & @xmath511 + 2 & 0.107 & 13.5 & 3.2 & @xmath512 + 3 & 0.303 & 7.5 & 2.0 & @xmath513 + 4 & 0.324 & 9.2 & 2.7 & @xmath514 + 5 & 0.507 & 12.8 & 2.9 & @xmath515 + 6 & 0.686 & 6.3 & 1.7 & @xmath516 + 7 & 1.541 & 35.4 & 8.0 & @xmath517 + 8 & 1.728 & 21.0 & 4.2 & @xmath518 + 9 & 1.915 & 19.8 & 3.2 & @xmath519 + 10 & 9.219 & 8.6 & 2.7 & @xmath520 + 11 & 10.433 & 13.0 & 2.6 & @xmath521 + 12 & 12.439 & 8.9 & 1.9 & @xmath522 + 13 & 17.641 & 6.5 & 1.6 & @xmath523 + 14 & 20.257 & 5.4 & 1.4 & @xmath513 + 15 & 21.355 & 4.6 & 1.3 & @xmath524 + 16 & 23.814 & 6.5 & 1.6 & @xmath523 +   + 1 & @xmath510 0.0 & 38 & 7 & 0 + 2 & 0.412 & 37 & 7 & 0 + 3 & 0.650 & 28 & 6 & 0 + 4 & 1.141 & 39 & 7 & 0 + 5 & 1.562 & 36 & 9 & 0 + 6 & 2.684 & 36 & 6 & 0 + 7 & 5.010 & 19 & 5 & 0 + 8 & 5.582 & 22 & 5 & 0 +   + 1 & @xmath510 0.0 & 12.0 & 2.4 & @xmath525 + 2 & 0.435 & 17.9 & 3.6 & @xmath526 + 3 & 1.710 & 23.5 & 4.7 & @xmath527 + 4 & 7.687 & 17.6 & 3.5 & @xmath526 + 5 & 9.099 & 20.3 & 4.1 & @xmath526 +    lcc quantity & kii  imb  baksan & kii",
    " imb +   + @xmath218 & 3.20 & 2.43 + @xmath309 ( mev ) & 3.30 & 3.51 + @xmath229 ( s ) & 10.43 & 10.43 + @xmath528 & & + @xmath529 ( kii ) & 16.6 + 5.6 & 13.6 + 5.6 + @xmath529 ( imb ) & 4.3 & 4.1 + @xmath529 ( baksan ) & 1.8 + 1.0 &  + @xmath31 ( km ) & 32.0 & 24.3 + @xmath275 ( @xmath530 erg ) & 4.30 & 3.19 +   + @xmath218 & 6.69 & 5.63 + @xmath309 ( mev ) & 3.43 & 3.61 + @xmath123 ( s ) & 1.75 & 1.61 + @xmath528 & 1.77 & 1.66 + @xmath529 ( kii ) & 15.1 + 5.6 & 13.0 + 5.6 + @xmath529 ( imb ) & 4.0 & 4.0 + @xmath529 ( baksan ) & 1.6 + 1.0 &",
    " + @xmath31 ( km ) & 66.9 & 56.3 + @xmath275 ( @xmath530 erg ) & 3.68 & 2.93 +   + @xmath218 & 4.02 & 3.42 + @xmath309 ( mev ) & 3.81 & 3.98 + @xmath123 ( s ) & 4.37 & 3.97 + @xmath528 & 1.0 & 1.0 + @xmath529 ( kii ) & 16.9 + 5.6 & 14.4 + 5.6 + @xmath529 ( imb ) & 4.0 & 3.9 + @xmath529 ( baksan ) & 1.8 + 1.0 &",
    " + @xmath31 ( km ) & 40.2 & 34.2 + @xmath275 ( @xmath530 erg ) & 5.02 & 3.96 +   + @xmath218 & 4.72 & 4.05 + @xmath309 ( mev ) & 4.02 & 4.17 + @xmath123 ( s ) & 1.30 & 1.24 + @xmath242 & 0.34 & 0.34 + @xmath528 & 7.8 & 4.5 + @xmath529 ( kii ) & @xmath531 & @xmath532 + @xmath529 ( imb ) & 3.8 & 3.7 + @xmath529 ( baksan ) & @xmath533 &",
    " + @xmath31 ( km ) & 47.2 & 40.5 + @xmath275 ( @xmath530 erg ) & 10.2 & 8.33 +   +   + @xmath218 & 2.44 & 2.20 + @xmath309 ( mev ) & 4.01 & 4.16 + @xmath534 ( s ) & 1.32 & 1.30 + @xmath123 ( s ) & 5.49 & 4.82 + @xmath535 & 15.4 & 13.3 + @xmath536 ( kii ) ( s ) & 0.71 & 0.70 + @xmath536 ( imb ) ( s ) & 1.09 & 1.06 + @xmath536 ( baksan ) ( s ) & 0.74 &  + @xmath528 & 5.5 & 1.4 + @xmath529 ( kii ) & @xmath537 & @xmath538 + @xmath529 ( imb ) & 4.2 & 4.0 + @xmath529 ( baksan ) & @xmath539 &",
    " + @xmath31 ( km ) & 24.4 & 22.0 + @xmath275 ( @xmath530 erg ) & 28.3 & 19.6 +    lcc quantity & kii  imb  baksan & kii ",
    "imb +   +   + @xmath218 & 1.71 & 1.48 + @xmath343 ( mev ) & 4.56 & 4.83 + @xmath344 ( s ) & 5.15 & 4.39 + @xmath540 ( mev ) & 2.02 & 1.96 + @xmath255 ( s ) & 0.74 & 0.76 + @xmath224 & 0.5 & 0.5 + @xmath528 & 577 & 101 + @xmath529 ( kii ) & @xmath541 & @xmath542 + @xmath529 ( imb ) & 4.5 & 4.3 + @xmath529 ( baksan ) & @xmath543 &  + @xmath31 ( km ) & 17.1 & 14.8 + @xmath275 ( @xmath530 erg ) & 2.84 ( 0.63 ) & 2.31 ( 0.54 ) +   +   + @xmath218 & 1.80 & 1.58 + @xmath343 ( mev ) & 4.64 & 4.89 + @xmath344 ( s ) & 14.7 & 12.5 + @xmath540 ( mev ) & 2.00 & 1.94 + @xmath255 ( s ) & 0.74 & 0.76 + @xmath224 & 0.5 & 0.5 + @xmath528 & 624 & 118 + @xmath529 ( kii ) & @xmath532 & @xmath544 + @xmath529 ( imb ) & 4.5 & 4.3 + @xmath529 ( baksan ) & @xmath543 &  + @xmath31 ( km ) & 18.0 & 15.8 + @xmath275 ( @xmath530 erg ) & 3.08 ( 0.61 ) & 2.53 ( 0.51 ) +   +   + @xmath218 & 5.75 & 4.79 + @xmath343 ( mev ) & 3.73 & 3.94 + @xmath344 ( s ) & 1.31 & 1.20 + @xmath540 ( mev ) & 1.88 & 1.82 + @xmath255 ( s ) & 0.73 & 0.76 + @xmath224 & 0.5 & 0.5 + @xmath528 & 138 & 32 + @xmath529 ( kii ) & @xmath545 & @xmath546 + @xmath529 ( imb ) & 4.34 & 4.2 + @xmath529 ( baksan ) & @xmath547 &  + @xmath31 ( km ) & 57.5 & 47.9 + @xmath275 ( @xmath530 erg ) & 3.26 ( 0.40 ) & 2.61 ( 0.35 ) +   +   + @xmath218 & 1.99 & 1.76 + @xmath343 ( mev ) & 4.47 & 4.72 + @xmath344 ( s ) & 20.1 & 16.9 + @xmath540 ( mev ) & 2.00 & 1.94 + @xmath255 ( s ) & 0.74 & 0.76 + @xmath224 & 0.5 & 0.5 + @xmath528 & 399 & 81 + @xmath529 ( kii ) & @xmath548 & @xmath549 + @xmath529 ( imb ) & 4.5 & 4.3 + @xmath529 ( baksan ) & @xmath543 &  + @xmath31 ( km ) & 19.9 & 17.6 + @xmath275 ( @xmath530 erg ) & 2.77 ( 0.61 ) & 2.27 ( 0.51 ) +   +   + @xmath218 & 2.33 & 2.01 + @xmath343 ( mev ) & 4.10 & 4.32 + @xmath344 ( s ) & 5.43 & 4.74 + @xmath540 ( mev ) & 2.45 & 2.40 + @xmath255 ( s ) & 0.05 & 0.05 + @xmath224 & 0.5 & 0.5 + @xmath528 & 384 & 32 + @xmath529 ( kii ) & @xmath550 & @xmath551 + @xmath529 ( imb ) & 4.1 & 3.9 + @xmath529 ( baksan ) & @xmath539 &  + @xmath31 ( km ) & 23.3 & 20.1 + @xmath275 ( @xmath530 erg ) & 3.27 ( 0.44 ) & 2.64 ( 0.40 ) +    rcc event & cooling & accretion +   + 1 & @xmath552 & @xmath553 + 2 & @xmath554 & @xmath521 + 3 & 0.16 & @xmath555 + 4 & @xmath556 & @xmath557 + 5 & @xmath558 & @xmath559 + 6 & 0.25 & 0.15 + 7 & @xmath527 & @xmath560 + 8 & @xmath561 & @xmath562 + 9 & @xmath563 & @xmath564 + 10 & 0.33 & 0.49 + 11 & 0.11 & 0.12 + 12 & 0.54 & 0.60 + 13 & 0.92 & 0.89 + 14 & 0.97 & 0.94 + 15 & 0.97 & 0.93 + 16 & 0.99 & 0.94 +   + 1 & @xmath565 & @xmath566 + 2 & @xmath567 & @xmath568 + 3 & @xmath569 & 0.12 + 4 & 0.30 & 0.35 + 5 & 0.55 & 0.52 +    lc quantity & kii  imb  baksan +   +   + @xmath218 & 1.78 + @xmath343 ( mev ) & 4.65 + @xmath344 ( s ) & 14.7 + @xmath540 ( mev ) & 2.04 + @xmath255 ( s ) & 0.56 + @xmath224 & 0.5 + @xmath4 ( ev ) & 3.02 + @xmath536 ( kii ) ( ms ) & 0.07 + @xmath536 ( imb ) ( ms ) & 0.04 + @xmath536 ( baksan ) ( ms ) & 0.13 + @xmath428 & 2.3 + @xmath529 ( kii ) & @xmath570 + @xmath529 ( imb ) & 4.5 + @xmath529 ( baksan ) & @xmath543 + @xmath31 ( km ) & 17.8 + @xmath275 ( @xmath530 erg ) & 3.04 ( 0.56 ) +    lcccc quantity & kii & imb & baksan & joint +   + @xmath571 & 0.38 & 0.45 & 0.52 &  + @xmath501 & @xmath572 & @xmath573 & @xmath574 & @xmath575 +   + @xmath571 & 0.31 & 0.28 & 0.38 &  + @xmath501 & 0.12 & 0.53 & 0.37 & 0.27 +   +   + @xmath571 & 0.27 & 0.23 & 0.37 & ",
    "+ @xmath501 & 0.25 & 0.77 & 0.39 & 0.52 +"
  ],
  "abstract_text": [
    "<S> we present a bayesian analysis of the energies and arrival times of the neutrinos from supernova sn 1987a detected by the kamiokande ii , imb , and baksan detectors , and find strong evidence for two components in the neutrino signal : a long time scale component from thermal kelvin - helmholtz cooling of the nascent neutron star , and a brief ( @xmath0 s ) , softer component similar to that expected from emission by accreting material in the delayed supernova scenario . in the context of this model , we show that the data constrain the electron antineutrino rest mass to be less than 5.7  ev with 95% probability . </S>",
    "<S> our analysis takes advantage of significant advances that have occured in the years since the detections in both our understanding of the supernova mechanism and our ability to analyze sparse data . </S>",
    "<S> this has led to significant improvement over previous studies in two important respects . </S>",
    "<S> first , our comparison of the data with parameterized models of the neutrino emission uses a consistent and straightforward bayesian statistical methodology . </S>",
    "<S> this methodology helps us distinguish the complementary tasks of parameter estimation and model assessment , and fully accounts for the strong , nonlinear correlations between inferred values of neutrino emission model parameters . </S>",
    "<S> it also clarifies and improves the derivation of the likelihood function ( the probability for the data ) , improving on earlier derivations in two ways : more consistent accounting for the energy - dependent efficiencies of the detectors ; and inclusion of the empirically measured detector background spectra . </S>",
    "<S> these improvements lead to significant differences between our inferences and those found in earlier studies . </S>",
    "<S> inclusion of detector background spectra proves crucial for proper analysis of the baksan data and for demonstrating its consistency with data from other detectors . </S>",
    "<S> second , we compare the data with a much wider variety of neutrino emission models than was explored previously , several of them inspired by recent numerical calculations of collapse and explosion based on the delayed supernova mechanism . </S>",
    "<S> this allows us to compare predictions of both the prompt and delayed mechanisms with the data , and insures that our conclusions are robust . </S>",
    "<S> we find that two - component models for the neutrino signal are @xmath1 times more probable than single - component models . </S>",
    "<S> moreover , single - component models imply a radius and binding energy for the nascent neutron star significantly larger than those implied by even the stiffest acceptable equations of state for neutron star matter . in contrast , the radius and binding energy implied by two - component models are in agreement with predictions . </S>",
    "<S> taking this agreement with prior expectations into account increases the odds in favor of two - component models by more than an order of magnitude . </S>",
    "<S> the inferred characteristics of the neutrino emission are in spectacular agreement with the salient features of the theory of stellar collapse and neutron star formation that had developed over several decades in the absence of direct observational data . </S>",
    "<S> we compare our work with previous work that used more conventional `` frequentist '' methods ( including our own previous maximum likelihood analysis ) . </S>",
    "<S> we identify several methodological and technical weaknesses in earlier analyses , and show how these are overcome in our bayesian analysis .    </S>",
    "<S> # 1@xmath2_[#1]_@xmath2 </S>"
  ]
}