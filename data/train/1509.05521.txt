{
  "article_text": [
    "this article is dedicated to the construction of anisotropic sparse quadrature methods , where we emphasize on gaussian type quadratures .",
    "anisotropic sparse quadrature methods methods can be seen as a generalization sparse smolyak type quadratures , cf.@xcite , since they are explicitly tailored to the anisotropic behaviour of the underlying integrand . exploiting these anisotropies",
    "leads to a remarkable improvement in the complexity of the sparse quadrature .",
    "the main task in estimating the quadrature s complexity is the estimation of the number of multi - indices which are contained in the sparse tensor product index set . for the isotropic variant , the number of indices can easily be determined by combinatorial arguments , see e.g.  @xcite .",
    "things get more involved if one considers weighted sparse tensor product spaces . in this case , to the best of our knowledge , only very rough estimates on the cardinality of the index set are known , although several estimates can be found in the literature , see e.g.  @xcite .",
    "in fact , this problem is equivalent to the estimation of the number of integer solutions of linear diophantine inequalities ( see @xcite and the references therein ) , which is a problem in number theory , or to the calculation of the integer points in a convex polyhedron .",
    "current estimates are not sharp and do not provide improved complexity results for the anisotropic sparse quadrature in comparison with the anisotropic full tensor product quadrature . in this article , we prove a novel formula to estimate the cardinality of the sparse tensor product index set in the weighted case .",
    "this formula is much sharper than the other established formulae .    a very popular application that requires efficient high - dimensional quadrature rules are parametric partial differential equations .",
    "they are obtained , for example , from partial differential equations with random data by truncating the series expansions of the underlying random fields and parametrizing with respect to the random fields distribution . as a representative for such problems",
    ", we will consider here elliptic diffusion problems with random coefficients as a specific example to quantify the performance of the anisotropic sparse quadrature . the resulting quadrature approach is very similar to the anisotropic sparse collocation method based on gaussian collocation points which has been introduced in @xcite .",
    "this method interpolates the random solution in certain collocation points and represents it in the parameter space with the aid of polynomials .",
    "thus , it belongs to the class of non - intrusive methods , cf .",
    "@xcite . instead of representing the random solution ,",
    "the anisotropic sparse quadrature can be employed to directly compute the solutions statistics , i.e.  its moments , and functionals of the solution .",
    "the remainder of this article is organized as follows .",
    "section  [ sec : spde ] specifies the quadrature problem under consideration and provides the corresponding framework .",
    "the subsequent section  [ sec : anisogauss ] is dedicated to the sparse anisotropic gaussian quadrature method . here , we present the construction of the sparse quadrature and provide related error estimates based on a one dimensional , generic estimate .",
    "section  [ sec : cost ] deals with the cost complexity of the anisotropic sparse quadrature .",
    "in particular , we state here a novel estimate on the number of indices in the weighted sparse tensor product and provide a proof of this estimate . in section  [ sec : application ] , we introduce diffusion problems with random coefficients as a relevant application that profits from the improved quadrature methods .",
    "a couple of numerical examples that are related to the application under consideration are given in section  [ sec : numres ] .",
    "note that , in order to show the asymptotic convergence behaviour of the anisotropic quadrature , we restricted ourselves to one - dimensional examples .",
    "this is to avoid dealing with the increased computational complexity of our solver in higher spatial dimensions .",
    "finally , we state concluding remarks in section  [ sec : conclusion ] .    throughout this article , in order to avoid the repeated use of generic but unspecified constants , by @xmath0 we mean that @xmath1 can be bounded by a multiple of @xmath2 , independently of the parameters which @xmath1 and @xmath2 may depend on .",
    "obviously , @xmath3 is defined as @xmath4 , and @xmath5 as @xmath0 and @xmath3 .",
    "let @xmath6 be a bounded or unbounded interval and denote by @xmath7 the set of all sequences @xmath8 , where @xmath9 .",
    "for a function @xmath10 and a suitable product density function @xmath11 , we are interested in the efficient approximation of the integral @xmath12 at first , we have to state more precisely how this integral has to be understood .",
    "to that end , we endow @xmath7 with the structure of a probability space @xmath13 in the usual way : let @xmath14 denote the borel @xmath15-field on @xmath16 .",
    "then , the borel @xmath15-field @xmath17 on @xmath7 is induced by the generating sets @xmath18 with this construction of @xmath17 at hand , the measure @xmath19 with @xmath20 defines a probability measure on @xmath17 .    in order to approximate numerically",
    ", we assume that there exists a sequence @xmath21 such that @xmath22 where @xmath23 , with a strictly decreasing null sequence @xmath24 . in the sequel ,",
    "we aim at approximating @xmath25 by the anisotropic sparse tensor product quadrature .",
    "it is evident that the precision of the applied quadrature has to increase when @xmath26 increases .",
    "moreover , the complexity usually scales exponentially in @xmath26 , which is referred to as the `` curse of dimensionality '' .",
    "therefore , we have to keep track of the impact of the dimension @xmath26 on the error estimates",
    ". to make this impact as mild as possible , we have to impose a special structure of the function @xmath27 and the approximations @xmath28 , respectively .",
    "[ ass : anaextension ] let @xmath29 and assume that @xmath27 is analytically extendable into @xmath30 for an isotone sequence @xmath31 .",
    "in addition , we suppose that @xmath28 is analytically extendable into @xmath32 .",
    "the sequence @xmath33 measures the anisotropic dependence of the function @xmath27 on the different dimensions .",
    "especially , in accordance with e.g.  @xcite and section  [ sec : application ] , assumption [ ass : anaextension ] guarantees that an @xmath34-point gaussian quadrature formula constructed with respect to the densities @xmath35 satisfies an one - dimensional error estimate of the form @xmath36 for some functions @xmath37 and @xmath38 $ ] .",
    "here and in the sequel , we set @xmath39 for a suitable weight function @xmath40 . in the following presentation , we restrict ourselves to sparse gaussian quadrature formulae .",
    "even so , we emphasize that the approach under consideration is not limited to them",
    ". any quadrature is feasible that satisfies a one dimensional error estimate which is similar to .",
    "we shall introduce anisotropic sparse gaussian quadrature formulae which extend the original idea of smolyak s construction from @xcite . to that end , we start by considering an increasing sequence of univariate gaussian quadrature points @xmath41 where @xmath42 .",
    "the associated gaussian quadrature weights are denoted by @xmath43 and the associated gaussian quadrature operators are denoted by @xmath44 .    following the notation of @xcite",
    ", we introduce for @xmath45 the difference quadrature operator @xmath46 with the telescoping sum @xmath47 , the isotropic @xmath26-fold tensor product quadrature operator , which uses in each direction @xmath48 quadrature points , can be written by @xmath49 where the superscript index indicates the particular dimension .",
    "the cost of applying the isotropic full tensor product quadrature operator is obviously given by the number of points @xmath50 contained in it .",
    "thus , this isotropic tensor product quadrature extremely suffers from the curse of dimensionality .",
    "the classical _ sparse gaussian quadrature _ , cf .",
    "@xcite , can overcome this problem up to a certain extent .",
    "it is based on linear combinations of tensor product quadrature formulae of relatively small size . to define the sparse gaussian quadrature",
    ", we introduce as in @xcite for each _ approximation level _ @xmath51 the sets of multi - indices @xmath52 and @xmath53 the smolyak quadrature operator , cf .",
    "@xcite , is then given by @xmath54 an equivalent expression is obtained by the _ combination technique _",
    "@xcite @xmath55 a visualization of the set of indices @xmath56 is given in figure [ fig : indicessparse ] .",
    "( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 4.1,0.1 ) rectangle ( 4.9,0.9 ) ; ( 5.1,0.1 ) rectangle ( 5.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 3.1,1.1 ) rectangle ( 3.9,1.9 ) ; ( 4.1,1.1 ) rectangle ( 4.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ; ( 1.1,2.1 ) rectangle ( 1.9,2.9 ) ; ( 2.1,2.1 ) rectangle ( 2.9,2.9 ) ; ( 3.1,2.1 ) rectangle ( 3.9,2.9 ) ; ( 0.1,3.1 ) rectangle ( 0.9,3.9 ) ; ( 1.1,3.1 ) rectangle ( 1.9,3.9 ) ; ( 2.1,3.1 ) rectangle ( 2.9,3.9 ) ; ( 0.1,4.1 ) rectangle ( 0.9,4.9 ) ; ( 1.1,4.1 ) rectangle ( 1.9,4.9 ) ; ( 0.1,5.1 ) rectangle ( 0.9,5.9 ) ;    ( 0,0 )  ( 6.5,0 ) node[right ] @xmath57 ; ( 0,0 )  ( 0,6.5 ) node[above ] @xmath58 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 0pt,2pt ) ",
    "( 0pt,-2pt ) node[below ] @xmath59 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 2pt,0pt )  ( -2pt,0pt ) node[left ] @xmath60 ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ;    ( 0,0 )  ( 6.5,0 ) node[right ] @xmath61 ; ( 0,0 ) ",
    "( 0,6.5 ) node[above ] @xmath62 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 0pt,2pt )  ( 0pt,-2pt ) node[below ] @xmath59 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 2pt,0pt )  ( -2pt,0pt ) node[left ] @xmath60 ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ;    ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ; ( 1.1,2.1 ) rectangle ( 1.9,2.9 ) ; ( 0.1,3.1 ) rectangle ( 0.9,3.9 ) ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 4.1,0.1 ) rectangle ( 4.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 3.1,1.1 ) rectangle ( 3.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ; ( 1.1,2.1 ) rectangle ( 1.9,2.9 ) ; ( 2.1,2.1 ) rectangle ( 2.9,2.9 ) ; ( 0.1,3.1 ) rectangle ( 0.9,3.9 ) ; ( 1.1,3.1 ) rectangle ( 1.9,3.9 ) ; ( 0.1,4.1 ) rectangle ( 0.9,4.9 ) ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 4.1,0.1 ) rectangle ( 4.9,0.9 ) ; ( 5.1,0.1 ) rectangle ( 5.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 3.1,1.1 ) rectangle ( 3.9,1.9 ) ; ( 4.1,1.1 ) rectangle ( 4.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ; ( 1.1,2.1 ) rectangle ( 1.9,2.9 ) ; ( 2.1,2.1 ) rectangle ( 2.9,2.9 ) ; ( 3.1,2.1 ) rectangle ( 3.9,2.9 ) ; ( 0.1,3.1 ) rectangle ( 0.9,3.9 ) ; ( 1.1,3.1 ) rectangle ( 1.9,3.9 ) ; ( 2.1,3.1 ) rectangle ( 2.9,3.9 ) ; ( 0.1,4.1 ) rectangle ( 0.9,4.9 ) ; ( 1.1,4.1 ) rectangle ( 1.9,4.9 ) ; ( 0.1,5.1 ) rectangle ( 0.9,5.9 ) ;    ( 8,7.4 ) node[right]@xmath63 to[out=180,in=90 ] ( 4.5,4.6 ) ;    ( 8,5.2)node[right]@xmath64 to[out=180,in=90 ] ( 4.5,3 ) ;    ( 8,3 ) node[right]@xmath65 to[out=180,in=90 ] ( 4.5,1.4 ) ;    ( 8,0.8)node[right]@xmath66 to[out=180,in=90 ] ( 4.5,-0.2 ) ; ( 8,-1.4 ) node[right]@xmath67 to[out=180,in=90 ] ( 4.5,-1.8 ) ;    ( 8,-3.6)node[right]@xmath68 to[out=180,in=90 ] ( 4.5,-3.4 ) ;    the number of quadrature points used in or is considerably reduced compared to the full tensor product quadrature .",
    "however , the smolyak quadrature operator does not take into account the fact that the different parameter dimensions are of different importance to the integrand @xmath28 .",
    "indeed , the cardinality of the set @xmath56 is given by @xmath69 which still grows exponentially in the dimension @xmath26 .",
    "thus , we assign a weight to each parameter dimension and use a weighted version of the smolyak quadrature operator .",
    "let @xmath70 denote a weight vector for the different parameter dimensions .",
    "we assume in the following that the weight vector is sorted in ascending order , i.e.  @xmath71 .",
    "otherwise , we would rearrange the parametric dimensions accordingly .",
    "we modify the sparse grid sets @xmath56 and @xmath72 in the following way , see also @xcite , @xmath73 and @xmath74 with this notation at hand , the _ anisotropic smolyak quadrature operator _ of level @xmath75 is defined by @xmath76 which can equivalently be expressed as , cf .",
    "@xcite , @xmath77    the formula can be regarded as the _ anisotropic combination technique quadrature_. for the evaluation of this formula , we only need to determine the coefficients @xmath78 and to apply tensor product quadrature formulae of relatively small size .",
    "thus , in order to compute the approximation to with the anisotropic smolyak quadrature , it is sufficient to evaluate the integrand @xmath28 on the _ anisotropic sparse grid _",
    "@xmath79 note that the smolyak quadrature operator coincides with the anisotropic smolyak quadrature operator for the special weight vector @xmath80 $ ] .    in figure",
    "[ fig : indicesweighted ] , the indices of the weighted sparse grid @xmath81 and of the weighted sparse grid @xmath82 are visualized .",
    "we observe that the number of indices is drastically reduced in comparison to the according isotropic sparse grids visualized in figure [ fig : indicessparse ] .",
    "( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 4.1,0.1 ) rectangle ( 4.9,0.9 ) ; ( 5.1,0.1 ) rectangle ( 5.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ;    ( 0,0 ) ",
    "( 6.5,0 ) node[right ] @xmath57 ; ( 0,0 )  ( 0,6.5 ) node[above ] @xmath58 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 0pt,2pt ) ",
    "( 0pt,-2pt ) node[below ] @xmath59 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4,5/5 ( 2pt,0pt )  ( -2pt,0pt ) node[left ] @xmath60 ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ;    ( 0,0 )  ( 6.5,0 ) node[right ] @xmath61 ; ( 0,0 )  ( 0,6.5 ) node[above ] @xmath62 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4 , 5/5 ( 0pt,2pt )  ( 0pt,-2pt ) node[below ] @xmath59 ; /in 0/0 , 1/1 , 2/2 , 3/3 , 4/4,5/5 ( 2pt,0pt )  ( -2pt,0pt ) node[left ] @xmath60 ;    ( 0,0 ) rectangle ( 6,6 ) ; ( 0,0 ) grid ( 6,6 ) ; ( 0,0 ) rectangle ( 6,6 ) ; ( 0.1,0.1 ) rectangle ( 0.9,0.9 ) ; ( 1.1,0.1 ) rectangle ( 1.9,0.9 ) ; ( 2.1,0.1 ) rectangle ( 2.9,0.9 ) ; ( 3.1,0.1 ) rectangle ( 3.9,0.9 ) ; ( 4.1,0.1 ) rectangle ( 4.9,0.9 ) ; ( 5.1,0.1 ) rectangle ( 5.9,0.9 ) ; ( 0.1,1.1 ) rectangle ( 0.9,1.9 ) ; ( 1.1,1.1 ) rectangle ( 1.9,1.9 ) ; ( 2.1,1.1 ) rectangle ( 2.9,1.9 ) ; ( 3.1,1.1 ) rectangle ( 3.9,1.9 ) ; ( 0.1,2.1 ) rectangle ( 0.9,2.9 ) ; ( 1.1,2.1 ) rectangle ( 1.9,2.9 ) ;    ( 6.5,4 ) node[right]@xmath63 to[out=180,in=90 ] ( 4,1.5 ) ;    ( 7.5,-2)node[right]@xmath64 to[out=180,in=90 ] ( 4,-1.5 ) ;    the computation of the anisotropic sparse quadrature formula depends on the choice of the weight vector @xmath83 and the sequence @xmath84 in . in view of the one - dimensional error estimate ,",
    "the sequence @xmath84 of the number of quadrature points is chosen in accordance with @xmath85    then , we can estimate the error of the difference gaussian quadrature operator @xmath86 for all @xmath87 and for all functions @xmath88 which are analytically extendable in @xmath89 by @xmath90 for @xmath91 , the difference gaussian quadrature operator coincides with the function evaluation at a particular point @xmath92 of @xmath16 which implies that @xmath93 note that this estimate is only valid in case that @xmath94 as it is case for the gauss - hermite and the gauss - legendre quadrature .",
    "analogously , it follows from and that @xmath95    next , let us consider the multivariate integrand @xmath96 which can analytically be extended into the region @xmath97 .",
    "then , it follows that the error of the tensor product of the operators @xmath98 is bounded by the product of the one - dimensional errors .",
    "indeed , we obtain for a multi - index @xmath99 that @xmath100 with @xmath101 and @xmath102 .",
    "in addition , we take the minimum in in order to ensure that the constant is @xmath103 if @xmath104 in accordance with .",
    "for the estimation of the quadrature error of the anisotropic sparse gaussian quadrature , we employ the following lemma .    [",
    "lem : costhsumm ] let @xmath105 be a summable sequence of positive real numbers .",
    "then , there exists for each @xmath106 a constant @xmath107 independent of @xmath108 such that @xmath109    let @xmath110 be arbitrary such that @xmath111 . from the summability of @xmath112",
    ", it follows that there exists a @xmath113 such that @xmath114 we now split the left - hand side in into @xmath115 then , the second factor can simply be estimated by @xmath116 the number of factors @xmath117 in the first product in is fixed and depends only on the choice of @xmath118 and on the decay properties of @xmath119 . since @xmath117 is a fixed natural number , there exists for all @xmath120 a constant @xmath121 such that @xmath122 hence , we obtain that @xmath123 since @xmath110 can be chosen arbitrary with the only limitation that @xmath124 , the choice @xmath125 yields the desired estimate .    with the above preliminaries",
    ", we are able to establish error estimates for the anisotropic sparse gaussian quadrature . to that end",
    ", we have additionally to exploit some properties of the function @xmath126 and the sequence @xmath33 in .",
    "[ ass : tauandgandh ] the sequence @xmath33 which describes the regions of analytic extendability of the function @xmath27 fulfills @xmath127 for some @xmath128 .",
    "hence , the sequence @xmath129 is summable .",
    "additionally , we suppose that the sequence @xmath130 is summable",
    ". moreover , the function @xmath131 is strictly monotone increasing and satisfies @xmath132 .    for the error estimation , we adapt some parts of the analysis in @xcite , but then conclude in a different way .",
    "[ lem : recest ] let the sequence of quadrature points be chosen as in and let the weight vector @xmath83 be given by @xmath133 . then , there exists for each @xmath106 a constant @xmath107 independent of @xmath26 such that the error of the anisotropic sparse gaussian quadrature is bounded by @xmath134 the constant hidden in depends on the continuity constant of @xmath135 and on @xmath136 .",
    "note that the constant @xmath107 tends to infinity as @xmath137 tends to @xmath138 .    in the same way as in @xcite , the error of the sparse quadrature",
    "is rewritten , with the notation @xmath139 , by @xmath140 the quantity @xmath141 is defined for @xmath142 by @xmath143 and for @xmath144 by @xmath145 for @xmath146 , each summand in can be estimated with , and with the continuity of the integration operator by @xmath147 with the choice @xmath148 for all @xmath149 , it follows that @xmath150 for @xmath144 , we have that @xmath151 . we thus deduce that @xmath152 it remains to estimate @xmath153 the maximum inside the product is @xmath154 except for the case @xmath155 .",
    "hence , it follows that @xmath156 the last inequality holds since @xmath157 is summable and , thus , lemma [ lem : costhsumm ] is applicable .",
    "combining our findings yields the estimate .",
    "lemma [ lem : recest ] implies that the anisotropic sparse gaussian quadrature converges exponentially with respect to the level @xmath51 .",
    "the convergence in lemma [ lem : recest ] is nearly as good as the convergence of the anisotropic tensor product gaussian quadrature on level @xmath51 , with @xmath158 quadrature points in the @xmath159-th direction .",
    "in order to find an error estimate in terms of the number of quadrature points , we additionally have to estimate the cost of the sparse gaussian quadrature method on level @xmath51 .",
    "we exploit that the weight vector @xmath83 is ordered ascendingly , i.e.  @xmath160 . in the following ,",
    "we establish a bound on the number of quadrature points used in the combination technique formula .",
    "this number is given by @xmath161 then , we simply use that @xmath162 , cf .   and , and",
    "estimate the maximum value of the summands in . for this , we have to solve the optimization problem @xmath163 this is equivalent to the problem @xmath164 we get an upper bound for this optimization problem if we extend the admissible set of multi - indices to arbitrary @xmath26-dimensional vectors with positive coefficients @xmath165 the problem s solution can be calculated by solving the equivalent optimization problem @xmath166 we solve it by means of lagrangian multipliers and get the optimal solution @xmath167 where @xmath168 is determined by @xmath169 this implies the following lemma on the upper bound for .    [",
    "lem : costcompl ] let the weight vector @xmath170 $ ] be ascendingly ordered .",
    "then , the cost complexity of the anisotropic sparse gaussian quadrature on level @xmath51 is , with @xmath168 from , bounded by @xmath171    the product on the right - hand side in can further be estimated .",
    "let the weight vector @xmath170 $ ] be ascendingly ordered and @xmath172 .",
    "then , it holds that @xmath173    we show for @xmath174 that @xmath175 the successive application of this inequality for @xmath176 leads to @xmath177 then , it follows by proceeding in the same way for @xmath178 that @xmath179 since @xmath180 , this would immediately imply the assertion .",
    "to prove , we use the abbreviation @xmath181 and rewrite this inequality by @xmath182 after expanding the products , some of the terms vanish and we can simplify this expression to @xmath183 here , the first and second inequality follow from @xmath184 and from @xmath185 .",
    "this completes the proof .",
    "next , we can deduce , in view of and , that the complexity of the anisotropic sparse gaussian quadrature is bounded by @xmath186      in order to complete the convergence analysis , it remains to estimate the number of indices in the set @xmath187 .",
    "therefore , we require the following lemma .    [",
    "lem : helplem ] for @xmath188 , @xmath189 and @xmath190 , there holds the inequality @xmath191 with equality when @xmath192 .",
    "we prove the assertion by induction on @xmath193 . for @xmath194 , we verify @xmath195 let the assertion be fulfilled for @xmath193 .",
    "then , we conclude for @xmath196 that @xmath197    [ conjecture ] the cardinality of the set @xmath187 in , where the weight vector @xmath170 $ ] is ascendingly ordered , i.e.  @xmath198 , is bounded by @xmath199    the prove is performed by induction on @xmath26 . for @xmath200 , the assertion is obviously fulfilled , since @xmath201 let us assume that is true for @xmath202 . for @xmath189",
    ", the cardinality of @xmath187 can be calculated by @xmath203 inserting the induction hypothesis yields that @xmath204 focusing on the last term and since @xmath205 for all @xmath206 , we conclude that @xmath207 applying the previous lemma with @xmath208 and @xmath209 leads to @xmath210 thus , we obtain that @xmath211 inserting this into finishes the proof .",
    "[ rem : indexset ]    1 .",
    "we would like to point out that estimate is sharp in the isotropic case , that is , for the weight @xmath212 .",
    "moreover , the ordering of the weight vector is crucial in this estimate .",
    "there are examples where this estimate does not hold if the weights are not in ascending order .",
    "2 .   at first glance",
    "one might claim that even the estimate @xmath213 is valid .",
    "this is true in a lot of cases which we investigated .",
    "nevertheless , there are examples where this estimate fails .      the findings of the previous two sections can be summarized to the error estimate of the anisotropic sparse grid quadrature @xmath214 and the complexity estimate @xmath215    in view of our application to parametric partial differential equations , we have to examine the cost complexity with respect to the properties of the sequence @xmath216 .",
    "in particular , under certain conditions on this sequence , the convergence rate in terms of the number of quadrature points is dimension - independent and algebraic of arbitrary order .",
    "[ theo : errestbad ]    if the sequence @xmath217 is summable , then there exists a constant @xmath218 , which does not dependent on the dimension @xmath26 for all @xmath219 but tends to @xmath220 if @xmath221 or @xmath222 , such that @xmath223 where @xmath224 denotes the total number of quadrature points in @xmath225 .",
    "the constant hidden in the estimate coincides with the constant in lemma [ lem : recest ] .    from the definition of the weights @xmath226 , cf .",
    "lemma [ lem : recest ] , we know that @xmath133 . since @xmath227 is summable , it follows with lemma [ lem : costhsumm ] that there exists for each @xmath228 a constant @xmath229 independent of @xmath26 such that @xmath230 inserting this into implies that @xmath231 this yields that the error in terms of @xmath224 is bounded by @xmath232    [ rem : dimunabhkonvsparse ] the condition that @xmath217 is summable implies that @xmath233 increases stronger than @xmath234 .",
    "in particular , a rate @xmath235 for arbitrary @xmath106 would be sufficient .",
    "unfortunately , since @xmath236 for the gauss - legendre and gauss - hermite quadrature , cf .   and , any algebraic increase of @xmath237 is not sufficient for the summability of @xmath217 .",
    "nevertheless , if @xmath237 increases subexponentially , i.e.  @xmath238 for arbitrary @xmath106 , summability of @xmath217 is guaranteed , cf .",
    "@xcite .    in view of this remark",
    ", we investigate in the rest of this section how fast the convergence rate deteriorates for an algebraic increase , i.e.  @xmath239 .",
    "[ lem : estpointslog ] let the sequence @xmath216 increase as @xmath240 for some @xmath241 and @xmath242 .",
    "then , we obtain that the number of indices in the anisotropic sparse grid is bounded by @xmath243 with a constant which is independent of @xmath26 .    from lemma",
    "[ conjecture ] , we know that @xmath244 next , we split the product into @xmath245 we estimate the last term by @xmath246 due to @xmath247 , the sum in this estimate can be bounded by the following integral : @xmath248 the first three factors in define a cubic polynomial in @xmath51 and can thus be estimated by the exponential function according to @xmath249 hence , putting all together , we end up with @xmath250    with lemma [ lem : estpointslog ] at hand , we are able to quantify how the dimensionality @xmath26 compromises the convergence rate of the anisotropic sparse gaussian quadrature .",
    "in fact , the dimensionality enters only with a factor @xmath251 in case of algebraic increasing regions of analyticity .",
    "let the conditions of lemma [ lem : recest ] be satisfied and let the assumptions of lemma [ lem : estpointslog ] be fulfilled .",
    "then , the error of the anisotropic sparse gaussian quadrature @xmath225 is bounded in terms of the total number of quadrature points by @xmath252    inserting into , leads to the complexity estimate @xmath253 combining this with the error estimate implies the desired bound .",
    "as a practical application of the sparse anisotropic gaussian quadrature , we consider random diffusion problems with either uniformly or lognormally distributed diffusion coefficients .",
    "since we lay our emphasis on the convergence behavior of the gaussian quadrature , we will deal here only with one - dimensional problems .",
    "even so , we want to emphasize that all results remains valid also in two and three spatial dimensions .",
    "let @xmath254 be a complete and separable probability space .",
    "we consider the diffusion equation @xmath255 with homogenous boundary conditions , i.e.  @xmath256 .",
    "the first step towards the solution for this class of problems is the parameterization of the stochastic parameter . to that end ,",
    "one decomposes the diffusion coefficient with the aid of the karhunen - love expansion .",
    "let the covariance kernel of @xmath257 be defined by the positive semi - definite function @xmath258(x)\\big)\\big(a({x'},\\omega)-{\\mathbb{e}}[a](x')\\big ) { \\operatorname{d\\!}}\\mathbb{p}(\\omega).\\ ] ] herein , the integral with respect to @xmath259 has to be understood in terms of a bochner integral , cf .",
    "now , let @xmath260 denote the eigenpairs obtained by solving the eigenproblem for the diffusion coefficient s covariance , i.e.   @xmath261 then , the karhunen - love expansion of @xmath257 is given by @xmath262(x)+\\sum_{n=1}^\\infty\\sqrt{\\lambda_n}\\varphi_n(x)x_n(\\omega),\\ ] ] where @xmath263 for @xmath264 are centered , pairwise uncorrelated and @xmath265-normalized random variables . in the uniformly distributed case , we have @xmath266)$ ] and in the lognormally distributed case , we have @xmath267 . note that we compute in the latter case the karhunen - love expansion of @xmath268 rather than of @xmath257 itself and set @xmath269(x)=0 $ ] . in the lognormal case ,",
    "the knowledge of @xmath270 together with @xmath269(x)=0 $ ] provides the unique description of @xmath271 since the underlying random process is gaussian . in the uniform case",
    ", we have additionally to assume that the random variables are independent and that @xmath272(x)>0 $ ] such that @xmath257 becomes uniformly elliptic .    by substituting the random variables with their image in @xmath16 ,",
    "we arrive in the uniformly distributed case at the parameterized karhunen - love expansion @xmath273(x)+\\sum_{n=1}^\\infty\\sqrt{\\lambda_n}\\varphi_n(x)\\sqrt{3}\\psi_n,\\ ] ] where @xmath274 $ ] and @xmath275 .",
    "note that the scaling factor @xmath276 stems from the normalization of the random varibles variance .",
    "for the lognormally distributed case , we obtain in complete analogy @xmath277 where @xmath278 and @xmath279 .",
    "we define @xmath280 .",
    "the decay of the sequence @xmath281 is important in order to determine the region of analytical extendability of the solution @xmath282 , cf .",
    "lemma [ lem : analgal ] .    truncating the respective karhunen - love expansion after @xmath189 terms , yields the parametric and truncated diffusion problem @xmath283 the impact of truncating the karhunen - love expansion on the solution is bounded by @xmath284 where @xmath285 montonically as @xmath286 , see e.g.  @xcite .",
    "herein , the bochner spaces @xmath287 , where @xmath288 is a separable banach space , consist of all equivalence classes of measurable functions @xmath289 with bounded norm @xmath290 see @xcite for more details on bochner spaces and bochner integrable functions .",
    "since the @xmath265-norm is stronger than the @xmath291-norm , this especially yields the approximation estimate for @xmath282 and @xmath292 , where the modulus has to be replaced by the @xmath293-norm .",
    "given the parametric solution @xmath294 , we are interested in determining proporties of its distribution . in our numerical examples",
    ", we focus on the computation of the solution s moments .",
    "these are given by the bochner integral @xmath295 especially , there holds @xmath296 .      in order to apply the presented quadrature theory to our parametric diffusion problems",
    ", we have to provide the related regularity results that allow for an analytic extension of @xmath292 into the complex plane .",
    "the extendability is guaranteed by the following lemma from @xcite , which has slightly been modified to fit our purposes .",
    "[ lem : analgal ] the solution @xmath292 to in the uniformly elliptic case admits an analytic extension into the region @xmath297^m,{{\\boldsymbol{\\tau}}})$ ] for all @xmath298 with @xmath299 in addition , it holds that @xmath300^m,{{\\boldsymbol{\\tau}}});h_0 ^ 1(d ) ) } \\lesssim \\|f\\|_{l^{2}(d)}.\\ ] ]    in the lognormal case , the solution @xmath292 to is analytically extendable into @xmath301 provided that @xmath302 moreover , the solution is bounded in accordance with @xmath303 for the weight function @xmath304 .",
    "the constants which are involved in the estimates depend on the choice of @xmath298 , but are independent of @xmath26 .",
    "lemma [ lem : analgal ] characterizes the region of analyticity and the according weight function @xmath305 and , therefore , assumption  [ ass : anaextension ] is satisfied in these cases .",
    "it remains to investigate the one - dimensional error estimates of the gauss - legendre and the gauss - hermite quadrature for functions @xmath306 which are analytically extendable into a region around the parameter domain @xmath16 .",
    "therefore , we provide the following two lemmata on the best polynomial approximation for analytic extendable and banach space valued functions , see @xcite , and the continuity of the gaussian quadrature operator .    from @xcite , we have the following result for the gauss - legendre quadrature .",
    "[ lem : uniquaderr ] let @xmath307 be a banach space .",
    "suppose that @xmath308;x)$ ] admits an analytic extension in @xmath309,\\tau)$ ] for some @xmath310 .",
    "then , the error of the best approximation by polynomials of degree at most @xmath159 can be bounded by @xmath311)\\otimes x } \\|v - w\\|_{c([-1,1];x)}\\le \\frac{2}{\\kappa-1 } e^{-n \\log \\kappa } \\|v\\|_{c_{\\sigma}(\\sigma([-1,1],\\tau);x)}\\ ] ] with @xmath312 .",
    "thus , in view of our generic error estimate , we end up with @xmath313,\\quad\\sigma(y)\\equiv1,\\quad g(\\tau ) = \\frac{4}{\\kappa-1 } \\quad\\text{and}\\quad h(\\tau)=\\log(\\kappa)\\ ] ]    in case of the gauss - hermite quadrature , we employ the next lemma from @xcite .",
    "[ lembnt ] suppose that @xmath314 admits an analytic extension in @xmath315 for some @xmath316 .",
    "then , the error of the best approximation by polynomials of degree at most @xmath159 can be bounded by @xmath317 where @xmath318 is a constant and the weight function @xmath319 is given by @xmath320 .",
    "similarly to the gauss - legendre quadrature , we obtain the generic error estimate for the gauss - hermite quadrature with @xmath321    finally , we would like to point out that , with the new estimate on the number of indices @xmath187 , we are able to get significantly improved results in comparison with the convergence of the anisotropic tensor product gaussian quadrature .",
    "more precisely , we are able to show dimension - independent convergence with an arbitrarily algebraic rate if the regions of analyticity of the integrand grow exponentially like @xmath322 for arbitrary @xmath106 .",
    "this covers the important case of diffusion coefficients which are derived from gaussian covariance kernels .",
    "in addition , we analyzed the case when @xmath323 grows algebraically , which covers the case of covariance kernels of the matrn class , and obtain that the dimensionality @xmath26 compromises the convergence rate at most by the term @xmath251 .",
    "in this section , we present numerical examples to validate the theoretical findings . as a practical application of the sparse anisotropic gaussian quadrature , we consider random diffusion problems with either uniformly or lognormally distributed diffusion coefficients as defined in the previous section .    in our numerical experiments , we employ two covariance kernels of the matrn class for @xmath324 and @xmath325 , cf .",
    "@xcite , i.e. @xmath326 and @xmath327 where @xmath328 .",
    "the correlation length is in both cases set to @xmath329 .",
    "the spatial discretization is performed with piecewise linear finite elements an a mesh with mesh size @xmath330 , which results from @xmath331 equidistant sub - intervals . a numerical approximation to the karhunen - love expansion is computed by the pivoted cholesky decomposition of the covariance operator with a trace error of @xmath332 .",
    "this yields an approximation error of the underlying random field of @xmath333 , see @xcite for the details .",
    "the related truncation rank is given by @xmath334 for @xmath335 and @xmath336 for @xmath337 .",
    "in the uniformly distributed case , we set @xmath272(x)=2.5 $ ] . from @xcite , we know that @xmath338 for @xmath335 and @xmath339 for @xmath337 .",
    "since the solution of is not known analytically , we have to provide a reference solution . the error with respect to the reference solution",
    "is measured in the @xmath340-norm for the approximation of the mean and in the @xmath341-norm for the approximations of the higher order moments , respectively .",
    "this reference solution is computed by the quasi - monte carlo quadrature with halton points and @xmath342 samples .    for the anisotropic sparse gaussian quadrature",
    ", we set the weights @xmath226 according to @xmath133 with the same functions @xmath343 and the same quantities @xmath237 as for a related anisotropic tensor product quadrature for the lognormal and the uniformly elliptic case , respectively .",
    "hence , our anisotropic sparse gaussian quadrature is essentially a sparsification of the anisotropic tensor product gaussian quadrature , cf .",
    "@xcite for more details on the anisotropic tensor product gaussian quadrature . to choose the same quantity @xmath237 for the region of analyticity as for the tensor product quadrature seems to be a violation of lemma [ lem : analgal ] .",
    "indeed , the assertion of this lemma is that the quantities @xmath237 , which describes the region of analytic extendability in each direction @xmath344 , should be rescaled to @xmath345 in order to ensure analytic extendability into the tensor domain @xmath346 .",
    "nevertheless , our experience suggests that the sparsification of the anisotropic gaussian quadrature yields an error which is nearly as good as the error of the anisotropic gaussian quadrature itself .    for nearly all numerical examples",
    ", it turns out that the convergence rates slightly decrease from the computation of the mean to the computation of the second moment and even successively for the higher order moments .",
    "therefore , we state for all examples the actually obtained convergence rate for the mean and for the fourth moment . the convergence rate of the second and third moment is then between these two convergence rates .",
    "in addition to the convergence studies for the sparse anisotropic gaussian quadrature , we also provide results on the estimated number of quadratures contained in the sparse grid .",
    "we compare the tensor product estimate @xmath347 the novel estimate proposed in this article @xmath348 and finally the well established formula by beged - dov , cf .",
    "@xcite , @xmath349      errors for @xmath324 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right),title=\"fig : \" ] errors for @xmath324 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right),title=\"fig : \" ]    for the smoothness parameter @xmath324 , we end up with a karhunen - love expansion of length @xmath334 .",
    "figure  [ fig : mat52gauss ] depicts the convergence rates for both diffusion coefficients . on the left",
    ", we see the convergence of the gauss - legendre quadrature and on the right the convergence of the gauss - hermite quadrature . for the anisotropic sparse gauss - legendre quadrature ,",
    "the convergence rate decreases slightly from @xmath351 to @xmath352 for the first to the fourth moment . in case of the gauss - hermite quadrature for the lognormally distributed diffusion coefficient ,",
    "the observed rate is considerably better .",
    "for the mean , we observe @xmath353 and still @xmath351 for the fourth moment .",
    "note that the stagnation in the convergence might be caused by the accuracy of the reference solution , which is only of order @xmath354 .    estimates @xmath324 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ] estimates @xmath324 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ]    in figure  [ fig : mat52complexity ] , we see the different estimates for the number of indices in the anisotropic sparse tensor product space . on the left , we have the estimates for the uniformly distributed coefficient and on the right for the lognormally distributed coefficient . as it turns out , for the uniformly distributed case as well as for the lognormal case , the considered formulae exhibit qualitatively the same behavior . the novel estimate proven in this article",
    "only slightly overestimates the number of indices and reflects perfectly the growth of the index set with increasing @xmath51 .",
    "although the formula of beged - dov is asymptotically much better than the crude tensor product estimate , it heavily overestimates the actual number of indices .",
    "errors for @xmath325 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ] errors for @xmath325 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ]    in this example , we have to deal with a @xmath356-dimensional integration problem .",
    "the convergence rates for the computation of the first four moments of the anisotropic sparse gaussian quadrature method are depicted in figure [ fig : mat72gauss ] . on the left hand side of this figure",
    ", we find the convergence rates in case of the uniformly distributed coefficient and on the right hand side for the lognormally distributed coefficient . in the uniformly distributed case , we obtain a convergence rate which is essentially the same for the computation of all considered moments and of order @xmath351 . in the lognormally distributed case , we obtain convergence rates that are considerably higher . for the mean , we observe a rate of @xmath357 and still a convergence rate of @xmath358 for the fourth moment .",
    "note that the stagnation in the convergence might be caused by the accuracy of the reference solution , which is theoretically only of order @xmath354 .",
    "estimates @xmath325 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ] estimates @xmath325 with uniformly distributed coefficient ( left ) and lognormally distributed coefficient ( right).,title=\"fig : \" ]    in figure  [ fig : mat72complexity ] , we see the different estimates for the number of indices in the anisotropic sparse tensor product space . on the left",
    ", we have the estimates for the uniformly distributed coefficient and on the right for the lognormally distributed coefficient . again , as in the example with @xmath324 , there is no significant difference between the lognormally distributed and the uniformly distributed case .",
    "again , the novel estimate only slightly overestimates the number of indices and reflects perfectly the growth of the index set with increasing @xmath51 , whereas the formula by beged - dov heavily overestimates the number of indices in @xmath187 .",
    "in the present article , a novel complexity estimate for the anisotropic sparse grid quadrature has been proven . under the assumption that the dimension weights @xmath359 are increasing at least logarithmically , i.e.  @xmath360 for some @xmath241 and @xmath242 , we can prove essentially dimension independent convergence .",
    "our theory has been applied for elliptic diffusion problems with uniformly elliptic random coefficient or lognormally distributed random coefficient . here , the anisotropic sparse gauss - legendre quadrature and the anisotropic sparse gauss - hermite quadrature have to be applied , respectively .",
    "nevertheless , the presented results remain also valid for other quadrature rules like e.g.  clenshaw - curtis or gauss - kronrod quadrature formulae .",
    "m.  griebel , m.  schneider , and c.  zenger . a combination technique for the solution of sparse grid problems . in p.",
    "de  groen and r.  beauwens , editors , _ iterative methods in linear algebra _ , pages 263281 .",
    "imacs , elsevier , north holland , 1992 ."
  ],
  "abstract_text": [
    "<S> this article is dedicated to the anisotropic sparse gaussian quadrature for functions which are analytically extendable into an anisotropic tensor product domain . </S>",
    "<S> based on a novel estimate for the cardinality of the anisotropic index set , we are able to substantially improve the error versus cost estimates of the anisotropic sparse quadrature . to validate the theoretical findings </S>",
    "<S> , we use the anisotropic sparse gaussian quadrature to compute the moments of elliptic partial differential equations with random diffusion . </S>"
  ]
}