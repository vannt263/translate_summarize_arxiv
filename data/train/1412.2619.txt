{
  "article_text": [
    "global sensitivity analysis ( sa ) offers a comprehensive approach to the model analysis . unlike local sa ,",
    "global sa methods evaluate the effect of a factor while all other factors are varied as well and thus they account for interactions between variables and do not depend on the choice of a nominal point .",
    "reviews of different global sa methods can be found in @xcite and @xcite .",
    "the method of global sensitivity indices suggested by @xcite , and then further developed by @xcite is one of the most efficient and popular global sa techniques .",
    "it belongs to the class of variance - based methods .",
    "these methods provide information on the importance of different subsets of input variables to the output variance .",
    "there are two types of sobol sensitivity indices : the main effect indices , which estimate the individual contribution of each input parameter to the output variance , and the total sensitivity indices , which measure the total contribution of a single input factor or a group of inputs .",
    "the total sensitivity indices are used to identify non - important variables which can then be fixed at their nominal values to reduce model complexity .",
    "this approach is known as `` factors fixing setting '' @xcite . for high - dimensional models the direct application of variance - based global sa measures",
    "can be extremely time - consuming and impractical .",
    "a number of alternative sa techniques have been proposed .",
    "one of them is the screening method by @xcite .",
    "it can be regarded as global as the final measure is obtained by averaging local measures ( the elementary effects ) .",
    "this method is considerably cheaper than the variance based methods in terms of computational time .",
    "the morris method can be used for identifying unimportant variables . however , the morris method has two main drawbacks .",
    "firstly , it uses random sampling of points from the fixed grid ( levels ) for averaging elementary effects which are calculated as finite differences with the increment delta comparable with the range of uncertainty . for this reason it can not correctly account for the effects with characteristic dimensions much less than delta .",
    "secondly , it lacks the ability of the sobol method to provide information about main effects ( contribution of individual variables to uncertainty ) and it ca nt distinguish between low and high order interactions .",
    "this paper presents a survey of derivative based global sensitivity measures ( dgsm ) and their link with sobol sensitivity indices .",
    "dgsm are based on averaging local derivatives using monte carlo or quasi monte carlo sampling methods .",
    "this technique is much more accurate than the morris method as the elementary effects are evaluated as strict local derivatives with small increments compared to the variable uncertainty ranges .",
    "local derivatives are evaluated at randomly or quasi randomly selected points in the whole range of uncertainty and not at the points from a fixed grid .",
    "the so - called alternative global sensitivity estimator defined as a normalized integral of partial derivatives was firstly introduced by @xcite .",
    "@xcite introduced some other dgsm and coined the acronym dgsm .",
    "they showed that dgsm can be seen as the generalization of the morris method @xcite .",
    "@xcite also established empirically the link between dgsm and sobol sensitivity indices .",
    "they showed that the computational cost of numerical evaluation of dgsm can be much lower than that for estimation of sobol sensitivity indices .",
    "@xcite proved theoretically that , in the cases of uniformly and normally distributed input variables , there is a link between dgsm and the sobol total sensitivity index @xmath1 for the same input .",
    "they showed that dgsm can be used as an upper bound on total sensitivity index @xmath1 .",
    "small values of dgsm imply small @xmath1 , and hence unessential factors @xmath2 .",
    "however , ranking influential factors using dgsm can be similar to that based on @xmath1 only for the case of linear and quasi - linear models .",
    "for highly non - linear models two rankings can be very different .",
    "they also introduced modified dgsm which can be used for both a single input and groups of inputs @xcite . from dgsm",
    ", @xcite have also derived lower bounds on total sensitivity index .",
    "@xcite extended results of sobol and kucherenko for models with input variables belonging to the general class of continuous probability distributions . in the same framework ,",
    "@xcite have defined crossed - dgsm , based on second - order derivatives of model output , in order to bound the total sobol indices of an interaction between two inputs .",
    "all these dgsm measures can be applied for problems with a high number of input variables to reduce the computational time .",
    "indeed , the numerical efficiency of the dgsm method can be improved by using the automatic differentiation algorithm for calculation dgsm as was shown in @xcite .",
    "however , the number of required function evaluations still remains to be proportional to the number of inputs .",
    "this dependence can be greatly reduced using an approach based on algorithmic differentiation in the adjoint or reverse mode @xcite ( ) .",
    "it allows estimating all derivatives at a cost at most 4 - 6 times of that for evaluating the original function @xcite .",
    "this paper is organised as follows : the morris method and dgsm are firstly described in the following section .",
    "sobol global sensitivity indices and useful relationships are then introduced .",
    "therefore , dgsm - based lower and uppers bounds on total sobol sensitivity indices for uniformly and normally distributed random variables are presented , followed by dgsm for groups of variables and their link with total sobol sensitivity indices .",
    "another section presents the upper bounds results in the general case of variables with continuous probability distributions .",
    "then , computational costs are considered , followed by some test cases which illustrate an application of dgsm and their links with total sobol sensitivity indices .",
    "finally , conclusions are presented in the last section .",
    "the morris method is traditionally used as a screening method for problems with a high number of variables for which function evaluations can be cpu - time consuming ( see ) .",
    "it is composed of individually randomized one - factor - at - a - time ( oat ) experiments .",
    "each input factor may assume a discrete number of values , called levels , which are chosen within the factor range of variation .",
    "the sensitivity measures proposed in the original work of @xcite are based on what is called an elementary effect .",
    "it is defined as follows .",
    "the range of each input variable is divided into _",
    "p _ levels . then the elementary effect ( incremental ratio ) of the _",
    "_ i-__th input factor is defined as @xmath3}{\\delta } , \\ ] ] where @xmath4 is a predetermined multiple of 1/(_p_-1 ) and point @xmath5 is such that @xmath6 .",
    "one can see that the elementary effect are finite difference approximations of the model derivative with respect to @xmath7 and using a large perturbation step @xmath8 .",
    "the distribution of elementary effects @xmath9 is obtained by randomly sampling _ r _ points from @xmath10 .",
    "two sensitivity measures are evaluated for each factor : @xmath11 an estimate of the mean of the distribution @xmath9 , and @xmath12 an estimate of the standard deviation of @xmath9 .",
    "a high value of @xmath11 indicates an input variable with an important overall influence on the output .",
    "a high value of @xmath12 indicates a factor involved in interaction with other factors or whose effect is nonlinear .",
    "the computational cost of the morris method is _",
    "n@xmath13 _ = _ r _ ( _ d+1 _ ) .",
    "the revised version of the @xmath14 measure and a more effective sampling strategy , which allows a better exploration of the space of the uncertain input factors was proposed by @xcite . to avoid the canceling effect which appears in non - monotonic functions @xcite introduced another sensitivity measure @xmath15 based on the absolute value of @xmath16 : @xmath17 .",
    "it was also noticed that @xmath15 has similarities with the total sensitivity index @xmath1 in that it can give a ranking of the variables similar to that based on the @xmath1 but no formal proof of the link between @xmath15 and @xmath0 was given @xcite .",
    "finally , other extensions of the initial morris method have been introduced for the second - order effects analysis @xcite @xcite @xcite , for the estimation of morris measures with any - type of design @xcite @xcite and for building some 3d morris graph @xcite .",
    "consider a differentiable function @xmath18 , where @xmath19 is a vector of input variables defined in the unit hypercube @xmath10 @xmath20 .",
    "local sensitivity measures are based on partial derivatives @xmath21 this measure @xmath22 is the limit version of the elementary effect @xmath9 defined in when @xmath8 tends to zero .",
    "it is its generalization in this sense . in sa , using the partial derivative @xmath23 is well known as a local method ( see ) . in this paper ,",
    "the goal is to take advantage of this information in global sa .    the local sensitivity measure @xmath24 depends on a nominal point @xmath25 and it changes with a change of @xmath26 .",
    "this deficiency can be overcome by averaging @xmath24 over the parameter space @xmath27 .",
    "this is done just below , allowing to define new sensitivity measures , called dgsm for derivative - based global sensitivity measures .",
    "assume that @xmath28 .",
    "three different dgsm measures are defined : @xmath29 @xmath30 where @xmath31 is a constant , and @xmath32      consider a function @xmath33 , where @xmath34 are independent random variables , defined in the euclidian space @xmath35 , with cumulative density functions ( cdfs ) @xmath36 .",
    "the following dgsm was introduced in @xcite : @xmath37,\\ ] ] with @xmath38 the joint cdf . a new measure is also introduced : @xmath39    in and",
    ", @xmath40 is in fact the mean value of @xmath41 . in the following and in practice",
    ", it will be the most useful dgsm .",
    "the method of global sensitivity indices developed by sobol ( see ) is based on anova decomposition @xcite . consider a square integrable function @xmath42 defined in the unit hypercube @xmath10 .",
    "it can be expanded in the following form @xmath43 this decomposition is unique if conditions @xmath44 for @xmath45 , are satisfied . here",
    "@xmath46 .",
    "the variances of the terms in the anova decomposition add up to the total variance of the function @xmath47 where @xmath48 are called partial variances .",
    "sobol defined the global sensitivity indices as the ratios @xmath49 all @xmath50 are non negative and add up to one : @xmath51 sobol also defined sensitivity indices for subsets of variables .",
    "consider two complementary subsets of variables @xmath52 and @xmath53 : @xmath54 let @xmath55 .",
    "the variance corresponding to the set @xmath52 is defined as @xmath56 @xmath57 includes all partial variances @xmath58 , @xmath59 ,  , @xmath60 such that their subsets of indices @xmath61 .",
    "the total sensitivity indices were introduced by @xcite .",
    "the total variance @xmath62 is defined as @xmath63 @xmath62 consists of all @xmath60 such that at least one index @xmath64 while the remaining indices can belong to the complimentary to _ k _ set @xmath65 .",
    "the corresponding global sensitivity indices are defined as @xmath66    the important indices in practice are @xmath67 and @xmath0 , @xmath68 : @xmath69 their values in most cases provide sufficient information to determine the sensitivity of the analyzed function to individual input variables .",
    "variance - based methods generally require a large number of function evaluations ( see ) to achieve reasonable convergence and can become impractical for large engineering problems .      to present further results on lower and upper bounds of @xmath0 , new notations and useful relationships have to be firstly presented .",
    "denote @xmath70 the sum of all terms in the anova decomposition that depend on @xmath2 : @xmath71 from the definition of anova decomposition it follows that @xmath72 it is obvious that @xmath73 denote @xmath74 the vector of all variables but @xmath2 , then @xmath75 and @xmath76 .",
    "the anova decomposition of @xmath42 can be presented in the following form @xmath77 where @xmath78 is the sum of terms independent of @xmath2 . because of it is easy to show that @xmath79 .",
    "hence @xmath80 this equation can be found in @xcite .",
    "the total partial variance @xmath81 can be computed as @xmath82 then the total sensitivity index @xmath0 is equal to @xmath83      consider continuously differentiable function @xmath42 defined in the unit hypercube @xmath10=@xmath84^{d } $ ] .",
    "this section presents a theorem that establishes links between the index @xmath1 and the limiting values of @xmath85 .    in the case",
    "when @xmath86 , sobol-jansen formula @xcite@xcite@xcite for @xmath87 can be rewritten as @xmath88^{2 } d{\\mathbf{x}}dx'_{i }    , \\ ] ] where @xmath89 .",
    "* theorem 1 . *",
    "assume that @xmath90 , then @xmath91    * proof : * consider the increment of @xmath18 in : @xmath92 where @xmath93 is a point between @xmath94 and @xmath95 . substituting into leads to @xmath96 in @xmath97 while the remaining integral is @xmath98 thus obtained inequalities are equivalent to . consider the function @xmath99 .",
    "in this case @xmath100 , @xmath101 and @xmath102 and the inequalities in become equalities .",
    "in this section , several theorems are listed in order to define useful lower and upper bounds of the total sobol indices .",
    "the proofs of these theorems come from previous works and papers and are not recalled here .",
    "two cases are considered : variables @xmath94 following uniform distributions and variables @xmath94 following gaussian distributions .",
    "the general case will be seen in a subsequent section .",
    "* theorem 2 .",
    "* there exists the following lower bound between dgsm and the sobol total sensitivity index : @xmath103\\left[g\\left(1,{\\mathbf{z}}\\right)+g\\left(0,{\\mathbf{z}}\\right)-2g\\left({\\mathbf{x}}\\right)\\right]d { \\mathbf{x}}\\right)^{2 } } { 4\\nu_{i } v } < s_{i}^{\\mbox{\\scriptsize{tot}}}\\ ] ]    * proof : * the proof of this theorem is given in @xcite and is based on equation and a cauchy - schwartz inequality applied on @xmath104 .    the lower bound number number one ( lb1 )",
    "is defined as @xmath105\\left[g\\left(1,{\\mathbf{z}}\\right)+g\\left(0,{\\mathbf{z}}\\right)-2g\\left({\\mathbf{x}}\\right)\\right]d { \\mathbf{x}}\\right)^{2 } } { 4\\nu_{i } v } .\\ ] ]    * theorem 3 .",
    "* there exists the following lower bound , denoted @xmath106 , between dgsm and the sobol total sensitivity index : @xmath107^{2 } } { ( m+1)^{2 } v } < s_{i}^{\\mbox{\\scriptsize{tot } } } .\\ ] ]    * proof : * the proof of this theorem in given in @xcite and is based on equation and a cauchy - schwartz inequality applied on @xmath108 . in fact , theorem 3 gives a set of lower bounds depending on parameter _",
    "m_. the value of _ m _ at which @xmath109 attains its maximum is of particular interest .",
    "further , star ( @xmath110 ) is used to denote such a value @xmath111 : @xmath112 .",
    "@xmath113 is called the lower bound number two ( lb2 ) : @xmath114^{2 } } { ( m^ { * } + 1)^{2 } v}\\ ] ]    the maximum lower bound lb * is defined as @xmath115 both lower and upper bounds can be estimated by a set of derivative based measures : @xmath116      * *    * theorem 4 .",
    "* there exists the following upper bound between dgsm and the sobol total sensitivity index : @xmath117    * proof : * the proof of this theorem in given in @xcite .",
    "it is based on inequality : @xmath118 and relationships and .",
    "consider the set of values @xmath119 , @xmath120 .",
    "one can expect that smaller @xmath40 correspond to less influential variables @xmath2 .",
    "this importance criterion is similar to the modified morris importance measure @xmath121 , whose limiting values are @xmath122    from a practical point of view the criteria @xmath123 and @xmath124 are equivalent : they are evaluated by the same numerical algorithm and are linked by relations @xmath125 and @xmath126 .    the right term in",
    "is further called the upper bound number one ( ub1 ) .    * theorem 5 .",
    "* there exists the following upper bound between dgsm and the sobol total sensitivity index : @xmath127    * proof : * the following inequality @xcite is used : @xmath128 the inequality is reduced to an equality only if @xmath129 is constant .",
    "assume that @xmath129 is given by , then @xmath130",
    ". from , equation is obtained .",
    "further @xmath131 is called the upper bound number two ( ub2 ) .",
    "note that @xmath132 for @xmath133 is bounded : @xmath134 .",
    "therefore , @xmath135",
    ".        * theorem 6 . *",
    "if @xmath136 is normally distributed with a mean @xmath137 and a finite variance @xmath138 , there exists the following lower bound between dgsm and the sobol total sensitivity index : @xmath139    * proof : * using the equation and cauchy - schwartz inequality applied on @xmath140 ( with @xmath38 the joint cdf ) , @xcite give the proof of this inequality when @xmath141 ( omitting to mention this condition ) . the general proof , obtained by @xcite ,",
    "is given below .",
    "consider a univariate function @xmath142 , with @xmath143 a normally distributed variable with mean @xmath144 , finite variance @xmath145 and cdf @xmath38 .",
    "with adequate conditions on @xmath146 , the following equality is obtained by integrating by parts : @xmath147 = \\displaystyle \\int_{-\\infty}^{\\infty } g'(x ) df(x ) = \\displaystyle \\frac{1}{\\sigma \\sqrt{2\\pi } } \\int_{-\\infty}^{\\infty } g'(x ) \\exp \\left[-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right ] dx \\\\ & = \\displaystyle \\frac{1}{\\sigma \\sqrt{2\\pi } } \\left [ g(x ) \\exp \\left[-\\frac{(x-\\mu)^2}{2\\sigma^2 } \\right ] \\right]_{-\\infty}^{+\\infty } + \\frac{1}{\\sigma \\sqrt{2\\pi } } \\int_{-\\infty}^{\\infty } g(x ) \\frac{x-\\mu}{\\sigma^2 } \\exp \\left[-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right ] dx   \\\\ & = \\displaystyle \\frac{1}{\\sigma^2 } \\int_{-\\infty}^{\\infty } x g(x ) df(x ) - \\mu \\int_{-\\infty}^{\\infty } g(x ) df(x ) .\\end{aligned}\\ ] ]    in this equation , replacing @xmath148 by @xmath149 with @xmath7 normally distributed , the @xmath150 dgsm writes @xmath151 because @xmath152 ( due to the anova decomposition condition ) .",
    "moreover , the cauchy - schwartz inequality applied on @xmath153 gives @xmath154 ^ 2 \\le \\int_{r^{d } } x_i^2 df({\\mathbf{x } } )   \\int_{r^{d } } [ u_i({\\mathbf{x}})]^2 df({\\mathbf{x } } ) .\\ ] ] combining the two latter equations leads to the expression @xmath155 which is equivalent to eq .",
    "( [ grindeq__38 _ ] ) .",
    "the following theorem 7 is a generalization of theorem 1 .",
    "* theorem 7 . * if @xmath136 has a finite variance @xmath156 and @xmath90 , then @xmath157 the constant factor @xmath156 can not be improved .    * theorem 8 . *",
    "if @xmath136 is normally distributed with a finite variance @xmath156 , there exists the following upper bound between dgsm and the sobol total sensitivity index : @xmath158 the constant factor @xmath156 can not be reduced .",
    "* proof : * the proofs of these theorems are presented in @xcite .",
    "let @xmath159 be a point in the @xmath160dimensional unit hypercube with lebesgue measure @xmath161 .",
    "consider an arbitrary subset of the variables @xmath162 , @xmath163 , and the set of remaining complementary variables @xmath53 , so that @xmath164 , @xmath165 .",
    "further all the integrals are written without integration limits , by assuming that each integration variable varies independently from @xmath166 to @xmath167 .",
    "consider the following dgsm @xmath168 : @xmath169 * theorem 9 . * if @xmath18 is linear with respect to @xmath170 , then @xmath171 , or in other words @xmath172 .",
    "* theorem 10 .",
    "* the following general inequality holds : @xmath173 , or in other words @xmath174 .",
    "* proof : * the proofs of these theorems are given in @xcite .",
    "the second theorem shows that small values of @xmath168 imply small values of @xmath175 and this allows identification of a set of unessential factors @xmath52 ( usually defined by a condition of the type @xmath176 , where @xmath177 is small ) .",
    "consider the one dimensional case when the subset @xmath52 consists of only one variable @xmath179 , then measure @xmath180 has the form @xmath181 it is easy to show that @xmath182 . from ub1 it follows that @xmath183 thus small values of @xmath178 imply small values of @xmath1 , that are characteristic for non important variables @xmath2 . at the same time , the following corollary is obtained from theorem 9 : if @xmath18 depends linearly on @xmath2 , then @xmath184 .",
    "thus @xmath178 is closer to @xmath81 than @xmath40 .",
    "note that the constant factor @xmath185 in is the best possible .",
    "but in the general inequality for @xmath178 the best possible constant factor is unknown",
    ".    there is a general link between importance measures @xmath178 , @xmath186 and @xmath40 : @xmath187 then @xmath188      consider independent normal random variables @xmath34 with parameters @xmath189 . define @xmath178 as @xmath190.\\ ] ] the expectation over @xmath191 can be computed analytically . then @xmath192.\\ ] ]    * theorem 11 . *",
    "if @xmath34 are independent normal random variables , then for an arbitrary subset @xmath52 of these variables , the following inequality is obtained : @xmath193    * proof : * the proof is given in @xcite .",
    "as previously , consider the function @xmath33 , where @xmath194 are independent random variables , defined in the euclidian space @xmath35 , with cdfs @xmath36 . assume further that each @xmath195 admits a probability density function ( pdf ) , denoted by @xmath196 .",
    "in the following , all the integrals are written without integration limits .",
    "the developments in this section are based on the classical @xmath197-poincar inequality : @xmath198 where @xmath38 is the joint cdf of @xmath199 .",
    "is valid for all functions @xmath200 in @xmath201 such that @xmath202 and @xmath203 .",
    "the constant @xmath204 in eq .",
    "( [ eq : poincare ] ) is called a poincar constant of @xmath38 . in some cases ,",
    "it exists and optimal poincar constant @xmath205 which is the best possible constant . in measure theory , the poincar constants are expressed as a function of so - called cheeger constants @xcite which are used for sa in @xcite ( see @xcite for more details ) .",
    "a connection between total indices and dgsm has been established by @xcite for variables with continuous distributions ( called boltzmann probability measures in their paper ) .",
    "* theorem 12 .",
    "* let @xmath206 and @xmath207 be respectively the cdf and the pdf of @xmath195 , the following inequality is obtained : @xmath208 with @xmath209 the dgsm defined in eq .",
    "( [ grindeq__36 _ ] ) and @xmath210 ^ 2.\\ ] ]    * proof : * this result comes from the direct application of the @xmath197-poincar inequality ( [ eq : poincare ] ) on @xmath149 ( see eq . )",
    ".    in @xcite and @xcite , the particular case of log - concave probability distribution has been developed .",
    "it includes classical distributions as for instance the normal , exponential , beta , gamma and gumbel distributions . in this case , the constant writes @xmath211 with @xmath212 the median of the distribution @xmath206 .",
    "this allows to obtain analytical expressions for @xmath213 in several cases @xcite . in the case of a log - concave truncated distribution on",
    "@xmath214 $ ] , the constant writes @xcite @xmath215 with @xmath216 the quantile function of @xmath195 .",
    "table [ tab : poinconst ] gives some examples of poincar constants for several well - known and often used probability distributions in practice .",
    ".poincar constants for a few probability distributions . [ cols=\"<,^,^\",options=\"header \" , ]     , @xmath0 , lb2 and ub1 for all input variables .",
    "example 2 with @xmath217 $ ] , @xmath218.,width=303,height=240 ]    * example 3 .",
    "* consider the reduced morris test function with four inputs @xcite : @xmath219 @xmath220{c }      0.05 \\\\       0.59 \\\\       10 \\\\       0.21      \\end{array }      \\right ]      \\hspace{0.5cm},\\hspace{0.5 cm }      b_{ij}=\\left [                          \\begin{array}[c]{c c c c }                              0&80&60&40\\\\                               0&30&0.73&0.18\\\\                               0&0&0.64&0.93\\\\                               0&0&0&0.06                          \\end{array }          \\right ]      \\hspace{0.5cm},\\hspace{0.5 cm }      b_{ij4}=\\left [                          \\begin{array}[c]{c c c c }                              0&10&0.98&0.19\\\\                               0&0&0.49&50\\\\                               0&0&0&1\\\\                               0&0&0&0                          \\end{array }          \\right ] \\;.\\ ] ] the indices @xmath221 are null .",
    "the four input variables @xmath7 @xmath222 follow uniform distribution on @xmath84 $ ] .",
    "sobol indices are computed via the monte - carlo scheme of @xcite ( using two initial matrices of size @xmath223 ) , while dgsm are computed with monte - carlo sampling of size @xmath224 ( using derivatives computing by finite differences with @xmath225 ) , with @xmath224 ranging from @xmath226 to @xmath227 , figure  [ majoration_morris ] shows that dgsm bounds ub@xmath228 are greater than the total sobol indices @xmath229 ( for @xmath230 ) as expected , except for @xmath231 which is a too small sample size . for small @xmath229 , ub@xmath228 is close to the @xmath229 value .",
    "it confirms that dgsm bounds are first useful for screening exercises .",
    "other numerical tests involving non - uniform and non - normal distributions for the inputs can be found in @xcite and @xcite .",
    "@xmath232{morris_dgsm_1.png}\\ ] ]",
    "this paper has shown that using lower and upper bounds based on dgsm is possible in most cases to get a good practical estimation of the values of @xmath0 at a fraction of the cpu cost for estimating @xmath0 .",
    "upper and lower bounds can be estimated using mc / qmc integration methods using the same set of partial derivative values .",
    "most of the applications show that dgsm can be used for fixing unimportant variables and subsequent model reduction because small values of dgsm imply small values of @xmath0 . in a general case variable ranking can be different for dgsm and variance based methods but for linear function and product function",
    ", dgsm can give the same variable ranking as @xmath0 .",
    "engineering applications of dgsm can be found for instance in @xcite and @xcite for biological systems modeling , @xcite for structural mechanics , @xcite for an aquatic prey - predator model , @xcite for a river flood model and @xcite for an hydrogeological simulator of the oil industry .",
    "one of the main prospect in practical situations is to use algorithmic differentiation in the reverse ( adjoint ) mode on the numerical model , allowing to estimate efficiency all partial derivatives of this model ( see ) . in this case",
    ", the cost of dgsm estimations would be independent of the number of input variables .",
    "obtaining global sensitivity information in a reasonable cpu time cost is therefore possible even for large - dimensional model ( several tens and spatially distributed inputs in the recent and pioneering attempt of @xcite ) .",
    "when the adjoint model is not available , the dgsm estimation remains a problem in high dimension and novel ideas have to be explored @xcite @xcite . coupling dgsm with non - parametric regression techniques or metamodel - based technique ( see ) is another research prospect as first shown by @xcite and @xcite .",
    "the authors would like to thank prof .",
    "i. sobol , dr .",
    "s. song , s. petit , dr .",
    "m. lamboni , dr .",
    "o. roustant and prof .",
    "f. gamboa for their contributions to this work .",
    "one of the authors ( sk ) gratefully acknowledges the financial support by the epsrc grant ep / h03126x/1 .",
    "iooss b , popelin al , blatman g , ciric c , gamboa f , lacaze s , lamboni m ( 2012 ) some new insights in derivative - based global sensitivity measures . in : proceedings of the psam11 esrel 2012 conference , helsinki , finland , pp 10941104        kiparissides a , kucherenko s , mantalaris a , pistikopoulos e ( 2009 ) global sensitivity analysis challenges in biological systems modeling .",
    "journal of industrial and engineering chemistry research 48:11351148    kucherenko s , song s ( 2015 ) derivative - based global sensitivity measures and their link with sobol sensitivity indices . in : cools r , nuyens d ( eds ) proceedings of the eleventh international conference on monte carlo and quasi - monte carlo methods in scientific computing ( mcqmc 2014 ) , springer - verlag , , leuven , belgium                        rodriguez - fernandez m , banga j , doyle f ( 2012 ) novel global sensitivity analysis methodology accounting for the crucial role of the distribution of input parameters : application to systems biology models . international journal of robust nonlinear control 22:10821102          saltelli a , annoni p , azzini i , campolongo f , ratto m , tarantola s ( 2010 ) variance based sensitivity analysis of model output . design and estimator for the total sensitivity index .",
    "computer physics communication 181:259270                      touzany s , busby d ( 2014 ) screening method using the derivative - based global sensitivity indices with application to reservoir simulator .",
    "oil & gas science and technology  rev ifp energies nouvelles 69:619632"
  ],
  "abstract_text": [
    "<S> the method of derivative based global sensitivity measures ( dgsm ) has recently become popular among practitioners . </S>",
    "<S> it has a strong link with the morris screening method and sobol sensitivity indices and has several advantages over them . </S>",
    "<S> dgsm are very easy to implement and evaluate numerically . </S>",
    "<S> the computational time required for numerical evaluation of dgsm is generally much lower than that for estimation of sobol sensitivity indices . </S>",
    "<S> this paper presents a survey of recent advances in dgsm concerning lower and upper bounds on the values of sobol total sensitivity indices @xmath0 . using these bounds it is possible in most cases to get a good practical estimation of the values of @xmath1 . </S>",
    "<S> several examples are used to illustrate an application of dgsm .    </S>",
    "<S> keywords : sensitivity analysis , sobol indices , morris method , model derivatives , dgsm , poincar inequality </S>"
  ]
}