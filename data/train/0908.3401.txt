{
  "article_text": [
    "recurrence times measure the time interval a system takes to return to a neighborhood of some state , being that it was previously in some other state . among the many ways time recurrences can be defined , two approaches that have recently attracted much attention are the first poincar recurrence times ( fprs ) @xcite and the recurrence plots ( rps ) @xcite .",
    "while poincar recurrences refer to the sequence of time intervals between two successive visits of a trajectory ( or a signal ) to one particular interval ( or a volume if the trajectory is high dimensional ) , a recurrence plot refers to a visualization of the values of a square array which indicates how much time it takes for two points in a trajectory with @xmath0 points to become neighbors again .",
    "both techniques provide similar results but are more appropriately applicable in different contexts .",
    "while the fprs are more appropriated to obtain exact dynamical quantities ( lyapunov exponents , dimensions , and the correlation function ) of dynamical systems @xcite , the rps are more oriented to estimate relevant quantities and statistical characteristics of data coming from complex systems @xcite .    the main argument in order to use recurrence times to model complex systems",
    "@xcite is that one can easily have experimental access to them . in order to know if a model can be constructed from the recurrence times , it is essential that at least the series of return times contains the same amount of information generated by the complex system , information being quantified by the entropy .",
    "entropy is an old thermodynamic concept and refers to the disorganized energy that can not be converted into work .",
    "it was first mathematically quantified by boltzmann in 1877 as the logarithm of the number of microstates that a gas occupies .",
    "more recently , shannon @xcite proposed a more general way to measure entropy @xmath1 in terms of the probabilities @xmath2 of all possible @xmath3 states of a system:@xmath4    applied to non - periodic continuous trajectories , e.g. chaotic trajectories , @xmath1 is an infinite quantity due to the infinitely many states obtained by partitioning the phase space in arbitrarily small sites .",
    "therefore , for such cases it is only meaningful to measure entropy relative to another trajectory .",
    "in addition , once a dynamical system evolves with time , it is always useful for comparison reasons to measure its entropy production per unit of time .",
    "such an ideal entropy definition for a dynamical system was introduced by kolmogorov in 1958 @xcite and reformulated by sinai in 1959 .",
    "it is known as the kolmogorov - sinai ( ks ) entropy , denoted by @xmath5 , basically the shannon s entropy of the set per unit of time @xcite , and it is the most successful invariant quantity that characterize a dynamical system @xcite .",
    "however , the calculation of the ks entropy to systems that might possess an infinite number of states is a difficult task , if not impossible . for a smooth chaotic system @xcite ( typically happens for dissipative systems that present an attractor )",
    ", pesin @xcite proved an equality between @xmath5 and the sum of all the positive lyapunov exponents .",
    "however , lyapunov exponents are difficult or even impossible to be calculated in systems whose equations of motion are unknown . therefore , when treating data coming from complex systems , one should use alternative ways to calculate the ks entropy , instead of applying pesin s equality .    methods to estimate the correlation entropy , @xmath6 , a lower bound of @xmath5 , and to calculate @xmath5 from time series were proposed in refs .",
    "@xcite . in ref .",
    "@xcite @xmath6 is estimated from the correlation decay and in ref .",
    "@xcite by the determination of a generating partition of phase space that preserves the value of the entropy .",
    "but while the method in ref .",
    "@xcite unavoidably suffers from the same difficulties found in the proper calculation of the fractal dimensions from data sets , the method in ref .",
    "@xcite requires the knowledge of the generating partitions , information that is not trivial to be extracted from complex data @xcite .",
    "in addition , these two methods and similar others as the one in ref . @xcite require the knowledge of a trajectory .",
    "our work is devoted to systems whose trajectory can not be measured .",
    "a convenient way of determining all the relevant states of a system and their probabilities ( independently whether such a system is chaotic ) is provided by the fprs and the rps . in particular to the shannon s entropy , in refs .",
    "@xcite ways were suggested to estimate it from the rps . in refs .",
    "@xcite a subset of all the possible probabilities of states , the probabilities related to the level of coherence / correlation of the system , were considered in eq .",
    "( [ se ] ) .",
    "therefore , as pointed out in ref .",
    "@xcite , the obtained entropic quantity does not quantify the level of disorganization of the system .",
    "remind that unavoidably shannon s entropy calculated from rps or fprs depends on the resolution with which the returns are measured .",
    "the main result of this contribution is to show how to easily estimate the ks - entropy from return times , without the knowledge of a trajectory .",
    "we depart from similar ideas as in refs .",
    "@xcite and show that the ks entropy is the shannon entropy [ in eq .",
    "( [ se ] ) ] calculated considering the probabilities of all the return times observed divided by the length of the shortest return measured .",
    "this result is corroborated with simulations on the logistic map , the hnon map , and coupled maps .",
    "we also show how to estimate a lower bound for the ks entropy using for that the returns with the shortest lengths ( the most probable returns ) , an approach oriented to the use of our ideas in experimental data .",
    "finally , we discuss in more details the intuitive idea of lettelier @xcite to calculate the shannon s entropy from a rp and show the relation between letellier s result and the ks entropy .",
    "let us start with some definitions . by measuring two subsequent returns to a region ,",
    "one obtains a series of time intervals ( fprs ) denoted by @xmath7 ( with @xmath8 ) .",
    "the characterization of the fprs is done by the probability distribution @xmath9 of @xmath7 , where @xmath10 represents the volume within which the fprs are observed . in this work",
    ", @xmath10 is a @xmath11-dimensional box , with sides @xmath12 , and @xmath11 is the phase space dimension of the system being considered .",
    "we denote the shortest return to the region @xmath10 as @xmath13 .    given a trajectory @xmath14 , the recurrence plot is a two - dimensional graph that helps the visualization of a square array @xmath15:@xmath16 where @xmath17 is a predefined threshold and @xmath18 is the heaviside function @xcite . in the coordinate @xmath19 of the rp one plots a black point if @xmath20 , and a white point otherwise .",
    "there are many interesting ways to characterize a rp , all of them related to the lengths ( and their probabilities of occurrence ) of the diagonal , horizontal , and vertical segments of _ recurrent _ points ( black points ) and of _ nonrecurrent _ points ( white points ) . differently from ref .",
    "@xcite where it was used the nonrecurrent diagonal segments , we consider here the vertical nonrecurrent and recurrent segments because they provide a direct link to the fprs @xcite .",
    "given a column @xmath3 , a vertical segment of @xmath21 white points starting at @xmath22 and ending at @xmath23 , indicates that a trajectory previously in the neighborhood of the point @xmath24 returns to it firstly after @xmath25 iterations in the neighborhood of the point @xmath24 , basically the same definition as the fpr to a volume centered at @xmath26 .",
    "however , the white points represent returns to the neighborhood of @xmath24 which are larger than 1 . in order to obtain the returns of length 1",
    ", one needs to use the recurrent segments , the segments formed by black points .",
    "a recurrent vertical segment at the column @xmath3 , starting at @xmath22 and ending at @xmath27 , means that it occurred @xmath21 first returns of length 1 to the neighborhood of the point @xmath26 .",
    "the probability density of the return times observed in the rp is represented also by @xmath9 .",
    "it is constructed considering the first returns observed in all columns of the rp and it satisfies @xmath28 .",
    "notice that the shannon s entropy of first returns of non - periodic continuous systems becomes infinite @xcite as the size @xmath29 of the volume @xmath10 approaches zero . for chaotic systems ( as well as for stochastic systems )",
    "the reason lies on the fact that the probability density @xmath9 approaches the exponential form @xmath30 @xcite , where @xmath31 is the probability of finding the trajectory within the volume @xmath10 .    placing in eq .",
    "( [ se ] ) the probabilities of returns @xmath9 , we can write that @xmath32 , where @xmath33 is some characteristic time of the returns @xcite that depends on how the returns are measured . for the fprs there",
    "exists three characteristic times : the shortest , the longest and the average return . the quantity @xmath33 can not be the longest return since it is infinite .",
    "it can not be the average return , since one would arrive to @xmath34 which equals zero as @xmath35 .",
    "therefore , @xmath36 is the only remaining reasonable characteristic time to be used which lead us to @xmath37)=\\frac{1}{\\tau_{min}({\\mathcal{b}}[\\epsilon ] ) } \\sum_{\\tau } \\rho(\\tau,{\\mathcal{b}}[\\epsilon ] ) \\log{\\left(\\frac{1 } { \\rho(\\tau,{\\mathcal{b}}[\\epsilon ] ) } \\right)}. \\label{hks_prob}\\ ] ]    for uniformly hyperbolic chaotic systems ( tent map , for example ) , we can prove the validity of eq .",
    "( [ hks_prob ] ) . from ref .",
    "@xcite we have that @xmath38))\\ ] ] a result derived from the fact that the ks entropy exponentially increases with the number of unstable periodic orbits embedded in the chaotic attractor .",
    "since @xmath39 as @xmath35 , assuming @xmath40 to be very large , and noticing that @xmath41 } d\\tau= -log{[\\mu]}+1 $ ] , assuming that @xmath42 and noticing that for such systems @xmath43=\\rho(\\tau_{min},\\epsilon)$ ] , we finally arrive that @xmath44 } =   - \\frac{1}{\\tau_{min } } \\sum_{\\tau } \\rho(\\tau ) \\log{[\\rho(\\tau ) ] } \\label{demonstration}\\ ] ] and therefore , the right - hand side of eq .",
    "( [ hks_prob ] ) indeed reflects the ks entropy .",
    "but notice that eq .",
    "( [ hks_prob ] ) is being applied not only to non - uniformly hyperbolic systems ( logistic and hnon maps ) but also to higher dimensional systems ( two coupled maps ) .",
    "this result can also be derived from ref .",
    "@xcite where it was shown that the positive lyapunov exponent @xmath45 in hyperbolic 1d maps is @xmath46}}{\\tau_{min}(\\mathcal{b}[\\epsilon])}.   \\label{benoit}\\ ] ] since @xmath47 as @xmath35 , and using that @xmath48 ( pesin s equality ) , and finally noticing that @xmath49 } d\\tau= -log{[\\mu]}+1 $ ] , one can arrive to the conclusion that @xmath36 in eq .",
    "( [ hks_prob ] ) .    the quantity in eq .",
    "( [ hks_prob ] ) is a local estimation of the ks entropy . to make a global estimation we can define the average @xmath50 \\label{average_hks}\\ ] ] representing an average of @xmath51 $ ]",
    "calculated considering @xmath52 different regions in phase space .    in order to estimate the ks entropy in terms of the probabilities obtained from the rps , one should use @xmath53 , i.e. , replace @xmath40 in eq .",
    "( [ hks_prob ] ) by @xmath54 , where @xmath55 , the average value of the shortest return observed in every column of the rp .",
    "the reason to work with an average value instead of using the shortest return considering all columns of the rp is that every vertical column in the rp defines a shortest return @xmath56 ( @xmath57 ) , and it is to expect that there is a nontypical point @xmath3 for which @xmath58 . imagining that the rp is constructed considering arbitrarily small regions ( @xmath59 ) and that we could treat an arbitrarily long data set",
    ", the column of the rp which would produce @xmath60 would be just one out of infinite others which produce @xmath61",
    ". there would be also a finite number of columns which would produce @xmath40 of the order of one ( but larger than one ) , but also those could be neglect when estimating the ks - entropy from the rps .",
    "the point we want to make in here is that the possible existence of many columns for which one has @xmath60 are a consequence of the finite resolution with which one constructs a rp . in order to minimize such effect in our calculation",
    "we just ignore the fact that we have indeed found in the rp @xmath60 , and we consider as @xmath40 any return time longer than 1 as the minimal return time . in fact , neglecting the existence of returns of length one is a major point in the work of ref .",
    "@xcite , since there only the nonrecurrent diagonal segments are considered @xcite , and thus , the probability of having a point returning to its neighborhood after one iteration is zero .    from the conditional probabilities of returns , a lower bound for the ks entropy",
    "can be estimated in terms of the fprs and rps by @xmath37 ) \\geq - \\frac{1}{n } \\sum_{i=1}^n \\frac{1}{p_i } \\frac{\\rho(\\tau_i+p_i)}{\\rho(\\tau_i ) } \\log{\\left[\\frac{\\rho(\\tau_i+p_i)}{\\rho(\\tau_i)}\\right ] } \\label{hks_cond}\\ ] ] where we consider only the returns @xmath7 for which @xmath62 and @xmath63 , with @xmath64 .    the derivation of eq .",
    "( [ hks_cond ] ) is not trivial because it requires the use of a series of concepts and quantities from the ergodic theory . in the following ,",
    "we describe the main steps to arrive at this inequality .",
    "first we need to understand the way the ks - entropy is calculated via a spatial integration . in short ,",
    "the ks - entropy is calculated using the shannon s entropy of the conditional probabilities of trajectories within the partitions of the phase space as one iterates the chaotic system backward @xcite .",
    "more rigorously , denote a phase space partition @xmath65 . by a partition",
    "we refer to a space volume but that is defined in terms of markov partitions .",
    "denote @xmath66 as @xmath67 where @xmath68 ( @xmath69 ) , where @xmath70 is a chaotic transformation .",
    "define @xmath71 and @xmath72 represents the probability measure of the set @xmath66 .",
    "the ks - entropy is defined as @xmath73 , where the summation is taken over @xmath74 iterations .",
    "assume now that the region @xmath10 represents the good partition @xmath65 .",
    "the region @xmath75 is the result of @xmath76 , i.e. , a @xmath77-th backward iteration of @xmath10 .",
    "so , clearly , if one applies @xmath77 forward iterations to @xmath75 , then @xmath78 .",
    "the quantities @xmath79 and @xmath72 refer to the measure of the chaotic attractor inside @xmath80 and @xmath66 , respectivelly . by measure",
    "we mean the natural measure , i.e. the frequency with which a typical trajectory visits a region .",
    "@xmath81 refers to the measure that remained in @xmath10 after @xmath82 iterations and @xmath83 the measure that remained in @xmath10 after @xmath84 iterations .    for @xmath85 ,",
    "we have that @xmath86 . also for finite values of @xmath82 , one has that @xmath87 .",
    "for any finite @xmath82 , we can split this fraction into two components : @xmath88 .",
    "@xmath89 refers to the measure in @xmath10 associated with unstable periodic orbits ( upos ) that return to @xmath10 , after @xmath82 iteration of @xmath70 , at least twice or more times .",
    "@xmath90 refers to the measure in @xmath10 associated with upos that return to @xmath10 only once .    as it is shown in ref .",
    "@xcite , @xmath91 , which in other words means that the probability density of the fprs in @xmath10 is given by @xmath92 .",
    "but , notice that for @xmath93 , @xmath94 since only returns associated with upos that return once can be observed inside @xmath10 , and therefore @xmath9 = @xmath95 , if @xmath96 .",
    "consequently , we have that @xmath97 , since @xmath98 and @xmath99 .    the remaining calculations to arrive in eq .",
    "( [ hks_cond ] ) consider the measure of the region @xmath100 ( instead of @xmath101 ) in order to have a positive condition probability , i.e. @xmath102 , with @xmath103 representing the measure of the trajectories that return to @xmath10 after @xmath104 iterations and @xmath105 the measure of the trajectories that return to @xmath10 after @xmath106 iterations .",
    "the inequality in eq .",
    "( [ hks_cond ] ) comes from the fact that one neglects the infinitely many terms coming from the measure @xmath107 that would contribute positively to this summation .",
    "in order to derive eq .",
    "( [ demonstration ] ) , we have assumed that @xmath109 } d\\tau= -\\log{[\\mu]}+1 $ ] , which is only true when @xmath40=0 . in reality , for @xmath110 , we have @xmath111 } d\\tau$ ] = @xmath112 + 1 $ ] , but as @xmath29 tends to zero @xmath113 and therefore , as assumed @xmath114 } d\\tau \\approxeq -\\log{[\\mu]}+1 $ ] .    making the same assumptions as before that @xmath47 as @xmath35 , and using eq .",
    "( [ benoit ] ) , then eq . ( [ hks_prob ] ) can be written as @xmath37 ) \\approxeq",
    "\\lambda + \\frac{1}{\\tau_{min}({\\mathcal{b}}[\\epsilon])}. \\label{erro}\\ ] ]    theoretically , one can always imagine a region @xmath29 with an arbitrarily small size , which would then make the term @xmath115 to approach zero .",
    "but , in practice , for the considered values of @xmath29 , we might have ( for atypical intervals ) shortest returns as low as @xmath116 . as a result",
    ", we expect that numerical calculations of the quantity in eq .",
    "( [ hks_prob ] ) would lead us to a value larger than the positive lyapunov exponent , as estimated from the returns of the trajectory to a particular region .",
    "naturally , @xmath115 would provide a local deviation of the quantity in eq .",
    "( [ hks_prob ] ) with respect to the ks entropy . to have a global estimation of the error we are making by estimating the ks entropy",
    ", we should consider the error in the average quantity @xmath108 which is given by @xmath117 ) } \\label{erro_medio}\\ ] ] where the average is taken over @xmath52 different regions in phase space , and thus for chaotic systems with no more than one positive lyapunov exponent @xmath118    to generalize this result to higher dimensional systems , we make the same assumptions as the ones to arrive to eq .",
    "( [ erro ] ) , but now we use eq .",
    "( [ demonstration ] ) .",
    "we arrive that @xmath119 ) \\rangle \\approxeq h + e ,   \\label{erro1}\\ ] ] where @xmath120 denotes the exact value of the ks entropy .",
    "finally , it is clear from eq .",
    "( [ erro1 ] ) that @xmath121 ) \\rangle$ ] is an upper bound for the ks entropy .",
    "thus , @xmath122 ) \\rangle .",
    "\\label{erro2}\\ ] ]",
    "in order to illustrate the performance of our formulas we use the logistic map [ @xmath123 , the hnon map [ @xmath124 , and @xmath125 , and a system of two mutually coupled linear maps [ @xmath126 and @xmath127 , @xmath128 , systems for which pesin s equality holds .",
    "the parameter @xmath129 in the coupled maps represents the coupling strength between them , chosen to produce a trajectory with two positive lyapunov exponents .    using eqs .",
    "( [ hks_prob ] ) and ( [ benoit ] ) to estimate @xmath5 and @xmath45 furnishes good values if the region @xmath10 where the returns are being measured is not only sufficiently small but also well located such that @xmath40 is sufficiently large . in such a case the trajectories that produce such a short return visit the whole chaotic set @xcite . for that reason we measure the fprs for 50 different regions with a sufficiently small volume dimension , denoted by @xmath12 , and use the fprs that produce the largest @xmath40 , minimizing @xmath5 . since the lower bound of @xmath5 in eq .",
    "( [ hks_cond ] ) is a minimal bound for the ks entropy , the region chosen to calculate it is the one for which the lower bound is maximal .",
    "this procedure makes @xmath5 and its lower bound ( calculated using the fprs ) not to depend on @xmath10 .    as pointed out in ref .",
    "@xcite , one should consider volume dimensions ( also known as thresholds ) which depend linearly on the size of the attractor @xcite , in order to calculate the shannon s entropy . in this work , except for the hnon map , we could calculate well @xmath5 , @xmath45 and a lower bound for @xmath5 from the fprs and rps , considering for every system fixed values @xmath12 and @xmath17 . for the hnon map , as we increase the parameter @xmath130 producing more chaotic attractors , we increase linearly the size of the volume dimension @xmath17 within the interval @xmath131 $ ] .",
    "we first compare @xmath5 ( see fig .",
    "[ fig1 ] ) , calculated from eq .",
    "( [ hks_prob ] ) in terms of the probabilities coming from the fprs and rps , in green diamonds and brown stars , respectively , with the value of the ks entropy calculated from the sum of the positive lyapunov exponents , represented by the brown straight line .",
    "as expected @xmath5 is close to the sum of all the positive lyapunov exponents .",
    "when the attractor is a stable periodic orbit we obtain that @xmath5 is small if calculated from the rps .",
    "in such a case , we assume that @xmath132 if calculated from the fprs .",
    "this assumption has theoretical grounds , since if the region is centered in a stable periodic attractor and @xmath133 ( what can be conceptually make ) , one will clearly obtain that the attractor is periodic .    the value of the lyapunov exponent calculated from the formula ( [ benoit ] ) is represented in fig .",
    "[ fig1 ] by the blue up triangles . as it can be checked in this figure , eq . ( [ benoit ] ) holds only for 1d hyperbolic maps .",
    "so , it works quite well for the logistic map ( a 1d `` almost '' uniformly hyperbolic map ) and somehow good for the hnon map .",
    "however , it is not appropriate to estimate the sum of the positive lyapunov exponents coming from 2d coupled systems",
    ". this formula assumes sufficient hyperbolicity and one - dimensionality such that @xmath134 .    to compare our approach with the method in ref .",
    "@xcite , we consider the hnon map with @xmath135=1.4 and @xmath136 for which the positive lyapunov exponent equals 0.420 .",
    "therefore , by using ruelle equality , @xmath137 . in ref .",
    "@xcite it is obtained that the correlation entropy @xmath6 equals 0.325 , with @xmath138 and in ref .",
    "@xcite @xmath139 . from eq .",
    "( [ hks_prob ] ) , we obtain @xmath140 and from eq .",
    "( [ hks_cond ] ) , we obtain @xmath141 , for @xmath12=0.01 .    in fig .",
    "[ fig2](a - c ) , we show the lower bound estimation of @xmath5 [ in eq .",
    "( [ hks_cond ] ) ] in terms of the rps ( black circles ) and in terms of fprs ( red squares ) .",
    "as expected , both estimations follow the tendency of @xmath5 as we increase @xmath135 .    another possible way eq .",
    "( [ hks_prob ] ) can be used to estimate the value of the ks - entropy is by averaging all the values obtained for different intervals , the quantity @xmath142 in eq .",
    "( [ average_hks ] ) . in fig .",
    "[ fig3](a ) , we show the values of @xmath5 as calculated from eq .",
    "( [ hks_prob ] ) considering a series of fprs with 500.000 returns of trajectories from the logistic map . for each value of the control parameter @xmath143 ,",
    "we randomnly pick 10 different intervals with @xmath12=0.00005 .",
    "the average @xmath108 is shown in fig .",
    "[ fig3](b ) .",
    "as one can see , @xmath108 is close to the lyapunov exponent @xmath45 .",
    "notice that from fig .",
    "[ fig3](a ) one can see that the minimal value of @xmath5 ( obtained for the largest @xmath40 ) approaches well the value of @xmath45 .    in order to have a more accurate estimation of the ks - entropy for the hnon map , we have used in figs .",
    "[ fig1](b ) and [ fig2](b ) a varying @xmath17 depending on the value of the parameter @xmath135 , exactly as suggested in @xcite , but similar results would be obtained considering a constant value . as an example , in fig .",
    "[ fig3](c ) we show the minimal value of @xmath5 considering regions with @xmath144 , for a large range of the control parameter @xmath135 .    in order to illustrate how the number of regions as well as the size of the regions alter the estimation of the ks - entropy , we show , in fig .",
    "[ fig4](a - c ) , the same quantities shown in fig .",
    "[ fig3](a - b ) , but now from fprs exclusively coming from the logistic map , considering 500 randonmly selected regions all having sizes @xmath12=0.0002 . recall that in figs .",
    "[ fig1 ] and [ fig3 ] , the minimal value of @xmath5 was chosen out of no more than 50 randonmly selected regions . comparing figs .",
    "[ fig3](b ) and [ fig4](b ) one notices that an increase in the number of selected regions is responsible to smooth the curve of @xmath108 with respect to @xmath143 .",
    "concerning the minimal value of @xmath5 , the use of intervals with size @xmath145 provides values close to the lyapunov exponent if this exponent is sufficiently low ( what happens for @xmath146 ) .",
    "otherwise , these values deviate when this exponent is larger ( what happens for @xmath147 ) .",
    "this deviation happens because for these chaotic attractors the size of the chosen interval was not sufficiently small @xcite .",
    "notice that the estimated ks entropy deviates from @xmath45 .",
    "see , for example , figs . [ fig3](b ) and [ fig4](b ) .",
    "one sees two main features in these figures .",
    "the first is that for most of the simulations , @xmath148 .",
    "the second is that the larger @xmath45 is , the larger the deviation is .",
    "the reason for the first feature can be explained by eqs .",
    "( [ erro_medio1 ] ) and ( [ erro2 ] ) .",
    "the reason for the second is a consequence of the fact that the larger the lyapunov exponent is , the smaller @xmath40 is , and therefore the larger the error in the estimation of the ks entropy .    to see that our error estimate provides reasonable results",
    ", we calculate the quantities @xmath108 ( green diamonds in fig .",
    "[ fig5 ] ) , for the logistic map considering a series of 250.000 fprs to @xmath52=100 randomly selected regions of size @xmath145 , and the average error @xmath149 , in eq .",
    "( [ erro_medio1 ] ) [ shown in fig .",
    "[ fig5 ] by the error bars ] .",
    "the value of the positive lyapunov exponent is shown in the full brown line .",
    "the error in our estimation is inversely proportional to the shortest return .",
    "had we considered smaller @xmath29 regions , @xmath40 would be typically larger and as a consequence we would obtain a smaller error @xmath149 in our estimation for the ks entropy .",
    "had we consider a larger number of fprs , the numerically obtained value of @xmath40 would be typically slightly smaller , making the error @xmath149 to become slightly larger .",
    "so , the reason of why the positive lyapunov exponent in fig . [ fig5 ]",
    "is located bellow the error bars for the quantity @xmath108 is a consequence of the fact that we have only observed 250.000 returns , producing an overestimation for the value of @xmath40 .",
    "had we considered a larger number of fprs would make the error @xmath149 to become slightly larger .",
    "the considered maps are ergodic . and",
    "therefore , the more ( less ) intervals used , the shorter ( the longer ) the time series needed in order to calculate the averages from the fpr as well as from the rp , as the average @xmath108 .",
    "concluding , we have shown how to estimate the kolmogorov - sinai entropy and a lower bound of it using the poincar first return times ( fprs ) and the recurrence plots .",
    "this work considers return times in discrete systems .",
    "the extension of our ideas to systems with a continuous description can be straightforwardly made using the ideas in ref .",
    "@xcite .",
    "we have calculated the expected error in our estimation for the ks entropy and shown that this error appears due to the fact that fprs can only be physically measured considering finite sized regions and only a finite number of fprs can be measured .",
    "this error is not caused by any fundamental problems in the proposed eq .",
    "( [ hks_prob ] ) . nevertheless , even for when such physical limitations are present , the global estimator of the ks entropy [ eq .",
    "( [ average_hks ] ) ] can be considered as an upper bound for the ks entropy [ see eq .",
    "( [ erro2 ] ) ] .",
    "v. afraimovich , chaos , * 7 * , 12 ( 1997 ) ; n. hadyn , j. luevano , g. mantica , s. vaienti , phys .",
    "lett . , * 88 * ( 2002 ) ; b. saussol , discrete and continuous dynamical systems a , * 15 * , 259 ( 2006 ) ; n. hadyn , _ et al .",
    "lett . , * 88 * , 224502 ( 2002 ) .",
    "n. marwan , m. c. romano , m. thiel , _ et al .",
    ". reports , * 438 * , 237 ( 2007 ) ; m. thiel , m. c. romano , j. kurths , _ et al .",
    "_ , europhys . lett . * 75 * , 535 ( 2006 ) ; m. c. romano , m. thiel , j. kurths , and c.grebogi , phys .",
    "e * 76 * , 036211 ( 2007 ) .",
    "the time version of the ks entropy is calculated from the average value of the difference between the shannon entropies ( per unit of time ) of a trajectory with a length @xmath150 and of a trajectory with a length @xmath151 , for all possible values of @xmath152 .",
    "more rigorously , @xmath153 $ ] , where @xmath154 is the shannon s entropy of a trajectory that visits @xmath155 volumes of sides @xmath29 in phase space . in each volume",
    "the trajectory remains during a time interval @xmath156 .",
    "as @xmath157 , the terms @xmath158 are infinities , but not the difference @xmath159 $ ] .",
    "since @xmath160 = k_{n } - k_{0}$ ] and that @xmath161 , then @xmath162 .",
    "so , basically the time version of the ks - entropy can be thought as the shannon s entropy divided by a characteristic time , @xmath33 , yet to be determined .                      while the white vertical segments correspond to the first poincar returns to an interval centered at a point , the white diagonal segments provide the @xmath152-th poincar returns . as an example , imagine that there are two black points placed at the coordinates ( 10,20 ) and ( 20,30 ) in the rp . in the white diagonal segment connecting these two black points",
    "there are no black points , which means that we have a nonrecurrent diagonal segment of length @xmath163 . that can only be possible if two first poincar returns of length 10 happened , or if one second poincar return of length 10 happened .",
    "assuming that @xmath164 , this leads @xmath165 . since @xmath166 , if @xmath35 , then @xmath167 .",
    "the exponential form of @xmath168 relies on the fact that the first returns can be imagined to be uncorrelated random variables due to the fast decay of correlation that chaotic systems have .",
    "the exponential form of @xmath168 to arbitrarely small volumes is proved for a large class of uniformly hyperbolic maps ( see ref .",
    "@xcite ) , for one - dimensional non - uniform hyperbolic maps ( unimodal maps , see ref .",
    "@xcite and multimodal maps , see @xcite ) . for finite sized volumes",
    "@xmath168 still preserves the exponential form @xcite .",
    "usually , the larger an attractor , the larger the lyapunov exponent . as discussed in @xcite , @xmath169 . assuming that a sufficiently small threshold @xmath29 provides a sufficiently large @xmath40 , this leads to @xmath170 and therefore the more chaotic an attractor",
    ", the larger @xmath29 must be in order to have a sufficiently large @xmath40 . since the series of fprs can be ( in principle theoretically ) calculated from arbitrarily large trajectories , we can consider ( from a theoretical perspective ) regions sufficiently small so that one can obtain fprs with sufficiently large @xmath40 , even for different values of the control parameters . on the other hand , rps",
    "are constructed with trajectories ( time series ) shorter than the ones used for the fprs . in order to have a rp",
    "for which @xmath171 is sufficiently large and at the same time producing a reasonable continuous distribution @xmath172 , the volume dimensions @xmath17 considered to construct the rps should be reasonably larger than @xmath12 .",
    "in addition , as one changes the control parameters producing more complex chaotic attractors , we might have to increase the value of @xmath17 ."
  ],
  "abstract_text": [
    "<S> * abstract : * observing how long a dynamical system takes to return to some state is one of the most simple ways to model and quantify its dynamics from data series . </S>",
    "<S> this work proposes two formulas to estimate the ks entropy and a lower bound of it , a sort of shannon s entropy per unit of time , from the recurrence times of chaotic systems . </S>",
    "<S> one formula provides the ks entropy and is more theoretically oriented since one has to measure also the low probable very long returns . </S>",
    "<S> the other provides a lower bound for the ks entropy and is more experimentally oriented since one has to measure only the high probable short returns . </S>",
    "<S> these formulas are a consequence of the fact that the series of returns do contain the same information of the trajectory that generated it . </S>",
    "<S> that suggests that recurrence times might be valuable when making models of complex systems . </S>"
  ]
}