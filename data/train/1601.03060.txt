{
  "article_text": [
    "when faced with noisy and incomplete sensory information , humans and other animals often behave near - optimally @xcite .",
    "optimal behavior requires that the brain compute posterior distributions over task - relevant variables , which often involves complex operations such as multiplying probability distributions or marginalizing over latent variables .",
    "how do neural circuits implement such operations ?",
    "a prominent framework addressing this question is the probabilistic population coding ( ppc ) framework , according to which the population activity on a single trial encodes a probability distribution rather than a single estimate and computations with probability distributions can be carried out by suitable operations on the corresponding neural responses @xcite .",
    "for example , ma et al .",
    "@xcite showed that if neural variability belongs to a particular class of probability distributions , the posterior distribution in cue combination tasks can be computed with a linear combination of the input responses .",
    "moreover , in this scheme , the form of neural variability is preserved between the input and the output , leading to an elegantly modular code . in more complex tasks ,",
    "linear operations are insufficient and it has been argued that multiplication and division of neural responses are necessary for optimal inference @xcite .    upon closer look ,",
    "however , these previous implementations of ppc suffer from several shortcomings .",
    "first , the networks in these studies were either fully manually designed , or partially manually designed and partially trained with large amounts of probabilistic data to optimize explicitly probabilistic objectives , e.g. minimization of kullback - leibler ( kl ) divergence .",
    "therefore , this literature does not address the important question of learning : how can probabilistic inference be learned from a realistic amount and type of data with minimal manual design of the networks ?",
    "second , although there are some commonalities between the neural operations required to implement probabilistic inference in different tasks , these operations generally differ from task to task .",
    "for instance , it has been argued that some form of divisive normalization of neural responses is necessary in tasks that involve marginalization @xcite .",
    "however , the specific form of divisive normalization that individual neurons have to perform differs substantially from task to task .",
    "therefore , it is unclear if probabilistic inference can be implemented in _",
    "generic _ neural networks , whose neurons all perform the same type of neurally plausible operation . third , in these studies , the number of neurons used for performing probabilistic inference scales unfavorably with the size of the input population ( linearly in the case of cue combination , but at least quadratically in all other tasks ) .",
    "therefore , the question of whether these tasks can be implemented more efficiently remains open .    in this paper",
    ", we address these issues .",
    "we show that generic neural networks trained with non - probabilistic error - based feedback perform near - optimal probabilistic inference in tasks with both categorical and continuous outputs .",
    "generic neural networks of the type we use in this paper have a long history @xcite , and have recently been linked directly to cortical responses @xcite .",
    "our main contribution is to connect generic neural networks to near - optimal probabilistic inference in common psychophysical tasks . for these tasks ,",
    "we analyze the network generalization performance , the efficiency of the networks in terms of the number of neurons needed to a achieve a given level of performance , the nature of the emergent probabilistic population code and the mechanistic insights that can be gleaned from the trained networks .",
    "we also investigate whether the time - course of error - based learning in generic neural networks is realistic for non - linguistic animals learning to perform a probabilistic inference task .",
    "* tasks . * we trained generic feedforward or recurrent neural networks on nine probabilistic psychophysical tasks that are commonly studied in the experimental and computational literature .",
    "the main tasks were : ( a ) linear cue combination @xcite , ( b ) coordinate transformations @xcite , ( c ) kalman filtering @xcite , ( d ) causal inference @xcite , ( e ) stimulus demixing @xcite , ( f ) binary categorization @xcite , ( g ) visual search with heterogeneous distractors @xcite ( see _ methods _ for task details ) .",
    "we also trained generic networks on two additional `` modular '' tasks to be discussed below .",
    "* networks . * the networks all received noisy sensory information about the stimulus or the stimuli in the form of a neural population with poisson variability .",
    "the hidden units of the networks were modeled as rectified linear units ( relus ) .",
    "relus are commonly used in neural networks due to their demonstrated advantage over alternative non - linearities in gradient - based learning algorithms @xcite .",
    "linear ( sigmoidal ) output units were used in tasks with continuous ( categorical ) outputs .",
    "schematic diagrams of the networks used for the main tasks considered in this paper are shown in figure  [ diagrams_fig ] .",
    "differences between the network architectures are due entirely to differences in the input and output requirements of different tasks : different tasks have different numbers of inputs or outputs and the outputs are continuous or categorical in different tasks .",
    "other than these task - dictated differences , the networks are truly generic in the sense that they are composed of neurons that perform the same type of biologically plausible operations in all tasks .    networks were trained to minimize mean squared error or cross - entropy in tasks with continuous or categorical outputs , respectively .",
    "importantly , the networks were provided only with the actual stimulus values or the correct class labels as feedback in each trial .",
    "thus , they did not receive any explicitly probabilistic feedback , nor were they explicitly trained to perform probabilistic inference .",
    "we manipulated sensory reliability trial - by - trial via gain variables @xmath0 multiplying the responses of the input populations , with higher gains corresponding to more reliable sensory information . in each task , networks were tested with a wide range of gains or gain combinations ( in tasks with more than a single stimulus ) . to test the generalization capacity of the networks , we trained them with a limited range of gains or gain combinations , as well as with the full range of test gains or gain combinations . the latter unrestricted training regime is called the `` all @xmath1 '' condition , whereas the former limited training regime is called the `` restricted @xmath1 '' condition in what follows .",
    "the specific gain ranges and gain combinations used in each task are indicated below ( _ methods _ ) .",
    "* generic neural networks trained with error - based learning rules implement probabilistic inference in standard psychophysical tasks . *",
    "the performance of well - trained networks is shown in figure  [ performance_all_fig]c and d for both `` all @xmath1 '' ( black ) and `` restricted @xmath1 '' ( red ) training conditions in all tasks ( complete learning curves of the networks are shown in supplementary figure  [ all_tasks_fig ] ) . for continuous tasks",
    ", performance is measured in terms of fractional rmse defined as @xmath2 where @xmath3 is the root mean - squared error ( rmse ) of the trained network , @xmath4 is the rmse of the posterior mean estimate . for categorical tasks , performance is measured in terms of fractional information loss defined as the average kl - divergence between the actual posterior and the network s output normalized by the mutual information between the class labels and the neural responses @xcite . with this measure ,",
    "a network that exactly reproduces the posterior achieves 0% information loss , whereas a network that produces random responses according to the prior probabilities of the classes has 100% information loss .    to make sure that optimal performance in our tasks can not be easily mimicked by heuristic , non - probabilistic models",
    ", we also calculated the performance of non - probabilistic reference models that did not take the reliabilities of the inputs into account ( figure  [ performance_all_fig]c - d , blue ) .",
    "the large performance gaps between these non - probabilistic models and the optimal model suggest that approaching optimal performance in our tasks requires performing truly probabilistic inference , i.e. taking the reliabilities of the inputs into account .",
    "in categorical tasks , the output nodes of the networks approximate the posterior probabilities of the classes given the inputs ( figure  [ performance_all_fig]b , d ) .",
    "theoretical guarantees ensure that this property holds under general conditions with a wide range of loss functions @xcite ( _ discussion _ ) .",
    "* encoding of posterior width in the hidden layers . * for continuous tasks , training with",
    "mean squared error loss guarantees asymptotic convergence to the posterior mean .",
    "do the networks also represent information about the posterior uncertainty in their hidden layers or do they discard this information ?",
    "representation of posterior uncertainty is evident in the kalman filtering task where accurate encoding of the posterior mean at a particular moment already requires the encoding of the posterior mean and the posterior width at the previous moment and the optimal integration of these with the current sensory information in the recurrent activity of the network .",
    "for the linear cue combination and coordinate transformation tasks , to test for the representation of posterior uncertainty in the hidden layer , we plugged the trained hidden layers into a network incorporating an additional input population and fixed their parameters ( figure  [ modular_fig]a ) .",
    "the rest of the network was then trained on a linear cue combination task with three input populations ( a similar modular task was designed in @xcite ) .",
    "if the fixed hidden layers do not encode the posterior width for the first two inputs , the combined network can not perform the three - input cue combination task optimally .",
    "however , the combined networks were able to perform the three - input cue combination task with little information loss despite receiving information about the first two inputs only through the fixed hidden layers ( figure  [ modular_fig]b - c ) .",
    "this suggests that although the initial networks were trained to minimize mean squared error , and hence were asymptotically guaranteed to reproduce the posterior means only , information about the posterior widths was , to a large extent , preserved in the hidden layer . the precise format in which posterior uncertainty is represented in the hidden layer activity",
    "will be discussed below .",
    "the combined coordinate transformation - cue combination ( ct+cc ) network also illustrates the generic nature of the representations learned by the hidden layers of our networks : the hidden layer of a network trained on the coordinate transformation task can be combined , without modification , with an additional input population to perform a different task , i.e. cue combination in this example .        *",
    "generalization to untrained stimulus conditions .",
    "* truly bayesian computation requires that the components of the bayesian computation , i.e. sensory likelihoods and the prior , be individually meaningful to the brain @xcite .",
    "thus , if we replace a particular likelihood for another , the system should continue to perform near - optimally .",
    "we tested for a limited form of such `` bayesian transfer '' by examining whether the trained networks generalize to unseen values or combinations of sensory reliability ( `` restricted @xmath1 '' conditions ) .",
    "as shown in figure  [ performance_all_fig]c and d ( red bars ) , the networks were able to generalize well beyond the training conditions in all tasks .",
    "an example is shown in figure  [ generalization_fig]a for the cue combination task . in this example",
    ", we trained a network with only two gain combinations , @xmath5 and @xmath6 , and tested it on all gain combinations of the form @xmath7 where @xmath8 with up to five - fold gain differences between the two input populations ( note that these gains are higher than those used in the main simulations to make the optimal combination rule approximately linear ) . to demonstrate",
    "that the trained networks performed qualitatively correct probabilistic inference , we set up cue conflict conditions similar to the cue conflict conditions in psychophysical studies @xcite , where we presented slightly different stimuli to the two input populations and manipulated the degree of conflict between the cues .",
    "the weights assigned to the first cue as a function of the gain ratio , @xmath9 , are shown in figure  [ generalization_fig]a both for the network and for the optimal rule .",
    "the network achieved low generalization error ( fractional rmse : 10.9% ) even after as few as 50 training examples in the impoverished training condition and performed qualitatively correct probabilistic inference in the untrained conditions . in particular , the network correctly adjusted the weights assigned to the two cues even as the ratio of their reliabilities varied over a 25-fold range ( figure  [ generalization_fig]a ) .",
    "the successful generalization performance of the neural networks is a result of two factors .",
    "first , the target function is approximately invariant to gain manipulations that differ between the training and test conditions . in cue combination , for instance , the target function is approximately invariant to the scaling of the input populations by arbitrary gains @xmath10 and @xmath11 ( equation  [ cue_comb_eq ] ) .",
    "the second factor is the network s inductive biases , i.e. how it tends to behave outside the training domain .",
    "these inductive biases depend on the details of the network architecture @xcite .    * alternative representations of stimulus reliability in the input populations . *",
    "thus far , we have assumed that sensory reliability has a purely multiplicative effect on the responses of input neurons .",
    "although this assumption likely holds for the effect of contrast on orientation selectivity in visual cortex @xcite , it is known to be violated for the effect of motion coherence on direction selectivity @xcite and for the effect of contrast on speed selectivity @xcite , and is unlikely to hold in the general case .",
    "the importance of this observation is that the poisson - like ppc approach proposed in @xcite can not easily handle cases where `` nuisance variables '' such as contrast or coherence do not have a purely multiplicative effect on neural responses .",
    "by contrast , our approach does not make any assumptions about the representation of stimulus reliability in the input populations .",
    "we demonstrated this in two cases ( figure  [ generalization_fig]b - c ) : ( i ) cue combination with tuning functions of the form reported in @xcite where stimulus coherence affects both the gain and the baseline of the responses ( figure  [ generalization_fig]b , left ) and ( ii ) cue combination with tuning functions of the form reported in @xcite for speed where both the peak response and the preferred speed depend on stimulus contrast ( figure  [ generalization_fig]b , right ) .",
    "thus , our networks can perform near - optimal inference regardless of the specific form in which stimulus reliability is encoded in the input populations .",
    "* sparsity - based representation of posterior uncertainty .",
    "* we now discuss how posterior uncertainty is represented in the hidden layers of the trained networks .",
    "we first note that in tasks with continuous output variables , the optimal solution is invariant to a multiplicative scaling @xmath0 of the input responses ( _ methods _ , equations  [ cue_comb_eq]-[kalman_last_eq ] ) . in such gain - invariant ( or approximately gain - invariant ) tasks , posterior uncertainty is represented in the sparsity of hidden layer activity . to understand the mechanism through which this sparsity - based representation arises , we investigated the conditions under which the network s output would be invariant to input gain scalings .",
    "we first derived an approximate analytical expression for the mean response of a typical hidden unit @xmath12 , as a function of the input gain @xmath0 , the mean input @xmath13 to the hidden unit for unit gain , and the mean @xmath14 and the standard deviation @xmath15 of the biases of the hidden units ( _ methods _ ) .",
    "to minimize the dependence of the mean hidden unit response on @xmath0 , we introduced the following measure of the total sensitivity of @xmath12 to variations in @xmath0 : @xmath16 where the prime represents the derivative with respect to @xmath0 , and numerically minimized @xmath17 with respect to @xmath13 , @xmath14 and @xmath15 , subject to the constraint that the mean response across different gains be equal to a positive constant @xmath18 .",
    "@xmath17 was minimized for a negative mean input @xmath13 , positive @xmath14 and a large @xmath15 value ( black star in figure  [ sparsity_fig]a ) . as an approximate rule , decreasing @xmath13 and increasing @xmath14 or @xmath15 lead to smaller @xmath17 values .",
    "because the input responses are always non - negative , the only way @xmath13 can be negative in our networks is if the mean input - to - hidden layer weight is negative .",
    "the negativity of the mean input @xmath13 implies that as the gain @xmath0 increases , the distribution of the total input to the unit shifts to the left ( figure  [ sparsity_fig]b , top ) , causing a larger proportion of the distribution to remain below the threshold ( represented by the dashed line in figure  [ sparsity_fig]b ) , hence decreasing the probability that the neuron will have a non - zero response ( figure  [ sparsity_fig]c , top ) .",
    "this mechanism causes the sparsification of the hidden unit responses with increasing @xmath0 and is particularly effective when the mean bias , @xmath14 , is large and positive . because increasing @xmath0 also increases the variance of the total input to the unit , the mean response for those inputs that do cross the threshold increases ( figure  [ sparsity_fig]d , top ) . as a result , the mean response of the neuron , which is a product of these two terms , remains roughly constant ( figure  [ sparsity_fig]e , top ) .",
    "we demonstrate this sparsification mechanism for a network trained on the coordinate transformation task in figure  [ sparsity_fig]f - i . because the coordinate transformation task is approximately gain - invariant ( _ methods _ , equation  [ ct_eq ] ) , the input - to - hidden layer weight distribution in the trained network was skewed toward negative values ( figure  [ sparsity_fig]f ) and the mean bias of the hidden units , @xmath14 , was positive ( figure  [ sparsity_fig]g ) , as predicted from our simple mean - field model .",
    "consequently , we found a strong positive correlation between the sparsity of hidden layer responses and the mean input response ( @xmath19 ; figure  [ sparsity_fig]i ) , but no correlation between the mean hidden layer response and the mean input response ( @xmath20 ; figure  [ sparsity_fig]h ) .",
    "the same type of analysis applies to the categorical tasks as well .",
    "however , the difference is that for some of our tasks with categorical outputs , in the optimal solution , the net input to the output unit had a strong dependence on @xmath0 .",
    "for example , in causal inference , the input to the sigmoidal output unit scales approximately linearly with @xmath0 ( equation  [ causal_inference_eq ] ) .",
    "similarly , in visual search , both global and local log - likelihood ratios have a strong dependence on @xmath0 ( through @xmath21 in equations  [ vs_global_eq]-[vs_local_eq ] ) .",
    "we emphasize that the distinction between @xmath0-dependence and @xmath0-invariance is not categorical : different tasks can have varying degrees of @xmath0-invariance or @xmath0-dependence and parameter choices in the same task can affect its @xmath0-dependence .    in the bottom panel of figure  [ sparsity_fig]b - e , predictions from the mean - field model",
    "are shown for a parameter combination where both @xmath13 and @xmath14 are small and slightly negative ( represented by the magenta dot in figure  [ sparsity_fig]a ) .",
    "this parameter combination roughly characterizes the trained networks in the causal inference task ( figure  [ sparsity_fig]j - m ) . in this case , because both @xmath13 and @xmath14 are close to 0 , the probability of non - zero responses as a function of @xmath0 stays roughly constant ( figure  [ sparsity_fig]c , bottom ) , causing the mean response to increase with @xmath0 ( figure  [ sparsity_fig]e , bottom ) .    based on our simple mean - field model , we therefore predicted that for those tasks where the net input to the output unit is approximately @xmath0-invariant , there should be a positive correlation between the sparsity of hidden unit responses and the input gain and no ( or only a weak ) correlation between the mean hidden unit response and the input gain . on the other hand , in tasks such as causal inference , where the net input to the output unit has a strong @xmath0-dependence",
    ", we predicted a positive correlation between the mean hidden unit response and the input gain and no ( or only a weak ) correlation between the sparsity of hidden unit responses and the input gain .",
    "we tested these predictions on our trained networks and confirmed that they were indeed correct ( figure  [ params_fig]a - b ) . for causal inference , visual search and stimulus demixing tasks , the correlation between the mean input and the sparsity of hidden layer responses was weak ( figure  [ params_fig]f ) , whereas for the remaining tasks",
    ", it was strong and positive .",
    "the opposite pattern was seen for the correlation between the mean input and the mean hidden layer response ( figure  [ params_fig]a ) . in @xmath0-dependent tasks such as causal inference",
    ", posterior uncertainty is thus represented largely in the mean hidden layer activity ; whereas in approximately @xmath0-invariant tasks such as coordinate transformation , it is represented largely in the sparsity of hidden layer activity .",
    "the sparsity - based representation of posterior uncertainty in @xmath0-invariant tasks was again driven by large negative mean input - to - hidden layer weights and large positive mean biases ( figure  [ params_fig]c - d ) .",
    "the difference between these two types of tasks ( @xmath0-invariant and @xmath0-dependent ) was also reflected in the tuning functions that developed in the hidden layer of the networks . for approximately @xmath0-invariant tasks such as coordinate transformation , increasing the input gain @xmath0 sharpens the tuning of the hidden units ( figure  [ tuning_functions_fig]a ) , whereas for @xmath0-dependent tasks such as causal inference , input gain acts more like a multiplicative factor scaling the tuning functions without changing their shape ( figure  [ tuning_functions_fig]b ) .",
    "we finally note that these results are decoder dependent . in the continuous tasks , for example ,",
    "if we use a divisively normalized decoder instead of a linear read - out , posterior uncertainty is encoded in the mean hidden layer response , rather than in the sparsity of hidden layer responses ( supplementary figure  [ supp_relunorm_fig ] ) .",
    "( plotted in log units ) as a function of the parameters @xmath13 , @xmath14 and @xmath15 for the constraint surface corresponding to @xmath22 .",
    "the optimal parameter values within the shown range are represented by the black star .",
    "the green and magenta dots roughly correspond to the parameter statistics in the trained coordinate transformation and causal inference networks , respectively .",
    "( b ) for the parameter combination corresponding to the green dot , the mean input @xmath13 is negative and the mean bias @xmath14 is positive .",
    "increasing the gain @xmath0 thus shifts the input distribution to the left : compare the black and red lines for input distributions with a small and a large gain , respectively .",
    "the means of the input distributions are indicated by small dots underneath .",
    "( c ) this , in turn , decreases the probability of non - zero responses , but ( d ) increases the mean of the non - zero responses ; hence ( e ) the mean response of the hidden units , being a product of the two , stays approximately constant as the gain is varied . in the bottom panel of ( b - e ) ,",
    "the results are also shown for a different parameter combination represented by the magenta dot in ( a ) .",
    "this parameter combination roughly characterizes the trained networks in the causal inference task .",
    "( f ) for a network trained in the coordinate transformation task , distributions of the input - to - hidden layer weights , @xmath23 ; ( g ) the biases of the hidden units , @xmath24 ; ( h ) scatter plot of the mean input @xmath25 vs. the mean hidden unit activity @xmath26 ; ( i ) the scatter plot of the mean input vs. the kurtosis of hidden unit activity @xmath27 .",
    "( j - m ) similar to ( f - i ) , but for a network trained in the causal inference task.,scaledwidth=100.0% ]         ( averaged over @xmath28 ) and the second row shows the tuning functions with respect to @xmath28 . increasing the gain sharpens the tuning curves in the coordinate transformation task ,",
    "whereas it has a more multiplicative effect in the causal inference task.,scaledwidth=100.0% ]    * random networks . * to investigate the architectural constraints on the networks capable of performing near - optimal probabilistic inference , we considered an alternative architecture , in which the input - to - hidden layer weights and the biases of the hidden units were set randomly and left untrained ; only the hidden - to - output layer weights and the biases of the output units were trained ( figure  [ random_recurrent_fig]a ) .",
    "such random networks can be plausible models of some neural systems @xcite .",
    "given the same amount of computational resources , these networks performed substantially worse than the fully trained networks ( figure  [ random_recurrent_fig]b ) . a well - known theoretical result can explain the inefficiency of random networks @xcite : the approximation error of neural networks with adjustable hidden units scales as @xmath29 with @xmath30 denoting the number of hidden units , whereas for networks with fixed hidden units , as in our random networks , the scaling is much worse : @xmath31 where @xmath32 is the dimensionality of the problem , suggesting that they need exponentially more neurons than fully trained networks in order to achieve the same level of performance .    * making the networks biologically more plausible : recurrent ei networks . *",
    "so far , we have only considered feedforward networks with undifferentiated neurons . to investigate whether introducing more biological realism would severely constrain the capacity of the networks to perform near - optimal probabilistic inference , following the approach proposed in @xcite , we trained fully recurrent networks with separate excitatory and inhibitory populations that respected dale s law : excitatory neurons projecting only positive weights , inhibitory neurons only negative weights .",
    "the input populations were also divided into excitatory and inhibitory sub - populations that obeyed dale s law ( figure  [ random_recurrent_fig]c ) .",
    "the performance of these recurrent ei networks were slightly worse than , but not substantially different from , the corresponding fully - trained feedforward networks ( figure  [ random_recurrent_fig]d ) .",
    "moreover , the networks re - coded stimulus reliability in a similar manner to the feedforward networks ( supplementary figure  [ supp_recurrent_ei_fig ] ) , suggesting that the main results reported for feedforward networks are robust to the incorporation of more biological realism into our networks",
    ".    -axis is cut off at 100% .",
    "( c ) schematic diagram of a recurrent ei network that obeys dale s law : inhibitory connections are represented by the red arrows and excitatory connections by the blue arrows ; inhibitory neurons are represented by lighter colors , excitatory neurons by darker colors . both input and hidden layers are divided into excitatory - inhibitory sub - populations at a 4-to-1 ratio .",
    "inputs to the network were presented over 10 time steps .",
    "( d ) performance of recurrent ei networks.,scaledwidth=100.0% ]    * error - based learning in generic neural networks accounts for the evolution of behavioral choice and accuracy in a binary categorization task . * the dependence of the networks performance on the number of training trials ( figure  [ all_tasks_fig ] ) suggests a possible explanation for deviations from optimal inference sometimes observed in experimental studies : i.e. insufficient training in the task . testing this hypothesis",
    "rigorously is complicated by possible prior exposure of the subjects to similar stimuli or tasks under natural conditions . among the tasks considered in this paper ,",
    "the binary categorization task minimizes such concerns , because it involves classifying stimuli into arbitrary categories .",
    "moreover , in this task , the behavior of both human and monkey observers were best explained by heuristic models that were quantitatively suboptimal , but qualitatively consistent with the optimal inference model @xcite .",
    "therefore , we sought to test the insufficient - training hypothesis for suboptimal inference in this task .",
    "the stimulus distributions for the two categories and the decision boundaries predicted by the optimal ( opt ) and three suboptimal models ( fix , lin , quad ) are shown in figure  [ qamar_fig]a - b .",
    "different suboptimal models make different assumptions about the dependence of the decision boundary on the sensory noise , @xmath33 ( figure  [ qamar_fig]b ) . in particular",
    ", the fix model assumes that the decision boundary is independent of @xmath33 , whereas lin and quad models assume that the decision boundary is a linear or quadratic function of @xmath33 , respectively @xcite .",
    "the learning curve of a monkey subject who performed a large number of trials in this task ( monkey l in @xcite ) is shown in figure  [ qamar_fig ] together with the performance of a neural network that received the same sequence of trials as the subject .",
    "the input noise of the network was matched to the sensory noise estimated for the subject and the learning rate of the network was optimized to fit the learning curve of the subject .",
    "the neural network was trained online , updating its parameters after each trial , in an analogous manner to how the monkey subject learns the task .",
    "besides providing a good fit to the learning curve of the subject ( figure  [ qamar_fig]c ) , the neural networks also correctly predicted the progression of the models that best fit the subject s data , i.e. early on in the training the quad model , then the lin model ( figure  [ qamar_fig]d ) . when we performed the same type of analysis on human subjects data , human observers consistently outperformed the networks and the networks failed to reproduce the learning curves of the subjects ( figure  [ qamar_fig]e ) .",
    "there might be several possible non - exclusive explanations for this finding .",
    "first , prior to the experiment , human observers were told about the task , including what examples from each category looked like .",
    "this type of knowledge would be difficult to capture with error - based learning alone and might have given human observers a head - start in the task .",
    "second , human observers might have benefited from possible prior familiarity with similar tasks or stimuli .",
    "third , human observers might be endowed with more powerful computational architectures than simple generic neural networks that allow them to learn faster and generalize better @xcite .    *",
    "low computational complexity of standard psychophysical tasks and the efficiency of generic networks .",
    "* for each of our tasks , we empirically determined the minimum number of hidden units , @xmath34 , required to achieve a given level of performance ( 15% information loss for visual search , 10% fractional rmse or information loss for the other tasks ) as a function of the total number of input units , @xmath32 , in our generic networks .",
    "an example is shown in figure  [ nhu_fig]a for the causal inference task with @xmath35 and @xmath36 .",
    "the scaling of @xmath34 with @xmath32 was better than @xmath37 , i.e. sub - linear , in all our tasks ( figure  [ nhu_fig]b ) . previous theoretical work suggests that this result can be explained by the smoothness properties of the target functions and the efficiency of the generic neural networks with adjustable hidden units .",
    "in particular , barron @xcite showed that the optimal number of hidden units in a generic neural network with a single layer of adjustable hidden units scales as @xmath38 with @xmath32 , where @xmath39 is a measure of the smoothness of the target function , with more smooth functions having lower @xmath39 values .",
    "as an example , in @xcite , it was shown that for the @xmath32-dimensional standard gaussian function , @xmath39 can be upper - bounded by @xmath40 , leading to an estimate of @xmath41 hidden units in terms of @xmath32 .",
    "for some of our tasks ( e.g. binary categorization ; figure  [ nhu_fig]b ) , the scaling of @xmath34 with @xmath32 was approximately constant over the range of @xmath32 values tested , suggesting smoothness properties similar to a @xmath32-dimensional standard gaussian .",
    "for the other tasks , the scaling was slightly worse , but still sub - linear in every case : in the worst case of coordinate transformation , linear regression of @xmath42 on @xmath43 yields a slope of @xmath44 ( @xmath45 ) .",
    "we can gain some intuition about the relatively benign smoothness properties of our tasks by looking at the analytic expressions for the corresponding target functions ( equations  [ cue_comb_eq]-[vs_local_eq ] ) : although the inputs are high dimensional , the solutions can usually be expressed as smooth functions of a small number of one - dimensional linear projections of the inputs .",
    "the efficiency of our generic networks contrasts sharply with the inefficiency of the manually crafted networks in earlier ppc studies @xcite : except for the linear cue combination task , these hand - crafted networks used a quadratic expansion which requires at least @xmath46 hidden units . moreover , unlike generic neural networks , these networks with hand - crafted hidden units are not guaranteed to work well in the general case , if , for example , the target function is not expressible in terms of a quadratic expansion . stacking the quadratic expansions",
    "hierarchically to make the networks more expressive would make the scaling of the number of hidden units with @xmath32 even worse ( e.g. @xcite ) .",
    "the fundamental weakness of these hand - crafted networks is the same as that of the random networks reviewed above : they essentially use a fixed basis set theoretically guaranteed to have much worse approximation properties than the adjustable basis of hidden units used in our generic networks @xcite .    , the minimum number of hidden units required to reach within 10% of optimal performance ( 15% for visual search ) , @xmath34 , is estimated ( shown by the arrows ) .",
    "an example is shown here for the causal inference task with @xmath35 and @xmath36 input units , respectively .",
    "( b ) @xmath34 plotted as a function of the total number of input units , @xmath32 , in different tasks .",
    "solid lines show linear fits . in these simulations ,",
    "the number of training trials for each task was set to the maximum number of training trials shown in supplementary figure  [ all_tasks_fig].,scaledwidth=100.0% ]",
    "we have shown that small generic neural networks trained with a standard error - based learning rule , but without any explicitly probabilistic feedback or training objective , implement probabilistic inference in simple psychophysical tasks and generalize successfully beyond the conditions they are trained in .    for tasks with continuous outputs , we trained our networks to minimize the squared error loss function , which is minimized by the posterior mean estimate .",
    "given the universal approximation guarantees for multilayer neural networks with rectified linear hidden units @xcite , it is not surprising that our networks can approximate the posterior mean given enough hidden units and training data .",
    "however , the findings that near - optimal performance can be achieved even in small networks trained with a relatively small number of training examples and that the networks can generalize successfully beyond the training data they receive depend on the particular problems we studied , in particular , on their low - dimensional nature and their smoothness properties , hence are not predicted by the universal approximation results .",
    "moreover , representing the posterior mean is necessary , but not sufficient for general probabilistic computation : it is also necessary to represent uncertainty on a trial - by - trial basis .",
    "using modular tasks , we showed that the networks implicitly represent uncertainty as well .",
    "this finding also holds when the networks are trained with absolute error loss ( supplementary figure  [ supp_alt_objectives_fig]a ) .    for tasks with categorical outputs , the output layer of a multilayer neural network",
    "is asymptotically guaranteed to converge to the posterior probabilities of the classes under a broad class of loss functions @xcite , including cross - entropy and mean squared error ( supplementary figure  [ supp_alt_objectives_fig]b ) . for the particular problems",
    "we studied , our results again show empirically that this convergence can be achieved relatively fast and does not require large networks .",
    "our tasks all assumed psychophysically realistic levels of sensory noise . at these noise levels ,",
    "simple heuristic non - probabilistic models that did not take trial - to - trial uncertainty into account are unable to mimic the performance of optimal probabilistic models .",
    "random networks with only trainable readout weights performed poorly in our tasks . this can be understood as a consequence of the poor approximation properties of such networks @xcite . on the other hand , making our networks biologically more plausible by making them fully recurrent and introducing separate excitatory and inhibitory populations throughout the network that respect dale s law in their connectivity pattern did not significantly impair the performance of the networks .",
    "* relationship to previous work . *",
    "our work is consistent with the probabilistic population coding framework according to which , by virtue of the variability of their responses , neural populations encode probability distributions rather than single estimates and computations with probability distributions can be carried out by suitable operations on the corresponding neural responses @xcite . however , our work disagrees with the existing literature on the implementation of such computations .",
    "we show that these computations do not require any special neural operations or network architectures than the very generic ones that researchers have been using for decades in the neural network community @xcite .    the recent literature on probabilistic population coding respects the principle that poisson - like neural variability be preserved between the input and output of a network , because this leads to a fully modular code that can be decoded with the same type of decoder throughout the network @xcite . to obtain actual networks , these studies then postulate a literal , one - to - one correspondence between the required neural computations that must be computed at the population level and the computations individual neurons perform .",
    "this literal interpretation leads to inefficient neural architectures containing intermediate neurons that are artificially restricted to summing or multiplying the activities of at most two input neurons and that perform substantially different operations in different tasks ( e.g. linear summation , multiplication or different forms of divisive normalization ) @xcite .",
    "our generic networks are not necessarily inconsistent with the principle of the preservation of poisson - like variability between the input and output of a network .",
    "our categorical networks already satisfy this principle , and our continuous networks satisfy it if , instead of a purely linear decoder , we use a linear decoder that is then normalized by the total activity in the hidden layer ( supplementary figure  [ supp_relunorm_fig ] ) . however",
    ", our results show that it is unnecessary and inefficient to postulate a direct correspondence between population - level and individual - neuron computations : standard neural networks with rectified linear hidden units that perform the same type of operation independent of the task implement population - level computations required for optimal probabilistic inference far more efficiently .",
    "* experimental predictions . *",
    "our results lead to several experimentally testable predictions .",
    "first , for gain - invariant tasks , we predict a novel sparsity - based coding of posterior uncertainty in cortical areas close to the behavioral readout .",
    "stimulus manipulations that increase sensory reliability such as an increase in contrast of the stimulus would be expected to increase the sparseness of the population activity in these areas",
    ". another straightforward consequence of this relationship would be a positive correlation between the performance of the animal in the task and the population sparsity of neurons recorded from the same areas .",
    "second , for gain - dependent tasks such as causal inference , we predict a different coding of posterior uncertainty based on the mean activity in areas close to the readout .",
    "moreover , based on our mean - field model of the mechanism underlying these two types of codes , we expect a trade - off between them : the stronger the correlation between sparsity and posterior uncertainty , the weaker the relationship between the mean activity and posterior uncertainty and vice versa .",
    "this can be tested with population recordings from multiple areas in multiple tasks .",
    "third , at the level of single cells , we predict tuning curve sharpening with increased input gain in tasks where a sparsity - based coding of reliability is predicted ( figure  [ tuning_functions_fig]a ) .",
    "such tuning curve sharpening has indeed been observed in cortical areas mt @xcite , mst @xcite and mstd @xcite . on the other hand",
    ", we expect the input gain to act more like a multiplicative factor in tasks where a mean activity based coding of reliability is predicted ( figure  [ tuning_functions_fig]b ) .",
    "sparse and reliable neural responses have been observed under natural stimulation conditions @xcite .",
    "inhibitory currents have been shown to be crucial in generating such sparse and reliable responses @xcite , reminiscent of the negative mean input requirement in our mean - field model of the sparsity - based coding of posterior uncertainty ( figure  [ sparsity_fig]b )",
    ".    * limitations . *",
    "our networks are highly idealized models of real neural circuits .",
    "although we validated our basic results using biologically more realistic recurrent excitatory - inhibitory networks ( figure  [ random_recurrent_fig]c - d ) , even these networks are simplistic models that ignore much of the complexity of real neural circuits .",
    "for example , real neural circuits involve several morphologically and physiologically distinct cell types with different connectivity patterns and with potentially distinct functions @xcite .",
    "real neurons also implement a diverse set of complicated non - linearities , unlike the simple rectification non - linearity we assumed in our networks .",
    "it remains to be determined what possible functional roles this diversity plays in neural circuits .",
    "however , even seemingly drastic simplifications can , in some cases , teach us important insights about the brain .",
    "for example , cortical networks are usually highly recurrent , thus modeling them as feed - forward networks might seem like a useless simplification .",
    "however , networks with feedback connections can sometimes behave effectively like a feedforward network @xcite . as another example , feedforward networks also currently provide the best characterization of the neural responses in higher visual cortical areas @xcite , even though these areas are known to involve abundant feedback connections both within the same area and between different areas .",
    "therefore , insights gained from understanding simplified models can be quite relevant for understanding real cortical circuits .",
    "second , our networks were trained with the backpropagation algorithm , which is usually considered to be biologically unrealistic due to its non - locality .",
    "although the backpropagation algorithm in its standard form we have implemented is indeed biologically unrealistic , biologically plausible approximations to backpropagation have been put forward recently @xcite . therefore , it is quite likely that one need not compromise the power of backpropagation in order to attain biologically plausibility .",
    "third , the stimuli that we used were far from naturalistic . however , the computations required in our tasks capture the essential aspects of the computations that would be required in similar tasks with natural stimuli .",
    "using simple stimuli allows for the parametric characterization of behavior and makes the derivation of the optimal solution more tractable .",
    "we have shown here that new insights can be obtained by combining analytically derived optimal solutions with neural networks .",
    "for example , understanding the novel sparsity - based representation of posterior uncertainty in the hidden layers of the networks in some tasks but not in others relied on the analysis of the optimal solutions in different tasks .    finally , as exemplified by the inability of error - based learning to account for the performance of human observers in the binary categorization task , we do not expect error - based learning in generic neural networks to fully account for all aspects of the performance of human observers , and possibly non - human observers as well , even in simple tasks .",
    "relatively mundane manipulations such as changing the target or the distractors , or the number of distractors in a visual search task , changing the duration of a delay interval in a short - term memory task require wholesale re - training of generic neural networks , which seems to be inconsistent with the way human observers , and possibly non - human observers , can effortlessly generalize over such variables .",
    "more powerful architectures that combine a neural network controller with an external memory can both learn faster and generalize better @xcite , offering a promising direction for modeling the generalization patterns of observers in simple psychophysical tasks .",
    "* data and code availability : * the data and code used to obtain the results reported in this paper are available at the following public repository : https://github.com/eminorhan/inevitable-probability .    * neural networks : * in all networks , the input units were independent poisson neurons : @xmath47 where @xmath48 is the vector of mean responses ( tuning functions ) , @xmath49 is the stimulus and @xmath50 is a stimulus contrast or coherence variable that controls the quality of sensory information . for the main results presented in the paper , we assume that the effect of @xmath50 can be described as a multiplicative gain scaling : @xmath51 where the individual tuning functions comprising @xmath52 were either linear ( stimulus demixing ) , von mises ( visual search ) or gaussian ( all other tasks ) .    to demonstrate the generality of our approach , we also considered two alternative ways in which stimulus contrast or coherence can affect the responses of the input population . in particular , for the cue combination task , we considered tuning functions where @xmath50 did not have a purely multiplicative effect , but affected the baseline responses as well @xcite : @xmath53 with @xmath54 where @xmath55 was chosen such that the mean response of the input population was independent of @xmath50 . secondly , again for the cue combination task with two cues , we considered tuning functions where stimulus contrast @xmath50 affected both the peak response and the preferred stimuli of input neurons , as reported in @xcite for speed tuning in area mt : @xmath56 with the following parameters : @xmath57 , @xmath58 , @xmath59 , @xmath60 , @xmath61 and @xmath62 with @xmath63 , @xmath64 , @xmath65 .",
    "the results for these two cases are shown in figure  [ generalization_fig]c .",
    "the hidden units in both feed - forward and recurrent networks were rectified linear units . in feed - forward networks ,",
    "the hidden unit responses are described by the equation : @xmath66_+$ ] and in recurrent networks by the equation : @xmath67_+$ ] , where @xmath68 and @xmath69 are the input and recurrent weights respectively and @xmath70_+$ ] denotes elementwise rectification .",
    "for tasks with continuous output variables , the network output corresponds to a linear combination of the hidden unit responses : @xmath71 , and in tasks with categorical variables , the network output was given by a linear combination of the hidden unit responses passed through a sigmoid nonlinearity : @xmath72 .    in the recurrent ei networks ,",
    "all connections were constrained to satisfy dale s law , as described in @xcite .",
    "the ratio of excitatory to inhibitory neurons in both input and recurrent populations was 4 to 1 .",
    "inputs were presented over 10 time steps , but the total input information was equated to the total input information in the feedforward networks .    in random networks ,",
    "input - to - hidden layer weights were sampled from a normal distribution with zero mean and standard deviation @xmath73 , where @xmath32 is the number of input neurons and @xmath30 is the number of hidden neurons @xcite ; biases of the hidden units were sampled from a normal distribution with zero mean and standard deviation of @xmath74 .    in the main simulations ,",
    "the networks had 200 hidden units . in cue combination , modular cue combination ,",
    "coordinate transformation , kalman filtering , binary categorization and causal inference tasks , there were 50 input neurons per input population .",
    "to make our results comparable to earlier results , we used 20 input neurons per input population in the visual search task and 10 input neurons per input population in the stimulus demixing task .",
    "* non - probabilistic models : * for the kalman filtering and all cue combination tasks , we used heuristic , non - probabilistic reference models that estimated the individual cues ( and the past state in kalman filtering ) optimally , but combined them suboptimally by weighting them equally regardless of their reliability . note that these models still performed a non - trivial probabilistic computation , namely marginalizing out a nuisance variable , i.e. the input gain , to come up with the optimal estimate of the individual cues . we also note that for the coordinate transformation task , unlike in cue combination or kalman filtering , the optimal combination rule does not depend on the reliabilities of the individual inputs . for the categorical tasks",
    ", we also used non - probabilistic reference models that assumed equal reliabilities for individual inputs . to give the reference models the best chance to perform well , we optimized the assumed common reliability of the inputs by minimizing the information loss",
    ".    * training procedure : * the feed - forward networks were trained with the standard backpropagation algorithm @xcite .",
    "the recurrent networks were trained with backpropagation through time @xcite .",
    "we used the adam stochastic gradient descent algorithm @xcite with learning rate @xmath75 to implement backpropagation .",
    "the batch sizes for the updates were 10 for binary categorization , 500 for visual search and 100 for the other tasks . in figure",
    "[ qamar_fig ] , we used an online vanilla stochastic gradient descent algorithm with learning rate decrease over trials described by @xmath76 where @xmath77 is the trial number . the parameters @xmath78 and @xmath79 were fit to the monkey s learning curve .",
    "* training conditions : * the `` all @xmath1 '' conditions in different tasks were as follows . in cue combination and coordinate transformation tasks , all 25 pairs of the form @xmath7 with @xmath80 were presented an equal number of times . in kalman filtering",
    ", @xmath0 was uniformly drawn between 0.3 and 3 at each time step . in binary categorization , the six gain values , @xmath81 ,",
    "were presented an equal number of times .",
    "these gain values were calculated from the mean noise parameter values reported for the human subjects in @xcite . in causal inference , all 25 pairs of the form @xmath7 with @xmath82 were presented an equal number of times . in stimulus demixing ,",
    "following @xcite , @xmath50 was uniformly and independently drawn between 2 and 9 for each source . in visual search , @xmath0 was randomly and independently set to either 0.5 or to 3 for each stimulus .",
    "the `` restricted @xmath1 '' conditions in different tasks were as follows .",
    "in cue combination and coordinate transformation tasks , the two pairs @xmath83 were presented an equal number of times . in kalman filtering , @xmath0 was randomly and independently set to either 0.3 or to 3 at each time step . in binary categorization , @xmath0 was always 4.2 .",
    "this gain value corresponds to 100% contrast as calculated from the mean noise parameter values for the human subjects reported in @xcite . in causal inference ,",
    "pairs of the form @xmath84 were presented an equal number of times . in stimulus demixing , @xmath50 was either set to 2 for all sources or else set to 9 for all sources . similarly , in visual search , @xmath0 was either set to 0.5 for all stimuli or else set to 3 for all stimuli .",
    "* mean - field model of hidden unit responses : * for a given input activity @xmath85 , we consider the responses of the hidden units as realizations of a random variable @xmath86 .",
    "the output weights are also assumed to be realizations of a random variable @xmath87 .",
    "we further assume that @xmath87 and @xmath86 are independent .",
    "the network s output is then proportional to @xmath88 .",
    "we want to make this expression invariant to the input gain @xmath0 .",
    "we first introduce a measure of the total sensitivity of this expression to variations in @xmath0 .",
    "we will do this by computing the magnitude of the derivative of @xmath88 with respect to @xmath0 and integrating over a range of @xmath0 values , but we first note that the output weights are already gain invariant , hence we can just consider @xmath26 .",
    "we now have to find an expression for @xmath26 .",
    "the net input to a typical hidden unit is given by : @xmath89 where @xmath90 are the input weights to a typical hidden unit .",
    "then : @xmath91_{+ } \\rangle = \\big[1-\\phi\\big(\\frac{-\\mu_{\\ast } } { \\sigma_{\\ast } } \\big ) \\big ]   \\mu_{\\ast }   + \\phi\\big(\\frac{-\\mu_{\\ast } } { \\sigma_{\\ast } } \\big ) \\sigma_{\\ast } \\label{mu_bar_eq}\\ ] ] where @xmath92 and @xmath93 are the cdf and the pdf of the standard gaussian distribution .",
    "as mentioned above , we then introduce the following measure of the total sensitivity of @xmath12 to variations in @xmath0 : @xmath94 where the prime represents the derivative with respect to @xmath0 . because @xmath0 always appears as @xmath95 or @xmath96 in @xmath12 ( equation  [ mu_bar_eq ] ) ,",
    "the parametrization in terms of @xmath0 , @xmath13 and @xmath33 is redundant .",
    "we therefore set @xmath60 , and hence expressed everything in terms of the scale of @xmath33 .",
    "we then minimized @xmath17 numerically with respect to @xmath13 , @xmath14 and @xmath15 subject to the constraint that the mean response across different gains be equal to some positive constant @xmath18 : @xmath97 this ensures that the degenerate solution where the hidden layer is completely silent is avoided .",
    "* task details : * in the linear cue combination task , the objective was to combine two cues , @xmath98 and @xmath99 , encoding information about the same variable , @xmath49 , in a statistically optimal way . assuming a squared error loss function , this can be achieved by computing the mean of the posterior @xmath100 .",
    "for a uniform prior distribution , the posterior mean is given by an expression of the form @xcite : @xmath101 where @xmath102 is the vector of preferred stimuli of input neurons and @xmath103 is a vector of ones .",
    "this expression is approximate when the prior is not uniform over the entire real line and the quality of the approximation can become particularly bad in the high noise regime considered in this paper .",
    "thus , in practice , we computed posterior means numerically , rather than using the above equation .",
    "the equation is still useful , however , in helping us understand the type of computation the network needs to perform to approximate optimal probabilistic inference . during training , the two cues received by the input populations were always non - conflicting : @xmath104 and the gains of the input populations varied from trial to trial .",
    "the network was trained to minimize the mean squared error between its output and the common @xmath49 indicated by the two cues .    in the coordinate transformation task ,",
    "the eye - centered location of an object in 1-d , @xmath105 , was encoded in a population of poisson neurons with responses @xmath98 and the current eye position , @xmath28 , was similarly encoded in a population of poisson neurons with responses @xmath99 .",
    "the goal was to compute the head - centered location of the object , which is given by @xmath106 . assuming uniform priors , the optimal estimate of @xmath49 can be expressed as @xcite : @xmath107 for suitable matrices @xmath108 and @xmath109 ( see @xcite for a full derivation ) .",
    "again , when the priors are not uniform over the real line , this expression becomes only approximate and posterior means are computed numerically .    in the kalman filtering task",
    ", we considered a one - dimensional time - varying signal evolving according to : @xmath110 , where @xmath111 with @xmath112 and @xmath113 . at each time",
    "@xmath77 , the stimulus was represented by the noisy responses , @xmath114 , of a population of input neurons with poisson variability .",
    "the input population projected to a recurrent pool of neurons that have to integrate the momentary sensory information coming from the input population with an estimate of the signal at the previous time step ( as well as the uncertainty associated with that estimate ) to perform optimal estimation of the signal at the current time step .",
    "we decoded the estimate of the signal at each time step by a linear read - out of the recurrent pool : @xmath115 .",
    "the network was trained with sequences of length @xmath116 using a squared error loss function .",
    "the posterior @xmath117 is gaussian with natural parameters given recursively by @xcite : @xmath118 where @xmath119 and @xmath120 are the mean and variance of @xmath121 which represents the momentary sensory evidence encoded in the input population .",
    "these are , in turn , given by @xmath122 and @xmath123 .    in the binary categorization task ,",
    "the goal was to classify a noisy orientation measurement into one of two overlapping classes that have the same mean but different variances . given a noisy activity pattern @xmath85 over the input population representing the observed orientation , the posterior probabilities of the two classes can be calculated analytically .",
    "the log - likelihood ratio of the two categories is given by @xcite : @xmath124 where @xmath125 and @xmath126 .",
    "the posterior probability of the first class is then given by a sigmoidal function of @xmath32 : @xmath127 .",
    "in the causal inference task , the goal was to infer whether two sensory measurements are caused by a common source or by two separate sources .",
    "the log - likelihood ratio of these two hypotheses is given by @xcite : @xmath128 \\label{causal_inference_eq}\\ ] ] where @xmath129 is the precision of the gaussian stimulus distribution and : @xmath130 where @xmath131 is the common variance of the gaussian tuning functions of the individual input neurons .",
    "@xmath132 and @xmath133 are the preferred stimuli of the neurons in the first and second populations respectively . for convenience",
    ", we assumed @xmath134 .",
    "the optimal probability of reporting `` same cause '' is then simply given as : @xmath135 .    in the stimulus demixing task ,",
    "the goal was to infer the presence or absence of different signal sources in a mixture of signals with unknown concentrations .",
    "as a concrete example , the signals can be thought of as different odors , and the task would then be to infer the presence or absence of different odors in an odor mixture with unknown concentrations @xcite .",
    "following @xcite , we assumed a linear mixing model : @xmath136 where @xmath137 denotes the presence or absence of the @xmath138-th odor source , @xmath139 denotes its concentration , @xmath140 is the concentration of the @xmath141-th odorant and @xmath142 is the weight of the @xmath138-th odor source in the @xmath141-th odorant .",
    "the task can then be formalized as the computation of the posterior probability of the presence or absence of each odor source , given noisy responses @xmath143 of populations of poisson neurons encoding the odorants : i.e. @xmath144 .",
    "the input populations were assumed to have linear tuning for the odorants : @xmath145 , where @xmath146 and @xmath147 were random vectors with positive entries @xcite . as in @xcite , we assumed four sources and four odorants .",
    "the networks were trained to minimize the cross - entropy between the network s outputs and the correct source present / absent labels , @xmath137 .    in the visual search task ,",
    "the goal was to infer the presence or absence of a target stimulus @xmath148 among a set of heterogeneous distractors .",
    "the log - likelihood ratio of the target presence is given by @xcite : @xmath149 where @xmath150 is the number of stimuli on the display ( we assumed @xmath151 ) and the local target presence log - likelihoods @xmath152 are given by : @xmath153 for independent poisson neurons , the stimulus kernel @xmath154 is given by @xmath155 , where we assumed von mises tuning functions for individual input neurons .",
    "the integral in the second term on the right hand side was calculated numerically .",
    "* behavioral data : * human and monkey behavioral data used in figure  [ qamar_fig ] were obtained from a previously published study @xcite",
    ". human behavioral data reported in figure  [ qamar_fig]e are from 6 human subjects ( one female ) who completed the main experiment in @xcite .",
    "the behavioral data reported in figure  [ qamar_fig]c are from monkey l. only incomplete behavioral data from another monkey that completed the experiment ( monkey a ) were available . because data from all trials are needed to obtain a reliable estimate of the subject s learning curve , data from this monkey were not used in the current paper . for further details about the experimental settings , subjects and model fitting ,",
    "see @xcite .",
    "99 barron ar ( 1993 ) universal approximation bounds for superpositions of a sigmoidal function .",
    "ieee trans inf theory 39(3):930 - 945 .",
    "battaglia pw , jacobs ra , aslin rn ( 2003 ) bayesian integration of visual and auditory signals for spatial localization .",
    "josa 20(7):1391 - 1397 .",
    "beck , jm et al .",
    "( 2008 ) probabilistic population codes for bayesian decision making .",
    "neuron 60:1142 - 1152 .",
    "beck jm , latham pe , pouget a ( 2011 ) marginalization in neural circuits with divisive normalization .",
    "j neurosci 31(43):15310 - 15319 .",
    "bengio y , lee d - h , bornschein j , lin z ( 2015 ) towards biologically plausible deep learning . arxiv:1502.04156 .",
    "britten kh , shadlen mn , newsome wt , movshon ja ( 1993 ) responses of neurons in macaque mt to stochastic motion signals .",
    "vis neurosci 10:1157 - 1169 .",
    "cadieu cf , hong h , yamins dlk , pinto n , ardila d , solomon ea , majaj nj , dicarlo jj ( 2014 ) deep neural networks rival the representation of primate it cortex for core visual object recognition .",
    "plos comput biol 10:e1003963 .",
    "caron sjc , ruta v , abbott lf , axel r ( 2013 ) random convergence of afferent olfactory inputs in the drosophila mushroom body .",
    "nature 497:113 - 117 .",
    "crochet s , poulet jfa , kremer y , petersen cch ( 2011 ) synaptic mechanisms underlying sparse coding of active touch .",
    "neuron 69:1160 - 1175 .",
    "ernst mo , banks ms ( 2002 ) humans integrate visual and haptic information in a statistically optimal fashion .",
    "nature 415:429 - 433 .",
    "fetsch cr , pouget a , deangelis dc , angelaki de ( 2012 ) neural correlates of reliability - based cue weighting during multisensory integration .",
    "nat neurosci 15:146 - 154 .",
    "glorot x , bengio y ( 2010 ) understanding the difficulty of training deep feedforward neural networks .",
    "aistats 9:249 - 256 .",
    "glorot x , bordes a , bengio y ( 2011 ) deep sparse rectifier neural networks .",
    "aistats 15:315 - 323 .",
    "goldman ms ( 2009 ) memory without feedback in a neural network .",
    "neuron 61(4):621 - 634 .",
    "graves a , wayne g , et al . ( 2016 ) hybrid computing using a neural network with dynamic external memory .",
    "nature 538:471 - 476 .",
    "haider b , krause mr , duque a , yu y , touryan j , mazer ja , mccormick da ( 2010 ) synaptic and network mechanisms of sparse and reliable visual cortical activity during nonclassical receptive field stimulation .",
    "neuron 65:107 - 121 .",
    "haider b , hausser m , carandini m ( 2013 ) inhibition dominates sensory responses in the awake cortex .",
    "nature 493:97 - 100 .",
    "hampshire ii jb , perlmutter ba ( 1990 ) equivalence proofs for multilayer perceptron classifiers and the bayesian discriminant function . in _ proceedings of the 1990 connectionist models",
    "summer school _ ( touretzky d , et al .",
    "eds . ) , morgan kaufmann .",
    "harris kd , shepherd gmg ( 2015 ) the neocortical circuit : themes and variations .",
    "nat neurosci 18:170 - 181 .",
    "heuer hw , britten kh ( 2007 ) linear responses to stochastic motion signals in area mst .",
    "j neurophysiol 98:1115 - 1124 .",
    "hillis jm , watt sj , landy ms , banks ms ( 2004 ) slant from texture and disparity cues : optimal cue combination .",
    "j vis 4(1 ) .",
    "kingma d , ba j ( 2014 ) adam : a method for stochastic optimization .",
    "arxiv:1412.6980 .",
    "krding k , beierholm u , ma wj , quartz s , tenenbaum jb , shams l ( 2007 ) causal inference in multisensory perception .",
    "plos one 2(9 ) , e943 .",
    "krekelberg b , van wezel rja , albright td ( 2006 ) interactions between speed and contrast tuning in the middle temporal area : implications for the neural code for speed .",
    "j neurosci 26(35 ) , 8988 - 8998 .",
    "kwon o - s , tadin d , knill dc ( 2015 ) a unifying account of visual motion and position perception .",
    "proc natl acad sci usa 112(26):8142 - 8147 .",
    "leshno m , lin vy , pinkus a , schocken s ( 1993 ) multilayer feed - forward networks with a non - polynomial activation function can approximate any function .",
    "neural netw 6:861 - 867 .",
    "lillicrap tp , cownden d , tweed db , akerman cj ( 2016 ) random synaptic feedback weights support error backpropagation for deep learning .",
    "nat commun 7:13276 .",
    "ma wj , beck jm , latham pe , pouget a ( 2006 ) bayesian inference with probabilistic population codes .",
    "nat neurosci 9(11):1432 - 1438 .",
    "ma wj , navalpakkam v , beck jm , berg rv , pouget a ( 2011 ) behavior and neural basis of near - optimal visual search .",
    "nat neurosci 14(6):783 - 790 .",
    "ma wj , rahmati m ( 2013 ) towards a neural implementation of causal inference in cue combination .",
    "multisens res 26:159 - 176 .",
    "makin jg , fellows mr , sabes pn ( 2013 ) learning multisensory integration and coordinate transformation via density estimation .",
    "plos comput biol 9:e1003035 .",
    "maloney lt , mamassian p ( 2009 ) bayesian decision theory as a model of human visual perception : testing bayesian transfer .",
    "vis neurosci 26:147 - 155 .",
    "mante v , sussillo d , shenoy kv , newsome wt ( 2013 ) context - dependent computation by recurrent dynamics in prefrontal cortex .",
    "nature 503 , 78 - 84 .",
    "merfeld dm , zupan l , peterka rj ( 1999 ) humans use internal models to estimate gravity and linear acceleration .",
    "nature 398:615 - 618 .",
    "morgan ml , deangelis gc , angelaki de ( 2008 ) multisensory integration in macaque visual cortex depends on cue reliability .",
    "neuron 59:662 - 673 .",
    "murphy bk , miller kd ( 2009 ) balanced amplification : a new mechanism of selective amplification of neural activity patters .",
    "neuron 61(4):635 - 648 .",
    "neal rm ( 1996 ) bayesian learning for neural networks .",
    "lecture notes in statistics no .",
    "118 , new york : springer - verlag .",
    "qamar at , cotton rj , george rg , beck jm , prezhdo e , et al .",
    "( 2013 ) trial - to - trial , uncertainty - based adjustment of decision boundaries in visual categorization .",
    "proc natl acad sci usa 110(50):20332 - 37 .",
    "rumelhart de , hinton ge , williams rj ( 1986 ) learning representations by back - propagating errors .",
    "nature 323:533 - 536 .",
    "sclar g , freeman rd ( 1982 ) orientation selectivity in the cat s striate cortex is invariant with stimulus contrast .",
    "exp brain res 46:457 - 461 .",
    "song hf , yang gr , wang x - j ( 2016 ) training excitatory - inhibitory recurrent neural networks for cognitive tasks : a simple and flexible framework .",
    "plos comput biol 12(2 ) : e1004792 .    stettler dd , axel r ( 2009 ) representations of odor in the piriform cortex .",
    "neuron 63:854 - 864 .",
    "sussillo d , churchland mm , kaufman mt , shenoy kv ( 2015 ) a neural network that finds a naturalistic solution for the prediction of muscle activity .",
    "nat neurosci 18:1025 - 1033 .",
    "vinje we , gallant jl ( 2000 ) sparse coding and decorrelation in primary visual cortex during natural vision .",
    "science 287:1273 - 1276 .",
    "williams rj , zipser d ( 1995 ) gradient - based learning algorithms for recurrent networks and their computational complexity . in : chauvin y ,",
    "rumelhart de ( eds . ) back - propagation : theory , architectures and applications .",
    "hillsdale , nj : erlbaum .",
    "wolpert dm , ghahramani z , jordan mi ( 1995 ) an internal model for sensorimotor integration .",
    "science 269(5232):1880 - 1882 .",
    "yamins dlk , hong h , cadieu cf , solomon ea , seibart d , dicarlo jj ( 2014 ) performance - optimized hierarchical models predict neural responses in higher visual cortex .",
    "pnas 111(23):8619 - 8624 .",
    "zemel r , dayan p , pouget a ( 1998 ) probabilistic interpretation of population codes .",
    "neural comput 10:403 - 430 .",
    "zipser d , andersen ra ( 1988 ) a back - propagation programmed network that simulates response properties of a subset of posterior parietal neurons .",
    "nature 331:679 - 684 ."
  ],
  "abstract_text": [
    "<S> animals perform near - optimal probabilistic inference in a wide range of psychophysical tasks . </S>",
    "<S> probabilistic inference requires trial - to - trial representation of the uncertainties associated with task variables and subsequent use of this representation . </S>",
    "<S> previous work has implemented such computation using neural networks with hand - crafted and task - dependent operations . </S>",
    "<S> we show that generic neural networks trained with non - probabilistic feedback using a simple error - based learning rule perform near - optimal probabilistic inference in nine common psychophysical tasks . in a probabilistic categorization task , error - based learning in a generic network simultaneously accounts for a monkey s learning curve and for the evolution of qualitative aspects of its choice behavior . in all tasks , </S>",
    "<S> the number of neurons required for a given level of performance grows sub - linearly with the size of the input population , a substantial improvement on previous implementations of probabilistic inference using hand - crafted neurons . </S>",
    "<S> the trained networks develop a novel sparsity - based probabilistic population code in a task - dependent manner . </S>",
    "<S> the tractability of the investigated tasks allows us to mechanistically understand the nature of this code . </S>",
    "<S> our results suggest that probabilistic inference emerges naturally in generic neural networks trained with error - based learning rules and that these types of networks can be used as simple plausible neural models of probabilistic inference . </S>"
  ]
}