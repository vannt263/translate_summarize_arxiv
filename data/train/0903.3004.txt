{
  "article_text": [
    "when transmitting over an erasure channel like the internet , one of the problems encountered is the delay experienced on the received information which is due to the possible re - transmission of lost packets .",
    "one way to eliminate these delays is by using forward error correction .    until now only block codes have been used for such a task ,",
    "see @xcite . in this paper",
    "we demonstrate how maximum distance profile ( mdp ) convolutional codes provide an attractive alternative .",
    "convolutional codes have a certain flexibility given by the `` sliding window '' characteristic .",
    "this means that the received information can be grouped in blocks or windows in many ways , depending on the erasure bursts , and then be decoded by decoding the `` easy '' blocks first .",
    "this flexibility in grouping information brings certain freedom in the handling of sequences ; we can split the blocks in smaller windows , we can overlap windows , etc . , we can proceed to decode in a less strict order .",
    "the blocks are not fixed as in the block code case , i.e. , they do not have a fixed grouping of a fixed length .",
    "we can slide along the transmitted sequence and decide the place where we want to start our decoding depending on the erasure occurrence .",
    "this property allows us to correct in a given block more erasures than a block code of that same length could do .",
    "an @xmath3 $ ] block code used for transmission over an erasure channel can correct up to @xmath4 erasures in a given block .",
    "the optimal error capability of @xmath4 is achieved by an @xmath3 $ ] maximum distance separable ( mds ) code .    as an alternative",
    "consider now a class of @xmath5 convolutional codes , i.e. , a class of rate @xmath6 convolutional codes having degree  @xmath7 .",
    "we will demonstrate that for this class , the maximum number of errors which can be corrected in some sliding window of appropriate size is achieved by the subclass of mdp convolutional codes . in this paper , we will study the maximum number of erasures that such a class of codes can decode and the conditions under which this happens .",
    "moreover we will show that over the erasure channel this class of codes can decode extremely efficiently .",
    "the paper is organized as follows .",
    "section  [ preliminaries ] provides the necessary background for the development of the paper .",
    "thus , subsection [ erasure ] explains the assumptions on the channel model ; subsection  [ mdp ] provides all the necessary concepts about mdp convolutional codes and their characterizations .",
    "section  [ decoding ] is the main part of the paper .",
    "it contains our main result and describes in detail the decoding procedure .",
    "it also provides examples and special concerns to be noticed when comparing with mds block codes , and in particular with reed - solomon codes .",
    "section  [ generatorm ] shows a decoding method in which the transmitted information is recovered directly .",
    "an erasure channel is a communication channel where the symbols sent either arrive correctly or the receiver knows that a symbol has not been received or was received incorrectly .",
    "an important example of an erasure channel is the internet , where packet sizes are upper bounded by 12,000 bits - the maximum that the ethernet protocol allows ( that everyone uses at the user end ) . in many cases , this",
    "maximum is actually used . due to the nature of the tcp part of the tcp / ip protocol stack ,",
    "most sources need an acknowledgment confirming that the packet has arrived at the destination ; these packets are only 320 bits long .",
    "so if everyone were to use tcp / ip , the packet size distribution would be as follows : 35% 320 bits , 35%  12,000 bits and 30%  in between the two , uniform .",
    "real - time traffic used , e.g. , in video calling does not need an acknowledgment since that would take too much time ; overall , the following is a good assumption of the packet size distribution : 30%  320 bits , 50%  12,000 bits , 20% in between , uniform .",
    "we can model each packet as an element or sequence of elements from a large alphabet .",
    "since packets over the internet are usually protected by a cyclic redundancy check ( crc ) code the receiver knows when a packet is in error or has not arrived . for the purpose of illustration we could employ as alphabet the finite field @xmath8 .",
    "if a packet has less than 1,000 bits then one uses simply the corresponding element of  @xmath9 .",
    "if the packet is larger one uses several alphabet symbols to describe the packet .",
    "even if one uses some interleaving , such an encoding scheme results in the property that errors tend to occur in bursts and this is a phenomena observed about many channels modeled via the erasure channel .",
    "this point is important to keep in mind when designing codes which are capable of correcting many errors over the erasure channel .",
    "let @xmath10 be a finite field .",
    "we view a convolutional code @xmath11 with rate @xmath6 as a submodule of @xmath12 $ ] ( see @xcite ) that can be described as @xmath13 |    { \\ensuremath{\\text{\\mathversion{bold}$v$}}}(z)=g(z){\\ensuremath{\\text{\\mathversion{bold}$u$}}}(z ) \\quad \\text{with } \\quad { \\ensuremath{\\text{\\mathversion{bold}$u$}}}(z )    \\in { \\mathbb{f}}^{k}[z ] \\right\\}\\ ] ] where @xmath14 is a @xmath15 polynomial matrix called a * generator matrix * for @xmath11 , @xmath16 is the * information vector * and @xmath17 is the * code vector * or * codeword*.    we define the * degree * of a convolutional code @xmath11 , and we denote it by @xmath7 , as the maximum of the degrees of the determinants of the @xmath18 sub - matrices of any generator matrix of @xmath11 .",
    "then we say that @xmath11 is an @xmath5 convolutional code  @xcite .    in case",
    "the convolutional code @xmath19 is also observable ( see , e.g. , @xcite ) then @xmath19 can be equivalently described through a parity check matrix . in other words",
    ", there exists in this case an @xmath20 full rank polynomial matrix @xmath21 such that @xmath13 \\",
    "\\ | \\ \\     h(z){\\ensuremath{\\text{\\mathversion{bold}$v$}}}(z)={\\ensuremath{\\text{\\mathversion{bold}$0 $ } } } \\in \\mathbb{f}^{n - k}[z ] \\right\\}.\\ ] ] if we write @xmath22 ( with @xmath23 ) and we represent @xmath21 as a matrix polynomial @xmath24 we can expand the kernel representation in the following way @xmath25    an important distance measure for convolutional codes is the * free distance * : @xmath26 the following lemma shows the importance of the free distance as a performance measure of a code used over the erasure channel .    if @xmath19 is a convolutional code with free distance @xmath27 and if during transmission at most @xmath28 erasures occur then these erasures can be uniquely decoded .",
    "moreover , there exist patterns of @xmath29 erasures which can not be uniquely decoded .",
    "let @xmath22 be a received vector with @xmath28 symbols erased .",
    "let the erasures be in positions @xmath30 .",
    "the homogeneous system   of @xmath31 equations with @xmath32 unknowns can be changed into an equivalent nonhomogeneous system @xmath33 of @xmath31 equations with @xmath28 unknowns @xmath34 .",
    "this nonhomogeneous system has a solution , because of the assumption that the channel allows only erasures .",
    "in addition the columns of the system matrix are linearly independent , because @xmath35 , so the matrix @xmath36 is full column rank .",
    "it follows from these two facts that the solution must be unique .",
    "rosenthal and smarandache  @xcite showed that an @xmath5 convolutional code has a free distance upper bounded by @xmath37 this bound is known as the * generalized singleton bound * @xcite since it generalizes in a natural way the singleton bound for block codes .",
    "analogously , we say that an @xmath5 code is a * maximum distance separable * convolutional code ( mds )  @xcite if its free distance achieves the generalized singleton bound .",
    "another local distance measure , important as well for decoding and related with the previous one , is the * column distance * @xcite , @xmath38 , given by the expression @xmath39}(z))\\ \\ | \\ \\     { \\ensuremath{\\text{\\mathversion{bold}$v$}}}(z)\\in \\mathcal{c } \\ \\ \\text{and } \\ \\ { \\mathbf{v}}_{0}\\neq    0\\right\\}\\ ] ] where @xmath40}(z)={\\mathbf{v}}_{0}+{\\mathbf{v}}_{1}z+\\ldots+{\\mathbf{v}}_{j}z^{j}$ ] represents the @xmath41th truncation of the codeword @xmath42 .",
    "it is related with the @xmath43 in the following way @xmath44 the @xmath41-th column distance is then upper bounded by @xmath45 and the maximality of any of the column distances implies the maximality of all the previous ones , that is , if @xmath46 for some @xmath41 , then @xmath47 for @xmath48 , see @xcite . the @xmath49-tuple @xmath50 is called the * column distance profile * of the code @xcite .",
    "since no column distance can achieve a value greater than the generalized singleton bound , the largest integer for which that bound can be attained is @xmath51 an @xmath5 convolutional code @xmath11 is * maximum distance profile * ( mdp ) @xcite , if @xmath52 . in this case , every @xmath38 for @xmath53 is maximal , so we can say that the column distances of mdp codes increase as rapidly as possible for as long as possible .    in order to characterize the column distances as well as mdp codes algebraically assume the parity check matrix is given as @xmath54 . for each @xmath55 define @xmath56 and define",
    ": @xmath57 then we have :    ( ( * ? ? ?",
    "* proposition 2.1))[theorem - d ] let @xmath58 .",
    "then the following properties are equivalent .",
    "@xmath59 ;    none of the first  @xmath60 columns of  @xmath61 is contained in the span of any other @xmath62 columns and one of the first  @xmath60 columns of  @xmath61 is in the span of some other @xmath28 columns of that matrix .    as a consequence we have the algebraic characterization of mdp convolutional codes :    ( ( * ? ? ?",
    "* theorem 3.1 ) ) [ mdp ] the @xmath41-th column distance attains the maximum value @xmath63 if and only if , every @xmath64 full - size minor of @xmath61 formed from the columns with indices @xmath65 , where @xmath66 for @xmath67 , is nonzero .",
    "in particular when @xmath68 , then @xmath21 represents an mdp code , if and only if , every @xmath69 full - size minor of @xmath70 formed from the columns with indices @xmath71 , where @xmath66 for @xmath72 , is nonzero .",
    "mdp convolutional codes can be thought to be like an mds block code within windows of size @xmath73 .",
    "the nonsingular full - size minors property given in the previous theorem ensures that if we truncate a codeword at iterations up to @xmath74 it will have weight higher or equal than the bound .",
    "let us suppose that we use an mdp convolutional code @xmath11 to transmit over an erasure channel .",
    "then we can state the following result .",
    "[ main ] let @xmath11 be an @xmath5 mdp convolutional code . if in any sliding window of length @xmath73 at most @xmath75 erasures occur then we can recover the whole sequence .",
    "assume that we have been able to correctly decode up to an instant @xmath76 .",
    "then we have the following homogeneous system : @xmath77 where @xmath78 takes the place of a vector that had some of the components erased .",
    "let the positions of the erased field elements be @xmath79 @xmath80 , where @xmath81 @xmath82 , are the erasures occurring in the first erased @xmath60-vector .",
    "we can compute the syndrome and get a nonhomogeneous system with @xmath75 equations and @xmath83 , at most @xmath75 , variables .",
    "we claim that there is an extension @xmath84 such that the vector @xmath85 is a codeword and such that @xmath86 is unique .    indeed",
    ", we know that a solution of the system exists since we assumed only erasures occur . to prove the uniqueness of @xmath86 , or equivalently , of the erased elements @xmath87",
    "let us suppose there exist two such good extensions @xmath88 and @xmath89 .",
    "let @xmath90 , be the column vectors of the sliding parity - check matrix in   which correspond to the erasure elements .",
    "we have : @xmath91 and @xmath92 where the vectors @xmath93 and @xmath94 correspond to the known part of the system . subtracting these equations and observing that @xmath95",
    ", we obtain : @xmath96 using theorem  [ theorem - d ] for a window of size @xmath74 , and using that the code is mdp , so @xmath97 , we obtain that , necessarily , @xmath98 by part ( b ) of theorem  [ theorem - d ] . this concludes the proof of our claim .    in order to find the value of this unique vector",
    ", we solve the full column rank system , find a solution and retain the part which is unique .",
    "then we slide @xmath60 bits to the next @xmath99 window and proceed as above .",
    "the decoding algorithm requires only simple linear algebra . for every @xmath100 erasures a matrix of size",
    "at most @xmath75 has to be inverted over the base field @xmath9 .",
    "this is easily achieved even over fairly large fields .",
    "in addition one should notice that for a rate @xmath101 mdp convolutional code , @xmath102 percent of the erasures can be corrected .",
    "theorem  [ main ] is optimal in a certain sense : one can show that for any @xmath5 code there exist patterns of @xmath103 erasures in a sliding window of length @xmath104 which can not be uniquely decoded .",
    "the following illustrative example compares the size of a particular mdp convolutional code with an mds block code which would perform similarly .",
    "let us take a @xmath105 mdp convolutional code to decode over an erasure channel .",
    "in this case the decoding can be completed if in any sliding window of length @xmath106 there are not more than @xmath107 erasures ; @xmath108 of the erasures can be recovered .",
    "the mds block code which achieves a comparable performance is a @xmath109 $ ] mds block code . in a block of @xmath110 symbols we can recover @xmath111 erasures , that is again @xmath108 .",
    "[ remark1 ] it has been noticed that the parameter @xmath74 gives us an upper bound on the length of the window we can take to correct , but it should be noticed as well that the property of theorem  [ mdp ] holds for every @xmath112 .",
    "this means that we can take smaller windows to set our systems ( the size will be conveniently decided by the distribution of the erasures in the sequence ) .",
    "then in a window of size @xmath113 symbols we can recover at most @xmath114 erasures .",
    "this property allows us to recover the erasures in situations where the mds block codes can not do it .",
    "for example , assume that we have been able to correctly decode up to an instant @xmath115 and then it comes a block of @xmath110 symbols where @xmath116 bursts of @xmath117 erasures occur separated by a block of @xmath118 clean symbols , and after it , clean symbols again .",
    "@xmath119 in this situation @xmath120 erasures happen in a block of @xmath110 symbols and the mds block code is not able to recover them . in the block code situation one has to skip the whole block losing that information , and go on with the decoding .    however",
    ", the mdp convolutional code can deal with this situation .",
    "let us set a @xmath120 symbols length window ; in these windows we can correct up to @xmath117 erasures .",
    "we can take @xmath111 previous decoded symbols , then set a window with the first @xmath117 erasures and @xmath117 more clean symbols . in this way",
    "we can recover the first block of erasures . then we can slide through the received sequence with this @xmath120 symbols window until we set the rest of the erasures in the same way .",
    "@xmath121 after this we have correctly decoded the sequence .    [ remark2 ] another advantage to remark",
    "is related to the storage and to the field size required to construct the codes . in the example , we propose we have a @xmath109 $ ] mds block code . if we take , for example , a reed - solomon code ( one of the most widely used mds block codes ) then we need to store the @xmath110 roots of a @xmath110 degree polynomial to set the code .",
    "that is , we need at least @xmath110 field elements .",
    "however , to set the @xmath105 mdp convolutional code we need to store the coefficients of @xmath116 polynomials of degree @xmath122 , that is at least @xmath111 different elements .    nevertheless there are some disadvantages . on the one hand ,",
    "the storage and the field size are smaller , but on the other hand , there are not direct constructions for the case of mdp convolutional codes .",
    "this is still an open problem .",
    "the construction of mdp convolutional codes has been developed somewhat @xcite , however there exists still no efficient algorithm to construct this class of codes . in relation to this problem , special type of matrices called _ superregular matrices _ proved to be relevant during this study and this topic has become of main importance when trying to construct mdp convolutional codes @xcite .",
    "if we denote by @xmath123 the @xmath124 submatrix obtained from a matrix @xmath125 by taking the rows with indices @xmath126 and the columns with indices @xmath127 , then we can define a superregular matrix as follows .",
    "@xcite a lower triangular toepliz matrix @xmath128 @xmath129 is said to be superregular if @xmath123 is nonsingular for all @xmath130 and all indices @xmath131 , @xmath132 which satisfy @xmath133 for @xmath134 .",
    "the submatrices obtained by picking such indices are called the _ proper submatrices _ and their determinants the _ proper minors _ of @xmath128 .    unfortunately",
    ", the characterization or construction of these matrices is a hard problem and more research is needed in this direction in order to come up with a construction for mdp convolutional codes .",
    "in this section we explain how the use of the generator matrix of the mdp code can make our decoding process more efficient and faster .    we know that the encoding process is represented by @xmath135 ,",
    "so the idea is to use this relation to recover directly the original message @xmath16 instead of computing first the code sequence and then decode it into the original sequence @xmath16 , as we did before when working with the parity check matrix .    in an analogous way to the parity check matrix",
    "we can expand the generator matrix into @xmath136 and define @xmath137 as @xmath138 then the equivalences in the following theorem give us the properties to improve the decoding algorithm .",
    "( ( * ? ? ?",
    "* theorem 2.4 ) ) let @xmath61 and @xmath137 be as in ( [ eq5 ] ) and ( [ eq7 ] )",
    ". then the following are equivalent :    1 .",
    "@xmath139 2 .",
    "every @xmath140 full - size minor of @xmath141 formed from the columns with indices @xmath142 , where @xmath143 for @xmath67 , is nonzero .",
    "one notices that for an mdp convolutional code the maximum size of the matrix @xmath137 we can construct is again given by the parameter @xmath74 .",
    "this tells us that the maximum number of original symbols we are able to recover in one time is @xmath144 .",
    "since in any sliding window of length @xmath73 not more than @xmath75 erasures occur we can set a full rank system with at least @xmath144 equations to recover the @xmath144 symbols of the original sequence",
    ". we will leave the details to the reader .",
    "in this paper , we propose mdp convolutional codes as an alternative to block codes when decoding over an erasure channel .",
    "we have seen that the step - by - step - mds property of the mdp codes lets us recover the maximum number of erasures at every step . even over large field",
    "sizes the complexity of decoding is polynomial for a fixed window size since the decoding algorithm requires the solving of some linear system only .",
    "moreover , the sliding window property allows us to adapt the decoding process to the distribution of the erasures in the sequence .",
    "we have shown how the possibility of taking smaller windows lets us recover erasures that the block codes can not recover .",
    "we would like to thank martin haenggi who explained us the distribution of packet sizes when transmitting files over the internet .",
    "r.  j. mceliece . the algebraic theory of convolutional codes . in v.  pless and w.c .",
    "huffman , editors , _ handbook of coding theory _ , volume  1 , pages 10651138 .",
    "elsevier science publishers , amsterdam , the netherlands , 1998 .",
    "j.  rosenthal .",
    "connections between linear systems and convolutional codes . in b.",
    "marcus and j.  rosenthal , editors , _ codes , systems and graphical models _ , i m a vol .",
    "123 , pages 3966 .",
    "springer - verlag , 2001 ."
  ],
  "abstract_text": [
    "<S> this paper studies the decoding capabilities of maximum distance profile ( mdp ) convolutional codes over the erasure channel and compares them with the decoding capabilities of mds block codes over the same channel . </S>",
    "<S> the erasure channel involving large alphabets is an important practical channel model when studying packet transmissions over a network , e.g , the internet .     </S>",
    "<S> +    @xmath0 partially supported by spanish grant mtm2008 - 06674-c02 - 01 and a grant of the vicerectorat dinvestigaci , desenvolupament i innovaci of the universitat dalacant for phd students during a stay at zrich universitt on charge to the same program .    </S>",
    "<S> @xmath1 supported by the swiss national science foundation under project no . </S>",
    "<S> 113251 .    </S>",
    "<S> @xmath2 supported by nsf grants dms-0708033 and tf-0830608 .    </S>",
    "<S> _ keywords _  convolutional codes , maximum distance separable codes , parity check matrix , decoding , erasure channel , reed - solomon codes . </S>"
  ]
}