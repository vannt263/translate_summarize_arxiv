{
  "article_text": [
    "spatially embedded systems are very important in biological and social sciences since most interactions among living beings or artificial actors take place in physical two- or three - dimensional space  @xcite . along these lines , game - theoretical interactions among spatially embedded agents distributed according to a fixed structure in the plane have been studied in detail , starting from the pioneering works of axelrod  @xcite and nowak and may  @xcite .",
    "the related literature is very large ; see , for instance , the review article by nowak and sigmund  @xcite and references therein for a synthesis .",
    "most of this work was based on populations of agents arranged according to planar regular grids for mathematical simplicity and ease of numerical simulation .",
    "recently , some extensions to more general spatial networks have been discussed in  @xcite .",
    "the study of strategic behavior on fixed spatial structures is necessary in order to understand the basic mechanisms that may lead to socially efficient global outcomes such as cooperation and coordination .",
    "however , in the majority of real situations both in biology and in human societies , actors have the possibility to move around in space .",
    "many examples can be found in biological and ecological sciences , in human populations , and in engineered systems such as ad hoc networks of mobile communicating devices or robot teams .",
    "mobility may have positive or negative effects on cooperation , depending on several factors .",
    "an early investigation was carried out by enquist and leimar  @xcite who concluded that mobility may seriously restrict the evolution of cooperation . in the last decade",
    "there have been several new studies of the influence of mobility on the behavior of various games in spatial environments representing essentially two strands of research : one in which the movement of agents is seen as a random walk , and a second one in which movement may contain random elements but it is purposeful , or strategy - driven .    random diffusion of mobile agents through space , either in continuous space or , more commonly , on diluted grids has been investigated in  @xcite . in the present study we focus on situations where , instead of randomly diffusing , agents possess some basic cognitive abilities and they actively seek to improve their situation by moving in space represented as a discrete grid in which part of the available sites are empty and can thus be the target of the displacement .",
    "this approach has been followed , for example , in  @xcite .",
    "the mechanisms invoked range from success - driven migration  @xcite , adaptive migration  @xcite , reputation - based migration  @xcite , risk - based migration  @xcite , flocking behavior  @xcite , and cooperators walking away from defectors  @xcite . in spite of the difference among the proposed models , the general qualitative message of this work is that purposeful contingent movement may lead to highly cooperating stable or quasi - stable population states if some conditions are satisfied .",
    "our approach is based on numerical simulation and is inspired by the work of helbing and yu  @xcite which they call `` success - driven migration '' and which has been shown to be able to produce highly cooperative states . in this model ,",
    "locally interacting agents playing either defection or cooperation in a two - person prisoner s dilemma are initially randomly distributed on a grid such that there are empty grid points .",
    "agents update their strategies according to their own payoff and the payoff earned by their first neighbours but they can also `` explore '' an extended square neighborhood by testing all the empty positions up to a given distance . if the player finds that it would be more profitable to move to one of these positions then she does it , choosing the best one among those tested , otherwise she stays at her current place .",
    "helbing and yu find that robust cooperation states may be reached by this mechanism , even in the presence of random noise in the form of random strategy mutations and random agent relocation .",
    "our study builds upon this work in several ways . in the first place ,",
    "whilst helbing and yu had a single game neighborhood and migration neighborhood , we systematically investigate these two parameters showing that only some combination do foster cooperation using success - driven migration .",
    "secondly , cost issues are not taken into account in  @xcite .",
    "however , it is clear that moving around to test the ground is a costly activity . in a biological setting",
    ", this could mean using up energy coming from metabolic activity , and this energy could be in short supply . in a human society",
    "setting , it is the search time that could be limited in a way or another . additionally to physical energy , cognitive abilities could also limit the search .",
    "we present results for a whole game phase space including the hawk - dove class of games , and the stag hunt coordination class .",
    "helbing s and yu s agents based their strategy change on the imitation of the most successful neighbour in terms of accumulated payoff .",
    "we kept this rule but also added the fermi strategy - updating rule , a choice that allows us to introduce a parametrized amount of imitation noise . with the imitiation of the best policy",
    "we find that cooperation prevails in the stag hunt and may evolve in the prisoner s dilemma for small interaction radius . with the fermi rule fully cooperative states",
    "are reached for the standard neighborhoods independently of the migration distances when the rate of random strategy imitation is high enough .",
    "we investigate three classical two - person , two - strategy , symmetric games classes , namely the prisoner s dilemma ( pd ) , the hawk - dove game ( hd ) , and the stag hunt ( sh ) .",
    "these three games are simple metaphors for different kinds of dilemmas that arise when individual and social interests collide .",
    "the harmony game ( h ) is included for completeness but it does nt originate any conflict .",
    "the main features of these games are well known ; more detailed accounts can be found elsewhere e.g.  @xcite .",
    "the games have the generic payoff matrix @xmath0 ( equation  [ eq : payoff ] ) which refers to the payoffs of the row player .",
    "the payoff matrix for the column player is simply the transpose @xmath1 since the game is symmetric .",
    "@xmath2 the set of strategies is @xmath3 , where @xmath4 stands for `` cooperation '' and @xmath5 means `` defection '' . in the payoff matrix @xmath6",
    "stands for the _ reward _ the two players receive if they both cooperate , @xmath7 is the _ punishment _ if they both defect , and @xmath8 is the _ temptation _ , i.e.  the payoff that a player receives if he defects while the other cooperates getting the _ sucker s",
    "payoff _ @xmath9 . for the pd ,",
    "the payoff values are ordered such that @xmath10 .",
    "defection is always the best rational individual choice , so that @xmath11 is the unique nash equilibrium ( ne ) . in the hd game",
    "the payoff ordering is @xmath12 .",
    "thus , when both players defect they each get the lowest payoff . @xmath13 and @xmath14 are ne of the game in pure strategies .",
    "there is a third equilibrium in mixed strategies which is the only dynamically stable equilibrium  @xcite . in the sh game ,",
    "the ordering is @xmath15 , which means that mutual cooperation @xmath16 is the best outcome and a ne .",
    "the second ne , where both players defect is less efficient but also less risky .",
    "the third ne is in mixed strategies but it is evolutionarily unstable  @xcite . finally , in the h game @xmath17 or @xmath18 .",
    "in this case @xmath4 strongly dominates @xmath5 and the trivial unique ne is @xmath16 .",
    "the game is non - conflictual by definition ; it is mentioned to complete the quadrants of the parameter space .",
    "there is an infinite number of games of each type since any positive affine transformation of the payoff matrix leaves the ne set invariant  @xcite .",
    "here we study the customary standard parameter space  @xcite , by fixing the payoff values in the following way : @xmath19 , @xmath20 , @xmath21 , and @xmath22 .",
    "therefore , in the @xmath23 plane each game class corresponds to a different quadrant depending on the above ordering of the payoffs as depicted in fig .",
    "[ phasespace ] , left image . the right image depicts the well mixed replicator dynamics stable states for future comparison .",
    "cccccccc   &   &      the euclidean two - dimensional space is modeled by a discrete square lattice of side @xmath24 with toroidal borders .",
    "each vertex of the lattice can be occupied by one player or be empty .",
    "the _ density _ is @xmath25 , where @xmath26 is the number of players .",
    "players can interact with @xmath27 neighbours which lie at an euclidean distance smaller or equal than a given constant @xmath28 .",
    "players can also migrate to empty grid points at a distance smaller than @xmath29 .",
    "we use three neighborhood sizes with radius @xmath30 , @xmath31 , and @xmath32 ; they contain , respectively , @xmath33 , @xmath34 , and @xmath35 neighbours around the central player .",
    "each agent @xmath36 interacts locally with a set of neighbours @xmath37 lying closer than @xmath28 .",
    "let @xmath38 be a vector giving the strategy profile at time @xmath39 with @xmath40 and @xmath41 and let @xmath0 be the payoff matrix of the game ( equation  [ eq : payoff ] ) .",
    "the quantity @xmath42 is the cumulated payoff collected by player @xmath36 at time step @xmath39 .",
    "we use two imitative strategy update protocols .",
    "the first is the fermi rule in which the focal player @xmath36 is given the opportunity to imitate a randomly chosen neighbour @xmath43 with probability : @xmath44 where @xmath45 is the difference of the payoffs earned by @xmath43 and @xmath36 respectively and @xmath46 is a constant corresponding to the inverse temperature of the system . when @xmath47 the probability of imitating @xmath43 tends to a constant value @xmath48 and when @xmath49 the rule becomes deterministic : @xmath36 imitates @xmath43 if @xmath50 , otherwise it does nt . in between these two extreme cases",
    "the probability of imitating neighbour @xmath43 is an increasing function of @xmath51 .",
    "the second imitative strategy update protocol is to switch to the strategy of the neighbour that has scored best in the last time step .",
    "in contrast with the previous one , this rule is deterministic .",
    "this _ imitation of the best _",
    "( ib ) policy can be described in the following way : the strategy @xmath38 of individual @xmath36 at time step @xmath39 will be @xmath52 where @xmath53 that is , individual @xmath36 will adopt the strategy of the player with the highest payoff among its neighbours including itself . if there is a tie , the winner individual is chosen uniformly at random .",
    "we use an asynchronous scheme for strategy update and migration , i.e. players are updated one by one by choosing a random player in each step with uniform probability and with replacement",
    ". then the player migrates with probability @xmath54 , otherwise it updates its strategy .",
    "if the pseudo - random number drawn dictates that @xmath36 should migrate , then it considers @xmath55 randomly chosen positions in the disc of radius @xmath29 around itself .",
    "the quantity @xmath55 could be seen as a kind of `` energy '' available to a player for moving around and doing its search .",
    "@xmath55 being fixed for a given run , it follows that an agent will be able to make a more complete exploration of its local environment the smaller the @xmath29 . for each trial position the player computes the payoff that it would obtain in that place with its current strategy .",
    "the positions already occupied are just discarded from the possible choices .",
    "then player @xmath36 stays at its current position if it obtains there the highest payoff , or migrates to the most profitable position among those explored during the test phase .",
    "if several positions , including its current one , share the highest payoff then it chooses one at random .",
    "we call this migration",
    "_ opportunistic _ or _ fitness - based_. the protocol described in helbing and yu  @xcite is slightly different : the chosen player chooses the strategy of the best neighbour including itself with probability @xmath56 , and with probability @xmath57 , with @xmath58 , its strategy is randomly reset . before this imitation step @xmath36 deterministically chooses the highest payoff free position in a square neighborhood of size @xmath59 cells surrounding the current player and including itself , where @xmath0 can take the values @xmath60 .",
    "if several positions provide the same payoff , the one that is closer is selected .",
    "the @xmath23 plane has been sampled with a grid step of @xmath61 and each value in the phase space reported in the figures is the average of @xmath62 independent runs .",
    "the evolution proceeds by first initializing the population by distributing @xmath63 players with uniform probability among the available cells .",
    "then the players strategies are initialized uniformly at random such that each strategy has a fraction of approximately @xmath54 . to avoid transient states ,",
    "we let the system evolve for a period of @xmath64 time steps and , in each time step , @xmath65 players are chosen for update . at this point",
    "almost always the system reaches a steady state in which the frequency of cooperators is stable except for small statistical fluctuations",
    ". we then let the system evolve for @xmath62 further steps and take the average cooperation value in this interval .",
    "we repeat the whole process @xmath62 times for each grid point and , finally , we report the average cooperation values over those @xmath62 repetitions .",
    "cccccccc   &   &    in this section we study cooperation with the ib rule and fitness - based opportunistic migration , and we explore the influence of different radii @xmath29 and @xmath28 and other parameters such as the density @xmath66 and the number of trials @xmath55 .",
    "the left image of fig .  [ ib1 ] displays the ts plane with the ib rule , a density @xmath67 , and @xmath68 . for small @xmath69",
    "full cooperation is achieved in the sh quadrant for all @xmath29 .",
    "the average levels of cooperation in the pd games are @xmath70 for @xmath71 and @xmath72 respectively .",
    "it is remarkable that cooperation emerges in contrast to the well mixed population case ( fig .",
    "[ phasespace ] , right image ) , and also that better results are obtained with respect to a fully populated grid in which agents can not move  @xcite .",
    "the hd does nt benefit in the same way and the cooperation levels are almost the same in the average .",
    "cooperation remains nearly constant as a function of @xmath29 for a given @xmath28 value but increasing @xmath28 has a negative effect .",
    "for higher game radius , @xmath73 cooperation is progressively lost in the pd games while there is little variation in the hd quadrant among the different cases due to the dimorphic structure of these populations . in the sh quadrant",
    "there is a large improvement compared to the well mixed case but the gain tends to decrease with increasing @xmath28 . in the pd with high @xmath28 , cooperators can not increase their payoff by clustering , since the neighborhood of defectors covers adjacent small clusters of cooperators , the payoff of defectors becomes higher and they can invade cooperators clusters .",
    "figure  [ grids ] illustrates in an idealized manner what happens to a small cooperators cluster when the game radius @xmath28 increases using a full grid for simplicity .",
    "cccccccc     for @xmath69 ( left image ) the cooperator cluster is stable as long as @xmath74 since the central cooperator gets a payoff of @xmath75 , while the best payoff among the defectors is obtained by the individual marked @xmath5 ( and by the symmetrically placed defectors ) and is equal to @xmath76 since @xmath20 . under this condition",
    "all the cooperators will thus imitate the central one . on the other hand",
    ", the defector will turn into a @xmath4 as long as @xmath77 , thus provoking cooperator cluster expansion for parameter values in this range . on the contrary , for @xmath78 ( right image ) the central cooperator",
    "gets @xmath79 whilst the central defector at the border has a payoff of @xmath80 .",
    "thus the cooperator imitates the defector if @xmath81 , i.e. @xmath82 since @xmath19 .",
    "this qualitative argument helps to explain the observed cooperation losses for increasing @xmath28 .",
    "this inequality is satisfied almost everywhere in the pd quadrant except in a very small area in its upper left corner .",
    "helbing and yu  @xcite found very encouraging cooperation results in their analysis but they only had a small game radius corresponding to the von neumann neighborhood which is constituted , in a full lattice , by the central individual and the four neighbours at distance one situated north , east , south , and west .",
    "we also find similar results for our smallest neighborhood having @xmath69 , which corresponds to the eight - points moore neighborhood but , as @xmath28 gets larger , we have just seen that a sizable portion of the cooperation gains are lost .",
    "we think that this is an important point since there are certainly situations in which those more extended neighborhoods are the natural choice in a spatially extended population .",
    "cccccccc   &   &    the number of trials @xmath55 could also be a critical parameter in the model . the right image of fig .",
    "[ ib1 ] refers to the same case as the left one , i.e. the ib update rule with opportunistic migration and @xmath67 , except for the number of trials which is one instead of @xmath83 .",
    "we observe that practically the same cooperation levels are reached at steady state in both cases for @xmath84 and @xmath85 , while there is a small increase of the average cooperation in the pd games for @xmath72 which goes from @xmath86 , @xmath87 , and @xmath88 for @xmath89 to @xmath90 , @xmath91 , and @xmath86 for @xmath92 , for @xmath93 respectively . on the whole , it is apparent that @xmath55 does not seem to have a strong influence .",
    "however , one might ask whether the times to convergence are shorter when more tests are used , a fact that could compensate for the extra work spent in searching . but figs .",
    "[ convergencetimes ] show that convergence times are not very different and decrease very quickly with the number of essays @xmath55 .",
    "this is shown for two particular games , one in the middle of the sh quadrant ( left image ) , and the other near the upper left corner of the pd space ( right image ) .",
    "thus , a shorter time does not compensate for the wasted trials .",
    "since moving around to find a better place is a costly activity in any real situation , this result is encouraging because it says that searching more intensively does nt change the time to convergence for more than four tests .",
    "thus , quite high levels of cooperation can be achieved by opportunistic migration at low search cost , a conclusion that interestingly extends the results presented in  @xcite .    in diluted grids",
    ", density is another parameter that influences the evolution of cooperation  @xcite , also in the presence of intelligent migration  @xcite .",
    "too high densities should be detrimental because clusters of cooperators are surrounded by a dense population of defectors , while low densities allow cooperator clusters to have less defectors in their neighborhood once they are formed .",
    "we have performed numerical simulations for two other values of the density besides @xmath48 , @xmath94 and @xmath95 .",
    "we do not show the figures to save space but the main remark is that there is a monotone decrease of cooperation going from low to higher densities in the low @xmath9 region that influences mainly the pd and , to a smaller extent , the sh games .",
    "in this section we use the more flexible strategy update protocol called the fermi rule which was described in sect .",
    "[ revision - protocols ] and in which the probability to imitate a random neighbour s strategy depends on the parameter @xmath46 . we have seen that using the ib rule with adaptive migration leads to full cooperation in the sh quadrant and improves cooperation in a part of the pd quadrant ( fig .  [ ib1 ] ) .",
    "this result does not hold with the fermi rule with @xmath96 , and we are back to full defection in the pd and almost @xmath97 cooperation as in the well mixed case in the sh ; this behavior can be appreciated in the leftmost image of fig .",
    "[ fermi0p5 ] .",
    "cccccccc   &   &   &   &    an interesting new phenomenon appears when @xmath46 becomes small , of the order of @xmath98 . in this case , the levels of cooperation increase in all games for @xmath28 values up to @xmath31 and cooperation raises to almost @xmath99 in all game phase space for @xmath69 , for all migration radii , see the third image of fig .",
    "[ fermi0p5 ] .",
    "the positive trend continues with decreasing @xmath46 ( see rightmost image ) and cooperation prevails almost everywhere . as we said above , the fermi rule with @xmath100 or less implies that the decision to imitate a random neighbour becomes almost random itself . thus , the spectacular gains in cooperation must depend in some way from opportunistic migration for the most part .",
    "figure  [ fermirand ] illustrates the dynamical behavior of a particular case in the pd space .",
    "here @xmath101 , @xmath102 , @xmath19 , @xmath20 ; that is , the game is in the middle of the pd quadrant .",
    "the other parameters are : @xmath100 , @xmath69 , and @xmath85 .",
    "this particular game would lead to full defection in almost all cases but here we can see that it leads to full cooperation instead .",
    "this is a surprising phenomenon that needs an explanation . at the beginning , due to opportunistic migration",
    ", cooperators will be likely to form small clusters between themselves more than defectors , as the latter tend to follow cooperators instead of clustering between themselves since the @xmath11 payoff is equal to @xmath103",
    ". the low @xmath46 value will make strategy change close to random and thus strategy update will have a neutral effect . indeed , as soon as cooperator clusters form due to migration , defectors that enter a cooperator cluster thanks to random imitation can not invade them . the situation there is akin to a full grid and the number of defectors inside the cluster will fluctuate .",
    "meanwhile , defectors at the border of a cooperator cluster will steadily turn into cooperators thus extending the cluster .",
    "this is due to the fact that lone defectors at the border will tend to imitate cooperators since defectors are less connected , and strategy imitation is almost random .",
    "finally , the defectors inside the clusters will reach the border and turn into cooperators as well .",
    "the phenomenon is robust with respect to the migration radius @xmath29 , as can be seen in the lower part of the third and fourth images of fig .",
    "[ fermi0p5 ] .",
    "cooperation prevails even when @xmath7 becomes positive which increases the payoff for defectors to aggregate .",
    "we have simulated the whole phase space for @xmath104 and @xmath105 .",
    "the results are similar to those with @xmath20 except that cooperation decreases slightly with increasing @xmath7 . on the same images",
    "it can be seen that the game radius @xmath28 has a large influence and cooperation tends to be lost for radii larger than @xmath30 .",
    "the reasons for this are very similar to those advocated in sect .",
    "[ ibam ] where fig .",
    "[ grids ] schematically illustrates the fact that increasing @xmath28 makes the situation more similar to a well mixed population . in these conditions ,",
    "the payoff - driven strategy imitation process becomes more important and may counter the benefits of opportunistic migration .",
    "however , since we believe that system possessing locality are important in practice , the findings of this section seem very encouraging for mobile agents that are better at finding more profitable positions and moving to them rather than at strategic reasoning .",
    "in this work we have explored some possibilities that arise when agents playing simple two - person , two - strategy evolutionary games may also move around in a certain region seeking better positions for themselves .",
    "the games examined are the standard ones , like the prisoner s dilemma , the hawk - dove , or the stag hunt . in this context ,",
    "the ability to move around in space is extremely common in animal as well as human societies and therefore its effect on global population behavior is an interesting research question .",
    "as already pointed out by other researchers  @xcite , adding a form of contingent mobility may result in better capabilities for the population to reach socially valuable results . among the existing models ,",
    "we have started from a slightly modified form of the interesting helbing s and yu s model  @xcite and have explored some further avenues that were left untouched in the latter work . in the model agents live and move in a discrete two - dimensional grid space in which part of the cells are unoccupied . using a strategy update rule that leads an agent to imitate her most successful neighbour as in  @xcite , and having the possibility to explore a certain number of free positions around oneself to find a better one , the gains in cooperative behavior are appreciable in the prisoner s dilemma , in qualitative agreement with  @xcite . in the hawk - dove games the gains in cooperation are small but",
    ", in addition , we find that cooperation is fully promoted in the class of stag hunt games which were not considered in  @xcite . in helbing and",
    "yu the exploration of the available cells in search of a better one was fixed and deterministic .",
    "the question of the amount of effort needed to improve the agent s situation was left therefore open , although this is clearly an important point , given that in the real world more exploration usually entails an increasing cost be it in terms of energy , time , or money . by using a similar search strategy but to random positions within a given radius , and by varying the number of searches available to the agent , we have seen that the convergence times to reach a given average level of cooperation do not degrade significantly by using fewer trials .",
    "this is a reassuring finding , given the above remarks related to the search cost .",
    "helbing and yu explored migration effects under a number of sizes of the square neighborhood around a given agent .",
    "however , they only had a single neighborhood for the game interactions , the standard five - cells von neumann neighborhood .",
    "we have explored this aspect more deeply and presented results for several combinations of game radius @xmath28 and migration radius @xmath29 . in fact , it turns out that increasing the interaction radius has an adverse effect on cooperation to the point that , at @xmath106 , cooperation levels are similar to those of a well mixed population , in spite of fitness - based migration . thus , positive results are only obtained when agents interact locally in a relatively small neighborhood which , fortunately , seems to be a quite common condition in actual spatial systems .",
    "most importantly , we have explored another important commonly used strategy update rule , the fermi rule .",
    "this rule is also imitative but allows to control the intensity of selection by varying a single parameter @xmath46 .",
    "when @xmath46 is high , i.e. larger than one , almost all the cooperation gains observed with the imitation of the best rule are lost and we are back to a scenario of defection in the prisoner s dilemma space and the stag hunt games are also influenced negatively .",
    "migration does not help in this case .",
    "however , when @xmath46 is low , of the order of @xmath107 , a very interesting phenomenon emerges : cooperation prevails everywhere in the game space for small game radius and for all migration radii , including in the pd space , which is notoriously the most problematic class of games . with @xmath100 or lower the strategy update is close to random ; however , fitness - based migration is active and thus we see that migration , and not strategy update , is the main force driving the population towards cooperation and we have hypothesized a qualitative mechanism that could explain this striking result .",
    "cooperation is robust with respect to the migration radius @xmath29 but increasing @xmath28 affects the results negatively for @xmath108 .",
    "the effect is mitigated the more random the strategy update , i.e. by further decreasing @xmath46 ."
  ],
  "abstract_text": [
    "<S> we study evolutionary games in a spatial diluted grid environment in which agents strategically interact locally but can also opportunistically move to other positions within a given migration radius . using the imitation of the best rule for strategy revision , it is shown that cooperation may evolve and be stable in the prisoner s dilemma game space for several migration distances but only for small game interaction radius while the stag hunt class of games become fully cooperative . </S>",
    "<S> we also show that only a few trials are needed for cooperation to evolve , i.e. searching costs are not an issue . </S>",
    "<S> when the stochastic fermi strategy update protocol is used cooperation can not evolve in the prisoner s dilemma if the selection intensity is high in spite of opportunistic migration . </S>",
    "<S> however , when imitation becomes more random , fully or partially cooperative states are reached in all games for all migration distances tested and for short to intermediate interaction radii .    </S>",
    "<S> = 1 </S>"
  ]
}