{
  "article_text": [
    "discretizations have become a leading tool for the construction of quantum gravity models @xcite , for instance in loop quantum gravity @xcite , spin foams @xcite or regge gravity @xcite .",
    "indeed discrete models provide a very effective method to access non - perturbative physics . given a discretization , the question arises how to relate observables from the discrete model to observables in the corresponding continuum limit ( should it exist ) .",
    "usually this question is handled by considering a family of discretizations , in which we can consider the refinement limit .",
    "observables computed from a given discretizations will in general be approximations to corresponding observables in the continuum limit .",
    "an alternative view is provided by the concept of cylindrical consistency , which is a key technique in the construction of the continuum hilbert space of loop quantum gravity @xcite .",
    "the idea here is that discretizations are not seen as approximation but as a selection of a certain set of degrees of freedom , for which the discrete model should give the same predictions as the continuum model .",
    "more precisely discretizations come with a ( partial ) ordering into finer and coarser and embedding maps of coarser into finer discretizations .",
    "cylindrical consistency demands that observables which can be represented in a given discretization should not depend on the choice of finer discretization into which this given discretization is embedded .",
    "in other words , a prediction drawn from a given discretization should be also valid for any refined discretization or the continuum limit .",
    "so far this concept has been successfully applied to the construction of the kinematical hilbert space @xcite , including observables and the hamiltonian constraints @xcite .",
    "the question arises whether we can implement this concept for the dynamics , for instance in the form of a path integral ( measure ) as suggested in @xcite see also @xcite for related ideas .",
    "this would be equivalent to a cylindrical consistent construction of transition amplitudes ( or the physical hilbert space ) . on the classical level we would ask for cylindrically consistent family of hamilton s principal functions which are the classical analogues of transition amplitudes @xcite .    in this way",
    "cylindrical consistency not only provides the continuum limit of a given theory , it also allows via the embedding maps a precise interpretation of discrete configurations ( states ) as elements of the continuum configuration ( hilbert ) space .",
    "the concept of a cylindrically consistent dynamics is actually very similar to the concept of perfect actions @xcite or perfect discretizations .",
    "these were suggested for gravitational systems in @xcite and constructed for a number of examples in @xcite to address the problem of broken diffeomorphism symmetry in generic discretizations of gravity @xcite .",
    "indeed recent work @xcite has shown that demanding diffeomorphism symmetry is a very strong requirement : there are many examples where it is equivalent to demanding triangulation ( or more generally discretization ) independence .",
    "this includes coarse graining the triangulation or making one region much denser triangulated than another region .",
    "such a notion implies that the discrete theory should correctly reproduce physics on all scales , not only on scales large compared to the discretization scale @xcite . in other words",
    "such a discretization has to mirror continuum theory exactly , which is the defining property of a perfect discretization .",
    "a way to construct such perfect discretizations is as fixed points of a ( real space ) wilsonian renormalization flow .",
    "such a flow generates non - local couplings ( in non - topological theories ) , see for instance @xcite .",
    "these non - local couplings are crucial in order to obtain a non  topological theory which is triangulation independent .",
    "the non  local couplings make the theory also computationally very challenging . as one basically attempts to solve the dynamics of the theory , a systematic framework that would improve the discretization in steps , and",
    "also allows a control on the amount of non - local couplings , is advisable . in this work",
    "we will propose such a framework . as a key input",
    "we introduce boundaries , the fineness of the boundary data will determine the quality of the approximation .",
    "this already indicates that we will have a partial ordering into finer and coarser boundaries and corresponding embedding maps .",
    "this will allow us to formulate the aim of achieving a perfect discretization as finding a cylindrically consistent effective action or hamilton s principal function/ path integral measure . as we will see the choice of embedding maps will be essential and should be determined by the dynamics of the system .",
    "another view point of how this proposal differs from the usual understanding of perfect discretizations , is that in the latter we keep the building blocks of the discretization simple but allow for non  local couplings between these building blocks . here",
    "we will introduce more and more complicated building blocks with finer and finer boundaries .",
    "the couplings between these building blocks will still be local , i.e. only variables associated to neighbouring building blocks will be coupled .",
    "note however that the number of such variables will be growing and that the couplings in - between the variables associated to one building block will be non  local ( if we see this building block as an extended object ) .",
    "in fact this shift of non  localities from in - between building blocks to introducing more and more variables to one building block is inspired by tensor network renormalization @xcite . there",
    "the path integral amplitude ( together with the measure ) associated to a certain region or building block is encoded into a tensor . summing over ( bulk ) variables correspond to the contraction of tensors into a new tensor , which typically is of higher rank , representing more complicated boundary data .",
    "the key question is then how to approximate a tensor of higher rank with a tensor of the original rank , that is one has to choose a truncation of the renormalization flow . here",
    "we will put forward the question whether and how we could use the embedding maps , which underly cylindrical consistency , for such a truncation .",
    "this relation of embedding maps to truncations of the renormalization flow makes it obvious that the embedding maps should be determined according to the dynamics of the system .",
    "+ in the next sections [ scalar ] and [ pot ] we will introduce the concept with the help of an example , the scalar field with and without potential in two dimensions . in the following sections [ larger ] and [ other ] we will consider variations of the coarse graining scheme and compare two different choices for the embedding maps .",
    "the coarse graining scheme will be formalized in section [ cyl ] , which will also shortly review the concept of cylindrical consistency . in section [ quantum ]",
    "we will extend the procedure to the quantum case and discover that the choice of embedding maps is even more important in this case .",
    "we end in section [ disc ] with a summary an outlook .",
    "as an instructive example consider the massless scalar field on a triangulation of flat euclidean two  dimensional space .",
    "one discretization for the scalar field action on a triangulation is given by [ 1 ] s=_s_= _ _ e ( _ |e ) ( _ s(e ) -_t(e ) ) ^2 , where @xmath0 is the angle at the vertex opposite the edge @xmath1 , and @xmath2 denote the source and target vertex of @xmath1 respectively .",
    "note that in two dimensions the action for the massless scalar field is scale invariant .",
    "the action ( [ 1 ] ) is given as a sum over actions associated to the triangles .",
    "this additivity of the action will be essential for what follows .",
    "as we will see the action associated to one triangle can be interpreted as hamilton s principal function for this triangle .",
    "the dynamics defined by the action ( [ 1 ] ) has the remarkable property to be invariant under the so - called 13 pachner move .",
    "this move divides one triangle into three by introducing an inner vertex , see figure [ triang ] .",
    "( this has to be done such that the deficit angle at the inner vertex is zero , i.e. after the subdivision the outer triangle is still flat . )",
    "hamilton s principal function @xmath3 , the action for the complex of three triangles , evaluated on a solution with given boundary data , will then agree with the action for one triangle ( which we identify with hamilton s principal function for this triangle ) [ 3 ] h_3(_1,_2,_3)= h_1(_1,_2,_3 ) .",
    "moreover the left hand side does not depend on where we place the inner vertex , that is the result is invariant under vertex displacement , which can be identified with a discrete notion of diffeomorphism symmetry @xcite .",
    "subdivisions of a triangle . ]",
    "the reason for this invariance is the simple solution for the field on the inner vertex given by [ 4 ] _ 0(x_1,x_2)=x_1 _ 1 + x_2 _ 2 + x_3(x_1,x_2 ) _ 3 where the @xmath4 are barycentric coordinates of the triangle , i.e give the position of the inner vertex as a weighted average of the outer vertex positions , with @xmath5 , so @xmath6 .",
    "this solution is a linear function in the coordinates and hence is also a solution of the continuum laplace operator .",
    "for such a linear solution we can exactly give three boundary data which define the derivatives in the two coordinate directions .",
    "we can define this solution ( [ 4 ] ) not only for the coordinate values of the actual inner vertex  we can also take this as a continuum solution .",
    "this is the reason why hamilton s principal function will be also invariant under further subdivisions of the triangle , including subdivisions of the boundary , as long as the boundary data are chosen to be ` edge wise ' linear , i.e. [ 5a ] _ k = x_l _ l + x_m _ m .",
    "( note that the set of coordinates with @xmath7 describes the line through the edge opposite the vertex @xmath8 . )",
    "the boundary data we impose are the ones following from the dynamics , as these data are induced on the boundary by the solution ( [ 4 ] ) .",
    "we conclude from this discussion that edge wise or piece wise linear boundary fields seem to be dynamically preferred .",
    "a two  dimensional triangulation can be changed into any other topologically equivalent triangulations by just applying @xmath9 , @xmath10 and @xmath11 pachner moves . hence to obtain full triangulation independence for our discrete theory we would just need invariance under the 22 move , which changes the way how two triangles are glued into a quadrangle .",
    "however the action ( [ 1 ] ) is in general not invariant under the @xmath11 move ( as the actions before and after the move display couplings along the two different diagonals ) .",
    "additionally demanding invariance under the @xmath11 pachner move and insisting on simple building blocks will lead to a non  local action @xcite .",
    "we will therefore employ a different strategy , allowing for more and more complicated building blocks .",
    "the discussion is easier on a regular lattice , so we start with actions on squares ( which for simplicity we take to be also geometrical squares , i.e. equilateral ) .",
    "the justification for this choice is that our aim is to give a construction principle for discrete theories , such that the dynamics described does not depend on which choice of discretization or lattice one starts with , so we can choose a simple , regular lattice .",
    "hence we consider a lattice built out of squares .",
    "the action for one square can be obtained from the action for a triangular subdivision ( [ 1 ] ) . for a regular lattice",
    "we have ( the lattice constant drops out as the action is scale invariant ) [ 5 ] s= _ s_= _ _ i=1,  4 ( _ i-_i+1)^2 . where @xmath12 is a cyclic ordering of the vertices associated to the square @xmath13 , so addition of indices is to be understood mod @xmath14 .",
    "the coupling along the diagonal drops out as @xmath15 for @xmath16 orthogonal .    now lets subdivide the square into four smaller squares .",
    "we obtain eight boundary fields and the field on the inner vertex @xmath17 , with notation explained in figure [ square ] .",
    "the eight boundary fields are given by the four fields on the corners of the composite square , which we denote by @xmath18 , and the boundary fields on the inner vertices of the subdivided edges which we denoted by @xmath19 for the vertices between the corners @xmath8 and @xmath20 .",
    "we solve the equation of motion for the inner vertex and insert this solution into the action for the four squares , which yields hamilton s function depending on the eight boundary fields .",
    "now we have to compare this to the original action , which is just a function of the four boundary fields . here",
    "we use the crucial insight from the previous discussion , which showed that piecewise linear fields define a special class of boundary data .",
    "so we define a new action as the hamilton function , which we just computed , evaluated on piecewise linear boundary fields , that is we set @xmath21 for the fields on the midpoints of the edges .",
    "the resulting action [ 7 ] s_&=&(_1-_2)^2 + ( _ 2-_3)^2+(_3-_4)^2 + ( _ 4-_1)^2 -(_1-_2+_3-_4)^2 + & = & s_-(_1-_2+_3-_4)^2 , where @xmath22 for this first step , just differs by a total square from the initial action , introducing in particular couplings along the diagonal .     the boundary fields on a square . to find the fixed point action with eight boundary fields @xmath23 one would have to set i.e.",
    "@xmath24 as it encodes the deviation from a piecewise linear field .",
    "]    this process can be repeated inducing a flow which only affects the value of @xmath16 .",
    "the fixed point @xmath25 can be readily found .",
    "this fixed point action enjoys an invariance under subdivisions of a certain type under the condition that the additional boundary data that result are fixed as ( specific linear ) functions of the initial boundary data .",
    "later we will discuss in which sense this action already encodes the continuum dynamics for very special boundary data .",
    "moreover this fixed point is unique in the following sense . parameterizing all quadratic ( normalized ) actions for a massless scalar field on a square by [ 8a ] s_=_i=1,  ,4 ( _ i^2 + a _ i _",
    "i+1 - ( 1+a ) _ i _",
    "i+2 ) one will find that @xmath26 is the only fixed point .",
    "this fixed point action agrees with the previous fixed point modulo a global rescaling .",
    "next we are going to construct an action which has the same invariance holding for more complicated boundary data , i.e. where the boundary fields can have a kink at the midpoint of the edges .",
    "to each midpoint @xmath27 between the corners @xmath8 and @xmath28 we introduce the ` fluctuation field ' @xmath29 . as initial action",
    "we take hamilton s principal function for the complex contracted out of four squares , defined by taking the fixed point action ( [ 9 ] ) as the action for one square .",
    "so we just have to repeat the previous computation keeping the eight boundary fields general .",
    "the resulting action is given by [ 9 ] s_^4 & = & s^*_+ _ 1i4 ( _ i _ i , i+1 + _ i _ i , i-1 -_i_i+1,i+2 -_i_i-1,i-2 ) + + & & _ 1i4 ( a_1_i , i+1 ^ 2 + a_2 _ i , i+1_i+1,i+2+a_2 _",
    "i , i+1_i-1,i+a_3 _",
    "i , i+1_i+2,i+3 ) with coefficients @xmath30 , which flow under the coarse graining procedure : we glue four of such squares , solve for the fields on the ( now five ) inner vertices , and determine hamilton s principal function on the subset of boundary data , where eight of the sixteen boundary fields are fixed as suitable averages of the eight remaining fields , see figure [ square ] . we take hamilton s principal function evaluated on such data as the new action for the square .",
    "the fixed point values for the coefficients @xmath30 can be given as the roots of a higher order polynomial , the numerical values are given by [ 10 ] a_1 : 2.5833 2.2756 , a_2 : -1.5 - 1.2003 , a_3 : -0.1666 -0.3427 where we gave the values for the initial hamilton s principal function and the action/ hamilton principal function at the fixed point .",
    "one will notice that the zeroth order part  the part quadratic in the @xmath31 fields  does not change ( if one starts with the previously computed fixed point action ) , nor does the part coupling the @xmath31 and the @xmath32 fields . we want to emphasize that this is a special property of the dynamics and choice of coarse boundary data considered here .",
    "to appreciate this point assume that we would treat the action ( [ 9 ] ) in a perturbative expansion with small inhomogenities @xmath32 . to this end",
    "we introduce an expansion parameter @xmath33 so that the action has the form [ 10a ] s= m + n + ^2 k where @xmath34 denote the quadratic forms specifying the dynamics . for the solutions to the equation of motions we make the ansatz [ 10b ] = ^0+^1 , = ^0which have then to satisfy the equations of motion 0=m^0 + ( m^1 + n ^0 ) [ 10c ] , 0= ^0n + ^2 ( ^1n + k ^0 ) .",
    "we can see that a perturbative solution is only possible if @xmath35 for solutions of the equations @xmath36 .",
    "this is a consistency conditions involving both @xmath37  that is the definition of the dynamics at zeroth order  and @xmath38  that is the coupling between zeroth order and first order variables .",
    "similar consistency conditions occur for the discretization of systems with gauge symmetries in situations where these are broken by discretization , see the discussion in @xcite .",
    "if the consistency conditions are satisfied the zeroth order solution will not be affected by the higher order terms ( i.e. there are no backreaction effects ) .",
    "remarkably these conditions are satisfied for the action ( [ 9 ] ) and explain why only the quadratic part in @xmath32 changes .",
    "we will however see that the first order term will change ( slightly ) if we include the higher order fluctuations .",
    "we can introduce further fluctuation fields @xmath39 and @xmath40 which are associated to vertices subdividing the edges between @xmath41 and between @xmath42 respectively . as mentioned previously the first order part , which is quadratic in the @xmath32-fields now does change , indicating that the @xmath32 and @xmath43 variables are not decoupled .",
    "the full fixed point action is quite lengthy , therefore we will just give the shifted values for the fixed point values of the coefficients for the @xmath44 part [ 11b ] a_1 : 2.27562.2011 , a_2:-1.2003 - 1.1805 , a_3 : -0.3427 - 0.3562    note that in the action ( [ 9 ] ) all fields are coupled to each other , that is the theory is non ",
    "local if one considers couplings between fields associated to one building block .",
    "on the other hand we still built the full dynamics out of local actions and building blocks which are glued to each other locally , namely by identifying fields on shared boundaries between building blocks .",
    "there are no couplings between fields on building blocks which do not share boundary fields .",
    "such non  local couplings would however arise in a perfect action approach @xcite , where one keeps the building blocks elementary .",
    "this shift of non  locality can be understood as an example of the general method to avoid non - local couplings by introducing additional variables .",
    "it should now be clear how to iterate this procedure . in each iteration",
    "we will allow more and more general boundary data . in the continuum",
    "limit we can hope to obtain hamilton s principal function for the boundary of a square .",
    "this method is also suitable for non  linear theories , e.g. a massless scalar field with potential @xmath45 . here",
    "even the discretization on a triangle does not enjoy any more the invariance under subdivisions .",
    "also there are different possibilities to discretize the potential term , for example one could take the average of the potentials of the fields or the potential evaluated on the average of the fields associated to one building block .",
    "we will see that with our method we can find a preferred discretization .    for the action on the square we make the ansatz that the potential term is a general homogenous polynomial of fourth degree in the fields .",
    "the kinetic term is given by the fixed point action for the massless field ( [ 7 ] ) : [ 12 ] s_,&=&s_^ * + + & & a^2 _ i ( b_1 _ i^4 + b_2 _ i^3 _ i+1 + b_2 _ i^3_i-1+b_3 _ i^2_i+1 ^ 2 + b_4",
    "_ i^3_i+2 + b_5",
    "_ i^2_i+1_i+2 + + & & b_5 _ i^2_i-1_i-2 + b_6 _ i-1_i^2_i+1+b_7_i^2 _ i+2 ^ 2 + b_8 _",
    "i_i+1_i+2_i+3 ) where @xmath46 is the lattice constant , so that the potential term is weighted with the area of the square .",
    "we proceed in the same way as in the previous section , that is we determine hamilton s principal function on the subdivided square evaluated on special boundary data , which also here we take to be linear along the edges of the square .",
    "the only point one has to take care of is to replace @xmath47 for the action of the smaller squares in the composite square in each coarse graining step .",
    "the full non - linear solution for the field on the inner vertex is a non - polynomial function of the boundary fields and in @xmath48 . to simplify the calculation we can expand in @xmath48 and consider only the first order in @xmath48 , see section [ larger ] for the second order result .",
    "the first order calculation implements also a truncation of the flow to polynomial actions up to degree four . as the quadratic part is already invariant only the coefficients @xmath49 will be changed .",
    "the solution to the fixed point equations is given by [ 13 ] b_1=c , b_2=c , b_3=c , b_4=c , b_5=c , b_6= c , b_7=c , b_8= c where @xmath50 is a multiplicative constant that just rescales @xmath48 .",
    "( for the initial action ( [ 12 ] ) with @xmath51 we flow to @xmath52 . )",
    "we see that we can define in this way a preferred discretization of the potential term for a given lattice . in the next section",
    "we will discuss whether this discretization encodes already the continuum result for edge  wise linear boundary data .",
    "in this section we are going to discuss the dependence of the sequence of fixed point action on changing the coarse graining scheme , in particular by taking larger coarse graining steps .",
    "this is actually very much related to the issue we discussed in section [ scalar ] , namely whether the lower order results changes if we take higher order fluctuations ( more complicated boundary data ) into account .",
    "we consider the scalar field ( with @xmath45 potential ) on a square with initial action ( [ 5 ] ) and subdivide not only into four but into sixteen squares .",
    "again we put special boundary data .",
    "for the simplest case , we choose boundary fields which are linear along the edges of the bigger square . for the inclusion of the fluctuations @xmath32 we allow a kink ",
    "described by the @xmath32fields  at the middle of the edges .    in general the fixed point actions will change as compared to the case , where we consider only the blocking of four squares into one square .",
    "the zeroth order result , i.e. the part which is quadratic in the fields @xmath53 does not change  neither if we include fluctuations @xmath32 or @xmath43 into the boundary nor if we change the step size of the coarse graining procedure .",
    "it is instructive to understand why this happens .",
    "the reason is in the choice of coarse boundary data  as for the case of the triangle in section ( [ scalar ] ) the piecewise linear boundary data are induced by a continuum solution which we can naturally obtain by extending the solution for the inner vertices and is given by [ 14 ] ( x , y)= _ i ( 1-| x - x_i|)(1-| y - y_i| ) _ i . here",
    "@xmath54 are orthogonal coordinates on the larger square normalized such that the coordinate distance between neighbouring vertices of the larger square is equal to one .",
    "@xmath55 are coordinates of the vertex @xmath8 .",
    "this solution holds for the actions ( [ 7 ] ) with any value of @xmath16 and @xmath56 and for the subdivision into any number of smaller squares . indeed in the case that we have a larger square built out of more than four squares",
    "also the solution along the inner edges will be a linear function of some lengths parameter along this edge .",
    "this reproduction of our choice of coarse boundary data along the inner boundaries is responsible for the stability of the zeroth order result under inclusions of higher order fluctuations .",
    "it also means that we actually found a continuum result : the fixed point action @xmath57 coincides with the continuum hamilton s principal function evaluated on edge  wise linear boundary data",
    ".    the exact reproduction of our notion of coarse boundary data on the inner boundaries does not hold anymore if we include either the @xmath32 fluctuations or the potential term @xmath45 .",
    "for the latter note that the terms linear in @xmath48 , which we computed in section ( [ pot ] ) will again remain stable both under the inclusion of @xmath32 fields and under changing the blocking size from four to sixteen squares .",
    "the reason is that for the computation of hamilton s function to first order in @xmath48 one needs only the zeroth order ( in @xmath48 ) solution .",
    "therefore the change will only start with the second order of @xmath48 .",
    "we therefore computed the fixed point action for the scalar field with @xmath45 potential to second order in @xmath48 , which is equivalent to a truncation to six order polynomials in the fields .",
    "we can compare the results with and without inclusion of @xmath32 fluctuations into the boundary data , and with a blocking of four squares into one or with a blocking of sixteen squares into one .",
    "the final fixed point actions are very lengthy as for instance at second order all six degree polynomials in the eight boundary fields ( @xmath53 and @xmath58 ) will appear",
    ". we will therefore just give the coefficients for the @xmath59 terms in the action and the coefficient for the @xmath60 term for the various coarse graining schemes .",
    "for comparison in all cases the coefficient in front of @xmath61 is @xmath62 and the coefficient in front of @xmath63 is @xmath64 .",
    "@xmath65    as we can see from the @xmath66 coefficients ( and the other @xmath67 coefficients in the @xmath31 fields not displayed here ) the difference for the fixed point actions which include @xmath32boundary fields are smaller than for the cases without the @xmath32fields .",
    "note also that the fixed point action computed from the coarse graining with @xmath68 square but without including @xmath32 fields is different from the fixed point action computed in the @xmath69 scheme but with the inclusion of the @xmath32 fields .",
    "( compare also the @xmath70 coefficient computed with including the @xmath43 fields , equation ( [ 11b ] ) and in the @xmath68 scheme . )",
    "the difference between the fixed point actions in the @xmath69 and in the @xmath68 scheme involving the @xmath31 and @xmath32 fields is however smaller compared to the case where only the @xmath31 fields are included .",
    "one would expect to obtain the continuum hamilton s principal function if we consider larger and larger coarse graining steps .",
    "( this is just the requirement of having a discretization that gives the continuum result in the continuum limit . ) in such a set  up we would however need to solve in one step for all the bulk fields at once .    increasing the number of boundary fields instead of the blocking step size has the advantage that the computation proceeds step  wise .",
    "for example for the @xmath71 scheme one has to solve for nine @xmath72 fields on the inner vertices , whereas for the @xmath73 scheme and inclusion of @xmath32 fields we just have to solve for five fields . both schemes involve however the same number of boundary data ( prior to restricting the boundary data to special ` coarse ' values ) .",
    "the reason why the second scheme involves less inner fields , is that we are using already hamilton s function for the square with more boundary data , in which we already solved for the field on the inner vertex .",
    "this gives exactly the difference of the four fields , whose solutions we obtained in the previous computation .",
    "in general we have a quadratic growth ( in 2d ) in the number of fields to solve for in the scheme with larger and larger blocking steps as compared to a linear growth in the scheme with including more and more boundary data .",
    "to get an impression of the convergence rate of the lower order parts of the fixed point action under inclusion of more and more boundary data we consider a scalar field with mass in the @xmath69 blocking scheme and compute the fixed point action by taking only @xmath53 fields , @xmath53 and @xmath58 and finally @xmath74 fields into account .",
    "although we are just considering a quadratic action the full fixed point action will involve arbitrary high ( even ) powers of the mass . to make the computation feasible we truncate to @xmath75 , that is to second order in the perturbation parameter @xmath76 .",
    "( as for the @xmath48 terms the @xmath77 terms of the action will remain stable under inclusion of higher order fields . ) for comparison in all cases the coefficient in front of @xmath61 is @xmath62 and the coefficient in front of @xmath78 is @xmath79 .",
    "@xmath80    as expected the change in the coefficient of the @xmath81 term is decreasing , from an order of @xmath82 to an order of @xmath83 between the different truncations .",
    "thus we can hope on a convergence of the coefficients to some ( continuum ) value .",
    "in conclusion we have to expect ` back reaction ' contributions from the inclusion of more inhomogeneous boundary data onto the terms in the fixed point action involving more homogeneous fields .",
    "this applies even for the linear dynamics in the case that the corresponding field modes do not completely decouple , as is the case between the @xmath32 and @xmath43 fields .",
    "such back reaction effects could be avoided by changing to decoupled modes , i.e. for a translation invariant boundary the fourier modes . in this case",
    "the higher ( order ) modes will not appear at all in the solution for the bulk fields  as long as these modes are set to zero in the boundary data .",
    "hence the boundary data reproduce itself on the inner boundaries , as discussed above .",
    "of course the construction of decoupled modes will only be possible for free theories . for interacting theories we might be able to identify modes , that is a decomposition of boundary fields , which only couple weakly with each other .",
    "the ( coarse ) boundary data will only be approximately reproduced on inner boundaries , but we can expect a fast convergence of the terms involving only lower order modes under inclusion of higher ( order ) modes into the boundary data .",
    "the advantage of the scheme proposed here is that one can determine the size of the corrections at least from one order to the next order , so that one can judge the reliability of the approximation scheme .",
    "here we will discuss a coarse graining scheme with a different choice of coarser boundary data .",
    "this choice follows more closely the usual understanding of coarse graining , e.g. fields in a region are averaged to a new field , constant on the region averaged over .",
    "hence we replace for the coarser boundary data ` piecewise linear ' fields with ` piecewise constant ' fields . for this",
    "we have also to change the geometrical set - up , as the fields will be now associated to the ( midpoints of the ) edges .",
    "such a set  up corresponds more closely to a tensor network renormalization approach , see @xcite and figure [ sqtnw ] .    the tensor network scheme for the coarse graining of a scalar field .",
    "the original square is rotated by @xmath84 , so that now the boundary fields can be associated to the edges of an unrotated square .",
    "the gluing of these new squares corresponds to combining tensors of rank four .",
    "the corresponding tensor network is indicated by blue lines .",
    "bulk fields @xmath85 are now associated to the inner edges of this tensor network .",
    "coarser boundary data correspond to piece wise constant fields . in the figure on the right we depicted the set  up for coarse graining with eight boundary fields",
    " fields on pairs of outer legs are set to be equal . ]",
    "coarser boundary data are now obtained by setting fields on a subdivided boundary edge to be equal .",
    "there is one subtlety one has to take care of : to find a fixed point one has to introduce a scale @xmath86 between the new average boundary fields and the to be averaged finer boundary fields , i.e. @xmath87 for the case that the boundary fields agree on pairs of boundary edges @xmath88 . to find the fixed point action , one has to normalize one of the coefficients in the action after each renormalization step to one . at the fixed point",
    "one can then determine the scaling @xmath86 by finding the normalization constant .",
    "this scale has to be properly taken into account if a potential term is added : as we can interpret @xmath86 as a length scale , fields carry the dimensions of inverse lengths .",
    "hence if we have to multiply the terms @xmath89 with @xmath90 , we should multiply terms @xmath91 with @xmath92 whereas terms @xmath93 are dimensionless and will not be rescaled .    we determined the fixed point action for the scalar field with mass , in a scheme where four squares are blocked into one square .",
    "we computed the fixed point action for three different set of boundary data : starting with four boundary fields @xmath94 which we interpret as edge  wise constant fields , to a set @xmath95 of eight boundary fields which we can interpret as piecewise constant fields along the edges , and finally a set @xmath96 of sixteen boundary fields .",
    "we will just display the coefficients for these three cases after restricting the boundary values to the simplest case , i.e. setting @xmath97 in the fixed point action .",
    "the resulting actions have to be normalized again in the way described in the previous paragraph , so that the actions can be compared with each other .",
    "the initial action is given by [ f1 ] s_=_i ( _ i^2 -_i_i+1+a^2m^2_i^2 ) . in the following table we will display the results for the three different sets of boundary fields with the notation [ f2 ] s_=_i ( _ i^2 + b_1 _ i_i+1 + b_2 _ i_i+2 & + & a^2m^2 ( c_1 _ i^2 + c_2_i_i+1 + c_3 _",
    "i_i+2 ) + & + & a^4m^4 ( d_1 _ i^2 + d_2_i_i+1 + d_3 _",
    "i_i+2 ) ) . because of the rescaling procedure the coefficient of the term @xmath61 will be always one , furthermore we will have @xmath98 which ensures that the massless part vanishes , if evaluated on a constant boundary field .",
    "@xmath99    from table ( [ tab3 ] ) we can see that we do not have stability of the coefficients at zeroth order , as was the case for the scheme with piecewise linear boundary fields .",
    "we explained in section [ larger ] that this can not be expected as piecewise constant fields do not appear as solutions on the inner edges .",
    "the coefficients for the kinetic part of the action and the ones in front of the @xmath76 terms do converge , although slower than in the scheme with piecewise linear boundary fields . moreover the coefficients in front of the @xmath75 terms show an unstable behaviour . in summary",
    "the scheme with piecewise linear fields seems to be better suited for the dynamics of a scalar field ( perturbed around the massless case ) .    in general",
    "we have to choose carefully a notion of coarse boundary data , which will underly the coarse graining scheme .",
    "this notion should be adjusted to the dynamics  ideally one should capture the relevant degrees of freedom .    another possibility to determine a notion of coarse boundary data is to follow the tensor network renormalization algorithm , where the truncation to coarse boundary data is entirely determined by the dynamics .",
    "this procedure was however developed not for classical theories but for quantum ones ( with discrete configurations , like ising spin systems ) , in which the partition function is rewritten as a contraction of a tensor network .",
    "contracting just four tensors @xmath100 to a new tensor @xmath101 , this tensor will have the double number of indices , which correspond to the double number of boundary data in each coarse graining step in our case .",
    "thus one has to truncate the tensor down to its original size as otherwise the number of indices grows exponentially with the number of iterations .",
    "this truncation is motivated by finding the most relevant modes in the tensor @xmath100 that contribute mostly to the partition function .",
    "the general problem in identifying these modes is that there is no canonical definition of eigenvalue decomposition for tensors , as there is for matrices .",
    "thus a procedure has been designed that introduces auxiliary matrices that allow for an eigenvalue decomposition @xcite . in general , the identification of the ` most relevant ' modes leads to field redefinitions , that may also depend on the renormalization step .",
    "the modes , identified as relevant , are included in the next iteration step , whereas the irrelevant ones are discarded .",
    "as the entire procedure is not so much motivated by finding the boundary wave function ( see however the discussion in @xcite ) for given boundary data , one usually does not keep track of these field redefinitions .",
    "this could however be done in principle .",
    "the information gained in this way could be used to identify a notion of coarse boundary data that is adjusted to the dynamics and therefore might also change during the iteration procedure .",
    "the resulting notion will of course depend on the truncation scheme for the tensors . on the other hand",
    "if one has reason to believe that a given notion of coarsening captures the relevant degrees of freedom , this notion can be used to define a truncation scheme for the tensor network algorithm .",
    "section [ quantum ] will discuss a possibility to extend our classical scheme to quantum mechanics , and we will see that identifying a proper notion of coarse boundary data becomes even more essential .",
    "in the discussion so far a choice of coarse boundary data was essential .",
    "we can formalize this notion using the concept of cylindrical consistency .",
    "this is a key idea in loop quantum gravity @xcite , which allows the construction of a hilbert space encoding the continuum configurations through an inductive limit of a family of hilbert spaces that are associated to ( finite ) graphs .",
    "there is a natural ( partial ) ordering of graphs into coarser or finer graphs .",
    "cylindrical consistency implements the requirement that a computation ( of expectation values , transition amplitudes etc . ) for a given state should not depend on whether this computation is performed in a hilbert space associated to a coarser or finer graph , as long as both graphs are fine enough to describe the given state .",
    "following this idea we introduce a ( partial order ) directed set structure on the set @xmath102 of boundaries @xmath103 , where @xmath104 , if @xmath105 is a refinement of @xmath103 . to every boundary we associate a configuration space @xmath106 , which typically is a direct product of some basic configuration space @xmath107 .",
    "the notion of coarse boundary data will be encoded in the choice of a family of embedding maps . for every pair @xmath104",
    "we define an injection [ 01b ] _ bb:c_b_b . where the image of @xmath108 determines the ` coarse boundary data ' in the configuration space @xmath109 .",
    "this family of injections needs to be consistent in the sense that for @xmath110 we should have [ 02b ] _ bb=_bb_bb .",
    "such a consistent family allows the construction of an inductive limit [ 02bb ] c_=_b c_b/~ , which consists of equivalence classes of elements in a disjoint union of configuration spaces @xmath106 over all boundaries @xmath111 .",
    "two elements @xmath112 and @xmath113 are equivalent if there exist a @xmath114 with @xmath115 and @xmath116 and @xmath117 holds . in other words",
    "two configurations defined on two different boundaries are equivalent if there is a finer boundary onto which the two configurations can be embedded and if these embeddings happen to agree .",
    "a family of functions @xmath118 is cylindrically consistent on the inductive family defined by @xmath119 , if [ 03a ] f_b=^*_bbf_b , f_b(c)=f_b ( _ bb(c ) ) c_b where @xmath120 is the pullback of @xmath108 .",
    "this just implements that the value of the function @xmath121 should not depend on the representative on which one chooses to evaluate .",
    "the procedure proposed in this work attempts to construct hamilton s principal function as a cylindrically consistent object : assume that we do have the continuum hamilton s function at our disposal . in the language we are using here , the continuum is given by the refinement limit of the boundaries @xmath103 , that is on a heuristic level we can imagine the continuum as an element @xmath50 for which @xmath122 for all finite boundaries in @xmath102 .",
    "now we can pull  back the continuum hamilton s function to any coarser boundary and the family of function so obtained will be cylindrically consistent . to be more precise the continuum limit of a function",
    "is actually defined through the condition of having a cylindrically consistent family of functions .",
    "we compute this continuum limit iteratively starting from an action @xmath123 ( identified with hamilton s principal function ) on some given boundary @xmath103 .",
    "this is used to compute hamilton s principal function on some finer boundary @xmath105 , we will denote the result by @xmath124 .",
    "for the fixed point action @xmath125 we demand that [ 03b ] ^*_bbs_b^b = s^*_b .",
    "if the fixed point action @xmath125 in ( [ 03b ] ) does not depend on the choice of finer boundary @xmath105 , then it is the @xmath103component of the cylindrically consistent family of hamilton s principal functions we are looking for : in the limit that @xmath105 approaches the continuum we converge to the continuum hamilton s principal function and the pull back to the coarser boundary @xmath103 defines the @xmath103component of the corresponding cylindrically consistent family of functions .",
    "we have seen that in the case of the massless free scalar field and for the zeroth order coefficient such an independence holds , but that in general one can only hope for approximate ( or a convergence ) of results . here",
    "the choice of the finer boundary @xmath105 determines the order of the approximation for the @xmath103component of the cylindrical consistent family of hamilton s functions .    we should remark that ( [ 03b ] )",
    "is to be understood for systems without an explicit scale , such as the massless scalar field .",
    "note that gravity , where the metric is a dynamical variable , is in this sense also without a scale ( if one does not expand on a background ) @xcite .",
    "this also holds for parametrized systems , where embedding coordinates are added as dynamical variables @xcite . in all these cases",
    "a notion of scale can be replaced by the notion of coarser and finer boundary data .    in the case of scale",
    "dependent actions , which we denote by @xmath126 , for example the scalar field with potential , we have to replace ( [ 03b ] ) by [ 04b ] ^*_bbs_b,la^b , a = s^*_b , la where the lattice constant in @xmath105 is @xmath127 and @xmath128 is hamilton s principal function computed from the action @xmath126 .",
    "even more generally the embeddings @xmath120 could also depend on the two scales involved .    in the previous scalar field examples , based on piecewise linear fields",
    ", the basic configuration space is associated to a vertex and given by @xmath129 .",
    "the configuration space for a boundary with @xmath38 vertices is given by @xmath130 .",
    "we considered the set of boundaries of a square with a given number of repeated subdivisions of the edges into two halves .",
    "@xmath105 is a refinement of @xmath103 if @xmath105 can be obtained from @xmath103 by such a subdivision .",
    "let us consider the case that @xmath105 is obtained from @xmath103 by one subdivision .",
    "we label the vertices in @xmath103 by indices @xmath8 ( cyclically ordered ) and the additional vertices in @xmath105 , which are between @xmath8 and @xmath28 ( mod the number of vertices in @xmath103 ) by @xmath27 .",
    "the injection map is then given by defining the fields on the additional vertices as average of the neighbouring vertices , i.e. [ 02 ] _",
    ")=(_1,(_1+_2),_2,(_2+_3),_3 ,  ) .",
    "iterating this procedure one obtains a directed set of boundaries and can define the inductive limit of configuration spaces .",
    "as mentioned in the previous section the notion of cylindrical consistency is crucial in the loop quantization of gravity .",
    "we therefore remark that the notion of cylindrical consistency for hamilton s principal function translates into the notion of a cylindrical consistent ( path integral ) measure in the quantum theory , a notion proposed in @xcite .",
    "such a cylindrical consistent measure would allow to make the path integral well defined @xcite . here",
    "we will only sketch the idea and point out one of the main issues one would have to address even in the case of free theories .",
    "hamilton s principal function associated to a region with a boundary is the classical analogue to the path integral over this region .",
    "the result of this path integral as a function of the boundary data is the ( generalized ) boundary wave function @xcite .",
    "note that  given a prescription for the path integral this boundary wave function is the unique _ physical _ state associated to this region .    for the following it",
    "is useful if we take a dual point on the path integral and rather see it as an ( anti  linear ) functional on the ( kinematical ) boundary hilbert space .",
    "that is we assume that we can associate to every boundary of a region a kinematical boundary hilbert space @xmath131 , that encodes all states that can in principle occur kinematically . a well defined quantum theory",
    "should then associate an amplitude map to every region , that is it defines a map on every boundary hilbert space : [ q1 ] p_bound : h_bound .",
    "as we map to @xmath132 the co  kernel of this map is one  dimensional , defining the physical wave function , which we mentioned before .",
    "the maps @xmath133 for unions of regions have to satisfy consistency conditions which are generalizations of the usual composition rule for the path integral @xcite .",
    "classically these consistency conditions correspond to the additivity of the action ( or the composition rule for hamilton s principal function ) .",
    "these considerations also hold for the case that we replace space time with a lattice or more general discretization . in this case",
    "the boundaries are discrete boundaries @xmath103 to which we associate hilbert spaces @xmath134 . as for the classical case we have to choose injection maps @xmath108 that embed the hilbert space @xmath134 into @xmath135 .",
    "such injections can be naturally constructed if we have projections @xmath136 on the configuration spaces at our disposal : assuming a polarization in which the quantum states are functions on the configuration space we can use the pullback of the projections to define injections : [ q2 ] _ bb:&&h_b_b + & & _ b_b _ b(c_b)=_b(_bb(c_b ) ) .",
    "the reader will note that in the classical case we also used injections instead of projections . in the case we discussed here",
    "we can however obtain projections by ` forgetting ' the fluctuation variables .",
    "i.e. in the case that coarse graining was based on piecewise linear fields and for a refinement which doubled the number of fields , @xmath137 to @xmath138 , we perform a variable transformation @xmath139 and define the projection as [ q3 ] _ bb(_1,_12,_2, ",
    ")=(_1,_2 ,  ) .",
    "such a projection satisfies @xmath140 where here the @xmath141 is the classical embedding map for the configuration spaces .",
    "such inductions which are based on projections are also used for the construction of the hilbert space in loop quantum gravity @xcite , see also @xcite .    a measure ( which here will be just understood as linear functional ) on a family of inductive hilbert spaces",
    "can be defined by providing a representation on each of the hilbert spaces @xmath134 .",
    "such a family of measures @xmath142 is cylindrically consistent if [ q4 ] _",
    "b(_b)=_b(_bb(_b ) ) . the ashtekar ",
    "lewandowki measure @xcite for the kinematical hilbert spaces in loop quantum gravity satisfies such consistency relations .",
    "one way to define the dynamics ( and the physical inner product ) would be via the path integrals acting as functionals on these kinematical hilbert spaces as in ( [ q1 ] ) .",
    "cylindrical consistent dynamics would then mean to have a cylindrical consistent family of ( anti  linear ) maps [ q5 ] p_b : h_b .",
    "as an example we can again consider the massless free scalar field . the kinematical hilbert space associated to the boundary with @xmath38 vertices will be @xmath143 , here we will have the case @xmath144 and @xmath145 .",
    "we define the path integral map for the boundary @xmath103 of the basic square as [ q6 ] p_b(_b)&=&_i=1,  ,4 d_i e^is_b(_i ) ( _ i ) where @xmath146 is a normalization factor .",
    "the path integral map for a refinement @xmath105 that subdivides a square into four would be given by [ q7 ] p_b(_b)&=&d_0_i=1 ,  , 4 d_i d_i , i+1 e^is_b(_i , _",
    "i , i+1,_0 ) ( _ i,_i , i+1 ) where @xmath17 is the scalar field on the inner vertex .",
    "@xmath147 are the variables introduced in ( [ q3 ] ) and @xmath148 is here the action for four squares obtained by summing the basic action @xmath123 over the four squares .",
    "if we define the injections @xmath108 as pullback of the projections ( [ q3 ] ) we obtain for the pullback of the path integral map from @xmath105 to @xmath103 [ q8 ] ( _ bb)^*p_b ( _ b)=p_b(_bb(_b))=d_0_i=1 ,  , 4 d_i d_i , i+1 e^is_b(_i , _",
    "i , i+1,_0 ) ( _ i ) . for cylindrical consistency of the path integral maps defined in this way we would need [ q8b ] _ i=1, ",
    ",4 d_i e^is_b(_i ) ( _ i ) = d_0_i=1 ,  , 4 d_i d_i , i+1 e^is_b(_i , _",
    "i , i+1,_0 ) _",
    "b(_i ) for a suitable class of test states @xmath149 . as we are considering free field theory the integral over the @xmath32 fields and",
    "@xmath17 is a ( analytically continued ) gaussian integration . indeed , as pre  factors arising from these integrations can be absorbed into the normalizations @xmath150 we can just consider the extremization of @xmath148 with respect to @xmath17 and then with respect to the fields @xmath147 .",
    "compared to the classical coarse graining procedure we therefore do not set the @xmath151 but have to find the extrema of hamilton s principal function @xmath152 with respect to these variables @xmath32 .",
    "we then obtain a new action , by evaluating hamilton s function on these extrema .",
    "this new action will depend just on the four fields @xmath53 and we can repeat the procedure and in this way obtain a renormalization flow of actions .",
    "the resulting flow does however not converge to a fixed point .",
    "rather a rescaling fixed point is reached , in which the action is rescaled by a given number ( smaller than one ) .",
    "indeed compared to the classical case we do not fix the boundary values of @xmath32 , but do minimize further the action with respect to these variables .",
    "the values of the boundary fields @xmath32 obtained in this way are however not reproduced , if we put the resulting squares again together , so that we have now a variation of the fields @xmath32 in the bulk .",
    "this is different from the classical case , where the boundary values @xmath153 are reproduced in a larger square . indeed",
    "if we include in this procedure higher order fields the ( rescaling ) fixed point , which differs from the classical one , will change towards the location of the classical fixed point .",
    "although one could deal with such a rescaling fixed point , the issue seems rather that we do not reproduce the classical result in the semi  classical limit .",
    "the key point responsible is the choice of embedding map , which also describes the choice of boundary conditions ( for the vertices carrying @xmath32 fields ) imposed on the quantum mechanical wave function , which we are trying to find .",
    "this point constituted also the main motivation for the introduction of the density matrix renormalization group procedure @xcite : find the ground state of a given hamiltonian in a given block with some fixed boundary conditions ( for instance that the wave function vanishes on the boundary ) .",
    "putting the blocks together and finding the ground state again for the larger block it might happen that the wave function evaluated on the now inner boundaries differs very much from the values prescribed by the conditions on the smaller blocks . even for",
    "the free particle in one dimension one will find a ground state wave function that vanishes on the ends of the smaller intervals , versus a maximum of the ground state wave function assumed on the midpoint of the doubled interval .",
    "this issue is solved by a kind of bootstrap approach  also the appropriate boundary conditions have to be constructed by considering not only the block itself but the block inside an environment ( built from the same block ) .    for our case ( of a free field ) we can attempt to reproduce the classical coarse graining by choosing an appropriate embedding map .",
    "in this case we have to pre  guess the correct vacuum for the finer degrees of freedom .",
    "we can choose the embedding as [ q9 ] _",
    "the condition ( [ q8b ] ) turns into [ q10 ] _ i=1,  ,4 d_i e^is_b(_i ) ( _ i ) = d_0_i=1 ,  , 4 d_i d_i , i+1 e^is_b(_i , _",
    "i , i+1,_0)-it ( , ) _",
    "+ we can fix @xmath100 such that the term @xmath154 exactly cancels the @xmath32 dependence in the action @xmath148 .",
    "if @xmath123 is the ( classical ) fixed point action , we reproduce also cylindrical consistency in the quantum case .",
    "( this will lead to a divergence in the integral over @xmath32 . in the case of loop quantum gravity",
    "the corresponding integration is over a compact space . also here we could ( bohr ) compactify @xmath129 , equivalent with a regularization of the integral to a finite interval @xmath155 $ ] and a normalization by @xmath156 , letting then @xmath157 . )",
    "we can interpret the choice of embedding ( [ q9 ] ) as selecting the correct vacuum for the finer degrees of freedom @xmath32 .",
    "only test states @xmath158 which have already the correct semi - classical behaviour with respect to the @xmath32 degrees of freedom , are propagated in the same way on the finer boundary , as the states @xmath149 on the coarser boundary .    in conclusion",
    "the choice of embedding seems to be even more essential in the quantum case . for the construction of these embedding maps methods from the density matrix renormalization group or tensor network based renormalization @xcite , which can be seen as a descendent of the density matrix renormalization group procedure , could be helpful .",
    "we would not have encountered problems with ( [ q8b ] ) , if the finer and coarser degrees of freedom where completely decoupled .",
    "achieving such a decoupling is one of the motivations behind the approach of entanglement renormalization @xcite .",
    "the tensor networks can in this case be understood as parametrizing an ansatz for a physical wave function .",
    "here we started with an embedding map inspired from loop quantum gravity , which we argued is not an appropriate one for coarse graining the free scalar field ( on a flat background ) .",
    "this does not mean that the loop quantum gravity embedding map might not be useful for coarse graining  as we argued the embedding should depend on the system and the dynamics it describes .",
    "indeed there are uniqueness results available for the loop quantum gravity embedding , and the vacuum underlying this embedding @xcite , which are based on the requirement of a ( spatially diffeomorphism symmetry covariant ) irreducible representation of the kinematical observable algebra and a ( spatially ) diffeomorphism invariant vacuum . on the other hand , it is not guaranteed that this embedding will allow for the construction of a cylindrically consistent measure encoding the dynamics via a path integral , in the way we outlined here , i.e. via a coarse graining procedure .",
    "as we have seen in the scalar field example we might need already some information on the physical vacuum for the finer degrees of freedom .",
    "the question is whether we can encode this physical vacuum into an inductive limit structure for the physical hilbert space",
    ". the crucial question will be whether such a structure exists and how it relates to the inductive limit structure of the kinematical hilbert space .",
    "note also that alternatives for the kinematical hilbert space have been explored @xcite .",
    "we proposed a coarse graining scheme , in which the central object is hamilton s principal function for the classical case and the physical wave function for the quantum case .",
    "both can be taken to define an improved or perfect discretization @xcite : hamilton s principal function can be used as the action associated to a building block with the corresponding boundary and the physical wave function can be used as the path integral amplitude for this building block .",
    "the main properties for this coarse graining scheme are :    * following the tensor network renormalization @xcite , instead of introducing non  local couplings between building blocks we introduce building blocks with more and more boundary data .",
    "the non  localities are shifted to occur in - between the boundary data associated to one building block .",
    "an advantage of this scheme is that using these building blocks to define a discretization the amount of non  locality ( i.e. the maximal lattice distance at which fields are coupled ) can be chosen .",
    "this choice also determines the truncation of the renormalization flow , as couplings over larger lattice distances are neglected . *",
    "the quality of this truncation can be tested by considering the higher order corrections .",
    "the approximations to hamilton s function for a given boundary @xmath103 are specified by finer boundaries @xmath105 , see formula ( [ 03b ] ) .",
    "such an approximation can be understood as an effective action which takes the corrections into account , that arise from the additional degrees of freedom in @xmath105 as compared to @xmath103 .",
    "taking the refinement limit of @xmath105 one obtains the continuum limit of hamilton s function for boundary data described by @xmath103 . *",
    "crucial for the coarse graining scheme is the choice of coarse boundary data encoded into a family of embedding maps .",
    "these embedding maps provide also an interpretation of discrete boundary data as configurations in a continuum theory .",
    "the embedding maps have to be adjusted to the dynamics , ideally the notion of coarse boundary data should be reproduced by the dynamics of the system .",
    "equivalently the choice of coarse boundary data should correspond to an ordering of the variables into finer and coarser degrees of freedom which are dynamically only weakly coupled . *",
    "the scheme proposed here seems to be especially suited for systems without an explicit ( lattice ) scale , which includes gravity systems @xcite . here",
    "a notion of scale can be replaced by a notion of coarser and finer boundary data .",
    "a certain truncation might give reliable result for boundary data up to a given complexity .",
    "there are many open issues left to be understood , in particular for the quantum theory case .",
    "the main point is how to select best the embedding maps . here",
    "methods developed in condensed matter and quantum information theory @xcite will be helpful .",
    "one question to address will be in which situations it is appropriate to determine the truncation scheme ( or embedding maps ) completely by the dynamics , as is done in @xcite or whether some predefined embedding might be sufficient .",
    "for the investigation of phase transition one would rather expect to need truncations that are determined by the dynamics .",
    "the second possibility might arise if we aim at determining a perfect discretization of a system in a well defined phase .",
    "this will be investigated for simplified models @xcite in @xcite .",
    "for instance the ashtekar ",
    "lewandowski measure ( and the embedding maps and kinematical vacuum on which this measure is based ) , used in loop quantum gravity , corresponds to the high temperature fixed point of lattice gauge theory @xcite . here",
    "an interesting question is whether we could construct a hilbert space and measure corresponding to the low temperature fixed point of lattice gauge theory , which is actually given by a topological theory , namely @xmath159theory , see for instance @xcite .",
    "@xmath159 theory underlies spin foam quantization , hence it would be natural to consider a coarse graining procedure with corresponding embedding maps . in this case",
    "the ( kinematical ) vacuum state should correspond to a physical state of @xmath159 theory , which in ( 2 + 1 ) d even coincides with the physical state of gravity . as shown in @xcite",
    "the construction of this physical state can be obtained starting from the usual loop quantum gravity hilbert space .",
    "hence we see that it is actually possible to obtain a physical vacuum , starting from a kinematical hilbert space , which is based on embeddings which rather encode a kinematical vacuum describing a very different phase .",
    "the question is however , which are the appropriate embedding maps to choose for the coarse graining procedure proposed here .",
    "for other lqg related hilbert spaces , based on condensate vacua , describing non  degenerate geometries , see @xcite .    another important question to address",
    "is whether one can estimate and obtain a bound for the ` back reaction ' effects , i.e. the change of the lower order results , obtained for very coarse boundary data , if finer and finer boundary data are included .",
    "this would already entail the existence of such a continuum limit , which in itself is a highly non ",
    "trivial question , in particular if it comes to the quantum theory .",
    "the advantage of the scheme here is that it provides a systematic way to improve the truncation in steps , and that the higher order corrections can be checked explicitly .",
    "let us mention some possible applications of this scheme .",
    "the main motivation is the construction of perfect discretizations for ( quantum ) gravity models .",
    "perfect discretizations have been proposed for gravity @xcite in order to avoid the breaking of diffeomorphism symmetry for generic discretizations @xcite .",
    "the notion of diffeomorphism symmetry for discretizations @xcite is a very powerful one as it implies discretization ( or triangulation ) independence @xcite . in the scheme proposed here the requirement of discretization or triangulation independence",
    "is imposed by computing fixed point actions at every step .",
    "we can then hope to obtain triangulation independence up to a given measure of fineness of the boundary data . in its simplest form",
    "this is already realized for ( classical ) regge gravity @xcite , namely for boundary data that lead to flat @xcite or constantly curved solutions @xcite ( for gravity with a cosmological constant ) .",
    "correspondingly a natural choice of an embedding map would be to implement piecewise flat or piecewise constantly curved geometries as coarser boundary configurations , see also @xcite .",
    "more generally the methods proposed here could be used to define improved discretizations for partial differential equations , if these can be derived from an action principle .",
    "the use of renormalization methods to obtain improved discretizations has been proposed for instance in @xcite , in particular in @xcite there are also embedding ( and projection ) maps used .",
    "the difference with the scheme here is the utilization of the action principle , the emphasis on interpreting discrete boundary data as elements in finer configuration spaces , as well as the possibility to improve the discretization in steps and to control the amount of non  local couplings .",
    "a particular problem for discretizations , related to the breaking of diffeomorphism symmetry is the loss of energy momentum conservation , see for instance @xcite .",
    "perfect discretizations would avoid such a breaking as these are defined to display continuum physics .",
    "this problem can be studied in parametrized field theory , where diffeomorphism symmetry is added through the introduction of embedding variables @xcite .",
    "the problem of energy conservation translates then into the problem of broken diffeomorphisms and in the canonical set  up to an anomalous constraint algebra . with the methods proposed here we can hope to obtain a discretization that is perfect for a certain class of boundary data and for which anomalies in the constraint algebra can be avoided . on a general method to obtain a discrete canonical formalism with the same ( diffeomorphism ) symmetries as the covariant one , see @xcite , in particular @xcite is applicable to boundaries with varying number of variables , which are also occurring here .",
    "of course we hope that the scheme proposed here can also be applied to quantum gravity models , in particular spin foams @xcite .",
    "although spin foams , being seen as a quantum version of regge calculus have been originally defined on simplicial lattices only , recently models on arbitrary lattices ( two  complexes ) have been constructed @xcite .",
    "these also provide an example of ` more complicated ' ( non  simplicial ) building blocks , which allow the allocation of finer and finer boundary data .",
    "we propose here that the amplitudes for such building blocks can be constructed through a coarse graining process as outlined in this work .",
    "see also @xcite for a formulation of spin foams as tensor networks and a coarse graining procedure for simplified models .",
    "there are also formulations available which define spin foams as generalized lattice gauge theories @xcite , which again can be extended to any two  complex .",
    "these formulations might allow to systematically investigate which notion of coarse boundary data , or embedding maps , will lead to interesting results . in particular @xcite",
    "provide a range of simplified models for which this question can be more easily explored .",
    "the standard lqg embedding provides a well defined choice and is strongly motivated by ( spatial ) diffeomorphism symmetry . as outlined in @xcite , at least on the classical level",
    "there are different interpretations possible of how the discrete data are to be understood in a continuum phase space .",
    "we suggest here that an embedding of discrete data into a continuum configuration or hilbert space should be determined by the dynamics .",
    "such an embedding would be rather associated to a physical vacuum and a physical hilbert space  as we indicated in section [ quantum ] it would encode information on the vacuum wave function for the finer degrees of freedom .    finally , we would like to mention that the notion of coarse and finer boundary degrees of freedom can be brought together with symmetry reduction and applications in ( quantum ) cosmology .",
    "very coarse states would correspond to homogeneous configurations , finer states would describe inhomogenities . indeed in the context of loop quantum cosmology @xcite there are different suggestions how",
    "the kinematics and dynamics can be obtained from the full theory @xcite and how to include corrections from inhomogenities , with @xcite discussing ( cylindrical ) consistency conditions for the truncation of a given theory to homogeneous degrees of freedom .",
    "i am very much indebted to benjamin bahr for many discussions , comments on the draft and suggesting the notion of cylindrical consistency for the coarse graining scheme .",
    "i furthermore thank jan ambjrn , laurent freidel , frank hellmann , carlo rovelli , lee smolin and sebastian steinhaus for discussions .",
    "research at perimeter institute is supported by the government of canada through industry canada and by the province of ontario through the ministry of research and innovation .",
    "b.  bahr , r.  gambini and j.  pullin , `` discretisations , constraints and diffeomorphisms in quantum gravity , '' sigma * 8 * ( 2012 ) 002 [ arxiv:1111.1879 [ gr - qc ] ] .",
    "+ m.  dupuis , j.  p.  ryan and s.  speziale , `` discrete gravity models and loop quantum gravity : a short review , '' arxiv:1204.5394 [ gr - qc ]",
    ".        t.  regge , `` general relativity without coordinates , '' nuovo cim .",
    "* 19 * ( 1961 ) 558 .",
    "+ t.  regge and r.  m.  williams , `` discrete structures in gravity , '' j.  math .",
    "* 41 * ( 2000 ) 3964 [ arxiv : gr - qc/0012035 ] .",
    "a.  ashtekar and c.  j.  isham , `` representations of the holonomy algebras of gravity and nonabelian gauge theories , '' class .",
    "* 9 * ( 1992 ) 1433 [ hep - th/9202053 ] .",
    "a.  ashtekar and j.  lewandowski , `` representation theory of analytic holonomy c * algebras , '' gr - qc/9311010 .",
    "a.  ashtekar and j.  lewandowski , `` projective techniques and functional integration for gauge theories , '' j.  math .",
    "* 36 * ( 1995 ) 2170 [ gr - qc/9411046 ] .",
    "a.  ashtekar and j.  lewandowski , `` differential geometry on the space of connections via graphs and projective limits , '' j.  geom .",
    "* 17 * ( 1995 ) 191 [ hep - th/9412073 ] .",
    "t.  thiemann , `` anomaly - free formulation of non - perturbative , four - dimensional lorentzian quantum gravity , '' phys .",
    "b * 380 * ( 1996 ) 257 [ arxiv : gr - qc/9606088 ] .",
    "`` quantum spin dynamics ( qsd ) , '' class .  quant .",
    "grav .   * 15 * ( 1998 ) 839 [ arxiv : gr - qc/9606089 ] .",
    "j.  a.  zapata , `` loop quantization from a lattice gauge theory perspective , '' class .",
    "* 21 * ( 2004 ) l115 [ gr - qc/0401109 ] .",
    "e.  manrique , r.  oeckl , a.  weber and j.  a.  zapata , `` loop quantization as a continuum limit , '' class .",
    "* 23 * ( 2006 ) 3393 [ hep - th/0511222 ] .",
    "j.  martinez , c.  meneses and j.  a.  zapata , `` geometry of c - flat connections , coarse graining and the continuum limit , '' j.  math .",
    "* 46 * ( 2005 ) 102301 [ hep - th/0507039 ] . c.  rovelli ,",
    "`` on the structure of a background independent quantum theory : hamilton function , transition amplitudes , classical limit and continuous limit , '' arxiv:1108.0832 [ gr - qc ] .",
    "p.  hasenfratz and f.  niedermayer , `` perfect lattice action for asymptotically free theories , '' nucl .",
    "b * 414 * ( 1994 ) 785 [ arxiv : hep - lat/9308004 ] .",
    "+ p.  hasenfratz , `` prospects for perfect actions , '' nucl .",
    "* 63 * ( 1998 ) 53 [ arxiv : hep - lat/9709110 ] . k.  giesel and t.  thiemann , `` algebraic quantum gravity ( aqg ) . i. conceptual setup , '' class .",
    "* 24 * ( 2007 ) 2465 [ gr - qc/0607099 ] .",
    "b.  bahr and b.  dittrich , `` improved and perfect actions in discrete gravity , '' phys .",
    "d * 80 * ( 2009 ) 124030 [ arxiv:0907.4323 [ gr - qc ] ] .",
    "b.  dittrich and s.  steinhaus , `` path integral measure and triangulation independence in discrete gravity , '' phys .",
    "d * 85 * ( 2012 ) 044032 [ arxiv:1110.6866 [ gr - qc ] ] .",
    "b.  dittrich , `` diffeomorphism symmetry in quantum gravity models , '' adv .",
    "* 2 * ( 2009 ) 151 , [ arxiv:0810.3594 [ gr - qc ] . ]",
    "b.  bahr and b.  dittrich , `` ( broken ) gauge symmetries and constraints in regge calculus , '' class .",
    "* 26 * ( 2009 ) 225011 [ arxiv:0905.1670 [ gr - qc ] ] . + b.  bahr and b.",
    "dittrich , `` breaking and restoring of diffeomorphism symmetry in discrete gravity , '' the planck scale : proceedings of the xxv max born symposium , wroclaw ( poland ) , 29 june - 3 july , 2009 , edited by j.  kowalski - glikman et .",
    "al .  , pp .",
    "10 - 17 , [ arxiv:0909.5688 [ gr - qc ] . ]",
    "b.  dittrich , f.  c.  eckert and m.  martin - benito , `` coarse graining methods for spin net and spin foam models , '' new j.  phys .",
    "* 14 * ( 2012 ) 035008 [ arxiv:1109.4927 [ gr - qc ] ] . b.  dittrich and f.  c.  eckert , `` towards computational insights into the large - scale structure of spin foams , '' j.  phys .",
    "* 360 * ( 2012 ) 012004 [ arxiv:1111.0967 [ gr - qc ] ] .",
    "r.  oeckl , `` a general boundary formulation for quantum mechanics and quantum gravity , '' phys .",
    "b * 575 * ( 2003 ) 318 [ hep - th/0306025 ] .",
    "f.  conrady and c.  rovelli , `` generalized schrodinger equation in euclidean field theory , '' int .",
    "j.  mod .",
    "a * 19 * ( 2004 ) 4037 [ hep - th/0310246 ] .",
    "b.  dittrich and p.  a.  hhn , `` canonical simplicial gravity , '' class .",
    "* 29 * ( 2012 )",
    "115009 [ arxiv:1108.1974 [ gr - qc ] ] . b.  dittrich , c.  guedes , d.  oriti ,  on the space of generalized fluxes for loop quantum gravity \" , to appear    s.  r.  white ,  density matrix formulation for quantum renormalization groups \" phys .",
    "* 96 * ( 1992 ) 2863 .",
    "+ u.  schollwck ,  the density  matrix renormalization group \" rev .",
    "* 77 * 92005 ) 259      c.  fleischhack , `` representations of the weyl algebra in quantum geometry , '' to appear in commun .",
    "arxiv : math - ph/0407006 .",
    "j.  lewandowski , a.  okolow , h.  sahlmann and t.  thiemann , `` uniqueness of diffeomorphism invariant states on holonomy - flux algebras , '' commun .",
    "* 267 * ( 2006 ) 703 [ arxiv : gr - qc/0504147 ] .",
    "t.  a.  koslowski , `` dynamical quantum geometry ( dqg programme ) , '' arxiv:0709.3465 [ gr - qc ] .",
    "t.  koslowski and h.  sahlmann , `` loop quantum gravity vacuum with nondegenerate geometry , '' sigma * 8 * ( 2012 ) 026 [ arxiv:1109.4688 [ gr - qc ] ] . b.  bahr , b.  dittrich and j.  p.  ryan , `` spin foam models with finite groups , '' arxiv:1103.6264 [ gr - qc ] .",
    "k.  noui and a.  perez , `` three dimensional loop quantum gravity : physical scalar product and spin foam models , '' class .",
    "* 22 * ( 2005 ) 1739 [ arxiv : gr - qc/0402110 ] .",
    "b.  dittrich and j.  p.  ryan , `` phase space descriptions for simplicial 4d geometries , '' class .",
    "* 28 * ( 2011 ) 065006 [ arxiv:0807.2806 [ gr - qc ] ] .",
    "a.  degenhard , j.  rodriguez - laguna ,  towards the evaluation of the relevant degrees of freedom in non - linear partial differential equations , j.  stat .",
    "* 106 * ( 2001 ) , 1093 .",
    "+ a.  degenhard , j.  rodriguez - laguna ,  real  space renormalization - group approach to field evolution equations , phys .",
    "* e65 * ( 2001 ) 036703        b.  dittrich and p.  a.  hhn , `` from covariant to canonical formulations of discrete gravity , '' class .  quant .",
    "* 27 * ( 2010 ) 155001 [ arxiv:0912.1817 [ gr - qc ] ] . w.  kaminski , m.  kisielowski and j.  lewandowski , `` spin - foams for all loop quantum gravity , '' class .",
    "* 27 * ( 2010 ) 095006 [ erratum - ibid .",
    "* 29 * ( 2012 ) 049502 ] [ arxiv:0909.0939 [ gr - qc ] ] .",
    "b.  bahr , f.  hellmann , w.  kaminski , m.  kisielowski and j.  lewandowski , class .",
    "quant .  grav .",
    "* 28 * ( 2011 ) 105003 [ arxiv:1010.4787 [ gr - qc ] ] . b.  bahr , b.  dittrich , f.  hellmann , w.  kaminski ,  holonomy spin foam models : definition and coarse graining \" , to appear + b.  bahr , b.  dittrich , f.  hellmann , w.  kaminski ,  holonomy spin foam models : universal boundary hilbert spaces \" , to appear h.  pfeiffer , `` dual variables and a connection picture for the euclidean barrett - crane model , '' class .",
    "* 19 * ( 2002 ) 1109 [ gr - qc/0112002 ] .",
    "e.  magliaro and c.  perini , `` local spin foams , '' arxiv:1010.5227 [ gr - qc ] . l.  freidel , m.  geiller and j.  ziprick , `` continuous formulation of the loop quantum gravity phase space , '' arxiv:1110.4833 [ gr - qc ] .",
    "m.  bojowald , `` loop quantum cosmology , '' living rev .",
    "* 11 * ( 2008 ) 4 .",
    "m.  bojowald , `` loop quantum gravity and cosmology : a dynamical introduction , '' arxiv:1101.5592 [ gr - qc ] .",
    "a.  ashtekar and p.  singh , `` loop quantum cosmology : a status report , '' class .",
    "* 28 * ( 2011 ) 213001 [ arxiv:1108.0893 [ gr - qc ] ] .    m.  bojowald and h.  a.  kastrup , `` quantum symmetry reduction for diffeomorphism invariant theories of connections , '' class .",
    "* 17 * ( 2000 ) 3009 [ hep - th/9907042 ] .",
    "j.  brunnemann and t.  thiemann , `` on ( cosmological ) singularity avoidance in loop quantum gravity , '' class .",
    "* 23 * ( 2006 ) 1395 [ gr - qc/0505032 ] .",
    "j.  brunnemann and c.  fleischhack , arxiv:0709.1621 [ math - ph ] .",
    "b.  dittrich and j.  tambornino , `` gauge invariant perturbations around symmetry reduced sectors of general relativity : applications to cosmology , '' class .",
    "* 24 * ( 2007 ) 4543 [ gr - qc/0702093 [ gr - qc ] ]",
    ". j.  brunnemann and t.  a.  koslowski , `` symmetry reduction of loop quantum gravity , '' class .",
    "* 28 * ( 2011 ) 245014 [ arxiv:1012.0053 [ gr - qc ] ] .    c.  rovelli and f.  vidotto , `` stepping out of homogeneity in loop quantum cosmology , '' class .  quant",
    ".  grav .",
    "* 25 * ( 2008 ) 225024 [ arxiv:0805.4585 [ gr - qc ] ] .",
    "e.  bianchi , c.  rovelli and f.  vidotto , `` towards spinfoam cosmology , '' phys .",
    "d * 82 * ( 2010 ) 084035 [ arxiv:1003.3483 [ gr - qc ] ] .",
    "e.  r.  livine and m.  martin - benito , `` classical setting and effective dynamics for spinfoam cosmology , '' arxiv:1111.2867 [ gr - qc ] .",
    "f.  hellmann , `` on the expansions in spin foam cosmology , '' phys .",
    "d * 84 * ( 2011 ) 103516 [ arxiv:1105.1334 [ gr - qc ] ] ."
  ],
  "abstract_text": [
    "<S> discrete models usually represent approximations to continuum physics . </S>",
    "<S> cylindrical consistency provides a framework in which discretizations mirror exactly the continuum limit . </S>",
    "<S> being a standard tool for the kinematics of loop quantum gravity we propose a coarse graining procedure that aims at constructing a cylindrically consistent dynamics in the form of transition amplitudes and hamilton s principal functions . </S>",
    "<S> the coarse graining procedure , which is motivated by tensor network renormalization methods , provides a systematic approximation scheme towards this end .    a crucial role in this coarse graining scheme </S>",
    "<S> is played by embedding maps that allow the interpretation of discrete boundary data as continuum configurations . </S>",
    "<S> these embedding maps should be selected according to the dynamics of the system , as a choice of embedding maps will determine a truncation of the renormalization flow . </S>"
  ]
}