{
  "article_text": [
    "there is currently much interest in performing ancestral inference from molecular population genetic data . to facilitate this inference ,",
    "there has been an explosion of research in developing computationally efficient methods .",
    "these techniques are designed either to compute the likelihood , for maximum likelihood estimation , of a sample of genes or for deriving the posterior distribution on parameters in coalescent models , which describe the ancestry of the genes .",
    "broadly speaking there are three main approaches to inference in molecular population genetics : ( i ) importance sampling for likelihood evaluation , whose application in population genetics was pioneered by ( griffiths & tavar , 1994a , b , c ) ( ii ) markov chain monte carlo methods ( e.g. kuhner et al .",
    "( 1995 ) , wilson & balding ( 1998 ) ) ( iii ) approximate bayesian computation ( abc ) ( del moral et al .",
    "( 2009 ) , marjoram et al .",
    "( 2003 ) ) .",
    "see stephens ( 2004 ) for a review .",
    "in this paper we concentrate on likelihood - based methods .",
    "molecular data have a sampling distribution which is a mixture over possible ancestries .",
    "the state space of the ancestries is huge and closed - form expressions are available only in the simplest cases .",
    "the objective is to calculate a parameter @xmath0 ( @xmath1 ) such that @xmath2 for some observed genetic data @xmath3 , parameter @xmath4 , probability density @xmath5 on @xmath6 and @xmath7 an integrable function .",
    "note that @xmath8 is typically the genetic types of a random sample of chromosomes .",
    "in addition , @xmath9 denotes the coalescent history , i.e.  the set of ancestral configurations at the embedded events in a markov process where coalescence , mutations or other events take place .",
    "@xmath10 denotes the current state , while @xmath11 is the state when a singleton ancestor is reached .    statistical inference associated to @xmath12",
    "can be regarded as a missing data problem and could , in principle , be tackled by the em algorithm ( dempster et al .  1977 ) and its monte carlo extensions ( e.g.  fort & moulins ( 2003 ) ) .",
    "however , @xmath13 , the stochastic tree , can be computationally expensive to simulate and such techniques are typically avoided .",
    "for example , for the coalescent ( kingman , 1982 ) and ancestral recombination graphs ( e.g.  fearnhead & donelly ( 2001 ) ) , the standard approach is to use is ( de iorio & griffiths , 2004a ; griffiths & tavar , 1994a ; stephens & donelly , 2000 ) and smc methods ( chen et al .",
    "2005 ) to approximate .",
    "these approximations are usually computed on a discrete grid @xmath14 and the estimate of @xmath15 corresponds to the largest approximated likelihood on @xmath16 .",
    "see also olsson & rydn ( 2008 ) for an alternative procedure for state - space models .",
    "techniques such as abc and composite likelihood ( wiuf , 2006 ) do not give solutions which are exact w.r.t .  the original model whilst , when possible , exact inference is of interest .",
    "this is because , given a reasonable stochastic model , the approach allows investigators to exactly ( up - to a numerical error ) average over the uncertainty in the tree structure when estimating genetic parameters of interest .",
    "one of the main drawbacks of existing exact is / smc schemes is the simulation of the tree backward in time , from observed data , until the tree coalesces . in many scenarios , especially for large data sets , when getting close to the top of the tree , it often takes a long time to coalesce .",
    "this is due to genetic parameters ( e.g. mutation rates ) that can be very large relative to the size of the data .",
    "consequently , it can take a very long time to simulate the tree back to the mrca . as a result",
    ", the variance of the estimate of the likelihood can be higher than is desirable , along with long cpu times .",
    "it should be noted that the calculation of the likelihood at these points , @xmath4 , can be inferentially important .",
    "in addition , it is seldom possible to speed up the simulation via importance sampling as the variance of the weights can become too large .",
    "that is , by adapting the parameter of the proposal to lead to a fast coalescence , the discrepancy between the true process and the proposal leads to a very inefficient algorithm w.r.t .  variance .",
    "the approach proposed in this paper is based on is .",
    "stephens & donelly ( 2000 ) proposed a way to use is efficiently to simulate ancestral trees by characterizing an optimal proposal distribution and similar methods have since been developed for a variety of genetic scenarios ( e.g.  de iorio & griffiths ( 2004a , b ) ) .",
    "the basic idea is to define an efficient proposal distribution on ancestral histories which allows us to reconstruct markov histories backwards in time from the sample @xmath8 to an mrca .",
    "we introduce a stopping time in the is proposal , backward in time , to stop the simulation before the mrca is reached . then using a simple stopped identity , forward in time we are able to characterize the bias introduced in the evaluation of the likelihood due to stopping the simulation of the stochastic tree .",
    "the bias can be understood by considering two aspects :    1 .",
    "the underlying mixing of the evolutionary process[pt : evpr ] 2 .",
    "the last exit time distributions on the process .",
    "[ pt : lepr ]    in the context of ( [ pt : evpr ] ) , the idea is that for many models , close to the top of the tree , the process is able to forget its initial condition . as a result ,",
    "stopping the simulation is reasonable , because the place where it is stopped is forgotten by the process forward in time ; we formalize these ideas later on . in reference to ( [ pt : lepr ] ) , the more information there is on the true marginal distributions of the process , the more it is possible to reduce the bias .",
    "ideas from the theory of population genetics models ( ethier & griffiths 1987 ; ewens , 1972 ) will be used to achieve the latter .    in reference to a comment of edwards ( 2000 ) , our method is termed the ` time machine ' .",
    "this is because , estimation is performed saving the simulation time of going all the way back in time to the mrca .",
    "a similar idea , in the context of filtering , can be found in the work of olsson et al .",
    "( 2008 ) and also in option pricing avramidis & lcuyer ( 2006 ) . in our context",
    ", we have a simpler underlying process than in filtering , but the ergodicity conditions considered there do not apply here .",
    "the mixing conditions that they require only apply locally and thus the proofs have to be modified .",
    "recall that approximate tools for inference from stochastic trees ( e.g.  del moral et al .",
    "( 2009 ) , meligkotsidou & fearnhead ( 2007 ) , tavar et al .",
    "( 2000 ) ) are available . however , our approach is ` less approximate ' , in that our point - wise estimate of the likelihood is significantly less - biased , but costing more in computational - time .",
    "this paper is structured as follows . in section",
    "[ sec : motex ] we introduce a motivating example , the coalescent model , which will help to illustrate our ideas . in section",
    "[ sec : stopsimos ] our methodology is described ; section [ sec : bias ] features an analysis of the bias of the approach ; section [ sec : simos ] presents a simulation study to demonstrate the performance of our algorithm and we conclude the paper in section [ sec : summary ] .",
    "appendix 1 contains some proofs , appendix 2 details of our numerical implementations .",
    "our ideas are illustrated in the context of the coalescent .",
    "however , the formulation is kept as general as possible , as the framework can be extended to other tree models , such as the infinite sites model . in appendix 3",
    "we show how this can be done .",
    "the coalescent model is used as a motivating example for our work .",
    "some notations are first introduced . in particular",
    ", we consider the case in which the type space @xmath17 for the collection of the @xmath18 genes / chromosomes is finite and the only genetic process of interest is mutation .",
    "denote by @xmath19 a measurable space .",
    "for two @xmath20finite measures @xmath21 and @xmath22 mutual absolute continuity is written @xmath23 and the radon - nikodym derivative as @xmath24 . given a markov kernel @xmath25 $ ] , let @xmath26 , ( the dirac measure ) and write the composition for @xmath27 as @xmath28 , with a corresponding composition of inhomogeneous kernels as @xmath29",
    ". write @xmath30 as the indicator of a set . for @xmath31 @xmath32",
    "denotes the class of stochastic matrices for which there exist a stationary distribution @xmath33 .",
    "the collection of bounded and measurable function are denoted @xmath34 .",
    "the supremum norm is written @xmath35 .",
    "the total variation distance between two probability measures @xmath21 and @xmath22 on @xmath19 is @xmath36 .",
    "given a probability measure @xmath37 , and a @xmath38 , the product measure is written @xmath39 , @xmath40 .",
    "the vector notation @xmath41 is adopted .",
    "in addition , let the @xmath42-dimensional vector @xmath43 where the 1 is in the @xmath44 position .",
    "the @xmath45 norm of a vector is written @xmath46 . for @xmath47 , @xmath48 .",
    "define the tree model on the measurable space @xmath49 , with @xmath50 .",
    "let @xmath51 .",
    "the basic idea is to maximize , w.r.t @xmath4 , the quantity @xmath52 where the observed data is @xmath53 , @xmath54 , normally the identity , for @xmath55 @xmath56 and @xmath57 for some @xmath58 and @xmath59 depending upon the model under study . in all of our examples",
    ", @xmath60 corresponds to the density of a non - decreasing ( in some sense ) markov process in discrete time , stopped at a random time @xmath61 ; that is @xmath62 throughout the article it is assumed that @xmath63 , i.e.  that the stopping time is a.s .  finite w.r.t @xmath5 .",
    "the stopping time will be determined by the first time that the tree is of ` size ' @xmath64 .",
    "introduce an absolutely continuous distribution @xmath65 on @xmath6 and sample @xmath66 according to @xmath65 , then the is estimator of @xmath12 is @xmath67\\ ] ] where @xmath68 and @xmath69 the empirical measure of the simulated samples .",
    "denote the number of genes of type @xmath70 at event @xmath71 of the process as @xmath72 , with @xmath73 .",
    "the objective is to find the genetic parameters @xmath74 where @xmath75 and @xmath76 , @xmath77 .",
    "@xmath78 is the mutation rate per chromosome per generation and mutations along the edges of the tree occur according to a markov chain with transition matrix @xmath79 .",
    "the various components of the identity ( [ eq : likelihood_id ] ) for the coalescent model are defined as : @xmath80 with @xmath81 the identity function , @xmath82 and finally , @xmath83 where @xmath84 @xmath85 and @xmath86 write @xmath87 ( here @xmath88 is counting measure ) .",
    "note that for any fixed @xmath51 , @xmath4 , @xmath89 .",
    "for simplicity of exposition , the results are given with only mutation .",
    "however , they can be easily extended to the case of migration as well ( e.g.  de iorio & griffiths ( 2004b ) ) .      to compute the likelihood , for a given @xmath4",
    ", importance sampling is adopted .",
    "an importance distribution , @xmath65 , is introduced to simulate the tree backward in time to the mrca ; this ensures that the data is hit .    in details ,",
    "let @xmath90 denote the reverse chain backward in time and write @xmath91 instead of @xmath13 ( this convention is used throughout the article , see also figure [ fig : coalgraph ] ) .",
    "let : @xmath92 for some markov transition @xmath93 ; see stephens & donelly ( 2000 ) for the optimal @xmath65 .",
    "then the likelihood is @xmath94 the simulation proceeds by sampling from @xmath95 and computing the weight @xmath96 simulations backward in time are carried out until we reach the mrca , i.e. when there is only one individual in the sample . this procedure is repeated @xmath97 times to provide a monte carlo estimator for the likelihood @xmath98\\ ] ] where @xmath99 are the simulated samples , @xmath100 for every @xmath101 and @xmath102 this can be repeated for many @xmath103 using a driving value ( griffiths & tavar , 1994 ) or bridge sampling ideas ( e.g.  fearnhead & donelly ( 2001 ) ) .",
    "in addition , to deal with the problem of weight degeneracy ( e.g.  doucet et al .",
    "( 2001 ) ) resampling steps can be added .",
    "see , for example , chen et al .",
    "( 2005 ) .",
    "( 1,1 ) ( .5,.75)(0,1)0.25 ( 0.25,.75)(1,0).5 ( 0.75,.75)(0,-1)0.5 ( 0.25,.75)(0,-1)0.1 ( 0.125,.65)(1,0)0.25 ( 0.125,.65)(0,-1)0.65 ( 0.375,.65)(0,-1)0.15 ( 0.3125,.5)(1,0)0.125 ( 0.3125,.5)(0,-1)0.5 ( 0.4375,.5)(0,-1)0.5 ( 0.625,.25)(1,0).25 ( 0.625,.25)(0,-1).25 ( 0.875,.25)(0,-1).25 ( 0.1,0.5)(0.1,0)8(1,0)0.05 ( 0.95,.95)@xmath104 ( 0.01,.95)@xmath105 ( 0.95,.75)@xmath106 ( 0.95,.65)@xmath107 ( 0.95,.5)@xmath108 ( 0.95,.25)@xmath109 ( 0.95,.01)@xmath110 ( 0.01,.5)@xmath111 ( 0.01,.25)@xmath112 ( 0.01,.01)@xmath113 ( 0.25,.45)@xmath114 ( 0.7,.45)@xmath115",
    "it is now detailed how we stop the simulation of the stochastic tree back in time before the mrca is reached . in the next section we provide theoretical results and connections to the theory of smc",
    "are established .",
    "for the purpose of stopping the simulation , introduce two stopping times ( forwards in time ) : the first hitting time of the set @xmath116 @xmath117 and some stopping time @xmath118 associated to the hitting of a set @xmath119 @xmath120 such that @xmath121 where @xmath122 is the @xmath123probability .",
    "for example , in the context of the coalescent , it is suggested to take , for @xmath124 @xmath125      let @xmath126 denote the expectations w.r.t the process @xmath127 .",
    "then the likelihood ( [ eq : likelihood_id ] ) can be written as @xmath128\\ ] ] and applying the strong markov property we have @xmath129\\;\\ ] ] that is , @xmath130 dz_{\\alpha } \\label{eq : stoplike}\\end{aligned}\\ ] ] where @xmath131 the equation ( [ eq : stoplike ] ) will be the starting point for constructing our biased estimates of the likelihood function .",
    "consider the coalescent model . specifically ,",
    "define , for @xmath132 the stopping time @xmath118 @xmath133 which is the first time the forward process has @xmath134 individuals .",
    "using equation ( [ eq : stoplike ] ) , we have @xmath135dz_{\\alpha } \\label{eq : coallikestp}.\\ ] ] in words this means that to have @xmath134 chromosomes , we need a minimum of @xmath136 steps in the process and @xmath137 has to be at least @xmath138 steps .    in this case ,",
    "write @xmath139 note this is well - defined due to the fact that the size of the population is non - decreasing , and then , for any @xmath140 @xmath141 where @xmath142 that is , given @xmath118 , the distribution of the chromosome counts at the first entrance time of @xmath143 can be written as the composition of :    * the distribution of the counts at the last exit time from @xmath144 * and the markov transition .",
    "returning to the likelihood ( [ eq : coallikestp ] ) and making the substitutions , @xmath145 , @xmath146 , it thus follows that @xmath147 here @xmath148 is the time from the last time there are @xmath136 chromosomes to @xmath64 chromosomes .",
    "now set @xmath149 in other words the simulation is stopped the first time there are @xmath136 chromosomes .",
    "our approximation of the likelihood is then @xmath150 on the basis of the above analysis , it is then clear that if @xmath151 then the approximation of the likelihood is exact .",
    "that is , to minimize the bias an approximation of the true distribution of the counts at the last time there are @xmath136 chromosomes should be used .",
    "the ideas and notation are clarified in figure [ fig : coalgraph ] .",
    "in our biased simulation , using the decomposition , the procedure will approximate @xmath152 where our notation is such that :    * @xmath153 is the time reversed process * @xmath114 is a first hitting time associated to @xmath153 * @xmath154 an approximation of a marginal probability .",
    "we begin by giving a simple result on the error bounds for smc algorithms .",
    "the result applies to the standard is algorithms , for example in de iorio & griffiths ( 2004b ) , stephens & donelly ( 2000 ) , and for the smc algorithms as in chen et al .",
    "the simulation is to be performed backward in time , as in section [ sec : likelihood_computation ] .",
    "the ideas here are adapted from the theory of del moral ( 2004 ) .",
    "the biased estimates are denoted as @xmath155 , @xmath156 , where @xmath157 depends upon whether is or smc is implemented .",
    "for example , in the is case : @xmath158 where @xmath159 is such that @xmath160 is the set associated to @xmath161 ( @xmath162a.s . ) , @xmath163 and @xmath164 .",
    "below expectations w.r.t the stochastic process that is simulated by the algorithm are written as @xmath165 and it is assumed @xmath166    [ prop : lpbound ] for any @xmath51 , @xmath167 , @xmath4 , @xmath168 , there exists a @xmath169 such that : @xmath170^{1/p } \\leq \\frac{b_{p , n}(\\theta)}{\\sqrt{n } } + |l_b(y_{1:n};\\theta ) - l(y_{1:n};\\theta)|.\\ ] ]    * remark*. _ the result shows the standard variance - bias type decomposition .",
    "that is , @xmath171 can be thought of as a bound on the variance and @xmath172 is the bias .",
    "our estimate converges to @xmath173 , and it is sought to control the bias term , which , in our case can be approximately written in the form @xmath174(p_{1:k}(f))| \\label{eq : biasdecomp}\\ ] ] for @xmath175 two probability measures and @xmath176 a sequence of non - homogenous markov kernels ( @xmath103 is suppressed on the r.h.s ) . _      a simple technical result is now given which shows how to control the bias term ( [ eq : biasdecomp ] ) .",
    "some assumptions are now made , that can be satisfied by many stochastic tree models .",
    "introduce a sequence of time inhomogeneous markov kernels @xmath177 , on space @xmath178 and a sequence of sets @xmath179 .",
    "[ hyp : p_nassump ] _ stability of @xmath177 .",
    "_    * \\(i ) * initial probability measures*. @xmath175 are concentrated on @xmath180 .",
    "* \\(ii ) * absorption of @xmath177*. for every @xmath181 , @xmath182 we have @xmath183 * \\(iii ) * local mixing of @xmath177*. for every @xmath181 , there exist @xmath184 , @xmath185 concentrated on @xmath186 , such that for all @xmath182 @xmath187    the assumption ( a[hyp : p_nassump ] ) ( which is comprised of ( i)-(iii ) ) will refer to the fast mixing of the process close to the top of the tree .",
    "the absorption type assumption refers to the birth process associated to coalescent type chains .",
    "[ prop : biascontrol ] assume ( a[hyp : p_nassump ] ) .",
    "then , for any @xmath188 , define : @xmath189 and we have @xmath190p_{1:k}\\|_{tv } \\leq \\vartheta_k\\|\\lambda_1-\\lambda_2\\|_{tv}.\\ ] ]    * remark 1*. _ the result helps to bound the bias as @xmath191(p_{1:k}(f))| \\leq \\|f\\|_{\\infty}\\|[\\lambda_1-\\lambda_2]p_{1:k}\\|_{tv}.\\ ] ] essentially , the fast mixing of @xmath192 within the domain it is constrained to allow the composition of kernels to forget its initial distribution at an exponential rate . in addition , as in olsson et al .",
    "( 2008 ) , assuming @xmath193 is uniform in @xmath194 , the benefits of stopping , in terms of variance / bias trade off can be substantial .",
    "_    * remark 2*. _ one point of interest in the sequel is that , if the mixing condition ( a[hyp : p_nassump ] ) does not hold , it is possible to establish a similar bound when the initial measures @xmath21 and @xmath22 are similar .",
    "that is to say , when @xmath23 and @xmath195 such that @xmath196 this is unsurprising as it implies that if the kernels do not mix , we need to ` match ' @xmath21 and @xmath22 for the bias to be small .",
    "_      ( a[hyp : p_nassump ] ) is now discussed in the context of the coalescent .",
    "note that the results follow , with some extra work , for coalescent processes with migration .",
    "readers interested in how the method may be applied can skip to section [ sec : simos ] , with no loss in continuity .",
    "suppose that the transition matrix @xmath79 satisfies , for any @xmath197 , @xmath198 and probability @xmath199 , @xmath200",
    "@xmath201 this condition implies that @xmath79 mixes extremely quickly .",
    "let @xmath202 ; this corresponds to the space of @xmath203 .",
    "also let @xmath204 .",
    "it is clear that @xmath205 : since we start with at most 3 chromosomes and the most possible after 3 steps is 6 .",
    "now it can be seen that , for any @xmath206 @xmath207 and @xmath208 with @xmath209\\bigg(\\frac{\\mu}{\\mu+2}\\bigg)^2\\bigg]^3.\\ ] ] here the minorising probability @xmath210 puts all its probability on having 3 chromosomes .",
    "then it can be subsequently seen that @xmath211 satisfies condition ( [ eq : mixingcond ] ) , with @xmath212 and so fourth . in effect",
    "the condition ( [ eq : mixingcond ] ) holds with @xmath213 ; that is , the closer to the top of the tree we stop , the faster the process will mix forward in time .    as a result , to bound the bias we can write it , approximately , in the form , for @xmath214 @xmath215\\ ] ] with @xmath21 as in ( [ eq : lastexit ] ) ,",
    "@xmath216 , @xmath217 , @xmath218 is associated to the fact that we need to iterate the kernels to satisfy ( [ eq : mixingcond ] ) and @xmath219 .",
    "@xmath220 is an integer big enough ( say @xmath221 ) where we suspect that the possibility of generating a tree of length @xmath194 and hitting the data is extremely small , so we can neglect the upper term .",
    "thus , approximately , the bound shows that the bias falls geometrically as we stop closer to the top of the tree .",
    "note , however , it can not go to zero unless @xmath21 and @xmath22 are equal . to an extent ,",
    "finding good approximations is more difficult than being able to stop the tree , which is why we focus on this .    *",
    "remark 1*. _ the result given here mirrors one proved by donelly & kurtz ( 1999 ) for fleming - viot models . in theorem 9.4 of that paper they show that the particle process is uniformly ergodic , if the mutation process is .",
    "this is very similar to the property established above . _    * remark 2*._the information , in terms of when to stop the simulation , that is contained in the bound on the bias is as follows .",
    "if the mutation process mixes quickly , as above , then the bias falls at a geometric rate : we should stop the simulation when the process starts to mutate many times .",
    "this could be measured in terms of the effective sample size ( e.g.  liu ( 2001 ) ) , if trees are simulated in parallel , or alternatively , if @xmath222 , for @xmath223 a large multiple of the current size of the tree .",
    "_    * remark 3*. _ in terms of the expression @xmath224 , one could adopt a parent - independent mutation ( pim ) marginal .",
    "if we have @xmath225 where @xmath226 is the transition for the pim , and the mutation vector is @xmath227 , then ideas from perturbed markov chains ( e.g.  mitrophanov ( 2005 ) ) can be adopted to determine a quantitative bound .",
    "we are currently investigating a meaningful bound . _",
    "to illustrate our approach , we consider three simulation scenarios : two pim models and one parent dependent mutation model ( pdm ) .",
    "the two pim models , denoted pim 0.5 - 0.5 and pim 0.1 - 0.9 are based on the following per - locus transition matrices : @xmath228 while the per - locus mutation probability matrix underlying the pdm model is @xmath229 in all three scenarios , the initial population was set to 100 sequences and we considered a single - locus case ( @xmath230 with 2 possible types ) . for the pdm model only , we also considered the case of 10 loci ( @xmath230 @xmath231=1024 different types ) .",
    "irrespective of the number of loci considered , the distribution of the 100 initial sequences among the different types was sampled from a multinomial distribution with a probability vector @xmath79 defined as the invariant point , solution of equation , @xmath232 , where @xmath194 denotes the number of loci considered and @xmath233 is the full mutation probability matrix .    the algorithm description is given in appendix 2 .",
    "for the function @xmath234 , we use the distribution of an un - ordered sample from a pim model ( which , even for the pim cases , is not the correct distribution in the bias term ) .",
    "simulations were carried out until there were @xmath235 sequences left in the population .",
    "@xmath236 exactly corresponds the approach in stephens & donelly ( 2000 ) and is subsequently referred to as @xmath237 .",
    "for each simulation , we examined 60 values for @xmath78 ranging from 0.1 to 30.1 .",
    "we report in figure [ graphe_distrib ] the estimated log - likelihood distribution , based on 100,000 samples for all four simulations scenarios ( presented in lines ) and three values of @xmath78 ( presented in columns ) .",
    "estimated distribution of the likelihood for the four simulation scenarios and for three values the mutation rate @xmath238 and @xmath239 . in each model",
    ", results are presented for the six stopping times in the simulation of the genealogical tree .",
    "plots are based on 100,000 samples . ]    in figure [ graphe_distrib ] it is clear that as expected , uniformly across the values of @xmath78 , the closer to the mrca the algorithm is stopped , the more accurate the distribution of the likelihood is estimated .",
    "however , up to tm 10% ( and even tm 25% for @xmath240 ) our results suggest that the time machine approximation and correction provides an accurate estimate of the distribution of the likelihood .",
    "conversely , when the algorithm is stopped too early ( tm @xmath241 25% ) the biased estimator underlying the time machine approach leads to very inaccurate estimates of the likelihood . for even more extreme cases ( tm 50% for @xmath242 ) , this results in a highly shifted estimated distribution of the likelihood .",
    "the above observations are also reflected in the mean likelihood ( figure [ meanl ] ) . for every model considered here , the simulations of the time machine up to tm 25% seem to provide estimates of the mean likelihood that are similar to the sd approach , although for larger values of @xmath78 , tm 25% seems to overestimate the mean likelihood .",
    "furthermore , the time machine approach seems to accurately locate the value of @xmath78 maximizing the likelihood for tm@xmath243 10% , and to provide acceptable approximations for for this when tm@xmath244 10% , regardless of the simulation scenario .",
    "estimated likelihood for the four simulation scenarios as a function of the mutation rate @xmath78 .",
    "plots are based on 100,000 samples . ]    in figure [ meant ] , the average computation time per iteration is plotted as a function of @xmath78 for the pdm-10 loci simulations .",
    "results for all other models led to the same conclusions and are therefore not shown . from this figure , the computation time appears to be a linearly increasing function of @xmath78 : increasing the mutation rate naturally decreases the probability of simulating a coalescent event and therefore tends to increase the time to reach the mrca ( or any population size ) .",
    "however , it seems that stopping the simulation when there are only more than 5 sequences left in the population drastically reduces the computation time : for tm 5% the simulation run is on average more than twice as fast as the sd simulation , and for tm 25% , the time machine is more than 3 times more time - efficient than the sd algorithm .",
    "it should also be noted that ` large ' values of @xmath78 ( around 10 ) , for which the time savings are most significant , also seem to be inferentially important ( see the fourth panel of figure [ meanl ] ) .    in figure [",
    "fig : relative_sd ] the relative standard deviation across our 100 repeats of the algorithm , of the time machine to sd are plotted for all the scenarios considered .",
    "it can be seen , as expected , that there is some variance reduction and , for example for the tm 5% pdm , the variance reduction is of the order 1.5 .",
    "average computation time as a function of the mutation rate @xmath78 .",
    "figures are based on 100,000 samples . ]",
    "relative standard deviation across 100 repeats of the time machine to sd .",
    "figures are based on 100,000 samples . ]    on the basis of our experiments , combining both computational efficiency and the numerical accuracy , the use of the time machine with tm 5% is an efficient alternative to the sd algorithm .",
    "the c++ code is available upon request from the third author .",
    "in this paper we have considered a new approach for simulation of stochastic trees and likelihood calculation of sample probabilities in population genetics models .",
    "the approach consists in stopping the backward simulations before the top of the tree is reached .",
    "we have provided theoretical results on the bias introduced in the estimation of the likelihood .",
    "some extensions to our work are described below .",
    "firstly , to extend our analysis to different models .",
    "the paper has been written to facilitate such analysis and we believe it is rather simple to deal with other stochastic tree models . also , some further empirical investigations would help support the simulations and theoretical analyses presented here .",
    "our methodology would be further enhanced with gpu technology ( e.g.  lee et al .",
    "( 2010 ) ) , and this is one area that we are currently investigating .    secondly , to look at the consistency ( in a likelihood sense ) of our biased monte carlo estimator . as we observed in section",
    "[ sec : simos ] , it appears that the time machine seems to recover the maximum likelihood estimator .",
    "therefore consistency , or potential asymptotic bias is of genuine interest .",
    "there are very few results in the context of consistency , due to the dependency in the data , after integrating out the tree .",
    "that is , it is difficult to apply uniform laws of large numbers to complex dependency structures .",
    "none - the - less , we suggest the work of douc et el .",
    "( 2004 ) , fearnhead ( 2003 ) , olsson et al .",
    "( 2008 ) , olsson & rydn ( 2008 ) as possible starting points for a proof .",
    "thirdly , the time machine can be used in the context of markov chain monte carlo ( mcmc ) .",
    "if one is interested in bayesian parameter inference , then a stopping - time smc algorithm can be used within an mcmc algorithm ( particle mcmc ( andrieu et al .",
    "significant time savings per iteration can be gained by using the time machine ; see jasra & kantas ( 2010 ) for some details .",
    "we thank prof .",
    "arnaud doucet for some valuable conversations related to this work .",
    "we give the proofs of propositions [ prop : lpbound ] and [ prop : biascontrol ] .    in the case of",
    "is , the result follows by adding and subtracting @xmath173 applying minkoswki and the marincinkiewicz - zygmund inequality . in the case of the smc algorithm",
    "the proof follows from the fact that the algorithm approximates a multi - level feynman - kac formula ; see chapter 12 , proposition 12.2.3 del moral ( 2004 ) .",
    "note that this point is apparently over - looked in chen et al .",
    "( 2005 ) , and such a result helps to verify the convergence of the algorithm .",
    "in addition , note that the proposition 12.2.3 of del moral ( 2004 ) does not depend on the importance weights being upper - bounded by 1 .",
    "hence , due to the boundedness of the weights , the same proof as for is applies , except the @xmath245 bound for particle approximations of feynman - kac formulae is used instead of the marincinkiewicz - zygmund inequality .",
    "the proof is fairly simple and combines the proof of lemma 3.9 and theorem 4.1 of le gland & oudjane ( 2004 ) ( see also theorem 3.1 of tadi & doucet ( 2005 ) ) .",
    "the idea is to use the contraction property of the total variation distance and hilbert metric , as well as the relation between the two ( see lemma 6.1 of tadi & doucet ( 2005 ) ) .",
    "the only real complication is using the local mixing condition ( [ eq : mixingcond ] ) to derive a bound on the radon - nikodym derivatives @xmath246 consider @xmath247 , clearly @xmath248 in addition @xmath249 since @xmath250 it follows that @xmath251 the proof can then be concluded by following the arguments of le gland & oudjane ( 2004 ) , lemma 3.9 and theorem 4.1 .",
    "let @xmath252 , @xmath253 , the population size within each of the @xmath42 states at time @xmath81 . the algorithm will simulate backward in time genealogical trees for an initial population , @xmath254 the ( @xmath255dimensional ) counts associated to the observed data , until there are @xmath256 sequences left in the population .",
    "the case where @xmath256=@xmath257 corresponds to ordinary coalescent and @xmath258 to the time machine .",
    "most of the notations can be found in sections [ sec : motivation ] and [ sec : id_interest ] .      for any generation @xmath81",
    ", there are @xmath259 sequences left in the population , the following steps will be iterated until @xmath259=@xmath256 :    1 .   sampling the type of the offspring sequence ( @xmath70 ) with probability @xmath260 2 .   getting the type of the ancestor sequence ( @xmath71 ) .",
    "+ a sequence of a given type @xmath70 can have arisen from an ancestor sequence of type @xmath71 through : 1 .   a coalescent event with a probability proportional to @xmath261 2 .   a @xmath71 to @xmath70 mutation event ( inclusive of self mutations , from type @xmath70 to type @xmath70 ) , with probability proportional to : @xmath262 where @xmath263 3 .",
    "updating the population sizes within each type .",
    "+ @xmath264 4 .",
    "calculate the contribution to the likelihood of the simulated event ( suppressing the subscript @xmath103 ) + @xmath265 where @xmath266 and @xmath267 5 .",
    "updating the log likelihood + @xmath268 6 .   assessing the stopping criterion .",
    "+ when the time machine is used ( @xmath230 @xmath258 ) , steps 1 to 5 are repeated until @xmath269 .",
    "otherwise , when the full tree is simulated ( @xmath256=@xmath257 ) , steps 1 to 5 are repeated until there are 2 sequences left in the population .",
    "then , mutations are simulated until both remaining sequences are of the same type , based on the following three steps : 1 .",
    "choose one of the two sequence , of type @xmath70 , with probability 0.5 .",
    "2 .   simulate the mutation event from an ancestor of type @xmath71 ( to type @xmath70 ) according to the probability defined in equation ( [ p_mut ] ) , and setting the coalescent probability to 0 .",
    "calculate the corresponding weight for the sampled @xmath71 to @xmath70 simulated transition . at this final stage",
    "there are only two individuals in the population ( @xmath270 ) , hence @xmath271 , and @xmath272 , then : @xmath273 when the final generation is reached @xmath274 , and @xmath275 for any other iterations in that step .",
    "the weight for each generation , derived from is then defined as : @xmath276 4 .",
    "update the likelihood according to equation ( [ update_l ] )      this step is specific to the time machine ( i.e.  if @xmath277 ) . recalling that @xmath114 is the generation at which the iterative algorithm was stopped ,",
    "the bias induced by stopping the simulation before reaching the mrca is estimated as : @xmath278 where @xmath279 denotes the gamma function .",
    "the likelihood of the tree is then updated @xmath280      the above algorithm is independently repeated @xmath97 times , the estimate of the log - likelihood is @xmath281 where @xmath282 is the value of the final weight for sample @xmath70 and @xmath283 .",
    "we now consider our results in the context of the infinite sites model .",
    "we concentrate upon likelihoods associated to rooted genealogical trees ; see ethier & griffiths ( 1987 ) or griffiths & tavar ( 1995 ) for more details .",
    "the model is based upon the simulation of distinct dna sequences , and the multiplicity of the sequences . in more details ,",
    "the simulation begins with a single dna sequence @xmath284 , and counts @xmath285 .",
    "the process can then undergo a mutation ( rate @xmath78 ) or a split . if a mutation occurs ( to the first sequence say ) we have the new state @xmath286 , @xmath287 and @xmath288 , otherwise the new state is @xmath284 and @xmath289 .",
    "the key point is that new mutations introduce a new site ( that is a new integer number ( which is larger than all others currently present ) to the start of a selected sequence ) and hence dna sequence , whilst splits only increase the number of an existing sequence .",
    "the state - space consists of the @xmath255distinct sequences ( vectors of potentially different length sequences @xmath290 ) and the respective counts @xmath291 of the sequences that have been simulated .",
    "that is , in the previous notation @xmath292 the simulation stops , as before , when @xmath293 . in general ,",
    "transitions are governed by the following markov kernel .",
    "a mutation ( rate @xmath78 ) , at time @xmath294 , of the @xmath295 sequence occurs with probability @xmath296 and a split of the @xmath295 sequence occurs with probability @xmath297 see ethier & griffiths ( 1987 ) and griffiths ( 1989 ) for details on the transition dynamics .    in this scenario ,",
    "the state - space is more complicated .",
    "let @xmath298 here @xmath299 are the lengths of the distinct sequences , and the ordering constraint notes that the discovery of a new site is added to the beginning of the segment vector . in addition , let @xmath300 then @xmath301 there are three trans - dimensional aspects to the state - space ; the time to simulate @xmath64 sequences ; the number of distinct sequences and the respective lengths of the distinct sequences ( which is determined in part by the first two aspects ) .      for the infinitely - many - sites model , we will use the idea of the first time the number of segregating sites is @xmath136 ( or mutations here ) to stop the simulations backward in time . in a similar manner to section [ sec : stopcoal ] , it can be established that we want the approximating function @xmath302 to be the marginal of the process at the last time we have @xmath136 segregating sites .    in the context of the infinitely - many - sites model , the bias is controlled by our ability to approximate this marginal ( see remark 2 in section [ sec : contrbias ] ) .",
    "this is because the markov transitions can only change the multiplicity of counts , or increase the number of distinct sequences ; we are unable to change the beginning of sequences . as a result",
    ", it is not possible to establish conditions such as ( a[hyp : p_nassump ] ) .",
    "we propose the following approximation of the marginal , based upon the theoretical properties of such models ( ethier & griffiths , 1987;griffiths , 1989 ) and the relation to the infinitely - many - alleles model ( e.g.  griffiths ( 1979 ) and the references there - in ) .",
    "let us consider the marginal distribution , call it @xmath303 .",
    "we extend the state - space to include uncertainty on @xmath42 , the number of distinct types , @xmath304 and @xmath305 the number of segregating sites , and adopt the decomposition @xmath306 now , under certain conditions , there are results about the exact densities @xmath307 ( ewens , 1972 ) and @xmath308 ( watterson , 1975 ) . in the case",
    "@xmath309 , as noted by griffiths ( 1979 ) , for large populations ( such that diffusion results can apply ) the infinitely - many - sites and infinitely - many - allele frequencies are not too different .",
    "therefore , we propose to use the probability ( as in ewens ( 1972 ) ) @xmath310 with @xmath311 are stirling numbers of the first kind .    for the quantities @xmath312 and @xmath313 , we use approximations . for the former ,",
    "a uniform distribution is adopted @xmath314\\bigg)^{-1}\\ ] ] where @xmath315 that is , it is a simple task in combinatorics to show that if there are @xmath305 mutations with @xmath316 repetitions of mutations @xmath257 to @xmath305 , ( subject to the constraint that each mutation can only occur at most once in each sequence and that order of allocating a mutation does not matter ) then there are @xmath317 possible sequences ; summing over all the possible multiples yields the desired cardinality of the state - space .",
    "@xmath313 is not known ( except as the marginal of a recursion ( as in ethier & griffiths ( 1987 ) ) ) and is assigned @xmath318 ( poisson ) distribution ( at time @xmath71 ) .    in practice",
    ", it may not be possible to evaluate some of these quantities and a further monte carlo simulation / numerical approximation ( for the integral over @xmath305 and the normalizing constant of @xmath319 ) will be required .",
    "that is to say , we set @xmath320 the approximation will be different for every simulated sample .",
    "lee , a. , yau , c. , giles , m. b. , doucet , a. & holmes , c.c .",
    "( 2010 ) . on the utility of graphics cards to perform massively parallel simulation of advanced monte carlo methods , _ j. comp . graph .",
    "_ , ( to appear ) ."
  ],
  "abstract_text": [
    "<S> in the following paper we consider a simulation technique for stochastic trees . </S>",
    "<S> one of the most important areas in computational genetics is the calculation and subsequent maximization of the likelihood function associated to such models . </S>",
    "<S> this typically consists of using importance sampling ( is ) and sequential monte carlo ( smc ) techniques . </S>",
    "<S> the approach proceeds by simulating the tree , backward in time from observed data , to a most recent common ancestor ( mrca ) . </S>",
    "<S> however , in many cases , the computational time and variance of estimators are often too high to make standard approaches useful . in this paper </S>",
    "<S> we propose to stop the simulation , subsequently yielding biased estimates of the likelihood surface . </S>",
    "<S> the bias is investigated from a theoretical point of view . </S>",
    "<S> results from simulation studies are also given to investigate the balance between loss of accuracy , saving in computing time and variance reduction . </S>",
    "<S> + * key words * : stochastic trees , sequential monte carlo , coalescent . </S>"
  ]
}