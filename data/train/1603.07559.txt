{
  "article_text": [
    "for a range of scientific studies including quantum computation , quantum information and quantum simulation , an important task is to learn and engineer quantum systems [ @xcite , @xcite ( @xcite , @xcite ) , @xcite , @xcite,@xcite , @xcite , and wang ( @xcite , @xcite ) ] .",
    "a  quantum system is described by its state characterized by a density matrix , which is a positive semidefinite hermitian matrix with unit trace . determining a quantum state , often referred to as quantum state tomography , is an important but difficult task [ @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite ] .",
    "it is often inferred by performing measurements on a large number of identically prepared quantum systems .",
    "more specifically , we describe a quantum spin system by the @xmath0-dimensional complex space @xmath1 and its quantum state by a complex matrix on @xmath1 .",
    "when measuring the quantum system by performing measurements on some observables which can be represented by hermitian matrices , we obtain the measurement outcomes for each observable , where the measurements take values at random from all eigenvalues of the observable , with the probability of observing a particular eigenvalue equal to the trace of the product of the density matrix and the projection matrix onto the eigenspace corresponding to the eigenvalue . to handle the up and down states of particles in a quantum spin system , a common approach is to employ the well - known pauli matrices as observables to perform measurements and obtain the so - called pauli measurements [ @xcite , @xcite , @xcite , @xcite , @xcite , and wang ( @xcite , @xcite ) ] .",
    "since all pauli matrices have @xmath2 eigenvalues , pauli measurements takes discrete values @xmath3 and @xmath4 , and the resulted measurement distributions can be characterized by binomial distributions . the goal is to estimate the density matrix based on the pauli measurements .",
    "traditional quantum tomography employs classical statistical models and methods to deduce quantum states from quantum measurements .",
    "these approaches are designed for the setting where the size of a density matrix is greatly exceeded by the number of quantum measurements , which is almost never the case even for moderate quantum systems in practice because the dimension of the density matrix grows exponentially in the size of the quantum system .",
    "for example , the density matrix for @xmath5 spin-@xmath6 quantum systems is of size @xmath7 . in this paper",
    ", we aim to effectively and efficiently reconstruct the density matrix for a large - scale quantum system with a relatively limited number of quantum measurements .",
    "quantum state tomography is fundamentally connected to the problem of recovering a high - dimensional matrix based on noisy observations [ @xcite ] .",
    "the latter problem arises naturally in many applications in statistics and machine learning and has attracted considerable recent attention . when assuming that the unknown matrix of interest is of ( approximately ) low - rank , many regularization techniques have been developed .",
    "examples include @xcite , @xcite , @xcite ( @xcite , @xcite ) , @xcite , @xcite , bunea , she and wegkamp ( @xcite , @xcite ) , klopp ( @xcite , @xcite ) , @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite , among many others .",
    "taking advantage of the low - rank structure of the unknown matrix , these approaches can often be applied to estimate unknown matrices of high dimensions .",
    "yet these methods do not fully account for the specific structure of quantum state tomography . as",
    "demonstrated in a pioneering article , @xcite argued that , when considering quantum measurements characterized by the pauli matrices , the density matrix can often be characterized by the sparsity with respect to the pauli basis . built upon this connection , they suggested a compressed sensing [ @xcite ] strategy for quantum state tomography [ @xcite and @xcite ] .",
    "although promising , their proposal assumes exact measurements , which is rarely the case in practice , and adopts the constrained nuclear norm minimization method , which may not be an appropriate matrix completion approach for estimating a density matrix with unit trace ( or unit nuclear norm ) .",
    "we specifically address such challenges in the present paper .",
    "in particular , we establish the minimax optimal rates of convergence for the density matrix estimation under both the spectral and frobenius norm losses when assuming that the true density matrix is approximately sparse under the pauli basis .",
    "furthermore , we show that these rates could be achieved by carefully thresholding the coefficients with respect to the pauli basis .",
    "because the quantum pauli measurements are characterized by the binomial distributions , the convergence rates and minimax lower bounds are derived by asymptotic analysis with manipulations of binomial distributions instead of the usual normal distribution based calculations .    the rest of paper proceeds as follows .",
    "section  [ sec2 ] gives some background on quantum state tomography and introduces a thresholding based density matrix estimator .",
    "section  [ sec3 ] develops theoretical properties for the density matrix estimation problem .",
    "in particular , the convergence rates of the proposed density matrix estimator and its minimax optimality with respect to both the spectral and frobenius norm losses are established .",
    "section  [ sec4 ] features a simulation study to illustrate finite sample performance of the proposed estimators .",
    "all technical proofs are collected in section  [ proofs ] .",
    "in this section , we first review the quantum state and density matrix and introduce pauli matrices and pauli measurements . we also develop results to describe density matrix representations through pauli matrices and characterize the distributions of pauli measurements via binomial distribution before introducing a thresholding based density matrix estimator .      for a @xmath0-dimensional quantum system",
    ", we describe its quantum state by a density matrix @xmath8 on @xmath0 dimensional complex space @xmath1 , where density matrix @xmath8 is a @xmath0 by @xmath0 complex matrix satisfying ( 1 ) hermitian , that is , @xmath8 is equal to its conjugate transpose ; ( 2 ) positive semidefinite ; ( 3 )  unit trace , that is , @xmath9 .    for a quantum system ,",
    "it is important but difficult to know its quantum state .",
    "experiments are conducted to perform measurements on the quantum system and obtain data for studying the quantum system and estimating its density matrix . in physics literature",
    ", quantum state tomography refers to reconstruction of a quantum state based on measurements for the quantum systems .",
    "statistically , it is the problem of estimating the density matrix from the measurements .",
    "common quantum measurements are on observable @xmath10 , which is defined as a hermitian matrix on @xmath1 .",
    "assume that the observable @xmath10 has the following spectral decomposition : @xmath11 where @xmath12 are @xmath13 different real eigenvalues of @xmath10 , and @xmath14 are projections onto the eigenspaces corresponding to @xmath12 .",
    "for the quantum system prepared in state @xmath8 , we need a probability space @xmath15 to describe measurement outcomes when performing measurements on the observable @xmath10 .",
    "denote by @xmath16 the measurement outcome of @xmath10 . according to the theory of quantum mechanics , @xmath16 is a random variable on @xmath15 taking values in @xmath17 , with probability distribution given by @xmath18 we may perform measurements on an observable for a quantum system that is identically prepared under the state and obtain independent and identically distributed observations .",
    "see @xcite , @xcite , and @xcite .",
    "the pauli matrices as observables are widely used in quantum physics and quantum information science to perform quantum measurements .",
    "let @xmath19 where @xmath20 , @xmath21 and @xmath22 are called the two - dimensional pauli matrices .",
    "tensor products are used to define high - dimensional pauli matrices .",
    "let @xmath23 for some integer @xmath5 .",
    "we form @xmath5-fold tensor products of @xmath24 , @xmath20 , @xmath21 and @xmath22 to obtain @xmath0 dimensional pauli matrices @xmath25 we identify index @xmath26 with @xmath27 .",
    "for example , @xmath28 corresponds to @xmath29 . with the index identification",
    "we denote by @xmath30 the pauli matrix @xmath31 , with @xmath32 .",
    "we have the following theorem to describe pauli matrices and represent a density matrix by pauli matrices .    [ thm-1 ]",
    "pauli matrices @xmath33 are of full rank and have eigenvalues @xmath2 .",
    "denote by @xmath34 the projections onto the eigen - spaces of @xmath30 corresponding to eigenvalues @xmath2 , respectively .",
    "then for @xmath35 , @xmath36 denote by @xmath37 the space of all @xmath0 by @xmath0 complex matrices equipped with the frobenius norm .",
    "all pauli matrices defined by ( [ pauli - matrix ] ) form an orthogonal basis for all complex hermitian matrices .",
    "given a density matrix @xmath8 , we can expand it under the pauli basis as follows : @xmath38 where @xmath39 are coefficients .",
    "for @xmath40 , @xmath41    suppose that an experiment is conducted to perform measurements on pauli observable @xmath30 independently for @xmath42 quantum systems which are identically prepared in the same quantum state @xmath8 . as @xmath30 has eigenvalues @xmath2 , the pauli measurements take values @xmath3 and @xmath4 , and thus the average of the @xmath42 measurements for each @xmath30 is a sufficient statistic .",
    "denote by @xmath43 the average of the @xmath42 measurement outcomes obtained from measuring @xmath30 , @xmath44 .",
    "our goal is to estimate @xmath8 based on @xmath45 .",
    "the following proposition provides a simple binomial characterization for the distributions of @xmath43 .",
    "[ thm-2 ] suppose that @xmath8 is given by ( [ beta - representation ] ) .",
    "then @xmath45 are independent with @xmath46 and @xmath47 follows a binomial distribution with @xmath42 trials and cell probabilities @xmath48 , where @xmath49 denotes the projection onto the eigenspace of @xmath30 corresponding to eigenvalue @xmath3 , and @xmath39 is the coefficient of @xmath30 in the expansion of @xmath8 in ( [ beta - representation ] ) .",
    "since the dimension of a quantum system grows exponentially with its components such as the number of particles in the system , the matrix size of @xmath8 tends to be very large even for a moderate quantum system .",
    "we need to impose some structure such as sparsity on @xmath8 in order to make it consistently estimable .",
    "suppose that @xmath8 has a sparse representation under the pauli basis , following wavelet shrinkage estimation we construct a density matrix estimator of @xmath8 .",
    "assume that representation ( [ beta - representation ] ) is sparse in a sense that there is only a relatively small number of coefficients @xmath50 with large magnitudes .",
    "formally , we specify sparsity by assuming that coefficients @xmath51 satisfy @xmath52 where @xmath53 , and @xmath54 is a deterministic function with slow growth in @xmath0 such as @xmath55 .",
    "pauli matrices are used to describe the spins of spin-@xmath6 particles along different directions , and density matrix @xmath8 in ( [ beta - representation ] ) represents a mixture of quantum states with spins along many directions .",
    "sparsity assumption ( [ csparsity ] ) with @xmath56 indicates the mixed state involving spins along a relatively small number of directions corresponding to those pauli matrices with nonzero @xmath50 .",
    "the sparsity reduces the complexity of mixed states .",
    "sparse density matrices often occur in quantum systems where particles have sparse interactions such as location interactions .",
    "examples include many quantum systems in quantum information and quantum computation [ @xcite , @xcite , @xcite , @xcite , @xcite , and wang ( @xcite , @xcite ) ] . since @xmath57 are independent , and @xmath58 .",
    "we naturally estimate @xmath50 by @xmath57 and threshold @xmath57 to estimate large @xmath50 , ignoring small @xmath59 , and obtain @xmath60 \\label{threshold1 } \\\\[-8pt ] \\nonumber \\hat{\\beta } _ k & = & \\operatorname{sign}(n_k ) \\bigl(|n_k|- \\varpi\\bigr)_+ , \\qquad k = 2 , \\ldots , d^2,\\end{aligned}\\ ] ] and then we use @xmath61 to construct the following estimator of @xmath8 , @xmath62 where the two estimation methods in ( [ threshold1 ] ) are called hard and soft thresholding rules , and @xmath63 is a threshold value which , we reason below , can be chosen to be @xmath64 for some constant @xmath65 .",
    "the threshold value is designed such that for small @xmath50 , @xmath57 must be bounded by threshold @xmath63 with overwhelming probability , and the hard and soft thresholding rules select only those @xmath57 with large signal components @xmath50 .",
    "as @xmath66 , an application of bernstein s inequality leads to that for any @xmath67 , @xmath68 and @xmath69^{d^2 - 1 } = \\bigl [ 1 - 2 d^{-2 \\hbar/(1+o(1 ) ) } \\bigr]^{d^2 - 1 } \\rightarrow1 , \\ ] ] as @xmath70 and @xmath71 , that is , with probability tending to one , @xmath72 uniformly for @xmath73 .",
    "thus , we can select @xmath64 to threshold @xmath57 and obtain @xmath61 in ( [ threshold1 ] ) .",
    "we fix matrix norm notation for our asymptotic analysis .",
    "let @xmath74 be a @xmath0-dimensional vector and @xmath75 be a @xmath0 by @xmath0 matrix , and define their @xmath76 norms @xmath77 denote by @xmath78 the frobenius norm of @xmath79 .    for the case of matrix , the @xmath80 norm",
    "is called the matrix spectral norm or operator norm .",
    "@xmath81 is equal to the square root of the largest eigenvalue of @xmath82 , @xmath83 and @xmath84 for a real symmetric or complex hermitian matrix @xmath79 , @xmath85 is equal to the largest absolute eigenvalue of @xmath79 , @xmath86 is the square root of the sum of squared eigenvalues , @xmath87 , and ( [ ell-1infty - norm])([ell-12infty - norm ] ) imply that @xmath88 .",
    "the following theorem gives the convergence rates for @xmath89 under the spectral and frobenius norms .",
    "[ thm-3 ] denote by @xmath90 the class of density matrices satisfying the sparsity condition ( [ csparsity ] ) .",
    "assume @xmath91 for some constants @xmath92 and @xmath93 . for density matrix estimator @xmath89 defined by ( [ threshold1])([threshold - estimator1 ] ) with threshold @xmath94 for some constant @xmath65",
    ", we have @xmath95 & \\leq &   c_2 \\pi^2_n(d ) \\frac{1}{d^2 } \\biggl ( \\frac { \\log d } { n } \\biggr)^{1-q } , \\\\ \\sup_{{\\bolds{\\rho}}\\in\\theta } e\\bigl[\\| \\hat{{\\bolds{\\rho } } } - { \\bolds{\\rho}}\\|_f^2 \\bigr ] & \\leq &   c_3 \\pi_n(d ) \\frac{1}{d } \\biggl ( \\frac { \\log d } { n } \\biggr)^{1-q/2},\\end{aligned}\\ ] ] where @xmath96 and @xmath97 are constants free of @xmath42 and @xmath0 .    [ rem1 ] theorem  [ thm-3 ] shows that @xmath89 achieves the convergence rate @xmath98 under the squared frobenius norm loss and the convergence rate @xmath99 under the squared spectral norm loss .",
    "both rates will be shown to be optimal in the next section .",
    "similar to the optimal convergence rates for large covariance and volatility matrix estimation [ @xcite and @xcite ] , the optimal convergence rates here have factors involving @xmath54 and @xmath100 .",
    "however , unlike the covariance and volatility matrix estimation case , the convergence rates in theorem  [ thm-3 ] have factors @xmath101 and @xmath102 for the squared spectral and frobenius norms , respectively , and go to zero as @xmath0 approaches to infinity .",
    "in particular , the result implies that mses of the proposed estimator get smaller for large @xmath0 .",
    "this is quite contrary to large covariance and volatility matrix estimation where the traces are typically diverge , the optimal convergence rates grow with the logarithm of matrix size , and the corresponding mses increase in matrix size",
    ". the new phenomenon may be due to the unit trace constraint on density matrix and that the density matrix representation ( [ beta - representation ] ) needs a scaling factor @xmath101 to satisfy the constraint . also for finite sample @xmath89",
    "may not be positive semidefinite , we may project @xmath89 onto the cone formed by all density matrices under a given matrix norm @xmath103 , and obtain a positive semidefinite density matrix estimator @xmath104 .",
    "since the underlying true density matrix @xmath8 is positive semidefinite with unit trace , and the representation ( [ threshold - estimator1 ] ) ensures that @xmath89 has unit trace , the projection implies @xmath105 .",
    "thus , @xmath106 .",
    "taking @xmath103 as the spectral norm or the frobenius norm and using theorem  [ thm-3 ] , we conclude that @xmath104 has the same convergence rates as @xmath89 .",
    "the following theorem establishes a minimax lower bound for estimating @xmath8 under the spectral norm .",
    "[ thm-4 ] we assume that @xmath54 in the sparsity condition ( [ csparsity ] ) satisfies @xmath107 for some constant @xmath108 and @xmath109 . then @xmath110 \\geq c_4 \\pi^2_n(d ) \\frac { 1}{d^2 } \\biggl ( \\frac { \\log d } { n } \\biggr)^{1-q},\\ ] ] where @xmath111 denotes any estimator of @xmath8 based on measurement data @xmath45 , and @xmath112 is a constant free of @xmath42 and @xmath0",
    ".    [ rem2 ] the lower bound in theorem  [ thm-4 ] matches the convergence rate of @xmath89 under the spectral norm in theorem  [ thm-3 ] , so we conclude that @xmath89 achieves the optimal convergence rate under the spectral norm . to establish the minimax lower bound in theorem  [ thm-4 ] , we construct a special subclass of density matrices and then apply le cam s lemma . assumption ( [ cond - pi ] )",
    "is needed to guarantee the positive definiteness of the constructed matrices as density matrix candidates and to ensure the boundedness below from zero for the total variation of related probability distributions in le cam s lemma .",
    "assumption ( [ cond - pi ] ) is reasonable in a sense that if the right - hand side of ( [ cond - pi ] ) is large enough , ( [ cond - pi ] ) will not impose very restrictive condition on @xmath54 .",
    "we evaluate the dominating factor @xmath113 on the right - hand side of ( [ cond - pi ] ) for various scenarios .",
    "first , consider @xmath56 , the assumption becomes @xmath114 , @xmath115 , and so assumption ( [ cond - pi ] ) essentially requires @xmath54 grows in @xmath0 not faster than @xmath116 , which is not restrictive at all as @xmath54 usually grows slowly in @xmath0 .",
    "the asymptotic analysis of high - dimensional statistics usually allows both @xmath0 and @xmath42 go to infinity .",
    "typically , we may assume @xmath0 grows polynomially or exponentially in @xmath42 .",
    "if @xmath0 grows exponentially in @xmath42 , that is , @xmath117 for some @xmath118 , then @xmath119 is negligible in comparison with @xmath120 , and @xmath113 behavior like @xmath120 .",
    "the assumption in this case is not very restrictive . for the case of polynomial growth , that is , @xmath121 for some @xmath122 , then @xmath123 . if @xmath124 , @xmath125 grows in @xmath0 like some positive power of @xmath0 .",
    "since we may take @xmath126 arbitrarily close to @xmath127 , the positiveness of @xmath128 essentially requires @xmath129 , which can often be quite realistic given that @xmath130 is usually very small .",
    "the theorem below provides a minimax lower bound for estimating @xmath8 under the frobenius norm .",
    "[ thm-5 ] we assume that @xmath54 in the sparsity condition ( [ csparsity ] ) satisfies @xmath131 for some constants @xmath132 and @xmath133",
    ". then @xmath134 \\geq c_5 \\pi_n(d ) \\frac{1}{d } \\biggl ( \\frac { \\log d } { n } \\biggr)^{1-q/2},\\ ] ] where @xmath111 denotes any estimator of @xmath8 based on measurement data @xmath45 , and @xmath135 is a constant free of @xmath42 and @xmath0 .",
    "[ rem3 ] the lower bound in theorem  [ thm-5 ] matches the convergence rate of @xmath89 under the frobenius norm in theorem  [ thm-3 ] , so we conclude that @xmath89 achieves the optimal convergence rate under the frobenius norm .",
    "similar to the remark  [ rem2 ] after theorem  [ thm-4 ] , we need to apply assouad s lemma to establish the minimax lower bound in theorem  [ thm-5 ] , and assumption ( [ cond - pi-0 ] ) is used to guarantee the positive definiteness of the constructed matrices as density matrix candidates and to ensure the boundedness below from zero for the total variation of related probability distributions in assouad s lemma .",
    "also the appropriateness of ( [ cond - pi-0 ] ) is more relaxed than ( [ cond - pi ] ) , as @xmath136 and the right - hand side of ( [ cond - pi-0 ] ) has main powers more than the square of that of ( [ cond - pi ] ) .",
    "it is interesting to consider density matrix estimation under a schatten norm , where given a matrix @xmath79 of size @xmath0 , we define its schatten @xmath137-norm by @xmath138 are the eigenvalues of the square root of @xmath139 .",
    "spectral norm and frobenius norm are two special cases of the schatten @xmath137-norm with @xmath140 and , respectively , and the nuclear norm corresponds to the schatten @xmath137-norm with @xmath141 .",
    "the following result provides the convergence rate for the proposed thresholding estimator under the schatten @xmath137-norm loss for @xmath142 .",
    "[ schatten.prop ] under the assumptions of theorem  [ thm-3 ] , the density matrix estimator @xmath89 defined by ( [ threshold1])([threshold - estimator1 ] ) with threshold @xmath94 for some constant @xmath65 satisfies @xmath143 \\leq c \\bigl[\\pi_n(d)\\bigr ] ^{2 - 2/\\max(s,2 ) } \\frac{1}{d^{2 - 2/s } } \\biggl(\\frac { \\log d}{n } \\biggr ) ^{1-q+q/\\max(s,2)}\\ ] ] for @xmath142 , where @xmath144 is a constant not depending on @xmath42 and @xmath0 .",
    "the upper bound in ( [ schatten - s1 ] ) matches the minimax convergence rates for both the spectral norm and frobenius norm .",
    "moreover , for the case of the nuclear norm corresponding to the schatten @xmath137-norm with @xmath141 , ( [ schatten - s1 ] ) leads to an upper bound with the convergence rate @xmath145 .",
    "we conjecture that the upper bounds in ( [ schatten - s1 ] ) are rate - optimal under the schatten @xmath137-norm loss for all @xmath146 .",
    "however , establishing a matching lower bound for the general schatten norm loss is a difficult task , and we believe that a new approach is needed for studying minimax density matrix estimation under the schatten @xmath137-norm , particularly the nuclear norm .",
    "[ rem4 ] the pauli basis expansion ( [ beta - representation ] ) is orthogonal with respect to the usual euclidean inner product , and as in the proof of lemma  [ lem - norm ] we have @xmath147 where @xmath148 and @xmath89 are threshold estimators of @xmath149 and @xmath8 , respectively .",
    "the sparse vector estimation problem is well studied under the gaussian or sub - gaussian noise case [ @xcite and @xcite ] and can be used to recover the minimax result for density matrix estimation under the frobenius norm loss , because of orthogonality .",
    "in fact , our relatively simple proof of the minimax results for the frobenius norm loss is essentially the same as the sparse vector estimation approach .",
    "however , such an equivalence between sparse density matrix estimation and sparse vector estimation breaks down for the general schatten norm loss such as the commonly used spectral norm and nuclear norm losses .",
    "for the spectral norm loss , lemma  [ lem - norm ] in section  [ proofs ] provides a sharp upper bound for @xmath150 $ ] through the @xmath151-norm of @xmath152 , and the proof of the minimax lower bound in theorem  [ thm-4 ] relies on the property that the spectral norm is determined by the largest eigenvalue only .",
    "such a special property allows us to reduce the problem to a simple subproblem and establish the lower bound under the spectral norm loss .",
    "the arguments can not be applied to the case of the general schatten norm loss in particular the nuclear norm loss .",
    "moreover , instead of directly applying lemma  [ lem - norm ] and remark  [ rem5 ] in section  [ proofs ] to derive upper bounds for the general schatten norm loss , we use the obtained sharp upper bounds for the spectral norm and frobenius norm losses together with moment inequalities to derive sharper upper bounds in proposition  [ schatten.prop ] . however , similar lower bounds are not available .",
    "our analysis leads us to believe that it is not possible to use sparse vector estimation to recover minimax lower bound results for the general schatten norm loss in particular for the spectral norm loss .",
    "a simulation study was conducted to investigate the performance of the proposed density matrix estimator for the finite sample .",
    "we took @xmath153 and generated a true density matrix @xmath8 for each case as follows .",
    "@xmath8 has an expansion over the pauli basis @xmath154 where @xmath155 , @xmath40 . from @xmath51",
    ", we randomly selected @xmath156 $ ] coefficients @xmath39 and set the rest of @xmath39 to be zero .",
    "we simulated @xmath157 $ ] values independently from a uniform distribution on @xmath158 $ ] , assigned the simulated values at random to the selected @xmath39 , and then constructed @xmath8 from ( [ rho - simulation ] ) .",
    "the constructed @xmath8 always has unit trace but may not be positive semi - definite .",
    "the procedure was repeated until we generated a positive semi - definite @xmath8 .",
    "we took it as the true density matrix .",
    "the simulation procedure guarantees the obtained @xmath8 is a density matrix and has a sparse representation under the pauli basis .    for each true density matrix @xmath8 ,",
    "as described in section  [ sec-2 - 2 ] we simulated data @xmath43 from a binomial distribution with cell probability @xmath39 and the number of cells @xmath159 .",
    "we constructed coefficient estimators @xmath160 by ( [ threshold1 ] ) and obtained density matrix estimator @xmath89 using ( [ threshold - estimator1 ] ) .",
    "the whole estimation procedure is repeated @xmath161 times .",
    "the density matrix estimator is measured by the mean squared errors ( mse ) , @xmath162 and @xmath163 , that are evaluated by the average of @xmath164 and @xmath165 over @xmath161 repetitions , respectively .",
    "three thresholds were used in the simulation study : the universal threshold @xmath166 for all @xmath39 , the individual threshold @xmath167 for each @xmath39 , and the optimal threshold for all @xmath39 , which minimizes the computed mse for each corresponding hard or soft threshold method .",
    "the individual threshold takes into account the fact in theorem  [ thm-2 ] that the mean and variance of @xmath43 are @xmath39 and @xmath168 , respectively , and the variance of @xmath43 is estimated by @xmath169 .    . ",
    "are plots of mses based on the spectral norm for @xmath153 , respectively , and  are plots of mses based on the frobenius norm for @xmath170 , respectively . ]",
    "[ figure1 ]    .  are plots of mses based on the spectral norm for @xmath153 , respectively , and  are plots of mses based on the frobenius norm for @xmath171 , respectively . ]    .  are plots of mses based on the spectral norm for @xmath172 , respectively , and  are plots of mses based on the frobenius norm for @xmath173 , respectively . ]     or @xmath174 against matrix size @xmath0 for the proposed density estimator with hard and soft threshold rules for @xmath175 .  are plots of @xmath174 times of mses based on the spectral norm for @xmath175 , respectively , and  are plots of @xmath0 times of mses based on the frobenius norm for @xmath175 , respectively . ]    figures  [ figure1 ] and [ figure2 ] plot the mses of the density matrix estimators with hard and soft threshold rules and its corresponding density matrix estimator without thresholding [ i.e. , @xmath39 are estimated by @xmath43 in ( [ threshold - estimator1 ] ) ] against the sample size @xmath42 for different matrix size @xmath0 , and figures  [ figure3 ] and [ figure4 ] plot their mses against matrix size @xmath0 for different sample size .",
    "the numerical values of the mses are reported in table  [ table1 ] .",
    "figures  [ figure1 ] and [ figure2 ] show that the mses usually decrease in sample size @xmath42 , and the thresholding density matrix estimators enjoy superior performances than that the density matrix estimator without thresholding even for @xmath176 ; while all threshold rules and threshold values yield thresholding density matrix estimators with very close mses , the soft threshold rule with individual and universal threshold values produce larger mses than others for larger sample size such as @xmath177 and the soft threshold rule tends to give somewhat better performance than the hard threshold rule for smaller sample size like @xmath178 .",
    "figures  [ figure3 ] and [ figure4 ] demonstrate that while the mses of all thresholding density matrix estimators decrease in the matrix size @xmath0 , but if we rescale the mses by multiplying it with @xmath174 for the spectral norm case and @xmath0 for the frobenius norm case , the rescaled mses slowly increase in matrix size @xmath0 .",
    "the simulation results largely confirm the theoretical findings discussed in remark  [ rem1 ] .",
    "let @xmath179 . denote by @xmath180 s generic constants whose values are free of @xmath42 and @xmath181 and may change from appearance to appearance .",
    "let @xmath182 and @xmath183 be the maximum and minimum of @xmath184 and @xmath126 , respectively . for two sequences @xmath185 and @xmath186 , we write @xmath187 if @xmath188 as @xmath189 , and write @xmath190 if there exist positive constants @xmath191 and @xmath192 free of @xmath42 and @xmath181 such that @xmath193 . without confusion",
    "we may write @xmath54 as @xmath194 .",
    "proof of proposition [ thm-1 ] in two dimensions , pauli matrices satisfy @xmath195 , and @xmath196 , @xmath197 have eigenvalues @xmath2 , the square of a pauli matrix is equal to the identity matrix , and the multiplications of any two pauli matrices are equal to the third pauli matrix multiplying by @xmath198 , for example , @xmath199 , @xmath200 , and @xmath201 .      for @xmath206 , @xmath207 , @xmath208 and @xmath209 , @xmath210\\otimes[{\\bolds{\\sigma}}_{\\ell_2}{\\bolds{\\sigma}}_{\\ell^\\prime_2 } ] \\otimes \\cdots\\otimes[{\\bolds{\\sigma}}_{\\ell_b } { \\bolds{\\sigma}}_{\\ell^\\prime_b}],\\ ] ] is equal to a @xmath0 dimensional pauli matrix multiplying by @xmath211 , which has zero trace .",
    "thus , @xmath212 , that is , @xmath30 and @xmath213 are orthogonal , and @xmath214 form an orthogonal basis .",
    "@xmath215 . in particular @xmath32 , and @xmath216 .",
    "@lcd4.3d1.3d1.3d1.3d1.3d1.3d1.3d2.3d2.3d2.3@ & & & + & & & + & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & + & & & & & & & + & & & & & & & & & & & + 32 & 100 & 348.544 & 4.816 & 4.648 & 5.468 & 4.790 & 6.104 & 4.762 & 24.782 & 15.180 & 0.619 + & 200 & 175.034 & 4.449 & 4.257 & 5.043 & 4.708 & 5.293 & 4.667 & 17.524 & 7.739 & 0.562 + & 500 & 70.069 & 2.831 & 3.054 & 3.344 & 4.130 & 3.260 & 4.071 & 11.083 & 2.397 & 0.373 + & 1000 & 35.028 & 1.537 & 1.974 & 1.875 & 3.201 & 1.875 & 3.155 & 7.837 & 1.099 & 0.212 + & 2000 & 17.307 & 0.785 & 1.195 & 1.001 & 2.230 & 0.989 & 2.200 & 5.541 & 0.551 & 0.116 + 64 & 100 & 368.842 & 1.583 & 1.572 & 1.744 & 1.583 & 1.954 & 1.586 & 27.148 & 16.660 & 0.395 + & 200 & 183.050 & 1.565 & 1.534 & 1.669 & 1.575 & 1.833 & 1.571 & 19.196 & 9.252 & 0.376 + & 500 & 73.399 & 1.175 & 1.228 & 1.367 & 1.490 & 1.347 & 1.476 & 12.141 & 2.900 & 0.307 + & 1000 & 36.692 & 0.566 & 0.807 & 0.747 & 1.249 & 0.722 & 1.233 & 8.585 & 1.308 & 0.177 + & 2000 & 18.402 & 0.186 & 0.443 & 0.255 & 0.832 & 0.251 & 0.820 & 6.070 & 0.657 & 0.061 + 128 & 100 & 381.032 & 0.543 & 0.542 & 0.574 & 0.543 & 0.705 & 0.545 & 29.323 & 17.500 & 0.237 + & 200 & 190.113 & 0.541 & 0.539 & 0.570 & 0.542 & 0.594 & 0.542 & 20.734 & 10.246 & 0.235 + & 500 & 75.824 & 0.471 & 0.480 & 0.514 & 0.525 & 0.509 & 0.522 & 13.114 & 3.547 &",
    "0.213 + & 1000 & 38.010 & 0.309 & 0.350 & 0.355 & 0.470 & 0.354 & 0.466 & 9.273 & 1.613 & 0.146 + & 2000 & 18.907 & 0.142 & 0.216 & 0.194 & 0.359 & 0.194 & 0.356 & 6.557 & 0.725 & 0.080 +      @lcd4.3d1.3d1.3d1.3d1.3d1.3d1.3d2.3d2.3d2.3@ & & & + & & & + & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & + & & & & & & & + & & & & & & & & & & & + 32 & 100 & 317.873 & 6.052 & 5.119 & 6.195 & 5.274 & 7.050 & 5.246 & 24.782 & 11.004 & 9.936 + & 200 & 159.679 & 5.217 & 4.629 & 5.616 & 5.187 & 5.874 & 5.143 & 17.524 & 5.681 & 3.771 + & 500 & 63.823 & 3.165 & 3.229 & 3.732 & 4.575 & 3.642 & 4.512 & 11.083 & 2.286 & 0.954 + & 1000 & 31.856 & 1.722 & 2.053 & 2.119 & 3.540 & 2.119 & 3.492 & 7.837 & 1.100 & 0.401 + & 2000 & 15.967 & 0.894 & 1.219 & 1.155 & 2.424 & 1.141 & 2.394 & 5.541 & 0.546 & 0.182 + 64 & 100 & 641.437 & 3.909 & 3.528 & 3.951 & 3.563 & 4.463 & 3.562 & 27.148 & 13.719 & 13.234 + & 200 & 319.720 & 3.706 & 3.401 & 3.755 & 3.548 & 4.082 & 3.536 & 19.196 & 7.042 & 5.515 + & 500 & 127.958 & 2.691 & 2.551 & 3.069 & 3.342 & 3.023 & 3.309 & 12.141 & 2.800 & 1.275 + & 1000 & 63.845 & 1.335 & 1.628 & 1.765 & 2.791 & 1.717 & 2.756 & 8.585 & 1.277 & 0.548 + & 2000 & 31.952 & 0.433 & 0.882 & 0.610 & 1.842 & 0.596 & 1.817 & 6.070 & 0.647 & 0.258 + 128 & 100 & 1283.182 & 2.370 & 2.240 & 2.370 & 2.242 & 2.924 & 2.245 & 29.323 & 15.989 & 16.128 + & 200 & 639.556 & 2.349 & 2.219 & 2.354 & 2.238 & 2.444 & 2.238 & 20.734 & 8.218 & 7.799 + & 500 & 255.954 & 1.990 & 1.906 & 2.125 & 2.172 & 2.102 & 2.160 & 13.114 & 3.355 & 1.773 + & 1000 & 127.714 & 1.221 & 1.341 & 1.463 & 1.943 & 1.448 & 1.924 & 9.273 & 1.546 & 0.729 + & 2000 & 63.921 & 0.581 & 0.815 & 0.798 & 1.471 & 0.798 & 1.456 & 6.557 & 0.719 & 0.327 +    denote by @xmath34 the projections onto the eigenspaces corresponding to eigenvalues @xmath2 , respectively .",
    "then for @xmath217 , @xmath218 and solving the equations we get @xmath219 for @xmath220 , @xmath221 , @xmath222 and @xmath213 are orthogonal , @xmath223 and @xmath224 which imply @xmath225    for a density matrix @xmath8 with representation ( [ beta - representation ] ) under the pauli basis ( [ pauli - matrix ] ) , from  ( [ eq1 ] ) we have @xmath226 and @xmath227 , and thus @xmath228 \\label{tr - qrho2 } \\\\[-8pt ] \\nonumber & = & \\frac{1}{2 } + \\frac{\\beta_k}{d } \\operatorname{tr}({\\mathbf{b}}_{k } { \\mathbf{q}}_{k \\pm } ) = \\frac{1 \\pm\\beta_k}{2}.\\end{aligned}\\ ] ]    proof of proposition  [ thm-2 ] we perform measurements on each pauli observable @xmath229 independently for @xmath42 quantum systems that are identically prepared under state @xmath8 .",
    "denote by @xmath230 the @xmath42 measurement outcomes for measuring @xmath229 , @xmath231 .",
    "@xmath232 @xmath233 , @xmath234 , @xmath235 , are independent , and take values @xmath2 , with distributions given by @xmath236    as random variables @xmath230 are i.i.d . and take eigenvalues @xmath2",
    ", @xmath237 is equal to the total number of random variables @xmath230 taking eigenvalue @xmath3 , and thus @xmath238 follows a binomial distribution with @xmath42 trials and cell probability @xmath239 . from ( [ tomography3])([tomography4 ] ) and proposition  [ thm-1 ] ,",
    "we have for @xmath234 , @xmath240              from proposition  [ thm-2 ] and ( [ tomography3])([tomography4 ] ) , we have that @xmath43 is the average of @xmath249 , which are i.i.d .",
    "random variables taking values @xmath2 , @xmath250 , @xmath251 and @xmath252 . applying bernstein s inequality ,",
    "we obtain for any @xmath67 , @xmath253 both @xmath254 and @xmath255 are less than @xmath256 , which is bounded by @xmath257    [ lem - norm ] @xmath258 + \\biggl\\ { \\sum _ { j=2}^p e\\bigl[|\\hat{\\beta}_j - \\beta_j|\\bigr ] \\biggr\\}^2 \\nonumber \\\\[-8pt ] \\label{e - spectral - norm - square } \\\\[-8pt ] \\nonumber & & { } - \\sum_{j=2}^p \\bigl\\{e\\bigl(|\\hat { \\beta}_j - \\beta _ j|\\bigr)\\bigr\\}^2.\\end{aligned}\\ ] ]    since pauli matrices @xmath30 are orthogonal with respect to the usual euclidean inner product , with @xmath259 , and @xmath260 , we have @xmath261 \\label{trace - norm } \\\\[-8pt ] \\nonumber & = & \\sum_{j=2}^p |\\hat { \\beta}_j - \\beta_j|^2/d , \\\\   p^{1/2 } \\| \\hat{{\\bolds{\\rho } } } - { \\bolds{\\rho}}\\|_2 & = & \\biggl\\| \\sum _ { j=2}^p ( \\hat{\\beta } _ j - \\beta_j ) { \\mathbf{b}}_j \\biggr\\|_2 \\leq\\sum _ { j=2}^p |\\hat{\\beta}_j - \\beta _",
    "j| \\| { \\mathbf{b}}_j \\|_2 \\nonumber \\\\[-8pt ] \\label{spectral - norm } \\\\[-8pt ] \\nonumber & = & \\sum_{j=2}^p |\\hat { \\beta}_j - \\beta_j| , \\\\",
    "p \\| \\hat{{\\bolds{\\rho } } } - { \\bolds{\\rho}}\\|_2 ^ 2   & = & \\biggl\\| \\sum _ { j=2}^p ( \\hat{\\beta}_j - \\beta_j ) { \\mathbf{b}}_j \\biggr\\|_2 ^ 2 \\nonumber\\\\ & \\leq & \\sum_{j=2}^p |\\hat { \\beta}_j - \\beta_j|^2 \\| { \\mathbf{b}}_j \\|_2 ^ 2 + 2 \\sum_{i < j } ^p \\bigl|(\\hat{\\beta}_i - \\beta_i ) ( \\hat{\\beta}_j - \\beta_j)\\bigr| \\| { \\mathbf{b}}_i { \\mathbf{b}}_j \\|_2 \\nonumber \\\\[-8pt ] \\label{spectral - norm - square } \\\\[-8pt ] \\nonumber & \\leq & \\sum_{j=2}^p |\\hat { \\beta}_j - \\beta_j|^2 \\| { \\mathbf{b}}_j \\|_2 ^ 2 + 2 \\sum_{i < j } ^p \\bigl|(\\hat{\\beta}_i - \\beta_i ) ( \\hat{\\beta}_j - \\beta_j)\\bigr| \\| { \\mathbf{b}}_i\\|_2 \\| { \\mathbf{b}}_j \\|_2 \\nonumber \\\\ & = & \\sum_{j=2}^p |\\hat { \\beta}_j - \\beta_j|^2 + 2 \\sum _",
    "{ i < j } ^p\\bigl|(\\hat{\\beta}_i - \\beta_i ) ( \\hat{\\beta}_j - \\beta_j)\\bigr| . \\nonumber\\end{aligned}\\ ] ]    as @xmath262 are independent , @xmath263 are independent .",
    "thus , from ( [ trace - norm])([spectral - norm - square ] ) we obtain ( [ e - trace - norm])([e - spectral - norm ] ) , and @xmath264 + \\biggl\\ { \\sum _ { j=2}^p e\\bigl[|\\hat{\\beta}_j - \\beta_j|\\bigr ] \\biggr\\}^2 - \\sum_{j=2}^p \\bigl\\{e\\bigl(|\\hat{\\beta}_j - \\beta_j|\\bigr)\\bigr \\}^2.\\end{aligned}\\ ] ]    [ rem5 ] since pauli matrices @xmath30 have eigenvalues @xmath2 , the schatten @xmath137-norm @xmath265 .",
    "similar to ( [ spectral - norm])([spectral - norm - square ] ) , we obtain that @xmath266 \\label{s - norm - square } \\\\[-8pt ] \\nonumber & = & d^{2/s } \\biggl [ \\sum_{j=2}^p | \\hat{\\beta}_j - \\beta_j|^2 + 2 \\sum _",
    "{ i < j } ^p \\bigl|(\\hat{\\beta}_i - \\beta_i ) ( \\hat{\\beta}_j - \\beta_j)\\bigr| \\biggr].\\hspace*{-12pt } \\nonumber\\end{aligned}\\ ] ]      using ( [ threshold1 ] ) , we have @xmath268 + |\\beta_j| p\\bigl(|n_j| \\leq\\varpi \\bigr ) \\nonumber \\\\ & & \\qquad \\leq   \\bigl[e| n_j - \\beta_j|^2 p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } + \\varpi p\\bigl(|n_j| \\geq\\varpi\\bigr ) + |\\beta_j| p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad \\leq    \\bigl [ n^{-1 } \\bigl(1-\\beta_j^2\\bigr ) p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } + \\varpi p\\bigl(|n_j| \\geq\\varpi\\bigr ) + |\\beta_j| p\\bigl(|n_j| \\leq\\varpi \\bigr ) \\nonumber \\\\ & & \\qquad\\leq   2 \\varpi \\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } + | \\beta _",
    "j| p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad=   2 \\varpi \\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } \\bigl\\{1\\bigl(|\\beta _ j| > a_1 \\varpi\\bigr)+ 1\\bigl(|\\beta_j| \\leq a_1 \\varpi\\bigr)\\bigr\\ } \\nonumber \\\\ & & \\qquad\\quad{}+ |\\beta_j| p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\bigl\\{1\\bigl(| \\beta_j| >",
    "a_2 \\varpi\\bigr)+1\\bigl(|\\beta_j| \\leq a_2 \\varpi\\bigr)\\bigr\\ } \\nonumber \\\\ & & \\qquad\\leq    2\\varpi1\\bigl(|\\beta_j| > a_1 \\varpi\\bigr ) + 2 \\varpi \\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } 1\\bigl(| \\beta_j| \\leq a_1 \\varpi\\bigr ) \\nonumber \\\\ & & \\qquad\\quad{}+ p\\bigl(|n_j|\\leq\\varpi\\bigr ) 1\\bigl(|\\beta_j| > a_2",
    "\\varpi\\bigr ) + |\\beta _",
    "j| 1\\bigl(|\\beta_j| \\leq a_2 \\varpi\\bigr),\\end{aligned}\\ ] ] where @xmath269 and @xmath270 are two constants satisfying @xmath271 whose values will be chosen later , and @xmath272^{1/2 } 1\\bigl(| \\beta_j| \\leq a_1 \\varpi\\bigr)\\label{beta-1 } \\\\ & & { } + \\sum_{j=2}^p p\\bigl(|n_j| \\leq\\varpi\\bigr ) 1\\bigl(|\\beta _",
    "\\varpi\\bigr ) + \\sum _ { j=2}^p |\\beta_j| 1\\bigl(| \\beta_j| \\leq a_2 \\varpi\\bigr ) . \\nonumber\\end{aligned}\\ ] ] similarly , @xmath273",
    "^ 2\\\\   & & \\qquad \\leq    e\\bigl[|\\hat{\\beta}_j - \\beta _ j|^2\\bigr ] \\nonumber \\\\ & & \\qquad\\leq    e\\bigl",
    "[ 2\\bigl(| n_j - \\beta_j|^2 + \\varpi^2 \\bigr ) 1\\bigl(|n_j| \\geq\\varpi\\bigr)\\bigr ] + | \\beta_j|^2 p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad \\leq   2 \\bigl[e| n_j - \\beta_j|^4 p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2}\\\\ & & \\qquad\\quad { } + 2 \\varpi ^2 p\\bigl(|n_j| \\geq\\varpi\\bigr ) + |\\beta_j|^2 p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad\\leq    c \\varpi^2",
    "\\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } + |\\beta_j|^2 p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad =   c \\varpi^2 \\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } \\bigl\\{1\\bigl(|\\beta_j| > a_1 \\varpi\\bigr)+ 1\\bigl(|\\beta_j| \\leq a_1 \\varpi\\bigr)\\bigr\\ } \\nonumber \\\\ & & \\qquad\\quad{}+ |\\beta_j|^2 p\\bigl(|n_j| \\leq\\varpi\\bigr ) \\bigl[1\\bigl(|\\beta_j| > a_2 \\varpi\\bigr ) + 1\\bigl(| \\beta_j| \\leq a_2 \\varpi\\bigr)\\bigr ]",
    "\\nonumber \\\\ & & \\qquad \\leq    c \\varpi^2 1\\bigl(|\\beta_j| > a_1 \\varpi\\bigr ) + c \\varpi^2 \\bigl[p\\bigl(|n_j| \\geq\\varpi\\bigr ) \\bigr]^{1/2 } 1\\bigl(|\\beta_j| \\leq a_1",
    "\\varpi\\bigr ) \\nonumber \\\\ & & \\qquad\\quad{}+ p\\bigl(|n_j|\\leq\\varpi\\bigr ) 1\\bigl(|\\beta_j| > a_2",
    "\\varpi\\bigr ) + |\\beta_j|^2 1\\bigl(|\\beta_j| \\leq a_2 \\varpi\\bigr),\\end{aligned}\\ ] ] and",
    "@xmath274\\nonumber\\\\   & & \\qquad \\leq    c \\varpi^2 \\sum_{j=2}^p 1\\bigl(| \\beta_j| >",
    "a_1 \\varpi\\bigr)\\nonumber \\\\[-8pt ] \\label{beta-2 } \\\\[-8pt ] \\nonumber & & \\qquad\\quad { } + c \\varpi^2 \\sum_{j=2}^p \\bigl[p\\bigl(|n_j| \\geq\\varpi \\bigr ) \\bigr]^{1/2 } 1\\bigl(| \\beta_j| \\leq a_1 \\varpi\\bigr ) \\\\ & & \\qquad\\quad{}+ \\sum_{j=2}^p p\\bigl(|n_j|",
    "\\leq\\varpi\\bigr ) 1\\bigl(|\\beta_j| > a_2 \\varpi\\bigr ) + \\sum _ { j=2}^p |\\beta_j|^2 1\\bigl(| \\beta_j| \\leq a_2 \\varpi \\bigr ) .",
    "\\nonumber\\end{aligned}\\ ] ] by lemma  [ lem - sparse ] , we have @xmath275 \\label{beta - sparse-11 } \\\\[-8pt ] \\nonumber & & \\qquad \\leq   ( a _ 2 \\varpi)^{2-q } \\sum _ { j=2}^{p } |\\beta_j|^q 1\\bigl(| \\beta_j| \\leq a_2 \\varpi\\bigr ) \\leq a_2^{2-q } \\pi_n(d ) \\varpi^{2-q } , \\\\",
    "\\label{beta - sparse-2 } & & \\varpi \\sum_{j=2}^p 1\\bigl(| \\beta_j| \\geq a_1 \\varpi\\bigr ) \\leq a_1^{-q}\\pi_n(d ) \\varpi^{1-q}.\\end{aligned}\\ ] ] on the other hand , @xmath276 \\\\ & & \\qquad\\leq4 p^{1- \\vafrac{\\hbar^2 |a_2 - 1|^2}{1+o(1 ) } } = 4 p^{-1 - ( 2-q)/(2 c_0 ) } \\leq4 p^{-1 } n^{-(q-2)/2}\\nonumber\\\\ & & \\qquad = o\\bigl(\\pi_n(d ) \\varpi^{2-q}\\bigr ) , \\nonumber\\end{aligned}\\ ] ] where the third inequality is from lemma  [ lem - tail ] , the first equality is due the fact that we take @xmath277 so that @xmath278 , and @xmath279 is the constant in assumption @xmath280 . finally , we can show @xmath281^{1/2 } 1\\bigl(| \\beta_j| \\leq a_1 \\varpi\\bigr ) \\\\ & & \\qquad\\leq\\varpi \\sum_{j=2}^p \\bigl[p ( n_j - \\beta_j \\leq- \\varpi- \\beta _ j ) \\nonumber \\\\ \\label{beta - sparse-4 } & & \\quad\\qquad{}+ p(n_j - \\beta_j \\geq\\varpi- \\beta_j ) \\bigr]^{1/2 } 1\\bigl(|\\beta_j| \\leq a_1 \\varpi\\bigr ) \\\\ & & \\qquad\\leq\\varpi \\sum_{j=2}^p \\bigl[p\\bigl ( n_j - \\beta_j \\leq- |1-a_1| \\varpi \\bigr ) + p\\bigl(n_j - \\beta_j \\geq|1-a_1| \\varpi\\bigr ) \\bigr]^{1/2 } \\nonumber \\\\ & & \\qquad \\leq2\\varpi p^{1- \\hbar^2 ( 1-a_1)^2/(2(1+o(1 ) ) ) } = 2\\varpi p^{-1 } = o\\bigl ( \\pi_n(d )",
    "\\varpi^{1-q}\\bigr ) , \\nonumber\\end{aligned}\\ ] ] where the third inequality is from lemma  [ lem - tail ] , and the first equality is due to the fact that we take @xmath282 so that @xmath283 . plugging ( [ beta - sparse-1])([beta - sparse-4 ] ) into ( [ beta-1 ] ) and ( [ beta-2 ] ) , we prove the lemma .",
    "proof of theorem  [ thm-3 ] combining lemma  [ lem - thm3 ] and ( [ e - trace - norm])([e - spectral - norm ] ) in lemma  [ lem - norm ] , we easily obtain @xmath284 & \\leq &   c_1 \\frac{\\pi_n(d)}{p^{1/2 } } \\biggl ( \\frac { \\log p } { n } \\biggr)^{\\vfrac{1-q}{2 } } , \\\\ e\\bigl[\\| \\hat{{\\bolds{\\rho } } } - { \\bolds{\\rho}}\\|_f^2\\bigr ]   & \\leq & c_0 \\pi_n(d ) \\frac{1}{d } \\biggl ( \\frac { \\log p } { n } \\biggr)^{1-q/2}.\\end{aligned}\\ ] ] using lemma  [ lem - thm3 ] and ( [ e - spectral - norm - square ] ) in lemma  [ lem - norm ] , we conclude @xmath285   & \\leq &   c_2 \\biggl [ \\pi^2_n(d ) \\frac{1}{p } \\biggl ( \\frac { \\log p } { n } \\biggr)^{1-q } + \\pi_n(d ) \\frac{1}{p } \\biggl ( \\frac { \\log p } { n } \\biggr)^{1-q/2 } \\biggr ] \\nonumber \\\\[-8pt ] \\label{equation - spectral - norm - square } \\\\[-8pt ] \\nonumber & \\leq &   c \\frac{\\pi^2_n(d)}{d^2 } \\biggl ( \\frac { \\log p } { n } \\biggr)^{1-q},\\end{aligned}\\ ] ] where the last inequality is due to the fact that the first term on the right - hand side of ( [ equation - spectral - norm - square ] ) dominates its second term .    proof of proposition  [ schatten.prop ] applying the lyapunov s moment inequality to the schatten @xmath137-norm , we have for @xmath286 $ ] and @xmath287 , @xmath288 & \\leq & d^{-1 + 2/s } e \\bigl [ \\| \\hat{{\\bolds{\\rho } } } -{\\bolds{\\rho}}\\|_{*2 } ^2 \\bigr ] \\\\ & = & d^{-1 + 2/s } e \\bigl [ \\| \\hat{{\\bolds{\\rho } } } -{\\bolds{\\rho}}\\|_{f } ^2 \\bigr ] \\\\ & \\leq & c_1 \\pi_n ( d ) d^{-2 + 2/s } \\biggl(\\frac{\\log d}{n } \\biggr ) ^{1-q/2},\\end{aligned}\\ ] ] where the last inequality is due to theorem  [ thm-3 ] . on the other hand , applying hlder s inequality by interpolating between schatten @xmath137-norms with @xmath289 and @xmath290",
    ", we obtain for @xmath291 $ ] and @xmath287 , @xmath292 & \\leq & e \\bigl [ \\| \\hat{{\\bolds{\\rho}}}- { \\bolds{\\rho}}\\|_{*2}^{4/s } \\| \\hat{{\\bolds{\\rho}}}- { \\bolds{\\rho}}\\| _ { * \\infty } ^{2 - 4/s } \\bigr ] \\\\ & \\leq & \\bigl [ e \\| \\hat { { \\bolds{\\rho}}}- { \\bolds{\\rho}}\\|_{*2}^{2 } \\bigr ] ^{2/s } \\bigl[e \\| \\hat{{\\bolds{\\rho}}}- { \\bolds{\\rho}}\\|_{*\\infty } ^{2 } \\bigr ] ^{1 - 2/s } \\\\ & \\leq & c_7 \\pi_n ^{2 - 2/s}(d ) d^{-2 + 2/s } \\biggl(\\frac{\\log d}{n } \\biggr ) ^{1-q+q / s},\\end{aligned}\\ ] ] where the last inequality is due to theorem  [ thm-3 ] , and @xmath293 .",
    "the result follows by combining the above two inequalities together .",
    "proof of theorem  [ thm-4 ] we first define a subset of the parameter space @xmath90 .",
    "it will be shown later that the risk upper bound under the spectral norm is sharp up to a constant factor , when the parameter space is sufficiently sparse .",
    "consider a subset of the pauli basis , @xmath294 , where @xmath295 or @xmath296 .",
    "its cardinality is @xmath297 .",
    "denote each element of the subset by @xmath298 , @xmath299 , and let @xmath300 .",
    "we will define each element of @xmath90 as a linear combination of @xmath298 .",
    "let @xmath301 , @xmath302 , and denote @xmath303 .",
    "the value of @xmath304 is either @xmath305 or  @xmath306 , where @xmath306 is the largest integer less than or equal to @xmath307 . by assumption ( [ cond - pi ] )",
    ", we have @xmath308 let @xmath309 and set @xmath310 .",
    "now we are ready to define @xmath90 , @xmath311 note that @xmath90 is a subset of the parameter space , since @xmath312 and its cardinality is @xmath313 .",
    "we need to show that @xmath314 note that for each element in @xmath90 , its first entry @xmath315 may take the form @xmath316 .",
    "it can be shown that @xmath317 it is then enough to show that @xmath318 which immediately implies @xmath319    we prove equation ( [ klowerbd ] ) by applying le cam s lemma . from observations",
    "@xmath320 , @xmath321 , we define @xmath322 , which is @xmath323 .",
    "let @xmath324 be the joint distribution of independent random variables @xmath325 .",
    "the cardinality of @xmath326 is @xmath313 . for two probability measures",
    "@xmath327 and @xmath328 with density @xmath329 and @xmath330 with respect to any common dominating measure @xmath331 , write the total variation affinity @xmath332 , and the chi - square distance @xmath333 . define @xmath334 the following lemma is a direct consequence of le cam s lemma [ cf .",
    "@xcite and @xcite ] .",
    "it is enough to show that @xmath342 which implies @xmath343 , then we have @xmath344 .",
    "let @xmath345 denote the number of overlapping nonzero coordinates between @xmath346 and @xmath347 .",
    "note that @xmath348    when @xmath349 , we have @xmath350 \\biggr ) ^{j } \\\\",
    "& = & \\biggl ( \\sum_{l=0}^{n } \\biggl [ \\pmatrix{n \\cr l } \\biggl ( \\frac { ( 1+a ) ^{2}}{2 } \\biggr ) ^{l } \\biggl ( \\frac { ( 1-a ) ^{2}}{2 } \\biggr )",
    "^{n - l } \\biggr ] \\biggr ) ^{j } \\\\ & = & \\biggl ( \\frac { ( 1+a ) ^{2}}{2}+\\frac { ( 1-a ) ^{2}}{2 } \\biggr ) ^{nj } \\\\ & = & \\bigl ( 1+a^{2 } \\bigr ) ^{nj}\\leq\\exp \\bigl ( na^{2}j \\bigr),\\end{aligned}\\ ] ] which implies @xmath351    since @xmath352 ^{2}\\cdot ( d-1-k ) \\cdot \\ldots\\cdot ( d-2k+j ) } { j!\\cdot ( d-1 ) \\cdot \\ldots \\cdot ( d - k ) } \\\\ & \\leq&\\frac{k^{2j } ( d-1-k ) ^{k - j } } { ( d - k ) ^{k}}\\leq \\biggl ( \\frac{k^{2}}{d - k } \\biggr ) ^{j},\\end{aligned}\\ ] ] and @xmath309 , we then have @xmath353 ^{j } \\leq\\sum_{1\\leq j\\leq k } \\biggl [ \\frac{d^{2v+ ( 1 - 2v ) /2}}{d - k } \\biggr ] ^{j}\\rightarrow0.\\end{aligned}\\ ] ]      apply assouad s lemma , and we show below that @xmath134 \\geq c \\pi_n(p ) \\frac{1}{d } \\biggl ( \\frac { \\log p } { n } \\biggr)^{1-q/2},\\ ] ] where @xmath111 denotes any estimator of @xmath8 based on measurement data @xmath262 , and @xmath180 is a constant free of @xmath42 and @xmath181 .    to this end",
    ", it suffices to construct a collection of @xmath356 density matrices @xmath357 such that ( i ) for any distinct @xmath358 and @xmath359 , @xmath360 where @xmath191 is a constant ; ( ii ) there exists a constant @xmath361 such that @xmath362 where @xmath363 denotes the kullback ",
    "leibler divergence .    by the gilbert ",
    "varshamov bound [ cf .",
    "@xcite ] , we have that for any @xmath364 , there exist @xmath365 binary vectors @xmath366 , @xmath367 , such that ( i ) @xmath368 , ( ii ) @xmath369 , and ( iii ) @xmath370 .",
    "let @xmath371 where @xmath372 since @xmath373 , @xmath374 whenever @xmath375 .",
    "moreover , @xmath376 on the other hand , @xmath377 now the lower bound can be established by taking @xmath378 and then @xmath379 which are allowed by the assumption @xmath380 for @xmath381 ."
  ],
  "abstract_text": [
    "<S> quantum state tomography aims to determine the state of a quantum system as represented by a density matrix . </S>",
    "<S> it is a fundamental task in modern scientific studies involving quantum systems . in this paper , we study estimation of high - dimensional density matrices based on pauli measurements . in particular , under appropriate notion of sparsity , we establish the minimax optimal rates of convergence for estimation of the density matrix under both the spectral and frobenius norm losses ; and show how these rates can be achieved by a common thresholding approach . </S>",
    "<S> numerical performance of the proposed estimator is also investigated .    </S>",
    "<S> ./style / arxiv - general.cfg    ,    ,    , </S>"
  ]
}