{
  "article_text": [
    "it has been known since gauss that every complex polynomial @xmath3 in a single complex variable splits into linear factors , and since ruffini and abel that there is no method based on iterated @xmath4-th roots to find these factors algebraically in general .",
    "therefore , numerical approximation methods are required to find the roots of polynomials .",
    "( detail ) .",
    "the colors illustrate the number of iterations until a root is found to high precision ; adjacent color contour lines show a single iteration .",
    "the scale is between 50 iterations ( red ) and 0 iterations ( dark blue ) ; bright green stands for 25 iterations .",
    "compare with figure  [ fig : newtonmarvin_1_24 ] .",
    "picture by marvin randig .",
    ", scaledwidth=60.0% ]    surprisingly , even today it is not clear how to find all roots most efficiently .",
    "there is a theoretically best possible algorithm due to pan @xcite , but it is not applicable in practice .",
    "perhaps the most efficient practical implementation is ` mpsolve 3.0 ` by bini and robol @xcite based on the ehrlich - aberth iteration , but it is still lacking good theory and especially a proof that it is generally convergent .",
    "newton s method is very good at finding roots locally , i.e.  once good approximations are known , but it has a reputation of being difficult to predict globally , for instance because of the `` chaotic '' nature of the iteration , and because of the possibility of having open sets of starting points that converge to attracting periodic orbits , rather than to roots .    the situation has improved substantially in recent times .",
    "indeed , a pleasant feature of newton s method is that one does not have to choose between theory and practical implementations : meanwhile it has good theory ( see @xcite on where to start the iteration , and @xcite with refinements in @xcite on estimates on its complexity that are near - optimal under certain assumptions ) , and it can be implemented quite successfully in practice for polynomials of very high degrees .",
    "the latter aspect is the key theme of the present manuscript .    in @xcite",
    ", we showed that newton s method can be used to find all roots of various complex polynomials efficiently , even up to degrees greater than one million ( where the polynomials were selected only on the criterion that they could be evaluated efficiently ) . in this note , we demonstrate that the computational complexity ( measured in computing time ) can be near - optimal for a wide range of degrees : all roots can be found in computing time between @xmath1 and @xmath5 , and in a number of newton iterations between @xmath1 and @xmath6 , with small constants , so that all roots can be found for degrees up to @xmath7 ( greater than @xmath8 million ) , and even higher degrees seem feasible .",
    "we present an algorithm based on newton s method that turns out to find all roots , the families of polynomials studied , and we describe the outcome of computer experiments .",
    "we also explain how to verify that indeed all roots of our polynomials have been found .",
    "this note should be seen as a continuation and improvement on @xcite , not as a survey on root finding for polynomials .",
    "there are interesting references on the latter , in particular the survey articles by mcnamee  @xcite , as well as studies by pan @xcite , renegar  @xcite , and especially mpsolve 3.0 from @xcite and eigensolve from @xcite .",
    "* acknowledgements*. we are very pleased to be able to report support , encouragement , and helpful suggestions from numerous friends and colleagues , especially dario bini , marcel oliver , victor pan , marvin randig , simon schmitt , and michael stoll .",
    "this research was supported in part by the advanced grant `` hologram '' of the european research council ( erc ) .",
    "there are a number of theoretical results available on the global dynamics of newton s method @xmath9 for a given polynomial @xmath3 .",
    "all require that a disk is known that contains all roots of @xmath3 .",
    "after appropriate rescaling , we may assume that all roots of @xmath3 are contained in @xmath10 .",
    "we showed in @xcite that there is a universal set of @xmath11 starting points , placed on @xmath12 concentric circles containing @xmath1 points each , so that newton s method started at these points will find all roots of all polynomials of degree  @xmath13 .",
    "this was improved in @xcite to a probabilistic set of starting points containing only @xmath14 starting points that find all roots with arbitrarily high probability .",
    "our earlier experiments in @xcite started with @xmath15 or @xmath16 equidistributed points on a single circle ; in many cases , @xmath15 points were sufficient , but always @xmath16 points were enough : this shows that in practice @xmath17 starting points seem to suffice , even though this is not supported by theory ( and there may well be special polynomials that require more starting points ) . of course , any additional factors like @xmath18 are hard to detect numerically , even when the degree ranges up to @xmath7 .    theoretical upper bounds on the expected number of required newton iterations were given in @xcite ; these are , up to polylogarithmic factors , on the order of @xmath19 or even @xmath20 .",
    "however , these previous methods all require at least @xmath21 iterations in order to find all roots : the methods rely on controlled newton dynamics away from @xmath10 , so all starting points @xmath22 are uniformly bounded away from the disk : @xmath23 for a uniform @xmath24 . however , on this domain we essentially have @xmath25 ( * ? ? ?",
    "* lemma  3 ) , so each orbit needs at least @xmath26 iterations until it even enters @xmath10 , and since at least @xmath13 orbits are required to find @xmath13 roots , we obtain a lower bound for the complexity of @xmath21 newton iterations .",
    "the upper bounds in @xcite are thus best possible , again up to polylogarithmic factors .",
    "one may try to remedy this problem by starting the iteration on a circle of radius , say , @xmath27 .",
    "such an approach comes with various problems .",
    "one is that we are losing the theory to guarantee that all roots will be found .",
    "another one is that this will be helpful only if a very tight bound for the smallest disk containing all roots is known , and only if most roots are near the boundary of that disk .",
    "this is not the case for instance for all polynomials considered by us ( but it is true if the coefficients of the polynomial are independently randomly distributed @xcite ) .",
    "one key observation is that the lower bound of the number of iterations comes from the iterations outside of @xmath10 , that is before the interesting dynamics even starts , and where all starting points are on very similar `` parallel '' orbits  a necessary consequence of the fact that we start the newton dynamics at points with controlled dynamics .",
    "typical initial orbits of the newton iteration are shown in figure  [ fig : paralleliterations ] .",
    "the approach we take in the experiments described in this paper is that on domains where orbits are `` parallel '' , fewer orbits are required , as indicated in figure  [ fig : newtonrefinement ] .",
    "starting points on a circle of radius @xmath28 ( here for a polynomial of degree @xmath29 , so we do not have enough starting points to find all roots ; the polynomial shown here describes periodic points of period dividing @xmath30 of @xmath31 ) .",
    "the apparent lines connect orbits under the newton dynamics ; colors indicate the number of iterations until an approximate root is found .",
    "the behavior of the iterations outside of the disk containing all roots is very parallel and `` wasteful '' , but required to carry over the control from the circle of starting points to the interesting dynamics on @xmath10 .",
    "observe that even if we had a very precise bound on the smallest disk containing all roots , this would not help much as most roots are away from the boundary of this disk .",
    ", scaledwidth=65.0% ]     points and refine only when adjacent orbits stop moving in parallel . as a result , most newton iterations are spent near the roots , and far fewer iterations are required .",
    "the polynomial is the same as in figure  [ fig : paralleliterations ] ( degree @xmath29 ) .",
    ", scaledwidth=65.0% ]    more precisely , we start the newton dynamics with a fixed number of , say , @xmath32 newton orbits on a circle away from @xmath10 where we have good control . along each triple of adjacent orbits",
    ", we compare the shapes of the triangles formed by the three points on adjacent orbits . as long as this shape remains nearly constant , so that the three orbits form nearly similar triangles , we keep iterating these three orbits , assuming that they represent similar dynamics for all orbits that might run between these three `` representative '' orbits .",
    "once the triangles start to deform , we split up these orbits by inserting an additional orbit half way between each of the two pairs of adjacent orbits ; see figure  [ fig : newtonrefinement ] .",
    "of course , this requires a heuristic refinement threshold parameter that describes the threshold of deformation after which parallel orbits are refined .",
    "we use the cross - ratio between three adjacent orbits with respect to @xmath33 : that is , @xmath34 where the index @xmath4 counts iterations and the index @xmath35 counts the circular order of the orbits ( with due modifications at the end to turn the linear order of natural numbers into a circular order ) .",
    "that is , without refinement , we have @xmath36 ; and when refinements occur , these are inserted into the circular order ( and the indices @xmath35 are shifted accordingly ) .    our refinement condition is essentially based on @xmath37 , where @xmath38 is the most recent iteration when a refinement occurred for this orbit ( properly accounting for index shifts because of refinements that might have occurred for other orbits ) .",
    "the algorithm is determined by a number of parameters that we determined heuristically :    * the number @xmath39 of initial orbits ( we usually use @xmath40 , but this should not make much of a difference ) ; * the maximal number of iterations a particular orbit can run for ( we use @xmath41 ) ; more important than this number is a good detection of periodic cycles ( if a positive fraction of orbits runs to the maximal number of allowed iterations , we end up at complexity @xmath21 ) ; * the maximal number of refinement generations ( we use @xmath42 ; that means that if all refinements have taken place , we end up with @xmath15 orbits ) ; * the refinement threshold @xmath43 : that is , the maximal value of @xmath44 that is allowed before further refinement occurs .",
    "most of the time , we use the value of @xmath45 , but for some experiments we had to increase sensitivity to @xmath46 ; * and a stopping criterion when success is declared that some orbit found a root : we stop when @xmath47 ; in practice , we use @xmath48 or sometimes @xmath49 ( while we used the ` long double ` data type with numerical precision of about @xmath50 relevant digits ) .    -1 finally , one needs a post - processing step : many roots will be found by several different orbits , and we have to make sure these roots are accounted for only once . here",
    "we use very simple - minded heuristics and declare that two orbits found different roots if they terminate at distance greater than @xmath51 ; here we use @xmath52 ( sometimes @xmath53 ) .",
    "of course , this requires an efficient way to sort the roots by mutual proximity ( when all roots are found by an algorithm that is linear up to log - factors , then for naive sorting procedures it is easy to spend more time on sorting than on root finding ) .",
    "of course all quantities are heuristic , and especially the choice of stopping criterion and post - processing ( distinguishing different roots found ) have obvious difficulties in the presence of high degrees or near - multiple roots .",
    "our point is not that this is a strong part of the algorithm , but that even with such a simple - minded approach all roots can be found for all the polynomials investigated , and for extremely large degrees .",
    "an improved approach for more `` challenging '' families of polynomials , especially with near - multiple roots , is discussed in @xcite .    in section",
    "[ sec : allrootsfound ] we describe several methods that establish a posteriori that all roots have been found with high accuracy .",
    "we investigate ( a subset of ) the same polynomials we already discussed in @xcite .",
    "we will briefly introduce the relevant families of polynomials and then present the results of the experiments .",
    "these polynomials have been chosen solely for the purpose of fast evaluation ( in terms of recursion ) : our focus is on root finding not efficient polynomial evaluation , so we chose polynomials where evaluation is easy . therefore , comparing our experiments with other experiments on different polynomials in terms of computing time yields an unfair bias in our favor , but comparisons in terms of the required number of newton iterations should be meaningful .",
    "these polynomials in a variable @xmath54 are defined by recursion @xmath55 , @xmath56 , so we have @xmath57 , @xmath58 , @xmath59 etc .",
    ", so that @xmath60 has degree @xmath61 . roots of @xmath60 are those parameters @xmath54 for which the iteration @xmath62 , @xmath63 is periodic with period ( dividing ) @xmath4 ; this implies that @xmath64 divides @xmath60 when @xmath65 divides @xmath4 ( using the fact that all roots of all @xmath60 are simple ; compare ( * ? ? ?",
    "* section  19 ) ) .",
    "roots of @xmath60 are known as _ centers of hyperbolic components of the mandelbrot set _ of period @xmath4 ( except those that are already roots of @xmath64 with @xmath66 ) .",
    "we found all roots for @xmath67 ( i.e.  degree @xmath68 , greater than 16 million ) in less than 160 hours ( on a standard pc using a single core ) .",
    "the detailed results are tabulated in figure  [ fig : mandelbrotcomplexitytable ] . in particular , we plot the complexity in terms of required newton iterations in figure  [ fig : mandelbrotiterationcomplexity ] : the diagram clearly shows that the complexity in terms of newton iterations scales better than @xmath69 .",
    "the complexity in terms of of computing time is shown in figure  [ fig : mandelbrottimecomplexity ] ; it seems to scale better than @xmath70 .",
    "this is of course related to the fact that our degree @xmath13 polynomials can be evaluated in @xmath71 operations .",
    "we realize that this is an untypical advantage of our polynomials .",
    "however , for polynomials given in coefficient form , there are fast methods of parallel evaluation at many points that should compensate for much of the complexity gain @xcite , ( * ? ? ?",
    "* section  8.5 ) ( these methods are efficient only when the number of evaluation points is comparable to the degree of the polynomial , which is the case for the newton algorithm because eventually all roots have to be found by their own newton orbit ) .    in order to find all roots , a significantly more sensitive refinement threshold of @xmath46 was used ( compared to @xmath45 used in the other experiments ) .",
    "we should point out that newton s method occasionally encounters attracting periodic orbits of periods greater than one .",
    "the total number of orbits that were detected to converge to attracting cycles of periods @xmath72 or more is shown in column j of figure  [ fig : mandelbrotcomplexitytable ] ; for large @xmath13 , this number seems to stabilize near @xmath73 ( column k and figure  [ fig : mandelbrothighercycles ] ) . while the total number of such orbits is relatively small",
    ", the orbits do not satisfy the easy - to - detect termination condition that a root is found , so the iteration times can be large . hence ,",
    "if such orbits are not caught efficiently , they will consume a lot of computing time .",
    "it turns out that for the mandelbrot center polynomials , far more attracting cycles were found than in most other experiments . for comparison , for the other families of polynomials investigated here ( periodic points of @xmath74 and @xmath75 ) , for degree @xmath76",
    "no attracting cycles were found at all , and for degree @xmath7 less than one hundred orbits converged to attracting cycles .",
    "( column g ) vs.  period .",
    "evidently the number of required iterations scales better than @xmath77 .",
    "]     ( column i ) . evidently , the time complexity scales better than @xmath70 ( in @xmath78 . ]    : for large @xmath13 , this number seems to stabilize near @xmath79 . ]      for the quadratic polynomial @xmath80 , a periodic point of period @xmath4 is a root of @xmath81 , where @xmath82 stands for the @xmath4-th iterate of @xmath83 .",
    "there are exactly @xmath84 periodic points of period @xmath4 .",
    "we found all periodic points of period @xmath85 , i.e.  for degree up to @xmath0 million , using a refinement threshold @xmath45 .",
    "the largest degree polynomial took about 89 hours .",
    "the results are given in detail in figure  [ fig : quadratic2complexitytable ] .",
    "the complexity in terms of required newton iterations is approximately @xmath86 ( see figure  [ fig : quadratic2iterationcomplexity ] ) .",
    "the computing time ( shown in figure  [ fig : quadratic2timecomplexity ] ) is in the order of @xmath87 for degrees @xmath13 up to 134 million .",
    "however , it oscillates significantly by almost a factor of @xmath72 . since we could not detect a clear reason for this oscillation , we ran the experiment twice .",
    "the outcome is very similar , except for large periods .",
    "these oscillations have no impact on the overall results of our experiments ( but should be investigated in future experiments )    note that this experiment would be outright impossible when expressing @xmath82 in coefficient form : the constant coefficient alone would have magnitude greater than @xmath88 , so for @xmath89 greater than @xmath90 .",
    "just storing this number would require about 15 megabytes per coefficient ( note that good relative precision is not sufficient because all the large terms are subtracted eventually ) , and we have to accommodate many million coefficients of possibly different magnitudes .     for periods @xmath85 ,",
    "divided by two scale functions .",
    "blue curve : time divided by @xmath91 ( column h in figure  [ fig : quadratic2complexitytable ] ) ; red curve : time divided by @xmath92 ( column i ) , multiplied by @xmath93 to adjust the scale .",
    "the time complexity seems to scale around @xmath94 ( in @xmath95 , with some fluctuations ) .",
    "two different runs of the same experiment are shown in different shades of color ( the number of iterations remained the same).,scaledwidth=75.0% ]     for periods @xmath85 , divided by two scale functions .",
    "blue curve : time divided by @xmath91 ( column h in figure  [ fig : quadratic2complexitytable ] ) ; red curve : time divided by @xmath92 ( column i ) , multiplied by @xmath93 to adjust the scale .",
    "the time complexity seems to scale around @xmath94 ( in @xmath95 , with some fluctuations ) .",
    "two different runs of the same experiment are shown in different shades of color ( the number of iterations remained the same).,scaledwidth=75.0% ]      we performed the same experiments for @xmath96 .",
    "the outcome was similar .",
    "we found ( almost ) all periodic points for periods up to @xmath89 , again with refinement threshold @xmath45 .",
    "this time , the computation was even faster : for period @xmath97 , it took 19 hours ( but 3 roots remained missing ) ; for @xmath98 , all roots were found in 9 hours .",
    "for periods @xmath85 .",
    "blue : iterations/@xmath99 ( column f in figure  [ fig : quadratic_i_complexitytable ] ) ; red : iterations/@xmath100 ( column g ) , multiplied by @xmath93 .",
    "the number of iterations seems to grow slightly faster than @xmath101 , but much slower than @xmath102 .",
    ", scaledwidth=72.0% ]    ) required for finding all periodic points of @xmath75 for periods @xmath85 , divided by three scale functions .",
    "blue curve : time divided by @xmath99 ( column h in figure  [ fig : quadratic_i_complexitytable ] ) ; red curve : time divided by @xmath91 ( column j ) , multiplied by @xmath103 to adjust the scale ; green curve : time divided by @xmath104 ( column i ) , multiplied by @xmath105 .",
    "the time complexity seems to scale with @xmath106.,scaledwidth=80.0% ]    one might argue that 3 out of 134 million roots missing are negligible . however , our goal is to find all roots without exception .",
    "of course we could have repeated the last experiment with slightly improved sensitivity .",
    "instead , we recovered the missing roots by different methods ; see section  [ sec : missingroots ] ) .",
    "interestingly , one was very near @xmath107 and the other two were very near @xmath108 .",
    "the computing time seems to oscillate somewhat unexpectedly in some of our experiments ( see for instance figure  [ fig : quadratic2timecomplexity ] ) .",
    "a natural explanation might come from the fact that the computers had some other tasks running on separate threads ( perhaps on separate cores ) , and while the actual computations would probably require the same amount of computing time , our memory - intense computations might suffer from unexpected memory swaps to the disk . a re - run of the most suspicious experiments showed of course the same number of newton iterations ( this part is deterministic ) , but also a rather similar oscillation of computing time as before ( also shown in figure  [ fig : quadratic2timecomplexity ] ) .    a first step to analyze this behavior consists of comparing computing time per number of newton iteration steps .",
    "since every newton iteration for our degree @xmath13 polynomials requires complexity @xmath12 , we show in figure  [ fig : computingtime_rescaled ] computing time divided by @xmath71 .",
    "not surprisingly , this is roughly constant for most series of experiments .",
    "interestingly , for the periodic points of @xmath75 one observes a certain decrease in @xmath13 .",
    "this might be explained by the fact that not most of the computing time is spent on the newton iterations , but other tasks require a significant fraction of the time .     because every evaluation of the polynomial should roughly have complexity @xmath71",
    "; combined for the three sets of experiments .",
    "interestingly , for some experiment these numbers seem to decrease .",
    "( this seems to indicate that the newton iterations do not use most of the computing time , perhaps because the recursion can be implemented particularly efficiently , so other tasks use a definite proportion of the computing time . ) of course , absolute numbers depend on the specific hard- and software used , but the relative behavior should be of structural interest .",
    ", scaledwidth=85.0% ]    of course , all computing times specified depend on the computer and its software used , in particular efficiency of the compiler and the number of cores available",
    ". therefore , the absolute scales are machine dependent and not very relevant ; however , we believe that the relative behavior for changing degrees is of structural interest .",
    "the issue of computing time oscillations warrants further study ( but stays within a factor of @xmath72 , often less , and is thus not relevant to the key findings of our experiments ) .",
    "we admit that our method is heuristic : we do not have an a - priori guarantee that all roots will be found by the iterated refinement newton algorithm . however , there are several possibilities for testing a posteriori that all roots have indeed been found .",
    "several of them have been described in detail in ( * ? ? ? * sections  2.3 and 2.4 ) , so we only briefly mention them here ; an additional method based on the newton identities is described in more detail .",
    "an easy observation shows that for any polynomial @xmath3 of degree @xmath13 with associated newton method @xmath109 , and for arbitrary @xmath110 , at least one root is contained in the disk @xmath111 with @xmath112 : so small newton displacement steps @xmath113 occur only near the roots .",
    "the factor of @xmath13 can be significantly improved if the approximate locations of many roots are already known ( * ? ? ?",
    "* lemma  4 ) . therefore ,",
    "if we have @xmath13 points ( coming from @xmath13 different newton orbits ) that all come with small disjoint disks containing at least one root , then they together describe all roots .",
    "this method worked in practice for all degree @xmath114 polynomials investigated in @xcite , but it requires that there are no near - multiple roots .    an independent and simpler test can be performed based on the vite formulas : the coefficients of the polynomial are the elementary symmetric functions of the roots and encode for instance the sum of all roots or their product , and thus provide independent tests of success .",
    "more systematically , one can easily compute the value of the power sums @xmath115 over all roots @xmath116 directly from the polynomial @xmath3 ; this approach is based on the well - known newton identities that relate the power sums to the coefficients of @xmath3 . comparing these with the power sums of all roots found is a natural generalization of the vite tests .",
    "we describe this in detail below ; the overall results are as follows .    in all experiments",
    "we describe , we found all roots according to the stopping and distinction criteria described in section  [ sec : iteratedrefinementnewton ] , and then used the power sum criterion to verify the roots found . for all our polynomials , even of maximal degrees , the power sum tests for exponents @xmath117 until @xmath118 were run successfully and give reason to conclude that newton s method with our ad - hoc stopping criterion described above ( requiring that @xmath119 ) found all roots with a typical accuracy of no more than @xmath120 .    as an example , for the @xmath121 periodic points of @xmath122 of period @xmath97 , the numerically computed power sum for @xmath117 was @xmath123 with a deviation of less than @xmath124 from the true integer value @xmath125 computed via the newton identities .",
    "if we assume that all roots were computed with equally and independently distributed errors of expected size @xmath126 , so that the summed error can be viewed as a brownian motion , then the total error of the sum should be on the order of @xmath127 .",
    "we can thus estimate @xmath128 .",
    "these results are discussed in section  [ sub : newtonidentitiespractice ] .      here",
    "we describe a systematic method for checking whether indeed all roots have been found that is based on the well known newton identities ( also known as newton - girard formulas ) that relate the coefficients of a polynomial ( which are up to sign the elementary symmetric functions of its roots ) to the power sums of all the roots .",
    "this method also makes it possible to locate missing roots in case not all were found ( see section  [ sec : missingroots ] ) .",
    "the idea is to use these identities to compute from the coefficients of the polynomial @xmath3 the sums of the powers of all roots of @xmath3 , then to subtract from these the sums of powers of all roots found : the closer this difference is to @xmath125 , the better the accuracy of the roots found .",
    "of course it is difficult to find all coefficients of @xmath3 ( and many of them often have extremely large absolute values ) ; but in order to compute the first @xmath129 power sums of the roots , only the top @xmath129 coefficients are required ( beyond the leading coefficient that we usually scale to @xmath130 anyway ) . for large degrees",
    ", even the top few coefficients can become very large in practice , and this may present numerical challenges .",
    "we start by writing @xmath131 .",
    "we have the leading coefficient @xmath132 , and the subsequent coefficients @xmath133 are ( up to sign ) the elementary symmetric polynomials in the roots @xmath134 we need the power sums @xmath135 for @xmath136 . they can be computed from the coefficients @xmath133 by the newton identities as follows : @xmath137 and so on for subsequent coefficients .",
    "therefore , each @xmath138 can be computed recursively from the @xmath133 and the previously computed @xmath139 .    in our applications ,",
    "the polynomial @xmath3 is not given in coefficient form , so in the first step the coefficients @xmath133 have to be computed . only the coefficients @xmath140 are required .",
    "they can be found easily using the recursion that defines @xmath3 : if in the recursion in every step only the @xmath129 top - most coefficients are kept , then the final result will correctly yield the desired coefficients @xmath141 .    to compute the coefficients @xmath133",
    ", one needs @xmath71 recursion steps , each with omplexity @xmath142 ( or less if more efficient multiplication is implemented ) , for a total of @xmath143 .",
    "the theoretical power sums @xmath138 for @xmath136 are computed through the newton identities , which are a triangular system of linear equations of dimension @xmath129 , so they are evaluated in complexity @xmath144 .",
    "both steps are negligible compared to the computation of the actual power sums from the roots found , which has complexity @xmath145 .      for the three families of polynomials , we computed the power sums for exponents @xmath146 , and compared them to the actual values computed using the newton identities .",
    "the differences are shown in figure  [ fig : newtonidentityprecision ] .",
    "( horizontal scale ) , for odd periods @xmath4 .",
    "top : centers of the mandelbrot set ; middle : periodic points of @xmath74 ; bottom : periodic points of @xmath75 .",
    "note that for the latter polynomials , the period @xmath147 graph includes three roots that were recovered using the newton identities .",
    "therefore , the values for @xmath148 are especially small ( these were used to reconstruct the three roots ) , while the others are relatively large ( due to the fact that the reconstructed roots have less precision than the others ) .",
    "the final @xmath89 graph is based on all roots found with maximal precision ( see section  [ sub : newtonidentitiespractics ] ) .",
    ", scaledwidth=80.0% ]    ( 0,0 ) ( -250,107)centers of the mandelbrot set     ( horizontal scale ) , for odd periods @xmath4 .",
    "top : centers of the mandelbrot set ; middle : periodic points of @xmath74 ; bottom : periodic points of @xmath75 .",
    "note that for the latter polynomials , the period @xmath147 graph includes three roots that were recovered using the newton identities .",
    "therefore , the values for @xmath148 are especially small ( these were used to reconstruct the three roots ) , while the others are relatively large ( due to the fact that the reconstructed roots have less precision than the others ) .",
    "the final @xmath89 graph is based on all roots found with maximal precision ( see section  [ sub : newtonidentitiespractics ] ) .",
    ", scaledwidth=80.0% ]    ( 0,0 ) ( -250,94.5)periodic points of @xmath74     ( horizontal scale ) , for odd periods @xmath4 . top : centers of the mandelbrot set ; middle : periodic points of @xmath74 ; bottom : periodic points of @xmath75 .",
    "note that for the latter polynomials , the period @xmath147 graph includes three roots that were recovered using the newton identities .",
    "therefore , the values for @xmath148 are especially small ( these were used to reconstruct the three roots ) , while the others are relatively large ( due to the fact that the reconstructed roots have less precision than the others ) .",
    "the final @xmath89 graph is based on all roots found with maximal precision ( see section  [ sub : newtonidentitiespractics ] ) .",
    ", scaledwidth=80.0% ]    ( 0,0 ) ( -250,104)periodic points of @xmath75    the observed errors are between @xmath149 and @xmath150 , not surprisingly with increasing errors for higher degrees and higher powers .",
    "within reasonably expected numerical error ( discussed below ) , we see these computations as convincing confirmation that indeed all roots were found .",
    "one way to model the error in these tests is to assume that all roots found have numerical errors of average size @xmath126 , distributed equally and independently . specifically for the power sums with exponent @xmath151 ,",
    "the sum is then a random walk of @xmath13 steps with average step size @xmath126 , so the accumulated error should be of size @xmath152 .",
    "figure  [ fig : expectederror ] shows that the results for @xmath151 are consistent with the interpretation that typically @xmath153 .    for @xmath154 , we encounter a precision issue for large numbers .",
    "let @xmath155 be the largest absolute values of the roots of a given polynomial ; we have @xmath156 for the mandelbrot centers , @xmath157 for periodic points of @xmath74 , and @xmath158 for periodic points of @xmath75",
    ". then @xmath159 for some @xmath35 .",
    "these numbers increase exponentially with large @xmath65 and",
    "are eventually subtracted from each other , or from the exact coefficients that in our cases are ( gaussian ) integers , so ( for number formats with fixed lengths mantissae ) the absolute errors in the sums increase with @xmath160 ; this would lead to approximately linear graphs in the accuracies shown in figure  [ fig : newtonidentityprecision ] , with slope @xmath161 . indeed , the average slopes are close to @xmath162 ( for the centers of the mandelbrot set ) , to @xmath163 ( for periodic points of @xmath74 ) , and to @xmath164 ( for periodic points of @xmath75 ) ; so in all three cases they are comparable to , and somewhat larger , than the predicted lower bounds of the accuracy . in any case , the most accurate tests for the achieved accuracy are those with low exponents @xmath65 .",
    ", for the three series of experiments ( vertical ) .",
    "the horizontal scale shows @xmath165 so that the degree is @xmath166 ( the periodic points have period @xmath165 , and the mandelbrot centers have period @xmath167 ) .",
    "observe that all values are of approximately constant size , mostly within a factor of @xmath168 .",
    "these data are consistent with the interpretation that all roots have been found with typical accuracy of at most @xmath169 . ,",
    "scaledwidth=80.0% ]    it might be interesting to report a few new challenges for these computations , coming from finite accuracy .",
    "one can use the newton identities in both directions : from the numerically computed power sums one can compute the coefficients and compare these with the true values from the polynomials , or do the computation backwards starting with the coefficients and compare the power sums .",
    "the latter approach , from coefficients to power sums , seems more natural in our case because we do most computations with ( gaussian ) integers , so without losing precisions .",
    "however , this involves _ much _ larger numbers ( our polynomials have very large coefficients , and we had to use integer arithmetic that can handle products of these without losing valid digits ) ; the computation in the other direction does not have the advantage of integers , but the numbers required are significantly smaller .",
    "another observation is that the very summation of the root powers loses valid digits .",
    "we had mentioned above that especially the high powers of the roots have limited absolute precision .",
    "in addition , when adding these large numbers , we often encounter very large sums ( consistent with the large predicted values from the newton identities ) .",
    "for instance , the powers @xmath170 for period @xmath89 of periodic points of @xmath74 sum up to about @xmath171 , which reduces the available absolute accuracy further .",
    "even when the power sum has small absolute value ( such as for @xmath172 for the same polynomial ) , the intermediate sums might become large before decreasing eventually ( especially when the roots found are sorted for instance by increasing real parts ) .",
    "we thus ran the addition a second time modulo @xmath130 and modulo @xmath35 , hence keeping track only of the fractional parts of the sums ( having checked that the integer part of the solution is consistent ) , so that all available accuracy can measure the difference to the exact integer value .",
    "the overall outcome of our three sets of experiments is that it is possible to find all roots of univariate polynomials of very large degrees in near - optimal complexity , both in terms of required newton iterations and in terms of computing time .",
    "all roots could be located for degrees up to 134 million , and the complexity per root is constant up to small logarithmic factors .",
    "the accuracy of all roots found is better than @xmath120 , comparable to the stopping condition @xmath173 .    in one of the experiments , for periodic points of period @xmath89 of @xmath75 , three of the more than @xmath0 million roots were missed .",
    "these could be recovered with good precision by a method described in section  [ sec : missingroots ] .",
    "a structural disadvantage of our iterated refinement newton root - finding method is that it does not come with an a priori guarantee that it will find all roots , and if in the end it turns out that some are missing , it is not clear where a refinement of starting points will recover the missing roots .",
    "this is different from the simpler linear scheme described in @xcite : there we usually start with @xmath15 equidistributed points on a single circle , and if some roots are missing , then this initial set of points can get refined for additional orbits .",
    "the crucial difference is that in the linear scheme from @xcite , every orbit starts at the same large circle surrounding all roots , so every orbit needs to run @xmath17 iterations before even getting close to the roots . in our iterated refinement newton algorithm",
    ", most orbits start very close to the roots , so far fewer iterations are required , but the refinement takes place away from the locus where we have good control .",
    "we gain a lot of speed at the expense of giving up guaranteed convergence .    indeed , in some experiments it does happen that the iterated refinement newton algorithm finds almost all roots , but several of the more than one million roots are missing ( in one case that we describe in detail , three out of @xmath0 million roots were missing ) .",
    "roots may be missing either because the refinement was not sensitive enough , or because the roots were found but not declared sufficiently different from nearby roots that were reported .    explicit deflation",
    "( dividing the original polynomial by the product of all linear factors corresponding to the roots found ) is tempting but not an option : just building all coefficients from the roots found has quadratic complexity , so this involves much higher effort than all of root finding . our global scheme does not have a way to pinpoint where the missing roots were lost , and thus where additional starting points are required to spot these .",
    "here we describe three methods , presumably well known , that have low complexity and that find missing roots efficiently when the number of remaining roots is small : if the given polynomial @xmath174 has degree @xmath13 and @xmath129 roots are missing , then the complexity of this post - processing is essentially @xmath145 , up to logarithmic factors .",
    "we are grateful to dario bini , victor pan and michael stoll for helpful suggestions here , and to marvin randig for substantial computational contributions .",
    "the idea of implicit deflation is to evaluate newton s method for @xmath180 in terms of @xmath3 and the roots found : we have @xmath181 and thus @xmath182 ( for products of polynomials , the logarithmic derivative is additive ) .",
    "we can thus evaluate @xmath183 using only @xmath184 ( which is computed by the usual newton method for @xmath185 ) and the roots found so far .",
    "if @xmath186 , then the final sum dominates the complexity : every iteration step of @xmath187 has complexity essentially @xmath17 , while the number of necessary newton iterations depends only on the degree @xmath129 of @xmath179 . depending on the efficiency of root finding for this ( relatively ) low degree polynomial , the number of required newton iterations is between @xmath188 and @xmath144 , so the total complexity of finding the remaining roots is between @xmath189 and @xmath190 .",
    "a second method to locate the missing roots is the ehrlich - aberth method ( which is underlying the successful implementation ` mpsolve ` to find all roots ) .",
    "this method is a parallel iteration in @xmath13 variables , where the @xmath191-th component is the newton method of @xmath192 and the @xmath193 are the current approximations to all @xmath13 roots . as with implicit differentiation",
    ", one does not need to compute @xmath194 explicitly for the newton displacement , but uses an analog of .",
    "all @xmath13 coordinates are updated simultaneously .",
    "if @xmath195 roots are already known , then this method is an iteration in only @xmath129 variables . in particular ,",
    "if @xmath196 , then implicit deflation equals the ehrlich - aberth method with @xmath197 coordinates fixed ; these two methods are thus closely related .",
    "a third method for locating missing roots is based on the newton identities described in section  [ sub : newtonidentities ] that relate the coefficients of a polynomial ( which are up to sign the elementary symmetric functions of its roots ) to the power sums of all the roots .",
    "this method may be in less frequent use , even though it is based on very classical ideas .",
    "it allows one to construct a polynomial @xmath179 of degree @xmath129 the roots of which are exactly the missing roots of @xmath3 .",
    "this polynomial will be constructed in terms of its coefficients using sums of different powers of the roots as well as newton s identities .",
    "the idea is to use these identities to compute from the coefficients of the polynomial @xmath3 the sums of the powers of all roots of @xmath3 , then to subtract from these the sums of powers of all roots found : we thus obtain the sums of powers of the missing roots , and from these one can compute the coefficients of @xmath179 by applying the newton identities backwards ( where @xmath179 as above is the polynomial that has exactly the missing roots ) .",
    "we describe this method in somewhat more detail .",
    "now suppose the @xmath195 roots @xmath198 of @xmath3 have already been computed , and @xmath129 roots @xmath199 are missing .",
    "we can compute their power sums @xmath200 from the @xmath138 and the @xmath195 roots found .",
    "finally , we are looking for the polynomial @xmath201 where the @xmath202 are the coefficients of @xmath179 .",
    "the coefficients @xmath202 can be determined from the @xmath203 using the newton identities backwards : @xmath204 therefore , once we know @xmath205 , we can find @xmath179 in coefficient form and then apply any root finder to this polynomial of degree @xmath129 .    in order to find the @xmath129 coefficients @xmath206 of @xmath179",
    ", only the power sums @xmath207 are required in the newton identities backwards , and hence only the power sums @xmath208 and the coefficients @xmath209 are required .",
    "we described earlier in section  [ sub : newtonidentities ] that these coefficients can be computed with little effort even when our polynomials @xmath3 are not given in coefficient form .",
    "the complexity of this method has been described in section  [ sub : newtonidentities ] : it is dominated by the computation of the power sums @xmath210 , which requires @xmath145 operations .",
    "the remaining computations for @xmath129 missing roots can be performed in @xmath143 operations .",
    "one structural advantage of this method is that the original roots are required only for the simple computation of the power sums , not for the subsequent root finding iteration . in our applications ,",
    "the roots were found on a different computer system than the one on which the missing roots were located , so not all @xmath195 previously found roots had to be transmitted , but only @xmath129 easily computed power sums ( it makes a substantial difference to transmit , or even to store , @xmath211 complex roots or @xmath212 power sums ) .",
    "this advantage comes with a certain disadvantage , though : the inaccuracies of all @xmath195 roots contribute equally to inaccuracies in the power sums , no matter how far they are from the missing roots ; in practice this limits the achievable accuracy of this method ( for the methods of implicit deflation or ehrlich  aberth , the inaccuracy of roots that are far from missing roots becomes far less important ) .",
    "the two purposes of newton identity , to find missing roots and to check the roots found and estimate the accuracy achieved , can be combined : after @xmath129 missing roots have been reconstructed using the first @xmath129 coefficients , one can compute @xmath213 additional coefficients and hence @xmath213 additional power sums , and use these to verify that now all roots have been found with great accuracy .      in this section ( performed in cooperation with marvin randig )",
    "we briefly describe how the reconstruction of the 3 missing roots among the @xmath7 periodic points of period @xmath97 of @xmath96 works , and illustrate the results and some practical challenges .",
    "we are interested in the roots of @xmath214 for @xmath89 .",
    "the coefficients are gaussian integers , and the first few have the following values : @xmath215 with @xmath216 ; the subsequent @xmath133 with @xmath65 odd vanish , while those with @xmath65 even are huge .",
    "the respective power sums from the newton identities have comparable sizes .",
    "subtracting the sum of 134 million numerically computed roots to obtain power sums of the three missing roots is a certain challenge to the numerics involved .",
    "roots found ( separated into integer and fractional parts , and displaying less accuracy than used ) , and the last column shows the numerical accuracy achieved for the sum of all @xmath7 roots , including the 3 recovered roots and the predicted value from column 2 .",
    "the odd powers @xmath130 , @xmath212 , @xmath168 were used to reconstruct the three missing roots and thus show large computational accuracy .",
    "the remaining powers @xmath217 , @xmath218 , @xmath219 indicate that all roots have been found with about ten digits accuracy ( probably much better for most roots ) .",
    ", title=\"fig:\",scaledwidth=95.0% ]    nonetheless , in this case the three missing roots were found : two were close to @xmath35 , and one was close to @xmath125 .",
    "this was done initially using the power sums @xmath130 , @xmath72 , and @xmath212 .",
    "however , we have @xmath220 , so in the subtraction 9 valid decimal digits are lost , which is a severe limitation to accuracy .",
    "therefore , the computations were redone using the power sums @xmath130 , @xmath212 , and @xmath168 for which no serious cancellations occur ( the odd power sums of all roots should vanish ) . the results are shown in figure  [ fig : threemissingroots ] .",
    "the third column shows that the odd power sums of the three missing roots must be equal to @xmath221 with an accuracy of @xmath222 , and indeed the three recovered missing roots are approximately @xmath223    the accuracy of these computations can be checked in the remaining power sums , as shown in the rightmost column in figure  [ fig : threemissingroots ] .",
    "the odd powers @xmath130 , @xmath212 , @xmath168 show only that the computations were self - consistent : the three roots were recovered so that these power sums are correct within a computational accuracy of about 16 digits .",
    "-1 the other power sums provide independent tests .",
    "the fact that they all match to about ten valid decimal digits can be taken as experimental confirmation that all roots were found to at least this precision ( but there are problems when two missing roots are very close to each other ; see below ) .",
    "we believe that the initial @xmath211 roots were found with accuracy of at least @xmath120 as in all other computations , so that the power sums have accuracy of around @xmath224 , and the accuracy of the three recovered roots should be comparable to this latter value ( much lower than the remaining roots because of the accumulated error in the large sums ) . this is consistent with the power sum for @xmath225 , and we argued above why power sums for higher powers have less accuracy even when the roots themselves have small errors .",
    "( for even powers , when the power sums were close to large gaussian integers , we again performed the computations twice , as described earlier : once to see that the sums are close to the desired gaussian integers , and once modulo gaussian integers to achieve higher absolute accuracy . )     for @xmath75 ( degree @xmath7 )",
    ". left : a detail near the missing root @xmath226 .",
    "black shows points for which the newton method with @xmath48 failed to find a root .",
    "comparison with figure  [ fig : newtonmarvin_1_19 ] ( same detail for the same polynomial , with @xmath227 ) shows that the problem was a sub - optimal stopping criterion : most black points actually converge to the missing root , which was however not recognized .",
    "right : the same polynomial with an even finer constant @xmath228 ( zoomed out ) : many more roots fail to be found .",
    "pictures by marvin randig.,title=\"fig:\",scaledwidth=47.0% ]   for @xmath75 ( degree @xmath7 ) .",
    "left : a detail near the missing root @xmath226 .",
    "black shows points for which the newton method with @xmath48 failed to find a root .",
    "comparison with figure  [ fig : newtonmarvin_1_19 ] ( same detail for the same polynomial , with @xmath227 ) shows that the problem was a sub - optimal stopping criterion : most black points actually converge to the missing root , which was however not recognized .",
    "right : the same polynomial with an even finer constant @xmath228 ( zoomed out ) : many more roots fail to be found .",
    "pictures by marvin randig.,title=\"fig:\",scaledwidth=47.0% ]    with these approximations , the three missing roots were found also by a refinement of the original newton iteration ; compare figures  [ fig : newtonmarvin_1_24 ] and [ fig : twomissingroots ] .",
    "improved approximations to these three roots are @xmath229 now with the same experimental accuracy as all other roots .",
    "a posteriori analysis reveals why the three roots were originally not found by our ad - hoc stopping criteria : for the first root , with our numerical accuracy we only achieve @xmath230 : we did have newton orbits that `` wanted to '' converge to the root , but the stopping criterion was too strict .",
    "the newton dynamics in figures  [ fig : newtonmarvin_1_19 ] and [ fig : newtonmarvin_1_24 ] ( left ) illustrates this : both show the same detail of the newton dynamics around this missing root , and both were computed with the algorithm described  except that in figure  [ fig : newtonmarvin_1_19 ] the requirement that @xmath231 was relaxed to @xmath232 .",
    "the black points in figure  [ fig : newtonmarvin_1_19 ] are points that do not converge to roots with the initial choice of @xmath233 .",
    "estimates using ( * ? ? ?",
    "* lemma  4 ) prove that the improved approximation to the first root is indeed close to a root with error at most @xmath234 ( probably better ) .",
    "the other two roots ( both near @xmath35 ) were missed because they were closer than @xmath52 from two other roots : in the first case , there was another root found at distance @xmath235 , and in the second case at distance @xmath236 , both somewhat smaller than @xmath237 in absolute value .    .",
    "the two missing roots near @xmath35 are indicated by blue dots together with the two nearby roots that were found ( manually inserted , not to scale : the distance between the pairs is @xmath238 , while the distance within both pairs is close to @xmath237 ) .",
    "picture by marvin randig.,width=257 ]    as we pointed out , the values of the constants in our algorithm were chosen in an ad - hoc fashion and obviously have to be adjusted for polynomials of extremely large degrees  but the underlying newton method is stable enough that it works well even with these ad - hoc criteria .    once the three missing roots were found to full precision as in , we compared their values with the approximations from the newton identities as in .",
    "for the root near @xmath107 , the error was @xmath239 , almost on the nose equal to the estimated value .",
    "however , for the two roots near @xmath35 , the error turned out to be equal to @xmath240 for both , much larger than expected .",
    "we provide an explanation below .",
    "observe first that the fact that both roots have errors with almost equal absolute values is due to the fact that they must match the sums of the first powers , so the deviations must be opposite to each other within the precision of the power sums .    the fact that the last two missing roots are very close to each other has to do with a particular property of our polynomial : all the roots we are looking for are periodic points of @xmath96 , so as a set they are invariant by @xmath241 .",
    "they are equidistributed with respect to harmonic measure on the julia set of @xmath241 , but all roots near @xmath107 are contracted by the quadratic map @xmath241 that has a critical point at @xmath107 , so the roots must be very close to each other near @xmath242 .",
    "the pairs of nearest roots are thus to be expected to be close to @xmath108 , and the trouble was caused by two such pairs .",
    "after the missing root near @xmath107 is recovered numerically with expected precision , the two missing roots near @xmath108 form a quadratic equation with an ( almost ) double root , given with some precision @xmath243 .",
    "in such a case , the roots only have precision @xmath244 , and this is what we experience here .",
    "it is an interesting fact that in the reconstruction of the last two missing roots , an extremely ill - conditioned quadratic equation causes substantial errors , while newton s method itself is able to find all @xmath7 roots ( many of them much closer to each other than this pair ) , even the three initially missing roots and the nearby roots close to them , without any issues of ill - conditioning ( except that we had to adjust our ad - hoc threshold parameters ) .",
    "of course , ill - conditioning is an ubiquitous experience , but it is remarkable how well newton can handle it .",
    "bla bollobs , malte lackmann , and dierk schleicher , _ a small probabilistic universal set of starting points for finding roots of complex polynomials by newton s method_. mathematics of computation * 82 * ( 2013 ) , 443457 .",
    "dierk schleicher and robin stoll , _",
    "newton s method in practice : finding all roots of polynomials of degree one million efficiently_. journal of theoretical computer science , to appear ( 2016 ) ."
  ],
  "abstract_text": [
    "<S> we present a practical implementation based on newton s method to find all roots of several families of complex polynomials of degrees up to @xmath0 million so that the observed complexity to find all roots is between @xmath1 and @xmath2 ( measuring complexity in terms of number of newton iterations or computing time ) . </S>",
    "<S> all computations were performed successfully on standard personal computers made in 2010/2011 , using only a single processor core . </S>"
  ]
}