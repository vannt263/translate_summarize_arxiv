{
  "article_text": [
    "in this paper , we develop som - based methods for the task of anomaly detection and visualization of aircraft engine anomalies .    the paper is organized as follows : section  [ sec : intro ] is an introduction to the subject , giving a small review of related articles . in section  [ sec :",
    "overview ] , the different components of the system proposed are being described in detail .",
    "section  [ sec : data ] presents the data that we used in this application , the experiments that we carried out and their results .",
    "section 4 presents a short conclusion .",
    "health monitoring consists in a set of algorithms which monitor in real time the operational parameters of the system .",
    "the goal is to detect early signs of failure , to schedule maintenance and to identify the causes of anomalies .",
    "here we consider a domain where health monitoring is especially important : aircraft engine safety and reliability .",
    "snecma , the french aircraft engine constructor , has developed well - established methodologies and innovative tools : to ensure the operational reliability of engines and the availability of aircraft , all flights are monitored . in this way , the availability of engines is improved : operational events , such as d&c ( delay and cancellation ) or ifsd ( in - flight shut down ) are avoided and maintenance operations planning and costs are optimized .",
    "this paper follows other related works .",
    "for example , @xcite have proposed the _ continuous empirical score _ ( ces ) , an algorithm for health monitoring for a test cell environment based on three components : a clustering algorithm based on em , a scoring component and a decision procedure .    in  @xcite",
    ", a similar methodology is applied to detect change - points in aircraft communication , addressing and reporting system ( acars ) data , which are basically messages transmitted from the aircraft to the ground containing on - flight measurements of various quantities relative to the engine and the aircraft .    in  @xcite , a novel _ star _",
    "architecture for kohonen maps is proposed .",
    "the idea here is that the center of the star will capture the normal state of an engine with some rays regrouping normal behaviors which have drifted away from the center state and other rays capturing possible engine defects .    in this paper",
    ", we propose a new anomaly detection method , using statistical methods such as projections on kohonen maps and computation of confidence intervals .",
    "it is adapted to large sets of data samples , which are not necessarily issued from a single engine .",
    "note that typically , methods for health monitoring use an extensive amount of expert knowledge , whereas the proposed method is fully automatic and has not been designed for a specific dataset .    finally , let us note that the reader can find a broad survey of methods for anomaly detection and their applications in  @xcite and @xcite .",
    "flight data consist of a series of measures acquired by sensors positioned on the engine or the body of the aircraft .",
    "data may be issued from a single or multiple engines .",
    "we distinguish between _ exogenous _ or _ environmental _ measures related to the environment and _ endogenous _ or _ operational _ variables related to the engine itself .",
    "the reader can find the list of variables in table  [ tab : variables ] .",
    "for the anomaly detection task , we are interested in operational measures",
    ". however , environmental influence on the operational measures needs to be removed to get reliable detection .",
    "+ exh & exhaustion gas temperature + n2 & core speed + temp1 & temperature at the entrance of the fan + pres & static pressure before combustion + temp2 & temperature before combustion + ff & fuel flow +   + alt & altitude + temp3 & ambient temperature + sp & aircraft speed + n1 & fan speed +   + eng & engine index + age & engine age +    the entire procedure consists of two main phases .    1 .",
    "the first phase is the _ training _ or _ learning _ phase where we learn based on healthy data .",
    "* we cluster data into clusters of environmental conditions using only environmental variables .",
    "* we correct operational measures variables from the influence of the environment using a linear model , and we get the residuals ( corrected values ) . * next , a som is being learned based on the residuals .",
    "* we calibrate the anomaly detection component by computing the confidence intervals of the distances of the corrected data to the som .",
    "the learning phase is followed by the _ test _",
    "phase , where novel data are taken into account .",
    "* each novel data sample is being clustered in one of the environment clusters established in the training phase . * it",
    "is then being corrected of the environment influence using the linear model estimated earlier . *",
    "the test sample is projected to the kohonen map constructed in the training phase and finally , the calibrated anomaly detection component determines if the sample is normal or not .",
    "an important point is the choice of the clustering method .",
    "note that clustering is carried out on the _ environmental _ variables .",
    "the most popular clustering method is the hierarchical ascending classification @xcite algorithm , which allows us to choose the number of clusters based on the explained variance at different heights of the constructed tree .",
    "however in this work our goal is to develop a more general methodology that could process even high - dimensional data and it is well - known that hac is not adapted to this kind of data .",
    "consequently , we are particularly interested in methods based on subspaces such as hddc  @xcite , since they can provide us with a parsimonious representation of high - dimensional data .",
    "thus , we will use hddc for the environment clustering , despite its less good performance for low - dimensional data .      in order to test the capacity of the proposed system to detect anomalies , we need data with anomalies . however , it is very difficult to get them due to the extraordinary reliability of the aircraft engines and we can not fabricate them because deliberately damaging the engine or the test cell is clearly not an option .",
    "therefore , we create artificial anomalies by corrupting some of the data based on expert specifications that have been established following well - known possible malfunctions of aircraft engines .    corrupting the data with anomalies",
    "is carried out according to a _ signature _ describing the defect ( malfunction ) .",
    "a signature is a vector @xmath0 .",
    "following @xmath1 , a corruption term is added to the nominal value of the signal for a randomly chosen set of successive data samples .",
    "figure  [ fig : anomaly_example - a ] gives an example of the corruption of the ff variable for one of the engines .",
    "figure  [ fig : anomaly_example - b ] shows the corrupted variable of the corrected data , that is , after having removed the influence of the environmental variables .      in order to build an anomaly detection component",
    ", we need a clustering method to define homogeneous subsets of corrected data .",
    "we choose to use the som algorithm  @xcite for its well - known properties of clustering organized with respect to each variable of the data as well as its visualization ability .",
    "the output of the algorithm is a set of prototype vectors that define an `` organized '' map , that is , a map that respects the topology of the data in the input space .",
    "we can then color the map according to the distribution of the data for each variable . in this way",
    ", we can visually detect regions in the map where low or high values of a given variable are located .",
    "a smooth coloring shows that it is well organized . in the next section ,",
    "we show how to use these properties for the anomaly detection task .      in this subsection , we present two anomaly detection methods that are based on confidence intervals .",
    "these intervals provide us with a `` normality '' interval of healthy data , which we can then use in the test phase to determine if a novel data sample is healthy or not .",
    "we have already seen that the som algorithm associates each data sample with the nearest prototype vector , given a selected distance measure . usually , the euclidean distance is selected .",
    "let @xmath2 be the number of the units of the map , @xmath3 the prototypes .",
    "for each data sample , we calculate @xmath4 , its distance to the map , namely the distance to its nearest prototype vector : @xmath5 where @xmath6 .",
    "note that this way of calculating distance will give us a far more useful measure than if we had just utilized the distance to the global mean , _",
    "i.e. _ @xmath7 .",
    "the confidence intervals that we use here are calculated using distances of training data to the map .",
    "the main idea is that the distance of a data sample to its prototype vector has to be `` small '' .",
    "so , a `` large '' distance could possibly indicate an anomaly .",
    "we propose a global and a local variant of this method .      during the training phase",
    ", we calculate the distances @xmath8 , @xmath9 , according to equation ( 1 ) .",
    "we can thus construct a confidence interval by taking the @xmath10-th percentile of the distances , @xmath11 , as the upper limit .",
    "the lower limit is equal to @xmath12 since a distance is strictly positive .",
    "we define thus the confidence interval  @xmath13 @xmath14 \\label{eq : global_confint}\\end{aligned}\\ ] ] for a novel data sample @xmath15 , we establish the following decision rule : @xmath16 the choice of the @xmath10-th percentile is a compromise taking into account our double - sided objective of a high anomaly detection rate with the smallest possible false alarm rate . moreover , since the true anomaly rate is typically very small in civil aircraft engines , the choice of such a high percentile , which also serves as an upper bound of the normal functioning interval , is reasonable .      in a similar manner , in the training phase",
    ", we can build a confidence interval for every cluster @xmath17 . in this way",
    ", we obtain @xmath2 confidence intervals @xmath18 , @xmath19 by taking the @xmath10-th percentile of the _ per _ cluster distances as the upper limit @xmath20 \\label{eq : local_confint}\\end{aligned}\\ ] ] for a novel data sample @xmath15 ( in the test phase ) , we establish the following decision rule : @xmath21",
    "in this section , we present the data that we used for our experiments as well as the processing that we carried out on them .    data samples in this dataset are snapshots taken from the cruise phase of a flight .",
    "each data sample is a vector of endogenous and environmental variables , as well as categorical variables .",
    "data are issued from @xmath22 distinct engines of the same type . for each time instant , there are two snapshots , one for the engine on the left and another one for the engine on the right .",
    "thus , engines appear always in pairs .",
    "snapshots are issued from different flights .",
    "typically , there is one pair of snapshots per flight .",
    "the reader can find the list of variables in table  [ tab : variables ] .",
    "the dataset we used here contains @xmath23 data samples and @xmath24 variables .",
    "we have divided the dataset into a training set and a test set . for the training set , we randomly picked @xmath25 data samples among the @xmath23 that we dispose of in total .",
    "the test set is composed of the @xmath26 remaining data samples .",
    "we have verified that all engines are represented in both sets .",
    "we have sorted data based on the engine i d ( primary key of the sort ) and for a given engine , based on the timestamp of the snapshot .",
    "we normalize the data ( center and scale ) because the scales of the variables were very different .",
    "clustering is carried out on environmental variables to define clusters of contexts .",
    "due to the large variability of the different contexts ( extreme temperatures very high or very cold and so on ) , we have to do a compromise between a good variance explanation and a reasonable number of clusters ( to keep a sufficient number of data in each cluster ) .",
    "if we compare hddc to the hierarchical ascending classification ( hac ) algorithm in terms of explained variance , we observe that the explained variance is about 50 % for five clusters for both algorithms .",
    "and as mentioned before , we prefer to use hddc  @xcite to present a methodology which can be easily adapted to high - dimensional data .",
    "let @xmath27 be the number of clusters .",
    "we correct the operational variables of environmental influence using the procedure we described in section 2 . after the partition into 5 clusters based on environmental variables , we compute the residuals of the operational variables as follows : if we set @xmath28 n1 , @xmath29 temp3 , @xmath30 sp , @xmath31 alt et @xmath32 age , we write @xmath33 where @xmath34 is one of the @xmath35 operational variables , @xmath36 is the engine index , @xmath37 is the cluster number , @xmath38 is the observation index .",
    "moreover , @xmath39 is the intercept , @xmath40 is the effect of the engine and @xmath41 the effect of the cluster .      by analyzing the residuals , one can observe that the model succeeds in capturing the influence of the environment on the endogenous measures , since the magnitude of the residuals is rather small ( between -0.5 and + 0.5 ) .",
    "the residuals therefore capture behaviors of the engine which are not due to environmental conditions .",
    "the residuals are expected to be centered , _",
    "i.e. _ to have a mean equal to @xmath12 . however , they are not necessarily scaled , so we re - scale them .    generally speaking ,",
    "since residuals are not smooth , we carry out smoothing using a moving average of width @xmath42 ( central element plus @xmath43 elements on the left plus @xmath43 elements on the right ) .",
    "we note that by smoothing , we lose @xmath44 data samples from the beginning and the end .",
    "therefore , we end up with a set of @xmath45 residual samples instead of the @xmath46 that we had initially .",
    "next , we construct a self - organizing map ( som ) based on the residuals ( figure  [ fig : som_app ] ) . we have opted here for a map of @xmath47 neurons ( @xmath48 ) because we need a minimum of observations per som cluster in order to calculate the normal functioning intervals with precision .",
    "endogenous variables .",
    "black cells contain high values of the variable while white ones contain low values .",
    "red dots refer to anomalies and green dots to healthy data for two different types of defects bearing on the variables n2 and exh .",
    "the proposed method clusters them in different regions of the map .",
    "the size of each dot is proportional to the number of points of the cluster.,scaledwidth=120.0% ]    the last step is the calibration of the detection component by determining the global and local confidence intervals based on the distances of the data to the map . for the global case , according to equation  [ eq : global_confint ] , we have : @xmath49\\end{aligned}\\ ] ] in a similar manner , we derive the upper limits of the local confidence intervals , ranging from @xmath50 to @xmath51 .      in the test phase",
    ", we assume that novel data samples are being made available .",
    "we first corrupt these data following the technique proposed in section  [ sec : anomalies ] .",
    "snecma experts provided us with signatures of @xmath24 known defects ( anomalies ) , that we added to the data . for data confidentiality reasons ,",
    "we are obliged to anonymize the defects and we refer to them as `` defect @xmath52 '' , `` defect @xmath53 '' etc .",
    "we start by normalizing test data with the coefficients used to normalize training data earlier .",
    "we then cluster data into environment clusters using the model parameters we estimated on the training data earlier .",
    "next , we correct data from environmental influence using the model we built on the training data . in this way , we obtain the test residuals , that we re - scale with the same scaling coefficients used to re - scale training residuals .",
    "we apply a smoothing transformation using a moving average , exactly like we did for training residuals .",
    "we use the same window size , _",
    "i.e. _ @xmath42 .",
    "smoothing causes some of the data to be lost , so we end up with @xmath54 test residuals instead of the @xmath26 we had initially .    finally , we project data onto the kohonen map that we built in the training phase and we compute the distances @xmath55 as in equation ( 1 ) .",
    "we apply the decision rule , either the global decision rule of  ( [ eq : decision_global ] ) or the local one of  ( [ eq : decision_local ] ) .    in order to evaluate our system",
    ", we calculate the detection rate ( @xmath56 ) and the false alarms rate ( @xmath57 ) : @xmath58    .detection rate ( @xmath56 ) and false alarm rate ( @xmath57 ) for different types of defects and for both anomaly detection methods ( global and local ) for test data . [ cols= \" < ,",
    "< , < , < , < \" , ]     in table  [ tab : taux ] , we can see detection results for all @xmath24 defects and for both detection methods ( global and local ) .",
    "it is clear that both methods succeed in detecting the defects , almost without a single miss .",
    "the global method has a lower false alarm rate than the local one .",
    "this is because in our example , confidence intervals can not be calculated reliably in the local case since we have few data per som cluster .",
    "figure  [ fig : gconfint ] shows the distance @xmath59 of each data sample ( samples on the horizontal axis ) to their nearest prototype vector ( equation  [ eq : dist ] ) .",
    "the light blue band shows the global confidence interval @xmath13 that we calculated in the training phase .",
    "red crosses show the false alarms and green stars the correct detections .        due to limited space in this contribution , the figures related to the local detection can be found in the following url : https://drive.google.com/folderview?id=0b0ejciu-platzzdqr25ovjnnatg&usp=sharing",
    "we have developed an integrated methodology for the analysis , detection and visualization of anomalies of aircraft engines .",
    "we have developed a statistical technique that builds intervals of `` normal '' functioning of an engine based on distances of healthy data from the map with the aim of detecting anomalies .",
    "the system is first calibrated using healthy data .",
    "it is then fully operational and can process data that was not seen during training .",
    "the proposed method has shown satisfying performance in anomaly detection , given that it is a general method which does not incorporate any expert knowledge and that it is , thus , a general tool that can be used to detect anomalies in any kind of data .",
    "another advantage of the proposed method is that the use of the dimension allows to carry out multi - dimensional anomaly detection in a problem of dimension @xmath52 .",
    "moreover , the representation of the operational variables given by the use of the distance to the som is of a higher granularity than that of the distance from the global mean .",
    "last but not least , the use of som allows us to give interesting visualizations of healthy and abnormal data , as seen in figure  [ fig : som_app ] .",
    "an extension of our work would be to carry out anomaly detection for datastreams using this method .",
    "a naive solution would be to re - calibrate the components of the system with each novel data sample , but it would be very time - consuming .",
    "instead , one can try to make each component of the system to operate on datastreams",
    ".    4 bouveyron , c. , girard , s. , and schmid , c. ( 2007a ) .",
    "high - dimensional data clustering . , 52(1):502519 .",
    "chandola , v. , banerjee , a. , and kumar , v. ( 2009 ) .",
    "outlier detection : a survey . , 41(3 ) .",
    "cme , e. , cottrell , m. , verleysen , m. , and lacaille , j. ( 2010a ) .",
    "aircraft engine health monitoring using self - organizing maps . in _ advances in data mining .",
    "applications and theoretical aspects _ , pages 405417 .",
    "cme , e. , cottrell , m. , verleysen , m. , lacaille , j. , et  al .",
    "( 2010b ) .",
    "self organizing star ( sos ) for health monitoring . in _ proceedings of the european conference on artificial neural networks _ , pages 99104 .",
    "duda , r.o . ,",
    "hart , p.e .",
    "( 1973 ) _ pattern classification and scene analysis_.",
    "new york : john wiley & sons , inc .",
    "kohonen , t. ( 2001 ) .",
    "_ self - organizing maps _ , volume  30 .",
    "lacaille , j. , cme , e. , et  al .",
    "sudden change detection in turbofan engine behavior . in _ proceedings of the the eighth international conference on condition monitoring and machinery failure prevention technologies _",
    ", pages 542548 .",
    "lacaille , j. and gerez , v. ( 2011 ) .",
    "online abnormality diagnosis for real - time implementation on turbofan engines and test cells .",
    "pages 579587 .",
    "lacaille , j. , gerez , v. , and zouari , r. ( 2010 ) . an adaptive anomaly detector used in turbofan test cells . in _ proceedings of the annual conference of the prognostics and health management society_. markou , m. ( 2003a ) . .",
    ", 83(12):24812497 .",
    "markou , m. ( 2003b ) . .",
    ", 83(12):24992521 ."
  ],
  "abstract_text": [
    "<S> we develop an application of som for the task of anomaly detection and visualization . to remove the effect of exogenous independent variables </S>",
    "<S> , we use a correction model which is more accurate than the usual one , since we apply different linear models in each cluster of context . </S>",
    "<S> we do not assume any particular probability distribution of the data and the detection method is based on the distance of new data to the kohonen map learned with corrected healthy data . </S>",
    "<S> we apply the proposed method to the detection of aircraft engine anomalies .    </S>",
    "<S> monitoring , aircraft , som , clustering , anomaly detection , confidence intervals </S>"
  ]
}