{
  "article_text": [
    "a crucial element of a ranking function is its evaluation design .",
    "research shows that for different types of applications , no single optimal ranking metric is robust enough to work generally  @xcite , and that all metrics disagree to some extent when relating rankings and user preferences .    consider the normalized form of the rank - based metric discounted cumulative gain @xmath1 ( @xmath0 )  @xcite , considered to be robust  @xcite .",
    "it allows users to associate multi - graded relevance judgments to items presented in a ranking , deviating from the common binary notion of relevance .",
    "it also uses discount factors to simulate user experience by decreasing the impact of the evaluation of a given item as you go through the ranking in a descending fashion , while most metrics weight the positions uniformly . despite the robustness of the metric",
    ", issues have been raised regarding its ad - hoc definition of relevance  @xcite .    in scenarios where baseline items scores are available and the divergence of such scores",
    "is considered an important factor , the evaluation design may require a greater detail on the impact of ranking errors .",
    "such requirements may be found in scenarios such as the recommendation of news based on their expected social popularity or the recommendation of stock options based on future winnings .",
    "given the issues raised by the standard ad - hoc definition of relevance  @xcite , these scenarios may require a principled manner of determining multi - graded relevance judgments of items in a finer granularity .",
    "consider the example of a news recommender system focused on anticipating the most popular daily news and suggesting them to users .",
    "this scenario is depicted in table  [ tbl : example ] , where the popularity score predicted by the system and the final popularity score are graded between @xmath2 and @xmath3 . in the example , the system recommends five news items on the first day and five other in the second day .",
    "# & news & recsys & baseline & & # & news & recsys & baseline + 1 & @xmath4 & 70 & 100 & & 1 & @xmath5 & 70 & 100 + 2 & @xmath6 & 50 & 80 & & 2 & @xmath7 & 50 & 20 + 3 & @xmath8 & 40 & 90 & & 3 & @xmath9 & 40 & 90 + 4 & @xmath10 & 15 & 15 & & 4 & @xmath11 & 15 & 15 + 5 & @xmath12 & 10 & 10 & & 5 & @xmath13 & 10 & 10 +    according to the final scores , the system made the same ranking error on both days by swapping the items on positions 2 and 3 .",
    "although the system made the same ordering error in both rankings , the error in the second day is considered more serious than the first .",
    "while permuting @xmath14 and @xmath15 seems acceptable given their similar final popularity score , the same does not happen when permuting @xmath7 and @xmath9 .",
    "this motivates the issue of how to correctly estimate the impact of ordering errors in ranking evaluation for such scenarios .",
    "since most ranking evaluation metrics disregard information portrayed in the scores ( _ e.g. _ distribution ) , they may over- or under - estimate rankings errors .    in this paper we show that the ad - hoc definition of relevance in @xmath0 poses issues of under- and over - estimation in the calculation of the metric , due to the disregard of the numerical scale of the ranked items scores .",
    "we then propose an automatic approach to attribute relevance judgments to items , accounting for the differences between their scores .",
    "our approach is evaluated in a synthetic and real - world scenarios and the differences in evaluation impact between the ad - hoc definition of relevance and our approach are discussed .    for the remainder of this paper we will use the terminology described in table  [ tbl : terminology ] .",
    "the paper is structured as follows . in section  [ sec : dcg ] the @xmath1 metric is described . the proposal to tackle the numerical scaling issue is presented in section  [ sec : solution ] . an experimental evaluation concerning the application of our proposal in the evaluation metric @xmath0",
    "is described in section  [ sec : exps ] .",
    "a discussion is provided in section  [ sec : discussion ] and conclusions presented in section  [ sec : conclusions ] .",
    ".list of terms used in the paper . [ cols=\"<,<\",options=\"header \" , ]",
    "the discounted cumulative gain ( dcg )  @xcite is composed of two sets of parameters : gain values and discount factors . the gain values are given by a function of ad - hoc relevance judgments associated to items in the ranking ( _ i.e. _ the higher the relevance , the higher the gain value , and vice - versa . ) .",
    "the discount factor is associated with the fact that the probability of a user seeing an item decreases as you go through the positions in a ranking .",
    "in essence , dcg is a weighted ( by the discount factor @xmath16 ) sum of the level of relevancy ( given by the gain values @xmath17 ) of the items in a rank @xmath18 of size @xmath19 , i.e. @xmath20 .",
    "this metric is commonly used in its normalized form , normalized discounted cumulative gain ( @xmath0 ) .",
    "the normalization is carried out as follows :    @xmath21    where the @xmath22 represents the maximum possible @xmath23 given by the optimal ranking order .    in literature concerning @xmath1 the two most popular forms of obtaining gain values ( @xmath17 ) are : _ 1 ) _ by using @xmath24 , and _ 2 ) _ through an exponential approach @xmath25 , where @xmath26 is the relevance judgment associated with a given item of index @xmath27 . to avoid ad - hoc relevance settings ,",
    "proposals have been made for data - driven approaches for learning gain values .",
    "zhou et al .",
    "@xcite propose a methodology capable of learning the gain values and discount factors from paired preferences of users .",
    "the authors modeled the problem as a special case of learning linear utility functions .",
    "demeester et al .",
    "@xcite propose the predicted relevance model ( prm ) to capture differences between assessor judgments and estimate the relevance of documents for random users .",
    "although related , these approaches are focused on learning the relevance of items by paired preferences of users . in our work",
    "we focus on problems where baseline scores are available ( _ e.g. _ retrieval scores ) and the problem is correctly determining the relevance judgment of items .",
    "we will base our work on the most common form of obtaining gain values : the exponential approach .    regarding the discount factor ( @xmath16 ) , according to wang et al .",
    "@xcite , there are at least two discount factors that guarantee the notion of consistent distinguishability .",
    "this notion states that for every pair of substantially different ranking functions , the ranking measure can decide which one is better in a consistent manner on almost all datasets .",
    "the authors concluded that both the logarithmic discount @xmath28 and the zipfian discount @xmath29  @xcite , where @xmath27 is the position of an item in the ranking , guarantee this property . in this paper",
    "we will assume the most commonly used , the logarithmic discount .    in @xmath1 ,",
    "the relevance judgments ( @xmath26 ) used to calculate gain values are commonly determined ad - hoc .",
    "the ad - hoc decision of relevance judgments may be problematic , as different judgments of relevance may derive different outcomes  @xcite .",
    "therefore , the decision concerning this parameter is crucial for the evaluation process .",
    "we find that previous work has neglected the impact of the numerical scale of ranked items scores . in applications of @xmath1 ,",
    "relevance judgments are usually defined as integer numbers in an increasing manner depicting levels .",
    "this approach may discard important information concerning the degree of divergence between items scores , potentially granting more or less relevance than in fact exists between ranked items , expressed by their respective true scores .",
    "therefore , in scenarios where the evaluation should also consider these score discrepancies between items in the ranking , we propose an automated , data - driven approach , for the definition of a degree of divergence relevance function , used to compute the relevance judgments ( @xmath26 ) of each item in a given set , then incorporated in the metric @xmath1 .",
    "let @xmath30 be a set of @xmath19 items , @xmath31 the respective set of scores and @xmath32 a set of relevance judgments @xmath33 associated to @xmath34 . given a ranking function _",
    "f _ that orders @xmath30 according to the respective @xmath31 scores in a decreasing fashion , the resulting ranking list @xmath35 satisfies the condition @xmath36 .",
    "our hypothesis is that the ad - hoc definition of relevance judgments in @xmath0 may under- or over- estimate the results of the metric due to the disregard of the distribution of the ranked items scores .",
    "we illustrate this scenario with a concrete example .",
    "let @xmath37 and @xmath31 a distribution of uniformly generated scores between @xmath2 and @xmath38 .",
    "for example purposes , we define in an ad - hoc manner that the judgments of relevance for an instance space of @xmath39 are as such : items with the top-10 scores have a relevance of @xmath40 , the remaining items in the top-25 scores a relevance of @xmath41 , the remaining items in the top-50 scores a relevance of @xmath2 , and the following items a relevance of @xmath42 .",
    "let us assume that a recommendation system proposes a ranking where the top 10-@xmath43 and top-@xmath44 items are permuted .",
    "given the uniform distribution of the generated scores in this example , the divergence of score @xmath45 between these two items should be residual .",
    "however , when computing @xmath0 using the previous ad - hoc parameters for relevance , we incur in a penalization that is disproportionate to the concrete score divergence between the items . this situation may also occur amongst items with the same relevance judgment , since items with a considerable score divergence may be attributed the same ad - hoc relevance .",
    "these examples coarsely show how the ad - hoc definition of relevance in @xmath0 may incur in a disproportionate penalization of the evaluation when considering the degree of divergence amongst items scores .",
    "furthermore , they show the interest of using a principled approach to the definition of relevance judgments , motivating our proposal described in the next section .",
    "the approach proposed in this paper consists of the interpolation of relevance judgments , based on the degree of divergence between ranked items scores .",
    "the interpolated relevance judgments are used to calculate gain values used in the evaluation metric @xmath0 . in this paper",
    "we stipulate that relevance judgments are bounded by @xmath46 , \\mathbb{r}$ ] , where @xmath42 is least relevant , and @xmath2 is most relevant .    to interpolate relevance judgments , we use piecewise cubic hermite interpolating polynomials  @xcite ( _ pchip _ ) in order to define the appropriate relevance function .",
    "this is done by interpolating a set of relevance judgments using specified control points .",
    "the choice of interpolation method was based on its simplicity and effectiveness in interpolating discrete data . moreover , by restricting the first derivative values at the control points they are capable of preserving local positivity , monotonicity and convexity of the data .",
    "these are most convenient properties in the context of our target scenarios , as we want to induce a continuous function reproducing , as closely as possible , the control points provided .",
    "we note that the control points are domain - dependent .",
    "this allows for our approach to meet the specifics of each domain .",
    "nonetheless , for the purposes of this paper we use as control points the minimum , median and maximum value of @xmath31 scores , introducing the following constraints to the interpolation process :    1 .",
    "all items @xmath47 with a respective score @xmath48 smaller than the median score have a relevance of @xmath42 ( _ i.e. _ non - relevant ) : the minimum and median score have a relevance judgment of @xmath42 ; 2 .   for the remaining items",
    ", relevance is interpolated from @xmath46 $ ] , where the item with median score @xmath49 has a relevance of @xmath42 and the item with maximum score has a relevance of @xmath2 ;    in case there are items with extremely large scores , this formulation may not be enough to correctly bias the evaluation of proposed rankings . in effect , in such situations we need to make sure these items with extremely high scores get properly ranked .",
    "therefore , one wants to penalise more seriously any ranking errors involving these cases . with this goal in mind , we bias our interpolation function to give these extremes a very high relevance judgement , and to clearly distinguish their relevance from that of non - extreme items .",
    "the box plot rule  @xcite says that any value larger than @xmath50 ( known as the upper whisker ) , where @xmath51 is the third quartile of a distribution and @xmath52 is the inter - quartile range , should be considered extreme , i.e. an outlier .",
    "we use this rule to determine if there are extreme values in our scores .",
    "if it is the case , we add a new control point to bias our interpolation function to assign relevance judgements that penalise ranking errors involving the items with these extreme scores .",
    "more specifically , the item with a score corresponding to the upper whisker will obtain a relevance judgement of @xmath53 , where @xmath54 is defined as    @xmath55    to illustrate , in figure  [ fig : relexample ] we show two examples of relevance functions using our approach using artificially generated data : one for cases without outliers , and another for cases with outliers .        in summary",
    ", we define the relevance judgements of items , used in calculating gain values of @xmath0 , through the application of @xmath56 using the above mentioned control points .",
    "we call the resulting relevance function @xmath57 , which is then used in the formula of @xmath0",
    ". we will refer to this proposed variant as @xmath58 .",
    "in this section we present two sets of results regarding synthetic and real - world application data .",
    "the synthetic data experiments show that in given situations of rank ordering , the impact of the degree of divergence in items scores is observed , and the standard @xmath0 may under- or over - estimate the results . by using real - world data , the objective is to show the difference between the standard @xmath0 and @xmath58 , and the impact of our proposal .",
    "both experiments use the cut - off version of @xmath0 ( @xmath59 ) .",
    "the cut - off version only considers the top @xmath60 items .",
    "we generated rankings using the example described in section  [ sec : solution ] with the sets of items @xmath30 and score @xmath31 of size @xmath37 .",
    "the set of ad - hoc relevance judgments @xmath32 used by the standard @xmath59 is also defined as in the example from section  [ sec : solution ] . in this experiment",
    "we set @xmath61 ( _ i.e. _ @xmath62 ) .",
    "two types of distribution of the @xmath31 scores are included : balanced and imbalanced . in the former , @xmath31 scores are uniformly generated within the interval of @xmath63 $ ] .",
    "as for the latter , 90% of the scores are generated within the interval of @xmath64 $ ] and 10% within the interval of @xmath65 $ ] .",
    "we describe two scenarios that illustrate concrete situations where our stated hypothesis may be proven .",
    "consider an ideal rank @xmath66 where @xmath27 is the position of a ranked item , @xmath67 .",
    "the testing scenarios are the following :    * scenario 1 : to exemplify a permutation of items with different ad - hoc relevance judgments , @xmath68 is permuted with @xmath69 : @xmath70 ; * scenario 2 : corresponds to an inverted ideal rank @xmath71 .    for each scenario and type of distribution",
    "we generated 1000 random samples of @xmath31 scores .",
    "for each of these cases we calculate the respective @xmath62 ( horizontal line ) and @xmath72 ( box plot ) scores .",
    "please note that as @xmath62 is insensitive to the @xmath31 scores and the relevance judgments are fixed ( top-10 items scores have a relevance judgment of @xmath40 , remaining items in top-25 items scores have a relevance judgment of @xmath41 , @xmath73 ) , the evaluation score is constant for the 1000 samples . in figure",
    "[ fig : synthetic ] we present the outcome of the compared evaluation between @xmath62 and @xmath72 .",
    "( horizontal line ) and @xmath72 ( box plot ) in two scenarios , by type of distribution.,width=302 ]    in scenario 1 , where items in position @xmath74 and @xmath75 are permuted , we observe similar results by both metrics .",
    "nevertheless , a fluctuation of @xmath72 results shows that , in the majority of cases , the standard @xmath62 over - estimates the impact of the ordering error in both the balanced and imbalanced distributions . in scenario 2 , depicting an inverted ideal rank , results show that @xmath72 varies considerably .",
    "this shows the impact of the underlying distribution of ranked items scores , when considered . according to the results in this scenario , the standard @xmath62 metric under - estimates the impact of the ordering errors in both the balanced and imbalanced distributions .",
    "moreover , we note that the impact of our proposal concerning the imbalanced distribution is much greater .",
    "this outcome shows the impact that the type of distribution has on both evaluations . as expected ,",
    "when the scores are more imbalanced the ranking errors tend to have a greater impact on the evaluation , and the @xmath72 metric is able to capture this in terms of overall evaluation of the rankings .",
    "given our hypothesis that the ad - hoc definition of relevance judgments in @xmath62 may under- or over - estimate the results of the metric due to the disregard of the distribution of ranked items scores , results from this experiment show that our hypothesis has empirical grounds .      in this set of experiments , we used data from google news and twitter .",
    "news items were retrieved from google news over a timespan of six months ( between june 1st and december 31st 2015 ) for four different topics : _ economy , microsoft , obama , _ and _ palestine_. during the collection period , a query for each topic was posed every 30 minutes , and the top-100 news were retrieved . for each news item retrieved , we collected its position in the google news ranking .    using the twitter api of november , 2015 . ]",
    "we retrieved the number of times the news was tweeted in the two days following its publication .",
    "the two days limit was decided considering the work of yang and leskovec  @xcite .",
    "the number of times a news item was tweeted is used as its score , and considered a proxy for its popularity for end - users . for each google news ranking",
    ", the ground - truth is given by a descending order ranking of the number of tweets obtained by each ranked item .",
    "this data set contains approximately 9.795 rankings per topic and a total of 107.590 news items where 6.468 items ( 6% ) were not published in twitter .",
    "an evaluation of each ranking produced by google news using @xmath59 and @xmath76 is depicted in figure  [ fig : realworldexp ] .",
    "the objective is to illustrate the overall differences between both metrics for different values of @xmath60 in all four topics : @xmath77 , @xmath74 , @xmath78 and @xmath79 .",
    "the ad - hoc relevance judgments used in the standard @xmath0 are those described in section  [ sec : solution ] .",
    "results show that the average evaluation of the rankings using the standard ad - hoc @xmath0 metric consistently shows better evaluation scores in comparison to @xmath58 . considering that the @xmath58 metric accounts for the items scores divergence",
    ", this analysis shows that despite the increasing value of @xmath60 and the topic evaluated , the @xmath0 metric tends to under - estimate the impact of ordering errors in the rankings .",
    "therefore , the results obtained show that our approach is useful for evaluation scenarios where items scores are available and the divergence between scores is an important a factor .",
    "the use of @xmath58 allows for an evaluation that shows a greater sensibility to the degree of divergence between ranked items , in comparison to the ad - hoc definition of relevance in the standard @xmath0 .",
    "considering the results of the experimental evaluation in both the synthetic and real - world settings , we have shown the interest of our proposal . by proposing a data - driven approach for the definition of relevance functions and its application in the popular @xmath0 evaluation metric we allow for a much finer - grain process for evaluating rankings . also , we show that our proposal is capable of correcting to some extent the issues of under- and over- evaluation related to the common use of ad - hoc relevance judgments in the @xmath0 metric .",
    "consider the analysis shown in figure  [ fig : realworld ] . in this figure",
    "we use a sample ( 2000 rankings ) of the results from the evaluation presented in section  [ subsec : realworld ] and compare the scores of both @xmath62 and @xmath72 metrics , in all topics .",
    "it illustrates the score differences of both metrics ( the @xmath80axis shows the value of @xmath81 ) .",
    "this shows that both metrics tend to evaluate the recommended rankings differently . analyzing the differences between both metrics",
    ", we learn that @xmath62 tends to assign a higher evaluation score to rankings , depicted by the differences between the two metrics being more frequently positive .",
    "also , it shows that this difference tends to increase with higher evaluation scores from @xmath62 . the fact that we observe these differences mean",
    "that in the real world scenario used , the variability of the scores that originate the rankings is present and significant , otherwise our proposal would not differ so much from standard @xmath62 . given the increasing throughput of online data and the changes ( _ i.e. _ seasonality , unexpected behaviour ) in user behaviour , this also shows the adaptability of our proposal and its contribution to the problem of evaluating rankings .",
    "finally , we should clarify that in light of the scenarios described in this paper , the ad - hoc definition of relevance judgments commonly used with the @xmath0 metric is naturally prone to the under- or over - evaluation issues described .",
    "this is due to the level - like depiction of relevance commonly used .",
    "nonetheless , the interest of our proposal lies on it being a principled way of depicting relevance judgments and thus bypassing the issues raised by the common ad - hoc definition .",
    "in this paper we study the performance of the metric normalized discounted cumulative gain ( @xmath0 ) in light of the numerical scale and distribution of ranked items scores .",
    "we show that the standard @xmath0 presents evidence of under- and over - estimating ordering errors in rankings due to the use of ad - hoc relevance judgements and the disregard for the underlying distribution of the items scores , when available and considered .",
    "we propose a data - driven approach capable of , under different types of distributions , interpolating the relevance of the items in a ranking , based on the degree of the divergence amongst the items scores .",
    "two sets of experiments were carried out , empirically showing the interest of our proposal resorting to specific scenarios , and by demonstrating its usefulness in a real - world scenario , in comparison to the ad - hoc definition of relevance judgments used in standard @xmath0 metric .",
    "future work will involve the extension of experiments to enable a more detailed explanation for the difference in results between the two metrics .",
    "additionally , we wish to study the possibility of using this approach with other ranking evaluation metrics .    for reproducibility , all code ( written in * r * ) and data necessary to replicate the results are available in the web page http://tinyurl.com/h454dry .",
    "this work is financed by the erdf ",
    "european regional development fund through the compete 2020 programme within project poci-01 - 0145-feder-006961 , and by national funds through the fct ",
    "fundao para a cincia e a tecnologia ( portuguese foundation for science and technology ) as part of project uid / eea/50014/2013 .",
    "it is also financed by the project `` tec4growth - pervasive intelligence , enhancers and proofs of concept with industrial impact / norte-01 - 0145-feder-000020 '' , which is financed by the north portugal regional operational programme ( norte 2020 ) , under the portugal 2020 partnership agreement , and through the european regional development fund ( erdf ) .",
    "the work of n. moniz is supported by a phd scholarship of fct ( sfrh / bd/90180/2012 ) .",
    "demeester , t. , aly , r. , hiemstra , d. , nguyen , d. , develder , c. : predicting relevance based on assessor disagreement : analysis and practical applications for search evaluation .",
    "information retrieval journal 19(3 ) , 284312 ( 2016 )"
  ],
  "abstract_text": [
    "<S> ranking evaluation metrics are a fundamental element of design and improvement efforts in information retrieval . </S>",
    "<S> we observe that most popular metrics disregard information portrayed in the scores used to derive rankings , when available . </S>",
    "<S> this may pose a numerical scaling problem , causing an under- or over - estimation of the evaluation depending on the degree of divergence between the scores of ranked items . </S>",
    "<S> the purpose of this work is to propose a principled way of quantifying multi - graded relevance judgments of items and enable a more accurate penalization of ordering errors in rankings . </S>",
    "<S> we propose a data - driven generation of relevance functions based on the degree of the divergence amongst a set of items scores and its application in the evaluation metric normalized discounted cumulative gain ( @xmath0 ) . </S>",
    "<S> we use synthetic data to demonstrate the interest of our proposal and a combination of data on news items from google news and their respective popularity in twitter to show its performance in comparison to the standard @xmath0 . </S>",
    "<S> results show that our proposal is capable of providing a more fine - grained evaluation of rankings when compared to the standard @xmath0 , and that the latter frequently under- or over - estimates its evaluation scores in light of the divergence of items scores . </S>"
  ]
}