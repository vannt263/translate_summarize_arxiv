{
  "article_text": [
    "for a hermitian operator @xmath0 in a finite dimensional inner product space , the rayleigh - ritz method finds the stationary values , called `` ritz values , '' of the rayleigh quotient @xmath4 on a given subspace as approximations to eigenvalues of @xmath0 . if this `` trial '' subspace is @xmath0-invariant , i.e. ,  invariant with respect to @xmath0 , the ritz values are exactly some of the eigenvalues of @xmath0 . given two finite dimensional subspaces @xmath1 and @xmath2 of the same dimension , such that @xmath1 is @xmath0-invariant , the absolute changes in the ritz values of @xmath0 with respect to @xmath1 compared to the ritz values with respect to @xmath2 represent the absolute eigenvalue approximation error .    a priori error bounds for eigenvalues approximated by",
    "the ritz values form one of the classical subjects in numerical linear algebra and approximation theory .",
    "such error bounds are used , e.g. ,  to estimate convergence rates of iterative methods for matrix eigenvalue problems . in approximation theory , the rayleigh - ritz method is the most common technique of approximating eigenvalues and eigenvectors of operators , e.g. ,  @xcite ; and _ a priori _ error bounds characterize the approximation quality .",
    "a priori _ bounds are known ; see , e.g. ,  @xcite and references there .",
    "a priori error bounds for eigenvalues in @xcite are based on the concept of angles between subspaces  one of the major ideas in multivariate statistics , closely related to canonical correlations .",
    "this concept also has applications in linear functional analysis and operator theory .",
    "the use of angles between subspaces for eigenvalue bounds is quite natural and may result in elegant and sharp estimates .",
    "majorization is another classical area of mathematics with numerous applications , in particular , for estimates involving eigenvalues and singular values .",
    "this paper includes all the necessary material on majorization , but should not serve as an introduction to the subject .",
    "we follow and refer the reader to @xcite , where background and references to original proofs can be found .    in the pioneering results of @xcite ,",
    "majorization is applied to bound eigenvalue errors _ a posteriori _ in the framework of angles between subspaces .",
    "a similar approach for _ a priori _ rayleigh - ritz error bounds is first developed in @xcite , e.g. ,   a bound with a sharp constant is proved if @xmath1 corresponds to a contiguous set of extreme eigenvalues of @xmath0 .",
    "our first major bound , of theorem [ thm_proximity_paper ] , extends the result of @xcite to the general case of an arbitrary @xmath0-invariant subspace @xmath1 , which solves ( * ? ? ?",
    "* conjecture  3.1 ) .",
    "moreover , our new proof , with small modifications , also covers the main result of @xcite .",
    "thus , our two bounds and of theorem [ thm_proximity_paper ] supersede all main rayleigh - ritz error bounds of @xcite .",
    "our proof is based on a new generalized pinching inequality for singular values and eigenvalues , theorem [ th : pin ] , which is a natural extension of the standard pinching inequality , e.g. ,  ( * ? ? ?",
    "* problem ii.5.4 ) .",
    "next , for the particular case of extreme eigenvalues in theorem [ thm_invariant2 ] we improve bound , by replacing the scalar constant in the bound with a vector of constants on the right - hand side .",
    "this is a delicate result ",
    "if one divides both sides of the improved bound , , by the vector of the constants , the statement no longer holds .",
    "our second main result , theorem [ thm : mult ] , is a majorization rayleigh - ritz error bound of multiplicative type , which deals with the products of the errors , rather than the sums .",
    "it allows us to establish majorization bounds for the relative errors , in theorem  [ cor1gr ] .",
    "finally , we extend our bounds to the case @xmath3 in infinite dimensional hilbert spaces , preparing for section [ s : fem ] .",
    "we apply our rayleigh - ritz majorization error bounds in the context of the finite element method ( fem ) , and briefly show how they improve the constant for a known fem eigenvalue error bound from @xcite in section [ s : fem ] .",
    "there are numerous traditional bounds in the form of vector inequalities developed over the decades by many mathematicians .",
    "the question concerning how the traditional and majorization bounds compare naturally arises .",
    "it appears feasible that properly formulated majorization bounds would eventually outperform and thus replace most conventional bounds .",
    "we already have examples of such a comparison in the present paper , but much more work in this direction is needed and will follow .",
    "we introduce definitions and after a brief motivation present theorems and conjectures on _ a priori _ majorization eigenvalue error bounds using principal angles between subspaces .",
    "we describe related results of @xcite that precede the developments of the present paper .",
    "we give only the definition of majorization here and refer the reader to subsection [ sect.majorization ] for an overview of some facts on majorization that we use . for a real vector",
    "@xmath5 $ ] let @xmath6 be the vector obtained by rearranging the entries of @xmath7 in an algebraically decreasing order , @xmath8 we use the term `` decreasing '' for `` nonincreasing '' , and `` increasing '' for `` nondecreasing '' , for conciseness .",
    "we say that vector @xmath9 weakly ( sub-)majorizes vector @xmath7 and we use the notation @xmath10 if @xmath11 .",
    "if in addition @xmath12 we write that vector @xmath9 ( strongly ) majorizes vector @xmath7 , which is denoted by @xmath13 .",
    "we overload the notation for scalars , e.g. , @xmath14 may denote the vector of ones .",
    "nonnegative vectors with different numbers of entries are compared by adding zero entries .",
    "let @xmath15 be a finite dimensional real or complex vector space , equipped with an inner product @xmath16 .",
    "this abstract inner - product space setting is justified by generalizing , in subsection [ ss : hilb ] , some of our results to the case of infinite dimensional hilbert spaces .",
    "we denote the vector of eigenvalues of a linear hermitian operator @xmath17 by @xmath18 , and keep the same notation for hermitian matrices .",
    "we assume that the vector of eigenvalues @xmath19 is arranged in decreasing order , i.e. ,  @xmath20 .",
    "multiple eigenvalues appear in @xmath19 repeatedly according to their multiplicities .",
    "we define singular values of a linear operator @xmath21 as @xmath22 , and keep the same notation for ( rectangular ) matrices , in which case the operator adjoint @xmath23 is replaced by the complex conjugate matrix transpose @xmath24 .",
    "let @xmath25 be a linear hermitian operator and @xmath26 and @xmath27 be orthoprojectors onto subspaces @xmath1 and @xmath2 with @xmath28 .",
    "we first give a brief description of ritz values .",
    "we define the rayleigh - ritz operator @xmath29 on @xmath1 , where @xmath29 denotes the restriction of the operator @xmath30 to its invariant subspace @xmath1 .",
    "the eigenvalues @xmath31 are called ritz values of the operator @xmath0 with respect to the subspace @xmath1 . in the particular case",
    "@xmath32 for a nonzero vector @xmath7 we define the rayleigh quotient @xmath33 . if @xmath1 is @xmath0-invariant , the ritz values @xmath31 are some of the eigenvalues of @xmath34 for two subspaces @xmath1 and @xmath2 of the same dimension , such that @xmath1 is @xmath0-invariant , and @xmath2 approximates @xmath1 , it is natural to expect that the ritz values @xmath35 approximate the subset of the eigenvalues of @xmath0 given by @xmath31 .",
    "the absolute changes in the ritz values of @xmath0 with respect to @xmath1 compared to the ritz values with respect to @xmath2 thus represent the absolute eigenvalue approximation error .",
    "the vector of cosines squared of principal angles _ from _ the subspace @xmath1 _ to _ the subspace @xmath2 is defined by @xmath36 where the eigenvalues of @xmath37 are rearranged in increasing order , so that the cosines are increasing , while the angles are defined such that @xmath38 . in other words , the cosine squared of angles from @xmath1 to @xmath2 are the ritz values of the operator @xmath39 on the trial subspace @xmath40 if @xmath41 the definition becomes symmetric with respect to @xmath1 and @xmath2 , so it gives the angles _ between _ subspaces @xmath1 and @xmath42 in the particular case @xmath32 and @xmath43 for unit vectors @xmath7 and @xmath9 , the vector @xmath44 has only one component @xmath45 $ ] , which is the acute angle between @xmath7 and @xmath9 defined in the standard way , i.e. ,   @xmath46 .",
    "if @xmath47 or @xmath48 , let orthonormal columns of matrices @xmath49 and @xmath50 span the subspaces @xmath1 and @xmath2 correspondingly .",
    "then @xmath51 and @xmath52 so @xmath53      let us first demonstrate that traditional inequalities may not be adequate for bounds on ritz values that involve angles between subspaces .",
    "suppose that we bound the vector @xmath54 of absolute values of matched distances between the decreasingly ordered ritz values by the vector @xmath55 of the sine of principal angles between @xmath56 and @xmath57 , in order to estimate the influence of changes in a trial subspace on the ritz values for the rayleigh - ritz method .",
    "without majorization , we can compare vectors using component - wise inequalities .",
    "for example , let @xmath58 and @xmath59.$ ] suppose that we had the inequality @xmath60 with some @xmath0-dependent constant @xmath61 .",
    "since we set the smallest angle between @xmath1 and @xmath2 to be zero , such an inequality would imply that at least one of the ritz values for @xmath1 is the same as that for @xmath2 .",
    "this is true only in exceptional cases , e.g. , if the subspaces @xmath1 and @xmath2 intersect in an eigenvector of @xmath0 .",
    "thus , changing even a _",
    "single _ vector in the basis of the trial subspace in the rayleigh - ritz method typically results in changes in _ all _ ritz values .",
    "thus , such an inequality can not possibly hold .",
    "typical known bounds for changes in the ritz values are inequalities only bounding the _ largest _ change in the ritz values by the _ largest _ angle between @xmath1 and @xmath2 .",
    "is it possible to take advantage of the knowledge of other angles to get improved bounds for the change in the ritz values ?",
    "majorization comes to the rescue as a natural tool for such bounds .",
    "this is the first main result of the paper for trial subspaces of the same dimension .",
    "[ thm_proximity_paper ] let @xmath56 and @xmath57 be subspaces of @xmath15 with @xmath62 , and let the operator @xmath0 be hermitian , then ( see ( * ? ? ?",
    "* remark 4.1 ) ) @xmath63 where @xmath64 and @xmath65 are the smallest and largest eigenvalues of the operator @xmath66 , respectively .",
    "also , if one of the subspaces is @xmath0-invariant then @xmath67    if , e.g. ,  @xmath1 is @xmath0-invariant , then @xmath68 is a subset of eigenvalues of @xmath0 counting the multiplicities , so the left - hand side of bound represents the absolute eigenvalue approximation error in the rayleigh - ritz method .",
    "all main proofs for new results here are collected in section [ s : p ] , e.g. , we give a unified proof of both bounds of theorem [ thm_proximity_paper ] in section [ sec : proximity_paper ] .",
    "our proof is shorter and simpler , but more sophisticated , compared to that used in @xcite , which covers a particular case of only .",
    "there are two novel key ideas in the proof .",
    "first , we concatenate the absolute values in the left hand side of ( or ) with the same values but with the negative sign .",
    "second , our new generalized pinching inequality of theorem [ thm : genpinching ] accurately bounds the concatenated vector .",
    "bound is proved in @xcite and bound is conjectured in ( * ? ? ?",
    "* conjecture  3.1 ) , but both with a larger constant , which is the spread @xmath69 of the spectrum of @xmath0 where @xmath70 and @xmath71 are the smallest and largest eigenvalues of @xmath0 , respectively .",
    "bounds and use the smaller spread , @xmath72 , of the spectrum of the operator @xmath66 .",
    "however , ( * ? ? ?",
    "* remark 4.1 ) states that these two statements are in fact equivalent .",
    "the argument of ( * ? ? ?",
    "* remark 4.1 ) is essential and used several times below .",
    "for completeness , let us reproduce it here .    in this paper",
    ", we always assume that both subspaces @xmath1 and @xmath2 are finite dimensional , cf .",
    "let us consider the finite dimensional subspace @xmath73 and the operator @xmath66 as replacements for the original space @xmath15 and the original operator @xmath0 .",
    "whether we define the rayleigh - ritz operator , e.g.,@xmath29 on @xmath1 starting with the original space @xmath15 and the operator @xmath0 , or with the reduced space @xmath73 and the operator @xmath66 , the outcome is evidently the same : @xmath74    moreover , if @xmath1 is @xmath0-invariant , it is also @xmath66-invariant , corresponding to the same set of eigenvalues . if this set of eigenvalues is the contiguous set of the largest eigenvalues of @xmath0 , it is also the contiguous set of the largest eigenvalues of @xmath66 . thus , without loss of generality , we can substitute the space @xmath73 and the operator @xmath66 for the space @xmath15 and the operator @xmath0 .",
    "this simple substitution improves the constants and , most importantly , allows us to handle easily the case of infinite dimensional @xmath15 as we explain later in lemma [ l : csle ] .      in the right - hand sides of both bounds in theorem [ thm_proximity_paper ]",
    "the scalar @xmath75 appears .",
    "we want to improve theorem [ thm_proximity_paper ] by replacing the scalar factor with the following decreasing _ vector _ of different scalar factors : @xmath76,\\ ] ] where @xmath77 and @xmath78 are the @xmath79 largest and smallest , respectively , eigenvalues of the operator @xmath66 . since there are @xmath80 nonzero components in the vector @xmath44 , only the first @xmath80 components of @xmath81 , which are all nonnegative ,",
    "will actually be used in upcoming bounds and , where the component - wise products of vectors @xmath81 and @xmath55 appear in the right - hand sides .",
    "let us consider an extreme case example with @xmath82 $ ] , i.e. ,   uncorrelated @xmath1 and @xmath2 .",
    "the largest variation in the individual ritz values is in this case clearly bounded by the scalar value @xmath75 of the spread of the spectrum of @xmath66 , which is already used in theorem [ thm_proximity_paper ] and which is the first component in the vector @xmath81 .",
    "now let us consider the sum of both components of the vector @xmath83 .",
    "this sum takes the largest value if @xmath1 is the span of two eigenvectors of @xmath0 corresponding to its largest eigenvalues , while @xmath2 is the span of two eigenvectors of @xmath0 corresponding to its smallest eigenvalues . but",
    "this largest value in this example is exactly the sum of both components of the vector @xmath81 .",
    "this example suggests that the vector spread @xmath81 might be the appropriate vector of constants to replace the scalar spread @xmath75 in theorem [ thm_proximity_paper ] .",
    "our numerical tests motivate the following conjecture .",
    "[ hyp2 ] let @xmath56 and @xmath57 be subspaces of @xmath15 with @xmath62 and operator @xmath0 be hermitian .",
    "then @xmath84 if in addition one of the subspaces is @xmath0-invariant then @xmath85    since @xmath86 , bounds and would follow from and , correspondingly .    here",
    ", we are able to prove only and under an additional assumption .",
    "[ thm_invariant2 ] if @xmath1 is @xmath0-invariant and corresponds to the contiguous set of the largest eigenvalues of @xmath0 , then bound holds .",
    "consequently , we obtain @xmath87 where we take into account that in this case @xmath88    bounds , , and are delicate .",
    "an attempt to improve them by dividing both sides by the vector of the constants breaks them all , as can be checked by running the following matlab code ( see @xcite for subspacea s description ) :    .... a = diag([2 1 0 0 ] ) ; x=[1 0;0 1;0 0;0 0 ] ; y = orth([1 0;1 2;2 -2;0 1 ] ) ; spr=[2 1 ] ' ; sintheta = flipud(sort(sin(subspacea(x , y ) ) ) ) lefthandside = flipud(sort(abs(sort(eig(x'*a*x))-sort(eig(y'*a*y ) ) ) ) ) sum(lefthandside)<=sum(spr.*sintheta.*sintheta )    % ( 2.4 ) and ( 2.5 ) hold   sum(lefthandside./spr)<=sum(sintheta )              % divided ( 2.3 ) breaks   ....    in this example , the vector of the constants in is equal to @xmath81 , i.e. ,  bounds and are the same and must hold , since the assumptions of theorem [ thm_invariant2 ] are satisfied , which is confirmed by the code .",
    "the last line shows that even , the weakest of the three bounds , does not hold if divided by @xmath81 .",
    "our bound is competitive compared to the following known inequality , @xmath89 which is proved in @xcite and presented above in a slightly modified formulation to make it consistent with .",
    "there is no majorization in each vector component is bounded separately , thus one can divide by the vector of the constants in contrast to . but only uses the largest angle , so it would be inferior to if other angles are much smaller compared to the largest angle  a common situation in applications ; e.g. ,  see section [ s : fem ] on fem .",
    "the main goal of this subsection is to formulate _ multiplicative _ analogs for the majorization - type bounds of the previous subsection , based on products rather than sums .",
    "the definition of majorization for vectors is based on the _ sums _ of vector components .",
    "it can also deal with the _ products _ of nonnegative vector components using the following conventions .",
    "if for nonnegative vectors @xmath5 $ ] and @xmath90 $ ] it holds that @xmath91 , we write @xmath92 .",
    "if in addition @xmath93 we write @xmath94 . for strictly positive vectors",
    "these conventions follow directly from the definition of ( weak ) majorization .",
    "the example of subsection [ sss : m ] implies that it is impossible to bound products of changes of different ritz values by the products of the sine of changes in the principal angles .",
    "our novel multiplicative bound below uses @xmath95 rather than @xmath96 to bound the relative eigenvalue error in the form of the products .",
    "[ thm : mult ] under the assumptions of theorem [ thm_invariant2 ] let @xmath97 and @xmath98 . then @xmath99 and we have @xmath100 which leads to @xmath101    we note that either majorization result of theorem [ thm : mult ] implies the bound @xmath102 which is an equivalent form of the already known sine - based inequality .      in all statements",
    "we have made so far we have assumed that @xmath103 but applications require the more general assumption @xmath104 , where we interpret the principal angles @xmath44 as the angles _ from _ @xmath1 _ to _ @xmath2 . in this paper , we briefly consider one such well known application of the rayleigh - ritz method : the finite element method for partial differential equations , in section [ s : fem ] . since we compare @xmath104 ritz values for the trial subspace @xmath1 against @xmath105 ritz values for the trial subspace @xmath2 , we can either specifically choose some appropriate @xmath106 ritz values out of @xmath105 ritz values for @xmath2 , or simply state that _ there exist _",
    "@xmath106 ritz values for the trial subspace @xmath2 such that our bounds hold .    bounds and do not hold if @xmath107 even using the latter , weaker , statement",
    ". indeed , e.g. ,  if @xmath108 and @xmath109 then either bound or would imply that @xmath68in this case a single number  is one of the ritz values for the trial subspace @xmath2 , which is not true since @xmath1 is arbitrary in @xmath2 .",
    "known results , e.g. ,  @xcite , guarantee the existence of @xmath106 ritz values for the trial subspace @xmath2 that are good approximations for @xmath107 eigenvalues for an arbitrary @xmath0-invariant subspace @xmath1 if @xmath44 is small .",
    "however , our numerical tests show that and still fail in this case ; cf .",
    "* lemma 2.6 ) . an approach of ( * ? ? ?",
    "* theorem 2.7 ) may help to overcome the obstacle , but it is outside of the scope of this paper .",
    "here we consider only the particular case where the @xmath0-invariant subspace @xmath1 corresponds to the contiguous set of the largest eigenvalues @xmath68 of @xmath0 .",
    "[ cor1 g ] let @xmath104 , the operator @xmath0 be hermitian , the @xmath0-invariant subspace @xmath1 correspond to the contiguous set of the largest eigenvalues of @xmath0 , and @xmath110 denote the @xmath79 largest eigenvalues of @xmath111 then @xmath112 if @xmath97 and @xmath98 , then @xmath113 @xmath114 and @xmath115    we use a technique presented in @xcite to extend rayleigh - ritz error bounds for the particular case @xmath62 to the general case @xmath104 .",
    "let @xmath104 and @xmath116 we define a new subspace @xmath117 to be the orthogonal projection of @xmath1 onto @xmath2 , i.e. ,  @xmath118 . assuming @xmath97 gives @xmath119 and @xmath120 since @xmath121 the courant - fisher min - max principle evidently implies that @xmath122 for the largest @xmath119 eigenvalues and that @xmath123 so leads to .",
    "since bound depends continuously on @xmath44 , the assumption @xmath97 can be removed by the continuity argument .",
    "now we apply to the pair of subspaces @xmath1 and @xmath117 instead of @xmath1 and @xmath2 , i.e.,@xmath124 this gives the following known inequality , e.g. ,  @xcite , @xmath125 if @xmath97 and @xmath98 , then @xmath126 theorem [ thm : mult ] immediately leads to and by monotonicity arguments .",
    "our previous results bound the absolute value of the eigenvalue error .",
    "they are all invariant with respect to shifting the operator @xmath0 into @xmath127 for any real shift @xmath128 . for eigenvalues that are small in absolute value , it is also important to bound the _ relative _ error .",
    "here we show how new relative bounds can be easily obtained from our theorem [ cor1 g ] . for relative bounds",
    "the shift - invariance will of course be lost , and it is natural to assume that @xmath129 .",
    "let us first explain how relative bounds are obtained , e.g. ,  from . since @xmath129 we can bound @xmath130 and divide both sides of the inequality by the vector @xmath131 , which gives @xmath132 this is already a relative bound , but only for the largest eigenvalues , which is not so useful .",
    "we can turn the largest eigenvalues into the smallest ones by substituting @xmath133 for @xmath0 as @xmath129 , but this substitution alone does not reproduce the inverse of the rayleigh quotient since in general @xmath134 there is a simple fix , though . introducing the notation @xmath135 for the @xmath0-based scalar product",
    ", we have the following trivial but crucial identity for the rayleigh quotient , @xmath136 it implies that the rayleigh - ritz method on a trial subspace @xmath1 applied to the operator @xmath0 in the original scalar product @xmath16 or to the operator @xmath133 in the @xmath0-based scalar product @xmath137 gives the same ritz vectors , and the ritz values are reciprocals of each other .",
    "the use of the @xmath0-based scalar product changes the way we measure the angles , see  @xcite .",
    "simultaneous substitutions @xmath133 for @xmath0 and @xmath137 for @xmath16 in and theorem [ cor1 g ] give the following new relative bounds .",
    "[ cor1gr ] let @xmath104 and @xmath138 the operator @xmath0 be hermitian and positive definite , @xmath129 , the @xmath0-invariant subspace @xmath49 correspond to the contiguous set of the smallest eigenvalues of @xmath0 , @xmath110 denote the @xmath79 ( counting the multiplicities ) smallest eigenvalues of @xmath139 and @xmath140 denote the vector of angles from @xmath1 to @xmath2 defined in the @xmath0-based scalar product @xmath137 .",
    "then @xmath141    let us highlight that bound is not only relative but also multiplicative .",
    "we finally note that the first statement , with the sine , in theorem [ cor1 g ] can not be transformed into a relative bound in the same way .",
    "a seemingly natural extension @xmath142 of is in fact wrong ; see    .... a = diag([1 2 3 100]);x=[1 0;0 1;0 0;0 0];y = orth([-6 -1;-7 1;2 6;1 -7 ] ) ;   sinthetaa = flipud(sort(sin(subspacea(x , y , a ) ) ) ) ; lefthandside=[1 1]'-[2 1]'./flipud(sort(eig(y'*a*y ) ) ) ; sum(lefthandside)<=sum(sinthetaa.*sinthetaa )              % fails   ....      here we extend some of the previous results to infinite dimensional spaces , using again ( * ? ? ?",
    "* remark 4.1 ) .",
    "let @xmath15 be an _",
    "infinite dimensional _",
    "hilbert space and @xmath25 be a linear bounded hermitian operator .",
    "let @xmath26 and @xmath27 be orthogonal projectors onto the nontrivial _ finite dimensional _ subspaces @xmath1 and @xmath2 with @xmath3 .",
    "the vector of cosines squared of @xmath79 principal angles from @xmath1 to @xmath2 is defined by @xmath143 if @xmath1 is @xmath0-invariant , the ritz values @xmath31 are some of the eigenvalues of @xmath0 , since we assume that @xmath1 is finite dimensional . throughout the section , we use the vectors of eigenvalues @xmath19",
    "enumerated in decreasing order only for finite dimensional operators , so the vectors have a finite number of components as before .    both subspaces @xmath1 and @xmath2 are finite dimensional .",
    "let us consider the finite dimensional subspace @xmath73 and the operator @xmath66 as replacements to the original space @xmath15 and the operator @xmath0 . the rayleigh - ritz operator @xmath29 on @xmath1 using the original space @xmath15 and the operator @xmath0 is the same as using the reduced space @xmath73 and the operator @xmath66 , as we have already discussed .",
    "if @xmath1 is @xmath0-invariant , it is also @xmath66-invariant , corresponding to the same set of eigenvalues .",
    "if this set of eigenvalues is the contiguous set of the largest eigenvalues of @xmath0 , which forms the top of the spectrum of @xmath0 , then it is also the contiguous set of the largest eigenvalues of @xmath66 .",
    "the latter may not be so evident in the infinite dimensional setting , so let us give and prove here the formal statement .",
    "[ l : csle ] for a linear bounded hermitian operator @xmath0 on an infinite dimensional hilbert space @xmath15 , let @xmath1 be a nontrivial finite dimensional @xmath0-invariant subspace of @xmath15 that corresponds to the top part of the spectrum of @xmath0 , i.e. ,  the smallest point of the spectrum of @xmath29 is an upper bound for the largest point of the spectrum of @xmath144 . then for any nontrivial finite dimensional subspace @xmath2 of @xmath15 the hermitian operator @xmath66 is invariant on @xmath1 , and the spectrum of the restriction of @xmath66 to @xmath1 comprises the @xmath79 largest eigenvalues of @xmath66 .",
    "the spectrum of a bounded hermitian operator is a closed bounded set on the real line . since @xmath1 is finite dimensional , the spectrum @xmath68 consists of @xmath79 eigenvalues , counting the multiplicities .",
    "since @xmath1 is @xmath0-invariant , the spectrum @xmath68 is a subset of the spectrum of @xmath0 , which by the lemma assumption forms the top part of the spectrum of @xmath0 .",
    "the subspace @xmath1 is @xmath0-invariant by assumption and is evidently @xmath145-invariant , so it is also @xmath66-invariant and thus @xmath68 is a subset of @xmath146 , counting the multiplicities , where the spectrum of @xmath66 consists of @xmath147 eigenvalues , counting the multiplicities , since both @xmath1 and @xmath2 , and thus their sum @xmath73 , are all finite dimensional .    the only somewhat nontrivial part of the proof is establishing that the spectrum of the restriction of @xmath66 to @xmath1 comprises the @xmath79 largest eigenvalues of @xmath66 using the lemma assumption that @xmath1 is an @xmath0-invariant subspace corresponding to the top part of the spectrum of @xmath0 . in other words , adding @xmath2 to @xmath1 does not add any new eigenvalues above @xmath148 .",
    "we already know that @xmath68 , on the one hand , makes up the top @xmath79 points of the spectrum , which are eigenvalues , counting the multiplicities , of @xmath0 and , on the other hand , is a subset of @xmath146 .",
    "we only need to show that the @xmath148-th eigenvalue of @xmath29 , which is at the same time the @xmath149-th top point of the spectrum of @xmath0 , counting the multiplicity of eigenvalues , bounds above the @xmath150-th eigenvalue of @xmath66 . but",
    "@xmath146 is a vector of ritz values of @xmath0 on the trial subspace @xmath73 , so this follows directly from the inf - sup principle for arbitrary hermitian ( not necessarily compact ) operators , see , e.g. , ( * ? ? ?",
    "* chapter ii , section 7 ) and ( * ? ? ?",
    "* theorem xiii.1 ) .",
    "we note that the assumptions of lemma [ l : csle ] are not of course applicable to all bounded hermitian operators .",
    "e.g. ,   lemma [ l : csle ] can not be applied to an orthogonal projector with an infinite dimensional range .",
    "it rather covers the class of operators with the top part of the spectrum being discrete  a modest , but practically important , extension of the class of compact operators ; see again ( * ? ? ?",
    "* chapter ii , section 7 ) and ( * ? ? ?",
    "* theorem xiii.1 , p. 76 ) .",
    "we finally note that the assumption of boundedness ( below ) of @xmath0 is not essential and can be easily replaced with the assumption that the subspace @xmath73 is in the domain of the definition of the corresponding quadratic form .",
    "the arguments above allow us to substitute the original infinite dimensional @xmath15 and @xmath0 with finite dimensional @xmath73 and @xmath66 in theorem  [ cor1 g ] .",
    "[ th : inf ] the infinite dimensional , @xmath151 , versions of theorem  [ cor1 g ] and its corollary hold under the assumptions of lemma [ l : csle ] .",
    "in the fem context , see , e.g. ,  @xcite , let us consider a specific example , the clamped membrane vibration problem  a well known eigenvalue problem for the negative laplacian @xmath152 operator in two dimensions . let the membrane be a non - convex polygon @xmath153 with a single reentrant corner @xmath154 .",
    "we will use the standard sobolev spaces @xmath155 of functions satisfying the homogeneous dirichlet conditions on the boundary of @xmath153 and @xmath156 with @xmath157    we set @xmath158 and define our operator @xmath0 as , informally speaking , the inverse to the negative laplacian ; see , e.g. ,  @xcite , so that @xmath129 is compact in @xmath15 .",
    "let us highlight that in this context we use the @xmath158 scalar product in the definition of the angles to bound the largest eigenvalues of @xmath0 , which are the reciprocals of the smallest eigenvalues of the negative laplacian .",
    "we are looking for an approximation of the invariant space @xmath159 of @xmath0 , corresponding to the main membrane vibration modes , within a trial subspace @xmath160 by the rayleigh - ritz method . using the simplest fem setup ,",
    "the domain @xmath153 is triangulated according to traditional assumptions , and @xmath2 consists of all piecewise linear ( on each triangle ) continuous functions satisfying the homogeneous dirichlet conditions on the boundary @xmath161 .",
    "the largest linear size of the largest triangle is denoted by @xmath162 .",
    "it holds that @xmath163 as @xmath164 , so we replace @xmath64 with its lower bound @xmath165 in and theorem [ cor1 g ] .",
    "the angles on the right - hand sides in our eigenvalue approximation error bounds characterize the approximability of the target invariant subspace @xmath1 by finite element functions from @xmath2 , which is typically measured by @xmath166 , where @xmath61 is a generic constant , @xmath162 approaches zero , and the exponent @xmath128 describes the approximation order .",
    "the approximability is determined by the type of the fem , smoothness of functions in @xmath1 , and the choice of the space  @xmath15 . for our example , the approximability bound for a function @xmath167 with some @xmath168 $ ] is @xmath169 .",
    "the actual lower bound for @xmath128 , which is @xmath170 , is determined by the angle @xmath171 of the reentrant corner of the polygon @xmath153 , which may lead to a corner singularity in eigenfunctions .",
    "the upper bound , @xmath14 , comes from the use of the piecewise linear fem .",
    "let us consider a particular case , where @xmath172 , denoting the largest eigenvalues by @xmath173 $ ] and the corresponding @xmath15-normalized eigenfunctions by @xmath174 and @xmath175 in @xmath1 . typically , both eigenfunctions @xmath174 and @xmath175 would have similar corner singularities in the reentrant corner , so both @xmath174 and @xmath176 with @xmath177 , but one of their linear combinations , e.g. ,   ( for illustrative purposes ) @xmath178 , might have the full @xmath179 regularity , i.e. ,   @xmath180 , and so by the approximability result we have @xmath181 .",
    "thus , @xmath182 $ ] ; here and below we neglect terms that are a smaller order of magnitude in @xmath162 compared to the terms kept . to clarify the example ,",
    "let us assume that simply @xmath183 $ ]",
    ".    this assumption may not be practical for our specific membrane problem .",
    "however , examples are given in @xcite , where eigenfunctions have different regularities , while corresponding to the same ( multiple ) eigenvalue .",
    "a perturbation argument shows that our assumption on regularity of linear combinations of eigenfunctions is realistic .    using the notation @xmath184 $ ] for the relevant fem ritz values",
    ", we obtain from , as in @xcite , that @xmath185 while implies the bound for the error in the trace , @xmath186 and gives the bound for the error in the product , @xmath187 the standard bound implies and only with an extra factor @xmath188 in the right - hand side .",
    "we conclude that can not take advantage of the better approximability of the function @xmath178 in this example , while our new majorization bounds and can , and lead to an improvement in the constant with the factor @xmath172 for the trace and product error bounds .",
    "majorization is a powerful tool that gives elegant and general error bounds for eigenvalues approximated by the rayleigh - ritz method .",
    "we discover several new results of this kind , including multiplicative bounds for relative errors .",
    "we apply majorization , apparently for first time , in the context of fem error bounds .",
    "our initial results are promising and expected to lead to further development of the majorization technique for the theory of eigenvalue computations .",
    "facts on majorization and angles , and most proofs are given here .",
    "for a real vector @xmath189 $ ] let @xmath190 be obtained by rearranging the entries of @xmath191 in an algebraically decreasing order , @xmath192 we denote @xmath193 $ ] and @xmath194 .",
    "we say that the vector @xmath195 weakly majorizes the vector @xmath191 and we use the notation @xmath196 \\prec_w [ b_1,\\cdots , b_n]$ ] or @xmath197 if @xmath198 .",
    "if in addition the sums above for @xmath199 are equal , @xmath195 ( strongly ) majorizes @xmath191 , which is denoted by @xmath200 .",
    "nonnegative vectors of different sizes may be compared by appending or removing zeros to match the sizes .",
    "the additive majorization statement @xmath201 for @xmath202-vectors @xmath203 and @xmath204 is equivalent to @xmath205 with @xmath206 if @xmath199 gives the equality .",
    "we write @xmath207 if @xmath208 and @xmath209 if in addition the case @xmath199 gives the equality , for nonnegative vectors @xmath203 and @xmath204 . for strictly positive vectors",
    "this follows directly from the definition of ( weak ) majorization .    we need several simple general facts on weak majorization : if nonnegative vectors @xmath210 and @xmath211 are decreasing and of the same size , then @xmath212 implies @xmath213 , but the converse is not true in general . if @xmath214 then @xmath215 .",
    "concatenation holds , i.e. ,   @xmath216 and @xmath217 imply @xmath218\\prec[c , d]$ ] ; ( * ? ? ?",
    "* corollary ii.1.4 , p. 31 ) . if @xmath212 and @xmath219 then @xmath220 for real vectors , if the bounds @xmath195 and @xmath221 are ordered in the same way ;",
    "4.a.1.b ) . for a convex increasing function @xmath222 ( e.g. ,  @xmath223 )",
    "@xmath197 implies @xmath224 ; ( * ? ? ?",
    "4.b.2 . , p. 109 ) .",
    "trivially , @xmath225 .",
    "let @xmath226 denote the vector of all singular values of the matrix @xmath0 in decreasing order ; and for @xmath0 with real eigenvalues let @xmath18 denote the vector of all eigenvalues of @xmath0 in decreasing order .",
    "the following theorems are mostly known ; see , e.g. ,  @xcite .",
    "[ thm : lid ] @xmath227 for hermitian @xmath0 and @xmath228 .",
    "[ thm : svp ] @xmath229 for general @xmath0 and @xmath228 , where we append zeros to the vectors of singular values if necessary to match the sizes .    for square matrices ( or operators within the same space )",
    "this is the classical gelfand - namark theorem ( * ? ? ?",
    "* theorem iii.4.5 ) .",
    "non - square matrices are extended with zero blocks to obtain square matrices .",
    "the extension with zero blocks only appends zero singular values and does not change the ranks .",
    "[ sv_product_majorization ] @xmath230 for general @xmath0 and @xmath228 , where we append zeros to the vectors of singular values if necessary to match the sizes .",
    "we add @xmath231 to both sides of the statement of theorem [ thm : svp ] and take the exponential function .",
    "our next theorem generalizes theorem [ thm : svp ] and improves ( * ? ? ?",
    "* corollary 2.4 ) .",
    "[ thm : svpp ] @xmath232 for general @xmath0 , @xmath228 , and @xmath61 , where we append zeros to singular values if necessary to match the sizes .",
    "theorem [ thm : svp ] can also be formulated as @xmath229 as singular values of @xmath233 and @xmath234 are the same up to zeros , so theorem [ thm : svp ] gives both @xmath235 and @xmath236 .",
    "as the right - hand sides in these majorization statements are ordered in the same manner , we can add the statements , obtaining the claim of the theorem .",
    "we also need the following generalized pinching inequality which may be new .",
    "[ th : pin ] for matrices @xmath237 , @xmath238 , @xmath228 , @xmath239 , and @xmath240 , such that all the products @xmath241 exist for @xmath242 , we have , possibly up to zeros , @xmath243\\prec_w s\\left(\\sqrt{a_1a_1^h+a_2a_2^h}b\\sqrt{c_1c_1^h+c_2c_2^h}\\right),\\ ] ] and in the case that @xmath244 and @xmath245 , we have , possibly up to zeros , @xmath246\\prec_w \\left(\\lambda\\left(\\sqrt{a_1a_1^h+a_2a_2^h}b\\sqrt{a_1a_1^h+a_2a_2^h}\\right)\\right)^+.\\ ] ] [ thm : genpinching ]    we denote @xmath247 $ ] and @xmath248 $ ] and form the @xmath188-by-@xmath188 block matrix @xmath249.\\ ] ] by the standard pinching inequality , e.g. ,  ( * ? ? ?",
    "* problem ii.5.4 ) , the combined singular values of the diagonal blocks of the matrix @xmath250 are weakly majorized by the singular values of @xmath250 .",
    "using the fact that eigenvalues of matrix products do not depend on the order of the multipliers shows that the singular values @xmath251 up to zeros are the same as @xmath252 , giving .    in the case",
    "that @xmath244 and @xmath245 , the eigenvalues of the diagonal blocks of @xmath250 ( which are now square ) are strongly majorized by the eigenvalues of @xmath250 . for the latter , we have , up to zeros , @xmath253 .",
    "appending or removing zeros preserve majorization for nonnegative vectors , so we replace @xmath254 in the formulas above , which proves .    if @xmath255=\\size b$ ] , there are no zeros appearing , so holds as a strong majorization and without the @xmath256 operation , as in the standard pinching inequality .",
    "we need the following :    [ th : a1 ] ( * ? ? ?",
    "* theorem 3.4 ) let @xmath41 .",
    "then we have the equalities @xmath257.$ ]    [ thm : lambdasin ] ( * ? ? ?",
    "* theorem 2.16 ) if @xmath258 , then the first , i.e. ,  largest , @xmath259 components of the vector @xmath260 are given by the vector @xmath261      in this section we provide the main and relatively long proofs .",
    "we start with two important simplifications .",
    "is an orthogonal projector , of bound has stimulated our present proof . ] first , by ( * ? ? ?",
    "* remark 4.1 ) we use the subspace @xmath73 and the operator @xmath66 as substitutions for the original space @xmath15 and the original operator @xmath0 , keeping the same notation , without loss of generality .",
    "second , the differences of ritz values do not change with a shift of @xmath0 , i.e. , for a real @xmath128 and @xmath262 , we have , e.g.,@xmath263 . so all our statements are invariant with respect to a real shift of @xmath0 , which we can freely choose .",
    "also , our bounds are invariant with respect to a real scaling of @xmath0 .",
    "thus for any real @xmath128 and @xmath264 we can replace @xmath0 with @xmath265 without loss of generality .",
    "we take @xmath266 and @xmath267 so in the rest of the proof we assume that @xmath0 is already shifted and scaled such that @xmath268 and @xmath269 , which guarantees well defined square roots @xmath270 and @xmath271 .",
    "we now prove that @xmath272 and if in addition @xmath1 is @xmath0-invariant then @xmath273    concatenating positive and negative values together , we obtain @xmath274^{{\\downarrow}}\\\\ = \\left[\\lambda((p_{{\\mathcal{x}}}a)|_{{\\mathcal{x}}})-\\lambda((p_{{\\mathcal{y}}}a)|_{{\\mathcal{y}}}),\\ , -\\left(\\lambda((p_{{\\mathcal{x}}}a)|_{{\\mathcal{x}}})-\\lambda((p_{{\\mathcal{y}}}a)|_{{\\mathcal{y}}})\\right)\\right]^{{\\downarrow}}\\\\ = \\left[\\lambda((p_{{\\mathcal{x}}}a)|_{{\\mathcal{x}}})-\\lambda((p_{{\\mathcal{y}}}a)|_{{\\mathcal{y}}}),\\ , \\lambda((p_{{\\mathcal{x}}}(i - a))|_{{\\mathcal{x}}})-\\lambda((p_{{\\mathcal{y}}}(i - a))|_{{\\mathcal{y}}})\\right]^{{\\downarrow}}.\\end{gathered}\\ ] ] it is more convenient for us to work in the whole space , so above we replace @xmath275^{{\\downarrow}}\\\\ = \\left[\\lambda(p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}})-\\lambda(p_{{\\mathcal{y}}}ap_{{\\mathcal{y}}}),\\ , \\lambda(p_{{\\mathcal{x}}}(i - a)p_{{\\mathcal{x}}})-\\lambda(p_{{\\mathcal{y}}}(i - a)p_{{\\mathcal{y}}})\\right]^{{\\downarrow}},\\end{gathered}\\ ] ] using @xmath276=\\lambda(p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}})$ ] and similar formulas involving @xmath2 instead of @xmath1 and @xmath277 instead of @xmath0 , which all hold since @xmath278 and @xmath279 in this proof , so the added zeros are correctly placed .          as in the previous proof , we start with two simplifications .",
    "the first one is the same : by ( * ? ? ?",
    "* remark 4.1 ) we use the subspace @xmath73 and the operator @xmath66 as substitutions for the original space @xmath15 and the original operator @xmath0 keeping the same notation , without loss of generality .",
    "second , we choose @xmath294 and assume that the shift is already applied to @xmath0 , i.e. ,  without loss of generality we assume that both @xmath295 and @xmath296 are nonnegative definite and so they have well - defined square roots @xmath297 and @xmath298 , correspondingly .    for an @xmath0-invariant subspace @xmath1 , we split @xmath299 and adding and subtracting @xmath300 we derive @xmath301    now",
    ", we bound separately the two terms in the sum in the last two lines .",
    "we remind the reader that @xmath200 and @xmath302 imply @xmath303 for real vectors , and this holds similarly for weak majorization .",
    "it is convenient to extend the operators restrictions by zero to the whole space and use a convention that operations and comparisons of nonnegative decreasing vectors with different numbers of components is done by appending zeros at the end of the vectors to match the vectors sizes , e.g.,@xmath304\\geq0.$ ] since @xmath62 the number of zeros to add for @xmath1 and @xmath2 is the same .",
    "however , a seemingly trivial claim @xmath305 $ ] is , in fact , _ wrong _ , since the components of @xmath306 may not be all nonnegative , so the added zeros are misplaced compared to @xmath307 which is decreasing by definition .",
    "we start with the first term in the sum on the right - hand side .",
    "since both @xmath308 and @xmath309 , we concatenate with zeros correctly and obtain @xmath310 & = & \\lambda(p_{{\\mathcal{x}}}ap_{{\\mathcal{x } } } ) -\\lambda(p_{{\\mathcal{y}}}p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}}p_{{\\mathcal{y}}})\\\\ & \\prec & \\lambda\\left(\\sqrt{p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}}}p_{{\\mathcal{x}}}p_{{{\\mathcal{y}^\\perp}}}p_{{\\mathcal{x}}}\\sqrt{p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}}}\\right)\\\\ & \\prec_w & s(p_{{\\mathcal{x}}}ap_{{\\mathcal{x}}})\\sin^2\\theta({\\mathcal{x}},{\\mathcal{y}}),\\end{aligned}\\ ] ] applying theorems [ thm : lid ] , [ sv_product_majorization ] , and [ th : a1 ] .      adding both bounds together gives the statement of the theorem , i.e.,@xmath314 finally , there are @xmath80 nonzero components in the vector @xmath44 , since @xmath315 .",
    "the first @xmath80 components in the vector @xmath316 are the same as those in the vector @xmath81 since we have redefined @xmath0 such that the sum @xmath73 gives the whole space and shifted @xmath0 such that @xmath317 and so we have @xmath318 and @xmath319 for each component of @xmath81 where @xmath320 the corresponding angle @xmath321 in the vector @xmath44 must be zero , so such a component of @xmath81 with an index larger than @xmath80 can be defined arbitrarily , since it is multiplied by zero .",
    "first we use exactly the same simplifications as in the beginning of the proof of theorem [ thm_proximity_paper ] in subsection [ sec : proximity_paper ] , so @xmath322 .",
    "we assume that the space @xmath15 is already mapped into a space of vectors , so that we can use a matrix proof here .",
    "let @xmath49 and @xmath50 be two matrices whose columns form orthonormal bases for @xmath1 and @xmath2 respectively , so we have @xmath323 and @xmath324 .",
    "the theorem s assumptions @xmath325 and @xmath97 give @xmath326 by .",
    "this is equivalent in our simplified situation to @xmath327 , so we can legitimately take the log of their ratio below . by analogy with ,",
    "since @xmath1 is @xmath0-invariant and @xmath328 because of the shift of a that made @xmath329 , we have @xmath330 where we denote @xmath331 .",
    "we have @xmath332 by definition and the theorem s assumption , so both matrices @xmath61 and @xmath333 are invertible and then @xmath334 .",
    "the key step is using theorem [ thm : svp ] , substituting @xmath335 and @xmath336 in @xmath337 replacing here @xmath338 with @xmath339 , as shown above , gives the multiplicative weak majorization bound of theorem [ thm : mult ] .",
    "if @xmath13 then @xmath340 for any nondecreasing convex real valued function @xmath341 , see , e.g. ,  ( * ? ?",
    "* statement 4.b.2 ) . taking @xmath342 for gives @xmath343 subtracting the vector of ones gives the second bound of theorem [ thm : mult ] .",
    "the authors thank : mark embree and anonymous referees for their useful and detailed comments ; chris paige and ivo panayotov for stimulating collaboration in @xcite , where bound has been proved for extreme eigenvalues ; ilya  lashuk for sharing his unpublished proof of a particular case of bound with @xmath344 ; and peizhen zhu for proofreading the manuscript ."
  ],
  "abstract_text": [
    "<S> the rayleigh - ritz ( rr ) method finds the stationary values , called ritz values , of the rayleigh quotient on a given trial subspace as approximations to eigenvalues of a hermitian operator @xmath0 . if the trial subspace is @xmath0-invariant , the ritz values are exactly some of the eigenvalues of @xmath0 . </S>",
    "<S> given two subspaces @xmath1 and @xmath2 of the same finite dimension , such that @xmath1 is @xmath0-invariant , the absolute changes in the ritz values of @xmath0 with respect to @xmath1 compared to the ritz values with respect to @xmath2 represent the rr absolute eigenvalue approximation error . </S>",
    "<S> our first main result is a sharp majorization - type rr error bound in terms of the principal angles between @xmath1 and @xmath2 for an arbitrary @xmath0-invariant @xmath1 , which was a conjecture in [ siam j. matrix anal . </S>",
    "<S> appl . , 30 ( 2008 ) , pp . </S>",
    "<S> 548 - 559 ] . </S>",
    "<S> second , we prove a novel type of rr error bound that deals with the products of the errors , rather than the sums . </S>",
    "<S> third , we establish majorization bounds for the relative errors . </S>",
    "<S> we extend our bounds to the case @xmath3 in hilbert spaces and apply them in the context of the finite element method .    </S>",
    "<S> majorization , angles , subspaces , projection , perturbation , error analysis , ritz values , rayleigh - ritz , eigenvalue , relative error bounds , multiplicative bounds , fem .    15a42 , 15a60 , 65f35 , 65n30 .    </S>",
    "<S> ( place for digital object identifier , to get an idea of the final spacing . ) </S>"
  ]
}