{
  "article_text": [
    "in wireless communication system , number of transmit and or received antennas are used to improve the diversity of the system . the channel @xmath2 between transmitter and receiver",
    "has the different form and depends on the number of antennas used at the transmitter and the receiver side .",
    "the channel for single - input - single - output ( siso ) as @xmath3 , for single - input - multiple - output ( simo ) as @xmath4 and for multiple - input - multiple - output ( mimo ) : @xmath5 .",
    "let * y*(n ) be received signal with the number of transmit antennas @xmath6 , multipath @xmath7 and channel noise @xmath8 , represented as    @xmath9    let @xmath10 be the received vector by stacking @xmath11 successive received vectors . where @xmath12^t$ ] and the transmitted symbol vector is @xmath13^t$ ] .",
    "then @xmath10 can be represented in matrix form as @xmath14 and the correlation matrix for @xmath15 can be written as @xmath16 $ ] .",
    "let @xmath17 $ ] and @xmath18 $ ] then the correlation matrix @xmath19 and @xmath20 at time instant @xmath21 and @xmath22 can be represented as equation ( [ eq : r1 ] ) and equation ( [ eq : r2 ] ) respectively .",
    "@xmath23      \\label{eq : r1 } } \\ ] ]    @xmath24      \\label{eq : r2 } } \\ ] ]",
    "the correlation matrix is complex matrix and the pseudo - inverse of * r * can be computed from cholesky factors , such that if lower triangular matrix @xmath25 is cholesky factors of the correlation matrix @xmath26 and can be represented as @xmath27 then pseudo - inverse of * r * can be computed as @xmath28 . the section below details the conventional cholesky algorithms and the rchol algorithm .",
    "the cholesky decomposition @xmath29 $ ] factorizes a complex ( or real - valued ) positive - denite hermitian symmetric matrix into a product of a lower triangular matrix and its hermitian transpose .",
    "@xmath27 where , * l * is a lower triangular matrix and @xmath30 is hermitian of * l*. the matrix * r * must be a positive definite and this method needs square root operation .      1 .",
    "compute * r * at each time instant n 2 .",
    "find the square root of diagonal element of * r * 3 .",
    "modify each column of * r * 4 .",
    "equate lower triangular part of * r * to * l * 5 .",
    "repeat steps @xmath31 to @xmath32 for each time instant      to avoid square root operation , a modified cholesky algorithm @xmath29 $ ] is used , which avoids square root operation by introducing a diagonal matrix d in between cholesky factors .",
    "the modified cholesky algorithm does not require * r * to be a positive definite matrix but it s determinant must be nonzero .",
    "* r * may be rank deficient to a certain degree i.e. d may contain negative main diagonal entries if * r * is not positive semi - definite",
    ".      1 .",
    "compute * r * at each time instant n 2 .",
    "modify each column of * r * 3 .",
    "equate the strictly lower part of matrix * r * to @xmath34 with ones on the main diagonal 4 .",
    "equate main diagonal of * r * with the main diagonal of * d * 5 .",
    "repeat step @xmath31 to @xmath32 for each time instant .",
    "the schur algorithm recursively compute the columns of the lower triangular matrix * h * form matrix * r*. it is shown in @xmath36 $ ] that levinson recursion may be used to derive the lattice recursion for computing qr factors of data matrices and lattice recursion can be used to derive the schur recursion for computing cholesky factors of a toeplitz correlation matrix .",
    "the detail algorithm is given in algorithm @xmath37 .",
    "the schur algorithm like previously mentioned algorithm computes all @xmath38 inner product to compute matrix * r * for initialization .      1 .",
    "compute * r * at each time instant n 2 .   initialize first column of * r * to the first column of cholesky factor * h * 3 .",
    "compute rest column recursively from columns of * r * 4 .",
    "repeat step @xmath31 to @xmath39 for each time instant      it is clear from above equation ( [ eq : r1 ] ) and equation ( [ eq : r2 ] ) that @xmath41 can be represented from submatrix of @xmath20 .",
    "to utilize such special structure of correlation matrices , we propose a modified recursive cholesky algorithm to compute the cholesky factors recursively .",
    "this algorithm is modification of schur algorithm mentioned above .",
    "the more general approach consists of using the schur algorithm to induce recursion for columns of dynamic * l*. this algorithm does not need n inner products to compute the correlation matrix * r*. the cholesky factors are computed explicitly such that let @xmath42then pseudo - inverse can be computed as @xmath43      1 .",
    "initialize first the first column of cholesky factor * a * as @xmath44 2 .",
    "compute second column recursively from @xmath45 and @xmath46 3 .",
    "substitute sub - matrix @xmath47 to @xmath48 4 .",
    "repeat step @xmath31 to @xmath39 for each time instant    in the schur algorithm , columns of cholesky factors at time instant @xmath49 are computed recursively from the correlation matrix at that instant .",
    "whereas in the rchol algorithm first two columns of cholesky factors at time instant @xmath49 is computed recursively from previous cholesky factor and submatrix of that cholesky factors are updated recursively from previous cholesky factor i.e. at time instant @xmath50 .",
    "conventional cholesky algorithm mentioned here are introduced for normal matrices whereas proposed matrix is well suited for block matrices and simulations are shown for that only .",
    "to compare proposed the rchol algorithm with schur algorithm , we compared the result of both the algorithm with theoretical results .",
    "fig . @xmath51 .",
    "show the ratio and difference of matrices @xmath52 , @xmath53 and @xmath54 , when the correlation matrix is unknown .",
    "that has the application in blind channel and or data estimation .",
    "1 ( a ) and ( b ) shows the maximum error for the rchol algorithm , @xmath55 $ ] is @xmath56 while for the schur algorithm , @xmath57 $ ] is @xmath58 i.e. nearly 6 times the rchol algorithm . in case of ratio fig .",
    "1 ( a ) and ( b ) shows the maximum ratio for the rchol algorithm , @xmath59 $ ] is @xmath60 while for the schur algorithm , @xmath61 $ ] is @xmath62 .",
    "1 show the ratio and difference of matrices @xmath52 , @xmath53 and @xmath54 , when the correlation matrix is known . fig .",
    "1 ( a ) and ( b ) shows that the maximum error for the rchol algorithm , @xmath55 $ ] is @xmath63 while for the schur algorithm , @xmath57 $ ] is @xmath64 i.e. nearly 6 times the rchol algorithm . in case of ratio fig . 1 ( e ) and ( f )",
    "shows that the maximum ratio for the rchol algorithm , @xmath65 $ ] is @xmath66 while for the schur algorithm , @xmath67 $ ] is @xmath68 .    from fig .",
    "1 it can be concluded that the schur algorithm is best suited when the correlation matrix is known , but leads to huge error propagation through the column when * r * is unknown and can not be applied for blind channel estimation . in converse ,",
    "the rchol algorithm is best suited for blind channel estimation and reduces error propagation through the column .",
    "convention methods of cholesky factorization requires the correlation matrix which needs inner product . while the recursive modied cholesky algorithm ( rchol ) algorithm is an explicit way to recursively calculating the pseudo - inverse of the matrices without estimating the correlation matrix .",
    "it requires less number of iteration which avoids error propagation through column updates .",
    "the rchol algorithm has most of the use in calculating the pseudo - inverse of the of a time - varying matrix which is applicable to simo / mimo , cdma , ofdm , etc . wireless communication systems ."
  ],
  "abstract_text": [
    "<S> the cholesky decomposition plays an important role in finding the inverse of the correlation matrices . </S>",
    "<S> as it is a fast and numerically stable for linear system solving , inversion , and factorization compared to singular valued decomposition ( svd ) , qr factorization and lu decomposition . </S>",
    "<S> as different methods exist to find the cholesky decomposition of a given matrix , this paper presents the comparative study of a proposed rchol algorithm with the conventional methods . </S>",
    "<S> the rchol algorithm is an explicit way to estimate the modified cholesky factors of a dynamic correlation matrix .    </S>",
    "<S> cholesky decomposition is a fast and numerically stable for linear system solving , inversion , and factorization compared to singular valued decomposition ( svd ) , qr factorization and lu decomposition @xmath0 $ ] . </S>",
    "<S> the wireless communication system is highly dependent on matrix inversion of the correlation matrix . </S>",
    "<S> such system consists of a huge matrix inversion . </S>",
    "<S> an outdoor wireless communication has a time - varying channel which changes dynamically for mobile user . in case of narrowband channel , </S>",
    "<S> the channel is considered constant for a symbol duration , whereas for broadband , it is changing within a symbol period . such time - varying channel forms the special structure of channel matrix and correlation matrix . to exploit such special structure , a novel modified recessive cholesky ( rchol ) algorithm </S>",
    "<S> is introduced in @xmath1 $ ] . </S>",
    "<S> our proposed ( rchol ) algorithm is a computational efficient algorithm to compute the modified cholesky factors of known as well as an unknown covariance matrix .    in this paper , we present the comparative study of conventional cholesky algorithm and the rchol algorithm to manifest the importance of the proposed algorithm in a highly dynamic wireless communication . </S>"
  ]
}