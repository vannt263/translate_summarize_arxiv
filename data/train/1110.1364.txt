{
  "article_text": [
    "the factor model appears in many scientific fields , such as economics and psychology literature , where the number of factors has a primary importance ( @xcite , @xcite ) .",
    "similar models can be found in physics of mixture @xcite , @xcite or population genetics . in wireless communications , a signal ( factor ) emitted by a source",
    "is modulated and received by an array of antennas which will permit the reconstruction of the original signal .",
    "more recently spiked population models has been introduced in @xcite that encompass factor models .",
    "a fundamental problem here is the determination of the number of factors .",
    "many methods have been developed , mostly based on information theoretic criteria , such as the minimum description length ( mdl ) estimator , bayesian model selection or bayesian information criteria ( bic ) estimators , see @xcite for a review .",
    "nevertheless , these methods are based on asymptotic expansions for large sample size and may not perform well when the dimension of the data @xmath1 is large compared to the sample size @xmath0 . to our knowledge",
    ", this problem in the context of high - dimension appears for the first time in @xcite .",
    "recent advances have been made using the random matrix theory by @xcite or onatski @xcite in economics , and kritchman & nadler in chemometrics literature @xcite .",
    "several studies have also appeared in the area of signal processing from high - dimensional data .",
    "everson & roberts @xcite proposed a method using both rmt and bayesian inference , while ulfarsson & solo combined rmt and stein s unbiased risk estimator ( sure ) in @xcite . in @xcite and @xcite ,",
    "the authors improved estimators based on information theoretic criteria and in @xcite , kritchman & nadler constructed an estimator based on the distribution of the largest eigenvalue ( hereafter refereed as the kn estimator ) . in @xcite",
    ", we have also introduced a new method based on recent results of @xcite and @xcite in random matrix theory .",
    "it is worth mentioning that for high - dimensional time series , an empirical method for the estimation of factor number has been recently proposed in @xcite and @xcite .    in",
    "most cited references , factors are assumed to be distinct .",
    "however , we observe that when some of these factors become close , the estimation problem becomes more difficult and these algorithms need to be modified .",
    "we refer this new situation as the case with possibly equal factors and its precise formulation will be given in section  3.2 .",
    "the aim of this work is to extend our method @xcite to this new case and to compare it with the kn estimator , that is known in the literature as one of best estimation method .",
    "the rest of the paper is organized as follows .",
    "section  2 introduces the model . in section  3",
    ", we define the estimation problem of the number of possibly equal factors and present our solution .",
    "we establish its asymptotic consistency .",
    "section 4 provides simulation experiments to access the quality of our estimator .",
    "next , we recall the kn estimator and conduct simulation experiments to compare these two methods . in section 6 ,",
    "we analyze the influence of a tuning parameter @xmath2 used in our estimator .",
    "finally , section 7 concludes with discussions .",
    "all proofs are given in the appendix .",
    "we consider the following strict factor model @xmath3 where    = 1em    @xmath4 are @xmath5 random factors ( @xmath6 ) assumed to have zero mean , unit variance and be mutually uncorrelated ;    @xmath7 is the @xmath8 full rank matrix of factor loadings ;    @xmath9 is the unknown noise level , @xmath10 is a @xmath11 vector of additive noise , independent of @xmath12 .",
    "the _ population covariance matrix _ @xmath13 of @xmath14 equals @xmath15 and has the spectral decomposition @xmath16 where @xmath17 is an unknown basis of @xmath18 and @xmath19 .",
    "the sample covariance matrix of the @xmath0 @xmath1-dimensional i.i.d .",
    "vectors considered at each time @xmath20 , @xmath21 is @xmath22 denote by @xmath23 its eigenvalues .",
    "our aim is to estimate @xmath5 on the basis of @xmath24 . to start with , we assume that the noise level @xmath25 is known .",
    "if this is indeed not the case , we will give a method in section [ sig ] to estimate it .",
    "in this section , we first recall our previous result of @xcite in the case of different factors .",
    "next , we propose an extension of the algorithm to the case with possibly equal factors . the consistency of the extended algorithm is established .",
    "we consider the case where the @xmath26 are all different , so there are @xmath5 distinct factors . according to @xcite , let us rewrite the spectral representation of @xmath27 as @xmath28 with @xmath29    it is assumed in the sequel that @xmath1 and @xmath0 are related so that when @xmath30 , @xmath31 .",
    "therefore , @xmath1 can be large compared to the sample size @xmath0 ( high - dimensional case ) .",
    "moreover , we assumed that @xmath32 for all @xmath33 , i.e all the factors @xmath34 are greater than @xmath35 .",
    "for @xmath36 , we define the function @xmath37 baik and silverstein @xcite proved that , under a moment condition on @xmath38 , for each @xmath39 and almost surely , @xmath40 they also proved that for all @xmath41 with a prefixed range @xmath42 and almost surely , @xmath43 the estimation method of @xmath5 in @xcite is based on a close inspection of differences between consecutive eigenvalues @xmath44 indeed , the results quoted above imply that a.s .",
    "@xmath45 , for @xmath46 whereas for @xmath47 , @xmath48 tends to a positive limit .",
    "thus it becomes possible to estimate @xmath5 from index - numbers @xmath49 where @xmath48 become small .",
    "more precisely , the estimator is @xmath50 where @xmath51 is a fixed number big enough , and @xmath52 is a threshold to be defined . in practice , the integer @xmath53 should be thought as a preliminary bound on the number of possible factors . in @xcite",
    ", we proved the consistency of @xmath54 providing that the threshold satisfies @xmath55 , @xmath56 and under the following assumption on the entries of @xmath57 .    [ hypothese ] the entries @xmath58 of the random vector @xmath59 have a symmetric law and a sub - exponential decay , that means there exists positive constants @xmath2 , @xmath60 such that , for all @xmath61 , @xmath62      as said in introduction , when some factors have close values , estimation algorithms need to be modified .",
    "more precisely , we adopt the following theoretic model with @xmath63 different factor strengths @xmath64 , each of them can appear @xmath65 times ( equal factors ) , respectively . in other words , @xmath66 with @xmath67 .",
    "when all the factors are unequal , differences between sample factor eigenvalues tend to a positive constant , whereas with two equal factors , such difference will tend to zero .",
    "this fact creates an ambiguity with those differences corresponding to the noise eigenvalues which also tend to zero .",
    "however , the convergence of the @xmath68 s , for @xmath69 ( noise ) is faster ( in @xmath70 ) than that of the @xmath68 from equal factors ( in @xmath71 ) as a consequence of theorem 3.1 of bai & yao @xcite .",
    "this is the key feature we use to adapt the estimator ( [ estimator ] ) to the current situation with a new threshold @xmath52 .",
    "the precise asymptotic consistency is as follows .",
    "[ consistence ] let @xmath72 be @xmath0 copies i.i.d . of @xmath38 which follows the model ( [ model ] ) and",
    "satisfies assumption [ hypothese ] .",
    "suppose that the population covariance matrix @xmath27 has @xmath63 non null and non unit eigenvalues @xmath73 with respective multiplicity @xmath74 ( @xmath67 ) , and @xmath75 unit eigenvalues .",
    "assume that @xmath76 when @xmath77 .",
    "let @xmath78 be a real sequence such that @xmath79 and @xmath56 .",
    "then the estimator @xmath54 is consistent , i.e @xmath80 in probability when @xmath30 .",
    "notice that , compare to the previous situation , the only modification of our estimator is a new condition @xmath79 on the convergence rate of @xmath52 .",
    "the proof of theorem  1 is postponed to appendix .",
    "when the noise level @xmath25 is unknown , an estimation is needed . in @xcite",
    ", we used an algorithm based on the maximum likelihood estimate @xmath81 as explained in @xcite and @xcite , this estimator has a negative bias .",
    "hence the authors developed an improved estimator with a smaller bias .",
    "we will use this improved estimator of noise level in our simulations for both estimator @xmath82 and the estimator @xmath83 ( see section 5 ) .",
    "to access the quality of our estimator , we first make the following modification : instead of making a decision once some difference @xmath84 is below the threshold @xmath52 ( see ( [ estimator ] ) ) , the modified estimator stops when two consecutive differences @xmath84 and @xmath85 are both below @xmath52 .",
    "more precisely , we set @xmath86 it is easy to see that the proof for the consistency of @xmath54 applies equally to @xmath87 under the same conditions as in theorem 1 .",
    "it remains to choose a threshold sequence @xmath52 to be used for our estimator @xmath87 .",
    "as argued in @xcite , we use a sequence @xmath52 of the form @xmath88 , where @xmath2 is a  tuning \" parameter to be adjusted . in all simulations",
    ", we consider 500 independent replications and take @xmath89 .",
    "table 1 gives a summary of parameters in our simulation experiments .",
    "there are two sets of experiments . in the first one ( figures 1 , 2 and models a , b , c and d in table 1 ) , factors are different and these experiments extend and complete results already reported in @xcite .",
    "the second set of experiments ( figures 3 , 4 and models e , f , g , h and j in table 1 ) addresses the new situation where some factors are equal .",
    "figure 7 considers the case of no factor .",
    "( figures 5 and 6 report comparison results developed in section 5 ) .",
    ".summary of parameters used in the simulation experiments .",
    "( l : left , r : right ) [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]     the values of @xmath90 are quite close to the values used in previous simulations experiment ( @xmath91 for @xmath92 and @xmath93 or 11 for @xmath94 ) , although they are slightly higher . therefore , this automatic calibration of @xmath90 can be used in practice for any data and sample dimensions @xmath1 and @xmath0 .    to assess the quality of this automatic calibration procedure , we run again a part of the previous simulation experiments this time using @xmath90 .",
    "figure 8 considers the case where @xmath94 . on the left we consider model a ( @xmath95 ) and model g ( @xmath96 ) ( upper curve ) . on the right we have model b ( @xmath97 ) and model h ( @xmath98 ) ( upper curve ) .",
    "the dots lines are the previous results with @xmath2 manually chosen .     for models",
    "a , g ( left ) and models b , h ( right ) . ]",
    "using the new automatically method causes only a slight deterioration of the estimation performance .",
    "we again observe significantly higher error rates in the case of equal factors for moderate sample sizes .",
    "figure 9 considers the case where @xmath92 , with models c ( @xmath99 ) and i ( @xmath100 ) ( upper curve ) on the left and model d ( @xmath101 ) and j ( @xmath102 ) ( upper curve ) on the right .     for models",
    "c , i ( left ) and models d , j ( right ) . ]    compared to the previous situation of @xmath94 , using the automatic value @xmath90 affects a bit more our estimator ( up to 10% of degradation ) .",
    "nevertheless , the estimator remains consistent .",
    "furthermore , we have to keep in mind that our simulation experiments have considered critical cases where factors eigenvalues are close : in many of practical applications , theses factors are more separated so that the influence of @xmath2 will be less important .",
    "in this paper we have considered the problem of the estimation of the number of factors in the high - dimensional case .",
    "when some factors have close or even equal values , the estimation becomes harder and existing algorithm need to be re - examined or corrected . in this spirit , we have proposed a new version of our previous algorithm .",
    "its asymptotic consistency is established .",
    "it becomes unavoidable to compare our algorithm to an existing competitor proposed by kritchman & nadler ( kn , @xcite , @xcite ) . from our extensive simulation experiments in various scenarios ,",
    "we observe that overall our estimator could have smaller misestimation rates , especially in cases with close and relatively low factor values ( figures 2 and 4 ) or more generally for almost all the cases provided that the sample size @xmath0 is moderately large ( @xmath103 or 500 )",
    ". nevertheless , if the primary aim is to fix the false alarm rate and the overestimation rates at a very low level , the kn estimator is preferable .",
    "however , our algorithm depend on a tuning parameter @xmath2 .",
    "most of the experiments reported here are obtained with a finely - turned value of @xmath2 and this value varies from case to case . by comparison ,",
    "the kn estimator is remarkably robust and a single value of @xmath104 was used in all the experiments . in section 6 , we have provided a first approach to an automatic calibration of @xmath2 which is quite satisfactory .",
    "however , more investigation is needed in the future on this issue .",
    "in the sequel , we will assume that @xmath89 ( if it is not the case , we consider @xmath105 ) . for the proof ,",
    "we need two theorems .",
    "the first , proposition [ yao ] , is a result of bai and yao @xcite which derives from a clt for the @xmath65-packed eigenvalues @xmath106\\mbox { , } j\\in j_k\\ ] ] where @xmath107 , @xmath108 for @xmath109 .",
    "[ yao ] assume that the entries @xmath110 of @xmath38 satisfy @xmath111 , @xmath112 for all @xmath113 and have multiplicity @xmath114 respectively .",
    "then as @xmath1 , @xmath30 so that @xmath115 , the @xmath65-dimensional real vector @xmath116 converges weakly to the distribution of the @xmath65 eigenvalues of a gaussian random matrix whose covariance depends on @xmath117 and @xmath118 .",
    "[ maida ] assume that the entries @xmath110 of @xmath38 have a symmetric law and a sub - exponential decay , that means there exists positive constants c , c such that , for all @xmath119 , @xmath120 .",
    "then , for all @xmath121 with a prefixed range @xmath42 , @xmath122        as @xmath123 converges weakly , it exists a function @xmath126 such that , for all @xmath127 , @xmath128 .",
    "furthermore , as @xmath129 , it exists @xmath130 such that for all @xmath131 , @xmath132 .",
    "so @xmath133 , and @xmath134 .",
    "now we can take @xmath135 : as @xmath123 is positive , @xmath136 .",
    "consequently , @xmath137      _ case of @xmath140_. in this case , @xmath141 ( noise eigenvalues ) . as @xmath55 such",
    "that , @xmath56 , and by using proposition [ maida ] in the same manner as in the proof of theorem 3.1 in @xcite , we have @xmath142        let @xmath144 ( simple factor ) and @xmath145 . for all @xmath146 , @xmath48 corresponds to a consecutive difference of @xmath147 issued from two different factors , so we can still use proposition [ yao ] and the proof of theorem 3.1 in @xcite to show that @xmath148            30 t.w .",
    "anderson , an introduction to multivariate statistical analysis , _",
    "wiley series in probability and statistics _ ( 2003 ) .",
    "z.d . bai and j.f .",
    "yao , central limit theorems for eigenvalues in a spiked population model , _ ann .",
    "h. poincar probab .",
    "_ * 44(3 ) * ( 2008 ) 447474 . j. baik and j.w .",
    "silverstein , eigenvalues of large sample covariance matrices of spiked population models , _",
    "j. multivariate anal . _ * 97 * ( 2006 ) 13821408 .",
    "f. benaych - georges , a. guionnet and m. maida , fluctuations of the extreme eigenvalues of finite rank deformations of random matrices , _ electron .",
    "_ * 16(60 ) * ( 2011 ) 16211662 .",
    "combettes and j. silverstein , signal detection via spectral theory of large dimensional random matrices , _ ieee trans . signal process .",
    "_ * 40(8 ) * ( 1992 ) 21002105 .",
    "r. everson and s. roberts , inferring the eigenvalues of covariance matrices from limited , noisy data , _ ieee trans . signal process .",
    "_ * 48(7 ) * ( 2000 ) 20832091 .",
    "harding , structural estimation of high - dimensional factor models , _ econometrica _ r&r .",
    "johnstone , on the distribution of the largest eigenvalue in principal component analysis , _ ann .",
    "* 29 * ( 2001 ) 295327 .",
    "s. kritchman and b. nadler , determining the number of components in a factor model from limited noisy data , _ chem .",
    "int . lab .",
    "* 94 * ( 2008 ) 1932 .",
    "s. kritchman and b. nadler , non - parametric detection of the number of signals : hypothesis testing and random matrix theory , _ ieee trans .",
    "signal process .",
    "_ * 57(10 ) * ( 2009 ) 39303941 . c. lam , q. yao and n. bathia , estimation of latent factors for high - dimensional time series , _ biometrika _ * 98 * ( 2011 ) 901918 . c. lam and q. yao , factor modeling for high - dimensional time series : inference for the number of factors , _ ann .",
    "( 2011 ) to appear .",
    "nadakuditi and a. edelman , sample eigenvalue based detection of high - dimensional signals in white noise using relatively few samples , _ ieee trans .",
    "signal process .",
    "_ * 56(7 ) * ( 2008 ) 26252638 .",
    "b. nadler , non - parametric detection of signals by information theoretic criteria : performance analysis and an improved estimator , _ ieee trans .",
    "signal process .",
    "_ * 58(5 ) * ( 2010 ) 27462756 .",
    "t. naes , t. isaksson , t. fearn and t. davies , user - friendly guide to multivariate calibration and classification , _ nir publications , chichester _ ( 2002 ) .",
    "a. onatski , testing hypotheses about the number of factors in large factors models , to appear in _ econometrica _ , ( 2008 ) .",
    "d. passemier and j.f yao , on determining the number of spikes in a high - dimensional spiked population model , _ random matrices : theory and applications _ * 1(1 ) * ( 2012 ) 1150002 .",
    "d. paul , asymptotic of sample eigenstructure for a large dimensional spiked covariance model , _ statistica sinica _ * 17 * ( 2007 ) 16171642 .",
    "ross , the arbitrage theory of capital asset pricing , _",
    "j. economic theory _ , * 13 * ( 1977 ) 341360 .",
    "ulfarsson and v. solo , dimension estimation in noisy pca with sure and random matrix theory , _ ieee trans . signal process .",
    "_ * 56(12 ) * ( 2008 ) 58045816 .",
    "m. wax and t. kailath , detection of signals by information theoretic criteria , _ ieee trans .",
    "speech , signal process . _",
    "* 33(2 ) * ( 1985 ) 387392 ."
  ],
  "abstract_text": [
    "<S> estimation of the number of factors in a factor model is an important problem in many areas such as economics or signal processing . </S>",
    "<S> most of classical approaches assume a large sample size @xmath0 whereas the dimension @xmath1 of the observations is kept small . in this paper </S>",
    "<S> , we consider the case of high dimension , where @xmath1 is large compared to @xmath0 . </S>",
    "<S> the approach is based on recent results of random matrix theory . </S>",
    "<S> we extend our previous results to a more difficult situation when some factors are equal , and compare our algorithm to an existing benchmark method . </S>"
  ]
}