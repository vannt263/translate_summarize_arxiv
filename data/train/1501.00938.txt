{
  "article_text": [
    "the aim of this paper is to extend convergence results for greedy and randomized versions of multiplicative schwarz methods for solving elliptic variational problems in hilbert spaces from the case of finite space splittings @xcite to the case of infinite space splittings .",
    "let @xmath3 be a separable real or complex hilbert space with scalar product @xmath4 , let @xmath5 be a continuous and coercive hermitian form on @xmath3 , and let @xmath6 be a bounded linear functional on @xmath3 .",
    "note that @xmath5 induces a spectrally equivalent scalar product on @xmath3 , in the sequel we write @xmath7 to indicate that we consider @xmath3 with this new scalar product , and use the notation @xmath8 for the induced norm .",
    "then the variational problem    find @xmath9 such that @xmath10 possesses a unique solution , and is equivalent to the quadratic minimization problem    find the minimizer @xmath9 of the quadratic functional @xmath11 we treat the problem in the form ( a ) , by turning it into an infinite linear system using space splittings as described next .",
    "the equivalent formulation ( b ) provides the link to convex optimization , where algorithms similar to the ones considered here are known and investigated under the name block - coordinate descent methods .    for the separable hilbert space @xmath7",
    ", we consider _ space splittings _ generated by families of hilbert spaces @xmath12 ( with scalar product @xmath13 and norm @xmath14 ) and bounded linear operators @xmath15 , @xmath16 , such that the span of the subspaces @xmath17 is dense in @xmath7 . here , the index set @xmath18 can be finite ( @xmath19 ) , or countable ( @xmath20 ) . these conditions on a space splitting are silently assumed throughout this paper .",
    "we call a space splitting _ stable _ , and write [ sss ] v_a=_ii r_iv_a_i : = \\{v=_ii r_iv_i : v_iv_a_i , ii } , if [ sss1 ] 0 < _ : = _ uv_a _ : = _",
    "uv_a < , where @xmath21 not every infinite space splitting is stable , in particular , in ( [ sss ] ) it is assumed that every element in @xmath7 possesses at least one converging series expansion with respect to @xmath22 which follows from ( [ sss1 ] ) and the assumed density of span(@xmath22 ) in @xmath7 .",
    "the constants @xmath23 and @xmath24 are called lower and upper stability constants , and @xmath25 is called the condition of the stable space splitting ( [ sss ] ) , respectively . a prominent case of stable space splittings are frames and fusion frames , see @xcite . in all these definitions ,",
    "we allow for redundancy , i.e. , @xmath26 is not required for @xmath27 , and we do not assume that the @xmath12 are closed subspaces of @xmath7 .    for the setup of schwarz iterative methods we need to define operators @xmath28 via the variational problems [ subproblem ] a_i(t_iv , v_i)=a(v , r_iv_i ) v_iv_a_i , to be solved for given @xmath29 on the spaces @xmath12 , @xmath30 .",
    "evaluating @xmath31 is equivalent to solving a variational problem in @xmath12 , and it is silently assumed that this is easier than solving the original problem ( a ) .",
    "this stems from the fact that @xmath12 has typically much smaller dimension than @xmath7 and/or the hermitian form @xmath13 leads to a linear system with better spectral properties or simpler structure .",
    "if the underlying space splitting is finite then , using these @xmath32 , analogs of the classical jacobi - richardson and gauss - seidel - sor iterations , called additive and multiplicative schwarz methods with respect to ( stable ) space splittings can be defined and investigated , pretty much along the lines of the standard methods , see @xcite .    here",
    "we formulate a generic version of the multiplicative ( also called sequential or asynchronous ) schwarz method with relaxation suitable for the case of infinite space splittings .",
    "choose an initial approximation @xmath33 , and repeat the following steps for @xmath34 until a stopping criterion is met :    * * subproblem pick and solution * : given the current @xmath35 and an index set @xmath36 , choose an index @xmath37 ( according to some rule to be specified ) , and compute the partial residual @xmath38 , where @xmath39 .",
    "although @xmath40 is unknown , this can be done since the right - hand side in the corresponding subproblem ( [ subproblem ] ) reads @xmath41 and does not depend on knowledge about @xmath40 . *",
    "* linear update * : determine relaxation parameters @xmath42 and @xmath43 ( according to some rule to be specified ) , and set [ updatelin ] u^(m+1)=_m u^(m)+_m r_ir^(m)_i .",
    "so far , this is a theoretical algorithm since executing steps 1 and 2 is not feasible without further specification and assumptions . in the case of finite splittings ,",
    "the schwarz iterative method figures also under the name alternating directions method ( adm ) , see @xcite for references .    as to step 1 , we need to specify the rule for picking the next index @xmath44 .",
    "there are at least three standard versions to be considered :    _ deterministic orderings_. in this case , we choose an index sequence @xmath45 beforehand . in the case of finite splittings ,",
    "the default orderings are cyclic ( @xmath46 ) or symmetric - cyclic ( @xmath47 ) for @xmath48 , @xmath49 ) which corresponds to the classical sor and ssor methods , respectively .",
    "a naive deterministic ordering for infinite space splittings would be to choose @xmath50 . for finite splittings ,",
    "convergence is known for cyclic orderings from the adm theory ( compare , e.g. , @xcite ) , see also the convergence rate estimates for schwarz iterative methods in @xcite and , more recently , for coordinate descent methods and convex optimization problems @xcite .",
    "_ greedy orderings_. the idea goes back to gauss and seidel , and was popularized by southwell @xcite ( the corresponding algorithms for finite splittings are often called gauss - southwell methods ) . here",
    "the decision for the next index @xmath51 depends on the current iterate @xmath35 , and aims at maximizing the error reduction in the next step . for instance",
    ", we can require @xmath52 to satisfy [ greedysss ] a_i_m(r^(m)_i_m , r^(m)_i_m)_m^2 _",
    "ii_m a_i(r^(m)_i , r^(m)_i ) , where @xmath53 $ ] is called weakness parameter .",
    "this approach is expensive , as it involves the computation of multiple partial residuals , at least approximately , just to pick the next index .",
    "most of the research on quantitative convergence results for greedy orderings and infinite splittings ( see @xcite for an overview ) is devoted to the case @xmath54 , where finding an @xmath55 that satisfies ( [ greedysss ] ) in a numerically feasible way can be guaranteed only under additional assumptions . in practice , one would prefer working with dynamically growing but finite index sets @xmath36 . in the case of finite splittings , algorithms with greedy orderings",
    "have been analyzed in the more general setting of convex optimization methods , see e.g. @xcite for early results in this direction , for a short proof in the case of problem ( a ) , see @xcite .    _",
    "random orderings_. choose a sequence of discrete probability distributions @xmath56 and pick @xmath57 randomly according to @xmath58 , @xmath34 . even in the case of finite splittings ,",
    "a theoretical analysis of such algorithms has been started only recently but it revealed that they are competitive with the best ( often unknown ) deterministic orderings , and numerically much cheaper than greedy orderings .",
    "we refer to @xcite for the setting of the present paper ( quadratic minimization as in ( b ) ) , and to @xcite for recent convergence results on block coordinate descent methods for large - scale convex optimization problems .",
    "certainly , there are many more variants to explore . in this paper , we concentrate on greedy and random orderings for infinite splittings ( @xmath59 ) .    as to step 2 , many options have been discussed in the literature , especially in connection with greedy orderings , see @xcite for an overview and references .    the simplest algorithms result if we fix both parameters @xmath60 , @xmath61 independently of @xmath62 , and assume some normalization condition for the @xmath63",
    ". then we arrive at analogs of the algorithms discussed in the theory of greedy methods under the names weak ( wga ) and weak relaxed ( wrga ) greedy algorithms .",
    "their counterparts for @xmath64 are called pure ( pga ) and relaxed ( rga ) greedy algorithms , respectively .",
    "more generally , one can try to find @xmath65 simultaneously by minimizing the new error term [ errornext ] u - u^(m+1)_a=_0 , u - u^(m)-r_ir_i^(m)_a , with respect to @xmath66 and @xmath67 .",
    "this is equivalent to solving a two - dimensional quadratic minimization problem .",
    "various restrictions have been proposed , e.g. , @xmath68 is a popular choice , see the early work @xcite on relaxed greedy algorithms , and @xcite in a slightly more general setting .    in this paper",
    ", we consider a variant with fixed parameter sequence [ alphachoice ] _",
    "m:=1-(m+2)^-1 ( 0,1 ) , m0 , and with @xmath43 determined by minimizing the error term ( [ errornext ] ) with respect to @xmath67 . more explicitly , [ omegachoice ] _",
    "m = = , where @xmath69 , @xmath70 . in the theory of greedy algorithms ,",
    "this version is labeled gawr , see @xcite .",
    "further modifications are listed and investigated in @xcite , for extensions to convex optimization problems on hilbert and banach spaces see the recent papers @xcite .",
    "we also mention that instead of finding an optimal approximation @xmath71 only from span(@xmath72 ) as done in ( [ errornext ] ) , one could include earlier approximations @xmath73 , @xmath74 , into the local search in step 2 .",
    "orthogonal matching pursuit is a relatively expensive extension of this type .",
    "a less expensive version motivated by the conjugate gradient method would be to find @xmath71 from span(@xmath75 ) .",
    "the main contributions of this paper can be summarized as follows . for the greedy case ,",
    "we restrict ourselves in ( [ greedysss ] ) to @xmath76,\\qquad i_m=\\nn , \\qquad   m\\ge 0,\\ ] ] and give a convergence proof for the above specified theoretical algorithm .",
    "this proof is , in the case of the hilbert space setting , a modification of the approach used in @xcite . in particular",
    ", we show the convergence rate @xmath77 for @xmath40 from the class @xmath1 which will be defined below .",
    "this class appears naturally in all investigations on greedy algorithms , and the exponent @xmath78 in the convergence rate estimate is known to be optimal in our considered situation of general space splittings @xcite .    for the case of random picks with a fixed probability distribution @xmath79",
    ", we prove a similar estimate for the expected error decay , @xmath80 for @xmath40 from a smaller class @xmath2 . to the best of our knowledge",
    ", this is the first general convergence result for randomized schwarz iterative methods in the case of infinite splittings . using an approximation and density argument",
    ", we show convergence in expectation ( without guaranteed rate ) also for arbitrary @xmath81 and for sequences @xmath58 that converge to a fixed probability distribution @xmath82 in @xmath83 .",
    "although mathematically not difficult , we emphasize that our approach via space splittings ( rather than expansions with respect to dictionaries @xmath84 and updates along one - dimensional search directions ) covers block - iterative methods , auxiliary space techniques , and outer approximation schemes which may lead to a broader applicability of our theoretical findings .",
    "the remainder of this paper is organized as follows : in section [ sec2 ] we present our convergence results . to this end , we first introduce approximation spaces @xmath85 associated with a given infinite space splitting , and give some preparatory lemmata . then , we prove the main theorems on convergence estimates for greedy and randomized schwarz iterations . in section [ sec3 ]",
    "we discuss some further results and consequences .",
    "throughout this section , set @xmath59 , and fix the families @xmath86 of auxiliary hilbert spaces and @xmath87 of bounded linear operators .",
    "furthermore , let them be such that the span of the linear subspaces @xmath88 is dense in @xmath7 .",
    "we assume uniform boundedness of the operators @xmath63 , i.e. , there exists a constant @xmath89 such that [ rbound ] r_iv_i_a^2 = a(r_iv_i , r_iv_i ) ^2 a_i(v_i , v_i)=^2 v_i^2_a_i , v_iv_a_i , i . in theory , this can always be achieved by rescaling either @xmath63 or the auxiliary hermitian forms @xmath90 . for the practical application",
    "this is however irrelevant as the minimization with respect to @xmath67 in the update step 2 of the algorithms automatically takes care of this . unless stated otherwise , we will _ not _ assume that ( [ sss ] ) is a stable space splitting for @xmath7 .    for",
    "any non - negative weight sequence @xmath91 , and @xmath92 , introduce approximation spaces @xmath93 as follows : for @xmath94 , define @xmath95 and introduce @xmath96 as the completion with respect to this ( quasi-)semi - norm . for the weight sequence @xmath97",
    ", we drop the superscript @xmath98 from the notation .",
    "the cases we are most interested in are @xmath99 where @xmath100 is any given discrete probability distribution , i.e. , @xmath101 and @xmath102 .",
    "the embeddings are continuous . if ( [ sss ] ) is a stable splitting , then obviously @xmath103 , and all spaces @xmath104 and @xmath105 , @xmath106 , are subspaces of @xmath7 .",
    "they are also dense in @xmath7 ( for @xmath104 under the assumption that @xmath107 ) . for the case of one - dimensional subspaces of @xmath7 generated by a countable dictionary ,",
    "these definitions are standard and have been instrumental for setting up a quantitative convergence theory for greedy algorithms with infinite dictionaries , see @xcite .",
    "the following technical lemma is crucial for our convergence proofs below .",
    "[ lem1 ] for the underlying space splitting , assume ( [ rbound ] ) .",
    "for any @xmath108 , denote @xmath109 , @xmath110 , @xmath111 .",
    "+ a ) if @xmath112 is such that @xmath113 for some @xmath114 , then , for any nontrivial @xmath115 , we have [ agreedy ] r_i^_a_i^ = a(e , w_i^ ) a(e , h ) .",
    "b ) if @xmath116 is any discrete probability distribution , then , for any nontrivial @xmath117 , we have [ arandom ] _ i _ ir_i_a_i = _ i _",
    "i a(e , w_i ) a(e , h ) .",
    "* proof*. since @xmath118 is the unique minimizer of the associated quadratic minimization problem , i.e. , @xmath119 for any index @xmath120 , one concludes for any @xmath121 with @xmath122 that @xmath123 if @xmath124 , after dividing by @xmath125 , this yields @xmath126 this inequality holds for @xmath127 as well , since in this case @xmath128 for all @xmath121 .",
    "since by @xmath129 convergence in @xmath1 obviously implies convergence in @xmath7 , we can assume that for any @xmath130 , there exists a finitely representable [ hhref ] = _",
    "ii c_ir_iv_i ( with finite @xmath131 and @xmath132 ) such that @xmath133 for part a ) , we thus have @xmath134 and letting @xmath135 implies ( [ agreedy ] )",
    ".    similarly , in part b ) we can choose @xmath136 of the form ( [ hhref ] ) such that @xmath137 then , by the same reasoning @xmath138 with @xmath139 , we get ( [ arandom ] ) which finishes the proof of lemma 1 .",
    "@xmath140    below , we will apply this lemma with @xmath141 , i.e. the error after @xmath62 steps of the algorithm , and with @xmath142 , i.e. the weakness parameter in the case of greedy orderings , while @xmath116 coincides with the probability distribution used to create random orderings .    as another preparation",
    ", we formulate an auxiliary result for approximation in @xmath104 spaces that will allow us to work with variable probability distributions ( see also remark 4 in section [ sec3 ] ) .",
    "[ lem2 ] assume that @xmath82 is a fixed probability distribution with support @xmath143 , and assume that @xmath144 is a sequence of probability distributions that converges to @xmath116 in the @xmath83 norm .",
    "for the underlying space splitting , assume ( [ rbound ] ) .",
    "then , for any given @xmath145 , there exists a sequence of finitely representable @xmath146 such that for @xmath70 [ hm ] h - h^(m)_a ( 1 + 3)h_^_-^(m)_^1,h^(m)_^ _ 3h_^_.    * proof*. since @xmath145 , for given @xmath70 and @xmath147 there is a finite @xmath148 and a @xmath149 such that @xmath150 in the definition of @xmath151 , set @xmath152 with a constant @xmath153 to be fixed below .",
    "then , obviously , we have h - h^(m)_a & & h-|h_a + _ ii\\i^(m ) r_iv_i_a h-|h_a + _",
    "ii^(m ) v_i_a_i + & & h_^ _ ( -^(m)_^1 + ( 1+)_ii\\i^(m ) _ i ) .",
    "but for @xmath154 we have @xmath155 , thus @xmath156 on the other hand , by the definition of @xmath157 and @xmath151 @xmath158 choosing @xmath159 gives then the statement of lemma [ lem2].@xmath140      as in the case of finite space splittings @xcite , our convergence proof of the schwarz iterative method for infinite space splittings is based on the same error representation for both greedy and random orderings .",
    "we therefore state the core estimates together in one place .",
    "[ theo1 ] consider an infinite space splitting consisting of auxiliary hilbert spaces @xmath12 and bounded linear operators @xmath15 , @xmath160 , such that span(@xmath161 ) is dense in @xmath7 and ( [ rbound ] ) holds .",
    "furthermore , consider a schwarz iterative method for the variational problem ( a ) with starting approximation @xmath162 and update rule ( [ updatelin ] ) , where the parameters @xmath163 and @xmath43 are specified by ( [ alphachoice ] ) and ( [ omegachoice ] ) , respectively .",
    "+ a ) assume that the update indices @xmath44 are chosen according to the greedy rule ( [ greedysss ] ) with @xmath164 and weakness parameter @xmath165 $ ] , @xmath70 .",
    "if @xmath166 then the squared error decay is given by @xmath167 b ) assume that the update indices @xmath168 are chosen randomly and independently according to a fixed discrete probability distribution @xmath116 , @xmath70 .",
    "if @xmath169 then the expected squared error decay is given by @xmath170    * proof*. we derive a recursion for the ( expected ) squared error .",
    "suppose that @xmath35 is determined , and that the @xmath120-th subproblem solution @xmath171 is used for the update to @xmath71 according to ( [ updatelin ] ) .",
    "thus , we can write @xmath172 where @xmath173 , and , in agreement with the previous subsection , @xmath174 .",
    "the parameter @xmath175 is found by solving the minimization problem @xmath176 thus , for any @xmath177 and any chosen @xmath120 , we have @xmath178 using the triangle inequality and ( [ rbound ] ) , the norm in the last term can be bounded , independently of @xmath120 , by @xmath179    for dealing with the term @xmath180 , we invoke lemma [ lem1 ] . in the case of greedy orderings , we take @xmath181 in part a ) of lemma [ lem1 ] and choose @xmath182 .",
    "we then arrive at [ egreedy ] e^(m+1)_a^2 _ m^2 e^(m)_a^2 + 2|_m^2(u_a^2 + ( /)^2u_^1 ^ 2 ) .",
    "denote @xmath183 and @xmath184 . substituting the concrete values of @xmath185 and @xmath186 into ( [ egreedy ] )",
    ", we obtain @xmath187 since @xmath188 , this implies @xmath189 for all @xmath70 , and proves the result in part a ) of theorem [ theo1 ] .    in the case of random orderings",
    ", we now use lemma [ lem1 ] b ) for the given discrete probability distribution @xmath116 with @xmath190 .",
    "this yields the following estimate for the conditional expectation of @xmath191 with respect to given @xmath35 valid for any @xmath192 : e(e^(m+1)_a^2| u^(m ) ) & & _",
    "m^2 e^(m)_a^2 + 2_m|_m ( a(e^(m),u ) -_i _ i a(e^(m),w_i^(m ) ) ) + & & + 2|_m^2(u_a^2+^2 ^2 ) + & & _",
    "m^2 e^(m)_a^2 + 2_m|_m a(e^(m),u)(1-u_^_^-1 ) + 2|_m^2(u_a^2+^2 ^2 ) .",
    "thus , fixing @xmath193 and taking the expectations with respect to @xmath35 , we get [ erandom ] e(e^(m+1)_a^2 ) _ m^2 e(e^(m)_a^2 ) + 2|_m^2(u_a^2 + ^2u_^_^2 ) .",
    "this gives part b ) of theorem [ theo1 ] if we argue as before.@xmath140    using a density argument as in @xcite , one can extend the estimate of theorem [ theo1 ] , and show convergence for all @xmath81 .",
    "[ theo2 ] under the same assumptions as in theorem [ theo1 ] , we have convergence and expected convergence @xmath194 in @xmath7 for the greedy and random schwarz iterative methods , respectively , with no additional assumptions on the solution @xmath81 of the variational problem ( a ) .",
    "+ more precisely , for the greedy version specified in part a ) of theorem [ theo1 ] and any @xmath115 , we have [ hgreedy ] u - u^(m)_a 2 u - h_a + , m0 . for the random version specified in part",
    "b ) of theorem [ theo1 ] and any @xmath195 , we have [ hrandom ] e(u - u^(m)_a^2)^1/2 2 u - h_a + , m0 .",
    "* proof*. we start with the greedy case , take any @xmath196 . repeat the proof of part a ) of theorem [ theo1 ] .",
    "when invoking lemma [ lem1 ] a ) , use it with @xmath197 instead of @xmath40 , and set @xmath198",
    ". then @xmath199 and ( [ egreedy ] ) can be replaced by @xmath200 if @xmath201 , then @xmath202 substituting the previous estimate of @xmath191 , this yields [ egreedy1 ] e^(m+1)_a _ m e^(m)_a+ 2|_m u - h_a + , where @xmath203 .",
    "if , alternatively , @xmath204 , then ( [ egreedy1 ] ) holds trivially .",
    "the inequality ( [ egreedy1 ] ) is complemented by [ egreedy2 ] e^(m+1)_a = _ _ m e^(m ) + |_m(u - w_i^(m))_a _",
    "me^(m)_a + |_mu_a .    in the random case",
    ", we proceed similarly . for any @xmath195",
    ", we apply lemma 1 b ) with @xmath205 .",
    "this shows @xmath206 and , instead of ( [ erandom ] ) , we obtain @xmath207 where @xmath208 . using the notation @xmath209 and the obvious inequality @xmath210 , by the same reasoning as above , we arrive at the following replacement for ( [ erandom ] ) : [ erandom1 ] _ m+1 _",
    "2|_m u - h_a + . to obtain a complementary estimate analogous to ( [ egreedy2 ] ) , by definition of @xmath71",
    "we can write @xmath211 then we take expectations on both sides , use again @xmath210 , and obtain [ erandom2 ] _",
    "m+1 ( _ m^2 _ m^2 + 2_m|_m u_ae(e^(m)_a)+|_m^2 u_a^2)^1/2_m _ m + |_m u_a .    up to different constants @xmath212 and @xmath213 , the recursive inequalites ( [ egreedy1]-[egreedy2 ] ) for the sequence @xmath214 and ( [ erandom1]-[erandom2 ] ) for @xmath215",
    "are identical .",
    "therefore , it is enough to consider the random case",
    ". set @xmath216 , @xmath70 .",
    "then , a quick calculation shows that ( [ erandom2 ] ) turns into [ e2 ] b_m+1 _",
    "m^1/2 b_m + , m0 , where @xmath217 , while under the assumption @xmath218 the inequality ( [ erandom1 ] ) implies [ e1 ] b_m+1 _ m^1/2 ( b_m+ )",
    ". a similar recursive system of inequalities has been considered in @xcite .",
    "lemma [ lem3 ] stated below implies @xmath219 for all @xmath70 ( note that @xmath220 ) .",
    "this yields @xmath221 and proves ( [ hrandom ] ) .",
    "the estimate ( [ hgreedy ] ) is derived in complete analogy .    to show convergence for arbitrary @xmath81 , for given @xmath222 , choose @xmath115 by the density of @xmath1 in @xmath7 such that @xmath223 .",
    "then , with this @xmath197 fixed , the second term in the right - hand side of ( [ hgreedy ] ) will become @xmath224 for all large enough @xmath62 as well .",
    "this proves convergence for the greedy version .",
    "an analogous argument shows @xmath225 as @xmath226 for the random case .",
    "theorem [ theo2 ] is fully established.@xmath140    for the convenience of the reader , we conclude this section with the short proof of the boundedness of sequences @xmath227 satisfying the recursion ( [ e2]-[e1 ] ) used in the proof of theorem [ theo2 ] .    [ lem3 ] suppose , a sequence @xmath227 satisfies the inequalities ( [ e2 ] ) and ( [ e1 ] ) , where @xmath228 and @xmath229 .",
    "fix a constant @xmath230 .",
    "then @xmath231 implies @xmath232 for all @xmath233 .",
    "in particular , if @xmath234 one can choose @xmath235 .    * proof*. we use induction in @xmath62 .",
    "assume @xmath232 . for a value @xmath236",
    "to be fixed below , we consider two cases .",
    "if @xmath237 , by ( [ e2 ] ) we have @xmath238 if [ c2 ] t_m^-1/2 ( a - ) . on the other hand , if @xmath239 we use ( [ e1 ] ) which gives @xmath240 if [ c1 ] t = = _ m^-1/2 .",
    "it is easy to see that the choice @xmath241 satisfies both ( [ c2 ] ) and ( [ c1 ] ) if @xmath242 .",
    "the latter follows from the assumption on @xmath243 which implies @xmath244 .",
    "this finishes the induction step , and proves lemma [ lem3 ] .",
    "* remark 1 . * our results for the expected error decay for random orderings imply immediately estimates in probability .",
    "using the markov - chebyshev inequality , under the assumptions of theorem [ theo1 ] b ) , we get @xmath245 for any error threshold @xmath130 , or , equivalently , @xmath246 for any confidence level @xmath247 . an investigation of the variance or other higher - order moments of the squared error that could lead to improved estimates has not been undertaken yet .",
    "numerical experiments with randomized schwarz iterations for finite splittings @xcite suggest that the variance is reasonably small in practice .",
    "* remark 2 . *",
    "if in addition to our assumptions on space splittings we assume that ( [ sss ] ) is a stable space splitting of @xmath7 , i.e. , if @xmath103 holds , then , for @xmath248 , @xmath249 and the greedy version of the schwarz iterative method specified in part a ) of theorem [ theo1 ] , we have the error decay rate [ aqerror ] u - u^(m)_a|c ( m+1)^1/2 - 1/q u__q , m0 , where @xmath250 is some absolute constant depending on @xmath251 and the upper stability constant @xmath24 only .",
    "this can be established by an interpolation argument along the lines of @xcite , where the authors consider the special case of splittings into one - dimensional subspaces @xmath252 of @xmath7 induced by a dictionary @xmath253 of unit norm elements @xmath254 such that its span is dense in @xmath7 . for this case , the estimate ( [ aqerror ] ) may be replaced by a similar statement for @xmath255 , where @xmath256 , @xmath249 , is obtained by real interpolation for the pair @xmath257 . in the special case , when @xmath258 is a frame in @xmath7 and thus @xmath259 , the scales @xmath260 and @xmath256 coincide for @xmath261 , in general , they are different .    .",
    "in @xcite , weaker error estimates for other greedy algorithms such as pga and wga can be found .",
    "we believe that their proofs carry over to the setting based on space splittings without difficulties .",
    "e.g. , for the pga with @xmath262 , we expect @xmath263 to hold , see @xcite for the pga in the dictionary case . whether the exponent @xmath264 can be increased to @xmath78 under the assumption that ( [ sss ] ) is a stable space splitting is an open problem , even when the space splitting comes from a frame .",
    "slightly better exponents are possible for pga and wga , see @xcite .",
    ". theorems [ theo1 ] and [ theo2 ] provide convergence guarantees under theoretical assumptions that look still questionable from a practical point of view : the question of rounding errors is not addressed , for the greedy version the condition ( [ greedysss ] ) needs to be checked for an infinite index set @xmath164 , while in the random schwarz iterative method drawing the next index @xmath44 according to a ( rather general ) discrete probability distribution @xmath116 defined on @xmath143 seems inconvenient as well .",
    "for greedy algorithms based on dictionaries , there are partial results in this direction @xcite which can be adapted to the case of space splittings considered here .",
    "we concentrate on the randomized version .",
    "when combined with lemma [ lem2 ] , the estimation techniques leading to theorem [ theo2 ] give the following result which , in particular , allows us to work with finitely supported probability distributions @xmath58 that converge to a desired @xmath82 sufficiently fast , without sacrificing convergence speed .",
    "[ pro3 ] assume that the indices @xmath44 in the random schwarz iteration are chosen using discrete probability distributions @xmath144 such that [ pierror ] ^(m)-_^1 d(m+2)^-1/2 , m0 , for some @xmath82 and some constant @xmath265 .",
    "then , assuming the remaining conditions of theorem [ theo1 ] part b ) , we have the estimate [ newrandom ] e(u - u^(m)_a^2)^1/2 2 u - h_a + c ( m+1)^-1/2,m0 , for any @xmath195 , with some constant @xmath266 depending on @xmath267 , @xmath268 , @xmath269 and the constant @xmath270 in ( [ pierror ] ) .    * proof*. we repeat the same steps that lead to ( [ erandom1 ] ) , with the following changes : the conditional expectation @xmath271 is now computed with respect to @xmath58 . for estimating the difference @xmath272",
    ", we use the @xmath273 whose existence is guaranteed by lemma [ lem2 ] , and set @xmath274 .",
    "this gives & & a(e^(m),u)-_i _ i^(m ) a(e^(m),w_i^(m ) ) a(e^(m),u - h^(m ) ) e^(m)_a(u - h_a+ h - h^(m)_a ) + & & e^(m)_a(u - h_a + d(1 + 3)h_^ _ ( m+2)^-1/2 ) , where we have substituted ( [ hm ] ) and ( [ pierror ] ) .",
    "using as before the notation @xmath275 and the obvious inequality @xmath210 , we arrive at the following replacement for ( [ erandom1 ] ) : [ erandom3 ] _ m+1 _",
    "m+ |_m ( 2u - h_a + c_0(m+2)^-1/2 ) + , where as before @xmath209 . the constants are @xmath276 , and @xmath277 see ( [ hm ] ) .",
    "this gives a recursion for @xmath278 similar to ( [ e1 ] ) but with a new term induced by the additional term @xmath279 in ( [ erandom3 ] ) : [ erandom4 ] b_m+1 _ m^1/2(b_m+ ) + , = .",
    "this relation is again complemented by the inequality ( [ e2 ] ) , this time with the constant @xmath280 . since repeating",
    "the proof of lemma [ lem3 ] with the additional term in the right - hand side of ( [ erandom4 ] ) does not represent any difficulty , we leave it to the reader to show that @xmath232 , @xmath70 , holds for some new constant @xmath243 depending on @xmath281 and @xmath282 .",
    "this shows ( [ newrandom ] ) with @xmath283 , and finishes our sketch of the proof of proposition [ pro3 ] .",
    "@xmath140    in the generality considered here , the obtained convergence rates for the error @xmath284 are not very impressive but unfortunately can not be improved much . for greedy orderings ,",
    "this issue has been addressed in @xcite .",
    "we add some comments for random orderings .",
    "consider the very special situation of a one - dimensional subspace splitting induced by a complete orthonormal system @xmath258 in @xmath3 with @xmath285 , and the problem of incremental approximation of a given @xmath9 by linear combinations of elements from @xmath258 .",
    "i.e. , if @xmath286 is the unique orthogonal decomposition of @xmath40 with respect to @xmath258 , then we have @xmath287 .",
    "fix the discrete probability distribution @xmath82 , and consider the associated randomized schwarz iterative method with updates of the form ( [ updatelin ] ) .",
    "it is easy to find that , due to the orthogonality of the splitting , the best expected convergence rate is achieved for @xmath60 . in that case",
    ", we have @xmath288 with probability @xmath289 , where @xmath290 is the random index sequence , and @xmath291 is the set of the first @xmath62 such indices ( @xmath291 may have cardinality @xmath292 , repetitions are possible ) .",
    "we leave it to the reader to verify the identity @xmath293 in the particular case considered , the formula confirms the statement of theorem [ theo2 ] b ) : since @xmath294 for all @xmath111 , we have @xmath295 as @xmath226 , i.e. , the expected error converges to @xmath296 for any @xmath9 and any probability distribution @xmath82 .    on the other hand , when inspecting the statement of theorem [ theo1 ] b ) for our case",
    ", we see that @xmath169 is equivalent to the inequality @xmath297 thus , for @xmath298 we have [ pcons ] e(u - u^(m)^2 ) u_^_^2 _ i _ i^2 ( 1-_i)^m , m1 , which is sharp in the sense that equality holds ( simultaneously for all @xmath233 ) if we set @xmath299 . since @xmath300 for @xmath301 $ ] for some absolute constant @xmath153 and all @xmath233 , we get @xmath302 indeed , the first sum can be estimated according to @xmath303 and the second is a finite sum with @xmath292 terms .",
    "this result is in line with the bound of theorem [ theo1 ] .",
    "no substantial improvement of the decay rate @xmath0 can be expected for general probability distributions : for each fixed @xmath62 , taking @xmath116 sufficiently close to the uniform distribution on @xmath304 provides a lower bound of @xmath305 for the right - hand side in ( [ pcons ] ) while choosing @xmath306 according to @xmath307 shows that , for some @xmath169 , lower bounds of the form @xmath308 may hold for all @xmath70 simultaneously , with any @xmath309 .",
    "however , for sequences @xmath116 of the form @xmath310 with @xmath311 , slight improvements are possible . note that for specific complete orthonormal systems ( such as the trigonometric system in @xmath312 ) the classes @xmath313 for such @xmath116 have natural interpretations as @xmath314-besov - lipschitz spaces ( in the case of our example",
    "this would be @xmath315 , and @xmath316 corresponds to a smoothness parameter ) .",
    "better rates can also be concluded if we assume that @xmath40 belongs to a smaller class of this type with parameter @xmath317 .",
    "although the validity of these observations heavily relies on the assumed orthogonality of the splitting , we believe that especially the randomized versions should be investigated further .",
    "in particular , improved convergence rates for special classes of space splittings ( e.g. , induced by multilevel frames and sparse grid spaces ) are desirable , and the potential of randomization techniques for the development of new adaptive algorithms needs to be further evaluated .",
    "m. griebel was partially supported by the project _",
    "exahd _ of the dfg priority program 1648 _ software for exascale computing \" ( sppexa ) _ and by the sonderforschungsbereich 1060 _ the mathematics of emergent effects _ funded by the deutsche forschungsgemeinschaft .",
    "99 a.  r. barron , universal approximation bounds for superposition of n sigmoidal functions .",
    "ieee trans .",
    "theory 39 ( 1993 ) , 930 - 945 .",
    "a. barron , a. cohen , w. dahmen , r. devore , approximation and learning by greedy algorithms , annals of statistics , 3(1 ) ( 2008 ) , 64 - 94 .",
    "a. beck , l. tetruashvili , on the convergence of block coordinate descent type methods , siam journal of optimization 23 ( 2013 ) , 2037 - 2060 .",
    "o. christensen , an introduction to frames and riesz bases , birkhuser , basel , 2003 .",
    "p. casazza , g. kutyniok , frames of subspaces , in wavelets , frames , and operator theory , contemp .",
    "345 , ams , providence , ( 2004 ) , 87 - 113 .",
    "r. devore , v. temlyakov , some remarks on greedy algorithms , adv .",
    "math . 5 ( 1996 ) , 173 - 187 .",
    "r. devore , v. temlyakov , convex optimization on banach spaces , found .",
    "comput . math .",
    "( 2015 ) , 1 - 26 .",
    "a. galantai , projectors and projection methods , kluwer , dordrecht , 2004 .",
    "m. griebel , multilevelmethoden als iterationsverfahren ber erzeugendensystemen , teubner - skripte numer .",
    ", teubner 1994 . m. griebel , p. oswald , remarks on the abstract theory of additive and multiplicative schwarz methods , numer . math .",
    "70 ( 1995 ) , 163 - 180 .",
    "m. griebel , p. oswald , greedy and randomized versions of the multiplicative schwarz method , lin .",
    "( 2012 ) , 1596 - 1610 .",
    "l. jones , a simple lemma on greedy approximation in hilbert space and convergence rates for projection pursuit regression and neural network training , annals of statistics 20(1 ) ( 1992 ) , 608 - 613 .",
    "d. leventhal , a. lewis , randomized methods for linear constraints : convergence rates and conditioning , math .",
    "35 , 3 ( 2010 ) , 641 - 654 . z. luo , p. tseng , on the convergence of the coordinate descent method for convex differentiable minimization , j. optim . th . appl .",
    "72 , 1 ( 1992 ) , 7 - 35 .",
    "j. mairal , optimization with first - order surrogate functions , proc .",
    "machine learning , atlanta , ga , usa , 2013 , pp .",
    "783 - 791 .",
    "y. nesterov , efficiency of coordinate descent methods on huge - scale optimization problems , siam j. optim .",
    "22 , 2 ( 2012 ) , 341 - 362 .",
    "h. nguyen , g. petrova , greedy strategies for convex optimization , ( submitted 2014 ) , ` http://www.math.tamu.edu/\\simgpetrova/ ` .",
    "p. oswald , multilevel finite element approximation - theory & applications .",
    "teubner - skripte numer .",
    "teubner , 1994 .",
    "p. oswald , stable space splittings and fusion frames in wavelets xiii ( v.k .",
    "goyal , m. papadakis , d. van de ville , eds . ) , proc .",
    "7446 ( spie , bellingham , 2009 ) , 744611 .",
    "p. oswald , on the convergence rate of sor : a worst case estimate , computing 52 ( 1994 ) , 245 - 255 .",
    "p. oswald , w. zhou , convergence analysis for kaczmarz - type iterations in a hilbert space framework , lin .",
    "appl . 478 ( 2015 ) , 131 - 161 .",
    "p. richtarik , m. takac , iteration complexity of randomized block - coordinate descent methods for minimizing a composite function , math .",
    "144 , 2 ( 2014 ) , 1 - 38 .",
    "r. southwell , relaxation methods in engineering science - a treatise in approximate computation , oxford univ . press , oxford , 1940",
    "r. southwell , relaxation methods in theoretical physics , clarendon press , oxford , 1946 .",
    "t. strohmer , r. vershynin , a randomized kaczmarz algorithm with exponential convergence , j. fourier anal .",
    "( 2009 ) , 262 - 278 .",
    "r. tappenden , p. richtarik , j. gondzio , inexact coordinate descent : complexity and preconditioning , ( 2013 ) , arxiv:1304.5530v1 .",
    "v. temlyakov , nonlinear methods of approximation , found .",
    "math . 3 ( 2003 ) , 33 - 107 .",
    "v. temlyakov , on greedy algorithms with restricted depth search , proc .",
    "steklov inst .",
    ", 248 ( 2005 ) , 255 - 267 , also imi - report 2004:27 , univ . south carolina .",
    "v. temlyakov , greedy approximation , acta numerica , vol .",
    "17 ( 2008 ) , 235 - 409 .",
    "v. temlyakov , relaxation in greedy approximation , constr .",
    "28 , 1 ( 2008 ) , 1 - 25 .",
    "v. temlyakov , greedy approximation , cambridge univ . press , 2011 .",
    "v. temlyakov , greedy approximation in convex optimization , constr .",
    "41 , 2 ( 2015 ) , 269 - 296 .",
    "p. tseng , dual ascent methods for problems with strictly convex cost and linear constraints , siam j. control and optimization 28 , 1 ( 1990 ) , 214 - 242 .",
    "p. tseng , convergence of a block coordinate descent method for non - differentiable minimization , journal of optimizatiom theory and applications 109 , 3 ( 2001 ) , 475 - 494 .",
    "j. xu , iterative methods by space decomposition and subspace correction , siam review 34 ( 1992 ) , 581 - 613 .. t. zhang , sequential greedy approximation for certain convex optimization problems , ieee trans .",
    "49 , 3 ( 2003 ) , 682 - 691 ."
  ],
  "abstract_text": [
    "<S> we prove the convergence of greedy and randomized versions of schwarz iterative methods for solving linear elliptic variational problems based on infinite space splittings of a hilbert space . for the greedy case , </S>",
    "<S> we show a squared error decay rate of @xmath0 for elements of an approximation space @xmath1 related to the underlying splitting . for the randomized case , </S>",
    "<S> we show an expected squared error decay rate of @xmath0 on a class @xmath2 depending on the probability distribution . </S>"
  ]
}