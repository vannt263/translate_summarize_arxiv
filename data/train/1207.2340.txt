{
  "article_text": [
    "analysis of network data is important in a range of disciplines and applications , appearing in such diverse areas as sociology , epidemiology , computer science , and national security , to name a few .",
    "network data here refers to observed edges between nodes , possibly accompanied by additional information on the nodes and/or the edges , for example , edge weights .",
    "one of the fundamental questions in analysis of such data is detecting and modeling community structure within the network .",
    "a lot of algorithmic approaches to community detection have been proposed , particularly in the physics literature ; see @xcite for reviews .",
    "these include various greedy methods such as hierarchical clustering ( see @xcite for a review ) and algorithms based on optimizing a global criterion over all possible partitions , such as normalized cuts @xcite and modularity .",
    "the statistics literature has been more focused on model - based methods , which postulate and fit a probabilistic model for a network with communities .",
    "these include the popular stochastic block model @xcite , its extensions to include varying degree distributions within communities @xcite and overlapping communities , and various latent variable models @xcite .",
    "the stochastic block model is perhaps the most commonly used and best studied model for community detection . for a network with @xmath0 nodes defined by its @xmath1 adjacency matrix @xmath2 , this model postulates that the true node labels @xmath3 are drawn independently from the multinomial distribution with parameter @xmath4 , where @xmath5 for all @xmath6 , and @xmath7 is the number of communities , assumed known .",
    "conditional on the labels , the edge variables @xmath8 for @xmath9 are independent bernoulli variables with @xmath10 = p_{c_i c_j},\\ ] ] where @xmath11 $ ] is a @xmath12 symmetric matrix .",
    "the network is undirected , so @xmath13 , and @xmath14 ( no self - loops ) .",
    "the problem of community detection is then to infer the node labels @xmath15 from @xmath2 , which typically also involves estimating @xmath16 and @xmath17 .",
    "there are many extensions of the block model , notably to mixed membership models @xcite , but we will only focus on one extension here that we use later in the paper .",
    "the block model implies the same expected degree for all nodes within a community , which excludes networks with `` hub '' nodes commonly encountered in practice .",
    "the degree - corrected block model @xcite removes this constraint by replacing ( [ bm ] ) with @xmath18 = \\theta _ i \\theta_j p_{c_i c_j}$ ] , where @xmath19 s are node degree parameters which satisfy an identifiability constraint .",
    "if the degree parameters only take on a discrete number of values , one can think of the degree - corrected block model as a regular block model with a larger number of blocks , but that loses the original interpretation of communities . in @xcite the bernoulli distribution for @xmath8",
    "was replaced by the poisson , primarily for ease of technical derivations , and in fact this is a good approximation for a range of networks @xcite .",
    "fitting block models is nontrivial , especially for large networks , since in principle the problem of optimizing over all possible label assignments is np - hard . in the bayesian framework , markov chain monte carlo methods have been developed , but they only work for networks with a few hundred nodes .",
    "variational methods have also been developed and studied ( see , e.g. , ) , and are generally substantially faster than the gibbs sampling involved in mcmc , but still do not scale to the order of a million nodes .",
    "another bayesian approach based on a belief propagation algorithm was proposed recently by decelle et al .",
    "@xcite , and is comparable to ours in theoretical complexity , but slower in practice ; see more on this in section  [ secsimulations].=1    in the non - bayesian framework , a profile likelihood approach was proposed in : since for a given label assignment parameters can be estimated trivially by plug - in , they can be profiled out and the resulting criterion can be maximized over all label assignments by greedy search .",
    "the same method is used in @xcite to fit the degree - corrected block model .",
    "the speed of the profile likelihood algorithms depends on exactly what search method is used and the number of iterations it is run for , but again these generally work well for thousands but not millions of nodes .",
    "a method of moments approach was proposed in , for a large class of network models that includes the block model as a special case .",
    "the generality of this method is an advantage , but it involves counting all occurrences of specific patterns in the graph , which is computationally challenging beyond simple special cases",
    ". some faster approximations for block model fitting based on spectral representations are also available @xcite , but the properties of these approximations are only partially known .",
    "profile likelihood methods have been proven to give consistent estimates of the labels when the degree of the graph grows with the number of nodes , under both the stochastic block models and the degree - corrected version  @xcite . to obtain `` strong consistency '' of the labels , that is , the probability of the estimated label vector being equal to the truth converging to 1 , the average graph degree @xmath20 has to grow faster than @xmath21 , where @xmath0 is the number of nodes . to obtain `` weak consistency",
    ", '' that is , the fraction of misclassified nodes converging to 0 , one only needs @xmath22 .",
    "asymptotic behavior of variational methods is studied in @xcite and , and in @xcite this belief propagation method is analyzed for both the sparse [ @xmath23 and the dense ( @xmath24 ) regimes , by nonrigorous cavity methods from physics , and a phase transition threshold , below which the labels can not be recovered , is established . in fact , it is easy to see that consistency is impossible to achieve unless @xmath25 , since otherwise the expected fraction of isolated nodes does not go to 0 . the results one can get for the sparse case , such as  @xcite , can only claim that the estimated labels are correlated with the truth better than random guessing , but not that they are consistent . in this paper , for the purposes of theory we focus on consistency and thus necessarily assume that the degree grows with  @xmath0 .",
    "however , in practice we find that our methods are very well suited for sparse networks and work well on graphs with quite small degrees .",
    "our main contribution here is a new fast pseudo - likelihood algorithm for fitting the block model , as well as its variation conditional on node degrees that allows for fitting networks with highly variable node degrees within communities .",
    "the idea of pseudo - likelihood dates back to @xcite , and in general amounts to ignoring some of the dependency structure of the data in order to simplify the likelihood and make it more tractable",
    ". the main feature of the adjacency matrix we ignore here is its symmetry ; we also apply block compression , that is , divide the nodes into blocks and only look at the likelihood of the row sums within blocks .",
    "this leads to an accurate and fast approximation to the block model likelihood , which allows us to easily fit block models to networks with tens of millions of nodes .",
    "another major contribution of the paper is the consistency proof of one step of the algorithm .",
    "the proof requires new and somewhat delicate arguments not previously used in consistency proofs for networks ; in particular , we use the device of assuming an initial value that has a certain overlap with the truth , and then show the amount of overlap can be arbitrarily close to purely random . finally , we propose spectral clustering with perturbations , a new clustering method of independent interest which we use to initialize pseudo - likelihood in practice . for sparse networks ,",
    "regular spectral clustering often performs very poorly , likely due to the presence of many disconnected components .",
    "we perturb the network by adding additional weak edges to connect these components , resulting in regularized spectral clustering which performs well under a wide range of settings .",
    "the rest of the paper is organized as follows .",
    "we present the algorithms in section [ secalgorithms ] , and prove asymptotic consistency of pseudo - likelihood in section  [ secconsist ] .",
    "the numerical performance of the methods is demonstrated on a range of simulated networks in section [ secsimulations ] and on a network of political blogs in section [ secexample ] .",
    "section [ secdiscuss ] concludes with discussion , and the contains some additional technical results .",
    "the joint likelihood of @xmath2 and @xmath15 could in principle be maximized via the expectation  maximization ( em ) algorithm , but the e - step involves optimizing over all possible label assignments , which is np - hard .",
    "instead , we introduce an initial labeling vector @xmath26 , @xmath27 , which partitions the nodes into @xmath7 groups .",
    "note that for convenience we partition into the same number of groups as we assume to exist in the true model , but in principle the same idea can be applied with a different number of groups ; in fact dividing the nodes into @xmath0 groups with a single node in each group instead gives an algorithm equivalent to that of  .",
    "the main quantity we work with are the block sums along the columns , @xmath28 for @xmath29 , @xmath30 .",
    "let @xmath31 .",
    "further , let @xmath32 be the @xmath33 matrix with entries @xmath34 given by @xmath35 let @xmath36 be the @xmath37th row of @xmath32 , and let @xmath38 be the @xmath39th column of @xmath17 .",
    "let @xmath40 and @xmath41 .",
    "our approach is based on the following key observations : for each node @xmath6 , conditional on labels @xmath42 with @xmath43 :    @xmath44 are mutually independent ;    @xmath45 , a sum of independent bernoulli variables , is approximately poisson with mean @xmath46 .    with true labels @xmath47 unknown",
    ", each @xmath48 can be viewed as a mixture of poisson vectors , identifiable as long as @xmath49 has no identical rows . by ignoring the dependence among @xmath50 , using the poisson assumption , treating @xmath47 as latent variables , and setting @xmath51",
    ", we can write the pseudo log - likelihood as follows ( up to a constant ) : @xmath52 a pseudo - likelihood estimate of @xmath53 can then be obtained by maximizing @xmath54 .",
    "this can be done via the standard em algorithm for mixture models , which alternates updating parameter values with updating probabilities of node labels .",
    "once the em converges , we update the initial block partition vector @xmath55 to the most likely label for each node as indicated by em , and repeat this process for a fixed number of iterations @xmath56 .    for any labeling @xmath55 ,",
    "let @xmath57 , @xmath58 if @xmath59 , @xmath60 and @xmath61 .",
    "we suppress the dependence on @xmath55 whenever there is no ambiguity .",
    "the details of the algorithmic steps can be summarized as follows .    _",
    "the pseudo - likelihood algorithm .",
    "_ initialize labels @xmath55 , and let @xmath62 , @xmath63 , @xmath64 , @xmath65 , @xmath66 and @xmath67",
    ". then repeat @xmath56 times :    compute the block sums @xmath68 according to ( [ eqbikdef ] ) .    using current parameter estimates",
    "@xmath69 and @xmath70 , estimate probabilities for node labels by @xmath71    given label probabilities , update parameter values as follows : @xmath72    return to step 2 unless the parameter estimates have converged .",
    "update labels by @xmath73 and return to step 1 .",
    "update @xmath74 as follows : @xmath75 .",
    "in practice , in step 6 we only include the terms corresponding to @xmath76 greater than some small threshold .",
    "the em method fits a valid mixture model as long as the identifiability condition holds , and is thus guaranteed to converge to a stationary point of the objective function @xcite .",
    "another option is to update labels after every parameter update ( i.e. , skip step 4 ) .",
    "we have found empirically that the algorithm above is more stable , and converges faster . in general",
    ", we only need a few label updates until convergence , and even using @xmath77 ( one - step label update ) gives reasonable results with a good initial value",
    ". the choice of the initial value of @xmath55 , on the other hand , can be important ; see more on this in section [ secinitvalue ] .      for networks with hub nodes or those with substantial degree variability within communities ,",
    "the block model can provide a poor fit , essentially dividing the nodes into low - degree and high - degree groups .",
    "this has been both observed empirically @xcite and supported by theory @xcite .",
    "the extension of the block model designed to cope with this situation , the degree - corrected block model @xcite , has an extra degree parameter to be estimated for every node , and writing out a pseudo - likelihood that lends itself to an em - type optimization is more complicated .",
    "however , there is a simple alternative : consider the pseudo - likelihood conditional on the observed node degrees . whether these degrees are similar or not will not then matter , and the fitted parameters will reflect the underlying block structure rather than the similarities in degrees .    the conditional pseudo - likelihood is again based on a simple observation :    if random variables @xmath78 are independent poisson with means @xmath79 , their distribution conditional on @xmath80 is multinomial .    applying this observation to the variables",
    "@xmath81 , we have that their distribution , conditional on labels @xmath15 with @xmath43 and the node degree @xmath82 , is multinomial with parameters @xmath83 , where @xmath84 . the conditional log pseudo - likelihood ( up to a constant )",
    "is then given by @xmath85 and the parameters can be obtained by maximizing this function via the em algorithm for mixture models , as before .",
    "we again repeat the em for a fixed number of iterations , updating the initial partition vector after the em has converged .",
    "the algorithm is then the same as that for unconditional pseudo - likelihood , with steps 2 and 3 replaced by :    based on current estimates @xmath86 and @xmath87 , let @xmath88    given label probabilities , update parameter values as follows : @xmath89      we now turn to the question of how to initialize the partition vector @xmath55 .",
    "note that the full likelihood , pseudo - likelihoods @xmath90 and @xmath91 , and other standard objective functions used for community detection such as modularity can all be multi - modal . the numerical results in section  [ secsimulations ] suggest that the initial value can not be entirely arbitrary , but the results are not too sensitive to it .",
    "we will quantify this further in section [ secsimulations ] ; here we describe the two options we use as initial values , both of which are of independent interest as clustering algorithms for networks .",
    "one of the simplest possible ways to group nodes in a network is to separate them by degree , say by one - dimensional @xmath7-means clustering applied to the degrees as in @xcite .",
    "this only works for certain types of block models , identifiable from their degree distributions , and in general @xmath7-means does not deal well with data with many ties , which is the case with degrees .",
    "instead , we consider two - dimensional @xmath7-means clustering on the pairs @xmath92 , where @xmath93 is the number of paths of length 2 from node @xmath6 , which can be obtained by summing the rows of @xmath94 .      a more sophisticated clustering scheme is based on spectral properties of the adjacency matrix @xmath95 or its graph laplacian .",
    "let @xmath96 be diagonal matrix collecting node degrees .",
    "a common approach is to look at the eigenvectors of the normalized graph laplacian @xmath97 , choosing a small number , say @xmath98 , corresponding to @xmath99 largest ( in absolute value ) eigenvalues , with the largest eigenvalue omitted ; see , for example , @xcite .",
    "these vectors provide an @xmath99-dimensional representation for nodes of the graph , on which we can apply @xmath7-means to find clusters ; this is one of the versions of spectral clustering , which was analyzed in the context of the block model in  @xcite .",
    "we found that this version of spectral clustering tends to do poorly at community detection when applied to sparse graphs , say , with expected degree @xmath100 .",
    "the @xmath99-dimensional representation seems to collapse to a few points , likely due to the presence of many disconnected components .",
    "we have found , however , that a simple modification performs surprisingly well , even for values of @xmath101 close to 1 .",
    "the idea is to connect all disconnected components which belong to the same community by adding artificial `` weak '' links . to be precise ,",
    "we `` regularize '' the adjacency matrix @xmath2 by adding @xmath102 multiplied by the adjacency matrix of an erdos ",
    "renyi graph on @xmath0 nodes with edge probability @xmath103 , where @xmath104 is a constant .",
    "we found that , empirically , @xmath105 works well for the range of @xmath0 considered in our simulations , and that the results are essentially the same for all @xmath106 thus we make the simplest and computationally cheapest choice of @xmath107 , adding a constant matrix of small values , namely , @xmath108 where @xmath109 is the all - ones @xmath0-vector , to the original adjacency matrix .",
    "the rest of the steps , that is , forming the laplacian , obtaining the spectral representation and applying @xmath7-means , are performed on this regularized version of @xmath2 .",
    "we note that to obtain the spectral representation , one only needs to know how the matrix acts on a given vector ; since @xmath110 , the addition of the constant perturbation does not increase computational complexity .",
    "we will refer to this algorithm as spectral clustering with perturbations ( scp ) , since we perturb the network by adding new , low - weight `` edges . ''",
    "by consistency we mean consistency of node labels ( to be defined precisely below ) under a block model as the size of the graph @xmath0 grows . for the theoretical analysis , we only consider the case of @xmath111 communities .",
    "we condition on the community labels @xmath112 , that is , we treat them as deterministic unknown parameters . for simplicity , here we consider the case of balanced communities , each having @xmath113 nodes .",
    "an extension to the unbalanced case is provided in the supplementary material  @xcite .",
    "the assumption of balanced communities naturally leads us to use the class prior estimates @xmath114 in ( [ eqcpl1stepiter ] ) .",
    "we call this assumption ( e ) ( for equal class sizes ) :    assume each class contains @xmath113 nodes , and set @xmath114 .    without loss of generality",
    ", we can take @xmath115 for @xmath116 .    as an intermediate step in proving consistency for the block model introduced in section [ secintro ] ,",
    "we first prove the result for a _ directed _ block model .",
    "recall that for the ( undirected ) block model introduced earlier , one has @xmath117 in the directed case , we assume that all the entries in the adjacency matrix are drawn independently , that is , @xmath118 we will use different symbols for the adjacency and edge - probability matrices in the two cases .",
    "this is to avoid confusion when we need to introduce a coupling between the two models . in both cases ,",
    "we have assumed that diagonal entries of the adjacency matrices are also drawn randomly ( i.e. , we allow for self - loops as valid within - community edges ) .",
    "this is convenient in the analysis with minor effect on the results .",
    "the directed model is a natural extension of the block model when one considers the pseudo - likelihood approach ; in particular , it is the model for which the pseudo - likelihood assumption of independence holds .",
    "it is also a useful model of independent interest in many practical situations , in which there is a natural direction to the link between nodes , for example , in email , web , routing and some social networks .",
    "the model can be traced back to the work of holland and leinhardt @xcite and wang and wong @xcite in which it has been implicitly studied in the context of more general exponential families of distributions for directed random graphs .",
    "our approach is to prove a consistency result for the directed model , with an edge - probability matrix of the form @xmath119 note that the only additional restriction we are imposing is that @xmath120 has the same diagonal entries .",
    "both @xmath121 and @xmath122 depend on @xmath0 and can in principle change with @xmath0 at different rates .",
    "this is a slightly different parametrization from the more conventional @xmath123 , where @xmath124 ( and @xmath16 ) do not depend on @xmath0 , and @xmath125 .",
    "we use this particular parametrization here because we only consider the case @xmath126 , and it makes our results more directly comparable to those obtained in the physics literature , for example , @xcite .",
    "a coupling between the directed and the undirected model that we will introduce allows us to carry the consistency result over to the undirected model , with the edge - probability matrix @xmath127 asymptotically , the two edge - probability matrices have comparable ( to first order ) expected degree and out - in - ratio ( as defined by @xcite ) , under mild assumptions .",
    "the average degrees for @xmath120 and @xmath17 are @xmath128 and @xmath129 , respectively .",
    "the latter is @xmath130 as long as @xmath131 .",
    "the condition is satisfied as soon as the average degree of the directed model has sublinear growth : @xmath132 .",
    "the same holds for out - in - ratios .    for our analysis",
    ", we consider an e - step of the cpl algorithm .",
    "it starts from some initial estimates @xmath133 , @xmath134 and @xmath135 of parameters @xmath121 , @xmath122 and @xmath16 , together with an initial labeling @xmath55 , and outputs the label estimates @xmath136,\\ ] ] where @xmath137 are the elements of the matrix obtained by row normalization of @xmath138^t$ ] . here",
    "@xmath139 is the confusion matrix as defined in ( [ eqrdef ] ) , and @xmath74 is given by either ( [ eqedgeprobdir ] ) or ( [ eqedgeprobundir ] ) , depending on the model , with @xmath121 and @xmath122 replaced with their estimates @xmath133 and @xmath134 .",
    "the key assumption of our analysis is that the initial labeling has a certain overlap with the truth ( we will show later that the amount of overlap is not important ) . one situation where this might naturally arise is survey data , when some small fraction of nodes has been surveyed about their community membership .",
    "another possibility is to run some other crude algorithm first to obtain a preliminary result .",
    "more formally , we consider an initial labeling @xmath140 , which is balanced ( i.e. , assigns equal number of nodes to each label ) and _ matches exactly @xmath141 labels in community @xmath142 _ , for some @xmath143 .",
    "we do not assume that we know which labels are matched , or the value of @xmath144 .",
    "it is easy to see that this is equivalent to @xmath55 matching exactly @xmath141 labels in each of the two communities .",
    "assuming @xmath141 to be an integer , let @xmath145 denote the collection of such labelings , @xmath146 our goal is to obtain a uniform result guaranteeing the consistency of cpl iteration ( [ eqcpl1stepiter ] ) for any initial labeling in @xmath147 .",
    "in particular , this guarantees consistency for any initial labeling of strength at least @xmath144 , even if it is obtained by an algorithm operating on the same adjacency matrix used by cpl .",
    "as will become clear in the course of the proof of theorem [ thmcpldir ] , although @xmath148 depend on @xmath149 ( which in turn depends on @xmath144 ) and @xmath74 , under the stated ( idealized ) assumptions , we do not need to know their exact values in order to implement rule ( [ eqcpl1stepiter ] ) .",
    "in particular , we do not need to know @xmath144 .",
    "we can plug in any number in @xmath150 for @xmath144 and get the same estimates .",
    "note that the value of @xmath151 corresponds to `` no correlation '' between the true and the initial labeling , whereas @xmath152 and @xmath153 both correspond to perfect correlation ( the labels are either all true or all flipped ) .",
    "let us consider the directed case first . as our measure of performance ( i.e. , the loss function ) , we take the following ( directed - case ) mismatch ratio @xmath154 where @xmath155 are computed based on the directed adjacency matrix @xmath156 , and @xmath157 is the set of permutations of @xmath158 , with @xmath159 accounting for the fact that the labels assigned to the communities are only determined up to a permutation .",
    "the counterpart for the undirected case is denoted by @xmath160 .",
    "note that the notion of consistency based on convergence of this quantity matches the `` weak '' consistency discussed in @xcite , rather than the `` strong '' consistency used by .",
    "define @xmath161 and let @xmath162 , @xmath163 $ ] be the binary entropy function .",
    "let us also consider the collection of estimates @xmath164 which have the same ordering as true parameters @xmath165 , @xmath166 then , we have the following result .",
    "[ thmcpldir ] assume , and let @xmath167 .",
    "let the adjacency matrix @xmath156 be generated according to the directed model ( [ eqdirmod ] ) with edge - probability matrix ( [ eqedgeprobdir ] ) , and assume @xmath168 .",
    "then , there exists a sequence @xmath169 such that @xmath170 and @xmath171 \\le\\exp \\bigl ( { -n\\bigl[h ( \\gamma)-\\kappa_{\\gamma}(n)\\bigr ] } \\bigr),\\ ] ] where @xmath172 = o(1)$ ] .",
    "in particular , if @xmath173 , we have @xmath174 and the cpl estimate is uniformly consistent .",
    "we think of @xmath144 as fixed , but it is possible to let @xmath175 , making the problem harder as @xmath176 grows . we still get consistency as long as @xmath177 .    in the balanced case",
    ", the cpl iteration has a simple intuitive interpretation , as will become clear during the proof of theorem [ thmcpldir ] .",
    "one starts with an initial assignment of labels to nodes .",
    "then , each node updates its label by taking a majority vote among its neighbors . in the case",
    "where @xmath178 , it is intuitively clear that for @xmath121 large enough , this procedure     and only one community is shown . from left to right , we have the initial labeling for a sparse graph @xmath179 , the new labeling for @xmath179 after one cpl iteration , the initial labeling for a dense graph @xmath180 , and the new labeling for @xmath180 after cpl iteration .",
    "nodes with red labels are `` infected , '' that is , their community label is incorrect . for the sparse case ,",
    "cpl iteration spreads the infection , while for the dense case , it has the opposite effect . ]",
    "increases the number of correct labels relative to the initial assignment .",
    "figure [ figmajorvote ] illustrates these ideas . in the general case where @xmath181 , theorem [ thmcpldir ] states that @xmath182 is the key parameter that needs to grow for the procedure to succeed.=1    while the labels are of primary interest in community detection , one may also be interested in consistency of the estimated parameters . under strong consistency in the sense of , consistency of the natural plug - in estimates of the block model parameters follows easily ,",
    "but here we only show weak consistency of the labels . however , in the directed model the pseudo - likelihood function we defined is in fact exactly the likelihood of @xmath183 s .",
    "parameter estimates ( say @xmath133 and  @xmath134 ) obtained by the em algorithm converge to a local maximum of this function . as a consequence of theorem  [ thmcpldir ] , these estimates are also consistent ( for @xmath121 and @xmath122 ) . since the likelihood is smooth with bounded derivatives , one may be able to use standard arguments to show that the estimated parameters are a unique local maximum in a neighborhood of the truth , and even derive their asymptotic normality along ; see , for example , theorem 6.2.1 , page 384 of .",
    "we do not pursue this direction here .",
    "we now turn to the undirected case .",
    "let @xmath184    [ thmcplundir ] assume , and let @xmath185 .",
    "let the adjacency matrix @xmath2 be generated according to the undirected model ( [ equndirmod ] ) with edge - probability matrix ( [ eqedgeprobundir ] ) , and assume @xmath168 .",
    "in addition , assume @xmath186 for some @xmath187 . then , there exist sequences @xmath188 such that @xmath189 satisfies ( [ equnineq ] ) , with @xmath190 replaced with @xmath191 and @xmath192 satisfies @xmath193 and @xmath194\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad \\le3\\exp \\bigl ( { -n\\bigl[h(\\gamma)-\\kappa_{\\gamma}(n ) \\bigr ] } \\bigr),\\nonumber\\end{aligned}\\ ] ] where @xmath195 is as defined in theorem [ thmcpldir ] .    in particular ,",
    "if @xmath196 , we have @xmath197 , and the cpl estimate is uniformly consistent .",
    "the proofs of both theorems can be found in section [ secproofs ] .",
    "condition ( [ eqagamassump ] ) can be met for a fixed @xmath187 by choosing @xmath144 sufficiently small and an upper bound on @xmath198 in terms of @xmath144 .",
    "for example , for @xmath199 and @xmath200 , we have ( [ eqagamassump ] ) if @xmath201    [ weakerassum ] the parameter @xmath182 controlling consistency is the same as the one reported in @xcite and @xcite .",
    "there the concern is with recovering a labeling which is positively correlated with the truth , and the threshold of success is observed to be @xmath202 .",
    "a similar lower bound was given in for spectral clustering .",
    "here , we are concerned with moving from a positively correlated labeling to one with an asymptotically vanishing mismatch ratio [ i.e. , @xmath203 , which is why we need @xmath173 .",
    "[ remsupparef ] these results can be extended to the case of unbalanced communities .",
    "such an extension is provided for the directed block model in the supplementary material @xcite . there",
    "we consider the model with two communities of sizes @xmath204 and @xmath205 ( not necessarily equal ) and an edge - probability matrix @xmath206 which relaxes our earlier assumption @xmath207 in ( [ eqedgeprobdir ] ) . the class of initial labelings is also enlarged to include those that have @xmath208-overlap with community @xmath37 , that is , @xmath209 , with @xmath210 .",
    "in this situation , one needs more assumptions on the initial estimate @xmath74 used in the cpl iteration than in the balanced case .",
    "supplementary material @xcite gives the details .",
    "while we do not discuss the undirected case in this general setting , ideas used in the proof of theorem [ thmcplundir ] can be used to carry the results from the directed to the undirected case .",
    "here we investigate the performance of both the unconditional and conditional pseudo - likelihood algorithms on simulated networks , as well as that of spectral clustering with perturbations .",
    "we simulate two scenarios , one from the regular stochastic block model and one from the degree - corrected block model , to assess the performance in the presence of hub nodes . throughout this section ,",
    "we fix @xmath211 and @xmath212 .",
    "conditional on the labels , the edges are generated as independent bernoulli variables with probabilities proportional to @xmath213 .",
    "the parameters @xmath214 are drawn independently from the distribution of @xmath215 with @xmath216 , @xmath217 .",
    "we do not enforce the identifiability scaling constraint on @xmath218 at this point as it is absorbed into the scaling of the matrix @xmath17 in ( [ eqpscaling ] ) below .",
    "we consider two values of @xmath219 : @xmath220 , which corresponds to the regular block model , and @xmath221 , which corresponds to a network where 10% of the nodes can be viewed as hubs .",
    "the matrix @xmath17 is constructed as follows .",
    "it is controlled by two parameters : the `` out - in - ratio '' @xmath222 @xcite , which we will vary from 0 to 0.2 , and the weight vector  @xmath223 , which determines the relative degrees within communities .",
    "we consider two values of @xmath223 : @xmath224 ( no information about communities is contained in node degrees ) and @xmath225 ( degrees themselves provide relevant information for clustering ) .",
    "if @xmath226 , we set @xmath227 , a diagonal matrix . otherwise , we set the diagonal of @xmath228 to @xmath229 and set all off - diagonal elements to @xmath142 .",
    "we then fix the overall expected network degree @xmath101 , which is the natural parameter to control and which we will vary from 1 to 15 .",
    "then we rescale @xmath228 to obtain this expected degree , giving the final  @xmath17 @xmath230    to compare our results to the true labels , we will use normalized mutual information ( nmi ) .",
    "one can think of the confusion matrix @xmath32 as a bivariate probability distribution , and of its row and column sums @xmath231 and @xmath232 as the corresponding marginals .",
    "then the nmi is defined by @xcite as @xmath233 , and is always a number between 0 and  1 ( perfect match ) .",
    "it is useful to have a few benchmark values of nmi for reference : for example , for large @xmath0 , matching @xmath234 , @xmath235 and @xmath236 of the labels correspond to values of nmi of approximately @xmath237 , @xmath238 and @xmath239 , respectively .",
    "all figures show the performance of the following methods : @xmath7-means clustering on 1- and 2-degrees ( dc ) , spectral clustering ( sc ) , spectral clustering with perturbations ( scp ) , unconditional pseudo - likelihood ( upl ) initialized with either dc or scp , and conditional pseudo - likelihood ( cpl ) , with the same two initial values for labelings .",
    "the number of outer iterations for upl and cpl is set to @xmath240 ; @xmath0 , @xmath101 , @xmath219 and the number of replications @xmath241 are specified in the figures .    .",
    "]    . ]    figures [ fignmibeta ] and [ fignmilam ] show results on estimating the node labels with varying @xmath222 and  @xmath101 , respectively .",
    "generally , smaller @xmath222 and larger @xmath101 make the problem easier , as we expect . in principle",
    ", degree - based clustering gives no information about the labels with uniform weights @xmath223 , and only a moderate amount of information with nonuniform weights , so it serves as an example of a poor starting value for pseudo - likelihood .",
    "regular spectral clustering performs well with uniform weights , but very poorly with nonuniform weights ; we conjecture that this is due to a limitation of @xmath7-means .",
    "spectral clustering with perturbation , on the other hand , performs very well in all scenarios .",
    "apart from being a useful general method on its own , it also serves as an example of a good starting value for pseudo - likelihood .",
    "figures [ fignmibeta ] and [ fignmilam ] show that pseudo - likelihood achieves large gains over a poor starting value , giving surprisingly good results even when starting from the uninformative degree clustering in the case of @xmath242 .",
    "one exception is unconditional pseudo - likelihood with @xmath243 and @xmath242 , which shows that conditioning is necessary to accommodate variation in degrees when the starting value is not very good .",
    "when spectral clustering with perturbation is used as a starting value , which is already very good , upl and cpl do not have much room to do better , although upl still provides a noticeable improvement , being overall the best method when initialized with scp .",
    "it appears that a good starting value overcomes the limitations of the regular block model for networks with hubs , effectively ruling out the competing solution which divides nodes by degree .",
    "finally , figure [ figtime ] shows run times for all the methods for the case of the regular block model ( @xmath220 ) with different community weights [ @xmath242 and @xmath244 .",
    "the times shown for upl and cpl do not include the time to compute the initial value , which is shown separately . for the case",
    "@xmath242 , all methods take roughly the same amount of time . for the case",
    "@xmath245 , spectral clustering ( sc ) takes considerably more time than the rest . on the other hand",
    ", scp takes nearly the same time as it takes for @xmath224 , and it slightly outperforms dc for larger values of @xmath0 .",
    "this might be explained , in part , by the sparse matrix multiplication required for dc , which is both time and memory - consuming for large @xmath0 .",
    "generally , scp provides an excellent starting value , with low computational complexity in a variety of situations .",
    "we have also done some brief comparisons with the belief propagation ( bp ) method of @xcite .",
    "direct fair comparison is difficult because of the different platform for the belief propagation code and the different way in which it handles initial values ; generally , we found that while the computing time of belief propagation scales with @xmath0 at the same rate as ours , bp is slower by a constant factor of about 10 . in terms of accuracy of community detection , in the examples we tried bp was either similar to or a little worse than pseudo - likelihood .",
    "this dataset on political blogs was compiled by adamic and glance @xcite soon after the 2004 u.s . presidential election .",
    "the nodes are blogs focused on us politics , and the edges are hyperlinks between these blogs .",
    "each blog was manually labeled as liberal or conservative in @xcite , and we treat these as true community labels . following @xcite , we ignore directions of the hyperlinks and analyze the largest connected component of this network , which has 1222 nodes and the average degree of 27 . the distribution of degrees is highly skewed to the right ( the median degree is 13 , and the maximum is 351 ) .",
    "the results in figure [ figblogs ] show that the conditional pseudo - likelihood produces a result closest to the truth , as one would expect in view of highly variable degrees .",
    "its result is also very close to those obtained by profile maximum likelihood for the degree - corrected block model and by two different modularities @xcite .",
    "unconditional pseudo - likelihood , on the other hand , puts high - degree nodes in one group and low - degree nodes in the other .",
    "this is very close to the block model solution @xcite .",
    "this example confirms that the unconditional and conditional pseudo - likelihood methods are correctly fitting the block model and the degree - corrected block model , respectively .",
    "due to symmetry , we can assume without loss of generality that @xmath246 .",
    "similarly , we can assume @xmath247 .",
    "then , for any @xmath248 we have @xmath249 .",
    "these will be our standing assumptions throughout the proofs . to see that the assumptions are not restrictive , one can check that the proof goes through , without change , if @xmath250 and @xmath251 . for the other two cases , namely , @xmath252 and @xmath253 , or @xmath250 and @xmath247",
    ", the proof goes through by switching the estimated labels when matching them with the true labels .",
    "that is , we compare estimated community @xmath142 to true community @xmath254 and vice versa .",
    "these can seen by examining ( [ eqcpl1simp ] ) and the discussion that follows .",
    "let us introduce the following notation : @xmath255 for @xmath256 . as long as @xmath257",
    ", we have @xmath258    under the equal priors assumption ( e ) , the cpl estimate ( [ eqcpl1stepiter ] ) simplifies to @xmath259 where @xmath260 are obtained by block compression of the directed adjacency matrix  @xmath156 .",
    "let us focus on @xmath261 from now on . then @xmath262 if @xmath263 for @xmath257 , we have @xmath264 , implying that @xmath265 where @xmath149 is defined in ( [ eqrdef ] ) .",
    "it is then not hard to see that after row normalization of @xmath138^t$ ] , we obtain @xmath266 , and @xmath267 .    since by assumption @xmath249 and @xmath252 , it follows that @xmath268 .",
    "then , ( [ eqcpl1simp ] ) is equivalent to @xmath269 .",
    "recalling that @xmath270 , we can write the condition as @xmath271 and @xmath272 . let @xmath273 be the set of all @xmath274 with @xmath257 , that is , @xmath275    for @xmath276 , let @xmath277 be the fraction of mismatches over community @xmath278 .",
    "note that the overall mismatch is @xmath279.\\ ] ] since we are focusing on @xmath261 , we are concerned with @xmath280 . in a slight abuse of notation , @xmath281 in ( [ eqoverallmis ] ) is in fact an upper bound on the mismatch ratio as defined in ( [ eqmisddef ] ) , since here we are using a particular permutation  the identity .",
    "let us define , for @xmath282 and @xmath283 , @xmath284 then we have @xmath285 where the inequality is due to treating the ambiguous case @xmath286 as error .",
    "we now set out to bound this in probability .",
    "let us start with a tail bound on @xmath287 for fixed @xmath288 and @xmath6 .",
    "[ lemxitailbound ] for any @xmath289 and @xmath290 $ ] , we have @xmath291 \\le\\exp \\biggl ( { -\\frac{t^2}{4(a+b ) } } \\biggr).\\ ] ]    we apply the classical bernstein inequality for sums of independent bounded random variables .",
    "let @xmath292 $ ] .",
    "note that @xmath293| \\le\\max(\\alpha _ { ij},1-\\alpha_{ij } ) \\le1 $ ] . for @xmath261 , we have @xmath294 where @xmath295 is defined based on labeling @xmath55 which correspond to @xmath288 .",
    "in addition , since @xmath296 , we have @xmath297 bernstein inequality implies @xmath298 \\le\\exp \\biggl ( { - \\frac{t^2}{2(v+ t/3 ) } } \\biggr).\\ ] ] noting that for @xmath299 , we have @xmath300 completes the proof .    we also need a tail bound on @xmath301 .",
    "let us define @xmath302,\\qquad { \\bar{p}}_1(r ) = \\frac1m\\sum_{i=1}^mp_i(r).\\ ] ] note that these probabilities do not depend on the particular value of @xmath289 , due to symmetry .",
    "we have the following lemma .",
    "[ lemnisdtailbound ] for @xmath303 , @xmath304",
    "\\le\\exp \\bigl ( { - e m{\\bar{p}}_1(r ) u \\log u } \\bigr).\\ ] ]    follows from lemma [ lempoitail ] in the , by noting that@xmath305 are independent bernoulli random variables .",
    "now we apply lemma [ lemxitailbound ] with @xmath306 .",
    "note that @xmath307 , for @xmath252 .",
    "noting that the rhs of ( [ eqxitailbound ] ) does not depend on @xmath6 , and using ( [ eqpirdef ] ) , we get @xmath308    the cardinality of the set @xmath309 is @xmath310})^2 $ ] where @xmath311 is the binary entropy function , and @xmath312 is as defined in the statement of the theorem .",
    "( see lemma 6 in the supplementary material @xcite for a proof . )",
    "applying lemma [ lemnisdtailbound ] with @xmath313 and the union bound , we obtain @xmath314\\\\ & & \\qquad \\le \\exp \\bigl\\ { { m \\bigl [ 2h(\\gamma ) -e { \\bar{p}}_1(0 ) u_n\\log u_n+ 2\\kappa _ { \\gamma}(n ) \\bigr ] } \\bigr\\}.\\end{aligned}\\ ] ] pick @xmath315 such that @xmath316 it follows , using @xmath113 , that @xmath317 \\le\\exp\\bigl\\ { -\\bigl[h(\\gamma ) - \\kappa_{\\gamma}(n)\\bigr ] n\\bigr\\}.\\ ] ] by symmetry the same bound holds for @xmath318 .",
    "it follows from ( [ eqoverallmis ] ) that the same holds for @xmath319 .",
    "this completes the proof of theorem [ thmcpldir ] .",
    "recall that @xmath2 and @xmath156 are the adjacency matrices of the undirected and directed cases , respectively .",
    "let us define @xmath320 , @xmath321 , @xmath322 as we did in the directed case , but based on @xmath2 instead of @xmath156 . for example , @xmath323 .",
    "our approach is to introduce a _ deterministic coupling _ between @xmath2 and @xmath156 , which allows us to carry over the results of the directed case .",
    "let @xmath324_{ij } = \\cases { 0 , & \\quad $ { \\widetilde{a}}_{ij } = { \\widetilde{a}}_{ji } = 0 $ , \\cr 1 , & \\quad otherwise.}\\ ] ] in other words , the graph of @xmath2 is obtained from that of @xmath156 by removing directions .",
    "note that @xmath325 which matches the relation between ( [ eqedgeprobdir ] ) and ( [ eqedgeprobundir ] ) . from ( [ eqcoupleaat ] )",
    ", we also note that @xmath326    let us now upper - bound @xmath327 in terms of @xmath328 . based on ( [ eqcoupleineq ] ) , only those @xmath329 that are equal to @xmath142",
    "contribute to the upper bound .",
    "more precisely , let @xmath330 , and take @xmath261 from now on .",
    "then @xmath331 we further notice that @xmath332 . to simplify notation ,",
    "let us define @xmath333 where the dependence on @xmath288 is due to @xmath334 being derived from @xmath288 [ recall that @xmath335 .",
    "thus we have shown @xmath336 recall from definition ( [ eqdefagam ] ) that @xmath337    [ lemaistailbound ] fix @xmath338 . for @xmath261 , we have @xmath339 = { \\mathbb{p}}\\bigl [ { { \\widetilde{a}}_{*i}}(\\sigma ) > ( 1 + { \\varepsilon } ) { a_\\gamma}\\bigr ] \\le",
    "\\exp \\biggl\\ { { -\\frac{{\\varepsilon}^2}{1+{\\varepsilon}/3 } } { a_\\gamma}\\biggr\\}.\\ ] ]    the equality of the two probabilities follows by symmetry .",
    "let us prove the bound for @xmath340 .",
    "we apply bernstein inequality .",
    "note that @xmath341 = \\sum_{j \\in{\\mathcal{s}}_{11 } } { \\mathbb{e}}[{\\widetilde{a}}_{ij}]+ \\sum _ { j \\in{\\mathcal{s}}_{12 } } { \\mathbb{e}}[{\\widetilde{a}}_{ij } ] \\\\ & = & \\sum_{j \\in{\\mathcal{s}}_{11 } } \\frac{a}{m } + \\sum _ { j \\in{\\mathcal{s}}_{12 } } \\frac{b}{m } = a\\gamma+ b(1-\\gamma ) = { a_\\gamma}.\\end{aligned}\\ ] ] since @xmath342 , we obtain @xmath343 \\le\\exp \\biggl ( { -\\frac{t^2}{2(\\mu+ t/3 ) } } \\biggr).\\ ] ] setting @xmath344 completes the proof .    from ( [ eqxiaxitineq ] )",
    ", it follows that @xmath345 which @xmath346 is the logical or .",
    "this can be seen ( as usual ) by noting that if the rhs does not hold , then @xmath347 , implying @xmath348 . translating to indicator functions , @xmath349 averaging over @xmath261 ( i.e. , applying @xmath350 ) , we get @xmath351 where @xmath352 , and similarly for @xmath353 . note that @xmath354 and @xmath355 , while not independent , have the same distribution by symmetry , so we can focus on bounding one of them .",
    "the key is that each one is a sum of i.i.d .",
    "terms , for example , @xmath356 .",
    "we have a bound on @xmath357 from lemma [ lemnisdtailbound ] .",
    "we can get similar bounds on the @xmath358-terms . to start , let @xmath359,\\qquad { \\bar{q}}_1(r ) = \\frac1m\\sum_{i=1}^mq_i(r),\\ ] ] similar to ( [ eqpirdef ] ) , and note that these quantities too are independent of the particular choice of @xmath289 .",
    "[ lemqtailbound ] for @xmath303 , @xmath360 \\le\\exp \\bigl ( { - e m{\\bar{q}}_1(r ) u \\log u } \\bigr).\\ ] ]    follows from lemma [ lempoitail ] in the , by noting that@xmath361 is an independent sequence of bernoulli variables .",
    "the same bound holds for @xmath362 .",
    "recall the definition of @xmath363 from  ( [ eqpirdef ] ) . using ( [ eqnqineq ] ) and lemmas [ lemnisdtailbound ] and [ lemqtailbound ]",
    ", we get @xmath364 \\biggr ] \\\\ & & \\qquad \\le{\\mathbb{p}}\\biggl [ \\sup_{\\sigma\\in\\sigma^\\gamma } \\frac1 m { \\widetilde{n}}_{n,1}(\\sigma;r ) \\ge e u_n{\\bar{p}}_1(r ) \\biggr]\\\\ & & \\qquad\\quad{}+ 2 { \\mathbb{p}}\\biggl [ \\sup_{\\sigma\\in\\sigma^\\gamma } \\frac1m{\\widetilde{q}}_{n,1 * } ( \\sigma;r/2 ) \\ge e v_n{\\bar{q}}_1(r ) \\biggr ] \\\\ & & \\qquad \\le \\exp \\bigl\\ { { m \\bigl [ 2h(\\gamma ) -e { \\bar{p}}_1(r ) u_n\\log u_n+ 2\\kappa _ { \\gamma}(n ) \\bigr ] } \\bigr\\}\\\\ & & \\qquad\\quad{}+ 2\\exp \\bigl\\ { { m \\bigl [ 2h(\\gamma ) -e { \\bar{q}}_1(r ) v_n\\log v_n+ 2\\kappa _ { \\gamma}(n ) \\bigr ] } \\bigr\\}\\end{aligned}\\ ] ] as long as @xmath365 . now ,",
    "take @xmath366 , so that lemma [ lemaistailbound ] implies @xmath367 now , in lemma [ lemxitailbound ] , take @xmath368 .",
    "note that the assumption @xmath369 implies @xmath370 .",
    "in addition @xmath371 as before .",
    "thus , the chosen @xmath372 is valid for lemma [ lemxitailbound ]",
    ". furthermore , @xmath373 .",
    "hence , the lemma implies @xmath374 ^ 2\\frac { ( a - b)^2}{a+b } } \\biggr\\}.\\ ] ] pick @xmath315 and @xmath375 such that @xmath376 the rest of the argument follows as in the directed case .",
    "this completes the proof of theorem [ thmcplundir ] .",
    "the proposed pseudo - likelihood algorithms provide fast and accurate community detection for a range of settings , including large and sparse networks , contributing to the long history of empirical success of pseudo - likelihood approximations in statistics . for the theoretical analysis ,",
    "we did not focus on the convergence properties of the algorithms , since standard em theory guarantees convergence to a local maximum as long as the underlying poisson or multinomial mixture is identifiable .",
    "the consistency of a single iteration of the algorithm was established for an initial value that is better than purely arbitrary , as long as , roughly speaking , the graph degree grows , and there are two balanced communities with equal expected degrees .",
    "the theory shows that this local maximum is consistent , and unique in a neighborhood of the truth , so in fact there is no need to assume that em has converged to the global maximum , an assumption which is usually made in analyzing em - based estimates . the theoretical analysis can be extended to the general two - community model with possibly unbalanced communities , as detailed in the supplementary material @xcite .",
    "extending our argument to more than two communities also seems possible , but that would require extremely meticulous tracking of a large number of terms which we did not pursue .",
    "we conjecture that additional results may be obtained under weaker assumptions if one focuses simply on estimating the parameters of the block model rather than consistency of the labels , just like one can obtain results for a labeling correlated with the truth ( instead of consistent ) under weaker assumptions discussed in remark [ weakerassum ] .",
    "for example , in a very recent paper @xcite , results are obtained under very weak assumptions for the mean squared error of estimating the block model parameter matrix @xmath17 ( which in itself does not guarantee consistency of the labels ) .",
    "while the primary interest in community detection is estimating the labels rather than the parameters , we plan to investigate this further to see if and how our conditions can be relaxed .",
    "while in theory any `` reasonable '' initial value guarantees convergence , in practice the choice of initial value is still important , and we have investigated a number of options empirically .",
    "spectral clustering with perturbations , which we introduced primarily as a method to initialize pseudo - likelihood , deserves more study , both empirically ( e.g. , investigating the optimal choice of the tuning parameter ) , and theoretically .",
    "this is also a topic for future work .",
    "here is a lemma which we used quite often in proving consistency results in section [ secproofs ] .",
    "[ lempoitail ] consider @xmath377 to be independent bernoulli variables with @xmath378 = p_i$ ] .",
    "let @xmath379 , @xmath380 = \\sum_{i=1}^mp_i$ ] and @xmath381 .",
    "then , for any @xmath303 , we have @xmath382    we apply a direct chernoff bound .",
    "let @xmath383 . then , by a result of hoeffding @xcite ( also see @xcite ) , @xmath384 for any convex function @xmath385 . letting @xmath386 , we obtain for @xmath387 , @xmath388 where we have used @xmath389 .",
    "the rhs is the chernoff bound for a poisson random variable with mean @xmath390 , and can be optimized to yield @xmath391 letting @xmath392 for @xmath303 and noting that @xmath393 , we get @xmath394 which is the desired bound .",
    "we would like to thank roman vershynin ( mathematics , university of michigan ) for highly illuminating discussions ."
  ],
  "abstract_text": [
    "<S> many algorithms have been proposed for fitting network models with communities , but most of them do not scale well to large networks , and often fail on sparse networks . here </S>",
    "<S> we propose a new fast pseudo - likelihood method for fitting the stochastic block model for networks , as well as a variant that allows for an arbitrary degree distribution by conditioning on degrees . </S>",
    "<S> we show that the algorithms perform well under a range of settings , including on very sparse networks , and illustrate on the example of a network of political blogs . </S>",
    "<S> we also propose spectral clustering with perturbations , a method of independent interest , which works well on sparse networks where regular spectral clustering fails , and use it to provide an initial value for pseudo - likelihood . </S>",
    "<S> we prove that pseudo - likelihood provides consistent estimates of the communities under a mild condition on the starting value , for the case of a block model with two communities .    ,    ,     + </S>"
  ]
}