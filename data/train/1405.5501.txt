{
  "article_text": [
    "[ [ technology - background ] ] technology background + + + + + + + + + + + + + + + + + + + + +    an ion mobility ( i m ) spectrometer ( ims ) measures the concentration of volatile organic compounds ( vocs ) in the air or exhaled breath by ionizing the compounds , applying an electric field and measuring how many ions drift through the field after different amounts of time . a multi - capillary column ( mcc ) can be coupled with an ims to pre - separate a complex sample by retaining different compounds for different times in the columns ( according to surface interactions between the compound and the column ) . as a consequence , compounds with the same ion mobility can be distinguished by their distinct retention times .    recently , the mcc / ims technology has gained importance in medicine , especially in breath gas analysis , as vocs may hint at certain diseases like lung cancer , chronic obstructive pulmonary disease ( copd ) or sarcoidosis  @xcite .",
    "a typical mcc / ims measurement takes about ten minutes . within this time the mcc pre - separates the sample .",
    "an i m spectrum is captured periodically every 100  ms .",
    "the aligned set of captured ims spectra is referred to an i m spectrum - chromatogram ( imsc ) which consists of an  @xmath0 matrix  @xmath1 , where  @xmath2 is the set of retention time points ( whenever an i m spectrum is captured , measured in seconds ) , and  @xmath3 is the set of drift time points ( whenever an ion measurement is made ; in milliseconds ) . to remove the influences of pressure , ambient temperature or drift tube size",
    ", a normalized quantity is used instead of drift time , namely the reduced mobility  @xmath4 with units of  @xmath5 , as described by  @xcite .",
    "( reduced ) mobility is inversely proportional to drift time , so we consider the reduced inversed mobility ( rim )  @xmath6 with units of  @xmath7 .",
    "rim and drift time are proportional , with the proportionality constant depending on the above external quantities . as not mentioned otherwise , in the following we use @xmath8 and @xmath9 which corresponds to the voltage and length of our ims drift tube .",
    "we assume that all time points ( or rims ) are equidistant ; so we may work with matrix indices  @xmath10 and  @xmath11 for convenience . on average , an i m spectrum takes about @xmath12 , corresponding to @xmath13 and an imsc about  @xmath14 .",
    "the signal values of an imsc are digitized by an analog - digital converter with a precision of  12  bits . since the device can operate in positive and negative mode , the values range between  @xmath15 and  @xmath16 .",
    "figure  [ fig : visualized - imsc ] visualizes an imsc as a heat map .",
    "areas with a high signal value are referred to as _ peaks_. a peak is caused by the presence ( and concentration ) of a certain compound ; the peak position  @xmath17 indicates which compound is present , and the peak volume contains information about the concentration .",
    "an inherent feature of ims technology is that the drift gas is ionized , too , which results in a `` peak '' that is present at each retention time at a rim of  @xmath18 ( figure  [ fig : visualized - imsc ] ) .",
    "it is referred to as the reactant ion peak ( rip ) .",
    "[ [ related - work - and - novel - contributions ] ] related work and novel contributions + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a typical work flow from a raw imsc to a `` diagnosis '' or classification of the measurement into one of two ( or several ) separate classes generally proceeds along the following steps described by @xcite : pre - processing , peak candidate detection , peak picking , and parametric peak modeling .",
    "all methods of this paper are adaptations of the expectation - maximization ( em ) algorithm , modified for their particular task .",
    "the em  algorithm ( introduced by @xcite ) is a statistical method frequently used for deconvolving distinct components in mixture models and estimating their parameters .",
    "we summarize its key properties in section  [ sec : algo : em ] .",
    "we previously used the em  algorithm for peak modeling , at the same time decomposing a measurement into separate peaks .",
    "we introduced a model that describes the shape of a peak with only seven parameters using a two - dimensional shifted inverse gaussian distribution function with an additional volume parameter @xcite .",
    "we also evaluated different peak candidate detection and peak picking methods , comparing for example manual picking by an expert with state of the art tools like iphex @xcite , visualnow @xcite , and our own methods @xcite .    in this work ,",
    "we focus on pre - processing .",
    "pre - processing is a crucial step because it determines the difficulty and the accuracy with which peak candidates ( and peaks ) can be identified and correctly modeled .",
    "it consists of several sub - tasks : denosing , baseline correction and smoothing .",
    "we discuss novel methods for denoising with integrated smoothing ( section  [ sec : denoising ] ) and for baseline correction ( section  [ sec : baseline ] ) .",
    "a second focus of this work is on finding peaks that correspond to each other ( and hence to the same measured compound ) in several measurements of a dataset .",
    "we introduce an em - based clustering method ( section  [ sec : clustering ] ) .",
    "an accurate clustering is important for determining feature vectors for classification .",
    "as the detected location of a peak may differ between several measurements , a clustering approach across measurements suggests itself .",
    "several clustering algorithms like  @xmath19-means ( first introduced by  @xcite ) or hierarchical clustering have the disadvantage that they need a fixed number of models or a threshold for the density within a cluster . in practice",
    ", these algorithms are executed several times with an increasing number of clusters and take the best result with respect to a cost function penalized with model complexity .",
    "dbscan  @xcite is a clustering method which does not require a fixed cluster number .",
    "we demonstrate that our proposed em variants outperform existing methods for their respective tasks in section  [ sec : eval ] and conclude the paper with a brief discussion .",
    "this section describes our adaptations of the em  algorithm ( summarized in section  [ sec : algo : em ] ) for denoising ( section  [ sec : denoising ] ) , baseline correction ( section  [ sec : baseline ] ) and peak clustering across different measurements ( section  [ sec : clustering ] ) .",
    "the first two methods use heterogeneous model components , while the last one dynamically adjusts the number of clusters . for each algorithm",
    ", we present background knowledge , the specific mixture model , the choice of initial parameter values , the maximum likelihood estimators of the m - step ( the e - step is described in section  [ sec : algo : em ] ) , and the convergence criteria . for peak clustering",
    ", we additionally describe the dynamic adjustment of the number of components .",
    "the algorithms are evaluated in section  [ sec : eval ] .      in all subsequent sections , variations of the em  algorithm @xcite for mixture model deconvolution",
    "are used . here",
    "we summarize the algorithm and describe the e - step common to all variants .",
    "a fundamental idea of the em  algorithm is that the observed data  @xmath20 is viewed as a sample of a mixture ( convex combination )  @xmath21 of probability distributions , @xmath22 where @xmath23  indexes the  @xmath24  different component distributions  @xmath25 , where @xmath26 denotes all parameters of distribution  @xmath25 , and @xmath27 is the collection of all parameters .",
    "the mixture coefficients @xmath28 satisfy @xmath29 for all  @xmath23 , and @xmath30 .",
    "we point out that , unlike in most applications , in our case the probability distributions @xmath25 are of different types , e.g. , a uniform and a gaussian one .",
    "the goal of mixture model analysis is to estimate the mixture coefficients  @xmath31 and the individual model parameters  @xmath32 , whose number and interpretation depends on the parametric distribution  @xmath25 .    since the resulting maximum likelihood parameter estimation problem is non - convex , iterative locally optimizing methods such as the expectation maximization ( em ) algorithm are frequently used .",
    "the em  algorithm consists of two repeated steps : the e - step ( expectation ) estimates the expected membership of each data point in each component and then the component weights  @xmath33 , given the current model parameters  @xmath34 .",
    "the m - step ( maximization ) estimates maximum likelihood parameters  @xmath26 for each parametric component  @xmath25 individually , using the expected memberships as hidden variables that decouple the model .",
    "as the em  algorithm converges towards a local optimum of the likelihood function , it is important to choose reasonable starting parameters for  @xmath35 .",
    "[ [ e - step ] ] e - step + + + + + +    the e - step is independent of the specific component distribution types and always proceeds in the same way , so we summarize it here once , and focus on the specific m - step in each of the following subsections . to estimate the expected membership  @xmath36 of data point  @xmath37 in each component  @xmath23 ,",
    "the component s relative probability at that data point is computed , i.e. , @xmath38 such that  @xmath39 for all  @xmath40",
    ". then the new component weight estimates  @xmath41 are the averages of  @xmath36 across all data points , @xmath42 where  @xmath43 is the number of data points .",
    "[ [ convergence ] ] convergence + + + + + + + + + + +    after each m - step of an em  cycle , we compare @xmath44 ( old parameter value ) and @xmath45 ( updated parameter value ) , where  @xmath46 indexes the elements of  @xmath47 , the parameters of component  @xmath23 .",
    "we say that the algorithm has converged when the relative change @xmath48 drops below the threshold  @xmath49 , corresponding to  @xmath50 precision , for all  @xmath51 .",
    "( if @xmath52 , we set @xmath53 . )      [ [ background ] ] background + + + + + + + + + +    a major challenge during peak detection in an imsc is to find peaks that only slightly exceed the background noise level .    as a simple method , one could declare each point  @xmath17 as a peak whose intensity  @xmath54 exceeds a given threshold .",
    "in imscs , peaks become wider with increasing retention time , while their volume remains constant , so their height shrinks , while the intensity of the background noise remains at the same level .",
    "so it is not appropriate to choose a constant noise level threshold , as peaks at high retention times may be easily missed .    to determine whether the intensity  @xmath54 at coordinates  @xmath17 belongs to a peak region or can be solely explained by background noise , we propose a method based on the em  algorithm .",
    "it runs in  @xmath55 time where  @xmath56 is the number of em  iterations .",
    "before we explain the details of the algorithm , we mention that it does not run on the imsc directly , but on a smoothed matrix  @xmath57 containing local averages from a window with margin  @xmath58 ; @xmath59 for all  @xmath10 , @xmath11 .",
    "since the borders of an imsc do not contain important information , we deal with boundary effects by computing  @xmath60 in those cases as averages of only the existing matrix entries .",
    "to choose the smoothing radius  @xmath58 , we consider the following argument . for distinguishing two peaks , @xcite introduced a minimum distance in reduced inverse mobility of  @xmath61 . in our datasets",
    "( 2500 drift times with a maximal value of reduced inverse mobility of  @xmath13 ) , this corresponds to  @xmath62 index units , so we use  @xmath63 index units to avoid taking to much noise into consideration .",
    "[ [ mixture - model ] ] mixture model + + + + + + + + + + + + +    based on observations of imsc signal intensities , we assume that    * the noise intensity has a gaussian distribution over low intensity values with mean  @xmath64 and standard deviation  @xmath65 , @xmath66 * the true signal intensity has an inverse gaussian distribution with mean @xmath67 and shape parameter  @xmath68 , i.e. , @xmath69 * there is an unspecific background component which is not well captured by either of the two previous distributions ; we model it by the uniform distribution over all intensities , @xmath70 and we expect the weight  @xmath71 of this component to be close to zero in standard imscs , a deviation indicating some anomaly in the measurement .",
    "we interpret the smoothed observed imsc  @xmath57 as a sample of a mixture of these three components with unknown mixture coefficients . to illustrate this approach ,",
    "consider figure  [ fig : denoisingmodels ] , which shows the empirical intensity distribution of an imsc ( histogram ) , together with the estimated components ( except the uniform distribution , which has the expected coefficient of almost zero ) .",
    "( green bars ) and estimated distribution of the noise component ( red line ) and of the signal component ( blue line ) . parameters for both components were estimated with the em  algorithm.,scaledwidth=98.0% ]    it follows that there are six independent parameters to estimate : @xmath64 , @xmath65 , @xmath67 , @xmath68 and weights @xmath72 ( noise , signal , background , where @xmath73 ) .    [",
    "[ initial - parameter - values ] ] initial parameter values + + + + + + + + + + + + + + + + + + + + + + + +    as the first and last  @xmath74 of data points in each spectrum can be assumed to contain no signal , we use their intensities empirical mean and standard deviation as starting values for  @xmath64 and  @xmath65 , respectively .",
    "the initial weight of the noise component is set to cover most points covered by this gaussian distribution , i.e. , @xmath75 .",
    "we assume that almost all of the remaining weight belongs to the signal component , thus @xmath76 , and @xmath77 .    to obtain initial parameters for the signal model ,",
    "let @xmath78 ( the complement of the intensities that are initially assigned to the noise component ) .",
    "we set @xmath79 and @xmath80 ( which are the maximum likelihood estimators for inverse gaussian parameters ) .",
    "[ [ maximum - likelihood - estimators ] ] maximum likelihood estimators + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the maximization step ( m - step ) we estimate maximum likelihood parameters for the non - uniform components . in all sums ,  @xmath81 extends over the whole matrix index set  @xmath82 .",
    "@xmath83    [ [ final - step ] ] final step + + + + + + + + + +    after convergence ( 810 em  loops in practice ) , the denoised signal matrix  @xmath84 is computed as follows : @xmath85      [ [ background-1 ] ] background + + + + + + + + + +    in an imsc , the rip with its long tail interferes with peak detection ; it is present is each spectrum and hence called the _ baseline_. the goal of this section is to remove the baseline and better characterize the remaining peaks .",
    "we consider every chromatogram ( column of the matrix shown in figure  [ fig : visualized - imsc ] ) separately .",
    "the idea is to consider intensities that appear at many retention times as part of the baseline . by analyzing the histogram  @xmath86 of chromatogram  @xmath87 ( with bin size  @xmath88 , since signal values are integers )",
    ", we observe that frequently occurring signals that are produced by the i m device itself or by drift gas , build the highest peak in the histogram , consider figure  [ fig : histogram - chromatograms ] ( top ) . on the other hand , histograms of chromatograms that are only negligibly influenced by the rip",
    "have a peak in the range of the background noise mean , see figure  [ fig : histogram - chromatograms ] ( bottom ) .",
    "[ [ mixture - model-1 ] ] mixture model + + + + + + + + + + + + +    we make the following assumption based on observations of chromatogram intensities :    * the intensities belonging to the baseline are normally distributed around their mean , @xmath89 * the remaining intensities belong to the signal of interest and can have any value above the baseline , so they are modeled by a uniform distribution between the minimum value  @xmath90 and maximum value  @xmath91 in the chromatogram  @xmath92 at drift time  @xmath93 , @xmath94    [ [ initial - parameter - values-1 ] ] initial parameter values + + + + + + + + + + + + + + + + + + + + + + + +    the start parameter for  @xmath95 is the most frequent intensity in the chromatogram ( the mode of the histogram ) ; we also set  @xmath96 and @xmath97 , @xmath98 .",
    "[ [ maximum - likelihood - estimators-1 ] ] maximum likelihood estimators + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the new values for mean and standard deviation of  @xmath99 are estimated by the standard maximum likelihood estimators , weighted by component membership .",
    "the following formulas apply to a single chromatogram  @xmath92 .",
    "@xmath100    [ [ final - step-1 ] ] final step + + + + + + + + + +    when the parameters converge , the baseline intensity for  @xmath92 is estimated at  @xmath101 ( note that we omitted the index  @xmath93 for  @xmath95 and  @xmath102 , as each chromatogram is processed independently ) .",
    "this baseline value is subtracted from each intensity in the chromatogram , setting resulting negative intensities to zero . in other words ,",
    "the new matrix is @xmath103 .",
    "[ [ background-2 ] ] background + + + + + + + + + +    peaks in several measurements are described by their location in retention time and reduced inverse mobility ( rim ) .",
    "let  @xmath104 be a union set of peak locations from different measurements with  @xmath105 being the number of peaks and  @xmath106 the retention time of peak  @xmath40 and  @xmath107 its rim .",
    "we assume that due to the slightly inaccurate capturing process , a peak ( produced by the same compound ) that appears in different measurements has slightly shifted retention time and rim .",
    "we introduce a clustering approach using standard 2-dimensional gaussian mixtures , but with dynamically adjusting the number of clusters in the process .",
    "[ [ mixture - model-2 ] ] mixture model + + + + + + + + + + + + +    we assume that the measured retention times and rims belonging to peaks from the same compound are independently normally distributed in both dimensions around the ( unknown ) component retention time and rim .",
    "let @xmath108 be the parameters for component  @xmath109 , and let @xmath110 be a two - dimensional gaussian distribution for a peak location @xmath111 with these parameters , @xmath112 the mixture distribution is @xmath113 with a yet undetermined number  @xmath24 of clusters .",
    "note that there is no `` background '' model component .",
    "[ [ initial - parameter - values-2 ] ] initial parameter values + + + + + + + + + + + + + + + + + + + + + + + +    in the beginning , we initialize the algorithm with as many clusters as peaks , i.e. , we set  @xmath114 .",
    "this assignment makes a background model obsolete , because all peaks are assigned to at least one cluster .",
    "all clusters get as start parameters for @xmath115 the original retention time and rim of peak location  @xmath116 , respectively , for  @xmath117 .",
    "remark that we are using in this description not the indices but the actual measures .",
    "we set @xmath118 and @xmath119 according to the peak characterizations by @xcite , dividing by  3 to let  @xmath120 since due to the strong skewed peaks in retention time the area under the curve is asymmetric .",
    "[ [ dynamic - adjustment - of - the - number - of - clusters ] ] dynamic adjustment of the number of clusters + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    after computing weights in the e - step , but before starting the m - step , we dynamically adjust the number of clusters by merging clusters whose centers are close .",
    "every pair  @xmath121 of clusters is compared in a nested for - loop .",
    "when @xmath122 and @xmath123 , then clusters  @xmath109 and  @xmath124 are merged by summing the weights @xmath125 and @xmath126 for all  @xmath40 , and these are assigned to the location of the cluster with larger weight .",
    "( the re - computation of the parameters happens immediately after merging in the maximization step . )",
    "the comparison order may matter in rare cases for deciding which peaks are merged first , but since new means and variances are computed , possible merges that were omitted in the current iteration , will be performed in the next iteration .",
    "this merging step is applied first time in the second iteration , since the cluster means need at least one iteration to move towards each other .",
    "[ [ maximum - likelihood - estimators-2 ] ] maximum likelihood estimators + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the maximum likelihood estimators for mean and variance of a two - dimensional gaussian are the standard ones , taking into account the membership weights , @xmath127 for all components  @xmath128 .",
    "one problem using this approach emerges from the fact that initially each cluster contains only one peak , leading to an estimated variance of zero in many cases . to prevent this , minimum values are enforced such that @xmath129 and @xmath130 for all  @xmath109 .",
    "[ [ final - step-2 ] ] final step + + + + + + + + + +    the em  loop terminates when no merging occurs and the convergence criteria for all parameters are fulfilled .",
    "the resulting membership weights determine the number of clusters as well as the membership coefficient of peak location  @xmath131 to cluster  @xmath109 .",
    "if a hard clustering is desired , the merging step has to be protocoled . at the beginning",
    "all peak indexes are singletons within their own sets . by merging ,",
    "the sets of both peaks are merged .",
    "in this section , we evaluate our algorithms against existing state - of - the - art ones on simulated data . we first discuss general aspects of generating simulated imscs ( section  [ sec : eval : general ] ) and then report on the evaluation results for denoising ( section  [ sec : eval : denoising ] ) , baseline correction ( section  [ sec : eval : baseline ] ) and peak clustering ( section  [ sec : eval : clustering ] ) .",
    "since we do not have `` clean '' real data , we decided to simulate imscs and add noise with the same properties as observed in real ims datasets .",
    "we generate simulated imscs of  @xmath132 retention time points and  @xmath133 rim points with several peaks ( see below ) , subsequently add noise ( see below ) , apply our and competing algorithms and compare the resulting imscs with the original simulated one .    [",
    "[ simulating - imscs - with - peaks ] ] simulating imscs with peaks + + + + + + + + + + + + + + + + + + + + + + + + + + +    a peak in an imsc can be described phenomenologically by a two - dimensional shifted inverse gaussian ( ig ) distribution @xcite .",
    "the one - dimensional shifted ig is defined by the probability density @xmath134 where  @xmath135 is an offset value .",
    "the density of a peak is @xmath136 where @xmath137 is the volume of the peak and @xmath138 .",
    "since the parameters  @xmath139 vary strongly on similar shapes , it is more intuitive to describe the function in terms of three descriptors , the mean  @xmath140 , the standard deviation  @xmath102 and the mode  @xmath141 .",
    "there is a bijection between  @xmath142 and  @xmath143 given by @xmath144 and the model parameters  @xmath142 can be uniquely recovered from these descriptors .",
    "the descriptors are drawn uniformly from the following intervals ( the unit for retention times is  s , the unit for rims is  @xmath7 , and volumes  @xmath137 are given in arbitrary volume units ) :    [ cols=\">,^ , < \" , ]     peak clusters are ellipsoidal and dense .",
    "from @xcite we know the minimum required distance between two peaks in order to be identified as two separate compounds .",
    "we simulate peak cluster centroids , 30 in the dense area and 20 in the sparse area , all picked randomly and uniformly distributed .",
    "we then randomly pick the number of peaks per cluster .",
    "we also randomly pick the distribution of peaks within a cluster . since we do not know the actual distribution model",
    ", we decided to simulate with three models : normal  ( n ) , exponential  ( e ) and uniform  ( u ) distribution with the following densities : @xmath145 here @xmath146 is the coordinate of the centroid with rim in @xmath7 and retention time in  s. for the normal distribution , @xmath147 and @xmath148 . for exponential distribution , @xmath149 (",
    "reduced mobility width for in single cell within  @xmath150 ) and  @xmath151 . for the uniform distribution",
    ", we use an ellipsoid with radii @xmath152 and @xmath153 .",
    "we compared the em  clustering with two common clustering methods , namely  @xmath19-means and dbscan .",
    "since  @xmath19-means needs a fixed  @xmath19 for the number of clusters and appropriate start values for the centroids , we decided to take  @xmath19-means++ ( described by  @xcite ) for estimating good starting values and give it an advantage by assigning the true number of partitions .",
    "dbscan has the advantage that it does not need a fixed number of clusters , but on the other hand it has some disadvantages .",
    "it finds clusters with non - linearly separable connections , but we assume that the partitions obey a kind of model with convex hull . on the other hand it yields no parameters describing the clusters .",
    "such parameters can be very important when using the clusters as features for a consecutive classification .    to measure the quality of the clustering  @xmath154 we take two measures in consideration : the fowlkes - mallows index ( fmi ) first described by  @xcite as well as the normalized variation of information ( nvi ) score introduced by  @xcite .    for the fmi one has to consider all pairs of data points .",
    "if two data points belong into the same true partition of  @xmath155 , they are called  _ connected_. accordingly , a pair of data points is called  _ clustered _ if they are clustered together by the clustering method we want to evaluate .",
    "pairs of data points , which are marked as connected as well as clustered , are referred to as true positives ( tp ) .",
    "false positives ( fp , not connected but clustered ) and false negatives ( fn , connected but not clustered ) are computed , analogously .",
    "the fmi is the geometric mean of precision and recall , let where  @xmath155 is the partition set and  @xmath154 the clustering . since , @xmath156 means no similarity between both clusterings and @xmath157 means that the clusterings agree completely .",
    "although the fmi determines the similarity between two clusterings , it yields unreliable results when the number of clusters in both clusterings differs significantly .",
    "thus we use a second measure that considers clusters sizes only , the normalized variation of information ( nvi ) . to compute the nvi",
    ", an auxiliary  @xmath158-dimensional matrix  @xmath159 has to be set up .",
    "thereby  @xmath160 determines the number of data points within partition  @xmath40 that are assigned to cluster  @xmath109 . using entropies",
    ", we can now determine the nvi score .",
    "define @xmath161 where  @xmath43 is the number of data points .",
    "@xmath162 means no variation between original partition and clustered data .",
    "an fmi score  @xmath163 and nvi score  @xmath164 indicates a perfect clustering .    for the first test we generated 100 sets of data points where the partitions is known , as previously described . in the second step",
    "performed an em  clustering as well as  @xmath19-means and dbscan for every set .",
    "finally we computed the both scores fmi and nvi for all sets .",
    "our results show that even with the unfair  @xmath19-means our em  clustering performs best in terms fmi and nvi score .",
    "it achieves in average best results , figure  [ fig : clusterresultswn ] shows two histograms of both fmi and nvi for all three methods . since this scenario is little realistic , we performed a second test .",
    "the difference to the first test is that we insert 200 equally distributed peaks randomly into the measurement area .",
    "all these peaks are singletons within the partition set . we denote the additional peaks as noise . after performing the second test",
    ", we can see that em  clustering still achieves best results in average , whereas @xmath19-means completely fails although we forward the correct  @xmath19 , because of insufficient determination of start points and no noise handling .",
    "all fmi and nvi scores from the second test are plotted as a histogram in figure  [ fig : clusterresults ] .",
    "we have presented three novel methods for certain problems i.e. denoising , baseline correction and clustering .",
    "all methods utilize a modified version of the em  algorithm for a deconvolution of mixture models .",
    "since our research is located in spectra analysis of ion mcc / ims devices , these methods are adjusted for this application field , but can easily be adapted for other purposes . in all tests our methods performed with best results . because of lack of the truth behind original measurements , we simulated test data using properties of real mcc / ims measurements .",
    "all methods are being applied for automated breath gas analysis to improve the accuracy of disease prediction , as previously evaluated by  @xcite .",
    "dk , sr are supported by the collaborative research center ( sonderforschungsbereich ,  sfb ) 876 `` providing information by resource - constrained data analysis '' within project tb1 , see http://sfb876.tu-dortmund.de .",
    "arthur , d. and vassilvitskii , s. ( 2007 ) .",
    "k - means++ : the advantages of careful seeding . in _ proceedings of the eighteenth annual acm - siam symposium on discrete algorithms",
    "_ , soda 07 , pages 10271035 .",
    "society for industrial and applied mathematics .",
    "bunkowski , a. , bdeker , b. , bader , s. , westhoff , m. , litterst , p. , and baumbach , j.  i. ( 2009 ) .",
    "signals in human breath related to sarcoidosis  results of a feasibility study using an automated peak finding procedure . , * 3*(4 ) , 046001 .",
    "ester , m. , kriegel , h .-",
    "sander , j. , and xu , x. ( 1996 ) . a density - based algorithm for discovering clusters in large spatial databases with noise . in _",
    "knowledge discovery and data mining ( kdd ) , proceedings of first international conference _ , volume  96 , pages 226231 .",
    "hauschild , a.  c. , kopczynski , d. , daddario , m. , baumbach , j.  i. , rahmann , s. , and baumbach , j. ( 2013 ) .",
    "peak detection method evaluation for ion mobility spectrometry by using machine learning approaches .",
    ", * 3*(2 ) , 277293 .",
    "kopczynski , d. , baumbach , j.  i. , and rahmann , s. ( 2012 ) .",
    "peak modeling for ion mobility spectrometry measurements . in _",
    "signal processing conference ( eusipco ) , 2012 proceedings of the 20th european _ , pages 18011805",
    ". ieee .",
    "macqueen , j. ( 1967 ) .",
    "some methods for classification and analysis of multivariate observations . in _ proceedings of the fifth berkeley symposium on mathematical statistics and probability",
    "_ , volume 1 : statistics , pages 281297 .",
    "university of california press .",
    "reichart , r. and rappoport , a. ( 2009 ) . the nvi clustering evaluation measure . in _ proceedings of the thirteenth conference on computational natural language learning _ , pages 165173 .",
    "association for computational linguistics .",
    "westhoff , m. , litterst , p. , freitag , l. , urfer , w. , bader , s. , and baumbach , j. ( 2009 ) .",
    "ion mobility spectrometry for the detection of volatile organic compounds in exhaled breath of lung cancer patients . , * 64 * , 744748 .",
    "westhoff , m. , litterst , p. , maddula , s. , bdeker , b. , rahmann , s. , davies , a.  n. , and baumbach , j.  i. ( 2010 ) .",
    "differentiation of chronic obstructive pulmonary disease ( copd ) including lung cancer from healthy control group by breath analysis using ion mobility spectrometry .",
    ", * 13*(3 - 4 ) , 131139 ."
  ],
  "abstract_text": [
    "<S> coupling a multi - capillary column ( mcc ) with an ion mobility ( i m ) spectrometer ( ims ) opened a multitude of new application areas for gas analysis , especially in a medical context , as volatile organic compounds ( vocs ) in exhaled breath can hint at a person s state of health . to obtain a potential diagnosis from a raw mcc / ims measurement , several computational steps are necessary , which so far have required manual interaction , e.g. , human evaluation of discovered peaks . </S>",
    "<S> we have recently proposed an automated pipeline for this task that does not require human intervention during the analysis . </S>",
    "<S> nevertheless , there is a need for improved methods for each computational step . in comparison to gas chromatography / mass spectrometry ( gc / ms ) data , </S>",
    "<S> mcc / ims data is easier and less expensive to obtain , but peaks are more diffuse and there is a higher noise level . </S>",
    "<S> mcc / ims measurements can be described as samples of mixture models ( i.e. , of convex combinations ) of two - dimensional probability distributions . </S>",
    "<S> so we use the expectation - maximization ( em ) algorithm to deconvolute mixtures in order to develop methods that improve data processing in three computational steps : denoising , baseline correction and peak clustering . </S>",
    "<S> a common theme of these methods is that mixture components within one model are not homogeneous ( e.g. , all gaussian ) , but of different types . </S>",
    "<S> evaluation shows that the novel methods outperform the existing ones . </S>",
    "<S> we provide python software implementing all three methods and make our evaluation data available at http://www.rahmannlab.de/research/ims . </S>"
  ]
}