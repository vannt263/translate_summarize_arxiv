{
  "article_text": [
    "the regularity lemma of szemerdi @xcite has proved to be a very useful tool in graph theory . it was initially developed as an auxiliary lemma to prove a long standing conjecture of erds and turn@xcite on arithmetic progressions , which stated that sequences of integers with positive upper density must contain arbitrarily long arithmetic progressions .",
    "now the regularity lemma by itself has become an important tool and found numerous other applications ( see @xcite ) .",
    "based on the regularity lemma and the blow - up lemma @xcite the regularity method has been developed that has been quite successful in a number of applications in graph theory ( e.g. @xcite ) .",
    "however , one major disadvantage of these applications and the regularity lemma is that they are mainly theoretical , they work only for astronomically large graphs as the regularity lemma can be applied only for such large graphs . indeed , to find the @xmath1-regular partition in the regularity lemma",
    ", the number of vertices must be a tower of 2 s with height proportional to @xmath2 .",
    "furthermore , gowers demonstrated @xcite that a tower bound is necessary .",
    "the basic content of the regularity lemma could be described by saying that every graph can , in some sense , be partitioned into random graphs . since random graphs of a given edge density",
    "are much easier to treat than all graphs of the same edge - density , the regularity lemma helps us to carry over results that are trivial for random graphs to the class of all graphs with a given number of edges .",
    "we are especially interested in harnessing the power of the regularity lemma for clustering data .",
    "graph partitioning methods for clustering and segmentation have become quite popular in the past decade because of representative ease of data with graphs and the strong theoretical underpinnings that accompany the same .    in this paper",
    "we propose a general methodology to make the regularity lemma more useful in practice . to make it truly applicable , instead of constructing a provably regular partition we construct an _ approximately _ regular partition .",
    "this partition behaves just like a regular partition ( especially for graphs appearing in practice ) and yet it does not require the large number of vertices as mandated by the original regularity lemma",
    ". then this approximately regular partition is used for performing clustering .",
    "we call the resulting new clustering technique _ regularity clustering_. we present comparisons with standard clustering methods such as @xmath0-means and spectral clustering and the results are very encouraging .",
    "to present our attempt and the results obtained , the paper is organized as follows : in section [ prior ] we discuss briefly some prior attempts to apply the regularity lemma in practical settings and place our work in contrast to those . in section [ clust ]",
    "we discuss clustering in general and also present a popular spectral clustering algorithm that is used later on the reduced graph .",
    "we also point out what are the possible ways to improve its running time . in section [ not ]",
    "we give some definitions and general notation . in section [ reg ]",
    "we present two constructive versions of the regularity lemma ( the original lemma was non - constructive ) .",
    "furthermore , in this section we point out the various problems arising when we attempt to apply the lemma in real - world applications . in section [ mod ]",
    "we discuss how the constructive regularity lemmas could be modified to make them truly applicable for real - world problems where the graphs typically are much smaller , say have a few thousand vertices only . in section [ app ]",
    "we show how this practical regularity partitioning algorithm can be applied to develop a new clustering technique . in section [ test ] , we present an extensive empirical validation of our method .",
    "section [ future ] is spent in discussing the various possible future directions of work .",
    "as we discussed above so far the regularity lemma has been  well beyond the realms of any practical applications \" @xcite , the existing applications have been theoretical , _ mathematical_. the only practical application attempt of the regularity lemma to the best of our knowledge is by sperotto and pelillo @xcite , where they use the regularity lemma as a pre - processing step .",
    "they give some interesting ideas on how the regularity lemma might be used , however they do not give too many details .",
    "taking leads from some of their ideas we give a much more thorough analysis of the modifications needed in order to make the lemma applicable in practice .",
    "furthermore , they only give results for using the constructive version by alon _",
    "et al _ @xcite , here we implement the version proposed by frieze and kannan @xcite as well .",
    "we also give a far more extensive empirical validation ; we use 12 datasets instead of 3 .",
    "out of the various modern clustering techniques , spectral clustering has become one of the most popular .",
    "this has happened due to not only its superior performance over the traditional clustering techniques , but also due to the strong theoretical underpinnings in spectral graph theory and its ease of implementation .",
    "it has many advantages over the more traditional clustering methods such as @xmath0-means and expectation maximization ( em ) .",
    "the most important is its ability to handle datasets that have arbitrary shaped clusters .",
    "methods such as @xmath0-means and em are based on estimating explicit models of the data .",
    "such methods fail spectacularly when the data is organized in very irregular and complex clusters .",
    "spectral clustering on the other hand does not work by estimating explicit models of the data but does so by analysing the spectrum of the graph laplacian .",
    "this is useful as the top few eigenvectors can unfold the data manifold to form meaningful clusters .    in this work",
    "we employ spectral clustering on the reduced graph ( which is an essence of the original graph ) , even though any other pairwise clustering method could be used .",
    "the algorithm that we employ is due to ng , jordan and weiss @xcite . despite various advantages of spectral clustering ,",
    "one major problem is that for large datasets it is very computationally intensive . and",
    "understandably this has received a lot of attention recently .",
    "as originally stated , the spectral clustering pipeline has two main bottlenecks : first , computing the affinity matrix of the pairwise distances between datapoints , and second , once we have the affinity matrix the finding of the eigendecomposition .",
    "many ways have been suggested to solve these problems more efficiently .",
    "one approach is not to use an all - connected graph but a k - nearest neighbour graph in which each data point is typically connected to @xmath3 neighboring datapoints(where @xmath4 is the number of data - points ) .",
    "this considerably speeds up the process of finding the affinity matrix , however it has a drawback that by taking nearest neighbors we might miss something interesting in the global structure of the data . a method to remedy",
    "this is the nystrm method which takes a random sample of the entire dataset ( thus preserving the global structure in a sense ) and then doing spectral clustering on this much smaller sample . the results are then extended to all other points in the data set @xcite .",
    "our work is quite different from such methods .",
    "the speed - up is primarily in the second stage where eigendecomposition is to be done .",
    "the original graph is represented by a reduced graph which is much smaller and hence eigendecomposition of this reduced graph can significantly ease the computational load . further work on a practical variant of the sparse regularity lemma",
    "could be useful in a speed - up in the first stage , too .",
    "below we introduce some notation and definitions for describing the regularity lemma and our methodology .",
    "let @xmath5 denote a graph , where @xmath6 is the set of vertices and @xmath7 is the set of edges .",
    "when @xmath8 are disjoint subsets of @xmath6 , the number of edges with one endpoint in @xmath9 and the other in @xmath10 is denoted by @xmath11 . when @xmath9 and @xmath10 are nonempty , we define the _ density _ of edges between @xmath9 and @xmath10 as @xmath12 .",
    "the most important concept is the following .",
    "the bipartite graph @xmath13 is @xmath1-_regular _ if for every @xmath14 , @xmath15 satisfying : @xmath16 otherwise it is @xmath1-_irregular_.    roughly speaking this means that in an @xmath1-regular bipartite graph the edge density between _ any _ two relatively large subsets is about the same as the original edge density . in effect",
    "this implies that all the edges are distributed almost uniformly .",
    "[ defn ] a partition @xmath17 of the vertex set @xmath18 of a graph @xmath5 is called an _ equitable partition _ if all the classes @xmath19 , have the same cardinality .",
    "@xmath20 is called the exceptional class .",
    "[ potential ] for an equitable partition @xmath17 of the vertex set @xmath21 of @xmath5 , we associate a measure called the _ index _ of @xmath17 ( or the potential ) which is defined by @xmath22    this will measure the progress towards an @xmath1-regular partition .",
    "an equitable partition @xmath17 of the vertex set @xmath21 of @xmath5 is called @xmath1-_regular _ if @xmath23 and all but @xmath24 of the pairs @xmath25 are @xmath1-regular where @xmath26 .    with these definitions we are now in a position to state the regularity lemma .",
    "[ p1 ] for every positive @xmath27 and positive integer @xmath28 there is an integer @xmath29 such that every graph with @xmath30 vertices has an @xmath1-regular partition into @xmath31 classes , where @xmath32 .    in applications of the regularity lemma",
    "the concept of the _ reduced graph _ plays an important role .    [",
    "reduced ] given an @xmath1-regular partition of a graph @xmath33 as provided by theorem [ p1 ] , we define the _ reduced graph _ @xmath34 as follows .",
    "the vertices of @xmath34 are associated to the classes in the partition and the edges are associated to the @xmath1-regular pairs between classes with density above @xmath35 .",
    "the most important property of the reduced graph is that many properties of @xmath36 are inherited by @xmath34 .",
    "thus @xmath34 can be treated as a representation of the original graph @xmath36 albeit with a much smaller size , an `` essence '' of @xmath36 .",
    "then if we run any algorithm on @xmath34 instead of @xmath36 we get a significant speed - up .      the original proof of the regularity lemma @xcite does not give a method to construct a regular partition but only shows that one must exist . to apply the regularity lemma in practical settings ,",
    "we need a constructive version .",
    "_ @xcite were the first to give an algorithmic version . since then a few other algorithmic versions have also been proposed @xcite , @xcite .",
    "below we present the details of the alon _",
    "algorithm .",
    "[ al ] for every @xmath27 and every positive integer @xmath28 there is an integer @xmath37 such that every graph with @xmath30 vertices has an @xmath1-regular partition into @xmath38 classes , where @xmath39 . for every fixed @xmath27 and @xmath40",
    "such a partition can be found in @xmath41 sequential time , where @xmath42 is the time for multiplying two @xmath4 by @xmath4 matrices with @xmath43 entries over the integers .",
    "the algorithm can be parallelized and implemented in @xmath44 .",
    "this result is somewhat surprising from a computational complexity point of view since as it was proved in @xcite that the corresponding decision problem ( checking whether a given partition is @xmath1-regular ) is co - np - complete .",
    "thus the search problem is easier than the decision problem . to describe this algorithm",
    ", we need a couple of lemmas .",
    "[ lnew1 ] let @xmath45 be a bipartite graph with equally sized classes @xmath46 .",
    "let @xmath47 .",
    "there is an @xmath41 algorithm that verifies that @xmath45 is @xmath1-regular or finds two subset @xmath48 , @xmath49 , @xmath50 , @xmath51 , such that @xmath52 .",
    "the algorithm can be parallelized and implemented in @xmath44 .",
    "this lemma basically says that we can either verify that the pair is @xmath1-regular or we provide certificates that it is not .",
    "the certificates are the subsets @xmath53 and they help to proceed to the next step in the algorithm .",
    "the next lemma describes the procedure to do the refinement from these certificates .",
    "[ lnew2 ] let @xmath5 be a graph with @xmath4 vertices .",
    "let @xmath17 be an equitable partition of the vertex set @xmath18 .",
    "let @xmath54 and let @xmath0 be a positive integer such that @xmath55 . if more than @xmath56 pairs @xmath57 , @xmath58 , are @xmath59-irregular then there is an equitable partition @xmath60 of @xmath6 into @xmath61 classes , with the cardinality of the exceptional class being at most @xmath62 and such that @xmath63    this lemma implies that whenever we have a partition that is not @xmath59-regular , we can refine it into a new partition which has a better index ( or potential ) than the previous partition .",
    "the refinement procedure to do this is described below .",
    "* refinement algorithm : * _ given a @xmath59-irregular equitable partition @xmath17 of the vertex set @xmath64 with @xmath65 , construct a new partition @xmath60 .",
    "+ for each pair @xmath66 , @xmath67 , we apply lemma [ lnew1 ] with @xmath68 , @xmath69 and @xmath1 . if @xmath66 is found to be @xmath1-regular we do nothing",
    ". otherwise , the certificates partition @xmath70 and @xmath71 into two parts ( namely the certificate and the complement ) . for a fixed @xmath72",
    "we do this for all @xmath73 . in @xmath70 ,",
    "these sets define the obvious equivalence relation with at most @xmath74 classes , namely two elements are equivalent if they lie in the same partition part for every @xmath75 .",
    "the equivalence classes will be called atoms . set @xmath76 , @xmath77 .",
    "then we construct our new partition @xmath60 by choosing a maximal collection of pairwise disjoint subsets of @xmath6 such that every subset has cardinality @xmath78 and every atom @xmath9 contains exactly @xmath79 subsets ; all other vertices are put in the exceptional class . the collection @xmath60 is an equitable partition of @xmath6 into at most @xmath80 classes and the cardinality of its exceptional class is at most @xmath81 . _    now we are ready to present the main algorithm .",
    "* regular partitioning algorithm : *    _ given a graph @xmath36 and @xmath1 , construct a @xmath1-regular partition .",
    "_    1 .   * initial partition : * arbitrarily divide the vertices of @xmath36 into an equitable partition @xmath82 with classes @xmath83 , where @xmath84 and hence @xmath85 .",
    "denote @xmath86 .",
    "2 .   * check regularity : * for every pair @xmath87 of @xmath88 , verify if it is @xmath1-regular or find @xmath89 , such that @xmath90 .",
    "3 .   * count regular pairs : * if there are at most @xmath91 pairs that are not verified as @xmath1-regular , then halt .",
    "@xmath88 is an @xmath1-regular partition .",
    "* refinement : * otherwise apply the refinement algorithm and lemma [ lnew2 ] , where @xmath92 , and obtain a partition @xmath60 with @xmath93 classes .",
    "* iteration : * let @xmath94 , and go to step 2 .",
    "since the index can not exceed @xmath95 , the algorithm must halt after at most @xmath96 iterations ( see @xcite ) .",
    "unfortunately , in each iteration the number of classes increases to @xmath97 from @xmath0 .",
    "this implies that the graph @xmath36 must be indeed astronomically large ( a tower function ) to ensure the completion of this procedure . as mentioned before",
    ", gowers @xcite proved that indeed this tower function is necessary in order to guarantee an @xmath1-regular partition for _ all _ graphs .",
    "the size requirement of the algorithm above makes it impractical for real world situations where the number of vertices typically is a few thousand .",
    "the frieze - kannan constructive version is quite similar to the above , the only difference is how to check regularity of the pairs in step 2 . instead of lemma [ lnew1 ] ,",
    "another lemma is used based on the computation of singular values of matrices . for the sake of completeness we present the details .",
    "[ singularfk ] let @xmath98 be an @xmath99 matrix with @xmath100 and @xmath101 and @xmath102 and @xmath59 be a positive real .    1 .",
    "if there exist @xmath103 such that @xmath104 and @xmath105 then @xmath106 ( where @xmath107 is the first singular value ) .",
    "if @xmath108 then there exist @xmath103 such that @xmath109 and @xmath110 , where @xmath111 .",
    "furthermorem @xmath112 can be constructed in polynomial time .    combining lemmas [ lnew2 ] and [ singularfk ]",
    ", we get an algorithm for finding an @xmath1-regular partition , quite similar to the alon _",
    "_ version @xcite , which we present below :    * regular partitioning algorithm ( frieze - kannan ) : *    _ given a graph @xmath36 and @xmath113 , construct a @xmath113-regular partition . _    1 .",
    "* initial partition : * arbitrarily divide the vertices of @xmath36 into an equitable partition @xmath82 with classes @xmath83 , where @xmath84 and hence @xmath85 .",
    "denote @xmath86 .",
    "2 .   * check regularity : * for every pair @xmath87 of @xmath88 , compute @xmath114 .",
    "if the pair @xmath115 are not @xmath1-regular then by lemma [ singularfk ] we obtain a proof that they are not not @xmath116-regular .",
    "3 .   * count regular pairs : * if there are at most @xmath117 pairs that produce proofs of non @xmath59-regularity , then halt .",
    "@xmath88 is an @xmath113-regular partition .",
    "* refinement : * otherwise apply the refinement algorithm and lemma [ lnew2 ] , where @xmath118 , and obtain a partition @xmath119 with @xmath93 classes .",
    "* iteration : * let @xmath120 , and go to step 2 .    this algorithm is guaranteed to finish in at most @xmath121 steps with an @xmath1-regular partition .",
    "we see that even the constructive versions are not directly applicable to real world scenarios .",
    "we note that the above algorithms have such restrictions because their aim is to be applicable to _ all _ graphs .",
    "thus , to make the regularity lemma truly applicable we would have to give up our goal that the lemma should work for _ every _ graph and should be content with the fact that it works for _ most _ graphs . to ensure that this happens , we modify the regular partitioning algorithm(s ) so that instead of constructing a regular partition , we find an _ approximately _ regular partition , which should be much easier to construct .",
    "we have the following 3 major modifications to the regular partitioning algorithm .",
    "* modification 1 : * we want to decrease the cardinality of atoms in each iteration . in the above refinement algorithm",
    "the cardinality of the atoms may be @xmath74 , where @xmath0 is the number of classes in the current partition .",
    "this is because the algorithm tries to find all the possible @xmath1-irregular pairs such that this information can then be embedded into the subsequent refinement procedure .",
    "hence potentially each class may be involved with up to @xmath122 @xmath1-irregular pairs .",
    "one way to avoid this problem is to bound this number .",
    "to do so , instead of using all the @xmath1-irregular pairs , we only use some of them .",
    "specifically , in this paper , for each class we consider at most one @xmath1-irregular pair that involves the given class . by doing this we reduce the number of atoms to at most @xmath123 .",
    "we observe that in spite of the crude approximation , this seems to work well in practice .",
    "* modification 2 : * we want to bound the rate by which the class size decreases in each iteration .",
    "as we have at most @xmath123 atoms for each class , we could significantly increase @xmath78 used in the refinement algorithm as @xmath124 , where a typical value of @xmath125 could be @xmath126 or @xmath127 , much smaller than @xmath128 .",
    "we call this user defined parameter @xmath125 the refinement number .",
    "* modification 3 : * modification 2 might cause the size of the exceptional class to increase too fast .",
    "indeed , by using a smaller @xmath125 , we risk putting @xmath129 portion of all vertices into @xmath20 after each iteration . to overcome this drawback , we `` recycle '' most of @xmath20 , i.e. we move back most of the vertices from @xmath20 .",
    "here is the modified refinement algorithm .",
    "* modified refinement algorithm : * _ given a @xmath59-irregular equitable partition @xmath17 of the vertex set @xmath64 with @xmath65 and refinement number @xmath125 , construct a new partition @xmath60 .",
    "+ for each pair @xmath66 , @xmath67 , we apply lemma [ lnew1 ] with @xmath68 , @xmath69 and @xmath1 . for a fixed @xmath72",
    "if @xmath66 is found to be @xmath1-regular for all @xmath75 we do nothing , i.e. @xmath70 is one atom .",
    "otherwise , we select one @xmath1-irregular pair @xmath66 randomly and the corresponding certificate partitions @xmath70 into two atoms . set @xmath130 , @xmath77 . then first we choose a maximal collection @xmath131 of pairwise disjoint subsets of @xmath6 such that every member of @xmath131 has cardinality @xmath78 and every atom @xmath9 contains exactly @xmath79 members of @xmath131",
    ". then we unite the leftover vertices in each @xmath70 , if there are at least @xmath78 vertices then we select one more subset of size @xmath78 from these vertices , we add these sets to @xmath131 and finally we add all remaining vertices to the exceptional class , resulting in the partition @xmath60 .",
    "the collection @xmath60 is an equitable partition of @xmath6 into at most @xmath132 classes .",
    "_    now , we present our modified regular partitioning algorithm",
    ". there are three main parameters to be selected by the user : @xmath1 , the refinement number @xmath125 and @xmath133 , the minimum class size when we must halt the refinement procedure .",
    "the parameter @xmath133 is used to ensure that if the class size has gone too small then the procedure should not continue .    *",
    "modified regular partitioning algorithm ( or the practical regularity partitioning algorithm ) : *    _ given a graph @xmath36 and parameters @xmath1 , @xmath125 , @xmath133 , construct an approx .",
    "@xmath1-regular partition .",
    "_    1 .   * initial partition : * arbitrarily divide the vertices of @xmath36 into an equitable partition @xmath82 with classes @xmath134 , where @xmath135 and hence @xmath136 . denote @xmath137 .",
    "* check size and regularity : * if @xmath138 , @xmath139 , then halt .",
    "otherwise for every pair @xmath87 of @xmath88 , verify if it is @xmath1-regular or find @xmath89 , such that @xmath90 .",
    "3 .   * count regular pairs : * if there are at most @xmath91 pairs that are not verified as @xmath1-regular , then halt .",
    "@xmath88 is an @xmath1-regular partition .",
    "* refinement : * otherwise apply the modified refinement algorithm , where @xmath140 , and obtain a partition @xmath60 with @xmath141 classes . 5 .   *",
    "iteration : * let @xmath142 , and go to step 2 .",
    "the frieze - kannan version is modified in an identical way .",
    "to make the regularity lemma applicable in clustering settings , we adopt the following two phase strategy ( as in @xcite ) :    1 .   * application of the practical regularity partitioning algorithm : * in the first stage we apply the practical regularity partitioning algorithm as described in the previous section to obtain an approximately regular partition of the graph representing the data .",
    "once such a partition has been obtained , the reduced graph as described in definition [ reduced ] could be constructed from the partition .",
    "* clustering the reduced graph : * the reduced graph as constructed above would preserve most of the properties of the original graph ( see @xcite ) .",
    "this implies that any changes made in the reduced graph would also reflect in the original graph .",
    "thus , clustering the reduced graph would also yield a clustering of the original graph .",
    "we apply spectral clustering ( though any other pairwise clustering technique could be used , e.g. in @xcite the dominant - set algorithm is used ) on the reduced graph to get a partitioning and then project it back to the higher dimension . recall that vertices in the exceptional set @xmath20 are leftovers from the refinement process and must be assigned to the clusters obtained .",
    "thus in the end these leftover vertices are redistributed amongst the clusters using a k - nearest neighbor classifier to get the final grouping .",
    "in this section we present extensive experimental results to indicate the efficacy of this approach by employing it for clustering on a number of benchmark datasets .",
    "we also compare the results with spectral clustering in terms of accuracy .",
    "we also report results that indicate the amount of compression obtained by constructing the reduced graph .",
    "as discussed later , the results also directly point to a number of promising directions of future work .",
    "we first review the datasets considered and the metrics used for comparisons .",
    "the datasets considered for empirical validation were taken from the university of california , irvine machine learning repository @xcite .",
    "a total of 12 datasets were used for validation .",
    "we considered datasets with real valued features and associated labels or ground truth . in some datasets (",
    "as described below ) that had a large number of real valued features , we removed categorical features to make it easier to cluster . unless otherwise mentioned ,",
    "the number of clusters was chosen so as to equal to the number of classes in the dataset ( i.e. if the number of classes in the ground truth is 4 , then the clustering results are for k = 4 ) .",
    "an attempt was made to pick a wide variety of datasets , i.e. with integer features , binary features , synthetic datasets and of course real world datasets with both very high and small dimensionality .",
    "the following datasets were considered ( for details about the datasets see @xcite ) : ( 1 ) red wine ( r - wine ) and ( 2 ) white wine ( w - wine ) , ( 3 ) the arcene dataset ( arcene ) , ( 4 ) the blood transfusion dataset ( blood - t ) , ( 5 ) the ionosphere dataset ( ionos ) , ( 6 ) the wisconsin breast cancer dataset ( cancer ) , ( 7 ) the pima indian diabetes dataset ( pima ) , ( 8) the vertebral column dataset ( vertebral-1 ) , the second task ( 9 ) ( vertebral-2 ) is considered as another dataset , ( 10 ) the steel plates faults dataset ( steel ) , ( 11 ) the musk 2 ( musk ) dataset and ( 12 ) haberman s survival ( haberman ) data .    next we discuss the metric used for comparison with other clustering algorithms . for evaluating the quality of clustering , we follow the approach of @xcite and use the cluster accuracy as a measure .",
    "the measure is defined as : @xmath143 where @xmath4 is the number of data - points considered , @xmath144 represents the true label ( ground truth ) while @xmath145 is the obtained cluster label of data - point @xmath146 . the function @xmath147 equals 1 if the true and the obtained labels match ( @xmath148 ) and 0 if they do nt .",
    "the function @xmath149 is basically a permutation function that maps each cluster label to the true label .",
    "an optimal match can be found by using the hungarian method for the assignment problem @xcite .      before reporting comparative results on benchmark datasets ,",
    "we first consider one dataset as a case study .",
    "while experiments reported in this case study were carried on all the benchmark datasets considered , the purpose here is to illustrate the investigations conducted at each stage of application of the regularity lemma .",
    "an auxiliary purpose is also to underline a set of guidelines on what changes to the practical regularity partitioning algorithm proved to be useful .",
    "for this task we consider the red wine dataset which has 1599 instances with 11 attributes each , the number of classes involved is six .",
    "it must be noted though that the class distribution in this dataset is pretty skewed ( with the various classes having 10 , 53 , 681 , 638 , 199 and 18 datapoints respectively ) , this makes clustering this dataset quite difficult when k = 6 .",
    "we however consider both k = 6 and k = 3 to compare results with spectral clustering .",
    "recall that our method has two meta - parameters that need to be user specified ( or estimated by cross - validation ) : @xmath1 and @xmath125 .",
    "note that @xmath133 is usually decided so that it is at least as big as @xmath150 .",
    "the first set of experiments thus explore the accuracy landscape of regularity clustering spanned over these two parameters .",
    "we consider 25 linearly spaced values of @xmath1 between 0.15 and 0.50 .",
    "the refinement number @xmath125 , as noted in section [ mod ] , can not be too large .",
    "since it can only take integer values , we consider six values from 2 to 7 . for the sake of comparison",
    ", we also obtain clustering results on the same dataset with spectral clustering with self tuning @xcite ( both using all connected and k - nearest neighbour graph versions ) and k - means clustering .",
    "figure [ fig : casestudy ] gives the accuracy of the regularity clustering on a grid of @xmath1 and @xmath125 .",
    "even though this plot is only for exploratory purposes , it shows that the accuracy landscape is in general much better than the accuracy obtained by spectral clustering for this dataset .     and refinement size @xmath125 ( with k = 6 on the left and k = 3 on the right ) .",
    "the plane cutting through in blue represents accuracy by running self - tuned spectral clustering using the fully connected similarity graph.,title=\"fig:\",width=192 ] and refinement size @xmath125 ( with k = 6 on the left and k = 3 on the right ) .",
    "the plane cutting through in blue represents accuracy by running self - tuned spectral clustering using the fully connected similarity graph.,title=\"fig:\",width=192 ]    an important aspect of the regularity clustering method is that by using a modified constructive version of the regularity lemma we obtain a much reduced representation of the original data .",
    "the size of the reduced graph depends both on @xmath1 and @xmath125 .",
    "however , in our observation it is more sensitive to changes to @xmath125 and understandably so . from the grid for @xmath1 and @xmath125",
    "we take three rows to illustrate the obtained sizes of the reduced graph ( more precisely , the dimensions of the affinity matrix of the reduced graph ) .",
    "we compare these numbers with the original dataset size . as we note in the results over the benchmark datasets in section [ benchmark ] , this compression is quite big in larger datasets .",
    ".reduced graph sizes .",
    "original affinity matrix size : 1599 @xmath151 1599 [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     [ uciresulttable ]    we compare our results with a fixed @xmath152 spectral clustering with both a fully connected graph ( spect2 ) and a k - nearest neighbour graph ( spect1 ) . for the sake of comparison",
    "we also include results for k - means on the entire dataset .",
    "we also report results on the compression that was achieved on each dataset in table [ uciresulttable ] ( the compression is indicated in the format x - y where x represents one dimension of the adjacency matrix of the dataset and y of the reduced graph ) .    in the results we observe that the regularity clustering method , as indicated by the clustering accuracies is quite powerful ; it gave significantly better results in 10 of the 12 datasets .",
    "it was also observed that the regularity clustering method did not appear to work very well in synthetic datasets .",
    "this seems understandable given the quasi - random aspect of the regularity method .",
    "we also report that the results obtained by the alon _",
    "et al . _ and by the frieze - kannan versions are virtually identical , which is not surprising .",
    "we believe that this work opens up a lot of potential research problems .",
    "first and foremost would be establishing theoretical results for quantifying the approximation obtained by our modifications to the regularity lemma .",
    "also , the original regularity lemma is applicable only while working with dense graphs .",
    "however , there are sparse versions of the regularity lemma .",
    "these sparse versions could be used in the first phase of our method such that even sparse graphs ( k - nearest neighbor graphs ) could be used for clustering , thus enhancing its practical utility even further .",
    "a natural generalization of pairwise clustering methods leads to hypergraph partitioning problems @xcite , @xcite .",
    "there are a number of results that extend the regularity lemma to hypergraphs @xcite , @xcite , @xcite .",
    "it is thus natural that our methodology could be extended to hypergraphs and then used for hypergraph clustering .    in final summary",
    ", our work gives a way to harness the regularity lemma for the task of clustering .",
    "we report results on a number of benchmark datasets which strongly indicate that the method is quite powerful . based on this work",
    "we also suggest a number of possible avenues for future work towards improving and generalizing this methodology ."
  ],
  "abstract_text": [
    "<S> in this paper we introduce a new clustering technique called _ </S>",
    "<S> regularity clustering_. this new technique is based on the practical variants of the two constructive versions of the regularity lemma , a very useful tool in graph theory . </S>",
    "<S> the lemma claims that every graph can be partitioned into pseudo - random graphs . </S>",
    "<S> while the regularity lemma has become very important in proving theoretical results , it has no direct practical applications so far . </S>",
    "<S> an important reason for this lack of practical applications is that the graph under consideration has to be astronomically large . </S>",
    "<S> this requirement makes its application restrictive in practice where graphs typically are much smaller . in this paper </S>",
    "<S> we propose modifications of the constructive versions of the regularity lemma that work for smaller graphs as well . </S>",
    "<S> we call this the practical regularity partitioning algorithm . the partition obtained by this </S>",
    "<S> is used to build the reduced graph which can be viewed as a compressed representation of the original graph . </S>",
    "<S> then we apply a pairwise clustering method such as spectral clustering on this reduced graph to get a clustering of the original graph that we call regularity clustering . </S>",
    "<S> we present results of using regularity clustering on a number of benchmark datasets and compare them with standard clustering techniques , such as @xmath0-means and spectral clustering . </S>",
    "<S> these empirical results are very encouraging . </S>",
    "<S> thus in this paper we report an attempt to harness the power of the regularity lemma for real - world applications . </S>"
  ]
}