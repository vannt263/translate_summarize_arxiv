{
  "article_text": [
    "lease take a look at the images in the top row of fig .",
    "[ fig : fig1 ] .",
    "which object stands out the most ( i.e. , is the most salient one ) in each of these scenes ?",
    "the answer is trivial .",
    "there is only one object , thus it is the most salient one .",
    "now , look at the images in the third row .",
    "these scenes are much more complex and contain several objects , thus it is more challenging for a vision system to select the most salient object .",
    "this problem , known as _ salient object detection ( and segmentation ) _ , has recently attracted a great deal of interest in computer vision community .",
    "the goal is to simulate the astonishing capability of human attention in prioritizing objects for high - level processing .",
    "such a capability has several applications in recognition ( e.g. ,  @xcite ) , image and video compression ( e.g. ,  @xcite ) , video summarization ( e.g. ,  @xcite , media re - targeting and photo collage ( e.g. ,  @xcite ) , image quality assessment ( e.g. ,  @xcite ) , image segmentation ( e.g. ,  @xcite ) , content - based image retrieval and image collection browsing ( e.g. ,  @xcite ) , image editing and manipulating ( e.g. ,  @xcite ) , visual tracking ( e.g. ,  @xcite ) , object discovery ( e.g. ,  @xcite ) , and human - robot interaction ( e.g. ,  @xcite ) .    a large number of saliency detection methods have been proposed in the past 7 years ( since  @xcite ) . in general , a salient object detection model involves two steps : 1 ) _ selecting objects to process _",
    "( i.e. , determining saliency order of objects ) , and 2 ) _ segmenting the object area _",
    "( i.e. , isolating the object and its boundary ) .",
    "so far , models have bypassed the first challenge by focusing on scenes with single objects ( see fig .  [",
    "fig : fig1 ] ) .",
    "they do a decent job on the second step as witnessed by very high performances on existing biased datasets ( e.g. , on asd dataset  @xcite ) which contain low - clutter images with often a single object at the center .",
    "however , it is unclear how current models perform on complex cluttered scenes with several objects . despite the volume of past research",
    ", this trend has not been yet fully pursued , mainly due to the lack of two ingredients : 1 ) suitable benchmark datasets for scaling up models and model development , and 2 ) a widely - agreed objective definition of the most salient object . in this paper",
    ", we strive to provide solutions for these problems .",
    "further , we aim to discover which component might be the weakest link in the possible failure of models when migrating to complex scenes .    some related topics , closely or remotely , to visual saliency modeling and salient object detection include : object importance  @xcite , object proposal generation  @xcite , memorability  @xcite , scene clutter  @xcite , image interestingness  @xcite , video interestingness  @xcite , surprise  @xcite , image quality assessment  @xcite , scene typicality  @xcite , aesthetic  @xcite , and attributes  @xcite .",
    "one of the earliest models , which generated the _ first wave _ of interest in image saliency in computer vision and neuroscience communities , was proposed by itti _",
    "et al . _",
    "this model was an implementation of earlier general computational frameworks and psychological theories of bottom - up attention based on center - surround mechanisms . in  @xcite ,",
    "itti _ et al .",
    "_ showed examples where their model was able to detect spatial discontinuities in scenes .",
    "subsequent behavioral ( e.g. ,  @xcite ) and computational studies ( e.g. ,  @xcite ) started to predict fixations with saliency models to verify models and to understand human visual attention .",
    "second wave _ of interest appeared with works of liu _ et al . _",
    "@xcite and achanta _ et al . _",
    "@xcite who treated saliency detection as a binary segmentation problem with 1 for a foreground pixel and 0 for a pixel of the background region .",
    "since then it has been less clear where this new definition stands as it shares many concepts with other well - established computer vision areas such as general segmentation algorithms ( e.g. ,  @xcite ) , category independent object proposals ( e.g. ,  @xcite ) , fixation prediction saliency models ( e.g.  @xcite ) , and general object detection methods .",
    "this is partly because current datasets have shaped a definition for this problem , which might not totally reflect full potential of models to _ select and segment salient objects in an image with an arbitrary level of complexity_.        reviewing all saliency detection models goes beyond the scope of this paper ( see  @xcite ) .",
    "some breakthrough efforts are as follows .",
    "et al . _",
    "@xcite introduced a conditional random field ( crf ) framework to combine multi - scale contrast and local contrast based on surrounding , context , and color spatial distributions for binary saliency estimation .",
    "et al . _",
    "@xcite proposed subtracting the average color from the low - pass filtered input for saliency detection .",
    "et al . _",
    "@xcite used a patch - based approach to incorporate global context , aiming to detect image regions that represent the scene .",
    "et al . _",
    "@xcite proposed a region contrast - based method to measure global contrast in the lab color space . in  @xcite ,",
    "wang _ et al . _ estimated local saliency , leveraging a dictionary learned from other images , and global saliency using a dictionary learned from other patches of the same image .",
    "et al . _",
    "@xcite observed that decomposing an image into perceptually uniform regions , which abstracts away unnecessary details , is important for high quality saliency detection . in  @xcite ,",
    "et al . _ utilized the difference between the color histogram of a region and its immediately neighboring regions for measuring saliency .",
    "et al . _",
    "@xcite defined a measure of saliency as the cost of composing an image window using the remaining parts of the image , and tested it on pascal voc dataset  @xcite .",
    "this method , in its essence , follows the same goal as in  @xcite .",
    "et al . _",
    "@xcite proposed a graphical model for fusing generic objectness  @xcite and visual saliency for salient object detection .",
    "shen and wu  @xcite modeled an image as a low - rank matrix ( background ) plus sparse noises ( salient regions ) in a feature space .",
    "more recently , margolin _ et al . _  @xcite integrated pattern and color distinctnesses with high - level cues to measure saliency of an image patch .",
    "some studies have considered the relationship between fixations and salincy judgments similar to  @xcite .",
    "for example , xu et al .",
    "@xcite investigated the role of high - level semantic knowledge ( e.g. , object operability , watchability , gaze direction ) and object information ( e.g. , object center - bias ) for fixation prediction in free viewing of natural scenes .",
    "they constructed a large dataset called `` object and semantic images and eye - tracking ( osie ) '' .",
    "indeed they found an added value for this information for fixation prediction and proposed a regression model ( to find combination weights for different cues ) that improves fixation prediction performance .",
    "koehler et al .",
    "@xcite collected a dataset known as the ucsb dataset .",
    "this dataset contains 800 images .",
    "one hundred observers performed an explicit saliency judgment task , 22 observers performed a free viewing task , 20 observers performed a saliency search task , and 38 observers performed a cued object search task .",
    "observers completing the free viewing task were instructed to freely view the images . in the explicit saliency judgment task , observers were instructed to view a picture on a computer monitor and click on the object or area in the image that was most salient to them . _ salient _ was explained to observers as something that stood out or caught their eye ( similar to  @xcite ) .",
    "observers in the saliency search task were instructed to determine whether or not the most salient object or location in an image was on the left or right half of the scene .",
    "finally , observers who performed the cued object search task were asked to determine whether or not a target object was present in the image .",
    "then , they conducted a benchmark and introduced models that perform the best on each of these tasks .",
    "a similar line of work to ours in this paper has been proposed by mishra _",
    "et al . _",
    "@xcite where they combined monocular cues ( color , intensity , and texture ) with stereo and motion features to segment a region given an initial user - specified seed point , practically ignoring the first stage in saliency detection ( which we address here by automatically generating a seed point ) .",
    "ultimately , our attempt in this work is to bridge the interactive segmentation algorithms ( e.g. ,  @xcite ) and saliency detection models and help transcend their applicability .",
    "perhaps the most similar work to ours has been published by li _",
    "_  @xcite . in their work , they offer two contributions . _ first _ , they collect an eye movement dataset using annotated images from the pascal dataset  @xcite and call their dataset pascal - s .",
    "_ second _ , they propose a model that outperforms other state - of - the - art salient object detection models on this dataset ( as well as four other benchmark datasets ) .",
    "their model decouples the salient object detection problem into two processes : 1 ) _ a segment generation process _ , followed by 2 ) _ a saliency scoring mechanism _ using fixation prediction . here ,",
    "similar to li _ et al .",
    "_ , we also take advantage of eye movements to measure object saliency but instead of first fully segmenting the scene , we perform a shallow segmentation using superpixels .",
    "we then only focus on segmenting the object that is most likely to attract attention .",
    "in other words , the two steps are similar to li _ et al . _ but are performed in the reverse order .",
    "this can potentially lead to better efficiency as the first expensive segmentation part is now only an approximation .",
    "we also offer another dataset which is complimentary to li _ et al .",
    "_ s dataset and together both datasets ( and models ) could hopefully lead to a paradigm shift in the salient object detection field to avoid using simple biased datasets .",
    "further , we situate this field among other similar fields such as general object detection and segmentation , objectness proposal generation models , and saliency models for fixation prediction .",
    "several salient object detection datasets have been created as more models have been introduced in the literature to extend capabilities of models to more complex scenes .",
    "table  [ tab : db ] lists properties of 19 popular salient object detection datasets . although these datasets suffer from some biases ( e.g. , low scene clutter , center - bias , uniform backgrounds , and non - ambiguous objects ) , they have been very influential for the past progress .",
    "unfortunately , recent efforts to extend existing datasets have only increased the number of images without really addressing core issues specifically background clutter and number of objects .",
    "majority of datasets ( in particular large scale ones such as those derived from the msra dataset ) have scenes with often one object which is usually located at the image center .",
    "this has made model evaluation challenging since some high - performing models that emphasize image center fail in detecting and segmenting the most salient off - center object  @xcite .",
    "we believe that now is the time to move on to more versatile datasets and remedy biases in salient object datasets .",
    "in this section , we briefly explain how salient object detection models differ from fixation prediction models , what people consider the most salient object when they are explicitly asked to choose one , what are the relationships between these judgments and eye movements , and what salient object detection models actually predict .",
    "we investigate properties of salient objects from humans point of view when they are explicitly asked to choose such objects .",
    "we then study whether ( and to what extent ) saliency judgments agree with eye movements . while it has been assumed that eye movements are indicators of salient objects , so far few studies ( e.g. ,  @xcite ) have directly and quantitatively confirmed this assumption .",
    "moreover , the level of agreement and cases of disagreement between fixations and saliency judgments have not been fully explored .",
    "some studies ( e.g. ,  @xcite ) , have shown that human observers choose to annotate salient objects or regions first but they have not asked humans explicitly ( labelme data was analyzed in  @xcite ) and they have ignored eye movements . knowing which objects humans consider as salient is specially crucial when outputs of a model are going to be interpreted by humans .",
    "there are two major differences between models defining saliency as `` where people look '' and models defining saliency as `` which objects stand out '' .",
    "_ first _ , the former models aim to predict points that people look in free - viewing of natural scenes usually for 3 to 5 seconds while the latter aim to detect and segment salient objects ( by drawing pixel - accurate silhouettes around them ) . in principle a model that scores well on one problem should not score very well on the other . an optimal model for fixation prediction should only highlight those points that a viewer will look at ( few points inside an object and not the whole object region ) .",
    "since salient object detection models aim to segment the whole object region they will generate a lot of false positives ( these points belong to the object but viewers may not fixate at them ) when it comes to fixation prediction . on the contrary",
    ", a fixation prediction model will miss a lot of points inside the object ( i.e. , false negatives ) when it comes to segmentation .",
    "_ second _ , due to noise in eye tracking or observers saccade landing ( typically around 1 degrees and @xmath0 30 pixels ) , highly accurate pixel - level prediction maps are less desired .",
    "in fact , due to these noises , sometimes blurring prediction maps increases the scores  @xcite . on the contrary , producing salient object detection maps that can accurately distinguish object boundaries are highly desirable specially in applications . due to these",
    ", different evaluation and benchmarks have been developed for comparing models in these two categories .    in practice ,",
    "models , whether they address segmentation or fixation prediction , are applicable interchangeably as both entail generating similar saliency maps .",
    "for example , several researches have been thresholding saliency maps of their models , originally designed to predict fixations , to detect and segment salient proto - objects ( e.g. ,  @xcite ) .          in our previous study",
    "@xcite , we addressed what people consider as the most outstanding ( i.e. , salient ) object in a scene . while in  @xcite we studied the explicit saliency problem from a behavioral perspective , here we are mainly interested in constructing computational models for automatic salient object detection in arbitrary visual scenes .",
    "a total of 70 students ( 13 male , 57 female ) undergraduate usc students with normal or corrected - to - normal vision in the age range between 18 and 23 ( mean = 19.7 , std = 1.4 ) were asked to draw a polygon around the object that stood out the most .",
    "participants annotations were supposed not to be too loose ( general ) or too tight ( specific ) around the object .",
    "they were shown an illustrative example for this purpose .",
    "participants were able to relocate their drawn polygon from one object to another or modify its outline .",
    "we were concerned with the case of selection of the single most salient object in an image .",
    "stimuli were the images from the dataset by bruce and tsotsos ( 2005 )  @xcite 681 pixels .",
    "images in this dataset have been presented at random to 20 observers ( in a free - viewing task ) for 4 sec each , with 2 sec of delay ( a gray mask ) in between . ] .",
    "see fig .",
    "[ fig : sampleio - am ] for sample images from this dataset .",
    "we first measured the degree to which annotations of participants agree with each other using the following quantitative measure : @xmath1    where @xmath2 and @xmath3 are annotations of @xmath4-th and @xmath5-th participants , respectively ( out of @xmath6 participants ) over the @xmath7-th image . above measure",
    "has the well - defined lower - bound of 0 , when there is no overlap in segmentations of users , and the upper - bound of 1 , when segmentations have perfect overlap .",
    "[ fig : exp1].left shows histogram of @xmath8 values .",
    "participants had moderate agreement with each other ( mean @xmath9 ; std @xmath10 ; significantly above chance ) .",
    "inspection of images with lowest @xmath8 values shows that these scenes had several foreground objects while images with highest annotation agreement had often one visually distinct salient object ( e.g. , a sign , a person , or an animal ; see fig .  [",
    "fig : sampleio - am ] ) .",
    "we also investigated the relationship between explicit saliency judgments and freeviewing fixations as two indicators of visual attention .",
    "here we used shuffled auc ( sauc ) score to tackle center - bias in eye movement data  @xcite . for each of 120 images , we showed that a map built from annotations of 70 participants explains fixations of free viewing observers significantly above chance ( sauc of @xmath11 , chance @xmath12 , @xmath13-test @xmath14 ; fig .",
    "[ fig : exp1].right ) .",
    "the prediction power of this map was as good as the itti98 model  @xcite .",
    "hence , we concluded that explicit saliency judgments agree with fixations .",
    "[ fig : sampleio - am ] shows high- and low - agreement cases between fixations and annotations .    here",
    ", we merge annotations of all 70 participants on each image , normalize the resultant map to [ 0 1 ] , and threshold it at 0.7 to build our first benchmark saliency detection dataset ( called bruce - a ) .",
    "prevalent objects in bruce and tsotsos dataset are man - made home supplies in indoor scenes ( see  @xcite for more details on this dataset ) .",
    "similar results , to link fixations with salient objects , have been reported by koehler _",
    "_  @xcite . as in  @xcite",
    ", they asked observers to click on salient locations in natural scenes .",
    "they showed high correlation between clicked locations and observers eye movements ( from a different group of subjects ) in free - viewing . while the most salient  @xcite , important  @xcite , or interesting  @xcite object may tell us a lot about a scene , eventually there is a subset of objects that can minimally describe a scene .",
    "this has been addressed in the past somewhat indirectly in the contexts of saliency  @xcite , language and attention  @xcite , and phrasal recognition  @xcite .",
    "based on results from our saliency judgment experiment  @xcite , we then decided to annotate scenes of the dataset by judd _",
    "et al . _",
    "the reason for choosing this dataset is because it is currently the most popular dataset for benchmarking fixation prediction models  @xcite .",
    "it contains eye movements of 15 observers freely viewing 1003 scenes from variety of topics .",
    "thus , using fixations we can easily determine which object , out of several annotated objects , is the most salient one .",
    "we only used 900 images from the judd dataset and discarded images without well - defined objects ( e.g. , mosaic tiles , flames ) or images with very cluttered backgrounds ( e.g. , nature scenes ) . figure  [ fig : figdiscarded ] shows examples of discarded scenes .",
    "we asked 2 observers to manually outline objects using the labelme  @xcite open annotation tool ( http://new-labelme.csail.mit.edu/ ) .",
    "observers were instructed to accurately segment as many objects as possible following three rules : 1 ) discard reflection of objects in mirrors , 2 ) segment objects that are not separable as one ( e.g. , apples in a basket ) , and 3 ) interpolate the boundary of occluded objects only if doing otherwise may create several parts for an occluded object .",
    "these cases , however , did happen rarely .",
    "observers were also told that their outline should be good enough for somebody to recognize the object just by seeing the drawn polygon .",
    "observers were paid for their effort .",
    "[ fig:1 ] shows sample images and their annotated objects . to determine which object is the most salient one , we selected the object at the peak of the human fixation map .          here",
    "we explore some summary statistics of our data . on average ,",
    "36.93% of an image pixels was annotated by the 1st observer with a std of 29.33% ( 44.52% , std=29.36% for the 2nd observer ) .",
    "27.33% of images had more than 50% of their pixels segmented by the 1st observer ( 34.18% for the 2nd ) . the number of annotated objects in a scene ranged from 1 to 31 with median of 3 for the 1st observer ( 1 to 24 for the 2nd observer with median of 4 ; fig .",
    "[ fig : stat].left ) .",
    "the median object size was 10% of the total image area for the 1st observer ( 9% for the 2nd observer ) .",
    "[ fig : stat].left ( inset ) shows the average annotation map for each observer over all images .",
    "it indicates that either more objects were present at the image center and/or observers tended to annotate central objects more .",
    "overall , our data suggests that both observers agree to a good extent with each other .",
    "finally , in order to create one ground truth segmentation map per image , we asked 5 other observers to choose the best of two annotations ( criteria based on selection of annotated objects and boundary accuracy ) .",
    "the best annotation was the one with max number of votes ( 611 images with 4 to 1 votes ) .",
    "next , we quantitatively analyzed the relationship between fixations and annotations ( note that we explicitly define the most salient object as the one with the highest fraction of fixations on it ) .",
    "we first looked into the relationship between the object annotation order and the fraction of fixations on objects .",
    "[ fig : stat].middle shows fraction of fixations as a function of object annotation order . in alignment with previous findings  @xcite we observe that observers chose to annotate objects that attract more fixations . but",
    "here , unlike  @xcite which used saliency models to demonstrate that observers prioritize annotating interesting and salient objects , we used actual eye movement data .",
    "we also quantized the fraction of fixations that fall on scene objects over the judd - a annotations , and observed that in about 55% of images , the most salient object attracts more than 50% of fixations ( mean fixation ratio of 0.54 ; image background=0.45 ; fig .",
    "[ fig : stat].right ) .",
    "the most salient object ranged in size from 0.1% to 90.2% of the image size ( median=10.17% ) .",
    "the min and max aspect ratio ( w / h ) of bounding boxes fitted to the most salient object were 0.04 and 13.7 , respectively ( median=0.94 ) .",
    "judd dataset is known to be highly center - biased  @xcite , in terms of eye movements  @xcite , due to two factors : 1 ) the tendency of observers to start viewing the image from the center ( a.k.a viewing strategy ) , and 2 ) tendency of photographers to frame interesting objects at the image center ( a.k.a photographer bias ) . here",
    "we verify the second factor by showing the average annotation map of the most salient object in fig .",
    "[ fig : meps ] . our datasets seem to have relatively less center - bias compared to msra-5k and cssd datasets .",
    "note that other datasets mentioned in table i are also highly center - biased . to count the number of images with salient objects at the image center , we defined the following criterion .",
    "an image is on - centered if its most salient object overlaps with a normalized ( to [ 0 1 ] ) central gaussian filter with @xmath15 .",
    "this gaussian filter is resized to the image size and is then truncated above 0.95 . utilizing this criterion",
    ", we selected 667 and 223 on - centered and off - centered scenes , respectively .",
    "partitioning data in this manner helps scrutinize performance of models and tackle the problem of center - bias .    to further explore the amount of center - bias in bruce - a and judd - a datasets , we first calculated the euclidean distance from center of bounding boxes , fitted to object masks , to the image center .",
    "we then normalized this distance to the half of the image diagonal ( i.e. , image corner to image center ) .",
    "[ fig : arearatio].left shows the distribution of normalized object distances .",
    "as opposed to msra-5k and cssd datasets that show an unusual peak around the image center , objects in our datasets are further apart from the image center .",
    "[ fig : arearatio].right shows distributions of normalized object sizes .",
    "a majority of salient objects in bruce - a and judd - a datasets occupy less than 10% of the image . on average , objects in our datasets are smaller than msra-5k and cssd making salient object detection more challenging .",
    "we also analyzed complexity of scenes on four datasets . to this end",
    ", we first used the popular graph - based superpixel segmentation algorithm by felzenszwalb and huttenlocher  @xcite to segment an image into contiguous regions larger than 60 pixels each ( parameter settings : @xmath16 = 1 , segmentation coefficient @xmath17 = 300 ) .",
    "the basic idea is that the more superpixels an image contains , the more complex and cluttered it is  @xcite . by analogy to scenes , an object with several superpixels is less homogeneous , and hence is more complex ( e.g. , a person vs. a ball ) .",
    "[ fig : stats ] shows distributions of number of superpixels on the most salient object , the background , and the entire scene .",
    "if a superpixel overlapped with the salient object and background , we counted it for both .",
    "in general , complexities of backgrounds and whole scenes in our datasets , represented by blue and red curves , are much higher than in the other two datasets .",
    "the most salient object in judd - a dataset on average contains more superpixels than salient objects in msra-5k and cssd datasets , even with smaller objects .",
    "the reason why number of superpixels is low on the bruce - a dataset is because of its very small salient objects ( see fig .  [",
    "fig : stats].right ) .    further , we inspected types of objects in judd - a images .",
    "we found that 45% of images have at least one person in them and 27.2% have more than two people . on average",
    "each scene has 1.56 persons ( std = 3.2 ) . in about 27% of images , annotators chose a person as the most salient object .",
    "we also found that 280 out of 900 images ( 31.1% ) had one or more text in them .",
    "other frequent objects were animals , cars , faces , flowers , and signs .",
    "in general , it is agreed that for good saliency detection , a model should meet the following three criteria : 1 ) _ high detection rate_. there should be a low probability of failing to detect real salient regions , and low probability of falsely detecting background regions as salient regions , 2 ) _ high resolution_. saliency maps should have high or full resolution to accurately locate salient objects and retain original image information as much as possible , and 3 ) _ high computational efficiency_. saliency models with low processing time are preferred . here , we analyze these factors by proposing a simple baseline salient object detection model .    we propose a straightforward model to serve two purposes : 1 ) _ to assess the degree to which our data can be explained by a simple model_. this way our model can be used for measuring bias and complexity of a saliency dataset , and 2 ) _ to gauge progress and performance of the state of the art models_. by comparing performance of best models relative to this baseline model over existing datasets and our datasets , we can judge how powerful and scalable these models are . note that we deliberately keep the model simple to achieve above goals .",
    "our model involves the following two steps : + _ * step 1 * _ : given an input image , we compute a saliency map and an over - segmented region map .",
    "for the former , we use a fixation prediction model ( traditional saliency models ) to find spatial outliers in scenes that attract human eye movements and visual attention . here , we use two models for this purpose : aws  @xcite and hounips  @xcite , which have been shown to perform very well in recent benchmarks and to be computationally efficient  @xcite . as controls , we also use the generic _ objectness _ measure by alexe _",
    "et al . _",
    "@xcite , as well as the human fixation map to determine the upper - bound performance .",
    "the reason for using fixation saliency models is to obtain an quick initial estimation of locations where people may look in the hope of finding the most salient object .",
    "these regions are then fed to the segmentation component in the next step .",
    "it is critical to first limit the subsequent expensive processes onto the right region .",
    "for the latter , as in the previous section , we use the fast and robust algorithm by felzenszwalb and huttenlocher  @xcite with same parameters as in section  [ statistics ] .",
    "_ * step 2 * _ : the saliency map is first normalized to [ 0 1 ] and is then thresholded at @xmath18 ( here @xmath18 = 0.7 )",
    ". then all unique image superpixels that spatially overlap with the truncated saliency map are included .",
    "here we discarded those superpixels that touch the image boundary because they are highly likely to be part of the background .",
    "finally , after this process , the holes inside the selected region will be considered as part of the salient object ( e.g. , filling in operation ) .",
    "[ fig : samples ] illustrates the process of segmentation and shows outputs of our model for some images from msra-5k , bruce - a , and judd - a datasets .",
    "the essential feature of our simple model is dissociating saliency detection from segmentation , such that now it is possible to pinpoint what might be the cause of mistakes or low performance of a model , i.e. , or .",
    "this is particularly important since almost all models have confused these two steps and have faded the boundary .",
    "note that currently there is no training stage in our model and it is manually constructed with fixed parameters .",
    "the second stage in our model is where more modeling contribution can be made , for example by devising more elaborate ways to include or discard superpixels in the final segmentation .",
    "one strategy is to learn model parameters from data .",
    "some features to include in a learning method are size and position of a superpixel , a measure of elongatedness , a measure of concavity or convexity , distance between feature distributions of a superpixel and its neighbors , etc . to some extent ,",
    "some of these these features have already been utilized in previous models  @xcite .",
    "another direction will be expanding our model to multi scale ( similar to  @xcite ) .",
    "we exhaustively compared our model to 8 state of the art methods which have been shown to perform very well on previous benchmarks  @xcite .",
    "these models come from 3 categories allowing us to perform cross - category comparison : 1 ) _ salient object detection models _ including cbsal  @xcite , svo  @xcite , pca  @xcite , goferman  @xcite , and fts  @xcite , 2 ) _ generic objectness measure _ by alexe _",
    "et al . _",
    "@xcite , and 3 ) _ fixation prediction models _ including aws  @xcite and hounips  @xcite .",
    "we use two widely adopted metrics :    * * precision - recall ( pr ) curve : * for a saliency map @xmath19 normalized to @xmath20 $ ] , we convert it to a binary mask @xmath21 with a threshold @xmath22 . @xmath23 and @xmath24 are then computed as follows given the ground truth mask @xmath25 : @xmath26 [ eqn : precision_recall ] to measure the quality of saliency maps produced by several algorithms , we vary the threshold @xmath22 from 0 to 255 . on each threshold , @xmath23 and @xmath24 values",
    "are computed .",
    "finally , we can get a precision - recall ( pr ) curve to describe the performance of different algorithms .",
    "+ we also report the f - measure defined as : @xmath27 + here , as in  @xcite and  @xcite , we set @xmath28 to weigh precision more than recall . * * receiver operating characteristics ( roc ) curve : * we also report the false positive rate ( @xmath29 ) and true positive rate ( @xmath30 ) during the thresholding a saliency map : @xmath31 where @xmath32 and @xmath33 denote the opposite ( complement ) of the binary mask @xmath21 and ground - truth , respectively .",
    "the roc curve is the plot of @xmath30 versus @xmath29 by varying the threshold @xmath22 .",
    "results are shown in fig .",
    "[ fig : bruce ] .",
    "consistent with previous reports over the msra-5k dataset  @xcite , cbsal , pca , svo , and alexe models rank on the top ( with f - measures above 0.55 and aucs above 0.90 ) .",
    "fixation prediction models perform lower at the level of the map .",
    "fts model ranked on the bottom again in alignment with previous results .",
    "our models work on par with the best models on this dataset with all f - measures above 0.70 ( max with alexe model about 0.73 ) . moving from this simple dataset ( because our simple models ranked on the top ; see also the analysis in section  [ statistics ] ) to more complex datasets ( middle column in fig .",
    "[ fig : bruce ] ) we observed a dramatic drop in performance of all models .",
    "the best performance now is 0.24 belonging to the pca model .",
    "we observed about 72% drop in performance averaged over 5 models ( cbsal , fts , svo , pca , and alexe ) from msra-5k to bruce - a dataset .",
    "note in particular how map model is severely degraded here ( poorest with f measure of 0.1 ) since objects are now less at the center .",
    "our best model on this dataset is the salbase - human ( f - measure about 0.31 ) .",
    "surprisingly , auc results are still high on this dataset since objects are small thus true positive rate is high at all levels of false positive rate ( see also performance of map ) . patterns of results over judd - a dataset are similar to those over bruce - a with all of our models performing higher than others .",
    "the lowest performance here belongs to fts followed by the two fixation prediction models .",
    "our salbase - human model scores the best with the f - measure about 0.55 . among our models that used a model to pick the most salient location , salbase - aws scores higher over bruce -",
    "a and judd - a datasets possibly because aws is better able to find the most salient location .",
    "the average drop from msra-5k to judd - a dataset is @xmath0 41% ( for 5 saliency detection models ) .",
    "[ fig : f - measure2 ] shows that these findings are robust to f - measure parameterization .",
    "tables  [ tab : db - fmeasure ] and  [ tab : db - auc ] summarize the f - measure and auc of models .",
    ".f - measure accuracy of models .",
    "performance of the best model is highlighted in boldface font . [ cols=\"^,^,^,^ \" , ]      to study the dependency of results on saliency map thresholding ( i.e. , how many superpixels to include ) , we varied the saliency threshold @xmath18 and calculated f - measure for salbase - human and salbase - aws models ( see fig .",
    "[ fig : salthreshold ] ) .",
    "we observed that even higher scores are achievable using different parameters .",
    "for example , since objects in the judd - a dataset are larger , a lower threshold yields a better accuracy .",
    "the opposite holds over the bruce - a dataset .      to investigate the dependency of results on segmentation parameters",
    ", we varied the parameters of the segmentation algorithm from too fine ( @xmath16 = 1 , k = 100 , min = 20 ; many segments ; over - segmenting ) to too coarse ( @xmath16 = 1 , k = 1000 , min = 800 ; fewer segments ; under - segmenting ) .",
    "both of these settings yielded lower performances than results in fig .  [",
    "fig : bruce ] . results with another parameter setting with @xmath16 = 1 , k = 500 , and min = 50 are shown in fig .",
    "[ fig : res_500_50 ] . scores and trends are similar to those shown in fig .",
    "[ fig : bruce ] , with salbase - human and salbase - aws being the top contenders .    .",
    "stars correspond to points shown in fig .",
    "[ fig : bruce ] . note that even higher accuracies are possible with different thresholds over our datasets .",
    "corresponding f - measure values over msra-5k for salbase - aws model are : 0.62 , 0.67 , 0.70 , 0.73 , and 0.62.,width=321,height=143 ]      analysis of cases where our model fails , shown in fig .",
    "[ fig : failure2 ] , reveals four reasons : _ first _ , on bruce - a dataset when humans look at an object more but annotators chose a different object .",
    "_ second _ , when a segment that touches the image border is part of the salient object .",
    "_ third _ , when the object segment falls outside the thresholded saliency map ( or a wrong one is included ) .",
    "_ fourth _ , when the first stage ( i.e. , fixation prediction model ) pick the wrong object as the most salient one ( see fig .",
    "[ fig : rrr ] , first column ) . regarding the first problem ,",
    "care must be taken in assuming what people look is what they choose as the most salient object .",
    "although this assumption is correct in a majority of cases ( fig .",
    "[ fig : exp1 ] ) , it does not hold in some cases .",
    "with respect to the second and third problems , future modeling effort is needed to decide which superpixels to include / discard to determine the extent of an object .",
    "the fourth problem points toward shortcomings of fixation prediction models .",
    "indeed , in several scenes where our model failed , people and text were the most salient objects .",
    "person and text detectors were not utilized in the saliency models employed here .",
    "[ fig : rrr ] shows a visual comparison of models over 12 scenes from the judd - a dataset .",
    "cbsal and svo generate more visually pleasant maps .",
    "goferman highlights object boundaries more than object interiors .",
    "pca generates center - biased maps . some models ( e.g. , goferman , fts ) generate sparse saliency maps while some others generate smoother ones ( e.g. , svo , cbsal ) .",
    "aws and hounips models generate pointy maps to better account for fixation locations .",
    "in this work , we showed that : 1 ) explicit human saliency judgments agree with free - viewing fixations ( thus extending our previous results in  @xcite ) , 2 ) our new benchmark datasets challenge existing state - of - the - art salient object detection models ( in alignment with li  _ et al .",
    "_ s dataset  @xcite ) , and 3 ) a conceptually simple and computationally efficient model ( @xmath00.2 s for @xmath34 saliency and segmentation maps on a pc with a 3.2 ghz intel i7 cpu and 6 gb ram using matlab ) wins over the state of the art models and can be used as a baseline in the future .",
    "we also highlighted a limitation of models which is the main reason behind their failure on complex scenes .",
    "they often segment the wrong object as the most salient one .",
    "previous modeling effort has been mainly concentrated on biased datasets with images containing objects at the center . here , we focused on this shortcoming and described how unbiased salient object detection datasets can be constructed .",
    "we also reviewed datasets that can be used for saliency model evaluation ( in addition to datasets in table  [ tab : db ] ) and measured their statistics .",
    "no dataset exists so far that has all of object annotations , eye movements , and explicit saliency judgments .",
    "bruce - a has fixations , and only explicit saliency judgments but not all object labels .",
    "judd - a , osie , and pascal - s datasets have annotations and fixations but not explicit saliency judgments . here , we chose the object that falls at the peak of the fixation map as the most salient one .",
    "ucsb dataset lacks object annotations but it has fixations and saliency judgments using clicks ( as opposed to object boundaries in bruce - a ) . future research by collecting all information on a large scale dataset will benefit salient object detection research .",
    "here we suggested that the most salient object in a scene is the one that attracts the majority of fixations ( similar to  @xcite ) .",
    "one can argue that the most salient object is the one that observers look at first . while in general , these two definitions may choose different objects , given the short presentation times in our datasets ( 3 sec on judd , 4 sec on bruce ) we suspect that both suggestions will yield to similar results .",
    "our model separates detection from segmentation .",
    "a benefit of this way of modeling is that it can be utilized for other purposes ( e.g. , segmenting interesting or important objects ) by replacing the first component of our model .",
    "further , augmented with a top - down fixation selection strategy , our model can be used as an active observer ( e.g. ,  @xcite ) .",
    "our analysis suggests two main reasons for model performance drop over the judd - a dataset : the _ first reason _ that the literature has focused so far is to avoid incorrectly segmenting the object region ( i.e. , increasing true positives and reducing false positives ) .",
    "therefore , low performance is partially due to inaccurately highlighting ( segmenting ) the salient object .",
    "the _ second reason _ that we attempted to highlight in this paper ( we believe is the main problem causing performance drop as models performed poorly on judd - a compared to msra-5k ) is segmenting the wrong object ( i.e. , not the most salient object ) .",
    "note that although here we did not consider the latest proposed salient object detection models in our model comparison ( e.g. ,  @xcite ) , we believe that our results are likely to generalize compared to newer models .",
    "the rationale is that even recent models have also used the asd dataset  @xcite ( which is highly center - biased ) for model development and testing .",
    "nontheless , we encourage future works to use our model ( as well as li et al.s model ) as a baseline for model benchmarking .    two types of cues can be utilized for segmenting an object : appearance  @xcite ( i.e. , grouping contiguous areas based on surface similarities ) and boundary  @xcite ( i.e. , cut regions based on observed pixel boundaries ) .",
    "here we mainly focused on the appearance features .",
    "taking advantage of both region appearance and contour information ( similar to  @xcite ) for saliency detection ( e.g. , growing the foreground salient region until reaching the object boundary ) is an interesting future direction . in this regard",
    ", it will be helpful to design suitable measures for evaluating accuracy of models for detecting boundary ( e.g. ,  @xcite ) .",
    "our datasets allow more elaborate analysis of the interplay between saliency detection , fixation prediction , and object proposal generation . obviously , these models depend on the other . on one hand ,",
    "it is critical to correctly predict where people look to know which object is the most salient one . on the other hand , labeled objects in scenes can help us study how objects guide attention and eye movements .",
    "for example , by verifying the hypotheses that some parts of objects ( e.g. , object center  @xcite ) or semantically similar objects  @xcite ) attract fixations more , better fixation prediction models become feasible .",
    "l. itti , c. koch , and e. niebur . a model of saliency - based visual attention for rapid scene analysis .",
    "_ ieee trans . pami _ , 1998 .",
    "n. d. b. bruce and j. k. tsotsos .",
    "saliency based on information maximization .",
    "_ nips _ , 2005 .",
    "x. hou and l. zhang .",
    "dynamic attention : searching for coding length increments .",
    "_ nips _ , 2008 .",
    "a. garcia - diaz , x. r. fdez - vidal , x. m. pardo , and r. dosil .",
    "decorrelation and distinctiveness provide with human - like saliency .",
    "_ acivs _ , 2009 .",
    "h. jiang , j. wang , z. yuan , y. wu , n. zheng , and s. li .",
    "salient object detection : a discriminative regional feature integration approach .",
    "_ ieee conference on computer vision and pattern recognition _ , 2013 .",
    "a. c. berg , t. l. berg , h. daume , j. dodge , a. goyal , x. han , a. mensch , m. mitchell , a. sood , k. stratos et al .",
    ", `` understanding and predicting importance in images , '' in ieee conference on computer vision and pattern recognition ( cvpr ) , 2012 , pp .",
    "3562 - 3569 .",
    "x. han , a. mensch , m. mitchell , a. sood , k. stratos et al .",
    ", `` understanding and predicting importance in images , '' in ieee conference on computer vision and pattern recognition ( cvpr ) , 2012 , pp .",
    "3562 - 3569 .",
    "s. dhar , v. ordonez , and t. l. berg , `` high level describable attributes for predicting aesthetics and interestingness , '' in ieee conference on computer vision and pattern recognition ( cvpr ) , 2011 , pp .",
    "1657 - 1664 .",
    "z. wang , a. c. bovik , h. r. sheikh , and e. p. simoncelli , `` image quality assessment : from error visibility to structural similarity , '' ieee transactions on image processing , vol .",
    "600 - 612 , 2004 .",
    "g. kulkarni , v. premraj , s. dhar , s. li , y. choi , a. c. berg , and t. l. berg , `` baby talk : understanding and generating simple image descriptions , '' in ieee conference on computer vision and pattern recognition ( cvpr ) , 2011 , pp .",
    "1601 - 1608 .",
    "u. rutishauser , d. walther , c. koch , and p. perona , `` is bottom - up attention useful for object recognition ? '' in proceedings of the ieee conference on computer vision and pattern recognition , 2004 , vol . 2 , 2004 , pp .",
    "ii-37 .        c. guo and l. zhang , `` a novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression , '' ieee trans . on image processing ,",
    "1 , pp . 185 - 198 , 2010 .",
    "ma , x .- s .",
    "hua , l. lu , and h .- j .",
    "zhang , `` a generic framework of user attention model and its application in video summarization , '' ieee transactions on multimedia , vol .",
    "907 - 919 , 2005 .",
    "a. ninassi , o. le meur , p. le callet , and d. barbba , `` does where you gaze on an image affect your perception of quality ? applying visual attention to image quality metric , '' in ieee conference on image processing ( icip ) , vol . 2 , 2007 , pp .",
    "ii-169 .",
    "j. li , m. levine , x. an , x. xu , and h. he , `` visual saliency based on scale - space analysis in the frequency domain , '' ieee trans . on pattern analysis and machine intelligence ,",
    "996 - 1010 , 2013 .",
    "s. frintrop , g. m. garca , and a. b. cremers , `` a cognitive approach for object discovery , '' icpr , 2014 .",
    "d. meger , p .- e .",
    "forssen , k. lai , s. helmer , s. mccann , t. southey , m. baumann , j. j. little , and d. g. lowe , `` curious george : an attentive semantic robot , '' robotics and autonomous systems , vol .",
    "56 , no . 6 , pp .",
    "503 - 511 , 2008 .",
    "ali borji received his bs and ms degrees in computer engineering from petroleum university of technology , tehran , iran , 2001 and shiraz university , shiraz , iran , 2004 , respectively .",
    "he did his ph.d .",
    "in cognitive neurosciences at institute for studies in fundamental sciences ( ipm ) in tehran , iran , 2009 and spent four years as a postdoctoral scholar at ilab , university of southern california from 2010 to 2014 .",
    "he is currently an assistant professor at university of wisconsin , milwaukee .",
    "his research interests include visual attention , active learning , object and scene recognition , and cognitive and computational neurosciences ."
  ],
  "abstract_text": [
    "<S> salient object detection or salient region detection models , diverging from fixation prediction models , have traditionally been dealing with locating and segmenting the most salient object or region in a scene . </S>",
    "<S> while the notion of most salient object is sensible when multiple objects exist in a scene , current datasets for evaluation of saliency detection approaches often have scenes with only one single object . </S>",
    "<S> we introduce three main contributions in this paper : first , we take an in - depth look at the problem of salient object detection by studying the relationship between where people look in scenes and what they choose as the most salient object when they are explicitly asked . </S>",
    "<S> based on the agreement between fixations and saliency judgments , we then suggest that the most salient object is the one that attracts the highest fraction of fixations . </S>",
    "<S> second , we provide two new less biased benchmark datasets containing scenes with multiple objects that challenge existing saliency models . </S>",
    "<S> indeed , we observed a severe drop in performance of 8 state - of - the - art models on our datasets ( 40% to 70% ) . </S>",
    "<S> third , we propose a very simple yet powerful model based on superpixels to be used as a baseline for model evaluation and comparison . </S>",
    "<S> while on par with the best models on msra-5k dataset , our model wins over other models on our data highlighting a serious drawback of existing models , which is convoluting the processes of locating the most salient object and its segmentation . </S>",
    "<S> we also provide a review and statistical analysis of some labeled scene datasets that can be used for evaluating salient object detection models . </S>",
    "<S> we believe that our work can greatly help remedy the over - fitting of models to existing biased datasets and opens new venues for future research in this fast - evolving field .    </S>",
    "<S> shell : xx ieee transactions on image processing    salient object detection , explicit saliency , bottom - up attention , regions of interest , eye movements </S>"
  ]
}