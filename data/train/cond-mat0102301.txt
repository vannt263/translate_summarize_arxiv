{
  "article_text": [
    "when a physical phenomenon is measured with a set of instruments , what we register is a sequence of values of some variable @xmath0    @xmath1 which takes values in a space @xmath2 .",
    "we will call @xmath2 the _ state space _ and the space of sequences @xmath3 the _ path space_. statistical properties of the phenomenon may be described at three different levels :    \\(1 ) by the expectation values of the observables ;    \\(2 ) by the probability measures on the state space @xmath2 ;    \\(3 ) by the probability measures on path space @xmath4 .",
    "one obtains three different characterizations of the phenomenon which represent successively finer levels of description of the statistical properties . borrowing a terminology used in large deviation theory@xcite @xcite",
    ", we will call these three types of description , respectively , _ level 1 , 2 and 3- statistical indicators . _    to obtain expectation values and probability measures we would require infinite samples and a law of large numbers .",
    "for any finite sample we obtain finite versions of the expectation values , the probability on state space and the probability on path space which are called the _ mean partial sums , _ the _ empirical measures _ ( or empirical probability distribution functions - pdf s ) and the measures on the _ empirical process_.    level-1 and level-2 analysis are the most common ones and their statistical indicators the most commonly quoted when a stochastic process is analyzed .",
    "however to the same expectation values for the observables or to the same pdf s , different processes may be associated .",
    "therefore full understanding of the process requires the determination of the level-3 indicators .",
    "recent advances have been obtained on the identification of processes , especially in connection with the analysis of hydrodynamic turbulence data@xcite",
    "@xcite @xcite @xcite @xcite .",
    "in particular it has been clarified that analysis and reconstruction of the process involves two different but related steps .",
    "one is the identification of the _ grammar _ of the process , that is , the allowed transitions in the state space or the subspace in path space that corresponds to actual orbits of the system .",
    "the second step is the identification of the _ measure _ , which concerns the occurrence frequency of each orbit in typical samples .",
    "although largely independent from each other , this two features have a related effect on the constraints they impose on the statistical indicators .",
    "identification of grammars and measures ( in particular gibbs measures ) has been dealt with recently , in particular in the context of hydrodynamic turbulence and other dynamical systems .",
    "market fluctuations is an interesting stochastic process@xcite @xcite .",
    "some analogies have been found between this process and some of the features of turbulence data@xcite @xcite",
    ". however , when statistical indicators are computed , it turns out that the two processes are different@xcite @xcite @xcite .",
    "nevertheless the statistical tools that have been developed for turbulence are mathematical devices which are not process - dependent and they may be applied to any stochastic process process .",
    "of course , underlying this approach is the working hypothesis that statistical methods , by themselves , are an appropriate tool to describe and reconstruct the market fluctuation process .",
    "this hypothesis underlies the modern view of the _ efficient market _ , namely the idea that the market appears to overreact in some circumstances and underreact in others is pure chance @xcite . in other words ,",
    "the expected value of abnormal returns is zero .",
    "contrariwise , if a well defined deterministic pattern of over- and underreaction is ever found then , in addition to chance , a behavioral component @xcite @xcite must always be included in any description of the market .",
    "behavioral trends , however , may turn out not inconsistent with a pure statistical description if the different reaction times of the diverse market components are taken into account , as well as the secondary reactions of the components to each other moves @xcite .    the emphasis on this paper will be on level-3 analysis and on the reconstruction of the processes .",
    "nevertheless we have also dedicated some time to the computation , for market fluctuations , of the level-1 and level-2 statistical indicators used in the past for turbulence data .",
    "in particular the behavior of some of these indicators already provides information on the nature of the grammars .",
    "this analysis is carried out in sect .",
    "3 . sect . 4",
    "is dedicated to the search for a gibbs measure and , once the long - memory features of the market processes are exhibited , sect .",
    "5 attempts to describe the processes in the framework of chains with complete connections .",
    "however , the first step in the analysis of any stochastic process is to inquire about the stationarity of the process and whether typical samples are available .",
    "this is the subject of the next section .",
    "large samples of high - frequency finance data are now available",
    ". however high - frequency data may not be the more appropriate data to begin understanding the stochastic process that underlies the market mechanism .",
    "this is because , when comparing minute to monthly variations for example , one is comparing systems with very different compositions , trading agents operating on the minute scale being in general different from those operating in longer time scales .",
    "this is evidenced , for example , by the different scaling laws for low and high - frequency data . in market data",
    "one faces a complexity versus statistics trade - off .",
    "the high frequency data certainly provides better statistics but it also involves the interplay of many more reaction time scales and market compositions in the trading process . for this reason , to `` purify '' as much as possible our samples , we have decided to concentrate on daily data .",
    "the price to be paid for this choice is the fact that , as compared for example with a large scale hydrodynamics experiment , the available amount of one - day market fluctuation data is relatively small .",
    "if , in addition , the data is non - stationary , the chances to obtain a reliable statistical analysis would be rather slim .",
    "reliable application of statistical mechanics tools to any kind of signal , presupposes that two conditions are fulfilled .",
    "first , that the process that generates the data has some kind of underlying stationarity or asymptotic stationarity .",
    "second , that the time sequence that is presented to the analysis is a typical sample of the process .",
    "the second condition , of course , we can only hope that it is realized and to improve our belief in this condition several different signals of a similar nature should be analyzed ( several different stocks , or currencies or markets ) . as to the first condition it requires some preprocessing of the data .",
    "we will concentrate in this paper in the daily fluctuation data of industrial stocks and indexes and the objective is to try to extract the features of the market process that acts on them .",
    "we look at each stock as an experimental probe that , while reacting to the market pressures , may reveal some of the mechanisms of the market process .",
    "market prices are by nature non - stationary entities .",
    "they fluctuate , they have general trends that depend on the general state of the economy , on the total amount of capital flowing to the market , on the general acceleration of the economy , on long and medium term political decisions and expectations , etc .",
    "nevertheless , our hypothesis is that , if all these global factors are extracted from the data , there are still some invariant features that characterize this peculiar human phenomenon .",
    "the type of data that will be analyzed is displayed in fig.1 that shows daily price data @xmath5 for three stocks and the nyse composite index .",
    "its non - stationary nature is very apparent .",
    "the first step is to extract the general trend .",
    "this is done , in a smooth way by a polynomial fit @xmath6 ( fig.2 shows an example , where a 7-degree polynomial is used ) .",
    "fig.3 shows the difference @xmath7 .",
    "clearly the data is still very far from stationary , because due to the market volume acceleration recent fluctuations carry a much larger weight . therefore the last step is a rescaling of the data , by the average @xmath8 , that is @xmath9 are the signals to be analyzed .. they are shown in fig.4 . to",
    "anyone used to examine turbulence data , it looks as if the market signals are now somewhat stable .",
    "that does not mean , of course , that they are stationary in the strict sense .",
    "however it suggests that in spite of currency adjustments , increased number of players , trade volumes and other macroeconomic indicators , there is something more or less permanent in this human game .",
    "detrending and rescaling of the data is important because we will be analyzing price differences over large time intervals . for one - day differences of log - price",
    ", the results would be identical to those obtained from the raw data .",
    "detrending and rescaling the data , the overall amplitude of price fluctuations becomes reasonably uniform over the time span of the data .",
    "however the process is not ( locally ) stationary , as seen in figs.5 and 6 that show the strong variation in time of the volatility ( here defined as the standard deviation of the price fluctuations ) .",
    "the two figures on the left show the standard deviation computed on a sliding time window of 10 days .",
    "on the right one compares the cumulative standard deviation for the rescaled ( full line ) and the non - rescaled data ( dashed line ) .",
    "it is quite apparent that only the rescaled data has the chance to belong to an asymptotically stationary process .",
    "once the data is detrended and rescaled there is in fact no evidence@xcite for an abnormal increase , in recent times , of the volatility in the underlying process .",
    "a direct test of stationarity of the detrended and rescaled data was obtained by coding with a 5-symbols alphabet ( as explained in sect .",
    "4 ) . then , computing the entropies of multi - symbol words , in the first and the second half of the samples , no significant difference is found .",
    "here we concentrate on level-1 and level-2 analysis of the regularized samples discussed in sect.2 , that is , we compute quantities related to averages values and to probability distribution functions ( pdf s ) .",
    "the level-3 analysis of the processes will be done in the latter sections .",
    "the main variables that are used to construct the statistical indicators are the differences of log - prices @xmath10 sometimes called the @xmath11days return . for each experimental sample ,",
    "three main statistical indicators are computed :    \\(i ) the maximum ( over @xmath12 ) of @xmath13@xmath14    \\(ii ) the moments of the distribution of @xmath15@xmath16 with @xmath17 meaning the sample average    \\(iii ) if inside a certain range , the moments satisfy @xmath18 then the scaling exponent @xmath19 is another important statistical indicator .    the results obtained from our detrended and rescaled samples are displayed in figs.7 to 9 .",
    "fig.7 refers to @xmath20 and fig.8 shows @xmath21 as a function of @xmath22 for different values of @xmath23 ( from top to bottom @xmath24 to @xmath25 ) .",
    "the large fluctuations in @xmath20 for large values of @xmath22 and in @xmath26 for large @xmath23 are quite natural given the size of the data samples .    in the range @xmath27 to @xmath28 the moments follow an approximate power law of the type of eq.([3.4 ] ) and from the behavior in this region we have extracted the scaling exponent @xmath19 shown in fig.9 .",
    "the main conclusions from this analysis of the statistical indicators are :    \\(a ) @xmath20 is log - concave , that is , @xmath29 is concave as a function of @xmath30 , increasing and probably ( with better statistics ) asymptotically constant for large @xmath31 ;    \\(b ) @xmath26 is also an increasing log - concave function of @xmath22 , allowing a power law approximation in a limited range ;    \\(c ) the scaling law @xmath19 is an increasing concave function of @xmath23 ;    \\(d ) for all samples , @xmath32 computed in the scaling region ( @xmath27 to @xmath33 ) is very close to 0.5 ;    \\(e ) the scaling properties of the nyse index seem somewhat different from those of the other stocks .",
    "however this is only apparent for @xmath34 , where poor statistics effects may already be felt",
    ".    from this analysis one also obtains precise statements concerning the similarities and differences between hydrodynamic turbulence and the market fluctuation process .",
    "properties ( a ) to ( c ) are shared by the turbulence data , although the numerical values of the statistical indicators are quite different . for example , for turbulence data @xmath35 whereas here @xmath36 , showing the essentially uncorrelated nature of the signal for @xmath37 .",
    "the correlation function of one - day returns and its absolute value @xmath38 and @xmath39 are shown in fig.10 .",
    "one sees that for @xmath40 the returns are uncorrelated , their correlation function remaining at the noise level .",
    "in contrast the correlation for the absolute value remains non - negligible for a longer time ( at least up to @xmath41 ) .",
    "this means that although the returns are linearly uncorrelated , non - linear functions of the returns remain correlated for longer periods .",
    "the behavior of the statistical indicators @xmath20 , @xmath21 and @xmath19 already has some strong implications on the level-3 features of the process , namely on the structure of its grammar .",
    "in fact , without restrictions on the allowed transitions @xmath20 and @xmath26 would be independent of @xmath22 and @xmath42 for all @xmath23 .",
    "in particular , property ( a ) implies that if the process is a topological markov chain the transitions allowed by the transition matrix @xmath43 must lie inside a strictly convex domain around the diagonal of @xmath43@xcite .",
    "fig.11 illustrates the dynamics of one - day returns @xmath44 it shows that the bulk of the data consists of a central core of small fluctuations with a few large flights away from this core .",
    "this structure of the data will have a strong influence on the results obtained in the next section .",
    "let us assume a coding of the dynamical system by a finite alphabet @xmath45 .",
    "then the space @xmath46 of orbits of the system are infinite sequences @xmath47 , @xmath48 , with the dynamical law being a shift @xmath49 on these symbol sequences . @xmath50",
    "depending on the dynamical law of the coded system , not all sequences will be allowed .",
    "the set of allowed sequences in @xmath46 defines the _ grammar _ of the shift .",
    "the set of all sequences which coincide on the first @xmath51 symbols is called a @xmath11_cylinder _ ( or @xmath11block ) and is denoted @xmath52 $ ] .",
    "the probability measures over the cylinders is the main tool that is used to characterize the dynamical properties and is a piece of information that may be inferred from the data .",
    "a particularly important measure on the cylinders is the gibbs measure defined by@xcite @xcite @xmath53\\right ) } { \\exp \\left ( -np+\\left ( s_{n}\\phi \\right ) ( \\omega ) \\right ) } \\leq c_{2 }   \\label{4.2}\\ ] ] with @xmath54 , @xmath55 being a hlder continuous function on @xmath56 called the _ potential _ and @xmath57 a function depending on the potential and the grammar called the _ pressure _ of @xmath58 .",
    "the ( equilibrium ) gibbs measure and the pressure bear an important relationship to the entropy @xmath59\\right ) \\log",
    "\\mu \\left ( [ i_{1}i_{2}\\cdots i_{n}]\\right )   \\label{4.3}\\ ] ] this is the variational principle that states that , for each potential and grammar , the @xmath60 taken over all @xmath61invariant measures @xmath62 is reached only for the gibbs measure @xmath63 and equals the pressure @xmath64    the potential may be chosen in such a way that @xmath65 .",
    "such potential is called a _ normalized potential_. in this case we have the following result@xcite @xmath66\\right ) } { \\mu \\left ( [ i_{2}(\\omega ) \\cdots i_{n}(\\omega ) ] \\right ) }   \\label{4.4a}\\ ] ] in principle this formula may be used to construct the potential using the empirical measures @xmath67\\right ) $ ] obtained from the experimental sample .",
    "the problem is that eq.([4.4a ] ) requires the use of blocks of length @xmath22 as large as possible but , for a finite sample , the statistics of such blocks suffers from large uncertainties .    for practical purposes the most important class of gibbs measures",
    "is the one associated to finite range potentials , that is , functions on @xmath46 that depend only on the first @xmath31 symbols of a sequence @xmath68 .",
    "the importance of finite range potentials lies in the fact that they may be used to uniformly approximate any hlder continuous potential and , on the other hand , given a limited amount of experimental data , only finite - range potentials may be reliably inferred from experiment .",
    "an important property of range@xmath69 potentials is that for all values @xmath70 with @xmath71 @xcite @xmath72\\right ) = \\frac{\\mu \\left ( [ i_{1}\\cdots i_{r}]\\right ) \\mu \\left ( [ i_{2}\\cdots i_{r+1}]\\right ) \\times \\cdots \\times \\mu \\left ( [ i_{n - r+1}\\cdots i_{n}]\\right ) } { \\mu \\left ( [ i_{2}\\cdots i_{r}]\\right ) \\mu \\left ( [ i_{3}\\cdots i_{r+1}]\\right ) \\times \\cdots \\times \\mu \\left ( [ i_{n - r+1}\\cdots i_{n-1}]\\right ) }   \\label{4.5}\\ ] ] we will make use of this important relation in our attempt to look for a gibbs measure for the market fluctuation data . on the one hand",
    "the relation ( [ 4.5 ] ) allows to express the entropy in terms of measures of cylinders of finite length only , namely @xmath73\\right ) \\log \\frac{\\mu \\left ( [ i_{1}\\cdots i_{k}]\\right ) } { \\mu \\left ( [ i_{1}\\cdots i_{k-1}]\\right ) } = h_{k}-h_{k-1 }   \\label{4.6}\\ ] ] for all @xmath74 if @xmath75 . if @xmath76 @xmath77 .",
    "@xmath78 is the entropy associated to cylinders of length @xmath79@xmath80\\right ) \\log",
    "\\mu \\left ( [ i_{1}\\cdots i_{k}]\\right )   \\label{4.6a}\\ ] ] this provides a criterium to find the range of the potential . using the empirical cylinder probabilities one computes @xmath78 for successively larger @xmath79 .",
    "then , the range of the potential is found when @xmath81 tends to a constant value .",
    "once the range is found , the potential may be constructed directly from the empirical weights @xmath82\\right ) $ ] .",
    "another important consequence of eq.([4.5 ] ) is that for @xmath83@xmath84\\right ) = \\frac{\\mu \\left ( [ i_{1}\\cdots i_{k}]\\right ) \\mu \\left ( [ i_{2}\\cdots i_{k+1}]\\right ) } { \\mu \\left ( [ i_{2}\\cdots i_{k}]\\right ) }   \\label{4.7}\\ ] ] we will use both the criterium following from ( [ 4.6 ] ) and eq.([4.7 ] ) to test for the possibility to construct a gibbs measure for the market fluctuation data .",
    "a five - symbols code @xmath45@xmath85 is used for the one - day return data @xmath86@xmath87 the average @xmath88 and standard deviation @xmath89 of the returns are computed . then",
    ", @xmath90    this coding is used and the empirical frequencies @xmath91\\right ) $ ] for blocks of successively larger order @xmath22 are found . of course @xmath22",
    "can not be arbitrarily large because of statistics .",
    "results will not be reliable whenever @xmath92 is larger than the size @xmath93 of the data sample .",
    "the statistical reliability may be directly tested either by comparing the number of different occurring blocks and @xmath92 or by observing the fall - off of the empirically computed @xmath94 .",
    "first we try to estimate a possible range for the potential using the criterium discussed above .",
    "the results are shown in figs.12 and 13 for the analyzed stocks and the nyse index .",
    "the plots on the left show the quantity @xmath95 and the plots on the right compare the number @xmath96 of occurring blocks of size @xmath79 in the data with the maximum possible number , @xmath97 .",
    "already for @xmath98 the difference @xmath81 seems to stabilize , staying nearly constant until @xmath99 .",
    "after @xmath99 it falls off , reflecting the lack of statistics also apparent in the comparison of @xmath100 with @xmath97 in the right hand side plots .",
    "these results seem to suggest that the data is described by a very short range potential .",
    "notice that for a similar analysis performed on hydrodynamic turbulence data the results are quite different with @xmath81 rising smoothly up to a certain saturation level and then decreasing when one reaches the lack of statistics level .    to check whether the short - range potential suggested by this criterium is reliable or whether it simply results from some misleading feature of the data",
    ", we have performed the test following from eq.([4.7 ] ) . for successively higher",
    "@xmath79 we estimate @xmath101\\right ) = \\frac{\\widetilde{\\mu } \\left ( [ i_{1}\\cdots i_{k}]\\right )   \\widetilde{\\mu } \\left ( [ i_{2}\\cdots i_{k+1}]\\right ) } { \\widetilde{\\mu } \\left ( [ i_{2}\\cdots i_{k}]\\right ) } $ ] from the empirical @xmath82\\right ) $ ] and @xmath102\\right ) $ ] , which is then compared with the empirically observed @xmath103\\right ) $ ] .",
    "the standard deviation of the relative positive errors @xmath104\\right ) -\\mu _ { e}\\left ( [ i_{1}\\cdots i_{k+1}]\\right ) } { \\frac{1}{2}% \\left ( \\widetilde{\\mu } \\left ( [ i_{1}\\cdots i_{k+1}]\\right ) + \\mu _ { e}\\left ( [ i_{1}\\cdots i_{k+1}]\\right ) \\right ) } \\right )   \\label{4.11}\\ ] ] is computed and the number of blocks for which this error is one and two standard deviations above the mean is computed .",
    "the result is plotted in fig.14 where the number of underestimation errors that are one ( o ) and two ( * ) standard deviations away from the mean error are compared with the total number @xmath105 of different observed blocks of each length @xmath79 .",
    "one sees that the number of large deviation errors is very large and , identifying the blocks for which these errors occur , one finds out that they all correspond to blocks involving large positive or negative @xmath106 s ( @xmath107 and @xmath108 ) .",
    "the conclusion is that a short - range potential would describe the small fluctuations in the data , the large fluctuations being badly described by it .",
    "the reason why the empirically found difference @xmath81 seems to saturate for a small @xmath79 is because , as is apparent from fig.11 , the bulk of the data consists mostly of small fluctuations plus a few large flights .",
    "the saturation of @xmath81 for small @xmath79 is a reflection of the largely uncorrelated nature of the small fluctuations , whereas other features like the large deviations , persistence of non - linear correlations ( volatility ) , etc .",
    "are not captured by a short - range potential .",
    "large deviations being misrepresented by an empirically constructed measure is typical of situations where the actual measure is non - gibbsian@xcite @xcite . in our case , however , it may also occur that the measure is gibbsian but with a long - range potential .",
    "this would correspond to a sharp rise of @xmath81 at @xmath98 followed by a very slow increase above @xmath98 . in the empirical results",
    "a small increase may be hidden by the fact that , as the block length increases , the statistics becomes poorer . a large deviation analysis applied to the calculation of @xmath109 , using a standard technique@xcite to construct the free energy and",
    "the deviation function from the data , is consistent with this hypothesis .    in any case , whether a gibbs measure exists or not , the finite - range potential framework does not seem to be the more convenient way to describe the market fluctuation process . in the next section",
    "we will explore another approach specially suited to deal with long - memory processes .",
    "processes with long memory have been studied in the past . under certain conditions , that is , when the dependence on the past does not decay too slowly , existence and uniqueness of a well defined process may be proved .",
    "a particularly well established framework is the one of chains with complete connections and summable decays ( @xcite @xcite @xcite and references therein ) .    a stochastic process @xmath110 with alphabet @xmath45 is said to be a _ chain with complete connections _ ( ccc ) if the following conditions are satisfied    1 .",
    "@xmath111@xmath112 2 .",
    "the limit @xmath113 exists @xmath114 3 .",
    "there is a sequence @xmath115 with @xmath116 , such that for all @xmath117 with @xmath118 for @xmath119@xmath120    the process is said to be a _ chain with complete connections and summable decay _ ( cccsd ) if @xmath121    conditions 1 . and 2 .",
    "are implicitly assumed when we considered the processes ( and pre - processed the data ) to be asymptotically stationary . as for the decays",
    "@xmath122 they may be estimated from a typical sample of the process . from the empirical probabilities for @xmath123 where @xmath124 is a block of arbitrary length ,",
    "ones computes for each fixed set @xmath125 the maximum and the minimum over @xmath124 , @xmath126 obtaining for @xmath122@xmath127 however if the statistics for very long blocks is poor , which is in general the case for finite samples , the computation of the maximum from empirical data is not reliable .",
    "a better estimate of the decay behavior of the decay rates is obtained from the following quantity , which smooths out the large fluctuations due to poor statistics @xmath128 the average being taken over all sets @xmath129 of size @xmath130 .",
    "the results obtained for the @xmath131coded data of the detrended fluctuations ( of bmw data ) using @xmath124 blocks of length 5 to 8 ( @xmath132 ) is plotted in fig.15 .",
    "similar results are obtained for the other data .",
    "the result is compatible with exponential decay , which would probably imply the existence of a gibbs measure ( albeit with a long range potential ) .",
    "the data for the maxima of @xmath133 displays large fluctuations and slower decay . however , with the amount of available data it is not reliable for long blocks . in any case , in the present context of ccc - processes ,",
    "what the result suggests is the summability of the @xmath134 s .",
    "( @xmath135 ) . for practical purposes the most importance consequence of",
    "this fact is that a ccc - process with summable decays is the @xmath136limit of its markov approximations of order @xmath79 .",
    "the nature of this approximation should however be clearly understood .",
    "the @xmath136_distance_@xcite between two processes refers not to the processes themselves but to the process that implements the coupling of the two processes .",
    "a _ coupling _ between two processes @xmath137 and @xmath138 over the alphabet @xmath139 is another process @xmath140 defined over @xmath141 such that the marginal probabilities of @xmath142 and @xmath143 coincide with those of @xmath144 and @xmath2 .",
    "then the @xmath136distance between @xmath0 and @xmath2 is @xmath145 for some types of coupling the two processes @xmath142 and @xmath146 are know to coincide after a certain random time .",
    "however , for the original processes @xmath0 and @xmath2 , if the @xmath136distance tends to zero it does mean that the processes will coincide after a certain time .",
    "it only means that it will occur for some other processes with the same marginal probabilities .",
    "this fact has an important bearing on the correct interpretation of the `` perfect simulation '' schemes @xcite proposed for ccc s .",
    "perfect simulation is always understood in the @xmath136distance sense and it does mean perfect prediction . it means simply that a process is constructed with the same conditional probabilities of the original process , whenever the conditional probabilities of the original process are known . in practice not all conditional probabilities involving infinite pasts are needed , because going back to a regeneration time , only a finite number of back steps are required .",
    "several simulation schemes have been proposed for ccc s with summable decays .",
    "the most important one for the applications , when the conditional probabilities are inferred from experiment , is the sequence of canonical markov approximations of finite order @xmath79 ( @xmath147cma ) .",
    "a @xmath147cma of a process @xmath0 is a markov chain @xmath148 of order @xmath79 with conditional probabilities @xmath149 such that @xmath150 for a ccc @xmath0 with summable decays@xcite @xmath151 @xmath152 being a constant .",
    "actually the property of the markov approximation that is essential for the approximation result ( [ 5.10 ] ) is @xmath153 meaning that for markov approximation schemes , other than the canonical one , eq.([5.10 ] ) holds provided ( [ 5.11 ] ) is satisfied .",
    "in fact , when the conditional probabilities are inferred from limited experimental data a different markov approximation is more convenient .",
    "the following approximation scheme is proposed for the market fluctuation data , which we call the @xmath154markov approximation :    \\i ) empirical transition probabilities @xmath155 are inferred from the occurrence probability of blocks of order @xmath156 .",
    "up to a certain order @xmath157 . of course , only probabilities that correspond to blocks @xmath158 that appear in the data will be available and especially for large @xmath130 many will be missing .",
    "\\ii ) for the simulation , with an approximation of order @xmath79 , one looks at the current block @xmath159 of order @xmath79 and uses the @xmath160empirical probability to infer the next state @xmath161 . if that block has not appeared in the data that was used to construct the empirical probabilities , then one looks at the @xmath162 sized block @xmath163 and uses the @xmath162 order empirical probabilities .",
    "if necessary the process is repeated until an available empirical probability is found .",
    "this is the reason why this is called the @xmath154markov approximation .",
    "this approximation scheme has been applied to the market fluctuation data and for each @xmath147order the successor @xmath161 of each block @xmath164 is compared with a prediction @xmath165 obtained by throwing a random number with the probabilities @xmath166 .",
    "figs.16 shows some of the results . in all cases",
    "the quantity that is plotted is the averaged squared error @xmath167 the average being taken over the samples and 100 different runs .",
    "the two upper plots and the left lower plot show the results obtained ( for each approximation order @xmath79 ) when half of the data for each company is used to predict the other half .",
    "the points labelled ( @xmath168 ) correspond to the past used to predict the future and those labelled ( @xmath169 ) to the future used to predict the past .",
    "finally the right lower plot shows the results obtained when @xmath165 is chosen at random ( for the 3 companies , ibm @xmath170 , bayer @xmath171 and bmw @xmath172 ) .",
    "the main conclusions that may be extracted from these results are :    * the average prediction obtained from using the empirical probabilities is better than a random choice .",
    "* however , the main improvement is a result of a correct accounting of the two - symbol probabilities ( @xmath173 ) . * after the improvement due to the use of the lowest order blocks a small ( but consistent ) improvement is found by using the past information up @xmath99 or @xmath174 .",
    "no significant improvement is obtained by using higher order approximations .",
    "this is consistent with the poorer statistics of large blocks .",
    "actually for each individual simulation the result of using @xmath175 leads to much larger fluctuations .",
    "the main conclusion is that although the bulk of the data is represented by a short - memory process , there is nevertheless evidence for a small long - memory component that is captured by the higher - order markov approximations .",
    "depending on the amount of data that is available to infer the empirical conditional probabilities there is a maximum @xmath176 that should be used for the simulation process .",
    "this @xmath177 value may be estimated from the quantity @xmath100 plotted in figs 12 and 13 . finally ,",
    "although a mild gain is obtained from using @xmath178block probabilities rather than one - symbol probabilities , it should be remembered that perfect simulation in the @xmath136distance sense is not perfect prediction for the actual process .",
    "this is a point to keep in mind when attempting to develop any trading strategies based on the empirical block probabilities .",
    "we have also explored the use of the empirical probabilities of one company to predict the behavior of the others . in all cases",
    "the improvement coming from the one - symbol probabilities ( as compared to random choice ) is obtained .",
    "this means that the one - symbol probabilities are similar in all companies .",
    "however for the long - memory component the behavior is very much company - dependent .",
    "for example there seems to be no correlation of this component between ibm and the other two companies , with the prediction being actually worse when the empirical probabilities for longer blocks are used .",
    "the same happens also when the empirical probabilities of bmw and bayer are used to predict ibm .",
    "however there is some statistical correlation between the long - memory components ( and some mild prediction improvement ) between bmw and bayer .",
    "this suggests that the statistical short - memory component of the market process might be similar for many different stocks , whether the long - memory component might be different from market to market and to divide the stocks into classes .",
    "a similar conclusion follows from the stocks taxonomy obtained by mantegna @xcite , although that work does not distinguish between the short- and long - memory components of the process .",
    "the bulk of the market fluctuation process seems to be a short - memory process . in addition",
    "it has a small long - memory component , which however is very important for practical purposes because it is associated with the large fluctuations of the returns .",
    "2 .   existence of the long - memory component suggests the _ chains with complete connections and summable decays _ as the appropriate framework to describe these processes .",
    "although the decays may be exponentially converging , the lack of accurate data concerning long blocks prevent an accurate description by a finite range gibbs potential .",
    "3 .   the sequence of empirical based @xmath154markov approximations discussed in sect.5 seems the most unbiased simulation of the process .",
    "eventual convergence in the @xmath136distance sense is expected to hold because the market fluctuation process seems to fit in the framework of chains with complete connections and summable decays .",
    "4 .   except for cases where one is sure of the existence of a finite potential , markov approximations must always be used if only finite data is available .",
    "this true whether a gibbs measure exists or not .",
    "what the chains with complete connections framework provides though , is a rationale for the convergence of the markov approximations and a criterium to estimate , through the @xmath122 decays , how good this approximation is .",
    "notice however the trade - off between higher order approximations and lack of statistics , that leads to an optimal block length for the empirical probabilities to be used in the simulations .",
    "5 .   as work for the future we point out that it would be interesting to analyze in this framework the high frequency market data",
    "here however attention should be paid to the possibly multi - scale and multi - component nature of the processes ."
  ],
  "abstract_text": [
    "<S> the statistical properties of a stochastic process may be described ( 1)by the expectation values of the observables , ( 2)by the probability distribution functions or ( 3)by probability measures on path space . here </S>",
    "<S> an analysis of level ( 3 ) is carried out for market fluctuation processes . </S>",
    "<S> gibbs measures and chains with complete connections are considered . </S>",
    "<S> some other topics are also discussed , in particular the asymptotic stationarity of the processes and the behavior of statistical indicators of level ( 1 ) and ( 2 ) . </S>",
    "<S> we end up with some remarks concerning the nature of the market fluctuation process .    </S>",
    "<S> * keywords * : market fluctuations , gibbs measures , chains with complete connections </S>"
  ]
}