{
  "article_text": [
    "the method of least squares linear regression ( straight line fitting ) has a very long history : it was invented in its simplest form by c.f .",
    "gau , but is still one of the most widespread and powerful approaches in data analysis . it may be used as a stand - alone tool to detect linear trends , or be incorporated into more complex analysis procedures , like detrended fluctuation analysis proposed in @xcite , whose first step requires subtraction of linear trends from subpartitions of data .",
    "the standard variant of the method assumes the linear relation between the dependent variable @xmath1 and the independent one @xmath2 , and the existence of a random impacts on the outcomes of single measurements , represented by the noise @xmath3 , so that @xmath4 and is aimed onto extracting information about @xmath5 and @xmath6 from such noisy data .",
    "the standard method works well if the data are `` compact '' , i.e. when the corresponding interval on the abscissa is homogeneously sampled and no large ordinate outliers are present .",
    "the method is essentially a parametric one and can be regarded as the maximum likelihood approach assuming the gaussian distribution of independent errors .",
    "the challenges of more complicated samples originating from modern problems of experimental and computational physics and related fields have motivated works aimed to improve the accuracy of fits to extremely irregular data , i.e. the ones having outliers on the ordinate and on the abscissa ( leverage points ) , or large errors in locating @xmath7 , see @xcite for the list of modern modifications .",
    "for this reason , a number of works discuss the criteria for a detection of this outliers with the following their elimination with respect to a prescribed cut - off level , and the regression of obtained `` cleared '' samples @xcite or a choice of subintervals , where the influence of outliers could be negligible @xcite .",
    "another problem arises for the non - independent noises which themselves can show trends @xcite .    even in the case of independent errors",
    "the problems arise if the noise possess a heavy - tailed distribution , i.e. generates large outliers .",
    "these are quite characteristic for a large variety of process in small nonequilibrium systems , network dynamics , econophysics , etc . @xcite .",
    "since these distributions may lack even the first moment , their processing , if keeping the principles of the least - square regression untouched , requires very specific methods @xcite including repeated median regression , the consideration of a nested hierarchy block subdivisions for the analyzed sample , etc . for such cases non - parametric regression methods may be superior to the standard one .    in the present work we discuss two such approaches , the quantile regression as pioneered by koenker and basset @xcite , and the scale parameter regression based on the properties of characteristic functions .",
    "the methods are non - parametric ( i.e. do not assume the specific form of the distribution ) and robust ( i.e. do not rely on the existence of its moments ) .",
    "our numerical examples consider linear trend in presence independent errors distributed according to lvy stable laws .    as a practical example",
    ", we consider geophysical data , namely the eastward component of the geomagnetic field measured on a moving antarctic ice shelf , showing a linear trend from the motion and a combination of small and large scale fluctuations . here",
    "the results of robust scale parameter regression are compared to conventional methods .",
    "before discussing the specific methods , let us shortly review the general idea ( or , better , general ideas ) of linear regression .",
    "posing the regression problem starts from the assumption that the values of the dependent variable ( observable ) @xmath8 linearly depend on @xmath7 , but are subject to additive noise @xmath9 , eq.([lire1 ] ) .",
    "we are looking for the way of inferring of the parameters @xmath5 and @xmath6 , delivering the best possible estimates @xmath10 and @xmath11 for these parameters . in the ideal situation ( at least in the asymptotic setting when the total number of measurement points @xmath12 gets large , @xmath13 ) the method should give @xmath14 , @xmath15 . in praxis , this is usually done by the application of the least squares fit .",
    "there are different ways to think about the least squares method .",
    "first , we can follow the standard line of argumentation pertinent to statistical inference and make a maximal likelihood estimate for the parameters @xmath5 and @xmath6 assuming the distribution of @xmath9 is gaussian with zero mean and unknown dispersion , @xmath16 in this case the probability density of a given realization of @xmath9 is given by the product of such single - point distributions : @xmath17 changing from @xmath9 to @xmath8 we get the corresponding density of the experimental outcomes @xmath18 , @xmath19 considering the log - likelihood of @xmath5 and @xmath6 provided the data , @xmath20 and maximizing it with respect to @xmath5 and @xmath6 , we get the least square prescription for finding @xmath5 and @xmath6 by minimizing the sum of squared residues @xmath21 ^ 2 = min.\\ ] ] note that this criterion , which essentially assumes the gaussian prior is of course a parametric one , and therefore not robust . assuming another distribution , say the laplace one with @xmath22 will lead to a different criterion , in this case to the minimization problem of @xmath23    another approach to the linear regression is a geometric one .",
    "as above , the variables @xmath9 are assumed to be i.i.d .",
    "random variables drawn from a distribution @xmath24 , which we will be assumed continuous , symmetric and monomodal .",
    "the coordinates of points @xmath25 are mutually independent .",
    "the points @xmath25 are considered as realizations of points in a two - dimensional _ cloud _ characterized by the density ( joint probability density ) @xmath26 .",
    "this cloud is mirror - symmetric with respect to @xmath2 axis .",
    "the pairs @xmath27 with @xmath8 depending on @xmath7 are realizations of points of another two - dimensional cloud , which is obtained from the first one by a shift and an affine transformation .",
    "the regression aims on the restoration of these transformation parameters @xmath5 and @xmath6 so that the cloud with the density @xmath28 with @xmath29 indeed has the properties discussed above .",
    "one looks for the empirical estimators @xmath10 and @xmath11 of these parameters .    if we say that this symmetry presumes the fact that the center of mass of the cloud lays on @xmath2 axis and then that one of its main axes of inertia coincide with it , we get from the first requirement @xmath30 so that @xmath31",
    ". then one notes that the main axes of inertia of the two - dimensional body are such that the moments of inertia with respect to these are extremal , and requires the extremality of @xmath32 ^ 2 = \\sum_i [ ( y_i - \\langle y \\rangle - a ( x_i - \\langle x \\rangle)]^2\\ ] ] ( with @xmath33 being the moment of inertia with respect to the @xmath2-axis ) with respect to @xmath5 with @xmath6 defined as before .",
    "this gives equations which define @xmath5 and @xmath6 from the least square method .",
    "however , the mirror - symmetry of the @xmath34-cloud with respect to @xmath2-axes can be cast into different other extremality prescriptions or into the statement that half of its mass has to lay above , and half below the axis , which gives ( provided @xmath6 is defined ) the robust median regression for @xmath5 .",
    "the method should work in this form provided @xmath35 and @xmath36 do exist . if they do not ( i.e. when the distribution of @xmath1 is broad ( outliers ) or the distribution of @xmath2 is broad ( leverage points ) ) , the standard problems arise .",
    "note that the median method is sensitive to the centering of the cloud : it will break down if the center of the cloud is at the origin .",
    "another variant of the geometric approach discussed below is based on a different consideration .",
    "it aims on finding the estimate for @xmath5 prior to connecting it to @xmath6 and is robust both with respect to outliers and to leverage points ( which question is not a topic of the present work ) .",
    "let us define the residues @xmath37 and concentrate first on the obtaining of the best estimate @xmath10 for the slope parameter @xmath5 .",
    "we note that the parameter @xmath6 only shifts the distribution of @xmath38 , and only influences the position of @xmath38 , while the parameter @xmath5 influences the width of @xmath39 . in the case of exact tuning @xmath40 this width is given by the one of the distribution of @xmath3 ; for @xmath41 the distribution of @xmath38 ( centered on @xmath42 ) is a _ convolution _ of the distribution of @xmath3 and the one of @xmath43 , which now has a nonzero width .",
    "since the convolution of two distributions is always `` broader '' than each of them , the minimal width will coincide with the one of the distribution of @xmath3 and achieved for @xmath40 . in a setting when the width of the distribution is given by its variance",
    ", the method again reduces to the least squares approximation : the empirical width is defined as @xmath44 and is minimized with respect to two free parameters @xmath10 and @xmath11 .",
    "in our approach we use the fact that while the parameter @xmath6 only shifts the distribution of @xmath38 , and influences the position of @xmath38 , the width of the distribution of @xmath38 is only influenced by the parameter @xmath5 . in the case of exact tuning @xmath40 this width is given by the one of the distribution of @xmath3 .",
    "our two regression approaches differ in the point of how this `` width '' of the distribution is defined .    as we have already seen , defining the width by a variance of the corresponding distribution ( provided it exists ) leads to the standard least square prescription",
    "; its additional advantage is that the minimization procedure follows by solution of a system of linear algebraic equations .",
    "other definitions of width ( for example estimation the first absolute moment of the distribution ) lead to nonlinear equations which have to be solved numerically .",
    "both methods estimate width via some absolute moments of the distribution .",
    "both methods do not work for distributions having power - law tails ; the first one fails for the ones with diverging second moment , the second one for the distributions with diverging first moment ( like cauchy distribution ) .",
    "moments do not represent robust statistics since they do not exist for all distributions .",
    "the robust statistics is given by such measures of width which exist for all distributions of @xmath1 and of @xmath2 .",
    "there are several classes of such robust measures either pertinent to the distribution itself , say , its quantiles , or to its characteristic function , say its scale parameter .",
    "these two possibilities will be discussed in the forthcoming sections . in all our discussions we will only concentrate on outliers , and both in our numerical examples and in the practical one @xmath7",
    "are homogeneously distributed within a finite interval .",
    "one of the robust estimates of width is given by interquantile distance of the corresponding distribution ( since the cumulative distribution function ( _ c.d.f .",
    "_ ) and therefore the quantiles do exist for any proper pdf ) .",
    "the practical realization for a given set of data @xmath45 , @xmath46 is subdivided into two steps . since the width of _ c.d.f .",
    "_ is invariant with respect to shifts , at the first step we consider the series @xmath47 and its _ c.d.f . _",
    "s @xmath48 for the trial slopes @xmath49 equidistantly sampled with the step @xmath50 within some interval .",
    "we moreover fix some quantiles @xmath51 and @xmath52 defining the width to be minimized ( in the following examples we set @xmath53 ) .",
    "as it has been discussed above , the minimal half - width of @xmath54 corresponds to the best fit of @xmath55 .    for each @xmath49 ,",
    "the obtained set of values @xmath56 is sorted in ascending order to @xmath57 , whence the desired _ c.d.f .",
    "_ half - width is simply @xmath58}-\\tilde{y}^{i}_{[n/4]}. \\label{hwk}\\ ] ] a search of the minimum for the series ( [ hwk ] ) provides the index of desirable value @xmath55 . here",
    "the square brackets denote an integer part of the fractions . having obtained @xmath10 , one can obtain the shift parameter @xmath11 as the median of the distribution of @xmath59 .",
    "however , it should be pointed out that it might be preferable to obtain the value of @xmath11 via the equidistant trials @xmath60 , for which the _ c.d.f .",
    "_ of the series @xmath61 has a median equal to zero instead of the single - run median search .",
    "this is the case for non - equispaced samples , since the algorithms for identifying the zero crossing provide better accuracy due to the possibility of interpolation .",
    "practically , due to sample s discreteness , we use the criterion of minimum for @xmath62}|$ ] , where @xmath57 is again the series of @xmath63 sorted in ascending order . thus both fitted parameters , @xmath5 and @xmath6 are determined .",
    "although in our simple realization of the method we mostly obtain the quantiles by simply counting the points , we note that this can be done in a more elegant way using the quantile regression methods as pioneered in @xcite ( see @xcite for the state of the art discussion ) .",
    "this general approach can be cast into the minimization problem , namely , in solving @xmath64 where @xmath65 is the regression quantile sought for .",
    "formally , the method requires the existence of the first moment of the @xmath1-distribution , and may lead to instabilities when applied to situations with large outliers , although we never encountered them is our test runs .",
    "it should be pointed out that although the approach works for an arbitrary part of _ c.d.f _",
    "s width , the important question is , what quantile has to be chosen to provide the largest local sensitivity of the method .",
    "let us at the beginning consider a centered distribution and take @xmath66 .",
    "let us denote @xmath67 .",
    "the distribution of centered @xmath1 is a convolution of the distributions of @xmath68 and of @xmath3 , since @xmath9 are independent on @xmath2 .",
    "for @xmath2 homogeneously distributed on the interval @xmath69 $ ] the convolution @xmath70 of the corresponding distributions can be expressed via the cumulative distribution function @xmath71 , namely @xmath72 . \\label{eqpfull}\\ ] ] for @xmath73 very large the distribution tends to a rectangular of width @xmath74 , so that its interquantile distance ( for given quantiles of index @xmath51 and @xmath52 ) is linear in @xmath73 .",
    "for @xmath73 small the dependence of interquantile distance on @xmath73 gets quadratic .",
    "let us discuss this situation by expanding the cumulative functions @xmath75 in eq .",
    "( [ eqpfull ] ) in taylor series around @xmath1 .",
    "since all even terms vanish , only the terms linear and cubic in @xmath76 survive in the lowest orders , so that @xmath77 = p(y ) + \\frac{p''(y)}{3}w^2 \\delta a^2 . \\label{taylor}\\ ] ] the position @xmath78 of the @xmath51-th quantile is given by @xmath79 inserting the expression eq.([taylor ] ) into eq.([quant ] ) and performing the integration we get @xmath78 as the solution of the equation @xmath80 we note that for @xmath81 the solution of @xmath82 gives exactly the quantile of the distribution of the noise , so that @xmath83 is proportional to the shift of this quantile when detuning @xmath5 .",
    "the highest sensitivity is attained when the largest absolute shift @xmath84 for given @xmath73 is observed .",
    "since @xmath85 this takes place when @xmath51 is chosen such that the absolute value of the logarithmic derivative @xmath86 is attained at the point @xmath78 of the error distribution .",
    "for example for the cauchy distribution this are _ exactly _ the lower and the upper _ quartiles _ of the distribution .    for a gaussian distribution , for which the logarithmic derivative equals to @xmath78 the absolute relative change in the quantile @xmath87 does nt depend on the index .",
    "however , it should be kept in mind in practical applications that the chosen quantile must contain a sufficient number of points .",
    "let us consider the signal @xmath88 , where @xmath3 is a random variable with the symmetric null - centered @xmath0-stable density with the characteristic function @xmath89 where @xmath90 $ ] is the characteristic exponent and @xmath91 is the scale parameter .",
    "note that for @xmath92 the second moment is absent , therefore the dispersion - based methods are inapplicable , and for @xmath93 $ ] even the mean value diverges , thus one can not apply the approaches calculating the absolute values of deviations .",
    "[ example ] demonstrates an example of the fitting for the function @xmath94 corrupted by the white lvy noise with @xmath95 ( cauchy distribution ) with the scale parameter @xmath96 , i.e. with a quite large outliers , over the time interval @xmath97 $ ] sampled with the unit step .",
    "the random numbers are generated by the routine stblrnd @xcite based on the methods presented in @xcite .",
    "the sample is processed by the written matlab routine with the step size @xmath98 for both @xmath5 taken from the interval @xmath99 $ ] and @xmath6 taken from @xmath100 $ ] .",
    "the obtained pair @xmath101 , while the conventional least squares method of linear fit provides sufficiently worse values @xmath102 .        fig .",
    "[ halfwidth ] demonstrates the behavior of the basic statistics of the method , the half - width of the cumulative distribution function .",
    "it is naturally irregular since a single random realization is processed .",
    "however , the global minimum is clearly visible even on the background of multiple small local ones .",
    "note that the presence of local minima might be a problem if the global one is shallow , as it happens in the example of sec .",
    "therefore it is always advisable to plot the curve like in fig .",
    "[ halfwidth ] to be able to estimate the possible uncertainties caused by this effect . in the case when such uncertainties are large it is better to resort to the method described in the next section .     as a function of the trial slopes @xmath49 for the data shown in the fig .",
    "[ example ] .",
    "]    fig .",
    "[ ensemble ] shows the behavior of scaled half - width of the _ c.d.f . _ for different characteristic exponents and scale factors , i.e. the @xmath0-dependence of @xmath103 .",
    "the curves are results of ensemble averaging over 10000 realizations .",
    "one can see that they all monotonically decrease when the distribution of errors tends to the normal distribution and have a universal shape ( the deviations are within the error of averaging ) .",
    "this fact follows from the self - similarity of the distributions ( [ pdf ] ) since their arguments depend on the combination @xmath104 if the scale parameter is defined as in eq.([pdf ] ) .",
    "additionally , this picture shows that although for different @xmath0 these are the quantiles with different indices which are most sensitive to the deviation of @xmath5 from its best value @xmath10 , fixing interquantile distance ( the half - width of _ c.d.f _ in our case ) as a test statistics practically provides a uniform quality of slope s determination .     and scales @xmath105 ( diamonds connected by the solid line ( blue in color online ) ) , @xmath106 ( circles connected by the dashed line ( black in color online ) ) and @xmath96 ( asterisks connected by the dash - dotted line ( red in color online ) ) . ]",
    "another method is based on the estimating width of the distribution via its characteristic function @xmath107 , which is also an object which does exist for any proper distribution .",
    "since the distribution of centered @xmath1 is a convolution of the distributions of @xmath68 and of @xmath3 , its characteristic function @xmath108 is the product of the characteristic functions of the distributions of @xmath3 , @xmath109 , and of @xmath110 , being @xmath111 : @xmath112 for example , for symmetric levy noise with scale parameter @xmath113 and homogeneous distribution of @xmath2 on @xmath114 we get @xmath115 ( where the prefactor of @xmath116 is simply the dispersion of the distribution of @xmath2 ) .",
    "thus , fixing some @xmath117 ( small enough so that the asymptotic expansion close to @xmath118 still works for both distributions of @xmath2 and of @xmath3 ) , we can look for the maximum in @xmath10 of @xmath108 which is attained exactly at @xmath81 .",
    "note that for gaussian distribution of @xmath3 eq.([fsink ] ) for small @xmath117 reduces to @xmath119 describing a centered distribution with the total dispersion @xmath120 so that minimizing the total width using the small-@xmath117 approach reduces to the minimizing of the dispersion of @xmath8 ; its approximation by an empirical estimator leads to the least squares method .",
    "the local sensitivity of the method is always given by @xmath121 so that it can be influenced by a judicious choice of @xmath117 which has to be small enough to allow using the quadratic approximation ( it depends e.g. on the higher moments of the @xmath2-distribution ) but not too small to make the sensitivity too low .",
    "this appropriate value of @xmath117 for an arbitrary @xmath0 can be determined by the following reasoning .",
    "the function @xmath122 in the first line of eq.([fsink ] ) is an oscillating function whose two roots closest to the global maximum at @xmath118 are located in @xmath123 therefore , if the value of @xmath10 can be restricted to @xmath124 $ ] by inspection , the frequency parameter can by taken as @xmath125 .",
    "this results in the location of the main maximum within the prescribed interval only .",
    "therefore , the operational idea of the method is to calculate the empirical characteristic function @xmath126 \\label{hatf}\\ ] ] as an approximation for @xmath108 for given @xmath5 and consider its dependence on @xmath5 for a fixed @xmath117 within the range described above .",
    "the shift parameter @xmath6 is omitted in eq .",
    "( [ hatf ] ) since it only introduces the phase multiplier @xmath127 which can be eliminated by considering @xmath128 ( or alternatively by centering in real space ) .",
    "[ kdiffa ] demonstrates the example of the behavior for the function @xmath129 calculated for a single realization of the same linear function corrupted by lvy noise as in the subsection 3.2 with the same spacing of the trial parameter @xmath5 .",
    "one can clearly see the maximum sought for , which allows to determine @xmath130 , a better estimate than the one obtained by the method of the previous section .",
    "moreover , the curve is much smoother in comparison with fig .",
    "[ halfwidth ] which allows to avoid false extrema .",
    "the still undefined parameter @xmath6 can be determined using the median regression of detrended data @xmath131 as described above , since in the present approach it only enters the phase shift and can only be defined modulo @xmath132 .    .",
    "]      let us compare the efficiency of two proposed methods , primarily in determination of the line s slope .",
    "since individual realizations , especially in the case of small @xmath0 , have a considerable variability , we performed the calculations for an ensemble of 1000 individual realizations ( with the parameters given above ) , each of them fitted separately .",
    "[ compl ] presents the resulting average values of the slope and its root - mean - square deviations from the exact value @xmath133 .",
    "[ compa ] shows a similar comparison for a fixed sample length ( @xmath134 ) but for different indices @xmath0 of the noise s distribution .    .",
    "]    one can see that both methods provide more than reasonable fitting even for very short samples .",
    "the method based on the characteristic function is more accurate for shortest samples that can be explained by the @xmath132-periodicity of the random phase : since large outliers originated from lvy noise are relatively rare , their influence in the vicinity of the main frequency maximum is small for short samples while their presence in boundary quartiles strongly influences the half - width of _",
    "c.d.f_. for larger samples , the equivalent outliers @xmath9 and @xmath135 result in larger errors in comparison with the results provided by the interquantile distance method .",
    "let us turn to the @xmath0-dependence .",
    "two methods perform slightly differently at small @xmath0 ( fig .  [ compa ] ) , otherwise reproducing the corresponding values very accurately . the root - mean - square deviation of @xmath10 from the exact value is a monotonically decaying function of the lvy index for the characteristic function method . for the interquartile method it has a minimum around @xmath95 :",
    "this fact reflects various sensitivity of the method for different @xmath0 ; taking quartiles produces maximal sensitivity exactly for @xmath95 .    .",
    "as a practical test we process geomagnetic field data measured by a fluxgate magnetometer located at halley , antarctica on the brunt ice shelf .",
    "such data are known to be complex comprising regular oscillations , highly irregular short bursts , and a linear trend originating from the ice shelf displacement @xcite .",
    "it should be pointed out that the de - trending of such data is one of the key problems of ice shelf - based data processing @xcite .",
    "[ halley_data ] demonstrates the example of such data , the small - scale processing of which has been discussed in the work @xcite .",
    "its authors highlighted the necessity of an additional median excluding even for very short portions of the data de - trended by a conventional method due to a presence of large outliers .",
    "the feature which makes this practical example different from our previous numerical ones is the correlated nature of the noise .",
    "however , one readily infers that the correlation time is short compared to the total measurement time , so that the methods should presumably work .",
    "the parameters of the noise were estimated as follows : the data were detrended by the least square fit , and then the routine stblfit @xcite was applied to check whether the de - trended distribution belongs to the class of alpha - stable ones .",
    "the process rapidly converges to the following parameters : the characteristic exponent @xmath136 , the skewness @xmath137 , the scale parameter @xmath138 and the location @xmath139 .",
    "thus , one can assume to a good approximation that ( up to the correlated nature of the noise ) the situation belongs to the class described above : the practically symmetric lvy noise .",
    "the nonzero location parameter appears due to inconsistencies in determination of the shift parameter by the usual least square approach as discussed below .",
    "the estimates for @xmath5 and @xmath6 given by the least mean square ( lms ) regression and by the scale parameter regression ( spr ) are @xmath140 and @xmath141 respectively .",
    "the results of the quantile regression ( qr ) for different quantiles are given in table [ intrqv ] .",
    ".the linear fit parameters for different interquantile distances . [ cols=\"^,^\",options=\"header \" , ]     [ outelim ]",
    "the results of this work can be summarized as follows .",
    "we have discussed two methods for the robust linear fit to noisy signals , which can be applied to the case when the lower moments for the noise probability distribution diverge , e.g. for lvy noises . both are based on the idea that the width of the distribution of the residues is the smallest when the slope of the regression line is chosen correctly , and differ in how this width is defined .",
    "the first method is the quantile regression approach .",
    "the second method deals with its counterpart in frequency domain , i.e. with the maximization of the trial characteristic function .",
    "both approaches demonstrate their robustness and high accuracy for the noise distributions with extremely large outliers and may be used for a wide range of applications , for which such a behavior is characteristic , e.g. in problems of plasma dynamics , econophysics , etc . as a practical test",
    "we apply the methods to the data of the geomagnetic field measurements by a detector placed on an antarctic ice shelf , showing large irregularity , and compare their performance to the one of standard approaches . in this case",
    "the scale parameter regression seems to perform the best .",
    "we gratefully thank dr . n.w .",
    "watkins ( lse ) for suggesting the geomagnetic data example and dr .",
    "freeman ( british antarctic survey ) for kindly providing the experimental data from halley , antarctica .    this work is partially supported by grant no .",
    "1391 of the ministry of education and science of the russian federation within the basic part of research funding no .",
    "2014/349 assigned to kursk state university and by dfg ( project so 307/4 - 1 ) .",
    "peng , s.  v. buldyrev , s.  havlin , m.  simons , h.  e. stanley , a.  l. goldberger , mosaic organization of dna nucleotides , phys .",
    "e 49 ( 1994 ) 16851689 . http://dx.doi.org/10.1103/physreve.49.1685 [ ] .",
    "c.  a. cantrell , technical note : review of methods for linear least - squares fitting of data and application to atmospheric chemistry problems , atmos .",
    "( 2008 ) 54775487 .",
    "http://dx.doi.org/10.5194/acp-8-5477-2008 [ ] .",
    "d.  grech , z.  mazur , on the scaling ranges of detrended fluctuation analysis for long - term memory correlated short series of data , physica a 392  ( 10 ) ( 2013 ) 23842397 .",
    "http://dx.doi.org/10.1016/j.physa.2013.01.049 [ ] .",
    "j.  m. chambers , c.  l. mallows , b.  w. stuck , a method for simulating stable random variables , journal of the american statistical association 71 ( 1976 ) 340344 .",
    "http://dx.doi.org/10.1080/01621459.1976.10480344 [ ] .",
    "a.  weron , r.  weron , computer simulation of lvy @xmath0-stable variables and processes , in : p.  garbaczewski , m.  wolf , a.  weron ( eds . ) , chaos the interplay between stochastic and deterministic behaviour , vol .",
    "457 of lecture notes in physics , springer berlin heidelberg , 1995 , pp . 379392 .",
    "r.  w. clarke , m.  p. freeman , n.  w. watkins , application of computational mechanics to the analysis of natural data : an example in geomagnetism , phys .",
    "e 67 ( 2003 ) 016203 . http://dx.doi.org/10.1103/physreve.67.016203 [ ] ."
  ],
  "abstract_text": [
    "<S> we consider the problem of linear fitting of noisy data in the case of broad ( say @xmath0-stable ) distributions of random impacts ( `` noise '' ) , which can lack even the first moment . </S>",
    "<S> this situation , common in statistical physics of small systems , in earth sciences , in network science or in econophysics , does not allow for application of conventional gaussian maximum - likelihood estimators resulting in usual least - squares fits . </S>",
    "<S> such fits lead to large deviations of fitted parameters from their true values due to the presence of outliers . </S>",
    "<S> the approaches discussed here aim onto the minimization of the width of the distribution of residua . </S>",
    "<S> the corresponding width of the distribution can either be defined via the interquantile distance of the corresponding distributions or via the scale parameter in its characteristic function . </S>",
    "<S> the methods provide the robust regression even in the case of short samples with large outliers , and are equivalent to the normal least squares fit for the gaussian noises . </S>",
    "<S> our discussion is illustrated by numerical examples .    </S>",
    "<S> _ * highlights : * _    * correct estimating of the linear fit parameters in a presence of large outliers * the median of the empirical distribution of the residues determines line s shift * the minimum of interquantile width determines line s slope ( 1st method ) * the maximum of characteristic function s residues determines line s slope ( 2nd method )    lvy noise , data processing , linear fit </S>"
  ]
}