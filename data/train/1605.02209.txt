{
  "article_text": [
    "true to `` stigler s law of eponymy '' ( stigler , 1980 ) , simpson s paradox has a long history in statistics going back to yule s ( 1903 ) ` spurious ' association , but it is currently credited to simpson ( 1951 ) for reframing it as a ` paradox ' ; see blyth ( 1972 ) .    the paradox seems to have a number of alternative conceptions , and thus , it is often described interchangeably as a counter - intuitive statistical result pertaining to :    \\(a ) statistical associations that reverse themselves , such as `` a marginal association can have a different direction from each conditional association '' ( agresti , 2013 ) .",
    "\\(b ) either the magnitude or the direction of an association between two variables is influenced by a third variable , such as \" the association between a pair of variables @xmath0 reverses sign upon conditioning on a third variable , @xmath1 .",
    "( pearl , 2014 ) .",
    "\\(c ) apparent statistical associations that after closer scrutiny of the data are rendered ` spurious ' ( yule , 1903 ) .",
    "the recent discussions in statistics have focused on adopting one of the perspectives ( a)-(c ) , and using actual or hypothetical data to either explain away the paradox or criticize other proposed ` solutions ' .",
    "the current dominating view revolves around perspective ( b ) that differs from ( a ) in so far as it emphasizes the causal dimension of conditioning on a confounder ; see pearl ( 2009 ) , spirtes et al .",
    "armistead ( 2014 ) put forward a dissenting view by arguing that perspective ( b ) is rather narrow to explain the different facets of the paradox :    a strong case can be made that simpson s paradox has different dimensions that are often conflated or ignored in the literature .",
    "as argued by wasserman ( 2004 ) :    the primary aim of this paper is to shed light on the different conceptions of the paradox by bringing out the similarities and differences between perspectives ( a)-(c ) .",
    "the key is provided by yule s idea of ` spuriousness ' in ( c ) .",
    "beginning with yule ( 1903 ) , the problem of ` fictitious ' associations and ` spurious ' correlations was a recurring theme in yules papers that culminated in yule ( 1926 ) on `` nonsense - correlations '' .",
    "although he shed some light on the issues involved , he did not succeed in establishing a direct link between spurious associations and invalid probabilistic assumptions for reasons to be discussed in the sequel .",
    "the notion of statistical misspecification can be used to formalize the term ` spurious ' as ` statistically untrustworthy ' results , stemming from unreliable inference procedures .",
    "this enables one to delineate between two distinct cases of association reversal :    case 1 .",
    "the reversal is statistically trustworthy due to statistical adequacy .",
    "the reversal is statistically untrustworthy due to statistical misspecification .",
    "it turns out that the statistical misspecification perspective suggests that in both cases there is nothing counterintuitive to explain .    in section 2",
    ", we discuss the case where the reversal is statistically trustworthy due to the fact that the statistical models involved are _ statistically adequate _ : the invoked probabilistic assumptions are valid for the particular data . when this is not the case , the inference results are likely to be statistically untrustworthy ( spurious ) .",
    "this is discussed in section 3 using two empirical examples that bring out the distinction between statistical and substantive misspecification .",
    "the statistical misspecification argument is illustrated further in section 4 using several widely discussed examples of the paradox . in section 5",
    ", we revisit the causal ` resolution ' of the paradox in an attempt to delineate the modeling and inference issues raised by the statistical misspecification perspective .",
    "consider the case of a linear regression ( lr ) model:@xmath2{c}y_{t}\\mathit{=}\\beta_{0}+\\beta_{1}x_{1t}+\\beta_{2}x_{2t}\\mathit{+}u_{t},\\medskip\\\\ ( u_{t}\\mathit{\\mid}x_{1t}\\mathit{=}x_{1t},x_{2t}\\mathit{=}x_{2t})\\mathit{\\backsim}\\text{\\textsf{niid}}(0,\\sigma_{u}^{2}),\\ t\\mathit{\\in } \\mathbb{n } , \\end{array } \\vspace*{-0.07in}\\label{rm1}\\ ] ] where ` niid ' stands for ` normal , independent and identically distributed ' .",
    "it is often insufficiently appreciated that the error assumptions imply a particular statistical parameterization for the unknown parameters @xmath3 in terms of the moments of the observable process @xmath4 underlying data @xmath5 ( see appendix ) .",
    "alternatively , one can derive the parameterization directly using the joint distribution of the observable random variables involved:@xmath2{c}\\left ( \\begin{array } [ c]{c}y_{t}\\\\ x_{1t}\\\\ x_{2t}\\end{array } \\right )   \\backsim\\text { \\textsf{niid}}\\left (   \\left ( \\begin{array } [ c]{c}\\mu_{1}\\\\ \\mu_{2}\\\\ \\mu_{3}\\end{array } \\right )   , \\left ( \\begin{array } [ c]{ccc}\\sigma_{11 } & \\sigma_{12 } & \\sigma_{13}\\\\ \\sigma_{12 } & \\sigma_{22 } & \\sigma_{23}\\\\ \\sigma_{13 } & \\sigma_{23 } & \\sigma_{33}\\end{array } \\right )   \\right ) \\end{array } \\vspace*{-0.1in}\\label{j}\\ ] ] in this case , the regression and skedastic functions take the form:@xmath2{c}e(y_{t}\\mathit{\\mid}x_{1t}\\mathit{=}x_{1t},x_{2t}\\mathit{=}x_{2t})\\mathit{=}\\beta_{0}\\mathit{+}\\beta_{1}x_{1t}\\mathit{+}\\beta_{2}x_{2t},\\ var(y_{t}\\mathit{\\mid}x_{1t}\\mathit{=}x_{1t},x_{2t}\\mathit{=}x_{2t})\\mathit{=}\\sigma^{2 } , \\end{array } \\vspace*{-0.1in}\\ ] ] where the parameterizations of @xmath6 are ( table 1):@xmath2{c}\\beta_{0}\\mathit{=}\\mu_{1}\\mathit{-}\\beta_{1}\\mu_{2}\\mathit{-}\\beta_{2}\\mu _ { 3},\\ \\beta_{1}\\mathit{=}\\frac{(\\sigma_{12}\\sigma_{33}-\\sigma_{13}\\sigma _ { 23})}{(\\sigma_{22}\\sigma_{33}-\\sigma_{23}^{2})},\\ \\beta_{2}\\mathit{=}\\frac{(\\sigma_{13}\\sigma_{22}-\\sigma_{12}\\sigma_{23})}{(\\sigma_{22}\\sigma _ { 33}-\\sigma_{23}^{2})}\\end{array } \\vspace*{-0.1in}\\label{b}\\]]@xmath2{cl}\\sigma_{u}^{2 } & \\mathit{=}\\sigma_{11}\\mathit{-}\\sigma_{12}\\left ( \\frac{\\sigma_{12}\\sigma_{33}-\\sigma_{13}\\sigma_{23}}{\\sigma_{22}\\sigma _ { 33}-\\sigma_{23}^{2}}\\right )   \\mathit{-}\\sigma_{13}\\left (   \\frac{\\sigma _ { 13}\\sigma_{22}-\\sigma_{12}\\sigma_{23}}{\\sigma_{22}\\sigma_{33}-\\sigma _ { 23}^{2}}\\right )   \\mathit{=}\\sigma_{11}\\mathit{-}\\sigma_{12}\\beta _ { 1}\\mathit{-}\\sigma_{13}\\beta_{2}\\end{array } \\label{s}\\ ] ] these results offer the key to elucidating perspectives ( a)-(b ) on simpson s paradox .    *",
    "perspective ( a ) on simpson s paradox*. the correlation between @xmath7 and @xmath8@xmath9__@xmath10__@xmath11 is positive ( @xmath12 ) , but the coefficient @xmath13 in ( [ rm1 ] ) is negative ( @xmath14 ) .    * is this reversal of association possible , and under what circumstances ? *    in light of the parameterization of @xmath13 in ( [ b ] ) , its numerator is negative when:@xmath15@xmath2{c}\\left [   ( \\sigma_{12}\\sigma_{33}\\mathit{-}\\sigma_{13}\\sigma_{23})<0\\right ] \\rightarrow\\left [   \\frac{\\sigma_{13}\\sigma_{23}}{\\sigma_{33}}>\\sigma _ { 12}\\right ] \\end{array } \\vspace*{-0.07in}\\ ] ] multiplying both terms in the last expression by @xmath16 yields:@xmath15 @xmath2{c}\\frac{\\sigma_{13}\\sigma_{23}}{\\sigma_{33}\\sqrt{\\sigma_{11}\\sigma_{22}}}\\mathit{=}\\rho_{13}\\rho_{23}>\\rho_{12}\\mathit{=}\\frac{\\sigma_{12}}{\\sqrt{\\sigma_{11}\\sigma_{22 } } } , \\end{array } \\vspace*{-0.05in}\\ ] ] where @xmath17__@xmath10__@xmath18 and @xmath19__@xmath10__@xmath20 .",
    "hence , @xmath12 and @xmath14 occur when the following conditions hold :    \\(i ) the correlation coefficients @xmath21 and @xmath22 have the _ same sign _ ,    \\(ii ) the product of @xmath21 and @xmath22 is greater than @xmath23 , i.e.  @xmath24 and    \\(iii ) the determinant of the correlation matrix of @xmath25 is positive:@xmath15@xmath2{c}corr(\\mathbf{z}_{t})\\mathit{=}1\\mathit{-}\\rho_{12}^{2}\\mathit{-}\\rho_{13}^{2}\\mathit{-}\\rho_{23}^{2}\\mathit{+}2\\rho_{12}\\rho_{13}\\rho_{23}\\mathit{>}0 . \\end{array } \\vspace*{-0.07in}\\ ] ] condition ( iii ) ensures that @xmath26 in ( [ j ] ) is proper , giving rise to a well - defined conditional distribution @xmath27 ; see spanos and mcguirk ( 2002 ) .",
    "assuming @xmath28 without any loss of generality , let the relevant correlations be : @xmath29 which satisfy ( i)-(iii ) above .",
    "\\(a ) for values @xmath30 : @xmath31    \\(b ) for values @xmath32 : @xmath33    note that the sign of @xmath34 reflects the common sign of @xmath35 in light of these results , it is clear that there is nothing paradoxical , or surprising , about the reversal of sign between the simple correlation @xmath12 [ stemming from the joint distribution @xmath36 , and the regression coefficient @xmath14 [ stemming from the conditional distribution @xmath37 .",
    "this reversal is due to the conditions ( i)-(iii ) above , which are easily testable in practice ; see spanos ( 2006b ) .",
    "it is well - known that there is a direct connection between @xmath38 and the regression coefficient of @xmath39 in the context of the simple linear regression:@xmath2{c}y_{t}\\mathit{=}\\alpha_{0}\\mathit{+}\\alpha_{1}x_{1t}+\\varepsilon_{t},\\medskip\\\\ ( \\varepsilon_{t}\\mathit{\\mid}x_{1t}\\mathit{=}x_{1t})\\mathit{\\backsim } \\text{\\textsf{niid}}(0,\\sigma_{\\varepsilon}^{2}),\\ t\\mathit{\\in}\\mathbb{n } , \\end{array } \\vspace*{-0.08in}\\label{rm2}\\ ] ] whose implicit statistical parameterization of @xmath40 is:@xmath2{c}\\alpha_{0}\\mathit{=}\\mu_{1}\\mathit{-}\\alpha_{1}\\mu_{2},\\ \\alpha_{1}\\mathit{=}\\frac{\\sigma_{12}}{\\sigma_{22}},\\ \\sigma_{\\varepsilon}^{2}\\mathit{=}\\sigma_{11}\\mathit{-}\\frac{\\sigma_{12}^{2}}{\\sigma_{22}}. \\end{array } \\vspace*{-0.08in}\\ ] ] this is because @xmath38 is a scaled @xmath41 reparameterization of @xmath42:@xmath2{c}\\rho_{12}\\mathit{=}\\frac{\\sqrt{\\sigma_{22}}}{\\sqrt{\\sigma_{12}}}\\alpha_{1}. \\end{array } \\vspace*{-0.12in}\\label{cr}\\ ] ] in the above numerical example , @xmath43 and  @xmath44 confirming the sign reversal .",
    "this implies that one can consider the question of association reversal by comparing the inference results in ( [ rm1 ] ) and ( [ rm2 ] ) .    in conclusion",
    ", it is very important to emphasize that in the above example , both lr models , ( [ rm1 ] ) and ( [ rm2 ] ) , are assumed to be statistically adequate : their probabilistic assumptions are valid . in the case of real data on @xmath45 , one needs to establish the statistical adequacy of both models using comprehensive misspecification testing .",
    "what are the probabilistic assumptions that need to hold for data @xmath5 ?",
    "in this section we bring out more explicitly the probabilistic assumptions comprising the linear regression ( lr ) model with a view to illustrate the role of statistical misspecification in shedding light on the various aspects of simpson s paradox .",
    "traditionally , the probabilistic assumptions underlying the linear regression ( lr ) model are specified in terms of the error term ; see appendix .",
    "it turns out , however , that such specifications are often incomplete and sometimes include non - testable assumptions .",
    "table 1 specifies the lr , generically defined by : in terms of the statistical generating mechanism ( gm ) and assumptions [ 1]-[5 ] that constitute a complete , internally consistent and testable set of assumptions in terms of the observable process @xmath46 underlying the data  @xmath47 .",
    "this provides a purely probabilistic construal for the notion of a statistical model , viewed as a particular parameterization of the process @xmath46 .",
    "intuitively , the statistical model comprises the totality of probabilistic assumptions one imposes on the process @xmath48 with a view to render data @xmath5 a ` typical ' realization thereof .",
    "the ` typicality ' is testable using thorough misspecification testing ; see spanos ( 2006a).@xmath49@xmath50{l}\\hline\\begin{tabular } [ c]{l}\\textbf{table 1 : linear regression model}\\end{tabular } \\\\\\hline\\hline $ \\overset{\\qquad}{\\begin{tabular } [ c]{ll}statistical gm : & $ y_{t}\\mathit{=}\\beta_{0}+\\mathbf{\\beta}_{1}^{\\top } \\mathbf{x}_{t}+u_{t},\\ t\\mathbf{\\mathit{\\in}}\\mathbb{n}$. \\end{tabular } } $ \\\\ $ \\underset{\\qquad}{\\left .",
    "\\begin{tabular } [ c]{lll}\\lbrack1 ] & normality : & $ \\left (   y_{t}\\mathbf{\\mid",
    "x}_{t}\\mathit{=}\\mathbf{x}_{t}\\right )   \\backsim\\mathsf{n}(.,.),$\\\\ \\lbrack2 ] & linearity : & $ e\\left (   y_{t}\\mathbf{\\mid x}_{t}\\mathit{=}\\mathbf{x}_{t}\\right )   \\mathit{=}\\beta_{0}+\\mathbf{\\beta}_{1}^{\\top}\\mathbf{x}_{t } , $ \\\\",
    "\\lbrack3 ] & homoskedasticity : & $ var\\left (   y_{t}\\mathbf{\\mid x}_{t}\\mathit{=}\\mathbf{x}_{t}\\right )   \\mathit{=}\\sigma^{2},$\\\\ \\lbrack4 ] & independence : & $ \\{\\left (   y_{t}\\mathbf{\\mid x}_{t}\\mathit{=}\\mathbf{x}_{t}\\right )   , \\",
    "t\\mathbf{\\mathit{\\in}}\\mathbb{n}\\}$ indep .",
    "process$,$\\\\ \\lbrack5 ] & t - invariance : &",
    "$ \\left (   \\beta_{0},\\mathbf{\\beta}_{1},\\sigma ^{2}\\right )   $ are \\textit{not } changing with $ t,$\\\\ \\multicolumn{3}{l}{$\\ \\ \\ \\ \\ \\",
    "\\beta_{0}\\mathit{=}e(y_{t})\\mathit{-}\\mathbf{\\beta}_{1}^{\\top}e(\\mathbf{x}_{t}),\\ \\mathbf{\\beta}_{1}\\mathit{=}[cov(\\mathbf{x}_{t})]^{-1}cov(\\mathbf{x}_{t},y_{t}),\\ $ } \\\\ & \\multicolumn{2}{l}{$\\sigma^{2}\\mathit{=}var(y_{t})\\mathit{-}cov(\\mathbf{x}_{t},y_{t})^{\\top}[cov(\\mathbf{x}_{t})]^{-1}cov(\\mathbf{x}_{t},y_{t})$}\\end{tabular } \\right\\ }   \\ t\\mathbf{\\mathit{\\in}}\\mathbb{n}.}$\\\\\\hline \\end{tabular}\\ ] ]    * statistical adequacy*. an estimated lr model is said to be _ statistically adequate _ when all assumptions [ 1]-[5 ] are valid for data @xmath51 in practice , statistical adequacy can be appraised using comprehensive misspecification testing ; see spanos ( 1999 , 2015 ) .",
    "the importance of establishing statistical adequacy stems from the fact that it secures the statistical reliability of inference based on such a model .",
    "that is , the inference propositions associated with the lr model , including the optimal properties of the mle estimators and the relevant error probabilities of the t and f tests , are reliable in the sense that their actual sampling distributions approximate closely the theoretical ones derived by invoking the validity of assumptions [ 1]-[5 ] .",
    "* unreliability of inference*. when any subset of the assumptions [ 1]-[5 ] are invalid , the reliability of inference of such procedures is called into question .",
    "statistical misspecifications are likely to give rise to inconsistent estimators as well as induce sizeable discrepancies between the nominal ( assumed ) error probabilities and the actual ones in testing . for instance , when any of the assumptions [ 2 ] , [ 4]-[5 ] are invalid , the ols estimators of @xmath52 are likely to be inconsistent , and the nominal error probabilities associated with the significance t - tests for the coefficients @xmath53 are likely to have significant discrepancies from the actual error probabilities ; see spanos and mcguirk ( 2001 ) , spanos ( 2010 ) .",
    "applying a @xmath54 significance level t - test when the actual type i error is closer to @xmath55 is likely to give rise to unreliable inferences .",
    "it is important to emphasize that for assumptions [ 4 ] and [ 5 ] to be testable , one needs to select an ordering of interest for data @xmath5 . in the case of time - series data ,",
    "the ordering of interest is invariably ` time ' , which is an interval scale variable . for cross - section data , however ,",
    "there are often several orderings of interest , depending on the individual unit being observed , and the modeler needs to think about such potential orderings as they relate to [ 4]-[5 ] .",
    "potential orderings for cross - section can vary from gender ( nominal scale ) , to age ( ratio scale ) , etc .",
    "let us return to example 1 , where the problem of association reversal can be viewed in the context of comparing the regression coefficients of @xmath56 @xmath42 and @xmath57 in the context of two linear regression models:@xmath58@xmath59{ll}model 1 : & $ y_{t}\\mathit{=}\\beta_{0}+\\beta_{1}x_{1t}+\\beta_{2}x_{2t}\\mathit{+}u_{t},\\ ( u_{t}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathit{\\backsim}\\text{\\textsf{niid}}(0,\\sigma_{u}^{2}),\\ t\\mathit{\\in } \\mathbb{n},\\medskip$\\\\ model 2 : & $ y_{t}\\mathit{=}\\alpha_{0}\\mathit{+}\\alpha_{1}x_{1t}+\\varepsilon _ { t},\\ ( \\varepsilon_{t}\\mathit{\\mid}x_{1t}\\mathit{=}x_{1t})\\mathit{\\backsim } \\text{\\textsf{niid}}(0,\\sigma_{\\varepsilon}^{2}),\\ t\\mathit{\\in}\\mathbb{n},$\\end{tabular } \\vspace*{-0.08in}\\ ] ] where @xmath60 in the previous section , it was argued that when both models are statistically adequate , it could happen that the estimated coefficients @xmath42 and @xmath13 differ in both sign and magnitude . there is , however , a sizeable literature on ` omitted variables ' which would call model 2 misspecified when @xmath61 turns out to be statistically significant ; see greene ( 2011 ) . in what sense is model 2 misspecified if its assumptions [ 1]-[5 ] ( table 1 ) are valid ?",
    "similarly , the literature on causal modeling would test the significance of the covariances @xmath62 and @xmath63 as they relate to the regression coefficients , to decide whether @xmath64 is a confounder ; see pearl ( 2011 ) .",
    "how does this relate to the statistical misspecification perspective ?    a closer look at the literature suggests that statistical misspecification is often conflated with substantive misspecification , using confusing and confused claims , such as the ols estimator of @xmath42 in model 2 is an inconsistent estimator of @xmath13 in model 1 ( greene , 2011 ) , ignoring the fact that the two coefficients represent very different parameterizations:@xmath65    to make any sense of such comparisons , one needs to distinguish between _ statistical _ and _ substantive adequacy _ because the former requires only that assumptions [ 1]-[5 ] are valid for @xmath5 .",
    "assumptions [ 1]-[5 ] have nothing to do with : the lr model includes all ` substantively ' relevant variables .",
    "the latter is a substantive assumption that pertains to the explanatory potential of the estimated model as it relates to the phenomenon of interest .",
    "substantive inadequacy can arise from missing but relevant variables , false causal claims , etc .",
    "the crucial importance of this distinction stems from the fact that when models 1 - 2 are statistically misspecified , both the test for an omitted variable , as well as the tests for deciding whether @xmath64 is a confounder , or a mediator , are likely to give rise to untrustworthy results ; see spanos ( 2006b ) .",
    "this distinction is also important when the term ` spurious ' is employed without being qualified to differentiate between _ statistically _ and _ substantively spurious _ inference results .",
    "indeed , the term ` spurious correlation ' is often used to describe the case where the statistical significance of a correlation coefficient is taken at face value , and an attempt is made to explain it away using substantive arguments ; see sober ( 2001 ) . more often than not , however",
    ", one can show that the statistical significance is more apparent than real , because it is just an untrustworthy result stemming from a statistically misspecified model .",
    "the problem of ` spurious ' associations , first noted by pearson ( 1896 ) , was high up in yule s agenda during the first quarter of the 20th century , returning to it on several occasions ; see yule ( 1909 , 1910 , 1921 ) .",
    "yule ( 1926 ) is the culmination of his efforts to unravel the puzzle of ` spurious ' results using the high correlations between time series data as an example .",
    "he used data measuring the ratio of church of england marriages to all marriages ( @xmath66 ) and the mortality rate ( @xmath67 ) over the period 1866 - 1911 , to demonstrate that their estimated correlation @xmath68 was both very high and statistically significant .",
    "he described this result as ` nonsense - correlation ' because  .",
    "he went on to reject any attempt , however ingenious , to rationalize such a statistical result on substantive grounds :    yule ( 1926 ) attempted to articulate the premise that ` nonsense - correlations ' have something to do with the fact that his time series data are _ not _ ` random series ' .",
    "he could not establish a clear and direct link between ` spurious ' associations and statistical misspecification , however , because he was missing two key components that were yet to be integrated into statistics .",
    "the first is the notion of a ` parametric statistical model ' , innovated by fisher ( 1922 ) , and the second is the theory of ` stochastic processes ' founded by kolmogorov ( 1933 ) .",
    "the former comprises all the probabilistic assumptions imposed on the data , and the latter formalizes the notions of a ` random series ' into a realizationn of an iid stochastic proceses ,  as well as departures from it in the form of probabilistic concepts for dependence and heterogeneity .",
    "* yule s reverse engineering*. given that there was no notion of a prespecified parametric statistical model , comprising the probabilistic assumptions imposed on the data , yule resorted to ` reverse engineering ' :    he went on to consider the formula for estimating the sample standard error and elicit the implicit probabilistic assumptions that render it a ` good ' estimator of the distribution standard error .",
    "let us emulate yule s reverse engineering using the sample correlation coefficient , which is the focus of his paper:@xmath58@xmath2{c}\\widehat{corr(x_{t},y_{t})}\\mathit{=}\\frac{\\begin{array } [ c]{c}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(y_{t}-\\overline{y})(x_{t}-\\overline{x } ) \\end{array } \\smallskip}{\\sqrt{\\left [   \\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(x_{t}-\\overline{x})^{2}\\right ]   \\left [   \\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(y_{t}-\\overline{y})^{2}\\right ]   } } , \\medskip\\\\\\begin{array } [ c]{c}\\overline{x}\\mathit{=}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}x_{t},\\ \\overline { y}\\mathit{=}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}y_{t},\\ \\widehat{var(x_{t})}\\mathit{=}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(x_{t}-\\overline{x})^{2},\\medskip\\\\ \\widehat{var(y_{t})}\\mathit{=}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(y_{t}\\mathit{-}\\overline{y})^{2},\\ \\widehat{cov(x_{t},y_{t})}\\mathit{=}\\frac{1}{n}\\sum\\nolimits_{t=1}^{n}(y_{t}\\mathit{-}\\overline{y})(x_{t}\\mathit{-}\\overline{x } ) , \\end{array } \\end{array } \\label{cor}\\ ] ] as a ` good ' estimator of the distribution correlation coefficient:@xmath69@xmath2{c}corr(x_{t},y_{t})\\mathit{=}\\frac{cov(x_{t},y_{t})}{\\sqrt{var(x_{t})var(y_{t})}}\\end{array } \\vspace*{-0.08in}\\ ] ] the first assumption implicit in these formulae is the _ constancy _ of the moments:@xmath2{c}e(y_{t})\\mathit{=}\\mu_{1},\\ e(x_{t})\\mathit{=}\\mu_{2},\\ var(y_{t})\\mathit{=}\\sigma_{11},\\ var(x_{t})\\mathit{=}\\sigma_{22},\\ cov(x_{t},y_{t})\\mathit{=}\\sigma_{12},\\ t\\mathit{\\in}\\mathbb{n } , \\end{array } \\vspace*{-0.08in}\\ ] ] which corresponds to a form of the _ i d assumption_. the formulae for @xmath70 and @xmath71 implicitly assume _ non - correlation _ over @xmath72 , otherwise they should have included covariances over @xmath72 terms .",
    "yule also sought to unveil the implicit distributional assumption the sample moments are not always ` optimal ' estimators of the distribution moments .",
    "for instance , the estimators in ( [ cor ] ) will be ` optimal ' under normality , but they will be non - optimal if the distribution is uniform ; see carlton ( 1946 ) .    in light of the fact that under normality the assumption of i d reduces to the constancy of the first two moments , and non - correlation",
    "coincides with _ independence _ , one could make a case that the implicit parametric statistical model underlying the above formulae is the * *  simple bivariate normal * * in table 2.@xmath59{l}\\hline\\begin{tabular } [ c]{l}\\textbf{table 2 - the simple } ( bivariate)\\textbf{\\ normal model}\\end{tabular } \\medskip\\\\\\hline\\hline $ \\left .",
    "\\begin{tabular } [ c]{lll}\\multicolumn{3}{l}{statistical gm:\\qquad\\qquad$\\mathbf{z}_{t}=\\mathbf{\\mu } + \\mathbf{u}_{t},$}\\\\ \\lbrack1 ] & normal : & $ \\mathbf{z}_{t}\\backsim\\mathsf{n}(.,.),$\\\\ \\lbrack2 ] & constant mean : & $ e(\\mathbf{z}_{t})\\mathit{=}\\mathbf{\\mu},$\\\\ \\lbrack3 ] & constant covariance : & $ var(\\mathbf{z}_{t})\\mathit{=}\\mathbf{\\sigma},$\\\\ \\lbrack4 ] & independence : & $ \\{\\mathbf{z}_{t},\\ t$\\textbf{$\\in$}$\\mathbb{n}\\}$ is independent.\\\\\\hline \\end{tabular } \\right\\ }   \\;t$\\textbf{$\\in$}$\\mathbb{n},$\\end{tabular}\\]]@xmath2{c}\\mathbf{z}_{t}\\mathit{:=}\\left ( \\begin{array } [ c]{c}y_{t}\\\\ x_{t}\\end{array } \\right )   , \\",
    "\\mathbf{\\mu}\\mathit{:=}\\left ( \\begin{array } [ c]{c}\\mu_{1}\\\\ \\mu_{2}\\end{array } \\right )   , \\ \\mathbf{\\sigma}\\mathit{:=}\\left ( \\begin{array } [ c]{cc}\\sigma_{11 } & \\sigma_{12}\\\\ \\sigma_{12 } & \\sigma_{22}\\end{array } \\right ) \\end{array } \\label{bn}\\ ] ]    when any of the assumptions [ 1]-[4 ] are invalid for the particular data @xmath5 , the estimated correlation coefficient is likely to be ` spurious ' ( statistically untrustworthy ) .",
    "granted , certain departures from particular assumptions , such as [ 2]-[4 ] , are more serious than other departures , say from [ 1 ] .",
    "a glance at the t - plots of yule s ( 1926 ) data suggests , to borrow his phrase on p. 5 , that :    ( aka iid).@xmath73{2.7959in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.7959 in ] { .. / .. / .. /swp55/docs - toshiba / o6m4v000.wmf}\\\\\\protect\\begin{tabular } [ c]{l}fig .",
    "1 : t - plot of $ x_{t}$-ratio of church of\\protect\\\\ england marriages to all marriages \\protect\\end{tabular } \\end{center } } } { \\parbox[b]{2.6922in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6922 in ] { .. / .. / .. /swp55/docs - toshiba / o6m4v001.wmf}\\\\\\protect\\begin{tabular } [ c]{l}fig .",
    "2 : t - plot of $ y_{t}$-the mortality rate\\protect\\\\ for the period 1866 - 1911 \\protect\\end{tabular } \\end{center } } } \\ ] ] both data series exhibit clear departures from iid ( fig .",
    "6 ) in the form of mean @xmath74-heterogeneity ( trending mean ) and dependence ( irregular cycles ) . to bring out the cycles in the original data more clearly one needs to subtract the trending means using , say , a generic 3rd degree trend polynomial.@xmath73{2.6714in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6714 in ] { .. / .. / .. /swp55/docs - toshiba / o6of6x00.wmf}\\\\ fig .",
    "3 : t - plot of detrended $ x_t$ \\end{center } } } { \\parbox[b]{2.629in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.629 in ] { .. / .. / .. /swp55/docs - toshiba / o6of6x01.wmf}\\\\ fig .",
    "4 : t - plot of detrended $ y_t$ \\end{center } } } \\ ] ]    in light of the direct relationship between the correlation ( @xmath38 ) and the regression coefficient ( @xmath13 ) in ( [ cr ] ) , one can pose the question of statistical adequacy in the context of the linear regression model , which will yield:@xmath2{c}y_{t}\\mathbf{\\mathit{=}}\\underset{(1.416)}{-10.847}\\mathit{+}\\underset{(.020)}{.419}x_{t}+\\widehat{u}_{t},\\;r^{2}\\mathbf{\\mathit{=}}.905,\\;s\\mathbf{\\mathit{=}}.664,\\;n\\mathbf{\\mathit{=}}46 , \\end{array } \\vspace*{-0.1in}\\label{eq5}\\ ] ] where the standard errors are reported in brackets below the coefficient estimates . both coefficients @xmath52",
    "seem statistically significant since the t - ratios are:@xmath2{cc}\\tau_{0}(\\mathbf{z}_{0})\\mathit{=}\\frac{10.847}{1.416}\\mathit{=}7.660[.000 ] , & \\tau_{1}(\\mathbf{z}_{0})\\mathit{=}\\frac{.419}{.020}\\mathit{=}20.95[.000 ] , \\end{array } \\vspace*{-0.1in}\\ ] ] and the p - values are given in square brackets .",
    "note that the implied correlation ( see ( [ cor ] ) ) yields the value in yule ( 1926 ) : @xmath75 $ ] .    a glance at the t - plot of the residuals ( fig .",
    "5 ) , however , indicates that ( [ eq5 ] ) is statistically misspecified ; assumptions [ 4]-[5 ] are likely to be invalid .",
    "the residual t - plot differs from that of a niid realization ( fig .",
    "6 ) in so far as it exhibits distinct trends and cycles .",
    "these misspecifications are confirmed formally by the statistical significance of the trends and lags in the auxiliary regression based on the residuals ( @xmath76 ) from ( [ eq5]):@xmath2{c}\\widehat{u}_{t}\\mathbf{\\mathit{=}}\\underset{(1.267)}{11.987}\\mathit{-}\\underset{(.016)}{.413}x_{t}\\mathit{-}\\underset{(.998)}{1.670}t\\mathit{-}\\underset{(.216)}{.406}t^{2}\\mathit{+}\\underset{(.076)}{.885}y_{t-1}\\mathit{+}\\underset{(.015)}{.006}x_{t-1}\\end{array } \\label{eq6}\\]]@xmath73{2.7821in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.7821 in ] { .. / .. / .. /swp55/docs - toshiba / o6kgis02.wmf}\\\\ fig .",
    "5 : t - plot of the residuals from ( \\ref{eq5 } ) \\end{center } } } { \\parbox[b]{2.6221in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6221 in ] { .. / .. / .. /swp55/docs - toshiba / o6kgis03.wmf}\\\\ fig . 6 : t - plot of niid data \\end{center } } } \\ ] ] these results suggest that the estimator of @xmath13 is inconsistent _ _ , _ _ and the t - test for its significance is statistically untrustworthy . taking mean deviations from @xmath77 when the actual means are trending ,",
    "will render all the above estimators in ( [ cor ] ) inconsistent .    in light of these departures from the iid assumptions ,  ( [ cor ] ) is an _",
    "inconsistent _ estimator of the correlation coefficient , and thus statistically spurious .",
    "indeed , one can easily show that when the data are de - trended and de - memorized ( subtract the temporal dependence using 2 lags ) to render  ( [ cor ] ) an appropriate estimator , the estimated correlation is : @xmath78,$ ] which is totally statistically insignificant .    in summary",
    ", the notion of statistical adequacy provides a direct and testable link between statistical misspecification and statistically untrustworthy ( spurious ) associations , or inference results more generally .",
    "a likely criticism of this link is that the probability assumptions of the assumed model in ( [ bn ] ) are too strong , in contrast to the current statistical practice favoring as weak a set of assumptions as possible .",
    "the short reply to such a charge is that weaker but non - testable assumptions ( i ) do not render the assumed model less vulnerable to statistical misspecifications , and ( ii ) they underestimate the importance of securing statistical adequacy .",
    "in addition , weak assumptions often rely on asymptotic sampling distributions without testing the validity of the assumptions invoked by limit theorems ; see spanos ( 2015 ) .",
    "the truth of the matter is that the trustworthiness of all inference results will rely exclusively on the approximate validity of the probabilistic assumptions imposed on @xmath79 and nothing else . as argued by le cam ( 1986 , p. xiv ) : @xmath80@xmath80      in this sub - section we consider an empirical example based on cross - section data because statistical adequacy is less well appreciated in such a context .",
    "consider the case where a practitioner wants to evaluate the effect of education on a person s income .",
    "the data refer to education , @xmath66-years of schooling , and income , @xmath67-thousands of dollars , for @xmath81 working people within the age group of 30 - 40 years old selected from a city s population .",
    "the estimated lr model yields:@xmath2{c}y_{t}\\mathbf{\\mathit{=}}\\underset{(1.957)}{53.694}\\mathit{-}\\underset{(.147)}{.474}x_{t}+\\widehat{u}_{t},\\;r^{2}\\mathbf{\\mathit{=}}.096,\\;s\\mathbf{\\mathit{=}}3.307,\\;n\\mathbf{\\mathit{=}}100 . \\end{array } \\vspace*{-0.08in}\\label{eq1}\\ ] ] both coefficients @xmath52 appear to be statistically significant since the t - ratios are:@xmath2{cc}\\tau_{0}(\\mathbf{z}_{0})\\mathit{=}\\frac{53.694}{1.957}\\mathit{=}27.437[.0000 ] , & \\tau_{1}(\\mathbf{z}_{0})\\mathit{=}\\frac{.474}{.147}\\mathit{=}3.224[.001 ] .",
    "\\end{array } \\vspace*{-0.08in}\\ ] ] the practitioner is surprised by the negative sign of the coefficient of @xmath82 since that implies that additional years of education contribute negatively to one s income .",
    "he takes a closer look at the data and decides to run separate linear regressions for men ( @xmath83 ) and women ( @xmath84 ) .",
    "the estimated lr model for men yields : @xmath2{c}y_{1t}\\mathbf{\\mathit{=}}\\underset{(2.236)}{45.229}\\mathit{+}\\underset{(.172)}{.409}x_{1t}+\\widehat{u}_{1t},\\;r^{2}\\mathbf{\\mathit{=}}.973,\\;s\\mathbf{\\mathit{=}}2.371,\\;n_{1}\\mathbf{\\mathit{=}}50 . \\end{array } \\vspace*{-0.1in}\\label{eq2}\\ ] ]    the estimated lr model for women yields:@xmath2{c}y_{2t}\\mathbf{\\mathit{=}}\\underset{(2.937)}{35.106}\\mathit{+}\\underset{(.199)}{.675}x_{2t}+\\widehat{u}_{2t},\\;r^{2}\\mathbf{\\mathit{=}}.193,\\;s\\mathbf{\\mathit{=}}2.124,\\;n_{2}\\mathbf{\\mathit{=}}50 . \\end{array } \\vspace*{-0.1in}\\label{eq3}\\ ] ]    the estimation results in ( [ eq2])-([eq3 ] ) indicate that for both estimated regressions :     the coefficients @xmath52 are statistically significant , and     the sign of the coefficient @xmath57 of education variable @xmath85 , is positive .    the positive sign of the estimated @xmath13 clearly contradicts the negative sign in ( [ eq1 ] ) , which is usually interpreted as a case where a statistical association is reversed .",
    "this is considered as an example of simpson s paradox when viewed from perspective ( b ) , where gender ( @xmath86 ) is viewed as a confounding variable that correlates with both @xmath67-income and @xmath66-education . in econometrics ,",
    "this is usually viewed as a case of ` omitted - variable bias ' ; see greene ( 2011 ) . according to pearl ( 2014 ) , p. 10",
    ", the only way to decide whether to rely on the aggregated data regression in ( [ eq1 ] ) or the disaggregated data regressions ( [ eq2])-([eq3 ] ) is to use causal calculus .",
    "@xmath73{3.039in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=3.039 in ] { .. / .. / .. /swp55/docs - toshiba / o6hx9702.wmf}\\\\ fig . 7 : residuals from equation ( \\ref{eq1 } ) \\end{center } } } \\ ] ]    upon reflection , however , the statistical misspecification perspective provides an alternative way to resolve the paradox on statistical adequacy grounds .",
    "the above estimation and testing results in ( [ eq1])-([eq3 ] ) are trustworthy only when the model assumptions [ 1]-[5 ] are valid for the particular data for each of the three estimated equations . estimating the aggregated data equation ( [ eq1 ] ) using ` gender ' as the ordering of interest , and plotting the residuals ( fig .",
    "7 ) suggests that ( [ eq1 ] ) is _ statistically misspecified _ because the t - plot is far from being normal white - noise .",
    "assumption [ 5 ] is clearly invalid since its sample mean is not constant around zero , but shifts from positive for the first half to negative for the second , and the variance appears smaller for the second half ; see spanos ( 1999 ) , ch .",
    "this form of t - heterogeneity differs from that in yule s data discussed above .",
    "this is confirmed by the auxiliary regression using the residuals ( @xmath76 ) : @xmath2{c}\\widehat{u}_{t}\\mathbf{\\mathit{=}}\\underset{(2.00)}{-15.986}\\mathit{+}\\underset{(.134)}{.967}x_{t}+\\underset{(.616)}{6.556}d_{t},\\;r^{2}\\mathbf{\\mathit{=}}.54,\\;s\\mathbf{\\mathit{=}}2.263,\\;n\\mathbf{\\mathit{=}}100 , \\end{array } \\vspace*{-0.12in}\\ ] ] where @xmath87 , 1-male , 0-female , since its coefficient is statistically significant : @xmath88.$ ]    this suggests that the statistical misspecification perspective provides a very different interpretation of the reversion results and offers an alternative way to resolve the apparent paradox .",
    "first , the key to resolving any seemingly conflicting inference results is not the notion of ` confounding ' ( pearl , 2014 ) , but that of statistical adequacy",
    ". before one can talk about any form of reversal of a statistical association , one needs to establish that all the associations involved are statistically trustworthy .",
    "any claim that there is a ` reversal of association ' between equation ( [ eq1 ] ) and ( [ eq2])-([eq3 ] ) is misleading since the aggregated data equation ( [ eq1 ] ) is statistically misspecified .",
    "therefore , the inference that the coefficient of @xmath66 is negative and statistically significant is untrustworthy ; an artifact of imposing invalid probabilistic assumptions on data @xmath89 .",
    "hence , the aggregate data misrepresent the relationship between @xmath67 and @xmath90    @xmath73{2.6221in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6221 in ] { .. / .. / .. /swp55/docs - toshiba / o6plix02.wmf}\\\\ fig . 8 : t - plot of income ( $ y_t)$ \\end{center } } } { \\parbox[b]{2.6221in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6221 in ] { .. / .. / .. /swp55/docs - toshiba / o6plix03.wmf}\\\\ fig .",
    "9 : t - plot of education ( $ x_t)$ \\end{center } } } \\ ] ]    second , the diagnosis that the variable ` gender ' , represented by @xmath86 is a missing ` confounder ' seems rather misleading for two reasons .",
    "the information pertaining to the ordering(s ) of potential interest is already in the original data @xmath89 ( see figures 8 - 9 ) .",
    "in addition , defining the confounder as an omitted variable @xmath1 which is related to the included variables @xmath91 and @xmath92 in the right way , requires that @xmath1 is stochastic variable , not a deterministic ordering . for statistical inference purposes , the inclusion of generic terms such as shifts in the mean , trends and lags in the estimated equation could , in certain cases , secure statistical adequacy , without having to resort to finding additional explanatory variables .    in the case of ( [ eq1 ] ) , a more pertinent explanation is that the modeler neglected , or chose to ignore , the heterogeneity in the data by assuming constant mean and variance ( i d ) for both data series with respect to the ordering , _",
    "gender_. such forms of misspecification pertain to statistical information contained in the data , which could be generically modeled using shift functions or / and trend polynomials in @xmath74 or / and lags , respectively ; see spanos ( 1999 ) .    in the case of example 3 , one could attempt to respecify the original equation in ( [ eq1 ] ) by including the dummy variable ( @xmath86):@xmath2{c}y_{t}\\mathbf{\\mathit{=}}\\underset{(2.00)}{37.639+}\\underset{(.616)}{6.556}d_{t}+\\underset{(.134)}{.501}x_{t}+\\widehat{u}_{t},\\;r^{2}\\mathbf{\\mathit{=}}.58,\\;s\\mathbf{\\mathit{=}}2.272,\\;n\\mathbf{\\mathit{=}}100 .",
    "\\end{array } \\vspace*{-0.08in}\\label{eq4}\\ ] ] as it stands , the coefficient of @xmath66 represents an misleading weighted average of the two coefficients from the disaggregated data in ( [ eq2])-([eq3 ] ) . the residuals from this equation ( fig .",
    "10 ) do not indicate any major departures from assumptions [ 1]-[5 ] , but in practice one needs to apply thorough misspecification testing to confirm or deny such a claim .",
    "for instance , one needs to test that the variances of the residuals in the two sub - samples are equal ; see spanos ( 1986 ) , p. 481 - 3 .    finally and most importantly , using the statistical misspecification perspective",
    ", one can distinguish clearly between example 1 ( section 2 ) , and examples 2 and 3 above .",
    "the key difference is that in example 1 both lr models ( [ rm1 ] ) and ( [ rm2 ] ) are statistically adequate .",
    "in contrast , in example 3 the estimated lr model ( [ eq1 ] ) based on aggregated data , is statistically misspecified which renders the estimated coefficients and t - tests statistically untrustworthy .",
    "hence , there was never a statistically trustworthy result at the aggregate level that gave rise to a reversal of associations .",
    "in example 3 , only the disaggregated data give rise to statistically reliable inferences .",
    "this calls seriously into question the conventional wisdom that these two cases as identical , as stated by samuels ( 1993 ) , p. 87 :    @xmath73{3.039in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=3.039 in ] { .. / .. / .. /swp55/docs - toshiba / o6lwna00.wmf}\\\\ fig . 10 : residuals from equation ( \\ref{eq4 } ) \\end{center } } } \\ ] ]    in concluding this section , it is important to emphasize that the statistical misspecification perspective requires one to know the complete set of probabilistic assumptions imposed on the data , i.e. the statistical model .",
    "more often than not , practitioners have an incomplete picture of the statistical model , they rarely test its assumptions , and thus the ensuing inference results are often untrustworthy . hence , in evaluating published empirical papers , it is sometimes useful to employ yule s reverse engineering to uncover the statistical model .",
    "in this section we will revisit two cross - section data sets that have been widely discussed in the statistics literature , using the statistical misspecification perspective .",
    "bickel et al . ( 1975 ) published an influential paper in _ science _",
    ", where they illustrated simpson s paradox using cross - section data based on uc berkeley admissions , for the fall of 1973 .",
    "their perspective relates to perspective ( a ) and pertains to the reversal of a statistical relationship between the aggregated data , at the university level , and the disaggregated data , at the department level .",
    "the aggregate data are shown in table 3 and the data for the largest 5 departments , denoted by a - f , are given in table 4 ;    see .",
    "the estimated parameter @xmath93 based on the aggregate data ( table 3 ) indicates that the rate of admissions for female candidates ( @xmath94 ) is smaller that for male candidates ( @xmath95 ) , and a test for the difference indicated a statistically significant difference ; see bickel et al .",
    "( 1975 ) . at the department level",
    ", however , the admissions rate for females is greater than that of males in five out of the six departments shown in table 4 .",
    "this is interpreted as an apparent reversal of the inference based on the aggregate data .",
    "the statistical misspecification perspective , however , suggests that the estimated admissions rate using the aggregated  data is statistically untrustworthy .",
    "let us unpack this claim.@xmath59{c}\\hline\\begin{tabular } [ c]{l}\\textbf{table 3 : } admissions aggregate data \\end{tabular } \\medskip\\\\\\hline\\hline\\begin{tabular } [ c]{|l||ll||r|}\\hline & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 3738 $ & $ 1494 $ & $ 5232$\\\\\\hline deny & $ 4704 $ & $ 2827 $ & $ 7531$\\\\\\hline\\hline total & $ 8442 $ & $ 4321 $ & $ 12763$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{m}\\mathit{=}\\frac{3738}{8442}\\mathit{=}.44,\\ \\widehat{\\theta } _ { f}\\mathit{=}\\frac{1494}{4321}\\mathit{=}.35 \\end{array } $ } \\\\\\hline \\end{tabular } \\end{tabular}\\ ] ] @xmath59{ll}\\hline \\multicolumn{2}{c}{\\begin{tabular } [ c]{l}\\textbf{table 4 : admissions disaggregated data for departments a - f}\\end{tabular } \\medskip}\\\\\\hline\\hline $ \\begin{tabular } [ c]{|l||ll||r|}\\hline \\fbox{\\begin{tabular } [ c]{l}a \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 512 $ & $ 89 $ & $ 601$\\\\\\hline deny & $ 313 $ & $ 19 $ & $ 332$\\\\\\hline\\hline total & $ 825 $ & $ 108 $ & 933\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{am}\\mathit{=}\\frac{512}{825}\\mathit{=}.62,\\ \\widehat{\\theta } _ { af}\\mathit{=}\\frac{89}{108}\\mathit{=}.82 \\end{array } $ } \\\\\\hline \\end{tabular } $ & $ \\begin{tabular } [ c]{|l||ll||r|}\\hline \\fbox{\\begin{tabular } [ c]{l}b \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 353 $ & $ 17 $ & $ 370$\\\\\\hline deny & $ 207 $ & $ 8 $ & $ 215$\\\\\\hline\\hline total & $ 560 $ & $ 25 $ & $ 585$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{bm}\\mathit{=}\\frac{353}{560}\\mathit{=}.63,\\ \\widehat{\\theta } _ { bf}\\mathit{=}\\frac{17}{25}\\mathit{=}.68 \\end{array } $ } \\\\\\hline \\end{tabular } $ \\\\ \\multicolumn{2}{l}{}\\\\",
    "$ \\begin{tabular } [ c]{|l||ll||r|}\\hline \\fbox{\\begin{tabular } [ c]{l}c \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 120 $ & $ 202 $ & $ 322$\\\\\\hline deny & $ 205 $ & $ 391 $ & $ 596$\\\\\\hline\\hline total & $ 325 $ & $ 593 $ & $ 918$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{cm}\\mathit{=}\\frac{120}{325}\\mathit{=}.37,\\ \\widehat{\\theta } _ { cf}\\mathit{=}\\frac{202}{593}\\mathit{=}.34 \\end{array } $ } \\\\\\hline \\end{tabular } $ & $ \\begin{tabular } [ c]{|l||ll||r|}\\hline",
    "\\fbox{\\begin{tabular } [ c]{l}d \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 139 $ & $ 131 $ & $ 270$\\\\\\hline deny & $ 278 $ & $ 244 $ & $ 522$\\\\\\hline\\hline total & $ 417 $ & $ 375 $ & $ 792$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{dm}\\mathit{=}\\frac{139}{417}\\mathit{=}.33,\\",
    "\\widehat{\\theta } _ { df}\\mathit{=}\\frac{131}{375}\\mathit{=}.35 \\end{array } $ } \\\\\\hline \\end{tabular } $ \\\\ \\multicolumn{2}{l}{}\\\\\\cline{2 - 2}$\\begin{tabular } [ c]{|l||ll||r|}\\hline \\fbox{\\begin{tabular } [ c]{l}e \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 53 $ & $ 94 $ & $ 147$\\\\\\hline deny & $ 138 $ & $ 199 $ & $ 337$\\\\\\hline\\hline total & $ 191 $ & $ 293 $ & $ 484$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{em}\\mathit{=}\\frac{53}{191}\\mathit{=}.28,\\ \\widehat{\\theta } _ { ef}\\mathit{=}\\frac{94}{293}\\mathit{=}.32 \\end{array } $ } \\\\\\hline \\end{tabular } $ & \\multicolumn{1}{l|}{$\\begin{tabular } [ c]{|l||ll||r|}\\hline \\fbox{\\begin{tabular } [ c]{l}f \\end{tabular } } & \\textbf{m}$\\text{\\textbf{ales}}$ & \\textbf{f}$\\text{\\textbf{emales}}$ & $ \\text{\\textbf{total}}$\\\\\\hline\\hline admit & $ 22 $ & $ 23 $ & $ 45$\\\\\\hline deny & $ 351 $ & $ 318 $ & $ 669$\\\\\\hline\\hline total & $ 373 $ & $ 341 $ & $ 714$\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{fm}\\mathit{=}\\frac{22}{373}\\mathit{=}.06,\\",
    "\\widehat{\\theta } _ { ff}\\mathit{=}\\frac{23}{341}\\mathit{=}.07 \\end{array } $ } \\\\\\hline \\end{tabular } $ } \\end{tabular}\\ ] ]    what is missing from the discussion of the traditional association reversal interpretation is any evidence that the above inferences based on the estimated @xmath96 is trustworthy",
    ". such evidence can be secured by testing the validity of the assumptions invoked by the above inferences , which comprise the underlying statistical model : a _ bivariate _ version of the simple bernoulli model ( table 5 ) , with @xmath96 replaced with a vector of unknown parameters @xmath97 ; see bishop et al .",
    "( 1975 ) .    in relation to the bernoulli model , it is important to point out that @xmath96 is also the mean of process underlying the data , as well as determining the variance , i.e.@xmath15@xmath2{c}e(x_{t})\\mathit{=}\\theta,\\ var(x_{t})\\mathit{=}\\theta(1\\mathit{-}\\theta),\\ 0\\leq\\theta\\leq1,\\ \\forall t\\mathbf{\\mathit{\\in}}\\mathbb{n}. \\end{array } \\vspace*{-0.07in}\\ ] ] @xmath59{l}\\hline\\begin{tabular } [ c]{l}\\textbf{table 5 - the simple bernoulli model}\\end{tabular } \\medskip\\\\\\hline\\hline $ \\left .",
    "\\begin{tabular } [ c]{lll}\\multicolumn{3}{l}{statistical gm:\\qquad\\qquad$x_{t}=\\theta+u_{t},\\;$}\\\\ \\lbrack1 ] & bernoulli : & $ x_{t}\\backsim\\mathsf{ber}(.,.),$\\\\ \\lbrack2 ] & constant mean : & $ e(x_{t})\\mathit{=}\\theta,$\\\\ \\lbrack3 ] & constant variance : & $ var(x_{t})\\mathit{=}\\theta(1-\\theta),$\\\\ \\lbrack4 ] & independence : & $ \\{x_{t},\\",
    "t$\\textbf{$\\mathit{\\in}$}$\\mathbb{n}\\}$ is independent .",
    "\\end{tabular } \\right\\ }   t$\\textbf{$\\mathit{\\in}$}$\\mathbb{n}$\\\\\\hline \\end{tabular}\\ ] ]    a glance at the estimated @xmath96 for males and females at the department level in table 4 , indicate clearly that the estimated means and variances differ , not only from those based on aggregate data , but also between departments .",
    "this renders assumptions [ 2 ] and [ 3 ] invalid at the aggregate level .",
    "that is , when the data are aggregated the process @xmath98 is no longer identically distributed ( i d ) with respect to the ordering ` gender ' .    in light of this , the association reversal is spurious because the estimated values:@xmath15@xmath2{c}\\widehat{\\theta}_{m}\\mathit{=}\\frac{3738}{8442}\\mathit{=}.44,\\ \\widehat{\\theta } _",
    "{ f}\\mathit{=}\\frac{1494}{4321}\\mathit{=}.35 \\end{array } \\vspace*{-0.07in}\\ ] ] from the aggregated data .",
    "this is because the estimators of @xmath96 using the aggregated data will be _ inconsistent _ estimators of the true @xmath96.@xmath99{2.6645in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.6645 in ] { .. / .. / ..",
    "/swp55/docs - toshiba / o6lwrg03.wmf}\\\\\\protect\\begin{tabular } [ c]{l}fig . 11 : t - plot of $ x_{t}\\backsim$\\textsf{beriid}$(.2,.16)$\\protect\\end{tabular } \\end{center } } } { \\parbox[b]{2.7475in}{\\begin{center } \\includegraphics [ natheight=3.464400 in , natwidth=5.190600 in , height=1.7331 in , width=2.7475 in ] { .. / .. / .. /swp55/docs - toshiba / o6lwrg04.wmf}\\\\\\protect\\begin{tabular } [ c]{l}fig . 12 : t - plot of $ z_{t}\\backsim$\\textsf{beriid}$(.6,.24)$\\protect\\end{tabular } \\end{center } } } \\ ] ]    to see how this arises in practice , consider figures 11 - 12 that represent the t - plots of two bernoulli iid [ ( @xmath100 $ ] processes with @xmath101 and @xmath102 respectively .",
    "as can be seen from these figures , the concentration of longer ` runs ' [ group of successive values of 0 s or 1 s ] switches from the value 0 to the value 1 as @xmath96 increases above @xmath103 .",
    "hence , any attempt to ignore the differences in the two moments of such processes will give rise to a misspecified bernoulli model .",
    "that invalidates any inferences based on the aggregate data , and the only potentially reliable inference can be drawn from the disaggregated data .",
    "the above statistical misspecification perspective can be used to explain the seemingly contradictory results in lindley and novick s ( 1981 ) hypothetical data shown below .",
    "this is a particularly interesting example because , as argued by armistead ( 2014 ) , the ordering of interest might become apparent after the data are collected .",
    "for instance , in a clinical trial the ` gender ' or / and ` age ' ordering(s ) might turn out to be relevant after the data are collected .",
    "the estimated @xmath96 s for the aggregated data in table 6:@xmath104@xmath2{c}\\widehat{\\theta}_{w}\\mathit{=}\\frac{20}{40}\\mathit{=}.5,\\ \\widehat{\\theta}_{b}\\mathit{=}\\frac{16}{40}\\mathit{=}.4 , \\end{array } \\vspace*{-0.07in}\\ ] ] are very different from those based on the disaggregated data ( table 7 ) , rendering the former statistically untrustworthy because it imposes an invalid assumption : the means of the bernoulli process underlying the disaggregated data are constant.@xmath59{l}\\hline\\begin{tabular } [ c]{l}\\textbf{table 6 : lindley - novick}\\\\ \\textbf{\\ \\ \\ \\ aggregated data}\\end{tabular } \\medskip\\\\\\hline\\hline\\begin{tabular } [ c]{|l||ll||r|}\\hline & \\textbf{white } & \\textbf{black } & $ \\text{\\textbf{total}}$\\\\\\hline\\hline high & $ 20 $ & $ 16 $ & $ 36$\\\\\\hline low & $ 20 $ & $ 24 $ & $ 44$\\\\\\hline\\hline total & $ 40 $ & $ 40 $ & $ 80$\\\\\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{w}\\mathit{=}\\frac{20}{40}\\mathit{=}.5,\\ \\widehat{\\theta}_{b}\\mathit{=}\\frac{16}{40}\\mathit{=}.4 \\end{array } $ } \\\\\\hline \\end{tabular } \\end{tabular}\\]]@xmath59{ll}\\hline \\multicolumn{2}{c}{\\begin{tabular } [ c]{l}\\textbf{table 7 : lindley - novick disaggregated data}\\end{tabular } } \\\\\\hline\\hline\\begin{tabular } [ c]{|l||ll||r|}\\hline short & \\textbf{white } & \\textbf{black } & $ \\text{\\textbf{total}}$\\\\\\hline\\hline high & \\multicolumn{1}{||c}{$2 $ } & \\multicolumn{1}{c||}{$9 $ } & \\multicolumn{1}{||c|}{$11$}\\\\\\hline low & \\multicolumn{1}{||c}{$8 $ } & \\multicolumn{1}{c||}{$21 $ } & \\multicolumn{1}{||c|}{$29$}\\\\\\hline\\hline total & \\multicolumn{1}{||c}{$10 $ } & \\multicolumn{1}{c||}{$30 $ } & \\multicolumn{1}{||c|}{$40$}\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{sw}\\mathit{=}\\frac{2}{10}\\mathit{=}.2,\\ \\widehat{\\theta } _ { sb}\\mathit{=}\\frac{9}{30}\\mathit{=}.3 \\end{array } $ } \\\\\\hline \\end{tabular } & \\begin{tabular } [ c]{|l||ll||r|}\\hline tall & \\textbf{white } & \\textbf{black } & $ \\text{\\textbf{total}}$\\\\\\hline\\hline high & \\multicolumn{1}{||c}{$18 $ } & \\multicolumn{1}{c||}{$7 $ } & \\multicolumn{1}{||c|}{$25$}\\\\\\hline low & \\multicolumn{1}{||c}{$12 $ } & \\multicolumn{1}{c||}{$3 $ } & \\multicolumn{1}{||c|}{$15$}\\\\\\hline\\hline total & \\multicolumn{1}{||c}{$30 $ } & \\multicolumn{1}{c||}{$10 $ } & \\multicolumn{1}{||c|}{$40$}\\\\\\hline\\hline \\multicolumn{4}{|l|}{$\\begin{array } [ c]{c}\\widehat{\\theta}_{tw}\\mathit{=}\\frac{18}{30}\\mathit{=}.6,\\ \\widehat{\\theta } _ { tb}\\mathit{=}\\frac{7}{10}\\mathit{=}.7 \\end{array } $ } \\\\\\hline \\end{tabular } \\end{tabular}\\ ] ]",
    "pearl s ( 2014 ) claims that the only way to resolve the paradox is to use causal calculus :    @xmath1@xmath1    viewing examples 2 - 5 from the misspecification perspective , however , lends support to the armistead s ( 2014 ) key argument :    indeed , in cases where the ` third variable ' represents an _ ordering _ of potential interest for the particular data , the only relevant criterion to decide which orderings are relevant for the statistical analysis of the particular data is the _ statistical adequacy _ of the estimated equations .",
    "that is , when two or more alternative orderings are potentially relevant for a particular data set , one needs to test the statistical adequacy of all three equations relative to each of these orderings before one could draw reliable conclusions concerning how to resolve any apparently paradoxical results .",
    "where does this leave the pearl ( 2014 ) claim quoted above ?      cartwright ( 1979 ) rightly points out that reliance on regularities and frequencies for statistical inference purposes is not sufficient for representing substantively meaningful causal relations . on the other hand ,",
    "imposing causal relations that belie the chance regularities in the data would only give rise to untrustworthy inference results . while the causal dimension remains an important component in delineating the issues raised by simpson s paradox , it is not the only relevant , or even the most important , dimension in unraveling the puzzle .",
    "indeed , the suggestion that in cases where the third variable ( ordering of interest ) is noncausal one should accept the results based on the aggregated data ( pearl , 2009 ) , is called into question by examples 2 - 5 .",
    "this is because when the model estimated using the aggregated data is statistically misspecified , the causal inference results pertaining to conditional independence are likely to be untrustworthy .",
    "one way or another , the modeler needs to account for the statistical information not accounted for by the original statistical model , with a view to ensure the trustworthiness of the ensuring statistical results .",
    "it is interesting to note that yule ( 1926 ) considered the third variable causal explanation , but questioned its value as a general ` solution ' to the problem :    a crucial issue that needs to be addressed by the causal explanation is that conditioning on a third variable is not as straightforward as adherents to this ` explanation ' of simpson s paradox would have us believe . in practice",
    ", the question whether a particular variable @xmath105 constitutes a confounder is not just a matter of testing whether @xmath105 relates to @xmath106 and @xmath107 the right way ; see pearl ( 2009 ) , spirtes et al .",
    "before such testing can even begin , one needs to test for the statistical adequacy of the estimated model with respect to a relevant ordering .",
    "although ` time ' is the obvious ordering for time series , it is no different than other deterministic orderings for cross - section data such as ` gender ' , marital status , age , geographical position , etc . ; only the scale of measurement differs .",
    "when the original model is statistically misspecified , it needs to be respecified with a view to secure statistical adequacy .",
    "often one can restore statistical adequacy using generic terms relating to that ordering . to secure substantive adequacy",
    ", however , one needs to replace such generic terms with  proper explanatory random variables without foregoing the statistical adequacy .",
    "the latter ensures the reliability of testing whether @xmath105 is a confounder or not ; see spanos ( 2006b ) .",
    "yule ( 1926 ) considered ` time ' as a third variable and expressed his misgivings :    viewing his comment from the vantage point of today s probabilistic perspective , the proposal to ` condition ' on a third variable raises technical issues , since the conditional distribution , defined by:@xmath15@xmath2{c}f(y_{t}\\mathit{\\mid}x_{t},d_{t};\\mathbf{\\varphi})\\mathit{=}\\frac { f(y_{t}\\mathit{,}x_{t},d_{t};\\mathbf{\\psi})}{f(d_{t};\\mathbf{\\phi})},\\ \\forall y_{t}\\mathit{\\in}\\mathbb{r}_{y } , \\end{array } \\vspace*{-0.07in}\\ ] ] makes no probabilistic sense when @xmath108 is a _ determinist ordering _ ( variable ) such as time ; see williams ( 1991 ) .",
    "this issue arises more clearly in cases where the ordering was deemed potentially important after the data have been collected , such as having plants grow short or tall , blood pressure being high or low , black or white plants , etc . ; see armistead ( 2014 ) .",
    "how does one bridge the gap between a deterministic ordering of interest and conditioning on a third random variable related to that ordering ?    * separating modeling from inference*. the statistical misspecification perspective suggests that to ensure the reliability of inference one needs to separate the initial stages of _ specification _ ( initial model selection ) _ misspecification testing _ and _ respecification _ , from _ inference _ proper .",
    "the latter includes testing for _ substantive adequacy _ , such as attributing causality to statistical associations . in practice",
    ", this requires focusing first on the ordering(s ) of interest that could potentially reveal statistical misspecifications that pertain to dependence and heterogeneity uncovered by misspecification testing .",
    "the next step is to respecify the initial model with a view to account for the statistical information revealed by the misspecification testing .",
    "this is usually achieved by employing _",
    "generic _ terms , such as shifts , trends and lags , to ` capture ' such forms of systematic statistical information .",
    "once statistical adequacy is secured one can then proceed to ` model ' such information by replacing the generic terms with appropriate explanatory variables with a view to improve the _ substantive adequacy _ without forgoing the statistical adequacy .",
    "this is because a third degree trend polynomial might capture the mean heterogeneity in the data to ensure the statistical reliability of inference , but from the substantive perspective it represents ignorance .",
    "replacing the trend polynomial with explanatory variables without forsaking statistical adequacy will add to our understanding of the phenomenon of interest ; see spanos ( 2010 ) .",
    "viewing the problem from a broader perspective , the primary reason for the untrustworthiness is that the question of probing for the nature of any causal connections pertains to _ substantive _ , and not _ statistical adequacy _",
    ", even though the distinction between the two might not always be clear cut or obvious ; see spanos ( 2010 ) .",
    "this distinction is crucial because any attempt to probe for substantive adequacy , including causal connections , before securing statistical adequacy  of the assumed statistical model is likely to give rise to unreliable results . to avoid this problem of unreliable inferences",
    ", one needs to establish the statistical adequacy of the original model first before probing for any form of substantive adequacy , such as attributing a causal interpretation to statistical associations .",
    "these include probing for the appropriateness of a particular confounder or choosing between different potential confounders ; see spanos ( 2006b ) for an extensive discussion .",
    "this distinction is crucial in differentiating between _ statistically _ and _ substantively _ ` spurious ' inferential results .",
    "unfortunately , in the statistics and philosophy of science literatures the term ` spurious ' is often used to describe the latter ; see blyth ( 1972 ) .",
    "what is often insufficiently appreciated is that one needs to establish first that there is a statistically trustworthy statistical association , before attempting to explain it away as substantively spurious .",
    "the statistical misspecification perspective also calls into question certain philosophical discussions of simpson s paradox that focus primarily on the ` numbers ' associated with the relevant probabilities / associations as in the case of example 1 . a typical representation of simpson s paradox in terms of events @xmath109 is:@xmath15@xmath2{c}\\begin{tabular } [ c]{l}$p(a\\mathit{\\mid}b)\\mathit{<}p(a\\mathit{\\mid}\\lnot b),\\text { but}\\medskip$\\\\ $ p(a\\mathit{\\mid}b , c)\\mathit{>}p(a\\mathit{\\mid}\\lnot b , c)$ and$\\medskip$\\\\ $ p(a\\mathit{\\mid}b,\\lnot c)\\mathit{>}p(a\\mathit{\\mid}\\lnot b,\\lnot c),$\\end{tabular } \\end{array } \\vspace*{-0.07in}\\label{ph}\\ ] ] where ` @xmath110 ' denotes the ` negation ' operator .",
    "malinas and bigelow ( 2016 ) illustrate ( [ ph ] ) using made up numbers that satisfy the above inequalities , and describe the source of the paradox as follows :    they proceed to claim that their artificial illustration provides a way to explain an empirical example from cohen and nagel ( 1934 ) concerning death rates in 1910 from tuberculosis in richmond , virginia and new york city .",
    "as argued above , however , in the case of observed data some of the ` numbers ' used in such arguments might be statistically untrustworthy , undermining the soundness of the logical argument in ( [ ph ] ) .",
    "indeed , oversimplifications of the form ( [ ph ] ) , contribute to the perpetuation of the misconceptions beleaguering the paradox .",
    "what is often insufficiently appreciated in statistical modeling and inference is that the inference propositions ( optimal estimators , tests , and predictors and their sampling distributions ) depend crucially on the validity of the probabilistic assumptions one imposes on the data .",
    "the totality of these assumptions comprise the underlying statistical model , which is used to define the distribution of the sample and the likelihood function .",
    "if the statistical model is misspecified , in the sense that any of its assumptions are invalid for the particular data , the reliability of inference based on such a model is usually undermined , giving rise to untrustworthy evidence .",
    "the paper revisited simpson s paradox using the statistical misspecification perspective with a view to shed light on several silent features of the paradox . using this perspective",
    ", it was argued that the key to unraveling the various counterintuitive results associated with this paradox is to formalize the vague notion of ` spurious ' inference results into ` statistically untrustworthy ' results which can be evidenced using misspecification testing .",
    "this enables one to distinguish between two different cases of the paradox as it relates to the reversal of statistical associations .",
    "case 1 , where the reversal is statistically trustworthy because the underlying statistical models are statistically adequate ( example 1 ) .",
    "case 2 , where the apparent reversal is statistically untrustworthy due to statistical misspecification ( examples 2 - 5 ) .",
    "the real issue is whether the inference results pertaining to statistical associations are statistically trustworthy or not , and the key criterion to appraise that is statistical adequacy .",
    "hence , the statistical misspecification perspective puzzles out simpson s paradox because in both cases there is nothing counterintuitive to explain .",
    "the statistical misspecification perspective is also used to revisit the causal dimension of the paradox by distinguishing between statistical and substantive inadequacy ( spuriousness ) . to ensure the reliability of any inferences relating to testing whether a third variable constitutes a confounder , requires that the underlying statistical model is statistically adequate .",
    "this is particularly problematic for the causal resolution of the paradox when the third variable is related to a relevant ordering of interest which is revealed after the data are collected . in such cases one needs to account for any departures from the model assumptions as they relate to the ordering in question , and replace the generic terms used to capture the neglected statistical information with substantively meaningful explanatory variables.@xmath111    99 armistead , t.w .",
    "( 2014 ) , resurrecting the third variable : a critique of pearl s causal analysis of simpson s paradox , _ the american statistician _ , 68 : 1 - 7 .",
    "bickel , p.j .",
    "hammel , and j.w .",
    "oconnell ( 1975 ) , sex bias in graduate admissions : data from berkeley ,  _ science _ , 187 , 398404 .",
    "bishop , y.m .",
    "fienberg , p.w .",
    "holland ( 1975 ) , _ discrete multivariate analysis : theory and practice _ , mit press , cambridge , ma .",
    "blyth , c.r . , ( 1972 ) , on simpson s paradox and the sure thing principle , _ journal of the american statistical association _ , 67 : 364366 .",
    "carlton , a. g. ( 1946 ) , estimating the parameters of a rectangular distribution ,  _ the annals of mathematical statistics _",
    ", * 17 * , 355 - 358 .",
    "cartwright , n. , ( 1979 ) , causal laws and effective strategies , _ nos _ , 13 ( 4 ) : 419437 .",
    "cohen , m. , and nagel , e. ( 1934 ) , _ an introduction to logic and the scientific method _",
    ", new york : harcourt , brace and company .",
    "fisher , r. a. ( 1922 ) , on the mathematical foundations of theoretical statistics , _ philosophical transactions of the royal society a _ , * 222 * : 309 - 368 .",
    "greene , w.h .",
    "( 2011 ) , _ econometric analysis _ , 7th ed .",
    ", new jersey : prentice hall .",
    "kolmogorov ,  a. n. ( 1933 ) , _ foundations of the theory of probability _ , 2nd english edition , chelsea publishing co. ny .    le cam , l. ( 1986 ) , _ asymptotic methods in statistical decision theory _ , springerverlag ,",
    "lindley , d.v . , and m.r .",
    "novick ( 1981 ) , the role of exchangeability in inference , _ journal of the american statistical association _",
    ", 9 : 4558 .",
    "malinas , g. and j. bigelow ( 2016 ) , simpson s paradox , the stanford encyclopedia of philosophy ( summer 2016 edition ) , edward n. zalta ( ed . ) , forthcoming url = @xmath112http://plato.stanford.edu / archives / sum2016/entries / paradox - simpson/@xmath113 .",
    "pearl , j. ( 2009 ) , _ causality : models , reasoning , and inference _",
    "( 2nd ed . ) , cambridge university press , ny .    pearl , j. ( 2011 ) , why there is no statistical test for confounding , why many think there is , and why they are almost right , department of statistics , ucla .",
    "pearl , j. ( 2014 ) , comment : understanding simpson s paradox , _ the american statistician _",
    ", 68(1 ) , 8 - 13 .",
    "pearson , k. ( 1896 ) , mathematical contributions to the theory of evolution  on a form of spurious correlation which may arise when indices are used in the measurement of organs , _ proceedings of the royal society of london _",
    ", 60(359 - 367 ) , 489 - 498 .",
    "samuels , m.l .",
    "( 1993 ) , simpson s paradox and related phenomena , _ journal of the american statistical association _",
    ", 88:421 , 81 - 88 .",
    "simpson , e.h .",
    "( 1951 ) , the interpretation of interaction in contingency tables , _ journal of the royal statistical society_. series b ( methodological ) , 238 - 241 .    sober , e. ( 2001 ) , venetian sea levels , british bread prices , and the principle of the common cause , _ the british journal for the philosophy of science _ , 52 : 331 - 346 .",
    "spanos , a. , ( 1986 ) , _ statistical foundations of econometric modelling _ , cambridge university press , cambridge .",
    "spanos , a. ( 1999 ) , _ introduction to probability theory and statistical inference _ , cambridge university press .",
    "spanos , a. ( 2006a ) , where do statistical models come from ? revisiting the problem of specification ,  pp .",
    "98 - 119 in _ optimality : the second erich l. lehmann symposium _ , edited by j. rojo , lecture notes - monograph series , vol .",
    "49 , institute of mathematical statistics .",
    "spanos , a. ( 2006b ) , revisiting the omitted variables argument : substantive vs. statistical adequacy ,  _ journal of economic methodology _",
    ", 13 : 179 - 218 .",
    "spanos , a. ( 2010 ) , statistical adequacy and the trustworthiness of empirical evidence : statistical vs. substantive information ,  _ economic modelling _",
    ", 27 : 14361452 .",
    "spanos , a. ( 2015 ) , statistical mis - specification testing in retrospect and prospect , working paper , virginia tech .",
    "spanos , a. and a. mcguirk ( 2001 ) , the model specification problem from a probabilistic reduction perspective ,  _ journal of the american agricultural association _ , * 83 * : 1168 - 1176 .",
    "spanos , a. and a. mcguirk ( 2002 ) , the problem of near - multicollinearity revisited : erratic vs. systematic volatility ,  _ journal of econometrics _ , * 108 * : 365 - 393 .    spirtes , p. , c.n .",
    "glymour , r. scheines ( 2000 ) , _ causation , prediction , and search_. mit press , ma .",
    "stigler , s. m. ( 1980 ) , stigler s law of eponymy , _ transactions of the new york academy of sciences _ , 39 : 147 - 157 .",
    "wasserman , l. ( 2004 ) , _ all of statistics : a concise course in statistical inference _ , springer , ny .    williams , d. ( 1991 ) , _ probability with martingales _",
    ", cambridge university press , cambridge .",
    "yule , g.u .",
    "( 1903 ) , notes on the theory of association of attributes in statistics , _ biometrika _ , 2 : 121 - 134 .",
    "yule , g.u .",
    "( 1909 ) , the applications of the method of correlation to social and economic statistics , journal of the royal statistical society , 72 : 721 - 730 .",
    "yule , g. u. ( 1910 ) , on the interpretation of correlations between indices or ratios , _ journal of the royal statistical society _ , 73 : 644 - 647 .",
    "yule , g. u. ( 1921 ) , on the time - correlation problem , with especial reference to the variate - difference correlation method , _ journal of the royal statistical society _ , 84 : 497 - 537 .",
    "yule , g.u .",
    "( 1926 ) , why do we sometimes get nonsense - correlations between time - series ? a study in sampling and the nature of time - series , _ journal of the royal statistical society _ , 89 : 1 - 64 .",
    "the traditional specification of the lr model takes the form:@xmath2{c}y_{t}\\mathit{=}\\beta_{0}+\\mathbf{\\beta}_{1}^{\\top}\\mathbf{x}_{t}\\mathit{+}u_{t},\\medskip\\\\ \\text{\\lbrack i]\\ } e(u_{t}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathit{=}0,\\ \\text{[ii]\\ } e(u_{t}^{2}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathit{=}\\sigma^{2},\\medskip\\\\ \\text{\\lbrack iii ] } e(u_{t}u_{s}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathit{=}0,\\ \\text{[iv ] } u_{t}\\mathit{\\backsim}\\text{\\textsf{n}}(.,.),\\ t\\mathit{\\in}\\mathbb{n}. \\end{array}\\ ] ]    assumptions [ i]-[iii ] relating to the first two moments of the conditional distribution @xmath115 imply that the model parameters @xmath116:**=**@xmath117 have the following statistical parameterizations in terms of the primary parameters of the joint distribution @xmath118 , @xmath119 : @xmath59{ll}$\\beta_{0}\\mathbf{=}e(y_{t})\\mathit{-}\\mathbf{\\beta}_{1}^{\\top}e(\\mathbf{x}_{t}),$ & $ \\mathbf{\\beta}_{1}\\mathit{=}\\mathbf{[}cov(\\mathbf{x}_{t})]^{-1}cov(\\mathbf{x}_{t},y_{t}),\\medskip$\\\\ \\multicolumn{2}{l}{$\\sigma^{2}\\mathbf{=}var(y_{t})\\mathit{-}cov(\\mathbf{x}_{t},y_{t})^{\\top}[cov(\\mathbf{x}_{t})]^{-1}cov(\\mathbf{x}_{t},y_{t})$}\\end{tabular } \\label{p}\\ ] ]    assumption [ i ] implies that:@xmath15@xmath2{c}e(u_{t}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathbf{=}0\\leftrightarrow e(y_{t}\\mathit{\\mid}\\mathbf{x}_{t}\\mathit{=}\\mathbf{x}_{t})\\mathbf{=}\\beta_{0}+\\mathbf{\\beta}_{1}^{\\top}\\mathbf{x}_{t}. \\end{array } \\label{ce}\\ ] ] the law of iterated expectations ( williams , 1991 ) : @xmath120{c}\\left (   e\\left [   e(y\\mathit{\\mid}\\sigma(\\mathbf{x}))\\right ]   \\right ) \\mathbf{=}e(y ) , \\end{array } $ ] where @xmath121 denotes the sigma - field generated by @xmath122 implies that:@xmath123   \\mathbf{=}e(y_{t})\\mathbf{=}\\beta_{0}\\mathit{+}\\mathbf{\\beta}_{1}^{\\top}e(\\mathbf{x}_{t})\\longrightarrow\\beta_{0}\\mathit{=}e(y_{t})-\\mathbf{\\beta}_{1}^{\\top } e(\\mathbf{x}_{t})\\ ] ] substituting @xmath124 back into @xmath125 yields:@xmath126   \\mathit{=}\\mathbf{\\beta}_{1}^{\\top}\\left [ \\mathbf{x}_{t}-e(\\mathbf{x}_{t})\\right ]   + u_{t}.\\ ] ] post - multiplying both sides by @xmath127   ^{\\top}$ ] and taking expectations yields:@xmath2{cl}cov(y_{t},\\mathbf{x}_{t } ) & \\mathit{:=}e\\left (   \\left [   y_{t}\\mathit{-}e(y_{t})\\right ]   \\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ] ^{\\top}\\right )   \\mathit{=}\\\\ & \\mathit{=}\\mathbf{\\beta}_{1}^{\\top}\\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ]   \\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ]   ^{\\top}\\mathit{+}e(u_{t}\\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ]   ^{\\top } ) .",
    "\\end{array}\\ ] ] since , the last term is zero : @xmath120{c}e(\\mathbf{x}_{t}^{\\top}u_{t})\\mathit{=}e\\left [   e(u_{t}\\mathit{\\mid}\\sigma(\\mathbf{x}_{t}))\\right ]   \\mathit{=}0 , \\end{array } \\smallskip\\newline$]it follows that : @xmath128^{-1}cov(\\mathbf{x}_{t},y_{t})$ ] .    in the case of",
    "@xmath129 we use a theorem analogous to the _ lie _ for the variance ( williams , 1991):@xmath2{c}var(y_{t})=e\\left [   var(y_{t}\\mathit{\\mid}\\sigma(\\mathbf{x}_{t}))\\right ] + var\\left [   e(y_{t}\\mathit{\\mid}\\sigma(\\mathbf{x}_{t}))\\right ]   , \\end{array}\\ ] ] where , by definition @xmath130   \\mathbf{=}\\sigma^{2}.$ ] the mean deviation of ( [ ce ] ) is:@xmath2{c}\\left [   \\beta_{0}\\mathit{+}\\mathbf{\\beta}_{1}^{\\top}\\mathbf{x}_{t}\\right ] -e\\left (   \\left [   \\beta_{0}\\mathit{+}\\mathbf{\\beta}_{1}^{\\top}\\mathbf{x}_{t}\\right ]   \\right )   \\mathit{=}\\mathbf{\\beta}_{1}^{\\top}\\left [ \\mathbf{x}_{t}-e(\\mathbf{x}_{t})\\right ]   , \\end{array}\\ ] ] and thus , by definition:@xmath2{c}var\\left [   e(y_{t}\\mathit{\\mid}\\mathbf{x}_{t})\\right ]   \\mathbf{=}e\\left [ \\mathbf{\\beta}_{1}^{\\top}\\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ]   \\left [   \\mathbf{x}_{t}\\mathit{-}e(\\mathbf{x}_{t})\\right ] ^{\\top}\\mathbf{\\beta}_{1}\\right ]   \\mathit{=}\\mathbf{\\beta}_{1}^{\\top}\\left [ cov(\\mathbf{x}_{t})\\right ]   \\mathbf{\\beta}_{1}. \\end{array } \\vspace*{-0.1in}\\ ] ] from this , it follows that : @xmath2{c}var(y_{t})\\mathbf{=}\\sigma^{2}\\mathit{+}\\mathbf{\\beta}_{1}^{\\top}\\left [ cov(\\mathbf{x}_{t})\\right ]   \\mathbf{\\beta}_{1}\\longrightarrow\\sigma ^{2}\\mathit{=}var(y_{t})\\mathit{-}\\mathbf{\\beta}_{1}^{\\top}\\left [ cov(\\mathbf{x}_{t})\\right ]   \\mathbf{\\beta}_{1 } , \\end{array } \\vspace*{-0.1in}\\ ] ] which yields the parameterization in ( [ p ] ) ."
  ],
  "abstract_text": [
    "<S> the primary objective of this paper is to revisit simpson s paradox using a statistical misspecification perspective . </S>",
    "<S> it is argued that the reversal of statistical associations is sometimes spurious , stemming from invalid probabilistic assumptions imposed on the data . </S>",
    "<S> the concept of statistical misspecification is used to formalize the vague term ` spurious results ' as ` statistically untrustworthy ' inference results . </S>",
    "<S> this perspective sheds new light on the paradox by distingusing between statistically trustworthy vs. untrustworthy association reversals . </S>",
    "<S> it turns out that in both cases there is nothing counterintuitive to explain or account for . </S>",
    "<S> this perspective is also used to revisit the causal ` resolution ' of the paradox in an attempt to delineate the modeling and inference issues raised by the statistical misspecification perspective . </S>",
    "<S> the main arguments are illustrated using both actual and hypothetical data from the literature , including yule s `` nonsense - correlations '' and the berkeley admissions study .    </S>",
    "<S> keywords : association reversal ; spurious correlation ; statistical misspecification ; statistical vs. substantive adequacy ; misspecification testing ; untrustworthy evidence ; causality ; confounding . </S>"
  ]
}