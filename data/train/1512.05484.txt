{
  "article_text": [
    "a robot interacting with its environment can collect large volumes of dynamic sensory input to overcome many challenges presented by static data .",
    "a robot manipulating an object with the capability to control its camera orientation , for example , is an example of an active object recognition system . in such dynamic interactions ,",
    "the robot can select the training data for its models of the environment , with the goal of maximizing the accuracy with which it perceives its surroundings . in this paper , we focus on active object recognition ( aor ) with the goal of developing a model that can be used by a robot to recognize an object held in its hand .",
    "there are a variety of approaches to active object recognition , the goal of which is to re - position sensors or change the environment so that the new inputs to the system become less ambiguous for label prediction @xcite .",
    "an issue with previous approaches to active object recognition is that they mostly used small simplistic datasets , which were not reflective of challenges in real - world applications @xcite . to avoid this problem ,",
    "we have collected a large dataset for active object recognition , called germs , which contains more than 120k high resolution ( 1920x1080 ) rgb images of 136 different plush toys .",
    "this paper extends our previous work , deep q - learning @xcite , where an action selection network was trained on top of a pre - trained convolutional neural network . in this paper",
    "we extend the model to train the network end - to - end using germs images to jointly predict object labels and action values .",
    "this paper makes two primary contributions : first , we develop a deep active object recognition ( daor ) model to jointly predict the label and the best next action on an input image .",
    "we propose a deep convolutional neural network that outputs the object labels and action - values in different layers of the network .",
    "we use reinforcement learning to teach the network to predict the action values , and minimize the action value prediction error along with the label prediction cross entropy .",
    "the visual features in early stages of this network are learned to minimize both errors .",
    "the second contribution of this work is to embed a generative dirichlet model of objects similarities for encoding the state of the system .",
    "this model integrates information from different images into a vector , based on which actions are calculated to optimize performance .",
    "we embed this model as a layer in the network and derive the learning rule for updating the dirichlet parameters using gradient descent .",
    "we conduct a series of experiments on the germs dataset to test ( 1 ) if the model can be trained jointly for label and action prediction , and ( 2 ) how effective is the proposed dirichlet state encoding compared to more traditional naive bayes approach , and ( 3 ) discuss some of the properties of the learned policies .     in the next section ,",
    "we review some of the previous approaches to active object recognition and examine the datasets they used .",
    "next we introduce the germs dataset and describe the training and testing data used for the experiments in this paper .",
    "after that , we describe the details of the proposed network and dirichlet state encoding , going into the details of cost functions and update rules for different layers of the network . in the results section ,",
    "we report the properties of the proposed network and compare its performance in different scenarios .",
    "the following section is the concluding remarks .",
    "active object recognition systems include two modules : a recognition module and a control module . given a sequence of images , the recognition module produces a belief state about the objects that generated those images .",
    "given this belief state , the control module produces actions that will affect the images observed in the future @xcite . the controller is typically designed to improve the speed and accuracy of the recognition module .",
    "one of the earliest active systems for object recognition was developed by wilkes and tsotsos @xcite .",
    "they used a heuristic procedure to bring the object into a standard view by a robotic - arm - mounted camera . in a series of experiments on 8 origami objects ,",
    "they qualitatively report promising results for achieving the standard view and retrieving the correct object labels .",
    "seibert and waxman explicitly model the views of an object by clustering the images acquired from the view - sphere of the object into aspects @xcite .",
    "the correlation matrices between these aspects are then used in an aspect network to predict the correct object label . using three model aircraft objects , they show that the belief over the correct object improves with the number of observed transitions compared to randomly generated paths on the view sphere of these objects .",
    "schiele and crowley developed a framework for active object recognition by making an analogy between object recognition and information transmission @xcite .",
    "they try to minimize the conditional entropy @xmath0 between the original object @xmath1 and the observed signal @xmath2 .",
    "they used the coil-100 dataset for their experiments , which consists of 7200 images of 100 toy objects rotated in depth @xcite .",
    "this dataset has been appealing for active object recognition because it provides systematically defined views of objects . at test time , by sequentially moving to the most and second most discriminative views of each object , schiele and crowley achieved almost perfect recognition accuracy on this dataset .",
    "borotschnig et al .",
    "formulate the observation planning in terms of maximization of the expected entropy loss over actions @xcite .",
    "larger entropy loss is equivalent to less ambiguity in interpreting the image . with an active vision system consisting of a turntable and a moving camera ,",
    "they report improvements in object recognition over random selection of the next viewing pose on a small set of objects .",
    "callari and ferrie take into account the object modeling error and search for actions that simultaneously minimize both modeling variance and uncertainty of belief over objects @xcite . using a set of 10 custom clay objects , they report decrease in the entropy of the classifier output and kullback - leibler divergence between the posterior distribution of each object and the corresponding true distribution .",
    "browatzki et al .",
    "use a particle filter approach to determine the viewing pose of an object held in - hand by an icub humanoid robot @xcite . for selecting the next best action , instead of maximizing the expected information gain , which is computationally expensive ,",
    "they maximize a measure of variance of observations across different objects .",
    "they show that their method is superior to random action selection on small sets of custom objects .",
    "atanasov et al .",
    "focus on the comparison of myopic greedy action selection that looks ahead only one step and non - myopic action selection which considers several time steps into the future @xcite .",
    "they formulate the problem as a partially observable markov decision process , showing their method is superior to random and greedy selection of actions on a small set of household objects .",
    "rebguns et al .",
    "used acoustic properties of objects to learn an infomax controller to recognize a set of 10 objects @xcite . in this work , they proposed a dirichlet based model to fuse information from different observations into a single belief vector . using this latent variable mixture model for acoustic similarities ,",
    "the robot learned to rapidly reduce uncertainty about the categories of the objects in a room .",
    "the state encoding of our system is similar to the mixture model of this work , however we embed this model into the network and train its parameters using gradient descent which is more suited for neural networks .",
    "paletta & pinz @xcite treat active object recognition as an instance of a reinforcement learning problem , using q - learning to find the optimal policy .",
    "they used an rbf neural network with the reward function depending on the amount of entropy loss between the current and the next state .",
    "a common trend in many of these approaches is the use of small , sometimes custom- designed sets of objects .",
    "there are medium sized datasets such as coil-100 , which consists of 7200 images of 100 toy objects rotated in depth @xcite .",
    "this dataset is not an adequately challenging dataset for several reasons , including the simplicity of the image background , and the high similarity of different views of the objects due to single - track recording sessions .",
    "what is missing is a challenging dataset for active object recognition with inherent similarities among different object categories .",
    "the dataset should be large enough to train models with large number of parameters , such as deep convolutional neural networks . in the next section ,",
    "we describe germs , a large and challenging dataset for active object recognition that we used for experiments in this paper .",
    "the germs dataset was collected in the context of the rubi project , whose goal is to develop robots that interact with toddlers in early childhood education environments @xcite .",
    "this dataset consists of 1365 video recordings of give - and - take trials using 136 different objects .",
    "the objects are soft toys depicting various human cell types , microbes and disease - related organisms .",
    "figure [ figure : collage ] shows the entire set of these toys .",
    "each video consists of the robot ( rubi ) bringing the grasped object to its center of view , rotating it by @xmath3 and then returning it .",
    "the dataset was recorded from rubi s head - mounted camera at 30 frames per second .",
    "the data for germs were collected in two days .",
    "on the first day , each object was handed to rubi in one of 6 pre - determined poses , 3 to each arm , after which rubi grabbed the object and captured images while rotating it .",
    "the robot also captured the positions of its joints for every capture image . on the second day",
    ", we asked a set of human subjects to hand the germ objects to rubi in poses they considered natural .",
    "a total of 12 subjects participated in test data collection , each subject handing between 10 and 17 objects to rubi . for each object , at least 4 different test poses were captured .",
    "the background of the germs dataset was provided by a large screen tv displaying video scenes from the classroom in which rubi operates , including toddlers and adults moving around .",
    "we use half of the data collected in day 1 and 2 for training and the other half of each day for testing .",
    "more specifically , three random tracks out of six tracks for each object in day 1 and two randomly selected tracks for each object from day 2 were used for training the network and the rest was used for testing .",
    "table [ table : datasetstats ] shows the statistics of training and testing data for the experiments in this paper .",
    ".germs dataset statistics ( mean@xmath4std ) [ cols=\"<,<,<,<\",options=\"header \" , ]       it may help us understand the weakness and strength of different models if we take a closer look into the learned policies . for this purpose",
    ", we visualize the consecutive actions in the interactions sequences of length 5 , as shown for training data in figures [ figure : policytrain ] and for test data in figure [ figure : policytest ] .",
    "each plot represents actions in different rows , with the magnitude and orientation of the action begin depicted by the length and direction of the corresponding arrow on the left side .",
    "each time step of the interaction sequence is shown as a numbered column .",
    "the colored lines in each plot connect one action in column @xmath5 to another action in column @xmath6 only if those actions appeared consecutively in interaction sequences at these time steps .",
    "the thickness of lines depicts the relative frequency by which two actions were observed on the data .",
    "figure [ figure : policytrain ] visualizes the policies dn - daor and nb - daor on the training data .",
    "this figure helps clarify the lower performance of nb models as described before . for nb - daor shown on the left side of figure [",
    "figure : policytrain ] , we see thick lines connecting actions that rotate the object with the largest magnitude in opposite directions .",
    "the relative thickness of these lines indicates that the model tends to go to one end of joint s rotation range , go back with one large rotation and then repeat . despite presence of other actions ,",
    "this back and forth action dominates the training process , leading to lower accuracy on test label prediction for single images . on the right side of figure [",
    "figure : policytrain ] we see that dn - daor picks a wide range of actions , which leads to better examination of training images and thus higher performance on single images .",
    "figure [ figure : policytest ] visualizes the learned policies at test time for nb - daor and dn - daor .",
    "we see on the left side that nb - daor only swings between the two large rotations in the opposite direction , while dn - daor prefers to do a few larger actions ( thick purple and blues lines connecting columns 2 , 3 and 4 ) followed by few smaller actions in different directions .",
    "there is no back and forth for dn - daor between visited joint positions , which leads to better performance on the test set .",
    "in this paper , we proposed a model for deep active object recognition based convolutional neural networks .",
    "the model is trained by jointly minimizing the action and label prediction simultaneously .",
    "the visual features in early stages of this network were trained by minimizing action and label prediction costs .",
    "the difference between the work presented here and deeply supervised networks @xcite is that in the latter , the training is carried out by minimizing the classification error in different layers , while in our approach we minimized the action learning costs along with classification error .",
    "we also adapted an alternative to the common naive bayes belief update rule for state encoding of the system .",
    "naive bayes has the potential to overfit to subsets of training images , which could lead to lower accuracy at the test time .",
    "we used a generative model based on dirichlet distribution to model the belief over target classes and actions performed on them .",
    "this model was embedded into the network , which allowed training the network in one pass jointly for label and action prediction .",
    "the results of experiments confirmed that the proposed dirichlet model is superior in test label prediction to the naive bayes approach for system s state encoding .",
    "a common trend we observed in the models trained in this paper was the strong preference for a few actions , which led to limited examination of the objects , and thus lower performance on label prediction .",
    "this preference was the strongest in the naive bayes state encoding models .",
    "employing dirichlet for state encoding helped alleviate this problem , mainly for the training data and less for test data .",
    "we observed that the strong preference for a limited set of actions weakens in the training stage for the dr - daor model , and as a result of this the test label prediction accuracy was improved .",
    "we hypothesize that in addition to state encoding , learning actions on the training images which have high label prediction accuracy , leads to this strong preference . in training our models",
    ", the training accuracy reaches above @xmath7 after 1000 iterations .",
    "this may cause the @xmath8to reward every action , which finally may lead to one action taking over and always producing the highest action value .",
    "the research presented here was funded by nsf iis 0968573 socs , iis int2-large 0808767 , and nsf sbe-0542013 and in part by us nsf aci-1541349 and oci-1246396 , the university of california office of the president , and the california institute for telecommunications and information technology ( calit2 ) .",
    "00    j. aloimonos , j. i. weiss , and a. bandyopadhyay , active vision , international j. computer vision , vol . 1 , no . 4 , pp .",
    "333 - 356 , 1988 .",
    "r. bajcsy , active perception , proceedings of the ieee , vol .",
    "76 , no . 8 , pp .",
    "966 - 1005 , 1988 .",
    "d. wilkes and j. k. tsotsos , active object recognition , proceedings cvpr92 . , 1992 ieee computer society conference on , pp .",
    "136 - 141 .",
    "ieee , 1992 .    m. seibert and a. m. waxman , adaptive 3-d object recognition from multiple views , ieee transactions on pattern analysis and machine intelligence , vol .",
    "107 - 124 , 1992 .",
    "b. schiele and j. l. crowley , transinformation for active object recognition , in computer vision , sixth international conference on , pp .",
    "249 - 254 .",
    "ieee , 1998 .",
    "s. a. nene , s. k. nayar and h. murase , columbia object image library ( coil-100 ) , technical report cucs-006 - 96 , columbia university , 1996 . h. borotschnig , l. paletta , m. prantl and a. pinz , appearance - based active object recognition , image and vision computing , vol .",
    "715 - 727 , 2000 .",
    "l. paletta and a. pinz , active object recognition by view integration and reinforcement learning , robotics and autonomous systems , vol .",
    "71 - 86 , 2000 .",
    "f. g. callari and f. p. ferrie , active object recognition : looking for differences , international j. computer vision , vol .",
    "189 - 204 , 2001 .",
    "b. browatzki , v. tikhanoff , g. metta , h. h. bulthoff and c. wallraven , active object recognition on a humanoid robot , in robotics and automation ( icra ) , 2012 ieee international conference on , pp .",
    "2021 - 2028 , ieee , 2012 .",
    "b. browatzki , v. tikhanoff , g. metta , h. h. bulthoff , c. wallraven , active in - hand object recognition on a humanoid robot , robotics , ieee transactions on , vol .",
    "99 , pp . 1 - 9 , 2014 .",
    "n. atanasov , b. sankaran , j. l. ny , g. j. pappas and k. daniilidis , nonmyopic view planning for active object classification and pose estimation , robotics , ieee transactions on , vol .",
    "1078 - 1090 , 2014",
    ". m. malmir , d. forster , k. youngstrom , l. morrison and j. r. movellan , home alone : social robots for digital ethnography of toddler behavior , computer vision workshops ( iccvw ) , 2013 ieee international conference on , pp .",
    "762 - 768 , 2013 .",
    "j. r. movellan , m. malmir and d. forester , hri as a tool to monitor socio - emotional development in early childhood education , in proc .",
    "hri 2nd workshop on applications for emotional robots , bielefeld , germany , 2014 .",
    "m. malmir , k. sikka , d. forster , j. movellan and g. w. cottrell .",
    "deep q - learning for active recognition of germs : baseline performance on a standardized dataset for active learning . in xianghua xie ,",
    "mark w. jones , and gary k. l. tam , editors , proceedings of the british machine vision conference ( bmvc ) , pages 161.1 - 161.11 .",
    "bmva press , september 2015 .",
    "krizhevsky , alex , ilya sutskever , and geoffrey e. hinton .",
    "`` imagenet classification with deep convolutional neural networks . '' in advances in neural information processing systems , pp .",
    "1097 - 1105 . 2012 .",
    "rebguns , antons , daniel ford , and ian r. fasel .",
    "`` infomax control for acoustic exploration of objects by a mobile robot . '' in workshops at the twenty - fifth aaai conference on artificial intelligence .",
    "denzler , joachim , christopher m. brown , and heinrich niemann .",
    "`` optimal camera parameter selection for state estimation with applications in object recognition . '' in pattern recognition , pp .",
    "305 - 312 .",
    "springer berlin heidelberg , 2001 ."
  ],
  "abstract_text": [
    "<S> an active object recognition system has the advantage of being able to act in the environment to capture images that are more suited for training and that lead to better performance at test time . in this paper </S>",
    "<S> , we propose a deep convolutional neural network for active object recognition that simultaneously predicts the object label , and selects the next action to perform on the object with the aim of improving recognition performance . </S>",
    "<S> we treat active object recognition as a reinforcement learning problem and derive the cost function to train the network for joint prediction of the object label and the action . </S>",
    "<S> a generative model of object similarities based on the dirichlet distribution is proposed and embedded in the network for encoding the state of the system . </S>",
    "<S> the training is carried out by simultaneously minimizing the label and action prediction errors using gradient descent . </S>",
    "<S> we empirically show that the proposed network is able to predict both the object label and the actions on germs , a dataset for active object recognition . </S>",
    "<S> we compare the test label prediction accuracy of the proposed model with dirichlet and naive bayes state encoding . </S>",
    "<S> the results of experiments suggest that the proposed model equipped with dirichlet state encoding is superior in performance , and selects images that lead to better training and higher accuracy of label prediction at test time .    active object recognition , deep learning , q - learning </S>"
  ]
}