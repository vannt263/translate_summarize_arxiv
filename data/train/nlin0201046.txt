{
  "article_text": [
    "much research has been done into the computational possibilities of neural networks . yet",
    "the engineering and industrial applications of these models have often eclipsed their use in trying to come to an understanding of naturally occurring neural systems .",
    "whereas in engineering we often use single neural networks to attack a single problem , in nature we see neural systems in competition .",
    "humans , for example , invest in the stock market , attempt to beat their business rivals , or , in extreme examples , plan wars against each other .",
    "we are , as darwin identified a century and a half ago , in competition for natural resources ; our neural systems ",
    "i.e .  our brains  are among the main tools we have to help us succeed in that competition .    in collaboration with chialvo ,",
    "one of the authors of this paper has developed a neural network model that provides a biologically plausible learning system  @xcite , based essentially around ` darwinian selection ' of successful behavioral patterns .",
    "this simple ` minibrain'as we will refer to it from now on  has been shown to be an effective learning system , being able to solve such problems as the exclusive - or ( xor ) problem and the parity problem .",
    "crucially , it has also been shown to be easily able to _ un - learn _ patterns of behavior once they become unproductive  an extremely important aspect of animal learning  while still being able to remember previously successful responses , in case they should prove useful in the future . these capabilities , combined with the simplicity of the model ,",
    "provide a powerful case for biological feasibility .    in choosing a competitive framework for this neural network",
    ", we follow the example of metzler , kinzel and kanter  @xcite , using the delightfully simple model of competition within a population provided by the minority model of challet and zhang  @xcite ( itself based on the ` el farol ' bar problem created by arthur  @xcite ) . in this game , a population of agents has to decide , independently of each other , which of two groups they wish to join .",
    "whoever is on the minority side ` wins ' and is given a point . by combining these two models  replacing the fixed strategies of agents in challet and zhang s model with agents controlled by the minibrain neural system  we have a model of neural systems in competition in the real world .",
    "this is not the first model of coevolution of strategies in a competitive game  a particularly interesting example is lindgren and nordahl s investigation of the prisoner s dilemma , where players on a cellular grid evolve and mutate strategies according to a genetic algorithm  @xcite .",
    "however , we believe that the biological inspiration for the minibrain model , and its demonstrated capacity for fast adaption , makes our model of special interest .    the structure of this paper is as follows :",
    "we begin with a discussion of what we mean when we talk about ` intelligence ' , noting how historical influences have shaped our instinctive ideas on this subject in potentially misleading ways ; in particular , we take issue with the suggestion that a creature s intelligence can be thought of as separate from its physical nature . we suggest that intelligence can only be measured in the context of the surrounding environment of the organism being studied : we must always consider the _ embodiment _ of any intelligent system .",
    "this is followed by the account of the computer experiments we have conducted , in which we investigate the behavioral patterns produced in the minibrain / minority model combination , and the ways in which they are affected by changing agent characteristics .",
    "we show how significant crowding behavior occurs within groups of agents with the same memory value , and demonstrate how this can allow a minority of high - memory agents to take advantage of the majority population and ` win ' on a regular basis  and , by the same token , condemn a population of largely similar agents to continually losing .",
    "indeed , perhaps the most startling implication of this model is that , in a competitive situation , having a ` strategy ' might well prove worse than simply making random decisions .",
    "these results are in strong contrast with those of metzler , kinzel and kanter , whose paper inspired these experiments . in their simulations ,",
    "a homogeneous population of perceptron agents relaxes to a stable state where all agents have an average 50% success rate , and overall population performance is better than random  @xcite .",
    "the perceptrons learn , in effect , to produce an efficient market system , and do not suffer from the crowding effect produced by minibrain agents . by the same token , however , it seems unlikely that a superior perceptron could win on a similar scale to a superior minibrain .",
    "we conclude with further discussion of the nature of intelligence , suggesting a conceptual approach that we believe will enable easier investigation of both natural and artificially created intelligent systems .",
    "having already suggested that we must consider ` embodied ' intelligences , we provide criteria for cataloguing that embodiment , consisting of hardwired parts  the input and output systems of the organism , the feedback mechanism that judges the success or failure of behavioral patterns  alongside a dynamic decision - making system that maps input to output and updates its methodology according to the signals received from the feedback system .",
    "the _ e.  coli _ bacterium has a curious mode of behavior .",
    "if it senses glucose in its immediate surroundings , it will move in the direction of this sweet nourishment .",
    "if it does not , it will flip over and move a certain distance in a random direction , before taking stock again , and so on and so on until it finds food .",
    "bacteria are generally not considered to be ` intelligent ' . yet",
    "this is a systematic response to environmental stimuli , not necessarily the _ best _ response but nevertheless a _ working _ response , a ` satisficing ' response .",
    "the _ e.  coli _ bacterium is responding in an intelligent way to the problem of how to find food .",
    "how do we square this with our instinctive feeling that bacteria are _ not _ intelligent ?",
    "are our instincts mistaken ?",
    "how , instinctively , do we define intelligence ?",
    "historically , philosophers have often proposed the idea of a separation between ` body ' and ` mind ' .",
    "the human mind , from this point of view , is something special , something distinct , something not bound up in the messy business of the real world .",
    "it s this , we are told , that separates us from the animals : we have this magical ability to _ understand _ , to _ think _ , to _ comprehend_the ability to view the world in a rational , abstract way and thus arrive at some fundamental _ truth _ about how the universe works .",
    "the idea of separate compartments of reality for body and mind has lost its stranglehold over our way of thinking , but its influence lingers on in our concept of intelligence .",
    "our minds , our consciousness , may be the result of physical processes , but we still cling to the idea that we have the ability to discover an abstract reality , and it s this idea that informs our notion of ` intelligence ' .",
    "an intelligent being is one that can see beyond its own personal circumstances , one that is capable of looking at the world around it in an objective fashion . given enough time , it can ( theoretically ) solve any problem you care to put before it .",
    "it is capable of rising above the environment in which it exists , and comprehending the nature of true reality .",
    "naturally , this has informed our ideas about artificial intelligence .",
    "an artificially intelligent machine will be one that works in this same environmentally uninhibited manner .",
    "if we tell it to drive a car , it will be able ( given time to teach itself ) to drive a car . if we tell it to cook a meal , it will be able to cook a meal . if we tell it to prove fermat s last theorem  ",
    "all of these , of course , assume that we have given it some kind of hardware with which to gather input and make output to the relevant system , whether car , kitchen or math textbook  assume , indeed , that we have these systems present at all  and it s this necessity that causes us to realize that in fact , _ the mind and its surrounding environment ( including the physical body of the individual ) are inseparable . _",
    "our brains are the product of evolution ; they are not an abstract , infinite system for solving abstract , infinite problems , but rather a very particular system for solving the very particular problems involved in coping with the environmental pressures about us . in this respect , we re no different from the _ e.  coli _ bacterium we discussed earlier : the environments we inhabit are different , and consequently so are our behavioral patterns , but on a conceptual level there is nothing to choose between us .",
    "_ intelligence only exists in the context of its surrounding environment .",
    "_ so , if we are to attempt to create an artificial intelligence system , we must necessarily also define a world in which it will operate . and the question of _ how _ intelligent that system is can only be answered by examining how good it is at coping with the problems this world throws up , by its ability to utilize the data available to it to find working solutions to these problems .",
    "the ` minibrain ' neural system , developed by one of the authors in collaboration with chialvo  @xcite , is an extremal dynamics - based decision - making system that responds to input by choosing from a finite set of outputs , the choice being determined by darwinian selection of good ( i.e.  successful ) responses to previous inputs ( negative feedback ) .",
    "we use the simple layered version of this model , consisting of a layer of input neurons , a single intermediary layer of neurons , and a layer of output neurons ; each input neuron is connected to every intermediary neuron by a synapse , and similarly each intermediary neuron is connected to every output neuron .",
    "every synapse is assigned a ` strength ' , initially a random number between @xmath0 and @xmath1 .",
    "competing against each other in the minority model , each agent receives data about the past , and gives as output which of the two the groups  we label them @xmath0 and @xmath1that it wishes to join .",
    "we follow the convention of challet and zhang s version of the game , that this knowledge is limited to knowing which side was the minority ( i.e.  winning ) group at each turn in a finite number of past turns  @xcite , so that agent input can be represented by a binary number of @xmath2 bits , where @xmath2 is the agent s memory .",
    "so , for example , if in the last three turns group @xmath0 lost , then won , then won again , this would be represented by the binary number @xmath3 , where the left - most bit represents the most recent turn , and each bit is determined by the number of the _ losing _ ( majority ) group that turn ( we choose these settings in order to match the way our computer code is set up ) .    in order to preserve symmetry of choice between the two groups , an agent with a memory of @xmath2",
    "turns will have @xmath4 input neurons , with the first of the @xmath5th pair of neurons firing if the bit representing the result @xmath5 turns ago is @xmath0 , the second neuron of the @xmath5th pair firing if the result was @xmath1 .",
    "for example , if an agent with a memory of @xmath6 ( and hence with @xmath7 input neurons ) is given the past @xmath3 as we discussed above , then the second , fourth and fifth input neurons will fire .",
    "[ fig:1 ] gives a picture of this architecture ( to avoid over - complicating the diagram , not all connections are shown ) .",
    "architecture of minibrain agents .",
    "every input neuron is connected to every intermediary neuron , and every intermediary neuron is connected to every output neuron . for our setup , we have two outputs , and @xmath4 inputs , where @xmath2 is the agent s memory.,width=317,height=167 ]    to determine the intermediary neuron that fires , we take for each the sum of the strengths of the synapses connecting it to the firing input neurons . the intermediary neuron with the greatest such sum",
    "is the one that fires .",
    "then , the output neuron that fires ( @xmath0 or @xmath1 ) is the one connected to the firing intermediary neuron by the strongest synapse .",
    "each turn , the synapses used are ` tagged ' with a chemical trace .",
    "if the output produced that turn is satisfactory ( in this setup , if the agent joins the minority group ) , no further action is taken .",
    "if the output is not satisfactory , however , a global feedback signal ( e.g.  the release of some hormone ) is sent to the system , and the tagged synapses are ` punished ' for their involvement in this bad decision by having their strengths reduced ( in our model , by a random number between @xmath0 and @xmath1 ) . as we noted in the introduction , this darwinian selection of successful behavioral patterns has already been shown to be an effective learning system when ` going solo '  @xcite ; how will it cope when placed in competition ?",
    "[ fig:2 ] shows the success rates of agents of different memory values .",
    "a group of @xmath8 agents has an even spread of memory values between @xmath1 and @xmath9 ; each agent has @xmath10 intermediary neurons .",
    "the figure shows their success rates over a period of @xmath11 turns .",
    "success rates of a mixed population of minibrain agents against their memory .",
    "agents have @xmath10 intermediary neurons.,width=284,height=196 ]    to a certain extent , these results reflect those found by challet and zhang when they explore the behavior of a mixed population of fixed - strategy agents  @xcite , inasmuch as performance improves with higher memory but tends to saturate eventually .",
    "standard deviation within each memory group is much lower for minibrain agents , however , suggesting crowding behaviour within memory groups , and we will later show that this does indeed occur .    disappointingly , we see that not one agent achieves as much as a 50% success rate  they would all be better off tossing coins to make their decisions .",
    "the even spread of memory values throughout the population means that agents with higher memory values can not take full advantage of their extra knowledge : the crowding behavior between agents with the same memory cancels out most of the positive effects .",
    "it s no good having lots of data on which to base your decision if lots of other people have that same data ",
    "everyone will come to the same conclusion and , in the minority model , that means losing .    necessarily , then , one of the conditions for an agent to succeed  i.e .",
    "to beat the coin - tossing strategy  is that there must be few other agents with the same amount of memory .",
    "this is demonstrated starkly in fig .",
    "[ fig:3 ] , displaying the results for a population of @xmath8 agents of whom _ one _ has a memory of @xmath6 , the rest only @xmath12 .",
    "success rate of a single agent of memory @xmath6 , versus a @xmath13-strong population of memory @xmath12 .",
    "agents have @xmath10 intermediary neurons.,width=284,height=226 ]    the astonishing success of this ` rogue ' agent ( it makes the right decision approximately 99.8% of the time ) shows clearly just how important a factor this crowding behavior is in the success ( or failure ) of agents .",
    "the fact that this agent is the only one receiving the extra data means that he can use it to his advantage .",
    "contrast this with the other agents who , for all their careful thinking , fail miserably because _",
    "almost all of them think alike  entirely independently  almost all of the time . _",
    "this example leads us to ask the more general question : given a population of agents who all have memory @xmath2 , can we always find such a ` rogue ' , an agent capable of understanding and thus beating the system ? that it is not merely a matter of agent memory is amply demonstrated in fig .",
    "[ fig:4 ] , where we see a population of memory @xmath14 pitted against a rogue with a memory of @xmath9 .",
    "success rate of a single agent of memory @xmath9 , versus a @xmath13-strong population of memory @xmath14 .",
    "agents have @xmath10 intermediary neurons.,width=284,height=193 ]    despite its high memory value ( twice that of the majority population ) the rogue agent is unable to beat the coin - tossing strategy .",
    "why is this ?",
    "a higher memory value should , by our earlier results , always be an advantage .",
    "certainly , since we have respected symmetry of choice between agent outputs , it should not be a _",
    "disadvantage_. what factor is it that prevents this agent from making full use of the memory available to it , memory which surely has within it useful data patterns that predict the behavior of the agents with memory @xmath14 , and thus should allow the rogue agent the success we expect it to achieve ?    the answer becomes clear when we examine the nature of the input that each agent receives  a binary number of length @xmath2 , where @xmath2 is the value of the agent s memory .",
    "so , it follows that the total possible number of inputs will be @xmath15 . for an agent with memory @xmath14 , this means @xmath16 possible inputs . for an agent with memory @xmath9 ,",
    "the total number of possible inputs is @xmath17 .",
    "compare this to the number of _ intermediary _ neurons possessed by each agent ( @xmath10 , in all the simulations we ve run so far ) and we realize that , while this is an adequate number for an agent receiving @xmath16 different possible inputs , it is wholly inadequate for an agent having to deal with some @xmath17 possible inputs .",
    "the number of intermediary neurons restricts the maximum performance of an agent by placing a limit on the amount of memory that can be effectively used .    bearing this condition in mind",
    ", we run a new set of games , again with a majority population of memory @xmath14 , but this time with a rogue of memory @xmath18 , and with the number of intermediary neurons given to each agent varying in each of these games . fig .",
    "[ fig:5 ] shows the results of games where agents have intermediary layers of , respectively , @xmath19 , @xmath20 , @xmath21 and @xmath17 neurons .",
    "success rates of single agents of memory @xmath18 , versus a @xmath13-strong population of memory @xmath14 , in simulations with @xmath19 , @xmath20 , @xmath21 and @xmath17 intermediary neurons per agent.,width=284,height=245 ]    the implications are clear  it is the number of intermediary neurons , as well as the amount of memory , that control whether or not a rogue agent can succeed , and , if it does , by how much .",
    "a higher memory value will always be an advantage , but the degree to which it is advantageous will be determined by the number of intermediary neurons possessed .",
    "memory , obviously , determines how much information an agent can receive ; the intermediary neurons are what provide agents analytic capability .",
    "our computer simulations suggest that in situations such as the ones already discussed , with a majority population of memory @xmath2 , it is the intermediary neurons , rather than the amount of memory possessed , that control the ability of a rogue agent to succeed .",
    "a memory of @xmath22 is all that is required , _ provided _ the rogue has enough intermediary neurons to be able to use it effectively .",
    "we can muddy the waters , so to speak , by giving the majority population an evenly distributed _",
    "spread _ of memory values ( perhaps from @xmath1 to @xmath2 ) rather than a single value . where a single memory value is used , the crowding behavior observed within memory groups will easily allow rogue agents to predict the minority group . with a series of different , smaller groups in competition",
    ", it becomes significantly less easy to make accurate predictions , and rogue agent success rates fall significantly .",
    "herding sheep is fairly easy ; jumping into the middle of a brawl is dangerous for anyone , even a world champion martial artist .",
    "all things considered , it seems as though this may be the key point in determining agent success .",
    "an agent can only be truly successful if it has plenty of ` prey ' whose weaknesses it can exploit . if the behavior of the prey is highly unpredictable , or the prey are capable of biting back , the agent s chances of success are vastly reduced .",
    "we have on several occasions referred to crowding behavior of minibrain agents within the same memory group . in this section ,",
    "we give a brief mathematical analysis of what causes this to arise .",
    "we begin with a simple case , assuming that all agents have the same memory value . obviously , because of the nature of the game",
    ", a majority of these agents will behave in the same way each turn . what we show",
    ", however , is that this majority is significantly more than would be found if the agents were deciding randomly as to which group to join .",
    "were agents to employ this strategy , the mean size of the ( losing ) majority group would be only a little over 50% .",
    "we define by @xmath23 the proportion of agents in the minority group given input @xmath24 , where the subscript @xmath5 is the number of times input @xmath24 has occurred before .",
    "if an input has not been seen before by agents , it follows that they will decide randomly which group to join , and so we have @xmath25 for all possible inputs @xmath24 .    if an input _ has _ been seen before , it follows that those agents in the minority group on that occasion  i.e.  those who were successful  will make the same decision as last time .",
    "those who were unsuccessful last time will make a random decision as to which group to join : we can expect , on average , half of them to change their minds , half to stay with their previous choice .",
    "the effect of this , ironically , is that this last group  the unsuccessful agents who keep with their previous choice  will probably ( in fact , almost certainly ) form the minority group this time round .",
    "and so we can define a recurrence relation , @xmath26    determining the expected proportion of agents joining the minority group for each occurrence of input @xmath24 .",
    "this allows us to develop a more general equation , @xmath27    where @xmath28    observe that this holds for @xmath29 , as a little calculation reveals @xmath30 .",
    "now , assume the equation holds for @xmath31 , with @xmath32 any positive integer , so @xmath33 .    by the recurrence relation , @xmath34    @xmath35\\ ]",
    "]    @xmath36\\ ] ]    @xmath37\\ ] ]    @xmath38    @xmath39    hence , @xmath40 , and so by the induction hypothesis @xmath41 for all @xmath42 .",
    "it follows , then , that as @xmath43 , so @xmath44 , and so , with repeated exposure to the input @xmath24 , we will find that on average @xmath45 of the agents will produce the same output . as a result",
    ", the average majority size per turn ( regardless of input given ) will also tend to @xmath45 as the agents become saturated by all the possible inputs .",
    "this can be observed in fig .",
    "[ fig:6 ] , which shows the average proportion of agents joining the majority group each turn in eight different games involving single memory value populations , the first involving agents of memory @xmath1 , the second with agents of memory @xmath12 , and so on up to the final game , with agents of memory @xmath9 .",
    "each game takes place over a time period of some @xmath46 turns .",
    "mean size of majority each turn in games with uniform agent memory , against different choices for this memory value .",
    "agent population per game is @xmath8 , but majority size is given proportionally .",
    "agents have @xmath10 intermediary neurons.,width=284,height=194 ]    as memory increases , so the number of possible inputs also increases , meaning there is less repeated exposure to individual inputs , and hence less crowding for a given time period . within a time - scale of @xmath46",
    "turns , the behavior of agents with longer memories is random more often than not , and so the mean size of majority is similar to that of agents making random decisions . as the number of turns increases , so we can expect the mean size of the majority to tend to @xmath45 for all memory values , not just the lowest .",
    "what implications does this have for games involving a mixed population of agents , such as that displayed in fig .",
    "[ fig:2 ] ? overall",
    ", the same principles will apply .",
    "repeated exposure to the same input will produce the same crowding effect .",
    "but we note that the inputs given to this system  eight - digit binary numbers  are interpreted differently by different agents . for agents with lower memories ,",
    "many of these ` different ' inputs are interpreted as being the same !",
    "for example , the inputs @xmath47 and @xmath48 are the same to an agent with a memory of @xmath6 or less .",
    "so  as is demonstrated by fig .",
    "[ fig:6]the crowding effect surfaces earlier in agents with lower memory values , and hence they are adversely affected to a greater degree .",
    "the agents with higher memory values fail to beat the 50% success rate , however , because there are too many of them  any insights they might have into the crowding behavior of the lower memory groups are obscured by the actions of their fellow high - memory agents .",
    "thus , the kind of behavior we see in fig .  [ fig:2 ] : the lower memory agents perform the worst , with the success rate increasing towards some ` glass ceiling ' as agent memory increases .",
    "it s only unique ` rogue ' agents , who do nt have a large group of fellows , who can see the crowding effect and thus beat the system .",
    "even such rogue agents can not succeed by any great margin in the case where they are pitted against a spread of memory values .",
    "the crowding behavior of the individual groups is obscured by the large number of them and predictions become difficult ; the rogue has to work out , not just in which direction the crowding within each group will go , but how much crowding will be taking place in each group  a difficult task indeed !",
    "if we increase the crowding , we also increase the rogue s chances of success .",
    "[ fig:7 ] shows the results from two different games involving @xmath8 agents .",
    "five of them are ` rogue ' agents with memory values of , respectively , @xmath14 , @xmath18 , @xmath7 , @xmath49 and @xmath9 .",
    "the rest have an even spread of memory values from @xmath1 to @xmath6 . in order to allow the higher memory values to be useful ,",
    "we give agents @xmath17 intermediary neurons .",
    "the difference between the games is that in the first , when punishing unsuccessful synapses , we employ the principle that has been used throughout this paper  synapses are punished _",
    "once_. in the second game , the punishment does not stop until the agent has learned what would have been the correct output .",
    "the result is that , when an input has been seen before , we will have 100% agreement within memory groups .",
    "success rates of rogue agents of memory @xmath18@xmath9 , versus a majority population with memory @xmath1@xmath6 , in games involving single punishment and ` infinite ' punishment of unsuccessful synapses .",
    "total agent population is @xmath8 .",
    "agents have @xmath17 intermediary neurons.,width=284,height=245 ]    we can see here how the increased crowding caused by ` infinite ' punishment allows the rogues to take advantage and be successful .",
    "a higher memory value is required for substantial success , but substantial success is possible  at the expense of the lower memory groups , whose success rates are substantially decreased by the extra crowding behavior they are forced to produce .",
    "the rogue agents in the game with single punishment , by contrast , are barely able to do better than a 50% success rate  though they can evidently glean _ some _ data from the crowding behavior displayed by the lower memory groups , it s not sufficient for any great success and they are only barely able to beat the expected success rate were they to make purely random decisions .",
    "this is a striking result , to say the least .",
    "_ the inevitable consequence of an analytic strategy is a predisposition to failure .",
    "_ challet and zhang  @xcite and w. b. arthur  @xcite have already shown that fixed strategies can prove to be a disadvantage compared to random decisions ; this occurs when the number of available strategies is small compared to the number of agents .",
    "the crowding behavior that results from minibrain agents imperfect analysis will inevitably reduce the number of strategies in use , thus dooming themselves to worse - than - random results .",
    "we can see this at work in the real world , every day . many strategies  whether for investments , business strategies , forming a relationship , or any of the myriad problems we have to solve ",
    "fail , because they are based on common knowledge , and as such , will be similar to most other people s strategies .",
    "we are often told , ` everybody knows that  ' , but few people realize the negative side of following such advice : since _ everybody _ knows it , _ everybody _ will come to the same conclusions as you , and so your strategy will be unlikely to succeed . perhaps the best recent example is the internet boom - and - bust : so many people thought the internet was the place to invest , the market overheated , and many companies went belly - up .",
    "as this paper was being prepared , a report was broadcast on uk television about an experiment in which a four - year - old child , picking a share portfolio , was able to outdo highly experienced city traders on the stock market . in such systems , with everyone s imperfect analysis competing against everyone else s , it seems highly likely that random decisions sometimes really are the best ; the minibrain / minority model combination would appear to confirm this .",
    "another interesting conclusion to be drawn from the computer experiments here described is that , given some particular minibrain agent , there is no way of deciding if it will be successful or not unless we know about the other agents it will be competing with .    in a sense this is not surprising .",
    "we know , for example , that to be a high - flier at an ivy league university requires considerably more academic ability than most other educational institutions .",
    "the athlete coming last in the final of the olympic 100 m can still run faster than almost anyone else in the world .",
    "we know that _ in these contexts _ the conditions to be the ` best ' are different , but there is surely still an overall comparison to be made between the whole of humanity . or is there ?",
    "recall our suggestion in the introduction to this paper that the question of how intelligent a system is can only be answered by examining how good it is at coping with the problems its surrounding environment throws up . to return to minibrain agents : by the concepts we discussed earlier , it is agents _ intelligence _ , and not just their success rate , that is dependent on their fellows , as well as their own , characteristics ; indeed , the two measures  success and intelligence  cannot be separated .",
    "contrast this with how we have identified a whole range of factors  memory , the number of intermediary neurons , the amount of punishment inflicted on unsuccessful synapses  that affect the manner in which an agent performs .",
    "there are objective comparisons that can be made between agents . while we might accept that any measure of ` intelligence ' we can conceive of will only hold in the context of the minority model , surely it is not fair to suggest that the only valid measure of intelligence is success rate in the context of the population of agents we place within that world ?    before we rush off to define our abstract ` agent iq ' , however , it s worth noting that all the measures of _ human _ , as well as minibrain , intelligence that we have put in place are in fact measures of success in particular contexts .",
    "when a teacher calls a pupil a ` stupid boy ' , he is not commenting on the child s intelligence in some abstract sense , but rather the child s ability to succeed at the tasks he is set in the school environment .",
    "( einstein was considered stupid in the context of a school environment where dyslexia and asperger s syndrome were unknown . ) when we say that human beings are more intelligent than other animals what we in fact mean is that human beings are more successful at manipulating their environment to their own benefit .",
    "high - fliers at ivy league universities are considered intelligent because of their academic success .",
    "olympic athletes are considered intelligent in the context of their sport because they are capable of winning consistently .",
    "even human iq tests , long thought to provide an abstract and objective measure of intelligence , work in this fashion , being a measure of an individual s success in solving logical problems .",
    "more recently these tests have been shown to discriminate against certain individuals based on their cultural background  a further indication of their non - abstract , non - objective nature  and in addition to this , psychologists are now proposing that there are other forms of intelligence , for example _ emotional _ intelligence or ` eq ' , which are just as important to individual success as intellectual ability .",
    "were abstract measures of intelligence possible , it would be reasonable to ask : ` who was more intelligent , albert einstein or ernest shackleton ? ' as it turns out , this question is impossible to answer .",
    "shackleton probably lacked einstein s capacity for scientific imagination , einstein probably did nt know a great deal about arctic survival , but both were highly successful  and thus by implication intelligent_in the context of their own chosen way of life .",
    "_ the same is true of our hypothetical ivy league student and olympic runner .",
    "we suggest that no other possible measure of intelligence is truly satisfactory .",
    "it is not an entirely easy concept to take on board .",
    "in particular , it conflicts with our instinctive sense of what it means to be ` intelligent ' . casually  and not so casually  we talk about people s intelligence in the context of their _ understanding _ , their _ conceiving _ , their _",
    "awareness_. in other words , we talk about it in the context of their _ consciousness_. in their paper ` consciousness and neuroscience '  @xcite , francis crick and cristoph koch refer to the philosophical concept of a ` zombie ' , a creature that looks and acts just like a human being but lacks conscious awareness .",
    "using the concepts of intelligence we have been discussing , this creature is just as intelligent as a real human .    yet , on closer examination , this is not such an unreasonable idea .",
    "such a ` zombie ' is probably scientifically untenable , but it should be noted that our measures of ` intelligence ' do not measure consciousness , at least not explicitly .",
    "a digital computer can solve logical problems , for example , and it seems very unlikely that such computers are conscious .",
    "the ` emotional intelligence ' we referred to earlier almost certainly has some unconscious elements to it : our ability to respond to a situation in an appropriate emotional manner tends to be an instinctive , more than a conscious , response .",
    "lizards , it is thought , lack a conscious sense of vision but they can still catch prey , find a mate and so on , using their visual sense to do so .",
    "in fact , most of the organisms that exist on earth are probably not conscious .",
    "consciousness , most likely , is a product of brain activity that is a useful survival aid , a useful aid for success .",
    "aid _ for success , and thus for intelligence , rather than a requirement .",
    "how , then , should we approach the question of what is an intelligent system ?",
    "in their description of the construction of the minibrain neural system , bak and chialvo note : ` biology has to provide a set of more or less randomly connected neurons , and a mechanism by which an output is deemed unsatisfactory  .",
    "it is absurd to speak of meaningful brain processes if the purpose is not defined in advance .",
    "the brain can not learn to define what is good and what is bad .",
    "this must be given at the outset .",
    "from there on , the brain is on its own '  @xcite .",
    "these concepts provide us with a way of thinking about intelligent systems in general , whether naturally occurring biological systems or man - made artificial intelligence systems .",
    "( ii)_a decision - making system . _ given an input , a systematic process is applied to decide what output to make .",
    "this can range from the purely deterministic ( e.g.  a truth - table of required output for each given input ) to the completely random .",
    "the e coli bacterium s behavior in response to the presence or otherwise of glucose  either moving in the direction of the food or , if none is to be found , in a random direction  is a perfect example .",
    "( iii)_a hardwired system for determining whether a given output has been successful , and sending appropriate feedback to the system . _",
    "again , the nature of this can vary . in our computer experiments ,",
    "success is defined as being in the minority group . for the _",
    "e.  coli _ bacterium , success is finding food .",
    "possible types of feedback range from the positive reinforcement of successful behavior practiced by many neural network systems , to the negative feedback of the minibrain model .",
    "the _ e.  coli _ bacterium provides perhaps the most extreme example : if it does nt find food within a certain time period , it will die !",
    "the last of these is perhaps the most difficult to come to terms with , simply because as human beings , we instinctively feel that it is a _ conscious _",
    "choice on our part as to whether many of our actions have been successful or not .",
    "nevertheless , the ultimate determination of success or failure must rest with hardwired processes over which the decision - making system has no control . if nothing else , we are all subject to the same consideration as _ e.  coli _ : if our actions do not provide our physical bodies with what they need to survive , they , and our brains and minds with them , will perish .",
    "we should , perhaps , include an extra criterion that for a system to be _ truly _ intelligent , the feedback mechanism must in some way affect the operation of the decision - making system , whether it is punishing ` bad ' synapses in the minibrain neural network , changing the entries in a truth - table , or killing a bacterium .",
    "a system that keeps making the same decision regardless of how consistently successful that decision is , is nt being intelligent . with this in mind",
    ", we might consider systems such as _",
    "e.  coli _",
    "( i.e.  systems which employ one single strategy , and when it becomes unsuccessful simply _ stop _ ) to be _ minimally intelligent _ systems .",
    "they re nowhere near as smart as other systems , natural and artificial , but at least they know when to quit .",
    "intelligence , we suggest , is not an abstract concept . the question of what is intelligent behavior can only be answered in the context of a problem to be solved .",
    "so in the search for artificial intelligence , we must necessarily start with the world in which we want that intelligence to operate ; we can not begin by creating some ` consciousness - in - a - box ' to which we then give a purpose , but must first establish what we want that intelligence to _ do _ , before building the systems  input - output , decision - making , feedback  that will best achieve that aim .",
    "computer programmers already have an instinctive sense of this when they talk about , for example , the ` ai ' of a computer game .",
    "( purpose : to beat the human player . no longer the deterministic strategies of space invaders  many modern computer games display a great subtlety and complexity of behavior . )",
    "this is not to denigrate attempts to build conscious machines .",
    "such machines would almost certainly provide the most powerful forms of artificial intelligence .",
    "but we are still a long way from understanding what consciousness is , let alone being able to replicate it , and as we have noted here , consciousness is not necessarily needed for intelligent behavior .",
    "the experiments discussed in this paper involve ` toy ' models .",
    "comparing the minibrain neural system to the real human brain is like comparing a paper airplane to a jumbo jet  @xcite .",
    "but paper airplanes can still fly , and there are still lessons to be learned .",
    "these ` toy ' experiments provide us with a context to begin identifying what it means to be intelligent .",
    "we have been able to suggest criteria for identifying intelligent systems that avoid the controversial issues of consciousness and understanding , and a method of determining how intelligent such systems are that rests on one simple , useful and practical question : how good is this system at doing what it s meant to do ?",
    "in other words , we and others have begun to demystify the subject of intelligence and maneuver it into a position where we can begin to ask precise and well - defined questions .",
    "paper airplanes can fly for miles if they re launched from the right places ."
  ],
  "abstract_text": [
    "<S> we investigate the behavioral patterns of a population of agents , each controlled by a simple biologically motivated neural network model , when they are set in competition against each other in the minority model of challet and zhang . </S>",
    "<S> we explore the effects of changing agent characteristics , demonstrating that crowding behavior takes place among agents of similar memory , and show how this allows unique ` rogue ' agents with higher memory values to take advantage of a majority population . </S>",
    "<S> we also show that agents analytic capability is largely determined by the size of the intermediary layer of neurons .    in the context of these results , </S>",
    "<S> we discuss the general nature of natural and artificial intelligence systems , and suggest intelligence only exists in the context of the surrounding environment ( _ embodiment _ ) .    </S>",
    "<S> source code for the programs used can be found at * http://neuro.webdrake.net/*. </S>"
  ]
}