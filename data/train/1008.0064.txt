{
  "article_text": [
    "networked storage systems have gained prominence in recent years . these include various genres , including decentralized peer - to - peer storage systems , as well as dedicated infrastructure based data - centers and storage area networks .",
    "because of storage node failures , or user attrition in a peer - to - peer system , redundancy is essential in networked storage systems .",
    "this redundancy can be achieved using either replication , or ( erasure ) coding techniques , or a mix of the two .",
    "erasure codes require an object to be split into @xmath1 parts , and mapped into @xmath3 encoded fragments , such that any @xmath1 encoded fragments are adequate to reconstruct the original object .",
    "such coding techniques play a prominent role in providing storage efficient redundancy , and are particularly effective for storing large data objects and for archival and data back - up applications ( for example , cleversafe @xcite , wuala @xcite ) .",
    "redundancy is lost over time because of various reasons such as node failures or attrition , and mechanisms to maintain redundancy are essential .",
    "it was observed in @xcite that while erasure codes are efficient in terms of storage overhead , maintenance of lost redundancy entail relatively huge overheads .",
    "a naive approach to replace a single missing fragment will require that @xmath1 encoded fragments are first fetched in order to create the original object , from which the missing fragment is recreated and replenished .",
    "this essentially means , for every lost fragment , @xmath1-fold more network traffic is incurred when applying such a naive strategy .",
    "several engineering solutions can partly mitigate the high maintenance overheads .",
    "one approach is to use a ` hybrid ' strategy , where a full replica of the object is additionally maintained @xcite .",
    "this ensures that the amount of network traffic equals the amount of lost data .",
    "a spate of recent works @xcite argue that the hybrid strategy adds storage inefficiency and system complexity .",
    "another possibility is to apply lazy maintenance @xcite , whereby maintenance is delayed in order to amortize the maintenance of several missing fragments .",
    "lazy strategies additionally avoid maintenance due to temporary failures .",
    "procrastinating repairs however may lead to a situation where the system becomes vulnerable , and thus may require a much larger amount of redundancy to start with .",
    "furthermore , the maintenance operations may lead to spikes in network resource usage @xcite .",
    "it is worth highlighting at this juncture that erasure codes had originally been designed in order to make communication robust , such that loss of some packets over a communication channel may be tolerated .",
    "network storage has thus benefitted from the research done in coding over communication channels by using erasure codes as black boxes that provide efficient distribution and reconstruction of the stored objects .",
    "networked storage however involves different challenges but also opportunities not addressed by classical erasure codes .",
    "recently , there has thus been a renewed interest @xcite in designing codes that are optimized to deal with the vagaries of networked storage , particularly focusing on the maintenance issue . in a volatile network where nodes may fail , or come online and go offline frequently",
    ", new nodes must be provided with fragments of the stored data to compensate for the departure of nodes from the system , and replenish the level of redundancy ( in order to tolerate further faults in future ) . in this paper",
    ", we propose a new family of codes called _ self - repairing codes _",
    "( src ) , which are tailored to fit well typical networked storage environments .      in @xcite ,",
    "dimakis et al .",
    "propose regenerating codes ( rgc ) by exposing the need of being able to reconstruct an erased encoded block from a smaller amount of data than would be needed to first reconstruct the whole object .",
    "they however do not address the problem of building new codes that would solve the issue , but instead use classical erasure codes as a black box over a network which implements random linear network coding and propose leveraging the properties of network coding to improve the maintenance of the stored data .",
    "network information flow based analysis shows the possibility to replace missing fragment using network traffic equalling the volume of lost data .",
    "unfortunately , it is possible to achieve this optimal limit only by communicating with all the @xmath2 remaining blocks .",
    "consequently , to the best of our knowledge , regenerating codes literature generally does not discuss how it compares with engineering solutions like lazy repair , which amortizes the repair cost by initiating repairs only when several fragments are lost .",
    "furthermore , for rgcs to work , even sub - optimally , it is essential to communicate with at least @xmath1 other nodes to reconstruct any missing fragment .",
    "thus , while the volume of data - transfer for maintenance is lowered , rgcs are expected to have higher protocol overheads , implementation and computational complexity .",
    "for instance , it is noted in @xcite that a randomized linear coding based realization of rgcs takes an order of magnitude more computation time than standard erasure codes for both encoding and decoding .",
    "the work of @xcite improves on the original rgc papers in that instead of arguing the existence of regenerating codes via deterministic network coding algorithms , they provide explicit network code constructions .    in @xcite ,",
    "the authors make the simple observation that encoding two bits into three by xoring the two information bits has the property that any two encoded bits can be used to recover the third one .",
    "they then propose an iterative construction where , starting from small erasure codes , a bigger code , called hierarchical code ( hc ) , is built by xoring subblocks made by erasure codes or combinations of them .",
    "thus a subset of encoded blocks is typically enough to regenerate a missing one .",
    "however , the size of this subset can vary , from the minimal to the maximal number of encoded subblocks , determined by not only the number of lost blocks , but also the specific lost blocks .",
    "so given some lost encoded blocks , this strategy may need an arbitrary number of other encoded blocks to repair .      while motivated by the same problem as rgcs and hcs , that of efficient maintenance of lost redundancy in coding based distributed storage systems , the approach of self - repairing codes ( src ) tries to do so at a somewhat different point of the design space .",
    "we try to minimize the number of nodes necessary to reduce the reconstruction of a missing block , which automatically translates into lower bandwidth consumption , but also lower computational complexity of maintenance , as well as the possibility for faster and parallel replenishment of lost redundancy .",
    "we define the _ concept of self - repairing codes _ as @xmath0 codes designed to suit networked storage systems , that encode @xmath1 fragments of an object into @xmath3 encoded fragments to be stored at @xmath3 nodes , with the properties that : + ( a ) _ encoded fragments can be repaired directly from other subsets of encoded fragments without having to reconstruct first the original data_. + more precisely , based on the analogy with the error correction capability of erasure codes , which is of any @xmath4 losses independently of which losses , + ( b ) _ a fragment can be repaired from a fixed number of encoded fragments , the number depending only on how many encoded blocks are missing and independent of which specific blocks are missing .",
    "_ to do so , srcs naturally require more redundancy than erasure codes .",
    "we will see more precisely later on that there is a tradeoff between the repair ability and this extra redundancy .",
    "consequently , srcs can recreate the whole object with @xmath1 fragments , though unlike for erasure codes , these are not arbitrary @xmath1 fragments , though many such @xmath1 combinations can be found ( see section [ sec : static ] for more details ) .",
    "note that even for traditional erasure codes , the property ( a ) may coincidentally be satisfied , but in absence of a systematic mechanism this serendipity can not be leveraged . in that respect , hcs @xcite",
    "may be viewed as a way to do so , and are thus the closest example of construction we have found in the literature , though they do not give any guarantee on the number of blocks needed to repair given the number of losses , i.e. , property ( b ) is not satisfied , and has no deterministic guarantee for achieving property ( a ) either .",
    "we may say that in spirit , src is closest to hierarchical codes - at a very high level , src design features mitigate the drawbacks of hcs .    in this work , we make the following _ contributions _ : + ( i ) we propose a new family of codes , self - repairing codes ( src ) , designed specifically as an alternative to erasure codes ( ec ) for providing redundancy in networked storage systems , which allow repair of individual encoded blocks using only few other encoded blocks .",
    "like ecs , srcs also allow recovery of the whole object using @xmath1 encoded fragments , but unlike in ecs , these are not any arbitrary @xmath1 fragments",
    ". however , numerous specific suitable combinations exist .",
    "+ ( ii ) we provide a deterministic code construction called _ homomorphic self - repairing code _ ( hsrc ) , showcasing that src codes can indeed be realized .",
    "+ ( iii ) hsrc self - repair operations are computationally efficient .",
    "it is done by xoring encoded blocks , each of them containing information about all fragments of the object , though the encoding itself is done through polynomial evaluation , not by xoring .",
    "+ ( iv ) we show that for equivalent static resilience , marginally more storage is needed than traditional erasure codes to achieve self - repairing property .",
    "+ ( v ) the need of few blocks to reconstruct a lost block naturally translates to low overall bandwidth consumption for repair operations .",
    "srcs allow for both eager as well as lazy repair strategies for equivalent overall bandwidth consumption for a wide range of practical system parameter choices .",
    "they also outperform lazy repair with the use of traditional erasure codes for many practical parameter choices .",
    "+ ( vi ) we show that by allowing parallel and independent repair of different encoded blocks , srcs facilitate fast replenishment of lost redundancy , allowing a much quicker system recovery from a vulnerable state than is possible with traditional codes .",
    "since this work aims at designing specifically tailored codes for networked storage systems , we first briefly recall the mechanisms behind erasure codes design . in what follows , we denote by @xmath5 the finite field with @xmath6 elements , and by @xmath7 the finite field without the zero element . if @xmath8 , an element @xmath9 can be represented by an @xmath10-dimensional vector @xmath11 where @xmath12 , @xmath13 , coming from fixing a basis , namely @xmath14 where @xmath15 forms a @xmath16-basis of @xmath5 , and @xmath17 is a root of an irreducible monic polynomial of degree @xmath10 over @xmath16 .",
    "the finite field @xmath16 is nothing else than the two bits 0 and 1 , with addition and multiplication modulo 2 .",
    "a linear @xmath18 erasure code over a @xmath6-ary alphabet is formally a linear map @xmath19 which maps a @xmath1-dimensional vector @xmath20 to an @xmath3-dimensional vector @xmath21 .",
    "the set @xmath22 of codewords @xmath21 , @xmath23 , forms the code ( or codebook ) .",
    "the third parameter @xmath24 refers to the minimum distance of the code : @xmath25 where the hamming distance @xmath26 counts the number of positions at which the coefficients of @xmath27 and @xmath28 differ .",
    "the minimum distance describes how many erasures can be tolerated , which is known to be at most @xmath4 , achieved by maximum distance separable ( mds ) codes .",
    "mds codes thus allow to recover any codeword out of @xmath1 coefficients .",
    "let @xmath29 be an object of size @xmath30 bits , that is @xmath31 , and let @xmath1 be a positive integer such that @xmath1 divides @xmath30 .",
    "we can write @xmath32 which requires the use of a @xmath0 code over @xmath33 , that maps @xmath29 to an @xmath34-dimensional binary vector @xmath27 , or equivalently , an @xmath3-dimensional vector @xmath35      since the work of reed and solomon @xcite , it is known that linear coding can be done via polynomial evaluation . in short , take an object @xmath36 of size @xmath30 , with each @xmath37 in @xmath33 , and create the polynomial @xmath38.\\ ] ] now evaluate @xmath39 in @xmath3 elements @xmath40 , to get the codeword @xmath41    [ ex : exrs23 ] suppose the object @xmath42 has 4 bits , and we want to make @xmath43 fragments : @xmath44 , @xmath45 .",
    "we use a @xmath46 reed - solomon code over @xmath47 , to store the file in 3 nodes . recall that @xmath48 where @xmath49 .",
    "thus we can alternatively represent each fragment as : @xmath50 , @xmath51 .",
    "the encoding is done by first mapping the two fragments into a polynomial @xmath52 $ ] : @xmath53 and then evaluating @xmath39 into the three non - zero elements of @xmath47 , to get a codeword of length 3 : @xmath54 where @xmath55 , @xmath56 , @xmath57 , so that each node gets two bits to store : @xmath58 at node 1 , @xmath59 at node 2 , @xmath60 at node 3 .",
    "encoding linearly data as explained in section [ sec : lincod ] can be done with arbitrary polynomials .",
    "we now first describe a particular class of polynomials that will play a key role in the construction of homomorphic codes , a class of self - repairing codes presented in subsection [ subsec : src ] .",
    "since we work over finite fields that contains @xmath16 , recall that all operations are done in characteristic 2 , that is , modulo 2 .",
    "let @xmath61 , for some @xmath62 .",
    "then we have that @xmath63 and consequently @xmath64 recall the definition of a linearized polynomial .",
    "a _ linearized polynomial _ @xmath39 over @xmath5 , @xmath8 , has the form @xmath65    we now define a _ weakly linearized polynomial _ as    a _ weakly linearized polynomial _ @xmath39 over @xmath5 , @xmath8 , has the form @xmath66    we will see below why we chose this name .",
    "we use the notation @xmath1 since later on it will indeed correspond to the number of data symbols that can be encoded with the proposed scheme .",
    "we start with a useful property of such polynomials .",
    "[ lem : sr ] let @xmath61 and let @xmath39 be a weakly linearized polynomial given by @xmath67 .",
    "we have @xmath68    note that if we evaluate @xmath39 in an element @xmath69 , we get , using ( [ eq : frob ] ) , that @xmath70    we can strengthen the above lemma by considering instead a polynomial @xmath39 over @xmath5 , @xmath8 , of the form : @xmath71 where @xmath72 , @xmath73 ( @xmath74 makes @xmath39 a linearized polynomial ) .",
    "we now get :    let @xmath61 and let @xmath39 be the polynomial given by @xmath75 , @xmath72 , @xmath76 .",
    "we have @xmath77    if we evaluate @xmath39 in @xmath78 , we get @xmath79 again by ( [ eq : frob ] ) , and @xmath80 using the property that @xmath81 for @xmath82 .",
    "we now mimic the way encoding works for reed - solomon codes ( see subsection [ subsec : encodpoly ] ) for weakly linearized polynomials . note that neither the encoding nor the decoding process described below are actual efficient algorithms .",
    "implementations of these processes is a separate issue to be dealt with .    1 .",
    "take an object @xmath29 of length @xmath30 , with @xmath1 a positive integer that divides @xmath30 .",
    "decompose @xmath29 into @xmath1 fragments of length @xmath83 : @xmath84 2 .",
    "take a linearized polynomial with coefficients in @xmath33 @xmath85 and encode the @xmath1 fragments as coefficients , namely take @xmath86 , @xmath87 .",
    "3 .   evaluate @xmath39 in @xmath3 non - zero values @xmath88 of @xmath33 to get a @xmath3-dimensional codeword @xmath89 and each @xmath90 is given to node @xmath91 for storage .",
    "in particular , we need @xmath92    1 .   given @xmath1 linearly independent fragments , the node that wants to reconstruct the file computes @xmath93 linear combinations of the @xmath1 fragments , which gives @xmath93 points in which @xmath94 is evaluated .",
    "lagrange interpolation guarantees that it is enough to have @xmath95 points ( which we have since @xmath96 for @xmath97 ) to reconstruct uniquely the polynomial @xmath94 and thus the data file .",
    "this requires @xmath98    a codeword constructed with the above procedure is of the form @xmath99 , where each coefficient is in @xmath33 and @xmath100 .",
    "we will denote by @xmath101 the maximum value that @xmath3 can take , namely @xmath102 .",
    "we know that @xmath33 contains a @xmath16-basis @xmath103 with @xmath83 linearly independent elements .",
    "if @xmath104 , the @xmath105 , @xmath106 , can be expressed as @xmath16-linear combinations of the basis elements , and we have from lemma [ lem : sr ] that @xmath107 in words , that means that an encoded fragment can be obtained as a linear combination of other encoded fragments . in terms of computational complexity , this further implies that the cost of a block reconstruction is that of some xors ( one in the most favorable case , when two terms are enough to reconstruct a block , up to @xmath108 in the worst case ) . on the other hand ,",
    "if @xmath88 are contained in @xmath109 , then the code has no self - repairing property .    for any choice of a positive integer @xmath1 that divides @xmath30",
    ", we work in the finite field @xmath33 . to do explicit computations in this finite field , it is convenient to use the generator of the multiplicative group @xmath110 , that we will denote by @xmath17 .",
    "a generator has the property that @xmath111 , and there is no smaller positive power of @xmath17 for which this is true .",
    "[ ex : complete]take a data file @xmath112 of @xmath113 bits , and choose @xmath114 fragments .",
    "we have that @xmath115 , which satisfies ( [ eq : boundk ] ) , that is @xmath116 .",
    "the file @xmath29 is cut into 3 fragments @xmath117 , @xmath118 , @xmath119 .",
    "let @xmath17 be a generator of the multiplicative group of @xmath120 , such that @xmath121 .",
    "the polynomial used for the encoding is @xmath122 the @xmath3-dimensional codeword is obtained by evaluating @xmath39 in @xmath3 elements of @xmath123 , @xmath124 by ( [ eq : boundn ] ) .    for @xmath125 , if we evaluate @xmath39 in @xmath126 , @xmath127 , then the 4 encoded fragments @xmath128 are linearly independent and there is no self - repair possible .",
    "now for @xmath129 , and say , @xmath130 , we get : @xmath131 note that @xmath132 suppose node 5 which stores @xmath133 goes offline .",
    "a new comer can get @xmath133 by asking for @xmath134 and @xmath135 , since @xmath136 table [ tab : enumerate ] shows other examples of missing fragments and which pairs can reconstruct them , depending on if 1 , 2 , or 3 fragments are missing at the same time .",
    ".ways of reconstructing missing fragment(s ) in example [ ex : complete ] [ cols=\"^,^ \" , ]     a potential schedule to download the available blocks at different nodes to recreate the missing fragments is as follows : in first time slot , @xmath137 , @xmath138 , @xmath139 , nothing , @xmath140 , @xmath141 and @xmath142 are downloaded separately by seven nodes trying to recreate each of @xmath143 respectively . in second time",
    "slot @xmath139 , @xmath142 , @xmath141 , @xmath138 , @xmath137 , @xmath140 and @xmath144 are downloaded .",
    "note that , besides @xmath145 , all the other missing blocks can now already be recreated . in third time slot ,",
    "@xmath139 can be downloaded to recreate it .",
    "thus , in this example , six out of the seven missing blocks could be recreated within the time taken to download two fragments , while the last block could be recreated in the next time round , subject to the constraints that any node could download or upload only one block in unit time .",
    "even if a full copy of the object ( hybrid strategy @xcite ) were to be maintained in the system , with which to replenish the seven missing blocks , it would have taken seven time units . while , if no full copy was maintained , using traditional erasure codes would have taken at least nine time units .",
    "this example demonstrates that src allows for fast reconstruction of missing blocks .",
    "orchestration of such distributed reconstruction to fully utilize this potential in itself poses interesting algorithmic and systems research challenges which we intend to pursue as part of future work .",
    "we propose a new family of codes , called self - repairing codes , which are designed by taking into account specifically the characteristics of distributed networked storage systems .",
    "self - repairing codes achieve excellent properties in terms of maintenance of lost redundancy in the storage system , most importantly : ( i ) low - bandwidth consumption for repairs ( with flexible / somewhat independent choice of whether an eager or lazy repair strategy is employed ) , ( ii ) parallel and independent ( thus very fast ) replenishment of lost redundancy .",
    "when compared to erasure codes , the self - repairing property is achieved by marginally compromising on static resilience for same storage overhead , or conversely , utilizing marginally more storage space to achieve equivalent static resilience .",
    "this paper provides the theoretical foundations for srcs , and shows its potential benefits for distributed storage .",
    "there are several algorithmic and systems research challenges in harnessing srcs in distributed storage systems , e.g. , design of efficient decoding algorithms , or placement of encoded fragments to leverage on network topology to carry out parallel repairs , which are part of our ongoing and future work .",
    "99 r. bhagwan , k. tati , y. cheng , s. savage , g. voelker , `` total recall : system support for automated availability management '' , _ networked systems design and implementation ( nsdi ) _ , 2004 .",
    "a. g. dimakis , p. brighten godfrey , m. j. wainwright , k. ramchandran , `` the benefits of network coding for peer - to - peer storage systems '' , _",
    "workshop on network coding , theory , and applications ( netcod ) _ , 2007 .",
    "a. g. dimakis , p. brighten godfrey , y. wu , m. o. wainwright , k. ramchandran , `` network coding for distributed storage systems '' , available online at",
    "_ http://arxiv.org / abs/0803.0632_. a. datta , k. aberer , `` internet - scale storage systems under churn  a study of the steady - state using markov models '' , _ peer - to - peer computing ( p2p ) _ , 2006 .",
    "a. duminuco , e. biersack , `` hierarchical codes : how to make erasure codes attractive for peer - to - peer storage systems '' , _ peer - to - peer computing ( p2p ) _ , 2008 .",
    "a. duminuco , e.w .",
    "biersack , `` a practical study of regenerating codes for peer - to - peer backup systems '' , _ intl .",
    "conference on distributed computing systems ( icdcs ) _ , 2009 .",
    "x. liu , a. datta , `` redundancy maintenance and garbage collection strategies in peer - to - peer storage systems '' , _ intl .",
    "symposium on stabilization , safety , and security of distributed systems ( sss ) _ 2009 .",
    "d. grolimund , `` wuala - a distributed file system '' , google tech talk _",
    "k. v. rashmi , n. b. shah , p. v. kumar and k. ramchandran , `` explicit construction of optimal exact regenerating codes for distributed storage '' , _ allerton conf . on control , computing and comm .",
    "i. s. reed and g. solomon , `` polynomial codes over certain finite fields '' , _ journal of the society for industrial and appl . mathematics _ , no 2 , vol . 8 , siam , 1960 .",
    "r. rodrigues and b. liskov , `` high availability in dhts : erasure coding vs. replication '' , _ workshop on peer - to - peer systems ( iptps ) _ 2005 ."
  ],
  "abstract_text": [
    "<S> erasure codes provide a storage efficient alternative to replication based redundancy in ( networked ) storage systems . </S>",
    "<S> they however entail high communication overhead for maintenance , when some of the encoded fragments are lost and need to be replenished . </S>",
    "<S> such overheads arise from the fundamental need to recreate ( or keep separately ) first a copy of the whole object before any individual encoded fragment can be generated and replenished . </S>",
    "<S> there has been recently intense interest to explore alternatives , most prominent ones being regenerating codes ( rgc ) and hierarchical codes ( hc ) . </S>",
    "<S> we propose as an alternative a new family of codes to improve the maintenance process , which we call _ self - repairing codes _ ( src ) , with the following salient features : ( a ) encoded fragments can be repaired directly from other subsets of encoded fragments without having to reconstruct first the original data , ensuring that ( b ) a fragment is repaired from a fixed number of encoded fragments , the number depending only on how many encoded blocks are missing and independent of which specific blocks are missing . </S>",
    "<S> these properties allow for not only low communication overhead to recreate a missing fragment , but also independent reconstruction of different missing fragments in parallel , possibly in different parts of the network . </S>",
    "<S> the fundamental difference between srcs and hcs is that different encoded fragments in hcs do not have symmetric roles ( equal importance ) . </S>",
    "<S> consequently the number of fragments required to replenish a specific fragment in hcs depends on which specific fragments are missing , and not solely on how many . </S>",
    "<S> likewise , object reconstruction may need different number of fragments depending on which fragments are missing . </S>",
    "<S> rgcs apply network coding over @xmath0 erasure codes , and provide network information flow based limits on the minimal maintenance overheads . </S>",
    "<S> rgcs need to communicate with at least @xmath1 other nodes to recreate any fragment , and the minimal overhead is achieved if only one fragment is missing , and information is downloaded from all the other @xmath2 nodes . </S>",
    "<S> we analyze the _ static resilience _ of srcs with respect to traditional erasure codes , and observe that srcs incur marginally larger storage overhead in order to achieve the aforementioned properties . </S>",
    "<S> the salient src properties naturally translate to _ low communication overheads _ for reconstruction of lost fragments , and allow reconstruction with lower latency by facilitating _ </S>",
    "<S> repairs in parallel_. these desirable properties make self - repairing codes a good and practical candidate for networked distributed storage systems .    </S>",
    "<S> * keywords : * coding , networked storage , self - repair </S>"
  ]
}