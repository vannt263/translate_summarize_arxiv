{
  "article_text": [
    "the understanding of the intrinsic difficulty of approximation of @xmath1-variate problems is a challenging problem especially when @xmath1 is large .",
    "we consider algorithms that approximate @xmath1-variate problems and use finitely many linear functionals : we compare the class @xmath2 of arbitrary linear information functionals with the class @xmath3 of information functionals that are given by function evaluations at single points .    to find best algorithms for the class @xmath2 is usually much easier than for the class @xmath3 , in particular if the source space is a hilbert space .",
    "this is especially the case for the worst case setting .",
    "the state of art may be found in @xcite , where the reader may find a number of surprising results .",
    "for example , there are multivariate problems for which the best rate of convergence of algorithms using @xmath4 appropriately chosen linear functionals is @xmath5 whereas for @xmath4 function values the best rate can be arbitrarily bad , i.e. , like @xmath6 , where the number of @xmath7 can be arbitrarily large , see @xcite which is also reported in @xcite pp .",
    "292 - 304 .",
    "furthermore , the dependence on @xmath1 may be quite different for the linear and standard classes .",
    "there are examples of interesting multivariate problems for which the dependence on @xmath1 _ is not _",
    "exponential for the class @xmath2 , and _ is _ exponential for the class @xmath3 .",
    "the exponential dependence on @xmath1 is called the _ curse of dimensionality_. on the other hand , for some other multivariate problems there is no difference between @xmath2 and @xmath3 .",
    "examples can be found , in particular , in @xcite and @xcite .",
    "tractability deals with how the intrinsic difficulty of a multivariate problem depends on @xmath1 and on @xmath8 , where @xmath9 is an error threshold .",
    "we would like to know when the curse of dimensionality holds and when we have a specific dependence on @xmath1 which is not exponential .",
    "there are various ways of measuring the lack of exponential dependence and that leads to different notions of tractability .",
    "in particular , we have polynomial tractability ( pt ) if the intrinsic difficulty is polynomial in both @xmath1 and @xmath8 .",
    "we have quasi - polynomial tractability ( qpt ) if the intrinsic difficulty is at most proportional to @xmath10 for some @xmath11 independent of @xmath1 and @xmath9 .    obviously , tractability may depend on which of the classes @xmath3 or @xmath2 is used .",
    "tractability results for @xmath3 can not be better than for @xmath2",
    ". the main question is for which multivariate problems they are more or less the same or for which multivariate problems they are essentially different .",
    "these questions were already addressed in @xcite .",
    "still , especially the worst case setting is not fully understood .",
    "we would like to get a better understanding how the power of the standard class @xmath3 is related to the power of the class @xmath2 of information .",
    "ideally , we would like to characterize for which multivariate problems the classes @xmath3 and @xmath2 lead to more or less the same tractability results and for which tractability results are essentially different .",
    "we plan to write a number of papers about this problem under the same title .",
    "we present the first part of this project .",
    "we restrict ourselves to linear multivariate problems defined as approximation of a linear continuous operator @xmath12 for general hilbert spaces @xmath13 and  @xmath14 . since we want to study the class @xmath3 we need to assume that function values are well defined and they correspond to linear continuous functionals .",
    "this is equivalent to assuming that @xmath13 is a reproducing kernel hilbert space .",
    "for the worst case setting and for the class @xmath2 , it is known what is the best way to approximate @xmath15 .",
    "the intrinsic difficulty of approximating @xmath15 is defined as the _ information complexity _ which is the minimal number of linear functionals which are needed to find an algorithm whose worst case error is at most  @xmath16 .",
    "this depends on the eigenvalues of the operator @xmath17 . for the class @xmath3",
    "the situation is much more complex and the _ information complexity _",
    ", which is now the minimal number of function values needed to get an error @xmath16 , depends not only on the eigenvalues of @xmath18 .",
    "our first result is the construction of continuous linear functionals @xmath19 which are at most as hard to approximate as @xmath15 for the class @xmath3 .",
    "furthermore , we characterize @xmath19 for which @xmath20 .",
    "they are of the form @xmath21 where @xmath22 is the largest eigenvalue of @xmath18 and @xmath23 of norm @xmath24 belongs to the eigenspace corresponding to @xmath22 .",
    "hence , if @xmath22 is of multiplicity @xmath24 then the choice of @xmath25 is essentially unique .",
    "if @xmath22 is of multiplicity larger than @xmath24 , then the choice of @xmath25 is not unique and may lead to trivial or hard linear functionals @xmath19 .    for @xmath19 with @xmath20 ,",
    "the information complexity of @xmath19 for the class @xmath3 is at most equal to the information complexity of @xmath15 .",
    "hence , if @xmath19 is hard to approximate so is @xmath15 .",
    "the essence of this result is that for approximation of linear functionals over some hilbert spaces there is a proof technique which allows to find sharp error bounds .",
    "this proof technique was developed in @xcite and requires that the reproducing kernel of @xmath26 has a so called decomposable part .",
    "we verify how this lower bound on approximating @xmath15 works for linear @xmath1-folded ( unweighted ) tensor product problems",
    ". then the corresponding linear functionals @xmath19 are also @xmath1-folded tensor products .",
    "we then may apply the existing negative tractability results for @xmath19 and conclude the same negative tractability results for @xmath15 .",
    "we illustrate our approach for a number of examples .",
    "in particular , we consider the sobolev space @xmath27 with the reproducing kernel @xmath28^d,\\ ] ] and @xmath29^d)$ ] .",
    "let @xmath30 be any non - zero tensor product operator @xmath31 with @xmath32 .",
    "let @xmath33 be the ordered sequence of eigenvalues of @xmath34 .",
    "let @xmath35 denote the polynomial decay of the eigenvalues @xmath36 .",
    "if the set of @xmath37 above is empty we set @xmath38 .",
    "let @xmath39 .",
    "it is known , see @xcite , that @xmath40 is quasi - polynomially tractable ( qpt ) for the class @xmath2 iff @xmath41 and @xmath42 . furthermore , if @xmath43 is positive then @xmath40 is not polynomially tractable ( pt ) . on the other hand , if @xmath44 then @xmath40 suffers from the curse of dimensionality for the class @xmath2 ( and obviously also for @xmath3 ) .    for the class @xmath3 , assume without loss of generality that @xmath41",
    "let @xmath45 be a normalized eigenfunction corresponding to the largest eigenvalue @xmath22 .",
    "we prove that @xmath40 suffers from the curse of dimensionality if @xmath46.\\ ] ] this means that we have the curse of dimensionality as long as the eigenfunction of @xmath47 corresponding to the largest eigenvalue is not proportional to the univariate reproducing kernel with one argument fixed .",
    "we then verify that this assumption holds for multivariate approximation , i.e. , for @xmath48 .",
    "this partially solves the open problem 131 from @xcite p. 361 .",
    "we believe that the assumption   is also necessary for the curse . more generally , we believe that for @xmath49 for some real @xmath50 and @xmath11 from the common domain of univariate functions , and of course for @xmath41 and @xmath42 , we have qpt for the class @xmath3 and this holds for any @xmath51 . but this will be the subject of the next part of our project .    in this paper",
    "we discuss only unweighted tensor products and that is why we do not have polynomial tractability ( pt ) for problems with two positive eigenvalues .",
    "pt and other notions of tractability may hold if we consider weighted tensor products with sufficiently decaying weights",
    ". this will be also a subject of our next study .",
    "consider a continuous linear and non - zero operator @xmath12 , where @xmath13 is a reproducing kernel hilbert space of real functions @xmath52 defined over a common domain @xmath53 for some positive integer @xmath1 , and @xmath14 is a hilbert space .",
    "we approximate @xmath15 by algorithms  @xmath54 that use at most  @xmath4 linear functionals . without loss of generality",
    "we may assume that @xmath54 is linear , see e.g. , @xcite .",
    "that is , @xmath55 for some @xmath56 and @xmath57 .",
    "using the same proof as in @xcite p. 345 , we may also assume that @xmath58 for some @xmath59 .",
    "we consider two classes of linear functionals @xmath60 s :    * the linear class of information @xmath2 which consists of all continuous and linear functionals @xmath60 s , i.e. , @xmath61 , and * the standard class of information @xmath3 which consists of function values , i.e. , @xmath62 for some @xmath63 , where @xmath64 is the reproducing kernel of @xmath13 .",
    "the @xmath4th minimal ( worst case ) error of approximating @xmath15 for the class @xmath65 is defined as @xmath66 for @xmath67 , we take @xmath68 and then we obtain the initial error which is independent of @xmath69 and given by @xmath70    for the class @xmath2 , it is well known that @xmath71 iff @xmath15 is compact .",
    "this is why we always may assume that @xmath15 is compact .",
    "then it is known that the @xmath4th minimal errors depend on the eigenvalues of @xmath72 more precisely , let @xmath73 be eigenpairs of @xmath74 , @xmath75 observe here that the @xmath76 are uniquely defined , but the @xmath77 are not unique .",
    "moreover , we formally define @xmath78 if the dimension of @xmath13 is finite and @xmath79 is larger than this dimension",
    ". then @xmath80 hence @xmath81 , and since @xmath15 is non - zero we have @xmath82 .",
    "the situation is much more complicated for the class @xmath3 .",
    "obviously , @xmath83 but it is not clear when the sequences @xmath84 and @xmath85 behave similarly .",
    "there are many papers studying the powers of @xmath3 and @xmath2 .",
    "the state of art can be found in  @xcite . in this paper",
    "we continue this study and show that the sequence @xmath84 can behave quite differently than the sequence @xmath85 .",
    "this will be done by showing first that many continuous and linear functionals are at most as hard to approximate as @xmath15 and there are functionals for which we can also match the initial error @xmath86 of @xmath15 .    more precisely , for any @xmath87 with @xmath88 define @xmath89 note that @xmath90 and therefore @xmath91 is a continuous linear functional .",
    "the @xmath4th minimal error of approximating @xmath91 is defined as for @xmath15 , this time with @xmath14 replaced by @xmath92 .",
    "clearly , @xmath93 .",
    "[ thm1 ]    for any @xmath87 with @xmath88 we have @xmath94 furthermore , @xmath95 where @xmath23 is any element of norm @xmath24 with @xmath96 .",
    "take an arbitrary linear algorithm @xmath97 for approximating @xmath15 .",
    "define @xmath98 as a linear algorithm for approximating @xmath91 .",
    "then @xmath99 therefore @xmath100 taking the supremum over the unit ball of @xmath13 and then the infimum over @xmath101 s and @xmath102 s , we conclude that @xmath103 as claimed .",
    "let @xmath104 be the multiplicity of the largest eigenvalue @xmath22 , i.e. , @xmath105 is the eigenspace of @xmath74 for the eigenvalue @xmath22 .",
    "take now @xmath106 for any @xmath107 with @xmath108 .",
    "then we have @xmath109 and @xmath110 furthermore , @xmath111 we need to show that @xmath112 holds only for such @xmath25 .",
    "take then any @xmath25 from @xmath14 such that @xmath88 and @xmath113 .",
    "we can represent @xmath114 where @xmath107 with @xmath115 , @xmath116 and @xmath117 is orthogonal to @xmath118 for all @xmath119 , i.e. , @xmath120 since @xmath121 we have @xmath122 on the other hand , @xmath123 we now analyze @xmath124 . note that @xmath125 .",
    "let @xmath126^{\\perp}.    \\ ] ] hence , for any @xmath117 from @xmath14 we have @xmath127 with @xmath128 and @xmath129 orthogonal to @xmath130 .",
    "then @xmath131 let @xmath132 . hence , if all @xmath133 then @xmath134 , otherwise @xmath135 is the number of positive eigenvalues @xmath76 .",
    "clearly , @xmath136 .",
    "we know that @xmath137 .",
    "then @xmath138 for all finite @xmath79 which are at most @xmath135 . multiplying the last equation by @xmath15 we obtain @xmath139",
    "hence , @xmath140 is an eigenpair of @xmath141 and @xmath142 that means that @xmath143 s are orthonormal in @xmath14 . since @xmath144 ,",
    "the @xmath143 s build a complete orthonormal system of @xmath130 and , when we return to , we may write @xmath145 and then @xmath146 since @xmath147 for all @xmath148 , we conclude that @xmath149 from this , we get @xmath150 since @xmath151 we conclude that @xmath152 and @xmath153 with @xmath154 .",
    "this completes the proof .    for any @xmath25 from @xmath14",
    "the linear functional @xmath91 can be also written as @xmath155    as an example , if we take @xmath156^d)$ ] then @xmath157^d}(sf)(x)\\,g(x)\\,{\\rm d}x.\\ ] ] furthermore , if we additionally assume that @xmath13 is continuously embedded in @xmath158^d)$ ] and take @xmath159 as multivariate approximation , @xmath160 for all @xmath161 , then @xmath157^d}f(x)\\,g(x)\\,{\\rm d}x.\\ ] ] if @xmath162 then @xmath163^d}f(x)\\,{\\rm d}x\\ ] ] is multivariate integration , and @xmath164 this relation between multivariate integration and approximation has been used in many papers . for some spaces",
    "the norm of multivariate integration and approximation is the same .",
    "this is the case for korobov spaces and some sobolev spaces as will be reported later .",
    "however , in general , the norm of multivariate integration is smaller and sometimes exponentially smaller than the norm of multivariate approximation .",
    "this is the case for some other sobolev spaces .",
    "for instance , this holds for the space @xmath165 with the reproducing kernel @xmath166.\\ ] ] it is known , see @xcite pp . 353 and 411 , that @xmath167 hence , @xmath168 although @xmath169 is barely larger than one , the ratio of the initial errors for multivariate approximation and integration goes to infinity exponentially fast with @xmath1 .",
    "as we shall see , the multiplicity of the largest eigenvalue for this multivariate approximation is @xmath170 .",
    "therefore , in order to match the norm of multivariate approximation we must use a weighted integration problem @xmath171 with @xmath172 ( or @xmath173 ) which for our example of @xmath174 is not equal to the constant function @xmath24 . in section",
    "[ unweighted ] we will show that @xmath175 for @xmath176\\in[0,1]^d$ ] .",
    "we find it interesting to know the `` most difficult '' integration problem @xmath91 ( with @xmath177 ) for a hilbert space of functions and hence present the graph of the function @xmath178 in figure 1 .",
    "the same @xmath25 is also the unique ( up to a multiplicative constant ) function that maximizes @xmath179 and hence solves an important optimization problem .",
    "for which @xmath180,width=377 ]    we now show that the choice of @xmath23 in @xmath106 may be important if the multiplicity of  @xmath22 is larger than @xmath24 .",
    "that is , it may happen that for some such @xmath25 the functional @xmath91 is trivial and for some other @xmath25 , it may be very difficult .",
    "let @xmath26 be the space of functions @xmath181 \\to { \\mathbb{r}}$ ] that are constant over @xmath182 $ ] and @xmath183 $ ] .",
    "that is , for @xmath184 there are real @xmath50 and @xmath185 such that @xmath186 for all @xmath187 $ ] and @xmath188 for all @xmath189 $ ] .",
    "we equip @xmath26 with the @xmath0 norm which can be written ( for the space @xmath26 ) as @xmath190 we define @xmath191 as the @xmath1 folded tensor product of the space @xmath26 .",
    "the space @xmath13 consists of piecewise constant functions over @xmath192 subintervals of volume @xmath193 which are a partition of the cube @xmath194^d$ ] .",
    "the space @xmath174 is also equipped with the @xmath0 norm . clearly , @xmath195 .",
    "let @xmath12 be the identity operator .",
    "then @xmath196 for all @xmath197 and any nonzero function from @xmath13 is an eigenfunction of @xmath198 .",
    "clearly , @xmath199 and therefore @xmath200 obviously , it also proves that @xmath201 for @xmath202 since @xmath203 .    for any",
    "@xmath25 of norm @xmath24 we have @xmath204 .",
    "we now show that @xmath205 very much depends on the choice of @xmath25 .",
    "suppose we take @xmath206 over @xmath182^d$ ] and @xmath207 otherwise .",
    "then @xmath208^d}f(x)\\,{\\rm d}x=2^{-d/2}\\,f(0)\\ ] ] is a trivial linear functional which can be solved exactly by using one function value at  @xmath209 .",
    "hence , @xmath210 in this case , the bound @xmath211 is useless .",
    "take now @xmath212 over the cube @xmath194^d$ ] .",
    "then @xmath213^d}f(x)\\,{\\rm d}x=\\frac1{2^d}\\,\\sum_{j=[j_1,j_2,\\dots , j_d]\\in    \\{0,1\\}^d}f(t_{j_1},t_{j_2},\\dots , t_{j_d}),\\ ] ] where @xmath214 and @xmath215 .",
    "we prove that the @xmath4th minimal error for @xmath216 is @xmath217 indeed , for @xmath218 we can sample @xmath52 at all points @xmath219 with @xmath220 and recover  @xmath91 exactly .",
    "therefore @xmath221 .",
    "assume now that @xmath202 .",
    "suppose we sample @xmath52 at some @xmath222 from the unit cube @xmath194^d$ ] .",
    "then it is enough to take @xmath52 which is zero at @xmath4 sub - cubes that contain samples @xmath222 , and which takes a constant value @xmath223 at @xmath224 sub - cubes .",
    "taking @xmath223 for which the norm is @xmath24 we obtain the equation @xmath225 which yields @xmath226 . then @xmath227 all linear algorithms must approximate @xmath228 by zero and therefore their worst case error is at least @xmath229 .",
    "the last bound is sharp if we take sample points @xmath222 at disjoint sub - cubes , as claimed .",
    "hence , in this case we have @xmath230 the bound is quite sharp as long as @xmath4 is much smaller than @xmath192 .    for general spaces , we will use theorem  [ thm1 ] for @xmath91 with @xmath231 . for the standard class of information",
    "@xmath3 , using lower bounds results for @xmath91 from @xcite , we obtain lower bounds results for @xmath15 . in this way",
    "we show , in particular , that we have sometimes the curse of dimensionality for  @xmath3 which is not present for the class @xmath2 .",
    "we need to recall the definition of the information complexity for the so - called normalized error criterion .",
    "it is defined as the minimal number of linear functionals from the class @xmath69 which are needed to reduce the initial error by a factor @xmath232 , where @xmath65 .",
    "that is , @xmath233 for the class @xmath2 , we obviously have @xmath234 unfortunately , there is no such or similar formula for the class @xmath3 .",
    "assume now that we have a sequence @xmath235 of continuous linear non - zero operators @xmath236 , where @xmath174 is a reproducing kernel hilbert space of real function defined over @xmath237 and @xmath238 is a hilbert space .",
    "in this case , we want to verify how the information complexity @xmath239 depends on @xmath8 and @xmath1 .",
    "in this paper we will use only a few tractability notions which are defined as follows .",
    "we say that    * @xmath40 suffers from the curse of dimensionality for the class @xmath65 iff there are positive numbers @xmath223 and @xmath240 as well as @xmath241 such that @xmath242 for all @xmath243 $ ] and infinitely many @xmath1 .",
    "* @xmath40 is quasi - polynomially tractable ( qpt ) for the class @xmath69 iff there are non - negative numbers @xmath240 and @xmath11 such that @xmath244 the infimum of numbers @xmath11 satisfying the bound above is called the exponent of qpt and denoted by @xmath245 .",
    "* @xmath40 is polynomially tractable ( pt ) for the class @xmath69 iff there are nonnegative numbers @xmath246 such that @xmath247    clearly , pt implies qpt .",
    "more about these and other tractability concepts can be found in @xcite .",
    "for the class @xmath2 , tractability notions depend on the decay of the eigenvalues @xmath248 of the operator @xmath249 .",
    "necessary and sufficient conditions can be found in the works cited above .",
    "again for the class @xmath3 , no such conditions are known and they can not depend only on the eigenvalues @xmath248 .",
    "from now on we study a sequence @xmath235 of tensor product problems . hence the spaces @xmath250 and @xmath251 as well as @xmath252 are given by tensor products of @xmath1 copies of @xmath26 and @xmath253 as well as a continuous linear operator @xmath32 , respectively , where @xmath26 is a reproducing kernel hilbert space of real univariate functions defined over @xmath254 and @xmath253 is a hilbert space . then @xmath174 is a space of @xmath1-variate real functions defined on @xmath255 ( @xmath1 times ) .    an important example is given by multivariate approximation .",
    "that is , we now take @xmath29^d)$ ] and @xmath256 with the embedding operator @xmath257 .",
    "then @xmath258 is also the embedding operator @xmath259 for all @xmath260 . in this case , we denote @xmath261    if @xmath51 is the reproducing kernel of @xmath26 then @xmath174 is a reproducing kernel hilbert space whose kernel is @xmath262,\\,y=[y_1,y_2,\\dots , y_d]\\in d_d.\\ ] ] for the class @xmath2 , it is well known that the eigenpairs @xmath263 of @xmath264 are given in terms of the eigenpairs @xmath73 of the univariate operator @xmath265 . as before we assume that @xmath266 , @xmath267 and that @xmath47 is non - zero .",
    "this means that @xmath82 . for the operator @xmath268 we have @xmath269 similarly , the eigenfunctions of @xmath268 are of product form @xmath270 where @xmath271(x)=    \\prod_{k=1}^d\\eta_{j_k}(x_k)\\ \\ \\ \\",
    "\\mbox{for all}\\ \\ x=[x_1,\\dots , x_d]\\in d_d.\\ ] ] then @xmath272 .",
    "hence , the initial error is @xmath273 if @xmath44 then we have at least @xmath192 eigenvalues of @xmath268 equal to @xmath274 , and therefore @xmath275 in this case @xmath39 suffers from the curse of dimensionality . on the other hand ,",
    "it is proved in @xcite , see also @xcite p. 112 , that @xmath40 is qpt for the class @xmath2 iff @xmath41 and @xmath276 if the last conditions hold then the exponent of qpt is @xmath277 note that for @xmath278 we have @xmath279 . in this case , @xmath280 is a continuous linear functional and @xmath281 for all @xmath282 and all @xmath283 .",
    "if @xmath284 then the exponent of qpt is positive and in this case it is also known that the problem @xmath40 is _ not _ pt for the class @xmath2 .",
    "we now turn to the class @xmath3 . without loss of generality",
    "we assume that @xmath41 since otherwise @xmath40 suffers from the curse of dimensionality also for the class @xmath3 .",
    "then the choice of the element @xmath25 for which @xmath112 in theorem [ thm1 ] is essentially unique and we take @xmath285 with @xmath286",
    ". we have @xmath287 which is a tensor product since @xmath288 let @xmath289 then @xmath290 is a linear tensor product functional .",
    "we have @xmath291 and @xmath292 .",
    "let @xmath293 theorem  [ thm1 ] yields that @xmath294 this implies the following corollary    [ cor111 ]    if one of the tractability notions does not hold for @xmath295 then it also does not hold for @xmath40 .",
    "we now illustrate corollary  [ cor111 ] for two examples for which @xmath295 is multivariate integration and for which it is known that multivariate integration suffers from the curse of dimensionality .",
    "[ kor ] * korobov space *    as in @xcite , let @xmath26 be a korobov space whose reproducing kernel is @xmath296\\ ] ] for some @xmath297 $ ] and @xmath298 .",
    "this corresponds to the norm @xmath299 of @xmath52 .",
    "we take @xmath300)$ ] and @xmath48 , hence we consider the approximation problem @xmath301 . in this case we know that @xmath302 hence , for @xmath303 multivariate approximation suffers from the curse of dimensionality for @xmath2 ( and of course for @xmath3 ) , and for @xmath304 , multivariate approximation is qpt with the exponent @xmath305    note that @xmath306 . therefore @xmath307 and @xmath308^d}f(x)\\,{\\rm d}x\\ \\ \\ \\ \\mbox{for all }    \\ \\ f\\in f_d\\ ] ] is multivariate integration . from theorem 16.16 on p. 457 in @xcite which is based on @xcite , we know that multivariate integration suffers from the curse of dimensionality .",
    "so does multivariate approximation due to corollary  [ cor111 ] .",
    "* sobolev space *    we now take the sobolev space @xmath26 of absolutely continuous functions on @xmath194 $ ] whose first derivatives are square integrable with the inner product @xmath309 this space has the intriguing reproducing kernel @xmath310,\\ ] ] see @xcite .",
    "we consider the @xmath0 approximation problem , as in example 4 .",
    "hence we have @xmath311 and @xmath312)$ ] .    in this case",
    "we have for @xmath313 that @xmath314 is of multiplicity @xmath24 , and @xmath315 . the second largest eigenvalue satisfies the condition @xmath316 ^ 2\\,{\\rm d}x}=\\frac1{1+\\mu_2},\\ ] ] where @xmath317 ^ 2\\,{\\rm d}x}{\\int_0 ^ 1f^2(x)\\,{\\rm        d}x}.\\ ] ] it is known , see e.g. @xcite , that @xmath318 . hence , have @xmath319 it is well known that @xmath320 so that @xmath321 .",
    "this implies that multivariate approximation for tensor products @xmath27 and @xmath29^d)$ ] is qpt for @xmath2 with the exponent @xmath322 due to the form of @xmath323 , the linear functional @xmath324 corresponds to multivariate integration .",
    "it is known that multivariate integration suffers from the curse , see @xcite which is also reported in @xcite pp .",
    "605 - 606 .",
    "hence , multivariate approximation also suffers the curse of dimensionality for the class @xmath3 due to corollary  [ cor111 ] .",
    "tractability of tensor product functionals @xmath295 was thoroughly studied in @xcite , see also chapters 11 and 12 of @xcite . in particular , for many spaces @xmath26 the problem @xmath295 suffers from the curse of dimensionality for the class @xmath3 .",
    "this holds if the reproducing kernel @xmath51 of @xmath26 has a decomposable part and the univariate function @xmath45 has non - zero components with respect to the decomposable part .",
    "if this is the case then @xmath40 also suffers from the curse of dimensionality for the class @xmath3 although we may have qpt for the class @xmath2 .",
    "we will mention more specific results in the next section .",
    "we now consider tensor product problems @xmath40 defined as in the previous section for the space @xmath26 taken as a sobolev space of univariate real functions defined over @xmath194 $ ] .",
    "more precisely , let @xmath26 be the space of absolutely continuous functions defined over @xmath194 $ ] and whose first derivatives belong to @xmath158)$ ] .",
    "the space @xmath26 has the reproducing kernel @xmath325,\\ ] ] and the inner product for @xmath326 is @xmath327 for the tensor product space @xmath328 of @xmath1 copies of @xmath26 , the inner product for @xmath329 is now of the form @xmath330^{|{{\\mathfrak{u}}}|}}\\frac{\\partial^{|{{\\mathfrak{u}}}|}f}{\\partial x_{{{\\mathfrak{u}}}}}(x_{{\\mathfrak{u}}},0 )    \\frac{\\partial^{|{{\\mathfrak{u}}}|}h}{\\partial x_{{{\\mathfrak{u}}}}}(x_{{\\mathfrak{u}}},0)\\,{\\rm d}x_{{{\\mathfrak{u}}}},\\ ] ] where @xmath331 , @xmath332 and @xmath333 is a @xmath1 dimensional vector with components  @xmath334 for @xmath335 and @xmath209 otherwise .",
    "it was proved in @xcite pp.195 - 200 , see also @xcite , that for any linear non - zero tensor product functional its information complexity ( for @xmath336 ) is @xmath24 or it is exponentially large in @xmath1 .",
    "furthermore , the information complexity is @xmath24 only for trivial cases when the linear tensor product functional is of the form @xmath337 for some non - zero real @xmath50 and for some @xmath338 $ ] . applying this results for @xmath295",
    "we see that as long as @xmath339$}\\ ] ] then @xmath295 as well as @xmath40 suffer from the curse of dimensionality for the class @xmath3 .",
    "we summarize the results from the last two sections in the following theorem .",
    "* let @xmath44 .",
    "then @xmath40 suffers from the curse of dimensionality for @xmath2 ( and @xmath3 ) .",
    "* let @xmath41 .",
    "then @xmath40 is qpt for @xmath2 iff holds .",
    "* let @xmath340 .",
    "then @xmath40 is not pt for the class @xmath2 .",
    "* let @xmath41 .",
    "if holds then @xmath40 suffers from the curse of dimensionality for @xmath3 .    in general ,",
    "the assumption   used in the last part of theorem [ thm2 ] is needed . indeed , if does not hold then we may have @xmath280 as a linear tensor product functional of the form @xmath341 with a nonzero real @xmath50 and @xmath342 $ ] .",
    "then @xmath40 is trivial since @xmath343 for all @xmath282 and all @xmath1 .",
    "we now verify the assumptions and for multivariate approximation @xmath301 .",
    "the eigenpairs @xmath73 were found in @xcite , see also @xcite pp .",
    "409 - 411 .",
    "we have @xmath344 , where @xmath345 is the unique solution of the nonlinear equation @xmath346 and @xmath347,\\ ] ] where @xmath348 for @xmath349 and @xmath350 the numerical computation yields @xmath351 clearly , @xmath352 as @xmath79 tends to infinity .",
    "this shows that @xmath353 therefore @xmath354 . hence holds and @xmath301 is qpt for the class @xmath2 .",
    "the assumption holds if for all @xmath355 and @xmath342 $ ] we can find @xmath356 $ ] such that @xmath357 for @xmath358 , the right hand side is constant , whereas the left hand side varies . for @xmath359 ,",
    "the right hand side is constant over @xmath360 $ ] , whereas the left hand side varies . therefore also holds .",
    "we summarize this in the following corollary .",
    "we add in passing that a similar analysis can be done if the reproducing kernel   is replaced by @xmath362,\\ ] ] for any @xmath363 $ ] or by @xmath364.\\ ] ] for these variants of the sobolev spaces , corollary  [ cor1 ] is valid .",
    "we conclude this paper with a comment on the rates of convergence and tractability notions for @xmath365 and @xmath336 . in @xcite ,",
    "the @xmath0 approximation problem was studied .",
    "it was shown that there are classes @xmath13 for which the best rate of convergence of algorithms using @xmath4 appropriately chosen linear functionals is @xmath5 whereas for @xmath4 function values the best rate can be arbitrarily bad . if the best rate for @xmath365 is faster than @xmath5 than we still do not know whether the rates for @xmath336 and @xmath365 always coincide .",
    "for the examples in this section the rates for @xmath336 and @xmath365 are basically ( up to log terms )  @xmath366 but tractability properties for @xmath365 and @xmath336 are quite different . hence , even if the rates are the same , tractability properties can be quite different for @xmath365 and @xmath336 ."
  ],
  "abstract_text": [
    "<S> we present a lower error bound for approximating linear multivariate operators defined over hilbert spaces in terms of the error bounds for appropriately constructed linear functionals as long as algorithms use function values . </S>",
    "<S> furthermore , some of these linear functionals have the same norm as the linear operators . </S>",
    "<S> we then apply this error bound for linear ( unweighted ) tensor products . in this way we use negative tractability results known for linear functionals to conclude the same negative results for linear operators . </S>",
    "<S> in particular , we prove that @xmath0-multivariate approximation defined for standard sobolev space suffers the curse of dimensionality if function values are used although the curse is not present if linear functionals are allowed . </S>"
  ]
}