{
  "article_text": [
    "spectral clustering groups together related data points and separates unrelated data points , using spectral graph theory , i.e. , spectral properties of matrices associated with the graph , such as graph adjacency and laplacian matrices ; see , e.g. ,  @xcite .",
    "internet search for `` spectral clustering '' nowadays returns over 200,000 links , 25,000 scholar publications , and 1,000 patent applications .",
    "the graph laplacian matrix is obtained from the graph adjacency matrix that represents graph edge weights describing similarities of graph vertices .",
    "the graph weights are commonly defined using a distance function measuring similarity between data points , where graph vertices represent the data points and graph edges are drawn between pairs of vertices , e.g. ,  if the distance between the corresponding data points has been measured .",
    "classical spectral clustering bi - partitions the graph according to the signs of the components of the fiedler vector ; see @xcite .    some important applications , e.g. ,  slashdot zoo @xcite and correlation @xcite clustering , naturally lead to signed graphs , i.e. , both with positive and _ negative _ weights . negative values in the graph adjacency matrix result in more difficult spectral graph theory ; see , e.g. ,  @xcite . applying the original definition of the graph laplacian to signed graphs",
    "breaks many useful properties of the graph laplacian , e.g. ,  leading to negative eigenvalues , making the definition of the fiedler vector ambivalent .",
    "the row - sums of the graph laplacian may vanish , invalidating the definition of the normalized laplacian .",
    "these difficulties are typically avoided by using the _ signed laplacian _ , e.g. , @xcite , defined similarly to the graph laplacian , but with the diagonal entries forced to be always positive large enough to make the signed laplacian positive semi - definite and its eigenvalues non - negative , allowing one to formally reuse the definitions of the fiedler vector and the normalized laplacian .    in this work",
    ", we argue that the original graph laplacian is a more natural and beneficial choice , compared to the signed laplacian , for spectral clustering . using a model of vibrations of a mass - spring system with some repulsive springs ,",
    "we explain , why the definition of the fiedler vector should be based on the smallest eigenvalue , no matter whether it is positive or negative . in comparison ,",
    "an `` inverting amplifier '' idea in ( * ? ? ?",
    "7 ) appears artificial , lacks intuition and leads to a questionable argument , where the sign of negative edges changes in the denominator , but not in the numerator , of the potential . turning to justification of the spectral clustering via relaxation , we compare the standard `` ratio cut , '' e.g. ,  @xcite , and `` signed ratio cut '' of @xcite , noting that minimizing the signed ratio cut puts less emphasis on cutting negative edges .",
    "we illustrate the behavior of the fiedler vector for an intuitively trivial case of partitioning a linear graph modelled by vibrations of a string .",
    "we  demonstrate numerically and analyze deficiencies of the popular signed laplacian vs. the standard laplacian for spectral clustering on a few simple examples .",
    "efficiency of solvers for eigenvalue problems in spectral clustering is crucial for practical computations , where the data become enormous in size and multi - threaded computational platforms get easily available ; e.g. cf .",
    "@xcite .",
    "a closely related to spectral clustering area of research is graph - based signal processing , that introduces eigenvectors of the graph laplacian as natural extensions of the fourier bases .",
    "for example , in  @xcite , graph - based edge - preserving denoising is performed by projecting the noisy signal on a lower dimensional krylov subspace of the graph laplacian , constructed using the signal .",
    "the construction of the graph laplacian of  @xcite is extended in @xcite to the case , where weights can be negative , leading to edge enhancing denoising . in the present work",
    ", we extend this idea to  clustering .",
    "the rest of the paper is organized as follows .",
    "we formally introduce the spectral clustering in section [ s : isc ] via eigendecomposition of the graph laplacian .",
    "section [ s : string ] deals with a simple , but representative , example  a linear graph , and motivates spectral clustering by utilizing properties of low frequency mechanical vibration eigenmodes of a string , as an example of a mass - spring model .",
    "negative edge weights are then naturally introduced in section [ s : n ] as corresponding to repulsive springs , and the effects of the negative weights on the eigenvectors of the laplacian are informally predicted by the repulsion of the masses connected by the repulsive spring . in section [",
    "s : sl ] , we present simple motivating examples , discuss how the original and signed laplacians are introduced via relaxation of combinatorial optimization , and numerically compare their eigenvectors and gaps in the spectra . in sections",
    "[ s : benefits ] and [ s : ddn ] , we explain benefits and peculiarities of using the negative weights for spectral clustering .",
    "possible future research directions are spotlighted in section [ s : future ] .",
    "let entries of the symmetric @xmath0-by-@xmath0 _ data similarity _ matrix matrix @xmath1 be called _ weighs _ and the matrix @xmath2 be diagonal , made of row - sums of the matrix @xmath1 .",
    "the matrix @xmath1 is a data similarity matrix that may be viewed as a matrix of scores , representing the similarity between pairs of @xmath0 data points .",
    "similarity matrices are commonly determined from their counterparts , distance matrices .",
    "the distance matrix is a matrix containing the distances , taken pairwise , of a set of points .",
    "the general connection is that the similarity is small if the distance is large , and vice versa .",
    "traditionally , all the entries ( weighs ) in @xmath1 are assumed to be non - negative , which is automatically satisfied for distance - based similarities .",
    "we extend clustering to a general case of both positive and negative weighs , e.g. , associated with correlations between pairs of data points .",
    "commonly , the data clustering problem is formulated as a graph partition problem , defined on data represented in the form of a graph @xmath3 , with @xmath0 vertices @xmath4 and @xmath5 edges @xmath6 such that it is possible to partition @xmath7 into sub - graphs .",
    "entries of @xmath1 are weighs of the corresponding edges @xmath6 , and the matrix @xmath1 is called the _",
    "graph adjacency _ matrix .",
    "the graph is called _ signed _ if it has edges with negative weighs .",
    "let us introduce the laplacian @xmath8 and the normalized laplacian @xmath9 matrices , assuming that @xmath2 is invertible , where @xmath10 is the identity matrix .",
    "normalizing the graph laplacian is basically vertex scaling , conveniently mapping the spectrum of the normalized laplacian @xmath11 on the real interval @xmath12 $ ] , if the edge - weighs are all non - negative . to simplify our presentation for the signed graphs ,",
    "we mostly avoid the normalized laplacian .    a good partition in the classical case of non - weighted graphs is informally described as the one in which the number of edges between separated sub - graphs is small .",
    "the goal of partitioning of signed graphs , e.g. , by cutting into two sub - graphs , is informally to minimize the total weight of the cut positive edges , while at the same time to maximize the absolute total weight of the cut negative edges . for uniform partitioning",
    ", one also needs to well - balance sizes or volumes of the resulting sub - graphs .",
    "traditional approaches to graph partitioning are combinatorial and naturally fall under the category of np - hard problems , solved using heuristics , such as relaxing the combinatorial constraints , as we briefly discuss below in subsection [ ss : relax ] .",
    "data clustering via graph spectral partitioning is a state - of - the - art tool , which is known to produce high quality clusters at reasonable costs of numerical solution of an eigenvalue problem for a matrix associated with the graph , e.g. ,  the graph laplacian .",
    "each eigenvector , denoted by @xmath13 , of the matrix @xmath14 is a solution of the eigenvalue problem @xmath15 , where the scalar @xmath16 denotes the eigenvalue corresponding to the eigenvector  @xmath17 together , @xmath16 and @xmath13 are called an _ eigenpair_.    the column - vector of ones is always a trivial eigenvector of @xmath14 corresponding to the zero eigenvalue .",
    "it is easy to show that the symmetric matrix @xmath14 has all non - negative eigenvalues @xmath16 , if all weights are non - negative .",
    "the graph laplacian matrix is symmetric , due to the earlier assumed symmetry of the adjacency matrix @xmath1 , which implies that all the eigenvalues are real , and the various eigenvectors can be chosen to be mutually orthogonal .",
    "a nontrivial eigenvector of the matrix @xmath14 corresponding to smallest eigenvalue @xmath16 of @xmath14 , commonly called the fiedler vector after the author of @xcite , bisects the graph @xmath7 into only two partitions , according to the signs of the entries of the eigenvector .",
    "since the fielder vector , as any other nontrivial eigenvector , is orthogonal to the vector of ones , it must have entries of opposite signs , thus , the sign - based bisection always generates a non - trivial two - way graph partitioning .",
    "we explain in section [ s : string ] , why such a partitioning method can be considered meaningful .",
    "a multiway spectral partitioning is obtained from `` low frequency eigenmodes , '' i.e. , eigenvectors corresponding to a cluster of smallest eigenvalues , of the laplacian matrix @xmath18 the cluster of ( nearly)-multiple eigenvalues naturally leads to the need of considering a fiedler invariant subspace of @xmath14 , spanned by the corresponding eigenvectors , extending the fielder vector , since the latter may be not unique or well numerically defined in this case .",
    "the fiedler invariant subspace provides a geometric embedding of the graph s vertices , reducing the general graph clustering problem to the problem of clustering of a point cloud ( of embedded graph vertices ) in a low - dimensional euclidean space .",
    "however , the simple and efficient idea of sign - based partitioning from the fiedler vector has no evident extension to the fiedler invariant subspace .",
    "practical multiway spectral partitioning can be performed using various competing heuristic algorithms , greatly affecting the results ; see , e.g. ,  @xcite .",
    "while these same heuristic algorithms can as well be used in our context of signed graphs , we restrict ourselves in this work only to the two - way partitioning using the component signs of the fiedler vector , for clarity of presentation and consistency .",
    "the presence of negative weights in signed graphs brings new theoretical and practical challenges to spectral graph partitioning :    * possible negative eigenvalues of the graph laplacian , making the definition of the fiedler vector somewhat ambiguous , e.g. , whether the smallest negative , positive , or by absolute value , eigenvalues should be used in the definition ; * more difficult spectral graph theory ; e.g. ,  cf .",
    "@xcite and @xcite ; * possible zero diagonal entries in the degree matrix @xmath2 , nullifying the definition of the normalized laplacian @xmath11 , cf .",
    "@xcite ; * violation of the maximum principle , which is the cornerstone in the proof of connectivity of clusters ; see @xcite ; * breaking the connection of spectral clustering to random walks and markov chains , cf .",
    "@xcite ; * invalidating an interpretation of the quadratic form @xmath19 as `` energy , '' e.g. , in the heat ( diffusion ) equation ; cf . a forward - and - backward diffusion in @xcite ; * the graph laplacian can no longer be viewed as a discrete analog of the laplace - beltrami operator on a riemannian manifold that motivates laplacian eigenmaps methods for manifold learning ; e.g. ,  see @xcite .    some of these challenges can be addressed by defining a _ signed _ laplacian as follows .",
    "let the matrix @xmath20 be diagonal , made of row - sums of the _ absolute values of the entries _ of the matrix @xmath1 , which thus are positive , so that @xmath21 is well - defined .",
    "we define the _ signed _ laplacian @xmath22 and the _ normalized signed _",
    "laplacian @xmath23 matrices , following , e.g. , @xcite .",
    "the signed laplacian is positive semi - definite , with all eigenvalues non - negative .",
    "the fiedler vector of the signed laplacian is defined in @xcite as an eigenvector corresponding to the smallest eigenvalue and different from the trivial constant vector .    in the rest of the paper ,",
    "we justify spectral partitioning of signed graphs using the original definition of the graph laplacian @xmath14 , and argue that better quality clusters can generally be expected from eigenvectors of the original @xmath14 , rather than from the signed laplacian @xmath24 .",
    "spectral clustering can be intuitively justified via a well - known , see , e.g. ,  @xcite , identification of the graph laplacian matrix @xmath14 with a classical problem of transversal vibrations of a mass - spring system with @xmath0 masses and @xmath5 springs , where the stiffness of the springs is related to the graph weights  the entries of the graph adjacency matrix @xmath25 we start with the simplest non - trivial example , where the mass - spring system is a discrete analog of a string .",
    "let @xmath26 with all other zero entries , so that the graph laplacian @xmath8 is a tridiagonal matrix @xmath27 that has nonzero entries @xmath28 and @xmath29 in the first row , @xmath29 and @xmath28 in the last row , and @xmath30 $ ] in every other row  a standard finite - difference approximation of the negative second derivative of functions with vanishing first derivatives at the end points of the interval .",
    "its eigenvectors are the basis vectors of the discrete cosine transform ; see the first five low frequency eigenmodes ( the eigenvectors corresponding to the smallest eigenvalues ) of @xmath14 displayed in the left panel in figure [ fig:2 ] .",
    "let us note that these eigenmodes all turn flat at the end points of the interval .",
    "the flatness is attributed to the vanishing first derivatives , which manifests itself in the fact , e.g. ,  that the laplacian row sums in the first and last rows always vanish .",
    "eigenvectors of matrix are well - known in mechanics , as they represent shapes of transversal vibration modes of a discrete analog of a string  a linear system of masses connected with springs .",
    "figure  [ fig : m - s - p ] illustrates a system with @xmath31 masses and @xmath32 springs .",
    "the frequency @xmath33 of the vibration mode @xmath13 satisfies @xmath34 .",
    "the eigenvectors of the graph laplacian are often called _ eigenmodes _ because of this mechanical analogy .",
    "the smallest eigenvalues @xmath35 correspond to low frequencies @xmath33 , explaining the terminology used in the caption in figure [ fig:2 ] .",
    "the system of masses is not attached , thus there is always a trivial eigenmode , where the whole system goes up / down , i.e. , the eigenvector @xmath13 is constant and @xmath36 .",
    "figure [ fig : m - s - p ] shows transversal displacements of the masses from the equilibrium plane for the first nontrivial mode , which is the fiedler vector , where the two masses on the left side of the system move synchronously up , while the two masses on the right side of the system move synchronously down .",
    "this is the same eigenmode as drawn in red color in figure [ fig:2 ] left panel for a similar linear system with a number of masses large enough to make a visual appearance of a continuous string .",
    "performing the bisection partitioning according to the signs of the fiedler vector , one puts the data points corresponding to the masses in the left half of the mass - spring system into one cluster and those in the right half into the other .",
    "the amplitudes of the fiedler vector are also very important .",
    "for example , the fiedler vector in figure  [ fig : m - s - p ] has smaller by absolute value components in the middle of the system . with",
    "the number of masses increased , the components in the middle of the system gets smaller .",
    "then , a perturbation of the graph weights can easily lead to a sign change in a small by the absolute value component , putting the corresponding data point into a difference cluster , as intuitively should be expected .",
    "thus , the squared amplitude of the component , after a proper scaling , can be interpreted as a probability of the corresponding data point to belong to the cluster determined according to the sign of the component .",
    "next , we set a very small value @xmath37 for some index  @xmath38 , keeping all other entries of the matrix @xmath1 the same as before . in terms of clustering",
    ", this example represents a situation , where there is an intuitively evident bisection partitioning , with one cluster containing all data points with indexes @xmath39 and the other with @xmath40 . in terms of our mass - spring system interpretation",
    ", we have a discrete string with one weak link , i.e. , one spring with such a small stiffness that makes two pieces of the string nearly disconnected .",
    "let us check how the low frequency eigenmodes react to such a change .",
    "the first five vectors of the corresponding laplacian are shown in figure [ fig:2 ] , right panel .",
    "we observe that all the plotted in figure [ fig:2 ] eigenvectors are aware of the soft ( having small stiffness ) spring between the masses with the indexes @xmath38 and @xmath41 .",
    "moreover , their behavior around the soft spring is very specific  they are all flat on both sides of the soft spring !",
    "the presence of the flatness in the low frequency modes of the graph laplacian @xmath14 on both sides of the soft spring is easy to explain mathematically .",
    "when the value @xmath37 is small relative to other entries , the matrix @xmath14 becomes nearly block diagonal , with two blocks , which approximate graph laplacian matrices on sub - strings to the left and to the right of the soft spring .",
    "the low frequency eigenmodes of the graph laplacian @xmath14 thus approximate combinations of the low frequency eigenmodes of the graph laplacians on the sub - intervals . but",
    "each of the low frequency eigenmode of the graph laplacian on the sub - interval is flat on both ends of the sub - interval , as explained above .",
    "combined , it results in the flatness in the low frequency modes of the graph laplacian @xmath14 on both sides of the soft spring .",
    "the flatness is also easy to explain in terms of mechanical vibrations .",
    "the soft spring between the masses with the indexes @xmath38 and @xmath41 makes the masses nearly disconnected , so the system can be well approximated by two independent disconnected discrete strings with free boundary conditions , on the left and on the right to the soft spring .",
    "thus , the low frequency vibration modes of the system are discontinuous at the soft spring , and nearly flat on both sides of the soft spring .",
    "can we do better in this toy example and make the flat ends to bend in the opposite directions , making it easier to determine the bisection partitioning even using low accuracy computations of the eigenvectors ? in @xcite , where graph based edge - preserving signal denoising is analyzed , we have suggested to enhance the edges of the signal by introducing negative edge weights in the graph , cf .",
    "@xcite . in the next subsection",
    ", we put a spring , which separates the masses by repulsing them , and see how it affects the low - frequency vibration modes .",
    "in  our  mechanical vibration model of a spring - mass system , the masses that are tightly connected have a tendency to move synchronically in low - frequency free vibrations . analyzing the signs of the components corresponding to different masses of the low - frequency vibration modes",
    "thus allows determining the clusters .",
    "the mechanical vibration model describes conventional clustering when all the springs are pre - tensed to create attracting forces between the masses , where the mass - spring system is subject to transverse vibrations , i.e. , enable the masses to move only in a transverse direction , perpendicular to a plane of the mass - spring system .",
    "however , one can also pre - tense some of the springs to create repulsive forces between some pairs of masses , as illustrated in figure  [ fig : m - s - n ] . in the context of data clustering mathematically formulated as graph partitioning",
    ", that corresponds to negative entries in the adjacency matrix .",
    "the negative entries in the adjacency matrix are not allowed in conventional spectral graph partitioning . however , the model of mechanical vibrations of the spring - mass system with repulsive springs is still valid , allowing us to extend the conventional approach to the case of negative weights .",
    "the masses , which are attracted , move together in the same direction in low - frequency free vibrations , while the masses , which are repulsed , have the tendency to move in the opposite direction .",
    "moreover , the eigenmode vibrations of the spring - mass system relate to the corresponding wave equation , where the repulsive phenomenon makes it possible for the time - dependent solutions of the wave equation to exponentially grow in time , if they correspond to negative eigenvalues .",
    "figure [ fig : m - s - n ] shows the same linear mass - spring system as figure  [ fig : m - s - p ] , except that the middle spring is repulsive , bending the shape of the fiedler vector in the opposite directions on different sides of the repulsive spring .",
    "the clusters in figure [ fig : m - s - p ] and figure [ fig : m - s - n ] are the same , based on the signs of the fiedler vectors .",
    "however , the data points corresponding to the middle masses being repulsed more clearly belong to different clusters in figure [ fig : m - s - n ] , compared to figure  [ fig : m - s - p ] , because the corresponding components in the fiedler vector are larger by absolute value in figure [ fig : m - s - n ] vs. figure  [ fig : m - s - p ] .",
    "determination of the clusters , using the signs of the fiedler vector , is easier for larger components that are less likely to be computed with a wrong sign due to data noise or inaccuracy of computations , e.g. ,  small number of iterations .",
    "figures [ fig:3 ] left panel displays the five eigenvectors , including the trivial one , for the five smallest eigenvalues of the same tridiagonal graph laplacian as that corresponding to the right panel in figure [ fig:2 ] except that the small positive entry of the weights @xmath37 for the same @xmath38 is substituted by @xmath42 in figure  [ fig:3 ] .",
    "we present a few simple motivating examples , discuss how the original and signed laplacians are introduced via relaxation of combinatorial optimization , and compare their eigenvectors and gaps in the spectra , computed numerically for these examples .",
    "the graph corresponding to the mass - spring system in figure [ fig : m - s ] , assuming unit by absolute value weights of the edges , leads to the following graph laplacian @xmath43 and the signed laplacian @xmath44 where the top left in figure [ fig : m - s ] mass , positioned between the repulsive springs , is assigned the index @xmath45 i.e. , corresponds to the first row and column of @xmath14 .",
    "even without computing the eigenvalue decomposition , one can easily predict that the eigenvector of @xmath14 , orthogonal to the trivial eigenvector of ones and corresponding to the smallest eigenvalue , should have the first component of the opposite sign compared to all other components , separating the first mass from the rest .    to setup a proper comparison ,",
    "let us consider a graph like the one corresponding to the mass - spring system in figure  [ fig : m - s ] , but with both repulsive springs being already eliminated . in terms of the graph , we substitute both negative weights with the zero weights , leading to the graph laplacian @xmath46 the fiedler vector of @xmath47 in is evidently piece - wise constant , with the first component having the opposite sign compared to all other components , separating the first mass from the rest . let @xmath48 denote the fiedler vector of @xmath47 in shifted by the vector of ones and scaled so that its components with the opposite sign are simply @xmath49 and @xmath29 , i.e. , e.g. ,  @xmath50 . we still have that @xmath51 .",
    "considering @xmath52 we get @xmath53 , thus , also @xmath54 , i.e. , @xmath48 is also an eigenvector of @xmath24 , corresponding to the smallest eigenvalue .",
    "therefore , in this example , we come to the surprising conclusion that performing graph spectral bi - partitioning based on the signed laplacian has no advantages compared to the spectral bi - partitioning , where the negative weights are simply nullified !    in another example , for the discrete string with one negative edge , we obtain @xmath55 where the graph laplacian @xmath47 corresponds to the two disconnected string pieces , and all dotted entries are zeros . again , we observe that the eigenvector @xmath48 of @xmath47 such that @xmath51 is piece - wise constant , and can be chosen to have components @xmath49 and @xmath29 , separating the left string piece from the right one . and yet again , @xmath53 , thus , @xmath54 , i.e. , @xmath48 is an eigenvector of both matrices @xmath24 and @xmath47 , corresponding to the smallest eigenvalue , in this example .",
    "a common approach to formulate spectral graph partitioning is via relaxation of combinatorial minimization problems .",
    "let us compare the standard `` ratio cut , '' e.g. ,  @xcite , leading to the traditional graph laplacian , and `` signed ratio cut '' of @xcite , used to justify the definition of the signed laplacian .",
    "let the graph @xmath4 be cut into sub - graphs @xmath56 and @xmath57 .",
    "the associated cut value @xmath58 is defined as the number of cut edges for graphs without weight and the sum of the weights of cut edges for weighted graphs . in signed graphs , thus , @xmath59 , where @xmath60 ( @xmath61 ) denotes the sum of the absolute values of the weights of cut positive ( negative ) edges . for uniform partitioning",
    ", one wants to balance the resulting sub - graphs , which is typically done dividing the cut by the size of the clusters , giving @xmath62 .",
    "minimizing the ratiocut is a combinatorial problem , but its relaxation , see e.g. ,  @xcite , leads to minimizing the rayleigh quotient for the graph laplacian . substituting sub - graph volumes for sizes similarly leads to the normalized laplacian , not covered here .",
    "the signed ratio cut of @xcite is defined by substituting the `` signed cut '' @xmath63 for the `` cut '' .",
    "however , the value @xmath64 of all negative edges in the signed graph remains constant , no matter what @xmath56 is .",
    "we notice that , up to this constant value , @xmath65 is equal to @xmath66 this expression is similar to that of @xmath58 , but the term @xmath60 appears with the multiplier @xmath67 , which suggests that the cuts minimizing quantities involving @xmath65 could tend to ignore the edges with negative weights , focusing instead on cutting the edges with small positive weights .",
    "in contrast , in the definition of @xmath58 , the positive and negative weights play equal roles .",
    "it appears hard to argue why minimizing the signed ratio cut would make more sense compared to the standard ratio cut for signed graphs . moreover , _ doubling _ the term @xmath60 appears somewhat arbitrary .    while the relaxation argument is often used as a motivation for spectral clustering , it is difficult to mathematically analyze how different cost functions in the combinatorial formulation affect their relaxed versions .",
    "it is also challenging to directly quantitively compare various spectral clustering formulations , where the clusters are determined from eigenvectors , since shapes of eigenvectors depend on the matrix coefficients in a complex way .",
    "we use the intuitive mass - spring system model to explain novel effects of spring repulsion on eigenmodes of the standard laplacian , but we are unaware of such a physical model for the signed laplacian .      since there is apparently still no algorithm universally accepted by experts for an ultimate determination of multiway clusters from several eigenvectors , we restrict ourselves to determining the clusters from the component signs of only one eigenvector , the fiedler vector for the traditional laplacian , and the first , or the second , smallest eigenvector of the signed laplacian , as advocated in @xcite .",
    "the shape of this single eigenvector that determines bi - partitioning is not the only important factor for spectral clustering .",
    "since the eigenvector has to be computed numerically and is subject to data noise , it is also important to check the shapes of other eigenvectors , corresponding to the nearby eigenvalues , that are likely to contaminate the approximate eigenvector of interest .",
    "figure [ fig:3 ] right panel displays the eigenmodes of the signed laplacian for the same weights as in the left panel .",
    "we observe that , indeed , as we have proved above , one of the eigenvectors is piece - wise constant , as in figure [ fig:2 ] right panel .",
    "moreover , the shapes of the other eigenmodes of the signed laplacian in figure [ fig:3 ] right panel also look more similar to those in figure [ fig:2 ] right panel , corresponding to the zero weight , than figure [ fig:3 ] left panel , corresponding to the original graph laplacian with the same weights .",
    "the eigenvectors the original laplacian with negative weights are preferably shaped , compared to those of the signed laplacian , potentially giving better  clustering .    to setup a direct numerical comparison , for the string example , we need to choose a practical eigensolver , so let us briefly discuss computational aspects of spectral clustering .",
    "the fiedler vector , or a group of eigenvectors , corresponding to the left - most eigenvalues of a symmetric eigenvalue problem can be computed by an iterative method , for example , as proposed in @xcite , by the locally optimal block preconditioned conjugate gradient ( lobpcg ) method ; see @xcite .",
    "lobpcg does not even need to store the matrix @xmath14 in memory , but only needs the results from multiplying the matrix @xmath14 by a given vector , or a block of vectors .",
    "this characteristic makes lobpcg applicable to eigenvalue analysis problems of very high dimensions , and results in good parallel scalability to large matrix sizes processed on many parallel processors ; e.g. ,  see reference @xcite , describing one open source and publicly available implementation of lobpcg .",
    "available convergence theory of lobpcg in @xcite requires the matrix be symmetric , but not necessarily with all non - negative eigenvalues , i.e. ,  a possible presence of negative eigenvalues still satisfies the convergence assumptions .",
    "the calculation of the product of the matrix @xmath14 by a vector is the main cost per iteration , no matter if the weights are positive or negative .    to this end",
    ", we perform @xmath68 iterations of lobpcg , without preconditioning and starting from a random initial approximation  the same for various choices of the weights and for different laplacians for our discrete string example .",
    "the number of iterations is chosen small enough to amplify the influence of inaccuracy in approximating the eigenvector on its shape .",
    "we display a representative case in figure [ fig : nazero ] .",
    "figure [ fig : nazero ] shows the approximately computed laplacian eigenmodes with the unit ( a ) , zero ( b ) , and negative ( c ) weight at one edge , as well as the signed laplacian  ( d ) , corresponding to the exact eigenfunctions in figures  [ fig:2 ]  and  [ fig:3 ] .",
    "initial large contributions from other eigenmodes , shown in figures  [ fig:2 ]  and  [ fig:3 ] , remain unresolved , as anticipated .",
    "if the bi - partitioning was performed according to the signs of the components of the computed eigenmode of the laplacian with the negative weight nullified , figure [ fig : nazero ] ( b ) , or the signed laplacian , figure  [ fig : nazero ]  ( d ) , the resulting clusters would be  wrong .    in a sharp contrast",
    ", the exact eigenmode of the original laplacian with the negative weight @xmath42 , figure  [ fig:3 ] left panel the blue line , as well its approximation in figure [ fig : nazero ] ( c ) , which is very different from all other approximate eigenmodes in figure [ fig : nazero ] , clearly demonstrate a sharp edge with a large jump in the functions at the correct location of the negative edge , between the @xmath69 and @xmath70 vertices .",
    "the signs of their components allow one to determine the optimal bi - partitioning .",
    "there are two reasons why the computed eigenmode in figure [ fig : nazero ] ( c ) visually much better approximates the exact fiedler vector compared to other cases in figure  [ fig : nazero ] .",
    "the first one is that the shape of the exact fiedler eigenmode ( blue line ) is very pronounced and quite different from those of other eigenfunctions with small eigenvalues in figure  [ fig:3 ] left panel .",
    "the second reason is more important and qualitative , but less evident , requiring additional information and explanations as follows .",
    "it is related to _ condition numbers _ of eigenvectors , which is primarily determined by a gap in the matrix spectrum .",
    "the convergence speed of iterative approximation to an eigenvector , as well as eigenvector sensitivity with respect to perturbations in the matrix entries , e.g. , due to noise , is mostly determined by a quantity , called the _ condition number _ of the eigenvector , defined for symmetric matrices as the ratio of the spread of the matrix spectrum to the gap in the eigenvalues .",
    "since we are interested in the eigenvector , corresponding to the smallest eigenvalue , the gap is simply the difference between the smallest eigenvalue and the other nearest eigenvalue , where the trivial zero eigenvalue of the laplacian can be excluded , since the corresponding trivial eigenvector , made of ones , can simply be ignored .",
    "what happens in our example , as we see numerically , the largest eigenvalue remains basically the same for all variants , so we only need to check the gap .",
    "it turns out that the gap for the signed laplacian is about @xmath71 times smaller , for all tested values of the negative weight , compared the gap for the case of the zero weight , explaining why we see no improvement in figures [ fig : nazero ] ( b ) and ( d ) , compared to ( a ) .",
    "in contrast , introducing the negative weight in the original laplacian tends to make the target smallest eigenvalue smaller , even negative , in our test for the discrete string , while not changing enough the other eigenvalues nearby . as a result ,",
    "the gap with the negative weight @xmath42 is @xmath72 times larger compared to the baseline case of the zero weight .",
    "we conclude that the eigenvector condition number for the signed laplacian is about @xmath71 time larger , while for the original laplacian is @xmath72 times smaller , depending on the negative weight @xmath42 , compared to the baseline eigenvector condition number for the laplacian with the zero weight , suggesting that the signed laplacian is numerically inferior for spectral clustering .",
    "we have observed that the approximate eigenvector of the signed laplacian in figure  [ fig : nazero ]  ( d ) produces wrong clusters , although either the first ( red ) or the second ( blue ) exact eigenvector of the signed laplacian in figure  [ fig:3 ] left panel would result in ideal clusters , cutting our linear graph at the correct location of the negative edge , between the @xmath69 and @xmath70 vertices .",
    "now , we present a bit more sophisticated example , where neither the first nor the second exact eigenvectors of the signed laplacian result in meaningful clusters , using the signs of the eigenvector components as suggested in @xcite .",
    "in other words , the signed laplacian fails .",
    "we  consider another standard linear mass - spring system with @xmath73 masses and one repulsive spring , @xmath74 between masses @xmath75 and @xmath76 , but add to the graph adjacency an extra `` noise '' full random matrix with entrees uniformly distributed between @xmath77 and @xmath78 .",
    "it turns out that in this example the two smallest eigenvalues of the signed laplacian form a cluster , making individual eigenvectors unstable with respect to the additive noise , leading to meaningless spectral clustering , if based on the signs on the components of any of the two eigenvectors .",
    "-mass string with a negative weight at one edge between vertices @xmath75 and @xmath76.,title=\"fig : \" ] -mass string with a negative weight at one edge between vertices @xmath75 and @xmath76.,title=\"fig : \" ]    the exact laplacian eigenmodes , are shown in figure [ fig : na ] , the original fiedler ( left panel ) and both eigenvectors of the signed laplacian ( right panel ) .",
    "the  signs of neither eigenvectors of the signed laplacian give any meaningful clusters , while the fiedler vector clearly suggests the perfect cut , as well as in our previous tests .",
    "a closer look at the two eigenvectors of the signed laplacian in figure [ fig : na ] ( right panel ) reveals a visible aperture between the values of the components in every eigenvector at the actually correct location , between graph vertices @xmath75 and @xmath76 , separating the graph partitions .",
    "this aperture , however , is not aligned with the sign change in any of the two eigenvectors , suggesting that partitioning , using the eigenvectors of the signed laplacian , should be based on the location of the aperture , rather than the signs of the components of the eigenvector , in contrast to @xcite . for example , the correct partitioning in this case can be determined via clustering of the one - dimensional point cloud , consisting of the components of the eigenvector , such as by k - means initiated with centroids at the local maximal cloud density points ( see , e.g. ,  @xcite and references there ) , which in @xmath28d is easy to estimate .",
    "clustering methods , which allows both the non - negative and negative entries in the graph adjacency matrix , are advantageous because situations where the pair of data points is disparate can be explicitly represented in the graph adjacency matrix . in the traditional approach , the entries in the graph adjacency matrix must be all non - negative , which does not admit negative data comparisons , available in many practical applications .    for example , a practically important case is where the data points are feature vectors of some underlining original data , or just vectors themselves .",
    "in such an example , the pair - wise comparing of data points can be determined based on a correlation or a covariance , instead of a distance , where the correlation and the covariance quantify a linear dependence between the vectors , such that the entry of the graph adjacency matrix is positive , negative , or zero , depending on whether the two vectors are positively correlated , negatively correlated , or uncorrelated , in contrast to @xcite , where negatively correlated data result in zero weights , while uncorrelated data give moderate positive weights .",
    "such a determination is advantageous because it directly uses the correlation or the covariance for the data comparing , even when the correlation or the covariance is negative for at least some pairs of the data points , thus potentially improving the quality of the clustering . in the traditional approach , the vectors would be typically compared using a kernel distance function leading to the graph adjacency matrix with all non - negative entries , enabling the conventional spectral clustering to proceed , but nullifying valid comparisons .",
    "the repulsive phenomenon is beneficial for clustering , increasing the quality of distinguishing data points having negative similarities . in the vibration model of the mass - spring system",
    ", any eigenmode corresponding to a negative eigenvalue , contributes to increasing the amplitudes of vibrations of components when the interaction between the components is repulsive .",
    "the increasing of the amplitudes of vibrations of the components is an indication that the components are not likely to appear in the same cluster , which makes the determining of clusters simpler .",
    "this argument also suggests that the repulsive ( negative ) spectrum is more important compared to the attractive ( positive ) spectrum or even the zero spectrum , and thus should be treated preferentially , as we discuss below in   [ s : ddn ] .",
    "the graph adjacency matrix with both positive and negative entries can lead to the graph laplacian having positive and negative eigenvalues .",
    "the repulsive spectrum of the negative eigenvalues of the graph laplacian is impossible in the conventional approach , creating a need to adjust some conventional tools used in traditional spectral clustering .    for the purpose of determining the clustering , the repulsive spectrum is advantageous , since the left - most negative eigenvalue corresponds to the least stable eigenmode in the mass - spring wave equation ( or the heat equation , cf .",
    "@xcite ) and , thus , is best suitable for determining the bisection partitioning using the signs of the components of the corresponding eigenvector .",
    "in contrast to the conventional case of spectral clustering with all non - negative weights , the presence of the repulsive ( negative ) spectrum may apparently result in clustering , where every cluster does not have to be connected .",
    "the mathematical reason for the lost of the connectivity is that the corresponding classical proof is based on a maximum principle ; see @xcite . in its turn",
    ", the maximum principle relies on negativity of all off - diagonal non - zero entries of the graph laplacian matrix @xmath14 , which is equivalent to non - negativity of all the entries of the graph adjacency matrix  @xmath25    some results of the traditional spectral graph theory significantly use the assumption of the positivity of the non - zero graph edge weights , and may fail if the assumption is violated . for example , @xcite bounds changes in the graph laplacian spectra , by representing the graph laplacian matrix as a diffusion operator on the vertexes of the graph , and then transforming the diffusion operator on the vertexes of the graph to a diffusion operator on the edges of the graph .",
    "the latter involves positive square roots of the graph edge weights , thus requiring weight positiveness .    even if the diagonal degree matrix @xmath2 is not degenerate , so that @xmath79 is correctly defined , some entries of @xmath80 may be negative . in the conventional case of all non - negative entries of @xmath1 , the matrix @xmath80 is associated with a markov random walk on the vertices of the graph , with the entries of @xmath80 , also all non - negative giving the probabilities of the walk ; e.g. ,  see @xcite . since in our scenario",
    "the adjacency matrix @xmath1 can have negative entries , so can @xmath80 , failing the association with the random walk ( unless some probabilities are allowed to be negative ! ) .",
    "it is always possible to define @xmath81 , but it would not be row - stochastic , if negative entries are present .",
    "we concentrate on the model of the system of masses connected with springs only because it directly leads to the standard definition of the graph laplacian , giving us a simple way to justify our introduction of the negative weights .",
    "similarly , we restrict the vibrations to be transversal , since then we can use the classical bisection partitioning definition based on the signs of the components of the fiedler vector .",
    "it is important to realize that the negative weights can as well be introduced in other models , cf .",
    "@xcite , that intuitively perform clustering .",
    "below we describe two more general models incorporating the negative weights .",
    "the first model is based on vibration modes of a wave equation of a system of interacting quasi - particles subjected to vibrations .",
    "each quasi - particle of the vibration model corresponds to one of the data points , and interaction coefficients of the vibration model are determined by pair - wise comparison of the data points , wherein the interacting is attractive and the interaction coefficient is positive if the data points in the pair are similar , or the interacting is absent and the interaction coefficient is zero when the data points in the pair are not comparable , or the interacting is repulsive and the interaction coefficient is negative when the data points in the pair are disparate , and where a strength of the interacting and an amplitude of the interaction coefficient represent a level of similarity or disparity .",
    "the eigenmodes are defined as eigenvectors of an eigenvalue problem , resulted from the usual separation of the time and spacial variables . in low - frequency or unstable vibration modes ,",
    "the quasi - particles are expected to move synchronically in the same direction if they are tightly connected by the attractive interactions , but in the opposite directions if the interactions are repulsive , or in the complementary ( if available ) directions if the interacting is absent .    compared to the already considered transversal vibrations , where the masses can only move up or down , on the one hand , determining the clusters by analyzing the shapes of the vibrations is less straightforward than simply using the signs of the components , but , on the other hand , allows reliable detection of more than two clusters from a single eigenmode .",
    "for example , a quasi - particle representing an elementary volume of an elastic body in three - dimensional space has six degrees of freedom , allowing to reliably define up to twelve clusters from a single vibration mode .",
    "already mentioned multiway spectral partitioning heuristic algorithms , such as in @xcite , would have to be adopted to the new case , where a quasi - particle , associated with a graph vertex , has multiple degrees of freedom .    a second , alternative",
    ", model is based on the concentration - diffusion equation , for a system made of interacting quasi - particles , subjected to concentration or diffusion , where each quasi - particle of the concentration - diffusion model corresponds to a point in the data , and the model quasi - particle interaction conductivity coefficients are determined by pair - wise comparison of data points , wherein the interaction is diffusive and the interaction conductivity coefficient is positive if the data points in the pair are similar , or the interaction is absent and the interaction conductivity coefficient is zero , if the data points in the pair are not comparable , or the interaction is concentrative and the interaction conductivity coefficient is negative , if the data points in the pair are disparate .",
    "the strength of the interaction and the amplitude of the interaction coefficient represent the level of similarity or disparity .",
    "as in the first model , the eigenvalue problem is obtained by the separation of the time and spacial variables in the time dependent diffusion equation .",
    "the clusters are defined by analyzing the eigenvectors corresponding to the left part of the spectrum , describing unstable or slowest modes .",
    "quasi - particles that concentrate together form a cluster by definition .    a forward - and - backward diffusion in @xcite provides a different interpretation of a similar diffusion equation , but where the negative sign in the conductivity coefficient is moved to the time derivative , thus making the time to go backward .",
    "this model requires the time to go forward on the graph edges with the positive weights and backward on the edges with the negative weights .",
    "spectral clustering has been successful in many applications , ranging from traditional resource allocation , image segmentation , and information retrieval , to more recent bio- and material - informatics , providing good results at reasonable costs .",
    "improvements of cluster quality and algorithm performance are important , e.g. , for big data or real - time clustering .",
    "we discuss introducing negative weights in the graph adjacency matrix for incorporating disparities in data via the powerful technique of spectral clustering that traditionally handles data with similarities .",
    "the direct incorporating of the disparities in the data into spectral clustering is expected to be of significance and have impact in any application domain , where the data disparities naturally appear , e.g. , if the data comparison involves the correlation or the covariance .",
    "if the data or data features are represented by elements of a vector space equipped with a vector scalar product , it can be used for determining the pair - wise comparison function , having both negative and non - negative values .",
    "our arguments aim at convincing the reader that the main framework of the traditional spectral clustering , with only non - negative weights , remains largely intact when negative weights are present .",
    "for example , the eigenvectors corresponding to the algebraically smallest eigenvalues ( that can be negative ) of the graph laplacian allow defining the clusters , at similar computational costs , but higher quality , compared to a naive substitution dissimilarities for disparities , to preserve the weights non - negative , as required in the traditional technique , or compared to the signed laplacian .    for signed graphs",
    ", we argue that the standard laplacian may outperform the signed laplacian for spectral clustering , and is better justified , using both the mass - spring system model with repulsive springs and the spectral clustering introduction via relaxation of the combinatorial minimization .",
    "the repulsive phenomenon is beneficial for clustering , increasing the quality of distinguishing data points having negative similarities , as well as increasing the relevant gap in the spectrum of the original graph laplacian , making the fiedler vector easier to compute and more robust to noise , compared to the eigenvectors of the signed laplacian .      , _ on the performance and energy efficiency of sparse linear algebra on gpus _ , the international journal of high performance computing applications , 0 ( 0 ) , p.  1094342016672081 ,",
    "https://doi.org/10.1177/1094342016672081 .      ,",
    "_ spectral theory for dynamics on graphs containing attractive and repulsive interactions",
    "_ , siam journal on applied mathematics , 74 ( 2014 ) , pp .",
    "83105 , https://doi.org/10.1137/130913973 , http://dx.doi.org/10.1137/130913973 . .    ,",
    "_ spectral segmentation using cartoon - texture decomposition and inner product - based metric _ , in graphics , patterns and images ( sibgrapi ) , 2011 24th sibgrapi conference on , aug 2011 , pp .",
    "266273 , https://doi.org/10.1109/sibgrapi.2011.34 . .      ,",
    "_ simple and scalable constrained clustering : a generalized spectral method _ , in proceedings of the 19th international conference on artificial intelligence and statistics , 2016 , pp",
    ".  445454 , http://www.jmlr.org/proceedings/papers/v51/cucuringu16.pdf .",
    ", _ a property of eigenvectors of nonnegative symmetric matrices and its application to graph theory _ , czechoslovak mathematical journal , 25 ( 1975 ) , pp .",
    "http://hdl.handle.net/10338.dmlcz/101357 .    ,",
    "_ spectral theory of unsigned and signed graphs .",
    "applications to graph clustering : a survey _ , arxiv e - prints , ( 2016 ) , https://arxiv.org/abs/1601.04692 .",
    "http://adsabs.harvard.edu/abs/2016arxiv160104692g .      ,",
    "_ a kernel view of the dimensionality reduction of manifolds _ , in proceedings of the twenty - first international conference on machine learning , icml 04 , new york , ny , usa , 2004 , acm , pp .  47 , http://doi.acm.org/10.1145/1015330.1015417 . .            ,",
    "_ modern preconditioned eigensolvers for spectral image segmentation and graph bisection _ , in proceedings of the workshop clustering large data sets",
    "; third ieee international conference on data mining ( icdm 2003 ) , boley , dhillon , ghosh , and kogan , eds . , melbourne , florida , 2003 , ieee computer society , pp .",
    "http://math.ucdenver.edu/~aknyazev/research/conf/icdm03.pdf .    , _",
    "majorization for changes in angles between subspaces , ritz values , and graph laplacian spectra _ , siam journal on matrix analysis and applications , 29 ( 2007 ) , pp .",
    "1532 , https://doi.org/10.1137/060649070 . .      ,",
    "_ spectral surface reconstruction from noisy point clouds _ , in proceedings of the 2004 eurographics / acm siggraph symposium on geometry processing , sgp 04 , new york , ny , usa , 2004 , pp .  1121 , http://doi.acm.org/10.1145/1057432.1057434 .",
    ", _ the slashdot zoo : mining a social network with negative edges _ , in proceedings of the 18th international conference on world wide web , www 09 , new york , ny , usa , 2009 , acm , pp .",
    "741750 , http://doi.acm.org/10.1145/1526709.1526809 . .",
    ", _ spectral analysis of signed graphs for clustering , prediction and visualization _ , in proceedings of the 2010 siam international conference on data mining , siam , 2010 , pp .",
    "559570 , http://epubs.siam.org/doi/abs/10.1137/1.9781611972801.49 . .              ,",
    "_ learning segmentation by random walks _ , in advances in neural information processing systems 13 , t.  k. leen , t.  g. dietterich , and v.  tresp , eds . , mit press , 2001 , pp .",
    "http://papers.nips.cc/paper/1830-learning-segmentation-by-random-walks.pdf .    ,",
    "_ on spectral clustering : analysis and an algorithm _ , in advances in neural information processing systems 14 , t.  g. dietterich , s.  becker , and z.  ghahramani , eds . , mit press , 2002 , pp .",
    "http://papers.nips.cc/paper/2092-on-spectral-clustering-analysis-and-an-algorithm.pdf .      ,",
    "_ partitioning sparse matrices with eigenvectors of graphs _ , siam journal on matrix analysis and applications , 11 ( 1990 ) , pp .",
    "430452 , https://doi.org/10.1137/0611030 , http://dx.doi.org/10.1137/0611030 .      , _ unfolding kernel embeddings of graphs : enhancing class separation through manifold learning _ , pattern recognition , ( 2015 ) , pp .   , https://doi.org/http://dx.doi.org/10.1016/j.patcog.2015.03.018 , http://www.sciencedirect.com/science/article/pii/s0031320315001193 . .",
    ", _ edge and contrast preserving in total variation image denoising _ , eurasip journal on advances in signal processing , 2016 ( 2016 ) , pp .",
    "121 , https://doi.org/10.1186/s13634-016-0315-5 , http://dx.doi.org/10.1186/s13634-016-0315-5 . .",
    ", _ advantages to modeling relational data using hypergraphs versus graphs _ , in 2016 ieee high performance extreme computing conference ( hpec ) , sept 2016 , pp .",
    "17 , https://doi.org/10.1109/hpec.2016.7761624 ."
  ],
  "abstract_text": [
    "<S> classical spectral clustering is based on a spectral decomposition of a graph laplacian , obtained from a graph adjacency matrix representing positive graph edge weights describing similarities of graph vertices . in signed graphs </S>",
    "<S> , the graph edge weights can be negative to describe disparities of graph vertices , for example , negative correlations in the data . </S>",
    "<S> negative weights lead to possible negative spectrum of the standard graph laplacian , which is cured by defining a signed laplacian . </S>",
    "<S> we revisit comparing the standard and signed laplacians and argue that the former is more natural than the latter , also showing that the negative spectrum is actually beneficial , for spectral clustering of signed graphs .    </S>",
    "<S> spectral clustering , signed graph , signed laplacian , mass - spring vibration    ams : 05c50 , 05c70 , 15a18 , 58c40 , 65f15 , 65n25 , 62h30 , 91c20 . </S>"
  ]
}