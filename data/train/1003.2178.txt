{
  "article_text": [
    "the need for methods described in this paper arose during development of the search @xcite for continuous gravitational wave signals . even though aimed at a specific purpose of following up outliers , they have much wider applicability . to that end",
    "we will present a simplified description that omits some technicalities specific to searches for continuous gravitational waves .    the algorithm @xcite detects gravitational waves by computing power received from a particular direction at a certain frequency and spindown .",
    "similar approaches include hough and stackslide searches @xcite .",
    "also , searches have been carried out with algorithms using substantially larger coherence lengths such as @xmath0-statistic @xcite .",
    "the power - based methods are computationally efficient and allow all - sky blind searches to be performed with the sensitivity scaling as fourth root of the amount @xmath1 of analyzed data .",
    "in contrast , coherent searches scale as @xmath2 but become impractical for moderate values of @xmath1 .",
    "they also rely heavily on knowing the exact form of the expected signal - an assumption that we feel is overly bold when one is looking for a form of radiation for which no prior direct observation exists .",
    "there are searches that fill the space between these extremes .",
    "one way is to combine incoherently an output of multiple coherent searches .",
    "another approach is to perform a hierarchical search that follows up outliers with longer baseline coherent investigation .",
    "both employ longer coherence baselines than power - based methods .",
    "thus , in order to make a successful detection , one needs to overcome a `` potential barrier '' in computational costs that separates a blind search from an easy verification of a successful candidate .",
    "one reason for difficulties with current coherent methods is that they are optimized with a specific signal waveform in mind , and then the search is iterated over many signal templates .",
    "the templates often overlap @xcite and , in fact , oversampling is routinely used to ensure that no signals are missed .",
    "this design is well warranted if sufficient computational power exists to exhaust the entire search space - but this is a situation current gravitational wave searches are * not * in .",
    "furthermore , maximization alone is not necessarily the most optimal statistic @xcite .",
    "we believe that an approach that combines attention to sensitivity and computational efficiency with more agile control over accepted waveforms is both more physically prudent and computationally accessible . to illustrate this , we present a _",
    "loosely coherent _ method that is based on estimating power for a family of signal waveforms at once .",
    "for the purposes of this paper we will assume that our entire dataset has been broken up into @xmath1 short portions each of which has been subjected to the fourier transform , and we are looking for a signal of constant amplitude that would land into a single frequency bin @xmath3 in @xmath4-th short fourier transform with varying phases @xmath5 .    if the phases were known in advance we could compute the power of a coherent sum @xmath6 the high values of which would indicate the presence of the signal .",
    "there is a large body of literature that describes designing statistics with optimal signal - to - noise ratios ( snr ) , in particular @xcite .    in many cases a part of signal evolution ( such as doppler modulation induced by motion of the earth )",
    "is known in advance .",
    "if we assume that this contribution has been factored out then the coherent power sum reduces to the case @xmath7 .",
    "the set @xmath8 of all possible phases ( modulo @xmath9 ) forms an @xmath1-dimensional torus on which @xmath10 is a smooth function . in practice",
    ", phases can not be determined exactly ahead of time , but rather obey a set of constraints .",
    "such family of signals would sweep a submanifold @xmath11 , possibly with boundary .",
    "our goal is then to find a statistic that achieves high values when a signal from @xmath12 is present and low values otherwise .",
    "one way to do that is take the maximum of @xmath10 over @xmath13 constrained to the submanifold @xmath12 .",
    "another approach is to view the unknown parameters as random , with the phases forming stochastic process , usually highly correlated .",
    "it is important to note that for either detection or establishment of upper limits we only need to know whether the signal is present , as the parameter estimation can be performed by partitioning @xmath12 into subsets .",
    "we call this a _ loosely coherent _ approach , as instead of trying to find signals with a certain pre - determined set of phases , we are content with any signal that has phase evolution from @xmath12 .",
    "the choice of the set @xmath12 and the statistic @xmath10 is then up to the designer of the search thus providing the necessary freedom to satisfy conflicting demands of efficiency in computation and signal recovery .    of course ,",
    "any practical detection algorithm , even designed with full knowledge of expected signal , will respond to data with signals from a wider set of phases than physically expected .",
    "tailoring the set @xmath12 at the design stage , rather than simply characterizing it after implementation , allows finer control over which astrophysical signals one can detect and particulars of template placement .",
    "the most straightforward way to construct a loosely coherent statistic is to maximize @xmath10 over the set of possible phases @xmath12 .",
    "this is a classical optimization problem with a quadratic objective that possesses several difficulties :    first , we are trying to _ maximize _ a non - negative definite quadratic function - thus our problem is inherently non - convex is called convex if the set of points @xmath14 is convex . in particular , for a differentiable @xmath15 , this assures that the gradient descent method can not become stuck in a valley . ] , even for small portions of @xmath12 .",
    "this precludes the use of well known optimization methods like gradient descent .",
    "secondly , the dimension @xmath1 is very large , with small searches starting at @xmath16 .",
    "the third difficulty is more subtle and is due to the nature of interesting signal families @xmath12 .",
    "these usually involve phases that evolve moderately fast with @xmath4 and can wrap around numerous times .",
    "a typical example is a linear evolution produced by mismatch in frequency given by @xmath17 with @xmath18 on the order of @xmath19 .    because of the wrap around",
    ", a small uncertainty in @xmath20 for some @xmath4 can result in very large uncertainty in @xmath21 for @xmath22 . in the limit @xmath23 the embedding of @xmath12 into the torus @xmath24 ( considered with @xmath25 norm in which it is not compact ) stops being differentiable or continuous altogether .",
    "the properties of the map @xmath26 as @xmath1 approaches infinity are tightly connected with the scalability in the number of templates . to describe this connection",
    "we need some well - known tools from functional analysis .",
    "let @xmath12 be a bounded ( i.e. compact ) finite dimensional manifold , possibly with boundary , with a metric @xmath27 . as mentioned before",
    ", we consider the torii @xmath28 with @xmath25 metric @xmath29 let @xmath30 be the family of embeddings describing phase evolution for successive sfts .",
    "our goal is to select templates in @xmath12 such their image under @xmath31 forms an @xmath32-net - any point in @xmath33 is within @xmath32 of an image of some template .",
    "we distinguish three fundamentally different situations :    * the map @xmath34 is lipschitz , i.e. it satisfies the following property : @xmath35 any continuously differentiable map is lipschitz . in this case",
    ", we can cover @xmath36 with any desired tolerance @xmath32 by constructing a set of templates in @xmath12 which forms an @xmath37-net . a well - known fact from topology",
    "@xcite is that it is possible to find coverings with template count scaling as @xmath38 where @xmath39 is the hausdorff dimension of @xmath12 .",
    "+ thus , we see that the template count does not depend on @xmath1 and is proportional to @xmath40 - the best we could hope for .",
    "an example of such a map is given by @xmath41 where @xmath42 is a fixed parameter ( such as earth rotation frequency ) and @xmath43 and @xmath18 are bounded search parameters .",
    "a physically relevant example is given by phase shifts from amplitude response of the detector .",
    "* the map @xmath34 is known to be continuous , but not lipschitz . in this case , we can still find a suitable template set for any desired tolerance @xmath32 , but the spacing of the templates in @xmath12 will not depend linearly on @xmath32 as it does in the lipschitz case .",
    "we thus retain independence of @xmath1 but the number of required templates can grow faster than @xmath40 . +",
    "a mathematical example of such a map is given by @xmath44 the required template count grows as @xmath45 .",
    "we are not aware of any physically motivated search for continuous gravitational radiation that has parameters of this form . *",
    "the map @xmath34 is not continuous . while this can be due to trivial causes such as partial breaks in otherwise lipschitz map , in general it would not be possible to find a finite template set to cover @xmath24 . for the finite case @xmath46 the template count will grow with @xmath1",
    "+ an example of such a map is given by frequency evolution discussed above : @xmath47 for which the required template count scales as @xmath48 .",
    "one way to deal with these difficulties is to partition @xmath1 into small enough sets so that maximization can actually be carried out and combine the results afterwards .",
    "further computational savings result from picking @xmath12 described by only a few necessary parameters and overcoming their scaling properties with large computing power .",
    "the coherent searches for gravitational radiation such as @xcite can be viewed as examples of this approach .",
    "another way to bring computational costs under control is to replace @xmath10 with a related function with a smaller lipschitz constant .",
    "one can achieve this by averaging @xmath10 over @xmath12 or its subsets , which is equivalent to computing expectation value of @xmath10 over some assumed distribution on @xmath12 .",
    "this spreads the signal response over a larger area , but we only have to make the computation once for each subset .",
    "for ease of exposition we use the usual lebesgue measure and average power rather than a more complicated statistic such as likelihood .    in the most extreme case",
    "we just average away the phases @xmath20 yielding the conventional semi - coherent method : @xmath49 if the phases are truly random this statistic will perform better in the presence of well behaved noise than computation of the maximum @xcite .",
    "a more conservative approach will limit phase evolution : @xmath50 yielding the following statistic ( computed using variables @xmath51 ) : @xmath52 which interpolates between the fully coherent sum for @xmath53 and the semi - coherent case @xmath54 . the allowed spacing between frequency templates increases with @xmath55 , and in the limiting case @xmath23",
    "is determined by the value of @xmath56 in units of frequency bins .",
    "this has proven to be a good initial estimate of the spacing required by searches where @xmath57 .",
    "this method will lose some power if the true frequency of the signal at the time corresponding to coefficient @xmath58 is not a harmonic sampled by the fourier transform . to avoid this , one can replace @xmath58 with more precise values estimated from the dirichlet kernel .",
    "this effectively makes sure that the point with all phases @xmath59 belongs to @xmath12 - a condition we assume from now on .",
    "it is also possible to use the same approach to reduce the influence of periodic changes of underlying frequency , such as caused by mismatch in sky position and the resultant doppler shifts .",
    "assume @xmath60 where @xmath43 is some unknown ( and irrelevant ) phase , @xmath42 and @xmath61 are known and fixed ( such as from sidereal doppler modulation ) and @xmath18 is allowed to vary , subject to @xmath62 .",
    "then @xmath63    as we have chosen a simple power sum @xmath10 as a starting point , our averaged statistic will always have the form @xmath64 for some kernel @xmath65 and is thus similar to cross - correlation search @xcite . as we will see later the efficient computation of the sum for small @xmath55",
    "is best done in a manner different from the cross - correlation statistic .",
    "the statistic @xmath66 can be rewritten as a scalar product of the vector of input data @xmath67 with the image of @xmath67 under the operator @xmath68 which square @xmath69 is given by the kernel @xmath65 : @xmath70 from this point of view @xmath68 acts as a filter rejecting signals outside the expected set , after which we take the usual semi - coherent sum .",
    "for example , @xmath68 can be chosen as a low - pass filter given by a @xmath71 or lanczos kernel .",
    "this would admit signals with phases varying slower than the filter cutoff frequency .    for a practical implementation the main point of concern",
    "is the ability of the statistic to tolerate frequency mismatch , as it directly impacts the number of templates . for this purpose",
    "the low pass filters are optimum , tolerating mismatch values up to a cutoff frequency and rejecting signals with faster varying phases .",
    "a more sophisticated approach is to assume a distribution on the set of allowed phases and then treat our signal as a highly correlated stochastic process .",
    "since the data analysis is typically carried out after the data collection is complete , one is not restricted to causal filters alone and , in the case of stationary noise and limited phase evolution , we obtain a low pass filter as a solution .    the loosely coherent statistic based on a @xmath71 filter",
    "is optimal in the following idealized situation : suppose our data @xmath72 consists of a sum of stationary mean zero gaussian noise of known variation ( which is typically easy to estimate from data known not to contain any signals ) and unknown band - limited signal of limited power , with no additional information on the signal form or phase evolution .",
    "a fourier transform will separate our data into high frequency area where there is no signal and which can be safely discarded and low frequency area which phase information is irrelevant due to the signal having an arbitrary spectral shape .",
    "we are thus left with a problem of deciding whether our low - frequency data is consistent with gaussian noise alone or there is an arbitrary additive signal present .",
    "both the limited power condition and the structure of gaussian noise are symmetric under unitary transformations .",
    "thus , if no other restrictions are present , the only meaningful information is the power contained in the low - frequency data .    while this fairly standard argument bridges both frequentist and bayesian approaches , it does have a number of limitations",
    "the most severe is that the symmetry is lost in case of non - stationary noise .",
    "additionally , a family of physical signals can be expected to have a spectrum more interesting than a plain flat - top .",
    "we will now qualify the phase shift evolution that one expects to encounter in current searches .    at the moment , the searches analyze data from @xmath73  hz through @xmath74  hz , accounting for spindowns as large as @xmath75  hz / s .",
    "the analysis is done using short fourier transforms ( sfts ) of @xmath76  s length , which have @xmath77 overlap in some searches , no overlap in others and often have gaps . for this paper",
    "we will assume that the time interval @xmath78 between @xmath58 and @xmath79 is @xmath80  s.    we will assume that @xmath72 have already been adjusted so that the template @xmath81 with all @xmath82 is in @xmath12 .",
    "there are several sources of non - trivial phase shifts , which we will describe in terms of maximum expected difference @xmath55 between nearby phases :    * frequency mismatch - a template possessing frequency different from @xmath81 by @xmath83 will experience a linear phase evolution of @xmath84 * sky position mismatch - a mismatch in sky position will produce a slightly different doppler shift . on short time scales this is dominated by earth rotation ( with velocity @xmath85c ) and is periodic in time and linear in sampled frequency : @xmath86 where @xmath87 is the maximum expected mismatch in radians , with practical values usually less than @xmath88 . *",
    "spindown mismatch - a spindown different from @xmath81 by @xmath89 will produce a linear evolution of the frequency and , thus , a quadratic change in phase : @xmath90 here @xmath91 shows maximum variation of time variable with respect to reference time .",
    "if the reference time is positioned at the center of the run , then @xmath91 is half the time base . *",
    "source frequency evolution - the source signal can be modulated by a nearby orbiting object .",
    "assuming circular orbit with radius @xmath92 ( expressed in astronomical units ) and using @xmath93 for the ratio of object mass @xmath94 to the star mass @xmath95 ( both expressed in units of solar mass ) the angular frequency of the modulation is : @xmath96 and the maximum doppler shift from the central body is @xmath97 the worst case change in phase induced by this motion over time @xmath78 and assuming radiating frequency @xmath15 is : @xmath98 the curiously small size of @xmath55 is due largely to the small value of product @xmath99 . for a search that assumes a specific phase evolution over a long time interval",
    "this would be much larger .",
    "the loosely coherent search is not completely immune from this effect - it will lose power when enough phase accumulates during integration for the signal to escape into nearby frequency bin .",
    "this suggests that searches looking for more extreme systems should use coarser frequency bins , smaller @xmath78 and tighter @xmath55 .",
    "table [ tab : phase_shift ] shows the expected phase shift for conditions commonly encountered in present day searches .",
    "[ tab : phase_shift ]    @p6cmlllll phase shift cause & @xmath100  hz & @xmath101  hz & @xmath102  hz & @xmath103  hz + frequency mismatch of    @xmath104 & @xmath105 & @xmath105 & @xmath105 & @xmath105 + sky position mismatch of    @xmath106 & @xmath107 & @xmath108 & @xmath109 & @xmath110 + spindown mismatch of    @xmath111  hz / s for @xmath112  y & @xmath113 & @xmath113 & @xmath113 & @xmath113 + source modulation for    @xmath114 and @xmath115  au & @xmath19 & @xmath116 & @xmath117 & @xmath118 +",
    "we will now turn to efficient computation of the loosely coherent statistic .",
    "given reduced sensitivity to perturbations in search parameters compared with purely coherent methods and corresponding reduction in the number of templates , the quadratic cost of computing the sum ( [ eqn : kernel_statistic ] ) is not completely unreasonable .    noticing that the kernel @xmath119 is a positive symmetric matrix , one expects to do better by finding eigenvectors and eigenvalues of @xmath120 and discarding eigenvectors with small eigenvalues .",
    "this will make the computational cost bilinear in @xmath1 and the number of remaining eigenvectors .",
    "let us consider , as an example , the case of limited phase evolution @xmath121 with the previously computed kernel @xmath122 where we introduced @xmath123 .",
    "when @xmath53 we are dealing with a fully coherent case and the kernel has only one eigenvector with non - zero eigenvalue , while for @xmath124 we have the semi - coherent case and @xmath120 is the identity matrix for which we have to use the entire basis .",
    "it seems reasonable to expect that for small @xmath55 we will have a few - eigenvector situation , while for large @xmath55 we will have something similar to a semi - coherent sum , where it makes sense not to truncate by eigenvalue but rather cut side diagonals of @xmath120 that are small .",
    "it turns out that the set of `` small '' @xmath55 values is quite large . to see why this is so , first examine the plot of @xmath125 versus phase mismatch @xmath55 on figure [ fig : alpha_delta ] . even for a phase mismatch",
    "as much as @xmath126 the value of @xmath125 is relatively small at @xmath127 .     on phase mismatch @xmath55,height=302 ]    secondly , consider the continuous version of our kernel : @xmath128(u)=\\int^\\infty_{-\\infty } e^{-\\alpha |u - v| } f(v ) dv\\ ] ] the operator @xmath129 is given by a convolution of @xmath130 with @xmath131 .",
    "as is well - known , fourier transform will convert convolution into multiplication .",
    "thus the spectrum of the convolution operator is given as fourier transform of its kernel .",
    "the functions @xmath132 can be considered as eigenvectors of @xmath129 in appropriate functional space ( e.g. @xmath133 ) : @xmath134(u)=\\int^\\infty_{-\\infty } e^{-\\alpha |u - v| } e^{i\\lambda v } dv=\\frac{2\\alpha}{\\alpha^2+\\lambda^2}e^{i\\lambda u}\\ ] ] the eigenvalues have the familiar lorentzian form @xmath135 with quadratic decay . in hindsight , this is not surprising as the condition @xmath121 is similar to the requirement that the signals we are looking for are band limited .",
    "@llll phase shift @xmath55 & @xmath16 & @xmath136 & @xmath137 + @xmath138 & 2 & 3 & 4 + @xmath139 & 7 & 22 & 42 + @xmath140 & 18 & 81 & 162 + @xmath141 & 66 & 324 & 647 + @xmath142 & 148 & 737 & 1474 + @xmath126 & 351 & 1751 & 3502 +    [ tab : eigencount1 ]    @llll phase shift @xmath55 & @xmath16 & @xmath136 & @xmath137 + @xmath138 & @xmath117 & @xmath118 & @xmath118 + @xmath139 & @xmath143 & @xmath144 & @xmath145 + @xmath140 & @xmath146 & @xmath105 & @xmath147 + @xmath141 & @xmath148 & @xmath149 & @xmath150 + @xmath142 & @xmath151 & @xmath152 & @xmath153 + @xmath126 & @xmath154 & @xmath155 & @xmath156 +    [ tab : eigencount5 ]    tables [ tab : eigencount1 ] and [ tab : eigencount5 ] show the number of eigenvectors needed to approximate @xmath120 given by formula [ eqn : exp_kernel ] for various numbers of equally spaced sfts and some typical values of @xmath55 .",
    "the approximation is done using operator norm which is equivalent to counting the number of eigenvalues that are at least 1% for table [ tab : eigencount1 ] ( 5% for table [ tab : eigencount5 ] ) of the largest eigenvalue of @xmath120 .",
    "while the fraction of eigenvectors does rise linearly with @xmath1 and thus the computational requirements are still quadratic , said fraction is a rather small number for @xmath157 and in practical implementations ( especially on processors with vector arithmetic ) the scaling will be close to linear .    for larger values of @xmath55 one might wish to go with a different algorithm .",
    "in particular , it makes sense to consider decompositions using non - orthogonal vectors , the simplest of which is obtained by truncation of side diagonals .     corresponding to first four largest eigenvalues for @xmath16 and @xmath158,height=302 ]    as we mentioned before , in the continuous case the eigenvectors are simple sine waves @xmath159 .",
    "the discrete case is nearly sinusoidal .",
    "the eigenvectors of the kernel [ eqn : exp_kernel ] corresponding to first four largest eigenvalues for @xmath16 and @xmath158 are shown on the figure [ fig : eigenvectors1000 ] .",
    "the eigenvector corresponding to the largest eigenvalue is not constant and can be regarded as a window one applies to the data in order to make the usual coherent sum respond to signals from @xmath12 .",
    "the eigenvector decomposition was done numerically using r @xcite .",
    "this idea can be exploited to speed up eigenvector decomposition , by analytically transitioning into the basis of pure sine waves and then discarding entries of @xmath120 from higher order modes .",
    "the remaining matrix of smaller dimension can then be diagonalized with conventional numerical techniques .",
    "it is interesting to consider the case of very short fourier transforms of a few seconds in length and correspondingly small @xmath78 .",
    "the phase shifts from most sources ( except for frequency mismatch ) will be small as well , and computation of @xmath120 can be performed by taking a fourier transform of the input data and then summing up power in low frequency harmonics weighted by eigenvalues of @xmath120 .",
    "this has close relation to the resampling technique @xcite .",
    "the resampling implementation of @xmath160-statistic operates by heterodyning 30 minute sfts to a desired frequency , inverting the fourier transform to obtain a time series which is stitched together and then band - limited and downsampled .",
    "the resulting time series is converted into detector frame which allows efficient computation of @xmath160-statistic using fourier transform .",
    "another way to obtain the same time series is to start with shorter sfts which frequency bins are large enough to accommodate doppler shift .",
    "a time series of frequency bins of these short sfts is then just another way of heterodyning our input data with the advantage of bypassing the need for inverse fourier transform .",
    "if the frequency band that is being searched is significantly smaller than the size of initial frequency bins the time series can be band - limited and downsampled just as done in @xcite .",
    "the conversion of heterodyned time - series into detector frame consists of two parts : removal of the phase shift from signal evolution due to intrinsic effects or earth motion , which is also done by loosely coherent method , and interpolation in order to obtain evenly spaced time series suitable for fast fourier transform algorithm .    the computation of @xmath160-statistic involves summing three terms quadratic in the elements of our time series with coefficients that depend on time position of the source and the detector but not the amplitude or polarization of the expected signal .",
    "this can be viewed as computation of a specific kernel @xmath120 which rank is at most @xmath118 .",
    "if we take the interpolation algorithm into account the rank will increase but will still be much smaller than kernel dimension .",
    "the same approach can be used to compute loosely coherent statistic where we might need to use additional terms to accommodate kernels with larger rank . in return",
    ", the statistic can be made more tolerant of mismatch in source parameters , such as sky location .",
    "it must be said that the sensitivity of a given method is best judged from a search made on real data , as computational efficiency and practicalities of detector artifacts in the input data have often a much stronger impact than an extra few percent gained by fine - tuning the algorithm with analytical considerations that assume gaussian noise .    nevertheless , it is useful to have an idea of what to expect in the perfect situation as a starting point for practical applications .",
    "we will concentrate on the case of perfectly coherent signal and how the performance varies between the extremes of coherent and semi - coherent power sums",
    ".    the standard methods of filtering theory can be employed to obtain a rough estimate . as we mentioned before , the phase evolution condition @xmath161 is closely related to the condition that our signals are band limited . in this case , the rejection of noise outside the acceptance band results in improvement in the signal - to - noise ratio compared to the usual semi - coherent case which is sensitive to all signals within the frequency bin of the original sfts .",
    "the acceptance band is narrowed down by a factor inversely proportional to the number of sfts it takes for the phase to make a full turn ( not to exceed , of course , the total number of sfts available ) .",
    "thus , given a fixed number of sfts , we expect the improvement in the signal - to - noise ratio to scale as @xmath162 tempered by the non - linear effects of our statistic .",
    "this is illustrated on figure [ fig : loose_snr ] that shows results of simulation evaluating signal - to - noise ratio gain for limited phase evolution statistic as we decrease @xmath55 for a coherent signal .",
    "the simulation was performed using @xmath16 sfts which were composed of gaussian noise @xmath163 with standard deviation @xmath117 and a constant signal with amplitude @xmath164 which results in the average signal - to - noise ratio of @xmath165 for a semi - coherent search .",
    "the statistic was computed according to the formula @xmath166 where the kernel @xmath167 was either an identity matrix for semi - coherent case , a matrix with @xmath117 in all cells for the coherent case or given by the formula [ eqn : exp_kernel ] for the loosely coherent case .",
    "the signal - to - noise ratio in this simulation was defined as the value of the statistic minus the average value obtained on noise alone and divided by the standard deviation of values produced by pure noise : @xmath168 here mean and standard deviation were taken over @xmath102 independent realizations of noise .",
    "all of the statistic values are described by a weighted @xmath169-squared distribution which depends on @xmath55 . for large @xmath55 , however , it is close to a gaussian distribution as well due to the central limit theorem . to illustrate the change in the distribution of our statistic",
    "we show @xmath170 and @xmath171 quantiles of the signal - to - noise ratios obtained as well as the mean .",
    "the vertical axis is logarithmic , so the spread in signal - to - noise ratios increases as @xmath55 becomes smaller .    .",
    "the upper , central and lower curves show 90% quantile , mean and 10% quantile of multiple simulation runs .",
    ", height=302 ]    the flattening out of the curve for small @xmath55 is due to different scaling regimes near the extremes of coherent and semi - coherent statistics .",
    "this can be illustrated by considering a semi - coherent statistic that operates on @xmath1 sfts which are coherently combined in stretches of @xmath4 sfts each and the results are combined incoherently .",
    "then the scaling law for the signal - to - noise ratio is : @xmath172 now suppose that @xmath173 is a certain fraction of @xmath1 . then the scaling is @xmath174 as our statistic is power based the sensivity will scale as @xmath175{\\alpha}\\sqrt{n})$ ] .",
    "the fourth root in @xmath125 has a really slow growth .",
    "for example , for @xmath176 it is only @xmath177 - so for less than a factor of @xmath118 loss in sensitivity the coherence length can be dropped by a factor of @xmath144 .",
    "an initial implementation of the loosely coherent statistic was done within the framework of the powerflux @xcite program .",
    "this implementation provided practical experience with a loosely coherent search and addressed the problem of following up outliers from the all - sky powerflux search over ligo s fifth science run .",
    "as the underlying code base was not designed with the loosely coherent search in mind , the code has a number of inefficiencies .",
    "in particular , the double sum in the statistic @xmath66 was computed by brute force . nevertheless , the speed was sufficient to quickly carry out searches in disks of @xmath178 radians radius on the sky over @xmath179 sfts split evenly between h1 and l1 detectors .",
    "the powers from individual detectors were combined incoherently to make the comparison to semi - coherent code more fair .",
    "the nearby sfts were separated by @xmath180  min . in practical data ,",
    "the sfts are usually @xmath77 overlapped , but there are can also be gaps in the data . the @xmath180  min constant was chosen as a reasonable worst case .",
    "while the analysis of actual interferometer data is still underway , we can report on results of simulations using gaussian data .",
    "for these simulations we used a lanczos kernel with parameter @xmath143 : @xmath181 this kernel naturally vanishes for widely separated sfts which makes this a variant of cross - correlation search , albeit with particularly large number of off - diagonal entries , which is further increased by the @xmath77 overlap of nearby sfts that is usually employed by powerflux .",
    "we explored values of @xmath55 as small as @xmath182 which involves summing up to @xmath183 diagonals when working with overlapped sfts .",
    "for these values of @xmath55 the required computational time scales as square of observation time ( for time bases several months and larger ) and as a cube of covered frequency range .",
    "figures [ fig : h0_vs_fbin ] and [ fig : snr_vs_h0 ] show results of monte - carlo injection run assuming a static source location ( right ascension 2.0 , declination 1.0 , spindown 0 ) and a linearly polarized signal .",
    "this choice was made to increase readability of the plots as all - sky injections with arbitrary polarizations inject different amount of power in the interferometer making the curves wider .",
    "the injections were made into gaussian data that was filtered to simulate hann windowed short fourier transforms ( sfts ) .",
    "the assumed frequency range varied from @xmath184 to @xmath185  hz and sft frequency bin size was @xmath186  hz .",
    "the 95% confidence level upper limits are produced by powerflux code for a set of 501 frequency bins given a particular direction on the sky and a spindown value .",
    "the results are then maximized over a set of polarizations and small area on the sky around the injection point .",
    "this follows the analysis method used in @xcite and @xcite .",
    "both semi - coherent ( power only ) and loosely coherent algorithms proceed by sampling discrete range of frequencies with configurable spacing in fractions of sft bin size .",
    "figure [ fig : h0_vs_fbin ] compares how the mismatch between the actual injected frequency and the sampled frequency affects upper limits produced by semi - coherent and loosely coherent codes .",
    "the frequency spacing was set at @xmath117  sft  bin and the injected strain value was fixed to @xmath187 .",
    "we see that a loosely coherent search with @xmath188 has an initial flat response for small mismatch in frequency which is followed by rapid decay to values below injected strain . in contrast , the semi - coherent search shows only minor reduction in the upper limit which is fully compensated by built - in correction factor .",
    "figure [ fig : snr_vs_h0 ] compares the signal to noise ratios ( snrs ) of semi - coherent and loose - coherent methods .",
    "the frequency spacing of the loosely coherent search was reduced to @xmath189th of the sft bin which insures correct reconstruction of the upper limit for the entire range of weak and strong signals . because of the larger number of templates , the snr achieved on pure noise is higher for the loosely coherent search than that of the semi - coherent search . for signals above noise the loosely coherent search produces signal - to - noise ratios on average @xmath73% larger than semi - coherent one .",
    "we have discussed the problem of detecting a family of signals @xmath12 from the point of view of computational efficiency and presented a method of creating a statistic that is sensitive to the entire family @xmath12 or its subset .",
    "two simple examples were considered which showed close ties to well - known methods of matched filtering , cross - correlation and semi - coherent sums .",
    "there are several directions of further study :    * the prototype large @xmath55 implementation shows feasibility of the overall method , but does not provide information on the overall computational efficiency .",
    "we plan to develop a dedicated small @xmath55 code to be used in targeted searches that cover small sky area ( such as galactic center or globular clusters ) .",
    "this should provide experience with scalability properties of the loosely coherent method .",
    "* the average of @xmath10 was used to make the maximization computationally tractable .",
    "in fact , for small @xmath1 the maximization can be carried out directly .",
    "it is worthwhile to investigate the possibility of combining the two techniques .",
    "* for the case of the set @xmath12 given by conditions @xmath121 and assuming small @xmath55 the maximization over @xmath10 can be carried out assuming @xmath190 .",
    "this converts the problem into the discrete domain and makes it amenable to binary optimization methods which have seen much progress in recent years .",
    "a particularly interesting observation is that for a noise dominated signal the function to be optimized has random coefficients , so an optimization method that works only on a certain proportion of objective functions can yield useful results .",
    "this work has been done while being a member of ligo laboratory , supported by funding from united states national science foundation .",
    "the simulations were completed on the wonderful atlas cluster at albert einstein institute , with special thanks due to bruce allen , carsten aulbert , henning fehrmann and miroslav shaltev .",
    "the author has greatly benefited from discussions with his colleagues , in particular joe betzweiser , chris messenger and keith riles .",
    "we are greatly thankful to the referee for many useful comments and suggestions .",
    "this document has the ligo document number p1000015 .",
    "searches for periodic gravitational waves from unknown isolated sources and scorpius x-1 : results from the second ligo science run abbott b ( the ligo scientific collaboration ) , _ phys .",
    "* 76 * ( 2007 ) 082001 einstein@home search for periodic gravitational waves in ligo s4 data , abbott b ( the ligo scientific collaboration ) , _ phys .",
    "d _ * 79 * , 022001 ( 2009 )"
  ],
  "abstract_text": [
    "<S> we introduce a `` loosely coherent '' method for detection of continuous gravitational waves that bridges the gap between semi - coherent and purely coherent methods . </S>",
    "<S> explicit control over accepted families of signals is used to increase sensitivity of power - based statistic while avoiding the high computational costs of conventional matched filters . </S>",
    "<S> several examples as well as a prototype implementation are discussed . </S>"
  ]
}