{
  "article_text": [
    "gravitational microlensing has become an important tool for the discovery and characterization of dark populations .",
    "there are now as many microlensing groups ( @xcite ) as there are potential lines of sight out of the galactic halo ( lmc , smc , galactic bulge , m31 ) .",
    "surveys toward the lmc have observed an excess in the number of microlensing events over what is expected from known populations of stars .",
    "we have recently reported 1317 microlensing events ( @xcite ; hereafter ) in 5.7 years of observations toward the lmc and recently erosii has reported two new events that they interpret as limiting the amount of halo dark matter ( @xcite ) , but are consistent with the results of . in addition , a number of candidates have been observed towards the smc ( @xcite ) .",
    "one natural explanation for this excess rate is a population of massive compact halo objects of mass @xmath0 that contribute @xmath1% to the mass of our galaxy s halo .",
    "however , previously unknown ( or underestimated ) populations of stellar lenses ( , in an lmc halo ) are a distinct possibility . in order to make quantitative statements about such a population",
    "an accurate determination of the survey s microlensing detection efficiency is required .",
    "here we describe the macho project s pipeline for calculating its detection efficiency .",
    "more details on the experiment , microlensing terminology , analysis , and interpretation can be found in the companion paper , and detailed reviews of microlensing in general are given by roulet & mollerach 1997 and paczyski 1996 .",
    "the detection probability for individual events depends on many factors , , the 3 event parameters @xmath2 , @xmath3 , @xmath4 ( maximum magnification , einstein - diameter crossing time and time of peak magnification , respectively ) , and the unlensed stellar magnitude , as well as the observing strategy and weather conditions .",
    "such a complicated dependence is most naturally solved using a monte carlo technique .",
    "we may simplify the dependence by averaging over the known distributions in @xmath2 , @xmath4 , the stellar magnitudes , and the known time - sampling and weather conditions , to derive our efficiency as a function only of event timescale , @xmath5 .",
    "given an efficiency @xmath5 we may compute the observed optical depth as ,    @xmath6    where @xmath7 is the survey s exposure in object - years , @xmath8 is the duration of event @xmath9 and @xmath5 is the efficiency for detecting microlensing with duration @xmath3 ( see also alcock 1996 and 1997a ; hereafter  and , respectively ) .",
    "the optical depth is a function of the amount and distribution of mass along the line of sight and is independent of the lens masses or velocities .",
    "however , we may extract more information if we assume a model of the galactic halo . with the use of a model",
    ", a likelihood analysis may be performed to determine the most likely lens mass @xmath10 and mass fraction @xmath11 of the halo model .",
    "a model yields the distribution of event durations @xmath12 ( @xcite ) , which , when combined with the efficiency and integrated over all possible durations , predicts the number of events one expects to observe from such a galactic halo composed entirely of machos .",
    "@xmath13    an identical method may be outlined for stellar populations as in .",
    "a likelihood estimator may be constructed from the observed events and the model  predicted number of events to determine simultaneously the most likely lens mass @xmath10 and mass fraction @xmath11 of the halo .",
    "note the vital role the efficiency plays in connecting the world of models to that of the survey .",
    "the efficiency is a strong function of the temporal sampling of the survey .",
    "events with very short durations ( or very long durations ) are unlikely to be detected as they easily fall ` in - between ' observations ( or for long durations , extend through the data window ) . a straightforward way of simulating this  sampling efficiency \" while retaining realistic behavior of the data is to use a random sample of real lightcurves from the survey in which to inject artificial microlensing . by randomly generating a number of events and running the same time - series analysis and selection criteria used in the real analysis , this monte carlo can be used to determine the survey s detection efficiency ( @xcite ) .",
    "how does one add microlensing onto a lightcurve ?",
    "a simple method is outlined in   [ samplinglc ] for the case where one assumes that each lightcurve represents a single resolved star . in this case",
    "all of the flux represented by the lightcurve is magnified by the microlensing model @xmath14 ( equation  [ equation6 ] below ) .",
    "the rarity of microlensing , however , demands crowded stellar fields in order to detect even a handful of events , and this in turn results in the blending of stellar light .",
    "the issue now becomes what fraction of the flux in the lightcurve ( or object ) is lensed ?",
    "our solution was first described briefly in  ( see pratt 1997 for a more thorough description ) and is outlined briefly as follows .",
    "the method involves the use of a large set of artificial star tests on a sample of macho survey images that are seeded with a color - magnitude diagram of the lmc .",
    "each artificial star was added to an entire series of observing conditions and over 15 peak magnifications .",
    "the macho survey s dedicated photometry code  was then run on the resulting images to determine how each star behaved over a range of seeing , sky , and magnification .",
    "the resulting photometry and photometric flags were stored in binary files , which we refer to as photometric response databases ( prdbs ) . in this",
    " photometric efficiency \" technique each artificial star ( hence forth referred to as a photometric response function or prf ) is used as a model for adding artificial microlensing onto lightcurves . in most cases only a fraction of the observed flux in the lightcurve is actually lensed , and the prf supplies us this fraction as a function of seeing and sky . in this way both blending and systematic photometry effects are mimicked in the resulting artificial data .",
    "blending introduces several problems that can affect microlensing surveys in serious ways and has been extensively investigated ( @xcite ) .",
    "in addition to diluting the true peak magnification @xmath2 , blending also biases the measured durations @xmath3 to shorter values , since blended events spend less time above a given threshold .",
    "this biasing of @xmath3 is particularly important as the optical depth estimate is proportional to the average duration of the events .",
    "another effect of blending ( which has received less attention , but is equally important ) is that the survey s exposure in star - years is typically quite a bit larger than is estimated by naively counting photometered objects .",
    "one can view this ( for a fixed exposure in object - years ) as a net increase in the efficiency which in part balances out a decrease in efficiency due to blending .",
    "all of these effects must be taken into account if one desires an accurate detection efficiency known at least to the level of , if not better than , the shot noise inherent in the low number of events seen toward the magellanic clouds .",
    "we make several corrections and improvements to the monte carlo presented in  and .",
    "most notably these are : ( 1 ) we add source stars to @xmath15 , more than 2.5 magnitudes below our faintest detected stars ( and 2.5 magnitudes fainter than was used in  and ) , ( 2 ) we use an up - to - date luminosity function of the lmc , constructed with our ground - based photometry for bright stars ( @xmath16 ) and hst photometry for dim stars ( @xmath17 ) , ( 3 ) we compute luminosity function normalizations separately for each macho field , ( 4 ) 10 fields of size @xmath18 with widely differing stellar density were used to simulate photometry of artificial stars over an average of 69 different observing conditions ( only 2 fields with @xmath1 observing conditions were used in  and ) , ( 5 ) an improved scheme for adding artificial microlensing onto real lightcurves , and ( 6 ) we describe a robust method of statistically correcting for the @xmath3 bias that can be used to estimate the optical depth .    in   [ sec - sodo ]",
    "we briefly review the macho telescope , photometry system and time - series analysis in order to introduce some macho specific vocabulary used throughout the rest of the paper . ",
    "[ sec - sampling ] outlines the sampling efficiency approach as a primer to the photometric efficiency discussion in   [ sec - photometric ] .",
    "the results of the photometric efficiency analysis is reserved for   [ sec - results ] , and we conclude in   [ sec - summary ] .",
    "the macho project has full - time use of the @xmath19 m telescope at mount stromlo observatory , australia , for a period of 8 years starting july 1992 .",
    "the telescope was re - commissioned especially for this project , and a computer - controlled pointing and drive system was installed .",
    "a system of corrective optics has been installed near the prime focus , giving a focal reduction to @xmath20 with a @xmath21 degree diameter field of view . a dichroic beam splitter and",
    "filters provide simultaneous images in two passbands , a `` red '' band ( @xmath22 nm ) and a `` blue '' band ( @xmath23 nm ) .",
    "two large ccd cameras are employed at the two foci ; each contains a @xmath24 mosaic of @xmath25 pixel loral ccd imagers .",
    "the pixel size is @xmath26 , which corresponds to @xmath27 on the sky , giving a sky coverage of @xmath28 square degrees .",
    "details of the camera system are given by stubbs ( 1993 ) and marshall ( 1994 ) while details of the telescope can be found in hart ( 1996 ) .",
    "the survey s photometry code  is a psf fitting algorithm based on @xmath29 ( @xcite ) .",
    "it runs in two different modes .",
    "the first mode , a template generation mode , is designed to run on a pair of red and blue images or  chunks . \"",
    "( each ccd is broken up into 16 roughly @xmath30 somewhat overlapping regions called  chunks \" for the purpose of photometric reductions . )",
    "the red chunk is reduced first in a manner similar to a standard reduction .",
    "next the blue chunk is reduced using the results from the red chunk to warm - start the reduction , which improves the star matching between colors .",
    "this produces a set of pre - templates for this chunk pair .",
    "once a set of pre - templates for an entire ccd ( 16 chunks ) has been generated the final templates are constructed by enlarging the pre - templates and including stars that lie as much as @xmath31 pixels outside the nominal chunk boundaries .",
    "this enlargement lessens negative effects on the routine photometry due to incorrect telescope pointing .",
    "the final set of template files contains a list of detected objects , their positions ( corrected to an airmass of one ) and their template magnitudes .",
    "a set of template files need be generated only once and is created using images with better than average seeing and dark sky conditions .",
    "all other images are processed in  routine \" mode , which proceeds as follows .",
    "the appropriate template file is used to warm - start the image by first locating and matching 50 bright unsaturated stars .",
    "these stars are used to determine a seven parameter analytic fit to the psf , a coordinate transformation , and a photometric zero point relative to the template .",
    "then all the template stars are subtracted from the image using the model psf and coordinate transformation ; the variance estimate for each pixel is adjusted to allow for errors in subtraction .",
    "next , photometric fitting is carried out for each star in descending order of brightness , by adding the analytic model of the star back to the subtracted frame and fitting a two - parameter fit to the star s flux and sky background , with pixels weighted by inverse variance .",
    "the model psf and computed position of the star are kept fixed .",
    "when a star is found to vary significantly from its template magnitude , it and its neighbors undergo a second iteration of fitting . for each star the estimated magnitude and error",
    "are determined , along with six other parameters (  flags \" ) measuring ( 1 ) the object  type \" ( single / blended , etc . ) , ( 2 ) the @xmath32 of the psf fit , ( 3 ) the  crowding , \" , the amount of flux contributed from nearby stars , ( 4 ) the weighted fractions of the psf masked due to cosmic rays , ( 5 ) the weighted fractions of the psf masked due to bad pixels and ( 6 ) the fit sky value .",
    "the set of photometric data points for each detected object are rearranged into a time series and combined with other relevant information ( including seeing , average sky brightness , airmass , etc . ) into portable binary files called sodsets .",
    "the sodsets are in turn passed into our time - series analysis code to search for variable objects and microlensing candidates ( see  for more details of the analysis ) . in brief",
    "the analysis code calculates for each lightcurve a set of variability statistics , average magnitudes , error bars , crowding , etc . , and for lightcurves deemed interesting ( level-1 events ) a five parameter fit to microlensing is applied , where the parameters are the unmagnified red and blue fluxes , the peak magnification @xmath2 , the time of peak magnification @xmath4 , and the einstein - diameter crossing time @xmath3 .",
    "many statistics describing the significance of the fit are also stored for the level-1 events .    from the complete set of statistics we designed criteria that select out microlensing candidates from a wide background of noise induced bumps and variable stars .",
    "two different sets of selection criteria ( criteria set a and b ) were used in , and we refer the interested reader to this paper for full details of the two selection criteria sets , as we give only a qualitative ` feel ' for the criteria here .",
    "criteria set a superficially resembles the criteria used in  and was designed to be somewhat restrictive in the sense that only good quality , high signal - to - noise ( s / n ) events were selected .",
    "the criteria are fairly tight and rely strongly on s / n statistics that are somewhat microlensing - shape specific .",
    "only 13 candidates in the first 5.7 years of lmc data passed criteria set a. in contrast criteria set b was designed to be inclusive in the sense that any event with a flat baseline and with one significant and unique bump was included .",
    "however , criteria set b was somewhat vulnerable to variable stars that exhibit constant baselines for long periods of time with only one outburst , such as exhibited by supernovae , and possibly cataclysmic variables and nova ( see  for a full discussion on how these interlopers were treated ) .",
    "some 17 candidates in the first 5.7 years of lmc data passed selection criteria set b.    the relative looseness of criteria set b over a was due to a set of new statistics that allowed us to more accurately characterize and remove the periodic and quasi - peridoic variable star populations . with",
    "a major source of background removed the s / n level could be lowered .",
    "one of the main overall differences in the two sets of selection criteria is that criteria set a is less sensitive on the whole to moderately blended and highly blended events as compared to criteria set b. also , criteria set b relies less on the microlensing - shape information and is less likely to be missing exotic forms of microlensing such as parallax and binary events .",
    "although criteria set b has overall higher detection efficiency than criteria set a the number of detected events compensates and the results presented of  are fairly insensitive to the choice of cuts . in what follows we will present both sets of selection criteria and discuss their differences .",
    "a key element in the efficiency determination is the @xmath33 database of lightcurves .",
    "this database represents an unbiased random selection of @xmath33 of the lightcurves contained in the macho project s lmc survey .",
    "it is unbiased with respect to observed magnitude , color , sampling rate , spatial distribution , and general data quality .",
    "the @xmath33 database contains @xmath34 lightcurves from the top 30 lmc fields and occupies @xmath35 gbytes of disk space .",
    "the lightcurves begin on day 200 ( @xmath36 ; 1992 july 19 ) and end on day 2267 ( 1998 march 17 ) which makes the data window 5.7 years long .",
    "the mean number of exposures per field is 719 , with a range from 180 to 1338 .",
    "approximately @xmath37 of the lightcurves have information in only one passband ( red or blue ) . of these @xmath38 have only red lightcurves and @xmath39 have only blue lightcurves .",
    "there is a fair amount of field overlap among the top 30 fields with about @xmath40 of lightcurves duplicated across fields .      here",
    "we assume that each lightcurve in the @xmath33 database is a single resolved star , and that our photometry code is  perfect \" in recovering flux .",
    "we further assume that the measurement errors involved are dominated by photon shot noise . given a lightcurve we proceed as follows : ( 1 ) first a robust mean",
    "magnitude @xmath41 for each bandpass is computed .",
    "( 2 ) then a set of event parameters @xmath42 , @xmath4 , and @xmath3 is generated where , ( a ) @xmath42 is chosen as a uniform deviate from zero to the experimental threshold @xmath43 ( @xmath44 ) , ( b ) @xmath4 is chosen as a uniform deviate from slightly before the beginning of the observations to slightly after ( day 190 to 2277 ) , and ( c ) @xmath3 is chosen as a uniform base 10 logarithmic deviate with a duration of 1 day up to 2000 days .",
    "( 3 ) for each point on the lightcurve we compute the  scatter \" from the mean in flux units as @xmath45 , where @xmath46 is a robust mean magnitude expressed in flux units , , @xmath47 .",
    "this scatter is assumed to be due entirely to photometric error rather than intrinsic variation in the source ( indeed , only @xmath48 of all lmc lightcurves show signs of intrinsic variability ) .",
    "( 4 ) the flux @xmath11 for this point is then  magnified \" @xmath49 , or expressed equivalently in magnitudes , @xmath50 .",
    "( 5 ) the flux error is modified as @xmath51 , which translates into magnitude space as @xmath52 .",
    "here @xmath53 is the time of the observation being modified and @xmath54 is    @xmath55^{1/2 } , \\label{equation5}\\ ] ]    with    @xmath56    this is performed for all points on the lightcurve and for both bandpasses .",
    "we leave the remaining photometric flags ( @xmath57 , crowding , etc . )",
    "unchanged .      using the technique of   [ samplinglc ] to modify lightcurves we proceed to add an event onto each lightcurve in the @xmath33 database .",
    "one complete loop through the @xmath33 database we refer to as a pass . for each  event",
    "\" we save information such as , ( 1 ) the lightcurve i d number ( field.tile.sequence ) , ( 2 ) a pass number , ( 3 ) a robust magnitude @xmath58 and color @xmath59 of the lightcurve , and ( 4 ) the input event parameters @xmath2 , @xmath4 , and @xmath3 .",
    "this bookkeeping information will later be matched with the output of the time - series analysis and used to calculate the efficiency .",
    "once we have created a complete pass and stored the bookkeeping information we next run the time - series analysis on the artificial lightcurves (   [ sec - sodo ] ) .",
    "the resulting output statistics and fits are written into a file and then matched on a lightcurve by lightcurve basis with the bookkeeping files that contain the input statistics .",
    "hereafter all parameters labeled with a prime refer to measured parameters ( , @xmath60 , @xmath61 , and @xmath62 ) and un - primed parameters refer to input or true parameter values .",
    "in addition , both criteria sets a and b described in   [ sec - sodo ]",
    "are applied to the resulting statistics , as in , and the results stored as an integer : zero = failed the criteria set , one = passed the criteria set .",
    "this creates a single datacube file containing input statistics , output statistics , and ` cut ' integers . in order to generate enough events to ensure adequate statistics we ran 5 passes through the @xmath33 database .",
    "though the same lightcurves were used 5 times each , completely different event parameters were generated for each pass . because we stored a unique pass number in the datacube",
    "file we simply concatenated all 5 datacube passes into one large datacube file for ease of use .    with this datacube",
    "it is straightforward to calculate the survey s sampling efficiency . since the artificial events are added with a uniform distribution in @xmath42 and @xmath4 , integration over these variables  ) in the event rate due to the motion of the earth around the sun . ]",
    "is not required .",
    "furthermore , since our assumption in   [ samplinglc ] is that each lightcurve represents a single resolved star , there is also no need to integrate over luminosity ( since , under this assumption , the @xmath33 database fairly samples the survey s luminosity distribution ) .",
    "we need only bin the data in @xmath3 and simply count the number of recovered events versus the number of added events .",
    "the efficiency is simply @xmath63 .      in figure  [ fig - samp - eff ]",
    "we compare the sampling efficiency derived from the 5.7-year data set for both criteria set a and b with the previous two data sets ,  and .",
    "the general behavior of the efficiency with @xmath3 is easy to understand .",
    "the gradual fall in efficiency as @xmath3 decreases is caused by a combination of a typical sampling rate of 1 - 2 days and large gaps of 3 - 50 days that exist due to bad weather and other telescope down time .",
    "the sharp drop at @xmath64 days is due to an explicit cut requiring @xmath65 days ( affecting both criteria set ) .",
    "the large difference in the efficiencies for the two selection criteria is due to a combination of ( 1 ) the different values used for the @xmath2 cut ( criteria set a uses @xmath66 while criteria set b uses @xmath67 ) , ( 2 ) criteria set b uses fewer s / n statistics , most of which are looser , ( 3 ) differences in variable star cuts , and ( 4 ) various cuts on the minimum quality of the lightcurve ( minimum number of points in the red and blue passbands , maximum crowding , etc . ) .",
    "the most striking difference between the previous two data sets and the 5.7-year set is the much higher efficiency at long durations .",
    "much of this difference is just a reflection of the longer baseline and an increase in the allowed duration ( @xmath65 days ) .",
    "however , a significant amount of the difference lies in a quirk of the  data set . in the  data six of the densest fields",
    "had their lightcurves cut in half , roughly , due to an early generation of templates used to reduce the photometry for these fields .",
    "these early templates made use of a different star naming convention than is currently used .",
    "roughly halfway through the  data set the current generation of templates was implemented on these six fields . since there was no straightforward way to cross reference the i d s of the stars in each different convention ( indeed , the map was not even one - to - one ) , and redoing the photometry was too prohibitive at the time , it was decided to consider as separate lightcurves the stars in these six fields before the upgrade and after the upgrade and to analysis them as such .",
    "this was handled in a self - consistent manner and more details can be found in .",
    "the primary effect of this was a lowered efficiency for long duration events , due primarily to ( 1 ) an effective cut on event peak @xmath4 where the fields were split and ( 2 ) the required minimum of 40 baseline points outside @xmath68 of the peak of the event that was used in the  selection criteria .",
    "the problem did not exist in the  data , thus the rather close behavior between  and  for long durations , even though the later had twice the coverage .",
    "the data has redone all its photometry in these six fields with the current generation of templates and does not suffer from this problem .",
    "it is also worth noting that in the @xmath3 range 1 - 40 days the sampling efficiency ( for both criteria ) is systematically smaller than the  and  results . in part",
    "this is due to differences in the selection criteria , but is also a product of including an additional 8 less densely sampled fields into the year  analysis .",
    "though this tends to reduce our efficiency it also increases our exposure . also note that criteria set b is always above criteria set a except for durations less than 10 days",
    ". the slightly lower efficiency of criteria set b in this range is due to the larger number of required points in the peak @xmath69 ( criteria set a only required 7 or more @xmath70 points ; see ) .",
    "in addition to @xmath5 it is also interesting to investigate the efficiency as a function of other parameters , such as magnitude , impact parameter and stellar density . also of considerable interest",
    "is the @xmath3 bias mentioned in the introduction .",
    "however , we hold off discussing these until after we have introduced the photometric efficiency as this scheme more realistically models the systematics of blending and the survey as a whole .",
    "in the introduction some of the potential problems associated with the effects of blending were discussed .",
    "blending causes systematic underestimation of both @xmath2 and @xmath3 , but also increases the number of stars to which the survey is sensitive .",
    "clearly none of these effects are taken into account by the sampling efficiency described in   [ sec - sampling ] . to correct for this deficiency , and to be able to generate realistic microlensing events ,",
    "we make use of a large database of artificial star photometry as first described in  and .",
    "we have developed techniques that allow us to use this artificial star photometry to inject synthetic microlensing onto @xmath33 database lightcurves , replacing the techniques described in   [ samplinglc ] .",
    "the new techniques allow us to empirically account for the blending problems , as well as other systematic photometry effects unique to such as various correlations with seeing , underestimation of error bars and other systematic changes in the photometry flags .",
    "our method involves a large set of artificial star tests on a sample of the macho survey s images that are seeded with a color - magnitude diagram of the lmc .",
    "a large set of real images that fairly sample the survey s distributions in observing conditions ( seeing and sky ) were used to create the database of input photometry versus output photometry for the sample of artificial stars and organized into a prdb .",
    "the prdb consists of @xmath71 individual prfs that represent how a star behaves as part of a blended object .",
    "each star was added to images over a range of observing conditions and over 15 peak magnifications .",
    "was run on the resulting images to determine how each star behaved over the range of seeing , sky , and magnification .",
    "the resulting photometry and photometric flags were stored in the prdbs .",
    "each prf represents a rule for how a lightcurve would respond to the addition of flux over a wide variety of observing conditions .",
    "this can be represented as ,    @xmath72    where @xmath73 is the recovered magnification , given an input magnification @xmath74 , stellar magnitudes @xmath75 and @xmath76 , object magnitudes @xmath77 and @xmath78 , and characterized by an observing condition ( @xmath79 and @xmath80 ) .    to implement the photometric efficiency",
    "properly it is important to know the underlying luminosity function ( lf ) to some limiting magnitude ( in our case about @xmath81 ) .",
    "we discuss our determination of the lf in ",
    "[ sec - cmd ] .",
    "next , in   [ sec - prdb ] we describe how the prdbs are generated , including the images , point - spread functions , coordinate and photometric transformations . in ",
    "[ sec - prf ] we show some example prfs and discuss general behaviors exhibited by the prfs .",
    "discussion of the photometric efficiency ( hereafter referred to as just the efficiency ) results is left for   [ sec - results ] .",
    "it is important to know the lf of stars in the lmc ( and to a lesser extent the color - magnitude diagram ) in order to accurately estimate the efficiency .",
    "this is because the lf , along with stellar density , dictates how much stellar psf overlap on the sky there is as a function of magnitude and thus how much blending one expects .",
    "also , since the survey s exposure is greater than the number of photometered objects suggests , and this can increase the sensitivity of the survey to microlensing , we need a fairly accurate estimate of the number of stars in our fields .",
    "the macho fields typically go incomplete at magnitudes greater than @xmath82 but can be complete to @xmath83 . because we desire to know the lf to at least @xmath81 we must resort to hubble space telescope ( hst ) wide field planetary camera 2 ( wfpc2 ) image data .",
    "the macho project has obtained hst wfpc2 data with the f555w and f675w filters for three fields in the lmc bar .",
    "these are located in the macho fields 2 , 11 , and 13 . for each field , we have obtained  shorts \" ( 3 - 4 @xmath84 30 sec exposures ) and  longs \" ( 3 - 4 @xmath84 400 - 500 sec exposures ) , in both filters .",
    "more details of the hst data reduction and analysis are contained in alcock ( 1999b ) .",
    "in addition we have obtained the reduced hst wfpc2 data from 6 lmc bar fields obtained and reduced by olsen 1999 ( kindly provided via private communication ) .",
    "these 6 fields are in the f555w and f814w filters and have similar  shorts \" and  longs \" giving completeness limits similar to our hst data .",
    "olsen s pc was positioned on old lmc globular clusters and so we discarded all pc data and , in addition , must be careful of a small contamination from cluster stars that extend into the edges of the wf ccds .",
    "details of the olsen hst reductions can be found in olsen 1998 and olsen 1999 .    in figure  [ fig - macho - hst - lf ]",
    "is plotted the v band ( f555w filter ) lf for the 3 macho hst fields .",
    "each field is normalized to have the same number of stars in the range @xmath85 , with the fields of higher stellar density , field  2 and 11 , normalized to field 13 ( lowest density and lowest s / n ) .",
    "the shape of the 3 lfs appear consistent with one another from @xmath86 , where shot noise dominates , to @xmath87 , where differences in stellar density between the 3 fields cause differences in completeness .",
    "figure  [ fig - olsen - hst - lf ] is similar to figure  [ fig - macho - hst - lf ] but shows olsen s 6 fields normalized in a similar fashion to the lowest s / n field .",
    "again the shapes of the 6 lfs appear consistent with one another between the shot noise on the bright end and the differing completeness on the dim end .",
    "we can quantify the above ` by eye ' assessment by computing a @xmath32 between fields along with the associated probability of obtaining a value of @xmath88 worse than the measured value .",
    "we find no significant difference between the 3 macho lfs with relative measured @xmath88 of 1.065 , 1.253 and 1.242 for the combinations 2 - 11 , 2 - 13 , and 11 - 13 . these correspond to probabilities of @xmath89 , @xmath90 , and @xmath91 ,",
    "respectively , that the value @xmath88 could be worse than the measured value .",
    "of the 6 olsen hst fields one stands out as anomalous in its @xmath88 value .",
    "the lf of ngc  1916 is the most discrepant but appears to be so due to heavy differential reddening ( @xcite ) with relative @xmath88 ranging from a low of 1.589 to a high of 3.777 , corresponding to a range of probabilities @xmath92 to @xmath93 .",
    "we thus discard this field from further analysis .",
    "the remaining 5 olsen lfs are consistent with one another , with relative @xmath88 ranging from a low of 1.118 to a high of 1.891 , corresponding to a range of probabilities @xmath94 to @xmath95 .",
    "the slightly worse probabilities seen in the olsen fields are likely due to contamination from the globular clusters spilling over into the wf ccds .",
    "in figure  [ fig - olsen - macho - f13-lf ] we plot macho s combined lf ( 3 fields ) and olsen s combined lf ( 5 fields ) , normalized to the macho combined lf in the range @xmath85 .",
    "the two lfs are consistent with one another in the range @xmath96 ( @xmath97 , @xmath98 ) .",
    "also plotted is macho s ground - based lf for field 13 ( @xmath99 objects ) which is one of our most complete , lowest reddened fields , with excellent template seeing and sky ( we have allowed for a small offset of @xmath100 in @xmath75 , see below ) .",
    "the shape of the ground - based lf in the range @xmath101 is good in comparison with the macho combined hst lf ( @xmath102 , @xmath103 ) . given the apparent lack of any significant difference in the shapes of the lfs for these 9 lmc bar fields we have chosen to combine 8 of them ( excluding ngc 1916 because of high reddening ) to form a lf with a fairly high s / n on the dim end ( to @xmath87 ) and to splice this together with the bright end ( @xmath104 ) of the macho ground - based lf . in this way we create a high s / n lf that is complete in the range @xmath105 .",
    "there is still a question of the completeness of the hst lfs for magnitudes greater than @xmath87 .",
    "we have performed artificial stars tests on our 3 macho hst fields and used the resulting completeness curves to correct the macho lf to @xmath106 .",
    "the completeness tests probably represent a slight underestimate of the true lf . because of the potential uncertainty in the shape of the lf for dim stars we have opted to create two different lfs in which to test for systematics .",
    "these are shown in panel ( a ) of figure  [ fig_eff_per_bin ] . the first lf ( hereafter @xmath107 )",
    "has been extended from @xmath108 to greater magnitudes using a power law with a slope of 0.415 ( @xcite ) derived from a linear regression fit between @xmath109 .",
    "this lf probably represents an overestimate of the number of faint stars .",
    "the second lf ( hereafter @xmath110 ) uses the completeness corrected macho lf as an estimate of the shape for dim stars .",
    "the shape of the true lf is likely to lie somewhere in between these two , but is probably closer to the completeness corrected @xmath110 .",
    "we choose to use both lfs in order to estimate any systematic error induced by such an uncertainty .      with the shape of the lf",
    "determined it only remains to find a normalization , that is , a number relating these two lfs to the total number of stars .",
    "this is most convenient to do on a field by field basis as the stellar density changes quite rapidly across our fields ( and also inside our fields , but we average over this ) .",
    "a normalization is calculated for each field using the ground - based lf for that field and the ` universal ' lfs shown in panel ( a ) of figure  [ fig_eff_per_bin ] .",
    "this is illustrated in figure  [ fig - example - norm - lf ] where four macho fields of widely differing stellar density are shown .",
    "first , we allow a slight offset in v magnitude that is field dependent and typically varies from -0.14 mag to 0.40 mag ( table  [ tab - norms ] ) .",
    "this slight offset is due to a combination of three effects , ( 1 ) extinction ( patchy , even on the scale of our fields ) , ( 2 ) the tilt of the lmc s disk ( maximum effect @xmath111 in our 30 fields ) , and ( 3 ) fields with poorly calibrated photometry .",
    "we note that the offsets are not correlated with seeing , sky , airmass or stellar density of the template images , but are strongly correlated with the color of the lmc clump , indicating that differences in extinction are the dominate cause .",
    "the offsets are derived by requiring the peaks of the clump and the tips of the giant branch to line up in @xmath75 with the ` universal ' lfs .",
    "the effect of extinction is to lower the number of source stars to which the survey is sensitive .",
    "only 22 lmc fields are well - calibrated ( @xcite ) and these typically have the smallest offsets , while 8 lmc fields have only approximate calibrations and typically have large positive offsets .",
    "once the offsets are applied we next require the number stars in the ` universal ' lfs in the range @xmath112 to match the number of objects in the ground - based lf in the same range .",
    "the two shifts typically align the ` universal ' lf to the observed lf quite well , both inside and outside the calibration bin , as seen in figure  [ fig - example - norm - lf ] .",
    "figure  [ fig - so22-density ] displays the normalizations for each of the 30 macho fields derived in the manner described above .",
    "our choice of units for the normalization is the ratio of the number of stars to the number of objects brighter than magnitude @xmath75 . in this case",
    "@xmath113 is convenient as there are few objects dimmer than this limit .",
    "the @xmath114 ratios are plotted versus the average density ( in @xmath115 ) for each field as solid circles and labeled with the field number .",
    "the normalizations are also supplied in table  [ tab - norms ] .",
    "note the general trend of increasing @xmath114 with increasing object density , which is simply a reflection of the fact that our fields become less complete in more crowded fields .",
    "the substantial amount of scatter seen at any given density is a reflection of other factors affecting completeness .",
    "for example , @xmath114 is strongly correlated with template sky for any given density , in the sense that fields with high sky tend to be less complete ( have higher @xmath114 ) . though @xmath114 appears not to be significantly correlated with template seeing this is not surprising as the range in seeing for our templates is not nearly as large as the range in sky .    using our 3 hst fields",
    "we may make a direct determination of @xmath114 by simply counting the macho objects that lie inside the wf ccds .",
    "these are shown in figure  [ fig - so22-density ] as solid triangles .",
    "we have connected points from the same fields with a solid line .",
    "note that the density shown for the field @xmath114 normalizations is an average over the whole field , while for the hst @xmath114 normalizations it is only over the wf ccds .",
    "in all three cases the hst frames are in higher than average density regions of the macho fields , resulting in higher @xmath114 ratios . the overall agreement between @xmath114 as determined using the individual field normalizations and as determined directly with hst is reassuring .",
    "we have also created three synthetic images as an additional check on the normalizations and to look for possible biases due to blending .",
    "briefly , the synthetic images are @xmath116 in size and were generated using empirical psfs ( see   [ sec - prdb ] ) derived from the template images .",
    "a lf similar to @xmath107 above was used to add @xmath117 stars down to @xmath118 uniformly over the image . a uniform sky with poisson noise was added to match the adu / pixel distribution and then  was run in template generation mode on these synthetic images . the resulting number of recovered objects and sky were compared with the real image values simulated .",
    "several iterations over the number of added stars versus added uniform sky were required to match the observed number of objects and sky level .",
    "the @xmath114 ratio for each of these synthetic images is shown as an open triangle in figure  [ fig - so22-density ] and is connected by a solid line to its corresponding field average .",
    "the densities of the three synthetic images are in general different from the corresponding field averages , based on where the chunk lies in the field .",
    "note the very similar behavior of the synthetically derived @xmath114 compared with the field average @xmath114 values and the hst derived @xmath114 .",
    "in all three cases the higher density had the higher @xmath114 ratio .",
    "also note the much larger increase in @xmath114 for the higher densities .",
    "this suggests a saturation point is reached in our densest fields whereby the addition of more stars results in a dwindling increase in the number of detected objects as the stars pile on top of one another in the image .",
    "we see a similar behavior in the synthetic images where to recover a given number of objects one must add a proportionally larger number of stars .    using the synthetic images we may also estimate the size of a possible bias in the normalizations due to blending",
    ". it would be desirable for our normalization bin ( @xmath112 ) to contain an equal number of photometered objects and real stars : , @xmath119 .",
    "our synthetic images have values of @xmath120 , @xmath121 , and @xmath122 , where the errors are 1@xmath123 poisson errors .",
    "they all appear to have slightly more photometered objects than real stars in the normalization bin , though two are entirely consistent with 1.0 .",
    "only the highest density image has a value that is significantly larger than 1.0 ( but by 4.5@xmath123 ) .",
    "this has the potential of biasing our derived values of @xmath114 to larger values .",
    "however , of the three synthetic images two have extreme densities ( as these were chosen to look for this effect ) and are not representative of the average density in our fields ( see figure  [ fig - so22-density ] ) . because we expect the biases to be strongest in our most crowded fields ( and to a lesser extent worse seeing template images ) the overall bias is certainly much less than the 18% seen in the extreme artificial chunk , and probably even less than the straight average of @xmath124% .",
    "another estimate versus @xmath125 and extrapolates the results to all 30 fields . a net bias of 6 - 8% is estimated . ]",
    "puts the possible bias at 6 - 8% .",
    "given the fairly small size of the effect ( @xmath126% ) we make no correction for this bias , but include it in our error budget ( see   [ sec - errorbudget ] ) .    the errors in @xmath127 ( table  [ tab - norms ] )",
    "were estimated as follows : ( 1 ) we allowed an uncertainty in the offsets of 0.1 mag , based on the scatter in the offsets between fields , and ( 2 ) based on the estimates of the maximum blending bias discussed above , the normalizations could be at most 10% too high and probably only 5% too low .",
    "we then propagated these two uncertainties through the normalization procedure to produce the final errors in the table .",
    "the average error in @xmath127 per field is @xmath40 .",
    "the density ( @xmath115 ) weighted mean number of stars to objects with @xmath128 is @xmath129 for @xmath107 and @xmath130 for @xmath110 .",
    "the normalization of each field amounts to correcting the macho nominal exposure in _ object - years _ to an exposure in _ star - years_. the uncertainty in the normalization is moderately large and translates directly into a moderately large uncertainty in the efficiency as discussed in   [ sec - results ] .",
    "since we simultaneously image in both a red and a blue passband we require a color - magnitude diagram ( cmd ) from which to draw our artificial stars .",
    "such a cmd was created for precisely this purpose and its construction is described in detail in alcock ( 1999b ) .",
    "briefly , we spliced the bright end ( @xmath131 ) of a cmd derived from @xmath124 million objects ( @xcite ) from our 22 calibrated ground - based fields onto the dim end ( @xmath132 ) of a cmd derived from our combined 3 hst fields ( which is scaled by relative sky area to the 9 m cmd ) .",
    "the hst cmd was corrected on the dim end ( @xmath133 ) using a completeness function that corrected the data to a slope of 0.415 in @xmath134 versus @xmath75 . a small amount of editing was also required to remove isolated high pixels ( due to the scaling up of the lower s / n hst data ) and bright foreground stars .",
    "the cmd used here need not be accurate ( though we endeavored to make it so ) as its only purpose is to draw artificial stars from a realistic distribution in color .",
    "we expect no dependence of the efficiency on color ( and see none ) and so henceforth discard any color dependency .      to create the photometric response database we selected 10 sub - images , approximately @xmath135 in size (  chunks \" ) , that span the range of stellar densities observed in the 30 macho fields ( @xmath136 to @xmath137 @xmath115 ; see table  [ tab - norms ] ) and that lie at a range of distances from the optical center of the bar ( from 10 arcmins to 3.2 degrees ) . for each of these 10 chunks we extracted from the macho archive a range of observing conditions that fairly sample the survey s distribution in seeing and sky .",
    "table  [ tab - chunks ] lists some relevant parameters for each chunk , including macho field and chunk i d , template observation number , density in @xmath115 , number of observing conditions @xmath138 , number of stars per grid @xmath139 ( see below ) , and the total number of useful prfs .",
    "the mean number of observing conditions for these 10 chunks is 69 , a factor of 3 more than used in  and .    in order to add artificial stars to these images we require knowledge of the point - spread function ( psf ) for each image .",
    "we also need a photometric and coordinate transformation ( ctr ) that maps the photometry and position of the artificial stars to some reference image , in this case the template images for each chunk .",
    "we generated empirical psfs using a perl script that automates the astronomical photometry package /(@xcite ) .",
    "the script iterates multiple times with a series of simple analytic psfs searching for stars , fitting , and subtracting neighbors to candidate psf stars on each iteration while using a progressively more realistic model of the psf .",
    "the final psf is a lorentz - gaussian analytic model with an empirical look - up table of corrections .",
    "psfs for each of the @xmath140 chunks are generated in this fashion , and are of higher quality than the simple modified gaussian analytic model used by .",
    "we visually inspected a number of psf subtracted images and were quite satisfied with the subtraction .",
    "photometry , using these psfs , was run on all @xmath140 chunks and the results fed into a custom code that searches for and computes both photometric and coordinate transformations .",
    "the code is based on the groth ( 1986 ) algorithm and incorporates a color dependent term in both photometric and coordinate transformations .",
    "the inclusion of color in the transformations allows for the effects of airmass , differential refraction , and a known systematic pier side ccd effect in the macho data (  blue jitter \" ; see alcock ( 1999b ) ) . from the residuals to the fits we find the coordinate transformations are good to @xmath141 pixels and the photometric transformations to @xmath142 mag .",
    "grids of artificial stars are added to each of the 10 chunks over all @xmath143 observing conditions using the appropriate psfs and ctrs for each observing condition .",
    "the grids contain from 64 to 156 artificial stars ( table  [ tab - chunks ] ) positioned on a pseudo - random spatial grid such that stars are never closer than @xmath144 arcsecs ( or approximately @xmath145 fwhm in median seeing ) and never closer than @xmath1 arcsecs to a boundary of the chunk .",
    "this is to avoid missing too much data because of telescope pointing errors .",
    "the magnitudes of the artificial stars , @xmath75 and @xmath76 , are drawn from the cmd of   [ sec - lmccmd ] in the range @xmath146 and @xmath147 .",
    "the cmd is sampled in a square - root fashion to ensure uniform statistics over the large range in luminosity .",
    "each star in the grid is added over a range of 15 peak magnifications @xmath148 . in each image",
    "the peak magnifications for each star are staggered so as not to add too many highly magnified stars to a given image . to cover as much of each chunk s image plane as possible ,",
    "60 different grids are created for each chunk .",
    "this corresponds to covering @xmath149 of the image plane ( depending on the chunk ) and represents a statistically significant number of possible photometric conditions in which a star could reside .",
    "all stars in a grid are first added with a magnification of one to the template image of the chunk and  is run in template generation mode on these template images to create the template files . with the template files created , we next loop through all observing conditions and all possible peak magnifications , adding the grid to the corresponding observing condition using the appropriate psfs , ctrs , ccd gains , and with a staggered magnification for each star .  in routine mode",
    "is run on each image created and the results are organized and stored in prdb files .",
    "we chose to store all photometry on the three spatially nearest recovered objects to each artificial star in order to map out where the added flux goes . for each grid of stars a prdb file with 17.4 mbytes of photometry is created . in total",
    "the prdb contains 10.4 gbytes of photometry on 196,740 recovered objects .",
    "the total number of artificial stars added to all 10 chunks over the 60 grids per chunk is 65,580 .",
    "of these 54,981 artificial stars contain enough reduced data ( greater than 50% in each passbands ) to be useful as prfs .",
    "this is a factor of five more prfs than was used in  and .",
    "approximately 16% of the prfs were lost due to a combination of ( 1 ) falling inside an obliterated region caused by a saturated star ( @xmath150 ) , ( 2 ) missing data entirely in either the red ( @xmath151 ) or blue ( @xmath152 ) bandpass , and ( 3 ) falling near an obliterated region , ccd defect , or chunk edge such that on average more than 50% of the photometry was missing ( @xmath153 ) .",
    "since we are only concerned with how responds to added flux the loss of poorly determined prfs is not a concern .",
    "the number of single bandpass lightcurves , ccd defects , and other missing data are preserved in the 1% database of lightcurves .",
    "initially we were concerned with how  divides up flux between two or more closely spaced stars , and which neighbor is most ` sensitive ' to the added flux .",
    "for example , in  two lightcurves ( events  7a and 7b ) are , in fact , the same event .",
    "event  7 was bright enough and in a locally crowded enough region that some of the flux from the primary ( 7a ) bled into a secondary neighbor ( 7b ) causing a spurious detection .",
    "although event  7b was removed from the list of microlensing events and had no adverse effect on the results of , it underscores the need to investigate what effect multiple crowded neighbors have on our efficiency . to investigate this we stored the photometry for the three spatially nearest objects to each artificial star in the prdbs .",
    "we found that in the vast majority of cases ( @xmath154 ) the nearest neighbor snatched most of the added flux and was the most ` sensitive ' .",
    "this is reassuring , both for simplicity s sake and because our previous work (  and ) had implicitly assumed this behavior .",
    "we illustrate this as follows .    for each neighbor",
    "we define a recovered magnification , @xmath155 , where @xmath156 is the flux of the neighbor for observing condition @xmath9 and peak magnification @xmath157 . here",
    "@xmath46 is the baseline flux for the neighbor ( that is the flux averaged over all @xmath9 with @xmath158 corresponding to @xmath159 ) . a scatter plot of @xmath160 versus @xmath74 for all @xmath9 shows an excellent linear relationship as expected ( see below ) , with a fit slope @xmath161 that is generally between 0 and 1 .",
    "this slope corresponds to the average blend fraction .",
    "we constructed a measure of sensitivity to added flux and computed this measure for each of the three neighbors to each artificial star .",
    "the measure we used was the fit slope @xmath10 divided by a mean relative error bar @xmath123 for the baseline , , measure = @xmath162 .",
    "this measure ensured that neighbors with large slopes and small error bars are counted as the most sensitive , while in the case of two neighbors with equal slopes the neighbor with the smallest error bars is counted as the most sensitive .",
    "this is likely to be the case as both selection criteria set a and b make use of a signal - to - noise cut requiring the magnification to exceed some multiple of the mean relative error bar ( see   [ sec - sodo ] and ) .    for each artificial star ,",
    "the three nearest neighbors are ranked according to the measure , and a cut @xmath67 was applied to each neighbor to ensure that the prf was not ` junk ' ( here @xmath2 is the maximum magnification of the recovered neighbor ) . only in @xmath163% of the cases",
    "was either the 2nd or 3rd nearest neighbor more ` sensitive ' than the nearest neighbor .",
    "we visually inspected a large number of these cases .",
    "in most cases there were two neighbors about equally spaced from the artificial star with neighbor  1 ( the closest ) dimmer than neighbor  2 .",
    "neighbor  2 was more ` sensitive ' for two reasons , ( 1 ) being brighter it had the smaller relative error bar and ( 2 ) due to a slight systematic bias in  the brighter stars , which are reduced first , can pirate flux from the wings of nearby dim stars . since only @xmath163% of cases are in error due to this effect , we restrict our attention to only the nearest neighbor .    a scatter plot of @xmath160 versus @xmath74 over all observing conditions is shown for four prfs in figure  [ fig - prfs ] .",
    "note the excellent linear relationship fit by the solid line .",
    "the dashed line is the simple analytic response function used in the sampling efficiency (   [ samplinglc ] ) and is plotted here for comparison .",
    "the panels correspond to ( a ) a unblended prf ( @xmath164 ) , ( b ) a somewhat blended prf ( @xmath165 ) , ( c ) a moderately blended prf ( @xmath166 ) , and ( d ) a heavily blended prf ( @xmath167 ) .",
    "the scatter at each @xmath74 is composed of @xmath143 observing conditions and is typically well correlated with seeing in the sense that worse seeing induces slightly larger magnifications .",
    "this is easy to understand , since worse seeing implies the psfs overlap more and thus more flux can be contributed to the nearest neighbor by a magnified star",
    ". a few cases of very high positive correlation and even negative correlation exist and correspond to cases where ( 1 ) the artificial star is not directly detected and lies a moderate distance from the nearest neighbor so that when it is magnified it only affects its nearest neighbor in poor seeing and ( 2 ) the artificial star lies almost equidistant between the two nearest neighbors and in good seeing contributes to the nearest neighbor but in bad seeing contributes more to the second nearest neighbor .    to investigate how the relative error bars @xmath123 ( error bars expressed in magnitudes ) behave versus @xmath74 we define an effective error ` de - magnification ' as @xmath168 , where @xmath169 is @xmath123 for observing condition @xmath9 and peak magnification @xmath157 .",
    "we normalize the error bar magnification separately for each observing condition @xmath9 because @xmath123 is in general highly correlated with seeing ( becoming larger in worse seeing ) .",
    "notice that @xmath170 for all @xmath9 when @xmath171 ( that is @xmath172 ) .",
    "figure  [ fig - prferrors ] is a scatter plot of @xmath173 versus @xmath74 for the same set of prfs as shown in figure  [ fig - prfs ] .",
    "over - plotted as a solid line on each panel is the purely poisson behavior used in the sampling efficiency ( @xmath174 ) .",
    "the behaviors of the prf s relative error bars show little resemblance to this purely poisson approximation .",
    "rather the prfs behave more like @xmath175 ( dashed line in the figure ) , which can be understood as follows .    in our most common case",
    "the noise is dominated by a combination of the poisson noise in the sky plus extra poisson noise added due to neighboring stars which have been subtracted during the photometry reductions .",
    "these are both independent of magnification , so the error in flux should not depend on magnification .",
    "that is , the error in linear flux units should not change at all , while the relative errors should behave as @xmath176 or , as in our case @xmath177 .",
    "this is the pattern we see in our prfs .",
    "however , very bright stars typically fall into the purely poisson limit .",
    "heavily blended prfs can also approach the poisson limit , and in some cases their relative error bars change very little as the magnified artificial star is only a small perturbation on the much brighter neighbor .",
    "the broad range in behavior of the prfs is illustrated in figure  [ fig - slopes ] , which is a scatter plot of fit slope @xmath161 versus magnitude @xmath75 for @xmath178 prfs .",
    "the amount and distribution of blending is immediately apparent in this plot , with the artificial stars being strongly bifurcated towards either being recovered within @xmath179 of their input flux or being blended by greater than @xmath180 .",
    "however , there are still a substantial number that are recovered at intermediate blend fractions , and as the artificial stars shown here represents a square - root sampling of the cmd ( thus under - weighting dim stars ; see   [ sec - prdb ] ) the corresponding results for a linear sampling would show proportionally even more blending .",
    "the left ordinate is the fit slope @xmath10 and the right ordinate is scaled to the maximum recovered magnification that each prf contains ( due to our maximum input magnification of 50 ) .",
    "for example , an artificial star with @xmath181 would contain a maximum recovered magnification of @xmath182 in the prf ( with any higher magnifications needing to be extrapolated beyond this point , see   [ modifylcsection ] ) .",
    "also plotted in figure  [ fig - slopes ] is a family of five smooth curves that correspond to model @xmath183 .",
    "each curve in the family assumes a certain amount of blended flux corresponding to @xmath184 , and @xmath185 mags in the figure .",
    "for example , a star blended with 20 mags of additional flux ( the center curve ) would fall at @xmath186 if it was @xmath187 , @xmath181 if it was @xmath188 , and @xmath189 if it was @xmath190 .",
    "note how the family of curves brackets the scattered points fairly well .",
    "the solid horizontal line labeled @xmath191 illustrates that stars fainter than @xmath81 rarely , if ever , are magnified greater than this limit . as a consequence ,",
    "if one desired to add stars fainter than @xmath192 , one would also need to add them at magnifications greater than 50 .",
    "the prfs also allow us to model how the photometry flags ( crowding , @xmath193 , fit sky , etc . ) are handled by  under various observing conditions and peak magnifications .",
    "we briefly summarize the noteworthy effects here .",
    "the crowding parameter , which is a measure of the amount of contaminating flux from nearby neighbors , not surprisingly , is highly correlated with seeing . as such",
    "we define a multiplicative ` magnification ' in a fashion identical to the relative error bars discussed above . in most cases ( @xmath194 )",
    "there is little or no variation of crowding with @xmath74 .",
    "however , in a few cases the crowding parameter increases smoothly with @xmath74 .",
    "the @xmath193 is also strongly correlated with seeing , but in the sense that the fit to the psf is worse in better seeing .",
    "this anti - correlation is mostly due to the photometered object being made up of multiple overlapping psfs , which are smoothed out in bad seeing . unlike the crowding parameter",
    ", the @xmath193 is anti - correlated with @xmath74 , in the sense that high magnifications result in poor fits to the psf .",
    "the fit sky parameter is not significantly correlated with either seeing or sky , and in only a few cases ( @xmath195% ) is the fit sky well correlated with @xmath74 , usually in the sense that it is higher for larger peak magnifications , but not always .",
    "neither the missing pixel or cosmic ray flags significantly correlate with seeing , sky , or magnification .",
    "the object type is more complicated , but fortunately for our purposes is not important .",
    "how the object type changes with seeing and sky is already properly handled in the 1% database and how it might change with magnification is inconsequential as long as it remains a valid type .",
    "we now replace the sampling efficiency rules (   [ samplinglc ] ) for modifying 1% database lightcurves with a new set of rules derived from the prfs . the prfs offer us an empirical set of rules that realistically incorporate blending and the many systematic photometry effects observed in  that were described in the last section .    to add microlensing onto a lightcurve with the prfs we must first match a lightcurve to a prf . this is most consistently performed using only the available measured parameters of the lightcurves , such as magnitude , color , average crowding , average error , etc .",
    "we have limited ourselves to three parameters , @xmath58 , @xmath196 , and crowding for the match .",
    "a match in average error was not chosen as it is already highly correlated with magnitude .",
    "instead we chose to match in crowding for the following reasons , ( 1 ) the average error is also correlated with crowding ( independent of magnitude ) , ( 2 ) the crowding parameter is a natural measure for parameterizing the image plane ( , regions of high stellar density versus low stellar density ) as there is a strong correlation ( @xmath197 ) of the average crowding in macho fields with stellar density , and ( 3 ) of all the measured parameters , we believe crowding to be the most likely to be connected with blending . though we see no strong correlations between blending and crowding , we do see a bifurcation reminiscent of figure  [ fig - slopes ] with a slight preference for strongly blended events to also be highly crowded .    to match our two large databases ( 1% database and prdb database )",
    "as uniformly as possible we use the following scheme .",
    "first , the 1% database of lightcurves is sampled uniformly because of the importance of correctly weighting the temporal sampling and the unbiased nature of the database . for each lightcurve in the 1% database a robust mean magnitude @xmath58 , color @xmath196 , and crowding",
    "@xmath198 are computed .",
    "the prfs are binned in three dimensions corresponding to their baseline magnitude @xmath199 , color @xmath200 , and crowding @xmath201 , with bins sizes of @xmath202 magnitude ( @xmath203 ) , @xmath204 color ( @xmath205 ) , and @xmath206 crowding ( @xmath207 ) .",
    "the bin sizes are constant over the most dense regions of their respective distributions , but grow slightly in size near the edges to accommodate for sparseness .",
    "the mean number of prfs in each bin is @xmath208 .",
    "however , due to the shape of the cmd @xmath209 of these bins are empty ( as they should be ) and thus the mean number of prfs in occupied bins is @xmath210 , with the typical occupied bin containing 12 - 20 prfs . with the large number of prfs employed it is unlikely ( @xmath211 ) that a lightcurve will encounter an empty bin .",
    "when this does occur we simply match to the nearest non - empty bin ( while holding crowding constant ) which is never more than one bin away . the prf bin that best matches the lightcurve",
    "is then selected and a prf is randomly chosen from this bin . in this way we sample the prfs as uniformly as possible .",
    "once a prf has been matched to a lightcurve , event parameters @xmath2 , @xmath4 , and @xmath3 are generated as in   [ samplinglc ] . the event is now added onto the lightcurve using the rules from the prf . each observation on the lightcurve with @xmath212",
    "is matched to the closest corresponding observing condition , @xmath9 , in the prf . in practice",
    "this amounts to minimizing the quantity @xmath213 to determine @xmath9 , where @xmath214 is the difference between the observation s seeing and the seeing in one of the @xmath143 observing conditions contained in the prf , normalized to the maximum range of seeing .",
    "@xmath215 is similarly defined and normalized .",
    "having determined the observing conditions @xmath9 , a two point linear interpolation is used to compute @xmath160 based on the low point @xmath216 and high point @xmath217 that bracket @xmath14 ( or the lowest two points for an extrapolation ) . to preserve as much of the intrinsic lightcurve scatter as possible",
    "a technique similar to that outlined in   [ samplinglc ] is employed in magnifying the flux . that is each magnitude",
    "is modified as @xmath218 .",
    "the relative error bars are modified as @xmath219 , where @xmath123 is the relative error bar for this observation and @xmath173 is also computed via a linear interpolation between @xmath220 and @xmath221 from the tabulated values of @xmath222 (   [ sec - prf ] ) .",
    "this technique preserves the intrinsic size of the lightcurve s relative error bars and realistically modifies how they respond with @xmath74 over the various observing conditions .",
    "the prfs also allow us to modify the photometry flags recorded by . as discussed in ",
    "[ sec - prf ] some of these show clear signs of systematic behavior with magnification .",
    "we chose to modify ( 1 ) the crowding parameter , which represents the amount of flux contributed from nearby stars , ( 2 ) the @xmath193 , which tends toward worse fits in better seeing and high magnification , and ( 3 ) the fit sky value .",
    "we do not modify ( 4 ) the object type flag , ( 5 ) the weighted fractions of the psf masked due to cosmic rays , and ( 6 ) the weighted fractions of the psf masked due to bad pixels .",
    "the flags are modified as @xmath223 , where @xmath224 is the respective flag ( crowding , @xmath193 , or fit sky ) and @xmath225 is a linearly interpolated difference between the prf s flag value at @xmath74 and at @xmath159 , computed separately for each observing condition @xmath9 .",
    "because the flags are logarithmic in nature the magnification translates into an additive term , much like in the case of magnitudes .",
    "this technique preserves the lightcurve s intrinsic flag values while realistically altering them as a function of @xmath74 and observing conditions .",
    "a sample lightcurve modified using the four prfs displayed in figures  [ fig - prfs ]  and  [ fig - prferrors ] is illustrated in figure  [ fig - artif - lc ] . in each panel",
    "the input event parameters were the same , @xmath226 and @xmath227 days .",
    "the panels correspond to blend fractions ( a ) @xmath164 , ( b ) @xmath165 , ( c ) @xmath166 , and ( d ) @xmath167 .",
    "note the dramatic drop in magnification @xmath2 and relative shortening of the duration @xmath3 as the event becomes more blended .",
    "also note the chromatic behavior exhibited in prf ( c ) due to the difference in color between the lensed star and the blended flux .",
    "we have visually inspected a large number of artificial lightcurves and compared the modified portions with real events seen towards both the lmc and galactic bulge .",
    "the comparison of magnification , error bars , and flags and their correlations with seeing and magnification are all quite satisfactory .",
    "a procedure similar to that outlined in   [ samplingcalculation ] is used to compute the photometric efficiency , with one important difference . in   [ samplingcalculation ] the distribution in luminosity of the stars",
    "was assumed to be the same as that observed by the survey ( , uncorrected for incompleteness ) since all photometered objects were counted as resolved stars .",
    "since we are now adding events onto lightcurves using an underlying luminosity distribution we need to integrate over this distribution , as the observed distribution is clearly incorrect (   [ sec - cmd ] ) . in principle , one could quantify the efficiency as a function of both duration @xmath3 and luminosity @xmath75 , and use this directly .",
    "however , in practice we can not unambiguously determine the unlensed luminosity ( at least without additional intensive follow - up photometry for blending fits or photometry from space ) . since the lmc s lf is well known to @xmath192 we opt to integrate out this variable .    to generate adequate statistics we make 10 passes through the 1% database of lightcurves , matching each lightcurve to a prf , which inturn is used to modify the lightcurve (   [ modifylcsection ] ) .",
    "bookkeeping information ( lightcurve i d , prf i d , @xmath75 , @xmath228 , @xmath58 , @xmath196 , @xmath2 , @xmath4 , @xmath3 , etc . ) for all lightcurves is stored and matched to the corresponding statistics ( @xmath60 , @xmath61 , @xmath62 , etc . ) generated by the time - series analysis (   [ sec - sodo ] ) .",
    "selection criteria set a and b are applied to these statistics and the results stored as integers in the datacube .",
    "the datacube is binned in two dimensions , @xmath75 and @xmath3 .",
    "recall that events are added uniformly in @xmath4 and @xmath42 , and so these are averaged over .",
    "we choose 100 bins in @xmath75 of size 0.1 mag in the range @xmath229 , and 24 bins in @xmath3 that are logarithmically spaced in the range @xmath230 days ( table  [ tab - eff ] ) .",
    "our artificial events are added uniformly in @xmath231 , so bins logarithmically spaced insures equal numbers of events in each @xmath3 bin . for each bin",
    "an efficiency is computed : @xmath232 where @xmath233 and @xmath234 are the number of events that pass the selection criteria set and the number of added events in the bin of @xmath3 and @xmath75 , respectively .",
    "it is worth mentioning that because @xmath235 is computed separately in each @xmath75 bin , this function is independent of the cmd used to seed the artificial star tests . from 10 passes through the 1% database ,",
    "@xmath236 million artificial events are generated and of these only @xmath237 pass criteria set a and @xmath238 pass criteria set b. the mean number of added events per bin is 500 and the mean number of recovered events per bin is 18 ( criteria set a ) .",
    "the function @xmath235 for criteria set b is shown in figure  [ fig_eff_per_bin ] as a contour plot in panel ( b ) .",
    "the contours correspond to efficiencies of 0.001 , 0.01 , 0.1 , 0.2 , 0.3 , 0.4 , and 0.5 .",
    "the gross behavior with @xmath3 and @xmath75 is apparent , with a broad peak in efficiency over the ranges @xmath239 days and @xmath240 .",
    "the function @xmath235 falls off rapidly for magnitudes smaller than @xmath241 due to an explicit cut @xmath242 ( criteria set b ) , but the more gradual fall off for dim stars is a natural consequence of fainter , lower s / n events .",
    "the gradual drop in efficiency for short duration events is caused by the sampling issues discussed in   [ samplingresults ] .",
    "the sharp cut at long durations ( @xmath65 days ) seen in the sampling efficiency has here disappeared , although a remnant can still be seen for bright events .",
    "the cause of this , of course , is blending .",
    "bright events are far less likely to be heavily blended , and thus are unlikely to be recovered with @xmath3 s longer than 600 days .",
    "events that are fainter are more commonly blended ( fit @xmath3 s much shorter ) and can be scattered below the cut at 600 days .",
    "a corollary to this is that intrinsically short events are unlikely to be detected on faint stars , which are typically blended , as is also seen in figure  [ fig_eff_per_bin ] , panel ( b ) .    given the uncertain knowledge of the source star s luminosity , the somewhat noisy function @xmath235 , and the fairly well constrained shape of the lmc s lf , we have opted to integrate out the variable @xmath75 in the function @xmath235 .",
    "although the shape of the lmc s lf is well known , the overall normalization to our fields , that is the number of stars with @xmath128 in our fields , is less certain (   [ sec - cmd ] ) .",
    "this uncertainty in normalization translates into an uncertainty in the survey s exposure in _ star - years_. however , it is expected that the efficiency times the exposure will converge at some magnitude @xmath243 .",
    "furthermore it is convenient to refer to our ` exposure ' in units of objects - years ( the number of lightcurves monitored times the duration of the survey ) as this number is well known .",
    "we opt to move the ( uncertain ) normalization , that translates the ` exposure ' in _ object - years _ into exposure in _ star - years _",
    ", into the efficiency .",
    "we can understand this as follows .",
    "assume a general distribution of event durations @xmath12 for some galactic model .",
    "the number of expected events @xmath244 is just ,    @xmath245    where the exposure here , @xmath246 , is in star - years and the efficiency is calculated from @xmath235 as ,    @xmath247    here @xmath243 is some cut - off magnitude where the integration is stopped and @xmath248 is the lmc s lf normalized such that ,    @xmath249    the exposure , @xmath246 , in equation  [ equation12 ] must be related to the observed number of objects , @xmath250 , as ,    @xmath251 n_{\\rm{obj } } t , \\label{equation15}\\ ] ]    where @xmath252 is the time - span of the survey and @xmath253 is a scaling factor that converts the average number of objects seen in the survey to the actual number of stars , down to the cut - off magnitude @xmath243 .",
    "@xmath253 may be estimated from ,    @xmath254    where @xmath255 is the ground - based luminosity function and is normalized to the total number of objects observed by the survey : , @xmath256 . similarly @xmath257 is the true underlying lf normalized as in   [ sec - lfnorm ] .",
    "the normalization @xmath253 was estimated for each field in   [ sec - cmd ] ( table  [ tab - norms ] and figure  [ fig - example - norm - lf ] ) for two cut - off magnitudes @xmath258 and @xmath259 and for two lf ( @xmath107 and @xmath110 ) .",
    "we make a simple re - definition ; let @xmath260 { \\cal e}_*(\\that)$ ] and @xmath261 . with these definitions equation  [ equation12 ] can be written as ,    @xmath262    a similar re - definition may be performed on equation  [ equation2 ] for the optical depth .",
    "the advantage of using @xmath7 and @xmath263 instead of @xmath246 and @xmath264 is twofold .",
    "firstly , the exposure in _ object - years _ , e , is known accurately .",
    "secondly , this substitution leaves @xmath263 containing the only reference to @xmath243 ( implicitly ) and we can investigate its convergence with magnitude easily .",
    "it is important to note that with the above definition of @xmath263 , the efficiency is no longer bound to lie below one .",
    "this slightly un - intuitive result is due to the fact that @xmath253 may be quite large ( table  [ tab - norms ] ) , though in practice @xmath263 always lies below one .",
    "a practical way of viewing @xmath263 is : given @xmath253 events , @xmath263 is the expected number of detected events for the given @xmath3 . in the limit",
    "@xmath265 the efficiency @xmath263 recovers its usual meaning .",
    "figure  [ fig_eff_per_bin ] illustrates the integration of @xmath235 , panel ( b ) , over a lf , panel ( a ) . the resulting function @xmath266*{\\cal e}_*(\\that)$ ]",
    "is shown in panel ( c ) .",
    "our two lfs , @xmath107 and @xmath110 , and their corresponding values of @xmath267 are displayed as dotted and solid lines , respectively .",
    "an important result is that @xmath263 is fairly robust to uncertainties in the lf fainter than @xmath108 . for durations less than 75 days the difference in @xmath263 as derived using either lf is less than 1% .",
    "the difference , however , becomes progressively larger for longer durations due to the relative difference in contributions from faint stars exhibited by the two lfs . at 300 days",
    "the difference is @xmath151 . in ",
    "[ sec - cmd ] we chose to favor @xmath110 over @xmath107 because of our hst completeness tests and because it seems unlikely that the lf will continue to rise so steeply beyond the clump for so long .",
    "evidently any moderately different lf would produce only a small difference in the overall efficiency .    in figure  [ fig_phot_eff ]",
    "we present the efficiency @xmath263 for selection criteria set a and b using lf @xmath110 .",
    "also shown for comparison are the photometric efficiencies used in  and .",
    "many of the differences between the old and new results , as seen in the sampling efficiencies (   [ samplingresults ] ) , can also be seen here .",
    "again the most striking difference is the much larger efficiency at long durations . as described in ",
    "[ samplingresults ] this has multiple causes , including ( 1 ) almost three times more baseline in the  data than in the  data , ( 2 ) a longer duration cut of @xmath65 days and ( 3 ) 6 high density fields which were previously split into two separate years of data ( due to an early generation of templates ) have been recombined .",
    "a new reason , unique to the photometric efficiency , is the contribution of faint stars to the efficiency for long duration events .",
    "this effect was troublesome in the  and  results since we lacked adequate numbers of faint stars ( only a few with @xmath108 and none with @xmath133 ) and thus were only confident that the photometric efficiency had converged for durations less than 150 days .",
    "as we show below the  results were likely to have converged only for durations less than 100 days .",
    "however , this resulted in an underestimate in the efficiency of less than 10% for durations around 150 days .",
    "criteria set a is closer in design to the  cuts and , as a consequence , follows the older results more closely for very short durations up to about 60 days . as noted above the sharp cut - off at durations around 600 days seen in the sampling efficiency",
    "is smoothed over in the photometric efficiency because blending scatters intrinsically long duration events to shorter measured durations .",
    "figure  [ fig_convergence ] shows the convergence of @xmath263 with @xmath243 for the four combinations of selection criteria sets a and b and @xmath107 and @xmath110 . in each panel the convergence of four different durations ( @xmath268 50 , 100 , 300 , and 1000 days ) is shown .",
    "the ordinate is in arbitrary relative units .",
    "criteria set b is our loosest set of cuts and is the least convergent of the two selection criteria sets used in .",
    "an inspection of the figure also shows that @xmath107 gives a somewhat slower convergence than @xmath110 .",
    "this is not surprising as @xmath107 contributes a substantially larger number of fainter stars as compared with @xmath110 .",
    "criteria set a with @xmath110 converges for durations less than 1000 days by @xmath269 and criteria set b with @xmath110 converges for durations less than 300 days by @xmath270 .",
    "if the true lf is closer in form to @xmath107 then it is possible that our efficiency results are somewhat underestimated for long duration events ( see   [ sec - errorbudget ] below ) .",
    "however , since none of the 17 candidates in  have durations longer than 300 days we feel that the convergence of the efficiency is more than adequate .",
    "there are a number of potential sources of error in estimating our efficiency and we list the most important ones in table  [ tab - errorbudget ] .",
    "we crudely classify the errors as ` signed ' or ` unsigned ' .",
    "that is , if we are reasonably certain the effect would only increase ( or decrease ) the efficiency we classified it as ` signed ' and marked it with the appropriate sign in the table",
    ". if we are not certain of it s sign we called it ` unsigned ' and left a question mark in the sign column of the table .",
    "the first unsigned error in the table ( # 1 ) is simply the uncertainty in our normalizations and was estimated to be @xmath1% in   [ sec - lfnorm ] .",
    "that is we are confident that we know the number of stars to the limit @xmath271 in our lmc fields to within @xmath1% .",
    "this is by far our largest source of error in the efficiency .",
    "the second unsigned error ( # 2 ) is an uncertainly in our incomplete knowledge of the shape of the lmc s lf at faint magnitudes . in ",
    "[ subsec - phoeff ] we used the difference between @xmath107 and @xmath110 to estimate a 1 - 3% effect depending on the duration of the event .",
    "another source of unsigned error ( # 3 ) is due to the finite number of monte carlo events , which we estimate to be @xmath272% based on the binomial distribution and the number of monte carlo events used .",
    "the fourth entry in table  [ tab - errorbudget ] ( # 4 ) is signed and represents a potential over - completeness bias . because blending might over - populate objects with respect to stars in our calibration bin ( @xmath112 )",
    ", this could cause an overestimation of @xmath263 . in ",
    "[ sec - lfnorm ] we estimated this could be as large as @xmath124% , but likely to be somewhat smaller ( perhaps 6 - 8% ) .",
    "the next signed error ( # 5 ) is related to our choice of using only the nearest neighbor to each artificial star , when in fact as many as @xmath273% of prfs had 2nd or 3rd nearest neighbors which were more sensitive to the lensed flux .",
    "of course what matters is how many 2nd or 3rd nearest neighbors would have been detected but were not because the closest neighbor was used instead , and this is probably smaller than the number of 2nd and 3rd nearest neighbors who are more sensitive .",
    "the efficiency is likely to be underestimated somewhat by this error .",
    "the next two signed errors are small and relate to ( # 6 ) our use of a ` universal ' lf ( especially in the outer lmc disk fields where the true lf likely turns over at brighter magnitudes ) and ( # 7 ) a possible slight underestimation of @xmath263 if convergence has not been reached by @xmath118 ( , if the the true underlying luminosity function is closer to @xmath107 ;   [ sec - convergence ] ) .",
    "we leave two potential sources of error unexplored in this paper because of their highly uncertain and complicated nature .",
    "the first of these ( # 8 in the table ) is the difficulty of incorporating binary star systems into the determination of the lf .",
    "binary stars could increase our exposure ( thereby increasing @xmath263 ) but also shift the lf toward fainter magnitudes ( decreasing @xmath263 ) .",
    "the effect on the lf of the local neighborhood is still controversial ( @xcite ) and any hope of resolving this for the lmc is beyond the scope of this paper , and left for future work .",
    "another unexplored source of error ( # 9 ) is due to our lack of exotic lensing monte carlo events .",
    "the behavior of this source of error is difficult to estimate as the shape of exotic lensing is likely to lower our efficiency , but caustic crossings might well increase it ( @xcite ) .",
    "binary lensing events are likely to dominate this effect , but the distributions of their event parameters is wide open to speculation ( but see alcock 1999c ) .",
    "we plan to investigate the effects of a binary lens population on our efficiency in a future paper .",
    "given the generally small size of the individual signed errors relative to the size of the unsigned errors , as well as the poisson - like ` counting ' errors in the optical depth estimates ( 13 - 17 events gives @xmath274 errors in the optical depth ; see table  10 in ) , halo mass fraction , etc .",
    ", and the fact that a number of these signed errors are of comparable size but opposite sign , we have chosen not to attempt to correct for them .",
    "our estimates of their size are rough , but probably accurate to within a factor of two .",
    "there is no correct way to total systematic errors - but assuming they are uncorrelated we can sum them in quadrature to get a total of @xmath275% , not including errors # 8 and # 9 , which may be the largest , but for which we do not have good estimates .",
    "alternatively , we can add the signed errors algebraically to get @xmath276% , then to this add the unsigned errors in quadrature , giving @xmath144% total error .",
    "so our best guess at the size of our error is 21 - 22% plus the unknown effects of binary corrections to the lf and exotic microlensing .",
    "our efficiency for each field is shown in figure  [ fig_photeff_vs_field ] .",
    "these have been calculated in the manner described above and normalized with each field s @xmath127 ( table  [ tab - norms ] ) . by splitting our @xmath236 million monte carlo events into 30 fields ,",
    "the shot noise has increased to 5 - 10% , which is somewhat field dependent . in principle",
    "the shot noise can be reduced by simply running more passes , but the cpu time required is somewhat prohibitive at the present time .",
    "nevertheless the efficiency for each field is important when looking for gradients in optical depth or rates across the face of the lmc , which the present level of accuracy is adequate for , given the small number of events ( 13 - 17 ) seen toward the lmc .",
    "differences seen between fields in figure  [ fig_photeff_vs_field ] are due primarily to ( 1 ) different normalizations for each field ( table  [ tab - norms ] ) , physically corresponding to larger numbers of stars and thus probability of detecting events in some fields , ( 2 ) different sampling rates due to observing strategy and weather across fields , and ( 3 ) to a smaller degree more crowded fields tend to have a larger effective area ( area covered by stellar psfs in the image plane ) in which to detect the presence of magnified events , because of blending .",
    "as discussed in the introduction , blending induces a bias in the measured parameters @xmath2 and @xmath3 .",
    "we can quantify this bias using our monte carlo events , and have developed a method of statistically correcting for @xmath3 bias when calculating optical depths .",
    "figure  [ fig_bias ] plots the ratio @xmath277 versus @xmath278 for a random sample ( @xmath279 ) of monte carlo events : panel ( a ) is for sampling efficiency events and ( b ) is for photometric efficiency events ( both use selection criteria set b ) .",
    "the majority of sampling efficiency events are recovered with little or no parameter bias in @xmath3 .",
    "( there is a small amount of bias in @xmath2 ( both directions ) caused by sampling and weather gaps that effectively obfuscate very high magnification events . )",
    "as the sampling efficiency does not simulate blending this result is not surprising .",
    "the results for the photometric efficiency events is quite different .",
    "a significant amount of blending can be seen in panel ( b ) of figure  [ fig_bias ] , were approximately 40% of the monte carlo events are blended with an additional 10% or more of un - lensed flux .",
    "the trend of decreasing @xmath2 with decreasing @xmath3 for highly blended events is well delineated in the figure .",
    "note that the photometric efficiency events sample the cmd ( luminosity function ) in a square - root fashion (   [ sec - prdb ] ) and thus dim stars are underpopulated in panel ( b ) of figure  [ fig_bias ] .",
    "factoring this in , as is done below , further increases the amount of blending and the size of any potential correction .",
    "we can calculate the efficiency as a function of various parameters ( , @xmath280 , @xmath42 , @xmath75 , @xmath58 , etc . ) for the photometric efficiency , and some of these are shown in ( for example , see their figure  6 ) .",
    "however , since the monte carlo events sample the cmd in a square - root fashion we must bin and re - weight with the correct lf . we must also bin and re - weight with a realistic distribution in @xmath3 as the monte carlo events are added with durations uniform in @xmath231 , which is unlikely to be the true distribution .",
    "we chose to re - weight with the distribution of durations predicted by a standard halo model with delta function mass @xmath281 ( @xcite ) , since this distribution closely matches the data ( average duration @xmath282 days ; see ) .",
    "fortunately , model dependency is weak as the distributions in @xmath42 , weighted and un - weighted ( that is using the @xmath231 distribution ) are quite similar .",
    "if the @xmath3 bias is left uncorrected the optical depth will be underestimated ( equation  [ equation2 ] ) .",
    "there are two very different , but complimentary , ways to correct for this bias in @xmath283",
    ". ideally one could perform microlensing fits on individual events that allow for unlensed flux in each passband .",
    "then each event could be corrected for blending separately and the maximum amount of information in the set of @xmath3 s would be retained . in practice",
    "this approach is difficult as the lightcurves are not always well sampled and can have considerable photometric scatter making the blend fits uncertain ( @xcite )",
    ". this situation can be greatly improved with accurate , dense , follow - up photometry on alerted events as is being done now routinely ( @xcite ) . however ,",
    "not all events are alerted .",
    "in addition , blending fits are not always unique and only on fairly high magnification events can the fit parameters be extracted with confidence .",
    "a second approach is to correct the @xmath3 bias in a statistical fashion .",
    "since we have _ a priori _ knowledge of the distribution of source stars from the luminosity function @xmath248 and can estimate the distribution of uncorrected durations @xmath284 we can compute a first order average correction as ,    @xmath285    where @xmath235 is defined as above and @xmath286 is defined as : @xmath287 or the median @xmath3 bias for the monte carlo events in a bin of @xmath3 and @xmath75 .",
    "the quantity @xmath286 lies between zero and one and is a strong function of @xmath3 and @xmath75 in the sense that @xmath286 is one for bright events and approaches zero for both dim events and for long duration events .",
    "the results of equation  [ equation18 ] for criteria set a and b using lfs @xmath107 and @xmath110 are tabulated in table  [ tab - bias ] , assuming mean durations of 41 , 92 , and 130 days ( corresponding to delta - function masses of 0.1 , 0.5 , and 1.0 @xmath288 in the model @xmath284 , respectively ) .",
    "the mean duration of the microlensing candidates in  corresponds most closely with our value of @xmath289 days or an average mass of @xmath290 .",
    "this correction may be used in equation  [ equation2 ] by simply substituting @xmath291 to obtain ,    @xmath292    note the optical depth defined in this manner does not scale simply as @xmath293 .",
    "we have tried computing @xmath294 as a function of measured parameters ( such as @xmath58 and @xmath62 ) but find that it is fairly constant over the measured ranges .",
    "the use of a model distribution in @xmath3 is somewhat worrisome .",
    "however , the range in corrections @xmath294 for different @xmath3 distributions is acceptably small , about 5% ( table  [ tab - bias ] ) .",
    "the error induced in the optical depth is somewhat smaller ( @xmath151 ; see table  9 in ) .    to check this statistical correction we ran a set of monte carlos on a toy model using our artificial events . the monte carlos work as follows : ( 1 ) first we bin the recovered artificial events in @xmath3 and @xmath75 , ( 2 ) we create @xmath244 ` events ' by sampling the lf @xmath248 and @xmath3 distribution function @xmath295 for a simple halo model with a delta function mass @xmath281 ( model s in , , and ) , ( 3 ) for each of these @xmath244 ` events ' we chose an artificial event to represent it by selecting at random from the appropriate bin in @xmath3 and @xmath75 , ( 4 ) three different optical depths for these @xmath244 ` events ' are computed using three different @xmath3 s ( the true @xmath3 , the fit @xmath62 and the statistically corrected @xmath296 ) .",
    "the number of @xmath244 ` events ' corresponds to the predicted number of observed events as computed by equation  [ equation3 ] .",
    "the experiment is repeated 1000 times and the results for selection criteria set b and @xmath110 are displayed as histograms of @xmath283 in figure  [ fig_monte_tau ] .",
    "the _ dashed histogram _ corresponds to calculating @xmath283 using the fit @xmath62 s and clearly underestimates the optical depth ( @xmath297 for model s ; the vertical line in the figure ) .",
    "using the true durations @xmath3 to compute @xmath283 gives the correct optical depth ( _ solid histogram _ ) .",
    "the optical depth computed using the statistically corrected durations , @xmath298 , is displayed as the _ dotted histogram _ and correctly predicts the true optical depth in a fairly unbiased manner .",
    "similar unbiased results are found using selection criteria set a , @xmath107 , @xmath110 , and using the @xmath295 distributions with delta - function masses of 0.1 and 1.0 @xmath288 .",
    "these monte carlos give us confidence that this statistical correction can be used in an unbiased manner to compute the optical depth toward the lmc .",
    "the results of  for 5.7 years of photometric data toward the lmc rely critically on how well we understand the detection efficiency . in this paper",
    "we calculated these efficiencies , correcting the most important systematics effects with realistic models . to account for the wide range of issues due to blending",
    "we perform artificial star tests on a broad range of images .",
    "these artificial stars tests allowed us to empirically account for blending and to model our photometry code s systematics . correcting for blending also required an accurate knowledge of the lmc s lf because microlensing magnifies flux and increases the survey s sensitivity to dim , unresolved stars .",
    "we found that our sensitivity @xmath263 to dim , unresolved stars vanishes for magnitudes fainter than @xmath81 and durations less than @xmath299 days .",
    "our sensitivity in previous results (  and ) was somewhat underestimated for durations greater than @xmath300 days .",
    "we also found the @xmath3 bias , due to blending , is of the order of 20% and we presented a method for statistically correcting this bias in our optical depth estimates .",
    "the method is complimentary to using blended @xmath3 fits .",
    "we are very grateful for the skilled support given our project by the technical staffs at the mt .",
    "stromlo and ctio observatories , and in particular we would like to thank s. chan , g. thorpe , s. sabine , j. smillie , and m. mcdonald , for their invaluable assistance in obtaining the data .",
    "we especially thank j.d .",
    "reynolds for valuable assistance with the database software that has made this effort possible .",
    "this work was performed under the auspices of the u.s .",
    "department of energy by university of california lawrence livermore national laboratory under contract no . w-7405-eng-48 .",
    "work performed by the center for particle astrophysics personnel is supported in part by the office of science and technology centers of nsf under cooperative agreement ast-8809616 .",
    "work performed at mssso is supported by the bilateral science and technology program of the australian department of industry , technology and regional development .",
    "dm is also supported by fondecyt 1990440 .",
    "cws thanks the packard foundation for their generous support .",
    "wjs is supported by a pparc advanced fellowship .",
    "kg is supported in part by the doe under grant def03 - 90-er 40546 .",
    "tv was supported in part by an igpp grant .",
    "rccccccccc 1 & 2.01 & 1.68 & 2740.0 & 0.10 & 241.3 & @xmath301 & @xmath302 & @xmath303 & @xmath304 2 & 1.56 & 1.63 & 3423.0 & 0.08 & 184.7 & @xmath305 & @xmath306 & @xmath307 & @xmath308 3 & 1.56 & 1.53 & 2950.0 & -0.02 & 173.4 & @xmath309 & @xmath310 & @xmath309 & @xmath311 5 & 1.21 & 1.78 & 3285.0 & 0.12 & 237.9 & @xmath312 & @xmath313 & @xmath307 & @xmath314 6 & 1.53 & 1.52 & 3176.0 & 0.08 & 226.4 & @xmath315 & @xmath316 & @xmath317 & @xmath318 7 & 1.46 & 1.60 & 3122.0 & 0.25 & 233.7 & @xmath307 & @xmath319 & @xmath320 & @xmath321 9 & 1.33 & 1.49 & 1771.0 & 0.12 & 209.7 & @xmath322 & @xmath323 & @xmath324 & @xmath325 10 & 1.31 & 1.66 & 2450.0 & 0.12 & 182.3 & @xmath326 & @xmath327 & @xmath326 & @xmath328 11 & 1.46 & 1.59 & 3153.0 & 0.10 & 221.9 & @xmath307 & @xmath329 & @xmath307 & @xmath330 12 & 1.57 & 1.58 & 3109.0 & -0.14 & 202.9 & @xmath305 & @xmath331 & @xmath307 & @xmath332 13 & 1.32 & 1.55 & 2290.0 & 0.10 & 179.6 & @xmath333 & @xmath334 & @xmath335 & @xmath336 14 & 1.32 & 1.62 & 1636.0 & 0.12 & 211.1 & @xmath335 & @xmath337 & @xmath322 & @xmath338 15 & 1.32 & 1.80 & 1543.0 & -0.08 & 182.9 & @xmath339 & @xmath340 & @xmath324 & @xmath341 17 & 1.36 & 1.55 & 2250.0 & 0.15 & 176.9 & @xmath342 & @xmath343 & @xmath342 & @xmath344 18 & 1.34 & 1.51 & 2310.0 & 0.15 & 214.0 & @xmath345 & @xmath346 & @xmath347 & @xmath348 19 & 2.50 & 1.80 & 2951.0 & 0.17 & 169.6 & @xmath349 & @xmath350 & @xmath317 & @xmath318 22 & 1.38 & 1.71 & 2250.0 & 0.17 & 141.1 & @xmath351 & @xmath332 & @xmath335 & @xmath336 23 & 1.38 & 1.65 & 2280.0 & 0.19 & 158.4 & @xmath345 & @xmath352 & @xmath347 & @xmath353 24 & 1.35 & 2.00 & 2090.0 & 0.25 & 148.3 & @xmath351 & @xmath354 & @xmath333 & @xmath355 47 & 1.60 & 1.57 & 2440.0 & 0.15 & 141.7 & @xmath356 & @xmath357 & @xmath358 & @xmath359 53 & 2.14 & 1.79 & 2840.0 & 0.40 & 100.0 & @xmath358 & @xmath360 & @xmath358 & @xmath361 55 & 2.01 & 1.83 & 2590.0 & 0.23 & 93.0 & @xmath322 & @xmath362 & @xmath339 & @xmath363 57 & 1.84 & 1.89 & 2510.0 & 0.29 & 98.9 & @xmath358 & @xmath364 & @xmath358 & @xmath365 76 & 1.25 & 1.60 & 2470.0 & 0.15 & 167.0 & @xmath335 & @xmath366 & @xmath335 & @xmath367 77 & 1.39 & 1.48 & 2314.0 & 0.06 & 316.3 & @xmath368 & @xmath369 & @xmath370 & @xmath371 78 & 1.41 & 1.58 & 3545.0 & 0.12 & 290.2 & @xmath370 & @xmath372 & @xmath373 & @xmath374 79 & 1.43 & 1.65 & 3465.0 & 0.08 & 255.5 & @xmath375 & @xmath376 & @xmath368 & @xmath377 80 & 1.43 & 1.56 & 3574.0 & 0.00 & 237.9 & @xmath378 & @xmath379 & @xmath380 & @xmath381 81 & 1.52 & 1.70 & 3657.0 & -0.04 & 210.6 & @xmath382 & @xmath383 & @xmath384 & @xmath385 82 & 1.52 & 1.45 & 3580.0 & -0.04 & 170.4 & @xmath386 & @xmath387 & @xmath388 & @xmath389    rrrccccc 1 & 2 & 9 & 5672 & 143.9 & 67 & 64 & 3226 2 & 7 & 40 & 5668 & 196.4 & 66 & 81 & 4209 3 & 19 & 22 & 4562 & 142.1 & 72 & 64 & 3219 4 & 22 & 38 & 1696 & 93.7 & 64 & 64 & 3419 5 & 55 & 54 & 5311 & 98.1 & 69 & 64 & 3294 6 & 77 & 27 & 4203 & 257.4 & 67 & 144 & 6884 7 & 77 & 50 & 2962 & 308.9 & 66 & 156 & 7622 8 & 78 & 6 & 5663 & 318.7 & 69 & 156 & 8381 9 & 78 & 47 & 5663 & 269.5 & 77 & 144 & 8074 10 & 81 & 18 & 5673 & 202.9 & 72 & 156 & 6653    cccccc 1 & 1.00 & 1.46 & 1.20 & 8.7e-04 & 1.9e-04 2 & 1.46 & 2.00 & 1.70 & 2.1e-03 & 5.7e-04 3 & 2.00 & 2.70 & 2.32 & 6.5e-03 & 2.2e-03 4 & 2.70 & 3.80 & 3.20 & 1.3e-02 & 5.7e-03 5 & 3.80 & 5.20 & 4.44 & 3.2e-02 & 1.5e-02 6 & 5.20 & 7.10 & 6.07 & 5.2e-02 & 3.7e-02 7 & 7.10 & 9.70 & 8.29 & 8.7e-02 & 7.8e-02 8 & 9.70 & 13.30 & 11.35 & 1.1e-01 & 1.1e-01 9 & 13.30 & 18.20 & 15.55 & 1.5e-01 & 1.8e-01 10 & 18.20 & 24.90 & 21.28 & 1.9e-01 & 2.5e-01 11 & 24.90 & 34.20 & 29.18 & 2.5e-01 & 3.2e-01 12 & 34.20 & 46.80 & 40.00 & 2.8e-01 & 3.8e-01 13 & 46.80 & 64.20 & 54.81 & 3.2e-01 & 4.4e-01 14 & 64.20 & 88.00 & 75.16 & 3.6e-01 & 4.7e-01 15 & 88.00 & 121.00 & 103.18 & 3.9e-01 & 5.1e-01 16 & 121.00 & 165.00 & 141.29 & 4.1e-01 & 5.4e-01 17 & 165.00 & 227.00 & 193.53 & 4.2e-01 & 5.3e-01 18 & 227.00 & 311.00 & 265.70 & 4.3e-01 & 5.3e-01 19 & 311.00 & 426.00 & 363.98 & 4.1e-01 & 4.9e-01 20 & 426.00 & 584.00 & 498.78 & 3.2e-01 & 4.1e-01 21 & 584.00 & 800.00 & 683.52 & 1.0e-01 & 1.7e-01 22 & 800.00 & 1096.00 & 936.37 & 4.7e-02 & 9.1e-02 23 & 1096.00 & 1502.00 & 1283.04 & 3.3e-02 & 6.8e-02 24 & 1502.00 & 2000.00 & 1733.14 & 3.0e-02 & 6.1e-02    clrl 1 & ?",
    "& @xmath39020% & lf normalization / exposure 2 & ? & @xmath3901 - 3% & lf for faint stars @xmath391 3 & ? & @xmath3921% & finite number of monte carlo events 4 & + & @xmath3906 - 8% & overcompleteness bias 5 & - & @xmath3903% & 1st neighbor prf bias 6 & + & @xmath3901% & lf in outer ` disk ' fields 7 & - & @xmath3921% & convergence for @xmath393 days 8 & ? & ?",
    "% & binary stars in lf 9 & ? & ?",
    "% & no exotic lensing events"
  ],
  "abstract_text": [
    "<S> the macho project is a search for dark matter in the form of massive compact halo objects ( machos ) . </S>",
    "<S> the project has photometrically monitored tens of millions of stars in the large magellanic cloud ( lmc ) , small magellanic cloud ( smc ) , and galactic bulge in search of rare gravitational microlensing events caused by these otherwise invisible objects . in 5.7 years of observations toward the lmc some 1317 microlensing events have been observed by the macho survey , allowing powerful statements to be made about the nature of the dark population in the halo of our galaxy . a critical component of these statements is an accurate determination of the survey s detection efficiency . the detection efficiency is a complicated function of temporal sampling , stellar crowding ( the luminosity function ) , image quality , photometry , time - series analysis , and criteria used to select the microlensing candidates . such a complex interdependence is most naturally solved using a monte carlo approach . here </S>",
    "<S> we describe the details of the monte carlo used to calculate the efficiency presented in the macho 5.7-year lmc results . </S>",
    "<S> a similar calculation was performed for macho s 1-year and 2-year results . here </S>",
    "<S> we correct several shortcomings of these past determinations , including ( 1 ) adding fainter source stars ( 2.5 magnitudes below our faintest detected  stars \" ) , ( 2 ) an up - to - date luminosity function for the lmc , ( 3 ) better sampling of real images in both stellar density and observing conditions , ( 4 ) an improved scheme for adding artificial microlensing onto a random sample of real lightcurves , and many other improvements . </S>",
    "<S> the monte carlo technique presented here realistically simulates the negative effects of severe crowding ( blending ) that is a fact of microlensing surveys .    * </S>",
    "<S> ( the macho collaboration ) *   + </S>"
  ]
}