{
  "article_text": [
    "minimum - redundancy coding plays an important role in data compression applications @xcite , as it gives the best possible compression of a finite text when using one static code per alphabet symbol .",
    "hence , this encoding method is extensively used in various fields of computer science like picture compression , data transmission , etc . in accordance ,",
    "the methods used for calculating minimum - redundancy prefix codes that correspond to sets of input symbol weights are of great interest @xcite .",
    "the minimum - redundancy prefix code problem is to determine , for a given list @xmath4 $ ] of @xmath0 positive symbol weights , a list @xmath5 $ ] of @xmath0 corresponding integer codeword lengths such that @xmath6 , and @xmath7 is minimized .",
    "( throughout the paper , when we mention that kraft inequality is satisfied , it is satisfied with an equality , i.e. , @xmath8 . ) once we have the codeword lengths corresponding to a given list of symbol weights , constructing a corresponding prefix code can be easily done in linear time using standard techniques .",
    "finding a minimum - redundancy code for @xmath4 $ ] is equivalent to finding a binary tree with minimum - weight external path length @xmath9 among all binary trees with leaves @xmath10 , where @xmath11 , and @xmath12 is the depth of @xmath13 in the corresponding tree .",
    "hence , if we consider a leaf as a weighted node , the minimum - redundancy prefix code problem can be defined as the problem of constructing such an optimal binary tree for a given set of weighted leaves .",
    "based on a greedy approach , huffman s algorithm @xcite constructs specific optimal trees , which are referred to as huffman trees . while every huffman code is an optimal prefix code ,",
    "the converse is not true .",
    "the huffman algorithm starts with a list @xmath14 of @xmath0 nodes whose values correspond to the given @xmath0 weights . in the general step ,",
    "the algorithm selects the two nodes with the smallest values in the current list and removes them from @xmath14 .",
    "next , the removed nodes become children of a new internal node , which is inserted in @xmath14 .",
    "this internal node is assigned a value equals the sum of the values of its children .",
    "the general step is repeated until there is only one node in @xmath14 , the root of the huffman tree .",
    "the internal nodes of a huffman tree are thereby assigned values throughout the algorithm ; the value of an internal node is the sum of the weights of the leaves of its subtree .",
    "the huffman algorithm requires @xmath15 time and linear space .",
    "the huffman s algorithm can be implemented in linear time if the input list was presorted @xcite .",
    "a distribution - sensitive algorithm is an algorithm whose performance relies on how the distribution of the input affects the output @xcite .",
    "for example , a related such algorithm is that of moffat and turpin @xcite ; where they show how to construct an optimal prefix code on a sorted - by - weight alphabet of @xmath0 symbols , which includes @xmath16 distinct symbol weights , in @xmath17 time .",
    "alternatively , an output - sensitive algorithm is an algorithm whose performance relies on properties of its output @xcite .",
    "the algorithms proposed in @xcite are in a sense output sensitive , since their additional space complexities depend on the maximum codeword length @xmath18 of the output code ; the b - lazyhuff algorithm @xcite runs in @xmath19 time and requires @xmath20 extra storage to construct an optimal prefix code on a sorted - by - weight @xmath0-symbol alphabet .    in this paper",
    ", we give an output - sensitive algorithm for constructing minimum - redundancy prefix codes ; our algorithm s performance depends on , @xmath1 , the number of different codeword lengths ( the number of levels that have leaves in the corresponding optimal binary tree ) .",
    "we distinguish two cases : the so called _ sorted case _ , if the sequence of input weights is presorted , and the _ unsorted case _ , otherwise .",
    "for the unsorted case , the running time of our algorithm is @xmath2 , which is linear when @xmath1 is a constant . for the sorted case ,",
    "our algorithm uses @xmath3 comparisons , which is sub - linear for sufficiently small @xmath1 .    throughout the paper",
    ", we interchangeably use the terms leaves and weights .",
    "the number of distinct codeword lengths of a prefix code is the same as the number of levels that contain leaves in the corresponding weighted tree .",
    "unless otherwise stated , we assume that the input weights are unsorted .",
    "unless explicitly mentioned , a node of a tree can be either a leaf or an internal node .",
    "the levels of the tree are numbered bottom up starting from level @xmath21 , i.e. , the root has the highest level number @xmath18 , its children are at level @xmath22 , and the leaves furthest from the root are at level @xmath21 ( note that this level numbering is nonstandard ) ; the length of the codeword assigned to a weight at level @xmath23 is accordingly equal to @xmath24 .",
    "the paper is organized as follows . in section @xmath25",
    ", we give a property of optimal prefix - code trees on which our construction algorithm relies . in section @xmath26 , we give the basic algorithm and prove its correctness .",
    "we show in section @xmath27 how to implement the basic algorithm of section @xmath26 to ensure the output - sensitive behavior ; consequently , the claimed bounds are driven .",
    "we conclude the paper in section @xmath28 .",
    "consider a a list of @xmath0 weights and a binary tree @xmath29 that has the following properties :    1 .",
    "the @xmath0 leaves of @xmath29 correspond to the given @xmath0 weights .",
    "the value of an internal node of @xmath29 equals the sum of the weights of the leaves of its subtree .",
    "3 .   for any level of @xmath29 , let @xmath30 be the nodes of that level in non - decreasing order with respect to their values . then",
    ", @xmath31 and @xmath32 are siblings for all @xmath33 .",
    "we define the _ exclusion property _ @xcite for @xmath29 as follows : @xmath29 has the exclusion property if and only if the values of the nodes at a level are not smaller than the values of the nodes at the lower levels .",
    "[ l1 ] @xcite given a prefix code whose corresponding tree @xmath29 has the aforementioned properties , the given prefix code is optimal and @xmath29 is a huffman tree if and only if @xmath29 has the exclusion property .",
    "[ [ proof . ] ] proof .",
    "+ + + + + +    first , assume that @xmath29 does not have the exclusion property .",
    "it follows that there exist two nodes @xmath34 and @xmath35 respectively at levels @xmath36 and @xmath37 such that @xmath38 and @xmath39 . swapping the subtree of @xmath34 with the subtree of @xmath35 results in another tree with a smaller external path length and a different list of levels , implying that the given prefix code is not optimal .",
    "next , assume that @xmath29 has the exclusion property .",
    "let @xmath40 $ ] be the list of leaves of @xmath29 , with @xmath41 for all @xmath33 .",
    "we prove by induction on the number of leaves @xmath0 that @xmath29 is an optimal binary tree , which corresponds to an optimal prefix code .",
    "the base case follows trivially when @xmath42 . as a result of the exclusion property",
    ", the two leaves @xmath43 must be at the lowest level of @xmath29 .",
    "also , property @xmath26 of @xmath29 implies that these two leaves are siblings .",
    "alternatively , there is an optimal binary tree with leaves @xmath40 $ ] where @xmath44 and @xmath45 are siblings ; a fact that is used to prove the correctness of huffman s algorithm @xcite . remove @xmath43 from @xmath29 ,",
    "replace their parent with a leaf @xmath46 whose weight equals @xmath47 , and let @xmath48 be the resulting tree",
    ". since @xmath48 has the exclusion property , it follows using induction that @xmath48 is an optimal tree with respect to its @xmath49 leaves @xmath50 $ ] .",
    "hence , @xmath29 corresponds to an optimal prefix code .",
    "our property @xmath26 ensures that every two consecutive nodes in the non - decreasing order of values are siblings , which is the way huffman s algorithm works .",
    "it follows that @xmath29 is a huffman tree .",
    "assume that a set of nodes of a tree that corresponds to a prefix code are numbered , starting from @xmath52 , in a non - decreasing order by their values .",
    "we define the _ rank _ of a node to be its number according to this ordering .",
    "sibling property _ was introduced by gallager @xcite .",
    "the sibling property states that a tree that corresponds to a prefix code is a huffman tree if and only if the nodes with ranks @xmath53 and @xmath54 are siblings for all @xmath33 .",
    "in fact , the sibling property is equivalent to property @xmath26 combined with the exclusion property .",
    "this equivalence can be directly proven , indicating that a tree @xmath29 that has the exclusion property is a huffman tree .    in general , building a tree @xmath29 that has the exclusion property ( huffman tree ) by evaluating all its internal nodes requires @xmath55 .",
    "this follows from the fact that knowing the values of the internal nodes of @xmath29 implies knowing the sorted order of the input weights , a problem that requires @xmath55 in the comparison - based decision - tree model .",
    "our main idea is that we do not have to explicitly construct @xmath29 in order to find optimal codeword lengths .",
    "instead , we only need to find the values for some of and not all the internal nodes to maintain the exclusion property .",
    "given a list of weights , we build a corresponding optimal tree level by level in a bottom - up manner . starting with the lowest level ( level @xmath21 ) ,",
    "a weight is momentarily assigned to a level as long as its value is less than the sum of the two nodes with the currently smallest ranks at that level ; this ensures the exclusion property .",
    "kraft inequality is enforced by making sure that , at the end of the algorithm , the number of nodes at every level is even , and that the number of nodes at the highest level containing leaves is a power of two .",
    "this results in some weights being moved upwards from their initially - assigned levels to the higher levels .",
    "the details follow .      for the sake of illustration",
    ", we start with an example . consider a list with thirty weights : ten weights of value @xmath25 , ten of value @xmath26 , five of value @xmath28 , and five of value @xmath56 .    to construct the optimal codes ,",
    "we start by finding the smallest two weights in the list ; these have the values @xmath57 .",
    "we now identify all the weights in the list with value less than @xmath27 , the sum of these two smallest weights .",
    "there are twenty such weights : ten weights of value @xmath25 and ten of value @xmath26 .",
    "all these weights are momentarily assigned to the bottom level , that is level @xmath21 with respect to our level numbering . the number of nodes at level @xmath21 is now even ; so , we go to the next upper level ( level @xmath52 ) .",
    "we identify the smallest two nodes at level @xmath52 , amongst the two smallest internal nodes resulting from combining nodes already at level @xmath21 ( these have values @xmath58 ) and the two smallest weights among those remaining in the list ( these have values @xmath59 ) .",
    "it follows that the smallest two nodes at level @xmath52 will be the two internal nodes @xmath58 whose sum is @xmath60 .",
    "all the remaining weights with value less than @xmath60 are to be momentarily assigned to level @xmath52 .",
    "accordingly , level @xmath52 now contains an odd number of nodes : ten internal nodes and five weights of value @xmath28 .",
    "see figure  [ fig : e1 - 1 ] .",
    "+   +   +    to make the number of nodes at level @xmath52 even , we move the node with the largest rank at level @xmath52 to the , still empty , next upper level ( level @xmath25 ) .",
    "the node to be moved , in this case , is an internal node with value @xmath61 .",
    "moving an internal node one level up implies moving the weights in its subtree one level up .",
    "so , the subtree consisting of the two weights of value @xmath26 is moved one level up .",
    "at the end of this stage , level @xmath21 contains ten weights of value @xmath25 and eight weights of value @xmath26 ; level @xmath52 contains two weights of value @xmath26 and five weights of value @xmath28",
    ". see figure  [ fig : e1 - 2 ] .",
    "the currently smallest two internal nodes at level @xmath25 have values @xmath62 and the smallest weight in the list has value @xmath56 .",
    "this means that all the five remaining weights in the list will be momentarily assigned to level @xmath25 .",
    "now , level @xmath25 contains eight internal nodes and five weights , for a total of thirteen nodes . see figure  [ fig : e1 - 3 ] .    since we are done with all the weights ,",
    "we only need to enforce the condition that the number of nodes at level @xmath26 is a power of two .",
    "all we need to do is to move the three nodes with the largest ranks , from level @xmath25 , one level up .",
    "the largest three nodes at level @xmath25 are the three internal nodes of values @xmath63 and @xmath64 .",
    "so , we move eight weights of value @xmath26 and two weights of value @xmath28 one level up . as a result ,",
    "the number of nodes at level @xmath26 will be @xmath60 ; that is a power of two .",
    "the root will then be at level @xmath61 .",
    "the final distribution of weights will be : ten weights of value @xmath25 at level @xmath21 ; ten weights of value @xmath26 and three weights of value @xmath28 at level @xmath52 ; and the remaining weights , two of value @xmath28 and five of value @xmath56 , at level @xmath25 .",
    "the corresponding codeword lengths are @xmath61 , @xmath28 and @xmath27 respectively .",
    "see figure  [ fig : e1 - 4 ] .",
    "note that we have not included all the internal nodes within figure [ fig : example ] .",
    "we have consciously only drawn the internal nodes that are required to be evaluated by our algorithm ; this will be elaborated throughout the next subsections .",
    "the idea of the algorithm should be clear .",
    "we construct an optimal tree by maintaining the exclusion property for all the levels .",
    "once the weights are placed in such a way that the exclusion property is satisfied , the property will as well be satisfied among the internal nodes .",
    "adjusting the number of nodes at each level will not affect the exclusion property , since we are always moving the largest nodes from one level to the next higher level . a formal description follows .",
    "( note that the main ideas of our basic algorithm described in this subsection are pretty similar to those of the lazy - traversal algorithm described in @xcite . )    1 .   consider a list of input symbol weights @xmath65 ( not necessarily sorted ) .",
    "the smallest two weights are found , removed from @xmath65 , and placed at the lowest level @xmath21 ; their sum @xmath66 is computed .",
    "the list @xmath65 is scanned and all weights less than @xmath66 are removed from @xmath65 and placed at level @xmath21 .",
    "set @xmath67 .",
    "2 .   repeat the following steps until @xmath65 is empty : 1 .",
    "if the number of nodes at level @xmath36 is odd , move the subtree rooted at the node with the largest rank from level @xmath36 to level @xmath68 .",
    "2 .   determine the new weights that will go to level @xmath68 as follows .",
    "find the smallest two internal nodes at level @xmath68 , and the smallest two weights among those remaining in @xmath65 .",
    "find the smallest two values amongst these four , and let their sum be @xmath66 .",
    "scan @xmath65 for all weights less than @xmath66 , and move them to level @xmath68 .",
    "3 .   @xmath69 .",
    "3 .   set @xmath70 , i.e. , @xmath71 is the highest level that is currently assigned weights",
    ". let @xmath72 be the current number of nodes at level @xmath71 .",
    "move the @xmath73 subtrees rooted at the nodes with the largest ranks from level @xmath71 to level @xmath74 .      to guarantee its optimality following lemma [ l1 ]",
    ", we need to show that both kraft inequality and the exclusion property hold for the constructed tree .    [ [ maintaining - kraft - inequality . ] ] * maintaining kraft inequality . *",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    first , we show by induction that the number of nodes at every level of the tree is even .",
    "assume that this is true up to level @xmath75 .",
    "since any subtree of our tree is a full binary tree ( every node has zero or two children ) , the number of nodes per level within any subtree is even except for its root . at step @xmath76 of the algorithm ,",
    "if the number of nodes at level @xmath36 is odd , we move a subtree one level up .",
    "we are thus moving even numbers of nodes between levels among the lower @xmath77 levels .",
    "hence , the number of nodes remains even per level among those levels . on the other hand , the number of nodes at level @xmath36 either decreases by @xmath52 ( if the moved root has no children ) or increases by @xmath52 ( if the moved root has two children ) .",
    "either way , the number of nodes at level @xmath36 becomes even .",
    "second , we show that the number of nodes at the last level that is assigned weights is a power of two . at step @xmath26 of the algorithm ,",
    "if @xmath72 is a power of two , no subtrees are moved up and kraft inequality holds .",
    "otherwise , we move @xmath73 nodes from level @xmath71 to level @xmath74 , leaving @xmath78 nodes at level @xmath71 other than the children of the roots that have just been moved to level @xmath74 .",
    "now , the number of nodes at level @xmath74 is @xmath79 internal nodes resulting from combining pairs of nodes from level @xmath71 , plus the @xmath73 nodes that we have just moved .",
    "this sums up to @xmath80 nodes ; that is a power of two .    [ [ maintaining - the - exclusion - property . ] ] * maintaining the exclusion property . * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we prove by induction that the even stronger sibling property holds , as long as we are correctly evaluating the prescribed internal nodes following huffman s rules .",
    "assume that the sibling property holds up to level @xmath77 . throughout the algorithm",
    ", we maintain the property by making sure that the sum of the values of the two nodes with the smallest ranks at a level is larger than all the values of the nodes at this level .",
    "when we move a subtree from level @xmath77 one level up , the root of this subtree is the node with the largest rank at its level .",
    "the validity of the sibling property at the lowest @xmath77 levels implies that the children of the node with the largest rank at a level have the largest ranks among the nodes at their level .",
    "hence , all the nodes of the moved subtrees at a certain level must have had the largest ranks among the nodes of their level .",
    "when such nodes are moved one level up their values are thus larger than those of the nodes at the lower levels , and the exclusion property is still maintained .",
    "we are still far from being done yet . though we have introduced the main idea behind the algorithm , some crucial details are still missing .",
    "namely , we did not show how to evaluate the essential internal nodes .",
    "should we have to evaluate all the internal nodes , breaking the @xmath81 bound would have been impossible .",
    "fortunately , we only need to evaluate few internal nodes per level .",
    "more precisely , except for the last level that is assigned weights , we may need to evaluate three internal nodes per level : the two with the smallest ranks and the one with the largest rank .",
    "the challenge is how to do that efficiently .",
    "another pitfall of our basic method , as we have just described , is that we are to evaluate internal nodes for every level of the tree up to the last level that is assigned weights .",
    "the work would thus be proportional to the difference between the length of the maximum and the minimum codeword lengths . we still need to do better , and the way out is to skip doing work at the levels that will not be assigned any weights .",
    "again , the challenge is how to do that efficiently .",
    "subsequently , we thus explain our detailed construction in section @xmath27 .",
    "up to this point , we have not shown how to evaluate the internal nodes needed by our basic algorithm , and how to search within the list @xmath65 to decide which weights are to be assigned to which levels .",
    "the basic intuition behind the novelty of our approach is that it does not require evaluating all the internal nodes of the tree corresponding to the prefix code , and would thus surpass the @xmath82 bound for several cases . in this section ,",
    "we show how to implement the basic algorithm in an output - sensitive behavior , filling in the missing details .",
    "the main idea is clarified through an example with @xmath83 weights , where @xmath0 is a power of two .",
    "assume that the resulting optimal tree will turn out to have @xmath84 : @xmath0 leaves at level @xmath21 , @xmath85 at level @xmath52 , and two at level @xmath86 .",
    "note that the @xmath87 leaves at levels @xmath21 and @xmath52 combine to produce two internal nodes at level @xmath86 .",
    "it is straightforward to come up with a set of weights that fulfills this outcome .",
    "however , to illustrate how the algorithm works for any such set of weights , it is better to handle the situation without explicitly deciding the weights .    for such case ,",
    "we show how to apply our algorithm so that the optimal codeword lengths are produced in linear time , even if the weights were not presorted . determining the weights to be assigned to level @xmath21",
    "can be easily done by finding the smallest two weights and scanning through the list of weights . to determine the weights to be assigned to level @xmath52",
    ", we need to find the values of the smallest two internal nodes at level @xmath52 ; these are respectively the sum of the smallest two pairs of weights . at this point , lets assume that the algorithm uses an oracle that recommends checking level @xmath88 next .",
    "a more involved task is to evaluate the two internal nodes @xmath89 and @xmath90 at level @xmath86 , which amounts to identifying the smallest as well as the largest @xmath85 nodes amongst the @xmath0 nodes at level @xmath52 .",
    "the main advantage is that we do not need to sort the values of the nodes at level @xmath52 .",
    "in addition , we do not need to explicitly evaluate all the @xmath85 internal nodes at level @xmath52 resulting from the pairwise combinations of the @xmath0 weights at level @xmath21 .",
    "what we really need to know is the sum of the smaller half as well as the sum of the larger half among the nodes at level @xmath52 .",
    "see figure [ fig : e2 ] .",
    "we show next that evaluating @xmath89 and @xmath90 can be done in linear time via a simple pruning procedure .    ,",
    "scaledwidth=90.0% ]    the nodes at level @xmath52 consist of two sets ; one set has @xmath85 leaves whose weights are known and thus their median @xmath91 can be found in linear time @xcite , and another set containing @xmath85 internal nodes whose values are not known , but whose median @xmath92 can still be computed in linear time by simply finding the two middle weights of the @xmath0 leaves at level @xmath21 and adding them .",
    "assuming without loss of generality that @xmath93 , then the larger half of the @xmath85 weights at level @xmath52 contribute to @xmath90 , and the smaller half of the @xmath0 weights at level @xmath21 contribute to @xmath89 .",
    "the above step of finding new medians for the leftovers of the two sets is repeated recursively on a problem half the size .",
    "this results in a procedure with a running time that satisfies the recurrence @xmath94 , whose solution results in @xmath95 .",
    "if the list of weights was presorted , no comparisons are required to find @xmath91 or @xmath92 ; we only need to compare them together . the total number of comparisons needed satisfies the recurrence @xmath96 , and hence @xmath97 .",
    "following the basic construction method , the optimal tree will be built bottom up .",
    "however , this will not be done level by level ; we shall only work in the vicinity of the levels that will end up having leaves .",
    "once we finish assigning weights to a level , we should be able to decide about the number of the next higher level to consider ( section [ next - level ] ) . as stated earlier , throughout the algorithm we have to efficiently evaluate some internal nodes .",
    "in general , for a specified level and a fixed @xmath98 , we need to be able to evaluate the node with the @xmath98-th smallest or largest rank among the internal nodes , or even among all the nodes , at that level ( section [ t - th ] ) .",
    "to be able to do that efficiently , we shall illustrate a method to evaluate one specific internal node that serves as the median of the nodes on the specified level .",
    "more precisely , if one counts the number of weights contributing to each node at the specified level , and supposedly sort the list of nodes on that level by value , the sought node will be the node that splits this sorted list in two sublists the number of weights contributing to each is close as possible to the other .",
    "we shall show how such splitting procedure is accomplished in a recursive manner ( section [ splitting ] ) .",
    "once we are able to evaluate such node , the other tasks like finding the next level to be assigned weights and finding the @xmath98-th smallest or largest nodes can be done by repeatedly calling the splitting procedure .",
    "the details are to come up next .",
    "let @xmath99 be the levels that have already been assigned weights after some iterations of our algorithm ( other levels only have internal nodes ) .",
    "let @xmath100 be the number of leaves so far assigned to level @xmath101 , and @xmath102 .    at the current iteration , we are looking forward to compute , @xmath103 , the level that will next be assigned weights by our algorithm .",
    "we use the fact that the weights that have already been assigned up to level @xmath104 are the only weights that may contribute to the values of the internal nodes below and up to level @xmath103 .    consider the internal node @xmath105 at level @xmath104 , where the sum of the number of leaves in the subtrees of level-@xmath104 internal nodes whose ranks are smaller than that of @xmath105 is at most but closest to @xmath106 .",
    "we call @xmath105 the _ splitting node of the internal nodes _ at level @xmath104 . in other words , if we define the _ multiplicity _ of a node to be the number of leaves in its subtree , then @xmath105 is the weighted - by - multiplicity median within the sorted - by - value sequence of the internal nodes at level @xmath104 .",
    "analogously , consider the node @xmath107 ( not necessarily an internal node ) at level @xmath108 , where the sum of the number of leaves in the subtrees of level-@xmath104 internal nodes whose ranks are smaller than that of @xmath107 plus the number of level-@xmath108 leaves whose ranks are smaller than that of @xmath107 is at most but closest to @xmath109 .",
    "we call @xmath107 the _ splitting node of all nodes _ at level @xmath108 .",
    "informally , @xmath105 splits the weights below level @xmath104 in two groups having almost equal counts , and @xmath107 splits the weights below and up to level @xmath104 in two groups having almost equal counts .    we extend the notion of splitting nodes to subsets of nodes .",
    "let @xmath110 be a list of weights constituting the leaves of a subset of the internal nodes at level @xmath104 having consecutive ranks .",
    "the splitting node @xmath111 is defined as the weighted - by - multiplicity median within the sorted - by - value sequence of those internal nodes .",
    "let @xmath112 be a subset of leaves at level @xmath104 having consecutive ranks .",
    "the splitting node @xmath113 is defined as the weighted - by - multiplicity median within the sorted - by - value sequence of @xmath112 in addition to the internal nodes at level @xmath104 whose subtrees have the leaves @xmath110 .    ,",
    "@xmath114 $ ] and @xmath107 at level @xmath104 .",
    "numbers inside nodes represent their values , and those outside internal nodes represent their multiplicity . for illustration purposes ,",
    "the internal nodes are drawn sorted by value and so are the leaves.,scaledwidth=90.0% ]    figure [ fig : e3 ] illustrates those definitions : the internal node with value @xmath60 is the splitting node @xmath105 of the internal nodes ; the sum of the multiplicity of the internal nodes with values smaller than @xmath60 is @xmath115 , and the sum of the multiplicity of those with values larger than @xmath60 is @xmath116 .",
    "the leaf with value @xmath64 is the splitting node @xmath107 of all nodes ; the sum of the multiplicity of the nodes with values smaller than @xmath64 is @xmath117 ( @xmath118 contribute to internal nodes plus @xmath25 leaves ) , and the sum of the multiplicity of those with values larger than @xmath64 is @xmath117 ( @xmath116 contribute to internal nodes plus @xmath26 leaves ) .      to find the splitting node @xmath107 of all nodes at level @xmath104 , we repeatedly identify splitting nodes of subsets of the internal nodes .",
    "the main idea is to apply a pruning procedure in a manner similar to binary search .",
    "starting with all the leaves and internal nodes at level @xmath104 , we repeatedly perform the following steps : compare the median of the leaves and the splitting node of the internal nodes , discard sublists of nodes from further consideration , and compute the median of the remaining leaves or the splitting node of the remaining internal nodes .",
    "the details follow .",
    "we find the leaf @xmath91 with the median weight among the list @xmath110 of the @xmath119 weights assigned to level @xmath104 , and partition @xmath110 into three sublists @xmath120 , @xmath121 and @xmath122 around @xmath91 , where @xmath121 is the list of weights with the smaller ranks .",
    "we recursively find the splitting node @xmath105 of the internal nodes at level @xmath108 using the list @xmath112 of the @xmath123 weights at the levels below @xmath104 , and partition @xmath112 into three sublists @xmath124 , @xmath125 and @xmath126 around @xmath105 , where @xmath125 is the list of weights contributing to the internal nodes with the smaller ranks .",
    "we use the function _ add - weights _ to compute the value of @xmath105 by adding the list of weights @xmath124 constituting the leaves of the subtree of @xmath105 . comparing the values of @xmath91 and @xmath105 , assume without loss of generality that @xmath127 .",
    "we conclude that either the weights in @xmath122 in addition to @xmath91 must have larger ranks than @xmath107 , or the internal nodes corresponding to the weights in @xmath125 in addition to @xmath105 must have smaller ranks than @xmath107 .",
    "accordingly , we either set @xmath110 to @xmath121 , and find the new median @xmath91 and the new lists @xmath121 and @xmath122 , or set @xmath112 to @xmath126 , and find the new splitting node @xmath105 and the new lists @xmath125 and @xmath126 .",
    "the pruning procedure continues until only the weights contributing to @xmath107 remain . as a byproduct , we compute , @xmath128 and @xmath129 , the two lists of weights contributing to the nodes at level @xmath104 whose ranks are smaller and respectively larger than that of @xmath107 .",
    "we also compute , @xmath130 , the rank of @xmath107 among the nodes at level @xmath104 .",
    "see the pseudo - code of algorithm [ find - split ] for the detailed description .",
    "@xmath131 _ cut _",
    "@xmath132 @xmath133 return  @xmath134 @xmath135 @xmath136 ,  @xmath137 ,  @xmath138 ,  @xmath139 @xmath140 ,  @xmath141 ,  @xmath142 @xmath133 @xmath143 ,  @xmath144 ,  @xmath145 ,  @xmath146 @xmath147 @xmath148 ,  @xmath149 ,  @xmath150 ,",
    "@xmath151 @xmath133 @xmath152 ,  @xmath153 ,  @xmath154 @xmath147 @xmath143 ,  @xmath144 ,  @xmath145 ,  @xmath146 @xmath152 ,  @xmath153 ,  @xmath154 @xmath147 @xmath155 ,  @xmath156 ,  @xmath157 return  @xmath158 @xmath148 ,  @xmath149 ,  @xmath150 , @xmath151 @xmath140 ,  @xmath141 ,  @xmath142 @xmath133 @xmath159 ,  @xmath160 ,  @xmath161 return  @xmath162    next , consider the problem of finding the splitting node @xmath105 of the internal nodes at level @xmath104 . observe that @xmath163 is a descendant of @xmath105 ; so , we start by recursively finding the node @xmath163 .",
    "let @xmath164 be the rank of @xmath163 among the nodes at level @xmath165 ; the numbering starts from @xmath52 .",
    "knowing that exactly @xmath166 nodes from level @xmath165 contribute to every internal node at level @xmath104 , we conclude that the largest @xmath167 among the @xmath168 nodes whose ranks are smaller than @xmath163 , and the smallest @xmath169 nodes among those whose ranks are larger than @xmath163 , are the nodes contributing to @xmath105 .",
    "we proceed by finding such nodes , a procedure that requires recursively finding more splitting nodes at level @xmath165 , in a way that will be illustrated in the next subsection . to summarize , the splitting node @xmath105 of level @xmath104 is evaluated as follows .",
    "the aforementioned pruning procedure is applied to split the weights already assigned to the lower @xmath170 levels to three groups ; those contributing to @xmath163 , those contributing to the nodes smaller than @xmath163 at level @xmath165 , and those contributing to the nodes larger than @xmath163 at level @xmath165 .",
    "the weights contributing to @xmath105 are : the weights of the first group , the weights among the second group contributing to the largest @xmath171 nodes smaller than @xmath163 , and the weights among the third group contributing to the smallest @xmath172 nodes larger than @xmath163 .",
    "we also compute , @xmath130 , the rank of @xmath105 among the internal nodes at level @xmath104 .",
    "see the pseudo - code of algorithm [ find - split - internal ] for the detailed description .",
    "@xmath173 @xmath174 ,  @xmath175 @xmath176 @xmath177 @xmath178 @xmath179 ,  @xmath180 return  @xmath158      consider the node @xmath181 that has the @xmath98-th smallest or largest rank among the nodes at level @xmath108 .",
    "the following recursive procedure is used to evaluate @xmath181 .    as for the case of finding the splitting node",
    ", we find the leaf with the median weight @xmath91 among the list of the @xmath182 weights already assigned to level @xmath108 , and evaluate the splitting node @xmath105 of the internal nodes at level @xmath108 ( applying the aforementioned recursive procedure ) using the list of the @xmath123 leaves of the lower levels .",
    "comparing @xmath91 to @xmath105 , we discard either @xmath91 or @xmath105 plus one of the four sublists the two sublists of @xmath182 leaves and the two sublists of @xmath123 leaves as not contributing to @xmath181 . repeating this pruning procedure , we identify the weights that contribute to @xmath181 and hence evaluate @xmath181 .",
    "accordingly , we also identify the list of weights that contribute to the nodes at level @xmath108 whose values are smaller or lager than the value of @xmath181 .",
    "the main ideas of this procedure are pretty similar to those of finding the splitting node , and hence we omit the details and leave them for the reader .",
    "we start by finding the minimum weight @xmath183 among the weights remaining in @xmath65 ( not assigned to any of the first @xmath23 levels ) , by applying the function _ minimum - weight_. we next use the value of @xmath183 to search within the nodes at level @xmath108 in a manner similar to binary search . the main idea is to find the maximum number of nodes with the smallest ranks at level @xmath108 such that the sum of their values is less than @xmath183 .",
    "we find the splitting node @xmath107 at level @xmath108 , and evaluate the sum of @xmath107 plus the weights contributing to the nodes at level @xmath108 whose ranks are less than that of @xmath107 . comparing this sum with @xmath183 ,",
    "we decide which sublist of the @xmath184 leaves to proceed to find its splitting node . at the end of this searching procedure",
    ", we would have identified the weights contributing to the @xmath185 smallest nodes at level @xmath108 , such that the sum of their values is less than @xmath183 and @xmath185 is maximum .",
    "( note that @xmath185 is at least @xmath25 . ) accordingly , the level to be considered next for assigning weights is level @xmath186 .",
    "see the pseudo - code of algorithm [ compute - next - level ] for the detailed description .",
    "@xmath187 @xmath188 , @xmath189 @xmath190 @xmath191 @xmath192 ,  @xmath193 ,  @xmath194 @xmath195 @xmath196 return  @xmath103    to prove the correctness of this procedure , consider any level @xmath36 where @xmath197 .",
    "the subtrees of the two internal nodes with the smallest ranks at level @xmath36 have at most @xmath198 nodes at level @xmath108 .",
    "hence , the sum of the values of such two nodes is less than @xmath183 . for the exclusion property to hold , no weights are to be assigned to any of these levels . on the contrary , the subtrees of the two internal nodes with the smallest ranks at level @xmath186 have more than @xmath185 nodes at level @xmath108 , and",
    "hence the sum of their values is at least @xmath183 . for the exclusion property to hold ,",
    "at least the weight @xmath183 is to be momentarily assigned to level @xmath186 .      after deciding the value of @xmath103",
    ", we need to maintain kraft inequality .",
    "this is accomplished by moving the subtrees of the @xmath199 nodes with the largest ranks from level @xmath108 one level up .",
    "let @xmath72 be the number of nodes currently at level @xmath108 and let @xmath200 , then the number of subtrees to be moved up is @xmath201 .",
    "see the pseudo - code of algorithm [ maintain - kraft ] .",
    "note that when @xmath202 ( as in the case of our basic algorithm ) , then @xmath203 if @xmath72 is odd and @xmath204 otherwise .",
    "@xmath205 @xmath206 @xmath207 @xmath208 @xmath209 @xmath210    to establish the correctness of this procedure , we need to show that both kraft inequality and the exclusion property hold . for a realizable construction , the number of nodes at level @xmath108 has to be even , and if @xmath211 , the number of nodes at level @xmath212 has to divide @xmath213 .",
    "if @xmath72 divides @xmath214 , no subtrees are moved to level @xmath212 and kraft inequality holds .",
    "if @xmath72 does not divide @xmath214 , then @xmath215 nodes are moved to level @xmath212 , leaving @xmath216 nodes at level @xmath108 other than those of the subtrees that have just been moved one level up .",
    "now , the number of nodes at level @xmath212 is @xmath217 internal nodes resulting from the nodes of level @xmath108 , plus the @xmath218 nodes that we have just moved .",
    "this sums up to @xmath219 nodes , which divides @xmath213 , and kraft inequality holds .",
    "the exclusion property holds following the same argument given in section [ ex ] .",
    "kraft inequality for the highest level that is assigned leaves , i.e. , when @xmath220 , is correctly maintained also following the argument given in section [ ex ] .      1 .",
    "the smallest two weights are found , moved from @xmath65 to the lowest level @xmath221 , and their sum @xmath66 is computed .",
    "the rest of @xmath65 is searched for weights less than @xmath66 , which are moved to level @xmath21 as well . set @xmath222 .",
    "2 .   repeat the following steps until @xmath65 is empty : 1 .",
    "compute @xmath103 ( the next level that will be assigned weights ) .",
    "2 .   maintain kraft inequality at level @xmath108 ( by moving the @xmath199 subtrees with the largest ranks from this level one level up ) .",
    "3 .   find the values of the smallest two internal nodes at level @xmath103 , and the smallest two weights from those remaining in @xmath65 .",
    "find the two nodes with the smallest ranks among these four , and let their sum be @xmath66 .",
    "4 .   search the rest of @xmath65 , and assign the weights less than @xmath66 to level @xmath103 .",
    "3 .   let @xmath72 be the current number of nodes at level @xmath104 .",
    "move the @xmath224 subtrees rooted at the nodes with the largest ranks from level @xmath104 to level @xmath225 .",
    "let @xmath226 be the time required to find the splitting node ( and also for the @xmath98-th smallest or largest node ) of a set of nodes at level @xmath104 that are roots of subtrees having the list of leaves @xmath227 .",
    "it follows that @xmath228 is the time required to find @xmath107 .",
    "let @xmath229 be the time required to find the splitting node of a set of internal nodes at level @xmath104 that are roots of subtrees having the list of leaves @xmath227 .",
    "it follows that @xmath230 is the time required to find @xmath105 .",
    "first , consider algorithm [ find - split ] .",
    "the total amount of work , in all the recursive calls , required to find the medians among the @xmath182 weights assigned to level @xmath108 is @xmath231 . during the pruning procedure to locate @xmath232 , the time for the @xmath233-th recursive call to find a splitting node of internal nodes at level",
    "@xmath108 is at most @xmath234 .",
    "the pruning procedure , therefore , requires at most @xmath235 time , where @xmath236 .",
    "mathematically , @xmath237 .",
    "second , consider algorithm [ find - split - internal ] . to find the splitting node of the internal nodes at level @xmath104 , we find the splitting node of all the nodes at level @xmath165 for the same list of weights .",
    "we also find the @xmath98-th smallest and largest nodes among each half of this list of weights ; the time for each of these two calls is at most @xmath238 .",
    "mathematically , @xmath239 .    summing up the bounds , the next relations follow : @xmath240    substitute with @xmath241 , for @xmath242 , @xmath243 , and a big enough constant @xmath244 .",
    "then , we induce for @xmath245 that @xmath246    using the fact that @xmath247 , then    @xmath248    consider the case when the list of weights @xmath65 is presorted .",
    "let @xmath249 be the number of comparisons required to find the splitting node .",
    "the number of comparisons , in all recursive calls , performed against the medians among the @xmath182 weights assigned to level @xmath108 , is at most @xmath250 ( at most @xmath251 comparisons to find @xmath232 , another @xmath251 to find the @xmath171-th largest node among the nodes smaller than @xmath232 , and a third @xmath251 to find the @xmath252-th smallest node among those larger than @xmath232 ) .",
    "the next relations follow : @xmath253    the @xmath254 bound , we showed for the running time of the unsorted case , obviously fulfills the preceding recursive relations as well .",
    "however , we next deduce another bound for the sorted case that is tighter when @xmath23 is sufficiently small .",
    "since the number of recursive calls at level @xmath104 is at most @xmath255 , it follows that @xmath256    substitute with @xmath257 , for @xmath242 , @xmath243 .",
    "we thus obtain for @xmath245 that @xmath258    third , consider algorithm [ compute - next - level ] . the time required by this procedure",
    "is dominated by the @xmath19 time to find the minimum weight @xmath183 among the weights remaining in @xmath65 plus the time for the calls to find the splitting nodes .",
    "let @xmath259 be the time required by this procedure , and let @xmath260 .",
    "then ,    @xmath261    let @xmath262 be the number of comparisons required by algorithm [ compute - next - level ] when the list of weights @xmath65 is presorted .",
    "then , @xmath263    finally , consider algorithm [ maintain - kraft ] .",
    "the required time is dominated by the time to find the weights contributing to the @xmath199 nodes with the largest ranks at level @xmath108 , which is @xmath254 . if @xmath65 is presorted , the number of comparisons involved is @xmath264 .    using the bounds deduced for the described steps of the algorithm",
    ", we conclude that the time required by the general iteration is @xmath265 .",
    "if @xmath65 is presorted , the required number of comparisons is @xmath264 .    to complete the analysis",
    ", we need to show the effect of maintaining kraft inequality on the complexity of the algorithm .",
    "consider the scenario when , as a result of moving subtrees one level up , all the weights at a level move up to the next level that already had other weights . as a result",
    ", the number of levels that contain leaves decreases .",
    "it is possible that within a single iteration the number of such levels decreases to half its value .",
    "if this happens for several iterations , the amount of work done by the algorithm would have been significantly large compared to , @xmath1 , the actual number of distinct codeword lengths .",
    "fortunately , this scenario will not happen quite often . in the next lemma , we bound the number of iterations performed by the algorithm by @xmath266 .",
    "we also show that at any step of the algorithm the number of levels that are assigned weights , and hence the number of iterations performed , is at most twice the number of the distinct optimal codeword lengths for the weights that have been assigned so far .",
    "the proof of the lemma is deferred to the appendix .",
    "[ l2 ] consider the set of weights that will have the @xmath267-th largest optimal codeword length at the end of the algorithm . during the execution of the algorithm",
    ", these weights will be assigned to at most two consecutive ( with respect to the levels that contain leaves ) levels , with level numbers , at most , @xmath268 and @xmath269 .",
    "hence , the number of iterations performed by the algorithm is at most @xmath266 .    using lemma [ l2 ] , the time required by our algorithm to assign the set of weights whose optimal codeword length is the @xmath23-th largest , among all distinct lengths , is @xmath270 .",
    "summing for all such lengths , the total time required by our algorithm is @xmath271 .",
    "consider the case when the list of weights @xmath65 is presorted . for achieving the claimed bounds ,",
    "the only point left to be mentioned is how to find the weights of @xmath65 smaller than the sum of the values of the smallest two nodes at level @xmath108 .",
    "once this sum is evaluated , we apply an exponential search that is followed by a binary search on the weights of @xmath65 ; this requires @xmath272 comparisons .",
    "using lemma [ l2 ] , the number of comparisons performed to assign the weights whose codeword length is the @xmath23-th largest among all distinct lengths is @xmath273 .",
    "summing for all such lengths , the number of comparisons performed by our algorithm is @xmath274 .",
    "our main theorem follows .    constructing a minimum - redundancy prefix code for a set of @xmath0 weights",
    "can be done in @xmath2 time , where @xmath1 is the number of distinct codeword lengths .",
    "if the list of weights is presorted , the algorithm uses @xmath3 comparisons .    for @xmath275 and any constant @xmath276",
    ", the above algorithm requires @xmath277 time .",
    "if the list of weights was presorted , for @xmath278 and any constant @xmath279 , the above algorithm requires @xmath280 comparisons",
    "we gave an output - sensitive algorithm for constructing minimum - redundancy prefix codes whose running time is @xmath2 . for sufficiently small values of @xmath1 ,",
    "this algorithm asymptotically improves over other known algorithms that require @xmath15 ; it is quite interesting to know that the construction of optimal codes can be done in linear time when @xmath1 turns out to be a constant . for sufficiently small values of @xmath1 ,",
    "if the sequence of weights was presorted , the number of comparisons performed by our algorithm is asymptotically better than other known algorithms that require @xmath19 comparisons . for such sorted sequences ,",
    "the number of comparisons required by our algorithm is poly - logarithmic when @xmath1 is a constant .",
    "two remaining questions are whether we can improve the bounds to be polynomial with respect to @xmath1 , and whether it is possible to make the algorithm practically more efficient by avoiding so many recursive calls to a median - finding algorithm .",
    "consider a set of weights that will turn out to have the same codeword length . during the execution of the algorithm ,",
    "assume that some of these weights are assigned to three levels .",
    "let @xmath281 be such levels .",
    "since we are maintaining the exclusion property throughout the algorithm and since @xmath282 , there will exist some internal nodes at level @xmath212 whose values are strictly smaller than the values of the weights at level @xmath283 ( some may have the same value as the smallest weight at level @xmath283 ) .",
    "the only way for such weights to catch each other at the same tree level would be as a result of moving subtrees up to maintain kraft inequality .",
    "suppose that , at some point of the algorithm , the weights that are currently at level @xmath108 are moved up to catch the weights at level @xmath283 .",
    "it follows that the internal nodes that are currently at level @xmath212 will accordingly move to the next upper level of the moved weights . as a result",
    ", the exclusion property will not hold ; a fact that contradicts the behavior of our algorithm .",
    "it follows that these weights will never be at the same tree level .",
    "we prove the second part of the lemma by induction .",
    "the base case follows easily for @xmath284 .",
    "assume that the argument is true for @xmath285 .",
    "by induction , the levels of the weights that will have the @xmath286-th largest optimal codeword length will be assigned to the at most @xmath287 and @xmath288 levels . from the exclusion property",
    ", it follows that the weights that have the @xmath267-th largest optimal codeword length must be at the next upper levels . using the first part of the lemma , the number of such levels is at most two .",
    "it follows that these weights are assigned to the , at most , @xmath268 and @xmath269 levels among those assigned weights .",
    "hence , the weights with the @xmath267-th largest optimal codeword length will be assigned within @xmath269 iterations .",
    "since the number of distinct codeword lengths is @xmath1 , the number of iterations performed by the algorithm is at most @xmath266 ."
  ],
  "abstract_text": [
    "<S> a new method for constructing minimum - redundancy binary prefix codes is described . </S>",
    "<S> our method does not explicitly build a huffman tree ; instead it uses a property of optimal prefix codes to compute the codeword lengths corresponding to the input weights . </S>",
    "<S> let @xmath0 be the number of weights and @xmath1 be the number of distinct codeword lengths . </S>",
    "<S> the running time of our algorithm is @xmath2 , which is asymptotically faster than huffman s algorithm for sufficiently small @xmath1 . </S>",
    "<S> if the given weights were presorted , our algorithm requires @xmath3 comparisons , which is sub - linear for sufficiently small @xmath1 . </S>"
  ]
}