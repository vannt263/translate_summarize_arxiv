{
  "article_text": [
    "the concept of inertial manifolds for deterministic partial differential equations was introduced in 1980s @xcite .",
    "these manifolds are finite dimensional invariant manifolds that attract every trajectory at an exponential rate .",
    "they play an important role in the study of the long - time behavior of solutions , since through them the dynamics of a large system can be described by a finite dimensional system . to be more specific ,",
    "the dimension of the state space is reduced by projecting the system onto the inertial manifold once the existence of the manifold has been proved . for certain dissipative nonlinear systems , the inertial manifold can be shown to exist and it exponentially attracts solution orbits @xcite . in the case",
    "where the existence of the inertial manifold is unknown , approximate inertial manifolds are introduced @xcite .",
    "several authors considered the construction of approximate inertial manifolds @xcite as well as numerical simulations using these manifolds @xcite .",
    "inertial manifolds have also been considered for stochastic systems @xcite . in one such study ,",
    "da prato and debussche @xcite introduced the concept of a stochastic inertial manifold for an abstract stochastic evolutionary equation in a hilbert space @xmath0 ( with scalar product @xmath1 and the induced distance @xmath2 )    @xmath3    where @xmath4 is a linear operator , @xmath5 and @xmath6 are two nonlinear functions , and @xmath7 is a wiener process taking values in another hilbert space @xmath8 .",
    "although a theoretical framework for stochastic inertial manifolds has been set up @xcite , it is desirable to efficiently approximate stochastic inertial manifolds and perform simulations on them .",
    "recently , roberts introduced a normal form transformation of stochastic differential systems when the dynamics contains both slow modes and quickly decaying modes @xcite , in which algebraic techniques were used .",
    "this is intended for reduction of finite dimensional systems and it might be used to test the numerical techniques that are proposed for the infinite dimensional case and also to inspire future development .    in this paper , we introduce a numerical scheme for simulating the stochastic inertial manifold of a stochastic evolutionary system with multiplicative noise , which includes stochastic differential equations ( sdes ) and stochastic partial differential equations ( spdes ) . by projecting to a countable basis , an spde could be converted to an infinite dimensional system of sdes .",
    "the main idea is to solve a coupled backward - forward system of sdes where the backward part is finite dimensional , but the forward part is either infinite or high dimensional .",
    "the forward picard type iteration scheme @xcite is performed on the backward part , and an euler discretization scheme is applied to the forward part .",
    "the graph for the stochastic inertial manifold is consequently obtained .",
    "two examples , one for a system of sdes and one for an spde , are presented to illustrate our backward - forward approach .",
    "the rest of this paper is organized as follows .",
    "section 2 formulates the problem and briefly reviews the analytical results @xcite .",
    "section 3 introduces the numerical scheme and performs the error analysis .",
    "an approximation procedure is discussed in section 4 . finally two numerical examples are presented in section 5 .",
    "we consider a stochastic evolutionary system in a hilbert space @xmath0 of the form    @xmath9    where the following conditions hold :    1 .   _",
    "linear part . _ + @xmath4 is a self - adjoint operator in @xmath0 with eigenvalues @xmath10 2 .   _ nonlinear part . _ + @xmath11 and @xmath12 , for some @xmath13 , are globally lipschitz and bounded , with lipschitz constants @xmath14 and  @xmath15 respectively , i.e. , for any @xmath16 , @xmath17 + when @xmath5 and @xmath6 are only locally lipschitz , but the corresponding deterministic system has a bounded absorbing set in an appropriate state space , it is possible to cut - off @xmath5 and @xmath6 to zero outside a ball containing the absorbing set . in this case",
    "the modified (  cut - off \" ) system has globally lipschitz drift and noise intensity .",
    "noise part .",
    "_ + although the wiener process @xmath7 may take values in a hilbert space  @xmath8 , to be specific , here we just consider @xmath7 to be a two - sided one dimensional wiener process , defined in a probability space @xmath18 , and adapted to a filtration @xmath19 ; note that @xmath20 is a two - parameter filtration @xcite or a one - parameter filtration starting at time @xmath21 instead of at time @xmath22 @xcite .",
    "more precisely , for each @xmath23 , @xmath24 which is the information generated by the wiener process w on the interval @xmath25 $ ] .",
    "we denote @xmath26 as @xmath20 for simplicity here and henceforth .",
    "+ the two - sided wiener process @xmath7 is defined in terms of two independent wiener processes @xmath27 and @xmath28 ( @xmath29 ) , as follows , + @xmath30 + the adaptedness means @xmath7 is measurable with respect to @xmath20 for each   @xmath31 .",
    "[ rmk1 ] the two - parameter filtration defined in requiring @xmath32 for @xmath33 is consistent with the well - known filtration for positive time .",
    "indeed , @xmath34 is @xmath35 in the two - parameter setting .",
    "the only difference between one - parameter and two - parameter filtrations in the above setting is their starting time . since the filtration specifies how the information is revealed in time , the property that a filtration is increasing corresponds to the fact the information is not forgotten .",
    "however , the generalization of filtration from one - parameter to two - parameter , while maintaining the property that a filtration is increasing , results in technical difficulties in constructing invariant manifolds since a backward sde is encountered . overcoming this difficulty",
    "will be discussed in detail in remark [ rmk3 ] .    as discussed in @xcite ,",
    "it is appropriate and convenient to consider the canonical sample space , by identifying sample paths of the wiener process @xmath7 with continuous curves ( passing through the origin at @xmath36 since @xmath37 ) .",
    "namely , a sample path is now a _ point _ in the space @xmath38 of continuous functions : @xmath39 .",
    "therefore the sample space is taken to be @xmath40 and @xmath41 is taken to be the wiener measure .",
    "this is analogous to the situation of dice - tossing , where we take six face values , @xmath42 and @xmath43 , as samples in the _ canonical _ sample space @xmath44 .",
    "when we  toss \" a wiener process @xmath7 , we see continuous ( but nowhere differentiable ) curves as  face values \" or samples .",
    "the wiener shift @xmath45 is defined as a mapping in the canonical sample space @xmath46 , for each fixed @xmath47 , @xmath48    [ wienershift ] the wiener shift defined in is a measure preserving transformation , i.e. @xmath49    where @xmath41 is the wiener measure and @xmath50 is implied .",
    "+ by a simple calculation , we see that @xmath51 ( the identity mapping in @xmath46 ) and @xmath52 .",
    "hence the wiener shift is a deterministic dynamical system ( or a flow ) in @xmath46 .",
    "the above equation means that @xmath53 thus @xmath45 is closely related to the noise in the stochastic system and is often called the _ driving flow_. the solution mapping satisfies the property @xcite @xmath54    a stochastic inertial manifold for is a random family of manifolds @xmath55 which is measurable with respect to @xmath56 and satisfies the following three properties :    1 .",
    "each realization of @xmath57 is a deterministic manifold : @xmath58 is a lipschitz ( or smooth ) manifold for @xmath59almost all @xmath60 .",
    "invariance : @xmath61 3 .",
    "exponential attraction : for any @xmath62 @xmath63    where @xmath64 is the unique solution for defined for @xmath65 such that @xmath66 and @xmath67 is the solution mapping @xmath68    1 .",
    "@xmath58 is a  random variable \" mapping all the samples ( continuous functions ) in the canonical sample space @xmath46 into the space of deterministic lipschitz ( or smooth ) manifolds @xcite , and thus is measurable with respect to @xmath69 .",
    "figure  [ stoimf ] explains the meaning of random family of manifolds @xmath70 heuristically .",
    "the stochastic invariant property can be considered as a natural generalization of invariance property in the deterministic setting . in the deterministic case , @xmath71 , which can be seen as @xmath72 since there is one and only one sample in such setting . in the stochastic",
    "setting , the invariance is in the sense of probability .",
    "more precisely , under the system evolution or solution mapping  @xmath73 , if we start from somewhere on the manifold @xmath58 , then after time @xmath31 , we will stand on manifold @xmath74 whose likelihood of occurrence is the same as @xmath58 .",
    "this is implied by the measure - preserving property of wiener shift @xmath45 , i.e. @xmath75 , see remark  [ wienershift ] . from now on",
    ", we do not distinguish  @xmath76 \" and  @xmath77 \" when we say  a fixed sample \" .",
    "recall that the construction of an inertial manifold in the deterministic case amounts to finding a graph above an eigenspace of the linear operator @xmath4 . by analogy",
    ", we take a projection @xmath78 to a finite dimensional eigenspace @xmath79 , and look for a function @xmath80 from @xmath81 to @xmath82 whose graph is invariant under the evolution of the stochastic system .",
    "the analytical foundation of our numerical method is the combination of two well known methods for constructing deterministic inertial manifolds .",
    "one is the lyapunov ",
    "perron method , and the other one is the graph transform method @xcite . roughly speaking , the lyapunov ",
    "perron method looks for solutions of the original equation whose components on @xmath83 are bounded for negative time .",
    "the graph transform method is to let an inertial manifold ( typically , the flat manifold @xmath84 ) evolve under the system evolution and to verify that the image of @xmath84 at time @xmath31 is a graph which will converge to an invariant manifold as @xmath85 .",
    "as introduced by da prato and debussche @xcite , we reformulate into a backward part and a forward part for time @xmath86 $ ] : @xmath87 and @xmath88 where @xmath78 is a projection from @xmath0 to the eigenspace spanned by the first @xmath89 eigenvalues @xmath90 of @xmath4 , and @xmath91 . here",
    "@xmath89 is determined by the eigenvalues and lipschitz constants for the existence of stochastic inertial manifolds @xcite .",
    "hence @xmath92 is of finite dimension @xmath89 and @xmath93 is of infinite dimension .",
    "the problem involves a backward stochastic evolutionary equation .",
    "[ rmk3 ] at first glance , we might want to solve the equations whose unknown is the pair @xmath94 , in the interval @xmath95 $ ] .",
    "however , this type of problem does not have solutions in general .",
    "for the existence and uniqueness of solution of sdes , in addition to the usual requirement as in the case of odes , it is also necessary for the solution to be adapted to the filtration generated by the noise .",
    "since the filtration is a collection of fields ,   @xmath96 , @xmath97 , if we use the usual backward integration method , i.e. , finding the solution at time @xmath31 by making use of the solution at time @xmath98 , then this @xmath99solution is @xmath100measurable but not necessarily @xmath101measurable , which violates the definition of solution for sdes .    in order to overcome this difficulty , the terminal value problem of sde",
    "is reformulated in such a way as to allow a solution that is @xmath102adapted .    by proposition 3.1 introduced by da prato and debussche @xcite ,",
    "for every @xmath103 that is @xmath104measurable and square integrable , there exists a unique triple @xmath105 such that    1 .",
    "@xmath106\\mapsto ph $ ] is mean - square continuous and adapted , + 2 .",
    "@xmath107\\mapsto qd(a^{\\alpha})$ ] is mean - square continuous and adapted , + 3 .",
    "@xmath108 is a square integrable martingale with values in @xmath84 ,    and @xmath105 solves the following combined backward - forward stochastic system , for time @xmath86 $ ] @xmath109 where @xmath110    note that the solution of this system sits on the interval @xmath111 $ ] , the first @xmath89 components of @xmath112 , i.e. @xmath92 , travel backward from 0 to @xmath113 , and the remaining infinitely many components of @xmath112 , i.e. @xmath93 , travel forward from @xmath113 to 0 .",
    "figure [ schematicbf ] is a schematic illustration of this backward - forward method .",
    "for each fixed @xmath114 , define a mapping @xmath115 via @xmath116 da prato and debussche @xcite showed that the limit of @xmath117 as @xmath118 in @xmath119 is the function @xmath80 whose graph above @xmath84 is the inertial manifold @xmath120 in the next section we discuss how to numerically simulate and then in section 4 we approximate the mapping @xmath80 and thus obtain an approximate inertial manifold @xmath121 .",
    "in this section , we devise a numerical scheme to compute the solution of the backward - forward stochastic system . our scheme is inspired by @xcite .",
    "some related references are @xcite .      literally speaking , the backward - forward numerical iteration scheme for works as follows : we start the first iteration by setting @xmath93 to be zero ( flat manifold ) for the entire time interval @xmath95 $ ] , and @xmath92 to be zero on @xmath122 together with the terminal @xmath92 value to be any @xmath123-measurable random variable .",
    "we obtain the @xmath92 trajectory backward in time , by using future information of @xmath124 at the previous iteration , and then we generate the @xmath93 trajectory future in time using past in time information of @xmath124 at the previous iteration .",
    "the iteration is stopped when the distance of two consecutive @xmath124 trajectories is less than a preset tolerance ; we then use the terminal @xmath93 value at that iteration to approximate one point on the manifold @xmath80 .",
    "we will illustrate the method in more detail in section  [ sec4 ] .    before getting to the backward - forward approach , we need the following preparatory work .",
    "let @xmath125 be an orthonormal basis for @xmath0 . in numerical analysis , we approximate the hilbert space ( could be infinite dimensional ) by a @xmath126dimensional subspace , and project into this subspace , i.e. @xmath127 in theory , @xmath128 could be infinite or a big natural number .",
    "the above projection is usually done by the galerkin method .",
    "we denote the numerical approximations of @xmath129 by @xmath130 , respectively",
    ". then @xmath131 and @xmath132 , @xmath133 and @xmath134 where @xmath135 .    for each fixed @xmath114 ,",
    "define a mapping @xmath115 via @xmath136 the limit of @xmath117 as @xmath118 in @xmath119 is the function @xmath80 , and its graph above @xmath137 is the ( approximate ) inertial manifold @xmath138 @xmath139 therefore , our goal of constructing the stochastic inertial manifold @xmath140 is to numerically solve in order to obtain @xmath115 for a large @xmath114 and for a number of sample @xmath76 s .    for convenience ,",
    "we denote @xmath141 for the rest of this paper . in the following ,",
    "we also denote @xmath142 by @xmath143 and @xmath144 by @xmath145 .    in principle",
    ", the solution of can be obtained as the limit of a picard type iteration @xmath146 as introduced by da prato and debussche @xcite . to be more precise ,",
    "@xmath147 , and @xmath148 is the solution of the following iteration scheme @xmath149 where @xmath150 $ ] .",
    "the conditional expectation given @xmath20 is introduced to guarantee that the solution is adapted , i.e. , measurable with respect to the filtration @xmath20 , as is done in the theory of backward sdes @xcite .",
    "our goal is to find @xmath115 via looking for @xmath151 for given @xmath152 since @xmath153 .",
    "we now introduce a time discretization of the above iteration .",
    "note that for the backward part @xmath154 , the conditional expectation is still involved ; for the forward part @xmath155 , we use the euler - maruyama scheme in the discretization . in the numerical computation",
    ", every simulation corresponds to one sample , however , we can not specify which sample we have actually chosen , but we do know that it is a validated sample in the sample space @xmath46 .",
    "suppose @xmath156 , taking @xmath7 to be one dimensional wiener process , and denoting @xmath157 , then a time discretization of is    @xmath158h\\,\\vline\\,\\f_{t_i}\\bigg\\},\\\\ y_{t_i}^{(n)}&=e^{-u(t_i+t)}y(-t)+\\sum_{j=0}^{i-1}e^{-u(t_i - t_j)}f_2(x_{t_j}^{(n-1)},y_{t_j}^{(n-1)})h\\\\ & + \\sum_{j=0}^{i-1}e^{-u(t_i - t_j)}g_2(x_{t_j}^{(n-1)},y_{t_j}^{(n-1)})\\dd w_j .",
    "\\end{array } \\right.\\end{aligned}\\ ] ]    in section  [ sec4 ] , we will explain how to implement this scheme .",
    "note that we could also use the available @xmath159 , instead of @xmath160 , at the current iteration ( for @xmath161 ) to calculate @xmath162 in the above scheme  .",
    "we now show the convergence of the above time discretized picard iteration scheme .",
    "we now prove the convergence of the numerical scheme devised in the last subsection .",
    "namely , we prove the convergence of @xmath163 to @xmath164 in a certain sense ( see theorem  [ thm1 ] below ) . to this end",
    ", we estimate @xmath165 and @xmath166 in lemma  [ l2 ] and lemma  [ l3 ] , respectively .",
    "define    @xmath167h\\bigg)\\mid\\f_{t_i}\\}\\\\ y_{t_i}^{(\\infty)}&=e^{-uh}[y_{t_{i-1}}^{(\\infty)}+\\int_{t_{i-1}}^{t_i}e^{u(s - t_{i-1})}f_2(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})ds+\\int_{t_{i-1}}^{t_i}e^{u(s - t_{i-1})}g_2(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})dw_s ] .",
    "\\end{array } \\right.\\end{aligned}\\ ] ]    recall @xmath168h\\bigg)\\mid\\f_{t_i}\\}\\\\ y_{t_i}^{(n+1)}&=e^{-uh}[y_{t_{i-1}}^{(n+1)}+\\int_{t_{i-1}}^{t_i}e^{u(s - t_{i-1})}f_2(x_{t_{i-1}}^{(n)},y_{t_{i-1}}^{(n)})ds+\\int_{t_{i-1}}^{t_i}e^{u(s - t_{i-1})}g_2(x_{t_{i-1}}^{(n)},y_{t_{i-1}}^{(n)})dw_s ] .",
    "\\end{array } \\right.\\end{aligned}\\ ] ]    [ l2 ] let the lipschitz condition be satisfied .",
    "assume that @xmath169 and @xmath170 then the following inequality holds : for all @xmath171 , @xmath172\\\\ & \\leq c_2(\\frac{1}{2}+c_1h)^n,\\end{aligned}\\ ] ] where @xmath173 depends on @xmath174 and @xmath175 depends on @xmath176 .",
    "first note that @xmath177h\\mid\\f_{t_i}\\},\\\\ x_{t_i}^{(n)}&={{\\bbb{e}}}\\{x_{t_{i+1}}^{(n)}+[sx_{t_{i}}^{(n-1)}-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)})]h\\mid\\f_{t_i}\\}.\\\\\\end{aligned}\\ ] ] we now estimate @xmath178\\\\ & = { { \\bbb{e}}}\\bigg(\\mid{{\\bbb{e}}}\\bigg\\{x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}+\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid\\f_{t_i}\\bigg\\}\\mid^2\\bigg)\\\\ & \\leq{{\\bbb{e}}}\\bigg({{\\bbb{e}}}\\bigg\\{\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}+\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid^2\\mid\\f_{t_i}\\bigg\\}\\bigg)\\\\ \\quad&\\text{(jensen 's inequality)}\\\\ & = { { \\bbb{e}}}\\bigg\\{\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}+\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid^2\\bigg\\}\\\\ & = { { \\bbb{e}}}\\bigg\\{\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2+\\mid\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid^2\\\\ & + 2\\mid(x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)})\\sqrt h\\mid\\mid\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]\\sqrt h\\mid\\bigg\\}\\\\ & \\leq{{\\bbb{e}}}\\bigg\\{\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2+\\mid\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid^2\\bigg\\}\\\\ & + 2\\sqrt{{{\\bbb{e}}}[\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2h]}\\sqrt{{{\\bbb{e}}}\\mid\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]^2h\\mid}\\\\ & \\leq{{\\bbb{e}}}\\bigg\\{\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2+\\mid\\big[sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n-1)},y_{t_{i}}^{(n-1)}))\\big]h\\mid^2\\bigg\\}\\\\ & + \\ga h{{\\bbb{e}}}\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2+\\ga^{-1}h{{\\bbb{e}}}\\mid sx_{t_{i}}^{(n)}-sx_{t_{i}}^{(n-1 ) } -(f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n)})-f_1(x_{t_{i}}^{(n)},y_{t_{i}}^{(n-1)}))\\mid^2\\\\ \\quad&(\\text{young 's inequality } ab\\leq \\frac{a^2}{2\\ga}+\\frac{b^2\\ga}{2}\\quad \\text { where $ \\ga>0 $ will be choosen later})\\\\ & \\leq(1+\\ga h)\\bigg({{\\bbb{e}}}\\mid x_{t_{i+1}}^{(n+1)}-x_{t_{i+1}}^{(n)}\\mid^2\\\\ & + \\frac{h+\\ga^{-1}}{1+\\ga h}l_f^2{{\\bbb{e}}}\\mid y_{t_{i}}^{(n)}-y_{t_{i}}^{(n-1)}\\mid^2h+\\frac{h+\\ga^{-1}}{1+\\ga h}l_f^2{{\\bbb{e}}}\\mid x_{t_{i}}^{(n)}-x_{t_{i}}^{(n-1)}\\mid^2h\\bigg).\\end{aligned}\\ ] ] since @xmath179 , by iterating the last inequality , we obtain    @xmath180\\nonumber\\\\ & \\leq l_f^2(h+\\ga^{-1})\\big[\\sum_{j = i}^{n-1}{{\\bbb{e}}}\\mid y_{t_j}^{(n)}-y_{t_j}^{(n-1)}\\mid^2h+\\sum_{j = i}^{n-1}{{\\bbb{e}}}\\mid x_{t_j}^{(n)}-x_{t_j}^{(n-1)}\\mid^2h\\big].\\end{aligned}\\ ] ]    for the forward sde part , since in the numerical scheme @xmath155 is only of finite dimension , we consider @xmath155 to be one - dimensional for simplicity , and estimate    @xmath181\\mid^2\\nonumber\\\\ \\leq 3e^{-2uh}\\bigg(&{{\\bbb{e}}}\\mid y_{t_{i-1}}^{(n+1)}-y_{t_{i-1}}^{(n)}\\mid^2+{{\\bbb{e}}}\\mid\\int_{t_{i-1}}^{t_i}e^{u(s - t_{i-1})}(f_2(x_{t_{i-1}}^{(n)},y_{t_{i-1}}^{(n)})-f_2(x_{t_{i-1}}^{(n-1)},y_{t_{i-1}}^{(n-1)}))ds\\mid^2\\nonumber\\\\ & + { { \\bbb{e}}}\\mid\\int_{t_{i-1}}^{t_i } e^{u(s - t_{i-1})}(g_2(x_{t_{i-1}}^{(n)},y_{t_{i-1}}^{(n)})-g_2(x_{t_{i-1}}^{(n-1)},y_{t_{i-1}}^{(n-1)}))dw_s\\mid^2\\bigg)\\nonumber\\\\ \\leq 3e^{-2uh}\\bigg(&{{\\bbb{e}}}\\mid y_{t_{i-1}}^{(n+1)}-y_{t_{i-1}}^{(n)}\\mid^2+h^2{{\\bbb{e}}}l_f^2(\\mid x_{t_{i-1}}^{(n)}-x_{t_{i-1}}^{(n-1)}\\mid+\\mid y_{t_{i-1}}^{(n)}-y_{t_{i-1}}^{(n-1)}\\mid)^2\\nonumber\\\\ & + h{{\\bbb{e}}}l_g^2(\\mid x_{t_{i-1}}^{(n)}-x_{t_{i-1}}^{(n-1)}\\mid+\\mid y_{t_{i-1}}^{(n)}-y_{t_{i-1}}^{(n-1)}\\mid)^2\\bigg)\\nonumber\\\\ \\leq 3e^{-2uh}\\bigg(&{{\\bbb{e}}}\\mid y_{t_{i-1}}^{(n+1)}-y_{t_{i-1}}^{(n)}\\mid^2+(2h^2l_f^2 + 2hl_g^2){{\\bbb{e}}}\\mid x_{t_{i-1}}^{(n)}-x_{t_{i-1}}^{(n-1)}\\mid^2\\nonumber\\\\ & + ( 2h^2l_f^2 + 2hl_g^2){{\\bbb{e}}}\\mid y_{t_{i-1}}^{(n)}-y_{t_{i-1}}^{(n-1)}\\mid^2\\bigg)\\nonumber\\\\ \\leq 6e^{-2uh}(&hl_f^2+l_g^2)\\bigg(\\sum_{j=1}^{i-1}{{\\bbb{e}}}\\mid x_{t_j}^{(n)}-x_{t_j}^{(n-1)}\\mid^2h+\\sum_{j=1}^{i-1}{{\\bbb{e}}}\\mid y_{t_j}^{(n)}-y_{t_j}^{(n-1)}\\mid^2h\\bigg),\\end{aligned}\\ ] ]    where the last inequality is by iteration .    combining and , and letting @xmath182 , we have @xmath183\\\\ & \\leq \\widetilde { m_1}t\\max_{0\\leq i\\leq n}\\bigg[{{\\bbb{e}}}\\mid x_{t_i}^{(n)}-x_{t_i}^{(n-1)}\\mid^2+{{\\bbb{e}}}\\mid y_{t_i}^{(n)}-y_{t_i}^{(n-1)}\\mid^2\\bigg]\\\\ & \\leq ( \\widetilde { m_1}t)^n\\max_{0\\leq i\\leq n}\\bigg[{{\\bbb{e}}}\\mid x_{t_i}^{(1)}-x_{t_i}^{(0)}\\mid^2+{{\\bbb{e}}}\\mid y_{t_i}^{(1)}-y_{t_i}^{(0)}\\mid^2\\bigg]\\\\ & = ( \\widetilde{m_1}t)^n\\max_{0\\leq i\\leq n}\\bigg[{{\\bbb{e}}}\\mid x_{t_i}^{(1)}\\mid^2+{{\\bbb{e}}}\\mid y_{t_i}^{(1)}\\mid^2\\bigg].\\end{aligned}\\ ] ]    define @xmath184\\bigg)^{\\frac{1}{2}}$ ] by @xmath185 .",
    "then the series @xmath186 converges when @xmath187 .",
    "therefore , for all @xmath171 , @xmath188 is a cauchy sequence and thus converges to @xmath189 in the mean square sense . to be more precise , @xmath190\\\\ & \\leq \\bigg(\\sum_{\\nu = n}^{\\infty}a_\\nu\\bigg)^2\\\\ & = \\frac{(\\widetilde m_1t)^n\\max_{0\\leq i\\leq n}\\bigg[{{\\bbb{e}}}\\mid x_{t_i}^{(1)}\\mid^2+{{\\bbb{e}}}\\mid y_{t_i}^{(1)}\\mid^2\\bigg]}{(1-\\sqrt{\\widetilde m_1t})^2}.\\end{aligned}\\ ] ]    choosing @xmath191 , @xmath192 as in the assumption , thus @xmath193 . by taking @xmath194 where @xmath173 depends on @xmath174 and @xmath195 , since @xmath196 as shown similarly as lemma 8 in bender and denk   @xcite and @xmath197 only depends on @xmath198",
    ", we have @xmath190\\\\ & \\leq c_2(\\frac{1}{2}+c_1h)^n,\\end{aligned}\\ ] ] where @xmath175 depends on @xmath176 .",
    "this proves the lemma .    in the following",
    ", @xmath199 will denote a generic positive constant , independent of @xmath200 and @xmath201 , that may take different values from line to line .",
    "[ l3 ] assume all the conditions as in lemma [ l2 ] are satisfied , then @xmath202    note that @xmath203 + [ sx_{t_{i-1}}^{(\\infty)}-f_1(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})](t_i - t_{i-1}).\\end{aligned}\\ ] ] for @xmath204 , we have @xmath205 + [ sx_{t_{i-1}}^{(\\infty)}-f_1(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})](t - t_{i-1}).\\end{aligned}\\ ] ] by the martingale representation theorem @xcite , @xmath206+\\int_{t_{i-1}}^{t}z_s^{(\\infty)}dw_s,\\ ] ] we have @xmath207 + \\int_{t_{i-1}}^{t}z_s^{(\\infty)}dw_s,\\end{aligned}\\ ] ] which yields @xmath208dt + z_t^{(\\infty)}dw_t.\\ ] ] by it s formula , we have @xmath209 ^ 2 & = { { \\bbb{e}}}[x_{t_i}-x_{t_i}^{(\\infty)}]^2\\\\ & -{{\\bbb{e}}}\\int_t^{t_i}2(x_s - x_s^{(\\infty)})[-s(x_s - x_{t_{i-1}}^{(\\infty)})+f_1(x_s , y_s)-f_1(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})]ds\\\\ & -{{\\bbb{e}}}\\int_t^{t_i}(z_s - z_s^{(\\infty)})^2ds.\\end{aligned}\\ ] ] let @xmath210 then define @xmath211ds\\\\ & \\leq { { \\bbb{e}}}[c\\int_t^{t_i}\\mid\\delta x_s\\mid(\\mid x_s - x_{t_{i-1}}^{(\\infty)}\\mid+\\mid y_s - y_{t_{i-1}}^{(\\infty)}\\mid)]\\\\ & \\leq\\int_t^{t_i}{\\alpha}{{\\bbb{e}}}\\mid\\delta x_s\\mid^2ds + \\frac{c}{{\\alpha}}\\int_{t}^{t_i}{{\\bbb{e}}}[\\mid x_s - x_{t_{i-1}}^{(\\infty)}\\mid^2+\\mid y_s - y_{t_{i-1}}^{(\\infty)}\\mid^2]ds.\\end{aligned}\\ ] ] since @xmath212\\\\ & \\leq2\\big[(s - t_{i-1}){{\\bbb{e}}}\\int_{t_{i-1}}^s(-sx_r+f_1(x_r , y_r))^2dr+{{\\bbb{e}}}\\int_{t_{i-1}}^sz_r^2dr\\big]\\\\ & \\leq2\\big[(s - t_{i-1})\\int_{t_{i-1}}^s[{{\\bbb{e}}}(-sx_r+f_1(x_r , y_r)-f_1(0,0))^2+{{\\bbb{e}}}(f_1(0,0))^2]dr\\\\ & + { { \\bbb{e}}}\\int_{t_{i-1}}^sz_r^2dr\\big]\\\\ & \\leq2[(s - t_{i-1})\\int_{t_{i-1}}^s{{\\bbb{e}}}(cx_r^2 + 2l_f(x_r^2+y_r^2)+c)dr+{{\\bbb{e}}}\\int_{t_{i-1}}^sz_r^2dr]\\\\ & \\leq ch,\\end{aligned}\\ ] ] then we have @xmath213\\\\ & \\leq c(h+{{\\bbb{e}}}\\mid\\delta x_{t_{i-1}}\\mid^2)\\end{aligned}\\ ] ] for @xmath214 . on the other hand , @xmath215\\\\ & \\leq ch,\\end{aligned}\\ ] ] and note also that @xmath216 agrees with @xmath155 at each grid point , i.e. @xmath217 , thus @xmath218\\\\ & \\leq c(h+{{\\bbb{e}}}\\mid\\delta y_{t_{i-1}}\\mid^2)\\\\ & = ch.\\end{aligned}\\ ] ] by the definition of @xmath219 , @xmath220ds\\\\ & \\leq \\int_{t}^{t_i}{\\alpha}{{\\bbb{e}}}\\mid\\delta x_s\\mid^2ds + \\frac{c}{{\\alpha}}[h^2+h{{\\bbb{e}}}\\mid\\delta x_{t_{i-1}}\\mid^2]\\end{aligned}\\ ] ] and @xmath221\\bigg).\\end{aligned}\\ ] ] let @xmath222 $ ] , then by grownwall s inequality , @xmath223 .",
    "plugging it in the second inequality of , we have @xmath224 by taking @xmath225 , we have @xmath226),\\end{aligned}\\ ] ] and if we choose @xmath227 , @xmath228 iterating the last inequality and recall that @xmath229 , we have for sufficiently small @xmath230 , @xmath231 which yields @xmath232 , and by , we get for all @xmath233 $ ] @xmath234 and the right hand side of the inequality does not depend on @xmath31 . therefore ,",
    "@xmath235 for the forward part @xmath155 , we have @xmath236ds \\nonumber\\\\ & + \\int_{t_{i-1}}^te^{-u(t - s)}[g_2(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})-g_2(x_s , y_s)]dw_s\\bigg)^2\\nonumber\\\\ & \\leq 2 h{{\\bbb{e}}}\\int_{t_{i-1}}^te^{-2u(t - s)}[f_2(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})-f_2(x_s , y_s)]^2ds\\nonumber\\\\ & + 2{{\\bbb{e}}}\\int_{t_{i-1}}^te^{-2u(t - s)}[g_2(x_{t_{i-1}}^{(\\infty)},y_{t_{i-1}}^{(\\infty)})-g_2(x_s , y_s)]^2ds\\nonumber\\\\ & \\leq[c(h+{{\\bbb{e}}}\\mid\\delta x_{t_{i-1}}\\mid^2)+c(h+{{\\bbb{e}}}\\mid\\delta x_{t_{i-1}}\\mid^2)](2h^2c+2hc)\\nonumber\\\\ & \\leq ch^2,\\end{aligned}\\ ] ] where the last inequality is due to . consider and , we have @xmath237 this proves the lemma .",
    "now we are ready to state the convergence theorem . for @xmath238 $ ] , define @xmath239 and @xmath240 .",
    "we can also define @xmath241 and @xmath242 as the linear interpolation among @xmath243 s and among @xmath244 s , respectively , and the following result also holds .",
    "[ thm1 ] assume that all the conditions in lemma  [ l2 ] are satisfied .",
    "then @xmath245 where @xmath246 will denote a generic constant depending only on the data @xmath176 .",
    "this implies the convergence of the numerical scheme , as @xmath247 and @xmath248 .",
    "note that @xmath249 by regularity of the true solution as well as lemma  [ l2 ] and lemma  [ l3 ] .",
    "taking supremum on both sides of the above inequality , we have @xmath250",
    "now we approximate the graph @xmath80 for the inertial manifold @xmath251 . recall that @xmath80 is approximated via @xmath252 when @xmath253 is sufficiently big",
    ", @xmath254 . so we need to evaluate @xmath255 ( which is y(0 ) in section 3 ) . to this end",
    ", we need to compute , step by step , @xmath256 in . for the backward part @xmath257 , the conditional expectations @xmath258\\in l^2(\\f_{t_i})$ ]  in will be approximated by their orthogonal projections @xmath259 on finite dimensional subspaces @xmath260 of @xmath261 , where @xmath261 contains all the functions in @xmath119 that are @xmath262-adapted .",
    "indeed , instead of computing @xmath257 as follows @xmath263\\vline\\f_{t_i}\\bigg\\},\\ ] ] we will compute its orthogonal projection @xmath264 : @xmath265\\vline\\f_{t_i}\\bigg\\}.\\ ] ]    denoting a basis of the projection space @xmath266 by @xmath267 , we then have @xmath268 set @xmath269 and @xmath270 , with prime denoting matrix transpose , the calculation for the backward part @xmath271 boils down to two aspects : one is the basis @xmath272 , the other is the coefficient @xmath273 .",
    "[ remarkbasis ] as in @xcite , a complete orthonormal basis of @xmath274 is given by the wick polynomials @xmath275 , @xmath276 where @xmath277 are hermite polynomials .",
    "here @xmath278",
    "@xmath279 and @xmath280 , are a set of complete orthonormal basis in the hilbert space @xmath281)$ ] .",
    "one choice of the basis elements are the hermite polynomials of brownian motion @xmath7 .",
    "in fact , @xmath282 since @xmath283 , the basis elements @xmath284 s are @xmath285 which are adopted in our numerical implementation .    in principle ,",
    "the coefficients @xmath286 are calculated as follows : @xmath287,\\end{aligned}\\ ] ] where @xmath288\\bigg)_{p , q=1,\\ldots , d(i)}$ ] are the inner - product matrices associated with the basis .    in practice , @xmath289",
    "are computed by their simulation - based estimators , such as monte carlo least squares estimators used here @xcite . to this end",
    ", we are assuming to have @xmath290 ( sufficiently large ) independent copies @xmath291 , @xmath292 , of @xmath293 . here the index @xmath294 denotes copies .",
    "then @xmath295\\bigg)_{p , q=1,\\ldots , d(i ) } = \\left (   \\begin{array}{cccc } { { \\bbb{e}}}\\eta_1^i\\eta_1^i & { { \\bbb{e}}}\\eta_1^i\\eta_2^i & \\cdots & { { \\bbb{e}}}\\eta_1^i\\eta_{d(i)}^i\\\\                                        { { \\bbb{e}}}\\eta_2^i\\eta_1^i & { { \\bbb{e}}}\\eta_2^i\\eta_2^i & \\cdots & { { \\bbb{e}}}\\eta_2^i\\eta_{d(i)}^i\\\\                                        \\vdots & \\vdots & \\cdots & \\vdots\\\\                                        { { \\bbb{e}}}\\eta_{d(i)}^i\\eta_1^i & { { \\bbb{e}}}\\eta_{d(i)}^i\\eta_2^i & \\cdots & { { \\bbb{e}}}\\eta_{d(i)}^i\\eta_{d(i)}^i \\end{array } \\right),\\end{aligned}\\ ] ] is replaced by its monte carlo simulation @xmath296 @xmath297 and is further rewritten as @xmath298 where @xmath299 the pseudo - inverse denoted by @xmath300 is used in the computation of @xmath296 .",
    "the calculation of the coefficients @xmath301 is to obtain the backward part @xmath257 .",
    "note that the calculation of @xmath301 also needs the forward part @xmath302 , which is calculated through euler - maruyama scheme .",
    "the following formulae illustrate how to update @xmath301 .",
    "@xmath303\\label{eq : alphan},\\\\ ( _ \\l\\hat { y}_{t_i}^{(n)})_{\\l=1,\\ldots , r}&\\triangleq(_1\\hat y_{t_i}^{(n ) } , _ 2\\hat y_{t_i}^{(n ) } , \\cdots , _",
    "{ r}\\hat y_{t_i}^{(n)})'\\nonumber\\\\ & = \\bigg(e^{-uh}[_\\l\\hat",
    "y_{t_{i-1}}^{(n-1)}+f_2(_\\l\\hat x_{t_{i-1}}^{(n-1)},_\\l\\hat y_{t_{i-1}}^{(n-1)})\\dd_j\\nonumber\\\\ & + g_2(_\\l\\hat x_{t_{i-1}}^{(n-1)},_\\l\\hat y_{t_{i-1}}^{(n-1)})\\dd _ \\l w_j]\\bigg)_{\\l = 1,\\ldots , r}\\label{eq : yn}.\\end{aligned}\\ ] ]    where @xmath304 are independent copies of @xmath305 corresponding to independent copies of basis functions @xmath306 .    upon converge , i.e. @xmath307 we have @xmath308 as our approximation of @xmath309 .",
    "although we only need the final grid point value @xmath310 ( recall that @xmath311 ) as our approximation of the inertial manifold @xmath312 , the intermediate points @xmath313 are approximated by @xmath314 as follows @xmath315\\label{eq : y}.\\end{aligned}\\ ] ] therefore , this approach of approximating stochastic inertial manifold also provides a way of solving backward - forward stochastic differential equations . as in equation ,",
    "@xmath316 s are approximated by its orthogonal projection @xmath317 , where the randomness comes from the basis functions @xmath318 rather than the coefficients @xmath319 .",
    "the fact that @xmath320 s are deterministic can be seen from , since @xmath320 s are expectations . in the numerical simulation of @xmath320 s , we utilize copies of @xmath321 s ( different copies corresponding to different sample paths @xmath76 ) to calculate the expectations .",
    "all the conditions required by bender and denk in @xcite are satisfied in our case , so the error analysis results for the monte carlo simulation also apply here .",
    "figure [ flowchart ] demonstrates the procedure of computing stochastic inertial manifold .",
    "specifically , the computation is achieved in the following way as shown in figure  [ schema ] : we begin with the flat manifold , i.e. let all the @xmath155-values be zero . in principle",
    ", we could take any other acceptable initial manifold and let it flow forward , and at the limit it would also approach the desired manifold .",
    "we thus start our iteration by letting the initial guess @xmath155 be zero at each @xmath322 , see . in order to avoid nestings of conditional expectations ,",
    "we also let initial guess @xmath154 values to be zero except at terminal time @xmath323 , which corresponds to letting all but the final set of coefficients @xmath320 to be @xmath22 , see .",
    "recall that we approximate each @xmath257 value by its finite dimensional orthogonal projection as in , so indeed we want to calculate @xmath301 .",
    "the terminal value of @xmath154 is set to be a @xmath324measurable random variable . at each iteration , in order to update @xmath325  , we use copies of @xmath326 as well as @xmath327 ( @xmath328 ) from previous iteration , and then generate copies of @xmath243 by virtue of copies of basis functions @xmath329 s , see .",
    "copies of @xmath244 are reproduced by an euler - maruyama scheme as in , in which different copies correspond to the sample @xmath76 s that are already chosen in basis functions @xmath329 s .",
    "this procedure is repeated until @xmath321 converges in the mean square sense .",
    "we finally acquire the terminal value of @xmath155 at the stopped iteration as the approximation of @xmath309 .",
    "in this section , we test our backward - forward numerical scheme in two examples .",
    "one is a system of sdes , and the other one is an spde ( which is converted to a system of sdes ) .",
    "* example 1 : a system of stochastic ordinary differential equations *    @xmath330    where @xmath7 is a scalar wiener process , @xmath331 and @xmath332 are real parameters , @xmath333 indicates the stratonovich interpretation of the noise term and @xmath334 .    figure [ eg1pplane ] is the phase portrait for the deterministic counterpart of example 1 ( @xmath335 ) .     and @xmath336 .",
    "_ _ ]    take @xmath337 and @xmath336 .",
    "figure [ eg1tra ] shows several sample solution paths of the sde system - .     and @xmath337 .",
    "_ _ ]    roberts @xcite introduced a normal form transform method for stochastic differential systems with both slow modes and quickly decaying modes .",
    "the ( approximate ) formula for the slow manifold ( a type of inertial manifold ) of example 1 obtained via his method .",
    "is @xmath338 and @xmath339 in figure  [ eg1slowmfd ] , we plot the stochastic inertial manifold according to @xmath340 and compare it with the stochastic inertial manifold from our backward - forward method for one sample path @xmath341 . there is a remarkable agreement of the shapes of the stochastic slow manifold obtained by the two distinct methods . for four samples in figure [ real ] , figure  [ difference ] then shows the discrepancy between the stochastic inertial manifold realised on three realisations @xmath342 and that realised on @xmath76 via our backward - forward approach , respectively , i.e. @xmath343 , @xmath344 , and @xmath345 in red , blue and green color .",
    "calculated by the backward - forward method and by the normal form transform method for example 1 .",
    "online version : magenta from the backward - forward method and black from the normal form transform method .",
    "_ ]        , while red ( top right ) , blue ( bottom left ) and green ( bottom right ) for discrepancies between stochastic manifold realised on samples @xmath346 , @xmath347 and @xmath348 and stochastic manifold realised on sample @xmath349 .",
    "_ ]    * example 2 : a stochastic partial differential equation *    we examine how effective the stochastic inertial manifold approach is in assisting the simulation of the long - term dynamics of an spde .",
    "we consider a stochastic partial differential equation @xmath350 where @xmath351 , @xmath7 is a scalar wiener process , and it interpretation of the noise term is adopted .",
    "let us first consider the dimension of the inertial manifold .",
    "note that the eigenvalues of the operator @xmath352 are @xmath353 with the corresponding eigenmodes @xmath354 , for @xmath355 .",
    "thus the dimension of the deterministic unstable eigenspace is 3 . in this example , @xmath356 .",
    "let @xmath78 be the orthogonal projection to the ( deterministic ) unstable eigenspace @xmath79 , spanned by eigenmodes @xmath357 .",
    "the existence of the stochastic inertial manifold requires the nonlinear terms to be the globally lipschitz . here , in example 2 ,",
    "although the drift term @xmath358 is only locally lipschitz , we can prepare the equation by replacing @xmath5 by the cutoff function @xmath359 which is defined to be @xmath5 in a bounded neighborhood centered at the origin , and 0 otherwise .",
    "the details of this procedure were described by da prato and debussche @xcite .    with the galerkin projection @xmath360 ,",
    "the evolutionary equations we will be working on become @xmath361 @xmath362 where we only keep four fourier modes @xmath363 for @xmath112 ; @xmath364 are simply ignored , as numerical simulations indicate that they are negligible in this specific case .",
    "it is difficult to visualize the stochastic inertial manifold directly .",
    "but we can plot a  point \" @xmath365 in @xmath79 and the corresponding  point \" @xmath366 on the inertial manifold , separately .",
    "the  point \" @xmath365 may be represented as @xmath367 with coordinates  @xmath368 .",
    "the corresponding  point \" @xmath369 on the stochastic inertial manifold is then computed through our backward - forward approach .",
    "we plot three different realizations of a point @xmath365 versus space variable @xmath154 in the left panel of figure  [ fig : spde ] , and then plot the corresponding point @xmath370 versus space variable @xmath154 separately in the right panel .    [ cols=\"^,^ \" , ]",
    "in this paper , we have devised a backward - forward numerical approach for computing stochastic inertial manifolds for stochastic evolutionary equations , including higher dimensional stochastic ordinary differential equations and stochastic partial differential equations .",
    "this approach is based on the stochastic inertial manifold theory of da prato and debussche @xcite , which requires a backward - forward approximation formulation .",
    "in fact , our approach also provides a stand - alone numerical scheme for solving backward - forward sdes .    unlike deterministic evolutionary equations",
    ", we need to guarantee the adaptedness of solution processes with respect to an appropriate filtration for stochastic evolutionary equations .",
    "this makes the computation in the backward part of our numerical approach cumbersome , as it involves simulating conditional expectations which further requires a random basis .",
    "it would be nice to have a numerical scheme that uses only forward simulations .",
    "clearly , a numerical scheme involving only forward simulations would be desirable ; such schemes have been devised for deterministic problems ( e.g. @xcite ) and we are working on adapting them for the stochastic case .                                            c. foias , g.r .",
    "sell and e.s .",
    "exponential tracking and approximation of inertial manifolds for dissipative nonlinear equations .",
    "_ journal of dynamics and differential equations_. * 1 * ( 1989 ) 199 - 244 .                                e. s. titi .",
    "une varit approximante de lattracteur universel des quations de navier  stokes , non linar , de dimension finie .",
    "_ comptes rendus de lacadmie des sciences _ , paris , * 307 * , srie i ( 1988 ) 383 - 385 ."
  ],
  "abstract_text": [
    "<S> a numerical approach for the approximation of inertial manifolds of stochastic evolutionary equations with multiplicative noise is presented and illustrated . after splitting the stochastic evolutionary equations into a backward and a forward part </S>",
    "<S> , a numerical scheme is devised for solving this backward - forward stochastic system , and an ensemble of graphs representing the inertial manifold is consequently obtained . </S>",
    "<S> this numerical approach is tested in two illustrative examples : one is for a system of stochastic ordinary differential equations and the other is for a stochastic partial differential equation .    </S>",
    "<S> [ [ key - words ] ] key words + + + + + + + + +    invariant manifolds , inertial manifolds , random dynamical systems , backward and forward stochastic differential equations , stochastic partial differential equations , numerical schemes </S>"
  ]
}