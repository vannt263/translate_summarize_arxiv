{
  "article_text": [
    "pinterest is an online catalog used to discover and save ideas .",
    "hundreds of millions of users organize pins around particular topics by saving them to boards .",
    "each of the more than 50 billion pins saved on pinterest has an image , resulting a large - scale , hand - curated collection , with a rich set of metadata .",
    "most pins images are well annotated : when a person bookmarks an image on to a board , a _",
    "pin _ is created around an image and a brief text description supplied by the user . when the same pin is subsequently saved to a new board by a different user , the original pin gains additional metadata that the new user provides .",
    "therefore , the data structure surrounding each pin continues to get richer each time the pin is re - saved .",
    "furthermore , boards ( i.e. collections of pins ) reveal relations _ between _ pins : if many users save these two pins together , there is a high likelihood that another user may find them to be related as well",
    ". such aggregated _ image co - occurrence _ statistics are found to be useful for related content recommendation .",
    "this work explores how user curation signals can be used in conjunction with content - based features to improve recommendation systems .",
    "specifically we introduce related pins , an _ item - to - item _ content recommendation service triggered when a pin closeup is shown to the user , and describe in detail our experiments using visual features ( such as those obtained from convolutional neural networks ) , which are of particular interest since this system ultimately recommends visual content .",
    "as one of the most popular features on pinterest  , related pins is a recommendation system that combines collaborative filtering  @xcite with content - based  @xcite retrieval . since may 2015 , the user engagement metric   on pin recommendations has improved by more than 50% .",
    "note that the improvement is the result of using both visual features and other metadata signals in the learning - to - rank framework  the scope of this paper is limited to the understanding of user curation and visual features in the context of recommendation systems .",
    "this work makes two contributions : first , we demonstrate that `` pinning , '' a form of user curation , provides valuable user signals for content recommendation .",
    "specifically we present our use of _ image / board co - occurrences _ , including the _ pinjoin _ data structure used to derive this signal .",
    "second , we demonstrate that combining collaborative filtering with content - based retrieval methods , such as applying a learning - to - rank framework  @xcite to a set of semantic and visual features associated with the candidate pins , can significantly improve user engagement .",
    "in particular , our a / b experiments demonstrate that the use of recently developed visual features ( when used in conjunction with other text and graph signals ) , such as those obtained from vgg  @xcite and faster r - cnn  @xcite yield significant gains in recommendation quality .",
    "collaborative filtering  @xcite using user - generated signals ( e.g. co - views , co - clicks ) is widely used in commercially deployed recommendation systems such as youtube related videos  @xcite and amazon related items  @xcite .",
    "this work investigates the use of _ user curation _ signals derived from pins image / board co - occurrences , which are unique to pinterest .",
    "visual features are widely used in both content - based recommendation systems and image search systems  @xcite , and the the learning - to - rank framework used in this paper from  @xcite has been widely used in industry  @xcite . to our best knowledge",
    "this work contains the first published empirical results on how the latest convolutional neural network ( cnn ) based visual features ( e.g. vgg  @xcite ) and large - scale object detection using faster r - cnn@xcite can improve commercial recommendation systems .",
    "visual features are computed using a distributed process described in our previous work  @xcite .",
    "content curation is the process of organizing and collecting content relevant to a particular topic of interest .",
    "pinterest is a user - powered content curation service as content is collected and grouped into topic boards , creating a rich set of metadata associated with pins images .",
    "for example , during pin creation , users typically provide a text description of the images as shown in figure 3 .",
    "although any single instance of text description can be noisy , an aggregated collection reveals important annotations relevant to the pin s image .",
    "furthermore , when a pin is saved to a board , one can infer the categorical information of the pin s image from the category the user selected for the board .",
    "formally , we denote the data structures associated with pins and boards in the following way : each _ pinjoin _ is a 3-tuple @xmath0 , where @xmath1 is the image url , @xmath2 is the collection of pins generated for that image , and @xmath3 is the aggregation of text annotations or keywords ( extracted from board titles and descriptions ) . each _",
    "boardjoin _ is represented as a 2-tuple @xmath4 , where t is the board title and p is a list of pins .",
    "pinjoin is conceptually similar to visual synsets  @xcite except in this case , all the images within a visual synset are exact duplicates of each other and the collection is curated manually . in practice , both of these structures contain additional metadata , such as category and topic information , which is used for deriving other features during re - ranking .",
    "user curation reveals relations _ among _ images : we observed that images of pins on the same board are semantically ( and to some extent visually ) related to each other .",
    "therefore , if enough users save these two pins together , there is a high likelihood that a new user may also find them to be related .",
    "this is helped by the fact that users on pinterest actively curate content  our engaged users have an average of 24 boards .",
    "an example of image / board co - occurrences is shown in figure  [ fig : occur_examples ] .",
    "this section presents the architecture that powers the pinterest related pins recommendation system .",
    "the first step described relies on collaborative filtering over user curation signals ( image co - occurrences on boards ) to generate a candidate sets .",
    "the second step uses content - based ranking approach to rank the candidates based on content signals such as visual features , textual signals , and categories signals derived from _",
    "pinjoins_.      the first step of the pipeline is to generate a set of image candidates for each query image , which will serve as candidate sets for content - based re - ranking .",
    "we adopt a classic collaborative filtering approach to exploit the pin / board co - occurrences as described in section 3 . for each pin , we select up to 10,000 pins with the highest number of shared boards . in practice",
    ", the candidate generation process is accomplished through a mapreduce job , which takes _ boardjoin _ @xmath5 as input .",
    "the mapping stage outputs image pairs @xmath6 for all image pairs in each board @xmath7 , and in the reduce stage all the related images are grouped by the same query image . for computational efficiency , we sample images based on the quality / popularity of the images . for pins that do not generate enough candidates through board co - occurrence",
    ", we rely on a content - based retrieval service described in our previous paper  @xcite .      after generating a set of candidates , we re",
    "- rank with a set of both content pair - features ( defined between a query and a candidate ) and query - independent features .",
    "in addition to standard features such as text annotation match and topic vector similarity , we were particularly interested in the effectiveness of visual similarity features for our re - ranking step .",
    "examples of visual features include the _ fc6 _ and _ fc8 _ activations of intermediate layers of deep convolutional neural networks ( cnns )  @xcite based on alexnet  @xcite and vgg  @xcite .",
    "these features are binarized ( _ fc6 _ ) and sparsified ( _ fc8 _ ) for representation efficiency and compared using hamming distance ( _ fc6 _ ) and cosine similarity ( _ fc8 _ ) , respectively .",
    "we use the open - source caffe  @xcite framework to perform training and inference of our cnns on multi - gpu machines . in this work ,",
    "we also trained an object detection module using faster r - cnn  @xcite , initially fine - tuned on a dataset containing the most common objects found on pinterest , including home decor and fashion categories such as various furniture types , shoes , dresses , glasses , bags and more .",
    "to learn the weight vector for our linear model , we adopted the learning - to - rank approach from joachims  @xcite .",
    "given training data in the form of relative ranking triplets @xmath8 , where document @xmath9 is considered to be more relevant to query @xmath10 than document @xmath11 , the ranksvm algorithm described in  @xcite approximates a weight vector @xmath12 which maximizes the number of training examples satisfying @xmath13 , where @xmath14 gives @xmath15 features of the document @xmath16 in the context of query @xmath17 .",
    "the relevance triplets we use in training are generated through user clicks and impression logs , normalized by position and device to account for position bias , using a clicks over expected clicks  @xcite ( coec ) model .",
    "for each query @xmath10 in our training set , given the set of observed results @xmath18 , we generate the training triplet : @xmath19 corresponding to the query , best engaged document , and worst engaged document .",
    "we also generate random negative examples : @xmath20 on the intuition that even poorly engaged candidates generated through our board co - occurrence signal should still be more relevant than a random document from our corpus of pins .",
    "in this subsection we present a qualitative analysis of using user curation signals to generate candidates for related pins .",
    "as we described previously , board co - occurrences for pins is a strong signal of relevance and has been the foundation of candidate generation for our system .",
    "figure  [ fig : occur_examples ] illustrates that the relevance of the candidates grows gradually when the number of co - occurrences with the query pin increases .",
    "we also show the percentage of image pairs having different number of board co - occurrences in figure  [ fig : cooccurrence ] .",
    "note that the majority of the image pairs ( around 80% ) only co - occur once on the same board , which suggests that ranking based on content features as the next step is important for finding high - quality recommendations . on the other hand , there are only a handful of image pairs which co - occur many times on the same boards .",
    "we found that one of the most important features for re - ranking the pin candidates generated through board co - occurrence is visual similarity .",
    "we validated this by setting up a series of a / b experiments , where we selected five million popular pins on pinterest as queries , and re - ranked their recommendations using different sets of features .",
    "the control group re - ranked related pins using a linear model with a set of standard features : text annotation similarity , topic vector similarity , category vector similarity , as well as query - independent features .",
    "the treatment group re - ranked using fine - tuned vgg _",
    "fc6 _ and _ fc8 _ visual similarity features along with indicator variables ( in addition to the features used in control ) .    across the 5 m query pins ,",
    "the treatment saw a 3.2% increase in save / clickthrough rate . after expanding the treatment to 100 m query pins",
    ", we observed a net gain of 4.0% in propensity to engage with related pins , and subsequently launched this model into production .",
    "similar experiments with a fine - tuned alexnet model yielded worse results ( only 0.8% engagement gain ) .",
    "when broken down by category , we noted that the engagement gain was stronger in predominantly visual categories , such as art ( 8.8% ) , tattoos ( 8.0% ) , illustrations ( 7.9% ) , and design ( 7.7% ) , and lower in categories which primarily rely on text , such as quotes ( 2.0% ) and fitness planning ( 0.2% ) . given the difference in performance among categories , we performed a follow - up experiment where we introduced a cross feature between the category vector of the query and the scalar _ fc6",
    "_ visual similarity feature ( between the query and candidate ) .",
    "this introduces 32 new features to the model , one for each of our site - wide categories ( these features are sparse , since the pinterest category vector thresholds most values to zero ) .",
    "the result from this was a further 1.2% engagement increase in addition to the gains from the initial visual re - ranking model .",
    "further work into component and cross product features is of interest to us , as they are essentially free to compute at rank - time , since the raw feature data is already stored .",
    "users are sometimes interested in the _ objects _ in the pin s image , instead of the full image ( as shown in figure  [ fig : visualobject ] ) .",
    "we therefore speculate that object detection , when feasible , should improve relevance targeting . after applying non - maximum suppression ( nms ) to the proposals generated by our fine - tuned faster r - cnn module mentioned in section , we considered query pins where the largest proposal occupies at least 25% of the pin s image , or if the proposal is smaller , it passes a confidence threshold of 0.9 in faster r - cnn .",
    "we categorize these images as containing a dominant visual object , and using the best - performing fine - tuned vgg re - ranking variant from the previous section as our control , we experimented with the following treatments :    * _ variant a _ :",
    "if a dominant visual object is detected in the query pin , we compute visual features ( vgg ) on just that object . * _ variant b _ : same as _ variant a _ , but we also hand - tune the ranking model by increasing the weight given to visual similarity by a factor of 5 .",
    "the intuition behind this variant is that when a dominant visual object is present , visual similarity becomes more important for recommendation quality . * _ variant c _ :",
    "if a dominant visual object is detected in the query pin , we still use the features from the entire image ( as the control does ) , but increase the weight given to visual similarity by a factor of 5 , as in _",
    "variant b_. in this variant , we assume that the presence of detected visual objects such as bags or shoes indicates that visual similarity is more important for this query .",
    ".results when using cross features and object detection , measured over a 7 day period in oct .",
    "2015 [ cols=\"<,<,^\",options=\"header \" , ]     results for these variants are listed in table [ tbl : visualsearchrel ] .",
    "variants a and b of the object detection experiments suggest that the tight bounding boxes from our object detection module do not provide enough context for our cnn models , but variant c , which results in an additional 4.9% engagement gain over the vgg similarity feature control , demonstrates that the presence of visual objects indicates that visual similarity should be weighed more heavily .",
    "based on these results , our future focus is scaling up the number of object categories we can detect , and tuning the weight given to visual similarity in variant b and c.",
    "the related pins system described in this work has improved user engagement metric and traffic on pin recommendations by more than 50% from may 2015 to november 2015 .",
    "this demonstrates that signals derived from user curation and the activity of users organizing content contain rich information about the images and are very effective when used in conjunction with collaborative filtering .",
    "we also demonstrate that visual features such as representations learned from cnns or presence of detected visual objects can be used in the learning - to - rank framework to improve item - to - item recommendation systems .",
    "one important component not discussed in this work is our use of user signal in the form of _ navboost _ , which also uses a model based on coec ( extended to actions beyond clicks ) to re - rank content based on user engagement .",
    "our future work includes exploring a richer set of features ( e.g. sparse features , dense features , cross - product features , more object categories ) and real - time recommendations ( enabling re - ranking based on locale , current search query , and other forms of personalization ) .",
    "we would like to thank our colleagues on the visual discovery and recommendations teams at pinterest , in particular dmitry chechik , yunsong guo , and many others .",
    "we d also like to acknowledge jeff donahue and trevor darrell from berkeley vision and learning center ( bvlc ) for their collaboration with pinterest and their work on caffe .",
    "s.  baluja , r.  seth , d.  sivakumar , y.  jing , j.  yagnik , s.  kumar , d.  ravichandran , and m.  aly .",
    "video suggestion and discovery for youtube : taking random walks through the view graph . in _ proceedings of the 17th international conference on world wide web _ , www 08 , pages 895904 , new york , ny , usa , 2008 .",
    "m.  bendersky , l.  garcia - pueyo , j.  harmsen , v.  josifovski , and d.  lepikhin .",
    "up next : retrieval methods for large scale related video suggestion . in _ proceedings of the 20th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 14 , pages 17691778 , new york , ny , usa , 2014 .",
    "o.  chapelle and y.  zhang .",
    "a dynamic bayesian network click model for web search ranking . in _ proceedings of the 18th international conference on world wide web _ , www 09 , pages 110 , new york , ny , usa , 2009 .",
    "acm .",
    "r.  datta , j.  li , and j.  z. wang .",
    "content - based image retrieval : approaches and trends of the new age . in _ proceedings of the 7th acm sigmm international workshop on multimedia information retrieval _ , mir 05 , pages 253262 , new york , ny , usa , 2005 .",
    "d.  a. ferrucci , e.  w. brown , j.  chu - carroll , j.  fan , d.  gondek , a.  kalyanpur , a.  lally , j.  w. murdock , e.  nyberg , j.  m. prager , n.  schlaefer , and c.  a. welty . building watson : an overview of the deepqa project .",
    ", 31(3):5979 , 2010 .",
    "y.  jing , d.  liu , d.  kislyuk , a.  zhai , j.  xu , j.  donahue , and s.  tavel . visual search at pinterest . in _ proceedings of the 21th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 15 , pages 18891898 , new york , ny , usa , 2015 .",
    "t.  joachims . optimizing search engines using clickthrough data . in _ proceedings of the eighth acm",
    "sigkdd international conference on knowledge discovery and data mining _ , kdd 02 , pages 133142 , new york , ny , usa , 2002 .",
    "acm .",
    "m.  richardson , a.  prakash , and e.  brill . beyond pagerank : machine learning for static ranking . in _ proceedings of the 15th international conference on world wide web _ , www 06 , pages 707715 , new york , ny , usa , 2006 .",
    "b.  sarwar , g.  karypis , j.  konstan , and j.  riedl .",
    "item - based collaborative filtering recommendation algorithms . in _ proceedings of the 10th international conference on world wide web _ , www 01 , pages 285295 , new york , ny , usa , 2001 ."
  ],
  "abstract_text": [
    "<S> this paper presents pinterest related pins , an item - to - item recommendation system that combines collaborative filtering with content - based ranking . </S>",
    "<S> we demonstrate that signals derived from _ user curation _ , the activity of users organizing content , are highly effective when used in conjunction with content - based ranking . </S>",
    "<S> this paper also demonstrates the effectiveness of visual features , such as image or object representations learned from convnets , in improving the user engagement rate of our item - to - item recommendation system . </S>"
  ]
}