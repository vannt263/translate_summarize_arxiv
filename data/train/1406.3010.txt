{
  "article_text": [
    "it has long been conjectured that humans , when tasked with recognizing the identity of an object or judging the similarity between objects , mentally simulate transformations of internal representations of those objects . shepard and metzler @xcite were the first to formalize this phenomenon , and assess it experimentally .",
    "they presented people with two line drawings , each of which portrayed a three - dimensional object in space .",
    "they showed that the reaction time for participants to decide whether the objects were the same ( except for a rotation in space ) or were different , was linearly related to the angle between the spatial orientation of the two objects .",
    "this finding indicated that a type of `` mental rotation '' was performed .",
    "if instead , a rotationally invariant representation of each object was formed , then the time required for a decision would presumably be independent of angle .",
    "although much progress on object recognition by machines has been inspired by human biology @xcite , these models have rarely accounted for the explicit transformation of internal representations analogous to human mental rotation . instead",
    ", much focus has been placed on developing recognizers that are invariant to spatial transformations .",
    "one example where invariance is engineered into the model is convolutional networks @xcite , which gain invariance to small translations in the input because they pool features over local regions .",
    "an alternative is to _ learn _ invariance , for example by augmenting the training set with perturbations of the training set @xcite , through temporal cues @xcite or incorporating linear transformation operators into feature learning algorithms @xcite .",
    "additionally , canonical correlation analysis ( cca ) @xcite and its non - linear variants have been used to model relationships between example pairs , including images of the same object under different view angles @xcite and images under different illumination conditions @xcite .",
    "another related stream includes various deformable part models @xcite and diffeomorphism models @xcite , where knowledge about specific spatial relationships or classes of transformations are encoded .",
    "some non - parametric methods bear a resemblance to mental rotation , for example , nearest - neighbor techniques in which examples are explicitly compared .",
    "however , for such methods to work well in domains with large intra - class variance , one either needs to maintain a database of essentially all different appearances of objects , or learn an invariant similarity measure @xcite .",
    "a class of relational unsupervised learning techniques @xcite use multiplicative interactions between inputs to represent correlation patterns across multiple images .",
    "one application of these methods has been to learn to represent transformations between image pairs @xcite .",
    "such a model can be used to assess the similarity between images and used for nearest - neighbor classification @xcite .",
    "another related line of research focuses on disentangling different attributes @xcite , for example face identity and expression .",
    "these models have multiple groups of hidden units corresponding to one group of visible units , where each group learns ` absolute ' representation of one attribute .",
    "in contrast , relational models @xcite learn to encode ` relative ' transformations between multiple groups of visible units , where each group represents one transformed instance of an image .    in this paper",
    ", we propose a neural architecture , inspired by mental rotation , that explicitly transforms representations of images while evaluating their similarity .",
    "the two key components of our approach are i ) a relational model trained on pairs of images which learns about the range of valid transformations ; and ii ) an optimization that attempts to transform an image such that its representation matches that of a target while respecting the constraints learned by the relational model .",
    "our work attempts to link two areas of study which have to - date remained disparate : unsupervised learning of image transformations and learning a similarity measure such that objects that are perceptually similar will have a high measurable similarity .",
    "the latter field has focused on methods which are computationally tractable , often learning a mahalanobis distance @xcite or other functional mapping @xcite in which distances can be computed for tasks such as nearest neighbour classification or document retrieval .",
    "such methods typically exploit distance information that is intrinsically available : binary or real - valued similarity or dissimilarity labels , user input , or class - based information .",
    "rarely has the set of known transformations of an object been incorporated in learning .",
    "an exception is hadsell et al .",
    "@xcite , though they do not attempt to model transformations .",
    "however , transformations are a cue for learning an invariant measure and often can be acquired cheaply through unlabeled data , for example , video .",
    "characterizing a transformation is central to our task .",
    "the field of representation learning @xcite is concerned with learning features which untangle unknown underlying factors of variation in data .",
    "these representations enable higher - level reasoning without domain - specific engineering . while the majority of these techniques are concerned with learning representations of individual objects ( e.g.  images ) a subclass of these methods aim to learn relations from pairs of objects @xcite .",
    "these techniques have been applied to feature covariances in image and audio data @xcite , learning image transformations @xcite , and spatio - temporal features for activity recognition @xcite .",
    "both probabilistic @xcite ) and non - probabilistic @xcite variants of relational feature learning methods exist .",
    "the former is based on extending the restricted boltzmann machine to three - way rather than pairwise interactions .",
    "the latter extends auto - encoders in a similar way .",
    "although the auto - encoder - based approach is easier to train using gradient descent , we adopt the rbm formalism in our work due to the simplicity with which its free energy can be computed to score input pairs under the model .",
    "recent work also suggests a means of scoring inputs under an autoencoder @xcite .",
    "a relational model captures the transformation between meaningful pairs of images @xmath0 , such as photos taken from different views of the same object , and images with different expressions of the same face .",
    "it encodes the transformation information of @xmath1 to @xmath2 as a hidden representation @xmath3 , which can also be used to transform the `` source '' @xmath1 towards the `` target '' @xmath2 .",
    "( h)@xmath3 ; ( fac ) [ below = of h ] edge [ - ] ( h ) ; ( x)[below = of fac , xshift=-4em]@xmath1 edge [ - > ] ( fac.left corner ) ; ( y)[right = of x , xshift=5em ] @xmath2 edge [ - ] ( fac.right corner ) ;                    [ sameidentity ]                    [ sameobject ]    the factored gated rbm ( fgrbm ) @xcite relates @xmath1 , @xmath2 and @xmath3 by the following energy function : @xmath4 where @xmath5 , @xmath6 and @xmath7 are the dimensionality of @xmath1 , @xmath2 and @xmath3 respectively ; @xmath8 , @xmath9 , and @xmath10 are a set of filters that project @xmath1 , @xmath2 and @xmath3 onto @xmath11 factors . @xmath12 and @xmath13 are the bias coefficients for @xmath2 and @xmath3 respectively .",
    "equation [ eq : gaussian_fgrbm_energy ] defines a gaussian - bernoulli @xcite version of fgrbm capable of modeling real - valued data , which has a slightly different energy function from that of the original binary fgrbm in @xcite .",
    "equation [ eq : gaussian_fgrbm_energy ] assumes that @xmath1 and @xmath2 are real - valued and @xmath3 is binary .",
    "we express the probability of @xmath2 and @xmath3 , conditioned on @xmath1 , in terms of the defined energy function as : @xmath14 where the partition function @xmath15 ensures normalization .",
    "marginalizing over @xmath3 , we obtain the probability distribution of @xmath2 : @xmath16 where @xmath17 is the free energy of @xmath2 , which is defined as @xmath18 , or @xmath19      to train the fgrbm , we would like to maximize the average log probability of @xmath2 given @xmath1 for a set of training pairs @xmath20 : @xmath21 where @xmath22 represents all the involved parameters .",
    "the partial derivative of the likelihood @xmath23 with respect to any parameter @xmath22 is @xmath24    where @xmath25 denotes the expectation with respect to @xmath26 .",
    "the first term is the derivative of the free energy which is tractable to compute .",
    "the second term involves integrating over all possible @xmath2 and therefore is intractable in non - trivial settings . in this paper",
    ", we used the contrastive divergence learning algorithm @xcite .",
    "we can use a trained fgrbm to transform an image @xmath1 with a given @xmath3 which encodes a transformation .",
    "the transforming function can be derived from the conditional @xmath27 by taking the conditional expectation of @xmath28 .",
    "we use @xmath29 to represent the transformed @xmath1 with respect to @xmath3 .",
    "@xmath29 has the same dimensionality as @xmath2 and we express the j^th^ element of @xmath30 as @xmath31    with @xmath29 , we can define the transforming distance @xmath32 between a pair of images @xmath33 , given their transformations represented by @xmath34 and @xmath35 respectively : @xmath36 where @xmath37 represents the transforming distance with a _ single - sided _ transformation and @xmath38 uses a _ dual - sided _ transformation . intuitively , the difference between these approaches is whether @xmath39 is transformed to match @xmath40 or if @xmath39 and @xmath40 are both transformed to match each other .",
    "@xmath41 can be any pairwise distance and @xmath42 can be any feature representation of @xmath43 . in this paper , for distance metrics , we simply consider the euclidean distance ; for feature representations , we consider raw pixels , principal component analysis ( pca ) and the contractive autoencoder ( cae ) @xcite .",
    "diagrams for both single and dual - sided transformed distances are shown in fig .",
    "[ fig : trans_dist ] .",
    "( h)@xmath44 ; ( fac ) [ below = of h ] edge [ - ] ( h ) ; ( x_0)[below = of fac , xshift=-3em]@xmath45 edge [ - > ] ( fac.left corner ) ; ( y)[right = of x_0 , xshift=4em ] @xmath46 edge [ - ] ( fac.right corner ) ;    ( ftr_0)[above = of y , xshift=0.8em ] @xmath47 edge [ - ] ( y ) ;    ( dist)[above = of ftr_0 , xshift=1.7em , yshift=0.5em]@xmath48 edge[-](ftr_0 ) ; ( ftr_1)[below = of dist , xshift=1.7em , yshift=-0.5em ] @xmath49 edge [ - ] ( dist ) ;    ( x_1)[right = of y , xshift=2.5em]@xmath50 edge[-](ftr_1 ) ;    [ singletrans ]    ( h_a)@xmath44 ; ( fac_a ) [ below = of h_a ] edge [ - ] ( h_a ) ; ( x_0)[below = of fac , xshift=-3em]@xmath45 edge [ - > ] ( fac_a.left corner ) ; ( t_a)[right = of x_0 , xshift=4em ] @xmath46 edge [ - ] ( fac_a.right corner ) ;    ( ftr_a)[above = of t_a , xshift=0.8em ] @xmath47 edge [ - ] ( t_a ) ; ( dist)[above = of ftr_a , xshift=1.8em , yshift=0.5em]@xmath48 edge[-](ftr_a ) ;    ( ftr_b)[right = of ftr_a , xshift=0.8em ] @xmath51 edge [ - ] ( dist ) ;    ( h_b)[right = of h_a , xshift=9.75em]@xmath52 ; ( fac_b ) [ right = of fac_a , xshift=9.25em ] edge [ - ] ( h_b ) ; ( t_b)[right = of t_a , xshift=2.5em]@xmath53 edge[-](ftr_b ) edge[-](fac_b.left corner ) ; ( x_b_0)[below = of fac_b , xshift=3em]@xmath50 edge [ - > ] ( fac_b.right corner ) ;    [ dualtrans ]    by doing `` mental rotation '' during image comparison , images undergo learned transformations to minimize their distance . if we only minimize the transforming distance @xmath32 over @xmath3 , the transformed image @xmath46 might be very similar to image @xmath40 while not respecting the constraints learned by the fgrbm , i.e. not being a `` valid '' transformation of @xmath39 . to effectively tie the `` identity '' of @xmath46 to @xmath39 throughout the transformation , we regularize this optimization by its free energy defined in equation [ eq : free_energy ] .",
    "accordingly , we have the following cost function : @xmath54 where @xmath3 represents both @xmath44 and @xmath52 for brevity . regularization term",
    "@xmath55 represents the free energy term(s ) : for a single - sided transformation , @xmath56 ; for a dual - sided transformation @xmath57 .",
    "@xmath58 is an empirically chosen weight constant to balance @xmath32 and @xmath55 ( we set @xmath59 in all of our experiments ) .",
    "the optimized fgrbm hidden vector @xmath60 is defined as : @xmath61 instead of optimizing the binary hidden units directly , we optimize the real - valued logits ( pre - sigmoid inputs ) .",
    "the pairwise image distance of @xmath33 after mental rotation is defined as : @xmath62 we use gradient descent with momentum to compute equation [ eq : h_opt ] . to allow parallel processing over pairs on a gpu , we do not set a stopping criterion for individual pairs .",
    "we stop the optimization after 30 iterations .",
    "we note that more sophisticated gradient - based optimization methods can be used , though they may not be as amenable to gpu - based parallelization .",
    "we considered two datasets : the toronto face database ( tfd ) @xcite and the norb dataset @xcite .",
    "a qualitative visual assessment was performed to demonstrate the validity of optimizing the transforming distance . to quantitatively evaluate , we replaced the l2 distance in k nearest neighbor ( knn ) algorithm with the proposed transforming distance .",
    "we denote this variant of knn as _ transforming knn_. specifically , a fgrbm is trained at the training stage ; during test time , this fgrbm defines a transforming distance that is used to match test images with examples in the knn database .      *",
    "the tfd * contains 102,236 face images of size 48 @xmath63 48 .",
    "3,874 of them are labeled with identities of 963 people . among these , 626 identities ( 3,537 images ) have at least 2 images for each identity .",
    "we refer to this subset as the identity - labeled images .",
    "we first learned the valid expression transformation within the same face identity using the fgrbm ( see fig .  [ sameidentity ] ) .",
    "we expect the transforming distance to be expression invariant and evaluate this by performing identity recognition .",
    "the tfd dataset was divided into four sets :    * the feature training set , which contains all the identity - unlabeled images and identities with a single image ( separated so that features are not biased towards either training or test set ) ; * the knn training set ( database ) , used for both training the fgrbm and as a knn database ; * the knn validation set , used for hyper - parameter cross - validation ; * and the knn test set .    to the best of our knowledge ,",
    "we are unaware of any reported work on identity recognition using the tfd dataset .",
    "therefore , we explore two methods to divide the identity - labeled images into training , validation and test sets , refered as tfds1 and tfds2 :    * * tfds1 * : for each identity , randomly take 1 image as test .",
    "for the remaining data , randomly take 1 as validation from any identity with at least 2 images .",
    "each random division results in a training set of size 2,540 , a validation set of size 371 and a test set of size 626 .",
    "the training set contains 21,948 image pairs , including self pairs ( i.e.  the identity transformation ) . * * tfds2 * : for each identity with at least 4 images , randomly take 1 image as test and 1 as validation .",
    "each division results in a training set of size 2,937 , a validation set of size 300 and a test set of size 300 .",
    "the training set contains 23,607 image pairs , including self pairs .",
    "there are several differences between tfds1 and tfds2 . in tfds1 ,",
    "the test set is larger .",
    "however , 326 identities have only one example .",
    "this challenges the model in two ways : i ) identities can not be learned by the fgrbm ; ii ) each identity appears only once in the knn database . in the tfds2 training set",
    ", images always appear in pairs , which favors both fgrbm training and knn .",
    "however , since only identities with at least 4 instances contribute to the validation and test sets , the knn database is `` diluted '' by 891 `` extra '' images which share identity with neither validation nor test .",
    "* the norb dataset * contains @xmath64 stereo image pairs of 50 toys from 5 categories .",
    "images were taken under different lighting conditions , elevations and azimuths @xcite .",
    "we used the `` small norb '' variant , where the images have a clean background .",
    "the training and test sets each contain 24,300 images .",
    "for norb , we try to model the transformation between images of the same object with different azimuth ( see fig .  [ sameobject ] ) .",
    "we expect the transforming distance to be rotation invariant.=-1    we arbitrarily assigned all images with instance number 7 to the validation set , which includes 4,860 images , and all images with instance label 4 , 6 , 8 , 9 to the training set , which contains 19,440 images .",
    "the training set was used for feature learning , fgrbm training and as the knn database .",
    "we used the default test set split .      before training the fgrbm and performing transforming distance",
    ", tfd images were preprocessed by local contrast normalization ( lcn ) @xcite with kernel size 9 . for the norb dataset",
    ", we only used the first image from each stereo pair .",
    "the images were first down - sampled to @xmath65 and then preprocessed by lcn with kernel size 3 .",
    "examples are shown in fig .",
    "[ fig : fgrbm ] ( b ) and ( c ) .    for tfd ,",
    "the fgrbm is trained on image pairs with the same identity .",
    "the fgrbm encodes valid expression transformation information . for norb , within each image pair , 2 images share the same class , instance , lighting condition and elevation .",
    "the fgrbm encodes the valid azimuth transformation information .",
    "based on the allowed azimuth difference between images , we trained 2 types of models : 1 ) _ anytrans _ , where the images within a pair have an arbitrary azimuth difference ; and 2 ) _ smalltrans _ , where the absolute value of azimuth difference is less than or equal to 40@xmath66 .      for the feature representation ,",
    "we cross - validated the choice of pca and cae with 64 , 128 and 256 hidden units on regular knn .",
    "the best one of these 6 combinations was chosen .",
    "for the fgrbm , we cross - validated hidden dimensionality of 64 , 128 and 256 by performing a single - sided transforming knn with pixel distance .",
    "for norb , the @xmath67 value for knn was cross - validated in the range of 1 to 30 . while for tfd , @xmath67 was set to 1 because of the nature of the task .",
    "the number of factors in the fgrbm is fixed as twice the dimensionality of the hidden units .",
    "due to space constraints , details of the remaining settings are provided in supplemental material .      to assess the transforming distance optimization process , we observed the transformed image @xmath68 at each optimization step .",
    "[ fig : img_seq ] shows the optimization process of both same - identity and different - identity image pairs .",
    "we see that during the optimization process , the transformed images are all valid transformations of the source images : the faces images preserves their identities , even when an image is transformed to match a face image with different identity ; the car and human figure are merely rotated , even when the human figure image is transformed to match the car image .",
    "this is an interesting generalization result , since the fgrbm was only trained on same - identity pairs .    ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ]    ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs . note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ]    ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 . the 1st and 3rd rows show the process of transforming same - identity pairs . the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs",
    ". note preservation of identity.=-1 , title=\"fig : \" ]    ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs",
    ". note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ] ; the last image is the `` target '' image @xmath50 ; images in - between are transformations of the source image @xmath46 , the second last image is the optimized transformation @xmath68 .",
    "the 1st and 3rd rows show the process of transforming same - identity pairs .",
    "the 2nd and 4th rows show different - identity pairs .",
    "note preservation of identity.=-1 , title=\"fig : \" ]      for quantitative evaluation , the transforming distance was combined with knn as the transforming knn .",
    "it is compared with 2 baseline methods : the regular knn and a proposed _ augmented knn_.      by performing `` space searching '' when calculating transforming distances , each example in knn database covers a volume , a manifold composed of all its valid transformations , in the data space .",
    "it is interesting to see if this `` expanding effect '' can be achieved by augmenting the knn database using the learned transformation and then performing regular knn .",
    "this comparison is meaningful especially when the data space is not well covered by the knn database ( e.g.  in the tfd dataset ) .",
    "therefore , we proposed the `` augmented knn '' and test it on tfd .",
    "additional training images were sampled from a trained fgrbm .",
    "we used each image in the knn database as the `` source '' image , and performed gibbs sampling alternating between hidden and target units .",
    "we retained one sample every 100 iterations . by repeating this 9 times for every image in the knn database",
    ", we acquired a database 10 times as large as the original database .",
    "we are unaware of any prior work which has used a relational model for dataset augmentation . provided the data to train the relational model is available",
    ", this seems like an attractive option to the usual approach of hand - coding perturbations @xcite.=-1      .knn classification accuracy ( % ) on the tfd dataset . [ cols=\"^,^,^,^,^,^,^,^ \" , ]     * tfd * results are shown in table [ tab : tfd ] .",
    "for both tfds1 and tfds2 , we analyzed both single and dual - sided transforming knn .",
    "results are compared against augmented knn and regular knn .",
    "transforming knn brings 6  10 % performance increase for tfds1 and about 25 % performance increase for tfds2 .",
    "augmented knn also brings some amount of accuracy increase , but not as high as transforming knn .",
    "this indicates that the augmented database does not cover as much as volume as the transforming distance , at least when the database is expanded tenfold .",
    "the performance differences between tfds1 and tfds2 correspond to our analysis in section [ sec : exp_data ] .",
    "accuracies in every column is higher in tfds2 than in tfds1 .",
    "this is probably due to the fact that in tfds2 , every test image has at least two corresponding images in the knn database , while in tfds1 , about half of the test images only have one .",
    "the relative performance increase is higher in tfds2 than in tfds1 .",
    "this is probably because that in tfds2 , expression transformation was learned for every identity , while in tfds1 , this was done only on about half of the identities .    *",
    "norb * results are given in table [ tab : norb ] .",
    "with a cross - validated @xmath67 value , the smalltrans knn has a 4% performance increase over regular knn .",
    "we are not surprised by the marginal improvement of the transforming knn .",
    "this is because the norb training set contains images of the same object taken from different azimuths ( every 20@xmath66 ) , which already provides some degree of rotation invariance .",
    "therefore smalltrans and anytrans can only do slightly better , if they provide a finer rotation invariance , say rotations under 20@xmath66 difference , for some cases .",
    "however , the rotation invariance afforded by the training set disappears when there are less examples in the database , which is further illustrated in fig .",
    "[ fig : knn_reduce ] and discussed in section [ sec : exp_knn_reduce ] .",
    "[ fig : knn_k ] shows knn accuracy with respect to different @xmath67 values . for tfd",
    ", we can see that both regular knn and transforming knn degrade as @xmath67 increases .",
    "this is mainly due to the lack of examples in its knn database : if @xmath67 is large , number of noise examples will be larger than true examples even the true examples might have higher similarities , which is also aggravated by the identity - imbalanced nature of tfd . in comparison ,",
    "augmented knn is the most robust to larger settings of @xmath67 , due to the richness of same - identity examples in the knn database .    for norb ,",
    "regular knn accuracy decreases with increasing @xmath67 .",
    "this is because without transforming distance , a test image should only be close to examples with the same class label and , with equal importance , the orientation in the knn database .",
    "therefore , test images can not utilize many examples to provide effective distances . on the contrary ,",
    "transforming knn can utilize training examples regardless of their orientation , which results in an increasing robustness with increasing @xmath67 .    .",
    "in ( a ) and ( b ) , the dual - sided transforming knn was performed and ( b ) shares the legend with ( a ) . in ( c ) , both smalltrans and anytrans are single - sided . ]    . in ( a ) and ( b )",
    ", the dual - sided transforming knn was performed and ( b ) shares the legend with ( a ) . in ( c ) , both smalltrans and anytrans are single - sided . ]    . in ( a ) and",
    "( b ) , the dual - sided transforming knn was performed and ( b ) shares the legend with ( a ) . in ( c ) , both smalltrans and anytrans are single - sided . ]       for all plots . ]     for all plots . ]     for all plots . ]",
    "as previously mentioned , under transforming knn , each example in the database can span a manifold and covers a `` volume '' .",
    "we examine this assumption by performing knn on reduced databases and showing the relationship between accuracy and missing data rate ( randomly discarded ) in fig .",
    "[ fig : knn_reduce ] . for both tfd and norb , transforming knn works reasonably well with missing data . their performance are still comparable to the regular knn with complete database , when 70% ( tfds1 ) , 80% ( tfds2 ) and even 99%",
    "( norb , anytrans ) data are missing .",
    "for tfd , missing data results in missing identities .",
    "therefore , no matter how good the relational model is , a performance drop is inevitable . in comparison",
    ", norb contains only 5 classes .",
    "this makes it possible to maintain performance under a very high missing data rate . in fig .",
    "[ fig : knn_reduce ] ( c ) , anytrans knn maintains its accuracy even when 99% data are missing ( 199 examples left in database ) ; smalltrans knn is still better than regular knn when 90% data are missing .",
    "smalltrans knn performs better than anytrans knn when the missing data rate is low , but degrades as the missing data rate increases .",
    "we suspect that the fgrbm has difficulty encoding complicated transformations ( e.g.  arbitrary 3d changes of objects ) .",
    "this conjecture ( on the complexity of transformation ) is supported by the fact that the best cross - validated fgrbm dimensionality is 128 for smalltrans and 256 for anytrans .",
    "although the anytrans fgrbm might have learned less realistic transformations , it seems to be able to bridge large transformation gaps when the database is sparse .",
    "it maintains its performance even when 99% data are missing , and still provides a 60% accuracy when 99.9% data are missing .",
    "this hints at the potential of transforming knn on `` weakly '' labeled datasets , where only a small portion of data have class labels and the majority of the data has weaker `` relational labels '' indicating image pairs .",
    "relational labels can be acquired from video . finally , using a reduced knn database could potentially speed up transforming knn by 100 times at test time .",
    "this alleviates the additional computational burden brought by test - time optimization .",
    "the key novelty in our work is the idea of augmenting learned similarity functions with latent variables capturing factors of variation .",
    "although we were inspired by the evidence of a mental faculty for the simulation of spatial transformations , we believe that this is just one example out of a richer class of dynamic similarity models achievable within this framework .",
    "that is to say , the proposed framework is generic , since it is composed of interchangeable components .    nevertheless , performing inference or optimization over latent variables while comparing examples is much more computationally demanding than the typical `` test - time '' application of learned similarity models .",
    "this can be partially alleviated by a reduced need for large databases .",
    "unfortunately our method precludes the use of approximate nearest neighbour techniques , which are typically used on large - scale problems of the type we considered .",
    "we have , however , achieved modest gains by parallelizing on gpus .",
    "we believe that the computational cost is the main concern in considering similarity models with latent variables and we intend to address this issue in future work .    in each of the two datasets we considered , only a single transformation class",
    "was learned .",
    "relational models like the fgrbm and relational autoencoder can , in theory , capture a rich set of transformations .",
    "therefore another avenue of future work is demonstrating the efficacy of transforming similarity across a wider range of transformations ."
  ],
  "abstract_text": [
    "<S> the human visual system is able to recognize objects despite transformations that can drastically alter their appearance . to this end </S>",
    "<S> , much effort has been devoted to the invariance properties of recognition systems . </S>",
    "<S> invariance can be engineered ( e.g.  convolutional nets ) , or learned from data explicitly ( e.g.  temporal coherence ) or implicitly ( e.g.  by data augmentation ) . </S>",
    "<S> one idea that has not , to date , been explored is the integration of latent variables which permit a search over a learned space of transformations . </S>",
    "<S> motivated by evidence that people mentally simulate transformations in space while comparing examples , so - called `` mental rotation '' , we propose a _ transforming distance_. here , a trained relational model actively transforms pairs of examples so that they are maximally similar in some feature space yet respect the learned transformational constraints . </S>",
    "<S> we apply our method to nearest - neighbour problems on the toronto face database and norb . </S>"
  ]
}