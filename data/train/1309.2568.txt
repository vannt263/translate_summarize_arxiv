{
  "article_text": [
    "products of random matrices arise in many areas of research and engineering @xcite . in studies of dynamical systems one uses products of random matrices to derive limiting laws for lyapunov exponents @xcite ; in information theory and wireless telecommunication  to calculate channel capacities for serial mimo ( multiple - input multiple - output ) transmission @xcite . with the help of products of random matrices one investigates unitary evolution @xcite , matrix diffusion @xcite or phase transitions in quantum yang - mills theories @xcite .",
    "one encounters products of random matrices in studies of quantum entanglement @xcite , financial engineering @xcite , and many other fields of research @xcite .",
    "the problem of random matrix multiplication has attracted attention since the sixties @xcite .",
    "originally the studies were mostly concentrated on deriving limiting laws for products of infinitely many finite random matrices @xcite with some exceptions where also limiting laws for infinite matrices were formulated @xcite .",
    "recently the focus has shifted to products of infinitely large matrices due to the discovery of a correspondence between infinitely large invariant random matrices and free random variables @xcite which have been studied in the framework of free probability @xcite  a new branch of probability theory that has been intensively developed since the eighties @xcite .",
    "many results derived in this theory have been applied to large random matrices in the limit of infinite matrix size @xmath0 .    in this paper",
    "we review some of these results , and give practical recipes to calculate eigenvalue densities of products of large random matrices . instead of giving formal proofs",
    "we gradually build up intuition passing from matrix addition through multiplication of hermitian random matrices to multiplication of non - hermitian matrices .",
    "free addition of large random matrices is a counterpart of addition of independent random variables in classical probability .",
    "we start with addition because it is much simpler than multiplication but it already has essential ingredients needed to understand a special role of invariant random matrices played in the formulation of limiting laws for eigenvalue distributions in the large @xmath1 limit .",
    "the key feature of invariant random matrices is that their eigenvectors are not correlated with the eigenvalues , and that they are uniformly distributed .",
    "the last statement means that the unitary matrix constructed from the normalized eigenvectors is uniformly distributed on the unitary group . in effect ,",
    "randomness of such matrices is entirely shaped by the probability distribution of the eigenvalues .",
    "the sum of independent invariant random matrices is an invariant random matrix . in the limit @xmath0 the eigenvalue density of the sum depends only on eigenvalue densities of the matrices added .",
    "this law is very similar to the law of addition in classical probability where the probability distribution of the sum of independent random variables can be calculated from the probability distributions of these variables .",
    "similarities to classical probability go far beyond that .",
    "one can write a dictionary between classical and free probability . in this dictionary , random variable corresponds to invariant random matrix for @xmath0 , probability density function to eigenvalue density , characteristic function to green s function , cumulant generating function ( logarithm of the characteristic function ) to r transform , mellin transform of the probability density function to s transform , independence to freeness , etc . using this correspondence one can find a full analogy between free addition and free multiplication of large invariant matrices and addition and multiplication of independent random variables .",
    "it is worth emphasizing that the laws of free addition and free multiplication can be independently derived using field theoretical methods , including perturbation theory of invariant matrix models @xcite , without referring to free probability .",
    "perturbation theory is a way of graphical enumeration of planar feynman diagrams that arise in the large @xmath1 limit @xcite .",
    "a great advantage of the field theoretical approach is that it also works in the case of non - hermitian matrices and it allows to derive a non - hermitian version of the multiplication law @xcite . to the best of our knowledge",
    "this result is beyond the reach of free probability so far .",
    "we shortly recall this result here .",
    "the paper is organized as follows . in section [ sec - add ]",
    "we discuss eigenvalues of a sum of random matrices .",
    "in particular we define a slightly modified version of matrix addition  such that it is independent of the eigenvectors of the matrices added .",
    "this brings us to the class of invariant random matrices that are discussed in section [ sec - inv ] . in section [ sec - fadd ]",
    "we recall the definition of the green s function , the moment generating function and the r transform .",
    "these functions are used in the derivation of limiting laws for invariant matrices in the large @xmath1 limit .",
    "we employ these functions in the formulation of the law of free addition . in section [ sec - mult ]",
    "we discuss the law of free multiplication for invariant hermitian matrices . in section [ sec - iso ]",
    "we discuss consequences of this law for multiplication of infinitely large isotropic non - hermitian matrices .",
    "finally in section [ sec - nh ] we show how to calculate eigenvalue densities for products of large independent non - hermitian matrices .",
    "we illustrate calculations with examples .",
    "we conclude the paper with a short summary in section [ sec - concl ] .",
    "let @xmath2 and @xmath3 be @xmath4 hermitian matrices .",
    "we are interested in the eigenvalues of the sum @xmath5 . to calculate them",
    "it is not sufficient to know the eigenvalues of @xmath2 and @xmath3 .",
    "one would also need to know their eigenvectors",
    ". actually it would be enough to know relative positions of the eigenvectors of @xmath2 and @xmath3 : for example the decomposition of @xmath3-eigenvectors in the eigenbasis of @xmath2 .",
    "one can , however , define a non - standard addition of matrices that depends only on the eigenvalues of individual matrices in the sum and not on their eigenvectors .",
    "this new addition is defined in a probabilistic way as a sum @xmath6 where @xmath7 are independent haar unitary matrices and @xmath8 denotes the hermitian conjugate of @xmath9 .",
    "let us recall that haar unitary matrix is a random matrix distributed according to the uniform measure on the unitary group @xmath10 .",
    "the matrix @xmath11 is not a concrete matrix but it is a random matrix or equivalently an ensemble of matrices with a certain probability measure .",
    "the eigenvalues of @xmath11 are random variables .",
    "one is interested in the joint probability distribution of these random variables .",
    "the marginal distribution of the joint probability distribution is referred to as the eigenvalue distribution .",
    "one should note that the transformations @xmath12 and @xmath13 preserve the eigenvalues of the individual terms , but uniformly randomize their eigenvectors .",
    "one can therefore expect that the eigenvalue distribution of @xmath14 depends only on eigenvalues of @xmath2 and @xmath3 .",
    "moreover , since the sum @xmath15 can be written as @xmath16 , where @xmath17 is also a haar unitary matrix , the eigenvalue distribution of the matrix @xmath18 averaged over @xmath19 is the same as the eigenvalue density of @xmath11 . in other words",
    "it is sufficient to randomize the eigenvectors of one matrix against the other .",
    "one can consider a more general version of the problem in which @xmath2 and @xmath3 are independent random matrices instead of being deterministic ones . in this case",
    "the question is whether one can determine the eigenvalue distribution of @xmath14 from the eigenvalue distributions of individual matrices @xmath2 and @xmath3 . the answer is affirmative for @xmath0 . in this limit",
    "the eigenvalue density @xmath20 of the sum @xmath14 can indeed be determined solely from the eigenvalue densities @xmath21 and @xmath22 . for finite",
    "@xmath1 the answer is more complicated since it depends also on eigenvalue correlations .",
    "the correlations can be neglected only in the limit @xmath0 .",
    "the addition ( [ fa ] ) is called free addition when @xmath0 and @xmath2 and @xmath3 are independent . in the next section we shall see that the addition ( [ fa ] ) is equivalent to the standard matrix addition @xmath5 for invariant random matrices .",
    "random matrices are formally defined by matrix ensembles equipped with probability measures .",
    "let us denote the measure of an @xmath4 hermitian random matrix @xmath23 by @xmath24 .",
    "random matrix @xmath23 is called invariant if the measure is invariant under the transformation @xmath25 , where @xmath26 is an arbitrary unitary matrix : @xmath27 .",
    "let us give two standard examples .",
    "one can construct an invariant random matrix from a diagonal random matrix @xmath28 and haar unitary random matrix @xmath9 @xmath29 the invariance of the measure for @xmath2 : @xmath30 is a direct consequence of the invariance of the haar measure @xmath31 under the right multiplication by a unitary matrix @xmath26 .",
    "one can choose the diagonal elements @xmath32 s of @xmath33 to be independent , identically distributed real random variables .",
    "in such a case the joint eigenvalue density factorizes and @xmath34 where @xmath35 is the probability density function for the random variables representing diagonal elements of @xmath33 .",
    "the factorization of the joint eigenvalue density reflects the independence of the eigenvalues .",
    "the eigenvalue density is @xmath36 .    in physical applications",
    "one frequently encounters invariant measures of the form @xcite @xmath37 where @xmath38 is a polynomial or a power series in @xmath2 and @xmath39 , denotes flat measure for @xmath4 hermitian matrices .",
    "the proportionality sign in ( [ v ] ) means that the right hand side is displayed up to a constant .",
    "this implicit constant ensures the probabilistic normalization @xmath40 .",
    "the joint probability eigenvalue distribution is given by a well - known dyson formula @xcite @xmath41 which can be interpreted as a partition function that describes a gas of @xmath1 particles in one dimension .",
    "we again skipped a normalization constant that ensures @xmath42 . in this picture",
    "the @xmath43-th eigenvalue @xmath32 corresponds to the position of the @xmath43-th particle in one - dimensional space .",
    "particles are in the potential @xmath44 .",
    "they repel each other with a logarithmic potential depending of the distance @xmath45 .",
    "the repulsion makes the eigenvalues interact . as a result",
    "they are correlated .",
    "the eigenvalue density can be calculated by integrating all but one eigenvalue from the joint eigenvalue distribution @xmath46 . in the limit",
    "@xmath0 one can relate the eigenvalue density to the potential by an integral equation @xcite @xmath47 obtained by applying the saddle point approximation to ( [ rhon ] ) .",
    "stands for principal value .",
    "one can use this equation to calculate the eigenvalue density for the given potential or to find the potential corresponding to a given eigenvalue density .",
    "in particular one can choose the potential to reproduce the same eigenvalue density as in the first ensemble ( [ ulu ] ) where the eigenvalue density is just equal to the probability density function for the diagonal elements of @xmath33 .",
    "the two random matrix ensembles ( [ ulu ] ) and ( [ v ] ) have completely different statistics of eigenvalues even if they have identical eigenvalue densities .",
    "let us come back to the general discussion of invariant random matrices .",
    "the standard addition @xmath5 of invariant random matrices is equivalent to free addition @xmath14 ( [ fa ] ) .",
    "this follows from the invariance of the measure , which implies that the matrix @xmath2 is identically distributed as @xmath48 .",
    "the same holds for @xmath3 and @xmath49 . for @xmath2 and @xmath3 being invariant random matrices , the two sums @xmath5 and @xmath14",
    "have identical probability measures .",
    "they represent the same random matrix ensemble .",
    "therefore from here on we shall not distinguish between @xmath5 and @xmath14 while discussing invariant random matrices .",
    "the sum of invariant random matrices is also an invariant random matrix .",
    "an important property of the sum @xmath5 of invariant matrices is that the eigenvalue density depends in the limit @xmath0 solely on the eigenvalue densities of @xmath2 and @xmath3 , as follows from the discussion in section [ sec - add ] .",
    "independent invariant random matrices for @xmath0 are called free .",
    "there is one - to - one correspondence between them and the free random variables known from free probability @xcite .    to summarize this section ,",
    "the standard addition of invariant random matrices is equivalent to free addition ( [ fa ] ) . in the limit @xmath0",
    "independent invariant random matrices are called free and the eigenvalue density @xmath50 of the free sum can be calculated from eigenvalues @xmath21 and @xmath22 of @xmath2 and @xmath3 .",
    "the resulting density is independent of the detailed statistics of eigenvalues .",
    "for example , it does not depend on whether eigenvalues are correlated or not or whether they are generated using the ensemble of type ( [ ulu ] ) , ( [ v ] ) or any other .",
    "the only thing that matters is the eigenvalue densities of the individual matrices in the sum . in the next section",
    "we briefly summarize the algorithm to calculate @xmath50 .",
    "for @xmath0 the eigenvalue density of an invariant random matrix @xmath2 can be described by an eigenvalue density @xmath21 having support @xmath51 on the real axis .",
    "typically @xmath51 is a finite interval . in calculations it is convenient to use the stieltjes transform of the density @xmath52 that is a complex function defined on the complex plane outside @xmath51 .",
    "this function is often called green s function .",
    "the density can be reconstructed from the green s function @xmath53 by calculating the imaginary part of the green s function close to the real axis @xmath54 the power expansion @xmath53 at infinity @xmath55 generates moments of the eigenvalue distribution @xmath56 these moments are equivalent to the trace moments @xmath57 calculated with respect to the probability measure @xmath58 for the entire matrix @xmath2 .",
    "the zeroth moment is fixed @xmath59 by the normalization of the measure .",
    "one often defines another moment generating function as a power series at zero @xmath60 it is related to the green s function @xmath61 the eigenvalue density @xmath21 , the moment generating function @xmath62 , and the green s function @xmath53 contain roughly speaking the same information about the eigenvalue distribution of the invariant matrix @xmath2 and one can reproduce these functions from each other .",
    "the idea is to calculate these functions for @xmath5 when the corresponding functions for @xmath2 and @xmath3 are given .",
    "let us first calculate the moments of @xmath5 @xmath63 the measure factorizes , since @xmath2 and @xmath3 are independent by assumption .",
    "for @xmath64 the last equation gives @xmath65 in the second equation we replaced @xmath66 by @xmath67 .",
    "the equality @xmath68 follows from the equation @xmath69 , which holds in the limit @xmath0 as a result of invariance and independence of @xmath2 and @xmath3 .",
    "the relations between moments ( [ mab2 ] ) can be written in a compact way using free cumulants which are certain ( specific ) combinations of moments @xcite : @xmath70 , @xmath71 , @xmath72 , etc .",
    "equations ( [ mab2 ] ) correspond to @xmath73 for @xmath64 .",
    "the concept of free cumulants is analogous to the standard cumulants in classical probability .",
    "let us recall that cumulants for a real random variable are generated as coefficients of the power series expansion of the logarithm of the characteristic function .",
    "the logarithm of the characteristic function for a sum of independent random variables is equal to the sum of logarithms of the characteristic functions of these random variables .",
    "therefore cumulants for the sum of independent variables are additive , exactly as free cumulants ( [ kab ] ) .",
    "free cumulants are , however , generated in a different way .",
    "the generating function for free cumulants is called r transform @xcite .",
    "free cumulants are equal to coefficients of the power series expansion @xmath74 note that there is a shift between the power of @xmath75 and the index of the corresponding cumulant .",
    "the r transform is related to the green s function which generates moments of the eigenvalue distribution .",
    "the relation reads @xmath76 we give it without a proof @xcite .",
    "one can find a diagrammatic interpretation of this equation @xcite using field theoretical methods for planar graphs enumeration @xcite .",
    "using equation ( [ gr ] ) one can find @xmath77 if @xmath78 is known .",
    "one can also invert equation ( [ gr ] ) @xmath79 this form is useful when one wants to determine the r transform for the given green s function .",
    "the r transform for the sum of free matrices @xmath5 is a sum of r transforms for @xmath2 and @xmath3 @xcite @xmath80 exactly as the logarithm of the characteristic function for the sum of independent real random variables in classical probability .",
    "the additivity of r transform reflects the invariance and independence of the measures for @xmath2 and @xmath3 in ( [ mab ] ) . for @xmath0",
    "these two properties correspond to freeness .",
    "explicit relations between free cumulants @xmath81 and moments @xmath82 can be found by inserting the power series @xmath83 and @xmath84 into equation ( [ rg ] ) .",
    "the first three free cumulants are identical as the standard ones @xmath85 , @xmath86 , @xmath87 . from the fourth",
    "one on they are different .",
    "the fourth free cumulant is @xmath88 while the standard one is @xmath89 .",
    "the r transform was first introduced in free probability by voiculescu @xcite .",
    "later it was observed that free cumulants are related to a combinatorial problem of non - crossing lines on a plane @xcite .",
    "for this reason free cumulants are sometimes called non - crossing cumulants . for completeness",
    "we mention that equation ( [ rg ] ) can be deduced @xcite using field theoretical methods of planar graph enumeration @xcite .",
    "the green s function and the r transform correspond to sums over certain classes of diagrams , and equations like ( [ gr ] ) - to dyson - schwinger equations @xcite .",
    "the combinatorics for planar feynman diagrams for matrix models is equivalent to the combinatorial approach to freeness @xcite .",
    "we close this section by giving a standard example . recall that in classical probability the normal random variable with the probability density function @xmath90 has all cumulants equal zero except @xmath91 .",
    "what is the corresponding random matrix eigenvalue density in free probability that has all free cumulants equal zero except the second one @xmath91 ?",
    "we want to find the eigenvalue density corresponding to the r transform equal @xmath92 ( [ r ] ) . using ( [ gr ] )",
    "we first find an equation for the green s function @xmath93 .",
    "it can be solved for @xmath77 : @xmath94 .",
    "we select the branch of the square root to match the asymptotic behavior @xmath95 for large @xmath75 .",
    "the eigenvalue density is ( [ rhog ] ) @xmath96 for @xmath97 $ ] and zero otherwise .",
    "it is the wigner semicircle law .",
    "odd moments of this distribution are equal zero while even moments @xmath98 are equal to the catalan numbers .",
    "one can use equation ( [ vrho ] ) to find that the corresponding potential is quadratic @xmath99 , so the invariant measure ( [ v ] ) is gaussian @xmath100 .",
    "let us slightly modify the r transform and consider @xmath101 . without repeating the calculations one can easily argue on general grounds that the corresponding eigenvalue density is shifted as compared to the previous case by the first cumulant @xmath102 and rescaled by the second one @xmath103 leading to @xmath104 and @xmath105 .",
    "let us now calculate the eigenvalue density of the sum of two independent large ( @xmath0 ) invariant matrices @xmath2 and @xmath3 that have eigenvalue densities given by the wigner semicircle law with different shift and scale parameters .",
    "denote these parameters by @xmath106 , @xmath107 for @xmath2 and @xmath108 , @xmath109 for @xmath3 , respectively .",
    "the r transforms are @xmath110 and @xmath111 . to find the eigenvalue density of the sum @xmath112",
    "we first calculate r transform that is equal to @xmath113 with @xmath114 and @xmath115 .",
    "the r transform is exactly of the same form as for @xmath2 and @xmath3 .",
    "therefore the eigenvalue density for @xmath116 is also given by the wigner semicircle law .",
    "the situation is analogous to that in classical probability where the sum of two random gaussian variables is known to be a gaussian random variable .",
    "one says that the semicircle law is stable with respect to free addition in the same way as the gaussian law is stable with respect to addition in classical probability .",
    "actually there exist a bijection between stable laws in classical and free probability that allows one to classify all stable laws in free probability @xcite .",
    "just as a curiosity we mention that the only distribution that is stable with respect to addition ( random variables ) and free addition ( random matrices ) is the cauchy distribution .",
    "as we have seen the law of addition for independent large invariant matrices can be concisely expressed in terms of the r transform ( [ rr ] ) . before discussing the law of multiplication",
    "it is convenient to recall the corresponding law in classical probability .",
    "let @xmath23 and @xmath117 be independent non - negative real random variables .",
    "what is the distribution of the random variable @xmath118 ? a way to derive this distribution is via the mellin transform of the probability density function .",
    "the mellin transform @xmath119 for the product @xmath118 is the product of mellin transforms @xmath120 for @xmath23 and @xmath117 .",
    "clearly this multiplication law is analogous to the addition law discussed in the previous section ( [ rr ] ) .",
    "it remains to find the corresponding law for products of large invariant matrices .",
    "let @xmath2 and @xmath3 be independent invariant matrices . for the moment we also assume @xmath2 and @xmath3 to be positive semi - definite .",
    "later we will weaken this restriction .",
    "the first trivial observation is that even if @xmath2 and @xmath3 are hermitian , the product @xmath121 is generically non - hermitian , so its eigenvalues are complex .",
    "therefore , it is convenient to introduce a slightly modified version of the multiplication @xcite @xmath122 we use dot in the notation to distinguish @xmath123 from the standard matrix multiplication @xmath121 .",
    "square root of a positive semi - definite matrix is defined as @xmath124 where @xmath26 is a unitary matrix that diagonalizes @xmath2 : @xmath125 .",
    "the product @xmath123 of hermitian matrices is hermitian .",
    "the product @xmath123 of invariant random matrices is an invariant random matrix .",
    "moreover , the probability measure @xmath126 for the product @xmath123 is identical as for @xmath127 : @xmath128",
    "so this product is in a sense commutative .",
    "one should also note that the trace moments for the product @xmath129 ( [ cprod ] ) are identical as for the standard product : @xmath130 .",
    "the law of free multiplication was formulated by voiculescu in free probability @xcite .",
    "later it was shown that it applies also to multiplication ( [ cprod ] ) of invariant random matrices in the limit @xmath0 @xcite .",
    "the multiplication law is expressed in terms of s transform @xmath131 where @xmath132 is a complex function .",
    "the s transform @xmath132 can be constructed from the moment generating function @xmath62 ( [ phi ] ) or actually the inverse function of @xmath133 that is usually denoted by @xmath134 : @xmath135 .",
    "the relation reads @xcite @xmath136 the s transform can be viewed as a series in @xmath75 @xmath137 that is obtained by inserting the inverse series in place of @xmath62 in equation ( [ s_chi ] ) .",
    "the coefficients of this series are related to the moments @xmath138 .",
    "the coefficients are singular for @xmath139 , in which case the s transform is ill - defined .",
    "the s transform is related to the r transform as follows @xcite @xmath140 if one knows the r transform then the last equation can be used to calculate the s transform .",
    "one can invert the last equation @xcite @xmath141 which allows one to calculate the r transform if the s transform is known . using these relations",
    "one can show that the multiplication law ( [ sab ] ) can be alternatively written in the r transform form @xcite : @xmath142 this set of equations looks more complicated than ( [ sab ] ) but in some situations it is more advantageous .",
    "for example , it can be used when the first moments vanish , that is when the s transforms are ill - defined . moreover",
    ", this form can be generalized to the case of non - hermitian matrices , as we discuss in section [ sec - nh ] .",
    "the two forms of the multiplication law are in a sense complementary .",
    "the original s transform form of ( [ sab ] ) has a very simple and appealing structure that reflects important properties of free products , for example that the multiplication @xmath123 ( [ cprod ] ) of invariant random matrices is commutative and associative : @xmath143 .",
    "this follows from the fact that multiplication on the right hand side of ( [ sab ] ) is just multiplication of complex numbers which is commutative and associative .",
    "let us give an example to illustrate how these formal relations work in practice .",
    "consider the product @xmath123 of two independent identical wishart matrices @xcite .",
    "the wishart matrix can be thought of as a square of a gaussian matrix from the gue ensemble @xcite .",
    "the matrices @xmath2 and @xmath3 have the eigenvalue densities @xmath144 @xmath145 for @xmath146 $ ] and @xmath147 for @xmath148 outside this interval . the green s function ( [ green ] ) corresponding to this density is @xmath149 and the moment - generating function ( [ phig ] ) @xmath150 the inverse function of @xmath151 fulfills the equation @xmath152 which can be solved for @xmath153 @xmath154 thus the s transform is ( [ s_chi ] ) @xmath155 we now want to find the s transform for the product @xmath156 from @xmath157 . using the multiplication law ( [ sab ] )",
    "we obtain @xmath158 we now proceed to find the eigenvalue density @xmath159 that corresponds to the s transform given above .",
    "first we write the equation for the inverse function of the moment generating function @xmath160 using ( [ s_chi ] ) .",
    "we invert it for @xmath161 : @xmath162 it is a cubic equation for @xmath161 . replacing @xmath161 with the green s function ( [ phig ] ) we have @xmath163 this equation has three solutions given by the cardano formulas .",
    "we select the one which asymptotically behaves as @xmath164 for large @xmath75 . using ( [ rhog ] )",
    "we find the density @xmath165 for @xmath166 $ ] and zero otherwise .",
    "we close this section with a few general comments .",
    "the multiplication law ( [ sab ] ) or ( [ rprod ] ) can be derived using solely perturbation expansion for invariant matrix models in the limit @xmath0 without referring to free probability .",
    "we refer the interested reader to @xcite .",
    "the second comment concerns the multiplication law for matrices which are not positive semi - definite . in the discussion above we restricted the class of matrices to positive semi - definite ones because we wanted to use @xmath167 in the definition of the product @xmath123 ( [ cprod ] ) . for ( invariant )",
    "hermitian matrices the product @xmath129 is ( invariant ) hermitian .",
    "one can also consider the multiplication law for the standard product @xmath121 of hermitian matrices . in this case @xmath2 and @xmath3 do not have to be positive semi - definite .",
    "the matrix @xmath121 is non - hermitian and thus has complex eigenvalues .",
    "its trace moments @xmath168 are , however , real .",
    "since the s transform depends only on the moments , all calculations are identical as discussed before for @xmath129 except that the final result @xmath169 can not be interpreted as an eigenvalue density function , but merely as a function to calculate the trace moments of the matrix @xmath121 : @xmath170 the eigenvalue density has in this case generically a two - dimensional support on the complex plane .",
    "for example , the product of two independent hermitian matrices from the gue ensemble is a non - hermitian matrix .",
    "each gue matrix has real eigenvalues with the eigenvalue distribution given by the wigner semicircle law .",
    "the r transform @xmath171 ( we consider standardized gue with the mean zero and unit variance ) . using the r transform form of the multiplication law ( [ rprod ] ) one finds that @xmath172 and thus @xmath173 .",
    "this means that all the moments @xmath174 .",
    "it does not mean , however , that eigenvalue density of the product is zero . to calculate the eigenvalue density in this case one has to use methods that allow one to treat non - hermitian matrices .",
    "we discuss them in the subsequent sections . here",
    "we only mention that the eigenvalue density for the product is @xmath175 where @xmath75 is a complex variable .",
    "this result was first derived in @xcite with the help of field theoretical methods .",
    "note that the result is invariant under rotations around the origin of the complex plane .",
    "the extension from hermitian to non - hermitian random matrices is similar to the extension from real to complex random variables in classical probability . in this section",
    "we employ this similarity to define isotropic random matrices @xcite being probably the simplest extension of invariant random matrices to non - hermitian ones .",
    "consider a complex random variable with a probability measure that is invariant under rotation around the origin of the complex plane @xmath176 .",
    "the probability density is a function of the distance from the origin @xmath177 .",
    "such a random variable @xmath178 can be constructed as a product of a real non - negative random variable @xmath179 and a uniformly distributed random phase @xmath180 .",
    "when one knows the probability density function for the radial variable @xmath179 , one can easily derive the probability density for @xmath75 on the complex plane .",
    "isotropic random matrices are constructed in a way that imitates this construction .",
    "a random matrix @xmath181 is called isotropic if the probability measure @xmath182 is invariant under the left and right multiplication by unitary matrices @xmath183 : @xmath184 . in math and engineering community such random matrices",
    "are called bi - unitarily invariant ( bui ) and in general they can be rectangular .",
    "here we concentrate on square matrices and use the name isotropic in reference to them .",
    "the simplest way of constructing isotropic random matrices is to build them from real semi - positive diagonal random matrices @xmath2 and haar unitary matrices @xmath7 independent of @xmath2 ( free of @xmath2 for @xmath0 ) @xmath185 clearly , the diagonal matrix @xmath2 corresponds to the radial variable @xmath179 of @xmath186 and the haar unitary matrices @xmath187 and @xmath9 to the uniform phase @xmath151 .",
    "there are two of them to ensure the invariance under multiplication by a unitary matrix on both sides .",
    "alternatively one could consider a one - sided invariance , in which case the last equation would take the form @xmath188 .",
    "most of the results given below hold in either case .",
    "another way to construct such matrices is to define them by a probability measure of the form @xcite @xmath189 where @xmath190 is flat measure for @xmath4 complex matrices and @xmath191 is a polynomial or a power series in @xmath23 .",
    "there are many other ways of defining isotropic matrices .",
    "an interesting property of isotropic random matrices is that independently of the way they are defined , in the limit @xmath0 there is a one - to - one correspondence between the eigenvalue density of the matrix @xmath181 and the eigenvalue density of the hermitian matrix @xmath192 associated with @xmath181 @xcite . by construction",
    "the matrix @xmath192 is an invariant positive semi - definite random matrix .",
    "we denote the square root of this matrix by @xmath193 .",
    "note that the eigenvalues of @xmath2 correspond to singular values of @xmath181 .",
    "we can use the whole arsenal of methods discussed in the previous section to calculate the eigenvalue distribution of such matrices or their products .",
    "the correspondence between the eigenvalue distribution of a large isotropic matrix and the distribution of its singular values was found by feinberg and zee @xcite who applied field theoretical perturbative methods to solve the matrix model ( [ isov ] ) and independently by haagerup and larsen @xcite who used methods of free probability .",
    "below we quote the result in the form given by haagerup and larsen @xcite . in the terminology of free probability isotropic matrices in the limit",
    "@xmath0 correspond to variables that are called r - diagonal @xcite .",
    "here we prefer to call them large isotropic matrices .",
    "the invariance of the measure implies that the eigenvalue density of an isotropic matrix is invariant under rotation around the origin of the complex plane . for an isotropic matrix @xmath181 it is convenient to define radial cumulative density function as the probability that a random eigenvalue of the isotropic matrix lies on the complex plane within the distance @xmath23 from the origin : @xmath194",
    "the eigenvalue density is related to the radial cumulative function as @xmath195 where @xmath196 is a possible point mass located at the origin .",
    "it corresponds to the probability of finding zero eigenvalues in the eigenvalue spectrum of @xmath181 . for @xmath197",
    "the number of zero eigenvalues is a finite fraction of all eigenvalues .",
    "knowing @xmath198 one can calculate the density @xmath199 and vice versa . with the help of this function",
    "one can write an equation which relates the eigenvalue distributions of @xmath181 and @xmath193 @xcite @xmath200 for @xmath201 .",
    "this equation does not fix the value of the radial cumulative function for @xmath202 .",
    "it is fixed by an additional equation @xmath203 where @xmath204 is the cumulative eigenvalue density function for @xmath2 .",
    "this equation merely means that the number of zero eigenvalues of @xmath181 is equal to the number of zero eigenvalues of @xmath2 .",
    "the value @xmath205 is generically zero except the situation when there is a point measure ( dirac delta ) at zero in the eigenvalue density @xmath21 , as for instance in the distribution @xmath206 with @xmath207 , @xmath208 and the support being @xmath209 $ ] .",
    "this distribution naturally arises in the context of random matrices and it is called anti - wishart distribution in physics literature and free poissonian in math and engineering literature .",
    "the first term on the right hand side means that the fraction of zero eigenvalues of the corresponding random matrix @xmath2 is @xmath210 .",
    "the corresponding isotropic random matrix @xmath188 ` inherits ' all zero eigenvalues from @xmath2 and thus the corresponding fraction of zero eigenvalues of @xmath181 is also @xmath211 .",
    "equations ( [ hltheorem ] ) and ( [ hl2 ] ) provide an implicit relation between @xmath199 and @xmath21 that allows one to calculate one from another .",
    "a few comments are in order .",
    "equation ( [ hltheorem ] ) was first published in physical literature in a slightly different ( less transparent ) albeit equivalent form @xcite . in this paper",
    "it was also observed that for @xmath0 the support of the eigenvalue density of an isotropic random matrix has the shape of a single ring on the complex plane and that the radii of the ring can be derived from the eigenvalue density of @xmath2 .",
    "the external radius is equal to @xmath212 and the internal one to @xmath213 .",
    "the ring reduces to a disk when @xmath214 . in the paper",
    "@xcite the discussion was formalized and all statements were proven rigorously using concepts of free probability .",
    "in addition to that the s transform form of equation ( [ hltheorem ] ) and the discussion of the point measure for zero eigenvalues @xmath215 ( [ hl2 ] ) were given .",
    "from the discussion @xcite it follows that in general there are three different types of solutions for @xmath216 .",
    "the ring solution that corresponds to @xmath198 growing monotonically from @xmath217 to @xmath218 for @xmath219 $ ] and for @xmath220 , the disk solution that corresponds to @xmath198 growing monotonically from @xmath217 to @xmath218 for @xmath221 $ ] and the disk solution with a finite fraction of zero eigenvalues @xmath197 that corresponds to @xmath198 growing monotonically from @xmath222 to @xmath218 for @xmath221 $ ] .",
    "let us illustrate how the haagerup - larsen theorem ( [ hltheorem ] ) works in practice by giving an example .",
    "consider a random matrix @xmath181 from the ginibre ensemble @xcite .",
    "it is an @xmath223 random matrix whose elements are independent identically distributed , normally distributed , centered complex random variables .",
    "the probability measure for @xmath181 is @xmath224 where @xmath225 is flat measure for @xmath4 complex matrices .",
    "obviously @xmath181 is an isotropic random matrix .",
    "the limiting eigenvalue density for this matrix for @xmath0 is given by the uniform distribution on the unit disk @xcite @xmath226 it is zero outside the disk .",
    "the cumulative density @xmath227 is @xmath228 inserting it into equation ( [ hltheorem ] ) we obtain an equation for the s transform @xmath229 next we find ( [ s_chi ] ) @xmath230 , the moment generating function ( the inverse function for @xmath231 ) and the green s function ( [ phig ] ) @xmath232 finally we calculate the eigenvalue density of @xmath233 ( [ rhog ] ) @xmath234 \\ , \\ ] ] and correspondingly of @xmath2 @xmath235 \\ .\\ ] ] this is the density of singular values of the ginibre matrix .",
    "we see that it is given by the quarter - circle law .",
    "let us now discuss the product of @xmath236 independent isotropic matrices @xmath237 , @xmath238 , @xmath239 , @xmath240 @xmath241 where @xmath242 s are independent isotropic matrices @xcite . the goal is to calculate the eigenvalue density and the singular value density in the limit @xmath0 having the knowledge of eigenvalue densities for the matrices in the product . since the product itself is an isotropic matrix we can use equation ( [ hltheorem ] ) to write @xmath243 the s transform for @xmath244 can be calculated using the multiplication law ( [ sab ] ) @xmath245 since the right - hand side of this equation is a product of complex numbers , it does not depend on the order of multiplication .",
    "if instead of @xmath246 we considered a product of matrices permuted with a permutation @xmath247 @xmath248 we would obtain the s transform @xmath249 identical to @xmath250 because multiplication on the right hand side of ( [ paaa ] ) is commutative",
    ". therefore @xmath251 are equal for any permutation @xmath247 . in other words ,",
    "the product of isotropic matrices is spectrally commutative in the limit @xmath0 .",
    "isotropic random matrices possess a striking property that has no counterpart in classical probability .",
    "consider the product @xmath252 of independent identically distributed isotropic random matrices .",
    "this can be realized by picking up @xmath236 independent matrices from the same ensemble and multiplying them .",
    "it turns out that in the limit @xmath0 such a product has exactly the same eigenvalue density as the @xmath236-th power @xmath253 of one matrix picked up at random from this ensemble @xcite .",
    "actually it was already observed in @xcite that singular values of @xmath254 and @xmath246 are identically distributed .",
    "this observation can be trivially extended to eigenvalues if one additionally assumes that @xmath255 ( [ hl2 ] ) .",
    "this is a sort of spectral self - averaging of multiplication in the limit @xmath0 because a single matrix from the ensemble is sufficiently representative in the @xmath236-fold product to give the same result as @xmath236 independent random realizations .",
    "the proof is short so we recall it here in the form given in @xcite where it was tacitly assumed that @xmath255 .",
    "all constituents needed for this proof can be found already in @xcite .",
    "we assume that @xmath256 ( [ hl2 ] ) .",
    "the s transform for the product of independent identically distributed matrices is the @xmath236-th power of the s transform for a single one @xmath257 as follows from equation ( [ paaa ] ) in which all @xmath258 are replaced by @xmath259 . inserting @xmath260 in place of @xmath250 in equation ( [ hlp ] ) and taking the @xmath236-th root of both sides we get @xmath261 comparing the last equation to equation ( [ hltheorem ] )",
    "we see that @xmath262 .",
    "we can now argue that the radial cumulative density @xmath263 for the power @xmath254 is given by the same expression .",
    "indeed , using directly the definition of radial cumulative density we have @xmath264 for @xmath201 , and for @xmath265 for @xmath202 and hence @xmath266 .",
    "this completes the proof .",
    "if @xmath267 then the proof breaks down at @xmath202 . recall that @xmath222 is the probability of drawing at random a zero - eigenvalue from the spectrum of random matrix @xmath181 . the corresponding probability for the product of @xmath236 independent @xmath181 matrices",
    "is @xmath268 , while for the @xmath236-th power @xmath269 , so we see that @xmath270 for @xmath197 .",
    "in particular , one can use the product - power equivalence to calculate the eigenvalue density of the product @xmath271 of @xmath236 independent ginibre matrices in the limit @xmath0 . we know that @xmath272 for @xmath273 $ ] for one ginibre matrix ( [ fg ] ) thus for the product of @xmath236 @xmath274   \\ . \\label{ggg}\\ ] ] the eigenvalue density for the product is ( [ rhof ] ) @xmath275 and zero outside the unit circle .",
    "this calculation reproduces in a very simple way the result that was originally obtained by different methods @xcite .",
    "this result can be generalized also to products of rectangular gaussian matrices @xcite or products @xcite of wigner matrices @xcite with non - gaussian entries .",
    "one can also find the distribution of singular values for the product of ginibre matrices @xcite .",
    "inserting radial cumulative density function ( [ ggg ] ) to the haagerup - larsen formula ( [ hltheorem ] ) one can find the green s function for @xmath276 @xcite @xmath277 and calculate the density function @xmath278 by using ( [ rhog ] ) . for @xmath279",
    "it gives the wishart distribution ( [ wish ] ) ; for @xmath280 the distribution given in equation ( [ ww ] ) .",
    "one can find an explicit expression for any @xmath236 @xcite .",
    "the last step is to change variables @xmath281 to go from @xmath278 to @xmath282 .    to summarize , large isotropic random matrices are exceptional in many respects .",
    "there exists a one - to - one correspondence between the densities of eigenvalues and singular values @xcite .",
    "multiplication of independent isotropic matrices is spectrally commutative and self - averaging in the large @xmath1 limit @xcite .",
    "one can also show that if the eigenvalue density for an isotropic matrix has a power - law singularity at zero @xmath283 with @xmath284 , then the density of singular values behaves at zero as @xmath285 @xcite .",
    "so far we have discussed invariant and isotropic random matrices .",
    "we are now going to discuss the more general case of products of non - hermitian matrices .",
    "the multiplication law for non - hermitian matrices was derived in reference @xcite by field theoretical methods .    to build some intuition",
    "let us discuss gaussian non - hermitian random matrices .",
    "one can construct such matrices from independent identically distributed hermitian gaussian matrices from the gue ensemble . the probability measure for gue matrices",
    "is @xmath286 , where @xmath287 is flat measure for hermitian matrices .",
    "let us take two independent such matrices @xmath2 and @xmath3 .",
    "the following combination @xmath288 is a complex random matrix ; @xmath2 gives rise to hermitian sector of @xmath289 and @xmath290 to the anti - hermitian one .",
    "the resulting matrix @xmath289 is a ginibre random matrix @xcite with the uniform eigenvalue distribution on the unit disk ( [ ginibre ] ) .",
    "one can also define elliptic random matrices @xcite @xmath291 being linear combinations of hermitian and anti - hermitian random matrices with different coefficients controlled by a mixing parameter @xmath292 . for @xmath293",
    "the random matrix @xmath289 reduces to the hermitian matrix @xmath2 , for @xmath294 to the ginibre matrix and for @xmath295 to the anti - hermitian matrix @xmath290 .",
    "the eigenvalue density of the matrix @xmath289 is constant on the support being an ellipse whose oblateness depends on @xmath292 .",
    "the probability measure for matrix @xmath289 can be calculated from the measure @xmath296 that factorizes since @xmath2 and @xmath3 are independent .",
    "changing variables to @xmath297 and @xmath298 one finds the probability measure for @xmath289 @xcite @xmath299 where @xmath300 . for",
    "this measure one can calculate two - point correlation functions @xmath301 .",
    "there are four such functions  : @xmath302 that can be compactly written in the matrix form @xmath303 the matrix on the right hand side of the last equation defines the correlation structure of the model @xcite .",
    "it plays an important role , as we shall see below .",
    "the parameter @xmath304 takes values between @xmath305 and @xmath218 .",
    "for ginibre matrix it is @xmath217 , and for gue it is @xmath218 .    without",
    "going into details we quote the law of non - hermitian matrix multiplication and refer the interested reader to @xcite .",
    "we present it in the r transform form ( [ rprod ] ) . the main difference as compared to the hermitian case ( [ rprod ] ) is that the r transform is not a complex function but a quaternionic one .",
    "we denote quaternions by calligraphic letters .",
    "the r transform maps quaternions @xmath306 onto quaternions @xmath307 .",
    "the multiplication law reads @xmath308^l",
    "\\left[{\\cal r}_b({\\cal g}_a)\\right]^r \\ , \\\\",
    "\\left[{\\cal g}_a\\right]^r   & = { \\cal g}_{ab } \\left[{\\cal r}_a({\\cal g}_b)\\right]^l \\ , \\\\",
    "\\left[{\\cal g}_b\\right]^l   & =           \\left[{\\cal r}_a({\\cal g}_b)\\right]^r { \\cal g}_{ab } \\ .",
    "\\end{split } \\label{rab}\\ ] ] here @xmath309 , @xmath310 and @xmath311 correspond to generalized quaternionic green s functions for @xmath181 , @xmath312 and @xmath313 .",
    "they have the structure : @xmath314 where @xmath315 and @xmath316 are complex functions .",
    "we suppressed the indices of the corresponding matrix ( @xmath181 , @xmath312 or @xmath313 ) in the last equation .",
    "the density is related to the upper left element @xmath316 of the generalized quaternionic green s function @xmath317 the superscripts @xmath318 and @xmath319 refer to the left and right adjoint actions of the following unitary matrix @xmath320 on matrices in the square brackets @xmath321^l = uxu^\\dagger \\ , \\quad   [ x]^r = u^\\dagger x u   \\ . \\label{lr}\\ ] ] the diagonal elements of @xmath26 are constructed from @xmath75 being the argument of the green s functions ( [ qgz ] ) .",
    "the generalized r transform is related to the green s function by an equation analogous to ( [ gr ] ) @xmath322 where @xmath323 this law looks complicated but in practice it reduces to a set of algebraic equations for @xmath316 from which one can calculate the eigenvalue density by taking the derivative with respect to @xmath324 ( [ elec ] ) . before we give an example let us mention an electrostatic analogy @xcite",
    ". in this analogy eigenvalues of a random matrix represent positions of charges in two - dimensions in the given potential , the function @xmath316 is interpreted as the electric field @xmath325 with components @xmath326 and @xmath327 and equation ( [ elec ] ) as the gauss law in two dimensions @xcite .",
    "it takes a more familiar form when written in the components of @xmath328 : @xmath329 we now illustrate how to use the multiplication law ( [ rab ] ) to calculate the eigenvalue density of the product .",
    "we consider as an example the multiplication of gaussian matrices constructed from the centered elliptic matrix @xmath289 ( [ mux ] ) by shifting and rescaling @xmath330 the scale parameter @xmath331 is a real number and the shift parameter @xmath332 is a complex number .",
    "the quaternionic r transform for @xmath181 is @xmath333 there are only two terms on the right - hand side because the matrix is gaussian and thus all higher order cumulants vanish ( [ r ] ) . the second term on the right - hand side is directly related to the matrix on the right hand side of equation ( [ tau ] ) that defines the two - point correlation structure of the model @xcite .",
    "the simplest example is @xmath334 , @xmath335 and @xmath336 ( [ aqs ] ) .",
    "it corresponds to the ginibre matrix .",
    "let us calculate the eigenvalue density for the product of two such matrices .",
    "the first equation in the multiplication law ( [ rab ] ) gives @xmath337 we used a shorthand notation @xmath338 .",
    "because @xmath181 and @xmath312 are identically distributed , we search a symmetric solution @xmath339 and @xmath340 . @xmath341",
    "now we can use the two remaining equations ( [ rab ] ) . because of the symmetry it is enough to use only one of them , for example the first one . replacing @xmath342 by @xmath343 ( [ gr ] )",
    "we can write this equation as @xmath344^r   = \\left[{\\cal r}_a({\\cal g}_b)\\right]^l \\ .\\ ] ] we can now eliminate @xmath345 in the last equation using ( [ raa ] ) .",
    "writing also @xmath346^r$ ] and @xmath347^l$ ] in the explicit matrix form we have @xmath348 where @xmath338 , as before .",
    "it is a set of equations for @xmath349 and @xmath350 .",
    "it has a trivial solution @xmath351 and a non - trivial one @xmath352 and @xmath353 .",
    "the two solutions coincide at the unit circle @xmath354 .",
    "the trivial solution holds for @xmath355 and the nontrivial one for @xmath356 .",
    "note that for both of them @xmath352 .",
    "inserting these solutions to ( [ raa ] ) we obtain @xmath345 and then using ( [ gr ] ) we derive the final result for the generalized green s function of the product @xmath357 inside the unit circle @xmath358 , and @xmath359 outside . applying the gauss law ( [ elec ] ) to the upper left element of @xmath360 ( denoted by @xmath361 ) we find the density @xmath362 for @xmath358 , and @xmath363 otherwise .",
    "the calculations were done for @xmath364 .",
    "one , however , ( quite surprisingly ) obtains the same result for the product of matrices with arbitrary @xmath365 and @xmath366 @xcite .",
    "the reason for this is the following .",
    "looking at the r transform ( [ rqs ] ) we see that @xmath304 appears only in the combination @xmath367 ( or , writing it separately for @xmath181 and @xmath312 , in combinations @xmath368 and @xmath369 ) .",
    "the dependence on @xmath304 s disappears for @xmath370 . since in the solution discussed above we had @xmath370 , we conclude that this solution is independent of @xmath365 and @xmath366 and thus it holds for any @xmath365 and @xmath366 . in particular , the product @xmath313 of two hermitian gue matrices ( @xmath371 ) or any elliptic random matrices has exactly the same eigenvalue density ( [ rab ] ) , which is spherically symmetric .",
    "\\(a )   where @xmath372 and @xmath373 are independent standardized ginibre matrices , each having the eigenvalue density uniformly distributed on the unit circle .",
    "the result is derived analytically @xcite .",
    "the horizontal axes correspond to the real and imaginary axes of the complex plane and the vertical one to the value of the eigenvalue density @xmath374 .",
    "the eigenvalue density has a support surrounded by a contour given by the pascal s limaon .",
    "( b ) solid line represents the pascal s limaon .",
    "dots correspond to eigenvalues collected for ten matrices of size @xmath375 generated by monte - carlo simulations .",
    "a few eigenvalues lie outside the limiting contour but this effect is expected by finite size analysis .",
    "the number of outliers decreases when the matrix size increases .",
    "[ 1x1x ] , title=\"fig:\",scaledwidth=35.0% ] ( b )   where @xmath372 and @xmath373 are independent standardized ginibre matrices , each having the eigenvalue density uniformly distributed on the unit circle .",
    "the result is derived analytically @xcite .",
    "the horizontal axes correspond to the real and imaginary axes of the complex plane and the vertical one to the value of the eigenvalue density @xmath374 .",
    "the eigenvalue density has a support surrounded by a contour given by the pascal s limaon .",
    "( b ) solid line represents the pascal s limaon .",
    "dots correspond to eigenvalues collected for ten matrices of size @xmath375 generated by monte - carlo simulations .",
    "a few eigenvalues lie outside the limiting contour but this effect is expected by finite size analysis .",
    "the number of outliers decreases when the matrix size increases .",
    "[ 1x1x ] , title=\"fig:\",scaledwidth=50.0% ]    in a similar way one can find the eigenvalue density for the product of matrices with non - zero constants @xmath332 ( [ aqs ] ) but the calculations are tedious . in figure",
    "[ 1x1x].(a ) we show an analytic result for the eigenvalue density for @xmath376 where @xmath372 and @xmath373 are independent ginibre matrices @xcite .",
    "the eigenvalue support is surrounded by a contour @xmath377 that corresponds to the the pascal s limaon . in figure [ 1x1x].(b ) we compare this theoretical prediction to monte carlo simulations of large , finite matrices .",
    "the agreement is very good . as another example , in figure [ 1x1h ] we show a comparison between monte carlo results and the analytic prediction for the contour of the support for the eigenvalue density of the product @xmath378 , where @xmath379 is the gue hermitian matrix and @xmath289 is the ginibre matrix .",
    "again the comparison shows a good agreement .",
    "the details of the calculations and other examples can be found in @xcite .     where @xmath289 is a standardized ginibre matrix and @xmath379 is an independent standardized hermitian gue matrix .",
    "the curves forming the contour are calculated analytically @xcite using the multiplication law ( [ rab ] ) .",
    "the extrapolation of these curves outside the support is shown in red dots .",
    "black dots correspond to eigenvalues collected for ten matrices of size @xmath375 generated by monte - carlo simulations .",
    "[ 1x1h ] , scaledwidth=50.0% ]    we summarize this section shortly by emphasizing that there exists an algorithm to calculate eigenvalue densities for products of non - hermitian matrices .",
    "this algorithm works for large random matrices ( @xmath0 ) with probability measures of the type @xmath380 with a self - adjoint potential @xmath381 which is bounded from below @xcite .",
    "using free probability one can find an explicit formula for the moment generating function for the product of invariant random hermitian matrices in the limit @xmath0 .",
    "this formula allows to calculate trace moments @xmath382 for independent ( free ) random matrices @xmath383 and to determine the eigenvalue density of the matrix @xmath384 ( if @xmath2 is positive semi - definite ) from eigenvalue densities of @xmath2 and @xmath3 .",
    "we discussed how to extend the formalism to non - hermitian matrices to calculate the eigenvalue density of the product @xmath121 , which is generically a non - hermitian matrix .",
    "the extension has been worked out using field theoretical methods of planar graphs enumeration .",
    "the multiplication law ( [ rab ] ) is conveniently written in the r transform form ( [ rprod ] ) .",
    "the r transform is a quaternionic function .",
    "one can use this law to find eigenvalue densities for products of large non - hermitian random matrices .",
    "isotropic matrices are a special class of non - hermitian random matrices .",
    "these matrices have two exceptional features as far as matrix multiplication is concerned .",
    "isotropic random matrices are spectrally commutative and self - averaging in the limit @xmath0 .",
    "the first notion means that the eigenvalue distribution of the product of such matrices does not depend on the order of matrix multiplication .",
    "for example , the matrix @xmath385 has the same eigenvalue density as @xmath386 .",
    "the second one means that the product of @xmath236 independent isotropic identically distributed matrices has the same eigenvalue distribution as the @xmath236-th power of a single matrix .",
    "we finish by mentioning that recently a progress has been also made in the understanding of microscopic properties of eigenvalues statistics for products of random matrices .",
    "for example , an explicit form of the joint probability distribution for eigenvalues and singular values of the product of ginibre matrices has been explicitly found @xcite .",
    "using these results one can determine not only the eigenvalue density but also joint eigenvalue distribution and eigenvalue correlations for products of large random matrices .",
    "one can also infer finite size corrections to the limiting laws discussed in this paper .",
    "the author would like to thank romuald janik , andrzej jarosz , giacomo livan , maciej a. nowak , gabor papp , artur swiech and ismail zahed for many interesting discussions and a fruitful collaboration on the subject and jeremi ochab for critical reading of the manuscript .",
    "the author also wants to thank the organizers of the conference `` inference , computation , and spin glasses '' held in sapporo , july 28th30th 2013 , for a kind invitation to give a talk on this conference .",
    "the research presented in the paper was financed by grant no .",
    "dec-2011/02/a / st1/00119 of national centre of science in poland .",
    "the participation in the conference was supported by the grant : grant - in - aid for scientific research on innovative areas , mext , japan .",
    "99 a. crisanti , g. paladin and a. vulpiani , _ products of random matrices , random matrices and their applications _ , ( berlin , heidelberg : springer - verlag , 1993 ) .",
    "newman , _ commun .",
    "phys . _ * 103 * , 121 ( 1986 ) .",
    "r. r. mueller , _ ieee trans . inf .",
    "theor . _ * 48 * , 2086 ( 2002 ) .",
    "janik and w. wieczorek , _ j. phys . a : math .",
    "gen . _ * 37 * , 6521 ( 2004 ) .",
    "e. gudowska - nowak , r.a .",
    "janik , j. jurkiewicz , m.a .",
    "nowak and w. wieczorek 2010 , _ chem .",
    "phys . _ * 375 * , 380 ( 2010 ) .",
    "r. lohmayer , h. neuberger and t. wettig , _ jhep _ * 0905 * , 107 ( 2009 ) .",
    "b. collins , i. nechita and k. zyczkowski , _ j. phys .",
    "a : math . theor . _ * 43 * , 275303 ( 2010 ) .",
    "bouchaud , l. laloux , m.a .",
    "miceli and m. potters m , _ epj b _ * 2 * , 201 ( 2007 ) .",
    "p. bougerol and j. lacroix j , _ products of random matrices with applications to schrdinger operators _ ( boston : birkjuser , 1985 ) .",
    "j. e. cohen , h. kesten and c.m .",
    "newman ( eds ) , _ random matrices and their applications , contemporary mathematics _ * 50 * , ( providence , ri : american mathematical society , 1986 ) .",
    "h. furstenberg and h. kesten , _ ann . math .",
    "statist . _",
    "* 31 * , 457 ( 1960 ) . v. i. oseledec ,",
    "moscow math .",
    "* 19 * , 197 ( 1968 ) .",
    "voiculescu , _ invent .",
    "math . _ * 104 * , 201 ( 1991 ) .",
    "r. speicher , _ math .",
    "ann . _ * 298 * , 611 ( 1994 ) .",
    "voiculescu , k.j .",
    "dykema and a. nica , _ free random variables , crm monograph series _ * 1 * , ( providence , ri : american mathematical society , 1992 ) .",
    "voiculescu , _ j. funct",
    "* 66 * , 323 ( 1986 ) .",
    "voiculescu , _ j. operator theory _ * 18 * , 223 ( 1987 ) .",
    "e. brezin , c. itzykson , g. parisi and j .- b .",
    "zuber , _ commun .",
    "phys . _ * 59 * , 35 ( 1978 ) .",
    "d. bessis , c. itzykson and j .- b .",
    "zuber , _ adv .",
    "_ * 1 * , 109 ( 1980 )",
    ". g. t hooft , _ nucl .",
    "b _ * 72 * , 461 ( 1974 ) .",
    "z. burda , r.a .",
    "janik and m.a .",
    "nowak , _ phys .",
    "e _ * 84 * , 061125 ( 2011 ) .",
    "mehta , _ random matrices _ ,",
    "( amsterdam : elsevier 2004 ) .",
    "g. akemann , j. baik and p. di francesco ( eds ) _ the oxford handbook of random matrix theory _ ,",
    "( oxford : oxford university press , 2011 ) .",
    "f. j. dyson , _",
    "phys . _ * 3 * , 140 ( 1962 ) .",
    "a. nica and r. speicher , _ lectures on the combinatorics of free probability , london mathematical society lecture note series _ * 335 * , ( cambridge : cambridge university press , 2006 ) .",
    "a. zee , _ nucl .",
    "b _ * 474 * , 726 ( 1996 ) .",
    "h. bercovici and v. pata , _ math .",
    "_ * 2 * , 791 ( 1995 ) .",
    "n. r. rao and r. speicher , _ elect .",
    "comm . in probab . _",
    "* 12 * , 248 ( 2007 ) .",
    "j. wishart , _ biometrika _ 20a(1 - 2 ) , 32 ( 1928 ) .",
    "z. burda , r.a .",
    "janik and b. waclaw , _ phys .",
    "e _ * 81 * , 041132 ( 2010 ) .",
    "z. burda , m.a .",
    "nowak and a. swiech , _ phys .",
    "rev . e _ * 86 * , 061137 ( 2012 ) .",
    "j. feinberg and a. zee , _ nucl .",
    "b _ * 501 * , 643 ( 1997 ) .",
    "u. haagerup and f. larsen , _",
    "* 176 * , 331 ( 2000 ) .",
    "a. nica and r. speicher , _ fields institute communications _ * 12 * , 149 ( 1997 ) .",
    "z. burda , g. livan and a. swiech , _ phys . rev .",
    "e _ * 88 * , 022107 ( 2013 ) .",
    "j. ginibre , _ j. math",
    "_ * 6 * , 440 ( 1965 ) .",
    "b.a . khoruzhenko and h .- j .",
    "sommers , _ non - hermitian random matrix ensembles _ , chapter 18 in reference @xcite ( preprint arxiv:0911.5645 ) .",
    "z. burda , a. jarosz , g. livan , m.a .",
    "nowak and a. swiech , _ phys .",
    "e _ * 82 * , 061114 ( 2010 ) .",
    "e. wigner e , _ ann . of math . _ * 62 * , 548 ( 1955 ) .",
    "n. alexeev , f. goetze and a. tikhomirov a , _ lith .",
    "j. _ * 50 * , 121 ( 2010 ) .",
    "s. orourke and a. soshnikov , _ electron .",
    "j. probab . _",
    "* 16 * , 81 ( 2011 ) .",
    "k.a . penson and k. zyczkowski , _ phys",
    "e _ * 83 * , 061118 ( 2011 ) .",
    "girko , _ theor .",
    "_ * 29 * , 694 ( 1985 ) .",
    "fyodorov , b.a .",
    "khoruzhenko and h .- j .",
    "sommers , _ phys . lett . a _ * 226 * 46 ( 1997 ) .",
    "sommers , a. crisanti , h. somplinsky and y. stein , _ phys .",
    "_ * 60 * , 1895 ( 1988 ) .",
    "a. swiech , _ applications of generalized free addition and multiplication laws to large non - hermitian random matrices _ , ( msc thesis , jagiellonian university , cracow 2013 ) .",
    "g. akemann and z. burda , _ j. phys . a : math .",
    "* 45 * , 465201 ( 2012 ) .",
    "g. akemann , m. kieburg and l. wei , _ j. phys .",
    "a : math . theor .",
    "_ * 46 * , 275205 ( 2013 ) ."
  ],
  "abstract_text": [
    "<S> we review methods to calculate eigenvalue distributions of products of large random matrices . </S>",
    "<S> we discuss a generalization of the law of free multiplication to non - hermitian matrices and give a couple of examples illustrating how to use these methods in practice . </S>",
    "<S> in particular we calculate eigenvalue densities of products of gaussian hermitian and non - hermitian matrices including combinations of gue and ginibre matrices . </S>"
  ]
}