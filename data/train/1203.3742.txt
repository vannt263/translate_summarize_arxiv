{
  "article_text": [
    "many optimization problems arising in engineering and economics can conveniently be formulated as _",
    "separable convex programming problems _ ( sepcps ) .",
    "particularly , optimization problems related to a network @xmath0 of @xmath1 agents , where @xmath2 denotes the set of nodes and @xmath3 denotes the set of edges in the network , can be cast into separable convex optimization problems .",
    "several applications can be found in the literature such as distributed control , network utility maximization , resource allocation , machine learning and multistage stochastic convex programming @xcite .",
    "problems of moderate size or possessing a sparse structure can be solved by standard optimization methods in a centralized setup . however , in many real applications we meet problems , which may not be suitable to solve by standard optimization approaches or exploiting problem structures , e.g. nonsmooth separate objective functions , dynamic structure or distributed information . in those situations , decomposition methods can be considered as an appropriate framework to tackle those problems . particularly , lagrangian dual decomposition techniques are widely used to decompose a large - scale separable convex optimization problem into smaller subproblem components , which can simultaneously be solved in a _ parallel manner _ or in a _ closed form_.    various approaches have been proposed to solve ( sepcp ) in decomposition framework .",
    "one class of algorithms is based on lagrangian relaxation and subgradient - type methods of multipliers @xcite .",
    "it has been observed that subgradient methods are usually slow and numerically sensitive to the choice of step sizes in practice @xcite .",
    "the second approach relies on augmented lagrangian functions , see e.g. @xcite .",
    "many variants were proposed to process the inseparability of the crossproduct terms in the augmented lagrangian function in different ways .",
    "another research direction is based on alternating direction methods which were studied , for example , in @xcite .",
    "alternatively , proximal point - type methods were extended to the decomposition framework , see , e.g. @xcite .",
    "other researchers employed interior point methods in the framework of decomposition such as @xcite .    in this paper , we follow the same line of the dual decomposition framework but in a different way . first , we smooth the dual function by using self - concordant barriers . by an appropriate choice of the smoothness parameter ,",
    "we show that the dual function of the smoothed problem is an approximation of the original dual function .",
    "then , we develop a new path - following gradient method for solving the smoothed dual problem . by strong duality",
    ", we can also recover an approximate solution for the original problem .",
    "compared to the previous related methods mentioned above , the new approach has the following advantages .",
    "first , since a self - concordant barrier function only depends on its barrier parameter , this allows us to avoid a dependency on the diameter of the feasible set as in prox - function smoothing techniques @xcite .",
    "second , the proposed method is a gradient - type scheme which allows to handle more general classes of problems than in path - following newton methods @xcite , in particular the nonsmoothness of the objective function .",
    "third , by smoothing via self - concordant barrier functions , if the objective function is smooth then instead of solving the primal subproblems as general convex programs we can treat them by using optimality conditions which are equivalent to solving nonlinear systems . finally , by convergence analysis , we provide an adaptive update for all the algorithmic parameters which still ensure the convergence of the new methods .",
    "0.2 cm _ contribution .",
    "_ the contribution of the paper can be summarized as follows :    * we propose to use a smoothing technique via barrier function to smooth the dual function of ( sepcp ) as in @xcite .",
    "however , we provide a new estimate for the dual function , see lemma [ le : barrier_smooth ] . *",
    "we propose a new path - following gradient - based decomposition algorithm , algorithm [ alg : gradient_method ] , to solve ( sepcp ) .",
    "this algorithm allows one to solve the subproblem of each component in parallel .",
    "moreover , all the algorithmic parameters are updated automatically without using any tuning strategy .",
    "* we prove the convergence of the algorithm and estimate its local convergence rate .",
    "* we modify the algorithm by applying nesterov s accelerating scheme to obtain a new variant , algorithm [ alg : fast_grad_alg ] , which possesses a convergence rate , i.e. @xmath4 , where @xmath5 is a given accuracy .",
    "let us emphasize the following points .",
    "the new estimate of the dual function considered in this paper is different from the one in @xcite which does not depend on the diameter of the feasible set of the dual problem .",
    "the worst case complexity of the second algorithm is @xmath4 which is much higher than in subgradient - type methods of multipliers @xcite .",
    "we notice that this convergence rate is optimal in the sense of nesterov s optimal schemes @xcite for this class of algorithms .",
    "moreover , we can choose smoothness parameter to adjust this convergence rate .",
    "all the algorithms can be implemented in a _",
    "parallel manner_.    0.2 cm _ outline . _",
    "the rest of this paper is organized as follows . in the next section , we state the problem formulation and review the lagrangian dual decomposition framework .",
    "section [ sec : dual_smooth ] considers a smoothing technique via self - concordant barriers and provides an estimate for the dual function .",
    "the new algorithms and their convergence analysis are presented in sections [ sec : gradient_method ] and [ sec : fast_grad_method ] .",
    "preliminarily numerical results are shown in the last section to verify our theoretical results .",
    "0.2 cm _ notation and terminology .",
    "_ throughout the paper , we work on the euclidean space @xmath6 endowed with an inner product @xmath7 for @xmath8 and the norm @xmath9 . for a proper , lower semi - continuous convex function @xmath10",
    ", @xmath11 denotes the subdifferential of @xmath10 at @xmath12 .",
    "if @xmath10 is concave then we also use @xmath11 for its super - differential at @xmath12 . for any @xmath13 such that @xmath14 is positive definite ,",
    "the local norm of a vector @xmath15 with respect to @xmath10 at @xmath12 is defined as @xmath16^{1/2}$ ] and its dual norm is @xmath17^{1/2}$ ] .",
    "it is obvious that @xmath18 .",
    "the notation @xmath19 and @xmath20 define the sets of nonnegative and positive numbers , respectively .",
    "the function @xmath21 is defined by @xmath22 and its dual function @xmath23 is @xmath24 .",
    "a _ separable convex programming _ problem ( sepcp ) is typically written as follows : @xmath25 where the decision variable @xmath26 with @xmath27 , the function @xmath28 is concave and the feasible set is described by the set @xmath29 , with @xmath30 nonempty , closed , convex sets for all @xmath31 . matrix @xmath32 $ ] , with @xmath33 for @xmath34 , @xmath35 and @xmath36 .",
    "the constraint @xmath37 in is called _ coupling linear constraint _ , while @xmath38 is referred to as _ local constraints _ of the @xmath39-th component ( agent ) .",
    "let @xmath40 be the partial lagrangian function associated with the coupling constraint @xmath37 of .",
    "the dual problem of is written as : @xmath41 where @xmath42 is the dual function defined by : @xmath43 due to the separability of @xmath44 , the dual function @xmath42 can be computed _ in parallel _ as : @xmath45 throughout this paper , we make the following assumptions :    [ as : a1 ] the following assumptions hold , see @xcite :    * the solution set @xmath46 of is nonempty . *",
    "either @xmath47 is polyhedral or the following slater qualification condition holds : @xmath48 where @xmath49 is the relative interior of @xmath47 . * the functions @xmath50 , @xmath34 , are proper , upper semicontinuous and concave and @xmath51 is full - row rank .",
    "assumption * * a.[as : a1 ] * * is standard in convex optimization . under this assumption ,",
    "_ strong duality _ holds , i.e. the dual problem is also solvable and @xmath52 .",
    "moreover , the set of lagrange multipliers , @xmath53 , is bounded . however , under assumption * * a.[as : a1 ] * * , the dual function @xmath42 may not be differentiable .",
    "numerical methods such as subgradient - type and bundle methods can be used to solve . nevertheless , these methods are in general numerically intractable and slow .",
    "in many practical problems , the feasible sets @xmath54 , @xmath34 are usually simple , e.g. box , polyhedra and ball . hence , @xmath54 can be endowed with a _ self - concordant barrier _ ( see , e.g. @xcite ) as in the following assumption .    [ as : a2 ] each feasible set @xmath54 , @xmath34 ,",
    "is bounded and endowed with a self - concordant barrier function @xmath55 with the parameter @xmath56 .",
    "note that the assumption on the boundedness of @xmath54 can be removed by assuming that the set of sample points generated by the new algorithm described below is bounded .",
    "[ re : as_a2 ] the theory developed in this paper can be easily extended to the case @xmath54 given as follows ( see @xcite ) for some @xmath57 : @xmath58 by applying the standard linear algebra routines , where the set @xmath59 has nonempty interior and associated with a @xmath60-self - concordant barrier @xmath55 .",
    "let us denote by @xmath61 the analytic center of @xmath54 , i.e. : @xmath62 where @xmath63 is the interior of @xmath54 .",
    "since @xmath54 is bounded , @xmath64 is well - defined @xcite .",
    "moreover , the following estimates hold : @xmath65 without loss of generality , we can assume that @xmath66 .",
    "otherwise , we can replace @xmath55 by @xmath67 for @xmath68 . since @xmath47 is separable , @xmath69 is a self - concordant barrier of @xmath47 with the parameter @xmath70 .",
    "let us define the following function : : @xmath71 where @xmath72 with @xmath73 being referred to as a smoothness parameter .",
    "note that the maximum problem in has a unique optimal solution , which is denoted by @xmath74 , due to the strict concavity of the objective function .",
    "we call this problem the",
    "_ primal subproblem_. consequently , the functions @xmath75 and @xmath76 are well - defined and smooth on @xmath77 for any @xmath73 .",
    "we call @xmath78 and @xmath79 the _ smoothed dual function _ of @xmath80 and @xmath42 , respectively .",
    "the optimality condition for is : @xmath81 let us define the full optimal solution @xmath82 .",
    "since problem is convex , this condition is necessary and sufficient for optimality .",
    "moreover , the gradients of @xmath83 and @xmath79 are given by : @xmath84 if @xmath85 is differentiable for some @xmath57 then the condition collapses to @xmath86 , which is indeed a _ system of nonlinear equations_. first , we prove that @xmath87 is an approximation of the dual function @xmath88 for sufficiently small @xmath89 .",
    "[ le : barrier_smooth ] suppose that assumptions * * a.[as : a1 ] * * and * * a.[as : a2 ] * * are satisfied .",
    "let @xmath90 be a strictly feasible point to , i.e. @xmath91 .",
    "then , for any @xmath89 , we have : @xmath92 moreover , it holds that : @xmath93^{1/2}.\\end{aligned}\\ ] ]    the first two inequalities in are trivial due to the definitions of @xmath88 , @xmath79 and the feasibility of @xmath90 .",
    "we only prove .",
    "indeed , since @xmath94 and @xmath95 , if we define @xmath96 , then @xmath97 if @xmath98 . by applying the inequality",
    "@xcite we have : @xmath99 using this inequality together with the definition of @xmath79 , the concavity of @xmath44 and @xmath100 , we deduce : @xmath101 by solving the maximization problem on the right hand side of and then rearranging the results , we obtain : @xmath102 +   t\\nu\\big[\\ln\\big(\\frac{g(y ) - \\phi(\\bar{x})}{t\\nu}\\big)\\big]_{+},\\ ] ] where @xmath103_{+ } : = \\max{\\left\\{\\cdot , 0\\right\\}}$ ] .",
    "moreover , it follows from that : @xmath104",
    "\\nonumber\\\\ & \\leq \\frac{1}{\\tau}\\big[g(y;t)-\\phi(\\bar{x } ) + tf(\\bar{x})\\big ] + \\frac{t\\nu}{1-\\tau}. \\nonumber\\end{aligned}\\ ] ] if we minimize the right hand side of this inequality in @xmath105 , then we get @xmath106 ^ 2 $ ] .",
    "finally , we plug this inequality into to obtain : @xmath107}{t\\nu}}\\right )   + tf(\\bar{x } ) \\\\ & \\leq g(y;t ) + t\\nu + tf(\\bar{x } ) + 2\\sqrt{t\\nu}\\left[g(y;t)-\\phi(\\bar{x } ) + tf(\\bar{x})\\right]^{1/2 } , \\end{aligned}\\ ] ] which is indeed .",
    "@xmath108    [ re : epsilon_gap ] it follows from that @xmath109 .",
    "hence , @xmath110 as @xmath111",
    ". moreover , this estimate is different from the one in @xcite , since we do not assume that @xmath112 is bounded .",
    "next , we consider the following minimization problem , called _ smoothed dual problem _ : @xmath113 we denote by @xmath114 the solution of .",
    "the following lemma shows the main properties of the functions @xmath115 and @xmath116 .",
    "[ le : properties_of_d ] suppose that assumptions * * a.[as : a1 ] * * and * * a.[as : a2 ] * * are satisfied . then :    * the function @xmath115 is convex and nonincreasing in @xmath20 for a given @xmath117 . moreover , we have : @xmath118 * the function @xmath116 defined by is differentiable and nonincreasing in @xmath20 .",
    "moreover , @xmath119 , @xmath120 and @xmath121 is feasible to the original problem .",
    "we only prove , the proof of the remainders can be found in @xcite .",
    "indeed , since @xmath115 is convex and differentiable and @xmath122 , we have @xmath123 .",
    "@xmath108    the statement ( b ) of lemma [ le : properties_of_d ] shows that if we find an approximate solution @xmath124 for for sufficiently small @xmath125 , then @xmath126 approximates @xmath127 ( recall that @xmath52 ) and @xmath128 is approximately feasible to .",
    "in this section we design a path - following gradient algorithm to solve the dual problem , analyze the convergence of the algorithm and estimate the local convergence rate .",
    "since @xmath79 is strictly convex and smooth , we can write the optimality condition of as : @xmath129 this equation has a unique solution @xmath114 .    now , for any given @xmath130",
    ", @xmath131 is positive definite .",
    "we introduce a local matrix norm : @xmath132 the following lemma shows a main property of the function @xmath87 .",
    "[ le : lipschitz_type ] suppose that assumptions * * a.[as : a1 ] * * and * * a.[as : a2 ] * * are satisfied",
    ". then , for all @xmath73 and @xmath133 , one has : @xmath134^t(y   - \\hat{y } ) \\geq \\frac{t{\\vert\\nabla{g}(y;t ) - \\nabla{g}(\\hat{y};t)\\vert}_2 ^ 2}{c_a \\left [ c_a + { \\vert\\nabla{g}(y , t ) - \\nabla{g}(\\hat{y};t)\\vert}_2\\right]},\\ ] ] where @xmath135 .",
    "consequently , it holds that : @xmath136 provided that @xmath137 .    for notational simplicity ,",
    "we denote by @xmath138 and @xmath139 . from the definition of @xmath140 and the cauchy - schwarz inequality we have : @xmath141^t(y-\\hat{y } ) = ( y-\\hat{y})^ta(x^ { * }   - \\hat{x}^ { * } ) .",
    "\\label{eq : lm31_est1}\\\\ & { \\vert\\nabla{g}(\\hat{y};t ) -   \\nabla{g}(y;t)\\vert}_2   \\leq { \\vert\\!\\verta\\vert\\!\\vert}^{*}_{x^{*}}{\\vert\\hat{x}^{*}- x^{*}\\vert}_{x^{*}}.\\label{eq : lm31_est2}\\end{aligned}\\ ] ] it follows from that @xmath142 - [ \\xi(x^ { * } ) - \\xi(\\hat{x}^{*})]$ ] , where @xmath143 . by multiplying this relation with @xmath144 and then using ( * ? ? ?",
    "* theorem 4.1.7 ) and the concavity of @xmath44 we obtain : @xmath145^t(x^ { * } - \\hat{x}^ { * } ) - [ \\xi(x^ { * } ) - \\xi(\\hat{x}^{*})]^t(x^ { * } - \\hat{x}^{*})\\nonumber\\\\ & \\overset{\\tiny\\textrm{concavity of}~\\phi}{\\geq } t[\\nabla{f}(x^ { * } ) - \\nabla{f}(\\hat{x}^{*})]^t(x^ { * } - \\hat{x}^{*})\\nonumber\\\\ & \\geq \\frac{t{\\vertx^ { * } - \\hat{x}^{*}\\vert}_{x^{*}}^2}{1 + { \\vertx^ { * } - \\hat{x}^{*}\\vert}_{x^{*}}}\\nonumber\\\\ & \\overset{\\tiny\\eqref{eq : lm31_est2}}{\\geq}\\frac{t\\left[{\\vert\\nabla{g}(y;t ) - \\nabla{g}(\\hat{y};t)\\vert}_2\\right]^2}{{\\vert\\!\\verta\\vert\\!\\vert}^{*}_{x^ { * } } \\left[{\\vert\\!\\verta\\vert\\!\\vert}^{*}_{x^ { * } } + { \\vert\\nabla{g}(y;t ) - \\nabla{g}(\\hat{y};t)\\vert}_2\\right]}. \\nonumber\\end{aligned}\\ ] ] substituting this inequality into we obtain .    by the cauchy - schwarz inequality",
    ", it follows from that @xmath146 , provided that @xmath147 . finally , by using the mean - value theorem",
    ", we have : @xmath148 which is indeed provided that @xmath137 .",
    "@xmath108    now , we describe one step of the path - following gradient method for solving .",
    "let us assume that @xmath117 and @xmath73 are the values at the current iteration , the values @xmath149 and @xmath150 at the next iteration are computed as : @xmath151 where @xmath152 is the current step size and @xmath153 is the decrement of the parameter @xmath154 .",
    "in order to analyze the convergence of the scheme , we introduce the following notation : @xmath155 first , we prove an important property of the _ path - following gradient scheme _ .",
    "[ le : gradient_method ] under assumptions * * a.[as : a1 ] * * and * * a.[as : a2 ] * * , the following inequality holds : @xmath156,\\ ] ] where @xmath157 and @xmath158 are defined by .",
    "since @xmath159 , by using with @xmath154 and @xmath150 , we have : @xmath160 next , by we have @xmath161 and @xmath162 .",
    "hence , we can derive : @xmath163 by plugging into , we obtain .",
    "[ le : m_bound ] for any @xmath117 and @xmath89 , the constant @xmath164 is bounded . more precisely , @xmath165 .",
    "furthermore , @xmath166 is also bounded , i.e. : @xmath167 , where @xmath168 $ ] .    for any @xmath130 , from the definition of @xmath169",
    ", we have : @xmath170^{1/2 } ~:~ { \\vertv\\vert}_2 = 1\\right\\}\\\\ & = \\sup\\left\\ { { \\vertu\\vert}^{*}_x ~:~ u = a^tv , ~{\\vertv\\vert}_2 = 1\\right\\}\\\\ & \\leq \\sup \\left\\ { ( \\nu+2\\sqrt{\\nu}){\\vertu\\vert}^{*}_{x^c } ~:~ u = a^tv , ~{\\vertv\\vert}_2 = 1\\right\\}\\\\ & = ( \\nu+2\\sqrt{\\nu})\\sup \\left\\ { \\left[v^ta\\nabla^2f(x^c)^{-1}a^tv\\right]^{1/2 } , ~{\\vertv\\vert}_2 = 1\\right\\}\\\\ & = ( \\nu+2\\sqrt{\\nu}){\\vert\\!\\verta\\vert\\!\\vert}^{*}_{x^c}.\\end{aligned}\\ ] ] here , the inequality in this implication follows from ( * ? ? ?",
    "* corollary 4.2.1 ) . by substituting @xmath171 into the above inequality",
    ", we obtain the first conclusion . in order to prove the second bound",
    ", we note that @xmath172 .",
    "therefore , by using , we can estimate : @xmath173 which is the second conclusion .",
    "@xmath108    next , we show how to choose the step size @xmath174 and the decrement @xmath153 such that @xmath175 in lemma [ le : gradient_method ] .",
    "we note that @xmath176 is obtained by solving the subproblem and the quantity @xmath177 is nonnegative and computable . by lemma [ le : m_bound ] , we see that : @xmath178 which shows that @xmath179 is bounded away from zero .",
    "we have the following estimate .",
    "[ le : choice_of_stepsize ] the step size @xmath179 defined by satisfies : @xmath180    let @xmath181 .",
    "we can simplify this function as @xmath182 $ ] , where @xmath183 .",
    "the function @xmath184 for all @xmath15 and @xmath185 at @xmath186 which leads to @xmath187 .",
    "@xmath108    since @xmath159 , if we choose @xmath188}$ ] then : @xmath189 therefore , the update rule for @xmath154 can be written as : @xmath190 } \\in ( 0 , 1).\\ ] ]      combing the above analysis , we can describe the path - following gradient decomposition method is follows :    _ path - following gradient decomposition_[alg : gradient_method ] * initialization : *    * choose an initial value @xmath191 and tolerances @xmath192 and @xmath193 . *",
    "take an initial point @xmath194 and solve _ in parallel _ to obtain @xmath195 .",
    "* compute @xmath196 , @xmath197 , @xmath198 and @xmath199 .",
    "* iteration : *   for  @xmath200 , perform the following steps :    * _ step 1 : _ update the barrier parameter : @xmath201 , where @xmath202 .",
    "* _ step 2 : _ solve _ in parallel _ to obtain @xmath203 .",
    "then , form the gradient vector @xmath204 . * _ step 3 : _",
    "compute @xmath205 , @xmath206 , @xmath207 and @xmath208 . *",
    "_ step 4 : _ if @xmath209 and @xmath210 , then terminate . * _ step 5 : _ compute the step size @xmath211 . * _ step 6 : _ update @xmath212 as : @xmath213    the main step of algorithm [ alg : gradient_method ] is step 2 , where we need to solve in parallel the primal subproblems . to form the gradient vector @xmath214",
    ", one can compute in parallel by multiplying column - blocks @xmath215 of @xmath51 by the solution @xmath216 .",
    "this task only requires local information to be exchanged between the current node and its neighbors .    from the update rule of",
    "@xmath154 we can see that @xmath217 as @xmath218 .",
    "this happens when the barrier function is approaching the boundary of the feasible set @xmath47 .",
    "hence , the parameter @xmath154 is not decreased .",
    "let @xmath219 be a sufficiently large positive constant .",
    "we can modify the update rule of @xmath154 as : @xmath220 in this case , the sequence @xmath221 generated by algorithm [ alg : gradient_method ] might not converge to zero .",
    "moreover , the step size @xmath222 computed at step 5 depends on the parameter @xmath125 . if @xmath125 is small then algorithm [ alg : gradient_method ] makes short steps toward a solution of .",
    "let us assume that @xmath223 .",
    "then , the following theorem shows the convergence of algorithm [ alg : gradient_method ] .",
    "[ th : gm_convergence ] suppose that assumptions * * a.[as : a1 ] * * and * * a.[as : a2 ] * * are satisfied .",
    "suppose further that the sequence @xmath224 generated by algorithm [ alg : gradient_method ] satisfies @xmath225 .",
    "then : @xmath226 consequently , there exists a limit point @xmath227 of @xmath228 such that @xmath227 is a solution of at @xmath229 .",
    "it is sufficient to prove .",
    "indeed , from we have : @xmath230 since @xmath231 and @xmath232 due to lemma [ le : m_bound ] , the above inequality leads to : @xmath233 this inequality implies @xmath234 , which leads to @xmath235 . by definition of @xmath236",
    "we have @xmath237 .",
    "@xmath108    [ re : step_size ] from the proof of theorem [ th : gm_convergence ] , we can fix @xmath238 in algorithm [ alg : gradient_method ] .",
    "this value can be computed a priori .",
    "let us analyze the local convergence rate of algorithm [ alg : gradient_method ] .",
    "let @xmath239 be an initial point of algorithm [ alg : gradient_method ] and @xmath114 be the unique solution of .",
    "we denote by : @xmath240 for simplicity of discussion , we assume that the smoothness parameter @xmath125 is fixed at @xmath241 sufficiently small for all @xmath242 ( see lemma [ le : barrier_smooth ] ) . the convergence rate of algorithm [ alg : gradient_method ] in the case @xmath243 is stated in the following lemma .",
    "[ le : convergene_rate ] suppose that the initial point @xmath239 is chosen such that @xmath244 .",
    "then : @xmath245 consequently , the local convergence rate of algorithm [ alg : gradient_method ] is at least @xmath246 .",
    "let @xmath247 and @xmath248 .",
    "then @xmath249 .",
    "first , by the convexity of @xmath250 we have : @xmath251 this inequality implies : @xmath252 since @xmath253 is fixed for all @xmath242 , it follows from that : @xmath254 where @xmath255 and @xmath256 . by using the definition of @xmath257 ,",
    "the last inequality is equivalent to : @xmath258 next , since @xmath259 for all @xmath260 and @xmath261 due to lemma [ le : m_bound ] , it follows from and that : @xmath262 for all @xmath263 .",
    "let @xmath264 .",
    "since @xmath249 , implies : @xmath265 by induction , this inequality leads to @xmath266 which is equivalent to @xmath267 provided that @xmath268 .",
    "since @xmath269 , this inequality is indeed .",
    "the last conclusion follows from .",
    "let us fix @xmath270 .",
    "the function @xmath271 is convex and differentiable but its gradient is not lipschitz continuous , we can not apply nesterov s fast gradient algorithm @xcite to solve . in this section ,",
    "we modify nesterov s fast gradient method in order to obtain an accelerating gradient method for solving .",
    "one step of the modified fast gradient method is described as follows .",
    "let @xmath272 and @xmath273 be given points in @xmath274 , we compute new points @xmath149 and @xmath275 as follows : @xmath276 where @xmath277 is the step size , @xmath278 , @xmath279 and @xmath280 are three parameters which will be chosen appropriately .",
    "first , we prove the following estimate .    [ le : accelerating_scheme ] let @xmath281 be a given parameter and @xmath282 .",
    "we define two vectors : @xmath283 ~~\\textrm{and}~~ r_{+ } = r - \\rho\\nabla{g(v ; \\underline{t})}.\\ ] ] then the new point @xmath149 generated by satisfies : @xmath284 provided that @xmath285 , where @xmath248 and @xmath286 .    since @xmath287 and @xmath288",
    ", it follows from that : @xmath289 now , since @xmath290 for all @xmath291 , the inequality implies : @xmath292 provided that @xmath285 . for any @xmath293 and @xmath294",
    "we have : @xmath295 by substituting and the relation @xmath296 into we obtain : @xmath297 \\nonumber\\\\ & = ( 1 - \\theta)g(y;\\underline{t } ) + \\theta\\underline{g}^ { * } + \\frac{\\theta^2\\bar{c}_a^2 } { \\underline{t}}\\big[{\\vertr-\\underline{y}^{*}\\vert}_2 ^ 2   - { \\vertr_{+ } - \\underline{y}^{*}\\vert}_2 ^ 2\\big].\\end{aligned}\\ ] ] since @xmath298 , by rearranging we obtain .",
    "next , we consider the update rule of @xmath299 .",
    "we can see from that if @xmath300 is updated such that @xmath301 then @xmath302 .",
    "the above condition implies : @xmath303 the following lemma provides an estimate for @xmath242 .",
    "[ le : update_theta ] the sequence @xmath304 generated by @xmath305 $ ] and @xmath306 satisfies : @xmath307    we note that @xmath308 . if we define @xmath309 then the last relation implies @xmath310 , which leads to @xmath311 .",
    "hence , @xmath312 . by induction , we have @xmath313 .",
    "more over , @xmath306 , we have @xmath314 . substituting @xmath314 into the last inequalities and then using the relation @xmath315 we obtain .",
    "@xmath108    by lemma [ le : accelerating_scheme ] , we have @xmath316 and @xmath317 . from these relations",
    ", we deduce that : @xmath318 note that if we combine and then : @xmath319 this is the second line of , where @xmath320 , @xmath321 and @xmath322 . by combining all the above analysis",
    ", we can describe the modified fast gradient algorithm in detail as follows :    _ fast gradient decomposition algorithm_[alg : fast_grad_alg ] * initialization : *  perform the following steps :    * given a tolerance @xmath323 .",
    "fix the parameter @xmath154 at a certain value @xmath241 . *",
    "find an initial point @xmath194 such that @xmath324 . *",
    "set @xmath325 and @xmath326 .",
    "* iteration : *   for  @xmath327 , perform the following steps :    * _ step 1 : _ if @xmath210 then terminate . * _ step 2 : _ compute @xmath328 $ ] .",
    "* _ step 3 : _ update @xmath212 as : @xmath329 where @xmath330 . * _ step 4 : _ update @xmath331 $ ] . *",
    "_ step 5 : _ update @xmath332 where @xmath333 . * _ step 6 : _ solve _ in parallel _ to obtain @xmath334 .",
    "then form a gradient vector @xmath335 and compute @xmath336 .",
    "the core step of algorithm [ alg : fast_grad_alg ] is step 6 , where we need to solve @xmath1 primal subproblems in parallel .",
    "algorithm [ alg : fast_grad_alg ] differs from nesterov s fast gradient algorithm @xcite at step 5 , where @xmath337 not only depends on @xmath212 and @xmath338 but also on @xmath339 .",
    "the following theorem shows the convergence of algorithm [ alg : fast_grad_alg ] .",
    "[ th : fast_grad_convergence ] let @xmath194 be an initial point of algorithm [ alg : fast_grad_alg ] such that @xmath340 .",
    "then the sequence @xmath341 generated by algorithm [ alg : fast_grad_alg ] satisfies : @xmath342    from and the update rule of @xmath343 , we have : @xmath344 by induction , we obtain from this inequality that : @xmath345 for @xmath346 . since @xmath306 and @xmath347 , we have @xmath348 and the last inequality implies @xmath349 . since @xmath350 due to lemma [ le : update_theta ] , we obtain .",
    "let us denote by : @xmath351 it is obvious that @xmath352 .",
    "this set is a neighbourhood of the solution @xmath353 of the problem .",
    "[ re : complexity ] let @xmath323 be a given accuracy .",
    "if we fix the barrier parameter @xmath354 then the worst - case complexity of algorithm [ alg : fast_grad_alg ] in the neighbourhood @xmath355 is @xmath356 , where @xmath357 .",
    "( _ switching strategy_)[re : switching_variant ] we can combine algorithms [ alg : gradient_method ] and [ alg : fast_grad_alg ] to obtain a switching variant :    * first , we apply algorithm [ alg : gradient_method ] to find a point @xmath358 and @xmath241 such that @xmath359 . *",
    "then , we switch to use algorithm [ alg : fast_grad_alg ] .",
    "we can also replace the constant @xmath360 in algorithm [ alg : fast_grad_alg ] by any upper bound @xmath361 of @xmath362 .",
    "for instance , we can choose @xmath363 .",
    "in this section , we test the switching variant of algorithms [ alg : gradient_method ] and [ alg : fast_grad_alg ] proposed in remark [ re : switching_variant ] which we name by ` pfgda ` for solving the following convex programming problem : @xmath364 where @xmath365 , and @xmath366 is a convex function , @xmath367 , @xmath368 and @xmath369 such that @xmath370 .",
    "we note that the feasible set @xmath371 $ ] can be decomposed into @xmath372 intervals @xmath373 $ ] and each interval is endowed with a @xmath374-self concordant barrier @xmath375 for @xmath376 . moreover , if we define @xmath377 $ ] then @xmath44 is concave and separable .",
    "problem can be reformulated equivalently to .",
    "the smoothed dual function components @xmath378 of can be written as : @xmath379 for @xmath376 .",
    "this one - variable minimization problem is nonsmooth but it can be solved easily . in particular , if @xmath85 is affine then this problem can be solved in a _",
    "closed form_. in case @xmath85 is smooth , we can reformulate into a smooth convex program by adding @xmath372 slack variables and @xmath380 additional inequality constraints to handle the @xmath381 part .",
    "we have implemented ` pfgda ` in c++ running on a @xmath382 cores intel xeon @xmath383ghz workstation with @xmath384 gb of ram .",
    "the algorithm was parallelized by using ` openmp ` .",
    "we terminated ` pfgda ` if : @xmath385 we have also implemented two algorithms , namely _ decomposition algorithm with two primal steps _",
    "* algorithm 1 ) and _ decomposition algorithm with two dual steps _ in ( * ? ? ?",
    "* algorithm 1 ) which we named ` 2pdecompalg ` and ` 2ddecompalg ` , respectively , for solving problem and compared them with ` pfgda ` .",
    "we terminated ` 2pdecompalg ` and ` 2ddecompalg ` by using the same conditions as in @xcite with the tolerances @xmath386 and @xmath387 .",
    "we also terminated all three algorithms if the maximum number of iterations @xmath388 was reached . in the last case",
    "we clarify that the algorithm is failed .    0.2 cm * a. basis pursuit problem . * if the function @xmath389 for all @xmath12 then problem becomes a bound constrained basis pursuit problem to recover the sparse coefficient vector @xmath12 of given signals based on a transform operator @xmath51 and a vector of observations @xmath390 .",
    "we assume that @xmath391 , @xmath392 and @xmath393 , where @xmath394 and @xmath12 has @xmath395 nonzero elements ( @xmath396 .    in this case",
    ", we only illustrate ` pfgda ` by applying it to solve some small size test problems . in order to generate a test problem",
    ", we generate a random orthogonal matrix @xmath51 and a random vector @xmath397 which has @xmath395 nonzero elements .",
    "then we define vector @xmath390 as @xmath398 .",
    "we test ` pfgda ` on the four problems such that @xmath399 $ ] are @xmath400 $ ] , @xmath401 $ ] , @xmath402 $ ] and @xmath403 $ ] .",
    "the results reported by ` pfgda ` are plotted in figure [ fig : basis_pursuit ] .",
    "-0.5 cm        -0.5 cm    as we can see from these figures that the vector of recovered coefficients @xmath12 matches very well the vector of original coefficients @xmath397 in these four problems",
    ". moreover , ` pfgda ` requires @xmath404 and @xmath405 iterations , respectively in the four problems .    0.2 cm * b. nonlinear separable convex problems .",
    "* in order to test the performance of ` pfgda ` , we generate in this case a large test - set of problems and compare the performance of ` pfgda ` with ` 2pdecompalg ` and ` 2ddecompalg ` .",
    "the test problems were generated as follows .",
    "we chose the objective function @xmath406 , where @xmath407 is a given parameter for @xmath376 .",
    "matrix @xmath51 was generated randomly in @xmath408 $ ] and then was normalized by @xmath409 .",
    "we generated a sparse vector @xmath397 randomly in @xmath410 $ ] with the density @xmath411 and defined a vector @xmath412 .",
    "vector @xmath413 was sparse and generated randomly in @xmath414 $ ] .",
    "the lower bound @xmath415 and the upper bounds @xmath416 were set to @xmath417 and @xmath418 , respectively for all @xmath376 .",
    "we benchmarked three algorithms with performance profiles @xcite .",
    "recall that a performance profile is built based on a set @xmath419 of @xmath420 algorithms ( solvers ) and a collection @xmath421 of @xmath422 problems .",
    "suppose that we build a profile based on computational time .",
    "we denote by @xmath423 .",
    "we compare the performance of algorithm @xmath424 on problem @xmath425 with the best performance of any algorithm on this problem ; that is we compute the performance ratio @xmath426 .",
    "now , let @xmath427 for @xmath428 .",
    "the function @xmath429 $ ] is the probability for solver @xmath424 that a performance ratio is within a factor @xmath430 of the best possible ratio .",
    "we use the term `` performance profile '' for the distribution function @xmath431 of a performance metric .",
    "we plotted the performance profiles in @xmath432-scale , i.e. @xmath433 .    we tested three algorithms on a collection of @xmath434 random problems with @xmath435 from @xmath436 to @xmath437 and @xmath372 from @xmath438 to @xmath439 .",
    "the profiles are plotted in figure [ fig : perf_profile1 ] .",
    "-0.5 cm     scale of three algorithms.,width=457,height=302 ]    -0.5 cm    based on this test , we can make the following observations .",
    "both algorithms , ` pdgda ` and ` 2ddecompalg ` , can solve all the test problems , while ` 2pdecompalg ` can only solve @xmath440 ( @xmath441 ) problems . `",
    "pfgda ` requires a significantly fewer iterations than ` 2pdecompalg ` and ` 2ddecompalg ` , and it has the best performance on @xmath442 problems in terms of number of iterations . `",
    "2ddecompalg ` is the best in terms of computational time where it reaches @xmath442 the test problem with the best performance .",
    "however , the number of nonzero elements of the obtained solution in ` pfgda ` matches very well the vector of original coefficients @xmath397 , while it is rather bad in ` 2pdecompalg ` and ` 2ddecompalg ` as we can see from the last figure . in other words , ` 2ddecompalg ` is not good at finding a sparse solution in this example .",
    "in this paper we have proposed two new dual gradient - based decomposition algorithms for solving large - scale separable convex optimization problems .",
    "we have analyzed the convergence of these to schemes and derived the rate of convergence .",
    "the first property of these methods is that they can handle general convex objective functions .",
    "therefore , they can be applied to a wide range of applications compared to second order methods .",
    "second , the new algorithms can implemented in parallel and all the algorithmic parameters are updated automatically without using any tuning strategy.third , the convergence rate of algorithm [ alg : fast_grad_alg ] is @xmath443 which is optimal in the dual decomposition framework . finally , the complexity estimates of the algorithms do not depend on the diameter of the feasible set as in proximal - type methods , they only depend on the parameter of the barrier functions .",
    "this research was supported by research council kul : pfv/10/002 optimization in engineering center optec , goa/10/09 manet ; flemish government : iof / kp / scores4chem , fwo : phd / postdoc grants and projects : g.0320.08 ( convex mpc ) , g.0377.09 ( mechatronics mpc ) ; iwt : phd grants , projects : sbo lecopro ; belgian federal science policy office : iuap p7 ( dysco , dynamical systems , control and optimization , 2012 - 2017 ) ;",
    "eu : fp7-embocon ( ict-248940 ) , fp7-sadco ( mc itn-264735 ) , erc st highwind ( 259 166 ) , eurostars smart , accm ; the european union , seventh framework programme ( fp7/20072013 ) , embocon , under grant agreement no 248940 ; cncs - uefiscdi ( project te , no .",
    "19/11.08.2010 ) ; ancs ( project pn ii , no .",
    "80eu/2010 ) ; sectoral operational programme human resources development 2007 - 2013 of the romanian ministry of labor , family and social protection through the financial agreements posdru/89/1.5/s/62557 .",
    "kojima , m. , megiddo , n. , mizuno , s. , et  al : horizontal and vertical decomposition in interior point methods for linear programs . technical report . , information sciences , tokyo institute of technology , tokyo ( 1993 ) .",
    "necoara , i. , savorgnan , c. , tran - dinh , q. , suykens , j.a.k . , diehl , m. : distributed nonlinear optimal control using sequential convex programming and smoothing techniques . in : proceedings of the 48th ieee conference on decision and control .",
    "shanghai , china ( 2009 ) ."
  ],
  "abstract_text": [
    "<S> a new decomposition optimization algorithm , called _ path - following gradient - based decomposition _ , is proposed to solve separable convex optimization problems . </S>",
    "<S> unlike path - following newton methods considered in the literature , this algorithm does not requires any smoothness assumption on the objective function . </S>",
    "<S> this allows us to handle more general classes of problems arising in many real applications than in the path - following newton methods . </S>",
    "<S> the new algorithm is a combination of three techniques , namely smoothing , lagrangian decomposition and path - following gradient framework . </S>",
    "<S> the algorithm decomposes the original problem into smaller subproblems by using dual decomposition and smoothing via self - concordant barriers , updates the dual variables using a path - following gradient method and allows one to solve the subproblem in parallel . </S>",
    "<S> moreover , the algorithmic parameters are updated automatically without any tuning strategy as in augmented lagrangian approaches . </S>",
    "<S> we prove the global convergence of the new algorithm and analyze its local convergence rate . </S>",
    "<S> then , we modify the proposed algorithm by applying nesterov s accelerating scheme to get a new variant which has a better local convergence rate . finally , we present preliminary numerical tests that confirm the theory development .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}