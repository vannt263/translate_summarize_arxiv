{
  "article_text": [
    "nowadays , model predictive controllers ( mpc ) , sometimes also called receding horizon controllers ( rhc ) , are used in a variety of industrial applications , cf . @xcite . as shown in @xcite , @xcite and @xcite , theory for such controllers",
    "is also widely understood both for linear and nonlinear systems .",
    "the control method itself deals with the problem of approximately solving an infinite horizon optimal control problem which is computationally intractable in general .",
    "reasons for its success are on the one hand its capability to directly incorporate constraints depending on the states and inputs of the underlying process .",
    "on the other hand , the fundamental steps of this method are very simple : first , a solution of a finite horizon optimal control problem is computed for a given initial value . in a second step ,",
    "the first element of the resulting control is implemented at the plant and in the last step , the finite horizon is shifted forward in time . as a consequence , the method is iteratively applicable and reveals the control to be a static state feedback .",
    "unfortunately , stability of solution of the infinite horizon problem may be lost due to considering only finite horizons . over the last two decades",
    ", several solutions have been proposed to cope with this issue , see , e.g. , @xcite , @xcite and @xcite .",
    "all these approaches require the horizon to be sufficiently long and computing the minimal required horizon length is computationally demanding .",
    "however , the horizon needs to be chosen as a worst case scenario which is usually needed to cope with small regions of state space only .",
    "our aim in this work is to develop online applicable adaptation strategies for the horizon length which guarantee stability of the closed loop . in particular , we follow the approach of @xcite where different suboptimality estimates have been developed to measure the performance of the model predictive controller .",
    "based on these estimates , we propose a simple technique to locally fit the horizon to the control task , the current state of the system and also to the mpc internal information .",
    "due to the change of the structure of the controller , however , known stability proofs and suboptimality results can not be applied . to cover these issues ,",
    "we present a stability result for mpc with varying optimization horizons using mild additional conditions . to some extend adaptation strategies of the horizon",
    "are known in the literature , see e.g. @xcite and @xcite , which are heuristics based on insight of the specific problem but have shown to be applicable in an adaptive model predictive control setting .",
    "in contrast to that , our approach can be proven rigorously and doesnot require any insight into the process under consideration ( note that different to our intention the term adaptive model predictive control is also used to incorporate model uncertainties , see , e.g. , @xcite and @xcite ) .    the paper is organized as follows : in section [ section : setting ] we describe and motivate the problem setup .",
    "section [ section : stability for standard nmpc ] deals with the a posteriori and a priori suboptimalty estimates which will be the foundation of our analysis . in the following section [ section : stability under adaptation ] ,",
    "we show how the stated stability results and estimates can be extended to the case of varying optimization horizons .",
    "thereafter , we state a simple shortening and prolongation strategy based on the suboptimality estimates given in section [ section : a simple adaptation strategy ] . in order to show the applicability and effectiveness of our approach , section [ section : numerical results ]",
    "contains a numerical example of the adaptive mpc approach .",
    "the final section [ section : conclusion ] concludes the paper and points out directions of future research .",
    "within this work we analyze nonlinear discrete time control systems of the form @xmath0 with @xmath1 and @xmath2 for @xmath3 . for the considered systems the state space @xmath4 and the control value space @xmath5 are arbitrary metric spaces .",
    "hence , all following results also apply to the discrete time dynamics induced by a sampled infinite dimensional system , cf .",
    "@xcite or @xcite . here",
    ", we denote the space of control sequences @xmath6 by @xmath7 and the solution trajectory for given control @xmath8 by @xmath9 . additionally , the sets @xmath10 and @xmath11 incorporate possible restrictions on the state and control respectively .    in the following , we aim at finding a static state feedback @xmath12 for a given control system which minimizes the infinite horizon cost functional @xmath13 with stage cost @xmath14 . the corresponding optimal value function",
    "is denoted by @xmath15 and throughout this paper we assume that the minimum with respect to @xmath8 is attained . the optimal value function @xmath16 can be used to define the infinite horizon feedback law @xmath17 for which one can show optimality using bellman s optimality principle . since the computation of the desired control law requires the solution of a hamilton  jacobi  bellman equation",
    ", we use a model predictive control approach in order to avoid the problem of solving an infinite horizon optimal control problem .",
    "the fundamental idea of such a model predictive controller is simple and consists of three steps which are repeated at every discrete time instant during the process run : first , an optimal control for the problem on a finite horizon @xmath18 $ ] is computed given the most recent known state of the system @xmath19 .",
    "then , the first control element is implemented at the plant and in the third step the entire optimal control problem considered in the first step is shifted forward in time by one discrete time instant which allows for iteratively repeating this process . in the literature",
    "this method is also termed receding horizon , see , e.g. , @xcite .",
    "in contrast to the infinite horizon optimal control , the problem in the second step is to minimize the truncated cost functional on a finite horizon @xmath20 the truncated horizon defines the set of discrete time instances @xmath21 . here",
    ", we assume the first instant to be denoted by zero for each optimal control problem within the mpc problem .",
    "in particular , we focus on the implementation of a constrained model predictive controller without additional stabilizing endpoint constraints or a lyapunov function type endpoint weight , see , e.g. , @xcite and @xcite , respectively .    throughout this work , we denote the closed loop solution at time instant @xmath22 by @xmath23 while @xmath24 denotes the open loop trajectory of the prediction",
    ". moreover , we use the abbreviations @xmath25 for the minimizing open loop control sequence of the reduced cost functional and its first element respectively .",
    "we call @xmath26 the optimal value function of the finite cost functional and , for notational purposes , we use @xmath27 to represent the @xmath22-th control value within the open loop control sequence corresponding to the initial value @xmath19 when it is necessary to distinguish between two or more different open loop controls . hence ,",
    "if the initial value @xmath28 is given , then the open loop control induces the open loop solution @xmath29 for all time instances @xmath30 on the optimization horizon @xmath31 . similarly",
    "to , the closed loop control can be defined as @xmath32 and the corresponding closed loop system is given by @xmath33 for all @xmath3 .",
    "note that due to the truncation of the infinite horizon cost functional to the finite mpc cost functional , stability and optimality properties of the closed loop solution , induced by the infinite horizon optimal control are not preserved in general .    here",
    ", our aim is to show that in order to guarantee stability of the closed loop , for any initial value @xmath34 , the requirement of considering the worst case optimization horizon @xmath35 for all initial values @xmath34 can be weakened .",
    "additionally , the resulting closed loop trajectory satisfies locally a predefined degree of suboptimality compared to the infinite horizon solution , .",
    "the measure of suboptimality we consider in the following is the difference between the infinite horizon cost induced by the mpc law @xmath36 , that is @xmath37 and the finite horizon cost @xmath38 or the infinite horizon optimal value function @xmath16 . in particular , the latter give us estimates on the degree of suboptimality of the controller @xmath36 of the mpc process . for this purpose ,",
    "we make extensive use of the suboptimality estimates derived in @xcite .",
    "[ suboptimality : prop : trajectory a posteriori estimate ] consider a feedback law @xmath39 and its associated trajectory @xmath40 according to with initial value @xmath41 .",
    "if there exists a function @xmath42 satisfying @xmath43 for some @xmath44 $ ] and all @xmath3 , then @xmath45 holds for all @xmath3 .    since all values in",
    "are computed throughout the nmpc process , @xmath46 can be easily computed online along the closed loop trajectory .",
    "thus , yields a computationally feasible and numerically cheap way to estimate the degree of suboptimality of the trajectory .    due to the fact that @xmath47 in is unknown at runtime",
    ", proposition yields an a posteriori estimator .",
    "however , we can also utilize a more conservative a priori estimate if we assume the following :    [ suboptimality : ass : apriori ] for given @xmath35 , @xmath48 , @xmath49 , there exists a constant @xmath50 such that for the open loop solution @xmath51 given by the inequalities @xmath52 hold for all @xmath53 and all @xmath3 .",
    "[ suboptimality : thm : apriori ] consider @xmath50 and @xmath35 , @xmath48 , @xmath54 such that @xmath55 holds .",
    "if assumption [ suboptimality : ass : apriori ] is fulfilled for these @xmath56 , @xmath35 and @xmath57 , then the estimate holds for all @xmath3 where @xmath58    note that we can not expect the relaxed lyapunov inequality or assumption [ suboptimality : ass : apriori ] to hold in practice .",
    "in many cases the discrete time system is obtained from a discretization of a continuous time system , e.g. sampling with zero order hold , see @xcite .",
    "hence , even if the continuous time system is stabilizable to a setpoint @xmath59 and no numerical errors occur during optimization and integration , the corresponding sampled  data system is most likely practically stabilizable at @xmath59 only .",
    "however , suboptimality results can be extended to cover the case of practical stability as well , see @xcite and @xcite . since extending the stability results we will present now to cover the practical case can be done analogously , see @xcite , we restrict ourselves to the case of asymptotic stability for simplicity of exposition .",
    "as stated at the end of section [ section : setting ] , we aim at weakening the worst case nature of the optimization horizon @xmath35 . here , one has to keep in mind that if a model predictive controller shall be designed for a given application , then stability of the resulting closed loop needs to be guaranteed for the entire working range @xmath10 . in practice",
    ", this may lead to very large optimization horizons @xmath35 . yet",
    ", most points visited by the closed loop we do not require such a large optimization horizon in order to guarantee stability .    here",
    ", we focus on locally guaranteeing a decrease of the cost function for each step of the mpc process and modify the horizon length @xmath35 to fulfill this task .",
    "similar to the suboptimality results from section [ section : stability for standard nmpc ] , we want to measure this decrease in terms of the running cost @xmath60 such that a given suboptimality bound @xmath61 is locally satisfied .    since we are now dealing with varying optimization horizons , we intuitively extend our notation from section [ section : stability for standard nmpc ] by adding the used optimization horizon as an argument , i.e. @xmath62 denotes the suboptimality degree @xmath46 with horizon @xmath35 .",
    "moreover , since the resulting closed loop control now depends on a sequence @xmath63 we denote such a control law by @xmath64 .    an abstract adaptive mpc algorithm which locally accomplishes the task of guaranteeing a decrease in the cost function is the following :    * given @xmath23 and @xmath65 do * *",
    "compute optimal control on horizon @xmath65 * * compute suboptimality degree @xmath66 * * if @xmath67 : call shortening strategy for @xmath65 + else : call prolongation strategy for @xmath65 + while @xmath68 * implement the first control component @xmath69 * set @xmath70 and shift the optimization horizon forward in time    in this context , we distinguish the following degrees of suboptimality :    [ stability under adaptation : def : suboptimality degree ] ( i ) given a set @xmath10 , then we call @xmath71 the _ global suboptimality degree_. + ( ii ) given a point @xmath34 , then we call @xmath72 the _ local suboptimality degree_. + ( iii ) given a closed loop trajectory @xmath40 we call @xmath73 the _ closed loop suboptimality degree_.    the problem which we are facing for such an adaptive mpc algorithm is the fact that none of the existing stability proofs , see , e.g. , @xcite , @xcite , @xcite , @xcite , @xcite and @xcite , can be applied in this context since these results assume @xmath35 to be constant while here the optimization horizon @xmath65 may change in every step of the mpc algorithm .    the major obstacle to apply the idea of proposition [ suboptimality : prop : trajectory a posteriori estimate ] in the context of varying optimization horizons @xmath35",
    "is the lack of a common lyapunov function along the closed loop . to compensate for this deficiency ,",
    "we make the following mild assumption :    [ stability under adaptation : ass : enhanced stabilizing ] given an initial value @xmath34 and a horizon length @xmath74 such that @xmath36 guarantees local suboptimality degree @xmath75 , @xmath61 , we assume that for @xmath76 , @xmath77 , there exist constants @xmath78 such that the inequalities @xmath79 hold where @xmath80 is the local suboptimality degree of the controller @xmath81 corresponding to the horizon length @xmath82 .    note that assumption [ stability under adaptation : ass : enhanced stabilizing ] is indeed very weak since for one we allow for non  monotone developments of the suboptimality degree @xmath83 if the horizon length is increased which may occur as shown in @xcite . here , we only make sure that if a certain suboptimality degree @xmath61 holds for a horizon length @xmath35 , then the estimate @xmath80 does not drop below zero if the horizon length @xmath82 is increased .    considering the value of @xmath84 , we notice that it may tend to zero if @xmath82 is increased , hence we have that @xmath85 is in general unbounded .",
    "the special case @xmath86 , however , states that the equilibrium of our problem has been reached and can be neglected in this context since this implies @xmath87 allowing for arbitrary @xmath85 .    given assumption [ stability under adaptation : ass : enhanced stabilizing ] , we obtain stability and a performance estimate of the closed loop in the context of changing horizon lengths similar to proposition [ suboptimality : prop : trajectory a posteriori estimate ] .",
    "[ stability under adaptation : thm : stability of adaptive mpc ] consider @xmath61 and a sequence @xmath88 , @xmath89 , where @xmath90 , such that the mpc feedback law @xmath64 defining the closed loop solution guarantees @xmath91 for all @xmath3 . if additionally assumption [ stability under adaptation : ass : enhanced stabilizing ] is satisfied for all pairs of initial values and horizons @xmath92 , @xmath3 , then we obtain @xmath93 to hold for all @xmath94 where @xmath95 .",
    "* proof : * given a pair @xmath92 , assumption [ stability under adaptation : ass : enhanced stabilizing ] guarantees @xmath96 for @xmath97 .",
    "now we choose @xmath98 within this local suboptimality estimation .",
    "hence , we obtain @xmath99 using the relaxed lyapunov inequality . multiplying by the stage cost @xmath100 , we can conclude @xmath101 using and assumption [ stability under adaptation : ass : enhanced stabilizing ] . summing the running costs along the closed loop trajectory",
    "reveals @xmath102 where we defined @xmath95 .",
    "+ since @xmath103 holds , taking @xmath104 to infinity reveals @xmath105 since the @xmath106 and @xmath107 hold by the principle of optimality , the assertion follows .",
    "comparing proposition [ suboptimality : prop : trajectory a posteriori estimate ] and theorem [ stability under adaptation : thm : stability of adaptive mpc ] , we see that the closed loop estimate @xmath108 may be smaller than the local suboptimality bound @xmath109 but due to @xmath78 we can guarantee @xmath110 .",
    "yet , @xmath108 may become very small depending on @xmath111 and @xmath85 from assumption [ stability under adaptation : ass : enhanced stabilizing ] .",
    "since now we have shown asymptotic stability of a mpc closed loop trajectory with varying optimization horizon , we show a very simple approach to guarantee the local suboptimality requirement @xmath67 . to this end , we assume the system to be controllable , i.e.    [ a simple adaptation strategy : ass : stabilizable ] given @xmath61 , for all @xmath112 there exists a finite horizon length @xmath113 such that the relaxed lyapunov inequality holds with @xmath75 .    [ a simple adaptation strategy : thm : stepsize shortening ] consider an optimal control problem , with initial value @xmath23 , horizon @xmath89 and fixed suboptimality bound @xmath61 and denote the optimal control sequence by @xmath114 .",
    "suppose there exists an integer @xmath115 , @xmath116 such that @xmath117 holds true for all @xmath118 .",
    "then , setting @xmath119 and @xmath120 for @xmath121 , inequality holds for @xmath122 with @xmath123 .",
    "* proof : * the proof follows directly from the fact that for @xmath120 the closed loop trajectory satisfies @xmath124 .",
    "hence , follows from .    with the choice @xmath125 , due to the principle of optimality",
    "we obtain that the optimal control problems within the next @xmath126 nmpc iterations are already solved since @xmath127 can be obtained from the optimal control sequence @xmath128 computed at time @xmath22 .",
    "this implies that the most efficient way for the reducing strategy is not to reduce @xmath65 itself but rather to reduce the horizons @xmath129 by @xmath30 for the subsequent sampling instants @xmath130 , i.e. , we choose the initial guess of the horizon @xmath131 .",
    "still , if the a posteriori estimate is used , the evaluation of requires the solution of an additional optimal control problem in each step . +",
    "in order to to use the _ a priori _ estimate given by theorem [ suboptimality : thm : apriori ] the following result can be used as a shortening strategy :    [ a simple adaptation strategy : thm : stepsize shortening2 ] consider a optimal control problem , with initial value @xmath23 and horizon @xmath132 , @xmath133 and denote the optimal control sequence by @xmath114 . moreover , the suboptimality bound @xmath61 is fixed inducing some @xmath134 via .",
    "suppose there exists an integer @xmath115 , @xmath135 such that for all @xmath118 there exist @xmath136 satisfying @xmath137 for all @xmath138 .",
    "then , setting @xmath119 and @xmath120 for @xmath121 , inequality holds for @xmath122 with @xmath123 .",
    "* proof : * since , hold for @xmath139 , theorem [ suboptimality : thm : apriori ] guarantees that the local suboptimality degree is at least as large as @xmath109 .",
    "if @xmath140 holds , we can make use of the fact that for @xmath120 the closed loop trajectory satisfies @xmath124 . by , , we obtain assumption [ stability under adaptation : ass : enhanced stabilizing ] to hold for @xmath122 . accordingly , the assertion follows from theorem [ suboptimality : thm : apriori ] which concludes the proof .",
    "note that while the a priori estimate from theorem [ suboptimality : thm : apriori ] is slightly more conservative than the result from proposition [ suboptimality : prop : trajectory a posteriori estimate ] , it is also computationally less demanding if the value @xmath57 is small . + in contrast to this efficient and simple shortening strategy , it is quite difficult to obtain efficient methods for prolongating the optimization horizon @xmath65 . in order to obtain a simple prolongating strategy , we invert the approach of theorem [ a simple adaptation strategy : thm : stepsize shortening ] , i.e. we iteratively increase the parameter @xmath35 until the requirement @xmath67 is satisfied .    [ a simple adaptation strategy : thm : stepsize prolongation ] consider an optimal control problem , with initial value @xmath23 and @xmath89 . moreover , for fixed @xmath61 suppose assumption [ a simple adaptation strategy : ass : stabilizable ] to hold .",
    "then , any algorithm which iteratively increases the optimization horizon @xmath65 terminates in finite time and computes a horizon length @xmath65 such that holds with local suboptimality degree @xmath109 .",
    "* proof : * follows directly from assumption [ a simple adaptation strategy : ass : stabilizable ] .    unfortunately , if does not hold , it is in general difficult to assess by how much @xmath65 should be increased such that holds for the increased @xmath65 .",
    "the most simple strategy of increasing @xmath65 by one in each iteration shows satisfactory results in practice , however , when starting the iteration with @xmath65 , in the worst case it requires us to check @xmath141 times at each sampling instant .",
    "in contrast to the shortening strategy , the principle of optimality can not be used here to establish a relation between the optimal control problems for different @xmath65 and , moreover , these problems may exhibit different solution structures which makes it a hard task to provide a suitable initial guess for the optimization algorithm .",
    "to illustrate the effects of using an adaptive nmpc , we consider a highrack warehouse @xmath142 where for simplicity of exposition the rope is modeled as a pendulum with variable length . here",
    ", @xmath143 denotes the position of the crab along the highrack , @xmath144 represents the length of the rope of the crane and @xmath145 corresponds to the angle of deflection of the rope .",
    "moreover , @xmath146 and @xmath147 denote the gravitational constant and the inertia of the angle of the rope , respectively .    for this example",
    ", we use mpc to generate a feedback for a representative transport action of a pallet from @xmath148 , @xmath149 to @xmath150 , @xmath151 ( with zero derivatives in initial and target position ) while maintaining the state and control constraints @xmath152 ^ 2 \\times [ 1 , 4 ] \\times [ -1 , 2 ] \\times [ -1 , 1 ] \\times { \\mathbb{r}}$ ] and @xmath153 \\times [ -1 , 2]$ ] . to this end , we use the running cost @xmath154          & + c_3 ( \\chi(t ) - \\hat{\\chi})^2 + c_4 \\dot{\\chi}^2(t ) + c_5 ( \\upsilon(t ) - \\hat{\\upsilon})^2 \\\\          & + c_6 \\dot{\\upsilon}^2(t ) + c_7 \\left ( u_1 ^ 2(t ) + u_2 ^ 2(t ) \\right ) dt\\end{aligned}\\ ] ] with constants @xmath155 , @xmath156 , @xmath157 , @xmath158 and @xmath159 and the sampling period @xmath160 . to solve the optimal control problem arising throughout the mpc procedure",
    ", we use a direct approach , i.e. discretize the continuous time problem and use an sqp method to solve the resulting optimization problem . here",
    ", we set the tolerance levels @xmath161 and @xmath162 for the differential equation solver and the optimization method respectively .",
    "since the adaptive mpc algorithm allows us to set the lower bound of the degree of suboptimality @xmath109 directly , we first investigate the @xmath163depending quality of a controlsequence on the closed loop cost @xmath164 . to this end",
    ", we terminate the algorithm when the condition @xmath165 is satisfied .",
    "the data we obtained for this setting is displayed in figure [ numerical results : figure : vinfty ] .",
    "# 1#1 # 1#1    ( -0.12,-0.2)(1.1,3.6 ) ( 0,0)(10,3 ) ( 1.03,3.2 ) ( 7.4,-0.1 ) ( -0.8,5.1 ) ( 0.01,2.72984)(0.02,2.71224)(0.03,2.71145)(0.04,2.71175)(0.05,2.70591)(0.06,2.7021)(0.07,2.69917)(0.08,2.69577)(0.09,2.68954)(0.1,2.20244)(0.11,2.2004)(0.12,2.20007)(0.13,2.19872)(0.14,2.18109)(0.15,1.90315)(0.16,1.89709)(0.17,1.68794)(0.18,1.5925)(0.19,1.58508)(0.2,1.55296)(0.21,1.39482)(0.22,1.34011)(0.23,1.33449)(0.24,1.23292)(0.25,1.23185)(0.26,1.22469)(0.27,1.10744)(0.28,1.02583)(0.29,0.985983)(0.3,0.982898)(0.31,0.967358)(0.32,0.892798)(0.33,0.881194)(0.34,0.878421)(0.35,0.86274)(0.36,0.836169)(0.37,0.811576)(0.38,0.738571)(0.39,0.734305)(0.4,0.699037)(0.41,0.671772)(0.42,0.670592)(0.43,0.645912)(0.44,0.623263)(0.45,0.611095)(0.46,0.603729)(0.47,0.602497)(0.48,0.601422)(0.49,0.585912)(0.5,0.566657)(0.51,0.546491)(0.52,0.535822)(0.53,0.535731)(0.54,0.532438)(0.55,0.518943)(0.56,0.514327)(0.57,0.511628)(0.58,0.491927)(0.59,0.479089)(0.6,0.467972)(0.61,0.464103)(0.62,0.455598)(0.63,0.458576)(0.64,0.449939)(0.65,0.443905)(0.66,0.44385)(0.67,0.442741)(0.68,0.426646)(0.69,0.422172)(0.7,0.413295)(0.71,0.412483)(0.72,0.411911)(0.73,0.405432)(0.74,0.40216)(0.75,0.400388)(0.76,0.390231)(0.77,0.386737)(0.78,0.385914)(0.79,0.382618)(0.8,0.380156)(0.81,0.373909)(0.82,0.374274)(0.83,0.368566)(0.84,0.36859)(0.85,0.367402)(0.86,0.365297)(0.87,0.356816)(0.88,0.356626)(0.89,0.356724)(0.9,0.348868)(0.91,0.346065)(0.92,0.342601)(0.93,0.337491)(0.94,0.334998)(0.95,0.331709)(0.96,0.328346)(0.97,0.326103)(0.98,0.324169 )    [ fig : v ]    here , one can nicely observe that the closed loop costs caused by the adaptive mpc feedback @xmath64 are decreasing as the lower bound @xmath109 is enlarged .",
    "this is right the behavior one would expect from the theoretical construction .",
    "however , using the adaptive mpc approach , larger @xmath109values not only provides a much better control sequence in terms of generated costs .",
    "we also like to mention that the total simulation time required to satisfy the termination criterion is also decreasing as @xmath109 is enlarged which is due to the use of larger optimization horizons @xmath65 throughout the run of the simulation . in figure",
    "[ numerical results : figure : ni ] , we additionally plotted the optimization horizon sequences @xmath166 for the selected values of @xmath109 .",
    "this figure demonstrates clearly the horizon incrementations during acceleration and deceleration  phases .",
    "in particular , a large optimization horizon is required to satisfy the desired decrease in the relaxed lyapunov inequality upon start of the simulation run which is then reduced as the crab moves towards its destination . in order to reduce the possibly occuring overshoot , the method automatically increases the horizon again . during the final leveling phase , again no large horizons are needed to satisfy .",
    "# 1#1 # 1#1    ( -0.1,-0.7)(6,12.5 ) ( 0,0)(6,5 ) ( 6.3,10.8 ) ( 7.3,-0.1 ) ( -0.23,3.4 ) ( 0,4)(0.2,4)(0.2,3)(0.4,3)(0.4,3)(0.6,3)(0.6,2)(0.8,2)(0.8,2)(1,2)(1,2)(1.2,2)(1.2,2)(1.4,2)(1.4,2)(1.6,2)(1.6,2)(1.8,2)(1.8,2)(2,2)(2,2)(2.2,2)(2.2,2)(2.4,2)(2.4,2)(2.6,2)(2.6,2)(2.8,2)(2.8,2)(3,2)(3,2)(3.2,2)(3.2,2)(3.4,2)(3.4,2)(3.6,2)(3.6,2)(3.8,2)(3.8,2)(4,2)(4,3)(4.2,3)(4.2,4)(4.4,4)(4.4,5)(4.6,5)(4.6,6)(4.8,6)(4.8,5)(5,5)(5,4)(5.2,4)(5.2,3)(5.4,3)(5.4,2)(5.6,2)(5.6,2)(5.8,2)(5.8,2)(6,2 ) ( 0,8)(0.2,8)(0.2,7)(0.4,7)(0.4,6)(0.6,6)(0.6,5)(0.8,5)(0.8,5)(1,5)(1,5)(1.2,5)(1.2,4)(1.4,4)(1.4,4)(1.6,4)(1.6,4)(1.8,4)(1.8,4)(2,4)(2,4)(2.2,4)(2.2,4)(2.4,4)(2.4,4)(2.6,4)(2.6,5)(2.8,5)(2.8,5)(3,5)(3,6)(3.2,6)(3.2,6)(3.4,6)(3.4,6)(3.6,6)(3.6,7)(3.8,7)(3.8,8)(4,8)(4,7)(4.2,7)(4.2,7)(4.4,7)(4.4,6)(4.6,6)(4.6,6)(4.8,6)(4.8,7)(5,7)(5,7)(5.2,7)(5.2,7)(5.4,7)(5.4,6)(5.6,6)(5.6,6)(5.8,6)(5.8,6)(6,6 )    [ fig : n ]    in figure [ numerical results : figure : ni ] , one can also see that the spike in the horizon length occurs earlier for @xmath167 .",
    "again , this corresponds to the mpc procedure recognizing the possible overshoot by means of .",
    "in this work we have shown stability and suboptimality estimates for model predictive controllers with varying optimization horizon .",
    "this result allows for developing strategies to adapt the horizon length instead of using a worst case estimate and control the quality of the feedback directly .",
    "+ future work may concern reducing the computational effort required to evaluate the suboptimality estimates .",
    "moreover , development and investigation of alternatives to prolongate the optimization horizon will be an issue , i.e. by combining information of several iterates .",
    "allgwer , f. and zheng , a. ( 2000 ) . _ nonlinear model predictive control _ , volume  26 of _ progress in systems and control theory_. birkhuser verlag , basel .",
    "papers from the workshop held in ascona , june 26 , 1998 .",
    "altmller , n. , grne , l. , and worthmann , k. ( 2010 ) . receding horizon optimal control for the wave equation . in _ proceedings of the 49th ieee conference on decision and control _ , 34273432 .",
    "atlanta , georgia .",
    "keerthi , s. and gilbert , e. ( 1988 ) .",
    "optimal infinite - horizon feedback laws for a general class of constrained discrete - time systems : stability and moving - horizon approximations .",
    "_ j. optim .",
    "theory appl .",
    "_ , 57(2 ) , 265293 .",
    "viquerat , a. , blackhall , l. , reid , a. , sukkarieh , s. , and brooker , g. ( 2008 ) . .",
    "in _ field and service robotics : results of the 6th international conference _ , volume  42 , 245254 .",
    "springer tracts in advanced robotics ."
  ],
  "abstract_text": [
    "<S> recently , suboptimality estimates for model predictive controllers ( mpc ) have been derived for the case without additional stabilizing endpoint constraints or a lyapunov function type endpoint weight . </S>",
    "<S> the proposed methods yield _ a posteriori _ and _ a priori _ estimates of the degree of suboptimality with respect to the infinite horizon optimal control and can be evaluated at runtime of the mpc algorithm . </S>",
    "<S> our aim is to design automatic adaptation strategies of the optimization horizon in order to guarantee stability and a predefined degree of suboptimality for the closed loop solution . here , </S>",
    "<S> we present a stability proof for an arbitrary adaptation scheme and state a simple shortening and prolongation strategy which can be used for adapting the optimization horizon .    adaptive control , model predictive control , stability , suboptimality , sampled - data control , sampled - data systems </S>"
  ]
}