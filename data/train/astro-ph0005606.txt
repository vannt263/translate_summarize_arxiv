{
  "article_text": [
    "estimating the gravity and velocity fields in the local universe from redshift surveys requires us to estimate the galaxy density field in the parts of the sky we can not survey , in particular behind the milky way .",
    "early attempts to do this assumed a uniform density of galaxies behind the milky way , or attempted a crude interpolation from above and below .",
    "a great advance was the introduction of weiner filtering techniques ( lahav 1994 ) , which combines interpolation and regularisation to provide a biased , but minimum variance , estimate of the underlying , real - space , density field .",
    "the major drawbacks are that it requires a prior estimate of the power spectrum , and also that structure not compatible with the assumption of gaussianity is strongly suppressed ; this limits its applicability to very large scales and poor resolutions .    to circumvent this ,",
    "we have developed a technique where the logarithm of the underlying field is expanded as a sum of harmonics .",
    "if galaxies were actually poisson - sampled from a lognormal underlying field , our resulting interpolated and regularised field would be the best possible estimate of the density field .",
    "this approximation is a good one ( hubble 1934 , coles and jones 1991 ) , and qualitatively we find our methods robust to deviations from lognormality .",
    "our input data consists of real or simulated redshift surveys : that is a clustered 3d discrete distribution over a predefined solid angle , and which we model as a stochastic process drawn from an underlying continuous non - negative density field ( e.g. peebles 1980 ) with a spatially - dependent sampling rate which we quantify as the selection function , @xmath2 .",
    "our aim is to find an expansion for the underlying density field which gives the maximum likelihood for the positions and redshifts of the galaxies in the survey , and to use this expansion to interpolate across regions with missing data .",
    "we work with the logarithm of the density field rather than the field itself , as this is both physically sensible and mathematically convenient .",
    "the basis functions can in principal be any arbitrary set of functions , but the method works faster the more nearly orthogonal they are over the volume of the survey .",
    "so we have a set of @xmath3 galaxies at positions @xmath4 , and a set of @xmath5 basis functions @xmath6 . because of the radial symmetry inherent in all - sky surveys , we use the bessel - fourier basis functions , as laid out by binney and quinn ( 1991 ) and heavens and taylor ( 1995 ) .",
    "these are products of spherical harmonics @xmath7 and spherical bessel functions @xmath8 , chosen to have zero derivative on the boundary at @xmath9 .",
    "we also have a set of amplitudes @xmath10 which we wish to determine by maximising the likelihood for the observed dataset .",
    "the amplitude of the underlying density field at @xmath11 is then          clearly we need an need an integral constraint on @xmath12 , otherwise the likelihood can always be increased simply by increasing the density everywhere .",
    "we demand that the total number of galaxies predicted by the density field over the unmasked region , equal the number actually observed , and we introduce this via a lagrange multiplier .",
    "this gives us the main result of this paper , that we can find an expansion of a non - negative density field , using an arbitrary set of basis functions , which gives the maximum likelihood for a discrete distribution assumed to be stochastically sampled from the density field with known but variable sampling rate @xmath13 , by solving the @xmath5 equations      the equations are non - linear whenever the density field itself is . in practice ,",
    "we solve them by using the multidimensional newton - raphson technique ( press 1986 ) - i.e. we iteratively solve them as a locally linear set of equations .",
    "this involves finding and inverting the information matrix      the more nearly linear the field , and the more nearly orthogonal the basis functions , the faster the method works .",
    "typically 10 iterations are sufficient .",
    "the solution @xmath10 of the equations ( 9 ) defines a density field that fills the entire volume , even if the data itself does not do so . as long as the regions of missing data are smaller than the resolution of the expansion , the solution is perfectly stable and gives a natural interpolation across these regions .",
    "indeed , if the field is actually lognormal , the set @xmath10 are independent gaussian deviates , and hence the reconstruction in the gaps is also lognormal with identical first and second moments to the regions with data - that is , they are statistically identical .      for predicting e.g. the gravity dipole on the local group , we would like to go out to a distance of @xmath14 or so while keeping a resolution of a @xmath15 or so nearby , requiring at first sight millions of modes .",
    "however , our method necessarily involves repeated matrix inversions with as many rows and columns as basis functions , and this limits us to a few thousand harmonics .",
    "we have thus made use of the suggestion in fisher ( 1995 ) , of first transforming the radial coordinate of the survey so as to make the selection function unity .",
    "that is , we define a new radial coordinate @xmath16 , where      note that this means that the resolution element becomes increasingly prolate with distance .",
    "we have chosen our maximum values of @xmath17 and @xmath18 such that the resolution is roughly isotropic at the median distance of the survey . in the rescaled survey ,",
    "the shot noise is the same everywhere .",
    "when we try and push to higher wavenumbers , the reconstruction unsurprisingly becomes unstable in regions of missing data , and some form of regularisation is needed .",
    "an obvious solution is to add a penalty term to the likelihood involving the amplitude of the harmonics , derived from their _ a priori _ distribution based on the power spectrum .",
    "however , we have not taken this approach because firstly , we would like to avoid external input ; secondly our radial transform makes this calculation rather ugly .",
    "instead , we have formulated an analogous penalty function suggested by andrew hamilton , based on the real as opposed to transformed density field : at each step in the iteration , we estimate the rms variation in @xmath19 in radial shells , and fit the log of this with a cubic polynomial , giving a smooth @xmath20 .",
    "we then add a penalty term to the likelihood of          from the information matrix , we can easily determine error maps for the reconstruction .",
    "the inverse of this matrix is the covariance matrix @xmath23 .",
    "the error in @xmath19 at any position is then given by          figure 1 shows the results of applying the algorithm to a cdm simulation with @xmath24 , first given the whole @xmath25 coverage , and then restricted to the btp and then the pscz area . in each case , we have used harmonics up to @xmath26 , @xmath27 .",
    "away from the plane , the reconstructions are virtually identical .",
    "the pscz reconstruction in the plane is in general good , except behind the galactic centre where the mask is widest - e.g. ( 20,0,2000 ) , ( 20,0,6000 ) , ( 350,-10,8000 ) .",
    "the btp reconstruction is much better ."
  ],
  "abstract_text": [
    "<S> we present a new technique for the interpolation of discretely - sampled non - negative scalar fields across regions of missing data . </S>",
    "<S> any set of basis functions can be used , though the method is fastest when they are close to orthogonal . </S>",
    "<S> we show how the technique may be efficiently applied when the discrete sampling rate varies across the field . </S>",
    "<S> regularisation is desirable to avoid over - fitting noisy data , and is necessary when the regions of missing data are larger than the required resolution . </S>",
    "<S> we present and investigate methods for such regularisation .    </S>",
    "<S> # 1 # 1to 0pt#1 @xmath0 ) @xmath1 ] v      # 1_#1 _ # 1_#1 _    # 1 1.25 in .125 in .25 in </S>"
  ]
}