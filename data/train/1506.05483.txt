{
  "article_text": [
    "the theoretical framework of this paper is that of bayesian adaptive estimation with an information based objective function ( see , e.g. , mackay @xcite , kujala and lukka @xcite , kujala @xcite ) . following the notation of kujala @xcite ,",
    "the basic problem we consider is the estimation of an unobservable random variable @xmath0 based on a sequence @xmath1 of independent ( given  @xmath2 ) realizations from some conditional densities @xmath3 indexed by trial _ placements _",
    "@xmath4 , each of which can be adaptively chosen from some set @xmath5 based on the outcomes @xmath6 of the earlier observations .",
    "a commonly used greedy strategy is to choose the next placement so as to maximize the expected immediate information gain , that is , the decrease of the ( differential ) entropy of the posterior distribution given the next observation .",
    "previous work on the asymptotics of bayesian estimation ( see , e.g. , schervish @xcite , van  der vaart @xcite ) has mostly concentrated on the i.i.d .",
    "case , and in the few cases where the independent ( given @xmath2 ) but not identical case is considered , it is customarily assumed that a certain fixed sequence of variables is given .",
    "hence , these results do not apply to the present situation where the sequence @xmath7 of placements is also random .",
    "paninski @xcite has developed an asymptotic theory for this adaptive setting .",
    "he states consistency and asymptotic normality results for the greedy information maximization placement strategy and quantifies the asymptotic efficiency of the method .",
    "however , the proofs therein are not complete and hence do not provide a sufficient foundation for some generalizations and theorems we are interested in . in this paper , we develop a more general theory which allows us to generalize the main results of paninski @xcite to almost sure convergence ( with novel proofs ) and to show that the greedy method is in a certain sense asymptotically optimal among _ all _ placement methods .",
    "furthermore , we provide a rigorous and general framework that lends itself to further extensions of the theory .",
    "one particular extension we are interested in is analyzing the asymptotic properties of the novel framework proposed in kujala @xcite . in this framework ,",
    "the observation of @xmath8 is associated with some random cost @xmath9 ( see section  [ secvaryingcost ] for details ) . to make measurement `` cost - effective '' , a myopic placement rule is considered that on each trial @xmath10 maximizes the expected value of the information gain ( decrease of entropy ) @xmath11 divided by the expected value of the cost @xmath12 .",
    "this is called a myopic strategy as it looks only one step ahead .",
    "however , it is not a greedy strategy as it does not optimize the immediate gain .    in kujala @xcite , the following fairly simple asymptotic optimality result is given for this myopic strategy .",
    "[ asymptotic2 ] suppose that there exists a constant @xmath13 such that @xmath14 for all possible sets @xmath15 of past observations .",
    "if the next placement @xmath7 is defined as the maximizer of ( [ const ] ) and if for some @xmath16 and @xmath17 , @xmath18 for all @xmath10 , then the gain - to - cost ratio satisfies @xmath19 this is asymptotically optimal in the sense that for any other strategy that satisfies ( [ ass1 ] ) , we have @xmath20    however , this result requires the obtainable information gains to not decrease over time for the optimality condition to make sense and hence does not in general apply to smooth models . in this paper , we provide a counterpart of the above result using an optimality criterion ( d - optimality ) relevant to smooth models .",
    "our results are structured as follows . in section  [ secconsistency ] , we derive strong consistency of the posterior distributions under extremely mild , purely topological conditions on the family of likelihood functions . in section  [ secnormality ] , we consider the local smoothness assumptions ( to be assumed in a certain neighborhood of the true parameter value ) required for asymptotic normality . in section  [ secasymprop ] , we develop a theory of asymptotic proportions and use it for a novel type of convergence of random variables that is required in our analysis .",
    "then , in sections  [ secd - optimality ] and [ secasyment ] , we are able to quantify the asymptotic covariance and asymptotic entropy of the posterior distribution and to show a form of asymptotic optimality for the standard greedy information maximization strategy . in section  [ secvaryingcost ] , these results are generalized to the situation with random costs of observation associated with each placement as discussed above .",
    "the heuristically justified , myopic placement strategy proposed in kujala @xcite turns out to be asymptotically optimal also in the sense of the present paper , supporting the view that this strategy is the most natural generalization of the greedy information maximization strategy to the situation where the costs of observation can vary .",
    "we give concrete examples of the optimality results in section  [ secexamples ] and then end with general discussion in section  [ secdiscussion ] .",
    "we shall denote random variables by upper case letters and their specific values by lower case letters .",
    "the information theoretic definitions that we will use are the ( differential ) entropy @xmath21 , which does depend on the parameterization of @xmath22 , the kullback  leibler divergence @xmath23 which is independent of the parameterization , and the mutual information @xmath24 which is also independent of the parameterization as well as symmetric .",
    "also , the identities @xmath25 hold whenever the differences are well defined . this is all standard notation ( see , e.g. , cover and thomas @xcite ) except that in our notation , there is no implicit expectation over the values of @xmath26 in @xmath27 , and so it is a random variable depending on the value of @xmath26 .",
    "similarly , a conditional density @xmath28 as an argument to @xmath29 is treated the same way as any other density of @xmath30 , with no implicit expectation over @xmath22 .",
    "the densities @xmath31 and @xmath32 above are assumed to be taken w.r.t .",
    "arbitrary dominating measures `` @xmath33 '' and `` @xmath34 '' .",
    "thus , following lindley @xcite , we are in fact working in full measure theoretic generality even though we use the more familiar notation .",
    "the underlying probability space is @xmath35 and so , for example , @xmath36 means the probability that the value of @xmath37 is within the measurable set @xmath38 . in some places",
    "we may abbreviate this by @xmath39 , but it will be clear from the context what random variable is referred to .",
    "when we say `` for a.e .",
    "@xmath2 '' , it is w.r.t .",
    "the prior distribution of @xmath40 .",
    "the @xmath41-algebra of @xmath42 is assumed to contain at least the borel sets of the topology which @xmath42 is assumed to be endowed with .",
    "for any fixed @xmath43 , we assume that the conditional densities @xmath44 are given w.r.t . the same dominating @xmath41-finite",
    "measure `` @xmath45 '' for all @xmath46 and when we say `` for a.e .",
    "@xmath47 '' , it is w.r.t .",
    "this measure . for brevity",
    ", we shall indicate conditioning on the data @xmath48 by the subscript @xmath10 on any quantities that depend on them .",
    "for example , @xmath49 is the posterior density of @xmath40 given @xmath50 and @xmath51 is the posterior expectation of @xmath52 given  @xmath50 .",
    "it is often assumed that one can observe multiple independent ( given @xmath2 ) copies of the same random variable @xmath8 .",
    "however , instead of complicating the general notation with something like @xmath53 , we rely on the fact that the set @xmath5 can explicitly include separate indices for any identically distributed copies , for example , one might have @xmath54 \\mathop{\\sim}\\limits^{\\mathrm{i.i.d.}}\\ , [ y_{(x , t')}\\mid\\theta]$ ] for all @xmath55 , @xmath56 . hence",
    ", we can use the simple notation with no loss of generality .",
    "the greedy information gain maximization strategy can be formally defined as choosing the placement @xmath7 to be the value @xmath57 that maximizes the mutual information @xmath58 , the expected decrease in the entropy of @xmath40 after the next observation .",
    "in some models , there may be no maximum of the mutual information in which case the placement should be chosen sufficiently close to the supremum , which we formally define as the ratio of the mutual information and its supremum converging to one ( condition o4 in section  [ secoptimality ] ) .",
    "the general assumptions for consistency are :    1 .   the parameter space @xmath42 is a compact topological space .",
    "2 .   the family of log - likelihoods is ( essentially ) equicontinuous , that is , for all @xmath46 and @xmath17 , there exists a neighborhood @xmath59 of @xmath2 such that whenever @xmath60 , @xmath61 for a.e .",
    "@xmath47 for all @xmath43 .",
    "all points in @xmath42 are statistically distinguishable from each other .",
    "that is , for all distinct @xmath62 , @xmath63 for some @xmath43 .",
    "4 .   for some @xmath64 ,",
    "the placements @xmath7 satisfy @xmath65 for all sufficiently large @xmath10 .",
    "these assumptions for consistency are considerably weaker than those formulated in paninski @xcite .",
    "in particular , the assumptions only pertain to the likelihood function @xmath44 , absolutely nothing is assumed about the prior distribution of @xmath40 .",
    "furthermore , these assumptions are purely topological in the sense that they are preserved by all homeomorphic transformations of @xmath42 .",
    "also , in c4 , we do not require perfect maximization of information gain ; this is useful as it allows us to apply the same result to the non - greedy strategy discussed in section  [ secvaryingcost ] as well .",
    "non - compact spaces can be handled if the log - likelihood has an ( essentially ) equicontinuous extension to a compactification of @xmath42 .",
    "this happens precisely when the following conditions hold :    1 .",
    "the parameter space @xmath42 is a topological space .",
    "the function @xmath66 , with the topology of the target space induced by the ( @xmath67$]-valued ) norm @xmath68 is continuous ( this is just restating c2 ) and the closure of the range @xmath69 is compact ( this is the extra condition needed for non - compact spaces ) .",
    "3 .   for all distinct @xmath62 ,",
    "the inequality @xmath70 holds true , where equality is interpreted w.r.t .",
    "( this is equivalent to c3 . )    in that case , @xmath71 lifts continuously to the stone ",
    "ech compactification @xmath72 of @xmath42 ( theorem  [ thmstonecech ] ) .",
    "condition   may not hold for the points added by the compactification , but this can be fixed by moving to the compact quotient space @xmath73 .",
    "thus , can always be replaced by the strictly weaker conditions .",
    "[ lemmingain ] suppose that hold .",
    "then , there exists a metric @xmath74 that is consistent with the topology of @xmath42 , and an estimator @xmath75 such that for each @xmath10 there exists @xmath43 such that @xmath76    first , we show that the pseudometric @xmath77 defined in c3 is continuous in @xmath78 for all @xmath43 .",
    "it can be shown using c2 that for any @xmath46 and @xmath17 , there exists a neighborhood @xmath79 such that @xmath80 for all @xmath81 .",
    "thus , for any @xmath17 and @xmath82 , the triangle inequality implies @xmath83 whenever @xmath84 , and so @xmath77 is continuous .",
    "as @xmath77 is continuous , the set @xmath85 is open for every @xmath43 .",
    "now c3 implies that @xmath86 covers @xmath78 , and as @xmath78 is compact , there exists a finite subcover @xmath87 .",
    "it follows that @xmath88^{1/2}\\ ] ] is positive definite and hence a metric .",
    "since @xmath89 is finite , this metric inherits the continuity of @xmath77 .    to show that the topology induced by @xmath90 coincides with that of @xmath42 , let @xmath59 be an arbitrary open neighborhood of @xmath91 .",
    "then @xmath92 is compact and so its continuous image @xmath93 is compact , too .",
    "it follows that @xmath94 is open and as @xmath95 , we obtain @xmath96 for some @xmath97 .",
    "thus , we obtain @xmath98 , and so the topology induced by @xmath90 is finer than the default topology of @xmath42 . as @xmath90 is continuous ,",
    "we obtain the converse , and so the topologies coincide .",
    "let then @xmath10 be arbitrary .",
    "we extend @xmath99 with a special point @xmath100 for which we define the distances @xmath101^{1/2}.\\ ] ] the extended distance function may not be strictly positive definite , but it is still a pseudometric and satisfies the triangle inequality . denoting @xmath102 we have @xmath103 for all @xmath46 , and the triangle inequality yields @xmath104 . adding both inequalities , we obtain @xmath105 for all @xmath46 .",
    "now , the @xmath106-bound of kullback ",
    "leibler divergence @xcite , lemma  11.6.1 , yields @xmath107 ^ 2p_t(\\theta ) \\,\\mathrm{d}\\theta \\\\ &",
    "= & 4\\int d(\\theta,\\bar\\theta_t)^2p_t ( \\theta)\\,\\mathrm{d}\\theta \\ge\\int d(\\theta,\\hat\\theta_t)^2p_t ( \\theta)\\,\\mathrm{d}\\theta.\\end{aligned}\\ ] ]    [ lemfinitesum ] suppose that @xmath108 is a function of @xmath40 and has a finite range @xmath109 .",
    "then , for arbitrarily chosen placements @xmath7 , the inequality @xmath110 holds almost surely ( which implies @xmath111 ) .",
    "as @xmath112 , where @xmath113 for all @xmath10 , we obtain @xmath114 for all @xmath10 . as @xmath115 is nonnegative , the sequence of partial sums is non - decreasing , and lebesgue s monotone convergence theorem yields @xmath116 which implies the statement .",
    "[ leminfoconv ] suppose that and hold .",
    "then @xmath117 for arbitrarily chosen placements @xmath7 .",
    "let @xmath118 be arbitrary .",
    "as @xmath42 is compact , a finite number of the sets @xmath79 given by c2 cover it .",
    "thus , we can partition the parameter space into a finite number of subsets @xmath119 each one contained in some @xmath79 . letting the random variable @xmath108 denote the index of the subset that @xmath40 falls into , the chain rule of mutual information yields @xmath120 where @xmath121 and lemma  [ lemfinitesum ] implies that @xmath122 .",
    "let us then look at the latter term .",
    "convexity of the kullback",
    " leibler divergence yields @xmath123\\,\\mathrm{d}\\theta \\\\ & = & \\int\\!\\!\\!\\int p_{t-1}(\\theta\\mid k)p_{t-1 } \\bigl ( \\theta'\\mid k \\bigr ) \\biggl[\\int p(y_t\\mid\\theta ) \\underbrace{\\log\\frac{p(y_t\\mid\\theta ) } { p(y_t\\mid\\theta')}}_{\\le2\\varepsilon \\mathrm{~for~a.e.~}y_t}\\,\\mathrm{d}y_t \\biggr]\\,\\mathrm{d}\\theta \\,\\mathrm{d } \\theta ' \\\\ & \\le&2\\varepsilon\\end{aligned}\\ ] ] for all @xmath10 .",
    "thus , @xmath124 almost surely .",
    "as @xmath17 was arbitrary , we obtain @xmath125 .",
    "[ lemeconv ] for any measurable function @xmath126 , if the prior expectation @xmath127 is well - defined and finite , then @xmath128 exists as a finite number almost surely .",
    "the finiteness of @xmath127 implies that @xmath129 must also be finite and so @xmath130 satisfies @xmath131 for all @xmath10 .",
    "furthermore , since @xmath132 depends linearly on the posterior @xmath133 whose expectation @xmath134 equals the prior @xmath135 , we obtain @xmath136 for all @xmath10 and so @xmath137 is a martingale . as @xmath138 ,",
    "theorem  [ thmmartingaleconv ] implies that @xmath139 exists as a finite number almost surely .",
    "[ thmsc ] suppose that hold",
    ". then , conditioned on almost any @xmath140 as the true parameter value , the posteriors are strongly consistent , that is , @xmath141 for any neighborhood @xmath59 of @xmath91 .",
    "as the metric @xmath90 given by lemma  [ lemmingain ] is bounded , lemma  [ lemeconv ] implies that @xmath142 exists and is finite for all @xmath2 in a countable dense subset of @xmath42 almost surely , in which case continuity of @xmath90 implies the same for all @xmath46 .",
    "lemmas  [ lemmingain ] and [ leminfoconv ] and c4 yield @xmath143 . as @xmath90 is bounded , lebesgue s dominated convergence theorem and markov s inequality imply @xmath144 for all @xmath17 and so @xmath145 .",
    "convergence in probability implies that there exists a subsequence @xmath146 such that @xmath147 .",
    "thus , conditioned on almost any @xmath91 as the true value , we obtain @xmath148 , and the triangle inequality yields @xmath149 as we have already established that the full sequence @xmath150 almost surely converges , it now follows that the limit must almost surely be zero .",
    "thus , given any neighborhood @xmath151 of @xmath91 , markov s inequality yields @xmath152    [ lemscimpl ] suppose that hold and assume that conditioned on @xmath140 as the true parameter value , the posteriors are strongly consistent . then :    1 .   given any metric @xmath90 consistent with the topology of @xmath42 , @xmath153 2 .",
    "for any neighborhood @xmath59 of @xmath91 there exists a constant @xmath154 such that , almost surely , @xmath155 for some @xmath43 for all sufficiently large @xmath10 .",
    "let @xmath156 be the diameter of @xmath40 .",
    "the triangle inequality @xmath157 implies @xmath158 and so consistency of the posteriors yields @xmath159 for all @xmath160 , which implies @xmath161 .",
    "let us then assume that the metric @xmath90 is the one given by lemma  [ lemmingain ] and choose @xmath17 such that @xmath162 . as @xmath163 , we have @xmath164 for all sufficiently large @xmath10 , and so lemma  [ lemmingain ] and markov s inequality yield @xmath165 for some @xmath43 .",
    "the differential entropy is sensitive to the parameterization , but asymptotically , we can in most cases ignore this due to the following lemma .",
    "[ lementkleq ] suppose that the prior entropy @xmath166 is well - defined and finite .",
    "then , @xmath167\\ ] ] exists as a finite number almost surely .    as @xmath168 and @xmath169",
    "is well - defined and finite , the statement follows from lemma  [ lemeconv ] .",
    "[ lemmaxchange ] suppose that holds and let @xmath71 be defined as in .",
    "then , for any subset @xmath170 , @xmath171 for all @xmath172 . if holds , then this upper bound is finite .",
    "let @xmath173 be fixed .",
    "if @xmath174 is multiplied by @xmath175 , it can change by at most a factor of @xmath176 , and for the same reason , the normalization constant for this density is within a factor of @xmath176 from @xmath177 .",
    "the statement follows .",
    "suppose then that c2@xmath178 holds .",
    "as @xmath69 is compact , it follows that @xmath179 must be bounded .",
    "[ lementsublin ] suppose that and hold .",
    "then , for any @xmath17 , the inequality @xmath180 holds true for all sufficiently large @xmath10 .",
    "let @xmath17 be arbitrary .",
    "as in the proof of lemma  [ leminfoconv ] , we partition @xmath42 into a finite number of subsets @xmath119 such that @xmath181 for all @xmath182 , @xmath47 , and @xmath43 , where @xmath183 is some fixed point of @xmath119 .",
    "let the random variable @xmath108 denote the index of the subset that @xmath40 falls into .",
    "lemma  [ lemmaxchange ] implies that @xmath184 for all @xmath182 , which yields @xmath185 for all @xmath10 and @xmath186 .",
    "the chain rule of kullback ",
    "leibler divergence now yields @xmath187 where we may assume that @xmath188 is positive since we can drop any set @xmath119 with @xmath189 from the partition .",
    "[ leminfoupper ] suppose that @xmath190 is bounded and the family of log - likelihoods is uniformly lipschitz , that is , @xmath191 for all @xmath62 for all @xmath47 and @xmath43 .",
    "then , for arbitrarily chosen placements @xmath7 , the expected gain over @xmath10 trials is bounded by @xmath192 for some constant @xmath193 .    for each @xmath10",
    ", we can subdivide the bounded parameter space @xmath42 into @xmath194 subsets @xmath119 , each having diameter @xmath195 . letting the random variable @xmath196 denote the index of the subset that @xmath40 falls into , the chain rule of mutual information yields @xmath197 as in equation  ( [ infochain ] ) in the proof lemma  [ leminfoconv ] .",
    "in this section , we assume that :    1 .   the parameter space @xmath42 is a subset of @xmath198 .",
    "the true parameter value @xmath91 is an interior point of @xmath42 .",
    "the log - likelihood @xmath199 is twice continuously differentiable with @xmath200 and @xmath201 for all @xmath43 and @xmath47 .",
    "the family of hessians @xmath202 is equicontinuous at @xmath91 over all @xmath43 and  @xmath47 .",
    "5 .   the prior density is absolutely continuous w.r.t .",
    "the lebesgue measure with positive and continuous density at @xmath91 .    for simplicity of notation ,",
    "all statements are implicitly conditioned on @xmath91 being the true parameter value . throughout this section",
    ", we will denote the posterior mean and covariance by @xmath203 and @xmath204 .",
    "note that the expected square error @xmath205 is minimized by the mean @xmath206 .",
    "thus , if the posteriors are strongly consistent , then lemma  [ lemscimpl ] implies that @xmath207 .",
    "note also that the square error is related to the variance through the identity @xmath208 .",
    "[ lemiapprox ] suppose that and hold and @xmath42 is a bounded convex set with diameter@xmath209 . then , there exists a constant @xmath210 such that for all @xmath10 , and @xmath57 , @xmath211 where @xmath212 denotes the frobenius product @xmath213 , and @xmath214 is the fisher information matrix @xmath215 \\biggl [ \\frac{\\nabla_\\theta p(y_x\\mid\\theta)}{p(y_x\\mid\\theta ) } \\biggr]^t p(y_x\\mid \\theta)\\,\\mathrm{d}y_x.\\ ] ]    we can formally expand the mutual information as @xmath216 \\,\\mathrm{d}y_x,\\end{aligned}\\ ] ] where @xmath217 .",
    "( although @xmath218 may not be well defined here , the last line is always well - defined and equal to the mutual information . ) denoting @xmath219 , taylor s theorem yields @xmath220 where @xmath221 is some number between @xmath222 and @xmath223 .",
    "the error term is bounded by @xmath224 and as @xmath225 , we further obtain @xmath226 due to the linearity of the integral , the constant and first order terms of the expansion cancel out , leaving just [ eqapprox1 ] @xmath227 ^ 2 + \\int[p(y_x\\mid\\theta)-p_{y_x}]^2 p_t(\\theta)\\,\\mathrm{d}\\theta } { 2p_{y_x } } \\,\\mathrm{d}y_x \\\\ & = & \\int \\frac{1}2{\\operatorname{var}}_t \\biggl(\\frac{p(y_x\\mid\\theta)}{p(y_x\\mid\\hat\\theta _ t ) }",
    "\\biggr ) p(y_x\\mid\\hat\\theta_t)\\,\\mathrm{d}y_x,\\end{aligned}\\ ] ] where the error is bounded by @xmath228 for all @xmath10 , @xmath75 , and @xmath57 ( jensen s inequality applies as @xmath229 is convex ) .",
    "now taylor s theorem yields @xmath230 where @xmath231 is a convex combination of @xmath75 and @xmath2 .",
    "the coefficients are uniformly bounded by @xmath232 and @xmath233 thus , denoting the linear term by @xmath26 and the error term by @xmath234 , we obtain @xmath235 where @xmath236 \\biggl[\\frac{\\nabla_\\theta p(y_x\\mid\\hat\\theta_t)}{p(y_x\\mid \\hat\\theta_t ) } \\biggr]^t , \\\\ { \\operatorname{var}}_t(b ) & \\le&\\mathrm{e}_t \\bigl({\\vert}b{\\vert}^2 \\bigr ) \\le \\bigl(\\tfrac{1}2 c_2 \\bigr)^2 \\mathrm{e}_t \\bigl({\\vert}\\theta-\\hat \\theta_t{\\vert}^4 \\bigr ) \\le \\bigl(\\tfrac{1}2c_2 \\bigr)^2 d \\mathrm{e}_t \\bigl({\\vert}\\theta-\\hat\\theta",
    "_ t{\\vert}^3 \\bigr ) , \\\\ \\bigl{\\vert}{\\operatorname{cov}}_t(a , b ) \\bigr{\\vert}&= & \\bigl{\\vert}\\mathrm{e}_t(ab)-\\underbrace{\\mathrm { e}_t(a)}_{=0 } \\mathrm{e}_t(b ) \\bigr{\\vert}\\le \\mathrm{e}_t \\bigl ( { \\vert}a{\\vert}{\\vert}b{\\vert}\\bigr ) \\le m\\tfrac{1}2c_2 \\mathrm{e}_t",
    "\\bigl({\\vert}\\theta-\\hat \\theta_t{\\vert}^3 \\bigr).\\end{aligned}\\ ] ]    for the next theorems and lemmas , we define the following conditions that depend on a subset @xmath38 :    1 .",
    "@xmath237 for all @xmath238 , @xmath43 , and @xmath47 .",
    "@xmath239 for all @xmath238 .",
    "the maximum likelihood estimator @xmath240 is eventually well - defined and converges to @xmath91 as @xmath10 increases within indices satisfying @xmath241 , where @xmath242 is the smallest eigenvalue of @xmath243 .",
    "[ leml12 ] suppose that and hold .",
    "then , for any @xmath244 , there exists a constant @xmath245 such that and hold for any neighborhood @xmath59 of @xmath91 having diameter less than @xmath246 .",
    "[ lemoutprob ] suppose that , , and hold . if @xmath247 for some @xmath248 , then @xmath249 where @xmath250 .",
    "furthermore , conditioned on @xmath91 as the true parameter value , @xmath251 for all @xmath10 satisfying @xmath241 , where @xmath242 is the smallest eigenvalue of @xmath243 .",
    "taylor s theorem yields @xmath252 for some @xmath231 between @xmath91 and @xmath2 .",
    "thus , @xmath253 implies @xmath254 , which in turn implies @xmath255 .",
    "this is equivalent to the first statement .",
    "let us then prove the latter statement .",
    "now @xmath256 implies that @xmath257 holds for at least one component @xmath258 .",
    "but as each @xmath259 is a martingale satisfying @xmath260 and @xmath261 , theorem  [ thmazuma ] yields @xmath262 for all @xmath258 .",
    "summing these probabilities over @xmath186 so as to give an upper bound on the probability that at least one component is over the limit gives the statement .",
    "[ leml3 ] suppose that and hold .",
    "then , holds almost surely .    for any sufficiently small @xmath17",
    ", n2 implies that the set @xmath263 is a subset of @xmath42 .",
    "lemma  [ lemoutprob ] applied to this set implies that @xmath264 converges fast in probability to @xmath91 , that is , the probability @xmath265 sums to a finite value over all @xmath10 .",
    "this implies that @xmath161 .",
    "[ thmasymnorm ] suppose that hold and let hold for some @xmath266 , @xmath267 , and @xmath38 .",
    "then , the following conditions surely hold when @xmath10 increases within indices satisfying @xmath241 :    1 .",
    "the posterior density of the scaled variable @xmath268 satisfies @xmath269 where @xmath270 denotes a normal density with given mean and covariance and @xmath271 .",
    "all moments as well as the entropy of @xmath272 are asymptotically equal to those of @xmath273 , that is , the difference converges to zero .",
    "adjusting for the @xmath274 scaling factor , this implies in particular that @xmath275 and @xmath276 for sufficiently large @xmath10 for some constant @xmath277 , and so ( assuming that @xmath59 is bounded and convex ) , lemma  [ lemiapprox ] yields @xmath278    the scaled variable @xmath279 takes values in the set @xmath280 . a  taylor expansion of @xmath281 at @xmath282 yields @xmath283 for all @xmath284 satisfying @xmath285 , where @xmath286 denoting @xmath287 , we have @xmath288 for sufficiently large @xmath10 and @xmath289 .",
    "it follows @xmath290 for all @xmath291 , where @xmath292 for @xmath293 .",
    "as @xmath294 is uniformly bounded and @xmath295 , it follows @xmath296f_t(\\phi)-n_t(\\phi)\\to0 $ ] for all @xmath297 .",
    "furthermore , as @xmath298 and @xmath299 for all @xmath300 , it follows @xmath301f_t(\\phi){\\vert}\\phi{\\vert}^k \\le \\int \\exp \\biggl(c-\\frac{1}4\\mu{\\vert}\\phi{\\vert}^2 \\biggr){\\vert}\\phi{\\vert}^k < \\infty , \\qquad \\int n_t(\\phi){\\vert}\\phi{\\vert}^k < \\infty\\ ] ] for all @xmath302 , and so lebesgue s dominated convergence theorem implies that @xmath303f_t(\\phi)u(\\phi ) - n_t ( \\phi)u(\\phi ) \\bigr{\\vert}\\,\\mathrm{d}\\phi\\to0\\ ] ] for any function @xmath304 .",
    "this implies that all moments of @xmath296f_t(\\phi)$ ] are asymptotically equal to those of @xmath294 .",
    "as the eigenvalues of @xmath305 are between @xmath306 and @xmath307 , the normalization constant @xmath308 is within the constant range @xmath309 $ ] , and it follows that the moments of the normalized densities @xmath310 and @xmath273 are also asymptotically equal .",
    "similarly , as @xmath311 , where the log - factors can be bounded by polynomials of @xmath312 , it follows that the entropies of @xmath310 and @xmath273 are asymptotically equal .",
    "( note that the entropy of a density @xmath313 can be calculated as @xmath314 . )",
    "[ lemasymhess ] suppose that and hold .",
    "then , conditioned on @xmath91 as the true parameter value , @xmath315 for all @xmath43 , and @xmath316 where @xmath271 .",
    "@xmath317 \\biggl[\\frac{\\nabla_\\theta p(y_x\\mid\\theta_0)}{p(y_x\\mid\\theta _ 0 ) } \\biggr]^t - \\frac{\\nabla^2_\\theta p(y_x\\mid\\theta_0)}{p(y_x\\mid\\theta_0 ) } \\biggr\\}\\,\\mathrm{d}y_x \\\\ & & \\quad = i_x(\\theta_0 ) -",
    "\\int\\nabla^2_\\theta p(y_x\\mid\\theta_0)\\,\\mathrm{d}y_x \\\\ & & \\quad = i_x(\\theta_0 ) - \\nabla_\\theta\\int \\nabla_\\theta p(y_x\\mid \\theta_0)\\,\\mathrm{d}y_x \\\\ & & \\quad = i_x(\\theta_0 ) - \\nabla^2_\\theta \\int p(y_x\\mid\\theta_0)\\,\\mathrm{d}y_x = i_x(\\theta_0),\\end{aligned}\\ ] ]    where the interchange of the order of integration and differentiation is justified by lebesgue s dominated convergence theorem for the @xmath45-integrable dominating functions @xmath318 and @xmath319 given by @xmath320 and @xmath321 thus , denoting @xmath322 , given @xmath323 , the sequence @xmath324 of partial sums is a martingale and satisfies @xmath325 for all @xmath186 , and so theorem  [ thmmartingaleslln ] implies that @xmath326 , which is the statement .",
    "[ corvarlower ] suppose that hold .",
    "then , for all @xmath266 , almost surely @xmath327 ( meaning that the difference is positive definite ) for all sufficiently large @xmath10 , where @xmath328 . in particular , @xmath329 and @xmath330 for all sufficiently large @xmath10 satisfying @xmath331 , where @xmath332 denotes the smallest eigenvalue of @xmath305 .",
    "let @xmath266 be arbitrary and define an augmented observation model @xmath333 , where @xmath334 is independent ( given @xmath2 ) from @xmath8 .",
    "let @xmath59 be a neighborhood of @xmath91 satisfying l1 and l2 as well as l3 almost surely .",
    "if we choose the auxiliary component @xmath335 so as to obtain @xmath336 for each @xmath10 , then l3 remains satisfied given the augmented data and we also obtain @xmath337 , because the augmented data will strictly decrease the square error from the original mean , and moving to the new mean can only further reduce this error .",
    "the normalized hessian at @xmath91 for the augmented data is @xmath338 , and so , due to lemma  [ lemasymhess ] , @xmath339 for all sufficiently large @xmath10 ( although we have fiddled with the @xmath340 values , lemma  [ lemasymhess ] still applies as it does not depend on these values ) .",
    "thus , theorem  [ thmasymnorm](3 ) implies that @xmath341 ( note that theorem  [ thmasymnorm ] is a sure result and hence applies even with our fiddled @xmath340 values ) .",
    "since @xmath342 decays exponentially in the augmented model , it follows that also @xmath343 .",
    "as the eigenvalues of @xmath344 are within the range @xmath345 $ ] , the matrix inverse behaves nicely and we obtain @xmath346 , which implies @xmath347 for all sufficiently large @xmath10 for any @xmath17 .",
    "it follows @xmath348 for all sufficiently large @xmath10 .",
    "in this section , we assume that :    1 .   hold globally .",
    "some neighborhood @xmath349 of @xmath140 is homeomorphic to a subset of @xmath198 that satisfies .",
    "3 .   there exists placements @xmath350 and nonnegative weights such that @xmath351 is positive definite .",
    "4 .   the placements @xmath7 satisfy @xmath352 ( see section  [ secasymprop ] below for the definition of `` @xmath353 '' . )    first , let us say a few words about the main difficulty related to the adaptivity of the placements , namely the complications caused by any secondary modes in the posterior distribution .",
    "this issue is discussed by paninski @xcite in the context of consistency , but it seems that even after consistency has been established , the issue can not be ignored .",
    "the information maximization strategy decreases the relative weights of any secondary modes only at a rate approximately proportional to @xmath354 @xcite .",
    "therefore , any secondary mode may have a contribution proportional to @xmath354 to all moments of the posterior distribution .",
    "this means that only the first order moments of the approximating normal distribution remain asymptotically accurate , even though its total variation distance from the posterior does tend to zero .",
    "in particular , the inverse hessian of the likelihood generally _ does not _ give an asymptotically accurate approximation of the global posterior covariance .",
    "( in fact , the global posterior covariance may be undefined as @xmath42 need not have a global euclidean structure . )    for this reason , the asymptotic approximation to the expected information gain @xmath355 given by theorem  [ thmasymnorm](3 ) only applies within a sufficiently small neighborhood @xmath59 of the true parameter value , where the posterior can be shown to be asymptotically unimodal . nonetheless , even though the local and global moments are not in good agreement asymptotically , it turns out that @xmath356 is in fact in good agreement with @xmath357 on `` most trials '' . indeed",
    ", as the relative weights of any secondary modes typically decay at an exponential rate with the number of trials whose placements can distinguish between them , it follows that the placements of only a decreasing fraction of trials can be significantly affected by the secondary modes .    to formalize this intuition",
    ", we will first develop a theory for measuring asymptotic proportions .",
    "to measure subsets @xmath358 , we use the _ proportion measures _",
    "@xmath359 where @xmath360 indicates the cardinality of a set .",
    "( note that although @xmath361 is a measure in the measure - theoretic sense for any @xmath362 , the limit @xmath363 is only a _ finitely additive _ measure . ) when we say `` for almost every @xmath364 '' , we mean that the set where the statement does not hold is a null set w.r.t .",
    "we use the notation @xmath365 to mean that there exists a subset @xmath358 with @xmath366 such that @xmath367(x_k - x)\\to 0 $ ] .",
    "we also define @xmath368 and when both equal @xmath57 , we write @xmath369 .    [ lempropconj ] suppose that for all @xmath370 , the proposition @xmath371 holds for a.e . @xmath372 .",
    "then there exists an increasing sequence @xmath373 such that @xmath374 holds for a.e . @xmath372 .    for all @xmath370",
    ", @xmath375 holds for a.e .",
    "@xmath372 . thus , for all @xmath370",
    ", @xmath376 is increasing in @xmath186 and tends to one as @xmath377 . choosing @xmath378 yields the statement .",
    "0    [ lemmultirhoto ] suppose that @xmath379 is increasing in @xmath380 for all @xmath372 and @xmath381 in @xmath186 for all @xmath370 .",
    "then , there exists an increasing sequence @xmath373 such that @xmath382",
    ".    for all @xmath370 , @xmath383}{n}\\ ] ] is increasing in @xmath380 and decreasing in @xmath186 and tends to zero as @xmath377 . choosing @xmath384 yields the statement",
    ".    [ lemproplemma ] if @xmath385 is a bounded sequence , then the following are equivalent :    1 .",
    "@xmath365 , 2 .",
    "@xmath386 for a.e .",
    "@xmath372 for all @xmath17 , 3 .",
    "@xmath369 , 4 .",
    ".    if @xmath385 is not bounded , then 13 are equivalent and implied by 4 .",
    "all implications are fairly obvious . as an example , `` 2 @xmath388 1 '' follows from lemma  [ lempropconj ] applied to @xmath389 $ ] .",
    "[ lemsubharmonic ] let @xmath385 be a nonnegative sequence .",
    "if @xmath390 , then for any @xmath17 , the inequality @xmath391 holds true for almost every @xmath372 ( which implies @xmath392 ) .    assume the contrary : for some @xmath17 there exists a set @xmath358 such that @xmath393 for all @xmath394 and for some @xmath154 , @xmath395 for arbitrarily large @xmath186 .",
    "as @xmath396 as @xmath397 for all @xmath186 , we can recursively find an increasing sequence of indices @xmath398 , @xmath399 , such that @xmath400 for all @xmath401 .",
    "this yields @xmath402 which contradicts the assumption .",
    "suppose that a sequence of random variables @xmath403 $ ] satisfies @xmath404 almost surely .",
    "then , @xmath405 .    by lemma  [ lemproplemma](4 ) and",
    "the dominated convergence theorem , @xmath406    suppose that the event @xmath407 happens for a.e .",
    "@xmath372 a.s .",
    "then , @xmath408 .",
    "we use the notation @xmath409 to mean that there exists a subset @xmath358 with @xmath366 such that @xmath410(x_k - x){\\mathop{\\to}\\limits^{\\mathrm{p}}}0 $ ] .",
    "[ lemprhotoequiv ] @xmath409 if and only if @xmath411 for all @xmath17 .",
    "the `` only if '' direction is obvious . we will prove the `` if '' direction .    by definition",
    ", we have @xmath412 for a.e .",
    "@xmath372 for all @xmath370 .",
    "lemma  [ lempropconj ] then implies that there exists an increasing sequence @xmath373 such that @xmath413 for a.e .",
    "@xmath372 .",
    "[ lemasprhoto ] suppose that a sequence of random variables @xmath414 satisfies @xmath404 almost surely .",
    "then , @xmath409 .",
    "let @xmath17 be arbitrary . denoting @xmath415,\\ ] ] @xmath404 implies that @xmath416 . as @xmath417 is bounded , the dominated convergence theorem implies @xmath418 and so lemma  [ lemproplemma](4 ) yields @xmath411 .",
    "now lemma  [ lemprhotoequiv ] implies the statement .",
    "0    let @xmath385 be a nonnegative sequence and suppose that @xmath419 .",
    "then , @xmath420 for a.e .",
    "@xmath372 for all @xmath421 .",
    "@xmath422}{n } \\le\\frac{\\sum_{k=1}^n[x_k\\ge k^{-\\alpha}]k^{-\\alpha}}{n^{1-\\alpha } } \\le\\frac{\\sum_{k=1}^nx_k}{n^{1-\\alpha } } \\le \\frac{a\\log n+b}{n^{1-\\alpha}}\\to0\\ ] ]    let @xmath385 be a nonnegative sequence and suppose that for some increasing sequence @xmath423 , the inequality @xmath424 holds true for all @xmath364 .",
    "then , @xmath425 for a.e .",
    "@xmath372 for any increasing sequence @xmath426 .",
    "@xmath427}{n } \\le\\frac{\\sum_{k=1}^n[x_k\\ge z_ky_k / n]z_ky_k / n}{nz_ky_k / n } \\le\\frac{\\sum_{k=1}^nx_k}{z_ny_n } \\le \\frac{y_n}{z_ny_n}\\to0\\ ] ]      in this section , we show that the greedy information maximization strategy satisfies asymptotically a condition known as d - optimality",
    ". this condition is defined as maximality of the determinant of the fisher information matrix of the experiment at the true parameter value @xmath91 .",
    "the d - optimality criterion is special among all functionals of the information matrix ( such as the trace , minimum eigenvalue , etc . ) in that it is insensitive to linear or affine transformations of the parameter space @xmath42 .",
    "furthermore , in the asymptotically normal models that we are interested in , it yields a ( local ) approximation of the posterior entropy , which is the utility function commonly used in adaptive estimation settings .",
    "we will make use of this fact in the next section to derive an asymptotic expression of the posterior entropy .",
    "[ leminfolower ] for almost any @xmath140 satisfying , there exists a constant @xmath428 such that for all @xmath266 , given @xmath91 as the true parameter value , almost surely @xmath429 for all sufficiently large @xmath10 satisfying @xmath430 , where @xmath242 denotes the smallest eigenvalue of @xmath431 .    denoting @xmath432 , where @xmath433 and @xmath434 are given by o3",
    ", the smallest eigenvalue @xmath435 is positive .",
    "suppose that @xmath349 has diameter @xmath156 and let @xmath436 be the constant of lemma  [ lemiapprox ] applied to @xmath349 as the parameter space .",
    "the same constant also applies to any subset @xmath437 with diameter @xmath438 and as the posteriors are strongly consistent in @xmath59 , too , lemma  [ lemscimpl ] implies that @xmath439 .",
    "thus , n3 and n4 imply that @xmath440 for all @xmath57 for all sufficiently large @xmath10 .",
    "we obtain @xmath441 for some @xmath43 ( fourth inequality ) for all sufficiently large @xmath10 ( third inequality ) , where we have used the fact that @xmath442 ( sixth and third inequalities ) .",
    "let us then choose @xmath443 so that @xmath428 as defined above is positive .",
    "now , the inequality @xmath444 , which follows from the chain rule of mutual information ( cf .",
    "the proof of the next lemma ) , and @xmath445corollary  [ corvarlower ] imply @xmath446 as lemma  [ lemscimpl ] yields @xmath447 , the statement follows .",
    "[ leminfolocal ] for almost any @xmath140 satisfying , there exists a neighborhood @xmath448 of  @xmath91 such that conditioned on @xmath91 as the true parameter value , almost surely , @xmath449    by lemmas  [ lemfinitesum ] ,  [ leminfoconv ] and [ lemsubharmonic ] , almost surely , the convergences @xmath450 ; y_{x_{t+1 } } \\bigr ) & \\leadsto & 0\\end{aligned}\\ ] ] hold for all neighborhoods @xmath59 in a countable basis of the compact metrizable space @xmath42 .",
    "it follows that the same is true conditioned on almost any @xmath140 as the true parameter value .",
    "thus , given almost any @xmath140 , we can pick a neighborhood @xmath451 of @xmath91 from the countable basis such that the above convergences almost surely hold .",
    "lemma  [ leminfolower ] ( applied to @xmath452 ) almost surely yields @xmath453 for all sufficiently large @xmath10 , where we denote @xmath454 .",
    "condition  c4@xmath445lemma  [ lemscimpl ] yields @xmath455 for all sufficiently large @xmath10 , and the chain rule of mutual information yields @xmath456 ; y_{t+1 } \\bigr ) + p_t(u){\\mathrm{i}}_t ( \\theta;y_{t+1 } \\mid u ) + p_t \\bigl(u^c \\bigr ) { \\mathrm{i}}_t \\bigl ( \\theta;y_{t+1}\\mid u^c \\bigr).\\ ] ] thus , almost surely , @xmath457 ; y_{t+1})}^{\\leadsto0}t^{-1 } } { \\underbrace{{\\mathrm{i}}_t(\\theta;y_{t+1 } ) } _ { \\ge c_1t^{-1 } } } \\biggr]\\leadsto1.\\ ] ]    [ corinfohess ] conditioned on almost any @xmath91 satisfying , the sequence @xmath458 satisfies @xmath459d_t\\leadsto0 $ ] a.s . for any given @xmath266 , where @xmath332 denotes the smallest eigenvalue of @xmath460 .",
    "let us first shrink the neighborhood @xmath349 of @xmath91 as necessary to make its diameter smaller than the constant @xmath246 given by lemma  [ leml12 ] .",
    "then , let @xmath451 be the neighborhood of @xmath91 given by lemma  [ leminfolocal ] . by theorem  [ thmasymnorm](3 ) , there now exist random sequences @xmath461 and @xmath462 such that conditioned on @xmath91 as the true value , @xmath463 whenever @xmath464 .",
    "for these @xmath10 , it follows @xmath465 where lemma  [ leminfolocal ] and the inequality @xmath466 yield @xmath467 and so @xmath459d_t\\leadsto0 $ ] .    [ lemminlambda ] conditioned on almost any @xmath91 satisfying , there exists @xmath306 such that @xmath464 for infinitely many @xmath468 , where @xmath332 denotes the smallest eigenvalue of @xmath469 .",
    "let @xmath266 be arbitrary .",
    "lemma  [ leminfolower ] almost surely yields @xmath470 for all sufficiently large @xmath10 satisfying @xmath471 and lemma  [ leminfolocal ] implies that @xmath472 for a.e .",
    "@xmath10 satisfying @xmath473 .",
    "let then @xmath474 and suppose that @xmath475 .",
    "then , @xmath476 , and then exists @xmath477 such that @xmath478 for all @xmath479 .",
    "it follows @xmath480 \\frac{1}t",
    "\\ge \\frac{c}\\mu\\sum_{j = j_0}^{j_1 - 1 } \\sum_{t=2^j(1+\\rho _",
    "j)}^{2^{j+1}-1}\\frac{1}t \\ge \\frac{c}\\mu(j_1-j_0)\\log\\frac{2}{3/2},\\ ] ] and so @xmath481 for all @xmath482 , @xmath479 .",
    "since @xmath306 was arbitrary , this implies that the sum grows asymptotically superlogarithmically if @xmath475 holds for all @xmath266 .",
    "if this event has positive probability among all @xmath483 , then also @xmath484 grows superlogarithmically , contradicting lemma  [ leminfoupper ] .",
    "thus , for almost all @xmath483 satisfying , either @xmath485 is not @xmath363-measurable or @xmath486 . in either case @xmath485",
    "is infinite .",
    "[ thmdopt ] conditioned on almost any @xmath140 satisfying , almost surely , @xmath487 where @xmath488 is the convex hull of the closure of @xmath489 .",
    "the maximizer @xmath490 is unique , because the determinant is log - concave on the compact convex set @xmath488 .",
    "this result is optimal in the sense that for any strategy of choosing the placements @xmath7 ( instead of and ) , almost surely @xmath491 .",
    "the objective function is @xmath492 where @xmath493 denotes the set of eigenvalues of @xmath234 .",
    "lemma  [ lemasymhess ] implies that @xmath305 is asymptotically a convex combination of matrices in the closure of @xmath489 and so @xmath494 .",
    "let us then show that this upper bound is tight .",
    "first , we choose some representation @xmath495 of the optimum point , where @xmath496 are matrices in the closure of @xmath489 and @xmath497 .    for any symmetric real matrix @xmath305 , we have ( with slight abuse of notation ) @xmath498_{i , j}^n , \\\\",
    "{ \\bigl[\\nabla^2 f(b_t ) \\bigr ] } b & = & - \\bigl [ \\bigl(b_t^{-1 } \\bigr)_i \\bigl(b_t^{-1 } \\bigr)_j^t\\odot b \\bigr]_{i , j}^n = -b_t^{-1}bb_t^{-1 } , \\\\",
    "b \\odot \\bigl[\\nabla^2 f(b_t ) \\bigr ] b & = & -{\\operatorname{tr}}\\bigl(b_t^{-1}bb_t^{-1}b \\bigr),\\end{aligned}\\ ] ] and taylor s theorem yields @xmath499 where @xmath500 is between @xmath501 and @xmath502 . denoting @xmath503",
    ", we obtain @xmath504 for all indices @xmath10 satisfying @xmath464 for any @xmath266 . denoting by @xmath505 the eigenvalues of @xmath506 ,",
    "corollary  [ corinfohess ] now implies that @xmath507 where @xmath459d_t\\leadsto0 $ ] for any @xmath266 . noting that @xmath508",
    ", we obtain @xmath509 where @xmath510 .    from now on , in order to keep the notation clean , we will implicitly condition all probability statements on @xmath323 .",
    "let the constants @xmath511 be arbitrary and define @xmath512 .",
    "suppose that some @xmath513 satisfies @xmath514 .",
    "then , the definition of @xmath306 guarantees that @xmath515 .",
    "let then @xmath5161,\\exp(\\mu / m ) ] $ ] be arbitrary .",
    "since @xmath517 can decrease by at most @xmath518 per each step , we obtain @xmath519 for all @xmath10 between @xmath513 and @xmath520 .",
    "thus , the following inequalities hold true for all @xmath521 : @xmath522 and dividing by @xmath523 , we obtain the inequality @xmath524 where we have used the fact that @xmath525 , and where the convergence holds for any increasing sequence of indices @xmath513 satisfying @xmath514 ( which implies @xmath464 for all @xmath521 ) .",
    "this convergence is obtained by applying lemma  [ lemproplemma](3 ) to the bounded sequence @xmath459d_{\\mu , t}\\leadsto0 $ ] , which yields @xmath526d_{\\mu , t } \\bigr{\\vert}\\to0\\ ] ] ( and since @xmath527 for all @xmath10 , lebesgue s dominated convergence theorem allows us to take this limit inside the expectation ) .",
    "thus , there exists a positive constant @xmath528 such that @xmath529 for all sufficiently large @xmath513 satisfying @xmath530 . also , since the maximum change in the value of @xmath71 over one step is bounded by @xmath531 for some constant @xmath532 ( depending on @xmath306 ) , we obtain @xmath533 now markov s inequality yields @xmath534 as this upper bound on the probability sums to a finite number over the sequence @xmath535 determined by @xmath536 , the borel  cantelli lemma implies that almost surely @xmath537 holds for only finitely many indices @xmath372 satisfying @xmath538 . thus , there exists @xmath539 such that for all @xmath540 , whenever @xmath541 , the value @xmath542 will increase by at least @xmath528 on each step as @xmath186 increases .",
    "furthermore , since @xmath543 for all @xmath544 , it follows that if @xmath545 for any @xmath540 , then @xmath546 for all sufficiently large @xmath10 ( provided that @xmath547 ) . since @xmath548 can be made arbitrarily close to @xmath549 by appropriate choices of rational @xmath550 and rational @xmath551 for arbitrarily small rational @xmath552 , we almost surely obtain @xmath553 unless @xmath554 eventually stays below any number . but",
    "this would imply that @xmath555 , which is almost surely contradicted by lemma  [ lemminlambda ] .",
    "[ cordopt ] conditioned on almost any @xmath140 satisfying , there exists a neighborhood @xmath59 of @xmath91 such that @xmath556 .",
    "this is optimal in the sense that for any other strategy in place of and , almost surely @xmath557 .",
    "given o4 , theorems  [ thmdopt ] and [ thmasymnorm](2 ) imply that @xmath558 . for any other strategy , we have @xmath559 a.s . , and",
    "so theorem  [ thmasymnorm](2 ) yields @xmath560 a.s . as @xmath10 increases within indices satisfying @xmath561 for some given @xmath266 .",
    "but corollary  [ corvarlower ] implies that if we choose a sufficiently small @xmath266 , then @xmath562 also for @xmath473 , and the statement follows .",
    "as discussed in the beginning of this section , secondary modes with weights proportional to @xmath354 may remain outside @xmath59 , and they do contribute to the asymptotic variance .",
    "thus , the d - optimality result ( part 2 ) shown here is only a local form of optimality",
    ".    the situation would be different if the placements were chosen so as to minimize the determinant of the posterior covariance @xmath563 directly ( which , of course , presupposes that the parameter space has global euclidean structure ) .",
    "then , slightly more trials would be spent to decrease the weights of the secondary modes , but they should remain insignificant in proportion .",
    "thus , we can conjecture that @xmath564 would still obtain in theorem  [ thmdopt ] with @xmath565 asymptotically equal to @xmath566 , making the result globally optimal .",
    "here we use the d - optimality result to derive an expression for the asymptotic entropy .",
    "[ cortinv ] conditioned on almost any @xmath140 satisfying , for any neighborhood @xmath59 of @xmath91 , there exists a constant @xmath567 such that almost surely , @xmath568 for a.e . @xmath468 .",
    "theorem  [ thmdopt ] implies that @xmath464 for all sufficiently large @xmath10 for some @xmath266 .",
    "hence , given any @xmath17 , theorem  [ thmasymnorm](3 ) yields @xmath569 for all sufficiently large @xmath10 , where @xmath59 is any sufficiently small neighborhood of @xmath91 . combined with lemma  [ leminfolocal ]",
    ", this implies that @xmath570 for a.e .",
    "@xmath468 , and so lemma  [ lemscimpl](2 ) yields the statement .",
    "note that the statement of corollary  [ cortinv ] holds only for a.e .",
    "what happens in a sufficiently long run is that most trials are spent on increasing the accuracy around the global mode and an approximately logarithmically growing number of trials is spent on placements that decrease the weights of secondary modes .",
    "however , on any such trial there is a small probability that the weight of the secondary mode actually increases , and given a sufficiently long run , this will eventually happen arbitrarily many times in a row , making the weight of the secondary mode temporarily arbitrarily much larger than the @xmath571 bound that holds on most trials .",
    "[ thmtinvp ] conditioned on almost any @xmath140 satisfying , if the prior entropy @xmath166 w.r.t .",
    "a parameterization that is consistent with the local euclidean structure ( i.e. , the prior density @xmath572 is given w.r.t . a measure that coincides with the lebesgue measure on subsets of @xmath349 ) is well - defined and finite , then , almost surely @xmath573    let us condition everything on @xmath91 being the true value .",
    "theorem  [ thmasymnorm](2 ) implies that for some sufficiently small neighborhood @xmath59 of @xmath91 , @xmath574 lemmas [ lementkleq ] and [ lementsublin ] imply that for any @xmath17 , @xmath575 for all sufficiently large @xmath10 , and as corollary  [ cortinv ] yields @xmath576 for a.e .",
    "@xmath10 , lemma  [ lemproplemma](2 ) implies @xmath577 .",
    "the statement now follows from the chain rule of entropy @xmath578 \\bigr)}_{\\to0~\\mathrm { a.s.}},\\ ] ] where the first term satisfies @xmath579 + \\underbrace{p_t \\bigl(u^c \\bigr)}_{\\le c / t}\\frac{n}2\\log t\\leadsto h^*.\\ ] ]    [ corasyment ] suppose that hold for almost all @xmath140 and that the prior entropy @xmath166 w.r.t .",
    "a parameterization that is consistent with the local euclidean structures @xmath349 in is well - defined and finite .",
    "then , @xmath580 in other words , there exists a set @xmath358 of indices with @xmath366 such that @xmath581 as @xmath10 increases within @xmath108 .",
    "apply lemma  [ lemasprhoto ] to the statement of theorem  [ thmtinvp ] .      in kujala",
    "@xcite the adaptive sequential estimation framework is generalized to the situation where the observation of @xmath8 is associated with some random cost @xmath9 of observation , which given the value of @xmath8 , is independent of @xmath40 and the results and costs of any other observations :    @xmath582 the technical requirement that @xmath9 depends on @xmath40 only through @xmath8 is satisfied in particular if @xmath9 is a component of @xmath8 .",
    "thus , it leads to no loss of generality if the incurred costs are observable .",
    "the goal considered in kujala @xcite is maximization of the expected information gain of a sequential experiment that terminates when the total cost overruns a given budget . to achieve this goal ,",
    "the heuristic of maximizing the expected information gain @xmath583 divided by the expected cost @xmath584 on each trial is proposed . in this section ,",
    "we are able to show that this heuristic is in fact asymptotically optimal ( as the budget tends to infinity ) under essentially the same conditions that the plain information gain maximization is .",
    "thus , condition o4 is now replaced by the following :    1 .",
    "the placements satisfy @xmath585 where @xmath586 , @xmath587 , and the family of expected cost functions @xmath588 is equicontinuous at @xmath91 .    due to the assumed bounds on the expected cost @xmath589 ,",
    "condition c4 is still satisfied and so all the previous lemmas depending on it apply . together with the following lemma , these bounds also imply that the total cost grows asymptotically within linear bounds .",
    "[ lemasymcost ] suppose that holds .",
    "then , conditioned on @xmath91 as the true parameter value , @xmath590 where @xmath591 . in particular , for any @xmath592 , almost surely @xmath593 for all sufficiently large @xmath10 ( as well as @xmath594 for all @xmath10 ) .    denoting @xmath595 , given @xmath323 ,",
    "the sequence @xmath324 of partial sums is a martingale and satisfies @xmath596 for all @xmath186 , and so theorem  [ thmmartingaleslln ] implies that @xmath326 , which is the statement .",
    "next , we will generalize corollary  [ corinfohess ] for the cost - aware placements .",
    "[ corinfohess2 ] conditioned on almost any @xmath91 satisfying and , the sequence @xmath597 satisfies @xmath598d_t\\leadsto0 $ ] a.s . for any given @xmath266 , where @xmath599 denotes the smallest eigenvalue of @xmath600 and @xmath591 .",
    "let us first shrink the neighborhood @xmath349 of @xmath91 as necessary to make its diameter smaller than the constant @xmath246 given by lemma  [ leml12 ] .",
    "then , let @xmath451 be the neighborhood of @xmath91 given by lemma  [ leminfolocal ] . the boundedness and equicontinuity at @xmath91 of @xmath601 $ ] imply that conditioned on @xmath323 , almost surely , @xmath602 , uniformly over all @xmath43 . combined with theorem  [ thmasymnorm](3 ) , this implies that there exist random sequences @xmath461 and @xmath462 such that conditioned on @xmath91 as the true value , @xmath603 whenever @xmath604 . for these @xmath10",
    ", it follows @xmath605 where lemma  [ leminfolocal ] and the inequality @xmath466 yield @xmath606 and so @xmath598d_t\\leadsto0 $ ] .",
    "[ leminfocostrange ] the range of the expression @xmath607 over all sequences @xmath385 in @xmath5 and all finite @xmath10 is a dense subset of the set @xmath488 defined as the closure of the convex hull of @xmath608 furthermore , the range of the limits of all converging @xmath609 equals @xmath488 .    for any sequence @xmath610 ,",
    "we have @xmath611 and so @xmath609 is always a convex combination of elements in @xmath612 .",
    "the convex combination is not exactly linear w.r.t .",
    "the number of different @xmath57 in the sequence because of the different @xmath613 weights , but nonetheless , by varying the proportions of different @xmath57 in a sufficiently long sequence , any convex combination can be approximated arbitrarily well .",
    "[ thmdopt - myopic ] conditioned on almost any @xmath140 satisfying , , almost surely , @xmath614 where @xmath615 and @xmath488 is the convex hull of the closure of @xmath616 this is optimal in the sense that for any strategy of choosing the placements @xmath7 ( instead of and ) , almost surely @xmath491 .",
    "since @xmath612 is bounded , @xmath488 is a compact convex set and @xmath490 is well defined .",
    "lemmas [ lemasymhess ] , [ lemasymcost ] , and [ leminfocostrange ] imply that @xmath491 a.s .",
    "let us then show that this upper bound is tight .",
    "lemma [ leminfocostrange ] implies that there exists a representation @xmath617 of the optimum point @xmath490 where @xmath618 are elements of @xmath619 .    denoting @xmath620 and @xmath621 , and assuming @xmath604",
    ", we obtain @xmath622 and so , for some @xmath500 between @xmath501 and @xmath502 , we obtain @xmath623 ^ 2}{c_t+c } \\biggr ) \\\\ & \\ge&\\underbrace{\\frac{\\mathrm{e}_t(c\\mid\\theta_0)}{c_t+c}}_{\\ge ( \\gamma / m)/(t+1 ) } \\biggl(b_t^{-1 } \\odot\\frac{b}{\\mathrm{e}_t(c\\mid \\theta_0 ) } - \\frac{nc}{\\mathrm{e}_t(c\\mid\\theta_0 ) } - \\frac { c_{m,\\mu,\\gamma}}{t+1 } \\biggr).\\end{aligned}\\ ] ] denoting by @xmath505 the eigenvalues of @xmath506 , we obtain @xmath624 where corollary  [ corinfohess2 ] implies that @xmath598d_t\\leadsto0 $ ] . noting that @xmath625 , it follows @xmath626 where @xmath627 .    from here on , the proof is essentially the same as in the maximum information case .",
    "we just use @xmath628 to guarantee that @xmath629 for @xmath630 .",
    "the part 2 of the d - optimality result as well as analogs of the asymptotic entropy results follow with essentially the same proofs ( just replacing @xmath10 with @xmath631 at appropriate places ) :    conditioned on almost any @xmath140 satisfying , , there exists a neighborhood @xmath59 of @xmath91 such that @xmath632 , where @xmath633 .",
    "this is optimal in the sense that for any other strategy in place of and , almost surely @xmath634 .    conditioned on almost any @xmath140 satisfying , , if the prior entropy @xmath166 w.r.t .",
    "a parameterization that is consistent with the local euclidean structure ( i.e. , the prior density @xmath572 is given w.r.t .",
    "a measure that coincides with the lebesgue measure on subsets of @xmath349 ) is well - defined and finite , then , almost surely @xmath635 where @xmath591 .",
    "[ corasyment - myopic ] suppose that hold for almost all @xmath140 and that the prior entropy @xmath166 w.r.t .",
    "a parameterization that is consistent with the local euclidean structures @xmath349 in is well - defined and finite .",
    "then , @xmath636 where @xmath591 .",
    "in other words , there exists a set @xmath358 of indices with @xmath366 such that @xmath637 as @xmath10 increases within @xmath108 .",
    "in this section , we give specific examples illustrating the optimality results .",
    "consider the psychometric model , where an observer s unknown intensity threshold @xmath40 for detecting a stimulus of intensity @xmath57 is distributed uniformly on @xmath638 $ ] and the trial result @xmath639 for a test intensity @xmath640 $ ] is distributed as @xmath641 where @xmath642 is the psychometric function , here assumed to be the sigmoid @xmath643 for simplicity ( for more general psychometric models , see kujala and lukka @xcite , and the references therein ) .    in this model ,",
    "the fisher information of a given placement @xmath57 is calculated as @xmath644 ^ 2 = \\frac{\\psi'(\\theta - x)^2}{\\psi(\\theta - x)[1-\\psi(\\theta - x ) ] } = \\frac{\\mathrm{e}^{\\theta - x } } { [ 1+\\mathrm{e}^{\\theta - x } ] ^2}.\\ ] ] thus , for any given @xmath91 , the d - optimal value of the averaged fisher information in theorem  [ thmdopt ] is @xmath645 given by the placement @xmath646 to which the greedy algorithm eventually converges .",
    "now corollary  [ corasyment ] yields @xmath647 and this is the asymptotically optimal posterior entropy . in this example , the same expression also gives the asymptotically optimal expected utility @xmath648 , which we will next compare to that of the offline design .",
    "[ exuniform - placement ] a rigorous study of the optimal offline design is beyond the scope of the present article , so we will not go into detailed proofs here but only sketch the general ideas . suffice it to say that for an offline design for optimizing the expected utility @xmath649 , one can not do much better than to use the usual strategy of placing the trials evenly on the interval @xmath638 $ ] .",
    "( due to boundary effects , an exactly uniform distribution of placements is not really the global optimum , but for simplicity , we avoid a more complicated discussion here . )    for uniform placement of trials on @xmath638 $ ] , lemma  [ lemasymhess ] implies @xmath650,\\ ] ] where @xmath651 , and it can be shown that the asymptotic posterior entropy satisfies @xmath652 + \\frac{n}{2}\\log(2\\uppi \\mathrm{e}){\\mathop{\\longrightarrow}\\limits^{\\mathrm{a.s.}}}0,\\ ] ] which implies the asymptotic lower bound @xmath653 \\ge-\\frac{1}2\\log0.01 + \\frac{n}2\\log(2\\uppi \\mathrm{e})\\ ] ] on the posterior entropy . comparing to the asymptotically optimal posterior entropy ( [ eqpsient - optimal ] ) , it follows that the offline design needs asymptotically at least @xmath654 times as many trials as the optimal adaptive design for the same accuracy .",
    "if the range @xmath638 $ ] is doubled , then this number approximately doubles as well , so the gap to the asymptotically optimal adaptive design can be arbitrarily large .",
    "let us then return to the adaptive case and suppose that instead of a unit cost , each trial costs @xmath655\\ ] ] units .",
    "such a formulation could be based on the assumption that the observer takes four times as long to respond when the stimulus is not detected .",
    "then , the asymptotic efficiency of a placement  @xmath57 in theorem  [ thmdopt - myopic ] is characterized by the expression @xmath656}=\\frac{1}{5 + 5\\cosh(\\theta_0-x)-3\\sinh ( \\theta_0-x)}.\\ ] ] this expression is maximized by the placement @xmath657 to which the myopic algorithm eventually converges to ( provided it is within the range @xmath638 $ ] ) .",
    "thus , assuming that @xmath658 and substituting the maximizer in ( [ eqexample - optimal - cost - aware ] ) , we obtain in theorem  [ thmdopt - myopic ] the d - optimal asymptotic efficiency @xmath659 . comparing to the asymptotically optimal placement @xmath646 for unit cost ( yielding @xmath660 in ( [ eqexample - optimal - cost - aware ] ) ) ,",
    "we see that the cost - aware strategy reaches the same accuracy in @xmath661 less cost ( time ) in this example .",
    "we have derived an expression for the asymptotic efficiency of any sequential experiment design for both the standard framework with unit cost of observation as well as for the generalized framework with random costs of observation as proposed in kujala @xcite .",
    "we have shown an asymptotic d - optimality result for the greedy information optimization strategy in the standard framework and we have extended this result for the novel myopic strategy proposed in kujala @xcite for the situation with random costs of observations .",
    "these results indicate that for ( almost ) all true parameter values @xmath91 , the greedy or myopic adaptive design is asymptotically optimal among all placement strategies in a well - defined sense .    assuming the standard sequential estimation framework with unit cost of observation , lemma  [ lemasymhess ] together with the asymptotic normality result imply that the asymptotic efficiency of any given design is characterized by the average @xmath662 of the fisher information matrices @xmath663 over the sequence of placements @xmath7 and the optimality criterion of a design refers to maximality of the determinant of this averaged information matrix at the limit . for any given @xmath91",
    ", there is a distribution ( or sequence ) of placements @xmath43 yielding the d - optimal average information matrix . for ( almost )",
    "all @xmath91 , the placements of the greedy adaptive design converge to such an optimum , whereas the offline design can not adjust the distribution of the placements @xmath43 depending on the true value @xmath91 .",
    "thus , the offline design can be equally efficient for a given true value of @xmath40 , but generally not for all values @xmath140 and depending on the model , the gap in efficiency can be arbitrarily large as seen in example  [ exuniform - placement ] .",
    "the situation is essentially the same in the framework with random costs of observation , the only difference being that the convergence of the estimate of @xmath40 is not measured in relation to @xmath10 but in relation to the total cost @xmath664 of placements . in this situation ,",
    "the asymptotic efficiency is characterized by the ratio @xmath665 and the limit is again determined by the distribution ( or sequence ) of the placements @xmath43 .",
    "theorem  [ thmdopt - myopic ] shows that the myopic strategy of maximizing @xmath666 yields the asymptotically d - optimal efficiency in this situation .    however , the actual utility function assumed in both of the frameworks considered is the differential entropy , and so the most relevant asymptotic optimality criterion should be based on the asymptotic properties of the differential entropy as shown in , for example , corollaries [ corasyment ]  and  [ corasyment - myopic ] .",
    "thus , a topic for future work is finding conditions under which the results of corollaries  [ corasyment ] and [ corasyment - myopic ] can be said to be optimal among all placement strategies .",
    "[ thmstonecech ] suppose that @xmath667 is a tychonoff space",
    ". then there exists a compact space @xmath668 that embeds @xmath667 as a dense subspace . any continuous map @xmath669 , where @xmath108 is a compact hausdorff space , lifts uniquely to a continuous map @xmath670 .",
    "[ thmmartingaleconv ] let @xmath414 be a submartingale ( i.e. , @xmath671 ) and suppose that @xmath672",
    ". then , @xmath673 exists almost surely and @xmath674 .",
    "for example , @xcite , theorem  b.117 , page  648 , or @xcite , theorem  1 , page  508 .",
    "[ thmmartingaleslln ] let @xmath675 be a martingale and let @xmath676 .",
    "if @xmath677 then @xmath678 .",
    "for example , @xcite or @xcite , theorem  4 , page  519 .",
    "[ thmazuma ] let @xmath414 be a martingale and suppose that @xmath679 for all @xmath186 .",
    "then , for all @xmath680 and @xmath372 , @xmath681 and @xmath682    see @xcite , theorem 2 and note around ( 2.18 ) on page  18 , or @xcite .",
    "the author is grateful to matti vihola for many stimulating discussions .",
    "this research was supported by the academy of finland ( grant number 121855 ) ."
  ],
  "abstract_text": [
    "<S> this paper presents a general asymptotic theory of sequential bayesian estimation giving results for the strongest , almost sure convergence . </S>",
    "<S> we show that under certain smoothness conditions on the probability model , the greedy information gain maximization algorithm for adaptive bayesian estimation is asymptotically optimal in the sense that the determinant of the posterior covariance in a certain neighborhood of the true parameter value is asymptotically minimal . using this result </S>",
    "<S> , we also obtain an asymptotic expression for the posterior entropy based on a novel definition of almost sure convergence on `` most trials '' ( meaning that the convergence holds on a fraction of trials that converges to one ) . </S>",
    "<S> then , we extend the results to a recently published framework , which generalizes the usual adaptive estimation setting by allowing different trial placements to be associated with different , random costs of observation . for this setting , the author has proposed the heuristic of maximizing the expected information gain divided by the expected cost of that placement . in this paper , we show that this myopic strategy satisfies an analogous asymptotic optimality result when the convergence of the posterior distribution is considered as a function of the total cost ( as opposed to the number of observations ) .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}