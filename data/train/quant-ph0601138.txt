{
  "article_text": [
    "as early as 1935 , schrdinger wrote : _   the rejection of realism has logical consequences . in general , a variable has no definite value before i measure it ; then measuring it does not mean ascertaining the value that it has .",
    "but then what does it mean ? \" _ @xcite .",
    "as the advent of quantum mechanics solved the long standing problem of providing an adequate description for several important and unexplained experiments , the problem of realism in quantum mechanics was initially perceived mainly as a challenge to the construction of a new philosophy of natural science . in support of this perception ,",
    "is the fact that almost all later theoretical advances with experimental consequences came about without any serious progress with this very basic problem . yet",
    "at the same time , a growing number of people recognized that progress in this problem would likely have deep consequences for the quantum - classical transition , the attempt to produce a successful unification of quantum mechanics and relativity theory , and the related problem of quantum cosmology .",
    "halfway the sixties two important advances were made . in 1964",
    ", john bell showed that any local hidden variable theory will yield predictions that are at odds with quantum mechanics .",
    "a few years later , kochen and specker @xcite presented an explicit set of measurements , for which the simultaneous attribution of values for each of these measurements , leads to a logical contradiction .",
    "the two results can be regarded as opposite faces of the same coin . whereas bell s result can be verified ( or refuted ) by experiment , kochen and specker s",
    "argument shows the problem also to be a deeply - rooted theoretical one .",
    "these two results have been of such importance , that the notion of realism in quantum physics is usually considered automatically as having either the meaning of ` locally realistic ' ( bell ) , or that of ` the impossibility of attributing predetermined outcome values to the set of observables ' ( kochen and specker ) .",
    "the apparent lack of realism in quantum mechanics has been illustrated again and again by clever theoretical constructions ranging from bell - type arguments to impossible coloring games , and the countless attempts to produce an as loophole free as possible experimental verification of these arguments .",
    "however , the commonly accepted notion that measuring a variable does not mean ascertaining the value that it has , does not mean that the answer to schrdinger s question is that the occurrence of a particular outcome has _ no _ meaning .",
    "every proper quantum experiment is a testimony to the contrary , for if a single outcome has no informational content about the system at all , then how are we to derive anything at all from the sum of a great number of informationally empty statements ? whether we perform a tomographic state reconstruction , or experimentally estimate the value of a physical quantity of a system , we accept that in a well constructed experiment every outcome presents a piece of information , a piece of evidence , that brings us closer to the true state of affairs , whatever that may be . to give a more detailed answer to the question , we are in need of a model that shows _ how _ a single outcome is obtained .",
    "we will provide such a model in an attempt to understand the meaning of the occurrence of a single outcome in a quantum mechanical experiment . more specifically",
    ", we will show that an observer actively seeking to minimize his own influence on the produced outcome , will , with the aid of bayesian decision theory , give outcomes whose relative frequency converges to the born rule in a natural way .",
    "this in turn will give us a possible interpretation for the occurrence of a particular outcome .",
    "let us assume we have a system @xmath0 for which we write @xmath1 to denote its set of states , and @xmath2 for an observable that can take any single outcome out of @xmath3 distinct values in the outcome set @xmath4 .",
    "at the most trivial level , there is a counting measure on the set of outcomes . if @xmath5 denotes the set of all subsets of @xmath6 , then the probability that a measurement of observable @xmath7 on the system in a state @xmath8 yields an outcome in a given subset @xmath9 is a mapping @xmath10 \\label{prob prescript}\\]]such that for disjoint @xmath11 @xmath12 we have : @xmath13the additive property described by ( [ prob add ] ) is generally accepted both in quantum and classical probability and provides the rationale for the use of normalized states , that is , states @xmath14 that satisfy : @xmath15 in this way , ( [ prob normalized ] ) reduces the number of free parameters in state space by one .",
    "we have written @xmath16 to emphasize that it represents the probability that the outcome @xmath17 obtains when ( we know that ) the system is prepared in the state @xmath18 the classical interpretation for the arisal of probabilities , is one of a lack - of - knowledge about the precise state being measured . from a naive epistemic perspective , the outcome @xmath17 is then an objective attribute of each measured state , and the probability related to each outcome is simply the fraction of states _ having _ the @xmath17-attribute  in the ensemble of systems that we measure . as indicated in the introduction ,",
    "such an interpretation for the probabilities in quantum mechanics is problematic . even for a single spin 1/2 particle",
    ", one can show @xcite three measurements suffice to exclude such an interpretation , even without taking recourse to locality issues .      in orthodox quantum mechanics ,",
    "the state space @xmath1 is the complex hilbert space @xmath19 .",
    "the set of states of the observed system that we will consider , is the set of unit vectors in an @xmath3-dimensional hilbert space @xmath20,@xmath21as usual , the norm @xmath22 is defined through the ( sesquilinear ) inner product that we will denote @xmath23 .",
    "alternatively , one can take rays or even density operators for the states . since both lead to essentially the same results",
    ", we will stick to unit norm vectors .",
    "let @xmath24 be the set of linear operators that act on the elements of @xmath25 , then an observable @xmath2 is represented by a self - adjoint element of @xmath26:@xmath27throughout this presentation , we assume @xmath2 has a discrete , finite , non - degenerate spectrum , which implies that eigenvectors belonging to different eigenvalues are orthogonal . let @xmath28 be the set of the eigenvectors with the same eigenvalue @xmath29 as the same eigenvector @xmath30 . ] of @xmath2@xmath31    we now have @xmath32 and @xmath33 and , because the spectrum is assumed non - degenerate , we have that @xmath34 is a basis or a complete orthonormal frame . from linear algebra",
    "we know that an arbitrary element @xmath35 of @xmath20 can be written in this frame @xmath36 as : @xmath37if @xmath35 satisfies ( [ prob normalized ] ) , then it lies in @xmath38 , and the @xmath39 obey:@xmath40moreover , one can easily verify that the observable @xmath2 can be written as@xmath41    hence the observable @xmath2 is in a one - to - one correspondence with an orthonormal frame @xmath28 of eigenvectors of @xmath2 and we will represent the observable by its associated frame . throughout this paper , we reserve superscripts of states as a mnemotechnical aid for system recognition ( i.e. @xmath35 is a system state and @xmath42 the state of the measurement apparatus ) and subscripts of states to denote eigenstates .",
    "if a system is in an eigenstate corresponding to outcome @xmath43 we will denote the corresponding eigenstate as @xmath44 for an arbitrary eigenstate @xmath45 we have@xmath46thus for an eigenstate , and also for a statistical mixture of eigenstates , the classical interpretation of probability as proportion of system having the @xmath17-attribute  is tenable .",
    "the more interesting case , however , is the probability for the occurrence of an outcome @xmath47 when the system is in a general state ( [ general state ] ) , which is given by the born rule : @xmath48    the analog with the classical situation would be that @xmath35 represents a mixture of states that have attribute @xmath49 in the right proportion such that the  born rule holds .",
    "however the born rule holds even when the system is in a pure state , i.e. a state which can not be obtained as a statistical mixture of states .",
    "we will show that it is possible to regard the probabilities as arising from a lack of knowledge about the detailed state of the observer if the observer actively attempts to choose the outcome that maximizes a specific likelihood ratio that we will present shortly .",
    "let us first define what we mean by an observer . an observer is a physical system that takes a question as input , and yields in reply an outcome which is a member of a discrete set .",
    "this outcome can be freely copied , and hence communicated to many other observers . in general",
    ", this definition of observer will include the experimental setup , apparata , sensors , and the human operator .",
    "it is however quite irrelevant to our purposes whether we consider an apparatus or a detector , an animal or a human being as observer , as long as we agree that it is this system that has produced the outcome",
    ". we will furthermore assume the observer comes to this outcome through _ a physical , deterministic interaction_. that is , if we have perfect knowledge of the initial state of the system and of the potentials that act on the system , we can in principle predict the future state of the system perfectly . besides the fact that all fundamental theories of physics ( even classical chaotic systems and quantum dynamics ) postulate deterministic evolution laws , the requirement of determinism allows to derive probability as a secondary concept .",
    "so let us assume that the outcome of an observation is the result of a deterministic interaction :    @xmath50    here @xmath51 is the interaction rule , @xmath1 is the set of states of the observed system , @xmath52 the set of states of the observing system and @xmath6 the set of outcomes that observable @xmath2 can have .",
    "we will deal only with a single observable , so no further notational reference is made to the particular observable .",
    "the mapping @xmath51 encodes how an observer in a state @xmath53 observing a system in the state @xmath54 , comes to the outcome @xmath55 because our observer is deterministic , we assume @xmath51 is single - valued .",
    "probability will only arise as a lack of knowledge on deterministic events .",
    "the observer faces the task of selecting an outcome from the set @xmath6 that tells something about the system under observation .",
    "but the outcome is always formulated by the observer , it has to be encoded somehow in the state of the observer after the observation .",
    "hence the outcome _ itself _ is also an observable quantity of the post - measurement state of the observer .",
    "the outcome will then have to share its story among the two participating systems that gave rise to its existence : it will always have something to say about both the observer _ and _ the system under study . in @xcite",
    "it was shown by a diagonal argument , that even in the most simple case of a perfect observer , observing only classical properties of a system @xmath0 in the state @xmath56 is actual , iff the testing of property @xmath57 for @xmath0 in the state @xmath56 , would yield an affirmation with certainty .",
    "a property is called classical when the outcome of the observation to test that property , was predetermined by the state of the sytem ( whatever that state was ) prior to the test . for a classical property we can define a negation in the lattice of properties that is simply the boolean not .",
    "a property @xmath57 is then classical for @xmath0 iff for each state of @xmath0 the property , _ or _ its negation , is actual . for details , see @xcite .",
    "] , there exist classical properties pertaining to himself that he can not perfectly observe .",
    "more specifically , even if the observer can observe a given ( classical ) property perfectly , he can not perfectly observe _ that _ he observes this classical property perfectly .",
    "there is no logical certainty with respect to faithfulness of a single shot , deterministic observation . on the other hand ,",
    "observation is an absolutely indispensable part of doing science , hence it is only natural that every scientist believes that faithful observation can and does indeed occur .",
    "living in the real world , somewhere between the extremes of the ideal and the impossible , we wonder whether there is a strategy for the observer so that he is guaranteed that each outcome he picks uses his observational powers to the best of his ability .      rather than attempting to measure observables in a single trial of an experiment ,",
    "our observer turns to a new strategy .",
    "first he prepares an ensemble of a large number of identical system states . next he will interact with each of the members of this ensemble in turn",
    "for each and every single interaction , he will pick the outcome that somehow ` has the largest likelihood ' of pertaining to the system . by randomizing his probe state and picking the outcomes in this way",
    ", the observer hopes to restore objectivity , so that he will eventually obtain information that pertains solely to the system under observation . to calculate @xmath58 within the deterministic setting of the previous section ( [ interaction ] )",
    "is in principle straightforward .",
    "the experiment our observer will perform is a repeated one , in which the set of states of the system under study is reduced to a singleton , and the set of states for the observer is the whole of @xmath52 .",
    "the set of states for the observer that leads to a given outcome @xmath59 when the observer observes a system in the state @xmath60 will be denoted as @xmath61 : @xmath62from the single - valuedness of @xmath51 in ( [ interaction ] ) , we have for @xmath63 : @xmath64if we assume that the act of observation of an observable leads to an outcome for every state of the system investigated , we have    @xmath65    in this way @xmath51 defines in a trivial way a _ partition _ of the state space of the observer with each member @xmath66 in the partition belonging to exactly one outcome .",
    "we are now ready to introduce probability . with @xmath67",
    "a @xmath68-algebra of borel subsets of @xmath69 ( which we tacitly assume includes @xmath70 for every @xmath71 ) , we define a probability measure @xmath72 that acts on the measure space @xmath73 for any two disjoint @xmath74 in @xmath67 , we have@xmath75 \\label{prob 2 prescript } \\\\",
    "\\mu ( \\sigma _ { i}\\cup \\sigma _ { j } ) & = & \\mu ( \\sigma _ { i})+\\mu ( \\sigma _ { j } )   \\notag",
    "\\\\ \\mu ( \\sigma _ { m } ) & = & 1   \\notag\\end{aligned}\\ ] ]    in order to calculate @xmath76 we need to evaluate the probability measure over the set of states for the observer giving rise to the outcome @xmath77 when they interact with a state @xmath35 : @xmath78this last formula is fundamental to this paper .",
    "it says that for a repeated experiment on a set of identical pure system states , the probability @xmath79 is given as the ratio of observer states that , given @xmath80 tell the outcome is @xmath81 to the total number of observer states .",
    "note that the sets @xmath66 are _ not _ sets of eigenvectors in the algebraic sense of the word ) are called in eigensets in accordance with @xcite . ] . however ,",
    "if it happens to be the case that , for a given @xmath82 and for almost every @xmath83 @xmath52 , we have @xmath84 in the sense that @xmath85then , for that particular @xmath86 we have @xmath87 the vector @xmath35 thus defined , will coincide with a regular eigenvector if the state space is a hilbert space .",
    "the relation between ( [ prob 2 prescript ] ) and ( [ prob prescript ] ) is through the mapping @xmath51 and the measure @xmath88 it is obvious that ( prob 2 prescript ) is additive in @xmath6 too @xmath89because of ( [ eigpart 1 ] ) .",
    "hence , if the probabilities of ( [ prob 2 prescript ] ) and ( [ prob prescript ] ) coincide for every single outcome ( the singletons in @xmath5 ) , they will coincide for all of @xmath90 in what follows we will therefore restrict our discussion to the probability related to the occurrence of a _ single _ outcome . in conclusion ,",
    "the success of the program to model the probabilities in quantum mechanics as coming from a lack of knowledge about the precise state of the observer stands or falls with the question of defining a natural mapping @xmath91 ( which determines the outcome and hence @xmath61 ) such that the measure @xmath72 of the eigenset @xmath66 pertaining to outcome @xmath47 is identical with the probability obtained by the born rule ( [ born ] ) .",
    "we can see from ( [ probability ] ) that the system state @xmath35 can be associated with a probability in a fairly trivial way : the probability of an outcome @xmath17 when the system is in a pure state @xmath35 , is the proportion of observer states that attribute outcome @xmath17 to that state . even for a repeated measurement on a set of identical pure states , fluctuations in the outcomes can arise if there is a lack of knowledge concerning the precise state of the observer .",
    "suppose now the observer , considered as a system in its own right , is in a state @xmath42 . then in exactly the same way we can associate a probability with that state too .",
    "the operational meaning of this association is given either by a secondary observer observing an ensemble of observers in the state @xmath42 , or by the observer consistently ( mis)identifying his own state @xmath42 for a state of the system @xmath35 .",
    "we have argued that every outcome will say something about the observer , ( that is , about @xmath42 ) , and something about the system ( that is , about @xmath92 ) .",
    "the problem is that this information is mixed up in a single outcome .",
    "some outcomes will contain more information about the state of the system , and some more about the state of the apparatus .",
    "eventually , we , as operators of our detection apparatus , will have to decide whether we will retain a given outcome , or reject it .",
    "such decisions are a vital part of experimental science .",
    "for example , an outcome that is deemed too far off the limit ( so - called _ outliers _ ) , is rejected and hence excluded in the subsequent analysis .",
    "the rationale for this exclusion is that an outlier does not contain information about the system we seek to investigate , but rather that it represents a peculiarity of the measurement . in practice , rejection or acceptance of an outcome",
    "does not depend on a rational analysis , but on the common sense and expectations of the experimenter .",
    "suppose however , that the observer does have absolute knowledge about the state of the system @xmath35 and his own state @xmath93 and recognizes the fact that the outcome he delivers may eventually be rejected .",
    "the observer considers this rejection to be based on the following binary hypotheses:@xmath94    in full , the hypotheses should actually read : the outcome @xmath95 yields as a consequence of the observer attributing the state @xmath96 ( or @xmath42 ) to the system . to combat rejection",
    ", the observer chooses the outcome that maximizes the likelihood that @xmath97 prevails , _ as if the outcome he delivers will eventually be judged for acceptance or rejection by one with absolute knowledge about _",
    "_  and _ _ @xmath42 .",
    "if , in an experiment , it is possible with ( non - vanishing probability ) to get an outcome @xmath47 under either hypothesis , then a factual occurrence of this outcome in an experiment supports _ _  both _ _ hypotheses simultaneously .",
    "what really matters in deciding between @xmath97 and @xmath98 on the basis of a single outcome , is not the probability of the correctness of each hypothesis itself , but rather whether one hypothesis has become _ more likely _ than the other as a result of getting outcome @xmath47 . from bayesian decision theory @xcite",
    ", we have that all the information in the data that is relevant for deciding between @xmath97 and @xmath99 is contained in the so - called likelihood ratios or , in the binary case , the _ _  odds _ _ @xmath100:@xmath101 in this last formula , the numerator and denominator are given by ( probability ) .",
    "we are now in position to state our proposed strategy for the bayes - optimal observer .",
    "we call a system @xmath102 in a state @xmath42 a _ bayes - optimal observer _ iff , after an interaction with a system in a state @xmath86 the state of @xmath102 will transform to a state that expresses the outcome @xmath47 that corresponds to the maximal likelihood ratio @xmath100 ( [ odds ] ) .",
    "picking the outcome @xmath47 from @xmath6 that maximizes the corresponding likelihood ratio @xmath103 is simply optimizing the odds for @xmath104 given his information .",
    "this concludes our description of the observer . to see",
    "what probability arises for a repeated experiment when an observer is bayes - optimal , we need a state space .",
    "we are especially interested in complex hilbert space , but we will first have a look at statistical mixtures .      if the conditional probabilities @xmath105 are well - defined ( which we will just accept for now ) , we can make a summary of them in a single vector @xmath106 @xmath107first we define the convex closure of a number of elements @xmath108 @xmath109 @xmath110=\\{a\\in   \\mathbb{r } ^{n}:a=\\sum \\lambda _ { i}a_{i},0\\leq \\lambda _ { i}\\in   \\mathbb{r } , \\sum \\lambda _ { i}=1\\ }   \\label{convex closure}\\]]if",
    "we write @xmath111,$ ] as we shortly will , we mean the convex closure of the elements in @xmath112 the standard @xmath113 simplex @xmath114 generated by the outcome set @xmath6 is:@xmath115   \\label{convex state space}\\]]we see from ( [ stat state ] ) , ( [ normalization 2 ] ) that @xmath116 belongs to @xmath117 by identification of the axes of @xmath118 with the members of @xmath119 we have @xmath120 the free vector space generated by the outcome set @xmath6 .",
    "vectors like @xmath121 are often called ` statistical states ' or ` mixtures ' in the literature .",
    "suppose now that all we can or care to know about the system @xmath0 and the observer @xmath102 , are the statistical states , i.e. the probabilities related to the outcomes of a single experiment . within this constraint , the vector @xmath121 represents all there is to know about @xmath0 and the state spaces @xmath1 and @xmath52 reduce to @xmath122 @xmath123having identified @xmath35 with @xmath121 in this particular case , the conditional probability @xmath124 denotes the probability that outcome @xmath125 occurs when our knowledge about the system is encoded in the statistical state @xmath106@xmath126 in this section @xmath127 denotes the standard inner product in euclidean space , and with @xmath128 , we have from this last equation @xmath129for a statistical state , the magnitude of the @xmath130 coordinate equals the probability of outcome @xmath131 we have a state space ( [ convex state space ] ) , and we have a rule to extract a probability from a state ( [ prob assignment ] )",
    ", so we can characterize the sets @xmath132 let @xmath121 and @xmath133 be arbitrary states in @xmath134 written as : @xmath135by the definition of bayes - optimal observation , we have that the outcome @xmath136 is chosen , if for all @xmath137 the corresponding likelihood ratio s satisfy @xmath138 by ( [ odds ] ) and ( [ stat state ] ) , @xmath49 is chosen , iff for all @xmath139 we have : @xmath140the regions @xmath141 are found by substitution of ( [ vectors ] ) in ( [ prob assignment ] ) and then into ( [ bo char ] ) . with @xmath142 ,",
    "we obtain : @xmath143according to ( [ probability ] ) , the probability of the outcome @xmath17 for the repeated experiment on a set of identical system states , is the ratio of observer states that tell the outcome is @xmath81 to the total number of observer states .",
    "because the state space is euclidean , it is natural to take for @xmath72 the @xmath113-lebesgue measure in @xmath144 assumed to be normalized : @xmath145 the probability @xmath146 that the bayes - optimal observer obtains the outcome @xmath136 is then given by@xmath147however , because of the way we defined the statistical state , the probability is also given directly by components of the state .",
    "so the question is whether the bayes - optimal observer ( [ pbo ] ) can recover that probability , i.e. is it true that ( [ pbo ] ) equals ( [ prob assignment ] ) : @xmath148to see if this is the case , we first define the open convex closure of a number of elements @xmath149 @xmath150 as @xmath151x_{1},\\ldots , x_{n}[=\\{x\\in   \\mathbb{r } ^{n}:x=\\sum \\lambda _ { i}x_{i},0<\\lambda _ { i}\\in   \\mathbb{r } , \\sum \\lambda _ { i}=1\\ }   \\label{open closure}\\]]we can now characterize @xmath152 for the statistical state as being ` almost equal ' to @xmath153x_{1},\\ldots , x_{k-1},\\mathbf{x}(\\psi ^{s}),x_{k+1},\\ldots , x_{n } [ \\label{eigset}\\ ] ]    a graphical representation of the eigensets in the simplex state space can be found in figure ( 1 ) .",
    "let @xmath154 be defined as in ( [ eigset ] ) , @xmath155 $ ] be the convex closure of @xmath156 and @xmath152 by ( [ real eigensets ] ) , then : @xmath157\\ ] ]    the proof of this lemma can be found in appendix a. to obtain the probability ( [ pbo ] ) , we calculate the @xmath158measure of @xmath155,$ ] which is simply the @xmath113-dimensional volume of the simplex @xmath155.$ ]    if @xmath72 is a ( probability ) measure such that @xmath159 and @xmath154 is defined by the convex closure of ( [ eigset ] ) , then we have @xmath160)=t_{k}$ ]    one can calculate of the volume of a simplex straightforwardly by determinant calculus , as was done in @xcite . for completeness",
    ", we have included an alternative in the form of a simple geometric argument in appendix b. we then easily obtain :    @xmath161    by the first lemma , we have @xmath162 $ ] . because @xmath163 we have@xmath164)\\]]by the second lemma we have @xmath160)=t_{k}$ ] . to calculate @xmath165",
    "we note that @xmath166)-\\mu ( [ c_{k}^{s}]\\cap c_{k}^{s}).$ ] because @xmath155\\cap c_{k}^{s}$ ] is the collection of faces of @xmath156 a set of finite cardinality whose members have an affine dimension maximally equal to @xmath167 it is @xmath158negligible , hence we also have @xmath168 establishing the result .",
    "we see that indeed the bayes - optimal observer recovers the probability that was encoded in the statistical state : @xmath169    in this way the observer succeeds in obtaining a quantity that , in the limit of infinite measurements , depends only on the state of the system under investigation , and not on his own state .",
    "the results we have obtained for the simplex state space are identical to those in @xcite , where the scheme was proposed under the name hidden measurements  to indicate the origin of the lack of knowledge . in @xcite",
    "the eigensets are postulated _ ad hoc _ , whereas we have derived their simplicial shape from the principle of bayes - optimal observation .",
    "we will use this principle in the next section to extend the results of @xcite to systems with a complex state space .",
    "before we do so , two remarks are in order .",
    "first , we did not specify whether the state @xmath121 is the result of mixing ` pure ' components with appropriate weights , as indicated by the components of the state , or whether it represents a statistical tendency , somewhat like a propensity , of an ensemble of identical ` pure ' states to reveal itself in the different outcomes .",
    "that is , if all we are allowed to do is perform a single experiment on each member of the ensemble , then from the resulting statistics of a single observable , we can not distinguish between these two situations .",
    "in other words , if we have an urn filled with coins and we are allowed to inspect the coin only after a single throw of the coin , for every coin in the urn , then we can not know whether it is a tendency of the coin to show heads with probability 1/2 , or whether half of the coins have both sides heads and half of them have both sides tails ( or indeed a mixture of these two situations ) .",
    "secondly , it is interesting that , even for the conceptually simple statistical mixtures , the outcome assignment given by the bayes - optimal observer is _ contextual _ in the following sense : given a state for the observer and system that lead to the outcome @xmath170 then the mere interchanging of the coefficients @xmath171 and @xmath172 ( equal to the probability for the outcomes @xmath173 and @xmath136 ) can easily result in a different outcome than @xmath170 even if _ neither _ @xmath174 _ nor _ @xmath49 is equal to @xmath175 ! this can readily be verified in figure ( [ picture contextual ] )",
    ". however , the probability @xmath176 of the outcome is a function of @xmath177 only , hence the probability itself is non - contextual .",
    "conversely , given a state of an observer @xmath42 and a system state @xmath82 that interact to yield the outcome @xmath178 it is often possible to change the outcome of the bayes - optimal observer to a different outcome by interchanging suitable coefficients of the observer , _ leaving _ @xmath179 _",
    "_  untouched__. this means that changing _ only _ the observer s preferences over the outcomes @xmath173 and @xmath170 may let the bayes - optimal observer decide another outcome than @xmath49 is more optimal , even if @xmath180 and @xmath181 are all different ! this contextual aspect of the outcome assignment can here be understood as a result of the inescapable bias introduced by the state of the observer in producing a single outcome , for the coefficients of his state represent his tendencies for each outcome . perhaps somewhat paradoxically , it is precisely through the averaging procedure over all the different possibilities for this bias , that a non - contextual probability emerges . from figure ( [ picture contextual ] )",
    "we see that the contextuality of the outcome assignment depends on the classical entropy of the state .",
    "according to a well - known theorem due to shannon , the higher the entropy of the state @xmath182 the closer the coefficients of @xmath35 in ( [ stat state ] ) are to @xmath183 and the closer this state will reside near the centre of the simplex , effectively limiting the possibilities for producing a contextual outcome change by interchanging coefficients .",
    "complex hilbert spaces are of considerable interest as they arise naturally in many prominent scientific areas including quantum theory , signal analysis ( both in time - frequency and in wavelet analysis ) , electromagnetism and electronic networks , and the more recently founded shape theory kendall 1999 .",
    "the natural setting for the discrete state space in these examples , is the space of square summable functions on a hilbert space @xmath184 over the field of complex numbers .",
    "a general state of the system @xmath185 can then be written as:@xmath186where @xmath187 and @xmath188 in this case the outcome set @xmath6 consists of an orthonormal frame of complex vectors @xmath189 an observer ( or a detector , which is quite the same for our purposes ) usually has a very large number of internal degrees of freedom .",
    "accordingly it lives in a hilbert space of appropriately high dimensionality .",
    "however , by the schmidt bi - orthogonal decomposition theorem , we know we can model every possible interaction between two systems , one living in a hilbert space of dimension @xmath190 and one in a hilbert space of dimension @xmath191 with @xmath192 by an interaction of two systems , each one living in a hilbert space of dimension @xmath193 with this in mind , we model the set of states of the observer as unit vectors in @xmath25 : @xmath194    the reader should take note of the fact that , every time we speak about the state of the observer , we mean the state in the subspace indicated by the schmidt bi - orthogonal decomposition theorem .",
    "the state of the observer , to us , always means only that part of the state that is of relevance to the production of the outcome .",
    "this is especially relevant for the interpretation of sentences such as uniform distribution of initial observer states , which taken too literally , would indicate the observer is perhaps doing something completely different than observing .",
    "the state of an observer with respect to an experiment with outcome set @xmath6 can be written as ( @xmath195 ) @xmath196because the coefficients now assume complex values , they can not be interpreted as probabilities because we do not have a total order relation in the field of complex numbers .",
    "this difference also affects the deeper , deterministic level of the description in a profound way .",
    "let us explain why this is the case . for the statistical states of the former section , each eigenset is a subsimplex of the state space .",
    "a simplex is a ( very ) special case of a convex set . because the eigensets share at most a lower dimensional face , any two different eigensets ( for a fixed system state )",
    "can be separated and @xmath197 are two sets in @xmath198 then a hyperplane @xmath199 is said to _ separate _ @xmath200 and @xmath197 iff _ _  _ _ @xmath200 is contained in one of the closed halfspaces associated with @xmath201 and @xmath197 lies in the opposite closed half - space .",
    "two convex sets in @xmath202 that share at most an affine set of dimension @xmath203 can be separated by a hyperplane . ] by a single hyperplane .",
    "but in a complex space a hyperplane does not separate that space in two half - spaces .",
    "to apply the criterion of bayes - optimality , one needs to decomplexify the space to restore the order relation , but this can be done in a variety of ways . on the other hand ,",
    "this plurality of decomplexifications need not bother us too much .",
    "just as in the case of the statistical states of the former section , the observer can check the statistical validity of his outcome assignment by verifying that the probability ( in the sense of a relative frequency ) that results from repeated application of his outcome assignment , equals the _ assumed _ probability . in the same way",
    ", we can simply postulate , or even guess , a specific form of the probability assignment and justify it _ a posteriori _ :",
    "if the relative frequency of an outcome ( as a result of the observers outcome assignment , based on the bayes - optimal condition ) , converges to a limit that yields ( a monotone function of ) the very probability assignment he used to obtain those outcomes , the bayes - optimal observer knows he was bayes - optimal .",
    "let us attempt a minimal generalization of the real case ( real eigensets ) , with @xmath35 and @xmath42 defined as in ( complex state ) , ( [ complex observer state ] ) and @xmath204 : @xmath205 ) , is that we take the _ modulus _ of the coefficients and that the set contains complex vectors , which is why we have given the eigenset the superscript @xmath206 . to check the consistency of our bayes - optimal observer in the complex state space",
    ", we evaluate the lebesgue measure @xmath207 therefore we regard the measure @xmath208 in @xmath209 as the lebesgue measure @xmath72 over @xmath210 the calculation of the measure by direct integration can be avoided by use of a mapping @xmath211 that preserves measures .",
    "a measurable mapping @xmath212 between measure spaces @xmath213 and @xmath214 is called a measure - preserving mapping if , for every @xmath215 , we have @xmath216 . in appendix c",
    "we demonstrate that the component - wise ( or haddamard ) product of a complex vector with its complex conjugate , that sends elements of the complex unit - sphere @xmath217 onto the @xmath113 -simplex @xmath218 is indeed measure preserving in this sense .",
    "we have given a graphic representation of the action of @xmath211 in figure ( [ picture complex ] ) .",
    "we are now in a position to prove our main result .",
    "@xmath219    with @xmath220 defined by ( [ eig complex ] ) , and @xmath153\\omega ( x_{1}),\\ldots , \\omega ( x_{k-1}),\\omega ( \\psi ^{s}),\\omega ( x_{k+1}),\\ldots , \\omega ( x_{n})[,\\]]it is straightforward to show that ( for more details , see @xcite ) we have:@xmath221\\]]let @xmath222 and @xmath223 stand for the normalized versions of the measures @xmath72 and @xmath208 in the proof in appendix c , so that their constant of proportionality equals one : @xmath224 by definition @xmath225 , and by the previous lemma , we have@xmath226the normalized measure @xmath227 of the real simplex @xmath228 was calculated in the real state space .",
    "a completely equivalent calculation gives us@xmath229    we see that indeed the bayes - optimal observer recovers the born rule as a result of his attempt to maximize the odds with respect to the outcome that pertains to the system . to be precise , we did not maximize the odds , because substitution of the born rule for the probability in ( [ odds ] ) gives:@xmath230whereas our observer , by ( [ eig complex ] ) , calculated the ratio s : @xmath231    where the tilde denotes the fact that , strictly speaking , this is not a likelihood , because @xmath232 and @xmath233 are nt probabilities ( they are square roots of probabilities ) .",
    "yet , it is obvious that the value of @xmath181 for which ( [ qm odds ] ) and ( [ pseudo odds ] ) are maximal , is the same because one is the square of the other , which is clearly a monotone function . as a consequence",
    ", it does not matter if the bayes - optimal observer works with ( [ qm odds ] ) or with ( [ pseudo odds ] ) : repeated application of either strategy on the same pure state will make the relative frequency converge to the born rule in exactly the same way in both cases .",
    "the outcome chosen by a bayes - optimal observers , is the one that maximizes the corresponding likelihood ratio @xmath234 any monotonously increasing function of the likelihood ratio s preserves their relative order , and hence their maximum . by ( [ real eigensets ] ) and ( [ eig complex ] ) , this carries over to the coefficients of the state vectors in both the real and the complex state space .",
    "the same is true for multiplication by a phase factor , which is cancelled by taking the moduli in ( [ eig complex ] ) . as a result ,",
    "the state space is not only a vector space , it is a _ projective vector space _ : if the vectors in the state space are multiplied @xmath235 @xmath236 , this does not change the result of the decision procedure adopted by the bayes - optimal observer .",
    "there is another interesting class of transformations that leaves the bayes - optimal decision unaltered . for any @xmath35",
    ", the probability of @xmath49 is defined as : @xmath237because @xmath238,$ ] @xmath211 continuous , and because the elements of @xmath155 $ ] have finite norm , the norm of the vectors in @xmath239 is finite too .",
    "we can then apply a linear transformation to the base vectors of the state space:@xmath240    the eigenset @xmath239 will accordingly be transformed by applying @xmath241 to @xmath242 and @xmath243 by lebesgue measure theory , the volume of the transformed set is proportional to the volume of the original set , the constant of proportionality being the determinant of the transformation : @xmath244for all @xmath245 this is a classic resultspace as a real @xmath246space , for which the theorem is applicable .",
    "] , and we refer the interested reader to ( rudin 1987 , p54 ) for a proof . note that this would typically be untrue for a nonlinear transformation . as a result",
    ", all transformations with @xmath247 leave the probabilities invariant , which means we have invariance under _ _",
    "unitary _ _ transformations .",
    "intuitively this is obvious : if the probabilities have their origin in a measure on state space , then scaling , phase shifting , forming the mirror image , or ` rotating ' the entire state space , does not alter the relative proportions of the eigensets , hence the invariance . of course , it is easy to derive from the born rule that the probabilities are invariant under unitary transformations , because the born rule is the square modulus of an inner product and a unitary transformation can be defined as a linear operator that leaves the inner product invariant .",
    "our invariance principle tells us the same story at a deeper level , for not only the probabilities",
    "are invariant under unitary transformation , but also each obtained outcome will be the same whether or not we unitarily transform the eigensets .",
    "suppose we have a particular statistical mixture @xmath248of two ( pure ) states @xmath249 and @xmath250 with @xmath2510,1[$ ] .",
    "suppose furthermore that @xmath252then an observing system is said to satisfy the _ _  linear mixture property _ _",
    "iff@xmath253    in words : the probability of a mixture equals the mixture of the probabilities . does the bayes - optimal observer satisfy the linear mixture property ?",
    "well , @xmath254 is a statistical mixture , as defined in the section on bayes - optimal observation of statistical mixtures , and each of the constituents in the mixture is a pure state , as defined in the section bayes - optimal observation in hilbert space .",
    "so clearly , our bayes - optimal observer satisfies the linear mixture property .",
    "in essence , this stems from his initial states being uniformly random ( almost everywhere ) . indeed , suppose the distribution of the initial states of the observer is _ not _ uniform a.e .. then one can always find a convex region @xmath0 in state space with surface measure @xmath255 , for which the density of observer states is not equal to @xmath256 without giving a formal proof , one can see that , it is always possible to find two states @xmath249 , @xmath257 and a real number @xmath2510,1[$ ] , such that @xmath258 @xmath0 and for which the linear mixture property will be violated .",
    "the linear mixture property is essential to experimental observation : no experimenter would put his faith in the hands of a detection apparatus that manifestly fails this most basic requirement . from this perspective",
    ", the difficulty of finding an intermediate region between the classical and the quantum , originates from the lack of a principle that determines _ how _ the observer should behave in order to objectively observe the intermediate region in absence of the linear mixture property . as an example , suppose we want to determine the length of a linearly extend system . in a classical setting , we are in principle free to choose the number of outcomes , and we are allowed to make many observations before we settle on the result of a single measurement .",
    "for example , we can align the zero of the measuring rod with one end point of the system and read the outcome at the other end point as many times as we want to .",
    "if we are not satisfied with the precision that the measuring rod affords , we can pick a better one , or improve it by adding a nonius ( or vernier ) system to it . as long as we are able to do this ,",
    "we are still in a classical regime of observation . in the classical regime of observation",
    ", the distribution of observer states will be highly non - uniform .",
    "ideally , of all possible measurements , the only uncertainty we have about the state of the observer that is assumed to be of relevance to the measurement outcome , is an uncertainty of the order of the smallest number the measuring rod can represent . to decrease the uncertainty about the result ,",
    "even beyond the precision offered by the smallest number the rod can represent , it is common scientific practice to perform the measurement many times . assuming identical , independent observations , one can apply standard error theory . in the beginning of the eighties , wootters",
    "has shown ( wootters 1980 , @xcite ) , using standard error theory , that the distance ( angle ) between two states on the unit sphere in ( real ) hilbert space , is proportional to the number of maximally discriminating observations along the geodesic between those two points .",
    "this beautiful result gains in richness when considered from the point of view that the probabilities arise in a bayes - optimal way . in our search for ever more precise measurements or measurements on ever smaller constituents of nature , we eventually reach a region where we can not repeat measurements without absorbing the system or altering its state .",
    "we may not even be able to choose freely the set of outcomes for a particular measurement , as is the case in the quantum regime .",
    "it is then no longer possible to directly obtain the `` true '' value of a physical quantity , because the eigenstate of the observing system may not ( and in general will not ) coincide with the state of the system under investigation .",
    "we can not attempt the same measurement ( or one with altered eigenstates ) on the same system , because the state of the system has been altered , or even destroyed . in view of this impossibility , we are led to statistical observation on ensembles .",
    "we have shown it is possible to recover an objective probability _ if _ the distribution of observer states is uniform .",
    "we see that the best possible observation scheme in the classical regime entails a _ minimal _ uncertainty ( i.e. about the interpretation of the last digit only ) in the state of the observer , and in the quantum regime a _ maximal _",
    "uncertainty ( any outcome is in principle possible ) about the state of the observer .",
    "the consequence of such an interpretation is , that we will only be able to identify intermediate regions when we allow for a more complete description of the observing system .",
    "in essence , we need to describe how to go from this minimal to this maximal uncertainty state .",
    "there are good reasons for cautiously entering this intermediate region .",
    "some of the beautiful properties of the classical and the quantum regime will not hold .",
    "for example , the linear mixture property can not be universally satisfied .",
    "moreover , we will obtain probability distributions that depend not only on the system , but at least partially on the dynamics of the observing system .",
    "it is possible to construct explicit models that show @xcite one can identify an intermediate region where the probabilities satisfy neither the classical statistical bonferroni inequalities indicating the absence of a straightforward kolmogorovian model , nor the accardi - fedullo inequalities @xcite that constrain the set of probabilities that are derivable from a hilbert space model .",
    "this opens up a whole new area of investigation , but only if we are willing to take the bold step of abandoning the full generality of the linear mixture property .",
    "the purpose of objective observation is to obtain a probability for the outcome that depends only on the system under study .",
    "how fast the sequence of outcomes converges to this probability , depends on how well the observer manages to distinguish his state from the state of the system under study .",
    "this aspect was neglected in the previous discussion .",
    "if we apply the born rule to calculate the quantities @xmath259 and @xmath260 we imply that @xmath261 however , if the choice between @xmath97 and @xmath98 is indeed a binary decision problem , we should have:@xmath262    the reason why this is not contradictory , is because the observer chooses his outcome , _ as if _ the outcome will be judged afterwards as a binary decision problem .",
    "the observer himself has a priori no clue what the value of @xmath263 might be .",
    "but even if he would estimate the value of @xmath263 after repeated measurements , then still this knowledge can not not help him to give a more optimal outcome .",
    "to the bayes - optimal observer , knowledge of @xmath264 would merely have the effect of scaling the odds in ( [ odds ] ) by @xmath265 the choice of the outcome for the bayes - optimal observer is based on the maximal likelihood and a monotone function of the likelihoods will not change the maximum .",
    "thus we see that the specific value of @xmath263 has no influence on the actual choice .",
    "if @xmath72 is truly uniform , then , the resulting relative frequency will converge to the bayes - optimal probability that only depends on the state of the system , whatever value @xmath263 happens to have in practice .",
    "however , a small value of @xmath263 implies that for each outcome , the probability that the outcome depends on the state of the system , is small .",
    "so the expected increase in information about the system as a result of obtaining that outcome , is small too .",
    "evidently this will extend the number of measurements needed to acquire information about the system .",
    "we see that @xmath263 is a crude statistical measure for the objectivity of the observer .",
    "it represents his ability to separate interior from exterior .",
    "it turns out we can always pick an outcome that supports @xmath266 more than it supports @xmath98 iff @xmath267 . to see this ,",
    "we proceed ad absurdum .",
    "if no outcome supports @xmath97 more than it supports @xmath268 then for all @xmath174 @xmath269but then we have:@xmath270which implies @xmath271 we obtain the contradiction iff @xmath272 in words : if we can do only slightly better than completely arbitrary in letting the outcome probability depend on the system , we can guarantee the existence of an outcome that maximizes the odds and is greater than unity .",
    "in fact , for any value of @xmath263 we can find an ( almost always unique ) outcome that maximizes the odds , but when @xmath273 the maximal likelihood ratio enjoys the property of being greater than one .      the proposed principle of observation is based on a bayesian treatment of a binary decision problem , but is not used in its usual decision - theoretic form . in decision theory",
    "we seek to establish which of the hypotheses enjoys the strongest support in evidence of the data . in our case",
    ", there is no data to feed the likelihood with , because we produce the data by means of the odds . the way we employ the principle is like an inverse decision problem , as if anticipating that the result will be judged afterwards by a decision procedure performed by one with absolute knowledge of the system and observer states prior to the measurement .",
    "the possibility of applying bayesian decision theory in quantum mechanics came to me through the realization that the criterion established by aerts d. at the end of aerts 1986 to characterize the so - called hidden measurements , is a monotone function of the bayesian odds and hence leads to the same choice for the outcome . in this sense , this paper can be seen as providing a bayesian foundation for the structure of the hidden measurements as given in , for example @xcite and @xcite , and extending the results to the complex hilbert space .",
    "more recently it has come to my attention that a somewhat similar paradigm ( without reference to quantum mechanics ) is proposed in several papers that deal with visual perception by humans .",
    "the idea that the visual system is rooted in inference , can be traced back to the work of helmholtz helmholtz , who proposed the notion of _ unconscious inference_. it was only in the last decade that it was accepted and translated into a mathematical framework , not in the least because computer scientists who want to model the human vision system are faced with the apparent complexity that underlies human perception .",
    "the bayesian framework provides the tools necessary to understand and explain a wide variety of sometimes baffling visual illusions that occur in human perception @xcite .",
    "in retrospect , we have borrowed the term ` bayes - optimal ' from this literature , because the term so neatly describes the principle and it did not seem appropriate to introduce a new term .",
    "there are however some differences in the application of the principle with respect to our proposal . in the literature on visual perception ,",
    "the prior distributions are derived from real world statistics .",
    "of course , this begs the question how these prior distributions were obtained in the first place .",
    "there are two basic possibilities to obtain a prior : either a prior distribution is based on some theoretical assumption , or it is established by looking at the relative frequency of actual recordings .",
    "the first option is the one we pursued in this article , where we assumed a uniform distribution of observer states . in the second case , which is the one adopted in the literature on perception , one has the advantage of being able to explain a wide variety of visual effects in human perception , and how the priors can be adapted through the use of bayesian updating , but we can not explain observation itself .",
    "the relative frequency needed to obtain the prior , is rooted in the observation of data , which requires another prior and so on ad infinitum .",
    "one can break from this loop by reconsideration of what a state is . in the literature on perception states",
    "are considered only as ( real ) statistical mixtures , severely limiting both the applicability and the philosophical scope of the paradigm .",
    "the state , as we have defined it here , can be a complex vector , not obtainable as a mixture in principle , and yet give rise to probabilities if we attempt to observe it as good as possible .",
    "so the state is simultaneously a description of the ` mode of being ' ( the pure state that physically interacts ) , _ and _ a ` catalogue of information ' ( the probabilities the bayes - optimal observer obtains ) .",
    "the possibility that the same principle governs human perception and quantum mechanical observation , strengthens the bayes - optimal paradigm .",
    "measurement apparata and human perception can be rooted in the same principle : the attempt to relate the outcome to the object under investigation as unambiguously as possible by choosing the outcome that has the largest odds ( [ odds ] ) . by repeating the observation many times , each time randomizing the internal state of the sensor",
    ", we obtain an invariant of the observation that pertains solely to the system .    another interesting link with the existing literature",
    "was pointed out to me by thomas durt @xcite .",
    "the regions of the bohm - bub model @xcite coincide with our definition of the eigensets in the complex case ( [ eig complex ] ) .",
    "moreover , bohm and bub propose a uniform measure of states that they interpret as apparatus states .",
    "they perform the integration directly for the two dimensional case , and indicate the integration scheme can be extended to the more dimensional case .",
    "their result , like ours , is the reproduction of the born rule . from the perspective of this paper ,",
    "bayes - optimal observation yields an interpretation for the regions employed by bohm and bub .",
    "the search for a bayesian or decision - theoretic framework for quantum probability has recently been subject of a number of interesting publications ( @xcite , @xcite , @xcite , @xcite , @xcite , saunders , @xcite , and @xcite ) .",
    "one important motivation for seeking such an interpretation , is that it allows for a subjective interpretation of quantum probability by regarding the state vector as a mathematical representation of the knowledge an agent has about a system .",
    "an often heard critique of bayesian interpretations of quantum probability is that , from a strictly bayesian point of view , the state vector represents the knowledge available to the agent that deals with it .",
    "a majority of physicists rejects this notion , mainly because they feel the relative frequencies obtained in actual experiments are objective features of the system , and not of the knowledge of the agent . the bayesian pragmatic response to this",
    ", is that what can be inferred about a system always depends on one s prior knowledge of the system .",
    "however , in a theory that takes observation as a primitive concept , one can not assume to have _ a priori _ knowledge .",
    "this is what we have modelled here as the uniform distribution of initial observer states and bayes - optimal observation of an ensemble of identical states will then result in an unbiased probability .",
    "if it is physically possible to obtain unbiased estimates for a sufficient number of observables so that we can reconstruct the state vector , then , at least in an operational sense , the state can be truly assigned in an objective way to a system . besides the objective informational content of the state",
    ", the state may also represent an objective reality .",
    "this is in agreement with the fact that we started from assumption ( [ interaction ] ) ; that the state is a realistic description of the system , and it is the state of the system and the observer that physically and deterministically interact to produce the measurement outcome .",
    "systems _ are _ in a state , and that state uniquely determines every possible interaction .",
    "the state vector truly represents complete information about a system , but not merely as a collection of objective attributes , but as a representation of the possible deterministic interactions with any other system , in particular observing systems .",
    "a classically objective attribute , from this perspective , is then the limiting case where the same result follows for the vast majority of states of bayes - optimal observing systems that the system can interact with .",
    "the proposed interpretation is falsifiable in principle but there are obstacles along the way . if we succeed in preparing the relevant degrees of freedom of the states of the apparatus , we could produce a non - uniform distribution for the initial states .",
    "such a prepared apparatus would be able to distinguish some pairs of states better , and some pairs of states worse than the usual born rule allows , which means it can only be used to our advantage if we posses _ some _ information about the state prior to the measurement .",
    "it also means that the probability for the occurrence of an outcome when we measure a mixture of states , depends nonlinearly on the probabilities for each component of the mixture ; a failure of what we have called the linear mixture property .",
    "this would most likely lead to a rejection of the validity of the apparatus by the majority of experimentalists . and",
    ", we hope to have shown , in complete absence of prior information , it is not evidently desirable to deviate from a complete lack of knowledge of the apparatus state .    perhaps there is another , still deeper , reason why it is not possible to completely control the state of the observer at the quantum level .",
    "the source of probability in observation , the randomness in the state of the observer , may very well at some point become _ fundamentally _ incontrollable .",
    "logical arguments seem to defend at least the possibility of such a thesis . in @xcite",
    ", it is shown by an elegant construction , that for every observer there will be different states of himself that he can not distinguish .",
    "in @xcite it is shown that , on purely logical grounds , no observer can determine whether his observations are entirely faithful .",
    "it seems that , for every single measurement outcome , there is a trade - off between the information an observer can choose to extract about himself , and about the system he is observing .",
    "this trade - off can be quantified .",
    "it is argued in @xcite and @xcite on thermodynamical grounds , that any gain in information about a system is accompanied by an equal increase of entropy about the state of the observing system . if this is indeed the underlying structure for the occurrence of the quantum probabilistic structure , then the probabilities in quantum mechanics are indeed ontic and epistemic at the same time . from an absolute perspective",
    ", probability always arises because there is a lack of knowledge situation ; it is a measure over deterministic events .",
    "but to the one who observes , this lack of knowledge may be fundamentally irreducable .",
    "it might turn out that , after all , einstein and bohr were both right about the origin of probabilities in quantum mechanics .",
    "* acknowledgements : * i want to thank freddy de ceuninck and michiel seevinck for reading and discussing the content of this paper .",
    "this work was supported by the flemish fund for scientific research ( fwo ) project g.0362.03 .",
    "99 accardi l. , fedullo a. ( 1982 ) . on the statistical meaning of complex numbers in quantum mechanics ,",
    "nuovo cimento , * 34 * , 161 - 173    aerts d. ( 1986 ) . a possible explanation for the probabilities of quantum mechanics , j. math",
    "* 27 * , 202 - 210    aerts d. ( 1987 ) .",
    "the origin of the non - classical character of the quantum probability model , in information , complexity , and control in quantum physics , a. blanquiere , et al .",
    ", springer - verlag .",
    "aerts d. , aerts s. , durt t. , lvque o. ( 2002 ) .",
    "quantum and classical probability in the epsilon model .",
    ". phys . * 38 * , 407 - 429    aerts s. ( 2005 ) .",
    "the born rule from a consistency requirement on hidden measurements in complex hilbert space , int .",
    "* 44 * , 7 , quant - ph/0212151    aerts s. ( 2005 ) .",
    "undecidable classical properties of observers , int .",
    "* 44 * , no 12 , quant - ph/0507001    aerts s. ( 2002 ) . hidden measurements from contextual axiomatics , in probing the structure of quantum mechanics , eds .",
    "aerts d. , czachor m. , durt t. , world scientific publishers , 149 - 164    alicki r. , horodecki m. , horodecki p. , horodecki r. ( 2004 ) .",
    "thermodynamics of quantum informational systems- hamiltonian description , quant - ph/0402012    bayes t. ( 1763 ) .",
    "an essay towards solving a problem in the doctrine of chances .",
    "* 53 * , 370 - 418    bell j.s .",
    "( 1964 ) . on the einstein - podolsky - rosen paradox ,",
    "physics * 1 * , 195 - 200    bohm d. , bub j. ( 1966 ) . a proposed solution of the measurement problem in quantum mechanics by a hidden variable model , rev .",
    ", * 38 * , 453 - 469    breuer t. ( 1995 ) . the impossibility of accurate self - measurements , philosophy of science  62 , 197 - 214",
    ".    caves c.m .",
    ", fuchs c. a. , schack r. ( 2002 ) .",
    "quantum probabilities as bayesian probabilities .",
    "physical review a. 65 , 022305 .",
    "dalla chiara m. ( 1977 ) , logical self - reference , set theoretical paradoxes and the measurement problem in quantum mechanics , journal of philosophical logic , * 6 * , 331 - 347    durt t. ( 1999 ) , about the possibility of supraluminal transmission of information in the bohm - bub theory , helv .",
    "acta , * 72 * , 356 - 376    deutsch d. ( 1999 ) , quantum theory of probability and decisions , proceedings of the royal society of london , _ a455 _ , 3129    deutsch d. ( 1985 ) .",
    "quantum theory , the church - turing principle and the universal quantum computer , proceedings royal society london ser .",
    "a , 400 , 96 - 117 .",
    "fuchs c.a .",
    "quantum mechanics as quantum information ( and only a little more ) , quant - ph/0205039    geisler w.s .",
    ", kersten d. ( 2003 ) .",
    "illusion , perception and bayes , current opinion in neurobiology * 13*,150 - 158    helmholtz h. ( 1867 ) .",
    "handbuch der physiologischen optik .",
    "leipzig , voss l. , germany    jaynes e.t .",
    "probability theory , the logic of science , cambridge university press    kendall d.g .",
    "barden d. , carne t.k . , le h. ( 1999 ) .",
    "shape and shape theory , wiley series in probability and statistics    kochen s. , specker e.p .",
    "the problem of hidden variables in quantum mechanics .",
    "* 17 * , 59 - 87    lehrer e. , shmaya e. ( 2005 ) .",
    "a subjective approach to quantum probability , arxiv : quant - ph/0503066    pitowsky i. ( 2003 ) .",
    "betting on the outcomes of measurements .",
    "studies in history and philosophy of modern physics * 34 * , 395 - 414    rudin w. ( 1987 ) .",
    "real and complex analysis , third edition , mcgraw - hill    saunders s. ( 2005 ) .",
    "what is probability ? in quo vadis quantum mechanics , a. elitzur , s. dolev , n. kolenda , eds . , springer verlag    schrdinger e. ( 1935 ) .",
    "die gegenwrtige situation in der quantenmechanik , naturwissenschaften * 23 *    spekkens r.w .",
    "( 2004 ) . in defense of the epistemic view of quantum states : a toy theory , quant - ph/0401052v1    szilard l. ( 1929 ) .",
    "53 , 840 , reprint of the english translation can be found in quantum theory and measurement , eds j. a. wheeler and w. h. zurek ( princeton university press , princeton , 1983 )    wallace d. ( 2003 ) .",
    "everettian rationality : defending deutsch s approach to probability in the everett interpretation , in studies in the history and philosophy of modern physics * 34 * , 415 - 438 , quant - ph/0312157    wootters w.k .",
    "the acquisition of information from quantum measurements , phd dissertation , university of texas at austin    wootters w.k .",
    "statistical distance and hilbert space , phys rev d * 23 * , 357362",
    "let @xmath274 be the ( not necessarily normalized ) ( @xmath275 -lebesgue measure in @xmath276 .",
    "then we have@xmath277 ) & = & \\frac{\\rho _ { n-1}([c_{k}^{s}])}{\\rho _ { n-1}(\\delta _ { n-1 } ) } \\\\ & = & \\frac{\\rho _ { n-1}([x_{1},\\ldots , x_{k-1},\\mathbf{x}(\\psi ^{s}),x_{k+1},\\ldots , x_{n}])}{\\rho _ { n-1}([x_{1},\\ldots , x_{n } ] ) } \\\\ & = & \\frac{\\rho _ { n-2}\\left ( b\\right ) d(b,\\mathbf{x}(\\psi ^{s}))}{\\rho _ { n-2}\\left ( b\\right ) d(b , x_{k})}\\end{aligned}\\]]in this last equation , @xmath278 $ ] is the face shared by the two simplices , and @xmath279 the smallest euclidean distance between point @xmath280 and each point of face @xmath281 which is proportional to the norm of the orthogonal projection of @xmath280 onto a unit vector @xmath282 perpendicular to @xmath283 in @xmath202 no unique vector is perpendicular to @xmath284 ( which only has affine dimension @xmath285 ) , but as long as we stick to the same vector @xmath282 for both simplices , the same constant of proportionality will apply , and the ratio will eliminate that constant .",
    "pick the @xmath49 base vector as @xmath282 , which is obviously unit - norm and perpendicular to @xmath283 the orthogonal projection of the top of @xmath154 to @xmath282 is : @xmath286 . for @xmath144",
    "the top is the vector @xmath49 itself and its projection @xmath287 hence we have@xmath288        we start with the first inclusion .",
    "suppose @xmath133 is in one of the open @xmath290simplices @xmath156 then , by definition , there exist @xmath291 such that , with @xmath292 @xmath293on the other hand we have that @xmath294 and hence there exist @xmath295 such that ( [ stat state ] ) holds : @xmath296substitution of ( [ a ] ) into ( [ s ] ) yields@xmath297calculating the likelihood ratios ( [ odds ] ) , we obtain @xmath298 and for @xmath299 we have:@xmath300we easily see that @xmath301 iff @xmath302 which is satisfied by assumption .",
    "hence , by ( [ real eigensets ] ) every @xmath303 @xmath154 gives an outcome @xmath49 , establishing the result .",
    "for the second inclusion , suppose there exists some @xmath304 with @xmath305 .",
    "$ ] the sets @xmath154 in our theorem , as can be seen from the definition ( [ eigset ] ) , are disjoint open @xmath113-simplices .",
    "if we had defined them by means of the _ closed _ convex closure , they would maximally share the @xmath306 simplex @xmath307:$]@xmath308\\cap \\lbrack c_{k}^{s}]=\\delta _ { n-2}^{s}(j , k)\\]]assume first @xmath280 is not in the boundary of @xmath155,$ ] i.e. not in one of the lower dimensional sub - simplices @xmath309 then @xmath310 @xmath311 with @xmath312 because of the above demonstrated first inclusion we have @xmath313 and hence @xmath314 if on the other hand @xmath315 , our outcome assignment on the basis of the maximum likelihood principle is ambiguous , as there will be two equal maxima , and even more when @xmath133 is chosen in a still lower dimensional subsimplex .",
    "however , we are free to choose whatever outcome we like as long as it is one of the maxima .",
    "because the maxima coincide , these points lie in the boundary and hence the conclusion remains @xmath316.$ ]          let @xmath255 be an arbitrary open convex set in @xmath324 .",
    "evidently , @xmath325 .",
    "let @xmath284 be the pull - back of @xmath255 under @xmath326 @xmath327clearly , @xmath328hence the theorem holds for convex sets in @xmath329 .",
    "this conclusion can readily be extended to an arbitrary @xmath113-dimensional rectangle set @xmath255 in @xmath330@xmath331\\}\\]]its measure factorizes into:@xmath332next consider n - tuples of complex numbers : @xmath333clearly @xmath334 .",
    "the measure of @xmath284 can be factorized as:@xmath335hence the theorem holds for an arbitrary rectangle set @xmath336 but every open set in @xmath114 can be written as a pair - wise disjoint countable union of rectangular sets .",
    "it follows that @xmath337 for all open sets in @xmath338 .",
    "both @xmath208 and @xmath72 are finite borel measures because @xmath338 and @xmath339 are both compact subsets of a vector space of countable dimension",
    ". therefore they must be regular measures ( @xcite , p47 ) , which are completely defined by their behavior on open sets .",
    "hence @xmath211 is measure preserving for borel sets ."
  ],
  "abstract_text": [
    "<S> we propose a simple abstract formalisation of the act of observation , in which the system and the observer are assumed to be in a pure state and their interaction deterministically changes the states such that the outcome can be read from the state of the observer after the interaction . </S>",
    "<S> if the observer consistently realizes the outcome which maximizes the likelihood ratio that the outcome pertains to the system under study ( and not to his own state ) , he will be called bayes - optimal . </S>",
    "<S> we calculate the probability if for each trial of the experiment the observer is in a new state picked randomly from his set of states , and the system under investigation is taken from an ensemble of identical pure states . for classical statistical mixtures , </S>",
    "<S> the relative frequency resulting from the maximum likelihood principle is an unbiased estimator of the components of the mixture . for repeated bayes - optimal observation in case </S>",
    "<S> the state space is complex hilbert space , the relative frequency converges to the born rule . </S>",
    "<S> hence , the principle of bayes - optimal observation can be regarded as an underlying mechanism for the born rule . </S>",
    "<S> we show the outcome assignment of the bayes - optimal observer is invariant under unitary transformations and contextual , but the probability that results from repeated application is non - contextual . </S>",
    "<S> the proposal gives a concise interpretation for the meaning of the occurrence of a single outcome in a quantum experiment as the unique outcome that , relative to the state of the system , is least dependent on the state of the observe at the instant of measurement . </S>"
  ]
}