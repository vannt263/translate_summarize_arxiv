{
  "article_text": [
    "with the growing abundance of publicly available data in digital form , there has been intense research on data integration . a critical component of the data integration process is the entity resolution problem , where uncertain references in the data to real - world entities such as people , places , organizations , events , etc . , need to be resolved according to their underlying real - world entities .",
    "entity resolution is needed in order to solve the ` deduplication ' problem , where the goal is to identify and consolidate pairs of records or references within the same relational table that are duplicates of each other .",
    "it also comes up as the ` fuzzy match ' problem , where tuples from two heterogeneous databases with different keys , and possibly different schemas , need to be matched and consolidated .",
    "it goes by different names even within the data mining and database communities , including record linkage , object consolidation , and reference reconciliation .",
    "the problem has a long history , and recent years have seen significant and fruitful research on this problem .",
    "however , in spite of the widespread research interest and the practical nature of the problem , many publicly accessible databases remain unresolved , or partially resolved , at best .",
    "the popular publication databases , citeseer and pubmed , are representative examples .",
    "citeseer contains several records for the same paper or author , while author names in pubmed are not resolved at all .",
    "this is due to a variety of reasons , ranging from rapid and often uncontrolled growth of the databases and the computational and other expenses involved in maintaining resolved entities .",
    "yet , millions of users access and query such databases everyday , mostly seeking information that , implicitly or explicitly , requires knowledge of the resolved entities .",
    "for example , we may query the citeseer database of computer science publications looking for books by ` s russell ' @xcite .",
    "this query would be easy to answer if all author names in citeseer were correctly mapped to their entities .",
    "but , unfortunately , this is not the case . according to citeseer records ,",
    "stuart russell and peter norvig have written more than 100 different books together .",
    "one of the main reasons behind databases containing unresolved entities is that entity resolution is generally perceived as an expensive process for large databases .",
    "also , maintaining a ` clean ' database requires significant effort to keep pace with incoming records .",
    "alternatively , we may be searching different online social network communities for a person named ` jon doe ' . in this case",
    ", each online community may individually have records that are clean .",
    "even then , query results that return records from all of the sources aggregated together may have multiple representations for the same jon doe entity .",
    "additionally , in both cases , it is not sufficient to simply return records that match the query name , ` s. russell ' or ` jon doe ' exactly . in order to retrieve all the references correctly",
    ", we may need to retrieve records with similar names as well , such as stuart russel or john doe. and , most importantly , for the results to be useful , we need to partition the records that are returned according to the real - world entities to which they correspond . such on - the - fly partitioning of returned results is also necessary when accessing third - party or external databases that do not provide full access possibly due to privacy and other concerns , and can be accessed only via specific query interfaces .    in this paper",
    ", we propose an alternative solution for answering entity resolution queries , where we obviate the need for maintaining resolved entities in a database . instead , we investigate entity resolution at query - time , where the goal is to enable users to query an unresolved or partially resolved database and resolve the _ relevant _ entities on the fly .",
    "a user may access several databases everyday and she does not want to resolve all entities in every database that she queries . she only needs to resolve those entities that are relevant for a particular query . for instance , when looking for all books by ` stuart russell ' in citeseer , it is not useful to resolve all of the authors in citeseer . since the resolution needs to be performed at query - time ,",
    "the requirement is that the resolution process needs to be quick , even if it is not entirely accurate .",
    "though entity resolution queries have not been addressed in the literature , there has been significant progress on the general entity resolution problem .",
    "recent research has focused on the use of additional relational information between database references to improve resolution accuracy @xcite .",
    "this improvement is made possible by resolving related references or records jointly , rather than independently .",
    "intuitively , this corresponds to the notion that figuring out that two records refer to the same underlying entity may in turn give us useful information for resolving other record pairs that are related .",
    "imagine that we are trying to decide if two authors ` stuart russell ' and ` s russell ' are the same person .",
    "we can be more confident about this decision if we have already decided that their co - authors ` peter norvig ' and ` p. norvig ' are the same person .",
    "as others have done , in our earlier work @xcite , we have demonstrated using extensive experiments on multiple real and synthetic datasets that collective resolution significantly improves entity resolution accuracy over attribute - based and naive relational baselines . however , its application for query - time entity resolution is not straight - forward , and this is precisely the problem that we focus on in this paper .",
    "the first difficulty is that collective resolution works for a database as a whole and not for a specific query .",
    "secondly , the accuracy improvement comes at a considerable computation cost arising from the dependencies between related resolutions .",
    "this added computational expense makes its application in query - time resolution challenging",
    ".    in this paper , which builds on and significantly extends the work presented in , we investigate the application of collective resolution for queries .",
    "first , we formally analyze how accuracies of different decisions in collective resolution depend on each other and on the structural characteristics of the data .",
    "the recursive nature of the dependency leads naturally to a recursive ` expand and resolve ' strategy for processing queries .",
    "the relevant records necessary for answering the query are extracted by a recursive expansion process and then collective resolution is performed only on the extracted records . using our analysis , we show that the recursive expansion process can be terminated at reasonably small depths for accurately answering any query ; the returns fall off exponentially as neighbors that are further away are considered .    however , the problem is that this unconstrained expansion process can return too many records even at small depths ; and thus the query may still be impossible to resolve in real - time .",
    "we address this issue using an adaptive strategy that only considers the most informative of the related records for answering any query .",
    "this significantly reduces the number of records that need to be investigated at query time , but , most importantly , does not compromise on the resolution accuracy for the query .",
    "our specific contributions in this paper are as follows :    1 .",
    "first , we motivate and formulate the problem of query - time entity resolution .",
    "our entity resolution approach is based on a relational clustering algorithm . to the best of our knowledge ,",
    "clustering based on queries in the presence of relations has received little attention in the literature .",
    "2 .   for collective resolution using relational clustering ,",
    "we present an analysis of how the accuracy of different resolution decisions depends on each other and on the structural characteristics of the data .",
    "we introduce the notion of precision and recall for individual entities , and show how they follow a geometric progression as neighbors at increasing distances are considered and resolved .",
    "our analysis shows that collective use of relationships can sometimes hurt entity resolution accuracy .",
    "this has not been previously reported in the literature .",
    "our analysis additionally demonstrates the convergent nature of resolution performance for the recursive query - resolution strategy that we propose .",
    "3 .   for resolving queries",
    "collectively , we propose a two - phase ` expand and resolve ' algorithm .",
    "it first extracts the related records for a query using two novel expansion operators , and then resolves the query by only considering the extracted records .",
    "we then improve on this algorithm using an adaptive approach that selectively considers only the ` most informative ' ones among the related records for a query .",
    "this enables collective resolution at query - time without compromising on resolution accuracy for the query .",
    "4 .   we present experimental results on two large real - world datasets where our strategy enables collective resolution in seconds .",
    "we compare against multiple baselines to show that the accuracy achieved using collective query resolution is significantly higher than those achieved using traditional approaches .",
    "we also use synthetically generated data to demonstrate the gains of collective query resolution over a wide range of attribute and relational characteristics .",
    "we additionally show that the empirical results are in agreement with the trends predicted by our analysis of collective resolution .",
    "the rest of the paper is organized as follows . in section  [ sec : er - form ] , we formalize the relational entity resolution problem and entity resolution queries , and also illustrate these with an example . in section  [ sec",
    ": rc - er ] , we briefly review the relational clustering algorithm that we employ for collective entity resolution and then , in section  [ sec : rc - analysis ] , investigate how resolution accuracy for related entities depend on each other for collective resolution using this algorithm . in section  [ sec : query - er ] , we extend collective resolution for queries , and describe and analyze an unconstrained recursive strategy for collectively resolving a query .",
    "we then modify this approach in section  [ sec : adaptive ] and present our adaptive algorithm that extracts only the ` most informative ' references for resolving a query .",
    "we present experimental results on real and synthetic data in section  [ sec : exp ] , review related work in section  [ sec : rw ] and finally conclude in section  [ sec : concl ] .",
    "in this section , we formally introduce the entity resolution problem and also entity resolution queries , and illustrate them using a realistic example  that of resolving authors in a citation database such as citeseer or pubmed .    in the simplest formulation of the entity resolution problem",
    ", we have a collection of references , @xmath0 , with attributes @xmath1 .",
    "let @xmath2 be the unobserved domain entities .",
    "for any particular reference @xmath3 , we denote the entity to which it maps as @xmath4 .",
    "we will say that two references @xmath3 and @xmath5 are _ co - referent _ if they correspond to the same entity , @xmath6 .",
    "note that in the case of an unresolved database , this mapping @xmath7 is _ not provided_. further , the domain entities @xmath8 and even the number of such entities is not known .",
    "however , in many domains , we may have additional information about relationships between the references .",
    "to model relationships in a generic way , we use a set of hyper - edges @xmath9 .",
    "each hyper - edge connects multiple references . to capture this , we associate a set of references @xmath10 with each hyper - edge @xmath11 .",
    "note that each reference may be associated with zero or more hyper - edges .",
    "let us now look at a sample domain to see how it can be represented in our framework .",
    "consider a database of academic publications similar to dblp , citeseer or pubmed .",
    "each publication in the database has a set of author names . for every author name",
    ", we have a reference @xmath3 in @xmath12 . for any reference @xmath3 , @xmath13 records the observed name of the author in the publication .",
    "in addition , we can have attributes such as @xmath14 to record other information for each author reference that may be available in the paper .",
    "now we come to the relationships for this domain .",
    "all the author references in any publication are connected to each other by a co - author relationship .",
    "this can be represented using a hyper - edge @xmath15 for each publication and by having @xmath16 for each reference @xmath5 in the publication . if publications have additional information such as title , keywords , etc , they are represented as attributes of @xmath17 .        to illustrate , consider the following four papers , which we will use as a running example :    1 .",
    "w. wang , c. chen , a. ansari , `` a mouse immunity model '' 2 .",
    "w. wang , a. ansari , `` a better mouse immunity model '' 3 .",
    "l. li , c. chen , w. wang,``measuring protein - bound fluxetine '' 4 .",
    "w. w. wang , a. ansari , `` autoimmunity in biliary cirrhosis ''    to represent them in our notation , we have 10 references @xmath18 in @xmath12 , one for each author name , such that @xmath19 @xmath20 , etc",
    ". we also have 4 hyper - edges @xmath21 in @xmath17 , one for each paper .",
    "the first hyper - edge @xmath22 connects the three references @xmath23 , @xmath24 and @xmath25 corresponding to the names ` w. wang ' , ` c. chen ' and ` a. ansari ' .",
    "this is represented pictorially in figure  [ fig : example ] .",
    "given this representation , the * entity resolution task * is defined as the partitioning or clustering of the references according to the underlying entity - reference mapping @xmath7 .",
    "two references @xmath3 and @xmath5 should be assigned to the same cluster if and only if they are coreferent , i.e. , @xmath6 .",
    "to illustrate , assume that we have six underlying entities for our example .",
    "this is illustrated in figure  [ fig : example ] using a different shading for each entity .",
    "for example , the ` wang s of papers 1 , 2 and 4 are names of the same individual but the wang ' from paper 3 is a reference to a different person . also , the  chen s from papers 1 and 3 are different individuals",
    ". then , the correct entity resolution for our example database with @xmath26 references returns @xmath27 entity clusters : @xmath28 @xmath29 @xmath30 @xmath31 .",
    "the first two clusters correspond to two different people named ` wang ' , the next two to two different people named ` chen ' , the fifth to ` ansari ' and the last to ` li ' .    any query to a database of references",
    "is called an * entity resolution query * if answering it requires knowledge of the underlying entity mapping @xmath7 .",
    "we consider two different types of entity resolution queries .",
    "most commonly , queries are specified using a particular value @xmath32 for an attribute @xmath33 of the references that serves as a ` quasi - identifier ' for the underlying entities",
    ". then the answer to the query @xmath34 should partition or group all references that have @xmath35 according to their underlying entities . for references to people ,",
    "the name often serves as a weak or noisy identifier . for our example",
    "bibliographic domain , we consider queries specified using @xmath36 . to retrieve all papers written by some person named ` w. wang ' , we issue a query using @xmath36 and ` w. wang ' . since names are ambiguous , treating them as identifiers leads to undesirable results . in this case",
    ", it would be incorrect to return the set @xmath37 of all references with name ` w wang ' as the answer to our query .",
    "this answer does not indicate that @xmath38 is not the same person as the other two .",
    "additionally , the answer should include the reference @xmath39 for ` w w wang ' , that maps to the same entity as the author of the first paper .",
    "therefore , the correct answer to the entity resolution query on ` w wang ' should be the partition @xmath40@xmath41 .",
    "entity resolution queries may alternatively be specified using a specific reference .",
    "imagine a citeseer user looking at a paper that contains some author name .",
    "the user may be interested in looking up other papers written by the same author , even though they may not know who that author is precisely .",
    "then the correct answer to a query on the reference @xmath42 is the group of references that are coreferent to @xmath42 , or , in other words , correspond to the same underlying entity . in our example , consider a query specified using the reference @xmath23 corresponding to the name ` w. wang ' in the first paper .",
    "then the correct answer to the query is the set of references @xmath43 . to distinguish it from the first type of entity resolution query , note that it does not include the cluster @xmath44 corresponding to the other entity that also has name ` w. wang ' .",
    "this second query type may be answered by first reducing it to an instance of the first type as @xmath45 , and then selecting the entity corresponding to reference @xmath23 .",
    "we denote this as @xmath46 . in the rest of this paper",
    ", we focus only on queries of the first type .",
    "although entity resolution for queries has not been studied in the literature , the general entity resolution problem has received a lot of attention .",
    "we review related work in detail in section  [ sec : rw ] . in this section ,",
    "we briefly review the different categories of proposed approaches before discussing how they may be adapted for query - time entity resolution .    in most entity resolution applications , data labeled with the underlying entities",
    "is hard to acquire .",
    "our focus is on unsupervised approaches for resolving entities .",
    "traditionally , attributes of individual references , such as names , affiliation , etc . , for person references , are used for comparing references .",
    "a similarity measure is generally employed over attributes , and only those pairs of references that have attribute similarity above a certain threshold are considered to be co - referent .",
    "this * attribute - based entity resolution * approach ( * a * ) often runs into problems . in our example , it is hard to infer with just attributes that references @xmath23 and @xmath38 are not co - referent although they have the same name , while @xmath23 and @xmath39 _ are _ co - referent although their names are different .    when relations between references are available , they may also be taken into account for computing similarities in the * naive relational entity resolution * approach ( * nr * ) . for computing similarities between two references",
    ", this approach additionally considers the attributes of the related references when comparing the attributes of their related references . in our example , this approach returns a higher similarity between @xmath23 ( ` w .",
    "wang ' ) and @xmath39 ( ` w .",
    "w. wang ' ) than the attribute - based approach , since they have co - authors @xmath25 and @xmath47 with very similar ( identical , in this case ) names .",
    "although this approach can improve performance in some cases , it does not always work .",
    "for instance , the two ` w. wang ' references @xmath23 and @xmath38 are not co - referent , though they both have co - authors with identical names ` c. chen ' .    instead of considering the attribute similarities of the related references , the * collective entity resolution * approach @xcite takes into account the _ resolution decisions _ for them . in our previous example",
    ", the correct evidence to use for the pair of references @xmath23 and @xmath38 is that their co - author references do not map to the same entity , although they have similar names .",
    "therefore , in order to resolve the ` w. wang ' references in the collective resolution approach , it is necessary to _ resolve _ the ` c. chen ' references as well , instead of considering the similarity of their attributes .",
    "the collective entity resolution approach has recently been shown to improve entity resolution accuracy over the previous approaches but is computationally more challenging .",
    "the references can not be resolved independently . instead , any resolution decision is affected by other resolutions through hyper - edges .    in earlier work",
    ", we developed a relational clustering algorithm ( * rc - er * ) for collective entity resolution using relationships .",
    "the goal of this approach is to cluster the references according to their entities taking the relationships into account .",
    "we associate a cluster label @xmath48 with each reference to denote its current cluster membership . starting from an initial set of clusters @xmath49 of references",
    ", the algorithm iteratively merges the pair of clusters that are the most similar . to capture the collective nature of the cluster assignment , the similarity measure between pairs of clusters considers the cluster labels of the related references .",
    "the similarity of two clusters @xmath50 and @xmath51 is defined as a linear combination of their attribute similarity @xmath52 and their relational similarity @xmath53 : @xmath54 where @xmath55 ( @xmath56 ) is the combination weight . the interesting aspect of the collective approach is the dynamic nature of the relational similarity .",
    "the similarity between two references depends on the _ current _ cluster labels of their related references , and therefore changes when related references change clusters . in our example , the similarity of the two clusters containing references ` w. wang ' and ` w. w. wang ' increases once their co - author references named ` a. ansari ' are assigned to the same cluster .",
    "we now briefly review how the two components of the similarity measure are defined .",
    "[ [ attribute - similarity ] ] attribute similarity : + + + + + + + + + + + + + + + + + + + + +    for each reference attribute , we use a similarity measure that returns a value between @xmath57 and @xmath58 for two attribute values indicating the degree of similarity between them .",
    "several sophisticated similarity measures have been developed for names , and popular tf - idf schemes may be used for other textual attributes such as keywords .",
    "the measure that works best for each attribute may be chosen .",
    "finally , a weighted linear combination of the similarities over the different attributes yields the combined attribute similarity between two reference clusters .",
    "[ [ relational - similarity ] ] relational similarity : + + + + + + + + + + + + + + + + + + + + + +    relational similarity between two clusters considers the similarity of their ` cluster neighborhoods ' .",
    "the neighborhood of each cluster is defined by the hyper - edges associated with the references in that cluster .",
    "recall that each reference @xmath42 is associated with one or more hyper - edges in @xmath17 . therefore , the hyper - edge set @xmath59 for a cluster @xmath60 of references is defined as @xmath61 this set defines the hyper - edges that connect a cluster @xmath60 to other clusters , and are the ones that relational similarity needs to consider . to illustrate , when all the references in our running example have been correctly clustered as in figure  [ fig : example](b ) , the hyper - edge set for the larger ` wang ' cluster is @xmath62 , which are the hyper - edges associated with the references @xmath23 , @xmath63 and @xmath39 in that cluster .",
    "given the hyper - edge set for any cluster @xmath60 , the neighborhood @xmath64 of that cluster @xmath60 is the set of clusters labels of the references spanned by these hyper - edges : @xmath65 for our example ` wang ' cluster , its neighborhood consists of the ` ansari ' cluster and one of the ` chen ' clusters , which are connected by its edge - set .",
    "then , the relational similarity measure between two clusters , considers the similarity of their cluster neighborhoods .",
    "the neighborhoods are essentially sets ( or multi - sets ) of cluster labels and there are many possible ways to define the similarity of two neighborhoods .",
    "the specific similarity measure that we use for our experiments in this paper is jaccard similarity and @xmath66 is defined as @xmath67 : @xmath68    [ [ clustering - algorithm ] ] clustering algorithm : + + + + + + + + + + + + + + + + + + + + +    given the similarity measure for a pair of clusters , a greedy relational clustering algorithm can be used for collective entity resolution .",
    "figure  [ fig : rc - algo ] shows high - level pseudo - code for the complete algorithm .",
    "aaaaaaaaaaaa = aaaaaa = aaaaaaaa = aaaaaa > algorithm rc - er ( reference set @xmath69 ) + 1 . find similar references in @xmath69 using blocking + 2 .",
    "initialize clusters using bootstrapping +   + 3 . for clusters",
    "@xmath70 such that similar@xmath71 + 4 .",
    "insert @xmath72 into priority queue +   + 5 . while priority queue not empty + 6 .",
    "extract @xmath73 from queue + 7 .",
    "if @xmath74 less than threshold , then stop + 8 .",
    "merge @xmath50 and @xmath51 to new cluster @xmath75 + 9 .",
    "remove entries for @xmath50 and @xmath51 from queue + 10 .",
    "for each cluster @xmath76 such that similar@xmath77 + 11 .",
    "insert @xmath78 into queue + 12 . for each cluster @xmath79 neighbor of @xmath75 + 13 . for @xmath76",
    "such that similar@xmath80 + 14 .",
    "update @xmath81 in queue +    the algorithm first identifies the candidate set of potential duplicates using a ` blocking ' approach @xcite .",
    "next , it initializes the clusters of references , identifies the ` similar ' clusters  or potential merge - candidates  for each cluster , inserts all the merge - candidates into a priority queue and then iterates over the following steps . at each step",
    ", it identifies the current ` closest pair ' of clusters from the candidate set and merges them to create a new cluster .",
    "it identifies new candidate pairs and updates the similarity measures for the ` related ' cluster pairs .",
    "this is the key step where evidence flows from one resolution decision to other related ones and this distinguishes relational clustering from traditional clustering approaches .",
    "the algorithm terminates when the similarity for the closest pair falls below a threshold or when the list of potential candidates is exhausted .",
    "the algorithm is efficiently implemented to run in @xmath82 time for @xmath83 references where each ` block ' of similar names is connected to @xmath84 other blocks through the hyper - edges .      in previous work",
    ", we ( and others ) have shown that collective resolution using relationships improves entity resolution accuracy significantly for offline cleaning of databases .",
    "so , naturally , we would like to use the same approach for query - time entity resolution as well .",
    "however , while the attribute - based and naive relational approaches discussed earlier can be applied at query - time in a straight - forward fashion , that is not the case for collective resolution .",
    "two issues come up when using collective resolution for queries .",
    "first , the set of references that influence the resolution decisions for a query need to be identified .",
    "when answering a resolution query for ` s. russell ' using the attribute - based approach , it is sufficient to consider all papers that have ` s. russell ' ( or , similar names ) as author name . for collective resolution , in contrast",
    ", the co - authors of these author names , such as ` p. norvig ' and ` peter norvig ' , also need to be clustered according to their entities .",
    "this in turn requires clustering their co - authors and so on .",
    "so the first task is to analyze these dependencies for collective resolution and identify the references in the database that are relevant for answering a query .",
    "but this is not enough .",
    "the set of references influencing a query may be extremely large , but the query still needs to be answered quickly even though the answer may not be completely accurate .",
    "so the second issue is performing the resolution task at query - time .",
    "these are the two problems that we address in the next few sections .",
    "for collective entity resolution , we have seen that resolution performance for the query becomes dependent on the resolution accuracy of the related entities . before we can analyze which other references influence entity resolution for the query and to what extent , we need to analyze the nature of this dependence for collective resolution in general . in this section , we identify the structural properties of the data that affect collective entity resolution and formally model the interdependent nature of the resolution performance .",
    "this analysis also helps us to understand when collective resolution using relational clustering helps , and , equally importantly , when it has an adverse effect as compared against traditional attribute - based resolution .",
    "the goal of an entity resolution algorithm is to partition the set @xmath85 of references into a set of clusters @xmath86 according to the underlying entities @xmath87 .",
    "the accuracy of the resolution depends on how closely the separation of the references into clusters corresponds to the underlying entities .",
    "we consider two different measures of performance .",
    "the first measure is _ recall _ for each entity . for any entity @xmath88",
    ", recall counts how many pairs of references corresponding to @xmath88 are correctly assigned to the same computed cluster .",
    "the second measure is _ precision _ for each computed cluster . for any cluster @xmath50",
    ", precision counts how many pairs of references assigned to @xmath50 truly correspond to the same underlying entity .",
    "( alternatively , _ imprecision _ measures how many pairs of references assigned to the cluster do not correspond to the same entity . ) in the next two subsections , we analyze how these two performance metrics are influenced , first , by the attribute values of the references , and then , by the observed relationships between them .",
    "first , consider an entity resolution algorithm that follows the traditional attribute - based approach and the analysis of its performance .",
    "such an algorithm only considers the attributes of individual references .",
    "it uses a similarity measure defined over the domain of attributes , and considers pair - wise attribute similarity between references for resolving them .",
    "let us define two references to be @xmath89-similar if their attribute - similarity is at least @xmath89 . then , given a resolution threshold @xmath89 , the attribute - based approach assigns a pair of references to the same cluster if and only if they are @xmath89-similar . to illustrate using our example , using any similarity measure defined over names and an appropriately determined similarity threshold @xmath89 ,",
    "the attribute - based approach would assign the three ` w. wang ' references ( @xmath23 , @xmath63 , @xmath38 ) to one cluster @xmath90 and the ` w. w. wang ' reference ( @xmath39 ) to a different cluster @xmath91 .",
    "this resolution of the wang references is not perfect in terms of precision or recall , since references @xmath23 , @xmath63 and @xmath39 map to one entity @xmath92 and @xmath38 maps to a second entity @xmath93 .",
    "cluster @xmath90 has precision less than 1 , since it incorrectly includes references for two different entities , and recall is less than 1 for entity @xmath92 , since its references are dispersed over two different clusters .    in order to analyze the performance of this attribute - based resolution approach given an arbitrary dataset",
    ", we now characterize a dataset in terms of the attribute values of its references .",
    "intuitively , the attribute - based approach works well when the references corresponding to the same entity are similar in terms of their attributes , and when the references corresponding to different entities are not . to capture this formally ,",
    "we define two probabilities that measure the attribute - similarity of references that map to the same entity , and the attribute - similarity of those that map to different entities :    * * attribute identification probability * @xmath94 : the probability that a pair of references chosen randomly from those corresponding to entity @xmath95 are @xmath89-similar to each other . * * attribute ambiguity probability * @xmath96 : the probability that a pair of references chosen randomly such that one corresponds to entity @xmath92 and the other to entity @xmath93 are @xmath89-similar to each other .    to illustrate using the four ` wang ' references , @xmath23 , @xmath63 and @xmath39 correspond to the same entity @xmath92 and @xmath38 corresponds to a different entity @xmath93 .",
    "also , assume that for some similarity measure for names and an appropriate threshold @xmath89 , references @xmath23 , @xmath63 and @xmath38 are @xmath89-similar to each other .",
    "then , of the 3 pairs of references corresponding to entity @xmath92 , only one ( @xmath23 and @xmath63 ) is @xmath89-similar , so that the attribute identification probability @xmath97 for entity @xmath92 is 0.33 . on the other hand , of the three pairs of references such that one maps to @xmath92 and the other to @xmath93 , two ( @xmath23 and @xmath38 , @xmath63 and @xmath38 ) are @xmath89-similar .",
    "this means that the attribute ambiguity probability @xmath98 between @xmath92 and @xmath93 is 0.66 .",
    "as can be seen from the above example , the performance of the attribute - based clustering algorithm can be represented in terms of these two probabilities . for any specified threshold @xmath89 ,",
    "the pairs of references for any entity that are correctly recalled are the ones that are @xmath89-similar , which is exactly what @xmath99 captures .",
    "therefore , the recall for any domain entity @xmath95 is @xmath100 . on the other hand , consider the cluster assignment for all the references that correspond to two entities @xmath92 and @xmath93 .",
    "the pairs that are incorrectly clustered together are those that correspond to two different entities , and yet are @xmath89-similar .",
    "this is what @xmath98 captures .",
    "therefore the imprecision of the cluster assignment of reference pairs corresponding to entities @xmath92 and @xmath93 is @xmath101 .",
    "alternatively , the precision is given by @xmath102 .",
    "now , we consider the collective entity resolution approach that additionally makes use of relationships , and analyze its impact on entity resolution accuracy . recall that we have a set @xmath103 of observed co - occurrence relationships between the references .",
    "such co - occurrences between references are useful for entity resolution when they result from strong ties or relations between their underlying entities .",
    "specifically , we assume that references to any entity @xmath88 co - occur frequently with references to a small set of other entities @xmath104 , which we call the entity neighbors , denoted @xmath105 , of entity @xmath88 .",
    "assuming such a neighborhood relationship among the underlying entities allows us to analyze the performance of the relational clustering approach .",
    "for those reference pairs that are @xmath89-similar in terms of attributes , the attribute evidence is enough for resolution . but",
    "now , unlike attribute - based clustering , any pair of references that are @xmath106-similar in terms of attributes , for some @xmath107 , are considered as candidates for being clustered together .",
    "not all of them actually get assigned to the same cluster . for reference pairs that are in the ring of uncertainty between @xmath89 and @xmath106 ,",
    "their relationships play a role in determining if they are similar enough , and consequently , if they should be clustered together . specifically",
    ", if references @xmath3 and @xmath5 co - occur through hyper - edge @xmath108 and references @xmath109 and @xmath110 co - occur through hyper - edge @xmath111 , then the relational similarity of the pair ( @xmath3 , @xmath109 ) is more when ( @xmath5 , @xmath110 ) belong to the same cluster . in general , multiple such relationships may be needed for tipping the balance , but for simplicity , we assume for now that a single pair of related references is sufficient .",
    "in other words , @xmath3 and @xmath109 get assigned to the same cluster if @xmath5 and @xmath110 are in the same cluster .",
    "we now analyze the impact that this approach has on entity resolution performance . without loss of generality ,",
    "assume that the @xmath112 pair get clustered together first by the relational clustering algorithm .",
    "this results in the other pair @xmath113 also getting clustered at some later iteration by considering this relational evidence . to see",
    "if this is accurate , we consider two situations , as we did with attribute evidence .",
    "the first is shown in figure  [ fig : rel](a ) , where both pairs truly correspond to the same entity . then the collective resolution decision is correct and we say that hyper - edges @xmath108 and @xmath111 are _ identifying relationships _ for that entity .",
    "formally , @xmath114 on the other hand , we may have a different scenario , in which both pairs of references correspond to two different entities .",
    "this second scenario is depicted in figure  [ fig : rel](b ) .",
    "then the first decision to resolve @xmath112 as co - referent is incorrect , and relational evidence obtained through hyper - edges @xmath108 and @xmath111 consequently leads to the incorrect resolution of @xmath113 .",
    "in this situation , collective resolution hurts accuracy , and we say that @xmath108 and @xmath111 form _ ambiguous relationships _ for both pairs of entities , whose references may be incorrectly clustered as a result of these relationships .",
    "formally , @xmath115    in general , a reference @xmath3 can have a co - occurrence relation @xmath108 that includes more than one other reference .",
    "we may think of this as multiple co - occurrence pairs involving @xmath3 .",
    "cluster labels of all these other references in the pairs influence resolution decisions for @xmath3 .",
    "when resolving @xmath3 with another reference @xmath109 that participates in co - occurrence relation @xmath111 , the fraction of common cluster labels between @xmath108 and @xmath111 determines whether or not @xmath3 and @xmath109 will be clustered together .",
    "if they are assigned to the same cluster , @xmath108 and @xmath111 are labeled identifying or ambiguous relationships based on whether @xmath3 and @xmath109 are actually co - referent or not .",
    "formally , we define :    * * identifying relationship probability * @xmath116 : the probability that a randomly chosen pair of @xmath106-similar references corresponding to entity @xmath95 has identifying relationships @xmath108 and @xmath111 with some other entity . * * ambiguous relationship probability * @xmath117 : the probability that a pair of @xmath106-similar references , chosen randomly such that one corresponds to entity @xmath92 and the other to entity @xmath93 , has ambiguous relationships @xmath108 and @xmath111 with some other pair of entities .    to illustrate these probabilities using our example , we have two ` wang ' entities , @xmath92 that has references @xmath23 , @xmath63 and @xmath39 , and @xmath93 that has reference @xmath38 .",
    "assume that the attribute threshold @xmath106 is such that all six pairs are considered potential matches .",
    "of the three pairs of references corresponding to @xmath92 , all of them have identifying relationships with the ` ansari ' entity .",
    "so , @xmath118 . to measure the relational ambiguity between the two ` wang ' entities , we consider the 3 possible pairs ( @xmath23 and @xmath38 , @xmath63 and @xmath38 , @xmath39 and @xmath38 ) . of these only one ( @xmath23 and @xmath38 ) pair has ambiguous relationships with two different ` chen ' entities .",
    "so , @xmath119 .",
    "given these two probabilities , we can analyze the performance of our relational clustering algorithm that combines attribute and relational evidence for collective entity resolution .",
    "it is not hard to see that the recall for any entity depends recursively on the recall of its neighbor entities .",
    "any pair of references for entity @xmath95 is resolved correctly on the basis of attributes alone with probability @xmath120 ( the identifying attribute probability ) .",
    "furthermore , it may still be resolved correctly in the presence of identifying relationships with a neighbor entity , _ if the related reference pair for the neighbor is resolved correctly_. denoting as @xmath121 the recall for entity @xmath95 and that for its neighbors as @xmath122 , we have : @xmath123    on the other hand , consider a pair of entities @xmath92 and @xmath93 .",
    "the cluster assignment for a pair of references corresponding to @xmath92 and @xmath93 is imprecise on the basis of its attributes alone with probability @xmath98 .",
    "even otherwise , the cluster assignment can go wrong by considering relational evidence .",
    "this happens in the presence of ambiguous relationships with references corresponding to another pair of entities , _ if those references are also clustered together incorrectly_. so the imprecision @xmath124 of the cluster assignment of reference pairs corresponding to entities @xmath92 and @xmath93 turns out to be : @xmath125    in general , any entity @xmath95 has multiple neighbors @xmath126 in its neighborhood @xmath127 . to formalize the performance dependence on multiple neighbors ,",
    "assume that if a co - occurrence involving references corresponding to @xmath95 is chosen at random , the probability of selecting a co - occurrence with a reference corresponding to @xmath126 is @xmath128 .",
    "then recall is given as : @xmath129 note that we have dropped @xmath89 and @xmath106 for notational brevity .",
    "for defining imprecision , observe that a reference corresponding to any neighbor @xmath130 of @xmath92 may co - occur with a reference for any neighbor @xmath131 of @xmath93 with probability @xmath132 .",
    "then imprecision is given as : @xmath133    given similarity thresholds @xmath89 and @xmath106 , relational clustering increases recall beyond that achievable using attributes alone .",
    "this improvement is larger when the probability of identifying relationships is higher . on the flip side ,",
    "imprecision also increases with relational clustering .",
    "typically , a low attribute threshold @xmath89 that corresponds to high precision is used , and then recall is increased using relational evidence . when the probability of ambiguous relations @xmath134 is small , the accompanying increase in imprecision is negligible , and performance is improved overall .",
    "however , the higher the ambiguous relationship probability @xmath134 , the less effective is relational clustering .",
    "thus the balance between ambiguous and identifying relations determines the overall benefit of collective resolution using relational clustering .",
    "when @xmath134 is high compared to @xmath135 , imprecision increases faster than recall , and overall performance is adversely affected compared to attribute - based clustering .",
    "( [ eqn : rec ] ) and eq .",
    "( [ eqn : imp ] ) quantify this dependence of resolution performance for any entity on the nature of its relationships with other entities . in the next section , we will use these equations to design and analyze a relational clustering algorithm for answering entity resolution queries .",
    "our analysis of collective resolution using relational clustering showed that the resolution accuracy for any underlying entity depends on the resolution accuracy for its related / neighboring entities . for the problem of answering entity resolution queries",
    ", the goal is not to resolve all the entities in the database .",
    "we need to resolve entities for only those references that are retrieved for the query .",
    "we have seen that collective resolution leads to potential performance improvements over attribute - based resolution .",
    "we now investigate how collective resolution can be applied for answering queries to get similar improvements .",
    "the obvious hurdle is illustrated by the expressions for performance metrics in eq .",
    "( [ eqn : rec ] ) and eq .",
    "( [ eqn : imp ] ) .",
    "they show that in order to get performance benefits for resolving the query using relational clustering , we need to resolve the neighboring entities as well . furthermore , to resolve the neighboring entities , we need to resolve their neighboring entities , and so on .",
    "these other entities that need to be resolved can be very large in number , and resolving them is expensive in terms of query - processing time .",
    "also , none of them are actually going to be retrieved as part of the answer to the query .",
    "so it is critical to identify and resolve those entities that contribute the most for improving resolution accuracy for the query .",
    "we propose a two - stage query processing strategy , consisting of an _ extraction phase _ , for identifying all the relevant references that need to be resolved for answering the query , and a _ resolution phase _",
    ", where the relevant references that have been extracted are collectively resolved using relational clustering .",
    "unfolding eq .",
    "( [ eqn : rec ] ) and eq .",
    "( [ eqn : imp ] ) starting from the query entities leads to a natural expansion process . in this section",
    ", we describe the extraction process using two novel expansion operators and , in parallel , we analyze the improvement in resolution accuracy that is obtained from considering co - occurrences .",
    "recall that an entity resolution query @xmath136 is specified using an attribute @xmath137 and a value @xmath32 for it .",
    "the answer to the query consists of a partitioning of all references @xmath42 that have @xmath35 or some value @xmath106-similar to @xmath32 .",
    "the correct answer to the query , in general , involves references from multiple entities @xmath138 .",
    "we measure resolution accuracy for the query using two metrics as before . for each of the query entities @xmath139",
    ", we measure recall @xmath140 and imprecision @xmath141 with respect to any other entity @xmath142 .",
    "entity @xmath142 may or may not belong to @xmath138 .    before going into the details of our algorithm for collective resolution of queries",
    ", we briefly recall the accuracy of the attribute - based strategy of resolving a query .",
    "this approach considers all references @xmath42 with @xmath143 @xmath106-similar to @xmath32 , and resolves them using their attributes only .",
    "the recall that results from this approach is @xmath144 , and the imprecision is given by @xmath145 .",
    "we propose two expansion operators for constructing the relevant set for an entity resolution query .",
    "we denote as _ level-0 references _ all references that are @xmath106-similar to the query attribute .",
    "these are the references that the user is interested in , and the goal is to resolve these correctly .",
    "the first operator we introduce is the * attribute expansion operator * @xmath146 , or a - expansion for short .",
    "given an attribute @xmath137 and a value @xmath32 for that attribute , @xmath147 returns all references @xmath42 whose attributes @xmath143 exactly match @xmath32 or are @xmath106-similar to @xmath32 . for a query @xmath136 , the _",
    "level-0 _ references can be retrieved by expanding @xmath148 as : @xmath149 the first step in figure  [ fig : expansion ] shows a - expansion for the query @xmath150 in our example .",
    "it retrieves the four references ( @xmath23,@xmath63,@xmath38,@xmath39 ) that have name ` w. wang ' or ` w. w. wang ' .     using h - expansion and a - expansion alternately ]    to consider co - occurrence relations",
    ", we construct the _ level-1 _",
    "references by including all references that co - occur with _",
    "_ references . for this",
    ", we use our second operator , which we call * hyper - edge expansion * @xmath151 , or h - expansion . for any reference @xmath42 , @xmath152 returns all references that share a hyper - edge with @xmath42 , and for a set @xmath153 of references @xmath154 returns @xmath155 .",
    "collective entity resolution requires that we consider all co - occurring references for each reference .",
    "this is achieved by performing h - expansion on the references at _ level-0 _ to retrieve the _",
    "level-1 _ references : @xmath156 figure  [ fig : expansion ] illustrates this operation in our example , where @xmath157 retrieves references ` c. chen ' ( @xmath24 ) and ` a. ansari ' ( @xmath25 ) , and so on .    to perform collective resolution for the query , we additionally need to _ resolve _ the references at _ level-1_. one option for _ level-1 _ references is attribute - based resolution using a conservative @xmath89-similarity to keep imprecision to a minimum .",
    "we can use our analysis technique from before to evaluate the performance for this approach .",
    "expanding from eq .",
    "( [ eqn : rec ] ) , and substituting @xmath158 for the recall of each neighboring entity @xmath159 for @xmath139 , the recall for any query entity is : @xmath160 similarly , on substituting @xmath161 in eq .",
    "( [ eqn : imp ] ) for the imprecision of each neighboring entity @xmath159 , we get the following expression for imprecision : @xmath162 to appreciate more easily the implications of considering first - order neighbors , we may assume that the attribute identification probability and the attribute ambiguity probability are the same for all the entities involved , i.e. , @xmath163 and @xmath164 . then , using @xmath165 for any entity @xmath95 , the expression for recall simplifies to @xmath166 \\nonumber\\end{aligned}\\ ] ] similarly , the expression for imprecision simplifies to @xmath167 \\nonumber\\end{aligned}\\ ] ]    so we can see that attribute - clustering of the first level neighbors potentially increases recall for any query entity @xmath139 , but imprecision goes up as well .",
    "however , when the balance between @xmath134 and @xmath135 is favorable , the increase in imprecision is insignificant and much smaller than the corresponding increase in recall , so that there is an overall performance improvement .",
    "can we do better than this ?",
    "we can go a step further and consider co - occurrence relations for resolving the _ level-1 _ references as well .",
    "so , instead of considering attribute - based resolution for references in _",
    "level-1 _ as before , we perform collective resolution for them .",
    "we consider all of their @xmath106-similar references , which we call _ level-2 _ references ( @xmath168 ) , using a - expansion : @xmath169 note that we have overloaded the a - expansion operator for a set @xmath153 of references : @xmath170 .",
    "the _ level-3 _ references are the second order neighbors that co - occur with _",
    "level-2 _ references .",
    "they are retrieved using h - expansion on the _ level-2 _ references : @xmath171 finally , as with the _ level-1 _ references earlier , we resolve the _",
    "level-3 _ references using @xmath89-similarity of their attributes alone .    in order to evaluate the impact on resolution accuracy for the query , we unfold the recursions in eq .",
    "( [ eqn : rec ] ) and eq .",
    "( [ eqn : imp ] ) up to two levels , and now substitute @xmath158 for recall and @xmath172 for imprecision for the second order neighbors .",
    "the trend in the expressions becomes clearly visible if we assume , as before , that @xmath173 and @xmath174 is identical for all entities , and , additionally , @xmath135 and @xmath134 are also the same , i.e. , @xmath175 and @xmath176 .",
    "then , we can work through a few algebraic steps to get the following expressions for recall and precision for any query entity @xmath139 : @xmath177 \\\\ i(e_q , e ' ) & = & a_a[1 + ( 1-a_a)r_a + ( 1-a_a)^2 r_a^2 ] \\label{eqn : gp}\\end{aligned}\\ ] ]    we can continue to unfold the recursion further and grow the relevant set for the query . formally , the expansion process alternates between a - expansion and h - expansion : @xmath178    as we proceed recursively and consider higher order co - occurrences for the query , additional terms appear in the expressions for precision and recall . but",
    "this does not imply that we need to continue this process to arbitrary levels to get optimum benefit . using our simplifying assumptions about the attribute and relational probabilities ,",
    "the expressions for both recall and imprecision for @xmath179 order co - occurrences turns out to be geometric progressions with @xmath180 terms .",
    "the common ratio for the two geometric progressions are @xmath181 and @xmath182 respectively .",
    "typically , both of these ratios are significantly smaller than 1 , and therefore converge very quickly with increasing co - occurrence level .",
    "so the improvement in resolution accuracy for the query @xmath148 falls off quickly with expansion depth , and we can terminate the expansion process at some cut - off depth @xmath183 without compromising on accuracy : @xmath184    of course , the assumptions about the attribute and relational probabilities being entity - independent do not hold in practice , so that the performance trends for increasing levels of co - occurrence can not be exactly captured by geometric progressions with a common ratio for successive terms .",
    "but the converging trends for both of them still hold in general , and the rate of convergence is still determined by the four probabilities @xmath185 and @xmath134 for the entities that are encountered during the expansion process .",
    "intuitively , smaller values for @xmath135 and @xmath134 indicate less sensitivity to co - occurrences , and the convergence is quicker . on the other hand ,",
    "higher values of @xmath173 and @xmath174 mean that more entities are resolved based on attributes alone  correctly or incorrectly  and the impact of co - occurrence relations is smaller . therefore convergence is quicker for higher values of @xmath173 and @xmath174 .    apart from imposing a cutoff on the expansion depth , the size of the relevant set can also be significantly reduced by restricting attribute expansion beyond _ level-0 _ to * exact a - expansion * @xmath186 .",
    "this only considers references with exactly the same attribute as @xmath42 and disregards other @xmath106-similar references .",
    "interestingly , we can show that the restricted strategy that alternates between exact a - expansion and h - expansion does not reduce recall significantly .",
    "the limited depth query expansion strategy proposed in the previous section is an effective approach that is able to answer queries quickly and accurately for many domains .",
    "however , for some domains , the size of the relevant set that is generated can be extremely large even for small expansion depths , and as a result , the retrieved references can not be resolved at query - time . in this section , we propose adaptive strategies based on estimating the ` ambiguity ' of individual references that makes our algorithm even more efficient while preserving accuracy .",
    "the main reason behind this explosive growth of the relevant set with increasing levels is that our query expansion strategy from the previous section is unconstrained  it treats all co - occurrences as equally important for resolving any entity .",
    "it blindly expands all references in the current relevant set , and also includes all new references generated by an expansion operation .",
    "given the limited time to process a query , this approach is infeasible for domains that have dense relationships . our solution is to identify the references that are likely to be the most helpful for resolving the query , and to focus on only those references . to illustrate using our example from figure  [ fig : expansion ] ,",
    "observe that ` chen ' and ` li ' are significantly more common or ` ambiguous ' names than ` ansari '  even different ` w. wang ' entities are likely to have collaborators named ` chen ' or ` li ' .",
    "therefore , when h - expanding @xmath187 for ` w. wang ' , ` ansari ' is more informative than ` chen ' or ` li ' .",
    "similarly , when n - expanding @xmath188 , we can choose not to expand the name ` a. ansari ' any further , since two ` a. ansari ' references are very likely to be coreferent .",
    "but we need more evidence for the  chen s and the  li s .    to describe this formally , the ambiguity of a value @xmath32 for an attribute @xmath137 is the probability that any two references @xmath3 and @xmath5 in the database that have @xmath189 are _ not _ coreferent : @xmath190 .",
    "the goal of adaptive expansion is to add less ambiguous references to the relevant set and to expand the most ambiguous references currently in the relevant set .",
    "we first define adaptive versions of our two expansion operators treating the ambiguity estimation process as a black - box , and then look at ways to estimate ambiguity of references .      the goal of adaptive expansion is to selectively choose the references to expand from the current relevant set , and also the new references that are included at every expansion step . for * adaptive hyper - edge expansion * , we set an upper - bound @xmath191 on the number of new references that h - expansion at a particular level can generate .",
    "formally , we want + @xmath192 @xmath193 @xmath194 . the value of @xmath191 may depend on depth @xmath195 but should be small enough to rule out full h - expansion of the current relevant set .",
    "then , given @xmath191 , our strategy is to choose the least ambiguous references from @xmath196 , since they provide the most informative evidence for resolving the references in @xmath197 . to achieve this ,",
    "we sort the h - expanded references in increasing order of ambiguity and select the first @xmath84 from them , where @xmath198 . @xmath199",
    "the setting for * adaptive attribute expansion * is very similar . for some positive number @xmath200 , exact a - expansion of @xmath197",
    "is allowed to include at most @xmath201 references .",
    "note that now the selection preference needs to be flipped  more ambiguous names need more evidence , so they are expanded first .",
    "so we can sort @xmath202 in decreasing order of ambiguity and select the first @xmath84 from the sorted list , where @xmath203 .",
    "but this could potentially retrieve only references for the most ambiguous name , totally ignoring references with any other name .",
    "to avoid this , we choose the top @xmath84 ambiguous references from @xmath197 _ before _ expansion , and then expand the references so chosen .",
    "@xmath204 though this can not directly control the number of new references added , @xmath205 is a reasonable estimate , where @xmath206 is the average number of references per name .",
    "the adaptive expansion scheme proposed in this section is crucially dependent on the estimates of name ambiguity .",
    "we now describe one possible scheme that worked quite well .",
    "recall that we want to estimate the probability that two randomly picked references with value @xmath32 for attribute @xmath137 correspond to different entities .",
    "for a reference attribute @xmath207 , denoted @xmath208 , a naive estimate for the ambiguity of a value of @xmath83 for the attribute is : @xmath209 where @xmath210 denotes the number of references with value @xmath211 for @xmath207 .",
    "this estimate is clearly not good since the number of references with a certain attribute value does not always match the number of different entity labels for that attribute .",
    "we can do much better if we have an additional attribute @xmath212 .",
    "given @xmath212 , the ambiguity for value of @xmath207 can be estimated as @xmath213 where @xmath214 is the number of distinct values observed for @xmath212 in references with @xmath215 .",
    "for example , we can estimate the ambiguity of a last name by counting the number of different first names observed for it .",
    "this provides a better estimate of the ambiguity of any value of an attribute @xmath207 , when @xmath212 is not correlated with @xmath207 .",
    "when multiple such uncorrelated attributes @xmath216 are available for references , this approach can be generalized to obtain better ambiguity estimates .",
    "aaaaaaaaaaaa = aaaaaa = aaaaaaaa = aaaaaa > algorithm query - time resolve ( @xmath69.name name ) + 1 .",
    "rset = relevantfrontier(name ) + 2 .",
    "rc - er(rset ) +   + algorithm findrelevantrefs(@xmath69.name name ) + 1 .",
    "initialize rset to \\ { } + 5 .",
    "initialize depth to 0 + 3 .",
    "initialize frontierrefs to \\ { } + 4 . while depth @xmath217 d * + 5 . if depth is even or 0 + 6 .",
    "r = @xmath146(frontierrefs ) + 7 .",
    "r = @xmath151(frontierrefs ) + 9 .",
    "frontierrefs = r + 10 .",
    "add frontierrefs to rset + 10 .",
    "increment depth + 11 .",
    "return rset +    putting everything together , high - level pseudo code for the query - time entity resolution algorithm is shown in figure  [ fig : qt - algo ] .",
    "the algorithm works in two stages  first , it identifies the relevant set of references given an entity name as a query , and then it performs relational clustering on the extracted relevant references .",
    "the relevant references are extracted using the recursive process that we have already seen .",
    "the relevant references at any depth @xmath195 are obtained by expanding the relevant references at depth @xmath218 , the expansion being dependent of whether it is an odd step or an even step .",
    "the actual expansion operator that is used may either be unconstrained or adaptive .",
    "for experimental evaluation of our query - time resolution strategies , we used both real - world and synthetically generated datasets .",
    "first , we describe our real datasets and the experiments performed on them and then we move on to our experiments on synthetic data .      for real - world data",
    ", we used two citation datasets with very different characteristics .",
    "the first dataset , * arxiv * , contains papers from high energy physics and was used in kdd cup 2003 .",
    "it has 58,515 references to 9,200 authors , contained in 29,555 publications .",
    "the number of author references per publication ranges from 1 to 10 with an average of 1.90 .",
    "our second dataset is the * elsevier biobase * database of publications from biology used in the recent ibm kdd - challenge competition .",
    "it includes all publications under ` immunology and infectious diseases ' between years 1998 and 2001 .",
    "this dataset contains 156,156 publications with 831,991 author references .",
    "the number of author references per publication is significantly higher than arxiv and ranges from 1 to 100 ( average 5.3 ) .",
    "all names in this database only have initials for first and middle names ( if available ) , unlike arxiv , which has both initialed and complete names .",
    "the number of distinct names in biobase is 303,693 , with the number of references for any name ranging from 1 to 193 ( average 2.7 ) .",
    "unlike arxiv , biobase includes keywords , topic classification , language , country of correspondence and affiliation of the corresponding author as attributes of each paper , all of which we use as attributes for resolution in addition to author names .",
    "biobase is diverse in terms of these attributes , covering 20 languages , 136 countries , 1,282 topic classifications and 7,798 keywords .    for entity resolution queries in arxiv",
    ", we selected all ambiguous names that correspond to more than one author entity .",
    "this gave us 75 queries , with the number of true entities for the selected names varying from 2 to 11 ( average 2.4 ) .",
    "for biobase , we selected as queries the top 100 author names with the highest number of references .",
    "the average number of references for each of these 100 names is 106 , and the number of entities for the selected names ranges from 1 to 100 ( average 32 ) , thereby providing a wide variety of entity resolution settings over the queries .",
    "we begin by exploring the growth rate of the relevant set for a query over expansion depth in the two datasets .",
    "figure  [ plot : growth](a ) plots the size of the relevant set for a sample query on the name ` t. lee ' for arxiv and ` m. yamashita ' for biobase .",
    "the growth rate for the arxiv query is moderate .",
    "the number of references with name ` t. lee ' is 7 , which is the number of relevant references at depth 0 , and the size grows to 7,500 by depth 7 .",
    "in contrast , for biobase the plots clearly demonstrate the exponential growth of the relevant references with depth for both name expansion strategies .",
    "there are 84 relevant references at depth 0 .",
    "when references are expanded using name similarity expansion , there are 722 relevant references at depth 1 , 65,000 at depth 3 and more than 586,000 at depth 5 .",
    "this is for a very restricted similarity measure where two names are considered similar only if their first initials match , and the last names have the same first character and differ overall by at most 2 characters .",
    "a more liberal measure would result in a significantly faster growth .",
    "we also observe that for exact expansion , the growth is slower but we still have 45,000 references at depth 3 , 384,000 at depth 5 and 783,000 by depth 7 .",
    "it is interesting to note that the growth slows down beyond depth 5 ; but this is because most of the references in the entire dataset are already covered at that depth ( biobase has 831,991 references in total ) .",
    "the growth rates for these two examples from arxiv and biobase are typical for all of our queries in these two datasets .",
    "next , in figure  [ plot : growth](b ) , we observe how the relational clustering algorithm * rc - er * scales with increasing number of references in the relevant set .",
    "all execution times are reported on a dell precision 870 server with 3.2ghz intel xeon processor and 3 gb of memory .",
    "the plot shows that the algorithm scales well with increasing references , but the gradient is different for the two datasets .",
    "this is mainly due to the difference in the average number of references per hyper - edge .",
    "this suggests that for arxiv , * rc - er * is capable of handling the relevant sets generated using unconstrained expansion .",
    "but for biobase , it would require up to 600 secs for 40,000 references , and up to 900 secs for 65,000 .",
    "so it is clearly not possible to use * rc - er * with unconstrained expansion for query - time resolution in biobase even for depth 3 .      in our next experiment ,",
    "we evaluate several algorithms for entity resolution queries .",
    "we compare entity resolution accuracy of the pair - wise co - reference decisions using the f1 measure ( which is the harmonic mean of precision and recall ) . for a fair comparison",
    ", we consider the best f1 for each of these algorithms over all possible thresholds for determining duplicates . for the algorithms , we compare _ attribute - based entity resolution _",
    "( * a * ) , _ naive relational entity resolution _ ( * nr * ) that uses _ attributes _ of related references , and our _ relational clustering algorithm for collective entity resolution _ ( * rc - er * ) using unconstrained expansion up to depth 3 .",
    "we also consider transitive closures over the pair - wise decisions for the first two approaches ( * a * * and * nr * * ) .",
    "for attribute similarity , we use the _ soft tf - idf _ with jaro - winkler similarity for names , which has been shown to perform the best for name - based resolution @xcite , and tf - idf similarity for the other textual attributes .",
    "0.15 in    .average entity resolution accuracy ( f1 ) for different algorithms over 75 arxiv queries and 100 biobase queries [ cols=\"<,^,^\",options=\"header \" , ]     -0.1 in    in table  [ table : adapt ] , we compare the two adaptive schemes against unconstrained expansion with @xmath219 over all queries . clearly , accuracy remains almost unaffected for both schemes .",
    "first , we note that * ax-2 * matches the accuracy of unconstrained expansion , and shows almost the same improvement over depth 1 .",
    "this accuracy is achieved even though it uses adaptive expansion that expands a small fraction of @xmath220 , and thereby reduces the average size of the relevant set from 44,000 to 5,500 .",
    "more significantly , * ax-1 * also matches this improvement even without including many depth-1 references .",
    "this reduction in the size of the relevant set has an immense impact on the query processing time .",
    "the average processing time drops from more than 600 secs for unconstrained expansion to 43 secs for * ax-2 * , and further to just 31 secs for * ax-1 * , thus making it possible to use collective entity resolution for query - time resolution .      as a further improvement",
    ", we investigate if processing time can be reduced by setting the expansion depth @xmath183 adaptively , depending on the ambiguity of the query name , as compared to a fixed @xmath183 for all queries . in a simple setup , we set @xmath183 to 1 for queries where the number of different first initials for a last name is less than 10 ( out of 26 ) , and explore depth 2 only for more ambiguous queries .",
    "this reduces expansion depth from 2 to 1 for 18 out of the 100 queries . as a result ,",
    "the average processing time for these queries is reduced by 35% to 11.5 secs from 17.7 secs with no reduction in accuracy . for three of these queries ,",
    "the original processing time at depth 2 is greater than 30 secs . in these preliminary experiments",
    ", we only evaluated our original set of 100 queries that are inherently ambiguous . in a more general setting , where a bigger fraction of queries have lower ambiguity , the impact is expected to be even more significant .      in addition to experiments on real datasets , we performed experiments on synthetically generated data .",
    "this enables us to reason beyond specific datasets , and also to empirically verify our performance analysis for relational clustering in general , and more specifically for entity resolution queries .",
    "we have designed a generator for synthetic data that allows us to control different properties of the underlying entities and the relations between them , and also of the observed co - occurrence relationships between the entity references . among other properties",
    ", we can control the number of entities , the average number of neighbor entities per entity , and the number and average size of observed co - occurrences .",
    "additionally , we can control the ambiguity of entity attributes , and the number of ambiguous relationships between entities .",
    "we present an overview of the synthetic data generation process in appendix a.    we have performed a number of different experiments on synthetic data . in the first set of experiments , we investigate the influence of identifying relationships on collective resolution using relational clustering .",
    "we generate 500 co - occurrence relations from the same 100 entities and 200 entity - entity relationships , using varying probability of co - occurrences @xmath221 in the data .",
    "the probability of ambiguous relationships is held fixed , so that higher @xmath222 translates to higher probability of identifying co - occurrences in the data .",
    "figure  [ plot:1](a ) shows recall at different similarity thresholds for three different co - occurrence probabilities .",
    "the results confirm that recall increases progressively with more identifying relationships at all thresholds .",
    "the curves for @xmath223 and @xmath224 flatten out only when no further recall is achievable .",
    "next , we observe the effect of ambiguous relations on the precision of collective resolution using relational clustering .",
    "we add 200 binary relationships between 100 entities in three stages with increasing ambiguous relationship probability ( @xmath225 } ) .",
    "then we perform collective resolution on 500 co - occurrence relations generated from each of these three settings . in figure  [ plot:1](b )",
    "we plot precision at different similarity threshold for three different values of @xmath226 .",
    "the plots confirm the progressive decrease in precision for all thresholds with higher @xmath226 .",
    "for both experiments , the results are averaged over 200 different runs .",
    "next , we evaluate collective resolution for queries . recall that the last two rows in table  [ table : performance ] clearly demonstrate the converging nature of performance over increasing expansion levels for queries on real datasets .",
    "we ran further experiments on synthetic data to verify this trend . in each run",
    ", we generated 2,500 co - occurrence relations from 500 entities having an average of 2 neighbors per entity .",
    "then we performed localized collective clustering in each case , using as query the most ambiguous attribute value ( that corresponds to the highest number of underlying entities ) . in figure  [ plot:2](c ) and ( d ) , we show how recall and precision change with increasing expansion level for a query .",
    "recall improves with increasing expansion level , while precision decreases overall , as is predicted by our analysis .",
    "importantly , recall increases at a significantly faster rate than that for the decrease in precision . in general , the rate of increase / decrease depends on the structural properties of the data , as we have shown in our analysis . in other experiments ,",
    "we have seen different rates of change , but the overall trend remains the same .",
    "our analysis also showed that precision and recall converge quickly over increasing expansion levels .",
    "this too is confirmed by the two plots where the curves flatten out by level 3 .",
    "finally , we discuss two of the current limitations of our collective entity resolution approach . recall that the similarity measure in eqn .",
    "[ eqn : alpha ] involves a weighting parameter @xmath55 for combining attribute and relational similarity .",
    "for all of our experiments , we report the best accuracy over all values of @xmath55 for each query . selecting",
    "the optimal value of @xmath55 for each query is an unresolved issue .",
    "however , our experiments reveal that even a fixed @xmath55 ( @xmath227 ) for all queries brings significant improvements over the baselines .",
    "the second issue is the determination of the termination threshold for * rc - er*. note that this is an issue for all of the baselines as well , and here we report best accuracy over all thresholds .",
    "this is an area of ongoing research .",
    "preliminary experiments have shown that the best threshold is often query specific  setting the threshold depending on the ambiguity of the query results in significantly better accuracy than a fixed threshold for all queries .",
    "for an empirical evaluation , we cleaned the entire arxiv dataset offline by running * rc - er * on all its references together , and terminated at the threshold that maximizes resolution accuracy over all references .",
    "this results in an overall accuracy ( f1 ) of @xmath228 . however , the average accuracy measured over the 75 queries in our test set is only @xmath229 . in comparison , the best obtainable accuracy",
    "when resolving the queries individually each with a different threshold is @xmath230 .",
    "this suggests that there may be potential benefits to localized cleaning over its global counterpart in the offline setting .",
    "the entity resolution problem has been studied in many different areas under different names  deduplication , record linkage , co - reference resolution , reference reconciliation , object consolidation , etc .",
    "much of the work has focused on traditional attribute - based entity resolution .",
    "extensive research has been done on defining approximate string similarity measures @xcite that may be used for unsupervised entity resolution .",
    "the other approach uses adaptive supervised algorithms that learn similarity measures from labeled data @xcite .    resolving entities optimally",
    "is known to be computationally hard even when only attributes are considered @xcite . therefore , efficiency has received a lot of attention in attribute - based data cleaning .",
    "the goal essentially is to avoid irrelevant and expensive attribute similarity computations using a ` blocking ' approach without affecting accuracy significantly .",
    "the merge / purge problem was posed by with efficient schemes to retrieve potential duplicates without resorting to quadratic complexity .",
    "they use a ` sorted neighborhood method ' where an appropriate key is chosen for matching .",
    "records are then sorted or grouped according to that key and potential matches are identified using a sliding window technique .",
    "however , some keys may be badly distorted so that their matches can not be spanned by the window and such cases will not be retrieved .",
    "the solution they propose is a multi - pass method over different keys and then merging the results using transitive closure .",
    "combine the union find algorithm with a priority queue look - up to find connected components in an undirected graph .",
    "propose the use of canopies to first partition the data into overlapping clusters using a cheap distance metric and then use a more accurate and expensive distance metric for those data pairs that lie within the same canopy . use an error tolerant index for data warehousing applications for probabilistically looking up a small set of candidate reference tuples for matching against an incoming tuple .",
    "this is considered ` probabilistically safe ' since the closest tuples in the database will be retrieved with high probability . this is also efficient since only a small number of matches needs to be performed .",
    "swoosh @xcite has recently been proposed as a generic entity resolution framework that considers resolving and merging duplicates as a database operator and the goal is to minimize the number of record - level and feature - level operations .",
    "an alternative approach is to reduce the complexity of individual similarity computations .",
    "propose a sampling approach to quickly compute cosine similarity between tuples for fast text - joins within an sql framework .",
    "all of these approaches enable efficient data cleaning when only attributes of references are considered .",
    "many recently proposed approaches take relations into account for data integration . introduce relational deduplication in data warehouse applications where there is a dimensional hierarchy over the relations . enhance attribute similarity between an ambiguous reference and the many entity choices for it with relationship analysis between the entities , like affiliation and co - authorship . in earlier work , we have proposed different measures for relational similarity and a relational clustering algorithm for collective entity resolution using relationships .",
    "collectively resolve entities of multiple types by propagating relational evidences in a dependency graph , and demonstrate the benefits of collective resolution in real datasets .",
    "have proposed a model for general multi - type relational clustering , though it has not been applied specifically for entity resolution .",
    "they perform collective factorization over related matrices using spectral methods to identify the cluster space that minimizes distortion over relationships and individual features at the same time .",
    "all of these approaches that make use of relationships either for entity matching ( where the domain entities are known ) or entity resolution ( where the underlying entities also need to be discovered ) have been shown to increase performance significantly over the attribute - based solutions for the same problems . however , the price they pay is in terms of computational complexity that increases due to a couple of different reasons .",
    "firstly , the number of potential matches increases when relationships are considered and individual similarity computations also become more expensive .",
    "secondly , collective resolution using relationships necessitates iterative solutions that make multiple passes over the data .",
    "while some of these approaches have still been shown to be scalable in practice , they can not be employed for query - time cleaning in a straight - forward manner .",
    "the idea of multi - relational clustering also comes up in the inductive logic programming ( ilp ) literature .",
    "have used multi - relational similarity for instance - based classification of representations in first order logic .",
    "they define the similarity of two objects , e.g. , of two people , as a combination of the similarity of their attribute values , such as their age , weight , etc . , and the similarity of the objects that they are related to , such as the companies they work for .",
    "this is similar to the naive relational similarity that we discussed earlier , except that the similarity of the connected objects is also defined recursively in terms of their connected objects .",
    "have used this recursive relational similarity measure for agglomerative clustering of first order representations . while recursive comparison of neighbors is shown to be effective in terms of accuracy of results ,",
    "the computational challenge is again a major drawback .",
    "probabilistic approaches that cast entity resolution as a classification problem have been extensively studied .",
    "the groundwork was done by .",
    "others @xcite have more recently built upon this work .",
    "adaptive machine learning approaches have been proposed for data integration @xcite , where active learning requires the user to label informative examples .",
    "probabilistic models that use relationships for collective entity resolution have been applied to named entity recognition and citation matching .",
    "these probabilistic approaches are superior to similarity - based clustering algorithms in that they associate a degree of confidence with every decision , and learned models provide valuable insight into the domain . however , probabilistic inference for collective entity resolution is not known to be scalable in practice , particularly when relationships are also considered .",
    "these approaches have mostly been shown to work for small datasets , and are significantly slower than their clustering counterparts .",
    "little work has been done in the literature for query - centric cleaning or relational approaches for answering queries , where execution time is as important as accuracy of resolution .",
    "approaches have been proposed for localized evaluation of bayesian networks @xcite , but not for clustering problems .",
    "recently , have addressed efficiency issues in computing top - k entity matches against a dictionary in the context of entity extraction from unstructured documents .",
    "they process top - k searches in batches where speed - up is achieved by sharing computation between different searches .",
    "motivate the problem of answering queries over databases that violate integrity constraints and address scalability issues in resolving inconsistencies dynamically at query - time .",
    "however , the relational aspect of the problem , which is the major scalability issue that we address , does not come up in any of these settings . in our earlier work on relational clustering , we used the idea of ` relevant references ' for experimental evaluation on the biobase dataset . as we have also discussed here",
    ", this dataset has entity labels only for the 100 most frequent names .",
    "therefore , instead of running collective resolution over the entire biobase dataset , we evaluated the 100 names separately , using only the ` relevant references ' in each case .",
    "the relevant references were the ones directly connected to references having the names of interest .",
    "the concept of focused cleaning , the performance analysis of relational clustering , the expand - resolve strategy and , most importantly , the idea of adaptive expansion for query - time resolution were not addressed in that paper .",
    "one of the first papers to make use of relational features for classification problem was by .",
    "they showed that for the problem of classifying hyper - linked documents , naive use of relationships can hurt performance . specifically ,",
    "if key terms from neighboring documents are thrown into the document whose topic is to be classified , classification accuracy degrades instead of improving .",
    "the parallel in our scenario of clustering using relationships is that the naive relational model ( * nr * ) may perform worse than the attribute model ( * a * ) in the presence of highly ambiguous relationships . showed that relationships can however be used for improved classification when the _ topic labels _ of the neighboring documents are used as evidence instead of naively considering the terms that they contain . in our earlier work , we have shown similar results for collective clustering using relationships , where the cluster labels of neighboring labels lead to improved clustering performance compared to naive relational and attribute - based clustering .",
    "the interesting result that we have shown in this paper both in theory and empirically is that even collective use of relationships can hurt clustering accuracy compared to attribute - based clustering .",
    "this happens when relationships between references are dense and ambiguous , and errors that propagate over relationships exceed the identifying evidence that they provide .",
    "in this paper , we have motivated the problem of query - time entity resolution for accessing unresolved third - party databases . for answering entity resolution queries ,",
    "we have addressed the challenges of using collective approaches , which have recently shown significant performance improvements over traditional baselines in the offline setting .",
    "the first hurdle for collective resolution arises from the interdependent nature of its resolution decisions .",
    "we first formally analyzed the recursive nature of this dependency , and showed that the precision and recall for individual entities grow in a geometric progression as increasing levels of neighbors are considered and collectively resolved .",
    "we then proposed a two - stage ` expand and resolve ' strategy for answering queries based on this analysis , using two novel expansion operators .",
    "we showed using our analysis that it is sufficient to consider neighbors up to small expansion depths , since resolution accuracy for the query converges quickly with increasing expansion level .",
    "the second challenge for answering queries is that the computation has to be quick . to achieve this , we improved on our unconstrained expansion strategy to propose an adaptive algorithm , which dramatically reduces the size of the relevant references  and , as a result , the processing time  by identifying the most informative references for any query .",
    "we demonstrated using experiments on two real datasets that our strategies enable collective resolution at query - time , without compromising on accuracy .",
    "we additionally performed various experiments on synthetically generated data over a wide range of settings to verify the trends predicted by our analysis . in summary , we have addressed and motivated a critical data integration and retrieval problem , proposed algorithms for solving it accurately and efficiently , provided a theoretical analysis to validate our approach and explain why it works , and , finally , shown experimental results on multiple real - world and synthetically generated datasets to demonstrate that it works extremely well in practice . while we have presented results for bibliographic data , the techniques are applicable in other relational domains .",
    "while we have shown the dramatic reduction in query processing time that comes with adaptive expansion , more research is necessary to be able to answer entity resolution queries on the order of milli - seconds , as may be demanded in many scenarios .",
    "interesting directions of future research include exploring stronger coupling between the extraction and resolution phases of query processing , where the expansion happens  on - demand \" only when the resolution process finds the residual ambiguity to be high and requires additional evidence for taking further decisions .",
    "this would directly address the problem of determining the expansion depth .",
    "while we have reported some preliminary experiments in this paper , more work needs to be done on adaptive depth determination depending on ambiguity . in the same context",
    ", we may imagine  soft \" thresholds for adaptive expansion , where the expansion operator automatically determines the number of hyper - edges or names to be expanded so that the residual ambiguity falls below some specified level .",
    "other interesting extensions include caching of intermediate resolutions , where the related resolutions performed for any query are stored and retrieved as and when required for answering future queries .",
    "we wish to thank our anonymous reviewers for their constructive suggestions which greatly improved this paper .",
    "this work was supported by the national science foundation , nsf # 0423845 and nsf # 0438866 , with additional support from the itic kdd program .",
    "we have designed a synthetic data generator that allows us to control different structural and attribute - based characteristics of the data . here",
    "we present an overview of the generation algorithm .",
    "the generation process has two stages . in the first stage",
    ", we create the collaboration graph among the underlying entities and the entity attributes . in the second , we generate observed co - occurrence relations from this collaboration graph . a high level description of the generative process in shown in figure  [ fig : synth - algo ] .",
    "next , we describe the two stages of the generation process in greater detail",
    ".    the graph creation stage , in turn , has two sub - stages .",
    "first , we create the domain entities and their attributes and then add relationships between them . for creating entities , we control the number of entities and the ambiguity of their attributes .",
    "we create @xmath231 entities and their attributes one after another . for simplicity and without losing generality ,",
    "each entity @xmath95 has a single floating point attribute @xmath232 , instead of a character string .",
    "a parameter @xmath233 controls the ambiguity of the entity attributes ; with probability @xmath233 the attribute of a new entity is chosen from values that are already in use by existing entities",
    ". then @xmath234 binary relationships are added between the created entities . as with the attributes",
    ", there is a parameter controlling the ambiguity of the relationships , as defined in section  [ sec : rc - analysis ] . for each binary relationship ( @xmath235 ) , first @xmath88",
    "is chosen randomly and then @xmath236 is sampled so that @xmath237 is an ambiguous relationship with probability @xmath226 .",
    "aaaaaaaaaaaa = aaaaaa = aaaaaaaa = aaaaaa > creation stage + 1 .",
    "repeat n times + 2 .",
    "create random attribute @xmath238 with ambiguity @xmath233 + 3 .",
    "create entity @xmath95 with attribute @xmath238 + 4 .",
    "repeat m times + 5 .",
    "choose entity @xmath88 randomly + 6 .",
    "choose entity @xmath236 with prob @xmath226 of an ambiguous relationship @xmath237 + 7 .",
    "set @xmath239 and @xmath240 +   + generation stage + 8 .",
    "repeat r times + 9 .",
    "randomly choose entity @xmath95 + 10 .",
    "generate reference @xmath42 using @xmath241 + 11 .",
    "initialize hyper - edge @xmath242 + 12 .",
    "repeat with probability @xmath243 + 13 .",
    "randomly choose @xmath236 from @xmath244 without replacement + 14 .",
    "generate reference @xmath5 using @xmath245 + 15 .",
    "add @xmath5 hyper - edge @xmath108 + 16 .",
    "output hyper - edge @xmath108 +    before describing the process of generating co - occurrence relationships from the graph , let us consider in a little more detail the issue of attribute ambiguity .",
    "what finally needs to be controlled is the ambiguity of the reference attributes .",
    "while these depend on the entity attributes , they are not completely determined by entities .",
    "taking the example of names , two people who have names ` john michael smyth ' and ` james daniel smith ' can still be ambiguous in terms of their observed names in the data depending on the generation process of observed names .",
    "in other words , attribute ambiguity of the references depends both on the separation between entity attributes and the dispersion created by the generation process .",
    "we make the assumption that for an entity @xmath95 with attribute @xmath232 , its references are generated from a gaussian distribution with mean @xmath238 and variance 1.0 .",
    "so , with very high probability , any reference attribute generated from @xmath232 will be in the range @xmath246 $ ] .",
    "so this range in the attribute domain is considered to be ` occupied ' by entity @xmath95 .",
    "any entity has an ambiguous attribute if its occupied range intersects with that of another entity .",
    "now we come to the generation of co - occurrence relationships from the entity collaboration graph . in this stage ,",
    "@xmath153 co - occurrence relationships or hyper - edges are generated , each with its own references .",
    "for each hyper - edge @xmath247 , two aspects need to be controlled  how many references and which references should be included in this hyper - edge .",
    "this is done as follows .",
    "first , we sample an entity @xmath88 which serves the initiator entity for this hyper - edge . then other entities @xmath248 for this hyper - edge are repeatedly sampled ( without replacement ) from the neighbors of the initiator entity @xmath88 .",
    "the size of the hyper - edge is determined using a parameter @xmath243 .",
    "the sampling step for a hyper - edge is terminated with probability @xmath243 after each selection @xmath248 .",
    "the process is also terminated when the neighbors of the initiator entity are exhausted .",
    "finally , references @xmath249 need to be generated from each of the selected entities @xmath248",
    ". this is done for each entity @xmath95 by sampling from its gaussian distribution @xmath250 .",
    "bilenko , m.   mooney , r. 2003 .",
    "adaptive duplicate detection using learnable string similarity measuresin the acm international conference on knowledge discovery and data mining ( sigkdd ) , washington dc , usa .",
    "chandel , a. , nagesh , p.  c. ,  sarawagi , s. 2006 .",
    "efficient batch top - k search for dictionary - based entity recognitionin the ieee international conference on data engineering ( icde ) , washington , dc , usa .",
    "chaudhuri , s. , ganjam , k. , ganti , v. ,  motwani , r. 2003 .",
    "robust and efficient fuzzy match for online data cleaningin the acm international conference on management of data ( sigmod ) , san diego , ca , usa .",
    "gravano , l. , ipeirotis , p. , koudas , n. ,  srivastava , d. 2003 .",
    "text joins for data cleansing and integration in an rdbmsin the ieee international conference on data engineering ( icde ) , bangalore , india .",
    "mccallum , a. , nigam , k. ,  ungar , l. 2000 .",
    "efficient clustering of high - dimensional data sets with application to reference matchingin the acm international conference on knowledge discovery and data mining ( sigkdd ) , boston , ma , usa .        monge , a.   elkan , c. 1997 .",
    "an efficient domain - independent algorithm for detecting approximately duplicate database recordsin the sigmod workshop on research issues on data mining and knowledge discovery ( dmkd ) , tuscon , az , usa .",
    "sarawagi , s.   bhamidipaty , a. 2002 .",
    "interactive deduplication using active learningin proceedings of the eighth acm international conference on knowledge discovery and data mining ( sigkdd ) , edmonton , alberta , canada ."
  ],
  "abstract_text": [
    "<S> entity resolution is the problem of reconciling database references corresponding to the same real - world entities . </S>",
    "<S> given the abundance of publicly available databases that have unresolved entities , we motivate the problem of _ query - time entity resolution _ : quick and accurate resolution for answering queries over such ` unclean ' databases at query - time . since collective entity resolution approaches  where related references are resolved jointly </S>",
    "<S>  have been shown to be more accurate than independent attribute - based resolution for off - line entity resolution , we focus on developing new algorithms for collective resolution for answering entity resolution queries at query - time . </S>",
    "<S> for this purpose , we first formally show that , for collective resolution , precision and recall for individual entities follow a geometric progression as neighbors at increasing distances are considered . unfolding </S>",
    "<S> this progression leads naturally to a two stage ` expand and resolve ' query processing strategy . in this strategy </S>",
    "<S> , we first extract the related records for a query using two novel expansion operators , and then resolve the extracted records collectively . </S>",
    "<S> we then show how the same strategy can be adapted for query - time entity resolution by identifying and resolving only those database references that are the most helpful for processing the query . </S>",
    "<S> we validate our approach on two large real - world publication databases where we show the usefulness of collective resolution and at the same time demonstrate the need for adaptive strategies for query processing . </S>",
    "<S> we then show how the same queries can be answered in real - time using our adaptive approach while preserving the gains of collective resolution . </S>",
    "<S> in addition to experiments on real datasets , we use synthetically generated data to empirically demonstrate the validity of the performance trends predicted by our analysis of collective entity resolution over a wide range of structural characteristics in the data .    </S>",
    "<S> [ section ] [ theorem]lemma [ theorem]proposition [ theorem]corollary </S>"
  ]
}