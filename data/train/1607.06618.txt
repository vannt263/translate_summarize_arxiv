{
  "article_text": [
    "the counting of  @xmath0-mers in large amounts of reads is a common task in bioinformatics .",
    "the problem is to count the occurrences of all  @xmath0-long substrings in a large amount of sequencing reads .",
    "its most prominent application is de novo assembly of genome sequences .",
    "although building a histogram of  @xmath0-mers seems to be quite a simple task from an algorithmic point of view , it has attracted a considerably amount of attention in recent years .",
    "in fact , the counting of  @xmath0-mers becomes a challenging problem for large instances , if it is to be both resource- and time - efficient and therefore makes it an interesting object of study for algorithm engineering .",
    "existing tools for  @xmath0-mer counting are often optimized for  @xmath2 and lack good performance for larger  @xmath0 .",
    "recent advances in technology towards larger read lengths are leading to the quest to cope with values of  @xmath0 exceeding  32 .",
    "studies elaborating on the optimal choice for the value of  @xmath0 recommend for various applications relatively high values @xcite . in particular , working with long sequencing reads helps to improve accuracy and contig assembly ( with  @xmath0 values in the hundreds )  @xcite . in this paper",
    ", we develop a tool with a high performance for such large values of  @xmath0 .      among the first software tools that succeeded in counting the  @xmath0-mers of large genome data sets was jellyfish @xcite , which uses a lock - free hash table that allows parallel insertion . in the following years",
    ", several tools were published , successively reducing running time and required memory .",
    "bfcounter  @xcite uses bloom filters for  @xmath0-mer counting to filter out rarely occurring  @xmath0-mers stemming from sequencing errors .",
    "other tools like dsk @xcite and kmc @xcite exploit a two - disk architecture and aim at reducing expensive io operations .",
    "turtle @xcite replaces a standard bloom filter by a cache - efficient counterpart .",
    "mspkmercounter @xcite introduces the concept of minimizers to the  @xmath0-mer counting , thus further optimizing the disk - based approach .",
    "the minimizer approach was later on refined to signatures within kmc2 @xcite .",
    "up to now , the two most efficient open source software tools have been kmc2 and dsk .",
    "kmc2 uses a sorting based counting approach that has been optimized for  @xmath2 .",
    "however , its performance drops when  @xmath0 grows larger .",
    "instead , dsk uses a single large hash table and is therefore efficient for large  @xmath0 ( but does not support  @xmath3 ) .",
    "however , for small  @xmath0 , it is clearly slower than kmc2 . to the best of our knowledge ,",
    "the only existing approach that uses gpus for counting  @xmath0-mers is the work by suzuki et al .",
    "@xcite .      in this article",
    "we present the open source  @xmath0-mer counting tool _",
    "gerbil_. our software is the result of an extensive process of algorithm engineering that tried to bring together the best ideas from the literature .",
    "the result is a  @xmath0-mer counting tool that is both time efficient and memory frugal .",
    "in addition , _ gerbil _ can optionally use gpus to accelerate the counting step .",
    "it outperforms its strongest competitors both in efficiency and resource consumption significantly . for large values of  @xmath0",
    ", it reduces the runtime by up to a factor of four .",
    "the software is written in c++ and cuda and is freely available at https://github.com/uni-halle/gerbil under mit license .    in the next section",
    "we describe the general algorithmic work flow of _",
    "gerbil_. thereafter , in section  [ sec : implementation ] , we focus on algorithm engineering aspects that proved essential for high performance and describe details , like the integration of a gpu into the counting process . in section  [ sec : results ] , we evaluate _ gerbil _",
    "s performance in a set of experiments and compare it with those of kmc2 and dsk .",
    "we conclude this article by a short summary and a glance on future work .",
    "_ gerbil _ is divided into two phases : ( 1 ) distribution and ( 2 ) counting . in this section ,",
    "we give a high - level description of _ gerbil _ s work flow .",
    "whole genome data sets typically do not fit into the main memory .",
    "hence , it is necessary to split the input data into a couple of smaller temporary files .",
    "_ gerbil _ uses a two - disk approach that is similar to those of most contemporary  @xmath0-mer counting tools @xcite .",
    "the first disk contains the input read data and is used to store the counted  @xmath0-mer values .",
    "we call this disk input / output - disk . the second disk , which we call working disk , is used to store temporary files .",
    "the key idea is to assure that the temporary files partition the input reads in such a way , that all occurrences of a certain  @xmath0-mer are stored in the same temporary file .",
    "this way , one can simply count the  @xmath0-mers of the temporary files independently of each other , with small main memory requirements . to split the genome data into temporary files , we make use of the _ minimizer _ approach that has been proposed by  @xcite and later on refined by  @xcite",
    ". a genome sequence can be decomposed into a number of overlapping _ super - mers_. each super - mer is a substring of maximal length such that all  @xmath0-mers on that substring share the same minimizer .",
    "hereby , a minimizer of a  @xmath0-mer is defined as its lexicographically smallest substring of a fixed length  @xmath4 with respect to some total ordering on strings of length  @xmath5 .",
    "see fig .",
    "[ fig : miminizerexample ] for an example .",
    "it suffices to partition the set of super - mers into different temporary files to achieve a partitioning of all different  @xmath0-mers @xcite .     and  @xmath6 .",
    "for each  @xmath0-mer , the bold part is its minimizer .",
    "the example uses the lexicographic ordering on 3-mers based on  @xmath7 .",
    "the sequence is divided into the five super - mers ` caaga ` , ` agaa ` , ` gaaca ` , ` acag ` , and ` cagtg ` that would be stored in temporary files.,scaledwidth=40.0% ]      the counting of  @xmath0-mers is typically done by one of two approaches : sorting and compressing  @xcite or using a hash table with  @xmath0-mers as keys and counters as values  @xcite .",
    "the efficiency of the sorting approach typically relies on the sorting algorithm radix sort , whose running time increases with the length of  @xmath0-mers .",
    "since we aim at high efficiency for large  @xmath0 , we decided to implement the hash table approach .",
    "therefore , we use a specialized hash table with  @xmath0-mers as keys and counters as values .",
    "we use a hash table that implements open addressing and solves collisions via double hashing .",
    "[ alg : hashinsert ] shows a high level description of the insertion method .",
    "hash table  @xmath8 ,  @xmath0-mer  @xmath9 , maximal number of trials  @xmath10 .",
    "@xmath11  @xmath12",
    "@xmath13  @xmath14  @xmath15 start emergency mechanism .",
    "although the following description of the main process is sequential , all of the steps are interleaved and therefore executed in parallel .",
    "this is done by a classical pipeline architecture .",
    "each output of a step makes the input of the next .",
    "we use ring buffers to connect the steps of the pipeline .",
    "such buffers are specialized for all combinations of single ( s)/multiple ( m ) producers ( p ) and single ( s)/multiple ( m ) consumers ( c ) .",
    "the actual number of parallel threads depend on the system and is determined by the software at runtime to achieve optimal memory throughput .",
    "the goal of the first phase is to split the input data into a number of temporary files .",
    "[ fig : phase1 ] visualizes the first phase .    1 .",
    "a group of reader threads read the genome reads from the input disk into the main memory .",
    "for compressed input , these threads also decompress it .",
    "a second group of parser threads convert the read data from the input format into an internal read bundle format .",
    "a group of splitter threads compute the minimizers of the reads .",
    "all subsequent substrings of a read that share the same minimizer are stored as a super - mer into an output buffer .",
    "a single writer thread stores the output buffers to a variable number of temporary files at the working disk .    ]    ]      after the first phase has been completed , the temporary files are sequentially re - read from working disk and processed in the following manner ( see fig .  [",
    "fig : phase2 ] ) .    1 .",
    "a single reader thread reads the super - mers of a temporary file and stores them in main memory .",
    "a group of threads split the super - mers into  @xmath0-mers .",
    "each  @xmath0-mer is distributed to one of multiple hasher threads by using a hash function on each  @xmath0-mer .",
    "this ensures that multiple occurrences of the same  @xmath0-mer are assigned to the same hasher thread and allows the distribution of separated hash tables to different memory spaces .",
    "a group of hasher threads insert the  @xmath0-mers into their thread - own hash tables .",
    "after a temporary file has been completely processed , each hasher thread sends the content of its hash table to an output buffer .",
    "4 .   a single writer thread writes from the output buffer to the output disk .",
    "dna reads typically contain bases that could not been identified correctly during the sequencing process .",
    "usually , such bases are marked @xmath16 in fastq input files . in accordance with established  @xmath0-mer counting tools",
    ", we ignore all  @xmath0-mers that contain an undetermined base .",
    "since dna is organized in double helix form , each  @xmath0-mer  @xmath17 corresponds to its _ reverse - complement _ that is defined by reversing  @xmath9 and replacing  @xmath18 and  @xmath19 .",
    "thus , the  @xmath0-mer  @xmath20 corresponds to  @xmath21 .",
    "many applications do not distinguish between a  @xmath0-mer and its reverse - complement .",
    "thus , each occurrence of  @xmath20 and  @xmath21 is counted as occurrences of their unique _",
    "canonical _ representation .",
    "_ gerbil _ uses the lexicographically smaller  @xmath0-mer as canonical representation .",
    "the use of reverse complement normalization can be turned off by command flag .",
    "we now want to point out several details on the algorithm engineering process that were essential to gain high performance .",
    "the choice of a total ordering has large effects on the size of temporary files and thus , also on the performance . to find a good total ordering",
    ", we have to balance various aspects .",
    "on the one hand , the total number of resulting super - mers are to be minimized to reduce the total size of disk memory that is needed by temporary files . on the other hand",
    ", the maximal number of distinct  @xmath0-mers that share the same minimizer should not be too large since we want an approximately uniform distribution of  @xmath0-mers to the temporary files .",
    "an `` ideal '' total ordering would have both a large total number of super - mers and a small maximal number of distinct  @xmath0-mers per minimizer .",
    "since these requirements contradict each other , we experimentally evaluated the pros and cons of various ordering strategies .",
    "cgat : :    the lexicographic ordering of minimizers based    on  @xmath22 .",
    "roberts et al .",
    "@xcite : :    they propose the lexicographic ordering of minimizers with respect    to  @xmath23 . furthermore , within the minimizer    computation all bases at even positions are to be replaced by their    reverse complement . thus , rare minimizers like  @xmath24    are preferred .",
    "kmc2 : :    the ordering that is proposed by  @xcite is a lexicographic ordering    with  @xmath7 and some built - in exceptions to eliminate    the large number of minimizers that start with  @xmath25    or  @xmath26 .",
    "random : :    a random order of all string of fixed length  @xmath5 is    unlikely to have both a small number of super - mers and a highly    imbalanced distribution of distinct  @xmath0-mers .",
    "it is simple    to establish , since we do not need frequency samples or further    assumptions about the distribution of minimizers .",
    "distance from pivot ( dfp(@xmath27 ) ) : :    to explain this strategy , consider the following observations :    ascendingly sorting the minimizers by their frequency favors rare    minimizers . as a consequence , the maximal number of    distinct  @xmath0-mers per minimizer is small .",
    "however , the    total number of super - mers can be very large .",
    "similarly , an    descendingly sorted ordering results in quite the opposite effect .",
    "to    find a compromise between both extremes , we initially sort the set of    minimizers by their frequency .",
    "since the frequencies depend on the    data set , we approximate them by taking samples during runtime .",
    "we fix    a pivot factor  @xmath28 and re - sort the minimizers    by the absolute difference of their initial position to the pivot    position  @xmath29 .",
    "the result is an ordering that does    neither prefer very rare nor very common minimizers and therefore    makes a good compromise .    ,",
    "@xmath30 ) .",
    "strategy dfp(@xmath31 ) has been tested with  @xmath32.,scaledwidth=50.0% ]      see fig .",
    "[ fig : minimizer ] for a rating of each strategy .",
    "the value on the  @xmath9-axis corresponds to the expected temporary disk memory , whereas the value on the  @xmath33-axis is correlated with the maximal main memory consumption of our program .",
    "a perfect strategy would be located at the bottom left corner .",
    "several strategies seem to be reasonable choices .",
    "we evaluated each strategy and found that a small number of super - mers is more important than a small maximal number of  @xmath0-mer per minimizer for most data sets . as a result",
    ", we confirm that the total ordering that is already been used by kmc2 is a good choice for most data sets .",
    "therefore , _ gerbil _ uses the strategy from kmc2 for its ranking of minimizers .",
    "the length  @xmath5 of miminizers is a parameter that has to be chosen with care .",
    "however , we can consider a basic rule : the larger @xmath5 is chosen , the less likely it becomes that consecutive @xmath0-mers share the same minimizer .",
    "therefore , the number of super - mers decreases with growing @xmath5 .",
    "an advantage of a smaller number of super - mers is that the set of super - mers can be distributed to the temporary files more uniformly , which results in temporary files of approximately uniform size .",
    "however , a major drawback of a large number of super - mers is the increased total size of temporary files .",
    "thus , a small @xmath5 results in a better data compression .    in our experiments , we found that choosing minimizer length  @xmath34 is most efficient for the data sets .      to integrate one or more gpus into the process of  @xmath0-mer counting , several problems have to be dealt with .",
    "typically , a gpu performs well only if it deals with data in a parallel manner .",
    "in addition , memory bound tasks ( i.e.tasks that do not require a lot of arithmetic operations ) like the counting of  @xmath0-mers require a carefully chosen memory access pattern to minimize the number of the accesses to the gpu s global memory .",
    "we decided to transfer the hash table based counting approach to the gpu .",
    "when compiled and executed with gpu support , _ gerbil _ automatically detects cuda capable gpus . for each gpu ,",
    "_ gerbil _ replaces a cpu hasher thread by a gpu hasher thread which maintains its own hash table in gpu memory .",
    "each gpu hash table is similar in function to a traditional hash table .",
    "however , unlike the traditional approach , we add a large number of  @xmath0-mers in parallel . therefore , the insertion procedure is slightly changed .",
    "first , a bundle of several thousand  @xmath0-mers is copied to the gpu global memory space .",
    "afterwards , we launch a large number of cuda blocks , each consisting of 32 threads .",
    "each block sequentially inserts a few  @xmath0-mers into the gpu hash table . since with increasing running time",
    ", it becomes more and more probable to find a mismatch when probing a hash table position , we additionally scan adjacent table positions in a range of 128 bytes when probing a hash table entry  ( see fig .  [ fig : memaccess ] ) . due to the architecture of a gpu ,",
    "this can be done within the same global memory access .",
    "thus , we scan up to 16 table entries in parallel , thereby reducing the number of accesses to a gpu s global memory . in addition , the total number of probing operations is drastically reduced . in particular , by probing just one entry after the other , 90.37% of all  @xmath35-mers of the _ f vesca _ data set ( table  [ tab : data ] ) can be inserted at first probing and no  @xmath35-mer needed more than 29 probings . in contrast , through scanning of adjacent table entries , 99.94% of all  @xmath35-mers could be inserted at the first trial and no  @xmath35-mer needed more than seven probing operations . to eliminate race conditions between cuda blocks ,",
    "we synchronize the probing of the hash table by using atomic operations to lock and unlock hash table entries .",
    "since such operations are efficiently implemented in hardware , a large number of cuda blocks can be executed in parallel .",
    "( 0,0.25 ) ",
    "( 1,0.25 ) ; ( 0,-0.25 ) ",
    "( 1,-0.25 ) ; ; ; ; ; ( 4.5,0.25 )  ( 5,0.25 ) ; ( 4.5,-0.25 )  ( 5,-0.25 ) ; at ( 6,0 ) ... ; ( 6,0.25 )  ( 6.5,0.25 ) ; ( 6,-0.25 ) ",
    "( 6.5,-0.25 ) ; ; ; ( 8.5,0.25 )  ( 9,0.25 ) ; ( 8.5,-0.25 )  ( 9,-0.25 ) ; ( 0.5,0 ) ",
    "node[above=0.4ex ] area that is scanned in parallel .",
    "( 7.5,0 ) ;      we dynamically balance the amount of  @xmath0-mers that are assigned to the various cpu and gpu hasher threads .",
    "therefore , we constantly measure the throughput of each hasher thread , i.e. the cpu - time needed to insert a certain number of  @xmath0-mers . whenever a new temporary file is loaded from disk",
    ", we rebalance the number of  @xmath0-mers that are assigned to each hasher thread , considering the throughput and capacity of each hash table . by that",
    ", we automatically determine a good division of labour between cpu and gpu hasher threads without the need of careful hand - tuning .",
    "we aim at estimating the expected size of each hash table as closely as possible to save main memory .",
    "we do so since reduced memory consumption leaves more memory to the operating system that can be used as cache when writing temporary files .",
    "therefore , we approximate the number of expected distinct  @xmath0-mers in each temporary file .",
    "we use a simple approximation mechanism that predicts the number of distinct  @xmath0-mers in a file by multiplying the number of  @xmath0-mers in each file with a constant that has been determined experimentally ( see fig .  [",
    "fig : kmerukmers ] ) . since this ratio depends on properties of the data set , we dynamically adjust the ratio during runtime .",
    "0.45        0.45       to insert a @xmath0-mer into the hash table , we use a hash function that implements double hashing .    ....",
    "/ * *   * hash function based on byte - wise interpretation of k - mers .   * @param kmer : a kmer that shall be inserted   * @param trial : the number of probings   * / uint32_t hash(const kmer < k > & kmer , const uint32_t trial ) {      uint8_t * keybytes = ( uint8_t * ) & kmer ;    // interpret kmer as byte array      uint32_t h1 = 0 ;     // value of first hash function      uint32_t h2 = 0 ;     // value of second hash function      for ( uint32_t i = 0 ; i < sizeof(kmer ) ; i++ ) {          h1 = 31 * h1 + keybytes[i ] ;          h2 = 37 * h2 + ~keybytes[i ] ;      }      return h1 + trial * h2 ; } ....      as a general strategy we use double hashing .",
    "we stop the probing of the hash table after a constant number of trials .",
    "therefore , it is possible that  @xmath0-mers could not be inserted into a hash table .",
    "for that reason , _ gerbil _ has a built - in emergency mechanism that handles such  @xmath0-mers to prevent them from getting lost .",
    "hereby , cpu and gpu hasher threads have different strategies .",
    "cpu hasher threads store such  @xmath0-mers in an additional temporary file , which is processed after the work with the current temporary file has been completed .",
    "in contrast , gpu hasher threads use part of free gpu memory to sequentially store those  @xmath0-mers that could not be inserted .",
    "after all  @xmath0-mers of a temporary file have been processed , the  @xmath0-mers in this area are counted via a sorting and compression approach .",
    "however , it is still possible to exceed the available gpu memory . in such a case",
    ", we copy the whole amount of  @xmath0-mers in that area back to main memory and store them in a temporary file , similar to the cpu emergency handling .",
    "such an operation is very costly .",
    "however , we have never observed a single gpu error handling and only few executions of cpu error handling when processing real world data sets .",
    "we tested our implementation in a set of experiments , using the same instances as deorowicz et al .",
    "@xcite ( see table  [ tab : data ] ) . for each data set we counted all  @xmath0-mers for  @xmath36 and  @xmath37 and compared _ gerbil _",
    "s running time with those of kmc2 in version 2.3.0 and dsk in version 2.0.7 .",
    "in addition , we used a synthesized test set _ grch38 _ , created from genome reference consortium human reference 38 ( gca_000001405.2 ) , from which we uniformly sampled  @xmath0-mers of size 1000 .",
    "the purpose of this data set is to have longer reads allowing to test the performance for larger values of  @xmath0 . to judge performance on various types of hardware , we executed the experiments on two different desktop computers .",
    "see table  [ tab : hardware ] for details about the hardware configuration of the test systems .",
    ".test systems .",
    "[ cols= \" < , > , > , > , > , > \" , ]",
    "we introduced the  @xmath0-mer counting software _",
    "gerbil _ that uses a hash table based approach for the counting of  @xmath0-mers . for large  @xmath0 , a use case that becomes important for long reads ,",
    "we are able to clearly outperform the state - of - the - art open source  @xmath0-mer counting tools , while using significantly less resources .",
    "we showed that _",
    "s running time can be accelerated by the use of gpus . however , since this only affects the second phase , the overall additional speedup is only very moderate . as future work , we plan to evaluate strategies to use gpus to accelerate also the first phase .",
    "another option for further speed - up would be to give up exactness by using bloom filters .",
    "10 [ 1]`#1 `    chikhi , r. , medvedev , p. : informed and automated @xmath0-mer size selection for genome assembly .",
    "bioinformatics 30(1 ) , 3137 ( 2014 )    deorowicz , s. , debudaj - grabysz , a. , grabowski , s. : disk - based k - mer counting on a pc .",
    "bmc bioinformatics 14(1 ) , 112 ( 2013 )    deorowicz , s. , kokot , m. , grabowski , s. , debudaj - grabysz , a. : kmc 2 : fast and resource - frugal k - mer counting .",
    "bioinformatics 31(10 ) , 15691576 ( 2015 )    li , y. , et  al .",
    ": mspkmercounter : a fast and memory efficient approach for k - mer counting .",
    "arxiv preprint arxiv:1505.06550 ( 2015 )    marais , g. , kingsford , c. : a fast , lock - free approach for efficient parallel counting of occurrences of k - mers .",
    "bioinformatics 27(6 ) , 764770 ( 2011 )    melsted , p. , pritchard , j.k . :",
    "efficient counting of k - mers in dna sequences using a bloom filter .",
    "bmc bioinformatics 12(1 ) , 17 ( 2011 )    rizk , g. , lavenier , d. , chikhi , r. : dsk : k - mer counting with very low memory usage .",
    "bioinformatics 29(5 ) , 6523 ( 2013 )    roberts , m. , hayes , w. , hunt , b.r . ,",
    "mount , s.m . ,",
    "yorke , j.a . : reducing storage requirements for biological sequence comparison .",
    "bioinformatics 20(18 ) , 33633369 ( 2004 )    roberts , m. , hunt , b.r . , yorke , j.a . ,",
    "bolanos , r.a . ,",
    "delcher , a.l . : a preprocessor for shotgun assembly of large genomes .",
    "journal of computational biology 11(4 ) , 734752 ( 2004 )    roy , r.s . ,",
    "bhattacharya , d. , schliep , a. : turtle : identifying frequent k - mers with cache - efficient algorithms .",
    "bioinformatics 30(14 ) , 19507 ( 2014 )    sameith , k. , roscito , j.g .",
    ", hiller , m. : iterative error correction of long sequencing reads maximizes accuracy and improves contig assembly .",
    "briefings in bioinformatics ( 2016 ) , http://dx.doi.org/10.1093/bib/bbw003    shuji  suzuki , masanori  kakuta , t.i.y.a . : accelerating identification of frequent k - mers in dna sequences with gpu . in : gtc 2014 ( 2014 )    xavier , b.b . , sabirova , j. , pieter , m. , hernalsteens , j.p . ,",
    "de  greve , h. , goossens , h. , malhotra - kumar , s. : employing whole genome mapping for optimal de novo assembly of bacterial genomes .",
    "bmc research notes 7(1 ) , 14 ( 2014 )",
    "_ gerbil _ can be controlled by several command line arguments and flags .",
    "lxr command & description & default + ` -k length ` & set the value of  @xmath0 , i.e. the length of  @xmath0-mers to be counted . supported  @xmath0 range from  @xmath38 to  @xmath39 . &",
    "28 + ` -m length ` & set the length  @xmath5 of minimizers . & auto + ` -e size ` & restrict the maximal size of main memory in ` mb ` or ` gb ` that _ gerbil _ is allowed to use . & auto + ` -f number ` & set the number of temporary files . & 512 + ` -t number ` & set the maximal number of parallel threads to use . & auto + ` -l count ` & set the minimal occurrence of a  @xmath0-mer to be outputted . & 3 + ` -i ` & enable additional output . & + ` -g ` & enable gpu mode .",
    "_ gerbil _ will automatically detect cuda - capable devices and will use them for counting in the second phase . &",
    "+ ` -v ` & show version number . & + ` -d ` & disable normalization of  @xmath0-mers .",
    "if normalization is disabled , a  @xmath0-mer and its reverse complement are considered as different  @xmath0-mers . if normalization is enabled , we map both  @xmath0-mer and its reverse complement to the same  @xmath0-mer . & + ` -s ` & perform a system check and display information about your system . &",
    "+ ` -x 1 ` & stop execution after phase one . do not remove temporary files and a ` binstatfile ` ( with statistical information ) .",
    "watch out : no ` output ` allowed . & + ` -x 2 ` & only execute phase two .",
    "requires temporary files and the ` binstatfile ` . & + ` -x b ` & do not remove the ` binstatfile ` . &",
    "+ ` -x h ` & create a histogram of @xmath0-mers in a human readable format in output directory . &",
    "_ gerbil _ supports the following input formats of genome read data : fastq , fasta , staden , as well as compressed files of these formats . to process multiple files",
    ", it also supports textfiles with paths to one or more input files .",
    "_ gerbil _ uses an output format that is easy to parse and requires little space .",
    "the counter of each occuring  @xmath0-mer is stored in binary form , followed by the corresponding byte - encoded  @xmath0-mer .",
    "each four bases of a  @xmath0-mer are encoded in one single byte .",
    "we encode a with 00 , c with 01 , g with 10 and t with 11 .",
    "most counters of  @xmath0-meres are slightly smaller than the coverage of the genome data .",
    "we exploit this property by using only one byte for counters less than 255 .",
    "a counter greater than or equal to 255 is encoded in five bytes . in the latter case ,",
    "all bits of the first byte are set to 1 .",
    "the remaining four bytes contain the counter in a conventional 32-bit unsigned integer .",
    "examples ( x is undefined ) :    * ` 67 aacgtg `  @xmath40 ` 01000011 00000110 1110xxxx ` * ` 345 tggatc `  @xmath40 ` 11111111 00000000 00000000 00000001 01011001 11101000 1101xxxx `    when called with command line argument ` -x h ` , _ gerbil _ additionally creates a human readable csv file including the same , but uncompressed information",
    ". this option should only be used for very small data sets .",
    "the data sets were downloaded from the following url s .        ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030575/srr072005.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030576/srr072006.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030576/srr072007.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030577/srr072008.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030577/srr072009.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030575/srr072010.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030575/srr072011.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030575/srr072012.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030578/srr072013.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030578/srr072014.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra020/sra020125/srx030578/srr072029.fastq.bz2 +        ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030308/srx043656/srr105788_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030308/srx043656/srr105788_2.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030309/srx043656/srr105789_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030309/srx043656/srr105789_2.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030312/srx043656/srr105792_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030312/srx043656/srr105792_2.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030314/srx043656/srr105794.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030314/srx043656/srr105794_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra030/sra030314/srx043656/srr105794_2.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036382/srx043656/srr197985.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036382/srx043656/srr197985_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036382/srx043656/srr197985_2.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036383/srx043656/srr197986.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036383/srx043656/srr197986_1.fastq.bz2 + ftp://ftp.ddbj.nig.ac.jp/ddbj_database/dra/fastq/sra036/sra036383/srx043656/srr197986_2.fastq.bz2 +              ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr359301.filt.fastq.gz + ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr359301_1.filt.fastq.gz + ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr359301_2.filt.fastq.gz + ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr360755.filt.fastq.gz + ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr360755_1.filt.fastq.gz + ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/hg02057/sequence_read/srr360755_2.filt.fastq.gz +"
  ],
  "abstract_text": [
    "<S> a basic task in bioinformatics is the counting of  @xmath0-mers in genome strings . </S>",
    "<S> the _ @xmath0-mer counting problem _ is to build a histogram of all substrings of length  @xmath0 in a given genome sequence . </S>",
    "<S> we present the open source  @xmath0-mer counting software _ </S>",
    "<S> gerbil _ that has been designed for the efficient counting of  @xmath0-mers for  @xmath1 . </S>",
    "<S> given the technology trend towards long reads of next - generation sequencers , support for large  @xmath0 becomes increasingly important . while existing  @xmath0-mer counting tools suffer from excessive memory resource consumption or degrading performance for large  @xmath0 , _ gerbil _ is able to efficiently support large  @xmath0 without much loss of performance . </S>",
    "<S> our software implements a two - disk approach . in the first step , </S>",
    "<S> dna reads are loaded from disk and distributed to temporary files that are stored at a working disk . in a second step , the temporary files are read again , split into  @xmath0-mers and counted via a hash table approach . </S>",
    "<S> in addition , _ gerbil _ can optionally use gpus to accelerate the counting step . for large  @xmath0 </S>",
    "<S> , we outperform state - of - the - art open source  @xmath0-mer counting tools for large genome data sets . </S>"
  ]
}