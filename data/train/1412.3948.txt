{
  "article_text": [
    "the recent technological revolution with widespread presence of computers , users and media connected by internet has created an unprecedented situation of data deluge , changing dramatically the way in which we look at social and economic sciences .",
    "as people increasingly use the internet for information such as business or political news , online activity has become a mirror of the collective consciousness , reflecting the interests , concerns , and intentions of the global population with respect to various economic , political , and cultural phenomena .",
    "humans interactions with technological systems are generating massive datasets documenting collective behaviour in a previously unimaginable fashion @xcite . by properly dealing with such data collections , for instance representing them by means of network structures @xcite ,",
    "it is possible to extract relevant information about the evolution of the systems considered ( i.e. trading @xcite , disease spreading @xcite , political elections @xcite ) .",
    "a particularly interesting case of study is that of the financial markets .",
    "markets can be seen as collective decision making systems , where exogenous ( news ) as well as endogenous ( price movements ) signals convey valuable information on the value of a company .",
    "investors continuously monitor these signals in the attempt of forecasting future price movements . because of their trading based on these signals ,",
    "the information is incorporated into prices , as postulated by the efficient market hypothesis @xcite .",
    "therefore the flow of news and data on the activity of investors can be used to forecast price movements .",
    "the literature on the relation between news and price movement is quite old and vast . in order to correlate news and price returns one needs to assess whether the former is conveying positive or negative information about a company , a particular sector or on the whole market",
    "this is typically done with the sentiment analysis , often performed with dedicated semantic algorithms as described and reviewed in the methods section .    in this paper , we combine the information coming from the sentiment conveyed by public news with the browsing activity of the users of a finance specialized portal to forecast price returns at daily and intra - day time scale . to this aim",
    "we leverage a unique dataset consisting of a fragment of the log of yahoo !",
    "finance , containing the news articles displayed on the web site and the respective number of `` clicks '' , i.e. the visualizations made by the users .",
    "our analysis considers 100 highly capitalized us stocks in a one - year period between 2012 and 2013 .",
    "for each of these companies we build a signed time series of the sentiment expressed in the related news .",
    "the sentiment expressed in each article mentioning a company is weighted by the number of views of the article . in our dataset",
    "each click action is associated with a timestamp recording the exact point in time when such action took place .",
    "thus we are able to construct time series at the time resolution of the minute . to the best of our knowledge ,",
    "this is the first time that an analysis like the one described in this paper is conducted at such intra - day granularity .",
    "the main idea behind this approach is that the sentiment analysis gives information on the news , while the browsing volume enable us to properly weigh news according to the attention received from the users .",
    "we find that news on the same company are extremely heterogeneous in the number of clicks they receive , an indication of the huge difference in their importance and the interest these news generate on users . for 70% of the companies examined , there is a significant correlation between the browsing volumes of financial news related to the company , and its traded volumes or absolute price returns . more important , we show that for more than 50% of the companies ( at hourly time scale ) , and for almost 40% ( at daily time scale ) , the click weighted average sentiment time series granger - cause price returns , indicating a rather large degree of predictability .",
    "our analysis is conducted on highly capitalized stocks belonging to the russell 3000 index traded in the us equity markets , which we monitor for a period of one year between 2012 and 2013 . among all companies , we selected the 100 stocks with the largest number of news published onyahoo !",
    "finance during the investigated period .",
    "the ticker list of the investigated stocks with a distinctive numerical company identifier follows : 1  kbh , 2  len , 3  cost , 4  dtv , 5  amgn , 6  yum , 7  ups , 8  v , 9  aet , 10  grpn , 11  znga , 12  abt , 13  luv , 14  rtn , 15  hal , 16  atvi , 17  mrk , 18  gps , 19  gild , 20  lcc , 21  nke , 22  mcd , 23  unh , 24  dow , 25  m , 26  cbs , 27  cop , 28  chk , 29  cat , 30  hon , 31  twx , 32  aig , 33  ual , 34  txn , 35  biib , 36  wag , 37  pep , 38  vmw , 39  ko , 40  qcom , 41  acn , 42  noc , 43  dish , 44  bby , 45  hd , 46  pg , 47  jnj , 48  axp , 49  mar , 50  twc , 51  utx , 52  ma , 53  blk , 54  ebay , 55  dal , 56  nwsa , 57  msci , 58  lnkd , 59  tsla , 60  cvx , 61  aa , 62  nyx , 63  jcp , 64  cmcsa , 65  ndaq , 66  it , 67  yhoo , 68  dis , 69  sbux , 70  pfe , 71  orcl , 72  hpq , 73  s , 74  lmt , 75  xom , 76  ibm , 77  nflx , 78  intc , 79  csco , 80  ge , 81  wfc , 82  wmt , 83  amzn , 84  vod , 85  dell , 86  f , 87  tri , 88  gm , 89  frt , 90  vz , 91  fb , 92  bac , 93  ms , 94  jpm , 95  c , 96  ba , 97  gs , 98  msft , 99  goog , 100  aapl .",
    "the numerical identifiers are assigned according to the increasing order of the total number of published news in yahoo ! finance .",
    "we considered three main sources of data for the selected stocks :      the first source contains information on price returns and trading volume of the stock at the resolution of the minute .",
    "we consider different time scales of investigation , corresponding to @xmath0 , @xmath1 , @xmath2 , @xmath3 , and @xmath4 minutes .",
    "the above values are chosen because they are sub - multiple of the trading day in the us markets ( from 9:30 am to 4:00 pm , corresponding to @xmath5 minutes ) . for each time scale and each stock",
    "we extract the following time series :    * @xmath6 , the traded volume in that interval of time , * @xmath7 , the logarithmic price return in the time scale , * @xmath8 , the return absolute value , a simple proxy for the stock volatility .    the precise definition of these variables is given in materials section . since trade volumes and absolute price returns are known to display a strong intra - day pattern , we de - seasonalize the corresponding time series ( in the same section we provide the details about this procedure ) .",
    "this procedure is necessary in order to avoid the detection of spurious correlation and granger causality due to the presence of a predictable intra - day pattern .",
    "the second source of data consists of the news published on yahoo !",
    "finance together with the time series of the aggregated clicks made by the users browsing each page .",
    "yahoo ! finance is a web portal for news and data related to financial companies , offering news and information around stock quotes , stock exchange rates , corporate press releases , financial reports , and message boards for discussion . providing consumers with a broad range of comprehensive online financial services and information , yahoo !",
    "finance has consistently been a leader in its category : in may 2008 it was the top financial website with 18.5 million u.s .",
    "visitors , followed by aol money & finance with 15.2 million visitors ( up 48 percent ) and msn money with 13.7 million visitors ( up 13 percent ) . as of today , recent estimates released in july 2015 confirm that yahoo !",
    "finance , with more than 72 million visitors , is still the leader finance website in the us , and the fourth in the whole world .",
    "we analyze a portion of the log of yahoo !",
    "finance , containing news articles displayed on the portal .",
    "the articles are tagged with the specific companies ( e.g. , google , yahoo ! , apple , microsoft ) or financial entities ( e.g. , market indexes , commodities , derivatives ) that are mentioned in its text .",
    "the dataset analyzed in this work does not consist of public data .",
    "it was extracted from a browsing log of the yahoo !",
    "finance web portal .",
    "the log stores all the actions made by the users who visit the website , such as views , clicks and comments on every page displayed on the portal . specifically , we extracted the news articles displayed on yahoo !",
    "finance and the respective number of `` clicks '' , i.e. the visualizations made by the users .",
    "we considered 100 us stocks in a one - year period between 2012 and 2013 .    for each considered company",
    "we build a signed time series of the sentiment expressed in the related news .",
    "the sentiment expressed in each article mentioning a company is weighted by the number of views of the article . in our dataset",
    "each click action is associated with a timestamp recording the exact point in time when such action took place .",
    "thus we are able to construct time series at the time resolution of the minute . while building the dataset , we observed the corporate policy of yahoo with respect to the confidentiality of the data and the tools used in this research .",
    "any sensitive identifier of yahoo user was discarded after the extraction and aggregation process .",
    "moreover our dataset does not store single actions or users , but only aggregated browsing volumes of financial articles displayed on yahoo !",
    "although the original log of yahoo ! finance is proprietary and can not obviously be shared , for repeatability of our analysis we can provide the browsing - volume time series extracted for the 100 companies as supplementary material .    in order to automatically detect whether the article is conveying positive or negative news on the company , we perform a sentiment analysis . to obtain a sentiment score ,",
    "we classify each article with _ sentistrength _",
    "@xcite , a state - of - the - art tool for extracting positive and negative sentiment from informal texts .",
    "the tool is based on a dictionary of `` sentiment '' words , which are manually picked by expert editors and annotated with a number indicating the amount of positivity or negativity expressed by them .",
    "the original dictionary of _ sentistrength _ is not tailored to any specific knowledge or application domain , thus it is not the most proper choice to compute a _",
    "financial _ sentiment . to solve this issue , following a practice that is common in most research on sentiment analysis and price returns  @xcite",
    ", we adapt the original dictionary by incorporating a list of sentiment keywords of special interest and significance for the financial domain @xcite . in materials",
    "section we discuss the robustness of this choice as well as the way news are associated to stocks .",
    "supported by previous research that studied stock price reaction to news headlines  @xcite , we simplify our data processing pipeline by performing the sentiment analysis computation on the title of each article , instead of using its whole content .",
    "the main reason for this choice is that the tone of the news is typically highlighted in the title , while the use in the text of many neutral words can increases the noise and reduces the ability of assessing the sentiment .",
    "finally , the choice also depended on the availability of data : the log at our disposal did not always contained the text of the news and this would have forced us to use a significant subsample .",
    "the sentiment score is a simple sign @xmath9 for each news depending on whether there are more positive or negative words in the title .",
    "finally , in our analysis we use the information on the browsing volume , that is , the time series of `` clicks '' that the web users made on each article displayed on yahoo ! finance to view its content . given that the users activity on this domain - specific portal proved to provide a clean signal of interest in financial stocks @xcite , we exploit it in this work to weight the sentiment of each article on a given financial company .",
    "specifically , we use the number of clicks of an article as a proxy for the level of attention that users gave to that news . by aggregating over a time window the clicks on all the articles , even published earlier , that mention a particular company , it is possible to derive an estimation of the attention around that company .    in summary",
    ", for each time scale and for each stock , the variables we extract from the database are ( see materials section ) :    * @xmath10 , the time series of the total number of clicks in a time window , * @xmath11 , the sum of the sentiment of all news related to each company , * @xmath12 , the sum of the sentiment of all news weighted by the number of clicks .",
    "the first quantity @xmath10 is non negative and measures the level of attention in a given time interval for news about a specific company .",
    "the @xmath11 variable is the usual sentiment indicator employed in numerous studies and provides the aggregated sentiment of the company specific news published in a given time interval .",
    "the most important and novel quantity is @xmath12 , which combines the two previous ones by assigning a sign to each click depending on the sentiment of the clicked news .",
    "as for the market variables , we remove the intra - day pattern from the click time series .",
    "in fact , both the publication of news @xcite and the clicking activity of users @xcite show a strong intra - day seasonality . these patterns are probably related to the way humans carry out their activities during the day ( e.g. small activity during lunchtime , more hectic activity at the beginning or at the end of the business day ) .",
    "regarding the analysis of search - engine queries , some recent works @xcite have studied the relation between the daily number of queries related to a particular stock and the trading volume over the same stock .",
    "an incomplete list of contributions on the role of news includes studies investigating ( i ) the relation between exogenous news and price movements @xcite , ( ii ) the correlation between high or low pessimism of media and high market trading volume @xcite ; ( iii ) the relation between the sentiment of news , earnings and return predictability @xcite , ( iv ) the role of news in the trading action @xcite ; ( v ) the role of macroeconomic news in the performance of stock returns @xcite , and ( vi ) the high - frequency market reaction to news @xcite .",
    "for example , in a recent paper @xcite , related to ours , authors show that daily trading volumes of stocks traded at nasdaq can be forecasted with the daily volumes of queries related to the same stocks . in another paper",
    "a similar analysis shows that an increase in queries predicts higher stock prices in the next two weeks @xcite .",
    "in @xcite authors test the explanatory power of investor attention  measured as the search frequency at daily level of stock names in baidu index  for abnormal daily returns and find evidence that the former granger causes stock price returns in excess with respect to the market index return , whereas there is little evidence for the opposite causal relation . as for social networks and micro - blogging platforms @xcite , twitter data is becoming an increasingly popular choice for financial forecasting .",
    "for example some have investigated whether the daily number of tweets predicts sp 500 stock prices @xcite .",
    "a textual analysis approach to twitter data can be found in other works @xcite where the authors find clear relations between mood indicators and dow jones industrial average .",
    "some other authors have used news , wikipedia data or search trends to predict market movements @xcite .",
    "there are two main critical aspects in the kind of analyses described above .",
    "first , the universe of all the search engine or social network users is probably too large and the fraction of users truly interested in finance is likely quite low .",
    "this is particularly true at intraday frequency , investigated in this paper .",
    "second , as we will empirically show below , the universe of news considered is very heterogeneous in terms of their relevance as a signal of future price movement .",
    "for example , in a day there might be several positive but almost irrelevant news and only one negative but very important news on a company . without weighting the relevance of the news",
    ", one could easily draw a wrong conclusion .",
    "the intuition behind the current work is that the number of times a news is viewed by users is a measure of its importance as well as of the surprise it conveys .",
    "moreover the users we consider are not generic , but are those who use one of the most important news and search portals for financial information , namely yahoo ! finance .      to overcome these limitations we collected for each stock and for each time scale a total of six time series , namely @xmath6 , @xmath7 , @xmath8 , @xmath10 , @xmath11 , and @xmath12 , and we study their dependence by making use of two tools .",
    "first , given two time series @xmath13 and @xmath14 , we consider the spearman s correlation coefficient @xmath15 where @xmath16 and @xmath17 correspond to the rank of the @xmath18-th realization of the @xmath19 and @xmath20 random variables , respectively , and @xmath21 is the time average value .",
    "the correlation @xmath22 quantifies the linear contemporaneous dependence without relying on the normal assumption for @xmath19 and @xmath20 . in order to assess the statistical significance of the measured value",
    "we perform a statistical test of the null hypothesis that the correlation is zero by randomizing the time series .",
    "our main goal is testing for the presence of statistical causality between the variables .",
    "to this end our second tool is the granger causality test @xcite .",
    "granger s test is a common test used in time series analysis to determine if a time series @xmath13 is useful in forecasting another time series @xmath14 .",
    "@xmath13 is said to _ granger - cause _",
    "@xmath14 if @xmath14 can be better predicted using both the histories of @xmath13 and @xmath14 rather than using only the history of @xmath14 . the granger causality can be assessed by regressing @xmath14 on its own time - lagged values and on those of @xmath13 .",
    "an f - test is then used to examine whether the null hypothesis that @xmath14 is not granger - caused by @xmath13 can be rejected with a given confidence level ( in this paper we use a p - value of 5% ) .",
    "the most important aspect of our analysis is to test whether one can forecast financial variables , and more specifically price returns , by using the information on the browsing activity of the users .",
    "namely if , by weighting the sentiment of the clicked news by the number of clicks each news receives , one can improve significantly the predictability of returns .      the first observation is the extreme heterogeneity of the attention that users of yahoo !",
    "finance show towards the financial news of a given company .",
    "figure [ heterogeneity ] shows the complementary of the cumulative distribution function of the number of clicks per news concerning a given stock .",
    "there we show the curves for each of the top 10 stocks and for the aggregate of 100 stocks . in all cases",
    "the tail of the distribution is very well fit by a power law behavior  @xcite with a tail exponent very close to @xmath0 ( see materials section ) in fact , the mean exponent across all stocks is @xmath23 and restricting on the top @xmath1 it is @xmath24 .",
    "this indicates that there is a huge heterogeneity in the number of clicks a news receives and therefore in the importance users give to it .",
    "it is also a warning that not weighting properly the importance of the news can lead to overstate the importance of the many irrelevant news and to understate the importance of the few really important ones .    .",
    "the dotted line corresponds to a power law with tail exponent fitted from the portfolio time series .",
    "we provide details about the standard error and the complete list of tail exponents for all the companies in materials section.,scaledwidth=75.0% ]      in order to understand how the relation between financial and news variables depends on the time scale , we perform a synchronous correlation analysis .",
    "for each of the 100 companies , we compute the spearman s correlation coefficient @xmath25 between the three sensible pairs made by one `` news '' time series and one `` financial '' time series .",
    "figure [ fcor1 ] summarizes the results for the 65 min time series .",
    "the x axis lists the companies , uniquely identified by a number that provides the rank of the company in the order from the least to the most cited one ( as measured by the absolute number of associated news ) .",
    "thus , 1 corresponds to the company kbh with the least number of news , while 100 to the most cited aapl .",
    "we label the y axis with the pairs @xmath26 , @xmath27 , and @xmath28 , while the color scale indicates the level of correlation .",
    "we compute the correlation sampling the original time series every 65 minutes , equalizing to zero those values whose significance does not reject the null hypothesis of zero correlation with 5% confidence .",
    "figure  [ fcor1 ] shows in general a positive and significant correlation between browsing activity and price volatility and volume , whereas the evidence of linear dependence between sentiment time series and price returns is mild , similarly to the result obtained by mao @xcite . in the fourth row of table  [ allcor1 ]",
    "we report the percentage of the 100 companies for which we reject the null hypothesis of zero correlation at 5% confidence level and .",
    "since we use multiple correlation tests in order to establish whether their is a significant relationship between key news and online quantities and key market variables , in the materials section we report results corrected for multiple hypotheses testing . applying the conservative correction proposed by bonferroni , the evidence of linear dependence enterily survives for click , volatility , and trade volume time series , whereas the hypothesis of zero - spearman s correlation between price returns and weighted sentiment is no more rejected .",
    "@lrrr time interval ( minutes ) & @xmath29 & @xmath30 & @xmath31 1 & 7 & 86 & 95 10 & 3 & 72 & 90 30 & 5 & 54 & 85 65 & 4 & 36 & 79 130 & 4 & 26 & 76    [ allcor1 ]      in order to investigate how the correlation changes with the time scale , in table  [ allcor1 ] we also show the percentage of rejection for the 1 , 10 , 30 , and 130 minutes time scales . as a general comment , we observe that the number of companies with a significant correlation becomes higher at finer time resolution .",
    "this is a known fact for market variables ( e.g. volume and volatility ) , while we document it for the first time at intraday scale also for browsing variables .",
    "the presence of a significant linear relation between the attention given to news articles ( signed on the basis of the sentiment expressed in them ) related to a given stock and the price return is mild .",
    "in particular the low fraction of companies rejecting the null hypothesis is compatible with the expected number of false positives due to multiple testing .",
    "please refer to materials section for the detailed results of a multiple test based on the bonferroni correction .",
    "the time scale might in principle depend on the relevance of the news .",
    "as we have seen , not all news are equal in terms of the attention they receive from the users . to investigate this dependence , we study the dynamics of the number of clicks an article received after its publication .",
    "we compute the cumulative number of clicks received by a given news until a given minute after the publication .",
    "we perform this for all minutes in a week after the publication .",
    "we then normalize this cumulative time series by dividing it by the total amount of clicks received by the news .",
    "we construct ten groups of news based on the deciles of the total number of news they eventually receive , and we compute for each group the average cumulative sum of clicks .     +    the result is shown in figure  [ dycdf ] .",
    "the inset reports for each decile the typical time scale of attention obtained by an exponential fit of the curves .",
    "remarkably , the time scale of attention is an increasing function of the importance of the news ( as measured by the total number of clicks ) .",
    "irrelevant news are immediately recognized as such , while important news continue to receive attention well after their publication .",
    "in general , the time scale of the users attention ranges between one and two hours after the publication , suggesting that this intraday time scale is probably the most appropriate to detect dependencies among financial variables and browsing activity .      the synchronous correlation is an important measure of dependence , but not necessarily a sign of causality .",
    "thus we perform a causality analysis by applying granger s test .",
    "we present the results of this analysis , for the 65-minute time horizon , in figure  [ gra1 ] .    ) .",
    "the white cells correspond to tests for which we do not reject the null hypothesis of no granger causality at 5% significance level .",
    "a black cell corresponds to a statistically significant granger causality.,scaledwidth=75.0% ]    the x axis lists the companies as done in figure  [ fcor1 ] , while the y axis labels the eight tests that we perform .",
    "black cells correspond to rejection of the null hypothesis of no granger causality , and the opposite for the white cells . when considering the non - negative variables ( @xmath6 , @xmath10 , and @xmath8 ) we observe strong causal relations .",
    "specifically , in 65% of the cases the clicking activity causes the trading volume and in 69% of the cases it causes price volatility .",
    "the causality is very strong also in the opposite direction , i.e. volume and volatility cause click volume .",
    "this is probably due in part to a reaction of users to anomalously high activity in the market ( in terms of volume and/or volatility ) , while in part it might be a statistical effect due to the fact that all the three variables are very autocorrelated in time , creating strong granger causal relations in both directions .",
    "we obtain the most interesting and unexpected results when considering the signed variables ( @xmath7 , @xmath11 , and @xmath12 ) .",
    "all these variables are weakly serially autocorrelated .",
    "when we consider the sentiment of the news ( @xmath11 , without the clicks ) , we find that only in 4% of the cases @xmath11 causes returns , and in 13% of the cases price return causes @xmath11 .",
    "especially the first value is expected under the null , since at 5% confidence level we expect 5% of false positive .",
    "this means that the simple sentiment of the news does not allow to forecast price returns at intraday ( hourly ) time scale . on the contrary ,",
    "when we consider the clicks weighted by the sentiment of the news ( @xmath12 ) , we find that in 53% of the cases it allows predicting returns and only in 19% of the cases the opposite occurs .",
    "in general , companies with more news have higher causality .",
    "our conclusions are even more striking when correcting the test for multiple hypotheses , as done for the spearman correlation case .",
    "the evidence of causality between price returns and unweighted sentiment of the news almost vanishes whereas the signal of causality between weighted sentiment and returns entirely survives .",
    "interestingly , the evidence of causality in the opposite direction ",
    "i.e. returns granger - causing weighted sentiment  weakens and an interesting asymmetric behavior between the two directions clearly emerges . in materials section",
    "we report the table with detailed results .",
    "these results show that , on a hourly time scale , the simple news sentiment time series alone ( i.e. the one without browsing activity ) is not able to predict the price returns ; instead , if we add the information provided by the browsing activity , we are then able to properly weigh the news ( and its sentiment ) by the importance the users give to it by clicking the page .",
    "thus , we find the interesting result that the browsing activity combined with the sentiment analysis of the news increases significantly the level of prediction of price returns for the stocks .",
    "most of the existing studies on sentiment and predictability of returns focus on daily or longer time scale . in order to compare properly our result with the existing literature , we present in table [ gra3 ] the results of the above granger tests on a daily time scale .",
    "table [ gra3 ] shows that , without the browsing activity , @xmath11 causes @xmath7 for 18% of the companies and @xmath7 granger - causes @xmath11 in 9% of the cases .",
    "thus there is now some predictability of sentiment , even if the number of companies is quite limited .",
    "this is consistent with the existing literature , which reports a weak daily predictability of returns by using sentiment .",
    "it is important to note that by adding the browsing activity we can double the number of companies for which there is predictability .",
    "in fact , @xmath12 granger - causes @xmath7 for 37% of the companies and 11% in the opposite direction .",
    "@lrr causality relation & hourly scale & daily scale @xmath32 & 4 & 18 @xmath33 & 13 & 9 @xmath34 & 19 & 11 @xmath35 & 53 & 37 @xmath36 & 100 & 97 @xmath37 & 65 & 52 @xmath38 & 69 & 52 @xmath39 & 96 & 16    [ gra3 ]",
    "we consider only trading hours ( i.e. from 9:30 am to 4:00 pm ) and trading days ( i.e. business days at the new york stock exchange ) , and we disregard the trading events that occur out of this time window . from the financial data we create",
    "three time series : the first one is the traded volume for each minute for each company , the second one is the logarithmic returns , and the last time series is the absolute value of the logarithmic returns .    1 .   * trade volume ( v ) time series*. it consists of the traded volume of a given company at minute time scale .",
    "we build a time series at time scale @xmath18 by summing the traded volumes @xmath40 at the smallest time scale @xmath41 ( in our case one minute ) .",
    "then , the total volume @xmath42 can be defined as follows : @xmath43 traded volumes at intra - day time @xmath18 are rescaled by a factor @xmath44 , which is computed as the average , over all days , of the volume at time @xmath18 normalized by the total daily volume . if @xmath45 is the raw volume of day @xmath46 and intra - day time @xmath18 , we define the rescaled time series as @xmath47 where @xmath48 and @xmath49 i.e. the total volume trades on day @xmath46 , and @xmath50 is the total number of trading days . 2 .",
    "* price return ( r ) time series*. we preliminary compute the logarithmic return , defined as @xmath51 where @xmath52 is the last recorded price in the interval @xmath53 $ ] .",
    "returns at intra - day time @xmath18 are rescaled by a factor @xmath54 , which is computed as the average , over all days , of absolute returns at time @xmath18 rescaled by the average volatility . more precisely ,",
    "if @xmath55 is the raw return of day @xmath46 and intra - day time @xmath18 , we define the rescaled time series as @xmath56 where @xmath57 and @xmath58 where we compute the mean value for all @xmath18 in a day @xmath46 .",
    "* volatility ( @xmath8 ) time series*. we employ as a simple proxy for the de - seasonalized intra - day volatility the absolute value of the rescaled return @xmath59 notice that the volatility @xmath60 is already de - seasonalized , because of the definition of @xmath7      we discuss here how we tagged the news and how we performed the sentiment analysis .",
    "the news data contained in the log of yahoo !",
    "finance were marked with relevant stocks , identified through two different tagging methods .",
    "a first type of annotations was provided by a team of editors , who manually assessed the articles published on the yahoo !",
    "finance website and marked them with companies which the content of the article was relevant for .",
    "in addition to that , relevant companies were also identified by applying a proprietary entity - recognition tool .",
    "we discarded all the articles that were tagged with more than 4 companies .",
    "this threshold was chosen heuristically in a preliminary assessment , where we verified that articles tagged with 5 or more companies generally corresponds to aggregated periodic reports , which mention long lists of stocks without being really specific about any of them .    among the obtained articles",
    ", we further processed those tagged with more than one company , introducing some additional filters to make sure we would consider the news for a company when the content of the article was really relevant to it , and not in the case where a company was only tagged due to a casual mention in the text .",
    "such additional filters consisted in only retaining the stocks that were mentioned either in the title or in the first paragraph of the article , which typically contains a summary of the key concepts discussed in the article .",
    "each article then contributed to the time series of all the stocks it was tagged for .",
    "as explained in the main text , we have used _ sentistrength _ adding a list of sentiment keywords of special interest and significance for the financial domain .",
    "we have tested the classification in good , bad , or neutral news using the general dictionary . in 84% of the cases",
    "the classification is the same by using both dictionary .",
    "this result indicates that our classification and the consequent analysis is pretty robust to the choice of dictionary . interestingly , 17% of the news classified as neutral by the general dictionary",
    "are classified as positive or negative by using the financial dictionary , while only 8% of the news classified as neutral by the financial dictionary are classified as positive or negative when using the general dictionary .",
    "this suggests that the use of a financial dictionary sharpens the capability of giving a positive or negative sign to a news .",
    "consistently with the financial time series , we consider only trading time and trading days .",
    "this implies that we neglect the clicks that occur out of this time window , because we are only interested in the click behaviour during the trading hours evolution of markets . from the click - through history of each news",
    "we create two time series : the first one is the total amount of clicks for each minute for each company , and the second one is the number of clicks multiplied by the sentiment score of the associated news .    1 .   * click ( c ) time series*. starting from the number of clicks of each news at the smallest time scale @xmath41 ( in our case one minute )",
    ", we build a time series at the time scale @xmath18 by aggregating the number of clicks of all the news of a given company .",
    "so if we denote by @xmath61 the number of news of a company , and by @xmath62 the number of clicks for news @xmath63 at scale @xmath41 , the total volume @xmath64 can be defined as @xmath65 the news that are not viewed in the time interval have zero clicks .",
    "we filter out the intra - day pattern from clicks by means of a simple methodology .",
    "clicks at intra - day time @xmath18 are rescaled by a factor @xmath66 , which is computed as the average , over all days , of the click volume at time @xmath18 normalized by the total number of daily clicks .",
    "more precisely , if @xmath67 is the raw click volume of day @xmath46 and intra - day time @xmath18 , we define the time series of rescaled clicks as : @xmath68 where @xmath69 and @xmath70 with @xmath71 the total number of clicks in a day .",
    "* sentiment ( s ) time series*. to construct this time series we consider the sentiment of the headlines of the news . with the same notation previously used @xmath72 where @xmath73 is the sign @xmath74 of the sentiment of a news headline published at time @xmath41 .",
    "* weighted sentiment ( ws ) time series*. we multiply the click count of each news by its sentiment score . with the same notation of the click time series",
    ", we have : @xmath75    this way , we weight the sign of every news by the level of attention that the news has received .",
    "we remark that for each trading day we consider all the clicks of all the news clicked in that day , not only the news that have been released in that day .",
    "then , we define the weighted sentiment as @xmath76      we estimate the power law tail exponent of the distribution of the number of clicks per news by employing the r package powerlaw developed and maintained by colin gillespie , and described in  @xcite .",
    "see table  [ 100stockspl ] for numerical details .",
    "@lrrrrlrrrr & @xmath77 & @xmath78 & @xmath79 & @xmath80 & & @xmath77 & @xmath78 & @xmath79 & @xmath80 aa & 1.05 & 0.09 & 482 & 114 & * jpm * & * 0.99 * & * 0.04 * & * 665 * & * 205 * * aapl * & * 0.97 * & * 0.05 * & * 2881 * & 1**451 * * & kbh & 1.33 & 0.20 & 402 & 98 abt & 1.39 & 0.33 & 530 & 261 & ko & 0.96 & 0.09 & 565 & 242 acn & 1.84 & 0.37 & 1074 & 313 & lcc & 0.95 & 0.08 & 722 & 371 aet & 1.21 & 0.13 & 261 & 54 & len & 0.86 & 0.19 & 256 & 197 aig & 1.16 & 0.13 & 854 & 193 & lmt & 1.41 & 0.14 & 808 & 159 amgn & 1.60 & 0.33 & 1596 & 445 & lnkd & 0.90 & 0.13 & 735 & 297 amzn & 1.06 & 0.05 & 969 & 206 & luv & 0.82 & 0.10 & 617 & 282 atvi & 1.47 & 0.23 & 863 & 192 & ma & 0.97 & 0.13 & 335 & 213 axp & 0.89 & 0.07 & 447 & 93 & mar & 1.34 & 0.17 & 318 & 90 * bac * & * 0.95 * & * 0.05 * & * 807 * & * 200 * & mcd & 0.71 & 0.06 & 462 & 305 * ba * & * 1.01 * & * 0.05 * & * 802 * & * 250 * & m & 0.86 & 0.09 & 384 & 200 bby & 0.74 & 0.13 & 957 & 526 & mrk & 1.53 & 0.20 & 966 & 213 biib & 1.88 & 0.41 & 1081 & 251 & msci & 1.12 & 0.09 & 205 & 62 blk & 1.20 & 0.12 & 547 & 122 & * ms * & * 1.15 * & * 0.09 * & * 615 * & * 457 * cat & 1.14 & 0.11 & 834 & 224 & * msft * & * 1.06 * & * 0.05 * & * 2247 * & * 507 * cbs & 0.82 & 0.07 & 169 & 75 & ndaq & 1.24 & 0.08 & 213 & 42 * c * & * 1.10 * & * 0.06 * & * 627 * & * 256 * & nflx & 0.94 & 0.07 & 613 & 141 chk & 1.72 & 0.18 & 1479 & 215 & nke & 1.09 & 0.14 & 566 & 143 cmcsa & 1.41 & 0.24 & 1186 & 357 & noc & 1.46 & 0.22 & 894 & 228 cop & 1.76 & 0.24 & 1708 & 303 & nwsa & 0.89 & 0.06 & 234 & 117 cost & 0.79 & 0.10 & 448 & 372 & nyx & 0.98 & 0.18 & 176 & 192 csco & 1.32 & 0.11 & 1290 & 271 & orcl & 0.95 & 0.20 & 523 & 422 cvx & 1.37 & 0.15 & 782 & 180 & pep & 0.92 & 0.13 & 565 & 220 dal & 1.01 & 0.12 & 959 & 220 & pfe & 1.54 & 0.14 & 1306 & 250 dell & 1.00 & 0.07 & 944 & 246 & pg & 1.02 & 0.11 & 809 & 327 dis & 0.72 & 0.04 & 283 & 198 & qcom & 1.44 & 0.23 & 1748 & 363 dish & 1.05 & 0.17 & 515 & 391 & rtn & 1.83 & 0.47 & 1379 & 425 dow & 1.21 & 0.13 & 818 & 313 & sbux & 0.80 & 0.07 & 453 & 236 dtv & 1.11 & 0.13 & 438 & 132 & s & 1.09 & 0.14 & 684 & 424 ebay & 0.91 & 0.11 & 1612 & 459 & tri & 0.89 & 0.04 & 122 & 62 * fb * & * 0.95 * & * 0.08 * & * 1211 * & * 1077 * & tsla & 0.98 & 0.11 & 3024 & 850 f & 0.96 & 0.05 & 1188 & 254 & twc & 1.06 & 0.09 & 403 & 176 frt & 1.19 & 0.08 & 412 & 87 & twx & 0.84 & 0.08 & 260 & 119 ge & 0.98 & 0.08 & 587 & 236 & txn & 1.55 & 0.42 & 1060 & 475 gild & 1.87 & 0.43 & 1300 & 294 & ual & 1.00 & 0.12 & 1153 & 659 gm & 0.84 & 0.05 & 863 & 296 & unh & 1.21 & 0.15 & 378 & 147 * goog * & * 0.92 * & * 0.03 * & * 1786 * & * 450 * & ups & 1.93 & 0.49 & 2499 & 721 gps & 1.28 & 0.17 & 390 & 158 & utx & 1.49 & 0.20 & 733 & 209 grpn & 0.93 & 0.13 & 644 & 193 & v & 1.17 & 0.13 & 505 & 243 * gs * & * 0.89 * & * 0.05 * & * 462 * & * 143 * & vmw & 1.50 & 0.45 & 1003 & 547 hal & 1.56 & 0.18 & 880 & 213 & vod & 1.87 & 0.42 & 1850 & 711 hd & 0.79 & 0.07 & 456 & 169 & vz & 1.11 & 0.10 & 1001 & 359 hon & 1.18 & 0.17 & 632 & 296 & wag & 1.06 & 0.23 & 512 & 322 hpq & 1.13 & 0.11 & 786 & 274 & wfc & 0.95 & 0.05 & 874 & 271 ibm & 1.11 & 0.11 & 1014 & 283 & wmt & 0.67 & 0.06 & 2073 & 517 intc & 1.35 & 0.32 & 1777 & 738 & xom & 1.29 & 0.12 & 802 & 147 it & 1.32 & 0.13 & 410 & 98 & yhoo & 1.15 & 0.12 & 2546 & 605 jcp & 0.75 & 0.07 & 2827 & 959 & yum & 0.90 & 0.10 & 483 & 225 jnj & 1.51 & 0.19 & 1058 & 174 & znga & 1.38 & 0.16 & 1578 & 338    [ 100stockspl ]      in tables  [ tab : spearman - bonferroni ] and  [ tab : granger - bonferroni ] we report the results for tests of zero spearman correlation and zero granger causality , respectively , under the very conservative correction proposed by bonferroni . if @xmath81 tests are performed and the desired significance is @xmath82 ( in our case @xmath83 , then only the tests with a p - value smaller than @xmath84 are rejected .",
    "since we perform @xmath85 tests , our corrected p - value is @xmath86 .",
    "@lrrr time interval ( minutes ) & @xmath29 & @xmath30 & @xmath31 1 & 0 & 73 & 92 10 & 0 & 48 & 81 30 & 0 & 24 & 76 65 & 0 & 9 & 66 130 & 0 & 6 & 55    @lr causality relation & hourly scale @xmath32 & 1 @xmath33 & 0 @xmath34 & 5 @xmath35 & 49 @xmath36 & 94 @xmath37 & 52 @xmath38 & 60 @xmath39 & 77    [ tab : granger - bonferroni ]",
    "the semantic analysis of the news on a specific company is known to have a small predictive power on the future price movements . at the light of our findings",
    ", we argue that this effect could be related to the distribution in the attention that the news receive , as clearly emerge in figure 1 : its scale - free behaviour reflects the extreme heterogeneity in the information they convey and the surprise they generate in the readers .",
    "our in - sample analysis shows that by adding the clicking activity of the web users , we can greatly increase the predictive power of the news for the price returns .",
    "this occurs because the time series built with only the sentiment of the news gives the same weight to all the news .",
    "in this way even irrelevant news are considered , adding noise to the sentiment time series and reducing the predictive power of the signal . adding the browsing activity means giving a meaningful weight to each news according to its importance , as measured by the attention it receives by the users , and it enhances the forecast ability of our approach .",
    "the approach to collective evaluation that we proposed in this paper can be useful in many other non financial contexts , since the overflow of information is a common aspect in our lives . in the financial domain , a natural extension of the present work concerns market instabilities and crashes .",
    "the analysis presented here is in fact unconditional , i.e. it does not target large price movements or , more generally , abnormal returns . from our societal perspective",
    "it would be extremely valuable to have a collective evaluation system , like the one presented here , capable of sifting the relevant information from the pool of data , news , blogs , etc , and to provide early warning indicators of large price movements .",
    "since we have reported evidences in favour of return predictability at intraday time scale  especially at hourly scale  this approach could be also used for real - time indicators , as well as for high - frequency instabilities and systemic price cojumps @xcite , which are becoming increasingly more frequent in our highly automated financial world .",
    "the authors warmly thank lucio calcagnile for the valuable technical support during the final stage of this work .",
    "gr and gc acknowledge support from fet open project simpol `` financial systems simulation and policy modelling '' nr . 610704 , ip project multiplex nr 317532 and progetto",
    "di interesse cnr `` crisislab '' .",
    "gc acknowledges also partial support from the u.s .",
    "department of the defense , defense threat reduction agency , grant hdtra1 - 11 - 1 - 0048 .",
    "fl acknowledges support from the fp7/2007 - 2013 under grant agreement crisis - ict-2011 - 288501 .",
    "data have been made available by yahoo !",
    "inc and quantlab groups ."
  ],
  "abstract_text": [
    "<S> the new digital revolution of big data is deeply changing our capability of understanding society and forecasting the outcome of many social and economic systems . unfortunately </S>",
    "<S> , information can be very heterogeneous in the importance , relevance , and surprise it conveys , affecting severely the predictive power of semantic and statistical methods . here </S>",
    "<S> we show that the aggregation of web users behavior can be elicited to overcome this problem in a hard to predict complex system , namely the financial market . </S>",
    "<S> specifically , our in - sample analysis shows that the combined use of sentiment analysis of news and browsing activity of users of yahoo ! </S>",
    "<S> finance greatly helps forecasting intra - day and daily price changes of a set of 100 highly capitalized us stocks traded in the period 2012 - 2013 . </S>",
    "<S> sentiment analysis or browsing activity when taken alone have very small or no predictive power . </S>",
    "<S> conversely , when considering a _ news signal _ where in a given time interval we compute the average sentiment of the clicked news , weighted by the number of clicks , we show that for nearly 50% of the companies such signal granger - causes hourly price returns . </S>",
    "<S> our result indicates a `` wisdom - of - the - crowd '' effect that allows to exploit users activity to identify and weigh properly the relevant and surprising news , enhancing considerably the forecasting power of the news sentiment . </S>"
  ]
}