{
  "article_text": [
    "efficient inference in large complex systems is a major challenge with significant implications in science , engineering and computing .",
    "exact inference is computationally hard in complex systems and a range of approximation methods have been devised over the years , many of which have been originated in the physics literature  @xcite . a recent review  @xcite highlights the links between the various approximation methods and their applications",
    ".    approximative bayesian inference techniques arguably offer the most principled approach to information extraction , by combining a rigorous statistical approach with a feasible but systematic approximation .",
    "although message passing techniques have existed for some time in the computer science community  @xcite they have enjoyed growing popularity in recent years  @xcite , mainly within the context of bayesian networks and the use of belief propagation ( bp ) for a range of inference applications , from signal extraction in telecommunication to machine learning .",
    "the main advantage of these techniques is their moderate growth in computational cost , with respect to the systems size , due to the local nature of the calculation when applied to sparse graphs . until recently ,",
    "message passing techniques were deemed unsuitable for inference in densely connected systems due to the inherently high number of short loops in the corresponding graphical representation , and the large number of connections per node , which results in a high computational cost .",
    "both properties are considered prohibitive to the use of conventional message passing techniques in such problems .    a recently suggested method for message passing in densely connected systems",
    "@xcite relies on replacing individual messages by averages sampled from a gaussian distribution of some mean and variance that are modified iteratively .",
    "the method has been applied for the cdma signal detection inference problem ; it successfully finds optimal solutions where the space of solutions is contiguous but breaks down when the solution space becomes fragmented , for instance , when there is a mismatch between the true and assumed noise levels in the cdma detection problem .",
    "the emergence of competing solutions gives rise to conflicting messages that result in bungled average messages and suboptimal performance .",
    "in statistical physics terms , it corresponds to the replica symmetric solution in dense systems  @xcite and gives poor estimates when more complex solution structures are required .    in the current paper",
    ", we methodologically extend the approach of kabashima  @xcite for inference in dense graphs by considering a large ( infinite ) number of replicated variable systems , exposed to the same evidential data ( received signals ) .",
    "each one of the systems represents a pure state and a possible solution .",
    "the pseudo posteriors , that form the basis for our estimates , are based on averages over the replicated systems .",
    "the method has been employed previously only in the non - critical regime  @xcite , using the most basic ( rs - like ) ansatz for the solution structure . in the current paper",
    "we study both critical and non - critical regimes and extend the solution structure considered to include step replica symmetry breaking ( 1rsb ) like structures  @xcite . to demonstrate the potential of this approach and the performance obtained using the resulting algorithm we apply the method to two different but related problems : signal detection in code division multiple access ( cdma ) and learning in the ising linear perceptron ( ilp ) .",
    "we investigate both rs and 1rsb - like structures .",
    "the former is applied to both cdma and ilp problems and seems to be sufficient for obtaining optimal performances ; the latter is applied to a variant of the cdma signal detection problem with a more complex noise model that exhibits rsb - like behaviour , to demonstrate its efficacy for particularly difficult inference tasks .    in section  [ sec : models ] we will introduce the general models studied , followed by a brief review of message passing techniques for dense systems in section  [ sec : message_passing ] .",
    "the general derivation of our approach , for both rs and rsb - like solution structures , will be presented in section  [ sec : general - formalism ] ; numerical studies of both cdma signal detection and ilp learning will be reported in section  [ sec : cdma ] . to demonstrate the method based on the more complex 1rsb solution structure , and to examine its efficacy to problems that require such structures",
    ", we will introduce a variant of the cdma signal detection problem and study it numerically in section  [ sec : cdma2gauss ] .",
    "we will conclude the presentation with a summary and point to future research directions .",
    "details of the derivation will be provided in appendices  [ app : rs]-[app : optimisation ] .",
    "before describing the inference method , the approach taken and the algorithms derived from it , it would be helpful to briefly describe the exemplar inference problems tackled in this paper .",
    "we apply the method to two different but related inference problems : signal detection in cdma and learning in the ising linear perceptron ( ilp ) .",
    "both correspond to inference problems where data points are noisy representations of sums of binary variables modulated by random binary values .",
    "multiple access communication refers to the transmission of multiple messages to a single receiver .",
    "the scenario we study here , described schematically in figure  [ cdma - ilp](a ) , is that of @xmath0 users transmitting independent messages over an additive white gaussian noise ( awgn ) channel of zero mean and variance @xmath1 .",
    "various methods are in place for separating the messages , in particular time , frequency and code division multiple access  @xcite .",
    "the latter , is based on spreading the signal by using @xmath0 individual random binary spreading codes of spreading factor @xmath2 .",
    "we consider the large - system limit , in which the number of users @xmath0 tends to infinity while the system load @xmath3 is kept to be @xmath4 .",
    "we focus on a cdma system using binary phase shift keying ( bpsk ) symbols and will assume the power is completely controlled to unit energy .",
    "the received aggregated , modulated and corrupted signal is of the form : @xmath5 where @xmath6 is the bit transmitted by user @xmath7 , @xmath8 is the spreading chip value , @xmath9 is the gaussian noise variable drawn from @xmath10 , and @xmath11 the received message .",
    "the task is to infer the original transmission from the set of received messages .",
    "this process is reminiscent of the learning task performed by a perceptron with binary weights and linear output , which is the next example considered in this paper .",
    "learning in neural networks has attracted considerable theoretical interest . in particular",
    "we focus on supervised learning from examples , which relies on a training set consisting of examples of the target task  @xcite .",
    "we consider a perceptron , described schematically in figure  [ cdma - ilp](b ) , which is a network that sums a single layer of inputs @xmath8 with synaptic weights @xmath6 and passes the result through a transfer function @xmath11 @xmath12 where @xmath13 is typically a non - linear sigmoidal function . if @xmath14 the network is termed _ linear output perceptron_. if the weights @xmath15 the network is called _ ising perceptron_. learning is a search through the weight space for the perceptron that best approximates a target rule .",
    "the similarity between the linear perceptron of equation  ( [ eq : perceptron ] ) and the cdma detection problem of eq.([eq : cdma ] ) allows for a direct relation between the two problems to be established .",
    "the main difference between the problems is the regime of interest . while cdma detection applications are of interest mainly for non - critical low load values , ilp studies focused on the critical regime .",
    "we consider both regimes in this paper .",
    "( 440,190 ) ( 0,-4)=98.5 mm ( 325,25)=50.5 mm ( 0,203)(a ) ( 305,203)(b )",
    "graphical models ( bayes belief networks ) provide a powerful framework for modelling statistical dependencies between variables  @xcite .",
    "they play an essential role in devising a principled probabilistic framework for inference in a broad range of applications .",
    "message passing techniques are typically used for inference in graphical models that can be represented by a sparse graph with a few ( typically long ) loops .",
    "they are aimed at obtaining ( pseudo ) posterior estimates for the system s variables by iteratively passing messages ( locally calculated conditional probabilities ) between variables .",
    "iterative message passing of this type is guaranteed to converge to the globally correct estimate when the system is tree - like ; there are no such guarantees for systems with loops even in the case of large loops and a local tree - like structure ( although message passing techniques have been used successfully in loopy systems , supported by some limited theory  @xcite ) . a clear link has been established between certain message passing algorithms and well known methods of statistical mechanics  @xcite such as the bethe approximation  @xcite .    these inherent limitations seem to prevent the use of message passing techniques in densely connected systems due to their high connectivity , implying an exponentially growing cost , and an exponential number of loops .",
    "however , an exciting new approach has been recently suggested  @xcite for extending bp techniques  @xcite to densely connected systems . in this approach",
    ", messages are grouped together , giving rise to a macroscopic random variable , drawn from a gaussian distribution of varying mean and variance for each of the nodes .",
    "the technique has been successfully applied to cdma signal detection problems and the results reported are competitive with those of other state - of - the - art techniques . however , the current approach has some inherent limitations  @xcite , presumably due to its similarity to the replica symmetric solution in the equivalent ising spin models  @xcite .    in a separate recent development",
    "@xcite , the replica - symmetric - equivalent bp has been extended to survey propagation ( sp ) , which corresponds to one - step replica symmetry breaking in diluted systems .",
    "this new algorithm , motivated by the theoretical physics interpretation of such problems , has been highly successful in solving hard computational problems  @xcite , far beyond other existing approaches .",
    "in addition , the algorithm facilitated theoretical studies of the corresponding physical system and contributed to our understanding of it  @xcite .",
    "the sp algorithm has recently been modified to handle ising and multilayer perceptrons  @xcite .",
    "we recently presented a new approach  @xcite for inference in densely connected systems , which was inspired by both the extension of bp to densely connected graphs and the introduction of sp .",
    "the systems we consider here are characterised by multiplicity of pure states and a possible fragmentation of the space of solutions . to address the inference problem in such cases we consider an ensemble of replicated systems where averages are taken over the ensemble of potential solutions .",
    "this amounts to the presentation of a new graph , where the observables @xmath11 are linked to variables in all replicated systems , namely @xmath16 ; where @xmath17 , as shown in figure .",
    "to estimate the variables @xmath18 given the data @xmath19 , in a bayesian framework , we have to maximise the posterior @xmath20 where we have considered independent data , and thus @xmath21 .",
    "the likelihood so defined is of a general form ; the explicit expression depends on the particular problem studied . here",
    ", we are interested in cases where @xmath22 is an unbiased vector and @xmath23 .",
    "the estimate we would like to obtain is the maximiser of the posterior marginal ( mpm ) @xmath24 which is expected to be a vector with equal entries for all replica @xmath25 .",
    "the number of operations required to obtain the full mpm estimator is of @xmath26 which is infeasible for large @xmath0 values .    to obtain an approximate mpm estimate",
    "we apply bp message passing technique  @xcite .",
    "in particular we are interested here in the application of bp to densely connected graphs , similar to the one presented in  @xcite .",
    "the latter is based on estimating a single solution and therefore does not converge , as has been observed , when the solution space becomes fragmented and multiple solutions emerge .",
    "this arguably corresponds to the replica symmetry breaking phenomena and occurs , for instance , when the noise level is unknown in the cdma signal detection case .",
    "a potential algorithmic improvement is achieved by the introduction of an sp - like approach , based on replicated variable systems , similar to the approach taken in problems that can be mapped onto sparsely connected graphs .     given data.,width=245 ]    using bayes",
    "rule one straightforwardly obtains the bp equations : @xmath27 for calculating the posterior @xmath28 we assume a dependency of the data on the parameters of the form @xmath29 , where @xmath30 is some general smooth function , @xmath31 are model parameters and @xmath32 are small enough to ensure that @xmath33 .",
    "we define the vector @xmath34 thus , using @xmath35 we can model the likelihood such that @xmath36p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\ , p\\left(\\mathbf{{\\delta}}_{\\mu k}|\\mathbf{b}\\right)\\,,\\label{eq : likelihood}\\end{aligned}\\ ] ] where we have assumed that @xmath37 ,    due to the assumed dependence of the observed values @xmath11 on @xmath38 and @xmath39 .",
    "an explicit expression for inter - dependence between solutions is required for obtaining a closed set of update equations .",
    "we assume a dependence of the form @xmath40 where @xmath41 is a vector representing an external field and @xmath42 the matrix of cross - replica interaction .",
    "the form of @xmath42 depends upon the particular case considered .",
    "we assume one of the following symmetry relation between the replicated solutions : @xmath43 where @xmath44 is a block index that runs from 1 to @xmath45 and ` a ' is a intra - block replica index that runs form 1 to @xmath46 where @xmath46 is the number of variables per block .",
    "we also make the following reasonable assumption @xmath47 , as one expects correlations to gradually decrease between variables with non - identical replica and block indices , respectively .    for both types of symmetries considered , the correlation matrix defined as : @xmath48 where @xmath49 is an index or a pair of indices for rs and 1rsb , respectively .",
    "the correlation matrix is assumed to be self - averaging , i.e. @xmath50 and preserves the symmetry of the matrix @xmath42 .",
    "an explicit derivation of the entries of @xmath51 is presented in appendices  [ app : rs ] and  [ app : rsb ] , for the rs and rsb - like correlation structures , respectively ; the matrices take following the general form : @xmath52+\\left(1-\\delta^{\\ell\\ell^{\\prime}}\\right)\\frac{1}{nl}\\left(v^{t}-r^{t}\\right)\\,.\\end{aligned}\\ ] ] thus , for the appropriate centre of the distribution @xmath53 ( see equations   ( [ eq : urs ] ) and ( [ eq : u1rsb ] ) ) , the probability of @xmath54 can be expressed as : @xmath55}\\right\\ } \\prod_{{\\rm a}=1}^{n}\\exp\\left\\ { -{\\displaystyle \\frac{\\left(\\delta_{\\mu k}^{\\ell{\\rm a}}-\\vartheta_{\\mu k}^{0\\ell t}\\right)^{2}}{2\\left(x^{t}-n^{-1}v^{t}\\right)}}\\right\\ }   & \\mbox{(rsb)}\\end{cases}}\\nonumber \\end{aligned}\\ ] ] for the rs and rsb - like correlation matrices , respectively , where @xmath56 and @xmath57      having obtained the conditional probability distribution @xmath58 one can then derive explicit expressions for the messages @xmath59 ( magnetisation ) and @xmath60 that can be viewed as parameters in the corresponding marginalised binary distributions @xmath61 and @xmath62 .    the messages from nodes @xmath11 to nodes @xmath39 , as derived in appendix  [ app : messages ] , equations  ( [ eq : mhat])-([eq : mm1rsb ] ) @xmath63 where @xmath64 , @xmath65 is defined in equation  ( [ eq : gcal ] ) and @xmath66 is obtained from the saddle point equations given by equation  ( [ eq : wrs ] ) in the rs case and by equation  ( [ eq : w1rsb ] ) in the 1rsb case .",
    "the messages from nodes @xmath39 to @xmath11 are given in both cases by the expression @xmath67    for the gauged field @xmath68 where @xmath69 .",
    "the distribution of this field is well approximated by a gaussian as a result of the central limit theorem .",
    "the mean and variance of the gaussian are @xmath70 and @xmath71 respectively : @xmath72\\simeq\\frac{1}{k}\\sum_{k=1}^{k}\\sum_{\\mu=1}^{n}\\left(\\hat{m}_{\\mu k}^{t}\\right)^{2}\\,.\\nonumber \\end{aligned}\\ ] ] both @xmath70 and @xmath71 are assumed to be independent of the index @xmath73 by virtue of the self - averaging property .",
    "for the same reason we expect the macroscopic variables defined as @xmath74 and @xmath75 , where @xmath76 , to be independent of the index @xmath77 thus , these macroscopic variables can be evaluated by the following integrals @xmath78 where @xmath79 .",
    "the structure of the correlation matrix used introduces free variables in the form of the correlation terms between replicated solutions .",
    "these are used for optimising the estimation provided with respect to a given performance measure .",
    "since the mpm estimator is given by @xmath80 , the expression for the error per bit rate takes the form : @xmath81 which is minimised when the true message vector * @xmath82 * and the vector of messages @xmath83 are parallel .",
    "therefore , the error rate per bit decreases as the ratio @xmath84 increases .",
    "the optimal value is reached when @xmath85 and @xmath86 as derived in appendix  [ app : optimisation ] .",
    "using this notation one defines @xmath87 for the cdma problem and @xmath88 for the ising perceptron . the goal is to get an accurate estimate of the vector @xmath82 for all users given the received message vector @xmath89 via a principled approximation of the posterior @xmath90 .",
    "an expression representing the likelihood is required and is easily derived from the noise model ( assuming zero mean and variance @xmath91 ) . if the arithmetic variance over replicas of the macroscopic message @xmath92 is finite and independent of the sub indexes @xmath73 and @xmath7 , i.e. @xmath93",
    ", then @xmath94 can be expanded as @xmath95\\,,\\label{supp}\\end{aligned}\\ ] ] where @xmath96 and @xmath97 .",
    "the function @xmath98 , defined in equation  ( [ eq : pcal ] ) , and obtained from this distribution is linear in @xmath99 ; therefore , the second derivative used for calculating the messages in equation  ( [ eq : m_hat ] ) @xmath100 and the corresponding structure of the correlation matrix is rs - like .    to calculate correlations between replica",
    "we expand @xmath94 in the large _",
    "limit in  ( [ supp ] ) , as shown in equation  ( [ eq : likelihood ] ) .",
    "according to the rs correlation assumption , the macroscopic variables satisfy the following relation : @xmath101 where @xmath102 for the cdma ( ilp ) system and @xmath103 for the cdma ( ilp ) systems , respectively , due to the change in scaling .",
    "the saddle point equation  ( [ eq : hcal1rsb ] ) provides a dominant value for the variable  @xmath99 @xmath104      the message from @xmath11 to @xmath105 at time @xmath106 is then given by : @xmath107    the main difference between equation  ( [ mhat1 ] ) and the equivalent equation in  @xcite is the dependence of the pre - factor on @xmath108 , reflecting correlations between different solutions groups ( replica ) . to determine this term we optimise the choice of @xmath91 by applying the condition @xmath109 . forcing this condition leads to a relation between the structure of the space of solutions , represented by @xmath108 , and the free parameter of the model @xmath91 . from equation  ( [ mhat1 ] ) and using @xmath109 and @xmath110 one obtains : @xmath111\\left(e^{t+1}\\right)^{2}\\,,\\end{aligned}\\ ] ] which imply , after simplification , that for both cases @xmath112 . despite the simplicity of this result , the process from which we obtained it provides us with a practical way to estimate the true noise variance .",
    "notice that for calculating @xmath70 and @xmath71 we used the limits @xmath113 .",
    "so that @xmath1 , which appears in the expression for @xmath71 , can be obtained from the signal vector of @xmath11 with an infinite number of entries .",
    "thus @xmath114 using this expression we can finally express the message as:@xmath115 where no prior belief of @xmath116 is required .",
    "the steady state equations for the macroscopic variables @xmath117 and @xmath70 are obtained by taken the limit @xmath118 .",
    "let us define @xmath119 and @xmath120 .",
    "in the asymptotic regime the following relations hold : @xmath121 and from these expressions one can obtain the full expression for the error per bit rate : @xmath122\\,.\\label{eq : epbbar}\\ ] ]",
    "the inference algorithm requires an iterative update of equations  ( [ eq : mmhatapprox],[mhatfin ] ) and converges to a reliable estimate of the signal , with no need for prior information of the noise level .",
    "the computational complexity of the algorithm is of @xmath123 .",
    "( 440,190 ) ( 0,0 ) ( 225,0 ) ( -10,193)(a ) ( 215,193)(b )    to test the performance of our algorithm we carried out a set of experiments of the cdma signal detection problem under typical conditions .",
    "error probability of the inferred signals was calculated for a system load of @xmath124 , where the true noise level is @xmath125 and the estimated noise is @xmath126 , as shown in figure  [ fig2](a ) .",
    "the solid line represents the expected theoretical results ( density evolution ) , knowing the exact values of @xmath1 and @xmath91 , while circles represent simulation results obtained via the suggested _ practical _ algorithm , where no such knowledge is assumed .",
    "the results presented are based on @xmath127 trials per point and a system size @xmath128 and are superior to those obtained using the original algorithm  @xcite .",
    "another performance measure one should consider is @xmath129 that provides an indication to the stability of the solutions obtained . in figure  [ fig2](b ) we see that results obtained from our algorithm show convergence to a reliable solution in contrast to the original algorithm  @xcite . the physical interpretation of the difference between the two results is assumed to be related to a replica symmetry breaking phenomenon .",
    "for the ilp , the @xmath130 regime of high interest as the system develops a critical behaviour for a range of @xmath1 values .",
    "we carried out a set of experiments for this system based on density evolution . in figure  [ fig - crit-1 - 2](a )",
    "we present curves of the bit error probability @xmath131 , defined in equation  ( [ eq : epbbar ] ) , as a function of the inverse load @xmath132 for different values of @xmath1 .",
    "three different regimes have been observed : for @xmath133 the curves exhibit a discontinuity at a value of @xmath134 that varies with @xmath1 ( first order phase transition - like behaviour ) . at @xmath135",
    "the curve becomes continuous but its slope diverges ( second order phase transition - like behaviour ) .",
    "the @xmath131 curves show analytical behaviour for noise values above 0.1025 .",
    "figure  [ fig - crit-1 - 2](b ) exhibits a phase diagram of the ilp system ; it shows the dependency of the critical load @xmath136 as a function of the noise parameter .",
    "the first order transition line ends in a second order transition point marked by a circle .",
    "the results obtained , and in particular the critical @xmath134 value , are consistent with those derived using the replica symmetric statistical mechanics - based analysis of the problem  @xcite .",
    "another indication for the critical behaviour is the number of steps required for the recursive update of equation  ( [ eq : ebar ] ) to convergence . in figure  [ fig - crit-3 - 4](a )",
    "we present the number of iterations required to reach a steady state as a function of @xmath132 when the noise parameter is set to @xmath137 .",
    "the number of iterations diverges when the critical value of @xmath134 is reached .    finally , we wish to explore the efficiency of the algorithm as a function of the system size . in figure  [ fig - crit-3 - 4](b )",
    "we present the result of iterating equations  ( [ eq : mmhatapprox ] ) and ( [ mhatfin ] ) for a system size of _ _ k__=500 .",
    "the curve presents mean values and error bars over 1000 experiments .",
    "there is a strong dependency of the error per bit rate on the size of the system , which is expected to converge to the asymptotic limit ( infinite system size ) represented by the solid line .",
    "( 440,190 ) ( 0,0)=67.5 mm ( 225,0 ) ( 0,193)(a ) ( 225,193)(b )    ( 440,190 ) ( 0,-4 ) ( 225,-5 ) ( 0,193)(a ) ( 225,193)(b )",
    "to demonstrate the suitability of the method for more complex inference problems that require a system with 1rsb - like structures , we will consider the cdma signal of equation  ( [ eq : cdma ] ) where the noise @xmath9 is drawn from a bi - gaussian distribution : @xmath138 where @xmath139 represents the bias and @xmath140 the positions of the gaussian peaks .",
    "we consider the particular case where @xmath141 , so that the gaussian peaks are slightly off centre . for this model",
    "the likelihood expression takes the form : @xmath142+\\frac{1+r}{2}\\exp\\left[-\\frac{\\left(y_{\\mu}-\\delta_{\\mu}^{\\ell{\\rm a}}-\\varepsilon\\right)^{2}}{2\\sigma^{2}}\\right]\\right\\ } \\,,\\ ] ] where _ r _ , @xmath143 and @xmath91 are estimates of the true parameters @xmath144 , @xmath145 and @xmath1 .    to derive the messages in this case we first calculate the function @xmath98 of equation  ( [ eq : pcal ] ) , which has the form : @xmath146 where @xmath147    following the derivation of appendix  [ app : messages ] , the saddle point equations  ( [ eq : wrs ] ) and ( [ eq : w1rsb ] ) can be expressed as : @xmath148 where we denote @xmath149 for the rs case and @xmath150 for the 1rsb case , @xmath151 , @xmath152 , @xmath153 and @xmath154 .",
    "the solution of this equation provides , up to order @xmath155 , @xmath156.\\end{aligned}\\ ] ] the function @xmath65 and its two first derivatives at the saddle point value are : @xmath157\\rho_{w}\\,\\varepsilon+\\\\   &   & + \\left[1-\\left(1-r^{2}\\right)\\rho_{w}^{2}\\,\\varepsilon^{2}-\\left(1-r^{2}\\right)\\left(1 - 3r^{2}\\right)\\updelta\\rho_{w}\\,\\rho_{w}^{2}\\,\\varepsilon^{4}\\right]\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)+\\\\   &   & + r\\left(1-r^{2}\\right)\\rho_{w}^{3}\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)^{2}\\varepsilon^{3}+\\frac{1}{3}\\left(1-r^{2}\\right)\\left(1 - 3r^{2}\\right)\\rho_{w}^{4}\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)^{3}\\varepsilon^{4}\\\\ \\mathcal{p}_{1 } & \\simeq & -\\rho_{0}+\\mathcal{o}\\left(\\varepsilon^{2}\\right)\\\\ \\mathcal{p}_{2 } & = & 2\\rho_{0}^{3}\\left(1-r^{2}\\right)\\left[r\\varepsilon^{3}+\\left(1 - 3r^{2}\\right)\\rho_{w}\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)\\varepsilon^{4}\\right]\\,,\\end{aligned}\\ ] ] therefore , one can obtain the following expression , required for calculating the messages in the 1rsb case ( [ eq : mm1rsb ] ) @xmath158\\,,\\ ] ] where @xmath159 .",
    "this straightforwardly leads to the following expression for the message : @xmath160r\\,\\varepsilon+\\right.\\nonumber \\\\   &   & + \\rho_{w}\\left[1-\\left(1-r^{2}\\right)\\rho_{w}\\,\\varepsilon^{2}-\\left(1-r^{2}\\right)\\left(1 - 3r^{2}\\right)\\left(\\upsilon_{n}-\\rho_{w}^{2}\\right)\\varepsilon^{4}\\right]\\,\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)+\\nonumber \\\\   &   & \\left.+r\\left(1-r^{2}\\right)\\rho_{w}^{3}\\,\\varepsilon^{3}\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)^{2}+\\frac{1}{3}\\left(1-r^{2}\\right)\\left(1 - 3r^{2}\\right)\\rho_{w}^{4}\\,\\varepsilon^{4}\\left(y_{\\mu}-u_{\\mu k}^{t}\\right)^{3}\\right\\ } \\,,\\label{eq:2gauss1rsb}\\end{aligned}\\ ] ] where @xmath161 .",
    "the expression for the message in the rs case is recovered from equation  ( [ eq:2gauss1rsb ] ) in the limit @xmath162      calculating the expressions for the macroscopic variables @xmath163 and @xmath164 , used in the optimisation process , requires performing the following sums , in the limit of @xmath165 with @xmath166 : @xmath167 where @xmath168 and @xmath169 . from the definition of the signal @xmath11 ( [ eq : cdma ] ) and the expression for the noise ( [ eq:2gruido ] ) we find that @xmath170 , @xmath171 , @xmath172 @xmath173 @xmath174 , @xmath175 , @xmath176 , @xmath177 and @xmath178 the explicit expressions derived for the macroscopic variables are : @xmath179\\rho_{w}\\,\\varepsilon^{4}\\\\ f^{t+1 } & = & b_{2}\\rho_{w}^{2}-2rb_{1}\\rho_{w}^{2}\\,\\varepsilon\\\\   &   & + \\left[r^{2}-2\\left(1-r^{2}\\right)b_{2}\\rho_{w}\\right]\\rho_{w}^{2}\\,\\varepsilon^{2}-2r\\left(1-r^{2}\\right)b_{1}\\left[\\upsilon_{n}-\\left(2 + 3b_{2}\\rho_{w}\\right)\\rho_{w}^{2}\\right]\\rho_{w}\\,\\varepsilon^{3}+\\\\   &   & + \\left(1-r^{2}\\right)\\left[2r^{2}\\left(\\upsilon_{n}-\\rho_{w}^{2}\\right)\\rho_{w}+\\left(1 - 3r^{2}\\right)b_{2}\\left(3\\rho_{w}^{2}+2b_{2}\\rho_{w}^{3}-2\\upsilon_{n}\\right)\\rho_{w}^{2}\\right]\\varepsilon^{4}\\,.\\end{aligned}\\ ] ] applying the optimisation conditions of appendix  [ app : optimisation ] , @xmath85 and @xmath86 , where @xmath180 one obtain the following conditions : @xmath181    in the 1rsb case one can further simplify these expressions by a suitable choice of @xmath182 and the number of replicas per block _",
    "n_. optimisation with respect to the latter results in @xmath183 which implies @xmath184 that by definition is larger than zero .",
    "this condition is satisfied if our estimate for the noise variance is smaller than the true parameter @xmath185 . in this case",
    "the number of replicas per block has to satisfy the condition @xmath186 interestingly this ties the noise level mismatch to the number of replicas , thus giving further insight to the role played by the structure of the inter - replica correlation matrix .    for @xmath187",
    ", the minimum value of @xmath188 is reached at @xmath189 .",
    "it is also possible to prove that @xmath190 although @xmath182 and @xmath46 will not be explicitly used in the following expressions , the correct choice of the value for these parameters allows one to use equations  ( [ eq : cond1 ] ) and ( [ eq : cond2 ] ) in order to find the final expression for the macroscopic variable @xmath163 , where no estimates are needed for the noise parameters : @xmath191    note that in the rs case we do not have the freedom to choose the number of replicas per block , given that this case is equivalent to take @xmath192 in the absence of the additional replica @xmath193 . for this reason equations  ( [ eq : cond1 ] ) and ( [ eq : cond2 ] ) and ( [ eq : cond2 ] ) take the form : @xmath194 and the macroscopic variable @xmath195 which depends on both estimates of the noise variance @xmath91 and bias @xmath196    given that the algorithm deals with finite signal vectors @xmath197 , the quantities @xmath198 and @xmath199 have to be approximated by the correspondent finite sums .",
    "therefore , we have : @xmath200 where we used the fact that @xmath201 .",
    "observe that no information about the true noise has been used to derive these expressions .",
    "having the estimates  ( [ eq : estb1b2 ] ) we can write down the messages explicitly : @xmath202\\,,\\end{aligned}\\ ] ] which can be now used recursively for obtaining the inferred solutions for this problem .",
    "notice that an estimate of _ both _ @xmath143 and @xmath116 in required in the rs case .      to test the performance of the 1rsb algorithm we carried out a set of experiments of the cdma signal detection problem with bi - gaussian noise .",
    "the results shown in figure  [ fign](a ) describe the error probability of the inferred signals as a function of the number of iterations has been calculated using both rs and 1rsb - like correlation matrices for the case of parameters mismatch .",
    "the system load used in the simulations was @xmath124 , the true noise level @xmath125 , gaussian bias of @xmath203 and weight @xmath2040.6 .",
    "the estimated noise parameters are @xmath126 and @xmath205 .",
    "the circles represent simulation results obtained via the 1rsb algorithm while the squares correspond to the rs - like structure .",
    "the results presented are based on @xmath127 trials per point and a system size @xmath206 ; error - bars are also provided .",
    "the results obtained using the 1rsb - like structure are superior to those obtained using the rs algorithm . as shown in figure  [ fign](b ) using the stability measure @xmath207 , both rs and 1rsb - based algorithms converge to reliable solutions ; the 1rsb - based algorithm is slightly slower to converge , presumably due to the more complex message passing scheme .",
    "( 440,190 ) ( 0,0 ) ( 225,0 ) ( -10,193)(a ) ( 215,193)(b )",
    "we present and methodologically develop a new algorithm for using bp in densely connected systems that enables one to obtain reliable solutions even when the solution space is fragmented .",
    "the algorithm relies on the introduction of a large number of replicated variable systems exposed to the same evidential nodes .",
    "messages are obtained by averaging over all replicated systems leading to pseudoposterior that is then used to infer the variable nodes most probable values .",
    "this is done with no actual replication , by introducing an assumption about correlations between the replicated variables and exploiting the high number of replicated systems .",
    "the algorithm was developed in a systematic manner to accommodate more complex correlation matrices .",
    "it was successfully applied to the cdma signal detection and ilp learning problems , using the rs - like correlation matrix , and to the cdma inference problem with bi - modal gaussian noise model in the 1rsb - like correlation matrix .",
    "the algorithm provides superior results to other existing algorithms  @xcite and a systematic improvement where more complex correlation matrices are introduced , where required .",
    "further research is required to fully determine the potential of the new algorithm .",
    "two particular areas which we consider as particularly promising are inference problems characterised by discrete data variables and noise model and problems that can be mapped onto _ sparse _ graphs .",
    "both activities are currently underway .",
    "support from evergrow ip no .",
    "1935 of the eu fp-6 is gratefully acknowledged .",
    "10 m. mzard , g. parisi and m.a .",
    "virasoro , _ spin glass theory and beyond _ , world scientific , singapore ( 1987 ) .",
    "m.  opper and d.  saad , _ advanced mean field methods : theory and practice _ , mit press , cambridge , ma 2001    j.  pearl , _ probabilistic reasoning in intelligent systems _ , morgan kaufmann publishers , san francisco , ca ( 1988 ) .",
    "jensen , _ an introduction to bayesian networks _ , ucl press , london ( 1996 ) .",
    "mackay , _ information theory , inference and learning algorithms _ , cambridge university press ( 2003 ) .",
    "y.  kabashima , j.  phys .",
    "a * 36 * , 11111 ( 2003 ) .",
    "h. nishimori , _ statistical physics of spin glasses and information processing _ , oxford university press , uk , ( 2001 ) .",
    "neirotti and d.  saad , europhys .",
    "lett .  * 71 * , 866 ( 2005 ) .",
    "although we will be using the terms rs and rsb , it should be clear that this is not directly related to the replica approach  @xcite , but merely uses similar structures for the cross - replica correlations .",
    "s.  verd , _ multiuser detection _ , cambridge university press uk ( 1998 ) .",
    "h. s. seung , h. sompolinsky and n. tishby , phys .",
    "a * 45 * , 6056 ( 1992 ) .",
    "y.  weiss , _ neural computation _ * 12 * , 1 ( 2000 ) .",
    "y.  kabashima , d.  saad , europhys .",
    "lett .  * 44 * , 668 ( 1998 ) .",
    "yedidia , w.t .",
    "freeman and y.  weiss , in _ advances in neural information processing systems _ * 13 * , 698 ( 2000 ) .",
    "m.  mzard , g.  parisi and r.  zecchina , science * 297 * , 812 ( 2002 ) .",
    "m.  mzard and r.  zecchina , phys .",
    "e * 66 * , 056126 ( 2002 ) .    a.  braunstein and r.  zecchina , phys .",
    "lett . , * 96 * 030201 ( 2006 )    y.  kabashima , jour .  of the physical society of japan",
    "* 74 * 2133(2005 )",
    "within the rs setting , the interaction term in equation  ( [ eq : ansatz ] ) is : @xmath208    a simplified expression for equation  ( [ eq : ansatz ] ) immediately follows @xmath209^{-1}\\exp\\left\\ { h_{\\mu k}^{t}\\sum_{\\mathrm{a}=1}^{n}b_{k}^{\\mathrm{a}}+\\frac{1}{2}q_{1\\mu k}^{t}\\left(\\sum_{\\mathrm{a}=1}^{n}b_{k}^{\\mathrm{a}}\\right)^{2}\\right\\ } \\\\   & = & [ \\mathcal{z}_{\\mu k}^{t}]^{-1}{\\displaystyle \\int_{-\\infty}^{\\infty}\\mathrm{d}x\\,\\exp\\left\\ { -\\frac{x^{2}}{2q_{1\\mu k}^{t}}+\\left(x+h_{\\mu k}^{t}\\right)\\sum_{\\mathrm{a}=1}^{n}b_{k}^{\\mathrm{a}}\\right\\ } } \\end{aligned}\\ ] ] where @xmath210 is a normalisation constant .",
    "the diagonal elements @xmath211 only affect the normalisation term and can therefore be taken to zero with no loss of generality .",
    "we expect the logarithm of the normalisation term @xmath210 ( linked to the free energy ) , obtained from the well behaved distribution @xmath212 , to be self - averaging .",
    "we therefore expect @xmath213 where @xmath214 and @xmath215 are the mean values of the parameters drawn for some suitable distributions and the over - line represents the mean value of the partition function over these distributions .",
    "in the following we will drop the upper - index _ t _ and the sub - indices @xmath73 and @xmath7 for brevity . to obtain the scaling behaviour of the various parameters",
    "one calculates @xmath216 explicitly , assuming the parameter @xmath217 is taken from a normal distribution @xmath218 .",
    "the partition function takes the form : @xmath219 thus , the mean value of the partition function over the set of parameters is : @xmath220 where @xmath221 the normalisation can be expressed as : @xmath222\\right\\ } \\\\   & = & \\mathcal{a}(n)\\,(n+1)\\binom{n}{n/2}\\,\\exp\\left\\ { n\\left[\\left|h\\right|+n\\frac{\\hat{q}_{1}}{2}+n^{3}\\frac{\\sigma_{q_{1}}^{2}}{8}\\right]\\right\\ } \\\\   & \\simeq & \\sqrt{\\frac{2}{\\pi}}\\mathcal{a}(n)\\,\\exp\\left\\ { n\\left[\\ln(2)+\\left|h\\right|+n\\frac{\\hat{q}_{1}}{2}+n^{3}\\frac{\\sigma_{q_{1}}^{2}}{8}\\right]\\right\\ } , \\end{aligned}\\ ] ] where @xmath223 .",
    "thus , @xmath224 , @xmath225 and @xmath226 .",
    "> from now on we will take the off - diagonal elements of the rs matrix @xmath42 equal to @xmath227 , where @xmath228 .    the form of the marginalised posterior at time _",
    "t _ is then : @xmath229 where @xmath230 the function @xmath231 presents one or two minima according to the following table : +    [ cols=\"^,^,^\",options=\"header \" , ]     where @xmath232 ; the coefficient @xmath233 plays the role of the inverse temperature . below the critical value",
    "@xmath234 a spontaneous magnetisation appears .",
    "this results from analysing the equation : @xmath235 the case of two maxima is presented in figure  [ 2peaks ] .    ) with two maxima and one minimum for a positive value of the field @xmath236.[2peaks],width=245 ]    we define the mean values from the distribution equation  ( [ pp ] ) .",
    "if the field @xmath236 is not zero , as shown in figure  [ 2peaks ] , @xmath237^{n}$ ] develops one dominant maximum as @xmath192 . for large enough @xmath46 , only this maximum contributes to the integrals ( [ pp ] ) and the algorithm obtained from this assumption turns out to be the same as the one presented in  @xcite .",
    "however , if the field is sufficiently small it gives rise to a new regime where the two maxima contribute . at the same time",
    ", it is important to note that a small , non zero field favours the solution of eq.([eq : derivada ] ) that satisfies @xmath238 to analyse the behaviour of the field , we will explore the solutions of eq.([eq : derivada ] ) in the regime @xmath239 . with this aim ,",
    "suppose that the solutions for the eq.([eq : derivada ] ) at zero field are @xmath240 where @xmath241 and @xmath242 .",
    "if the field is sufficiently small one can expand the solutions of equation  ( [ eq : derivada ] ) as @xmath243 where @xmath244 is expected to be small and satisfies @xmath245 .",
    "observe that if the field is positive ( negative ) , both roots are displaced to the right ( left ) with respect to the zero field solutions .",
    "using this expression for the roots in eq.([eq : derivada ] ) and disregarding terms of @xmath246 one finds that @xmath247 the expression for the exponent @xmath248 near the roots and in the @xmath239 regime is then @xmath249 and , by the definition of the @xmath250 , the product @xmath251 is positively defined .",
    "let us define @xmath252 $ ] .",
    "we expect that , for large @xmath46 the following approximation to be valid : @xmath253\\left(x - x_{h}\\right)^{2}\\right\\ } \\right.\\nonumber \\\\   &   & \\left.\\qquad+{\\rm e}^{-nmh}\\exp\\left\\ { -\\frac{n}{2}\\left[g_{1}^{-1}-\\beta_{-h}\\left(m , g_{1}\\right)\\right]\\left(x - x_{-h}\\right)^{2}\\right\\ } \\right\\ } \\,.\\label{exph0}\\end{aligned}\\ ] ] using equation  ( [ exph0 ] ) one can calculate the normalisation in equation  ( [ eq : z ] ) @xmath254\\left(x - x_{h}\\right)^{2}\\right\\ } \\nonumber \\\\   &   & + { \\rm e}^{-n\\left(\\phi_{0}+mh\\right)}\\int{\\rm d}x\\,\\exp\\left\\ { -\\frac{n}{2}\\left[g_{1}^{-1}-\\beta_{-h}\\left(m , g_{1}\\right)\\right]\\left(x - x_{-h}\\right)^{2}\\right\\ } \\nonumber \\\\   & \\simeq & \\sqrt{\\frac{2\\pi g_{1}\\xi\\left(m , g_{1}\\right)}{n}}\\!\\,{\\rm e}^{-n\\phi_{0}}\\!\\left\\ { \\,{\\rm e}^{nmh}\\!\\left(1-g_{1}\\left(1-m^{2}\\right)\\xi^{2}\\left(m , g_{1}\\right)\\ , mh\\right)\\right.\\nonumber \\\\   &   & \\qquad\\qquad\\qquad\\left.+\\,\\,{\\rm e}^{-nmh}\\!\\left(1+g_{1}\\left(1-m^{2}\\right)\\xi^{2}\\left(m , g_{1}\\right)\\ , mh\\right)\\right\\ } \\,\\,.\\label{eq : zzz}\\end{aligned}\\ ] ] the mean value of a given function @xmath255 with respect to the conditional probability distribution defined in equation  ( [ pp ] ) is then:@xmath256\\!\\left(x\\!-\\ ! x_{h}\\right)^{2}\\right\\ } \\\\   &   & \\qquad\\qquad\\qquad\\qquad\\qquad\\left[f\\left(x_{h}\\right)+\\left(x - x_{h}\\right)f^{\\prime}\\left(x_{h}\\right)+\\frac{1}{2}\\left(x - x_{h}\\right)^{2}f^{\\prime\\prime}\\left(x_{h}\\right)\\right]\\\\   &   & + \\mathcal{z}^{-1}{\\rm e}^{-n\\left(\\phi_{0}+mh\\right)}\\int\\!\\!{\\rm d}x\\,\\exp\\left\\ { -\\frac{n}{2}\\left[g_{1}^{-1}\\!-\\!\\left(1\\!-\\ !",
    "m^{2}\\right)\\!\\left(1\\!+\\!2\\xi\\left(m , g_{1}\\right)\\ , mh\\right)\\right]\\!\\left(x\\!-\\ !",
    "x_{-h}\\right)^{2}\\right\\ } \\\\   &   & \\qquad\\qquad\\qquad\\qquad\\qquad\\left[f\\left(x_{-h}\\right)+\\left(x - x_{-h}\\right)f^{\\prime}\\left(x_{-h}\\right)+\\frac{1}{2}\\left(x - x_{-h}\\right)^{2}f^{\\prime\\prime}\\left(x_{-h}\\right)\\right]\\,,\\end{aligned}\\ ] ] which implies , considering that the integrals of the linear terms are zero and keeping only the leading terms in the expansions , that the expectation values takes the form : @xmath257\\left\\ { f\\left(x_{h}\\right)+\\frac{g_{1}}{2n}\\xi\\left(m , g_{1}\\right)\\ , f^{\\prime\\prime}\\left(x_{h}\\right)\\right\\ } \\\\   &   & + { \\rm e}^{-2nmh}\\left(1 + 2\\xi^{2}\\left(m , g_{1}\\right)\\ , mh\\right)f\\left(x_{-h}\\right)\\,.\\end{aligned}\\ ] ] considering the expansion of @xmath258 and disregarding terms of @xmath259 , one can write : @xmath260\\!+\\ !",
    "f^{\\prime}\\left(mg_{1}\\right)\\!\\xi\\left(m , g_{1}\\right)h.\\label{eq : meanrs}\\ ] ] the resulting one and two variable expectation values become @xmath261\\xi\\left(m_{\\mu k}^{t},g_{1\\mu k}^{t}\\right)-2{\\rm e}^{-2nm_{\\mu",
    "k}^{t}h_{\\mu k}^{t}}\\right]m_{\\mu k}^{t}\\\\   &   & \\qquad\\qquad+\\xi\\left(m_{\\mu k}^{t},g_{1\\mu k}^{t}\\right)\\,\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]h_{\\mu k}^{t}\\end{aligned}\\ ] ]    and@xmath262 where @xmath263\\,\\left\\ { \\frac{g_{1\\mu k}^{t}}{n}\\,\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]+2m_{\\mu k}^{t}h_{\\mu k}^{t}\\right\\ } \\,,\\ ] ] and @xmath264    thus , the leading terms for the covariance matrix of the replicated variables are : @xmath265\\\\   &   & + \\left(1-\\delta^{{\\rm ab}}\\right)\\left\\ { \\frac{g_{1\\mu k}^{t}}{n}\\xi\\left(m_{\\mu k}^{t},g_{1\\mu k}^{t}\\right)\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]^{2}+4{\\rm e}^{-2nm_{\\mu k}^{t}h_{\\mu k}^{t}}\\left(1-{\\rm e}^{-2nm_{\\mu k}^{t}h_{\\mu k}^{t}}\\right)\\left(m_{\\mu k}^{t}\\right)^{2}\\right\\ } \\,.\\end{aligned}\\ ] ] if one requires the non - diagonal elements of this covariance matrix to have the same scaling as the inter - replica interaction matrix , the field has to behave in such a way that the exponential term contributes at most in @xmath266 one thus expects the field to obey @xmath267 , where the @xmath268 are appropriate constants . with this asymptotic behaviour ,",
    "the expression for the entries in the covariance matrix is @xmath269+\\left(1-\\delta^{{\\rm ab}}\\right)\\,\\frac{g_{1\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{1\\mu k}^{t}\\right)}{n}\\,\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]^{2}\\,,\\ ] ] which serves to define the probability distribution for the macroscopic variable @xmath270 .",
    "under a solution correlation matrix that resembles the 1rsb structure , the system comprises @xmath277 variables , where both the number of blocks _",
    "l _ and the number of variables per block _",
    "n _ are considered large . as",
    "before we are interested in the regime where @xmath45 and @xmath162    with this setting , the interaction term in equation  ( [ eq : ansatz ] ) is now:@xmath278 thus we have now @xmath279 squared sums in the exponent that can be replaced by integrals:@xmath209^{-1}{\\displaystyle \\int\\mathrm{d}\\mathbold{x}}\\,\\exp\\left\\ { -\\frac{x_{0}^{2}}{2q_{2\\mu k}^{t}}-\\sum_{\\ell=1}^{l}\\frac{x_{\\ell}^{2}}{2\\updelta q_{\\mu k}^{t}}+\\sum_{\\ell=1}^{l}\\left(x_{0}+x_{\\ell}+h_{\\mu k}^{t}\\right)\\sum_{\\mathrm{a}=1}^{n}b_{k}^{\\ell\\mathrm{a}}\\right\\ } \\,,\\end{aligned}\\ ] ] where @xmath280 and @xmath281 . also here",
    "we expect the logarithm of the normalisation term ( linked to the free energy ) obtained from the well behaved distribution @xmath212 to be self - averaging , thus:@xmath282 which is satisfied if the entries behave like @xmath283 and @xmath284 where @xmath285 and @xmath286 .",
    "using this new scaled parameters , the expression for the normalisation is @xmath287 where@xmath288\\,.\\ ] ]    as before , we drop the indexes @xmath73 , _ k _ , and _",
    "t _ for brevity .",
    "the critical points of the function @xmath289 satisfy the following set of equations : @xmath290 which are satisfied for the following values : @xmath291 where @xmath292 .",
    "the second equation in the set , equation  ( [ eq : set ] ) , has the same form for all @xmath293 and in the small field regime it has at most three different solutions . from the three possible solutions ,",
    "one is a local maximum ; of the other two , the one that has the same sign as _ h _ is dominant .",
    "thus we can expect , for all @xmath44 , @xmath294 .",
    "this reduces the set of @xmath279 equations to one @xmath295 where @xmath296 .",
    "with the substitution @xmath297 the equation has the same form as equation  ( [ eq : derivada ] ) , i.e. @xmath298 if one considers again the field _",
    "h _ to be small , the solutions can be expressed as an expansion of the zero field solutions @xmath299 , where @xmath300 is given by equation  ( [ eq : xih ] ) , and @xmath301 using these expansions the critical values are given by : @xmath302 $ ] and @xmath303 $ ] for all @xmath304    as in the rs case , the expansion of @xmath248 around the critical points in the small field regime is @xmath305 .",
    "so the dominant solution is the one that shares the sign with the field .    for a sufficiently large system with @xmath277 variables ,",
    "one expects the following expansion to be valid:@xmath306\\right.\\nonumber \\\\   &   & \\left.\\qquad\\quad+{\\rm e}^{-nlmh}\\exp\\left[-\\frac{nl}{2}\\left(\\mathbf{x}\\!-\\!\\mathbf{x}_{-h}^{*}\\right)^{\\sf t}\\mathbf{h}_{\\phi ,-",
    "h}\\left(\\mathbf{x}\\!-\\!\\mathbf{x}_{-h}^{*}\\right)\\right]\\right\\ } \\,,\\label{eq : expmultivar}\\end{aligned}\\ ] ] where @xmath307 is the hessian of @xmath248 in @xmath308 .",
    "defining @xmath309\\ , mh\\right\\ } $ ] , the entries of the hessian become @xmath310 the corresponding characteristic equation is : @xmath311 the solutions for this equation , disregarding terms of @xmath312 and @xmath313 , are : @xmath314\\left[\\xi(m , g)+1\\right]\\left(1-m^{2}\\right)\\ , mh\\right\\}\\nonumber \\\\ \\lambda_{1,\\pm h } & = & \\frac{1}{l}\\left(\\gamma_{\\pm h}-\\frac{\\beta_{\\pm h}^{2}}{\\alpha_{\\pm h}}\\right)\\label{eq : eigenvalues}\\\\   & \\simeq & \\lambda_{1}\\left\\ { 1\\pm2\\frac{\\xi(m , g_{1})^{2}\\left[\\xi(m , g_{2})-1\\right]}{1-\\left[\\xi(m , g_{1})-1\\right]\\left[\\xi(m , g_{2})-1\\right]}\\left[\\xi(m , g)+1\\right]\\left(1-m^{2}\\right)\\ , mh\\right\\}\\nonumber \\\\ \\lambda_{\\ell,\\pm h } & = & \\frac{1}{l}\\gamma_{\\pm h}\\nonumber \\\\   & \\simeq & \\lambda_{\\ell}\\left\\ { 1\\pm2\\left[\\xi(m , g_{2})-1\\right]\\left[\\xi(m , g)+1\\right]\\left(1-m^{2}\\right)\\ , mh\\right\\ } \\quad\\forall\\,\\ell=2,\\dots , l\\,,\\nonumber\\end{aligned}\\ ] ] where @xmath315 , @xmath316 and @xmath317 .",
    "the corresponding eigenvectors , up to order @xmath318 , are : @xmath319 these vectors satisfy the normalisation condition @xmath320\\;\\;\\forall\\ell,\\ell^{\\prime}=0,1,\\dots , l.$ ] the linear transformation from the canonical basis to the basis of eigenvectors is then represented by a matrix with the entries @xmath321\\nonumber \\\\   &   & + \\frac{1}{\\sqrt{l}}\\,\\delta_{1j}\\left[\\delta_{0i}\\,\\frac{\\beta_{0}}{\\alpha_{0}}+\\left(1-\\delta_{0i}\\right)\\right]-\\frac{1}{l}\\,\\delta_{0j}\\left(1-\\delta_{0i}\\right)\\,\\frac{\\beta_{0}}{\\alpha_{0}}\\,,\\label{eq : rot}\\end{aligned}\\ ] ] ignoring terms of @xmath322 . because this transformation is a rigid rotation , the following properties are satisfied : @xmath323 and @xmath324    second order terms in equation  ( [ eq : expmultivar ] ) can be re - written using the diagonal representation of the hessian .",
    "therefore , keeping only terms of order @xmath325 we have that : @xmath326 , where @xmath327 and @xmath328 is the diagonal representation of the hessian , i.e. @xmath329 . using the diagonal representation in conjunction with equation  ( [ eq : expmultivar ] ) one obtains an expression for the normalisation term @xmath330\\\\   &   & + { \\rm e}^{-nl\\left(\\phi_{0}+mh\\right)}\\int{\\rm d}\\mathbf{y}\\,\\exp\\left[-\\frac{nl}{2}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)^{\\sf t}\\mathbf{h}_{\\phi ,- h}^{\\prime}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)\\right]\\\\   & \\simeq & { \\rm e}^{-nl\\phi_{0}}\\left(\\frac{2\\pi}{nl}\\right)^{\\frac{l+1}{2}}\\left[{\\rm e}^{nlmh}\\prod_{\\ell=0}^{l}\\lambda_{\\ell , h}^{-\\frac{1}{2}}+{\\rm e}^{-nlmh}\\prod_{\\ell=0}^{l}\\lambda_{\\ell ,- h}^{-\\frac{1}{2}}\\right]\\,.\\end{aligned}\\ ] ] for a small field , the product of the eigenvalues can be approximated by @xmath331\\left[\\xi(m , g)+1\\right]lmh\\right\\ } \\prod_{\\ell=0}^{l}\\lambda_{\\ell}^{-\\frac{1}{2}}\\,.\\end{aligned}\\ ] ] thus , the expression for @xmath332 reduces to @xmath333\\left[\\xi(m , g)+1\\right]lmh\\right\\ } \\right.\\\\   &   & \\qquad\\qquad\\qquad+\\left.{\\rm e}^{-nlmh}\\left\\ { 1+\\left[\\xi(m , g_{2})-1\\right]\\left[\\xi(m , g)+1\\right]lmh\\right\\ } \\right\\ } \\,.\\end{aligned}\\ ] ] the mean value of a given function @xmath334 is then given by @xmath335\\\\   &   & + \\mathcal{z}^{-1}{\\rm e}^{-nl\\left(\\phi_{0}+mh\\right)}\\int{\\rm d}\\mathbf{y}\\,\\exp\\left\\ { -\\frac{nl}{2}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)^{\\sf t}\\mathbf{h}_{\\phi ,- h}^{\\prime}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)\\right\\ } \\\\   &   & \\qquad\\qquad\\qquad\\qquad\\qquad\\left[f\\left(\\mathbf{x}_{-h}\\right)+\\frac{1}{2}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)^{\\sf t}\\mathbf{h}_{f ,- h}^{\\prime}\\left(\\mathbf{y}-\\mathbf{y}_{-h}^{*}\\right)\\right]\\,,\\end{aligned}\\ ] ] where @xmath336 is the hessian of the function @xmath337 in the basis of eigenvectors of @xmath338 , evaluated at the critical points .",
    "the linear terms in the expansion of @xmath339 do not contribute to the expectation value .",
    "the gaussian integral of the cross products of the type @xmath340 with @xmath341 are zero , thus the gaussian integral of the second term in the expansion of @xmath339 becomes : @xmath342\\left(\\mathbf{y}-\\mathbf{y}_{\\pm h}^{*}\\right)^{\\sf t}\\mathbf{h}_{f,\\pm h}^{\\prime}\\left(\\mathbf{y}-\\mathbf{y}_{\\pm h}^{*}\\right)\\nonumber \\\\ i_{+ } & \\simeq & \\frac{1}{2}\\,\\left\\ { 1-{\\rm e}^{-2nlmh}\\left\\ { 1 + 2\\left[\\xi(m , g_{2})-1\\right]\\left[\\xi(m , g)+1\\right]lmh\\right\\ } \\right\\ } \\;\\frac{1}{nl}\\,\\sum_{\\ell=0}^{l}\\lambda_{\\ell , h}^{-1}\\left(\\mathbf{h}_{f , h}^{\\prime}\\right)_{\\ell\\ell}\\nonumber \\\\ i_{- } & \\simeq & \\frac{1}{2}\\,{\\rm e}^{-2nlmh}\\left\\ { 1 + 2\\left[\\xi(m , g_{2})-1\\right]\\left[\\xi(m , g)+1\\right]lmh\\right\\ } \\;\\frac{1}{nl}\\,\\sum_{\\ell=0}^{l}\\lambda_{\\ell ,- h}^{-1}\\left(\\mathbf{h}_{f ,- h}^{\\prime}\\right)_{\\ell\\ell}\\,.\\label{b6}\\end{aligned}\\ ] ] using the expansion @xmath343 where @xmath344 and @xmath345 , the diagonal entries of the transformed hessian are : @xmath346 with @xmath347 defined by the second term in ( [ b7 ] ) . using the entries of the diagonalised hessian ,",
    "the last term in the integrals ( [ b6 ] ) becomes @xmath348 disregarding terms of @xmath349 the expectation value of an arbitrary function @xmath337 can then be approximated by @xmath350\\!+\\!\\delta\\ !",
    "h,\\label{eq : mean1rsb}\\end{aligned}\\ ] ] where we have disregarded terms of @xmath351,@xmath352 and @xmath353 . by simple inspection ,",
    "equation  ( [ eq : mean1rsb ] ) is equivalent to the rs mean value equation  ( [ eq : meanrs ] ) .",
    "the single variable mean value is then : @xmath354 the expansion for @xmath355 is @xmath356\\left(1,\\stackrel{\\ell-1\\;{\\rm times}}{\\overbrace{0,0,\\dots,0}},1,\\stackrel{l-\\ell\\;{\\rm times}}{\\overbrace{0,0,\\dots,0}}\\right)^{\\sf t}\\mathbold{\\xi}\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)h_{\\mu k}^{t}\\,,\\ ] ] which results in the following expression for the single variable mean value @xmath357h_{\\mu k}^{t}\\\\   &   & -m_{\\mu k}^{t}\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\frac{1}{nl}\\sum_{k=0}^{l}\\lambda_{k}^{-1}\\left(\\mathbf{m^{\\prime}}_{0\\ell}\\right)_{kk}\\,,\\end{aligned}\\ ] ] where @xmath358 is a matrix such that @xmath359\\mathbf{m}_{0\\ell}$ ] . in the basis of the @xmath360 eigenvalues , the expressions for the diagonal elements of this matrix are @xmath361 where @xmath362 if @xmath363 and 0 otherwise .",
    "the sum of the eigenvalues inverse times the diagonal elements equation  ( [ eq : diagm ] ) results in @xmath364+\\frac{1}{nl}\\,\\frac{1}{\\alpha_{0}}\\left[1+\\frac{\\left(\\alpha_{0}+\\beta_{0}\\right)^{2}}{\\alpha_{0}\\gamma_{0}-\\beta_{0}^{2}}\\right]\\\\   & = & \\frac{1}{n}\\,\\frac{1}{\\gamma_{0}}\\,\\left[\\sum_{k=2}^{l}\\frac{1}{k\\left(k-1\\right)}\\right]+\\frac{1}{nl}\\,\\frac{1}{\\alpha_{0}}\\left[1+\\frac{\\left(\\alpha_{0}+\\beta_{0}\\right)^{2}}{\\alpha_{0}\\gamma-\\beta_{0}^{2}}\\right]\\\\   & = & \\frac{1}{n}\\,\\frac{1}{\\gamma_{0}}+\\frac{1}{nl}\\,\\frac{1}{\\alpha_{0}}\\left[1+\\frac{\\left(\\alpha_{0}+\\beta_{0}\\right)^{2}}{\\alpha_{0}\\gamma_{0}-\\beta_{0}^{2}}-\\frac{\\alpha_{0}}{\\gamma_{0}}\\right]\\\\   & = & \\frac{1}{n}\\ , g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)+\\frac{1}{nl}\\,\\left[g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)\\right]\\end{aligned}\\ ] ] where we have used that @xmath365^{-1}=(l-1)/l,$ ] @xmath366 and @xmath367=g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right).$ ] the final expression for the expectation value of a single variable is @xmath368\\ , m_{\\mu k}^{t}\\nonumber \\\\   &   & -\\frac{g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{nl}\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\ , m_{\\mu k}^{t}\\nonumber \\\\   &   & + \\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\ , h_{\\mu k}^{t}\\,.\\label{eq : meanb1rsb}\\end{aligned}\\ ] ] to calculate @xmath369 , an off - diagonal element ( @xmath370 ) in the same block  @xmath44 , we can apply the equation  ( [ eq : mean1rsb ] ) with @xmath371 , thus the hessian matrix is @xmath372\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\mathbf{m}_{0\\ell}$ ] , thus : @xmath373\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\nonumber \\\\   &   & + \\frac{g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{nl}\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\nonumber \\\\   &   & + 2\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\ , m_{\\mu k}^{t}h_{\\mu k}^{t}.\\label{eq : meanbblock1rsb}\\end{aligned}\\ ] ] finally , to calculate the expectation value for the product of two variables belonging to different blocks @xmath374 ( the sub - block index @xmath375 is insignificant in this case ) , @xmath376 .",
    "we set @xmath377 , thus the hessian matrix @xmath378 where @xmath379\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]$ ] , @xmath380^{2}$ ] and @xmath381 $ ] .",
    "the diagonal elements @xmath382 in the basis of eigenvectors of @xmath360 are @xmath383\\\\ \\mathcal{k}_{\\ell\\ell^{\\prime};j } & = & -2\\delta_{j\\ell}\\mathcal{m}_{2}\\left(m_{\\mu k}^{t}\\right)\\frac{\\ell-1}{\\ell}-2\\left[\\theta\\left(j-\\ell\\right)\\theta\\left(\\ell^{\\prime}-j\\right)\\right]\\frac{\\mathcal{m}_{2}\\left(m_{\\mu k}^{t}\\right)}{j(j-1)}\\\\   &   & -2\\delta_{j\\ell^{\\prime}}\\left[\\frac{\\mathcal{m}_{1}\\left(m_{\\mu k}^{t}\\right)}{\\ell^{\\prime}}+\\frac{\\mathcal{m}_{2}\\left(m_{\\mu k}^{t}\\right)}{\\ell^{\\prime}}\\left(\\ell^{\\prime}-1+\\frac{1}{\\ell^{\\prime}-1}\\right)\\right]+2\\theta\\left(j-\\ell^{\\prime}\\right)\\frac{\\mathcal{m}_{0}\\left(m_{\\mu k}^{t}\\right)}{j(j-1)}\\,,\\end{aligned}\\ ] ] thus , the sum of the diagonal elements is : @xmath384\\!-\\!\\frac{1}{n}\\frac{1}{\\gamma_{0}}\\left\\ { \\mathcal{m}_{2}\\left(m_{\\mu k}^{t}\\right)\\left[\\frac{\\ell-1}{\\ell}\\!+\\!\\sum_{j=\\ell+1}^{\\ell^{\\prime}-1}\\frac{1}{j(j-1)}\\right]\\right.\\\\   &   & + \\left.\\frac{\\mathcal{m}_{1}\\left(m_{\\mu k}^{t}\\right)}{\\ell^{\\prime}}+\\frac{\\mathcal{m}_{2}\\left(m_{\\mu k}^{t}\\right)}{\\ell^{\\prime}}\\left(\\ell^{\\prime}-1+\\frac{1}{\\ell^{\\prime}-1}\\right)-\\mathcal{m}_{0}\\left(m_{\\mu k}^{t}\\right)\\sum_{j=\\ell^{\\prime}+1}^{l}\\frac{1}{j(j-1)}\\right\\ } \\\\   & = & -\\frac{g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{n}\\,\\left[\\mathcal{m}_{1}\\left(m_{\\mu k}^{t}\\right)-\\mathcal{m}_{0}\\left(m_{\\mu k}^{t}\\right)\\right]\\\\   &   & \\qquad+\\frac{g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{nl}\\mathcal{m}_{0}\\left(m_{\\mu k}^{t}\\right)\\,.\\end{aligned}\\ ] ] using the sum of diagonal terms one then derives the expected correlation for variables belonging to two different blocks @xmath385\\nonumber \\\\   &   & + \\frac{g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{nl}\\left[1 - 3\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\nonumber \\\\   &   & + 2\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]\\ , m_{\\mu k}^{t}h_{\\mu k}^{t}\\,.\\label{eq : covllprime}\\end{aligned}\\ ] ] keeping in mind that @xmath386 and using equations  ( [ eq : meanb1rsb])-([eq : covllprime ] ) , the covariance matrix entries can be then calculated : @xmath387+\\delta^{\\ell\\ell^{\\prime}}\\left(1-\\delta^{{\\rm a}{\\rm a}^{\\prime}}\\right)\\,\\frac{g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{n}\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]^{2}\\\\   &   & + \\left(1-\\delta^{\\ell\\ell^{\\prime}}\\right)\\,\\frac{g_{\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{\\mu k}^{t}\\right)-g_{2\\mu k}^{t}\\xi\\left(m_{\\mu k}^{t},g_{2\\mu k}^{t}\\right)}{nl}\\left[1-\\left(m_{\\mu k}^{t}\\right)^{2}\\right]^{2}\\,,\\end{aligned}\\ ] ] where we have kept only the dominant terms at each entry , disregarding terms of order @xmath388 .",
    "if the @xmath271 and @xmath272 are unbiased variables , the variable @xmath270 , by virtue of the central limit theorem , obeys a normal distribution , with mean value and covariance matrix that can be obtained by employing the expressions derived for @xmath389 @xmath390 where @xmath391 is given by equations  ( [ eq : xxx ] ) and @xmath392^{2}\\\\ v_{\\mu k}^{t } & \\equiv & \\sum_{l\\neq k}\\varepsilon_{\\mu l}^{2}g_{\\mu l}^{t}\\xi\\left(m_{\\mu l}^{t},g_{\\mu l}^{t}\\right)\\left[1-\\left(m_{\\mu l}^{t}\\right)^{2}\\right]^{2}\\end{aligned}\\ ] ] are macroscopic variables of @xmath4 .",
    "in particular , @xmath276 and @xmath393 are free variables that can be used to optimise a given performance measure .",
    "from the conditional probabilities of equations  ( [ eq : bp1 ] ) and ( [ eq : bp2 ] ) and with the application of the probability distributions @xmath394 of equation  ( [ eq : pdelrs ] ) in  ( [ eq : likelihood ] ) we can express the message from nodes @xmath11 to nodes @xmath105 at time @xmath106 as : @xmath395}{{\\displaystyle \\int{\\rm d}\\mathbf{\\delta}_{\\mu k}}p\\left(\\mathbf{\\delta}_{\\mu k}|\\mathbf{b}\\right){\\displaystyle \\sum_{\\left\\ { \\mathbf{b}_{k}\\right\\ } } } p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\left[1+\\varepsilon_{\\mu k}\\mathbf{b}_{k}^{\\sf t}\\nabla_{\\mathbf{{\\delta}}_{\\mu k}}\\ln p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\right]}\\,.\\nonumber \\end{aligned}\\ ] ] if @xmath396 , and ignoring @xmath397 terms , the traces on @xmath39 can be written as @xmath398 & = & 2^{n}p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\\\ { \\displaystyle \\sum_{\\left\\ { \\mathbf{b}_{k}\\right\\ } } } b_{k}^{{\\rm a}^{\\prime}}\\ , p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\left[1+\\varepsilon_{\\mu k}\\mathbf{b}_{k}^{\\sf t}\\nabla_{\\mathbf{{\\delta}}_{\\mu k}}\\ln p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\right ] & = & 2^{n}\\varepsilon_{\\mu k}p\\left(y_{\\mu}|\\mathbf{{\\delta}}_{\\mu k};\\mathbold{\\gamma}\\right)\\frac{\\partial}{\\partial\\delta_{\\mu k}^{{\\rm a}^{\\prime}}}\\ln p\\left(y_{\\mu}|\\delta_{\\mu k}^{\\tilde{{\\rm a}}};\\mathbold{\\gamma}\\right)\\,,\\end{aligned}\\ ] ] thus , following from ( [ eq : mhat ] ) and neglecting @xmath399 terms @xmath400^{n-1}}\\nonumber \\\\   &   & \\qquad\\times\\int{\\rm d}\\delta\\exp\\left\\ { -\\frac{\\left(\\delta-\\vartheta\\right)^{2}}{2x^{t}}\\right\\ } \\frac{\\partial}{\\partial\\delta}p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)\\,,\\nonumber \\end{aligned}\\ ] ] and @xmath401\\right\\ } \\\\   &   & \\qquad\\times\\prod_{\\ell\\neq\\ell^{\\prime}}{\\displaystyle \\left[\\int{\\rm d}\\delta\\exp\\left\\ { -\\frac{\\left(\\delta-\\vartheta_{\\mu k}^{0\\ell t}\\right)^{2}}{2x^{t}}+\\ln p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)\\right\\ } \\right]^{n}}\\\\   &   & \\qquad\\times{\\displaystyle \\left[\\int{\\rm",
    "d}\\delta\\exp\\left\\ { -\\frac{\\left(\\delta-\\vartheta_{\\mu k}^{0\\ell^{\\prime}t}\\right)^{2}}{2x^{t}}+\\ln p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)\\right\\ } \\right]^{n-1}}\\\\   &   & \\qquad\\times\\int{\\rm d}\\delta\\exp\\left\\ { -\\frac{\\left(\\delta-\\vartheta_{\\mu k}^{0\\ell^{\\prime}t}\\right)^{2}}{2x^{t}}\\right\\ } \\frac{\\partial}{\\partial\\delta}p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)\\,,\\end{aligned}\\ ] ] where @xmath402 and @xmath403 are suitable normalisation constants and @xmath56 .",
    "one can then define : @xmath404^{-1}\\int{\\rm d}\\delta\\exp\\left\\ { -{\\displaystyle \\frac{\\left(\\delta-\\vartheta\\right)^{2}}{2x^{t}}}\\right\\ } { \\displaystyle \\frac{\\partial}{\\partial\\delta}p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)}\\nonumber \\\\   & = & \\left[\\mathcal{g}\\left(y_{\\mu},\\vartheta\\right)\\right]^{-1}\\int{\\rm d}\\delta\\exp\\left\\ { -{\\displaystyle \\frac{\\left(\\delta-\\vartheta\\right)^{2}}{2x^{t}}}\\right\\ } \\frac{\\delta-\\vartheta}{x^{t}}{\\displaystyle p\\left(y_{\\mu}|\\delta;\\mathbold{\\gamma}\\right)}\\nonumber \\\\   & = & \\frac{\\partial}{\\partial\\vartheta}\\ln\\mathcal{g}\\left(y_{\\mu},\\vartheta\\right)\\label{eq : pcal}\\\\ ^{{\\rm ( rs)}}\\mathcal{h}\\left(\\vartheta , y_{\\mu}\\right ) & \\equiv & \\frac{\\left(\\vartheta - u_{\\mu k}^{t}\\right)^{2}}{2r_{\\mu k}^{t}}-\\ln\\mathcal{g}\\left(y_{\\mu},\\vartheta\\right)\\label{eq : hcalrs}\\\\ ^{{\\rm ( 1rsb)}}\\mathcal{h}\\left(\\vartheta^{0},\\vartheta^{\\ell},y_{\\mu}\\right ) & \\equiv & \\frac{1}{2}\\,\\left[\\frac{\\left(\\vartheta^{0}\\right)^{2}}{v^{t}-r^{t}}+\\frac{\\left(\\vartheta^{\\ell}\\right)^{2}}{v^{t}-l^{-1}\\left(v^{t}-r^{t}\\right)}\\right]-\\ln\\mathcal{g}\\left(y_{\\mu,}\\vartheta_{\\mu k}^{0\\ell t}\\right)\\,.\\label{eq : hcal1rsb}\\end{aligned}\\ ] ] thus the expression for the rs message is : @xmath405 in the large _",
    "limit , only the solutions @xmath66 of @xmath406 , that correspond to the minimum of @xmath407 contribute to the integral .",
    "the dominant term in the integral is obtained via saddle point methods , which leads to the final expression for the message @xmath408 where @xmath66 is given by equation  ( [ eq : wrs ] ) .",
    "the 1rsb case is a little more delicate .",
    "the exponential is a sum over @xmath45 functions@xmath409 .",
    "therefore , a taylor expansion close to the saddle point of equation  ( [ eq : w1rsb ] ) is employed resulting in @xmath410 where @xmath411 is the energy of the ground state , @xmath412 and the entries @xmath413 , @xmath414 and @xmath415 satisfy the equation@xmath416 where @xmath417 is the solution of equation  ( [ eq : w1rsb ] ) .",
    "if @xmath418 and @xmath419+\\left(\\delta_{j0}+\\delta_{k0}\\right)\\left(1-\\delta_{jk}\\right)l^{-1}h_{1}$ ] is the hessian of @xmath420 , then @xmath421 the matrix @xmath422 has the same structure as @xmath360 , therefore , the eigenvalues and eigenvectors of @xmath422 can be obtained adapting equations  ( [ eq : eigenvalues ] ) and ( [ eq : eigenvectors ] ) by the substitutions @xmath423 , @xmath424 and @xmath425 .",
    "expanding @xmath98 at the saddle point @xmath417 one obtains @xmath426 where @xmath427 the resulting messages are @xmath428}}{{\\displaystyle \\int{\\rm d}\\mathbf{{\\omega}}\\,\\exp\\left\\ { -\\frac{nl}{2}\\updelta\\mathbf{\\theta}^{\\sf t}\\mathbf{h}_{\\mathcal{h}}\\updelta\\mathbf{\\theta}\\right\\ } } } } \\end{aligned}\\ ] ] where the term proportional to @xmath429 vanishes for parity reasons . in the basis of eigenvectors of @xmath422 , i.e. @xmath430 where * u * is adapted from equation  ( [ eq : rot ] ) , the message has the form:@xmath431 where @xmath432 are the eigenvalues of @xmath422 and @xmath433 is adapted from equation  ( [ eq : diagm ] ) .",
    "the expression for the message is reduced to @xmath434}\\nonumber \\\\   & \\simeq & \\varepsilon_{\\mu k}\\frac{\\tilde{\\vartheta}_{\\mu k}^{t}-u_{\\mu k}^{t}}{{2v}^{t}-r^{t}}+\\frac{\\varepsilon_{\\mu k}}{2n}\\,\\frac{\\mathcal{p}_{2}v^{t}}{1-\\mathcal{p}_{1}v^{t}}\\,.\\label{eq : mm1rsb}\\end{aligned}\\ ] ]    the expression for the messages from * b*-nodes to * y*-nodes is : @xmath435 which can be approximated by @xmath436}{{\\displaystyle \\sum_{\\left\\ { \\mathbf{b}_{k}\\right\\ } } } \\,\\int\\mathrm{d}\\mathbf{\\delta}_{\\nu k}p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu k};\\mathbold{\\gamma}\\right)p\\left(\\mathbf{{\\delta}}_{\\nu k}|\\mathbf{b}\\right)\\left[1+\\varepsilon_{\\nu k}\\mathbf{b}_{k}^{\\sf t}\\nabla_{\\mathbf{{\\delta}}_{\\nu k}}\\ln p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu k};\\mathbold{\\gamma}\\right)\\right]}\\\\   & = & \\frac{{\\displaystyle \\sum_{b_{k}^{{\\rm a}^{\\prime}}=\\pm1}}\\ , b_{k}^{{\\rm a}^{\\prime}}\\int\\mathrm{d}\\mathbf{\\delta}_{\\nu k}p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu k};\\mathbold{\\gamma}\\right)p\\left(\\mathbf{{\\delta}}_{\\nu k}|b_{k}^{{\\rm a}^{\\prime}}\\right)\\left[1+\\varepsilon_{\\nu k}b_{k}^{{\\rm a}^{\\prime}}{\\displaystyle \\frac{\\partial}{\\partial\\delta_{\\mu k}^{{\\rm a}^{\\prime}}}}\\ln p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu k};\\mathbold{\\gamma}\\right)\\right]}{{\\displaystyle \\sum_{b_{k}^{{\\rm a}^{\\prime}}=\\pm1}}\\,\\int\\mathrm{d}\\mathbf{\\delta}_{\\nu k}p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu",
    "k};\\mathbold{\\gamma}\\right)p\\left(\\mathbf{{\\delta}}_{\\nu k}|b_{k}^{{\\rm a}^{\\prime}}\\right)\\left[1+\\varepsilon_{\\nu k}b_{k}^{{\\rm a}^{\\prime}}{\\displaystyle \\frac{\\partial}{\\partial\\delta_{\\mu k}^{{\\rm a}^{\\prime}}}}\\ln p\\left(y_{\\nu}|\\mathbf{{\\delta}}_{\\nu k};\\mathbold{\\gamma}\\right)\\right]}\\\\   & = & \\frac{{\\displaystyle \\sum_{b_{k}^{{\\rm a}}=\\pm1}b_{k}^{{\\rm a}}}{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1+\\widehat{m}_{\\nu k}^{t}b_{k}^{{\\rm a}}}{\\mathscr n_{\\nu k}^{t}}}}{{\\displaystyle \\sum_{b_{k}^{{\\rm a}}=\\pm1}}{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1+\\widehat{m}_{\\nu k}^{t}b_{k}^{{\\rm a}}}{\\mathscr n_{\\nu k}^{t}}}}=\\frac{{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1+\\widehat{m}_{\\nu k}^{t}}{\\mathscr n_{\\nu k}^{t}}}-{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1-\\widehat{m}_{\\nu k}^{t}}{\\mathscr n_{\\nu k}^{t}}}}{{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1+\\widehat{m}_{\\nu k}^{t}}{\\mathscr n_{\\nu k}^{t}}}+{\\displaystyle \\prod_{\\nu\\neq\\mu}}{\\displaystyle \\frac{1-\\widehat{m}_{\\nu k}^{t}}{\\mathscr n_{\\nu k}^{t}}}}=\\tanh\\left(\\sum_{\\nu\\neq\\mu}{\\rm arctanh}\\left(\\widehat{m}_{\\nu k}^{t}\\right)\\right)\\,,\\end{aligned}\\ ] ] but since @xmath437 we have that @xmath438",
    "for the rs case the equation to be solved is : @xmath439 thus , the equation to be satisfied is:@xmath440    for the 1rsb case we have that @xmath441 resulting in the set of equations:@xmath442 which is equivalent to:@xmath443 where @xmath444 . observed that equation  ( [ eq : w1rsb ] ) is equivalent to equation  ( [ eq : wrs ] ) and that the ground state @xmath66 is independent of the indices 0 and @xmath44 .",
    "our goal is to devise an algorithm that returns a better estimate of the message at each iteration ; we therefore apply a variational approach that optimises the free parameters of the model at each iteration .",
    "we expect to find a suitable set of parameters @xmath445 that maximises the drop in error per bit rate .",
    "the second term of the right hand side of equation  ( [ eq : gg ] ) is an implicit function of the parameters @xmath31 through @xmath70 and @xmath71 , therefore @xmath451 where the partial derivatives with respect to @xmath70 and @xmath71 are @xmath452\\left[n^{t}-m^{t}\\tanh\\left(\\sqrt{f^{t}}z+e^{t}\\right)\\right]\\\\ \\frac{\\partial}{\\partial f^{t}}\\left(\\frac{m^{t}}{\\sqrt{n^{t}}}\\right ) & = & \\left(n^{t}\\right)^{-\\frac{3}{2}}\\int\\mathcal{d}z\\,\\frac{z}{2\\sqrt{f^{t}}}\\,\\left[1-\\tanh^{2}\\left(\\sqrt{f^{t}}z+e^{t}\\right)\\right]\\left[n^{t}-m^{t}\\tanh\\left(\\sqrt{f^{t}}z+e^{t}\\right)\\right]\\,.\\end{aligned}\\ ] ] by the definition of the field @xmath68 we have that @xmath453 . exploiting gaussian properties of the distribution of @xmath454 ( [ eq : ef ] )",
    "@xmath455 and we suppose that @xmath70 and @xmath71 are both explicit functions of the parameters @xmath31 , therefore @xmath456\\left\\ { \\frac{\\partial e^{t}}{\\partial\\gamma_{i}}-\\frac{1}{2}\\,\\frac{e^{t}}{f^{t}}\\,\\frac{\\partial f^{t}}{\\partial\\gamma_{i}}\\right\\ } \\,.\\ ] ] by differentiation equation  ( [ eq : gg ] ) and using equation  ( [ eq : gammadiff ] ) one obtains @xmath457}\\left(\\frac{\\partial e^{t}}{\\partial\\gamma_{i}}-\\frac{1}{2}\\,\\frac{e^{t}}{f^{t}}\\,\\frac{\\partial f^{t}}{\\partial\\gamma_{i}}\\right)\\nonumber \\\\   &   & -\\left(n^{t}\\right)^{-\\frac{3}{2}}\\int\\mathcal{d}z\\,\\frac{n^{t}-m^{t}\\tanh\\left(\\sqrt{f^{t}}z+e^{t}\\right)}{\\cosh^{2}\\left(\\sqrt{f^{t}}z+e^{t}\\right)}\\left(\\frac{\\partial e^{t}}{\\partial\\gamma_{i}}+\\frac{z}{2\\sqrt{f^{t}}}\\frac{\\partial f^{t}}{\\partial\\gamma_{i}}\\right)\\nonumber \\\\   & = & -\\left(f^{t}n^{t}\\right)^{-\\frac{3}{2}}\\int\\frac{{\\rm d}u}{\\sqrt{2\\pi}}\\exp{\\textstyle \\left[-{\\displaystyle \\frac{\\left(u - e^{t}\\right)^{2}}{2f^{t}}}\\right]}\\,\\frac{u}{2}\\,\\frac{n^{t}-m^{t}\\tanh\\left(u\\right)}{\\cosh^{2}\\left(u\\right)}\\nonumber \\\\   &   & -\\left(\\frac{\\partial e^{t}}{\\partial\\gamma_{i}}-\\frac{1}{2}\\,\\frac{e^{t}}{f^{t}}\\,\\frac{\\partial f^{t}}{\\partial\\gamma_{i}}\\right)\\nonumber \\\\   &   & \\;\\times\\left\\ { \\frac{\\lambda^{2}}{\\sqrt{2\\pi}f^{t}}\\exp{\\textstyle \\left[-\\!{\\displaystyle \\frac{\\left(e^{t}\\right)^{2}}{2f^{t}}}\\right]}+\\int\\!\\!\\frac{{\\rm d}u}{\\sqrt{2\\pi f^{t}\\left(n^{t}\\right)^{3}}}\\exp{\\textstyle \\left[-\\!{\\displaystyle \\frac{\\left(u - e^{t}\\right)^{2}}{2f^{t}}}\\right]}\\,\\frac{n^{t}\\!-\\",
    "! m^{t}\\tanh\\left(u\\right)}{\\cosh^{2}\\left(u\\right)}\\right\\ } \\,.\\label{eq : casi}\\end{aligned}\\ ] ] to optimise @xmath458 with respect to @xmath459 one requires @xmath460 .",
    "the first term of the right hand side of equation  ( [ eq : casi ] ) is independent of the index _",
    "i _ and is zero if and only if the integrand is an odd function .",
    "this is true if @xmath461 .",
    "this condition is only satisfied if @xmath85 which automatically makes @xmath110 . by the application of this condition , the sum between curly brackets in the second term at the right hand side of eq.([eq : casi ] )",
    "is always positive , which implies @xmath86 .    the conditions",
    "@xmath85 and @xmath86 imply that : @xmath462 therefore , if the critical point is a minimum , then the expansion @xmath463 has a second term that satisfy the conditions : @xmath464 and @xmath465 , validating the optimisation process ."
  ],
  "abstract_text": [
    "<S> an efficient bayesian inference method for problems that can be mapped onto dense graphs is presented . </S>",
    "<S> the approach is based on message passing where messages are averaged over a large number of replicated variable systems exposed to the same evidential nodes . </S>",
    "<S> an assumption about the symmetry of the solutions is required for carrying out the averages ; here we extend the previous derivation based on a replica symmetric ( rs ) like structure to include a more complex one - step replica symmetry breaking ( 1rsb)-like ansatz . to demonstrate the potential of the approach it is employed for studying critical properties of the ising linear perceptron and for multiuser detection in code division multiple access ( cdma ) under different noise models . </S>",
    "<S> results obtained under the rs assumption in the non - critical regime give rise to a highly efficient signal detection algorithm in the context of cdma ; while in the critical regime one observes a first order transition line that ends in a continuous phase transition point . </S>",
    "<S> finite size effects are also observed . </S>",
    "<S> while the 1rsb ansatz is not required for the original problems , it was applied to the cdma signal detection problem with a more complex noise model that exhibits rsb behaviour , resulting in an improvement in performance . </S>"
  ]
}