{
  "article_text": [
    "diploid organisms , including humans , have homologous pairs of chromosomes where one chromosome in a pair is inherited from mother and the other from father .",
    "the two chromosomes in a pair are similar and essentially carry the same type of information but are not identical",
    ". in particular , chromosomes in a pair differ at a small fraction of positions ( i.e. , loci ) .",
    "such variations are referred to as single nucleotide polymorphisms ( snps ) ; in humans , frequency of snps is @xmath0 in @xmath1 .",
    "a haplotype is the string of snps on a single chromosome in a homologous pair .",
    "haplotype information is essential for understanding genetic causes of various diseases and for advancement of personalized medicine .",
    "however , direct measurement and identification of the entire haplotype is generally challenging , costly , and time and labor intensive . alternatively",
    ", single individual haplotypes can be assembled from short reads provided by high - throughput sequencing systems .",
    "these systems rely on so - called shotgun sequencing to oversample the genome and generate a redundant library of short reads .",
    "the reads are mapped to a reference and the individual genome is assembled following consensus of information provided by the reads .",
    "the length of each read ( i.e. , dna fragment ) in state - of - the - art sequencing systems is typically @xmath2 base pairs @xcite .",
    "note that this length is comparable to the average distance between snps on chromosomes .",
    "therefore , a single read is unlikely to cover more than one variant site which is needed for the haplotype assembly .",
    "moreover , the origin of a read ( i.e. , to which chromosome in a pair the read belongs ) is unknown and needs to be inferred @xcite .",
    "paired - end sequencing @xcite , also known as mate - paired sequencing @xcite , helps overcome these problems .",
    "this process generates pairs of short reads that are spaced along the target genome , where the spacing ( so - called insert size ) between the two reads in a pair is known .",
    "the mate - pairs allow acquisition of the information about distant snps on the same haplotype , and thus help assemble the haplotype .",
    "[ fig : pairedend ] illustrates the procedure of generating paired - end reads from a pair of chromosomes , where each read may cover two or more variant sites .",
    "the goal of haplotype assembly is to identify the chromosome from which fragments are sampled , and to reconstruct the haplotype sequences .",
    "when there are no sequencing errors , a fragment conflict graph framework @xcite converts the original problem into partitioning of the set of reads into two subsets , each collecting the reads that belong to the same chromosome in a pair . for erroneous data , it poses haplotyping as an optimization problem of minimizing the number of transformation steps needed to generate a bipartite graph @xcite .",
    "this leads to various formulations of the haplotype assembly problem including minimum fragment removal ( mfr ) , minimum snp removal ( msr ) , and minimum error correction ( mec)@xcite . the last one , mec , has been the most widely used criterion for haplotype assembly , due to its inherent relationship with independent error model .        in this paper",
    ", we analyze the haplotype assembly problem from information - theoretic perspective .",
    "in particular , we determine necessary and sufficient conditions for haplotype assembly , both in the absence of noise as well as for the case where data is erroneous . the paper is organized as follows .",
    "section ii formalizes the haplotype assembly problem . in section iii",
    ", we present an information theoretic view of haplotype assembly in the absence of sampling errors , and the erroneous case is discussed in section iv .",
    "simulation results and analyses are shown in section v. finally , section vi concludes the paper .",
    "a single nucleotide polymorphism ( snp ) is the variation between two chromosomes where the corresponding bases in a specific location on the chromosomes differ from each other .",
    "typically , diploid organisms have only two possible variants at one snp site . for the sake of convenience ,",
    "we denote one of the two variants as @xmath3 ( i.e. , the dominant one ) , while the other one we denote as @xmath4 ( i.e. , the recessive one ) . with this notation",
    ", a haplotype sequence @xmath5 comprising information about all snp sites on one of the chromosomes in a pair can be represented by a string with elements in @xmath6 , while the haplotype associated with the other chromosome in the pair is its additive inverse @xmath7 , where we denote @xmath8 and @xmath9 is the length of haplotypes ( i.e. , the number of snps ) .",
    "each paired - end read contains partial information about either of these two haplotypes .",
    "consider a set of discrete random variables @xmath10 , where @xmath11 and @xmath12 is the number of reads .",
    "each @xmath10 corresponds to the chromosome membership for read @xmath13 .",
    "more precisely , here , @xmath14 due to the limitation of read lengths , only a small fraction of entries are observed . in other words , a paired - end read @xmath15",
    "could be considered as a sequence drawn from the alphabet @xmath16 , where `` @xmath17 '' refers to the lack of information about that site . in the absence of sampling noise ,",
    "every observed element @xmath18 is obtained as the product of the corresponding snp and associated membership information @xcite .",
    "formally , this relationship is given by @xmath19    the collection of all reads forms a matrix @xmath20 , whose rows correspond to @xmath12 paired - end reads , and whose columns correspond to @xmath9 snp sites .",
    "the @xmath13th row of @xmath20 is denoted as @xmath15 ( i.e. , read @xmath13 ) , and the @xmath21th element of @xmath15 is denoted as @xmath18 . typically , only few entries in each row are numerical , if the effect of burst variations is ignored .    by equation , the observed matrix @xmath20 could be interpreted as being obtained from a rank @xmath0 matrix @xmath22 , whose row @xmath23 is either @xmath5 or @xmath7 based on the value of @xmath10 , while most of its entries are erased in the reading process . in particular , we have @xmath24 and @xmath25 is the collection of all observed locations , and the projection @xmath26 is defined by @xmath27 hence , the task of haplotype assembly is to recover haplotype @xmath5 and chromosome membership vector @xmath28 , or equivalently the matrix @xmath22 , from the observation matrix @xmath20 .",
    "an example , illustrated by fig .",
    "[ fig : pairedend ] , corresponds to the scenario of @xmath29 snp sites and @xmath30 paired - end reads . since only the first @xmath31 reads are ( shotgun ) sequenced from chromosome @xmath0",
    ", we obtain the chromosome membership vector @xmath32 .",
    "if denoting the haplotype from chromosome @xmath0 as @xmath33 , then the observed reads matrix , without the influence of error , is given by @xmath34.\\label{equ : reads_example}\\end{aligned}\\ ] ]",
    "from a joint source - channel coding perspective , haplotype assembly aims to recover two sources being communicated through an erasure channel ( see fig .  [",
    "fig : model ] ) .",
    "the first source is haplotype information , @xmath5 , and the second source is the chromosome membership vector @xmath28 .",
    "both of these vectors are assumed to originate from a uniform distribution , i.e. , their entries have @xmath35 probability to take values from @xmath6 .",
    "these two sources are encoded jointly using the function @xmath36 , and the encoded codeword @xmath37 . in particular ,",
    "each entry in @xmath22 is given by @xmath38 , which implies the encoder is a bijection .",
    "after receiving the output from channel @xmath20 , the decoder uses the decoding function to map its channel observations into an estimate of the message .",
    "specifically , we consider the decoder ( i.e. , an algorithm for haplotype assembly ) given by @xmath39 , such that @xmath40 , where @xmath41 represents the estimate .",
    "note that the encoding function is a bijection , decoding @xmath22 is equivalent to decoding both @xmath5 and @xmath28 .",
    "we define the error probability of decoding as @xmath42 as in the conventional information - theoretic analysis of a communication channel , we consider all possible choices of matrix @xmath22 ( denote the resulting ensemble by @xmath43 ) , and let @xmath12 and @xmath9 be large enough such that there exists at least one decoding function @xmath44 with small probability of error .",
    "the channel model reflects particular reading technique .",
    "for the paired - end sequencing technique without sampling errors , let us consider the channel @xmath45 described as follows :",
    "1 .   erasures happen independently across rows .",
    "2 .   in each row , only @xmath46 entries remain and their positions are uniformly random .",
    "unerased entries are observed correctly .    in other words , we observe precisely @xmath46 entries in each row of @xmath22 for simpleness for the moment , and the observations are correct and independent across different rows . under these assumptions ,",
    "the number of remaining entries in each column of @xmath20 approximately obeys poisson distribution .",
    "moreover , the expected length of insert size between @xmath46 sampled entries within a row is given by @xmath47 .",
    "we should point out that the insert size in practice is indeed limited and can not be made arbitrarily large .",
    "based on this model for haplotype assembly without sequencing errors , we consider the necessary and sufficient conditions on the required number of reads for recovery .",
    "[ thm : ed ] given @xmath46 arbitrary reliable observations in each row , the original haplotype matrix @xmath22 could be reconstructed only if the number of reads satisfies @xmath48 where @xmath9 is the length of target haplotype .",
    "moreover , if @xmath49 , a reconstruction algorithm , erasure decoding , could determine @xmath22 accurately with high probability . specifically , given a target small constant @xmath50 , there exists @xmath9 large enough such that by choosing @xmath51 the probability of error @xmath52 .",
    "we show the proof to necessary and sufficient conditions separately in the following two subsections .      using fano s inequality @xcite",
    ", we find that : @xmath53 where @xmath43 is the assemble of all possible @xmath22 , and its size is upper bounded by @xmath54 .",
    "recall @xmath25 comprises locations where @xmath22 is observed , which is also random based on sampling locations .",
    "then , @xmath25 is independent of @xmath22 , and its rows are independent due to our channel assumption .",
    "therefore , we have @xmath55 where @xmath56 follows from independence between @xmath22 and @xmath25 ; @xmath57 from fano s inequality , i.e. , equation ; @xmath58 from the fact @xmath20 is deterministic if @xmath22 and @xmath25 are both known in the error - free case ; and @xmath59 from the assumption that every row has exactly @xmath46 entries observed and noises are independent and symmetric .    finally , by noting that @xmath60 , we need @xmath61 for accurate recovery .",
    "more precisely , roughly we need @xmath62 for recovery with arbitrary small probability of decoding error .    note that in this proof , channel model is only utilized when bounding @xmath63 . to this end",
    ", the necessary result is extendable to more channel models ( i.e. , reading techniques ) . in particular",
    ", the lower bound @xmath62 fits for deterministic choice of reading sites , paired - end reading with fixed insert size , and more importantly , reading techniques with more than @xmath46 observations in each read .",
    "the essential condition for the establishment of necessary condition is to ensure the matrix is sparse .",
    "more precisely , the number of all observed entries in the matrix is in proportion to @xmath9 .",
    "the goal of a decoding algorithm is to recover @xmath22 ( or equivalently @xmath5 and @xmath28 ) from @xmath20 with high confidence . here ,",
    "we show a simple and effective algorithm , called `` erasure decoding '' , which requires only @xmath64 number of reads for reliable haplotype recovery . detailed steps of this algorithm are described as follows :    1 .",
    "choose the `` seed '' @xmath65 as an arbitrary non - erased entry in the first row , i.e. @xmath66 , where @xmath21 is randomly chosen such that @xmath67 .",
    "evaluate the membership of first row as @xmath68 .",
    "2 .   find all other rows with position @xmath21 not erased , i.e. , @xmath69 3 .",
    "evaluate the membership of all rows with indices in @xmath70 as @xmath71 for every @xmath72 .",
    "4 .   decode snps in the first row by @xmath73 for every @xmath72 and @xmath74 .",
    "5 .   delete all rows with indices in @xmath70 .",
    "arbitrarily choose another non - erased entry in the first row as the new seed @xmath66 , which has not been chosen as seed in any of the former steps .",
    "repeat step @xmath75 to @xmath76 until no row could be further erased .",
    "if the first row is the only remaining one and its entries are all decoded , claim @xmath77 ; otherwise claim a failure .    in this algorithm",
    ", we arbitrarily evaluate a chromosome membership for the first row , but it may not be the correct one .",
    "in fact , if the algorithm successfully decodes both @xmath5 and @xmath28 , then all elements could be flipped due to an incorrect choice of initial membership .",
    "however , the recovered matrix @xmath22 remains the same , due to the particular product operation to generate @xmath22 . at this point",
    ", the choice of initial membership does not influence the decoding performance .",
    "erasure decoding is closely connected to the bipartite partition interpretation @xcite .",
    "note that if our algorithm successfully recovers the message matrix @xmath22 , we can realign its rows such that the matrix could be partitioned into two sub - matrices with different chromosome memberships . to this end",
    ", the erasure decoding provides a practical algorithm to fulfill partition a bipartite for haplotype assembly , in the error - free case .",
    "[ fig : decoding ] shows the details of decoding procedures for the example illustrated in fig .",
    "[ fig : pairedend ] , where the read matrix is given by .    .",
    "in every round ( step @xmath75 to @xmath76 ) , the seed is marked in a rectangle , with its column index given by @xmath21 .",
    "rows that share the same positions observed as the seed are collected in assemble @xmath70 . a straight line crossing a whole row of the matrix represents a deletion .",
    "]    here , we analyze the performance of this proposed algorithm .",
    "more precisely , we show that if the number of reads sample is large enough , i.e. @xmath49 , the source matrix @xmath22 could be recovered correctly with high probability .",
    "observe that in the absence of sampling errors , the erasure decoding algorithm ensures the output to be the correct haplotype if both of the following conditions are satisfied .    1 .",
    "all rows except for the first one are deleted .",
    "all entries in the first row are decoded    at this point , decoding error occurs if at least one of the following events happen .    1 .",
    "the event @xmath78 : at least one of the columns in @xmath20 is erased such that the corresponding snp could not be decoded ; 2 .",
    "the event @xmath79 : there exist a partition of row indices @xmath80 , and a partition of column indices @xmath81 , such that @xmath82 and @xmath83 ( to make sure @xmath46 entries could be sampled from each row ) , and @xmath84 for any @xmath85 . in other words , the sampled entries could be considered as originated from two disjoint subsets of target haplotypes and thus there is no hope to recover it due to the lack of information bridging these subsets .",
    "we outline how to bound the probability of each of the two error events .",
    "first , note that by coupon collector effect , if @xmath49 then every column is covered by at least one read with high probability .",
    "more precisely , by taking @xmath86 , the error event ( or equivalently the tail distribution for coupon collector problem ) is given by @xmath87^m\\nonumber\\\\                      & \\leq \\sum\\limits_{i=1}^{n-2}n^i e^{-m\\frac{2i",
    "n - i(i+1)}{n(n-1)}}\\nonumber\\\\                      & = \\sum\\limits_{i=1}^{n-2}o(n^{-i})\\nonumber\\\\                      & = o(n^{-1 } ) .",
    "\\label{equ : error_1}\\end{aligned}\\ ] ]    on the other hand , the second error event @xmath79 could be further decomposed into sub - events @xmath88 which represent the type @xmath46 error event with particular @xmath89 and @xmath90 .",
    "then , we have @xmath91 observe that by symmetry and monotonicity , the right hand side in is maximized by two extreme points on the feasible @xmath92region , i.e. , for any @xmath93 and @xmath94 , @xmath95 .",
    "in particular , we have @xmath96^{m-1}}{[n(n-1)]^{m-1}}\\nonumber\\\\                          & \\leq n\\ln n \\left(1-\\frac{4n-6}{n(n-1)}\\right)^{n\\ln n-1}\\nonumber\\\\                          & \\leq n\\ln n e^{-\\frac{4n-6}{n(n-1)}(n\\ln n-1)}\\nonumber\\\\                          & = o(n^{-3}\\ln n).\\nonumber\\end{aligned}\\ ] ] hence , the probability of the second error event is upper bounded by @xmath97 combining these two bounds together , we obtain @xmath98 for arbitrary @xmath50 with sufficiently large @xmath9 .    note that there is a log - factor gap between the lower and upper bounds .",
    "as analyzed in @xcite , this log - factor generally exists and ensures enough entries sampled from each column for accurate recovery .",
    "if a more systematic reading method could be adopted to generate the observation matrix , the log - factor may not be essential for reconstruction .",
    "we will see in the next section , for the erroneous case , this log - factor gap between two bounds also exists .",
    "when determining the snp on a particular location , we basically perform a hypothesis testing between dominant and recessive . to this end , when sequencing errors are present , some of the entries observed in @xmath20 are flipped . here , we assume errors are independent and identically distributed",
    ". more precisely , generation of errors could be modeled as messages passing through a set of independent binary symmetric channels with parameter @xmath99 , where @xmath99 is the probability of flipping the sign . denoting the noise as matrix @xmath100 , where @xmath101 are i.i.d .",
    "distributed , we have @xmath102 hence , the system model for the erroneous case could be considered as the one for error - free case concatenated with a channel representing the generation of noises .",
    "more precisely , the equivalent channel model @xmath45 considered in this section is described as follows :    1 .",
    "erasures happen independently across rows .",
    "2 .   in each row , only @xmath46 entries remain and their positions are uniformly random .",
    "3 .   unerased entries have probability @xmath99 to be read incorrectly , and the errors happen independently .",
    "then , for perfect recovery , we want to reconstruct @xmath22 from @xmath20 with high probability . however , if no more than two entries could be observed in a row , the identification of origin is not always feasible .",
    "for instance , if we observe @xmath103 in a particular read , and know only one error happens when sequencing .",
    "then , there is no hope to discover whether the potential true sequence should be @xmath104 or @xmath105 , although either way does not influence the decoding of haplotypes . to this end , in the erroneous case , we aim to recover the row space only , i.e. , the haplotype @xmath5 , from matrix @xmath20 with high probability . more precisely , if denoting the estimate from a recovery algorithm as @xmath106 , we define the probability of error in this case as @xmath107 to evaluate the recovery accuracy .",
    "we desire this probability to be arbitrarily small , on an average across all possible implementation of @xmath5 .",
    "[ thm : sp ] given @xmath46 arbitrary unreliable observations in each row , the original haplotype vector @xmath5 could be reconstructed only if the number of reads satisfies @xmath48 where @xmath9 is the length of target haplotype .",
    "moreover , if @xmath49 , a reconstruction algorithm , spectral partitioning , could determine @xmath5 accurately with high probability .",
    "specifically , given a target small constant @xmath50 , there exists @xmath9 large enough such that by choosing @xmath51 the probability of error @xmath52 .",
    "the theorem shows that although observations are not reliable due to sampling noises , the number of reads needed remains the same scale of @xmath9 . here , we provide details to show the proofs to both conditions separately in the following subsections .      to study the necessary condition ,",
    "one may still rely on the fano s equality , i.e. , @xmath108 using this , we obtain @xmath109 in this case , @xmath110 does not vanish due to the influence of noise . in particular , by noting noises are assumed to be i.i.d .",
    ", we have @xmath111 combining with the observations that @xmath112 and @xmath113 , we have @xmath114},\\ ] ] which is still an @xmath62 scale lower bound .      on the other hand , from the perspective of sufficient condition , if errors happen , erasure decoding algorithm may not apply . with any luck",
    ", the algorithm sometimes recovers haplotypes correctly , but more commonly , erroneous items in the matrix may cause a failure . in fact ,",
    "an effective algorithm for haplotype assembly from a small number of reads remains open .",
    "most state - of - the - art algorithms are still based on graphical interpretation with an optimization formulation , adopting different objective criteria @xcite .    in particular , among these criteria ,",
    "widely adopted ones include minimum fragment removal ( mfr ) , minimum snp removal ( msr ) , and minimum error correction ( mec ) .",
    "mfr @xcite criterion aims to remove the minimum number of fragments ( i.e. , reads ) so as to leave a bipartite .",
    "the remaining graph is conflict - free and algorithms for error - free case could therefore be performed on it to recover the haplotypes .",
    "however , to solve this optimization problem itself is not immediate , since it is non - convex in general .",
    "msr @xcite criterion is an alternative formulation for the problem .",
    "precisely , it removes the least number of snp sites such that the remaining graph could be partitioned into two haplotypes . from the perspective of graphical interpretation",
    ", msr aims to find the maximum independent set of the original graph .",
    "mec @xcite criterion requires to flip the minimum number of entries in observed matrix to allow the assembly of haplotypes .",
    "it corresponds to a straight - forward error - correction insight with i.i.d .",
    "noise generation model .",
    "to this end , mec is the most widely preferred criterion in studies for the moment .",
    "hapcut @xcite is a typical algorithm to solve the mec optimization problem .",
    "however , in general , current algorithms basically consider the number of reads as a known parameter for complexity analysis , rather than regarding it as the essential measurement to argue sufficient condition for haplotyping . as a contrast , in this paper , we focus on the information theoretical view : the condition for perfect recovery .",
    "in particular , we propose a low - rank matrix interpretation for haplotype assembly",
    ". intuitively , for haplotype assemble , we aim to partition all snp sites into two sets , corresponding to dominant and recessive correspondingly . by regarding the adjacent matrix of the original graph as a perturbation of a planted model , which is a low rank matrix in nature",
    ", we claim that the partition is perfect as long as the parameters are chosen properly . in detail , first , we describe the `` spectral partitioning '' algorithm using svd technique to obtain a weaker conclusion that the fraction of partition errors vanishes as @xmath9 increases , and then , we use a remark to discuss a modified algorithm for perfect recovery at the end of this section .",
    "the steps for spectral partitioning are described as follows :    1 .",
    "construct an adjacent matrix @xmath115 based on the observation matrix @xmath20 , such that for every @xmath116 with @xmath117 , @xmath118 then , let @xmath119 for any @xmath117 to guarantee symmetry , and let @xmath120 for diagonal entries .",
    "2 .   perform singular value decomposition ( svd ) to matrix @xmath121 , i.e. @xmath122 such that @xmath123 are unitary matrices , and @xmath124 is diagonal .",
    "3 .   take the eigenvector @xmath125 corresponding to the second largest eigenvalue of @xmath121 , then construct sets @xmath126 based on this , the haplotype is recovered by @xmath127    in words , for every entry in @xmath121 , performs a majority voting among all reads covering the corresponding snp sites .",
    "note that this is equivalent to map hypothesis testing with uniform prior distribution . hence ,",
    "if the distribution of haplotype is not assumed to be uniform , or error distributions are not identical across snp sites , weighted majority voting should be utilized for a general case .    here ,",
    "we analyze the performance of spectral partitioning by showing its relationship to the classical partitioning problem on a planted model .",
    "the intuition originates from the perturbation theory for eigenvectors , with respect to a low rank matrix .",
    "the analysis follows steps similar to @xcite , but focusing on the particular haplotype assembly background such that bounds in this paper are much tighter .",
    "first of all , we consider the planted model , i.e. , a matrix @xmath128 defined as @xmath129_{n_1\\times n_1 } & \\left[\\beta\\right]_{n_1\\times n_2}\\nonumber\\\\ \\left[\\beta\\right]_{n_2\\times n_1 } & \\left[\\alpha\\right]_{n_2\\times n_2 } \\nonumber \\end{array } \\right],\\nonumber\\end{aligned}\\ ] ] where @xmath130 , @xmath131 , and @xmath132_{n_1\\times n_1}$ ] represents for an @xmath133 sub - matrix with all entries as @xmath134 .    by this particular construction , matrix @xmath135",
    "is believed to be low - rank .",
    "in fact , if we perform svd on @xmath135 , it is evident to see the rank of @xmath135 is @xmath46 , and its first two singular values and corresponding singular vectors are given by @xmath136_{1\\times n_1},\\left[\\frac{1}{\\sqrt{n_1\\mu_1 ^ 2+n_2}}\\right]_{1\\times n_2}\\right),\\label{equ : bar_v_1}\\\\ \\bm{v}_2(\\bm{b})&=\\left(\\left[\\frac{\\mu_2}{\\sqrt{n_1\\mu_2 ^ 2+n_2}}\\right]_{1\\times n_1},\\left[\\frac{1}{\\sqrt{n_1\\mu_2 ^ 2+n_2}}\\right]_{1\\times n_2}\\right),\\label{equ : bar_v_2}\\end{aligned}\\ ] ] where @xmath137 note that @xmath138 and @xmath139 for any @xmath140 and @xmath141 , so @xmath142",
    ". moreover , due to @xmath139 , the first @xmath140 entries in @xmath143 have opposite signs compared to the last @xmath141 ones .",
    "based on this observation , if we partition the indices into two sets with respect to their signs in @xmath143 , the result naturally provides a classification corresponding to different blocks of matrix @xmath135 .",
    "till now , we have introduced the intuition for performing partitioning on the planted model , i.e. , the second eigenvector has the inherent ability to distinguish different block indices .",
    "the next step is to relate the planted model @xmath135 to the adjacent matrix @xmath121 , as constructed by in the algorithm .",
    "note that each entry in @xmath121 is obtained from a majority voting among all random sequenced reads covering the corresponding snp sites .",
    "hence , entries in the upper triangle matrix of @xmath121 are random and independent .",
    "moreover , the distribution of each entry is bernoulli , and its parameter only depends on whether the corresponding snp sites are from the same block or not . to this end ,",
    "two parameters are enough to characterize the distribution of @xmath121 , and this provides an opportunity to connect @xmath121 to @xmath135 , with respect to a proper permutation of rows and columns ( note that permutation does not influence the eigenvectors ) .",
    "in particular , for any @xmath116 with @xmath144 , we define @xmath145 where @xmath146 is the permutation of rows and columns . in words",
    ", @xmath134 is the probability that two snp sites from the same cluster are detected correctly by majority voting , while @xmath147 is the probability that two snp sites from different clusters are detected inaccurately .",
    "evidently , @xmath134 and @xmath147 are closely related to the sequencing techniques , more precisely , the parameters @xmath9 , @xmath12 , and @xmath99 . in our case of unreliable paired - end sequencing , the explicit ways of calculating @xmath134 and @xmath147 are described as follows : @xmath148^i\\left[1-\\frac{2}{n(n-1)}\\right]^{m - i}\\sum_{l=\\lfloor i/2\\rfloor+1}^i{i\\choose l}[(1-p)^2+p^2]^l[2p(1-p)]^{i - l}\\right\\},\\nonumber\\end{aligned}\\ ] ] where @xmath149 is the probability of one particular read covering target snp sites @xmath93 and @xmath94 ; @xmath150 is the probability that a particular read observes the snps are the identical given the fact @xmath151 ; the second summation ranging from @xmath152 to @xmath13 represents for the majority voting among @xmath13 voters .",
    "analogously , we have @xmath153^i\\left[1-\\frac{2}{n(n-1)}\\right]^{m - i}\\sum_{l=\\lfloor i/2\\rfloor+1}^i{i\\choose l}[2p(1-p)]^l[(1-p)^2+p^2]^{i - l}\\right\\},\\nonumber\\end{aligned}\\ ] ] where @xmath154 is the probability that a particular read observes the snps are identical given the fact @xmath155 .",
    "neither @xmath134 or @xmath147 is straightforward to calculate , however , we could still seek a lower bound for @xmath134 and an upper bound for @xmath147 , to make a worse case discussion .    [",
    "lem : bounds ] for the choice of @xmath49 with sufficient large @xmath9 , there exist positive constants @xmath156 , @xmath157 , and @xmath158 , such that @xmath159\\ln n}{n-1},\\label{equ : alpha_bound}\\\\ \\beta   & \\leq \\frac{2\\kappa_1[2p(1-p)]\\ln n}{(n-1)(1-\\kappa_3^{-1})},\\label{equ : nbeta_bound}\\end{aligned}\\ ] ] where @xmath160 and @xmath161 .",
    "this lemma shows both @xmath134 and @xmath147 have @xmath162 scale bounds , and the proof is left in appendix  [ app : lemma1 ] .",
    "next , using this scale bound , we are ready to show the differences between eigenvectors of @xmath121 and @xmath135 are small , such that their signs are identical with high probability .      after revealing the relationship between adjacent matrix @xmath121 and planted model @xmath135",
    ", we move on to discover the difference between their eigenvectors , using matrix perturbation theory . to this end , we show that for our choices of @xmath134 and @xmath147 , the second eigenvector of @xmath121 has a vanishing perturbation compared to the one of @xmath135 .",
    "this observation provides a theoretical base to perform spectral partitioning on @xmath121 , instead of on @xmath135 , without much loss in performance .",
    "the classical matrix perturbation theory allows one to determine the sensitivity of the matrix eigenvalues and eigenvectors with respect to a slight influence .",
    "@xcite pioneers this area by providing a general bound for matrix eigenvalue perturbation , and the later work @xcite improves this bound , under further assumption to the matrices .",
    "meanwhile , the famous davis - kahan sin - theta theorem @xcite characterizes the rotation of eigenvectors after perturbation , and @xcite focuses on random matrices to propose a probabilistic sin - theta theorem .",
    "compared to those general results , the observed matrices in haplotype assembly problem always contain particular structures , for instance , independent and binary distributed entries , low rank , and etc . to this end , we follow the result from a recent perturbation study @xcite , which has a much tighter bound with respect to binary random matrices , summarized in a lemma as follows .",
    "[ lem : perturbation ] consider a square @xmath163 symmetric @xmath164-diagonal random matrix @xmath165 such that its elements @xmath166 are independent bernoulli random variables with parameters @xmath167=\\rho_{uv}\\chi n^{-1}$ ] , where @xmath168 are constants and @xmath169 .",
    "then , with probability at least @xmath170 , we have @xmath171)|\\leq o(\\chi^{1/2}),\\label{equ : thm_lambda}\\\\ & ||\\bm{v}_k(\\bm{m})-\\bm{v}_k(\\mathbb{e}[\\bm{m}])||\\leq o(\\chi^{-1/2}),\\label{equ : thm_v}\\end{aligned}\\ ] ] for any @xmath172 not larger than the rank of @xmath173 $ ] , where @xmath174 is the @xmath172-th largest eigenvalue of @xmath165 , and @xmath175 is the corresponding @xmath172-th eigenvector .",
    "back to the haplotype assembly problem , we utilize the lemma directly by considering @xmath165 as the adjacent matrix @xmath121 .",
    "note that @xmath121 is already a @xmath164-diagonal random matrix , with each entry independently distributed as bernoulli random variable .",
    "the parameters of these bernoulli distributions , i.e. , @xmath134 and @xmath147 , satisfy the scale constraints with @xmath176 , due to lemma  [ lem : bounds ] .",
    "moreover , note that @xmath177=\\pi(\\tilde{\\bm{b}})$ ] , where @xmath178 , and permutation @xmath146 does not change the eigenvectors .",
    "hence , from , we have @xmath179 .",
    "thus , we obtain latexmath:[\\ ] ] thus , the upper bound for @xmath147 is also @xmath162 scale .    a point to clarify is , in this proof , we have argued several times about `` large enough @xmath9 '' .",
    "one may concern that whether the particular choice of @xmath9 satisfying proof assumptions could match the practical requirement of haplotype assembly .",
    "in fact , for instance , we have @xmath441 in the simulation setup , then if simply choosing @xmath442 , and @xmath443 , the minimum value for @xmath9 to satisfy both assumptions and is given by @xmath444 which is quite smaller than the commonly accepted value in haplotype assembly . to this end ,",
    "our bounds hold well from the practical perspective ."
  ],
  "abstract_text": [
    "<S> this paper studies the haplotype assembly problem from an information theoretic perspective . </S>",
    "<S> a haplotype is a sequence of nucleotide bases on a chromosome , often conveniently represented by a binary string , that differ from the bases in the corresponding positions on the other chromosome in a homologous pair . </S>",
    "<S> information about the order of bases in a genome is readily inferred using short reads provided by high - throughput dna sequencing technologies . in this paper , </S>",
    "<S> the recovery of the target pair of haplotype sequences using short reads is rephrased as a joint source - channel coding problem . </S>",
    "<S> two messages , representing haplotypes and chromosome memberships of reads , are encoded and transmitted over a channel with erasures and errors , where the channel model reflects salient features of high - throughput sequencing . </S>",
    "<S> the focus of this paper is on the required number of reads for reliable haplotype reconstruction , and both the necessary and sufficient conditions are presented with order - wise optimal bounds . </S>"
  ]
}