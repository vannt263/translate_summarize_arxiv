{
  "article_text": [
    "binary multiplication is one of the most fundamental operations in digital electronics .",
    "multiplication complexity is usually measured by bit additions , assumed to have a unitary cost .",
    "consider the task of multiplying two @xmath0-bit numbers @xmath4 and @xmath5 by repeated accumulations and additions .",
    "if @xmath4 and @xmath5 are chosen randomly ( _ i.e. _ of expected hamming weight @xmath6 = @xmath7 ) their classical multiplication is expected to require @xmath8 additions of @xmath4 .",
    "the goal of this work is to decrease this work - factor by splitting @xmath5 and batch - processing its parts .",
    "the proposed algorithm is similar in spirit to common - multiplicand multiplication ( cmm ) techniques @xcite , @xcite , @xcite , @xcite .",
    "we first extend the exponent - folding technique @xcite , suggested for exponentiation , to multiplication .",
    "a similar approach has been tried in @xcite to fold the multiplier into halves . here",
    "we provide an efficient and generalized operand decomposition technique , consisting in a memory - efficient multiplier partitioning method and a fast combination method .",
    "for the sake of clarity , let us illustrate the method with a toy example .",
    "as the multiplicand @xmath4 is irrelevant in estimating the work - factor ( @xmath4 only contributes a multiplicative constant ) , @xmath4 will be omitted .",
    "let @xmath9 and @xmath10 .    for @xmath11 , set @xmath12 with @xmath13 iff @xmath14 and @xmath15 .",
    "that is , @xmath16 is the characteristic vector of the column @xmath17 in the 2 by @xmath2 array formed by @xmath18 and @xmath19 in parallel .",
    "hence ,    @xmath20    note that all of @xmath21 , @xmath22 , @xmath23 , and @xmath24 are bitwise mutually exclusive , or disjoint . all these characteristic vectors except @xmath21 can be visualized in a natural way as a venn diagram ( see fig . [ fig1 ] ) . hence",
    ", @xmath19 and @xmath18 can be represented as    @xmath25        now , the multiplication of @xmath4 by @xmath5 can be parallelized essentially by multiplying @xmath4 by @xmath22 , @xmath23 , and @xmath24 ; the final assembly of the results of these multiplications requires a few additions and shifts .",
    "namely ,    @xmath26    where @xmath27 can be performed by an @xmath28-bit left shift of @xmath29 .",
    "all these procedures are summarized in algorithm 1 .",
    "note that algorithm 1 eliminates the need of storage for characteristic vectors by combining the partitioning into characteristic vectors and the parallel evaluation of several @xmath30 computations .",
    "[ alg1 ] accumulate - and - add multiplication by operand - folding in half    1234561234123412341234= @xmath0-bit integers @xmath4 and @xmath31 , where @xmath32 = ( @xmath33 ) and @xmath34 + * output : * @xmath35 + 1 @xmath36 + 2 - 1 @xmath37 * to * @xmath38 * do * + 2 - 2 ( @xmath39 ) @xmath40 ( 00 ) + 2 - 3 @xmath41 @xmath42 @xmath43 + 2 - 4 @xmath4 @xmath42 @xmath44 + 3 - 1 @xmath45 @xmath42 @xmath45 + @xmath46 + 3 - 2 @xmath47 @xmath42 @xmath47 + @xmath46 + 4 @xmath48 @xmath42 ( @xmath49 ) + @xmath47    suppose that both @xmath4 and @xmath5 are @xmath0-bit integers and each @xmath32 is an @xmath50-bit integer . on average , the hamming weights of @xmath32 and @xmath16 are @xmath51 and @xmath52 , respectively . for evaluating @xmath53 ,",
    "algorithm 1 requires @xmath54 additions without taking into account shift operations into account .",
    "hence , performance improvement over classical accumulate - and - add multiplication is @xmath55 . in exchange ,",
    "algorithm 1 requires three additional temporary variables .",
    "let @xmath5 be an @xmath0-bit multiplier having the binary representation @xmath56 , _",
    "i.e. _ , @xmath57 where @xmath58 . by decomposing @xmath5 into @xmath59 parts ,",
    "@xmath5 is split into @xmath59 equal - sized substrings as @xmath60 , where each @xmath32 , represented as @xmath61 , is @xmath62-bits long .",
    "if @xmath0 is not a multiple of @xmath59 , then @xmath63 is left - padded with zeros to form an @xmath28-bit string .",
    "hence , @xmath64    by horner s rule , equation [ eq_horner ] can be rewritten as @xmath65    the problem is now reduced into the effective evaluation of the @xmath66 in advance , which is known as the common - multiplicand multiplication ( cmm ) problem .",
    "for example @xcite dealt with the case @xmath67 , and @xcite dealt with the case @xmath68 or possibly more . in this work we present a more general and efficient cmm method .",
    "as in the toy example above , the first step is the generation of @xmath69 disjoint characteristic vectors @xmath70 from the @xmath59 decomposed multipliers @xmath32 .",
    "each @xmath70 is @xmath28 bits long and of average hamming weight @xmath71 .",
    "note that , as in algorithm 1 , no additional storage for the characteristic vectors themselves is needed in the parallel computation of the @xmath72 s .",
    "the next step is the restoration of @xmath73 for @xmath74 using the evaluated values @xmath75 .",
    "the decremental combination method proposed in @xcite makes this step more efficient than other methods used in cmm . for notational convenience",
    ", @xmath76 can simply be denoted as @xmath77 by omission of zero runs on its left side , and @xmath78 can be denoted as @xmath79 where @xmath80 is the binary representation of a non - negative integer @xmath81 .",
    "then @xmath73 for @xmath82 can be computed by @xmath83    figure [ fig2 ] shows the combination process for a case @xmath68 with venn diagrams .    ]",
    "the last step is the application of horner s rule on the results obtained from the above step .",
    "the overall procedure to compute @xmath84 is given in algorithm 2 .",
    "note that algorithm 2 saves memory by recycling space for evaluated characteristic vectors , without use of temporary variables for @xmath85 .",
    "[ alg2 ] accumulate - and - add multiplication by generalized operand decomposition    1234561234123412341234= @xmath0-bit integers @xmath4 and @xmath86 , where @xmath32 = ( @xmath87 ) and",
    "@xmath88 + * output : * @xmath35 + 1 @xmath89 for all @xmath90 + 2 - 1 @xmath37 * to * @xmath38 * do * + 2 - 2 ( @xmath91 ) @xmath40 @xmath92 + 2 - 3 @xmath93 @xmath42 @xmath94 + 2 - 4 @xmath4 @xmath42 @xmath44 + 3 - 1 @xmath95 * down to * 1 * do * + 3 - 2 @xmath96 * to * @xmath97 * do * + 3 - 3 @xmath98 @xmath42 @xmath99 \\{@xmath98 corresponds to @xmath85 } + 3 - 4 @xmath100 @xmath42 @xmath101 + 4 - 1 @xmath48 @xmath42 @xmath102 + 4 - 2 @xmath103 * down to * 1 * do * + 4 - 3 @xmath48 @xmath42 @xmath104 + 4 - 4 @xmath48 @xmath42 @xmath105",
    "it is interesting to determine how the actual number of additions necessary to perform a multiplication decreases as parallelization increases . neglecting the additions required to recombine the parallelized results",
    ", the number of additions tends to zero as the degree of parallelism @xmath59 increases .",
    "the convergence is slow , namely :    @xmath106    since @xmath107 is required to avoid edge effects . in practice",
    "if the operand is split into an exponential number of sub - blocks ( actually @xmath108 ) the total hamming weight of the blocks will converge to zero .    to understand why things are so",
    ", we introduce the following tools :    let @xmath109 $ ] and @xmath110 then    @xmath111    more precisely , @xmath112 and    @xmath113    let @xmath5 have length @xmath114 and density @xmath115 , _",
    "i.e. _ weight @xmath116 .",
    "after performing the splitting process , we get three blocks , @xmath23 , @xmath22 and @xmath24 of length @xmath117 and respective densities @xmath110 for the first two and @xmath118 for @xmath24 .",
    "the total cost of a multiplication is now reduced from @xmath116 to    @xmath119    in other words , the gain of this basic operation is nothing but the hamming weight of @xmath24 :    @xmath120    graphically , the operation can be regarded as a tree with root @xmath5 , two nodes @xmath23 , @xmath22 and a leaf @xmath24 . the gain is the hamming weight of the leaf .    we will now show that by iterating this process an infinity of times , the total gain will converge to the hamming weight of @xmath5 .",
    "apply the splitting repeatedly to the nodes : this gives a binary tree having two nodes and one leaf at level one , and more generally @xmath121 nodes and @xmath122 leaves at level @xmath123 .",
    "the gain @xmath124 of this process is the sum of the weights of the @xmath125 leaves , that is :    @xmath126    as @xmath123 increases we get an infinite tree @xmath127 , a gain of    @xmath128    and a total weight of    @xmath129      we now apply the previous recursive iteration _ simultaneously _ ( in parallel ) to all leaves .",
    "note that each leaf from the previous step thereby gives rise to @xmath130 new leafs .",
    "in other words , neglecting edge effects we have @xmath131 .",
    "the last step consists in iterating the splitting process @xmath81 times and letting @xmath81 tend to infinity . by analogy to the calculations of the previous section the outcome is an extra gain of :    @xmath132    considering @xmath133 and letting @xmath134 , we get a total gain of :    @xmath135    thus a non - intuitive phenomenon occurs :    * although @xmath136 , eventually the complete ternary tree @xmath137 is covered , hence there are no pending leaves . * the sum of an exponential number of weights ( @xmath108 with @xmath138 ) tends to zero .",
    "the influence of truncation to a level @xmath139 is twofold :    * the recursive iterations @xmath140 are limited to @xmath95 , thus limiting the number of additional gains @xmath141 to @xmath142 . *",
    "each splitting process is itself limited to level @xmath59 , thus limiting each additional gain @xmath143 to @xmath144 .",
    "let us estimate these two effects :    @xmath145    @xmath146    but @xmath147    hence the global weight tends to zero like @xmath148 .",
    "accumulate - and - add multiplication performance is proportional to the number of additions required .",
    "hence , we analyze the performance of the proposed multiplication algorithm .    in step 2 , as the average hamming weight of each characteristic vector is @xmath71 , where @xmath88 , the number of additions needed to multiply @xmath4 by @xmath149 disjoint characteristic vectors in parallel is @xmath150 on average . in step 3 ,",
    "the computation of every @xmath85 by combination of the evaluated characteristic vectors requires the following number of additions : @xmath151    whereas the method used in @xcite requires @xmath152 additions . in step 4 , the completion of @xmath53 using horner s rule requires @xmath153 additions .",
    "therefore , the total number of additions needed to perform the proposed algorithm is on average equal to : @xmath154 on the other hand , @xmath155 in the worst case .    .optimal",
    "@xmath59 for @xmath156 as a function of @xmath0 [ cols=\"^,^,^,^\",options=\"header \" , ]     performance improvement over the classical accumulate - and - add multiplication algorithm is asymptotically :    @xmath157    larger @xmath59 values do not necessarily guarantee the better performance , because the term @xmath158 increases exponentially with @xmath59 .",
    "thus , a careful choice of @xmath59 is required .",
    "the analysis of @xmath159 for usual multiplier sizes @xmath0 yields optimal @xmath59 values that minimize @xmath159 .",
    "the optimal @xmath59 values as a function of @xmath0 are given in table [ tab1 ] .",
    "table [ tab1 ] also includes comparisons with the classical algorithm for the both the case and the worst cases .    in modern public key cryptosystems , @xmath0",
    "is commonly chosen between 1024 and 2048 .",
    "this corresponds to the optimum @xmath160 _ i.e. _ an 2.011 to 2.260 performance improvement over the classical algorithm and 1.340 to 1.560 improvement over the canonical signed digit multiplication algorithm @xcite where the minimal hamming weight of is @xmath161 on the average .",
    "on the other hand , the proposed algorithm requires storing @xmath162 temporary variables , which correspond to @xmath163-bit memory . whenever @xmath164 , although optimal performance is not guaranteed , the new algorithm is still faster than both classical and canonical multiplication .    100    yen , s .- m . , and laih , c .- s . , common - multiplicand multiplication and its applications to public key cryptography , _ electron .",
    "_ , 1993 , 29(17 ) , pp . 15831584",
    ".    wu , t .- c . , and chang , y .- s .",
    ", improved generalisation common - multiplicand multiplications algorithm of yen and laih , _ electron .",
    "_ , 1995 , 31(20 ) , pp",
    ". 17381739 .    s.  yen , improved common - multiplicand multiplication and fast exponentiation by exponent decomposition , _ ieice trans .",
    "fundamentals _ , 1997 , e80-a(6 ) , pp",
    ". 11601163 .    c.  ko and s.  johnson , multiplication of signed - digit numbers , _ electron .",
    "lett . _ , 1994 , 30(11 ) , pp .",
    "840841 .",
    "d.  lou , and c.  chang , fast exponentiation method obtained by folding the exponent in half , _ electron .",
    "lett . _ , 1996 , 32(11 ) , pp . 984985 .",
    "chung , b. , hur , j. , kim , h. , hong , s .-",
    "m . , and yoon , h. , improved batch exponentiation , _ submitted to inform . process .",
    "lett _ , nov . 2005 .",
    "+    arno , s. , and wheeler , f.s . , signed digit repersentations of minimal hamming weight , _ ieee trans . computers _",
    ", 1993 , 42(8 ) , pp .",
    "....      entity mult_entity is      generic(constant m : natural : = 32 ;              constant k   : natural : = 2 ) ;      port(a : in std_logic_vector ( m-1 downto 0 ) ;           b : in std_logic_vector ( m-1 downto 0 ) ;          c : out std_logic_vector(2*m-1 downto 0 ) ) ;    end mult_entity ; architecture behavioral of mult_entity is      signal n : natural : = m+k-1/k ;      signal input_length : natural : = n*k ;      signal output_length : natural : = 2*input_length ;      signal c_temp : std_logic_vector(2*input_length-1 downto 0 ) ;      signal c_parts_length : natural : = input_length+n ;      signal a_temp : std_logic_vector(c_parts_length-1 downto 0 ) ;      signal b_value : integer ;      type bx_type is array ( k downto 1 ) of std_logic_vector(n-1 downto 0 ) ;      signal bx : bx_type ;      signal cx_count : natural : = 2**k-1 ;      type cx_type is array ( cx_count downto 1 ) of std_logic_vector(c_parts_length-1 downto 0 ) ;      signal cx : cx_type ;      for i in 1 to k-1 loop bx(i)(n-1 downto 0 ) < = b(i*n-1 downto ( i-1)*n ) ; end loop ;      bx(k)(m-(n*(k-1))-1 downto 0 ) < = b(m-1 downto m - n*(k-1 ) ) ; if ( ( m mod k)>0 ) then bx(k)((n-1 ) downto ( n-1-(m mod k ) ) ) < = \" 0 \" ; end if ; a_temp ( m-1 downto 0 ) < = a ; a_temp ( c_parts_length-1 downto m ) < = \" 0 \" ;    --step 1 for i in 1 to 2**k-1 loop cx(i ) < = \" 0 \" ; end loop ; --step 2 - 1 for i in 0 to n-1 loop      b_value < = 0 ;      for j in 1 to k loop          if ( ( bx(j)(i))='1 ' ) then b_value < = b_value + 2**(j-1 ) ; end if ;      end loop ; --steps 2 - 2 and 2 - 3      if ( b_value>0 ) then cx ( b_value ) < = cx ( b_value ) + a_temp ; end if ; --step 2 - 4      a_temp < = a_temp(c_parts_length-2 downto 0)&\"0 \" ; end loop ;    --step 3 - 1 for i in k downto 1 loop --step 3 - 2    for j in 1 to 2**(i-1)-1 loop --step 3 - 3      cx(2**(i-1 ) ) < = ( cx(2**(i-1 ) ) + cx(2**(i-1)+j ) ) ; --step 3 - 4      cx(j ) < = ( cx(j ) + cx(2**(i-1)+j ) ) ;    end loop ; end loop ; --step 4 - 1 c_temp ( c_parts_length-1 downto 0 ) < = cx(2**(k-1 ) ) ; c_temp ( n-1 downto c_parts_length-1 ) < = \" 0 \" ; --step 4 - 2 for i in k-1 downto 1 loop --step 4 - 3      c_temp < = c_temp(2*m-1-n downto 0 ) & \" 0 \" ; --step 4 - 4      c_temp",
    "< = c_temp + cx(2**(i-1 ) ) ; end loop ;"
  ],
  "abstract_text": [
    "<S> this paper describes a new accumulate - and - add multiplication algorithm . </S>",
    "<S> the method partitions one of the operands and re - combines the results of computations done with each of the partitions . </S>",
    "<S> the resulting design turns - out to be both compact and fast .    </S>",
    "<S> when the operands bit - length @xmath0 is 1024 , the new algorithm requires only @xmath1 additions ( on average ) , this is about half the number of additions required by the classical accumulate - and - add multiplication algorithm ( @xmath2 ) .    </S>",
    "<S> thefnmarkfootnotetext@xmath3 most of the work has been done while this author was working at the max - planck institut fr mathematik ( mpim bonn , germany ) </S>"
  ]
}