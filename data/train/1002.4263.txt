{
  "article_text": [
    "many modern communication channels are modeled as a gaussian multiple - input multiple - output ( mimo ) channel .",
    "examples include multi - tone digital subscriber line ( dsl ) , orthogonal frequency division multiplexing ( ofdm ) and multiple transmit - receive antenna systems .",
    "it is known that the capacity of the gaussian mimo channel is achieved by beamforming a _ gaussian input alphabet _ along the right singular vectors of the mimo channel .",
    "the received vector is projected along the left singular vectors , resulting in a set of parallel gaussian subchannels .",
    "optimal power allocation between the subchannels is achieved by waterfilling @xcite . in practice",
    ", the input alphabet is _ not gaussian _ and is generally chosen from a finite signal set .",
    "we distinguish between two kinds of mimo channels : _ i _ ) _ diagonal _ ( or parallel ) channels and _ ii _ ) _ non - diagonal _ channels .    for a diagonal mimo channel with discrete input alphabets , assuming only power allocation on each subchannel ( i.e. , a diagonal precoder ) , mercury / waterfilling was shown to be optimal by lozano _",
    "_ in @xcite . with discrete input alphabets , cruz _",
    "later proved in @xcite that the optimal precoder is , however , non - diagonal , i.e. , precoding needs to be performed across all the subchannels .    for a general non - diagonal gaussian mimo channel ,",
    "it was also shown in @xcite that the optimal precoder is non - diagonal .",
    "such an optimal precoder is given by a fixed point equation , which requires a high complexity numeric evaluation .",
    "since the precoder jointly codes all the @xmath1 inputs , joint decoding is also required at the receiver .",
    "thus , the decoding complexity can be very high , specially for large @xmath1 , as in the case of dsl and ofdm applications .",
    "this motivates our quest for a practical low complexity precoding scheme achieving near optimal capacity .    in this paper",
    ", we consider a general mimo channel and a non - diagonal precoder based on x - codes @xcite .",
    "the mimo channel is transformed into a set of parallel subchannels using singular value decomposition ( svd ) and x - codes are then used to pair the subchannels .",
    "x - codes are fully characterized by the pairings and the 2-dimensional real rotation matrices for each pair .",
    "these rotation matrices are parameterized with a single angle .",
    "this precoding structure enables us to express the total mutual information as a sum of the mutual information of all the pairs .",
    "the problem of finding the optimal precoder with the above structure , which maximizes the total mutual information , can be split into two tractable problems : _ i _ ) optimizing the rotation angle and the power allocation within each pair and _ ii _ ) finding the optimal pairing and power allocation among the pairs .",
    "it is shown by simulation that the mutual information achieved with the proposed pairing scheme is very close to that achieved with the optimal precoder in @xcite , and is significantly better than the mercury / waterfilling strategy in @xcite .",
    "our approach greatly simplifies both the precoder optimization and the detection complexity , making it suitable for practical applications .",
    "the rest of the paper is organized as follows .",
    "section  [ smprecoding ] introduces the system model and svd precoding . in section  [ optimalprecoding ] ,",
    "we provide a brief review of the optimal precoding with discrete inputs in @xcite and the relevant mimo capacity . in section  [ precodingx ] , we present the precoding using x - codes with discrete inputs and the relevant capacity expressions . in section  [ two_subch ]",
    ", we consider the first problem , which is to find the optimal rotation angle and power allocation for a given pair .",
    "this problem is equivalent to optimizing the mutual information for a gaussian mimo channel with two subchannels . in section [ multi_subch ] , using the results from section [ two_subch ] , we attempt to optimize the mutual information for a gaussian mimo channel with @xmath1 subchannels , where @xmath2 .",
    "conclusions are drawn in section  [ conclusions].finally , in section [ sec_ofdm ] we discuss the application of our precoding to ofdm systems .",
    "_ notations _ : the field of complex numbers is denoted by @xmath3 and let @xmath4 be the positive real numbers .",
    "superscripts @xmath5 and @xmath6 denote transposition and hermitian transposition , respectively . the @xmath7 identity matrix is denoted by @xmath8 , and the zero matrix is denoted by @xmath9 .",
    "the @xmath10 $ ] is the expectation operator , @xmath11 denotes the euclidean norm of a vector , and @xmath12 the frobenius norm of a matrix .",
    "finally , we let @xmath13 be the trace of a matrix .",
    "we consider a @xmath14 mimo channel , where the channel state information ( csi ) is known perfectly at both transmitter and receiver .",
    "let @xmath15 be the vector of input symbols to the channel , and let @xmath16 , @xmath17 , @xmath18 , be a full rank @xmath19 channel coefficient matrix , with @xmath20 representing the complex channel gain between the @xmath21-th input symbol and the @xmath22-th output symbol .",
    "the vector of @xmath23 channel output symbols is given by @xmath24 where @xmath25 is an uncorrelated gaussian noise vector , such that @xmath26= { \\bf i}_{n_r}$ ] , and @xmath27 is the total transmitted power .",
    "the power constraint is given by @xmath28 = 1\\ ] ] the maximum multiplexing gain of this channel is @xmath29 .",
    "let @xmath30 be the vector of @xmath1 information symbols to be sent through the mimo channel , with @xmath31 = 1 , i = 1 , \\cdots , n$ ] .",
    "then the vector @xmath32 can be precoded using a @xmath33 matrix @xmath34 , resulting in @xmath35 .",
    "the capacity of the deterministic gaussian mimo channel is then achieved by solving    [ cap_gaussian ] @xmath36    where @xmath37 is the mutual information between @xmath38 and @xmath39 , and @xmath40 $ ] , @xmath41 $ ] are the covariance matrices of @xmath38 and @xmath32 respectively .",
    "the inequality in ( [ cap_gaussian_mimo ] ) follows from the data processing inequality @xcite .",
    "let us consider the singular value decomposition ( svd ) of the channel @xmath42 , where @xmath43 , @xmath44 , @xmath45 , @xmath46 , and @xmath47 with @xmath48 .",
    "telatar showed in @xcite that the gaussian mimo capacity @xmath49 , is achieved when @xmath38 is gaussian distributed and @xmath50 is diagonal .",
    "diagonal @xmath50 can be achieved by using the optimal precoder matrix @xmath51 , where @xmath52 is the diagonal power allocation matrix such that @xmath53 .",
    "furthermore , @xmath54 , are i.i.d .",
    "gaussian ( i.e. , _ no coding is required across the input symbols @xmath55 _ ) . with this , the second line of ( [ cap_gaussian_mimo ] ) is actually an equality .",
    "also , projecting the received vector @xmath39 along the columns of @xmath56 is information lossless and transforms the non - diagonal mimo channel into an equivalent diagonal channel with @xmath1 non - interfering subchannels .",
    "the equivalent diagonal system model is then given by @xmath57 where @xmath58 is the equivalent noise vector , and has the same statistics as @xmath25 .",
    "the total mutual information is now given by @xmath59 note that now the mutual information is a function of only the power allocation matrix @xmath60 diag@xmath61 , with the constraint tr@xmath62 .",
    "optimal power allocation is achieved through waterfilling between the @xmath1 parallel channels of the equivalent system in ( [ eq_diag_model_ch6 ] ) @xcite .",
    "in practice , discrete input alphabets are used .",
    "subsequently , we assume that the @xmath22-th information symbol is given by @xmath63 , where @xmath64 is a finite signal set .",
    "let @xmath65 be the overall input alphabet .",
    "the capacity of the gaussian mimo channel with discrete input alphabet @xmath66 is defined by the following problem    [ cap_discrete ] @xmath67    note that there is no maximization over the pdf of @xmath32 , since we fix @xmath68 .",
    "the optimal precoder @xmath69 , which solves problem [ cap_discrete ] , is given by the following fixed point equation given in @xcite @xmath70 where @xmath71 is the minimum mean - square error ( mmse ) matrix of @xmath32 given by @xmath72 )   ( { \\bf u } - { { \\mathbb e}}[{\\bf u}|{\\bf y}])^\\dag   ] \\ ] ] the optimal precoder is derived using the relation between mmse and mutual information @xcite .",
    "we observe that , with discrete input alphabets , it is no longer optimal to beamform along the column vectors of @xmath73 and then use waterfilling on the parallel subchannels .",
    "even when @xmath74 is diagonal ( parallel non - interfering subchannels ) , the optimal precoder @xmath69 is _ non diagonal _ , and can be computed numerically ( using a gradient based method ) as discussed in @xcite . however , the complexity of computing @xmath69 is prohibitively high for practical applications , especially when @xmath1 is large and/or the channel changes frequently .",
    "we propose a suboptimal precoding scheme based on x - codes @xcite , which achieves close to the optimal capacity @xmath75 , at low encoding and decoding complexities .",
    "x - codes are based on a pairing of @xmath1 subchannels @xmath76\\times [ 1,n ] , i_k < j_k , k = 1 , \\ldots n/2 \\}$ ] . for a given @xmath1 ,",
    "there are @xmath77 possible pairings .",
    "let @xmath78 denote the set of all possible pairings .",
    "for example , with @xmath79 , we have @xmath80    x - codes are generated by a @xmath81 real orthogonal matrix , denoted by @xmath82 .",
    "when precoding with x - codes , the precoder matrix is given by @xmath83 , where @xmath84 is the diagonal power allocation matrix such that @xmath53 .",
    "the @xmath85-th pair consists of subchannels @xmath86 and @xmath87 . for the @xmath85-th pair ,",
    "the information symbols @xmath88 and @xmath89 are jointly coded using a @xmath90 real orthogonal matrix @xmath91 given by @xmath92 \\ \\ \\",
    "k=1,\\ldots n/2\\ ] ] the angle @xmath93 can be chosen to maximize the mutual information for the @xmath85-th pair .",
    "each @xmath91 is a submatrix of the code matrix @xmath94 as shown below @xmath95 it was shown in @xcite that , for achieving the best diversity gain , an optimal pairing is one in which the @xmath85-th subchannel is paired with the @xmath96-th subchannel .",
    "for example , with this pairing and @xmath1 = @xmath97 , the x - code generator matrix is given by @xmath98\\ ] ] the special case with @xmath99 , results in no coding across subchannels .    given the generator matrix @xmath82 , the subchannel gains @xmath100 , and the power allocation matrix @xmath101 , the mutual information between @xmath32 and @xmath39 is given by @xmath102 where the received vector pdf is given by @xmath103 and when @xmath104 ( i.e. , @xmath105 ) , it is equivalently given by @xmath106 where @xmath107 .",
    "we next define the capacity of the mimo gaussian channel when precoding with @xmath82 . in the following , we assume that @xmath105 , so that @xmath108 . note that , when @xmath109 , the receiver processing @xmath110 becomes information lossy , and @xmath111 .",
    "we introduce the following definitions . for a given pairing @xmath112 ,",
    "let @xmath113 , @xmath114 , @xmath115 , @xmath116 and @xmath117 .",
    "due to the pairing structure of @xmath82 the mutual information @xmath118 can be expressed as the sum of mutual information of all the @xmath119 pairs as follows : @xmath120    having fixed the precoder structure to @xmath83 , we can formulate the following    [ cap_discrete_xcoded ] @xmath121    it is clear that the solution of the above problem is still a formidable task , although it is simpler than problem [ cap_discrete ] .",
    "in fact , instead of the @xmath7 variables of @xmath34 , we now deal with @xmath1 variables for power allocation in @xmath101 , @xmath119 variables for the angles defining @xmath91 , and the pairing @xmath122 . in the following",
    ", we will show how to efficiently solve problem [ cap_discrete_xcoded ] by splitting it into two simpler problems .",
    "power allocation can be divided into power allocation among the @xmath119 pairs , followed by power allocation between the two subchannels of each pair .",
    "let @xmath123 be a diagonal matrix , where @xmath124 with @xmath125 being the power allocated to the @xmath85-th pair .",
    "the power allocation within each pair can be simply expressed in terms of the fraction @xmath126 of the power assigned to the first subchannel of the pair .",
    "the mutual information achieved by the @xmath85-th pair is then given by @xmath127 where @xmath128 is given by @xmath129 where @xmath130 and @xmath91 is given by ( [ akmat ] ) .    the capacity of the discrete input mimo gaussian channel when precoding with x - codes can be expressed as    [ capxcodesapprox ] @xmath131    where @xmath132 , the capacity of the @xmath85-th pair in the pairing @xmath112 , is achieved by solving    [ capxcodes_pair ] @xmath133    in other words , we have split problem [ cap_discrete_xcoded ] into two different simpler problems .",
    "firstly , given a pairing @xmath112 and power allocation between pairs @xmath134 , we can solve problem [ capxcodes_pair ] for each @xmath135 .",
    "problem [ capxcodesapprox ] uses the solution to problem [ capxcodes_pair ] to find the optimal pairing @xmath136 and the optimal power allocation @xmath137 between the @xmath119 pairs . for small @xmath1 , the optimal pairing and power allocation between pairs",
    "can always be computed numerically and by brute force enumeration of all possible pairings .",
    "this is , however , prohibitively complex for large @xmath1 , and we shall discuss heuristic approaches in section [ multi_subch ] .",
    "we will show in the following that , although suboptimal , precoding with x - codes will provide a close to optimal capacity with the additional benefit that the detection complexity at the receiver is highly reduced , since there is coupling only between pairs of channels , as compared to the case of full - coupling for the optimal precoder in @xcite .    in the next section ,",
    "we solve problem [ capxcodes_pair ] , which is equivalent to finding the optimal rotation angle and power allocation for a gaussian mimo channel with only @xmath138 subchannels .",
    "with @xmath138 , there is only one pair and only one possible pairing .",
    "therefore , we drop the subscript @xmath85 in problem [ capxcodes_pair ] and we find @xmath139 in problem [ cap_discrete_xcoded ] . the processed received vector @xmath140 is given by @xmath141 where @xmath142 is the equivalent noise vector with the same statistics as @xmath25 .",
    "let @xmath143 be the overall channel power gain and @xmath144 be the _ condition number _ of the channel .",
    "then ( [ rxn2 ] ) can be re - written as @xmath145 where @xmath146 and @xmath147 .",
    "the equivalent channel @xmath148 now has a gain of @xmath149 , and its channel gains are dependent only upon @xmath150 .",
    "our goal is , therefore , to find the optimal rotation angle @xmath151 and the fractional power allocation @xmath152 , which maximize the mutual information of the equivalent channel with condition number @xmath150 and gain @xmath153 .",
    "the total available transmit power is now @xmath154 .",
    "it is difficult to get analytic expressions for the optimal @xmath151 and @xmath152 , and therefore we can use numerical techniques to evaluate them and store them in lookup tables to be used at run time . for a given application scenario , given the distribution of @xmath150 , we decide upon a few discrete values of @xmath150 which are representative of the actual values observed in real channels .",
    "for each such quantized value of @xmath150 , we numerically compute a table of the optimal values @xmath152 and @xmath151 as a function of @xmath154 .",
    "these tables are constructed offline . during the process of communication",
    ", the transmitter knows the value of @xmath155 and @xmath150 from channel measurements .",
    "it then finds the lookup table with the closest value of @xmath150 to the measured one .",
    "the optimal values @xmath152 and @xmath151 are then found by indexing the appropriate entry in the table with @xmath154 equal to @xmath156 .    in fig .",
    "[ palloc_frac ] , we graphically plot the optimal power fraction @xmath157 to be allocated to the stronger channel in the pair , as a function of @xmath27 . the input alphabet is 16-qam and @xmath158 . for @xmath159 ,",
    "both channels have equal gains , and therefore , as expected , the optimal power allocation is to divide power equally between the two subchannels .",
    "however with increasing @xmath150 , the power allocation becomes more asymmetrical .",
    "it is observed that at low @xmath27 it is optimal to allocate all power to the stronger channel . at high @xmath27",
    "the opposite is true , and it is the weaker channel which gets most of the power . for a fixed @xmath150 , as @xmath27 increases , the power allocated to the stronger channel",
    "is shifted to the weaker channel .",
    "for a fixed @xmath27 , a higher fraction of the total power is allocated to the weaker channel with increasing @xmath150 . in the high @xmath27 regime , these results are in contrast with the waterfilling scheme , where almost all subchannels are allocated equal power .    in fig .",
    "[ palloc_theta ] , the optimal rotation angle @xmath160 is plotted as a function of @xmath27 .",
    "the input alphabet is 16-qam and @xmath161 . for @xmath159",
    "the mutual information is independent of @xmath162 for all values of @xmath27 . for @xmath163 ,",
    "the optimal rotation angle is almost invariant to @xmath27 . for larger @xmath150 ,",
    "the optimal rotation angle varies with @xmath27 and approximately ranges between @xmath164 for all @xmath27 values of interest .",
    "[ mi_vs_pfrac_17db_16qam ] shows the variation of the mutual information with the power fraction @xmath165 for @xmath166 .",
    "the power @xmath27 is fixed at 17 db and the input alphabet is 16-qam .",
    "we observe that for all values of @xmath150 , the mutual information is a concave function of @xmath165 .",
    "we also observe that the sensitivity of the mutual information to variation in @xmath165 increases with increasing @xmath150 .",
    "however , for all @xmath150 , the mutual information is fairly stable ( has a `` plateau '' ) around the optimal power fraction .",
    "this is good for practical implementation , since this implies that an error in choosing the correct power allocation would result in a very small loss in the achieved mutual information .    in fig .",
    "[ mi_vs_theta_17db_16qam ] , we plot the variation of the mutual information w.r.t . the rotation angle @xmath162 .",
    "the power @xmath27 is fixed at 17 db and the input alphabet is 16-qam . for @xmath159 ,",
    "the mutual information is obviously constant with @xmath162 . with increasing @xmath150 , mutual information",
    "is observed to be increasingly sensitive to @xmath162 .",
    "however , when compared with fig .",
    "[ mi_vs_pfrac_17db_16qam ] , it can also be seen that the mutual information appears to be more sensitive to the power allocation fraction @xmath165 , than to @xmath162 .    in fig .",
    "[ thetavar_4qam ] , we plot the mutual information of x - codes for different rotation angles with @xmath166 and @xmath167 . for each rotation angle , the power allocation is optimized numerically .",
    "we observe that , the mutual information is quite sensitive to the rotation angle except in the range 30 - 40@xmath168 .",
    "we next present some simulation results to show that indeed our simple precoding scheme can significantly increase the mutual information , compared to the case of no precoding across subchannels ( i.e. , mercury / waterfilling ) .",
    "for the sake of comparison , we also present the mutual information achieved by the waterfilling scheme with discrete input alphabets .",
    "we restrict the discrete input alphabets @xmath169 , to be square @xmath170-qam alphabets consisting of two @xmath171-pam alphabets in quadrature .",
    "mutual information is evaluated by solving problem [ capxcodes_pair ] ( i.e. , numerically maximizing w.r.t .",
    "the rotation angle and power allocation ) .    in fig .",
    "[ beta2_4_16qam ] , we plot the maximal mutual information versus @xmath27 , for a system with two subchannels , @xmath172 and @xmath166 . mutual information is plotted for 4- and 16-qam signal sets .",
    "it is observed that for a given achievable mutual information , coding across subchannels is more power efficient .",
    "for example , with 4-qam and an achievable mutual information of @xmath173 bits , x - codes require only @xmath174 db more transmit power when compared to the ideal gaussian signalling with waterfilling .",
    "this gap increases to @xmath175 db for mercury / waterfilling and @xmath176 db for the waterfilling scheme with @xmath177-qam as the input alphabet .",
    "a similar trend is observed with @xmath178-qam as the input alphabet .",
    "the proposed precoder clearly performs better , since the mutual information is optimized w.r.t . the rotation angle @xmath162 and power allocation , while mercury / waterfilling , as a special case of x - code",
    ", only optimizes power allocation and fixes @xmath179 .    in fig .",
    "[ beta124_4qam ] , we compare the mutual information achieved by x - codes and the mercury / waterfilling strategy for @xmath166 and @xmath180 . the input alphabet is @xmath177-qam .",
    "it is observed that both the schemes have the same mutual information when @xmath159 .",
    "however with increasing @xmath150 , the mutual information of mercury / waterfilling strategy is observed to degrade significantly at high @xmath27 , whereas the performance of x - codes does not vary as much .",
    "the degradation of mutual information for the mercury / waterfilling strategy is explained as follows . for the mercury / waterfilling strategy , with increasing @xmath150 ,",
    "all the available power is allocated to the stronger channel till a certain transmit power threshold .",
    "however , since finite signal sets are used , mutual information is bounded from above until the transmit power exceeds this threshold .",
    "this also explains the reason for the intermediate change of slope in the mutual information curve with @xmath181 ( see the rightmost curve in fig .  [ beta124_4qam ] ) . on the other hand , due to coding across subchannels",
    ", this problem does not arise when precoding with x - codes .",
    "therefore , in terms of achievable mutual information , rotation coding is observed to be more robust to ill - conditioned channels .    for low values of @xmath27 , mutual information of",
    "both the schemes are similar , and improves with increasing @xmath150 .",
    "this is due to the fact that , at low @xmath27 , mutual information increases linearly with @xmath27 , and therefore all power is assigned to the stronger channel . with increasing @xmath150 , the stronger channel has an increasing fraction of the total channel gain , which results in increased mutual information .    in fig .",
    "[ beta1248_16qam ] , the mutual information with x - codes is plotted for @xmath182 and with 16-qam as the input alphabet . it is observed that at low values of @xmath27 , a higher value of @xmath150 is favorable .",
    "however at high @xmath27 , with 16-qam input alphabets , the performance degrades with increasing @xmath150 .",
    "this degradation is more significant compared to the degradation observed with 4-qam input alphabets .",
    "therefore it can be concluded that the mutual information is more sensitive to @xmath150 with 16-qam input alphabets as compared to 4-qam .",
    "we now consider the problem of finding the optimal pairing and power allocation between pairs for different gaussian mimo channels with even @xmath1 and @xmath183 .",
    "we first observe that mutual information is indeed sensitive to the chosen pairing , and this therefore justifies the criticality of computing the optimal pairing .",
    "this is illustrated through fig .",
    "[ n4pair ] , for @xmath79 with a diagonal channel @xmath184 and 16-qam .",
    "optimal power allocation between the two pairs is computed numerically .",
    "it is observed that the pairing @xmath185 performs significantly better than the pairing @xmath186 .    in fig .",
    "[ cruz_cmp ] , we compare the mutual information achieved with optimal precoding @xcite , to that achieved by the proposed precoder with 4-qam input alphabet",
    ". the @xmath187 full channel matrix ( non - diagonal channel ) is given by ( 42 ) in @xcite .",
    "for x - codes , the optimal pairing is @xmath185 and the optimal power allocation between the pairs is computed numerically .",
    "it is observed that x - codes perform very close to the optimal precoding scheme .",
    "specifically , for an achievable mutual information of 6 bits , compared to the optimal precoder @xcite , x - codes need only 0.4db extra power whereas 2.3db extra power is required with mercury / waterfilling .",
    "another application is in wireless mimo channels with perfect channel state information at both the transmitter and receiver .",
    "the channel coefficients are modeled as i.i.d complex normal random variables with unit variance .    in fig .",
    "[ mimo_ergodic_cap ] , we plot the ergodic capacity ( i.e. , the mutual information averaged over channel realizations ) for a @xmath187 wireless mimo channel . for x - codes , the best pairing and power allocation between pairs are chosen numerically using the optimal @xmath162 and power fraction tables created offline . it is observed that at high @xmath27 , simple rotation based coding using x - codes improves the mutual information significantly , when compared to mercury / waterfilling .",
    "for example , for a target mutual information of 12 bits , x - codes perform 1.2db away from the idealistic gaussian signalling scheme . this gap from the gaussian signalling scheme increases to 3.1db for the mercury / waterfilling scheme and to 4.4db for the waterfilling scheme with 16-qam alphabets .    in this application scenario",
    "the low complexity of our precoding scheme becomes an essential feature , since the precoder can be computed on the fly using the look - up tables for each channel realization .",
    "in ofdm applications , @xmath1 is large and problem [ capxcodesapprox ] becomes too complex to solve , since we can no more find the optimal pairing by enumeration .",
    "it was observed in section [ two_subch ] , that for @xmath138 , a larger value of the condition number @xmath150 leads to a higher mutual information at low values of @xmath27 ( low snr ) .",
    "therefore , we conjecture that pairing the @xmath85-th subchannel with the @xmath188-th subchannel could have mutual information very close to optimal , since this pairing scheme attempts to maximize the minimum @xmath150 among all pairs . we shall call this scheme the `` conjectured '' pairing scheme , and the x - code scheme , which pairs the @xmath85-th with the @xmath189-th subchannel , the  x - pairing \" scheme .",
    "note that the `` x - pairing '' scheme was proposed in @xcite as a scheme which achieved the optimal diversity gain when precoding with x - codes .    given a pairing of subchannels ,",
    "it is also difficult to compute the optimal power allocation between pairs @xmath134 .",
    "however , it was observed that for channels with large @xmath1 , even waterfilling power allocation between the pairs ( with @xmath190 as the channel gain of the @xmath85-th pair ) results in good performance .",
    "apart from the `` conjectured '' and the `` x - pairing '' schemes , we propose the following scheme which is based on the  hungarian \" assignment algorithm @xcite and which attempts to find a good approximation to the optimal pairing .",
    "we shall call this as the  hungarian \" pairing scheme . before describing the `` hungarian '' pairing scheme",
    ", we briefly review the hungarian assignment problem as follows .",
    "consider @xmath191 different workers and @xmath191 different jobs that have to be completed .",
    "also let @xmath192 be the cost involved when the @xmath22-th worker is assigned to the @xmath21-th job .",
    "we can therefore think of a cost matrix , whose @xmath193-th entry has the value @xmath192 .",
    "the hungarian assignment problem , is to then find the optimal assignment of workers to jobs ( each worker getting assigned to exactly one job ) such that the total cost of getting all the jobs completed is minimized .",
    "it is easy to see , that a maximization job assignment problem could be posed into a minimization problem and vice versa .    to find a good approximation to the optimal pairing",
    ", we split the @xmath1 subchannels into two groups _",
    "i ) _ group - i : subchannels 1 to @xmath119 , with the @xmath21-th subchannel in the role of the @xmath21-th job ( @xmath194 ) , _ ii ) _ group - ii : subchannels @xmath195 to @xmath1 , with the @xmath196-th subchannel in the role of the @xmath22-th worker ( @xmath197 ) . therefore , there are @xmath119 workers and jobs .    for a given snr @xmath27 , we initially assume uniform power allocation between all pairs and therefore assign a power of @xmath198 to each pair .",
    "the value of @xmath192 is evaluated by finding the optimal mutual information achieved by an equivalent @xmath199 channel with the @xmath200-th and the @xmath21-th subchannels as its two subchannels .",
    "this can be obtained by first choosing a table ( see section [ two_subch ] ) with the closest value of @xmath150 to the given @xmath201 , and then indexing the appropriate entry into the table with snr=@xmath202 .",
    "the hungarian algorithm then finds the pairing with the highest mutual information .",
    "power allocation between the pairs is then achieved through the waterfilling scheme .",
    "it was observed through monte - carlo simulations that , even uniform power allocation between the subchannels results in almost same mutual information as achieved through waterfilling between pairs .",
    "this can be explained from the fact that by separating into a group of stronger ( group - i ) and a group of weaker channels ( group - ii ) , any pairing would result in all pairs having almost the same channel gain @xmath203 .",
    "this therefore implies that the optimal power allocation scheme would allocate nearly equal power to all pairs , which both the uniform and the waterfilling schemes would also do .",
    "henceforth , it can be conjectured that with the proposed separation of subchannels into 2 groups , both the uniform and the waterfilling power allocation schemes would have close to optimal performance , and any further improvement in mutual information by optimizing the power allocation would be minimal .",
    "this also supports the initial usage of uniform power @xmath198 to compute the entries @xmath192 before executing the hungarian algorithm .",
    "furthermore , the computational complexity of the hungarian algorithm is @xmath204 and is therefore practically feasible .    to study the sensitivity of the mutual information to the pairing of subchannels",
    ", we also consider a `` random '' pairing scheme . in the  random \" pairing scheme ,",
    "we first choose a large number ( @xmath205 50 ) of random pairings .",
    "for each chosen random pairing we evaluate the mutual information ( through monte - carlo simulations ) with waterfilling power allocation between pairs . finally the average mutual information is computed .",
    "this gives us insight into the mean value of the mutual information w.r.t .",
    "it would also help us in quantifying the effectiveness of the heuristic pairing schemes discussed above .",
    "we next illustrate the mutual information achieved by these heuristic schemes for an ofdm system with @xmath206 subchannels and 16-qam .",
    "the channel impulse response is @xmath207 $ ] .",
    "for the  conjectured \" and the  x - pairing \" schemes also , power allocation is achieved through waterfilling between the pairs .    in fig .",
    "[ ofdm_ex_1 ] the total mutual information is plotted as a function of the snr per sub carrier .",
    "it is observed that the proposed precoding scheme performs much better than the mercury / waterfilling scheme .",
    "the proposed precoder with the  hungarian \" pairing scheme performs within 1.1db of the gaussian signalling scheme for an achievable total mutual information of @xmath208 bits ( i.e. , a rate of 96/128 = 3/4 ) .",
    "the proposed precoder with the  hungarian \" pairing scheme performs about 1.6db better than the mercury / waterfilling scheme . the  x - pairing \" scheme performs better than the mercury / waterfilling and worse than the  hungarian \" pairing scheme . even at a low rate of 1/2 ( i.e. , a total mutual information of 64 bits ) , the proposed precoder with the  hungarian \" pairing scheme performs about 0.7db better than the mercury / waterfilling scheme .    in fig .",
    "[ ofdm_ex_2 ] , we compare the mutual information achieved by the various heuristic pairing schemes . it is observed that the  conjectured \" pairing scheme performs very close to the  hungarian \" pairing scheme except at very high snr . for example , even for a high mutual information of 96 bits , the  hungarian \" pairing scheme performs better than the  conjectured \" pairing scheme by only about 0.2db .",
    "however at very high rates ( like 7/8 and above ) , the  hungarian \" pairing scheme is observed to perform better than the  conjectured \" pairing scheme by about 0.7db .",
    "therefore for low to medium rates , it would be better to use the  conjectured \" pairing since it has the same performance at a lower computational complexity . the mutual information achieved by the  random \" pairing scheme is observed to be strictly inferior than the  conjectured \" pairing scheme at all values of snr , and at low snr it is even worse than the mercury / waterfilling strategy .",
    "this , therefore implies that the total mutual information is indeed sensitive to the chosen pairing .",
    "further , till a rate of 1/2 ( i.e. , a mutual information of 64 bits ) it appears that any extra optimization effort would not result in significant performance improvement for the  conjectured \" pairing scheme , since it is already very close to the idealistic gaussian signalling schemes .",
    "however at higher rate and snr it may still be possible to improve the mutual information by further optimizing the selection of pairing scheme and power allocation between pairs .",
    "this is however a difficult problem that requires further investigation .",
    "in this paper , we proposed a _ low complexity _ precoding scheme based on the pairing of subchannels , which achieves near optimal capacity for gaussian mimo channels with discrete inputs .",
    "the low complexity feature relates to both the evaluation of the optimal precoder matrix and the detection at the receiver .",
    "this makes the proposed scheme suitable for practical applications , even when the channels are time varying and the precoder needs to be computed for each channel realization .",
    "the simple precoder structure , inspired by the x - codes , enabled us to split the precoder optimization problem into two simpler problems .",
    "firstly , for a given pairing and power allocation between pairs , we need to find the optimal power fraction allocation and rotation angle for each pair .",
    "given the solution to the first problem , the second problem is then to find the optimal pairing and the power allocation between pairs .",
    "the proposed precoder was shown to perform better than the mercury / waterfilling strategy for both diagonal and non - diagonal mimo channels",
    ". future work will focus on finding close to optimal pairings , and close to optimal power allocation strategies between pairs .",
    "s.k .  mohammed , e.  viterbo , y.  hong , and a.  chockalingam , `` mimo precoding with x- and y - codes , '' _ submitted to ieee trans . on information theory _ , nov 2009 ( available at http://arxiv.org/abs/0912.1909v1 ) .",
    "a.  lozano , a.m.  tulino , and s.  verdu , `` optimum power allocation for parallel gaussian channels with arbitrary input distributions , '' _ ieee .",
    "trans . on information theory _ , pp .  30333051 , vol .",
    "52 , no .  7 ,",
    "july 2006 ."
  ],
  "abstract_text": [
    "<S> we consider gaussian multiple - input multiple - output ( mimo ) channels with discrete input alphabets . </S>",
    "<S> we propose a non - diagonal precoder based on the x - codes in @xcite to increase the mutual information . </S>",
    "<S> the mimo channel is transformed into a set of parallel subchannels using singular value decomposition ( svd ) and x - codes are then used to pair the subchannels . </S>",
    "<S> x - codes are fully characterized by the pairings and a @xmath0 real rotation matrix for each pair ( parameterized with a single angle ) . </S>",
    "<S> this precoding structure enables us to express the total mutual information as a sum of the mutual information of all the pairs . </S>",
    "<S> the problem of finding the optimal precoder with the above structure , which maximizes the total mutual information , is solved by _ i _ ) optimizing the rotation angle and the power allocation within each pair and _ ii _ ) finding the optimal pairing and power allocation among the pairs . </S>",
    "<S> it is shown that the mutual information achieved with the proposed pairing scheme is very close to that achieved with the optimal precoder by cruz _ </S>",
    "<S> et al . _ , and is significantly better than mercury / waterfilling strategy by lozano _ </S>",
    "<S> et al._. our approach greatly simplifies both the precoder optimization and the detection complexity , making it suitable for practical applications .    mutual information , mimo , ofdm , precoding , singular value decomposition , condition number . </S>"
  ]
}