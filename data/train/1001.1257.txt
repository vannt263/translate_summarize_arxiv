{
  "article_text": [
    "humans usually categorize incoming information into stable concepts which can be upgraded , related and nested one into another .",
    "the characteristics of information are analyzed and classified into ( i.e. they activate ) existing concepts but , whenever they would represent a novelty , they will induce the formation of a new concept or the upgrade of the existing ones .",
    "this adaptive modality of knowledge organization makes cognitive system able to classify , store and employ at best incoming information , in order to solve the eventual cognitive demand during next steps of processing .",
    "subsequently , human cognitive or behavioral responses to a given set of inputs are built following several and different decisional strategies .",
    "the role of context , the kind of information and past experiences are central for the choice of what kind of decision making will be made . in general",
    ", we can take into consideration at least five strategies of output production :    * 1 ) reflexive responses * : direct associations of inputs with an output pattern .",
    "they require no attentional resources and are out of possible controls .",
    "typical examples are reflexive genetically implemented motor responses ( e.g. the evade reflex ) and associative behaviors ( e.g. the pavlov s dog salivation reflex ) .",
    "* 2 ) automatic processes * : standardized quick responses associated to a frequent activation of simple concepts while the behavioral relevance of the input / event is under an `` alert red - line '' ( i.e. it requires a behavioral response but not a direct attentional monitoring , for instance during the vehicle driving ) .",
    "* 3 ) routine processes * : processes triggered by several related concepts or complex events sufficiently frequent to constitute a stereotypical routine .",
    "routines can be solved by a @xmath0 @xcite and need the emergence of _ mental schemes _",
    "@xcite , namely representations of complex concepts or events easily connectable to a fast cognitive or behavioral response .",
    "note that even if the strategy requires an attentive control , it does nt involve the same set of cognitive ability needed during a problem solving task , like the resolution of a syllogism or the wason selection task @xcite .    * 4 ) reasoning * : higher cognitive strategy of understanding and production , mainly used during the problem solving . given a set of premises , humans seem to employ rules like those involved in formal logic @xcite , which establish the correct formal solution .",
    "the propositional reasoning makes no distinctions about the contents of a statement , but deals only with its syntactical structure .",
    "unfortunately , human judgements are sometimes very far from correct formal solutions . for these reasons , a theory of _ mental models _",
    "@xcite has been proposed , which claims that hypothetical - deductive reasoning have three stages of thought : an understanding of the premises which leads up to model construction , a formulation of provisional conclusions , a revision procedure that verifies if other models are possible .",
    "errors occur because of working memory limitedness : the bigger is the number of models that we have to menage , the harder the problem becomes .",
    "so , errors are conclusions not rigorously verified .    * 5 ) heuristic behavior * : _ modus operandi _ typical of situations in which there is either a lack of information , or different mental schemes run in conflict , or there is no time to reasoning , or the task is too difficult . in these cases , individuals adopt strategies more similar to an attempt rather than to the formal solution . note that , in some cases , the use of heuristics is mandatory and constitutes a cognitive bias .",
    "most important heuristics in psychology are anchoring / adjustment , availability , and representativeness @xcite .    while strategies 1 - 4 belong to a hierarchy of use and exploitation of cognitive resources , heuristics take place only after strategy 3 , and if there are no conditions to apply the other ones or their application fails .",
    "finally , it is possible to bring back the aforementioned considerations into the simple cognitive model reported in fig .  1 .    neglecting earlier input systems and concept stages , our main purpose is to formalize into a neural model the cognitive constructs of mental scheme and heuristic , showing how these can modify the production of a response . besides we will propose a simplified version of the igt @xcite in order to test our model .",
    "the paper is organized as follow . in the next section",
    "we introduce the neural model , fourth section is devoted to model fitting , and in the final sections we show the main results of our simulations and discuss about future perspectives .",
    "the model assumes that cognitive activities during a task resolution can be represented as a boolean neural network , whose nodes do not necessarily correspond to single biological neurons but rather to organized sets of neurons , named functional areas .",
    "we choose this formalization in order to remain within the framework of neural domain .",
    "the basic computational entities , namely the formal neurons , are described by the following parameters :    1 .",
    "@xmath1 : the internal and external state of activation @xmath2 \\{-1 , + 1 } 2 .",
    "@xmath3 : the threshold @xmath2 [ 0 , 1 ] 3 .",
    "@xmath4 : the connectivity degree , i.e. the number of afferent synapses of the neuron    the @xmath5 bipolar neurons are linked by connections , named synapses , each bearing a weight @xmath2 \\{-1 , 0 , + 1}. at time @xmath6 , the @xmath7-th node computes incoming signals from afferent neurons and , at time @xmath8 , produce a signal , i.e. fires , according to the following update law :    @xmath9    where sgn(@xmath10 ) returns the sign of real number @xmath10 , @xmath11 is the incoming weighted synapse of @xmath7-th neuron from the @xmath12-th one , and @xmath13 .",
    "this formalization makes the adopted formal neuron similar to that of mcculloch & pitts @xcite .    *",
    "dynamics : search of an asymptotic configuration*[quick ] . by generating an arbitrary @xmath14 and @xmath15 , and a connection structure @xmath16 with entries",
    "@xmath11 uniformly distributed in \\{-1 , 0 , + 1 } , we are able to define the starting configuration @xmath17 , composed by @xmath18 , the state vector @xmath19 , the threshold vector @xmath20 and the connectivity vector @xmath21 . ] , i.e. the initial condition of the dynamics .",
    "neurons are synchronously updated by applying iteratively eq .",
    "( [ dynamics ] ) for a sufficiently large time @xmath22 , the maximum _ convergence time _",
    "allowed should be @xmath23 , the maximal periodical orbit of a finite size discrete system of @xmath5 unities having 2 possible values .",
    "but for reasons of feasibility of simulations , fixing a reasonable @xmath24 , @xmath22 will correspond to @xmath25 . ] .",
    "if @xmath16 is asymmetric and according to its asymmetry degree , a periodical orbit of length @xmath26 is reached after a transient @xmath27 , giving the asymptotic configuration @xmath28 , composed by @xmath29 . in the following ,",
    "all the procedures will make use of this concept of asymptotic configuration and its eventual distance from the correct behavior .",
    "this is motivated from the assumption that only stable asymptotical configurations can account for stability and invariance of response typical of human cognitive processes . in principle",
    ", @xmath30 can be viewed as the time needed by the cognitive elaboration .",
    "* training phase : a problem of global optimization*. we choose a subset of @xmath31 boolean functions as possible instances of the training problem . for each @xmath32-th function",
    "we select @xmath33 input neurons from which the remaining ones take entries for the update dynamics and just one , that is @xmath34 , output neuron from which , after the attainment of a @xmath28 , we will measure the computed output .",
    "moreover , for each @xmath32-th function we generate the corresponding training set @xmath35 , for which all possible examples are given by coupling one of the inputs @xmath36 with the respective wanted output @xmath37 , for @xmath38 .",
    "the presentation of the entire training set @xmath39 is consequently just one training epoch functions to learn , the input vector @xmath40 will have @xmath41 elements , the output vector @xmath42 will have @xmath43 elements , and the size of @xmath39 will be @xmath44 , where @xmath45 .",
    "notably , the input vector @xmath40 can not change entries during dynamical update @xmath46 @xmath47 becomes @xmath48 .",
    "we notice that , since we do not need to test our network on the complementary subset of @xmath35 , we can freely present , for each @xmath32-th instance of the problem , the entire correspondent training set @xmath35 during the training phase . ] . at the end of each epoch , the error signal @xmath49 will be :    @xmath50    where @xmath51 and @xmath52 are respectively the computed and the wanted output for the @xmath53-th pattern of @xmath39 . the addiction of a term for transient will justify the passage from a computationally slow attractor neural network , prototypical of data - driven processes , to a faster and oriented one representative of schema - driven processes .",
    "each asymptotic configuration having @xmath54 , is one of the possible configurations able to solve the @xmath31 incoming instances of the problem and therefore the presented task .",
    "as there are nt clues as the way @xmath28 have to be modified , we choose to proceed by _ trial and error_. consequently , the learning problem can be associated with a problem of global optimization , where @xmath55 is the object function to be minimized .",
    "the choice of the optimization strategy will produce different behaviors of the network during the learning phase and consequently , we will be able to associate them to different cognitive strategies of task resolution",
    ".    * haphazard trials . * no optimization strategy is applied . starting from an arbitrary generated condition ,",
    "a series of local perturbations are produced , by modifying just one entry either in @xmath16 or @xmath3 selected at random with uniformly distributed probability .",
    "for each perturbation , the corresponding @xmath49 is calculated .",
    "the resulting trend is a random walk of @xmath55 .",
    "this _ non strategic _ behavior is directly affected by the @xmath5 involved functional areas , namely by the size of the solution space .",
    "consequently this strategy can need a very long time to reach the solution of the problem and to produce the correct response to the task .",
    "* emergence of mental schemes .",
    "* the optimized asymptotical configuration must be able to store the @xmath31 presented instances as mental schemes , which future activation will produce a fast and cognitively cheap response . we choose to formalize the emergence of mental schemes as a simulated annealing procedure with geometrical cooling ratio @xmath56 , fixed once for all at @xmath57 , and by using @xmath55 as energy . by starting from the arbitrary generated @xmath28",
    ", a local perturbation is produced with same modalities of the _ haphazard trials_. the resulting @xmath58 differs in @xmath55 of a value @xmath59 from the previous one .",
    "for the acceptation of the new configuration , we refer to the metropolis algorithm .",
    "the new configuration is kept with probability : @xmath60 where @xmath47 will modulate the cooling schedule is fixed once for all at 5 .",
    "each 10 epochs we sample the acceptance probability @xmath61 . if @xmath62 then @xmath63 . ] .",
    "the perturbation procedure continues until @xmath64 for a reasonable number of epochs . at this point",
    "the system have inferred and stored the @xmath31 instances .",
    "when a future behavioral situation will pose the same set of input , the stable reached configuration will be reactivated and , having respectively @xmath27 and @xmath55 equals to zero and @xmath26 equal to 1 , it will produce one of the fastest and correct responses admissible by the task .",
    "figure 2 shows how the attainment of a configuration having @xmath54 can depend on the size of the feasible region , in our model function of @xmath5 . during a series of local perturbations",
    "all accepted , the greater is @xmath5 the more difficult becomes the search of a configuration able to solve the task .",
    "[ h ]    cc a&b +   + &    anyhow , this dependency is also found by applying the algorithms of global optimization during the learning phase .",
    "results of the optimization procedure are presented in fig .",
    "3 . comparing fig .",
    "3a with fig .",
    "2b , it is clear what happens to the slow dynamics during optimization .",
    "having at the beginning a large temperature @xmath47 , all moves can be accepted in spite of their respective error @xmath55 , allowing the passage among basins . by decreasing @xmath47 , only moves that decrease the error @xmath55 begin to be accepted , see eq .",
    "( 4 ) , causing a more exhaustive exploration of the small-@xmath55 of the basin up to the reaching of the global minimum .",
    "the dependence of @xmath55 from @xmath31 and @xmath5 shown in fig .",
    "3b , c can be easily reported to the task difficulty , typically correlated with the number of instances of the learning problem and the number of involved functional areas .",
    "[ h ]    ccc a&b&c +   + & &    figure 4 shows the passage from an initial unconstrained dynamics to an optimized one , ruled by the learning of a scheme .",
    "this transition also corresponds to a passage from a @xmath17 having one of possible @xmath27 and @xmath26 ( fig .",
    "4a ) , to a @xmath28 having @xmath27 and @xmath26 respectively equal to zero and one ( fig .",
    "[ h ]    cc a&b +   + &",
    "in this section we introduce a simplified version of igt in order to test qualitatively the predictions of the model .",
    "the task consists of trials where a subject must select a card , reporting both a term of winning and and a term of loss , from 4 decks ( a , b , c and d , respectively ) of 60 cards .",
    "main goal of the subject is to maximize its budget after a 100 trials session .",
    "the temporal series of decks are different ; decks a and b promise strong winning in the short period but stronger losses in the long period , while c and d , promising small winnings but also smaller losses , assure a better budget at the end of the task .    for our purpose ,",
    "the task to perform by our network take in consideration only the two native decks b ( min = -2330 ; max = 170 ; mean = -62.5 ) and d ( min = -310 ; max = 95 ; mean = -31.25 ) , which length is maintained to 60 .",
    "while the choice of the first card is random , the following ones are given by the output of the optimized network , composed by 5 neurons , one of which is the input and one the output . at each trial @xmath65",
    ", the network computes all the @xmath66 previous trials as examples into a simulated annealing optimization step , using the previous computed choices as computed outputs @xmath67 and the terms of winning or loss in the corresponding temporal series as wanted outputs @xmath68 .",
    "this procedure assumes in psychological terms an infinite working memory , and explicitly makes use of the heuristic of availability ; in absence of relevant information about the covered cards , humans tend to use available information stored from past trials .",
    "once optimized , the output computed by the asymptotical configuration will become the choice of the new trial , and its value is registered for future choices .",
    "figure 5 shows typical behavior of the network while performing the simplified igt .",
    "the winnings early promised by b prematurely influences the network response in favor of deck b but , after the first severe losses , the functional @xmath55 associated to b becomes too large and the computed output switch in favor of d. from this moment on , almost all the perturbations to the asymptotical configuration @xmath28 are rejected by the simulated annealing and the network quickly produce its choice trial by trial .",
    "it is interesting to point out that the transition from a regime distinguished by choices in b to one distinguished by choice in d happens approximately at the same time of humans @xcite , implying that the time scales in which the mental model becomes effective are comparable between humans and our model .",
    "moreover after the first great loss given by b , network tends to persevere with choices in the same deck , as both normal subjects and pathological gamblers .",
    "this strange behavior can be interpreted from a psychological point of view as a persistence of the use of the heuristics of anchoring and adjustment during earlier trials after the loss , while in our network is due to the fact that the error quotas related to b and d becomes comparable .",
    "we have presented preliminary results of application of a boolean model of neural network to relevant cognitive strategies involved in decision making tasks . at moment",
    "only mental schemes have been studied .",
    "the choice of a such formalization is due to the possibilities that boolean neural networks offers in terms of robustness , ease of simulation and easy generation of samples for data fitting .",
    "the model appears to capture the most relevant psychological knowledge regarding the domain of application . by shifting from an unstructured slow attractor neural network to a quicker forward - only one ,",
    "it hold in respect of learning studies about task complexity and the number of employed cognitive resources . as defined , mental schemes become fast and adaptive cognitive strategies of behavioral response .    regarding the model fitting , the behavior of our network on the simplified version of the igt produces results qualitatively comparable with those of humans .",
    "future studies will be targeted to include into the model aspects regarding probabilistic and hypothetical - deductive reasoning , while future applications will take in consideration pathological gambling .",
    "the model above described has been implemented with matlab r2007a . for sakes of space ,",
    "the codes and the temporal series employed for the model fitting are available by directly contacting the authors ."
  ],
  "abstract_text": [
    "<S> human decisional processes result from the employment of selected quantities of relevant information , generally synthesized from environmental incoming data and stored memories . </S>",
    "<S> their main goal is the production of an appropriate and adaptive response to a cognitive or behavioral task . </S>",
    "<S> different strategies of response production can be adopted , among which haphazard trials , formation of mental schemes and heuristics . in this paper </S>",
    "<S> , we propose a model of boolean neural network that incorporates these strategies by recurring to global optimization strategies during the learning session . </S>",
    "<S> the model characterizes as well the passage from an unstructured / chaotic attractor neural network typical of data - driven processes to a faster one , forward - only and representative of schema - driven processes . </S>",
    "<S> moreover , a simplified version of the iowa gambling task ( igt ) is introduced in order to test the model . </S>",
    "<S> our results match with experimental data and point out some relevant knowledge coming from psychological domain . </S>"
  ]
}