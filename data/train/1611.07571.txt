{
  "article_text": [
    "machine learning tasks are typically subdivided into two groups : supervised ( when labels for data are provided by human annotators ) and unsupervised ( no data labelled ) . recently ,",
    "more labelled data with millions of examples have become available ( for example , imagenet  @xcite , microsoft coco  @xcite ) , which led to significant progress in supervised learning research .",
    "this progress is partly due to the emergence of convenient labelling systems like amazon mechanical turk .",
    "still , the human labelling process is expensive and does not scale well .",
    "moreover , it often requires a substantial effort to explain human annotators how to label data .",
    "learning an interest point detector is a task where labelling ambiguity goes to extremes . in images , for example , we are interested in a sparse set of image locations which can be detected repeatably even if the image undergoes a significant viewpoint or illumination change .",
    "these points can further be matched for correspondences in related images and used for estimating the sparse 3d structure of the scene or camera positions .",
    "although we have some intuition about what properties interest points should possess , it is unclear how to design an optimal detector that satisfies them . as a result ,",
    "if we give this task to a human assessor , he would probably select whatever catches his eye ( maybe corners or blobs ) , but that might not be repeatable .    in some cases , humans have no intuition what points could be `` interesting '' .",
    "let s assume one wants to match new images to untextured parts of an existing 3d model  @xcite .",
    "the first step could be an interest point detection in two different modalities : rgb and depth map , representing the 3d model .",
    "the goal would be to have the same points detected in both .",
    "it is particularly challenging to design such a detector since depth maps look very different from natural images .",
    "that means simple heuristics will fail : the strongest corners / blobs in rgb might come from texture which is missing in depth maps .",
    "aiming at being independent of human assessment , we propose a novel approach to the interest point detection via unsupervised learning . up to our knowledge",
    ", unsupervised learning for this task has not yet been explored in previous work . some earlier works hand - crafted detectors like dog  @xcite .",
    "more recent works used supervised learning to select a `` good '' subset of detections from a hand - crafted detector .",
    "for example , lift  @xcite aims to extract a subset of dog detections that are matched correctly in the later stages of the sparse 3d reconstruction .",
    "however , relying on existing detectors is not an option in complicated cases like a cross - modal one .",
    "our method , by contrast , learns the solution from scratch .",
    "the idea of our method is to train a neural network that maps an object point to a single real - valued response and then rank points according to this response .",
    "this ranking is optimized to be repeatable under the desired transformation classes : if one point is higher in the ranking than another one , it should still be higher after a transformation .",
    "consequently , the top / bottom quantiles of the response are repeatable and can be used as interest points .",
    "this idea is illustrated in figure  [ fig : teaser ] .    when detecting interest points , it is often required to output not only the position of the point in the image , but also some additional parameters like scale or rotation .",
    "the detected values of those parameters are influenced by the transformations applied to the images .",
    "all transformations can be split into two groups based on their desired impact on the output of the detector .",
    "transformations for which the detector is supposed to give the same result are called invariant .",
    "transformations that should transform the result of a detector together with the transformation  and thus their parameters have to be estimated as latent variables  are called covariant  @xcite .",
    "when learning a detector with our method , we can choose covariant and invariant transformations as it suits our goals .",
    "this choice is implemented as a choice of training data and does not influence the formulation .",
    "the paper is organized as follows . in section  [ sec : related ] , we discuss the related work . in section  [ sec : detbyrank ] , we introduce our formulation of the detection problem as the unsupervised learning to rank problem , and show how to optimize it . in section  [ sec : imagepoint ] , we demonstrate how to apply our method to interest point detection in images .",
    "finally , in section  [ sec : experiments ] we validate our approach experimentally and conclude in section  [ sec : conclusion ] by summarizing the paper and listing possibilities for future work .",
    "currently , unsupervised learning comprises many directions : learning the distribution that best explains data ( gaussian mixture models learned via em - algorithm  @xcite , restricted boltzmann machines  @xcite , generative adversarial nets  @xcite ) , clustering , dimensionality reduction and unsupervised segmentation ( kmeans  @xcite , lle  @xcite , isomap  @xcite , pca  @xcite , normalized cuts  @xcite , t - sne  @xcite ) , learning to simulate task solvers ( when a solution is provided by the solver and the task is automatically generated  @xcite ,  @xcite ) , learning data representation suitable for further use in some other task ( autoencoders  @xcite , deep convolutional adversarial nets  @xcite , learning by context prediction  @xcite , learning from tracking in videos  @xcite , metric learning  @xcite , learning by predicting inpainting  @xcite , learning by solving jigsaw puzzles  @xcite ) .",
    "while some tasks actually have a non - human label ( for example , solver simulation can obtain the solution by running a solver ) , others ( for example , representation learning ) have none at all .",
    "instead , they try to find an auxiliary task which is hard enough in order to learn a representation that is useful for already existing tasks ( classification , for example ) .",
    "designing such a task is non - trivial , therefore only few successful approaches exist ( for example , @xcite ) .    our approach , on the other hand , does not require designing an unrelated auxiliary task . if we can obtain a repeatable ranking , then the top / bottom quantiles of this ranking can be used as detections .",
    "one particular application of our method is interest point detection in images .",
    "most of the existing image interest point detectors are hand - crafted to select particular visual elements like blobs , corners or edges .",
    "these include dog detector  @xcite , harris corner detector  @xcite and its affine - covariant version  @xcite , fast corner detector  @xcite and mser  @xcite .",
    "most recently , there also emerged methods that do supervised learning building upon a hand - crafted solution : lift  @xcite aims to extract an sfm - surviving subset of dog detections , tilde  @xcite uses dog for collecting a training set , @xcite samples training points only where log filter gives large absolute - value response .",
    "building upon a hand - crafted detector restricts those supervised approaches to a subset of their basic method detections  which makes those approaches inapplicable in the cases where there is no good detector yet .",
    "our unsupervised method instead learns the detector completely from scratch by optimizing for a repeatable ranking .    finally ,",
    "a particularly challenging case in image interest point detection is the cross - modal one : the interest points should be repeatable among different image modalities .",
    "several works mention this complex issue ( @xcite , @xcite , @xcite , @xcite ) but do not propose a general solution .",
    "our approach , on the contrary , is general in a sense that the same learning procedure could be applied to different tasks : we show it to work for rgb / rgb and rgb / depth modality pairs .",
    "in this section we introduce the problem of learning an interest point detector as the problem of learning to rank points .",
    "we consider interest points to come from the top / bottom quantiles of some response function .",
    "if these quantiles are preserved under certain transformation classes , we have a good detector : it re - detects the same points . for the quantiles of the ranking to be preserved , we search for a ranking which is invariant to those transformations .",
    "let us consider a set @xmath0 of objects , every object @xmath1 being an @xmath2-dimensional tuple of points @xmath3 .",
    "each point @xmath4 comes from a set @xmath5 of points .",
    "each object @xmath6 can undergo transformations from a set @xmath7 .",
    "each transformation @xmath8 preserves certain point correspondences : some points in object @xmath9 will correspond to points in object @xmath6 .",
    "we assume one point can have at most one correspondence in the other object . to simplify the notation",
    ", we assume the correspondences have the same indexes in an object @xmath6 before and after a transformation .",
    "we denote the set of corresponding point indexes as @xmath10 , where @xmath11 is the number of correspondences for points in @xmath6 and @xmath9 .",
    "we want to rank object points and represent this ranking with a single real - valued response function @xmath12 , where @xmath13 is a point and @xmath14 is a vector of parameters ( one possible choice of @xmath15 is a neural network ) .",
    "thus , invariance of the ranking under transformation @xmath8 can be stated as follows : for every quadruple @xmath16 satisfying @xmath17 , it holds that @xmath18 from the condition above it follows    if @xmath15 satisfies the ranking constraints ( [ eq : ineq ] ) and every point has a correspondence , the top / bottom quantiles of @xmath15 before a transformation correspond to the top / bottom quantiles of @xmath15 after it .",
    "[ ob : quantile ]    thus , to get a repeatable interest point detector , one just needs to sort all points @xmath19 of the object @xmath6 by their response @xmath12 and take the top / bottom quantiles as interest points .    in the next section we will state the optimization objective aiming at preserving the ranking ( [ eq : ineq ] ) .",
    "first , let us introduce a ranking agreement function for quadruples : @xmath20 then the ranking invariance condition  ( [ eq : ineq ] ) can be re - written as @xmath21 in order to give preference to this invariance , we will assume the object set @xmath0 and the transformation set @xmath22 to be finite ( for the sake of training ) and minimize the objective : @xmath23 where @xmath24 is a function penalizing non - positive values .",
    "one naive solution would be to use a `` misranking count '' loss @xmath25 unfortunately , this loss is hard to optimize as it either does nt have a gradient or its gradient is zero .",
    "instead , we upper - bound the discontinuous loss with a differentiable one . in this work , we choose to use the hinge loss @xmath26 then the final form of our minimized objective will be @xmath27 which is differentiable as long as @xmath28 is differentiable w.r.t @xmath29 ( that is satisfied if @xmath15 is a neural network ; note that the objective above is non - convex even if @xmath15 is linear ) .",
    "therefore , we can use gradient descent for the optimization .",
    "learning detectors from scratch is a hard task since it is non - trivial to formulate good detector criteria in the optimization framework .",
    "as investigated by  @xcite , a good detector should produce interest points that are robust to viewpoint / illumination changes ( to detect the same points and further match them ) and sparse ( to make feature matching feasible ) . to comply with the earlier introduced terminology",
    ", @xmath6 is an image , @xmath19 is a position in the image represented by a patch , a transformation @xmath30 is a viewpoint / illumination change and correspondence sets @xmath31 are patch - to - patch correspondences between images observing the same 3d scene .",
    "it is typical for interest point detectors to ensure sparsity in two ways : by retaining the top / bottom quantiles of the response function ( contrast filtering ) and by retaining the local extrema of the response function ( non - maximum suppression ) .",
    "while observation [ ob : quantile ] suggests reproducibility of our detections under contrast filtering , it turns out that non - maximum suppression is also suitable for our detector according to the following    if @xmath15 satisfies the ranking constraints ( [ eq : ineq ] ) and the neighborhood of the correspondence @xmath32 is visible in both images @xmath33 , then @xmath34 is a local extremum in image @xmath6 @xmath35 @xmath36 is a local extremum in image @xmath9 .",
    "[ ob : extrema ]    it is easy to see why this observation is true : if the position is ranked higher / lower than all the neighbors in one image , the corresponding position should be ranked higher / lower than the corresponding neighbors in another image .",
    "thus the proposed objective is beneficial for the detector pipeline which consists of non - maximum suppression and contrast filtering .",
    "this pipeline is followed by many detectors including the popular dog detector  @xcite . in the following section ,",
    "we explain how to train an image interest point detector with our objective .",
    "we need to sample from both the image set @xmath0 and the transformation set @xmath22 to perform training with the objective ( [ eq : objective ] ) .",
    "we could , of course , take images and transformations from any available image dataset with correspondences .",
    "but this does nt address two important questions :    * how to achieve invariance exactly to the transformations that we want ?",
    "for example , most real images are taken up - right , so there is no relative rotation between any pair of them .",
    "but we want our detector to be robust to cases where there is such a rotation . * how to augment the training images ?",
    "for example , all the objects in the training images might be well - illuminated .",
    "but in the testing images some objects might be in the shadow , while others are in the light .",
    "we might want to be robust to such cases .",
    "in this chapter we will show how to achieve each goal by randomly transforming training quadruples @xmath37    to achieve invariance to a transformation class @xmath38 , we can sample two random transformations @xmath39 and apply a quadruple of transformations @xmath40 to the training quadruples @xmath41 element - wise .",
    "this expresses our preference to preserve the ranking even if a random transformation from @xmath38 is applied to the image .    to augment the data with a transformation class @xmath42 , we can sample two random transformations @xmath43 and apply @xmath44 to @xmath41 .",
    "this means that we apply the same transformation to both patches in the correspondence to create more training data .",
    "finally , there are some invariant / augmenting transformations which ca nt be easily parametrized and sampled ( , the non - lambertian effect ) . in that case",
    ", we fully rely on their distribution , coming from the real data .",
    "our objective function ( [ eq : objective ] ) is based on pairs of correspondences , forming training quadruples ( an example of such a quadruple is shown in fig .",
    "[ fig : pipeline ] ) . to train a detector , we need to obtain those correspondences .",
    "we investigated learning :    * an rgb detector from ground - truth correspondences ( they come from projecting laser - scanned 3d points onto images ) , * a fully - unsupervised rgb detector ( correspondences are obtained by randomly warping images and changing illumination ) , * a cross - modal rgb / depth detector ( correspondences are trivially obtained as coinciding locations in view - aligned kinect rgbd frames ) .",
    "we further describe the setup of those experiments .    * detector class .",
    "* we concentrate on the most commonly used type of detectors : scale - space - covariant , rotation - invariant ones ( although our method is suitable for any combination of detector covariances / invariances ) .",
    "for example , dog belongs to that type .",
    "those detectors consider an interest point @xmath19 to be characterized by an image location @xmath45 and a scale @xmath46 .",
    "the points are detected in a @xmath47-dimensional space ( scale - space ) using a response function @xmath48 consequently , non - maximum suppression and contrast filtering work in this @xmath47-dimensional space as well ( with a @xmath49 neighborhood ) .",
    "since rotation is not estimated , the detector is required to be invariant to it .",
    "the invariance is achieved by the random sampling ( see section  [ sec : training ] ) .",
    "* detector evaluation .",
    "* dog is the most widely used detector nowadays , so we use it as a baseline in our evaluation .",
    "the whole detector is a multi - stage pipeline in which we aim to substitute a crucial part : the filter used to convolve the image . in order to make a fair evaluation",
    ", we fix all the other stages of the pipeline .",
    "the whole procedure works as follows .",
    "first , we apply the response function @xmath50 to all spatial positions of the image at all considered scales .",
    "this is the stage we are aiming to substitute with a learned function ( dog filter in the standard pipeline ) .",
    "second , we do non - maximum suppression in scale - space .",
    "third , we do accurate localization based on the second - order taylor expansion of the response function around potential interest points  @xcite .",
    "finally , we only take points for which the absolute value of the response is larger than a threshold .    for quantitative evaluation",
    ", we used the repeatability measure described in  @xcite .",
    "the repeatability is the ratio between the number of points correctly detected in a pair of images and the number of detected points in the image with the lowest number of detections .",
    "it is only meaningful to compare methods producing the same number of interest points : otherwise some method might report too many points and unfairly outperform others ( , if we take all points as `` interesting '' , repeatability will be very high ) .",
    "therefore , we consider a range of top / bottom quantiles , producing the desired numbers of points and compare all methods for those fixed numbers",
    ".    * response function .",
    "* in all experiments , the response function @xmath28 is a neural network .",
    "we describe it as a tuple of layers and use the notation :    * @xmath51 for convolutional layers with filter size @xmath52 , taking @xmath53 input channels , outputting @xmath54 channels , using zero - padding of @xmath19 pixels on each border ( stride is always @xmath55 in all experiments ) , * @xmath56 for fully - connected layers , taking @xmath53 features and outputting @xmath54 features , * @xmath57 for elu non - linearity function  @xcite , * @xmath58 for batch normalization layer , * @xmath59 for applying the same network @xmath60 times .    in all the experiments ,",
    "the response function is applied to grayscale @xmath61x@xmath61 patches .",
    "if the training data is in color , we convert it to grayscale .",
    "the patches are preprocessed as it s typical for neural networks : the mean over the whole patch is subtracted , then it is divided by the standard deviation over the patch .",
    "* augmentation . *",
    "we augment the training data ( see section  [ sec : training ] ) with random rotations from @xmath62 $ ] and random scale change from @xmath63 $ ]",
    ".    * optimization details . * to optimize the objective ( [ eq : objective ] ) , we use the adadelta algorithm  @xcite , which is a version of gradient descent that chooses the gradient step size per - parameter automatically .",
    "we implement the model and optimization on a gpu ( nvidia titan x ) using the torch7 framework  @xcite .",
    "the batch size is @xmath64 , our models are trained for @xmath65 epochs , each consisting of randomly sampling a pair of corresponding images and then randomly sampling @xmath66 quadruples from this pair .",
    "eventually , by the time training stops our models have seen @xmath67 million sampled quadruples .      in this experiment , we show how to use existing 3d data to establish correspondences for training a detector",
    ".    * training . *",
    "we used the dtu robot image dataset  @xcite .",
    "it has 3d points , coming from a laser scanner , and camera poses , which allow to project 3d points into the pairs of images and extract image patches centered at the projections .",
    "those projections form the correspondence pairs for training .",
    "* testing .",
    "* we used the oxford vgg dataset  @xcite , commonly chosen for this kind of evaluation .    * nn architectures . * in this experiment , we tested two nn architectures : a linear model @xmath68 and a non - linear nn with one hidden layer @xmath69 .    * results .",
    "* we demonstrate that the filter of our learned linear model is different from the filters of the baselines in figure  [ fig : filters ] .",
    "furthermore , we show the detections of the linear model in comparison to dog in figure  [ fig : detections ] .",
    "our learned model detects points , different from dog : they are more evenly distributed in images .",
    "that is usually profitable for estimating geometric transformations between camera frames .",
    "the learned response functions with both investigated architectures ( linear , non - linear ) demonstrate better performance than baselines in most cases , as shown in table  [ tab:3d ] ( results are averaged over all image pairs for each transformation type ) .",
    "moreover , the non - linear model performs better than the linear one in the majority of the cases .",
    "[ cols=\"^,^,^ \" , ]",
    "in this work , we have proposed an unsupervised approach to learning an interest point detector .",
    "the key idea of the method is to produce a repeatable ranking of points of the object and use top / bottom quantiles of the ranking as interest points . we have demonstrated how to learn such a detector for images . we show superior or comparable performance of our method with respect to dog in two different settings : learning standard rgb detector from scratch and learning a detector , repeatable between different modalities ( rgb and depth from kinect ) .",
    "future work includes learning the descriptor jointly with our detector .",
    "also , one could investigate applying our method to detection beyond images ( , to interest frame detection in videos ) ."
  ],
  "abstract_text": [
    "<S> several machine learning tasks require to represent the data using only a sparse set of interest points . </S>",
    "<S> an ideal detector is able to find the corresponding interest points even if the data undergo a transformation typical for a given domain . </S>",
    "<S> since the task is of high practical interest in computer vision , many hand - crafted solutions were proposed . in this paper </S>",
    "<S> , we ask a fundamental question : can we learn such detectors from scratch ? </S>",
    "<S> since it is often unclear , what points are `` interesting '' , human labelling can not be used to find a truly unbiased solution . </S>",
    "<S> therefore , the task requires an unsupervised formulation . </S>",
    "<S> we are the first to propose such a formulation : training a neural network to rank points in a transformation - invariant manner . </S>",
    "<S> interest points are then extracted from the top / bottom quantiles of this ranking . </S>",
    "<S> we validate our approach on two tasks : standard rgb image interest point detection and challenging cross - modal interest point detection between rgb and depth images . </S>",
    "<S> we quantitatively show that our unsupervised method performs better or on - par with baselines . </S>"
  ]
}