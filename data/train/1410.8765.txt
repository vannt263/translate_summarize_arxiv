{
  "article_text": [
    "the problem of quickest detection has been known in the engineering literature since the 1930s . since then",
    "there have been various analytical considerations of the quickest detection problem in a variety of models and setups ( see @xcite for an overview ) .",
    "the quickest detection problem , also known as the disorder problem , concerns the detection of a change point in the statistical behavior of a stream of sequential observations . the objective is to blanace the trade off between a small detection delay and small frequency of false alarms . of this problem",
    "there are two main formulations , the bayesian and the min  max . in the former , the change point or disorder time",
    "is assumed to have an a priori distribution usually independent of the observation process while in the latter it is assumed to be an unknown constant .",
    "an interesting variation of the bayesian problem in which the change point is assumed to depend on the observations is discussed in @xcite and treated under poisson dynamics in @xcite .    yet in all formulations considered thus far , it is assumed that there is either one stream of observations in which there is one @xcite or multiple alternatives regarding the law of the post change distribution of the observations @xcite , or alternatively , multiple streams of observations of various models all undergoing a disorder at the same time @xcite . in our work",
    ", we assume that there are @xmath0 sources of observations coupled by correlated noise .",
    "the observations are assumed to be continuous and thus a wiener model is used .",
    "the problem considered in this work is that in which the @xmath0 different streams of observations coupled by correlated noise may undergo a change at @xmath0 distinct change points .",
    "the objective is then to detect the minimum of the change points or disorder times . of this type of problem",
    "there has thus far been a bayesian formulation in independent streams of poisson observations @xcite .",
    "recently , the case was also considered of change points that propagate in a sensor array @xcite . however , in this configuration the propagation of the change points depends on the _ unknown _ identity of the first sensor affected and considers a restricted markovian mechanism of propagation of the change .    in this paper , we consider the case in which the change points can be different and do not propagate in any specific configuration .",
    "in fact , in our formulation the change points or disorder times are assumed to be unknown constants and a min ",
    "max approach to their estimation is taken .",
    "in particular , we consider an extended lorden criterion to measure the worst detection delay over all observation paths and change points .",
    "the objective is then to find a stopping rule that minimizes the detection delay subject to a lower bound constraint on the mean time to the first false alarm .",
    "the @xmath0 streams of observations are coupled through correlated noise . in particular ,",
    "correlations are modeled through a stochastic correlation matrix that is assumed to be nonsingular and predictable .",
    "this work is a continuation of the problem considered in @xcite in which the case is considered of independent observations received at each sensor . in that work",
    ", it is seen that the decentralized system of sensors in which each sensor employs its own cumulative sum ( cusum ) @xcite strategy and communicates its detection through a binary asynchronous message to a central fusion center , which in turn decides at the first onset of a signal based on the first communication performs asymptotically just as well as the centralized system . in other words , the minimum of @xmath0-cusums is asymptotically optimal in detecting the minimum of @xmath0 distinct change points in the case of independent observations as the mean time to the first false alarm increases without bound .",
    "the mean time to the first false alarm can be used as a benchmark in actual applications in which the engineer or scientist may make several runs of the system while it is in control in order to uniquely identify , the appropriate parameter that would lead to a tolerable rate of false detection .",
    "the problem of optimal detection then boils down to minimizing the detection delay subject to a tolerable rate of false alarms .",
    "asymptotic optimality is then proven by comparing the rate of increase in detection delay to the rate of false alarms as the threshold parameter varies .",
    "a series of more recent related work includes the case in which the system of sensors is coupled through the drift parameter as opposed to the noise @xcite . in that work",
    ", it is once again seen that the minimum of @xmath0-cusums is also asymptotically optimal in detecting the minimum of @xmath0 distinct change points with respect to a generalized kullback  leibler distance criterion inspired by @xcite .    yet , in none of the above cases is the case of correlated noise considered even though it is very important in practical applications .",
    "in fact , there are multiple applications of this problem especially in the area of communications where sensor networks are widely used and multiple correlated streams of observations are present .",
    "the change points , usually representing the onset of a signal in a specific sensor , may well be distinct .",
    "the minimum of the change points then represents the onset of a signal in the system .",
    "the presence of correlations is due to the fact that , although sensors are placed typically at different locations , they are subject to the same physical environment . for example , in the case of sensors monitoring traffic in opposite ( same ) directions may have negative ( positive ) correlations due to environmental factors such as the direction of the wind @xcite . moreover ,",
    "the appearance of a signal at one location may or may not cause interference of the signal at another location , thus causing correlations whose structure may even be time or observations dependent .",
    "this happens when the sensors are closely spaced relative to the curvature of the field being sensed .",
    "for example , temperature sensors or humidity sensors that are in a similar geographic region will produce readings that are correlated .",
    "a stochastic correlation matrix would best describe such a situation .",
    "some of the relevant literature that includes such examples can be found in @xcite .    in an earlier work @xcite",
    "the authors treat the problem of quickest detection of the minimum of two change points in the special case of two streams of sequential observations when the correlation in the noise of the observations is constant and negative and the same drifts are assumed after each of the disorder times .",
    "this work treats the general case of @xmath0 correlated streams of observations in the presence of partial information regarding the post - change drifts which can as such be different .",
    "moreover , we consider a general stochastic correlation matrix allowing for both positive and negative time and state dependent correlations in the system .",
    "the results found in this work are in fact rather surprising .",
    "it is seen that the minimum of @xmath0-cusum stopping rules maintains its asymptotically optimal character as the mean time to the first false alarm increases without bound even in the case of partially known drifts and a stochastic correlation matrix coupling the noise of @xmath0 streams of observations . in particular , it is proved that the @xmath0-cusum stopping rule ( defined in algorithm  [ ncusum ] ) is second - order asymptotically optimal below . ] in the case the post - disorder drift parameters assumed across the @xmath0 streams of observations are the same , and is third - order asymptotically optimal when the post - disorder drift parameters are different for an appropriately chosen set of threshold parameters whose form is explicitly given .",
    "the method used to prove the asymptotic optimality of the @xmath0-cusum stopping rule is to bound the optimal detection delay from above and from below .",
    "then we examine the rate at which the difference between the upper and the lower bounds approach each other as the mean time to the first false alarm increases without bound . this method is similar to @xcite .",
    "however , the methodology developed in this work for establishing the upper and lower bounds is more efficient and robust in that it is based on probabilistic arguments . in contrast",
    ", the existing work in continuous - time , which is either relied on brute computation of the asymptotic behaviors of maximum drawdown densities @xcite or on the derivation of sharp solutions to dirichlet problems with neumann conditions @xcite , is very difficult in high - dimension and highly sensitive to the model parameters .",
    "the methodology developed in this paper is universal and can thus handle a non - markovian , predictable correlation matrix process for the noises , which is very useful in practical applications .",
    "finally , our methodology can be applied to other detection problems not covered in this paper , for example , quickest detection with multiple alternatives @xcite . in establishing the lower bound",
    ", we give a nontrivial generalization of a measure change technique developed in @xcite to @xmath0-dimensions .",
    "although we do not get the exact optimality as in one dimension @xcite , we do prove that the optimal detection delay in @xmath0-dimensions is bounded from below by that obtained in one dimension , under any predictable , nonsingular correlation matrix .",
    "in the next section , we formulate the problem mathematically , review the existing results in one dimension , and introduce the @xmath0-cusum stopping rule . in section  [ robust ] , we establish a robust upper bound and a robust lower bound for both the optimal detection delay and the detection delay of the @xmath0-cusum stopping rule .",
    "these bounds are then used in section  [ asympt ] to show the main result of the paper  the asymptotic optimality of the @xmath0-cusum stopping rule under complete or partial information of the drifts and a stochastic cross - correlated noise structure in the observations .",
    "applications of these results are discussed in section  [ applications ] .",
    "we conclude with some closing remarks in section  [ conclusion ] .",
    "the proof of the lemma that is omitted can be found in the .    throughout the paper ,",
    "we denote by @xmath1 , @xmath2 , @xmath3 and @xmath4 $ ] .",
    "consider a filtered probability space @xmath5 with filtration @xmath6 , and the processes @xmath7 , @xmath8 , are assumed to satisfy the following stochastic differential equations : @xmath9 here , @xmath10 are deterministic but _ unknown _ positive constants or @xmath11 , @xmath12 are positive constants ( but not necessarily the value of it ) , then we can take @xmath13 as the @xmath14th observation process so that the post - change drift is @xmath15 .",
    "we do not treat in this paper , however , the case in which we do not know the sign of the post - change drift . ]",
    "that are either completely known or partially known . in the latter case , we assume that @xmath16 is a known constant , and for @xmath17 , there are known positive constants @xmath18 such that @xmath19 $ ] holds . is known , we can conveniently take @xmath20 . ]",
    "the processes @xmath21 for @xmath22 are @xmath0 correlated standard brownian motions with a predictable , nonsingular , stochastic instantaneous correlation matrix @xmath23 . that is",
    ", @xmath24 is the instantaneous correlation between brownian motions @xmath25 and @xmath26 ( see also @xcite , page 227 ) .",
    "an example covered by the above assumptions is one in which @xmath27 for @xmath28 and some @xmath29 . in other words",
    ", there is a deterministic exponential decay in the instantaneous correlation of the two sensors @xmath14 and @xmath30 .",
    "such a situation may arise by the sudden arrival of a passing rainstorm at sensors @xmath14 and @xmath30 , which are customarily placed in the same geographical region and are therefore also subject to the same climate conditions . yet",
    "our formulation is even more general in that it is also able to capture state dependent correlations which is a very realistic scenario since observations of higher intensity are typically more likely to cause higher correlations in the noise , for instance , @xmath31 and @xmath32 for @xmath33 .",
    "another example of a correlated nonstationary white noise structure arises in the problem of monitoring the vibration of a mechanical system and is discussed in full detail in section  11.1.4.1 of @xcite .    to facilitate our analysis",
    ", we introduce a family of probability measures on the canonical space @xmath34 : @xmath35 . here , @xmath36 corresponds to the measure generated on @xmath37 by the processes @xmath38 when the change in the @xmath0-tuple process occurs at the time points @xmath39 , @xmath40 , respectively . in particular",
    ", the measure @xmath41 characterizes the law of @xmath0 correlated standard brownian motions @xmath21 . for other @xmath42 s",
    ", the measure @xmath36 can be defined through the radon  nikodym derivative process @xmath43 fulfills the novikov condition : @xmath44 \\label{eq : nov } \\\\[-8pt ] \\eqntext{{\\displaystyle}\\forall t\\ge0 , \\forall(s_1 , \\ldots , s_n)\\in(\\overline{\\mathbb{r}}_+)^n.}\\end{aligned}\\ ] ] we comment that the `` reality '' measure @xmath45 is one unknown element in @xmath46 .    to describe the `` marginal '' law of the @xmath14th component of the @xmath0-tuple process @xmath47",
    ", we also introduce the measure @xmath48 , which is the probability measure generated by the process @xmath49 on the space @xmath50 , where @xmath51 for @xmath52 , is the natural filtration of @xmath49 , and @xmath39 is the value of the change - point for process @xmath49 .",
    "our objective is to find a stopping rule @xmath53 , which is adapted to the natural filtration @xmath54 : @xmath55 , needs not to be adapted to @xmath56 .",
    "for example , @xmath57 can be driven by a @xmath0-dimensional brownian motion which is independent of @xmath25 s . ] to balance the trade - off between a small detection delay subject to a lower bound on the mean - time to the first false alarm and will ultimately detect @xmath58 , which will be denoted by @xmath59 in what follows . as a performance measure , we consider @xmath60 where @xmath61 , @xmath62 denotes the expectation under the probability measure @xmath63 , and the supremum over @xmath64 is taken over the set in which @xmath65 .",
    "in other words , we consider the worst detection delay over all possible realizations of paths of the @xmath0-tuple of the stochastic process @xmath66 up to time @xmath67 , and then consider the worst detection delay over all possible @xmath0-tuples @xmath68 over a set in which at least one of the components takes a finite value .",
    "this is because @xmath53 is a stopping rule meant to detect the minimum of the @xmath0 change points and , therefore , if one of the @xmath0 processes undergoes a regime change , any unit of time by which @xmath53 delays in reacting , should be counted toward the detection delay .",
    "although it seems to be a quite pessimistic measure for detection delay , this framework has the merit that one does not need to impose any prior knowledge of the distribution of the change - points @xmath69 s , as discussed in @xcite . in all , this gives rise to the following stochastic optimization problem : @xmath70 where @xmath71 captures the mean time to the first false alarm and as such the above constraint describes the tolerance on the false alarms .",
    "in particular , the constant @xmath72 is the lowest acceptable value of the mean time to the first false alarm . in other words ,",
    "the reciprocal of @xmath73 , namely @xmath74 , captures the highest tolerance to the frequency of false alarms of the family of stopping times considered in this problem .",
    "when detecting @xmath69 is our only concern , and that @xmath75 is a known constant , the problem reduces to an one - dimensional problem of detecting a one - sided change in a sequence of brownian motion observations , whose optimality was found in @xcite and @xcite . it is shown that the optimal stopping rule under lorden s criterion is the continuous time version of page s cusum stopping rule , namely the first passage time of the process @xmath76 \\\\[-8pt ] \\eqntext{{\\displaystyle}\\mbox{for } \\tilde{u}_t^{(i ) } : = \\mu_i \\xi_t^{(i ) } - \\frac{1}{2 } \\mu_i^2 t \\quad\\mbox{and}\\quad \\tilde{m}_t^{(i ) } : = \\inf_{0\\le s\\le t } \\tilde{u}_s^{(i)},}\\end{aligned}\\ ] ] and the cusum stopping rule with the threshold @xmath77 is given by @xmath78 the optimal threshold @xmath79 is chosen so that @xmath80 the corresponding optimal detection delay achieved by the cusum stopping rule @xmath81 is then given by @xmath82 the fact that the worst detection delay in the one - dimensional problem is the same as that incurred in the case that the change point is exactly at @xmath83 is a consequence of the nonnegativity and strong markov property of the cusum process , from which it follows that the worst detection delay occurs when the cusum process is at @xmath83 at the time of the change ( see also @xcite ) .",
    "the optimality of the cusum stopping rule in the presence of only one observation process with a known drift suggests that a cusum type of stopping rule might display similar optimality properties in the case of multiple observation processes for the problem ( [ eqnproblem ] ) . in particular , an intuitively appealing rule , when the detection of @xmath59 is of interest , is to take the minimum of @xmath0-cusum - like stopping rules ( see , e.g. , @xcite ) , which we formalize in the following algorithm .",
    "[ ncusum ] the @xmath0-cusum stopping rule with a threshold vector @xmath84 is given by @xmath85 , where for each @xmath8 , @xmath86 \\label{cusum1chart } \\\\[-25pt ] \\eqntext{{\\displaystyle}\\mbox{with } y_t^{(i)}=u_t^{(i)}-m_t^{(i ) } , \\mbox{for } u_t^{(i)}:=\\underline { \\mu } _",
    "i \\xi_t^{(i)}-\\frac{1}{2}\\underline { \\mu}_i^2t}\\\\ \\eqntext{{\\displaystyle}\\mbox{and } m_t^{(i)}:=\\inf _ { 0\\le s\\le t}u_t^{(i)}.}\\end{aligned}\\ ] ]    that is , we use what is known as a multichart cusum stopping rule @xcite , which can be written as @xmath87 where @xmath88 is the semi - martingale defined in ( [ cusum1chart ] ) , for @xmath8 .",
    "we notice that each of the @xmath89 , for @xmath8 , are stopping rules also with respect to each of the smaller filtrations @xmath90 , and thus they can be employed by each one of the sensors @xmath91 , for each @xmath14 independently .",
    "each of the sensors can then subsequently communicate an alarm to a central fusion center once its threshold , say @xmath92 , is reached by its own cusum statistic process @xmath93 .",
    "the resulting rule , namely algorithm [ ncusum ] , can then be devised by the central fusion center in that it will declare a detection at the first instance one of the @xmath0 sensors communicates .    from ( [ 1dimpr ] ) and ( [ cusum1chart ] ) , it is easily seen that @xmath94 and @xmath95 , a.s .",
    ", provided that @xmath96 is known .",
    "in particular , we always have @xmath97 and @xmath98 .",
    "while it seems prohibitively difficult to devise a stopping rule that achieves the optimal detection delay @xmath99 under a general nonsingular correlation matrix @xmath100 , the above @xmath0-cusum stopping rule @xmath101 provides a low - complexity candidate detection rule for detecting @xmath59 .    in particular , we will show that the @xmath0-cusum stopping rule is asymptotically optimal . to this effect , we give the following definitions of asymptotic optimality as in @xcite .",
    "[ optdef ] given @xmath72 and a stopping time @xmath102 , we say that :    1 .",
    "@xmath103 has the first - order asymptotic optimality for problem ( [ eqnproblem ] ) if and only if @xmath104 2 .",
    "@xmath103 has the second - order asymptotic optimality for problem ( [ eqnproblem ] ) if and only if @xmath105<\\infty\\quad\\mbox{and}\\quad \\lim _ { \\gamma\\to\\infty}\\inf_{t\\in \\mathcal { t}_\\gamma}j^{(n)}(t)=\\infty.\\ ] ] 3 .",
    "@xmath103 has the third - order asymptotic optimality for problem ( [ eqnproblem ] ) if and only if @xmath105=0\\quad \\mbox{and}\\quad\\lim _ { \\gamma\\to\\infty}\\inf_{t\\in \\mathcal { t}_\\gamma}j^{(n)}(t)=\\infty.\\ ] ]    below we will investigate the performance of @xmath101 by contrasting it with the optimal detection delay .",
    "in this section , we examine the performance of the @xmath0-cusum stopping rule by presenting an upper bound and a lower bound for both the detection delay of the @xmath0-cusum stopping rule and the optimal detection delay defined in ( [ eqnproblem ] ) . to this end , we derive a robust upper bound for the detection delay of a particular @xmath0-cusum stopping rule  @xmath106 in @xmath107 . because @xmath101 can not beat the unknown optimal stopping rule ( if it ever exists ) , this upper bound will also bound the optimal detection delay from above . we then demonstrate that the optimal detection delay in the @xmath0-dimensional system is bounded from below by the optimal delay in 1-dimensional systems .      in this subsection , we derive a robust upper bound for the detection delay of a @xmath0-cusum stopping rule @xmath101 , whose thresholds set @xmath108 is chosen so that @xmath109 for any @xmath72 .",
    "the upper bound , that we obtain , also dominates the optimal detection delay , due to the fact that @xmath110 holds .",
    "now let us introduce @xmath111 for @xmath112 , where @xmath113 is the detection delay of the stopping rule @xmath53 when @xmath114 , implying that the performance measure defined in ( [ jkl ] ) is given by @xmath115 .",
    "we now consider the case when all drifts @xmath75 s are known constants . in this case , we select @xmath108 such that @xmath116 or equivalently [ by ( [ 1dimsol ] ) ] , @xmath117 due to the monotonicity of function @xmath118 , @xmath92 s are uniquely determined once @xmath119 is given .",
    "in general , if we only have partial information about @xmath75 s for @xmath17 , we instead consider @xmath120 by choosing the @xmath0-cusum stopping rule @xmath106 in this way , we are able to get an easily computable upper bound for the worst detection delay @xmath121 . the assertion is proved in the following proposition .",
    "[ upb ] suppose that @xmath122 satisfies the equations in ( [ hi ] ) or  ( [ hi1 ] ) , then we have for the @xmath0-cusum stopping rule @xmath123 , that @xmath124 where the function @xmath118 is defined in ( [ g ] ) .    for any @xmath125 such that @xmath126 and @xmath127 , we have @xmath128 where the last equality follows from the fact that the cusum stopping rule @xmath129 is @xmath130-measurable and we can thus use the `` marginal '' law of the @xmath30th component of the @xmath0-tuple process @xmath47 , given in this case by the measure @xmath131 . by taking the essential supremum and then the supremum over @xmath132 such that @xmath114 on both sides of ( [ e < ] ) , and using the definitions in ( [ jkl ] ) and ( [ jjn ] ) for @xmath133 , we get that @xmath134 to get the conditional expectation in the above expression , we use the strong markov property of the processes @xmath135 ( see , e.g. , @xcite , theorem 7.2.4 ) and apply it s formula to @xmath136 ( see , e.g. , @xcite , theorem 4.1.2 ) for the function @xmath118 given in ( [ g ] ) ( see also shiryaev @xcite and moustakides @xcite ) , we obtain that ( by the monotonicity of @xmath118 ) @xmath137 \\nonumber \\\\ \\label{sing } & = & \\mathbf{1}_{\\{t_{h_j}^j > s_j\\ } } \\biggl[\\int_{s_j}^{t_{h_j}^j } \\underline{\\mu}_j \\biggl(\\mu_j-\\frac{1}{2 } \\underline{\\mu}_j \\biggr)\\,{d}s\\\\ & & \\nonumber\\hspace*{43pt}{}-\\int_{s_j}^{t_{h_j}^j}g ' \\bigl(-y_s^{(j)}\\bigr)\\,{d}m_s^{(j)}+m_{t_{h_j}^j}-m_{s_j } \\biggr],\\end{aligned}\\ ] ] where the process @xmath138 is given by ( [ cusum1chart ] ) and the continuous square integrable martingale @xmath139 is given by @xmath140 taking into account that the process @xmath138 decreases only on the random set @xmath141 and the measure @xmath142 off this set , together with the fact that @xmath143 , we conclude that the integral in ( [ sing ] ) can be set equal to zero .",
    "we then take the conditional expectations with respect to the probability measure @xmath144 given @xmath145 in ( [ sing ] ) and by means of the doob s optional sampling theorem ( see , e.g. , @xcite , chapter  1 , theorem  3.22 ) , we have @xmath146 \\label{j11 } \\\\[-8pt ] \\nonumber & \\ge & \\frac{\\underline{\\mu } _ j^2}{2}\\mathbb{e}_{s_j}^{j}\\bigl\\",
    "{ \\bigl(t_{h_j}^j - s_j\\bigr)^+| \\mathcal{g}_{s_j}^j\\bigr\\}.\\end{aligned}\\ ] ] therefore , by ( [ j1 < ] ) and ( [ j11 ] ) we have @xmath147 . by the arbitrariness of @xmath30",
    ", we have @xmath148 \\label{jn}\\\\[-8pt ] \\nonumber & \\le &   \\max \\biggl\\ { \\frac{2}{\\mu_1 ^ 2 } g(-h_1),\\ldots,\\frac{2}{\\underline { \\mu } _",
    "n^2 } g(-h_n ) \\biggr\\ } = \\frac{2}{\\mu_1 ^ 2}g(-h_1),\\end{aligned}\\ ] ] where the last equality is a consequence of the equations in ( [ hi1 ] )",
    ".    condition ( [ hi1 ] ) reduces the thresholds selection problem from @xmath0 dimension to one dimension . in order to bound the optimal detection delay in ( [ eqnproblem ] ) using the result in proposition [ upb ]",
    ", we will choose @xmath149 so that the resulting @xmath0-cusum stopping rule @xmath109 .",
    "that is , @xmath150 to this end , we derive a lower bound for the mean time to the first false alarm @xmath151 , which is robust with respect to the covariance matrix @xmath152 . in the sequel",
    ", we first study the case of equal drift size with complete information , where @xmath153 are known constant , and then treat the case of unequal drift size with complete information , such that @xmath75 s are all known and @xmath154 holds for some @xmath155 .",
    "finally , we study the general case with partial information , where we only know @xmath156 and the intervals @xmath157\\ni\\mu_i$ ] for all @xmath17 .      in this case",
    ", it is assumed that all @xmath75 are known and @xmath158 for all @xmath8 .",
    "then the monotonicity of function @xmath118 and ( [ hi ] ) imply that @xmath159 for the @xmath0-cusum stopping rule .",
    "hence , with a slight abuse of notation , we denote by @xmath160 .",
    "below we derive a lower bound for the mean time of the first false alarm of the latter .",
    "[ thm : false_alarm ] suppose that all thresholds of the @xmath0-cusum stopping rule are chosen to be equal to @xmath161 .",
    "then the first false alarm for the @xmath0-cusum stopping rule @xmath162 satisfies @xmath163 where the function @xmath118 is defined in ( [ g ] ) .    for any @xmath8",
    ", we have @xmath164 \\label{r1 } \\\\[-8pt ] \\nonumber & = & \\mathbb{e}_{\\infty,\\ldots,\\infty}\\ { t_h \\ } + \\mathbb{e}_{\\infty,\\ldots,\\infty } \\bigl\\ { \\mathbb{e}_{\\infty , \\ldots,\\infty}\\bigl\\ { t_h^{i } - t_h | \\mathcal{f}_{t_h } \\bigr\\ } \\mathbf{1}_{\\{t_h^{i } \\neq t_h\\ } } \\bigr\\ } , \\nonumber\\end{aligned}\\ ] ] where the third equality follows from the tower property of the conditional expectation and the finiteness of @xmath101 .    as in the proof of proposition [ upb ] , we apply it s formula to @xmath165 ( see , e.g. , @xcite , theorem  4.1.2 ) to obtain that @xmath166 where the process @xmath167 is given by ( [ 1dimpr ] ) and the continuous square integrable martingale @xmath168 ( with respect to @xmath41 ) is given by @xmath169 taking into account that the process @xmath167 decreases only on the random set and the measure @xmath170 off this set , together with the fact that @xmath143 , we conclude that the integral in ( [ ito s expansion ] ) can be set equal to zero .",
    "we then take the conditional expectations with respect to the probability measure @xmath41 in ( [ ito s expansion ] ) and by means of the doob s optional sampling theorem ( see , e.g. , @xcite , chapter  1 , theorem  3.22 ) , we have @xmath171 therefore , using equation ( [ ito ] ) in the expression of ( [ r1 ] ) we have that @xmath172 \\label{r3 } \\\\[-8pt ] \\nonumber & = &   \\mathbb{e}_{\\infty,\\ldots,\\infty}\\ { t_h \\ } + \\mathbb{e}_{\\infty,\\ldots,\\infty } \\biggl\\ { \\frac{2}{\\mu^2 } \\bigl(g(h ) - g\\bigl(y^{(i)}_{t_h } \\bigr)\\bigr ) \\mathbf{1}_{\\{t_h^{i } \\neq t_h\\ } } \\biggr\\ } \\nonumber \\\\ & \\leq & \\mathbb{e}_{\\infty,\\ldots,\\infty}\\ { t_h \\ } + \\frac{2}{\\mu^2 } g(h ) \\mathbb{p}_{\\infty,\\ldots,\\infty } \\bigl ( t_h^{i } \\neq t_h \\bigr ) , \\nonumber\\end{aligned}\\ ] ] where the first equality and the function @xmath118 are given by ( [ g ] ) and the third equality follows from the definition of the one - dimensional cusum stopping rule in ( [ cusum1chart ] ) .",
    "it follows that @xmath173 hence , by summing both sides over all @xmath8 , we get @xmath174 which completes the proof of ( [ lbsame ] ) .    as a result of proposition [ thm : false_alarm ]",
    ", when @xmath175 for all @xmath8 , for any @xmath72 and any @xmath0-dimensional , predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 , we can choose the threshold @xmath177 using @xmath178 then we will have @xmath109 .",
    "moreover , proposition [ upb ] implies that , both the optimal detection delay @xmath179 and the detection delay of this @xmath0-cusum stopping rule @xmath180 , are bounded above by @xmath181 .      in this case",
    ", it is assumed that all @xmath75 are known and @xmath182 holds for some @xmath155 .",
    "then the monotonicity of function @xmath118 and ( [ hi ] ) imply that @xmath183 , for the @xmath0-cusum stopping rule @xmath106 .",
    "when @xmath92 s are all big , the condition ( [ hi ] ) is approximately a linear constraint on @xmath92 s , and hence @xmath184 .",
    "intuitively , with high chances , @xmath185 for @xmath186 will proceed @xmath187 for @xmath188 due to their smaller thresholds .",
    "hence , it is expected that @xmath189 , where the inequality follows from ( [ lbsame ] ) .",
    "below we rigorously show the validness of this heuristic argument .",
    "[ thm : false_alarm_k ] suppose that the drifts @xmath75 of the observation processes @xmath190 , @xmath8 are such that @xmath191 holds .",
    "suppose also that the thresholds @xmath108 satisfy ( [ hi ] ) .",
    "then the mean time to the first false alarm for the @xmath0-cusum stopping rule @xmath101 satisfies @xmath192 \\label{lbsamek } \\\\[-8pt ] \\nonumber & = &   \\biggl(1-\\sum _ { j = k+1}^n\\frac{\\mu _ j^2}{\\mu_1 ^ 2}\\frac{g(h_1)}{g(h_{j } ) } \\biggr ) \\frac{2}{k\\mu_1 ^ 2 } g(h_1),\\end{aligned}\\ ] ] where the function @xmath118 is defined in ( [ g ] ) .",
    "let us denote by @xmath193 . for any @xmath188 , following similar arguments to the ones in ( [ r1 ] ) through ( [ r3 ] )",
    ", we have in this case that @xmath194 which implies that @xmath195 on the other hand , for any @xmath186 , we similarly have @xmath196 which implies that @xmath197 summing up both sides of the above inequality for all @xmath186 , we obtain that @xmath198 \\label{fal2p } \\\\[-8pt ] \\nonumber & = & \\frac{2}{\\mu_1 ^ 2 } g(h_1 ) \\bigl[1-\\mathbb{p}_{\\infty,\\ldots,\\infty}(t_\\hbar \\neq r_{h_1})\\bigr].\\end{aligned}\\ ] ] however , we also have @xmath199 where we used ( [ eq : bound_prob ] ) in the above inequality .",
    "it follows from ( [ fal2p ] ) and ( [ p2 g ] ) that @xmath200 which completes the proof .    as a result of proposition [ thm : false_alarm_k ] , when @xmath201 , then for any @xmath72 and any @xmath0-dimensional , predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 , we can choose the set of thresholds @xmath108 using ( [ hi ] ) and the transcendental equation @xmath202 \\label{inequalh } \\\\[-8pt ] \\nonumber & & \\qquad = \\biggl(1-\\sum _ { j = k+1}^n\\frac{\\mu_j^2}{\\mu_1 ^ 2}\\frac{\\mathrm{e}^{h_1}-h_1 - 1}{\\mathrm{e}^{h_{j}}-h_{j}-1 } \\biggr)\\frac{2}{k\\mu _ 1 ^ 2}\\bigl(\\mathrm{e}^{h_1}-h_1 - 1\\bigr)= \\gamma,\\end{aligned}\\ ] ] then the resulting @xmath0-cusum stopping rule @xmath203 .",
    "again , proposition [ upb ] then implies that , both the optimal detection delay @xmath179 and the detection delay of this @xmath0-cusum stopping rule @xmath121 , are bounded above by @xmath204 .      in this case",
    ", it is assumed that only @xmath205 , @xmath17 , are known , and that @xmath206 . without loss of generality , we assume that @xmath207 holds for some @xmath208 .",
    "[ thm : false_alarm_k1 ] suppose that the drifts @xmath75 of the observation processes @xmath190 , @xmath8 are such that @xmath209 holds and @xmath19 $ ] for all @xmath17 .",
    "suppose also that the thresholds @xmath108 satisfy ( [ hi1 ] ) .",
    "then the mean time to the first false alarm for the @xmath0-cusum stopping rule @xmath101 satisfies @xmath210 \\label{lbsamek1}\\\\[-12pt ] \\nonumber & & \\qquad \\ge \\frac{2}{\\sum_{1\\le i\\le k'}\\mu_1(2\\overline{\\mu}_i-\\mu_1 ) } \\biggl(1-\\sum_{k'+1\\le j\\le n } \\frac { \\underline{\\mu}_j(2\\overline{\\mu}_j-\\underline{\\mu_j})}{\\mu_1 ^ 2 } \\frac{g(h_1)}{g(h_j ) } \\biggr ) g(h_1),\\hspace*{-23pt}\\end{aligned}\\ ] ] where the function @xmath118 is defined in ( [ g ] ) .    according to ( [ hi1 ] ) , we have @xmath211 .",
    "let us denote by @xmath212 .",
    "similar ( [ eq : bound_prob ] ) in the proof of proposition [ thm : false_alarm_k1 ] , for any @xmath213 , we have @xmath214 it follows that @xmath215 which implies that @xmath216 \\label{eq : bound_prob1 } \\\\[-8pt ] \\nonumber & \\le & \\sum_{k'+1\\le j\\le n}\\frac{\\underline{\\mu}_j(2\\overline{\\mu } _",
    "j-\\underline{\\mu_j})}{\\mu_1 ^ 2 } \\frac{g(h_1)}{g(h_j)}.\\end{aligned}\\ ] ] on the other hand , for any @xmath217 , by it s formula ( see , e.g. , @xcite , theorem  4.1.2 ) we have @xmath218 which implies that @xmath219 summing up both sides of the above inequality for all @xmath217 , we obtain that @xmath220 \\\\[-8pt ] \\nonumber & & \\qquad = g(h_1)\\bigl[1-\\mathbb{p}_{\\infty,\\ldots,\\infty}(t_\\hbar\\neq r_{h_1})\\bigr ] \\\\ & & \\qquad\\ge g(h_1 ) \\biggl(1-\\sum_{k'+1\\le j\\le n } \\frac{\\underline{\\mu } _",
    "j(2\\overline{\\mu}_j-\\underline{\\mu_j})}{\\mu_1 ^ 2 } \\frac { g(h_1)}{g(h_j ) } \\biggr ) , \\nonumber\\end{aligned}\\ ] ] where we used ( [ eq : bound_prob1 ] ) in the last step .",
    "the conclusion of the proposition follows immediately .    as a result of proposition [ thm : false_alarm_k1 ] ,",
    "when we only known @xmath156 and possible ranges for other drift @xmath75 s , given any @xmath221 and any @xmath0-dimensional , predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 , we can choose the set of thresholds  @xmath108 using ( [ hi1 ] ) and the transcendental equation @xmath222 then the resulting @xmath0-cusum stopping rule @xmath223 .",
    "again , proposition [ upb ] then implies that both the optimal detection delay @xmath179 and the detection delay of this @xmath0-cusum stopping rule @xmath121 , are bounded above by @xmath204 .      in this subsection",
    ", we present a robust lower bound for the optimal detection delay @xmath179 .",
    "in fact , we can prove a stronger statement : for any stopping rule @xmath224 , its detection delay @xmath225 , is bounded below by the optimal detection delay in one dimension .",
    "the proof is accomplished by a change of measure argument as in @xcite plus a decomposition formula for the radon  nikodym derivative in @xmath0 dimensions .",
    "[ lem : girsanov ] let @xmath226 be the law of the @xmath0-tuple process @xmath227 for the brownian motions defined in ( [ itodynamics ] ) . and",
    "let @xmath228 be the law of the @xmath0-tuple process @xmath229 .",
    "then for all @xmath230 , @xmath231 where @xmath232 is defined in ( [ 1dimpr ] ) and @xmath233 is the stochastic exponential of the local martingale @xmath234 defined in ( [ bt])([wtb ] ) .",
    "moreover , the standard brownian motions driving @xmath234 are independent of @xmath235 .",
    "the proof can be found in the .",
    "[ lemmalb ] for any stopping rule @xmath236 , we have @xmath237 , where @xmath79 satisfies @xmath238 for the function @xmath118 defined in  ( [ g ] ) .",
    "let @xmath53 be an arbitrary @xmath56-stopping rule such that @xmath239 holds and observe that @xmath240 where @xmath241 , a.s .",
    ", and @xmath242 is the cusum stopping rule given in ( [ 1dimcusumstop ] ) for some threshold @xmath243 which will be determined later . clearly , @xmath244 is a finite stopping rule . in",
    "what follows , we will demonstrate that for any given @xmath245 , there exists a @xmath246 such that @xmath247 where @xmath248 is chosen so that @xmath249 and the function @xmath118 is given by ( [ g ] ) . because @xmath250 in ( [ ineq2 ] ) can be arbitrarily small , ( [ new index ] ) and ( [ ineq2 ] )",
    "will imply the assertion in the proposition for @xmath251 .",
    "this is in a similar light as in @xcite .    by applying it s formula ( see , e.g. , @xcite , theorem 4.1.2 and @xcite ) to @xmath252 and proceed by using similar arguments as in ( [ ito s expansion])([ito ] ) in proposition [ thm : false_alarm ]",
    ", we obtain that , for any fixed @xmath253 , @xmath254 \\label{ito 1d } \\\\[-8pt ] \\nonumber & & \\qquad   = \\frac{2}{\\mu_1 ^ 2 } \\mathbb{e}_{s,\\infty,\\ldots,\\infty } \\bigl\\ { g\\bigl(-y_{t_\\nu } ^{(1)}\\bigr ) - g\\bigl(-y_{s}^{(1 ) } \\bigr ) | \\mathcal{f}_{s}\\bigr\\ } { \\bf1}_{\\{t_\\nu \\ge s \\}}.\\\\[-18pt ] \\nonumber\\end{aligned}\\]]using girsanov s theorem ( see , e.g. , @xcite , chapter  3 , theorem  5.1 ) and lemma  [ lem : girsanov ] at the finite stopping rule @xmath255 for a fixed @xmath256 , we have that @xmath257 \\big| \\mathcal{f}_{s } \\biggr\\}\\\\ & & \\quad\\qquad{}\\times\\mathbf{1}_{\\{t_\\nu \\wedge n > s\\}}.\\end{aligned}\\ ] ] consider the enlargement of filtration @xmath258 .",
    "then clearly , @xmath259 for all @xmath260 , but on the event @xmath261 , for all @xmath262\\subset[0,t_\\nu^1]$ ] , we have @xmath263 . by the tower property of conditional expectation , on the event that @xmath264 , @xmath265 \\big| \\mathcal{f}_{s } \\biggr\\ } \\nonumber \\\\ & & \\qquad = \\mathbb{e}_{\\infty,\\ldots,\\infty } \\biggl\\{\\mathrm{e}^{u_{t_\\nu \\wedge n}^{(1 ) } - u_{s}^{(1 ) } } \\bigl[g \\bigl(-y_{t_\\nu\\wedge n}^{(1)}\\bigr)-g\\bigl(-y_{s}^{(1 ) } \\bigr)\\bigr ] \\nonumber \\\\[-8pt ] \\label{girsanov1}\\\\[-8pt ] \\nonumber & & { } \\hspace*{47pt}\\qquad\\quad{}\\times \\mathbb{e } _ { \\infty,\\ldots,\\infty } \\biggl\\{\\frac{\\mathcal{e}(b^{(1)})_{t_\\nu \\wedge n}}{\\mathcal{e}(b^{(1)})_{s } } \\big| \\mathcal{f}_{s}^a \\biggr\\ } \\big| \\mathcal { f}_{s } \\biggr\\ } \\\\ & & \\qquad = \\mathbb{e}_{\\infty,\\ldots,\\infty } \\bigl\\ { \\mathrm{e}^{u_{t_\\nu \\wedge n}^{(1 ) } - u_{s}^{(1 ) } } \\bigl[g \\bigl(-y_{t_\\nu\\wedge n}^{(1)}\\bigr)-g\\bigl(-y_{s}^{(1 ) } \\bigr)\\bigr ] | \\mathcal{f}_{s } \\bigr\\ } , \\nonumber\\end{aligned}\\ ] ] where the last equality is due to the fact that @xmath266 is a @xmath267-exponential martingale [ under assumption equation ( [ eq : nov ] ) ] driven by brownian motions that are independent of @xmath235 ( see lemma [ lem : girsanov ] ) .",
    "similarly , it can be shown that @xmath268 we now let @xmath269 in ( [ girsanov1 ] ) and ( [ girsanov2 ] ) . from the fact that @xmath270 , and the monotonicity of function @xmath271 , we have that @xmath272 and",
    "thus the bounded convergence theorem implies that , on the event @xmath273 , @xmath274 \\label{e88g}\\\\[-8pt ] \\nonumber & & \\qquad   = \\mathbb{e}_{\\infty,\\ldots,\\infty}\\bigl\\{\\mathrm{e}^{u_{t_\\nu } ^{(1)}-u_{s}^{(1 ) } } \\bigl[g \\bigl(-y_{t_\\nu}^{(1)}\\bigr)-g\\bigl(-y_{s}^{(1 ) } \\bigr)\\bigr ] | \\mathcal{f}_{s}\\bigr\\}.\\end{aligned}\\ ] ] it follows from ( [ new index ] ) , ( [ ito 1d ] ) , ( [ e88 ] ) and ( [ e88 g ] ) that @xmath275 \\label{ineq } \\\\[-8pt ] \\nonumber & & \\qquad \\ge \\mathbb{e}_{s,\\infty,\\ldots,\\infty}\\bigl\\{(t_\\nu - s)^+ | \\mathcal{f}_{s}\\bigr\\}\\mathbf{1}_{\\{t_\\nu > s\\ } } \\\\ & & \\qquad= \\frac{2}{\\mu_1 ^ 2}\\mathbb{e}_{\\infty,\\ldots,\\infty}\\bigl\\{\\mathrm{e}^{u_{t_\\nu } ^{(1)}-u_{s}^{(1 ) } } \\bigl[g\\bigl(-y_{t_\\nu}^{(1)}\\bigr)-g\\bigl(-y_{s}^{(1 ) } \\bigr)\\bigr ] | \\mathcal{f}_{s}\\bigr\\}\\mathbf{1}_{\\{t_\\nu > s\\}}. \\nonumber\\end{aligned}\\ ] ] following the same arguments as in theorem 2 of @xcite , we integrate both sides of the above inequality with respect to @xmath276 for all @xmath277 $ ] and then take the expectation under @xmath41 .",
    "we therefore obtain that @xmath278\\bigl(-{d}m_{s}^{(1 ) } \\bigr ) \\biggr\\}.\\end{aligned}\\ ] ] notice that the measure @xmath279 is supported on the random set @xmath280 , and that @xmath281 , thus we obtain that @xmath282 g\\bigl(-y_{t_\\nu } ^{(1 ) } \\bigr)\\bigr\\}.\\ ] ] on the other hand , by letting @xmath283 in ( [ ineq ] ) we have that @xmath284 in all , we have that @xmath285 holds .",
    "to relate the detection delay in ( [ ineq3 ] ) to the first false alarm constraint @xmath73 , we use similar arguments as in ( [ ito s expansion])([ito ] ) in proposition [ thm : false_alarm ] , to obtain that @xmath286 by taking the limit as @xmath287 and using monotone convergence theorem , we have that @xmath288 , and @xmath289 , which implies that there exists a large enough @xmath243 , such that @xmath290 holds for any prespecified @xmath245 . now consider the nonnegative function @xmath291 - g(y ) + g(\\nu^\\star_1)$ ] , using which we trivially have @xmath292 , implying that @xmath293 \\label{ineqe } \\\\[-8pt ] \\nonumber & \\ge & \\mathbb{e}_{\\infty,\\ldots,\\infty}\\bigl\\{\\mathrm{e}^{y_{t_\\nu } ^{(1)}}\\bigr\\ } g\\bigl(- \\nu^\\star_1\\bigr ) -",
    "\\frac{\\mu_1 ^ 2}{2 } \\varepsilon \\\\ & \\ge & \\mathbb{e}_{\\infty,\\ldots,\\infty}\\bigl\\{\\mathrm{e}^{y_{t_\\nu } ^{(1)}}\\bigr\\ } \\biggl[g \\bigl(-\\nu^\\star_1\\bigr ) -",
    "\\frac{\\mu_1 ^ 2}{2 } \\varepsilon \\biggr ] , \\nonumber\\end{aligned}\\ ] ] since @xmath294 .",
    "the above inequality in ( [ ineqe ] ) together with ( [ ineq3 ] ) yields  ( [ ineq2 ] ) , which completes the proof .",
    "in this section , we demonstrate the asymptotic optimality of the @xmath0-cusum stopping rule @xmath106 for @xmath108 chosen such that ( [ hi ] ) and either ( [ equalh ] ) or ( [ inequalh ] ) hold , or ( [ hi1 ] ) and ( [ inequalh1 ] ) hold . to this end , we examine the asymptotic behavior of the robust upper and low bounds established in section  [ robust ] .",
    "we show that the additional detection delay of @xmath101 over the optimal detection delay remains bounded as the mean time of the first false alarm  @xmath73 increases without bound .",
    "let any sufficiently large @xmath72 and recall from section  [ robust ] ( in particular propositions [ upb ] and [ lemmalb ] ) that the optimal detection delay in ( [ eqnproblem ] ) is bounded from below and above as @xmath295 where the set of thresholds @xmath248 and @xmath108 is , respectively , determined using @xmath296 and either ( [ hi ] ) together with ( [ equalh ] ) or with ( [ inequalh ] ) , or ( [ hi1 ] ) together with ( [ inequalh1 ] ) , when the drifts sizes @xmath75 are all known and equal or unequal , are different , we do not necessarily require the uniqueness of @xmath108 that solves ( [ hi ] ) and ( [ inequalh ] ) . ] or partially known , respectively .",
    "it is easily seen from result 3 in the appendix of @xcite that , as @xmath297 , @xmath298    moreover , when all the drifts are known and @xmath299 for all @xmath8 , the thresholds @xmath300 for all @xmath8 . using ( [ equalh ] ) and result 3 in the appendix of @xcite we have that , as @xmath297 , @xmath301 \\label{up1 } \\frac{2}{\\mu_1 ^ 2 } g(-h_1)&=&\\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log \\frac{n \\mu _ 1 ^ 2}{2}+\\log\\gamma-1+o(1 ) \\biggr).\\end{aligned}\\ ] ] as a result , we have the following optimality result .    [ thm1 ]",
    "assume that the drift sizes are all known and @xmath302 for all @xmath8 .",
    "then for any predictable , nonsingular , stochastic instantaneous correlation matrix covariance matrix @xmath176 , the @xmath0-cusum stopping rule @xmath101 defined in algorithm [ ncusum ] , where the set of thresholds @xmath108 is chosen using ( [ hi ] ) and  ( [ equalh ] ) , is asymptotically optimal to the problem ( [ eqnproblem ] ) .",
    "more specifically , the difference between the detection delay of the @xmath0-cusum stopping rule , @xmath303 , and the optimal detection delay @xmath179 , is bounded above by @xmath304 , as .",
    "the result follows from ( [ ubj ] ) , ( [ lowbound1 ] ) and ( [ up1 ] ) : @xmath305 & \\le & \\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log\\frac{n \\mu_1 ^ 2}{2}+\\log\\gamma- 1 + o(1 ) \\biggr ) - \\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log\\frac{\\mu_1 ^ 2}{2}+\\log \\gamma -1+o(1 ) \\biggr ) \\\\[-2pt ] & = & \\frac{2}{\\mu_1 ^ 2}\\log n+o(1),\\end{aligned}\\ ] ] as @xmath297 .    on the other hand , in the more general case that the drifts are all known and @xmath306 , using ( [ hi ] ) , ( [ inequalh ] ) and",
    "result 3 in the appendix of  @xcite , we obtain that @xmath307 \\label{up2 } \\frac{2}{\\mu_1 ^ 2 } g(-h_1)&=&\\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log \\frac{k \\mu _",
    "1 ^ 2}{2}+\\log\\gamma-1+o(1 ) \\biggr).\\end{aligned}\\ ] ] it follows that we have the following optimality result .    [ thm2 ]",
    "assume that the drift sizes are known and @xmath308 .",
    "then for any predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 , the @xmath0-cusum stopping rule @xmath101 defined in algorithm  [ ncusum ] , where the set of thresholds @xmath108 is chosen using ( [ hi ] ) and ( [ inequalh ] ) , is asymptotically optimal to the problem ( [ eqnproblem ] ) .",
    "more specifically , the difference between the detection delay of the @xmath0-cusum stopping rule , @xmath121 , and the optimal detection delay @xmath179 , is bounded above by @xmath309 , as @xmath297 .",
    "in particular , if @xmath310 , then @xmath101 is equivalent to the optimal solution to ( [ eqnproblem ] ) asymptotically .",
    "the result follows from ( [ ubj ] ) , ( [ lowbound1 ] ) and ( [ up2 ] ) : @xmath311 & \\le&\\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log\\frac{k \\mu_1 ^ 2}{2}+\\log\\gamma- 1 + o(1 ) \\biggr ) - \\frac{2}{\\mu_1 ^ 2 } \\biggl(\\log\\frac{\\mu_1 ^ 2}{2}+\\log \\gamma -1+o(1 ) \\biggr ) \\\\[-2pt ] & = & \\frac{2}{\\mu_1 ^ 2}\\log k+o(1),\\end{aligned}\\ ] ] as @xmath297 . if @xmath310 , the above upper bound for @xmath312 is @xmath313 , and hence , the @xmath0-cusum stopping rule is equivalent to the optimal solution to ( [ eqnproblem ] ) asymptotically .    finally ,",
    "if we only know @xmath156 and have partial information about other drifts , that is , @xmath314 $ ] for all @xmath17 and @xmath315 for some @xmath316 . using ( [ hi1 ] ) , ( [ inequalh1 ] ) and",
    "result 3 in the appendix of @xcite , we obtain that @xmath317 \\label{up22 } \\frac{2}{\\mu_1 ^ 2 } g(-h_1)&=&\\frac{2}{\\mu_1",
    "^ 2 } \\biggl(\\log \\frac{\\sum_{1\\le i\\le k'}\\mu_1(2\\overline{\\mu}_i-\\mu_1)}{2}+\\log\\gamma-1+o(1 ) \\biggr).\\end{aligned}\\ ] ] it follows that we have the following optimality result .    [ thm3 ]",
    "assume that the @xmath156 is known , @xmath318 $ ] for all @xmath17 and that @xmath319 for some @xmath320",
    ". then for any predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 , the @xmath0-cusum stopping rule @xmath101 defined in algorithm  [ ncusum ] , where the set of thresholds @xmath108 is chosen using ( [ hi1 ] ) and ( [ inequalh1 ] ) , is asymptotically optimal to the problem ( [ eqnproblem ] ) .",
    "more specifically , the difference between the detection delay of the @xmath0-cusum stopping rule , @xmath121 , and the optimal detection delay @xmath179 , is bounded above by @xmath321 as @xmath297 .",
    "in particular , if @xmath322 , then @xmath101 is equivalent to the optimal solution to  ( [ eqnproblem ] ) asymptotically .",
    "the result follows from ( [ ubj ] ) , ( [ lowbound1 ] ) and ( [ up22 ] ) : @xmath323 as @xmath297 .",
    "if @xmath322 , the above upper bound for @xmath312 is @xmath313 , and hence , the @xmath0-cusum stopping rule is equivalent to the optimal solution to ( [ eqnproblem ] ) asymptotically .    from definition [ optdef",
    "] , we know that the order of the asymptotic optimality achieved in theorems [ thm1 ] , [ thm2 ] , [ thm3 ] is of the second order . if @xmath156 is strictly smaller than all the other drifts ( @xmath310 in theorem [ thm2 ] and @xmath322 in theorem [ thm3 ] ) , then the @xmath0-cusum stopping rule given by algorithm [ ncusum ] , and either ( [ hi ] ) and ( [ inequalh ] ) , or ( [ hi1 ] ) and ( [ inequalh1 ] ) exhibits third - order asymptotic optimality .",
    "moreover , it can be seen after a perusal of the proofs that the order of the asymptotic optimality of the @xmath0-cusum does not change if we model @xmath75 s as @xmath267-adapted processes bounded by known constants @xmath324 and @xmath325 , for all @xmath17 .",
    "in this section , we discuss one of the applications of the results in decentralized communication systems .",
    "let us now suppose that each of the observation processes @xmath326 become sequentially available at a particular location monitored by sensor @xmath91 , which then employs an asynchronous communication scheme to a central fusion center .",
    "in particular , sensor @xmath91 communicates to the central fusion center only when it wants to signal an alarm , which is elicited according to a cusum stopping rule @xmath89 as in ( [ cusum1chart ] ) adapted to the small filtration @xmath327 .",
    "the observations received at the @xmath0 sensors can change dynamics at distinct unknown points @xmath69 .",
    "an example of such a case is described in @xcite where the motivation suggested arises in the health - monitoring of mechanical , civil and aeronautic structures .",
    "the fusion center , whose objective is to detect the first time when there is a change in at least one of the sensors devises a minimal strategy ; that is , it declares that a change has occurred at the first instance when one of the sensors communicates an alarm .",
    "the implication of the main theorems in section  [ asympt ] is that in fact this strategy is the best , at least asymptotically , in that there is no loss in performance , between the case in which the fusion center receives the raw data @xmath328 summarized in the large filtration @xmath329 directly and the case in which the communication that takes place is limited to the decentralized setup . in other words , the cusum stopping rule @xmath101 is a sufficient statistic ( at least asymptotically ) of the minimum @xmath0 possibly distinct change points .",
    "that is , the stopping rule @xmath101 is an asymptotically optimal solution to the problems of quickest detection presented in ( [ eqnproblem ] ) . in practice sensors",
    "are cheap and easy to replace devices whereas central fusion centers or central processing units are not .",
    "transferring most of the processing work to the sensors while incurring no loss in the efficiency of the system is thus valuable and can render cost and speed effective communication systems .",
    "in this paper , we study the problem of detecting the minimum of @xmath0 different change points in a @xmath0-dimensional brownian system with partial information of the drifts and an arbitrary , predictable , nonsingular , stochastic instantaneous correlation matrix @xmath176 .",
    "it is shown that , under an extended lorden s minmax criterion , the @xmath0-cusum stopping rule exhibits asymptotic optimality in the tradeoff between detection delay and false alarms , as the mean time to the first false alarm increases without bound . moreover ,",
    "the performance of the @xmath0-cusum stopping rule under dependence is _ no worse than _ that under independence @xcite .",
    "this optimality result is obtained by establishing a robust upper bound and a robust lower bound for the optimal detection delay .",
    "the contribution of this work can be seen in two folds .",
    "first , we designed a low complexity , efficient stopping rule without using the explicit information of the covariance matrix @xmath176 .",
    "this stopping rule is guaranteed to have a comparable performance or identical performance as the optimal stopping rule , even with cross - correlated observations  a nontrivial extension to the existing literature and the first formal treatment of correlated noise in change - point detection .",
    "second , the robust bounds obtained in this work provide a unified robust probabilistic ( rather than analytical ) approach to treat detection problems with multiple change - points or multiple alternatives @xcite .",
    "this is especially useful when the analytical characteristic such as joint density or green functions are not explicitly available .",
    "let us denote by @xmath330 the @xmath331 matrix obtained from @xmath176 by removing its first column and first row , and by @xmath332 the @xmath331 matrix @xmath333 .",
    "we further introduce a local martingale    @xmath334 \\label{bt}\\\\[-8pt ] \\nonumber & & \\hspace*{34pt}{}\\times \\bigl(\\sqrt { 1-\\bigl(\\rho_s^{2,1}\\bigr)^2}\\,{d}\\tilde { w}_s^{(2 ) } , \\ldots , \\sqrt{1-\\bigl ( \\rho_s^{n,1}\\bigr)^2}\\,{d}\\tilde { w}_s^{(n ) } \\bigr ) ' , \\\\",
    "\\label{wtb } \\tilde{w}_t^{(i)}&= & \\int _ 0^t\\frac{{d}w_s^{(i)}-\\rho_s^{i,1}\\,{d}w_s^{(1)}}{\\sqrt{1-(\\rho _ s^{i,1})^2 } } , \\qquad 2\\le i\\le n.\\end{aligned}\\ ] ] the local martingale @xmath335 will naturally appear in ( [ eq : last ] ) of the following proof .",
    "we are now ready to prove the assertion in lemma [ lem : girsanov ] .",
    "proof of lemma [ lem : girsanov ] since @xmath176 is nonsingular at all time a.s .",
    ", we can use a cholesky decomposition to obtain a lower triangular , nonsingular matrix - valued process @xmath336 , and a @xmath0-dimensional standard brownian motion @xmath337 , such that @xmath338 holds .",
    "in particular , we have @xmath339 , @xmath340 , and @xmath341 for all @xmath342 . using girsanov s theorem ( see , e.g. , @xcite , chapter  3 , theorem  5.1 ) and the condition in ( [ eq : nov ] )",
    ", the measure changes from @xmath343 to @xmath228 is given by the exponential martingale @xmath344 where @xmath345 is a @xmath0-tuple process , such that @xmath346 it is easily seen that @xmath347 .",
    "moreover , from @xmath341 for any @xmath348 , we know that @xmath349 where @xmath350 is a @xmath351 nonsingular matrix - valued process . on the other hand , notice that @xmath352 \\label{n2}\\\\[-8pt ] \\nonumber & & \\qquad=(\\tilde{l}_t)^{-1 } \\bigl({d}w_t^{(2)}-\\rho_{t}^{2,1}\\,{d}w_t^{(1 ) } , \\ldots , { d}w_t^{(n)}- \\rho _ { t}^{n,1}\\,{d}w_t^{(1 ) } \\bigr)'.\\hspace*{-6pt } \\ ] ] using the equations in ( [ n1 ] ) and ( [ n2 ] ) , we conclude that @xmath353 & & \\qquad = \\int_0^t\\nu_s^{(1 ) } \\,{d}z_s^{(1)}+\\int_0^t \\bigl(\\nu_s^{(2)},\\ldots , \\nu_s^{(n ) } \\bigr ) \\bigl({d}z_s^{(2)},\\ldots , { d}z_s^{(n ) } \\bigr ) ' \\nonumber \\\\[-2pt ] & & \\qquad = \\mu_1 w_t^{(1)}-\\mu_1\\int _ 0^t\\bigl(\\rho_s^{2,1 } , \\ldots,\\rho _",
    "s^{n,1}\\bigr ) \\bigl(\\tilde { l}_s ' \\bigr)^{-1}(\\tilde{l}_s)^{-1}\\nonumber\\\\[-2pt ] & & \\label{eq : last } \\qquad\\qquad\\hspace*{60pt } { } \\times \\bigl({d}w_s^{(2)}-\\rho _ { s}^{2,1}\\,{d}w_s^{(1 ) } , \\ldots , { d}w_s^{(n)}- \\rho_{s}^{n,1}\\,{d}w_s^{(1 ) } \\bigr ) ' \\\\[-2pt ] & & \\qquad=\\mu_1 w_t^{(1)}-\\mu_1\\int _ 0^t\\bigl(\\rho_s^{2,1 } , \\ldots,\\rho _",
    "s^{n,1}\\bigr ) \\bigl(\\sigma _",
    "\\tilde{\\sigma}_s^1\\bigr)^{-1}\\nonumber\\\\ & & \\hspace*{60pt}\\qquad\\qquad{}\\times \\bigl(\\sqrt { 1-\\bigl(\\rho_s^{2,1}\\bigr)^2}\\,{d}\\tilde { w}_s^{(2 ) } , \\ldots , \\sqrt{1-\\bigl ( \\rho_s^{n,1}\\bigr)^2}\\,{d}\\tilde { w}_s^{(n ) } \\bigr ) ' \\nonumber \\\\[-2pt ] & & \\qquad=\\mu_1 w_t^{(1)}+b_t^{(1 ) } , \\nonumber\\end{aligned}\\ ] ] where the third equality follows from the fact that @xmath354 holds ( see accompanying internet supplement ) .",
    "finally , by the way we construct @xmath335 , we know that the brownian motions that drive @xmath335 and @xmath235 are independent and this completes the proof .",
    "the authors are grateful to the editor and anonymous referees for their comments contributing to the improvement of this manuscript ."
  ],
  "abstract_text": [
    "<S> we study a wiener disorder problem of detecting the minimum of @xmath0 change - points in @xmath0 observation channels coupled by correlated noises . it is assumed that the observations in each dimension can have different strengths and that the change - points may differ from channel to channel . </S>",
    "<S> the objective is the quickest detection of the minimum of the @xmath0 change - points . </S>",
    "<S> we adopt a min  </S>",
    "<S> max approach and consider an extended lorden s criterion , which is minimized subject to a constraint on the mean time to the first false alarm . </S>",
    "<S> it is seen that , under partial information of the post - change drifts and a general nonsingular stochastic correlation structure in the noises , the minimum of  @xmath0 cumulative sums ( cusum ) stopping rules is asymptotically optimal as the mean time to the first false alarm increases without bound . </S>",
    "<S> we further discuss applications of this result with emphasis on its implications to the efficiency of the decentralized versus the centralized systems of observations which arise in engineering .    </S>",
    "<S> ./style / arxiv - general.cfg    , </S>"
  ]
}