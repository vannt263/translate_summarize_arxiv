{
  "article_text": [
    "the discontinuous galerkin ( dg ) time - stepping method is a single - step implicit scheme defined by a variational temporal discretization of parabolic evolution equations that generalizes the backward euler method to higher - order approximations @xcite . for an introduction to this time discretization scheme in the context of abstract parabolic problems ,",
    "we refer the reader to @xcite . in certain cases ,",
    "it coincides with the radau iia implicit runge  kutta ( irk ) schemes and the subdiagonal pad approximations to the exponential function @xcite .",
    "it can be coupled with standard spatial discretization schemes , such as finite difference , finite element or spectral methods ; in particular , when coupled to a spatial finite element method ( fem ) , it leads to a tensor - product space - time fem .",
    "the dg time - stepping method features many advantages that make it an attractive choice for solving parabolic problems .",
    "first , it permits arbitrarily high - order approximation to the solution , along with superconvergence at the time - step nodes @xcite , see also @xcite for optimal - order a priori error estimates in natural norms with explicit dependence on the polynomial degree . unlike linear multistep schemes ,",
    "it is thus not constrained by the dahlquist barrier theorem and it does not require an auxiliary scheme to compute the first few solution values .",
    "furthermore , the dg time - stepping method allows fully variable time - step sizes , approximation orders , and even spatial mesh refinement / coarsening between time - steps ; it is thus well - suited for adaptive algorithms driven by rigorous a posteriori error estimates @xcite .",
    "the dg time - stepping method also permits the temporal version of @xmath1-refinement , where one varies both the time - step size as well as the approximation order on each time - step , thereby yielding exponential convergence rates for a broad class of solutions with singularities induced by the initial datum or by the source term  @xcite . in these applications , it is common to use high temporal polynomial degrees in order to match the high - order spatial approximation , see for instance the experiments in  @xcite .    in applying the dg time - stepping method in practice , we are faced with the challenge of solving a large nonsymmetric linear system at each time - step . in this work ,",
    "we are interested in developing preconditioned iterative methods for solving these linear systems .",
    "we focus here on the dg time - stepping method in the context of an abstract semi - discrete evolution problem of the form @xmath2 where the solution @xmath3 { \\rightarrow}{\\mathsf{v}}$ ] , with @xmath4 a finite dimensional space , where @xmath5 and @xmath6 are symmetric positive definite matrices .",
    "semi - discrete problems of the form   arise from the application of a wide range of spatial discretizations , including conforming and nonconfirming finite elements , finite differences , and spectral methods , to a broad class of parabolic problems , such as general self - adjoint second - order and fourth - order parabolic partial differential equations ( pde ) . we emphasize that our results are valid for general symmetric positive definite matrices @xmath5 and @xmath6 , although the reader may consider the heat equation as a concrete example , with @xmath5 and @xmath6 respectively representing the mass and stiffness matrices for a suitable approximation space @xmath4 .",
    "the dg time - stepping method applied to the evolution problem   leads to a sequence of linear systems of the general block form @xmath7 where @xmath8 denotes the time - step size , the polynomial degree @xmath9 defines the approximation order of the scheme , the solution coefficients @xmath10 for @xmath11 , and , after mapping the time - step interval to the reference interval @xmath12 , we have @xmath13 where @xmath14 is a chosen basis of @xmath15 the space of real - valued polynomials of degree at most @xmath9 . for the case",
    "@xmath16 , the dg method reduces to the backward euler method and the system is therefore symmetric .",
    "however , for @xmath17 , the system matrix @xmath18 of is nonsymmetric with dimension  @xmath19 , which is considerably larger than for linear multistep methods ; even for moderate sizes of @xmath6 and @xmath5 , standard direct solution algorithms can be prohibitively expensive . unlike the block triangular linear systems obtained from diagonally irk ( dirk ) and singly diagonally irk ( sdirk ) schemes ( see @xcite and the references therein ) , the system   does not immediately reveal any simple structure offering a straightforward solution algorithm .",
    "see also @xcite for a discussion of sirk methods .",
    "since the dg time - stepping method is connected to the radau iia irk scheme , it is interesting to relate our approach to the literature on solving the systems of irk schemes . in particular , one of the earliest approaches",
    "@xcite for solving the linear systems of general irk schemes , such as  , is based on transforming the system matrix to a block - diagonal matrix with blocks of the form @xmath20 , where the @xmath21 denote here the generalized eigenvalues of @xmath22 with respect to @xmath23 , and where the transformation is given by the corresponding eigenvectors .",
    "this leads to @xmath24 independent smaller linear systems that can be solved in parallel .",
    "it turns out that for the dg time - stepping method , the generalized eigenvalues @xmath25 are complex numbers related to the roots of the denominator of a rational pad approximation to the exponential function .",
    "therefore , the resulting transformed system is complex - valued and non - hermitian despite @xmath5 and @xmath6 being symmetric .",
    "in addition to the increased computational cost of complex arithmetic , this approach has an important shortcoming in terms of robustness and numerical stability for high - order approximations , due to ill - conditioning of the eigenvector transformations , as pointed out in ( * ? ? ? * remark  5.4 ) .",
    "this issue can be avoided by employing alternative factorizations , at the expense of the block - diagonal structure of the transformed problem : @xcite propose a factorization based on the schur decomposition theorem , leading to a block - triangular complex transformed problem ; the solution is then obtained by solving @xmath24 complex non - hermitian systems in sequence .",
    "preconditioned iterative methods offer an alternative approach to decoupling the system by complex transformations . in this direction , @xcite",
    "propose a linear iterative fixed point scheme based on an approximation of the block lu factorization of @xmath18 , and they analyse the contraction rates of their method for @xmath26 .",
    "an alternative approach is to apply directly a preconditioned krylov subspace method to , as proposed in @xcite propose a block - diagonal preconditioner for irk schemes to be used with gmres .",
    "they show that the preconditioner is robust with respect to the time - step size @xmath8 , but their experiments show that it is not robust with respect to @xmath9 .",
    "@xcite develop a preconditioner specifically for the dg time - stepping method for @xmath27 ( as well as for the related continuous galerkin method of same size ) based on an approximate schur complement preconditioner for one of the unknown coefficients @xmath28 in .",
    "it is thus apparent from these references that finding preconditioning strategies for the dg time - stepping method that are robust with respect to the polynomial degree @xmath9 has been a challenging open problem .    in this work ,",
    "we propose a robust and efficient preconditioned iterative method for the dg time - stepping method . instead of focusing exclusively on the block structure of",
    ", our approach draws upon the inf - sup analysis of the method and the underlying continuous analysis of parabolic pdes , and we take advantage of the variational structure of the dg time - stepping method in an essential way .",
    "first , in section  [ sec : left_precond ] , we construct and apply a left - preconditioner @xmath29 to the linear system @xmath30 given by , resulting in a preconditioned system @xmath31 with the key benefit that the transformed matrix  @xmath32 is symmetric positive definite .",
    "we immediately point out that @xmath33 , i.e.  we are not forming the normal equations of the system . instead",
    ", our construction of @xmath29 is motivated by parabolic inf - sup theory , and we show that the matrix @xmath34 represents the discrete version of the natural parabolic energy norm of the underlying evolution equation : for example , in the context of second - order parabolic pdes , the matrix  @xmath34 is a discrete gram matrix for the natural solution space @xmath35 ; we refer the reader to @xcite for an introduction to the continuous analysis of parabolic problems .",
    "the transformed symmetric positive definite system can therefore be solved by the preconditioned conjugate gradient  ( pcg ) algorithm @xcite , which , in our case , minimizes the error in the physically relevant norm over a krylov subspace . in order to obtain the fast and robust convergence of the pcg algorithm , in section  [ sec : spect_equiv ] ,",
    "we construct a spectrally equivalent preconditioner @xmath36 for @xmath34 , such that the condition number of the preconditioned system satisfies @xmath37 independently of all parameters @xmath8 , @xmath9 , @xmath5 and @xmath6 .",
    "therefore , the preconditioner is fully _ robust _ with respect to all problem and discretization parameters , including the polynomial degree .",
    "furthermore , the preconditioners are _ efficient _ , firstly in the sense of guaranteeing the fast convergence of the pcg algorithm in the physically relevant norm , and secondly in the sense of computational cost , for the following reasons . in section  [ sec : implementation ] we show that the preconditioners are well - suited for parallelization over the blocks and involve only simpler matrices of the form @xmath6 and @xmath38 with real positive @xmath39 for which efficient solvers are often available .",
    "furthermore , we show experimentally in section  [ sec : num_exp ] that the ideal preconditioners can be approximated in practice by cheap spectrally equivalent approximations , such as a small number of multigrid @xmath40-cycles .",
    "we refer the reader to @xcite and @xcite for further discussions of the notion of efficiency of preconditioners .",
    "this paper is organized as follows : after introducing in detail the dg time - stepping method in section  [ sec : preliminaries ] , we present the preconditioning strategy in section  [ sec : preconditioners ] , where we construct the preconditioners @xmath29 and @xmath36 , and where we establish the condition number bound  .",
    "section  [ sec : implementation ] considers the efficient implementation of the method , and section  [ sec : num_exp ] presents the results of numerical experiments testing the robustness and efficiency of the preconditioners .",
    "in this section , we introduce in detail the dg time - stepping method in the context of self - adjoint semi - discrete dissipative evolution equations .",
    "we also introduce two key ingredients in our approach .",
    "the first ingredient is the well - known temporal reconstruction operator commonly used in a posteriori analysis @xcite , which is the subject of section  [ sec : reconstruction ] .",
    "the second ingredient is a spectral equivalence result for preconditioners from @xcite , which we present in section  [ sec : negative_norm ] .",
    "let @xmath4 denote a finite dimensional real vector space , equipped with a given basis @xmath41 .",
    "let @xmath4 be equipped with two inner products @xmath42 and @xmath43 , and let @xmath5 and @xmath6 be their matrix representations , given by @xmath44 and @xmath45 for all @xmath46 , @xmath47 .",
    "the inner products @xmath48 and @xmath49 induce the norms @xmath50 and @xmath51 on @xmath4 .",
    "let @xmath15 denote the space of real - valued polynomials of degree at most @xmath9 , and let @xmath52 be the space of @xmath4-valued polynomials of a single real variable with degree at most @xmath9 .",
    "for example , if @xmath53 is a basis of @xmath15 , then every @xmath54 is of the form @xmath55 with coefficients @xmath56 for each @xmath57 .",
    "we gather these coefficients in the vector @xmath58 .",
    "it follows that @xmath59 , the dimension of the space @xmath52 , is equal to @xmath60 .",
    "an equivalent point of view is to consider @xmath52 as the tensor - product space derived from @xmath15 and @xmath4 .",
    "[ rem : basis ] in this setting , it is natural to view functions in @xmath52 as mappings from time into @xmath4 , and as a slight abuse of standard terminology , we will say that @xmath53 forms a basis of @xmath52 . of course",
    ", this must be interpreted as the lengthier statement that @xmath61 forms a basis of @xmath52 , where @xmath41 is a basis of  @xmath4 .",
    "if @xmath62 is a linear operator between @xmath4 and either itself or its dual @xmath63 , then we can extend @xmath62 to @xmath52 by applying it coefficient - wise : @xmath64 the inner products @xmath48 and @xmath49 also extend to @xmath52 in the natural way .",
    "likewise , if @xmath65 is a linear operator then we define @xmath66 . for instance",
    ", we define the time derivative @xmath67 of @xmath54 by @xmath68 .",
    "let @xmath69 and @xmath70 denote respectively the @xmath71-inner product and @xmath71-norm over the interval @xmath12 .",
    "let @xmath72 denote the set of legendre polynomials , as defined for instance in ( * ? ? ?",
    "the legendre polynomials are orthogonal in the @xmath71-inner product : for all @xmath73 , @xmath74 , @xmath75 furthermore , @xmath76 and @xmath77 for all @xmath78 .      after mapping a given current time - step interval to the reference interval @xmath12",
    ", the dg time - stepping method leads to the discrete problem of finding @xmath79 such that @xmath80 where @xmath81 is a bounded linear functional on @xmath52 , and the bilinear form @xmath82 is defined by @xmath83 where @xmath8 denotes the time - step size and @xmath9 denotes the polynomial degree of the approximation . in practice , the time - step size , the polynomial degree , or even the matrices @xmath5 and @xmath6 may vary between time - steps , although on any given time - step the linear system has the general form of . given a basis @xmath53 for @xmath52 , the problem can be represented by a linear system @xmath84 where @xmath18 is a @xmath85 block matrix , where @xmath86 is the vector of coefficients of the expansion of @xmath87 , and where @xmath88 with each @xmath89 , @xmath57 , being the restriction of @xmath81 to @xmath90 . therefore , the system has the block structure shown in  .",
    "[ rem : b_challenges ] in order to motivate our approach to preconditioning , it will be helpful to bear in mind the following point concerning the structure of the bilinear form @xmath91 .",
    "it is well - known that the bilinear form @xmath91 enjoys the following coercivity property @xmath92 which enables us to deduce the well - posedness of .",
    "unfortunately , the norm defined by the right - hand side of does not include the time derivative , and thus coercivity and boundedness of @xmath91 in this norm can only be obtained from an inverse inequality for the finite dimensional space @xmath52 , at the expense of introducing constants that are not robust with respect to @xmath8 and @xmath9 .",
    "this point suggests that norm preconditioners for @xmath18 that are based on the right - hand side of are unlikely to be robust with respect to the discretization parameters .",
    "as we shall see below , our approach is based on the inf - sup stability of the bilinear form @xmath91 , which provides a sharper analysis of the structure of the problem than the coercivity result of .",
    "some of our main tools are the reconstruction operator defined in section  [ sec : reconstruction ] , and a corresponding suitable negative norm along with a key spectral equivalence result , which we recall in section  [ sec : negative_norm ] .",
    "we introduce the reconstruction operator @xmath93 , defined by @xmath94 as noted above , @xmath95 naturally extends to an operator from @xmath52 to @xmath96 .",
    "as explained in remark  [ rem : radau_interpolant ] below , @xmath95 is the reconstruction operator commonly used in a posteriori error analysis  @xcite .",
    "the key benefit of the reconstruction operator @xmath95 for our purposes is that we may express the bilinear form @xmath91 in the following equivalent form @xmath97 we emphasize here that @xmath98 since @xmath99 for @xmath79 . to see how is obtained from",
    ", we note that the properties of the legendre polynomials imply that , for any @xmath54 , @xmath100 substituting @xmath101 for @xmath102 , which belongs to @xmath103 whenever @xmath104 , in and using integration by parts shows that @xmath105 the equivalent form of @xmath91 given in   then follows from .",
    "[ rem : radau_interpolant ] the operator @xmath95 is the reconstruction operator commonly used in the a  posteriori error analysis of the dg time - stepping method @xcite .",
    "this operator is often defined by the interpolation conditions @xmath106 for all @xmath107 , where @xmath108 are the gauss ",
    "radau quadrature points , in addition to a further condition , chosen here as @xmath109 .",
    "it turns out that the definition given above in and this interpolatory definition are equivalent , since the gauss ",
    "radau points are the roots of the polynomial @xmath110 , see @xcite and ( * ? ? ?",
    "* eq .  8.961.5 ) .",
    "we note here that a straightforward consequence of the above properties is that , for any @xmath111 , we have @xmath112 in @xmath12 if and only if @xmath113 in @xmath12 .",
    "we also note that we will not need the gauss ",
    "radau points for the implementation of the preconditioners in this work .",
    "in addition to the norms @xmath50 and @xmath114 , we will also use the negative norm @xmath115 defined by @xmath116 the negative norm @xmath115 can be equivalently characterized by the identity @xmath117 where @xmath118 is identified with its vector representation in the basis @xmath41 . indeed , follows from the upper bound @xmath119 , which is obtained by choosing @xmath120 in , and from the lower bound @xmath121 , which is obtained by applying the cauchy ",
    "schwarz inequality as follows : @xmath122 , where we have simplified @xmath123 .",
    "the identity thus shows that the norm @xmath115 is in fact induced by an inner product @xmath124 represented by the matrix @xmath125 .",
    "the following result due to j.  w.  pearson and a.  j.  wathen  @xcite will play a key part in the construction of our preconditioners .",
    "[ lem : pearson ] let @xmath6 and @xmath5 be arbitrary symmetric positive definite matrices and let @xmath126 be a nonnegative real number .",
    "then we have @xmath127    for the original proof of this result , see ( * ? ? ?",
    "* thm  4 ) .",
    "we provide here an alternative proof which highlights the negative norm structure of the matrix @xmath125 , as given in .",
    "first , the upper bound of is immediate from @xmath128 now , for any @xmath129 , we have @xmath130 by .",
    "it follows from the inequality @xmath131 for any @xmath132 , @xmath133 that @xmath134 note that is precisely the lower bound of .",
    "in this section , we construct a left preconditioner that will transform the linear system   to a symmetric positive definite system that represents a discrete parabolic energy norm .",
    "our left preconditioner is defined simply in terms of a substitution for the test function @xmath135 appearing in the bilinear form @xmath136 .",
    "we start by defining the operator @xmath137 by @xmath138 where we recall the definition of the reconstruction operator @xmath95 from and its natural to extension to @xmath52 as explained in section  [ sec : approximation_space ] .",
    "the fact that @xmath139 for any @xmath54 implies that the solution @xmath87 of also solves @xmath140 where the bilinear form @xmath141 and linear functional @xmath142 are obtained by substituting the test function @xmath143 in place of @xmath135 : @xmath144 we note that the operator @xmath145 can be viewed as defining a left preconditioner for the linear system that represents .",
    "indeed , let @xmath146 denote the matrix representation of the linear operator @xmath145 in the basis @xmath53 .",
    "then , for any functions @xmath87 and @xmath147 , and their respective vector representations @xmath148 and @xmath149 , we have @xmath150 and @xmath151 .",
    "therefore , the linear system is equivalent to @xmath152 with @xmath153 and @xmath154 denoting respectively the left - preconditioned matrix and right - hand side .    as the following theorem shows",
    ", @xmath141 represents a discrete version of the natural energy norm for parabolic problems . indeed , in applications to second - order parabolic pdes , @xmath141 is comparable to the inner product of @xmath155 , which is the natural solution space of the continuous problem  @xcite .",
    "[ thm : l_form ] let the bilinear form @xmath156 and linear functional @xmath157 be defined by  .",
    "then , for any functions @xmath87 and @xmath54 , we have the identity @xmath158 therefore , @xmath141 is symmetric and positive definite on @xmath52 , and for any symmetric positive definite matrices @xmath6 and @xmath5 , any @xmath159 and any @xmath160 , we have @xmath161 where @xmath162 is the norm induced by the auxiliary bilinear form @xmath163 defined by : @xmath164 thus , the function @xmath79 solves if and only if @xmath87 solves .",
    "first , it is straightforward to obtain the following identities which hold for any @xmath165 : @xmath166 next , we use the identities in to simplify the different terms in @xmath167 , and eventually we obtain @xmath168 by , we have @xmath169 which , after substitution of the last terms in , implies the equivalent form for @xmath141 given in  . next , to show , we note that first that the lower bound @xmath170 is immediate , whereas the upper bound @xmath171 follows from the application of the cauchy ",
    "schwarz inequality to .",
    "finally , it follows that the problem has a unique solution , momentarily denoted @xmath172 .",
    "moreover , it is well - known that has a unique solution @xmath79 .",
    "since the definition of @xmath141 and @xmath142 in   shows that @xmath87 is a solution of , we deduce from uniqueness that @xmath173 .",
    "therefore , the problems and are equivalent .",
    "[ rem : kreuzer_infsup ] theorem  [ thm : l_form ] can be viewed as part of the inf - sup analysis of the dg time - stepping method : defining the energy norm @xmath174 and the norm @xmath175 , we have @xmath176 where the first equality is attained by choosing the optimal test function @xmath177 , since @xmath178 .",
    "this observation highlights the fact that the operator @xmath145 represents the operator that gives the optimal test function in the inf - sup analysis of the dg time - stepping method .",
    "it is in this sense that our preconditioning strategy is directly motivated by the inf - sup theory of the dg time - stepping method .",
    "as shown by theorem  [ thm : l_form ] , the bilinear form @xmath141 is symmetric and positive definite .",
    "therefore , the linear system   can be solved iteratively by the preconditioned conjugate gradient  ( pcg ) algorithm @xcite . in this section",
    ", we construct a spectrally equivalent and easily applicable preconditioner for @xmath34 , thereby leading to the robust and fast convergence of the pcg algorithm .",
    "recall that the bilinear form @xmath141 is spectrally equivalent to the bilinear form @xmath163 defined by .",
    "the first step in our construction of a preconditioner is to choose an advantageous temporal basis for @xmath52 that block - diagonalizes the matrix @xmath179 that represents @xmath163 . in a second step , we construct an easily applicable preconditioner , denoted by @xmath36 , under this basis , and we apply lemma  [ lem : pearson ] to show robust spectral equivalence between @xmath36 and @xmath34 .",
    "it follows from remark  [ rem : radau_interpolant ] that the symmetric bilinear form @xmath180 is positive definite and thus defines an inner - product on @xmath15 .",
    "therefore , there exists a set of linearly independent polynomial eigenfunctions @xmath181 and corresponding real positive eigenvalues @xmath182 such that @xmath183 we note that the eigenvalues and eigenfunctions generally depend on @xmath9 , and are not necessarily hierarchical .",
    "the eigenfunctions are chosen to be orthonormalized : @xmath184 we provide a practical method for computing this basis along with the corresponding eigenvalues in section  [ sec : comp_eigenfunctions ] .",
    "the following result characterizes the distribution of the eigenvalues .",
    "[ thm : eigenvalue_distribution ] let @xmath159 be a nonnegative integer , and let @xmath185 be the eigenvalues of the generalized eigenvalue problem  .",
    "then , there exists a positive constant @xmath186 , independent of @xmath187 and @xmath9 , such that @xmath188 moreover , there exists a constant @xmath189 , independent of @xmath9 , such that @xmath190    we leave the proof of theorem  [ thm : eigenvalue_distribution ] to appendix  [ sec : eigenvalues ] since it is based on some results presented in the later section  [ sec : comp_eigenfunctions ] .",
    "figure  [ fig : eigenvalues ] shows that the orders of the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp .",
    "the eigenfunctions for @xmath191 are shown in figure  [ fig : eigenfunctions ] .",
    "it is advantageous to use the basis @xmath192 in computations since in this basis , the dominant terms in the bilinear form @xmath141 , namely those belonging to the bilinear form @xmath163 , are represented by a block - diagonal matrix .",
    "indeed , let @xmath179 denote the matrix representation of the bilinear form @xmath163 , defined in , under the basis @xmath192 of @xmath52 , where we recall the terminology from remark  [ rem : basis ] .",
    "then , in this basis , the matrix @xmath179 has a simple block - diagonal structure:@xmath193 in other words , @xmath179 is block - diagonal , with blocks @xmath194 for @xmath57 . keeping in mind lemma  [ lem : pearson ] ,",
    "it is then natural to define the norm preconditioner @xmath36 by @xmath195 the matrix @xmath36 is symmetric positive definite , and its inverse is trivially given by @xmath196 we propose to use @xmath36 as a preconditioner for the pcg algorithm applied to .",
    "each pcg iteration requires the application of @xmath197 , which comprises two applications of a solver for a weighted backward euler step and one multiplication by @xmath6 per block .",
    "we now give the central result of this work , which shows that @xmath34 and @xmath36 are spectrally equivalent with fully robust bounds .",
    "[ thm : l_h_equivalence ] let @xmath159 , and let @xmath198 and @xmath199 be the eigenfunctions and eigenvalues of .",
    "let @xmath34 be the matrix representation of @xmath141 in the basis @xmath192 .",
    "then , for any symmetric positive definite matrices @xmath6 and @xmath5 , any @xmath160 and any @xmath159 , we have @xmath200    theorem  [ thm : l_form ] , in particular , shows that @xmath201 lemma  [ lem : pearson ] , applied block - wise with @xmath202 , implies that @xmath203 therefore , and imply .",
    "theorem  [ thm : l_h_equivalence ] immediately implies that the condition number @xmath204 of the preconditioned system , defined as the ratio of extremal eigenvalues of @xmath205 , satisfies @xmath206 therefore , we may expect very fast convergence from the pcg algorithm for @xmath31 using the preconditioner @xmath36 .",
    "indeed , for an initial guess @xmath207 , the iterates @xmath208 of the pcg algorithm satisfy the well - known bound @xcite @xmath209 where we recall the energy norm @xmath210 .",
    "the fact that the condition number @xmath211 shows that the left preconditioner @xmath29 and the norm preconditioner @xmath36 are very effective at preconditioning the original system matrix @xmath18 , despite @xmath18 being nonsymmetric and poorly conditioned .",
    "this is a key aspect of the efficiency of the proposed preconditioners .",
    "furthermore , we highlight that and are valid for any time - step size  @xmath8 , any polynomial degree @xmath9 , and any symmetric positive definite matrices @xmath5 and @xmath6 . thus the preconditioners are fully robust with respect to all discretization and problem parameters .",
    "the fact that the energy norm @xmath212 appears in the bound is advantageous in practice . since the endpoint value of the solution at @xmath213 serves as initial datum for the next time - step , it is beneficial to be able to control the accuracy to which it is computed .",
    "for example , shows that the energy norm controls the value at @xmath213 in the @xmath5-norm , which is the natural norm for this quantity of interest .",
    "we note that the factor of @xmath8 appearing alongside @xmath214 in the energy norm can be scaled out as it appears in both the numerator and denominator of .",
    "therefore is a guaranteed convergence rate for this quantity of interest in the physically relevant norm .     computed by the method of section  [ sec : comp_eigenfunctions ] and arranged in decreasing order , for @xmath215 , @xmath216 , @xmath217 and @xmath217 .",
    "all plots are on a logarithmic scale , except for @xmath215 which is given on a semilogarithmic scale .",
    "it appears that the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp . ]",
    "computed by the method of section  [ sec : comp_eigenfunctions ] and arranged in decreasing order , for @xmath215 , @xmath216 , @xmath217 and @xmath217 .",
    "all plots are on a logarithmic scale , except for @xmath215 which is given on a semilogarithmic scale .",
    "it appears that the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp.,title=\"fig : \" ]   computed by the method of section  [ sec : comp_eigenfunctions ] and arranged in decreasing order , for @xmath215 , @xmath216 , @xmath217 and @xmath217 .",
    "all plots are on a logarithmic scale , except for @xmath215 which is given on a semilogarithmic scale .",
    "it appears that the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp.,title=\"fig : \" ]   computed by the method of section  [ sec : comp_eigenfunctions ] and arranged in decreasing order , for @xmath215 , @xmath216 , @xmath217 and @xmath217 .",
    "all plots are on a logarithmic scale , except for @xmath215 which is given on a semilogarithmic scale .",
    "it appears that the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp.,title=\"fig : \" ]   computed by the method of section  [ sec : comp_eigenfunctions ] and arranged in decreasing order , for @xmath215 , @xmath216 , @xmath217 and @xmath217 .",
    "all plots are on a logarithmic scale , except for @xmath215 which is given on a semilogarithmic scale .",
    "it appears that the bounds of theorem  [ thm : eigenvalue_distribution ] are sharp.,title=\"fig : \" ]",
    "the algorithm requires the computation of the eigenfunctions @xmath192 and eigenvalues @xmath218 defined in , which involves solving a symmetric positive definite eigenvalue problem of dimension  @xmath24 .",
    "this poses little difficulty , as in practice @xmath9 is usually small , especially in comparison to @xmath219 .",
    "since this step only depends on @xmath9 and is fully independent of @xmath6 , @xmath5 and @xmath8 , it can be pre - computed to very high accuracy .",
    "we now show how to assemble this eigenvalue problem in a form where it can be solved numerically .",
    "since the cases @xmath16 and @xmath27 can be easily computed by hand , we present a general method for @xmath220 . in the following ,",
    "we will use the following identity for the legendre polynomials @xmath221 , see ( * ? ? ? * sec .",
    "8.914 ) : @xmath222    [ lem : psi_basis ] let @xmath220 be a nonnegative integer .",
    "define the polynomials @xmath223 then , there holds @xmath224 therefore , we have , for each @xmath225 , @xmath226    consider the case @xmath227 : @xmath228 , and @xmath229 . therefore @xmath230 , and thus @xmath231 , which is for @xmath227 .",
    "now consider the general case @xmath232 .",
    "since @xmath233 for all @xmath74 , we have @xmath234 and thus @xmath235 .",
    "now , the identity implies that @xmath236 thus verifying for @xmath232 . for the case @xmath237",
    ", we use the fact that @xmath238 to compute @xmath239 therefore , similarly to , the identity for @xmath237 follows from .",
    "define the matrix @xmath240 such that @xmath241 as in .",
    "define the diagonal matrix @xmath242 , which represents the @xmath71-inner product in the legendre polynomial basis .",
    "define the matrix @xmath243 by @xmath244 note that @xmath245 .",
    "it follows from that the eigenvalue problem can be expressed as : find @xmath246 and @xmath218 such that @xmath247 the eigenvalue problem can thus be solved numerically by standard eigenvalue solvers .",
    "the eigenfunctions @xmath192 can then be recovered as @xmath248      in order to compute the action of the left - preconditioner @xmath29 , we use the matrix representation of the mapping @xmath249 in the basis given by @xmath192 .",
    "thus we need to find the matrix @xmath250 such that @xmath251 for all @xmath11 .",
    "we show below that this is easily computed . inverting by induction yields@xmath252 therefore , we have @xmath253 where , after some calculation , it is found that the matrix @xmath254 can be defined in terms of @xmath255 , @xmath256 , and @xmath257 by @xmath258    let @xmath220 be an integer , and let @xmath192 be the eigenfunctions defined by .",
    "then , for each @xmath11 , there holds @xmath259 where @xmath40 is as in , the matrix @xmath260 is as in , and where @xmath261 .",
    "the orthogonality of the matrix @xmath40 in implies that @xmath262 . since the basis @xmath263 is orthonormal in the inner product of , there holds @xmath264 where we have used and in the first line .",
    "therefore , we compute @xmath265 which completes the proof .",
    "we now show how the matrix @xmath250 is used in applying the preconditioner  @xmath29 . for @xmath266 , there holds @xmath267 therefore , @xmath268 , where @xmath269 , can be computed componentwise by @xmath270 the action of @xmath29 requires the solution of @xmath24 independent systems with matrix @xmath6 , which can be performed in parallel .",
    "if we ignore communication costs , then the cost of computing @xmath271 is independent of the polynomial degree @xmath9 on a parallel machine with sufficiently many computing nodes .",
    "after application of the preconditioner @xmath29 , the linear system has the form @xmath272 where @xmath153 , which can be solved by the pcg algorithm with preconditioner @xmath36 , as suggested in section  [ sec : preconditioners ] .",
    "the pcg algorithm requires the action of the matrices @xmath34 and @xmath197 at each iteration .",
    "there are two ways to implement the action of @xmath34 , the first being the application of @xmath18 followed by @xmath29 .",
    "the downside of this approach is that it leads to greater communication costs on a distributed memory parallel machine where each node holds in memory only a few coefficients of @xmath148 : the matrices @xmath18 and @xmath29 are generally block - dense , so all vector components must be exchanged between all computational nodes for both steps .",
    "the second approach is to use , which shows that @xmath34 can be expressed as a diagonal matrix plus a `` rank - two '' term : in the basis @xmath192 , we have @xmath273 where @xmath274 are the vectors of endpoint values of the @xmath275 . therefore , we may compute @xmath276 , with @xmath277 , as follows :    [ eq : compute_l ] @xmath278    this approach requires the same number of matrix - vector products as the first approach outlined above , but the communication costs are greatly reduced . indeed",
    ", it is seen that the above procedure requires the parallel computation of the @xmath279 , which are then gathered and reduced by one or two nodes tasked with computing @xmath280 .",
    "the results are then broadcast back to all nodes , after which all subsequent computations can be performed in parallel .    finally , the application of @xmath197 is trivially parallel , as it requires only that each node solves two linear systems involving the matrix @xmath281 , and one application of @xmath6 .",
    "theorem  [ thm : eigenvalue_distribution ] shows that the eigenvalues remain uniformly bounded from above , and that the smaller eigenvalues approach zero as @xmath9 increases .",
    "therefore , for large @xmath9 and @xmath187 , the matrix @xmath281 becomes increasingly similar to @xmath5 , implying that these systems will become increasingly easy to solve in many applications .",
    "in this experiment , we study the dependence of the condition numbers @xmath204 of the preconditioned system @xmath205 on the problem and discretization parameters . in order to compute accurately the condition numbers ,",
    "we consider first a one - dimensional problem .",
    "let @xmath5 and @xmath6 be the mass and stiffness matrices obtained by applying piecewise - linear continuous finite elements on a uniform subdivision of the domain @xmath282 into elements of size @xmath283 , @xmath284 .",
    "we note that @xmath5 and @xmath6 thus depend on @xmath285 , although this is left implicit in our notation . for this experiment ,",
    "we use direct solvers to implement the action of @xmath286 and @xmath287 .",
    "table  [ tab : tau_dependence ] shows the condition numbers @xmath204 as a function of @xmath8 for a wide range of parameters . for this experiment ,",
    "we set @xmath288 and @xmath289 .",
    "it is found that for either very large or very small @xmath8 , @xmath290 .",
    "this is easily explained by the fact that@xmath291 therefore the condition number @xmath290 as @xmath292 or @xmath293 .",
    "thus the maximal condition number is found for intermediate values of the time - step size @xmath8 , although in all cases it satisfies the theoretical bound @xmath294 as shown in  .",
    ".dependence of the condition number @xmath204 of @xmath295 on a wide range of values for the time - step size @xmath8 .",
    "observe that for either very large or very small @xmath8 , the condition number is asymptotically @xmath296 , in agreement with .",
    "this explains the observation that the maximum condition number is observed for intermediate values .",
    "[ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "we have developed efficient and robust preconditioners enabling the fast solution of the dg time - stepping method by the preconditioned conjugate gradient algorithm .",
    "the analysis and numerical experiments show that the ideal and approximate preconditioners are robust with respect to all discretization parameters and lead to low condition numbers for the preconditioned system .",
    "thus the high - order solution of large problems by the dg time - stepping method is tractable under the proposed approach .",
    "in this section , we present the proof of theorem  [ thm : eigenvalue_distribution ] . without loss of generality ,",
    "it is sufficient to consider only @xmath220 throughout this section .",
    "we will make use of weyl s theorem from eigenvalue perturbation theory  @xcite .    for a positive integer @xmath297 , let @xmath298 and @xmath299 denote symmetric @xmath300 matrices .",
    "let @xmath301 denote the eigenvalues of @xmath298 and let @xmath302 denote the eigenvalues of @xmath299 .",
    "then , for each @xmath303 , we have @xmath304 where @xmath305 denotes the matrix @xmath306-norm .    we are now ready to prove theorem  [ thm : eigenvalue_distribution ]",
    ".    _ proof of theorem  [ thm : eigenvalue_distribution ] . _",
    "recall that the matrix @xmath298 is defined by .",
    "we start by noting that the matrix @xmath298 is pentadiagonal , i.e. @xmath307 if @xmath308 .",
    "moreover , it is easy to show from the properties of legendre polynomials that there exists a constant @xmath186 independent of @xmath9 such that @xmath309 the cauchy ",
    "schwarz inequality implies that @xmath310 , and thus all entries of @xmath298 are uniformly bounded .",
    "since @xmath298 has at most @xmath311 nonzero entries per row , and all entries are uniformly bounded , the gershgorin discs of @xmath298 are bounded independently of @xmath9 .",
    "the gershgorin disc theorem therefore implies that there is a constant @xmath186 , independent of @xmath9 , such that @xmath312 , the maximal eigenvalue of @xmath298 , satisfies @xmath313 .",
    "this corresponds to for the case @xmath314 .",
    "we consider now @xmath315 , and without loss of generality , we may assume that @xmath220 . for @xmath316 , we define the orthogonal projector @xmath317 by @xmath318 where the polynomials @xmath319 are defined by , and @xmath320 .",
    "define the matrix @xmath321 by @xmath322 .",
    "note that @xmath323 is zero if either @xmath73 or @xmath187 is greater than @xmath324 , and equals @xmath325 otherwise .",
    "thus , the matrix @xmath326 has the general form @xmath327 where @xmath328 denotes the @xmath329 principal submatrix of @xmath298 .",
    "the main step of the proof is to use repeatedly to find an upper bound for @xmath330 for arbitrary @xmath331 and @xmath332 , define the polynomials @xmath333 and @xmath334 .",
    "then , we have @xmath335 it follows from the definition of @xmath336 in that @xmath337 since @xmath338 if @xmath308 , the strengthened cauchy ",
    "schwarz inequality yields @xmath339 note that this implies the following a priori estimate for the orthogonal projector : @xmath340 thus and the cauchy ",
    "schwarz inequality imply that @xmath341 for @xmath342 and @xmath343 , we have @xmath344 if @xmath345 and @xmath346 , and thus @xmath347 the cauchy ",
    "schwarz inequality thus implies that @xmath348 an identical argument shows that @xmath349 combining , and implies that there exists a constant @xmath186 , independent of @xmath9 and @xmath324 , such that @xmath350 therefore , weyl s theorem implies that the eigenvalues @xmath351 of @xmath298 and @xmath352 of @xmath326 satisfy @xmath353 where the constant @xmath186 is independent of @xmath187 , @xmath324 and @xmath9 .",
    "however , it is clear from that @xmath354 for @xmath343 , and thus there exists a constant @xmath186 independent of @xmath9 and @xmath324 such that @xmath355 the left - hand side of this inequality is independent of @xmath324 while the right - hand side is valid of all @xmath356 . therefore , the choice @xmath357 yields for @xmath358 .",
    "the lower bound follows from inverse inequalities .",
    "indeed , @xmath359 satisfies @xmath360 to obtain , it is therefore enough to show the inverse inequality @xmath361 for any @xmath362 , standard inverse inequalities @xcite imply that @xmath363 it follows from that @xmath364 substituting into yields .",
    "the author wishes to express his thanks to paul  houston , lorenz  john , christian  kreuzer , endre  sli and martin  vohralk for many helpful discussions .",
    "the author was supported by an epsrc doctoral prize at the mathematical institute , university of oxford , during the period in which part of this work was completed .",
    "\\(2015 ) , eighth edition , elsevier / academic press , amsterdam , pp .",
    "xlvi+1133 . translated from the russian , translation edited and with a preface by daniel zwillinger and victor moll , revised from the seventh edition ."
  ],
  "abstract_text": [
    "<S> the discontinuous galerkin time - stepping method has many advantageous properties for solving parabolic equations . </S>",
    "<S> however , it requires the solution of a large nonsymmetric system at each time - step . </S>",
    "<S> this work develops a fully robust and efficient preconditioning strategy for solving these systems . drawing on parabolic inf - sup theory , </S>",
    "<S> we first construct a left preconditioner that transforms the linear system to a symmetric positive definite problem to be solved by the preconditioned conjugate gradient algorithm . </S>",
    "<S> we then prove that the transformed system can be further preconditioned by an ideal block diagonal preconditioner , leading to a condition number bounded by @xmath0 for any time - step size , any approximation order and any positive - definite self - adjoint spatial operators . </S>",
    "<S> numerical experiments demonstrate the low condition numbers and fast convergence of the algorithm for both ideal and approximate preconditioners , and show the feasibility of the high - order solution of large problems . </S>",
    "<S> discontinuous galerkin ; time discretizations ; parabolic pde ; preconditioning ; conjugate gradient algorithm . </S>"
  ]
}