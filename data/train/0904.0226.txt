{
  "article_text": [
    "in contemporary wireless communication systems , arq ( automatic repeat request ) is generally used above the physical layer ( phy ) to compensate for packet errors : incorrectly decoded packets are detected by the receiver , and a negative acknowledgement is sent back to the transmitter to request a re - transmission .",
    "in such an architecture there is a natural tradeoff between the transmitted rate and arq re - transmissions .",
    "a high transmitted rate corresponds to many packet errors and thus many arq re - transmissions , but each successfully received packet contains many information bits . on the other hand , a low transmitted rate corresponds to few arq re - transmissions , but few information bits are contained per packet .",
    "thus , a fundamental design challenge is determining the transmitted rate that maximizes the rate at which bits are successfully delivered .",
    "since the packet error probability is an increasing function of the transmitted rate , this is equivalent to determining the optimal packet error probability , i.e. , the optimal phy reliability level .",
    "we consider a wireless channel where the transmitter chooses the rate based only on the fading statistics because knowledge of the instantaneous channel conditions is not available ( e.g. , high velocity mobiles in cellular systems ) . the transmitted rate - arq tradeoff is interesting in this setting because the packet error probability depends on the transmitted rate in a non - trivial fashion ; on the other hand , this tradeoff is somewhat trivial when instantaneous channel state information at the transmitter ( csit ) is available ( see remark [ remk1 ] ) .",
    "we begin by analyzing an idealized system , for which we find that making the phy too reliable can lead to a significant penalty in terms of the achieved goodput ( long - term average successful _ throughput _ ) , and that the optimal packet error probability is decreasing in the average snr and in the fading selectivity experienced by each transmitted codeword .",
    "we also see that for a large level of system parameters , choosing an error probability of @xmath0 leads to near - optimal performance .",
    "we then consider a number of important practical considerations , such as a limit on the number of arq re - transmissions and unreliable acknowledgement feedback . even after taking these issues into account",
    ", we find that a relatively unreliable phy is still preferred .",
    "because of fading , the phy can be made reliable only if the transmitted rate is significantly reduced .",
    "however , this reduction in rate is not made up for by the corresponding reduction in arq re - transmissions",
    ".      there has been some recent work on the joint optimization of packet - level erasure - correction codes ( e.g. , fountain codes ) and phy - layer error correction @xcite .",
    "the fundamental metric with erasure codes is the product of the transmitted rate and the packet success probability , which is the same as in the idealized arq setting studied in section [ sec - ideal ] . even in that idealized setting ,",
    "our work differs in a number of ways .",
    "references @xcite study multicast ( i.e. , multiple receivers ) while @xcite considers unicast assuming no diversity per transmission , whereas our focus is on the unicast setting with diversity per transmission .",
    "furthermore , our analysis provides a general explanation of how the phy reliability should depend on both the diversity and the average snr .",
    "in addition , we consider a number of practical issues specific to arq , such as acknowledgement errors ( section [ sec - nonideal ] ) , as well as hybrid - arq ( section [ sec - harq ] ) .",
    "we consider a rayleigh block - fading channel where the channel remains constant within each block but changes independently from one block to another . the @xmath1-th ( @xmath2 ) received channel symbol in the @xmath3-th ( @xmath4 ) fading block @xmath5",
    "is given by @xmath6 where @xmath7 represents the channel gain and is i.i.d .",
    "across fading blocks , @xmath8 denotes the gaussian input symbol constrained to have unit average power , and @xmath9 models the additive gaussian noise assumed to be i.i.d . across channel uses and fading blocks .",
    "although we focus on single antenna systems and rayleigh fading channel , our model can be easily extended to multiple - input and multiple - output ( mimo ) systems and other fading distributions as commented upon in remark [ remk3 ] .",
    "each transmission ( i.e. , codeword ) is assumed to span @xmath10 fading blocks , and thus @xmath10 represents the time / frequency selectivity experienced by each codeword . in analyzing arq systems ,",
    "the packet error probability is the key quantity .",
    "if a strong channel code ( with suitably long blocklength ) is used , it is well known that the packet error probability is accurately approximated by the mutual information outage probability @xcite . under this assumption ( which is examined in section [ sec - finite_blk ] ) , the packet error probability for transmission at rate @xmath11 bits / symbol is given by ( * ? ? ?",
    "* eq ( 5.83 ) ) : @xmath12.\\end{aligned}\\ ] ] here we explicitly denote the dependence of the error probability on the average signal - to - noise ratio @xmath13 , the selectivity order @xmath10 , and the transmitted rate @xmath11 .",
    "we are generally interested in the relationship between @xmath11 and @xmath14 for particular ( fixed ) values of @xmath13 and @xmath10 . when @xmath13 and @xmath10 are constant , @xmath11 can be inversely computed given some @xmath14 ; thus , throughout the paper we replace @xmath11 with @xmath15 wherever the relationship between @xmath11 and @xmath14 needs to be explicitly pointed out .",
    "the focus of the paper is on simple arq , in which packets received in error are re - transmitted and decoding is performed only on the basis of the most recent transmission .. ] more specifically , whenever the receiver detects that a codeword has been decoded incorrectly , a nack is fed back to the transmitter . on the other hand , if the receiver detects correct decoding an ack is fed back . upon reception of an ack ,",
    "the transmitter moves on to the next packet , whereas reception of a nack triggers re - transmission of the previous packet .",
    "arq transforms the system into a variable - rate scheme , and the relevant performance metric is the rate at which packets are _ successfully _ received .",
    "this quantity is generally referred to as the long - term average _ goodput _ , and is clearly defined in each of the relevant sections . and consistent with the assumption of no csit ( and fast fading ) , we assume fading is independent across re - transmissions .",
    "in this section we investigate the optimal phy reliability level under a number of idealized assumptions . although not entirely realistic , this idealized model yields important design insights . in particular , we make the following key assumptions :    * channel codes that operate at the mutual information limit ( i.e. , packet error probability is equal to the mutual information outage probability ) . * perfect error detection at the receiver . *",
    "unlimited number of arq re - transmissions . *",
    "perfect ack / nack feedback .    in section [ sec - nonideal ]",
    "we relax these assumptions , and find that the insights from this idealized setting generally also apply to real systems .    in order to characterize the long - term goodput in this idealized setting . in order to do so",
    ", we must quantify the number of transmission attempts / arq rounds needed for successful transmission of each packet .",
    "if we use @xmath16 to denote the number of arq rounds for the _ i_-th packet , then a total of @xmath17 arq rounds are used for transmitting @xmath18 packets ; note that the @xmath16 s are i.i.d . due to the independence of fading and noise across arq rounds . each codeword is assumed to span @xmath19 channel symbols and to contain @xmath20 information bits , corresponding to a transmitted rate of @xmath21 bits / symbols",
    ". the average rate at which bits are successfully delivered is the ratio of the bits delivered to the total number of channel symbols required .",
    "the goodput @xmath22 is the long - term average at which bits are successfully delivered , and by taking @xmath23 we get @xcite : @xmath24},\\end{aligned}\\ ] ] where @xmath25 is the random variable describing the arq rounds required for successful delivery of a packet .    because each arq round is successful with probability @xmath26 , with @xmath14 defined in ( [ outage_nharq ] ) , and rounds are independent",
    ", @xmath25 is geometric with parameter @xmath26 and thus @xmath27=1/(1-\\varepsilon)$ ] . based upon ( [ gput_nharq ] )",
    ", we have @xmath28 where the transmitted rate is denoted as @xmath15 to emphasize its dependence on @xmath14 .    based on this expression",
    ", we can immediately see the tradeoff between the transmitted rate , i.e. the number of bits per packet , and the number of arq re - transmissions per packet : a large @xmath15 means many bits are contained in each packet but that many re - transmissions are required , whereas a small @xmath15 corresponds to fewer bits per packet and fewer re - transmissions .",
    "our objective is to find the optimal ( i.e. , goodput maximizing ) operating point on this tradeoff curve for any given parameters @xmath13 and @xmath10 .    because @xmath15 is a function of @xmath14 ( for @xmath13 and @xmath10 fixed ) ,",
    "this one - dimensional optimization can be phrased in terms of @xmath15 or @xmath14 .",
    "we find it most insightful to consider @xmath14 , which leads to the following definition :    [ def1 ] the optimal packet error probability , where optimal refers to goodput maximization with goodput defined in ( [ gput_nharq ] ) , for average signal - to - noise ratio @xmath13 and per - codeword selectivity order @xmath10 is : @xmath29    by finding @xmath30 , we thus determine the optimal phy reliability level and how this optimum depends on channel parameters @xmath13 and @xmath10 , which are generally static over the timescale of interest .    for @xmath31 , a simple calculation shows is also derived in @xcite .",
    "however , authors in @xcite only consider @xmath31 case rather than @xmath32 scenarios , which are further investigated in our work . ]",
    "@xmath33 where @xmath34 is the lambert w function @xcite .",
    "unfortunately , for @xmath32 it does not seem feasible to find an exact analytical solution because a closed - form expression for the outage probability exists only for @xmath31 .",
    "however , the optimization in ( [ opt_gput_nharq ] ) can be easily solved numerically ( for arbitrary @xmath10 ) .",
    "in addition , an accurate approximation to @xmath30 can be solved analytically , as we detail in the next subsection .    in order to provide a general understanding of @xmath35 , fig .",
    "[ fig : gput_eps ] contains a plot of goodput @xmath22 ( numerically computed ) versus outage probability @xmath14 for @xmath36 and @xmath37 at @xmath38 and @xmath39 db . for each curve ,",
    "the goodput - maximizing value of @xmath14 is circled . from this figure",
    ", we make the following observations :    * making the physical layer too reliable or too unreliable yields poor goodput . *",
    "the optimal outage probability decreases with @xmath13 and @xmath10 .",
    "these turn out to be the key behaviors of the coding - arq tradeoff , and the remainder of this section is devoted to analytically explain these behaviors through a gaussian approximation .",
    "[ remk1 ] throughput the paper we consider the setting _ without _ channel state information at the transmitter ( csit ) . if there is csit , which generally is the case when the fading is slow relative to the delay in the channel feedback loop , the optimization problem in _ definition [ def1 ] _ turns out to be trivial . when csit is available , the channel is essentially awgn with an instantaneous snr that is determined by the fading realization but is known to the tx .",
    "if a capacity - achieving code with infinite codeword block - length is used in the awgn channel , the relationship between error and rate is a step - function :    = 0 , & if @xmath40 + 1 , & if @xmath41 .",
    "thus , it is optimal to choose a rate very slightly below the instantaneous capacity @xmath42 . for realistic codes with finite blocklength ,",
    "the @xmath14-@xmath11 curve is not a step function but nonetheless is very steep .",
    "for example , for turbo codes the waterfall characteristic of error vs. snr curves ( for fixed rate ) translates to a step - function - like error vs. rate curve for fixed snr .",
    "therefore , the transmitted rate should be chosen close to the bottom of the step function .",
    "the primary difficulty in finding @xmath30 stems from the fact that the outage probability in ( [ outage_nharq ] ) can only be expressed as an @xmath10-dimensional integral , except for the special case @xmath31 . to circumvent this problem",
    ", we utilize a gaussian approximation to the outage probability used in prior work @xcite .",
    "the random variable @xmath43 is approximated by a @xmath44 random variable , where @xmath45 and @xmath46 are the mean and the variance of @xmath47 , respectively : @xmath48,\\\\ \\sigma^2(\\snr)&=&\\mathbb{e}_{|h|}\\left[\\log_2(1+\\snr|h|^2)\\right]^2-\\mu^2(\\snr).\\end{aligned}\\ ] ] closed forms for these quantities can be found in @xcite . based on this approximation we have @xmath49 where @xmath50 is the tail probability of a standard normal . solving this equation for @xmath15 and plugging into ( [ gput_nharq2 ] ) yields the following approximation for the goodput , which we denote as @xmath51 : @xmath52 where @xmath53 is the inverse of the @xmath54 function .",
    "the optimization of @xmath51 turns out to be more tractable .",
    "we first rewrite @xmath51 as @xmath55 where the constant @xmath56 is the @xmath57-normalized standard deviation of the received mutual information : @xmath58 we can observe that @xmath59 decreases in @xmath13 and @xmath10 .",
    "we now define @xmath60 as the @xmath51-maximizing outage probability : @xmath61 where we have pulled out the constant @xmath45 from ( [ eta_g_2 ] ) because it does not affect the maximization .",
    "[ pro1 ] the phy reliability level that maximizes the gaussian approximated goodput is the unique solution to the following fixed point equation : @xmath62 furthermore , @xmath60 is increasing in @xmath59 .",
    "see appendix [ pf_a ] .",
    "we immediately see that @xmath60 depends on the channel parameters only through @xmath59 . furthermore , because @xmath59 is decreasing in @xmath13 and @xmath10 , we see that @xmath60 decreases in @xmath10 ( i.e. , the channel selectivity ) and @xmath13 .",
    "straightforward analysis shows that @xmath60 tends to zero as @xmath10 increases approximately as @xmath63 , while @xmath60 tends to zero with @xmath13 approximately as @xmath64 .    in fig .",
    "[ fig : opt_eps_snr ] , the exact optimal @xmath35 and the approximate - optimal @xmath60 are plotted vs. @xmath13 ( db ) for @xmath65 and @xmath39 .",
    "the gaussian approximation is seen to be reasonably accurate , and most importantly , correctly captures behavior with respect to @xmath10 and @xmath13 .    in order to gain an intuitive understanding of the optimization , in fig .",
    "[ fig : phy_arg ] the success probability @xmath26 ( left ) and the goodput @xmath66 ( right ) are plotted versus the transmitted rate @xmath11 for @xmath67 db . for each @xmath10",
    "the goodput - maximizing operating point is circled .",
    "first consider the curves for @xmath37 .",
    "for @xmath11 up to approximately @xmath68 bits / symbol the success probability is nearly one , i.e. , @xmath69 . as a result ,",
    "the goodput @xmath22 is approximately equal to @xmath11 for @xmath11 up to @xmath68 .",
    "when @xmath11 is increased beyond @xmath68 the success probability begins to decrease non - negligibly but the goodput nonetheless increases with @xmath11 because the increased transmission rate makes up for the loss in success probability ( i.e. , for the arq re - transmissions ) .",
    "however , the goodput peaks at @xmath70 because beyond this point the increase in transmission rate no longer makes up for the increased re - transmissions ; visually , the optimum rate ( for each value of @xmath10 ) corresponds to a point beyond which the success probability begins to drop off sharply with the transmitted rate .    to understand the effect of the selectivity order @xmath10 , notice that increasing @xmath10 leads to a steepening of the success probability - rate curve",
    "this has the effect of moving the goodput curve closer to the transmitted rate , which leads to a larger optimum rate and a larger optimum success probability ( @xmath71 ) . to understand why @xmath35 decreases with @xmath13 , based upon the rewritten version of @xmath51 in ( [ eta_g_2 ] )",
    "we see that the governing relationship is between the success probability @xmath26 and the normalized , rather than absolute , transmission rate @xmath72 .",
    "therefore , increasing @xmath13 steepens the success probability - normalized rate curve ( similar to the effect of increasing @xmath10 ) and thus leads to a smaller value of @xmath35",
    ".    is is important to notice that the optimum error probabilities in fig .",
    "[ fig : opt_eps_snr ] are quite large , even for large selectivity and at high snr levels .",
    "this follows from the earlier explanation that decreasing the error probability ( and thus the rate ) beyond a certain point is inefficient because the decrease in arq re - transmissions does not make up for the loss in transmission rate .    to underscore the importance of not operating the phy too reliably , in fig .",
    "[ fig : goodput_snr ] goodput is plotted versus @xmath13 ( db ) for @xmath36 and @xmath39 for the optimum error probability @xmath73 as well as for @xmath74 , @xmath75 , and @xmath76 .",
    "choosing @xmath74 leads to near - optimal performance for both selectivity values . on the other hand",
    ", there is a significant penalty if @xmath77 or @xmath76 when @xmath36 ; this penalty is reduced in the highly selective channel ( @xmath78 ) but is still non - negligible .",
    "indeed , the most important insight from this analysis is that making the phy too reliable can lead to a significant performance penalty ; for example , choosing @xmath79 leads to a power penalty of approximately @xmath39 db for @xmath36 and @xmath80 db for @xmath78 .",
    "[ remk3 ] _ proposition [ pro1 ] _ shows @xmath60 is only determined by @xmath59 , which is completely determined by the statistics of the received mutual information per packet .",
    "this implies our results can be easily extended to different fading distributions and to mimo by appropriately modifying @xmath45 and @xmath81 .",
    "while the previous section illustrated the need to operate the phy at a relatively unreliable level under a number of idealized assumptions , a legitimate question is whether that conclusion still holds when the idealizations of section [ sec - ideal ] are removed .",
    "thereby motivated , in this section we begin to carefully study the following scenarios one by one :    * finite codeword block - length .",
    "* imperfect error detection .",
    "* limited number of arq rounds per packet . *",
    "imperfect ack / nack feedback .    as we shall see , our basic conclusion is upheld even under more realistic assumptions .",
    "although in the previous section we assumed operation at the mutual information of infinite blocklength codes , real systems must use finite blocklength codes . in order to determine the effect of finite blocklength upon the optimal phy reliability , we study the mutual information outage probability in terms of the _ information spectrum _ , which captures the block error probability for finite blocklength codes . in @xcite",
    ", it was shown that actual codes perform quite close to the information spectrum - based outage probability .    by extending the results of @xcite , the outage probability with blocklength @xmath19 ( symbols )",
    "is @xmath82,\\end{aligned}\\ ] ] where @xmath11 is the transmitted rate in nats / symbol , and @xmath83 s are i.i.d .",
    "laplace random variables @xcite , each with zero mean and variance two .",
    "the first term in the sum is the standard infinite blocklength mutual information expression , whereas the second term is due to the finite blocklength , and in particular captures the effect of atypical noise realizations .",
    "this second term goes to zero as @xmath84 ( i.e. , atypical noise does not occur in the infinite blocklength limit ) , but can not be ignored for finite @xmath19 .",
    "the sum of i.i.d .",
    "laplace random variables has a bessel - k distribution , which is difficult to compute for large @xmath19 but can be very accurately approximated by a gaussian as verified in @xcite .",
    "thus , the mutual information conditioned on the @xmath10 channel realizations is approximated by a gaussian random variable :    @xmath85    ( this is different from section [ sec_gauss ] , where the gaussian approximation is made with respect to the fading realizations ) .",
    "therefore , we can approximate the outage probability with finite block - length @xmath19 by averaging the cumulative distribution function ( cdf ) of ( [ gauss_finite ] ) over different channel realizations : @xmath86    in fig . [ fig : ps_r_fin ] , we compare finite and infinite blocklength codes by plotting success probability @xmath26 vs. @xmath15 ( bits / symbol ) for @xmath78 at @xmath38 and @xmath39 db . it is clearly seen that the steepness of the success - rate curve is reduced by the finite blocklength ; this is a consequence of atypical noise realizations .",
    "we can now consider goodput maximization for a given blocklength @xmath19 : @xmath87 where both @xmath15 and @xmath14 are computed ( numerically ) in the finite codeword block - length regime .    in fig .",
    "[ fig : opt_eps_snr_fin ] , the optimal @xmath14 vs. snr ( db ) is plotted for both finite block - length coding and infinite block - length coding .",
    "we see that the optimal error probability becomes larger , as expected by success - rate curves with reduced steepness in fig .",
    "[ fig : ps_r_fin ] . at high snr",
    ", the finite block - length coding curve almost overlaps the infinite block - length coding curve because the unusual noise term in the mutual information expression is negligible for large values of snr .",
    "as expected , the optimal reliability level with finite blocklength codes does not differ significantly from the idealized case .",
    "a critical component of arq is error detection , which is generally performed using a cyclic redundancy check ( crc ) .",
    "the standard usage of crc corresponds to appending @xmath88 parity check bits to @xmath89 information bits , yielding a total of @xmath20 bits that are then encoded ( by the channel encoder ) into @xmath19 channel symbols . at the receiver ,",
    "the channel decoder ( which is generally agnostic to crc ) takes the @xmath19 channel symbols as inputs and produces an estimate of the @xmath20 bits , which are in turn passed to the crc decoder for error detection .",
    "a basic analysis in @xcite shows that if the channel decoder is in error ( i.e. , the @xmath20 bits input to the channel encoder do not match the @xmath20 decoded bits ) , the probability of an undetected error ( i.e. , the crc decoder signals correct even though an error has occurred ) is roughly @xmath90 .",
    "therefore , the overall probability of an undetected error is well approximated by @xmath91 .",
    "undetected errors can lead to significant problems , whose severity depends upon higher network layers ( e.g. , whether or not an additional layer of error detection is performed at a higher layer ) and the application .",
    "however , a general perspective is provided by imposing a constraint @xmath92 on the undetected error probability , i.e. , @xmath93 . based on this constraint ,",
    "we see that the constraint can be met by increasing @xmath88 , which comes at the cost of overhead , or by reducing the packet error probability @xmath14 , which can significantly reduce goodput ( section [ sec - ideal ] ) .",
    "the question most relevant to this paper is the following : does the presence of a stringent constraint on undetected error probability motivate reducing the phy packet error probability @xmath14 ?",
    "the relevant quantity , along with the undetected error probability , is the rate at which information bits are correctly delivered , which is : @xmath94 where @xmath95 is the effective transmitted rate after accounting for the parity check overhead .",
    "it is then relevant to maximize this rate subject to the constraint on undetected error : and @xmath96 upon @xmath13 , @xmath10 and @xmath19 is suppressed henceforth , except where explicit notation is required . ] : @xmath97    although this optimization problem ( nor the version based on the gaussian approximation ) is not analytically tractable , it is easy to see that the solution corresponds to @xmath98 , where @xmath35 is roughly the optimum packet error probability assuming perfect error detection ( i.e. the solution from section [ sec - ideal ] ) . in other words ,",
    "the undetected error probability constraint should be satisfied by choosing @xmath88 sufficiently large while leaving the phy transmitted rate nearly untouched . to better understand this , note that reducing @xmath88 by a bit requires reducing @xmath14 by a factor of two .",
    "the corresponding reduction in crc overhead is very small ( roughly @xmath99 ) , while the reduction in the transmitted rate is much larger .",
    "thus , if we consider the choices of @xmath14 and @xmath88 that achieve the constraint with equality , i.e. , @xmath100 , goodput decreases as @xmath14 is decreased below the packet error probability which is optimal under the assumption of perfect error detection . in other words , operating the phy at a more reliable point is not worth the small reduction in crc overhead .      in certain applications such as voice - over - ip ( voip ) , there is a limit on the number of re - transmissions per packet as well as a constraint on the fraction of packets that are not successfully delivered within this limit .",
    "if such constraints are imposed , it may not be clear how aggressively arq should be utilized .",
    "consider a system where any packet that fails on its @xmath101-th attempt is discarded ( i.e. , at most @xmath102 re - transmissions are allowed ) , but at most a fraction @xmath103 of packets can be discarded , where @xmath104 is a reliability constraint . under these conditions , the probability a packet is discarded is @xmath105 , i.e. , the probability of @xmath101 consecutive decoding failures , while the long - term average rate at which packets are successfully delivered still is @xmath106 . to understand why the goodput expression is unaffected by the delay limit , note that the number of successfully delivered packets is equal to the number of transmissions in which decoding is successful , regardless of which packets are transmitted in each slot .",
    "the delay constraint only affects which packets are delivered in different slots , and thus does not affect the goodput . ) , and then applying the renewal - reward theorem @xcite . ]    since the discarded packet probability is @xmath105 , the reliability constraint requires @xmath107 .",
    "we can thus consider maximization of goodput @xmath106 subject to the constraint @xmath107 . because the goodput is observed to be concave in @xmath14 , only two possibilities exist .",
    "if @xmath108 is larger than the optimal value of @xmath14 for the unconstrained problem , then the optimal value of @xmath14 is unaffected by @xmath103 . in the more interesting and relevant case where @xmath108 is smaller than the optimal unconstrained @xmath14 , then goodput is maximized by choosing @xmath14 equal to the upper bound @xmath108 .",
    "thus , a strict delay and reliability constraint forces the phy to be more reliable than in the unconstrained case .",
    "however , amongst all allowed packet error probabilities , goodput is maximized by choosing the largest .",
    "thus , although strict constraints do not allow for very aggressive use of arq , nonetheless arq should be utilized to the maximum extent possible .",
    "we finally remove the assumption of perfect acknowledgements , and consider the realistic scenario where ack / nack feedback is not perfect and where the acknowledgement overhead is factored in .",
    "the main issue confronted here is the joint optimization of the reliability level of the forward data channel and of the reverse acknowledgement ( feedback / control ) channel .",
    "as intuition suggests , reliable communication is possible only if some combination of the forward and reverse reliability levels is sufficiently large ; thus , it is not clear if operating the phy at a relatively unreliable level as suggested in earlier sections is appropriate .",
    "the effects of acknowledgement errors can sometimes be reduced through higher - layer mechanisms ( e.g. , sequence number check ) , but in order to shed the most light on the issue of forward / reverse reliability , we focus on an extreme case where acknowledgement errors are most harmful . in particular , we consider a setting with delay and reliability constraints as in section [ sec - delay ] , and where any nack to ack error leads to a packet missing the delay deadline .",
    "we first describe the feedback channel model , and then analyze performance .",
    "we assume ack / nack feedback is performed over a rayleigh fading channel using a total of @xmath109 symbols which are distributed on @xmath110 independently faded subchannels ; here @xmath110 is the diversity order of the feedback channel , which need not be equal to @xmath10 , the forward channel diversity order . since the feedback is binary , bpsk is used with the symbol repeated on each sub - channel @xmath111 times . for the sake of simplicity , we assume that the feedback channel has the same average snr as the forward channel , and that the fading on the feedback channel is independent of the fading on the forward channel .",
    "after maximum ratio combining at the receiver , the effective snr is @xmath112 , where @xmath113 are the feedback channel fading coefficients .",
    "the resulting probability of error ( denoted by @xmath114 ) , averaged over the fading realizations , is @xcite : @xmath115 where @xmath116 .",
    "clearly , @xmath114 is decreasing in @xmath109 and @xmath13 .",
    "and @xmath117 errors have unequal probabilities .",
    "however , this does not significantly affect performance and thus is not considered . ]      in order to analyze performance with non - ideal feedback , we must first specify the rules by which the transmitter and receiver operate .",
    "the transmitter takes precisely the same actions as in section [ sec - delay ] : the transmitter immediately moves on to the next packet whenever an ack is received , and after receiving @xmath102 consecutive nack s ( for a single packet ) it attempts that packet one last time but then moves on to the next packet regardless of the acknowledgement received for the last attempt .",
    "of course , the presence of feedback errors means that the received acknowledgement does not always match the transmitted acknowledgement .",
    "the receiver also operates in the standard manner , but we do assume that the receiver can always determine whether or not the packet being received is the same as the packet received in the previous slot , as can be accomplished by a simple correlation ; this reasonable assumption is equivalent to the receiver having knowledge of acknowledgement errors .    in this setup",
    "an ack@xmath118nack error causes the transmitter to re - transmit the previous packet , instead of moving on to the next packet .",
    "the receiver is able to recognize that an acknowledgement error has occurred ( through correlation of the current and previous received packets ) , and because it already decoded the packet correctly it does not attempt to decode again . instead , it simply transmits an ack once again .",
    "thus , each ack@xmath118nack error has the relatively benign effect of wasting one arq round .",
    "on the other hand , nack@xmath118ack errors have a considerably more deleterious effect because upon reception of an ack , the transmitter automatically moves on to the next packet .",
    "because we are considering a stringent delay constraint , we assume that such a nack@xmath118ack error can not be recovered from and thus we consider it as a lost packet that is counted towards the reliability constraint .",
    "this is , in some sense , a worst - case assumption that accentuates the effect of nack@xmath118ack errors ; some comments related to this point are put forth at the end of this section .",
    "to more clearly illustrate the model , the complete arq process is shown in fig .",
    "[ fig : arq_proc ] for @xmath119 .",
    "each branch is labeled with the success / failure of the transmission as well as the acknowledgement ( including errors ) .",
    "circle nodes refer to states in which the receiver has yet to successfully decode the packet , whereas triangles refer to states in which the receiver has decoded correctly .",
    "a packet loss occurs if there is a decoding failure followed by a nack@xmath118ack error in the first two rounds , or if decoding fails in all three attempts .",
    "all other outcomes correspond to cases where the receiver is able to decode the packet in some round , and thus successful delivery of the packet . in these cases , however , the number of arq rounds depends on the first time at which the receiver can decode and when the ack is correctly delivered .",
    "( if an ack is not successfully delivered , it may take up to @xmath101 rounds before the transmitter moves on to the next packet . )",
    "notice that after the @xmath101-th attempt , the transmitter moves on to the next packet regardless of what acknowledgement is received ; this is due to the delay constraint that the transmitter follows .    based on the figure and the independence of decoding and feedback errors across rounds , the probability that a packet is lost ( i.e.",
    ", it is not successfully delivered within @xmath101 rounds ) is : @xmath120 where the first @xmath102 terms represent decoding failures followed by a nack@xmath118ack error ( more specifically , the @xmath121-th term corresponds to @xmath122 decoding failures and @xmath122 correct nack transmissions , followed by another decoding failure and a nack@xmath118ack error ) , and the last term is the probability of @xmath101 decoding failures and @xmath102 correct nack transmissions .",
    "if we alternatively compute the success probability , we get the following different expression for @xmath123 : @xmath124 where the @xmath3-th summand is the probability that successful forward transmission occurs in the @xmath3-th arq round . based upon ( [ xi_del ] ) and ( [ xi_del2 ] )",
    "we see that @xmath123 is increasing in both @xmath14 and @xmath114 .",
    "thus , a desired packet loss probability @xmath123 can be achieved by different combinations of the forward channel reliability and the feedback channel reliability : a less reliable forward channel requires a more reliable feedback channel , and vice versa .    as in section [ sec - delay ] we impose a reliability constraint @xmath125 , which by ( [ xi_del ] ) translates to a joint constraint on @xmath14 and @xmath114 .",
    "the relatively complicated joint constraint can be accurately approximated by two much simpler constraints .",
    "since we must satisfy @xmath126 even with perfect feedback ( @xmath127 ) , for any @xmath128 we also must satisfy @xmath126 ( this ensures that @xmath101 consecutive decoding failures do not occur too frequently ) .",
    "furthermore , by examining ( [ xi_del ] ) it is evident that the first term is dominant in the packet loss probability expression .",
    "thus the constraint @xmath125 essentially translates to the simplified constraints @xmath129 these simplified constraints are very accurate for values of @xmath14 not too close to @xmath108 . on the other hand , as @xmath14 approaches @xmath108 , @xmath114 must go to zero very rapidly ( i.e. much faster than @xmath130 ) in order for @xmath125 .",
    "the first constraint in ( [ simple - constraints ] ) reveals a general design principle : the _ combination _ of the forward and feedback channel must be sufficiently reliable .",
    "this is because @xmath131 is precisely the probability that a packet is lost because the initial transmission is decoded incorrectly and is followed by a nack@xmath118ack error .",
    "having established the reliability constraint , we now proceed to maximizing goodput while taking acknowledgement errors and arq overhead into account . with respect to the long - term average goodput , by applying the renewal - reward theorem again",
    "we obtain : @xmath132}.\\end{aligned}\\ ] ] where random variable @xmath25 is the number of arq rounds per packet , and @xmath27 $ ] is derived in appendix [ pf_c ] . here",
    ", @xmath133 is the feedback overhead penalty because each packet spanning @xmath19 symbols is followed by @xmath109 symbols to convey the acknowledgement .",
    "we now maximize goodput with respect to both the forward and feedback channel error probabilities : @xmath134}\\\\ & & \\text{subject to}~~ \\xi_d \\leq q\\nonumber\\end{aligned}\\ ] ] noting that @xmath114 is a decreasing function of the number of feedback symbols @xmath109 , according to ( [ fb_rl ] ) .",
    "this optimization is not analytically tractable , but can be easily solved numerically and can be understood through examination of the dominant relationships .",
    "the overhead factor @xmath135 clearly depends only on @xmath114 ( i.e. , @xmath109 ) .",
    "although the second term @xmath136 $ ] depends on both @xmath14 and @xmath114 , the dependence upon @xmath114 is relatively minor as long as @xmath114 is reasonably small ( i.e. less than @xmath0 ) .",
    "thus , it is reasonable to consider the perfect feedback setting , in which case the second term is @xmath106 .",
    "therefore , the challenge is balancing the feedback channel overhead factor @xmath133 with the efficiency of the forward channel , approximately @xmath106 , while satisfying the constraint in ( [ simple - constraints ] ) .",
    "if @xmath109 is chosen small , the feedback errors must be compensated with a very reliable , and thus inefficient , forward channel ; on the other hand , choosing @xmath109 large incurs a large feedback overhead penalty but allows for a less reliable , and thus more efficient , forward channel .    in fig .",
    "[ fig : eps_theta_del ] , the jointly optimal ( @xmath137 ) are plotted for a conservative set of forward channel parameters ( @xmath138 with @xmath139 or @xmath39 db , and @xmath140 data symbols per packet ) , stringent delay and reliability constraints ( up to @xmath119 arq rounds and a reliability constraint @xmath141 ) , and different diversity orders ( @xmath142 and @xmath143 ) for the feedback channel .",
    "also plotted is the curve specifying the ( @xmath144 ) pairs that achieve the reliability constraint @xmath145 .",
    "as discussed earlier , this curve has two distinct regions : for @xmath146 it is essentially the straight line @xmath147 , whereas @xmath114 must go to zero very quickly as @xmath14 approaches @xmath148 .",
    "when @xmath149 , the optimal point corresponds to the transition between these two regions . moving to the right of",
    "the optimal corresponds to making the phy more reliable while making the control channel less reliable ( i.e. , decreasing @xmath14 and @xmath109 ) , but this is suboptimal because the overhead savings do not compensate for the loss incurred by a more reliable phy . on the other hand , moving to the left is suboptimal because only a very modest increase in @xmath14 is allowed , and this increase comes at a large expense in terms of control symbols . if @xmath150 , the optimal point is further to the left because the feedback overhead required to achieve a desired error rate is reduced .",
    "however , the behavior is quite different if there is no diversity on the feedback channel ( @xmath151 ) . without diversity ,",
    "the feedback error probability decreases extremely slowly with @xmath109 ( at order @xmath152 ) , and thus a very large @xmath109 is required to achieve a reasonable feedback error probability . in this extreme case , it is optimal to sacrifice significant phy efficiency and choose @xmath14 quite a bit smaller than @xmath148 .",
    "notice that increasing @xmath13 moves the optimal to the left for all values of @xmath110 because a larger snr improves the feedback channel reliability while not significantly changing the behavior of the forward channel .",
    "this behavior is further explained in fig .",
    "[ fig : gput_eps_del ] , where goodput @xmath22 ( optimized with respect to @xmath114 ) is plotted versus forward error probability @xmath14 for the parameters of the previous figure , with @xmath139 db and @xmath151 and @xmath80 here .",
    "the figure illustrates the stark contrast with respect to feedback channel diversity : with diversity ( even for @xmath149 ) , the goodput increases monotonically up to a point quite close to @xmath153 , while without diversity the goodput peaks at a point far below @xmath153 .",
    "this is due to the huge difference in the feedback channel reliability with and without diversity : in order to achieve @xmath154 , at @xmath139 db without diversity @xmath155 symbols are required , whereas @xmath156 suffices for @xmath149 . to more clearly",
    "understand why the optimal point with diversity is so close to @xmath153 , let us contrast two different choices of @xmath14 for @xmath149 . at the optimal @xmath157 , we require @xmath158 and thus @xmath159 . on the other hand , at the suboptimal @xmath160 we require @xmath161 and thus @xmath156 . reducing the forward error probability by a factor of @xmath162",
    "reduces the feedback overhead from @xmath163 to @xmath164 , but reduces the transmitted rate by about @xmath165 .    the takeaway message of this analysis is clear : as long as the feedback channel has at least some diversity ( e.g. , through frequency or antennas ) , stringent post - arq reliability constraints should be satisfied by increasing the reliability of the feedback channel instead of increasing the forward channel reliability .",
    "this is another consequence of the fact that decreasing the forward channel error probability requires a huge backoff in terms of transmitted rate , which in this case is not compensated by the corresponding decrease in feedback overhead .",
    "while up to now we have considered simple arq , contemporary wireless systems often utilize more powerful hybrid - arq ( harq ) techniques .",
    "when incremental redundancy ( ir ) harq , which is the most powerful type of harq , is implemented , a nack triggers the transmission of extra parity check bits instead of re - transmission of the original packet , and the receiver attempts to decode a packet on the basis of all previous transmissions related to that packet .",
    "this corresponds to accumulation of mutual information across harq rounds , and thus essentially matches the transmitted rate to the instantaneous channel conditions without requiring csi at the transmitter @xcite .",
    "the focus of this section is understanding how the phy transmitted rate should be chosen when harq is used .",
    "unlike simple arq , harq requires the receiver to keep information from previous rounds in memory ; partly for this reason , harq is generally implemented in a two - layered system ( e.g. , in 4 g cellular networks such as lte @xcite @xcite ) in which the harq process has to restart ( triggered by a higher - layer simple arq re - transmission ) if the number of harq rounds reaches a defined maximum .",
    "the precise model we study is described as follows .",
    "as before , each harq transmission ( i.e. , round ) experiences a diversity order of @xmath10 .",
    "however , a maximum of @xmath166 harq rounds are allowed per packet . if a packet can not be decoded after @xmath166 harq rounds , a post - harq outage is declared .",
    "this triggers a higher - layer simple arq re - transmission , which restarts the harq process for that packet .",
    "this two - layered arq process continues ( indefinitely ) until the packet is successfully received at the receiver . for the sake of simplicity ,",
    "we proceed under the ideal assumptions discussed in section [ sec - ideal ] .",
    "note that the case @xmath167 reverts to the simple arq model discussed in the rest of the paper .",
    "given this model , the first - harq - round outage probability , denoted @xmath168 , is exactly the same as the non - harq outage probability with the same @xmath13 , diversity order @xmath10 , and rate @xmath11 , i.e. , @xmath169.\\end{aligned}\\ ] ] in this expression @xmath11 is the transmitted rate during the first harq round , which we refer to as the harq initial rate @xmath170 hereafter .",
    "because ir leads to accumulation of mutual information , the number of harq rounds needed to decode a packet is the smallest integer @xmath171 ( @xmath172 ) such that @xmath173 therefore , the post - harq outage , denoted by @xmath14 , is : @xmath174.\\end{aligned}\\ ] ] this is the probability that a packet fails to be decoded after @xmath166 harq rounds , and thus is the probability that the harq process has to be restarted .    using the renewal - reward theorem as in @xcite yields the following expression for the long - term average goodput with harq : @xmath175},\\end{aligned}\\ ] ] where the distribution of @xmath171 is determined by ( [ defnt ] ) .",
    "our interest is in finding the initial rate @xmath170 that maximizes @xmath22 .",
    "this optimization is not analytically tractable , but we can nonetheless provide some insight .    in fig .",
    "[ fig : gput_r_comp ] , goodput is plotted versus vs. @xmath170 for @xmath36 and a maximum of @xmath176 harq rounds , as well as for a system using only simple arq ( i.e. , @xmath167 ) with the same @xmath36 , at @xmath139 and @xmath39 db . we immediately observe that goodput with harq is maximized at a considerably higher rate than for the system without harq .",
    "although we do not have analytical proof , we conjecture that the goodput - maximizing initial rate with harq is always larger than the maximizing rate without harq ( for equal diversity order per round / transmission ) .",
    "in fact , with harq the initial rate should be chosen such that the first - round outage @xmath168 is quite large , and for larger values of @xmath166 the optimizer actually trends towards one .",
    "if @xmath168 is small , then harq is rarely used which means that the rate - matching capability provided by harq is not exploited .",
    "however , @xmath170 should not be chosen so large such that there is significant probability of post - harq outage , because this leads to a simple arq re - transmission and thus forces harq to re - start .",
    "the following theorem provides an upper bound on the optimal initial rate :    [ theo1 ] for any @xmath177 , and @xmath166 , the optimal initial rate with harq is upper bounded by @xmath178 times the optimal transmitted rate for a non - harq system with diversity order @xmath179 .",
    "the harq goodput can be rewritten as @xmath180}.\\end{aligned}\\ ] ] based on ( [ pharq ] ) we see that the post - harq outage probability @xmath14 is precisely the same as the outage probability for a non - harq system with diversity order @xmath179 and transmitted rate @xmath181 .",
    "therefore , the term @xmath182 in ( [ eq - gputharq ] ) is precisely the goodput for a non - harq system with diversity order @xmath179 .",
    "based on ( [ defnt ] ) we can see that the term @xmath183 $ ] is decreasing in @xmath181 , and thus the value of @xmath181 that maximizes ( [ eq - gputharq ] ) is smaller than the value that maximizes @xmath182 .",
    "notice that @xmath179 is the maximum diversity experienced by a packet if harq is used , whereas @xmath179 is the precise diversity order experienced by each packet in the reference system ( in the theorem ) without harq . combined with our earlier observation",
    ", we see that the initial rate should be chosen large enough such that harq is sufficiently utilized , but not so large such that simple arq is overly used .",
    "in this paper we have conducted a detailed study of the optimum physical layer reliability when simple arq is used to re - transmit incorrectly decoded packets .",
    "our findings show that when a cross - layer perspective is taken , it is optimal to use a rather unreliable physical layer ( e.g. , a packet error probability of 10% for a wide range of channel parameters ) .",
    "the fundamental reason for this is that making the physical layer very reliable requires a very conservative transmitted rate in a fading channel ( without instantaneous channel knowledge at the transmitter ) .",
    "our findings are quite general , in the sense that the phy should not be operated reliably even in scenarios in which intuition might suggest phy - level reliability is necessary .",
    "for example , if a smaller packet error mis - detection probability is desired , it is much more efficient to utilize additional error detection bits ( e.g. , crc ) as compared to performing additional error correction ( i.e. , making the phy more reliable ) .",
    "a delay constraint imposes an upper bound on the number of arq re - transmissions and an upper limit on the phy error probability , but an optimized system should operate at exactly this level and no lower .",
    "finally , when acknowledgement errors are taken into account and high end - to - end reliability is required , such reliability should be achieved by designing a reliable feedback channel instead of a reliable data ( phy ) channel .    in a broader context , one important message is that traditional diversity metrics , which characterize how quickly the probability of error can be made very small , may no longer be appropriate for wireless systems due to the presence of arq . as seen in @xcite in the context of multi - antenna communication , this change can significantly reduce the attractiveness of transmit diversity techniques that reduce error at the expense of rate .",
    "we first prove the strict concavity of @xmath51 . for any invertible function @xmath184 ,",
    "the following holds @xcite : @xmath185 by combining this with @xmath186 , we get @xmath187 which is strictly negative . according to this , the second derivative of @xmath188 is : @xmath189 because @xmath190 , in order to prove @xmath191 we only need to show that the expression inside the parenthesis in ( [ etag_prov ] ) is strictly positive . if we substitute @xmath192 ( here we define @xmath193 ) , then we only need to prove @xmath194 .",
    "notice when @xmath195 , the left hand side is negative ( because @xmath196 ) and the inequality holds .",
    "when @xmath197 , the left hand side becomes @xmath198 . from @xcite , @xmath199 , so if @xmath197 , @xmath200 as a result , the second derivative of @xmath188 is strictly smaller than zero and thus @xmath51 is strictly concave in @xmath14 .",
    "since @xmath51 is strictly concave in @xmath14 , we reach the fixed point equation in ( [ first_der ] ) by setting the first derivative to zero .",
    "the concavity of @xmath51 implies @xmath201 is decreasing in @xmath14 , and thus from ( [ first_der ] ) we see that @xmath60 is increasing in @xmath59 .",
    "if the arq process terminates after @xmath3 rounds ( @xmath202 ) , the reasons for that can be :    * the first @xmath3 decoding attempts are unsuccessful , the first @xmath203 nacks are received correctly , but a nack@xmath118ack error happens in the @xmath3-th round , the probability of which is @xmath204 . * the packet is decoded correctly in the @xmath205-th round ( for @xmath206 ) , but the ack is not correctly received until the @xmath3-th round .",
    "this corresponds to @xmath207 decoding failures with correct acknowledgements , followed by a decoding success and @xmath208 acknowledgement errors ( ack@xmath118nack ) , and then a correct acknowledgement : @xmath209 .",
    "* there are @xmath101 decoding failures with @xmath102 correct nacks , the probability of which is @xmath211 . *",
    "the packet is decoded correctly in the @xmath205-th round ( for @xmath212 ) , but the ack is never received correctly .",
    "this corresponds to @xmath207 decoding failures with correct nacks , followed by a decoding success and @xmath213 acknowledgement errors ( ack@xmath118nack ) : @xmath214 .",
    "these events are again exclusive .",
    "therefore , the expected number of rounds is : @xmath215 & = & \\sum_{i=1}^{d-1}i\\cdot\\left ( \\varepsilon^i\\cdot(1-\\varepsilon_{\\textrm{fb}})^{i-1}\\cdot\\varepsilon_{\\textrm{fb } } + \\sum_{j=1}^i \\varepsilon^{j-1 }   ( 1-\\varepsilon_{\\textrm{fb}})^j ( 1 - \\varepsilon ) \\varepsilon_{\\textrm{fb}}^{i - j } \\right ) \\nonumber\\\\ & & + d\\cdot\\left ( \\varepsilon^{d-1}\\cdot(1-\\varepsilon_{\\textrm{fb}})^{d-1 } + \\sum_{j=1}^{d-1 } \\varepsilon^{j-1 }   ( 1-\\varepsilon_{\\textrm{fb}})^{j-1 } ( 1 - \\varepsilon ) \\varepsilon_{\\textrm{fb}}^{d - j } \\right).\\end{aligned}\\ ] ]        c.  berger , s.  zhou , y.  wen , p.  willett , and k.  pattipati , `` optimizing joint erasure - and error - correction coding for wireless packet transmissions , '' _ ieee transactions on wireless communications _ , vol .  7 , no . 11 part 2 , pp .",
    "45864595 , 2008 .",
    "m.  s. alouini and a.  j. goldsmith , `` capacity of rayleigh fading channels under different adaptive transmission and diversity - combining techniques , '' _ ieee trans .",
    "_ , vol .",
    "48 , no .  4 , pp .",
    "11651181 , jul .",
    "m.  r. mckay , p.  j. smith , h.  a. suraweera , and i.  b. collings , `` on the mutual information distribution of ofdm - based spatial multiplexing : exact variance and outage approximation , '' _ ieee trans .",
    "inform . theory _",
    "54 , no .  7 , pp . 32603278 , jul",
    ". 2008 .",
    "h.  ekstrom , a.  furuskar , j.  karlsson , m.  meyer , s.  parkvall , j.  torsner , and m.  wahlqvist , `` technical solutions for the _ 3 g _ long - term evolution , '' _ ieee communications magazine _ , vol .",
    "44 , no .  3 , pp .",
    "3845 , 2006 ."
  ],
  "abstract_text": [
    "<S> [ sec - abs ] this paper studies the tradeoff between channel coding and arq ( automatic repeat request ) in rayleigh block - fading channels . </S>",
    "<S> a heavily coded system corresponds to a low transmission rate with few arq re - transmissions , whereas lighter coding corresponds to a higher transmitted rate but more re - transmissions . </S>",
    "<S> the optimum error probability , where optimum refers to the maximization of the average successful throughput , is derived and is shown to be a decreasing function of the average signal - to - noise ratio and of the channel diversity order . </S>",
    "<S> a general conclusion of the work is that the optimum error probability is quite large ( e.g. , @xmath0 or larger ) for reasonable channel parameters , and that operating at a very small error probability can lead to a significantly reduced throughput . </S>",
    "<S> this conclusion holds even when a number of practical arq considerations , such as delay constraints and acknowledgement feedback errors , are taken into account . </S>"
  ]
}