{
  "article_text": [
    "the computation of integrals of the form of @xmath2=\\int_{-1}^1w(x)f(x)dx\\ ] ] is one of the oldest and most important issues in numerical analysis .",
    "quadrature formulae are usually derived from polynomial interpolation by a finite sum @xmath3=\\sum_{j=1}^nw_jf(x_j),\\quad x_j\\in [ -1,1]}.\\ ] ]    among all interpolation type quadrature rules with @xmath0 nodes , the gauss - christoffel formula , denoted by @xmath4 $ ] , has the highest accuracy of degree @xmath5 ( c.f .",
    "davis and rabinowitz @xcite , gautschi @xcite ) . particularly , for jacobi weight function @xmath6",
    "( @xmath7 , @xmath8 ) , fast evaluation of the nodes and weights for the gauss quadrature was given by glaser , liu and rokhlin @xcite with @xmath9 operations , which has been recently extended by both bogaert , michiels and fostier @xcite , and hale and townsend @xcite . a matlab file for computation of these nodes and weights",
    "can be found in chebfun system @xcite .",
    "it has been observed for a long time that , in the case @xmath10 , for most integrands , @xmath0-point gauss and @xmath0-point clenshaw - curtis quadrature ( denoted by @xmath11 $ ] ) are about equally accurate ( c.f . ohara and smith @xcite , evans @xcite and kythe and schferkotter @xcite . for more details , see trefethen @xcite ) .",
    "this observation was made precise by trefethen @xcite , by using new asymptotics on the coefficients of chebyshev expansions for functions of finite regularity : suppose @xmath12 satisfies a dini - lipschitz condition on @xmath13 $ ] , then it has the following uniformly convergent chebyshev series expansion ( c.f .",
    "cheney @xcite ) @xmath14 where the prime denotes summation whose first term is halved , @xmath15 denotes the chebyshev polynomial of degree @xmath16 , and the chebyshev coefficient @xmath17 is defined by @xmath18    trefethen in @xcite - point gauss and clenshaw - curtis quadrature . ]",
    "showed that for an integer @xmath19 , if @xmath12 has an absolutely continuous @xmath20st derivative @xmath21 on @xmath13 $ ] and a @xmath22th derivative @xmath23 of bounded variation @xmath24 , then for each @xmath25 , @xmath26 and @xmath27-i_{n}^g[f]|&\\mbox{for all $ n\\ge k/2 + 1$}\\\\    \\end{array}.\\right.\\ ] ]    chebyshev expansions are very useful tools for numerical analysis .",
    "their convergence is guaranteed under rather general conditions and they often converge fast compared with other polynomial expansions ( c.f . fox and parker @xcite , hesthaven et al .",
    "@xcite , petras @xcite and xiang @xcite ) .",
    "for example , it has been shown that the coefficient @xmath17 of the chebyshev expansion of @xmath28 decays a factor of @xmath29 faster than the corresponding coefficient of the legendre expansion , which is mentioned in @xcite and boyd @xcite , and made precise in @xcite and wang and xiang @xcite .",
    "additionally , the quadrature errors of the gauss and clenshaw - curtis can be represented by using the chebyshev expansion , respectively , if @xmath30 is absolutely convergent , as @xmath31=i[f]-i_n^g[f]=\\sum_{j=2n}^{\\infty}a_je_n^g[t_j],\\ , e_n^{c\\texttt{-}c}[f]=i[f]-i_n^{c\\texttt{-}c}[f]=\\sum_{j = n}^{\\infty}a_je_n^{c\\texttt{-}c}[t_j]}$.}\\ ] ]    a new convergence rate improved one further power of @xmath0 for @xmath0-point gauss and clenshaw - curtis quadrature is given in xiang and bornemann @xcite for @xmath32 ( @xmath33 ) , based on the work of curtis and rabinowitz @xcite and riess and johnson @xcite from the early 1970s , and a refined estimate for gauss quadrature applied to chebyshev polynomials due to petras in 1995 @xcite . here , we say @xmath32 if the chebyshev coefficient @xmath17 satisfies that @xmath34 @xcite .",
    "moreover , from @xcite , we see that if @xmath12 has an absolutely continuous @xmath20st derivative @xmath21 on @xmath13 $ ] ( if @xmath19 ) and @xmath35 then @xmath36 .    in this paper , along the way to @xcite , by using refined estimates on the aliasing errors about the integration of chebyshev polynomials by gauss quadrature , in section 2 , we will improve the convergence rate for @xmath0-point gauss - legendre quadrature for @xmath32 as @xmath37=\\left\\{\\begin{array}{ll } o(n^{-2s}),&0 < s < 1\\\\ o(n^{-2}\\ln n),&s=1\\\\ o(n^{-s-1 } ) , & s>1 \\end{array}.\\right.\\ ] ] in section 3 , we will present optimal general convergence rates for generalized @xmath0-point clenshaw - curtis quadrature , fejr s first and second rules for @xmath32 for the following weights :    * for @xmath6 : @xmath38=\\left\\{\\begin{array}{ll } o(n^{-s-1})&\\mbox{if $ \\min(\\alpha,\\beta)\\ge -\\frac{1}{2}$}\\\\ o(n^{-s-2 - 2\\min(\\alpha,\\beta)})&\\mbox{if $ -1<\\min(\\alpha,\\beta ) < -\\frac{1}{2}$}\\end{array},\\right.\\ ] ] * for @xmath39 : @xmath38=\\left\\{\\begin{array}{ll } o(n^{-s-1})&\\mbox{if $ \\beta > -\\frac{1}{2}$}\\\\ o(n^{-s-2 - 2\\beta}\\ln n)&\\mbox{if $ -1<\\beta\\le -\\frac{1}{2}$}\\end{array}.\\right.\\ ] ]    without ambiguity , here @xmath40 $ ] denotes the quadrature error of the @xmath0-point clenshaw - curtis quadrature , fejr s first and second rules for function @xmath32 , respectively .",
    "it is worth noting that these convergence orders are attainable for some functions of finite regularities .",
    "final remarks on comparison with the convergence rate of gauss quadrature is included in section 4 .",
    "let @xmath41 be the zeros of the legendre polynomial of degree @xmath0 , ordered by @xmath42 , and @xmath43 the corresponding weights in the @xmath0-point gauss quadrature ( @xmath44 ) .",
    "xiang and bornemann @xcite showed for @xmath32 that @xmath45=\\left\\{\\begin{array}{ll } o(n^{-3s/2}),&0 < s < 2\\\\ o(n^{-s-1 } ) , & s\\ge 2 \\end{array},\\right .",
    "\\mbox{while   $ e_n^{c\\texttt{-}c}[f]=o(n^{-s-1})$ for $ s>0$},\\ ] ] by applying the asymptotic formulae for @xmath46 and @xmath43 for @xmath47 denotes the integral part of @xmath48 . ]",
    "@xmath49 where @xmath50 together with the error estimate given by petras @xcite for @xmath51 @xmath52|=\\left\\{\\begin{array}{ll } \\frac{2+o(mr / n^2)}{|4r^2 - 1|}+o(m^4/n^6 ) + o(m^2\\log n / n^2),&-n < r",
    "< n\\\\ \\frac{\\pi}{2}+ o(m / n^2 ) + o(m^4/n^6)+o(m\\log n / n^2 ) , & r=\\pm n \\end{array}.\\right.\\ ] ]    by using the following refined estimates , we can get an improved convergence rate on the gauss quadrature .",
    "the aliasing and aliasing errors about the integration of chebyshev polynomials by the @xmath0-point gauss quadrature satisfy that for @xmath53 , @xmath54&=&\\left\\{\\begin{array}{ll}(-1)^j\\frac{2}{1",
    "- 4r^2}+o(m / n^2),&\\ m = j(4n+2)+2r , \\quad -n < r < n\\\\",
    "\\pm(-1)^j\\frac{\\pi}{2}+o(m / n^2),&\\   m=(2j-1)(2n+1)\\pm 1\\end{array},\\right.\\\\ \\quad\\quad \\quad   |e_n^g[t_m]|&=&\\left\\{\\begin{array}{ll } \\frac{2}{|4r^2 - 1|}+o(m / n^2),&\\ m = j(4n+2)+2r,\\quad -n < r < n\\\\ \\frac{\\pi}{2}+o(m / n^2),&\\   m=(2j-1)(2n+1)\\pm 1\\end{array}.\\right.\\end{aligned}\\ ] ]    for the case @xmath51 with @xmath55 and @xmath53 : from ( 2.1 ) , we have @xmath56 where @xmath57 and get @xmath58 which yields @xmath59=\\sum_{k=1}^n w_k\\cos m\\theta_k=(-1)^j i[t_{|2r|}]-2(-1)^j\\sum_{k=1}^n w_k \\sin \\frac{h_k}{2}\\sin\\left(\\frac{h_k}{2}+2r\\theta_k\\right).}$}\\ ] ] furthermore , note that @xmath60 from the estimate on @xmath61 ( 2.3 ) and using @xmath62 for @xmath63 , we obtain @xmath64 and applying an @xmath65 bound on the weights from ( 2.2 ) or szeg @xcite , we obtain @xmath66 moreover , by ( 2.2 ) and ( 2.3 ) , it is easy to derive that @xmath67 which , together with the estimate @xmath68 , induces @xmath69 combining ( 2.9)-(2.11 ) derives @xmath70 .",
    "consequently , by ( 2.8 ) we get ( 2.5 ) , and then using @xmath71=\\frac{2}{1 - 4\\ell^2}$ ] for @xmath72 we get ( 2.6 ) , in the case @xmath51 with @xmath55 and @xmath53 .    for the case",
    "@xmath73 : @xmath74 can be written by ( 2.1 ) as @xmath75\\sin \\theta_k\\\\ & = & \\pm ( -1)^{j+1}\\sin \\theta_k + 2(-1)^{j+1}\\sin\\frac{\\widetilde{h}_k}{2}\\cos \\left(\\frac{\\widetilde{h}_k}{2}\\pm \\theta_k\\right),\\end{array}\\ ] ] where @xmath76 by the same arguments as those for the estimate of @xmath77 , similarly , we have @xmath78 and then @xmath79&=&{\\displaystyle\\pm ( -1)^{j+1}\\sum_{k=1}^nw_k\\sin \\theta_k+2(-1)^{j+1}\\sum_{k=1}^nw_k\\sin\\frac{\\widetilde{h}_k}{2}\\cos \\left(\\frac{\\widetilde{h}_k}{2}\\pm \\theta_k\\right)}\\\\ % & = & { \\displaystyle\\pm ( -1)^{j+1}\\sum_{k=1}^nw_k\\sin \\theta_k+o(m / n^{2})}\\\\ & = & { \\displaystyle\\pm   ( -1)^{j+1}\\sum_{k=1}^nw_k\\sin ( -\\cos^{-1 } x_k)+o(m / n^{2})}\\\\ & = & \\pm   ( -1)^{j}i_n^g[\\sqrt{1-x^2 } ] + o(m / n^{2}).\\end{array}\\ ] ] furthermore , from frster and petras @xcite , we find that @xmath80-i[\\sqrt{1-x^2}]|=|2(i[g(x)]-i_n^g[g(x)])|\\le 2\\sin^2\\frac{2\\pi}{(2n+1)^2}\\ ] ] by setting @xmath81 and applying the fact that @xmath82 is convex on @xmath13 $ ] with @xmath83 , which , together with @xmath84=\\frac{\\pi}{2}$ ] , @xmath71=\\frac{2}{1 - 4\\ell^2}$ ] for @xmath72 and ( 2.12 ) , derives the desired results in the case @xmath73 .",
    "if @xmath85 , the error of the @xmath0-point gauss quadrature has the rate @xmath86    with @xmath32 , that is , @xmath87 for some @xmath88 , we see that @xmath89= \\sum_{m=2n}^{\\infty}a_{m}e^{g}_n [ t_{m}]}\\ ] ] is uniformly and absolutely convergent since @xmath87 and @xmath90|\\le\\frac{32}{15}$ ] for @xmath91 ( c.f . brass and petras @xcite ) . then @xmath92 $ ] can be estimated , by the asymptotics on @xmath93 , estimates ( 2.6 ) on @xmath90|$ ] and using @xmath94=0 $ ] for @xmath95 , as    @xmath96}\\big|\\\\ & = & o\\left({\\displaystyle   \\sum_{j=1}^{n}\\sum_{|r|<n}\\frac{2/|4r^2 - 1|}{(j(4n+2)+2r)^{1+s}}+\\sum_{j=1}^{n}\\frac{\\pi}{((2j-1)(2n+1)\\pm 1)^{1+s}}}\\right)\\\\ & & { \\displaystyle   + o\\left(\\frac{1}{n^2}\\right)\\sum_{m=2n}^{4n(n+1)-1}\\frac{1}{m^{s } } + o\\left(\\sum_{m=4n(n+1)}^{\\infty}\\frac{|e_n^g[t_m]|}{m^{1+s}}\\right)}\\\\ & = & { \\displaystyle o\\left(\\frac{1}{n^{1+s}}\\right)+o\\left(\\frac{1}{n^2}\\right)\\sum_{m=2n}^{4n(n+1)-1}\\frac{1}{m^{s}}+o\\left(\\sum_{m=4n(n+1)}^{\\infty}\\frac{1}{m^{1+s}}\\right)}\\\\ & = & { \\displaystyle o\\left(\\frac{1}{n^{1+s}}\\right)+o\\left(\\frac{1}{n^2}\\int_{2n}^{4n(n+1)-1}x^{-s}dx\\right)+o\\left(\\frac{1}{n^{2s}}\\right ) } , \\end{array}\\ ] ] which leads to the desired result based up @xmath97 , @xmath98 and @xmath99 , respectively .",
    "_ the convergence rate ( 2.13 ) is optimal for @xmath99 , which is verified similarly with @xmath100 used in @xcite ( see the right two columns in figures 2.1 - 2.2 , respectively ) . while for @xmath32 with @xmath101 , the convergence rate ( 2.13 ) is better than that in @xcite .",
    "however , the numerical examples in @xcite show that the @xmath0-point gauss quadrature also enjoys the same convergence rate @xmath102 ( see the left column in figures 2.1 - 2.2 , respectively ) . _    -point gauss for @xmath103 ( @xmath32 ) with @xmath104 , respectively : @xmath105.,width=566,height=226 ]     for @xmath0-point gauss for @xmath103 ( @xmath32 ) with @xmath104 , respectively : @xmath105.,width=566,height=264 ]    remark 2 . _",
    "these techniques are difficult to be extended to study gauss - christoffel quadrature for general jacobi weight functions . however ,",
    "following the ideas of riess and johnson @xcite , trefethen @xcite and xiang and bornemann @xcite , the optimal general convergence rates for generalized @xmath0-point clenshaw - curtis quadrature , fejr s first and second rules are not difficult to be obtained . _",
    "fejr @xcite in 1933 suggested using the zeros of a chebyshev polynomial of first or second kind as interpolation points for quadrature rules of the form ( 1.2 ) .",
    "here we consider the generalized fejr and clenshaw - curtis quadrature .",
    "* fejr s first rule * uses the zeros of the chebyshev polynomial @xmath106 of the first kind ( also called classic chebyshev points @xcite ) @xmath107=\\int_{-1}^1w(x)q_{n-1}^1(x)dx=\\sum_{j=0}^{n-1}b_j^1\\int_{-1}^1w(x)t_j(x)dx,\\ ] ] where @xmath108 is the interpolation polynomial defined by @xmath109 while * fejr s second rule * uses the zeros of the chebyshev polynomial @xmath110 of the second kind ( also called filippi points @xcite ) @xmath111=\\int_{-1}^1w(x)q_{n-1}^2(x)dx=\\sum_{j=0}^{n-1}b_j^2\\int_{-1}^1w(x)t_j(x)dx,\\ ] ] where @xmath112 is defined by @xmath113 * clenshaw - curtis quadrature * ( c.f .",
    "clenshaw - curtis @xcite ) is to use the above chebyshev points with @xmath114 instead of @xmath115 including the endpoints @xmath116 and @xmath117 : @xmath118=\\int_{-1}^1w(x)q_{n-1}^3(x)dx=\\sum_{j=0}^{n-1}b_j^3\\int_{-1}^1w(x)t_j(x)dx,\\ ] ] where @xmath119 is defined by @xmath120 the coefficients @xmath121 ( @xmath122 ) in the above three interpolation polynomials can be fast computed by fft ( c.f .",
    "dahlquist and bjrck @xcite , trefethen @xcite , waldvogel @xcite and xiang et al .",
    "@xcite ) .",
    "in addition , the modified moments @xmath123 can be efficiently evaluated by recurrence formulae for jacobi weights or jacobi weights multiplied by @xmath1 ( c.f . piessens and branders @xcite ) .",
    "* @xmath6 : the recurrence formulae for the evaluation of the modified moments @xmath124 are @xmath125 with @xmath126 furthermore , the asymptotic expression is given by using the asymptotic theory of fourier coefficients ( c.f .",
    "lighthill @xcite ) as @xmath127\\\\    & & +   ( -1)^{k+1}2^{\\alpha-\\beta}\\cos(\\pi\\beta)\\gamma(2\\alpha+2)[k^{-2 - 2\\beta}+o(k^{-2\\beta-4})],\\quad k\\rightarrow \\infty.\\end{array}}\\ ] ] the forward recursion is perfectly numerically stable , except in two cases : @xmath128 * @xmath39 : for @xmath129 the recurrence formulae are @xmath130 with @xmath131,\\ ] ] where @xmath132,\\ ] ] @xmath133 is the beta function and @xmath134 is the psi function ( c.f . abramowitz and stegun @xcite ) .",
    "additionally , the asymptotic expression is given by using the asymptotic theory of fourier coefficients as @xmath135 - 2^{\\beta-\\alpha-2}\\cos(\\pi\\alpha)\\gamma(2\\alpha+4)k^{-4 - 2\\alpha},\\quad k\\rightarrow \\infty.\\end{array}\\ ] ] the forward recursion is also perfectly numerically stable the same as that for ( 3.2 ) .",
    "for more details , see piessens and branders @xcite .    the convergence for the generalized @xmath0-point clenshaw - curtis quadrature",
    ", fejr s first and second rules , for @xmath2=\\int_{-1}^1k(x)f(x)dx\\ ] ] with @xmath136 for some @xmath137 , has been extensively studied in elliott and paget @xcite , sloan @xcite and sloan and smith @xcite , etc . taking into the banach - steinhaus ( or uniform boundedness ) theorem , using the convergence of fourier series and marcinkiewicz s inequality ( * ? ? ? * vol .",
    "28 - 30 ) , sloan @xcite and sloan and smith @xcite showed that the sums of the absolute values of the weights in ( 1.2 ) for the @xmath0-point clenshaw - curtis and fejr s first rule are uniformly bounded , i.e. @xmath138 and extended to the point set @xmath139 .",
    "identity ( 3.7 ) is also satisfied by @xmath140 $ ] .",
    "suppose @xmath141=\\int_{-1}^1k(x)f(x)dx$ ] with @xmath136 for some @xmath137 , then the weights of @xmath140 $ ] satisfy ( 3.7 ) .",
    "since the weights of @xmath140 $ ] can be represented as @xmath142 ( c.f .",
    "@xcite ) . define an odd , @xmath143-periodic function @xmath144 by @xmath145 then @xmath146 has the form of @xmath147 which is the @xmath16th fourier sine coefficient of @xmath144 . in particular , the weight @xmath148 can be written as @xmath149 where @xmath150 is the @xmath0th partial sum of the fourier series for the function @xmath151 .",
    "therefore , the sum of the absolute values of the weights becomes @xmath152 which , by directly following a similar proof to @xcite , establishes @xmath153    suppose @xmath141=\\int_{-1}^1k(x)f(x)dx$ ] with @xmath136 for some @xmath137 , then @xmath154=i[f]$ ] for all continuous functions in @xmath13 $ ] .    by lemma 3.1",
    ", it directly follows from @xcite .    based upon these uniform boundedness , we see that for @xmath32 with @xmath33 , @xmath155|=|i[f]-i_n[f]|=\\big|\\sum_{j = n}^{\\infty}a_je_n[t_j]\\big|\\le \\sum_{j = n}^{\\infty}|a_j||e_n[t_j]|\\ ] ] since @xmath156 and @xmath157 $ ] are uniformly bounded for @xmath158 , where @xmath159 denotes the error of the above these three @xmath0-point quadrature rules corresponding to the two jacobi weight functions .",
    "furthermore , any rearrangement of the infinite sum @xmath160|$ ] converges to the same sum .    in the following",
    ", we will consider aliasing errors on the integration of the chebyshev polynomials by these three quadrature rules , and derive the optimal general rate of convergence .",
    "the computation of the aliasings by the clenshaw - curtis , fejr first and second rules is much simple , which can be exactly computed from fox and parker @xcite @xmath161 for @xmath162 , @xmath163 and @xmath164 as @xmath165=(-1)^pi[t_{j}],\\quad i_n^{f_1}[t_{2p(n-1)}]=0,\\quad i_n^{f_2}[t_{2p(n+1)\\pm j}]=i[t_{j}],\\end{aligned}\\ ] ] @xmath166=i_n^{f_2}[t_{n } ] , \\quad i_n^{f_2}[t_{(2p+1)(n+1)}]=i_n^{f_2}[t_{n+1}],\\end{aligned}\\ ] ] and @xmath167&=i[t_{j}].\\end{aligned}\\ ] ]    ( second mean value theorem for integration @xcite ) ( i ) if @xmath168 \\rightarrow r$ ] is a positive monotonically decreasing function and @xmath169 \\rightarrow r$ ] is an integrable function , then there exists a number @xmath170 $ ] such that @xmath171    \\(ii ) if @xmath168\\rightarrow r$ ] is a positive monotonically increasing function and @xmath169 \\rightarrow r$ ] is an integrable function , then there exists a number @xmath170 $ ] such that @xmath172    \\(iii ) if @xmath168 \\rightarrow r$ ] is a monotonic function and @xmath169 \\rightarrow r$ ] is an integrable function , then there exists a number @xmath170 $ ] such that @xmath173    * @xmath6 : the modified moment satisfies @xmath174 moreover , the aliasing errors by the three quadrature rules for @xmath175 , @xmath176 or @xmath177 with respect to @xmath178 $ ] , @xmath179 $ ] and @xmath180 $ ] for @xmath164 and @xmath181 , respectively , satisfy @xmath182|=|m_j(\\alpha,\\beta)|+o\\left(\\frac{1}{m^{2 + 2\\overline{\\min}(\\alpha,\\beta)}}\\right),\\ ] ] where @xmath183 is defined by @xmath184 * @xmath39 : for @xmath185 , the modified moment satisfies @xmath186 the aliasing errors by the three quadrature rules for @xmath175 , @xmath176 or @xmath177 with respect to @xmath178 $ ] , @xmath179 $ ] and @xmath180 $ ] for @xmath164 and @xmath181 , respectively , satisfy @xmath182|=|g_j(\\alpha,\\beta)|+o\\left(\\frac{\\ln 2m}{m^{2 + 2\\beta}}\\right)+o\\left(\\frac{1}{m^{4 + 2\\alpha}}\\right).\\ ] ] particularly , for @xmath187 , the term @xmath188 in ( 3.15 ) and ( 3.16 ) is replaced by @xmath189 , respectively .",
    "* @xmath6 : by setting @xmath190 , it follows @xmath191 + * in the case @xmath192 * : notice that @xmath193 where the first term on the right hand side can be estimated by @xmath194 then , by @xmath195 for @xmath196 $ ] , the first term in ( 3.17 ) can be estimated as @xmath197 moreover , the second term in ( 3.17 ) @xmath198 can be estimated by ( iii ) of lemma 3.3 as follows @xmath199 for some @xmath200 $ ] by using the monotonicity of @xmath201 on @xmath202 $ ] . applying ( iii ) of lemma 3.3 again for @xmath203 on @xmath202 $ ] , we obtain @xmath204 and then we get @xmath205 which , combining ( 3,17 ) and ( 3.18 ) , yields @xmath206 + similarly , by setting @xmath207 , it yields @xmath208 and then @xmath209 .",
    "+ * in the case @xmath210 * : without loss of generality , assume @xmath187",
    ". then @xmath211 .",
    "the special case for @xmath212 follows directly from @xmath213 . in the other case",
    ", @xmath214 can be reduced to the case @xmath192 by integrating by parts at most @xmath215 times , and then ( 3.13 ) follows from a similar way for this case .",
    "+ similarly , * in the case @xmath216 * , integrating by parts once follows the desired result .",
    "thus , by induction we get ( 3.13 ) for @xmath217 .",
    "+ expression ( 3.14 ) directly follows from the aliasings ( 3.10 - 3.12 ) and the asymptotics on @xmath214 .",
    "* @xmath39 : similarly , by setting @xmath190 it follows @xmath218 + * in the case @xmath219 * : by using @xmath220 , @xmath221 and @xmath222 for @xmath223 $ ] , we have the following estimates on the first and third terms in ( 3.19 ) , respectively , @xmath224 and @xmath225 while for the second term in ( 3.19 ) , integrating by parts we get @xmath226 where @xmath227 can be estimated by ( ii ) of lemma 3.3 for some @xmath228 $ ] , @xmath229 for @xmath230 $ ] , and @xmath231,\\ ] ] as @xmath232 similarly , we obtain @xmath233 which together indicates @xmath234 .",
    "+ particularly , in the case @xmath187 , @xmath235 can be estimated by ( 3.19 ) with @xmath236 instead of @xmath237 as @xmath238 where the second term in ( 3.20 ) can be estimated by @xmath239 for some @xmath240 $ ] , which , together with @xmath241 and ( 3.20 ) , implies @xmath242 .",
    "+ for the general cases , applying similar arguments as those for @xmath6 gives the desired result ( 3.15 ) by induction .",
    "+ expression ( 3.16 ) directly follows from the aliasings and the asymptotics on @xmath243 .",
    "if @xmath85 for @xmath33 , the convergence of @xmath0-point clenshaw - curtis quadrature , fejr s first and second rules has the rate    * for @xmath6 : @xmath38=\\left\\{\\begin{array}{ll } o(n^{-s-1})&\\mbox{if $ \\min(\\alpha,\\beta)\\ge -\\frac{1}{2}$}\\\\ o(n^{-s-2 - 2\\min(\\alpha,\\beta)})&\\mbox{if $ -1<\\min(\\alpha,\\beta ) < -\\frac{1}{2}$}\\end{array};\\right.\\ ] ] * for @xmath39 : @xmath38=\\left\\{\\begin{array}{ll } o(n^{-s-1})&\\mbox{if $ \\beta > -\\frac{1}{2}$}\\\\ o(n^{-s-2 - 2\\beta}\\ln n)&\\mbox{if $ -1<\\beta\\le -\\frac{1}{2}$}\\end{array}.\\right.\\ ] ]    here we only prove ( 3.22 ) for @xmath244 $ ] for @xmath39 .",
    "similar proofs can be applied to prove ( 3.21 ) and other cases in ( 3.22 ) .",
    "with @xmath32 , we see that @xmath245= \\sum_{m = n}^{\\infty}a_m e^{f_1}_n [ t_m]}\\ ] ] is uniformly and absolutely convergent since @xmath87 and @xmath246 $ ] are uniformly bounded independent of @xmath0 and @xmath247",
    ". moreover , @xmath248 $ ] can be estimated by @xmath249|\\le \\sum_{m = n}^{\\infty}|a_m| |e^{f_1}_n [ t_m]| = s_0+s_3,\\ ] ] with @xmath250|},\\quad\\quad s_3 = { \\displaystyle\\sum_{\\ell=1}^{\\infty}|a_{\\ell n}||e_n^{f_1}[t_{\\ell n}]|}.\\ ] ] from the aliasing ( 3.10 ) , we find @xmath251|}\\\\ & \\le&{\\displaystyle\\sum_{p=1}^{\\infty}\\left\\{|a_{2pn}| \\cdot ( |g_{2pn}(\\alpha,\\beta)|+|g_0(\\alpha,\\beta)|)+|a_{(2p-1)n}| \\cdot ( |g_{(2p-1)n}(\\alpha,\\beta)|+|i_n^{f_1}[t_n]|)\\right\\}}\\\\ & = & { \\displaystyle\\sum_{p=1}^{\\infty}\\frac{o(1)}{(2pn ) ^{s+1}}}\\\\ & = & { \\displaystyle o(n^{-s-1 } ) } \\end{array}\\ ] ] since @xmath252 , @xmath253 and @xmath254 $ ] are uniformly bounded from ( 3.15 ) .    additionally ,",
    "@xmath255 can be estimated by @xmath256 according to the aliasing errors ( 3.16 ) @xmath257|=|g_j(\\alpha,\\beta)|+o\\left(\\frac{\\ln 2m}{m^{2 + 2\\beta}}\\right)+o\\left(\\frac{1}{m^{4 + 2\\alpha}}\\right)\\ ] ] as follows with @xmath258 and @xmath259 combining these estimates , we obtain ( 3.22 ) for the @xmath0-point fejr s first rule .",
    "the optimal general convergence rates of these three quadrature rules can be verified by using @xmath260 ( @xmath32 with @xmath33 not an even number ) .",
    "figures 3.1 - 3.2 illustrate the convergence rates for @xmath0-point clenshaw - curtis , fejr s first and second rules for jacobi weight @xmath6 and @xmath261 with @xmath262 and @xmath263 , compared with @xmath264 if @xmath265 , and @xmath266 if @xmath267 , respectively .",
    "figures 3.3 - 3.4 show the convergence rates by these three @xmath0-point quadrature with the same functions for weight @xmath268 , compared with @xmath264 if @xmath269 , and @xmath270 if @xmath271 , respectively .",
    "the numerical evidence shows that clenshaw - curtis and fejr s first and second quadrature are of approximately equal accuracy for these two weights , and the convergence rates ( 3.21 ) and ( 3.22 ) are attainable for some functions of finite regularities .",
    "-point clenshaw - curtis , fejr s first and second rules for @xmath272 ( @xmath273 ) and @xmath6 with @xmath274 and @xmath275 ( @xmath117st row ) , and @xmath276 and @xmath277 ( @xmath278nd row ) , compared with @xmath279 and @xmath280 , respectively , for @xmath105.,width=566,height=302 ]    -point clenshaw - curtis , fejr s first and second rules for @xmath281 ( @xmath282 ) and @xmath6 with @xmath274 and @xmath275 ( @xmath117st row ) , and @xmath276 and @xmath277 ( @xmath278nd row ) , compared with @xmath283 and @xmath284 , respectively , for @xmath105.,width=566,height=302 ]    -point clenshaw - curtis , fejr s first and second rules for @xmath272 ( @xmath273 ) and @xmath268 with @xmath274 and @xmath275 compared with @xmath279 ( @xmath117st row ) , and @xmath276 and @xmath277 ( @xmath278nd row ) , compared with @xmath285 , respectively , for @xmath105.,width=566,height=302 ]    -point clenshaw - curtis , fejr s first and second rules for @xmath281 ( @xmath282 ) and @xmath268 with @xmath274 and @xmath275 compared with @xmath283 ( @xmath117st row ) , and @xmath276 and @xmath277 ( @xmath278nd row ) , compared with @xmath286 , respectively , for @xmath105.,width=566,height=302 ]",
    "the peano kernel theorem provides a most useful representation of the quadrature error for the set of bounded variation functions ( c.f .",
    "brass @xcite , brass and petras @xcite and davis and rabinowitz @xcite ) . based on the peano kernel theorem and the estimates on the kernel function ( c.f .",
    "freud @xcite ) , brass and petras @xcite obtained the error bound for any quadrature with positive quadrature weights ( also see diethelm @xcite ) .",
    "( brass and petras @xcite ) suppose @xmath287 is a nonnegative and integrable weight function satisfies @xmath288 and @xmath289=0 $ ] for any positive interpolatory quadrature formula @xmath290 with @xmath0 nodes=0 $ ] means @xmath291=i[p]-i_n[p]=0 $ ] for all @xmath292 . ] , where @xmath293 denotes the set of polynomials with degree less than @xmath114 . if @xmath12 has an absolutely continuous @xmath20st derivative @xmath21 on @xmath13 $ ] ( if @xmath19 ) and a @xmath22th derivative @xmath23 of bounded variation @xmath294 , then the quadrature error satisfies @xmath295= o(n^{-k-1}).\\ ] ]    thus , @xmath0-point gauss quadrature for the weight function satisfying ( 4.1 ) has the convergence rate ( 4.2 ) .",
    "particularly , the rate ( 4.2 ) can be achieved for functions of the form of @xmath296 where @xmath297 is chosen so that @xmath298 and @xmath299 is the @xmath300th peano kernel function ( c.f brass and petras @xcite ) .",
    "then for this set of functions , the rate ( 4.2 ) is optimal .",
    "however , the optimal convergence rate could be missed for such function which is of @xmath22th bounded variation with @xmath301 but the @xmath300th bounded variation does not exist , for example , @xmath302 ( @xmath303 , @xmath304 ) , @xmath305 ( @xmath306 , @xmath307 , @xmath308 , @xmath309 ) and @xmath310 where @xmath33 is a non - integer , @xmath311 and @xmath312 )      comparing theorem 3.5 and theorem 4.1 , we see that the convergence orders in theorem 3.5 on the above special functions by @xmath0-point clenshaw - curtis quadrature , fejr s first and second rules can be estimated higher than those by @xmath0-point gauss quadrature given in theorem 4.1 for @xmath6 with @xmath314 .    nevertheless , numerical evidence shows that for jacobi weight @xmath6 ( @xmath315 ) , @xmath0-point gauss quadrature enjoys the same convergence rate ( 3.21 ) as that for @xmath0-point clenshaw - curtis and fejr s quadrature , and is of approximately equal accuracy . for simplicity , here we only consider comparisons between gauss and clenshaw - curtis quadrature for @xmath261 ( @xmath316 , @xmath317 ) and @xmath6 with @xmath274 and @xmath275 , and @xmath276 and @xmath277 , respectively : @xmath105 ( see figure 4.1 ) . based on these numerical evidence",
    ", we put an open problem at the end ."
  ],
  "abstract_text": [
    "<S> in this paper , we study the optimal general convergence rates for quadratures derived from chebyshev points . by building on the aliasing errors on integration of chebyshev polynomials , together with the asymptotic formulae on the coefficients of chebyshev expansions , new and optimal convergence rates for @xmath0-point clenshaw - curtis , </S>",
    "<S> fejr s first and second quadrature rules are established for jacobi weights or jacobi weights multiplied by @xmath1 . </S>",
    "<S> the convergence orders are attainable for some functions of finite regularities . in addition , by using refined estimates on aliasing errors on integration of chebyshev polynomials by gauss - legendre quadrature , an improved convergence rate for gauss - legendre is given too .    </S>",
    "<S> clenshaw - curtis , fejr , gauss quadrature , chebyshev points , convergence rate , aliasing , chebyshev expansion .    65d32 , 65d30 </S>"
  ]
}