{
  "article_text": [
    "image deblurring , demixing problem , variational calculus , feature extraction , harmonic analsysis , sampling theory , multiscale analysis , mean curvature , high - order pde",
    "processing textured images is difficult , but such images are common in many applications . for example , as part of the 2015 - 2016 forensic statistics program at the statistical and applied mathematical sciences institute , much of the research dealt with images of fingerprints , balistic striations on bullets , and shoeprints , and all of these are typically textured .",
    "there is an extensive literature on methods for processing piecewise smooth images ; e.g. , image restoration by functional analysis @xcite , image representation by harmonic analysis @xcite and image segmentation @xcite .",
    "much less has been done with textured images .    instead of being piecewise smooth , textured images have fine scale discontinuities , so that neighboring pixels in the image may take very different values in gray scale or color space .",
    "examples are a shoeprint in sand , where the grainy structure of the sand provides the texture , or a fingerprint on leather , where the leather s texture interacts with the signal , see @xcite .    to demix ( i.e. , to simultaneously deblur and decompose ) textured images",
    ", we substantially extend the work in thai and gottschlich @xcite .",
    "that paper provided a directional decomposition of gray - scale images @xmath0 into three parts , consisting of piecewise smooth structure @xmath1 , texture @xmath2 , and fine scale residual structure @xmath3 .",
    "the solution required minimization of the directional total variation norm , which entails the solution to a second - order partial differential equation .",
    "the new approach is based upon @xcite , and also focuses upon gray - scale images .",
    "but now it decomposes the image @xmath0 into four parts , adding fine - scale noise structure @xmath4 to the previous three distinctions .",
    "it also models a blur operator @xmath5 ( for simplicity , @xmath5 is assumed to be known , which is reasonable since in principle it can be measured for any camera in a specific application ) .",
    "thus the demixing problem is formulated as @xmath6 where @xmath7 is a convolution operator .",
    "the solution minimizes a function of several well - chosen norms and uses directional mean curvature rather than a directional decomposition .",
    "this entails solution of a fourth - order partial differential equation ( cf .",
    "zhu and chan @xcite ) which addresses the `` staircase effect '' in the tv - l2 model @xcite .",
    "other high - order partial differential equation ( pde ) approaches for image reconstruction are given in @xcite .",
    "importantly , this work finds a new connection between the minimization problem in demixing and multiscale harmonic analysis .",
    "this connection enables a more general theory and a new solution strategy .",
    "our model realistically reflects the mechanism of image capture .",
    "the true image is a combination of both smooth regions , texture , and fine scale structure .",
    "blurring is inevitable , and the additive noise term accounts for other distortions ( e.g. , threshold variation in the cmos or ccd light sensors , edge effects between pixels ) .",
    "the reconstruction error ( the pixel - wise difference between the true image and the estimated image ) is especially useful since it permits a quantitative basis for comparing the quality of demixing algorithms . when two algorithms make comparable assumptions about smoothness and the blur operator , then any structure that persists after demixing appears in the reconstruction error .",
    "its mean squared error , or the eigenvalues of the estimated covariance matrix , enable one to determine which algorithm has successfully extracted more signal .    despite the ability of the euler - lagrange equations associated with the variational model to achieve advanced performance in image analysis , numerical solution of this high order pde",
    "is difficult .",
    "following @xcite , a numerical augmented lagrangian method ( alm ) is applied to split the directional mean curvature norm into several @xmath8- and @xmath9-norms , which are solvable by iterative shrinkage / thresholding ( ist ) algorithms @xcite .",
    "@xcite proved the equivalence between alm , dual methods ( e.g. , chambolle s projection @xcite ) , and the splitting bregman method @xcite for solving the convex optimization .",
    "( note that alm or the splitting bregman method can be employed in the douglas - rachford splitting scheme @xcite . )    we focus on understanding the advantages of the fourth - order pde approach to reconstruct a smooth image with sharp edges , and make two contributions :    1 .",
    "we provide a general solution to a mathematical model for textured image deconvolution and decomposition with four meaningful components , and 2 .",
    "we find a link between functional analysis and multiscale sampling theory in harmonic analysis and filter banks .",
    "this employs a novel directional mean curvature demixing ( dmcd ) method for textured images corrupted by i.i.d .",
    "noise with a given blur kernel .    to develop these ideas ,",
    "section 2 introduces the mathematical framework , and section 3 describes the use of directional mean curvature for demixing and the algorithm needed to fit the model .",
    "section 4 makes a quantitative comparison between the demixing results from the proposed algorithm and results from a standard alternative algorithm .",
    "section 5 describes the new model s correspondence with multiscale harmonic analysis .",
    "section 6 summarizes our conclusions . for readability ,",
    "mathematical proofs are provided in the appendix and we also refer the reader to @xcite for more detailed notation and literature review .",
    "in this section we define the image and present the directional forward / backward difference operators .",
    "we also specify the directional gradient and divergence operators , the directional laplacian operator , and the discrete directional @xmath10-norm . using the curvelet transform and pointwise shrinkage operators ,",
    "these enable the mathematical derivation of the new demixing algorithm .",
    "given a discrete grayscale image @xmath11 : \\omega \\rightarrow \\mathbb r_+$ ] of size @xmath12 , with the lattice @xmath13 \\in [ 0 \\ , , d_1 - 1 ] \\times [ 0 \\ , , d_2 - 1 ] \\subset \\mathbb z^2 \\big\\ } \\,,\\ ] ] let @xmath14 be the euclidean space whose dimension is given by the size of the lattice @xmath15 ; i.e. , @xmath16 .",
    "the 2d discrete fourier transform @xmath17 acting on @xmath11 $ ] is @xmath18 ~\\stackrel{\\mathcal f}{\\longleftrightarrow}~ f(e^{j { { \\boldsymbol \\omega } } } )    = \\sum_{{{\\boldsymbol k}}\\in \\omega } f[{{\\boldsymbol k } } ] \\cdot e^{-j \\langle { { \\boldsymbol k}}\\ , , { { \\boldsymbol \\omega}}\\rangle_{\\ell_2}},\\ ] ] where the fourier coordinates @xmath19 ^ 2 $ ] are defined on the lattice as @xmath20 = \\left ( \\frac{2 \\pi d_2'}{d_2 } \\ , , \\frac{2 \\pi d_1'}{d_1 } \\right )    \\mid ( d_2 ' \\ , , d_1 ' ) \\in \\left [ - \\frac{d_2}{2 } \\",
    ", , \\frac{d_2}{2 } \\right ) \\times \\left [ - \\frac{d_1}{2 } \\ , , \\frac{d_1}{2 } \\right )",
    "\\subset \\mathbb z^2   \\big\\ } \\,.\\ ] ] we let @xmath21 = \\big [ e^{j\\omega_1 } \\ , , e^{j\\omega_2 } \\big]$ ] denote the discrete coordinates of the fourier transform .",
    "given the matrix @xmath22 the directional forward and backward difference operators ( with periodic boundary condition and direction @xmath23 ) in a matrix form , i.e. @xmath24 \\big]_{{{\\boldsymbol k}}\\in \\omega } \\in x$ ] , are @xmath25 f({{\\boldsymbol z } } ) \\ , ,   \\\\   & \\partial_l^- { { \\mathbf f}}= - \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf f}}{{\\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf f}}\\right ]   ~~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~      -\\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1}-1 ) \\right ] f({{\\boldsymbol z } } ) \\,.\\end{aligned}\\ ] ] the transposed matrices of @xmath26 and @xmath27 are @xmath28 and @xmath29 , respectively .",
    "their adjoint operators are @xmath30 .    the directional gradient and divergence operators are , respectively , @xmath31_{l=0}^{l-1 } \\in x^l    ~~\\text{and}~~   \\text{div}_l^\\pm \\vec{{{\\mathbf g } } } = \\sum_{l=0}^{l-1 } \\partial_l^\\pm { { \\mathbf g}}_l \\in x.\\end{aligned}\\ ] ]    note that the adjoint operator of @xmath32 is @xmath33 , i.e. , @xmath34    the directional laplacian operator is @xmath35    remind that given @xmath36 , the impulse responses of directional derivative and directional laplacian operators in a continuous setting are @xmath37 \\delta({{\\boldsymbol x } } )   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\cos\\left ( \\frac{\\pi l}{l } \\right ) j \\omega_x + \\sin\\left ( \\frac{\\pi l}{l } \\right ) j \\omega_y \\ , ,   \\\\   \\delta_l \\delta({{\\boldsymbol x } } ) & = \\sum_{l=0}^{l-1 } \\partial_l^2 \\delta({{\\boldsymbol x } } )    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   -\\sum_{l=0}^{l-1 } \\left [ \\cos \\left ( \\frac{\\pi l}{l } \\right ) \\omega_x + \\sin \\left ( \\frac{\\pi l}{l } \\right ) \\omega_y \\right]^2 \\,,\\end{aligned}\\ ] ] with @xmath38 are continuous version of @xmath39 which is numerically used instead .",
    "extending @xcite , and due to the discrete nature of images , thai and gottschlich @xcite defines the discrete directional @xmath10-norm with @xmath40 in the anisotropic version as @xmath41_{s=0}^{s-1 } \\in x^s \\big\\ } \\,.\\end{aligned}\\ ] ] as stated in @xcite and @xcite , the space of bounded variation @xmath42 is suitable for the piecewise smooth image component @xmath1 , the @xmath43-space is suitable for the texture component @xmath2 , and the dual besov space @xmath44 is suitable for the noise component @xmath4 , where @xmath45    since natural images are better described in terms of multi - scale and multi - direction , we apply the curvelet transform @xcite instead of the wavelet transform in the dual besov space , see @xcite .",
    "motivated by the dantzig selector @xcite , aujol and chambolle @xcite and thai and gottschlich @xcite , find that the residual @xmath4 is better captured by @xmath46 ( bounded by a constant @xmath47 ) in the curvelet domain , which can be represented by an indicator function on a feasible convex set @xmath48 as @xmath49 this measure controls the maximum curvelet coefficient of the residual @xmath4 .",
    "due to the curvlet transform , no assumption on the kind of noise is needed ( e.g. gaussian , laplacian or weakly correlated noise ) , see @xcite .",
    "following @xcite , thai and gottschlich @xcite proposes a threshold based on extreme value theory for ( [ eq : residual : curvelet ] ) . note that if @xmath4 is normally distributed , the random variable @xmath50 has the gumbel distribution ( since the curvelet of a gaussian process is weakly correlated ) , see @xcite . in general , for correlated noise",
    ", its distribution is a max - stable process @xcite .",
    "it is known that the solution of @xmath9 minimization is a shrinkage operator , see @xcite .",
    "it can be defined in a matrix form as @xmath51 with the point - wise operators .",
    "for example , a multiply pointwise operator of functions @xmath52 is @xmath53 d[{{\\boldsymbol k } } ] \\big]_{{{\\boldsymbol k}}\\in \\omega}$ ] .",
    "the discrete convolution of two functions @xmath54 is defined in a matrix form as @xmath55 \\right]_{{{\\boldsymbol k}}\\in \\omega }    ~~\\text{and}~~   ( f \\ast d)[{{\\boldsymbol k } } ] = \\sum_{{{\\boldsymbol n}}\\in \\omega } f[{{\\boldsymbol n } } ] d[{{\\boldsymbol k}}- { { \\boldsymbol n } } ] \\,.\\end{aligned}\\ ] ] for simplicity , given @xmath56 , we denote @xmath57_{l=0}^l \\in x^{l+1 } \\,.\\end{aligned}\\ ] ]    given a curvelet transform @xmath58 and its inverse version @xmath59 @xcite and a function @xmath0 , the curvelet shrinkage thresholding operator @xmath60 is defined as @xmath61 note that one can easily apply other kinds of harmonic analysis than the curvelet , e.g. , the shearlet @xcite , steerable wavelet @xcite , contourlet @xcite and dual - tree complex wavelet @xcite . given a function @xmath62 , its time reversed function @xmath63 \\big]_{{{\\boldsymbol k}}\\in \\omega } \\in x$ ] is defined as @xmath64 = f[-{{\\boldsymbol k } } ] ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~ f({{\\boldsymbol z}}^{-1 } ) \\,.\\end{aligned}\\ ] ] for more mathematical background and notation , we refer the reader to @xcite .",
    "we assume that the original image @xmath0 , which consists of piecewise smooth regions @xmath1 , texture @xmath2 and fine scale structure @xmath3 , is blurred by the operator @xmath65 and corrupted by noise @xmath4 as @xmath66 = \\big [ h \\ast ( u + v + \\rho ) \\big ] [ { { \\boldsymbol k } } ] + \\epsilon[{{\\boldsymbol k } } ] \\,,~ { { \\boldsymbol k}}\\in \\omega \\,.\\end{aligned}\\ ] ] instead of the total variation norm @xcite , and following the higher order approaches @xcite , we propose a discrete directional mean curvature ( dmc ) norm to reconstruct the piecewise - smooth image @xmath1 as @xmath67 }    ~~\\text{and}~~   \\kappa^\\text{d}_l \\{{{\\mathbf u}}\\ } = \\text{div}^-_l \\bigg\\ { \\frac{\\nabla^+_l { { \\mathbf u } } } { \\sqrt{\\boldsymbol 1 + \\abs{\\nabla^+_l { { \\mathbf u}}}^{\\cdot 2 } } } \\bigg\\}\\end{aligned}\\ ] ] with the matrix of ones @xmath68 ( size @xmath12 ) .",
    "according to @xcite , a discrete dmc is rewritten as @xmath69 } { \\abs { \\big [ \\nabla^+_l { { \\mathbf u}}\\ , , \\boldsymbol 1 \\big ] } } \\bigg\\ } \\,.\\end{aligned}\\ ] ]    as in the dg3pd model @xcite , and following the image generation mechanism shown in fig .  1 , we define the discrete dmcd model for image deconvolution and decomposition problem as @xmath70 following @xcite , the discrete directional @xmath10-norm measures texture in several directions , and the dual of a generalized besov space in the curvelet domain @xmath58 captures the residual structure @xmath3 and noise @xmath4 .",
    "note that the @xmath71-norm of the curvelet transform is a good measure for fine scale oscillating patterns ( i.e. , residual structure and noise ) , which can be either independent or `` weakly '' correlated and need not follow a gaussian distribution .",
    "the @xmath10-norm for texture is handled by the approach of vese and osher @xcite . according to meyer @xcite ( or @xcite )",
    ", the oscillating components do not have small @xmath72 or @xmath73-norm .",
    "from the definition of the directional @xmath10-norm ( [ eq : directionalgnorm ] ) and the curvelet space for noise measurement ( [ eq : residual : curvelet ] ) , the constrained minimization ( [ eq : minimization : sdmcdd:1 ] ) is rewritten as @xmath74     visualization of the innovation model for dmcd .",
    "the inverse operator @xmath75 does not exist in general , but the reconstructed image is obtained by the proposed minimization ( [ eq : minimization : sdmcdd:2]).,scaledwidth=75.0% ]    similar to @xcite , in order to solve ( [ eq : minimization : sdmcdd:2 ] ) we introduce five new variables @xmath76_{l=0}^{l } \\ , , \\vec{{{\\mathbf t } } } = \\big [ { { \\mathbf t}}_l \\big]_{l=0}^{l } \\",
    ", ,   \\vec{{{\\mathbf y } } } = \\big [ { { \\mathbf y}}_l \\big]_{l=0}^l \\ , , \\vec{{{\\mathbf w } } } = \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1}$ ] where @xmath77        & \\in x^{l+1 } \\ , ,    \\\\    { { \\mathbf d}}= \\text{div}^-_l \\vec{{{\\mathbf t } } }       & \\in x \\ , ,     \\\\   \\vec{{{\\mathbf t } } } = \\vec{{{\\mathbf y } } }       & \\in x^{l+1 } \\",
    ", ,    \\\\   \\vec{{{\\mathbf y } } } = \\big [ { { \\mathbf y}}_l \\big]_{l=0}^l     & \\in \\mathscr r \\ , ,   \\\\     \\vec{{{\\mathbf w } } } = \\vec{{{\\mathbf g } } }   & \\in x^s \\ , , \\end{cases } \\end{aligned}\\ ] ] with the indicator function on its feasible convex set @xmath78 } \\leq 1 \\ , , l = 0 , \\ldots , l \\ , , { { \\boldsymbol k}}\\in \\omega \\big\\ } \\,.\\end{aligned}\\ ] ] the augmented lagrangian method ( alm ) is applied to ( [ eq : minimization : sdmcdd:2 ] ) by introducing lagrange multipliers @xmath79_{l=0}^l \\in x^{l+1 } \\ , , \\boldsymbol{\\lambda}_{\\boldsymbol 3 } \\in x \\ , ,   \\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 4 } = \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol 4 l } \\big]_{l=0}^l \\in x^{l+1 } \\ , , \\boldsymbol{\\lambda}_{\\boldsymbol 5 } \\in x \\ ,",
    ", \\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 6 } = \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol 6 s } \\big]_{s=0}^{s-1 } \\in x^s \\ , , \\boldsymbol{\\lambda}_{\\boldsymbol 7 } \\in x \\big)$ ] and positive parameters @xmath80_{i=1}^7 > 0 $ ] as @xmath81 and the lagrange function is @xmath82 due to multi - variable minimization , the numerical solution of ( [ eq : simsegdeb : lagrangefunc ] ) is obtained by applying the alternating directional method of multipliers through iteration @xmath83 to find @xmath84 given the initialization as @xmath85 , we solve the following ten subproblems and then update the seven lagrange multipliers in each iteration .    *",
    "the `` @xmath1-problem '' : * fix @xmath86 and then solve @xmath87 given @xmath88 , we denote the discrete fourier transforms of @xmath89 \\ , , r_l[{{\\boldsymbol k } } ] \\ , , \\lambda_{2l}[{{\\boldsymbol k } } ] \\ , , f[{{\\boldsymbol k } } ] \\ , , v[{{\\boldsymbol k } } ] \\ , ,   \\rho[{{\\boldsymbol k } } ] \\ , , \\epsilon[{{\\boldsymbol k}}]$ ] and @xmath90 $ ] by @xmath91 and @xmath92 , respectively .",
    "the minimizer of ( [ eq : problem : u ] ) is solved in the fourier domain as @xmath93 \\,,\\ ] ] with @xmath94   \\big [ r_l({{\\boldsymbol z } } ) + \\frac { \\lambda_{2 l}({{\\boldsymbol z } } ) } { \\beta_2 } \\big ]   \\\\ &   + \\beta_5 h({{\\boldsymbol z}}^{-1 } ) \\big [ f({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) v({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) p({{\\boldsymbol z } } ) - { { \\mathcal e}}({{\\boldsymbol z } } ) + \\frac{\\lambda_5({{\\boldsymbol z}})}{\\beta_5 } \\big ] \\,,\\end{aligned}\\ ] ] and @xmath95    * the `` @xmath2-problem '' : * fix @xmath96 and then solve @xmath97 let @xmath98 denote the matrix - valued dirac delta function evaluated at @xmath99",
    ". then a solution of ( [ eq : problem : v ] ) is @xmath100 with @xmath101 \\ast { { \\mathbf v}}^{(\\tau-1 ) }     + \\alpha^{(\\tau ) } \\check{{{\\mathbf h } } } \\ast \\big ( { { \\mathbf f}}- { { \\mathbf h}}\\ast { { \\mathbf u}}- { { \\mathbf h}}\\ast { { \\boldsymbol \\rho}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 5}}{\\beta_5 } \\big ) \\big )    \\\\   & + \\frac { \\beta_7 \\alpha^{(\\tau ) } } { \\beta_5 + \\alpha^{(\\tau ) } \\beta_7 }   \\big ( \\underbrace { -\\sum_{s=0}^{s-1 } \\big [ \\cos\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf g}}_s { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf g}}_s \\big ] } _ { = \\text{div}^-_s \\vec{{{\\mathbf g } } } }       - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 7}}{\\beta_7 } \\big ) \\,.\\end{aligned}\\ ] ] using the inverse cumulative distribution function to get the quantile corresponding to probability @xmath102 , one can choose an adaptive @xmath103 at each iteration @xmath104 as @xmath105    * the `` @xmath106-problem '' : * fix @xmath107 and then solve @xmath108 the solution of the @xmath9 minimization ( [ eq : problem : d ] ) is obtained by the shrinkage operator as @xmath109 } _ { = \\text{div}^-_l \\vec{{{\\mathbf t } } } }   - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } \\ , , \\frac{1}{\\beta_3 } \\big ) \\,.\\end{aligned}\\ ] ]    * the `` @xmath110-problem '' : * fix @xmath111 and solve @xmath112 the minimizer of problem ( [ eq : problem : r ] ) is obtained by the shrinkage operator as @xmath113           - \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 2 l } } { \\beta_2 } + \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times { { \\mathbf y}}_l    \\,,~ \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_2 } \\bigg )    \\,,~ &",
    "l = 0 , \\ldots , l-1    \\\\",
    "\\displaystyle { \\mathop{\\rm shrink}}\\left ( \\mathbf{1 } - \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 2 l } } { \\beta_2 } + \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times { { \\mathbf y}}_l    \\,,~ \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_2 }    \\right )    \\,,~ & l = l \\ , .",
    "\\end{cases}\\end{aligned}\\ ] ]    * the `` @xmath114-problem '' : * fix @xmath115 and solve @xmath116 similar to the `` @xmath1-problem '' , we denote @xmath117 and @xmath118 as the discrete fourier transforms of @xmath119 \\ , , \\lambda_{4l}[{{\\boldsymbol k } } ] \\ , , d[{{\\boldsymbol k } } ] \\ , , t_l[{{\\boldsymbol k}}]$ ] and @xmath120 $ ] with @xmath88 , respectively . the solution of this `` @xmath114-problem '' ( [ eq : problem : t ] ) for each separable problem @xmath121 is @xmath122    \\,,~ l = 0 , \\ldots , l-1 \\ , ,    \\\\    \\displaystyle    { { \\mathbf t}}_l = { { \\mathbf y}}_l - \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 } \\ , ,   \\end{cases}\\end{aligned}\\ ] ] with @xmath123   -\\beta_3 \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) \\right ] \\times   \\\\ & \\qquad ~   \\left [ d({{\\boldsymbol z } } ) + \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\left [ \\cos\\left(\\frac{\\pi l'}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right ) ( z_1^{-1 } - 1 ) \\right ] t_{l'}({{\\boldsymbol z } } ) + \\frac { \\lambda_3({{\\boldsymbol z } } ) } { \\beta_3 } \\right ] \\,.\\end{aligned}\\ ] ] note that @xmath124 is similar to the auto - correlation function in the riesz basis @xcite .    *",
    "the `` @xmath125-problem '' : * fix @xmath126 and solve @xmath127 due to its separability , we consider the problem at @xmath23 and the solution of ( [ eq : problem : y ] ) is @xmath128^{\\cdot 2 } } \\ , .    \\end{cases }   \\end{aligned}\\ ] ]    * the `` @xmath129-problem '' : * fix @xmath130 and solve @xmath131 due to the @xmath9-minimization , a solution of ( [ eq : problem : w ] ) for each separable problem @xmath132 is @xmath133 note that @xmath134 can be adaptively chosen as @xmath135 .",
    "* the `` @xmath136-problem '' : * fix @xmath137 and solve @xmath138 due to the higher order partial differential equation ( in a discrete setting ) of the euler - lagrange equation for ( [ eq : problem : g ] ) , the solution is obtained in the fourier domain , which is similar to the `` @xmath1-problem '' and the `` @xmath114-problem '' .",
    "we denote @xmath139 and @xmath140 as the discrete fourier transform of @xmath141 \\ , , \\lambda_{6s}[{{\\boldsymbol k } } ] \\ , , g_s[{{\\boldsymbol k}}]$ ] and @xmath142 $ ] with @xmath88 , respectively .",
    "the solution of this `` @xmath136-problem '' ( [ eq : problem : g ] ) for each separable problem @xmath132 is @xmath143 with @xmath144   -\\beta_7 \\left [ \\cos\\left(\\frac{\\pi s}{s}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi s}{s}\\right ) ( z_1 - 1 ) \\right ] \\times   \\\\ &   \\left [ v({{\\boldsymbol z } } ) + \\sum_{s'=[0 , s-1 ] \\backslash \\{s\\ } } \\left [ \\cos\\left(\\frac{\\pi s'}{s}\\right)(z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi s'}{s}\\right ) ( z_1^{-1 } - 1 ) \\right ] g_{s'}({{\\boldsymbol z } } ) + \\frac{\\lambda_7({{\\boldsymbol z}})}{\\beta_7 } \\right ] \\,.\\end{aligned}\\ ] ]    * the `` @xmath3-problem '' : * fix @xmath145 and solve @xmath146 } ^2_{\\ell_2 }    \\big\\}.\\end{aligned}\\ ] ] minimization of ( [ eq : problem : rho ] ) is approximated by the first - order taylor expansion as @xmath147 \\big|\\big|^2_{\\ell_2 }    \\big\\ } \\,.\\end{aligned}\\ ] ] its solution is @xmath148 \\,,\\end{aligned}\\ ] ] where @xmath149 can be selected by the @xmath102-quantile as @xmath150 .",
    "note that without component @xmath3 in minimization ( [ eq : minimization : sdmcdd:2 ] ) , it is difficult to separate texture @xmath2 and some very fine scale structures in an original image because of a blurring kernel .    * the `` @xmath4-problem '' : * fix @xmath151 and solve @xmath152 \\big|\\big|^2_{\\ell_2 }    \\big\\}.\\end{aligned}\\ ] ] similar to the `` @xmath3-problem '' ( [ eq : problem : rho ] ) and given a possible choice @xmath153 , the solution of ( [ eq : problem : epsilon ] ) is @xmath154 \\ , .",
    "\\end{aligned}\\ ] ]    the final solution is found by iteratively updating the lagrange multipliers @xmath155    @xmath156     \\,,~~ \\abs{\\vec{{{\\mathbf r } } } } = \\sqrt { \\sum_{l=0}^l { { \\mathbf r}}_l^{\\cdot 2 } } \\,,~~    \\langle \\vec{{{\\mathbf y } } } \\ , , \\vec{{{\\mathbf r } } } \\rangle_x = \\sum_{l=0}^l { { \\mathbf y}}_l \\cdot^\\times { { \\mathbf r}}_l    \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 2 l}^{(\\tau ) } & =    \\begin{cases }      \\boldsymbol{\\lambda}_{\\boldsymbol 2 l}^{(\\tau-1 ) } + \\beta_2 \\big [ { { \\mathbf r}}_l - \\cos\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf u}}{{\\mathbf{d}_{\\mathbf 2}^{\\text t}}}- \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d_1}}}{{\\mathbf u}}\\big ] \\ , , &",
    "l = 0 , \\ldots , l-1 \\\\",
    "\\boldsymbol{\\lambda}_{\\boldsymbol 2 l}^{(\\tau-1 ) } + \\beta_2 \\big [ { { \\mathbf r}}_l -   \\boldsymbol 1 \\big ] \\ , , &",
    "l = l   \\end{cases }   \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol",
    "3}^{(\\tau ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 3}^{(\\tau-1 ) }   + \\beta_3 \\big [ { { \\mathbf d}}+ \\sum_{l=0}^{l-1 } \\big [ \\cos\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf t}}_l { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf t}}_l \\big ] \\big ]   \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 4 l}^{(\\tau ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 4 l}^{(\\tau-1 ) }   + \\beta_4 \\big [ { { \\mathbf t}}_l - { { \\mathbf y}}_l \\big ] \\,,~~",
    "l = 0 , \\ldots , l   \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 5}^{(\\tau ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 5}^{(\\tau-1 ) }   + \\beta_5 \\big [ { { \\mathbf f}}- { { \\mathbf h}}\\ast { { \\mathbf u}}- { { \\mathbf h}}\\ast { { \\mathbf v}}- { { \\mathbf h}}\\ast { { \\boldsymbol \\rho}}- { { \\boldsymbol \\epsilon}}\\big ]     \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 6 s}^{(\\tau ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 6 s}^{(\\tau-1 ) }   + \\beta_6 \\big [ { { \\mathbf w}}_s - { { \\mathbf g}}_s \\big ]        \\,,~ s = 0 , \\ldots , s-1    \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 7}^{(\\tau ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 7}^{(\\tau-1 ) }   + \\beta_7 \\big [ { { \\mathbf v}}+ \\underbrace { \\sum_{s=0}^{s-1 } \\left [ \\cos\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf g}}_s { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf g}}_s \\right ] } _ { = -\\text{div}^-_s \\vec{{{\\mathbf g } } } } \\big ] \\ , .      \\end{aligned}\\ ] ]    as in @xcite , relative error on the log scale shows the convergence of the algorithm as @xmath157 note that the convergence can be performed by other criteria , see @xcite .",
    "we use this criterion because the problem is convex in @xmath158 , and because our method emphasizes texture recovery .",
    "figure [ fig : deblurdecomp : barbara : nonoise ] illustrates a performance of our demixing model in terms of simultaneously decomposing and deblurring through directional mean curvature .",
    "this result will be clearly explained in later sections after we set up the link between the dmcd model and filter banks in harmonic analysis .",
    "the algorithms 1 - 4 in appendix c summarize a numerical solution of the dmcd model ( [ eq : minimization : sdmcdd:1 ] ) .",
    "in this section , we establish a deep connection between the proposed demixing model and multiscale harmonic analysis . specifically , we analyze filter banks generated by the dmcd model at iteration @xmath104 in the ordering for the @xmath159-problems according to the algorithms 1 - 4 in appendix c. these filter banks are similar to a wavelet - like operator @xcite .",
    "we then generalize the concept of filter banks in the @xmath1-problem and the @xmath160-problem to continuous and discrete multiscale sampling versions .",
    "the mathematical proofs are described in proposition [ prop : vcpyramid : problem : u : spatial]-[prop : dmcddmultiscalesamplingtheory : g - problem ] in appendix a. to summarize the filter banks of these solutions , we refer the reader to algorithms 5 - 7 in appendix c and figure [ fig : mdcd_let : filterbanks : c0_1 ] , [ fig : mdcd_let : filterbanks : c10 ] , [ fig : mdcd_let : filterbanks:3d ] ( for a version of sampling theory ) and figure [ fig : mdcd_let : u - g - problems ] ( for multiscale version ) .",
    "although the concept of filter banks and scaling / wavelet functions are different in harmonic analysis , we shall combine these two concepts in this section .",
    "consider the sampling theory form for the @xmath1-problem ( see proposition [ prop : vcpyramid : problem : u : spatial ] in appendix a ) .",
    "given @xmath88 and taking @xmath161 , a solution of the @xmath1-problem ( [ eq : problem : u ] ) at iteration @xmath104 can be rewritten in a form of sampling theory as @xmath162 = \\left ( \\phi^{l , c_{25 } } \\ast \\check{h } \\ast \\left ( f - h \\ast v^{(\\tau-1 ) } - h \\ast \\rho^{(\\tau-1 ) } - \\epsilon^{(\\tau-1 ) } + \\frac{\\lambda_5^{(\\tau-1)}}{\\beta_5 } \\right ) \\right)[{{\\boldsymbol k } } ]    \\notag   \\\\ &   + \\sum_{l=0}^{l-1 } \\left ( \\check{\\tilde{\\psi}}^{l , c_{25}}_l \\ast    \\left [ { \\mathop{\\rm shrink}}\\left ( \\psi^l_l \\ast u^{(\\tau-1 ) } - \\frac { \\lambda_{2 l}^{(\\tau-1 ) } } { \\beta_2 } + \\frac { \\lambda_1^{(\\tau-1 ) } + \\beta_1 } { \\beta_2 } y_l^{(\\tau-1 ) }                        \\,,~ \\frac { \\lambda_1^{(\\tau-1 ) } + \\beta_1}{\\beta_2 } \\right )                + \\frac { \\lambda_{2 l}^{(\\tau-1 ) } } { \\beta_2 } \\right ]   \\right ) [ { { \\boldsymbol k}}]\\end{aligned}\\ ] ] with three definitions .    * definition the of @xmath163}$]-component . * at a direction @xmath23 , we have @xmath164 = \\text{proj}_{[-1,1 ] } \\left [ \\vec{y}\\prime^{(\\tau-1)}[{{\\boldsymbol k } } ] \\right]$ ] with @xmath165 = \\left [ y_l\\prime^{(\\tau-1)}[{{\\boldsymbol k } } ] \\right]_{l=0}^{l-1}$ ] and @xmath166    & = \\left ( \\xi^{l , c_{34}}_l \\ast \\left [ y_l^{(\\tau-2 ) } - \\frac { \\lambda_{4l}^{(\\tau-2 ) } } { \\beta_4 } \\right ] \\right ) [ { { \\boldsymbol k } } ]   + \\frac { \\lambda_{4l}^{(\\tau-2)}[{{\\boldsymbol k } } ] } { \\beta_4 }               \\notag                 \\\\ &   + \\left ( \\theta^{l , c_{34}}_l \\ast \\left [   \\text{shrink } \\left ( \\sum_{l'=0}^{l-1 } \\check{\\tilde \\theta}^l_{l ' } \\ast t_{l'}^{(\\tau-2 ) } - \\frac{\\lambda_3^{(\\tau-2)}}{\\beta_3 } \\,,~ \\frac{1}{\\beta_3 } \\right ) + \\frac { \\lambda_3^{(\\tau-2 ) } } { \\beta_3 }           - \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\check{\\tilde \\theta}^l_{l ' } \\ast",
    "t_{l'}^{(\\tau-2 ) } \\right ]     \\right ) [ { { \\boldsymbol k } } ]                                                                \\notag                                                       \\\\ &    + \\frac{\\lambda_1^{(\\tau-2)}[{{\\boldsymbol k } } ] + \\beta_1}{\\beta_4 }      { \\mathop{\\rm shrink}}\\left ( \\partial_l^+ u^{(\\tau-2 ) } - \\frac { \\lambda_{2 l}^{(\\tau-2 ) } } { \\beta_2 }                     + \\frac { \\lambda_1^{(\\tau-2 ) } + \\beta_1 } { \\beta_2 } y_l^{(\\tau-2 ) }                    \\ , , \\frac { \\lambda_1^{(\\tau-2 ) } + \\beta_1}{\\beta_2 } \\right ) [ { { \\boldsymbol k } } ] .",
    "\\end{aligned}\\ ] ] note that due to the high order pde behind directional mean curvature , @xmath167 in ( [ eq : vcpyramid : problem : u : spatial:1 ] ) is updated from @xmath168 and @xmath169 at every iteration @xmath104 and a thresholding value adaptively depends on lagrange multiplier @xmath170 and @xmath171 .    *",
    "definition of frames in ( [ eq : vcpyramid : problem : u : spatial:1 ] ) at direction @xmath172 . * to simply the notation , we use a parameter @xmath173 instead of @xmath174 to define frames as @xmath175    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\phi^{l , c}({{\\boldsymbol z } } ) = \\frac{1}{\\displaystyle \\abs{h({{\\boldsymbol z}})}^2 + c \\sum_{l'=0}^{l-1 } \\abs { \\cos\\left(\\frac{\\pi l'}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right)(z_1 - 1 ) } ^2 } \\ , ,   \\\\   \\label{eq : vcpyramid : problem : frameelements : u : dualwavelet:1 }   \\check{\\tilde \\psi}^{l , c}_l[{{\\boldsymbol k } } ] = - c \\partial_l^- \\phi^{l , c}[{{\\boldsymbol k } } ]   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\tilde{\\psi}^{l , c}_l({{\\boldsymbol z}}^{-1 } )    = \\frac{\\displaystyle c \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1^{-1 } - 1 ) \\right ] }           { \\displaystyle c \\sum_{l'=0}^{l-1 } \\abs { \\cos\\left(\\frac{\\pi l'}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right)(z_1 - 1 ) } ^2 + \\abs{h({{\\boldsymbol z}})}^2 } \\ , ,   \\\\   \\label{eq : vcpyramid : problem : frameelements : u : wavelet:1 }   \\psi^l_l[{{\\boldsymbol k } } ] = \\partial_l^+ \\delta[{{\\boldsymbol k } } ]   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\psi^l_l({{\\boldsymbol z } } ) = \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1 - 1 ) \\,\\end{aligned}\\ ] ] where @xmath176 $ ] denotes the dirac delta function evaluated at position @xmath177 . note that given the spectrum of an impulse response for a blur operator @xmath178 with @xmath179 ( usually @xmath180 ) due to its lowpass - like kernel ) , these bounded frames satisfy the unity condition : @xmath181    * definition of frames in ( [ eq : vcpyramid : problem : y:1 ] ) at direction @xmath172 .",
    "* we also simplify the notation by using @xmath182 instead of @xmath183 , so @xmath184 = \\big [ 1 - c \\partial_l^- \\partial_l^+ \\big]^{-1 } \\delta[{{\\boldsymbol k } } ]   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\xi^{l , c}_l({{\\boldsymbol z } } ) = \\frac { 1 } { 1 + c \\abs { \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) } ^2 }     \\ , ,   \\\\",
    "\\label{eq : filterbanks : xithetatheta_tilde:2:1 }   \\theta^{l , c}_l[{{\\boldsymbol k } } ] = -c \\partial_l^+ \\xi^{l , c}_l[{{\\boldsymbol k } } ]   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~      \\theta^{l , c}_l({{\\boldsymbol z } } ) =    \\frac { -c \\big [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) \\big ] }          { 1 + c \\abs { \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) } ^2 } \\ , ,   \\\\   \\label{eq : filterbanks : xithetatheta_tilde:3:1 }   \\check{\\tilde \\theta}^l_l[{{\\boldsymbol k } } ] = \\partial_l^- \\delta[{{\\boldsymbol k } } ]   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     \\tilde \\theta^l_l({{\\boldsymbol z}}^{-1 } ) = - \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1 } - 1 ) \\right ] \\,.\\end{aligned}\\ ] ] due to the splitting method for minimization in ( [ eq : minimization : sdmcdd:2 ] ) , there is no effect from a blur operator @xmath178 on these frames .",
    "moreover , it is easy to see that these frames are bounded above from zero for @xmath19 ^ 2 $ ] and also satisfy the unity condition in the fourier domain as @xmath185    figures [ fig : mdcd_let : filterbanks : c0_1 ] and [ fig : mdcd_let : filterbanks : c10 ] depict the spectrum of these filter banks with @xmath186 and @xmath187 , respectively .",
    "figure [ fig : mdcd_let : filterbanks:3d ] illustrates a 3-dimensional version of @xmath188 and @xmath188 without the blurring effect ; i.e. , @xmath189 .",
    "now consider the multiscale sampling version of the @xmath1-problem ( see proposition [ prop : dmcddmultiscalesamplingtheory : u - problem ] ) .",
    "since a solution of the @xmath1-problem can be described in a form of the sampling theory in harmonic analysis , we generalize this form to its ( continuous and discrete ) multi - scale version ( with some simplified notation as in the proof of proposition [ prop : dmcddmultiscalesamplingtheory : u - problem ] in appendix a ) .    for the discrete case , given a function @xmath190 , a constant @xmath191 and @xmath88 , the discrete multiscale sampling theory at scale @xmath192 and direction @xmath193 is @xmath194 = ( f \\ast \\phi){[{{\\boldsymbol k } } ] }   + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } ( f \\ast \\check { \\tilde{\\psi } } _ { il } \\ast \\psi_{il } ) { [ { { \\boldsymbol k } } ] }   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~              f({{\\boldsymbol z } } ) = f({{\\boldsymbol z } } ) \\phi({{\\boldsymbol z } } )   + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } f({{\\boldsymbol z } } ) \\tilde \\psi_{il}({{\\boldsymbol z}}^{-1 } ) \\psi_{il}({{\\boldsymbol z } } ) \\,.\\end{aligned}\\ ] ] their frames are defined in the fourier domain ( see figure [ fig : mdcd_let : u - g - problems](b ) for their spectra ) as @xmath195    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\phi({{\\boldsymbol z } } ) = i^{-1 } \\sum_{i=0}^{i-1 } \\phi_\\text{int}({{\\boldsymbol z}}^{a^i } ) \\ , ,   \\\\",
    "\\psi_{il}[{{\\boldsymbol k } } ]    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\psi_{il}({{\\boldsymbol z } } ) = i^{-\\frac{1}{2 } } \\psi_l({{\\boldsymbol z}}^{a^i } ) \\ , ,   \\\\",
    "\\check{\\tilde \\psi}_{il}[{{\\boldsymbol k } } ]    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\tilde \\psi_{il}({{\\boldsymbol z}}^{-1 } ) = i^{-\\frac{1}{2 } } \\tilde \\psi_l({{\\boldsymbol z}}^{-a^i } ) \\,,\\end{aligned}\\ ] ] with the discrete version of the interpolant @xmath196 and the directional mother dual / primal wavelet @xmath197 ( with @xmath23 ) as @xmath198 & = \\left [ c ( -\\delta_{\\text{d}l } ) + 1 \\right]^{-1 } \\delta[{{\\boldsymbol k } } ]   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\phi_\\text{int}({{\\boldsymbol z } } ) = \\frac{1}{\\displaystyle 1 + c \\sum_{l'=0}^{l-1 } \\abs { \\sin\\left(\\frac{\\pi l'}{l}\\right)(z_1 - 1 ) + \\cos\\left(\\frac{\\pi l'}{l}\\right)(z_2 - 1 ) } ^2 } \\ , ,   \\\\",
    "\\check{\\tilde \\psi}_l[{{\\boldsymbol k } } ] & = \\underbrace { - c \\left [ c ( -\\delta_{\\text{d}l } ) + 1 \\right]^{-1 } \\partial_l^- \\delta[{{\\boldsymbol k } } ] }                                   _ { \\displaystyle = -c \\partial_l^- \\phi_\\text{int}[{{\\boldsymbol k } } ] }   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\tilde \\psi_l({{\\boldsymbol z}}^{-1 } ) = \\frac{\\displaystyle c \\left [ \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1 } - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) \\right ] }                             { \\displaystyle 1 + c \\sum_{l'=0}^{l-1 } \\abs { \\sin\\left(\\frac{\\pi l'}{l}\\right)(z_1 - 1 ) + \\cos\\left(\\frac{\\pi l'}{l}\\right)(z_2 - 1 ) } ^2 } \\ , ,   \\\\",
    "\\psi_l[{{\\boldsymbol k } } ] & = \\partial^+_l \\delta[{{\\boldsymbol k } } ]    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\psi_l({{\\boldsymbol z } } ) = \\sin\\left(\\frac{\\pi",
    "l}{l}\\right ) ( z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) \\,.\\end{aligned}\\ ] ] note that these discrete frames are bounded and also satisfy the unity condition , since @xmath199    for the continuous case , given a constant @xmath191 , @xmath88 and @xmath200 whose discrete fourier transform is @xmath201 or @xmath202 , the multiscale sampling theory at scale @xmath192 and direction @xmath193 is @xmath203 & = ( f \\ast \\phi)[{{\\boldsymbol k } } ] + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } ( f \\ast \\check { \\tilde{\\psi } } _ { il } \\ast \\psi_{il } ) [ { { \\boldsymbol k } } ]     ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    f(e^{j{{\\boldsymbol \\omega } } } ) = f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat \\phi({{\\boldsymbol \\omega } } ) + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat{\\tilde{\\psi}^*_{il}}({{\\boldsymbol \\omega } } ) \\widehat{\\psi_{il } } ( { { \\boldsymbol \\omega } } ) \\ ,   \\end{aligned}\\ ] ] and their frames are defined in the fourier domain with @xmath36 ( see figure [ fig : mdcd_let : u - g - problems](a ) for their spectra ) as @xmath204 with the interpolant @xmath196 in the continuous setting and , for @xmath23 , the directional dual / primal wavelet @xmath197 and @xmath205 , so @xmath206^{-1 } \\delta({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\phi_\\text{int}}({{\\boldsymbol \\omega } } ) = \\frac{1}{\\displaystyle 1 + c \\sum_{l'=0}^{l-1 } \\left [ \\cos(\\frac{\\pi l'}{l } ) \\omega_2 + \\sin(\\frac{\\pi l'}{l } ) \\omega_1 \\right]^2 } \\ , ,    \\\\    \\check{\\tilde \\psi}_l({{\\boldsymbol x } } ) = -c \\partial_l \\phi_\\text{int}({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\tilde \\psi^*_l}({{\\boldsymbol \\omega } } ) = \\frac{\\displaystyle -c \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) j \\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) j \\omega_1 \\right ] }                              { \\displaystyle 1 + c \\sum_{l'=0}^{l-1 } \\left [ \\cos\\left(\\frac{\\pi l'}{l}\\right ) \\omega_2 + \\sin\\left(\\frac{\\pi l'}{l}\\right ) \\omega_1 \\right]^2 } \\ , ,    \\\\    \\psi_l({{\\boldsymbol x } } ) = \\partial_l \\delta({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\psi_l}({{\\boldsymbol \\omega } } ) = \\cos\\left(\\frac{\\pi l}{l}\\right ) j\\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) j\\omega_1 \\ , .   \\end{aligned}\\ ] ] similar to its discrete version , these bounded frames in a continuous setting also satisfy the unity condition as @xmath207 also note that , unlike the continuous filter banks in figure [ fig : mdcd_let : u - g - problems](a ) , there are aliasing effects in the discrete version in figure [ fig : mdcd_let : u - g - problems](b ) because of the exponential operator in the complex domain ; i.e. , @xmath208 .      the solution of the @xmath2-problem ( [ eq : problem : v ] )",
    "is rewritten in a sampling theory form with two shrinkage operators ( due to @xmath209 and @xmath210 in the dmcd model ( [ eq : minimization : sdmcdd:2 ] ) ) , the lagrange multipliers @xmath211 and the blur kernel @xmath5 as @xmath212 with @xmath213 \\right]_{{{\\boldsymbol k}}\\in \\omega}$ ] and @xmath214 & = \\frac { \\beta_5 } { \\beta_5 + \\alpha^{(\\tau ) } \\beta_7 }   \\left ( \\left ( \\delta - \\alpha^{(\\tau ) } \\check{h } \\ast h \\right ) \\ast v^{(\\tau-1 ) }     + \\alpha^{(\\tau ) } \\check{h } \\ast \\left ( f - h \\ast u^{(\\tau ) } - h \\ast \\rho^{(\\tau-1 ) } - \\epsilon^{(\\tau-1 ) } + \\frac{\\lambda_{5}^{(\\tau-1)}}{\\beta_5 } \\right ) \\right ) [ { { \\boldsymbol k } } ]   \\\\   & + \\frac { \\beta_7 \\alpha^{(\\tau ) } } { \\beta_5 + \\alpha^{(\\tau ) } \\beta_7 }   \\left ( \\sum_{s=0}^{s-1 } \\check{\\tilde \\theta}^{s}_s \\ast g_s^{(\\tau ) } - \\frac{\\lambda_7^{(\\tau-1)}}{\\beta_7 } \\right ) [ { { \\boldsymbol k}}].\\end{aligned}\\ ] ] by choosing @xmath215 , the solution of the @xmath216-problem ( [ eq : problem : g ] ) at iteration @xmath104 is @xmath217 & = \\left ( \\xi^{s , c_{67}}_s \\ast \\left [ { \\mathop{\\rm shrink}}\\left ( g_s^{(\\tau-1 ) } - \\frac{\\lambda_{6 s}^{(\\tau-1)}}{\\beta_6 } \\,,~ \\frac{\\mu_1}{\\beta_6 } \\right ) + \\frac{\\lambda_{6 s}^{(\\tau-1)}}{\\beta_6 } \\right ] \\right ) [ { { \\boldsymbol k } } ]   + \\left ( \\theta^{s , c_{67}}_s \\ast \\left [ \\check{\\tilde \\theta}^{s}_s \\ast g_s^{(\\tau-1 ) } + \\frac{\\lambda_7^{(\\tau-1)}}{\\beta_7 } \\right ] \\right ) [ { { \\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] note that the sampling theory form for ( [ eq : filterbanks : problem : g : spatial:1 ] ) is more obvious if we simplify the equation by removing the shrinkage operator and the lagrange multipliers , so @xmath218 & = \\left ( \\xi^{s , c_{67}}_s \\ast g_s^{(\\tau-1 ) } \\right ) [ { { \\boldsymbol k } } ]   + \\big ( \\theta^{s , c_{67}}_s",
    "\\ast \\check{\\tilde \\theta}^{s}_s \\ast g_s^{(\\tau-1 ) } \\big)[{{\\boldsymbol k } } ] \\ , .          \\end{aligned}\\ ] ] frames @xmath219 and @xmath220 are well defined in ( [ eq : filterbanks : xithetatheta_tilde:1:1])-([eq : filterbanks : xithetatheta_tilde : unitycondition:1 ] ) , see proposition [ prop : vcpyramid : problem : v : spatial:1 ] in appendix a.    the multiscale sampling version of the @xmath136-problem is similar to the @xmath1-problem ; see proposition [ prop : dmcddmultiscalesamplingtheory : g - problem ] in appendix a. given a discrete function ( data ) @xmath62 , constant @xmath221 and @xmath88 , the discrete multiscale sampling theory at scale @xmath192 and direction @xmath193 is @xmath222 = ( f \\ast \\xi)[{{\\boldsymbol k } } ]   + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } ( f \\ast \\check{\\tilde \\theta}_{si } \\ast \\theta_{si } ) [ { { \\boldsymbol k } } ]   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   f({{\\boldsymbol z } } ) =    f({{\\boldsymbol z } } ) \\xi({{\\boldsymbol z } } ) +     \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } f({{\\boldsymbol z } } ) \\tilde\\theta_{si}({{\\boldsymbol z}}^{-1 } ) \\theta_{si}({{\\boldsymbol z}})\\end{aligned}\\ ] ] and their frames are defined in the fourier domain as @xmath223 \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }   \\xi({{\\boldsymbol z } } ) = \\frac{1}{si } \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } \\xi_s({{\\boldsymbol z}}^{a^i } ) \\,,~   \\theta_{si}[{{\\boldsymbol k } } ] \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }    \\theta_{si}({{\\boldsymbol z } } ) = \\frac{1}{\\sqrt{si } } \\theta_s({{\\boldsymbol z}}^{a^i } )     \\text { and }   \\tilde\\theta_{si}[{{\\boldsymbol k } } ] \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }   \\tilde\\theta_{si}({{\\boldsymbol z } } ) = \\frac{1}{\\sqrt{si } } \\tilde\\theta_s({{\\boldsymbol z}}^{a^i } ) \\,\\end{aligned}\\ ] ] ( see figure [ fig : mdcd_let : u - g - problems](d ) for their spectra ) .",
    "the @xmath224 and @xmath225 are defined in ( [ eq : filterbanks : xithetatheta_tilde:1:1])-([eq : filterbanks : xithetatheta_tilde:3:1 ] ) .",
    "these multiscale frames also satisfy the unity condition in the fourier domain as @xmath226 given a constant @xmath227 and a discrete function @xmath11 \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow } f(e^{j{{\\boldsymbol \\omega}}})$ ] , the continuous multiscale sampling theory form at scale @xmath192 and direction @xmath193 is @xmath228 = ( f \\ast \\xi)[{{\\boldsymbol k } } ] + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } ( f \\ast \\check{\\tilde \\theta}_{si } \\ast \\theta_{si})[{{\\boldsymbol k } } ]    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   f(e^{j{{\\boldsymbol \\omega } } } ) = f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat \\xi({{\\boldsymbol \\omega } } ) + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat{\\tilde \\theta_{si}^ * } ( { { \\boldsymbol \\omega } } ) \\widehat{\\theta_{si } } ( { { \\boldsymbol \\omega } } ) \\end{aligned}\\ ] ] with @xmath229 and frames @xmath230^{-1 } \\delta({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     \\widehat{\\xi_s}({{\\boldsymbol \\omega } } ) = \\frac { 1 } { 1 + c \\left [ \\cos \\left ( \\frac{\\pi s}{s } \\right ) \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) \\omega_1 \\right]^2 }   \\ , ,   \\\\   \\theta_s({{\\boldsymbol x } } ) = -c \\partial_s \\xi_s({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     \\widehat{\\theta_s}({{\\boldsymbol \\omega } } ) =    \\frac { -c \\big [ \\cos(\\frac{\\pi s}{s } ) j \\omega_2 + \\sin(\\frac{\\pi s}{s } ) j \\omega_1 \\big ] }          { 1 + c \\left [ \\cos \\left ( \\frac{\\pi s}{s } \\right ) \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) \\omega_1 \\right]^2 } \\ , ,   \\\\",
    "\\check{\\tilde \\theta}_s({{\\boldsymbol x } } ) = \\partial_s \\delta({{\\boldsymbol x } } )   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\widehat{\\tilde \\theta_s^*}({{\\boldsymbol \\omega } } ) = \\cos \\left ( \\frac{\\pi s}{s } \\right ) j \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) j \\omega_1 \\,\\end{aligned}\\ ] ] ( see figure [ fig : mdcd_let : u - g - problems](d ) for their spectra ) .",
    "these bounded frames satisfy the unity condition in the fourier domain since @xmath231    figure [ fig : mdcd_let : u - g - problems](c , d ) illustrates these multiscale filter banks for continuous and discrete settings .",
    "multi - scale and multi - direction analysis in the curvelet domain is especially useful for demixing the noise and residuals .",
    "we minimize ( [ eq : minimization : sdmcdd:2 ] ) in terms of the supremum norms of the curvlet coefficients corresponding to the indicator functions for the residual structure and noise terms , @xmath232 and @xmath233 , respectively .",
    "there are two terms in every solution of the @xmath3-problem ( [ eq : problem : rho ] ) or the @xmath4-problems ( [ eq : problem : epsilon ] ) , namely an updated remainder and its curvelet smoothing term @xmath234 $ ] determined by the soft - thresholding operator .",
    "we describe the case of the @xmath4-problem , but the explanation is the same for the @xmath3-problem . a solution of ( [ eq : problem : epsilon ] ) at iteration @xmath104 is @xmath235 \\end{aligned}\\ ] ] where @xmath236 , the remainder at iteration @xmath104 , can be approximated as @xmath237 in ( [ eq : epsilonproblem : filterbanks ] ) , we call @xmath238 the updated term and @xmath239 $ ] the smoothing term found by curvelet soft - thresholding @xmath234 $ ] ( up to a level @xmath240 ) . if , at iteration @xmath104 , the updated term @xmath236 still contains both signal and noise , then the noise in @xmath236 is removed by the @xmath241-operator . finally , by subtraction , @xmath242 contains almost pure noise ( up to a degree @xmath240 ) .",
    "this `` smoothing and subtraction '' procedure results from the constraint @xmath243 , which takes advantage of the sparsity assumption in the curvelet transform ; i.e. , the multi - scale and multi - directional partition of the fourier domain .",
    "to quantify the improvement obtained by the proposed algorithm , we perform our demixing algorithm upon two images : the `` barbara '' image figure [ fig : deblurdecomp : barbara : nonoise](a ) , and a fingerprint image used in the samsi program on forensic statistics .",
    "we use barbara image because it contains many key apects of image analysis , i.e. , homogeneous areas and texture at different scales ( on the scarf , trouser and tablecloth ) .",
    "we compare our proposed algorithm to the tv-@xmath8 deblurring algorithm @xcite and to the blind deblurring by the matlab function deconvblind.m .",
    "the criterion for comparing peformance is the mean squared error ( mse ) in the pixel - wise difference between the true image @xmath244 and a combination of the signal components obtained from the demixing algorithms @xmath245 : @xmath246 in order to evaluate the performance of the algorithms , besides simple visual comparison and the calculation of the mean square error , we also use the eigenvalues of the estimated covariance matrix under the assumption that any structure which persists after demixing appears in the reconstruction error and the eigenvalues of the estimated covariance matrix enable one to determine which algorithm successfully extracted more signal . in the same vein , we denote @xmath247 as a vectorized sample of @xmath248 non - overlapping blocks of the error ( @xmath249 ) , i.e. @xmath250 .",
    "the maximum eigenvalue of the estimated covariance matrix ( mec ) for sample @xmath247 is defined as @xmath251}\\end{aligned}\\ ] ] with sample mean and sample covariance , respectively , as @xmath252 figure [ fig : deblurdecomp : barbara : nonoise ] illustrates the result of the proposed demixing dmcd model on the barbara image . a blurred image @xmath0 ( b ) ( a convolution of original image @xmath244 ( a ) and a known smoothing kernel @xmath89 \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow } h({{\\boldsymbol z}})$ ] in ( c ) ) is simultaneously reconstructed and decomposed into the piecewise smooth image @xmath1 ( d ) , the sparse texture @xmath2 ( e ) and its binarized version ( j ) and the residual structure @xmath3 ( f ) .",
    "the convergence of the algorithm is measured by the relative error of texture @xmath2 in log scale ( k ) .",
    "it shows that the proposed dmcd model can reconstruct a blurred image and simultaneously decompose it into different components , including sparse texture @xmath2 and piecewise smooth @xmath1 with sharp edges , while preserving contrast .",
    "so , the reconstructed image with @xmath245 in figure [ fig : deblurdecomp : barbara : nonoise](h ) can preserve contrast and texture with small mean squared error in comparison with the original image figure [ fig : deblurdecomp : barbara : nonoise](a ) .",
    "figure [ fig : barbara : compare:2-multidir ] illustrates the benefit of directional mean curvature ( dmc ) over mean curvature ( mc ) @xmath253 . although a reconstructed image ( a ) with mean curvature @xmath253 is good , texture still remains in the piecewise smooth component @xmath1 ( b ) , see figure [ fig : deblurdecomp : barbara : nonoise](d - g ) for a comparison with dmc @xmath254 .",
    "this artifact is due to the large bandwidth of a lowpass @xmath255 which covers texture information , see ( m ) . for the homogeneous areas ,",
    "a comparison of a reconstructed image between @xmath256 and @xmath257 directions is depicted in ( e - l ) .",
    "we see that the reconstructed components @xmath1 by dmc ( h , l ) are smoother in approximating the function @xmath0 ( f , j ) , and mc produces the `` stair - case '' effect , see ( u , k ) . an explanation for this benefit of dmc is that increasing @xmath193 makes the bandwidth of the lowpass @xmath255 smaller ( see ( m ) and ( o ) for @xmath258 and @xmath259 , respectively ) while small wavelet coefficients are eliminated in different directions , see equation ( [ eq : vcpyramid : problem : u : spatial:1 ] ) .",
    "this effect makes a cartoon @xmath1 smoother and removes oscillating patterns , such as texture and noise .",
    "the highpass @xmath260 are depicted in ( n ) and ( p ) for @xmath258 and @xmath259 , respectively .",
    "the stair case effect is due to the assumption of sparse signal under the gradient operator , and the directional version of the total variation norm @xcite is known to handle this limitation .",
    "the proposed directional mean curvature norm benefits from the advantages of both the high - order pde approach and the ability of directional methods to enhance sparse signal while preserve sharp edges in the restored image .    figure [ fig : deblurdecomp : barbara : compare ] compares our demixing method to tv-@xmath8 deblurring and the blind deblurring by the matlab function deconvblind.m .",
    "we see that tv-@xmath8 ( c , f ) can recover very sharp edges , but it also eliminates texture .",
    "the blind deblurring can recover texture , but it also produces `` ringing '' effects ( i.e. , the larger a kernel size is , the more artifacts there are in the reconstructed image ) , see ( b , e ) .",
    "we observed that a kernel of size 7 is the best choice in terms of minimizing ringing .",
    "the matlab function can directly estimate an unknown blur kernel , which our method does not , but it can not decompose an image into different components while deblurring , and its performance on deblurring still has problematic ringing .",
    "besides the barbara image , we also demix a fingerprint image which contains small scale objects ( noise ) together with fingerprint patterns ( texture ) , see figure [ fig : deblurdecomp : fingerprint : nonoise ] .",
    "dmc removes the texture component in the piecewise smooth component @xmath1 ( d ) while preserving sharp edges , and the texture component @xmath2 ( e , j ) is sparse .",
    "also , small scale structure is separated in @xmath3 .",
    "finally , the reconstructed by dmcd ( h ) achieves good performance in terms of mean squared error and visualization .",
    "figure [ fig : deblurdecomp : fingerprint : noise ] illustrates the performance of our method when signal is corrupted by noise .",
    "we add an i.i.d .",
    "gaussian noise @xmath261 with @xmath262 to a blurred signal ( b ) . by choosing a threshold @xmath263 ,",
    "the noise component can be separated by the dmcd model ",
    "see its qq - plot ( d ) . and",
    "a reconstructed image ( i ) still preserves texture .",
    "note that mathematically selecting an optimal threshold for this gaussian noise is beyond this paper .",
    "we use the qq - plot to evaluate this threshold instead . the dmcd model for other textured images",
    "are depicted in figure [ fig : deblurdecomp : ballistic]-[fig : deblurdecomp : tiger ] in appendix b.    figure [ fig : mdcd_let : fingerprint : u - g - problems ] illustrates a multiscale decomposition of the fingerprint image by filter banks in an harmonic analysis obtained from the @xmath1-problem and the @xmath136-problem ( or the @xmath2-problem ) in subsection [ subsection : uproblem : multiscale ] and [ subsection : vproblem : multiscale ] , respectively .",
    "the corresponding filter banks of figure [ fig : mdcd_let : fingerprint : u - g - problems ] are depicted in figure [ fig : mdcd_let : u - g - problems ] .",
    "we provide the dmcd method to demix a blurred image @xmath0 ( with a known blurred kernel @xmath5 ) into four meaningful components : piecewise smooth @xmath1 , texture @xmath2 , fine scale residual structure @xmath3 , and noise @xmath4 , so @xmath264 .",
    "a cornerstone of the dmcd analysis is the assumption that signal is sparse under some transformed domains .",
    "using novel norms as key ingredients , we address some transformed domains to enforce on these components :    * the directional mean curvature ( dmc ) norm eliminates texture from a piecewise smooth @xmath1 while keeping edges and preserving its contrast . this property is due to the multi - directional and high - order approach which enhances sparsity of the objects under dmc . *",
    "the directional @xmath10-norm is applied to capture texture @xmath2 and the @xmath9-norm @xmath209 obtains sparse coefficients which are mainly due to repeated pattern . * the fine scale residual structure @xmath3 and noise @xmath4",
    "are measured in the @xmath71-norm of curvelet coefficients @xmath50 .",
    "since this @xmath71-norm takes the advantage of the multi - scale and multi - directional curvelet transform , oscillating components can be independent ( e.g. , white noise @xmath4 ) or weakly correlated ( fine scale residual structure @xmath3 ) .",
    "we also apply our dmcd model to real images to find superior results compared to other state - of - the - art methods , as measured by mean squared error and the maximum eigenvalue of the estimated covariance matrix .",
    "moreover , dmcd simultaneously solves the decomposition and deblurring problems .",
    "finally , we uncover a link between functional analysis and multiscale sampling theory , e.g. , between harmonic analysis and filter banks .",
    "due to high - order pde problem , following @xcite , an augmented lagrangian method is applied to split dmc into several @xmath9- and @xmath8-norms .",
    "the advantage of this splitting method is to approximate complicated norms , but it also introduces new parameters which are chosen beforehand to speed of the convergence of the algorithm .",
    "this material was based upon work partially supported by the national science foundation under grant dms-1127914 to the statistical and applied mathematical sciences institute and department of statistical science at duke university .",
    "any opinions , findings , and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation .    10    d.  mumford and j.  shah .",
    "optimal approximations by piecewise smooth functions and associated variational problems . , 42(5):577685 , july 1989 .",
    "potts . some generalized order - disorder transformations .",
    ", 48:106109 , 1952 .",
    "l.  rudin , s.  osher , and e.  fatemi .",
    "nonlinear total variation based noise removal algorithms .",
    ", 60(1 - 4):259268 , november 1992 .",
    "g.  aubert and l.  vese .",
    "a variational method in image recovery .",
    ", 34(5):19481979 , october 1997 .",
    "t.  chan , a.  marquina , and p.  mulet .",
    "high - order total variation - based image restoration .",
    ", 22(2):503516 , july 2000 .",
    "w.zhu and t.  chan .",
    "image denoising using mean curvature of image surface . , 5(1):132 , january 2012 .",
    "k.  papafitsoros and c.b .",
    "a combined first and second order variational approach for image reconstruction .",
    ", 48(2):308338 , february 2014 .",
    "t.  goldstein and s.  osher .",
    "the split bregman method for @xmath265-regularized problems .",
    ", 2(2):323343 , april 2009 .",
    "e.  cands and d.  donoho .",
    "new tight frames of curvelets and optimal representations of objects with piecewise singularities . , 57(2):219266 , february 2004 .",
    "e.  cands , l.  demanet , d.  donoho , and l.  ying .",
    "fast discrete curvelet transforms . , 5(3):861899 ,",
    "september 2006 .",
    "starck , d.l .",
    "donoho , and e.j .",
    "cands . astronomical image representation by the curvelet transform . ,",
    "398(2):785800 , february 2003 .",
    "j.  ma and g.  plonka .",
    "the curvelet transform .",
    ", 27(2):118133 , march 2010 .",
    "g.  kutyniok and d.  labate , editors . .",
    "birkhuser , boston , ma , usa , 2012 .",
    "do and m.  vetterli .",
    "the contourlet transform : an efficient directional multiresolution image representation .",
    ", 14(12):20912106 , december 2005 .",
    "m.  unser and d.  van  de ville .",
    "wavelet steerability and the higher - order riesz transform .",
    ", 19(3):636652 , march 2010 .",
    "j.  gilles , g.  tran , and s.  osher .",
    "2d empirical transforms .",
    "wavelets , ridgelets , and curvelet revisited . , 7(1):157186 , january 2014 .",
    "chan and l.a .",
    "active contours without edges . , 10(2):266277 , february 2001 .",
    "x.  bresson , s.  esedoglu , p.  vandergheynst , j.p .",
    "thiran , and s.  osher .",
    "fast global minimization of the active contour / snake model . , 28(2):151167 , june 2007 .",
    "chan , s.  esedoglu , and m.  nikolova .",
    "algorithms for finding global minimizers of image segmentation and denoising models .",
    ", 66(5):16321648 , february 2012 .",
    "j.  lie , m.  lysaker , and x.c .",
    "tai . a binary level set model and some applications to mumford - shah image segmentation .",
    ", 15(5):11711181 , may 2006 .",
    "m.  kass , a.  witkin , and d.  terzopoulos .",
    "snakes : active contour models .",
    ", 1(4):321331 , january 1988 .",
    "w.  zhu , x.c .",
    "tai , and t.  chan .",
    "image segmentation using euler s elastica as the regularization .",
    ", 57(2):414438 , april 2013 .",
    "brown , t.f .",
    "chan , and x.  bresson . a convex relaxation method for a class of vector - valued minimization problems with applications to mumford - shah segmentation . , 2010 .",
    "brown , t.f .",
    "chan , and x.  bresson .",
    "completely convex formulation of the chan - vese image segmentation model .",
    ", 98(1):103121 , may 2012 .",
    "l.l .  wang y.  gu and x.c .",
    "tai . a direct approach toward global minimization for multiphase labeling and segmentation problems .",
    ", 21(5):23992411 , may 2012 .",
    "brown , t.f .",
    "chan , and x.  bresson .",
    "convex formulation and exact global solutions for multi - phase piecewise constant mumford - shah image segmentation . , 2009 .",
    "chan , b.y .",
    "sandberg , and l.a .",
    "active contours without edges for vector - valued images . , 11(2):130141 , june 2000 .",
    "d.  maltoni , d.  maio , a.  k. jain , and s.  prabhakar . .",
    "springer , london , u.k . , 2009 .",
    "thai and c.  gottschlich .",
    "directional global three - part image decomposition .",
    ", 2016(12):120 , march 2016 .",
    "s.  ling and t.  strohmer .",
    "blind deconvolution meets blind demixing : algorithms and performance bounds . , ( submitted ) .",
    "m.  lysaker , a.  lundervold , and x.c .",
    "noise removal using fourth - order partial differential equation with applications to medical magnetic resonance images in space and time .",
    ", 12(12):15791590 , december 2003 .",
    "t.  rahman , x.c .",
    "tai , and s.  osher . a tv - stokes denoising algorithm .",
    ", 4485:473483 , june 2007 .",
    "j.  hahn , c.  wu , and x.c .",
    "augmented lagrangian method for generalized tv - stokes model .",
    "50(2):235264 , february 2012 .    x.c .",
    "tai , j.  hahn , and g.j .",
    "a fast algorithm for euler s elastica model using augmented lagrangian method .",
    ", 4(1):313344 , february 2011 .",
    "l.  calatroni , b.  dring , and c.b .",
    "adi splitting schemes for a fourth - order nonlinear partial differential equation from image processing . , 34(3):931957 , march 2014 .",
    "i.  daubechies , m.  defrise , and c.  d. mol . an iterative thresholding algorithm for linear inverse problems with a sparsity constraint .",
    ", 57(11):14131457 , august 2004 .",
    "a.  beck and m.  teboulle .",
    "a fast iterative shrinkage - thresholding algorithm for linear inverse problems .",
    ", 2(1):183202 , january 2009 .",
    "dias and m.  figueiredo . a new twist : two - step iterative shrinkage / thresholding algorithms for image restoration . , 16(12):29923004 , december 2007 .    c.  wu and x.  c. tai .",
    "augmented lagrangian method , dual methods , and split bregman iteration for rof , vectorial tv , and higher order methods . , 3(3):300339 , july 2010 .",
    "a.  chambolle .",
    "an algorithm for total variation minimization and applications .",
    ", 20(1 - 2):8997 , january 2004 .",
    "s.  setzer .",
    "operator splittings , bregman methods and frame shrinkage in image processing . , 92(3):265280 , july 2011 .",
    "thai and l.  mentch .",
    "multiphase segmentation for simultaneously homogeneous and textural images .",
    ", submitted .",
    "thai and c.  gottschlich .",
    "simultaneous inpainting and denoising by directional global three - part decomposition : connecting variational and fourier domain based image processing . , submitted .",
    "thai and c.  gottschlich .",
    "global variational method for fingerprint segmentation by three - part decomposition .",
    ", 5(2):120130 , june 2016 .",
    "y.  meyer . .",
    "american mathematical society , boston , ma , usa , 2001 .",
    "aujol and a.  chambolle .",
    "dual norms and image decomposition models . , 63(1):85104 , june 2005 .",
    "vese and s.  osher .",
    "modeling textures with total variation minimization and oscillatory patterns in image processing .",
    ", 19(1 - 3):553572 , december 2003 .",
    "e.  cands and t.  tao .",
    "the dantzig selector : statistical estimation when @xmath266 is much larger than @xmath267 .",
    ", 35(6):23132351 , december 2007 .",
    "m.  haltmeier and a.  munk .",
    "extreme value analysis of empirical frame coefficients and implications for denoising by soft - thresholding .",
    ", 36(3):434460 , may 2014 .",
    "max - stable processes and spatial extremes . , 1990 .",
    "m.  schlather .",
    "models for stationary max - stable random fields . , 5(1):3344 , august 2002 .",
    "phd thesis , university of goettingen , goettingen , germany , january 2015 .    s.  yi , d.  labate , g.r .",
    "easley , and h.  krim . a shearlet approach to edge analysis and detection .",
    ", 18(5):929941 , may 2009 .",
    "m.  unser , n.  chenouard , and d.  van  de ville .",
    "steerable pyramids and tight wavelet frames in @xmath268 . , 20(10):27052721 , october 2011 .",
    "m.  unser , d.  sage , and d.  van  de ville .",
    "multiresolution monogenic signal analysis using the riesz - laplace wavelet transform .",
    ", 18(11):24022418 , november 2009 .",
    "cunha , j.  zhou , and m.n .",
    "the nonsubsampled contourlet transform : theory , design , and applications .",
    ", 15(10):30893101 , october 2006 .",
    "selesnick , r.g .",
    "baraniuk , and n.c .",
    "the dual - tree complex wavelet transform .",
    ", 22(6):123151 , november 2005 .",
    "t.  chan , a.  marquina , and p.  mulet .",
    "high - order total variation - based image restoration . , 22(2):503516 ,",
    "july 2000 .",
    "w.  zhu , x.c .",
    "tai , and t.  chan .",
    "augmented lagrangian method for a mean curvature based image denoising model .",
    ", 7(4):14091432 , november 2013 .",
    "j.  gilles .",
    "multiscale texture separation .",
    ", 10(4):14091427 , december 2012 .",
    "garnett , p.w .",
    "jones , t.m .",
    "le , and l.a .",
    "modeling oscillatory components with the homogeneous spaces @xmath269 and @xmath270 . , 7(2):275318 , 2011 .    m.  unser .",
    "sampling - 50 years after shannon . ,",
    "88(4):569587 , april 2000 .",
    "i.  khalidov and m.  unser . from differential equations to the contruction of new wavelet - like bases . , 54(4):12561267 , april 2006 .",
    "p.  getreuer .",
    "total variation deconvolution using split bregman . , ( 2):158174 , 7 2012 .",
    "y.  wang , w.  yin , and y.  zhang .",
    "a fast algorithm for image deblurring with total variation regularization .",
    ", 2007 .",
    "i.  ekeland and r.  temam . .",
    "society for industrial and applied mathematics , philadelphia , pa , usa , 1999 .     ( a ) is convolved by an operator @xmath89 \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow } h({{\\boldsymbol z}})$ ] in ( c ) to obtain a blurred version @xmath0 ( b ) .",
    "a reconstructed image ( h ) or ( i ) is obtained by applying the dmcd model to different reconstructed components of @xmath0 , i.e. piecewise smooth image @xmath1 ( d ) , texture @xmath2 ( e , j ) with @xmath271 \\neq 0 \\ , , { { \\boldsymbol k}}\\in \\omega \\ } } { d_1 d_2 } 100 \\%",
    "= 29.59\\%$ ] and residual @xmath3 ( f ) .",
    "by choosing parameters as @xmath272 , @xmath80_{i=1}^7 = \\mu_1 = 10^{10 } \\text { and } \\alpha = 0.1 $ ] , the convergence of dmcd is illustrated by a relative error of @xmath2 in a log scale ( k ) , see figure [ fig : barbara : compare:2-multidir ] for a comparison of our directional mean curvature based approach with the original mean curvature one ( @xmath256 ) . [ fig : deblurdecomp : barbara : nonoise ] , scaledwidth=100.0% ]     this figure visualizes filter banks produced by the dmcd model ( [ eq : vcpyramid : problem : frameelements : u : scalingfunc:1])-([eq : filterbanks : xithetatheta_tilde:3:1 ] ) with parameters @xmath273 .",
    "a total wavelet function ( c ) is defined as @xmath274 .",
    ", scaledwidth=100.0% ]     this figure illustrates a comparison of directional mean curvature and original mean curvature on texture ( a - d ) and homogeneous areas ( e - l ) .",
    "visualization of the dmcd model with directions @xmath275 and the other parameters are the same as in figure [ fig : deblurdecomp : barbara : nonoise ] .",
    "although a reconstructed image @xmath276 ( a ) has a good performance , almost texture are still kept in @xmath1 .",
    "this unsatisfied effect of a decomposition is due to a bandwidth of filters in the fourier domain , see ( m - p ) . plots ( e - l ) show the advantage of the multi - directional mean curvature for a reconstructed component @xmath1 in terms of approximation and smoothness . increasing @xmath193 causes a shrinkage of bandwidth in a lowpass @xmath255 ( m ) and ( o ) ( for @xmath258 and @xmath259 , respectively ) .",
    "this effect makes a cartoon @xmath1 smoother and removes oscillating pattern , e.g. texture and noise .",
    "the highpass @xmath260 are depicted in ( n ) and ( p ) for @xmath258 and @xmath259 , respectively .",
    "the other parameters are the same as in figure [ fig : deblurdecomp : barbara : nonoise ] .",
    ", scaledwidth=100.0% ]     ( c , f ) shows our better performance in terms of mean squared error ( mse ) and the maximum eigenvalue of the estimated covariance matrix ( mec ) and visualization .",
    "reconstructed images are illustrated on the first row and their corresponding error images are on the second row .",
    "the value of all error images are added by 150 for visualization .",
    "the third row shows sample covariance matrices of @xmath248 non - overlapping blocks of the errors on the second row .",
    "we see that tv-@xmath8 can recover very sharp edges , but it also eliminates texture . the blind deblurring ( with matlab function `` deconvblind.m '' ) can recover texture , but it also produces `` ringing effects '' ( the larger a kernel size is , the more artifacts on its reconstructed image are ) .",
    "we observed that a size of kernel 7 as its recommendation is the best choice in terms of `` ringing effects '' on its reconstructed image by visualization ( although this matlab function can estimate an unknown blur kernel itself which is more advantage than us , it can not do demixing to decompose an image into different components while deblurring ) .",
    "[ fig : deblurdecomp : barbara : compare ] , scaledwidth=100.0% ]     and the other parameters are the same as in figure [ fig : deblurdecomp : barbara : nonoise ] , see figure [ fig : deblurdecomp : fingerprint : noise ] for its noisy version .",
    "[ fig : deblurdecomp : fingerprint : nonoise ] , scaledwidth=100.0% ]     ( a ) is corrupted by a blur operator ( c ) and an i.i.d .",
    "gaussian noise @xmath277 to obtain ( b ) .",
    "choose parameters @xmath278 and the other parameters are as in figure [ fig : deblurdecomp : barbara : nonoise ] , reconstructed images ( i ) and ( j ) have a good performance in terms of mse and visualization .",
    "the qqplot of @xmath4 ( d ) shows that an estimated @xmath4 approaches the gaussian assumption .",
    "the convergence of the algorithm ( l ) is computed in a log scale .",
    "[ fig : deblurdecomp : fingerprint : noise ] , scaledwidth=100.0% ]",
    "[ prop : problem : t ] the solution of the `` @xmath114-problem '' is @xmath279      \\,,~ l = 0 , \\ldots , l-1 \\ , ,     \\\\     \\displaystyle     { { \\mathbf y}}_l - \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 } \\ , .",
    "\\end{cases }   \\end{aligned}\\ ] ] with @xmath280    -\\beta_3 \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) \\right ] \\times    \\\\ & \\qquad ~    \\left [ d({{\\boldsymbol z } } ) + \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\left [ \\cos\\left(\\frac{\\pi l'}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right ) ( z_1^{-1 } - 1 ) \\right ] t_{l'}({{\\boldsymbol z } } ) + \\frac { \\lambda_3({{\\boldsymbol z } } ) } { \\beta_3 } \\right ]   \\ , .   \\end{aligned}\\ ] ]    the euler - lagrange equation is @xmath281     + \\beta_4 \\left [ \\vec{{{\\mathbf t } } } - \\vec{{{\\mathbf y } } } + \\frac { \\vec{\\boldsymbol{\\lambda}_{\\boldsymbol 4 } } } { \\beta_4 } \\right ]    \\\\    & = \\beta_3 \\nabla^+_l \\left [ { { \\mathbf d}}- \\text{div}^-_l \\vec{{{\\mathbf t } } } + \\frac { \\boldsymbol{\\lambda_3 } } { \\beta_3 } \\right ]     + \\beta_4 \\left [ \\vec{{{\\mathbf t } } } - \\vec{{{\\mathbf y } } } + \\frac { \\vec{\\boldsymbol{\\lambda}_{\\boldsymbol 4 } } } { \\beta_4 } \\right ]   \\end{aligned}\\ ] ] we have @xmath282_{l=0}^{l-1 } \\ , , \\text{div}^-_l \\vec{{{\\mathbf t } } } = \\sum_{l=0}^{l-1 } \\partial_l^- { { \\mathbf t}}_l    \\ , , \\vec{{{\\mathbf t } } } = \\left [ { { \\mathbf t}}_l \\right]_{l=0}^l \\ , , \\vec{{{\\mathbf y } } } = \\left [ \\vec{{{\\mathbf y}}}_l \\right]_{l=0}^l   \\ , , \\vec{\\boldsymbol{\\lambda_4 } } = \\left [ \\boldsymbol{\\lambda}_{\\boldsymbol 4l } \\right]_{l=0}^l   $ ] thus , @xmath283     + \\beta_4 \\left [ { { \\mathbf t}}_l - { { \\mathbf y}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4a } } { \\beta_4 } \\right ] = 0    \\,,~ l = 0 , \\ldots , l-1 .    \\\\    \\displaystyle    \\beta_4 \\left [ { { \\mathbf t}}_l - { { \\mathbf y}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 } \\right ] = 0   \\end{cases }   \\\\ \\leftrightarrow~   & \\begin{cases }    \\displaystyle    \\left [ \\beta_4 -\\beta_3 \\partial_l^+\\partial_l^- \\text{id } \\right ] { { \\mathbf",
    "t}}_l =     -\\beta_3 \\partial^+_l \\left [ { { \\mathbf d}}- \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\partial_{l'}^- { { \\mathbf t}}_{l ' } + \\frac { \\boldsymbol{\\lambda_3 } } { \\beta_3 } \\right ]     - \\beta_4 \\left [ - { { \\mathbf y}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 } \\right ]    \\,,~ l = 0 , \\ldots , l-1 .    & ( a )    \\\\    \\displaystyle    { { \\mathbf t}}_l = { { \\mathbf y}}_l - \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 }    & ( b )   \\end{cases }   \\end{aligned}\\ ] ] the fourier transform of equation ( a ) is @xmath284^{-1 }    \\left [    -\\beta_3 \\partial^+_l \\left [ { { \\mathbf d}}- \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\partial_{l'}^- { { \\mathbf t}}_{l ' } + \\frac { \\boldsymbol{\\lambda_3 } } { \\beta_3 } \\right ]     - \\beta_4 \\left [ - { { \\mathbf y}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4l } } { \\beta_4 } \\right ]    \\right ]    \\\\    \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     t_l({{\\boldsymbol z } } ) & : = \\frac { \\mathcal m_l({{\\boldsymbol z } } ) } { \\mathcal n_l({{\\boldsymbol z } } ) }    = \\left [ \\beta_4 + \\beta_3 \\abs { \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) } ^2 \\right]^{-1 } \\times    \\\\ & \\qquad \\quad    \\bigg [ - \\beta_4 \\left [ - y_l({{\\boldsymbol z } } ) + \\frac { \\lambda_{4l}({{\\boldsymbol z } } ) } { \\beta_4 } \\right ]    -\\beta_3 \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) \\right ] \\times    \\\\ & \\qquad \\quad    \\left [ d({{\\boldsymbol z } } ) + \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\left [ \\cos\\left(\\frac{\\pi l'}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right ) ( z_1^{-1 } - 1 ) \\right ] t_{l'}({{\\boldsymbol z } } ) + \\frac { \\lambda_3({{\\boldsymbol z } } ) } { \\beta_3 } \\right ]     \\bigg ] \\ , .   \\end{aligned}\\ ] ]    the solution of the `` @xmath285_{l=0}^{l-1}$]-problem '' is @xmath286    given @xmath287 and @xmath288^l_{l=0 } \\in x^{l+1}$ ] , we have @xmath289    * the proofs for this remark are * @xmath290 } _ { = \\norm { { { \\mathbf t}}_l } ^2_{\\ell_2 } } \\,,\\qquad    \\left \\langle { { \\mathbf f}}\\ , , \\sum_{l=0}^l { { \\mathbf t}}_l \\right \\rangle_{\\ell_2 }     = \\sum_{{{\\boldsymbol k}}\\in \\omega } f[{{\\boldsymbol k } } ] \\left [ \\sum_{l=0}^l { { \\mathbf t}}_l[{{\\boldsymbol k } } ] \\right ]    = \\sum_{l=0}^l \\underbrace { \\sum_{{{\\boldsymbol k}}\\in \\omega } f[{{\\boldsymbol k } } ] t_l[{{\\boldsymbol k } } ] } _ { = \\left \\langle { { \\mathbf f}}\\ , , { { \\mathbf t}}_l \\right \\rangle_{\\ell_2 } }       \\quad \\text{and }    \\\\    \\left \\langle { { \\mathbf f}}\\ , , { { \\mathbf d}}\\cdot^\\times { { \\mathbf u}}\\right \\rangle_{\\ell_2 } & = \\sum_{{{\\boldsymbol k}}\\in \\omega } f[{{\\boldsymbol k } } ] \\left ( { { \\mathbf d}}\\cdot^\\times { { \\mathbf u}}\\right)[{{\\boldsymbol k } } ]    = \\sum_{{{\\boldsymbol k}}\\in \\omega } \\bigg ( \\underbrace { f[{{\\boldsymbol k } } ] { { \\mathbf d}}[{{\\boldsymbol k } } ] } _ { = ( { { \\mathbf f}}\\cdot^\\times { { \\mathbf d}})[{{\\boldsymbol k } } ] } \\bigg ) { { \\mathbf u}}[{{\\boldsymbol k } } ] \\ , .   \\end{aligned}\\ ] ]    let @xmath291 \\in x^l$ ] , the objective function is rewritten as @xmath292     \\\\    & = \\left\\langle \\boldsymbol{\\lambda_1 } + \\beta_1 \\ , , \\abs{\\vec{{{\\mathbf r } } } } \\right\\rangle_{\\ell_2 }    + \\frac{\\beta_2}{2 } \\sum_{l=0}^l \\bigg [     \\norm { { { \\mathbf r}}_l } ^2_{\\ell_2 } + 2 \\left\\langle { { \\mathbf r}}_l \\ , , - a_l + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 2 l}}{\\beta_2 } - \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times { { \\mathbf y}}_l \\right\\rangle_{\\ell_2 }    + \\norm { - a_l + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 2 l}}{\\beta_2 } - \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times { { \\mathbf y}}_l } ^2_{\\ell_2 }    \\\\    & + \\norm { - a_l + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 2 l}}{\\beta_2 } } ^2_{\\ell_2 }    - \\norm { - a_l + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 2 l}}{\\beta_2 } - \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times { { \\mathbf y}}_l } ^2_{\\ell_2 } \\bigg ]     \\\\    & = \\left\\langle \\boldsymbol{\\lambda_1 } + \\beta_1 \\ , , \\abs{\\vec{{{\\mathbf r } } } } \\right\\rangle_{\\ell_2 }    +     \\frac{\\beta_2}{2 } \\norm { \\vec { { \\mathbf r}}- \\vec a + \\frac{\\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 2}}{\\beta_2 } - \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times \\vec { { \\mathbf y}}}^2_{\\ell_2 }     +     \\underbrace {    \\frac{\\beta_2}{2 } \\left [     \\norm { - \\vec a + \\frac{\\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 2}}{\\beta_2 } } ^2_{\\ell_2 }    - \\norm { - \\vec a + \\frac{\\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 2 l}}{\\beta_2 } -   \\frac { \\boldsymbol{\\lambda_1 } + \\beta_1 } { \\beta_2 } \\cdot^\\times \\vec{{\\mathbf y}}}^2_{\\ell_2 } \\right ]     } _ { = ~ \\text{constant } }   \\end{aligned}\\ ] ] under a minimization , a constant term can be removed and the `` @xmath110-problem '' is rewritten as @xmath293 + \\beta_1 ) \\abs{\\vec{r}[{{\\boldsymbol k } } ] }    + \\frac{\\beta_2}{2 } \\abs { \\vec{r}[{{\\boldsymbol k } } ] - \\vec{a}[{{\\boldsymbol k } } ] + \\frac { \\vec{\\lambda_2}[{{\\boldsymbol k } } ] } { \\beta_2 } - \\frac { \\lambda_1[{{\\boldsymbol k } } ] + \\beta_1 } { \\beta_2 } \\vec{y}[{{\\boldsymbol k } } ] } ^2    \\right ]    \\right\\ }   \\end{aligned}\\ ] ] due to separability , consider at @xmath294 , we have @xmath295     & = { \\mathop{\\rm argmin}}_{\\vec{r}[{{\\boldsymbol m } } ] \\in \\mathbb r^{l+1 } } \\left\\ { \\mathscr f(\\vec{r}[{{\\boldsymbol m } } ] ) =    \\abs{\\vec{r}[{{\\boldsymbol m } } ] }    + \\frac{1}{2 } \\frac{\\beta_2}{\\lambda_1[{{\\boldsymbol m } } ] + \\beta_1 } \\abs { \\vec{r}[{{\\boldsymbol m } } ] - \\vec{a}[{{\\boldsymbol m } } ] + \\frac { \\vec{\\lambda}_2[{{\\boldsymbol m } } ] } { \\beta_2 } - \\frac { \\lambda_1[{{\\boldsymbol m } } ] + \\beta_1 } { \\beta_2 } \\vec{y}[{{\\boldsymbol m } } ] } ^2    \\right\\ }    \\\\    & = { \\mathop{\\rm shrink}}\\left ( \\vec{a}[{{\\boldsymbol m } } ] - \\frac { \\vec{\\lambda}_2[{{\\boldsymbol m } } ] } { \\beta_2 } + \\frac { \\lambda_1[{{\\boldsymbol m } } ] + \\beta_1 } { \\beta_2 } \\vec{y}[{{\\boldsymbol m } } ]    \\,,~ \\frac{\\lambda_1[{{\\boldsymbol m } } ] + \\beta_1}{\\beta_2 } \\right ) \\ , .",
    "\\end{aligned}\\ ] ] we have @xmath296^l_{l=0 } \\in x^{l+1 } \\ , , \\vec{a } = \\left [ \\left [ \\partial^+_l { { \\mathbf u}}\\right]_{l=0}^{l-1 } \\ , , 1 \\right ] \\in x^{l+1 }   \\ , , \\vec{{{\\mathbf y } } } = \\left [ { { \\mathbf y}}_l \\right]_{l=0}^l \\in x^{l+1 } \\ , ,",
    "\\boldsymbol{\\lambda_1 } \\in x    \\ , , \\vec{\\boldsymbol{\\lambda_2 } } = \\left [ \\boldsymbol{\\lambda}_{\\boldsymbol 2 l } \\right]_{l=0}^l \\in x^{l+1}.\\ ] ] the matrix form is @xmath297    [ lem : l1-projection ] given @xmath298 and @xmath299 , a solution of @xmath9-minimization ( a primal problem ) in a matrix form is @xmath300 with @xmath301^{\\cdot 2 } } $ ] .",
    "denote @xmath302 as a dual variable of @xmath303 , the legendre - fenchel transform of @xmath304 on a convex set is @xmath305 } \\leq \\mu \\right\\ } \\ , .",
    "\\end{aligned}\\ ] ] a dual problem of ( [ eq : primal : vectorl1:y ] ) is @xmath306    * proof for a solution of @xmath9-minimization ( [ eq : primal : vectorl1:y ] ) with a vector - valued form : *    to be self - contained , a proof of ( [ eq : primal : vectorl1:y : solution ] ) is provided for vector - valued data from @xcite and @xcite .",
    "an objective function in ( [ eq : primal : vectorl1:y ] ) is rewritten as @xmath307 }     + \\frac{1}{2 } \\sum_{l=0}^l \\left ( y_{\\text{p } l}[{{\\boldsymbol k } } ] - y'_{l}[{{\\boldsymbol k } } ] \\right)^2    \\right ] \\ , .",
    "\\end{aligned}\\ ] ] the optimal condition of @xmath308 at @xmath309 and @xmath310 is @xmath311 }    = \\mu \\frac { y _ { \\text{p } l ' } [ { { \\boldsymbol k } } ' ] } { \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] } } + y_{\\text{p } l'}[{{\\boldsymbol k } } ' ] - y'_{l'}[{{\\boldsymbol k } } ' ]    \\,,~~     \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] } = \\sqrt { \\sum_{l=0}^l y^2_{\\text{p } l}[{{\\boldsymbol k } } ' ] } \\in \\mathbb r   \\end{aligned}\\ ] ] if @xmath312 , then by sub - differential we choose @xmath313 = \\frac { \\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] } { \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] } } \\in \\mathbb r^{l+1}$ ] such that @xmath314 } = \\sqrt { \\sum_{l=0}^{l } c^2_l[{{\\boldsymbol k } } ' ] } \\leq 1    $ ] and @xmath315 = \\mu \\vec{c}[{{\\boldsymbol k}}']$ ] with @xmath316 } = \\mu \\abs{\\vec{c}[{{\\boldsymbol k } } ' ] } \\leq \\mu$ ] .    if @xmath317 , then we have @xmath318 = \\left [ \\frac { \\mu } { \\abs{\\vec{y } _",
    "{ \\text{p}}[{{\\boldsymbol k } } ' ] } } + 1 \\right ] \\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ]    ~\\leftrightarrow~    \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } = \\left [ \\frac { \\mu } { \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol",
    "k } } ' ] } } + 1 \\right ] \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] }    = \\mu + \\abs{\\vec{y } _ { \\text{p}}[{{\\boldsymbol k } } ' ] } \\ , .",
    "\\end{aligned}\\ ] ] thus , we have @xmath319 = \\frac { \\vec{y'}[{{\\boldsymbol k } } ' ] } { \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } } \\left [ \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } - \\mu \\right ] \\ , .",
    "\\end{aligned}\\ ] ] finally , we have a solution of ( [ eq : primal : vectorl1:y ] ) with @xmath309 as @xmath320 = \\begin{cases }     0 \\ , , & \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } \\leq \\mu        \\\\",
    "\\frac { \\vec{y'}[{{\\boldsymbol k } } ' ] } { \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } } \\left [ \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } - \\mu \\right ] \\ , , & \\text{else }    \\end{cases }    = \\frac { \\vec{y'}[{{\\boldsymbol k } } ' ] } { \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } } \\max \\left ( \\abs{\\vec{y'}[{{\\boldsymbol k } } ' ] } - \\mu \\ , , 0 \\right ) \\ , ,   \\end{aligned}\\ ] ] or its matrix form is @xmath321^{\\cdot 2 } } \\ , .",
    "\\end{aligned}\\ ] ]    * proof for a lengendre - fenchel transform of @xmath304 in ( [ eq : legendrefenchel : vectorl1:y ] ) : *    the epigraph of a convex function @xmath322 is a convex set as @xmath323 a hyperplane ( defined by @xmath324 ) lying below @xmath325 , i.e. @xmath326 , results in the legendre - fenchel transform of @xmath322 as a convex function @xmath327 the optimal condition of its objective function @xmath328 y_{\\text{p } l}[{{\\boldsymbol k } } ]    - \\sqrt { \\sum_{l=0}^l y_{\\text{p } l}^2[{{\\boldsymbol k } } ] }    \\right ]   \\end{aligned}\\ ] ] at @xmath309 and @xmath329 is @xmath330 }    = \\frac{1}{\\mu } y_{\\text{d } l'}[{{\\boldsymbol k } } ' ] - \\frac { y_{\\text{p } l'}[{{\\boldsymbol k } } ' ] } { \\abs { \\vec{y}_\\text{p } [ { { \\boldsymbol k } } ' ] } }    \\\\ \\leftrightarrow~    y_{\\text{d } l'}[{{\\boldsymbol k } } ' ] & = \\mu \\frac { y_{\\text{p } l'}[{{\\boldsymbol k } } ' ] } { \\abs { \\vec{y}_\\text{p } [ { { \\boldsymbol k } } ' ] } }    \\,,~ \\text {   with   } \\abs { \\vec{y}_\\text{p } [ { { \\boldsymbol k } } ' ] } = \\sqrt{\\sum_{l=0}^l y^2_{\\text{p } l } [ { { \\boldsymbol k } } ' ] } \\ , .   \\end{aligned}\\ ] ] if @xmath331 , then by sub - differential we choose @xmath313 = \\frac { \\vec{y}_{\\text{p}}[{{\\boldsymbol k } } ' ] } { \\abs { \\vec{y}_\\text{p } [ { { \\boldsymbol k } } ' ] } } \\in \\mathbb r^{l+1}$ ] such that @xmath332 } \\leq 1 $ ] , so @xmath333 and @xmath334 = \\mu \\vec{c}[{{\\boldsymbol k}}']$ ] with @xmath335 } = \\mu \\abs{\\vec{c}[{{\\boldsymbol k } } ' ] } \\leq \\mu \\,,~ \\forall { { \\boldsymbol k } } ' \\in \\omega$ ] which is equivalent to @xmath336 } \\leq \\mu   \\text {    and    }   \\abs{\\vec{y}_{\\text{d}}[{{\\boldsymbol k } } ' ] } = \\sqrt { \\sum_{l=0}^l y^2_{\\text{d } l}[{{\\boldsymbol k } } ' ] } \\ , .",
    "\\end{aligned}\\ ] ] thus , @xmath337 if @xmath338 , we have @xmath339 y_{\\text{p } l}[{{\\boldsymbol k } } ]    - \\sqrt { \\sum_{l=0}^l y_{\\text{p } l}^2[{{\\boldsymbol k } } ] }    \\right ]    \\geq     \\sum_{{{\\boldsymbol k}}\\in \\omega } \\sum_{l=0}^l \\left [    \\frac{1}{\\mu } y_{\\text{d } l}[{{\\boldsymbol k } } ] y_{\\text{p } l}[{{\\boldsymbol k } } ]    - \\abs { y_{\\text{p } l}[{{\\boldsymbol k } } ] }    \\right ]      \\\\    & = \\begin{cases } \\displaystyle     \\sum_{{{\\boldsymbol k}}\\in \\omega } \\sum_{l=0}^l \\left [ \\frac{1}{\\mu } y_{\\text{d } l}[{{\\boldsymbol k } } ] - 1 \\right ] y_{\\text{p } l}[{{\\boldsymbol k } } ]      \\ , , & y_{\\text{p } l}[{{\\boldsymbol k } } ] \\geq 0 \\ , , \\forall l \\ , , { { \\boldsymbol k}}\\ , ,     \\\\ \\displaystyle     \\sum_{{{\\boldsymbol k}}\\in \\omega } \\sum_{l=0}^l \\left [ \\frac{1}{\\mu } y_{\\text{d } l}[{{\\boldsymbol k } } ] + 1 \\right ] y_{\\text{p } l}[{{\\boldsymbol k } } ]     \\ , , & y_{\\text{p } l}[{{\\boldsymbol k } } ] < 0 \\ , , \\forall l \\ , , { { \\boldsymbol k}}\\ , .",
    "\\end{cases }   \\end{aligned}\\ ] ] we observe that given @xmath340 } > \\mu$ ] , @xmath341 when @xmath342 .",
    "thus , @xmath343 } > \\mu \\ , , \\forall { { \\boldsymbol k}}\\in \\omega \\ , .",
    "\\end{aligned}\\ ] ] so , we have the legendre - fenchel transform of @xmath304 on a convex set is @xmath344 } \\leq \\mu \\right\\ } \\ , .",
    "\\end{aligned}\\ ] ]    * proof for a solution of dual problem of ( [ eq : primal : vectorl1:y ] ) , eq .",
    "( [ eq : dual : vectorl1:y])-([eq : dual : vectorl1:y : solutionprimaldual ] ) : *    we define epigraph of the legendre - fenchel transform @xmath345 in ( [ eq : legendrefenchel : proof ] ) as a set of hyperplane lying below a convex function @xmath346 as @xmath347 by bi - conjugate of a convex function , we have @xmath348 the equality happens ,",
    "i.e. @xmath349 , if @xmath303 is the sub - differential of @xmath350 or @xmath302 is the sub - differential of @xmath346 as @xmath351 equivalently , the objective function in ( [ eq : primal : vectorl1:y ] ) is rewritten as @xmath352    since legendre - fenchel transform of @xmath322 is @xmath353 , we build a dual relation of a non - smooth minimization ( [ eq : primal : vectorl1:y ] ) by considering the optimal condition of an objective function @xmath354 at @xmath355 with the sub - differential @xcite as @xmath356 thus , we have @xmath357 where @xmath358 is a solution of a dual problem of ( [ eq : primal : vectorl1:y ] ) by a primal / dual relation as @xmath359 note that a convex set @xmath360 is equivalent to @xmath9-ball as @xmath361 } \\leq \\mu     ~\\leftrightarrow~     \\abs { \\vec{y}_\\text{d}[{{\\boldsymbol k } } ] } \\leq \\mu \\,,~ \\forall { { \\boldsymbol k}}\\in \\omega    \\right\\ }     \\ , .   \\end{aligned}\\ ] ] thus , a solution of a dual problem ( [ eq : dual : vectorl1:y : proof ] ) is a projection of @xmath362 onto an @xmath9-ball @xmath360 as @xmath363    the solution of the `` @xmath364_{l=0}^{l-1}$]-problem '' is @xmath365^{\\cdot 2 } } \\ , .",
    "\\end{cases }     \\end{aligned}\\ ] ]    under a minimization , the objective function is rewritten as @xmath366   \\\\ &   - \\frac{\\beta_4}{2 } \\sum_{l=0}^l \\norm { { { \\mathbf t}}_l + \\frac{\\boldsymbol{\\lambda_{4l}}}{\\beta_4 } + { { \\mathbf r}}_l \\cdot^\\times \\frac{\\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_4 } } ^2_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\sum_{l=0}^l \\norm { { { \\mathbf t}}_l + \\frac{\\boldsymbol{\\lambda_{4l}}}{\\beta_4 } } ^2_{\\ell_2 }   \\\\   & = \\mathscr r^*(\\vec{{{\\mathbf y } } } ) + \\frac{\\beta_4}{2 } \\norm { \\vec{{{\\mathbf y } } } - \\left [ \\vec{{{\\mathbf t } } } + \\frac { \\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 4 } } { \\beta_4 } + \\vec{{{\\mathbf r } } } \\cdot^\\times \\frac{\\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_4 } \\right ] } ^2_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\left [ \\norm{\\vec{{{\\mathbf t } } } + \\frac{\\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 4}}{\\beta_4 } } ^2_{\\ell_2 }   - \\norm { \\vec{{{\\mathbf t } } } + \\frac{\\vec{\\boldsymbol \\lambda}_{\\boldsymbol 4}}{\\beta_4 } + \\vec{{{\\mathbf r } } } \\cdot^\\times \\frac{\\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_4 }   } ^2_{\\ell_2 }   \\right ] \\,.\\end{aligned}\\ ] ] according to lemma [ lem : l1-projection ] , a solution of a minimization of the `` @xmath125-problem '' is @xmath367    \\bigg|\\bigg|^2_{\\ell_2 }   \\right\\ }   = \\begin{cases }       \\vec{{{\\mathbf y } } ' } \\ , , & \\abs{\\vec{{{\\mathbf y } } ' } } \\leq 1   \\\\",
    "\\frac { \\vec{{{\\mathbf y } } ' } } { \\abs{\\vec{{{\\mathbf y } } ' } } } \\ , , & \\text{else }      \\end{cases}\\end{aligned}\\ ] ] with @xmath368_{l=0}^l \\in x^{l+1 }    \\,,~~   { { \\mathbf y}}'_l = { { \\mathbf t}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4 l } } { \\beta_4 } + { { \\mathbf r}}_l \\cdot^\\times \\frac{\\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_4 }   ~~ \\text{and}~~   \\abs{\\vec{{{\\mathbf y } } ' } } = \\sqrt { \\sum_{l=0}^l \\left [ { { \\mathbf t}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 4 l } } { \\beta_4 } + { { \\mathbf r}}_l \\cdot^\\times \\frac{\\boldsymbol{\\lambda_1 } + \\beta_1}{\\beta_4 } \\right]^{\\cdot 2 } } \\,.\\end{aligned}\\ ] ]",
    "[ prop : problem : u ]    the solution of the `` @xmath1-problem '' is as follows @xmath369 \\,.\\end{aligned}\\ ] ] with @xmath370   \\left [ r_l({{\\boldsymbol z } } ) + \\frac { \\lambda_{2 l}({{\\boldsymbol z } } ) } { \\beta_2 } \\right ]   \\\\   & + \\beta_5 h({{\\boldsymbol z}}^{-1 } ) \\left [ f({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) v({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) p({{\\boldsymbol z } } ) - { { \\mathcal e}}({{\\boldsymbol z } } ) + \\frac{\\lambda_5({{\\boldsymbol z}})}{\\beta_5 } \\right ] \\",
    "{ { \\mathcal x}}({{\\boldsymbol z } } ) & = \\beta_2 \\sum_{l=0}^{l-1 } \\abs { \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1 - 1 ) } ^2 + \\beta_5 \\abs{h({{\\boldsymbol z}})}^2 \\,.\\end{aligned}\\ ] ]    the euler - lagrange equation is @xmath371 = -\\partial_l^- \\delta[{{\\boldsymbol k } } ] }    \\left [ { { \\mathbf r}}_l - \\partial^+_l { { \\mathbf u}}+ \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 2 l } } { \\beta_2 } \\right ]    - \\beta_5 \\check{{{\\mathbf h } } } \\ast \\left [ { { \\mathbf f}}- { { \\mathbf h}}\\ast { { \\mathbf u}}- { { \\mathbf h}}\\ast { { \\mathbf v}}- { { \\mathbf h}}\\ast { { \\boldsymbol \\rho}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 5}}{\\beta_5 } \\right ]    \\\\ \\leftrightarrow~ &    \\left [ -\\beta_2 \\sum_{l=0}^{l-1 } \\partial_l^- \\partial^+_l \\delta + \\beta_5 \\check{{{\\mathbf h } } } \\ast { { \\mathbf h}}\\right ] \\ast { { \\mathbf u}}=    - \\beta_2 \\sum_{l=0}^{l-1 } \\partial_l^- \\left [ { { \\mathbf r}}_l + \\frac { \\boldsymbol{\\lambda}_{\\boldsymbol 2 l } } { \\beta_2 } \\right ]    + \\beta_5 \\check{{{\\mathbf h } } } \\ast \\left [ { { \\mathbf f}}- { { \\mathbf h}}\\ast { { \\mathbf v}}- { { \\mathbf h}}\\ast { { \\boldsymbol \\rho}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 5}}{\\beta_5 } \\right ]     \\\\",
    "\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     & \\left [ \\beta_2 \\sum_{l=0}^{l-1 } \\abs { \\cos(\\frac{\\pi l}{l})(z_2 - 1 ) + \\sin(\\frac{\\pi l}{l})(z_1 - 1 ) } ^2     + \\beta_5 \\abs{h({{\\boldsymbol z}})}^2 \\right ] u({{\\boldsymbol z } } )    \\\\ &    = \\beta_2 \\sum_{l=0}^{l-1 } \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1^{-1 } - 1 ) \\right ]    \\left [ r_l({{\\boldsymbol z } } ) + \\frac { \\lambda_{2 l}({{\\boldsymbol z } } ) } { \\beta_2 } \\right ]    \\\\ &    + \\beta_5 h({{\\boldsymbol z}}^{-1 } ) \\left [ f({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) v({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) p({{\\boldsymbol z } } ) - { { \\mathcal e}}({{\\boldsymbol z } } ) + \\frac{\\lambda_5({{\\boldsymbol z}})}{\\beta_5 } \\right ]    \\end{aligned}\\ ] ] by applying the fourier transform , a solution of the `` @xmath1-problem '' is @xmath372^{-1 }    \\\\ &    \\bigg [ \\beta_2 \\sum_{l=0}^{l-1 } \\left [ \\cos(\\frac{\\pi l}{l})(z_2^{-1 } - 1 ) + \\sin(\\frac{\\pi l}{l})(z_1^{-1 } - 1 ) \\right ]    \\left [ r_l({{\\boldsymbol z } } ) + \\frac { \\lambda_{2 l}({{\\boldsymbol z } } ) } { \\beta_2 } \\right ]    \\\\ &    + \\beta_5 h({{\\boldsymbol z}}^{-1 } ) \\left [ f({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) v({{\\boldsymbol z } } ) - h({{\\boldsymbol z } } ) p({{\\boldsymbol z } } ) - { { \\mathcal e}}({{\\boldsymbol z } } ) + \\frac{\\lambda_5({{\\boldsymbol z}})}{\\beta_5 } \\right ] \\bigg ] \\ , .",
    "\\end{aligned}\\ ] ]    the sum of two @xmath8 functions is rewritten as @xmath373    @xmath374    } _ { : = ~ c_{f_1 f_2 } }   \\end{aligned}\\ ] ]    [ lem : linearizeconvexfunc ] given a non - smooth convex function @xmath375 , e.g. @xmath376 and a smooth convex function @xmath377 , e.g. @xmath378 , we linearize a convex minimization as @xmath379    1-dimensional taylor expansion of a function @xmath380 at @xmath381 is @xmath382 with @xmath383 is a @xmath384-th order derivative of @xmath380 at @xmath385 , i.e. @xmath386 .    the 1st order of the 2-dimensional taylor expansion of a function @xmath387 at @xmath388 with @xmath389 is @xmath390    as in ista @xcite or fista @xcite , given a convex minimization @xmath391 @xmath375 is a non - smooth ( non - differentiable ) convex function , e.g. @xmath376 and @xmath377 is a smooth ( differentiable ) convex function , e.g. @xmath378 . by the 1-st order taylor expansion of a smooth function @xmath392 at @xmath393 in ( [ eq : taylorexpansion ] ) , minimization ( [ eq : cvxapproximation : ista ] )",
    "is rewritten as @xmath394    [ prop : problem : v ]    the solution of the `` @xmath2-problem '' is as follows @xmath395 with @xmath396 \\ast { { \\mathbf v}}^{(\\tau-1 ) }        + \\alpha^{(\\tau ) } \\check{{{\\mathbf h } } } \\ast \\left ( { { \\mathbf f}}- { { \\mathbf h}}\\ast { { \\mathbf u}}- { { \\mathbf h}}\\ast { { \\boldsymbol \\rho}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 5}}{\\beta_5 } \\right ) \\right )    \\\\   & + \\frac { \\beta_7 \\alpha^{(\\tau ) } } { \\beta_5 + \\alpha^{(\\tau ) } \\beta_7 }   \\big ( \\underbrace { -\\sum_{s=0}^{s-1 } \\big [ \\cos(\\frac{\\pi s}{s } ) { { \\mathbf g}}_s { { \\mathbf{d_2}}}+ \\sin(\\frac{\\pi s}{s } ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf g}}_s \\big ] } _ { = \\text{div}^-_s \\vec{{{\\mathbf g } } } }       - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 7}}{\\beta_7 } \\big ) \\,.\\end{aligned}\\ ] ]    according to lemma [ lem : linearizeconvexfunc ] , a linearized version of the `` @xmath2-problem '' is @xmath397 }                              ^{= \\frac{\\partial q({{\\mathbf v}})}{\\partial { { \\mathbf v } } } \\mid_{{{\\mathbf v}}= { { \\mathbf v}}^{(\\tau-1 ) } } }   \\big )    \\bigg |\\bigg | ^2_{\\ell_2 }   \\\\ & \\qquad \\qquad \\quad   + \\frac{\\beta_7}{2\\beta_5 } \\norm { { { \\mathbf v}}- \\big ( \\text{div}^-_s \\vec{{{\\mathbf g } } } - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 7}}{\\beta_7 } \\big ) } ^2_{\\ell_2 }   \\bigg\\ } \\,,~~ \\tau = 1 , \\ldots    \\\\ &   = { \\mathop{\\rm argmin}}_{{{\\mathbf v}}\\in x } \\bigg\\ {    \\norm{{{\\mathbf v}}}_{\\ell_1 }     + \\frac{\\beta_5 + \\alpha^{(\\tau ) } \\beta_7}{2 \\mu_2 \\alpha^{(\\tau ) } } \\norm { { { \\mathbf v}}- { { \\mathbf t}}_{{\\mathbf v}}}^2_{\\ell_2 }   \\bigg\\ } \\end{aligned}\\ ] ] with @xmath398 \\big )    + \\frac { \\beta_7 \\alpha^{(\\tau ) } } { \\beta_5 + \\alpha^{(\\tau ) } \\beta_7 }   \\big ( \\text{div}^-_s \\vec{{{\\mathbf g } } } - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 7}}{\\beta_7 } \\big ) \\,.\\end{aligned}\\ ] ] thus , a solution of the @xmath2-problem is defined at iteration @xmath104 as @xmath399    [ prop : problem : g ]    the `` @xmath160-problem '' @xmath400 has a minimizer as @xmath401 with @xmath144   -\\beta_7 \\left [ \\cos\\left(\\frac{\\pi s}{s}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi s}{s}\\right ) ( z_1 - 1 ) \\right ] \\times   \\\\ &   \\left [ v({{\\boldsymbol z } } ) + \\sum_{s'=[0 , s-1 ] \\backslash \\{s\\ } } \\left [ \\cos\\left(\\frac{\\pi s'}{s}\\right)(z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi s'}{s}\\right ) ( z_1^{-1 } - 1 ) \\right ] g_{s'}({{\\boldsymbol z } } ) + \\frac{\\lambda_7({{\\boldsymbol z}})}{\\beta_7 } \\right ] \\,.\\end{aligned}\\ ] ]    given @xmath402_{s=0}^{s-1 } \\ , , \\vec{{{\\mathbf w } } } = \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1 } \\ , , \\vec{\\boldsymbol{\\lambda}}_{\\boldsymbol 6 }",
    "= \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol 6s } \\big]_{s=0}^{s-1}$ ] and @xmath403_{s=0}^{s-1}$ ] , the euler - lagrange equation is @xmath404   - \\beta_7 \\underbrace { \\frac { \\partial \\big\\ { \\text{div}^-_s \\vec{{{\\mathbf g } } } \\big\\ } } { \\partial \\vec{{{\\mathbf g } } } } }                       _ { = \\big ( \\text{div}^-_s \\big)^ * \\delta = - \\nabla_s^+ \\delta }   \\big [ { { \\mathbf v}}- \\text{div}^-_s \\vec{{{\\mathbf g } } } + \\frac{\\boldsymbol{\\lambda_7}}{\\beta_7 } \\big]\\end{aligned}\\ ] ] given @xmath405 , we have @xmath406   + \\beta_7 \\partial_s^+ \\big [ { { \\mathbf v}}- \\underbrace { \\sum_{s'=0}^{s-1 } \\partial^-_{s ' } { { \\mathbf g}}_{s ' } } _ { = \\text{div}^-_s \\vec{{{\\mathbf g } } } } + \\frac{\\boldsymbol{\\lambda_7}}{\\beta_7 } \\big ]    \\\\   \\leftrightarrow    { { \\mathbf g}}_s & = \\big [ \\beta_6 - \\beta_7 \\partial^+_s \\partial^-_s \\text{id } \\big]^{-1 }           \\bigg [ -\\beta_7 \\partial_s^+ \\big [ { { \\mathbf v}}- \\sum_{s'=[0 , s-1 ] \\backslash \\{s\\ } } \\partial^-_s { { \\mathbf g}}_s + \\frac{\\boldsymbol{\\lambda_7}}{\\beta_7 } \\big ]                  + \\beta_6 \\big [ { { \\mathbf w}}_s + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 6 s}}{\\beta_6 } \\big ]           \\bigg]\\end{aligned}\\ ] ] thus , a solution of the `` @xmath136-problem '' is obtained in the fourier domain .",
    "[ prop : vcpyramid : problem : u : spatial ] a solution of the `` @xmath1-problem '' ( [ eq : problem : u ] ) can be rewritten in a form of sampling theory as in equation ( [ eq : vcpyramid : problem : u : spatial:1 ] ) .",
    "we analyze filter banks generated by the dmcd model at iteration @xmath104 in the listed order of algorithm 1 - 4 in appendix c.    * a. the `` @xmath114-problem '' : *    from ( [ eq : problem : d : solution ] ) and a solution of the `` @xmath114-problem '' ( [ eq : problem : t ] ) , we have @xmath407 - \\beta_3 \\partial_l^- \\partial_l^+ \\delta[{{\\boldsymbol k } } ]   \\\\   { { \\mathcal m}}_l^{(\\tau)}({{\\boldsymbol z } } ) & \\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow }   \\beta_4 \\big [ y_l^{(\\tau-1 ) } - \\frac { \\lambda_{4l}^{(\\tau-1 ) } } { \\beta_4 } \\big ] [ { { \\boldsymbol k } } ]    \\\\ &   -\\beta_3 \\partial_l^+    \\big [ \\underbrace { \\text{shrink } \\big ( \\sum_{l'=0}^{l-1 } \\partial_{l'}^- t_{l'}^{(\\tau-1 ) } - \\frac{\\lambda_3^{(\\tau-1)}}{\\beta_3 } , \\frac{1}{\\beta_3 } \\big ) }                   _ { = d^{(\\tau)}[{{\\boldsymbol k } } ] }         + \\frac { \\lambda_3^{(\\tau-1 ) } } { \\beta_3 }          - \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\partial_{l'}^- t_{l'}^{(\\tau-1 ) } \\big ] [ { { \\boldsymbol k } } ] \\end{aligned}\\ ] ] due to @xmath408 ^ 2 \\ , , $ ] and choose @xmath409 , a solution of the `` @xmath114-problem '' at a direction @xmath23 is rewritten as @xmath410    \\notag   \\\\ &   + \\theta^{l , c_{34}}_l({{\\boldsymbol z } } )   \\big [ d^{(\\tau)}({{\\boldsymbol z } } ) + \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\big [ \\cos\\left(\\frac{\\pi l'}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right ) ( z_1^{-1 } - 1 ) \\big ] t_{l'}^{(\\tau-1)}({{\\boldsymbol z } } ) + \\frac { \\lambda_3^{(\\tau-1)}({{\\boldsymbol z } } ) } { \\beta_3 } \\big ] \\,.\\end{aligned}\\ ] ] given @xmath88 , the inverse fourier transform of ( [ eq : vcpyramid : problem : t:1 ] ) at a direction @xmath23 is @xmath411 & = \\big ( \\xi^{l , c_{34}}_l \\ast \\big [ y_l^{(\\tau-1 ) } - \\frac { \\lambda_{4l}^{(\\tau-1 ) } } { \\beta_4 } \\big ] \\big ) [ { { \\boldsymbol k } } ]    \\notag   \\\\ &   + \\big ( \\theta^{l ,",
    "c_{34}}_l \\ast \\big [ \\underbrace { \\text{shrink } \\big ( \\sum_{l'=0}^{l-1 } \\check{\\tilde \\theta}^l_{l ' } \\ast t_{l'}^{(\\tau-1 ) } - \\frac{\\lambda_3^{(\\tau-1)}}{\\beta_3 } \\,,~ \\frac{1}{\\beta_3 } \\big ) + \\frac { \\lambda_3^{(\\tau-1 ) } } { \\beta_3 } }                                         _ { \\displaystyle = { \\mathop{\\rm st}}\\big ( \\sum_{l'=0}^{l-1 } \\check{\\tilde \\theta}^l_{l ' } \\ast t_{l'}^{(\\tau-1 ) } \\ , , \\frac{\\lambda_3^{(\\tau-1)}}{\\beta_3 } \\ , , \\frac { 1 } { \\beta_3 } \\big ) }           - \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\check{\\tilde \\theta}^l_{l ' } \\ast",
    "t_{l'}^{(\\tau-1 ) } \\big ]     \\big ) [ { { \\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] frames at a direction @xmath23 are @xmath412 = \\left [ 1 - c_{34 } \\partial_l^- \\partial_l^+ \\right]^{-1 } \\delta[{{\\boldsymbol k } } ] \\ , ,   \\\\   \\label{eq : filterbanks : xithetatheta_tilde:2 }   \\theta^{l , c_{34}}_l({{\\boldsymbol z } } ) & =    \\frac { -c_{34 } \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) \\right ] }        { 1 + c_{34 } \\abs { \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) } ^2 }   ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~     \\theta^{l , c_{34}}_l[{{\\boldsymbol k } } ] = -c_{34 } \\partial_l^+ \\xi^{l , c_{34}}_l[{{\\boldsymbol k } } ] \\ , ,   \\\\",
    "\\label{eq : filterbanks : xithetatheta_tilde:3 }   \\tilde \\theta^l_l({{\\boldsymbol z}}^{-1 } ) & = - \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1 } - 1 ) \\right ]   ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~     \\check{\\tilde \\theta}^l_l[{{\\boldsymbol k } } ] = \\partial_l^- \\delta[{{\\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] note that these frames satisfy the unity condition as @xmath413 figure [ fig : mdcd_let : filterbanks : c0_1 ] and [ fig : mdcd_let : filterbanks : c10 ] illustrate the spectrum of these filter banks .",
    "* b. the `` @xmath125-problem '' : *    given @xmath88 , a solution of the `` @xmath125-problem '' ( [ eq : problem : y ] ) ( at iteration @xmath104 ) is rewritten as @xmath414^{\\cdot 2 } }    \\end{cases }    \\\\",
    "\\leftrightarrow~    \\vec{y}^{(\\tau)}[{{\\boldsymbol k } } ] & = \\text{proj}_{[-1,1 ] }    \\bigg [ \\underbrace {           \\vec{t}^{(\\tau)}[{{\\boldsymbol k } } ] + \\frac { \\vec{\\lambda}_4^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_4 }            + \\frac{\\beta_1 + \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_4 } \\vec{r}^{(\\tau)}[{{\\boldsymbol k } } ]           } _ { \\displaystyle = \\vec{y}^{\\prime(\\tau)}[{{\\boldsymbol k } } ] = \\big [ y_l^{\\prime(\\tau)}[{{\\boldsymbol k } } ] \\big]_{l=0}^l }   \\bigg ] \\,.\\end{aligned}\\ ] ] by denoting @xmath415 = \\big [ y_l^{(\\tau ) } [ { { \\boldsymbol k } } ] \\big]_{l=0}^{l } \\,,~ \\vec{t}^{(\\tau ) } [ { { \\boldsymbol k } } ] = \\big [ t_l^{(\\tau ) } [ { { \\boldsymbol k } } ] \\big]_{l=0}^{l } \\,,~ \\vec{r}^{(\\tau ) } [ { { \\boldsymbol k } } ] = \\big [ r_l^{(\\tau ) } [ { { \\boldsymbol k } } ] \\big]_{l=0}^{l } \\ , , $ ] and from ( [ eq : vcpyramid : problem : t:2 ] ) and a solution of the `` @xmath110-problem '' at direction @xmath416 , we rewrite @xmath417 = \\text{proj}_{[-1,1 ] } \\big [ \\vec{y}^{\\prime(\\tau)}[{{\\boldsymbol k } } ] \\big]$ ] with @xmath418 & =    t_l^{(\\tau)}[{{\\boldsymbol k } } ] + \\frac { \\lambda_{4l}^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_4 }    + \\frac{\\beta_1 + \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_4 } r_l^{(\\tau)}[{{\\boldsymbol k } } ]      \\notag   \\\\ &   = \\left ( \\xi^{l , c_{34}}_l \\ast \\left [ y_l^{(\\tau-1 ) } - \\frac { \\lambda_{4l}^{(\\tau-1 ) } } { \\beta_4 } \\right ] \\right ) [ { { \\boldsymbol k } } ]   + \\frac { \\lambda_{4l}^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_4 }                             \\notag   \\\\ &   + \\left ( \\theta^{l , c_{34}}_l \\ast \\left [   \\text{shrink } \\left ( \\sum_{l'=0}^{l-1 } \\check{\\tilde \\theta}^l_{l ' } \\ast t_{l'}^{(\\tau-1 ) } - \\frac{\\lambda_3^{(\\tau-1)}}{\\beta_3 } \\,,~ \\frac{1}{\\beta_3 } \\right ) + \\frac { \\lambda_3^{(\\tau-1 ) } } { \\beta_3 }           - \\sum_{l'=[0 , l-1 ] \\backslash \\{l\\ } } \\check{\\tilde \\theta}^l_{l ' } \\ast",
    "t_{l'}^{(\\tau-1 ) } \\right ]     \\right ) [ { { \\boldsymbol k } } ]                                                                \\notag   \\\\ &    + \\frac{\\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1}{\\beta_4 }      { \\mathop{\\rm shrink}}\\left ( \\partial_l^+ u^{(\\tau-1)}[{{\\boldsymbol k } } ] - \\frac { \\lambda_{2 l}^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_2 }                     + \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1 } { \\beta_2 } y_l^{(\\tau-1)}[{{\\boldsymbol k } } ]                    \\ , , \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1}{\\beta_2 } \\right ) \\,,\\end{aligned}\\ ] ] where the definition of @xmath419 and @xmath420 are well defined in ( [ eq : filterbanks : xithetatheta_tilde:1])-([eq : filterbanks : xithetatheta_tilde : unitycondition ] ) .    * c. the `` @xmath1-problem '' : *    from a solution of the  @xmath1-problem ( [ eq : problem : u ] ) , we have @xmath421 -\\beta_2 \\sum_{l=0}^{l-1 } \\partial_l^- \\partial_l^+ \\delta[{{\\boldsymbol k } } ]   \\\\   { { \\mathcal y}}^{(\\tau)}({{\\boldsymbol z } } ) & ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~     \\beta_5 \\big ( \\check{h } \\ast \\big [ f - h \\ast v^{(\\tau-1 ) } - h \\ast \\rho^{(\\tau-1 ) } - \\epsilon^{(\\tau-1 ) } + \\frac{\\lambda_5^{(\\tau-1)}}{\\beta_5 } \\big ] \\big ) [ { { \\boldsymbol k } } ]   \\\\ &   - \\beta_2 \\sum_{l=0}^{l-1 } \\partial_l^-    \\big [ \\underbrace { { \\mathop{\\rm shrink}}\\big ( \\partial_l^+ u^{(\\tau-1)}[{{\\boldsymbol k } } ] - \\frac { \\lambda_{2 l}^{(\\tau-1 ) } [ { { \\boldsymbol k } } ] } { \\beta_2 } + \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1 } { \\beta_2 } y_l^{(\\tau-1 ) } [ { { \\boldsymbol k } } ]                       \\,,~ \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1}{\\beta_2 } \\big )                     } _ { = r_l^{(\\tau)}[{{\\boldsymbol k } } ] }         + \\frac { \\lambda_{2 l}^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_2 } \\big]\\end{aligned}\\ ] ] to avoid singularity , we check @xmath422 at @xmath423 as @xmath424 if a blur operator has @xmath179 ( usually @xmath425 because @xmath426 often plays as a lowpass kernel in the fourier domain ) , then the function @xmath422 satisfies @xmath427 ^ 2 \\,.\\end{aligned}\\ ] ] note that this is similar to a condition of riesz basis .",
    "thus , a solution of the `` @xmath1-problem '' is rewritten as @xmath428    \\notag   \\\\ & \\quad   + \\sum_{l=0}^{l-1 } \\tilde\\psi_l^{l , c_{25}}({{\\boldsymbol z}}^{-1 } ) \\left [ r_l^{(\\tau)}({{\\boldsymbol z } } ) + \\frac { \\lambda_{2 l}^{(\\tau-1)}({{\\boldsymbol z } } ) } { \\beta_2 } \\right ] \\,.\\end{aligned}\\ ] ] given @xmath88 , the inverse fourier transform of ( [ eq : vcpyramid : problem : u ] ) is @xmath429 = \\big ( \\phi^{l , c_{25 } } \\ast \\check{h } \\ast \\big ( f - h \\ast v^{(\\tau-1 ) } - h \\ast \\rho^{(\\tau-1 ) } - \\epsilon^{(\\tau-1 ) } + \\frac{\\lambda_5^{(\\tau-1)}}{\\beta_5 } \\big ) \\big)[{{\\boldsymbol k } } ]    \\notag   \\\\ &   + \\sum_{l=0}^{l-1 } \\check{\\tilde{\\psi}}^{l , c_{25}}_l [ { { \\boldsymbol k } } ] \\ast",
    "\\bigg [ { \\mathop{\\rm shrink}}\\big ( \\big(\\psi^l_l \\ast u^{(\\tau-1)}\\big)[{{\\boldsymbol k } } ] - \\frac { \\lambda_{2 l}^{(\\tau-1 ) } [ { { \\boldsymbol k } } ] } { \\beta_2 } + \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1 } { \\beta_2 } y_l^{(\\tau-1 ) } [ { { \\boldsymbol k } } ]                       \\,,~ \\frac { \\lambda_1^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\beta_1}{\\beta_2 } \\big )                + \\frac { \\lambda_{2 l}^{(\\tau-1)}[{{\\boldsymbol k } } ] } { \\beta_2 } \\bigg ] .\\end{aligned}\\ ] ] at a direction @xmath23 , we have @xmath164 = \\mathbb p_{[-1,1 ] } \\big [ \\vec{y}\\prime^{(\\tau-1)}[{{\\boldsymbol k } } ] \\big]$ ] with @xmath430 = \\big [ y_l^{\\prime(\\tau-1)}[{{\\boldsymbol k } } ] \\big]_{l=0}^{l-1}$ ] as defined in ( [ eq : vcpyramid : problem : y ] ) at iteration @xmath431 .",
    "note that @xmath167 in ( [ eq : vcpyramid : problem : u : spatial ] ) is updated from @xmath168 and @xmath169 at every iteration @xmath104 .",
    "frames ( at direction @xmath23 ) are well defined in the fourier domain @xmath432 \\ , ,   \\\\",
    "\\label{eq : vcpyramid : problem : frameelements : u : dualwavelet }   \\tilde{\\psi}^{l , c_{25}}_l({{\\boldsymbol z}}^{-1 } )    & = \\frac{\\displaystyle c_{25 } \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2^{-1 } - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1^{-1 } - 1 ) \\right ] }           { \\displaystyle c_{25 } \\sum_{l'=0}^{l-1 } \\abs { \\cos\\left(\\frac{\\pi l'}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l'}{l}\\right)(z_1 - 1 ) } ^2 + \\abs{h({{\\boldsymbol z}})}^2 }   ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~    \\check{\\tilde \\psi}^{l , c_{25}}_l[{{\\boldsymbol k } } ] = - c_{25 } \\partial_l^- \\phi^{l , c_{25}}[{{\\boldsymbol k } } ]   \\ , ,   \\\\",
    "\\label{eq : vcpyramid : problem : frameelements : u : wavelet }   \\psi^l_l({{\\boldsymbol z } } ) & = \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2 - 1 ) + \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1 - 1 )   ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~   \\psi^l_l[{{\\boldsymbol k } } ] = \\partial_l^+ \\delta[{{\\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] given an impulse response of a blur operator @xmath178 , these frames satisfy the unity conditions as @xmath433 the definition of @xmath434 and @xmath435 ( for variable @xmath436 $ ] in ( [ eq : vcpyramid : problem : u : spatial ] ) ) are in ( [ eq : filterbanks : xithetatheta_tilde:1])-([eq : filterbanks : xithetatheta_tilde:3 ] ) which satisfy the unity condition ( [ eq : filterbanks : xithetatheta_tilde : unitycondition ] ) in the fourier domain . figure",
    "[ fig : mdcd_let : filterbanks : c0_1 ] and [ fig : mdcd_let : filterbanks : c10 ] depict the spectra of these frames in the fourier domain for different values of parameter @xmath437 and @xmath438 , respectively .    [ prop : vcpyramid : problem : v : spatial:1 ] a solution of the `` @xmath2-problem '' ( [ eq : problem : v ] ) can be rewritten as in equation ( [ eq : vcpyramid : problem : v : spatial:1 ] ) with two shrinkage operators due to @xmath209 and @xmath210 in a minimization problem ( [ eq : minimization : sdmcdd:2 ] ) .    from a solution of the `` @xmath136-problem '' ( [ eq : problem : g ] ) , we have @xmath439 - \\beta_7 \\partial_s^- \\partial_s^+ \\delta[{{\\boldsymbol k } } ]   \\\\   { { \\mathcal b}}_s^{(\\tau)}({{\\boldsymbol z } } ) & ~\\stackrel{{{\\mathcal f}}^{-1}}{\\longleftrightarrow}~   \\beta_6 \\big [ \\underbrace{{\\mathop{\\rm shrink}}\\big ( g_s^{(\\tau-1)}[{{\\boldsymbol k } } ] - \\frac{\\lambda_{6 s}^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_6 } \\,,~ \\frac{\\mu_1}{\\beta_6 } \\big)}_{= w_s^{(\\tau)}[{{\\boldsymbol k } } ] }    + \\frac{\\lambda_{6 s}^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_6 } \\big ]   \\\\ & \\qquad   -\\beta_7",
    "\\partial_s^+ \\big [ \\underbrace { v^{(\\tau-1)}[{{\\boldsymbol k } } ] - \\sum_{s'=[0 , s-1 ] \\backslash \\{s\\ } } \\partial_{s'}^- g_{s'}^{(\\tau-1)}[{{\\boldsymbol k } } ] } _ { = \\partial_s^- g_s^{(\\tau-1)}[{{\\boldsymbol k } } ] }   + \\frac{\\lambda_7^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_7 } \\big ]           \\end{aligned}\\ ] ] due to @xmath440 and by choosing @xmath215 , a solution of the @xmath136-problem ( at a direction @xmath132 ) is well defined in the fourier domain as @xmath441   + \\theta^{s , c_{67}}_s({{\\boldsymbol z } } ) \\big [ \\tilde \\theta^{s}_s({{\\boldsymbol z}}^{-1 } ) g_s^{(\\tau-1)}({{\\boldsymbol z } } ) + \\frac{\\lambda_7^{(\\tau-1)}({{\\boldsymbol z}})}{\\beta_7 } \\big ] \\ , .",
    "\\end{aligned}\\ ] ] its inverse fourier transform is @xmath442 & = \\xi^{s , c_{67}}_s[{{\\boldsymbol k } } ] \\ast \\big [ { \\mathop{\\rm shrink}}\\big ( g_s^{(\\tau-1)}[{{\\boldsymbol k } } ] - \\frac{\\lambda_{6 s}^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_6 } \\,,~ \\frac{\\mu_1}{\\beta_6 } \\big ) + \\frac{\\lambda_{6 s}^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_6 } \\big ]   + \\theta^{s , c_{67}}_s[{{\\boldsymbol k } } ] \\ast \\big [ \\check{\\tilde \\theta}^{s}_s[{{\\boldsymbol k } } ] \\ast g_s^{(\\tau-1)}[{{\\boldsymbol k } } ] + \\frac{\\lambda_7^{(\\tau-1)}[{{\\boldsymbol k}}]}{\\beta_7 } \\big ] \\ , .",
    "\\end{aligned}\\ ] ] definition of frames @xmath219 and @xmath220 are well defined in ( [ eq : filterbanks : xithetatheta_tilde:1:1])-([eq : filterbanks : xithetatheta_tilde : unitycondition:1 ] ) .",
    "and we finalize this proof by applying @xmath443 in equation ( [ eq : filterbanks : problem : g : spatial ] ) to a solution of the @xmath2-problem ( [ eq : problem : v ] ) .",
    "[ prop : dmcddmultiscalesamplingtheory : u - problem ] the discrete and continuous versions of the multiscale sampling theory for the `` @xmath1-problem '' are defined in ( [ label : multiscalesamp : discreteprojection : prop ] ) and ( [ label : multiscalesamp : continuousprojection : prop ] ) , respectively .    *",
    "proof for the discrete multiscale sampling theory ( [ label : multiscalesamp : discreteprojection : prop ] ) : *    in order to build a form of multiscale sampling version generated by a solution of the `` @xmath1-problem '' , for easy calculation we consider ( [ eq : vcpyramid : problem : u : spatial:1 ] ) without blur operator , i.e. @xmath444 , and simplify its notation by    * replacing @xmath445 ( due to a condition of a decomposition in ( [ eq : minimization : sdmcdd:1 ] ) ) * removing shrinkage operator , the lagrange multipliers @xmath446 and @xmath447 , * denoting @xmath448 .",
    "thus , we rewrite ( [ eq : vcpyramid : problem : u : spatial:1 ] ) as @xmath449 = \\big ( u^{(\\tau-1 ) } \\ast \\phi_\\text{int } \\big)[{{\\boldsymbol k } } ]      + \\sum_{l=0}^{l-1 } \\big ( u^{(\\tau-1 ) } \\ast \\check{\\tilde \\psi}_l \\ast \\psi_l \\big)[{{\\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] at a convergence , i.e. when iteration @xmath104 goes to infinity , we have @xmath450 and ( [ eq : multiscalesamp : noscale_blur ] ) is rewritten as @xmath451 = \\big ( u \\ast \\phi_\\text{int } \\big)[{{\\boldsymbol k } } ] + \\sum_{l=0}^{l-1 } \\big ( u \\ast \\check{\\tilde \\psi}_l \\ast \\psi_l \\big)[{{\\boldsymbol k } } ]    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    u({{\\boldsymbol z } } ) = u({{\\boldsymbol z } } ) \\phi_\\text{int}({{\\boldsymbol z } } ) + \\sum_{l=0}^{l-1 } u({{\\boldsymbol z } } ) \\tilde{\\psi}_l({{\\boldsymbol z}}^{-1 } ) \\psi_l({{\\boldsymbol z } } ) \\ , .",
    "\\end{aligned}\\ ] ] from ( [ eq : vcpyramid : problem : frameelements : u : scalingfunc:1])-([eq : vcpyramid : problem : frameelements : u : wavelet:1 ] ) without blur operator , i.e. @xmath189 , and definition of the impulse response of a discrete directional laplacian operator , the interpolant @xmath196 and directional primal / dual wavelet @xmath452 with @xmath453 are @xmath454 & = \\left [ c ( -\\delta_{\\text{d}l } ) + 1 \\right]^{-1 } \\delta[{{\\boldsymbol k } } ]   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\phi_\\text{int}({{\\boldsymbol z } } ) = \\frac{1}{\\displaystyle 1 + c \\sum_{l=0}^{l-1 } \\abs { \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2 - 1 ) } ^2 } \\ , ,   \\\\",
    "\\label{eq : filterbanks : xithetatheta_tilde : multiscalesamp:2 }   \\check{\\tilde \\psi}_l[{{\\boldsymbol k } } ] & = \\underbrace { - c \\big [ c ( -\\delta_{\\text{d}l } ) + 1 \\big]^{-1 } \\partial_l^- \\delta[{{\\boldsymbol k } } ] }                                   _ { \\displaystyle = -c \\partial_l^- \\phi_\\text{int}[{{\\boldsymbol k } } ] }   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\tilde \\psi_l({{\\boldsymbol z}}^{-1 } ) = \\frac{\\displaystyle c \\left [ \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1 } - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) \\right ] }                             { \\displaystyle 1 + c \\sum_{l=0}^{l-1 } \\abs { \\sin\\left(\\frac{\\pi l}{l}\\right)(z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right)(z_2 - 1 ) } ^2 } \\ , ,   \\\\",
    "\\label{eq : filterbanks : xithetatheta_tilde : multiscalesamp:3 }   \\psi_l[{{\\boldsymbol k } } ] & = \\partial^+_l \\delta[{{\\boldsymbol k } } ]    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\psi_l({{\\boldsymbol z } } ) = \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) \\,.\\end{aligned}\\ ] ] note that the directional mother dual / primal wavelet plays as an operator - like wavelet of interpolant as @xmath455 = c ( -\\delta_{\\text{d}l } ) \\phi_\\text{int}[{{\\boldsymbol k } } ]    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\psi({{\\boldsymbol z } } ) = \\sum_{l=0}^{l-1 } \\psi_l({{\\boldsymbol z } } ) \\tilde \\psi_l({{\\boldsymbol z}}^{-1})\\end{aligned}\\ ] ] and these frame elements satisfy a perfect reconstruction scheme , i.e. @xmath456 from ( [ eq : multiscalesamp : noscale ] ) , we defined a multiscale projection of a function @xmath457 to scaling space and its orthogonal wavelet space , i.e. @xmath458 with scale @xmath459 and direction @xmath23 as @xmath460 & = \\underbrace { \\sum_{{{\\boldsymbol n}}\\in \\mathbb z^2 } u[{{\\boldsymbol n } } ] \\phi[{{\\boldsymbol k}}- { { \\boldsymbol n } } ] } _ { = ( u \\ast \\phi)[{{\\boldsymbol k } } ] }   + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 }    \\underbrace { \\sum_{{{\\boldsymbol n}}\\in \\mathbb z^2 } \\big\\langle u , \\tilde \\psi_{il}[\\cdot - { { \\boldsymbol n } } ] \\big\\rangle_{\\ell_2 } \\psi_{il}[{{\\boldsymbol k}}- { { \\boldsymbol n } } ] }             _ { = ( u \\ast \\check { \\tilde{\\psi } } _ { il } \\ast \\psi_{il } ) [ { { \\boldsymbol k } } ] }   \\\\   \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~              u({{\\boldsymbol z } } ) & = u({{\\boldsymbol z } } ) \\phi({{\\boldsymbol z } } )   + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } u({{\\boldsymbol z } } ) \\tilde \\psi_{il}({{\\boldsymbol z}}^{-1 } ) \\psi_{il}({{\\boldsymbol z } } )     \\notag\\end{aligned}\\ ] ] where definition of frames on spaces @xmath461 and @xmath462 are defined in the fourier domain from ( [ eq : filterbanks : xithetatheta_tilde : multiscalesamp:1])-([eq : filterbanks : xithetatheta_tilde : multiscalesamp : unitycondition ] ) , as ( see figure [ fig : mdcd_let : u - g - problems](b ) for their spectra ) @xmath195    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\phi({{\\boldsymbol z } } ) = i^{-1 } \\sum_{i=0}^{i-1 } \\phi_\\text{int}({{\\boldsymbol z}}^{a^i } ) \\ , ,   \\\\   \\psi_{il}[{{\\boldsymbol k } } ]    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\psi_{il}({{\\boldsymbol z } } ) = i^{-\\frac{1}{2 } } \\psi_l({{\\boldsymbol z}}^{a^i } ) ~~ \\text{and }   \\\\   \\check{\\tilde \\psi}_{il}[{{\\boldsymbol k } } ]    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\tilde \\psi_{il}({{\\boldsymbol z}}^{-1 } ) = i^{-\\frac{1}{2 } } \\tilde \\psi_l({{\\boldsymbol z}}^{-a^i } ) \\,,\\end{aligned}\\ ] ] which satisfy the unity condition as @xmath463 given @xmath464 , wavelet coefficients in direction @xmath465 and scale @xmath384 is @xmath466 = \\big\\langle u \\ , , \\tilde \\psi_{il}[\\cdot - { { \\boldsymbol n } } ] \\big\\rangle_{\\ell_2 }    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   c_{il}({{\\boldsymbol z } } ) = u({{\\boldsymbol z } } ) \\tilde \\psi_{il}({{\\boldsymbol z}}^{-1 } ) \\,.\\end{aligned}\\ ] ]    * 2 .",
    "proof for the continuous multiscale sampling theory ( [ label : multiscalesamp : continuousprojection : prop ] ) : *    the impulse response of a continuous directional laplacian operator is @xmath467 ^ 2   \\end{aligned}\\ ] ] note that the 1st order maclaurin approximation is a link between a continuous and discrete version of the operator .",
    "similar to a discrete domain ( [ eq : filterbanks : xithetatheta_tilde : multiscalesamp:1])-([eq : filterbanks : xithetatheta_tilde : multiscalesamp : unitycondition ] ) , the continuous version of the interpolant @xmath196 and the directional dual / primal wavelet @xmath197 and @xmath205 ( with @xmath23 ) are @xmath468^{-1 } \\delta({{\\boldsymbol x } } )    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\phi}_\\text{int}({{\\boldsymbol \\omega } } ) = \\frac{1}{\\displaystyle 1 + c \\sum_{l=0}^{l-1 }",
    "\\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) \\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) \\omega_1 \\right]^2 } \\ , ,    \\\\    \\check{\\tilde \\psi}_l({{\\boldsymbol x } } ) & = -c \\partial_l \\phi_\\text{int}({{\\boldsymbol x } } )    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\tilde \\psi^*_l}({{\\boldsymbol \\omega } } ) = \\frac{\\displaystyle -c \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) j \\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) j \\omega_1 \\right ] }                              { \\displaystyle 1 + c \\sum_{l=0}^{l-1 } \\left [ \\cos\\left(\\frac{\\pi l}{l}\\right ) \\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) \\omega_1 \\right]^2 } \\ , ,    \\\\    \\psi_l({{\\boldsymbol x } } ) & = \\partial_l \\delta({{\\boldsymbol x } } )    ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    \\widehat{\\psi}_l({{\\boldsymbol \\omega } } ) = \\cos\\left(\\frac{\\pi l}{l}\\right ) j\\omega_2 + \\sin\\left(\\frac{\\pi l}{l}\\right ) j\\omega_1 \\ , .",
    "\\end{aligned}\\ ] ] similarly , this directional wavelet also plays as an operator - like wavelet of the interpolant @xcite as @xmath469 note that we have a pair of the continuous fourier transform as @xmath470 with a constant @xmath471 and @xmath36 .",
    "thus , definition of frames is ( see figure [ fig : mdcd_let : u - g - problems](a ) for their spectrum ) @xmath472 and they satisfy the unity condition @xmath473 a multiscale decomposition in a continuous setting for @xmath457 is @xmath474 & = \\underbrace { \\sum_{{{\\boldsymbol n}}\\in \\mathbb z^2 } u[{{\\boldsymbol n } } ] \\phi({{\\boldsymbol k}}- { { \\boldsymbol n } } ) } _ { = \\left ( u \\ast \\phi \\right)[{{\\boldsymbol k } } ] }    + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 }     \\underbrace { \\sum_{{{\\boldsymbol n}}\\in \\mathbb z^2 } \\left\\langle u \\ , , \\tilde \\psi_{il } ( \\cdot - { { \\boldsymbol n } } ) \\right\\rangle_{\\ell_2 } \\psi_{il}({{\\boldsymbol k}}- { { \\boldsymbol n } } ) } _ { = \\left ( u \\ast \\check{\\tilde \\psi}_{il } \\ast \\psi_{il } \\right)[{{\\boldsymbol k } } ] }    \\\\ \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    u(e^{j{{\\boldsymbol \\omega } } } ) & = u(e^{j{{\\boldsymbol \\omega } } } ) \\widehat{\\phi}({{\\boldsymbol \\omega } } ) + \\sum_{i=0}^{i-1 } \\sum_{l=0}^{l-1 } u(e^{j{{\\boldsymbol \\omega } } } ) \\widehat{\\tilde \\psi}_{il}^ * ( { { \\boldsymbol \\omega } } ) \\widehat{\\psi}_{il}({{\\boldsymbol \\omega } } ) \\ , .   \\end{aligned}\\ ] ]    [ prop : dmcddmultiscalesamplingtheory : g - problem ] the continuous and discrete versions of the multiscale sampling theory for the `` @xmath136-problem '' are defined in ( [ label : multiscalesamp : discreteprojection : gproblem : prop ] ) and ( [ label : multiscalesamp : continuousprojection : gproblem : prop ] ) .    * 1 .",
    "proof for the discrete multiscale sampling theory ( [ label : multiscalesamp : discreteprojection : gproblem : prop ] ) : *    to ease the calculation , we denote @xmath475 .",
    "given @xmath476 , a simplified version of ( [ eq : filterbanks : problem : g : spatial:1 ] ) in the @xmath136-problem is obtained by removing a shrinkage operator and lagrange multipliers @xmath477 as @xmath218 & = \\left ( \\xi_s \\ast g_s^{(\\tau-1 ) } \\right ) [ { { \\boldsymbol k } } ]   + \\left ( \\theta_s \\ast \\check{\\tilde \\theta}_s \\ast g_s^{(\\tau-1 ) } \\right ) [ { { \\boldsymbol k } } ] \\,.\\end{aligned}\\ ] ] denote @xmath478 and @xmath479 as discrete fourier transform of @xmath480 \\ , , \\theta_s[{{\\boldsymbol k}}]$ ] and @xmath481 $ ] , respectively . at convergence when the iteration @xmath104 goes to infinity , i.e. @xmath482 , we have @xmath483 & = \\left ( \\xi_s \\ast g_s \\right ) [ { { \\boldsymbol k } } ]   + \\left ( \\theta_s \\ast \\check{\\tilde \\theta}_s \\ast g_s \\right ) [ { { \\boldsymbol k } } ]   ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   g_s({{\\boldsymbol z } } ) = \\xi_s({{\\boldsymbol z } } ) g_s({{\\boldsymbol z } } ) + \\theta_s({{\\boldsymbol z } } ) \\tilde \\theta_s({{\\boldsymbol z}}^{-1 } ) g_s({{\\boldsymbol z } } ) \\end{aligned}\\ ] ] and the unity condition is @xmath484 given @xmath62 whose discrete fourier transform is @xmath202 , a multiscale sampling theory in the fourier domain is described as @xmath485 & = \\underbrace { \\sum_{\\boldsymbol n \\in \\mathbb z^2 } f[\\boldsymbol n ] \\xi[{{\\boldsymbol k}}- \\boldsymbol n ] } _ { = ( \\xi \\ast f)[{{\\boldsymbol k } } ] }   + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 }    \\underbrace {   \\sum_{\\boldsymbol n \\in \\mathbb z^2 } \\left\\langle { { \\mathbf f}}\\ , , \\tilde{\\theta}_{si}(\\cdot - \\boldsymbol n ) \\right\\rangle_{\\ell_2 }    \\theta_{si}[{{\\boldsymbol k}}- \\boldsymbol n ]   } _ { = ( \\check{\\tilde \\theta}_{si } \\ast \\theta_{si } \\ast f ) [ { { \\boldsymbol k } } ] } \\,,\\end{aligned}\\ ] ] where the frames ( see figure [ fig : mdcd_let : u - g - problems](d ) for their spectra ) @xmath223",
    "\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }   \\xi({{\\boldsymbol z } } ) = \\frac{1}{si } \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } \\xi_s({{\\boldsymbol z}}^{a^i } ) \\,,~   \\theta_{si}[{{\\boldsymbol k } } ] \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }   \\theta_{si}({{\\boldsymbol z } } ) = \\frac{1}{\\sqrt{si } } \\theta_s({{\\boldsymbol z}}^{a^i } )   \\text { and }   \\tilde\\theta_{si}[{{\\boldsymbol k } } ] \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow }   \\tilde\\theta_{si}({{\\boldsymbol z } } ) = \\frac{1}{\\sqrt{si } } \\tilde\\theta_s({{\\boldsymbol z}}^{a^i } ) \\,.\\end{aligned}\\ ] ] satisfy the unity condition @xmath226 and @xmath224 and @xmath225 are defined in ( [ eq : filterbanks : xithetatheta_tilde:1:1])-([eq : filterbanks : xithetatheta_tilde:3:1 ] ) .    *",
    "proof for the continuous multiscale sampling theory ( [ label : multiscalesamp : continuousprojection : gproblem : prop ] ) : *    similar to the @xmath1-problem and by some simplified notations as in the previous explanation , we derive a continuous version for multiscale sampling theory in the @xmath136-problem by considering continuous operators in ( [ eq : filterbanks : xithetatheta_tilde:1:1])-([eq : filterbanks : xithetatheta_tilde:3:1 ] ) as @xmath486^{-1 } \\delta({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     \\widehat{\\xi_s}({{\\boldsymbol \\omega } } ) = \\frac { 1 } { 1 + c \\left [ \\cos \\left ( \\frac{\\pi s}{s } \\right ) \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) \\omega_1 \\right]^2 }   \\ , ,   \\\\   \\theta_s({{\\boldsymbol x } } ) = -c \\partial_s \\xi_s({{\\boldsymbol x } } )    & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~     \\widehat{\\theta_s}({{\\boldsymbol \\omega } } ) =    \\frac { -c \\left [ \\cos\\left(\\frac{\\pi s}{s}\\right ) j \\omega_2 + \\sin\\left(\\frac{\\pi",
    "s}{s}\\right ) j \\omega_1 \\right ] }          { 1 + c \\left [ \\cos \\left ( \\frac{\\pi s}{s }",
    "\\right ) \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) \\omega_1 \\right]^2 } \\ , ,   \\\\",
    "\\check{\\tilde \\theta}_s({{\\boldsymbol x } } ) = \\partial_s \\delta({{\\boldsymbol x } } )   & ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   \\widehat{\\tilde \\theta_s^*}({{\\boldsymbol \\omega } } ) = \\cos \\left ( \\frac{\\pi s}{s } \\right ) j \\omega_2 + \\sin \\left ( \\frac{\\pi s}{s } \\right ) j \\omega_1 \\,.\\end{aligned}\\ ] ] these bounded frames satisfy the unity condition in the fourier domain as ( @xmath487 ) @xmath488 given a constant @xmath221 and a discrete function @xmath489 whose discrete fourier transform is @xmath201 , a multiscale sampling theory in the continuous setting is defined as @xmath490 thus , we reformulate the above formulae as @xmath66 & = \\underbrace { \\sum_{{{\\boldsymbol n}}\\in \\mathbb z^2 } f[{{\\boldsymbol n } } ] \\xi({{\\boldsymbol k}}- { { \\boldsymbol n } } ) } _ { = ( f \\ast \\xi)[{{\\boldsymbol k } } ] }   + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 }    \\underbrace {   \\sum_{{{\\boldsymbol n}}\\in",
    "\\mathbb z^2 }   \\left\\langle f \\ , , \\tilde \\theta_{si}(\\cdot - { { \\boldsymbol n } } ) \\right\\rangle_{\\ell_2 } \\theta_{si}({{\\boldsymbol k}}- { { \\boldsymbol n } } )    } _ { = ( f \\ast \\check{\\tilde \\theta}_{si } \\ast \\theta_{si})[{{\\boldsymbol k } } ] } \\ , .   \\\\",
    "\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~   f(e^{j{{\\boldsymbol \\omega } } } ) & = f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat \\xi({{\\boldsymbol \\omega } } ) + \\sum_{i=0}^{i-1 } \\sum_{s=0}^{s-1 } f(e^{j{{\\boldsymbol \\omega } } } ) \\widehat{\\tilde \\theta}_{si}^*({{\\boldsymbol \\omega } } ) \\widehat{\\theta}_{si}({{\\boldsymbol \\omega } } ) \\end{aligned}\\ ] ] with frames ( see figure [ fig : mdcd_let : u - g - problems](c ) for their spectra ) @xmath491 note that these multiscale frames are also bounded and satisfy the unity condition in the fourier domain as @xmath492",
    "[ alg : dmcdd:1 ]"
  ],
  "abstract_text": [
    "<S> approximation theory plays an important role in image processing , especially image deconvolution and decomposition . for piecewise </S>",
    "<S> smooth images , there are many methods that have been developed over the past thirty years . </S>",
    "<S> the goal of this study is to devise similar and practical methodology for handling textured images . </S>",
    "<S> this problem is motivated by forensic imaging , since fingerprints , shoeprints and bullet ballistic evidence are textured images . in particular , it is known that texture information is almost destroyed by a blur operator , such as a blurred ballistic image captured from a low - cost microscope . </S>",
    "<S> the contribution of this work is twofold : first , we propose a mathematical model for textured image deconvolution and decomposition into four meaningful components , using a high - order partial differential equation approach based on the directional mean curvature . </S>",
    "<S> second , we uncover a link between functional analysis and multiscale sampling theory , e.g. , harmonic analysis and filter banks . both theoretical results and examples with natural images </S>",
    "<S> are provided to illustrate the performance of the proposed model . </S>"
  ]
}