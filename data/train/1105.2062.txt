{
  "article_text": [
    "what is the performance of a collection of @xmath3 subtractively - dithered uniform scalar quantizers with the same step size , used in parallel ?",
    "the essence of this question  and a precise analysis under high - resolution assumptions  is captured by answering another fundamental question : what is the mean - squared error ( mse ) performance of a @xmath3-cell quantizer with randomly - placed thresholds applied to a uniformly - distributed source ?",
    "for both ( equivalent ) questions , it is not obvious _ a  priori _ that the performance penalties relative to optimal deterministic designs are bounded ; here we find concise answers that demonstrate that these performance penalties are small .",
    "specifically , the multiplicative penalty in mse for quantization of a uniform source is at most @xmath4 in the codebook - constrained case and about @xmath2 in the entropy - constrained case at high rate , where @xmath1 is the euler  mascheroni constant  @xcite .",
    "the translation of these results is that the multiplicative penalty in mse for high - rate parallel dithered quantization is at most @xmath4 when there is no expoitation of statistical dependencies between channels and about @xmath5 when joint entropy coding or slepian  wolf coding  @xcite is employed and the number of channels is large .",
    "quantization with parallel channels is illustrated in fig .",
    "[ fig : parallelquantizers ] .",
    "each of @xmath3 quantizers is a subtractively - dithered uniform scalar quantizer with step size @xmath6 . denoting the dither , or _",
    "offset _ , of quantizer @xmath7 by @xmath8 , the thresholds of the quantizer are @xmath9 .",
    "one may imagine several stylized applications in which it is advantageous to allow the @xmath8s to be arbitrary or chosen uniformly at random .",
    "for example , with parallel quantizer channels , one may turn channels on and off adaptively based on available power or the desired signal fidelity  @xcite .",
    "alteration of the lossless coding block could then be achieved through a variety of means  @xcite .",
    "the same figure could represent a distributed setting , in which @xmath3 sensors measure highly - correlated quantities ( all modeled as @xmath10 ) ; with a slepian  wolf code  @xcite or universal slepian  wolf code  @xcite , the sensors can quantize and encode their samples autonomously .",
    "variations in the @xmath8s could also arise unintentionally , through process variation in sensor manufacturing due to cost reduction or size reduction ; mitigation of process variations is expected to be of increasing importance  @xcite .",
    "this letter addresses the performance loss relative to deterministic joint design of the channels or coordinated action by the distributed sensors .",
    "( -2.5,-1)(8.5,4.5 ) ( -2.5,4.0)@xmath10    ( -2.0,4.0)(0.0,4.0 ) ( 0,3.5)(3,4.5 ) ( 1.5,4.0)@xmath11 ( 3.0,4.0)(4.5,4.0 ) ( 3.75,4.3)@xmath12    ( -1.5,4.0)(-1.5,2.5 ) ( -1.5,2.5)(0.0,2.5 ) ( 0,2)(3,3 ) ( 1.5,2.5)@xmath13 ( 3.0,2.5)(4.5,2.5 ) ( 3.75,2.8)@xmath14    ( 1.5,1.0)@xmath15    ( -1.5,2.5)(-1.5,1.0 ) ( -1.5,1.0)(-1.5,-0.5 ) ( -1.5,-0.5)(0.0,-0.5 ) ( 0,-1)(3,0 ) ( 1.5,-0.5)@xmath16 ( 3.0,-0.5)(4.5,-0.5 ) ( 3.75,-0.2)@xmath17    ( 4.5,-1)(7.5,4.5 ) ( 6.0,2.05)entropy ( 6.0,1.45)coding ( 7.5,1.75)(8.5,1.75 )    collectively , the @xmath3 parallel quantizers specify input @xmath10 with thresholds @xmath18",
    ". one would expect the best performance from having @xmath19 uniformly spaced in @xmath20 $ ] through @xmath21 ; this intuition is verified under high - resolution assumptions , where the optimal entropy - constrained quantizers are uniform  @xcite . to analyze performance relative to this ideal",
    ", it suffices to study one interval of length @xmath6 in the domain of the quantizers because the thresholds repeat with a period of @xmath6 .",
    "this analysis is completed in section  [ sec : basic ] .",
    "the ramifications for the system in fig .",
    "[ fig : parallelquantizers ] are made explicit in section  [ sec : ditheredquantizers ] .",
    "section  [ sec : twounequal ] considers uniform quantizers with unequal step sizes , and section  [ sec : discussion ] provides additional connections to related results and concludes the note .",
    "let @xmath10 be uniformly distributed on @xmath22 .",
    "suppose that a @xmath3-level quantizer for @xmath10 is designed by choosing @xmath23 thresholds independently , each with a uniform distribution on @xmath22 .",
    "put in ascending order , the random thresholds are denoted @xmath24 , and for notational convenience , let @xmath25 and @xmath26 .",
    "a regular quantizer with these thresholds has lossy encoder @xmath27 given by @xmath28 the optimal reproduction decoder for mse distortion is @xmath29 given by @xmath30 we are interested in the average rate and distortion of this random quantizer as a function of @xmath3 , both with and without entropy coding .",
    "[ thm : basicd ] the mse distortion , averaging over both the source variable @xmath10 and the quantizer thresholds @xmath24 , is @xmath31 }      \\ = \\ \\frac{1}{2(k+1)(k+2)}.\\ ] ]    let @xmath32 denote the length of the quantizer partition cell that contains @xmath33 when the random thresholds are @xmath34 ; i.e. , @xmath35 since @xmath10 is uniformly distributed and the thresholds are independent of @xmath10 , the quantization error is conditionally uniformly distributed for any values of the thresholds . thus the conditional mse given the thresholds is @xmath36}/12 $ ] , and averaging over the thresholds as well gives @xmath37}/12 $ ] .",
    "the possible values of the interval length , @xmath38 , are called _ spacings _ in the order statistics literature  ( * ? ? ?",
    "6.4 ) . with a uniform parent distribution ,",
    "the spacings are identically distributed .",
    "thus they have the distribution of the minimum , @xmath39 : @xmath40 the density of @xmath41 is obtained from the density of @xmath39 by noting that the probability that @xmath10 falls in an interval is proportional to the length of the interval : @xmath42 for @xmath43 .",
    "now d & = & * e *  =   _ 0 ^ 1 ^2 k(k-1 ) ( 1-)^k-2 d + & = & , completing the proof .",
    "an alternative proof is outlined in the appendix .    the natural comparison for ( [ eq : theorem - d ] ) is against an optimal @xmath3-level quantizer for the uniform source .",
    "the optimal quantizer has evenly - spaced thresholds , resulting in partition cells of length @xmath44 and thus mse distortion of @xmath45 .",
    "asymptotically in @xmath3 , distortion ( [ eq : theorem - d ] ) is worse by a factor of @xmath46 , which is at most @xmath4 and approaches @xmath4 as @xmath47 . in other words , designing a _ codebook - constrained _ or _ fixed - rate _ quantizer by choosing the thresholds at random creates a multiplicative distortion penalty of at most 6 .",
    "now consider the _ entropy - constrained _ or _",
    "variable - rate _ case .",
    "if an entropy code for the indexes is designed without knowing the realization of the thresholds , the rate remains @xmath48 bits per sample .",
    "however , conditioned on knowing the thresholds , the quantizer index @xmath49 is not uniformly distributed , so the performance penalty can be reduced .",
    "[ thm : basicr ] the expected quantizer index conditional entropy , averaging over the quantizer thresholds @xmath24 , is @xmath50 }      \\ = \\ \\frac{1}{\\ln 2 } \\sum_{k=2}^k \\frac{1}{k}.\\ ] ]    the desired expected conditional entropy is the expectation of the self - information , @xmath51 .",
    "let @xmath41 be defined as in the proof of theorem  [ thm : basicd ] to be the length of the interval containing @xmath10 .",
    "since the probability of @xmath10 falling into any subinterval of @xmath22 of length @xmath52 is @xmath52 , we have r & = & * e * + & = & - _ 0 ^ 1 ( _ 2 ) k(k-1 ) ( 1-)^k-2 d , which equals ( [ eq : theorem - r ] ) by direct calculation ; see also  @xcite , ( * ? ? ?",
    "* @xmath534.6 ) .",
    "an alternative proof is outlined in the appendix .    to compare again against an optimal @xmath3-level quantizer , note that evenly - spaced thresholds would yield @xmath54 while the rate in ( [ eq : theorem - r ] ) is also essentially logarithmic in @xmath3 .",
    "the quantity ( [ eq : theorem - r ] ) includes the _ harmonic number _",
    "@xmath55 , which has been studied extensively .",
    "for example , @xmath56 where @xmath57 is called the euler  mascheroni constant  @xcite .    combining ( [ eq : theorem - d ] ) and ( [ eq : theorem - r ] ) while exploiting the asymptotic approximation @xmath58 yields @xmath59 and a distortion  rate performance of @xmath60 where @xmath61 represents a ratio approaching 1 as @xmath3 increases for distortions and difference approaching 0 as @xmath3 increases for rates . the exact performance from ( [ eq : theorem - d])([eq : theorem - r ] ) is shown in fig .  [ fig : randomquanttheory ] with normalization through division by @xmath62 .",
    "let us now return to the system depicted in fig .",
    "[ fig : parallelquantizers ] . high - resolution analysis of this system for any number of channels @xmath3 follows easily from the results of the previous section .",
    "[ bl][bl]@xmath5    for notational convenience , let us assume that the source @xmath10 has a continuous density supported on @xmath22 .",
    "fix @xmath63 and consider @xmath3 uniform quantizers with step size @xmath6 applied to @xmath10 .",
    "quantizer @xmath11 has lossy encoder @xmath64 with thresholds at integer multiples of @xmath6 .",
    "the remaining @xmath23 quantizers are offset by @xmath65 , i.e. , the thresholds of quantizer @xmath7 with lossy encoder @xmath66 are at @xmath67 .",
    "we would like to first approximate the distortion in joint reconstruction from @xmath68 . the first quantizer index @xmath69 isolates @xmath10 to an interval @xmath70 of length @xmath6 .",
    "since @xmath10 has a continuous density and @xmath63 , we may approximate @xmath10 as conditionally uniformly distributed on this interval . thus we may apply theorem  [ thm : basicd ] to obtain @xmath71 where @xmath61 represents a ratio approaching 1 as @xmath72 .",
    "the average of the joint entropy is increased from ( [ eq : theorem - r ] ) by precisely @xmath73 . since @xmath74 where @xmath75 is the differential entropy of @xmath10  @xcite , @xmath76 where @xmath61 represents a difference approaching 0 as @xmath72 . for a large number of channels @xmath3 ,",
    "eliminating @xmath6 gives @xmath77 where ( a ) is exact as @xmath72 , ( b ) is the standard approximation for harmonic numbers , and ( c ) is an approximation for large @xmath3 .",
    "this distortion exceeds the distortion of optimal entropy - constrained quantization by the factor @xmath5 .",
    "the methodology introduced here can be extended to cases with unequal quantizer step sizes .",
    "the details become quickly more complicated as the number of distinct step sizes is increased , so we consider only two step sizes .",
    "we also limit attention to source @xmath10 uniformly distributed on @xmath22 .",
    "let quantizer @xmath64 be a uniform quantizer with step size @xmath78 and thresholds at integer multiples of @xmath79 ( no offset ) .",
    "let @xmath80 be a uniform quantizer with step size @xmath81 and thresholds offset by @xmath39 , where @xmath39 is uniformly distributed on @xmath82 . without loss of generality , assume @xmath83 .",
    "( it does not matter which quantizer is fixed to have no offset ; it only simplifies notation . )    mimicking the analysis in section  [ sec : basic ] , the performance of this pair of quantizers is characterized by the p.d.f .  of the length of the partition cell into which",
    "@xmath10 falls .",
    "furthermore , because of the random dither @xmath39 , the partition cell lengths are identically distributed .",
    "let @xmath84 be the length of the partition cell with left edge at @xmath85 .",
    "clearly @xmath84 is related to @xmath39 by [ eq : twounequalm ] m  =  \\ {    ll a_1 , & ; + _ 0 , & .    .",
    "so @xmath84 is a mixed random variable with ( generalized ) p.d.f.@xmath86.\\ ] ] with @xmath41 defined ( as before ) as the length of the partition cell that contains @xmath10 , f_l ( ) & = & + & = & + ( -_0 ) , for @xmath87 .",
    "the average distortion is given by @xmath88 }      \\ = \\",
    "\\frac{\\delta_0 ^ 2}{12 } \\ , \\cdot \\ ,              \\frac{\\delta_1 - \\frac{3}{4}\\delta_0}{\\delta_1 - \\half\\delta_0}.\\ ] ] this expression reduces to ( [ eq : ditheredequal - d ] ) ( with @xmath89 ) for @xmath90 .",
    "also , it approaches @xmath91 as @xmath92 consistent with the second quantizer providing no information .",
    "the average rate is @xmath93 }                                                      \\ = \\",
    "\\log_2 \\delta_0^{-1 }             + \\frac{1}{2\\ln2 } \\ , \\frac{\\delta_0}{2\\delta_1 - \\delta_0}.\\ ] ] this reduces to ( [ eq : ditheredequal - r ] ) ( with @xmath89 and @xmath94 ) for @xmath90 .",
    "one way in which unequal quantization step sizes could arise is through the quantization of a frame expansion  @xcite .",
    "suppose the scalar source @xmath10 is encoded by dithered uniform scalar quantization of @xmath95 with step size @xmath63 for each component of @xmath96 .",
    "this is equivalent to using quantizers with step sizes @xmath97 directly on @xmath10 .",
    "fixing @xmath98 so that @xmath83 , we can express the distortion ( [ eq : d - twoquantizers ] ) as @xmath99 and the rate ( [ eq : r - twoquantizers ] ) as @xmath100    the quotient [ eq : qtheta ] q _",
    "=   =   ( ) can be interpreted as the multiplicative distortion penalty as compared to using a single uniform quantizer .",
    "this is bounded above by @xmath101 which is consistent with evaluating ( [ eq : ditheredequal_a ] ) at @xmath89 .",
    "thus , joint entropy coding of the quantized components largely compensates for the ( generally disadvantageous ) expansion of @xmath10 into a higher - dimensional space before quantization ; the penalty is only an @xmath102 distortion factor or @xmath103 bits .",
    "this note has derived distortion  rate performance for certain randomly - generated quantizers",
    ". the thresholds ( analogous to offsets in a dithered quantizer ) are chosen according to a uniform distribution .",
    "the technique can be readily extended to other quantizer threshold distributions ; however , the uniform distribution is motivated by the asymptotic optimality of uniform thresholds in entropy - constrained quantization .    the analysis in section  [ sec : ditheredquantizers ] puts significant burden on the entropy coder to remove the redundancies in the quantizer outputs @xmath104 .",
    "this is similar in spirit to the universal coding scheme of ziv  @xcite , which employs a dithered uniform scalar quantizer along with an ideal entropy coder to always perform within 0.754 bits per sample of the rate ",
    "distortion bound . in the case that the quantizers are distributed , we are analyzing the common strategy for wyner ",
    "ziv coding  @xcite of quantizing followed by slepian  wolf coding ; we obtain a concrete rate loss upper bound of @xmath105 bits per sample when the rate is high ; this is approached when the number of encoders is large . with non - subtractive dither , the randomization of thresholds is unchanged but the reproduction points are not matched to the thresholds .",
    "thus , the rate computation is unchanged but distortions are increased .",
    "use of analog - to - digital converter channels with differing quantization step sizes was studied in  @xcite . unlike the present note",
    ", this work exploits correlation of a wide - sense stationary input ; however , it is limited by a simple quantization noise model and estimation by linear , time - invariant ( lti ) filtering .    exact mse analysis of quantized overcomplete expansions has proven difficult , so many papers have focused on only the scaling of distortion with the redundancy of the frame  @xcite .",
    "the example in section  [ sec : twounequal ] , could be extendable to more general frame expansions .",
    "the proofs of theorems  [ thm : basicd ] and  [ thm : basicr ] are indirect in that they introduce the random variable @xmath41 for the length of the partition cell containing @xmath10 . a more direct proof is outlined here .    for fixed thresholds @xmath24 , @xmath106 }     \\ = \\",
    "\\sum_{k=1}^k \\frac{1}{12}\\left ( a_k - a_{k-1 } \\right)^3,\\ ] ] @xmath107    the quantizer maps interval @xmath108 to @xmath109 so @xmath110 the entropy expression is thus immediate .",
    "the distortion expression follows by expanding the expectation using the law of total expectation with conditioning on @xmath49 :     + & = & _ k=1^k _ ( a_k - a_k-1)^2 + & & _ ( a_k - a_k-1 ) .",
    "+    the theorems are proved by averaging over the joint distribution of the quantizer thresholds @xmath111 , which is uniform over the simplex @xmath112 .",
    "the author is thankful to john sun , lav varshney , and an anonymous reviewer for helpful suggestions .",
    "n.  t. thao and m.  vetterli , `` deterministic analysis of oversampled a / d conversion and decoding improvement based on consistent estimates , '' _ ieee trans .",
    "signal process .",
    "_ , vol .",
    "42 , no .  3 , pp . 519531 , mar ."
  ],
  "abstract_text": [
    "<S> the distortion  rate performance of certain randomly - designed scalar quantizers is determined . </S>",
    "<S> the central results are the mean - squared error distortion and output entropy for quantizing a uniform random variable with thresholds drawn independently from a uniform distribution . </S>",
    "<S> the distortion is at most 6 times that of an optimal ( deterministically - designed ) quantizer , and for a large number of levels the output entropy is reduced by approximately @xmath0 bits , where @xmath1 is the euler  mascheroni constant . </S>",
    "<S> this shows that the high - rate asymptotic distortion of these quantizers in an entropy - constrained context is worse than the optimal quantizer by at most a factor of @xmath2 .    </S>",
    "<S> euler  mascheroni constant , harmonic number , high - resolution analysis , quantization , slepian  wolf coding , subtractive dither , uniform quantization , wyner </S>",
    "<S>  ziv coding . </S>"
  ]
}