{
  "article_text": [
    "cuba is a library for multidimensional numerical integration written in c99 with interfaces for fortran , c / c++ , and mathematica .",
    "cuba offers a choice of four independent routines for multidimensional numerical integration , vegas , suave , divonne , and cuhre , with very different characteristics @xcite .",
    "numerical integration is perfectly suited for parallel execution , which can significantly speed up the computation as it generally incurs only a very small overhead .",
    "several features for concurrent sampling were added in cuba versions 3 and 4 , for both parallelization and vectorization .",
    "the objective was to make parallel use of cuba very easy , ideally automatic , and led to the following design decisions :    \\1 .",
    "no kind of message passing interface is used , as that requires extra software to be installed .",
    "that is , the parallelization is restricted to one computer , using operating - system functions only . a standard setup these days is a single cpu with a number of cores , say 4 or 8 . utilizing many more compute nodes , as one could potentially do with mpi , is more of a theoretical option anyway since",
    "the speed - ups can not be expected to grow linearly , see sect .",
    "[ sect : perf ] on performance .",
    "cuba uses @xmath0/@xmath1 rather than the @xmath2 functions .",
    "the latter are slightly more efficient because parent and child share their memory space , but for the same reason they also require a reentrant integrand function , and the programmer may not have control over reentrancy in all languages ( e.g.  fortran s i / o is typically non - reentrant )",
    ". @xmath0 on the other hand creates a completely independent copy of the running process and thus works for any integrand function .",
    "\\3 . changing the number of cores to use should not require a re - compile , in particular as the program image should be able to run on several computers ( with possibly different numbers of cores ) simultaneously .",
    "this is solved through an environment variable @xmath3 , which defaults to the number of idle cores on the present system .",
    "the present note describes the concurrent features of cuba 4 and discusses their performance . for installation and usage details",
    "not related to parallelization , the user is referred to the cuba manual .",
    "cuba uses a master  worker model .",
    "the master process orchestrates the parallelization but does not count towards the number of cores , e.g.   @xmath4 means four workers and one master . very importantly",
    ", the samples are generated by the master process only and distributed to the workers , such that random numbers are never used more than once .",
    "the parallelization of cuba naturally focusses on the main sampling routine @xmath5 , called by all cuba integrators , which has been abstracted since the very first cuba version simply because it is implemented very differently in fortran / c / c++ and in mathematica .",
    "@xmath5 in principle parallelizes straightforwardly on @xmath6 cores :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ serial version : = sample @xmath7 points . + parallel version : sample @xmath8 points on core 1 , + @xmath9 + sample @xmath8 points on core @xmath6 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the actual distribution strategy is somewhat more involved and is described in sect .",
    "[ sect : cores ] .",
    "one appealing aspect of the parallelization through @xmath5 is that changes are made at a conceptually ` low ' level of the integration , i.e.  parallelization can be dealt with without modifying the integration algorithm itself .",
    "the speed - ups achieved with divonne by parallelizing @xmath5 alone were generally unsatisfactory and significantly below those of the other integrators , e.g.  @xmath10 1.5 on four cores .",
    "the divonne algorithm works in three phases :    * partitioning phase : split the integration region into subregions with approximately equal spread , defined as @xmath11 where the minimum and maximum of the integrand @xmath12 are sought using methods from numerical optimization . *",
    "sampling phase : sample the subregions independently with the same number of points each .",
    "that number is extrapolated from the results of the partitioning phase .",
    "* refinement phase : further subdivide or sample again if results from the partitioning and sampling phase do not agree within their estimated errors .",
    "it turned out that the partitioning phase was crucial for attaining reasonable speed - ups and needed special treatment : firstly , the original partitioning algorithm divided the regions recursively ( and with a minimum recursion depth , too ) and had to be ` un - recursed ' , mainly by better bookkeeping of the subregions .    secondly , the partitioning phase was modified such that each core receives an entire region to subdivide , not just a list of points ( as @xmath5 does ) . in particular the minimum / maximum search , during which only one point at a time is sampled ,",
    "is distributed much more efficiently this way .",
    "the other two phases were not so critical precisely because they sample more points per region .    by moving the parallelization one level ` up ' as it were ,",
    "i.e.  no longer at the ` lowest ' ( sampling ) level of the integration , the genuine divonne algorithm becomes more entwined with the parallelization , of course , and also the master ",
    "worker communication becomes more complex .",
    "the parallelization procedure is rather different in fortran / c / c++ and in mathematica .",
    "we shall deal with the latter first because it needs only a short explanation .",
    "the remainder of this chapter is then devoted to the fortran / c / c++ case .",
    "the mathematica version of cuba performs its sampling through a function @xmath13 . by default this",
    "is identical to @xmath14 , i.e.  the serial version , so to parallelize one merely needs to redefine @xmath15 ( after loading cuba ) .",
    "if the integrand depends on user - defined symbols or functions , their definitions must be distributed to the workers beforehand using @xmath16 and likewise required packages must be loaded with @xmath17 instead of @xmath18 ; this is explained in detail in the mathematica manual .      in fortran and c / c++ the cuba library can ( and usually does ) automatically parallelize the sampling of the integrand .",
    "it parallelizes through @xmath0 and @xmath1 which , though slightly less performant than pthreads , do not require reentrant code .",
    "( reentrancy may not even be under full control of the programmer , for example fortran s i / o is usually non - reentrant . )",
    "worker processes are started and shut down only as few times as possible , however , so the performance penalty is really quite minor even for non - native fork implementations such as cygwin s .",
    "parallelization is not available on native windows for lack of the @xmath0 function .",
    "the communication of samples to and from the workers happens through ipc shared memory ( @xmath19 and colleagues ) , or if that is not available , through a @xmath20 ( two - way pipe ) .",
    "remarkably , the former s anticipated performance advantage turned out to be hardly perceptible .",
    "possibly there are cache - coherence issues introduced by several workers writing simultaneously to the same shared - memory area .      for reference ,",
    "the prototypes of the integrators in cuba 4 are repeated here ; their detailed description is left to the cuba manual .",
    "only the underlined arguments are relevant for the following discussion .",
    "`  subroutine  vegas(ndim ,  ncomp ,  integrand ,  userdata ,  , ` + `  epsrel ,  epsabs ,  flags ,  seed ,  mineval ,  maxeval , ` + `  nstart ,  nincrease ,  nbatch ,  gridno ,  statefile ,  , ` + `  neval ,  fail ,  integral ,  error ,  prob ) `    `  subroutine  suave(ndim ,  ncomp ,  integrand ,  userdata ,  , ` + `  epsrel ,  epsabs ,  flags ,  seed ,  mineval ,  maxeval , ` + `  nnew ,  flatness ,  statefile ,  , ` + `  nregions ,  neval ,  fail ,  integral ,  error ,  prob ) `    `  subroutine  divonne(ndim ,  ncomp ,  integrand ,  userdata ,  , ` + `  epsrel ,  epsabs ,  flags ,  seed ,  mineval ,  maxeval , ` + `  key1 ,  key2 ,  key3 ,  maxpass , ` + `  border ,  maxchisq ,  mindeviation , ` + `  ngiven ,  ldxgiven ,  xgiven ,  nextra ,  peakfinder , ` + `  statefile ,  , ` + `  nregions ,  neval ,  fail ,  integral ,  error ,  prob ) `    `  subroutine  cuhre(ndim ,  ncomp ,  integrand ,  userdata ,  , ` + `  epsrel ,  epsabs ,  flags ,  mineval ,  maxeval , ` + `  key ,  statefile ,  , ` + `  nregions ,  neval ,  fail ,  integral ,  error ,  prob ) `    the external function which computes the integrand is expected to be declared as    `  integer  function  integrand(ndim ,  x ,  ncomp ,  f ,  userdata ,  ,  ,  ... ) ` + `  integer  ndim ,  ncomp ,  nvec ,  core ` + `  double  precision  x(ndim , nvec ) ,  f(ncomp , nvec ) `    the integrand receives @xmath21 @xmath22-dimensional samples in @xmath23 and is supposed to fill the array @xmath24 with the corresponding @xmath25-component integrand values .",
    "the return value is irrelevant unless it is @xmath26 , in the case of which the integration will be aborted immediately .",
    "note that @xmath21 indicates the actual number of points passed to the integrand here and may be smaller than the @xmath21 given to the integrator .",
    "the dots represent optional arguments provided by vegas , suave , and divonne ( see manual ) .",
    "also @xmath27 , @xmath21 , and @xmath28 are optional and may be omitted if unused , i.e.  as in former cuba versions the integrand may minimally be declared ( for @xmath29 ) as    ....    integer function integrand(ndim , x , ncomp , f )    integer ndim , ncomp    double precision x(ndim ) , f(ncomp ) ....      the c / c++ prototypes are contained in @xmath30 .",
    "they are reproduced here for reference .",
    "again , only the underlined arguments are relevant for the present discussion",
    ".    .... typedef int ( * integrand_t)(const int * ndim , const double x [ ] ,    const int * ncomp , double f [ ] , void * userdata ) ;    typedef void ( * peakfinder_t)(const int * ndim , const double b [ ] ,    int * n , double x [ ] ) ; ....    ` void  vegas(const  int  ndim ,  const  int  ncomp , ` + `  integrand_t  integrand ,  void  userdata ,  , ` + `  const  double  epsrel ,  const  double  epsabs , ` + `  const  int  flags ,  const  int  seed , ` + `  const  int  mineval ,  const  int  maxeval , ` + `  const  int  nstart ,  const  int  nincrease ,  const  int  nbatch , ` + `  const  int  gridno ,  const  char  statefile ,  , ` + `  int  neval ,  int  fail , ` + `  double  integral [ ] ,  double  error [ ] ,  double  prob [ ] ) `    ` void  suave(const  int  ndim ,  const  int  ncomp , ` + `  integrand_t  integrand ,  void  userdata ,  , ` + `  const  double  epsrel ,  const  double  epsabs , ` + `  const  int  flags ,  const  int  seed , ` + `  const  int  mineval ,  const  int  maxeval , ` + `  const  int  nnew ,  const  double  flatness , ` + `  const  char  statefile ,  , ` + `  int  nregions ,  int  neval ,  int  fail , ` + `  double  integral [ ] ,  double  error [ ] ,  double  prob [ ] ) `    ` void  divonne(const  int  ndim ,  const  int  ncomp , ` + `  integrand_t  integrand ,  void  userdata ,  , ` + `  const  double  epsrel ,  const  double  epsabs , ` + `  const  int  flags ,  const  int  seed , ` + `  const  int  mineval ,  const  int  maxeval , ` + `  const  int  key1 ,  const  int  key2 ,  const  int  key3 , ` + `  const  int  maxpass ,  const  double  border , ` + `  const  double  maxchisq ,  const  double  mindeviation , ` + `  const  int  ngiven ,  const  int  ldxgiven ,  double  xgiven [ ] , ` + `  const  int  nextra ,  peakfinder_t  peakfinder , ` + `  const  char  statefile ,  , ` + `  int  nregions ,  int  neval ,  int  fail , ` + `  double  integral [ ] ,  double  error [ ] ,  double  prob [ ] ) `    ` void  cuhre(const  int  ndim ,  const  int  ncomp , ` + `  integrand_t  integrand ,  void  userdata ,  , ` + `  const  double  epsrel ,  const  double  epsabs , ` + `  const  int  flags , ` + `  const  int  mineval ,  const  int  maxeval , ` + `  const  int  key ,  const  char  statefile ,  , ` + `  int  nregions ,  int  neval ,  int  fail , ` + `  double  integral [ ] ,  double  error [ ] ,  double  prob [ ] ) `    the ` integrand_t ` type intentionally declares only a minimalistic integrand type ( and even the @xmath27 argument could be omitted further ) .",
    "a more complete declaration is    ` typedef  int  ( * integrand_t)(const  int  ndim ,  const  double  x [ ] , ` + `  const  int  ncomp ,  double  f [ ] ,  void  userdata , ` + `  ,  ,  ... ) ; `    where the dots stand for extra arguments passed by vegas , suave , and divonne ( see manual ) not needed in the following . in the presence of an @xmath21 argument ,",
    "@xmath23 and @xmath24 are actually two - dimensional arrays , @xmath31[*ndim]}$ ] and @xmath32[*ncomp]}$ ] .",
    "the integrand receives @xmath33 @xmath34-dimensional samples in @xmath23 and is supposed to fill the array @xmath24 with the corresponding @xmath35-component integrand values .",
    "the return value is irrelevant unless it is @xmath26 , which signals immediate abortion of the integration .",
    "note that @xmath33 indicates the actual number of points passed to the integrand here and may be smaller than the @xmath33 given to the integrator .",
    "the workers are usually started and stopped automatically by cuba s integration routines , but the user may choose to start them manually or keep them running after one integration and shut them down later , e.g.  at the end of the program , which can be slightly more efficient .",
    "the latter mode is referred to as ` spinning cores ' and must be employed with certain care , for running workers will not ` see ' subsequent changes in the main program s data ( e.g.  global variables , common blocks ) or code ( e.g.  via @xmath36 ) unless special arrangements are made ( e.g.  shared memory ) .",
    "the spinning cores are controlled through the ` @xmath37 ' argument of the cuba integration routines ( sect .",
    "[ sect : commonargs ] ) :    * a value of @xmath38 or @xmath39%val(0 ) ( in fortran ) or @xmath40 ( in c / c++ ) tells the integrator to start and shut down the workers autonomously .",
    "this is the usual case .",
    "no workers will still be running after the integrator returns .",
    "no special precautions need to be taken to communicate e.g.  global data to the workers .",
    "note that it is expressly allowed to pass a ` naive ' @xmath38 ( which is an @xmath41 , not an @xmath42 ) in fortran . *",
    "passing a zero - initialized variable for @xmath37 instructs the integrator to start the workers but keep them running on return and store the ` spinning cores ' pointer in @xmath37 for future use .",
    "the spinning cores must later be terminated explicitly by @xmath43 , thus invocation would schematically look like this : + .... integer*8 spin spin = 0 call vegas ( ... , spin , ... ) ... call cubawait(spin ) .... + .... void * spin = null ;    vegas ( ... , & spin , ... ) ; ...",
    "cubawait(&spin ) ; .... * a non - zero @xmath37 variable is assumed to contain a valid ` spinning cores ' pointer either from a former integration or an explicit invocation of @xmath44 , as in : + .... integer*8 spin call cubafork(spin ) call vegas ( ... , spin , ... ) ... call cubawait(spin ) .... + .... void * spin ; cubafork(&spin ) ; vegas ( ... , & spin , ... ) ; ... cubawait(&spin ) ; ....      based on the strategy used to distribute samples , cuba distinguishes two kinds of workers .",
    "workers of the first kind are referred to as ` accelerators ' even though cuba does not actually send anything to a gpu or accelerator in the system by itself ",
    "this can only be done by the integrand routine .",
    "the assumption behind this strategy is that the integrand evaluation is running on a device so highly parallel that the sampling time is more or less independent of the number of points , up to the number of threads @xmath45 available in hardware .",
    "cuba tries to send exactly @xmath45 points to each core  never more , less only for the last batch . to sample",
    "e.g.  2400 points on three accelerators with @xmath46 , cuba sends batches of 1000/1000/400 and not , for example , 800/800/800 or 1200/1200 .",
    "the number of accelerators @xmath47 and their value of @xmath45 can be set through the environment variables    `    cubaaccel=`@xmath47 = ( default : 0 ) + `    cubaaccelmax=`@xmath45 ( default : 1000 )    or , superseding the environment , an explicit    `  call  cubaaccel(`@xmath47 ` ,  ` @xmath45 ` ) `    cpu - bound workers are just called ` cores ' .",
    "their distribution strategy is different in that all available cores are used and points are distributed evenly . in the example above , the batches would be 800/800/800 thus .",
    "each core receives at least 10 points , or else fewer cores are used .",
    "if no more than 10 points are requested in total , cuba uses no workers at all but lets the master sample those few points .",
    "this happens during the partitioning phase of divonne , for instance , where only single points are evaluated in the minimum / maximum search .",
    "conversely , if the division of points by cores does not come out even , the remaining few points ( @xmath48 ) are simply added to the existing batches , to avoid an extra batch because of rounding . sampling 2001 points on two cores with @xmath49",
    "will hence give two batches 1001/1000 and not three batches 1000/1000/1 .",
    "although there is typically no hardware limit , a maximum number of points per core , @xmath50 , can be prescribed for cores , too . unless the integrand is known to evaluate equally fast at all points , a moderate number for @xmath50 ( 10000 ,",
    "say ) may actually increase performance because it effectively load - levels the sampling . for",
    ", a batch always goes to the next free core so it does nt matter much if one core is tied up with a batch that takes longer .",
    "the number of cores @xmath51 and the value of @xmath50 can be set analogously through the environment variables    `    cubacores=`@xmath51 = ( default : no .",
    "of idle cores ) + `    cubacoresmax=`@xmath50 ( default : 10000 )    if @xmath3 is unset , the idle cores on the present system are taken ( total cores minus load average ) , which means that a program calling a cuba routine will by default automatically parallelize on the available cores .",
    "again , the environment can be overruled with an explicit    `  call  cubacores(`@xmath51 ` ,  ` @xmath50 ` )  `    using the environment has the advantage , though , that changing the number of cores to use does not require a re - compile , which is particularly useful if one wants to run the program on several computers ( with potentially different numbers of cores ) simultaneously , say in a batch queue .",
    "the integrand function may use the ` @xmath28 ' argument ( sect .",
    "[ sect : commonargs ] ) to distinguish accelerators ( @xmath52 ) and cores ( @xmath53 ) .",
    "the special value @xmath54 ( @xmath55 ) indicates that the master itself is doing the sampling .",
    "user subroutines for ( de)initialization may be registered with    `  call  cubainit(initfun ,  initarg )  ` + `  call  cubaexit(exitfun ,  exitarg ) `    `  cubainit(initfun ,  initarg ) ;  ` + `  cubaexit(exitfun ,  exitarg ) ; `    and will be executed in every process before and after sampling . passing a null pointer ( @xmath39%val(0 ) in fortran , @xmath40 in c",
    "/ c++ ) as the first argument unregisters either subroutine .",
    "the init / exit functions are actually called as    `  call  initfun(initarg ,  core )  ` + `  call  exitfun(exitarg ,  core ) `    `  initfun(initarg ,  & core ) ;  ` + `  exitfun(exitarg ,  & core ) ; `    where @xmath56 and @xmath57 are the user arguments given with the registration ( arbitrary in fortran , @xmath58 in c / c++ ) and @xmath28 indicates the core the function is being executed on , with ( as before ) @xmath59 for accelerators , @xmath53 for cores , and @xmath54 for the master .    on worker processes ,",
    "the functions are respectively executed after @xmath0 and before @xmath1 , independently of whether the worker actually receives any samples .",
    "the master executes them only when actual sampling is done . for accelerators ,",
    "the init and exit functions are typically used to set up the device for the integrand evaluations , which for many devices must be done per process , i.e.  after the @xmath0 .      by creating a new process image",
    ", @xmath0 circumvents all memory concurrency , to wit : each worker modifies only its own copy of the parent s memory and never overwrites any other s data .",
    "the programmer should be aware of a few potential problems nevertheless :    * communicating back results other than the intended output from the integrand to the main program is not straightforward because , by the same token , a worker can not overwrite any common data of the master , it will only modify its own copy .",
    "+ data exchange between workers is likewise not directly possible .",
    "for example , if one worker stores an intermediate result in a common block , this will not be seen by the other workers .",
    "+ possible solutions include using shared memory ( @xmath19 etc . , see app .",
    "[ app : shm ] ) and writing the output to file ( but see next item below ) .",
    "* @xmath0 does not guard against competing use of other common resources .",
    "for example , if the integrand function writes to a file ( debug output , say ) , there is no telling in which order the lines will end up in the file , or even if they will end up as complete lines at all .",
    "buffered output should be avoided at the very least ; better still , every worker should write the output to its own file , e.g.  with a filename that includes the process i d , as in : + ....     character*32 filename     integer pid     data pid /0/",
    "if ( pid .eq .",
    "0 ) then         pid = getpid ( )       write(filename,'(\"output.\",i5.5 ) ' ) pid       open(unit=4711 , file = filename )     endif .... * fortran users are advised to flush ( or close ) any open files before calling cuba , i.e.  @xmath60 .",
    "the reason is that the child processes inherit all file buffers , and _ each _ of them will write out the buffer content at exit .",
    "cuba preemptively flushes the system buffers already ( @xmath61 ) but has no control over fortran s buffers .    for debugging , or",
    "if a malfunction due to concurrency issues is suspected , a program should be tested in serial mode first , e.g.  by setting @xmath62 ( sect .",
    "[ sect : cores ] ) .",
    "vectorization means evaluating the integrand function for several points at once .",
    "this is also known as single instruction multiple data ( simd ) paradigm and is different from ordinary parallelization where independent threads are executed concurrently .",
    "it is usually possible to employ vectorization on top of parallelization .",
    "vector instructions are commonly available in hardware , e.g.  on x86 platforms under acronyms such as sse or avx .",
    "language support varies : fortran 90 s syntax naturally embeds vector operations .",
    "many c / c++ compilers offer auto - vectorization options , some have extensions for vector data types ( usually for a limited set of mathematical functions ) , and even hardware - specific access to the cpu s vector instructions .",
    "and then there are vectorized libraries of numerical functions available .",
    "cuba can not automatically vectorize the integrand function , of course , but it does pass ( up to ) @xmath21 points per integrand call ( sect .",
    "[ sect : commonargs ] ) .",
    "this value need not correspond to the hardware vector length  computing several points in one call can also make sense e.g.  if the computations have significant intermediate results in common .",
    "the actual number of points passed is indicated through the corresponding @xmath21 argument of the integrand .    a note for disambiguation : the @xmath63 argument of vegas is related in purpose but not identical to @xmath21 .",
    "it internally partitions the sampling done by vegas but has no bearing on the number of points given to the integrand . on the other hand , it it pointless to choose @xmath64 for vegas",
    "parallelization entails a certain overhead as usual , so the efficiency will depend on the ` cost ' of an integrand evaluation , i.e.  the more ` expensive ' ( time - consuming ) it is to sample the integrand , the better the speed - up will be .",
    "the timing measurements in the following figures were made with the 11 integrands of the demo code included in the cuba distribution , which were originally chosen to highlight different aspects of the integrators .",
    "these are simple one - liners and for timing purposes ` infinitely ' fast .",
    "to tune the cost of the integrands , a calibrated delay loop was inserted into the integrand functions .",
    "the calibration was necessary because the system time resolution was visibly imprinted on the first versions of the plots . in a separate program ,",
    "the delay loop was executed with no upper bound but with the timer set to interrupt at 10 seconds .",
    "the number of cycles performed per second was recorded in a file and in subsequent timing measurements was used to compute the upper bound of the delay loop .",
    "this guaranteed that , for a prescribed delay , each integrand was slowed down by the same number of delay - loop turns , with a @xmath65sec precision of the delay .",
    "the number of repetitions of each integration was moreover adjusted for each integrator to make the serial version run for 240 sec .",
    "that leaves at least 30 sec run - time per invocation even for the ideal speed - up of 8 ( on an i7 ) , long enough to make time - measurement errors negligible .    to exclude systematic effects ,",
    "all measurements were done on the same i7 - 2600k linux machine , idle except for the timing program .",
    "the i7 processor has four real and eight virtual ( hyperthreaded ) cores , i.e.   eight register sets but only four arithmetic units . beyond four cores , indicated by a line in the plots ,",
    "cpu effects are thus expected on top of cuba s ` pure ' scaling behavior .",
    "[ fig : easyhard ] shows the speed - ups for an ` easy ' and a ` hard ' one of the 11 integrands of the demo program included in the cuba package for two different integrand delays .",
    "also in the one - core case the parallel version was deployed ( one master , one worker ) , which explains why the timings normalized to the serial version are below 1 , in the top row visibly so .",
    "the first , expected , observation is that parallelization is worthwhile only for not - too - fast integrands .",
    "this is not a major showstopper , however , as many interesting integrands fall into this category anyway .",
    "what appears to be a drastic underperformance of cuhre in the ` easy ' case can in fact be attributed to cuhre s outstanding efficiency : it delivers a result correct to almost all digits with around 300 samples . in such a case ,",
    "cuba may for efficiency choose not to fill all available cores and relative to the full number of cores this shows up as a degradation .",
    "the second observation is that parallelization works best for ` simple - minded ' integrators , e.g.  vegas .",
    "this is showcased even better in fig .",
    "[ fig : allintegrands ] .",
    "the ` intelligent ' algorithms are generally much harder to parallelize because they do nt just do mechanical sampling but take into account intermediate results , make extra checks on the integrand ( e.g.  try to find extrema ) , etc .",
    "this is particularly true for divonne , see sect .",
    "[ sect : divonne ] .",
    "then again ,",
    "the ` intelligent ' algorithms are usually faster to start with , i.e.  converge with fewer points sampled , which compensates for the lack of parallelizability .",
    "cuba speed - ups for three - dimensional integrals with @xmath66 requested accuracy . _ left : _ ` easy ' integrand , _ right : _ ` hard ' integrand .",
    "_ top : _ ` fast ' integrand ( @xmath67sec ) , _ bottom : _ ` slow ' integrand ( @xmath68sec per evaluation ) .",
    "_ solid : _ shared memory , _ dashed : _ socketpair communication ( two curves each to show fluctuations in timing ) . ]",
    "comparison of the parallelization efficiency for all 11 integrands . ]",
    "the cuba library for multidimensional numerical integration now features concurrent sampling and thereby achieves significant speed - ups .",
    "no extra software needs to be installed since only operating - system functions are used .",
    "no reentrancy is required for the integrand function since @xmath0/@xmath1 is applied .",
    "parallelization is usually switched on automatically but can be controlled through api calls or the environment .",
    "cuba is available from @xmath69 and licensed under the lgpl .",
    "the download contains a manual which gives full details on installation and usage .",
    "the author thanks alexander smirnov for valuable suggestions and comments and the miapp workshop ` challenges , innovations and developments in precision calculations for the lhc ' for hospitality during the preparation of this work .    9    t.  hahn , comput .  phys .  commun .",
    "* 168 * ( 2005 ) 7895 [ hep - ph/0404043 ] .",
    "s.  agrawal , t.  hahn , e.  mirabella , j.  phys .",
    "* 368 * ( 2012 ) 012054 [ arxiv:1112.0124 ] .",
    "b.  chokoufe nejad , t.  hahn , j .- n .",
    "lang , e.  mirabella , j.  phys .",
    "* 523 * ( 2014 ) 012050 [ arxiv:1310.0274 ] .",
    "ipc shared memory is not natively available in fortran , but it is not difficult to make it available using two small c functions @xmath70 and @xmath71 :        void shmalloc_(shminfo * base , memindex * i , const int * n , const int * size ) {    base->id = shmget(ipc_private , * size*(*n + 1 ) - 1 , ipc_creat | 0600 ) ;    assert(base->id ! = -1 ) ;    base->addr = shmat(base->id , null , 0 ) ;    assert(base->addr !",
    "= ( void * ) -1 ) ;    * i = ( ( char * ) ( base->addr + * size - 1 ) - ( char * ) base)/(long)*size ; }      the function @xmath70 allocates ( suitably aligned ) @xmath72 elements of size @xmath73 and returns a mock index into @xmath74 , through which the memory is addressed in fortran",
    ". the array @xmath74 must be of the desired type and large enough to store the struct @xmath75 , e.g.  two doubles wide .",
    "be careful to invoke @xmath71 after use , for the memory will not automatically be freed upon exit but stay allocated until the next reboot ( or explicit removal with @xmath76 ) ."
  ],
  "abstract_text": [
    "<S> the parallel version of the multidimensional numerical integration package cuba is presented and achievable speed - ups discussed . </S>"
  ]
}