{
  "article_text": [
    "quantum systems play an important role in atomic and molecular physics , chemistry , material science and many important current technologies such as nuclear magnetic resonance imaging  @xcite and spectroscopy  @xcite , promising nascent quantum technologies such as spintronic devices  @xcite , and potential future technologies such as quantum information processing  @xcite .",
    "novel applications require increasingly sophisticated control , and accurate and precise models to facilitate controlled manipulation of their dynamics .",
    "although theoretical device modelling remains important , system identification and data - driven models are becoming increasingly important in many areas of science and technology to accurately describe individual systems  @xcite .",
    "system identification comprises a range of problems including model identification , model discrimination and model verification .",
    "once a model has been selected , the task often reduces to identifying parameters in the model from experimental data . in the quantum domain",
    "this is often data from one of the many types of spectroscopy , from magnetic resonance to laser to electron transmission spectroscopy , depending on the physical system .",
    "more recently single shot measurements of quantum systems have also become important for quantum devices relying on individual quantum states .",
    "fourier analysis of the spectra is frequently used to identify model parameters such as chemical shifts and relaxation rates by examination of the positions and shape of peaks in a free - induction - decay ( fid ) spectrum  @xcite .",
    "fourier analysis of rabi oscillation spectra has also been used to identify hamiltonians  @xcite , as well as decoherence and relaxation parameters for two - level systems  @xcite , and concurrence spectroscopy  @xcite has been applied to determine information about coupling between qubits . for more complex systems , bayesian techniques and maximum likelihood estimation  @xcite",
    "have proved to be extremely valuable to construct data - driven models to identify hamiltonian parameters  @xcite and decoherence parameters for multi - level systems  @xcite .",
    "bayesian techniques have also been applied for adaptive hamiltonian learning using sequential monte - carlo techniques  @xcite .    in this work",
    "we revisit simpler systems : two - level systems subject to decoherence , one of the simplest but arguably most important models in quantum physics .",
    "the model is ubiquitous in magnetic resonance imaging , where the magnetization signal from protons ( spin-@xmath0 particles ) precessing and dephasing in a magnetic field is the basis for non - invasive , in - vivo imaging . in quantum information",
    "it describes qubits as the fundamental building blocks subject to decoherence .",
    "therefore , characterization of two - level systems is extremely important .",
    "we compare two frequently used estimation strategies based on fourier analysis and a bayesian approach combined with maximum likelihood estimation , for the ubiquitous parameter estimation problem of a two - level system subject to decoherence .",
    "we consider accuracy , precision and efficiency for different systems and noise models , including gaussian noise , typically encountered for large ensemble measurements , and projection noise , typically present in data from repeated single - system measurements .",
    "in this section we introduce our dynamic model of the physical system and our assumptions about initialisation and measurement of the system .",
    "we focus in particular on the different options for the measurements depending on the nature of the physical system and hence the measurements from which we wish to estimate the parameters .      the state of a quantum system is generally described by a density operator @xmath1 , which , for a system subject to a markovian environment , evolves according to a lindblad - type master equation @xmath2 + \\d[v]\\rho , \\\\",
    "\\d[v ]          & = v \\rho v^\\dag - \\tfrac{1}{2 } ( v^\\dag v \\rho + \\rho v^\\dag v ) ,     \\end{split}\\ ] ] where @xmath3 represents the hamiltonian and @xmath4 the dephasing operator .",
    "if the dephasing occurs in the same basis as the hamiltonian evolution then we can choose a basis in which both @xmath5 and @xmath4 are diagonal .",
    "for a two - level system we can thus write @xmath6 and @xmath7 , where @xmath8 , leaving us essentially with two core system parameters to identify , @xmath9 and @xmath10 , or often @xmath11 .      a basic experiment involves initalizing the system in some state @xmath12 and measuring the decay signal , a so - called free - induction decay experiment .",
    "the measured signal depends on the system parameters as well as the initial state and the measurement .",
    "taking the measurement operator to be of the form @xmath13 and taking the initial state to be @xmath14 the measurement signal is of the form @xmath15 assuming the system is initially in the ground state @xmath16 , e.g. , corresponding to spins being aligned with an external magnetic field , the initialization procedure corresponds to applying a short pulse to put the system into a superposition of the ground and excitation state .",
    "notice if the system is not well characterized then it is likely to be infeasible to prepare the system in a well - defined superposition state with a known angle @xmath17 .",
    "rather , @xmath17 becomes an additional parameter to be estimated .",
    "the operator @xmath18 corresponds to measuring the system with regard to an axis tilted by an angle @xmath19 from the system axis in the @xmath20 plane , which can describe many different experimental situations . in an fid experiment in nmr , for example",
    ", an @xmath21-magnetization measurement corresponds to setting @xmath22 . in a rabi spectroscopy experiment of a quantum dot , where the population of the ground and/or excited state is measured ,",
    "e.g. , via a fluorescence measurement , we would typically set @xmath23 . in some situations , such as the examples",
    "mentioned , the hamiltonian and measurement bases may be well - known .",
    "in other situations , however , such as in a double quantum dot system with charge state read - out via a single electron transistor perhaps , @xmath19 may a priori at most be approximately known . in this case",
    "@xmath17 becomes an additional parameter to be estimated . in this work",
    "we employ a formalism that does not require either the initial state or measurement to be known a priori .      in an fid experiment we could in principle measure",
    "the decay signal continuously .",
    "however , modern receivers typically return a digitized signal , i.e. , a vector of time samples , usually the signal values integrated over short time intervals @xmath24 . for this type of readout ,",
    "the number @xmath25 of time samples and their spacing @xmath24 are usually fixed , or at least selected prior to the start of the experiment . in this set - up",
    "there is usually little opportunity for adaptive refinement short of simply repeating the entire experiment with shorter @xmath24 or larger @xmath25 .    in other situations , such as rabi spectroscopy  @xcite",
    ", each measurement corresponds to a separate experiment .",
    "for example , we prepare the system in a certain initial state , let it evolve under some hamiltonian ( with parameters to be estimated ) for some time @xmath26 before performing a measurement to determine the state of the system .",
    "in this case we are more flexible and can in principle choose the measurement times adaptively , trying to optimize the times to maximize the amount of information obtained in each measurement .",
    "here we mainly consider the case of a regularly sampled measurement signal but we also briefly consider how the estimation can be improved in the latter case by adaptive sampling with particular focus on the comparison between the different estimation strategies .",
    "in many settings from nmr and mri to electron spin resonance ( esr ) to atomic ensembles in atom traps , large ensembles of spins or atoms are studied resulting in ensemble average measurements . in this",
    "setting , the backaction from the measurement is negligible and the system can be measured continuously to obtain a measurement signal @xmath27 .",
    "the noise in the signal is well approximated by gaussian noise , which can be simulated by adding a zero - mean gaussian noise signal @xmath28 to the ideal signal @xmath29 , i.e. , the measured signal @xmath30 . by the law of large numbers and iterated logarithm law  @xcite this gives a gaussian distribution for @xmath31 with mean @xmath29 and variance @xmath32 for @xmath33 .",
    "this is a good error model for simulating physical systems and estimating the noise in actual measurement data when the ensemble size @xmath34 is large .",
    "more recently single quantum systems , such as trapped ions  @xcite , trapped atoms  @xcite , single electron spins  @xcite , and charge states in josephson junctions  @xcite , have become an important topic for research because of their potential relevance to quantum technolgoies . given a single copy of a two - level system , measurement of any observable yields only a single bit of information indicating a 0 or 1 result . to determine the expectation value of an observable the experiment has to be repeated many times and the results averaged .",
    "furthermore , due to the backaction of the measurement on the system , we can generally only perform a single projective measurement . to obtain data about the observable at different times",
    "the system has to be re - initialized and the experiment repeated for each measurement . in this context",
    "the ensemble size @xmath34 is the number of times each experiment on a single copy of the system is repeated .",
    "as repetitions are time- and resource - intensive , it is desirable to keep @xmath34 small .",
    "however , this means the precision of the expectation values of observables becomes limited by projection noise , following a poisson distribution .",
    "to simulate experiments of this type we compute the probability @xmath35 of measurement outcome @xmath36 for the simulated system , generate @xmath34 random numbers @xmath37 between @xmath38 and @xmath36 , drawn from a uniform distribution , and set @xmath39 , where @xmath40 is the number of @xmath41 .",
    "this section introduces the three parameter estimation strategies based on fourier and bayesian analysis we wish to compare .",
    "a common technique to find frequency components in a noisy time - domain signal is spectral analysis .",
    "consider a measurement signal of the form @xmath42 which corresponds directly to measurement ( [ eq : meas1 ] ) if we set @xmath43 and @xmath44 .",
    "subtracting the mean of the signal @xmath45 and rescaling gives @xmath46 . to account for",
    "the fact that @xmath47 is defined only for @xmath48 we multiply @xmath47 by the heaviside function @xmath49 the fourier transform of @xmath50 is @xmath51 and the power spectrum is @xmath52 .",
    "differentiating with respect to @xmath9 and setting the numerator to @xmath38 shows that @xmath53 has extrema for @xmath54 and @xmath55 .",
    "the real roots @xmath56 of this equation satisfy @xmath57 and the corresponding maximum of the power spectrum @xmath58 defining the error term @xmath59 we can estimate the frequency @xmath60 and dephasing rate @xmath61 from the peak height @xmath62 and position @xmath56 via @xmath63 determining the maximum @xmath62 and its location @xmath56 from @xmath64 , we may choose @xmath65 and @xmath66 as starting point for a local minimization routine provided @xmath67 as is usually the case .    instead of estimating the height of the peak ,",
    "estimates for @xmath60 and @xmath61 can also be obtained using the width of the peak .",
    "let @xmath68 be the ( positive ) frequencies for which @xmath69 assumes half its maximum .",
    "one way to estimate @xmath68 is to take the minimum and maximum of @xmath70 , assuming that sufficient measurements have been made such that @xmath71 is symmetric and peaked , i.e. , it has low skewness and high kurtosis .",
    "the full - width - half - maximum @xmath72 of @xmath69 is @xmath73 and we can derive the following expression : @xmath74\\\\      & = \\left[\\sqrt{\\omega_*^2 + 2\\sqrt{3 } \\gamma\\sqrt{\\omega_*^2+\\gamma^2}}-\\omega _ * \\right ] .",
    "\\end{split}\\ ] ] hence , given the location @xmath56 and half - width @xmath75 of the peak solving for @xmath61 gives the alternative @xmath76 where @xmath77 .",
    "strategy 2 based on peak - positions and linewidths is probably the most common approach for estimating frequencies and @xmath78-relaxation rates from fid signals in nmr and in many other contexts .",
    "the expressions for @xmath79 , the peak heights and linewidth are more complicated than those for quadrature measurements as we only have a real cosine signal but the approach is fundamentally the same .      given discrete time - sampled data represented by a row vector @xmath80 of length @xmath81 containing the measurement results obtained at times @xmath82 for @xmath83 ,",
    "let @xmath84 be the vector of the corresponding measurement outcomes predicted by the model .",
    "@xmath84 depends on the model parameters , here @xmath60 and @xmath61 .",
    "assuming gaussian noise with variance @xmath85 we define the joint likelihood  @xcite @xmath86.\\ ] ] if the noise level @xmath87 of the data is not known a priori , we can eliminate this parameter following the standard bayesian approach by integrating over @xmath87 from @xmath38 to @xmath88 , using the jeffrey s prior @xmath89 .",
    "this gives @xmath90 where @xmath91 is the gamma function .",
    "it is usually more convenient and numerically robust to work with the ( negative ) logarithm of the likelihood function , the so - called log - likelihood .",
    "when the noise level @xmath87 is known the log - likelihood reduces to @xmath92 where the constant is usually omitted ; when @xmath87 is not known a priori we obtain instead @xmath93 the idea of maximum likelihood estimation is to find the model parameters that maximize this ( log-)likelihood function . to simplify this task , we follow a similar approach as in previous work @xcite and express the signals as linear combinations of a small number @xmath94 of basis functions @xmath95 determined by the functional form of the signals . in our case",
    "the measurement signal @xmath29 can be written as a linear combination of @xmath96 basis functions @xmath97 with @xmath98 and @xmath99 .",
    "as the basis functions are not orthogonal , we define an orthogonal projection of the data onto the basis functions sampled at times @xmath82 as follows .",
    "let @xmath100 be a matrix whose rows are the basis functions @xmath95 evaluated at times @xmath82 , @xmath101 , and @xmath102 be the eigendecomposition of the positive - definite matrix @xmath103 .",
    "then @xmath104 is a matrix satisfying @xmath105 , whose rows form an orthonormal set , @xmath106 , and we define the orthogonal projection of the data vectors onto the basis function by @xmath107 .    projecting the data onto a linear combination of basis functions introduced @xmath94 nuisance parameters @xmath108 . using a standard bayesian approach",
    "we can eliminate them by integration using a uniform prior , and following further simplifications  @xcite , it can be shown that the log - likelihood  ( [ eq : likelihood2 ] ) becomes @xmath109\\ ] ] where @xmath110 and @xmath111 and we have dropped the constant offset .",
    "this log - likelihood function can be evaluated efficiently , and we can use standard optimization algorithms to find its maximum , motivating @xmath112 note that in general , finding the global maximum of the log - likelihood function is non - trivial as it is non - convex , tends to become sharply peaked , especially for large data sets , and may have many local extrema , necessitating global search techniques .",
    "however , for our two - parameter case , finding the global optimum over reasonable ranges for @xmath9 and @xmath61 proved straightforward using either standard quasi - newton or even nelder - mead simplex optimization . for more complex functions a density estimator such as particle filters ( sequential monte carlo methods ) or kernel density estimators may be used , which also enable effective determination of the maximum .",
    "we now compare the three strategies introduced in the previous section for ensemble and single - shot measurements and also discuss the uncertainty in the estimated parameters and show how strategy  3 enables the estimation of additional initialisation and measurement parameters . for this",
    "we use @xmath113 systems with different values for @xmath9 and @xmath61 , given in table  [ table : models ] , and collect measurement data from simulations with the relevant noise models . for each system",
    "the signal was sampled uniformly at @xmath114 time points @xmath115 $ ] .",
    "we assume that we have some order of magnitude estimate of the system frequency @xmath116 based on the physical properties of the system , giving us a range for the values of @xmath9 . without loss of generality",
    "we can express both @xmath9 and @xmath61 in units of @xmath116 .",
    "accordingly all times quoted in the following will be in units of @xmath117 . in our simulations",
    "we choose @xmath118 $ ] and @xmath119 $ ] in units of @xmath116 .",
    "to calculate an average relative error for the parameter estimates , @xmath120 runs were performed for each system and noise level and the error computed as    @xmath121    [ eq : error ]    where @xmath9 and @xmath61 are the actual parameters of the simulated system and @xmath122 and @xmath123 are the estimated values for the @xmath124th run .",
    "+   +     of the measurement data for 10 model systems of type 1 obtained from strategy 3 closely track the actual noise levels of the simulated data @xmath125.,scaledwidth=49.0% ]      to compare the different estimation strategies for discretely sampled signals with gaussian noise we simulate the measurement result @xmath126 at time @xmath127 .",
    "the expected signal @xmath128 was calculated based on the selected model and gaussian noise of mean @xmath38 and standard deviation @xmath87 added to each value .",
    "[ fig : signal ] ( left ) shows an example of an ideal measurement signal and simulated data with uniform sampling at times @xmath129 with @xmath130 .",
    "[ fig : compare1 ] compares the errors according to ( [ eq : error ] ) for the three strategies .",
    "strategy  2 , probably the most common technique for estimating the frequency and dephasing parameter using the position and width of the peak in the fourier spectrum , actually gives the least accurate and least precise estimates  the median error of the estimated values is large , as is the spread of the errors for different systems as indicated by the large error bars .",
    "strategy  1 produces slightly improved estimates , but parameter estimates based on strategy 3 are significantly better .",
    "the results are similar for @xmath9 and @xmath61 .",
    "[ fig : estimation - bias ] furthermore suggests that strategies  1 and 2 are _ not _ unbiased estimators .",
    "the mean of the distribution over the estimation runs does not appear to converge to the true value of the parameter even for very lowest noise level and 1000 runs .",
    "strategy  3 , however , appears to be an unbiased gaussian estimator",
    ".    one interesting feature of strategies  1 and 2 is that the median estimation errors appear to be almost constant over the range of noise levels considered , while for strategy  3 the error increases with increasing noise level , as one would expect .",
    "a probable reason for this is that the uncertainties in the position , and indirectly the width , of the peaks in the fourier spectrum primarily depend on the length of the signal @xmath131 .",
    "specifically , for a fixed number of samples ,  @xcite found that the uncertainty in the parameter estimates was mainly proportional to @xmath132 .",
    "this would explain why the accuracy of the estimates obtained from the fourier - based strategies appears roughly constant as the signal length and number of samples were both fixed in our simulated experiments ( @xmath133 , @xmath114 ) .",
    "so it might be argued that the fourier - based strategies are less sensitive to noise .",
    "however , it is important to notice that even for noise with @xmath134 , strategy  3 still outperforms the other strategies in all cases .    furthermore , accurately and precisely estimating location and width of a peak in the fourier spectrum for a relatively short , noisy signal can be challenging , as illustrated by the power spectrum examples in fig .",
    "[ fig : fourier - problems ] .",
    "the blue bars show the @xmath135 , where @xmath136 is the discrete fourier transform of the measured discrete signal @xmath137 computed using the fast fourier transform ( fft ) , after centering and rescaling , @xmath138 with @xmath139 and @xmath140 .",
    "the red curve is an approximation to the continuous fourier transform @xmath141 where the integral has been approximated using the trapezoidal rule with @xmath142 for @xmath143 and @xmath144 .",
    "the left figure shows a `` good '' power spectrum for a low - noise input signal . even in this case",
    "the frequency resolution is limited but the peak has a more or less lorentzian shape and the width is well defined .",
    "however , for increasing noise the peak can become increasingly distorted ( center ) and for very noisy signals it may even become split ( right ) making width estimation difficult and assumptions about kurtosis and skewness are no longer valid .",
    "a further advantage of strategy  3 is that it also provides direct estimates for the noise variance  @xcite @xmath145 and fig .",
    "[ fig : compare1c ] shows that the estimates are very accurate across the board .              for single shot measurements for 10 model systems , averaged over 100 runs each , obtained from strategy 3 .",
    "the @xmath34 estimates closely track the actual number of repetitions of the single shot measurements for the simulated data @xmath146.,scaledwidth=49.0% ]      to assess if there are significant differences in the performance of different estimation strategies in the presence of projection noise , we repeat the analysis in the previous subsection for the same 10 model systems , sampled over the same time interval @xmath147 $ ] , but with various levels of projection noise added instead of gaussian noise . fig .",
    "[ fig : signal ] ( right ) shows an example of an ideal measurement signal and simulated data .",
    "[ fig : compare2 ] shows the relative errors for the different estimation strategies for the same model systems but subject to ( simulated ) projection noise .",
    "strategy  3 again performs significantly better than the other strategies .",
    "[ fig : compare2b ] shows that the likelihood of the estimates increases with increasing number of repetitions @xmath34 , as expected .",
    "it also shows again that the maximum likelihood for some model systems is consistently higher than for others , as was observed for gaussian noise .",
    "[ fig : compare2c ] shows that even the estimates for the noise variance @xmath85 obtained automatically with strategy  3 are very accurate in that the results obtained closely track the theoretical values @xmath148 expected for projection noise .",
    "overall this shows that although the noise strictly follows a poisson distribution in this case , we still obtain very good estimates of the noise level for typical values of @xmath34 using a gaussian error model in the derivation of the maximum likelihood estimation strategy .",
    "so overall strategy  3 appears to be consistently better than strategies  1 and 2 , independent of the types of measurements and their associated noise for the two - level frequency and dephasing estimation problem .     and",
    "@xmath61.,scaledwidth=49.0% ]             +    ) for different noise levels.,scaledwidth=49.0% ]      the error statistics are useful for comparing different strategies in terms of both the accuracy ( mean or median of error ) and precision ( spread of errors ) of the estimated parameters , and the graphs above show that strategy  3 outperforms the other strategies on both counts .",
    "however , obtaining such statistics requires data from many simulated experiments as well as knowledge of the actual system parameters . in practice ,",
    "the actual values of the system parameters to be estimated are usually unknown , as otherwise there would be no need to estimate the parameters in the first place , so we can not use error statistics directly to determine the accuracy and precision of our estimates .",
    "however , we can estimate the uncertainty of the parameter estimates , as discussed next .    for the fourier - based strategies we have already mentioned that the uncertainty in the parameter estimates is mainly determined by the frequency resolution , limited by the sampling rate based on the nyquist - shannon sampling theorem , which is fixed @xmath149 in our case , and the length of the sampled input signal as the gabor limit implies as trade - off between time- and band - limits .    for the maximum likelihood estimation we can obtain uncertainty estimates for the parameters from the width of the peak of the likelihood function around the maximum",
    "we use the following simple strategy .",
    "let @xmath150 be the parameters for which the log - likelihood assumes its ( global ) maximum @xmath151 . to estimate the uncertainty in @xmath9 we compute the log - likelihood @xmath152 for values @xmath153 where @xmath154 is significantly larger than @xmath38 ( implemented by sampling under the assumption that @xmath154 is not too far off a peaked distribution ) .",
    "then we find the range of @xmath153 for which the actual likelihood @xmath155 to determine the full width at half maximum ( fwhm ) @xmath156 of the likelihood peak in the @xmath9 direction . assuming a roughly gaussian peak the uncertainty in @xmath9 is then given by @xmath157 and similarly for @xmath61 .",
    "[ fig : peak - width ] shows the resulting peaks in the likelihood function for a typical experiment together with the fwhm estimates , showing greater uncertainty in the @xmath61 estimates .",
    "[ fig : compare1a ] show the resulting uncertainties for parameter estimates obtained by strategy  3 for the ensemble measurements .",
    "the uncertainty in the @xmath9 and @xmath61 estimates increases with the noise level , as one would expect , but for some systems the increase is steeper than for others . in particular , the uncertainties are greater for models 4 , 5 and 10 , for which @xmath61 is large , and lowest for model system 9 , which has the lowest @xmath61 of the 10 models .",
    "the higher uncertainties coincide with dips in the maximum of the log - likelihood in fig .",
    "[ fig : compare1b ] .",
    "although there is some variation in the value of the maximum log - likelihood between different runs for the same model and error level , the differences between the average of the maximum log - likelihood over many runs for model systems 1 and 5 are several standard deviations , e.g.  @xmath158 ( for model 1 , @xmath134 ) vs @xmath159 ( model 5 , @xmath134 ) .",
    "this is consistent with the peak of the ( log-)likelihood being lower and broader for model 5 , resulting in higher uncertainty , and narrower and higher for model 1 , resulting in less uncertainty .",
    "[ fig : compare2a ] shows that the uncertainties for parameter estimates behave the same ways for single shot measurements as a function of the projection noise level @xmath160 .",
    "this suggests that given the same amount of data the uncertainty of our estimates increases slightly with larger dephasing rate .",
    "a probable explanation for this is that the signal decays faster for higher dephasing and thus the signal - to - noise ratio of the later time samples is reduced . for higher dephasing rates the results",
    "could likely be improved by adding more samples for shorter times or introducing weights and reducing the latter for measurements obtained for longer times .",
    "and @xmath161 including uncertainty as a function of the noise level @xmath87 for 10 model systems.,scaledwidth=49.0% ]     and @xmath161 as a function of the number of single shot repetitions @xmath34 for 10 model systems ( type 1 , averaged over 100 runs each).,title=\"fig:\",scaledwidth=49.0% ] +      according to ( [ eq : im ] ) strategy  3 also provides information about the initialization and measurement procedure via estimates for the parameters @xmath162 and @xmath161 . for this model",
    "we obtain @xmath163 and thus    @xmath164 , \\\\",
    "\\theta_m & = \\tfrac{1}{2}[\\arccos(\\alpha_1 - \\alpha_2 ) - \\arccos(\\alpha_1+\\alpha_2)].\\end{aligned}\\ ] ]    fig .",
    "[ fig : compare1d ] shows the estimates for the parameters @xmath162 and @xmath161 with error bars indicating uncertainty for the ensemble measurements . from the plot it is evident that @xmath165 and @xmath166 for @xmath167 , which suggests @xmath168 , which agrees with the values of the initialization and measurement angles used in the simulated experiments .",
    "[ fig : compare2d ] shows that the same is true in the case of projection noise for single shot measurements .",
    "the associated estimates for the parameters @xmath162 and @xmath161 in converge to @xmath165 and @xmath166 for @xmath169 , which suggests @xmath168 , which also agrees with the values of the initialization and measurement angles used in the simulated experiments .",
    "similar behaviour is observed for other choice of the initialization and measurement angles .",
    "the fisher information matrix @xmath170 is defined by @xmath171             =   \\int \\frac{\\partial l}{\\partial\\theta_i } \\ , \\frac{\\partial l}{\\partial\\theta_j }",
    "f(x|\\theta ) dx            = - e \\left [ \\frac{\\partial^2l}{\\partial \\theta_i \\partial\\theta_j } \\right ] % \\end{split}\\ ] ] where @xmath172 is the log - likelihood of the measurement outcome @xmath21 given @xmath173 and @xmath174 the expectation w.r.t .",
    "if the estimator @xmath131 for the parameters @xmath173 is unbiased , i.e. the mean square error of @xmath131 is @xmath175 where @xmath176 is the covariance matrix of the estimator , then the matrix @xmath177 must be positive semi - definite and @xmath178 gives an estimate of how close we are to the cramer - rao limit .",
    "applied to our case , @xmath179 and @xmath180 with @xmath181 , we get    @xmath182 \\frac{\\partial p(\\theta , t_n)}{\\partial \\theta_1}\\\\ \\frac{\\partial l}{\\partial \\theta_2 }   & = -\\frac{1}{\\sigma^2 } \\sum_{n=1}^n [ p(\\theta , t_n)-x_n ] \\frac{\\partial p(\\theta , t_n)}{\\partial \\theta_2}\\\\\\end{aligned}\\ ] ]    and    @xmath183    setting @xmath184 we have @xmath185 with @xmath186 and @xmath187 , @xmath188 . similarly for the other partial derivatives . noting @xmath189      d x_n = p_n\\ ] ] and",
    "assuming the estimator is unbiased , we finally obtain the entries of the fisher information matrix @xmath190 while our simulations suggest that the estimators based on strategies  1 and  2 are not unbiased , strategy  3 appears to be unbiased .",
    "[ fig : fisher ] , showing the smallest eigenvalue of the matrix @xmath191 for our various test systems subject to projection noise , suggests that we indeed approach the cramer - rao bound for @xmath33 and @xmath192 .",
    "we may find that the accuracy or precision of the parameters obtained from an initial data set is not sufficient and we would like to improve it by acquiring additional data .",
    "adaptive refinement strategies depend on the experimental set - up and system and a detailed analysis of specific strategies is beyond the scope of this paper .",
    "however , we shall briefly discuss general approaches for iterative refinement for the fourier and bayesian estimation approaches and compare these for a few examples .    in some settings an entire measurement trace",
    "is obtained in a single experimental run and we are only able to sample the signal at regular time intervals restricted by the experimental equipment available . in this case",
    "the only options available to us are extending the signal length ( keeping sampling density or number of sample points constant ) or repeating the experiment .",
    "if fourier - based estimation strategies are used , the only way to really improve the resolution of the fourier spectrum , and thus the accuracy and precision of our estimates , is by increasing the signal length .",
    "however , for a decaying signal the signal - to - noise ratio progressively deteriorates until the signal vanishes , limiting the accuracy and precision that are attainable .",
    "this is illustrated in fig .",
    "[ fig : refine1](left ) , which shows the ( normalized ) power spectrum for 1 to 1000 repetitions of the experiment for model parameters 4 , assuming each individual measurement trace is subject to gaussian noise at @xmath134 and the signals are averaged . for a single run of the experiment with this level of noise ,",
    "the peak is distorted but the power spectrum quickly converges .",
    "the corresponding estimates for @xmath9 and @xmath61 ( fig .",
    "[ fig : refine1 ] , center and right ) also converge but not to the true value . for strategy",
    "2 the @xmath9 and @xmath61 estimates are inaccurate .",
    "the optimization step in strategy  1 appears to improve the accuracy of the @xmath9 estimates but the @xmath61 estimates are still inaccurate .",
    "strategy  3 does not suffer from these limitations and averaging multiple short traces should increase the accuracy of our estimates . indeed the figure shows that this appears to be the case : both the @xmath9 and @xmath61 estimates converge to the true values .",
    "this shows that strategy  3 allows adaptive refinement even if all we are able to do is to repeat the experiment multiple times and average the measurement traces .",
    "however , in some situations we have more freedom . for rabi spectroscopy , for example , each data point , corresponding to a measurement at a particular time @xmath82 ,",
    "may be obtained in a separate experiment , and we may be free to choose the measurement times @xmath82 flexibly . in this case , having obtained @xmath81 measurements we can try to choose the next measurement time @xmath193 such that it optimizes the amount of information we gain from the experiment .",
    "we could ask , for example , considering all possible outcomes of a measurement at time @xmath26 and their probability based on our current knowledge , at what time should we measure next to achieve the largest reduction in the uncertainty of our estimates .",
    "however , this would require calculating the uncertainty of the parameters ( e.g. , by estimating the width of the likelihood peaks ) for all possible measurement times and outcomes .",
    "given the continuum of measurement outcomes and measurement times , this is generally too expensive to calculate .",
    "we therefore consider a simpler heuristic .",
    "we generate a number of guesses @xmath194 for the parameters based on the current likelihood distribution for the parameters .",
    "we then calculate the measurement signal @xmath195 for a set of discrete times and select the next measurement time where the variance of the predicted measurement results is greatest .",
    "the idea behind this strategy is that a larger spread in the predicted results indicates greater uncertainty , and a measurement at such a time should result in a greater reduction of the uncertainty .",
    "we illustrate this strategy in fig .",
    "[ fig : refine2 ] .",
    "the variance of the predicted traces @xmath196 exhibits oscillations at about twice the frequency of the signal , being largest around the minima and maxima of the oscillatory signal but due to the damping of the signal there is an overall envelope and a global maximum around @xmath197 in units of @xmath198 . to avoid repeated sampling at the same time it is desirable to introduce a degree of randomness , e.g. , by selecting the next measurement time based on the maximum of the variance of @xmath199 sampled over a discrete set of times @xmath200 , such as a non - uniform low - discrepancy sampling of the time interval",
    "@xmath201 $ ] .",
    "furthermore , in practice it may be rather inefficient to recalculate the variance of the traces after a single measurement .",
    "instead , it we shall acquire an initial set of @xmath202 data points and then select the next @xmath40 measurement times to coincide with peaks in the variance of the traces where we allow @xmath40 to vary depending on the number of peaks . in fig .  [ fig : refine2 ] , for example , there are eight local peaks and we would choose the next eight measurement times to coincide with these maxima and iterate the process .",
    "an even simpler way of iterative refinement is via low - discrepancy ( ld ) time sampling , a generalization of uniform sampling that lends itself to easy iterative refinement .",
    "the basic idea of ld sequences is to ensure the largest gap between samples is asymptotically optimal , while there is little uniformity in the sampling points to avoid aliasing effects ( see blue noise criterion ) . in this case",
    "the initial measurement times are chosen to be the first @xmath202 elements in a low - discrepancy quasi - random sequence such as the hammersley sequence  @xcite , and in each subsequent iteration the next @xmath203 elements of the sequence are used .",
    "the number of initial measurements @xmath202 and subsequent measurements per iteration @xmath203 are completely flexible , the elements of the sequence can be scaled to uniformly cover any desired time interval , and we can perform as many iterations as desired .",
    "[ fig : ld - iter ] shows the measurement times as a function of the iteration as determined by the hammersley sequence with @xmath204 and @xmath205 for 10 iterations and total sampling times @xmath133 , showing that uniform coverage of the sampling interval is maintained . for a fixed number of measurements",
    "@xmath114 we verified that there was no significant difference in the errors and uncertainties of the parameter estimates between low - discrepancy and uniform sampling for the cases considered above .",
    "furthermore , iterative refinement based on ld - sampling performed very well .",
    "[ fig : ld - refine ] for model system 4 with measurements subject to 5% gaussian noise shows that simple iterative ld - sampling actually outperforms the adaptive refinement strategy based on the trace - variance described above . while this may not be universally the case , and",
    "may be due to the variations in the trace variance being relatively small in our example , it shows that simple strategies such as iterative ld - sampling can be highly effectively .         and @xmath61 parameter estimates for iterative ld - sampling and adaptive sampling based on trace variance for model system 4 with measurements subject to 5% gaussian noise and projection noise @xmath192 , respectively.,scaledwidth=49.0% ]",
    "so far we have considered a particular model of a dephasing two - level system with dephasing acting in the hamiltonian basis . however ,",
    "if control fields are applied , as in a rabi oscillation experiment for example , then the effective hamiltonian and the dephasing basis may not coincide .",
    "for example , for two - level atoms in a cavity driven resonantly by a laser , the effective hamiltonian with regard to a suitable rotating frame is @xmath206 , where @xmath207 is the rabi frequency of the driving field . assuming the driving field does not alter the dephasing processes , so that we still have @xmath208 , the resulting measurement trace is given by  @xcite : @xmath209 where @xmath210 , \\\\    \\omega      & = \\sqrt{\\omega^{2}-\\tfrac{\\gamma^{2}}{4 } } \\label{omegahat}.\\end{aligned}\\ ] ] if @xmath211 then @xmath9 is purely imaginary and the sine and cosine terms above turn into their respective hyperbolic sine and cosine equivalents .",
    "if @xmath212 , the expression @xmath213 must be analytically continued .    due to the more complex nature of the signal ,",
    "the fourier estimation strategies are not directly applicable .",
    "however , we can very easily adapt strategy  3 .",
    "all that is required is a change in the basis functions , setting @xmath214 and @xmath215 .",
    "[ fig : type2 ] shows the log - likelihood functions for a very sparsely sampled signal with significant projection noise for a system of type ( [ eq : meas2 ] ) for a simulated experiment performed with @xmath216 and @xmath217 .",
    "the signal is a damped oscillation , though not a simple damped sinusoid .",
    "strategy  3 easily succeeds in identifying the model parameters and the log - likelihood function has a clearly defined peak .",
    "in fact , we are showing the log - likelihood here as the actual likelihood function is so sharply peaked that its internal structure , especially the squeezed nature , is not easy to see .    finally , fig .",
    "[ fig : type2-error ] ( left ) shows the error statistics for the @xmath9 and @xmath61 estimates obtained using strategy  3 for 10 models of type ( [ eq : meas2 ] ) with the same values for @xmath207 and @xmath61 as in table  [ table : models ] .",
    "we compare two experimental conditions : @xmath218 , which corresponds to maximum visibility of the oscillations and @xmath217 , @xmath216 , for which the signal is more complex and the visibility of the oscillations is reduced as shown in fig .",
    "[ fig : type2 ] .",
    "the estimation errors are very similar to those for models of type 1 .",
    "for @xmath61 they are effectively identical for both experimental conditions ; for @xmath207 they are slightly larger in case 2b , as might be expected as the visibility of the oscillations is reduced in this case .    in both cases",
    "we also obtain excellent estimates of the noise level @xmath87 of the data as well as estimates for the parameters @xmath162 and @xmath161 .",
    "as before , if the initial state prepared or the precise measurement performed are unknown a priori , as may well be the case for a system that is not yet well characterized , we can use these parameters to derive estimates for @xmath17 and @xmath19 :    @xmath219\\\\ \\theta_m & = \\frac{1}{2}[\\arccos(\\alpha_2-\\alpha_1)-\\arccos(\\alpha_2+\\alpha_1)]\\end{aligned}\\ ] ]    fig .",
    "[ fig : type2-error ] ( right ) shows the estimates derived for the angles @xmath17 and @xmath19 for both experimental conditions .",
    "the markers indicate the average of the estimate for all runs and all model systems , the errorbars indicate the standard deviation of the estimates .",
    "the estimates are not as accurate as those for the system parameters , as one would expect as we have marginalized the amplitudes @xmath162 and @xmath161 and thus @xmath17 and @xmath19 .",
    "however , they are still quite close to the actual values ( black dash - dot lines ) with the exception of the @xmath17 estimate for case ( 2a ) , which is slightly more biased and less accurate ",
    "it should be 0 , coinciding with the measurement angle @xmath19 .",
    "we have investigated the ubiquitous problem of identifying crucial parameters from experimental data for two - level systems subject to decoherence . comparing different strategies based on the analysis of fourier spectra as well as bayesian modelling and maximum likelihood estimation ,",
    "the latter approach was found to be vastly superior to commonly used fourier based strategies in terms of accuracy and precision of the estimates obtained .",
    "strategies based on simple fourier analysis are limited by the accuracy with which the positions , heights and widths of the fourier peaks can be determined . as the spectral resolution is limited by signal length and sampling rate , the accuracy of fourier - based estimation schemes for short , decaying signals or sparse noisy data",
    "is limited .",
    "the bayesian approach is not constrained in this way and yields uncertainties for the system parameters as well as information about the noise in the data .",
    "an additional advantage of the bayesian estimation is that it does not require a priori knowledge of the initialization or measurement angles @xmath17 and @xmath19 .",
    "rather , the estimation procedure provides values for the coefficients of the basis functions , which are related to the parameters @xmath17 and @xmath19 .",
    "the results are widely applicable to many experimental settings from the analysis for free - induction decay signals for spin systems , e.g. , in nmr , mri and esr to rabi spectrocopy fo atomic ensembles , trapped ions , quantum dots or josephson junction devices .",
    "we acknowledge funding from the ser cymru national research network in advanced engineering and materials .",
    "sgs also thanks the royal society for funding through a leverhulme senior fellowship grant and the uk engineering and physical sciences research council for recent funding .",
    "fcl acknowledges funding from the cardiff university research leave fellowship scheme ."
  ],
  "abstract_text": [
    "<S> we compare the accuracy , precision and reliability of different methods for estimating key system parameters for two - level systems subject to hamiltonian evolution and decoherence . </S>",
    "<S> it is demonstrated that the use of bayesian modelling and maximum likelihood estimation is superior to common techniques based on fourier analysis . </S>",
    "<S> even for simple two - parameter estimation problems , the bayesian approach yields higher accuracy and precision for the parameter estimates obtained . </S>",
    "<S> it requires less data , is more flexible in dealing with different model systems , can deal better with uncertainty in initial conditions and measurements , and enables adaptive refinement of the estimates . </S>",
    "<S> the comparison results shows that this holds for measurements of large ensembles of spins and atoms limited by gaussian noise as well as projection noise limited data from repeated single - shot measurements of a single quantum device . </S>"
  ]
}