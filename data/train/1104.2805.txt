{
  "article_text": [
    "one of the main differences between human brains and those of other animals is the size of the neocortex [ @xcite ; @xcite ; @xcite ; @xcite ] .",
    "humans have one of the largest neocortical sheets , relative to their body weight , in the entire animal kingdom .",
    "the human neocortex is not a single undifferentiated functional unit , but consists of several hundred individual processing modules called areas .",
    "these areas are arranged in a highly interconnected , hierarchically organized network .",
    "the visual system alone consists of several dozen different visual _ areas _ , each of which plays a distinct functional role in vision . the largest visual area ( indeed , the largest area in the entire neocortex )",
    "is the primary visual cortex , area v1 .",
    "because of its central importance in vision , area v1 has long been a primary target for computational modeling .",
    "the most powerful tool available for measuring human brain activity is functional mri ( fmri ) .",
    "however , fmri data provide a rather complicated window on neural function . first , fmri does not measure neuronal activity directly , but rather measures changes in blood oxygenation caused by metabolic processes in neurons .",
    "thus , fmri provides an indirect and nonlinear measure of neuronal activity .",
    "second , fmri has a fairly low temporal and spatial resolution .",
    "the temporal resolution is determined by physical changes in blood oxygenation , which are two orders of magnitude slower than changes in neural activity .",
    "the spatial resolution is determined by the physical constraints of the fmri scanner ( i.e , limits on the strength of the magnetic fields that can be produced , and limits on the power of the radio frequency energy that can be deposited safely in the tissue ) . in practice ,",
    "fmri signals usually have a temporal resolution of 12 seconds , and a spatial resolution of 24 millimeters .",
    "thus , a typical fmri experiment might produce data from 30,00060,000 individual voxels ( i.e. , volumetric pixels ) every 12 seconds .",
    "these data must first be filtered to remove nonstationary noise due to subject movement and random changes in blood pressure .",
    "then they can be modeled and analyzed in order to address specific hypotheses of interest .",
    "one recent approach for modeling fmri data is to use a training data set to estimate a separate model for each recorded voxel , and to test predictions on a separate validation data set . in computational neuroscience these models",
    "are called _ encoding _ models , because they describe how information about the sensory stimulus is encoded in measured brain activity .",
    "alternative hypotheses about visual function can be tested by comparing prediction accuracy of multiple encoding models that embody each hypothesis [ @xcite ] .",
    "furthermore , estimated encoding models can be converted directly into _ decoding _ models , which can in turn be used to classify , identify or reconstruct the visual stimulus from brain activity measurements alone [ @xcite ] .",
    "these decoding models can be used to measure how much information about specific stimulus features can be extracted from brain activity measurements , and to relate these measurement directly to behavior [ @xcite ; @xcite ; @xcite ] .",
    "most encoding and decoding models rely on parametric regression methods that assume the response is linearly related with stimulus features after fixed parametric nonlinear transformation(s ) .",
    "these transformations may be necessitated by nonlinearities in neural processes [ e.g. , @xcite ] , and other potential sources inherent to fmri such as dynamics of blood flow and oxygenation in the brain [ @xcite ; @xcite ] and other biological factors [ @xcite ] .",
    "however , it can be difficult to guess the most appropriate form of the transformation(s ) , especially when there are thousands of voxels and thousands of features , and when there may be different transformations for different features and different voxels .",
    "inappropriate transformations will most likely adversely affect prediction accuracy and might also result in incorrect inferences and interpretations of the fitted models .",
    "in this paper we use a new , sparse and flexible nonparametric approach to more adequately model the nonlinearity in encoding models for fmri voxels in human area v1 .",
    "the data were collected in an earlier study [ @xcite ] .",
    "the stimuli were grayscale natural images ( see figure  [ fignatural - images ] ) .",
    "the original analysis focused on a class of models that included a fixed parametric nonlinear transformation of the stimuli , followed by linear weighting .",
    "here we show by residual analysis that this model does not account for a substantial nonlinear response component ( section  [ secencoding ] ) .",
    "we therefore model these data by a sparse nonparametric method [ @xcite ] after preselection of features by marginal correlation .",
    "the resulting model qualitatively affects inferred tuning properties of v1 voxels ( section  [ sectuning ] ) , and it substantially improves response prediction ( section  [ secadditivemodels ] ) .",
    "the sparse nonparametric model also improves decoding accuracy ( section  [ secdecoding ] ) .",
    "we conclude that the nonlinearities found in the responses of voxels measured using fmri impact both model performance and model interpretation .",
    "although our paper focuses entirely on area v1 , our approach can be extended easily to voxels recorded in other areas of the brain .",
    "degrees of the field of view , and were cropped to a circular aperture and blended into the background to reduce edge effects . ]",
    "brain area v1 is located in the occipital cortex and is an early processing area of the visual pathway .",
    "it receives much of its input from the lateral geniculate nucleus  a small cluster of cells in the thalamus that is the brain s primary relay center for visual information from the eye .",
    "many of the properties of v1 neurons have been described by visual neuroscientists [ see @xcite for a summary ] . in most cases these neurons",
    "are described as spatio - temporal filters that respond whenever the stimulus matches the _ tuning properties _ of the filter .",
    "the important spatial tuning properties for v1 neurons are related to spatial position , orientation and spatial frequency .",
    "thus , each v1 neuron responds maximally to stimuli that appear at a particular spatial location within the visual field , with a particular orientation and spatial frequency .",
    "stimuli at different spatial positions , orientations and frequencies will elicit lower responses from the neuron . because v1 neurons are tuned for spatial position , orientation and spatial frequency",
    "they are often modeled as gabor filters ( whose impulse response is the product of a harmonic function and a gaussian kernel ) [ @xcite ] .",
    "although tuning for orientation and spatial frequency can be described using a linear filter model , it is well established that individual v1 neurons do not behave exactly like linear filters .",
    "studies using white noise stimuli have reported a nonlinear relationship between linear filter outputs and measured neural responses [ e.g. , @xcite ; @xcite ] .",
    "furthermore , it is known that the responses of v1 neurons saturate ( like @xmath0 or @xmath1 ) with increasing contrast [ e.g. , @xcite ; @xcite ] .",
    "finally , there is evidence that the responses of v1 neurons are normalized by the activity of other neurons in their spatial or functional neighborhood . this phenomenon  known as _",
    "divisive normalization_can account for a variety of nonlinear behaviors exhibited by v1 neurons [ @xcite ; @xcite ] .",
    "it is reasonable to expect that the nonlinearities at the neural level will affect voxel responses evoked by natural images , so a statistical model should describe adequately these nonlinearities .",
    "the data consist of fmri measurements of blood oxygen level - dependent activity ( or bold response ) at @xmath2 voxels in area v1 of a single human subject [ see @xcite ] . the voxels , measuring @xmath3 millimeters , were acquired in coronal slices using a 4 t inova mr ( varian , inc . ,",
    "palo alto , ca ) scanner , at a rate of 1hz , over multiple sessions .",
    "two sets of data were collected during the experiment : training and validation . during the training stage",
    "the subject viewed @xmath4 grayscale natural images randomly selected from an image database , each presented twice ( but not consecutively ) in a pseudorandom sequence ; see figure  [ fignatural - images ] .",
    "each image was presented in an on - off - on - off - on pattern for 1 second with an additional 3 seconds off between presentations . for the validation",
    "data the subject viewed @xmath5 novel natural images presented in the same way as in the training stage , but with a total of @xmath6 presentations of each image .",
    "data collection required approximately 10 hours in the scanner , distributed across 5 two hour sessions .",
    "data preprocessing is necessary to correct several sampling artifactsthat  are intrinsic to fmri .",
    "first , volumes were manually co - registered(in - house software ) to correct for differences in head positioning acrosssessions .",
    "slice - timing and automated motion corrections ( spm99,http://www.fil.ion.ucl.ac.uk / spm ) were applied to volumes acquired within the same session .",
    "these corrections are standard and their details are explained in the supplementary information of @xcite .",
    "our encoding and decoding analyses depend upon defining a single scalar fmri voxel response to each image .",
    "the procedures used to extract this scalar response from the bold time series measurements acquired during the fmri experiment are described in the . in short",
    ", we assume that each distinct image evokes a fixed timecourse response , and that the response timecourses evoked by different images differ by only a scale factor .",
    "we use a model in which the response timecourses and scale factors are treated as separable parameters , and then use these scale factors as the scalar voxel responses to each image . by extracting a single scalar response from the entire timecourse , we effectively separate the salient image - evoked attributes of the bold measurements from those attributes due to the bold effect itself [ @xcite ] .",
    "an encoding model that predicts brain activity in response to stimuli is important for neuroscientists who can use the model predictions to investigate and test hypotheses about the transformation from stimulus to response . in the context of fmri ,",
    "the voxel response is a proxy for brain activity , and so an fmri encoding model predicts voxel responses .",
    "let @xmath7 be the response of voxel @xmath8 to an image stimulus @xmath9 .",
    "we follow the approach of @xcite and model the conditional mean response , @xmath10 as a function of local contrast energy features derived from projecting the image onto a 2d gabor wavelet basis .",
    "these features are inspired by the known properties of neurons in v1 , and are well established in visual neuroscience [ see , e.g. , @xcite ; @xcite ; @xcite ] .",
    "a 2d gabor wavelet @xmath11 is the pointwise product of a complex 2d fourier basis function and a gaussian kernel : @xmath12 where @xmath13        the basis we use is organized into 6 spatial scales / frequencies @xmath14 , where wavelets tile spatial locations @xmath15 and 8 possible orientations @xmath16 , for a total of @xmath17 wavelets .",
    "figure  [ figgabor - wavelets ] shows all of the possible scale and orientation pairs .",
    "let @xmath18 denote a wavelet in the basis .",
    "the local contrast energy feature is defined as @xmath19 ^ 2 +   \\biggl [ \\sum_{a ,",
    "b } { \\operatorname{im}}g_j(a , b ) s(a , b )   \\biggr]^2\\ ] ] for @xmath20 . the feature set is essentially a localized version of the ( estimated ) fourier power spectrum of the image .",
    "each feature measures the amount of contrast energy in the image at a particular frequency , orientation and location .",
    "the model proposed in @xcite assumes that @xmath21 is a weighted sum of a fixed transformation of the local contrast energy features .",
    "they applied a square root transformation to @xmath22 to make the relationship between @xmath21 and the transformed features more linear .",
    "thus , their model is=1 @xmath23 we refer to ( [ eqsqrt - model ] ) as the @xmath24 model .",
    "@xcite fit this model separately for each of the @xmath25 voxels , using gradient descent on the squared error loss with early stopping [ see , e.g. , @xcite ] , and demonstrated that the fitted models could be used to identify , from a large set of novel images , which specific image had been viewed by the subject .",
    "they used a simple decoding method that selects , from a set of candidates , the image @xmath26 whose predicted voxel response pattern @xmath27 is most correlated with the observed voxel response pattern @xmath28 . although @xcite focused on decoding , the encoding model is clearly an integral part of their approach .",
    "we found a substantial nonlinear aspect of the voxel response that their encoding @xmath24 model does not take into account .    since the gradient descent method with early stopping",
    "is closely related to the lasso method [ @xcite ] , we fit the model ( [ eqsqrt - model ] ) separately to each voxel [ as in @xcite ] using lasso [ @xcite ] , and selected the regularization parameters with bic ( using the number of nonzero coefficients in a lasso model as the degrees of freedom ) . figure  [ figlinear - voxel - residuals ] shows plots of the residuals and fitted values for four different voxels . with the aid of a loess smoother [ @xcite ] , we see a nonlinear relationship between the residual and the fitted values .",
    "this pattern is not unique to these four voxels .",
    "we extended this analysis to all @xmath25 voxels . by standardizing the fitted values",
    ", we can overlay the smoothers for all @xmath25 voxels and inspect for systematic deviations from the @xmath24 model across all voxels .",
    "figure  [ figlinear - all - residuals ] shows the result .",
    "nonlinearity beyond the @xmath24 model is present in almost all voxels , and , moreover , the residuals appear to be heteroskedastic .    ) for four different voxels ( labeled above ) .",
    "the solid curves show a loess fit of the residual on the fitted values . ]    ) blended across all @xmath25 voxels .",
    "the solid curves show the loess fits of the residuals on the fitted values for each voxel . ]    composing the square root transformation with an additional nonlinear transformation could absorb some of the residual nonlinearity in the @xmath24 model",
    ". instead of the square root , @xmath29 was used by @xcite to analyze the same data set as we do in this paper and it has also been used in other applications [ see @xcite for an example in the analysis of internet traffic data ] .",
    "the resulting model is @xmath30 and we refer to it as the @xmath31 model .",
    "we fit model ( [ eqlog - model ] ) using lasso with bic , and compared its prediction performance with model ( [ eqsqrt - model ] ) by evaluating the squared correlation ( predictive @xmath32 ) between the predicted and actual response across all 120 images in the validation set .",
    "figure  [ figcc - sqrtx - logx ] shows the difference in predictive @xmath32 values of the two models for each voxel .",
    "there is an improvement in prediction performance ( median @xmath33 for voxels where both models have an @xmath34 ) with model ( [ eqlog - model ] ) .",
    "however , examination of residual plots ( not shown ) reveals that there is still residual nonlinearity .",
    "( based on the validation data ) of the @xmath35 model ( [ eqlog - model ] ) and the @xmath24 model ( [ eqsqrt - model ] ) .",
    "the vertical axis shows the difference @xmath32 of ( [ eqlog - model ] ) @xmath36 of ( [ eqsqrt - model ] ) .",
    "the median improvement of model ( [ eqlog - model ] ) is @xmath33 for voxels where both models have a predictive @xmath34 . ]",
    "the @xmath0 and @xmath37 transformations were used in previous work to approximate the contrast saturation of the bold response .",
    "rather than trying other fixed transformations to account for the nonlinearities in the voxel response , we employed a sparse nonparametric approach that is based on the additive model .",
    "the additive model [ cf .",
    "@xcite ] is a useful generalization of the linear model that allows the feature transformations to be estimated from the data . rather than assuming that the conditional mean @xmath38 is a linear function ( of fixed transformations ) of the features , the additive ( nonparametric ) model assumes that @xmath39 where @xmath40 are unknown , mean 0 predictor functions in some hilbert spaces @xmath41 .",
    "the linear model is a special case where the predictor functions are assumed to be of the form @xmath42 .",
    "the monograph of hastie and tibshirani describes methods of estimation and algorithms for fitting ( [ eqgam ] ) , however , the setting there is more classical in that the methods are most appropriate for low - dimensional problems ( small @xmath43 , large @xmath44 ) .",
    "@xcite extended the additive model methodology to the high - dimensional setting by incorporating ideas from the lasso .",
    "their sparse additive model ( spam ) adds a sparsity assumption to ( [ eqgam ] ) by assuming that the set of active predictors @xmath45 is sparse",
    ". they propose fitting ( [ eqgam ] ) under this sparsity assumption by minimization of the penalized squared error loss @xmath46 where @xmath47 is the euclidean norm in @xmath48 , @xmath49 is the @xmath44-vector of sample responses , @xmath50  is the vector of @xmath51 s , @xmath52 is the vector obtained by applying @xmath53 to each sample of @xmath22 , and @xmath54 .",
    "the penalty term , @xmath55 , is the functional equivalent of the lasso penalty .",
    "it simultaneously encourages sparsity ( setting many @xmath53 to zero ) and shrinkage of the estimated predictor functions by acting as an l1 penalty on the empirical l2 function norms @xmath56 , @xmath57 .    ' '' ''    0.25em 0.25em    ' '' ''    the algorithm proposed by @xcite for solving the sample version of the spam optimization problem ( [ eqspamloss ] ) is shown in figure  [ figspam - backfitting ] .",
    "it generalizes the well - known backfitting algorithm [ @xcite ] by incorporating an additional soft - thresholding step .",
    "the main bottleneck of the algorithm is the complexity of the smoothing step .",
    "we did not apply spam directly to the feature @xmath58 , but instead applied it to the transformed feature , @xmath59 .",
    "we refer to the model @xmath60 as v - spam``v '' for visual cortex and v1 neuron - inspired features .",
    "there is no loss in generality of this model when compared with ( [ eqgam ] ) , but there is a practical benefit because the @xmath59 feature tends to be better spread out than the @xmath58 feature .",
    "this has a direct effect on the smoothness of @xmath61 .",
    "although we did not try other transformations , we found that applying the spam model directly to the @xmath58 features rather than @xmath62 resulted in poorer fitting models .",
    "we fit the v - spam model separately to each voxel , using cubic spline smoothers for the @xmath61 .",
    "we placed knots at the deciles of the @xmath63 feature distributions and fixed the effective degrees of freedom [ trace of the corresponding smoothing matrix ; cf .",
    "@xcite ] to 4 for each smoother .",
    "this choice was based on examination of a few partial residual plots from model ( [ eqlog - model ] ) and comparison of smooths for different effective degrees of freedoms .",
    "we felt that optimizing the smoothing parameters across features and voxels ( with generalized cross - validation or some other criterion ) would add too much complexity and computational burden to the fitting procedure .",
    "the amount of time required to fit the v - spam model for a single voxel with @xmath64 features is considerably longer than for fitting a linear model , because of the complexity of the smoothing step .",
    "so for computational reasons we reduced the number of features to 500 by screening out those that have low marginal correlation with the response , which reduced the time to fit one voxel to about 10 seconds .",
    "we selected the regularization parameter @xmath65 using bic with the degrees of freedom of a candidate model defined to be the sum of the effective degrees of freedom of the active smoothers ( those corresponding to nonzero estimates of @xmath53 ) .",
    "figure  [ figvspam - voxel - residuals ] shows residual and fitted value plots for the four voxels that we examined in the previous section .",
    "little residual nonlinearity remains in this aspect of the v - spam fit .",
    "the residual linear trend in the loess curve is due to the shrinkage effect of the spam penalty  the residuals of a penalized least squares fit are necessarily correlated with the fitted values .",
    "figure  [ figvspam - all - residuals ] shows the residuals and fitted values of v - spam for all @xmath25 voxels .",
    "in contrast to figure  [ figlinear - all - residuals ] , there is neither a visible pattern of nonlinearity , nor a visible pattern of heteroskedasticity .    ) for four different voxels ( labeled above ) .",
    "the solid curves show a loess fit of the residual on the fitted values .",
    "compare with figure  [ figlinear - voxel - residuals ] .",
    "the linear trend in the residuals is due to the shrinkage effect of the penalty in the spam criterion ( [ eqspamloss ] ) . ]    ) for all @xmath25 voxels .",
    "the solid curves show the loess fits of the residuals on the fitted values for each voxel .",
    "compare with figure  [ figlinear - all - residuals ] . ]    [ cols=\"^ \" , ]     the v - spam model better addresses nonlinearities in the voxel response . to determine if this model leads to improved prediction performance , we examined the squared correlation ( predictive @xmath32 ) between the predicted and actual response across all 120 images in the validation set .",
    "figure  [ figcc - vspam ] compares the predictive @xmath32 of the v - spam model for each voxel with those of the @xmath24 model ( [ eqsqrt - model ] ) and the @xmath31 model ( [ eqlog - model ] ) . across most voxels",
    ", there is a substantial improvement in prediction performance .",
    "the median ( across voxels where both models have a predictive @xmath34 ) is @xmath66 over the @xmath24 model , and @xmath67 over the @xmath31 model .",
    "thus , the additional nonlinear aspects of the response revealed in the residual plots ( figures [ figlinear - voxel - residuals ] and [ figlinear - all - residuals ] ) for the parametric @xmath24 and @xmath31 models are real and they account for a substantial part of the prediction of the voxel response .",
    "decoding models have received a great deal of attention recently because of their role in potential `` mind reading '' devices .",
    "decoding models are also useful from a statistical point of view because their results can be judged directly in the known and controlled stimulus space . here we show that accurately characterizing nonlinearities with the v - spam encoding model ( presented in the preceding section ) leads to substantially improved decoding .",
    "we used a naive bayes approach similar to that proposed by @xcite to derive a decoding model from the v - spam encoding model . recall that @xmath7 ( @xmath68 and @xmath69 ) is the response of voxel @xmath8 to image @xmath9 . a simple model for @xmath7 that is compatible with the least squares fitting in section  [ secencoding ]",
    "assumes that the conditional distribution of @xmath7 given @xmath9 is normal with mean @xmath70 and variance @xmath71 , and that @xmath72 are conditionally independent given @xmath9 . to complete the specification of the joint distribution of the stimulus and response ,",
    "we take an empirical approach [ @xcite ] by considering a large collection of images @xmath73 similar to those used to acquire training and validation data .",
    "the bag of images prior places equal probability on each image in @xmath73 : @xmath74 this distribution only implicitly specifies the statistical structure of natural images . with bayes rule",
    "we arrive at the decoding model @xmath75 this model suggests that we can identify the image @xmath26 that most closely matches a given voxel response pattern @xmath76 by the rule @xmath77 the fitted models from section  [ secencoding ] provide estimates of @xmath78 . given @xmath79 ,",
    "the variance @xmath71 can be estimated by @xmath80 where @xmath81 is the degrees of freedom of the estimate @xmath79 ( the number of nonzero coefficients in the case of linear models , or 4 times the number of nonzero functions in the case of v - spam ; cf .",
    "section  [ secadditivemodels ] ) . substituting these estimates into ( [ eqbayesrule ] ) gives the decoding rule @xmath82 although we have estimates for every voxel , not every voxel may be useful for decoding@xmath79 may be a poor estimate of @xmath78 or @xmath21 may be close to constant for every @xmath26 . in that case , we may want to select a subset of voxels @xmath83 and restrict the summation in the above display to @xmath84 .",
    "thus , we propose the decoding rule @xmath85 one strategy for voxel selection is to set a threshold @xmath86 for entry to @xmath84 based on the usual @xmath32 computed with the training data , @xmath87 so that @xmath88",
    ". we will examine this strategy later in the section .    to use ( [ eqdecoding - model ] ) as a general purpose decoder ,",
    "the collection of images @xmath73 should ideally be large enough so that every natural image @xmath9 is `` well - approximated '' by some image in @xmath73 .",
    "this requires a distance function over natural images in order to formalize `` well - approximate , '' but it is not clear what the distance function should be .",
    "we consider instead the following paradigm .",
    "suppose that the image stimulus @xmath9 that evoked the voxel response pattern is actually contained in @xmath73",
    ". then it may be possible for ( [ eqdecoding - model ] ) to recover @xmath9 exactly .",
    "this is the basic premise of the identification problem where we ask if the decoding rule can correctly identify @xmath9 from a set of candidates @xmath89 . within this paradigm ,",
    "we assess ( [ eqdecoding - model ] ) by its _ identification error rate _",
    ", @xmath90 on a future stimulus and voxel response pair @xmath91 that is independent of the training data .",
    "the identification error rate should increase as @xmath92 increases .",
    "however , the rate at which it increases will depend on the model used for estimating @xmath79 .",
    "we investigated this by starting with a database @xmath93 of @xmath94 images ( as in figure  [ fignatural - images ] ) that are similar to , but do not include , the images in the training data or validation data , and then repeating the following experiment for different choices of @xmath95 :    form @xmath73 by drawing a sample of size @xmath95 without replacement from @xmath93 .",
    "estimate the identification error rate ( [ eqid - error - rate ] ) using the 120 stimulus and voxel response pairs @xmath96 in the validation data .",
    "average the estimated identification error rate over all possible @xmath97 of size @xmath95 .",
    "the average identification error rate can be computed without resorting to monte carlo .",
    "given @xmath98 , @xmath99 if and only if @xmath100 for every @xmath101 . since",
    "@xmath73 is drawn by a simple random sample , the number of times that event ( [ eqscore ] ) occurs follows a hypergeometric distribution .",
    "so the conditional probability that ( [ eqcorrect - event ] ) occurs is just the probability that a hypergeometric random variable is equal to @xmath95",
    ". the parameters of this hypergeometric distribution are given by the number of images in @xmath93 that satisfy ( [ eqscore ] ) , the number of images in @xmath93 that do not satisfy ( [ eqscore ] ) , and @xmath95 . counting the number of images in @xmath93 that satisfy / do not satisfy ( [ eqscore ] ) is easy and only has to be done once for each @xmath9 in the validation data , regardless of @xmath95 .",
    "thus , the computation involves evaluating ( [ eqscore ] ) @xmath102 times ( since there are @xmath5 images in the validation data and @xmath94 images in @xmath103 ) , and then evaluating @xmath5 hypergeometric probabilities for each @xmath95 .    ) as a function of the number of possible images ( @xmath104 ) .",
    "the error rates were estimated using the validation data and @xmath105 randomly sampled from a database of @xmath94 images . ]",
    "figure  [ figdecoding - error - numberofimages ] shows the results of applying the preceding analysis to the fixed transformation models ( [ eqsqrt - model ] ) and ( [ eqlog - model ] ) and the v - spam model ( [ eqvspam ] ) . each model has its own subset of voxels @xmath84 used by the decoding rule .",
    "we set the training @xmath32 thresholds ( [ eqtraining - r2 ] ) so that the corresponding decoding rule used @xmath106 voxels for each model .",
    "when @xmath107 is small , identification is easy and all three models have very low error rates . as the number of possible images increases , the error rates of all three models increase but at different rates . at maximum ,",
    "when @xmath108 and there are @xmath109 candidate images ( @xmath94 images in @xmath110 plus @xmath51 correct image not in @xmath110 ) for the decoding rule to choose from , the fixed transformation models have an error rate of about @xmath111 , while the v - spam model has an error rate of about @xmath112 .",
    "c    ) as a function of the training @xmath32 threshold ( [ eqtraining - r2 ] ) when the number of possible images is @xmath113 . estimated identification error rate .",
    "the solid circles on each curve mark the points where the number of voxels used by the decoding rule is ( from left to right ) @xmath114 , @xmath115 or @xmath116 .",
    "pointwise 95% confidence bands for the difference between the identification error rates of ( upper ) @xmath24 model ( [ eqsqrt - model ] ) and v - spam ; ( lower ) @xmath31 model ( [ eqlog - model ] ) and v - spam . the confidence bands reflect uncertainty due to sampling variation of the validation data.,title=\"fig : \" ] + ( a ) + ) as a function of the training @xmath32 threshold ( [ eqtraining - r2 ] ) when the number of possible images is @xmath113 . estimated identification error rate .",
    "the solid circles on each curve mark the points where the number of voxels used by the decoding rule is ( from left to right ) @xmath114 , @xmath115 or @xmath116 .",
    "pointwise 95% confidence bands for the difference between the identification error rates of ( upper ) @xmath24 model ( [ eqsqrt - model ] ) and v - spam ; ( lower ) @xmath31 model ( [ eqlog - model ] ) and v - spam . the confidence bands reflect uncertainty due to sampling variation of the validation data.,title=\"fig : \" ] + ( b )    the ordering of and large gap between the fixed transformation models and v - spam at maximum does not depend on our choice of @xmath117 voxels .",
    "fixing @xmath108 so that the number of possible images is maximal , we examined how the identification error rate varies as the training @xmath32 threshold is varied .",
    "figure  [ figdecoding - error - r2 ] shows our results . the threshold corresponding to @xmath114 voxels is larger for v - spam than the fixed transformation models .",
    "it is about @xmath118 for v - spam and @xmath119 for the fixed transformation models .",
    "when the threshold is below @xmath120 , the error rates of the three models are indistinguishable .",
    "above @xmath120 , v - spam generally has a much lower error rate than the fixed transformation models . in panel ( a ) of figure  [ figdecoding - error - r2 ] we also see that v - spam can achieve an error rate lower than the best of the fixed transformation models with half as many voxels ( @xmath121 versus @xmath122 ) .",
    "these results show that the substantial improvements in voxel response prediction by v - spam can lead to substantial improvements in decoding accuracy .",
    "in computational neuroscience , the _ tuning function _ describes how the output of a neuron or voxel varies as a function of some specific stimulus feature [ @xcite ] . as such",
    ", the tuning function is a special case of an encoding model , and once an encoding model has been estimated , a tuning function can be extracted from the model by integrating out all of the stimulus features except for those of interest . in practice , this extraction is achieved by using an encoding model to predict responses to parametrized , synthetic stimuli .",
    "one way to assess the quality of an encoding model is to inspect the tuning functions that are derived from it [ @xcite ] .    for vision ,",
    "the most fundamental and important kind of tuning function is the spatial receptive field .",
    "each neuron ( or voxel ) in each visual area is sensitive to stimulus energy presented in a limited region of visual space , and spatial receptive fields describe how the response of the neuron or voxel is modulated over this region . in the primary visual cortex ,",
    "response modulation is typically strongest at the center of the receptive field .",
    "response modulation is much weaker at the periphery , but has been shown to have functionally significant effects on the output of the neuron ( or voxel ) [ @xcite ] .",
    "the panels in figure  [ figspatial - rf ] show estimated spatial receptive fields for voxel 717 using the three different models considered here [ we chose this voxel because its predictive @xmath32 varied greatly among the three models : 0.26 for the @xmath24 model ( [ eqsqrt - model ] ) , 0.42 for the @xmath31 ( [ eqlog - model ] ) , and 0.57 for v - spam ( [ eqvspam ] ) ] .",
    "these estimated receptive fields indicate the locations within the spatial field of view that are predicted to modulate the response of the voxel by each model .",
    "all three models agree that the voxel is tuned to a region in the lower - right quadrant of the field of view ; however , for v - spam the receptive field is more expansive , and is thus able to capture the weak but potentially important responses at the far periphery of the visual field .    like spatial tuning , orientation and frequency tuning",
    "are fundamental properties of v1 , so it is essential to inspect the orientation and frequency tuning functions that are derived from encoding models for this area . as seen in the panels of figure",
    "[ figfrequency - and - orientation - tuning ] , the v - spam model is better able to capture the weaker responses to orientations and spatial frequencies away from the peaks of the tuning .    finally , we examine tuning to image contrast , which is another critical property of v1 .",
    "image contrast strongly modulates responses in v1 and is also perceptually salient , so contrast tuning functions are frequently used to study the relationship between activity and perception [ @xcite ] .",
    "the contrast tuning function describes how a voxel is predicted to respond to different contrast levels .",
    "it is constructed by computing the predicted response to a stimulus of the form @xmath123 , where @xmath124 is standardized 2d pink noise ( whose power spectral density is of the form @xmath125 ) , and @xmath126 is the root - mean - square ( rms ) contrast . at zero contrast",
    "the noise is invisible and only the background can be seen ; as contrast increases the noise becomes more visible and distinguishable from the background .",
    "figure  [ figcontrast - tuning - function ] shows the contrast response function for the voxel as estimated by the three models .",
    "the first two , the @xmath24 and @xmath31 , look nearly linear and relatively flat over the range of contrasts present in the training images .",
    "the v - spam prediction tapers off as contrast increases , and it is much more negative for low contrasts than predicted by @xmath24 and @xmath31 . the v - spam prediction is closer to what is expected based on previous direct measurements [ @xcite ] , and suggests that v - spam is more sensitive to responses evoked by lower contrast stimulus energy .    .",
    "the tick marks indicate the deciles of rms contrast in the training images ( e.g. , fewer than @xmath127 of training images have contrast between @xmath128 and  @xmath129 ) . ]",
    "the relatively more sensitive tuning functions derived from the v - spam model of voxel 717 have a simple explanation .",
    "the models selected by bic for this voxel included different numbers of features : 7 for @xmath24 , 29 for @xmath31 , and 53 for v - spam .",
    "since the features are localized in space , frequency , and orientation , the number of features in the selected model is related to the sensitivity of the estimated tuning functions in the periphery .",
    "bic forces a trade - off between the residual sum of squares ( rss ) and number of features .",
    "the models with fixed transformations have much larger rss values than v - spam , and the trade - off ( see figure  [ figbic - comparison ] ) favors fewer features for them because the residual nonlinearity ( as shown in figure  [ figlinear - voxel - residuals ] ) does not go away with increased numbers of features .",
    "this suggests that the sensitivity of a voxel to weaker stimulus energy is not detected by the @xmath24 and @xmath31 models , because it is masked by residual nonlinearity .",
    "so the tuning function of a voxel can be much broader than inferred by the model when the model is incorrect .",
    "using residual analysis and a start - of - the - art sparse additive nonparametric method ( spam ) , we have derived v - spam encoding models for v1 fmri bold responses to natural images and demonstrated the presence of an important nonlinearity in v1 fmri response that has not been accounted for by previous models based on fixed parametric nonlinear transforms . this nonlinearity could be caused by several different mechanisms including the dynamics of blood flow and oxygenation in the brain and the underlying neural processes . by comparing v - spam models with the previous models , we showed that v - spam models can both improve substantially prediction accuracy for encoding and decrease substantially identification error when decoding from very large collections of images .",
    "we also showed that the deficiency of the previous encoding models with fixed parametric nonlinear transformations also affects tuning functions derived from the fitted models .",
    "model ( [ eqsqrt - model ] ) , the @xmath31 model ( [ eqlog - model ] ) , and v - spam ( [ eqvspam ] ) . ]",
    "since encoding and decoding models are becoming more prevalent in fmri studies , it is important to have methods to adequately characterize the nonlinear aspects of the response - stimulus relationship .",
    "failure to address nonlinearity effectively can lead to suboptimal predictions and incorrect inferences .",
    "the methods used here , combining residual analysis and sparse nonparametric modeling , can easily be adopted by neuroscientists studying any part of the brain with encoding and decoding models .",
    "the fmri signal @xmath130 measured at voxel @xmath8 can be modeled as a sum of three components : the bold signal @xmath131 , a nuisance signal @xmath132 ( consisting of low frequency fluctuations due to scanner drift , physiological noise , and other nuisances ) , and noise @xmath133 : @xmath134 the bold signal is a mixture of evoked responses to image stimuli .",
    "this reflects the underlying hemodynamic response that results from neuronal and vascular changes triggered by an image presentation .",
    "the hemodynamic response function @xmath135 characterizes the shape of the bold response ( see figure  [ fighrf ] ) , and is related to the bold signal by the linear time invariant system model [ @xcite ] , @xmath136 where @xmath44 is the number of images , @xmath137 is the set of times at which image @xmath138 is presented to the subject , and @xmath139 is the amplitude of the voxel s response to image  @xmath138 .        to extract @xmath140 from the fmri signal ,",
    "it is necessary to estimate the hemodynamic response function and the nuisance signal .",
    "we used the method described in @xcite , modeling @xmath135 as a linear combination of fourier basis functions covering a period of 16 seconds following stimulus onset , @xmath132 as a degree 3 polynomial , and @xmath133 as a first - order autoregressive process .",
    "the resulting estimates @xmath141 are the voxel responses for each image .",
    "a preliminary version of this work was presented in @xcite .",
    "we thank the editor and reviewer for valuable comments on an earlier version that have led to a much improved article ."
  ],
  "abstract_text": [
    "<S> functional mri ( fmri ) has become the most common method for investigating the human brain . however , fmri data present some complications for statistical analysis and modeling . </S>",
    "<S> one recently developed approach to these data focuses on estimation of computational encoding models that describe how stimuli are transformed into brain activity measured in individual voxels . </S>",
    "<S> here we aim at building encoding models for fmri signals recorded in the primary visual cortex of the human brain . </S>",
    "<S> we use residual analyses to reveal systematic nonlinearity across voxels not taken into account by previous models . </S>",
    "<S> we then show how a sparse nonparametric method [ _ j . </S>",
    "<S> roy . </S>",
    "<S> statist . </S>",
    "<S> soc . </S>",
    "<S> ser . </S>",
    "<S> b _ * 71 * ( 2009b ) 10091030 ] can be used together with correlation screening to estimate nonlinear encoding models effectively . </S>",
    "<S> our approach produces encoding models that predict about 25% more accurately than models estimated using other methods [ _ nature _ * 452 * ( 2008a ) 352355 ] . </S>",
    "<S> the estimated nonlinearity impacts the inferred properties of individual voxels , and it has a plausible biological interpretation . one benefit of quantitative encoding models is that estimated models can be used to decode brain activity , in order to identify which specific image was seen by an observer . </S>",
    "<S> encoding models estimated by our approach also improve such image identification by about 12% when the correct image is one of 11,500 possible images .    </S>",
    "<S> ,    ,    ,    ,    . </S>"
  ]
}