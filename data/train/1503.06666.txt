{
  "article_text": [
    "music summarization has been the subject of research for at least a decade and many algorithms that address this problem , mainly for popular music , have been published in the past @xcite . however , those algorithms focus on producing human consumption - oriented summaries , i.e. , summaries that will be listened to by people motivated by the need to quickly get the gist of the whole song without having to listen to all of it .",
    "this type of summarization entails extra requirements besides conciseness and diversity ( non - redundancy ) , such as clarity and coherence , so that people can enjoy listening to them .",
    "generic summarization algorithms , however , focus on extracting concise and diverse summaries and have been successfully applied in text and speech summarization @xcite .",
    "their application , in music , for human consumption - oriented purposes is not ideal , for they will select and concatenate the most relevant and diverse information ( according to each algorithm s definition of relevance and diversity ) without taking into account whether the output is enjoyable for people or not .",
    "this is usually reflected , for instance , on discontinuities or irregularities in beat synchronization in the resulting summaries .",
    "we focus on improving the performance of tasks recognized as important by the  community , e.g. music genre classification , through summarization , as opposed to considering music summaries as the product to be consumed by people .",
    "thus , we can ignore some of the requirements of previous music summarization efforts , which usually try to model the musical structure of the pieces being summarized , possibly using musical knowledge .",
    "although human - related aspects of music summarization are important in general , they are beyond the focus of this paper .",
    "we claim that , for  tasks benefiting from summaries , it is sufficient to consider the most relevant parts of the signal , according to its features . in particular , summarizers do not need to take into account song structure or human perception of music .",
    "our rationale is that summaries contain more relevant and less redundant information , thus improving the performance of tasks that rely on processing just a portion of the whole signal , leading to faster processing , less space usage , and efficient use of bandwidth .",
    "we use  @xcite , lexrank  @xcite ,  @xcite ,  @xcite , and support sets  @xcite to summarize music for automatic ( instead of human ) consumption . to evaluate the effects of summarization",
    ", we assess the performance of binary and 5-class music genre classification , when considering song summaries against continuous clips ( taken from the beginning , middle , and end of the songs ) and against the whole songs .",
    "we show that all of these algorithms improve classification performance and are statistically not significantly different from using the whole songs .",
    "these results complement and solidify previous work evaluated on a binary fado classifier  @xcite .",
    "the article is organized as follows : section [ sec : music - summarization ] reviews related work on music - specific summarization .",
    "section [ sec : generic - summarization ] reviews the generic summarization algorithms we experimented with :  ( section [ sub : grasshopper ] ) , lexrank ( section [ sub : lexrank ] ) ,  ( section [ sub : lsa ] ) ,  ( section [ sub : mmr ] ) , and support sets - based centrality ( section [ sub : support - sets ] ) . section [ sec : experiments ] details the experiments we performed for each algorithm and introduces the classifier .",
    "sections [ sec : binary - results ] and [ sec : multiclass - results ] report our classification results for the binary and multiclass classification scenarios , respectively .",
    "section [ sec : discussion ] discusses the results and section [ sec : conclusions ] concludes this paper with some remarks and future work .",
    "current algorithms for music summarization were developed to extract an enjoyable summary so that people can listen to it clearly and coherently .",
    "in contrast , our approach considers summaries exclusively for automatic consumption .",
    "human - oriented music summarization starts by structurally segmenting songs and selecting meaningful segments to include in the summary .",
    "the assumption is that songs are represented as label sequences where each label represents a different part of the song ( e.g. , ababca where a is the chorus , b the verse , and c the bridge ) . in @xcite ,",
    "segmentation is achieved by using a  to detect key changes between frames and  to detect repeating structure . in @xcite ,",
    "a gaussian - tempered `` checkerboard '' kernel is correlated along the main diagonal of the song s self - similarity matrix , outputting segment boundaries .",
    "then , a segment - indexed matrix , containing the similarity between detected segments , is built .",
    "is applied to find its rank-@xmath0 approximation .",
    "segments are , then , clustered to output the song s structure . in @xcite , a similarity matrix is built and analyzed for fast changes , outputting segment boundaries ; segments are clustered to output the `` middle states '' ; an  is applied to these states , producing the final segmentation . then , various strategies are considered to select the appropriate segments .    in @xcite , a modification of the  divergence",
    "is used to group and label similar segments .",
    "the summary consists of the longest sequence of segments belonging to the same cluster . in @xcite and @xcite ,",
    "average similarity is used to extract a thumbnail @xmath1 seconds long that is the most similar to the whole piece .",
    "it starts by calculating a similarity matrix through computing frame - wise similarities .",
    "then , it calculates an aggregated similarity measure , for each possible starting frame , of the @xmath1-second segment with the whole song and picks the one that maximizes it as the summary .",
    "another method for this task , maximum filtered correlation  @xcite , starts by building a similarity matrix and then a filtered time - lag matrix , embedding the similarity between extended segments separated by a constant lag .",
    "the starting frame of the summary corresponds to the index that maximizes the filtered time - lag matrix . in @xcite",
    ", music is classified as pure or vocal , in order to perform type - specific feature extraction .",
    "the summary , created from three to five seconds subsummaries ( built from frame clusters ) , takes into account musicological and psychological aspects , by differentiating between types of music based on feature selection and specific duration .",
    "this promotes human enjoyment when listening to the summary .",
    "since these summaries were targeted to people , they were evaluated by people .    in @xcite",
    ", music datasets are summarized into a codebook - based audio feature representation , to efficiently retrieve songs in a query - by - tag and query - by - example fashion .",
    "an initial dataset is discretized , creating a dictionary of @xmath2 basis vectors . then , for each query song , the audio signal is quantized , according to the pre - computed dictionary , mapping the audio signal into a histogram of basis vectors .",
    "these histograms are used to compute music similarity .",
    "this type of summarization allows for efficient retrieval of music but is limited to the features which are initially chosen .",
    "our focus is on audio signal summaries , which are suitable for any audio feature extraction , instead of proxy representations for audio features .",
    "applying generic summarization to music implies song segmentation into musical words and sentences .",
    "since we do not take into account human - related aspects of music perception , we can segment songs according to an arbitrarily fixed size .",
    "this differs from structural segmentation in that it does not take into account human perception of musical structure and does not create meaningful segments .",
    "nevertheless , it still allows us to look at the variability and repetition of the signal and use them to find its most important parts .",
    "furthermore , since it is not aimed at human consumption , the generated summaries are less liable to violate the copyrights of the original songs .",
    "this facilitates the sharing of datasets ( using the signal itself , instead of specific features extracted from it ) for  research efforts . in the following sections , we review the generic summarization algorithms we evaluated .",
    "[ [ sub : grasshopper ] ]    the  @xcite was applied to text summarization and social network analysis , focusing on improving ranking diversity .",
    "it takes an @xmath3 matrix @xmath4 representing a graph where each sentence is a vertex and each edge has weight @xmath5 corresponding to the similarity between sentences @xmath6 and @xmath7 ; and a probability distribution @xmath8 encoding prior ranking .",
    "first , @xmath4 is row - normalized : @xmath9",
    ". then , @xmath10 is built , incorporating the user - supplied prior ranking @xmath8 ( @xmath11 is an all-1 vector , @xmath12 is the outer product , and @xmath13 is a balancing factor ) . the first ranking state @xmath14 is found by taking the state with the largest stationary probability ( @xmath15 is the stationary distribution of @xmath16 ) . each time a state is extracted ,",
    "it is converted into an absorbing state to penalize states similar to it . the rest of the states are iteratively selected according to the expected number of visits to each state , instead of considering the stationary probability .",
    "if @xmath17 is the set of items ranked so far , states are turned into absorbing states by setting @xmath18 and @xmath19 , @xmath20 .",
    "if items are arranged so that ranked ones are listed before unranked ones , @xmath16 can be written as follows : @xmath21 @xmath22 is the identity matrix on @xmath17 .",
    "@xmath23 and @xmath24 are rows of unranked items .",
    "@xmath25 is the expected number of visits to state @xmath7 starting from state @xmath6 ( @xmath26 ) .",
    "the expected number of visits to state @xmath7 , @xmath27 , is given by @xmath28 and the next item is @xmath29 , where @xmath30 is the size of @xmath17 .",
    "lexrank @xcite relies on the similarity ( e.g. cosine ) between sentence pairs ( usually , _",
    "tf - idf _ vectors ) .",
    "first , all sentences are compared to each other . then , a graph is built where each sentence is a vertex and edges are created between every sentence according to their pairwise similarity ( above a threshold ) .",
    "lexrank can be used with both weighted ( eq .  [ eq : lex - rank - w ] ) and unweighted ( eq .  [ eq : lex - rank - u ] ) edges .",
    "then , each vertex score is iteratively computed . in eq .",
    "[ eq : lex - rank - w ] through [ eq : lex - rank - u ] , @xmath31 is a damping factor to guarantee convergence ; @xmath32 is the number of vertices ; @xmath33 is the score of vertex @xmath6 ; and @xmath34 is the degree of @xmath6 .",
    "summaries are built by taking the highest ranked sentences .    in lexrank",
    ", sentences recommend each other : sentences similar to many others will get high scores .",
    "scores are also determined by the score of the recommending sentences .",
    "@xmath35 @xmath36}\\frac{\\text{sim}\\left(v_{i},v_{j}\\right)}{\\sum_{v_{k}\\in adj\\left[v_{j}\\right]}\\text{sim}\\left(v_{j},v_{k}\\right)}s\\left(v_{j}\\right)\\ ] ] @xmath37}\\frac{s\\left(v_{j}\\right)}{d\\left(v_{j}\\right)}\\ ] ]    [ [ sub : lsa ] ]    was first applied in text summarization in @xcite .",
    "is used to reduce the dimensionality of an original matrix representation of the text .",
    "-based summarizers start by building a @xmath38 terms by @xmath32 sentences matrix @xmath39 .",
    "each element of @xmath39 , @xmath40 , has a local ( @xmath41 ) and a global ( @xmath42 ) weight .",
    "@xmath41 is a function of term frequency in a specific sentence and @xmath42 is a function of the number of sentences that contain a specific term .",
    "usually , @xmath43 are _ tf - idf _ scores .",
    "the result of applying the  to @xmath39 is @xmath44 , where @xmath45 ( @xmath46 matrix ) are the left singular vectors ; @xmath47 ( @xmath48 diagonal matrix ) contains the singular values in descending order ; and @xmath49 ( @xmath48 matrix ) are the right singular vectors .",
    "singular values determine topic relevance : each latent dimension corresponds to a topic .",
    "the rank-@xmath0 approximation considers the first @xmath0 columns of @xmath45 , the @xmath50 sub - matrix of @xmath47 , and the first @xmath0 rows of @xmath49 .",
    "relevant sentences are the ones corresponding to the indices of the highest values for each right singular vector .",
    "this approach has two limitations @xcite : by selecting @xmath0 sentences for the summary , less significant sentences tend to be extracted when @xmath0 increases ; and , sentences with high values in several topics , but never the highest , will never be included in the summary . to account for these effects , a sentence score was introduced and @xmath0 is chosen so that the @xmath51 singular value does not fall under half of the highest singular value : @xmath52 .",
    "[ [ sub : mmr ] ]    sentence selection in  @xcite is done according to their relevance and diversity against previously selected sentences , in order to output low - redundancy summaries .",
    "is a query - based method that has been used in speech summarization @xcite .",
    "it is also possible to produce generic summaries by taking the centroid vector of all the sentences as the query .",
    "uses @xmath53 to select sentences . @xmath54  and  @xmath55 are similarity metrics ( e.g. cosine ) ; @xmath56 and @xmath57 are unselected and previously selected sentences , respectively ; @xmath24 is the query , and @xmath13 balances relevance and diversity .",
    "sentences can be represented as _ tf - idf _ vectors .",
    "this method was first applied in text and speech summarization @xcite .",
    "centrality is based on sets of sentences that are similar to a given sentence ( support sets ) : @xmath58 .",
    "support sets are estimated for every sentence .",
    "sentences frequent in most support sets are selected : @xmath59 .",
    "this is similar to unweighted lexrank ( section [ sub : lexrank ] ) , except that support sets allow a different threshold for each sentence ( @xmath60 ) and their underlying representation is directed , i.e. , each sentence only recommends its most semantically related sentences . the thresholds can be heuristically determined .",
    "@xcite , among others , uses a passage order heuristic which clusters all passages into two clusters , according to their distance to each cluster s centroid .",
    "the first and second clusters are initialized with the first and second passages , respectively , and sentences are assigned to clusters , one by one , according to their original order .",
    "the cluster that contains the most similar passage to the passage associated with the support set under construction is selected as the support set .",
    "several metrics were tested for defining semantic relatedness ( e.g. minkowski distance , cosine ) .",
    "we evaluated generic summarization by assessing its impact on binary and multiclass music genre classification .",
    "these tasks consist of classifying songs based on a scheme ( e.g. artist , genre , or mood ) .",
    "classification is deemed important by the  community and annual conferences addressing it are held , such as , which comprises  @xcite for comparing state - of - the - art algorithms in a standardized setting .",
    "the best  2015 system @xcite  for the `` audio mixed popular genre classification '' task uses  for classifying music genre , based on spectral features .",
    "we follow the same approach and our classification is also performed using  @xcite .",
    "note that there are two different feature extraction steps .",
    "the first is done by the summarizers , every time a song is summarized . the summarizers output audio signal corresponding to the selected parts , to be used in the second step , i.e. , when doing classification , where features are extracted from the full , segmented , and summarized datasets .",
    "the features used by the  consist of a 38-dimensional vector per song , a concatenation of several statistics on features used in @xcite , describing the timbral texture of a music piece .",
    "it consists of the average of the first 20  concatenated with statistics ( mean and variance ) of 9 spectral features : centroid , spread , skewness , kurtosis , flux , rolloff , brightness , entropy , and flatness .",
    "these are computed over feature vectors extracted from 50ms frames without overlap .",
    "this set of features and a smaller set , solely composed of  averages , were tested in the classification task .",
    "all music genres in our dataset are timbrically different from each other , making these sets good descriptors for classification .",
    "our experimental datasets consist of a total of 1250 songs from 5 different genres : bass , fado , hip hop , trance , and indie rock .",
    "bass music is a generic term referring to several specific styles of electronic music , such as dubstep , drum and bass , electro , and more .",
    "although these differ in tempo , they share similar timbral characteristics , such as deep basslines and the `` wobble '' bass effect .",
    "fado is a portuguese music genre whose instrumentation consists of stringed instruments , such as the classical and the portuguese guitars .",
    "hip hop consists of drum rhythms ( usually built with samples ) , the use of turntables and spoken lyrics .",
    "indie rock usually consists of guitar , drums , keyboard , and vocal sounds and was influenced by punk , psychedelia , post - punk , and country .",
    "trance is an electronic music genre characterized by repeating melodic phrases and a musical form that builds up and down throughout a track .",
    "each class is represented by 250 songs from several artists .",
    "the multiclass dataset contains all songs .",
    "two binary datasets were also built from this data , in order to test our hypothesis on a wider range of classification setups : bass vs. fado and bass vs. trance , each containing the 500 corresponding songs .",
    "10-fold cross - validation was used in all classification tasks .",
    "first , as baselines , we performed 3 classification experiments using 30s segments , from the beginning , middle , and end of each song .",
    "then , we obtained another baseline by using the whole songs .",
    "the baselines were compared with the classification results from using 30s summaries for each parameter combination and algorithm .",
    "we did this for both binary datasets and then for the multiclass dataset .",
    "applying generic summarization algorithms to music requires additional steps .",
    "since these algorithms operate on the discrete concepts of word and sentence , some preprocessing must be done to map the continuous frame representation obtained after feature extraction to a word / sentence representation . for each song",
    "being summarized , a vocabulary is created , through clustering the frames feature vectors .",
    "mlpack s @xcite implementation of the @xmath0-means algorithm was used for this step ( we experiment with some values for @xmath0 and assess their impact on the results ) . after clustering ,",
    "a vocabulary of musical words is obtained ( each word is a frame cluster s centroid ) and each frame is assigned its own cluster centroid , effectively mapping the frame feature vectors to vocabulary words .",
    "this transforms the real / continuous nature of each frame ( when represented by a feature vector ) to a discrete nature ( when represented as a word from a vocabulary ) .",
    "then , the song is segmented into fixed - size sentences ( e.g. , 5-word sentences ) . since every sentence contains discrete words from a vocabulary , it is possible to represent each one as a vector of word occurrences / frequencies ( depending on the weighting scheme ) which is the exact representation used by generic summarization algorithms .",
    "sentences were compared using the cosine distance .",
    "the parameters of all of these algorithms include : features , framing , vocabulary size ( final number of clusters of the @xmath0-means algorithm ) , weighting ( e.g. , _ tf - idf _ ) , and sentence size ( number of words per sentence ) .    for the multiclass dataset , we also ran experiments comparing human - oriented summarization against generic summarization .",
    "this translates into comparing average similarity summaries ( for several durations ) against 30-second generic summaries , as well as comparing structural against fixed - size sentences .",
    "we also compared the performance of generic summaries against the baselines for smaller summary durations .",
    "every algorithm was implemented in c++ .",
    "we used : opensmile @xcite for feature extraction , armadillo @xcite for matrix operations , marsyas @xcite for synthesizing the summaries , and the segmenter used in @xcite for structural segmentation .",
    "our experiments covered the following parameter values ( varying between algorithms ) : frame and hop size combinations of ( 0.25,0.125 ) , ( 0.25,0.25 ) , ( 0.5,0.25 ) , ( 0.5,0.5 ) , ( 1,0.5 ) and ( 1,1 ) ( in seconds ) ; vocabulary sizes of 25 , 50 , and 100 ( words ) ; sentence sizes of 5 , 10 , and 20 ( words ) ; `` dampened '' _ tf - idf _ ( takes logarithm of _ tf _ instead of _",
    "tf _ itself ) and binary weighting schemes . as summarization features , we used  vectors of sizes 12 , 20 , and 24 .",
    "these features , used in several previous research efforts on music summarization in @xcite , describe the timbre of an acoustic signal .",
    "we also used a concatenation of  vectors with the 9 spectral features enumerated in section [ sub : features ] . for",
    ", we tried @xmath13 values of 0.5 and 0.7 .",
    "our  implementation also makes use of the sentence score and the topics cardinality selection heuristic described in section [ sub : lsa ] .",
    "first , we analyze results on the binary datasets , bass vs. fado and bass vs. trance . the reason we chose these pairs was because we wanted to see summarization s impact on an easy to classify dataset ( bass and fado are timbrically very different ) and a more difficult one ( bass and trance share many timbrical similarities due to their electronic and dancefloor - oriented nature ) .",
    "for all experiments , classifying using the 38-dimensional features vector produced better results than using only 20 , so we only present those results here .",
    "the best results are summarized in tables [ tab : binary - baselines ] , [ tab : bass - fado ] , and [ tab : bass - trance ] .",
    ".bass vs. trance summaries [ cols=\"^,^,^\",options=\"header \" , ]     [ tab : avg - sim ]        we can see that this type of summarization reaches the performance of generic summaries ( 30 seconds ) and full songs when the summary duration reaches 80 seconds ( 89.2% accuracy ) .",
    "this means that , for a human - oriented summary to be as descriptive and discriminative as a generic summary , an additional 50 seconds ( 2.67 times the length of the original ) are needed .",
    "even though the starting point of this contiguous summary is carefully selected by this algorithm , it still lacks diversity because of its contiguous nature , hindering classification accuracy for this summarizer .",
    "naturally , by extending summary duration , summaries include more diverse information , eventually achieving the accuracy of full songs .",
    "another form of human - oriented summarization is achieved by using generic summarization operating on structurally segmented sentences , done according to what humans might consider to be structurally meaningful segments .",
    "after structural segmentation , we fed each of the 5 generic algorithms with the resulting sentences instead of fixed - size ones and truncated the summary at 30 seconds , when necessary .",
    "the parameterization used for these experiments was the one that yielded the best results in the previous experiments for each algorithm .",
    "the accuracy results for , lexrank , , , and support sets were , respectively , 82.64% , 83.76% , 81.84% , 82.40% , and 83.84% . even though structurally segmented sentences slightly improve performance , when considering classification accuracy , they are still outperformed by fixed - size segmentation .",
    "the best algorithm can only achieve 83.84% accuracy .",
    "this is because these sentences are much longer , therefore harming diversity in summaries .",
    "furthermore , important content in structural sentences can always be extracted when using smaller fixed - size sentences .",
    "thus , using smaller sentences , prevents the selection of redundant content .",
    "we ran the wilcoxon signed - ranked test on all of the confusion matrices presented above against the full songs scenario .",
    "the continuous sections p - values were @xmath61 , @xmath62 , and @xmath63 for the 30-second beginning , middle , and end sections of the songs , respectively , which means that they differ markedly from using full songs ( as can also be seen by the accuracy drops they cause ) .",
    "the summaries , however , were very close to full songs , in terms of accuracy .",
    "the p - values for , lexrank , , , and support sets were @xmath64 , @xmath65 , @xmath66 , @xmath67 , and @xmath68 , respectively .",
    "thus , statistically speaking , using any of these 30-second summaries does not significantly differ from using full songs for classification ( considering 95% confidence intervals ) .",
    "furthermore , the p - values for 20-second  summaries and for 10-second support sets summaries were @xmath69 and @xmath70 , respectively , with the remaining p - values of increasing summary sizes also being superior to @xmath71 .",
    "thus , statistically speaking , generic summarization ( in some cases ) does not significantly differ from using full songs for classification , for summaries as short as 10 seconds ( considering a 95% confidence interval ) .",
    "this is noteworthy , considering that the average song duration in this dataset is 283 seconds , which means that we achieve similar levels of classification performance using around 3.5% of the data .",
    "human - oriented summarization is able to achieve these performance levels , but only at 50-second summaries and with a p - value of @xmath72 , barely over the @xmath71 threshold .",
    "however , the 60-second summaries produced by this algorithm can not reach that threshold . only at 80 seconds",
    "is a comfortable p - value ( @xmath73 ) for the 95% confidence interval attained .",
    "although every algorithm creates summaries in a different way , they all tend to include relevant and diverse sentences .",
    "this compensates their reduced lengths ( up to 30 seconds of audio ) allowing those clips to be representative of the whole musical pieces , from an automatic consumption view , as demonstrated by our experiments .",
    "moreover , choosing the best 30-second contiguous segments is highly dependent on the genres in the dataset and tasks it will be used for , which is another reason for preferring summaries over those segments .",
    "the more varied the dataset , the less likely a fixed continuous section extraction method is to produce representative enough clips .",
    "bass and trance were the most influenced genres , by summarization , in these experiments .",
    "these are styles with very well defined structural borders , and a very descriptive structural element  the _ drop_. the lack of that same element in a segment markedly hinders classification performance , suggesting that any genre with similar characteristics may also benefit from this type of summarization .",
    "it is also worth restating that hip hop and indie rock were very positively influenced by summarization , regarding classification performance improvements over using full songs .",
    "this shows that , sometimes , classification on summarized music can even outperform using the whole data from the original signal .",
    "we also demonstrated that generic summarization using fixed - size sentences , that is , summarization not specifically oriented towards human consumption greatly outperforms human - oriented summarization approaches for the classification task .",
    "summarizing music prior to the classification task also takes time , but we do not claim it is worth doing it every time we are about do perform a  task .",
    "the idea is to compute summarized datasets offline for future use in any task that can benefit from them ( e.g. , music classification ) .",
    "currently , sharing music datasets for  research purposes is very limited in many aspects , due to copyright issues .",
    "usually , datasets are shared through features extracted from ( 30-second ) continuous clips .",
    "that practice has drawbacks , such as : those 30 seconds may not contain the most relevant information and may even be highly redundant ; and the features provided may not be the ones a researcher needs for his / her experiments . summarizing datasets",
    "this way also helps avoiding copyright issues ( because summaries are not created in a way enjoyable by humans ) and still provide researchers with the most descriptive parts ( according to each summarizer ) of the signal itself , so that many different kinds of features can be extracted from them .",
    "we showed that generic summarization algorithms perform well when summarizing music datasets about to be classified .",
    "the resulting summaries are remarkably more descriptive of the whole songs than their continuous segments ( of the same duration ) counterparts .",
    "sometimes , these summaries are even more discriminative than the full songs .",
    "we also presented an argument stating some advantages in sharing summarized datasets within the  community .",
    "an interesting research direction would be to automatically determine the best vocabulary size for each song .",
    "testing summarization s performance on different classification tasks ( e.g. , with more classes ) is also necessary to further strengthen our conclusions .",
    "more comparisons with non - contiguous human - oriented summaries should also be done .",
    "more experimenting should be done in other  tasks that also make use of only a portion of the whole signal .",
    "m.  cooper and j.  foote , `` summarizing popular music via structural similarity analysis , '' in _ proc . of the ieee workshop on applications of signal processing to audio and acoustics _ ,",
    "2003 , pp . 127130 .",
    "j.  carbonell and j.  goldstein , `` the use of mmr , diversity - based reranking for reordering documents and producing summaries , '' in _ proc . of the 21st annual intl .",
    "acm sigir conf . on research and development in information retrieval _ , 1998 , pp .",
    "335336 .",
    "t.  k. landauer and s.  t. dutnais , `` a solution to plato s problem : the latent semantic analysis theory of acquisition , induction , and representation of knowledge , '' _ psychological review _ , vol .",
    "104 , no .  2 ,",
    "pp . 211240 , 1997 .",
    "x.  zhu , a.  b. goldberg , j.  v. gael , and d.  andrzejewski , `` improving diversity in ranking using absorbing random walks , '' in _ proc . of the 5th north american chapter of the association for computational linguistics - human language technologies conf .",
    "_ , 2007 , pp . 97104 .",
    "y.  vaizman , b.  mcfee , and g.  lanckriet , `` codebook - based audio feature representation for music information retrieval , '' _ ieee / acm trans . on audio , speech and language processing _ ,",
    "22 , pp . 14831493 , 2014 .",
    "y.  gong and x.  liu , `` generic text summarization using relevance measure and latent semantic analysis , '' in _ proc . of the 24th annual intl .",
    "acm sigir conf . on research and development in information retrieval _ , 2001 , pp .",
    "1925 .",
    "k.  zechner and a.  waibel , `` minimizing word error rate in textual summaries of spoken language , '' in _ proc . of the 1st north american chapter of the association for computational linguistics",
    "_ , 2000 , pp",
    ". 186193 .",
    "wu and j .- s .",
    "r. jang , `` combining acoustic and multilevel visual features for music genre classification , '' _ acm trans . on multimedia computing , communications and applications _",
    "12 , no .  1 ,",
    "pp . 10:110:17 , 2015 .",
    "r.  r. curtin , j.  r. cline , n.  p. slagle , w.  b. march , p.  ram , n.  a. mehta , and a.  g. gray , `` mlpack : a scalable c++ machine learning library , '' _ journal of machine learning research _ , vol .",
    "14 , no .  1 ,",
    "pp . 801805 , 2013 .",
    "f.  eyben , f.  weninger , f.  gross , and b.  schuller , `` recent developments in opensmile , the munich open - source multimedia feature extractor , '' in _ proc . of the 21st acm intl .",
    "conf . on multimedia _ , 2013 , pp .",
    "835838 .",
    "francisco raposo graduated in information systems and computer engineering ( 2012 ) from instituto superior tcnico ( ist ) , lisbon .",
    "he received a masters degree in information systems and computer engineering ( 2014 ) ( ist ) , on automatic music summarization .",
    "he s currently pursuing a phd course on information systems and computer engineering .",
    "his research interests focus on music information retrieval ( mir ) , music emotion recognition , and creative - mir applications .",
    "ricardo ribeiro has a phd ( 2011 ) in information systems and computer engineering and an msc ( 2003 ) in electrical and computer engineering , both from instituto superior tcnico , and a graduation degree ( 1996 ) in mathematics / computer science from universidade da beira interior .",
    "his current research interests focus on high - level information extraction from unrestricted text or speech , and improving machine - learning techniques using domain - related information .",
    "david martins de matos graduated in electrical and computer engineering ( 1990 ) from instituto superior tcnico ( ist ) , lisbon .",
    "he received a masters degree in electrical and computer engineering ( 1995 ) ( ist ) .",
    "he received a doctor of engineering degree in systems and computer science ( 2005 ) ( ist ) .",
    "his current research interests focus on computational music processing , automatic summarization and natural language generation , human - robot interaction , and natural language semantics ."
  ],
  "abstract_text": [
    "<S> in order to satisfy processing time constraints , many  tasks process only a segment of the whole music signal . </S>",
    "<S> this may lead to decreasing performance , as the most important information for the tasks may not be in the processed segments . </S>",
    "<S> we leverage generic summarization algorithms , previously applied to text and speech , to summarize items in music datasets . </S>",
    "<S> these algorithms build summaries ( both concise and diverse ) , by selecting appropriate segments from the input signal , also making them good candidates to summarize music . </S>",
    "<S> we evaluate the summarization process on binary and multiclass music genre classification tasks , by comparing the accuracy when using summarized datasets against the accuracy when using human - oriented summaries , continuous segments ( the traditional method used for addressing the previously mentioned time constraints ) , and full songs of the original dataset . </S>",
    "<S> we show that , lexrank , , , and a support sets - based centrality model improve classification performance when compared to selected baselines . we also show that summarized datasets lead to a classification performance </S>",
    "<S> whose difference is not statistically significant from using full songs . </S>",
    "<S> furthermore , we make an argument stating the advantages of sharing summarized datasets for future  research . </S>"
  ]
}