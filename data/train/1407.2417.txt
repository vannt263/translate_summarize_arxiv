{
  "article_text": [
    "paper considers multimessage multicast networks ( mmns ) ( * ? ? ?",
    "* chapter 18 ) in which the destination nodes want to decode the same set of messages transmitted by the source nodes .",
    "a well - known outer bound on the capacity region of the discrete memoryless mmn ( dm - mmn ) is the _ cut - set bound _ , developed by el gamal in 1981  @xcite .",
    "this bound states that for any cut @xmath0 of the network with nodes indexed by @xmath1 , the sum of the achievable rates of messages on one side of the cut is upper bounded by the conditional mutual information of the input variables in @xmath0 and the output variables in @xmath2 given the input variables in @xmath3 .",
    "the dm - mmn is a generalization of the well - studied discrete memoryless relay channel ( dm - rc ) @xcite .",
    "it is known that the cut - set bound is not tight in general @xcite , but it is tight for several classes of dm - mmns , including the physically degraded dm - rc  @xcite , the semi - deterministic dm - rc  @xcite , the deterministic relay network with no interference @xcite , the finite - field linear deterministic network @xcite and the wireless erasure network @xcite .",
    "one potential drawback of the cut - set bound is the fact if it is tight , i.e. , there exists a matching achievable inner bound , this only implies a _ weak converse _ for the problem . in other words , it only guarantees that for all rate tuples not belonging to the region prescribed by the cut - set bound , the average error probability in decoding the transmitted messages is bounded away from zero as the block length of any code tends to infinity . in information theory , it is also important to establish _ strong converses _ as such definitive statements indicate that there is a sharp phase transition between rate tuples that are achievable and those that are not .",
    "a strong converse implies that for all codes with rate tuples that are in the exterior of the region prescribed by the fundamental limit , the error probability must necessarily tend to one .",
    "the contrapositive of this statement can be stated as follows : all codes whose error probabilities are no larger than @xmath4 as the block length grows , i.e. , @xmath5-reliable codes , must have rate tuples belonging to the region prescribed by the fundamental limit ( in our case , a looser version of the cut - set bound that is tight for some dm - mmns ) .",
    "this is clearly a stronger statement than the weak converse which considers codes with vanishing error probabilities .",
    "the main contribution of this work is a self - contained proof of the strong converse for some classes of dm - mmns in which the cut - set bound is tight .",
    "these classes of dm - mmns include deterministic relay networks with no interference @xcite , finite - field linear deterministic networks @xcite and wireless erasure networks @xcite .",
    "so for example , for wireless erasure networks studied by dana , gowaiker , palanki , hassibi and effros @xcite , all sequences of codes with rates above the capacity have average error probabilities that necessarily tend to one as the block length grows .",
    "the authors of  @xcite proved using fano s inequality  ( * ? ? ?",
    "* section  2.10 ) that all codes with rates above capacity have average error probabilities that are bounded away from zero .",
    "thus , a consequence of our main result is an important strengthening of the converse in ( * ? ? ?",
    "* theorem 2 ) .",
    "in addition , we show , using our main theorem , that the strong converse holds for _ dm - mmns consisting of independent discrete memoryless channels ( dmcs ) _ and _ single - destination dm - mmns consisting of independent dmcs with destination feedback_. our main result implies that for the aforementioned dm - mmns , rate tuples of @xmath5-reliable codes where @xmath6 must belong to the region prescribed by the cut - set bound  @xcite .    the technique that we employ",
    "is based on properties of the rnyi divergence @xcite .",
    "this is a powerful technique for establishing strong converses in information theory .",
    "it has been employed previously to establish strong converses for point - to - point memoryless dmcs with output feedback  @xcite , classical - quantum channels  @xcite and most recently , entanglement - breaking quantum channels  @xcite .",
    "we were inspired to use the rnyi divergence technique for our strong converse proof because of the similarities of dm - mmns to channels with full output feedback as shown in the context of sphere - packing bounds on the reliability function for the dm - rc in  @xcite .",
    "the papers that are most closely related to the present work are the ones by behboodi and piantanida who conjectured that the strong converse holds for dm - rcs  @xcite and general dm multicast networks  @xcite . also see appendix  c in the thesis by behboodi  @xcite .",
    "it appears to the present authors , however , that some steps in the justifications , which are based on the information spectrum method @xcite , are incomplete .",
    "therefore , we are motivated to provide a strong converse for some ( albeit somewhat restrictive ) classes of dm - mmns using a completely different and elementary method  namely , the rnyi divergence approach @xcite .",
    "as mentioned by polyanskiy and verd  @xcite , this approach is arguably the simplest method for proving that memoryless channels with feedback satisfy the strong converse and thus , we are inspired to leverage it to prove the strong converse for some classes of dm - mmns .",
    "this paper is organized as follows .",
    "section  [ notation ] presents the notation used in this paper .",
    "section  [ sectiondefinition ] provides the problem formulation of the dm - mmns and presents our main theorem .",
    "section  [ sectionrenyi ] introduces the rnyi divergence and discusses its important properties .",
    "section  [ sectionsimulatingdistribution ] contains an important lemma concerning _ simulating distributions _ which is used in the proof of our main theorem .",
    "section  [ sectionmainresult ] presents the proof of our main theorem .",
    "we also compare and contrast our proof with the proof of the usual cut - set bound which only implies a weak converse . in section  [ sectionmmnwithtightcutset ]",
    ", we discuss the above - mentioned classes of dm - mmns whose cut - set bounds are tight , and we use our main theorem to prove the strong converse for them .",
    "we conclude our discussion and suggest avenues for future research in section  [ sec : conclu ] .",
    "proofs of the more technical auxiliary results are relegated to the appendices .",
    "we use @xmath7 to represent the probability of an event  @xmath8 , and we let @xmath9 be the characteristic function of @xmath8 .",
    "we use a capital letter  @xmath10 to denote a random variable with alphabet @xmath11 , and use the small letter @xmath12 to denote a realization of  @xmath10 .",
    "we use @xmath13 to denote a random vector @xmath14 $ ] , where the components @xmath15 have the same alphabet  @xmath11 .",
    "we let @xmath16 and @xmath17 denote the probability mass distribution of @xmath10 and the conditional probability mass distribution of @xmath18 given @xmath10 respectively for any discrete random variables  @xmath10 and  @xmath18 . for any mapping @xmath19 whose domain includes @xmath11 , we let @xmath20 denote the probability mass distribution of @xmath21 when @xmath10 is distributed according to @xmath16 . we let @xmath22 and @xmath23 be the evaluations of @xmath16 and @xmath17 respectively at @xmath24 and @xmath25 .",
    "we let @xmath26 denote the joint distribution of @xmath27 , i.e. , @xmath28 for all @xmath12 and @xmath29 .",
    "if @xmath10 and @xmath18 are independent , their joint distribution is simply @xmath30 . for simplicity",
    ", we drop the subscript of a notation if there is no ambiguity",
    ". we will take all logarithms to base 2 , and we will use the convention that @xmath31 and @xmath32 throughout this paper",
    ". for any discrete random variable @xmath33 distributed according to @xmath34 , we let @xmath35 and @xmath36 be the entropy of @xmath10 given @xmath37 and mutual information between @xmath10 and @xmath18 given @xmath37 respectively .",
    "the @xmath38-distance between two distributions @xmath16 and @xmath39 on the same discrete alphabet @xmath11 , denoted by @xmath40 , is defined as @xmath41 . if @xmath10 , @xmath18 and @xmath37 are distributed according to @xmath34 and they form a markov chain , we write @xmath42 or more simply , @xmath43 .",
    "we consider a dm - mmn that consists of @xmath44 nodes .",
    "let @xmath45 be the index set of the nodes , and let @xmath46 and @xmath47 be the sets of sources and destinations respectively .",
    "we call @xmath48 the _ multicast demand _ on the network .",
    "the sources in @xmath49 transmit information to the destinations in @xmath50 in @xmath51 time slots ( channel uses ) as follows .",
    "node  @xmath52 transmits message @xmath53 for each @xmath54 and node @xmath55 , for each @xmath56 , wants to decode @xmath57 , where @xmath58 denotes the rate of message @xmath59 .",
    "we assume that each message @xmath59 is uniformly distributed over @xmath60 and all the messages are independent .",
    "for each time slot @xmath61 and each @xmath62 , node  @xmath52 transmits @xmath63 , a function of @xmath64 , and receives , from the output of a channel , @xmath65 where @xmath66 and @xmath67 are some alphabets that possibly depend on  @xmath52 .",
    "after  @xmath51 time slots , node  @xmath55 declares  @xmath68 to be the transmitted  @xmath59 based on @xmath69 for each @xmath70 .    to simplify notation , we use the following conventions for each @xmath71 : for any random tuple @xmath72 we let @xmath73 be a subtuple of @xmath74 .",
    "similarly , for any @xmath61 and any random tuple @xmath75 we let @xmath76 be a subtuple of @xmath77 . for any @xmath78-dimensional random tuple @xmath79 , we let @xmath80 be a subtuple of @xmath79 .",
    "the following six definitions formally define a dm - mmn and its capacity region .",
    "[ discretememoryless ] a discrete network consists of @xmath44 finite input sets @xmath81 , @xmath44 finite output sets @xmath82 and a conditional distribution @xmath83 . the discrete network is denoted by @xmath84 .",
    "[ defcode ] let @xmath84 be a discrete network , and let @xmath48 be the multicast demand on the network .",
    "an @xmath85-code , where @xmath86 denotes the tuple of code rates @xmath87 , for @xmath51 uses of the network consists of the following :    1 .",
    "a message set @xmath88 at node  @xmath52 for each @xmath62 , where @xmath89 for each @xmath90 .",
    "message @xmath91 is uniform on @xmath92 .",
    "an encoding function @xmath93 for each @xmath62 and each @xmath94 , where @xmath95 is the encoding function at node  @xmath52 in the @xmath96 time slot such that @xmath97 3 .",
    "a decoding function @xmath98 for each @xmath99 , where @xmath100 is the decoding function for message @xmath59 at node  @xmath55 such that @xmath101    since the encoder @xmath95 can depend on the `` feedback signal '' @xmath102 , we are allowing full output feedback for each of the transmitting nodes ; cf .  section [ sectionwithfeedback ] .",
    "in addition , the definition of  @xmath95 allows every node to process information in a causal way with a delay of one unit .",
    "[ memoryless ] a discrete network @xmath84 with multicast demand @xmath48 , when used multiple times , is called a _ discrete memoryless multimessage multicast network ( dm - mmn ) _ if the following holds for any @xmath103-code :    for all @xmath71 , we define @xmath104 , the marginal distribution of channel @xmath105 , as follows : @xmath106 for all @xmath107 and @xmath108",
    ". let @xmath109 be the collection of random variables that are generated before the @xmath96 time slot .",
    "then , for each @xmath94 and each @xmath71 , @xmath110 for all @xmath111 , @xmath112 and @xmath113",
    ".    [ cutseterrorprobability ] for an @xmath103-code defined on the dm - mmn with multicast demand @xmath48 , the _ average probability of decoding error _ is defined as @xmath114 we call an @xmath103-code with average probability of decoding error not exceeding @xmath115 an _",
    "@xmath116-code_.    [ cutsetachievable rate ] a rate tuple @xmath117 is _",
    "@xmath5-achievable _ for the dm - mmn with multicast demand @xmath48 if there exists a sequence of @xmath116-codes for the dm - mmn such that @xmath118    [ cutsetcapacity region ] the _ @xmath5-capacity region _",
    "( for @xmath6 ) of the dm - mmn with multicast demand @xmath48 , denoted by @xmath119 , is the set consisting of all @xmath5-achievable rate tuples @xmath117 with @xmath120 for all @xmath90 .",
    "capacity region _ is defined to be the 0-capacity region @xmath121 .",
    "the following theorem is the main result in this paper .",
    "[ thmmainresult ] let @xmath84 be a dm - mmn with multicast demand @xmath48 .",
    "define @xmath122{2.4in}{$ \\sum _ { i\\in t } r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{rout}\\ ] ] then for each @xmath6 , @xmath123",
    "we now make a couple of remarks concerning theorem  [ thmmainresult ] .",
    "first , define the usual cut - set bound ( * ? ? ?",
    "* theorem 18.1 ) @xmath124{2.4in}{$ \\sum _",
    "{ i\\in t } r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{rcutset}\\ ] ] it is well known that @xmath125 is an outer bound on the capacity region , i.e. , that @xmath126 note that @xmath127 is similar to @xmath125 except that the union and the intersection operations are interchanged .",
    "consequently , @xmath127 is potentially looser ( larger ) than the @xmath125 .",
    "this discrepancy is briefly explained as follows : the proof of theorem  [ thmmainresult ] ( i.e. , the bound in ) leverages the properties of the rnyi divergence , while the proof of the cut - set bound ( i.e. , the bound in ) is based on fano s inequality ( * ? ? ?",
    "* theorem 18.1 ) . for both proofs ,",
    "the first step is to fix an achievable rate tuple @xmath86 and a sequence of @xmath85-codes .",
    "next a cut @xmath71 that satisfies @xmath128 is also fixed . in both proofs , we eventually arrive at the bound @xmath129 for some @xmath130 , which implies that @xmath131{2.35 in}{$ \\sum _ { i\\in t } r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}^{(t)}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{derivationcutset*}\\ ] ] however , the proofs of bounds and yield under different assumptions on the asymptotic behavior of the average error probability @xmath5 . for the proof of the cut - set bound , it is assumed that @xmath132 and hence using fano s inequality combined with properties of the relative entropy and the conditional mutual information such as the chain rule are sufficient for proving .",
    "using fano s inequality , @xmath130 can be shown to be the limit of the sequence of empirical input distributions induced by the sequence of codes ( if the limit does not exist , we can always consider a convergent subsequence instead and the following arguments go through in a similar way ) .",
    "in other words , @xmath133 this implies that @xmath134 does _ not _ depend on  @xmath0 and hence the union and the intersection operations in can be interchanged , resulting in an improved bound .",
    "in contrast , for the proof of our bound , it is assumed that @xmath6 and hence we need to use properties of the rnyi divergence to prove .",
    "since @xmath134 _ does _ depend on  @xmath0 in general for the proof involving the rnyi divergence , the union and the intersection operations in can not be interchanged in general , which prevents us from further strengthening the bound in . in section  [ sec : fano ] , we further elaborate on the similarities of and differences between the proofs of our bound and the cut - set bound .",
    "second , although @xmath127 is potentially looser than the cut - set bound , it can be shown that @xmath135 for some classes of networks including the deterministic relay networks with no interference @xcite , the finite - field linear deterministic networks @xcite and the wireless erasure networks @xcite ( discussed in section  [ sectionmulticastnetworks ] ) , the class of dm - mmns consisting of independent dmcs ( discussed in section  [ sectiondm - mmnconsistingofdmcs ] ) and the class of single - destination dm - mmns consisting of independent dmcs with destination feedback ( discussed in section [ sectionwithfeedback ] ) .",
    "therefore , theorem  [ thmmainresult ] implies the strong converses for these networks .",
    "we briefly outline the content in the sections to follow : the proof of theorem  [ thmmainresult ] leverages properties of the rnyi divergence , which we discuss in section  [ sectionrenyi ] . in section  [ sectionsimulatingdistribution ]",
    ", we construct so - called _ simulating distributions _ , which form an important part of the proof of theorem  [ thmmainresult ] .",
    "the details of the proof of theorem  [ thmmainresult ] are provided in section  [ sectionmainresult ] .",
    "readers who are only interested in the the application of theorem [ thmmainresult ] to specific channel models may proceed directly to section [ sectionmmnwithtightcutset ] .",
    "the following definitions of ( conditional ) relative entropy and ( conditional ) rnyi divergence are standard  @xcite .",
    "[ defrenyidivergence ] let @xmath136 and @xmath137 be two probability distributions on @xmath11 , and let @xmath138 be a probability distribution on @xmath139 .",
    "let @xmath140 be the _ relative entropy _ between @xmath16 and @xmath39 , and",
    "let @xmath141 be the _",
    "conditional relative entropy _ between @xmath142 and @xmath143 conditioned on @xmath138 .",
    "then , the _ rnyi divergence with parameter _",
    "@xmath144 between @xmath136 and @xmath137 , denoted by @xmath145 , is defined as follows : @xmath146 in addition , the _",
    "conditional rnyi divergence with parameter _",
    "@xmath144 between @xmath142 and @xmath143 given @xmath138 , denoted by @xmath147 , is defined as follows : @xmath148 note that for @xmath149 , @xmath150 can be expressed in terms of the unconditional rnyi divergence as @xmath151    we summarize two important properties of @xmath147 in the following theorem , whose proof can be found in ( * ? ? ?",
    "* theorems 5 and 9 ) .    [ thmrenyidivergence ] for any @xmath144 , the following statements hold for any two conditional probability distributions @xmath152",
    ", @xmath153 and any probability distribution @xmath138 :    * ( continuity ) @xmath154 is continuous in @xmath155 . *",
    "( data processing inequality ( dpi ) ) @xmath156 for any function @xmath19 with domain @xmath11 .",
    "in particular , @xmath157 .",
    "most converse theorems use fano s inequality ( * ? ? ?",
    "* section  2.10 ) to obtain a lower bound on the error probability .",
    "however , this can only lead to weak converse results .",
    "the following proposition , analogous to fano s inequality , enables us to prove strong converse results by providing a better lower bound on the error probability .",
    "essentially , we have the freedom to choose any @xmath158 in the bound in   below .",
    "[ propositiondlambdalowerbound ] let @xmath159 be a probability distribution defined on @xmath160 for some @xmath161 , and let @xmath162 be the marginal distribution of @xmath159 .",
    "in addition , let @xmath163 be a distribution defined on @xmath161 .",
    "suppose @xmath164 is the uniform distribution , and let @xmath165 be a real number in @xmath166 .",
    "then for each @xmath167 , @xmath168    fix a @xmath167 and let @xmath169 .",
    "consider the following chain of inequalities : @xmath170 where    1",
    ".   follows from the dpi in theorem  [ thmrenyidivergence ] ; 2 .   follows from definition  [ defrenyidivergence ] and the facts that @xmath171 3",
    ".   follows from the fact that @xmath172 .",
    "this completes the proof .",
    "the following proposition enables us to approximate the conditional rnyi divergence @xmath173 by the conditional relative entropy @xmath174 .",
    "since the proof for the following proposition is straightforward but involves some tedious algebra , we defer it to appendix  [ appendixa ] .",
    "[ propositiondlambdatomutualinfo ] let @xmath175 $ ] be a real number , and let @xmath34 be a probability distribution defined on @xmath176 .",
    "then , @xmath177    we made no attempt to optimize the remainder term @xmath178 as the important part of the statement is that this remainder term is uniform in @xmath34 on a sufficiently small interval to the right of @xmath179 .",
    "in fact , it only depends on the product @xmath180 .",
    "proposition  [ propositiondlambdalowerbound ] provides a lower bound for the error probability , and the lower bound holds for all @xmath181 .",
    "therefore , we are motivated to choose a _ simulating distribution _",
    "@xmath181 so that the left hand side of can be simplified . before describing the simulating distribution , we state the following proposition which facilitates to characterize an important property of markov chains .    [ propositionmcsimplification ]",
    "suppose there exist two probability distributions @xmath182 and @xmath183 such that @xmath184 for all @xmath12 , @xmath29 and @xmath185 whenever @xmath186 .",
    "then @xmath187 forms a markov chain .",
    "in addition , @xmath188    the proof of is contained ( * ? ? ? * proposition  2.5 ) .",
    "it remains to show .",
    "summing @xmath12 and then @xmath185 on both sides of , we have @xmath189 and @xmath190 for all @xmath12 , @xmath29 and @xmath185 whenever @xmath186 , which implies .",
    "the construction of the simulating distribution is contained in the following lemma . before stating lemma",
    ", we make the following definitions : given an @xmath191-code , we let @xmath192 be the probability distribution induced by the code according to definitions  [ defcode ] and  [ memoryless ] . in the following ,",
    "we drop the subscripts of the probability distributions to simplify notation . for each @xmath193 and each @xmath194 , recalling that @xmath195 denotes the channel of the dm - mmn defined in definition  [ memoryless ] , we define @xmath196 .",
    "then , we define @xmath197 and @xmath198 for @xmath199 based on @xmath200 as follows : for all @xmath201 and @xmath113 , let @xmath202 and @xmath203 it can be verified by using , and that @xmath204 , and hence @xmath198 can be viewed as a tilted version of @xmath205 .",
    "more specifically , we can see from that @xmath197 can be viewed as a weighted version of @xmath206 where the weighting distribution is a tilting of @xmath207 towards @xmath208 .",
    "[ lemmasimulatingdistribution ] given an @xmath191-code for the dm - mmn , let @xmath192 be the probability distribution induced by the code according to definitions  [ defcode ] and  [ memoryless ] .",
    "let @xmath0 be an arbitrary subset of @xmath1 and fix an arbitrary @xmath194 .",
    "then there exists a probability distribution @xmath209 that satisfies the following properties :    1 .",
    "2 .   @xmath211 .",
    "3 .   for each @xmath94 , @xmath212 forms a markov chain .",
    "4 .   for each @xmath94 , @xmath213 , where @xmath214 is induced by the joint distribution in . 5 .   for each @xmath94 , @xmath215 .",
    "we call @xmath209 a _ @xmath155-simulating distribution of @xmath192 neglecting @xmath0 _ because @xmath216 represents a",
    " @xmath155-tilting \" of @xmath205 through property  ( iv ) and captures all the important properties of @xmath217 when @xmath217 is generated according to the given code distribution @xmath192 .",
    "we prove the lemma by first constructing a distribution of @xmath218 denoted by @xmath219 .",
    "subsequently , we use @xmath219 as a building block to construct a distribution of @xmath220 .",
    "define @xmath221 recursively construct @xmath222 for each @xmath223 , where @xmath224 is as defined in . applying recursively from @xmath225 to @xmath226 and using",
    ", we have @xmath227 after defining @xmath219 through , and , we are now ready to define @xmath228 as follows : @xmath229 in the rest of the proof , we want to show that @xmath209 satisfies properties ( i ) , ( ii ) , ( iii ) , ( iv ) and ( v ) .    since @xmath230 for all @xmath231 , it follows that property ( i ) holds .    in order to prove property ( ii ) , we write @xmath232 which implies from proposition  [ propositionmcsimplification ] that @xmath233 .    in order to prove properties ( iii ) , ( iv ) and ( v ) , we write for each @xmath234 @xmath235 where ( a ) follows from marginalizing .",
    "it then follows from and proposition  [ propositionmcsimplification ] that for each @xmath94 , @xmath236 forms a markov chain and @xmath237 properties  ( iii ) and  ( iv ) follow from and respectively .",
    "in addition , for each @xmath94 , @xmath238 then , for each @xmath94 , @xmath239 where    1",
    ".   follows from the fact that @xmath240 forms a markov chain ( cf .  definition  [ defcode ] ) .",
    "2 .   follows from and proposition  [ propositionmcsimplification ] .",
    "property  ( v ) follows from .",
    "we partition the proof into several subsections for the sake of clarity and readability . in the final subsection ( section  [ sec : fano ] )",
    ", we compare and contrast the proof of theorem [ thmmainresult ] with the proof of the usual cut - set bound which only implies a weak converse .",
    "fix an @xmath4 and let @xmath117 be an @xmath5-achievable rate tuple for the dm - mmn . by definitions  [ cutsetachievable rate ] and  [ cutsetcapacity region ] ,",
    "there exists a number @xmath241 and a sequence of @xmath116-codes on the dm - mmn such that for all sufficiently large  @xmath51 , @xmath242 fix a sufficiently large  @xmath51 such that holds , and let @xmath192 be the probability distribution induced by the @xmath116-code on the dm - mmn .",
    "fix an arbitrary @xmath71 such that @xmath243 , and choose a node @xmath244 .",
    "fix an arbitrary @xmath167 .",
    "let @xmath209 be a @xmath155-simulating distribution of @xmath192 neglecting  @xmath0 such that @xmath209 satisfies all the properties in lemma  [ lemmasimulatingdistribution ] .",
    "then , it follows from proposition  [ propositiondlambdalowerbound ] and definition  [ defcode ] with the identifications @xmath245 , @xmath246 , @xmath247 , @xmath248 , @xmath249 and @xmath250 that @xmath251      let @xmath252 and @xmath253 be the random variables generated before the @xmath96 time slot , and consider the following chain of inequalities : @xmath254 where    1 .",
    "follows from the dpi of @xmath173 by introducing @xmath255 .",
    "2 .   follows from property  ( i ) in lemma  [ lemmasimulatingdistribution ] .",
    "3 .   follows from the fact that @xmath256 and @xmath255 are independent .",
    "4 .   follows from the dpi of @xmath173 by introducing the channel output @xmath257 .",
    "5 .   follows from property  ( ii ) in lemma  [ lemmasimulatingdistribution ] and the fact that @xmath258 forms a markov chain .",
    ".   follows from the dpi of @xmath173 by introducing the channel input @xmath259 .    in order to simplify , we consider @xmath260 where    1",
    ".   follows from property  ( iii ) in lemma  [ lemmasimulatingdistribution ] .",
    "2 .   follows from property  ( v ) in lemma  [ lemmasimulatingdistribution ] .",
    "consider the distribution @xmath261 using , and definition  [ defrenyidivergence ] and omitting subscripts of probability distributions to simplify notation , we have @xmath262 following , we consider the following chain of equalities : @xmath263 letting @xmath264 and @xmath265 for each @xmath94 and following , we consider @xmath266 where ( a ) is a telescoping product . for each @xmath94 , define @xmath267 to be the following distribution : @xmath268 for all @xmath269 . combining , and , we obtain @xmath270 which implies from and definition  [ defrenyidivergence ] that @xmath271      construct a probability distribution @xmath272 for each @xmath94 as @xmath273 for all @xmath274 ( cf .  ) , where @xmath195 denotes the channel of the dm - mmn . combining , , and property  ( iv ) in lemma  [ lemmasimulatingdistribution ] , we have @xmath275 for each @xmath94 where @xmath276 is as defined in .",
    "then , it follows from property  ( iv ) in lemma  [ lemmasimulatingdistribution ] , and that @xmath277 using and proposition  [ propositionmcsimplification ] , we obtain @xmath278 for all @xmath94 , which implies from that @xmath279      let @xmath280 be a random variable uniformly distributed on @xmath281 and independent of all other random variables .",
    "construct the probability distribution @xmath282 such that @xmath283 for all @xmath94 , @xmath284 and @xmath285 .",
    "then , we can calculate the joint distributions @xmath286 and @xmath287 as follows : @xmath288 and @xmath289 it follows from and proposition  [ propositionmcsimplification ] that @xmath290 @xmath291 and @xmath292 following , consider the following chain of inequalities : @xmath293 where    1",
    ".   follows from the concavity of @xmath294 and jensen s inequality .",
    "2 .   follows from that @xmath295 for all @xmath94 .",
    "3 .   follows from and .",
    "combining , and , we obtain @xmath296 for all @xmath167 .      for each block length @xmath51 , choose @xmath155 to be dependent on @xmath51 as follows : @xmath297 it then follows from , proposition  [ propositiondlambdatomutualinfo ] , and the fact that @xmath298 that @xmath299 if @xmath300 ( i.e. , @xmath301 so proposition  [ propositiondlambdatomutualinfo ] applies ) . taking the limit inferior on both sides of , we obtain @xmath302 consider each distribution on @xmath303 as a point in the @xmath304-dimensional euclidean space .",
    "then , by the compactness of the probability simplex , there exists a subsequence of the natural numbers @xmath305 , say indexed by @xmath306 , such that @xmath307 is convergent with respect to the @xmath38-distance .",
    "let @xmath308 be the limit of the subsequence such that @xmath309 for all @xmath274 .",
    "combining and , we have @xmath310 since @xmath311 is a continuous functional of distribution @xmath312 , it follows from and that @xmath313 the theorem then follows from and .      following the setting in section  [ subsectionlowerbound ] at the beginning of the proof of theorem  [ thmmainresult ] and following the cut - set bound approach that uses fano s inequality (",
    "* ? ? ? * theorem 18.1 ) ( leading to a weak converse ) , we can lower bound the average error probability @xmath115 as follows @xmath314 the bound holds for each @xmath0 that satisfies @xmath128 .",
    "next , using the dpi for the relative entropy and a time - sharing random variable for the purpose of single - letterization ( * ? ? ?",
    "* theorem 18.1 ) , it can be shown that @xmath315 where @xmath316 is the empirical input distribution induced by the @xmath85-code . combining and and using the fact that @xmath317 does not depend on  @xmath0",
    ", we obtain @xmath318{2.6 in}{$ \\sum _ { i\\in t } r_{i }   \\le   \\frac{1}{1-\\epsilon}{i_{\\bar p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c})},\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{elucidatecutset }   \\end{aligned}\\ ] ] for @xmath132 , immediately reduces to the cut - set bound . for @xmath319 ,",
    "the bound in can not be used to prove strong converse theorems because of the multiplicative factor @xmath320 .",
    "the proofs of   and   share many common steps , but significantly they differ in the first step where for fixed rates , lower bounds on the error probabilities are sought . more specifically , our approach relates a conditional rnyi divergence to the error probability ( cf .",
    "proposition  [ propositiondlambdalowerbound ] ) , while the approach that hinges on fano s inequality relates a conditional mutual information to the error probability ( cf .",
    "the inequality in  ) .",
    "however beyond the first step , the application of the dpi and the method of single - letterization are almost the same for both proofs , but we do need to eventually approximate the conditional rnyi entropy with the conditional mutual information ( cf .  proposition  [ propositiondlambdatomutualinfo ] ) to obtain bound  .",
    "the two different ways of lower bounding the error probability yield two different outer bounds stated in and respectively .",
    "in this section , we will use theorem  [ thmmainresult ] to prove strong converses for some classes of dm - mmns whose capacity regions are known . unless specified otherwise , we let @xmath48 denote the multicast demand on the networks .",
    "we start this section by stating an achievability result for multimessage multicast networks in the following theorem , which is a specialization of the main result of _ noisy network coding _ by lim , kim , el gamal and chung  @xcite .",
    "noisy network coding was also discovered by yassaee and aref  @xcite .",
    "[ theoremnnc ] let @xmath321 be a dm - mmn , and let @xmath322{4 in}{$ \\sum _ { i\\in t }   r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c})-h_{p_{x_{\\mathcal{i}}}q_{y_{\\mathcal{i}}|x_\\mathcal{i}}}(y_t|x_\\mathcal{i } , y_{t^c } ) \\linebreak \\text { where $ p_{x_\\mathcal{i}}\\triangleq \\prod_{i=1}^n p_{x_i}$,}\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{rin}\\ ] ] then , @xmath323",
    ".    the theorem follows by taking @xmath324 in theorem 1 of @xcite .",
    "we would like to identify multicast networks whose inner bounds @xmath325 coincides with our outer bound @xmath127 in theorem  [ thmmainresult ] . using the following definition and corollary , we can state , in theorem  [ thmmainresultapplication ] , a sufficient condition for @xmath326 to hold .",
    "[ defmaximalproductdistribution ] a dm - mmn @xmath84 is said to be _ dominated by a maximal product distribution _ if there exists some product distribution @xmath327 such that the following statement holds for each @xmath193 : @xmath328    the following corollary is a direct consequence of theorem  [ thmmainresult ] and definition  [ defmaximalproductdistribution ] , and the proof is deferred to appendix  [ appendixb ] .",
    "[ corollaryproductdistributionouterbound ] let @xmath84 be a dm - mmn , and let @xmath329{2.7 in}{$ \\sum _ { i\\in t } r_{i }   \\le   i_{(\\prod_{i=1}^n p_{x_{i}})q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{routdet}\\ ] ] if the dm - mmn is dominated by a maximal product distribution , then @xmath330 for all @xmath6 .",
    "[ thmmainresultapplication ] let @xmath84 be a dm - mmn .",
    "suppose the dm - mmn satisfies the following two conditions :    1 .",
    "the dm - mmn is dominated by a maximal product distribution .",
    "2 .   for all @xmath71 and all @xmath331 , @xmath332 .    then @xmath333 for all @xmath6 .",
    "since the dm - mmn is dominated by a maximal product distribution , it follows from theorem  [ theoremnnc ] and corollary  [ corollaryproductdistributionouterbound ] that @xmath334 for all @xmath6 .",
    "in addition , it follows from , and condition 2 that @xmath335 .",
    "theorem  [ thmmainresultapplication ] implies the strong converse for the classes of dm - mmns which satisfy conditions 1 and 2 .",
    "since the deterministic relay networks with no interference @xcite , the finite - field linear deterministic networks @xcite and the wireless erasure networks @xcite satisfy both conditions in theorem  [ thmmainresultapplication ] , the strong converse holds for these networks .",
    "we note that for the class of wireless erasure networks , one assumes that the erasure pattern of the entire network is known to each destination , i.e. , @xmath336 contains the erasure pattern as side information for each @xmath337 ( * ? ? ?",
    "* section  iii.c ) , and hence condition 2 in theorem  [ thmmainresultapplication ] is satisfied . in the following subsection",
    ", we introduce a dm - mmn connected by independent dmcs and prove the strong converse using corollary  [ corollaryproductdistributionouterbound ] and theorem  [ thmmainresult ] .",
    "consider a dm - mmn where a dmc is defined for every link @xmath338 .",
    "let @xmath339 and @xmath340 denote the input and output alphabets of the dmc carrying information from node  @xmath52 to node  @xmath55 for each @xmath338 , and let @xmath341 denote the dmc . for each @xmath338 , the capacity of channel @xmath341 , denoted by @xmath342 ,",
    "is attained by some @xmath343 , i.e. , @xmath344 then , we define the input and output alphabets for each node @xmath52 in the following natural way : @xmath345 and @xmath346 for each @xmath347 , and we let @xmath348 denote the channel of the network .",
    "in addition , we assume @xmath349 i.e. , the random transformations ( noises ) from @xmath350 to @xmath351 are independent and the overall channel of the network is in a product form",
    ". it then follows from and proposition  [ propositionmcsimplification ] that @xmath352 forms a markov chain for all @xmath338 .",
    "we call the network described above the _ dm - mmn consisting of independent dmcs_. one important example of such networks is the _ line network _ in which @xmath353 consists of nonzero - capacity links of the form @xmath354 for all @xmath355 and zero - capacity links for the other node pairs .",
    "define @xmath356{1.8 in}{$ \\sum _ { i\\in t } r_{i }   \\le   \\sum _ { ( i , j)\\in t \\times t^c } c_{i , j},\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{rprime}\\ ] ] since the dmcs from @xmath350 to @xmath351 are all independent and each of the dmc can carry information at a rate arbitrarily close to the capacity , it follows from the network equivalence theory @xcite and theorem  [ theoremnnc ] that @xmath357 is precisely the capacity region of the dm - mmn consisting of independent dmcs , which is formally stated in the following corollary and proved in appendix  [ appendixc ] .",
    "[ corollaryinnerboundptp ] @xmath358 .",
    "we use the outer bound @xmath127 proved in theorem  [ thmmainresult ] ( cf .  ) to prove the following lemma .",
    "[ lemmaptp ] @xmath359 for all @xmath6 .    for completeness , the proof is provided in appendix  [ appendixd ] .",
    "the following theorem is a direct consequence of corollary  [ corollaryinnerboundptp ] and lemma  [ lemmaptp ] .",
    "[ theoremptpnetwork ] let @xmath321 be a dm - mmn consisting of independent dmcs .",
    "then , @xmath360 for all @xmath6 .",
    "theorem  [ theoremptpnetwork ] implies the strong converse for the class of dm - mmns consisting of independent dmcs .      in this section",
    ", we examine a class of dm - mmns with destination feedback , which is a generalization of the dm - mmn consisting of independent dmcs discussed in the previous section .",
    "we assume @xmath361 and let @xmath362 denote the ( single ) destination node throughout this section .",
    "we define the single - destination dm - mmn consisting of independent dmcs with feedback as follows .",
    "[ defdm - mmnwithfeedback ] let @xmath321 be dm - mmn consisting of independent dmcs with multicast demand @xmath363 as defined in the previous section .",
    "a single - destination dm - mmn with multicast demand @xmath363 , denoted by @xmath364 , is called the _ feedback version of @xmath321 _ if the following two conditions hold :    1 .",
    "@xmath365 for all @xmath347 .",
    "2 .   suppose @xmath366 associated with the mmn @xmath321 is generated according to @xmath367 for some input distribution @xmath368 .",
    "then , the random tuple @xmath369 associated with the mmn @xmath364 is distributed according to @xmath370 where @xmath371 and @xmath372 for all @xmath347 .",
    "let @xmath364 be the feedback version of @xmath321 with multicast demand @xmath363 .",
    "it then follows from definitions  [ defdm - mmnwithfeedback ] and  [ defcode ] that for any @xmath85-code on @xmath364 , both @xmath373 and @xmath102 are available for encoding @xmath374 at node  @xmath52 for all @xmath347 . in other words",
    ", there exists for each @xmath347 a perfect feedback link which carries the output symbols at node  @xmath375 to node  @xmath52 .",
    "consequently , the capacity region of @xmath321 is always a subset of the capacity region of @xmath364 .",
    "shannon showed in @xcite that the capacity of any dmc is equal to the capacity of the feedback version , and the strong converse for the feedback version has been shown in ( * ? ? ? * section  iv ) .",
    "also see ( * ? ? ?",
    "* problem 2.5.16(c ) ) for another proof sketch of the strong converse for a dmc with feedback . here , we show that @xmath357 ( defined in ) is equal to the @xmath5-capacity region of any single - destination dm - mmn consisting of independent dmcs as well as the @xmath5-capacity region of the feedback version for any @xmath376 . in other words , feedback does not enlarge the @xmath5-capacity region of any single - destination dm - mmn consisting of independent dmcs .",
    "thus , the strong converse also holds for the feedback version of this class of dm - mmns .",
    "[ thmptpfeedbackversion ] let @xmath321 be a dm - mmn consisting of independent dmcs with multicast demand @xmath363 , and let @xmath357 be the set defined in .",
    "suppose @xmath364 is a feedback version of @xmath321 .",
    "let @xmath376 be a real number and let @xmath119 and @xmath377 be the @xmath5-capacity regions of @xmath321 and @xmath364 respectively .",
    "then , @xmath378 .",
    "theorem  [ thmptpfeedbackversion ] can be proved similarly to theorem  [ theoremptpnetwork ] .",
    "we provide a concise proof in appendix  [ appendixe ] . since the @xmath5-capacity region with",
    "_ imperfect feedback _ compared with perfect feedback can not be larger and the @xmath5-capacity region with _ no feedback _ is equal to @xmath357 by theorem  [ theoremptpnetwork ] , it follows from theorem  [ thmptpfeedbackversion ] that the strong converse also holds for any single - destination dm - mmn consisting of independent dmcs with imperfect feedback .",
    "in this paper , we proved that the strong converse holds for some classes of dm - mmns for which the cut - set bound is achievable by leveraging some elementary properties of the conditional rnyi divergence .",
    "we suggest three promising avenues for future research .",
    "first , the foremost item is to show that all rate tuples that lie in the exterior of the usual cut - set bound for dm - mmns  @xcite result in error probabilities tending to one .",
    "this seems rather challenging as we have to assert the existence of a _ common _ distribution @xmath379 for all cut - sets @xmath0 in .",
    "this would allow us to swap the intersection and union in theorem [ thmmainresult ] .",
    "second , and less ambitiously , we also hope to extend our result to gaussian networks ( * ? ? ?",
    "* chapter 19 ) , which may be tractable if we restrict the models under consideration to the class of gaussian networks for which the optimum input distribution is a multivariate gaussian .",
    "finally , it may be fruitful and instructive to focus our attention on smaller dm - mmns such as the dm - rc .",
    "for any random variables @xmath380 and @xmath381 , we let @xmath382 be the _ support _ of @xmath380 conditioned on the event @xmath383 . if @xmath381 is a trivial random variable , i.e. , @xmath384 , then @xmath385 is simply the support of @xmath380 . if @xmath179 , the statement of the proposition is obvious so henceforth , we prove the statement for @xmath386 $ ] .",
    "suppose @xmath33 is jointly distributed according to @xmath387 which we abbreviate as @xmath388 in this proof .",
    "let @xmath389 be a function of @xmath155 defined on @xmath390 .",
    "straightforward calculations involving lhpital s rule reveal that @xmath391 and @xmath392 ( cf .  definition  [ defrenyidivergence ] ) . using taylor s theorem ,",
    "we obtain @xmath393 for some @xmath394 $ ] , which implies that @xmath395 using standard calculus techniques , we obtain @xmath396 in order to obtain an upper bound for @xmath397 , we will calculate a lower bound for @xmath398 and upper bounds for @xmath399 and @xmath400 consider the following chain of inequalities : @xmath401 on the other hand , fix @xmath12 , @xmath29 and @xmath185 such that @xmath402 and @xmath403 , and consider @xmath404 as well as @xmath405 . since @xmath406 , there exist @xmath407 and @xmath408 such that @xmath409 and @xmath410 . using the facts that @xmath411",
    "$ ] and @xmath412 , we have @xmath413 and @xmath414 then , @xmath415 and @xmath416 where    1 .   follows from and ; 2",
    ".   follows from calculus that @xmath417 for all @xmath418 ; 3 .   follows from and ; 4",
    ".   follows from calculus that @xmath419 for all @xmath418 .    combining , , , and",
    ", we obtain @xmath420 which implies that for each @xmath421 $ ] ( note @xmath422 so we can cancel the common factors @xmath423 ) , @xmath424 and hence follows .",
    "suppose the dm - mmn is dominated by some maximal product distribution @xmath327 such that for each @xmath71 , we have @xmath328 this then implies from theorem  [ thmmainresult ] that for each @xmath6 , @xmath425{2.4in}{$ \\sum _ { i\\in t } r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}^*q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\ } \\stackrel{\\eqref{routdet}}{\\subseteq}\\mathcal{r}_{\\text{out}}^ * .\\end{aligned}\\ ] ] this completes the proof .",
    "construct a counterpart of the channel @xmath321 as follows : let @xmath426 be a noiseless dm - mmn consisting of independent dmcs with multicast demand @xmath48 such that for each @xmath338 , the dmc carrying information from node  @xmath52 to node  @xmath55 is an error - free ( noiseless ) channel , denoted by @xmath427 , with capacity @xmath342 ( cf .  ) . to be more precise",
    ", @xmath427 can carry @xmath428 error - free bits for each @xmath338 for @xmath51 uses of @xmath426 .",
    "let @xmath429 denote the capacity region of @xmath426 .",
    "it follows from the network equivalence theory @xcite that @xmath430 .",
    "in addition , it has been shown in ( * ? ? ? * section iia ) that @xmath431 .",
    "consequently , @xmath432 , which is what was to be proved .",
    "since @xmath433 for all @xmath6 by theorem  [ thmmainresult ] , it remains to show @xmath434 . in order to obtain an outer bound of @xmath127 , we consider the following chain of inequalities for each @xmath368 and each @xmath71 : @xmath435 where    1",
    ".   follows from the fact that for all @xmath436 , @xmath437 2",
    ".   follows from the fact that for all @xmath438 , @xmath439    combining , and , we have @xmath440 .",
    "fix any @xmath6 . since @xmath441 by theorem  [ theoremptpnetwork ] and @xmath442 , it remains to show that @xmath443 .",
    "define @xmath444{2.4in}{$ \\sum _ { i\\in t } r_{i }   \\le   i_{p_{x_{\\mathcal{i}}}\\tilde q_{\\tilde y_{t^c}|x_\\mathcal{i}}}(x_t ; \\tilde y_{t^c}|x_{t^c}),\\\\   r_i=0 \\text { for all } i\\in\\mathcal{s}^c$ } \\right.\\right\\}. \\label{routtilde}\\ ] ] since @xmath445 for all @xmath6 by theorem  [ thmmainresult ] and @xmath434 by lemma  [ lemmaptp ] , it suffices to show @xmath446 . to this end",
    ", we consider the following chain of equalities for each @xmath368 and each @xmath71 such that @xmath447 : @xmath448 where    1",
    ".   follows from condition 2 in definition  [ defdm - mmnwithfeedback ] ; 2 .   follows from the fact that @xmath447 .    combining , and , we have @xmath449 .",
    "the authors are indebted to prof .",
    "shun watanabe for pointing out an error in an earlier version of this paper .",
    "d.  xu and d.  erdogmuns , `` rnyi s entropy , divergence and their nonparametric estimators , '' in _ information theoretic learning : rnyi s entropy and kernel perspectives _ , j.  c. principe , ed.1em plus 0.5em minus 0.4emspringer , 2010 , pp",
    ". 47102 .",
    "m.  m. wilde , a.  winter , and d.  yang , `` strong converse for the classical capacity of entanglement - breaking and hadamard channels via a sandwiched rnyi relative entropy , '' _ commun .  math .",
    "331 , no .  2 ,",
    "pp . 593622 , 2014 ."
  ],
  "abstract_text": [
    "<S> this paper establishes that the strong converse holds for some classes of discrete memoryless multimessage multicast networks ( dm - mmns ) whose corresponding cut - set bounds are tight , i.e. , coincide with the set of achievable rate tuples . </S>",
    "<S> the strong converse for these classes of dm - mmns implies that all sequences of codes with rate tuples belonging to the exterior of the cut - set bound have average error probabilities that necessarily tend to one ( and are not simply bounded away from zero ) . </S>",
    "<S> examples in the classes of dm - mmns include wireless erasure networks , dm - mmns consisting of independent discrete memoryless channels ( dmcs ) as well as single - destination dm - mmns consisting of independent dmcs with destination feedback . </S>",
    "<S> our elementary proof technique leverages properties of the rnyi divergence </S>",
    "<S> .    strong converse , multimessage multicast networks , rnyi divergence , wireless erasure networks </S>"
  ]
}