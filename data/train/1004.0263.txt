{
  "article_text": [
    "high flexibility and extremely lean and quick development cycle have always made _ `` pure '' _",
    "( i.e. based on general purpose processors without any dedicated hardware subsystem ) sdrs very attractive for research , development and small - scale market deployment , low throughput per watt compared to equivalent hardware ( hw ) implementations has equally kept them from accessing major markets .",
    "it has always been a universally accepted assumption that a greater amount of generality and flexibility of the radio system had to be paid with heavy losses on power efficiency , due to the necessary usage of general purpose cpus .",
    "accordingly , sdr implementations up to the present date have simply aimed to replicate the classical hw - implemented signal processing chains into the software realm .",
    "aim of this research is to prove that , by making use of all the resources available on a general purpose computing system ( i.e. not only calculus but also memory ) , it is possible  at least  to substantially reduce the power efficiency gap that exists between sdrs based on general purpose cpus and hw implementations of the same radio system .",
    "implications of such results include potential for deploying flexible radio technologies on the industrial scale ( due to increase of power efficiency up to levels that would make them a practical alternative to hw solutions ) as well as do suggest the possibility to implement fully generic , c++ definable _ radio signal processing cores _ being trivially derived from currently available general purpose cpus , yet able to deliver very high signal synthesis and demodulation performances .    in order to achieve our goal , we must adapt classical concepts known in computer science under the collective denomination of _ space / time tradeoffs _ to the signal processing realm . in previous literature",
    ", space / time tradeoffs are intended either as increasing the level of hardware ( and thus often software ) parallelism of a given implementation ( therefore consuming more space ) in order to reduce the execution time , as in @xcite and @xcite or as pre - calculating data that is already being offered by the given algorithm ( or by an equivalent version of it obtained by means of some algebraic manipulation being fully peculiar to the single algorithm ) into some tabular form @xcite .",
    "this research provides instead a convenient and rather general instrument which enables decomposition of any radio signal processing algorithm into a set of constituent parts defined in the following as _ segments_. a re - aggregation rule is also described for those segments , yielding a re - implementation of the given algorithm which takes conspicuous advantage from the presence of abundant memory resources .",
    "we start our discussion by observing that any radio system and , more generally , any system performing some signal processing , can be represented both in a black - box fashion ( figure [ fig : bb1 ] )    and as the chain ( or web ) of its constituent functional blocks ( figure [ fig : chain1 ] ) .",
    "if we chose the black box representation of figure [ fig : bb1 ] , then we can consider our radio system ( e.g. a receiver ) to be fully equivalent to a mathematical function @xmath0 which maps a certain amount of soft - valued channel symbols into the corresponding hard - valued demodulated information bits . at the receiver side ,",
    "we call the minimum amount of channel symbols that can be processed independently ( without requiring any other information ) from the remainder of the stream the _ minimum independent data set _ ( mids ) .",
    "e.g. for etsi dvb - t @xcite standard this would be 4 ofdm frames ( i.e. what is called a _ superframe _ in @xcite ) .",
    "obviously , on the tx path , the mids would be the minimum amount of information bits that the modulator will need in order to generate the atomic unit of soft - valued baseband signal defined by the radiotransmission standard .",
    "we indicate the size ( number of items ) of the mids with symbol @xmath1 while @xmath2 is the cardinality of the alphabet each datum belongs to .",
    "domain of @xmath0 is then defined as the set of all possible messages which can be represented within the mids .",
    "we call _ input space _ the domain of @xmath0 and @xmath3 the cardinality of such space",
    ". it would then be :    @xmath4    dually , _",
    "output space _ is how we name the target set of @xmath0 while its cardinality is @xmath5 .",
    "then , if we could find a convenient analytical expression for function @xmath0 , we could consider implementing our example dvb - t demodulator by programming such analytical expression into a computing system .",
    "still , this would be a _ calculus - only _ implementation of the system , like any classical hw or sw implementation of a radio system just is .",
    "i.e. such implementation would only take advantage of calculus resources being available on a general purpose computing system , disregarding the  indeed usual and cheap  presence of abundant memory resources .",
    "this said , it would be natural and obvious to think of replacing function @xmath0 with table @xmath6 : a table containing , for each item of the input space , the associated output value as shown in figure [ fig : ft ] .",
    "this would be a _ memory - only _ implementation , would _ not require extraction of @xmath0 in analytical form _ but would obviously yield a @xmath3 being not practical for any memory technology available today or in the foreseeable future .",
    "actually , the table @xmath6 could be filled up by running the standard , computation - only , implementation of function @xmath0 ( that is the radio signal processing chain implementing it ) over the entire input space at instantiation time .",
    "such considerations suggest that the path towards optimal sdrs lies somewhere among hybrid systems which are able to use up both calculus and memory .",
    "we now move a step forward by abandoning the single black - box representation of our sdr system which we used as a tool to describe the fundamental rationale behind the ma idea .",
    "we begin the process of designing memory acceleration for our sw radio and , in order to do this , we go deeper into the knowledge of the sdr we wish to implement by representing it as the web of its constituent blocks , see figure [ fig : chain1 ] .",
    "we call this representation change the _ 0-step _ of _ algorithm segmentation _ because at first we consider our radio system to be a single signal processing algorithm and then we break it down into its functional blocks . obviously such _ 0-step",
    "_ comes for free as long as any radiotransmission system is conceived since the beginning as a chain of functional blocks .",
    "actually , at this early stage we assume each of the functional blocks @xmath7 to be _ atomic _ , i.e. impossible to break in a further web of constituent algorithmic functional blocks , still , in subsequent phases of ma design , _ algorithm segmentation _ will be developed further as it will play a key - role for the effectiveness of the ma / mb - sdr implementation strategy .",
    "precisely , within the scope of this work , _ algorithm segmentation _ is defined as the decomposition of a functional block @xmath0 , formerly assumed to be atomic , into a chain ( or web ) of constituent sub - blocks @xmath7 which implements the same function as @xmath0 .",
    "input spaces of sub blocks @xmath8 will be different from and significantly smaller than @xmath3 , if algorithm segmentation was performed correctly .    it must be noted that algorithm segmentation is not algorithm re - design : in particular this yields that algorithm segmentation _ does not change the overall computational cost of the segmented algorithm_.    .ma / mb - sdr symbols and taxonomy [ cols=\"^,^\",options=\"header \" , ]     we call @xmath9 the computational cost of the _ n - th _ functional block and use a graphical representation of the sdr in which the size of the functional block is directly proportional to such cost , see figure [ fig : chain2 ] . it is possible to express @xmath9 either as the number of operations per second ( op / s ) required by the block to work in real - time or as the cpu time it requires to process a given amount of data while being unthrottled ( i.e. absorbing 100% of available cpu resources while running ) .",
    "obviously such representation choice has to be kept consistent throughout the ma design process .",
    "indeed we suggest the first method as the more practical when designing ma from paper ( i.e. in absence of an optimized , computation - only reference implementation of the system that is being accelerated ) .",
    "second method is instead best suited when such an implementation is available and cpu times absorbed by the single blocks can be measured .",
    "the symbol @xmath10 represents the total computational cost of memory management for table @xmath11 , that is the cost of memory address calculation and the equivalent computational cost ( consumption of cpu time or of a given number of operations ) yielded by memory access latencies , if any is present and significant .",
    "@xmath12 is the total computational power in op / s available within the computing platform .",
    "@xmath13 is the total size of available memory within the computing platform , @xmath14 is the total memory footprint of table @xmath11 , @xmath15 is the data size of items stored in @xmath11 , all such quantities are expressed in bytes .",
    "we call @xmath16 the acceleration efficiency for block @xmath0 :    @xmath17    where @xmath18 is the number of the obtained sub - blocks @xmath19 that will be implemented in memory through the use of suitable tables and @xmath20 is the number of tables used to produce such an implementation",
    ".    acceleration efficiency [ @xmath16 ] is therefore defined as the ratio between the computational effort being saved by means of the performed in - memory implementations , reduced by the amount of computational work needed for table management , and the total memory footprint being required .",
    "it is also possible to define acceleration efficiency on a per - table basis , we obtain :    @xmath22    where @xmath18 indicates in this case the number of computational sub - blocks which are substituted by table @xmath11 .",
    "a negative value for @xmath16 ( or of course @xmath23 ) has to be avoided as it indicates the chosen ma design will reduce system performance .",
    "aim of memory acceleration is to assist the general purpose computing system in processing the informative signal ( both rx and tx sides ) through the usage of memory resources , thus increasing the overall throughput by a factor that we will call the _ acceleration factor _ , in symbols : @xmath24 .",
    "such result is obtained by convenient substitutions of functional blocks being conventionally implemented by using pure calculus @xmath7 with the pre - computed tables @xmath11 presented in paragraph [ subsec : repr ] that is performed after one or more steps of _ algorithm segmentation _ and according to the recursive table aggregation rule which will be described in the following .",
    "therefore ma design reaches optimality when all memory resources available are used and the maximum possible value for @xmath24 is reached .",
    "that is , when all memory is used and is used well .",
    "the _ input space cardinality _",
    "@xmath25 $ ] of each @xmath7 is assumed to be _ independent _ from its _ computational cost _",
    "@xmath26 $ ] or , in the worst case , weakly correlated .",
    "think for example of three typical signal processing blocks being present in any modern radio system : a block - based forward error correction ( fec ) decoder , its associated interleaver and a scrambler preforming energy dispersal on a set of data sized precisely the same as the fec block .",
    "such three blocks share the very same @xmath3 but yield enormously different computational costs ( i.e. at least one order of magnitude ) with the fec decoder being dramatically heavier than the other two .",
    "therefore , as long as the amount of memory resources @xmath27 $ ] is finite , it is necessary that those resources are used to accelerate the computationally - heaviest blocks of the chain .",
    "performing memory - acceleration of a low @xmath9 block immediately would obliterate optimality as long as the memory used to replace computation yielded by such block could be better used in order to replace an heavier block .",
    "process reaches optimality when memory space is exhausted and the maximum possible number of operations ( or the maximum possible amount of cpu time ) has been replaced by memory look - ups providing the same output .      considering that each implemented table yields , at least , one look - up act in order to perform the computation it is supposed to ,",
    "we conclude that minimizing @xmath28 ( i.e. the total memory management cost in our implementation ) necessarily requires to aggregate as many functional blocks @xmath7 as possible into a single table @xmath11 . also , we must consider that most general purpose computing systems have a hierarchical memory structure with smaller and faster caches in the proximity of the computing core and a bigger , slower extended memory in a more peripheral spot of the system ( see figure [ fig : memstruct ] ) .",
    "therefore , it has a dramatic effect on system performance to store contiguously in memory information which will be used contiguously in time . thus , as long as the functions implemented by each block are applied serially along the chain , it is a good thing that memory implementation of contiguous functional blocks happens within the same table @xmath11 .",
    "this actually makes it easy to structure the table in order to make it cache friendly , or either simply yields cache friendliness itself if cardinality of input spaces is small enough .",
    "we thus propose a recursive table aggregation rule ( rtar ) which is conceived in order to provide the aggregation of as many of the functional blocks as possible into the same table as well as in order to call for algorithm segmentation which is a demanding task in terms of design effort only upon functional blocks where it is really needed and useful .",
    "a recursive table aggregation rule which ensures that ma design respects criteria discussed in [ sec : ad ] and in [ sec : taecf ] , provided that recursion is applied up to the exhaustion of memory resources , is presented in the following .",
    "rtar is a recursive design algorithm for memory acceleration of a given sdr system .    broadly speaking , it is possible to state that aim of algorithm segmentation is to break a functional block down into the highest possible number of component sub - blocks yielding as small input spaces as possible .",
    "aim of rtar is instead to re - aggregate as many of the _ heaviest _ functional blocks ( and sub - blocks ) , in which the system has been decomposed , within the smallest possible number of tables @xmath11 as allowed by available memory resources .",
    "memory - contiguity of time - contiguous information as discussed in [ sec : taecf ] is provided by rtar as well as management of algorithm segmentation , which is invoked by rtar only on the blocks where it is most effective .",
    "we call _ table boundary _ ( tb ) the line containing the subsystem we try to memory - accelerate during each step of the recursive design process .",
    "interfaces from and towards the remainder of the system are given by the system chain connection arrows that do cross the tb .",
    "a block is called _ peripheral _ if all of its input arrows and/or all of its output arrows do cross the _",
    "table boundary_.    1 .",
    "define whole radio as sub - system to be memory - accelerated .",
    "this is equivalent to enclosing the entire radio within the table boundary .",
    "calculate @xmath29 .",
    "if obtained table fits in memory , then go to step 3 ) , if not , perform _",
    "0-step _ of algorithm segmentation .",
    "the table boundary now contains the system broken down to the block level .",
    "2 .   identify the computationally - lightest block contained within the table boundary and release it by moving it outside the table boundary ( figure [ fig : tb1 ] ) . if the released block is not peripheral , then release all blocks depending on its output , see figure [ fig : tb2 ] .",
    "calculate @xmath29 again , if table fits then go to step 3 ) , otherwise iterate step 2 ) up to when either the table fits or the @xmath7 atomicity limit is reached ( figure [ fig : atomreached ] ) . if the latter becomes true , perform a further algorithm segmentation step over @xmath7 and restart iterating step 2 ) .",
    "note that , in the case atomicity limit is reached , the block which will undergo algorithm segmentation is the heaviest block of the whole radio , then the sub - blocks obtained from segmentation collectively yield the majority of the computational cost of the sdr , subsequent iterations will thus be performed leaving the table boundary around such sub - blocks without re - initializing .",
    "whenever one of the sub blocks obtained from algorithm segmentation is released , check whether the table boundary encloses a computational cost @xmath30 which is greater than the cost of any functional block outside the tb . in case",
    "this condition becomes false , re - initialize the tb to enclose the entire system and iterate step 2 ) .",
    "3 .   implement the subsystem being enclosed in the current table boundary by substituting its computation - only functional blocks with a suitable table @xmath6 .",
    "table @xmath6 will be an input / output map completely equivalent to the replaced subsystem . if there are still blocks not implemented in memory and memory resources are not exhausted , initialize table boundary for next iteration by enclosing all the remainder of the radio system , then go to step 2 ) .",
    "it must be noted that the proposed rtar algorithm is sub - optimal .",
    "indeed , aiming for optimality would require an exhaustive approach .",
    "algorithm segmentation should then be performed on all blocks , regardless of their computational cost , then , on the completely algorithm - segmented version of the system to be memory accelerated , all possible aggregates of segments ( i.e. the obtained sub - blocks ) should be considered and characterized by means of saved computational cost ( @xmath31 ) and memory footprint ( @xmath14 ) . after discarding all aggregates which are unable to fit in memory , the set of aggregates which maximizes @xmath24 , under the system s memory resource constraints , should be implemented as memory tables .    though suboptimal , we believe the proposed rtar algorithm reaches a good trade - off point between performance and design complexity .",
    "in fact , it was able to provide substantial ( roughly one order of magnitude ) acceleration factors on the two very diverse algorithms presented in following sections , while yielding acceptable ma design effort .",
    "as previously stated we call _ algortim segmentation _ the process of breaking a single functional block @xmath0 up into its constituent functional sub - blocks or",
    "_ segments_.    algorithm segmentation simply identifies segments within the given algorithm @xmath0 while doing no re - design of the segmented algorithm .",
    "thus , computational cost of segmented system @xmath0 is conserved .",
    "a _ segment _ is any sub - system of @xmath0 for which a mids can be identified ( over one or more input lanes ) .",
    "output yielded by the processing of such mids is input to one or some of the subsequent segments which concur to build up @xmath0 as a whole .",
    "the reason for which algorithm segmentation is such a crucial tool for ma is that there is _ positive correlation _ between the _ number of different sub - functions _ that a functional block performs and @xmath1 .",
    "this happens because , within a functional block that includes many sub - blocks , such sub blocks do operate with different _ granularities _",
    "( i.e. with different mids ) and therefore the mids of the entire block typically grows , in order to accommodate all of the underlying , to their _ least common multiple .",
    "_    as a consequence , being @xmath3 an extremely non linear function of @xmath1 ( indeed , it is exponential in @xmath1 ) as shown in [ eq : ci ] , it is highly convenient to keep @xmath1 as small as possible by means of algorithm segmentation in order to obtain tables @xmath11 which can fit into the available memory resources .    in practice",
    "it turns out that functional blocks that do perform several _ different _ sub - functions will have a large @xmath1 and will require segmentation in order to be ( even partially ) implemented in memory .",
    "please note that we are not stating the presence of any kind of correlation between input space cardinality @xmath3 and computational cost of a block .    as radio signal processing algorithms",
    "do differ really much from one another , they do offer very different opportunities for algorithm segmentation .",
    "it is therefore difficult to give optimality bounds for algorithm segmentation into an ma context , still we can say that the best algorithm segmentation is the one providing the finest possible _ granularity of input spaces _ of obtained sub blocks .",
    "this is true because the smaller the granularity is , the closer the rtar will manage to bring the total memory occupancy of the ma - ed sdr , @xmath32 , to the memory capacity of the system @xmath13 .    thus , for what stated above about the positive correlation between number of sub - functions implemented by a block and its mids size , it turns out that the more sub - blocks @xmath18 algorithm segmentation obtains from the given block , the better algorithm segmentation was performed .",
    "finally it is possible to state that the joint action of algorithm segmentation and rtar is to _ decompose the given sdr system down to the finest possible level of computational granularity , in order to allow for a re - implementation which is capable of using as much as possible of the available memory resources to perform the heaviest part of the computation that the sdr requires .",
    "all this , just with the smallest possible computational cost of memory management .",
    "_    this is the gist of the ma concept .      once the acceleration process has been completed ( i.e. the rtar algorithm terminates for memory exhaustion or on having memory - accelerated the entire system ) it is possible to calculate the obtained acceleration factor @xmath24 as @xmath33    where @xmath18 is the number of functional sub - blocks @xmath7 that have been implemented in memory through the use of suitable tables and @xmath20 is the number of tables that have been used to produce such an implementation .",
    "@xmath34 accounts for the computational cost of remaining blocks which where not implemented in memory .",
    "it is indeed very difficult to give an upper bound for @xmath24 , that is determine the optimal acceleration which can be obtained through ma , as long as such acceleration depends on optimality of algorithm segmentation , which in turn heavily depends on the algorithm ( the functional block ) which is to be segmented and memory - accelerated .",
    "different algorithms offer different opportunities for segmentation and therefore @xmath35 is highly dispersed among implementations .",
    "still , an estimate can be given , which though is fully dependent on the number of tables @xmath20 that the rtar obtains from the segments @xmath18 the given system @xmath0 ( either a functional block or the entire radio ) has been broken up into by _",
    "algorithm segmentation_. it is assumed that the complete system @xmath0 finally fits into the available memory . we have : @xmath36 where @xmath37 is the access latency for each table ( depending on table dimension and chosen implementation platform ) , @xmath38 is the number of inputs to each table , @xmath39 is the computational cost for one multiplication by a constant and @xmath40 is the computational cost of one sum with a variable .",
    "all such quantities , including @xmath41 , can be both expressed in terms of number of operations and required cpu time .",
    "the numerator is the total computational cost of the original system @xmath0 expressed as the sum of computational costs of all sub - blocks it was broken down into .",
    "the denominator general term @xmath42 is indeed our estimate for @xmath10 .",
    "as already stated , aim of ma is to create software radios that exploit all the resources available on a general purpose computing system , that is not only calculus but also memory .",
    "thus , based on the acceleration efficiency , it is possible to derive an overall merit parameter which describes quantitatively how a memory - accelerated sdr implementation ranks with respect to another one . given a radio whose black - box aggregate representation we call @xmath0 , we define @xmath43 as the overall merit parameter of the memory - accelerated implementation of @xmath0 .    @xmath44    where @xmath45 represents the computational work required by the implemented radio when running throttled , that is on line and processing exactly the amount of samples per second which is required by the chosen radiofrequency communication standard . actually the first two rational factors do account for use of all available memory and computational resources respectively .",
    "a good way of evaluating @xmath43 for the various ma - sdrs one might wish to compare is to run the radio unthrottled ( i.e. at the full speed allowed by the hardware it is running upon ) , this yields :    @xmath46    assuming this and simplifying the total memory occupancy of the tables @xmath32 in [ eq : i ] we obtain    @xmath47      all performance results presented in section [ rimem ] have been obtained by applying ma alone , i.e. by making use of no other performance enhancement technique such as low level ( assembler ) programming or parallelization .",
    "this was done in order to explore the contribution to performance enhancement that ma can provide by itself .    still , it is important to note how ma is fully compatible with such performance - computing typical implementation techniques and to consider how such techniques could provide further acceleration when applied within an ma context .",
    "compatibility with low level programming is trivial and does not deserve a discussion . for parallel implementation instead ,",
    "a possible objection is that concurrent access to a certain memory area from multiple computing cores can result in the need for collision control and , therefore , performance bottleneck .",
    "such problem can be easily avoided by simply making use of cache friendliness .",
    "multicore computing systems do often have cache memories which are dedicated to each single core as depicted in figure [ fig : multicorecache ] .",
    "such memories are independently accessed by each of the cores removing the possibility of collisions .",
    "collisions could instead happen when loading the required memory table ( or table portion ) from the external random access memory ( ram ) into the core - dedicated caches as shown in figure [ fig : multicorecache ] .",
    "appropriate use of a cache - friendly table structure will make these fetches extremely rare , while the frequent look - ups required by our memory - based computation scheme happen only within the core - dedicated cache .",
    "therefore , should access contention happen at the ram - level , it would be rare enough not to threaten the performance level of the system .",
    "as a real - world _ proof of concept _ of ma we provide the results we obtained by applying the ma technique to our fully software implementation of a an etsi dvb - t @xcite receiver called r - dvb @xcite .    after implementing r -",
    "dvb the usual , computation - only , way and performing several cycles of code optimization , our realtime distance ratio was about 10 ( i.e. r - dvb requiring 10 times the realtime in order to process a given amount of samples ) , r - dvb including the entire etsi dvb - t reception chain from reference signals removal up to demodulated transport stream ( ts ) delivery .",
    "test and reference platform for all further considerations is an intel q9400 cpu clocked at 2.66 ghz .",
    "all implemented software makes _ no use of parallelization _",
    "( all code is single threaded ) , therefore _ only one of the four cores _",
    "available on our test cpu is used by any of the implementations presented here .",
    "obviously , aiming to implement an entire etsi dvb - t receiver as a single memory table ( i.e. by applying no algorithm segmentation nor any rtar cycles ) , makes no sense at all , still , we assumed such ideal wish as the formal starting point of rtar . once released the single block representation of the system , we profiled the computational cost of the entire demodulation chain on a functional - block basis , thus performing what we called the _ 0-step _ of algorithm segmentation .",
    "it was immediately clear that the k=7 viterbi decoder @xcite included in the demodulation chain @xcite was by far the heaviest block of the system .",
    "actually , viterbi alone took about @xmath48 times the realtime , while the remainder of the chain took only @xmath49 times the realtime to be executed .",
    "this meant , according to rtar , that viterbi decoder was meant to be the first block to undergo memory acceleration .",
    "such activity produced a novel implementation of the viterbi decoder algorithm , relying almost entirely upon memory resources , which we then humorously named _",
    "rimembri _ in order to stress its peculiar , memory - based nature .",
    "such memory implementation of the by far heaviest block of the receiver chain was what enabled us to obtain a completely realtime , fully software etsi dvb - t receiver on a low budget general purpose cpu as described in @xcite .",
    "such a result would not have been possible without ma .",
    "_ rimembri _ implementation is described in the following .",
    "actually , as stated above , applying rtar recursively as described in [ subsec : rtar ] , we got to the point where we were requested to segment our etsi dvb - t , k=7 viterbi decoder . a classical functional block decomposition of the viterbi algorithm is shown in figure [ fig : vit - classic - decomp ] , where all functions are implemented through pure computation .",
    "the blocks of such decomposition are the usual viterbi decoder add compare select ( acs ) function , a block updating the memories of decoded bits ( path bitsets ) for each viterbi decoder state , a block updating the metrics ( weights ) for each of the decoder s state and a block selecting the likeliest ( smallest metric ) state after a decoding - depth long observation .    obviously , after such basic segmentation , input space cardinalities @xmath8 were still far too large to fit into available memory .",
    "we iterated rtar until we obtained the segmented implementation of figure [ fig : vit - as ] and convenient table boundaries .",
    "within such implementation , a much finer segmentation of the viterbi algorithm is visible .",
    "previous functional blocks have been broken up into several constituent sub - blocks , namely :    * calculation of current input bitset s distance from each transition label * sum of branch metrics * branch metric comparison and selection * sum and updating of path metrics * updating of path bitsets    upon each rtar iteration completion , a table boundary was produced while algorithm segmentation was performed when required . by implementing each table boundary ( i.e. the functional blocks aggregated within ) as a memory table",
    ", we obtained the implementation shown in figure [ fig : vit - rtar ] .",
    "in such implementation , add , compare and select functions for as many as 4 states are performed through a single memory look up . another memory table implements the selection of the likeliest state , while update of decoded bit memories and of current metrics for each state is still being performed through pure computation .    as memory resources of our test system",
    "are being just marginally exploited ( 50 mib out of 4 gib ) and some functions are still implemented the usual , computation - only way , rtar could be further iterated in order to bring to memory also such functional blocks , providing further acceleration to the overall system .",
    "the relevant implication of the described implementation strategy is that the computational cost required to perform the single memory look - up is by far smaller than what direct computation of the required result would yield .",
    "for this reason we claim that the described approach _ aggregates many elementary computation acts within a certain number of cpu cycles _ and thus reduces the power efficiency gap between sw and hw implementations , without losing anything in reconfigurability and flexibility of the system .      on the reference cpu described in section [ rimem ] , the computation - only implementation of our viterbi decoder takes about @xmath50 times the realtime .",
    "after undergoing memory acceleration , the same implementation takes @xmath51 times the realtime .",
    "acceleration factor @xmath24 equals @xmath52 .",
    "total memory occupancy of the memory - accelerated implementation is @xmath53 mib .",
    "presented performance test results were obtained by compiling sourcecode with _ g++ _",
    "compiler , version @xmath54 .",
    "some results obtained while applying ma to other algorithms are worth to be mentioned as well . within the synchronization section of the same etsi dvb - t receiver",
    "( please see @xcite ) a carrier frequency fractional ( i.e. expressed as a fraction of ofdm subcarrier spacing ) offset corrector which used to be implemented by means of pure calculus was accelerated by a factor @xmath55 after undergoing ma . in short , within this very basic ma application , a single , computationally - implemented , oscillator generating any complex tone that could be required to compensate the estimated fractional offset is _ algorithm - segmented _ down to a set of oscillators capable of generating only a single frequency .",
    "each of such sub - blocks ( sub - oscillators ) is implemented by means of a memory table , therefore obtaining full memory implementation of the fractional frequency offset corrector block as shown in figure [ fig : ma_lo ] .    as discussed above ,",
    "functional blocks inherently working on large amounts of data ( i.e. featuring big mids ) require well - designed segmentation in order to be conveniently accelerated . when such blocks do perform very basic operations on such broad data sets , they are difficult to segment . at the time of writing this article , work is underway in order to obtain the largest possible memory - acceleration of quite a computationally heavy algorithm presenting such challenges , namely the ofdm time and frequency offset estimator described by van de beek , sandell and borjesson in @xcite .",
    "memory - accelerated implementations obtained so far , provided acceleration factors as big as @xmath56 which are expected to grow by means of further development and will be described in future ma - related works .",
    "reference hw / sw platform for this implementation is the same as described above .",
    "we believe that , by having obtained acceleration factors of about one order of magnitude in terms of computational efficiency by applying ma to two highly diverse signal processing algorithms ( namely an hard - valued viterbi decoder and a soft - valued , correlator - based ofdm synchronizer ) , we have shown the generality of ma approach , that is its applicability to an extremely wide variety of radio signal processing algorithms .    for such a reason , authors do propose ma as an implementation technique for radio signal processing within sdr systems which can provide a substantial boost to their performances and therefore move sdr technologies much closer to market segments they are currently excluded from , because of their poor energy efficiency .",
    "based on the performance boost obtained by applying ma approach to our radios , curiosity naturally arises about evaluating the possibility to take the ma concept to its absolute limit : _ memory - implementation of the entire radio system_.    at this point it might be useful to discuss _ what _ actually distinguishes software implementations from hardware ones to the extent that average power efficiency gap between the two is as wide as two orders of magnitude in favour of hw systems ( with worst cases reaching three orders of magnitude ) .",
    "key concept in order to understand this huge separation is _",
    "specificity_. software implementations do rely on general purpose processors , which means that such computing systems feature as - small - as - possible operation granularity .",
    "i.e. the simplest arithmetic operations ( sums ) are _ serially _ performed a huge number of times and combined in order to produce the required processing .",
    "this yields that a given ( rather complex ) operation will require a very big number of clock cycles to be performed . on the other hand , hw implementations consist of task - specific circuits made up of many synchronous logic components .",
    "thus , in a hw implementation , a large number of elementary operations will be _ aggregated within a single clock cycle _",
    "( i.e. each time the system clock signal completes a cycle , many elementary operations take place throughout the entire system , in all of its sections ) , clock frequency then can be kept much lower than what is required by sw systems in order to perform , in real - time , the amount of computation required by a certain radio standard .",
    "this is actually where the power efficiency gap between the two implementation classes is generated .    in section",
    "[ sec : ad ] we described ma technique as a way of assisting processing - yielded computation through the usage of memory resources . indeed , given the above analysis of the difference between hw and sw systems , we could even look at the ma approach as a way of making up for the low operation granularity that characterizes software systems and impairs them with respect to their hw counterparts , when it comes to comparing power efficiencies .",
    "i.e. as hw systems do aggregate many operations within the same clock cycle by means of implementing several dedicated subsystems all triggered by each and every clock edge , _ ma approach aggregates many elementary operations by storing the result of their combination into a single table_. some clock cycles will then be used in order to access the content of the table but still , if ma was designed correctly , the amount of _ equivalent _ elementary operations _ performed per single clock cycle _ will be greatly increased .",
    "based on such considerations , the idea of extending memory implementation to the entire radio system starts getting attractive .",
    "thus , we define a memory based sdr ( mb - sdr ) as _ a software defined radio where most ( or all ) of the computation is performed by means of suitable memory look - ups_. it might appear at a first glance that such a design choice conflicts with what stated in section [ subsec : repr ] , where we claimed that efficient sdr implementations must use up all resources available ( calculus and memory ) in order to perform their computation .",
    "actually , by implementing an mb - sdr , calculus resources are not left unused , they are used ( exclusively or almost exclusively ) to cover the computational work [ @xmath57 yielded by memory management .",
    "this obviously loosens performance requirement over computing resources and therefore _ mandates downsizing of the computing core _ in order to have it fully loaded and obtain the required increase in power efficiency . as a result ,",
    "role of the computing core of an mb - sdr is just to _ move the data around _ and _ fetch the necessary information _ from the right memory tables while actual computation truly happens only _ in memory_. considering that , with present technology , an average computer cpu can take about 140 watts of electrical power while 2 gib , double data rate 2 ( ddr2 ) ram modules typically require 4.4 to 5 watts , this appears to be an interesting strategy to increase power efficiency of sdrs .",
    "it is important to note how such a power efficiency gain has absolutely no impact upon the flexibility of the system .",
    "the flexibility and ease of reconfiguration which are peculiar to any sdr are fully conserved by the ma / mb - sdr approach as long as resources used for speeding up the computation are provided by memory and not by a different ( less flexible ) computation technology , as it happens instead whenever performance boost is gained by replacing sw implementations with specialized hw .",
    "as long as we have defined above an mb - sdr as accommodating in memory _ all _ , but even just _ most _ , of the computation yielded by the radio communication system , hierarchical , computational - cost - driven memory - mapping of functional blocks remains a necessity .",
    "rtar is thus kept as the instrument of such prioritization while algorithm segmentation still provides input space cardinality reduction as described for the general case in subsection [ subsec : mas ] .",
    "based on the here - described results obtained by applying ma to a considerably broad set of radio signal processing algorithms , we believe the ma technique presented here can provide substantial performance boost , and thus power efficiency , to existing sdr systems as well as to any system performing signal processing functions over general purpose computing architectures . as long as different algorithms dramatically",
    "differ in the opportunities they offer for algorithm segmentation ( and thus in the achievable acceleration factor ) there is no algorithmic solution to perform as , which therefore remains a peculiarly human design task . for such reason",
    ", we suggest this work opens an interesting lane for research into the signal processing field .",
    "finding optimal segmentation of classical radio signal processing algorithms in order to allow for the most efficient memory acceleration is both a challenging effort and a promising research path .",
    "actually , upon success , performance boosts of at least _ one order of magnitude _ could be delivered to existing software defined radios by making them energy - practical _ without reducing their peculiar flexibility / reconfigurability features_. both theoretical and applied signal processing skills are needed in order to move along such research path .    it must be also considered that acceleration factors presented within this work are obtained by using both computing architectures and compilers ( gnu g++ ) that are totally unaware of the ma approach and therefore neglect memory access optimization in favour of pure computation .",
    "it is thus expected that applying ma on computational back - ends that take into account memory management and access optimization would result in even bigger acceleration factors .",
    "though developed for general purpose cpus , memory acceleration can easily be applied to other computational architectures , for example multicore digital signal processors ( dsps ) or multiprocessor system - on - chip ( mpsoc ) implementations . to such systems",
    "it would provide substantial acceleration by offloading computational effort from processing cores towards onboard memory resources .    in conclusion , we might state that ma / mb - sdr approach promises to be a considerable step along the path to truly flexible radios that have very small loss in power efficiency with respect to equivalent hardware implementation .",
    "d.  cociorva and g.  baumgartner and c.g .",
    "lam and p.  sadayappan and j.  ramanujam and m.  nooijen and d.e .",
    "bernholdt and r.  harrison , _ space - time trade - off optimization for a class of electronic structure calculations _ , new york , usa : acm sigplan notices , volume 37 , pages 177 - 186 , acm , 2002 c.d .",
    "space / time trade - offs for higher radix modular multiplication using repeated addition _ , ieee transactions on computers , vol .",
    "2 , february 1997 m.  stamp , _ once upon a time - memory tradeoff _ , available online : http://en.wikipedia.org/wiki/space-timetradeoff/#external_links    _ digital video broadcasting ( dvb ) ; framing structure , channel coding and modulation for digital terrestrial television _ ,",
    "etsi en 300 744 v1.5.1 , sophia antipolis , france .",
    "j. viterbi , _ error bounds for convolutional codes and an asymptotically optimum decoding algorithm _ , ieee transactions on information theory , vol .",
    "it-13 , april , 1967 , pp .",
    "260 - 269 l.  rose and m.  luise and f.  giannetti and v.  pellegrini,_r - dvb : software defined radio implementation of dvb - t signal detection functions for digital terrestrial television _",
    "v.  pellegrini , m.  di dio , l.  rose , m.  luise _ `` a real time , fully software , etsi dvb - t receiver based on the usrp , '' _ in proceedings wsr10 , karlsruhe , germany , march 2010 .",
    "m.  di dio and m.  luise and f.  giannetti and v.  pellegrini , _ signal synchronization and channel estimation / equalization functions for dvb - t software - defined receivers _ j. j. van de beek and m. sandell and p. o. borjesson , _ ml estimation of time and frequency offset in ofdm systems _",
    "vincenzo pellegrini vincenzo pellegrini received the b.e .",
    "degree in telecommunications engineering from the university of pisa , pisa , italy , in july 2006 . since the beginning of his b.e",
    ". degree thesis , he is actively working with the `` dsp for communications lab '' ( dspcola ) of the dept .",
    "of information engineering , university of pisa , under the supervision of prof .",
    "marco luise . from february 2008",
    "to december 2008 he worked as the main software developer and hardware sub - system integrator of european project grides at wiser srl , livorno . in january 2008",
    "he obtained the first fully software radio implementation of an etsi dvb - t modulator capable of running realtime over low cost general purpose cpus .",
    "results of such work were published along with a full system demonstration in march 2008 at wsr08 conference in karlsruhe , germany .",
    "luca rose luca rose received his cum - laude m.e .",
    "degree from pisa university in april 2009 .",
    "he has been working within dspcola up to september 2009 developing the memory - accelerated viterbi decoder described within this work .",
    "he is now with suplec , paris .",
    "mario di dio received his cum - laude b.e .",
    "degree in telecommunications en- gineering from the university of pisa , pisa , italy , in july 2007 with a the- sis on wireless cooperative communica- tion . in september 2009",
    "he received his cum - laude m.e .",
    "degree from the same university with a thesis developing the synchronization and channel estima- tion / equalization functions for a sdr fully - software dvb - t re- ceiver . since october 2008 he is actively working with the `` dsp for communications lab '' ( dspcola ) of the dept . of infor- mation engineering , university of pisa , under the supervision of prof .",
    "marco luise .",
    "since january 2010 he is attending his phd studies in radio transmission systems at university of pisa .",
    "his research inter- ests are in the areas of digital communications , signal processing and estimation theory .",
    "his current research topics focus on effi- cient signal processing algorithms for sofware defined radio and estimation theory applied to cognitive radio ."
  ],
  "abstract_text": [
    "<S> since j. mitola s work in 1992 , software defined radios ( sdrs ) have been quite a hot topic in wireless systems research . </S>",
    "<S> though many notable achievements were reported in the field , the scarcity of computational power on general purpose cpus has always constrained their wide adoption in production environments . </S>",
    "<S> if conveniently applied within an sdr context , classical concepts known in computer science as _ space / time tradeoffs _ can be extremely helpful when trying to mitigate this problem . </S>",
    "<S> inspired by and building on those concepts , this paper presents a novel sdr implementation technique which we call _ memory acceleration _ ( ma ) that makes extensive use of the memory resources available on a general purpose computing system , in order to accelerate signal computation . </S>",
    "<S> ma can provide substantial acceleration factors when applied to conventional sdrs without reducing their peculiar flexibility . as a practical proof of this , an example of ma applied in the real world to the etsi dvb - t @xcite viterbi decoder @xcite is provided . </S>",
    "<S> actually ma is shown able to provide , when applied to such viterbi decoder , an acceleration factor of _ </S>",
    "<S> 10.4x _ , with no impact on error correction performances of the decoder and by making no use of any other typical performance enhancement techniques such as low level ( assembler ) programming or parallel computation , which though remain compatible with ma . </S>",
    "<S> opportunity for extending the ma approach to the entire radio system , thus implementing what we call a memory - based software defined radio ( mb - sdr ) is finally considered and discussed .    </S>",
    "<S> software radio , signal processing , memory accelerated signal processing , ma , mb - sdr . </S>"
  ]
}