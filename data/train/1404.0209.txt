{
  "article_text": [
    "most models in statistical physics are not solvable analytically , and therefore an alternative way is needed to determine thermodynamical quantities .",
    "numerical simulations help in this task , but introduce another challenge : it is not possible , in most cases , to enumerate all the possible configurations of a system ; one therefore has to create a set of configurations that are representative for the entire ensemble . in this section , we will illustrate our purpose with the ising model .",
    "this is a renowned model because of its simplicity and success in the description of critical phenomena  @xcite .",
    "the degrees of freedom are spins @xmath0 placed at the vertex @xmath1 of a lattice .",
    "this lattice will be square or cubic for simplicity , with edge size @xmath2 and dimension @xmath3 .",
    "thus , the system contains @xmath4 spins .",
    "the hamiltonian of the ising model is : @xmath5 where the summation runs over all pairs of nearest - neighbor spins @xmath6 of the lattice and @xmath7 is the strength of the interaction .",
    "the statistical properties of the system are obtained from the _ partition function _ : @xmath8 where the summation runs over all the configurations @xmath9 .",
    "the energy of a configuration is denoted by @xmath10 . here , @xmath11 is the inverse temperature ( temperature @xmath12 and boltzmann constant @xmath13 ) .",
    "the ising model displays a second - order phase transition at the temperature @xmath14 , characterised by a high temperature phase with an average magnetization zero ( disordered phase ) and a low temperature phase with a non - zero average magnetization ( ordered phase ) .",
    "the system is exactly solvable in one and two dimensions . for @xmath15 ,",
    "the critical properties are easily obtained by the renormalization group . in three dimensions no exact solution is available .",
    "even a @xmath16 cubic lattice of very modest size @xmath17 generates @xmath18 configurations in the partition function .",
    "if we want to obtain e.g. critical exponents with a sufficient accuracy , we need sizes that are at least an order of magnitude larger .",
    "an exact enumeration is a hopeless effort .",
    "_ monte carlo simulations",
    "_ are one of the possible ways to perform a sampling of configurations .",
    "this sampling is made out of a set of configurations of the phase space that contribute the most to the averages , without the need of generating every single configuration .",
    "this is referred to as _ importance sampling_. in this sampling of the phase space , it is important to choose the appropriate monte carlo scheme to reduce the computational time . in that respect ,",
    "the ising model is interesting because the different regimes in temperature lead to the development of new algorithm that reduce tremendously the computational time , specifically close to the critical temperature .",
    "we will start these notes by introducing two important principles of monte carlo simulations : detailed balance and ergodicity .",
    "then we will review different examples of monte carlo methods applied to the ising model : local and cluster algorithms , the rejection free ( or continuous time ) algorithm , and another kind of monte carlo simulations based on an alternative representation of the spin system , namely the so - called worm algorithm .",
    "we continue with discussing dynamical quantities , such as the thermalization and correlation times .",
    "the basic idea of most monte carlo simulations is to iteratively propose a small random change in a configuration @xmath20 , resulting in the trial configuration @xmath21 ( the index `` @xmath22 '' stands for trial ) .",
    "next , the trial configuration is either accepted , i.e. @xmath23 , or rejected , i.e. @xmath24 . the resulting set of configurations for @xmath25 is known as a markov chain in the phase space of the system .",
    "we define @xmath26 as the probability to find the system in the configuration @xmath27 at the time @xmath22 and @xmath28 the transition rate from the state @xmath27 to the state @xmath29 .",
    "this markov process can be described by the master equation : @xmath30\\,,\\label{meq}\\ ] ] with the condition @xmath31 and @xmath32 for all @xmath27 and @xmath29 .",
    "the transition probability @xmath28 can be further decomposed into a trial proposition probability @xmath33 and an acceptance probability @xmath34 so that @xmath35 . a proposed change in the configuration is usually referred to as a monte carlo move .",
    "conventionally , the time scale in monte carlo simulations is chosen such that each degree of freedom of the system is proposed to change once per unit time , statistically .",
    "the first constraint on this markov chain is called _ ergodicity _ : starting from any configuration @xmath36 with nonzero boltzmann weight , any other configuration with nonzero boltzmann weight should be reachable through a finite number of monte carlo moves .",
    "this constraint is necessary for a proper sampling of phase space , as otherwise the markov chain will be unable to access a part of phase space with a nonzero contribution to the partition sum .",
    "apart from a very small number of peculiar algorithms , a second constraint is known as the _ condition of detailed balance_. for every pair of states @xmath27 and @xmath29 , the probability to move from @xmath27 to @xmath29 , as well as the probability for the reverse move , are related via : @xmath37 the meaning of this condition can be seen in eq .",
    "( [ meq ] ) : a stationary probability ( i.e. @xmath38 ) is reached if each individual term in the summation on the right hand side cancels .",
    "this prevents the markov chain to be trapped in a limit cycle  @xcite .",
    "this is a strong , but not necessary , condition .",
    "we mention that generalizations of monte carlo process that do not satisfy detailed balance exist .",
    "the combination of ergodicity and detailed balance assures a correct algorithm , i.e. , given a long enough time , the desired distribution probability is sampled .",
    "the key question in monte carlo algorithms is which small changes one should propose , and what acceptance probabilities one should choose .",
    "the trial proposition and acceptance probabilities have to be well chosen so that the probability of sampling of a configuration @xmath27 ( after thermalization ) is equal to the _ boltzmann weight _ :",
    "@xmath39 in which @xmath40 is the energy of configuration @xmath27 .",
    "the knowledge of the partition function @xmath41 is not necessary because the transition probabilities are constructed with the ratio of probabilities .",
    "the detailed balance condition  ( [ detbal ] ) , using ( [ bolweight ] ) , can be rewritten as : @xmath42",
    "one often - used approach to realize detailed balance is to propose randomly a small change in state @xmath27 , resulting in another state @xmath29 , in such a way that the reverse process ( starting in @xmath29 and then proposing a small change that results in @xmath27 ) is equally likely . more formally , a process in which the condition @xmath43 holds for all pairs of states @xmath44 .",
    "for example , taking the example of an ising model containing @xmath45 spins , it corresponds to chose randomly one of the spins on the lattice , therefore @xmath46 .",
    "detailed balance allows for a common scale factor in the acceptance probabilities for the forward and reverse monte carlo moves , but being probabilities , they can not exceed 1 .",
    "simulations are then fastest if the bigger of the two acceptance probabilities is equal to 1 , i.e. either @xmath47 or @xmath48 is equal to 1 .",
    "these conditions ( including detailed balance ) are realized by the so - called _ metropolis algorithm _ ,",
    "in which the acceptance probability is given by : @xmath49= { \\rm min } \\left[1,\\exp(-\\beta(e_b - e_a ) \\right].\\label{metro}\\ ] ] thus , a proposed move that does not raise the total energy is always accepted , but a proposed move which results in higher energy is accepted with a probability that decreases exponentially with the increase of the energy difference . for the sake of illustration , let us describe how a simulation of the ising model looks like :    1 .",
    "initialize all spins ( either random or all up ) 2 .",
    "perform @xmath45 random trial moves ( @xmath4 ) : 1 .",
    "randomly select a site 2 .",
    "compute the energy difference @xmath50 if the trial ( here a spin flip ) induces a change in energy 3 .",
    "generate a random number @xmath51 uniformly distributed in @xmath52 $ ] 4 .",
    "if @xmath53 or if @xmath54 : flip the spin 3 .   perform sampling of some observables    the step 2 corresponds to one unit time step of the monte carlo simulation .",
    "an alternative to the metropolis algorithm is the _ glauber dynamics",
    "_  @xcite .",
    "the trial probability is the same as metropolis i.e. @xmath55 .",
    "however the acceptance probability is now : @xmath56 which also satisfies the detailed balance condition eq.([detbalbol1 ] ) .",
    "many models encounter phase transitions at some critical temperature .",
    "the paradigmatic example for the second order phase transitions is the ising model defined in eq .",
    "( [ hising ] ) . in the vicinity of the critical temperature , the spins display _",
    "critical fluctuations_. as shown in figure  [ ising ] ( middle ) , large aligned spin domains appear .",
    "this phenomenon is associated with ( i ) the divergence of the correlation length @xmath57 of the connected spin - spin correlation function @xmath58 ( ii ) the divergence of the correlation time of the autocorrelation function @xmath59 . moreover ,",
    "the correlation time increases with the size of the system like @xmath60 where @xmath61 is the _ critical dynamical exponent_. for the 2d ising model simulated with the metropolis algorithm , @xmath62  @xcite .",
    "this phenomenon of critical slowing down reflects the difficulty to change the magnetization of a correlated spin cluster .",
    "take again the example of a 2d spin system where one spin has four nearest neighbors .",
    "if this spin is surrounded by aligned spins , its contribution to the energy is @xmath63 and after the reversal of this spin , this becomes @xmath64 .",
    "right at @xmath65 , the acceptance probability is low for the metropolis algorithm : @xmath66 .",
    "thus , most of the flipping attempts are rejected .",
    "making matters worse , even if such a spin with aligned neighbours is flipped , the next time it is selected , it will surely flip back .",
    "only spin flips at the edge of a cluster have a significant effect over a longer time ; but their fraction becomes vanishingly small when the critical temperature is approached and the cluster size diverges .",
    "one remedy is to develop a non - local algorithm that flips a whole cluster of spins at once .",
    "such an algorithm has been designed for the ising model by wolff  @xcite , following the idea of swendsen and wang  @xcite for more general spin systems .",
    "a sketch of this procedure is shown in figure  [ wolff ] .",
    "the procedure consists of first choosing a random initial site ( seed site ) .",
    "then , we add each neighboring spin , provided it is aligned , with the probability @xmath67 .",
    "if it is not aligned , it can not belong to the cluster .",
    "this step is iteratively repeated with each neighbor added to the cluster . when no neighbor can be added to the cluster anymore , all the spins in the cluster flip at once . the probability to form a certain cluster of spins in state @xmath27 before the wolff move is the same as that in state @xmath29 after the wolff move , except for the aligned spins that have not been added to the cluster at the boundaries . the probability to not add",
    "an aligned spin is @xmath68 .",
    "if @xmath69 and @xmath70 stand for non - added aligned spins to the cluster for @xmath27 and @xmath29 , @xmath71 and the detailed balance condition ( [ detbalbol1 ] ) can be rewritten as : @xmath72 noticing that @xmath73 , it follows that : @xmath74^{n - m}\\,.\\ ] ] therefore , choosing @xmath75 , the acceptance probabilities simplifies : @xmath76 . for this reason the spins can be automatically flipped when the cluster is formed . in the vicinity of the critical point , the wolff algorithm significantly reduces the autocorrelation time and the critical dynamical exponent compared to a local algorithm ( such as metropolis or glauber ) .",
    "we notice that the time @xmath77 measured in units of wolff iterations involves a subset of spins corresponding to the averaged size @xmath78 of a cluster . on the other hand a time @xmath79 measured in units of metropolis iterations involves all spins of the network i.e. @xmath4 spins .",
    "to compare the efficiency of both algorithms fairly , it is therefore necessary to define a rescaled wolff autocorrelation time @xmath80 .",
    "moreover , it is possible to show that @xmath81  @xcite . noticing that @xmath82 , it follows ( remembering @xmath83 ) @xmath84 leading to the definition of the dynamical critical exponent @xmath85 . in 2@xmath3 for example , remarkably , the dynamical exponent is @xmath86 for wolff ( see e.g.  @xcite and references therein ) whereas @xmath87  @xcite for metropolis .",
    "as we have seen in the previous subsection , with a local algorithm ( like e.g. metropolis ) a spin flip of the ising model at criticality has a high probability to be rejected , and this holds even more in the ferromagnetic phase . a significant amount of the computational time will therefore be spent without making the system evolve .",
    "an alternative way has been proposed by gillespie  @xcite in the context of chemical reactions and afterwards applied by bortz , kalos and lebowitz in the context of spin systems  @xcite .",
    "briefly , this algorithm lists all possible monte carlo moves that can be performed in the system in its current configuration .",
    "one of these moves is chosen randomly according to its probability , and the system is forced to move into this state .",
    "the time step of evolution during such a move can be estimated rigourously .",
    "this time will change from each configuration and can not be set to unity as in the metropolis algorithm : it takes a continuous value .",
    "this is why this algorithm is sometimes called _ continuous time algorithm_. on the one hand , this algorithm has to maintain a list of all possible moves , which requires a relatively heavy administrative task , on the other hand , the new configuration is always accepted and this saves a lot of time when the probability of rejection would otherwise be high .",
    "it is also sometimes called the _ rejection free algorithm_. the efficiency of this algorithm will be maximized for @xmath88 . in detail ,",
    "one iteration of the continuous time algorithm looks like :    1 .   list all possible moves from the current configuration .",
    "each of these @xmath70 moves has an associated probability @xmath89 .",
    "2 .   calculate the integrated probability that a move occurs @xmath90 .",
    "3 .   generate a random number @xmath91 uniformly distributed in @xmath92 $ ] .",
    "this selects the chosen move with probability @xmath93 .",
    "4 .   estimate the time elapsed during the move : @xmath94 where @xmath95 is a random number uniformly distributed in @xmath52 $ ] : @xmath96 ) . ]",
    "implementation of this algorithm becomes easier if the probabilities @xmath89 can only take a small number of values . in that case",
    ", lists can be made of all moves with the same probability @xmath89 .",
    "the selection process is then first to select one of the lists , with the appropriate probability , after which randomly one move is selected from that list .",
    "this is the case e.g. in ising simulations on a square ( 2@xmath3 ) or cubic ( 3@xmath3 ) lattice , when the probability @xmath89 is limited to the values @xmath97 , @xmath98 , @xmath99 , or @xmath100 ( the latter occurring only in 3@xmath3 ) .",
    "we present here another example of a local algorithm , the so - called _ worm algorithm _ introduced by prokofev , svistunov and tupitsyn  .",
    "the difference with the algorithms presented above is an alternative representation of the system , in terms of graphs instead of spins .",
    "the markov chain is therefore performed along graph configurations rather than spin configurations , but always with metropolis acceptance rates .",
    "the principle is based on the high temperature expansion of the partition function .",
    "suppose that we want to sample the magnetic susceptibility of the ising model .",
    "we can access it via the correlation function using the ( discrete ) fluctuation - dissipation theorem : @xmath101 where @xmath102 is the connected correlation function between sites @xmath1 and @xmath103 . in the high temperature phase , the average value of the spin cancels and @xmath104 .",
    "the first step is to write the correlation function @xmath105 of the ising model in the following form : @xmath106     illustration of a move with the worm algorithm .",
    "thick lines stand for one example of graph contributing to the correlation function : one path joining the sites @xmath1 et @xmath103 ( the sources ) and possibly closed loops .",
    "these two graphs differ in one iteration of the worm algorithm . according to ( [ dev2 ] ) , the graph on the left and on the right have respective equilibrium probabilities @xmath107 and @xmath108 ( we neglect loops that are not relevant for this purpose ) . from the detailed balance condition ( [ detbal ] ) , the metropolis acceptance rates are @xmath109 and @xmath110 . in both case",
    "@xmath111 where @xmath3 is the dimension of the ( hypercubic ) lattice . ]",
    "the configurations that contribute to the sum in ( [ dev2 ] ) contain an even number of spins in the product at any given site .",
    "other products involving an odd number of spins in the product contribute zero .",
    "each term can be associated with a path determined by the sites involved in it .",
    "a contribution to the sum is made of a ( open ) path joining sites @xmath1 and @xmath103 and closed loops .",
    "the sum over the configurations can be replaced by a sum over such graphs .",
    "figure  [ worm - bis ] sketches such a contribution for a given couple of source sites @xmath1 and @xmath103 .",
    "the importance sampling is no longer made over spin configurations but over graphs that are generated as follows .",
    "one of the two sources , say @xmath1 , is mobile . at every steps , it moves randomly to a neighboring site @xmath70 .",
    "any nearest - neighbor site can be chosen with the trial probability @xmath112 , where @xmath3 is the dimension of the ( hypercubic ) lattice .",
    "if no link is present between the two sites , then a link is created with the acceptance probability : @xmath113 if a link is already present , it is erased with the acceptance probability : @xmath114 since @xmath115 for all values @xmath116 , the probability ( [ taux2 ] ) is equal to unity and the link is always erased .",
    "these probabilities are obtained considering the metropolis acceptance rate eq.([metro ] ) and the expression of the correlation function ( [ dev2 ] ) .",
    "the procedure is illustrated in figure  [ worm - bis ] .",
    "the open paths in the two graphs are resp .",
    "made of 5 and 6 lattice spacings ( we neglect the loop that does not contribute in this example ) . according to ( [ dev2 ] ) , the graphs on the left and on the right have equilibrium probabilities @xmath117 and @xmath118 , respectively .",
    "the transition probability ( [ metro ] ) is thus written @xmath119 and @xmath120 , in agreement with ( [ taux1 ] ) and ( [ taux2 ] ) .",
    "if the two sources meet , they can move together on another random site with a freely chosen transition probability .",
    "when the two sources move together , they leave a closed loop behind that justifies the simultaneous presence of open path and closed loop in figure  [ worm - bis ] .",
    "these loops may disappear if the head of the worm meets them .",
    "compared to the swendsen - wang algorithm , the worm algorithm has a dynamical exponent slightly higher in 2@xmath3 but significantly lower in 3@xmath3  @xcite .",
    "the efficiency of this algorithm can be improved with the use of a continuous time implementation  @xcite .",
    "the formalism of the worm algorithm is suitable for high temperature . in the critical region ,",
    "the number of graphs that contribute to the correlation function increases exponentially . in order to check the convergence of the algorithm",
    ", we can compare it with the wolff algorithm for the 5@xmath3 ising model with different lattice sizes in figure  [ test ] .",
    "the two algorithms give results in good agreement , except in the critical region where the converge of the worm algorithm is slower as the lattice size @xmath2 increases .",
    "in order to perform a sampling of thermodynamical quantities at a given temperature , one has to first thermalize the system .",
    "usually , it is possible to set up the system either at infinite temperature ( all spins random ) or in the ground state ( all spins up or down ) .",
    "let us start from an initial random configuration .",
    "if the thermalization takes place above the critical temperature , then the relaxation is exponential .",
    "as we come closer to the critical point , the equilibrium correlation length becomes larger and the relaxation becomes much slower and eventually algebraic right at @xmath14 .",
    "an example of such process for the 2@xmath3 ising model is given in fig .",
    "[ quench ] .",
    "initially ( @xmath121 ) , the system is prepared at infinite temperature , all the spins are random",
    ". then the glauber dynamics is applied at the critical temperature .",
    "we see the nucleation and the evolution of correlated spin domains in time ( @xmath1220 , 10 , 100 , 1000 from left to right ) .",
    "it is possible to show that in such a quench , the correlation length grows with time like  @xcite : @xmath123 where @xmath61 is the critical dynamical exponent ( @xmath62  @xcite for the 2@xmath3 ising model ) .",
    "the time needed to complete thermalization at criticality is therefore @xmath124 . in case of a subcritical quench ,",
    "the system has to choose between two ferromagnetic states of opposite magnetization .",
    "again , the relaxation is slow because there is nucleation and growth of domain of opposite magnetization .",
    "we define the typical size of a domain at a time @xmath22 by @xmath125 .",
    "the thermalization process involves the growth ( coarsening ) of these domains , until eventually one domain spans the whole system .",
    "only then , equilibrium is reached ( in the low temperature phase , the expectation of the absolute value of the magnetization is nonzero ) .",
    "the motion of the domain walls is mostly diffusive @xmath126 with a dynamical exponent @xmath127  @xcite .",
    "the walls have to cover a distance @xmath128 , so that the thermalization time scales as @xmath129 .",
    "this time diverges again with system size . starting from an ordered state",
    "does not help for the critical quench ( but it does help to start in the ground state to thermalize the system at @xmath130 ) .",
    "once the system is thermalized , one has to be aware of another dynamical effect : the correlation time .",
    "this is the time needed to perform sampling between statistically uncorrelated configurations . in the high temperature phase ,",
    "the correlation time is equal to the thermalization time , up to some factor close to unity .",
    "this is not surprising , as proper thermalization requires the configuration to become uncorrelated from the initial state .",
    "practically , in all monte carlo simulations , one has to estimate @xmath131 at the temperature of sampling to treat properly the error bars .    in the low temperature phase , after thermalization ,",
    "the magnetization is either positive or negative , and stays like that over prolonged periods of time .",
    "so - called magnetization reversals do occur now and then , but the characteristic time between those increases exponentially with system size . because of the strict symmetry between the parts of phase space with positive and negative magnetization , in practice one is not so much interested in the time of magnetization reversals , but rather in the correlation time @xmath131 within the up- or down - phase ; and this time is some temperature - dependent constant , irrespective of the system size provided it is significantly larger than the correlation length .",
    "let us consider now the two - time spin - spin correlation functions in the framework of dynamical scaling  @xcite .",
    "we will use for this purpose a continuous space , so that the spin @xmath132 on the site @xmath1 is now denoted by @xmath133 where @xmath134 is the position vector . upon a dilatation with a scale factor @xmath135 , the equilibrium correlation @xmath136",
    "is assumed to satisfy the homogeneity relation : @xmath137 where @xmath138 is the scaling dimension of magnetization density with @xmath139 for two - dimensional systems and @xmath61 is again the critical dynamical exponent .",
    "the motivation for the last two arguments of the scaling function in equation ( [ eq1c ] ) comes from the behavior of the correlation length either with time , @xmath140 , or with temperature , @xmath141 . setting @xmath142 in equation ( [ eq1c ] )",
    ", we obtain : @xmath143 the algebraic prefactor corresponds to the critical behavior while the scaling function includes all corrections to it .",
    "the characteristic time : @xmath144 appears as the relaxation time of the system .",
    "here we are interested only in autocorrelation functions for which @xmath145 .",
    "moreover , we expect an exponential decay of the scaling function @xmath146 in the paramagnetic phase .",
    "therefore , the autocorrelation function can generally be written at equilibrium as : @xmath147    the spin - spin autocorrelation function @xmath148 versus time is plotted in fig.[fig : mcor ] ( left ) for the 2@xmath3 ising model of size @xmath149 .",
    "the different curves correspond to different inverse temperatures @xmath150 to 0.39 ( the critical inverse temperature is @xmath151 ) .",
    "we observe an increase of the autocorrelation time as the temperature comes closer to @xmath14 .",
    "the autocorrelation time can be obtained from a fit of the curve in the main graph , assuming eq.([eq2 ] ) .",
    "the result is plotted versus @xmath152 in the inset .",
    "the numerics tend to the behavior of eq.([scaltau ] ) as @xmath12 goes to @xmath14 .",
    "some other aspects of critical dynamics are interesting to study , for instance , the time evolution of the equilibrium mean - square displacement of the magnetization .",
    "it is defined as : @xmath153    at small time differences ( @xmath154 ) , the dynamics consists of sparsely distributed proposed spin flips , each of which has a nonzero acceptance probability .",
    "since these spin flips are uncorrelated and their number scales as @xmath155 , in the short - time regime ( @xmath156 ) , @xmath157 behaves diffusively : @xmath158    the magnetization at long time @xmath159 is no longer correlated i.e. @xmath160 .",
    "moreover , the expectation value of the squared magnetization is directly related to the magnetic susceptibility like @xmath161 where @xmath4 ( for @xmath162 , @xmath163 ) .",
    "it diverges at the critical temperature with system size as @xmath164 , implying : @xmath165 therefore @xmath157 has to grow from @xmath166 to @xmath167 . assuming a power law behavior",
    ", it follows that @xmath168 .",
    "therefore , in this regime , we can assume the following form for @xmath157 : @xmath169 where @xmath170 is a scaling function with the limit @xmath171 when @xmath172 and @xmath173 at intermediate times .",
    "we measured the function @xmath157 as defined in eq.([eq : mcor ] ) in simulations of the two - dimensional ising model at the critical temperature for various systems sizes .",
    "the scaling function @xmath170 is plotted in fig .  [",
    "fig : mcor ] ( right ) , using the exponents @xmath174 , @xmath175 and @xmath176 .",
    "with increasing system size , the data become increasingly consistent with a simple power law behavior ( for intermediate times between the early - time behavior ( eq .",
    "( [ eq : early ] ) and the time of saturation @xmath177 ) .",
    "this power law behavior corresponds to an instance of _ anomalous diffusion _",
    "i.e. a mean - square deviation growing as a power law with an exponent @xmath178 compatible with : @xmath179    assuming eq.([ad ] ) , the magnetization autocorrelation function for intermediate times ( i.e. between times of order unity and the correlation time , thus spanning many decades ) is compatible with the first terms of the taylor expansion of a stretched exponential : @xmath180 this conjecture compares well with the numercis for the correlation function in figure  [ fig : mcor ] ( right , in the inset ) .",
    "this shows that the dynamical critical exponent @xmath61 appears at relatively small times @xmath181 .",
    "in these lecture notes , we provide an introduction to monte carlo simulations that are a way to produce a set of representative configurations of a statistical system .",
    "we start with the basic principles : ergodicity and detailed balance . in the next parts , we present several monte carlo algorithms .",
    "to illustrate their functioning , we use the example of the ising model .",
    "this model is defined by scalar spins on a lattice that interact via nearest - neighbor interactions .",
    "this is the paradigmatic system for second order phase transitions : a critical temperature shares a disorderered phase at high temperature and an ordered phase at low temperature .",
    "these different regimes induce different strategies for the monte carlo simulations . in the disordered phase ,",
    "local algorithms such as metropolis or glauber are efficient . in the critical region ,",
    "the appearance of long range correlations have set a computational challenge .",
    "it has been solved by the use of cluster algorithms such as the wolff algorithm that flips a whole cluster of correlated spins . below the critical temperature ,",
    "when the probability of spin flip is low , it is a gain of computational time to program the continuous time algorithm .",
    "it forces the system into a new configurations , with a jump in time according to the probability of transition .",
    "finally , we describe an interesting algorithm based on an alternative representation of the model in terms of graphs instead of spins .",
    "we end with important considerations on the dynamics : thermalization and correlation time .",
    "we thank christophe chatelain for his careful reading of the manuscript and the various collaborations that have largely inspired these notes .",
    "we also thank raoul schram for stimulating discussions and the reading of the manuscript .",
    "j - cw is supported by the laboratory of excellence initiative ( labex ) numev , od by the scientific council of the university of montpellier 2 .",
    "this work is part of the d - itp consortium , a program of the netherlands organisation for scientific research ( nwo ) that is funded by the dutch ministry of education , culture and science ( ocw ) .",
    "nightingale m p @xmath19 blte h w j ( 1996 ) dynamic exponent of the two - dimensional ising model and monte carlo computation of the subdominant eigenvalue of the stochastic matrix _ phys .",
    "lett . _ * 76 * , 4548 .",
    "gnd s , dilaver m , aydin m @xmath19 gnd y ( 2005 ) a study of dynamic finite size scaling behavior of the scaling functions - calculation of dynamic critical index of wolff algorithm _ comp .",
    "comm . _ * 166 * , 1 .",
    "gillespie d t ( 1976 ) a general method for numerically simulating the stochastic time evolution of coupled chemical reactions _ j. comp",
    ". phys . _ * 22*,403434 ; ( 1977 ) exact stochastic simulation of coupled chemical reactions _ j. phys .",
    "chem . _ * 81 * , 23402361 ."
  ],
  "abstract_text": [
    "<S> monte carlo simulations are methods for simulating statistical systems . </S>",
    "<S> the aim is to generate a representative ensemble of configurations to access thermodynamical quantities without the need to solve the system analytically or to perform an exact enumeration . </S>",
    "<S> the main principles of monte carlo simulations are ergodicity and detailed balance . </S>",
    "<S> the ising model is a lattice spin system with nearest neighbor interactions that is appropriate to illustrate different examples of monte carlo simulations . </S>",
    "<S> it displays a second order phase transition between a disordered ( high temperature ) and ordered ( low temperature ) phases , leading to different strategies of simulations . the metropolis algorithm and </S>",
    "<S> the glauber dynamics are efficient at high temperature . </S>",
    "<S> close to the critical temperature , where the spins display long range correlations , cluster algorithms are more efficient . </S>",
    "<S> we introduce the rejection free ( or continuous time ) algorithm and describe in details an interesting alternative representation of the ising model using graphs instead of spins with the worm algorithm . </S>",
    "<S> we conclude with an important discussion of the dynamical effects such as thermalization and correlation time .    </S>",
    "<S> monte carlo simulations , ising model , algorithms </S>"
  ]
}