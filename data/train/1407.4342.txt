{
  "article_text": [
    "extended min - sum ( ems ) type decoders @xcite for non - binary ldpc codes achieve a considerable complexity reduction with respect to the full sum - product ( sp ) decoder .",
    "ems decoders work with truncated messages in the logarithmic domain , while sp decoders typically work with full messages of length @xmath0 in the probability domain , where @xmath0 is the alphabet size .",
    "a rough side by side comparison gives    * a variable nodes of degree @xmath5 in the logarithmic domain performs an addition of @xmath6 terms followed by @xmath5 substractions to compute extrinsic messages ; * the same variable node in the probability domain performs a multiplication of @xmath6 factors followed by @xmath5 divisions ; * a check node of degree @xmath7 must perform @xmath7 cyclic convolutions of @xmath8 input vectors ; * a cyclic convolution of two vectors of length @xmath0 computed directly requires @xmath9 multiplications followed by @xmath0 sums of @xmath0 terms ; * in the probability domain , if the alphabet size is a power of 2 , i.e. , @xmath10 , the cyclic convolution can be achieved by taking a walsh hadamard ( wh ) transform , then performing extrinsic products as in a variable node , and then applying the inverse wh transform .",
    "this reduces the complexity of the cyclic convolution from an order of @xmath9 to an order of @xmath3 .",
    "fitting these elements together , we see that if the ems works with truncated messages of length @xmath11 , then it will achieve a lower complexity order only if @xmath12 .",
    "complexity order is only relevant in the asymptotic regime . for non - binary ldpc decoding",
    ", the asymptotic complexity for large @xmath0 and @xmath1 is irrelevant .",
    "the cases of interest for all practical purposes are for @xmath0 between 4 and 256 .",
    "therefore , in order to assess the benefits of ems decoders , it is crucial to get an exact comparison between the number of operations for specific values of interest for @xmath0 and @xmath1 .    in the literature on ems decoders @xcite",
    ", it is naturally assumed that the wh based decoders in the probability domain can only be applied to full non - truncated messages and therefore there can be no reduction from the complexity order of @xmath3 . in this contribution , we show that this is not exactly true and that , while the wh transform must be applied to a full length message , some complexity savings can be achieved if the full length message has been converted from a truncated message . we proceed to define a framework for counting the exact number of additions and minus operations that are required by a wh transform in a decoder working with truncated messages .",
    "this paves the way for a fair complexity comparison of the ems with essentially equivalent wh - based approaches .",
    "if we work with truncated messages , it is necessary to specify which symbols in gf(@xmath0 ) the message entries correspond to .",
    "this is not necessary for full - length messages because the natural ordering of message entries to symbols can be assumed .",
    "reduced complexity approaches based on the cyclic convolution of truncated messages need to carry the assignment of message entries to symbols through the operations , performing sums in gf(@xmath0 ) in parallel to the message value calculations in order to work out the assignment of message entries to symbols in the resulting message .",
    "note that when applying a cyclic convolution to two truncated messages of length @xmath11 , the result is likely to have more than @xmath1 entries .",
    "therefore , selecting which of the @xmath1 entries to retain in the resulting truncated message is a non - trivial operation that is part of the design process for reduced complexity algorithms .",
    "working in the logarithmic domain with full messages is fully equivalent to the probability domain .",
    "if we denote messages in the probability domain as @xmath13 then the equivalent message in the logarithmic domain @xmath14 is defined as @xmath15 where @xmath16 is an arbitrary constant , typically @xmath17 or @xmath18 , where the latter ensures that all message entries are positive .",
    "even if the constant @xmath16 is unknown , the probability vector can be recovered from the vector of logarithms by normalizing so that its entries sum to 1 .    for truncated messages , working in the logarithmic domain adds a dimension of subtelty . in the probability domain , the values of the truncated message contain an implicit statement about the values of the probabilities in the part of the message that is missing .",
    "since the probabilities over the complete symbol alphabet must sum to 1 , we know that the sum of the probabilities in the missing part is the difference between the sum of message values and 1 , i.e. , if @xmath19 is the set of symbols corresponding to entries in the truncated message , @xmath20 it is common to assume that the probabilities in the missing part of the message are uniformly distributed , i.e. , for @xmath21 , @xmath22 where @xmath23 .",
    "when working in the logarithmic domain , there is now an extra degree of freedom , as the sum of probabilities in the message is not expected to be 1 , and therefore the @xmath16 can not be recovered from the message . if the @xmath16 used in the conversion is unspecified , the logarithmic message becomes disconnected from any specific probability vector . in practice ,",
    "reduced complexity methods operating cyclic convolutions on truncated messages do not bother to specify @xmath16 and appear not to suffer from the resulting disconnection .",
    "reduced complexity methods operating on truncated messages aim to retain the symbols with highest probabilities within their truncated message , assuming all others to be uniformly distributed . since the transformation into the logarithmic domain is monotone irrespective of @xmath16 , retaining the symbols with maximal @xmath24 is equivalent to maximizing the corresponding probabilities .",
    "we have seen that conceptually , methods operating on truncated messages are assuming probability distributions with uniform tails on the complete symbol alphabet , where the uniform tail contains the symbols that are missing in the truncated message .",
    "if we now consider the walsh - hadamard approach to the cyclic convolution , we are constrained by the fact that the wh transform can not be applied to a truncated message .",
    "this is because the rule that multiplication in the wh domain is equivalent to a convolution in the time domain only applies if the wh transform is taken over the full symbol alphabet size .",
    "we can however replace a true complete probability distribution by a distribution with a uniform tail , following the same concept as truncated message decoders .",
    "indeed , we can transmit truncated messages along the edges of our decoder graph , and add a uniform tail before the message enters the wh transform .",
    "similarly , we can truncate the message coming out of the wh transform before the check node outputs it to an edge in the graph .",
    "therefore , any complexity reduction for wh - based decoders operating on messages with uniform tails must answer the following questions :    * can the complexity of the wh transform be reduced below @xmath25 when the input vector has a uniform tail ? * can the complexity of the _ inverse _ wh transform be reduced below @xmath25 if we are ultimately only interested in the largest @xmath1 outputs of the transform ?    we will address these questions in the following sub - sections .",
    "let @xmath19 be the set of @xmath1 symbol indices in a truncated message received from the graph .",
    "we complete the message as a full - length message @xmath26 such that @xmath27 is the entry in the truncated message for @xmath28 , and @xmath29 where @xmath30 is defined as in ( [ eq : tailprobs ] ) .",
    "let us now re - write the message as a sum @xmath31 where @xmath32 is a uniform message of length @xmath0 with entries @xmath33 and @xmath34 is defined as @xmath35 since the wh transform is linear , the transform of @xmath36 is equal to the sum of the transforms of @xmath32 and @xmath34 .",
    "the wh transform of the uniform vector @xmath32 has a nonzero component @xmath37 in position 1 and all zeros elsewhere .",
    "our problem then is to estimate the complexity of the wh transform applied to a vector @xmath34 of length @xmath0 with only @xmath11 non - zero entries .",
    "( 120,70 ) ( 0,70)[lb ] ( 0,0)(0,10)8 ( 2,0)(20,0)7 ( 20,10)[lb ] ( 0,0)(0,10)2(1,0)20 ( 0,0)(2,1)20 ( 0,10)(2,-1)20 ( 20,80)[lb ] ( 0,0)(0,20)4 ( 0,0)(40,0)3 ( 20,0)(0,40)2(1,0)20 ( 20,30)(0,40)2(1,0)20 ( 20,10)(0,40)2(2,1)20 ( 20,20)(0,40)2(2,-1)20 ( 60,0)(0,20)2(1,0)20 ( 60,50)(0,20)2(1,0)20 ( 60,10)(0,20)2(2,3)20 ( 60,40)(0,20)2(2,-3)20 ( 100,0)(1,0)20 ( 100,10)(2,3)20 ( 100,20)(2,-1)20 ( 100,30)(1,1)20 ( 100,40)(1,-1)20 ( 100,50)(2,1)20 ( 100,60)(2,-3)20 ( 100,70)(1,0)20 ( 0,10)(1,0)20 ( 20,10)(2,1)20 ( 0,10)(2,-1)20 ( 20,0)(1,0)20 ( 40,0)(1,0)20 ( 60,0)(1,0)20 ( 40,0)(2,1)20 ( 60,10)(2,3)20 ( 40,20)(1,0)20 ( 60,20)(1,0)20 ( 40,20)(2,1)20 ( 60,30)(2,3)20 ( 80,0)(1,0)20 ( 100,0)(1,0)20 ( 80,0)(2,1)20 ( 100,10)(2,3)20 ( 80,20)(1,0)20 ( 100,20)(2,-1)20 ( 80,20)(2,1)20 ( 100,30)(1,1)20 ( 80,40)(1,0)20 ( 100,40)(1,-1)20 ( 80,40)(2,1)20 ( 100,50)(2,1)20 ( 80,60)(1,0)20 ( 100,60)(2,-3)20 ( 80,60)(2,1)20 ( 100,70)(1,0)20 ( 0,50)(2,-1)20 ( 20,40)(1,0)20 ( 0,50)(1,0)20 ( 20,50)(2,1)20 ( 40,40)(1,0)20 ( 60,40)(2,-3)20 ( 40,40)(2,1)20 ( 60,50)(1,0)20 ( 40,60)(1,0)20 ( 60,60)(2,-3)20 ( 40,60)(2,1)20 ( 60,70)(1,0)20 ( 80,10)(2,-1)20 ( 80,10)(1,0)20 ( 80,30)(2,-1)20 ( 80,30)(1,0)20 ( 80,50)(2,-1)20 ( 80,50)(1,0)20 ( 80,70)(2,-1)20 ( 80,70)(1,0)20    an example of this is illustrated in figure  [ fig : whdir ] , where the wh transform is applied to a vector of length 8 with only 2 non - zero elements .",
    "the bold lines in the graph correspond to edges transporting non - zero elements , while the gray edges transport only zeros . instead of the usual @xmath38 additions and @xmath39 minus operations required by the wh transform",
    ", we see that only 8 additions and 10 minus operations are performed in this case",
    ". a wh butterfly processing two zeros does not need to be activated at all . a wh butterfly processing one non - zero element and a zero requires only a copy and possibly a minus operation but no addition .",
    "only wh butterflies receiving two non - zero elements perform two additions and one minus each .",
    "the number of additions and minus operations can vary , as illustrated in figure  [ fig : whdir2 ] , where only 2 additions and 1 minus operation are required for a different configuration of 2 non - zero elements in a length 8 input vector .",
    "( 120,70 ) ( 0,70)[lb ] ( 0,0)(0,10)8 ( 2,0)(20,0)7 ( 20,10)[lb ] ( 0,0)(0,10)2(1,0)20 ( 0,0)(2,1)20 ( 0,10)(2,-1)20 ( 20,80)[lb ] ( 0,0)(0,20)4 ( 0,0)(40,0)3 ( 20,0)(0,40)2(1,0)20 ( 20,30)(0,40)2(1,0)20 ( 20,10)(0,40)2(2,1)20 ( 20,20)(0,40)2(2,-1)20 ( 60,0)(0,20)2(1,0)20 ( 60,50)(0,20)2(1,0)20 ( 60,10)(0,20)2(2,3)20 ( 60,40)(0,20)2(2,-3)20 ( 100,0)(1,0)20 ( 100,10)(2,3)20 ( 100,20)(2,-1)20 ( 100,30)(1,1)20 ( 100,40)(1,-1)20 ( 100,50)(2,1)20 ( 100,60)(2,-3)20 ( 100,70)(1,0)20 ( 0,10)(1,0)20 ( 20,10)(2,1)20 ( 0,10)(2,-1)20 ( 20,0)(1,0)20 ( 0,0)(2,1)20 ( 0,0)(1,0)20 ( 40,0)(1,0)20 ( 60,0)(1,0)20 ( 40,0)(2,1)20 ( 60,10)(2,3)20 ( 40,20)(1,0)20 ( 60,20)(1,0)20 ( 40,20)(2,1)20 ( 60,30)(2,3)20 ( 80,0)(1,0)20 ( 100,0)(1,0)20 ( 80,0)(2,1)20 ( 100,10)(2,3)20 ( 80,20)(1,0)20 ( 100,20)(2,-1)20 ( 80,20)(2,1)20 ( 100,30)(1,1)20 ( 80,40)(1,0)20 ( 100,40)(1,-1)20 ( 80,40)(2,1)20 ( 100,50)(2,1)20 ( 80,60)(1,0)20 ( 100,60)(2,-3)20 ( 80,60)(2,1)20 ( 100,70)(1,0)20    as these figures demonstrate , the number of operations is a random variable that depends on the position of the non - zero elements in the input vector .",
    "let us denote as @xmath40 a vector of indicator random variables that are 1 if the corresponding entry is non - zero and 0 if the corresponding entry is 0 .",
    "the number of non - zero elements @xmath1 in an input vector is the hamming weight @xmath41 of the corresponding vector of indicator variables .",
    "we will assume that all patterns of non - zero input elements are equally probable , e.g. , @xmath42 for any @xmath43 .",
    "the number of additions @xmath44 and the number of minus operations @xmath45 depend only on the vector of indicator random variables , i.e. , @xmath46 and @xmath47 .",
    "we are interested in evaluating the expectated number of operations @xmath48 $ ] and @xmath49 $ ] in the wh transform .",
    "we follow two approaches , one approximate and the other exact .",
    "the approximate approach assumes that @xmath50 is the output of a bernoulli process with parameter @xmath51 .",
    "this means that the number of non - zero entries is now a random variable rather than being fixed , but its expected value is equal to @xmath1 , and all sequences of weight @xmath1 remain equi - probable , even though we are assuming the wrong sequence probabilities .",
    "if we consider the first layer of butteflies in the wh transform , we note that both outputs of a butterfly will be non - zero if any or both of its inputs are non - zero ] .",
    "therefore , we can write a recursive formula for the probability of a non - zero entry at the output of a layer of butterflies given its input probability @xmath52 where we note @xmath53 for the input probability of the first layer . of course the outputs of a layer are not bernoulli , since non - zero outputs always come in pairs .",
    "we will make a further approximation in assuming that the interleavers between layers of butterflies are random , resulting in bernoulli inputs to each layer , so that we can safely apply ( [ eq : recursive_probs ] ) to all layers in the wh transform .",
    "a butterfly with two non - zero entries will perform two additions and one minus operation ; a butterfly with one non - zero entry will perform no additions and possibly one minus ; and a butterfly with zero entries performs no operations at all .",
    "therefore , we can express the expected number of additions for a layer as @xmath54 \\approx \\frac{q}{2}(2p_i^2 ) = qp_i^2 \\label{eq : adds_layer}\\ ] ] where @xmath55 is the expected number of additions per butterfly and @xmath56 is the number of butterflies per layer .",
    "similarly , we can express the expected number of minus operations for a layer as @xmath57 \\approx \\frac{q}{2}[p_i^2+p_i(1-p_i ) ] = qp_i/2 .",
    "\\label{eq : minuses_layer}\\ ] ] by applying ( [ eq : recursive_probs ] ) recursively and ( [ eq : adds_layer ] ) and ( [ eq : minuses_layer ] ) to each layer , we can calculate a simple approximation to the number of additions and minus operations required by the length @xmath0 wh transform with @xmath58 non - zero entries .",
    "these figures will not be exact because they rely on two approximations , namely replacing the exact number of non - zero entries by an expectation , and assuming that the interleavers between layers in the wh transform are random .",
    "table  [ table : nops_wh64 ] at the end of this section shows the results obtained with the approximate method versus the exact values for @xmath59 .",
    "the approximations appear to be slightly lower than the exact values .",
    "the approximate approach has the advantage that it is much easier to evaluate and does not require to evaluate any factorials .",
    ".excact numbers of operations for @xmath1 non - zero inputs in a length @xmath60 wh transform , and exact number of additions and minus operations in a length @xmath61 wh transform [ cols=\"^,^,^\",options=\"header \" , ]     the results in table  [ table : nops_wh64 ] show that substantial savings can be achieved for @xmath59 when @xmath1 is smaller than about 16 , with a ballpoint figure of approximately 50% savings for additions from @xmath3 for @xmath62 . the last line for @xmath63 corresponds to full - length messages with no non - zero entries , with exactly @xmath3 additions and @xmath64 minus operations .",
    "figure  [ fig : additions - wh ] shows the number of additions relative to @xmath3 for a fixed truncated size @xmath65 , demonstrating that the savings improve as the alphabet size grows",
    ".      a similar approach could be adopted to count the number of operations in an inverse wh transform when only a portion of the output message needs to be computed . however",
    ", this approach assumes that we know which of the output symbols will be in the truncated message and which symbols will be left out and assigned to the uniform tail . the obvious way to select symbols for",
    "the truncated message is to retain the @xmath1 symbols with the largest probability .",
    "however , this requires to compute all @xmath0 values in order to decide which @xmath1 values are the largest .",
    "hence , reducing the complexity of the inverse wh transform is a harder problem , that lies outside the scope of this paper",
    ". it may be possible to reduce the complexity based on novel techniques proposed in @xcite .",
    "we have presented evidence to the fact that using truncated messages in wh - based iterative decoders for non - binary codes can achieve gains with respect to full wh decoders . at this point , we are unable to conclude whether wh based decoders operating on truncated messages may compete with ems decoders , because constraint nodes need to take an inverse wh transform for every outgoing message .",
    "we have as of yet no conclusive evidence that the complexity of the inverse wh transform can be reduced if the target is a truncated message .",
    "hence , currently there is no doubt that the ems and its many variants is the most efficient known algorithm for decoding non - binary ldpc codes .",
    "we believe however that wh based decoders should be investigated further as there may be a way to achieve comparable complexity with methods operating in the wh domain if reduced complexity inverse wh transforms can be devised .      d.  declercq and m.  p. fossorier , `` decoding algorithms for nonbinary ldpc codes over gf(q ) , '' _ ieee trans .",
    "_ , vol .  55 , no .  4 , pp . 633643 , apr . 2007 . [ online ] .",
    "available : http://publi-etis.ensea.fr/2007/df07\"[http://publi-etis.ensea.fr/2007/df07 \" ]    a.  voicila , d.  declercq , f.  verdier , m.  fossorier , and p.  urard , `` low - complexity decoding for non - binary ldpc codes in high order fields , '' _ ieee trans . on commun .",
    "_ , vol .",
    "58 , no .  5 , pp .",
    "13651375 , may 2010 .",
    "e.  li , d.  declercq , and k.  gunnam , `` trellis based extended min - sum algorithm for non - binary ldpc codes and its hardware structure , '' _ in ieee trans . communications _ , vol .",
    "61 , no .  7 , pp .",
    "26002611 , july 2013 .",
    "r.  scheibler , s.  haghigahatshoar , and m.  vetterli , `` a fast hadamard transform for signals with sub - linear sparsity in the transform domain , '' 2013 , arxiv pre - print .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1310.1803"
  ],
  "abstract_text": [
    "<S> the extended min - sum ( ems ) algorithm for non - binary low - density parity - check ( ldpc ) defined over an alphabet of size @xmath0 operates on truncated messages of length @xmath1 to achieve a complexity of the order @xmath2 . in contrast , walsh - hadamard ( wh ) transform based iterative decoders achieve a complexity of the order @xmath3 , which is much larger for @xmath4 . in this paper </S>",
    "<S> , we demonstrate that considerable savings can be achieved by letting wh based decoders operate on truncated messages as well . </S>",
    "<S> we concentrate on the direct wh transform and compute the number of operations required if only @xmath1 of the @xmath0 inputs are non - zero . </S>",
    "<S> our paper does not cover the inverse wh transform and hence further research is needed to construct wh based decoders that can compete with the ems algorithm on complexity terms . </S>"
  ]
}