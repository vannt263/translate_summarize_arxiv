{
  "article_text": [
    "what are the laws that regulate learning on a neuronal level in animals or humans ? so far this important question is open , however , the imagination one has for a biological learning rule is that the synaptic weights are changed according to a local rule . in the context of neural networks",
    "means that only the adjacent neurons of a synapse contribute to changes of the synaptic weight .",
    "such a mechanism with respect to synaptic strengthening was proposed by donald hebb @xcite in 1949 and experimentally found by t. bliss and t. lomo @xcite . in a biological terminus hebbian learning",
    "is called _ long - term potentiation _ ( ltp ) .",
    "experimentally as well as theoretically there is a great body of investigations aiming to formulate precise conditions under which learning in neural networks takes place .",
    "for example the influence of the precise timing of pre- and postsynaptic neuron firing @xcite or the duration of a synaptic change ( for a review see @xcite ) termed _ short _ or _ long - term plasticity _ have been studied extensively .",
    "all of these contributions share the locality condition proposed by hebb @xcite . in this article",
    "we present a novel stochastic hebb - like learning rule inspired by experimental findings about heterosynaptic plasticity @xcite .",
    "this form of neural plasticity affects not only the synpase between pre- and postsynaptic neuron in which a synaptic modification was induced , but also further remote synapses of the pre- and postsynaptic neuron .",
    "additionally , we demonstrate that this learning rule can be successfully applied to train multilayer neural networks .",
    "this paper is organized as follows . in section [ intro_nn ]",
    "we give the motivation for our learning rule by a summary of experimental observations concerning synaptic plasticity and properties of biological and artificial neural networks as far as they are useful for a better understanding of our learning rule . in section [ def_lr ]",
    "we propose our learning rule and give a mathematical definition .",
    "we investigate our learning rule in section [ results ] by numerical simulations . in section [ discussion ]",
    "we discuss and compare our stochastic learning rule with other learning rules .",
    "this article ends in section [ end ] with a conclusion and an outlook on further investigations .",
    "one property that have all neural networks in common , biological as well as artificial , is that there are two different processes taking place simultaneously .",
    "the first process concerns signal processing and the second learning .",
    "signal processing is reflected by the time dependent activity @xmath0 of a neuron @xmath1 , whereas learning concerns the dynamical behavior of the synaptic weights @xmath2 between two neurons @xmath1 and @xmath3 in the network .",
    "one major difference between both dynamics is that they occur on different timescales .",
    "normally , learning is much slower than the neural activity . despite our focus in this article on the learning dynamics",
    ", we can not neglect a treatment of the neural activity , because both processes are coupled and influence each other .",
    "figure [ fig1 ] shows a schematic neural network consisting of @xmath4 neurons .",
    "the synapses are not drawn directly from neuron to neuron but in two pieces .",
    "this shall depict the synaptic cleft of chemical synapses .",
    "the reason for this becomes more clear , when we describe our learning rule below .",
    "the left figure describes a signal path within a feed - forward network involving the neurons @xmath5 and the synapses between these neurons @xmath6 . in this and",
    "all following figures we suppose that the signal flow and , hence , the orientation of the path , is from the top to the bottom .",
    "the neurons ( synapses ) , which were actively involved in this signal processing , are drawn as black circles ( full lines ) . concerning this information flow , frey et al .",
    "@xcite found in the hippocampus of rats in vivo that there is a _ synaptic tagging _ mechanism .",
    "this mechanism tagges synapses which were repeatly involved in information processing within a certain time window of up to 1.5 hours . if one of these synapses is restimulated within this time interval then a synaptic modification is induced .",
    "one can interpret this as a kind of echo or memory within the neural network of past activity .",
    "hence , the left fig .",
    "[ fig1 ] can be interpreted in a way that the depicted path from neuron @xmath7 to @xmath8 is not the actual information flow , but the reflection of recent past activity , which the neurons and synapses can remember by an additional degree of freedom .",
    "suppose now , that this signal flow caused a synaptic modification on @xmath9 as depicted in the right fig .",
    "this situation corresponds to the so called hebbian learning @xcite .",
    "necessary conditions for this kind of learning are that the neurons , surrounding the synapse , were both active within a certain time window , which is in the @xmath10 range , and that the presynaptic neuron fires before the postsynaptic neuron @xcite . in biological terms hebbian learning",
    "is also called _ long - term potentiation _ ( ltp ) , because it strengthens the synaptic weight in contrast to _ long - term depression _ ( ltd ) , which weakens the synaptic weight , if the spiking time points of pre- and postsynaptic neuron are reversed . however , both kinds of learning , ltp as well as ltd , have one common ground , they are homosynaptic in respect to the number of synapses which are changed .",
    "recently , there is an increasing number of experimental results , which investigate a new form of synaptic modification , the so called heterosynaptic plasticity .",
    "in contrast to homosynaptic plasticity , where only the synapse between active pre- and postsynaptic neuron is changed , heterosynaptic plasticity concerns also further remote synapses of the pre- and postsynaptic neuron . this scenario is depicted in the left fig .",
    "we suppose again , that the synapse @xmath11 was changed either by ltp or ltd .",
    "fitzsimonds et al .",
    "@xcite found in cultured hippocampal neurons that the induction of ltd in @xmath11 is also accompanied by back propagation of depression in the dendrite tree of the presynaptic neuron . further more , depression also propagates laterally in the pre- and postsynaptic neuron .",
    "similar results hold for the propagation of ltp , see @xcite for a review .",
    "these experimental findings are depicted in the left fig .",
    "we emphasize all synapses , whose weights are changed @xmath12 , and all neurons , which enclose these synapses by drawing full lines respectively black circles . a direct comparison between the left fig . [ fig2 ] , which depicts heterosynaptic plasticity , with the right fig .",
    "[ fig1 ] , which depicts homosynaptic plasticity , reveals the tremendous difference in the affected number of synapses and the starlike spread of plasticity in some of the synapses connected with the two neurons , which were the case for the induction of plasticity in synapse @xmath9 .",
    "we want explicitly to emphasize , that fitzsimonds et al . found up to now no forward propagated postsynaptic plasticity .",
    "this would correspond to the synapses @xmath13 of neuron @xmath14 , which are drawn as dotted lines in the left fig.[fig2 ] .",
    "a biological explanation for the cellular mechanisms of these findings is currently under investigation .",
    "fitzsimonds et al .",
    "@xcite suggest the existence of retrograde signaling from the post- to the presynaptic neuron which could produce a secondary cytoplasmic factor for back - propagation and presynaptic lateral spread of ltd . on the postsynaptic side lateral spread of ltd could be explained similarly under the assumption that there is a blocking mechanism for the cytoplasmic factor which prevents forward propagated ltd .",
    "they are of the opinion that extracellular diffusible factors are of minor importance .     are drawn as black circles ( full lines ) .",
    "right : otmakova et al",
    ". found , that neurons in the ca1 region of the hippocampus receive a global reinforcement signal in form of dopamin.,width=192 ]     are drawn as black circles ( full lines ) .",
    "right : otmakova et al",
    ". found , that neurons in the ca1 region of the hippocampus receive a global reinforcement signal in form of dopamin.,width=188 ]    the experiments of fitzsimonds et al .",
    "@xcite are certainly an extention of homosynaptic learning , which we denote briefly as hebbian learning , but nevertheless both principles can be characterized as unsupervised learning because both learning types use exclusively local information available in the neural system .",
    "this is in contrast to the famous back - propagation learning rule @xcite for artificial neural networks .",
    "the back - propagation algorithm is famous because until the 1980 s there was no systematic method known to adjust the synaptic weights of an artificial multilayer ( feed - forward ) network to learn a mapping .",
    "still , the problem with the back - propagation algorithm is that it is not biological plausible because it requires a back - propagation of an error in the network .",
    "we emphasize , that the problem is not the back - propagation process itself , because , e.g. , heterosynaptic plasticity could provide such a mechanism as depicted in the left fig .",
    "[ fig2 ] , but the knowledge of the error , which can not be known explicitely to the neural network @xcite .",
    "for this reason learning by back - propagation is classified as supervised learning or learning by a teacher @xcite . however , there is a modified form of supervised learning namely reinforcement learning that is biologically plausible .",
    "reinforcement learning reduces the information provided by a teacher to a binary reinforcement signal @xmath15 that reflects the quality of the network s performance .",
    "interestingly , experimental observations from the hippocampus ca1 region have shown that there is a global signal in form of dopamine which is feedback to the neurons and causes thereby a modulation of ltd @xcite .",
    "schematically , this is depicted in the right fig .",
    "[ fig2 ] . in this figure",
    "each neuron is connected with an additional edge which represents the feedback of dopamin in form of a reinforcement signal @xmath15 .",
    "based on the experimental findings by frey et al .",
    "@xcite and otmakova et al .",
    "@xcite , bak and chialvo @xcite as well as klemm et al .",
    "@xcite suggested biologically inspired learning rules for neural networks that combine unsupervised hebbian ( homosynaptic ) with reinforcement learning .",
    "we call this kind of combination of hebbian and reinforcement learning hebb - like learning to indicate that the learning rule is different from hebb , but contains nevertheless characteristics which are biological plausible .",
    "this includes the extention from purely unsupervised to a combination of unsupervised and reinforcement learning .",
    "the question which arises now is : how can one construct a hebb - like learning rule which mimics additionally the learning behavior of heterosynaptic plasticity found by fitzsimonds et al .",
    ". this question will be addressed in the next section .",
    "the working mechanism of the learning rule we suggest is based on the explanation of fitzsimonds et al .",
    "@xcite for heterosynaptic plasticity given above . to understand what kind of mathematical formulation is capable to describe a secondary cytoplasmic factor in a qualitative way we start our explanation with emphasizing that a neuron is from a biological point of view first of all a cell .",
    "the subdivision of a neuron in synapses , soma ( cell body ) and axon is a model and reflects already the direction of the information flow within the neuron namely from the synapses ( input ) to the soma ( information processing ) to the axon ( output ) . here , we do not question this model view with respect to the direction of signal processing , but to learning .",
    "we see no biological reason why the model of a neuron for signal processing should be the same as the model of a neuron for learning . in fig .",
    "[ fig3 ] we emphasize the cell character of a neuron by underlying the contour of the whole neuron in gray .",
    "now , our reason for drawing the synapses in an unusual way becomes clear , because it emphasizes automatically the cell character of a neuron .",
    "suppose now , we assign to each neuron in the network one additional parameter @xmath16 as shown in fig .",
    "we call these parameters @xmath16 neuron counters .",
    "the neuron counters shall modulate the synaptic modification in a certain way defined in detail below .",
    "according to our cell view of the neuron , we assume further that the neuron counters of adjacent neurons , which are connected by synapses , can communicate with each other in an additive way . e.g. , in fig .",
    "[ fig3 ] the neuron counters @xmath17 and @xmath18 form a new value @xmath19 in synapse @xmath11 , which we call the approximated synapse counter . by this mechanism",
    "we obtain a star - like influence of , e.g. , the neuron counters @xmath17 and @xmath18 on all synapses connected with neuron @xmath20 or @xmath21 , because either @xmath22 or @xmath23 holds and regulates the synaptic update of the corresponding synaptic weight of the synapses @xmath24 and @xmath25 respectively .",
    "this situation corresponds in a qualitative way to the learning behavior of heterosynaptic plasticity , however , with the difference , that we have a fully symmetrical learning rule .",
    "an interpretation of the communication between adjacent neuron counters can be given , if one views the neuron counters as cytoplasmic factors , which are allowed to freely move within the cytoplasm of the corresponding neuron ( cell ) . because , we introduced no blocking mechanism for the forward propagation of the postsynaptic neuron counter we result in a fully symmetric communication between adjacent neuron counters .        in the next section ,",
    "we define the qualitative principle for heterosynaptic learning presented above mathematically .",
    "unfortunately , there are no experimental data available that would allow to specify the influence of @xmath26 on the corresponding synapse @xmath27 quantitatively . for this reason",
    ", we use an ansatz to close this gap and make it plausible @xcite",
    ".      if one assumes , that the neuron counters shall modulate learning , then it is plausible to determine the values of @xmath16 as a function of a reinforcement signal @xmath15 reflecting the performance of the network qualitatively . in the most simple case , the dynamics of the neuron counters depends linearly on the reinforcement signal .",
    "@xmath28 here , @xmath29 is a threshold that restricts the possible values of the neuron counters @xmath16 to @xmath30 possible values @xmath31 .",
    "the value of @xmath16 reflects the network s performance , but it has only relative and no absolute meaning with respect to the mean network error .",
    "this can be seen by the following example .",
    "suppose @xmath32 , then it is clear that at least the last output of the network was right , @xmath33 .",
    "however , we know nothing about the outputs which occurred before the last one .",
    "e.g. , the following two sequences of reinforcement signals can lead to the same value of the neuron counter @xmath32 : @xmath34 and @xmath35 if the start value is @xmath36 for @xmath37 and @xmath38 for @xmath39 .",
    "obviously , the estimated mean error is different in both cases , if averaged over the last seven time steps .",
    "the crucial point is , that the start value of the neuron counter is not available for the neuron and , hence , the neuron can not directly calculate the mean error of the network .",
    "however , we can introduce a simple assumption , which allows an estimate of the mean network error .",
    "we claim that , if @xmath40 for one neuron in a network , but trained by two different learning rules then the mean error of network one is lower then of network two .",
    "this may not hold for all cases , but it is certainly true in average . by this",
    "we couple the value of the neuron counter to the mean error of the network . due to the fact , that this holds only statistically , we will introduce a stochastic rather than a deterministic update rule for the synapses that depends on the neuron counters . in the previous section we said , that adjacent neuron counter can communicate , if both neurons are connected by a synapse .",
    "this gives a new variable @xmath41 we call the approximated synapse counter .",
    "we will use the approximated synapse counter as the driving parameter of our stochastic update rule , because its value reflects the performance of the synapse in the network which shall be updated , because the synapses are the adaptive part of a neural network .",
    "hence , evaluating the value of an approximated synapse counter of a synapse will give us indirectly a decision for the update of this synapse .",
    "it is clear that , roughly speaking , the higher the approximated synapse counter of a synapse is the higher should be the probability the synapse is updated .",
    "this intuitively plausible assumption will now be quantified .",
    "similar to @xcite only active synapses @xmath27 which were involved in the last signal processing step can be updated , if the output of the network was wrong .",
    "this is plausible , because it prevents that already learned mappings in the neural network are destroyed possibly .",
    "if @xmath42 the probability , that synapse @xmath27 is updated is given by @xmath43 this probability has to be calculated for each synapse @xmath27 in the network .",
    "we want to emphasize , that this needs only local information besides the reinforcement signal .",
    "hence , it is a biologically possible mechanism .",
    "if the synapse is actually chosen for update , the synaptic weight will be modified by @xmath44 here , @xmath45 is a positive constant which determines the amount of the synaptic depression . to evaluate the stochastic update condition eq .",
    "[ supdate ] the two auxiliary variables @xmath46 and @xmath47 have to be identified .",
    "this is done in the following way :    1 .",
    "calculate the approximated synapse counter @xmath48 2 .",
    "map the value of the approximated synapse counter @xmath26 to @xmath49 by @xmath50 we call @xmath51 rank ordering probability distribution 3 .",
    "the random variable @xmath46 is drawn from the continuous coin distribution @xmath52 .",
    "\\label{p_coin}\\\\\\ ] ]    we had three reasons to choose a power law in eq .",
    "[ p_coin ] for the coin distribution instead of an equal distribution , which would be the simplest choice .",
    "first , we see no evidence that a random number generator occurring in a neural system should favor a equal distribution .",
    "second , it is highly probable that two different random number generators of the same biological system are not identical .",
    "instead , they could have different parameters , in our case they could have different exponents . in this paper",
    "we will content ourself investigating the case of identical random number generators , but our framework can be directly applied to the described scenario .",
    "third , by choosing @xmath53 , the coin distribution in eq . [ p_coin ] becomes the equal distribution .",
    "this allows us to investigate the influence of the distance of the coin distribution to an equal distribution on the learning behavior of a neural network by studying different parameters of @xmath54 .",
    "we want to remark , that in this case the update probability eq .",
    "[ supdate ] simplifies to @xmath55        before we present our results in the next section , we want to visualize the stochastic update probability @xmath56 .",
    "figure [ fig3_new ] shows the update probability @xmath56 as function of @xmath47 .",
    "the different curves correspond to different values of the exponent @xmath54 of the coin distribution .",
    "one can see , that the update probability follows the values of @xmath47 .",
    "this holds for each curve in fig .",
    "[ fig3_new ] .",
    "that means , the higher the values of @xmath47 are the higher is the update probability .",
    "this is the behavior one would intuitively expect , because high values of @xmath47 correspond to high values of the approximated synapse counters @xmath26 indicating high values of the neuron counters , which correspond to a bad network performance .",
    "moreover , one can see in fig .",
    "[ fig3_new ] that the larger @xmath54 the higher is the update probability for fixed @xmath47 . in the limit",
    "@xmath57 the update probability equals one for all values of @xmath47 .",
    "hence , higher values of the exponent @xmath54 of the coin distribution result in a higher update probability .",
    "that means , by @xmath54 one can control the sensitivity by which the update probability depends on @xmath47 .",
    "another parameter our stochastic update rule depends on is the exponent of the rank ordering distribution @xmath58 .",
    "we display in fig .",
    "[ fig_update2 ] @xmath56 as function of @xmath58 and @xmath47 to visualize its influence on the update probability .",
    "the values of the update probability are color - coded and blue corresponds to @xmath59 and red to @xmath60 . for the left fig .",
    "[ fig_update2 ] we used @xmath61 and for the right @xmath62 as exponent for the coin distribution .",
    "if @xmath63 no update takes place . for increasing values of the approximated synapse counter and fixed values of @xmath58 one obtains increasing values for the update probability .",
    "moreover , higher values of @xmath54 lead to higher values of @xmath56 . this can be seen by comparing the left and right fig .",
    "[ fig_update2 ] . increasing values of @xmath58 result in decreasing values of @xmath56 for fixed @xmath26 .            to summarize , the stochastic update condition we introduced for a synaptic update depends on six parameters @xmath64 from the visualizations we gave in fig .",
    "[ fig3_new ] and [ fig_update2 ] we saw that increasing values of @xmath26 and @xmath54 as well as decreasing values of @xmath58 lead to an increase in the update probability .",
    "for the following simulations we use a three - layer feed - forward network . the neural network consist of @xmath65 input- , @xmath66 hidden- and @xmath67 output neurons .",
    "the neurons of adjacent layers are all to all connected with synapses @xmath68 . as neuron model we us binary neurons @xmath69 for @xmath70 .",
    "the network dynamics is regulated by a winner - take - all mechanism whereas the inner fields of the neurons are calculated by @xmath71 here , _ all _ means all neurons of the preceding layer . as active neuron in each layer",
    "we choose the neuron with the highest activity @xmath72 which is set to @xmath73 .",
    "all other neurons are set to zero . by this",
    "we enforce a sparse coding .",
    "bak and chialvo @xcite have called this _",
    "extremal dynamics_.    the training of the neural network works as follows : we choose randomly one of the possible input patterns and initialize the neurons in the input layer .",
    "then we calculate according to the network dynamics eq .",
    "[ innerfield]-[argmax ] the activity of the neurons in the subsequent layers .",
    "if the output of the network is correct we set @xmath33 otherwise the reinforcement signal is set to @xmath42 . according to eq .",
    "[ synmem2 ] we calculate the new values of the neuron counters for the neurons which were active during the signal processing of the input pattern .",
    "if @xmath42 we apply our stochastic learning rule otherwise we proceed with the next input pattern until the network converged .",
    "the mapping which shall be learned by the network is the exclusive - or ( xor ) function and higher dimensional extensions thereof called the parity problem .",
    "one can describe the mappings from the parity problem class as indicator functions for an odd or even number of @xmath60 s in the binary input vector @xmath74 of the network .",
    "if the number of @xmath60 s in the input vector is odd the output of the network shall be @xmath75 if it is even @xmath76 . in this sense ,",
    "the exclusive - or ( xor ) function is the two dimensional @xmath77 representative of this class . to avoid the case of a zero input vector , which would result in zero activity of subsequent layers ,",
    "we introduce a bias neuron @xmath78 . here , the index @xmath79 is given by the exponent of the maximal number of patterns @xmath80 which can be realized by a random binary vector of length @xmath79 . for the following simulations",
    "the initial weights of the network were chosen randomly from @xmath81 $ ] and the neuron counters were all set to zero . the learning rate @xmath45 was randomly chosen from @xmath82 $ ] , with @xmath83 , each time when a synaptic modification was induced .",
    "we start our investigations by studying the influence of the memory length of the neuron counters @xmath84 and the exponents @xmath54 and @xmath58 on the mean ensemble error @xmath85 of the network s performance during learning the xor function . the contour plot in fig .",
    "[ fig_res1 ] shows the simulation results for @xmath86 and three neurons in the hidden layer .",
    "the mean ensemble error @xmath85 was obtained by averaging over independent runs of an ensemble of size @xmath87 and is displayed at the time steps @xmath88 ( left figure ) and @xmath89 ( right figure ) during the learning process . to find the optimal parameter configuration @xmath90 which minimizes the mean ensemble error @xmath91 we keep @xmath84 fixed and vary @xmath54 and @xmath58 in the interval @xmath92 $ ] in @xmath93 steps .    [ cols=\"^ \" , ]             from fig .",
    "[ fig_res1 ] one can see that learning takes place in the whole parameter space @xmath94 .",
    "of course there are regions in which learning is much faster than in others due to the fact that the resulting update probability of our learning rule , controlled by @xmath94 , is more suitable for the learning task . to investigate the @xmath84 dependence of our learning rule we repeated these simulations for several @xmath84 values .",
    "the results for the optimal parameter configurations @xmath95 from these simulations can be found in table [ tab1 ] . from these results",
    "one can conclude that there is no single parameter configuration in this @xmath96 dimensional parameter space , which minimizes @xmath85 .",
    "but there exist multiple parameter configurations resulting in almost the same performance with respect to the absolute convergence of the network .",
    "interestingly , from table [ tab1 ] one can see , that with increasing values of @xmath84 , @xmath54 also increases but @xmath58 is almost constant . based on our explanation in section [ math_def ] about the dependence of @xmath56 on @xmath54 and @xmath58 we can conclude , that higher values of @xmath84 require a higher update probability .",
    "this makes sense , because the complexity of the mapping to be learned by the network was not changed .",
    "only the memory length of the neuron counters was enlarged .",
    "apparently , this was not necessary and , hence , would result in worse results , because averaging over a longer time interval @xmath84 is more time consuming . this effect is compensated by the higher @xmath54 value resulting in more frequent updates . for our subsequent investigations",
    "we use the optimal parameter values obtained at the learning time step @xmath89 from table [ tab1 ] .    based on these results",
    "we study systematically the dependence of the mean learning time from the network topology and the network dynamics . in the left fig .",
    "[ fig_res2 ] we show the mean learning time as function of the number of neurons @xmath66 in the hidden layer .",
    "the curves are indexed by different values of the neuron counter @xmath84 .",
    "in the lower figure we demonstrate the robustness of these results in the presence of noise @xmath97 by using a noisy winner - take - all mechanism as network dynamics which adds to the inner fields eq .",
    "[ innerfield ] of the neurons noise @xmath97 before the neuron with the highest inner field is selected .",
    "the noise was uniformly drawn from @xmath98 $ ] with @xmath99 . from both figures",
    "one can see that the mean learning time decreases with an increasing number of neurons in the hidden layer as expected whereas the increase from @xmath96 to @xmath100 neurons has the biggest effect .",
    "this is due to the fact that the destructive path inference , which means that already correctly learned paths in the network are destroyed by a new synaptic modification , is strongly reduced by increasing the number of possible paths as a result of additional neurons in the hidden layer . increasing",
    "the number of neurons beyond @xmath101 has only marginal influence because an additional increase of redundant paths has no affect . even in the presence of noise",
    "our learning rule is capable of learning the xor function .",
    "one can nicely see how an increasing number of neurons in the hidden layer can efficiently reduce the amount of noise in the system .",
    "in this subsection we study the influence of the number of patterns to be learned on the mean learning time .",
    "we use @xmath80 input patterns , for @xmath102 , and correspondingly @xmath103 neurons in the input layer and @xmath104 neurons in the hidden layer .",
    "neurons in the hidden layer . the mean learning time was averaged over an ensemble of size @xmath105 .",
    "the symbols correspond to results obtained from simulations whereas the lines are the results from a least mean square fit .",
    "the exponents for the power laws are @xmath106 in acceding order of @xmath84.,width=321 ]    the network dynamics was again regulated by a winner - take - all mechanism .",
    "our results shown in fig .",
    "[ fig_res3 ] for the mean learning times are comparable to the results obtained by bak and chialvo @xcite with the difference that they even used @xmath107 neurons in the hidden layer .",
    "moreover , the mean learning time scales for numerical values for @xmath108 for the three different curves . ] with problem size @xmath109 according to a power law @xmath110 with exponent @xmath111 .",
    "this demonstrates not only , that our stochastic learning rule is able to learn the problem but also , that learning is efficient , because otherwise the mean learning times would follow an exponential function .      finally , we investigated the influence of the type of the probability distribution used for the coin and rank ordering distribution . here",
    ", we use an exponential distribution for the coin and rank ordering distribution and study the learning behavior .",
    "we found significantly worse results compared to the results for the power law ( not shown ) presented in the last section . to understand this",
    ", we display in fig .",
    "[ fig_exp ] the update probability as function of @xmath58 and @xmath26 .",
    "one can see , there are essentially only two states , the update probability can take , zero and one ( upper right ) .",
    "that means , @xmath56 produces a rather deterministic update behavior which is inappropriate , because the information provided by the approximated synapse counters is uncertain .",
    "other values for @xmath54 show qualitatively the same results .",
    "this demonstrates that the larger variability provided by a power law distribution is important for a good learning behavior .",
    "mathematical investigations of biological as well as artificial learning rules for neural networks have been attractive to scientists since decades , because of the importance of the underlying problem and implications arising out of an understanding thereof .",
    "we want to finish this article , by discussing and comparing our novel stochastic hebb - like learning rule with other models introduced so far , which are constrained in a way that makes them biologically plausible .",
    "bak and chialvo @xcite introduced a learning rule which combines anti - hebb or long - term depression ( ltd ) and reinforcement learning .",
    "klemm et al .",
    "@xcite extended the learning rule from bak and chialvo by introducing one additional degree of freedom for each synapse in the network .",
    "they called this degree of freedom synapse counter .",
    "moreover , bosman et al .",
    "proposed a learning rule which incorporates hebb ( ltp ) , anti - hebb ( ltd ) and reinforcement learning @xcite .",
    "all these approaches have in common with our learning rule , that they utilize a reinforcement signal as feedback reflecting the current performance of the network .",
    "the usage of a reinforcement signal seems not only to be plausible but indispensable to learn mappings , because the neural network has to adapt to its environment by interacting with it otherwise the animal will die fast .",
    "similar to physical energy , it is also impossible to generate information out of nothing in a meaningful way .",
    "the reinforcement signal makes a neural network and , hence , a brain , an open system according to the flow of information .",
    "this depicts intuitively the difficulty of the system under investigation , because open or dissipative systems are by far less understood than closed , e.g. , hamiltonian systems .",
    "in contrast , all models @xcite proposed before are purely deterministic with respect to the decision if an update for a synapse shall take place or not . additionally , all learning rules @xcite can only explain homosynaptic plasticity .",
    "we think , due to the fact that the neural network is an open system it can not make deterministic decisions which are objective , because of the lack of complete information .",
    "of course , one can always search for the best decision based on the amount of information available in the system .",
    "however , this internal ( in the neural network ) optimality does not guarantee external ( the overall network performance ) optimality . in this article , we took the point of view , that we assume we have incomplete information and , hence , we are only able to provide an update probability indicating a kind of confidence level for this update based on our incomplete information .",
    "explicitely , this enters our model in form of the approximated synapse counters . for every network topology",
    "one can calculate the synapse counter as a function of the neuron counters introduced by klemm et al .",
    "however , this results normally in relations , which involve not only the neuron counters enclosing the synapse , but also further remote neuron counters @xcite .",
    "this can be seen with the help of fig .",
    "for example , the neuron counter of neuron five can be written as a linear sum of the synapse counters : @xmath112 these equations represent a failure conservation for the incoming and outgoing connections respectively .",
    "if the neuron counter of neuron five is @xmath113 then the sum of all synapse counters leading to neuron five has to be equal to this number , because there is no other way information can involve neuron five in the signal processing .",
    "the same holds for the outgoing information , represented by eq .",
    "[ coding ] . in general ,",
    "such linear failure conservation relations between the neuron and synapse counters lead to the linear system @xmath114 here , @xmath115 represents the @xmath116-dimensional vector of neuron and @xmath117 the @xmath118-dimensional vector of synapse counters .",
    "the integer valued @xmath116 times @xmath118 matrix @xmath119 depends on the network topology .",
    "the problem becomes nonlinear if one wants to obtain the synapse counters as function of the neuron counters , because the inverse of the non - quadratic matrix @xmath119 in eq .",
    "[ coding2 ] can only be done by calculating a pseudoinverse to obtain @xmath120 .",
    "this is the situation we are facing .",
    "explicite calculation by using the moore - penrose pseudo inverse @xcite leads to the statement given above @xcite .",
    "hence , a biologically plausible learning rule can not use these relations , because this would violate the local information condition in neural networks .",
    "one possibility around this obstacle is to approximate the synapse counter by the sum of the neuron counters enclosing this synapse , however , with the additional assumption to view the resulting value in a probabilistic rather than deterministic way .",
    "our simulations showed , that a merely addition ( or multiplication ) of the neuron counters does not lead to meaningful results at all @xcite .",
    "moreover , also the used probability distributions have significant influence on the learning dynamics as demonstrated in the results section [ results ] .",
    "the fact , that power law distributions give significantly better results than exponential distributions for the coin and rank ordering distribution corresponds to results of recent investigations of heuristic optimization strategies .",
    "boettcher et al .",
    "@xcite demonstrated that the usage of power law distributions in optimization problems , e.g. , finding the energy ground states for spin glasses @xcite and graph bi - partitioning @xcite , which are both np - hard optimization problems , can give better results compared to simulated annealing @xcite or genetic algorithms @xcite .",
    "they explained this effect by the positive influence of the inherently large fluctuations within the system , which prevents to get trapped a long time in local minima of the error function .    from a biological point of view",
    "the most significant difference between our stochastic hebb - like learning rule and the other learning rules @xcite is certainly that our model aims to explain heterosynaptic plasticity , which has been found experimentally @xcite , instead of homesynaptic plasticity , in a qualitative way .",
    "this is also the major objective of this paper .",
    "hence , a direct comparison between our model and the other learning rules can not be given fairly without neglecting or underestimating significant components of our model .",
    "for example , we introduced one new degree of freedom for each neuron in the form of neuron counters .",
    "bosman et al .",
    "@xcite do not rely on this or similar parameters whereas klemm et al .",
    "@xcite introduced one additional degree of freedom for each synapse .",
    "that means , in this context our model has @xmath116 parameters , the model of bosman et al .",
    "none , and klemm et al .",
    "@xmath121 parameters . here",
    ", let @xmath79 be the average number of synapses a neuron has in a network .",
    "this makes the learning rule of bosman et al . in a mathematical sense",
    "minimal compared to ours .",
    "however , biologically it can not describe heterosynaptic plasticity and , hence , lacks this ability , which makes a comparison in the number of parameters meaningless .",
    "interestingly , despite the fact , that heterosynaptic plasticity is more complex then homosynaptic plasticity the learning rule of klemm et al . uses @xmath79 times more parameters than our model .",
    "in general , we think that due to the almost overwhelming complexity of biological phenomena mathematical modeling should stay always in tight contact with experimental findings to constrain the model by regularities found in nature .",
    "these constrains can only lead to minimal mathematical models in the context under consideration , but not beyond .",
    "we presented a novel stochastic hebb - like learning rule for neural networks and demonstrated its working mechanism exemplary in learning the exclusive - or ( xor ) problem in a three - layer network .",
    "we investigated the convergence behavior by extensive numerical simulations depending on three different network dynamics which correspond all to biological forms of lateral inhibition .",
    "we found in all cases parameter configurations for @xmath84 , the length of the neuron memory , @xmath54 , the exponent of the coin distribution and @xmath58 , the exponent of the rank ordering distribution , which constitute the hebb - like learning rule , to obtain not only a solution to the exclusive - or ( xor ) problem but comparably well results to a learning rule recently proposed by klemm , bornholdt and schuster @xcite .",
    "this is remarkable , if one keeps in mind that our learning rule uses less parameters than the model proposed by @xcite . because the number of neurons is always ( much ) less then the number of synapses the same holds for the respective numbers of synaptic and neuron counters which were used in the learning rules .",
    "an interesting implication of our learning rule and its inherent stochastic character is that it offers a quantitative biologically plausible explanation of heterosynaptic plasticity which is observed experimentally .",
    "in addition to the experimentally observed back - propagation , pre- and postsynaptic lateral spread of _ long - term depression _ ( ltd ) our learning rule predicts forward propagated postsynaptic ltd for reasons of a symmetric communication between adjacent neurons .",
    "as far as we know there is no theoretical explanation of that phenomenon so far and we are looking forward to new experiments helping to clarify this important question .",
    "we would like to thank tom bielefeld , rolf d. henkel , jens otterpohl , klaus pawelzik , roland rothenstein , peter ryder , heinz georg schuster and helmut schwegler for fruitful discussions ."
  ],
  "abstract_text": [
    "<S> in this article we intoduce a novel stochastic hebb - like learning rule for neural networks that is neurobiologically motivated . </S>",
    "<S> this learning rule combines features of unsupervised ( hebbian ) and supervised ( reinforcement ) learning and is stochastic with respect to the selection of the time points when a synapse is modified . </S>",
    "<S> moreover , the learning rule does not only affect the synapse between pre- and postsynaptic neuron , which is called homosynaptic plasticity , but effects also further remote synapses of the pre- and postsynaptic neuron . </S>",
    "<S> this more complex form of synaptic plasticity has recently come under investigations in neurobiology and is called heterosynaptic plasticity . </S>",
    "<S> we demonstrate that this learning rule is useful in training neural networks by learning parity functions including the exclusive - or ( xor ) mapping in a multilayer feed - forward network . </S>",
    "<S> we find , that our stochastic learning rule works well , even in the presence of noise . </S>",
    "<S> importantly , the mean learning time increases with the number of patterns to be learned polynomially , indicating efficient learning . </S>"
  ]
}