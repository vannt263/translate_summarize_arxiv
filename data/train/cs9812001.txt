{
  "article_text": [
    "i would like to express my sincere appreciation to my supervisor , prof .",
    "junichi tsujii of the university of tokyo , for his continuous encouragement and guidance .",
    "it was prof .",
    "tsujii who guided me in the fundamentals of natural language processing when i was an undergraduate student at kyoto university .",
    "his many helpful suggestions and comments have also been crucial to the completion of this thesis .",
    "i would also like to express my gratitude to the members of my dissertation committee : prof .",
    "toshihisa takagi and prof .",
    "hiroshi imai of the university of tokyo , prof .",
    "yuji matsumoto of nara institute of science and technology ( naist ) , and prof .",
    "kenji kita of tokushima university , who have been good enough to give this work a very serious review .",
    "very special thanks are also due to prof .",
    "makoto nagao of kyoto university for his encouragement and guidance , particularly in his supervision of my master thesis when i was a graduate student at kyoto university i learned a lot from him , especially in the skills of conducting research .",
    "he is one of the persons who continue to influence me strongly in my research carrer , even though the approach i am taking right now is quite different from his own .",
    "i also would like to express my sincere gratitude to prof .",
    "yuji matsumoto .",
    "he has given me much helpful advice with regard to the conduct of research , both when i was at kyoto university and after i left there .",
    "the use of dependency graphs for representation of case frame patterns was inspired by one of his statements in a personal conversation .",
    "i would like to thank prof .",
    "junichi nakamura of kyoto university , prof .",
    "satoshi sato of the japan advance institute of science and technology , and other members of the nagao lab .",
    "for their advice and contributions to our discussions .",
    "the research reported in this dissertation was conducted at c&c media research laboratories , nec corporation and the theory nec laboratory , real world computing partnership ( rwcp ) .",
    "i would like to express my sincere appreciation to mr .",
    "katsuhiro nakamura , mr .",
    "tomoyuki fujita , and dr .",
    "shun doi of nec . without their continuous encouragement and support ,",
    "i would not have been able to complete this work .",
    "sincere appreciation also goes to naoki abe of nec .",
    "most of the research reported in this thesis was conducted jointly with him . without his advice and proposals ,",
    "i would not have been able to achieve the results represented here .",
    "ideas for the tree cut model and the hard co - occurrence model came out in discussions with him , and the algorithm ` find - mdl ' was devised on the basis of one of his ideas .",
    "i am deeply appreciative of the encouragement and advice given me by kenji yamanishi of nec , who introduced me to the mdl principle ; this was to become the most important stimulus to the idea of conducting this research .",
    "he also introduced me to many useful machine learning techniques , that have broadened my outlook toward the field .",
    "i also thank jun - ichi takeuchi , atsuyoshi nakamura , and hiroshi mamitsuka of nec for their helpful advice and suggestions .",
    "jun - ichi s introduction to me of the work of joe suzuki eventually leads to the development in this study of the case - dependency learning method .",
    "special thanks are also due to yuuko yamaguchi and takeshi futagami of nis who implemented the programs of find - mdl , 2d - clustering .    in expressing my appreciation to yasuharu den of naist , david carter of speech machines , and takayoshi ochiai of nis , i would like them to know how much i had enjoyed the enlightening conversations i had with them .",
    "i am also grateful to prof .",
    "mark petersen of meiji university for what he has taught me about the technical writing of english .",
    "petersen also helped correct the english of the text in this thesis , and without his help , it would be neither so readable nor so precise .",
    "yasuharu den , kenji yamanishi , david carter , and diana mccarthy of sussex university read some or all of this thesis and made many helpful comments .",
    "thanks also go to all of them , though the responsibility for flaws and errors it contains remains entirely with me .",
    "i owe a great many thanks to many people who were kind enough to help me over the course of this work .",
    "i would like to express here my great appreciation to all of them .",
    "finally , i also would like to express a deep debt of gratitude to my parents , who instilled in me a love for learning and thinking , and to my wife hsiao - ya , for her constant encouragement and support .",
    "[ cols= \" < , > \" , ]      lexical semantic knowledge acquisition and structural disambiguation are difficult tasks .",
    "although i think that the investigations reported in this thesis represent some significant progress , further research on this problem is clearly still needed .",
    "other issues not investigated in this thesis and some possible solutions include :    more complicated models : :    in the discussions so far , i have restricted the class of hard case    slot models to that of tree cut models for an existing thesaurus    _ tree_. under this restriction , we can employ an efficient    dynamic - programming - based learning algorithm which can provablely find    the optimal mdl model . in practice , however , the structure of a    thesaurus may be a directed acyclic graph ( dag ) and straightforwardly    extending the algorithm to a dag may no longer guarantee that the    optimal model will be found .",
    "the question now is whether there exist    sub - optimal algorithms for more complicated model classes .",
    "the same    problem arises in case dependency learning , for which i have    restricted the class of case frame models to that of dependency forest    models",
    ". it would be more appropriate , however , to restrict the class    to , for example , the class of normal bayesian networks . how to learn    such a complicated model , then , needs further investigation . unified model",
    ": :    i have divided the problem of learning lexical knowledge into three    subproblems for easy examination .",
    "it would be more appropriate to    define a single unified model . how to define such a model , as well as    how to learn it , are issues for future research .",
    "( see @xcite    for some recent progress on this issue ; see also discussions in    chapter 3 . )",
    "combination with extraction : :    we have seen that the amount of data currently available is generally    far less than that necessary for accurate learning , and the problem of    how to collect sufficient data may be expected to continue to be a    crucial issue .",
    "one solution might be to employ bootstrapping , i.e. , to    conduct extraction and generalization , iteratively . how to combine the    two processes needs further examination .",
    "combination with word sense disambiguation : :    i have not addressed the word sense ambiguity problem in this thesis ,    simply proposing to conduct word sense disambiguation in    pre - processing .",
    "( see @xcite for her proposal on word sense    disambiguation . ) in order to improve the disambiguation results ,    however , it would be better to employ the soft case slot model to    perform structural and word sense disambiguation at the same time . how    to effectively learn such a model requires further work .",
    "soft clustering : :    i have formalized the problem of constructing a thesaurus into that of    learning a double mixture model . how to efficiently learn such a model    is still an open problem .",
    "parsing model : :    the use of lexical knowledge alone in disambiguation might result in    the resolving of most of the ambiguities in sentence parsing , but not    all of them . as has been described , one solution to the problem might    be to define a unified model combining both lexical knowledge and    syntactic knowledge .",
    "the problem still requires further work .",
    "abe , naoki and hang li .",
    "1996 . learning word association norms using tree cut pair models .",
    ", pages 311 .",
    "abe , naoki , hang li , and atsuyoshi nakamura . 1995 .",
    "on - line learning of binary lexical relations using two - dimensional weighted majority algorithms .",
    ", pages 311 .",
    "almuallim , hussein , yasuhiro akiba , takefumi yamazaki , akio yokoo , and shigeo kaneda .",
    "two methods for alt - j / e translation rules from examples and a semantic hierarchy . , pages 5763 .",
    "alshawi , hiyan and david carter .",
    "training and scaling preference functions for disambiguation .",
    ", 20(4):635648 .",
    "altmann , gerry and mark steedman .",
    "1988 . interaction with context during human sentence processing .",
    ", 30:191238 .",
    "bahl , lalit  r. , frederick jelinek , and robert mercer .",
    "1983 . a maximum likelihood approach to continuous speech recognition .",
    ", 5(2):179190 .",
    "barron , andrew  r. and thomas  m. cover .",
    "1991 . minimum complexity density estimation . , 37(4):10341054 .",
    "berger , adam  l. , stephen j.  della pietra , and vincent j.  della pietra .",
    "a maximum entropy approach to natural language processing .",
    ", 22(1):3971 .",
    "black , ezra .",
    "an experiment in computational discrimination of english word senses .",
    ", 32(2):185193 .",
    "black , ezra , fred jelinek , john lafferty , and david  m. magerman .",
    "1993 . towards history - based grammars : using richer models for probabilistic parsing .",
    ", pages 3137 .",
    "brent , michael  r. 1991 .",
    "automatic acquisition of subcategorization frames from untagged text .",
    ", pages 209214 .",
    "brent , michael  r. 1993 . from grammar",
    "to lexicon : unsupervised learning of lexical syntax .",
    ", 19(2):243262 .",
    "brent , michael  r. and timothy  a. cartwright .",
    "distributional regularity and phonotactic constraints are useful for segmentation .",
    ", 61:93125 .",
    "brent , michael  r. , sreerama  k. murthy , and andrew lundberg .",
    "1995 . discovering morphemic suffixes : a case study in minimum description length induction . .",
    "brill , eric .",
    "transformation - based error - driven learning and natural language processing : a case study in part - of - speech tagging .",
    ", 21(4):543565 .",
    "brill , eric and philip resnik .",
    "a rule - based approach to prepositional phrase attachment disambiguation .",
    ", pages 11981204 .",
    "briscoe , ted and john carroll .",
    "generalized probabilistic lr parsing of natural language ( corpora ) with unification - based grammars .",
    ", 19(1):2559 .",
    "briscoe , ted and john carroll .",
    "automatic extraction of subcategorization from corpora . .",
    "brown , peter , stephen  della pietra , vincent  della pietra , and robert mercer .",
    "word sense disambiguation using statistical methods .",
    ", pages 264270 .",
    "brown , peter  f. , vincent j.  della pietra , peter  v. desouza , jenifer  c. lai , and robert  l. mercer",
    "class - based n - gram models of natural language . , 18(4):283298 .",
    "bruce , rebecca and janyce wiebe . 1994 .",
    "word - sense disambiguation using decomposable models . , pages 139145 .",
    "carter , david . 1997 .",
    "the treebanker : a tool for supervised training of parsed corpora . .",
    "cartwright , timothy  a. and michael  r. brent .",
    "segmenting speech without a lexicon : the roles of phonotactics and speech source . , pages 8390 .",
    "chang , jing - shin , yih - fen luo , and keh - yih su .",
    "1992 . : a generalized probabilistic semantic model for ambiguity resolution .",
    ", pages 177184 .",
    "charniak , eugene .",
    "statistical parsing with a context - free grammar and word statistics . .",
    "charniak , eugene , curtis hendrickson , neil jacobson , and mike perkowitz .",
    "equations for part - of - speech tagging .",
    ", pages 784789 .",
    "chen , kuang - hua and hisn - hsi chen .",
    "1994 . extracting noun phrases from large - scale texts : a hybrid approach and its automatic evaluation . ,",
    "pages 234241 .",
    "chiang , tung - hui , yi - chung lin , and keh - yih su .",
    "robust learing , smoothing , and parameter tying on syntactic ambiguity resolution . , 21(3):321349 .",
    "chitrao , mahesh  v. and ralph grishman . 1990 .",
    "statistical parsing of messages .",
    ", pages 263266 .",
    "chow , c.k . and c.n .",
    "liu . 1968 .",
    "approximating discrete probability distributions with dependence trees .",
    ", 14(3):462467 .",
    "church , kenneth , william gale , patrick hanks , and donald hindle .",
    "parsing , word associations and typical predicate - argument relations .",
    ", pages 389398 .",
    "church , kenneth , william gale , patrick hanks , and donald hindle .",
    "using statistics in lexical analysis . in uri",
    "zernik , editor , _ lexical acquisition : exploiting on - line resources to build a lexicon_. lawrence erlbaum associates , hillsdale , pages 115164 .",
    "church , kenneth and patrick hanks . 1989 .",
    "word association norms , mutual information , and lexicography . , pages 7683 .",
    "church , kenneth .",
    "w. 1988 . a stochastic parts program and noun phrase parser for unrestricted text . , pages 136143 .",
    "clarke , bertrand  s. and andrew  r. barron .",
    "information - theoretic asymptotics of bayes methods . , 36(3):453471 .",
    "collins , michael . 1996 . a new statistical parser based on bigram lexical dependencies . , pages 184191 .",
    "collins , michael .",
    "three generative lexicalized models for statistical parsing . , pages 1623 .",
    "collins , michael and james brooks . 1995 .",
    "prepositional phrase attachment through a backed - off model . .",
    "cooper , gregory  f. and edward herskovits .",
    "a bayesian method for the induction of probabilistic networks from data .",
    ", 9:309347 .",
    "cover , thomas  m. and joy  a. thomas . 1991 . .",
    "john wiley & sons inc .",
    ", new york .",
    "cucchiarelli , alessandro and paola velardi .",
    "automatic selection of class labels from a thesaurus for an effective semantic tagging of corpora .",
    ", pages 380387 .",
    "dagan , ido , shaul marcus , and shaul makovitch . 1992 .",
    "contextual word similarity and estimation from sparse data .",
    ", pages 164171 .",
    "dagan , ido , fernando pereira , and lillian lee . 1994 .",
    "similarity - based estimation of word cooccurrence probabilities . , pages 272278 .",
    "dagan , ido , fernando pereira , and lillian lee .",
    "similarity - based methods for word sense disambiguation . , pages 5663 .",
    "darroch , j.  n. and d.  ratcliff .",
    "generalized iterative scaling for log - linear models .",
    ", 43(5):17401480 .",
    "dempster , a.p .",
    "laird , and d.b .",
    "maximum likelihood from incomplete data via the em algorithm .",
    ", 39(1):138 .",
    "den , yasuharu .",
    "thesis , kyoto univ .",
    "ellison , t.  mark .",
    "discovering planar segregations .",
    ", pages 4247 .",
    "ellison , t.  mark .",
    "1992 . discovering vowel harmony . in walter daelmans and david powers , editors , _ background and experiments in machine learning of natural language_. pages 205207 .",
    "fillmore , c. 1968 .",
    "the case for case . in e.",
    "bach and r.  harms , editors , _ universals in linguistics theory_. holt , rinehart , and winston , new york .",
    "fisher , r.a .",
    "olyver and boyd .",
    "ford , marylyn , joan bresnan , and ronald kaplan .",
    "1982 . a competence based theory of syntactic closure .",
    "framis , francesc  ribas .",
    "an experiment on learning appropriate selectional restrictions from a parsed corpus . , pages 769774 .",
    "frazier , lyn and janet fodor .",
    "the sausage machine : a new two - stage parsing model . , 6:291325 .",
    "fujii , atsushi , kentaro inui , takenobu tokunaga , and hozumi tanaka .",
    "to what extent does case contribute to verb sense disambiguation .",
    ", pages 5964 .",
    "fujisaki , t. , f.  jelinek , j.  cocke , e.  black , and t.  nishino .",
    "a probabilistic parsing method for sentence disambiguation . ,",
    "pages 8594 .",
    "gale , william , kenneth  ward church , and david yarowsky . 1992 .",
    "estimating upper and lower bounds on the performance of word - sense disambiguation programs . ,",
    "pages 249256 .",
    "gale , williams  a. and kenneth  w. church .",
    "poor estimates of context are worse than none .",
    ", pages 283287 .",
    "gelfand , alan  e. and adrian  f.m .",
    "sampling - based approach to calculating marginal densities .",
    ", 85(40):398409 .",
    "geman , stuart and donald geman .",
    "stochastic relaxation , gibbs distributions and the bayes restoration of images .",
    ", pami-6(6):721741 .",
    "golding , andrew  r. and dan roth .",
    "1996 . applying winnow to context - sensitive spelling correction . ,",
    "pages 182190 .",
    "golding , andrew  r. and yves schabes . 1996 . combining trigram - based and feature - based methods for context - sensitive spelling correction .",
    ", pages 7178 .",
    "grefenstette , gregory .",
    "kluwer academic publishers , boston .",
    "grishman , ralph and john sterling .",
    "acquisition of selectional patterns . ,",
    "pages 658664 .",
    "grishman , ralph and john sterling .",
    "generalizing automatically generated selectional patterns .",
    ", pages 742747 .",
    "grunwald , peter .",
    "a minimum description length approach to grammar inference .",
    "in s.  wemter , e.  riloff , and g.  scheler , editors , _ symbolic , connectionist and statistical approaches to learning for natural language processing , lecture note in ai_. springer verlag , pages 203216 .",
    "guthrie , joe  a. , louise guthrie , yorick wilks , and homa aidinejad .",
    "subject - dependent co - occurrence and word sense disambiguation . , pages 146152 .",
    "han , te  sun and kingo kobayashi .",
    "iwanami shoten publishers , tokyo .",
    "haruno , masahiko and yuji matsumoto .",
    "mistake - driven mixture of hierarchical tag context trees .",
    ", pages 230237 .",
    "haruno , masahiko , satoshi shirai , and yoshifumi ooyama .",
    "1998 . using decision trees to construct a practical parser . .",
    "hastings , w.k . 1970 .",
    "onte carlo sampling method using markov chains and their applications .",
    ", 57:97109 .",
    "helmbold , david  p. , robert  e. schapire , yoram singer , and manfred  k. warmuth .",
    "a comparison of new and old algorithm for a mixture estimation problem . , pages 6978 .",
    "hindle , donald . 1990 .",
    "noun classification from predicate - argument structures .",
    ", pages 268275 .",
    "hindle , donald and mats rooth .",
    "1991 . structural ambiguity and lexical relations .",
    ", pages 229236 .",
    "hindle , donald and mats rooth . 1993 . structural ambiguity and lexical relations . , 19(1):103120 .",
    "hobbs , jerry  r. and john bear .",
    "two principles of parse preference . , pages 162167 .",
    "hogenhout , wide  r. and yuji matsumoto .",
    "1996 . training stochastical grammars on semantical categories . in stefan wermter , ellen riloff , and gabriele scheler , editors , _ connectionist , statistical and symbolic approaches to learning for natural language processing_. springer .",
    "hogenhout , wide  r. and yuji matsumoto .",
    "1997 . a preliminary study of word clustering based on syntactic behavior . , pages 1624 .",
    "inui , kentaro , virach sornlertlamvanich , and hozumi tanaka .",
    "probabilistic glr parsing : a new formalization and its impact on parsing performance .",
    ", 5(3):3352 .",
    "iwayama , makoto and takenobu tokunaga .",
    "cluster - based text categorization : a comparison of category search strategy .",
    ", pages 273280 .",
    "jaynes , e.  t. 1978 . where do we stand on maximum entropy ? in r.",
    "d. levine and m.  tribus , editors , _ the maximum entropy formalism_. mit press .",
    "jeffreys , h. 1961 . .",
    "oxford univ . press .",
    "jelinek , f. , j.  d. lafferty , and r.  l. mercer .",
    "basic methods of probabilistic context free grammars . .",
    "jelinek , f. and r.  i. mercer .",
    "interpolated estimation of markov source parameters from sparse data . in e.s .",
    "gelseman and l.n .",
    "kanal , editors , _ pattern recognition in practice_. north - holland publishing company , pages 381397 .",
    "johnson - laird , p.  n. 1983 . .",
    "harvard univ . press .",
    "katz , j.  j. and j.  a. fodor .",
    "the structure of semantic theory .",
    ", 39:170210 .",
    "katz , slava  m. 1987 .",
    "estimation of probabilities from sparse data for the language model component of a speech recognizer . ,",
    "assp-35(3):400401 .",
    "kimball , john .",
    "seven principles of surface structure parsing in natural language . , 2(1):1547 .",
    "kirkpatrick , s. , c.  d. gelatt , and m.p .",
    "optimization by simulated annealing .",
    ", 220:671680 .",
    "kita , kenji .",
    "ph.d thesis , waseda univ .",
    "knuth , donald  e. 1973 . .",
    "addison - wesley publishing company .",
    "krichevskii , r.  e. and v.  k. trofimov .",
    "the performance of universal coding .",
    ", 27(2):199207 .",
    "kupiec , julian  m. 1992 .",
    "robust part - of - speech tagging using a hidden markov model .",
    ", 6:225242 .",
    "kurohashi , sadao and makoto nagao .",
    "1994 . a syntactic analysis method of long japanese sentences based on the detection of conjunctive structures .",
    ", 20(4):507534 .",
    "lakoff , george .",
    "the university of chicago press .",
    "lari , k. and s.j .",
    "the estimation of stochastic context free grammars using the inside - outside algorithm . , 4:3556 .",
    "leacock , claudia , geoffrey towell , and ellen voorhees .",
    "1993 . corpus - based statistical sense resolution . .",
    "li , hang .",
    "1996 . a probabilistic disambiguation method based on psycholinguistic principles . ,",
    "pages 141154 .",
    "li , hang and naoki abe . 1996 .",
    "clustering words with the mdl principle . , pages 49 .",
    "li , hang and naoki abe . 1997 . clustering words with the mdl principle . , 4(2):7188 .",
    "li , hang and kenji yamanishi . 1997 .",
    "document classification using a finite mixture model .",
    ", pages 7188 .",
    "littlestone , nick . 1988 .",
    "learning quickly when irrelevant attributes abound : a new linear - threshold algorithm .",
    ", 2:285318 .",
    "littlestone , nick and manfred  k. warmuth .",
    "1994 . the weighted majority algorithm .",
    ", 108:212261 .",
    "magerman , david  m. 1994 . .",
    "thesis , stanford univ .",
    "magerman , david  m. 1995 .",
    "statistical decision - tree models for parsing . , pages 276283 .",
    "magerman , david  m. and mitchell  p. marcus .",
    "pearl : a probabilistic chart parser .",
    ", pages 193199 .    manning , christopher  d. 1992 . automatic acquisition of a large subcategorization dictionary from corpora . ,",
    "pages 235242 .",
    "marcus , mitchell  p. , beatrice santorini , and mary  ann marcinkiewicz .",
    "1993 . building a large annotated corpus of english : the penn treebank . , 19(1):313330 .",
    "matsumoto , yuji , hiroyuki ishimoto , and takehito utsuro .",
    "structural matching of parallel texts .",
    ", pages 2330 .",
    "mccarthy , diana .",
    "word sense disambiguation for acquisition of selectional preferences .",
    ", pages 5260 .",
    "mckeown , kathleen and vasileios hatzivassiloglou .",
    "1993 . augmenting lexicons automatically : clustering semantically related adjectives . .",
    "mcmahon , john  c. and francis  j. smith .",
    "improving statistical language model performance with automatically generated word hierarchies .",
    ", 22(2):217247 .",
    "mcroy , susan  w. 1992 . using multiple knowledge sources for word sense discrimination .",
    ", 18(1):130 .",
    "merialdo , bernard .",
    "tagging english text with a probabilistic model .",
    ", 20(2):155171 .",
    "miller , george  a. 1995 .",
    "ordnet : a lexical database for english . , pages 3941 .",
    "miyata , takashi , takehito utsuro , and yuji matsumoto .",
    "ayesian network models of subcategorization and their mdl - based learning from corpus . , pages 321326 .",
    "nagao , katashi . 1990 .",
    "dependency analyzer : a knowledge - based approach to structural disambiguation .",
    ", 2:282287 .",
    "nagata , masaaki .",
    "1994 . a stochastic japanese morphological analyzer using a forward - dp backward - a * n - best search algorithm . , pages 201207 .",
    "ng , hwee  tou and hian  beng lee .",
    "1996 . integrating multiple knowledge sources to disambiguate word sense : an examplar - based approach . ,",
    "pages 4047 .",
    "niwa , yoshiki and yoshihiko nitta .",
    "co - occurrence vectors from corpora vs. distance vectors from dictionaries . , pages 304309 .",
    "nomiyama , hiroshi .",
    "machine translation by case generalization .",
    ", pages 714720 .",
    "pearl , judea .",
    "morgan kaufmann publishers inc . , san mateo , california .",
    "pereira , fernando and yoram singer .",
    "1995 . beyond word n - grams . ,",
    "pages 183190 .",
    "pereira , fernando and naftali tishby .",
    "distributional clustering , phase transitions and hierarchical clustering .",
    ", pages 108112 .",
    "pereira , fernando , naftali tishby , and lillian lee .",
    "distributional clustering of english words . ,",
    "pages 183190 .",
    "pollard , c. and i.  a. sag .",
    "chicago univ . press .",
    "quinlan , j.  ross and ronald  l. rivest .",
    "1989 . inferring decision trees using the minimum description length principle . , 80:227248 .",
    "ratnaparkhi , adwait .",
    "a maximum entroy part - of - speech tagger . .",
    "ratnaparkhi , adwait .",
    "1997 . a linear observed time",
    "statistical parser based on maximum models . .",
    "ratnaparkhi , adwait , jeff reynar , and salim roukos .",
    "1994 . a maximum entropy model for prepositional phrase attachment . ,",
    "pages 250255 .",
    "resnik , philip .",
    "ordnet and distributional analysis : a class - based approach to lexical discovery . .",
    "resnik , philip .",
    "thesis , univ . of pennsylvania .",
    "resnik , philip .",
    "semantic classes and syntactic ambiguity . .",
    "ribas , francesc .",
    "1995 . on learning more appropriate selectional restrictions .",
    "rissanen , jorma .",
    "a universal prior for integers and estimation by minimum description length .",
    ", 11(2):416431 .",
    "rissanen , jorma .",
    "universal coding , information , predication and estimation .",
    ", 30(4):629636 .",
    "rissanen , jorma .",
    "world scientific publishing co. , singapore .",
    "rissanen , jorma .",
    "fisher information and stochastic complexity .",
    ", 42(1):4047 .",
    "rissanen , jorma .",
    "stochastic complexity in learning .",
    ", 55:8995 .",
    "ristad , eric  sven and robert  g. thomas . 1995 .",
    "new techniques for context modeling . .",
    "rivest , ronald  l. 1987 . learning decision lists .",
    ", pages 229246",
    ".    rose , kenneth , eitan gurewitz , and geoffrey  c. fox .",
    "statistical mechanics and phase transitions in clustering . , 65(8):945948 .",
    "rosenfeld , ronald .",
    "a maximum entropy approach to adaptive statistical language modeling .",
    ", 22(1):3971 .",
    "samuelsson , christer .",
    "a novel framework for reductionistic statistical parsing .",
    ", pages 208215 .",
    "saul , lawrence and fernando pereira .",
    "aggregate and mixed - order markov models for statistical language processing . .",
    "schabes , yves . 1992 .",
    "stochastic lexicalized tree - adjoining grammars . , pages 425432 .",
    "schtze , hinrich .",
    "csli stanford .",
    "schtze , hinrich .",
    "1998 . automatic word sense discrimination .",
    ", 24(1):97123 .",
    "schtze , hinrich and yoram singer .",
    "part - of - speech tagging using a variable memory markov model .",
    ", pages 181187 .",
    "schwarz , g. 1978 .",
    "estimation of the dimension of a model .",
    ", 6:416446 .",
    "sekine , satoshi , jeremy  j. carroll , sofia ananiadou , and junichi tsujii .",
    "automatic learning for semantic collocation .",
    ", pages 104110 .",
    "shirai , kiyoaki , kentaro inui , takenobu tokunaga , and hozumi tanaka .",
    "a framework of intergrating syntactic and lexical statistics in statistical parsing .",
    ", 5(3):85106 .",
    "smadja , frank .",
    "retrieving collocations from text : xtract . , 19(1):143177 .",
    "solomonoff , r.j .",
    "1964 . a formal theory of inductive inference 1 and 2 .",
    ", 7:122,224254 .",
    "stolcke , andreas and stephen omohundro .",
    "1994 . inducing probabilistic grammars by bayesian model merging . in rafael  c. carrasco and jose oncina , editors , _ grammatical inference and applications_. springer verlag , pages 106118 .",
    "stolcke , andreas and jonathan segal .",
    "precise n - gram probabilities from stochastic context - free grammars . , pages 7479 .",
    "su , keh - yih and jing - shin chang .",
    "semantic and syntactic aspects of score function . , pages 642644 .",
    "su , keh - yih , jong - nae wang , mei - hui su , and jin - shin chang .",
    "1989 . a sequential truncation parsing algorithm based on the score function . ,",
    "pages 95104 .",
    "suzuki , joe .",
    "1993 . a construction of bayesian networks from databases based on an mdl principle . , pages 266273 .",
    "tanaka , hideki .",
    "1994 . verbal case frame acquisition from a bilingual corpus : gradual knowledge acquisition .",
    ", pages 727731 .",
    "tanaka , hideki .",
    "1996 . decision tree learning algorithm with structured attributes : application to verbal case frame acquisition . ,",
    "pages 943948 .",
    "tanner , martin  a. and wing  hung wong .",
    "the calculation of posterior distributions by data augmentation .",
    ", 82(398):528540 .",
    "tokunaga , takenobu , makoto iwayama , and hozumi tanaka .",
    "automatic thesaurus construction based - on grammatical relations . , pages 13081313 .",
    "tsujii , junichi .",
    "shoukoudou , tokyo .",
    "ueda , naonori and ryohei nakano .",
    "deterministic annealing em algorithm .",
    ", 11(2):271282 .",
    "ushioda , akira .",
    "hierarchical clustering of words and application to nlp tasks .",
    ", pages 2841 .",
    "utsuro , takehito and yuji matsumoto .",
    "learning probabilistic subcategorization preference by identifying case dependencies and optimal noun class generalization level . , pages 364371 .",
    "utsuro , takehito , yuji matsumoto , and makoto nagao .",
    "lexical knowledge acquisition from bilingual corpora .",
    ", pages 581587 .",
    "velardi , paola , maria  teresa pazienza , and michela fasolo .",
    "1991 . how to encode semantic knowledge : a method for meaning representation and computer - aided acquisition . , 17(2):153170 .",
    "voorhees , ellen  m. , claudia leacock , and geoffrey towell . 1995 .",
    "learning context to disambiguate word senses . in t.",
    "petsche , s.j.hanson , and j.w .",
    "shavlik , editors , _ computational learning theory and natural language learning systems 3 : selecting good models_. mit press , pages 279305 .",
    "wallace , c. and d.  m. boulton .",
    "an information measure for classification .",
    ", 11:185195 .",
    "webster , mort and mitch marcus . 1989 .",
    "automatic acquisition of the lexical semantics of verbs from sentence frames .",
    ", pages 177184 .",
    "wermter , stefan .",
    "integration of semantic and syntactic constraints for structural noun phrase disambiguation .",
    ", pages 14861491 .",
    "whittemore , greg , kathleen ferrara , and hans brunner .",
    "empirical study of predictive powers of simple attachment schemes for post - modifier prepositional phrases . ,",
    "pages 2330 .",
    "wilks , yorick . 1975 . an intelligent analyzer and understander of english . , 18(5):264274 .",
    "wright , j.h .",
    "lr parsing of probabilistic grammars with input uncertainty for speech recognition .",
    ", 4:297323 .",
    "yamanishi , kenji . 1992a . a learning criterion for stochastic rules .",
    ", 9:165203 .",
    "yamanishi , kenji .",
    "thesis , univ . of tokyo .",
    "yamanishi , kenji .",
    "1996 . a randomized approximation of the mdl for stochastic models with hidden variables . , pages 99109 .",
    "yarowsky , david .",
    "word - sense disambiguation using statistical models of roget s categories trained on large corpora .",
    ", pages 454460 .",
    "yarowsky , david .",
    "one sense per collocation . .",
    "yarowsky , david .",
    "decision lists for lexical ambiguity resolution : application to accent restoration in spanish and french . , pages 8895 .",
    "yarowsky , david .",
    "unsupervised word sense disambiguation rivaling supervised methods .",
    ", pages 189196 .",
    "[ [ section ] ]      we consider here @xmath1    we first make taylor s expansion of @xmath2 around @xmath3 : @xmath4 where @xmath5 denotes a transpose of @xmath6 .",
    "the second term equals 0 because @xmath3 is the mle estimate , and we ignore the fourth term .",
    "furthermore , the third term can be written as @xmath7 where ` @xmath8 ' denotes the natural logarithm ( recall that ` @xmath9 ' denotes the logarithm to the base 2 ) . under certain suitable conditions , when @xmath10 , @xmath11 can be approximated as a @xmath12-dimensional matrix of constants @xmath13 known as the ` fisher information matrix . '",
    "let us next consider @xmath14    differentiating this formula with each @xmath15 and having the results equal 0 , we obtain the following equations : @xmath16 suppose that the eigenvalues of @xmath13 are @xmath17 , and the eigenvectors are @xmath18 .",
    "if we consider only the case in which the axes of a cell ( @xmath12-dimensional rectangular solid ) in the discretized vector space are in parallel with @xmath18 , then ( [ eq : delta ] ) becomes @xmath19 hence , we have @xmath20 and @xmath21 moreover , since @xmath22 where ` @xmath23 ' stands for the determinant of @xmath24 , we have @xmath25 ) becomes @xmath26      i describe here a method of learning the soft case slot model defined in ( [ eq : soft - csmodel ] ) .",
    "we can first adopt an existing soft clustering of words and estimate the word probability distribution @xmath27 within each class by employing a heuristic method ( cf . , @xcite ) .",
    "we can next estimate the coefficients ( parameters ) @xmath28 in the finite mixture model .",
    "there are two common methods for statistical estimation , maximum likelihood estimation and bayes estimation . in their implementation for estimating the above coefficients",
    ", however , both of them suffer from computational intractability .",
    "the em algorithm @xcite can be used to approximate the maximum likelihood estimates of the coefficients .",
    "the markov chain monte - carlo technique @xcite can be used to approximate the bayes estimates of the coefficients .",
    "we consider here the use of an extended version of the em algorithm @xcite .",
    "for the sake of notational simplicity , for some fixed @xmath29 and @xmath30 , let us write @xmath31 as @xmath32 and @xmath27 as @xmath33 . then the soft case slot model in ( [ eq : soft - csmodel ] ) may be written as @xmath34 letting @xmath35 , for a given training sequence @xmath36 the maximum likelihood estimate of @xmath37 , denoted as @xmath3 , is defined as the value that maximizes the following log likelihood function @xmath38    the em algorithm first arbitrarily sets the initial value of @xmath37 , which we denote as @xmath39 , and then successively calculates the values of @xmath37 on the basis of its most recent values .",
    "let @xmath40 be a predetermined number . at the @xmath41th iteration ( @xmath42 )",
    ", we calculate @xmath43 by @xmath44 where @xmath45 ( when @xmath46 , helmbold et al s version simply becomes the standard em algorithm ) , and @xmath47 denotes @xmath48 after @xmath40 numbers of calculations , the em algorithm outputs @xmath49 as an approximate of @xmath3 .",
    "it is theoretically guaranteed that the em algorithm converges to a _",
    "local _ maximum of the likelihood function @xcite .",
    "if we write @xmath50 for the number of tree cuts in a complete @xmath51-ary tree of depth @xmath52 , we can show by mathematical induction that the number of tree cuts in a complete @xmath51-ary tree of depth @xmath53 satisfies @xmath54since clearly @xmath55 and @xmath56    since the number of leaf nodes @xmath57 in a complete @xmath51-ary tree equals @xmath58 , we conclude that the number of tree cuts in a complete @xmath51-ary tree is of order @xmath59 .",
    "note that the number of tree cuts in a tree depends on the structure of that tree .",
    "if a tree is what i call a ` one - way branching @xmath51-ary tree , ' then it is easy to verify that the number of tree cuts in that tree is only of order @xmath60 .",
    "figure  [ fig : owb - tree ] shows an example one - way branching @xmath51-ary tree .",
    "note that a thesaurus tree is an unordered tree ( for the definition of an unordered tree , see , for example , @xcite ) .",
    "for an arbitrary subtree @xmath61 of a thesaurus tree @xmath62 and an arbitrary tree cut model @xmath63 in @xmath62 , let @xmath64 denote the submodel of @xmath65 that is contained in @xmath61 . also , for any sample @xmath66 , let @xmath67 denote the subsample of @xmath66 contained in @xmath61 .",
    "( note that @xmath68 , @xmath69 . ) then , in general for any submodel @xmath70 and subsample @xmath67 , define @xmath71 to be the data description length of subsample @xmath67 using submodel @xmath70 , define @xmath72 to be the parameter description length for the submodel @xmath70 , and define @xmath73 to be @xmath74 .",
    "first for any ( sub)tree @xmath62 , for any ( sub)model @xmath75 which is contained in @xmath62 except the ( sub)model consisting only of the root node of @xmath62 , and for any ( sub)sample @xmath76 contained in @xmath62 , we have @xmath77 where @xmath78 denote the child subtrees of @xmath62 .    for any ( sub)tree @xmath62 , for",
    "any ( sub)model @xmath75 which is contained in @xmath62 except the ( sub)model consisting only of the root node of @xmath62 , we have @xmath79 where @xmath80 denote the child subtrees of @xmath62 .    when @xmath62 is the entire thesaurus tree , the parameter description length for a tree cut model in @xmath62 should be @xmath81 in ( [ eq : prov3 ] ) is common to each model in the entire thesaurus tree , it is irrelevant for the purpose of finding a model with the minimum description length",
    ".    we will thus use identity ( [ eq : prov2 ] ) both when @xmath62 is a proper subtree and when it is the entire tree .",
    "( this allows us to use the same recursive algorithm ( find - mdl ) in all cases . )",
    "it follows from ( [ eq : prov1 ] ) and ( [ eq : prov2 ] ) that the minimization of description length can be done essentially independently for each subtree .",
    "namely , if we let @xmath82 denote the minimum description length ( as defined by ( [ eq : prov1 ] ) and ( [ eq : prov2 ] ) ) achievable for ( sub)model @xmath83 on ( sub)sample @xmath76 contained in ( sub)tree @xmath62 , @xmath84 the mle estimate of the probability for node @xmath85 , and @xmath86 the root node of @xmath62 , then we have @xmath87 , [ \\hat{p}({\\rm root}(t ) ) ] ) , s_t)\\}. \\\\   \\end{array}\\ ] ] here , @xmath80 denote the child subtrees of @xmath62 .    the rest of the proof proceeds by induction .",
    "first , if @xmath62 is a subtree having a single node , then there is only one submodel in @xmath62 , and it is clearly the submodel with the minimum description length .",
    "next , inductively assume that find - mdl@xmath88 correctly outputs a submodel with the minimum description length for any subtree @xmath61 of size less than @xmath89 .",
    "then , given a ( sub)tree @xmath62 of size @xmath89 whose root node has at least two child subtrees , say @xmath90 , for each @xmath91 , find - mdl@xmath92 returns a submodel with the minimum description length by inductive hypothesis .",
    "then , since ( [ eq : prov4 ] ) holds , in whichever way the if - clause on lines 8 , 9 of find - mdl is evaluated , what is returned on line 11 or line 13 will still be a ( sub)model with the minimum description length , completing the inductive step .",
    "it is easy to see that the time complexity of the algorithm is linear in the number of leaf nodes of the input thesaurus tree .",
    "we prove here that the dependency tree models based on a labeled free tree are equivalent to one another . here",
    ", a labeled free tree means a tree in which each node is associated with one unique label and in which any node can be the root .",
    "suppose that the free tree we have is now rooted at @xmath93 ( figure  [ fig : free - tree ] ) .",
    "the dependency tree model based on this rooted tree will then be uniquely determined .",
    "suppose that we randomly select one other node @xmath94 from this tree .",
    "if we reverse the directions of the links from @xmath93 to @xmath94 , we will obtain another tree rooted at @xmath94 . another dependency tree model based on this tree",
    "will also be determined .",
    "it is not difficult to see that these two distributions are equivalent to one another , since @xmath95 thus we complete the proof .",
    "we can represent any dependency forest model as @xmath96 where @xmath97 denotes a random variable which @xmath94 depends on .",
    "we let @xmath98 .",
    "note that there exists a @xmath99 for which @xmath100 .",
    "the sum of parameter description length and data description length for any dependency forest model equals @xmath101 where @xmath57 denotes data size , @xmath102 the possible values of @xmath94 , and @xmath103 the number of possible values of @xmath94 .",
    "we let @xmath104 and @xmath105 .    furthermore , the sum of parameter description length and data description length for the independent model ( i.e. , @xmath106 ) equals @xmath107    thus , the difference between the description length of the independent model and the description length of any dependency forest model becomes @xmath108    any dependency forest model for which there exists an @xmath52 satisfying @xmath109 is not favorable from the viewpoint of mdl because the model for which the corresponding @xmath52 satisfying @xmath110 always exists and is clearly more favorable .",
    "we thus need only select the mdl model from those models for which for any @xmath52 , @xmath111 is satisfied . obviously , the model for which @xmath112 is maximized is the best model in terms of mdl . what suzuki s algorithm outputs is exactly this model , and this completes the proof",
    "1 .   li , h. : a probabilistic disambiguation method based on psycholinguistic principles , ( in japanese ) _ computer software _ ,",
    "vol.13 , no . 6 , ( 1996 ) pp .",
    "li , h. and abe , n. : clustering words with the mdl principle , _ journal of natural language processing _ ,",
    "vol.4 , no .",
    "2 , ( 1997 ) , pp .  7188 .",
    "li , h. and abe , n. : generalizing case frames using a thesaurus and the mdl principle , _ computational linguistics _ ,",
    "vol.24 , no.2 ( 1998 ) , pp .  217 - 244 .      1 .",
    "li , h. and abe , n. : generalizing case frames using a thesaurus and the mdl principle , _ proceedings of recent advances in natural language processing _ ,",
    "( 1995 ) , pp .",
    "abe , n. and li , h. : on - line learning of binary lexical relations using two - dimensional weighted majority algorithms , _ proceedings of the 12th international conference on machine learning ( icml95 ) _ , ( 1995 ) , pp .  7188 .",
    "li , h. : a probabilistic disambiguation method based on psycholinguistic principles , _ proceedings of the 4th workshop on very large corpora _ , ( 1996 ) , pp .",
    "li , h. and abe , n. : clustering words with the mdl principle , _ proceedings of the 16th international conference on computational linguistics ( coling96 ) _ , ( 1996 ) , pp .",
    "49 . 5 .",
    "li , h. and abe , n. : learning dependencies between case frame slots , _ proceedings of the 16th international conference on computational linguistics ( coling96 ) _ , ( 1996 ) , pp .",
    "abe , n. and li , h.:learning word association norms using tree cut pair models , _ proceedings of the 13th international conference on machine learning ( icml96 ) _ , ( 1996 ) , pp .",
    "7188 . 7 .",
    "li , h. and yamanishi , k. : document classification using a finite mixture model , _ proceedings of the 35th annual meeting of association for computational linguistics ( acl / eacl97 ) _ , ( 1997 ) . 8",
    ".   li , h. and abe , n. : word clustering and disambiguation based on co - occurrence data , _ proceedings of the 18th international conference on computational linguistics and the 36th annual meeting of association for computational linguistics ( coling - acl98 ) _ , ( 1998 ) , to appear ."
  ],
  "abstract_text": [
    "<S> structural disambiguation in sentence analysis is still a central problem in natural language processing . </S>",
    "<S> past researches have verified that using lexical semantic knowledge can , to a quite large extent , cope with this problem . </S>",
    "<S> although there have been many studies conducted in the past to address the lexical knowledge acquisition problem , further investigation , especially that based on a _ principled methodology _ is still needed , and this is , in fact , the problem i address in this thesis .    </S>",
    "<S> the problem of acquiring and using lexical semantic knowledge , especially that of case frame patterns , can be formalized as follows . </S>",
    "<S> a learning module acquires case frame patterns on the basis of some case frame instances extracted from corpus data . </S>",
    "<S> a processing ( disambiguation ) module then refers to the acquired knowledge and judges the degrees of acceptability of some number of new case frames , including _ previously unseen _ ones .    </S>",
    "<S> the approach i adopt has the following characteristics : ( 1 ) dividing the problem into three subproblems : case slot generalization , case dependency learning , and word clustering ( thesaurus construction ) . </S>",
    "<S> ( 2 ) viewing each subproblem as that of statistical estimation and defining probability models for each subproblem , ( 3 ) adopting the minimum description length ( mdl ) principle as learning strategy , ( 4 ) employing efficient learning algorithms , and ( 5 ) viewing the disambiguation problem as that of statistical prediction .    the need to divide the problem into subproblems </S>",
    "<S> is due to the complicatedness of this task , i.e. , there are too many relevant factors simply to incorporate all of them into a single model . </S>",
    "<S> the use of mdl here leads us to a theoretically sound solution to the ` data sparseness problem , ' the main difficulty in a statistical approach to language processing .    in chapter 3 , </S>",
    "<S> i define probability models for each subproblem : ( 1 ) the hard case slot model and the soft case slot model ; ( 2 ) the word - based case frame model , the class - based case frame model , and the slot - based case frame model ; and ( 3 ) the hard co - occurrence model and the soft co - occurrence model . </S>",
    "<S> these are respectively the probability models for ( 1 ) case slot generalization , ( 2 ) case dependency learning , and ( 3 ) word clustering . here </S>",
    "<S> the term ` hard ' means that the model is characterized by a type of word clustering in which a word can only belong to a single class alone , while ` soft ' means that the model is characterized by a type of word clustering in which a word can belong to several different classes .    in chapter 4 , </S>",
    "<S> i describe one method for learning the hard case slot model , i.e. , generalizing case slots . </S>",
    "<S> i restrict the class of hard case slot models to that of tree cut models by using an existing thesaurus . in this way </S>",
    "<S> , the problem of generalizing the values of a case slot turns out to be that of estimating a model from the class of tree cut models for some fixed thesaurus tree . </S>",
    "<S> i then employ an efficient algorithm , which provably obtains the optimal tree cut model in terms of mdl . </S>",
    "<S> this method , in fact , conducts generalization in the following way . </S>",
    "<S> when the differences between the frequencies of the nouns in a class are not large enough ( relative to the entire data size and the number of the nouns ) , it generalizes them into the class . when the differences are especially noticeable , on the other hand , it stops generalization at that level .    in chapter 5 , </S>",
    "<S> i describe one method for learning the case frame model , i.e. , learning dependencies between case slots . </S>",
    "<S> i restrict the class of case frame models to that of dependency forest models . </S>",
    "<S> case frame patterns can then be represented as a dependency forest , whose nodes represent case slots and whose directed links represent the dependencies that exist between these case slots . </S>",
    "<S> i employ an efficient algorithm to learn the optimal dependency forest model in terms of mdl . </S>",
    "<S> this method first calculates a statistic between all node pairs and sorts these node pairs in descending order with respect to the statistic . </S>",
    "<S> it then puts a link between the node pair highest in the order , provided that this value is larger than zero . </S>",
    "<S> it repeats this process until no node pair is left unprocessed , provided that adding that link will not create a loop in the current dependency graph .    in chapter 6 , </S>",
    "<S> i describe one method for learning the hard co - occurrence model , i.e. , automatically conducting word clustering . </S>",
    "<S> i employ an efficient algorithm to repeatedly estimate a suboptimal mdl model from a class of hard co - occurrence models . </S>",
    "<S> the clustering method iteratively merges , for example , noun classes and verb classes in turn , in a bottom up fashion . for each merge it performs </S>",
    "<S> , it calculates the decrease in empirical mutual information resulting from merging any noun ( or verb ) class pair , and performs the merge having the least reduction in mutual information , provided that this reduction in mutual information is less than a threshold , which will vary depending on the data size and the number of classes in the current situation .    in chapter 7 </S>",
    "<S> , i propose , for resolving ambiguities , a new method which combines the use of the hard co - occurrence model and that of the tree cut model . in the implementation of this method </S>",
    "<S> , the learning module combines with the hard co - occurrence model to cluster words with respect to each case slot , and it combines with the tree cut model for generalizing the values of each case slot by means of a hand - made thesaurus . </S>",
    "<S> the disambiguation module first calculates a likelihood value for each interpretation on the basis of hard co - occurrence models and outputs the interpretation with the largest likelihood value ; if the likelihood values are equal ( most particularly , if all of them are 0 ) , it uses likelihood values calculated on the basis of tree cut models ; if the likelihood values are still equal , it makes a default decision .    </S>",
    "<S> the accuracy achieved by this method is @xmath0 , which is higher than that of state - of - the - art methods . </S>"
  ]
}