{
  "article_text": [
    "in the complex - valued gaussian channel with signal - to - noise ratio @xmath2 the mutual information of very general constellations ( e.  g.  zero - mean with uncorrelated real and imaginary parts each of energy  @xmath3 @xcite ) has the same low-@xmath2 asymptotics as the channel capacity , namely @xmath4 . these constellations also attain the minimum bit - energy - to - noise - variance ratio of -1.59 at vanishing @xmath2 .",
    "a natural question concerns the extent to which this universality extends to other common channel models .",
    "we consider here the discrete - time poisson channel , frequently used to represent optical communication channels , and quantity the gap between the channel capacity and the mutual information for fixed signal constellations . as a by - product of our analysis",
    ", we also determine the asymptotic form of the capacity at vanishing signal energy .",
    "consider a memoryless channel with input @xmath5 and output @xmath6 given by the sum @xmath7 of a noise @xmath8 and a signal component @xmath9 , itself a function of the input @xmath5 .",
    "the input @xmath5 is a non - negative real number ( i.  e.  it has units of energy ) , drawn from a unit - energy set @xmath10 according to a probability distribution @xmath11 .",
    "we let @xmath9 be distributed according to a poisson distribution of parameter @xmath12 , where @xmath13 is an average signal energy . the output components @xmath9 , @xmath8 , and @xmath6 are nonnegative integers .",
    "we study three channel models : noiseless , with @xmath14 ; additive poisson noise , where @xmath8 follows a poisson distribution of mean @xmath15 ; and additive geometric noise , with @xmath8 distributed according to a geometric distribution of mean @xmath15 . with additive poisson noise the channel transition probability , denoted by @xmath16 ,",
    "is given by @xmath17 where @xmath18 .",
    "for the channel with geometric noise , we have @xmath19 remark that the model with additive geometric noise arises in representations of electromagnetic radiation as a photon gas @xcite .    in this letter , we compute the minimum energy per bit for these models .",
    "we also study the asymptotics of the mutual information @xmath20 at low @xmath13 and compare them with the channel capacity @xmath21 at energy @xmath13 .",
    "the main results are presented in the next section ; the proofs can be found in the appendices .",
    "a closed - form expression for the capacity @xmath21 of the discrete - time poisson channel is not known . for the noiseless channel ( i.  e.  with @xmath22 , the best known firm upper bound was derived in @xcite , and is given by @xmath23    as for lower bounds , binary modulation attains a high mutual information at low values of @xmath13 .",
    "specifically , let the symbols be located at @xmath24 and @xmath25 , and be respectively used with probabilities @xmath26 and @xmath27 .",
    "we denote the mutual information attained by such modulation by @xmath28 .",
    "a trite computation gives @xmath29    setting @xmath30 , and using the taylor expansion of the logarithm @xmath31 around @xmath24 in both eq .",
    "and eq .  , we have that @xmath32 therefore , the capacity @xmath21 of the noiseless discrete - time poisson channel behaves as @xmath33 at vanishing @xmath13 .",
    "moreover , a similar reasoning shows that flash signalling with @xmath34 ( for @xmath35 ) asymptotically behaves as @xmath36 for low @xmath13 . combining eqs .   and  , we obtain the following    [ thm : cappoislowes ] for vanishing @xmath13 the capacity @xmath21 behaves as @xmath37    this result complements the asymptotic behaviour for very large values of @xmath13 , which was established in @xcite , @xmath38    observe that eq",
    ".   implies that the capacity per unit energy @xmath39 , @xmath40 is infinite for the discrete - time poisson channel .",
    "this well - known result had been obtained by verd @xcite by exploiting a simple formula for @xmath39 in channels which have a zero - energy symbol ( @xmath24 in our case ) , namely @xmath41 where @xmath42 is the divergence between the transition probabilities @xmath43 for arbitrary input @xmath44 and zero input @xmath45 .    by definition ,",
    "the minimum energy per bit @xmath46 , where the capacity is measured in bits , is given by @xmath47 .",
    "applied to the family of channels we consider , we have    in the absence of additive noise , i.  e. for @xmath14 , or in the presence of additive poisson noise , the minimum energy per bit is @xmath48 . equivalently the capacity per unit cost is @xmath49 .    with additive geometric noise ,",
    "the minimum energy per bit is @xmath50 and the capacity per unit cost is @xmath51 .",
    "the latter result is new .",
    "remarkably , the minimum energy per bit has the same form as in the gaussian channel , for a minimum ratio @xmath52 of -1.59 .",
    "the proof can be found in appendix  [ app : cunitcost ] .",
    "we now move on to study the asymptotics of the mutual information @xmath20 ( in nats ) at low @xmath13 for fixed unit - energy constellations @xmath10 .",
    "the output @xmath9 is distributed according to a poisson distribution of parameter @xmath12 .",
    "we determine the first two coefficients @xmath53 and @xmath54 in the taylor expansion around @xmath55 , that is @xmath56 also , we define the energy per bit @xmath57 as @xmath58 . denoting the first- and second - order moments of the constellation by @xmath59 ( we often have @xmath60 ) and @xmath61",
    "respectively , we have    in the absence of additive noise , i.  e. for @xmath14 , the mutual information behaves at low @xmath13 as eq .   with @xmath62    as long as @xmath15 , regardless of whether @xmath8 has a poisson or a geometric distribution , the coefficients in eq .",
    "are @xmath63    eq .",
    "is proved in appendix  [ app : cmexpansiondtp ] , eq .   in appendices  [ app : cmexpansiondtpb ] and",
    "[ app : cmexpansionaeq ] for poisson and geometric noise respectively .      in the presence of non - zero additive noise , the mutual information is concave at zero signal - energy ( because @xmath64 , @xmath65 ) and the minimum energy per bit is not attained at zero capacity .",
    "this effect can be seen in fig .",
    "[ fig : t20070112-eblog ] , which depicts the energy per bit @xmath57 as a function of the mutual information for several positive values of @xmath1 .",
    "the modulation depicted is uniform pulse - energy modulation ( pem ) , e.  g.  @xmath66 points uniformly located between 0 and 2 with spacing @xmath67 .",
    "general signal constellations do not attain the minimum energy - per - bit at vanishing signal energy . the determination of the minimum energy per bit attained by these modulations is an open problem .     as a function of the mutual information for uniform @xmath66-pem and varying @xmath1 ( geometric noise ) . ]    moreover , since there is no coefficient in @xmath68 in eq .",
    ", these modulations do not attain the minimum energy per bit @xmath69 .",
    "this is true even for the noiseless channel , for which @xmath70 . in this case ,",
    "binary modulation at points @xmath71 and @xmath72 respectively used with probabilities @xmath26 and @xmath27 , with fixed @xmath27 , has coefficients @xmath53 and @xmath54 @xmath73 in the limit @xmath74 , @xmath75 and the bit energy at zero capacity , @xmath76 , approaches 0 , the minimum energy per bit . fig .",
    "[ fig : t20070215-bnr ] depicts @xmath57 as a function of the mutual information for various fixed values of @xmath27 and for @xmath34 . for comparison",
    ", we also include the value of @xmath57 corresponding to the upper bound in eq .  .",
    "even though @xmath76 indeed approaches zero , it does so rather slowly .",
    "also , the gap between the energy per bit corresponding to @xmath77 and @xmath69 closes slowly .",
    "numerical evaluation shows that it is only for values of @xmath13 below @xmath78 ( ! ) that @xmath79 exceeds @xmath80 . even though one eventually has @xmath81 , convergence to the limit is very slow",
    "this fact , together with the concave nature of the mutual information @xmath82 at zero @xmath13 for nonzero additive noise , suggests that the asymptotic analysis of the capacity and the mutual information in the discrete - time poisson channel fails to capture the key features of these quantities .",
    "this behaviour stands in contrast with the gaussian channel , where asymptotic expansions give an accurate representation of the capacity and the mutual information @xcite .     as a function of the mutual information or the capacity ( noiseless channel , @xmath14 ) . ]",
    "we first consider the case with additive poisson noise .",
    "using eq .   for @xmath83 and the definition of divergence , we have @xmath84 hence , @xmath85    we now consider the channel with additive geometric noise . using eq .   for @xmath83 and the definition of divergence , we have @xmath86 where @xmath87 .",
    "let us define @xmath88 and the quantity @xmath89 , i.  e.  the cumulative distribution function of a poisson random variable with mean @xmath90 .    moving the exponential out of the logarithm",
    ", we obtain @xmath91 hence , the capacity per unit energy is given by @xmath92 since @xmath93 , its logarithm is always non - positive , and @xmath94 the proof is completed by proving that @xmath95 where we expressed @xmath16 as a function of @xmath96 .",
    "if this condition holds true , then eq .   becomes an equality .    in eq .",
    "we split the summation over @xmath97 into two parts , from 0 to @xmath98 , and from @xmath99 to infinity . in the first part",
    ", @xmath100 is an increasing function in @xmath97 , and therefore @xmath101 hence , the summation for @xmath102 is bounded as @xmath103 and , multiplying by the exponential factor @xmath104 , we have @xmath105 both summands vanish as @xmath106 .",
    "the second has the form @xmath107 which decays exponentially in @xmath44 , since the sum satisfies @xmath108 and @xmath109 vanishes for large @xmath110 .",
    "similarly , the summation @xmath111 remains bounded , since it is the partial sum of a convergent series , with @xmath112-th coefficient @xmath113 and @xmath114 .",
    "this is verified by the checking the ratio test , as @xmath115 boundedness of the partial sum implies that , after multiplying times an exponential factor @xmath116 , the first summand vanishes as @xmath117 .",
    "next , we consider the remainder of the summation in eq .",
    ", @xmath118 clearly , @xmath119 and therefore @xmath120 , so each summand is negative and bounded by @xmath121 summing over @xmath97 , @xmath122    using that @xmath87 and taking into account the denominator @xmath123 in eq .  , we must study the behaviour of @xmath124 as @xmath117 . by construction , @xmath125 , and therefore @xmath126 since @xmath127 for @xmath128 ,",
    "a fact which follows from the inequality @xmath129 , the left - hand side of eq .   is strictly upper bounded by a function @xmath130 , with @xmath131 .",
    "hence , the function in eq .",
    "vanishes exponentially as @xmath117 , and so does the term @xmath132 this proves the limit in eq .   and that eq .",
    "holds with equality .",
    "the mutual information is given by @xmath133    using the taylor expansion of the exponential @xmath134 , we notice that there are only three possible channel outputs to order @xmath135 , namely @xmath136 since each of these cases behaves differently , we examine them separately .",
    "we rewrite the variable in the @xmath137 in eq .   with the appropriate approximation . when the output is @xmath138 , the variable is @xmath139 taking logarithms , and using the formula @xmath140 , we obtain @xmath141    for @xmath142 , the variable in the logarithm in eq .",
    "is @xmath143 taking logarithms , and using the taylor expansion , we get @xmath144 we will later verify that no higher - order terms are required .    at last , for @xmath145 , the variable in the logarithm in eq .",
    "is @xmath146 again , taking logarithms , and using the taylor expansion , we get @xmath147 later , we will verify that no higher - order terms are required .    after carrying out the averaging over @xmath97",
    ", we first combine eqs .  ,   and   with the probabilities in eqs .",
    " and then group all terms up to @xmath148 to derive @xmath149 the expectation over @xmath44 is straightforward , and gives the desired @xmath82 .",
    "the mutual information is given by @xmath150    using the taylor expansion of the exponential , and neglecting terms of order higher than @xmath135 , the channel output law is given by @xmath151    we next examine the logarithm in eq .  .",
    "first , the taylor expansions of @xmath152 and @xmath153 yield @xmath154 similarly , using the expansion of the exponential , we have @xmath155 now , carrying out the expectation over @xmath156 we obtain @xmath157    next , using the expansion of the logarithm , we obtain @xmath158    now , multiplying by the channel law , we get for given @xmath44 and @xmath97 @xmath159 after carrying out the expectation over @xmath44 , some terms cancel to give @xmath160    as a final step , we sum over @xmath97 to obtain the mutual information , @xmath161",
    "the mutual information is given by @xmath162 where @xmath16 is given by eq .  .    as it happened in the discrete - time poisson channel ,",
    "the taylor expansion of the exponential implies that there are only three possible channel outputs @xmath163 to order @xmath135 , that is , @xmath164 hence the channel output @xmath165 only includes these contributions .",
    "we distinguish three cases , viz .",
    "@xmath138 , @xmath142 , and @xmath166 .",
    "we next rewrite the numerator and denominator in the @xmath137 in eq .   with the appropriate approximation . for @xmath138 , the common term @xmath174 cancels , and the numerator is @xmath175 in the denominator",
    ", we keep the expansion @xmath176 taking logarithms of eqs .   and  ,",
    "using a taylor expansion , and combining numerator and denominator , we obtain @xmath177        if the output is @xmath166 , in an analogous way we use eq .",
    "to rewrite the logarithm of the ratio of numerator and denominator as @xmath182 using now the taylor expansion of the logarithm , we obtain @xmath183          the summation over @xmath166 can be carried out and yields @xmath188 then , combining eq .   into eq .  , and summing with eqs .   and   ( including the factor @xmath185 ) ,",
    "we obtain @xmath189 the expansion for @xmath82 follows ."
  ],
  "abstract_text": [
    "<S> the first terms of the low - signal - energy asymptotics for the mutual information in the discrete - time poisson channel are derived and compared to an asymptotic expression of the capacity . in the presence of non - zero additive noise ( either poisson or geometric ) , </S>",
    "<S> the mutual information is concave at zero signal - energy and the minimum energy per bit is not attained at zero capacity . </S>",
    "<S> fixed signal constellations which scale with the signal energy do not attain the minimum energy per bit . </S>",
    "<S> the minimum energy per bit is zero when additive poisson noise is present and @xmath0 when additive geometric noise of mean @xmath1 is present . </S>"
  ]
}