{
  "article_text": [
    "in this work , we propose the method of constructing ( binary ) expansions of discrete - time continuous alphabet channels , and coding over the resulting set of parallel channels .",
    "we apply this _ coding over expansions _ method to additive exponential noise ( aen ) channels , where the signal and noise terms constructing the channel output are represented with their corresponding binary digits . focusing on the additive exponential noise component",
    ", we show that the binary expansion of the noise consists of independent bernoulli distributed random variables at each level .",
    "( the mean of each random variable is a function of their level number in the expansion and the mean of the underlying exponential noise . ) this way , thanks to the expansion technique , we show that continuous alphabet channels can be considered as a set of parallel binary symmetric channels ( bscs ) .    instead of coding for every level in the expansion",
    ", we consider signaling over a finite number of levels , and we resolve the problem arising from carryovers either by considering them as noise , or by decoding them the least significant bit onwards to the most significant bit .",
    "for each case , we state the corresponding achievable rate as an optimization problem , where the rate is maximized over the choices of the bernoulli distributions for the signal transmission over each level with the constraint that that the combined random variables satisfy the channel input constraint .",
    "then , utilizing an approximately optimal input distribution , we show that one can celebrate the achievability of an @xmath0-gap to capacity result in the high snr regime .",
    "this method together with capacity - achieving low - complexity codes ( such as polar coding ) allows one to achieve the capacity of the aen in the high snr regime .    the additive exponential noise ( aen ) channel is of particular interest as it models worst - case noise given a mean and a non - negativity constraint on noise @xcite .",
    "in addition , the aen model naturally arises in non - coherent communication settings , and in optical communication scenarios .",
    "( we refer to @xcite and @xcite for an extensive discussion on the aen channel . )",
    "verd derived the optimal input distribution and the capacity of the aen channel in @xcite .",
    "martinez , on the other hand , proposed the pulse energy modulation scheme , which can be seen as a generalization of amplitude modulation for the gaussian channels . in this scheme ,",
    "the constellation symbols are chosen as @xmath1 , for @xmath2 with a constant @xmath3 , and it is shown that the information rates obtained from this constellation can achieve an energy ( snr ) loss of @xmath4 db ( with the best choice of @xmath5 ) compared to the capacity in the high snr regime . another constellation technique for this coded modulation approach",
    "is recently considered in @xcite , where it is shown that log constellations are designed such that the real line is divided into ( @xmath6 ) equally probable intervals .",
    "@xmath7 of the centroids of these intervals are chosen as constellation points , and , by a numerical computation of the mutual information , it is shown that these constellations can achieve within a @xmath8 db snr gap in the high snr regime .",
    "our approach , which achieves arbitrarily close to the capacity of the channel , outperforms these previously proposed modulation techniques .",
    "the rest of the paper is organized as follows .",
    "the next section describes the aen channel model . in section  [ sec : binexp ] , we present the key lemma which shows that one independent bernoulli distributed random variables occur in the binary expansion of an exponential random variable .",
    "armed with this result , section  [ sec : em ] develops the expansion modulation technique , where we state the main results of the paper .",
    "numerical results are provided in section  [ sec : numres ] , and the paper concludes with a discussion section ( section  [ sec : discuss ] ) .",
    "we consider the additive exponential noise ( aen ) channel given by @xmath9 where @xmath10 are independently and identically distributed according to the additive noise with an exponential density with mean @xmath11 ; i.e. , omitting the index @xmath12 , the noise has the following density : @xmath13 where @xmath14 for @xmath15 and @xmath16 otherwise .",
    "the transmitter conveys one of the messages , @xmath17 , which is uniformly distributed in @xmath18 , i.e. , the random message @xmath19 ; and it does so by mapping the message to the channel input using the encoding function @xmath20 , where @xmath21 , under the constraints that @xmath22 and @xmath23 \\leq e_x,\\ ] ] where @xmath24 is the maximum average energy .",
    "the decoder uses the decoding function @xmath25 to map its channel observations to an estimate of the message .",
    "specifically , @xmath26 , where the estimate is denoted by @xmath27 .    the rate @xmath28 is said to be achievable , if the average probability of error defined by @xmath29 can be made small for large @xmath30 .",
    "the capacity of aen is denoted by @xmath31 , which is the maximum achievable rate @xmath28 .",
    "the capacity of aen is given by @xcite , where @xmath32 where @xmath33 , and the capacity achieving input distribution is given by @xmath34 where @xmath35 if @xmath36 , and @xmath37 otherwise .",
    "note that this is the @xmath38 , where @xmath39 is given by the aen channel .",
    "surprisingly , while the capacity achieving input distribution for the additive white gaussian noise ( awgn ) channel is gaussian , here the optimal input distribution is not exponentially distributed .",
    "however , we observe that in the high snr regime , the optimal distribution gets closer to an exponential distribution with mean @xmath40 .",
    "we show the following lemma , which allows us to have independent bernoulli random variables in the binary expansion of an exponential random variable .    [",
    "lem : exp ] let @xmath41 s be independent bernoulli random variables with parameters given by @xmath42 , i.e. , @xmath43 and @xmath44 , and consider the random variable defined by @xmath45 then , the choice of @xmath46 implies that the random variable @xmath47 is exponentially distributed with mean @xmath48 , i.e. , @xmath49    the proof follows by extending the one given in @xcite .",
    "we show the result by calculating the moment generating function of @xmath47 . using the assumption that @xmath50 are mutually independent",
    ", we have @xmath51          = { \\mbox{\\bb e}}\\left[e^{t\\sum\\limits_{l=-\\infty}^{\\infty}2^l b_l}\\right ]          = \\prod_{l=-\\infty}^{\\infty}{\\mbox{\\bb e}}\\left[e^{t2^l b_l}\\right].\\end{aligned}\\ ] ] note that for any @xmath52 , @xmath53&= & \\frac{e^{t2^l}}{1+e^{\\lambda 2^l}}+\\left(1-\\frac{1}{1+e^{\\lambda 2^l}}\\right ) = \\frac{e^{t 2^l}+e^{\\lambda 2^l}}{1+e^{\\lambda 2^l}}\\nonumber\\\\ & = & \\frac{1+e^{(t-\\lambda ) 2^l}}{1+e^{-\\lambda 2^l}}.\\end{aligned}\\ ] ] then , using the fact that for any constant @xmath54 , @xmath55 we can obtain the following for @xmath56 , @xmath57 & = & \\lim_{n\\rightarrow\\infty}\\prod_{i=0}^{n}\\frac{1+e^{(t-\\lambda ) 2^l}}{1+e^{-\\lambda 2^l}}\\nonumber\\\\ & = & \\frac{1-e^{-\\lambda}}{1-e^{t-\\lambda}}\\nonumber\\\\ & = & \\lim_{n\\rightarrow\\infty}\\frac{1-e^{(t-\\lambda)2^{n+1}}}{1-e^{t-\\lambda}}\\frac{1-e^{-\\lambda } } { 1-e^{-\\lambda2^{n+1}}}\\nonumber\\\\ & = & \\frac{1-e^{-\\lambda}}{1-e^{t-\\lambda}}.\\label{eqn : part1}\\end{aligned}\\ ] ] and , similarly , for the negative part , we have @xmath58 which further implies that @xmath59 & = & \\lim_{n\\rightarrow\\infty}\\frac{1-e^{t-\\lambda}}{1-e^{(t-\\lambda)2^{-n}}}\\frac{1-e^{-\\lambda2^{-n}}}{1-e^{-\\lambda}}\\nonumber\\\\ & = & \\frac{\\lambda(1-e^{t-\\lambda})}{(\\lambda - t)(1-e^{-\\lambda})}. \\label{eqn : part2}\\end{aligned}\\ ] ] thus , finally for any @xmath56 , multiplying equations  [ eqn : part1 ] and  [ eqn : part2 ] , we get @xmath60 the observation that this is the moment generation function for an exponentially distributed random variable with parameter @xmath61 concludes the proof .",
    "our proposed coding scheme consists of coding over expansion , referred to as expansion modulation ( em ) , and coding for the resulting parallel binary symmetric channels ( bscs ) .",
    "more specifically , em refers to a modulation over the binary expansion of the channel over levels ranging from @xmath62 to @xmath63 , i.e. , @xmath64 where the expansions of the signal and noise are given by @xmath65 when we take the limit @xmath66 , the channel given by corresponds to the one given by .",
    "we propose coding over the expansion levels of this channel .",
    "more specifically , the least significant bit channel is given by @xmath67 a capacity achieving bsc code is utilized over this channel with input probability distribution given by @xmath68 .",
    "( for example , the polar coding method  @xcite , allows one to construct capacity achieving codes for the @xmath69 level channel . ) instead of directly using the capacity achieving code design , we use the combination of the capacity achieving code and the method of gallager  @xcite to achieve a rate corresponding to the one obtained by the mutual information @xmath70 evaluated with an input distribution bernoulli with parameter @xmath42.(the desired distributions will be made clear in the following part . )    noting that the sum is a modulo-@xmath71 sum in the above channel , there will be carryovers from this sum to the next level , @xmath72 . denoting the carryover seen at level @xmath73 as @xmath74",
    ", the remaining channels can be represented with with the following @xmath75 where the effective noise , @xmath76 , is a bernoulli random variable obtained by the convolution of the noise and the carryover @xmath77 with @xmath78 and @xmath79 . here , the carry over probability is given by @xmath80    due to lemma  [ lem : exp ] , the noise seen at each level will be described by independent bernoulli random variables , and therefore , our coding scheme will be over the parallel channels given by for @xmath81 , where @xmath82 .      using a capacity achieving code for bscs , combined with the gallager s method , expansion modulation readily achieves the following result .",
    "[ thm:1 ] expansion modulation , when implemented with capacity achieving codes for the resulting bscs , achieves the rate given by @xmath83 for any @xmath84 , where @xmath85 for @xmath86 . to satisfy the energy constraint , @xmath87 $ ]",
    "is chosen such that @xmath88   = \\frac{1}{n } \\sum\\limits_{i=1}^n \\sum\\limits_{l =- l_1}^{l_2 } 2^{l } p_l \\leq e_x.\\ ] ]    the optimization problem stated in the result above is highly non - trivial . however , utilizing the optimal input distribution , ( [ eq : optinput ] ) , one can adopt the following approximate distributions in theorem  [ thm:1 ] . at a high snr , we observe that the optimal input distribution is approximated by an exponential distribution .",
    "then , one can simply choose @xmath42 from the binary expansion of the exponential distribution with mean @xmath40 . to satisfy the power constraint",
    ", we use coding only for @xmath89 of the time , and for the rest we set the channel input to @xmath37 .",
    "( as a second approach , in the numerical results , we compare this choice with the one of choosing @xmath42 from the binary expansion of the exponential distribution with mean @xmath24 . )",
    "the next method gives a better rate result with a minimal increase in complexity .      in the scheme above ,",
    "let us consider decoding starting from the level @xmath69 .",
    "the receiver will obtain the correct @xmath90 for @xmath91 .",
    "as the receiver has the knowledge of @xmath92 for @xmath91 , it will also have the knowledge of the correct noise sequence @xmath93 for @xmath94 . with this knowledge ,",
    "the receiver can directly obtain @xmath95 for @xmath94 , which is the carryover from level @xmath69 to level @xmath72 . using this carryover sequence in decoding at level @xmath72",
    ", the receiver can get rid of carryover noise .",
    "thus , the effective channel that the receiver will see can be represented by @xmath96 for @xmath81 .",
    "we remark that with this decoding strategy the effective channels will no longer be a set of independent parallel channels , as decoding in one level affects the channels at higher levels . however , if the utilized coding method is strong enough ( e.g. , if the error probability decays to @xmath37 exponentially with @xmath30 ) , then this carryover decoding error can be made insignificant by increasing @xmath30 for a given number of levels ( here , @xmath97 ) .",
    "we state the rate resulting from this approach .",
    "[ thm:2 ] expansion modulation , by decoding the carryovers , achieves the rate given by @xmath98 for any @xmath84 , where @xmath87 $ ] is chosen to satisfy @xmath23",
    "= \\frac{1}{n } \\sum\\limits_{i=1}^n \\sum\\limits_{l =- l_1}^{l_2 } 2^{l } p_l \\leq e_x.\\ ] ]    compared to the previous case , the optimization problem is simpler here as the rate expression is simply the sum of the rates obtained from a set of parallel channels .",
    "we now show that the proposed scheme achieves the capacity of aen channel in the high snr regime for a sufficiently high number of levels . towards this end , we provide a bound for the capacity gap , @xmath99 , where @xmath100\\end{aligned}\\ ] ] is the achievable rate given in theorem  [ thm:2 ] with @xmath101 , @xmath102 , and @xmath103 , when the approximate input distribution discussed above ( i.e. , exponential with mean @xmath40 ) is used .",
    "first , we obtain the asymptotic behavior of entropy at each level .",
    "[ lem : entropy ] entropy of the bernoulli random variable at level @xmath73 , @xmath104 , is bounded by @xmath105 where @xmath106 and @xmath107 are both constants taking the values @xmath108 and @xmath109 .",
    "note that , @xmath110 when @xmath111 , we obtain a lower bound as @xmath112 on the other hand , when @xmath113 , by using the facts that @xmath114 for any @xmath115 , and @xmath116 for any @xmath117 , we have @xmath118    , @xmath119 , @xmath120 and rate at each level are shown , where @xmath121 . the coding scheme with @xmath122 covers the significant portion of the rate obtained by using all of the parallel channels . as shown in the text",
    ", @xmath42 is a shifted version of @xmath119 . ]",
    "this lemma tells us that the tails bounds are exponential .",
    "although better bounds may exist , the exponential bound is sufficient for further analysis .",
    "based on the lemma above , we obtain the following .",
    "[ thm : gap ] for any @xmath123 , there exists an @xmath0-dependent constant @xmath124 such that if @xmath125 and @xmath126 , then the capacity gap is bounded by @xmath127 .",
    "( the total number of levels is given by @xmath128 , where @xmath103 . )",
    "we first observe that @xmath129 & = \\sum_{l =- l}^{l+\\gamma } \\left[h(p_l\\otimes q_l)-h(p_l)\\right ] + \\sum_{l =- l}^{l+\\gamma } \\left[h(p_l)-h(q_l)\\right],\\nonumber\\\\ & \\geq\\sum_{l =- l}^{l+\\gamma } \\left[h(p_l)-h(q_l)\\right],\\label{thm : c_r}\\end{aligned}\\ ] ] where the last inequality is due to the fact that @xmath130 .",
    "observing that @xmath131 and adopting lemma  [ lem : entropy ] , we have    1 .",
    "@xmath132 : @xmath133 2 .",
    "@xmath134 : @xmath135+[h(p_{l+\\gamma})-h(q_{l+\\gamma})]= h(p_l)-h(n_{l+\\gamma})$ ] @xmath136 and 3 .",
    "@xmath137 and @xmath138 : @xmath139    combining these pieces together , we will obtain @xmath140 & > \\sum_{l = c}^{\\gamma - c } \\left(1-c_2\\cdot 2^{l-\\gamma}-c_1\\cdot 2^{-l}\\right ) + \\sum_{l =- c+1}^{c-1}\\left(1-c_2\\cdot 2^{l-\\gamma}-c_1\\cdot 2^{-(l+\\gamma)}\\right)\\nonumber\\\\ & > \\gamma -(c_1+c_2)2^{-c}-(c_1+c_2)2^{c-\\gamma-1}\\nonumber\\\\ & > \\gamma-8\\log e\\cdot 2^{-c},\\label{thm : term2}\\end{aligned}\\ ] ] where the last inequality uses the assumption that @xmath125 .",
    "thus , we obtain a bound for the capacity gap    @xmath141 + \\left [ h(p_l)-h(q_l ) \\right]\\bigg\\}\\nonumber\\\\          & \\leq \\gamma-\\left(1 - 2^{-\\gamma}\\right)(\\gamma-8\\log e\\cdot 2^{-c})\\nonumber\\\\          &",
    "< \\gamma 2^{-\\gamma}+8\\log e\\cdot 2^{-c}\\nonumber\\\\          & \\leq2c\\cdot 2^{-2c}+8\\log e\\cdot 2^{-c}\\nonumber\\\\          & < 16\\log e\\cdot 2^{-c } \\nonumber\\\\          & = \\epsilon,\\end{aligned}\\ ] ]    where we used the decreasing property of @xmath142 for @xmath143 , and the assumption that @xmath144 . fig .",
    "[ fig : bitrate ] helps explicate the key steps of the proof .",
    "we calculate the rates obtained from the two schemes above ( @xmath145 in theorem  [ thm:1 ] and @xmath146 in theorem  [ thm:2 ] ) with two different input probability distribution choices ( denoted by @xmath147 and @xmath148 ) :    * @xmath147 : choosing @xmath42 from the binary expansion of the exponential distribution with mean @xmath40 . to satisfy the power constraint , we use coding only for the fraction of the channel uses ( i.e. , @xmath149 of the time ) . * @xmath148 : choosing @xmath42 from the binary expansion of the exponential distribution with mean @xmath24 .",
    "the first choice closely resembles the optimal distribution given in .",
    "however , as the unused channels vanish in the high snr regime , we expect that both choices result in the same rate as snr gets large .",
    "numerical results are given in fig .",
    "[ fig : numres ] .",
    "it is evident from the figure ( and from the analysis given in theorem  [ thm : gap ] ) that the proposed technique , when implemented with sufficiently large number of levels , outperforms the snr gaps previously reported in @xcite and @xcite .    :",
    "the rate obtained by considering carry over as noise . @xmath146 : the rate obtained by decoding carry overs at each level .",
    "@xmath147 : choosing @xmath42 from the binary expansion of the exponential distribution with mean @xmath40 . to satisfy the power constraint ,",
    "only a fraction of the channel uses ( i.e. , @xmath89 of the time ) is utilized .",
    "@xmath148 : choosing @xmath42 from the binary expansion of the exponential distribution with mean @xmath24 .",
    "solid and dotted curves correspond to coding over @xmath150 and @xmath151 number of levels , respectively . ]",
    "we note the followings .",
    "* expansion coding allows the construction of good channel codes for discrete - time continuous channels using good discrete memoryless channel codes . for instance",
    ", one can utilize binary expansion together with polar codes .",
    "the underlying code is @xmath152-ary polar code , as we need to implement gallager s method in constructing the input distribution @xmath153 for coding over level @xmath73 .",
    "( see , e.g. , @xcite for details . ) in addition , expansion modulation can be implemented over a @xmath152-ary expansion of the channel , and any good code for the resulting modulo @xmath152-sum channel can be used . *",
    "avestimehr et al .",
    "@xcite have introduced the deterministic approximation approach for point - to - point and multi - user channels .",
    "the basic idea is to construct an approximate channel for which the transmitted signals are assumed to be noiseless above the noise level . using this high snr approximation ,",
    "one only needs to deal with the interference seen at a particular receiver ( in a networked model ) .",
    "our expansion coding scheme can be seen as a generalization of these deterministic approaches .",
    "here , the ( effective ) noise in the channel is carefully calculated and the system takes advantage of coding over the noisy levels at any snr .",
    "this generalized channel approximation approach can be useful in reducing the large gaps reported in the previous works .",
    "* although our discussion is limited to the aen channel , where the proposed scheme outperforms the previously proposed modulation schemes and performs arbitrarily close to the capacity of the aen channel , the expansion coding refers to a more general framework and is not limited to such channels . towards this end ,",
    "our ongoing efforts are focused on utilizing the proposed scheme for aen multiple - user channels , and for their awgn counterparts .",
    "recall that , in our construction , @xmath119 is the probability that bernoulli random variable takes value 1 at level @xmath73 .",
    "thus , @xmath110 when @xmath111 , we obtain a lower bound as @xmath112 on the other hand , when @xmath113 , by using the facts that @xmath114 for any @xmath115 , and @xmath116 for any @xmath117 , we have @xmath154              e.  arikan , `` channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans . on inf .",
    "theory _ , vol .",
    "55 , no .  7 , pp . 30513073 , jul ."
  ],
  "abstract_text": [
    "<S> a general method of coding over expansions is proposed , which allows one to reduce the highly non - trivial problem of coding over continuous channels to a much simpler discrete ones . </S>",
    "<S> more specifically , the focus is on the additive exponential noise ( aen ) channel , for which the ( binary ) expansion of the ( exponential ) noise random variable is considered . </S>",
    "<S> it is shown that each of the random variables in the expansion corresponds to independent bernoulli random variables . </S>",
    "<S> thus , each of the expansion levels ( of the underlying channel ) corresponds to a binary symmetric channel ( bsc ) , and the coding problem is reduced to coding over these parallel channels while satisfying the channel input constraint . </S>",
    "<S> this optimization formulation is stated as the achievable rate result , for which a specific choice of input distribution is shown to achieve a rate which is arbitrarily close to the channel capacity in the high snr regime . </S>",
    "<S> remarkably , the scheme allows for low - complexity capacity - achieving codes for aen channels , using the codes that are originally designed for bscs . </S>",
    "<S> extensions to different channel models and applications to other coding problems are discussed . </S>"
  ]
}