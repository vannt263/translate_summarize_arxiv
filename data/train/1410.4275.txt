{
  "article_text": [
    "estimating the proportion @xmath0 of true null hypotheses is of considerable importance due to the routine implementation of false discovery rate ( fdr ) control in various scientific endeavors , such as genomics , neuroscience , economics and finance .",
    "the proportion @xmath0 is the key ingredient of many adaptive fdr procedures @xcite , such that a less conservative estimator of @xmath0 tends to make the corresponding fdr procedures more powerful @xcite .",
    "it is also the key component of the two - groups models and local fdr @xcite and the positive fdr and q - value @xcite , such that an accurate estimate of @xmath0 is needed to determine the two - groups models and that a more accurate estimate of @xmath0 leads to more accurate estimates of the local fdr , fdr or q - value of the corresponding fdr procedures .    equally important",
    "is the dual quantity , @xmath1 , the proportion of false nulls , and an accurate estimate of @xmath2 induces an accurate estimate of @xmath0 .",
    "most existing estimators of @xmath0 or @xmath2 , including those in @xcite , were developed under the assumption that the p - values or test statistics are weakly dependent .",
    "however , p - values and test statistics derived from high - dimensional data can be strongly dependent ( see examples in @xcite ) , and none of these estimators have been shown to be consistent under strong dependence .    motivated by multiple testing for marginal regression analysis for dependent high - dimensional data , we consider estimating the proportion of components of a normal random vector that have nonzero means . more specifically ,",
    "suppose the vector @xmath3 is normally distributed with mean vector @xmath4 and a known correlation matrix @xmath5 representing certain types of strong dependence .",
    "consider simultaneously testing the null hypothesis @xmath6 for @xmath7 .",
    "we will construct a consistent estimator of the proportion of nonzero normal means , @xmath8when the correlation matrix @xmath5 encodes strong covariance dependence and has a few dominant eigenvalues .",
    "the new estimator provides a partial but positive answer to the quest suggested by @xcite on consistently estimating the proportion of nonzero normal means under arbitrary covariance dependence .",
    "it is perhaps the first among estimators of this proportion that has theoretically ensured consistency under strong dependence .",
    "two by - products of developing the new estimator are an extension to more general settings of the fourier transform method to estimate @xmath2 in @xcite and an alternative method to estimate the ( principal ) factors in order to adjust for dependence in multiple testing ; see details in and .",
    "the rest of the article is organized as follows .",
    "the motivation for the setup of the problem is given in , and an application of the new estimator to multiple testing in an association study based on brain imaging data is provided in .",
    "we develop the consistent estimator of @xmath2 in and present simulation studies on it in .",
    "we end the article with a discussion in .",
    "this article has supplementary material .",
    "the setup for multiple testing which components of a normal random vector have zero means when their correlation matrix is known is motivated by multiple testing for marginal regression analysis for dependent high - dimensional data ; see @xcite , @xcite and @xcite for examples of such analyses in gene expression studies , genome wide association studies and brain imaging analysis , respectively . in these studies ,",
    "the aim is to identify covariates that are associated with the response variable when there are many candidate covariates while maintaining the fdr at a target level . to this end",
    ", the response variable is regressed on each covariate to produce an estimated regression coefficient .",
    "then multiple testing is conducted to assess which regression coefficients are nonzero statistically , and conclusions are drawn on which covariates are associated with the response variable .    to formally state the above procedure ,",
    "let @xmath9 be the response variable and @xmath10 be the covariates .",
    "the @xmath11th null hypothesis @xmath12 is  no association between @xmath9 and @xmath13 \" , and the multiple testing problem is to simultaneously assess the null hypotheses @xmath14 .",
    "let @xmath15 be a sample of @xmath9 and @xmath16 be a sample of @xmath13 for each @xmath11 , where @xmath17 usually holds . for each @xmath11 ,",
    "the marginal regression model @xmath18 is used , where @xmath19 s are i.i.d . with mean @xmath20 and standard deviation @xmath21 .",
    "this converts testing @xmath12 to testing if @xmath22 .",
    "let @xmath23 be the least squares estimate of @xmath24 , @xmath25 be the sample standard deviation of @xmath26 , and @xmath27 then , when @xmath28 is not very small , each @xmath29 will be approximately normally distributed with mean @xmath30 and standard deviation @xmath31 . when @xmath19 s are normally distributed , @xmath32 , conditioning on all @xmath33 s , is normally distributed with mean vector @xmath34 and covariance matrix @xmath35 note that @xmath36 is a correlation matrix since @xmath29 s have standard deviation @xmath31",
    ".    now testing if @xmath22 is equivalent to testing @xmath6 using @xmath37 , i.e. , assessing if an @xmath13 is associated with @xmath9 is converted to testing @xmath6 . in other words",
    ", we are testing which components of the normal random vector @xmath37 have zero means . to control the fdr or estimate the local fdr or q - value",
    "when simultaneously testing @xmath6 for @xmath7 , the proportion of nonzero normal means @xmath2 defined in , i.e. , @xmath38 needs to be estimated accurately .",
    "we would like to emphasize that the population covariance matrix of @xmath3 is the correlation matrix @xmath36 and that @xmath36 is known based on the sample @xmath33 for @xmath39 and @xmath40 when @xmath21 is known . in practice ,",
    "@xmath41 can be estimated by @xmath42 when @xmath43 , where @xmath44 and @xmath45 . since @xmath46 is usually large , the variability of @xmath47",
    "can be ignored so that @xmath47 can be taken as @xmath41 .",
    "if we set @xmath48 with @xmath49 , then @xmath50 can be regarded as having the same distribution as @xmath37 .",
    "correspondingly , we are back to testing which components of the normal random vector @xmath50 have nonzero means with a known correlation matrix @xmath36 .",
    "as an application , we apply the new estimator to estimate the proportion of nonzero normal means after marginal regression analysis has been applied to a high - dimensional data set .",
    "the data set was obtained from brain imaging in a study of the cortical thickness of adults who had a diagnosis of attention deficit / hyperactivity disorder ( adhd ) as children @xcite .",
    "the data set contains cortical thickness measurements for around @xmath51 cortical voxels and behavioral measurements for each of the @xmath52 individuals . here",
    "we would like to identify voxels that may affect the overall behavior of an individual by assessing the association between the cortical thickness of each voxel to a global assessment of behavior .",
    "namely , the response variable is the global assessment of behavior and the covariates are the voxel - wise cortical thicknesses .",
    "eigenvalues of the correlation matrix , for which the largest eigenvalue dominates.,scaledwidth=85.0% ]    the marginal regression analysis described in is applied to the data set . to ensure the normality assumption in each marginal regression model",
    "is not seriously violated , we apply the shapiro test to assess the normality of the residuals for each marginal regression and select @xmath29 s for which the shapiro test has p - value @xmath53 . among these @xmath29 s",
    ", we further select those whose absolute values are @xmath54 and whose correlation matrix @xmath36 is approximately structured ; see panels ( b ) , ( c ) and ( d ) of .",
    "this gives @xmath55 test statistics @xmath29 , whose histogram is shown in panel ( a ) of . coincidentally , the minimal absolute value of these @xmath29 s is @xmath56 .",
    "however , the correlations between a large proportion of @xmath29 s are fairly strong ; see panel ( b ) of .    our new estimator @xmath57 of the proportion @xmath2 of nonzero normal means is @xmath58 for these @xmath29 s , i.e. , the proportion @xmath59 of zero normal means is @xmath60 .",
    "thus , only a few voxels are correlated with the global assessment of behavior by their cortical thicknesses .",
    "this is consistent with the finding in @xcite that in this data set correlations may cause the impression of many true associations .",
    "however , the estimators in @xcite , @xcite and @xcite estimate @xmath0 to be @xmath61 , @xmath20 and @xmath62 respectively , which are all misleading .    on the other hand , @xmath2 being estimated to be @xmath58 by our estimator suggests that almost all @xmath29 s under consideration have mean @xmath20 .",
    "consequently , the empirical density of these @xmath29 s may be approximated by the random function developed in @xcite .",
    "we applied their random function with @xmath63 latent variables , which seems to give the best approximation among choices of different numbers of latent variables ; see the blue curve in panel ( a ) of .",
    "it can be seen that the approximation is good .",
    "this is consistent with our estimate of @xmath2 being @xmath58 .",
    "however , the use of @xmath63 latent variables by the random function in the approximation reflects the fact that there are a few voxels that are associated with the global assessment of behavior and that the correlations among the test statistics @xmath29 can not be fully accounted for by few latent variables or principal factors ; see panel ( b ) of .",
    "our strategy to develop the consistent estimator of @xmath64 is explained as follows .",
    "first , we utilize the _ principal factor approximation _ ( pfa ) developed in @xcite to decompose @xmath3 into two independent normal random vectors , such that the major vector contributes",
    "the major part of the covariance dependence between the components of @xmath3 and the minor vector consists of `` weakly dependent '' ( to be specified in ) random variables .",
    "we then estimate the major vector . to do this ,",
    "we establish two properties of a type of _ concave partially penalized least squares _ ( cppls ) estimate when the involved normal random errors have heterogenous variances and are weakly dependent and when there are incidental parameters .",
    "finally , we extend the _ fourier transform method _ ( ftm ) to estimate @xmath64 in @xcite to the case of weakly dependent normal random errors with heterogeneous variances , and apply the extended ftm to components of the mean - shifted , estimated minor vector to estimate @xmath64 consistently .    before presenting the theory ,",
    "we introduce some conventions and notations .",
    "we take the convention that a vector is always a column vector , and use @xmath65 to denote that @xmath66 is an @xmath67-dimensional normally distributed random vector with mean vector @xmath68 and covariance matrix @xmath69 .",
    "further , for two sequences @xmath70 and @xmath71 , the  big o \" notation @xmath72 means that @xmath73 for some constant @xmath74 for sufficiently large @xmath67 ; for two positive sequences @xmath70 and @xmath71 , the  small o \" notation @xmath75 means that @xmath76 .",
    "finally , @xmath77 denotes the probability measure and @xmath78 the expectation with respect to @xmath77 .",
    "recall that @xmath3 is an @xmath67-dimensional normal vector with mean @xmath4 and a known correlation matrix @xmath5 .",
    "let the spectral decomposition of @xmath5 have eigenvalues @xmath79 and corresponding orthonormal eigenvectors @xmath80 , @xmath81 .",
    "it is easy to verify that for a fixed @xmath82 there exists @xmath83 between @xmath20 and @xmath84 ( @xmath83 is dependent on @xmath67 ) such that @xmath85    assume @xmath67 is large and pick @xmath83 such that holds .",
    "let @xmath86 , @xmath87 , @xmath88 and @xmath89 , where @xmath90 is the identity matrix .",
    "then we have @xmath91 or equivalently @xmath92 upon setting @xmath93 . clearly , @xmath94 is independent of @xmath95 , and both are @xmath67-dimensional normal random vectors .",
    "components of @xmath96 are called the `` principal factors '' in @xcite .",
    "let @xmath97 be the covariance matrix of @xmath95 .",
    "since @xmath83 has been chosen such that holds , we see @xmath98 where @xmath99 denotes the frobenius norm of a matrix . in this case , components of @xmath95 are called `` weakly dependent '' by @xcite . in view of this",
    ", we call @xmath94 and @xmath95 the `` major '' and `` minor '' vectors , respectively . to summarize , using the pfa we have decomposed @xmath3 into the sum of the major and minor vectors , such that the minor vector contains weakly dependent entries with heterogeneous variances .",
    "let @xmath100 be the variance of the @xmath11th entry @xmath101 of the major vector @xmath102 and @xmath103 ( with @xmath104 ) .",
    "then each @xmath105 is the reciprocal of the standard deviation of the @xmath11th entry @xmath106 of the minor vector @xmath107 . the important quantity @xmath108 measures the speed of pfa , in that larger @xmath109 indicates faster pfa .",
    "note that @xmath109 tends to be large when @xmath110 has a few dominant eigenvalues .",
    "now we turn to estimating the major vector @xmath111 .",
    "since the mean vector @xmath112 contains a proportion @xmath0 of zero entries and is usually sparse , we estimate @xmath111 by taking @xmath112 as the incidental parameter .",
    "specifically , we consider the following estimate @xmath113 of @xmath114 , where @xmath115and @xmath116 denotes the set of local minimizers . in , the univariate function @xmath117 is the _ minimax concave penalty _ ( mcp ) in @xcite with tuning parameter @xmath118 .",
    "specifically , @xmath119 is defined by its derivative as @xmath120 with a second tuning parameter @xmath121 , where @xmath122 .",
    "since the components of @xmath95 in model ( [ eqb103 ] ) are _ weakly dependent and have heterogeneous variances _ ( wdh ) , @xmath123 is concave , and in ( [ 5.1 ] ) only @xmath124 but not @xmath125 is penalized , we call ( [ eqb107 ] ) a cppls with normal errors that are wdh",
    ". this is different than the settings of most penalized linear regression methods where the random errors have identical variances and there are no incidental parameters .",
    "we point out that penalizing @xmath124 in is to exploit the sparsity of @xmath126 so that a more accurate estimate of @xmath111 can be obtained and that a local minimizer @xmath127 in is sufficient to construct the consistent estimator of @xmath2 ; see and .",
    "when we implement our consistent estimator of @xmath2 , we will directly obtain an estimate of the principal factors @xmath128 by an alternating optimization technique from the equivalent formulation of and ; see for details .",
    "let @xmath129 where we recall @xmath130 is the maximum of the standard deviations of the @xmath106 s .",
    "the quantity @xmath131 is roughly the maximum of the @xmath67 entries @xmath106 of the minor vector @xmath132 .",
    "we now show the existence of a solution to ( [ 5.1 ] ) such that @xmath133 has the needed property ( but not having to be consistent ) for the extended ftm to estimate @xmath64 later in and .",
    "[ thmasympexpanconsist ] choose @xmath83 such that holds .",
    "if @xmath134 is finite , @xmath135 and @xmath136 for some @xmath137 , then , with probability approaching to @xmath31 as @xmath138 , there exists an estimate @xmath133 of @xmath94 from ( [ 5.1 ] ) such that @xmath139 .    since @xmath140 , allows us to construct an estimate @xmath141 of @xmath96 such that @xmath142 and @xmath143 .",
    "however , does not say that @xmath144 is consistent since only @xmath139 for some @xmath137 is needed .",
    "we briefly comment on the conditions involved in .",
    "the requirement that @xmath145 is finite and @xmath135 for some @xmath137 means that the magnitude of the largest nonzero normal mean does not have to large but it should not decrease to zero very rapidly as @xmath138 .",
    "this requirement is easily satisfied .",
    "the condition @xmath136 for some @xmath137 means that the maximal noise level induced by entries @xmath106 of the minor vector @xmath107 should decrease to zero at appropriate speed as @xmath138 .",
    "this can be achieved when @xmath110 has a few large eigenvalues of magnitude @xmath146 or a few dominant eigenvalues ; see the types of covariance dependence and @xmath110 in .      once we are able to control the difference between the estimate @xmath133 of the major vector @xmath94 ( see ) , it is possible to estimate @xmath2 from the mean - shifted , estimated minor vector @xmath147 where @xmath148 is given in . the superior performance of the fourier transform ( ft ) based estimator of @xmath2 in @xcite relies crucially on the assumption that the normal random vector has independent or strongly mixing components and that components with zero means have the same variance . however , noticing that @xmath149 , @xmath81 in model ( [ eqb103 ] ) are weakly dependent ( which is different than being strongly mixing ) and have heterogeneous null distributions ( i.e. , potentially with different variances @xmath150 even if their means are zero ) , we need to extend the ft - based estimator so that it can applied to @xmath151 in .",
    "let @xmath152 for @xmath153 .",
    "define@xmath154 } \\omega \\left ( \\zeta \\right ) \\exp\\left(2^{-1}\\left ( t\\zeta \\sigma \\right ) ^{2}\\right)\\cos \\left ( t\\zeta x\\right ) d\\zeta \\text { , }   \\label{eqb14}\\]]and@xmath155 } \\exp\\left(\\sqrt{-1}t\\mu \\zeta \\right)\\omega \\left ( \\zeta \\right ) d\\zeta   \\label{eqb41}\\]]for some @xmath156 that is bounded on @xmath157 $ ] , symmetric around @xmath20 and lebesgue integrates to @xmath31 .",
    "we have @xmath158 = \\psi \\left ( t;\\mu \\right ) = \\hat{\\omega}\\left ( t\\mu \\right ) $ ] when @xmath159 , where @xmath160 denotes the fourier transform of a lebesgue integrable function @xmath161 on @xmath162 .",
    "obviously , @xmath163 and @xmath164 = \\left ( \\kappa _ { 1}\\left ( t;\\cdot \\right ) \\ast \\phi _ { 0,1}\\right ) \\left ( \\mu \\right ) = \\psi \\left ( t;\\mu \\right ) = { \\mathbb}{e}\\left [ \\kappa _ { \\sigma } \\left ( t;x\\right ) \\right ] = \\left ( \\kappa _ { \\sigma } \\left ( t;\\cdot \\right ) \\ast \\phi _ { 0,\\sigma } \\right ) \\left ( \\mu \\right ) \\text{,}\\]]where @xmath165 denotes the convolution .",
    "further , lemma 7.1 in @xcite holds for the pair of functions in ( [ eqb14 ] ) and ( [ eqb41 ] ) .",
    "let @xmath166 and @xmath167",
    ". then @xmath168 . following @xcite",
    ", we define the underlying phase function@xmath169 \\label{eqd1}\\]]and empirical phase function @xmath170 \\text{. }   \\label{eqd2}\\]]we remark that @xmath171 and @xmath172 generalize corresponding functions in @xcite by allowing for heterogeneous variance @xmath173 for each @xmath174 since there @xmath175 has been used .",
    "the performance of the ft - based estimator hinges upon how accurately @xmath176 approximates @xmath177 , the oracle that knows the true value @xmath64 .",
    "specifically , the smaller @xmath178 is , the more accurately @xmath179 estimates @xmath64 .",
    "so , we first need to bound @xmath180 . on the other hand , @xmath181 is unknown and estimated by @xmath151 in ( [ eqb108 ] ) .",
    "therefore , we also need to bound @xmath182 . through bounds on both @xmath183 and @xmath184",
    ", we will be able develop an ft - based estimator under the settings of our model ( [ eqb103 ] ) .",
    "in fact , we have the following :    [ lmbounddiffphasefuncwtumix]choose @xmath83 such that holds .",
    "then , for any @xmath185 , with probability at least @xmath186,@xmath187where @xmath188for some finite constant @xmath189",
    ". in particular , when @xmath190 , @xmath191almost surely for any @xmath192 .",
    "bounds @xmath183 when the random errors , i.e. , @xmath193 s , have heterogeneous variances and are weakly dependent .",
    "therefore , it generalizes the bound on @xmath194 in @xcite and @xcite , and we have extended the ft - based estimator to weakly dependent normal random errors with heterogeneous variances .",
    "the proof of uses a different technique than that in @xcite .    with regard to the conditions used in",
    ", we have the following remarks : inequality is always achievable by choosing a suitable @xmath83 as we have pointed out earlier right after ; the requirement @xmath195 means that the maximal standard deviation @xmath196 of the @xmath106 s should decrease to zero faster than @xmath197 , which is achievable when @xmath110 has a few dominant eigenvalues ; see the types of covariance dependence and @xmath110 in .",
    "we are ready to introduce the new , consistent estimator of the proportion @xmath2 of nonzero normal means .",
    "when the difference @xmath198 ( see ) , the overall speed @xmath109 of pfa , and the property of the nonzero @xmath199 s are compatible with each other , the lipschitz property of @xmath200 ( defined by ) will imply that @xmath201    \\label{eqb109}\\ ] ] converges to @xmath179 in probability . in other words ,",
    "the plug - in estimator @xmath202 will consistently estimate @xmath64 .",
    "[ thmconsistplugest]let @xmath203 .",
    "choose @xmath83 such that holds and let @xmath204 be independent of @xmath205 . if the assumptions of hold with @xmath206 , and @xmath207 , then @xmath208 with @xmath151 in ( [ eqb108 ] ) and any @xmath192 consistently estimates @xmath209 as @xmath138 .    provides a consistent estimator @xmath57 of @xmath2 when the correlation matrix @xmath110 encodes strong dependence but has a few dominant eigenvalues .",
    "it induces a consistent estimator of @xmath210 as @xmath211 . and",
    "show that the consistency of the new estimator @xmath57 does not require that of estimating the major vector @xmath111 , the principal factors @xmath128 , or the mean vector @xmath112 .",
    "they also show that , due to the needed speed for the pfa to control the dependence among the entries of the minor vector , the new estimator @xmath57 may not be consistent for @xmath2 when @xmath3 has an arbitrary pair of mean vector @xmath126 and correlation matrix @xmath36 .",
    "we briefly discuss the conditions involved in , which contain those used in .",
    "the conditions in are used to obtain an estimate @xmath144 of @xmath102 such that @xmath139 for some @xmath212 , so that we can apply the extended ftm to the entries of @xmath213 to estimate @xmath2 .",
    "they are satisfied when @xmath110 has a few eigenvalues of magnitude @xmath146 or a few dominant eigenvalues as discussed right after ; see the types of covariance dependence and @xmath110 in .",
    "the condition @xmath207 simply requires the minimal magnitude of the nonzero normal means not to be extremely small .",
    "this condition is easily satisfied and was also used in @xcite and @xcite , and it is compatible with the conditions in .",
    "finally , the scale of the frequency domain is set as @xmath214 for the empirical phase function @xmath215 in as done also in @xcite , so that the convergence rate of @xmath215 compensates the oscillations induced by the noise variables @xmath106 and @xmath208 can consistently estimate @xmath2 for any @xmath216 .",
    "this property of @xmath57 allows to pick any scale from the family @xmath217 for the frequency domain in order to consistently estimate @xmath2 .      in this section",
    ", we present the implementation of @xmath202 .",
    "pfa is easily implemented by the spectral decomposition of the correlation matrix @xmath36 and then choosing@xmath218with some @xmath219 .",
    "we set @xmath220 for the simulations in and the application in . after setting up the pfa",
    ", we then implement the cppls using the mcp in ( [ 9 ] ) with @xmath221 ( see @xcite for the rationale on choosing @xmath221 ) .",
    "specifically , we solve the equivalent problem @xmath222 with @xmath223 via alternating optimization ( e.g. , @xcite ) through the following steps :    1 .",
    "set @xmath224 and initialize @xmath225 .",
    "2 .   use the package of @xcite to compute the solution path of @xmath226 for @xmath227 , a grid of descendingly ordered @xmath228 values automatically set by , where @xmath229 has been indexed by @xmath230 @xmath231 .",
    "pick @xmath232 , @xmath233 for which @xmath234 3 .",
    "compute @xmath235 , where @xmath236 , @xmath237 , and @xmath238 is the observation from @xmath3 .",
    "note that the @xmath239 s are the eigenvalues of @xmath110 and @xmath240 s are their corresponding eigenvectors .",
    "4 .   set @xmath241 to be @xmath242 .",
    "repeat steps 2 . and 3 .",
    "until @xmath243 with @xmath244 , where @xmath245 .",
    "suppose a local minimizer @xmath246 has been found , we compute @xmath247 as in ( [ eqb108 ] ) .",
    "to implement the last step , i.e. , the fourier transform in ( [ eqb109 ] ) , for @xmath57 , we use the triangular density @xmath248 and modify the codes of @xcite to accommodate ( [ eqd1 ] ) and ( [ eqd2 ] ) since the standard deviations @xmath249 of the @xmath250 s are not equal to each other and @xmath250 s are weakly dependent .",
    "the modified codes are then applied to the components of @xmath251 to estimate @xmath64 .",
    "we first describe the estimators of @xmath2 to be compared and then present the simulation studies . by the duality between @xmath64 and @xmath252 , we will transform an estimator @xmath253 of @xmath254 into @xmath255 , and compare the new estimator @xmath57 with @xmath256 with the median based estimator @xmath257 + 1\\right ) \\left [ m\\left ( 1-p_{\\left ( \\left [ m/2\\right ] \\right ) } \\right ) \\right ] ^{-1}\\ ] ] in @xcite , @xmath258 with @xmath259 in @xcite , and @xmath260 with @xmath261 ( also called `` slim '' ) in @xcite .",
    "it should be noted that @xmath262 was claimed by its developers to be robust to dependence . since the estimators @xmath263 , @xmath264 and @xmath262 are based on p - values , we will convert each observed normal random variable @xmath265 into @xmath266 and apply each of these estimators to the @xmath67 p - values to estimate @xmath2 , where @xmath267 is the cumulative distribution function of the standard normal random variable @xmath268 .",
    "we will choose @xmath269 values of @xmath2 , and for each value of @xmath2 simulate @xmath269 types of covariance dependence and @xmath269 levels of minimal signal strength .",
    "set @xmath270 . for each @xmath271 and @xmath272 , execute the following :    step 1 .",
    ": :    set @xmath273 and    @xmath274 . for the mean vector    @xmath275 ,",
    "set @xmath276 for    @xmath277 but generate    @xmath278 for    @xmath279 independently from the uniform    distribution on    @xmath280 $ ] .",
    "the signs of    @xmath281 for @xmath279 are    generated from @xmath282 independent bernoulli random    variables each taking values @xmath283 with equal    probability .",
    "step 2 . : :    generate @xmath284 whose entries are    @xmath285 i.i.d",
    ". realizations of the standard normal random    variable .",
    ": :    pick one of the @xmath269 types of covariance dependence :    +    * block : set @xmath286 for    @xmath287 but    @xmath288 with    @xmath289  for @xmath290 .",
    "the    corresponding correlation matrix @xmath110    is not block diagonal but has three blocks of size @xmath291    of dependent @xmath292 s , one in the upper right , the    other the lower left , and the third the lower right , where some    correlations are strong .    *",
    "equal correlation (  equal corr . \" ) : set    @xmath293 with @xmath294 and    generate    @xmath295 ,    where @xmath296 is a column vector of    @xmath31 s .    * three factors (  3    factors \" ) :  @xmath297    for @xmath298 .",
    "the correlation between    @xmath299 and @xmath300 for    @xmath301 is    @xmath302 , i.e. , the    @xmath299 s are equally correlated but the equal    correlations are generated by @xmath303 factors    @xmath304 , @xmath305 and    @xmath306 .    * two components (  two comp . \" ) : set    @xmath307 , @xmath308 for    @xmath309 .",
    "the correlation between @xmath310 and    @xmath299 for @xmath311 is    @xmath312 , and that between @xmath299    and @xmath300 for @xmath313 and    @xmath301 is @xmath314 .",
    "the corresponding    correlation matrix @xmath110 has two    components , one for equal correlation @xmath312 and the    other for equal correlation @xmath314 .    *",
    "unstructured : generate a @xmath315 matrix    @xmath316 of i.i.d .",
    "observations from the standard    normal random variable , compute the sample correlation matrix    @xmath317 of @xmath316 , and set    @xmath318 .",
    "there is no structure for the correlations among the    @xmath319 s when they have correlation matrix    @xmath36 .",
    ": :    set    @xmath320 and    @xmath321 , for    which @xmath3 has correlation matrix    @xmath36 ; generate an observation    @xmath238 from @xmath3 and apply each    of the four estimators @xmath57 ,    @xmath263 , @xmath264 and    @xmath262 to estimate @xmath2 based on    @xmath238 .",
    ": :    repeat steps 1 . to 4 .",
    "@xmath291 times .",
    "we refer to  block \" ,  equal correlation \" ,  three factors \" and  two components \" as  structured covariance dependence \" .",
    "each of the three types of dependence ,  equal correlation \" ,  three factors \" and  two components \" , represents long range dependence which is neither weak dependence nor strong mixing .",
    "so , these are types of strong but structured covariance dependence for components of a normal random vector .",
    "unstructured \" dependence can induce long range dependence too . for each of the structured covariance dependence",
    ", the corresponding @xmath36 has one dominant eigenvalue ; see for the @xmath322 largest eigenvalues for each type of @xmath36 .",
    "largest eigenvalues of the correlation matrix @xmath36 for each type of dependence .",
    "for each structured covariance dependence , the corresponding correlation matrix @xmath110 has one dominant eigenvalue , whereas for  unstructured \" covariance dependence @xmath110 has @xmath323 dominant eigenvalues.,scaledwidth=95.0% ]      an estimator @xmath324 of the proportion @xmath2 of nonzero normal means is said to be better if it is no larger than @xmath2 ( in order to maintain conservative fdr control or estimation ) and has smaller bias and standard deviation ( i.e. , is more accurate and stable ) . recall that @xmath325 is the minimum of the absolute values of the nonzero means , i.e. , the minimal signal strength .",
    "for @xmath326 , visualizes the performances of the estimators of @xmath64 and records the biases and _ sample standard deviations _ ( std dev ) of these estimators .",
    "they show that the new estimator @xmath57 is the best for structured covariance dependence .",
    "results for @xmath327 are given in the supplementary material .",
    "we omit reporting the performance of @xmath264 since it is always close to @xmath31 .    for structured covariance dependence ,",
    "the following are observed : ( i ) the new estimator @xmath57 is the best when the minimal signal strength is relatively large ; ( ii ) it is also the best when @xmath328 regardless of the minimal signal strength ; ( iii ) it always has the smallest variance . for unstructured covariance dependence , the following are observed : ( i ) the new estimator tends to be more accurate as the minimal signal strength becomes smaller when @xmath2 is not large ; ( ii ) it is the best when the minimal signal strength is small and @xmath329 ; ( iii ) it is the best when all combinations of values of @xmath2 and the minimal signal strength are considered ; see and the figures in the supplementary material .",
    "these observations suggest that the new estimator can be safely applied to estimate @xmath2 in applications where our problem setup is appropriate ( see the examples in and ) , the proportion of nonzero normal means @xmath329 , and the correlation matrix of the test statistics is approximately structured with a few dominating eigenvalues .",
    "finally , the slim estimator @xmath262 and the median based estimator @xmath263 usually have relatively large variance when the covariance dependence is  equal correlation \" or  two components \" . for structured covariance dependence , when @xmath330 but @xmath331 , i.e. , when the signals are dense and relatively weak , the median based estimator @xmath263 is more accurate than the new estimator .",
    "this is likely because in this case more information on the distribution of nonzero normal means is available to @xmath263 .",
    "for unstructured covariance dependence , when @xmath332 but @xmath329 , the slim estimator @xmath262 is slightly more accurate than the new estimator ; see and the tables in the supplementary material .",
    "this is likely because in this case the slim estimator better utilizes the cumulative distribution function ( cdf ) of the p - values since it is based on the quantiles of local estimates of @xmath2 obtained from different parts of such a cdf .",
    "of an estimator @xmath324 of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath333 , where the dashed line marks @xmath334 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive excess and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best . ]",
    ".bias and sample standard deviation ( std dev ) of estimators of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath333 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive bias and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best . [",
    "cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "for multiple testing which components of a normal random vector have zero means , we have developed a consistent estimator of the proportion of nonzero normal means when the components can be strongly dependent and their correlation matrix has a few dominating eigenvalues .",
    "the new estimator is accurate and stable .",
    "it can be applied to multiple testing related to marginal regression analysis for high - dimensional data where the random errors are normally distributed .    in order to develop this estimator ,",
    "we have established the existence and property of a concave partially penalized least squares ( cppls ) estimate with weakly dependent , heterogenous normal random errors in the presence of incidental parameters .",
    "we have also extended the fourier transform method to estimate this proportion in @xcite to the case of weakly dependent normal random errors that have heterogeneous variances .",
    "our results on the cppls estimate of the principal factors can be strengthened to provide an alternative to several strategies for adjusting for dependence in multiple testing .",
    "these include the method in @xcite to estimate the factors by the expectation - maximization ( em ) algorithm @xcite , that in @xcite to estimate the principal factors by @xmath335-regression under the assumption @xmath336 , and that in @xcite to estimate the shared variation by ridge - type shrinkage .",
    "our extension of the ftm of @xcite is nontrivial since the normal random errors have heterogenous variances and are weakly dependent .",
    "accordingly , we have used a general technique to derive the bounds on the difference between the phase function and its estimate .",
    "we point out that it may still be possible to consistently estimate the proportion of nonzero normal means when the correlation matrix of the normal random vector is unknown but not accurately estimated .",
    "note that @xmath2 is invariant under any permutation of the indices of the means that keeps @xmath2 unchanged and that it is invariant under nonzero scaling of the means . since a permutation corresponds to an orthogonal matrix and a nonzero scaling to a nonsingular diagonal matrix ,",
    "the two invariant properties of @xmath2 imply that the estimation of @xmath2 is quite robust to the inaccuracy in estimating the factors ( or major vector ) , the means and the correlation / covariance matrix .",
    "we leave the exploration along this line to future research .",
    "we provide the proofs of , , and , and additional simulation results for the new estimator under different minimal signal strengths of the nonzero normal means .",
    "this research was funded in part by a national science foundation plant genome research program grant ( no .",
    "ios-1025976 ) to r.w .",
    "doerge , and it produced the technical report @xcite .",
    "the authors would like to thank philip t. reiss and armin schwartzman for providing the brain imaging data set and @xmath337 codes used for the analysis in @xcite , jiashun jin for providing the technical report @xcite , jianqing fan for helpful pointers , and runlong tang for sharing the manuscript @xcite .",
    "xx    , d.  schwartzman , a. 2015 .",
    "the empirical distribution of a large number of correlated normal variables , _",
    "assoc . _ * 110*(511 ) :  12171228 .    , y. , krieger , a.  m.  yekutieli , d. 2006 .",
    "adaptive linear step - up procedures that control the false discovery rate , _ biometrika _ * 93*(3 ) :  491507 .    ,",
    "y.  yekutieli , d. 2001 . the control of the false discovery rate in mutliple testing under dependency , _ ann .",
    "_ * 29*(4 ) :  11651188 .    , j.  c.  hathaway , r.  j. 2002 .",
    "some notes on alternating optimization , _ lecture notes in computer science _",
    ".  187195 .    , g.  roquain , e. 2009 .",
    "adaptive false discovery rate control under independence and dependence , _ j. mach .",
    "* 10 * :  28372871 .",
    ", x.  doerge , r. 2012 . estimating the proportion of nonzero normal means under certain strong covariance dependence , _ technical report .",
    "department of statistics , purdue university , west lafayette _ .",
    ", a.  p. , laird , n.  m.  rubin , d.  b. 1977 .",
    "maximum likelihood from incomplete data via the em algorithm , _",
    "j. r. statist .",
    "b _ * 39*(1 ) :  138 .    ,",
    "k.  h.  storey , j.  d. 2012 .",
    "cross - dimensional inference of dependent high - dimensional data , _",
    "assoc . _ * 107*(497 ) :  135151 .    , b. , tibshirani , r. , storey , j.  d.  tusher , v. 2001 .",
    "empirical bayes analysis of a microarray experiment , _",
    "assoc . _ * 96*(456 ) :  11511160 .    ,",
    "j. , han , x.  gu , w. 2012 . estimating false discovery proportion under arbitrary covariance dependence , _",
    "assoc . _ * 107*(499 ) :  10191035 .",
    ", j. , tang , r.  shi , x. 2012 .",
    "partial consistency with sparse incidental parameters , _ arxiv.org/pdf/1210.6950 _ .",
    ", c. , kloareg , m.  causeur , d. 2009 .",
    "a factor model approach to multiple testing under dependence , _",
    "_ * 104*(488 ) :  14061415 .    , j. 2006 .",
    "propotions of nonzero normal means : universal oracle equivalence and uniformly consistent estimations , _ technical report .",
    "department of statistics , purdue university , west lafayette _ .    , j. 2008 .",
    "proportion of non - zero normal means : universal oracle equivalences and uniformly consistent estimators , _ j. r. statist .",
    "b _ * 70*(3 ) :  461493 .    ,",
    "j.  cai , t.  t. 2007 . estimating the null and the proportion of nonnull effects in large - scale multiple comparisons , _",
    "assoc . _ * 102*(478 ) :  495506 .",
    ", l.  yakovlev , a. 2007 .",
    "diverse correlation structures in gene expression data and their utility in improving statistical inference , _ ann .",
    "_ * 1*(2 ) :  538559 .    , m. , henery , l.  b.  ferkingstad , e. 2005 . estimating the proportion of true null hypotheses , with application to dna microarray data ,",
    "_ j. r. statist .",
    "b _ * 67*(4 ) :  555572 .    ,",
    "j.  t.  storey , j.  d. 2008 . a general framework for multiple testing dependence , _ proc .",
    "natl . acad .",
    "_ * 105*(48 ) :  1871818723 .    , r. 1988 .",
    "strong laws of large numbers for weakly correlated random variables , _ the michigan mathematical journal _ * 35 * :  353359 .    ,",
    "r. , friedman , j.  h.  hastie , t. 2011 .",
    "parsenet : coordinate descent with nonconvex penalties , _ j. amer . statist .",
    "assoc . _ * 106*(495 ) :  11251138 .",
    "owen , a.  b. 2005 .",
    "variance of the number of false discoveries , * 67*(3 ) :  411426 .    ,",
    "a. , calza , s. , gusnanto , a.  pawitan , y. 2006 .",
    "multidimensional local false discovery rate for microarray studies , _ bioinformatics _ * 22*(5 ) :  556565 .",
    "proal , e. , reiss , p.  t. , klein , r.  g.  et  al 2011 .",
    "brain gray matter deficits at 33-year follow - up in adults with attention - deficit / hyperactivity disorder established in childhood , _ arch .",
    "gen . psychiatry _ * 68*(11 ) :  11221134 .    , j. 2003 .",
    "the positive false discovery rate : a bayesian intepretation and the q - value , _ ann .",
    "_ * 3*(6 ) :  20132035 .    , j.  d. 2002 . a direct approach to false discovery rates , _",
    "j. r. statist .",
    "b _ * 64*(3 ) :  479498 .    ,",
    "j.  d. , taylor , j.  e.  siegmund , d. 2004 .",
    "strong control , conservative point estimation in simultaneous conservative consistency of false discover rates : a unified approach , _ j. r. statist .",
    "b _ * 66*(1 ) :  187205 .    , h .- q . ,",
    "tuominen , l.  k.  tsai , c .- j .",
    "2011 . : a sliding linear model for estimating the proportion of true null hypotheses in datasets with dependence structures , _ bioinformatics _ * 27 * :  225231 .    ,",
    "nearly unbiased variable selection under minimax concave penalty , _ ann .",
    "_ * 38*(2 ) :  894942 .",
    "in the proofs , @xmath77 denotes the probability measure , @xmath78 the expectation with respect to @xmath77 ,  @xmath77-a.s .",
    "\" means  almost surely in @xmath77 \" , and @xmath338 and @xmath339 are the covariance and variance operator with respect to @xmath77 , respectively .",
    "further , @xmath340 and @xmath341 are the probabilistic versions of the  big @xmath342 \" and  small @xmath343 \" notations , respectively . finally , @xmath344 denotes a generic , positive constant whose values can vary at different occurrences .",
    "we will use the same notations and settings in the main paper , and all asymptotics are for when @xmath138 .",
    "let @xmath345 be the sign function .",
    "it is easy to see that @xmath346 and @xmath347 necessarily satisfy@xmath348let @xmath349 and @xmath350",
    ". then @xmath351 and @xmath352 for @xmath353 whereas @xmath354 and @xmath355 for @xmath356 . therefore",
    ", @xmath357it is left to pick @xmath358 and @xmath359 such that @xmath360 .",
    "let  @xmath361 , where we recall that @xmath149 s are components of @xmath95 .",
    "note @xmath362 . by mill s ratio , @xmath363so , @xmath364 .",
    "hereunder , we condition our arguments on the event @xmath365 and do not mention this explicitly when a proposition holds _ with probability approaching to @xmath31 _ ( abbreviated as `` wpa-1 '' ) .    set @xmath366 for @xmath356 . then@xmath367on the other hand,@xmath368definitely , we can set @xmath369 and @xmath359 such that @xmath370 , @xmath371 but @xmath372 .",
    "this , with the finiteness of @xmath373 , implies@xmath374similarly , we can set @xmath375 such that @xmath376 and @xmath377with the above choice of @xmath375 , @xmath369 and @xmath359 , we obtain @xmath378by the assumptions on @xmath379 and @xmath380 , we have @xmath381 . the proof is completed .",
    "pick a @xmath382}$ ] .",
    "let @xmath383 , @xmath384 $ ] and @xmath385 .",
    "then , @xmath386 = i_{1}+i_{2}$ ] with @xmath387 $ ] and @xmath388 , where@xmath389.\\]]define @xmath390 . given @xmath185 ,",
    "our strategy has two steps : ( a ) derive a general bound on @xmath386 $ ] to deduce ( [ eq14 ] ) , i.e. @xmath391 ( b ) with@xmath392show @xmath386 = o\\left ( m^{-\\hat{\\delta}}\\right ) $ ] for some @xmath393 , which invokes theorem 6 of @xcite , a strong law of large numbers ( slln ) for weakly dependent random variables , to imply @xmath394    let @xmath395 for @xmath396 since @xmath397 is normally distributed as @xmath398 with mean @xmath20 and variance @xmath399 for @xmath400 , we have@xmath401 = \\exp \\left ( \\sqrt{-1}t\\zeta \\left ( u_{i}+u_{j}\\right ) \\right ) \\exp \\left ( -2^{-1}t^{2}\\zeta ^{2}\\tilde{a}_{ij}\\right ) \\text{,}\\]]where we recall @xmath402 when @xmath400 . therefore,@xmath403 = \\exp \\left ( \\sqrt{-1}t\\zeta \\left ( u_{i}+u_{j}\\right ) \\right ) g_{ij}\\]]with@xmath404similarly , since @xmath405 is normally distributed as @xmath406 with @xmath407 for @xmath400 , we have@xmath408 = \\exp \\left ( \\sqrt{-1}t\\zeta \\left ( u_{i}-u_{j}\\right ) \\right ) \\hat{g}_{ij}\\]]with@xmath409where @xmath410 is the complex conjugate of @xmath411 .",
    "therefore,@xmath412 \\right ) + \\re \\left ( { \\textrm{cov}}\\left [ \\chi _ { i},\\overline{\\chi _ { j}}\\right ] \\right ) \\right ]   \\\\ & = & 2^{-1}\\left\\ { \\cos \\left [ t\\zeta \\left ( u_{i}+u_{j}\\right ) \\right ] g_{ij}+\\cos \\left [ t\\zeta \\left ( u_{i}-u_{j}\\right ) \\right ] \\hat{g}_{ij}\\right\\ } \\text{,}\\end{aligned}\\]]where @xmath413 denotes the real part .",
    "from@xmath414for some @xmath415 that is strictly between @xmath20 and @xmath416 , we see that , for each fixed @xmath417 and @xmath418,@xmath419therefore,@xmath420for some constant @xmath189 , where we have used ( [ eqb23 ] ) and ( [ 24 ] ) ( i.e. , the components of the minor vector are weakly dependent ) . on the other hand , @xmath421 for some @xmath422 strictly between @xmath199 and @xmath423 , and@xmath424 = t^{2}\\zeta ^{2}{\\textrm{var}}\\left [ v_{i}\\sin \\left ( t\\zeta \\tilde{v}_{i}^{\\ast } \\right ) \\right ]",
    "\\leq t^{2}\\zeta ^{2}{\\mathbb{e}}\\left [ v_{i}^{2}\\right ] = t^{2}\\zeta ^{2}a_{i}^{-2}\\text{.}\\]]so,@xmath425 = t^{2}a_{\\left ( 1\\right ) } ^{-2}m^{-1}\\text{.}\\ ] ]    hence , @xmath386 \\leq p_{m}\\left ( t , a_{\\left ( 1\\right ) } \\right ) $ ] and@xmath426 } { \\tilde{\\varepsilon}^{2}}\\leq \\dfrac{p_{m}\\left ( t , a_{\\left ( 1\\right ) } \\right ) } { \\tilde{\\varepsilon}^{2}}\\text{,}\\]]where @xmath427 is defined by , i.e. , @xmath428 from @xmath429we see that , i.e. , @xmath391 holds with probability at least @xmath430 .",
    "finally , when ( [ eq16 ] ) holds , we have @xmath431 \\times \\left [ -1,1\\right ] } p_{m}\\left ( t , a_{\\left ( 1\\right ) } \\right ) = o\\left ( m^{-\\hat{\\delta}}\\right)\\]]for any @xmath393 , which implies ( [ eq15 ] ) .",
    "further , ( eq16 ) implies@xmath432 \\times \\left [ -1,1\\right ] } \\gamma \\zeta ^{2}a_{\\left ( 1\\right ) } ^{-2}\\log m=0\\]]and @xmath433where we have used the _ dominated convergence theorem _ ( dct ) . thus , ( [ eqb97 ] ) , i.e. , @xmath434holds almost surely for any @xmath192 .",
    "this completes the proof .",
    "let @xmath435 .",
    "let @xmath436 @xmath214 . by the decomposition @xmath437 , where @xmath438 @xmath439 and @xmath440 , we see that , to show @xmath441 converges to zero in probability , it suffices to show @xmath442 for @xmath443 .",
    "first , @xmath444 for @xmath445 and @xmath446 , which implies @xmath447 .",
    "secondly , since @xmath448 for @xmath206 implies @xmath449 , implies @xmath450 \\right\\vert = o_{{\\mathbb{p}}}\\left ( 1\\right ) .\\ ] ] therefore , it is left to show @xmath451 .    clearly , @xmath452for some @xmath453 strictly between @xmath174 and @xmath454 .",
    "therefore , for some constant @xmath189,@xmath455since the assumptions of hold with @xmath456 , we have @xmath457 thus , @xmath451 and the new estimator is consistent .",
    "this completes the proof .",
    "of an estimator @xmath324 of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath459 , where the dashed line marks @xmath334 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive excess and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best . ]        & benjamini & new & slim & benjamini & new & slim + & @xmath460 & 0.25419 & -0.014123 & 0.0473018 & 0.004791 & 0.011922 & 0.02906 + & @xmath461 & 0.17846 & -0.023529 & 0.0104083 & 0.004862 & 0.012706 & 0.02618 + & @xmath462 & 0.10534 & -0.031114 & -0.0253431 & 0.004397 & 0.012091 & 0.02369 + & @xmath463 & 0.03299 & -0.040947 & -0.0540270 & 0.003688 & 0.011331 & 0.02334 + & @xmath464 & -0.04141 & -0.051469 & -0.0796037 & 0.003476 & 0.013769 & 0.01770 + & @xmath460 & 0.24728 & -0.007783 & 0.0414034 & 0.054264 & 0.005273 & 0.07092 + & @xmath461 & 0.16896 & -0.017141 & -0.0024242 & 0.046204 & 0.005294 & 0.06306 + & @xmath462 & 0.09378 & -0.026396 & -0.0298384 & 0.036331 & 0.005103 & 0.04441 + & @xmath463 & 0.02339 & -0.034508 & -0.0560876 & 0.023223 & 0.005540 & 0.02979 + & @xmath464 & -0.04453 & -0.042546 & -0.0805302 & 0.006821 & 0.005016 & 0.01912 + & @xmath460 & 0.25377 & -0.007472 & 0.0449588 & 0.012572 & 0.008664 & 0.02873 + & @xmath461 & 0.17780 & -0.015670 & 0.0073633 & 0.010953 & 0.008519 & 0.02546 + & @xmath462 & 0.10435 & -0.024700 & -0.0247023 & 0.008860 & 0.008035 & 0.02460 + & @xmath463 & 0.03239 & -0.033361 & -0.0536669 & 0.005573 & 0.008583 & 0.02071 + & @xmath464 & -0.04252 & -0.045129 & -0.0808634 & 0.003026 & 0.008066 & 0.01689 + & @xmath460 & 0.24726 & -0.007399 & 0.0426443 & 0.054458 & 0.004820 & 0.06928 + & @xmath461 & 0.16894 & -0.016524 & 0.0006644 & 0.046675 & 0.005052 & 0.05951 + & @xmath462 & 0.09401 & -0.025075 & -0.0303219 & 0.036513 & 0.005015 & 0.04602 + & @xmath463 & 0.02321 & -0.034048 & -0.0562381 & 0.023041 & 0.004737 & 0.03104 + & @xmath464 & -0.04563 & -0.043493 & -0.0845221 & 0.007394 & 0.004882 & 0.01881 + & @xmath460 & 0.25261 & 0.078054 & 0.0402548 & 0.022265 & 0.048054 & 0.03827 + & @xmath461 & 0.17663 & 0.054929 & 0.0032062 & 0.019681 & 0.039897 & 0.03298 + & @xmath462 & 0.10342 & 0.030467 & -0.0279321 & 0.015767 & 0.031933 & 0.03103 + & @xmath463 & 0.03094 & 0.006424 & -0.0547324 & 0.010271 & 0.024221 & 0.02262 + & @xmath464 & -0.04300 & -0.020007 & -0.0798758 & 0.004244 & 0.014929 & 0.01842 +",
    "of an estimator @xmath324 of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath466 , where the dashed line marks @xmath334 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive excess and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best . ]        & benjamini & new & slim & benjamini & new & slim + & @xmath460 & 0.251239 & -0.02859 & 0.03061 & 0.005244 & 0.012226 & 0.02780 + & @xmath461 & 0.171458 & -0.05259 & -0.02855 & 0.005536 & 0.011961 & 0.02461 + & @xmath462 & 0.093704 & -0.07496 & -0.07159 & 0.004831 & 0.012025 & 0.02345 + & @xmath463 & 0.015120 & -0.10247 & -0.12107 & 0.004615 & 0.011275 & 0.02177 + & @xmath464 & -0.062935 & -0.12464 & -0.16016 & 0.004301 & 0.012714 & 0.01912 + & @xmath460 & 0.245220 & -0.02272 & 0.03848 & 0.053462 & 0.005501 & 0.06705 + & @xmath461 & 0.163943 & -0.04790 & -0.03300 & 0.044930 & 0.005671 & 0.06405 + & @xmath462 & 0.084956 & -0.07289 & -0.07837 & 0.035441 & 0.005697 & 0.05238 + & @xmath463 & 0.008581 & -0.09584 & -0.12486 & 0.024455 & 0.006716 & 0.04157 + & @xmath464 & -0.066525 & -0.11862 & -0.16469 & 0.011959 & 0.006021 & 0.03133 + & @xmath460 & 0.250940 & -0.02256 & 0.03108 & 0.012354 & 0.008811 & 0.03082 + & @xmath461 & 0.171241 & -0.04626 & -0.02198 & 0.010703 & 0.009120 & 0.02397 + & @xmath462 & 0.092923 & -0.07104 & -0.07174 & 0.008347 & 0.008424 & 0.02640 + & @xmath463 & 0.015106 & -0.09444 & -0.11993 & 0.006036 & 0.009406 & 0.02097 + & @xmath464 & -0.064713 & -0.12332 & -0.16786 & 0.004150 & 0.009297 & 0.02094 + & @xmath460 & 0.245060 & -0.02238 & 0.03654 & 0.053556 & 0.005032 & 0.06732 + & @xmath461 & 0.163905 & -0.04662 & -0.03104 & 0.045450 & 0.005361 & 0.06488 + & @xmath462 & 0.085247 & -0.07087 & -0.07673 & 0.035645 & 0.005492 & 0.05235 + & @xmath463 & 0.008764 & -0.09532 & -0.12412 & 0.023999 & 0.005743 & 0.04048 + & @xmath464 & -0.067362 & -0.12043 & -0.16524 & 0.012664 & 0.005727 & 0.02882 + & @xmath460 & 0.249922 & 0.06448 & 0.02616 & 0.021811 & 0.048529 & 0.03801 + & @xmath461 & 0.170336 & 0.02643 & -0.02451 & 0.019033 & 0.040653 & 0.03948 + & @xmath462 & 0.091818 & -0.01258 & -0.07581 & 0.015448 & 0.034280 & 0.03266 + & @xmath463 & 0.013838 & -0.05185 & -0.12380 & 0.010985 & 0.027010 & 0.02879 + & @xmath464 & -0.065132 & -0.09237 & -0.16962 & 0.005999 & 0.018722 & 0.02375 +",
    "of an estimator @xmath324 of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath467 , where the dashed line marks @xmath334 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive excess and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best when @xmath468 . ]        & benjamini & new & slim & benjamini & new & slim + & @xmath460 & 0.245957 & -0.04825 & 0.01839 & 0.005497 & 0.011937 & 0.02837 + & @xmath461 & 0.161015 & -0.09324 & -0.05349 & 0.005513 & 0.012646 & 0.02498 + & @xmath462 & 0.075451 & -0.14118 & -0.13249 & 0.004933 & 0.011847 & 0.02240 + & @xmath463 & -0.008615 & -0.18822 & -0.19711 & 0.004885 & 0.011040 & 0.02106 + & @xmath464 & -0.093345 & -0.23572 & -0.26009 & 0.004702 & 0.012653 & 0.02117 + & @xmath460 & 0.241180 & -0.04626 & 0.14697 & 0.053735 & 0.005582 & 0.26926 + & @xmath461 & 0.155209 & -0.09529 & -0.05549 & 0.046329 & 0.006044 & 0.06793 + & @xmath462 & 0.071163 & -0.13860 & -0.12985 & 0.038140 & 0.006346 & 0.07068 + & @xmath463 & -0.012609 & -0.18545 & -0.19737 & 0.030060 & 0.007522 & 0.06367 + & @xmath464 & -0.096940 & -0.23512 & -0.26692 & 0.021829 & 0.007367 & 0.06070 + & @xmath460 & 0.246505 & -0.04425 & 0.01510 & 0.012261 & 0.009987 & 0.02951 + & @xmath461 & 0.160753 & -0.09302 & -0.05686 & 0.010697 & 0.009969 & 0.02676 + & @xmath462 & 0.075914 & -0.13882 & -0.12332 & 0.008874 & 0.009748 & 0.02715 + & @xmath463 & -0.008183 & -0.18409 & -0.19474 & 0.007228 & 0.010166 & 0.02765 + & @xmath464 & -0.093632 & -0.23435 & -0.26177 & 0.005357 & 0.010227 & 0.02490 + & @xmath460 & 0.240983 & -0.04578 & 0.13871 & 0.053916 & 0.005523 & 0.27153 + & @xmath461 & 0.155600 & -0.09186 & -0.05598 & 0.046797 & 0.006392 & 0.07209 + & @xmath462 & 0.070082 & -0.14165 & -0.13441 & 0.039092 & 0.006409 & 0.07113 + & @xmath463 & -0.012546 & -0.18511 & -0.20071 & 0.029788 & 0.006578 & 0.06477 + & @xmath464 & -0.095580 & -0.23234 & -0.26579 & 0.021121 & 0.006424 & 0.06042 + & @xmath460 & 0.245087 & 0.04575 & 0.02019 & 0.021652 & 0.051253 & 0.03633 + & @xmath461 & 0.159096 & -0.01542 & -0.05924 & 0.018245 & 0.044311 & 0.03805 + & @xmath462 & 0.075125 & -0.07051 & -0.12931 & 0.016123 & 0.038958 & 0.03538 + & @xmath463 & -0.009509 & -0.12753 & -0.19460 & 0.012958 & 0.033182 & 0.03458 + & @xmath464 & -0.094581 & -0.18777 & -0.26273 & 0.009914 & 0.027927 & 0.03491 +",
    "of an estimator @xmath324 of the proportion @xmath2 of nonzero normal means when the minimum of the absolute values of the nonzero normal means @xmath470 , where the dashed line marks @xmath334 .",
    "a better estimator @xmath324 of @xmath2 should have non - positive excess and smaller variance and be less downwardly biased .",
    "the new estimator  new \" is overall the best when @xmath468 . ]        & benjamini & new & slim & benjamini & new & slim + & @xmath460 & 0.23945 & -0.07003 & 0.13999 & 0.005094 & 0.012275 & 0.30106 + & @xmath461 & 0.14752 & -0.14233 & -0.06759 & 0.005283 & 0.012476 & 0.12139 + & @xmath462 & 0.05458 & -0.21564 & -0.17694 & 0.005034 & 0.012507 & 0.02591 + & @xmath463 & -0.03794 & -0.29012 & -0.26412 & 0.005127 & 0.013514 & 0.02565 + & @xmath464 & -0.12977 & -0.36424 & -0.35232 & 0.005528 & 0.013013 & 0.02554 + & @xmath460 & 0.23544 & -0.07268 & 0.53766 & 0.055891 & 0.005364 & 0.38548 + & @xmath461 & 0.14254 & -0.14847 & 0.33706 & 0.051612 & 0.005972 & 0.39554 + & @xmath462 & 0.05141 & -0.21878 & 0.14399 & 0.046523 & 0.006069 & 0.38112 + & @xmath463 & -0.04019 & -0.29192 & -0.02156 & 0.042268 & 0.007171 & 0.34644 + & @xmath464 & -0.13267 & -0.36826 & -0.16599 & 0.037492 & 0.007023 & 0.33717 + & @xmath460 & 0.23971 & -0.07115 & 0.08490 & 0.012650 & 0.010405 & 0.24650 + & @xmath461 & 0.14685 & -0.14689 & -0.06656 & 0.011602 & 0.010402 & 0.12239 + & @xmath462 & 0.05498 & -0.21895 & -0.16891 & 0.010737 & 0.010130 & 0.03146 + & @xmath463 & -0.03675 & -0.29099 & -0.25970 & 0.010095 & 0.010581 & 0.02957 + & @xmath464 & -0.13000 & -0.36777 & -0.35140 & 0.008433 & 0.010582 & 0.02901 + & @xmath460 & 0.23528 & -0.07252 & 0.52016 & 0.056066 & 0.005478 & 0.38460 + & @xmath461 & 0.14364 & -0.14537 & 0.32067 & 0.051706 & 0.006208 & 0.39345 + & @xmath462 & 0.05079 & -0.22168 & 0.12641 & 0.047270 & 0.006179 & 0.38413 + & @xmath463 & -0.04020 & -0.29189 & -0.06215 & 0.041698 & 0.006677 & 0.33270 + & @xmath464 & -0.13161 & -0.36584 & -0.17868 & 0.037143 & 0.006294 & 0.31426 + & @xmath460 & 0.23877 & 0.02449 & 0.26522 & 0.022070 & 0.054233 & 0.36265 + & @xmath461 & 0.14544 & -0.05801 & 0.05228 & 0.020112 & 0.049378 & 0.29151 + & @xmath462 & 0.05424 & -0.13505 & -0.14387 & 0.019006 & 0.047700 & 0.14959 + & @xmath463 & -0.03867 & -0.21312 & -0.25001 & 0.017243 & 0.044206 & 0.09389 + & @xmath471 & -0.13083 & -0.29451 & -0.33146 & 0.015898 & 0.042353 & 0.11841 +"
  ],
  "abstract_text": [
    "<S> motivated by multiple testing related to marginal regression analysis for dependent high - dimensional data , we consider multiple testing which components of a normal random vector have zero means , where the proportion of components that have nonzero means plays an important role . </S>",
    "<S> we construct a consistent estimator of the proportion when components of the normal random vector can be strongly dependent . </S>",
    "<S> our estimator is perhaps the first among estimators of this proportion that has theoretically ensured consistency under strong dependence . </S>",
    "<S> it is accurate and stable as demonstrated by extensive simulation studies . </S>",
    "<S> its utility is illustrated by an application to multiple testing related to an association study based on brain imaging data . </S>",
    "<S> _ keywords _ : concave partially penalized least squares ; fourier transform ; multiple hypothesis testing ; proportion of nonzero normal means ; proportion of true null hypotheses . </S>",
    "<S> _ msc 2010 subject classifications _ : primary 62h15 , 62f12 ; secondary 62h25 . </S>"
  ]
}