{
  "article_text": [
    "starting with iras , and continuing with iso , the spitzer space telescope and akari , surveys using space - based infrared telescopes have revealed that many galaxies emit a significant fraction of their total luminosity at mid- and far - infrared ( ir ) wavelengths , this emission coming from dust grains which have been heated by absorbing optical or ultraviolet ( uv ) light from stars or agn .",
    "measurements of the integrated extragalactic background light reveal that the mid- and far - ir wavelength range contain as much energy as the ultraviolet and optical parts @xcite .",
    "dust therefore plays a key role in shaping the observational signature of the overall global star formation history .",
    "building on the success of space - based infrared telescopes as well as ground - based sub - mm instruments like the submillimetre common user bolometric array ( scuba ) on the james clerk maxwell telescope , a number of new instruments and space missions are planned which will map the universe at wavelengths sensitive to emission from dust ( e.g. herschel , scuba-2 , lmt , alma ) .",
    "some of these new instruments will allow wide field surveys to be carried out , such as the herschel atlas survey which will cover 600 square degrees and will provide accurate measurements of the clustering of galaxies selected by their far ir emission .",
    "these new surveys will be targetted by other telescopes , building up multi - wavelength coverage .",
    "it is therefore essential to develop theoretical tools which can take advantage of these new data and which make predictions of galaxy spectral energy distributions ( seds ) over a wide range of wavelengths .    in this paper",
    "we build on a hybrid model introduced by granato et  al .",
    "( 2000 ) which combines the semi - analytical galaxy formation code  ( cole et  al .",
    "2000 ) with a spectro - photometric code  ( silva et  al .",
    "the semi - analytical model uses simple physically motivated recipes and prescriptions to follow the baryonic process believed to be important for galaxy formation ( see baugh 2006 for an overview )",
    ".  takes the star formation history predicted for each model galaxy by  and makes an accurate calculation of the sed from the far - uv to the radio .",
    "calculates the absorption of starlight by dust self - consistently by radiative transfer , using the dust mass obtained from the gas mass and metallicity , and the disk and bulge scalelengths predicted by the model .",
    "the spectrum of dust emission is calculated by solving for the radiative equilibrium temperatures of individual dust grains .",
    "the hybrid   plus   model successfully reproduces the abundance of lyman - break galaxies at high redshift ( detected through their emission in the rest frame uv ) and the number counts and redshifts of submillimetre selected galaxies ( baugh et  al . 2005 ) .",
    "this model has also been used to predict the number counts and redshift distributions of galaxies as measured in the mid and far ir by the spitzer space telescope ( lacey et  al .",
    "2008 ) .    to build mock catalogues with information about the spatial distribution of galaxies for wide field surveys like the herschel atlas",
    ", we need to use the hybrid  plus  model to populate large volume n - body simulations . in this paper",
    "we use the millennium simulation of the evolution of structure in a cold dark matter universe ( springel et  al .",
    "the simulation volume is @xmath3 mpc on a side and contains around 20 million dark matter haloes at the present day . to build a mock catalogue for",
    "the herschel atlas , which extends to @xmath4 , would require us to populate around 30 snapshots from the millennium , which would run to around 500 million dark matter haloes .",
    "the  code takes several minutes to run for each galaxy , so to process on the order of one billion galaxies would take around 100 years on current large computers .    in this paper",
    "we explore an alternative approach in which we train an artificial neural network to mimic the calculation of seds by .",
    "we show that it is possible to construct a neural net which , starting from a small number of galaxy properties which can be readily predicted by , can produce reasonably accurate predictions of the luminosity which would result from a direct calculation with .",
    "we note that a complementary approach in which an artificial neural network is trained to speed up part of the calculation carried out by  has been developed by silva et  al .",
    "( 2009 , in preparation ) .    here",
    "we introduce the neural net technique and apply it to study the overlap between lyman - break galaxies and submillimetre selected galaxies .",
    "we give a brief overview of  and  in section 2 and explain how they are combined into a hybrid code to predict the spectral energy distributions of galaxies . in section 3 , we give some theoretical background to artificial neural networks .",
    "section 4 is devoted to an investigation of the accuracy of the neural net in predicting galaxy luminosities for different choices for the set - up of the net .",
    "we apply the new technique to the prediction of the luminosity functions of lyman - break galaxies at @xmath5 , mid - ir selected galaxies at @xmath6 and submillimetre galaxies at @xmath0 in section 5 , where we compare the results from the neural net against the direct calculations from .",
    "we show how well the model can predict colour distributions in section 6 . in section 7",
    ", we examine the overlap between galaxies selected in the rest - frame uv and in the observer frame sub - millimeter .",
    "finally , in section 8 , we present our conclusions . throughout",
    "we assume the cosmology of the millennium simulation with a present - day matter density of @xmath7 and a cosmological constant of @xmath8 .",
    "in this section , for completeness , we give a brief overview of the semi - analytical galaxy formation model galform and the spectro - photometric code grasil .",
    "we also explain how these codes can be used in combination to predict the full spectral energy distributions of a population of galaxies .      the fate of baryons in a universe in which structure in the dark matter forms hierarchically depends on a range of often complex and nonlinear physical phenomena .",
    "the galform code models these processes using physically motivated recipes .",
    "some parts of the model are better understood than others .",
    "for example , the merger history of dark matter haloes has been modelled extensively using n - body simulations of gravitational instability and accurate monte carlo techniques have been developed to replicate the merger histories ( e.g. parkinson , cole & helly 2008 ) .",
    "on the other - hand , the rate at which stars form from a reservoir of cold gas is not well understood theoretically and is modelled by adopting a prescription which contains parameters .",
    "the values of the parameters are fixed by requiring that the model reproduces a subset of observations of the galaxy population . the philosophy behind semi - analytical modelling is set out in the review by baugh ( 2006 ) .",
    "full details of the galform model are given by cole et  al .",
    "( 2000 ) and in subsequent papers which have presented developments of the original model ( benson et  al .",
    "2003 ; baugh et  al . 2005 ; bower et  al .",
    "2006 ; font et  al .",
    "2008 ) . a useful summary of the model used in this paper , that of baugh et  al . ( 2005 ) , is given by lacey et  al .",
    "the baugh et  al .",
    "model reproduces the observed abundance of lyman - break galaxies and galaxies detected with the scuba instrument .",
    "we use the ann model to investigate the overlap between these populations in section 7 .    the key point to have clear is that galform predicts the full star formation and chemical enrichment history of galaxies .",
    "the starting point is the merger history of a dark matter halo .",
    "the rules describing the baryonic physics are applied to gas in the merger tree , starting from the branches which are in place at the earliest time .",
    "the code then follows the gas cooling , star formation , feedback processes and galaxy mergers . the star formation history , which includes the metallicity of the stars made at each timestep , is the primary ingredient required to compute the spectral energy distribution of a galaxy . in its standard mode of operation",
    ", galform uses a stellar population synthesis model ( such as the one devised by bruzual & charlot 2003 ) to construct a composite stellar population for each galaxy .",
    "extinction of starlight by dust is calculated by assuming that the dust and stars are mixed together , rather than by treating the dust as a foreground slab .",
    "galform predicts the half - mass radius of the disk and bulge components of each galaxy ( see cole et  al .",
    "2000 ; tests of the model for calculating sizes are presented in cole et  al . and also in almeida et  al . 2007 and gonzalez et  al . 2008 ) . assuming a random inclination angle at which to view the galactic disk , the attenuation of starlight is computed using the tabulated results of radiative transfer calculations carried out by ferrara et  al .",
    "( 1999 ) .",
    "the grasil code ( silva et  al . 1998 ) can be used to accurately model the observed seds of galaxies over a wide range of wavelengths  from the far - uv to radio . in the standard application of grasil",
    ", a parameterized star formation history is tuned until a given observed sed is reproduced ( e.g * ? ? ?",
    ". the unique selling point of grasil is its sophisticated handling of the extinction and reprocessing of starlight by dust .",
    "the galaxy as an axially symmetric system with a disk and bulge component .",
    "the dust is assumed to be divided into two phases : a diffuse component and dense , star - forming molecular clouds , with the mass fraction between the two being a model parameter .",
    "stars are born within molecular clouds and then escape after a few myr .",
    "the extinction of the light from a set of stars depends on their age relative to this escape time .",
    "high mass stars , which typically dominate the emission at ultraviolet wavelengths , spend a significant fraction of their short lifetimes within the optically thick molecular clouds .",
    "consequently , the emission at these wavelengths is heavily extincted .",
    "the time for a star to escape from a molecular cloud is a model parameter .",
    "grasil calculates the radiative transfer of starlight through this dust distribution ( molecular clouds and cirrus ) , and then solves for the temperature distribution of the dust grains at each point in the galaxy self - consistently based on the local stellar radiation field .",
    "this temperature distribution is then used to calculate the dust emission .",
    "effects of very small grains , subject to temperature fluctuations , as well as polycyclic aromatic hydrocarbons ( pahs ) are included .",
    "the model is calibrated against available data of normal and starburst galaxies in the local universe @xcite",
    ". the self - consistent calculation of dust temperatures by grasil avoids the need to impose a dust temperature by hand , as is common in other models .",
    "granato et  al .",
    "( 2000 ) described how the grasil code can be used to compute the seds of galform galaxies .",
    "the semi - analytical code predicts the star formation history of each galaxy , outputting the star formation rate in all the progenitors of the galaxy , stored in bins of metallicity .",
    "the model also outputs the scale lengths of the galaxy s disk and bulge , and the mass and metallicity of the cold gas .",
    "grasil takes this information and produces an unextincted and an extincted sed for the galaxy .",
    "the calculation carried out by grasil improves over the standard calculation made by galform in two main areas : i ) dust extinction at short wavelengths , which is strongly affected by molecular clouds , is calculated more accurately ; and ii ) the emission of radiation by dust is included .",
    "artificial neural networks ( anns ) are mathematical constructs designed to replicate the behaviour of the human brain . given a training set of observations consisting of inputs with an associated set of outputs ,",
    "the role of the ann is to `` learn '' from these observations in order to be able to predict the output from a new set of inputs .",
    "the origins of the technique date back to @xcite , who developed a simple network using _ artificial neurons _ to perform logical operations .",
    "however , the concept of learning was only introduced a few years after this by @xcite and implemented by @xcite .",
    "nowadays anns are widely used in computer science , finance , physics , mathematics , astronomy and many other areas .",
    "typical applications include pattern recognition , function approximation , prediction and forecasting , and categorization .",
    "even though neural networks have traditionally been viewed as black boxes , for which the user has little knowledge of their internal workings , they offer a number of advantages over other data mining and analysis tools , such as the ability to learn and applicability to a wide of problems .",
    "also , anns can be readily parallelized .      in simple terms",
    ", the brain can be thought of as a collection of billions of special cells called neurons , which process information and are interconnected through synapses in a complex net .",
    "neurons work by receiving electrochemical signals from other neurons , some of which will excite the cell whereas others will inhibit it . the neuron adds up these inputs and if the sum exceeds a certain threshold , it will transmit the same signal to other neurons . in this case",
    "the neuron is said to be activated .",
    "anns are similar to their biological counterparts : they consist of simple computational units ( also called neurons or nodes ) , which are connected in a network . for every neuron we need to specify the input connections and their associated weight , @xmath9 .",
    "the neuron multiplies the input by its weight and adds the contributions from the interconnected units .",
    "the sum is then mapped by the activation function , @xmath10 , to the output value , which , in turn , will become an input to the next group of adjacent neurons .",
    "if we define @xmath11 as the input signal coming from neuron @xmath12 , and @xmath13 as the weight between the input @xmath12 and neuron @xmath14 , then the output , @xmath15 , from the neuron is given by : @xmath16    there are numerous types of anns which differ in the way the neurons are organized and exchange information .",
    "it is common to group the neurons into layers . in general",
    ", there is an input layer , an output layer and some number of hidden layers in between .",
    "the input layer is responsible for handling the input data .",
    "it is clear that there is no activation function associated with this layer , because the output values of their neurons are simply set to be equal to their input values .",
    "the output of the network is recovered from the output layer . using only one input layer and one output layer",
    ", it is possible to construct a very simple network called a perceptron . the perceptron can recognize simple patterns in data . for more difficult tasks , we need hidden layers between the input and output layers .",
    "the term `` hidden '' is used because the user does not have direct access to the inputs and outputs dealt with by these layers .",
    "networks with more than just an input and output layer are called multilayer networks or multilayer perceptrons .",
    "they are the most widely used due to their ability to learn nonlinear functions .",
    "the three most popular network configurations are : the perceptron ( no hidden layers ) , the feed - forward and the recurrent network ( the latter two cases both use hidden layers ) .",
    "feed - forward nets are the most widely employed due to their simplicity .",
    "these anns pass information from the input layer , through the hidden layers to the output neurons .",
    "in recurrent networks , on the other hand , the output from the neurons can be fed backwards , through feedback connections , and act as input .",
    "such behaviour is similar to that found in the biological brain .",
    "even though recurrent networks can perform better than the feed - forward nets , they suffer from a major drawback : training is more difficult due to their oscillatory , even chaotic behaviour , resulting in longer computing times .",
    "there are two types of learning : supervised and unsupervised . in the first case ,",
    "the network is presented with a target consisting of a set of inputs with associated outputs .",
    "the ann adapts its weights in order to reproduce the desired output . in unsupervised learning",
    ", the network does not have a target output . in this case , the aim is to find patterns and to group the data . in this paper",
    "we focus on supervised learning .",
    "there are several different approaches to supervised learning . most share the common feature that the ann learns by comparing the predicted output to the target output .",
    "the algorithm of this process is simple : ( i ) start with an untrained net ; ( ii ) determine the output from a given input ; ( iii ) compare the output to the target output and compute an error ; ( iv ) adjust the weights in order to reduce the error .",
    "the most widely used learning algorithm is the backpropagation algorithm , which was introduced by @xcite .",
    "this algorithm finds the local minimum of the error function : @xmath17 where @xmath18 represents the desired or target output values , and @xmath19 is the predicted output from the neuron . using the gradient descent method",
    ", it can be shown that the update to the weights from the hidden layer to the output layer is given by : @xmath20 with @xmath21 known as the learning rate , @xmath22 ( where the activation function , @xmath10 , is differentiable ) and @xmath23 is the output from the preceding hidden neuron .",
    "a similar expression can be found for the variation of the weights between the input and hidden layers .",
    "it is clear that if the surface corresponding to the error function has multiple local minima then this method , as originally defined , will only guarantee convergence towards one of the minima but not necessarily to the global minimum .",
    "however , this is not an insurmountable problem since , during the first steps of the gradient descent , the weights will gradually move towards the global minimum .",
    "moreover , in the worse case scenario , the weights will converge to a local minimum in the vicinity .",
    "there are several methods to avoid this behaviour : we could add an extra factor to eq .",
    "[ eq : ann.deltaw ] , @xmath24 , called the momentum , which has the same direction as the previous step change , @xmath25 , and is controlled by the coefficient @xmath26 . alternatively",
    ", we can train the network several times using the same training sample but with different initial random weights .",
    "the latter approach is the one we will follow in this paper .",
    "a further refinement is the resilient backpropagation algorithm @xcite , in which instead of adopting the full change in the weights specified by eq .",
    "[ eq : ann.deltaw ] , we only use the sign of the derivative multiplied by a constant .",
    "we also adopt this method in our network .",
    "the resilient backpropagation algorithm has the advantage of being one of the fastest learning algorithms .    in an ideal situation ,",
    "the ann would , of course , find the optimal set of weights such that the error function is minimized .",
    "however , there is an important aspect that we have to bear in mind .",
    "one of the reasons why we use anns is that we need to achieve generalization ; i.e. it is more important to find the network that best fits the testing or validation set , than it is to find the minimum of the error function for the training set .",
    "in fact , if the net is overtrained it will start to fit the noise associated with the data instead of the underlying signal .",
    "this leads to overfitting and consequently may affect the performance of the ann on the validation sample .",
    "one of the procedures deployed to avoid overfitting is to use a so - called early stop . in this case , the training process is terminated when either the error function reaches a pre - defined threshold or a maximum number of iterations is reached . the latter choice is adopted in this paper .    finally , a brief word about the form of the activation function .",
    "as we saw , the activation function plays an important role in the neural network .",
    "it allow us to activate or deactivate neurons and adds the nonlinearity needed to solve complex problems .",
    "evidently , activation functions only make sense for the hidden and output layers , not for input layers .",
    "there are many activation functions ; in fact , any nonlinear function would fit the bill .",
    "the most common are : the sigmoid function , @xmath27 , where @xmath28 is the _ steepness _ ; the gaussian , @xmath29 ; and the elliot , @xmath30 .",
    "our default choice is the sigmoid function ; we contrast the performance of the ann with this activation function against some of the others listed above in section  4.5.3 .",
    "our main objective is to predict a galaxy s spectral energy distribution using a small set of its physical properties as predicted by  .",
    "this is far from a simple proposition , due to the complexity of the individual spectra and the wide range of spectral energy distributions found in a population of galaxies . in this section",
    "we explain how we use the ann to predict spectra or luminosities , showing the first results and discussing some performance issues .",
    "the training process is crucial for anns .",
    "the better the network learns about the characteristics of the training set , the better it will perform when predicting the spectra of a new set of galaxies .",
    "the galaxy spectra calculated by  are far from simple . as noted in section  [ section : model ] ,  calculates the stellar emission , dust extinction and dust emission , using the star formation and metal enrichment histories predicted by galform . as a consequence ,",
    "spectra are complex and varied .",
    "the seds we compute from  comprise , in our application , 456 wavelength bins ( this number can be varied in ) , so the output has a high dimensionality .",
    "[ fig : ann.seds ] shows some examples of spectra produced by . in the top panel , we plot the spectral energy distribution of a randomly selected galaxy ( black line ) , showing the different contributions ( extincted starlight , molecular dust clouds and diffuse dust ) .",
    "the mid - infrared emission in this particular galaxy is dominated by pah molecular bands and the far - infrared by cirrus ( diffuse dust ) emission .",
    "further examples of total galaxy seds are shown in the bottom panel of this plot .",
    "= 8.truecm = 8.truecm    = 8.truecm    fig .",
    "[ fig : ann.sd ] shows a quantitative view of the complexity of the spectra output by  for a population of galaxies .",
    "we plot the ratio between the standard deviation and the mean of the normalized spectra for a representative sample of galaxies .",
    "this plot shows that the ultraviolet , mid infrared , microwave and the radio regions of the spectrum show the most variety in galaxy seds .",
    "the visible and far - infrared parts of the model spectra show , by comparison , less variance .",
    "each spectrum is composed of 456 flux bins , so our first approach will be to set the number of output neurons in our net to be 456 , one for each flux bin . later on",
    "we will try different methods in order to reduce the dimensionality and variance of the output space . for use in the ann ,",
    "we first normalize the total luminosity in each sed to unity .",
    "we then assign the logarithm of the flux at each wavelength to these outputs in order to reduce the dynamic range of the training data .",
    "the selection of the input for the ann is less straightforward .",
    "the natural choice would be to adopt the same input as used directly by  to create the spectra , i.e. the star formation and metal enrichment histories along with the gas mass and metallicity , and the scale - lengths of the disk and bulge . however , this is hard to implement due to the enormous number of input variables implied ( more than 3000 taking into account the different timesteps and bins of metallicity in which the star formation histories are stored ) .",
    "this , in turn , would represent a substantial amount of computing time and complexity for the learning process . to keep things simple",
    ", we decided to use a small set of galaxy properties , measured at the output redshift at which the galaxy s sed is required .",
    "after some investigation , we found that a useful set of galaxy properties to serve as input to the ann is : total stellar mass , stellar metallicity , bolometric luminosity , circular velocity of the disc measured at the half - mass radius , the effective circular velocity of the bulge , disc and bulge half - mass radii , v - band luminosity weighted age , v - band dust extinction optical depth , metallicity of the cold gas , the mass of stars formed in the last burst and the time since the start of the last burst of star formation .",
    "( recall bursts are triggered by galaxy mergers or by disks becoming dynamically unstable ; the latter process does not operate in the baugh et  al .",
    "model which is used as an example in this paper . )",
    "we therefore construct an input layer with 12 galaxy properties .",
    "it is important to note that this set of input galaxy properties has been tuned for the @xcite model at @xmath31 .",
    "for a different model , the the ann might perform better with a different set of galaxy properties as inputs .",
    "we also note that the above list of input galaxy properties includes the circular velocities of the disk and bulge - these properties affect the sed through their effect on the efficiency of supernova feedback and on the star formation timescale .    in this section ,",
    "the training and testing samples were extracted from a large catalogue of galaxies from the baugh et  al .",
    "model at @xmath31 , following a similar procedure to that used by @xcite .",
    "the  catalogue is sampled to give equal numbers of galaxies in logarithmic bins of total stellar mass .",
    "this strategy yields 1945 galaxy spectra for the training set , each of which is composed of 456 flux bins , i.e. a @xmath32 data array . a further set of 1898 galaxies",
    "were used as a validation sample .      to predict luminosities",
    ", we use a supervised feed - forward neural network composed of 12 neurons in the input layer ( which correspond to the 12 galaxy properties listed above ) , 60 neurons in one hidden layer and 456 neurons in the output layer ( which are set to be equal to the logarithm of the flux in each of the spectrum bins ) .",
    "the ann architecture is therefore 12:60:456 .",
    "unless otherwise specified , the following procedures and parameters were chosen : ( i ) in order to deal with the different ranges of the input and output properties , we subtract the mean ( computed over the training sample ) from each input and output and divide by the respective standard deviation ; ( ii ) we adopt a sigmoid activation function ; ( iii ) the maximum number of training epochs is set to 5000 ( i.e. this is the criteria used to stop the training process ) ; ( iv ) in order to guarantee convergence towards the global minimum of the error function ( see previous section ) , we train the ann ten times using different initial random weights , and select the one that gives the smallest root mean square logarithmic error ( see definition below ) for the validation sample . later in this section",
    ", we will show how the results change on modifying the ann parameters .",
    "= 8.5truecm    in fig .",
    "[ fig : ann.predicted.spectra ] we plot four randomly selected examples of the spectra predicted by the ann and compare these with the original spectra . fig .",
    "[ fig : ann.predicted.spectra ] shows that even without further optimization , the spectra predicted using the ann agree , on the whole , reasonably well with the original spectra , particularly at visible and near - infrared wavelengths .",
    "however , in certain wavelength ranges , some galaxies exhibit predicted luminosities which differ by more than an order of magnitude from their true values .",
    "= 8.truecm = 8.truecm = 8.truecm = 8.truecm    to gain a more quantitative feel for the performance of the ann , we plot in fig .",
    "[ fig : ann.compare.predicted.spectra ] the ratio of the predicted to original luminosity for selected , representative wavelength bins : the foca ( the focal corrector anastigmat balloon borne camera ) @xmath33 m , b ( @xmath34 m ) , irac ( the infra red array camera on spitzer ) @xmath35 m and scuba ( submillimetre common user bolometric array ) @xmath36 m bands . the statistics of the distributions are also summarized in table  [ tab : ann.predicted.spectra ] . here",
    "the root mean squared logarithmic error is defined as : @xmath37 ^ 2 } \\",
    ", , \\ ] ] and @xmath38 gives the percentage of galaxies with predicted luminosities which lie within 10% of the true values .",
    "note that @xmath39 has a similar form to the error function which the ann attempts to minimize , as given in eq .  2 .    [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     = 8.truecm    in fig .",
    "[ fig : clustering.colours.sv ] we plot the distribution of observer - frame r - band  sub - mm ( 850 @xmath40 m ) colours predicted by the ann , for galaxies in the millennium simulation at @xmath0 .",
    "we plot the colour distributions for smgs with flux densities @xmath41 and @xmath42 mjy in the two panels . for galaxies with @xmath41 mjy , we find a median colour of @xmath43 .",
    "brighter smgs with @xmath44 mjy display a colour distribution which is on average @xmath45 times redder , with a median colour of @xmath46 .",
    "the colour distributions are also seen to be very broad , especially for the brighter sub - mm flux limit , which covers a range @xmath47 in colour .",
    "we also show ( as hatched histograms ) the colour distributions which result for each sub - mm flux limit if we further select only galaxies with optical magnitudes brighter than @xmath48 .",
    "this shows how we lose the redder part of the optical  sub - mm colour distribution with this optical selection .",
    "in this paper we have introduced a new method to rapidly predict accurate spectral energy distributions over a wide wavelength range from a small number of galaxy properties , using artificial neural networks ( ann ) .",
    "granato et  al .",
    "( 2000 ) combined the galform semi - analytical galaxy formation code with the spectro - photometric code grasil .",
    "the use of grasil allows a more comprehensive and accurate treatment of the effect of dust on the sed of the galaxy , predicting the dust emission in the mid- and far - ir regions , as well as improving the accuracy of the predicted spectra in the uv .",
    "unfortunately , grasil takes several minutes to run for each galaxy , which prohibits the direct application of this code to populate large dark matter simulation volumes with galaxies .",
    "the ann provides a fast , simple and flexible means to calculate accurate galaxy spectra based on . here ,",
    "we have carried out the first tests of the method and present applications to galaxy luminosities and colours .",
    "the ann is trained using a sample of galaxies for which  has been run to compute spectra .",
    "we found that the ann approach performs well when predicting galaxy spectra from galaxy properties .",
    "the best performing ann architecture we found is a simple supervised , feed - forward net , composed of 12 input galaxy properties , two hidden layers with 30 neurons each , and one output neuron .",
    "the ann works best when predicting the luminosity at one wavelength at a time , rather than the whole spectrum . due to the inherent variety in the spectra of galaxies which are undergoing a burst of star formation , or which recently underwent a burst , we found it best to train the ann separately for samples of quiescent and bursting galaxies .",
    "the ann needs to be trained at each redshift of interest and for each set of  plus  parameters .",
    "the luminosities predicted by the ann agree remarkably well with those computed directly using . in the observer frame @xmath1 m at @xmath0 , over 90% of the ann predicted luminosities lie within 10% of the true luminosities calculated directly from .",
    "the ann works somewhat less well in the uv and mid - ir .",
    "nevertheless , at all the wavelengths considered we find that the luminosity functions predicted by the ann are in excellent agreement with those computed directly with .",
    "the ann also performs well when predicting the colours of galaxies . in this case , the ann is trained for each band individually .",
    "given this success , we applied the ann to investigate the overlap between samples of rest - frame uv and sub - mm selected galaxies at @xmath49 .",
    "this problem is ideally suited to the ann approach , as it requires a large sample of galaxies covering a wide range of luminosity .",
    "although we predict that 50% of bright submillimetre sources ( 850@xmath40 m flux greater than 5 mjy ) should have optical magnitudes brighter than @xmath48 , these smgs make up only a small fraction of an optically selected sample at the same magnitude limit . in an optically selected sample of galaxies at @xmath0 brighter than @xmath50 , 10% are predicted to have an 850 @xmath40 m flux brighter than 1 mjy and 1% are expected to be brighter than 5 mjy .",
    "these predictions seem consistent with recent observational constraints ( e.g. * ? ? ?",
    "the success of our new ann approach in generating accurate predictions of the spectral energy distributions of large samples of galaxies means that we can now produce mock catalogues of galaxies for forthcoming surveys such as the herschel atlas survey , which will cover 600 square degrees in five far - infrared bands , and the scuba-2 cosmology legacy survey , which will cover around 40 square degrees to a fainter flux limit in the sub - mm . in a companion paper",
    "we apply the ann technique to populate the millennium simulation with galaxies with accurate sub - mm fluxes to make predictions for the clustering of dusty galaxies .",
    "ca gratefully acknowledges support in the form of a scholarship from the science and technology foundation ( fct ) , portugal .",
    "this work was supported in part by the science and technology facilities council and by the royal society .",
    "csf is a royal society wolfson research merit award holder .",
    "99 adelberger k.l . , steidel c.c . , 2000 , apj , 544 , 218 alexander d.m . ,",
    "bauer f.e .",
    ", brandt w.n . , hornschemeier a.e .",
    ", vignali c. , garmire g.p . ,",
    "schneider d.p . , chartas g. , gallagher s.c .",
    ", 2003 , mnras , aj , 125 , 383 alexander d.m .",
    ", bauer f.e . ,",
    "chapman s.c . , smail i. , blain a.w . , brandt w.n . ,",
    "ivison r.j . , 2005 ,",
    "apj , 632 , 736 baugh c.m . , lacey c.g . ,",
    "frenk c.s .",
    ", granato g.l . , silva l. , bressan a. , benson a.j . , cole s. , 2005 , mnras , 356 , 1191 baugh c.m . , 2006 ,",
    "phys . , 69 , 3101 blain a.w . , smail i. , ivison r.j . , kneib j .-",
    ", frayer d.t . , 2002 ,",
    "phr , 369 , 111 blain a.w . ,",
    "chapman s.c . , smail i. , ivison r. , 2004 , apj , 611 , 725 bower r.g . , benson a.j . , malbon r. , helly j.c . , frenk c.s . ,",
    "baugh c.m .",
    ", cole s. , lacey c.g . , 2006 ,",
    "mnras , 370 , 645 bressan a. , granato g.l . , silva l. , 1998 , a&a , 332 , 135 bressan a. , silva l. , granato g.l . , 2002 ,",
    "a&a , 392 , 377 chapman s.c . , scott d. , steidel c.c . , borys c. , halpern m. , morris s.l .",
    ", adelberger k.l . ,",
    "dickinson m. , giavalisco m. , pettini m. , 2000 , mnras , 319 , 318 chapman s.c . , blain a.w . , smail i. , ivison r.j . , 2005 ,",
    "apj , 622 , 772 cole s. , lacey c.g . , baugh c.m . , frenk c.s . , 2000 ,",
    "mnras , 319 , 168 croton d.j . , springel v. , white s.d.m . ,",
    "de lucia g. , frenk c.s . , gao l. , jenkins a. , kauffmann g. , navarro j.f . ,",
    "yoshida , n. , 2006 , mnras , 365 , 11 granato g.l . , lacey c.g .",
    ", silva l. , bressan a. , baugh c.m . , cole s. , frenk c.s . , 2000 , apj , 542 , 710 hauser m.g . ,",
    "arendt r.g . , kelsall t. , dwek e. , odegard n. , weiland j.l . , freudenreich h.t . ,",
    "reach w.t .",
    ", silverberg r.f . ,",
    "moseley s.h .",
    ", et  al . , 1998 , apj , 508 , 25 hebb d.o . , 1949 , the organization of behavior , john wiley & sons hughes d.h . , serjeant s. , dunlop j. , rowan - robinson m. , blain a. , mann r.g . , ivison r. , peacock j. , efstathiou a. , gear w. , et  al . , 1998 , nature , 394 , 241 lacey c.g .",
    ", baugh c.m .",
    ", frenk c.s . , silva l. , granato g.l . , bressan a. , 2008 , mnras , 385 , 1155 mcculloch w. , pitts w. , 1943 , bulletin of mathematical biophysics , 5 , 115 panuzzo p. , granato g.l . , buat v. , inoue a.k . , silva l. , iglesias - pramo j. , bressan a. , 2007 , mnras , 375 , 640 puget j.l . ,",
    "abergel a. , bernard j.p .",
    ", boulanger f. , burton w.b . ,",
    "desert f.x .",
    ", hartmann d. , 1996 , a&a , 308 , 5 riedmiller m. , braun h. , 1993 , proc . of the ieee intl .",
    "conf . on neural networks , 586 rosenblatt f. , 1958 , psychological review , 65 , 386 rosenblatt f. , 1962 , principles of neurodynamics , spartan rumelhart d.e .",
    ", hitton g.e . , williams r.j . , 1986 ,",
    "parallel distributed processing : explorations scarselli f. , tsoi a.c . , 1998 , nn , 11 , 15 schurer a. , calura f. , silva l. , pipino a. , granato g.l . , matteucci f. , maiolino r. , 2009 , mnras , accepted , arxiv:0901.1207 silva l. , granato g.l .",
    ", bressan a. , danese l. , 1998 , apj , 509 , 103 smail i. , ivison r.j . , blain a.w . , 1997 , apjl , 490 , 5 smail i. , 2002 , ap&ss , 281 , 453 springel v. , white s.d.m . , jenkins a. , frenk c.s . , yoshida n. , gao l. , navarro j. , thacker r. , croton d. , helly j. , 2005 , nature , 435 , 629 steidel c.c . , adelberger k.l . , giavalisco m. , dickinson m. , pettini m. , 1999 , apj , 519 , 1 steidel c.c . , adelberger k.l . ,",
    "shapley a.e . , pettini m. , dickinson m. , giavalisco m. , 2003 , apj , 592 , 728 steidel c.  c. , shapley a.  e. , pettini m. , adelberger k.  l. , erb d.  k. , reddy n.  a. , hunt m.  p. , 2004 ,",
    "apj , 604 , 534 vega o. , silva l. , panuzzo p. , bressan a. , granato g.l . , chavez m. , 2005 , mnras , 364 , 1286"
  ],
  "abstract_text": [
    "<S> we introduce a new technique based on artificial neural networks which allows us to make accurate predictions for the spectral energy distributions ( seds ) of large samples of galaxies , at wavelengths ranging from the far - ultra - violet to the sub - millimetre and radio . </S>",
    "<S> the neural net is trained to reproduce the seds predicted by a hybrid code comprised of the  semi - analytical model of galaxy formation , which predicts the full star formation and galaxy merger histories , and the  spectro - photometric code , which carries out a self - consistent calculation of the sed , including absorption and emission of radiation by dust . using a small number of galaxy properties predicted by </S>",
    "<S> , the method reproduces the luminosities of galaxies in the majority of cases to within 10% of those computed directly using . </S>",
    "<S> the method performs best in the sub - mm and reasonably well in the mid - infrared and the far - ultra - violet . </S>",
    "<S> the luminosity error introduced by the method has negligible impact on predicted statistical distributions , such as luminosity functions or colour distributions of galaxies . </S>",
    "<S> we use the neural net to predict the overlap between galaxies selected in the rest - frame uv and in the observer - frame sub - mm at @xmath0 . </S>",
    "<S> we find that around half of the galaxies with a @xmath1 m flux above 5 mjy should have optical magnitudes brighter than @xmath2 mag . </S>",
    "<S> however , only 1% of the galaxies selected in the rest - frame uv down to @xmath2 mag should have @xmath1 m fluxes brighter than 5 mjy . </S>",
    "<S> our technique will allow the generation of wide - angle mock catalogues of galaxies selected at rest - frame uv or mid- and far - infrared wavelengths . </S>"
  ]
}