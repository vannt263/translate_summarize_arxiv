{
  "article_text": [
    "mathematical models are frequently highly tuned with parameters being given to many decimal places .",
    "these parameters are often fitted to a set of mean observational / experimental data and so the inherent variability in the underlying dynamical processes is not captured . a very recent approach for capturing this important and intrinsic variability",
    "is based around the concept of a population of models ( poms ) @xcite in which a mathematical model is built that has a set of points , rather than a single point , in parameter space , all of which are selected to fit a set of experimental / observational data .",
    "since first proposing the pom approach for neuroscience modelling , it has been extended to cardiac electrophysiology @xcite , @xcite . in that setting , biomarkers , such as action potential duration and beat - to - beat variability , are extracted from time course profiles and then the models are calibrated against these biomarkers .",
    "upper and lower values of each biomarker as observed in the experimental data are used to guarantee that estimates of variability are within biological ranges for any model to be included in the population .",
    "if the data can not be characterised by a set of biomarkers then time course profiles can be used and a normalised root - mean - square ( nrms ) comparison between the data values and the simulation values at a set of time points can be used to calibrate the population .",
    "this approach suggests a possible new way in which science is done .",
    "firstly , the pom approach leads to methodologies that are essentially probabilistic in nature .",
    "secondly , it gives greater weight to the experimentation , modelling , simulation feedback paradigm @xcite . by implementing experiments based on a population of models , as distinct from experiments based on a single model",
    ", the variability in the underlying structure can be captured by allowing changes in the parameters values .",
    "such an approach avoids complications arising from decisions on the use of `` best '' or `` mean '' data , and the difficulties of identifying such data .",
    "building populations of models requires the generation of a number of parameter sets for the initial population , sampled from a possibly high - dimensional parameter space . with recent advances in computational power , it is possible to generate large numbers of such models , leading to a better understanding of the systems under investigation .",
    "there are many ways to sample the parameter space , depending on costing constraints and therefore limits of computation .",
    "a parameter sweep will cover the whole parameter space at a certain discrete resolution , while random sampling , latin hypercube sampling ( lhs ) and orthogonal sampling ( os ) will give increasingly improved coverage of parameter space when the number of samples is fixed and independent of the dimension of the space .    in this paper",
    "we focus on lhs , a technique first introduced by mckay , beckman and conover @xcite .",
    "suppose that the @xmath1 dimensional parameter space is divided into @xmath2 equally sized subdivisions in each dimension .",
    "a latin hypercube ( lh ) trial is a set of @xmath2 random samples with one from each subdivision ; that is , each sample is the only one in each axis - aligned hyperplane containing it .",
    "mckay , beckman and conover suggested that the advantage of lhs is that the values for each dimension are fully stratified , while stein @xcite showed that with lhs there is a form of variance reduction compared with uniform random sampling . a variant of lhs , known as orthogonal sampling , adds the requirement that the entire sample space must be sampled evenly .    depending on the underlying application poms may be constructed in a number of different ways . in @xcite , @xcite , for example , poms are developed from lhs , a useful approach because it provides insights into the nature of variability in cardiac electrophysiology . in this case",
    "the coverage of parameter space , as long as it is random in some appropriate manner , is less of an issue than for the case where poms are used for parameter fitting . in this",
    "setting , poms have similarities with approximate bayesian computation ( abc ) @xcite .",
    "by contrast , in abc the sampling is usually performed adaptively so as to converge to subregions of parameter space where the calibrated models lie , as distinct from random sampling of the entire space .",
    "thus in certain circumstances , it is important to estimate the expected coverage of parameter space given @xmath3 latin hypercube trials of @xmath1-dimension .    in the paper @xcite the authors focused on estimating the expected coverage of a @xmath5-dimensional parameter space for a population of @xmath3 lh trials with each trial of size @xmath2 . in particular , counting arguments were used to predict the expected coverage of points in the parameter space after @xmath3 trials .",
    "these estimates were compared against numerical results based on a matlab implementation of 100 simulations .",
    "the results of the simulations led the authors to conjecture that the expected percentage coverage by @xmath3 trials of a @xmath5-dimensional parameter space , over values @xmath6 , tended to @xmath7 .",
    "as mckay , beckman and conover @xcite state an advantage of lhs is that it stratifies each univariate mean simultaneously .",
    "tang @xcite and others have suggested that it may also be important to stratify the bivariate margins .",
    "for instance , an experimental design may involve a large number of variables , but in reality only a relatively small number of these variables are virtually effective .",
    "one way of dealing with this problem has been to project the factors onto a subspace spanned by the effective variables .",
    "however this can result in a replication of sample points within the effective subspace .",
    "welch et al .",
    "@xcite suggest lhs as a method for screening for effective factors , but tang notes that there is still no guarantee that even in the case of bivariate margins that this projection is uniformly distributed .",
    "thus as an alternative , tang @xcite advocates orthogonal sampling and proposes a technique based on the existence of orthogonal arrays .",
    "he goes on to show that orthogonal sampling achieves uniformity on small dimensional margins and further that there is a form of variance reduction .",
    "approach is to start with an orthogonal array ( defined in section 2 ) and to replace its entries by random permutations to obtain an orthogonal sample .",
    "we will expand on this idea in section 2 , as well as describing an alternate method for orthogonal sampling .",
    "orthogonal arrays and covering arrays have been used also for generating interaction test suites for the testing of component - based systems .",
    "it is recognised that for large systems exhaustive testing may not be feasible , and instead suites are designed to test for @xmath0-way interactions , for @xmath8 ; for details see @xcite , @xcite . in @xcite and @xcite ,",
    "bryce and colbourn give a density based greedy algorithm for the generation of covering arrays for testing @xmath9 interactions . this research and",
    "that in @xcite have led us to investigate the relationship between experimental design and building poms .",
    "thus in this paper rather than focusing solely on the coverage of the @xmath1-dimensional parameter space we wish to investigate the coverage of these lower dimensional subspaces .",
    "the motivation for this is that resource constraints restricting the size of the population of models may preclude significant coverage of the entire parameter space .",
    "however , it may be desirable to know if such a population of models calibrates for interactions of `` small strength '' by checking for all possible combinations of levels for , say , pairs or triples of variables .",
    "this would equate to investigating the coverage of two and three dimensional subspaces .",
    "the justification is that statistical techniques may be used to compare results for pairwise or three - way interactions .",
    "we will approach this question through the use of both lhs and os .    in section 2",
    ", we will give further discussion on lhs and os .",
    "we will also briefly review tang s construction for orthogonal sampling and then given an alternate method for the generation of orthogonal samples . in section 3",
    "we report on matlab implementations of simulations of latin hypercube trials and orthogonal sampling to test for uniform coverage of lower dimensional subspaces . in section 4",
    "we discuss and summarise the results from section 3 as well as discussing future directions .",
    "before introducing constructions we review the well known methods used to generate latin hypercube samples and formalise the definitions for orthogonal samples .",
    "a latin hypercube trial generates an @xmath2 by @xmath1 matrix where each column is a random permutation of @xmath10 and then each row forms a @xmath1-tuple of the latin hypercube trial . thus given an experiment on @xmath1 variables each taking parameter values @xmath6 , a _ latin hypercube trial _ is a randomly generated subset of @xmath2 points from a @xmath1-dimensional parameter space satisfying the condition that the projections onto each of the @xmath11-dimensional subspaces are permutations ; so for each variable the @xmath2 points cover all possible parameter values for the corresponding subspace . by way of an example",
    "we take @xmath12 and @xmath13 giving below two latin hypercube trials lhs1 and lhs2 .",
    "@xmath14    formally , a latin hypercube trial @xmath15 is said to be an _ orthogonal sample _ ( os ) if @xmath16 and for each of the @xmath17 @xmath1-tuple of the form @xmath18 , where @xmath19 , there exists an element of @xmath15 of the form @xmath20 , where @xmath21 . in the above examples , @xmath12 and @xmath22 thus @xmath23 and @xmath24 .",
    "so we rewrite the numbers @xmath25 as @xmath26 , @xmath27 , @xmath28 , @xmath29 , @xmath30 , @xmath31 , @xmath32 and @xmath33 . using this representation",
    "we rewrite lhs1 as lhs3 and lhs2 as lhs4 .",
    "consider lhs3 and take the first two @xmath34-tuples @xmath35 and @xmath36 and project each ordered pair onto its first coordinate ; that is , @xmath37 and @xmath38 .",
    "then in the eight @xmath34-tuples of lhs3 we see @xmath39 twice , and so we can not get all distinct eight @xmath34-tuples on the set @xmath40 . therefore lhs3 is not an orthogonal sample , however we can check that lhs4 is an orthogonal sample .",
    "tang s @xcite construction for orthogonal samples is based on the existence of orthogonal arrays .",
    "these are structures that can be generalised to covering arrays .",
    "an _ orthogonal array _",
    "oa@xmath41 on @xmath1 factors , of strength @xmath42 over the set @xmath43 is a subset of the @xmath1-dimensional space @xmath44 with the property that the projection onto any of the @xmath45 @xmath0-dimensional subspace @xmath46 covers the entire subspace with multiplicity @xmath47 , where @xmath48 . in a _ covering array _",
    "the projections onto all @xmath0-dimensional subspaces cover the entire subspace with multiplicity at least @xmath47 .",
    "tang takes a random orthogonal array and replaces each value @xmath49 , @xmath50 , by an @xmath51 vector where the entries correspond to a random permutation on the set @xmath52 .",
    "the rows of this new @xmath53 form the tuples of a latin hypercube trial which is also an orthogonal sample .",
    "the random orthogonal array is achieved by taking an orthogonal array and randomly permuting rows , columns and values within a column .",
    "by contrast we have constructed @xmath1-dimensional orthogonal samples ( where variables take the values @xmath54 , for some positive integer @xmath55 ) using the following procedure :    procedure :    * open an @xmath56 array @xmath57 $ ] and an @xmath58 array @xmath59 $ ] . *",
    "generate all possible @xmath17 @xmath1-tuples with entries chosen from @xmath60 .",
    "* assign each @xmath1-tuple to a separate row of @xmath61 . then if @xmath62 is assigned to row @xmath63 , set @xmath64 , @xmath65 .",
    "* for each @xmath65 columns @xmath66 and @xmath67 are filled as follows . for each @xmath68 , identify all rows @xmath63 such that @xmath69 .",
    "note that there are @xmath70 rows for each @xmath49 .",
    "generate a random permutation on the set @xmath71 and assign these values sequentially to the @xmath72 entries @xmath73 . * for @xmath74 and @xmath65 set @xmath75 .",
    "it is now easy to check that @xmath76 satisfies the definition of a latin hypercube trial and also an orthogonal sample .",
    "in @xcite we used matlab simulations to make conjectures about the coverage of parameter space in terms of the number @xmath3 of latin hypercube trials given the variable size @xmath2 for dimension @xmath77 . in this section we look at the coverage of @xmath78 and @xmath79 dimensional subspaces in the @xmath80 dimensional parameter space .",
    "@xmath81{fig1d3t2.eps } & \\includegraphics[width=0.45\\textwidth]{fig2d3t3.eps } \\label{fig - d3 } \\end{array}\\ ] ]    @xmath81{fig3d4t2.eps } & \\includegraphics[width=0.45\\textwidth]{fig4d4t3.eps } \\label{fig - d4 } \\end{array}\\ ] ]    @xmath81{fig5d5t2.eps } & \\includegraphics[width=0.45\\textwidth]{fig6d5t3.eps } \\label{fig - d5 } \\end{array}\\ ] ]    @xmath81{fig7d4t4.eps } & \\includegraphics[width=0.45\\textwidth]{fig8d5t4.eps } \\label{fig-4tuples } \\end{array}\\ ] ]    in fig ( [ fig - d3 ] ) we show lhs results when @xmath12 , for 2-tuples and 3-tuples , with coverage 25% , 50% , 75% and 100% .",
    "fig ( [ fig - d4 ] ) shows lhs results when @xmath82 , and fig ( [ fig - d5 ] ) gives the @xmath83 results .",
    "all the quantities have been averaged over 200 trials , and the graphs plot the @xmath84 of the data .",
    "when we look at the 2-dimensional subspaces ( @xmath85 ) with @xmath86 , we observe that the number of trials required for a specific percentage coverage is similar , regardless of the dimension @xmath1 of the system .",
    "in particular , the gradient at 25% , 50% , 75% coverage is 1 , while the gradient at 100% coverage is approximately 1.25 for all values at @xmath86 . we observe a correspondingly similar behaviour for 3d subspaces ( @xmath79 ) for @xmath86 , except in these cases the gradient is 2 for incomplete coverage and approximately 2.3 for 100% coverage .    in @xcite we suggested that in the case @xmath77 the percentage cover for @xmath3 trials and @xmath2 divisions is @xmath7 .",
    "the results here with @xmath87 and @xmath88 suggest that the percentage coverage when @xmath89 is given by    @xmath90 and that in the asymptotic limit as @xmath3 becomes large then @xmath91    more generally we conjecture for any @xmath92 that    @xmath93 and that in the asymptotic limit as @xmath3 becomes large then @xmath94    this is consistent with the 25% , 50% , 75% coverage in which the gradient of the log data is @xmath95 . the only question to address is why the gradient is slightly larger than @xmath95 for 100% coverage . to see this",
    "we see that 100% coverage implies @xmath96 .",
    "thus under our conjecture    @xmath97 or    @xmath98 using the fact that @xmath99 for @xmath55 small , then this implies    @xmath100 and so @xmath101 it is this latter term that gives an apparent gradient slightly larger than @xmath95 .    thus we make the following conjecture    * conjecture : * the coverage of a @xmath0 dimensional subspace of a @xmath1 dimensional parameter space of size @xmath2 when performing @xmath3 trials of latin hypercube sampling is given by @xmath102 or @xmath103 when @xmath3 is large .",
    "thus if costs and/or experimental factors influence the size of the sample , we can use this information to direct our experiments .",
    "so this builds confidence in the modelling results .    for lhs ,",
    "where @xmath12 and @xmath104 , we investigate the variability ( see fig ( [ fig - theory ] ) ) in coverage of the sub - blocks of the @xmath5-dimensional spaces , and compare this with orthogonal sampling where by design the coverage is uniform over the sub - blocks .",
    "the results in the bar graphs can be interpreted by taking a 3-dimensional parameter space , where each of the three variables takes @xmath105 distinct levels .",
    "then we partition each 1-dimensional space into @xmath106 sub - blocks of size @xmath107 .",
    "we are interested in counting the number of points that lie in each @xmath108 sub - block when projected onto the 2-dimensional subspaces .",
    "our simulations take the average number of latin hypercube trials needed to cover 25% and 75% of the parameter space and then count the number of points in each of the 2-dimensional sub - blocks .",
    "this number is taken as a fraction of the number of trials . for orthogonal sampling",
    "this fraction is 1 across all sub - blocks but as can be seen from the figures , there is much variability when the points are generated using latin hypercube trials .",
    "@xmath109{bar2dsubblocks25.eps } \\end{array } & \\begin{array}{c } \\includegraphics[width=0.5\\textwidth , height = 0.4\\textheight]{bar2dsubblocks75.eps } \\end{array } \\label{fig - theory } \\end{array}\\ ] ]    this emphasises the value of orthogonal sampling versus latin hypercube sampling , where the latter is shown to not cover the sample space uniformly at percentage coverings that are less than 100% .",
    "in this paper we have used simulations to give a conjecture about the coverage of a @xmath0 dimensional subspace of a @xmath1 dimensional parameter space of size @xmath2 when performing @xmath3 trials of latin hypercube sampling .",
    "this coverage takes the form @xmath110 or @xmath103 when @xmath3 is large .",
    "this extends the work in @xcite .",
    "we suggest that the coverage is independent of @xmath1 and this allows us to make connections between building populations of models and experimental designs .",
    "we also show that orthogonal sampling is superior to latin hypercube sampling in terms of giving a more uniform coverage of the @xmath0 dimensional subspace at the sub - block size level when only attempting partial coverage of this subspace .",
    "we will attempt to prove our conjecture analytically in a subsequent paper .",
    "50 o. j. britton ; a. bueno - orovio , k. van ammel , h.r .",
    "luc , r. towart , d.j .",
    "gallacher and b. rodriguez , experimentally calibrated population of models predicts and explains inter subject variability in cardiac cellular electrophysiology , _ pnas _ , 2014 , doi:10.1073/pnas.1304382110 .",
    "k. burrage , p.m. burrage , d. donovan , t. mccourt and h.b .",
    "thompson , estimates on the coverage of parameter space using populations of models , _ modelling and simulation , iasted , acta press _ , 2014 ,",
    "doi : 10.2316/p.2014.813 - 013 .",
    "a. carusi , k. burrage and b. rodriguez , bridging experiments , models and simulations : an integrative approach to validation in computational cardiac electrophysiology , _ am .",
    "j. physiology _ , * 303(2 ) * , 2012 , h14455 .",
    "c. c. drovandi , a. n. pettitt and m. j. faddy , approximate bayesian computation using indirect inference , _ journal of the royal statistical society : series c ( applied statistics ) _ , * 60(3 ) * , 2011 , 317-337 .",
    "e. marder and a. l.taylor , multiple models to capture the variability of biological neurons and networks , _ computation and systems , nature neuroscience _ , * 14(2 ) * , 2011 , 133138 .",
    "mckay , r.j .",
    "beckman and w.j .",
    "conover , a comparison of three methods for selecting values of input variables in the analysis of output from a computer code , _ technometrics _ , * 21(2 ) * , 1979 , 239245 .",
    "j. walmsley , j.f .",
    "rodriguez , g.r .",
    "mirams , k. burrage , i. r. efimov and b. rodriguez , mrna expression levels in failing human hearts predict cellular electrophysiological remodelling : a population based simulation study , _ plos one _ , * 8(2 ) * , 2013 , e56359"
  ],
  "abstract_text": [
    "<S> in this paper we have used simulations to make a conjecture about the coverage of a @xmath0 dimensional subspace of a @xmath1 dimensional parameter space of size @xmath2 when performing @xmath3 trials of latin hypercube sampling . </S>",
    "<S> this takes the form @xmath4 . </S>",
    "<S> we suggest that this coverage formula is independent of @xmath1 and this allows us to make connections between building populations of models and experimental designs . </S>",
    "<S> we also show that orthogonal sampling is superior to latin hypercube sampling in terms of allowing a more uniform coverage of the @xmath0 dimensional subspace at the sub - block size level . </S>"
  ]
}