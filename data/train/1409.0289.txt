{
  "article_text": [
    "determining connectivity in populations of neurons is fundamental to understanding neural computation and function . in recent years",
    ", calcium imaging has emerged as a promising technique for measuring synaptic activity and mapping neural micro - circuits  @xcite .",
    "fluorescent calcium - sensitive dyes and genetically - encoded calcium indicators can be loaded into neurons , which can then be imaged for spiking activity either _ in vivo _ or _ in vitro_. current methods enable imaging populations of hundreds to thousands of neurons with very high spatial resolution . using two - photon microscopy",
    ", imaging can also be localized to specific depths and cortical layers @xcite .",
    "calcium imaging also has the potential to be combined with optogenetic stimulation techniques such as in @xcite .",
    "however , inferring neural connectivity from calcium imaging remains a mathematically and computationally challenging problem . unlike anatomical methods ,",
    "calcium imaging does not directly measure connections .",
    "instead , connections must be inferred indirectly from statistical relationships between spike activities of different neurons .",
    "in addition , the measurements of the spikes from calcium imaging are indirect and noisy .",
    "most importantly , the imaging introduces significant temporal blurring of the spike times : the typical time constants for the decay of the fluorescent calcium concentration , @xmath0 , can be on the order of a second  orders of magnitude slower than the spike rates and inter - neuron dynamics .",
    "moreover , the calcium imaging frame rate remains relatively slow  often less than 100  hz .",
    "hence , determining connectivity typically requires super - resolution of spike times within the frame period .    to overcome these challenges , the recent work @xcite proposed a bayesian inference method to estimate functional connectivity from calcium imaging in a systematic manner . unlike  model - free \" approaches such as in  @xcite , the method in @xcite assumed a detailed functional model of the neural dynamics with unknown parameters including a connectivity weight matrix @xmath1 . the model parameters including the connectivity matrix",
    "can then be estimated via a standard em procedure  @xcite .",
    "while the method is general , one of the challenges in implementing the algorithm is the computational complexity .",
    "as we discuss below , the e - step in the em procedure essentially requires estimating the distributions of hidden states in a nonlinear dynamical system whose state dimension grows linearly with the number of neurons .",
    "since exact computation of these densities grows exponentially in the state dimension , @xcite uses an approximate method based on blockwise gibbs sampling where each block of variables consists of the hidden states associated with one neuron .",
    "since the variables within a block are described as a low - dimensional dynamical system , the updates of the densities for the gibbs sampling can be computed efficiently via a standard particle filter @xcite .",
    "however , simulations of the method show that the mixing between blocks can still take considerable time to converge .",
    "this paper presents two novel contributions that can potentially significantly improve the computation time of the em estimation as well as the generality of the model .",
    "the first contribution is to employ an approximate message passing ( amp ) technique in the computationally difficult em step .",
    "the key insight here is to recognize that a system with multiple neurons can be `` factorized '' into simple , scalar dynamical systems for each neuron with linear interactions between the neurons .",
    "as described below , we assume a standard leaky integrate - and - fire ( lif ) model for each neuron @xcite and a first - order ar process for the calcium imaging  @xcite . under this model ,",
    "the dynamics of @xmath2 neurons can be described by @xmath3 systems , each with a scalar ( i.e.  one - dimensional ) state .",
    "the coupling between the systems will be linear as described by the connectivity matrix @xmath1 . using this factorization , approximate state estimation",
    "can then be efficiently performed via approximations of loopy belief propagation ( bp ) @xcite .",
    "specifically , we show that the loopy bp updates at each of the factor nodes associated with the integrate - and - fire and calcium imaging can be performed via a scalar standard forward ",
    "backward filter . for the updates associated with",
    "the linear transform @xmath1 , we use recently - developed approximate message passing ( amp ) methods .    amp was originally proposed in @xcite for problems in compressed sensing .",
    "similar to expectation propagation @xcite , amp methods use gaussian and quadratic approximations of loopy bp but with further simplifications that leverage the linear interactions .",
    "amp was used for neural mapping from multi - neuron excitation and neural receptive field estimation in  @xcite . here",
    ", we use a so - called hybrid amp technique proposed in @xcite that combines amp updates across the linear coupling terms with standard loopy bp updates on the remainder of the system . when applied to the neural system , we show that the estimation updates become remarkably simple : for a system with @xmath2 neurons , each iteration involves running @xmath3 forward  backward scalar state estimation algorithms , along with multiplications by @xmath1 and @xmath4 at each time step .",
    "the practical complexity scales as @xmath5 where @xmath6 is the number of time steps .",
    "we demonstrate that the method can be significantly faster than the blockwise gibbs sampling proposed in @xcite , with similar accuracy .",
    "in addition to the potential computational improvement , the amp - based procedure is somewhat more general .",
    "for example , the approach in @xcite assumes a generalized linear model ( glm ) for the spike rate of each neuron .",
    "the approach in this work can be theoretically applied to arbitrary scalar dynamics that describe spiking . in particular , the approach can incorporate a physically more realistic lif model .    the second contribution is a novel method for initial estimation of the connectivity matrix . since we are applying the em methodology to a fundamentally non - convex problem ,",
    "the algorithm is sensitive to the initial condition .",
    "however , there are now several good approaches for initial estimation the spike times of each neuron from its calcium trace via sparse deconvolution @xcite .",
    "we show that , under a leaky integrate and fire model , that if the true spike times were known exactly , then the maximum likelihood ( ml ) estimation of the connectivity matrix can be performed via sparse probit regression  a standard convex programming problem used in classification @xcite . we propose to obtain an initial estimate for the connectivity matrix @xmath1 by applying the sparse probit regression to the initial estimate of the spike times .",
    "we consider a recurrent network of @xmath2 spontaneously firing neurons .",
    "all dynamics are approximated in discrete time with some time step @xmath7 , with a typical value @xmath7 = 1 ms .",
    "importantly , this time step is typically smaller than the calcium imaging period , so the model captures the dynamics between observations .",
    "time bins are indexed by @xmath8 , where @xmath6 is the number of time bins so that @xmath9 is the total observation time in seconds .",
    "each neuron @xmath10 generates a sequence of spikes ( action potentials ) indicated by random variables @xmath11 taking values @xmath12 or @xmath13 to represent whether there was a spike in time bin @xmath14 or not .",
    "it is assumed that the discretization step @xmath7 is sufficiently small such that there is at most one action potential from a neuron in any one time bin .",
    "the spikes are generated via a standard leaky integrate - and - fire ( lif ) model @xcite where the ( single compartment ) membrane voltage @xmath15 of each neuron @xmath10 and its corresponding spike output sequence @xmath11 evolve as [ eq : vlif ] _",
    "i^1 = ( 1-_if)v_i^k + q_i^k + d_v_i^k , q_i^k = _",
    "j=1^n w_ijs_j^k- + b_if , i , d_v_i^k ~n(0,_if ) , and [ eq : vireset ] ( v_i^1,s_i^1 ) =    ( _ i^k , 0 ) & v_i^k < , + ( 0 , 1 ) & _ i^k ,    where @xmath16 is a time constant for the integration leakage ; @xmath17 is the threshold potential at which the neurons spikes ; @xmath18 is a constant bias term ; @xmath19 is the increase in the membrane potential from the pre - synaptic spikes from other neurons and @xmath20 is a noise term including both thermal noise and currents from other neurons that are outside the observation window .",
    "the voltage has been scaled so that the reset voltage is zero .",
    "the parameter @xmath21 is the integer delay ( in units of the time step @xmath7 ) between the spike in one neuron and the increase in the membrane voltage in the post - synaptic neuron .",
    "an implicit assumption in this model is the post - synaptic current arrives in a single time bin with a fixed delay .    to determine functional connectivity ,",
    "the key parameter to estimate will be the matrix @xmath1 of the weighting terms @xmath22 in .",
    "each parameter @xmath22 represents the increase in the membrane voltage in neuron @xmath10 due to the current triggered from a spike in neuron @xmath23 .",
    "the connectivity weight @xmath22 will be zero whenever neuron @xmath23 has no connection to neuron @xmath10 .",
    "thus , determining @xmath1 will determine which neurons are connected to one another and the strengths of those connections .",
    "for the calcium imaging , we use a standard model  @xcite , where the concentration of fluorescent calcium has a fast initial rise upon an action potential followed by a slow exponential decay . specifically , we let @xmath24 be the concentration of fluorescent calcium in neuron @xmath10 in time bin @xmath14 and assume it evolves as first - order auto - regressive @xmath25 model , [ eq : zk ] z_i^1 = ( 1-_ca , i)z_i^k + s_i^k , where @xmath26 is the calcium time constant . the observed net fluorescence level is then given by a noisy version of @xmath27 , [ eq : yk ] y_i^k = a_ca ,",
    "i z_i^k + b_ca , i + d_y_i^k , d_y_i^k ~n(0,_y ) , where @xmath28 and @xmath29 are constants and @xmath30 is white gaussian noise with variance @xmath31 .",
    "nonlinearities such as saturation described in @xcite can also be modeled .    as mentioned in the introduction , a key challenge in calcium imaging",
    "is the relatively slow frame rate which has the effect of subsampling of the fluorescence . to model the subsampling , we let @xmath32 denote the set of time indices @xmath14 on which we observe @xmath33 .",
    "we will assume that fluorescence values are observed once every @xmath34 time steps for some integer period @xmath34 so that @xmath35 where @xmath36 is the number of calcium image frames .",
    "let @xmath37 be set of all the unknown parameters , [ eq : thetadef ] = \\ { , _",
    "if , _ ca , _ if , b_if , i , _ ca , a_ca , i , b_ca , i , i=1,  ,n } , which includes the connectivity matrix , time constants and various variances and bias terms . estimating the parameter set @xmath37 will provide an estimate of the connectivity matrix @xmath1 , which is our main goal .    to estimate @xmath37",
    ", we consider a regularized maximum likelihood ( ml ) estimate [ eq : thetaml ] = _ l(| ) + ( ) , l(| ) = -p(| ) , where @xmath38 is the set of observed values ; @xmath39 is the negative log likelihood of @xmath38 given the parameters @xmath37 and @xmath40 is some regularization function . for the calcium imaging problem ,",
    "the observations @xmath38 are the observed fluorescence values across all the neurons , [ eq : yveci ] = \\ { _ 1,  ,_n } , _",
    "i = \\ { y_i^k , k i_f } , where @xmath41 is the set of fluorescence values from neuron @xmath10 , and , as mentioned above , @xmath32 is the set of time indices @xmath14 on which the fluorescence is sampled .    the regularization function @xmath40 can be used to impose constraints or priors on the parameters . in this work , we will assume a simple regularizer that only constrains the connectivity matrix @xmath1 , [ eq : phiell1 ] ( ) = _ 1 , _ 1 : = _ ij |w_ij| , where @xmath42 is a positive constant .",
    "the @xmath43 regularizer is a standard convex function used to encourage sparsity @xcite , which we know in this case must be valid since most neurons are not connected to one another .",
    "exact computation of @xmath44 in is generally intractable , since the observed fluorescence values @xmath38 depend on the unknown parameters @xmath37 through a large set of hidden variables .",
    "similar to @xcite , we thus use a standard em procedure @xcite . to apply the em procedure to the calcium imaging problem ,",
    "let @xmath45 be the set of hidden variables , [ eq : xdef ] = \\ { , , , } , where @xmath46 are the membrane voltages of the neurons , @xmath47 the calcium concentrations , @xmath48 the spike outputs and @xmath49 the linearly combined spike inputs .",
    "for any of these variables , we will use the subscript @xmath10 ( e.g.  @xmath50 ) to denote the values of the variables of a particular neuron @xmath10 across all time steps and superscript @xmath14 ( e.g.  @xmath51 ) to denote the values across all neurons at a particular time step @xmath14 .",
    "thus , for the membrane voltage @xmath52    the em procedure alternately estimates distributions on the hidden variables @xmath45 given the current parameter estimate for @xmath37 ( the e - step ) ; and then updates the estimates for parameter vector @xmath37 given the current distribution on the hidden variables @xmath45 ( the m - step ) .",
    "* _ e - step : _ given parameter estimates @xmath53 , estimate [ eq : estepdist ] p(|,^ ) , which is the posterior distribution of the hidden variables @xmath45 given the observations @xmath38 and current parameter estimate @xmath53 . *",
    "_ m - step _ update the parameter estimate via the minimization , [ eq : mstep ] ^+1 = _ + ( ) , where @xmath54 is the joint negative log likelihood , [ eq : lxytheta ] l(,| ) = - p(,| ) . in the expectation is with respect to the distribution found in and @xmath40 is the parameter regularization function .",
    "the next two sections will describe how we approximately perform each of these steps .      for the calcium imaging problem ,",
    "the challenging step of the em procedure is the e - step , since the hidden variables @xmath45 to be estimated are the states and outputs of a high - dimensional nonlinear dynamical system . under the model in section  [ sec : model ] , a system with @xmath2 neurons will require @xmath2 states for the membrane voltages @xmath15 and @xmath2 states for the bound ca concentration levels @xmath27 , resulting in a total state dimension of @xmath3 .",
    "the e - step for this system is essentially a state estimation problem , and exact inference of the states of a general nonlinear dynamical system grows exponentially in the state dimension .",
    "hence , exact computation of the posterior distribution for the system will be intractable even for a moderately sized network .    as described in the introduction , we thus use an approximate messaging passing method that exploits the separable structure of the system . for the remainder of this section",
    ", we will assume the parameters @xmath37 in are fixed to the current parameter estimate @xmath53 .",
    "then , under the assumptions of section  [ sec : model ] , the joint probability distribution function of the variables can be written in a factorized form , [ eq : pxyfact ] p ( , ) = p ( , , , , ) = _",
    "k=0 ^ 1 _ \\ { ^k = ^k } _ i=1^n ^if_i(_i,_i,_i )",
    "^ca_i(_i,_i,_i ) , where @xmath55 is a normalization constant ; @xmath56 is the potential function relating the summed spike inputs @xmath57 to the membrane voltages @xmath50 and spike outputs @xmath58 ; @xmath59 relates the spike outputs @xmath58 to the bound calcium concentrations @xmath60 and observed fluorescence values @xmath41 ; and the term @xmath61 indicates that the distribution is to be restricted to the set satisfying the linear constraints @xmath62 across all time steps @xmath14 .",
    "as in standard loopy bp @xcite , we represent the distribution in a _ factor graph _ as shown in fig .",
    "[ fig : factorgraph ] .",
    "now , for the e - step , we need to compute the marginals of the posterior distribution @xmath63 from the joint distribution . using the factor graph representation ,",
    "loopy bp iteratively updates estimates of these marginal posterior distributions using a message passing procedure , where the estimates of the distributions ( called beliefs ) are passed between the variable and factor nodes in the graph .    to reduce the computations in loopy bp further",
    ", we employ an approximate message passing ( amp ) method for the updates in the factor node corresponding to the linear constraints @xmath62 .",
    "amp was originally developed in @xcite for problems in compressed sensing , and can be derived as gaussian approximations of loopy bp @xcite similar to expectation propagation @xcite . in this work ,",
    "we employ a hybrid form of amp @xcite that combines amp with standard message passing .",
    "the amp methods have the benefit of being computationally very fast and , for problems with certain large random transforms , the methods can yield provably bayes - optimal estimates of the posteriors , even in certain non - convex problem instances .",
    "however , similar to standard loopy bp , the amp and its variants may diverge for general transforms ( see @xcite for some discussion of the convergence ) . for our problem , we will see in simulations that we obtain fast convergence in a relatively small number of iterations .",
    "= [ circle , draw , fill = orange!30 ] = [ circle , draw , fill = orange!70 ] = [ rectangle , draw , fill = green!30 ]    ( qi ) @xmath57 ; ( psiif )    [ cols=\"^ \" , ]",
    "the method was tested using realistic network parameters , as shown in table  [ tbl : simparam ] , similar to those found in neurons networks within a cortical column  @xcite .",
    "similar parameters are used in @xcite .",
    "the network consisted of 100 neurons with each neuron randomly connected to 10% of the other neurons .",
    "the non - zero weights @xmath22 were drawn from an exponential distribution .",
    "all weights were positive ( i.e. the neurons were excitatory  there were no inhibitory neurons in the simulation ) . however , inhibitory neurons can also be added . a typical random matrix @xmath1 generated in this manner would not in general result in a stable system . to stabilize the system , we followed the procedure in @xcite where the system is simulated multiple times .",
    "after each simulation , the rows of the matrix @xmath1 were adjusted up or down to increase or decrease the spike rate until all neurons spiked at a desired target rate . in this case , we assumed a desired average spike rate of 10  hz .    from the parameters in table",
    "[ tbl : simparam ] , we can immediately see the challenges in the estimation .",
    "most importantly , the calcium imaging time constant @xmath26 is set for 500  ms . since the average neurons spike rate is assumed to be 10  hz , several spikes will typically appear within a single time constant .",
    "moreover , both the integration time constant and inter - neuron conduction time are much smaller than both the image frame rate and calcium time constants .    a typical simulation of the network after the stabilization is shown in fig .  [ fig : canetsim ] . observe that due to the random connectivity , spiking in one neuron can rapidly cause the entire network to fire .",
    "this appears as the vertical bright stripes in the lower panel of fig .",
    "[ fig : canetsim ] .",
    "this synchronization makes the connectivity detection difficult to detect under temporal blurring of ca imaging since it is hard to determine which neuron is causing which neuron to fire .",
    "thus , the random matrix is a particularly challenging test case .     ,",
    "title=\"fig:\",scaledwidth=40.0% ]   , title=\"fig:\",scaledwidth=40.0% ]    the results of the estimation are shown in fig .",
    "[ fig : simresults ] .",
    "the left panel shows the relative mean squared error defined as [ eq : relmse ] = , where @xmath64 is the estimate for the weight @xmath22 .",
    "the minimization over all @xmath65 is performed since the method can only estimate the weights up to a constant scaling .",
    "the relative mse is plotted as a function of the em iteration , where we have performed only a single loopy bp iteration for each em iteration .",
    "we see that after only 30 iterations we obtain a relative mse of 7%  a number at least comparable to earlier results in @xcite , but with significantly less computation .",
    "the right panel shows a scatter plot of the estimated weights @xmath64 against the true weights @xmath22 .",
    "we have presented a scalable method for inferring connectivity in neural systems from calcium imaging . the method is based on factorizing the systems into scalar dynamical systems with linear connections . once in this",
    "form , state estimation  the key computationally challenging component of the em estimation  is tractable via approximating message passing methods .",
    "the key next step in the work is to test the methods on real data and also provide more comprehensive computational comparisons against current techniques such as @xcite .",
    "as described in section  [ sec : estep ] , the e - step inference is performed via an approximate message passing technique @xcite . as in standard sum - product",
    "loopy bp @xcite , the algorithm is based on passing  belief messages \" between the variable and factor nodes representing estimates of the posterior marginals of the variables . referring to the factor graph in fig .",
    "[ fig : factorgraph ] , we will use the subscripts @xmath66 , @xmath67 and @xmath68 to refer respectively to the factor nodes for integrate and fire potential functions @xmath69 , the calcium imaging potential functions @xmath70 and the linear constraints @xmath71 .",
    "we use the subscripts @xmath72 and @xmath73 to refer to the variable nodes for @xmath49 and @xmath48 .",
    "we use the notation such as @xmath74 to denote the belief message to the variable node @xmath19 from the integrate and factor node @xmath69 .",
    "similarly , @xmath75 will denote the reverse message from the variable node to the factor node .",
    "the messages to and from the variable nodes @xmath11 are binary : @xmath76 or 1 .",
    "hence , they can be parameterized by a single scalar .",
    "similar to expectation propagation @xcite , the messages to and from the variable nodes @xmath19 are approximated as gaussians , so that we only need to maintain the first and second moments .",
    "gaussian approximations are used in the variational bayes method for calcium imaging inference in @xcite .    to apply the hybrid amp algorithm of @xcite to the factor graph in fig .",
    "[ fig : factorgraph ] , we use standard loopy bp message updates on the if and ca factor nodes , and amp updates on the linear constraints @xmath71 . the amp updates are based on linear - gaussian approximations . the details of the messages updates are as follows .",
    "[ [ messages - from - psiif_i ] ] messages from @xmath69 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this factor node represents the integrate and fire system for the voltages @xmath15 and is given by [ eq : psiif ] ^if_i(_i,_i,_i ) = _",
    "k=0 ^ 1 p(v_i^1,s_i^1|v_i^k , q_i^k ) , where the conditional density @xmath77 is given by integrate and fire system and .",
    "to describe the output belief propagation messages for this factor node , define the joint distribution , + & = & _ k=0 ^ 1 p(v_i^1,s_i^1|v_i^k , q_i^k ) p_if q(q_i^k)p_if s(s_i^k ) , [ eq : pifjoint ] where @xmath75 and @xmath78 are the incoming messages from the variable nodes . to compute the output messages , we must first compute the marginal densities @xmath79 and @xmath80 of this joint distribution .    to compute these marginal densities ,",
    "define @xmath81 . now recall that the amp assumption is that each incoming distribution @xmath75 is gaussian .",
    "let @xmath82 and @xmath83 be the mean and variance of this distribution .",
    "thus , the joint distribution is identical to the posterior distribution of a linear system with a gaussian input [ eq : vlifi ] _",
    "i^k = ( 1-_if)_i^k + _ i^k , _",
    "i^k ~n(_i^k+b_i,_q_i^k + _ if ) , with the reset and spike output in and output observations @xmath84 .",
    "this is a nonlinear system with a one - dimensional state @xmath15 .",
    "hence , one can , in principle , approximately compute the marginal densities @xmath79 and @xmath80 of with a one - dimensional particle filter  @xcite . however , we found it computationally faster to simply use a fixed discretization of the set of values @xmath15 . in the experiments below we used @xmath85",
    "20 values linearly spaced from 0 to the threshold level @xmath17 .",
    "using the fixed discretization enables a number of the computations to be computed once for all time steps , and also removes the computations and logic for pruning necessary in particle filtering . after computing the marginals @xmath79 and @xmath80 ,",
    "we set the output messages as @xmath86    [ [ messages - from - psica_i ] ] messages from @xmath70 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in this case , the factor node represents the ca imaging dynamics and is given by , [ eq : psica ] ^ca_i(_i,_i,_i ) = _",
    "k=0 ^ 1 p(z_i^1|z_i^k , s_i^k ) _ k i_f p(y_i^k|z_i^k ) , where @xmath87 and @xmath88 are given by the relations and describing the fluorescent ca@xmath89 concentration evolution and observed fluorescence . recall that @xmath32 in is the set of time samples on which the output @xmath90 is observed . to compute the output beliefs for the factor node , as before , we define the joint distribution , + & = & _ k=0 ^ 1 p(z_i^1|z_i^k , s_i^k)p_ca s(s_i^k ) _ k i_f p(y_i^k|z_i^k ) , [ eq : pcajoint ] where @xmath91 are the input messages from the variable nodes @xmath11 .",
    "this distribution @xmath92 is identical to a the distribution for a linear system with a scalar state @xmath27 , gaussian observations @xmath90 and a discrete zero - one input @xmath11 with prior @xmath91 .",
    "similar to the integrate - and - fire case , we can approximately compute the posterior marginals @xmath93 by discretizing the states @xmath27 and using a standard forward ",
    "backward estimator . from the posterior marginals",
    "@xmath93 , we can then compute the belief messages for the factor node back to the variable nodes @xmath11 : @xmath94 .    [ [ amp - messages - from - the - linear - constraints - qbfkwbfsbfk ] ] amp messages from the linear constraints @xmath71 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    standard loopy bp updates for this factor node would be intractable for typical connectivity matrices @xmath1 . to see this , suppose that in the current estimate for the connection matrix @xmath1 , each neuron is connected to @xmath95 other neurons .",
    "hence the rows of @xmath1 will have @xmath95 non - zero entries .",
    "each constraints @xmath96 will thus involve @xmath95 binary variables , and the complexity of the loopy bp update will then require @xmath97 operations .",
    "this computation will be difficult for large @xmath95 .",
    "the hybrid amp algorithm of @xcite uses gaussian approximations on the messages to reduce the computations to simple linear transforms .",
    "first consider the output messages @xmath98 to the variable nodes @xmath19 .",
    "these messages are gaussians .",
    "let @xmath82 and @xmath99 be their mean and variance and let @xmath100 and @xmath101 be the vector of these quantities . in the hybrid amp algorithm , these means and variances are given by [ eq : qgamp ] ^k = ^k - _ q^k^k , _",
    "q^k = ||^2_s^k , where @xmath102 and @xmath103 are the vectors of means and variances from the incoming messages @xmath104 , and @xmath105 is the matrix with components @xmath106 .",
    "the variables @xmath107 is a real - valued state vector , which is initialized to zero . in , the multiplication @xmath108 is to be performed componentwise : @xmath109 .    to process the incoming belief messages from the variable nodes @xmath110 ,",
    "let @xmath111 and @xmath112 be the vector of mean and variances of the incoming beliefs @xmath113 .",
    "these quantities are to be distinguished from @xmath100 and @xmath101 , the mean and variance vectors of the outgoing messages @xmath114 .",
    "we then first compute , ^k = ( ^k - ^k)/_q^k , _ p^k = , where the divisions are componentwise .",
    "next , we compute the quantities ^k = ^k + _ s^k ^t^k , _",
    "s^k = 1/(||^2_p^k ) , where , again , the divisions are componentwise and the multiplication between @xmath103 and @xmath115 is componentwise .",
    "the output message to the variable nodes @xmath116 is then given by @xmath117 with possible values @xmath118 or 1 .",
    "[ [ variable - node - updates ] ] variable node updates : + + + + + + + + + + + + + + + + + + + + + +    the variable node updates are based on the standard sum - product rule @xcite . in the factor graph in fig .",
    "[ fig : factorgraph ] , each variable nodes @xmath19 is only connected to two factor nodes : the factor node for the potential function @xmath69 and the factor node for the linear constraint @xmath62 .",
    "hence , the variable node will simply relay the messages between the nodes : @xmath119 recall that these messages are approximated as gaussians , so the messages can be represented by mean and variances .",
    "each binary spike variable nodes @xmath11 is connected to three factor nodes : the integrate and fire potential function @xmath69 , the calcium imaging potential function @xmath70 and the linear constraint @xmath62 . in the sum - product rule ,",
    "the output message to any one of these nodes is the product of the incoming messages from the other two .",
    "hence , & & p_if s(s_i^k ) p_w s(s_i^k)p_q s(s_i^k ) , p_ca s(s_i^k ) p_w s(s_i^k)p_if s(s_i^k ) , + & & p_w s(s_i^k ) p_ca s(s_i^k)p_if s(s_i^k ) .",
    "the proportionality constant is simple to compute since the variables are binary so that @xmath76 or 1 .",
    "we show that given the spike sequence @xmath11 , the maximum likelihood estimate of the connectivity weights @xmath1 and bias terms @xmath18 can be computed approximately via a sparse probit regression of the form . to this end , suppose that we know the true spike sequence @xmath11 for all neurons @xmath10 and times @xmath14 .",
    "let @xmath120 , be the index of time bins @xmath14 where there is a spike ( i.e.  @xmath121 when @xmath122 for some @xmath123 ) .",
    "now , consider any time @xmath14 between two spikes @xmath124 .",
    "since @xmath121 at the initial time @xmath125 , shows that the voltage must starts at zero : @xmath126 . integrating from this initial condition",
    ", we have that for any @xmath127 , [ eq : vtildeu ] _ i^k = _",
    "j=1^n w_iju_j^k + ( k - t_i^)b_if , i + _ i^k , u_j^k = _ m=0^k - t_i^-1 ( 1-_if)^m s_i^k - m- , where @xmath128 is the integration of the gaussian noise @xmath20 up to time @xmath14 .",
    "we can rewrite in vector form [ eq : vtildeuvec ] _",
    "i^k = _ k^t _ i + c_ikb_if , i + _ i^k , where @xmath129 and @xmath130 are the vectors with the components @xmath22 and @xmath131 and @xmath132 .",
    "now , let @xmath133 be the set of spikes @xmath134 for all @xmath23 and all time bins @xmath135 , so that @xmath136 represents the past spike events .",
    "observe that in the model , the vector @xmath137 can be computed from @xmath136 and the noise @xmath138 is independent of @xmath133 . also , from , @xmath139 if and only if @xmath140 .",
    "hence , we have that the conditional probability of the spike event at some time @xmath141 , given the past spikes is [ eq : psreg ] p(s_i^1=1|a_k ) = ( ) , where @xmath142 is the variance of @xmath128 in , and @xmath143 is the cumulative distribution function of a unit gaussian . given the conditional probability , we can then estimate the parameters @xmath144 , through the maximization [ eq : betaopt ] ( _ i,_if , i ) = _ _ i , b_if , i _ k=0 ^ 1 l_ik ( _ k^t _",
    "i + c_ikb_if , i - , s_i^k ) + _",
    "j=1^n |w_ij| , where @xmath145 is the probit loss function [ eq : probitloss ] l_ik(z , s ) =    - ( ( z/_ik ) ) & s_i^k=1 + -(1-(z/_ik ) ) & s_i^k = 0    given the conditional probabilities , the minimization is precisely the maximum likelihood estimate of the parameters with an additional @xmath43 regularization term to encourage sparsity in the weights @xmath130 . but this minimization is exactly a sparse probit regression that is standard in linear classification  @xcite .",
    "the only issue is that the optimization function with the probit loss requires knowledge of the threshold @xmath17 and variances @xmath142 .",
    "since we are only interested in the connectivity weights up to a constant factor , we can arbitrarily set the threshold level @xmath17 to some value , say @xmath146 . in principle , the noise variances @xmath142 can be derived from the integration noise variance @xmath147 in .",
    "however , the variance @xmath147 may itself not be initially known .",
    "instead , we simply select @xmath142 to be a constant value that is relatively large to account for initial errors in the @xmath11 .",
    "this research was supported by nsf grants 1116589 and 1254204 .",
    "the authors would like to thank bruno olshausen , fritz sommer , lav varshney , mitya chlovskii , peyman milanfar , evan lyall , and eftychios pnevmatikakis for their insights and support .",
    "this work would not have been possible without the supportive environment and wonderful discussions at the berkeley redwood center for theoretical neuroscience  thank you ."
  ],
  "abstract_text": [
    "<S> fluorescent calcium imaging provides a potentially powerful tool for inferring connectivity in neural circuits with up to thousands of neurons . </S>",
    "<S> however , a key challenge in using calcium imaging for connectivity detection is that current systems often have a temporal response and frame rate that can be orders of magnitude slower than the underlying neural spiking process . </S>",
    "<S> bayesian inference methods based on expectation - maximization ( em ) have been proposed to overcome these limitations , but are often computationally demanding since the e - step in the em procedure typically involves state estimation for a high - dimensional nonlinear dynamical system . in this work , we propose a computationally fast method for the state estimation based on a hybrid of loopy belief propagation and approximate message passing ( amp ) . </S>",
    "<S> the key insight is that a neural system as viewed through calcium imaging can be factorized into simple scalar dynamical systems for each neuron with linear interconnections between the neurons . using the structure , </S>",
    "<S> the updates in the proposed hybrid amp methodology can be computed by a set of one - dimensional state estimation procedures and linear transforms with the connectivity matrix . </S>",
    "<S> this yields a computationally scalable method for inferring connectivity of large neural circuits . </S>",
    "<S> simulations of the method on realistic neural networks demonstrate good accuracy with computation times that are potentially significantly faster than current approaches based on markov chain monte carlo methods . </S>"
  ]
}