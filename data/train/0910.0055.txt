{
  "article_text": [
    "in the last years considerable attention has been addressed to the distribution of inter - event times in natural hazards , in particular earthquakes@xcite , but also in human responses@xcite and social behavior@xcite . in some of these systems ,",
    "the shape of the inter - event - time distribution for events above a certain threshold in size is independent on the threshold .",
    "indeed , let @xmath0 denote the inter - event time , defined as the time between consecutive events above a size threshold @xmath1 and let @xmath2 be its probability density , then we can write @xmath3 where @xmath4 is a scaling function that provides the shape of @xmath2 and @xmath5 is the occurrence rate for events above @xmath1 , providing the scale of @xmath2 ( and @xmath6 provides the scale for @xmath0 ) .    if the size distribution follows a power law ( which is not always the case@xcite ) , then @xmath7 ( where @xmath8 is the exponent of the cumulative size distribution ) , and then @xmath9 which turns out to be a scaling law , equivalent to those obtained in the study of critical phenomena@xcite .",
    "the law reflects a scale - invariant condition : there exist a change of scale in @xmath0 and @xmath1 ( a linear transformation ) that does not lead to any change in the statistical properties of the process , at least regarding the inter - event - time probability density .",
    "the function @xmath10 is just the scaling function @xmath4 , except for proportionality constants .    why is this scaling law of some relevance or interest ? in general ,",
    "when events are removed from a point process ( as it is done in our case by raising the size threshold ) , the resulting inter - event - time distribution changes with respect to the original one , and a scaling law as eq .",
    "( [ scaling ] ) does not apply .",
    "however , for high enough thresholds @xmath1 ( for the extreme events that are of interest in hazard assessment studies ) , and when the events are randomly removed , it is expected that the resulting time process tends to a poisson process ( which means that the occurrence of the extreme events is independent on the history of the process , and just some multi - faced dice , thrown in continuous time , decides if an event takes place or not ) . from the point of view of statistical physics",
    ", the poisson process constitutes a trivial fixed - point solution of the renormalization equations describing the _ thinning _ or decimation performed in event occurrence when the size threshold is raised@xcite . for event occurrence on a large spatial scale , as for instance worldwide earthquakes ,",
    "there is a second reason to expect exponential inter - event - time distributions : the pooled output of several time processes ( i.e. , china seismicity , superimposed to japan seismicity , etc ... ) tends to a poisson process if the processes are independent@xcite .",
    "it is therefore surprising not only that the scaling function @xmath4 is not exponential , but also that a non - exponential scaling function exists . in the case of earthquakes@xcite ( and fractures@xcite )",
    "@xmath4 is approximated by the so called gamma distribution , with parameters @xmath11 and @xmath12 , @xmath13 where @xmath14 is the complement of the incomplete gamma function ( not normalized ) , @xmath15 .",
    "the cutoff value @xmath16 is not considered a free parameter but fixed and the scale parameter @xmath12 is not independent but can be obtained from the value of @xmath11 and @xmath16 taking into account that @xmath17 ( using that @xmath5 is the inverse of the mean inter - event time ) . for stationary seismicity , as well as from fracture and nanofracture experiments",
    ", the shape parameter @xmath11 turns out to be close to 0.7 , see refs . .",
    "the reason to disregard @xmath18values below @xmath16 is due , on the one hand , to the incompleteness of seismic catalogs on the shortest time scales and to the existence errors in the determination of the inter - event times when these are small , and on the other hand to the breakdown of the stationarity condition in those short time scales by small aftershock sequences .",
    "the usual way to establish the validity of a scaling law such as eq .",
    "( [ scaling ] ) is by plotting the different rescaled quantities together ( in our case inter - event - time distributions for different thresholds ) and judge visually if they collapse onto a single curve or not",
    ". it would be nice if one could put some numbers into the quality of the scaling and the fit of the scaling function and test their limits of validity .",
    "let us note that kagan has argued that one of the reasons because theoretical physics has failed not only to predict but to explain earthquake occurrence is due to the poor use of statistics by the researchers in the field@xcite .",
    "indeed , `` the quality of current earthquake data statistical analysis is low .",
    "since little or no study of random and systematic errors is performed , most published statistical results are artifacts . ''",
    "we believe this criticism has applicability beyond the case of statistical seismology .    in this paper we will first use the kolmogorov - smirnov two - sample test in order to evaluate the fulfillment of the inter - event - time scaling law ( [ scaling ] ) in southern california seismicity .",
    "next , the goodness of the fit of the scaling function ( [ gamma ] ) to the rescaled inter - event - time densities will be tested by adapting the procedure introduced by clauset _",
    "et al._@xcite , consisting in maximum likelihood estimation of parameters , kolmogorov - smirnov one - sample statistic evaluation , and monte carlo simulation of the inter - event times in order to compute the distribution of the statistic .",
    "the seismological data used will be the southern california waveform cross - correlation catalog of shearer _",
    "et al._@xcite ( for which , as far as the author knows , no study has published plain inter - event - time distributions @xmath2 , nevertheless , see also refs . ) .",
    "the catalog spans the years 1984 - 2002 ( included ) , containing 77034 earthquakes with magnitude @xmath19 .",
    "notice that we will use @xmath20 as a measure of size , although by the gutenberg - richter law it is not power - law distributed but exponentially distributed@xcite . in order to recover a power - law distribution",
    "one has to deal with the seismic moment , or the energy , which are exponential functions of the magnitude .",
    "we will concentrate in earthquake occurrence under stationary conditions .",
    "it is well know that earthquakes trigger more earthquakes with a rate that changes in time following the omori law@xcite . in general , this breaks stationarity , as the rate of occurrence is not constant in time ; however , at ( relatively ) large scales the resulting superposition of time - varying rates yields a constant rate , as it happens in worldwide seismic occurrence , and also for southern california in certain time periods in which the largest earthquakes do not occur , see fig . 1 of ref . .",
    "precisely for this reason , inter - event - times for stationary seismicity are more reliable than for non - stationary periods , as the large earthquakes present in the latter case prevent the detection of the small ones@xcite , which has dramatic consequences in the computation of the inter - event times .",
    "the stationary time periods under consideration in this paper are ( refining those in ref .",
    ", following ref . ):",
    "@xmath21 , @xmath22 , @xmath23 , @xmath24 , @xmath25 , @xmath26 , @xmath27 , @xmath28 , @xmath29 , @xmath30 , @xmath31 , where time is measured in years , 1 year = 365.25 days ( every 4 years an integer value in years corresponds to the true starting of the year ) .",
    "a simple way to quantify the validity of the scaling hypothesis in probability distributions can be obtained from the two - sample kolmogorov - smirnov ( ks ) test , which compares two empirical distributions .",
    "the procedure begins with the calculation of the maximum difference , in absolute value , between the rescaled cumulative distributions of the two data sets , i.e. , @xmath32 as we have more than two data sets , we label them with indices @xmath33 and @xmath34 .",
    "the empirical cumulative distribution functions @xmath35 are calculated as the fraction of observations in data set @xmath33 below value x , and constitute an estimation of the theoretical cumulative distribution function , @xmath36 = \\int_m^x d_k(x ) dx$ ] .    obviously , the difference @xmath37 is randomly distributed , and therefore we can refer to it as a statistic .",
    "the key element of the ks test is that when the data sets @xmath33 and @xmath34 come indeed from the same underlying distribution @xmath38 , the distribution of the ks statistic @xmath37 turns out to be independent on the form of @xmath39 and can be easily computed .",
    "therefore , the resulting value of @xmath37 can be considered as small or large by comparison with its theoretical distribution . under the null hypothesis that both data sets come from the same distribution , the probability that the ks statistic is larger than the obtained empirical value @xmath37 gives the so called @xmath40value , which constitutes the probability of making an error if the null hypothesis is rejected .",
    "the formulas for the probability distribution of @xmath37 are simple enough and are given by press _",
    "et al._@xcite , depending only on the number of data @xmath41 in each of the sets ; so , approximately , for large @xmath42 , @xmath43 } =   q([\\sqrt{n_e}+0.12 + 0.11/\\sqrt{n_e } ] d ) , \\label{q}\\ ] ] with @xmath44 a decreasing function taking values between 1 and 0 ( see ref . ) and @xmath42 an effective number of data points ( the `` reduced '' number , or one half of the harmonic mean of the number of data ) . nevertheless , in order to calculate the @xmath40value it is simpler to use the numerical routines provided in the same reference@xcite ( in particular , the routine called probks ) .",
    "notice that we have to compare the distributions of seismicity for @xmath45 and @xmath46 after rescaling , i.e. , as a function of @xmath47 and @xmath48 , respectively ( otherwise , without rescaling , the distributions can not be the same ) . in order to do that ,",
    "for each data set , we first calculate the mean value of the inter - event time , @xmath49 , and then , we disregard inter - event time values such that @xmath50 .",
    "the elimination of the smallest values increases the mean value of the remaining rescaled inter - event times , so , we repeat the procedure : we recalculate the mean inter - event time and rescale again the data by the new rate , disregarding those values below @xmath16 . the resulting data",
    "set has a mean value very close to one .",
    "we will assume that this procedure does not invalidate the applicability of the formulas we use for the calculation of the @xmath40value .",
    "the rescaled inter - event - time cumulative distributions for different magnitude ranges are shown at fig .",
    "[ twosample ] , ranging from @xmath19 to @xmath51 , fixing @xmath52 .",
    "the scaling seems rather good , except for the case @xmath53 .",
    "table [ t1 ] shows the ks statistic for each pair of distributions , as well as the corresponding @xmath40values . due to their high values",
    "( in all cases larger than 0.18 but in some others larger than 0.95 ) , the null hypothesis can not be rejected and each pair of data sets are compatible with the same underlying distribution , and therefore we have to agree with the scaling hypothesis ( within statistical significance ) .",
    "let us note that the @xmath40value , being itself originated by a random set , is a random quantity ( when different data sets are considered ) , and it turns out that the distribution of @xmath54 is uniform , between 0 and 1 .",
    "so , there is no reason to prefer @xmath55 in front of @xmath56 .",
    "only small enough values of @xmath54 should lead to the rejection of the null hypothesis .",
    "the results for the same data using @xmath57 ( which increases @xmath41 ) , also shown in table [ t1 ] , are again in concordance with the scaling hypothesis , being the smallest @xmath40value for this case larger than 0.14 . even for @xmath58",
    "all the @xmath40values are above 0.2 , except for some of the pairs involving the set with @xmath19 .",
    "the behavior of @xmath37 when @xmath16 is changed , which , following ref . should be a guide to chose the value of @xmath16 ( although in a different type of test , see next section ) , is not clear in this case .",
    "a different statistical test regards the goodness of the fit applied to some data . for instance , we can ask whether eq .",
    "( [ gamma ] ) is a good approximation to the empirical scaled distributions of inter - event times . here",
    ", we will adapt the method of ref . to the kind of distributions that we are interested in .",
    "first , a fit has to be performed .",
    "a usual way of proceed in the case of long - tailed distributions is to minimize the squared differences between the empirical density and the theoretical density in logarithmic scale ; however , this method shows some problems and involves the arbitrary estimation of the density ; other problems arises if one fits the cumulative distribution@xcite .",
    "in contrast , maximum likelihood estimation avoids these difficulties by working directly with the `` raw '' data .    in order to be more general ,",
    "let us consider the distribution given by the probability density , @xmath59 which constitutes the so called generalized gamma distribution , with shape parameters @xmath11 and @xmath60 and scale parameter @xmath12 .",
    "we consider @xmath11 and @xmath60 greater than zero , the opposite case can be considered as well but then the function @xmath61 has to be replaced by its complementary function ( and multiplied by -1 , as @xmath62 ) .",
    "the cutoff value @xmath16 could be fixed to zero , but , as we have mentioned , for our data it is convenient to consider @xmath63 .",
    "the @xmath64th moment of the distribution is given by @xmath65 for @xmath66 and @xmath67 .",
    "notice that a particular case is given by the scaling function @xmath68 appearing in eq .",
    "( [ scaling ] ) , for which @xmath69 , and only two of the three parameters are free ; nevertheless we will not make use of that restriction for estimating the parameters .",
    "the method of maximum likelihood estimation is based on the calculation of the likelihood function @xmath70 , see ref . .",
    "this is given by ( or , in order to avoid dimensional problems , proportional to ) the probability per unit of @xmath71 that the data set comes from a particular distribution , given the values of its parameters i.e. , @xmath72 } { d x_1 , d x_2 , \\dots d x_n } \\simeq \\prod_{i=1}^n d(x_i",
    "| \\gamma,\\delta , a),\\ ] ] where @xmath41 is the number of data and we make explicit the dependence of the probability density on its parameters .",
    "the last step assumes that each value @xmath73 is independent on the rest . naturally , this is not always the case ( we know that earthquake inter - event times are correlated@xcite ) and then the maximum likelihood method provides an estimation of the distribution that generates the dataset in consideration but it may be that the dataset is not representative of the process we are studying ( due to correlations , the phase space may not be evenly sampled ) .",
    "it is more practical to work with the log - likelihood , @xmath74 , which is the logarithm of the likelihood ; dividing also by @xmath41 , @xmath75 which , notice , can be understood as a kind of estimator of the entropy of the distribution from the available data ( with a missing @xmath76 sign ) . in the case of the generalized gamma distribution ( [ gammagen ] )",
    "it is easy to get that @xmath77 where we have omitted a term @xmath78 that is independent on the parameters of the distribution , and we have introduced @xmath79 as the geometric mean of the data , @xmath80 , and @xmath81 as what we may call the @xmath82power mean , @xmath83 { \\sum x_i^\\delta / n}$ ] ( which , in contrast to @xmath79 , depends on the value of the parameter @xmath60 ; for instance , for @xmath84 , @xmath85 is the arithmetic mean , but for @xmath86 , @xmath85 is the harmonic mean ) .",
    "the best estimate of the parameters would be that that maximizes the likelihood , or , equivalently , the log - likelihood .",
    "the previous expression is too complicated to be maximized analytically , and it is too complicated to differentiate even ( in fact , we would need to compute the derivative of the incomplete gamma function ) .",
    "so , we will perform a direct numerical maximization ( in particular we will use the numerical routine amoeba from ref .",
    "; the function @xmath61 can be computed from the same source using routines gammq and gammln ) .    fixing @xmath87 , from which we recover eq .",
    "( [ gamma ] ) as a model of the distribution ( which yields only one free parameter and has the advantage of being compatible with a poisson process in the limit of long times ) , the resulting values of the parameters @xmath11 and @xmath12 , obtained from maximum likelihood estimation , are given in table [ t2 ] .",
    "in all cases , except for @xmath51 , and if the cutoff @xmath16 is not too small , the values of @xmath11 are close to 0.7 .",
    "once we have obtained the estimators of the parameters , we can ask about their meaning .",
    "maximum - likelihood estimation does not mean that it is likely that the data comes from the proposed theoretical distribution , with those parameters .",
    "in fact , maximum likelihood can be minimum unlikelihood , i.e. , we are taking the less bad option among those provided by the _ a priori _ assumed probability model . in order to address this issue it is necessary to perform a goodness - of - fit test .    following ref .",
    "we can employ again the kolmogorov - smirnov test , this time for one sample .",
    "the ks statistic is , similarly as before @xmath88 where @xmath89 is the empirical cumulative distribution of the data , defined in the previous section , and @xmath90 is the theoretical proposal . for the distribution of eq .",
    "( [ gammagen ] ) , @xmath91 the resulting values of @xmath92 for our problem are also shown in table [ t2 ] .",
    "now we can apply the recipe of clauset _ et al .",
    "_ in order to select the most appropriate value of the cutoff @xmath16 , which consists in selecting the value which minimizes @xmath92 .",
    "comparing between 0.003 , 0.01 , and 0.03 , it seems clear that we should chose @xmath52 .    at this point",
    "we could proceed as in the previous section , using the formulas for the distribution of @xmath92 .",
    "however , that only would be right if we were not estimating @xmath39 from the data ( if we were comparing with a theory free of parameters for instance ) . in order to know the distribution of the statistic @xmath92 when the data are generated by the model with the parameters obtained by maximum likelihood estimation , we will use monte carlo simulations . indeed , generating data from the theoretical distribution , we can repeat the whole process to obtain the statistical behavior of @xmath92 when the null hypothesis is true ( when the data come from the proposed theoretical distribution ) , and we can do it many times , in order to get significant statistics .",
    "schematically , the process for the calculation of @xmath54 consists of the multiple iteration of the following steps :    1 .",
    "simulate synthetic data @xmath1 from the distribution given by eq .",
    "( [ gamma ] ) using the parameters @xmath11 and @xmath12 obtained before for the empirical data 2 .",
    "estimate the parameters @xmath93 and @xmath94 by fitting the synthetic data @xmath1 to eq .",
    "( [ gamma ] ) ( proceeding in the same way as described above for the empirical data , see eq .",
    "( [ logl ] ) and so on ) .",
    "3 .   evaluate the ks statistic for the distribution of synthetic data @xmath1 [ generated in ( 1 ) with parameters @xmath11 and @xmath12 ] and the theoretical distribution with parameters @xmath93 and @xmath94 [ calculated in ( 2 ) ] , i.e. , @xmath96    we will obtain synthetic inter - event times from the gamma distribution by generating a table of the cumulative distribution . as the probability of an event has to be the same independently on the random variable we assign to that event , then , @xmath97 , where @xmath98 is a uniform random number between zero and one and is also its own cumulative distribution .",
    "we can calculate numerically the function @xmath39 ( thanks to the numerical recipes gammq and gammln@xcite ) , but are unable to calculate its inverse ( at least , in a reasonable computer time ) , so we will tabulate the values of @xmath39 , for selected values of @xmath99 in log scale ( this is to deal with the multiple time scales that appear in the process , described by eq .",
    "( [ gamma ] ) or ( [ cumul ] ) when @xmath100 and @xmath101 ) . to be concrete , @xmath102 , where @xmath103 and @xmath104 is just a constant .",
    "then , when a uniform value @xmath98 is generated we can obtain the corresponding value of @xmath99 by looking at the table and interpolating ( or extrapolating ) using the closest values of @xmath105 .    for the case of our interest , the @xmath40values calculated in this way , using 1000 randomly generated samples ( which yield an uncertainty of about 3 % in @xmath54 ) ,",
    "are included in table [ t2 ] .",
    "taking @xmath52 ( the value arising by the application of clauset _ et al .",
    "_ recommendation ) , we can not reject the hypothesis that the data set comes from the theoretical distribution with maximum likelihood parameters , except for @xmath106 , which yields @xmath107 , which is beyond the usual onset of acceptance of the null hypothesis , @xmath108 .",
    "figure [ onesample ] illustrates the reason of the rejection .",
    "indeed , although the theoretical distribution is very close to the empirical one , the difference is large enough for the high number of data involved .",
    "although eq .",
    "( [ q ] ) is not valid in this case , we can use it as an approximation and see how for large @xmath41 the statistic @xmath92 scales as @xmath109 ( @xmath110 here ) . as the mode of the distribution @xmath44 in eq .",
    "( [ q ] ) is around 0.735 and practically all the probability is contained below 2 , this means that we can expect @xmath111 .",
    "so , for large @xmath41 , @xmath92 tends to zero , and the ks test is able to detect any small difference between the proposed theoretical distribution and the `` true '' distribution .",
    "this means that the test is not adequate if we are just interested to find an approximation to the true distribution , as only the `` true '' distribution is not rejected for a sufficient number of data . for comparison ,",
    "we show in table [ t3 ] the results for an exponential scaling function , which is clearly rejected except for @xmath53 .",
    "as another alternative , note that we have tested separately the validity of the scaling law and the adequacy of the scaling function given by eq .",
    "( [ gamma ] ) .",
    "we could take advantage of the scaling behavior to fit and test the goodness of fit of the scaling function .",
    "for instance , we could combine all rescaled data sets ( for all values of the minimum magnitude ) and proceed as in sect . 3 for this combined data set .",
    "the problem is that , by virtue of the gutenberg - richter law , when the minimum magnitude is raised in one unit , the number of events decreases by a factor 10 , and therefore , data sets with large minimum magnitudes are under - represented .",
    "perhaps we could just truncate the samples in order that all of them had the same number of data , but that would lead to a tremendous wasting of information .",
    "the surprising character of the scaling law ( [ scaling ] ) when the scaling function is not exponential has lead to some criticisms by molchan@xcite and saichev and sornette@xcite .",
    "the latter authors propose that , for the so called etas model , the scaling law is not valid , and one has a very slow variation of the inter - event - time distribution when the magnitude threshold is raised .",
    "although we have tested that the scaling law is consistent with the data within statistical significance , this does not mean that we should reject saichev and sornette result .",
    "nevertheless , the simplicity of the scaling hypothesis makes it the most adequate model for seismicity , at least as a null model to contrast with other hypothesis . on the other hand ,",
    "other seismicity models have been recently proposed , which , in contrast to the etas model , are fully scale invariant and one would expect that are characterized by scaling inter - event - time distributions@xcite .",
    "saichev and sornette also provide a pseudo - scaling function to which inter - event - time distributions can be fit@xcite . in principle , the very same procedure used in our paper can be applied directly in order to fit the parameters of the saichev - sornette function and test the goodness - of - fit of the outcome . it is expected that the use of this new function , which has more parameters than eq .",
    "( [ gamma ] ) and models better the left tail of the distribution , could lead to the reduction of the cutoff @xmath16 above which the functions are fit .",
    "we leave this task for future research .",
    "\\(a ) ( b )    \\(c ) ( d )    @lr|rrrrr@ + @xmath57 & @xmath41 & @xmath112 & @xmath113 & @xmath114 & @xmath115 & @xmath116 + @xmath112 & 19821 & - & 41.6% & 43.8% & 14.3% & 31.9% + @xmath113 & 5187 & 0.014 & - & 57.1% & 29.6% & 31.1% + @xmath114 & 1268 & 0.025 & 0.024 & - & 68.0% & 33.5% + @xmath115 & 340 & 0.062 & 0.054 & 0.044 & - & 28.1% + @xmath116 & 76 & 0.108 & 0.110 & 0.110 & 0.124 & - +   +    @l|rrrrr@ + @xmath117 & @xmath41&@xmath11 & @xmath12 & @xmath92 & @xmath40value + @xmath112 & 18870 & 0.68 & 1.41 & 0.007 & 3.2% + @xmath113 & 4953 & 0.64 & 1.50 & 0.009 & 37.3% + @xmath114 & 1184 & 0.69 & 1.41 & 0.021 & 21.8% + @xmath115 & 309 & 0.67 & 1.45 & 0.029 &",
    "73.6% + @xmath116 & 70 & 0.95 & 1.05 & 0.082 & 29.3% +   +    @l|rrrrr@ + @xmath118 & @xmath41&@xmath11 & @xmath12 & @xmath92 & @xmath40value + @xmath112 & 19466 & 0.65 & 1.51 & 0.009 & 0.0% + @xmath113 & 5102 & 0.62 & 1.57 & 0.011 & 11.2% + @xmath114 & 1247 & 0.59 & 1.65 & 0.029 & 1.4% + @xmath115 & 328 & 0.56 & 1.74 & 0.046 & 9.0% + @xmath116 & 74 & 0.72 & 1.37 & 0.103 & 5.8% +   +",
    "the author has been benefited by discussions with a. deluca and r. d. malmgren , and appreciate the generosity of shearer _ et al .",
    "_ to make the results of their research publicly available .",
    "this research has been part of the spanish projects fis2006 - 12296-c02 - 01 and 2005sgr-0087 .",
    "10              j.  strm , p.  c. f.  di stefano , f.  prbst , l.  stodolsky , j.  timonen , c.  bucci , s.  cooper , c.  cozzini , f.v .",
    "feilitzsch , h.  kraus , j.  marchese , o.  meier , u.  nagel , y.  ramachers , w.  seidel , m.  sisti , s.  uchaikin , and l.  zerle .",
    "fracture processes observed with a cryogenic detector .",
    "356 , 262266 , 2006 .                                  y.  y. kagan .",
    "why does theoretical physics fail to explain and predict earthquake occurrence ? in p.",
    "bhattacharyya and b.  k. chakrabarti , editors , _ modelling critical and catastrophic phenomena in geoscience _ , lecture notes in physics , 705 , pages 303359 .",
    "springer , berlin , 2006 .",
    "p.  shearer , e.  hauksson , and g.  lin .",
    "hypocenter relocation with waveform cross- correlation , part 2 : results using source - specific station terms and cluster analysis .",
    "95 , 904915 , 2005 . , file shlk@xmath1191@xmath11902.txt ."
  ],
  "abstract_text": [
    "<S> we explore in depth the validity of a recently proposed scaling law for earthquake inter - event time distributions in the case of the southern california , using the waveform cross - correlation catalog of shearer _ et al . _ </S>",
    "<S> two statistical tests are used : on the one hand , the standard two - sample kolmogorov - smirnov test is in agreement with the scaling of the distributions . on the other hand , the one - sample kolmogorov - smirnov statistic complemented with monte carlo simulation of the inter - event times , as done by clauset _ </S>",
    "<S> et al . </S>",
    "<S> _ , supports the validity of the gamma distribution as a simple model of the scaling function appearing on the scaling law , for rescaled inter - event times above 0.01 , except for the largest data set ( magnitude greater than 2 ) . </S>",
    "<S> a discussion of these results is provided . </S>"
  ]
}