{
  "article_text": [
    "in his popular expository article on universality examples in mathematics and physics tao @xcite mentions zipf s empirical power law of word frequencies as lacking any `` convincing explanation for how the law comes about and why it is universal . '' by _ universality _ he means the idea where systems follow certain macroscopic laws that are largely independent of their microscopic details . in this article",
    "we drop down many levels from natural language to discuss _ two _ universality properties associated with the toy monkey model of zipf s law . both of these properties were considered in perline @xcite , but the presentation there was incompletely developed , and here we clarify and greatly expand upon these two ideas by showing : ( 1 ) how the model displays a nearly universal tendency towards a @xmath0 exponent in its power law behavior ; and ( 2 ) the significance of the central limit theorem ( clt ) for a random number of i.i.d .",
    "variables in the model with a finite word length cutoff",
    ". we will sometimes refer to the case with a finite word length cutoff as _ monkey twitter _ , as explained in section 3 .",
    "our paper is laid out as follows . in section 2",
    "we prove the strong tendency towards an approximate @xmath0 exponent under very broad conditions by means of a limit theorem for the logarithms of random spacing due to shao and hahn .",
    "a somewhat longer approach to this proof is in perline @xcite , where an elementary derivation of power law behavior of the monkey model is first given before applying the shao - hahn limit result . in section 3 ,",
    "we explain the underlying lognormal structure of the _ central part _ of the distribution of word probabilities in the case of a _ finite word length _ cutoff and show how it leads to a hybrid zipf - lognormal distribution ( called a lognormal - pareto distribution in @xcite ) .",
    "these are universality properties in exactly tao s sense because the distribution of the word probabilities ( the macro behavior ) is within very broad bounds independent of the details of how the letter probabilities for the monkey s typewriter are selected ( the micro behavior ) . in section 4 , we discuss the multiple connections between these results and well - known research from other areas where pareto - zipf type distributions have been investigated . in the remainder of this section",
    "we sketch some historical background .",
    "it has been known for many years that the monkey - at - the - typewriter scheme for generating random `` words '' conforms to an inverse power law of word frequencies and therefore mimicks the inverse power form of zipf s @xcite statistical regularity for many natural languages .",
    "_ however , zipf s empirical word frequency law not only follows a power distribution , but as he emphasized , it also very frequently exhibits an exponent in the neighborhood of @xmath0 .",
    "_ that is , letting @xmath2 represent the observed ranked word frequencies , zipf found @xmath3 , with @xmath4 a constant depending on the sample size .",
    "many qualifications have been raised regarding this approximation ( including the issue of the divergence of the harmonic series ) ; yet as i.j .",
    "good @xcite commented : `` the zipf law is unreliable but it is often a good enough approximation to demand an explanation . ''",
    "figure 1 illustrates the fascinating universal character of this word frequency law using the text from four different authors writing in four different european languages in four different centuries .",
    "the plots are shown in the log - log form that zipf employed , and they resemble countless other examples that researchers have studied since his time .",
    "the raw text files for the four books used in the graphs were downloaded from the public gutenberg databank @xcite .",
    "the monkey model has a convoluted history .",
    "the model can be thought of as actually embedded within the combinatoric logic of mandelbrot s early work providing an information - theoretic explanation of zipf s law .",
    "for example , in mandelbrot @xcite there is an appendix entitled `` combinatorial derivation of the law @xmath5 '' ( his notation ) that effectively specifies a monkey model , including a markov version , but is not explicitly stated as such .",
    "however , his derivation there is informal , and the first completely rigorous analysis of the general monkey model with independently combined letters was given only surprisingly recently by conrad and michenmacher @xcite .",
    "their analysis utilizes analytic number theory and is , as a result , somewhat complicated - a point they note at the end of their article .",
    "a simpler analysis using only elementary methods based on the pascal pyramid has now been given by bochkarev and lerner @xcite .",
    "they have also analyzed the more general markov problem @xcite and hidden markov models @xcite .",
    "edwards , foxall and perkins @xcite have provided a directly relevant analysis in the context of scaling properties for paths on graphs explaining how the markov variation can generate both a power law or a weaker scaling law , depending on the nature of the transition matrix .",
    "perline @xcite also gives a simple approach to the demonstration of power law behavior .",
    "a clarifying and important milestone in the history of this topic came from the cognitive psychologist , g. a. miller @xcite .",
    "miller used the simple model with equal letter probabilities and an independence assumption to show that this version generates a distribution of word probabilities that conforms to an approximate inverse power law such that the probability @xmath6 of the @xmath7 largest word probability is ( in a sense that needs to be made precise ) of the form @xmath8 , for @xmath9 . _ in addition _",
    ", he made the very interesting observation that by using a keyboard of @xmath10 letters and one space character , with the space character having a probability of .18 ( about what is seen in empirical studies of english text ) , the value of @xmath11 in this case is approximately -1.06 , very close to the nearly -1 value in samples of natural language text as illustrated in figure 1 . in his simplified model ,",
    "it turns out that @xmath12 , where @xmath13 is the space probability , so that @xmath11 approaches -1 from below as @xmath14 increases .",
    "( natural logarithms are denoted @xmath15 and logarithms with any other radix will be explicitly indicated , as in @xmath16 .",
    "note that miller s @xmath17 involves a _ ratio _ of logarithms , so that it is invariant with respect to the radix used in the numerator and denominator . ) consequently , miller s model not only mimicks the form of zipf s law for real languages , but with a large enough alphabet size it even mimicks the key parameter value .",
    "_ in this article we give a broad generalization of miller s observation to the case of unequal letter probabilities .",
    "_ in light of our present results given in section 2 , the application of sample spacings from a uniform distribution in @xcite to study the @xmath0 behavior using an asymptotic regression line should now be viewed as just a step in a direction that ultimately led us to the shao and hahn limit used here .",
    "for our analysis we specify a keyboard with an alphabet of @xmath18 letters @xmath19 and a space character @xmath20 .",
    "the letter characters have non - zero probabilities @xmath21 .",
    "the space character has probability @xmath22 , so that @xmath23 .",
    "a word is defined as any sequence of non - space letters terminating with a space .",
    "a word @xmath24 of exactly @xmath25 letters is a string such as @xmath26 and has a probability of the form @xmath27 because letters are struck independently .",
    "the space character with no preceding letter character will be considered a word of length zero .",
    "the rank ordered sequence of descending word probabilities in the ensemble of all possible words is written @xmath28 ( @xmath29 is always the first and largest word probability . )",
    "we break ties for words with equal probabilities by alphabetical ordering , so that each word probability has a unique rank @xmath30 .",
    "conrad and mitzenmacher @xcite give a carefully constructed definition of power law behavior in the monkey model as the situation where there exist two positive constants @xmath31 and @xmath32 such that the inequality    @xmath33    holds for sufficiently large @xmath30 .",
    "following the argument in bochkarev and lerner @xcite , @xmath17 in the monkey model turns out to be simply the solution to    @xmath34    with @xmath35 . in the miller model with equal letter probabilities ,",
    "@xmath36 , so from equation ( 2 ) , @xmath17 in this case is found to be @xmath37 . in the fibonacci example given by conrad and mitzenmacher @xcite and",
    "in mitzenmacher @xcite they use @xmath38 letters with probabilities @xmath39 , @xmath40 and @xmath41 so that @xmath42 .",
    "then @xmath17 is the solution to @xmath43 , giving    @xmath44    to understand conditions leading to @xmath45 , we define spacings through a random division of the unit interval and then state the shao - hahn limit law .",
    "let @xmath46 be a sample of @xmath47 i.i.d .",
    "random variables drawn from a distribution on @xmath1 $ ] with a bounded density function @xmath48 .",
    "write the order statistics of the sample as @xmath49 . the @xmath14 _ spacings _ @xmath50 are defined as the differences between the successive order statistics : @xmath51 , @xmath52 for @xmath53 and @xmath54",
    ". we ll refer to this as a _ generalized broken stick process_. by shao and hahn corollary 3.6 , we have    @xmath55    as @xmath56 and where _ a.s . _ signifies _ almost sure convergence _",
    ", @xmath57 is the euler constant and @xmath58 is the differential entropy of @xmath59 .",
    "clearly ,    @xmath60    so dividing through by @xmath61 gives    @xmath62    as @xmath56 .",
    "the right side of the limit in ( 6 ) goes to 0 because @xmath63 goes to 0 by the boundedness of the density @xmath59 . expressing logarithms with a radix @xmath64 then leads to the limit    @xmath65    our _ universality property _ for @xmath17 will now follow almost immediately from this .",
    "we use sample spacings to populate the @xmath14 letter probabilities for the monkey keyboard . since @xmath22 is the probability of the space character , define @xmath66 @xmath67 so that @xmath68 .",
    "let @xmath69 .",
    "then from the limit ( 7 ) , we have @xmath70 as @xmath56 .",
    "since @xmath71 and @xmath9 , showing that @xmath72 will prove that @xmath73 as @xmath56 . to see that this is the case , note : @xmath74\\\\ & \\le & \\log_k \\big ( { q_1^{1/\\beta } + q_2^{1/\\beta}\\dots + q_k^{1/\\beta}\\over k}\\bigr)\\\\ & = & \\log_k { 1\\over k}=-1,\\end{aligned}\\ ] ] where the inequality in ( 10 ) follows from the geometric - arithmetic mean inequality .",
    "therefore , from @xmath75 we see that @xmath72 and so @xmath76 . in the special case of miller s model using all equal letter probabilities , @xmath77 .",
    "the broad generality of the shao - hahn limit leads to the near - universal characterization of the approximation @xmath45 as @xmath14 increases .",
    "figure 2 presents graphical results using simulations of sample spacings from several distributions to illustrate this phenomenon . in figure 2(a ) we plot @xmath78 by @xmath79 for the miller model with exactly the parameter values he used , i.e. , @xmath10 letters , a space probability @xmath80 and equal letter probabilities @xmath81 .",
    "the graph is based on the ranks @xmath82 , corresponding to all words of length @xmath83 non - space letters .",
    "figures 2(b ) through 2(d ) are based on generating @xmath10 letter probabilities from three different continuous distributions with bounded densities @xmath59 on @xmath1 $ ] using a generalized broken stick method to obtain the sample spacings .",
    "again @xmath80 was used for the probability of the space character and the letter probabilities were populated with values from the spacings with @xmath66 , @xmath84 , so that in each case , @xmath85 , as in miller s example . for each graph in figure 2(b ) - 2(d ) , we generated the largest 475255 word probability values in order to match the miller example of fig 2(a ) .",
    "the three continuous distributions , all defined on @xmath1 $ ] , are :    * a unform distribution with density @xmath86 ; * a beta @xmath87 distribution with density + @xmath88 * a triangular distribution with density @xmath89     log - log plots of monkey word probabilities by rank showing the asymptotic tendency towards a @xmath0 exponent ( slope on the log - log scales ) using four different distributions to generate letter probabilities : equal probabilities in 2(a ) and a generalized broken stick process in 2(b)-2(d ) .",
    "@xmath10 letters were used in all cases and the largest @xmath90 word probabilities are displayed . ]    the graphs in figures 2(b)-2(d ) illustrate our theoretical derivation , but we also note that the very linear plots indicate what appears to be an almost `` immediate '' convergence to power law behavior exceeding what might be expected from the asymptotics of conrad - mitzenmacher and bochkarov - lerner .",
    "the discussion of the finite word length version of the monkey model in @xcite was incomplete because it did not explicitly provide the normalizing constants for the application of anscombe s clt for a random number of i.i.d .",
    "variables , as we do here .",
    "we also want to explain more clearly the nature of the hybrid zipf - lognormal distribution that results from a finite length cutoff when letter probabilities are not identical .",
    "the focus in section 2 on the infinite ensemble of word probabilities @xmath91 _ ranked _ to give @xmath92 has actually obscured the significant _ hierarchical structure _ of the monkey model - what mandelbrot @xcite ( p. 345 ) , called a _ lexicographic tree _ - which only becomes evident when word length is considered . to see this , write @xmath93 for the multiset of all word probabilities for monkey words of exactly length @xmath25 .",
    "there are @xmath94 probabilities in @xmath93 having a total sum of @xmath95 and an average value of @xmath96 , declining geometrically with @xmath25 . now taking word length into account ,",
    "mandelbrot s lexicographic tree structure becomes clear with the simple case of @xmath38 letters : the root node of the tree has a probability of @xmath22 ( for the `` space '' word of length 0 ) ; it has two branches to the next level consisting of nodes for words of length 1 with probabilities @xmath97 and @xmath98 ; these each branch out to the next level with four nodes having probability values @xmath99 and so on .",
    "the relevance of the clt is seen first by representing any probability @xmath100 as a product of i.i.d .",
    "random variables times the constant @xmath22 : @xmath101 , where each @xmath102 takes on one of the letter probability values @xmath103 with probability @xmath104 ( i.e. , we use the natural counting measure to construct a probability space on @xmath93 ) .",
    "let @xmath105 and @xmath106 .",
    "assume that @xmath107 , i.e. , the letter probabilities are not all equal . then @xmath108 is the mean and @xmath109 is the variance of @xmath110 for @xmath111 , and it follows that @xmath112 and @xmath113 are the respective mean and variance of @xmath114 for @xmath100 .",
    "therefore , @xmath115 is asymptotically normally distributed @xmath116 ( the term @xmath117 is rendered negligible in the asymptics ) so that for sufficiently large @xmath25 , @xmath118 itself will be approximately lognormal @xmath119 .",
    "this approximate normality for the log - probabilities of words of fixed length is quite obvious and was noted in passing by mandelbrot @xcite ( p. 210 ) .",
    "however , he missed a _",
    "observation that the @xmath120 word probabilities for @xmath121 have a distribution that behaves in its central part away from the tails very much like @xmath122 .",
    "that is , a version of the clt can be applied to words of length @xmath123 , not just to words of length @xmath25 , and the two distributions , _ in one sense _ , are very close to each other .    to explain why this is so , for @xmath124 represent @xmath125 as a sum of a _ random number _ of i.i.d .",
    "random variables ( plus the constant @xmath117 ) , where @xmath126 is itself a random variable with a finite geometric distribution , @xmath127 .",
    "we will not repeat the calculations of @xcite here , but it is easily shown that @xmath128 in probability . because this limiting constant is 1 , anscombe s generalization of the clt @xcite ( theorem 3.1 , p. 15 ) can be applied with the _ identical _ normalizing constants @xmath129 and @xmath130 as used above with @xmath110 for @xmath122 .",
    "consequently , it is _ also _ true that for @xmath131 , the normalized sum @xmath132 has an asymptotic @xmath116 distribution . in other words",
    "the two random sums @xmath133 and @xmath134 behave so similarly in their centers that the word probabilities in @xmath135 and @xmath136 are _ both _ approximately @xmath137 .",
    "however , it is essential to remark that the two distributions have very different upper tail behavior . in this regard ,",
    "le cam s @xcite comment that french mathematicians use the term `` central '' referring to the clt `` because it refers to the center of the distribution as opposed to its tails '' is particularly relevant .",
    "the behavior of @xmath131 is illustrated in the graphs of figure 3(a ) and 3(b ) .",
    "the plot in figure 3(a ) was generated just as in figure 2(b ) except that a finite length cutoff of @xmath138 letters has been applied . to make this clear , in figure 2(b )",
    "the plot shows the top 475255 word probabilities in @xmath91 generated using @xmath10 letters derived from uniform spacings .",
    "in contrast , using the same letter probabilities , the plot in figure 3(a ) shows the 475255 word probabilities generated with word length @xmath83 letters , i.e. , all the values of @xmath139 .",
    "word length in the case of _ unequal _ letter probabilities is certainly correlated , _ but not perfectly _ , with word probability : words of shorter length will , _ on average _ , have a higher probability than those of longer length , but except in miller s degenerate case , there will always be reversals where a longer word will have a higher probability than a shorter word .",
    "however , writing @xmath140 for the ranked values of @xmath136 , it should be evident that for any given rank @xmath30 , @xmath141 and that @xmath142 when @xmath25 is sufficiently large . in short",
    ", @xmath136 inherits its upper tail power law behavior from @xmath143 , which is illustrated by comparing the top part of the curve in figure 3(a ) with the corresponding part of figure 2(b ) .",
    "figure 3(b ) uses the same data points from figure 3(a ) graphed as a normal quantile plot , and its roughly linear appearance for the logarithm of word probabilities for @xmath131 conforms to an approximate guassian fit , although certainly the bending in the upper half of the distribution departs a bit from the linear trend of the lower half .",
    "the fact that a distribution can have a power law tail and lognormal central part and _ still look lognormal over essentially its entire range _ may seem surprising .",
    "the discussion in @xcite about _ power law mimicry _ in the upper tail of lognormal distributions helps to explain why this can happen .",
    "we will call the distribution for @xmath136 a zipf - lognormal distribution .    the monkey model with a fixed word length cutoff",
    "can prove useful as a motivating idea . in the next section",
    ", we will discuss how models with the same branching tree structure have been proposed many times in the past , typically in settings where something like a finite word length is natural to consider . for the moment",
    ", think of the social networking service , twitter , which allows members to exchange messages limited to at most 140 characters .",
    "define _ monkey twitter _ with a finite limit of @xmath144 characters .",
    "for convenience , in any implementation of a monkey twitter random experiment we will assume that monkeys would always fill up their allotted message space of @xmath144 characters .",
    "monkey words still require a terminating space character , so it is possible for a monkey to type ( at most ) one `` non - word , '' which can vary in length from 1 to @xmath144 characters , and will always be the last part of a message string .",
    "non - words are discarded , and the probabilities for the legitimate monkey words , varying in length from 0 to @xmath25 non - space characters plus a terminating space character , will correspond to the values in @xmath136 .",
    "figure 3(a ) is a log - log plot of monkey word probabilities by rank for all words of length @xmath83 non - space characters using letter probabilities from uniform spacings .",
    "the linear upper tail coincides closely with the previous figure 2(b ) , but the power law clearly breaks down .",
    "figure 3(b ) shows the same word probabilities in a standard normal quantile plot .",
    "its rough linearity confirms an approximate gaussian fit over the whole distribution even though the upper tail is a power law as seen on the left in figure 3(a ) .",
    "we refer to this distribution as a zipf - lognormal hybrid , and it has many connections to other distributions discussed in the statistical literature . ]",
    "the subject of power law distributions is a vast topic of research reaching across diverse scientific disciplines @xcite . here",
    "we provide a brief sketch of how our results connect to some other work and how they can be considered in a much more general light .",
    "the monkey model viewed in terms of its hierarchical tree structure is the starting point for understanding its general nature .",
    "though miller did not explicitly present his model as a branching tree , several researchers at almost the same time in the mid - to - late 1950s were highlighting this form using the equivalent of equal letter probabilities to motivate the occurrence of empirical power law distribution in other areas .",
    "for example , beckman @xcite introduced this idea in connection with the power law of city populations within a country ( `` auerbach s law '' @xcite ) .",
    "using essentially the same logic as miller , but in a completely different setting , beckman assumed that a given community will have @xmath14 satellite communities , each with a constant decreasing fraction of the population at a higher level .",
    "that is , if @xmath145 is the population of the largest city and @xmath146 , there will be @xmath14 nearby satellite communities with population @xmath147 , @xmath148 smaller communities nearby to these with population @xmath149 , and so on .",
    "mandelbrot @xcite ( p. 226 ) had an apt expression for this pattern : he described it as `` compensation between two exponentials '' because the number of observations at each level increases geometrically while the mean value decreases geometrically .",
    "beckman then went on to note that if instead of using a constant decreasing fraction @xmath150 , one used a random variable @xmath151 on @xmath152 , the population at the @xmath153 level down would be a random variable of the form @xmath154 , leading to an approximate lognormal distribution of populations at this level .",
    "this corresponds to our discussion of monkey word probabilities in @xmath135 , although beckman was not aware of the still stronger statement of lognormality for the probabilities of words of length @xmath123 in @xmath155 that we demonstrated using anscombe s clt .",
    "many more examples of a branching tree structure essentially equivalent to miller s monkey model with equiprobable letters have been proposed over the years to motivate the occurrence of a huge variety of empirical power law distributions , including such size distributions as lake areas , island areas ( `` korcak s law '' ) , river lengths , etc . indeed",
    ", mandelbrot s @xcite classic book on fractals is a rich source of these .",
    "this equiprobability case is so simple to analyze that it has been invoked over and over again to illustrate how power law behavior can arise .",
    "however , the more complicated case using unequal letter probabilities ( or proportions ) _ and a finite word length cutoff _ is what really underscores the close analogy between the monkey zipf - lognormal distribution and other mixture models exhibiting hybrid power law tails and approximately lognormal central ranges .",
    "empirical distributions of this form have appeared with great frequency .",
    "in fact there is a long history of researchers , including pareto , first discovering what appears to be an empirical power law over an entire distribution because they start out by looking at only the largest observations ( cities , corporations , islands , etc . ) .",
    "however , when they extend their measurements to the part of the distribution below the upper tail , _ which is always more difficult to observe _ , the power law behavior typically breaks down .",
    "several examples of this are chronicled in @xcite .",
    "the power law for city sizes noted above is a perfect illustration .",
    "auerbach in 1913 @xcite looked at the 94 largest german cities from a 1910 census and showed a good power law fit , but because he did not include the thousands of smaller communities , he may not have been aware that this relationship breaks down .",
    "modern studies of the _ full _ distribution of communities , such as eeckhout s @xcite analysis of the populations of 25,359 places from u.s .",
    "census 2000 , prove with high confidence that the _ bulk _ of the community populations fit an approximate lognormal distribution and that the power law behavior is confined to the upper tail .",
    "montroll and shlesinger @xcite explained how to generate a pareto - lognormal hybrid for income distributions by using a hierarchical mixture model of lognormal distributions .",
    "this is motivated from several angles , including the notion that higher classes amplify their income by organizing in such a way as to benefit from the efforts of others .",
    "reed and hughes @xcite have provided a far - ranging framework for understanding these hybrid distributions across the entire spectrum of disciplines where they have been discovered : `` physics , biology , geography , economics , insurance , lexicography , internet ecology , etc . '' in @xcite he and hughes give a condensed summary showing that `` if stochastic processes with exponential growth in expectation are killed ( or observed ) randomly , the distribution of the killed or observed state exhibits power - law behavior in one or both tails . ''",
    "this work encompasses : ( 1 ) geometric brownian motion ( gbm ) ; ( 2 ) discrete multiplicative processes ; ( 3 ) homogeneous birth and death processes ; and ( 4 ) galton - watson branching processes",
    ". in one of many variations on this theme , in his gbm model @xcite reed specifies a stochastic process that uses lognormal distributions varying continuously in time with an exponential mixing distribution and shows that this generates a `` double pareto - lognormal distribution . ''",
    "this has an asymptotic pareto upper tail and a central part approximately lognormal ; in addition , it exhibits interesting asymptotic behavior in the it lower tail where it is characterized by a direct ( rather than an inverse ) power law .",
    "reed has gone to great effort to demonstrate the high quality of the fit of this distribution for all ranges of values ( low , middle , high ) across a wide variety of size distributions such as particle and oil field sizes @xcite , incomes @xcite , internet file sizes and the sizes of biological genera @xcite .    in today",
    "s nomenclature , the term",
    "_ zipf s law _ has come to mean any power law distribution with an exponent close to the value @xmath0 , not just the word frequency law .",
    "( to be clear here , when we refer to power law distributions , we also mean the hybrids with power law tails that we have been considering . )",
    "the subset of power laws with this restricted exponent value is surprisingly large and includes the distribution of firm sizes @xcite , city sizes @xcite , the famous gutenberg - richter law for earthquake magnitudes @xcite and many others .",
    "gabaix @xcite pointed out that while it has long been known that stochastic growth processes could generate power laws , `` these studies stopped short of explaining why the zipf exponent should be 1 . '' to address this question , he has given a theoretical explanation of the genesis of a @xmath0 exponent for the zipf law for city populations , but in fact , his approach can be regarded more generally .",
    "his key idea is a variation of gibrat s @xcite _ law of proportion effect _ : using a fixed number of normalized city population quantities that sum to 1 and assuming growth processes ( expressed as percentages ) randomly distributed as i.i.d .",
    "variables with a common mean and variance , he proves that a steady state will satisfy zipf s law .",
    "this proof requires an additional strong assumption in order to reach a steady state , namely , a lower bound for the ( normalized ) population size .",
    "gabaix goes on to discuss relaxed versions of his model and how it fits into the larger context of similar work done by others .    in their monograph on zipf",
    "s law saichev et al @xcite modify and extend the core gabaix idea in numerous ways that render it more realistic . for concreteness , they present their work using the terminology of financial markets and corporate asset values , but they are very clear on how their models are relevant to a broad range of `` physical , biological , sociological and other applications . '' as with reed , gbm plays an important role in their investigations , which incorporate birth and death processes , acquisitions and mergers , the subtleties of finite - size effects and other features .",
    "notably , they focus on the sets of conditions that lead to an approximate @xmath0 exponent .    in both harrmoes and topse @xcite and",
    "corominas - murtra and sol @xcite @xmath0 emerges as a consequence of certain information theoretic ideas pertaining to the entropy function under growth assumptions . in @xcite",
    "the focus is on language and the expansion of vocabulary size while simultaneously maintaining finite entropy .",
    "the perspective in @xcite is broader , but still based on the idea of systems with an expanding number of possible states `` characterized by special features on the behavior of the entropy . ''",
    "there is another topic area of statistical research that impacts on our work .",
    "natural language word frequency distributions have been characterized as _",
    "large number of rare events _ ( lnre ) distributions because when collections of text are examined , no matter how big , there are always a large number of words that occur very infrequently in the sample @xcite .",
    "lnre behavior indicates a tip - of - the - iceberg phenomenon resulting from a bias that captures the most common words , but necessarily misses a vast quantity of rarely used words .",
    "this is a classic and much studied problem encountered in species abundance surveys in ecological research , where a key question becomes estimating the size of the _ zero abundance class _ - the typically great number of species not observed in a sample because of their rarity @xcite .",
    "to get an idea of the significance of this issue , consider that figure 3(a ) graphs the _ population _ ( or _ parent _ or _ theoretical _ ) word probabilities for the zipf - lognormal distribution , and not the _ sample _ frequencies as would be obtained from actually carrying out the monkey twitter experiment .",
    "simple visual inspection of figure 3(a ) indicates that the linear part of the graph ( i.e. , the power law tail ) holds for about 5 logarithmic decades or about the first 100000 word probabilities out of the total of 475255 probabilities plotted there",
    ". however , these 100000 probabilities comprise 97.4% of the total probability mass of all 475255 values .",
    "intuitively , it should be clear that sampling from this zipf - lognormal population distribution will be dominated by the zipf part , not the lognormal part . unless the sample size was astronomically large , so that the large number of low probability words showed up , the underlying structure of the parent distribution would not reveal itself . to carry this idea still further ,",
    "imagine the situation if the word length cutoff was on the order of @xmath156 characters , such as with real twitter .",
    "no experiment could be run within any realistic time frame to ever hope to obtain a sample sufficiently large to uncover the true hybrid character of the population distribution ",
    "the sample would always appear as a zipf law , not a zipf - lognormal law .",
    "this kind of _ visibility bias _ has been a constant and recurring theme in all areas where pareto - zipf type distributions have been studied @xcite .",
    "we believe its significance has been poorly appreciated in relation to this topic .",
    "finally , we will take a more birds - eye view of matters and remark that our application of random spacings is very much in the spirit of the enormously fruitful study of _ random matrix theory _ and a class of stochastic systems referred to as the _ kpz universality class_. along these lines borodin and gorin @xcite have discussed a variety of probabilistic systems  that can be analyzed by essentially algebraic methods , \" yet are applicable to a broad array of topics .",
    "miller s demonstration of power law behavior and an approximate @xmath0 exponent with increasing @xmath14 for the monkey model is in a similar vein .",
    "we regard this result as analogous to the borodin and gorin example of the de moivre - laplace proof of the clt for a sequence of i.i.d .",
    "bernoulli trials , which depends on having an explicit pre - limit distribution and then taking `` the limit of the resulting expression . ''",
    "( we want to add , however , that miller s model is ultimately _ too simple _ to reveal the approximate lognormal behavior of the monkey word probabilities - for that , we needed to assume non - identical letter probabilities . )",
    "our point is to make clear that the monkey model fits into a much larger conceptual scheme than appears at first glance .",
    "sample spacings provide a natural way to populate the letter probabilities in the monkey model through a random division of the unit interval .",
    "the shao and hahn asymptotic limit law for the logarithms of spacings then leads to the result that the exponent in the power law of word frequencies will tend towards a @xmath0 value under broad conditions as the number of letters in the alphabet increases .",
    "the monkey model can also be viewed as a branching tree structure . in that light , anscombe s clt reveals an underlying lognormal central part of the word frequency distribution when a finite word length cutoff is imposed .",
    "the resulting hybrid zipf - lognormal distribution has many connections to other work .",
    "the visibility bias inherent in sampling from this distribution is similar to what has been noted as a characteristic of many different empirical power laws .",
    "perline , r. the random division of the unit interval and the approximate @xmath0 exponent in the monkey - at - the - typewriter model of zipf s law . submitted to _ stat .",
    "_ march 5 , 2015 and under review .",
    "project gutenberg .",
    "michael hart .",
    "available online : http://www.gutenberg.org/ ( accessed on june 6 , 2014 ) . the plain text files for these four books , each in their original language , were used to obtain the word frequencies plotted in figure 1 : joyce , j. _ ulysses _ ; hugo , v. _ les miserables _ , volume 1 ; goethe , w. _ faust _ ; cervantes , m. _ don quijote_.                        mandelbrot , b.b .",
    "on the theory of word frequencies and on related markovian models of discourse . in _ structure of language and its mathematical aspects : proceedings of symposia on applied mathematics volume 3 _ ; jakobson , r. , ed .",
    "soc . : providence , ri , usa , 1961 ; pp .",
    "190 - 219 ."
  ],
  "abstract_text": [
    "<S> the distribution of word probabilities in the monkey model of zipf s law is associated with two universality properties : ( 1 ) the power law exponent converges strongly to @xmath0 as the alphabet size increases and the letter probabilities are specified as the spacings from a random division of the unit interval for any distribution with a bounded density function on @xmath1 $ ] ; and ( 2 ) , on a logarithmic scale the version of the model with a finite word length cutoff and unequal letter probabilities is approximately normally distributed in the part of the distribution away from the tails . </S>",
    "<S> the first property is proved using a remarkably general limit theorem for the logarithm of sample spacings from shao and hahn , and the second property follows from anscombe s central limit theorem for a random number of i.i.d . </S>",
    "<S> random variables . </S>",
    "<S> the finite word length model leads to a hybrid zipf - lognormal mixture distribution closely related to work in other areas .    </S>",
    "<S> a version of this paper was submitted to entropy on 11/20/15 . + </S>",
    "<S> this document was texd on 11/27/15 .    </S>",
    "<S> .5 in </S>"
  ]
}