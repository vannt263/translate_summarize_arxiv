{
  "article_text": [
    "due to their popularity , osns are excellent platforms for influence propagation",
    ". users of osns tend to reply / forward the content they are interested in , which makes the content visible to all other users in their social circles .",
    "one use case of influence propagation is the _ viral marketing campaigns _",
    "@xcite , where a company provides free samples of a product to some influential individuals ( the seed nodes ) , in order to spread the product information to at least a certain number of users via word - of - mouth effect .",
    "since the seminal paper by kempe et al .",
    "@xcite , influence propagation in osns has been studied in various contexts @xcite .    in previous works , there are two major types of influence propagation models : the triggering model @xcite and the continuous - time diffusion model @xcite . in the former , the influence propagates in rounds ,",
    "so that the propagation rates between all node pairs are the same . in the latter ,",
    "the propagation rate for a node pair is decided by a probability density function .    unfortunately , the models are not able to characterize one important property : a topic can propagate faster in osns once it becomes popular , which we confirmed by analyzing crawled twitter data .",
    "the reason is , the two models share a common feature that they are _ static _ : the constant propagation rates or the pdfs are known and remain fixed .",
    "thus , a propagation model that can allow changes in propagation rates _ based on the current status of the propagation _ is in need , to clearly depict influence propagation in reality .    with the observation",
    ", we propose the dip model that explicitly considers the rate increase .",
    "to analytically study the model , we formulate the tap - dip problem , which asks for minimizing the seed set size and guaranteeing that the number of nodes influenced can reach a certain threshold within time limit . during the process",
    ", the propagation rate may increase when number of influenced nodes is larger than an amount .",
    "the tap - dip problem has one new dimension , dynamic propagation rate , which makes it extremely challenging .",
    "as even computing the exact influence is # p - hard @xcite , solving influence propagation related problems in osns relies heavily on sampling techniques .",
    "each sample provides information on what nodes can be influenced by a certain node ( forward sampling @xcite ) or the set of nodes that may influence a target node ( reverse sampling @xcite ) .",
    "obviously , the sample generation process has no access to global information , such as the overall number of influenced nodes .",
    "thus , the sampling methods are not able to consider rate increase and can not be adapted in solving tap - dip .    to tackle the challenges brought by dynamic propagation rates , we propose the algorithm los ( lipschitz optimization scheme ) which can decide the best time that the propagation rate may increase , in terms of minimizing the number of seeds used to trigger the increase together with those to guarantee reaching thresholds . with a fixed time of the rate increase in each subproblem ,",
    "the sampling methods are again applicable . however , the subproblem is still complicated as it needs to meet the thresholds for both triggering the rate increase and satisfying the activation requirement . to solve the subproblem",
    ", we designed the first efficient algorithms for both multi - tap ( mtap ) and multi - influence maximization ( mim ) , based on the ris approach @xcite . using los ,",
    "the tap - dip problem can be solved with an approximation ratio of @xmath2 ( @xmath1 is the set of nodes in the osn ) , which is close to the best ratio @xmath3 that one can expect for tap _ without _ dip .",
    "experimentally , we demonstrate the efficiency of los and explore various settings of the dip model using several real - world osn datasets .    in summary ,",
    "our contributions are as follows .",
    "* we propose the tap - dip problem , the first influence propagation related problem that explicitly considers propagation rate increase .",
    "we also provide data analysis results that supports the rate increase in twitter . *",
    "we propose los , the first algorithm that can solve tap - dip with approximation guarantee of @xmath2 .",
    "also , as subroutines of los , we develop mminseed and multi - im algorithms , which are the first algorithms that can efficiently solve the mtap problem and the mim problem , respectively . *",
    "we perform extensive experiments on various real osn data sets to demonstrate both the efficiency of our proposed algorithms and the drastic difference in the solution when considering rate increase",
    ".    * related work . * kempe et al .",
    "@xcite are the first to study influence propagation in osns mathematically .",
    "their focus was on the influence maximization problem ( i m ) , which drew much attention in the research community @xcite .",
    "another major problem is what we termed as the tap @xcite .",
    "the main propagation model adopted in the papers is the triggering model @xcite or its variations , the independent cascading ( ic ) model or the linear threshold ( lt ) model .",
    "another model that considers variation in propagation rate is the continuous time diffusion model @xcite .",
    "however , both models assume known and fixed parameters for the diffusion , which may not represent the real - world scenarios .    as even computing",
    "the exact influence is # p hard @xcite , the mainstream approach of solving i m or tap relies extensively on sampling , which is inefficient ( due to many redundant samples ) until borgs et al .",
    "proposed the reverse influence sampling ( ris ) method in @xcite .",
    "the ris method was further refined in @xcite for better time complexity .",
    "however , the ris method was not yet applied to solve tap or mim .",
    "the existing solutions on tap @xcite , mtap @xcite or mim @xcite all utilized the classical sampling method proposed in @xcite , which has a much higher time complexity than ris .",
    "thus , no existing methods can solve tap or mim efficiently .",
    "* organization .",
    "* the rest of the paper is organized as follows . in section [ sc :",
    "model ] , we present our analysis on propagation rates and describe the dip model and the tap - dip problem .",
    "section [ sc : los ] and [ sc : mminseed ] discuss our solution , los to tap - dip .",
    "the performance of los and the behavior of the dip model are analyzed in section [ sc : exp ] .",
    "section [ sc : conclusion ] concludes the paper and provides some insights on how los can be extended to solve a more generalized tap - dip problem .",
    "in this section , we first analyze the twitter data we crawled , which provides solid evidence that being trending will highly likely increase the propagation rate of a topic .",
    "then we introduce the graph model of the osn and the dynamic influence propagation model .",
    "we present the formal definition of tap - dip at the end of this section .",
    "we crawled the tweet stream data for 93 different twitter trending topics in the us using twitter api , during the period of sept .",
    "2016 to oct . 2016 .",
    "specially , we collected the _",
    "retweets _ whose times are within three hours of the time that the topic first became trending .",
    "the retweets are separated by the trending time and into two groups , before trending and after trending . for each group",
    ", we calculate the average retweet delay , where a retweet delay is the time difference between the retweet and the original tweet .",
    "the average retweet delay is a good indicator of propagation speed , while the quotient of the delays before / after trending can discover the speed change due to being trending for each topic . in the process , we filter out the outlier retweets whose delays are larger than a day .",
    "also , we filter out the topics with limited number of valid retweets in any of its groups .",
    "the reason for filtering is that otherwise , the average delay in those cases can be too high or too low , which damages the validity of the analysis .",
    "we set the minimum number of required valid retweets to be @xmath4 for each group . after the filtering , 55 topics remained .    for conciseness",
    ", we only display the histograms of the quotients , while leaving the details in the supplementary materials .",
    "figure [ fig : ratebefore ] is the original speed change distribution , it indicates that more than 70% of the trending topics had the propagation speed increased ( only the left most bar indicates a decrease in speed ) . in reality",
    ", the users may retweet some old tweets after the topic becomes trending . in this case , the retweet delay can be altered as the difference between the trending time and the retweet time .",
    "figure [ fig : rateafter ] displays the speed change distribution after the modification . in this case , over 85% of the topics experienced a rate increase after being trending .",
    "clearly , the data supports the claim that popular topics can propagate faster , which strengthens the need of a dynamic influence propagation model , which we will address in the following .",
    "we abstract the osn to be a directed , connected graph @xmath5 , where @xmath1 denotes all the users in the osn , and @xmath6 corresponds to the relationships among the users ( follow , friend , etc . )",
    "each edge @xmath7 is associated with a weight @xmath8 $ ] and a probability density function @xmath9 , which are used to characterize the influence propagation model that is detailed in the following . also , the osn has a threshold @xmath10 such that when a topic influenced at least @xmath11 nodes , it will become trending .",
    "the propagation rate @xmath12 for a trending topic is @xmath13 , which value remains at @xmath14 for normal topics .      in this paper , to model the change in influence propagation rate while considering the impact of social relationship strength , we combine the ic model and the continuous - time diffusion model into the continuous ic model ( cic ) , whose definition is as follows .",
    "we denote the initial set of activated ( influenced ) nodes as @xmath15 .    consider a graph @xmath5 with @xmath9 and @xmath16 defined on each edge @xmath7 .",
    "the influence diffusion process starts when all nodes in @xmath15 are activated at time @xmath17 and all other nodes remain unactivated .",
    "when node @xmath18 is activated at time @xmath19 , each neighbor @xmath20 of @xmath18 will be activated at time @xmath21 with probability @xmath16 where @xmath22 follows the probability density function @xmath9 .",
    "once a node is activated , it will never be deactivated .",
    "the process stops when no more nodes can be activated .    based on the cic model , a trending topic can propagate faster , as it has a shorter delay in transmission .",
    "we denote @xmath23 as the total number of nodes influenced at time @xmath19 , given the initial seed set @xmath15 .",
    "also , we write @xmath24 $ ] as the _ influence spread _ of seed set @xmath15 up to time @xmath19 .    with the definition of @xmath23 and the connection between trending and faster propagation",
    ", we can characterize propagation rate @xmath12 as a function of time @xmath19 .",
    "according to @xcite , a topic is trending at time @xmath19 when the number of nodes influenced by the seed set @xmath15 is larger than fraction @xmath10 of nodes in @xmath1 .",
    "when the seed set @xmath25 is known , we have : @xmath26 in this section and for the major part of the paper , we focus on the case when the propagation rate can change only once , as such a case corresponds to our findings from data analysis . we will discuss the possibility of having multiple propagation rate changes in section [ sc : conclusion ] .      in a viral marketing campaign",
    ", the goal can often be influencing at least a certain number of users within a period of time .",
    "for example , a company showcasing its new product will want it to be exposed to a certain percentage of the market within a few days after the release .",
    "the company needs to choose some users as seeds to propagate the product information , and seeding each user incurs a cost . for cost - effectiveness",
    ", companies always want to minimize the number of seed users , when the costs of seeding the users are the same .",
    "thus , the problem can be rephrased as finding a seed set with minimum size such that the number of activated nodes can be at least a certain threshold @xmath27 .",
    "such a problem is termed as the _ threshold activation problem ( tap)_. in a typical tap problem , the underlying influence propagation model is often static , that the parameters of the model will not change overtime .",
    "tap - dip , however , is the version of tap that considers dynamic influence propagation models . in this paper , we focus on the tap problem with the propagation model cic .    given an osn @xmath5 with @xmath9 and @xmath16 defined on each edge @xmath7 , the activation threshold @xmath28 , the trending triggering threshold @xmath10 , the propagation rate @xmath29 , the time limit @xmath30 , tap - dip asks to find a seed set @xmath15 with minimum size such that the influence spread @xmath31 is at least @xmath32 .    in the following two sections , we detail los , our solution to tap - dip . for conciseness ,",
    "most of the proofs are placed in the appendix .",
    "in this section , we propose our solution , los , to tap - dip .",
    "lipschitz optimization @xcite is a technique to find global optimal values for unknown functions , given that the function satisfies lipschitz continuity .",
    "we postpone the details and focus on one question : why do we need it ?",
    "the sole reason why we introduce lipschitz optimization is that all of the existing solutions for influence propagation related problems require a fixed propagation model for sample generation .",
    "however , in tap - dip , we have no idea when the topic will become trending .",
    "thus , the sampling methods will face an unbreakable obstacle that they can not decide when the influence can reach the neighboring nodes from a just activated node , as the propagation rate is determined by global information : the number of nodes influence at that time .",
    "therefore , solving tap - dip requires prior knowledge on the propagation rates for all time points from @xmath33 to the time limit .",
    "as we only consider one time change in propagation rates , the requirement can be simplified to knowing the exact time of the `` speed - up '' . when the speed - up time @xmath19 is known , the sampling methods are at their full power and can be used to calculate the minimum number of seed nodes to ( 1 ) guarantee that the topic will become trending and the speed - up will happen at time @xmath19 ; ( 2 ) guarantee the overall influence reaches the threshold",
    ". we will detail our sample - based method in section [ sc : mminseed ] .",
    "for now , we assume the method to find the seed nodes is in a black box and denote @xmath34 as the minimum number of seed nodes when the speed - up happens at time @xmath19 .",
    "naturally , we want to find a @xmath35 such that @xmath36 is the minimum @xmath34 value in the domain of @xmath19 .",
    "then , the seed set calculated at time @xmath35 will be our solution .",
    "however , the function @xmath37 is unknown , as it may change with different network topology and propagation parameters and thus has no closed form .",
    "therefore , the job of optimizing @xmath37 is suitable for lipschitz optimization , once we can prove @xmath37 is lipschitz continuous .",
    "a function @xmath38 defined on @xmath39 is lipschitz continuous if there exists a real constant @xmath40 , such that for all @xmath41 , @xmath42    if we denote @xmath43 as the minimum distance between any two possible values of @xmath19 , we can easily prove that @xmath34 is lipschitz continuous with @xmath44 .",
    "unfortunately , lipschitz optimization can hardly benefit from such a crude estimation of @xmath45 .",
    "the larger the @xmath45 value , the more complicated the problem .",
    "therefore , we introduce a relaxed version of @xmath34 that a much smaller @xmath45 is achievable .",
    "we write the relaxed version of @xmath34 as @xmath46 , where @xmath47 denotes the minimum number of nodes to guarantee @xmath10 fraction of influenced nodes in @xmath48 and therefore a speed - up at @xmath19 ; @xmath49 denotes the minimum number of nodes to guarantee @xmath28 fraction of activation in @xmath48 _ given _ a speed - up at @xmath19 .",
    "notice that @xmath49 is calculated based on the assumption that the nodes triggered the speed - up did not influence any nodes in @xmath48 .",
    "therefore , @xmath50 is an upper bound of the number of required nodes .",
    "the following lemma demonstrates that the optimal value of @xmath50 is at most two times the optimal value of @xmath34 .",
    "[ lemma : ddipsinglebound ] @xmath51 where @xmath52 $ ] .",
    "it is clear that @xmath53 are monotonically decreasing / increasing with @xmath19 , respectively . in the following",
    ", we will prove that @xmath50 is lipschitz continuous using such a property .",
    "[ lemma : locallipschitzconstant ] given an interval @xmath54 $ ] and function values @xmath55 , @xmath50 is lipschitz continuous over @xmath54 $ ] with constant @xmath56    the following lemma ensures a lower bound on function value within any interval of function @xmath50 .",
    "[ lemma : locallowerbound ] @xcite when @xmath50 is lipschitz continuous over @xmath54 $ ] with constant @xmath45 , @xmath57}h(t)\\geq \\frac{h'(t_1)+h'(t_2)}{2}-\\frac{l(t_2-t_1)}{2}\\label{eqn : locallowerbound}\\end{aligned}\\ ] ]    with lemmas [ lemma : locallipschitzconstant ] and [ lemma : locallowerbound ] , we propose los for finding the global minimum of @xmath50 over @xmath58 $ ] . to calculate @xmath50 , we use alg . [ alg : mminseed ] , which is detailed in section [ sc : mminseed ] .    in los , we start with two values @xmath59 and one interval @xmath58 $ ] . in each iteration",
    ", we calculate one more @xmath50 value and increase the number of intervals by one . by lemma [ lemma : locallowerbound ]",
    ", we can have a lower bound on all function values in each interval .",
    "the key for los is the strategy of choosing the value @xmath60 in each iteration @xmath61 .",
    "intuitively , we pick @xmath60 in the interval with the smallest lower bound among all intervals , such that @xmath62 is likely to be closer to the global optimal .",
    "theorem [ theorem : lipschitzratio ] demonstrates that los can always find a solution that is larger than the optimal by at most @xmath14 .",
    "[ alg : mminseed ] to calculate @xmath63 $ ] the global minimizer @xmath64 of @xmath50 and the value @xmath65 calculate @xmath66 by alg .",
    "[ alg : mminseed ] .",
    "let @xmath67 , @xmath68 .",
    "calculate @xmath69 based on @xmath70 , @xmath61++ + calculate @xmath62 by alg .",
    "[ alg : mminseed ] + renumber all calculated points such that @xmath71 calculate @xmath72 based on + calculate @xmath73 based on rhs of + let @xmath74 @xmath75 + @xmath76 + calculate @xmath65 by alg .",
    "[ alg : mminseed ] .",
    "+ @xmath77    [ theorem : lipschitzratio ] the output @xmath65 of alg .",
    "[ alg : lipschitz ] satisfies @xmath78 .",
    "in this section , we describe the missing piece in section [ sc : los ] : how to find a minimized seed set when the speed - up time is given , which completes the full picture of los . from alg .",
    "[ alg : lipschitz ] , we can observe that the required algorithm needs to complete two tasks : the first is to calculate @xmath50 , which can be further broken down to @xmath47 and @xmath49 ; the second is to calculate @xmath34 . with a closer look",
    ", we notice that the second task is a generalization of the first .",
    "the reason is that in calculating @xmath34 , the seed set is required to satisfy two thresholds : one is @xmath11 , for triggering the speed up at time @xmath19 ; another is @xmath32 , for fulfilling the activation requirement . while for @xmath47 and @xmath49 , only one threshold is required in each calculation . seeing this , we propose _ mminseed _ , the algorithm to minimize the seed set size and satisfy multiple thresholds .    in order to use mminseed in all scenarios ,",
    "we describe it in a generalized setting , then we discuss how it can be customized for finding @xmath50 and @xmath34 .",
    "as the name suggests , the multi - tap ( mtap ) problem considers multiple thresholds @xmath79 on ground sets @xmath80 in the osn @xmath5 .",
    "each ground set @xmath81 is a subset @xmath1 .",
    "the selected seed set in mtap is required to influence @xmath82 nodes in each ground set .",
    "notice that we consider a fixed propagation model in mtap .      due to the complexity from the probabilistic network ,",
    "sampling is the most popular method to estimate the influence spread of a seed set in each ground set .",
    "here we adopt the state - of - art reverse influence sampling ( ris ) technique @xcite for generating samples . specially , we combine the sampling methods in two recent papers @xcite to generate samples for each ground set under continuous ic propagation model .",
    "the ris approach has two phases . in the sample generation phase ,",
    "a number of samples are generated , where each sample consists of all nodes that can influence a random node in a realization of the probabilistic graph . in the seed set selection phase , a maximum coverage problem ( with nodes as sets and samples as elements ) is greedily solved to obtain the seed set for influence maximization .",
    "to adapt the ris framework to solve mtap , there are two obstacles .",
    "the first one is how to guide the solution to consider all the thresholds at the same time . a second and more challenging one",
    "is that , the ris framework is designed for maximizing influence with a fixed number of seeds .",
    "also , the number of samples required to guarantee a certain level of accuracy will increase with more seed nodes .",
    "however , mtap asks for minimizing the seed set size , which is unknown and can not be used to determine the number of required samples .      to overcome the first obstacle",
    ", we need to design an objective function that satisfies the following conditions : ( 1 ) maximizing the function will fulfill all thresholds .",
    "( 2 ) when a threshold is fulfilled , additional influence to the corresponding ground set should not bring any benefit to the function ( 3 ) the function must be submodular .",
    "the first two conditions insure the correctness of the function , while the last one guarantees the performance , as otherwise no approximation ratio will exist .    based on the conditions , we design the function @xmath83 , which is defined as @xmath84 where @xmath85 denotes the nodes influenced by @xmath15 in the ground set @xmath86 .",
    "clearly , @xmath83 is submodular and monotone increasing as it is the summation of submodular functions .",
    "also , each ground set can contribute up to its threshold to the function value .",
    "additionally , the maximum of this function can only be achieved when all thresholds are fulfilled .    in the following , we propose the mminseed algorithm .",
    "we delay its subroutine alg .",
    "[ alg : multiim ] and the theoretical analysis to section [ ssc : theoreticalanalysis ] .    in mminseed , the process of finding the number of seeds utilizes the submodularity of @xmath87 . in each round",
    ", mminseed calculates the average gain in @xmath87 of a seed node added in the previous round and the gap from the current @xmath88 value to the requirement .",
    "then it decides how many new seed nodes are required , assuming all the new nodes can bring the gain equal to the average value calculated .",
    "the approach will reduce the number of calls to alg .",
    "[ alg : multiim ] . comparing with binary search ,",
    "the greatest advantage of this approach is that it will never choose a seed set size that is larger than necessary , which is guaranteed by submodularity .",
    "a larger seed set is not preferable since it leads to generating more samples , which is redundant and costs extra time .",
    "graph @xmath5 , ground sets @xmath80 with thresholds @xmath79 , @xmath89 seed set @xmath90 @xmath91 .",
    "+ @xmath92 , @xmath93 , @xmath94 + find @xmath15 using alg .",
    "[ alg : multiim ] with @xmath95 + @xmath96 + @xmath97 + find @xmath15 using alg .",
    "[ alg : multiim ] with @xmath95 @xmath15      in the tap - dip problem , the ground sets for both the trending threshold @xmath10 and the activation threshold @xmath28 are the same , which is @xmath1 .",
    "then , for estimating @xmath34 , we let @xmath98 , @xmath99 , @xmath100 . for estimating @xmath47 , we just have @xmath99 . for @xmath49 , simply let @xmath101 .",
    "however , the time limit or propagation rate for each threshold can be different . in mminseed",
    ", we assume that a trending threshold is met when the expected influence , but not the real influence , is larger than @xmath11 .",
    "this assumption is validated in @xcite , as the influence is concentrated at the expectation .",
    "we will also demonstrate in our experiments that the performance of the algorithms are satisfactory .",
    "since @xmath87 is submodular , the following result @xcite holds using the greedy algorithm , if all @xmath87 values can be obtained in polynomial time : @xmath102 where @xmath103 is the collection of the first @xmath104 sets selected by the greedy algorithm to maximize @xmath87 and @xmath105 is the optimal collection of size @xmath61 ( that yields the maximum @xmath87 value among all collections with size at most @xmath61 ) .    however , the values of @xmath87 are not accurate but estimated by ris .",
    "we have the following claim , which will be used to prove the approximation ratio of mminseed . how the validity of claim [ claim : greedyguarantee ] can be ensured by alg .",
    "[ alg : multiim ] will be discussed later in this section .",
    "[ claim : greedyguarantee ] @xmath106 with a high probability .",
    "[ theorem : greedybicriteriaratio ] alg .",
    "[ alg : mminseed ] has approximation ratio @xmath107 and achieves at least @xmath108 of the required @xmath87 value , given the correctness of claim [ claim : greedyguarantee ] .",
    "graph @xmath5 , ground sets @xmath80 with thresholds @xmath79 , precision parameters @xmath89 , @xmath109 seed set @xmath25 collection of samples @xmath110 + @xmath111",
    "@xmath112 + @xmath113 + @xmath114 = greedy size @xmath61 solution to maximize @xmath115 + @xmath116 + generate @xmath117 samples for @xmath118 .",
    "+ @xmath119 @xmath114    los has an approximation ratio of @xmath2 .",
    "the result follows directly by combining lemma [ lemma : ddipsinglebound ] , theorem [ theorem : lipschitzratio ] and theorem [ theorem : greedybicriteriaratio ] .    in the following",
    ", we will first derive the number of samples required to guarantee claim [ claim : greedyguarantee ] in theorem [ theorem : numberofsamples ] .",
    "then , we propose our algorithm , alg .",
    "[ alg : multiim ] that solves a general problem of maximizing @xmath83 as defined in with @xmath45 thresholds @xmath120 and @xmath45 ground sets , using at most @xmath61 nodes as seed nodes .",
    "[ alg : multiim ] ensures the total number of samples is at least and thus leads to claim  [ claim : greedyguarantee ] .",
    "[ lemma : numberofsampleguarantee ] alg . [ alg : multiim ] guarantees the number of samples for each threshold is at least @xmath121 when it stops , with probability at least @xmath122 .",
    "[ theorem : numberofsamples ] the number of samples required to guarantee with probability at least @xmath123 is @xmath124 and @xmath125 @xmath126 and @xmath89 are constants .",
    "one special feature for mim is that for small values of @xmath61 , @xmath127 can be @xmath33 for some @xmath128 .",
    "in such cases , the above lemmas hold trivially and the number of required samples is defined as @xmath33 .",
    "now we introduce our algorithm to mim , alg .",
    "[ alg : multiim ] .",
    "it maintains @xmath45 collections of samples @xmath129 ( one for each threshold ) and it keeps generating new samples for each collection up to a given amount @xmath117 .",
    "then , alg . [ alg : multiim ] greedily solves a submodular maximization problem with the submodular function @xmath83 defined in , using at most @xmath61 nodes .",
    "the resulting set @xmath114 is used to verify if the number of samples intersect with @xmath114 , @xmath130 , is at least @xmath131 .",
    "if the verification is successful , @xmath118 is enough to guarantee the accuracy of estimating the ground set .",
    "it then stops generating new samples for @xmath118 . otherwise , it doubles @xmath117 , generating samples up to @xmath117 and rerun the verification .",
    "when all @xmath118 passed the verification , the solution @xmath114 is returned as output .",
    "[ alg : multiim ] guarantees claim [ claim : greedyguarantee ] with probability at least @xmath132 .",
    "the result is straightforward when combining theorem [ theorem : numberofsamples ] and lemma [ lemma : numberofsampleguarantee ] , and applying the union bound .",
    "the experiments are conducted on a linux machine with 2.3ghz xeon 18 core processor and 256 gb of ram .",
    "we carry experiments under continuous ic models on the following datasets from @xcite .",
    ".datasets statistics [ cols= \" < , > , > , > , > \" , ]     * datasets . *",
    "we select a set of 8 osn datasets of various sizes to fully test the impact of the dynamic influence propagation model .",
    "the description summary of those datasets is shown in table [ tab : data_sum ] .    * parameter settings .",
    "* we follow the papers @xcite for setting propagation probability @xmath16 , which is calculated as @xmath133 where @xmath134 denotes the indegree of node @xmath20 .",
    "we model the propagation rate using weibull distribution as @xcite and fix the shape parameter at @xmath135 , scale parameter at @xmath14 throughout the experiments .    in all the experiments , we keep @xmath136 and @xmath137 if the values are not stated otherwise .",
    "the time limit is set at 10 .",
    "the values of @xmath29 , the propagation rate change , varies from @xmath138 to @xmath139 .",
    "the @xmath140 values are not set explicitly , instead , we set the number of nodes required for being trending ( t - node ) and for overall activation requirement(a - node ) , based on the size of the networks .",
    "the parameters are summarized in table [ tab : data_sum ] .",
    "since the tap - dip problem is new , there are no suitable algorithms that can be compared directly with los .",
    "instead , we demonstrate the performance of los via its subroutine .",
    "we compare the mminseed algorithm with its variation that uses the imm algorithm @xcite instead of the multi - im algorithm ( [ alg : multiim ] ) as a subroutine . in the comparison ,",
    "we only allow one threshold and modify imm s sampling method to allow the continuous - ic model .",
    "the comparison is based on the scenario with no rate change and the lowest activation threshold for each network .",
    "figure [ fig : time_compare ] proves a clear difference of the running time.the multi - im supported mminseed is much faster ( the running time is in log scale ) than the one supported by imm . the main reason for the superior performance of multi - im is that it decides the sample requirement dynamically , while imm has a parameter estimation stage to estimate the number of required samples , which can be inaccurate and results in a sample collection that is much larger than necessary when the seed set size is small . in the running time comparison , we set @xmath141 to allow imm finish in reasonable time .",
    "each number is the average of 10 runs , as the variation of running time is small and the difference is apparent .",
    "[ [ scalability - of - los . ] ] scalability of los .",
    "+ + + + + + + + + + + + + + + + + + +    during our experiments , we observe that all the scenarios had less than @xmath142 iterations inside los , which means the time complexity of los is larger than that of mminseed only by a multiplicative constant ( @xmath143 ) .",
    "figure [ fig : runningtime ] demonstrates the scalability of los .",
    "the trend line denotes the size of different networks ( number of edges ) and the box plots displays the running time in different networks with various settings .",
    "we can observe a nice feature of los that its running time grows linearly in terms of network size .",
    "for large networks such as pokec ( 61.2 m edges ) and livejournal ( 138 m edges ) , los can finish within three hours .",
    "figure [ fig : seeddistribution ] compares the seed sets obtained by los ( los seeds ) and those obtained by solving the tap problem without considering the rate increase ( base seeds ) . in the pie charts ,",
    "the shared seeds means the proportion of seed nodes that exists in both los seeds and base seeds .",
    "the data in each chart is averaged among the result from 180 runs of various settings . clearly , running los and considering",
    "the rate increase explicitly result in a large reduction in number of seeds required .    as the los seed set is mostly a subset of the base seed set",
    ", we would expect that the los seed set has a smaller influence spread .",
    "however , we will demonstrate that the los seeds can still meet the threshold with extensive simulations .",
    "for each setting in each dataset , we simulate @xmath144 random propagation process from both the los seeds and the base seeds .",
    "the rate increase is applied when the _ actual _ number of influenced nodes hit the trending thresholds .",
    "figure [ fig : coverage ] depicts the percentage of nodes activated when comparing with the corresponding threshold .",
    "as we set @xmath145 at @xmath146 , the reference line is drawn at @xmath147 .",
    "a point over the reference line means the average activated nodes ( over 10,000 simulations ) in a certain scenario meets @xmath147 of the threshold .",
    "in all the four datasets , the base seed set activated much more nodes than required by the threshold , which suggests that their size can actually be reduced . in most cases",
    ", the los seed sets can meet the requirement .",
    "one exception is in the wikivote data set , a close inspection reveals that the actual time of rate increase is larger than the expected time and los overestimated the effect of rate increase .",
    "it is likely that the influence spread in wikivote is not concentrated at the expectation .      in this section ,",
    "we test the impact of three parameters : @xmath29 ( the propagation rate after trending ) , t - node ( # nodes required to be trending ) and a - node ( overall activation requirement ) to the behavior of los .",
    "the results are displayed in heat maps , a warmer color means an earlier time for rate increase ( decided by los ) .",
    "the data sets are grouped based on parameter setting ( refer to table [ tab : data_sum ] for details ) into small ( facebook and wikivote ) , medium ( gplus , twitter , epinions and slashdot ) and large ( livejournal and pokec ) . in each heat map , we vary two parameters and take average over the other . as we did not complete all experiments on large datasets , we will only display one heatmap for them .",
    "a warmer color in a cell denotes a earlier time for rate increase .    in figure",
    "[ fig : ssr ] , we vary @xmath29 and t - nodes .",
    "one clear trend is that when more t - nodes are required , los tend to choose a later time for starting the trend and the speed up .",
    "it is reasonable as it can be costly to activate t - nodes early when the number is high . as we observed in some scenarios",
    ", los may choose not to have the speed up at all when t - node is too large and @xmath29 is small .",
    "what seems counter - intuitive in figure [ fig : ssr ] is that los may not choose to have the speed up earlier when @xmath29 increases .",
    "this phenomena can possibly explained from the perspective of cost .",
    "with a larger @xmath29 , los can influence a set of nodes in less time , even with the same seed set .",
    "thus , los is not that `` hurry '' of starting the speed up , as it is able to reach the threshold when triggering the speed up later with less cost .    in figure [",
    "fig : srcr ] , we vary @xmath148 . in most of the cases ,",
    "los tend to have the speed up earlier when facing a larger threshold .",
    "the opposite is shown in some rare cases , mostly because @xmath29 is too low or @xmath149 is too high , which makes los think starting the speed - up early is not beneficial .",
    "in this paper , we proposed a novel dynamic influence propagation model , which can more accurately characterize the information diffusion in social networks compared with the existing propagation models .",
    "the model is supported by analysis of the retweet data we crawled , that most topics will propagate faster after being trending . to study the impact of dip in osns",
    ", we propose a new tap - dip problem by substituting the static propagation model in tap with dip .",
    "although tap - dip is even harder than dip , we designed the los algorithm that can solve it with approximation ratio similar to the best for tap . in experiments , we demonstrated that los can generate high quality seed sets and is also scalable .",
    "the idea of varying propagation rates may also impact some closely related problems .",
    "for example , to restraining misinformation propagation @xcite with dip can be challenging .",
    "also , the current tap - dip problem allows a single rate increase , yet the propagation rate of some topics may change multiple times , or even continuously .",
    "also , tap - dip requires activating one threshold , while some variations of tap may need to activate different thresholds for different target groups , especially for multiplex osns or osns with clear community structure @xcite .",
    "notice that if we can fix all the times for rate increase , the mminseed algorithm is still applicable , as it is general enough to handle multiple thresholds at the same time .",
    "however , the performance of the los algorithm may be degraded , since we need to locate not one , but multiple times for rate increase , and multi - variate lipschitz optimization can be time - consuming . to tackle this problem",
    ", we may allow heuristic algorithms that focus on one rate increase time per iteration and assume all other times are fixed .",
    "we leave the design of such heuristic algorithms , or even a completely new algorithm to solve tap - dip , in future work .",
    "* proof of lemma [ lemma : ddipsinglebound ] *    first , it is clear that @xmath150 and @xmath151 by definition of optimal values of @xmath37 and @xmath152 .",
    "we also claim that @xmath153 as otherwise , at least one of @xmath154 is not minimum . therefore , @xmath155    * proof of lemma [ lemma : locallipschitzconstant ] *    denote @xmath156 as two arbitrary points in @xmath54 $ ] .",
    "as @xmath157 are monotone decreasing / increasing respectively , we have @xmath158    therefore , @xmath159    similarly , @xmath160    thus , @xmath161    * proof of theorem [ theorem : lipschitzratio ] *    by the time alg .",
    "[ alg : lipschitz ] stops , the global minimum @xmath162 of @xmath163 is lower bounded by @xmath164 as @xmath165 is the minimum lower bound of all intervals . since @xmath166 is the minimum of all calculated function values , we have : @xmath167    * proof of theorem [ theorem : greedybicriteriaratio ] *    denote the optimal solution to mtap as @xmath168 .",
    "we consider the greedily selected collection @xmath103 with smallest @xmath104 that satisfies @xmath169 where @xmath170 is a constant .",
    "so , we want to solve the equation @xmath171 . by",
    ", we have @xmath172 the last inequality follows as @xmath173 and @xmath174 . by selecting @xmath175 , we have @xmath176 and the coverage @xmath177 is at least @xmath178 .",
    "* proof of theorem [ theorem : numberofsamples ] *    we write @xmath179 where @xmath180 . denote @xmath118 as the collection of samples for estimating @xmath181 and @xmath182 where @xmath183 when @xmath184 and 0 otherwise",
    ". define @xmath185 denote the optimal size @xmath61 solution that maximizes @xmath83 as @xmath105 and the greedy size @xmath104 solution as @xmath103 .",
    "now , we bound the number of samples required to approximate @xmath186 using @xmath187 with @xmath188 ratio and arrive at",
    ".    we will need the following two lemmas in our proof .",
    "[ lemma : firstthreshold ] @xcite let @xmath189 , and @xmath190 if the total number of samples is at least @xmath191 , then @xmath192 holds with at least @xmath193 probability , for the optimal seed set @xmath168 .",
    "[ lemma : secondthreshold ] @xcite let @xmath194 and @xmath195 for the set @xmath196 , if @xmath197 and the total number of samples is at least @xmath198 , then @xmath199 holds with at least @xmath200 probability .",
    "the original lemma [ lemma : secondthreshold ] is only for the case when @xmath201 and for function @xmath202 instead of @xmath83 , yet it can be easily extended to this more generalized version .",
    "also , since we consider situations with @xmath203 and the first derivative of @xmath204 is positive , we can increase @xmath61 such that @xmath205 and achieve a upper bound @xmath206 on @xmath198 with single variable @xmath104 .",
    "@xmath207 we now claim that @xmath208 holds with probability @xmath209 with at least @xmath191 samples .    to prove the claim , we consider four situations w.r.t .",
    "@xmath210 and @xmath211 for each @xmath128 .    *",
    "situation 1 : * @xmath212 .",
    "in this situation , @xmath213 and @xmath214 and the claim holds naturally due to lemma [ lemma : firstthreshold ] .",
    "* situation 2 : * @xmath215 .",
    "in this situation , @xmath213 and @xmath216 . by lemma",
    "[ lemma : firstthreshold ] , @xmath217    * situation 3 : * @xmath218 .",
    "in this situation , @xmath219 and @xmath220 .",
    "so , @xmath221 .",
    "* situation 4 : * @xmath222 .",
    "in this situation , @xmath223 , so @xmath224 .    combining the results from all four possible situations ,",
    "we have proved the claim .    with both lemma [ lemma : secondthreshold ] and the claim ,",
    "the minimum number of samples to guarantee is @xmath225 .",
    "we write @xmath226 by @xcite , setting @xmath227 where @xmath125 bring the number of samples to @xmath228 which is larger than @xmath229 by at most a small constant .",
    "the probability of ensuring is at least @xmath123 by union bound .",
    "* proof of lemma [ lemma : numberofsampleguarantee ] *    we introduce lemma [ lemma : martingale ] this proof .",
    "[ lemma : martingale]@xcite for any @xmath89 , @xmath230\\leq e^{-\\frac{\\epsilon^2}{2+\\frac{2}{3}\\epsilon}t \\mu_x}\\end{aligned}\\ ] ]    here we consider bernoulli random variables @xmath231 with mean @xmath232 .",
    "@xmath233 \\leq \\pr[\\sum_{i=1}^{|\\mathcal{r}^l|}x_{s_k}^i\\leq \\sum_{i=1}^{q^l}x_{s_k}^i]\\\\          & = \\pr[c_{\\mathcal{r}^l}(s_k)\\leq \\sum_{i=1}^{q_l}x_{s_k}^i]\\\\          & \\leq pr[\\gamma^l\\leq \\sum_{i=1}^{q_l}x_{s_k}^i]\\\\          & \\leq pr[\\frac{(1+\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2})q^l\\times \\mathbb{i}(s_k)}{|v^l|}\\times \\frac{\\mathbb{i}(s_k^*)}{\\mathbb{i}(s_k)}\\leq \\sum_{i=1}^{q_l}x_{s_k}^i]\\\\          & \\leq   pr[\\sum_{i=1}^{q^l}x_{s_k}^i - q^l\\mu_{x_{s_k}}\\geq \\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2}q^l\\mu_{x_{s_k}}\\frac{\\mathbb{i}(s^*_k)}{\\mathbb{i}(s_k ) } ] \\\\          & \\leq \\exp(-\\frac{(\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2})^2(\\frac{\\mathbb{i}(s^*_k)}{\\mathbb{i}(s_k)})^2}{2+\\frac{2}{3}(\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2})\\frac{\\mathbb{i}(s^*_k)}{\\mathbb{i}(s_k)}}q^l \\mu_{x_{s_k } } ) \\quad\\text{(lemma \\ref{lemma : martingale})}\\\\          & \\leq \\exp(-\\frac{(\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2})^2\\mathbb{i}(s^*_k)}{2\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2}|v^l|}q^l)\\\\          & \\leq \\exp(-\\frac{\\log \\frac{3l^2}{(2l-1)\\delta}\\frac{1}{\\phi^2}\\mathbb{i}(s^*_k)}{2|v^l|}q^l)\\leq \\frac{2l-1}{3l^2}\\delta\\qquad\\qquad\\end{aligned}\\ ] ]",
    "figure [ fig : ratenumberinc ] displays the status for each individual topic after trending .",
    "the @xmath234-axis is the speed increase rates , which we summarized in figure [ fig : ratebefore ] .",
    "the @xmath235-axis ( in log scale ) denotes the multiplicative increase in number of retweets after a topic was trending .",
    "the size of each circle denotes the amount of retweets for a topic .",
    "we can observe from fig .",
    "[ fig : ratenumberinc ] that all topics had more retweets after trending and a majority of them had a faster propagation rate .    from figure",
    "[ fig : ratenumberinc ] , we are able to explore another dimension of the data , that is the number of retweets for each topic , which hints a possible reason of the rate decrease .",
    "we observe that the topics that had a speed decrease tend to have a larger number of retweets , compared with those topics that had a speed increase .",
    "it is likely that the user distributions for the topics are different .",
    "some very popular topics may draw the attention of a wide range of audiences , including those who are not that interested , while the other topics may only attract the users who show a strong interest .",
    "intuitively , a user with stronger interest in a topic may interact with the others at a much faster pace and those comparatively lack interest in a topic may not respond as fast .",
    "thus , the topics with more retweets ( which indicates they are popular ) may likely have a higher retweet delay after trending .",
    "another possible reason for the rate decrease is how the topics become trending . in one case",
    ", there can be many users interested in a topic and tweeted individually . in another case",
    ", a smaller group of users can have heated discussions on a certain topic . in both cases",
    ", twitter may sense the large volume of content on one topic and the topic will be marked as trending . in the first case , being trending will draw the attention of more people and those who are previously interested in the topic will also be interested to retweet to start some discussion . in the second case ,",
    "however , the heat from the discussions may already die down when the topic becomes trending , which can result in a longer retweet delay ."
  ],
  "abstract_text": [
    "<S> although influence propagation of online social networks ( osns ) is widely studied in literature , none of the existing works can cope with the situation that the propagation rate dynamically increases for popular topics . </S>",
    "<S> instead , they all assumed known rates ( either constants or drawn from known distributions ) for influence propagation models </S>",
    "<S> . however , such models can not correctly describe influence diffusion in reality .    in this paper </S>",
    "<S> , we propose a novel model , dynamic influence propagation ( dip ) , that allows propagation rate to change during the diffusion , based on which we define a new problem : threshold activation problem under dip ( tap - dip ) , which adds another layer of complexity over the already # p - hard tap problem . despite the hardness of tap - dip </S>",
    "<S> , we are able to design a lipschitz optimization scheme ( los ) that can solve tap - dip with @xmath0 ratio where @xmath1 is the set of nodes in the osn . using various real osn datasets </S>",
    "<S> , we experimentally demonstrate that los not only generates high - quality yet much smaller seed sets when being aware of the rate increase , but also scalable . </S>"
  ]
}