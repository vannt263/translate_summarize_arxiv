{
  "article_text": [
    "as advances in technology allow for the collection and storage of vast databases , there is a growing need for advanced machine learning techniques for speeding up the execution of queries on such large datasets . in this work we focus on the fundamental task of estimating the selectivity , or output size , of a database query , which is a crucial step in a number of query processing tasks such as execution plan",
    "optimization and resource allocation in parallel and distributed databases .",
    "the task of efficiently obtaining such accurate estimates has been extensively studied in previous work with solutions ranging from storage of pre - computed statistics on the distribution of values in the tables , to online sampling of the databases , and to combinations of the two approaches  @xcite .",
    "histograms , simple yet powerful statistics of the data in the tables , are the most commonly used solution in practice , thanks to their computational and space efficiency",
    ". however , there is an inherent limitation to the accuracy of this approach when estimating the selectivity of queries that involve either multiple tables / columns or correlated data .",
    "running the query on freshly sampled data gives more accurate estimates at the cost of delaying the execution of the query while collecting random samples from a disk or other large storage medium and then performing the analysis itself .",
    "this approach is therefore usually more expensive than a histogram lookup .",
    "our goal in this work is to exploit both the computational efficiency of using pre - collected data and the provable accuracy of estimates obtained by running a query on a properly sized random sample of the database .",
    "we apply the statistical concept of vc - dimension  @xcite to develop and analyze a novel technique to generate accurate estimates of query selectivity . roughly speaking , the vc - dimension of a collection of indicator functions ( hypotheses ) is a measure of its complexity or expressiveness ( see sect .  [",
    "sec : vcdim ] for formal definitions )",
    ". a major theoretical contribution of this work , which is of independent interest , is an explicit bound to the vc - dimension of any class of queries , viewed as indicator functions on the cartesian product of the database tables . in particular , we show that the vc - dimension of a class of queries is a function of the maximum number of boolean , select and join operations in any query in the class , but it is not a function of the number of different queries in the class . by adapting a fundamental result from the vc - dimension theory to the database setting ,",
    "we develop a method that for any class of queries , defined by its vc - dimension , builds a concise sample of the database , such that with high probability , the execution of _ any _ query in the class on the sample provides an accurate estimate for the selectivity of the query on the original large database .",
    "the error probability holds _ simultaneously _ for the selectivity estimate of _ all _ queries in the collection , thus the same sample can be used to evaluate the selectivity of multiple queries , and the sample needs to be refreshed only following major changes in the database .",
    "the size of the sample does not depend on the size ( number of tuples ) in the database , just on the complexity of the class of queries we plan to run , measured by its vc - dimension .",
    "both the analysis and the experimental results show that accurate selectivity estimates can be obtained using a sample of a surprising small size ( see table  [ tab : samplesize ] for concrete values ) , which can then reside in main memory , with the net result of a significant speedup in the execution of queries on the sample .",
    "a technical difficulty in applying the vc - dimension results to the database setting is that they assumes the availability of a uniform sample of the cartesian product of all the tables , while in practice it is more efficient to store a sample of each table separately and run the queries on the cartesian product of the samples , which has a different distribution than a sample of the cartesian product of the tables .",
    "we develop an efficient procedure for constructing a sample that circumvents this problem ( see sect .  [",
    "sec : applications ] ) .",
    "we present extensive experimental results that validate our theoretical analysis and demonstrate the advantage of our technique when compared to complex selectivity estimation techniques used in postgresql and the microsoft sql server .",
    "the main advantage of our method is that it gives provably accurate predictions for the selectivities of all queries with up to a given complexity ( vc - dimension ) specified by the user before creating the sample , while techniques like multidimensional histograms or join synopses are accurate only for the queries for which they are built .",
    "note that we are only concerned with estimating the selectivity of a query , not with approximating the query answer using a sample of the database ( das  @xcite presents a survey of the possible solutions to this latter task ) .",
    "[ [ outline . ] ] outline .",
    "+ + + + + + + +    the rest of the paper is organized as follows .",
    "we review the relevant previous work in sect .",
    "[ sec : prevwork ] . in sect .",
    "[ sec : prelim ] we formulate the problem and introduce the vapnik - chervonenkis dimension and the related tools we use in developing our results .",
    "our main analytical contribution , a bound on the vc dimension of class of queries is presented in sect .",
    "[ sec : vcdimqueries ] .",
    "the application of these results for selectivity estimation is given in sect .",
    "[ sec : applications ] .",
    "experiments are presented in sect .",
    "[ sec : experiments ] .",
    "methods to estimate the selectivity ( or cardinality of the output ) of queries have been extensively studied in the database literature primarily due to the importance of this task to query plan optimization and resource allocation .",
    "a variety of approaches have been explored , ranging from the use of sampling , both online and offline , to the pre - computation of different statistics such as histograms , to the application of methods from machine learning  @xcite , data mining  @xcite , optimization  @xcite , and probabilistic modeling  @xcite .",
    "the use of sampling for selectivity estimation has been studied mainly in the context of online sampling  @xcite , where a sample is obtained , one tuple at a time , after the arrival of a query and it used only to evaluate the selectivity of that query and then discarded .",
    "sampling at random from a large database residing on disk is an expensive operation  @xcite , and in some cases sampling for an accurate cardinality estimate is not significantly faster than full execution of the query  @xcite .",
    "a variety of sampling and statistical analysis techniques has been tested to improve the efficiency of the sampling procedures and in particular to identify early stopping conditions .",
    "these include sequential sampling analysis  @xcite , keeping additional statistics to improve the estimation  @xcite , labelling the tuples and using label - dependent estimation procedures  @xcite , or applying the cumulative distribution function inversion procedure  @xcite .",
    "some work also looked at nonuniform sampling  @xcite and stratified sampling  @xcite . despite all these relevant contributions ,",
    "online sampling is still considered too expensive for most applications .",
    "an offline sampling approach was explored by ngu  et  al .",
    "@xcite , who used systematic sampling ( requiring the tuples in a table to be sorted according to one of the attributes ) with a sample size dependent on the number of tuples in the table .",
    "the paper does not give any explicit guarantee on the accuracy of their predictions .",
    "chaudhuri  et  al .",
    "@xcite present an approach which uses optimization techniques to identify suitable strata before sampling .",
    "the obtained sample is such that the mean square error in estimating the selectivity of queries belonging to a given workload is minimized , but there is no quality guarantee on the maximum error .",
    "haas  @xcite developed hoeffding inequalities to bound the probability that the selectivity of a query estimated from a sample deviates more than a given amount from its expectation .",
    "however , to estimate the selectivity for multiple queries and obtain a given level accuracy for all of them , simultaneous statistical inference techniques like the union bound should be used , which are known to be overly conservative when the number of queries is large  @xcite . on the contrary , our result will hold simultaneously for _ all _ queries within a given complexity ( vc dimension ) .",
    "a technical problem arises when combining join operations and sampling . as pointed out by chaudhuri  et  al .",
    "@xcite , the cartesian product of uniform samples of a number of tables is different from a uniform sample of the cartesian product of those tables .",
    "furthermore , given a size @xmath0 , it is impossible to a priori determine two sample sizes @xmath1 and @xmath2 such that uniform samples of these sizes from the two tables will give , when joined together along a common column , a sample of the join table of size @xmath0 . in sect .",
    "[ sec : applications ] we explain why only the first issue is of concern for us and how we circumvent it .    in practice",
    "most database systems use pre - computed statistics to predict query selectivity  @xcite , with histograms being the most commonly used representation . the construction , maintenance , and use of histograms",
    "were thoroughly examined in the literature  @xcite , with both theoretical and experimental results .",
    "in particular chaudhuri  et  al .",
    "@xcite rigorously evaluated the size of the sample needed for building a histogram providing good estimates for the selectivities of a large group of ( select only , in their case ) queries .",
    "kaushik  et  al .",
    "@xcite extensively compared histograms and sampling from a space complexity point of view , although their sample - based estimator did not offer a uniform probabilistic guarantee over a set of queries and they only consider the case of foreign - key equijoins .",
    "we address both these points in our work .",
    "although very efficient in terms of storage needs and query time , the quality of estimates through histograms is inherently limited for complex queries because of two major drawbacks in the use of histograms : intra - bucket uniformity assumption ( i.e. , assuming a uniform distribution for the frequencies of values in the same bucket ) and inter - column independence assumption ( i.e. , assuming no correlation between the values in different columns of the same or of different tables ) .",
    "different authors suggested solutions to improve the estimation of selectivity without making the above assumptions  @xcite . among these solutions",
    ", the use of multidimensional histograms  @xcite seems the most practical",
    ". nevertheless , these techniques are not widespread due to the extra memory and computational costs in their implementation .",
    "efficient and practical techniques for drawing random samples from a database and for updating the sample when the underlying tables evolve have been extensively analyzed in the database literature  @xcite .",
    "the _ vapnik - chervonenkis dimension _ was first introduced in a seminal article  @xcite on the convergence of probability distributions , but it was only with the work of haussler and welzl  @xcite and blumer  et  al .",
    "@xcite that it was applied to computational sampling and learning theory . since then , vc - dimension has encountered enormous success and application in the fields of computational geometry  @xcite and machine learning  @xcite but its use in system - related fields is not as widespread . in the database literature ,",
    "it was used in the context of constraint databases to compute good approximations of aggregate operators  @xcite .",
    "vc - dimension - related results were also recently applied in the field of database privacy by blum , ligett , and roth  @xcite to show a bound on the number of queries needed for an attacker to learn a private concept in a database .",
    "gross - amblard  @xcite showed that content with unbounded vc - dimension can not be watermarked for privacy purposes .    to the best of our knowledge ,",
    "our work is the first to provide explicit bounds on the vc - dimension of queries and to apply the results to query selectivity estimation .",
    "we consider a database @xmath3 of @xmath4 tables @xmath5 .",
    "we denote a column @xmath6 of a table @xmath7 as @xmath8 and , for a tuple @xmath9 , the value of @xmath10 in the column @xmath6 as @xmath11 .",
    "we denote the domain of the values that can appear in a column @xmath8 as @xmath12 .",
    "our focus is on queries that combine select and join operations , defined as follows .",
    "we do not take projection operations into consideration because their selectivities have no impact on query optimization .",
    "[ def : selectquery ] given a table @xmath7 with columns @xmath13 , a _ selection query _ @xmath14 on @xmath7 is an operation which returns a subset @xmath15 of the tuples of @xmath7 such that a tuple @xmath10 of @xmath7 belongs to @xmath15 if and only if the values in @xmath10 satisfy a condition @xmath16 ( the _ selection predicate _ ) expressed by @xmath14 . in full generality",
    ", @xmath16 is the boolean combination of clauses of the form @xmath17 , where @xmath18 is a column of @xmath7 , `` @xmath19 '' is one of @xmath20 and @xmath21 is an element of the domain of @xmath18 .",
    "we assume that all @xmath22 are such that it is possible to build total order relations on them .",
    "this assumptions does not exclude categorical domains from our discussion , because the only meaningful values for `` @xmath19 '' for such domains are `` @xmath23 '' and `` @xmath24 '' , so we can just assume an arbitrary but fixed order for the categories in the domain .",
    "[ def : joinquery ] given two tables @xmath25 and @xmath26 , a @xmath27 @xmath14 on a common column @xmath6 ( i.e. a column present both in @xmath25 and @xmath26 ) is an operation which returns a subset of the cartesian product of the tuples in @xmath25 and @xmath26 .",
    "the returned subset is defined as the set @xmath28 where `` @xmath19 '' is one of @xmath20 .",
    "our definition of a join query is basically equivalent to that of a _ theta - join _  ( * ? ? ?",
    "* sect.5.2.7 ) , with the limitation that the join condition @xmath16 can only contain a single clause , i.e. a single condition on the relationship of the values in the shared column @xmath6 and only involve the operators @xmath20 ( with their meaning on @xmath29 ) .",
    "the pairs of tuples composing the output of the join in our definition have a one - to - one correspondence with the tuples in the output of the corresponding theta - join .",
    "[ def : general query ] given a set of @xmath30 tables @xmath31 , a _ combination of select and join operations _",
    "is a query returning a subset of the cartesian product of the tuples in the sets @xmath32 , where @xmath33 is the output of a selection query on @xmath34 .",
    "the returned set is defined by the selection queries and by a set of join queries on @xmath35 .",
    "[ def : exectree ] given a query @xmath14 , a _ query plan _ for @xmath14 is a directed binary tree @xmath36 whose nodes are the elementary ( i.e. select or join ) operations into which @xmath14 can be decomposed .",
    "there is an edge from a node @xmath37 to a node @xmath38 if the output of @xmath37 is used as an input to @xmath38 .",
    "the operations on the leaves of the tree use one or two tables of the database as input .",
    "the output of the operation in the root node of the tree is the output of the query .",
    "it follows from the definition of a combination of select and join operations that a query may conform with multiple query plans .",
    "nevertheless , for all the queries we defined there is ( at least ) one query plan such that all select operations are in the leaves and internal nodes are join nodes  @xcite . to derive our results",
    ", we use these specific query plans .    two crucial definitions that we use throughout the work",
    "are the _ cardinality _ of the output of a query and the equivalent concept of _ selectivity _ of a query .",
    "[ def : cardsel ] given a query @xmath14 and a database @xmath3 , the _ cardinality _ of its output is the number of elements ( tuples if @xmath14 is a selection queries , pairs of tuples if @xmath14 is a join query , and @xmath30-uples of tuples for combinations of join and select involving @xmath30 tables ) in its output , when run on @xmath3 .",
    "the _ selectivity _",
    "@xmath39 of @xmath14 is the ratio between its cardinality and the product of the sizes of its input tables .",
    "our goal is to store a succint representation ( sample ) @xmath40 of the database @xmath3 such that an execution of a query on the sample @xmath40 will provide an accurate estimate for the selectivity of each operation in the query plan when executed on the database @xmath3 .",
    "the vapnik - chernovenkis ( vc ) dimension of a family of indicator functions ( or equivalently a family of subsets ) on a space of points is a measure of the complexity or expressiveness of set of functions in that structure  @xcite .",
    "a finite bound on the vc - dimension of a structure implies a bound on the number of random samples required for approximately learning that structure .",
    "we outline here some basic definitions and results and their adaptation to the specific setting of queries .",
    "we refer the reader to the works of alon and spencer  ( * ? ? ?",
    "14.4 ) , chazelle  ( * ? ? ?",
    "* chap .  4 ) , and vapnik  @xcite for an in - depth discussion of the vc - dimension theory .",
    "vc - dimension is defined on _ range spaces _ :    [ defn : rangespace ] a _ range space _ is a pair @xmath41 where @xmath42 is a ( finite or infinite ) set and @xmath43 is a ( finite or infinite ) family of subsets of @xmath42 .",
    "the members of @xmath42 are called _ points _ and those of @xmath43 are called _",
    "ranges_.    in our setting , for a class of select queries @xmath44 on a table @xmath7 , @xmath42 is the set of all tuples in the input table , and @xmath43 the family of the outputs ( as sets of tuples ) of the queries in @xmath44 when run on @xmath7 .",
    "for a class @xmath44 of queries combining select and join operations , @xmath42 is the cartesian product of the associated tables and @xmath43 is the family of outcomes of queries in @xmath44 , seen as @xmath30-uples of tuples , if @xmath30 tables are involved in the queries of @xmath44 . when the context is clear we identify the family @xmath43 with a class of queries .    to define the vc - dimension of a range space we consider the projection of the ranges into a set of points :    [ defn : proj ]",
    "let @xmath41 be a range space and @xmath45 .",
    "the _ projection _ of @xmath43 on @xmath46 is defined as @xmath47 .",
    "a set is said to be shattered if all its subsets are defined by the range space :    [ defn : shatter ] let @xmath41 be a range space and @xmath45 .",
    "if @xmath48 , then @xmath46 is said to be _ shattered by @xmath43_.    the vc - dimension of a range space is the cardinality of the largest set shattered by the space :    [ defn : vcdim ] let @xmath49 be a range space .",
    "the _ vapnik - chervonenkis _ dimension ( or _ vc - dimension _ ) of @xmath15 , denoted as @xmath50 is the maximum cardinality of a shattered subset of @xmath42 . if there are arbitrary large shattered subsets , then @xmath51 .",
    "when the ranges represent all the possible outputs of queries in a class @xmath44 applied to database tables @xmath3 , the vc - dimension of the range space is the maximum number of tuples such that any subset of them is the output of a query in @xmath44 .    note that a range space @xmath41 with an arbitrary large set of points @xmath42 and an arbitrary large family of ranges @xmath43 can have a bounded vc - dimension .",
    "a simple example is the family of intervals in @xmath52 $ ] ( i.e. @xmath42 is all the points in @xmath52 $ ] and @xmath43 all the intervals @xmath53 $ ] , such that @xmath54 ) .",
    "let @xmath55 be the set of three points @xmath56 .",
    "no interval in @xmath43 can define the subset @xmath57 so the vc - dimension of this range space is @xmath58 .",
    "this observation is generalized in the following result  ( * ? ? ?",
    "* lemma 10.3.1 ) :    [ lem : matousek ] the vc - dimension of the range space @xmath59 , where @xmath42 is the set of all half - spaces in @xmath60 equals @xmath61 .",
    "the main application of vc - dimension in statistics and learning theory is its relation to the minimum size sample needed for approximate learning of a set of indicator functions or hypothesis .",
    "[ defn : eapprox ] let @xmath41 be a range space and let @xmath46 be a finite subset of @xmath42 .    1 .   for @xmath62 ,",
    "a subset @xmath63 is an @xmath64_-approximation _ for @xmath46 in @xmath41 if @xmath65 , we have @xmath66 .",
    "2 .   for @xmath67 ,",
    "a subset @xmath63 is a _ relative _",
    "_ for @xmath46 in @xmath41 if for any range @xmath69 such that @xmath70 we have @xmath71 and for any range @xmath69 such that @xmath72 we have @xmath73",
    ".    an @xmath64-approximation ( resp . a relative @xmath68-approximation ) can be probabilistically constructed by sampling the point space  @xcite .",
    "[ thm : eapprox ] let @xmath41 be a range space of vc - dimension at most @xmath74 , @xmath46 a finite subset of @xmath42 , and @xmath75 a random sample of @xmath46 of cardinality @xmath0 .    1 .",
    "there is a positive constant @xmath76 such that for any @xmath77 and @xmath78 @xmath79 is an @xmath64-approximation for @xmath46 with probability at least @xmath80 .",
    "2 .   there is a positive constant @xmath81 such that for any @xmath82 and @xmath83 @xmath79 is a relative @xmath68-approximation for @xmath46 with probability at least @xmath80 .",
    "lffler and phillips  @xcite showed experimentally that the constant @xmath76 is approximately @xmath84 .",
    "it is also interesting to note that an @xmath64-approximation of size @xmath85 can be built _ deterministically _ in time @xmath86  @xcite .    in sect .",
    "[ sec : applications ] we use an @xmath64-approximation ( or a relative @xmath68-approximation ) to compute good estimates of the selectivities of all queries in @xmath44 .",
    "we obtain a small approximation set through probabilistic construction . the challenge in applying thm .",
    "[ thm : eapprox ] to our setting is computing the vc - dimension of a range space defined by a class of queries .",
    "we state here a few fundamental results that will be used in our analysis .",
    "first , it is clear that if the vc - dimension of a range space @xmath41 is @xmath74 then latexmath:[$2^d\\leq    by members of @xmath43 .",
    "next we define for integers @xmath88 and @xmath89 the _ growth function _ @xmath90 as @xmath91    the growth function is used in the following results  ( * ? ? ?",
    "14.4 ) .",
    "[ lem : sauer ] if @xmath41 is a range space of vc - dimension @xmath74 with @xmath92 points , then @xmath93 .",
    "[ corol : sauerproj ] if @xmath41 is a range space of vc - dimension @xmath74 , then for every finite @xmath45 , @xmath94 .    our analysis in sect .",
    "[ sec : vcdimqueries ] uses the following bound which is an extension of  ( * ? ? ?",
    "* corol .",
    "14.4.3 ) to arbitrary combinations of set operations .",
    "[ lem : genboolcomp ] let @xmath41 be a range space of vc - dimension @xmath95 and let @xmath96 be the range space on @xmath42 in which @xmath97 include all possible combinations of union and intersections of @xmath98 members of @xmath43",
    ". then @xmath99 .",
    "let @xmath46 be an arbitrary subset of cardinality @xmath100 of @xmath42 .",
    "we have @xmath101 .",
    "there are @xmath102 possible choices of @xmath98 members of @xmath103 , and there are no more than @xmath104 boolean combinations using unions and intersections of the @xmath98 sets , where @xmath105 is the @xmath106 catalan number ( @xmath107 ) . if @xmath108 then @xmath46 can not be shattered .",
    "this inequality holds for @xmath109",
    "in this section we develop a general bound on the vc - dimension of classes of queries .",
    "we start by computing the vc - dimension of simple select queries on one column and then move to more complex types of queries ( multi - attributes select queries , join queries ) .",
    "we then extend our bounds to general queries that are combinations of multiple select and join operations .",
    "let @xmath7 be a table with @xmath110 columns @xmath111 , and @xmath100 tuples .",
    "for a fixed column @xmath8 , consider the set @xmath112 of the selection queries in the form @xmath113 where @xmath19 is an inequality operator ( i.e. , either `` @xmath114 '' or `` @xmath115 '' ) '' and `` @xmath116 '' can be reduced to `` @xmath114 '' and `` @xmath115 '' respectively . ] and @xmath117 .",
    "let @xmath118 be two queries .",
    "we say that @xmath119 is equivalent to @xmath120 ( and denote this fact as @xmath121 ) if their outputs are identical , i.e. , they return the same set of tuples when they are run on the same database .",
    "note that @xmath121 defines a proper equivalence relation .",
    "let @xmath122 be the maximum subset of @xmath112 that contains no equivalent queries , i.e. it contains one query from each equivalent class .",
    "[ lem : vcdimselmulcol ] let @xmath7 be a table with @xmath110 columns @xmath123 , @xmath124 , and consider the set of queries @xmath125 where @xmath126 is defined as in the previous paragraph . then , the range space @xmath127 has vc - dimension at most @xmath128 .",
    "we can view the tuples of @xmath7 as points in the @xmath110-dimensional space @xmath129 .",
    "a tuple @xmath9 such that @xmath130 is represented on the space by the point @xmath131 .",
    "the queries in @xmath132 can be seen as half spaces of @xmath133 . in particular",
    "any query in @xmath132 is defined as in   and can be seen as the half space @xmath134 it then follows from lemma  [ lem : matousek ] that @xmath135 .",
    "we now extend these result to general selection queries .",
    "consider the set @xmath136 of queries whose selection predicate can be expressed as the boolean combination of the selection predicates of at most two queries from @xmath132 .",
    "these are the queries of the form : @xmath137 where @xmath138 and @xmath139 are two columns from @xmath7 ( potentially , @xmath140 ) , @xmath141 , @xmath142 , `` @xmath143 '' is either `` @xmath114 '' or `` @xmath115 '' and `` @xmath144 '' is either `` ` and ` '' or `` ` or ` '' .",
    "note that , in particular the queries in the form @xmath145 where @xmath146 is either `` @xmath23 '' or `` @xmath24 '' , belong to @xmath136 because we can rewrite a selection predicate containing one of these operators as a selection predicate of two clauses using `` @xmath114 '' and `` @xmath115 '' joined by either @xmath147 ( in the case of `` @xmath23 '' ) or @xmath148 ( in the case of `` @xmath24 '' ) .    by applying lemma  [ lem : genboolcomp ] , we have that the vc - dimension of the range space @xmath149 is at most @xmath150 , where @xmath110 is the number of columns in the table @xmath7",
    ".    we can generalize this result to @xmath38 boolean combinations of selection predicates as follows .",
    "[ lem : vcdimselgen ] let @xmath7 be a table with @xmath110 columns , let @xmath151 and let @xmath152 be the set of selection queries on @xmath7 whose selection predicate is a boolean combination of @xmath38 clauses . then",
    ", the vc - dimension of the range space @xmath153 is at most @xmath154 .",
    "note that we can not apply the bound used in the proof of lemma  [ lem : vcdimselmulcol ] since not all queries in @xmath152 are equivalent to axis - aligned boxes .",
    "once we apply boolean operations on the outputs of the individual select operation , the set of possible outputs , @xmath153 , may form complex subsets , including unions of disjoint ( half - open ) axis aligned - rectangles and/or intersections of overlapping ones that can not be represented as a collection of half spaces .",
    "thus , we need to apply a different technique here .",
    "the output of a query @xmath14 in @xmath155 can be seen as the boolean combination ( i.e. union and intersection ) of the outputs of at most @xmath38 `` simple '' select queries @xmath156 from @xmath157 where each of these queries @xmath156 is as in  .",
    "an ` and ` operation in the predicate of @xmath14 implies an intersection of the outputs of the corresponding two queries @xmath156 and @xmath158 , while an ` or ` operation implies a union of the outputs . by applying lemma  [ lem : genboolcomp ] ,",
    "we obtain the result .",
    "let @xmath25 and @xmath26 be two distinct tables , and let @xmath159 and @xmath160 be two families of ( outputs of ) select queries on the tuples of @xmath25 and @xmath26 respectively .",
    "let @xmath161 , @xmath162 and let @xmath163 .",
    "let @xmath6 be a column along which @xmath25 and @xmath26 are joined , and let @xmath164 be the cartesian product of the two tables .    for a pair of queries @xmath165 , @xmath166 , let @xmath167 where @xmath168 .",
    "@xmath169 is the set of ordered pairs of tuples ( one from @xmath25 and one from @xmath26 that forms the output of the join query @xmath170 here we simplify the notation by identifying select queries with their predicates .",
    "we have @xmath171 and @xmath172 .",
    "let @xmath173 @xmath174 i the set of outputs of all join queries like the one in  , for all pairs of queries in @xmath175 and all values of `` @xmath19 '' .",
    "we present here an upper bound to the vc - dimension of the range space @xmath176 .",
    "[ lem : vcdimjoin ] @xmath177    let @xmath178 and @xmath179 .",
    "assume that a set @xmath180 is shattered by @xmath174 , and @xmath181 .",
    "consider the two cross - sections @xmath182 and @xmath183 .",
    "note that @xmath184 and @xmath185 and by  [ corol : sauerproj ] @xmath186 and @xmath187 .",
    "for each set @xmath188 ( i.e. , for each subset @xmath189 , given that @xmath190 ) there is a pair @xmath191 , @xmath165 , @xmath166 , and there is @xmath19 , such that @xmath192 .",
    "each of such pair @xmath191 identifies a distinct pair @xmath193 , therefore each element of @xmath194 can be identified at most @xmath195 times , the number of possible values for `` @xmath19 '' .",
    "in particular , for a fixed `` @xmath19 '' , an element of @xmath196 can be identified at most once . to see this ,",
    "consider two different sets @xmath197 .",
    "let the pairs @xmath198 , @xmath199 , @xmath200 , @xmath201 , be such that @xmath202 and @xmath203 .",
    "suppose that @xmath204 ( @xmath205 ) and @xmath206 ( @xmath207 ) .",
    "the set @xmath1 can be seen as @xmath208 .",
    "analogously the set @xmath2 can be seen as @xmath209 . but given that @xmath210 and @xmath206 , this leads to @xmath211 , a contradiction .",
    "hence , a pair @xmath212 , @xmath213 , @xmath214 can only be identified at most @xmath195 times , one for each possible value of `` @xmath19 '' .",
    "thus,@xmath215 @xmath46 could not be shattered if @xmath216 , i.e. , if @xmath217 the rightmost inequality holds for @xmath218 .",
    "the above results can be generalized to any query plan represented as a tree where the select operations are in the leaves and all internal nodes are join operations .",
    "as we said earlier , such a tree exists for any query .",
    "[ lem : vcdimmuljoin ] consider the class @xmath44 of queries that can be seen as combinations of select and joins on @xmath219 tables @xmath220 .",
    "let @xmath221 , @xmath222 be the range space associated with the select queries on the @xmath223 tables .",
    "let @xmath224 .",
    "let @xmath110 be the maximum number of columns in a table @xmath34 .",
    "we assume @xmath225 .",
    "is reasonable for any practical case .",
    "] let @xmath226 be the range space associated with the class @xmath44 .",
    "the range set @xmath227 is defined as follows .",
    "let @xmath228 , @xmath229 , and let @xmath230 be a sequence of @xmath231 join conditions representing a possible way to join the @xmath223 tables @xmath34 , using the operators @xmath232 .",
    "we define the range @xmath233 @xmath227 is the set of all possible @xmath234 .",
    "then , @xmath235    note that this lemma is not just an extension of lemma  [ lem : vcdimjoin ] to join queries between multicolumns tables .",
    "instead , it is an extension to queries containing multiple joins ( possibly between multicolumns tables ) .",
    "assume that a set @xmath180 is shattered by @xmath227 , and @xmath181 .",
    "consider the cross - sections @xmath236 .",
    "note that @xmath237 and by  [ corol : sauerproj ] @xmath238 .",
    "for each set @xmath239 ( i.e. , for each subset @xmath189 , given that @xmath190 ) there is a sequence @xmath240 , @xmath229 , and there is an @xmath230 , such that @xmath241 .",
    "each sequence @xmath242 identifies a distinct sequence @xmath243 , therefore each element of @xmath244 can be identified at most @xmath245 times , one for each different @xmath230 .    in particular , for a fixed @xmath230 , an element of @xmath246 can be identified at most once . to see this ,",
    "consider two different sets @xmath247 .",
    "let the vectors @xmath248 , @xmath249 , @xmath250 , be such that @xmath251 and @xmath252 .",
    "suppose that @xmath253 ( @xmath254 ) .",
    "the set @xmath1 can be seen as @xmath255 .",
    "analogously the set @xmath2 can be seen as @xmath256 . but given that @xmath257 , this leads to @xmath211 , a contradiction .",
    "hence , a vector @xmath258 , @xmath259 , can only be identified at most @xmath30 times , one for each different @xmath230 . for each of the @xmath231",
    "join conditions composing @xmath230 we need to choose a pair @xmath260 expressing the columns along which the tuples should be joined .",
    "there are at most @xmath261 such pairs ( some of them can not actually be chosen , e.g. those of the type @xmath262 ) .",
    "there are then @xmath263 ways of choosing these @xmath231 pairs . for each choice of @xmath231 pairs , there are @xmath264 ways of choosing the operators in the join conditions ( @xmath195 choices for @xmath19 for each pair ) .",
    "we have @xmath265 thus , @xmath266 .",
    "@xmath46 could not be shattered if @xmath216 , i.e. if @xmath267 the rightmost inequality holds for @xmath268 .      combining the above results we prove :    [ thm : vcdimgenqueries ] consider a class @xmath269 of all queries with up to @xmath231 join and @xmath223 select operations , where each select operation involves no more than @xmath110 columns and @xmath38 boolean operations , then @xmath270    note that theorem  [ thm : vcdimgenqueries ] gives an upper bound to the vc - dimension .",
    "our experiments suggest that in most cases the vc - dimension and the corresponding minimum sample size are even smaller .",
    "we applying the theoretical result on the vc - dimension of queries to constructing a concrete algorithm for selectivity estimation and query plan optimization .",
    "our goal is to apply def .",
    "[ defn : eapprox ] and thm .",
    "[ thm : eapprox ] to compute an estimate of the selectivity of sql queries .",
    "let @xmath269 be a class of queries as in theorem  [ thm : vcdimgenqueries ] .",
    "the class @xmath269 defines a range space @xmath49 such that @xmath42 is the cartesian product of the tables involved in executing queries in @xmath269 , and @xmath43 is the family of all output sets of queries in @xmath269 .",
    "let @xmath40 be an @xmath64-approximation of @xmath42 and let @xmath271 be the output set of a query @xmath272 when executed on the original dataset , then @xmath273 and @xmath274 is the output set when the query is executed on the sample ( see details below ) .",
    "thus , by def .",
    "[ defn : eapprox ] , latexmath:[\\[\\left|\\frac{|x\\cap r|}{|x| } - \\frac{|{{\\cal s}}\\cap r|}{|{{\\cal s}}|}\\right|=    selectivity of running a query @xmath272 on an @xmath64-approximation of @xmath42 is within @xmath64 of the selectivity of @xmath14 when executed on the original set of tables .",
    "note that for any execution plan of a query @xmath272 , all the queries that correspond to subtrees rooted at internal nodes of the plan are queries in @xmath269 .",
    "thus , by running query @xmath14 on an @xmath64-approximation of @xmath42 we obtain accurate estimates for the selectivity of all the subqueries defined by its execution plan .",
    "corresponding results are obtained by using a relative @xmath68-approximation for @xmath42 .",
    "we apply thm .",
    "[ thm : eapprox ] to probabilistically construct an @xmath64-approximation of @xmath42 .",
    "a technical difficulty in algorithmic application of the theorem is that it is proven for a uniform sample of the cartesian product of all the tables in the database , while in practice it is more efficient to maintain the table structure of the original database in the sample .",
    "it is easier to sample each table independently , and to run the query on a sample that consists of subsets of the original tables rather than re - writing the query to run on a cartesian product of tuples .",
    "however , the cartesian product of independent uniform samples of tables is not a uniform sample of the cartesian product of the tables  @xcite .",
    "we developed the following procedure to circumvent this problem .",
    "assume that we need a uniform sample of size @xmath10 from @xmath276 , which is the cartesian product of @xmath30 tables @xmath277 .",
    "we then sample @xmath10 tuples uniformly at random from each table @xmath34 , to form a sample table @xmath278 .",
    "we add an attribute @xmath279 to each @xmath278 and we set the value in the added attribute for each tuple in @xmath278 to a unique value in @xmath280 $ ] .",
    "now , each sample table will contain @xmath10 tuples , each tuple with a different index value in @xmath280 $ ] .",
    "given an index value @xmath281 $ ] , consider the set of tuples @xmath282 , @xmath283 such that @xmath284 .",
    "@xmath285 can be seen as a tuple sampled from @xmath276 , and the set of all @xmath285 , @xmath281 $ ] is a uniform random sample of size @xmath10 from @xmath276 .",
    "we run queries on the sample tables , but in order to estimate the selectivity of a join operation we count a tuple @xmath286 in the result only if the set of tuples composing @xmath286 is a subset of @xmath285 for some @xmath281 $ ] .",
    "this is easily done by scanning the results and checking the values in the @xmath279 columns ( see algorithms  [ alg : createsam ] and  [ alg : computesel ] ) .",
    "@xmath287 @xmath288 indexes of the sample tables involved in @xmath289 @xmath290 @xmath291    [ lem : computesel ] the @xmath292 procedure ( in alg .",
    "[ alg : computesel ] ) executes a query on the cartesian product of independent random samples of the tables but outputs the selectivity that corresponds to executing the query on a random sample of the cartesian product of the original tables .",
    "the @xmath293 procedure chooses from each table a random sample of @xmath10 tuples and adds to each sampled tuple an index in @xmath280 $ ] .",
    "each sample table has exactly one tuple with each index value , and the cartesian product of the sample tables has exactly one element that is a concatenation of tuples , all with the same index @xmath294 in their tables . restricting the selectivity computation to these @xmath10 elements ( as in @xmath295 ) gives the result .    note that our method circumvent the major difficulty pointed out by chaudhuri  et  al .",
    "they also proved that , in general , it is impossible to predict sample sizes for given two tables such that the join of the samples of two tables will result in a sample of a required size out of the join of the two tables .",
    "our method does not require a sample of a given size from the result of a join .",
    "the vc - dimension sampling technique requires only a sample of a given size from the cartesian product of the tables , which is guaranteed by the above procedure .",
    "identifying the optimal query plan during query optimization may require executing several candidate query plans on the sample",
    ". a standard bottom - up candidate plan generation allows us to execute sub - plans once , store their results and reuse them multiple times as they will be common to many candidate plans .",
    "while the overhead of this execution - based selectivity estimation approach will still likely be higher than that of pre - computation based techniques ( e.g. , histograms ) , the reduced execution times of highly optimized plans enabled by better estimates , especially for complex and long - running queries , will more than compensate for this overhead .",
    "thus , storing intermediate results that are common to several executions will speed up the total execution time on the sample .",
    "the significant improvement in the selectivity estimates in complex queries well compensates for the extra work in computing the selectivity estimates .",
    "this section presents the results of the experiments we run to validate our theoretical results and to compare our selectivity estimation method with standard techniques implemented in postgresql and in microsoft sql server .",
    "[ [ goals . ] ] goals .",
    "+ + + + + +    the first goal of the experiments is to evaluate the practical usefulness of our theoretical results . to assess this",
    ", we run queries on a large database and on random samples of it of different sizes .",
    "we use the selectivity of the each query in the random samples as an estimator for the selectivity in the large database with the adjustments for join operations , as described in the previous section .",
    "we compute the error between the estimate and the actual selectivity to show that the thesis of thm .",
    "[ thm : eapprox ] is indeed valid in practice .",
    "the use of a large number of queries and of a variety of parameters allows us to evaluate the error rate as a function of the sample size .",
    "we then compare our method with the commonly used selectivity estimation based on precomputed histograms ( briefly described in sect .",
    "[ sec : selhist ] ) .",
    "we use histograms with a different number of buckets to show that , no matter how fine - grained the histograms might be , as soon as the inter - column and intra - bucket assumptions are no longer satisfied , our approach gives better selectivity estimates .      in many modern database systems ,",
    "the query optimizer relies on histograms for computing data distribution statistics to help determine the most efficient query plans .",
    "in particular , postgresql uses one - dimensional equi - depth ( i.e. , equal frequency buckets ) histograms and a list of the most common values ( mcv ) for each column ( of a database table ) to compute optimizer statistics .",
    "the mcv information stores the most frequent @xmath296 items ( by default @xmath297 ) and their frequency for each column .",
    "the histograms ( by default with @xmath298 bins ) are built for the values not stored in the mcv list .",
    "the selectivity of a constraint @xmath299 , where @xmath46 is a column and @xmath300 is a value is computed from the mcv list if @xmath300 is in the mcv list or from the histogram bin that contains @xmath300 if @xmath300 is not in the mcv list .",
    "the selectivity of a range constraint such as @xmath301 is computed with information from both the mcv list and the histogram , i.e. , the frequencies of the most common values less than x and the frequency estimate for @xmath301 from the histogram will be added to obtain the selectivity .    in postgresql ,",
    "the histograms and the mcv lists for the columns of a table are built using a random sample of the tuples of the table .",
    "the histograms and the mcv list for all columns of a table are based on the same sample tuples ( and are therefore correlated ) .",
    "the sample size is computed for each column using a formula based on the table size , histogram size , and a target error probability developed by chaudhuri  et  al .",
    "@xcite and the largest sample size required by the columns of a table is used to set the sample size of the table .",
    "finally , the join selectivity of multiple constraints are computed using the attribute independence assumption : e.g. , selectivities are added in case of an or operator and multiplied for an and operator .",
    "therefore , large selectivity estimation errors are possible for complex queries and correlated inputs .",
    "[ [ original - tables . ] ] original tables .",
    "+ + + + + + + + + + + + + + + +    the tables in our large database were randomly generated and contain 20 million tuples each . there is a distinction between tables used for running selection queries and tables used for running join ( and selection ) queries . for tables on which we run selection queries only , the distributions of values in the columns fall in two different categories :    * * uniform and independent : * the values in the columns are chosen uniformly and independently at random from a fixed domain ( the integer interval @xmath302 $ ] , the same for all columns ) .",
    "each column is treated independently from the others . *",
    "* correlated : * two columns of the tables contain values following a multivariate normal distribution with mean @xmath303 and a non - identity covariance matrix @xmath304 ( i.e. , the values in the two different columns are correlated ) .",
    "the tables for join queries should be considered in pairs @xmath305",
    "( i.e. , the join happens along a common column @xmath6 of tables @xmath46 and @xmath79 ) .",
    "the values in the columns are chosen uniformly and independently at random from a fixed domain ( the integer interval @xmath302 $ ] , the same for all columns ) .",
    "each column is treated independently from the others .",
    "[ [ sample - tables . ] ] sample tables .",
    "+ + + + + + + + + + + + + +    we sampled tuples from the large tables uniformly , independently , and with replacement , to build the sample tables .",
    "for the samples of the tables used to run join queries , we drew random tuples uniformly at random from the base tables independently and added a column @xmath279 to each tuple such that each tuple drawn from the same base table has a different value in the additional column and with tuples from different tables forming an element of the sample ( of the cartesian product of the base tables ) if they have the same value in this additional column , as described in sect .",
    "[ sec : building ] .    for each table in the original database we create many sample tables of different sizes .",
    "the sizes are either fixed arbitrarily or computed using   from thm .",
    "[ thm : eapprox ] .",
    "the arbitrarily sized sample tables contain between @xmath306 and @xmath307 million tuples .",
    "to compute the vc - dimension - dependent sample size , we fixed @xmath308 , @xmath309 , and @xmath310 .",
    "the parameter @xmath74 was set to the best bound to the vc - dimension of the range space of the queries we were running , as obtained from our theoretical results .",
    "if we let @xmath110 be the number of columns involved in the selection predicate of the queries and @xmath38 be the number of boolean clauses in the predicate , we have that @xmath74 depends directly on @xmath110 and @xmath38 , as does the sample size @xmath0 through in thm .",
    "[ thm : eapprox ] . for selection queries , we used @xmath311 and @xmath312 , with the addition of the combination @xmath313 , @xmath314 .",
    "we run experiments on join queries only for some combinations of @xmath110 and @xmath38 ( i.e. for @xmath315 and @xmath316 ) due to the large size of the resulting sample tables .",
    "table  [ tab : samplesize ] shows the sample sizes , as number of tuples , for the combinations of parameters we used in our experiments .",
    ".sample sizes [ cols=\"^,^,^,^,^,^ \" , ]     [ [ histograms . ] ] histograms .",
    "+ + + + + + + + + + +    we built histograms with a different number of buckets , ranging from @xmath298 to @xmath306 .",
    "due to limitations in postgresql , incrementing the number of buckets in the histograms also increments the number of values stored in the mcv list .",
    "even if this fact should have a positive influence on the quality of the selectivity estimates obtained from the histograms , our results show that the impact is minimal , especially when the inter - column independence and the intra - bucket uniformity assumptions are not satisfied . for sql server",
    ", we built the standard single - column histograms and computed the multi - column statistics which should help obtaining better estimations when the values along the columns are correlated .",
    "[ [ queries . ] ] queries .",
    "+ + + + + + + +    for each combination of the parameters @xmath110 and @xmath38 and each large table ( or pair of large tables , in the case of join ) we created @xmath298 queries , with selection predicates involving @xmath110 columns and @xmath38 boolean clauses . the parameters in each clause ,",
    "the range quantifiers , and the boolean operators connecting the different clauses were chosen uniformly at random to ensure a wide coverage of possible queries .",
    "[ [ selection - queries . ] ] selection queries .",
    "+ + + + + + + + + + + + + + + + + +    the first result of our experiments is that , for all the queries we run , on all the sample tables , the estimate of the selectivity computed using our method was within @xmath64 ( @xmath317 ) from the real selectivity . the same was not true for the selectivity computed by the histograms .",
    "as an example , in the case of @xmath318 , @xmath314 and uniform independent values in the columns , the default postgresql histograms predicted a selectivity more than @xmath64 off from the real selectivity for 30 out of 100 queries .",
    "nevertheless , in some of cases the histograms predicted a selectivity closer to the actual one than what our method predicted .",
    "this is especially true when the histogram independence assumption holds ( e.g. , for @xmath318 , @xmath314 the default histograms gave a better prediction than our technique in 11 out of 100 cases ) .",
    "similar situations also arise for sqlserver .",
    ", @xmath314 ]    since the selectivity estimated by the our method was always within @xmath64 from the actual , we report the actual percent error , i.e. the quantity @xmath320 where @xmath321 is the predicted selectivity .",
    "we analyze the average and the standard deviation of this quantity on a set of queries and the evolution of these measures as the sample size increases .",
    "we can see from fig .",
    "[ fig : t_k5_u200k_unif_k2_b5_errperc ] and  [ fig : t_k2_correl_k2_b8_errperc ] that both the average and the standard deviation of the percentage error of the prediction obtained with our method decrease as the sample size grows ( the rightmost plotted sample size is the one from table  [ tab : samplesize ] , i.e. , the one computed in  thm.[thm : eapprox ] .",
    "more interesting is the comparison in those figures between the performance of the histograms and the performance of our techniques in predicting selectivities . when the assumptions of the histograms hold , as is the case for the data plotted in fig .  [",
    "fig : t_k5_u200k_unif_k2_b5_errperc ] , the predictions obtained from the histograms are good .    , @xmath322    but as soon as the data are correlated ( fig .",
    "[ fig : t_k2_correl_k2_b8_errperc ] ) , our sampling method gives better predictions than the histograms even at the smallest sample sizes and keeps improving as the sample grows larger .",
    "it is also interesting to observe how the standard deviation of the prediction error is much smaller for our method than for the histograms , suggesting a much higher consistency in the quality of the predictions . in fig .",
    "[ fig : t_k2_correl_k2_b8_errperc ] we do not show multiple curves for the different postgresql histograms because increasing the number of buckets had very marginal impact on the quality of the estimates , sometimes even in the negative sense ( i.e. , an histogram with more buckets gave worse predictions than an histogram with less buckets ) , a fact that can be explained with the variance introduced by the sampling process used to create the histograms .",
    "for the same reason we do not plot multiple lines for the prediction obtained from the multi - columns and single - column statistics of sql server : even when the multi - column statistics were supposed to help , as in the case of correlated data , the obtained prediction were not much different from the ones obtained from the single - column histograms .",
    "[ [ join - queries . ] ] join queries .",
    "+ + + + + + + + + + + + +    the strength of our method compared to histograms is even more evident when we run join queries , even when the histograms independent assumptions are satisfied . in our experiments , the predictions obtained using our technique were always within @xmath64 from the real values , even at the smallest sample sizes , but the same was not true for histograms .",
    "for example , in the case of @xmath315 and @xmath314 , @xmath323 out of @xmath324 predictions from the histograms were more than @xmath64 off from the real selectivities .",
    "figure  [ fig : join_k1_b1_errperc ] shows the comparison between the average and the standard deviation of the percentage error , defined in the previous paragraph , for the histograms and our method .",
    "the numbers include predictions for the selection operations at the leaves of the query tree .    , @xmath325    again , we did not plot multiple curves for histograms with a different number of buckets because the quality of the predictions did not improve as the histograms became more fine - grained .",
    "to understand the big discrepancy between the accurate predictions of our method and the wrong estimates computed by the histograms in postgresql we note that for some join queries , the histograms predicted an output size on the order of the hundreds of thousands tuples but the actual output size was zero or a very small number of tuples . observing the curves of the average and the standard deviation of the percentage error for the prediction obtained with our method",
    ", we can see that at the smaller sample sizes the quality of the predictions only improves minimally with the sample size . this is due to the fact that at small sizes our prediction for the join operation is very often zero or very close to zero , because the output of the query does not contain enough pairs of tuples from the sample of the cartesian product of the input table ( i.e. pairs of tuples with the same value in the @xmath279 column ) . in these cases ,",
    "the prediction can not be accurate at all ( i.e. the error is 100% if the original output contained some tuples , or 0% if the query returned an empty set in the large databases ) .",
    "as soon as the sample size grows more , we can see first a jump to higher values of the percentage error , which then behaves as expected , i.e. , decreasing as the sample size increases .    in fig .",
    "[ fig : join_k1_b1_errperc ] we also show a comparison between the percentage error of predictions obtained using our method in two different ways : the `` theoretically correct '' way that makes use of the number of pairs of tuples with the same value in the @xmath279 column and the `` practitioner '' way which uses the size of the output of the join operation in the sample , therefore ignoring the @xmath279 column .",
    "recall that we had to add the @xmath279 column because thm .",
    "[ thm : eapprox ] requires a uniform sample of the cartesian product of the input tables . as it is evident from fig .",
    "[ fig : join_k1_b1_errperc ] , the `` practitioner '' way of predicting selectivity gives very good results at small sample sizes ( although it does not offer theoretical guarantees ) .",
    "these results are similar in spirit , although not equivalent , to the theoretical conclusions presented by haas  et  al .",
    "@xcite in the setting of selectivity estimation using online sampling .",
    "we develop a novel method for estimating the selectivity of queries by executing it on a concise , properly selected , sample of the database .",
    "we present a rigorous analysis of our method and extensive experimental results demonstrating its efficiency and the accuracy of its predictions .",
    "most commercial databases use histograms built on a single column , for selectivity estimation .",
    "there has also been significant research on improving the estimate using multidimensional histograms  @xcite and join synopses  @xcite .",
    "the main advantage of our method is that it gives uniformly accurate estimates for the selectivity of any query within a predefined vc - dimension range .",
    "method that collect and store pre - computed statistics gives accurate estimates only for the relations captured by the collected statistics , while estimates of any other relation relies on an independence assumption .",
    ", which give probabilistic guarantees on the error of the predicted selectivity , to match the accuracy of our new method with histograms and join synopses one would need to create , for each table , a multidimensional histogram where the number of dimensions is equal to the number of columns in the tables .",
    "the space needed for a multidimensional histogram is exponential in the number of dimensions , while the size of our sample representation is almost linear in that parameter .",
    "furthermore , to estimate the selectivity for join operations one would need to create join synopses for all pairs of columns in the database , again in space that grows exponential in the number of columns .            , chaudhuri , s. , and das , g. 2003 .",
    "dynamic sample selection for approximate query processing . in _ proceedings of the 2003 acm sigmod international conference on management of data_. sigmod 03 .",
    "acm , new york , ny , usa , 539550 .      , ligett , k. , and roth , a. 2008 .",
    "a learning theory approach to non - interactive database privacy . in _ proceedings of the 40th annual acm symposium on theory of computing_. stoc 08 .",
    "acm , new york , ny , usa , 609618 .                , motwani , r. , and narasayya , v. 1999 . on random sampling over joins . in _ proceedings of the 1999 acm",
    "sigmod international conference on management of data_. sigmod 99 .",
    "acm , new york , ny , usa , 263274 .      ,",
    "mcnamee , l. , and matloff , n.  s. 1990 .",
    "selectivity estimation using homogeneity measurement . in _ proceedings of the sixth international conference on data engineering_. ieee computer society , washington , dc ,",
    "usa , 304310",
    ".      \\2005 .",
    "histograms revisited : when are histograms the best approximation method for aggregates over joins ? in",
    "_ proceedings of the twenty - fourth acm sigmod - sigact - sigart symposium on principles of database systems_. pods 05 .",
    "acm , new york , ny , usa , 228237 .        ,",
    "l . , and ramakrishnan , r. 2000 .",
    ": self - tuning samples for approximate query answering . in _ proceedings of the 26th international conference on very large data bases_. vldb 00 .",
    "morgan kaufmann publishers inc . , san francisco , ca , usa , 176187 .      ,",
    "lehner , w. , and haas , p.  j. 2006 . a dip in the reservoir : maintaining sample synopses of evolving datasets . in",
    "_ proceedings of the 32nd international conference on very large data bases_. vldb 06 .",
    "vldb endowment , almaden , ca , usa , 595606 .    ,",
    "lehner , w. , and haas , p.  j. 2007 . maintaining bernoulli samples over evolving multisets . in _ proceedings of the twenty - sixth acm sigmod - sigact - sigart symposium on principles of database systems_. pods 07 .",
    "acm , new york , ny , usa , 93102 .",
    "query selectivity estimation via data mining . in _ intelligent information processing and web mining , proceedings of the international iis : iipwm04 conference held in zakopane , poland , may 17 - 20 , 2004 _ , m.  a. klopotek , s.  t. wierzchon , and k.  trojanowski , eds . advances in soft computing .",
    "springer - verlag , berlin heidelberg , germany , 2938 .        , naughton , j.  f. , seshadri , s. , and swami , a.  n. 1993 .",
    "fixed - precision estimation of join selectivity . in _ proceedings of the twelfth acm sigact - sigmod - sigart symposium on principles of database systems_. pods 93 .",
    "acm , new york , ny , usa , 190201 .      , naughton , j.  f. , and swami , a.  n. 1994 . on the relative cost of sampling for join selectivity estimation . in _ proceedings of the thirteenth acm sigact - sigmod - sigart symposium on principles of database systems_. pods 94 .",
    "acm , new york , ny , usa , 1424 .",
    "sampling - based selectivity estimation for joins using augmented frequent value statistics . in _ proceedings of the eleventh international conference on data engineering_. icde 95 .",
    "ieee computer society , washington , dc , usa , 522531 .      ,",
    "shepherd , j. , and ngu , a. h.  h. 1997 .",
    "query size estimation using machine learning . in _ proceedings of the fifth international conference on database systems for advanced applications ( dasfaa)_. world scientific press , hackensack , nj , usa , 97106 .        , ozsoyoglu , g. , and taneja , b.  k. 1988 .",
    "statistical estimators for relational algebra expressions . in",
    "_ proceedings of the seventh acm sigact - sigmod - sigart symposium on principles of database systems_. pods 88 .",
    "acm , new york , ny , usa , 276287 .",
    "balancing histogram optimality and practicality for query result size estimation . in _ proceedings of the 1995 acm",
    "sigmod international conference on management of data_. sigmod 95 .",
    "acm , new york , ny , usa , 233244 .    , koudas , n. , muthukrishnan , s. , poosala , v. , sevcik , k.  c. , and suel , t. 1998 .",
    "optimal histograms with quality guarantees . in _ proceedings of the 24rd international conference on very large data bases_. vldb 98 .",
    "morgan kaufmann publishers inc . , san francisco , ca , usa , 275286 .    ,",
    "pol , a. , and arumugam , s. 2004 .",
    "online maintenance of very large random samples . in _ proceedings of the 2004 acm",
    "sigmod international conference on management of data_. sigmod 04 .",
    "acm , new york , ny , usa , 299310 .    ,",
    "glimcher , l. , jermaine , c. , and agrawal , g. 2006 .",
    "new sampling - based estimators for olap queries . in _ proceedings of the 22nd international conference on data engineering_. icde 06 .",
    "ieee computer society , washington , dc , usa , 18.    \\2008 .",
    "robust stratified sampling plans for low selectivity queries . in _ proceedings of the 2008 ieee 24th international conference on data engineering_. ieee computer society , washington , dc ,",
    "usa , 199208 .      ,",
    "lehner , w. , zhou , j. , and zabback , p. 2007 .",
    "cardinality estimation using sample views with quality assurance . in _ proceedings of the 2007 acm sigmod international conference on management of data_. sigmod 07 .",
    "acm , new york , ny , usa , 175186 .",
    "shape fitting on point sets with probability distributions . in _ algorithms - esa 2009 _ , a.  fiat and p.  sanders , eds .",
    "lecture notes in computer science series , vol .",
    "springer - verlag , berlin heidelberg , germany , 313324 .      ,",
    "vitter , j.  s. , and wang , m. 1998 .",
    "wavelet - based histograms for selectivity estimation . in _ proceedings of the 1998 acm",
    "sigmod international conference on management of data_. sigmod 98 .",
    "acm , new york , ny , usa , 448459 .            ,",
    "haas , p.  j. , ioannidis , y.  e. , and shekita , e.  j. 1996 . improved histograms for selectivity estimation of range predicates . in _ proceedings of the 1996 acm",
    "sigmod international conference on management of data_. sigmod 96 .",
    "acm , new york , ny , usa , 294305 .    \\1997 .",
    "selectivity estimation without the attribute value independence assumption . in _ proceedings of the 23rd international conference on very large data bases_. vldb 97 .",
    "morgan kaufmann publishers inc .",
    ", san francisco , ca , usa , 486495 .    \\2010 .",
    "understanding cardinality estimation using entropy maximization . in _ proceedings of the twenty - ninth acm sigmod - sigact - sigart symposium on principles of database systems_. pods",
    "acm , new york , ny , usa , 5364 .    ,",
    "haas , p.  j. , markl , v. , kutsch , m. , and tran , t.  m. 2006 . : consistent histogram construction using query feedback . in _ proceedings of the 22nd international conference on data engineering_. icde 06 .",
    "ieee computer society , washington , dc , usa , 39.",
    "\\2003 . a multi - dimensional histogram for selectivity estimation and fast approximate query answering . in _ proceedings of the 2003 conference of the centre for advanced studies on collaborative research_. cascon 03 .",
    "ibm press , boston , ma , usa , 328342 .    ,",
    "vitter , j.  s. , and iyer , b.  r. 1997 . selectivity estimation in the presence of alphanumeric correlations .",
    "in _ proceedings of the thirteenth international conference on data engineering_. icde 97 .",
    "ieee computer society , washington , dc , usa , 169180 ."
  ],
  "abstract_text": [
    "<S> we develop a novel method , based on the statistical concept of the _ vapnik - chervonenkis dimension _ , to evaluate the selectivity ( output cardinality ) of sql queries  a crucial step in optimizing the execution of large scale database and data - mining operations . </S>",
    "<S> the major theoretical contribution of this work , which is of independent interest , is an explicit bound to the vc - dimension of a range space defined by all possible outcomes of a collection ( class ) of queries . </S>",
    "<S> we prove that the vc - dimension is a function of the maximum number of boolean operations in the selection predicate and of the maximum number of select and join operations in any individual query in the collection , but it is neither a function of the number of queries in the collection nor of the size ( number of tuples ) of the database . </S>",
    "<S> we leverage on this result and develop a method that , given a class of queries , builds a concise random sample of a database , such that with high probability the execution of _ any _ query in the class on the sample provides an accurate estimate for the selectivity of the query on the original large database . </S>",
    "<S> the error probability holds _ simultaneously _ for the selectivity estimates of _ all _ queries in the collection , thus the same sample can be used to evaluate the selectivity of multiple queries , and the sample needs to be refreshed only following major changes in the database . </S>",
    "<S> the sample representation computed by our method is typically sufficiently small to be stored in main memory . </S>",
    "<S> we present extensive experimental results , validating our theoretical analysis and demonstrating the advantage of our technique when compared to complex selectivity estimation techniques used in postgresql and the microsoft sql server . </S>"
  ]
}