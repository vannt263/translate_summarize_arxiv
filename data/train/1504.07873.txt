{
  "article_text": [
    "single molecule measurements of molecular motors allow to study the motion of individual enzymes .",
    "the studies range from enzymes making comparably large steps e.g. motor proteins like myosin v @xcite and kinesin @xcite to dna based molecular machines which make steps on the scale of single nucleotides @xcite .",
    "experimental techniques to study these systems range from single molecule fluorescence localization @xcite to optical and magnetic tweezers @xcite .",
    "most of these measurements represent the underlying dynamics as one - dimensional time series of positional changes .",
    "the enzymatic reactions which fuel this motion appear as stochastic events resulting in step - like movements @xcite obliterated by noise . nowadays",
    "state of the art optical tweezers experiments allow to study the movement of enzymes with a resolution down to single base pairs @xcite .",
    "for example , studies on the @xmath129 bacteriophage ring atpase @xcite used the information from step detection data to propose a complete model of the mechanochemical cycle .",
    "however , oftentimes analysis schemes rely on low pass smoothed data .    indeed",
    ", the problem of finding steps is not only limited to studies of movement of enzymes but appears in a wide range of biomolecular experiments from fluorescence resonance energy transfer trajectories @xcite , to steps in membrane tether formation @xcite , or the opening of ion channels @xcite , just to name a few .",
    "consequently , there is a rich amount of signal processing techniques available to recover piecewise constant signals from noisy data .",
    "due to the stochastic nature of enzymatic stepping the number of steps is often not known a priori . therefore , different step finding algorithms have been developed @xcite .",
    "one class of algorithms determine steps from single molecule data based on statistical hypothesis testing in a moving window .",
    "a prominent example is the so called t - test , which is based on the student s t - test @xcite . in this algorithm",
    "a step is recorded when the hypothesis that two normally distributed random variables have the same mean is violated .",
    "the mean is calculated with respect to a certain time window which is an input parameter that can be eliminated by sweeping through various window sizes .",
    "thus , the t - test is conceptionally simple .",
    "however , for situations with small step - sizes and as a result comparatively large noise , increasing window sizes are required , limiting efficient step - detection .",
    "hidden markov models ( hmm ) have been developed for situations with poor signal - to - noise ratio @xcite . in hmm",
    "the signal is modelled as a markov process with transitions between discrete states obliterated by gaussian white noise .",
    "thus , in the hmm analysis of stepping data , transition probabilities of a markov process are obtained from a maximum likelihood estimation and the steps are reconstructed using the viterbi algorithm @xcite .",
    "a hmm for processive molecular motor data requires many states to model the possible positions on the template , making it computationally expensive .",
    "performance can be improved by cutting the signal at a predefined amplitude and transforming positions to periodic coordinates to limit the necessary number of states @xcite .",
    "hmms proved to be excellent tools for pattern recognition in many fields .",
    "however , in addition to being computationally demanding they rely on assumptions about the hidden stepping process and about the noise model .",
    "another popular class of step - finding algorithms reconstruct the underlying step signal by successively introducing new steps until a stop - criterion is met @xcite .",
    "one commonly used approach is developed by kalafut and visscher ( k & v ) .",
    "it positions every new step such that the bayesian information criterion with respect to the noisy data is minimized @xcite .",
    "it is a topic of current research , if this is a valid assumption for change - point problems @xcite .",
    "the algorithm does not require user input and stops when the addition of new steps is unfavorable according to the bayesian information criterion .",
    "the k & v algorithm is a member of the larger class of step - finding methods which minimize a certain energy function @xcite .",
    "however , since the k & v algorithm only adds new steps and does not remove previously found steps , it is not guaranteed that the global energy minimum is found @xcite . finding the global minimum is possible , if these energy functions are convex . in this case",
    ", efficient algorithms can be used that yield good approximations to the underlying step signal @xcite . however , for poor signal to noise ratio , these convex energy functions are too simplistic to optimally detect steps , resulting in an overfitting of the data , i.e. more steps are detected than are actually present .",
    "thus , if steps are hidden in noise such algorithms behave as efficient filter - functions , and accurate step - detection requires an additional second stage on the filtered , i.e. denoised data @xcite .    here",
    ", we present a novel two stage approach , termed energy based stepfinding ( ebs ) , where both stages are based on the minimisation of energy functions . in a first stage , we denoise the signal with a highly efficient and fast optimization algorithm . the algorithm minimizes a convex energy function in a process called total variation denoising ( tvdn ) .",
    "we show that an optimal denoising can be found making the process effectively parameter - free .",
    "there is no further assumption about the noise necessary . for actual step detection ,",
    "we proceed in the second stage of ebs with combinatorial clustering ( cc ) of the denoised data into steps .",
    "such an approach is already in common use in the computer vision community @xcite and is both computationally efficient and fast .",
    "the energy functions used in cc belong to a more general class which allows the incorporation of prior knowledge such as the step size of the stepper to make the algorithm more accurate .",
    "we tested ebs with simulated data that were created based on experimental data of rna polymerase ii ( pol ii ) movement .",
    "we compare the performance of ebs on the same simulated data to ( i ) a t - test , ( ii ) to the variable stepsize hmm and ( iii ) to the k & v algorithm .",
    "the analysis reveals that ebs performs faster and more accurately .",
    "we therefore applied the algorithm to detect steps in experimental data of the bacteriophage @xmath129 packaging motor and to determine pauses of pol ii transcription elongation in high resolution optical tweezers experiments .",
    "starting from a large and noisy trajectory of motor protein movement we use an energy based step detection ( ebs ) . to reveal the steps produced by the underlying biological system hidden in noise , one has to identify piecewise constant parts in the data set .",
    "this is done by taking the @xmath2-element noisy input data and creating an @xmath2-element output set of steps .",
    "therefore one needs to penalize variations within neighboring variables in the signal .",
    "in contrast one needs to increase the energy if the free variables deviate too much from the measured signal .",
    "this is reflected in the energy function @xmath3 where @xmath4 and @xmath5 are the @xmath2-element input data and output variable vectors respectively . minimizing the energy function",
    "is the conceptual baseline of our approach .",
    "it consists of terms where variables interact with the input data @xmath6 , as well as nearest neighbor interaction between two adjacent variables @xmath7 .",
    "unfortunately , depending on the actual shape of these terms the optimization problem can get prohibitively computationally expensive @xcite",
    ". one of the design goals of ebs was to work efficiently for large data sets on commodity hardware .",
    "therefore , we chose an approach which , in the first stage denoises and smoothens the signal by minimizing a simple convex energy function , solving the tvdn problem .",
    "the result of this stage is the set of denoised steps .",
    "each step is characterized by its amplitude and length .",
    "we call the combination of amplitude and length from now on a tuple",
    ". the amount of tuples remains comparably low even for a significantly increased sampling rate .",
    "this makes ebs well suited for high bandwidth data consisting of a huge number of datapoints .",
    "afterwards we use this smaller set of tuples and minimize a more sophisticated energy function in the cc stage , which is defined on a discrete level set and incorporates a step height prior .",
    "a flowchart of this two stage process is shown in figure [ fig : algorithmoverview ] .      in the first stage of ebs",
    ", we separate noise from the actual stepping signal .",
    "this stage works on the full and noisy 1d input data set @xmath8 , which can be quite large ( @xmath9 datapoints ) . to denoise we minimize an energy function known as total variation denoising ( tvdn ) problem @xcite , @xmath10 where the optimal solution @xmath11 represents the denoised signal .",
    "the @xmath12 and @xmath13 are the @xmath14-th entry of the time - discrete input and solution vector , respectively .",
    "this optimal solution is a tradeoff between prior knowledge that the enzymatic steps yield piecewise constant signals , which is introduced by @xmath15 , a function which penalizes introducing steps . on the other hand",
    "the term @xmath16 penalizes deviations of the resulting solution from the input signal .",
    "the regularization parameter @xmath17 is important for the solution @xmath11 and controls the relative weight of the two terms .",
    "the unique solution of this problem requires no assumption about the characteristics of the noise .",
    "therefore the denoising step works well in case of gaussian white noise as well as more complicated colored noise .    the energy function in eq .",
    "is strictly convex , which means regardless of the input data @xmath4 there exists one unique solution @xmath11 ( see e.g. @xcite ) .",
    "we have applied a fast algorithm for solving the tvdn problem ( appendix ) which can easily handle millions of data points in a few milliseconds @xcite .",
    "the algorithm scans forward through the signal . during this",
    "it tries to extend segments of the signal with the same amplitude , until optimality conditions derived from the tvdn problem are violated .",
    "if this happens the method backtracks to a position where a new step can be introduced , re - validates the current segment until this position and starts a new segment ( appendix ) .",
    "an open problem in the context of tvdn for step detection is how to choose the regularization parameter @xmath17 such that as few as possible true steps are lost ( false negatives ) but still the data is not overfitted ( false positives ) .",
    "we propose a heuristic method to choose an optimal value for @xmath17 , termed @xmath18 , automatically . to motivate these heuristics",
    "we have a closer look to the two limits naturally imposed to @xmath17 . for @xmath19 the tvdn algorithm perfectly reproduces the input signal such that @xmath20 . on the other hand , the upper bound of sensible values is marked by @xmath21 . above this threshold the solution of eq .",
    "is constant @xmath22 for all @xmath14 .",
    "the value of @xmath23 can be derived analytically from the underlying fenchel - rockafellar @xcite problem ( appendix ) .",
    "there exists a transition in tvdn while varying the regularization parameter from a stable minimization into the over fitting regime .",
    "thus , by lowering @xmath17 from @xmath23 to @xmath24 one observes a sudden increase of steps produced by tvdn ( figure [ fig : tvdnheuristic ] ) .    .",
    "the number of produced steps and plateaus vs. different @xmath17 . for small @xmath25 solving the tvdn problem reproduces the input signal and the number of steps equals the number of data points . for big @xmath26",
    "the number of steps is significantly lower .",
    "the point @xmath27 ( magenta ) before the number of steps increases suddenly marks the value of the tvdn regularization parameter that we choose in our heuristic",
    ". plotted is a constant signal with added gaussian white noise ( red ) , a signal with exponentially distributed dwell times and gaussian white noise ( blue ) , and the same signal without white noise ( cyan).,width=336 ]    this marks the point when the tvdn minimization breaks down and the solution starts to fit noise .",
    "the breakdown also persists while varying sampling frequency or rate of steps as well as signal to noise ratio ( appendix ) . to choose the optimal value of @xmath17 , @xmath18",
    ", we use a line - search algorithm which detects the sudden increase in the slope of the number of steps in the resulting signal and uses a slightly larger value .",
    "the sole input to this algorithm is the analytically determined value of @xmath23 .",
    "therefore the @xmath18-heuristic provides us with a stable parameter - free means to choose an optimized tvdn regularization parameter .",
    "our implementation of 1d total variation denoising is based on the c code published together with @xcite .",
    "this publication also provides a detailed outline of the tvdn algorithm , describtion of its working principles as well as the optimality condition it adheres to .",
    "typically tvdn is addressed by fixed - point methods @xcite .",
    "these methods reach the minimal theoretically possible algorithmic complexity @xcite .",
    "a different kind of approach @xcite uses the local nature of the total variation denoising filter and provides a very fast , memory efficient , non - iterative way to solve eq . .",
    "although the theoretical complexity of this algorithm is worse compared to fixed - point methods it actually achieves competitive or even faster results on signals which exhibit piecewise constant characteristics . for practical",
    "situation the complexity class of the algorithm can be assumed to be @xmath28 .",
    "thus for such signals denoising of @xmath29 datapoints takes around @xmath30 on a recent @xmath31 processor .    after successful tvdn of the signal @xmath32 consists of @xmath33 steps",
    "a step is characterized by a discontinuity between two neighboring plateaus with different amplitude @xmath34 .",
    "it is beneficial to represent the signal not in the basis of indexed amplitudes @xmath35 , but instead to use tuples @xmath36 . where @xmath37 is the amplitude and @xmath38 is the length of the @xmath39-th plateau . by this change of representation the number of elements of the data set",
    "is typically reduced from several millions to a few thousand .",
    "this increases computational efficiency due to the fact that the complexity of following algorithms depends on the number of elements in the data set .",
    "therefore , a compressed signal consisting of tuples opens up the possibility to apply sophisticated step - detection algorithms on the data .",
    "the problem can now be cast as a markov random field @xcite and can be tackled by a cc method as will be presented in the following section .      as stated above",
    ", the input to the second stage of ebs are tuples of amplitude and corresponding length @xmath41 of the compressed signal . to reveal the actual steps , these tuples have to be clustered on a discrete set of levels by minimizing an energy function .",
    "this means that a combinatorial version of an energy function similar to eq .",
    "has to be optimized .",
    "the length of a plateau plays the role of a weighting factor changing the contribution of a single tuple or a pair of tuples to the total energy . with these modifications a general energy loss function takes the form , @xmath42 where the possible @xmath43 are taken from a set of levels @xmath44 .",
    "the value of the data term @xmath45 depends on deviations of @xmath46 from the input .",
    "the pairwise term @xmath47 encodes interaction potentials between neighboring plateaus .",
    "essentially the problem means to cluster the tuples @xmath48 to discrete levels , such that the joint configuration @xmath49 minimizes @xmath50 .",
    "an elegant solution can be found by mapping the problem onto a graph @xmath51 , consisting of vertices @xmath52 and edges @xmath53 . for the simple binary case , where the tuples have to be assigned to only two levels ,",
    "termed source @xmath54 and terminal @xmath55 , both of these levels as well as all tuples represent vertices @xmath52 .",
    "@xmath53 denotes the set of edges connecting the vertices ( figure [ fig : gcproblem_structure ] ) and each edge carries a capacity @xmath56 ( figure [ fig : gcproblem_capacities_edges ] ) .",
    "therefore there are two types of edges , those connecting neighboring tuples and those edges connecting tuples to levels .",
    "the capacities of the former are encoded in the pairwise term @xmath47 and the latter are represented by the data term @xmath45 . in the process of assigning a level @xmath43 to tuples the graph cut algorithm solves the following binary decision problem : is the assignment to level @xmath55 more favorable than assignment to level @xmath54 in terms of the energy function ? in the graphical representation this assignment is represented by a cut through edges of neighboring tuples and edges between tuples and the @xmath54 and @xmath55 level ( figure [ fig : gcproblem_optimal_cut ] ) .    due to the well known min cut / max flow theorem of graph theory the optimal energy coincides with the smallest sum of capacities of the edges one has to cut from the graph to disconnect @xmath54 from @xmath55 @xcite .",
    "the cut splits the graph @xmath57 in two subgraphs : the part @xmath58 which is connected to the vertex @xmath54 and the part @xmath59 which is connected to @xmath55 .",
    "the algorithm we apply solves this problem in polynomial time ( appendix ) .    to make min cut / max flow useable for the above described assignment of multiple different levels @xmath43",
    "it has to be embedded into an outer procedure . for this",
    "we use the @xmath40-expansion algorithm @xcite .",
    "it finds provably good approximate solutions by iteratively solving graph cut problems on graphs representing the binary decision whether to alter the previous assigned level configuration or not @xcite . for a multi level problem new levels",
    "are added successively in a random order .",
    "that means , once the graph has been optimized for @xmath14 levels and the new @xmath60th level is introduced , @xmath55 corresponds to the assignment to the predefined level set and @xmath54 to the new level .",
    "again capacities for all edges are computed . with the new graph cut , vertices in the subgraph @xmath58",
    "get assigned their new level , the other vertices connected to @xmath59 keep their previously assigned level . after having introduced all levels , in order to minimize the energy even more , the assignment can be optimized by iteratively reintroducing the complete level set . this iteration stops when the overall energy is not decreasing anymore ( appendix ) .    in general finding the level configuration which coincides with minimal",
    "energy requires at least nondeterministic polynomial time .",
    "graph cut algorithms provide the advantage to solve the problem in polynomial time , with the constraint to be just applicable to energies which exhibit a strong local minimum @xcite .",
    "this is the case if the pairwise terms @xmath61 of the energy function satisfy @xmath62 for arbitrary levels @xmath63 .",
    "this is also known as submodularity or regularity condition . +      to perform cc",
    "we have to specify the energy function , eq.([eq : combinatorialfunctional ] ) as well as the level grid .",
    "the levels can be chosen arbitrarily , and depending on the problem , provide an elegant way to introduce prior information .",
    "often molecular motors move in discrete steps with known step - size . in this case",
    ", the spacing of the level grid can be chosen to match the known step - size . if such information is not known a priori or steps are expected to be nonuniform the levels have to be chosen with a refinement that corresponds to the required numerical accuracy , i.e. with a sufficiently small spacing .    to determine the relative importance of the terms @xmath64 and @xmath65 in equation [ eq : combinatorialfunctional ]",
    ", we introduce the parameters @xmath66 , @xmath67 and @xmath68 which regularize the detected steps .",
    "+ the data terms @xmath69 penalizes deviations of the proposed level amplitude @xmath43 to the original tuple amplitude @xmath70 at the vertex @xmath71 @xmath72 where @xmath66 is a regularization parameter determining the importance of the data term , and @xmath73 the weight of the current tuple .",
    "the most prominent plateaus are likely to be discovered by tvdn and contribute a tuple with a large weight .",
    "thus , in order to preserve these plateaus the data term also depends on the weight @xmath73 .    for the case of an equidistant level set",
    "@xmath61 consists of two different terms , a smoothing term and a term that favors steps of a certain size .",
    "the first and simpler pairwise energy uses a potts model @xcite to increase the energy whenever two assigned levels @xmath43 and @xmath74 differ @xmath75 where @xmath76 if @xmath77 and @xmath78 else . here",
    "@xmath67 is the smoothing parameter determining the energetic penalty for differing adjacent levels .",
    "the potts model satisfies the submodularity condition , eq . , @xcite",
    ". a larger regularization parameter @xmath67 boosts clustering of the signal and therefore combines steps .",
    "there is no other a - priori bias towards combining steps due to the cc algorithm itself .",
    "+ the second more sophisticated contribution to the pairwise term in eq.([eq : combinatorialfunctional ] ) favors level changes of specific size between adjacent sites .",
    "this second pairwise term is optional if step sizes are uniform and it serves the purpose to introduce that prior information . lowering the regularization parameter @xmath68 gives rise to the introduction of new steps with a special step height .",
    "the complete pairwise term @xmath79 thus includes prior information about step heights and is given by @xmath80 with an expected average step height @xmath81 determined by the underlying process .",
    "the depth of the jump height prior potential is given by the jump height parameter @xmath68 .",
    "in contrary to eq .",
    "we chose this term to not depend on the weights of the adjacent sites to regularize step sizes independently of the corresponding dwell times .",
    "note that not all pairwise terms constructed by eq .",
    "strictly fulfill the submodularity condition , eq . .",
    "therefore we applied an extension to the graph construction procedure proposed in @xcite to circumvent a submodularity violation ( appendix ) .",
    "the procedure truncates the energy until it satisfies .",
    "the procedure is applicable to any energy function and provides a provably good approximation for a single expansion move . for the complete @xmath40-expansion the procedure is applicable if most of the terms are submodular @xcite .",
    "this is fulfilled by all signals presented below : mean fraction of non - submodular terms @xmath82 .      in order to quantify positional and temporal accuracy of the steps detected by ebs we use simulated data of noisy steps which are generated in a two stage process .",
    "in a first stage we generate a piecewise constant signal according to a simplified pol ii stepping model where a step is the product of an enzymatic process with a certain net rate .",
    "this model contains an elongation state with forward steps of @xmath83 in size generated using an effective stepping rate @xmath84",
    ". we also account for backtracked states which can be entered by a backward step of @xmath85 @xcite with a rate @xmath86 . in a backtracked state pol ii",
    "can step forward or backward by @xmath85 with the rates @xmath87 or @xmath88 respectively .",
    "secondly , we simulate experimental noise including effects of confined brownian motion of trapped microspheres . to accurately reflect the experiment",
    ", we take into account changes in tether length and tether stiffness due to the motion of the enzyme .",
    "we apply a harmonic description of the trapping potentials and assume that the dna linker can be described by a spring constant @xmath89 determined by the worm like chain model ( appendix ) .    in real experiments ,",
    "the equilibrium position of the trapped microspheres is influenced by drift which leads to colored noise characteristics on long timescales .",
    "sources of drift are , for example , pointing or power fluctuations of the trapping laser or temperature drifts . to analyze the influence of drift on the detected step signal",
    "we simulate drift as a confined brownian motion with a very slow time constant ( @xmath90 ) and a diffusion constant of @xmath91 .",
    "this represents a stochastically fluctuating base line which is added to the simulated steps .",
    "furthermore , the drift signal is assumed to be small enough not to affect kinetic parameters of the stepping simulation . using these parameters",
    ", the simulation produces drifts of around @xmath92 on a timescale of @xmath93 ( figure [ fig : exampledriftdata ] ) which can be even outperformed by current high resolution instruments @xcite .",
    "we simulated a slow , an intermediate and a fast scenario with elongation rates of @xmath94 , @xmath95 and @xmath96 , respectively .",
    "for the slow scenario we generated @xmath97 data points with time increments corresponding to a @xmath98 sampling frequency .",
    "simulated signals of the intermediate scenario consist of @xmath99 data points with @xmath100 sampling frequency .",
    "the computed standard deviation in both scenarios is @xmath101 at the given sampling frequency . for the fast scenario we chose @xmath102 data points and @xmath103 sampling rate .",
    "moreover in the fast scenario we use higher noise amplitudes with a computed standard deviation of @xmath104 at the @xmath103 sampling frequency .    for ebs analysis of the noisy steps we have to choose the parameters @xmath105 , @xmath106 and @xmath107 as well as the level spacing for cc .",
    "since our task is to optimize eq.([eq : combinatorialfunctional ] ) we are only interested in relative values of the data and interaction function .",
    "thus , we can arbitrarily set @xmath108 .",
    "@xmath106 and @xmath107 are parameters that have to be defined by the user .",
    "the smoothing parameter @xmath106 has to be large enough to cluster small steps but small enough not to miss simulated steps .",
    "to this end , simulated data can be used to optimize parameters such that as many steps as possible are recovered but only few false positives are created ( appendix ) .",
    "we choose @xmath109 , @xmath110 and use a level grid spacing of @xmath85 i.e. the simulated step - size .    in order to compare different step - finding algorithms ,",
    "we need to define a criterion when a detected step occurs at the correct time - point .",
    "a detected step is classified correct whenever its temporal position lies with @xmath111 of the simulated step .",
    "we choose the window size such that @xmath112 .",
    "this allows for a small temporal shift of the detected steps with respect to a simulated step .",
    "the window is small enough to minimize classification of a step as correct by chance but large enough to make the step detection robust against numerical error .",
    "the definition of correct steps is further used to introduce two quantities that characterize step detection performance .",
    "the recall is defined by the number of correct steps divided by the number of simulated steps and provides information about the completeness of the recovered steps .",
    "the recall s value is only meaningful in combination with a second quantity called precision .",
    "precision is defined by the number of correct steps divided by the number of detected steps , which is essentially the probability that a detected step is in the above defined time interval around a simulated step .      in transcription elongation periods of forward motion",
    "are oftentimes interrupted by backward steps .",
    "this so - called backtracking is important in - vivo for regulating transcription and therefore it is desirable to accurately detect backtracks in order to better understand regulation .",
    "dwell times between detected steps are assigned to the set of backtracked states when they lead to a backward step . a backtracked pausing interval ends at a forward step that transfers pol ii back to the elongation state . at high noise and for fast steps we do not expect that our method will perfectly find all backtracking events present .",
    "for example , short backtracks can be omitted resulting in a long dwell time between two forward transitions in the detected steps . however , since the rates of backtracking are slow compared to elongation rates , we can correct for the missed detection of a backward step by a statistical hypothesis testing of dwell times , assuming that forward stepping follows an exponential waiting time distribution ( appendix ) .",
    "the corresponding mean dwell time can be estimated from the dwell time histogram of forward steps .",
    "thus , dwell times which violate this hypothesis are also considered as backtracked intervals , even if the actual backtracking step is not detected .",
    "a typical method for this separation is a savitzky - golay filtered velocity threshold pause detection ( sgvt ) .",
    "sgvt finds backtracked regions in savitzky - golay smoothed data from histograms of instantaneous velocities @xcite .",
    "these histograms show a pause - peak around zero velocity and an elongation - peak .",
    "one typically defines a velocity threshold by computing the mean plus one ( or two ) standard deviation(s ) of the pause - peak which is used to characterize paused regions in transcription data .",
    "a sensible choice for typical pol ii experiments of the savitzky - golay filter parameter is to use third order polynomials and a frame size of 2.5s @xcite .",
    "we will compare the performance of the sgvt algorithm to ebs in determining backtracks .",
    "we developed the ebs algorithm to determine steps in the trajectories of molecular motors ( the software package can be downloaded at https://github.com/qubit-ulm/pwcs ) and tested this algorithm on simulated data of pol ii stepping using published rates ( methods and appendix ) .",
    "we first simulated data using the intermediate scenario ( methods ) .",
    "we simulated a trajectory of @xmath113 ( i.e. @xmath114 data points ) resulting in @xmath115 steps . in our simulation noise amplitudes",
    "are much larger than the @xmath85 steps of the simulated step signal ( figure [ fig : tvdngcutresult ] ) .",
    "tvdn efficiently removes noise and produces a set of @xmath116 plateaus ( figure [ fig : tvdnstepsgcutresult ] ) .",
    "the tvdn data approximates the simulated step signal , but often decomposes a simulated step into several smaller steps .",
    "how well a particular algorithm can detect steps is best tested by computing the recall , i.e. the number of correct steps divided by the number of simulated steps , and the precision , the number of correct steps divided by the number of detected steps ( methods ) . for ideal step detection both recall and precision have to be close to one .",
    "a step finder which exhibts low recall but high precision tends to underfit the simulated step signal . on the other hand ,",
    "high recall but low precision is a sign of overfitting .",
    "both , underfitting as well as overfitting are undesired since they may significantly distort statistical properties calculated from the detected step signal .    for the simulated data the computed recall of tvdn is @xmath117 , which is fairly high",
    ". however , this comes at the cost of a low precision of @xmath118 . in the second step of ebs we use cc to cluster the denoised data to predefined levels of integer multiples of the known step size of @xmath85",
    "this results in a total of @xmath119 found steps and thus many steps in the tvdn data are removed ( figure [ fig : ebsstepsgcutresult ] ) .",
    "tvdn visually traces the simulated data very well ( figure [ fig : tvdnstepsgcutresult ] ) , however overfits the signal , i.e. there are many more detected plateaus than simulated steps . in this example , the cc algorithm performs much better , due to the high noise not all steps are recovered ( figure [ fig : ebsstepsgcutresult ] ) .",
    "some simulated steps were missed or fused to steps of double size . compared to the tvdn",
    "the computed recall is slightly reduced , but the precision of @xmath120 is much higher , showing that the data is fitted more accurately .",
    "the quality of the performance of cc depends on the value of the prior potential parameters @xmath121 tuned to optimize precision and recall ( appendix ) .",
    "the @xmath18-heuristic is the starting point of finding steps which are corrupted by noise and here we analyze the applicability of this scheme on simulated data .",
    "in general we do not expect that this scheme returns good results for arbitrarily large noise amplitudes or sampling frequencies on the order of stepping rates .",
    "the dependencies on noise amplitudes and sampling frequencies for poisson distributed steps ( forward stepping with rate constant @xmath122 ) covered by noise can be best summarized in the following phase diagrams ( figure [ fig : phasesamplfreq ] and [ fig : phasesnr ] ) . as for the data shown in figure [ fig : tvdnheuristic ]",
    "we compute the number of produced steps after tvdn for different denoising parameter @xmath17 . for a signal of @xmath123 length with @xmath124",
    "poisson distributed steps we vary the sampling frequency and keep the standard deviation of noise constant at @xmath125 ( figure [ fig : phasesamplfreq ] ) . for each sampling frequency",
    "the number of produced steps is normalized to the number of simulated data points .",
    "furthermore , we vary the standard deviation of noise and keep the sampling frequency constant at @xmath126 ( figure [ fig : phasesnr ] ) .    in the overfitting regime ( white ) , the number of steps of the denoised signal equals the number of data points . at @xmath127",
    "the denoised signal is constant without any steps . at a sampling frequency",
    "@xmath128 the number of steps as a function of @xmath17 has a clear transition between overfitting and underfitting and resembles the data shown in figure [ fig : tvdnheuristic ] ( blue ) . as the sampling frequency is lowered the transition is shifted more and more torwards @xmath23 . below a sampling frequency of @xmath129 the number of produced steps are gradually increasing until there are as many steps as data points , as was already observed for the data in figure [ fig : tvdnheuristic ] ( red curve ) .",
    "if the sampling frequency is this low , the @xmath18-heuristic is not applicable anymore since tvdn breaks down and just imitates noise . at @xmath130",
    "there are on average @xmath131 data points for each plateau .",
    "since steps are poissonian distributed many steps have plateaus that consist of less than @xmath131 data points and are thus hardly distinguishable from noise . for decreasing signal to noise ratio ( snr )",
    "we get a similar shift of the phase boundary torwards @xmath23 for worse snr , figure [ fig : phasesnr ]",
    ".      actual measured data exhibits drift stemming from the instrument . to analyze the influence of drift on step detection performance of ebs , simulated data ( slow scenario )",
    "is used with different amplitudes of a stochastic drift .",
    "an example of such a drift can be seen in figure [ fig : exampledriftdata ] .",
    "it produces a deviation of @xmath132 in a time interval of @xmath133 compared to the simulation without drift ( figure [ fig : exampledriftdata ] , green arrow ) .",
    "this slightly influences the @xmath17-versus - number - of - steps curve of the tvdn heuristic ( figure [ fig : tvdncurvedrift ] ) . in an intermediate regime of @xmath134",
    "the additional low frequency fluctuations produce slightly more steps when drift is present ( figure [ fig : tvdncurvedrift ] , red ) compared to the same noisy step signal without drift ( figure [ fig : tvdncurvedrift ] , blue ) .",
    "although ebs can eliminate most of these drift induced tvdn steps some false positives remain which decreases the algorithms step detection precision .",
    "we analyzed the influence of drift on the precision by successively increasing the diffusion constant @xmath135 of the drift simulation ( @xmath136 ) .",
    "for every value of @xmath135 , 25 signals were simulated according to the slow scenario and the mean precision of step detection was plotted against the mean peak - to - peak difference of the drift of each signal ( figure [ fig : corectlydetdrift ] ) . for relatively small drift ( @xmath137 ) precision",
    "decreased by only @xmath138 and thus the influence of such a drift is rather negligible .",
    "only the comparably large drift of @xmath139 decreases the precision to @xmath140 and thus introduces much more false positives than for signals without drift .      in the following",
    "we compare the performance of the ebs algorithm to commonly used algorithms for detecting steps in the trajectory of motor proteins namely , a t - test @xcite,(using an implementation that sweeps over different window sizes , @xcite ) , the kalafut and visscher algorithm ( k & v ) , @xcite , ( using the implementation from @xcite ) and the variable stepsize hidden markov model ( hmm ) @xcite .",
    "( 1,1.58023033 ) ( 0,0 ) in @xmath141 ) : t - test ( @xmath142 ) , hmm ( @xmath143 ) , k & v ( @xmath144 ) , ebs ( @xmath145 ) , simulation ( @xmath146 ) .",
    "note that in case of the detected dwell times the first two bars are not taken into account since steps with short dwell times are likely to be skipped by step detection algorithms.,title=\"fig : \" ] ( 0.1006768,1.25324419)(0,0)[lb ] ( 0.06664107,1.33886205)(0,0)[lb ] ( 0.06664107,1.4244799)(0,0)[lb ] ( 0.46218538,1.41224308)(0,0)[lb ] ( 0.1006768,0.98095835)(0,0)[lb ] ( 0.06664107,1.07941885)(0,0)[lb ] ( 0.06664107,1.17787936)(0,0)[lb ] ( 0.46583206,1.13718381)(0,0)[lb ] ( 0.1006768,0.7086725)(0,0)[lb ] ( 0.04476096,0.807133)(0,0)[lb ] ( 0.06664107,0.90559351)(0,0)[lb ] ( 0.46096982,0.86489796)(0,0)[lb ] ( 0.1006768,0.43638665)(0,0)[lb ] ( 0.06664107,0.53484716)(0,0)[lb ] ( 0.06664107,0.63330766)(0,0)[lb ] ( 0.47312543,0.59805637)(0,0)[lb ] ( 0.1242587,0.1307944)(0,0)[lb ] ( 0.26040163,0.1307944)(0,0)[lb ] ( 0.41356242,0.1307944)(0,0)[lb ] ( 0.56672321,0.1307944)(0,0)[lb ] ( 0.719884,0.1307944)(0,0)[lb ] ( 0.87304479,0.1307944)(0,0)[lb ] ( 0.45853869,0.08460306)(0,0)[lb ] ( 0.1006768,0.1641008)(0,0)[lb ] ( 0.06664107,0.2486616)(0,0)[lb ] ( 0.06664107,0.3332224)(0,0)[lb ] ( 0.03841175,0.67363568 ) ( 0.41234734,0.32090827)(0,0)[lb ]    ( 1,0.57142857 ) ( 0,0 ) ( 0.25522732,0.03194034)(0,0)[lb ] ( 0.40480564,0.03194034)(0,0)[lb ] ( 0.55531301,0.03194034)(0,0)[lb ] ( 0.71511097,0.03194034)(0,0)[lb ] ( 0.10992267,0.05739653)(0,0)[lb ] ( 0.08390905,0.18746463)(0,0)[lb ] ( 0.08390905,0.31753273)(0,0)[lb ] ( 0.08390905,0.44760083)(0,0)[lb ] ( 0.06269492,0.06529175 ) ( 0.80627013,0.4317223)(0,0)[lb ] ( 0.80627013,0.39287096)(0,0)[lb ]    in order to quantitatively compare the results of the algorithms , we chose the slow , intermediate and fast scenarios ( methods ) . to get statistically meaningful results we simulated 25 time traces for each scenario .",
    "input parameters of the step - detection algorithms were adjusted once for each simulation scenario ( appendix ) .",
    "after the analysis the detected steps were compared to the simulated input steps by computing recall and precision according to our criterion of correctly recovered steps ( methods and figure [ fig : compperformance ] ) .    for the slow scenario , around half of the simulated steps could be recovered by each of the four algorithms ( figure [ fig : stepsrecall ] ) .",
    "while the k & v algorithm recovers the fewest of the simulated steps ( recall : @xmath147 ) , the much larger precision ( @xmath148 ) shows that there are comparably few false positives among the detected steps . the other algorithms exhibit a somewhat smaller precision ( t - test @xmath149 , hmm @xmath150 and ebs @xmath151 ) , but a higher recall ( t - test : @xmath152 , hmm : @xmath153 , and ebs : @xmath120 ) .",
    "this means that more detected steps are misplaced or shifted with respect to the simulated steps .",
    "hence , for these conditions all four algorithms work well and recover a similar amount of steps in a close vicinity of the simulated steps .",
    "however , the k & v algorithm is a little more conservative towards placement of new steps thus increasing the precision but lowering the recall .    in the intermediate scenario stepping rates are faster which clearly reduces the recall for the t - test ( @xmath154 ) .",
    "this effect is less dramatic for the hmm ( @xmath155 ) , k & v ( @xmath156 ) and ebs ( @xmath155 ) .",
    "the precision of hmm ( @xmath157 ) and k & v ( @xmath158 ) are at a similar level followed by ebs ( @xmath159 ) and t - test ( @xmath152 ) .",
    "the fast scenario exhibits even faster steps and higher noise amplitudes and thus is the most difficult simulation setting considered here .",
    "the t - test recovers @xmath160 of the simulated steps at around half the precision of the other algorithms showing the worst performance .",
    "the performance also decreased for the other three algorithms .",
    "however , compared to hmm ( @xmath161 ) and k & v ( @xmath162 ) , ebs recovers approximately twice as many correct steps ( @xmath163 ) at a comparable precision ( hmm : @xmath164 , k & v : @xmath152 and ebs : @xmath147 ) .",
    "the correct timing of a detected step , as described by the computed values of precision and recall is only one important aspect of step detection .",
    "it is also important to test whether the recovered step - size distribution resembles the simulated stepping behaviour ( figure [ fig : corrsizestephist ] ) . for the fast scenario , due to the lower bandwidth and",
    "faster stepping rates the algorithms do not reproduce the simulated step size well . here , all algorithms tend to fuse @xmath85 steps to steps of larger size which explains the smaller number of found steps compared to number of simulated steps ( figure [ fig : stepsrecall ] , [ fig : stepsprecision ] ) . while the t - test is showing a broad distribution of step sizes and both hmm and k & v detect mostly steps of size larger than @xmath165 , the step size distribution obtained by ebs resembles the expected distribution most closely .",
    "in contrast for the slow scenario step - size histograms show a majority of the expected @xmath85 steps for all algorithms considered here ( appendix , figure [ fig : addstepsizehist ] ) .",
    "therefore , in comparison with the fast scenario it becomes evident how much the noise influences the step size distributions . compared to the other algorithms , the denoising stage of ebs is the most robust .",
    "important statistical properties of the underlying chemical cycle of a motor protein are often obtained from the distribution of dwell times , i.e. the duration between adjacent steps . to analyze the quality of the detected dwell times in the fast scenario ,",
    "we compute dwell time histograms ( @xmath166 binning ) from the detected steps of each algorithm and compare them to the distribution of simulated dwell times ( figure [ fig : dwelltimedist ] ) . while the ebs derived dwell time histogram has a similar shape than the actual simulation input , the other algorithms fail to recover the general shape of the histogram .",
    "this observation is also reflected in the rate constants of a double exponential fit to the dwell time distribution ( figure [ fig : dwelltimedist ] , red curve ) . here",
    ", rate constants extracted from the steps detected by ebs deviate about a factor of two from those extracted directly from the simulated distribution . in contrast , the rate constants determined by the other algorithms deviate by several orders of magnitude when determining the pausing rate and are also considerably worse compared to ebs in determining the elongation rate .",
    "how well the detected dwell time distributions reproduce the simulation can also be quantified by the kullback - leibler divergence ( figure [ fig : dwelltimekl ] ) . as expected",
    "the kullback - leibler divergence of ebs is smaller compared to the other algorithms .",
    "moreover , due to the slower stepping rates and smaller noise amplitudes in the slow scenario , dwell time histograms of detected steps are more similar to the distribution of the simulation than in the fast scenario ( figure [ fig : dwelltimekl ] , blue bars ) .    in summary , with properly adjusted parameters , none of the algorithms overfits the highly noisy data since precision exceeds recall in all four cases and thus there are fewer detected steps than simulated steps ( figure [ fig : stepsrecall ] and [ fig : stepsprecision ] ) .",
    "nevertheless , the low recall performance means that step detection accuracy is strongly compromised for the lower bandwidth signal of the fast scenario and directly extracting information of the underlying enzymatic cycles of elongation from dwell time fluctuations would result in errors .",
    "moreover , we also compared the run - times for all four algorithms on signals which contain @xmath167 data points and @xmath168 simulated steps .",
    "we chose rate constants according to the intermediate scenario and recorded the respective run times ( @xmath169 ) .",
    "ebs is the fastest algorithm with run times of @xmath170 .",
    "the t - test is @xmath171 times , the k & v : @xmath172 times and the hmm : @xmath173 times slower ( appendix , table [ tab : dataptsruntime ] ) .",
    "ebs is fast enough , that even very high bandwidth signals with @xmath174 data points ( @xmath175 simulated steps ) can be compressed very quickly , yielding a run time of only @xmath176 ( appendix ) . therefore , ebs can process much more data points at comparably short run time and is essentially limited only by the available memory size ( appendix ) . the ability to quickly process a large number of data points can be used to increase the accuracy of step - finding when the signal is sampled with higher rates .",
    "for example when using kinetics of the intermediate scenario , the recall can be increased at similar precision from @xmath155 with @xmath100 sampling rate to @xmath177 with @xmath178 ( appendix ) .    in summary , in the slow and intermediate scenario",
    "the algorithms under consideration perform similarly in the total number of steps found as well as in the number of correct steps . in the fast scenario where elongation rates are faster ,",
    "bandwidth is lower and noise amplitudes are higher ebs shows better results .",
    "moreover when using ebs , the results of the fast scenario could be improved by higher sampling rates which gives more data points for each plateau while still preserving comparably short run times .",
    "thus , the ebs method especially excels for signals obtained from long measurement time , high bandwidth and poor signal to noise ratio .      experimental data of pol ii transcription at saturating nucleotide concentrations yield rates comparable to the fast scenario .",
    "for these conditions the ebs as the best performing algorithm would be able to correctly detect only @xmath180 of all simulated steps .",
    "therefore , in order to better test the step - finding properties of ebs on actual experimental data one would need to reduce the stepping rates , or apply the algorithm to a motor protein with larger step size .",
    "a prominent example for such a process is the packaging of dna by the bacteriophage @xmath179 motor , which makes steps of @xmath181 which consist of a burst of four steps with a size of @xmath182 each @xcite .",
    "we have applied ebs to experimental stepping data of @xmath179 recorded with a bandwidth of @xmath183 using opposing forces of around @xmath184 @xcite .",
    "we used @xmath182 for the level grid spacing as well as for the jump height prior ( @xmath81 in eq.([eq : labelterm ] ) ) .",
    "the standard deviation of the experimental noise at this sampling frequency was found to be @xmath185 .",
    "for this motor at low forces of a few pn a fast burst of four @xmath186 steps is followed by a long dwell time ( figure [ fig : pauseregions ] a ) .",
    "the presence of @xmath182 steps had previously been identified at large forces leading to a slow down of the @xmath182 steps @xcite . at the forces of @xmath184",
    "the previously applied t - test had failed to resolve the @xmath186 steps .",
    "in contrast , some of the steps are detected by ebs ( figure [ fig : pauseregions ] and appendix figure [ fig : phi29example ] ) .      while the ebs algorithm is not able to determine a large fraction of steps of pol ii at saturating nucleotide concentrations",
    "given published noise levels , it can be used to investigate pausing of the enzyme .",
    "we use ebs to detect pauses ( methods ) in experimental data from single molecule transcription elongation data of pol ii ( m. jahnel , s. grill lab ) .",
    "further we compare the pauses extracted from ebs step data to the result of sgvt ( methods ) which is a commonly applied method from the literature @xcite .",
    "the signal consists of @xmath187 data points and was recorded with a sampling frequency of @xmath103 .",
    "the noise amplitude has an estimated average standard deviation of @xmath188 @xmath189 .",
    "thus the experimental data is comparable to the fast scenario .",
    "we used both sgvt as well as ebs to detect pauses and backtracks of the enzyme ( methods , figure [ fig : pauseregions ] ) .",
    "when comparing the results from both algorithms one finds that most long pauses do overlap , while differences are observed for the detected short pauses .    in order to get a better understanding of how well the two algorithms perform , we again use simulated data with parameters for stepping rates and sampling frequency according to the fast scenario ( appendix ) . in accordance with previously published discussions on backtracked pauses",
    "@xcite we distinguish long ( @xmath190 ) and short pauses ( @xmath191 ) by a time scale @xmath192 .",
    "all simulated long pauses were found by ebs ( @xmath193 ) and the total length of long pauses compared to simulated long pauses was @xmath194 .",
    "also the sgvt found almost all long pauses ( @xmath195 ) with @xmath196 of the total duration of simulated long pauses .",
    "both methods did not falsely assign long pauses and thus the result of finding long pauses in step detected data and in sg filtered data largely agrees .",
    "however concerning short pauses , ebs outperforms sgvt in recall ( ebs : @xmath197 , sgvt : @xmath198 ) and precision ( ebs : @xmath199 , sgvt : @xmath200 ) .    especially for experiments with near base pair resolution and slow elongation rates ( i.e. @xmath201 ) ,",
    "sg filtered data is not suitable to distinguish between pauses and natural waiting times of elongation and hence step - detection becomes the only option . for these experiments pause - detection accuracy is very high and allows the analysis of dwell time fluctuations .",
    "this provides further insights into enzymatic reaction cycles such as dna sequence dependent dynamics @xcite .",
    "we have presented a novel energy based step finding scheme comprised of a denoising stage that uses tvdn followed by a cc analysis .",
    "the cc stage uses a graph cut algorithm and provides the possibility to include prior information . for biomotors with unknown step size",
    ", cc can be performed without step size prior terms .",
    "if the detected steps exhibit a dominant step size , a second application of ebs with this prior information can improve results .",
    "the ebs algorithm outperforms current schemes for detecting steps or pausing events in time trajectories of molecular motors . in case of high - noise data it had the highest recall with comparable precision . the higher step detection performance of ebs is also reflected in the step size and dwell time distributions which better reproduce the simulated distributions . in particular , for the fast scenario where the recall is rather low , further analysis of the dwell time distribution returns useful rate constants in contrast to the rates extraced from dwell time distributions of the competing algorithms . in addition",
    "ebs is much faster than competing algorithms .",
    "in particular the high computational speed of ebs becomes an advantage when multiple executions of the algorithm are necessary .",
    "one example for an extension of ebs with multiple executions , is an iteratively adapting level grid which could be used for signals with unknown step heights .",
    "similar schemes are already available for hmms @xcite and were successfully applied to fret data @xcite . for ebs ,",
    "this could be implemented by methods from multi - model fitting @xcite .",
    "another example could be to expand ebs to allow for drift correlation .",
    "as is , ebs is relatively insensitive to drift so that drifts on the order of @xmath202 have a negligible effect on step - finding ( results & discussion ) @xcite .",
    "however , one could explicitly correct for drift by using a decorrelation scheme as previously developed @xcite . again",
    "this would necessitate multiple execution of ebs .",
    "a reason the proposed ebs method exhibits competitive performance is a favorable representation of information in the signal , which led to the two stage process . here",
    ", we have used tvdn to build a fast and unbiased denoising scheme while still preserving the step features of the underlying signal .",
    "this was possible by using a drastically improved algorithm for solving the one dimensional tvdn problem which allows us to choose the regularization parameter @xmath18 automatically .",
    "in fact , tvdn with this @xmath18 performs often very well in tracing the actual signal even under noisy conditions .",
    "consequently , if tvdn is used as first stage , the choice of the regularization parameter is very important and can significantly influence the performance of further steps .",
    "previously , tvdn has been applied in a step detection algorithm of the rotary flagella motor movement @xcite . the method to determine the parameter @xmath17 developed here could be directly applied to this problem thus increasing the accuracy of the denoising scheme .",
    "nonetheless , a more rigorous theoretical examination of the sudden change from over- to underfitting of tvdn which led to our heuristics remains to be done .",
    "donoho et al .",
    "@xcite have reviewed the observation that sudden break - downs of model selection or robust data fitting occur in high - dimensional data analysis and signal processing .",
    "they further refined this finding for compressed sensing in @xcite , which is a class of @xmath203 regularized convex optimization problems .",
    "it remains an interesting question if similar theoretical statements can be established for tvdn .",
    "there exist different ways to solve the subsequent clustering problem for step detection .",
    "for example when step sizes are uniform and the signal is periodic , such as for the above mentioned rotary bacterial flagella motor , a fourier transform - based technique with nonlinear thresholding in frequency space can be used @xcite .",
    "in contrast the presented cc algorithm is broadly applicable to non - periodic signals .",
    "we found that our implementation of cc is very well suited to cluster the output of the compression since it provides a framework to include prior information and it applies to a broad class of step signals including steps with non uniform sizes .",
    "further there are comparably fast algorithms available to solve relevant energy functions .",
    "in fact , we found that our algorithm scaled approximately quadratically in the number of tuple and linearly in the size of the predefined level set in our applications ( appendix ) .",
    "the penalizing energy scheme can be extended in an intuitive way to other prior information .",
    "for example , a histogram prior could yield a global energy term that favors certain step sizes and dwell time histograms .",
    "the adjustment of the regularization parameters of the @xmath204 energy function can be guided by comparing results with simulated stepping data .",
    "this choice is not dependent on noise due to the preceeding application of tvdn .",
    "further by using weights in the energy terms the regularization parameters can be applied to different datasets of the same underlying stepping process .",
    "both , the tvdn stage as well as the clustering stage , provide the possibility to harness parallelization to gain speedups .",
    "a long high bandwidth trajectory could be divided into smaller time - intervals , which could then be treated in parallel .",
    "of course one would need to find a way to take care of the boundaries between the intervals , e.g. by shifting the time intervals and merging the data .",
    "this extension would also make a quasi online processing of measurement data possible , where new intervals are successively ingested .",
    "ebs was successfully applied to detect pauses by pol ii as well as @xmath186 steps in the packaging of dna by the bacteriophage @xmath179 motor . however , while some steps could be found , the larger the noise and smaller the step - size the fewer correct steps are found . to make fully use of the advantages of ebs higher bandwidth data is needed .",
    "moreover , shorter tether length , smaller beads or stiffer handles provided by dna origami @xcite increase resolution and thus improve step detection .    in summary ,",
    "the ebs method fills the gap of tools which are able to handle high bandwidth data with many data points as well as very noisy data under quite general assumptions .",
    "regardless of the difference in tvdn and graph cut the energy based model provides an intuitive access for the user of the method .",
    "j. r. , k. p .- y . , m. b. p. and j. m. designed research and wrote the manuscript .",
    "k. p .- y . and",
    "j. r. developed algorithms and analyzed data .",
    "we thank marcus jahnel for providing the experimental pol ii data , gheorghe chistol for providing the experimental @xmath179 phage packaging data and jeffrey r. moffitt and gheorghe chistol for matlab code of the t - test algorithm . +",
    "this work was supported by the eu integrating project siqs , the erc synergy grant bioq as well as the erc starting grant remodeling and an alexander von humboldt professorship .",
    "+ unless otherwise stated computations were performed on the computational resource bwunicluster funded by the ministry of science , research and the arts baden - wrttemberg and the universities of the state of baden - wrttemberg , germany , within the framework program bwhpc .",
    "in this section we want to show , how to determine the value of @xmath23 in tvdn analytically .",
    "the @xmath23 value determines the value of the regularization parameter @xmath17 in equation above which the solution @xmath205 remains constant and therefore contains no steps anymore .",
    "the information in the following subsections is twofold : first derive general expressions for the fenchel - rockafellar - dual problem and the forward - backward splitting applied to tvdn , second we then derive a condition for @xmath23 from the fenchel - rockafellar dual problem and provide an analytical solution .",
    "furthermore we give hints on the special ( tridiagonal ) structure of the involved operators .",
    "the definitions in the next sections follow the work of @xcite .",
    "independent of the problem of our work , we start with a function @xmath206 which is convex , proper , and lower semi - continuous . then @xmath207 is called it s legendre - fenchel dual function @xcite .",
    "@xmath208 is also convex , and it holds @xmath209 .",
    "a further specialization is useful in the context of our work , as the tvdn problem consists of a minimization of two composed convex functions @xmath210 where @xmath211 and the convex functions @xmath212 and @xmath213 .",
    "we assume , that @xmath214 and therefore there exists a lipschitz continuous gradient .    due to the fenchel - rockafellar theorem , covered in chapter 15 of @xcite ,",
    "the following problems are equivalent : @xmath215 where @xmath216 denotes the adjoint function .",
    "the unique solution of the primal problem @xmath217 can be recovered from a solution of the dual problem @xmath218 , which has not to be necessarily unique .",
    "@xmath219 we use an additional assumption which is not a constraint for the tvdn problem : @xmath220 is simple .",
    "that means , one can compute a closed - form expression for the so - called proximal mapping @xmath221 further due to moreau s identity @xmath222 is also simple @xcite .",
    "a typical method to do proximal minimization is forward - backward splitting ( see eg . chapter 27 of @xcite ) .",
    "the dual update is given by @xmath226 in this update step @xmath227 , where @xmath228 is the lipschitz constant .",
    "the primal iterates are given by : @xmath229 the above general statements and theorems are taken from the tool set of convex analysis .",
    "for further background see e.g. @xcite or @xcite . in the following",
    "we discuss more problem specific expressions .      in a continuous picture",
    "the total variation of a smooth function @xmath230 is defined as @xmath231 in the discretized version one has to consider a discretized gradient operator @xmath232 with @xmath233 .",
    "@xmath234 where @xmath235 and therefore @xmath236 taking the following form : @xmath237 using this and taking into account that the divergence and gradient operator are minus adjoint of each other ( @xmath238 ) the adjoint of the discrete gradient operator @xmath239 is minus the discrete divergence : @xmath240 therefore the divergence highly resembles a typical laplace filter from signal processing .",
    "this leads for a single entry to @xmath241 . for the deviation of @xmath23",
    "we assume the boundary conditions that @xmath242 and @xmath243 .    for noise removal ( and to get the connection to eq .",
    ") the following problem has to be solved @xmath244 to make use of the material so far choose the following composition @xmath245 after that one has to translate @xmath206 and @xmath246 into their dual representations @xmath247 and @xmath248 by using the following relations    * for @xmath249 and @xmath250 can be inverted then @xmath251 * for @xmath252 is a @xmath253-norm : then the dual function corresponds with the indicator function @xmath254 of the convex set @xmath255 : @xmath256    using that we get the following dual representation of the dual functions @xmath257 for the tvdn problem in the fenchel - moreau - rockafellar formulation . @xmath258",
    "the solution to the dual problem @xmath259 can be obtained by solving @xmath260 and by applying eq the solution to the primal problem @xmath205 @xmath261    what is missing for concrete expression for the forward backward iterations is first a closed form for the gradient of @xmath262 , which is given by @xmath263 secondly it is possible for the proximal operator of @xmath264 , which is the orthogonal projection on the set @xmath255",
    "@xmath265 @xmath266 inserting the above statements into the general dual update step from eq .",
    ", one gets the following expression : @xmath267 .      finding a maximal regularization parameter",
    "@xmath17 is equal to finding a a criterion , such that the dual iterations remain constant @xmath268 @xmath269 by using eq .",
    "one can see , that this will lead to a steady state solution @xmath270 . for simplicity",
    "assume @xmath271 . starting from the proximal iteration we find that in case of @xmath272 the problem simplifies to @xmath273 to satisfy the constant condition from eq .",
    "the @xmath274 has to be in the solution of : @xmath275 the shape of @xmath276 is the following @xmath277 linear equations with a tridiagonal affine transform @xmath276 can be efficiently solved for example an algorithm proposed by rose @xcite .    still missing is a treatment of the primal iteration step @xmath278 .",
    "the connection to the @xmath17 in the original tvdn problem is given such that , the karush - kuhn - tucker conditions are still valid for our steady state solution .",
    "this means , that every @xmath274 in the dual solution has to satisfy @xmath279\\,.\\ ] ] to ensure this , we have to choose @xmath280 which gives as a clear statement how to choose a maximal lambda .",
    "as outlined in the methods section of the paper , we use a sudden increase of resulting steps when decreasing the regularization parameter @xmath17 in the tvdn problem shown in eq . from @xmath23 to determine @xmath18 . in the following ,",
    "we want to describe the heuristic method , we used to choose the value of @xmath18 . starting point for the algorithm is the value of @xmath23 on a curve like the one depicted in figure [ fig : tvdnheuristic ] .",
    "the iterative method shown in algorithm [ algo : lambda_heuristic ] approximates the point of steepest ascent in an @xmath17-@xmath281 diagram , where @xmath281 is the number of steps , by searching an interval where the slope exceeds the slope of the secant of @xmath282 .",
    "the function @xmath283 counts the number of steps after the tvdn minimization for a given value of @xmath17 .",
    "+ this simple method gave us stable results for a variety of our test signals , either simulated or experimentally gathered .",
    "in the following section we have a closer look into the stability of the effect of sudden increase of steps .",
    "in the process of assigning a level @xmath43 to vertex @xmath291 the above mentioned graph cut algorithm solves a binary decision problem , whether the assignment of a new level is more favorable in terms of the energy loss function or not .",
    "the binary outcome of the decision is reflected in the graph structure by introducing two special vertices , where @xmath55 is associated with keeping the old and @xmath54 with assigning the proposed level .",
    "the energy values of the data term @xmath69 as well as the pairwise term @xmath292 and their different combinations of keeping the current level or assigning a new level are mapped to capacities of edges in the markov random field . in this section this mapping",
    "is explained stemming theoretical foundations outlined by kolmogorov et .",
    "al . in @xcite .",
    "the graph cut algorithm solves this problem in polynomial time for a certain set of useful energy functions @xcite .    in figure",
    "[ fig : mrf_energy_f1 ] the situation for the data term is depicted . here",
    "the mapping is easy , as the energy for a single variable @xmath71 for the current level @xmath293 is mapped to the edge @xmath236 .",
    "the energy @xmath294 for a new level is mapped to the edge @xmath295 .",
    "the situation for the pairwise term @xmath79 is more complicated and depicted in figure [ fig : mrf_energy_f2 ] . here",
    "two variables @xmath71 and @xmath296 are involved which leads to four different energy combinations @xmath297 , @xmath298 , @xmath299 , @xmath300 are possible . here",
    "@xmath297 is associated with the energy value if both variables get assigned a new level .",
    "in contrast @xmath300 represents the energy of both variables keeping their current levels .",
    "the two other combinations represent the case when one variable keeps the current label and the other gets the new level assigned .",
    "@xmath298 the variable @xmath60 keeps its level , for @xmath299 this is the case for the variable @xmath14 .",
    "the first summand on the right hand side is mapped to terminal capacities .",
    "this means that the capacity @xmath34 is associated with the edge @xmath255 , and the capacity @xmath302 with the edge @xmath295 .",
    "the second summand maps to the edge @xmath303 and gets the capacity @xmath304 .    at this point",
    "the above mentioned strategy to circumvent a violation of submodularity is applied if @xmath305 . then",
    "in turn @xmath298 and @xmath299 is increased and @xmath297 is decreased by a small amount until the submodularity condition eq . is satisfied .",
    "details and limitation of this approach can be found in @xcite .",
    "finding a solution @xmath306 that minimizing eq .",
    "is a problem that is in general np - hard to solve for @xmath307 .",
    "the iterative @xmath308-expansion algorithm outlined in algorithm [ algo : alpha - expansion ] finds provably good approximate solutions to this problem .      in each iteration",
    "the algorithm updates or moves the current labeling @xmath312 if it has found a better configuration . to achieve this",
    ", in each iteration , a new , randomly chosen label @xmath313 is introduced and each site @xmath71 has the choice to stay with the previous label or adopt the new proposed label @xmath40 .",
    "the binary optimization problem is solved via a graph cut ( line [ algo : alpha - expansion : argmin ] of algorithm [ algo : alpha - expansion ] ) .",
    "this step is called @xmath40-expansion due to the fact , that the number of nodes with the label @xmath40 assigned could grow during this phase . the outer iteration stops if no new label assignments happened within two cycles .",
    "the @xmath40-expansion algorithm was initially published by boykov et al . in @xcite .",
    "the submodularity condition imposes structure on the energy minimization problem which allows stronger algorithmic results . in this sense",
    "the concept of submodularity plays a similar role for discrete , combinatorial clustering as convexity plays for continuous optimization .",
    "the max - flow / min - cut algorithm we use for minimization relies on that the supplied energy function satisfying the submodularity condition .",
    "unfortunately , the pairwise term does not strictly satisfy the submodularity condition .",
    "therefore we adopted a truncation scheme proposed by rother et al . in @xcite .",
    "the truncation procedure for a single term can be summarized as follows : either @xmath314 decreased or @xmath315 or @xmath316 are increased until the submodularity condition is satisified .",
    "this procedure is applicable to any energy function , and provides a provably good approximation for a single expansion move .",
    "the authors of @xcite limit suitability for the case only a limited amount of terms are non - submodular . + in principle there exist more sophisticated graph cut algorithms that alter the mapping of the combinatorial values of the energy to capacities of the edges of the graph @xcite . in the same work ,",
    "the authors compare performance of their more complicated optimization scheme for non - submodular energies to truncating the energy as we did . for a small percentage of terms violating the submodularity condition no severe degradation of the performance",
    "was found so we stayed with the simpler method , as it is more accessible and easier to reason about .",
    "the implications of non - submodular terms highly depend on the underlying dataset and the chosen pairwise energy function .",
    "if , like in case of our label prior term the non - submodular case is a rare event , the simple truncation procedure has a positive impact .",
    "thus , the submodularity violation is a problem that has rather theoretical implications than practical importance for our applications .      when analyzing high - bandwidth noisy time traces of the movement of molecular motors the cc step often limits run time performance .",
    "most of all , perfomance is influenced by system size , i.e. the number of tuples and number of levels in the label grid set .",
    "to analyse the scaling behaviour for these two influences numerically , we simulated 10 noisy poisson step signals for each system size and label grid set and record computation times .",
    "( [ fig : gcutscaling ] ) shows mean and standard deviations as error bars . in fig.([fig : scalingnodes ] ) system size was increased from 250 to 3000 tuples and the number of levels offered to the combinatorial optimization problem was kept constant to around 800 levels . in this case",
    "computational time is expected to scale mostly with the complexity of the boykov - kolmogorov max flow algorithm which has a worst case complexity of @xmath317 @xcite . where @xmath255 is the cost of the minimal cut , @xmath318 and @xmath319 are respectively the number of edges and nodes in the graph .",
    "for the type of graphs considered here , for each additional tuple in the input data set we have to add two edges which would give a worst case complexity of roughly @xmath320 .",
    "however , computation times fit well to a quadratic function meaning that for our signals the scaling behaviour is better than the worst case complexity ( figure [ fig : scalingnodes ] , red curve ) .",
    "+ the second case is shown in fig.([fig : scalinglabels ] ) . when the system size is fixed ( here : @xmath321 tuples ) and the number of labels increases ( here : from @xmath322 to ca .",
    "@xmath323 ) by refining the label grid subsequently , the corresponding run times increase linear .",
    "this is in agreement with the theory behind multi label graph cut problems @xcite .",
    "the @xmath40-expansion offers new labels one by one in a random order until all labels were used and the iteration stops .",
    "thus the observed linear scaling in the number of labels is also expected from theory .",
    "it is important to point out that due to the tvdn compression the expression above is an improvement for this type of step signals ( high bandwidth , number of data points @xmath324 but comparably few steps @xmath325 ) compared to the fourier transform accelerated hmm implementation @xcite : @xmath326 where @xmath327 is the number of position states , @xmath281 the number of molecular states and @xmath2 the number of data points .",
    "moreover , the direct comparison of run times and memory consumption given in the main text shows that our algorithm is advantageous regarding computational resources compared to existing algorithms .      since markov chain monte carlo ( mcmc ) methods are standard techniques to optimize an energy functional with pott s model terms like eq.([eq : labelterm ] )",
    ", we compare the graph cut method with a metropolis hastings ( mh ) sampling and simulated annealing ( sa ) optimization algorithm @xcite . in each iteration",
    "we randomly generate a proposal assignment of labels .",
    "the new assignment of a site is accepted or rejected according to the standard mh rules .",
    "moreover a logarithmic temperature schedule is used for sa .",
    "the temperature parameter is introduced as commonly done : @xmath328 .",
    "if an accepted proposal has smaller energy than all previous ones it becomes the new configuration that minimizes eq.([eq : combinatorialfunctional ] ) . to compare the quality of the step detection result we computed the energy , eq.([eq : combinatorialfunctional ] ) with prior terms eq.([eq : labelterm ] ) for the energy minimizing solutions of graph cut and mcmc method , fig.([fig : rgraphcutmcmc ] ) . for a system size below @xmath329 tuples ,",
    "computation times of the graph cut algorithm were always below @xmath330 . since mcmc is computationally more complex longer computation times were used for mcmc , i.e. @xmath331 which allowed for @xmath332 iterations of a sa temperature cycle .",
    "each cycle consists of @xmath333 subsequent cooling steps and in each step we iterate through @xmath334 proposals .",
    "inspite of the significantly higher computational cost the mcmc solutions always have higher energies compared to graph cut and the excess energy increases for larger systems .",
    "this shows that mcmc returns increasingly worse solutions compared to the graph cut technique when the number of input data grows for fixed computation time .",
    "as expected , graph cut shows an approximately linear increase in energy with linearly increasing system size .    to conclude , the plain mcmc algorithm used here is conceptually simpler than graph cut but computationally more expansive and also less suited to cluster the denoised steps optimally according to an energy functional .",
    "this finding in one dimension is not surprising , since similar observations had been made in 2d image analysis @xcite .",
    "single base pair steps are typically exceeded by noise fluctuations and most of the time it is not possible to judge by eye whether an algorithm correctly positioned steps .",
    "therefore simulated data is necessary to show and compare the performance of step detection algorithms .",
    "we generate noisy steps in two stages as outlined in fig.([fig : datasimulationmodel ] ) .",
    "first , we generate a piecewise constant signals according to a simplified version of the linear ratchet model of pol ii @xcite .",
    "this model contains elongation and backtracked states and reproduces the ability to pause @xcite , but does not accurately reflect the temporal order of translocation and other enzymatic processes . during elongation , @xmath85 forward",
    "steps are generated with an effective rate of @xmath84 .",
    "this effective rate includes the process of translocation , ntp insertion and pyrophosphate release . in our model catalysis , bond formation and @xmath335 release",
    "are summarized by a rate @xmath336 .",
    "furthermore , the ntp - binding net rate is @xmath337 and the translocation net rate @xmath338 .",
    "@xmath339 is the ntp concentration , @xmath340 the dissociation constant , @xmath341 is the forward translocation rate of pol ii and @xmath342 backward translocation .",
    "the values of these constants are known from experiments @xcite .",
    "the elongation rate is then determined by @xmath343 . + with a rate of @xmath344 the motor makes a backward step of identical size as the forward step and thus enters the backtracked state",
    ". the enzyme can further backtrack by a rate @xmath345 or return to the original state with a rate @xmath346 ( figure [ fig : pol2stepgeneration ] ) .",
    "+ the rates corresponding to a forward step ( @xmath347 , @xmath348 ) or backward step ( @xmath349 , @xmath88 , @xmath350 ) are modified under external forces according to @xmath351 , where @xmath352 and the plus sign in the exponent applies to rates of forward steps .",
    "simulations were computed for an assisting force of @xmath353 . at this force forward and backward diffusion rates are @xmath354 , @xmath355 and @xmath356 , in accordance with the kinetic model . for numerical simulation purposes",
    "the rates above are divided by the simulation s time increment to yield dimensionless quantities .",
    "+ the transitions between elongation and backtracked states are generated using the gillespie stochastic simulation scheme @xcite for a single enzyme .",
    "dwell times are sampled from an exponential distribution according to the respective rates .",
    "+ in a second step , we simulated experimental noise including effects of confined brownian motion of trapped micro spheres . to accurately reflect the experiment",
    ", we take into account changes in the tether length and in the tether stiffness due to motion of the enzyme .",
    "we apply a harmonic description of the trapping potentials and assume that the dna linker can be described by a spring constant @xmath89 determined by the worm like chain model @xcite .",
    "+ to formulate the equation of motion of two trapped micro spheres tethered by dna we choose the coordinate system such that the enzyme moves in @xmath357-direction .",
    "furthermore we assure that drag coefficients @xmath358 and the trapping stiffness @xmath359 are identical in both traps . with this",
    "the effective dna length @xmath357 can be described by the following equation . @xmath360 where @xmath361 , @xmath89 is the dna stiffness and @xmath362 is the drag coefficient .",
    "@xmath363 is the thermal force which is treated as gaussian white noise : @xmath364 and @xmath365 .",
    "eq.([eq : trapeqsimplemain ] ) describes a so called ornstein - uhlenbeck process and can be solved and simulated by standard techniques of stochastic differential equations @xcite which is shown in the next subsection .",
    "eq.([eq : trapeqsimplemain ] ) was derived for the static situation without positional changes .",
    "however , a molecular motor which is attached between micro spheres by a dna - tether will change the tether length during its activity .",
    "thus , @xmath89 is also changing and can be computed using the worm - like chain model @xcite .",
    "+ in the simulations we use a trap stiffness of @xmath366 , a drag coefficient of @xmath367 corresponding to beads with @xmath368 diameter and an initial length of @xmath369 for the dna tether .",
    "we simulated a slow , an intermediate and a fast scenario which differ by stepping speed , sampling frequency , number of data points and noise amplitudes .",
    "sampling frequencies and number of data points of the slow scenario are @xmath370 and @xmath371 points , for the intermediate scenario : @xmath372 and @xmath373 points and for the fast scenario : @xmath374 and @xmath375 .",
    "the elongation rate @xmath84 of the slow scenario @xmath94 can be expected at a ntp concentration of @xmath376 . since backtracking becomes more likely at these ntp concentrations we limited analysis to simulated data that shows a net forward translocation .",
    "this excludes analysis of simulated data which exhibits only backtracked states .",
    "elongation rates of the intermediate ( @xmath95 ) and fast scenario ( @xmath377 ) are expected at @xmath378 and @xmath379 respectively .",
    "the standard deviation of noise amplitudes are directly computed from the noisy input data .",
    "this is done by subtracting the simulated step signal from the noisy steps and computing the standard deviation of the remaining signal . in both scenarios ,",
    "slow and intermediate , the computed standard deviation is @xmath101 at the given sampling frequency . for the fast scenario",
    "we choose @xmath102 data points and @xmath103 sampling rate .",
    "moreover in the fast scenario we use higher noise amplitudes with a computed standard deviation of @xmath104 at the @xmath103 sampling frequency .",
    "+ finally , for all three scenarios 25 data sets were simulated and analyzed .",
    "table [ tab : overviewsim ] gives an overview over the simulation parameters .",
    "e. a. galburt , s. w. grill , a. wiedmann , l. lubkowska , j. choy , e. nogales , c. bustamante .",
    "backtracking determines the force sensitivity of rnap ii in a factor - dependent manner .",
    "_ nature _ 446:820 - 823 .",
    "( 2007 )                    g. chistol , s. liu , c. l. hetherington , j. r. moffitt , s. grimes , p. j. jardine , c. bustamante .",
    "high degree of coordination and division of labor among subunits in a homomeric ring atpase .",
    "_ cell _ 151:1017 - 1028 .",
    "( 2012 )                                                        n. komissarova and m. kashlev .",
    "rna polymerase switches between inactivated and activated states by translocating back and forth along the dna and the rna .",
    "_ journal of biological chemistry _",
    "272:15329 - 15338 .",
    "( 1997 )            b. treutlein , a. muschielok , j. andrecka , a. jawhari , c. buchen , d. kostrewa , j. michaelis .",
    "dynamic architecture of a minimal rna polymerase ii open promoter complex .",
    "_ molecular cell _ 46:136 - 146 .",
    "( 2012 )        d. donoho and j. tanner . observed universality of phase transitions in high - dimensional geometry , with implications for modern data analysis and signal processing .",
    "a vol . _ 367:4273 - 4293 . ( 2009 )                                y. boykov and v. kolmogorov .",
    "an experimental comparison of min - cut / max - flow algorithms for energy minimization in vision .",
    "_ pattern analysis and machine intelligence , ieee transactions _ on 26(9):1124 - 1137 .",
    "( 2004 )      m. dangkulwanich , t. ishibashi , s. liu , m. l. kireeva , l. lubkowska , m. kashlev , c. j. bustamante .",
    "complete dissection of transcription elongation reveals slow translocation of rna polymerase ii in a linear ratchet mechanism .",
    "_ elife _ 2:e00971 ."
  ],
  "abstract_text": [
    "<S> analyzing the physical and chemical properties of single dna based molecular machines such as polymerases and helicases requires to track stepping motion on the length scale of base pairs . </S>",
    "<S> although high resolution instruments have been developed that are capable of reaching that limit , individual steps are oftentimes hidden by experimental noise which complicates data processing . here , we present an effective two - step algorithm which detects steps in a high bandwidth signal by minimizing an energy based model ( energy based step - finder , ebs ) . first , an efficient convex denoising scheme is applied which allows compression to tuples of amplitudes and plateau lengths . </S>",
    "<S> second , a combinatorial clustering algorithm formulated on a graph is used to assign steps to the tuple data while accounting for prior information .    </S>",
    "<S> performance of the algorithm was tested on poissonian stepping data simulated based on published kinetics data of rna polymerase ii ( pol ii ) . </S>",
    "<S> comparison to existing step - finding methods shows that ebs is superior in speed while providing competitive step detection results especially in challenging situations .    moreover , the capability to detect backtracked intervals in experimental data of pol ii as well as to detect stepping behavior of the phi29 dna packaging motor is demonstrated .     ^@xmath0^ the authors contributed equally to this article . </S>"
  ]
}