{
  "article_text": [
    "the syslog mechanism and its protocols@xcite are widely deployed in various kinds of systems to collect system status messages from an informational level to a critical level in a standardized way .",
    "since the original syslog protocol did not define any message body structure , the log messages are typically in free form text messages .",
    "the newer syslog protocol specification@xcite tried to organize semantic structures in the body part of a message , however , not many programs respect the specification so far .",
    "moreover , the decision on whether to use the newer format or not depends on vendors , software , or even individual programmers sometimes , we anyway have to handle both old and new message formats .",
    "there are various approaches to infer log message templates .",
    "slct@xcite is one of the basic approach to infer message templates without any prerequisite knowledge .",
    "slct is a two - pass template inferring method . in the first pass",
    ", it counts the number of words that appear in the entire log messages and find frequent words and its positions in a message .",
    "the more frequently a word appears , we can guess the word is likely a fixed keyword of the template message .",
    "for example , a message `` ` interface eth0 up ` '' is covered by the template `` ` { ( interface , 0 ) , ( up , 2 ) } ` '' that means the keyword `` ` interface ` '' is at the position 0 , and `` ` up ` '' is at the position 2 .",
    "logcluster@xcite is similar to slct but addressing shortcomings of slct .",
    "slct creates templates as a set of pairs of a word and its position .",
    "because of this , slct is sensitive to the position of words .",
    "logcluster allows variable length of parameters between fixed words .",
    "for example , `` ` interface eth0 up ` '' and `` ` interface hq link up ` '' are covered by one template `` ` interface * { 1,2 } up ` '' , where `` ` * { 1,2 } ` '' means 1 or 2 wildcard words .",
    "same as slct , logcluster requires a two - pass processing to detect the list of frequent words .",
    "xu , el al .",
    "proposed a method using source code knowledge to infer message templates in @xcite .",
    "this is useful when we know what kind of software are used in the target operation system .",
    "this approach requires preparation before classifying log messages .",
    "it also requires to update the inferred log template when software used in the target system is added or updated .",
    "kimura , et al . introduced a character class based clustering method in their work@xcite .",
    "they defined 5 classes of words each consists of only numbers , numbers and letters , symbols and letters , only letters , and only symbols respectively .",
    "the latter classes are considered more important than the former classes .",
    "the weight values for how much emphasize each class are pre - calculated based on a pa - i supervised leaning algorithm@xcite .",
    "when comparing two messages , the ratio of the number of classes included in each message is used .",
    "the more the messages are similar , the ratio will get closer to 1 .",
    "shiso@xcite is another template generation method focusing on online processing .",
    "it calculates a property of words as a vector by counting types of characters included in a word such as capital alphabets , lower alphabets , numbers , marks , and so on .",
    "shiso computes a euclidean distance between words of two messages being compared and generates similarity index of two messages .",
    "if the index is smaller than the pre - defined threshold , shiso infers the two are similar and makes a cluster .",
    "since syslog messages are printed by programs , each message has a pre - formatted style .",
    "[ fig : message - examples ] shows some examples of system log messages .    ....",
    "oct   1 00:12:51 backup sshd[6854 ] : invalid user vyatta from 41.190.192.158 oct   1 00:12:51 backup sshd[6854 ] : input_userauth_request : invalid user vyatta [ preauth ] oct   1 01:02:55 backup cron[7069 ] : pam_unix(cron : session ) : session closed for user root ....    as many previous works explained , a message comprises of two kinds of components , one is a fixed component and the other is a variable component . in the first line in [ fig : message - examples ] , assuming that we know the head of the message contains date information and host information , ` sshd ` , ` 6845 ` , ` vyatta ` , and ` 41.190.192.158 ` are variable components , while ` invalid ` , ` user ` , and ` from ` are fixed components .",
    "many existing methods try to classify these components based on some pre - defined knowledge , such as frequency of appearance , ratio of character type , and so on .",
    "our simple question was that do we really need to consider the property of each word .",
    ".... dec   1 00:05:01 vm1.example.com postfix / cleanup[2767 ] : 7ef561405e3 : message-id=<20151130150501.7ef561405e3@vm1.example.com >",
    "dec   1 00:10:01 vm1.example.com postfix / cleanup[3247 ] : 898fd1405e3 : message-id=<20151130151001.898fd1405e3@vm1.example.com >",
    "dec   1 00:27:27 backup sshd[15406 ] : invalid user admin from 222.186.30.174 dec   1 04:29:58 backup sshd[16287 ] : invalid user a from 218.38.12.218 ....    [ fig : similar - message - examples ] shows different examples of similar messages that should be clustered into the same group .",
    "if we read these messages , we can easily create a cluster of `` ` postfix / cleanup [ * ] : * : message - id= * ` '' for the first group , and `` ` sshd [ * ] : invalid user * from * ` '' , where `` ` * ` '' means a variable component because we have knowledge of what is a process identifier , or what is an ip address to infer which parts are fixed and which are not . but even though we do not use such knowledge , here is another factor we can read from these examples , that is the length of each word .",
    "it is obvious that all the fixed components have the same word length in the message .",
    "variable words have different word length , but tend to have similar length because they share the same context , such as a message identifier , an ip address , a process identifier , a host / user name , and so on .",
    "[ fig : length - distribution - examples ] shows examples of distribution of word length of some messages groups .",
    "as we can read from the figures , each syslog message has a unique pattern of distribution of length of each words .",
    "the length of the first position is usually fixed because a process name is printed here normally .",
    "the second position is process identifiers and it is usually 3 to 5 digits",
    ". the 7th position of [ subfig : sshd-1 ] is a placeholder for ip addresses and contains either ipv4 or ipv6 address . because ipv6 address can be printed shorter by eliminating zero fields , the position has wider range of length . the 9th position of [ subfig : sshd-2 ] is a placeholder for host names . in our data ,",
    "the median of the length of the position was 29 and almost fixed however , we saw some very short and long host names in the log .",
    "we analyzed how much the set of length of words are correlated each other using the syslog message dataset # 2 shown in table  [ tab : syslog - datasets ] .",
    "the dataset is a collection of messages gathered from hypervisors operated by the wide project .",
    "the distribution of the number of words of each message ( excluding date and host name information ) is shown in [ fig : nwords - distribution ] .",
    ".,scaledwidth=40.0% ]    [ cols=\">,<,>\",options=\"header \" , ]     the prototype code is available at github .",
    "we tried to find unique syslog message patterns using the messages clustered by lenma .",
    "we clustered all the messages using the algorithm and made message groups for every minute .",
    "the dataset used for this grouping is the dataset # 3 and the period is from october to december 2015 .",
    "each group has its own distribution pattern of templates , however , many of them are similar each other .",
    "we counted the number of appearance of templates of each group , clustered them using the @xmath0 test , and finally achieved 25 message group clusters out of 132480 (= 60 minutes @xmath1 24 hours @xmath1 92 days ) groups .",
    "the frequently observed patterns are shown in [ fig : frequent - patterns ] , and the counts are 16235 and 115299 times respectively . since each group is one - minute - long",
    ", almost 91 days out of 92 days match these patterns .",
    "there were some unique patterns found from the result .",
    "[ fig : unique - patterns](a ) shows that there were not common ssh incoming activities .",
    "[ fig : unique - patterns](b ) was observed when one of the nodes in the target node group rebooted .",
    "there are many approaches to detect anomalies or cluster messages based - on templates ( @xcite ) .",
    "our template mining technology can be used with these detection / clustering methods .",
    "in this section we discuss issues of our proposed method . some of the issues discussed here are not specific to our proposal only , but are applied to online template mining methods in general",
    ".    the proposed algorithm does nt take into account frequency of appearance of words .",
    "this causes state messages invisible from output .",
    "for example , ` interface eth0 up ` and ` interface eth1 down ` may generate a template such as ` interface * * ` .",
    "however , we may want two different templates ` interface * up ` and ` interface * down ` in some cases . because we are focusing on online realtime template generation",
    ", it is difficult to predict a specific word is going to be a stable word like ` up ` and ` down ` or not .    how to determine the threshold value is an important factor in the method .",
    "if the value is too loose , the algorithm will generate more specific templates that will separate messages of same meaning to different groups . in this paper",
    ", we used 0.9 as @xmath2 and 3 as @xmath3 to cluster three different message sources ( table  [ tab : syslog - datasets ] ) achieved from different administrative groups .",
    "we could achieve the similar number of templates as shiso could infer with the threshold values when applied to the standard linux server syslog messages , however the proper values may be different when applied to other kinds of dataset .",
    "in this paper , we have proposed a new clustering method for inferring system log message templates using the length of each words of messages .",
    "many existing template mining approaches try to characterize words of messages by their character types , ratio of character types .",
    "our proposal comes from the question that do we really need to investigate the word property so close .",
    "we have focused on the length of each word and found each message template has a unique sequence of word length that can be used to cluster messages .",
    "the proposed method is designed for use of online ( one - pass ) template mining .",
    "the two - pass methods usually generate better templates by surveying frequency of words to detect if a specific word is a fixed word or a variable word , however they require time before clustering and has difficulty to adapt dynamic changes of message trends .",
    "recently many systems are implemented with dynamic components such as open source software .",
    "such components are updated continuously , and even replaced with a different components providing the same functionality . in such a situation , adapting upgraded components and/or new components are important .",
    "our proposed mechanism could produce similar number of templates as past works with less complicity of mining processing ."
  ],
  "abstract_text": [
    "<S> the analysis techniques of system log messages ( syslog messages ) have a long history from when the syslog mechanism was invented . typically , the analysis consists of two parts , one is a message template generation , and the other is finding something interesting using the messages classified by the inferred templates . </S>",
    "<S> it is important to generate better templates to achieve better , precise , or convincible analysis results . in this paper </S>",
    "<S> , we propose a classification methodology using the length of words of each message . </S>",
    "<S> our method is suitable for online template generation because it does not require two - pass analysis to generate template messages , that is an important factor considering increasing amount of log messages produced by a large number of system components such as cloud infrastructure . </S>"
  ]
}