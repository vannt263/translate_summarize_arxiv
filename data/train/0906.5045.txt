{
  "article_text": [
    "estimation of the power spectral density of a continuous time wide sense stationary stochastic process is an old problem .",
    "a set of regularly ( uniformly ) spaced samples is generally used for this purpose .",
    "when the process is bandlimited , the spectral density of the original process can be recovered from that of the sampled process , provided that the sampling is fast enough .",
    "in such a case , estimation of the spectral density from finitely many observations at an appropriate sampling rate is a well established topic and many useful nonparametric and parametric methods have been developed @xcite . if the underlying process is not bandlimited , the spectral density of the original process is not identifiable from regularly spaced samples , because of the problem of wrapping around of the spectral density caused by the process of sampling  also known as aliasing @xcite .",
    "in such a case , one can not estimate the spectral density consistently from regularly spaced samples at any fixed sampling rate .",
    "this inadequacy of sampling at regular intervals necessitated the exploration of other strategies for sampling .",
    "shapiro and silverman @xcite considered alias free sampling schemes in the sense that two continuous time processes with different power spectra do not produce the same spectrum of the sampled sequence .",
    "they proved that additive random sampling through a class of renewal processes , including the homogeneous poisson process , is alias free .",
    "beutler @xcite formalized the definition of alias free sampling relative to a family of spectral distributions and gave different sampling schemes that are alias free relative to different families of spectral distributions .",
    "masry @xcite provided a modified definition of alias free sampling that would guarantee the existence of a consistent estimator of the power spectral density .",
    "subsequently , the possibility of breaking free from the nuisance of aliasing through irregular sampling enthused many researchers and practitioners .",
    "masry @xcite proposed a poisson sampling based estimator similar to the smoothed periodogram , and proved that the proposed estimator is consistent for any average sampling rate , under certain conditions .",
    "several irregular sampling based methodologies of estimation of the power spectral density of a non - bandlimited process have also been proposed @xcite@xcite and applied to various fields including signal and image processing .",
    "some of these methods are analogous to methods developed for regularly sampled data .",
    "irregularly spaced data occur naturally in many practical situations like seismic data @xcite , turbulent velocity fluctuation @xcite , laser doppler anemometer ( lad ) data @xcite , wide - band antenna arrays @xcite , computer aided tomography , spotlight - mode synthetic aperture radar @xcite and so on . there have been attempts to use standard methods for spectrum estimation for such data , after suitable weighting@xcite or interpolation @xcite of the data .",
    "the advent of new methodologies for irregularly sampled data are important for such problems .    however , in many applications , including internet traffic data @xcite , seismology @xcite , @xcite , image processing @xcite and so on , one has control over the sampling mechanism . in such cases , the selection of the sampling scheme is a serious issue .",
    "regular sampling is easier to implement than irregular sampling .",
    "the literature on power spectrum estimation based on regular sampling contains a large collection of methods , and these have been studied in detail .",
    "an estimator based on regularly sampled data is generally computationally simpler than a similar estimator based on irregularly sampled data .",
    "moreover , it is well known that spectral estimators based on irregularly sampled data have higher variances than those based on regularly sampled data @xcite , @xcite . on the other hand , the possibility of aliasing and the proven inconsistency of spectral estimators based on regular sampling are arguments in favour of using irregular sampling .",
    "these opposing arguments necessitate a thorough comparison of spectral estimators based on different sampling strategies .",
    "a systematic numerical comparison is not available in the literature .",
    "a simulated example given by masry @xcite was meant only to highlight the problem of aliasing and to demonstrate how it can be overcome with irregular sampling .",
    "studies by roughan @xcite in the special case of active measurements for network performance produced mixed results , which led the author to conclude that , while spectral estimators based on poisson sampling have less efficiency ( i.e. , high variance ) , such techniques could be used to detect periodicities in the system , and to determine which rate of regular sampling would be inadequate . in the absence of a comprehensive empirical study",
    ", it appears that many researchers shun regular sampling mainly because of the stigma of inconsistency attached to spectral estimators based on regularly sampled data @xcite .",
    "consistency of an estimator concerns its behaviour as the sample size goes to infinity .",
    "however , it does not make practical sense to let the sample size tend to infinity with fixed sampling rate .",
    "if one gathers more and more resources to increase the sample size , one can use some of these resources to sample faster . realizing this , practitioners fix the intended range of spectrum estimation , and then sample an appropriately filtered process at a sufficiently high frequency to avoid aliasing .",
    "sometimes one goes for successively higher rates of uniform sampling to determine an appropriate rate of sampling @xcite .",
    "however , these common sense approaches are yet to be backed up by appropriate asymptotic calculations .",
    "there is a need to bridge this gap by working out the large sample properties of estimators _ when the sampling rate changes suitably as the sample size goes to infinity_.    let @xmath0 be the spectral density of a mean square continuous , wide sense stationary process @xmath1 .",
    "the most commonly used nonparametric estimator of @xmath0 based on the @xmath2 uniformly spaced samples at the sampling rate @xmath3 is @xmath4 , where @xmath5}(\\lambda),\\ ] ] where @xmath6 is a covariance averaging kernel , @xmath7 is the indicator function that takes the value 1 when @xmath8 and the value 0 otherwise , @xmath9 is a sequence of window widths such that @xmath10 and @xmath11 as @xmath12 and @xmath13 is an estimator of the covariance function , defined as @xmath14 this estimator is known to be consistent when the underlying process is bandlimited .    in the present work , without assuming that the process is bandlimited , we examine the asymptotic properties of the estimator given in ( [ unifest ] ) by letting @xmath3 go to infinity at an appropriate rate , as @xmath2 goes to infinity . in the sequel",
    ", we shall use the notation @xmath15 instead of @xmath3 , in order to explicitly indicate the dependence of the sampling rate on the sample size .",
    "accordingly , we use the following modified notation of the estimator of ( [ unifest ] ) : @xmath16}(\\lambda)\\ ] ] where @xmath17    in section  [ s2 ] , we prove the consistency of the estimator @xmath18 under some general conditions . in section  [ s3 ] , we calculate the rate of convergence of the bias and variance of this estimator , and determine the optimal rates at which @xmath15 and @xmath19 should go to infinity so that the mean square error has the fastest possible rate of convergence .",
    "subsequently , we compare the rates of convergence of the bias and the mean squared error ( mse ) of this estimator with those of a similar estimator proposed by masry @xcite , based on non - uniform ( poisson ) sampling .",
    "we present the results of a simulation study in section  [ s4 ] and provide some concluding remarks in section  [ s5 ] . the proofs",
    "are given in the appendix .",
    "consider the mean square continuous , wide sense stationary stochastic process @xmath20 with zero mean , ( auto-)covariance function @xmath21 and spectral density @xmath0 . in order to prove that the estimator ( [ unifestn ] ) is consistent ,",
    "it is sufficient to show that the bias and the variance of the estimator tend to zero as the sample size ( @xmath2 ) tends to infinity .",
    "we assume the following condition on the covariance function @xmath21 .    * condition 1 . * the function @xmath22 , defined over the real line as @xmath23 is integrable .",
    "* remark 1 .",
    "* condition 1 is equivalent to saying that the covariance function @xmath21 is bounded over @xmath24 by a non - negative , non - increasing and integrable function .",
    "we assume the following conditions on the choice of the kernel @xmath6 , the kernel window width @xmath25 and the sampling rate @xmath15 .",
    "* condition 2 .",
    "* the covariance averaging kernel function @xmath6 is continuous , even , square integrable and bounded by a non - negative , even and integrable function having a unique maximum at 0 .",
    "further , @xmath26 .",
    "* condition 3 . *",
    "the kernel window width is such that @xmath27 and @xmath11 as @xmath28 .",
    "* condition 4 . *",
    "the sampling rate is such that @xmath29 and @xmath30 as @xmath31 .",
    "* remark 2 . *",
    "note that the estimator @xmath18 can be written as @xmath32 where @xmath33}(\\lambda),\\\\ w_n(\\lambda)&=&\\sum_{j=-\\infty}^\\infty \\int_{-\\infty}^\\infty k(t)e^{-\\frac{it\\lambda}{\\rho_n}-2\\pi i jt}dt.\\end{aligned}\\ ] ] thus , @xmath18 is the smoothed version of @xmath34 , the periodogram , where the degree of smoothness is controlled by the smoothing parameter @xmath35 of the frequency domain window @xmath36 .",
    "condition 4 says that this parameter goes to zero , and the sampling rate goes to infinity , as the sample size goes to infinity .    under conditions 14 ,",
    "the bias of the estimator @xmath18 given by ( [ unifestn ] ) tends to zero uniformly over any closed and finite interval .    before examining the variance of the estimator",
    "we assume the following condition on the fourth order moments of the process @xmath37 .",
    "* condition 5 .",
    "* the fourth moment @xmath38 exists for every @xmath39 , and the fourth moment function @xmath40 $ ] is a function only of the lags @xmath41 , @xmath42 and @xmath43 .",
    "further , the fourth order cumulant function @xmath44 , defined by    rcl q(v_1,v_2,v_3)&=&p(v_1,v_2,v_3)-p_g(v_1,v_2,v_3 ) , + & & + p(v_1,v_2,v_3)&=&e(x(t)x(t+v_1))x(t+v_2)x(t+v_3 ) + p_g(v_1,v_2,v_3 ) & = & c(v_1)c(v_2-v_1)+c(v_2)c(v_3-v_1 ) + & & + c(v_3)c(v_1-v_2 ) ,    satisfies @xmath45 where @xmath46 are all continuous , even , nonnegative and integrable functions over the real line , which are non - increasing over @xmath24 .",
    "* remark 3 .",
    "* condition 5 is satisfied by a gaussian process , as the function @xmath47 reduces to the function @xmath48 .    under conditions",
    "15 , the variance of the estimator @xmath18 given by ( [ unifestn ] ) converges as follows : @xmath49 = ( 1+\\delta_{0,\\lambda})[\\phi(\\lambda)]^{2}\\int_{-\\infty}^{\\infty}k^{2}(x)dx,\\ ] ] where @xmath50 is 1 if @xmath51 and is 0 otherwise .",
    "the convergence is uniform over any closed and finite interval that does not include the frequency 0 . in particular",
    ", the variance converges to 0 .",
    "it follows from theorems 1 and 2 that , under conditions 15 , the estimator @xmath52 is consistent , and is uniformly consistent over any closed and finite frequency interval that does not include the point 0 .",
    "the rate of convergence of the variance of @xmath52 follows from theorem  2 .",
    "we assume a few further conditions in order to arrive at a rate of convergence for its bias .",
    "these include additional conditions on the shapes of the covariance function and the kernel function .",
    "* condition 1a .",
    "* the function @xmath53 , defined over the real line as @xmath54 is integrable , for some positive number @xmath55 greater than 1 .",
    "* condition 1b . *",
    "the spectral density is such that , for some @xmath56 , @xmath57 is @xmath58 , i.e. , @xmath59 for some positive @xmath60 .    for any kernel @xmath6 ,",
    "let us define @xmath61 for each positive number @xmath62 such that the limit exists .",
    "the characteristic exponent of the kernel is defined as the largest number @xmath62 , such that the limit exists and is non - zero @xcite . in other words ,",
    "the characteristic exponent is the number @xmath62 such that @xmath63 is @xmath64 .    *",
    "condition 2a .",
    "* the characteristic exponent of the kernel @xmath6 is equal to the number @xmath55 , for which condition 1a is assumed to hold .",
    "* remark 4 . * condition 1a implies condition 1 ( see remark 1 ) , and also that @xmath0 is @xmath65 $ ] times differentiable , where @xmath65 $ ] is the integer part of @xmath55 .",
    "thus , the number @xmath55 indicates the degree of smoothness of the spectral density .",
    "if condition 1a holds for a particular value of @xmath55 , then it would also hold for smaller values .",
    "* remark 5 .",
    "* the number @xmath66 indicates the rate of decay of the spectral density .",
    "the following are two interesting situations , where condition  1b holds .    1 .",
    "the spectral density @xmath0 is a rational function , i.e. , @xmath67 , where @xmath47 and @xmath68 are polynomials such that the degree of @xmath68 is more than degree of @xmath47 by at least @xmath66 .",
    "note that continuous time arma processes possess rational power spectral density .",
    "the function @xmath21 has the following smoothness property : @xmath21 is @xmath66 times differentiable and the @xmath69 derivative of @xmath21 is in @xmath70 .",
    "* remark 6 .",
    "* the number @xmath66 can be increased indefinitely by continuous time low pass filtering with a cut off frequency larger than the maximum frequency of interest .",
    "there are well - known filters such as the butterworth filter , which have polynomial rate of decay of the transfer function with specified degree of the polynomial , that can be used for this purpose .    under condition 24 , 1a , 1b and 2a",
    ", the bias of the estimator @xmath52 given by ( [ unifestn ] ) is @xmath71\\\\&=\\left[-\\frac{k_{q}}{2\\pi}\\int_{-\\infty}^{\\infty}|t|^{q}c(t)e^{-it\\lambda } dt\\right](\\rho_n b_n)^{q}+o\\left((\\rho_n b_n)^{q}\\right)\\\\&~+ \\left[-\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}|t|c(t)e^{-it\\lambda } dt\\right]\\left(\\frac{\\rho_n}{n}\\right)+o\\left(\\frac{\\rho_n}{n}\\right)\\\\&~+ \\left[\\frac{a}{(2\\pi)^{p}}\\sum_{|l|>0}\\frac{1}{|l|^p}\\right]\\frac{1}{(\\rho_n)^{p}}+o\\left(\\frac{1}{(\\rho_n)^{p}}\\right ) , \\end{split}\\ ] ] i.e. , @xmath72=o\\left((\\rho_nb_n)^{q}\\right ) + o\\left(\\frac{\\rho_n}{n}\\right)+o\\left(\\frac{1}{\\rho_n^{p}}\\right),\\ ] ] uniformly in @xmath73 over any closed and finite interval .",
    "* remark 7 .",
    "* condition 2a can be relaxed to the extent that the characteristic exponent of the kernel @xmath6 is required to be greater than or equal to the number @xmath55 , for which condition 1a is assumed to hold .",
    "if it is strictly greater than @xmath55 , then the term @xmath74 in the above theorem would have to be replaced by @xmath75 .",
    "this follows from equation ( [ 2arelax ] ) in the appendix and the fact that @xmath76 in this case . on the other hand ,",
    "if a kernel with characteristic exponent less than @xmath55 is used , then one does not fully utilize the strength of the assumption on the smoothness of the spectral density , implied by condition 1a , and hence gets a slower rate of convergence .      from theorem  3 and theorem",
    "2 , it is observed that the bias and the variance of the estimator @xmath52 converge to zero at different rates .",
    "we set out to choose the sampling rate @xmath15 and the window width @xmath25 in order to ensure that mse of @xmath52 converges to zero as fast as possible .",
    "it would turn out that this happens when the squared bias and the variance go to zero at the same rate .    under conditions",
    "25 , 1a , 1b and 2a , the optimal rate of convergence of the mse of the estimator @xmath52 is given by @xmath77=o\\left(n^{-\\frac{2pq}{p+q+2pq}}\\right ) , \\label{msereg}\\ ] ] which corresponds to the optimal choices @xmath78 for some positive constants @xmath79 and @xmath80 .    the above optimal rates of @xmath15 and @xmath25 lead to the following corollaries to theorems 2 and 3 , respectively .",
    "* corollary 1 . *",
    "_ under the conditions 1 , 2 , 5 and the choices of @xmath15 and @xmath25 given by ( [ rhon][bn ] ) , we have @xmath81 = \\frac 1q ( 1+\\delta_{0,\\lambda})[\\phi(\\lambda)]^{2}\\int_{-\\infty}^{\\infty}k^{2}(x)dx , \\qquad\\label{phivar}\\ ] ] where @xmath50 is equal to 1 if @xmath51 , and is 0 otherwise . _    * corollary 2 . *",
    "_ under the conditions 1a , 1b , 2 , 2a and the choices of @xmath15 and @xmath25 given by ( [ rhon][bn ] ) , we have @xmath82 \\\\=&-(pq)^q \\frac{k_{q}}{2\\pi}\\int_{-\\infty}^{\\infty}|t|^{q}c(t)e^{-it\\lambda } dt\\!+\\!\\frac1{p^{p}}\\frac{a}{(2\\pi)^p}\\sum_{|l|>0}\\frac{1}{|l|^p},\\label{phibias } \\end{split}\\ ] ] where the constant @xmath60 is as in condition 1b . _      among the various schemes for sampling a continuous time stochastic process at irregular intervals , the poisson sampling proposed by silverman",
    "@xcite is the simplest and most popular . here",
    ", we compare the asymptotic behaviour of the estimator @xmath18 with a similar estimator based on poisson sampling .",
    "let @xmath83 be the sampling points from a poisson process with average sampling rate @xmath3 .",
    "masry @xcite proved that , under conditions 1 , 2 , 3 and 5 , the estimator @xmath84 defined as @xmath85 is consistent for @xmath57 for any choice of @xmath3 .    under the above conditions , the asymptotic variance of @xmath86 satisfies @xmath87\\\\ = & \\rho\\left[\\phi(\\lambda)+\\frac{c(0)}{2\\pi\\rho}\\right]^{2}(1+\\delta_{0,\\lambda})\\int_{-\\infty}^{\\infty}k^{2}(t)dt .",
    "\\end{split}\\ ] ]    for specifying the rate of convergence of the bias , masry @xcite assumed the following additional conditions .    * condition 1c .",
    "* @xmath88 is integrable for some positive integer  @xmath55 .    *",
    "condition 2b .",
    "* @xmath6 is @xmath55 times differentiable with bounded derivatives , where @xmath55 is an integer for which condition 1c holds .",
    "note that condition 1c is implied by condition 1a with the same or higher value of @xmath55 as is used here .",
    "masry @xcite showed that , under conditions 1 , 2 , 3 , 1c and 2b , the bias of the estimator @xmath86 is given as @xmath89=&e[\\widehat{\\psi}_n(\\lambda)]-\\phi(\\lambda ) \\\\=&\\sum_{l=1}^{q-1}\\frac{(i)^{l}k^{(l)}(0)b_n^{l}}{l!}\\phi^{(l)}(\\lambda)+o(b_n^{q})+o\\left(\\frac{1}{n}\\right ) .",
    "\\end{split}\\ ] ]    it follows from ( [ psibias ] ) that the rate of convergence of the bias of @xmath86 is @xmath90 , where @xmath91    the fastest possible rate of convergence is @xmath92 , and this is achieved when one uses a kernel , which further satisfies condition 2a with the same or higher value of @xmath55 as is used here . in such a case , we have @xmath93=o(b_n^{q})+o\\left(\\frac{1}{n}\\right ) . \\label{psibias1}\\ ] ] if the condition 2a holds with a higher value of @xmath55 , then the term @xmath94 has to be replaced by @xmath95    let us now assume that the kernel is chosen appropriately to ensure ( [ psibias1 ] ) .",
    "note that the bias and the variance of @xmath86 converge to zero at different rates .",
    "one can choose the rate of convergence of the window width @xmath25 such that the mse converges as fast as possible .",
    "it turns out that if @xmath96 , then the optimal choice of @xmath97 is @xmath98 , in which case the squared bias and variance of @xmath86 are both @xmath99 .    in summary , under conditions 1 , 1c , 2 , 2a , 2b , 5 and @xmath100",
    "the mse of @xmath86 is @xmath101=o\\left(n^{-\\frac{2q}{2q+1}}\\right).\\]]the rate of convergence of mse of @xmath52 is given in theorem  4 under conditions 1a , 1b , 2 , 2a , 5 and ( [ rhon][bn ] ) .",
    "both the results hold when @xmath15 and @xmath25 for @xmath18 are chosen as in ( [ rhon][bn ] ) , @xmath25 for @xmath84 is chosen as in ( [ bnp ] ) and the following conditions hold simultaneously : condition 1a for some @xmath55 greater than 1 ( which implies condition 1c for @xmath65 $ ] and condition 1 ) , condition 2 , condition 2a ( for the same @xmath55 as in condition 1a ) , condition 2b for @xmath65 $ ] , and condition 5 . under this common set of conditions , we have @xmath102&=o\\left(n^{-\\frac{2[q]}{2[q]+1}}\\right),\\\\ mse[\\widehat{\\phi}_n(\\lambda)]&=o\\left(n^{-\\frac{2q}{2q+1+q / p}}\\right).\\end{aligned}\\ ] ]    when @xmath55 is an integer , i.e. , @xmath65=q$ ] , the rate of convergence of the mse of @xmath52 is slower than that of @xmath86 .",
    "the two rates are comparable if @xmath66 is much larger than @xmath55 .",
    "when @xmath55 is not an integer , the mse of @xmath52 converges faster when @xmath103/(q-[q])$ ] , and in particular when @xmath66 is very large .",
    "as we have indicated in remark  6 , for every fixed @xmath55 , one can make @xmath66 suitably large through low pass filtering .",
    "if the rates of convergence are comparable , the constants associated with these rates become important .",
    "we will compare the constants of the asymptotic bias of @xmath52 and @xmath86 as well as the constants of their asymptotic variance separately , assuming that @xmath55 is an integer .    under conditions 1 , 2 , 5 and ( [ bnp ] )",
    ", we have @xmath104\\\\ = & \\frac1r\\rho\\left[\\phi(\\lambda)+\\frac{c(0)}{2\\pi\\rho}\\right]^{2}(1+\\delta_{0,\\lambda})\\int_{-\\infty}^{\\infty}k^{2}(x)dx . \\end{split}\\ ] ] on the other hand , we have from corollary 1 that under the conditions 1 , 2 , 5 and ( [ rhon][bn ] ) , @xmath105\\\\ = & \\frac 1q ( 1+\\delta_{0,\\lambda})[\\phi(\\lambda)]^{2}\\!\\int_{-\\infty}^{\\infty}k^{2}(x)dx.\\end{split}\\ ] ]    the ratio of the constants for the asymptotic variances of @xmath86 and @xmath52 is @xmath106^{2}. \\label{psivaratio}\\ ] ] this ratio depends on the poisson sampling rate @xmath3 and the true value of the power spectral density @xmath57 .",
    "this ratio can be much larger than 1 , particularly for larger values of @xmath73 .",
    "in fact , even if @xmath3 is chosen to minimize this ratio for a given value of @xmath57 ( though this is not practically possible ) , the minimum value happens to be @xmath107 $ ] , which can be arbitrarily large for large values of @xmath73 .",
    "thus , the variance of @xmath86 can generally be expected to be larger than that of @xmath52 .",
    "we now turn to the comparison of the expressions for bias . under conditions 1c , 2 , 2a and 2b along with ( [ bnp ] )",
    ", we have @xmath108-\\phi(\\lambda)]\\\\ = & -r^qk_{q}\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}|t|^{q}c(t)e^{-it\\lambda } dt . \\end{split}\\ ] ] on the other hand , we have from corollary 2 that under the conditions 1a , 1b , 2 , 2a and ( [ rhon][bn ] ) , @xmath109 \\\\=&-(pq)^q k_{q}\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}|t|^{q}c(t)e^{-it\\lambda } dt+\\frac1{p^p}\\frac{a}{(2\\pi)^p}\\sum_{|l|>0}\\frac{1}{|l|^p}. \\end{split}\\end{aligned}\\ ] ] the first term of the expression on the right hand side is proportional to the expression on the right hand side of ( [ psibias2 ] ) .",
    "these terms are small for large values of @xmath73 , while the second term of the expression on the right hand side of the above inequality does not depend on @xmath73 .",
    "even if the value of the second term is small , it would make a difference for large values of @xmath73 .",
    "consequently , @xmath86 can generally be expected to have a smaller bias than @xmath52 .    in summary , even though both @xmath52 and @xmath86 are consistent estimators under the stated conditions , there is a trade - off between @xmath52 and @xmath86 in terms of bias and variance .",
    "there is no clear order between the constants of the mean square errors of the two estimators .    in order to examine the validity of the asymptotic results and the above comparisons for small samples",
    ", we turn to monte carlo simulations , reported in the next section .",
    "in this section , we shall present the simulation study of performance of the spectral density estimators based on regular and poisson sampled data . we consider a continuous time autoregressive ( ar(4 ) ) process having the spectral density @xmath110 where @xmath111 , @xmath112 , @xmath113 , @xmath114 and @xmath115 .",
    "a process @xmath20 having the above spectral density can be written as @xcite @xmath116 where the impulse function @xmath117 is given by @xmath118 and the constants @xmath119 , @xmath120 , are the solution of the following system of linear equations : @xmath121 @xmath122 being the @xmath123th derivative of @xmath117 evaluated at @xmath124 .    in view of the above representation",
    ", we simulate the process @xmath125 given by @xmath126 the process @xmath127 is not a stationary process .",
    "however , as @xmath39 becomes large , the variance of the difference between the processes @xmath125 and @xmath128 becomes small .",
    "we find out the value of @xmath39 , say @xmath129 , such that @xmath130 , and consider the path of the simulated process @xmath125 from @xmath129 onwards .    for estimation , we assume that the underlying power spectral density satisfies condition 1a with @xmath131 .",
    "according we use the hanning kernel @xmath132}(x),\\ ] ] which has characteristic exponent  2 .      here",
    ", we consider the performance of @xmath52 over the frequency range @xmath133 $ ] .",
    "we used the optimal choice of sampling rate developed in section  [ optrate ] to generate regularly spaced samples of the process for sample sizes @xmath134 .",
    "we assume condition 1a with @xmath131 and condition 1b with @xmath135 ( both of which actually hold for the underlying power spectral density ) . for the above choices , the optimal powers of @xmath2 for the sampling rate and the window width are @xmath136 and @xmath137 .",
    "we choose @xmath138 and @xmath139 .",
    "figure 1 shows the average of the estimated power spectral density computed from 500 simulation runs , the empirically observed bias and variance , together with the true power spectral density and the theoretical ( asymptotic ) bias and variance , respectively , for the three samples sizes .    -15pt",
    "+ -15pt   + -15pt     from these figures , it can be observed that as the sample size goes from 100 to 10000 , the empirical values of bias and variance get closer to the asymptotic results .",
    "moreover , the theoretical ( asymptotic ) computations are quite comparable to the empirical values , even for sample size 100 .",
    "we generate poisson sampled data with the average sampling rate @xmath140 for sample sizes @xmath141 , 1000 and 10000 , and compute the estimator @xmath86 on @xmath133 $ ] . here , the optimal power of @xmath2 for the window width is @xmath142 .",
    "we use @xmath143 .",
    "figure 2 shows the empirical bias , variance and mse of the estimators @xmath52 and @xmath86 computed from 500 simulation runs , as a function of the frequency , for sample sizes 100 , 1000 and 10000 .    -15pt",
    "+ -15pt   + -15pt     from these figures , it can be observed that the bias of @xmath84 is generally less than that of @xmath18 while the variance of @xmath84 is larger than that of @xmath18 .",
    "the differences diminish with larger sample size .",
    "these patterns are in accordance with the large sample comparisons made in section  [ poicomp ] .",
    "the mse of @xmath84 is larger than that of the @xmath18 for larger frequencies .",
    "the mse is plotted in log - scale in order to highlight the fact that this quantity , in the case of @xmath84 , levels off to a constant value for larger frequencies , while in the case of @xmath18 , it continues to decline .",
    "this difference in behaviour is in accordance with the variance expressions given in ( [ phivar ] ) and ( [ psivar1 ] ) .",
    "in this paper , we have shown that the smoothed periodogram based on regularly spaced samples of a continuous time stationary stochastic process is consistent , under certain conditions , provided that the sampling rate increases appropriately as the sample size goes to infinity .",
    "we have also shown that , under the conditions used in the proofs , the estimators based on uniformly and non - uniformly spaced samples have about the same rates of convergence .",
    "thus , our results remove a widely perceived theoretical deficiency of a popular spectral estimator based on regular sampling .",
    "it has been a common experience , both theoretically and empirically@xcite , that the smoothed periodogram estimator ( [ unifest ] ) of a non - bandlimited power spectral density has less variance and more bias compared to the corresponding estimator @xmath84 based on poisson sampling .",
    "what the results of section  [ s3 ] show is that , even though the new asymptotic results presented in this paper establish consistency of the smoothed periodogram @xmath18 and the rates of convergence of the estimators @xmath18 and @xmath84 are comparable , the constants for the first order approximations of the bias and variance of the two estimators exhibit the same type of trade off , i.e. , the constant for the bias term is larger in the case of @xmath18 , and the constant for the variance term is larger in the case of @xmath84 .",
    "the new asymptotic calculations provide a theoretical justification of using the smoothed periodogram with common sense , even if the underlying power spectral density is not bandlimited .",
    "this common sense approach consists of appropriate filtering of the continuous time process followed by sampling at a suitably uniform rate .",
    "remark  6 and theorem  4 give guidelines for choosing a suitable filter and an appropriate sampling rate , respectively , which may be useful for practitioners .",
    "the simulation results reported in section  [ s4 ] illustrate how one can choose an appropriate sampling rate for estimating the power spectral density , and obtain results in line with the theoretical results .",
    "even though the underlying spectral density in this example is not band - limited , the estimator @xmath144 ( based on uniformly spaced samples ) is found to have smaller mse than @xmath145 ( based on poisson samples ) for larger frequencies .",
    "the reverse order holds for smaller frequencies .",
    "this shows that there is no clear dominance of one kind of sampling over another .",
    "this finding for finite samples complements our asymptotic results .",
    "our results do not take anything away from the vast literature on spectrum estimation through irregularly sampled data .",
    "these methods may be quite appropriate when one does not have control over the sampling mechanism , when irregular sampling is logistically feasible and methodologically not limited , or when regular sampling have to be avoided for a specific reason ( other than its perceived inconsistency ) .",
    "further , an irregular sampling scheme such as poisson sampling can be used where an estimator based on it is expected , either through theoretical analysis or through simulation studies , to have smaller mse than the corresponding estimator based on regular sampling scheme .",
    "we have shown in section  [ poicomp ] how our theoretical results can be used to compare uniform and poisson sampling schemes .",
    "the results compiled there may be used to make further comparisons under different constraints .",
    "for example , if there is a limit to the maximum average sampling rate and/or the maximum sample size , one may make an optimal choice of the window width for fixed values of these two parameters , and then determine the corresponding mse . in the case of @xmath18 , the optimal choice of the window width ( for given sample size and sampling rate ) is given by ( [ interm ] ) , while the choice in the case of @xmath84 can be derived similarly from ( [ psivar ] ) and ( [ psibias])@xcite . the best rates and constants achievable under the two sampling schemes , under appropriate constraints , may then be used to make a suitable choice of the sampling scheme . however , if there is a hard restriction on the minimum separation between two successive samples ( rather than a restriction on the _ average _ sampling rate ) , then one can not use poisson sampling at all . in such cases ,",
    "irregular sampling may be done according to a renewal process , with the inter - sample distance having a restricted probability distribution .",
    "such a sampling scheme would not satisfy the sufficient condition for alias - free sampling given in theorem 1 of @xcite .",
    "thus , one may have to look further in search of a suitable estimator based on non - uniform sampling under such a restriction .",
    "the proven consistency of the smoothed periodogram opens up the possibility of establishing consistency of _ parametric _ estimators of the power spectral density of a continuous time process based on regularly spaced samples , by allowing the sampling rate together with the sample size to go to infinity .",
    "such asymptotic calculations may potentially be used to justify and/or fine - tune multi - resolution methods of spectrum estimation@xcite .",
    "we denote by @xmath146 a function that bounds the covariance averaging kernel @xmath6 as in condition  2 .",
    "further , we denote @xmath147 by @xmath148 .",
    "* proof of theorem 1 .",
    "*  we shall show that the bias of the estimator @xmath52 given by ( [ unifestn ] ) converges to @xmath124 uniformly over @xmath149 $ ] for any @xmath150 , @xmath151 such that @xmath152 . in order to compute the bias ,",
    "we evaluate @xmath153 $ ] : @xmath154&=e\\left[\\frac{1}{n}\\sum_{j=1}^{n-|v|}x \\left(\\frac{j}{\\rho_n}\\right)x\\left(\\frac{j+|v|}{\\rho_n}\\right)\\right]\\notag\\\\ & = \\left(1-\\frac{|v|}{n}\\right)c\\left(\\frac{v}{\\rho_n}\\right ) .",
    "\\label{expg}\\end{aligned}\\ ] ] therefore , we have @xmath155\\\\ = & \\frac{1}{2\\pi\\rho_n}\\sum_{|v|<n}\\!\\left(1\\!-\\!\\frac{|v|}{n}\\right)c\\left(\\frac{v}{\\rho_n}\\right ) k(b_n v)e^{\\frac{-iv\\lambda}{\\rho_n}}1_{[-\\pi\\rho_n,\\pi\\rho_n]}(\\lambda).\\end{aligned}\\ ] ] consider the simple function @xmath156 , defined over @xmath149\\times(-\\infty,\\infty)$ ] , by @xmath157}(\\lambda)1_{\\left(\\frac{v-1}{\\rho_n},\\frac{v}{\\rho_n}\\right]}(t).\\end{aligned}\\ ] ] observe that @xmath158 $ ] .",
    "+ define the function @xmath159 , over @xmath149\\times(-\\infty,\\infty)$ ] , by @xmath160 observe that @xmath161 which is continuous .    for any @xmath162",
    ", let @xmath163 be the smallest integer greater than or equal to @xmath164 .",
    "note that the interval @xmath165 $ ] contains the point @xmath39 and @xmath166 . for sufficiently large @xmath2",
    ", we have from conditions 3 and 4 , @xmath167}(\\lambda).\\end{aligned}\\ ] ] proving the uniform convergence of @xmath168 $ ] over finite interval @xmath169 $ ] amounts to proving @xmath170 uniformly over @xmath169 $ ] . by virtue of the continuity of the limiting function ,",
    "this in turn is equivalent to proving that @xmath171 converges continuously over this interval @xcite , i.e. , for any sequence @xmath172 , @xmath173 where @xmath174 $ ] .    by continuity of the function @xmath175 with respect to @xmath39 and @xmath73",
    ", we have from conditions 3 and 4 , for any fixed @xmath39 , @xmath176 note that from conditions 1 and 2 , we have the dominance @xmath177}(t)\\le m h_0(t).\\end{aligned}\\ ] ] where @xmath22 is the function described in condition  1 .",
    "thus , by applying the dominated convergence theorem ( dct ) , we have @xmath178    hence , @xmath179\\rightarrow \\phi(\\lambda)$ ] uniformly on @xmath169 $ ] .",
    "@xmath180    * proof of theorem 2 .",
    "*  the estimator @xmath52 , given by ( [ unifestn ] ) , can be written as @xmath181 therefore , @xmath182=i_1 + 2i_2(\\lambda)+i_3(\\lambda),\\ ] ] where    rcl i_1&=&var[_n(0 ) ] , + i_2()&=&cov , + i_3()&=&var .",
    "before we consider the convergence of the above three terms , we simplify the computation of @xmath183 for non negative @xmath41 and @xmath42 .",
    "note from condition  5 that @xmath184\\\\ = & e\\left[\\frac{1}{n^{2}}\\sum_{j=1}^{n - v_{1}}\\sum_{l=1}^{n - v_{2}}x\\!\\!\\left(\\frac{j}{\\rho_n}\\right ) x\\!\\!\\left(\\frac{j\\!+\\!v_{1}}{\\rho_n}\\right)x\\!\\!\\left(\\frac{l}{\\rho_n}\\right ) x\\!\\!\\left(\\frac{l\\!+\\!v_2}{\\rho_n}\\right)\\right]\\\\ = & \\frac{1}{n^{2}}\\sum_{j=1}^{n - v_{1}}\\sum_{l=1}^{n - v_{2 } } \\left[c\\!\\!\\left(\\frac{v_{1}}{\\rho_n}\\!\\right)\\!c\\!\\!\\left(\\frac{v_{2}}{\\rho_n}\\!\\right ) + c\\!\\!\\left(\\!\\frac{j\\!-\\!l\\!+\\!v_{1}}{\\rho_n}\\!\\right)\\!c\\!\\!\\left(\\!\\frac{j\\!-\\!l\\!-\\!v_{2}}{\\rho_n}\\!\\right)\\right.\\\\ & \\left.~ + c\\!\\!\\left(\\!\\frac{j\\!-\\!l}{\\rho_n}\\right)\\!c\\!\\!\\left(\\!\\frac{j\\!-\\!l\\!+\\!v_{1}\\!-\\!v_{2}}{\\rho_n}\\right ) + q\\!\\!\\left(\\frac{v_1}{\\rho_n},\\frac{l\\!-\\!j}{\\rho_n},\\frac{l\\!-\\!j\\!+\\!v_2}{\\rho_n}\\right)\\right]\\\\ = & \\left(1-\\frac{v_{1}}{n}\\right)c\\!\\!\\left(\\frac{v_{1}}{\\rho_n}\\right ) \\left(1-\\frac{v_{2}}{n}\\right)c\\!\\!\\left(\\frac{v_{2}}{\\rho_n}\\right)\\\\ & ~+\\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2})~c\\!\\!\\left(\\frac{u+v_{1}}{\\rho_n}\\right)c\\!\\!\\left(\\frac{u - v_{2}}{\\rho_n}\\right)\\\\ & ~+\\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2})~c\\!\\!\\left(\\frac{u}{\\rho_n}\\right)c\\!\\!\\left(\\frac{u+v_{1}-v_{2}}{\\rho_n}\\right ) \\\\ & ~+\\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2})~q\\!\\!\\left(\\frac{v_1}{\\rho_n},\\frac{-u}{\\rho_n},\\frac{-u+v_2}{\\rho_n}\\right ) , \\end{split}\\ ] ] where @xmath185 is a function with values between 0 and 1 defined as follows @xmath186 therefore , by using ( [ expg ] ) and ( [ exp_cros ] ) , we have @xmath187-e[\\widehat{\\gamma}_n(v_{1})]e[\\widehat{\\gamma}_n(v_{2})]\\\\ = & \\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2 } ) c\\left(\\frac{u+v_{1}}{\\rho_n}\\right)c\\left(\\frac{u - v_{2}}{\\rho_n}\\right)\\\\ & + \\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2})c\\left(\\frac{u}{\\rho_n}\\right)c\\left(\\frac{u+v_{1}-v_{2}}{\\rho_n}\\right ) \\\\&+ \\frac{1}{n}\\sum_{|u|<n}u_{n}(u , v_{1},v_{2})q\\left(\\frac{v_1}{\\rho_n},\\frac{-u}{\\rho_n},\\frac{-u+v_2}{\\rho_n}\\right ) . \\end{split}\\ ] ] we now use this simplified form of @xmath183 to establish the convergence of the three terms , @xmath188 , @xmath189 and @xmath190 .",
    "using ( [ desofcov ] ) and condition 5 , @xmath188 is given as @xmath191 \\\\",
    "\\le&\\frac{2c(0)}{(2\\pi)^{2}n\\rho_n}\\sum_{|u|<n}\\!\\left|c\\!\\!\\left(\\frac{u}{\\rho_n}\\!\\right)\\!\\right|\\frac{1}{\\rho_n } + \\frac{g_1(0)g_2(0)}{(2\\pi)^{2}n\\rho_n}\\!\\sum_{|u|<n}\\!\\!g_3\\!\\!\\left(\\frac{u}{\\rho_n}\\!\\right)\\!\\!\\frac{1}{\\rho_n}.\\end{aligned}\\ ] ] as in theorem 1 , we can view @xmath192 as the integral of the function @xmath193 defined by @xmath194}(t).\\ ] ] since @xmath195 , and @xmath196 holds from condition  1 , we get @xmath197 by applying the dct as in theorem  1 , under condition  4 .",
    "a similar argument , together with conditions 4 and 5 , ensures that @xmath198 .",
    "both the limiting integrals are finite .",
    "so @xmath199 as @xmath200 .    using ( [ desofcov ] ) and condition 5 , the term @xmath189 is given as @xmath201 the last expression does not depend on @xmath73 .",
    "an argument as in the case of @xmath188 will show that @xmath202 , under conditions  2 and  3 .",
    "the convergence of the other sums have already been discussed in connection with the term  @xmath188 .",
    "hence , @xmath203 as @xmath200 uniformly for all @xmath73",
    ".    now we will consider @xmath190 . using ( [ desofcov ] ) , this term can be written as @xmath204k(b_n v_1)k(b_n v_2)\\\\&\\times\\cos\\left(\\frac{\\lambda v_1}{\\rho_n}\\right)\\cos\\left(\\frac{\\lambda v_2}{\\rho_n}\\right)\\\\=&i_{31}(\\lambda)+i_{32}(\\lambda)+i_{33}(\\lambda ) , \\end{split}\\ ] ] where @xmath205 @xmath206 and @xmath207    from conditions 2 and 5 , @xmath208 by using a similar argument as in the case of @xmath188 , we have @xmath209 dv_2.\\end{aligned}\\ ] ] hence , @xmath210 as @xmath211 uniformly for all @xmath73 .",
    "+ consider the term @xmath212 , let @xmath213 .",
    "@xmath214 from condition 2 , observe that @xmath215 consider the simple function @xmath216 , defined over @xmath217 by @xmath218}(x)1_{(\\frac{j-1}{\\rho_n},\\frac{j}{\\rho_n}]}(t)1_{(\\frac{l-1}{\\rho_n},\\frac{l}{\\rho_n}]}(t^{'}\\!),\\end{aligned}\\ ] ] so that @xmath219 since @xmath220 , we have , for any fixed @xmath221 and for large enough @xmath2 , the inequality @xmath222 , i.e. , @xmath223 . therefore , for large @xmath2 , the unique integer @xmath123 for which @xmath224}(t)$ ] is non - zero is smaller than the unique integer @xmath225 for which @xmath226}(x)$ ] is non - zero .",
    "however , the ranges of summations in the definition of @xmath227 do not permit the order @xmath228 .",
    "therefore , @xmath229 . from condition 1 and 2",
    ", we have the dominance @xmath230 by applying the dct , we have @xmath231 since the function @xmath227 does not depend on @xmath73 , we have @xmath232 uniformly for all @xmath73 .    in view of the convergence of the terms @xmath188 , @xmath189 , @xmath233 and @xmath212 , we have @xmath234=0\\ ] ] uniformly for all @xmath73 , and so we need to prove the convergence of @xmath235 only .    now consider @xmath236 and let @xmath237 .",
    "@xmath238    for @xmath51 , it follows from ( [ restvar ] ) and lemma  1 below that @xmath239=2[\\phi(0)]^{2 } \\int_{-\\infty}^{\\infty}k^{2}(x)dx\\ ] ]    for @xmath240 , we will further decompose @xmath236 as follows . by applying the formula @xmath241 and @xmath242",
    ", we have @xmath243 where @xmath244 @xmath245 and @xmath246    it follows from equation ( [ restvar ] ) , lemma 2 and lemma 3 below that @xmath247= & \\lim_{n\\rightarrow\\infty}nb_ni_{321}(\\lambda)\\\\ = & [ \\phi(\\lambda)]^{2 } \\int_{-\\infty}^{\\infty}k^{2}(x)dx , \\end{split}\\ ] ] and the convergence is uniform over any closed interval that does not include the frequency 0 .",
    "this completes the proof .",
    "+ @xmath180    @xmath248dt~dx .",
    "\\end{split}\\ ] ]    * proof of lemma 1 . *  consider the simple function @xmath156 , defined over @xmath249 by @xmath250}(x)1_{(\\frac{j-1}{\\rho_n},\\frac{j}{\\rho_n}]}(t)1_{(\\frac{l-1}{\\rho_n},\\frac{l}{\\rho_n}]}(t^{'}\\!).\\end{aligned}\\ ] ] observe from ( [ i32des ] ) that @xmath251 define @xmath252 , @xmath253 and @xmath254 as the smallest integers greater than or equal to @xmath255 , @xmath164 and @xmath256 , respectively .",
    "thus , @xmath257\\times\\left(\\frac{j_{n-1}(t)}{\\rho_n},\\frac{j_n(t)}{\\rho_n}\\right]\\times \\left(\\frac{l_{n-1}(t')}{\\rho_n},\\frac{l_n(t')}{\\rho_n}\\right]$ ] and @xmath258 as @xmath28 .",
    "since @xmath11 and @xmath259 as @xmath200 , we have , for any point @xmath260 and large enough @xmath2 , the inequalities @xmath261 , i.e. , @xmath262 .",
    "thus , for sufficiently large @xmath2 , we have @xmath263 also , for large @xmath2 , we have @xmath264 , and so @xmath265 is positive and it converges to  1 .",
    "therefore , by virtue of conditions  1 and  2 , we have @xmath266 again , from conditions  1 and  2 , we have the dominance @xmath267 by applying the dct , we have @xmath268\\!dtdx . \\end{split}\\ ] ] @xmath180    the function @xmath269 converges as follows : @xmath270\\!dt\\right]\\!dx .",
    "\\end{split}\\ ] ] the convergence is uniform on @xmath149 $ ] for arbitrary @xmath150 and @xmath151 such that @xmath152 and @xmath271 .",
    "* proof of lemma 2 .",
    "*  consider the simple function @xmath156 , defined over @xmath149\\times(0,\\infty)\\times(-\\infty,\\infty)\\times(-\\infty,\\infty)$ ] by @xmath272}(x)1_{(\\frac{j-1}{\\rho_n},\\frac{j}{\\rho_n}]}(t)1_{(\\frac{l-1}{\\rho_n},\\frac{l}{\\rho_n}]}(t^{'}\\!),\\end{aligned}\\ ] ] so that , from ( [ a321 ] ) , @xmath273 a similar argument as in the proof of lemma 1 will show that for @xmath260 and sufficiently large @xmath2 , @xmath274 where @xmath252 , @xmath253 and @xmath254 are the smallest integers greater than or equal to @xmath255 , @xmath164 and @xmath256 , respectively , and that the function @xmath275 converges to the function @xmath159 , defined over @xmath249 by @xmath276    observe also that @xmath277 is a continuous function in @xmath73 . as in the proof of theorem  1 , we prove the convergence of @xmath278uniformly on @xmath149 $ ] , by showing that for any sequence @xmath172 , @xmath279 for @xmath280 $ ] .",
    "the latter convergence follows , through condition  1 and  2 and the dct , from the dominance @xmath281 and the convergence of the integrand , which holds because of the continuity of the kernel , the cosine and the covariance function .",
    "hence , @xmath282 converges as stated uniformly on @xmath149 $ ] .",
    "+ @xmath180    the functions @xmath283 and @xmath284 converge to @xmath124 uniformly on @xmath149 $ ] for arbitrary @xmath150 and @xmath151 such that @xmath152 and @xmath271",
    ".    * proof of lemma 3 .",
    "*  consider the simple function @xmath156 , defined over @xmath149\\times(0,\\infty)\\times(-\\infty,\\infty)\\times(-\\infty,\\infty)$ ] by @xmath285}(x)\\times1_{(\\frac{j-1}{\\rho_n},\\frac{j}{\\rho_n}]}(t)1_{(\\frac{l-1}{\\rho_n},\\frac{l}{\\rho_n}]}(t^{'}),\\end{aligned}\\ ] ] so that , from ( [ a322 ] ) , @xmath286 a similar argument as in the proof of lemma 1 will show that for @xmath260 and sufficiently large @xmath2 , @xmath287 where @xmath252 , @xmath253 and @xmath254 are the smallest integers greater than or equal to @xmath255 , @xmath164 and @xmath256 , respectively .    for obtaining the uniform convergence of @xmath288 ,",
    "consider @xmath289}\\left|\\int_{0}^{\\infty}\\!\\!\\int_{-\\infty}^{\\infty}\\!\\!\\int_{-\\infty}^{\\infty}\\!\\!s_n(\\lambda , x , t , t^{'})dxdtdt^{'}\\right|\\notag\\\\ \\!\\le\\!&\\sup_{\\lambda \\in [ \\lambda_l,\\lambda_u]}\\int_{0}^{\\infty}\\!\\!\\int_{-\\infty}^{\\infty}\\!\\!\\int_{-\\infty}^{\\infty}\\!\\!|s_n(\\lambda , x , t , t^{'}\\!)-g_n(\\lambda , x , t , t^{'}\\!)|dxdtdt^{'}\\notag\\\\",
    "~+\\!&\\sup_{\\lambda \\in [ \\lambda_l,\\lambda_u]}\\left|\\int_{0}^{\\infty}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}g_n(\\lambda , x , t , t^{'})dxdtdt^{'}\\right| , \\label{2step}\\end{aligned}\\ ] ] where the function @xmath290 is defined over @xmath149\\times(0,\\infty)\\times(-\\infty,\\infty)\\times(-\\infty,\\infty)$ ] by @xmath291 we shall prove the convergence of @xmath283 given in ( [ i322 ] ) by proving the convergence of the two integrals on the right hand side of ( [ 2step ] ) .    in order to prove the first convergence , we follow the route taken in theorem  1 , i.e. , we show that for any sequence @xmath292 @xmath293 for @xmath294 $ ] . the above integral can be written as @xmath295 where the function @xmath296 is defined over @xmath149\\times(0,\\infty)\\times(-\\infty,\\infty)\\times(-\\infty,\\infty)$ ] by @xmath297 now observe that @xmath298 where @xmath299 since @xmath300 as @xmath28 , we have @xmath301 since from condition 1 and 2 , we have the dominance @xmath302 by applying dct , we have @xmath303    turning to the second term on the right hand side of ( [ 2part ] ) , observe that for any fixed @xmath304 , @xmath305 . by applying the mean value theorem to the cosine function in the interval @xmath306 $ ] , we have @xmath307 for some @xmath308 $ ]",
    ". therefore @xmath309 thus , @xmath310 so @xmath311 from condition 1 and 2 , we have the dominance @xmath312 which leads us , through another use of the dct , the convergence of the second integral of ( [ 2part ] ) .",
    "this establishes that the first term on the right hand side of ( [ 2step ] ) converges to  0 .",
    "we only have to deal with the second term .",
    "let @xmath313 in order to establish the uniform convergence of @xmath193 over @xmath149 $ ] , it is enough to show that @xmath314 for any sequence @xmath315 , where @xmath294 $ ] . by using the reimann - lebesgue lemma",
    ", we have @xmath314 .",
    "thus , the second term on the right hand side of ( [ 2step ] ) also converges to  0 .",
    "hence , @xmath316 converges to  0 uniformly on @xmath149 $ ] as @xmath200 .",
    "convergence of @xmath317 to 0 can be established in a similar manner.@xmath318    * proof of theorem 3 . *",
    "condition  1 ensures absolute summability of the covariance sequence @xmath319 of the regularly sampled process @xmath320 , for fixed @xmath321 .",
    "the corresponding spectral density @xmath322 is defined as @xmath323 the function @xmath322 is periodic with period @xmath324 and is related to the function @xmath0 as follows : @xmath325.\\ ] ] in particular , for @xmath326 $ ] , @xmath327    for sufficiently large @xmath2 , @xmath328 lies outside any finite interval @xmath149 $ ] , and the bias of the estimator @xmath52 given by ( [ unifestn ] ) on @xmath149 $ ] can be decomposed as follows .",
    "@xmath329-\\phi(\\lambda)\\\\= & \\frac{1}{2\\pi\\rho_n}\\sum_{|v|<n}\\left(1-\\frac{|v|}{n}\\right)c\\left(\\frac{v}{\\rho_n}\\right)k(b_n v)e^{-\\frac{iv\\lambda}{\\rho_n}}-\\phi(\\lambda)\\\\=&\\frac{1}{2\\pi\\rho_n}\\sum_{|v|<n}\\left(1-\\frac{|v|}{n}\\right)c\\left(\\frac{v}{\\rho_n}\\right)k(b_n v)e^{-\\frac{iv\\lambda}{\\rho_n}}-\\xi_n(\\lambda)\\\\&+\\sum_{l=1}^{\\infty}\\phi(\\lambda+2\\pi",
    "l \\rho_n)+\\sum_{l=-\\infty}^{-1}\\phi(\\lambda+2\\pi l \\rho_n)\\\\=&b_1(\\lambda)+b_2(\\lambda)+b_3(\\lambda)+b_4(\\lambda)+b_5(\\lambda ) , \\end{split}\\ ] ] where    rcl b_1()&=&-_|v|<n(1-k(b_n v))c()e^- , + b_2()&=&-_|v|<nc()k(b_n v)e^- , + b_3()&=&-_|v|nc()e^- , + b_4()&=&_l=1^(+2l _ n ) , + b_5()&=&_l=-^-1(+2l _ n ) .",
    "we will consider each @xmath330 , @xmath331 , separately .",
    "@xmath332 consider the simple function @xmath216 defined over @xmath149\\times(-\\infty,\\infty)$ ] as @xmath333}(t).\\end{aligned}\\ ] ] observe that @xmath334 .",
    "for any @xmath335 , we define @xmath163 as the smallest integer greater than or equal to @xmath336 .",
    "it follows that @xmath337 , and for sufficiently large @xmath2 and any @xmath335 , we can write @xmath338 from conditions  4 and  2a , we have @xmath339 also , condition 1a implies @xmath340 by applying the dct , we have @xmath341 thus , @xmath342 is @xmath343 .",
    "the fact that this convergence is uniform over the interval @xmath149 $ ] can be established by choosing any sequence @xmath344 in this interval that converges to @xmath73 , and showing that @xmath345 converges to the right hand side of ( [ 2arelax ] ) .",
    "the term @xmath346 can be written as @xmath347 where @xmath156 is defined over @xmath149\\times(-\\infty,\\infty)$ ] as @xmath348}(t).\\ ] ] as in the case of @xmath342 , it can be shown that @xmath349 from condition 1a , it follows that @xmath350 . now again by applying the dct , we have @xmath351 thus , @xmath346 is @xmath352 .",
    "the uniform convergence can be argued similarly as in the case of @xmath342 .",
    "the term @xmath353 satisfies @xmath354.\\end{aligned}\\ ] ] observe that for each fixed @xmath2 , we have from condition 1a , @xmath355 so @xmath356 hence @xmath357 is bounded by an @xmath358 term , which converges to zero faster than @xmath346 .    as for the term @xmath359",
    ", we have from condition 1b and dct @xmath360 hence @xmath361 .",
    "similarly it can be proved that @xmath362    the theorem is proved by combining the five terms .",
    "@xmath180    * proof of theorem 4 . *",
    "it follows from theorems  2 and  3 that the mse of the estimator @xmath144 can be written as @xmath363&=&[e\\{\\widehat\\phi_n(\\lambda)-\\phi(\\lambda)\\}]^2 + var[\\widehat{\\phi}_n(\\lambda)]\\nonumber\\\\ & = & o\\left((\\rho_nb_n)^{2q}\\right)+o\\left({\\rho_n^2\\over n^2}\\right)+o\\left({1\\over\\rho_n^{2p}}\\right)\\nonumber\\\\ & & \\qquad+o\\left({1\\over nb_n}\\right ) .",
    "\\label{mserate}\\end{aligned}\\ ] ] let us first fix @xmath2 and @xmath15 and minimize the mse with respect to @xmath25 .",
    "the squared bias is an increasing functions of @xmath25 , while the variance is a decreasing function of @xmath25 .",
    "therefore , the maximum possible value is minimized ( i.e. , the fastest rate of convergence is achieved ) when @xmath364 , i.e. , when @xmath365 by substituting this value in the expression for the mse , and making use of the fact that @xmath366 and @xmath367 , we have @xmath77=o\\left(\\left({\\rho_n\\over n}\\right)^{2q\\over 2q+1}\\right)+o\\left({1\\over\\rho_n^{2p}}\\right).\\ ] ] the first term on the right hand side is an increasing function of @xmath15 , while the second term is a decreasing function of @xmath15 .",
    "therefore , the maximum of the two terms is minimized when @xmath368 , i.e. , when @xmath15 is chosen as in ( [ rhon ] ) . the optimal rate for @xmath25 , as given in ( [ bn ] ) ,",
    "is obtained by substituting the expression for @xmath15 in ( [ interm ] ) .",
    "further substitution of these two optimal rates in ( [ mserate ] ) gives ( [ msereg]).@xmath180",
    "the authors gratefully acknowledge suggestions and technical help from professors b.v . rao and arup bose of the indian statistical institute .",
    "suggestions from two referees have been useful in improving the clarity of the presentation .",
    "e.  masry ,  poisson sampling and spectral estimation of continuous - time processes \" , _ ieee trans .",
    "inf . theory _ ,",
    "it-24 , no .",
    "2 , pp . 173183 , mar 1978 .",
    "d.  p.  mitchel ,  generating antialiased images at low sampling density \" , _ comp . graphics _ , vol .",
    "65 72 , july 1987 .    m.  lehr and s.  k.  lii ,  wavelet spectral density estimation under irregular sampling \" , in _ conference record of the thirty - first asilomar conference on signals , systems and computers _ , vol .",
    "2 , pp . 11171121 , nov 1997 .            m.  j.  tummers and d.  m.  passchier ,  estimation of the spectral density function from randomly sampled lda data \" , in _",
    "10th international symposium on applications of laser techniques to fluid mechanics _",
    ", july 2000 .",
    "t.  p.  bronez , ",
    "spectral estimation of irregularly sampled multidimensional processes by generalized prolate spheroidal sequences \" , _ ieee trans .",
    "acoustics speech signal processing _ , vol .",
    "18621873 , dec 1988 .",
    "m.  i.  moore , a.  w.  visser and t.  l.  g.  shirtcliffe ,  experiances with the brillinger spectral estimator applied to simulated irregularly observed process \" , _ time series analysis _ , vol .",
    "8 , issue 4 , pp . 433442 , 2008 .",
    "e.  masry , ",
    "spectral estimation of continuous - time processes : performance comparision between periodic and poisson sampling schemes \" , _ ieee trans",
    ". automatic control _",
    "ac-23 , no .",
    "4 , pp . 679685 , aug 1978 .",
    "radhendushka srivastava received the b.sc .",
    "degree and the m.sc .",
    "degree in statistics from the university of lucknow in the years 2003 and 2005 , respectively .",
    "he is currently a senior research fellow in the indian statistical institute , and is working towards the ph.d .",
    "degree in statistics .",
    "his research interests include time series analysis , stochastic processes and applications of statistical methods to signal processing .",
    "debasis sengupta received b.tech .",
    "degree in electronics and electrical communications engineering from the indian institute of technology , kharagpur , in 1984 and master s degrees in electrical engineering and in statistics from the university of rhode island , kingston in the year 1986 and the university of california , santa barbara , in the year 1988 , respectively .",
    "he received ph.d .",
    "degrees in electrical and computer engineering and in statistics from the university of california , santa barbara , in the years 1989 and 1990 , respectively .",
    "subsequently he has been with the applied statistics unit of the indian statistical institute , kolkata , where he has been a professor since 1997 .",
    "his research interests include regression , multivariate analysis , time series analysis and statistical signal processing ."
  ],
  "abstract_text": [
    "<S> in the matter of selection of sample time points for the estimation of the power spectral density of a continuous time stationary stochastic process , irregular sampling schemes such as poisson sampling are often preferred over regular ( uniform ) sampling . </S>",
    "<S> a major reason for this preference is the well - known problem of inconsistency of estimators based on regular sampling , when the underlying power spectral density is not bandlimited . </S>",
    "<S> it is argued in this paper that , in consideration of a large sample property like consistency , it is natural to allow the sampling rate to go to infinity as the sample size goes to infinity . through appropriate asymptotic calculations under this scenario </S>",
    "<S> , it is shown that the smoothed periodogram based on regularly spaced data is a consistent estimator of the spectral density , even when the latter is not band - limited . </S>",
    "<S> it transpires that , under similar assumptions , the estimators based on uniformly sampled and poisson - sampled data have about the same rate of convergence . apart from providing this reassuring message , the paper also gives a guideline for practitioners regarding appropriate choice of the sampling rate . </S>",
    "<S> theoretical calculations for large samples and monte - carlo simulations for small samples indicate that the smoothed periodogram based on uniformly sampled data have less variance and more bias than its counterpart based on poisson sampled data .    spectrum estimation , periodogram , regular sampling , poisson sampling , consistency , rates of convergence . </S>"
  ]
}