{
  "article_text": [
    "in this note we propose a vectorized implementation of the non - parametric bootstrap for statistics based on sample moments .",
    "our approach is based on the multinomial sampling formulation of the non - parametric bootstrap .",
    "this formulation is described in the next section , but , in essence , follows from the fact that the bootstrap distribution of any sample moment statistic ( generated by sampling @xmath0 data points with replacement from a population of @xmath0 values , and evaluating the statistic on the re - sampled version of the observed data ) can also be generated by weighting the observed data according to multinomial category counts sampled from a multinomial distribution defined over @xmath0 categories ( i.e. , data points ) and assigning probability @xmath1 to each one of them .",
    "the practical advantage of this multinomial sampling formulation is that , once we generate a matrix of bootstrap weights , we can compute the entire vector of bootstrap replications using a few matrix multiplication operations .",
    "the usual re - sampling formulation , on the other hand , is not amenable to such vectorization of computations , since for each bootstrap replication one needs to generate a re - sampled version of the data .",
    "vectorization is particularly important for matrix - oriented programming languages such as r@xcite and matlab@xcite , where matrix / vector computations tend to be faster than scalar operations implemented in a loop .",
    "this note is organized as follows .",
    "section 2 : ( i ) presents notation and background on the standard data re - sampling approach for the non - parametric bootstrap ; ( ii ) describes the multinomial sampling formulation of the bootstrap ; and ( iii ) explains how to vectorize the bootstrap calculations .",
    "section 3 reports a comparison of computation times ( in r ) required by the vectorized and standard approaches , when bootstrapping pearson s sample correlation coefficient in real and simulated data sets .",
    "finally , section 4 presents some final remarks , and point out that the bayesian bootstrap computations can also be easily vectorized .",
    "let @xmath2 represent a random variable distributed according to an unknown probability distribution @xmath3 , and let @xmath4 be an observed random sample from @xmath3 .",
    "the goal of the bootstrap is to estimate a parameter of interest , @xmath5 , based on a statistic @xmath6 .",
    "let @xmath7 represent the empirical distribution of the observed data , @xmath8 , assigning probability @xmath1 to each observed value @xmath9 , @xmath10 .",
    "a bootstrap sample , @xmath11 , corresponds to a random sample of size @xmath0 draw from @xmath7 .",
    "operationally , sampling from @xmath7 is equivalent to sampling @xmath0 data points with replacement from the population of @xmath0 objects @xmath12 .",
    "the star notation indicates that @xmath13 is not the actual data set @xmath8 but rather a re - sampled version of @xmath8 .",
    "the sampling distribution of estimator @xmath14 is then estimated from @xmath15 bootstrap replications of @xmath16 .",
    "now , consider the estimation of the first moment of the unknown probability distribution @xmath3 , @xmath17 on the basis of the observed data @xmath8 .",
    "if no further information ( other than the observed sample @xmath8 ) is available about @xmath3 , then it follows that the best estimator of @xmath5 is the plug - in estimate ( see page 36 of @xcite ) , @xmath18 and the bootstrap distribution of @xmath14 is generated from @xmath15 bootstrap replications of @xmath19 .",
    "algorithm [ alg : usualboot ] summarizes the approach .",
    "_ for @xmath20 : _    * draw a bootstrap sample @xmath11 from the empirical distribution of the observed data , that is , sample @xmath0 data points with replacement from the population of @xmath0 objects @xmath4 .",
    "* compute the bootstrap replication @xmath21 .",
    "alternatively , let @xmath22 represent the number of times that data point @xmath9 appears in the bootstrap sample @xmath13 , and @xmath23 .",
    "then , the category counts , @xmath24 , of the bootstrap sample @xmath13 are distributed according to the multinomial distribution , @xmath25 where the vector @xmath26 has length @xmath0 .",
    "now , since @xmath27 it follows that the bootstrap replication of the first sample moment of the observed data can we re - expressed , in terms of the bootstrap weights @xmath28 as , @xmath29 so that we can generate bootstrap replicates using algorithm [ alg : multiboot ] .",
    "_ for @xmath20 : _    * draw a bootstrap count vector @xmath30 . *",
    "compute the bootstrap weights @xmath31 . *",
    "compute the bootstrap replication @xmath32 .",
    "the main advantage of this multinomial sampling formulation of the non - parametric bootstrap is that it allows the vectorization of the computation .",
    "explicitly , algorithm [ alg : multiboot ] can be vectorized as follows :    1 .",
    "draw @xmath15 bootstrap count vectors , @xmath33 , from ( [ eq : boot.mult ] ) , using a single call of a multinomial random vector generator ( e.g. , ` rmultinom ` in r ) .",
    "2 .   divide the sampled bootstrap count vectors by @xmath0 in order to obtain a @xmath34 bootstrap weights matrix , @xmath35 .",
    "3 .   generate the entire vector of bootstrap replications , @xmath36 in a single computation .",
    "it is clear from equation ( [ eq : main.connection ] ) that this multinomial sampling formulation is available for statistics based on any arbitrary sample moment ( that is , statistics defined as functions of arbitrary sample moments ) .",
    "for instance , the sample correlation between data vectors @xmath37 and @xmath38 , is a function of the sample moments ,    @xmath39    and the bootstrap replication , @xmath40 \\ , \\big[n \\sum_{i } y_i^{\\ast 2 } - ( \\sum_{i } y_i^\\ast)^2\\big]}}~,\\ ] ] can be re - expressed in terms of bootstrap weights as , @xmath41 \\ , \\big[\\sum_i w_i^\\ast \\ , y_i^2 - ( \\sum_{i } w_i^\\ast \\ , y_i)^2\\big]}}~,\\ ] ] and in vectorized form as , @xmath42 \\bullet \\big[({\\boldsymbol{y}}^2)^t { \\boldsymbol{w}}^\\ast - ( { \\boldsymbol{y}}^t { \\boldsymbol{w}}^\\ast)^2 \\big]}}~ , \\label{eq : vec.cor}\\ ] ] where the @xmath43 operator represents the hadamard product of two vectors ( that is , the element - wise product of the vectors entries ) , and the square and square root operations in the denominator of ( [ eq : vec.cor ] ) are also performed entry - wise .",
    "in this section , we illustrate the gain in computational efficiency achieved by the vectorized multinomial sampling bootstrap , relative to two versions the standard data re - sampling approach : ( i ) a strait forward version based on a ` for ` loop ; and ( ii ) a more sophisticated version , implemented in the ` bootstrap ` r package@xcite , where the ` for ` loop is replaced by a call to the ` apply ` r function . in the following ,",
    "we refer to these two versions as  loop \" and  apply \" , respectively .",
    "we bootstrapped pearson s sample correlation coefficient using the american law school data ( page 21 of @xcite ) provided in the ` law82 ` data object of the ` bootstrap ` r package .",
    "the data is composed of two measurements ( class mean score on a national law test , lsat , and class mean undergraduate grade point average , gpa ) on the entering class of 1973 for @xmath44 american law schools . figure [ fig : example1 ] presents the results .",
    "the top left panel of figure [ fig : example1 ] shows the time ( in seconds ) required to generate @xmath15 bootstrap replications of @xmath45 , for @xmath15 varying from 1,000 to 1,000,000 .",
    "the red , brown , and blue lines show , respectively , the computation time required by the  apply \" ,  loop \" , and the vectorized multinomial sampling approaches .",
    "the center and bottom left panels show the computation time ratio of the data re - sampling approach versus the vectorized approach as a function of @xmath15 .",
    "the plots clearly show that the vectorized bootstrap was considerably faster than the data re - sampling implementations for all @xmath15 tested .",
    "the right panels show the @xmath46 distributions for the three bootstrap approaches based on @xmath47 .",
    "figure [ fig : example2 ] presents analogous comparisons , but now focusing on a subset of @xmath48 samples from the american law school data ( page 19 of @xcite ) , provided in the ` law ` data object of the ` bootstrap ` r package .",
    "this time , the vectorized implementation was remarkably faster than the data re - sampling versions .",
    "the center and bottom left panels of figure [ fig : example2 ] show that the vectorized implementation was roughly 50 times faster than the re - sampling versions , whereas in the previous example it was about 8 times faster ( center and bottom left panels of figure [ fig : example1 ] ) .",
    "the performance difference observed in these two examples suggests that the gain in speed achieved by the vectorized implementation decreases as a function of the sample size . in order to confirm this observation , we used simulated data to compare the bootstrap implementations across a grid of 10 distinct sample sizes ( varying from 15 to 915 ) for @xmath15 equal to 10,000 , 100,000 , and 1,000,000 .",
    "figure [ fig : example3 ] reports the results .",
    "the left panels of figure [ fig : example3 ] show computation times as a function of increasing sample sizes . in all cases tested the vectorized implementation ( blue line ) outperformed the  apply \" version ( red line ) , whereas the  loop \" version ( brown line ) outperformed the vectorized implementation for large sample sizes ( but was considerably slower for small and moderate sample sizes ) .",
    "the central and right panels show the computation time ratios ( in log scale ) comparing , respectively , the  loop \" vs vectorized and the  apply \" vs vectorized implementations .",
    "the horizontal line is set at zero and represents the threshold below which the data re - sampling approach outperforms the vectorized implementation .",
    "note that log time ratios equal to 4 , 3 , 2 , 1 , and 0.5 , correspond to speed gains of 54.60 , 20.09 , 7.39 , 2.72 , and 1.65 , respectively .",
    "all the timings in this section were measured on an intel core i7 - 3610qm ( 2.3 ghz ) , 24 gb ram , windows 7 enterprize ( 64-bit ) platform .",
    "in this note we showed how the multinomial sampling formulation of the non - parametric bootstrap can be easily implemented in vectorized form .",
    "we illustrate the gain in computational speed ( in the r programming language ) using real and simulated data sets .",
    "our examples provide several interesting insights .",
    "first , the re - sampling implementation based on the ` for ` loop was generally faster than the implementation provided by the ` bootstrap ` r package , which employs the ` apply ` in place of the ` for ` loop ( compare the red and brown curves on the top left panel of figures [ fig : example1 ] and [ fig : example2 ] , and on the left panels of figure [ fig : example3 ] ) .",
    "this result illustrates the fact that ` apply ` is not always faster than a ` for ` loop ( see @xcite for further discussion and examples ) .",
    "second , the vectorized implementation outperformed the data re - sampling implementation provided in the ` bootstrap ` r package in all cases tested ( left panels in figures [ fig : example1 ] and [ fig : example2 ] , and right panels in figure [ fig : example3 ] ) .",
    "third , the gain in speed achieved by the vectorized implementation decreases as a function of the sample size ( figure [ fig : example3 ] ) .",
    "this decrease is likely due to the increase in memory requirements for generating and performing operations in the larger bootstrap weight matrices associated with the larger sample sizes .",
    "we point out , however , that even though optimized blas ( basic linear algebra subprograms ) libraries could potentially increase the execution speed of our vectorized operations in large matrices / vectors @xcite , our examples still show remarkable / considerable gains for small / moderate sample sizes even without using any optimized blas library ( as illustrated by figures [ fig : example2 ] and [ fig : example1 ] ) .    for the sake of clarity , the exposition in section 2 focused on statistics based on sample moments of the observed data , @xmath8 .",
    "we point out , however , that the multinomial sampling formulation of the bootstrap is available for any statistic satisfying the more general relation , @xmath49 where the @xmath50th sample moment represents the particular case , @xmath51 .",
    "clearly , the left hand side of equation ( [ eq : general ] ) still represents a bootstrap replication of the first sample moment of the transformed variable @xmath52 .",
    "the multinomial sampling formulation of the non - parametric bootstrap is not new .",
    "it is actually a key piece in the demonstration of the connection between the non - parametric bootstrap and bayesian inference , described in @xcite and in section 8.4 of @xcite , where the non - parametric bootstrap is shown to closely approximate the posterior distribution of the quantity of interest generated by the bayesian bootstrap @xcite .",
    "this close connection , also implies that the bayesian bootstrap can be easily implemented in vectorized form . as a matter of fact , instead of generating the bootstrap weights from bootstrap count vectors sampled from a multinomial distribution , the bayesian bootstrap samples the weights directly from a @xmath53 distribution .",
    "we point out , however , that , to the best of our knowlege , the multinomial sampling formulation has not been explored before for vectorizing bootstrap computations .",
    "s original , from statlib and by rob tibshirani .",
    "r port by friedrich leisch ( 2014 ) bootstrap : functions for the book  an introduction to the bootstrap \" .",
    "r package version 2014.4 ."
  ],
  "abstract_text": [
    "<S> in this note we propose a vectorized implementation of the non - parametric bootstrap for statistics based on sample moments . </S>",
    "<S> basically , we adopt the multinomial sampling formulation of the non - parametric bootstrap , and compute bootstrap replications of sample moment statistics by simply weighting the observed data according to multinomial counts , instead of evaluating the statistic on a re - sampled version of the observed data . using this formulation </S>",
    "<S> we can generate a matrix of bootstrap weights and compute the entire vector of bootstrap replications with a few matrix multiplications . </S>",
    "<S> vectorization is particularly important for matrix - oriented programming languages such as r , where matrix / vector calculations tend to be faster than scalar operations implemented in a loop . </S>",
    "<S> we illustrate the gain in computational speed achieved by the vectorized implementation in real and simulated data sets , when bootstrapping pearson s sample correlation coefficient . </S>"
  ]
}