{
  "article_text": [
    "sequential importance sampling is a widely - used approach for randomly sampling from complex distributions .",
    "it has been applied in a variety of fields , such as protein folding @xcite , population genetics @xcite , and signal processing @xcite .",
    "binary contingency tables is an application where the virtues of sequential importance sampling have been especially highlighted ; see chen et al .",
    "this is the subject of this note .",
    "given a set of non - negative row sums @xmath1 and column sums @xmath2 , let @xmath3 denote the set of @xmath4 0/1 tables with row sums @xmath5 and column sums @xmath6 .",
    "our focus is on algorithms for sampling ( almost ) uniformly at random from @xmath7 , or estimating @xmath8 .",
    "sequential importance sampling ( sis ) has several purported advantages over the more classical markov chain monte carlo ( mcmc ) method , such as :    speed : : :    chen et al .",
    "@xcite claim that sis is faster than mcmc algorithms .",
    "however , we present a simple example where sis requires exponential    ( in @xmath9 ) time . in contrast , a mcmc algorithm was    presented in @xcite which is guaranteed to require at most    time polynomial in @xmath9 for every input .",
    "convergence diagnostic : : :    one of the difficulties in mcmc algorithms is determining when the    markov chain of interest has reached the stationary distribution , in    the absence of analytical bounds on the mixing time .",
    "sis seemingly    avoids such complications since its output is guaranteed to be an    unbiased estimator of @xmath8 .",
    "unfortunately , it is    unclear how many estimates from sis are needed before we have a    guaranteed close approximation of @xmath8 . in our    example",
    "for which sis requires exponential time , the estimator appears    to converge , but it converges to a quantity that is off from    @xmath8 by an exponential factor .    before formally stating our results",
    ", we detail the sequential importance sampling approach for contingency tables , following  @xcite .",
    "the general importance sampling paradigm involves sampling from an ` easy ' distribution @xmath10 over @xmath7 that is , ideally , close to the uniform distribution . at every round",
    ", the algorithm outputs a table @xmath11 along with @xmath12 . since for any @xmath10 whose support is @xmath7 we have @xmath13 = |\\omega|,\\ ] ] we take many trials of the algorithm and output the average of @xmath14 as our estimate of @xmath8 .",
    "more precisely , let @xmath15 denote the outputs from @xmath16 trials of the sis algorithm .",
    "our final estimate is @xmath17 one typically uses a heuristic to determine how many trials @xmath16 are needed until the estimator has converged to the desired quantity .    the sequential importance sampling algorithm of chen et al .",
    "@xcite constructs the table @xmath11 in a column - by - column manner .",
    "it is not clear how to order the columns optimally , but this will not concern us as our negative results will hold for any ordering of the columns .",
    "suppose the procedure is assigning column @xmath18 .",
    "let @xmath19 denote the residual row sums after taking into account the assignments in the first @xmath20 columns .",
    "the procedure of chen et al",
    ".  chooses column @xmath18 from the correct probability distribution conditional on @xmath21 , @xmath19 and the number of columns remaining ( but ignoring the column sums @xmath22 ) .",
    "this distribution is easy to describe in closed form .",
    "we assign column @xmath18 the vector @xmath23 where @xmath24 , with probability proportional to @xmath25 where @xmath26 .",
    "if no valid assignment is possible for the @xmath18-th column , then the procedure restarts from the beginning with the first column ( and sets @xmath27 in for this trial ) .",
    "sampling from the above distribution over assignments for column @xmath18 can be done efficiently by dynamic programming .",
    "[ ftn : delicatesampling ] chen et al .  devised a more subtle procedure which guarantees that there will always be a suitable assignment of every column .",
    "we do not describe this interesting modification of the procedure , as the two procedures are equivalent for the input instances which we discuss in this paper .",
    "we now state our negative result .",
    "this is a simple family of examples where the sis algorithm will grossly underestimate @xmath8 unless the number of trials @xmath16 is exponentially large .",
    "our examples will have the form @xmath28 for row sums and @xmath29 for column sums , where the number of rows is @xmath30 , the number of columns is @xmath31 , and we require that @xmath32 .",
    "[ thm : verybad ] let @xmath33 be constants satisfying @xmath34 and consider the input instances @xmath35 , @xmath36 with @xmath30 rows . fix any order of columns ( or rows , if sequential importance sampling constructs tables row - by - row ) and let @xmath37 be the random variable representing the estimate of the sis procedure after @xmath16 trials of the algorithm .",
    "there exist constants @xmath38 and @xmath39 such that for every sufficiently large @xmath40 and for any @xmath41 , @xmath42    in contrast , note that there are mcmc algorithms which provably run in time polynomial in @xmath43 and  @xmath40 for _ any _ row / column sums . in particular , the algorithm of jerrum , sinclair , and vigoda  @xcite for the permanent of a non - negative matrix yields as a corollary a polynomial time algorithm for any row / column sums .",
    "more recently , bezkov , bhatnagar and vigoda  @xcite have presented a related simulated annealing algorithm that works directly with binary contingency tables and has an improved polynomial running time .",
    "we note that , in addition to being formally asymptotically faster than any exponential time algorithm , a polynomial time algorithm has additional theoretical significance in that it ( and its analysis ) implies non - trivial insight into the the structure of the problem .",
    "some caveats are in order here .",
    "firstly , the above results imply only that mcmc outperforms sis asymptotically _ in the worst case _ ; for many inputs , sis may well be much more efficient .",
    "secondly , the rigorous worst case upper bounds on the running time of the above mcmc algorithms are still far from practical .",
    "chen et al .",
    "@xcite showed several examples where sis outperforms mcmc methods .",
    "we present a more systematic experimental study of the performance of sis , focusing on examples where all the row and column sums are identical as well as on the `` bad '' examples from theorem  [ thm : verybad ] .",
    "our experiments suggest that sis is extremely fast on the balanced examples , while its performance on the bad examples confirms our theoretical analysis .",
    "we begin in section [ sec : preliminaries ] by presenting a few basic lemmas that are used in the analysis of our negative example . in section [ sec : mainexample ] we present our main example where sis is off by an exponential factor , thus proving theorem [ thm : verybad ] .",
    "finally , in section  [ sec : experiments ] we present some experimental results for sis that support our theoretical analysis .",
    "we will continue to let @xmath44 denote the probability that a table @xmath45 is generated by sequential importance sampling algorithm .",
    "we let @xmath46 denote the uniform distribution over @xmath7 , which is the desired distribution .    before beginning our main proofs we present two straightforward technical lemmas which are used at the end of the proof of the main theorem .",
    "the first lemma claims that if a large set of binary contingency tables gets a very small probability under sis , then sis is likely to output an estimate which is not much bigger than the size of the complement of this set , and hence very small .",
    "let @xmath47 .",
    "[ lem : underestimate ] let @xmath48 and let @xmath49 be such that @xmath50 .",
    "then for any @xmath51 , and any @xmath16 , we have @xmath52    the probability that all @xmath16 sis trials are not in @xmath53 is at least @xmath54 where the first inequality follows from @xmath55 , valid for @xmath56 , and the second inequality is the standard @xmath57 for @xmath58 .    let @xmath15 be the @xmath16 tables constructed by sis .",
    "then , with probability @xmath59 , we have @xmath60 for all @xmath61 .",
    "notice that for a table @xmath11 constructed by sis from @xmath62 , we have @xmath63 let @xmath64 denote the event that @xmath60 for all @xmath61 , @xmath65 ; hence , @xmath66    we can use markov s inequality to estimate the probability that sis returns an answer which is more than a factor of @xmath67 worse than the expected value , conditioned on the fact that no sis trial is from @xmath53 : @xmath68 finally , removing the conditioning we get : @xmath69    the second technical lemma shows that if in a row with large sum ( linear in @xmath40 ) there exists a large number of columns ( again linear in @xmath40 ) for which the sis probability of placing a @xmath70 at the corresponding position differs significantly from the correct probability , then in any subexponential number of trials the sis estimator will very likely exponentially underestimate the correct answer .",
    "[ lem : separable ] let @xmath71 be positive constants . consider a class of instances of the binary contingency tables problem , parameterized by @xmath40 , with @xmath30 row sums , the last of which is @xmath72 .",
    "let @xmath73 denote the set of all valid assignments of @xmath0 to columns @xmath74 .",
    "suppose that there exist constants @xmath75 and a set @xmath76 of cardinality @xmath77 such that one of the following statements is true :    a.   for every @xmath78 and any @xmath79 , @xmath80 b.   for every @xmath78 and any @xmath79 , @xmath81    then there exists a constant @xmath82 such that for any constant @xmath83 and any sufficiently large @xmath40 , for any @xmath84 , @xmath85    in words , in @xmath86 trials of sequential importance sampling , with probability at least @xmath87 the output is a number which is at most a @xmath88 fraction of the total number of corresponding binary contingency tables",
    ".    we will analyze case ( i ) ; the other case follows from analogous arguments .",
    "consider indicator random variables @xmath89 representing the event that the uniform distribution places @xmath70 in the last row of the @xmath61-th column .",
    "similarly , let @xmath90 be the corresponding indicator variable for the sis .",
    "the random variable @xmath89 is dependent on @xmath91 for @xmath92 and @xmath90 is dependent on @xmath93 for @xmath92 .",
    "however , each @xmath89 is stochastically dominated by @xmath94 which has value @xmath70 with probability @xmath95 , and each @xmath90 stochastically dominates the random variable @xmath96 which takes value @xmath70 with probability  @xmath97 . moreover , the @xmath94 and @xmath96 are respectively i.i.d .",
    "now we may use the chernoff bound .",
    ". then @xmath99 and @xmath100 let @xmath101 be the set of all tables which have less than @xmath102 ones in the last row of the columns in @xmath76 .",
    "let @xmath103 .",
    "then @xmath104 for @xmath105 .",
    "thus , by the first inequality , under uniform distribution over all binary contingency tables the probability of the set @xmath101 is at least @xmath106 .",
    "however , by the second inequality , sis constructs a table from the set @xmath101 with probability at most @xmath107 .",
    "we are ready to use lemma  [ lem : underestimate ] with @xmath108 and @xmath109 .",
    "since under uniform distribution the probability of @xmath101 is at least @xmath106 , we have that @xmath110 .",
    "let @xmath111 be any constant and consider @xmath84 sis trials .",
    "let @xmath112 .",
    "then , by lemma  [ lem : underestimate ] , with probability at least @xmath113 the sis procedure outputs a value which is at most an @xmath114 fraction of @xmath115 .",
    "in this section we prove theorem [ thm : verybad ] .",
    "before we analyze the input instances from theorem [ thm : verybad ] , we first consider the following simpler class of inputs .",
    "the row sums are @xmath118 and the number of rows is @xmath30 .",
    "the column sums are @xmath119 and the number of columns is @xmath120 .",
    "we assume that sequential importance sampling constructs the tables column - by - column .",
    "note that if sis constructed the tables row - by - row , starting with the row with sum @xmath121 , then it would in fact output the correct number of tables exactly .",
    "however , in the next subsection we will use this simplified case as a tool in our analysis of the input instances @xmath122 , @xmath123 , for which sis must necessarily fail regardless of whether it works row - by - row or column - by - column , and regardless of the order it chooses .",
    "[ lem : columnones ] let @xmath124 , and consider an input of the form @xmath125 with @xmath30 rows . then there exist constants @xmath38 and @xmath39 , such that for any sufficiently large @xmath40 , with probability at least @xmath126 , column - wise sequential importance sampling with @xmath127 trials outputs an estimate which is at most a @xmath128 fraction of the total number of corresponding binary contingency tables . formally , for any @xmath41 , @xmath129    the idea for the proof of the lemma is straightforward . by the symmetry of the column sums , for large @xmath40 and @xmath121 and @xmath130 a uniform random table will have about @xmath131 ones in the first @xmath132 cells of the last row , with high probability .",
    "we will show that for some @xmath130 and @xmath133 , sequential importance sampling is very unlikely to put this many ones in the first @xmath132 columns of the last row .",
    "therefore , since with high probability sequential importance sampling will not construct any table from a set that is a large fraction of all legal tables , it will likely drastically underestimate the number of tables .",
    "before we prove the lemma , let us first compare the column distributions arising from the uniform distribution over all binary contingency tables with the sis distributions .",
    "we refer to the column distributions induced by the uniform distribution over all tables as the _ true _ distributions .",
    "the true probability of @xmath70 in the first column and last row can be computed as the number of tables with @xmath70 at this position divided by the total number of tables . for this particular sequence ,",
    "the total number of tables is @xmath134 , since a table is uniquely specified by the positions of ones in the last row and the permutation matrix in the remaining rows and corresponding columns .",
    "therefore , @xmath135    on the other hand , by the definition of sequential importance sampling , @xmath136 , where @xmath137 is the row sum in the @xmath61-th row .",
    "therefore , @xmath138    observe that if @xmath139 for some constant @xmath124 , then for sufficiently large @xmath40 we have @xmath140 as we will see , this will be true for a linear number of columns , which turns out to be enough to prove that in polynomial time sequential importance sampling exponentially underestimates the total number of binary contingency tables with high probability .",
    "we will find a constant @xmath141 such that for every column @xmath142 we will be able to derive an upper bound on the true probability and a lower bound on the sis probability of @xmath70 appearing at the @xmath143 position .    for a partially filled table with columns",
    "@xmath144 assigned , let @xmath145 be the remaining sum in the last row and let @xmath146 be the number of other rows with remaining row sum @xmath70 .",
    "then the true probability of @xmath70 in the @xmath61-th column and last row can be bounded as @xmath147 while the probability under sis can be bounded as @xmath148 observe that for fixed @xmath149 , the function @xmath95 is increasing and the function @xmath97 is decreasing in @xmath61 , for @xmath150 .",
    "recall that we are considering a family of input instances parameterized by @xmath40 with @xmath151 , for a fixed @xmath124 .",
    "we will consider @xmath142 for some @xmath152 .",
    "let @xmath153 @xmath154 @xmath155 and recall that for fixed @xmath156 , @xmath157 is increasing in @xmath141 and @xmath158 is decreasing in @xmath141 , for @xmath71 .",
    "let @xmath159 be such that @xmath160 .",
    "such an @xmath141 exists by continuity and the fact that @xmath161 .    by the above",
    ", for any @xmath162 and sufficiently large @xmath40 , and for any @xmath142 , the true probability is upper - bounded by @xmath163 and the sis probability is lower - bounded by @xmath164 . for our purposes",
    "it is enough to fix @xmath165 .",
    "now we can use lemma  [ lem : separable ] with @xmath141 and @xmath156 defined as above , @xmath166 and @xmath167 ( notice that all these constants depend only on @xmath156 ) , and @xmath168 .",
    "this finishes the proof of the lemma with @xmath169 and @xmath170 .",
    "notice that every contingency table with row sums @xmath116 and column sums @xmath117 is binary .",
    "thus , this instance proves that the column - based sis procedure for general ( non - binary ) contingency tables has the same flaw as the binary sis procedure .",
    "we expect that the negative example used for theorem  [ thm : verybad ] also extends to general ( i.e. , non - binary ) contingency tables , but the analysis becomes more cumbersome .",
    "recall that we are working with row sums @xmath28 , where the number of rows is @xmath30 , and column sums @xmath29 , where the number of columns is @xmath171 .",
    "we will eventually fix @xmath172 and @xmath173 , but to simplify our expressions we work with @xmath174 and @xmath175 for now .",
    "the theorem claims that the sis procedure fails for an arbitrary order of columns with high probability .",
    "we first analyze the case when the sis procedure starts with columns of sum @xmath70 ; we shall address the issue of arbitrary column order later .",
    "as before , under the assumption that the first column has sum @xmath70 , we compute the probabilities of 1 being in the last row for uniform random tables and for sis respectively . for the true probability , the total number of tables can be computed as @xmath176 , since a table is uniquely determined by the positions of ones in the @xmath175 column and @xmath174 row and a permutation matrix on the remaining rows and columns .",
    "thus we have @xmath177 let @xmath178 and @xmath179 for some constants @xmath180 ( notice that this choice guarantees that @xmath181 and @xmath182 , as required ) . then , as @xmath40 tends to infinity , @xmath183 approaches @xmath184 and @xmath185 approaches @xmath186 notice that @xmath187 if and only if @xmath188 .",
    "suppose that @xmath189 ( the opposite case follows analogous arguments and uses the second part of lemma  [ lem : separable ] ) .",
    "as in the proof of lemma  [ lem : columnones ] , we can define @xmath141 such that if the importance sampling does not choose the column with sum @xmath175 in its first @xmath190 choices , then in any subexponential number of trials it will exponentially underestimate the total number of tables with high probability .",
    "formally , we derive an upper bound on the true probability of @xmath70 being in the last row of the @xmath61-th column , and a lower bound on the sis probability of the same event ( both conditioned on the fact that the @xmath175 column is not among the first @xmath61 columns assigned ) .",
    "let @xmath191 be the current residual sum in the last row , @xmath146 be the number of rows with sum @xmath70 , and @xmath192 the remaining number of columns with sum @xmath70 .",
    "notice that @xmath193 , @xmath194 , and @xmath195 .",
    "then @xmath196 as before , notice that if we fix @xmath197 satisfying @xmath198 and @xmath199 , then @xmath200 is an increasing function and @xmath201 is a decreasing function in @xmath61 , for @xmath202 .",
    "recall that @xmath203 .",
    "suppose that @xmath204 for some @xmath141 which we specify shortly .",
    "thus , the upper bound on @xmath200 in this range of @xmath61 is @xmath205 and the lower bound on @xmath201 is @xmath206 .",
    "if @xmath207 and @xmath208 , then the upper bound on @xmath200 converges to @xmath209 and the lower bound on @xmath201 converges to @xmath210 let @xmath211 we set @xmath141 to satisfy @xmath212 and @xmath213 .",
    "now we can conclude this part of the proof identically to the last paragraph of the proof of lemma  [ lem : columnones ] .",
    "it remains to deal with the case when sequential importance sampling picks the @xmath175 column within the first @xmath77 columns .",
    "suppose @xmath175 appears as the @xmath214-th column .",
    "in this case we focus on the subtable consisting of the last @xmath215 columns with sum @xmath70 , @xmath216 rows with sum @xmath70 , and one row with sum  @xmath217 , an instance of the form @xmath218",
    ". we will use arguments similar to the proof of lemma  [ lem : columnones ] .",
    "first we express @xmath217 as a function of @xmath216 .",
    "we have the bounds @xmath219 and @xmath220 where @xmath221 .",
    "let @xmath222 .",
    "thus , @xmath223 .",
    "now we find @xmath224 such that for any @xmath225 we will be able to derive an upper bound on the true probability and a lower bound on the sis probability of @xmath70 appearing at position @xmath226 of the @xmath227 subtable , no matter how the first @xmath214 columns were assigned . in order to do this , we might need to decrease @xmath141  recall that we are free to do so as long as @xmath141 is a constant independent of @xmath40 . by the derivation in the proof of lemma  [ lem : columnones ] ( see expressions and ) , as @xmath216 ( and thus also @xmath40 ) tends to infinity , the upper bound on the true probability approaches @xmath228 and the lower bound on the sis probability approaches @xmath229 where the last inequality holds as long as @xmath230 .",
    "notice that for fixed @xmath231 satisfying @xmath232 , the function @xmath233 is increasing and @xmath234 is decreasing in @xmath224 , for @xmath235 . similarly , for fixed @xmath236 satisfying @xmath237 , the function @xmath233 is increasing and @xmath234 is decreasing in @xmath141 , for @xmath238 .",
    "therefore , if we take @xmath239 , we will have the bounds @xmath240 recall that @xmath241 . if we choose @xmath141 so that @xmath242 , then in similar fashion to the last paragraph of the proof of lemma  [ lem : columnones ] , we may conclude that the sis procedure likely fails .",
    "more precisely , let @xmath243 and let @xmath244 and @xmath245 be the upper bound ( for sufficiently large @xmath40 ) on the true probability and the lower bound on the sis probability of @xmath70 appearing at the position @xmath143 for @xmath246 .",
    "therefore lemma  [ lem : separable ] with parameters @xmath247 , @xmath156 , @xmath76 of size @xmath248 , @xmath95 , and @xmath97 implies the statement of the theorem .",
    "finally , if the sis procedure constructs the tables row - by - row instead of column - by - column , symmetrical arguments hold .",
    "this completes the proof of theorem  [ thm : verybad ] .",
    "we performed several experimental tests which show sequential importance sampling to be a promising approach for certain classes of input instances .",
    "we ran sequential importance sampling algorithm for binary contingency tables , using the following stopping heuristic .",
    "let @xmath250 .",
    "for some @xmath251 we stopped if the last @xmath252 estimates were all within a @xmath253 factor of the current estimate .",
    "we set @xmath254 and @xmath255 .",
    "figure [ fig : convergence](a ) shows the evolution of the sis estimate as a function of the number of trials on the input with all row and column sums @xmath256 , and @xmath257 matrices . in our simulations we used the more delicate sampling mentioned in remark [ ftn : delicatesampling ] , which guarantees that the assignment in every column is valid , i.e. , such an assignment can always be extended to a valid table ( or , equivalently , that the random variable @xmath37 is always strictly positive ) .",
    "five independent runs are depicted , together with the correct number of tables @xmath258 , which we computed exactly . to make the figure legible ,",
    "the @xmath259-axis is scaled by a factor of @xmath260 and it only shows the range from @xmath261 to @xmath262 . note that the algorithm appears to converge to the correct estimate , and our stopping heuristic appears to capture this behavior .",
    "matrix where all @xmath256 .",
    "the @xmath263-axis is the number of sis trials , and the @xmath259-axis corresponds to the estimate scaled down by a factor of @xmath260 .",
    "five independent runs of sequential importance sampling are depicted .",
    "notice that the @xmath259-axis ranges from @xmath261 to @xmath262 , a relatively small interval , thus it appears sis converges to the correct estimate .",
    "( b ) the input instance is from theorem  [ thm : verybad ] with @xmath264 , @xmath265 and @xmath266 .",
    "the estimate ( @xmath259-axis ) is plotted on a logarithmic scale ( base @xmath261 ) and one unit on the @xmath263-axis corresponds to @xmath267 sis trials . note that in this instance sis appears to converge to an incorrect estimate .",
    "nine independent runs of the sis algorithm are shown : the red curves construct tables column - by - column with columns sorted by decreasing sum , the blue curves construct row - by - row with rows sorted by decreasing sum , and the green curves construct column - by - column with columns sorted increasingly.,title=\"fig : \" ] ( a )     matrix where all @xmath256 . the @xmath263-axis is the number of sis trials , and the @xmath259-axis corresponds to the estimate scaled down by a factor of @xmath260 .",
    "five independent runs of sequential importance sampling are depicted .",
    "notice that the @xmath259-axis ranges from @xmath261 to @xmath262 , a relatively small interval , thus it appears sis converges to the correct estimate .",
    "( b ) the input instance is from theorem  [ thm : verybad ] with @xmath264 , @xmath265 and @xmath266 .",
    "the estimate ( @xmath259-axis ) is plotted on a logarithmic scale ( base @xmath261 ) and one unit on the @xmath263-axis corresponds to @xmath267 sis trials . note that in this instance sis appears to converge to an incorrect estimate .",
    "nine independent runs of the sis algorithm are shown : the red curves construct tables column - by - column with columns sorted by decreasing sum , the blue curves construct row - by - row with rows sorted by decreasing sum , and the green curves construct column - by - column with columns sorted increasingly.,title=\"fig : \" ] ( b )    in contrast , figure [ fig : convergence](b ) depicts the sis evolution on the negative example from theorem [ thm : verybad ] with @xmath268 and @xmath269 , i.e. , the input is @xmath270 on a @xmath271 matrix . in this case",
    "the correct number of tables is @xmath272 we ran the sis algorithm under three different settings : first , we constructed the tables column - by - column where the columns were ordered from the largest sum , as suggested in the paper by chen et al .",
    "@xcite ( the red curves correspond to three independent runs with this setting ) ; second , we ordered the columns from the smallest sum ( the green curves ) ; and third , we constructed the tables row - by - row where the rows were ordered from the largest sum ( the blue curves ) .",
    "the @xmath259-axis is on a _ logarithmic scale _ ( base 10 ) and one unit on the @xmath263-axis corresponds to @xmath267 sis trials .",
    "we ran the sis estimates for twice the number of trials determined by our stopping heuristic to indicate that the unfavorable performance of the sis estimator on this example is not the result of a poor choice of stopping heuristic .",
    "notice that even the best estimator differs from the true value by about a factor of @xmath273 , while the blue curves are off by more than a factor of @xmath267 .",
    "figure [ fig : comparereg ] represents the number of trials required by the sis procedure ( computed by our stopping heuristic ) on several examples for @xmath274 matrices .",
    "the four curves correspond to @xmath275 , @xmath261 , @xmath276 and @xmath277-regular row and column sums . the @xmath263-axis represents @xmath43 , the number of rows and columns , and the @xmath259-axis captures the required number of sis trials .",
    "for each @xmath43 and each of these row and column sums , we took @xmath278 independent runs and we plotted the median number of trials .",
    "for comparison , in figure [ fig : comparebad ] we plotted the estimated running time for our bad example from theorem [ thm : verybad ] ( recall that this is likely the running time needed to converge to a wrong value ! ) for @xmath279 ranging from @xmath278 to @xmath280 and various settings of @xmath281 : @xmath282 ( red ) , @xmath283 ( blue ) , @xmath284 ( green ) , and @xmath285 ( black ) . in this case",
    "it is clear that the convergence time is considerably slower compared with the examples in figure [ fig : comparereg ] .      .",
    "the inputs are of the type described in theorem  [ thm : verybad ] , with @xmath286 ( red ) , @xmath287 ( blue ) , @xmath288 ( green ) , and @xmath289 ( black ) .",
    "the right plot shows the same four curves with the number of sis trials plotted on a logarithmic scale .",
    "note that the algorithm appears to be converging in sub - exponential time .",
    "recall from figure [ fig : convergence ] that it is converging to the wrong estimate . ]      .",
    "the inputs are of the type described in theorem  [ thm : verybad ] , with @xmath286 ( red ) , @xmath287 ( blue ) , @xmath288 ( green ) , and @xmath289 ( black ) .",
    "the right plot shows the same four curves with the number of sis trials plotted on a logarithmic scale .",
    "note that the algorithm appears to be converging in sub - exponential time .",
    "recall from figure [ fig : convergence ] that it is converging to the wrong estimate . ]          m. de iorio , r. c. griffiths , r. lebois , and f. rousset , stepwise mutation likelihood computation by sequential importance sampling in subdivided population models .",
    "_ , 68:41 - 53 , 2005 .",
    "jerrum , a. sinclair and e. vigoda , a polynomial - time approximation algorithm for the permanent of a matrix with non - negative entries .",
    "_ journal of the association for computing machinery _ , 51(4):671 - 697 , 2004 ."
  ],
  "abstract_text": [
    "<S> the sequential importance sampling ( sis ) algorithm has gained considerable popularity for its empirical success . </S>",
    "<S> one of its noted applications is to the binary contingency tables problem , an important problem in statistics , where the goal is to estimate the number of @xmath0 matrices with prescribed row and column sums . </S>",
    "<S> we give a family of examples in which the sis procedure , if run for any subexponential number of trials , will underestimate the number of tables by an exponential factor . </S>",
    "<S> this result holds for any of the usual design choices in the sis algorithm , namely the ordering of the columns and rows . </S>",
    "<S> these are apparently the first theoretical results on the efficiency of the sis algorithm for binary contingency tables . finally , we present experimental evidence that the sis algorithm is efficient for row and column sums that are regular . </S>",
    "<S> our work is a first step in determining the class of inputs for which sis is effective .    </S>",
    "<S> * keywords : * sequential monte carlo ; markov chain monte carlo ; + graphs with prescribed degree sequence ; zero - one table </S>"
  ]
}