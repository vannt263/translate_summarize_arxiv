{
  "article_text": [
    "we provide further details into the derivation of eq . 3 in the main text for linearized signaling networks .",
    "the proof for linear networks , sketched in the main text , follows as a special case . for linearized signaling networks , @xmath82 , where @xmath83 $ ] , @xmath84 $ ] , and @xmath85 can depend on @xmath0 ( because the linearization depends on the trajectory the network is linearized about . )",
    "we use @xmath86 $ ] to denote the expectation of the random variable @xmath87 .",
    "the dependence of @xmath85 on @xmath0 makes the proof of eq . 3 for linearized networks more subtle than for linear networks .",
    "we start from eq . 2 in the main text : @xmath88 =   \\sigma_{x(t_{\\rm{o}})}^2 / \\left(de[x(t_{\\rm{o}})|c]/dc \\right)^2\\ ] ] the variance in the numerator of eq .",
    "[ eq : sig ] is : @xmath89 \\nonumber \\\\ & =   e\\left [ \\left ( \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t )",
    "\\delta s(t ) dt \\right ) ^2 \\right ] \\nonumber \\\\ & = \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t_1 ) e[\\delta s(t_1 ) \\delta s(t_2 ) ] f_c(t_{\\rm{o}}-t_2 ) dt_1 dt_2 \\nonumber \\\\ & = \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t_1 ) c(t_1,t_2 ) f_c(t_{\\rm{o}}-t_2 ) dt_1 dt_2\\end{aligned}\\ ] ] to determine the denominator of eq .",
    "[ eq : sig ] , note that @xmath90 + \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t ) \\left ( s\\left(t\\right ) - e\\left[s\\left(t\\right)|c\\right ] \\right ) dt$ ] . taking the expectation at a concentration @xmath91 yields : @xmath92 = e[x(t_{\\rm{o}})|c ] + \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t ) ( e[s(t)|c+dc ] - e[s(t)|c ] ) dt$ ] . then , because @xmath93 is stationary : @xmath94}{dc }   = \\dfrac{de[s|c]}{dc } \\int_0^{t_{\\rm{o } } } f_c(t_{\\rm{o}}-t ) dt\\ ] ] inserting eqs .",
    "[ eq : numer ] and [ eq : denom ] into the numerator and denominator , respectively , of eq .",
    "[ eq : sig ] , we find eq . 3 in the main text : @xmath95   =   \\sigma_{\\hat{c}}^2 [ s ] \\nonumber \\\\ & \\times \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } \\bar{f}(t_{\\rm{o}}-t_1 ) \\bar{c}(t_1,t_2 ) \\bar{f}(t_{\\rm{o}}-t_2 ) dt_1 dt_2.\\end{aligned}\\ ] ] the integrals of the weighting function in the denominator of eq .",
    "[ eq : sig ] normalize the weighting functions in the numerator of eq .",
    "[ eq : sig ] ; the correlation function is normalized by pulling the stationary variance of the signal @xmath93 into the prefactor .",
    "we consider a reversible cascade consisting of @xmath46 layers / species that are each degraded at the same rate , @xmath27 : @xmath96 , where @xmath48 , @xmath97 , and @xmath98 .",
    "assuming @xmath99 , @xmath50 , as for the examples in the main text .",
    "for @xmath100 , the network is the one - level reversible cascade studied in the main text , with @xmath101 .",
    "the one - level reversible cascade places the most weight on the most recent value of the signal ( @xmath102 ) .",
    "the weighting function for general @xmath46 , which can be determined by laplace transforming the governing differential equations , behaves as @xmath103 ( fig .",
    "[ fig : multireverse ] ) .",
    "the exponential factor , which reflects the reversibility of the cascade , emphasizes the most recent values of the signal ; the polynomial factor , which reflects the number of levels , emphasizes older values of the signal . in combination ,",
    "the two factors lead to nonmonotonic weighting functions that peak some finite time in the past , @xmath104 ( fig .",
    "[ fig : multireverse ] ) . as a result",
    ", additional levels in a cascade can increase the effective integration time over which the weighting function is nonzero .",
    "levels places maximum weight on past time points @xmath105 for cascades with 1 ( blue ) , 2 ( green ) , or 3 ( red ) levels , respectively .",
    "the plotted weighting functions have been normalized to integrate to 1.,width=321 ]    by remembering farther into the past , multilevel reversible cascades can improve the performance of signaling networks , provided @xmath70 is not limiting . using eq .",
    "3 in the main text , the estimation error for a one - level reversible cascade , @xmath100 , is : @xmath106 =   \\frac{\\sigma_{\\hat{c}}^2 [ s]}{\\frac{1}{k_{\\rm b } \\tau_{\\rm c } } + 1}\\ ] ] in the limit @xmath107 .",
    "this equation is similar to the extrinsic component of the noise - addition rule , after rearrangement of terms @xcite .",
    "the solution for general @xmath46 can be obtained in terms of the hypergeometric function but is difficult to analyze .",
    "for a two - level ( @xmath108 ) cascade the estimation error is : @xmath109 =   \\frac{\\frac{1}{2 k_{\\rm b } \\tau_{\\rm c}}+1}{\\left(\\frac{1}{k_{\\rm b } \\tau_{\\rm c } } + 1\\right)^2 } \\sigma_{\\hat{c}}^2 [ s]\\ ] ] which is smaller than the error for the one - level cascade for all finite values of @xmath110 .",
    "the improvement is greatest in the limit of slow - decaying molecules , @xmath111 ; then , the error of a two - level cascade is half that of a one - level cascade . more generally , by combining different multilevel cascades that peak at different times in the past , networks can both shape weighting functions and extend the range over which they are nonzero , even when the lifetimes of signaling molecules are limited .",
    "we consider the non - stationary signal @xmath1 introduced in the main text , generated by @xmath112 with @xmath113 and @xmath114 .",
    "the correlation time is @xmath115 .",
    "because the signal is nonstationary , the weighting function @xmath116 no longer reduces to @xmath23 . in what follows we write @xmath117 , where the argument is the time directly ( i.e. the time since the change in environment ) and not @xmath37 , as for the stationary input signal",
    "the response of a signaling network with weighting function @xmath117 is @xmath118 . as for a stationary signal ,",
    "the variance of an estimate based on @xmath14 is given by eq .",
    "[ eq : sig ] , when @xmath14 is linear over the fluctuations in @xmath1 .",
    "note that @xmath119 so that @xmath120/dc$ ] in the denominator of eq .",
    "[ eq : sig ] is : @xmath121 the numerator of eq .",
    "[ eq : sig ] is : @xmath122 \\nonumber \\\\ & = &   e\\left [ \\left ( \\int_0^{t_{\\rm{o } } } f(t ) \\left(s(t ) - \\mu_{s(t ) } \\right )   \\right)^2\\right ] \\nonumber \\\\   & = & \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } f(t_1 )",
    "c(t_1,t_2 ) f(t_2 ) dt_1 dt_2\\end{aligned}\\ ] ] as for a stationary signal , except that the correlation function for the non - stationary signal is : @xmath123 for this non - stationary case , we define a normalized weighting function @xmath53 , which differs from that for the stationary case presented in the main text : @xmath124 so that @xmath125",
    ". additionally , we define @xmath126 to be the correlation function normalized by the signal s variance @xmath127 in steady state , @xmath128 .",
    "combining eqs .",
    "[ eq : sig ] , [ eq : denom2 ] , [ eq : numer2 ] , and [ eq : normal ] , the analogue of eq .",
    "3 in the main text for this non - stationary signal is : @xmath129 = \\frac{c}{k_{\\rm p } \\tau_{\\rm c } }   \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } \\bar{f}(t_1 ) \\bar{c}(t_1,t_2 ) \\bar{f}(t_2 ) dt_1 dt_2\\ ] ] the prefactor can be interpreted as the error of an estimate of @xmath0 based only on an instantaneous observation of the signal in steady state ( i.e. @xmath130 ) : @xmath131 =   \\sigma_{s}^2 / \\left(d\\mu_s / dc \\right)^2 = k_{\\rm p } c \\tau_{\\rm c } / ( k_{\\rm p } \\tau_{\\rm c})^2 = c / ( k_{\\rm p } \\tau_{\\rm c})$ ] .       for a signal with @xmath7 = 0.1 ( green ) , 1 ( red ) , and 10 ( blue ) . for comparison , the weighting functions have been renormalized to integrate to 1 ; i.e. we have multiplied by a factor @xmath133 so that @xmath134",
    ". the delta functions at time @xmath10 are truncated for illustration , with height equal to their respective coefficients .",
    "some minimal weight is placed on all points ; how much depends on @xmath7 and @xmath10 .",
    "then additional weight is placed on early and late data points , because of correlations in the input signal .",
    "the final time point dominates the estimate when @xmath135 ( blue curve ) .",
    ", width=321 ]    one way to solve eq .",
    "[ eq : inteq ] is to differentiate three times with respect to @xmath136 , resulting in an ordinary differential equation after substitution of intermediate derived equalities ( see ref .",
    "@xcite for a discussion of this method for solving integral equations ) .",
    "the solution is ( fig .",
    "[ fig : model ] ) : @xmath137 with @xmath138 note that the weighting function has units of 1/time , @xmath139 has units of 1/time , @xmath140 has no units , and the delta function has units of 1/time .",
    "the weight placed on the final time point grows relative to the weight placed on other points as @xmath141 decreases , as measured by its contribution to the integral of the weighting function .",
    "the first term approaches a constant weight for @xmath142 .",
    "the corresponding minimal estimation error is , as in the main text : @xmath143 = \\frac{\\sigma_{\\hat{c}}^2 [ s ] } { t_{\\rm{o}}/(2    \\tau_{\\rm",
    "c } ) +   \\ln \\left ( 2   -e^{-t_{\\rm{o}}/\\tau_{\\rm c}}\\right)/2}\\ ] ] the short and long time limits of eq .",
    "[ eq : nonperf ] can be motivated with simple arguments . for short observation times",
    "@xmath80 , the estimate is essentially constructed from @xmath81 only , since eq .",
    "[ eq : nonopt ] indicates that all weight is placed on the final time point in that limit . because no @xmath93 molecules decay on the short time @xmath144 , the number of @xmath93 molecules at time @xmath10 is poisson distributed with arrival rate @xmath75 , mean @xmath145 , and variance @xmath145 .",
    "the variance of an estimate based on @xmath81 is then , from eq .",
    "[ eq : sig ] , @xmath146 , the short time approximation of eq .",
    "[ eq : nonperf ] .",
    "the long time approximation of eq .",
    "[ eq : nonperf ] is @xmath131 / ( t_{\\rm{o}}/(2 \\tau_{\\rm c}))$ ] , identical to the long - time approximation for an estimate based on a stationary signal of equivalent duration ( see eq . 5 in the main text ) .",
    "the effect of the non - stationarity is washed out on long time scales . for finite times",
    ", the non - stationary signal contains less extractable information than a stationary signal of equal duration ."
  ],
  "abstract_text": [
    "<S> living cells often need to extract information from biochemical signals that are noisy . </S>",
    "<S> we study how accurately cells can measure chemical concentrations with signaling networks that are linear . for stationary signals of long duration </S>",
    "<S> , they can reach , but not beat , the berg - purcell limit , which relies on uniformly averaging in time the fluctuations in the input signal . for short times or nonstationary signals , however , they can beat the berg - purcell limit , by non - uniformly time - averaging the input . </S>",
    "<S> we derive the optimal weighting function for time averaging and use it to provide the fundamental limit of measuring chemical concentrations with linear signaling networks .    </S>",
    "<S> cells measure concentrations of chemicals via receptors on their surface . </S>",
    "<S> these measurements , however , are inevitably corrupted by noise that arises from the stochastic arrival of ligand molecules at the receptor by diffusion and from the stochastic binding of the ligand to the receptor . </S>",
    "<S> biochemical networks that transmit the information on the ligand concentration from the surface of the cell to its interior often have to filter this noise extrinsic to the cell as much as possible . </S>",
    "<S> however , how the capacity of signaling networks to remove extrinsic noise depends on their design , and what the fundamental limits to this capacity are , remain open questions .    </S>",
    "<S> several studies have addressed the question how accurately the ligand concentration @xmath0 can be estimated from the time trace of the number of ligand - bound receptors , @xmath1 , over some integration time @xmath2 @xcite . </S>",
    "<S> berg and purcell assumed that the estimate @xmath3 with least error is the one that matches the observed time average of the stochastic signal @xmath1 , @xmath4 , giving all the signal values equal weight in the average @xcite . </S>",
    "<S> when @xmath1 is stationary , with mean @xmath5 , variance @xmath6 , and correlations that decay exponentially over a time @xmath7 , the estimate @xmath3 has variance ( error ) @xcite : @xmath8 & = & \\frac{\\sigma_{\\bar{s}}^2 } { \\left ( d\\mu_{s}/dc \\right)^2 }   = \\frac{\\sigma^2_{s } / \\left ( d\\mu_s / dc \\right)^2}{\\frac{t}{2 \\tau_{\\rm c } } \\left(1-\\frac{1-\\exp(-t/\\tau_{\\rm c})}{t/\\tau_{\\rm c}}\\right)^{-1}}.\\end{aligned}\\ ] ] more recently , mora , endres , and wingreen showed that , when @xmath9 , maximum likelihood estimation produces an estimate that is better by 50% , since the time - average includes noise from stochastic ligand unbinding , which provides no information about the ligand concentration @xcite .    while these previous studies have considered how much information about the ligand concentration is encoded in receptor - occupancy time traces , they do not address the question how much information biochemical networks can actually extract from these time traces . to extract all the information , the biochemical networks downstream of the receptors would need to construct a maximum likelihood estimate @xcite . </S>",
    "<S> however , it is not clear that typical biochemical networks do this , nor is it clear that they time - average signals _ uniformly _ as in the berg - purcell estimate . </S>",
    "<S> moreover , the previous analyses @xcite assumed an integration time @xmath2 , but what time scales in the processing network actually set the integration time remains unclear . </S>",
    "<S> we therefore study how accurately biochemical networks can estimate the ligand concentration from receptor time traces .    </S>",
    "<S> we focus on a simple but broad class of signaling networks , linear networks @xcite . </S>",
    "<S> many networks respond linearly over the range of fluctuations in their input ( e.g. @xcite ) and a systematic study can be done analytically . since the effects of noise intrinsic to the molecular interactions inside cells have been well studied @xcite , we focus on networks in the deterministic limit . </S>",
    "<S> this enables us to understand the unique effects due to the noise in the input signal .    </S>",
    "<S> linear networks time - average the input signal , but do not generally give rise to uniformly weighted time - averages . </S>",
    "<S> we study how different signaling motifs sculpt the weighting of the signal as a function of time , and how this affects the precision of ligand sensing . </S>",
    "<S> while linear networks can not extract all of the information in the input signal ( i.e. the maximum likelihood estimate @xcite ) , they can , surprisingly , reach the berg - purcell limit and even exceed it by 12% ; this is because the optimal weighting is non - uniform , in contrast to the berg - purcell estimate . </S>",
    "<S> we show that a simple network based on a feed - forward loop , a common motif in biochemical networks @xcite , can reach the bound for linear signaling networks , and we elucidate the combination of time scales that sets the effective integration time . </S>",
    "<S> we conclude by studying how reliably biochemical signaling networks can extract information from non - stationary signals .    </S>",
    "<S> we consider a cell that responds after a finite time @xmath10 to a change in its environment which happens at time @xmath11 . </S>",
    "<S> this time @xmath10 is the observation time , which , as we discuss below , provides an upper bound to the integration time . </S>",
    "<S> as before , the receptor time trace provides the signal to the cell , @xmath1 . to compare to previous results </S>",
    "<S> , we initially assume that the change in the environment , and therefore the ligand concentration , is instantaneous , and that the receptors immediately adjust . </S>",
    "<S> moreover , we assume that the fluctuations in @xmath1 decay exponentially with correlation time @xmath7 @xcite . </S>",
    "<S> we neglect stochasticity in the time @xmath10 , and , as mentioned above , the intrinsic noise in the processing network . </S>",
    "<S> the capacity of the cell to respond is then limited by the information in the stationary input @xmath1 from time @xmath12 to @xmath10 ( fig . </S>",
    "<S> 1a ) .    as a measure of how much information </S>",
    "<S> the cell can extract , we determine how accurately the ligand concentration can be estimated from the molecular output @xmath13 of the processing network at the time @xmath10 of the response , assuming the response is made instantaneously based on @xmath14 . as illustrated below in examples , the output of a linear signaling network is @xmath15 , where the unnormalized weighting ( response or transfer ) function @xmath16 reflects how the processing network at time @xmath10 weights the signal at an earlier time @xmath17 @xcite . to compare to previous results </S>",
    "<S> , we assume that either : ( 1 ) @xmath18 for @xmath19 , which corresponds to a scenario where the response time @xmath20 of the network is shorter than @xmath10 , or , equivalently , the network reaches steady state by the time @xmath10 ( fig . </S>",
    "<S> 1b ) ; or ( 2 ) @xmath21 for @xmath19 , which corresponds to a scenario in which the cell is initially in a basal state ( fig . </S>",
    "<S> 1c ) . in both cases </S>",
    "<S> , we then have @xmath22 . when neither @xmath23 nor @xmath1 are zero for @xmath19 , then previous states of the environment , corresponding to @xmath19 , influence the state of the signaling network at time @xmath10 . </S>",
    "<S> such previous environmental states can be a source of additional noise in @xmath14 , complicating inference of the current environmental state , as well as a source of information , helping inference , if environmental transitions are correlated .    , and the number of bound receptors , @xmath1 , adjusts instantaneously . </S>",
    "<S> @xmath1 is stationary between time 0 and the time @xmath10 , when the cell responds . </S>",
    "<S> the signaling network is either in a steady state by time @xmath10 , independent of the initial condition , width=321 ]    ( b ) , or in a basal state at time @xmath11 ( c ) . </S>",
    "<S> @xmath24 denotes the number of @xmath13 molecules at time @xmath25 . </S>",
    "<S> the solid and dashed lines in panel b represent different initial conditions . </S>",
    "<S> [ fig : model2 ]    we start by considering a simple linear signaling network , a reversible one - level cascade , in which the output molecule @xmath13 is directly activated by the receptor with rate constant @xmath26 and can be degraded with rate constant @xmath27 ( fig . </S>",
    "<S> [ fig : model3]a ) . </S>",
    "<S> then , deterministically , @xmath28 . </S>",
    "<S> the response of this network at time @xmath10 is @xmath29 with @xmath30 and @xmath31 ( fig . [ </S>",
    "<S> fig : model3]a ) . </S>",
    "<S> we neglect the term @xmath32 for the reasons mentioned above : either because @xmath10 is larger than the response time @xmath33 in which case @xmath34 , or , because the initial state is ligand - free and @xmath35 . </S>",
    "<S> we note that the weighting function @xmath36 decays with increasing @xmath37 , which means that more weight is placed on more recent values of the input signal . </S>",
    "<S> this is because the decay reaction is least likely to have degraded the most recently produced @xmath13 molecules .        </S>",
    "<S> we now address the question how the departure from uniform weighting affects the error in the estimate of the concentration . following the derivation of eq . </S>",
    "<S> [ eq : bp ] @xcite , an estimate of the ligand concentration from @xmath14 has variance @xmath38 =   \\sigma_{x(t_{\\rm{o}})}^2 / \\left(d\\mu_{x(t_{\\rm{o}})}/dc \\right)^2,\\ ] ] where the mean @xmath39 of @xmath14 is a linear function of @xmath0 over the range of fluctuations in @xmath14 . </S>",
    "<S> using @xmath40 , we then arrive at ( see supplement ) @xmath41 =   \\sigma_{\\hat{c}}^2 [ s ]   \\nonumber \\\\ & \\times \\int_0^{t_{\\rm{o } } } \\int_0^{t_{\\rm{o } } } \\bar{f}(t_{\\rm{o}}-t_1 ) \\bar{c}(t_1,t_2 ) \\bar{f}(t_{\\rm{o}}-t_2 ) dt_1 dt_2.\\end{aligned}\\ ] ] here , @xmath42 </S>",
    "<S> = \\sigma^2_{s } / \\left ( d\\mu_s / dc \\right)^2 $ ] is the error of an estimate based on an _ instantaneous _ observation of the signal @xmath1 . the reduction in error , resulting from averaging the fluctuations in the input signal over time , depends on the normalized correlation function of the input fluctuations , @xmath43 , and on the normalized weighting function , @xmath44 .    </S>",
    "<S> fig . </S>",
    "<S> [ fig:2]b shows that the one - level reversible cascade extracts less information from the input signal than a network that averages the input uniformly over time . </S>",
    "<S> only when @xmath27 goes to zero , and @xmath45 , does the network , which now becomes an _ irreversible _ one - level cascade , implement uniform time averaging and does it extract the same amount of information . </S>",
    "<S> intuitively , degrading @xmath13 destroys information . </S>",
    "<S> while degradation is required to make a signaling network responsive to new environments , this example shows that it may be useful to make degradation as weak as possible or to physically separate the receptors and deactivating enzymes ( _ e.g. _ in different domains on the membrane @xcite ) , such that @xmath13 is deactivated only after the response has been made .    signaling networks typically consist of more than one layer , which makes it possible to sculpt the weighting function @xmath36 . </S>",
    "<S> as an illustration , we first consider an _ </S>",
    "<S> irreversible _ cascade consisting of @xmath46 layers / species : @xmath47 , where @xmath48 and @xmath49 . </S>",
    "<S> assuming @xmath35 , @xmath50 , where the weighting function now behaves as @xmath51 . </S>",
    "<S> such cascades place more weight on early values of the input signal , which have had more time to propagate through the network ( fig . </S>",
    "<S> [ fig:2]c ) . as a result , they underutilize ( down - weight ) the most recent information in the signal , and indeed , these cascades perform worse than a strict average of the input ( fig . </S>",
    "<S> [ fig:2]d ) .    </S>",
    "<S> the above formalism can be generalized to arbitrarily large linear signaling networks . </S>",
    "<S> multilevel _ </S>",
    "<S> reversible _ cascades have weighting functions that peak some finite time in the past , balancing the down - weighting of the signal from the distant past due to the reverse reactions , with the down - weighting of the signal from the recent past resulting from the multi - level character of the network ( see supplement ) . </S>",
    "<S> more generally , linear combinations of the weighting functions for reversible and irreversible cascades can be achieved with multiple cascades that are activated by the input in parallel and which independently activate the same effector molecule , as we demonstrate below . clearly , signaling networks allow for very diverse weighting functions .    </S>",
    "<S> this raises the question whether there exists an optimal weighting function @xmath52 that minimizes the error in the estimate of the ligand concentration . to this end </S>",
    "<S> , we differentiate eq . </S>",
    "<S> [ eq : sigma_c_2 ] with respect to @xmath53 using lagrange multipliers that constrain the integral of @xmath53 to 1 , to find the optimal ( normalized ) weighting function : @xmath54 the first term places equal weight on all prior values of the input , as assumed in previous studies @xcite . the second term , however , places greater weight on the first and last observed values of the signal , which are the two signal values that are the least correlated . </S>",
    "<S> indeed , this is the central result of this manuscript : the optimal weighting function does _ not _ correspond to uniform weighting of all signal values . </S>",
    "<S> how much weight is placed on the first and last points is determined by @xmath55 , which decreases from one to zero as the response time @xmath10 over the correlation time @xmath7 increases .    </S>",
    "<S> the optimal weighting function can be implemented using common network motifs . </S>",
    "<S> for example , the commonly observed feed - forward loop @xcite in fig . </S>",
    "<S> [ fig:2]g contains two branches which independently activate @xmath13 . </S>",
    "<S> the left branch , a one - level _ </S>",
    "<S> reversible _ cascade , amplifies later values of the signal ( @xmath56 ) ; the right branch , a multilevel _ irreversible _ cascade , amplifies earlier ( @xmath57 ) values of the signal . </S>",
    "<S> together , they produce a weighting function which selectively amplifies less correlated values of the input ( fig . </S>",
    "<S> [ fig:2 ] g , h ) , outperforming the uniform average that could be obtained by reading out node @xmath58 directly . </S>",
    "<S> this simple network illustrates how a spectrum of protein lifetimes and cascade levels can be used to shape weighting functions .    </S>",
    "<S> the optimal weighting function @xmath59 also provides the fundamental limit on the ability of linear signaling networks to measure chemical concentrations : @xmath60 = \\frac{\\sigma_{\\hat{c}}^2 [ s ] } { t_{\\rm{o}}/(2\\tau_{\\rm c})+1},\\ ] ] which is obtained by combining eqs . </S>",
    "<S> [ eq : sigma_c_2 ] and [ eq : f_opt ] . </S>",
    "<S> eq . </S>",
    "<S> [ eq : fundlim ] has a simple interpretation : a time series of length @xmath10 contains an independent observation every time period of the order of the correlation time , plus one corresponding to the observation at @xmath11 . </S>",
    "<S> eq . </S>",
    "<S> [ eq : fundlim ] is then the formula for the variance of the mean of @xmath61 independent , identically distributed random variables .    </S>",
    "<S> the improvement of the optimal weighting function over uniform weighting ( eq . </S>",
    "<S> [ eq : bp ] ) is maximal when the observation time is about three correlation times . </S>",
    "<S> the maximum improvement over the sample average is 12% ( fig . </S>",
    "<S> [ fig:2]f ) . </S>",
    "<S> while this improvement over the berg - purcell estimate is modest , and smaller than the 50% improvement that could in principle be obtained by maximum likelihood @xcite , it does show , for the first time , that simple signaling networks can indeed reach the berg - purcell limit , and even exceed it .    </S>",
    "<S> equally important , our analysis provides a clear perspective on the integration time . </S>",
    "<S> clearly , @xmath62 , the time on which the cell must respond , provides an upper bound on the integration time . yet , the processing network weights the input signal by @xmath63 , which may become zero for @xmath64 . in this case , the _ effective _ integration time @xmath65 is limited by the range over which @xmath63 is non - zero . </S>",
    "<S> for example , the weighting function of the one - level reversible cascade becomes zero on the time scale @xmath66 , the lifetime of the output component . </S>",
    "<S> this can be ( much ) smaller than @xmath62 , in which case @xmath65 is limited by @xmath67 : @xmath68 . </S>",
    "<S> essentially , degradation of the output erases memory of the input . </S>",
    "<S> however , our study of multi - level reversible cascades shows that in general the range over which @xmath36 is non - zero can be longer than the lifetime of the individual components . </S>",
    "<S> additional intermediate layers not only change the form of @xmath36 , but also extend the range over which it is non - zero , increasing the integration time over which the output remembers past signals ( see supplement ) .    </S>",
    "<S> values for the correlation time @xmath69 of the input signal and the observation time @xmath70 vary widely across biological systems . </S>",
    "<S> ligand - receptor half - lives , a key determinant of @xmath69 , vary at least over more than an order of magnitude , i.e. from milliseconds to an hour @xcite . </S>",
    "<S> the cell - cycle time provides an upper bound on @xmath70 @xcite ( e.g. 45 minutes in _ e. coli _ @xcite and 100 minutes in yeast @xcite ) , but signaling modules and transcriptional responses can make decisions sooner . </S>",
    "<S> indeed , @xmath70 is not always significantly larger than @xmath69 , so that the regime in which linear networks can beat the berg - purcell estimate is biologically relevant . </S>",
    "<S> for example , both the mapk response to egf stimulation @xcite and the nf-@xmath71b response to tnf stimulation @xcite peak on the time scale of ligand - receptor debinding ( 10 minutes @xcite and 30 minutes @xcite , respectively ) . </S>",
    "<S> additionally , correlation times for gene expression are of the order of the cell cycle time in both _ </S>",
    "<S> e. coli _ and human cells @xcite , suggesting the finite @xmath70 limit is also important for scenarios in which intracellular proteins act as receptors for intracellular signals @xcite .    </S>",
    "<S> interestingly , when @xmath72 , the equilibration time of the signal must be taken into account , since the equilibration time is , according to the fluctuation - dissipation theorem , given by the correlation time , at least when the change in @xmath0 is small . </S>",
    "<S> therefore , we end by studying how signaling networks can extract information from non - stationary signals . </S>",
    "<S> we study an input signal generated by @xmath73 with @xmath74 and forward and reverse rates @xmath75 and @xmath76 , respectively . </S>",
    "<S> this signal increases to its steady state value on a time scale @xmath77 , which also equals the steady - state correlation time @xmath7 . extending the procedure in eqs . </S>",
    "<S> [ eq : sigma_c_2 ] and [ eq : f_opt ] , the minimal estimation error with a linear signaling network is @xmath78 = \\frac{\\sigma_{\\hat{c}}^2 [ s ] } { t_{\\rm{o}}/(2 \\tau_{\\rm c } ) + \\ln \\left ( 2      -e^{-t_{\\rm{o}}/\\tau_{\\rm c}}\\right)/2}$ ] ( see supplement ) . </S>",
    "<S> this shows that less information can be extracted from non - stationary signals than from stationary ones . to avoid the detrimental effect of correlations , the optimal weighting function places more weight on the initial and final points , as for stationary signals </S>",
    "<S> however , because there is no information at @xmath11 , the amplification of early time points is spread over time points @xmath79 ( fig . </S>",
    "<S> s2 ) . additionally , the relative amplification of the last time point increases with decreasing @xmath10 . indeed , when @xmath80 , no previous signal values are sufficiently uncorrelated with the most recent one , and almost all weight is placed on the final time point @xmath81 .    </S>",
    "<S> we have studied the ability of linear signaling networks to extract information from noisy input signals . while the data processing inequality suggests that it is advantageous to limit the number of nodes in a signaling network to minimize the effect of intrinsic noise @xcite , here </S>",
    "<S> we show that there can be a competing effect , in terms of information processing , in favor of increasing the number of nodes : better removal of extrinsic noise . </S>",
    "<S> additional nodes make it possible to sculpt the weighting function for averaging the incoming signal , allowing signaling networks to reach and even exceed the berg - purcell limit . </S>",
    "<S> our predictions could be tested experimentally in a controlled setting by using _ in vitro _ or _ in vivo _ </S>",
    "<S> synthetic signaling networks @xcite . </S>",
    "<S> dual reporter constructs can be used to isolate the effects of extrinsic noise , studied in this letter , from noise intrinsic to the signaling machinery itself @xcite .    </S>",
    "<S> this work is part of the research program of the  </S>",
    "<S> ( fom ) \" , which is financially supported by the  organisatie voor wetenschappelijk onderzoek ( nwo ) . \" we thank andrew mugler and wiet de ronde for a careful reading of the manuscript .    </S>",
    "<S> 10    h.  c. berg and e.  m. purcell , biophys . </S>",
    "<S> j. * 20 * , 193 ( 1977 ) .    </S>",
    "<S> w. bialek and s. setayeshgar , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 102 * , 10040 ( 2005 ) .    </S>",
    "<S> k. wang , w .- j . </S>",
    "<S> rappel , r. kerr , and h. levine , phys . </S>",
    "<S> rev . </S>",
    "<S> e * 75 * , 061905 ( 2007 ) .    </S>",
    "<S> w .- j . </S>",
    "<S> rappel and h. levine , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 100 * , 228101 ( 2008 ) .    </S>",
    "<S> r.  g. endres and n.  s. wingreen , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 103 * , 158101 ( 2009 ) .    </S>",
    "<S> g. aquino and r.  g. endres , phys . </S>",
    "<S> rev . </S>",
    "<S> e * 81 * , 021909 ( 2010 ) .    </S>",
    "<S> b. hu , w. chen , w .- j . </S>",
    "<S> rappel , and h. levine , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 105 * , 048104 ( 2010 ) .    </S>",
    "<S> t. mora and n.  s. wingreen , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 104 * , 248101 ( 2010 ) .    </S>",
    "<S> p.  j.  m. van haastert and m. postma , biophys j * 93 * , 1787 ( 2007 ) .    </S>",
    "<S> m. skoge , y. meir , and n.  s. wingreen , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 107 * , 178101 ( 2011 ) .    </S>",
    "<S> r. heinrich , b.  g. neel , and t.  a. rapoport , mol . </S>",
    "<S> cell * 9 * , 957 ( 2002 ) .    </S>",
    "<S> e. ziv , i. nemenman , and c.  h. wiggins , plos one * 2 * , 1077 ( 2007 ) .    </S>",
    "<S> s. tanase - nicola , p.  b. warren , and p.  r. ten wolde , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 97 * , 068102 ( 2006 ) .    w.  h. de  ronde , f. tostevin , and p.  r. ten wolde , phys . rev . </S>",
    "<S> e * 82 * , 031914 ( 2010 ) .    </S>",
    "<S> f. tostevin and p.  r. ten wolde , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . * 102 * , 218101 ( 2009 ) .    </S>",
    "<S> g. tkacik , c.  g. callan , and w. bialek , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 105 * , 12265 ( 2008 ) .    </S>",
    "<S> j. paulsson , nature * 427 * , 415 ( 2004 ) .    </S>",
    "<S> r. milo _ </S>",
    "<S> et  al . _ , </S>",
    "<S> science * 298 * , 824 ( 2002 ) .    </S>",
    "<S> w .- j . </S>",
    "<S> rappel and h. levine , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 49 * , 19270 ( 2008 ) .    </S>",
    "<S> w.  h. de  ronde , ph.d . </S>",
    "<S> thesis , vrije universiteit , amsterdam , the netherlands , 2012 .    </S>",
    "<S> m. samoilov , a. arkin , and j. ross , j. phys . </S>",
    "<S> chem . </S>",
    "<S> a * 106 * , 10205 ( 2002 ) .    </S>",
    "<S> x. gao _ </S>",
    "<S> et  al . </S>",
    "<S> _ , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 108 * , 14509 ( 2011 ) .    </S>",
    "<S> d.  a. lauffenburger and j. linderman , _ receptors _ ( oxford university press , oxford , 1992 ) .    </S>",
    "<S> n. rosenfeld _ </S>",
    "<S> et  al . _ , </S>",
    "<S> science * 307 * , 1962 ( 2005 ) .    </S>",
    "<S> s.  d. talia _ </S>",
    "<S> et  al . _ , </S>",
    "<S> nature * 448 * , 947 ( 2007 ) .    </S>",
    "<S> b. schoeberl , c. eichler - jonsson , e.  d. gilles , and g. muller , nature biotech . </S>",
    "<S> * 20 * , 370 ( 2002 ) .    </S>",
    "<S> r. avraham and y. yarden , nat . </S>",
    "<S> rev . </S>",
    "<S> mol . </S>",
    "<S> cell bio . </S>",
    "<S> * 12 * , 104 ( 2011 ) .    </S>",
    "<S> r. cheong _ </S>",
    "<S> et  al . _ , science * 334 * , 354 ( 2011 ) .    </S>",
    "<S> m. grell , h. wajant , g. zimmerman , and p. scheurich , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 95 * , 570 ( 1998 ) .    </S>",
    "<S> a. sigal _ </S>",
    "<S> et  al . _ , </S>",
    "<S> nature * 444 * , 643 ( 2006 ) .    </S>",
    "<S> c.  j. bashor , a.  a. horwitz , s.  g. peisajovich , and w.  a. lim , annu . </S>",
    "<S> rev . </S>",
    "<S> biophys . * 39 * , 515 ( 2010 ) .    </S>",
    "<S> m.  b. elowitz , a.  j. levine , e.  d. siggia , and p.  s. swain , science * 297 * , 1183 ( 2002 ) .    c.  g. bowsher and p.  s. swain , proc . </S>",
    "<S> nat . </S>",
    "<S> acad . </S>",
    "<S> sci . * 109 * , e1320 ( 2012 ) . </S>"
  ]
}