{
  "article_text": [
    "the replica method @xcite for random spin systems has been successfully employed in neural network models of associative memory @xcite .",
    "however the replica method requires the concept of free energy . on the other hand , various types of neural network models which have no energy concept , such as a network with asymmetric synaptic coupling or temporally fluctuating synaptic coupling ,",
    "may be in existence .",
    "the self - consistent signal - to - noise analysis ( scsna ) @xcite , which is an alternative approach to the replica method for deriving a set of order parameter equations , requires no energy concept .",
    "thus it can be applicable to study the statistical properties of wider class of networks including networks without energy concept .",
    "the scsna , which was originally proposed for deriving a set of order parameter equations for a deterministic analog neural network with or without energy functions , becomes applicable to a stochastic network by noting that the tap equation defines the deterministic one equivalent to the original stochastic one .",
    "the scsna is closely related to the thouless - anderson - palmer ( tap ) equation @xcite via the concept of cavity method in the case where a network has energy concept @xcite and the relationship between the two was studied in detail in the networks with two - body and multi - body interactions @xcite .",
    "the coefficient of the onsager reaction term characteristic to the tap equation which determines the form of the transfer function is self - consistently obtained through the concept shared by the cavity method and the scsna .",
    "the tap equation is of our interest for studying the statistical properties of a network without energy concept .",
    "however the tap equations for a network with synaptic noise are not found in literatures .",
    "the main target of this paper is to derive the tap equation for a network with temporally fluctuating synaptic noise as _ multiplicative noise_.    the effects of such synaptic noise on the retrieval properties of networks have been studied in some recent works @xcite .",
    "according to the stochastic resonance theory @xcite , the temporally fluctuating synaptic noise may possibly be expected to reduce the interference of the uncondensed patterns on the retrieval property of the network ( noise in terms of stochastic resonance ) and , as a result , enhance the retrieval property or the storage capacity ( signal ) of the network .",
    "however such an argument is not found in literatures . to discuss the effect of temporally fluctuating synaptic noise on the retrieval property , it is important to construct a tractable model to study the role played by such synaptic noise .    in literatures ,",
    "the term `` synaptic noise '' is used in three meanings : ( i ) quenched disorder in synaptic couplings @xcite , ( ii ) randomness related to the dilution of synaptic couplings @xcite , and ( iii ) temporal fluctuation of synaptic couplings @xcite .",
    "we will use the term `` synaptic noise '' in the third meaning in the present paper .",
    "cortes @xcite ( see also @xcite ) investigated the case where neurons obey a master equation with continuous time and the synaptic couplings obey ( i ) slow dynamics @xcite , ( ii ) fast dynamics @xcite ( iii ) middle speed dynamics @xcite compared to the dynamics of neurons .",
    "in the first case , since the synaptic couplings obey slow dynamics , the adiabatic approximation for the synaptic couplings becomes exact in the limit where the time scale of synapse dynamics @xmath0 and quenched random noise in couplings again arises .",
    "thus the synaptic noise is regarded as the well - known quenched random variable and this type of synaptic noise has been studied as `` synaptic noise '' in many literatures @xcite .    in the second case , since the dynamics of the synaptic noise is sufficiently fast compared to the dynamics of neurons , one can define the effective strength of synaptic coupling by averaging the temporally fluctuating synaptic coupling @xcite . in this case",
    ", one can find the effective hamiltonian of the network and use well - known replica method @xcite to obtain the order parameters analytically @xcite .",
    "other example of the fast synaptic dynamics can be found in @xcite , which studies the properties of the equilibrium state of the system with stochastically evolving couplings .    on the other hand , the third case is difficult to deal with analytically especially in the case where the number of memory patterns is proportional to the total number of neurons and only numerical results based on computer simulations exist @xcite . in spite of these recent efforts to elucidate the effects of synaptic noise on the retrieval properties of neural networks ,",
    "such preceding studies have been based on the macroscopic viewpoint , where the order parameters solely have been investigated , and the tap equations for such cases have not been reported .",
    "the purpose of this paper is two - fold : ( i ) we will derive the tap equation for a stochastic analog network with temporally fluctuating multiplicative synaptic noise which is not found in literatures . ( ii )",
    "we will study the scsna and the tap equation for such a network to elucidate the effects of the multiplicative synaptic noise on the retrieval property from both microscopic and macroscopic viewpoint .",
    "part of this work is reported elsewhere @xcite .",
    "this paper is organized as follows : in the next section , we will describe an analog neural network model with temporally fluctuating synaptic noise as multiplicative noise which is assumed to be white noise to write down a set of langevin equations , and derive the corresponding fokker - planck equation .",
    "we will see that the equilibrium solution of the fokker - planck equation is given as a gibbs probability density with the effective temperature , which should be determined self - consistently in the thermodynamic limit .",
    "in section 3 , we will apply the cavity method to derive the formal expression of the tap equation ( pre - tap equation ) . then using the scsna",
    ", we will self - consistently obtain the concrete form of the transfer function which yields the complete form of the tap equation as well as a set of order parameter equations . in section 4",
    ", the phase diagram for our model will be shown .",
    "in the last section , we will conclude this paper .",
    "let us deal with the following stochastic analog neural network of @xmath1 neurons with temporally fluctuating synaptic noise : @xmath2 where @xmath3 ( @xmath4 ) represents a state of the neuron at site @xmath5 taking a continuous value , @xmath6 is a potential of an arbitrary form which determines the probability distribution of @xmath3 in the case without the input @xmath7 , @xmath8 the langevin white noise with its noise intensity @xmath9 and @xmath10 the synaptic coupling .",
    "we note here that , in the case of associative memory neural network , the synaptic coupling @xmath11 is usually defined by the well - known hebb learning rule .",
    "however some experimental results show that the synaptic couplings have temporal fluctuations which originate from the dynamics of neurotransmitters or kinetics of ion channels independent of that of neurons @xcite , and hence the effects of such synaptic noise may be relevant to the retrieval properties in realistic networks . to investigate such effects of synaptic noise , we assume the synaptic coupling taking the form : @xmath12 where @xmath13 is defined by the usual hebb learning rule @xmath14 with @xmath15 the number of patterns embedded in the network , @xmath16 is the @xmath17 embedded pattern at neuron @xmath5 , and @xmath18 denotes the synaptic noise independent of @xmath19 , which we assume in our model as white noise with its intensity @xmath20 for simplicity . notice that , in equation ( [ 1 ] ) , the synaptic noise behaves as _ multiplicative noise _ and the synaptic coupling @xmath10 is asymmetric .    noting @xmath21 by means of ito integral",
    ", we obtain the fokker - planck equation corresponding to the langevin equation ( [ 1 ] ) as @xmath22 where @xmath23 .",
    "since the self - averaging property holds in the thermodynamic limit @xmath24 , one can identify @xmath25 as @xmath26 where @xmath27 represents the thermal average with respect to @xmath28 .",
    "thus equation ( [ fpe ] ) is found to be a nonlinear fokker - planck equation whose diffusion coefficient @xmath29 depends on the probability density @xmath28 @xcite . in this paper",
    "we are concerned with deriving the tap equation and order parameter equations for the equilibrium state self - consistently .",
    "furthermore the order parameter @xmath25 is also obtained self - consistently in our framework as seen below .",
    "supposing @xmath25 is given , the fokker - planck equation ( [ fpe ] ) turns to be a linear equation and one can easily find the equilibrium probability density for the linear fokker - planck equation ( [ fpe ] ) as @xmath30 where @xmath31 denotes the normalization constant and @xmath32 plays the role of the _ effective temperature of the network_. notice that the temperature of the system is modified to @xmath33 as a consequence of the multiplicative noise and it depends on the order parameter @xmath25 . here",
    "it is easily checked that the equilibrium distribution of the system becomes gibbs distribution in the thermodynamic limit @xmath24 .    since we have explicitly written down the equilibrium probability distribution density ( [ eqprob ] ) as a form of gibbs distribution",
    ", one can define the ( effective ) hamiltonian of @xmath1-body system as @xmath34 then regarding the original network with multiplicative noise ( [ 1 ] ) as an analog version of the standard hopfield model whose hamiltonian is given by equation ( [ hamiltonian ] ) with the effective temperature @xmath33 , one can apply the usual cavity method @xcite to this system and derive the ( pre-)tap equation .",
    "we have obtained the equilibrium probability density as a form of gibbs distribution ( [ eqprob ] ) and the effective hamiltonian ( [ hamiltonian ] ) in the previous section .",
    "thus the cavity method @xcite , which is usually applied to the network models for deriving the tap equation , is applicable for our model . according to the cavity method",
    ", we divide the hamiltonian of @xmath1-body system ( [ hamiltonian ] ) into that of @xmath35-body system and the part involving in the state of @xmath36 neuron as @xmath37 where @xmath38 is the local field at site @xmath5 and the hamiltonian of @xmath35-body system @xmath39 is given as @xmath40 .",
    "then the marginal probability density distribution of @xmath3 and the local field @xmath41 is given as @xmath42\\delta\\left ( h_{i}-\\sum_{j(\\neq i)}\\bar{j}_{ij}x_{j } \\right ) p_{n}({\\mathbf x})\\nonumber\\\\ & = & \\tilde{z}^{-1}\\exp\\left\\{\\ -\\beta_{\\mathrm{eff}}\\left [ \\phi ( x_{i})-h_{i}x_{i}\\right]\\right\\ } p_{n-1}(h_{i})\\ , , \\nonumber\\end{aligned}\\ ] ] where @xmath43 is the normalization constant and @xmath44 denotes the probability density of the local field @xmath41 in the @xmath35-body system defined as @xmath45\\delta\\left ( h_{i}-\\sum_{j(\\neq i)}\\bar{j}_{ij } x_{j}\\right)\\exp\\left [ -\\beta_{\\mathrm{eff}}h_{n-1}\\right]\\ , , \\nonumber\\end{aligned}\\ ] ] where @xmath46 denotes the normalization constant .",
    "since the local field is given as the summation of a sufficiently large number of random variables and their cross - correlations are expected to be @xmath47 , one can expect that @xmath44 turns out to be a gaussian density in the thermodynamic limit @xmath24 according to the central limit theorem : @xmath48\\ , , \\nonumber\\end{aligned}\\ ] ] where @xmath49 represents the thermal average with respect to the @xmath35-body probability density @xmath50 and @xmath51 is the variance of @xmath44 , which is evaluated later self - consistently in the framework of the scsna . then taking the average of @xmath3 with respect to the marginal probability @xmath52 straightforwardly yields @xmath53 where @xmath54 is a transfer function defined as @xmath55\\right\\}}{\\int dx\\,\\exp\\left\\ {   -\\beta_{\\mathrm{eff } } \\left[\\phi ( x)-yx-\\frac{\\beta_{\\mathrm{eff}}\\sigma^{2}}{2}x^{2 } \\right]\\right\\}}\\ , .\\label{f}\\end{aligned}\\ ] ] similarly @xmath56 is obtained as @xmath57 thus we have the pre - tap equation @xmath58 where @xmath59 . since the concrete form of the transfer function @xmath54 depends on the effective temperature @xmath60 and the variance of the local field @xmath51 ,",
    "it is necessary to obtain @xmath60 and @xmath51 to have the tap equation @xcite .",
    "equation ( [ pretap ] ) is regarded as defining a deterministic analog network corresponding to the original stochastic one ( [ 1 ] ) , and hence we can apply the scsna to equation ( [ pretap ] ) to determine @xmath60 and @xmath51 self - consistently as was studied for the case without synaptic noise @xcite . for simplicity ,",
    "we here assume that the only one condensed pattern @xmath61 is retrieved .",
    "the extension to the case of an arbitrary finite number of condensed patterns is straightforward . using the overlap order parameter @xmath62 ,",
    "the equilibrium average of the local field is rewritten as @xmath63 using the scsna , the above local field can be rewritten as @xcite @xmath64 where @xmath65 , @xmath66 and @xmath67 is a gaussian random variable with zero mean . as seen below , we will evaluate the overlap @xmath68 self - consistently , and then obtain @xmath67 and @xmath69 through the equivalence between the expression of the local field ( [ locfield ] ) and ( [ loc ] ) . substituting equation ( [ loc ] ) into the pre - tap equation ( [ pretap ] )",
    "reads @xmath70 and comparing this equation with equation ( [ nm1 ] ) yields @xcite @xmath71 since @xmath56 is considered to be a gaussian random variable which should not contain the onsager reaction term . noting that @xmath72 for @xmath73 , one can obtain the overlap for uncondensed patterns as @xmath74 where @xmath75 denotes the derivative of the transfer function @xmath54 and the order expansion of @xmath54 with respect to @xmath76 has been applied to @xmath77 . using equation ( [ mmu ] ) and the definitions of @xmath67 and @xmath69 , one finds @xmath78 thus the variance of @xmath67 is evaluated as @xmath79 where @xmath80 represents the average over a random variables @xmath81 and the gaussian variable @xmath82 , and the self - averaging property has been used .",
    "similarly one obtains the set of order parameter equations as @xmath83 in the case where the multiplicative synaptic noise does not exist or the intensity of the synaptic noise is zero , i.e. , @xmath84 , the set of order parameter equations ( [ sigma ] ) , ( [ m ] ) , ( [ u ] ) , ( [ gamma ] ) takes a closed form and determines the form of the transfer function @xmath54 as well as the order parameters self - consistently . for the case with multiplicative noise , however , it does not suffice to determine the form of the transfer function .",
    "we need the order parameter @xmath25 , which determines @xmath60 , as well as @xmath85 , @xmath86 , @xmath87 , @xmath88 to determine the concrete form of @xmath54 .",
    "since @xmath25 is related to the macroscopic susceptibility of the system and , by definition of @xmath54 ( [ f ] ) , the order parameter @xmath86 corresponds with the susceptibility as @xmath89 , one finds @xmath90 the set of equations ( [ 5.5 ] ) , ( [ sigma ] ) , ( [ m ] ) , ( [ u ] ) , ( [ gamma ] ) , ( [ qhat ] ) takes a closed form and thus one can determine the form of @xmath54 self - consistently as well as the set of order parameters . therefore substituting into the pre - tap equation ( [ pretap ] ) the solutions @xmath60 and @xmath88 that are self - consistently obtained within this framework yields the tap equation .",
    "we have derived the tap equation as well as the set of order parameter equations in the previous section . in this section",
    "we show the phase diagram by solving the set of order parameter equations ( [ sigma ] ) , ( [ m ] ) , ( [ u ] ) , ( [ gamma ] ) , ( [ qhat ] ) numerically and investigate the effect of the multiplicative synaptic noise .    for the well - known transfer function of the ising neurons @xmath91 , it is easy to understand the effects of the interference of the synaptic noise .",
    "this choice of the transfer function is equivalent to taking the potential @xmath92 as @xmath93}{\\int\\ , \\exp\\left [ -\\beta_{\\mathrm{eff}}\\phi ( x)\\right]\\ , dx } =   \\frac{1}{2}\\delta ( x-1)+\\frac{1}{2}\\delta ( x+1)\\ , .\\nonumber\\end{aligned}\\ ] ] in the ising neuron model , since @xmath25 is simply given as @xmath94 and @xmath95 , the retrieval state vanishes for @xmath96 according to the results of amit - geutfreund - sompolinsky ( ags ) @xcite .    in this section , for simplicity ,",
    "we consider the double - well potential whose minima are located at @xmath97 : @xmath98 where @xmath99 determines the depth of the wells of the potential .",
    "this potential yields a continuous distribution of neuron states and thus defines an _ analog _ network model in which @xmath25 is non - trivial .",
    "we investigate a phase diagram for the _ analog _ network model and elucidate the effects of the multiplicative noise on the retrieval properties .",
    "storage capacity @xmath100 as a function of the intensity of the external noise @xmath101 for various values of @xmath102 .",
    "the solid curve denotes the storage capacity for @xmath103 .",
    "the broken ( ) , dashed ( ) and dotted ( ) curves represent the storage capacity for @xmath104 , @xmath105 , @xmath106 , respectively .",
    "the retrieval state locates below the curve and vanishes at @xmath107 .",
    "we set @xmath108 . ]",
    "@xmath100-dependence of the overlap @xmath85 obtained from the scsna ( solid curve ) together with that from numerical simulations with @xmath109 ( dots ) .",
    "the potential is given by equation ( [ pot ] ) with @xmath108 .",
    "the intensities of additive and multiplicative synaptic noise are @xmath110 and @xmath111 respectively . ]",
    "distribution of the thermal average of the state of neurons , or the local magnetization with parameters @xmath110 , @xmath111 , @xmath112 , @xmath108 . from figure [ fig2 ]",
    "this parameter set locates in the non - retrieval phase .",
    "this distribution shows that the non - retrieval spin glass phase arises in this regime . ]",
    "figure [ fig1 ] illustrates the storage capacity @xmath100 as a function of the intensity of the external noise @xmath101 .",
    "the solid line is for the absence of the synaptic noise , i.e. , @xmath103 .",
    "the line in figure [ fig1 ] denotes the numerical solution of the order parameter equations for each intensity of the synaptic noise @xmath103 , @xmath113 , @xmath105 , @xmath106 and the retrieval state vanishes at @xmath107 for @xmath108 .",
    "the @xmath100-@xmath101 line for the _ analog network _ is deformed compared to the ising networks .",
    "this is the effect of potential properties and the _ effective temperature _ , or the _ non - trivial order parameter _",
    "@xmath25 , while @xmath94 for ising neurons .",
    "we can see that the storage capacity is incrementally decreased as the intensity of the synaptic noise increases .",
    "this result is reasonable since the memories are encoded in the synaptic coupling as local minima of the _ effective _ free energy corresponding to equation ( [ eqprob ] ) and the synaptic noise is expected to disturb the fine structure of the energy landscape .",
    "figure [ fig2 ] displays the @xmath100-dependence of the overlap @xmath85 obtained from the scsna together with that from numerical simulations with @xmath109 .",
    "we can see that the overlap @xmath85 decreases as the number of embedded patterns @xmath100 increases and retrieval state vanishes ( @xmath114 ) at @xmath115 .",
    "figure [ fig3 ] illustrates the distribution of the thermal average of the state of neurons , or the local magnetization @xmath116 at @xmath110 , @xmath111 , @xmath117 , @xmath108 obtained from numerical simulations with @xmath109 .",
    "we can see from figure [ fig2 ] that the overlap @xmath114 in this regime .",
    "however the local magnetizations @xmath116 s are seen to distribute around @xmath118 .",
    "this means that a spin glass phase arises in this regime .",
    "we can also show the existence of the non - retrieval spin glass phase analytically by solving the set of order parameter equations ( [ 5.5 ] ) , ( [ sigma ] ) , ( [ m ] ) , ( [ u ] ) , ( [ gamma ] ) and ( [ qhat ] ) . since @xmath114 in the non - retrieval phase ,",
    "the order parameter equations ( [ sigma ] ) and ( [ u ] ) become @xmath119 where @xmath120 denotes the average with respect to the gaussian random variable @xmath82 . for the non - retrieval phase @xmath114 , it is trivial that the order parameter equation @xmath121 holds . by definition of the transfer function @xmath54 ,",
    "the order parameter @xmath86 is rewritten as @xmath122 where @xmath123 is the edward - anderson order parameter .",
    "the set of order parameter equations ( [ 5.5 ] ) , ( [ gamma ] ) , ( [ qhat ] ) , ( [ sigmasg ] ) , ( [ usg ] ) , ( [ qsg ] ) takes a closed form .",
    "thus we can find the non - retrieval spin glass phase by solving these equations to obtain @xmath124 . since the edward - anderson order parameter @xmath125 is expected to be small in the regime close to the paramagnetic phase , the taylor expansion with respect to @xmath125 is applicable for these order parameter equations to illustrate the paramagnetic ( @xmath126)-spin glass ( @xmath124 ) phase boundary .",
    "this boundary is expected to correspond to the de almeida - thouless ( at ) line .",
    "the study on the relationship between the scsna and the replica symmetry breaking is underway .",
    "we have derived the tap equation for a stochastic analog neural network with temporally fluctuating multiplicative synaptic noise , which is not found in literatures .",
    "more specifically , we have derived the tap equation together with the set of order parameter equations by using the scsna and the cavity method .",
    "our original model _ does not _ have the concept of free energy .",
    "since the self - averaging property holds in the thermodynamic limit @xmath24 , we have found that the nonlinear fokker - planck equation ( [ fpe ] ) becomes quasi - linear to allow one to obtain equilibrium probability density obeying the gibbs one with effective temperature and hence that the network with white synaptic noise has the _ effective _ hamiltonian in the large @xmath1 limit .",
    "thus the cavity method , which is applicable to the model with energy concept , becomes available to obtain the ( pre-)tap equation .",
    "unlike the case without synaptic noise , the concrete form of the transfer function @xmath54 of our model has been found to depend not only on the coefficient of the onsager reaction term but on the order parameter @xmath25 .",
    "@xmath25 as well as the coefficient of the onsager reaction term have been obtained self - consistently within the framework of the scsna .",
    "the full tap equation straightforwardly follows from the pre - tap equation by substituting the solutions of the order parameter equations into the pre - tap equation ( [ pretap ] ) .",
    "furthermore , we have found that the storage capacity of the network gradually decreases as the intensity of the synaptic noise increases , since the fine structure of the energy landscape tends to disappear by the interference of the synaptic noise .",
    "this effect of the interference of the synaptic noise on the behavior of the retrieval property has been shown to appear via the effective temperature @xmath127 .",
    "all the results presented in this paper are obtained via the cavity method and the scsna . on the other hand ,",
    "the order parameter equations ( [ sigma ] ) , ( [ m ] ) , ( [ u ] ) , ( [ gamma ] ) , ( [ qhat ] ) can be reproduced as replica symmetric case by the replica method , since the system has the effective hamiltonian ( [ hamiltonian ] ) .",
    "thus our results are expected to be exact within the replica symmetric approximation .",
    "however , the development of the analysis in the framework of the scsna for replica symmetry breaking solutions is now underway .    in other works dealing with the temporal fluctuation in synaptic couplings @xcite , the authors study the case of the fast synapse dynamics .",
    "then the synaptic coupling is modified to take the form of `` effective synaptic coupling '' and the system becomes to have an effective hamiltonian . in this case",
    "the `` effective synaptic coupling '' is _ straightforwardly determined _ by both the number of embedded patterns and the intensity of langevin noise associated with neuron dynamics .",
    "on the other hand , the time scale of fluctuation of synaptic coupling in our model is _ comparable to that of the neuron dynamics_. our model results in having the `` effective temperature '' and hence the effective hamiltonian in the thermodynamic limit .",
    "however , in our model , the `` effective temperature '' is _ determined only self - consistently _ together with the other order parameters .    in this paper",
    "we have dealt with a network subjected to asymmetric multiplicative synaptic noise given as white noise involving both pre- and post - neuron and the noise has no correlation with the synaptic coupling given by the hebb learning rule .",
    "however some other versions of synaptic noise may be considered : ( i ) synaptic noise depending only on pre- or post - neuron ,",
    "( ii ) synaptic noise correlated with the hebb learning rule ,",
    "( iii ) colored synaptic noise .",
    "for some of these cases , one can rigorously derive the tap equation and the set of order parameter equations similarly to the case we have seen in this paper .",
    "the analysis for such cases will be reported elsewhere .",
    "this work was supported by a 21st century coe program at tokyo tech `` nanometer - scale quantum physics '' by the ministry of education , culture , sports , science and technology .",
    "99 sherrington d and kirkpatrick s 1975 _ phys . rev .",
    "lett . _ * 35 * 1792 mzard m , parisi g and virasoro m a 1987 _ spin glass theory and beyond _",
    "( singapore : world scientific ) amit d j , geutfreund h and sompolinsky h 1985 _ phys . rev .",
    "lett . _ * 55 * 1530 shiino m and fukai t 1992 _ j. phys .",
    "gen . a _ * 25 * l375 shiino m and fukai t 1993 _ phys . rev .",
    "e _ * 48 * 867 shiino m and yamana m 2004 _ phys .",
    "e _ * 69 * 011904 thouless d j , anderson p w and palmer r g 1977 _ philos . mag . _ * 35 * 593 morita t and horiguchi t 1976 _ solid . state .",
    "* 833 ichiki a and shiino m 2006 _ phys . rev .",
    "e _ * 74 * 017103 garrido p l and marro j 1991 _ lecture notes in computer science _ * 540 * 25 marro j , torres j j and garrido p l 1999 _ j. stat .",
    "* 94 * ( 1 - 6 ) 837",
    "garrido p l and marro j 1994 _ j. stat . phys . _ * 74 * 663 torres j j ,",
    "garrido p l , and marro j 1997 _ j. phys . a : math .",
    "7801 gammaitoni l , hanggi p , jung p and marchesoni f 1998 _ rev .",
    "phys . _ * 70 * 223 benzi r and vulpiani a 1981 _ j. phys .",
    "* 14 * l453 nicolis c and nicolis g 1981 _ tellus _ * 33 * 225 sompolinsky h 1986 _ phys .",
    "a _ * 34 * 2571 treves a and amit d j 1988 _ j. phys .",
    "a _ * 21 * 3155 amari s 1972 _ ieee trans .",
    "syst . man .",
    "* 2 * 643 hopfield j j 1982 _ proc .",
    "usa _ * 79 * 2552 gardiner c w 2004 _ handbook of stochastic methods : for physics , chemistry and the natural sciences _",
    "( berlin : springer - verlag ) cortes j m , torres j j , marro j , garrido p l and kappen h j 2006 _ neural comp . _ * 18 * 614 pantic l , torres j j , kappen h j and gielen s c a m 2002 _ neural comp . _",
    "* 14 * 2903 cortes j m , garrido p l , marro j and torres j j 2004 _ neurocomputing _ * 58 * -*60 * 67 choi m y , park k and shim g m 1993 _ j. phys . a : math .",
    "_ * 26 * 3697 marro j and dickman r 1999 _ nonequilibrium phase transitions in lattice models _ ( cambridge : cambridge university press ) uezu t and coolen a c c 2002 _ j. phys . a : math .",
    "gen . _ * 35 * 2761 ; private communication with uezu t ichiki a and shiino m to appear in _ physica e _ anderson c r , cull - candy s g and miledi r 1978 _ j. physiol .",
    "_ * 282 * 219 frank t d 2005 _ nonlinear fokker - planck equations : fundamentals and applications _",
    "( berlin : springer - verlag ) shiino m 1987 _ phys .",
    "a _ * 36 * 2393"
  ],
  "abstract_text": [
    "<S> effects of synaptic noise on the retrieval process of associative memory neural networks are studied from the viewpoint of neurobiological and biophysical understanding of information processing in the brain . </S>",
    "<S> we investigate the statistical mechanical properties of stochastic analog neural networks with temporally fluctuating synaptic noise , which is assumed to be white noise . such networks , in general , defy the use of the replica method , since they have no energy concept . </S>",
    "<S> the self - consistent signal - to - noise analysis ( scsna ) , which is an alternative to the replica method for deriving a set of order parameter equations , requires no energy concept and thus becomes available in studying networks without energy functions . </S>",
    "<S> applying the scsna to stochastic network requires the knowledge of the thouless - anderson - palmer ( tap ) equation which defines the deterministic networks equivalent to the original stochastic ones . </S>",
    "<S> the study of the tap equation which is of particular interest for the case without energy concept is very few , while it is closely related to the scsna in the case with energy concept . </S>",
    "<S> this paper aims to derive the tap equation for networks with synaptic noise together with a set of order parameter equations by a hybrid use of the cavity method and the scsna . </S>"
  ]
}