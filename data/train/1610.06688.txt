{
  "article_text": [
    "multispectral imaging systems have emerged as a new technology that is able to deal with various problems encountered with broadband systems .",
    "the development of new cameras and filters enables us to see beyond the visible spectrum such as in the infrared [ 700nm-1 mm ] , ultraviolet [ 10nm-380 nm ] , x - ray [ 0.01nm-10 nm ] spectrums .",
    "a multispectral image is a set of several monochrome images of the same scene , each of which is taken at a specific wavelength .",
    "each monochrome image is referred to as a band or channel .",
    "a multispectral image may be seen as a three dimensional image cube with two spatial dimensions consisting of the vertical and horizontal axes , and a spectral third dimension .",
    "a monochrome image has one spectral band where each pixel is represented by one scalar value .",
    "a multispectral image consists of at least two bands .",
    "a pixel is represented by a vector of @xmath0 components where @xmath0 is the number of spectral bands . in that sense ,",
    "a color image may be seen as a multispectral image with three spectral bands .",
    "however , the term `` multispectral '' is commonly used for images with more than three spectral bands .",
    "images with more than a hundred bands are commonly called hyperspectral images . using multispectral images is justified by two main reasons .",
    "first , narrow spectral bands exhibit more relevant information compared with conventional broadband color and black and white images .",
    "indeed , we obtain a unique spectral signature of the objects being captured .",
    "such information can be used to enhance the accuracy of image processing applications .",
    "second , by using multispectral images , we are able to separate the illumination information from object reflectance , in contrast to broadband images where it is almost impossible to do so .",
    "this separated information can now be used to normalize images .",
    "for instance , in face recognition applications , near - infrared spectral band can be combined with the visible image .",
    "this approach has been widely used to construct more effective biometric systems @xcite .",
    "thermal infrared images have also been widely used .",
    "thermal infrared sensors detect the heat energy radiated from the face which is independent from the illumination as in the case of reflectance @xcite . furthermore , thermal infrared is less sensitive to scattering and absorption by smoke or dust and invariant in case of illumination change @xcite .",
    "it also allows to reveal anatomical information which is very useful in detecting disguised faces @xcite .",
    "the quality of a multispectral image has great implications on the efficiency of image processing applications .",
    "environmental corruption such as noise and blur is a common phenomena for any captured images due to many factors . in particular",
    ", a multispectral image can be subject to quality degradation due to the imperfectness of sensors @xcite . particularly , noise is inevitable in all real broadband and multichannel images .",
    "thus , it is essential to have techniques that ensure noise removal to adequate levels in order to increase performance in many image processing applications such as classification and segmentation @xcite.in our work , we propose an improved version of the nlm filter called optimized vector nlm ( ovnlm ) , where we take into account the spectral dimension of data .",
    "in fact , the nlm denoising filter exploits the redundancy of information in image . in this paper , we propose an optimization approach to tune the filter parameters .",
    "these parameters are optimized using stein s unbiased risk estimator ( sure ) rather than using ad hoc means .",
    "furthermore , we propose a modification to the nlm filter in order to improve its performance . indeed",
    ", the ovnlm is proposed to attenuate the computational complexity of the nlm filter by considering only pixels which are most similar to each other in computing a restored pixel .",
    "this attenuation is achieved using a similarity measure based on a probabilistic approach . in section 2 , we present an overview of the previous works related to multispectral image denoising and give more details about our contribution .",
    "section 3 summarizes the nlm filter and describes the proposed ovnlm filter . in section 4",
    ", we present experimental results of our framework and compare them with similar schemes performed on multispectral images .",
    "conclusions are drawn in section 5 .",
    "several techniques have been proposed to tackle the problem of multispectral image denoising . the work of luisier et al .",
    "@xcite represents the state of the art in multispectral image denoising .",
    "authors proposed a denoising algorithm parameterized as a linear expansion of thresholds @xcite .",
    "optimization is carried out using stein s unbiased risk estimator ( sure ) @xcite .",
    "the thresholding function is point wise and wavelet based .",
    "a non - redundant orthonormal wavelet transform is applied on the noisy input image .",
    "next , a vector - valued thresholding of individual multichannel wavelet coefficients is performed .",
    "finally , an inverse wavelet transform is applied to obtain the denoised image .",
    "the application of an orthonormal wavelet transform is justified by two main properties .",
    "first , assuming a white gaussian noise in the image domain @xmath1 , its wavelet coefficients remain also gaussian and are independent between subbands .",
    "second , the mean square error ( mse ) in @xmath1 is equal to the sum of subbands mses.another sure based approach was proposed in @xcite .",
    "authors used a generalized form of shrinkage estimate .",
    "the optimal choice of parameters is based on the minimization of the quadratic risk or mse that depends on the original data which is unknown .",
    "parameters are chosen so as to minimize the obtained risk .",
    "note that the proposed denoising framework was built around a wavelet - based approach .",
    "two decomposing schemes were proposed : a decimated m - band wavelet transform and an m - band dual - tree wavelet decomposition . for each case , the associated estimator is obtained.another scheme was proposed in @xcite .",
    "the algorithm which jointly removes noise and blur from images is based on the expectation and maximization ( em ) algorithm @xcite .",
    "the noisy signal is decomposed into two independent parts : the first one represents the blurring problem while the second represents the denoising one .",
    "the latter is performed in wavelet domain .",
    "a gaussian scale mixture is used to model the probability density of the wavelet coefficients . besides that , a coregistered auxiliary noise - free image of the same scene is included in the framework to improve the restoration process .",
    "in fact , this inclusion provides an extra prior information to the model . in @xcite , authors proposed a partial differential equation denoising system based on the total variation ( tv ) denoising method used in @xcite which proposes to minimize an objective function . for this , authors used the time marching method @xcite .",
    "the denoising task is then reduced to a partial differential equation ( pde ) problem .",
    "authors injected in this pde problem an auxiliary image as a prior .",
    "this approach is justified by the fact that edge directions and texture information of the auxiliary image are similar to those of the noisy image .",
    "thus , a smoothing term that takes into account the contribution of this prior information is added .",
    "although this approach offered better noise smoothing and details conservation , the availability of a reference image as a prior is not straightforward .",
    "a non - local multidimensional tv model has been recently proposed in @xcite .",
    "authors presented the denoising problem as a minimization of a mean square cost function that depends on a regularization term .",
    "the non - local property is not restricted to patches from one band but also to other bands with high correlation .",
    "thus , for a given pixel , the similarity between patches from other bands is considered in the computation of the weight .",
    "the multichannel image is first divided into many groups . for a given band ,",
    "bands with high correlation are grouped together .",
    "in addition , the regularization parameters are computed adaptively for each band and derived from the estimated noise standard deviation using the coefficient of the highest frequency wavelet subband .",
    "the obtained minimization problem is solved using bregmanized operator splitting @xcite which introduces an auxiliary variable .",
    "the unconstrained problem is treated using bregman iteration method which leads to an update algorithm where gauss - seidel and shrinkage methods are used .",
    "the proposed framework was jointly used for multichannel image denoising and inpainting . although the non - local approach offers good denoising performance , it is still computationally expensive and memory space consuming . in @xcite , zhao",
    "et al proposed a denoising framework based on sparse presentation and low rank constraint .",
    "authors analyzed the difference in rank between a clean and a noisy image and concluded that the rank of the clean image is far smaller than the size of the multichannel image .",
    "however , this is not true for the noisy image .",
    "thus , an assumption is made : a low rank is a characteristic of a noise free multichannel image .",
    "this information is incorporated in the cost function .",
    "furthermore , the cost function requires patch extraction . to avoid the problem of curse of dimensionality and large error",
    ", authors suggested to reshape the 3d spectral cube into a 2d matrix by converting each band into a vector , then patches are extracted .",
    "the optimization with respect to some variables is carried out by fixing some other variables .",
    "the overall complexity of this approach is @xmath2 where @xmath3 and @xmath4 are the height and length of the spatial dimension .",
    "although good denoising performance was obtained , this approach does nt perform well in the presence of high level of noise since it is based on dictionary learning for sparsity representationyuan et al .",
    "studied in @xcite the noise in multichannel images , and concluded that there are two types of noise distributions : one distribution in spatial domain and one in spectral domain .",
    "thus , two tv models are used : one applied for multichannel image denoising in spatial domain and the other one is applied in the spectral domain .",
    "the two models are both optimized with the split bregman method where the regularization parameter is selected as the one with highest mean peak signal - to - noise ratio and structural similarity index .",
    "authors studied also the complementary nature of both schemes and concluded that both denoising results can complement each other and that a fusing process can bring additional improvements . by using the metric @xmath5",
    "proposed in @xcite , a fusion scheme between bands from each denoising result is proposed and the final denoised multichannel image is obtained .",
    "this approach exhibited good denoising performance but can be improved by adaptively adjusting the regularization parameter on which the denoising performance is highly dependent .",
    "yuan et al . in @xcite",
    "proposed also another denoising method where the regularization term in the cost function is often approached by a kernel model .",
    "however , this approach has three main drawbacks when applied for multichannel image denoising .",
    "first , the spectral information is not considered .",
    "second , since the spatial resolution is lower than the spectral resolution , this approach is inefficient .",
    "finally , noise differs from one band to another .",
    "this fact is not considered .",
    "given these challenges , authors suggested two strategies . in the first one ,",
    "a spectral - spatial kernel model is considered where the spatial and spectral information are simultaneously used . in the second",
    "one , noise distributions in spectral bands are considered different and a local kernel is used to balance the contributions between bands .",
    "however , the regularization parameter which balances the contribution between the regularization term and fidelity term is not adaptively estimated . in @xcite , authors proposed a denoising framework based on the bayesian least squares optimization problem .",
    "this framework requires the computation of the posterior distribution based on monte carlo sampling @xcite .",
    "given the noisy pixel , the procedure starts by choosing some neighbor pixels .",
    "then , the acceptance probability of the sampled pixel given the noisy one is used to decide whether the sampled pixel is to be considered or not .",
    "this decision is based on a comparison between the acceptance probability and the random variable drawn from the uniform distribution . after selecting sample pixels ,",
    "the importance - weighted monte carlo posterior estimate is computed using the weighted histogram approach proposed in @xcite , then finally the denoised pixel is obtained .",
    "peng et al . proposed in @xcite a vector version of the bilateral filter .",
    "the basic assumption behind this filter is that pixels which have influence on the restored pixels are not just neighbor pixels but neighbor pixels with similar values .",
    "typically , in a similar way to gaussian filter , bilateral filter is defined as a weighted average of neighbor pixels . however , in order to preserve edges , the difference in value with the neighbor pixels is taken into account . in their work ,",
    "peng et al . extended the bilateral filter to the vector form .",
    "the dissimilarity measure is now expressed as a multivariate gaussian function . for simplification purposes and to avoid the computation of the noise covariance matrix , data are projected into subspace using principle component analysis ( pca ) , and noise variance of individual channels is computed using the median absolute deviation method @xcite . however",
    ", this ad hoc method makes the results enormously dependent on the choice of filter parameters .",
    "authors in @xcite proposed an optimization framework for the vector bilateral filter using sure .",
    "they proved that within a neighborhood of a given edge pixel , a high signal to error ( ser ) measure is obtained by maximizing the weight attributed to neighbor pixels with similar values and minimizing the weight given to pixels with significant different values .",
    "authors have also demonstrated that the ser of the vector version of the bilateral filter is always greater than the component wise 2d bilateral filter .",
    "the optimization scheme is based on the minimization of the mse . however , the underlying difficulty of this measure is that it involves the original image which is unknown .",
    "mse is seen as a random variable that depends on the noise .",
    "its expected value is called the risk . to overcome this issue ,",
    "filter parameters are obtained by minimizing the unbiased risk expression of the sure estimator .",
    "the obtained minimization problem is non - linear and is solved numerically using sequential quadratic programming ( sqp ) .",
    "experiments on color and multispectral images have been conducted and comparison using the peak signal to noise ratio ( psnr ) is presented .",
    "maggioni et al .",
    "@xcite presented an extension to the bm3d denoising algorithm @xcite called bm4d .",
    "based on the paradigm of grouping and collaborative filtering , cubes of voxels are stacked and processed in the transform domain which exploits correlation within cubes and the non - local correlation between the corresponding voxels of different cubes .",
    "this approach leads to an effective separation between signal and noise through coefficient shrinkage .",
    "peng et al .",
    "@xcite proposed the tdl algorithm .",
    "authors focused on the spatial non - local similarity and the spectral correlation of multispectral images .",
    "a non - local tensor dictionary learning model is developed .",
    "this model is constrained by group - block sparsity .",
    "in addition , the proposed model is decomposed into a series of low - rank tensor approximation problems .",
    "these problems are approached using higher - order statistics .",
    "manjon et al .",
    "@xcite have recently proposed a new algorithm for multispectral image denoising based on the non - local mean ( nlm ) filter @xcite .",
    "nlm filter is designed so that it takes advantage of the redundancy exhibited in the image .",
    "this redundancy is no longer pixel based but window based . in other words , every small window centered on a pixel is supposed to have many similar windows .",
    "these windows can be located anywhere in the image domain @xmath1 and are no longer restricted to the neighborhood . in the multispectral framework ,",
    "information from various bands are combined and a new weight is proposed",
    ". also nlm filter is very effective , it is highly dependent on the choice of three parameters : the radius of the search window , the radius of the neighborhood window and a smoothing parameter that controls the degree of the smoothing .",
    "the latter is very important . indeed , with a small value",
    ", little noise will be removed . on the other hand , with a high value",
    ", the image will be blurred .",
    "authors have set these parameters manually .",
    "motivated by the successful applications of nlm filter in image denoising and details preservation compared to other filters ( e.g. bilateral ) , we propose a modified version of the nlm filter called optimized vector nlm ( ovnlm ) filter .",
    "our contribution consists in :    * proposing a vector version of the nlm filter where we take into consideration the additional information brought by the spectral imaging system . * automatic tuning of the filter parameters . unlike the ad hoc method proposed in @xcite",
    ", we use an optimization approach to properly choose these parameters in a way that guarantees better denoising performance .",
    "* reducing the computation complexity .",
    "the main advantage of nlm filter is its non - local property which means each pixel is influenced by all pixels in the image .",
    "this comes unfortunately with more computation burden .",
    "we alleviate this burden by proposing a similarity measure used to decide whether we should take the pixel contribution or not during the pixel restoration process .",
    "our experimental results demonstrate that this approach not only reduces the computation time but also ensures good denoising results .",
    "we prove through quantitative evaluation the advantages of the proposed method compared to other denoising algorithms derived from the classic nlm filter as well as from other theories .",
    "indeed , our method achieves better denoising performance compared to other algorithms .",
    "furthermore , we show how ovnlm is capable to preserve image details while conserving its non - local property and ensuring acceptable computational efficiency .",
    "we consider the following additive noise model : @xmath6 where @xmath7 and @xmath8 are the noisy and original pixels respectively , @xmath9 is the gaussian noise and @xmath10 is the pixel coordinates in the spatial domain .",
    "the basic assumption behind the definition of the nlm filter is that we need to take advantage of the high degree of redundancy in the   is any set of pixels @xmath11 in the image domain @xmath1 such that a local window surrounding @xmath12 is similar to the local window surrounding @xmath11 @xcite .",
    "the general case of nlm filter is given by : @xmath13 @xmath14 is the weight calculated for each pixel .",
    "it is computed based on a similarity measure between pixels in position @xmath12 and @xmath11 .",
    "@xmath14 satisfies the following constraints : @xmath15 the similarity between two pixels @xmath12 and @xmath11 is measured as a decreasing function of the gaussian weighted euclidean distance @xmath16 , where @xmath17 is the standard deviation of the gaussian kernel .",
    "let @xmath18 and @xmath19 be the pixel vectors of the gray level intensity within a squared neighborhood centered at positions @xmath12 and @xmath11 respectively .",
    "@xmath20 @xmath21 acts as a smoothing parameter .",
    "@xmath22 is a normalization constant which ensures that @xmath23 .",
    "@xmath24 the gaussian weighted euclidean distance is given by : @xmath25 where @xmath26 is a local window and @xmath27 is defined as : @xmath28 thus , we can distinguish two main characteristics : the restored pixel is obtained by taking into account the contribution of pixels in the whole image and the weight computation is based on the similarity between local windows .",
    "such characteristics have triggered researchers to design various novel methods @xcite .",
    "to take advantage of the additional information brought by the spectral dimension , we extend the nlm filter to the vector case . in the multispectral context",
    ", we have the reflectance intensity at a given position in different spectral bands .",
    "thus , we are operating on a set of pixel vectors @xmath29 .",
    "we define the vector nlm ( vnlm ) filter as : @xmath30 where the new formulation of the weight between two pixels at position @xmath12 and @xmath11 is defined as : @xmath31 if @xmath32 , where @xmath33 is the identity matrix , we get the classical euclidean distance .",
    "@xmath34      in our framework design , we target two main objectives : optimize the parameters of the filter and reduce its computation complexity .",
    "first we use both the classical euclidean distance @xmath35 and mahalanobis distance @xmath36 where @xmath37 is a covariance matrix .",
    "in addition , we preselect for each pixel a subset of the most similar pixels based on a probabilistic similarity measure .",
    "the filter depends on two parameters : the smoothing parameter @xmath38 and the covariance matrix @xmath37 .",
    "thus , we have : @xmath39 where @xmath40 is a nonlinear estimator and @xmath41 is the filter parameter.our aim is to optimize @xmath41 so that we can ensure the choice of the optimal parameters in order to obtain the best denoising result .",
    "the performance of the estimator is generally evaluated using the mean square error ( mse ) : @xmath42 however , the problem of such estimator is that the ground truth image @xmath43 is unknown .",
    "mse can be seen as a random variable of the noise .",
    "its expected value is designated as the risk @xmath44 and expressed as : @xmath45 the problem of estimating the risk without the need to have the underlying image @xmath8 is approached by stein s unbiased risk estimator ( sure ) @xcite .",
    "thus , we have @xcite : @xmath46 and : @xmath47 @xmath48 is the transpose operator .",
    "if we consider zero mean multivariate gaussian noise , we get @xcite : @xmath49 where @xmath50 is the noise covariance matrix . + by combining eq .",
    "[ eq_nlm1 ] and eq .",
    "[ eq_nlm2 ] , we end up with an expression without @xmath8 : @xmath51 therefore , the risk @xmath52 is the unbiased risk estimator of mse in eq .",
    "[ eq_mse ] and is given by : @xmath53 where @xmath54 is the jacobian matrix with respect to @xmath7 .",
    "@xmath55 is given by @xcite : @xmath56 where @xmath57 is the delta function and @xmath58 is defined as : @xmath59 with the derivation of @xmath58 ( see appendix ) , we formulate the problem of vector nlm filter as a constrained optimization problem : @xmath60 note that in case of using the euclidean distance , the only parameter to be optimized is @xmath38 .      if we go back to eq .",
    "[ eq_vonlm ] , we can clearly see that in order to restore every pixel , we need to go through every other pixel in the domain @xmath1 .",
    "this is obviously a very time consuming process . to attenuate the computation complexity of the proposed vnlm filter",
    ", we propose to preselect for each processed pixel , a set of most relevant pixels based on the similarity measure proposed in @xcite .",
    "this measure is based on a probabilistic approach to compute the similarity between two pixels based on the noise distribution . in the grayscale case ,",
    "the similarity measure is defined as : @xmath61 where @xmath62 is the maximum value of the true intensity , @xmath63 is a constant , and @xmath64 is the error function defined as : @xmath65 fig .",
    "[ heat ] illustrates the form of the similarity measure for @xmath66=100 .",
    "brighter values indicate higher similarity .",
    "values are mapped to the range [ 0,1 ] for visualization purpose ]    for a given @xmath67 , eq .",
    "[ eq_sim ] illustrates a gaussian function .",
    "we consider that all values beyond the width of 1/@xmath68 of maximum ( @xmath69 ) are zeros . in the case of rgb color images ,",
    "the similarity between two pixels @xmath70 $ ] and @xmath71 $ ] is defined as : @xmath72 we generalize this similarity measure for the multispectral case , such that the similarity measure between @xmath73 and @xmath74 is defined as : @xmath75 the proposed optimized vnlm ( ovnlm ) filter becomes : @xmath76      the proposed approach is detailed in what follows .",
    "we solve the constrained non - linear optimization problem using sequential quadratic programming .",
    "given a noisy image , the noise covariance matrix is estimated with the standard median absolute deviation method @xcite .",
    "the diagonal elements of @xmath50 are calculated as follows : @xmath77 @xmath78 .",
    "the off - diagonal elements are defined as : @xmath79\\ ) \\end{tabular}\\ ] ] where : @xmath80 and @xmath81 and @xmath82 .",
    "we minimize the risk value based on an optimal choice of parameters @xmath83 until we reach the maximum number of iteration @xmath84 or the risk value decreases below a preset threshold @xmath85 .",
    "we implemented this approach in matlab ( r2015a ) .",
    "the minimization is conducted using the function @xmath86 with the risk as an objective function to minimize and sqp as the optimization approach .",
    "we use a neighborhood window of @xmath87 and we set up @xmath88 .",
    "l * input*(@xmath89 + * output * optimal @xmath90 with minimal @xmath91 + * 1 * - initialize @xmath50 , @xmath38 , @xmath37 , iter=0 , maximum iteration number + @xmath92 @xmath84 and stopping threshold @xmath85 + * 2 * - iteration : * do * + @xmath93 a- calculate @xmath90 using eq . and",
    "+ @xmath93 b- calculate @xmath94 using + @xmath93 c- @xmath95",
    "+ @xmath93 d- update @xmath38 with sqp + @xmath93 e- update @xmath37 with sqp + @xmath93 f- compute @xmath96 ) + * while * ( @xmath97 or @xmath98 ) +    [ nlm_algo ]",
    "to assess the performance of our approach , we conducted experiments on real world multispectral images . in one of the experiments , we used the salinas scene collected using the airborne visible infra - red imaging spectrometer ( aviris ) at nasa s jet propulsion laboratory .",
    "sample bands are shown in fig .",
    "[ salinas ] .",
    "the salinas valley image is a high spatial resolution image consisting of a collection of 224 spectral band images taken over salinas valley california in the range from 0.4@xmath99 m to 2.5@xmath99 m at a resolution of 3.7 meters per pixel .",
    "spectral bands [ 108 - 112 ] , [ 154 - 167 ] and 220 are discarded due to water absorption and noise . before processing ,",
    "images are resized to @xmath100 pixels . in another experiment we used multispectral face images from the iris lab database at the university of tennessee @xcite .",
    "the iris lab database was built between august 2005 and march 2006 and consists of 2624 multispectral face images taken along the visible spectrum in addition to thermal images with a resolution of @xmath101 pixels .",
    "rgb images are also generated with a resolution of @xmath102 pixels .",
    "these images are taken in different lighting conditions : halogen light , daylight and fluorescent light .",
    "the total size of the database is 8.91 gb . a total of 82 participants were involved from different genders ( 76% male , 24% female ) , ethnicities as depicted in table [ tab_eth ] , ages , facial expression , genders and hair characteristics .",
    "we conducted experiments on 8 multispectral images referred to as @xmath103 @xmath104 .",
    "figures [ ms2 ] and [ ms ] illustrate the multispectral image samples taken with halogen light and used in our experiments .         in 480 nm , 560 nm and 720 nm ]     in 480 nm ,",
    "560 nm and 720 nm ]    .ethnicity percentage in iris @xmath105 database [ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab_sub8 ]",
    "let : @xmath106 .",
    "@xmath107\\ )      \\\\      \\\\",
    "\\(\\bullet p - s \\not\\in k : \\ )      \\\\      \\\\      \\ ( = exp(-\\frac{1}{h^2}(y_s - y_p)^t\\phi^{-1}(y_s - y_p ) ) \\cdot   \\)\\\\      \\\\      \\(exp(-\\frac{1}{h^2 } \\sum_{\\substack{k\\in k\\\\ k\\neq 0 } } ( y_{s - k}-y_{p - k})^{t}\\phi^{-1}(y_{s - k}-y_{p - k } ) )      \\)\\\\      \\end{tabular}\\ ] ] @xmath108",
    "41 natexlab#1#1 [ 1]`#1 ` [ 2]#2 [ 1]#1 [ 1]http://dx.doi.org/#1 [ ] [ 1]pmid:#1 [ ] [ 2]#2 , , . .",
    ", , , . . ,",
    ". , . . , . , , , , , , . , in : , pp . . , , , ,",
    ". . , . , , , a. . , . , ,",
    ", , , , . . ,",
    ", , , . . ,",
    ", , , , , , , , . . , . , , , , ,",
    ", , , , . . ,",
    ", , , , . . ,",
    ", , , , . . ,",
    ", , , . . ,",
    ", , . , in : , pp . .",
    ", , , . , in : , , , ( eds . ) , . .",
    "volume  , pp . .",
    ", , , , . . ,",
    ", , , , . . ,",
    ", , . , in : , pp . . , ,",
    ", in : , pp . . , , , . , in : , pp . .",
    ", , , a. . , .",
    ", , , , , , b. , in : , pp . .",
    ", , , . . ,",
    ", , , . . ,",
    ". , . . , . , ,"
  ],
  "abstract_text": [
    "<S> nowadays , many applications rely on images of high quality to ensure good performance in conducting their tasks </S>",
    "<S> . however , noise goes against this objective as it is an unavoidable issue in most applications . </S>",
    "<S> therefore , it is essential to develop techniques to attenuate the impact of noise , while maintaining the integrity of relevant information in images . </S>",
    "<S> we propose in this work to extend the application of the non - local means filter ( nlm ) to the vector case and apply it for denoising multispectral images . </S>",
    "<S> the objective is to benefit from the additional information brought by multispectral imaging systems . </S>",
    "<S> the nlm filter exploits the redundancy of information in an image to remove noise . </S>",
    "<S> a restored pixel is a weighted average of all pixels in the image . in our contribution </S>",
    "<S> , we propose an optimization framework where we dynamically fine tune the nlm filter parameters and attenuate its computational complexity by considering only pixels which are most similar to each other in computing a restored pixel . </S>",
    "<S> filter parameters are optimized using stein s unbiased risk estimator ( sure ) rather than using ad hoc means . </S>",
    "<S> experiments have been conducted on multispectral images corrupted with additive white gaussian noise and psnr and similarity comparison with other approaches are provided to illustrate the efficiency of our approach in terms of both denoising performance and computation complexity .    </S>",
    "<S> multispectral image , vector non - local mean filter , stein s unbiased risk estimator 00 - 01,99 - 00 </S>"
  ]
}