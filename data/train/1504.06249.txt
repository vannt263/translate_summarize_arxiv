{
  "article_text": [
    "the advent of high - throughput genomics technologies has made available large quantities of data , transforming molecular biology into a remarkably data - rich science .",
    "each passing year sees an increase in the use of high - dimensional data to probe everything from gene regulation and the evolution of genomes to the individual genetic profile of complex disease development .",
    "life scientists now find themselves having to cope with huge data sets , and face challenges extracting and interpreting the wealth of information hidden in these data .",
    "representing data in a well - studied formal structure is ideally suited to follow - up analysis and to addressing many of the questions arising from the interpretation of large scale data .",
    "recently developed experimental and computational techniques yield networks of increased size and sophistication .",
    "the study of such complex cellular networks is emerging as a new challenge in biology .",
    "network science is now central to molecular biology , serving as a framework for reconstructing and analyzing relations among biological units  @xcite .",
    "the characteristic combination in biology of minute observation and a large number of variables results in very dense networks , the upshot of which , from a data analysis perspective , is the so - called  curse of dimensionality \" problem  @xcite .",
    "biological networks carry information , transfer information from one region to another and implement functions represented by the network s interactions .",
    "the visualization and analysis of such networks can pose significant challenges , which are often met by identifying the backbone of complex networks . over the last decade , determining the vital features of these huge networks has been an intriguing topic , and continues to be a challenge .",
    "dimension reduction methods offer a potentially useful strategy for tackling such problems .",
    "they aim to reduce the predictor dimension prior to any modeling efforts .",
    "the main aim of all these efforts is to extract a processing core from large noisy networks .",
    "surprisingly , the amount of information lost or conserved in so doing has remained unknown or unquantified . furthermore , there is no general framework for evaluating and comparing these methods .",
    "here we propose a novel approach for studying the complexity of biological networks and for evaluating network dimensionality reduction processes , applying information - theoretic measures to detect global and local patterns .",
    "in particular , we study the rate at which information can be lost , recovered or reconstructed in reduced complex artificial and real networks , while retaining the typical features of biological , social , and engineering networks , such as scale - free edge distribution and the small - world property . we will use a more powerful measure of information and randomness than shannon s information entropy , namely , the so - called kolmogorov complexity @xmath0 .",
    "@xmath0 has been proven to be a universal measure theoretically guaranteed to asymptotically find any computable regularity  @xcite in a dataset .",
    "@xmath0 can be effectively approximated by using lossless compression algorithms , for example .",
    "that is , compression algorithms for which decompression fully recovers the original object , with no loss of information . a good introduction to the subject",
    "may be found in  @xcite and  @xcite . to approximate kolmogorov complexity",
    ", we use a technique called the _ block decomposition method _",
    "@xcite ( or simply bdm ) based on algorithmic probability  @xcite and two generally employed lossless compression algorithms , bzip2 and deflate .",
    "bzip2 is an open source data compressor that uses a stack of different algorithms superimposed one atop the other starting with run - length encoding , burrows - wheeler or the huffman coding , among others .",
    "we sometimes compare , strengthen or complement findings by also providing estimations of shannon s information entropy .",
    "while more dimension reduction techniques can be conceived of than can be thoroughly analyzed in a single paper , we provide the tools and methods with which to do so , regardless of the technique . here , however , we compare three distinct graph dimension reduction techniques ( graph spectrum , sparse graph and motif profile ) and evaluate their ability to preserve the information content of the original network .",
    "these methods have been applied to different biological networks in order to understand complex cellular behaviours  @xcite .",
    "the logic behind the use of motif profiles is the basic assumption that the over - representation of a certain motif in a network indicates that it has some functional importance .",
    "thus , exploring the most frequently occurring motifs in a network may afford novel insights into the functionality of these motifs within the network .",
    "fanmod  @xcite has been used to find network motif profiles .",
    "the sparse networks have been obtained by applying the effective resistances sparsification method .",
    "effective resistances sparsification has been reported to be one of the quickest sparsification methods , which keeps the backbone of a network intact  @xcite .",
    "we compare what the three methods ( see appendix ) , graph spectra , graph motifs and graph sparsification which are clearly forms of lossy compression as the networks can not be fully recovered ",
    "capture , and we test whether they characterize families of networks . in other words , we measure the ability of these methods to preserve key information .",
    "we show that they not only capture different properties but also preserve different amounts of information from the original objects .",
    "there were four main sources of networks to which dimensionality reduction methods and information - theoretic measures were applied one source was tailored graphs produced specifically for this paper , such as spider graphs and co - spectral graphs .",
    "real - world networks come from the landmark paper where network motifs for systems biology was introduced  @xcite .",
    "finally , from the widely - known artificial gene network series century database ( mendes db )  @xcite , a sample comsisting of two small - world networks ( sw ) , two scale - free networks ( sf ) and two erds - rnyi networks ( er ) were used , all of them with 100 nodes and 200 edges .",
    "these are public data sources of well - known networks , used instead of custom - made networks in the interest of impartiality .",
    "methods and measures were thus applied to networks that are widely available and not to networks contrived to suit the particular methods or measures applied in this paper . from now on all graphs analyzed , whether natural or synthetic , are directed , but no information regarding activation or inhibition is taken into account ( since for several of them there is none ) .",
    ".*complexity approximation by bdm , deflate and bzip2 of all original graphs . *",
    "[ cols=\"^,^,^,^,^,^,^,^,^,^ \" , ]     complexity of all graphs approximated by the three methods : bdm , deflate and bzip2 , normalized by number of nodes and number of edges . list sorted by last column bzip2 normalized by number of edges .",
    "a figure plotting these values for comparison and normalized between 0 and 1 is provided in fig .",
    "[ figure3 ] .",
    "[ tab : table1 ]    , [ figure4 ] and [ figure5].,width=453 ]                          the complexity of biological networks may be studied by employing information - theoretic measures to detect global and local patterns and to measure the information content of graphs and networks .",
    "[ figure1 ] shows the flowchart of the proposed testbed for assessing information loss / preservation in network dimensionality techniques .",
    "first , as a proof of concept , fig .",
    "[ figure2]a shows that the shannon entropy of the adjacency matrix diminishes in value for a growing number of disconnected nodes .",
    "[ figure2]b shows the impact of adding disconnected nodes to a graph as an estimation error of approximations to graph entropy ( @xmath1 ) , and of graph algorithmic complexity estimated by bdm ( @xmath2 ) . the block decomposition method ( bdm )",
    "is a novel technique for approximating kolmogorov complexity by means of algorithmic probability ( c.f .",
    "section  [ kmotifs ] ) .",
    "both bdm and @xmath3 measures behave as expected : while algorithmic complexity increases marginally due to the small information content added , with diminishing impact , by the contribution of every disconnected node , entropy asymptotically moves towards 0 . since the graph entropy and complexity",
    "are measured over the adjacency matrix of the graph , adding disconnected nodes means adding rows and columns of 0s , which are highly compressible and of low entropy and block entropy ( entropy rate , i.e. taking as unit _ micro - states _ all submatrices of @xmath4 bits from @xmath5 to the length of the adjacency matrix ) .",
    "it follows then that algorithmic complexity captures important features of these graphs .    in  @xcite",
    ", we showed that deflate and bdm very closely approximated the complexity of dual graphs .",
    "here we performed a similar test using cospectral graphs , with a surprising positive outcome . in graph theory , the set of eigenvalues of the adjacency matrix of a graph is referred to as the _ spectrum _ of the graph .",
    "two graphs are _",
    "isospectral _ or _ cospectral _ if the adjacency matrices of the graphs have equal multisets of eigenvalues , i.e. , the same spectra .",
    "cospectral graphs may look very different ; two examples are shown in  [ figure2]b",
    ". however , entropy ( fig .",
    "[ figure2]b ) and algorithmic complexity estimated by bzip2 ( fig .",
    "[ figure2]b and c ) and bdm ( fig .",
    "[ figure1]d ) provided the same information content values for almost all co - spectral graphs considered .",
    "bdm ( fig .",
    "[ figure2]d ) provided better estimations ( with higher rank correlation and less outliers ) than bzip2 and entropy ( fig .",
    "[ figure1]c ) for 180 graphs and their cospectrals , that is , the original graphs and their cospectral counterparts had values closer to each other .",
    "this is consistent with the fact that cospectral graphs share important algebraic properties and should therefore have a similar information content , but it was not necessarily theoretically expected , there being no known procedure for producing all graphs with a certain spectrum and no simple algorithm for producing a cospectral graph from a given graph . in general , there is no one - to - one correspondence , and in this sense the cospectral information - content similarity is more surprising than that of dual graphs .",
    "that classic entropy , bzip2 complexity and bdm based on algorithmic probability produce very similar complexity values for cospectral graphs means that these methods are ( from worse to better ) able to capture fundamental algebraic properties shared by cospectral graphs and so can be used , as we claim , for comparing reduction methods .    as part of the dataset to be considered , we assessed the amount of information ( in bits ) in six networks from an artificial gene network database : two networks with small - world ( sw ) topology , two scale - free networks ( sf ) and two erds - rnyi ( er ) . in the past ,",
    "most of the work on the complexity of graphs was focused on random networks , the so - called erds - rnyi networks .",
    "but most of the interesting features of biological networks arise from the fact that these networks are not like random graphs .",
    "connections among elements in a biological network are neither simple nor random . the small - world property of networks  signified by a small diameter  has been established beyond a doubt , revealing the key role of short cuts common in many real networks , from protein interactions to social networks , and from the network of hyperlinked documents to the interconnected hardware behind the internet .",
    "real networks , including biological networks , are also known to be scale - free  @xcite .",
    "this suggests other possible mechanisms that could be guiding network formation .    here",
    "we explore the complexity of these three large random graph classes , i.e. , er , sf and sw and various real - world , biological and non - biological networks .",
    "the results of the estimation of the kolmogorov complexity of these artificial networks show that while there is no agreement as regards whether sw is more complex than sf or vice versa , for shannon entropy , sw networks display greater combinatorial complexity ( not shown in graphs ) .",
    "but for bdm , sf networks are more complex ( fig .",
    "[ figure3]a , b ) , and both compression algorithms are in agreement as to the slightly greater complexity of sw and er networks ( fig .",
    "[ figure3]a , b ) .",
    "and in fact we have found that both bdm and compression can separate these graph in topological groups ( see  @xcite and  @xcite ) . however , compression algorithms reverse the complexity order among sf , sw and er , which is once again in agreement with bdm on motifs as a network dimensionality reduction method ( fig .",
    "[ figure5 ] ) , thus showing that bdm does not harbor a bias toward motifs . that compression of the original graphs retrieves a different order than bdm and compression on motif profiles is counterintuitive because sw networks for small rewiring probability are very close to regular ( ring / cycle ) networks and should therefore not have large complexity values .",
    "however , compression algorithms differ from bdm in that they are entropy rate estimators and can therefore be fooled if no trivial statistical regularities are found .",
    "since we have normalized kolmogorov complexity estimations by number of edges and nodes , this result can be compared directly with other networks , and we do not need to have exactly the same number of nodes or edges for comparison .",
    "[ figure3 ] shows the complexity values and information content estimations of the 16 graphs from  @xcite and the mendes db  @xcite using bzip2 and deflate lossless compression algorithms ( bdm can not be applied directly to real - number values , see section  [ kmotifs ] ) as approximations to kolmogorov complexity normalized by node .",
    "interestingly , we see bdm values retrieve differences between networks , meaning that local regularities better characterize them .",
    "so bdm values can be used to characterize families of networks .",
    "we report the results of our evaluation of the loss and preservation of information in network reduction techniques .",
    "to do this we first measure the information content of the adjacency matrix of a graph @xmath6 , then the information content of the graph @xmath7 resulting from the application of each dimensionality reduction method .",
    "finally we consider the difference of these values @xmath8 for complexity measure @xmath9 and reduction method @xmath10 . in general , @xmath11 , but some methods , such as spectral analysis ( c.f .",
    "section  [ kspectra ] ) , can lead to the introduction of spurious information such that @xmath12 , especially for complexity measures of an entropic nature , such as compression ( in contrast to those of an algorithmic nature such as bdm ) .",
    "but we are mostly interested in the case in which given 2 graphs @xmath13 and @xmath14 such that @xmath15 for complexity measure @xmath9 , then @xmath16 , especially for cases in which this is preserved across different @xmath9s .    the subgraph complexity ( bdm ) and lossless compression ( bzip2 ) values of the networks ( fig .  [ figure3 ] ) that were classified by their network motifs have been studied before  @xcite , in order to assess the preservation of relative information content . that is , whether @xmath17 , where @xmath10 is any of the complexity methods used in this project : bdm , deflate ( compress ) and bzip2 , on all reduction methods : motif profiles , graph spectra and sparsification . the results summarized in fig .",
    "[ figure3 ] encompass genetic , protein , power grid and social networks , as described in  @xcite .",
    "the plot shows that compression and bdm preserve to some degree the relative information content of most types of networks but bdm produces a convex curve while all others are more concave ( fig .",
    "[ figure3]b ) .",
    "while deflate and bzip2 show different degrees of success at distinguishing families of networks , bdm was the best at distinguishing networks by their families assigning lower or higher complexity to different groups ( e.g. , genetic vs protein vs electric , or erds - rnyi vs scale - free vs small world ) even normalizing by edge density and thus truly capturing essential differences of their topological properties .",
    "this is consistent with the main result in  @xcite , showing that local graph structures can classify network families with great precision , bdm , however , looks at local structures in the network adjacency matrices instead , which is a proper superset than counting subgraphs ( motifs ) as done before in the cited papers .",
    "there is an extensive literature on connecting graph properties to the eigenvalues of graph adjacency matrices .",
    "the so - called eigenvalue spectrum of these graphs provides information about their structural properties .",
    "eigenvalues store information about a graph",
    ". many properties of a graph can be recognized from its spectrum  @xcite .",
    "we have calculated the amount of information preserved in spectra of different network families .",
    "graph spectra can characterize certain properties of graphs .",
    "for example , spider graphs with @xmath18 rays have redundant eigenvalues , and the spider graph spectrum characterizes the graph by its number of rays and diameter .",
    "indeed , it follows from the configuration of the adjacency matrix that the spectrum of a spider graph of @xmath18 rays and diameter 1 is :    @xmath19 ,    with spiders of greater diameter having slightly greater complexity .",
    "this simplicity in the redundancy of the spectrum of spider graphs is consistent with their low kolmogorov complexity .    unlike the process of growing a spider graph , growing a random graph with edge density 0.5 requires a larger amount of information to specify the graph spectrum .",
    "indeed , the kolmogorov complexity of the spectrum of a spider graph is bounded by the number of rays @xmath18 with the same eigenvalue @xmath20 with @xmath0 complexity @xmath21 , and the number @xmath22 of trailing 0s with kolmogorov complexity @xmath23 .",
    "all biological networks were subject to the greatest loss of information when spectral sparsification was used ( see fig .  [ figure3 ] , where spectral curves are mostly flat , thus not allowing us to distinguish between different networks ) .",
    "this is because spectra analysis is lossy ( many graphs can have the same graph spectrum ) and therefore is bound to lose vital information , even if spectra capture important algebraic properties of a network .",
    "biological networks were also found to have close to nilpotent eigenvalues , but we found no theoretical explanation for this ( see fig .",
    "[ figure4 ] where biological networks have values closer to @xmath24 ) .",
    "we think the reason is the high number of low degree nodes in biological networks .",
    "indeed , it has been pointed out that the spectrum of these networks is quite susceptible to fluctuations of the vertex degrees , and in the case of irregular graphs the eigenvalues of the adjacency matrix just mirror the tails of the degree distribution and thus do not reflect any global graph properties  @xcite .    while spectra analysis is known to be a lossy data reduction technique ,",
    "our results show that spectra analysis respects the information order of real - world networks , as compared to the full lossless compressed lengths of the networks .",
    "another interesting phenomenon was the perfect match of values between bdm and deflate for the synthetic networks .",
    "thus , taken together , bdm and deflate perfectly differentiate between the natural and artificial networks to be further investigated .",
    "that graph spectra are inconsistent with the common estimation trend of kolmogorov complexity , as reported in previous experiments , suggests that graph spectra analysis is the method with the greater loss of information .",
    "yet this does not make it less interesting as a measure for quantifying certain aspects of a graph , provided we take into account that this method may indeed lose the relative complexity and information content of the original graph .",
    "the graph laplacian may be claimed to more naturally represent some properties of graphs , when compared to the plain graph spectrum . from the point of view of information content",
    ", the laplacian can not contain more information than the information that can already be extracted from the adjacency matrix .",
    "indeed , the laplacian is defined as @xmath25 , where @xmath26 is a diagonal matrix where each diagonal entry is the number of links for each node and @xmath27 the adjacency matrix .",
    "@xmath26 can clearly be derived from @xmath27 as the sum of 1s in each row . moreover , the calculation of the laplacian is of fixed size .",
    "hence @xmath28 differs only by a constant value .",
    "but it remains to be ascertained whether the laplacian conserves more information than the regular graph spectrum , despite the fact that both retrieve the same number of vector entries .    taking the information content from the spectra alone does not preserve the relative order or show any clustering capabilities by type of network .",
    "this means that when using bdm , graph motif and compressibility analysis , order is better preserved among networks of the same family than among different families .",
    "the idea of a local scale subgraph - based analysis was first presented in  @xcite , when network motifs were discovered in the gene regulation ( transcription ) network of the bacteria e. coli and then in a large set of natural networks .",
    "a network motif is defined as a recurrent and statistically significant sub - graph occurring in a network or across various networks .",
    "more formally , if @xmath6 and @xmath3 are two graphs , @xmath29 , the number of appearances of graph @xmath3 in @xmath6 is referred to as the frequency @xmath30 of @xmath3 in @xmath6 . a graph is referred to as recurrent ( or frequent ) in @xmath6 when its frequency @xmath31 is above a predefined threshold or cut - off value ( usually compared to a random graph ) .",
    "much work has been done on the subject , resulting in the discovery of characteristic motifs among species and network types , and even superfamilies  @xcite of network motifs that characterize complete classes of networks such as transcription interaction , signal transduction , even social networks .",
    "motifs have recently garnered much attention as a useful concept for uncovering the structural design principles of complex networks  @xcite .",
    "there have been suggestions that motif analysis can not deliver on the promise of a deeper understanding of the networks studied ( eg  @xcite ) , mainly because of a loss of information pertaining to context , i.e. , the broken connections between subgraphs  @xcite .",
    "while it is clear that local scale information is lost , it is not clear how much a subgraph analysis can preserve of the information content of the original full - size networks .",
    "motifs have been of signal importance largely because they may reflect functional properties .",
    "we ask how much information can be recovered by looking at a network on a very local scale , as proposed by the network motif analysis approach .",
    "the concept of algorithmic probability will enable us to approximate and add small - scale complexity from the decomposition of a network into its possible subgraphs in order to determine the amount of information that is preserved in this bottom - up approach , as compared to the information content of the full - size network .    in fig .",
    "[ figure2 ] we show the motifs , as calculated by the open - source software fanmod  @xcite , of escherichia coli  @xcite , together with information - theoretic measures associated with each motif .",
    "we see that shannon s entropy distinguishes two cases , assigning the two lowest possible entropic measures ( @xmath32 and @xmath33 ) , while bdm approximations provide a finer - grained classification , retrieving 3 different values for all 4 motifs .",
    "both shannon entropy and kolmogorov complexity approximations agree on the equal complexity of the first two motifs .",
    "results of applying compressibility ( deflate and bzip2 ) and algorithmic probability ( bdm ) to approximate the kolmogorov complexity motifs of the artificial network showing the agreement of the compressed size of network motif files , network motifs of size 4 and 5 , when compared to the complexity of the original networks ( bdm , bzip2 and deflate ) ( see fig .",
    "[ figure3 ] ) .    fig .",
    "[ figure3]c shows that natural and synthetic networks that belong to the same family or have the same topology have similar complexity values , both for the original and for the motif compressed file sizes .",
    "the same compression trend is confirmed between motifs and bdm for both sets of graphs , providing further evidence of the connection established in this paper between the information content of subgraphs ( more properly , some subarrays of the adjacency matrices ) and the frequency of a subset of overrepresented graphs ( known as graph motifs ) .",
    "similarly , but to a lesser degree , bzip2 and deflate ( fig .",
    "[ figure3]a - b ) show network family clustering capabilities , assigning graphs of similar origins or topology more or less the same incompressibility values as approximations of their complexity / information content .",
    "sparsification can be viewed as a procedure for finding a set of representative edges and weighting them appropriately in order to choose a smaller but representative number of vertices and edges that preserve important features of a network , for example , its _",
    "backbone_. sparse graphs are easier to handle than denser ones and can be used for network dimensionality reduction for the study of very large networks .",
    "a sparse graph is one whose number of edges is reasonably viewed as being proportional to its number of vertices .",
    "one may consider a graph sparse if its average degree is less than 10  @xcite . while real - world networks are already sparse by most standards , because of their typically large size it is often useful to reduce their dimensionality further in order to enable inspection of the most important connections , for example , in biology , where even a new link of regulation between genes can be a breakthrough .",
    "sparsification methods have been used in biology ( eg  @xcite ) .",
    "it has traditionally been shown that these algorithms preserve topological properties of the original networks after sparsification , but little is known about the information content conservation . in this section",
    "we calculated the amount of information preserved in spectral sparsifiers of different types of network .",
    "we used the algorithm suggested in  @xcite for the purpose , a fast algorithm to calculate sparse networks by random sampling , where the sampling probabilities are given by the effective resistances of the edges .",
    "the effective resistance of an edge is known to be equal to the probability that the edge appears in a random spanning tree of @xmath6 .",
    "it has been proved that for each error parameter @xmath34 there is such a spectral sparsifier , and that it can be calculated in @xmath35 time for some large constant @xmath36independent of the sampling method  by replacement from graph @xmath6 .",
    "@xmath37 will denote the graph resulting from the application of the sparsification method to @xmath6 .",
    "here we are interested in determining whether this other method actually preserves the information of the network , beyond topological properties .",
    "to which end we again measure the information content  by way of shannon entropy and kolmogorov complexity  of the networks previously studied .",
    "[ figure3 ] show that the method does indeed follow the relative information content of the lossless compressed lengths of the original networks .",
    "we have chosen the error terms for all networks so as to keep 20% , 40% , 60% and 80% of the edges , following a recent , widely accepted network sparsification algorithm , as described in  @xcite .",
    "we report the findings for the rate of information loss in fig .",
    "[ figure3 ] .",
    "the information loss rates for sparsification preserving degree distribution ( see fig .  [ figure5 ] ) ( differences between 20% , 40% , 60% and 80% threshold values ) are -2.44 , -0.908 and -0.611 .",
    "the relative order of information content was preserved upon application of all methods .",
    "only bzip2 reports an inconsistency in the relative information conservation for sw networks .",
    "the rest  including deflate ",
    "indicate good preservation of the features that characterize the information content of the original networks .",
    "we calculated the graph spectra of several real - world networks from  @xcite .",
    "@xmath38 , consisting of a list of eigenvalues of the adjacency matrix of @xmath6 , denotes the spectra .",
    "[ figure3 ] shows the result of compressing both the original networks and their graph spectra .",
    "the approximation of the algorithmic information content preserved by the spectra is calculated by losslessly compressing @xmath38 of @xmath39 eigenvalues of the graph adjacency matrix of @xmath6 of size @xmath39 , and is denoted by @xmath40 , where @xmath9 is a lossless compression algorithm ( e.g. , bzip2 or deflate ) and @xmath38 the eigenvalues sorted from smallest to largest . as seen in fig .",
    "[ figure3 ] , bdm fully characterizes network topology ( see the synthetic network values ) and assigns similar complexity to similar networks , in agreement with previously reported motif analysis results .",
    "[ figure3 ] shows the complexity values for the protein networks 1 , 2 and 3 ; social networks 1 and 2 ; electronic circuit networks 1 and 2 ; genetic networks ( yeast and ecoli ) ; and 3 types of graph with different topologies ( erds - rnyi , scale - free and small - world from the mendes db ) .",
    "the rate of information loss is clear , with the greatest loss at 80% and then diminishing at a decreasing speed the greater the sparsity , keeping relative information but deleting edges at the determined values .",
    "trends show that the algorithm preserves the absolute and relative information content of the original networks .",
    "[ figure4 ] shows a very interesting phenomenon .",
    "reaching a 40% sparsification value has the diametrically opposite effect to losing information ; the resulting network appears more random because most of the structure is lost . then at 20% the original trend resurfaces",
    "; the resulting sparse graph is truly small as compared to @xmath41 and comes last , with the smallest information content .",
    "combined , this strongly suggests that keeping less than 50% leads to important information being lost , and some complexity may actually be introduced ( e.g. , from graph disconnection ) .",
    "this of course depends on the topological structure of the graph  it is known that scale - free networks are more robust in the face of random failure but less so in the face of targeted attacks  @xcite .",
    "this is in contrast to motif analysis , as shown in   subsection  [ kmotifs ] , where it was demonstrated that very few elements of local structure ( subgraphs ) preserve the basic information necessary to continue characterizing the networks .",
    "sparsification is thus seen to be safe for real - world networks at a 50% value , and unsafe for lower values , where most of the information begins to be lost , as happens in spectral analysis .",
    "while a variety of dimensionality reduction techniques have been proposed in recent years , beyond network motif analysis and sparsification techniques , there has not been much done in the area of network dimensionality reduction . here",
    ", we presented a novel and systematic way to compare old and new dimensionality reduction techniques based on information theory .",
    "the suggested methodology is based on the calculation of the preservation of information content .",
    "here it was empirically demonstrated the application of these novel methods .",
    "we have measured their effectiveness on a relatively limited but representative set of data , and reported their potential and associated information loss for dimensionality reduction . while our empirical results are a useful pointer , further numerical and theoretical work is probably needed to understand better the reasons underpinning the reported results .    as a proof of concept",
    ", we first showed that approximations of the information content of cospectral networks are similar , as is consistent with the theory .",
    "we then tested three important graph dimensionality reduction techniques , showing the various ways and the degrees to which each method is capable of preserving the information content of the original networks .",
    "we calculated for the first time the impact of applying three important network reduction techniques to the information content of the 3 most important random and complex graph models , namely erds - rnyi , barabsi - albert and watts - strogatz .",
    "the results of the experiments reveal that the sparsification method evaluated preserves relative information and that its rate of information loss is as expected , but in deleting more than half the edges it leads to significant inconsistencies and loss of information . in the case of motif analysis , we found results in agreement with the method based on algorithmic probability that approximated the algorithmic information content of a network by considering local regularities , validating ( and generalizing ) the surprising fact that local regularities ( subgraphs ) preserve information to such a degree that important profiling information from the networks is fully recoverable ( e.g. , their type across different superfamilies ) , as reported in  @xcite . finally , graph spectra was the most irregular reduction technique , capturing important algebraic information in a condensed fashion but in the process losing most of the information content of the original network .",
    "the results we report indicate that a local complexity approach retrieves enough local information about networks to distinguish between families , which is not possible by averaging their information content on the global scale through applying lossless compressibility to the complete networks .",
    "the results suggest that despite its local nature , motif analysis is the method that preserves the most information , while sparsification techniques are to be used carefully and can not reduce the network edge density by more than 50% without losing information essential for characterizing the network s original complexity . and finally , while graph spectra analysis captures important algebraic features , it is to be used with the greatest care , as it is definitely the technique that loses most of the original information content , making it impossible to reconstruct properties of the original graph in the general case .",
    "the paper explains these results by identifying weaknesses among these techniques and providing instructions on what they are best at and what to avoid , thus making it possible to improve the application of these methods for different purposes and clearing a path to assess other techniques and make meaningful comparisons .",
    "it helps to evaluate and compare network dimension reduction techniques that have been proposed so far and may be introduced in the future .",
    "the authors would like to thank our karolinska institutet colleagues : gordon ball for his valuable technical help , and the other members of the unit of computational medicine .",
    "this work was supported in part by the foundational questions institute ( hz ) , the john templeton foundation ( hz ) , the vinnova ( vinnmer ) marie - curie fellowship , ( nk ) , afa insurance ( jt ) , torsten sderberg foundation ( jt ) , stategra ( jt , hz ) , the stockholm county council and the swedish research council . the funders played no role in the design of the study , in data collection and analysis , in the decision to publish , or in the preparation of the manuscript .",
    "aho , m.r .",
    "garey , j.d.ullman , the transitive reduction of a directed graph , _ siam journal on computing _ 1 ( 2 ) : 131137 , 1972",
    ". m. albrecht , a. kerren , k. klein , o. kohlbacher , p. mutzel , w. paul , f. schreiber , and m. wybrow , on open problems in biological network visualization , d. eppstein and e. gansner , editors , graph drawing , _ lecture notes in computer science _ , 5849:256267 , springer berlin heidelberg , 2010 .",
    "r. albert , h. jeong , a.l .",
    "barabasi , error and attack tolerance of complex networks , _ nature _ jul 27;406(6794):37882 , 2000 .",
    "r. albert and a .-",
    "barabsi , statistical mechanics of complex networks , _ rev .",
    "74 , _ 47 , 2002 .",
    "aliferis , a. statnikov , and i. tsamardinos , challenges in the analysis of mass - throughput data : a technical commentary from the statistical machine learning perspective , _ cancer inform _ , 2 : 133162 , 2006 .",
    "u. alon , collection of complex networks .",
    "uri alon homepage 2007 ( accessed on july 2013 ) .",
    "e. august and a. papachristodoulou , efficient , sparse biological network determination , _ bmc systems biology , _ 3:25 , 2009 .",
    "a. banerjee , j. jost , graph spectra as a systematic tool in computational biology , _",
    "discrete applied mathematics _",
    ", 157:10 , pp . 24252431 , 2009 .",
    "barabsi , r. albert , emergence of scaling in random networks .",
    "science 286 ( 5439 ) : 509512 , 1999 .",
    "j. batson , d.a .",
    "spielman , n. srivastava , and s .- h .",
    "teng , spectral sparsification of graphs : theory and algorithms , vol .",
    "56:8 , _ communications of the acm _",
    "s. boccaletti , v. latora , y. moreno , m. chavez , d .- u .",
    "hwang , complex networks : structure and dynamics , _ physics reports , _",
    "vol 424:45 , pp .",
    "175308 , 2006 .",
    "s. carmi , s. havlin , s. kirkpatrick , y. shavitt , e. shir , a model of internet topology using k - shell decomposition , _ proc natl acad sci usa _ 104 : 1115011154 , 2007 .",
    "calude , _ information and randomness : an algorithmic perspective _ , eatcs series , 2nd . edition , 2010 , springer .",
    "g.j . chaitin . on the length of programs for computing finite binary sequences _ journal of the acm _ , 13(4):547569 , 1966 .",
    "there are planar graphs almost as good as the complete graph , _",
    "j. comput .",
    "sci . , _ 39:205219 , 1989 . t.m . cover and j.a .",
    "thomas , _ elements of information theory _ ,",
    "2nd edition , wiley - blackwell , 2009 .",
    "e.r . van dam , and w.h .",
    "haemers , spectral characterizations of some distance - regular graphs ,",
    "_ j. algebraic combin . _ 15 , 189 - 202 , 2003 .",
    "delahaye and h. zenil , numerical evaluation of the complexity of short strings : a glance into the innermost structure of algorithmic randomness , _ applied mathematics and computation _ 219 , 6377 , 2012 .",
    "dorogovtsev and j.f.f .",
    "mendes , evolution of networks , _ adv .",
    "_ 51 , 1079 , 2002 .",
    "p. eichenberger , m. fujita , s.t .",
    "jensen , e.m .",
    "conlon , d.z .",
    "rudner , s.t .",
    "wang , c. ferguson , k. haga , t. sato , j.s .",
    "liu , r , losick , the program of gene transcription for a single differentiating cell type during sporulation in bacillus subtilis , _ plos biology _ 2 ( 10 ) : e328 , 2004 . n.j .",
    "foti , j.m .",
    "hughes , and d.n .",
    "rockmore , nonparametric sparsification of complex multiscale networks , _ plos one _ , 6(2 ) : e16431,2011 .",
    "r.l .. graham , p hell , on the history of the minimum spanning tree problem  annals of the history of computing , vol 1:7 , 4357 , 1985",
    ". a. gundert and u. wagne , on laplacians of random complexes , _ proceedings of the acm symposium on computational geometry , socg 2012_. s. ivakhno and j.d .",
    "armstrong , non - linear dimensionality reduction of signaling networks , _ bmc systems biology _ , 127,2007",
    ". m. kitsak , l.k .",
    "gallos , s. havlin , f. liljeros , l. muchnik , h.e .",
    "stanley , h.a .",
    "makse , identification of influential spreaders in complex networks .",
    "_ nat phys _ 6 : 888893 , 2010 .",
    "three approaches to the quantitative definition of information , _ problems of information and transmission _",
    ", 1(1):17 , 1965 .",
    "knabe , _ computational genetic regulatory networks : evolvable , self - organizing systems _ , springer , 2013 .",
    "knabe , c.l .",
    "nehaniv , m.j .",
    "schilstra , do motifs reflect evolved function ? no convergent evolution of genetic regulatory network subgraph topologies , _ biosystems _ , 94 ( 1 - 2 ) : 6874 , 2008 .",
    "langton , studying artificial life with cellular automata , _ physica d : nonlinear phenomena , _ 22 ( 1 - 3 ) : 120149 , 1986 .",
    "laws of information conservation ( non - growth ) and aspects of the foundation of probability theory , _ problems of information transmission _",
    ", 10(3):206210 , 1974 . m. li and p.",
    "vitnyi , _ an introduction to kolmogorov complexity and its applications _ , 3rd ed . ,",
    "springer , 2009 .",
    "m. liu , b. liu , f. wei , graphs determined by their ( signless ) laplacian spectra , _ electronic journal of linear algebra , _ 22 , pp .",
    "112124 , 2011 .",
    "p. mendes , s. wei , and ye keying , artificial gene networks for objective comparison of analysis algorithms , _ eccb _ , pp 122129 , 2003 .",
    "r. milo , s. shen - orr , s. itzkovitz , n. kashtan , d. chklovskii , and u. alon .",
    "network motifs : simple building blocks of complex networks , _ science _ 298 , no .",
    "5594 : 824 - 827 , 2002 .",
    "r. milo , s. itzkovitz , n. kashtan , r. levitt , s. shen - orr , v. ayzenshtat , m. sheffer , u. alon , superfamilies of designed and evolved networks , _ science _ 303 , 15381542 , 2004 .",
    "newman , finding community structure in networks using the eigenvectors of matrices , _ phys .",
    "e _ 74 , 036104 , 2006 . n. przulj , d.g .",
    "corneil , and i. jurisica . modeling interactome : scale - free or geometric ? .",
    "_ bioinformatics 20 , _ 18 : 35083515 , 2004 .",
    "t. rado , on non - computable functions , _ bell system technical j. _ , 41 , 877884 , may 1962 .",
    "shannon , a mathematical theory of communication .",
    "_ bell system technical journal , _ 27 ( 3 ) : 379423 , 1948 .",
    "shen - orr , r. milo , s. mangan and u. alon , network motifs in the transcriptional regulation network of escherichia coli , _ nature genet .",
    "_ 31 , 6468 , 2002 . k. tsuda , hj .",
    "shin , and b. schlkopf , fast protein classification with multiple networks , _ bioinformatics _ , vol .",
    "21 , issue suppl .",
    "2 , pp ii59ii65 , 2005 . m.e.j .",
    "newman , the structure and function of complex networks , _ siam review _ 45 ( 2 ) : 167256 , 2003 .",
    "f. soler - toscano , h. zenil , j .-",
    "delahaye and n. gauvrit , _ correspondence and independence of numerical evaluations of algorithmic information measures _ , computability , vol .",
    "2 , pp . 125140 , 2013 . f. soler - toscano , h. zenil , j .-",
    "delahaye and n. gauvrit , _ calculating kolmogorov complexity from the frequency output distributions of small turing machines _ , plos one 9(5 ) , e96223 , 2014 .",
    "solomonoff , a formal theory of inductive inference : parts 1 and 2 .",
    "_ information and control _ , 7:122 and 224254 , 1964 .",
    "spielman , n. srivastava , graph sparsification by effective resistances , _ proceedings of the fortieth annual acm symposium on theory of computing ( stoc 08 ) , _ 563568 , 2008 .",
    "spielman , s .- h.teng , spectral sparsification of graphs , _ siam j. comput . , _",
    "40(4 ) , 9811025 , 2011 . s. wernicke , f. rasche , fanmod : a tool for fast network motif detection , _ bioinformatics , _ 22 ( 9 ) : 11521153 .",
    "h. zenil , f. soler - toscano , k. dingle and a. louis , graph automorphisms and topological characterization of complex networks by algorithmic information content , physica a : statistical mechanics and its applications , vol .",
    "404 , pp . 341?358 , 2014 .",
    "h. zenil , f. soler - toscano , j .- p .",
    "delahaye and n. gauvrit , _ two - dimensional kolmogorov complexity and validation of the coding theorem method by compressibility _",
    "h. zenil , n.a .",
    "kiani and j. tegnr , methods of information theory and algorithmic complexity for network biology , arxiv:1401.3604 , 2014 .",
    "network dimensionality methods have been introduced and used in biology  @xcite for purposes such as analysis and profiling . in general",
    "the goal of network sparsification is to approximate a given graph @xmath6 by a sparse graph @xmath3 on the same set of vertices .",
    "if @xmath3 is close to @xmath6 in some appropriate metric , then @xmath3 can be used as a signature , preserving important properties of @xmath6 for faster computation after reducing the size of @xmath6 and without introducing too much error , thus making computation time and storage of @xmath3 cheaper , as the network is more sparse compared with @xmath6 .",
    "obvious trivial sparsification methods include edge deletion by some criteria , such as the outermost ones ( called a @xmath18-shell  @xcite , often used to identify the core and the periphery of the networks ) , but most of them ( such as the aforementioned ) are rather arbitrary or ad - hoc , devised for specific purposes , rather than general methods aiming at preserving important , algebraic , topological or dynamical properties of the original graph .",
    "several notions of graph sparsification have been proposed .",
    "for example , a method motivated by proximity problems in computational geometry was introduced in the form of _ graph spanners _",
    "a spanner is a sparse graph in which the shortest - path distance between every pair of vertices is approximately the same in the original graph as in the spanner .",
    "for example , a popular sparsification algorithm is the _ spanning tree _",
    "@xcite designed to preserve node distance but clearly destroy all other local node properties such as the clustering coefficient .    not many non - trivial methods for network dimensionality reduction exist today , and it is acknowledged  @xcite that spectral graph sparsification is among the most efficient both in preserving important algebraic and dynamical properties of a network and in terms of fast calculation . in part",
    "the lack of more methods is due to a lack of assessment tools using which to decide whether one method is better than another in general terms , rather than whether it preserves one or another specific graph theoretic property ( e.g. , the transitive edge deletion method destroys the clustering coefficient of the original graph  @xcite ) . among the methods considered in this paper",
    "is a high - quality cutting - edge one  @xcite based on graph spectra .",
    "graph spectral sparsification is a technique that has been used in data analysis as a dimensionality reduction method in biology  @xcite .",
    "however , whether most graphs are uniquely determined by their spectrum is an open problem .",
    "but because at least some graphs share the same spectrum the process is lossy , because one can not fully recover the original graph from its spectrum , at least in these cases .",
    "for example , almost all trees are cospectral ( the share of cospectral trees on @xmath36 vertices tends to 1 as @xmath36 grows ) , where _ almost _ means that the set of elements for which the property does not hold is a set of measure zero .    a good introduction to spectral graph sparsification",
    "may be found in  @xcite and we use it to illustrate the network dimension reduction assessing tool introduced in this paper .",
    "the notion upon which all these methods are based is the spectral similarity of graph laplacians .",
    "spectral sparsification requires that the laplacian quadratic form of the sparsifier approximate that of the original graph on all real vector inputs .",
    "this is equivalent to saying that the laplacian of the sparsifier is a good preconditioner for the laplacian of the original  @xcite .",
    "another more recent method closer to biology works by looking at the subgraphs ( of very small size ) that make up a graph @xmath6 .",
    "the method , introduced in  @xcite , turns out to be capable of characterizing networks by the families to which they belong ( e.g. , genetic versus social ) and is therefore also a perfect candidate for quantifying the amount and type of information that is preserved and lost when retaining only the network motifs of the original graph .",
    "it compares the frequency of small subgraphs with randomized versions of the same network ( i.e. , networks with the same size and the same degree distribution ) . over and",
    "under - represented subgraphs are called network motifs and turn out to characterize a network type .",
    "each of these network motifs , defined by a particular pattern of interaction between vertices , may reflect a framework in which particular functions are achieved efficiently .",
    "it is generally believed that motifs are of signal importance largely because they may reflect functional properties .",
    "the calculation of network motifs may provide a deep insight into a network s function but their calculation is computationally challenging .",
    "we are therefore limited to small sizes and hence to considering only local structures .",
    "the surprising result is that these local structures contain enough information about a system to characterize it uniquely , at least in the case of graphs with similar topologies and functions .",
    "a graph in @xmath6 is considered frequent and therefore denoted as a motif when its frequency @xmath31 is above a predefined threshold or cut - off value .",
    "there is an ensemble @xmath42 of random graphs corresponding to the null - model associated with @xmath6 .",
    "we should choose @xmath43 random graphs uniformly from @xmath42 and calculate the frequency for a particular frequent sub - graph @xmath7 in @xmath6 . if the frequency of @xmath7 in @xmath6 is higher than its arithmetic mean frequency in @xmath43 random graphs @xmath44 , where @xmath45 , we consider this frequent subgraph ` significant ' and hence treat @xmath7 as a network motif of @xmath6 .",
    "the @xmath46-score has been defined by the formula ,      where @xmath48 and @xmath49 stand for mean and standard deviation frequency in set @xmath50 .",
    "the larger the @xmath51 , the more significant is the sub - graph @xmath7 as a motif  @xcite .",
    "the biological studies endeavor to interpret the motifs detected for biological networks .",
    "for example , the network motifs found in e. coli were discovered in the transcription networks of other bacteria such as yeast , among others  @xcite .",
    "[ kmotifs ] ) and two universally employed lossless compression algorithms , bzip2 and deflate , the former set to maximum compression ( option flag set at -9 ) and the latter in the default position as implemented in _",
    "s compress function version 10 .",
    "bzip2 is an open source data compressor that uses a stack of different algorithms superimposed one atop the other , starting with run - length encoding , burrows - wheeler or the huffman coding , among others .",
    "we sometimes compare , strengthen or complement findings by also providing estimations of shannon s information entropy on the adjacency matrix .",
    "central to information theory is the concept of shannon s information entropy  @xcite , which quantifies the average number of bits needed to store or communicate a message .",
    "shannon s entropy determines that one can not store ( and therefore communicate ) a symbol with @xmath36 different symbols in less than @xmath52 bits . in this sense ,",
    "shannon s entropy determines a lower limit below which no message can be further compressed , not even in principle . for an ensemble @xmath53 , where @xmath54 is",
    "the set of possible outcomes ( the random variable ) , @xmath55 and @xmath56 is the probability of an outcome in @xmath54 .",
    "the shannon information content or entropy of @xmath57 is then given by            for example , a complete graph and a completely disconnected graph would have minimal shannon entropy because the adjacency matrix entries are either all 0 or all 1 ( assuming self - loops ) . however , erds - rnyi ( er ) graphs with edge density 0.5 would have maximal shannon entropy because their adjacency matrices have about the same number of 1s and 0s and are therefore statistically ` typical' every bit is equally highly surprising .",
    "in other words , the bits of the adjacency matrices of complete and completely disconnected graphs are unsurprising , because getting a 1 after a long list of 1s , or a 0 after a long list of 0s does not add any shannon information .",
    "this is , however , very different in algorithmic information theory , where we are interested in whether bits are causally related .",
    "for example , the adjacency matrix of a directed complete graph  the direction being that the matrix is diagonal , with either all 1s on one side of the diagonal and 0s on the other side ( or the other way around)would have maximal shannon entropy but is clearly not random , and should therefore have a low ( algorithmic ) information content .",
    "we therefore used a graph algorithmic complexity measure rather than this statistical combinatorial one .",
    "the concept of algorithmic probability ( also known as levin s semi - measure ) yields a method for approximating kolmogorov complexity related to the frequency of patterns in the adjacency matrix of a network , including therefore the number of subgraphs in a network .",
    "the algorithmic probability  @xcite of a subgraph @xmath62 is a measure that describes the probability that a random computer program @xmath63 will produce @xmath3 when run on a 2-dimensional tape universal ( prefix - free ) .",
    "for details see  @xcite . ] ) turing machine @xmath64 .",
    "that is , @xmath65 .",
    "an example of a popular 2-dimensional tape turing machine is langton s ant  @xcite , commonly referred to as a _",
    "turmite_.    the probability semi - measure @xmath66 is related to kolmogorov complexity @xmath67 in that @xmath66 is at least the maximum term in the summation of programs ( @xmath68 ) , given that the shortest program carries the greatest weight in the sum .",
    "the algorithmic coding theorem  @xcite further establishes the connection between @xmath66 and @xmath67 as ( @xcite ) : @xmath69 ( eq .",
    "1 ) , where @xmath70 is some fixed constant , independent of @xmath71 .",
    "the theorem implies that  @xcite one can estimate the kolmogorov complexity of a graph from its frequency of production by running random programs that simply rewrite eq .",
    "( 1 ) as : @xmath72 .    in  @xcite",
    "a technique was advanced for approximating @xmath66 ( hence @xmath0 ) by means of a function that considers all turing machines of increasing size ( by number of states ) . indeed , for small values of @xmath36 states and @xmath18 colors ( usually 2 colors only ) , @xmath73 is computable for values of the busy beaver problem  @xcite that are known , providing a means to numerically approximate the kolmogorov complexity of small graphs , such as network motifs .",
    "the coding theorem then establishes that graphs produced with lower frequency by random computer programs have higher kolmogorov complexity , and vice versa .",
    "the method is called the _ block decomposition method _ ( bdm ) because it consists of decomposing the adjacency matrix of a graph into subgraphs of sizes for which complexity values have been estimated , then reconstructing an approximation of the kolmogorov complexity of the graph by adding the complexity of the individual pieces according to rules of information theory , as follows :      where @xmath75 represents the set with elements @xmath76 , obtained when decomposing the adjacency matrix of @xmath6 into all subgraphs contained in @xmath6 of size @xmath77 . in each @xmath76 pair , @xmath78 is one such submatrix of the adjacency matrix and @xmath79 its multiplicity ( number of occurrences ) .",
    "as is evident from the formula , repeated subgraphs only contribute to the complexity value with the subgraph bdm complexity value once plus a logarithmic term as a function of the number of occurrences .",
    "this is because the information content of subgraphs is only sub - additive , as one would expect from the growth of their description lengths ( `` @xmath36 times a subgraph '' ) .",
    "applications of @xmath66 and @xmath67 have been explored in  @xcite , and include applications to graph theory and complex networks  @xcite and  @xcite where the technique was first introduced .      in fig .",
    "[ figure2 ] the motif - analysis software called fanmod  @xcite was used to calculate the graph motifs ( the over - represented subgraphs ) , and we took the output files with the adjacency matrices in string form .",
    "this was done for motifs of size 4 and 5 .",
    "the files considered contained the occurring subgraphs in string notation followed by their frequency of occurrence , so in a strict sense these files are already a compressed version as they only contain the different subgraphs but not their repetitions , other than as encoded in their frequencies . in the files only motifs were considered , that is , subgraphs of size 4 and 5 that were either over or under - represented as compared with randomized versions of the same network .",
    "more precisely , motifs were calculated with fanmod by using a parameter absolute @xmath46 score larger than 2 , a @xmath63-value less than 0.05 , a frequency of at least 0.01% , and included in the output file motifs that have been found at least 5 times .",
    "the files were therefore further compressed with both bzip2 and deflate in order to capture possible statistical regularities in the type and frequencies of the motifs .",
    "then the files were compared to the compressed lengths of the original networks for both compression algorithms .",
    "the underlying rationale is that non - random graphs will show an over - representation of certain motifs and an under - representation of others , hence reducing or increasing the number of these objects in the resulting files .",
    "indeed , from the output files of fanmod one can reconstruct some of the information of the original network , with the number of subgraphs and their frequency , but some information is lost in the form of the way in which all these subgraphs ( motifs ) may have been connected .",
    "motif analysis displays both conservation of information and clustering capabilities by families , as reported in  @xcite and verified again here with bdm .",
    "results are summarized in fig .",
    "[ figure2]c .",
    "it is worth noting that because bdm looks at local regularities only , it may be biasing or amplifying the results toward network motifs over other network dimensionality reduction approaches .",
    "this is not a problem but nonetheless something to be taken into consideration .",
    "another interesting phenomenon to investigate is the information loss and preservation when considering all possible induced subgraphs ( graphlets ) in a graph  @xcite ."
  ],
  "abstract_text": [
    "<S> to cope with the complexity of large networks , a number of dimensionality reduction techniques for graphs have been developed . </S>",
    "<S> however , the extent to which information is lost or preserved when these techniques are employed has not yet been clear . here </S>",
    "<S> we develop a framework , based on algorithmic information theory , to quantify the extent to which information is preserved when network motif analysis , graph spectra and spectral sparsification methods are applied to over twenty different biological and artificial networks . </S>",
    "<S> we find that the spectral sparsification is highly sensitive to high number of edge deletion , leading to significant inconsistencies , and that graph spectral methods are the most irregular , capturing algebraic information in a condensed fashion but largely losing most of the information content of the original networks . </S>",
    "<S> however , the approach shows that network motif analysis excels at preserving the relative algorithmic information content of a network , hence validating and generalizing the remarkable fact that despite their inherent combinatorial possibilities , local regularities preserve information to such an extent that essential properties are fully recoverable across different networks to determine their family group to which they belong to ( eg genetic vs social network ) . </S>",
    "<S> our algorithmic information methodology thus provides a rigorous framework enabling a fundamental assessment and comparison between different data dimensionality reduction methods thereby facilitating the identification and evaluation of the capabilities of old and new methods . + keywords : dimensionality reduction techniques ; kolmogorov complexity ; network ; graph spectra ; graph motifs ; graph sparsification </S>"
  ]
}