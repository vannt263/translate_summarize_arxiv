{
  "article_text": [
    "ising model , which consists of spins arranged in a graph , is a fundamental model in statistical physics .",
    "it also has direct applications in many fields of science including e.g. physics @xcite , neuron science @xcite , computer science @xcite and social science @xcite . with different distribution of couplings ,",
    "ising model can act as model of different systems e.g. ferromagnets , spin glasses and neural networks .",
    "it gives a simple example of phase transitions , which is a phenomenon appearing in different fields of science , and it can be seen as a simple model for collaborative behavior of iterating systems .",
    "exact solution of ising model only exists in special cases of topologies , e.g. one dimensional and two dimensional lattices . on a general graphs that the most applications meet ,",
    "one usually needs approximations , especially with a general distribution of couplings .",
    "commonly used approximations in statistical physics includes na \" i ve mean - field approximation , tap approximation and kikuchi expansions . among those approximation , one of the most popular approximation is bethe approximation which assumes independence of conditional probabilities .",
    "bethe approximation is exact on trees , and is found to be a good approximation on ( random ) sparse systems .",
    "message passing algorithms based on bethe approximation , so called belief propagation ( bp ) algorithms and its variations , have been used widely in many fields @xcite .",
    "it has been recently proposed in @xcite that in network clustering ( community detection ) problem , where the task is to cluster nodes of graph into groups , belief propagation  @xcite , known in statistical physics as the cavity method  @xcite , can be approximated by spectral clustering using a matrix called `` non - backtracking '' matrix @xmath0 .",
    "the reason is that in the clustering problem where permutation symmetry holds , bp equation always has a `` paramagnetic '' fixed - point where every node takes equal probability in each group . linearizing bp equation around this paramagnetic fixed - point results to a linearized version of bp which is equivalent to spectral clustering using non - backtracking matrix on the graph .",
    "spectral clustering using `` non - backtracking '' improves significantly the performance of clustering over other matrices like random walk matrix and laplacians , and gives a nature choice of number of groups in the graph .",
    "the reason for the improvement is that non - backtracking matrix of a graph as a good property that almost all its eigenvalues are confined by a disk in the complex plane , so the eigenvalues corresponding to community structure lay outside the disk and are easily distinguishable .",
    "since the key that relates bp and non - backtracking matrix is the `` paramagnetic '' fixed - point , it is natural to think that similar for graphs , there must be also a non - backtracking matrix for ising model when ising model has a paramagnetic phase at high temperature without external fields .",
    "so the main purpose of this paper is to study the non - backtracking operator to ising model on a graph with a given distribution of couplings at a certain temperature , and study some properties on spectrum of the matrix . unlike non - backtracking matrix in graphs , the non - backtracking matrix of ising model",
    "is a function of couplings and temperature . in another sense",
    "we can think it as a non - backtracking matrix of a weighted graph .",
    "we also study the application of matrix @xmath1 with some special distribution of couplings where ising model acts like spin glasses or associative memory .",
    "we show how to use spectrum of @xmath1 to detect phases and phase transitions in the thermodynamics limit of system as well as in single instance of small systems .",
    "we will also give an example on how to control the neural network using eigenvalues and eigenvector of @xmath1 .",
    "the paper is organized as follows .",
    "section  [ sec : b ] includes definitions of the non - backtracking matrix for ising model , some properties of its spectrum for general couplings are computed . in section",
    "[ sec : examples ] we give several examples on ising model with specific coupling distributions , including ferromagnet , sherrington - kirkpatrick model and viana - bray model .",
    "we show that in the thermodynamic limit results obtained using non - backtracking matrix recover the known results of phase boundaries . in section  [ sec : hop ] we consider hopfield model as associative memory where some binary patterns are memorized . in thermodynamics limit we recover the phase boundaries obtained by replica method , it also allows one to determine number of patterns and retrieve all the patterns simultaneously . on single instances",
    "we show how to make a given network more sparse while keeping patterns memorized using non - backtracking matrix .",
    "we conclude in section  [ sec : dis ] .",
    "as we introduced in the introduction , non - backtracking operator appears naturally in linearizing bp of inference of stochastic block model @xcite , also in linearizing bp for modularity @xcite .",
    "so we can do similar things : obtaining non - backtracking operator by linearizing bp equation of ising model at paramagnetic fixed point .",
    "we consider ising model on a graph with @xmath2 spins , @xmath3 is used to denote a configuration , with @xmath4 and @xmath5 .",
    "energy ( hamiltonian ) of system with zero external field is pairwise : @xmath6 boltzmann distribution with inverse temperature @xmath7 reads @xmath8 on a single instance of the graph , one can use belief propagation algorithm to study the marginals of the boltzmann distribution . for ising model",
    ", bp equation reads @xmath9 where @xmath10 denotes `` cavity '' probability of @xmath11 taking value @xmath12 with spin @xmath13 removed from the graph , @xmath14 denotes neighbors of @xmath15 and @xmath16 is the normalization .",
    "when bp equation converges on a graph , one can compute marginals of a spin taking value @xmath12 using @xmath17 where again @xmath18 is the normalization .",
    "it is easy to see that @xmath19 for all cavity messages and all marginals is always a fixed point of bp .",
    "we call this fixed point `` paramagnetic '' fixed - point",
    ". we can write bp messages as deviations from this paramagnetic fixed point : @xmath20 with @xmath21 it is easy to check that derivatives of bp messages evaluated at paramagnetic fixed - point reads @xmath22 equation is a linearized version of bp equation , and it is equivalent to the eigenvector problem of an operator that we call non - backtracking for ising model : @xmath23 which is defined on the directed edges of the graph , with weight @xmath24 on each directed edge .",
    "if we use @xmath25 to denote number of edges in the graph , then the size of @xmath1 is @xmath26 .",
    "note that in right hand side of last equation , @xmath27 is the non - backtracking operator used in @xcite for clustering problem . in discussion of @xcite authors",
    "suggested a weighted non - backtracking matrix , and our matrix @xmath1 can be seen as such weighted non - backtracking matrix , with weight @xmath24 on each edge .",
    "following the technique used in @xcite , the edge of bulk of eigenvalues of @xmath1 can be computed by the following inequality , @xmath28 where @xmath29 denotes one eigenvalue , and there are @xmath30 such eigenvalues .",
    "note that @xmath31}_{i\\to j , i\\to j}$ ] is contributed by paths connecting edge @xmath32 with distance @xmath33-step away : @xmath34}_{i\\to j , i\\to j}=\\sum_{u}\\prod_{(x\\to y ) \\in",
    "u}\\tanh^2(\\beta j_{x\\to j}),\\ ] ] where @xmath35 denotes one such path and @xmath36 denotes edges belonging to path @xmath35",
    ". when @xmath2 is large , and couplings @xmath37 are i.i.d",
    ". distributed , for each path @xmath35 we have @xmath38 where average @xmath39 is taken over realizations of couplings , and there are @xmath40 such paths with @xmath41 denoting excess degree @xmath42 by taking expectation we have @xmath43 then relation can be written as @xmath44 and it holds for any @xmath33 .",
    "last equation tells us that almost all @xmath1 s eigenvalues are confined by a disk of radius @xmath45 in the complex plan , with @xmath46 the disk containing almost all the eigenvalues means the density of eigenvalues @xmath47 is non - zero inside the disk , and is zero outside the bulk .",
    "note that there could be outlier eigenvalues outside the bulk with zero density .",
    "there is another way to understand the edge of bulk , in the sense of noise propagation on trees : consider some random noise with mean @xmath48 and unit variance are put on the leaves of a tree ; by iterating @xmath1 , the noise may be propagated to the root of the tree with non - vanishing variance , if @xmath49 thus radius of disk @xmath50 tells us that random noise could make edwards - anderson order parameter @xcite of the system finite , which is a sign showing that system is in the `` spin glass '' state , and replica symmetry is breaking .",
    "so @xmath45 tell us where is the spin glass state and its relative strength to other possible states .",
    "@xmath51 point is also known as the de almeida - thouless local stability condition  @xcite , the kesten - stigum bound  @xcite , or the threshold for census or robust reconstruction  @xcite .",
    "if there are real - eigenvalues outside the bulk , they may tell us other possible state of the system , which correspond to other bp solutions .",
    "for example , if all the couplings are positive , it is easy to see that there could be one positive eigenvalue associated with an eigenvector with most of its entries positive .",
    "we can approximately recover this eigenvector by the following scheme : assume the graph is a tree with all its nodes associated with spin @xmath52 , or equivalently on the edge associated with leaves of the tree @xmath53 .",
    "by @xmath33 steps iterating of @xmath1 , we define an ferromagnetic `` approximate '' eigenvector @xmath54 as @xmath55 if with @xmath56 the vector @xmath57 is still correlated with @xmath58 , the all - one vector on the leave , system has a ferromagnetic state where information is preserved during iterating . on a tree ,",
    "last equation can be written as contribution of paths @xmath35 connecting edge @xmath32 and edge @xmath59 distance @xmath33 away : @xmath60 where @xmath61 denotes edges belong to path @xmath35 , and there are @xmath40 such paths .",
    "when @xmath2 and @xmath33 are large , if we assume the self - average property , @xmath62 eq .   can be written as @xmath63 where @xmath39 is again taking average over realizations of couplings .",
    "iterating @xmath1 once gives @xmath64 and the eigenvalue is @xmath65 @xmath66 is indeed an eigenvector of @xmath1 if @xmath67 goes to zero when @xmath33 is large . in another words",
    ", @xmath66 is an eigenvector if the noise propagation is slower than propagation of information @xmath68 , that is @xmath69 , which asks the informative eigenvalue of ferromagnetic state out of the bulk . besides the ferromagnetic eigenvalue",
    ", there could be other real - eigenvalues representing other states of the system .",
    "so the competition of real - eigenvalues and @xmath45 gives us the information of the phases and phase transitions of system .",
    "we note that @xmath45 and @xmath70 have been already computed in @xcite , using a different technique .",
    "however authors in @xcite did not claim or show the sharp edge of bulk of spectrum .",
    "another reason that we keep the detailed computation of @xmath70 and @xmath45 in this paper is that we need the technique in sec .",
    "[ sec : hop ] to compute the spectrum of non - backtracking matrix of hopfield neural networks .",
    "in this section we apply the non - backtracking operator to ising model with specific distributions of couplings .",
    "one aim is to see whether non - backtracking operator recovers the known results of phase transitions on those systems .      for first example",
    "we consider ferromagnetic ising model , which has @xmath71 . if we consider ferromagnet on erds - rnyi random graphs where @xmath72 , result given by non - backtracking matrix would be quite accurate , due to the locally tree - like structure of the topology . from the analysis of last section , for this model we have @xmath73 and @xmath74",
    "thus @xmath75 is always larger than @xmath76 with finite @xmath7 and @xmath77 .",
    "it means this system can never be in spin glass state , it has to be in either ferromagnetic state or paramagnetic . and at @xmath78 , which implies that at @xmath79 system undergoes a transition from paramagnetic to ferromagnetic phase .",
    "note that @xmath1 can be expressed as @xmath80 where @xmath0 is the non - backtracking matrix on the graph . from @xcite",
    "we know that @xmath0 has the largest eigenvalue @xmath81 , so as a sanity check , one can verify that @xmath82 . in fig .",
    "[ fig : ising ] spectrum of @xmath1 is plotted in the complex plane for ising model on a random graph with two @xmath7 values , one is in paramagnetic state and the other one is in ferromagnetic state . as shown in the figure , with @xmath83 , the largest eigenvalue of @xmath1 is smaller than one , which tells us that the paramagnetic fixed - point is stable . with @xmath84 ,",
    "the largest eigenvalue of @xmath1 is greater than @xmath85 , telling us the paramagnetic fixed - point is unstable towards the direction of ferromagnetic state .",
    "it has been shown in @xcite that non - trivial part of @xmath0 s spectrum is can be obtained from a @xmath86 matrix @xmath87 where @xmath88 is diagonal matrix with degree of nodes on the diagonal entries , @xmath89 is the identity matrix and @xmath90 is the adjacency matrix .",
    "thus non - trivial part of @xmath1 s spectrum for ferromagnet can also be computed with less effort .     and",
    "@xmath91 ( left ) and @xmath92 ( right ) [ fig : ising],title=\"fig : \" ]   and @xmath91 ( left ) and @xmath92 ( right ) [ fig : ising],title=\"fig : \" ]      if the network has a community structure , e.g. the number of edges connecting same group is much larger than number of edges connecting to different groups , besides the eigenvector pointing in direction to all - one vector , there could be other eigenvectors with some positive and some negative entries , with signs representing group memberships .",
    "here we consider networks that generated by a generative model named stochastic block model ( sbm ) or planted partition model @xcite .",
    "sbm is one of the widely used model to generate benchmark networks containing community structure . in the model , there are @xmath93 groups of nodes , each node @xmath15 has a pre - assigned group label @xmath94 , edges are generated independently according to a @xmath95 matrix @xmath96 by connecting each pair of nodes @xmath97 with probability @xmath98 . here for simplicity we discuss the commonly studied case that matrix @xmath96 has only two distinct entries , @xmath99 if @xmath100 and @xmath101 if @xmath102 , and we use @xmath103 to denote the ratio between these two entries .",
    "a phase transition at @xmath104 @xcite has been discovered in this model that finite amount of information about planted partition @xmath105 can be inferred with @xmath106 , and one can do the optimal inference of sbm to recover information of @xmath105 all the way down to the transition .",
    "so it is a good benchmark for testing performance of community detection algorithms .",
    "here we consider the simple two - group case with equal group sizes . from @xcite we know that in the detectable regime , edge of bulk of matrix @xmath0 is @xmath107 , it has two real eigenvalues outside the bulk , the first one @xmath108 corresponds to the eigenvector with entries having same sign .",
    "and the second one @xmath109 corresponds to the eigenvector correlated with community structure .",
    "according to eq .  , edge of bulk of matrix @xmath1 on the network is @xmath110 first eigenvalue is @xmath111 , and the eigenvalue corresponding to the community structure is @xmath112 so if @xmath113 , the community structure in the network is detectable by ising model ( by excluding the ferromagnetic state in some way ) .",
    "recall that belief propagation we used to derive the non - backtracking matrix at the beginning of the paper is nothing but an iterative method to decrease bethe free energy ; and a fixed point of belief propagation is a local minimum of bethe free energy @xcite .",
    "obviously paramagnetic solution is always one local minimum of bethe free energy .",
    "as we discussed above , eigenvalues larger than one in non - backtracking matrix tells us the instability of this paramagnetic fixed - point , which is also the instability of this local minimum of bethe free energy .",
    "there is another way to study the instability of a minimum of free energy , which is hessian matrix of bethe free energy ( we call it hessian for simplicity ) evaluated at paramagnetic fixed - point @xcite , which reads @xmath114}\\delta_{ij } -\\frac{\\tanh(\\beta j_{ij})}{1-\\tanh^2(\\beta j_{ij})}.\\ ] ] detailed derivations can be found at e.g. @xcite . for ferromagnets",
    "last equation reduces to @xmath115 the paramagnetic state is stable if this matrix is positive semidefinite . if it has negative eigenvalues , there must be other minimums of free energy at some point in the phase space , in direction that pointed by components of eigenvectors corresponding to negative eigenvalues .",
    "this scheme has been used in @xcite to do spectral clustering on graphs where the hessian is expressed as a function of @xmath33 , with @xmath116 in our settings .    given @xmath7 and the graph",
    ", we have the following picture on the non - backtracking matrix and hessian matrix : if @xmath117 , only paramagnetic fixed - point is stable , hessian is positive semi - definite . if @xmath118 and @xmath119 , paramagnetic fixed - point is unstable towards the ferromagnetic state , hessian has one negative eigenvalues .",
    "if @xmath113 , paramagnetic fixed - point is unstable towards both the ferromagnetic state and the planted configuration ( the community structure ) , hessian has two negative eigenvalues .",
    "then we see that non - backtracking matrix works equivalently to hessian in determine the phases of ferromagnets .",
    "but we note that computing spectrum of hessian is much faster than non - backtracking matrix , because hessian is symmetric and size of hessian is smaller ( @xmath120 instead of @xmath26 in non - backtracking matrix ) .",
    "if we are not interested in the phase of ising model but only the problem of node clustering in a given network , we can choose @xmath7 as we want .",
    "as we shown above , @xmath7 does not influence the shape of spectrum of non - backtracking matrix , if @xmath121 , the second eigenvalue is always outside the bulk , thus we can always check whether there is a second eigenvalue outside the bulk to determine number of groups and use the eigenvector associated with it to detect the community structure .",
    "this is the idea explored in @xcite which uses matrix @xmath0 in doing spectral clustering .",
    "the situation is different for hessian , if @xmath7 is too small , hessian is positive semidefinite , it looses its ability of determining number of groups in network .",
    "so it is important to select a good @xmath7 value that gives negative eigenvalues .",
    "the authors of @xcite suggested to chose @xmath122 , equivalent to set @xmath123 in our settings . as we discussed above , @xmath122 is the point that edge of bulk reaches @xmath85 , thus if there is a second real - eigenvalue of @xmath1 outside the bulk and is greater than @xmath85 , or equivalently a stable state correlated with community structure in ising model , one should be able to find a second negative eigenvalue of @xmath124 with @xmath122 .    on the one hand , detecting number of groups using real eigenvalues of @xmath0 outside the bulk is easier than tunning @xmath7 value to look for negative eigenvalues of @xmath124 , especially on real - world networks .",
    "but on the other hand , tunning @xmath7 gives @xmath124 ability to optimize accuracy of detected communities , at least in synthetic networks .",
    "spin glass models were proposed to explain magnetic systems with frozen structural disorder , by introducing `` frustration '' using a particular distribution of couplings .",
    "now theory of spin glasses e.g. replica symmetry breaking and cavity method find many application is many fields . in this section",
    "we consider non - backtracking matrix of two spin glass models , namely sherrington - kirkpatrick model @xcite and viana - bray model @xcite .",
    "it is well known that those spin glass models have paramagnetic phase at high temperature and spin - glass phase at low - temperature where both magnetization and edwards - anderson parameter are non - zero , and the replica symmetry is broken @xcite .",
    "first we consider sherrington kirkpatrick model which is defined on fully connected graph with couplings following gaussian distribution : @xmath125 from eq .   and eq .  , we have @xmath126 and @xmath127 so the paramagnetic solution is stable as long as @xmath128 .",
    "and system enters spin glass state with @xmath129 .",
    "these are the well known results .    to test theory ( eq .  ) , in fig .",
    "[ fig : sk_beta ] we plot the edge of bulk ( absolute value of the largest eigenvalues ) as a function of @xmath7 for networks with @xmath130 .",
    "we can see that it consistent well with @xmath131 .    the spectrum of @xmath1 on sk model with two @xmath7 values are also shown in fig .",
    "[ fig : sk ] .",
    "we can see that with @xmath132 , the edge of bulk is smaller than @xmath85 , which means system is in paramagnetic phase . in the right , with @xmath129 , the edge of bulk is greater than @xmath85 , system is in the spin glass phase . moreover , from eq .",
    "we can also see that for the fully connected model distribution of couplings are not important , what really matters to the spin glass transition is the variance of couplings .    from the last section , we see that hessian matrix of bethe free energy works as well as non - backtracking matrix in detecting paramagnetic to ferromagnetic transition in ferromagnets , but it does not work well in sk model .",
    "our numerical result ( as well as experimental results in @xcite ) show that hessian matrix for sk model is positive definite , thus it does not tell us where system encounters the spin glass transition .",
    ", as a function of @xmath7 for sk model with @xmath130 .",
    "each point is averaged over @xmath133 instances .",
    "[ fig : sk_beta ] ]     and @xmath134 . in left panel @xmath135 , system is in paramagnetic phase and in right panel @xmath136 , system is in spin glass phase.[fig : sk],title=\"fig : \" ]   and @xmath134 . in left panel @xmath135",
    ", system is in paramagnetic phase and in right panel @xmath136 , system is in spin glass phase.[fig : sk],title=\"fig : \" ]      viana - bray model @xcite , also called @xmath137 model , is a spin glass model defined on random graphs .",
    "it is similar to the ferromagnets on random graphs but with couplings taking @xmath12 and @xmath138 randomly which give frustration to the system .",
    "@xmath139 by varying @xmath140 and @xmath7 , the system can be in paramagnetic phase , spin glass phase or ferromagnetic phase . from  eq .",
    "we have @xmath141 and @xmath142 obviously system undergoes paramagnetic to spin glass transition at @xmath143 independent of @xmath140 . and may undergo paramagnetic to ferromagnetic transition if @xmath144 .",
    "so our result recovers the phase boundaries derived using replica methods in @xcite . in fig .",
    "[ fig : vb ] we plot the spectrum of non - backtracking matrix for viana - bray model in the complex plane for system in two phases , one in spin glass phase where there is no real eigenvalues outside the bulk , and the other one in ferromagnetic phase where there is one real eigenvalue outside the bulk and is greater than @xmath85 .    , @xmath145 .",
    "in the left panel @xmath146 , @xmath147 , system is in spin glass phase and in the right panel @xmath148 , system is in ferromagnetic phase [ fig : vb],title=\"fig : \" ] , @xmath145 . in the left panel @xmath146 ,",
    "@xmath147 , system is in spin glass phase and in the right panel @xmath148 , system is in ferromagnetic phase [ fig : vb],title=\"fig : \" ]",
    "hopfield model is a classic model for associative memory , it stores patterns by couplings of ising model .",
    "we assume @xmath149 random binary patterns @xmath150 $ ] with @xmath151 $ ] , @xmath152 $ ] stored in network by hebb s rule @xcite : @xmath153 if @xmath149 patterns are memorized successfully , they can be retrieved by glauber dynamics @xcite : at time @xmath154 one neuron @xmath15 is randomly selected and its value @xmath155 is updated according to the probabilistic rule @xmath156 from a random configuration , glauber dynamics could converge to set of configurations that correlated with one pattern .",
    "if all patterns are memorized successfully in the network , each pattern will behave like an attractor to the glauber dynamics , with different basin of attractions .",
    "that is why hopfield model is categorized into attractor neural networks @xcite .",
    "the reason that patterns behave as attractors to the dynamics is that in hebb s rule , each pattern corresponds to a minima of free energy , and glauber dynamics , which a `` spin - flip '' algorithm that converges to equilibrium , will trap into one of those local minimum of free energy .",
    "the original hopfield network was defined on fully - connected network , and its statistical mechanics has been studied @xcite using replica method . however fully - connected model is not biologically realistic . in this paper",
    "we will focus on its more biologically - realistic version , which is hopfield model on a random graph .",
    "the model is also called finite - connectivity hopfield model and its statistical mechanics has also studied using replicas @xcite , and phase boundaries were analyzed .",
    "the phase diagram of hopfield model ( both fully - connected and on a random graph ) is composed of three parts : at high temperature every neuron behaves the same , magnetization is zero , system is in the paramagnetic phase ; at a low temperature and with a low number of patterns , patterns are attractive to glauber dynamics and system is in `` retrieval '' or `` memory '' phase ; at a low temperature and a high number of patterns , network is confused by so many patterns thus none of the pattern is memorized successfully , glauber dynamics will go away even started from one of the patterns , system is in spin glass phase .    note that replica results were derived for the model at thermodynamic limit averaged over disorder ( realizations of patterns ) , thus it is hard to apply the replica result to a single instance of network , to do tasks such as retrieving patterns and determining number of patterns .",
    "the classic way to do such tasks is glauber dynamics .",
    "however on large networks it is time consuming , and the result depends on the initial configuration of the dynamics . and it is hard for glauber dynamics to determine how many patterns stored in the network , because one can not explore all the initial configurations",
    ".    a faster way to retrieval patterns is running bp on the instance .",
    "but there is still a drawback that it is difficult to answer how many patterns there are in the network , since explore all possible initial messages for bp is hard .",
    "in the rest part of the section we will study how to do the pattern retrieval task using non - backtracking matrix .",
    "it recovers replica result at thermodynamics limit easily , and on single instances it has advantages over glauber dynamics and bp for speed as well as for determining number of patterns .",
    "first we study the spectrum of non - backtracking operator at thermodynamic limit . from eq .",
    ", the edge of bulk of hopfield model , which tells us where is the spin glass phase , is expressed as @xmath157 the averaging is taken over random patterns .",
    "obviously there is no stable `` ferromagnetic '' state since if we iterate @xmath1 with all - one configuration @xmath158 on leaves of the tree , we get @xmath159 however , note that if instead of all - one configuration , we put a pattern in the leaves of the tree and do iterating , the information of the pattern could be preserved during iterating .",
    "it is very similar to initialize belief propagation by messages correlated with one pattern , or running glauber dynamics from a pattern .",
    "analysing iterating with a random pattern on leaves is difficult , but we can show it in an equivalent but easier way , by focusing on one of the stored patterns , let us say @xmath160 without loss of generality . since patterns are chosen randomly and independently , we can do a gauge transformation to all the patterns which transforms @xmath160 to all - one configuration , and transforms other patterns to @xmath161 it is easy to see that this transformation does not change distance between patterns , thus does not change the property of the system .",
    "original patterns can be recovered easily by product @xmath162 again : @xmath163 under this transformation , couplings become @xmath164}.\\ ] ] obviously now couplings are biased to positive , and there could be a ferromagnetic state in the transformed system",
    ". then we can treat @xmath165 term as a `` signal '' term that tells us information about all - one configuration , and term @xmath166 as a `` noisy '' term that gives some cross - talk noise to signal term .",
    "if there is only one pattern , cross - talk noise is @xmath48 , the problem essentially goes back to the ferromagnets .",
    "when number of pattern is small , noisy term has small fluctuation thus signal remains clear during iterating .",
    "it is easy to see that the eigenvector correlated to the all - one vector in the transformed system is related to the eigenvector correlated with the first pattern in the original system . and the eigenvalue associated with the eigenvector correlated with all - one vector in the transformed system is the same with the eigenvalue associated with eigenvector correlated with first pattern in original system . with @xmath167",
    ", this eigenvalue can be written as @xmath168 so setting @xmath169 gives paramagnetic to retrieval transition and @xmath170 gives paramagnetic to spin glass transitions .",
    "if we write last equation in the form of @xmath171 we can see that the expression for phase boundaries are in agreement with result obtained by replica method @xcite , considering a little different definition of the model .",
    "moreover , with patterns chosen randomly at thermodynamic limit , we have @xmath172    if we do the above gauge transform on every pattern , we would have @xmath149 such eigenvalues . but note that though we studied the @xmath173 and @xmath174 with the gauge transform , it is only a trick to study analytically in an easier way the eigenvalues . in a single instance , we do not need to do such transform , there should be @xmath149 eigenvalues corresponds to @xmath149 patterns . and on the given network , once we find real eigenvalues outside the bulk , we can use eigenvectors associated with those eigenvalues to retrieve patterns .    for more detail , after we have an eigenvector @xmath175 , first we obtain the vector @xmath176 containing summation of incoming values from edges for nodes , from an eigenvector @xmath177 , @xmath178 then we set positive entries of @xmath176 to @xmath85 and negative entries to @xmath138 , and zero entries to @xmath85 or @xmath138 randomly .",
    "the obtained configuration should be correlated with the pattern , i.e. the overlap parameter which is inner product of obtained configuration and a pattern @xmath179 is positive .    in fig .",
    "[ fig : scatter_plot ] we plot one memorized binary pattern compared with one eigenvector of non - backtracking matrix , we can see that the sign of components of eigenvector are correlated with sign of the binary pattern .    .",
    "[ fig : scatter_plot ] ]    in fig .",
    "[ fig : hop ] we plot the spectrum of a hopfield network with different parameters in the complex plane . in left panel ,",
    "@xmath180 , three patterns are memorized , system is in retrieval phase .",
    "there are three eigenvectors outside the edge of bulk , and the associated eigenvectors are correlated with three stored patterns , with the overlap ( eq . ) for three patterns much larger than @xmath48 . in right panel ,",
    "@xmath181 , none of the patterns is memorized successfully . in spectrum ,",
    "the edge of bulk is larger than @xmath85 , there is no real eigenvalues outside the bulk , so system is in spin glass state .    in the thermodynamic limit",
    ", self - averaging property will make those @xmath149 eigenvalues identical .",
    "but in the finite - size networks , we could obtain different eigenvalues , telling us that @xmath149 patterns are not memorized equally strong .",
    "one example is shown in left panel of fig .  [",
    "fig : hop ] where three real - eigenvalues outside the bulk are not equal to each other . when @xmath149 real - eigenvalues",
    "are all out of bulk but not equal , though from random initial vectors , iterating @xmath1 will always leads to the eigenvector associated with the largest eigenvalue , other patterns could be retrievable by other methods , e.g. by running glauber dynamics starting from a configuration or running bp from a random messages .",
    "we have tested that by running glauber dynamics we can reach other patterns according to the eigenvalues outside the bulk from random initial configurations .",
    "we think the pattern with the largest eigenvalue are indeed stronger than other two patterns , and has larger basin of attraction than other two patterns ; however its basin attraction does not dominate the entire configuration space , so other two patterns are still able to attract glauber dynamics .",
    "another situation is that not all @xmath149 eigenvalues are outside the bulk and larger than @xmath85 .",
    "this means not all the patterns are memorized stably .",
    "we have tested that in this case only patterns according to eigenvalues outside the bulk are attractive to glauber dynamics . for those patterns according to eigenvalues inside bulk or smaller than @xmath85 ,",
    "glauber dynamics starting from exactly the pattern will still run away and converge to configurations around other patterns .",
    "so those patterns are indeed not retrievable .",
    "so as described above , we can find all real - eigenvalues and use all real - eigenvectors associated with those eigenvalues to retrieve pattern simultaneously , as opposed to bp or glauber dynamics , where only one pattern is retrieved at one time , without knowing neither total number of patterns , nor which patterns are memorized stronger than the others .",
    "besides the phase diagram , another property that has been studied extensively in neural networks is the capacity of the network that we denote by @xmath182 .",
    "capacity is the maximum number of patterns ( divided by number of neurons ) that could be stored successfully .",
    "this property is closely related to the strength of the memorized patterns . in our picture of spectrum of non - backtracking operator , by increasing number of patterns , number of real eigenvalues outside of bulk increases , but each of eigenvalue becomes closer to the bulk .",
    "when @xmath149 exceeds @xmath183 , real - eigenvalues disappear and become complex eigenvalues , then system enters spin glass phase and losses all the memory .    a large amount of studies",
    "have been devoted to increase capacity and the retrieval abilities of neural networks by optimizing the learning rule or by optimizing the topology of the network @xcite . in the following text of the paper we are going to discuss more on optimizing the topology of the network .",
    "we know that fully - connected hopfield network can store number of patterns proportional to number of neurons , but the fully - connected topology is not biological realistic . on the other hand , when we dilute the network , i.e. by making the network more and more sparse by removing edges , number of patterns stored is decreasing but the number of patterns per edge is increasing @xcite .",
    "thus one interesting question would be , given a network , how to make the network more sparse while keeping information of pattern stored by the network unchanged .",
    "this problem could be studied easily by non - backtracking matrix , since real eigenvalues outside the bulk tell us the stability of patterns , if we can keep those eigenvalues unchanged in manipulating topology of the network , we can keep those patterns stable in the network . a nature idea to keep eigenvalues",
    "could be by converting the problem to an optimization problem that at each time we remove the edge that decrease least the gap of eigenvalues , @xmath184 where @xmath185 is the eigenvalue corresponding to the pattern we want to keep , and @xmath186 is the edge of bulk of non - backtracking matrix .",
    "this process is easy to implement but the computation is time consuming because selecting the edge that decreases least the spectral gap we have to remove every edge from the graph one by one , compute eigenvalues , then add the edge back .",
    "one way to make the process faster is to remove the edge that changes least the spectral gap among small randomly selected subset of edges .",
    "actually if we are interested in keeping one eigenvalue @xmath187 instead of keeping the gap , we can do things much easier .",
    "assume after one edge removed , matrix @xmath1 becomes @xmath188 if we look @xmath189 as a perturbation to the matrix @xmath1 and assume that after the perturbation , an eigenvalue changes from @xmath187 to @xmath190 , a left eigenvalue changes from @xmath191 to @xmath192 , and a right eigenvector changes from @xmath177 to @xmath193 , then we have the following relation @xmath194 ignoring second order terms , we have @xmath195 multiplying left eigenvector @xmath191 in both sides of last equation results to @xmath196 then the expression of change of @xmath187 by perturbation is written as : @xmath197 in our problem @xmath189 is actually a matrix with entries zero except those with edges @xmath32 and @xmath198 involved .",
    "then the last equation can be written as @xmath199      \\nonumber\\\\      & = & \\frac{2\\lambda}{uv}(u_{i\\to j}v_{i\\to j}+u_{j\\to i}v_{j\\to i}).\\end{aligned}\\ ] ] so the change of eigenvalues becomes a function of left and right eigenvectors . by computing once the eigenvectors , we know exactly which edge could change least the eigenvalue .",
    "so we can make network more sparse while keeping information of a pattern stable , by removing edges that give least @xmath200 iteratively . for more detail , at each step , left and right eigenvectors associated with a real eigenvalue are computed , one ( or several edges ) that minimizes @xmath200 are removed , then the above process are repeated until network is sparse enough .",
    "note this procedure is similar to the decimation algorithm using marginals of a message passing algorithm in solving constraint satisfaction problems @xcite , where nodes having most biased marginals are removed ( fixed ) at each iterating .",
    "we did some numerical experiments on the edge - removing scheme and compared its performance with random removing in fig  [ fig : deci ] , where the real eigenvalue and edge of bulk are plotted as a function of fraction of edges removed .",
    "we can see from the figure that random removing makes the real eigenvalue decreasing very fast while our process keep the eigenvalue unchanged up to more than half edges removed . though edge of bulk in our process decreases also slower , the real eigenvalue joins bulk later than that in random removing .",
    "note that the problem of removing edges is just a simple example of optimizing topology of a neural network using the non - backtracking operator .",
    "since information of stability of patterns can be obtained at same time by non - backtracking matrix we believe other kinds of topology optimization on neural networks can also be done easily using non - backtracking matrix .",
    "and @xmath201 patterns with @xmath202 ( left ) and @xmath203 patterns with @xmath204 ( right ) .",
    "in left panel , three patterns are all memorized , overlap ( eq . ) for three patterns obtained using first three eigenvectors are @xmath205 , @xmath206 and @xmath207 . in right panel none of the patterns",
    "is memorized , system is in the spin glass phase . [",
    "fig : hop],title=\"fig : \" ]   and @xmath201 patterns with @xmath202 ( left ) and @xmath203 patterns with @xmath204 ( right ) . in left panel ,",
    "three patterns are all memorized , overlap ( eq . ) for three patterns obtained using first three eigenvectors are @xmath205 , @xmath206 and @xmath207 . in right panel none of the patterns",
    "is memorized , system is in the spin glass phase . [",
    "fig : hop],title=\"fig : \" ]    .[fig : deci ] ]",
    "as a conclusion , we have introduced non - backtracking operator for ising model with general coupling distributions , it can be seen as a generalization of non - backtracking operator from a unweighted graph to weighted graph with an edge weighted by @xmath208 . in thermodynamic",
    "limit its spectrum gives us phase transitions of the model . and in single instances its eigenvectors can be used to control the model .",
    "all above studies were made for ising model without external fields . with external fields present ,",
    "it has been shown @xcite that paramagnetic solution still exists but with finite magnetization .",
    "it would be interesting to extend current study to that case .    if one compares the spectrum of non - backtracking operator of a hopfield model with @xmath149 patterns and that of a network generated by stochastic block model with @xmath149 communities , one find that they are quite similar .",
    "however the stochastic block model corresponds to a potts model with @xmath149 states and one basin of attraction , as opposed to hopfield model which corresponds to ising model with @xmath209 states and @xmath149 basin of attractions .",
    "so it would be interesting to study such connection in detail in future work .",
    "note that spectrum density of non - backtracking matrix of a graph has been computed in @xcite using belief propagation",
    ". it would be interesting to compute non - backtracking matrix of ising model using the same technique .",
    "p.z . was supported by afosr and darpa under grant fa9550 - 12 - 1 - 0432 .",
    "we are grateful to ruben andrist , florent krzakala , cristopher moore , alaa saade and lenka zdeborov for helpful conversations , and federico ricci - tersenghi for discussing and pointing out reference @xcite ."
  ],
  "abstract_text": [
    "<S> the non - backtracking operator was recently shown to give a redemption for spectral clustering in sparse graphs . in this paper </S>",
    "<S> we consider non - backtracking operator for ising model on a general graph with a general coupling distribution by linearizing belief propagation algorithm at paramagnetic fixed - point . </S>",
    "<S> the spectrum of the operator is studied , the sharp edge of bulk and possible real eigenvalues outside the bulk are computed analytically as a function of couplings and temperature . </S>",
    "<S> we show the applications of the operator in attractor neural networks . at thermodynamic limit </S>",
    "<S> , our result recovers the phase boundaries of hopfield model obtained by replica method . on single instances of hopfield model , its eigenvectors </S>",
    "<S> can be used to retrieve all patterns simultaneously . </S>",
    "<S> we also give an example on how to control the neural networks , i.e. making network more sparse while keeping patterns stable , using the non - backtracking operator and matrix perturbation theory . </S>"
  ]
}