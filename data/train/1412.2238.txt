{
  "article_text": [
    "many dynamical systems can be modelled as continuous - time markov processes @xmath0 that are driven by gaussian white noise @xmath1 with @xmath2 and @xmath3 .",
    "the temporal evolution of such a process obeys a langevin equation ",
    "a first order ordinary differential equation ( ode ) that is stochastically forced @xmath4    here and in the following it s definition of a stochastic integral is used @xcite .",
    "furthermore , a stationary stochastic process is looked at , whereas in general @xmath5 and @xmath6 may depend on time .",
    "the kramers  moyal coefficients of the fokker ",
    "planck equation corresponding to eq .",
    "( [ langevin_y ] ) are denoted by @xmath7 and @xmath8 and commonly referred to as drift- and diffusion function respectively @xcite .",
    "these functions uniquely define the stochastic process and are related to @xmath5 and @xmath6 by @xmath9    it is possible to estimate @xmath7 and @xmath8 from a given time series of @xmath10 by a markov analysis .",
    "this technique , also denoted as direct estimation method , has been introduced in the late 1990s @xcite . since then it has been successfully applied to problems out of many different fields .",
    "reviews on markov analysis and its applications can be found e.g. in @xcite .",
    "the method is based on the fact that the moments @xmath11 of the conditional process increments of @xmath10 can be expressed in terms of the kramers  moyal coefficients @xmath12^k\\right>\\big|_{{{\\mathbf}{y}}(t)={{\\mathbf}{y}}}\\cr   & = & \\tau{\\mathbf}{d}^{(k)}({{\\mathbf}{y}})+o(\\tau^2 ) , \\quad k\\;=\\ ; 1,2.\\end{aligned}\\ ] ]    here and in the following the @xmath13-th power of a vector denotes a @xmath13-fold dyadic product . the time argument @xmath14 of @xmath11",
    "is suppressed here because a stationary process is assumed .",
    "this assumption also allows a moment estimation from a single time series ",
    "ensemble averages can be replaced by time averages then ( tacitly assuming ergodicity ) . for a non - stationary process",
    "an ensemble of time series would be needed ( alternatively a windowing strategy could be applied , assuming a slowly varying time dependence ) .    the moments @xmath11 ( eq .  ( [ moments_incy ] ) ) can be expressed in terms of moments @xmath15 of the two - point probability density function ( pdf ) of @xmath10 at times @xmath14 and @xmath16 .",
    "these moments @xmath15 are defined as @xmath17    where again the time argument @xmath14 is suppressed because of the assumption of stationarity . using the well known relations @xmath18 and @xmath19 leads to @xmath20    for @xmath21 , this yields @xmath22 ( suppressing the unneeded argument @xmath23 and taking into account the scalar nature of @xmath24 ) . consequently one can write @xmath25 and one obtains @xmath26    the moments @xmath27",
    "can directly be estimated from a given time series . in practise",
    ", this is usually done by applying a binning approach . estimating the moments for a number of time increments",
    "@xmath23 then allows to solve eq .",
    "( [ relation_m_d ] ) for @xmath28 in a least square sense .",
    "usually a low order polynomial in @xmath23 is used for a fit of the right hand side , as the higher order terms in above equation are known to be powers of @xmath23 @xcite .",
    "this strategy will be denoted as standard markov analysis ( sma ) in the following .",
    "next , a stochastic process @xmath29 is looked at that obeys the _ second order _ ode @xmath30    here @xmath1 denotes gaussian white noise again . as eq .",
    "( [ second_order_ode ] ) is a second order ode , such a process is not markovian , i.e. , the statistics of its increments do not only depend on the value of @xmath31 but also on its derivative . in an extended phase space , however , consisting of the values of @xmath31 and @xmath32 ,",
    "the dynamic becomes markovian . with the definitions",
    "@xmath33    eq .  ( [ second_order_ode ] ) can be written as a system of first order equations that define a langevin process @xmath34 $ ] in @xmath35 dimensions @xmath36.\\end{aligned}\\ ] ]    the kramers  moyal coefficients of the corresponding fokker ",
    "planck equation are simpler than in the general @xmath35-dimensional case , as they are given by @xmath37    of cause , these coefficients can be estimated from a given time series of @xmath0 by the above mentioned sma .",
    "but therefor the values of @xmath31 _ and _ @xmath32 must be given ( eq .",
    "( [ def_pos_velo ] ) ) . for real word data",
    "this will not always be the case .",
    "frequently only a series of positions @xmath38 will be given for a second order process obeying eq .",
    "( [ second_order_ode ] ) , while the corresponding velocities @xmath39 are missing .",
    "it may , e.g. , be hard to accurately meassure the velocities in a given experimental setup .",
    "or it may not have been realized in advance that @xmath29 needs to be modelled as second order process . or it may simply have been assumed that a highly resolved series of position values will provide sufficiently accurate information on the velocities .    if @xmath32 is missing , these velocity values need to be estimated numerically .",
    "this seems to be no major problem as @xmath29 is a continuously differentiable function .",
    "its derivative can be estimated by a discrete differencing scheme with arbitrary accuracy  provided the step - size of the scheme ( here and in the following denoted by @xmath40 ) can be chosen small enough .",
    "so for a sufficiently fine sampled series of positions the estimation - errors of the velocities will become negligible .",
    "the standard approach for an analysis , therefore , goes like this : choose some small step - size @xmath40 and estimate the series @xmath41 using the given series @xmath42 . then apply a sma to the resulting series @xmath10 .",
    "this strategy will be denoted as standard embedding approach ( sea ) in the following .",
    "such an approach , however , has its flaws . for a markov analysis",
    ", the moments of process-_increments _ will be looked at ( see eq .",
    "( [ moments_incy ] ) ) . for these quantities",
    "the effects of the estimation errors will show to be of importance unless the step - size @xmath40 ( used for velocity estimation ) can be chosen much smaller than the time increment @xmath23 ( used for increment calculation ) .",
    "at the same time , however , @xmath23 needs to be small compared to the characteristic time scale @xmath43 of the process under investigation .",
    "otherwise the higher order terms in eq .",
    "( [ relation_m_d ] ) can no longer be approximated by a low order polynomial .",
    "the requirement @xmath44 will only rarely be fulfilled in practise as it requires data with a very high temporal resolution ( compared to the characteristic time scale @xmath43 ) .",
    "also another source of errors has to be considered for real data : any measurement noise that afflicts the values of @xmath42 will lead to an additional error in the estimation of @xmath41 . for a differencing scheme with step - size @xmath40 , this error will be proportional to @xmath45 , as will be seen later ( assuming uncorrelated measurement noise ) .",
    "so even if the measurement noise is very small , and thus negligible for @xmath42 itself , it may become important in the estimation of @xmath41 for small values of @xmath40 .",
    "above considerations imply that for real data neither the values of @xmath46 nor that of @xmath47 are known accurately .",
    "the noisy values , which _ are _ at hand , will be denoted by @xmath48 in the following .",
    "the aim of this paper is , to provide of a modified embedding approach ( mea ) that accounts for the errors due to differencing scheme and meassurement noise . as a by - product also a quantitative description of the errors of the sea",
    "will be found .",
    "however , only _",
    "weak _ measurement noise can be accounted for .",
    "this restriction is a consequence of the perturbative approach that will be used .",
    "the requirements on the noise will be given later , but , roughly speaking , the noise must be negligible for the position values and its effect on the velocity increments may at most be of the same order as the effects of the driving stochastic force @xmath49 .",
    "this paper is organized as follows : in sec .",
    "[ sec_moments_noisy ] the observable moments @xmath50 of the noisy time series will be expressed in terms of moments of the _ noisy _ values @xmath48 and @xmath51 conditioned on the _ true _",
    "value @xmath0 .",
    "subsequently , based on a taylor ",
    "it  expansion , these conditional noisy values will be expressed in terms of process parameters , measurement noise and stochastic integrals of @xmath49 in sec .",
    "[ sec_cond_values ] .",
    "the resulting expressions , together with an assumption on the magnitude of the measurement noise , will lead to an explicit description of @xmath50 in sec .",
    "[ sec_moments_mknu ] then .",
    "this description will serve two purposes .",
    "firstly , the effects of the reconstruction errors of a sea can be quantified ( sec .",
    "[ sec_systematic errors ] ) .",
    "secondly , a mea can be specified that allows an accurate estimation of the kramers  moyal coefficients and the properties of the measurement noise ( sec .",
    "[ sec_alternative_approach ] ) .",
    "subsequently a numerical test case will be specified in sec .",
    "[ sec_example ] , which will be used to compare the results of sea and mea with and without measurement noise ( secs .",
    "[ sec_comparison_nonoise ] and [ sec_comparison_noise ] ) .",
    "for a series of noisy values @xmath52 only the noisy counterparts @xmath50 of the moments @xmath15 can be estimated . in analogy to eq .",
    "( [ def_momk ] ) they can be defined as @xmath53    here and in the following , the time arguments @xmath14 and @xmath23 are omitted to allow for a more compact notation .",
    "stochastic variables implicitely refer to time @xmath14 now , and the shortcut @xmath54 is used to denote @xmath51 .    next the moments @xmath50 need to be related to the process parameters and the properties of the measurement noise . as outlined in sec .",
    "[ sec_intro ] , the first step will be , to express the moments @xmath50 in terms of moments of the conditional noisy values @xmath55 and @xmath56 .",
    "this can be done as follows : first , the pdf in eq .",
    "( [ def_smomk ] ) is rewritten as @xmath57    where @xmath58 denotes the pdf of @xmath10 .",
    "inserting eq .",
    "( [ def_expand_twopoint_dens ] ) and interchanging the order of integration thus allows to write the moments @xmath50 in the form @xmath59 with @xmath60    expressing the integral in eq .",
    "( [ def_convlike ] ) by a moment expansion yields ( using summation convention ) @xmath61,\\end{aligned}\\ ] ]    where the moments are defined as @xmath62    here @xmath63 denotes a dyadic product . inserting the definition of @xmath64 first leads to @xmath65    using the relation @xmath66 then gives    @xmath67    the general form of the observable moments @xmath50 therefore reads ( dropping the asterisk on the parameter @xmath68 ) @xmath69_{i_1,\\ldots , i_k }                                        [ { \\mathbf}{b}^\\nu\\!({{\\mathbf}{y}})]_{j_1,\\ldots , j_\\nu}\\big>\\right\\}\\end{aligned}\\ ] ]    with    [ def_a_b ] @xmath70    this is a quite general result  no information on how @xmath48 and @xmath0 are related is used so far .",
    "this will be done in the next section , where the conditional values of @xmath52 and @xmath54 will be expressed explicitly .",
    "in this section we will specify the assumptions on the measurement noise together with the details of the differencing scheme .",
    "this will allow to express the conditional values of @xmath52 and @xmath54 in terms of measurement noise and conditional values of @xmath42 .",
    "based on a taylor ",
    "it  expansion , these conditional values @xmath42 can then be expressed in terms of the driving stochastic force and process parameters .    to avoid confusion ,",
    "time arguments will be given explicitly again in the following .",
    "however , the shortcut @xmath71 will be used to indicate conditioning on @xmath72 .",
    "the given values @xmath73 are assumed to be spoilt by additive , gaussian distributed and temporally uncorrelated measurement noise @xmath74 with an expectation value of zero and covariance matrix @xmath75    [ definition_gamma ] @xmath76    the noise is also assumed to be independent of @xmath49 and @xmath10 ( implying @xmath77 ) .",
    "the conditional values @xmath78 are thus given by @xmath79    for the reconstruction of @xmath41 a first order forward differencing scheme with a step - size of @xmath40 , applied to the observable values @xmath80 , will be used in the following .",
    "the conditional values @xmath81 therefore are given by @xmath82\\cr   & &     + \\frac{1}{\\theta}\\left[{\\boldsymbol{\\gamma}}(t\\!+\\!\\delta\\!+\\!\\theta)\\!-{\\boldsymbol{\\gamma}}(t\\!+\\!\\delta)\\right].\\end{aligned}\\ ] ]    the values @xmath83 at time @xmath84 can be expressed by a taylor  it  expansion ( see app .",
    "[ app_taylor_ito ] ) @xmath85    here @xmath86 denotes a vector of stochastic integrals that only depend on the realization of @xmath49 in the interval @xmath87 .",
    "the components of this vector are of magnitude @xmath88 and have an expectation value of zero .",
    "all other expansion terms are summarized in the remainder @xmath89 with a magnitude of @xmath90 and an expectation value of @xmath91 .    in summary , above results",
    "lead to the following expressions for @xmath92    [ def_ys ] @xmath93",
    "now the moments @xmath94 can be attacked . for a calculation of @xmath94 explicit expressions for the vectors @xmath95 and @xmath96 , as defined in eq .",
    "( [ def_a_b ] ) , are needed . using the results from the previous section ( eq .  ( [ def_ys ] ) )",
    "one finds    [ def_a_b_explicit ] @xmath97 { { \\mathbf}{f}}({{\\mathbf}{y}})\\tau      + { { \\mathbf}{g}}({{\\mathbf}{y}})\\frac{{\\mathbf}{i}^{t,\\tau\\!+\\!\\theta}-{\\mathbf}{i}^{t,\\tau}-{\\mathbf}{i}^{t,\\theta}}{\\theta }      + \\frac{{\\boldsymbol{\\gamma}}(t\\!+\\!\\tau\\!+\\!\\theta)-{\\boldsymbol{\\gamma}}(t\\!+\\!\\tau)-{\\boldsymbol{\\gamma}}(t\\!+\\!\\theta)+{\\boldsymbol{\\gamma}}(t)}{\\theta }      + \\frac{{{\\mathbf}{r}}^{t,\\tau\\!+\\!\\theta}\\!({{\\mathbf}{y}})-{{\\mathbf}{r}}^{t,\\tau}\\!({{\\mathbf}{y}})-{{\\mathbf}{r}}^{t,\\theta}\\!({{\\mathbf}{y}})}{\\theta } \\end{bmatrix},\\\\[.3em ] { \\mathbf}{b}({{\\mathbf}{y}},\\tau,\\theta )   & = & \\begin{bmatrix } { \\boldsymbol{\\gamma}}(t)\\\\[.3em ] { { \\mathbf}{f}}({{\\mathbf}{y}})\\frac{\\theta}{2 }      + { { \\mathbf}{g}}({{\\mathbf}{y}})\\frac{{\\mathbf}{i}^{t,\\theta}}{\\theta }      + \\frac{{\\boldsymbol{\\gamma}}(t\\!+\\!\\theta)-{\\boldsymbol{\\gamma}}(t)}{\\theta }      + \\frac{{{\\mathbf}{r}}^{t,\\theta}\\!({{\\mathbf}{y}})}{\\theta } \\end{bmatrix}.\\end{aligned}\\ ] ]    these expressions contain infinitely many terms , summarized in the remainders @xmath98 .",
    "to allow for a series truncation , a small parameter @xmath99 is introduced in the following to express the magnitude of terms ( it is tacitly assumed here that the problem is described in dimensionless form with @xmath100 an @xmath101 being of order @xmath102 ) .",
    "it will be assumed that @xmath23 and @xmath40 are of the same order of magnitude as @xmath99 and that the measurement noise @xmath103 is of the same order as @xmath104 @xmath105    in a strict sense , the use of the landau symbols here is not appropriate , because there is no functional relation between @xmath99 and , e.g. , @xmath23 . above notation",
    "is rather used to express the assumptions that , firstly , @xmath23 , @xmath99 and @xmath103 are small quantities , which allows to sort powers by magnitude ( like e.g. @xmath106 ) .",
    "secondly , it is assumed that @xmath23 , @xmath40 and @xmath107 are of compareable size , where compareable size means that , when resticting to small exponents , also powers of different quantities can be sorted by size ( like e.g. @xmath108 or @xmath109 ) .",
    "this will be sufficient for appropriate low order approximations .    with this assumptions the lowest order terms in @xmath95 and @xmath96",
    "are of order @xmath110 .",
    "the magnitude of a moment @xmath94 , therefore , is given by ( omitting arguments ) @xmath111    for a first order description of the moments @xmath50 thus only moments @xmath94 with @xmath112 need to be taken into account .",
    "using eq .",
    "( [ def_var_ii0 ] ) and the properties of @xmath113 , one finds    @xmath114 { { \\mathbf}{m}}^{(0,1 ) } & = & \\begin{bmatrix } { \\mathbf}{0 } \\\\",
    "\\frac{1}{2}\\theta{{\\mathbf}{f}}\\end{bmatrix}\\!+\\!o({\\varepsilon}^2),\\\\ { { \\mathbf}{m}}^{(0,2 ) } & = & \\begin{bmatrix }    { \\mathbf}{0 } & { \\mathbf}{0 } \\\\    { \\mathbf}{0 } & \\frac{1}{3}\\theta{{\\mathbf}{g}}{{\\mathbf}{g}}^t\\!+\\!2\\frac{{{\\mathbf}{v}}}{\\theta^2 } \\end{bmatrix}\\!+\\!o({\\varepsilon}^2),\\end{aligned}\\ ] ]    @xmath115    @xmath116    with @xmath117 \\tau-\\frac{1}{3}\\theta    & , & \\tau\\ge\\theta \\end{array}\\right . .\\end{aligned}\\ ] ]    inserting these expressions into eq .",
    "( [ def_mstar_m ] ) , finally , yields a first order description of the moments @xmath50 in terms of @xmath118 , @xmath100 , @xmath101 and @xmath75 .",
    "it turns out that derivatives with respect to components of @xmath119 do not appear in the terms up to order @xmath120 ",
    "so for a first order description only the derivatives with respect to the components of @xmath121 need to be considered .",
    "it also turns out that only the upper half of the vector @xmath122 and the upper quarter of the matrix @xmath123 need to be looked at ( those components that correspond to moments of the increments of @xmath124 ) . to take ( syntactical ) advantage of this reduction in dimensionality the notations    @xmath125    are introduced , where @xmath126 and @xmath127 are in the range @xmath128 .",
    "the relevant equations can now be written compactly as    [ relation_mstar_d ] @xmath129              + \\frac{\\theta}{6}\\,\\hat{\\partial}_i\\hat{\\partial}_j [ \\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}]\\cr & &             + \\frac{v_{ij}}{\\theta^2}\\,\\hat{\\partial}_i\\hat{\\partial}_j\\rho + o({\\varepsilon}^2),\\\\[0.5em ] { \\hat m^{(1)}}_i({{\\mathbf}{y}},\\tau,\\theta ) & = & \\tau\\rho f_i                -\\frac{1}{2}(\\tau\\!-\\!\\psi)\\,\\hat{\\partial}_j [ \\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}]\\cr & &               + ( 2\\!+\\!\\delta_{\\tau,\\theta})\\frac{v_{ij}}{\\theta^2}\\,\\hat{\\partial}_j\\rho + o({\\varepsilon}^2),\\\\[0.5em ] { \\hat m^{(2)}}_{ij}({{\\mathbf}{y}},\\tau,\\theta ) & = &              \\psi\\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}\\cr & &             + 2(2\\!+\\!\\delta_{\\tau,\\theta})\\frac{v_{ij}}{\\theta^2}\\,\\rho+o({\\varepsilon}^2).\\end{aligned}\\ ] ]    these equations directly relate the unknown quantities @xmath118 , @xmath100 , @xmath130 and @xmath75 and the observable quantities @xmath131 .",
    "the function argument of @xmath118 , @xmath100 and @xmath101 is given by @xmath68 .",
    "the function @xmath132 depends on @xmath23 and @xmath40 and has a piecewise definition only , eq .",
    "( [ def_psi ] ) .",
    "next the sea will be analyzed , using the final result of the previous section ( eq .  ( [ relation_mstar_d ] ) ) . only the case without measurement noise , i.e. @xmath133 , will be looked at .",
    "this will show the pure effects of the reconstruction errors caused by the numerical estimation of @xmath41 .    for a time series , where @xmath41 has been reconstructed by a first order forward differencing scheme with stepsize @xmath40 , the observable moments @xmath131 are described by eq .",
    "( [ relation_mstar_d ] ) . ignoring this result and attempting a markov analysis as outlined in sec .",
    "[ sec_intro ] will put the focus on the terms @xmath134 . according to eq .",
    "( [ relation_m_d ] ) , these terms should be finite - increment estimates of @xmath100 and @xmath130 ( @xmath135 resp .",
    "@xmath136 ) . in fact , however , the terms evaluate to    [ estim1_f_g ] @xmath137\\cr & & + o({\\varepsilon})\\\\ \\label{estim1_g } \\frac{{\\hat m^{(2)}}_{ij}({{\\mathbf}{y}},\\tau,\\theta)}{\\tau{\\hat m^{(0)}}({{\\mathbf}{y}},\\theta ) }    & = & \\frac{\\psi(\\tau,\\theta)}{\\tau}({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij } + o({\\varepsilon}).\\end{aligned}\\ ] ]    trying to extrapolate these estimates to @xmath138 then becomes problematic . instead of being approximately constant , as expected from eq .",
    "( [ relation_m_d ] ) , the values will show non - linear behaviour caused by the function @xmath139 . for fixed @xmath40",
    "this function starts linear with a value of zero at @xmath140 , passes through @xmath141 at @xmath142 and approaches a value of one for @xmath143 .",
    "simply fitting a low order polynomial to all estimates up to some maximum increment @xmath144 will thus , in general , under - estimate @xmath130 ( because of @xmath145 ) . an error of compareable size ( although with arbitrary sign ) will occure when estimating @xmath100 .    in principle , however , the estimates for large @xmath23 , i.e. where @xmath146 , could be used for a fit . on the other hand also",
    "the influence of higher order terms becomes stronger for large increments .",
    "unless a time series is sampled with a very small timestep , such an approach will also fail to provide accurate estimates for @xmath147 and @xmath148 .",
    "based on eq .  ( [ relation_mstar_d ] ) ,",
    "we now will propose a modified approach that takes into account the effects of the differencing scheme as well as the effects of measurement noise .",
    "an important point in this approach will be to keep the ratio of @xmath23 and @xmath40 fix .",
    "this provides an easy way to avoid problems caused by the non - linear term @xmath149 . in the following @xmath150",
    "is chosen .",
    "equation  ( [ relation_mstar_d ] ) then reads    [ relation2_hatm_d ] @xmath151              + \\frac{\\tau}{6}\\,\\hat{\\partial}_i\\hat{\\partial}_j [ \\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}]\\cr & &             + \\frac{v_{ij}}{\\tau^2}\\,\\hat{\\partial}_i\\hat{\\partial}_j\\rho + o({\\varepsilon}^2 ) , \\\\",
    "\\label{relation2_hatm1_d } { \\hat m^{(1)}}_i({{\\mathbf}{y}},\\tau,\\tau ) & = & \\tau\\rho f_i                -\\frac{\\tau}{6}\\,\\hat{\\partial}_j [ \\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}]\\cr & &               + 3\\frac{v_{ij}}{\\tau^2}\\,\\hat{\\partial}_j\\rho + o({\\varepsilon}^2 ) , \\\\",
    "\\label{relation2_hatm2_d } { \\hat m^{(2)}}_{ij}({{\\mathbf}{y}},\\tau,\\tau ) & = &              \\tau\\frac{2}{3}\\rho\\,({{\\mathbf}{g}}{{\\mathbf}{g}}^t)_{ij}\\cr & &             + 6\\frac{v_{ij}}{\\tau^2}\\,\\rho + o({\\varepsilon}^2).\\end{aligned}\\ ] ]    a fixed ratio of @xmath23 and @xmath40 also leads to a simpler form of the higher order terms ( see app .  [ app_higher_order ] ) .",
    "each term of order @xmath152 on the right hand side of eq .",
    "( [ relation2_hatm_d ] ) has the form @xmath153    with @xmath154    here the symbol @xmath155 is used to denote such a term and @xmath156 accounts for the assumption on the magnitude of @xmath75 .",
    "the functional form of @xmath155 ( with respect to @xmath23 ) can thus be described by a function - base @xmath157 that consists of @xmath158 functions @xmath159 . as noted in app .",
    "[ app_higher_order ] , this implies @xmath160 and thus puts a limit on the accuracy that can be achieved in least square fits of @xmath131 . e.g.",
    "it is not possible to distinguish a first order term @xmath161 and a fourth order term @xmath162 by their functional form .    in the following eq .",
    "( [ relation2_hatm0_d ] ) will be used in the form @xmath163 , i.e. the explicit results for the first order terms will not be used .",
    "this avoids the need to numerically calculate the derivatives that appear within these terms .",
    "next , eqs .",
    "( [ relation2_hatm1_d ] ) and ( [ relation2_hatm2_d ] ) are divided by @xmath118 .",
    "replacing @xmath118 by @xmath164 in the resulting left hand sides will only result in additionally terms of order @xmath165 and higher for the right hand sides .",
    "one finds ( omitting function arguments again )    [ relation3_hatm_d ] @xmath166    with the shortcut @xmath167}{6\\rho}.\\end{aligned}\\ ] ]    the term @xmath168 in eq .",
    "( [ relation3_hatm1_d ] ) will now be expressed as @xmath169 , where @xmath170 is a unknown constant ( of order @xmath171 ) .",
    "finally , it will be assumed that @xmath75 is known .",
    "this assumption is not mandatory ",
    "@xmath75 could be estimated using eq .",
    "( [ relation3_hatm2_d ] )  but this quantity can be estimated more easily in advance by , e.g. , analyzing the auto - covariance of @xmath80 .",
    "the final set of equations now reads    [ relation4_hatm_d ] @xmath172    the terms on the left hand sides can be estimated for different values of @xmath23 from a given time series . choosing appropriate sets of regression functions thus allows to estimate @xmath118 , @xmath173 and @xmath130 by a linear regression analysis . once these quantities have been estimated , eq .",
    "( [ correction_f ] ) can be used to finally calculate @xmath100 ( the derivative that appears in eq .",
    "( [ correction_f ] ) can , e.g. , be calculated using a density - weighted local polynomial fit of @xmath174 ) .",
    "the functional form of the higher order terms can be shown to still obey eq .",
    "( [ def_high_order ] ) .",
    "therefore @xmath175 , @xmath176 and @xmath177 are appropriate function sets for eq .",
    "( [ relation4_hatm0_d ] ) , ( [ relation4_hatm1_d ] ) and ( [ relation4_hatm2_d ] ) if terms up to order @xmath120 shall be taken into account . to also take into account second order terms",
    ", the functions @xmath178 must be added to the sets . in principle , also third order terms can be accounted for in eq .",
    "( [ relation4_hatm1_d ] ) and ( [ relation4_hatm2_d ] ) by also adding the functions @xmath179 . in practise , however , a large number of regression functions and also large negative exponents lead to numerical problems . as a compromise , the terms",
    "can partially be accounted for . in the numerical example",
    "given later , e.g. , only @xmath180 is used as regression function for third order terms .",
    "to check the analytical results and to compare the different embedding approaches , a numerical example is investigated now . as",
    "test case a scalar process @xmath181 ) is chosen that obeys the second order ode @xmath182    where @xmath183 and @xmath184 are defined as @xmath185    again @xmath186 denotes gaussian white noise with @xmath187 . above ode",
    "can be rewritten as a system of first order odes for a @xmath188 process @xmath0 , the components of which are given by position @xmath189 and velocity @xmath190 of the @xmath191 process @xmath192",
    "@xmath193    these equations describe an ornstein  uhlenbeck process in two dimensions and can be solved analytically .",
    "the characteristic time scales of the auto - covariance of @xmath10 are found to be @xmath194 and @xmath195 .",
    "the values of @xmath10 are gaussian distributed and have a variance of @xmath196 .    for this process a time series of @xmath10 , consisting of @xmath197 values , sampled with a time increment @xmath198 , is generated .",
    "excerpts of the resulting series for @xmath199 and @xmath200 are shown in figs .",
    "( [ fig1 ] ) and ( [ fig2 ] ) . here",
    "also a basic problem of the sea can be seen , which was noted in sec .",
    "( [ sec_intro ] ) and quantified in sec .",
    "( [ sec_systematic errors ] ) : even if a series is sampled sufficiently fine to allow an accurate estimation of @xmath200 by a numerical differencing scheme , the velocity _ increments _ ( for time increment @xmath23 ) will still show notable errors for small @xmath23 .",
    "this error depends on the ratio @xmath201 ( here @xmath202 ) and its effects can be quantified by the function @xmath132 in eq .",
    "( [ estim1_f_g ] ) .",
    "( * a * ) . a zoomed - in view ( * b * ) shows that the signal in fact is smooth and thus allows to numerically estimate its derivative if the sampling time step @xmath203 is sufficiently small.,width=283 ]     ( * a * ) . in the zoomed - in view ( * b * ) additionally the numerically estimated derivative of @xmath199",
    "allthough the values of both series ( true and estimated ) quite accurately match , there are notable differences for the small scale increments.,width=283 ]    to obtain a baseline for the accuracy that can be achieved with the given data , a sma is applied to the true @xmath188 series @xmath10 first . here and for subsequent analyses a binning approach is used , where the region @xmath204\\times[-1,1]$ ] of the @xmath205-plane is covered by @xmath206 bins . for one of these bins",
    "the estimated moments of the conditional velocity increments are shown in fig .",
    "( [ fig3 ] ) .    .",
    "the corresponding fits are shown as solid curves .",
    "estimates are taken at @xmath207 . here",
    "@xmath183 and @xmath208 have values of @xmath209 and @xmath210 respectively ( dashed lines).,width=283 ]    actually the moments in fig .",
    "( [ fig3 ] ) are scaled by @xmath211 , as is usually done for their visual presentation .",
    "this allows to interprete the estimation of @xmath183 and @xmath208 as extrapolating the scaled moments to @xmath138. later on , however , when measurement noise enters the scene , a more general interpretation will be needed , where @xmath183 and @xmath208 are found by a linear regression strategy . of cause",
    "this interpretation is also valid in the given setup .",
    "the values of @xmath183 and @xmath208 are given by the coefficients of the linear part ( in @xmath23 ) of the conditional moments @xmath212 and @xmath213 respectively ( see eq .",
    "( [ relation_m_d ] ) ) .    in the following the regression functions @xmath214 and @xmath215 are used to fit the estimated first and second conditional moments ( this corresponds to fitting a linear function to the values in fig.([fig3]a ) and a quadratic function to those in fig.([fig3]b ) ) .",
    "the maximum increment that is used for these fits is chosen as @xmath216 .",
    "the resulting estimates for @xmath183 and @xmath208 are shown in fig .",
    "( [ fig4 ] ) . in fig .",
    "( [ fig5 ] ) the absolute errors @xmath217 and @xmath218 of these estimates are shown . in regions with low density ( as noted above , the pdf of @xmath10 is a symmetric gaussian with a standard deviation of @xmath219 ) fluctuations become larger but there is no obvious bias of the results .     and @xmath208 ( * a * , * b * ) , obtained by a sma.,width=325 ]     and @xmath208 ( * a * , * b * ) , obtained by a sma.,width=325 ]",
    "next the results of the different embedding approaches are looked at . first a sea is used to perform an analysis solely based on the @xmath191 series of positions @xmath199 .",
    "the corresponding velocity values @xmath200 are estimated by a first order forward differencing scheme with a step size of @xmath202 and the resulting @xmath188 series then is analyzed by a sma .    as is shown in fig .",
    "( [ fig6 ] ) , the estimated moments of the conditional velocity increments behave quite different , compared to those obtained from the true @xmath188 series ( shown in fig .  ( [ fig3 ] ) ) . as expected from eq .",
    "( [ estim1_f_g ] ) , the moments show strongly nonlinear behaviour for small increments @xmath23 . for an estimation of @xmath183 and @xmath208 ,",
    "therefore , only increments with @xmath220 are used .",
    "least square fits are performed using the same sets of regression functions as in the previous section .",
    "the absolute errors @xmath217 and @xmath218 of the resulting estimates are shown in fig .",
    "( [ fig7 ] ) . of cause ,",
    "the fluctuations become larger now as fewer increments are used for the fits .",
    "but , more importantly , it is obvious that @xmath208 is systematically under - estimated . and also",
    "the estimates for @xmath183 clearly show a significant bias that is approximately linear in @xmath221 .    ) .",
    "the estimated values ( circles ) are scaled by @xmath211 .",
    "the corresponding fits are shown as solid curves . additionally , the estimates obtained by a sea with @xmath222 are shown ( crosses ) .",
    "estimates are taken at @xmath207 . here",
    "@xmath183 and @xmath208 have values of @xmath209 and @xmath210 respectively ( dashed lines).,width=283 ]     and @xmath208 ( * a * , * b * ) , obtained by a sea.,width=325 ]    using a sea also affects the estimates for the process density @xmath118 .",
    "it would be missleading , however to compare the estimates @xmath24 to the true density @xmath118 , as is done in fig .",
    "( [ fig8]a ) . to a large extent",
    "the observed errors are caused by finite size effects and not by the reconstruction approach ( the binned density of the true @xmath188 series would show very similar errors ) .",
    "to assess the errors that are introduced by the embedding approach , the estimates @xmath24 thus should be compared to the binned density of the @xmath188 series .",
    "this is done in fig .",
    "( [ fig8]b ) , where the erros are found to be biased by a hyperbolic function in @xmath223 and @xmath221 .     are shown . in ( * b * )",
    "errors are relative to the binned density of the @xmath188 series.,width=325 ]    now a mea , as proposed in sec .",
    "( [ sec_alternative_approach ] ) , is applied .",
    "again the analysis is purely based on the @xmath191 series of positions @xmath199 .",
    "opposed to a sea , however , velocities are no longer estimated by a differencing scheme with a fixed step size .",
    "instead , velocities and velocity increments for time increment @xmath23 are estimated using the step size @xmath224 . using a binning approach , it is not much more effort than for a sea to implement the calculation of the density @xmath24 and of the conditional moments @xmath225 and @xmath213 . in pseudo - code",
    "this reads :    .... for i=1:n - kmax   %",
    "n data - points    for k=1:kmax   % kmax increments      pos = x[i ]   % x is data array      velo = ( x[i+k]-x[i])/k / dt   % sampling step dt      dvelo = ( x[i+2*k]-2*x[i+k]+x[i])/k / dt      idx = getbinindex(pos , velo )      if(isvalid(idx ) )        m0[idx][k ] + = 1        m1[idx][k ] + = dvelo        m2[idx][k ] + = dvelo*dvelo      end    end end for idx=1:idxmax   % loop over all indicees    for k=1:kmax      m1[idx][k ] /=",
    "m0[idx][k ] % 1st cond .",
    "moment      m2[idx][k ] /=",
    "m0[idx][k ] % 2nd cond .",
    "moment      m0[idx][k ] /= ( n - kmax)*binsize % density    end end ....    estimates for density and conditional moments obtained by a mea are shown in fig .",
    "( [ fig9 ] ) . as expected from eq .",
    "( [ relation3_hatm_d ] ) , the scaled moments now approach @xmath226 and @xmath227 respectively for @xmath228 .",
    "also the density @xmath24 now depends on @xmath23 and approaches the density of the @xmath188 series .    ) of the conditional velocity increments ( * b * , * c * ) .",
    "the estimates ( circles ) have been obtained by a mea .",
    "the corresponding fits are shown as solid curves .",
    "estimates are taken at @xmath207 . here",
    "@xmath226 ( see eq .",
    "( [ correction_f ] ) ) and @xmath227 have values of @xmath229 and @xmath230 respectively and the binned density of the @xmath188 series has a value of @xmath231 ( dashed lines).,width=283 ]    all increments up to @xmath232 are used for the least square fits .",
    "the regression functions @xmath233 are used to fit the density estimates . for the fits of the estimated first and second conditional moments",
    "again the functions @xmath214 respectively @xmath215 are used .",
    "there is no need to add functions like @xmath234 , as still a case without measurement noise is looked at .",
    "the errors of the resulting estimates for @xmath118 , @xmath183 and @xmath208 are shown in fig .",
    "( [ fig10 ] ) . opposed to a sea , shown in fig .",
    "( [ fig7 ] ) , no obvious biasing of the estimates can be observed and the fluctuations of @xmath217 and @xmath218 are compareable to those observed in an analysis of the @xmath188 series using a sma .",
    "( * a * ) and absolute errors of the estimates for @xmath183 and @xmath208 ( * b * , * c * ) , obtained by a mea . errors in ( * a * ) are relative to the binned density of the @xmath188 series.,width=325 ]",
    "so far , only data without measurement noise as been analyzed .",
    "next , a series of noisy values @xmath235 is generated by adding gaussian , uncorrelated noise with a variance of @xmath236 ( this corresponds to a noise - to - signal amplitude ratio of @xmath237 ) to the series @xmath199 .",
    "this noisy series @xmath235 is then analyzed  first by applying a sea and next by applying a mea .",
    "moments obtained by a sea are shown in fig .",
    "( [ fig11 ] ) . due to the measurement noise",
    "the scaled moments now diverge for @xmath238 . for an estimation of @xmath183 and @xmath208 , therefore , again only increments with @xmath220 are used .",
    "least square fits again are performed using the functions @xmath214 and @xmath215 respectively .",
    "the absolute errors @xmath217 and @xmath218 of the resulting estimates are shown in fig .",
    "( [ fig12 ] ) .",
    "it turns out that @xmath208 is systematically _",
    "over_-estimated now .",
    "the estimates for @xmath183 still show a significant bias that is approximately linear in @xmath221  allthough the bias now has switched sign .",
    "( obtained by a sea with @xmath202 ) .",
    "the estimated values ( circles ) are scaled by @xmath211 .",
    "the corresponding polynomial fits are shown as solid curves .",
    "estimates are taken at @xmath207 . here",
    "@xmath183 and @xmath208 have values of @xmath209 and @xmath210 respectively ( dashed lines).,width=283 ]     and @xmath208 ( * a*,*b * ) , obtained by using a sea for the noisy series @xmath235.,width=325 ]    finally our proposed mea is applied to the series @xmath235 , what leads to estimates for density and conditional moments as shown in fig .",
    "( [ fig13 ] ) . for @xmath238 the moments are diverging because of the terms proportional to @xmath234 ( and other higher order terms proportional to negative powers of @xmath23 ) , as described by eq .",
    "( [ relation3_hatm_d ] ) .",
    "it is thus neccessary now , to add appropriate regression functions that account for these terms : for density estimation , all terms up to order @xmath120 are accounted for by using the functions @xmath175 .",
    "fits of the first conditional moments ( yielding an estimate for @xmath226 ) are performed using the regression functions @xmath239 , i.e. considering terms up to order @xmath165 .",
    "fits of the second conditional moments , finally , ( yielding an estimate for @xmath227 ) are performed using the regression functions @xmath240 .",
    "this choice needs some explanation .",
    "firstly , only @xmath180 is present to account for third order terms .",
    "this is a compromise for numerical reasons ",
    "it reduces the number of regression functions and avoids numerical problems with large negative powers of @xmath23 .",
    "secondly , the first order term @xmath241 is not accounted for by any regression function .",
    "this term is assumed to be known and thus does not need to be estimated .",
    "the value of @xmath242 is estimated in advance by extrapolating the auto - covariance function of @xmath235 to @xmath138 and then taking the difference to @xmath243 .",
    "estimates for @xmath242 that are obtained this way are accurate within about five percent , as has been checked numerically .",
    "using above sets of regression functions and all increments up to @xmath232 then leads to estimates for @xmath183 and @xmath208 , the absolute errors of which are shown in fig .",
    "( [ fig14 ] ) .",
    "the estimates are quite heavily fluctuating now .",
    "but  at least to the bare eye  the results seem not to be biased .    ) of the conditional velocity increments ( * b * , * c * ) of the noisy series @xmath235 . the estimates ( circles )",
    "have been obtained by a mea .",
    "the corresponding fits are shown as solid curves .",
    "the non - diverging parts of these fits are shown as dashed curves .",
    "estimates are taken at @xmath207 . here",
    "@xmath226 ( see eq .",
    "( [ correction_f ] ) ) and @xmath227 have values of @xmath229 and @xmath230 respectively and the binned density of the @xmath188 series has a value of @xmath231 ( dashed lines).,width=283 ]     and @xmath208 ( * a * , * b * ) , obtained by using a mea for the noisy series @xmath235.,width=325 ]",
    "solid quantitative results for biases of the results of the different analyses that have been performed would require an averaging over a large number of analyses of independent realizations of @xmath10 . instead , a simpler approach is chosen to numerically compare the results .",
    "a polynomial @xmath244 with @xmath245    is fitted to the results for @xmath183 and @xmath208 using a density weighted least square fit . according to eq .",
    "( [ def_exp_f_g ] ) the only non - zero coefficients for @xmath183 should be @xmath246 and @xmath247 .",
    "for @xmath208 only @xmath248 should be non - zero . defining @xmath249 as the root of the density weighted mean of the squared differences between the actual estimates and @xmath244 , allows to also assess the fluctuations .",
    "the results for @xmath183 and @xmath208 are given in table  [ tab1 ] .",
    "exact & 0.00 & -1.00 & -3.00 & 0.00 & 0.00 & 0.00 & + sma & 0.00 & -1.00 & -2.97 & -0.05 & 0.01 & 0.02 & 0.06 + sea & 0.00 & -1.00 & -2.77 & -0.05 & 0.01 & 0.02 & 0.06 + mea & 0.00 & -0.99 & -2.97 & -0.05 & 0.01 & 0.02 & 0.06 + @xmath250 & 0.00 & -1.00 & -3.16 & -0.05 & 0.01 & 0.01 & 0.06 + @xmath251 & 0.00 & -0.97 & -2.98 & -0.05 & 0.00 & 0.00 & 0.13 + & a & b_1 & b_2 & c_11 & c_12 & c_22 & + exact & 1.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & + sma & 1.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.01 & 0.02 + sea & 0.89 & 0.00 & 0.00 & 0.00 & 0.00 & -0.04 & 0.04 + mea & 1.00 & 0.00 & 0.00 & 0.00 & 0.01 & 0.00 & 0.02 + @xmath250 & 1.11 & 0.00 & 0.00 & 0.00 & 0.04 & 0.08 & 0.04 + @xmath251 & 1.00 & 0.01 & 0.00 & 0.01 & 0.02 & 0.00 & 0.06 +    the most pronounced effects of a sea can be observed for the coefficient @xmath252 , when estimating @xmath183 , respectively for the coefficient @xmath253 , when estimating @xmath208 .",
    "these coefficients are also strongest affected by the presence of measurement noise . applying a mea , however , yields results that are compareable to those obtained by an analysis of the @xmath188 series  at least if no measurement noise is present . for noisy data",
    "the coefficients still are quite accurate but the mean error , @xmath249 , becomes larger then .",
    "this is a consequence of the large number of regression functions that is required for the analysis of noisy data .",
    "for a time series analysis of a process @xmath31 that is described by a stochastically forced second order ode , frequently an embedding strategy as outlined in sec .",
    "[ sec_intro ] is used : first the temporal derivative @xmath32 is estimated for each point in time by a numerical differencing scheme , and a new series @xmath254 is built .",
    "then a markov analysis is applied to the series @xmath10 in order to estimate its drift- and diffusion functions . however , the errors that are caused by the differencing scheme lead to notably biased estimates for these functions . additionally , even a very small amount of measurement noise has strong influence on the results .",
    "the errors of the above standard approach have been studied analytically and a modified approach has been proposed .",
    "this approach allows for an accurate estimation of the drift- and diffusion functions and , additionally , is able to deal with weak measurement noise .",
    "this has been verified for a numerical test case .    in this numerical test",
    "it also could be seen that measurement noise is a bigger problem than one might think intuitively . already measurement noise with an noise - to - signal amplitude ratio of @xmath237 had a severe influence : for the standard approach , it introduces an additional , notable bias to the results . for the modified approach",
    ", however , the results stay unbiased . here",
    "the presence of noise only affects the fluctuations , which become much stronger .",
    "the implementation of the presented approach is easily done and straight forward .",
    "the algorithm is not demanding with respect to memory or cpu power .",
    "all calculations have been performed on a standard desktop pc , where each analysis took less than one minute .",
    "compared to the standard approach , our modified embedding approach performs much better at compareable costs .",
    "it , therefore , should be the method of choice in the given setup .",
    "it  expansion of @xmath46 provides a stochastic description of the values @xmath255 for given @xmath0 . assuming smooth functions @xmath100 and @xmath101 , the expansion can be written as an infinite sum of deterministic and stochastic integrals that only depend on @xmath256 and @xmath49 and that are weighted by coefficient functions .",
    "these functions only depend on the values and derivatives of @xmath100 and @xmath101 , evaluated at @xmath0 . in the following",
    ", some properties of the integrals will shortly be summarized .",
    "a detailed description of the taylor  it   expansion and the properties of the stochastic integrals can be found e.g. in @xcite .    using a multi - index @xmath257 ,",
    "the expansion of @xmath42 can be written quite compactly @xmath258    with @xmath259    here @xmath260 denotes the above mentioned coefficient functions .",
    "the multiple integrals @xmath261 may contain integrations with respect to time as well as integrations with respect to components of the wiener process @xmath262 , associated with the gaussian noise @xmath1 .",
    "the structure of each integral is determined by its multi - index @xmath257 @xmath263    with @xmath264    the multi - index also determines the order of magnitude of the integral @xmath265    with @xmath266    because of it s definition of the stochastic integral , the expectation value of @xmath261 will be zero if it contains any integration with respect to a wiener process , i.e. if there are any non - zero components in it s index - vector . otherwise , when all components are zero , the integral becomes purely deterministic and evaluates to @xmath267 , where @xmath268 indicates the length of @xmath257 .    in app .",
    "[ app_higher_order ] expectation values of multiple products of integrals will be of interest .",
    "this will be restricted to such products , however , where the increments @xmath269 of the integrals are all of the same order of magnitude @xmath270    with @xmath271    here a sufficient ( but not neccessary ) condition for a vanishing expectation value is an odd total number of non - zero entries in the index vectors , i.e. a non - integral value of @xmath272 .",
    "non - vanishing expectation values will thus always have the magnitude of an integral power of @xmath256 . for an even more restrictive case , where the ratios @xmath273 of the increments are kept fix",
    ", the expectation value actually becomes proportional to a power of @xmath256 ( this can be shown by scaling the time variables in the integrals and using the fact that @xmath274 is ( statistically ) identical to @xmath1 ) @xmath275    with @xmath276    this only holds for @xmath277 .",
    "otherwise the expectation values will in general not have a uniform definition but will be given by multivariate polynomials in the variables @xmath278 with coefficients depending on size relations of the increments .",
    "the following explicit expectation value may serve as an example , but the result is also actually used in the calculation of the moments @xmath94 in sec .",
    "[ sec_moments_mknu ] @xmath279 \\frac{1}{2}\\delta_1",
    "^ 2\\delta_2-\\frac{1}{6}\\delta_1 ^ 3\\ ; , & \\delta_2 > \\delta_1 \\end{array}\\right . .\\end{aligned}\\ ] ]    next the actual expansion will be given .",
    "there is one special point in the expansion of @xmath42 : if the last entry of an index - vector is non - zero , the corresponding coefficient function @xmath260 will be vanishing ( this is due to the fact that @xmath42 is not directly driven by noise ; see eq .",
    "( [ langevin_yemb ] ) ) .",
    "the remaining integrals will thus all be at least of order @xmath280 @xmath281    with @xmath282    the remainder @xmath98 is used to summarize all remaining expansion terms .",
    "its lowest order stochastic terms are given by @xmath283 and its lowest order deterministic term by @xmath284 .",
    "thus @xmath98 is a term of order @xmath90 with the statistical properties @xmath285",
    "equation ( [ relation_mstar_d ] ) is accurate up to first order only . the classical markov analysis , as sketched in sec .",
    "[ sec_intro ] , faces the same problem : equation  ( [ relation_m_d ] ) the relation between the moments @xmath15 and the kramers  moyal coefficients , is accurate up to order @xmath286 only .",
    "however , for eq .",
    "( [ relation_m_d ] ) the functional form ( with respect to @xmath23 ) of the higher order terms is known ",
    "terms of order @xmath287 simply are proportional to @xmath288 . performing a linear regression with a function - base @xmath289 will thus allow parameter estimations with an accuracy of @xmath287 ( of cause , there are practical limitations for @xmath268 ) .    for higher order estimations in the given setup ,",
    "the functional form ( with respect to @xmath23 and @xmath40 ) of the higher order terms of @xmath131 is needed . because the functional form of _ all _ terms of @xmath131 is dictated by the form of the moments @xmath290",
    ", the starting point will be the vectors @xmath95 and @xmath96 .    according to eq .",
    "( [ def_a_b_explicit ] ) the components of both vectors can be expressed as linear combination of terms that either stem from the taylor ",
    "it  expansion or from the measurement noise . denoting the former by @xmath291 and",
    "the later by @xmath292 , the terms can be expressed as ( using @xmath293 as defined in eq .",
    "( [ def_m_alpha ] ) ) @xmath294      a component of @xmath94 , therefore , can be expressed as a linear combination of expectation values of @xmath296 factors @xmath297 . because @xmath113 is assumed to be external noise , each expectation value , denoted by @xmath298 , can be factorized .",
    "@xmath299      the components @xmath103 have been assumed to be gaussian noise with a magnitude of @xmath301 . a non - vanishing expectation value of a product of @xmath268 factors @xmath302 will thus be given by @xmath303 , where @xmath304 in general depends on whether @xmath23 equals @xmath40 or not . as @xmath292",
    "either denotes a factor @xmath305 or a factor @xmath306 , one finds @xmath307      the expectation value of a product of integrals @xmath261 will be a polynomial @xmath244 in @xmath23 and @xmath40 , where the coefficients in general will depend on whether @xmath23 is smaller than @xmath40 or not . for",
    "each monomial the powers of @xmath23 and @xmath40 will sum up to a value @xmath309 , determined by the index - vectors of the integrals . as @xmath291 either denotes a factor @xmath261 or a factor @xmath310 , one finds @xmath311      the expectation values @xmath298",
    "can thus be written as a linear combination of terms @xmath313 , as defined below .",
    "here it has been used that odd moments of @xmath305 are vanishing , i.e. only even values @xmath314 have to be considered .",
    "@xmath315      the value of @xmath317 depends on whether @xmath23 is smaller , equal or larger than @xmath40 .",
    "keeping the ratio of @xmath23 and @xmath40 fix , therefore , leads to a constant factor @xmath317 .",
    "the functional form of the terms @xmath313 ( and thus of all terms in the moments @xmath131 ) is then given by @xmath318      because @xmath23 is assumed to be of order @xmath120 , the term @xmath313 is of order @xmath320 .",
    "the function - base of terms of order @xmath152 , denoted by @xmath157 , thus consists of the @xmath23-dependend parts of all terms @xmath313 with @xmath321      unfortunately this means @xmath323 , which puts a limit on the accuracy that can be achieved .",
    "it is , for example , not possible to distinct some of the terms of order @xmath324 from the terms of order @xmath120 . at most , therefore , an accuracy of order three can be achieved ( if no @xmath102 terms are present ) ."
  ],
  "abstract_text": [
    "<S> the stochastic properties of a langevin - type markov process can be extracted from a given time series by a markov analysis . </S>",
    "<S> also processes that obey a stochastically forced second order differential equation can be analyzed this way by employing a particular embedding approach : to obtain a markovian process in 2n dimensions from a non markovian signal in n dimensions , the system is described in a phase space that is extended by the temporal derivative of the signal . for a discrete time series , </S>",
    "<S> however , this derivative can only be calculated by a differencing scheme , which introduces an error . </S>",
    "<S> if the effects of this error are not accounted for , this leads to systematic errors in the estimation of the drift- and diffusion functions of the process . in this paper </S>",
    "<S> we will analyze these errors and we will propose an approach that correctly accounts for them . </S>",
    "<S> this approach allows an accurate parameter estimation and , additionally , is able to cope with weak measurement noise , which may be superimposed to a given time series . </S>"
  ]
}