{
  "article_text": [
    "in quantum feedback control ( qfc ) , an observer continuously monitors a quantum system  @xcite , and uses the information from this measurement , as it is obtained , to control the system by continually modifying the hamiltonian and/or the observable being measured . over the last decade the topic of qfc",
    "has generated an increasing amount of theoretical  @xcite and experimental  @xcite work .",
    "this is due partly to experimental progress in micro- and mesoscopic quantum systems  @xcite , partly because qfc possesses a wide range of potential applications  @xcite , and partly because of its connection with fundamental questions in quantum mechanics  @xcite .",
    "unlike in classical feedback control , in qfc the measurement that is part of the feedback loop affects the dynamics of the system  @xcite .",
    "even so , qfc is actually contained within the general framework of classical control theory .",
    "this is because , even if the measurement in the feedback process is continually modified as the system evolves , quantum systems are merely specific examples of noisy non - linear dynamical systems . as a result ,",
    "the techniques of classical control theory are usually applicable to quantum systems .",
    "however , most of the powerful results of control theory apply only to linear systems , and are therefore not relevant to the majority of quantum feedback control problems .",
    "an important exception are the `` verification theorems ''  @xcite .",
    "these are applicable to feedback control in any dynamical system , and have two uses .",
    "the first is to test whether or not a given feedback protocol is the _ optimal _ protocol for a given task .",
    "if one has devised a protocol , by intuitive means or otherwise , it is very useful to be able to check if it is optimal , especially if the protocol admits an analytic solution . knowing that a protocol is optimal is useful , but so is knowing that it is not",
    " this tells us that there may yet be hidden and unexpected things to learn about the given problem .",
    "the second use of verification theorems is that they provide a systematic numerical procedure for finding optimal feedback protocols .",
    "the literature on verification theorems is not easily accessible to most quantum physicists , however , because it is written in the jargon of axiomatic probability theory ( filtrations , adapted processes and the like ) .",
    "further , the most widely applicable verification theorem , proved in the last few years , requires the use of `` superderivatives '' and `` viscosity solutions ''  @xcite , a subject unfamiliar to most theoretical physicists .",
    "our purpose here is to explain , in a straightforward manner and without technical jargon , how to check if a feedback protocol is optimal , and how to find optimal protocols numerically .",
    "we also give a concrete example of the former , involving an optimal feedback protocol that we reported recently in ref .",
    "@xcite , and for which the viscosity verification theorem is essential .",
    "we note that we were first introduced to verification theorems by the article of wiseman and bouten , in which they used these theorems to prove the optimality of a number of quantum rapid - purification protocols  @xcite .",
    "since the usefulness of verification theorems in qfc is clear , we felt that an accessible article on this topic would useful .",
    "we begin in the following section by introducing the subject of quantum feedback control itself .",
    "while the concepts are simple , it does require stochastic calculus , and this is unfamiliar to many physicists .",
    "we thus start by discussing this aspect of qfc a little .",
    "we then present the equations of motion for a continuously monitored system , and show how the effect of feedback can be easily included .",
    "we next show how to quantify the problem of optimizing the feedback protocol for a given task .",
    "having done this we now know what the optimization problem is for any given control task , and we can show how to use the `` classic '' verification theorem to check whether a feedback protocol is optimal . this is the subject of sections  [ cvt ] and  [ vteg ] .",
    "the classic verification theorem is sufficient so long as the evolution induced by the feedback protocol has continuous first and second derivatives . for many protocols the evolution of the system does not satisfy this condition , however .",
    "an example is a protocol which switches abruptly at some time from one hamiltonian to another . in this case",
    "the evolution has continuous derivatives everywhere except at the point(s ) where the protocol switches . to check optimality in this more general case we require a more general verification theorem",
    "this theorem , while very similar to the first , requires the use of viscosity solutions . in section  [ vs ]",
    "we explain how to calculate a superderivative ( and subderivative ) , and how to show if a function is a `` viscosity solution '' of a given differential equation .",
    "we can then show how to use the more general verification theorem to determine the optimality of a feedback protocol that has discontinuities , and we do this in section  [ evt ] . with this",
    "we have achieved our main goal . in section  [ findop ]",
    "we show how the verification theorems also provide a numerical method to find optimal feedback protocols , and in section  [ oco ] we show how , with almost no modification , the same techniques work for time - optimal control problems .",
    "section  [ conc ] concludes with a brief summary .",
    "the dynamics of an isolated quantum system is given by schrdinger s equation .",
    "if we describe the system using a density matrix , @xmath0 , then this equation is @xmath1 .\\ ] ] if there is an environment that introduces noise into the system , then one can often include the effects of this environment by adding the terms of a lindblad master equation to the above hamiltonian evolution  .",
    "the equation of motion for @xmath0 becomes @xmath1   + \\gamma \\mathcal{d}[c ] \\rho , \\ ] ] where we have defined @xmath2 \\rho = 2c^\\dagger \\rho c - c^\\dagger c \\rho - \\rho c^\\dagger c .\\ ] ] here @xmath3 is a rate constant , and @xmath4 is an operator that depends on the coupling of the system to the environment . to add to the equation of motion the effect of monitoring the system , we simply add another set of terms .",
    "before we do so , however , let us explain exactly what we mean by monitoring .",
    "monitoring a system means that we obtain a continuous readout of some property of the system .",
    "let us say that we are monitoring the position of an object .",
    "this means that in each tiny time - step @xmath5 , we obtain a little bit of information about this position , @xmath6 . why a tiny bit ?",
    "why not the precise position ? to understand this , first recall that all real measurements ( classical as well as quantum ) have some inaccuracy , which means that the measurement result is @xmath6 plus some random number ( the error ) .",
    "this random number limits the amount of information we have about @xmath6 ( that is , it limits the accuracy to which we can pinpoint @xmath6 after obtaining the result ) .",
    "now , no physical measurement process can extract a finite amount if information in an infinitely short time , because the speed of any interaction is necessarily finite .",
    "thus in a time interval @xmath5 , the amount of information must also be infinitesimal , which means that the error must tend to infinity as @xmath7 .",
    "for a classical measurement the measurement result in a time interval @xmath5 is therefore given by @xmath8 where @xmath6 is the true value of @xmath6 , and @xmath9 must have a bigger variance the smaller @xmath5 .",
    "it turns out that the quantum equivalent of this is  @xcite @xmath10 where @xmath11 is the operator for the observable @xmath6   the result should be the true value plus an error , it is not so clear why the expression @xmath12 also makes sense . nevertheless , it turns out that the two forms are completely equivalent .",
    "it follows that the only way that a measurement of @xmath6 can determine the expectation value of @xmath6 precisely is to determine the true value of @xmath6 precisely , at which point the expectation value and the true value are the same . ] .",
    "it turns out that if the error is gaussian , ( being by far the most common measurement error because of the central limit theorem , and the one we will consider here ) , the variance of @xmath9 must be proportional to @xmath13 ( and thus the error is proportional to @xmath14 ) . for further details on the reason for this ,",
    "we refer you to  @xcite .",
    "because of this the value of @xmath15 becomes , strictly speaking , infinite as @xmath16 .",
    "so instead of writing our equations in terms of @xmath15 , we write them instead in terms of @xmath17 , which we will denote by @xmath18 .",
    "this is a perfectly finite quantity .",
    "se we have @xmath19 where @xmath20 is an arbitrary constant determining the amount of the noise , and @xmath21 is a gaussian random variable with mean zero and variance equal to @xmath5 .",
    "thus in each interval @xmath5 , @xmath21 is picked from the probability density @xmath22    now that we know precisely what we mean by a continuous measurement of a physical quantity @xmath6 ; we mean a measurement that provides a continuous stream of measurement results @xmath23 . now we need to know how the state @xmath0 changes in each time interval as a result of the measurement . in the interval @xmath5 , the state @xmath24 goes to @xmath25 , where  @xcite @xmath26\\rho +   \\sqrt{2k}(x\\rho + \\rho x - 2\\langle x\\rangle \\rho ) dw , \\ ] ] where @xmath27 and as usual @xmath28 $ ] . loosely speaking",
    ", @xmath29 gives the rate at which the measurement extracts information about @xmath6 . here",
    "the random increment @xmath21 is precisely the _ same _ increment that appears in the measurement record @xmath18 .",
    "this makes sense : the change in the state of the system in the time interval @xmath5 depends upon the measurement result in that time interval . as a result",
    "we can also write the above equation for @xmath30 directly in terms of the measurement record : @xmath26\\rho +   4k(x\\rho + \\rho x - 2\\langle x\\rangle \\rho ) ( dr - \\langle x \\rangle dt ) .\\",
    "] ] normally one would divide @xmath30 by @xmath5 to get the time derivative @xmath31 , and write the equation of motion for @xmath0 using this derivative .",
    "however , @xmath32 is rather pathological ( just as @xmath33 is above ) , so when writing differential equations involving @xmath21 we keep them in terms of differentials .",
    "thus the full equation of motion for a noisy system that is also continuously monitored is @xmath34 dt + \\mathcal{d}[c]\\rho dt   - k \\mathcal{d}[x]\\rho dt   \\nonumber \\\\               &   & +   \\sqrt{2k}(x\\rho + \\rho x - 2\\langle x\\rangle \\rho ) dw .",
    "\\label{smerec}\\end{aligned}\\ ] ] this equation is referred to as a _",
    "stochastic _ equation , because it contains a term that fluctuates randomly .    to be able to manipulate stochastic equations",
    ", one needs to use the rules of _",
    "stochastic calculus_. this boils down entirely to the rule @xmath35 . on first sight",
    "this is a very strange relation , because @xmath21 is random , and @xmath5 is deterministic .",
    "however , note that @xmath36 . because of this , if one divides any tiny time interval into many smaller sub - intervals , and adds up the many increments of @xmath37 , the result is a deterministic quantity in the limit in which there are infinitely many sub - intervals  @xcite .",
    "the result is that in the continuum limit it is always true that @xmath35 . for further details regarding the manipulation and solution of stochastic equations",
    "we refer you to  @xcite .    now that we have the evolution equation for a monitored system , we want to include feedback in the dynamics .",
    "this is very simple .",
    "all we do is specify that the observer can change the hamiltonian of the system , @xmath38 , and also if we wish , the measured observable @xmath11 , and allow @xmath38 and @xmath11 to be some function of the measurement results .",
    "specifically , @xmath38 and @xmath11 at time @xmath39 are allowed to be any function of the measurement results , @xmath23 , obtained up until that time .",
    "we can write @xmath38 , for example , as @xmath40 , with @xmath41 where @xmath42 is an arbitrary function of its arguments . because the density matrix at time @xmath39 completely determines",
    "the future behavior of the system ( given the system hamiltonian ) , all optimal feedback protocols can be obtained by making @xmath43 and @xmath44 functions of @xmath24 ( and possibly the current time , @xmath39 ) . the observer obtains @xmath24 simply by using the measurement results to solve eq.([smerec ] ) from the initial time up until time @xmath39 .",
    "thus we choose @xmath45 and @xmath46 .",
    "the equation for the evolution of @xmath0 , including feedback , is then simply @xmath47 dt - k \\mathcal{d}[x(t,\\rho)]\\rho dt    \\notag \\\\               &   &   +   \\sqrt{2k}[x(t,\\rho ) \\rho + \\rho x(t,\\rho ) - 2\\langle x(t,\\rho ) \\rangle \\rho ] dw \\notag \\\\               &   & + \\mathcal{d}[c]\\rho dt     .",
    "\\label{fullsme}\\end{aligned}\\ ] ] the problem of feedback control is to determine @xmath48 and/or @xmath49 in order to achieve a desired evolution as closely as possible in the presence of noise .      in feedback control",
    "the goal is usually one of three things : to arrive at a desired state at a given time @xmath50 ; to produce an evolution that is as close as possible to some desired evolution ; or to reach a given state as quickly as possible .",
    "the first two are called  finite - horizon \" control , and the third  time - optimal \" control .",
    "we will consider the first two of these when introducing the verification procedures .",
    "these procedures can be applied equally well to the third , with minor modification , and we discuss this in section  [ oco ] .",
    "the reason that the first two control objectives fall in the same category is that the first is merely a special case of the second : in the former we require the system to be close to a specific pure state at a given  horizon time \" @xmath50 ; in the latter we require that the system be as close as possible to some given ( time dependent ) pure state , @xmath51 , at _ every _ time .",
    "this desired state is called the _",
    "target state _ , or the target evolution .",
    "( note that there is little point in choosing the target state to be mixed - mixing merely represents a lack of knowledge regarding the state , and this is not beneficial in a control setting . )",
    "now consider the second control objective .",
    "to define precisely how well a control protocol achieves the objective , we need to choose a measure of the distance from one quantum state to another to quantify what we mean by the system being _ close _ to the target state .",
    "there are a number of measures we can use , such as the fidelity  @xcite , the distinguishability  @xcite , or the quantum relative entropy  @xcite , to name but three .",
    "if we choose the fidelity then we want our control protocol to minimize @xmath52 since this is a function of time , to obtain a single quantity to minimize we must combine @xmath53 at all the different times into a single number . to use verification theorems , and indeed the majority of results of optimal control theory",
    ", we must combine the @xmath54 s in a simple fashion : the function to minimize must be merely a weighted sum of the @xmath54 s at different times . since time is continuous , this means that the function to minimize is @xmath55 , for some @xmath56 and final time @xmath50 .",
    "this means that the function to minimize is simply an integral over time of a function of the state @xmath0 at each time .",
    "fortunately this form is quite reasonable and well - motivated , and is rather general .",
    "for example , we can weight different times differently in the integral if some are more important that others .",
    "if the final time is especially important , we can give it extra weight by including it by itself in addition to the integral ( that is , place a delta function weighting at time @xmath50 ) .",
    "we can also include more general functions of the state , since we can place any function of the form @xmath57 in the integral .",
    "for example , if we just want to control the expectation value of a particular observable then @xmath58 can be a function of this expectation value .",
    "or we could choose @xmath58 to be the von neumann entropy of the state , as another example .",
    "there is one more crucial thing to add .",
    "if we could both extract information from the system infinitely fast , and apply infinite forces to the system ( control hamiltonians that induce infinitely fast dynamics ) then we could easily make the system follow any target evolution exactly , even in the presence of environmental disturbance and other noise .",
    "feedback control is only non - trivial if the measurement rate and/or feedback forces are constrained , which they always are in real applications .",
    "there are two ways to place constraints on the control inputs and the measurement rate .",
    "one is simply to place a fixed upper bound on them , and attempt to minimize @xmath59 under these constraints .",
    "the alternative is to include a function of the measurement rate and feedback hamiltonian in @xmath58 .",
    "this means that in minimizing @xmath59 we are trying to find the protocol that gives us the best evolution , while at the same time keeping the control forces as small as possible .",
    "the size of the feedback forces , and the rate at which we extract information , are referred to as the  costs \" of the control protocol . because one often includes these in the functional to minimize , @xmath59 , this functional",
    "is usually called the _",
    "cost_.    finally , since the system is driven by noise , the actual cost ( effort ) expended by the controller on a given run will depend on the specific values that the noise takes for that run .",
    "these specific values are called the _",
    "noise realization_. since the actual cost will vary from run - to - run , it is sensible to have the control protocol minimize the _ average _ value of @xmath59 , where the average is over all noise realizations .    to summarize succinctly the above discussion",
    ", a feedback control problem is defined by the equation of motion of the system we are trying to control , and a cost of the form @xmath60 dt + m(\\rho(t ) ) \\right\\rangle_{\\mbox{\\scriptsize n } } ,     \\label{cost}\\ ] ] that we choose based on our control objective , and that we want to minimize . here",
    "@xmath61 is the part of the hamiltonian that gives the forces applied by the controller ( the  control hamiltonian \" ) , and we have separated out the contribution to the cost of the final state , calling this @xmath62 .",
    "it is useful to do this because in many control problems it is , in fact , only the final state that is important , so that one sets @xmath63 . the angle brackets with the subscript ",
    "n \" , @xmath64 , indicate that the value of the integral is averaged over all possible noise realizations .",
    "we now explain how to use the `` classic '' verification theorem of optimal control theory to determine whether a given protocol is the optimal one .",
    "we will now move to a new notation .",
    "this is to make the presentation easier , and to employ the same notation as used by most control theory texts .",
    "we write the general dynamical equation for the system we are trying to control as @xmath65 here the state of the system is given by the vector @xmath66 , and the control inputs to the system are denoted by the vector @xmath67 ( which is usually a function of the current state , @xmath6 )   does not depend explicitly on the state of the system at _ earlier _ times , the control is referred to as _ markovian_. in fact , so long as the current state is the observers complete state - of - knowledge determined from the measurement record , in theory there is never any need to have the current control depend upon the system at earlier times , since the complete future evolution is entirely determined by the current state . ] .",
    "thus for quantum feedback control , the vector @xmath66 is the vector of the elements of @xmath0 : @xmath68    the vector @xmath69 is the set of all parameters that we can vary . if we write the control hamiltonian as @xmath70 where the @xmath71 are real numbers , then @xmath67 is the set of these @xmath71 , along with a set of numbers that determine the observable we choose to measure , @xmath44 . if we write @xmath11 as @xmath72 where @xmath73 is unitary and @xmath74 is diagonal , then @xmath11 is determined in the most general case by the diagonal elements of @xmath74 , and the @xmath75 angles @xmath76 that parametrize an @xmath77-dimensional unitary  @xcite .",
    "thus @xmath78    the vector @xmath79 is any vector - valued function of @xmath66 , @xmath67 and @xmath39 , and gives the deterministic dynamics of the system .",
    "it is determined by the hamiltonian @xmath38 and the noise operator @xmath4 .",
    "the noise on the system actually gives deterministic motion , because we are considering the evolution of the density matrix .",
    "it is only the measurement that makes the evolution stochastic . )",
    "the matrix - valued function @xmath80 gives the stochastic part of the evolution .",
    "it is determined by the measured observable @xmath44 .",
    "the vector @xmath81 is a vector of mutually independent wiener noises . as usual",
    "we will take the initial time to be @xmath82 , denote the initial state of the system as @xmath83 , and we will call the final ( horizon ) time @xmath84 .",
    "the function @xmath85 completely defines the control protocol .",
    "it tells us what control inputs ( what control hamiltonian ) to apply at any time @xmath39 , for every possible state of the system at that time .",
    "thus @xmath85 _ is _ the control protocol .",
    "the control inputs , @xmath67 , are usually subject to limits .",
    "in general these limits can be defined by any closed region in the vector space in which @xmath67 lives .",
    "the simplest set of conditions would be @xmath86 note that the region ( and thus @xmath87 and @xmath88 ) is not a function of @xmath39 or @xmath66 ; there is only one region that bounds the values control inputs for the duration of the control .",
    "the procedure we will describe is general enough , however , to handle a limiting region that varies with time .",
    "as described above , the control objective is to minimize a _ cost _ , @xmath59 .",
    "using our new notation , this cost is @xmath89 where @xmath58 and @xmath90 are functions that we choose . for the verification procedure",
    ", we have to introduce one more quantity , called the _ cost function _ , @xmath91 .",
    "this is defined as the value of @xmath59 over the interval @xmath92 $ ] , given that the system is at state @xmath66 at time @xmath39 : @xmath93 note that @xmath91 is the average cost that will have to be paid over the time remaining , given we have reached time @xmath39 .",
    "for this reason it is often called the  cost - to - go \" .      to determine whether a given control protocol , @xmath94 is optimal , one performs the following four steps :    * 1*. integrate the equations of motion of the system to calculate the cost function , @xmath95 , for this protocol .    *",
    "2*. check that @xmath96 satisfies two continuity conditions .",
    "these are that @xmath97 are continuous . here",
    "@xmath98 denotes the matrix of second derivatives of @xmath96 .",
    "* 3*. determine whether or not @xmath99 satisfies the following differential equation ( called the hamilton - jacobi - bellman ( hjb ) equation ) : @xmath100 ,     \\label{hjb}\\ ] ] with the final condition @xmath101  , is always satisfied by the cost function , since this condition follows immediately from its definition . ]",
    ".    we will give the function @xmath102 below .",
    "before we do so , we note that the maximum is taken over the allowed values of a vector @xmath103 .",
    "the allowed values of @xmath103 are those of @xmath67 : @xmath103 can only take values in the region that bounds the values of @xmath104 .",
    "note that because @xmath102 is a function of @xmath39 and @xmath66 , one must maximize @xmath102 separately at each time and at each value of @xmath66 .",
    "because of this , the value of @xmath103 that maximizes @xmath102 will in general be different at different values of @xmath39 and @xmath66 .",
    "thus the @xmath103 that maximizes @xmath102 is in general a function of @xmath39 and @xmath66 : @xmath105 .",
    "now we come to the function @xmath102 .",
    "this is @xmath106   \\nonumber \\\\      & & -   \\mathbf{a }   { \\boldsymbol{\\cdot}}\\frac{\\partial c}{\\partial \\mathbf{x } } - l(t,\\mathbf{x},\\mathbf{v } ) .\\end{aligned}\\ ] ] note that @xmath79 and @xmath80 are respectively the vector and matrix that appear in the equation of motion for the system , @xmath107 is the vector of first derivatives of @xmath96 , and @xmath98 is the matrix of second derivatives . to check that @xmath96 satisfies the differential equation given by eq.([hjb ] ) , the only potentially tricky thing is determining what the maximum of @xmath102 is for each @xmath39 and @xmath6  however , this can be fairly easy , depending on the system .",
    "* 4*. check that the @xmath104 for your protocol maximizes @xmath102 ( if this maximum is unique , then this also means that @xmath108 ) .",
    "we now apply the verification theorem to a concrete example .",
    "this example was solved in ref .",
    "@xcite , but without the details of the analysis .",
    "the problem involves feedback control of a 3-state quantum system ( otherwise known as a qutrit ) . the purpose is to prepare the system in a given pure target state at time @xmath50 , but it is only the measurement strength @xmath29 that is bounded ; it is assumed the feedback hamiltonian available to the controller generates evolution that is much faster than the measurement strength , and the noise in the system .",
    "it is also assumed that the controller has the ability to implement any hamiltonian for the qutrit .",
    "because of the strong feedback hamiltonian , the problem becomes one of maximizing the largest eigenvalue of the density matrix .",
    "the reason for this is that , at any desired time , the controller can quickly evolve the system ( that is , apply a unitary operator ) so that the eigenvector corresponding to the largest eigenvalue is equal to the target state . for a given density matrix ,",
    "this unitary operation maximizes the probability that the system is in the target state , and is thus the optimal application of the hamiltonian part of the feedback . in this case",
    "the probability that the system is in the target state is equal to the largest eigenvalue of the density matrix .",
    "the feedback control problem in this case is therefore to choose the measured observable , @xmath44 , as the system evolves , so as to maximize the largest eigenvalue of the density matrix at time @xmath50 .",
    "since the feedback hamiltonian is very large , it can also be used to continually rotate the eigenvectors of the density matrix so the density matrix eigenbasis remains constant with time .",
    "the result of this is that , when we express @xmath11 in terms of this eigenbasis , the equations of motion for the eigenvalues of the density matrix are decoupled from those of the eigenvectors , and so we only need to consider the motion of the eigenvalues to find the optimal control protocol .",
    "in addition to the restriction on the measurement strength , we restrict the observable @xmath11 to having equi - spaced eigenvalues . since the measurement part of the master equation is invariant under the transformation @xmath109 , where @xmath110 is a real number , @xmath11 can be taken to be traceless without loss of generality . as a result ,",
    "the measured observable is of the form @xmath111 where @xmath73 is any unitary .    before solving the problem",
    ", we specialize to the  regime of good control \" .",
    "this is the regime in which the probability that the system is in the target state , @xmath112 , is close to unity  @xcite .",
    "this means that @xmath113 , where @xmath114 .",
    "one can then simplify the dynamics of the density matrix by expanding to first order in @xmath115 . recall that the goal of the feedback in this case is to optimize the largest value of the density matrix , and this problem is completely defined by the dynamics of the eigenvalues alone .",
    "we now denote the largest eigenvalue by @xmath116 , the second largest by @xmath117 , and the smallest by @xmath118 . since @xmath119 , we have only two independent dynamical variables , @xmath117 and @xmath118 . in the regime of good control , under a measurement of @xmath11 ,",
    "the equations of motion are  @xcite @xmath120 dt \\nonumber \\\\                          &    & + \\sqrt{8 } ( x_{00 } - x_{11 } ) \\lambda_1 dw   \\label{eqem1 } \\\\",
    "d\\lambda_2 & = & - 8 \\left [ |x_{20}|^2 \\lambda_2 + |x_{12}|^2 \\frac{\\lambda_1 \\lambda_2}{\\lambda_1 - \\lambda_2 } \\right ] dt \\nonumber \\\\                          &    & + \\sqrt{8 } ( x_{00 } - x_{22 } ) \\lambda_2 dw \\label{eqem2 } , \\end{aligned}\\ ] ] where the matrix elements of @xmath11 are those in the eigenbasis of the density matrix at the current time .",
    "note that the task is to choose @xmath44 so as to maximize @xmath121 , which means minimizing @xmath122 .",
    "our candidate for the optimal control protocol , suggested in  @xcite , is to choose @xmath11 at each time so that , in the eigenbasis of the density matrix , it is @xmath123 this is suggested as the optimal protocol _ only _ up until the point at which @xmath117 has been reduced to the value of @xmath118 .",
    "we now use the procedure described in the previous section to determine whether or not this protocol is optimal .",
    "( if you really want to burn this procedure into your brain , you can stop reading now and try it . )    to begin we need to obtain the cost function . for this",
    "we need the time evolution of the thing we want to minimize ( the cost ) , @xmath115 , under the suggested protocol . under the protocol ,",
    "the only non - zero elements of @xmath11 are @xmath124 , and the equations of motion become @xmath125 these are easy to solve , with the result that @xmath126 . recall that the cost function , @xmath127 , is the value of @xmath115 at the final time , @xmath50 , given that we _ started _ with the values @xmath117 and @xmath118 at time @xmath39 .",
    "so this is @xmath128 note that all the derivatives of @xmath96 are continuous , so the continuity conditions for the verification theorem are satisfied .",
    "now we have to calculate the function @xmath102 .",
    "the ingredients for this are the equations of motion , eqs .",
    "( [ eqem1 ] ) and ( [ eqem2 ] ) , and the first and second derivatives of @xmath96 with respect to @xmath117 and @xmath118 . calculating these derivatives we find that @xmath129 \\nonumber \\\\             &   & + 8 \\left ( \\frac{\\lambda_1 \\lambda_2}{\\lambda_1 - \\lambda_2 } \\right ) |x_{21}|^2   ( 1 -   e^{-8a^2 ( t - t ) } ) .",
    "\\end{aligned}\\ ] ] we must now find the maximum of @xmath130 over all @xmath11 , under the constraint eq.([xcon ] ) .",
    "thus we must maximize @xmath102 over all unitaries @xmath73 .",
    "it is important to note that the @xmath131 that appears in @xmath130 above it not part of the optimization ; this has already been fixed by the protocol . to perform the maximization , we note first that we are only considering times @xmath39 such that @xmath132 . because of this , we can show that @xmath102 will be maximized if we maximize @xmath133 , \\end{aligned}\\ ] ] where @xmath134 and @xmath135 are constants satisfying @xmath136 .",
    "( specifically @xmath137 , and @xmath138/[\\lambda_1/\\lambda_2 - 1]$ ] . )",
    "we do this maximization over @xmath73 numerically using matlab s fminsearch function .",
    "( this function uses the nelder - mead direct search algorithm . )",
    "this shows that the maximum is obtained when @xmath11 is given by eq.([xmax ] ) .",
    "substituting this into @xmath130 we have @xmath139 calculating the time derivative of @xmath96 we have @xmath140 eqs .",
    "( [ cvtrhs ] ) and ( [ cvtlhs ] ) are equal .",
    "thus the cost function satisfies the hamilton - jacobi - bellman equation ( eq.([hjb ] ) ) , and so the protocol is optimal .",
    "recall that we have only tested the protocol up until the point at which the lowest two eigenvalues equalize .",
    "if @xmath39 is the starting time , and @xmath50 the final time , then this means that @xmath141",
    "the purpose of `` viscosity solutions '' ( a branch of the theory of differential equations ) is to allow one to define a continuous function to be a solution of a second order differential equation , even though the function does not have well - defined derivatives .",
    "the reason that this subject is useful to us here , is that optimal feedback protocols often produce cost functions ( @xmath142 in the previous section ) that are not differentiable at some ( usually small , finite ) set of points .",
    "it turns out that such cost functions are viscosity solutions of the hjb equation , and as a result one can check their optimality by using a verification theorem that is very similar to the classic verification theorem in the previous section .",
    "so it turns out yet again that an initially rather odd - seeming branch of mathematics has a direct application .    to use the more general verification theorem we first have to know how to show if something is a viscosity solution to a given de . to do this we need two new definitions , that of a _ superderivative _ ( also called a _ superjet _ ) and a _ subderivative _ ( or _ subjet _ ) . to begin with ,",
    "note that if a function @xmath143 is twice - differentiable at point @xmath144 , then @xmath145 to second order in @xmath146 , where @xmath147 is the vector of first derivatives , and @xmath148 is the matrix of second derivatives : @xmath149 we now define the superderivative , @xmath150 of a function at the point @xmath144 as the set of all vectors @xmath151 and matrices @xmath148 such that @xmath152 to second order in @xmath153 .",
    "the subderivative , @xmath154 is similarly defined by replacing the @xmath155 with a @xmath156 . in feedback control , the functions one deals with are usually twice - differentiable everywhere except at a small number of points .",
    "so as an example , let us calculate the super- and subderivatives of the function @xmath157 at the point @xmath158 ( where it is not differentiable ) .",
    "to do this we first expand @xmath159 about the point @xmath160 , using the fist two terms of the taylor series .",
    "this gives @xmath161 to second order in @xmath162 .",
    "so for the real numbers @xmath163 and @xmath148 to be in the superderivative set , @xmath164 , we need them to satisfy the following two equations simultaneously : @xmath165 note that the second order terms are irrelevant unless the first order terms on each side are equal . examining equation eq.([jplus2 ] )",
    "we see that the condition is satisfied so long as @xmath166 , or @xmath167 and @xmath168 . examining equation eq.([jplus1 ] ) , the condition is satisfied when @xmath169 ( remember that @xmath170 is _ negative _ for eq.([jplus1 ] ) ) , or @xmath171 and @xmath172 . since ( [ jplus1 ] ) and @xmath173 must be satisfied simultaneously , the superderivative is the set @xmath174 for the real numbers @xmath163 and @xmath148 to be in the subderivative , @xmath175 , they must satisfy @xmath176 from eq.([jneg1 ] ) we find that @xmath177 , and from eq.([jneg2 ] ) that @xmath178 . since these can not both be true at once , @xmath175 is the empty set : @xmath179    now that we know what superderivatives and subderivatives are , we can define a _",
    "viscosity solution _ to a differential equation .",
    "we first write our differential equation in the form @xmath180 a continuous function @xmath143 is a viscosity solution of this pde if it is true that @xmath181 if the function @xmath182 is a viscosity solution of a pde at a given point , and its derivatives exist at this point , then it is a solution in the normal sense . therefore , to determine if a function is a viscosity solution to a pde , one first checks that it is a solution to the pde in all regions where its first two derivatives are defined .",
    "then one calculates the super- and subderivatives of @xmath182 at those points where its derivatives are not defined , and checks that @xmath182 is a viscosity solution at those points .",
    "the more general verification theorem , due to zhou and collaborators  @xcite , states that @xmath183 is an optimal feedback protocol so long as the following conditions are satisfied by the cost function , @xmath184  :    * 1*. the cost function must be a viscosity solution of the hjb equation , and it must be true that @xmath185 . to determine whether these conditions are satisfied , one first writes the hjb equation in the form @xmath186 = 0 .",
    "\\label{hjb2}\\ ] ] if we set the vector @xmath187 in eq.([pde ] ) to @xmath188 , then the above hjb equation is exactly of the form given in eq.([pde ] ) . because the hjb equation does not depend on any second derivatives that include @xmath39 , to determine whether @xmath96 is a viscosity solution , we do not need to consider these second derivatives when calculating the super- and subderivatives .",
    "thus , for the purposes of solving the hjb equation , the superderivative at @xmath189 and time @xmath190 , @xmath191 , is the set of values of @xmath192 such that @xmath193 where @xmath194 and @xmath195 .",
    "naturally the subderivative is defined in the same way , with the inequality reversed .",
    "armed with these super- and subderivatives one uses the procedure described in the previous section to determine if @xmath96 is a viscosity solution to the hjb equation .    *",
    "2*. check that @xmath196 maximizes @xmath102 .",
    "* 3*. for each @xmath39 there must be a @xmath197 , @xmath198 and @xmath199 , such that : @xmath200 and @xmath201 where @xmath202 is the evolution of the system under our feedback protocol @xmath183 .",
    "the reason that we no longer need the maximization in this equation , is because @xmath96 is a viscosity solution to the hjb equation ( eq.([hjb2 ] ) ) , and @xmath203 maximizes @xmath102 .",
    "this means that setting @xmath204 and @xmath205 already maximizes @xmath102 .",
    "for this example we consider the same control problem as the previous example ( sec .  [ vteg ] ) , but we consider the problem for all evolution times , not merely up until the two smallest eigenvalues have equalized . from this point",
    "onwards , the protocol suggested in ref .",
    "@xcite involves rapidly switching the measured observable between @xmath11 , given by eq.([xmax ] ) , and the observable @xmath206 this is equivalent to measuring @xmath11 while rapidly switching the eigenvectors of the eigenvalues @xmath117 and @xmath118 . in the limit of fast switching ,",
    "the equations of motion of both eigenvalues are identical , and given by @xmath207 starting at time @xmath39 , and evolving the eigenvalues using the original protocol up until time @xmath208 , where @xmath209 , and then using the second protocol from that time until time @xmath50 , we find that , for @xmath210 , the cost function is @xmath211 for times @xmath212 , the cost function is still given by eq.([w1 ] ) , and we will call this @xmath213 .    the cost function is continuous everywhere , but is no longer differentiable at @xmath214 .",
    "thus we can not use the classic verification theorem on the protocol , but must use the enhanced verification theorem .",
    "this requires that we show that @xmath96 is a solution to the hjb equation on the intervals in which it has continuous derivatives , and that it is a viscosity solution at the point @xmath214 .",
    "we already know that it satisfies the hjb equation on the interval @xmath215 $ ] ( that is , when the evolution time is less than @xmath216 ) .",
    "so we examine next the interval @xmath217 $ ] . to calculate",
    "@xmath102 we need the first and second derivatives of @xmath218 with respect to @xmath117 and @xmath118 .",
    "these are @xmath219 the expression we get for @xmath102 this time is @xmath220 we therefore need to find the @xmath73 that maximizes @xmath221 once again we perform this optimization numerically using matlab s fminsearch .",
    "it turns out that there are many unitaries that maximize @xmath222 , and the unitaries that give the @xmath11 s defined by eqs .",
    "( [ xmax ] ) and ( [ xmax2 ] ) both do so .",
    "so we have @xmath223 this is exactly the time derivative of @xmath218 , so the cost function does satisfy the hjb equation on the interval @xmath224 $ ] .",
    "our final task is to determine whether the cost function is a viscosity solution to the hjb equation at @xmath225 . to do this",
    "we would usually proceed to calculate the super and subderivatives , which would involve expanding @xmath213 and @xmath218 in their taylor series as describe in sec .  [ vs ] .",
    "however , it turns out that in this case we can take a shortcut .",
    "first we note that the protocol involves switching between two measurement operators , so the cost function must be a solution to the hjb equations for both .",
    "the two hjb equations are @xmath226 because these do not contain the second derivatives , we do not need to calculate the @xmath148 part of the super and subderivatives to determine if @xmath96 is a viscosity solution .",
    "we only need the first order parts , @xmath227 and @xmath151 .",
    "but since the first derivatives of @xmath96 are continuous at @xmath225 , @xmath227 and @xmath151 are exactly these derivatives   is automatically a viscosity solution to the hjb equation at @xmath225 . ] .",
    "so all we need to do is to substitute @xmath213 ( or @xmath218 ) into eqs .",
    "( [ hjbf1 ] ) and ( [ hjbf2 ] ) , and check that it is a solution to both . indeed it is , and thus @xmath96 is a viscosity solution of the hjb equation , and we can conclude that the suggested protocol is optimal .",
    "the two verification theorems we have described above also provide a method to search for optimal protocols . to see how this works we return to the hamilton - jacobi - bellman equation , which is @xmath100 .",
    "\\label{hjb_again}\\ ] ] recall that @xmath91 is the total average cost over the remaining time interval , @xmath92 $ ] , given that the system has state @xmath66 at time @xmath39 .",
    "the elements of the vector @xmath103 , in general being functions of the state @xmath66 and time @xmath39 , are the parameters that give the control protocol .",
    "the evolution of the system , @xmath228 , and the cost function @xmath91 , are determined by the choice of @xmath103 .",
    "if the pair @xmath103 and @xmath96 solve the hjb equation when substituted into it , then @xmath103 is an optimal protocol .",
    "the fact that allows us to use the hjb equation to search for optimal protocols , is that _ every _ pair of @xmath103 and @xmath96 satisfies the equation @xmath229 however , @xmath102 will only be maximized if @xmath103 is an optimal protocol .",
    "this means that we can find an optimal protocol by searching over the allowed space of controls @xmath103 for the @xmath103 that maximizes @xmath102 .",
    "note that if @xmath103 is time - dependent , then we will have to search over all functions @xmath103 for one that maximizes @xmath102 at _ every _ time @xmath39 .",
    "this can certainly be a challenging task  nevertheless , it does provide a systematic procedure .",
    "further , the problem simplifies in the following way : one can perform the search by starting close to the final time , and stepping backwards . that is , solving for the optimal @xmath103 in the small time interval @xmath230 $ ] , for all states @xmath6 at the start of this interval .",
    "then , with @xmath231 for that interval fixed at the optimal result obtained , solving for the interval @xmath232 $ ] , and so - on moving backwards .",
    "because of the form of the cost , eq.([cost ] ) , this backwards - in - time procedure will find a globally optimal @xmath103 for the whole interval .",
    "( this point is discussed in most control texts that include the bellman equation - see e.g.  @xcite . )",
    "if @xmath103 is not a function of time , but only of the state , @xmath66 , then the task is significantly easier , since not only is the search space reduced , but it usually means that if @xmath102 is maximized at a single time , it is maximized at all times , so we need only evaluate @xmath102 at a single time . if one can obtain an analytic solution to the equations of motion for every @xmath103 , then one can obtain an analytic expression for @xmath102 in terms of @xmath103 . in this case",
    "numerical minimization is likely to be easy .",
    "so far we have taken the cost to be a function of the dynamical variables , integrated over time , including a separate contribution at the final time .",
    "there is another useful form for the cost function that allows us to use the exactly the same verification procedures .",
    "this alternative cost is what we use if we want to minimize the _ time _ taken to reach a particular event .",
    "this kind of control problem is called _ time - optimal control_. in this case we define a function @xmath233 of the dynamical variables ( and perhaps of time ) , and the goal is to minimize the time taken for @xmath234 to cross a fixed value @xmath235 , called the _",
    "threshold_. the cost is then defined as the expectation value of the time remaining before @xmath234 crosses the threshold .",
    "everything else is the same as before , the only change is this form of the cost . as before , the cost function , @xmath91 , is the average value of the cost from time @xmath39 until we finish , given that the state at time @xmath39 is @xmath66 .",
    "that means that @xmath91 is the average value of time it will take to cross the threshold , given that the current time is @xmath39 and current state is @xmath66 .",
    "thus if we define @xmath236 as the state ( or set of states ) for which @xmath237 , then @xmath238 .",
    "the only change in the verification theorem is that the hjb equation changes a little .",
    "it is now  @xcite @xmath100 - 1 ,    \\label{hjbtoc}\\ ] ] where @xmath102 is the same as before , except that it no longer contains the function @xmath58 : @xmath239   -   \\mathbf{a } { \\boldsymbol{\\cdot}}\\frac{\\partial c}{\\partial \\mathbf{x } } .\\ ] ] note that the hjb equation does not contain either the function @xmath233 , or the threshold value @xmath240  .",
    "this is , of course , satisfied by the cost function , @xmath96 , since it is part of its definition . ] .",
    "these have already played their role by determining @xmath96 .",
    "we have shown how to use verification theorems to determine whether a given feedback protocol is optimal .",
    "the procedure is quite straightforward , and involves : 1 .  solving the equations of motion to obtain the cost function , 2 .  checking two simple continuity conditions on the cost function , 3 .  checking that the cost function is a solution of the hjb equation , and 4 .  checking that the protocol maximizes the rhs of the hjb equation .",
    "if the cost function does not satisfy the continuity conditions ( step 2 above ) , then there is an enhanced verification procedure that can be used .",
    "this is essentially the same as the previous procedure , but one checks instead that the cost function is a _ viscosity _ solution of the hjb equation .",
    "we have also described how the hjb equation can be used , at least in principle , to find optimal protocols . for non - trivial problems",
    "this will usually , but not always , require a numerical implementation , and if so is likely to be numerically intensive . what we have not yet done is to show how the hjb equation is derived .",
    "this is actually quite straightforward , and we give this derivation in the appendix .",
    "to begin with we define the _ value function _ , @xmath241 , as the minimum of the cost function over all possible control protocols : @xmath242 where we have added the subscript @xmath67 to the cost function to make explicit the fact that it depends on the choice of the control , @xmath243 . recall that the cost function , @xmath244 , is the average value of the cost that will be incurred from time @xmath39 until the final time .",
    "( the cost function is defined in section  [ cvt ] ) . the starting point for the hjb equation",
    "is the fact that the value function satisfies the recursion relation @xmath245 where @xmath246,\\mathbf{x}(s),s)$ ] is the instantaneous cost incurred at time @xmath247 .",
    "this recursion relation follows immediately from two facts .",
    "the first is that any protocol that gives the optimal control from time @xmath248 to @xmath50 , must also give the optimal control from any time @xmath249 to @xmath50 .",
    "recall that the optimal protocol tells us what control to apply at every time @xmath39 , for every state @xmath228 that the system could be in at that time .",
    "thus if the protocol @xmath69 minimizes @xmath244 , then it also minimizes @xmath250 for @xmath251 .",
    "the second fact is that the total cost is merely a sum ( integral ) over the separate costs @xmath252 at each time @xmath39 . because of this the total average cost incurred from time @xmath39 onwards is the sum of the cost incurred from time @xmath39 to @xmath253 , and the cost incurred from @xmath253 onwards .",
    "that is @xmath254 adding to this the fact that the optimal protocol @xmath67 minimizes both @xmath244 and @xmath250 , we obtain the recursion relation for @xmath255 ( eq.([recur2 ] ) ) .",
    "the hjb equation can be extracted from eq.([recur2 ] ) by setting @xmath256 and applying ito s rule , @xmath35 .",
    "note that this means we must keep all the differentials up to the second order . to begin with we have @xmath257 we now substitute into this the taylor expansion for @xmath258 , being @xmath259 and the equation of motion for the system , ( eq.([sys - dy ] ) ) , being @xmath260 the result is the hjb equation @xmath261   \\right .",
    "\\nonumber \\\\               &   &   \\left .",
    "-\\mathbf{a }   { \\boldsymbol{\\cdot}}\\frac{\\partial c}{\\partial               \\mathbf{x}}-l(t,\\mathbf{x},\\mathbf{u } )   \\right\\ } .\\end{aligned}\\ ] ] notice that in the last step we used the fact that @xmath262 for any function @xmath182",
    ". a rigorous derivation of the hjb equation can be found in many stochastic control textbooks , an example being ref .",
    "@xcite .",
    "belavkin , _ non - demolition measurement and control in quantum dynamical systems _ , a.  blaquiere , s.  diner and g.  lochak , eds .",
    ", in _ information , complexity and control in quantum physics .",
    "proceedings of the 4th international seminar on mathematical theory of dynamical systems and microphysics _ ,",
    "udine , 413 sept .",
    "1985 , springer - verlag , new york , 1987 , pp . 331336 .",
    "m. yanagisawa and h. kimura , _ a control problem for gaussian states _",
    ", in _ learning , control and hybrid systems , lecture notes in control and information sciences _ , y.  yamamoto and s.  hara , eds . ,",
    "springer - verlag , new york , 1998 , pp .",
    "249313 .",
    "wang , j.s .",
    "jin , and x.q .",
    "li , _ continuous weak measurement and feedback control of a solid - state charge qubit : a physical unravelling of non - lindblad master equation _ , phys .",
    "b 75 ( 2007 ) , p. 155304 .                            a.a .",
    "houck , d.i .",
    "schuster , j.m .",
    "gambetta , j.a .",
    "schreier , b.r .",
    "johnson , j.m .",
    "chow , l. frunzio , j. majer , m.h .",
    "devoret , s.m .",
    "girvin , and r.j .",
    "schoelkopf , _ generating single microwave photons in a circuit _ , nature 449 ( 2007 ) , pp .",
    "328331 .    d.i .",
    "schuster , a.a .",
    "houck , j.a .",
    "schreier , a. wallraff , j.m .",
    "gambetta , a. blais , l. frunzio , j. majer , b. johnson , m.h .",
    "devoret , s.m .",
    "girvin and r.j .",
    "schoelkopf , _ resolving photon number states in a superconducting circuit _ , nature 445 ( 2007 ) , pp ."
  ],
  "abstract_text": [
    "<S> while feedback control has many applications in quantum systems , finding optimal control protocols for this task is generally challenging . </S>",
    "<S> so - called `` verification theorems '' and `` viscosity solutions '' provide two useful tools for this purpose : together they give a simple method to check whether any given protocol is optimal , and provide a numerical method for finding optimal protocols . while treatments of verification theorems usually use sophisticated mathematical language , this is not necessary . in this article </S>",
    "<S> we give a simple introduction to feedback control in quantum systems , and then describe verification theorems and viscosity solutions in simple language . </S>",
    "<S> we also illustrate their use with a concrete example of current interest . </S>"
  ]
}