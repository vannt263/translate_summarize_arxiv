{
  "article_text": [
    "[ [ evolutionary - algorithms - ea ] ] evolutionary algorithms ( ea ) : + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    evolutionary algorithms are capable of solving complicated optimization tasks in which an objective function @xmath1 shall be maximized .",
    "@xmath2 is an individual from the set @xmath3 of feasible solutions .",
    "infeasible solutions due to constraints my also be considered by reducing @xmath4 for each violated constraint .",
    "a population @xmath5 of individuals is maintained and updated as follows : one or more individuals are selected according to some selection strategy .",
    "in generation based eas , the selected individuals are recombined ( e.g.  crossover ) and mutated , and constitute the new population .",
    "we prefer the more incremental , steady - state population update , which selects ( and possibly delets ) only one or two individuals from the current population and adds the newly recombined and mutated individuals to it .",
    "we are interested in finding a single individual of maximal objective value @xmath4 for difficult multimodal and deceptive problems .",
    "[ [ standard - selection - schemes - std ] ] standard selection schemes ( std ) : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the standard selection schemes ( abbreviated by std in the following ) , proportionate , truncation , ranking and tournament selection all favor individuals of higher fitness @xcite .",
    "this is also true for less common schemes , like boltzmann selection @xcite .",
    "the fitness function is identified with the objective function ( possibly after a monotone transformation ) . in",
    "linear proportionate selection the probability of selecting an individual depends linearly on its fitness @xcite . in truncation",
    "selection the @xmath6 fittest individuals are selected , usually with multiplicity @xmath7 in order to keep the population size fixed @xcite .",
    "( linear ) ranking selection orders the individuals according to their fitness .",
    "the selection probability is , then , a ( linear ) function of the rank @xcite .",
    "tournament selection @xcite , which selects the best @xmath8 out of @xmath9 individuals has primarily developed for steady - state eas , but can be adapted to generation based eas .",
    "all these selection schemes have the property ( and goal ! ) to increase the average fitness of a population , i.e.  to evolve the population towards higher fitness . for a population with a gaussian fitness distribution ,",
    "the probability of selecting an individual and the effect of selection is shown in figure [ figsel ] .",
    "[ [ the - problem - of - the - right - selection - pressure ] ] the problem of the right selection pressure : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the standard selection schemes std , together with mutation and recombination , evolve the population towards higher fitness .",
    "if the selection pressure is too high , the ea gets stuck in a local optimum , since the genetic diversity rapidly decreases . the suboptimal genetic material which might help in finding the global optimum",
    "is deleted too rapidly ( premature convergence ) . on the other hand",
    ", the selection pressure can not be chosen arbitrarily low if we want ea to be effective . in difficult optimization problems , suitable population sizes , mutation and recombination rates , and selection parameters , which influence the selection intensity , are usually not known beforehand",
    ". often , constant values are not sufficient at all .",
    "there are various suggestions to dynamically determine and adapt the parameters @xcite .",
    "other approaches to preserve genetic diversity are fitness sharing @xcite , crowding @xcite and local mating @xcite .",
    "they depend on the proper design of a neighborhood function based on the specific problem structure and/or coding .",
    "[ [ the - main - idea ] ] the main idea : + + + + + + + + + + + + + +    here , we propose a new selection scheme , based on the insight that we are not primarily interested in a population converging to maximal fitness , but only in a single individual of maximal fitness .",
    "the scheme automatically creates a suitable selection pressure and preserves genetic diversity better than std . the proposed fitness uniform selection scheme fuss ( see also figure [ figsel ] ) is defined as follows : _ if the lowest / highest fitness values in the current population @xmath10 are @xmath11 , we select a fitness value @xmath4 uniformly in the interval @xmath12 $ ] .",
    "then , the individual @xmath13 with fitness nearest to @xmath4 is selected and a copy is added to @xmath10 , possibly after mutation and recombination . _ we will see that fuss maintains genetic diversity much better than std , since a distribution over the fitness values is used , unlike std , which all use a distribution over individuals .",
    "premature convergence is avoided in fuss by abandoning convergence at all .",
    "nevertheless there is a selection pressure in fuss towards higher fitness .",
    "the probability of selecting a specific individual is proportional to the distance to its nearest fitness neighbor . in a population with a high density of unfit and low density of fit individuals ,",
    "the fitter ones are effectively favored .",
    "[ [ contents ] ] contents : + + + + + + + + +    in _ section [ secfuss ] _ we discuss the problems of local optima and exponential takeover @xcite in std .",
    "motivated by the need to preserve genetic diversity , we define the fitness uniform selection scheme fuss .",
    "we discuss under which circumstances fuss leads to an ( approximate ) fitness uniform population .",
    "further properties of fuss are discussed in _ section [ secprop ] _ , especially , how fuss creates selection pressure towards higher fitness and how it preserves diversity better than std .",
    "further topics are the equilibrium distribution and the transformation properties of fuss under linear and non - linear transformations .    in _ section [ secex ] _ we demonstrate by way of a simple optimization example that an ea with fuss can optimize much faster than with std . we show that crossover can be effective in fuss , even when ineffective in std .",
    "furthermore , fuss and std are compared to random search with and without crossover .",
    "there is a possible slowdown when including recombination , as discussed in _ section [ seccross ] _ , which can be avoided by using a scale independent pair selection .",
    "it is a `` best '' compromise between unrestricted recombination and recombination of individuals with similar fitness only .    to simplify the discussion we have concentrated on the case of discrete , equi - spaced fitness values . in many practical problems ,",
    "the fitness function is continuously valued .",
    "fuss and some of the discussion of the previous sections is generalized to the continuous case in _ section [ seccont]_.    a summary , conclusions and further discussions can be found in _ section [",
    "secconc]_.    the focus of this work is on a theoretical analysis of fuss .",
    "implementation details and numerical results for various test - functions and for real - world problems will be presented elsewhere .",
    "[ [ the - problem - of - local - optima ] ] the problem of local optima : + + + + + + + + + + + + + + + + + + + + + + + + + + + +    proportionate , truncation , ranking and tournament are the standard ( std ) selection algorithms used in evolutionary optimization .",
    "they have the following property : if a local optimum @xmath14 has been found , the number of individuals with fitness @xmath15 increases exponentially .",
    "assume a low mutation and recombination rate , or , for instance , truncation selection _",
    "after _ mutation and recombination .",
    "further , assume that it is very difficult to find an individual more fit than @xmath14",
    ". the population will then degenerate and will consist mostly of @xmath14 after a few rounds .",
    "this decreased diversity makes it even more unlikely that @xmath16 gets improved .",
    "the suboptimal genetic material which might help in finding the global optimum has been deleted too rapidly . on the other hand ,",
    "too high mutation and recombination rates convert the ea into an inefficient random search . in the following we suggest a new a new selection scheme , which automatically generates a suitably adapting selection pressure .    [",
    "[ the - fitness - uniform - selection - scheme - fuss ] ] the fitness uniform selection scheme ( fuss ) : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for simplicity we start with a fitness function @xmath17 with discrete equi - spaced values @xmath18 . the continuous valued case @xmath19 $ ] is considered later . the fitness uniform selection scheme ( fuss ) is defined as follows : randomly select a fitness value @xmath4 uniformly from the fitness values @xmath20 .",
    "randomly ( uniformly ) select an individual @xmath21 from population @xmath10 with fitness @xmath4 .",
    "add another copy of @xmath21 to @xmath10 .",
    "note the two stage uniform selection process which is very different from a one step uniform selection of an individual of @xmath10 ( see figure [ figsel ] ) .    in std",
    ", inertia increases with population size .",
    "a large mass of unfit individuals reduces the probability of selecting fit individuals .",
    "this is not the case for fuss .",
    "hence , without loss of performance , we can define a _ pure model _ , in which no individual is ever deleted ; the population size increases with time .",
    "no genetic material is ever discarded and no fine - tuning in population size is necessary .",
    "what may prevent the pure model from being applied to practical problems are not computation time issues , but memory problems . if space gets a problem we delete individuals from the most occupied fitness levels .",
    "most of the following statements remain valid with this modification .",
    "[ [ asymptotically - fitness - uniform - population ] ] asymptotically fitness uniform population : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the expected number of individuals per fitness level @xmath4 after @xmath22 selections is @xmath23 , where @xmath24 is the initial distribution .",
    "hence , asymptotically the fitness levels get uniformly occupied by a population fraction @xmath25 where @xmath26 is the set of individuals at time @xmath22 with fitness @xmath4 .",
    "[ [ fitness - gaps - and - continuous - fitness ] ] fitness gaps and continuous fitness : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we made two unrealistic assumptions .",
    "first , we assumed that each fitness level is initially occupied .",
    "if the smallest / largest fitness values in @xmath27 are @xmath28 we extend the definition of fuss by selecting a fitness value @xmath4 uniformly in the interval @xmath29 $ ] and an individual @xmath30 with fitness nearest to @xmath4 .",
    "this also covers the case when there are missing intermediate fitness values , and also works for continuous valued fitness functions ( @xmath31 ) .",
    "[ [ mutation - and - recombination ] ] mutation and recombination : + + + + + + + + + + + + + + + + + + + + + + + + + + +    the second assumption was that there is no mutation and recombination . in the presence of small mutation and/or recombination rates",
    "eventually each fitness level will become occupied and the occupation fraction is still asymptotically approximately uniform . for larger rates",
    "the distribution will be no longer uniform , but the important point is that the occupation fraction of _ no _ fitness level decreases to zero for @xmath32 , unlike for std .",
    "furthermore , fuss selects by construction uniformly in the fitness levels , even if the levels are not uniformly occupied .",
    "we will see that this is the more important property .",
    "[ [ fuss - effectively - favors - fit - individuals ] ] fuss effectively favors fit individuals : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    fuss preserves diversity better than std , but the latter have a ( higher ) selection pressure towards higher fitness , which is necessary for optimization . at first glance",
    "it seems that there is no such pressure at all in fuss , but this is deceiving . as fuss selects uniformly in the fitness levels , individuals of low populated fitness levels are effectively favored .",
    "the probability of selecting a specific individual with fitness @xmath4 is inverse proportional to @xmath33 ( see figure [ figsel ] ) . in a typical ( fuss )",
    "population there are many unfit and only a few fit individuals . hence , fit individuals",
    "are effectively favored until the population becomes fitness uniform .",
    "occasionally , a new higher fitness level is discovered and occupied by a new individual , which then , again , is favored .    [",
    "[ no - takeover - in - fuss ] ] no takeover in fuss : + + + + + + + + + + + + + + + + + + + +    with fuss , takeover of the highest fitness level never happens .",
    "the concept of takeover time @xcite is meaningless for fuss .",
    "the fraction of fittest individuals in a population is always small .",
    "this implies that the average population fitness is always much lower than the best fitness .",
    "actually , a large number of fit individuals is usually not the true optimization goal .",
    "a single fittest individual usually suffices to having solved the optimization task .",
    "[ [ fuss - may - also - favor - unfit - individuals ] ] fuss may also favor unfit individuals : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    note , if it is also difficult to find individuals of low fitness , i.e.  if there are only few individuals of low fitness , fuss will also favor these individuals .",
    "half of the time is `` wasted '' in searching on the wrong end of the fitness scale .",
    "this possible slowdown by a factor of 2 is usually acceptable . in section [ secex ] we will see that in certain circumstances this behaviour can actually speedup the search . in general , fitness levels which are difficult to reach , are favored .",
    "[ [ distribution - within - a - fitness - level ] ] distribution within a fitness level : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    within a fitness level there is no selection pressure which could further exponentially decrease the population in certain regions of the individual space .",
    "this ( exponential ) reduction is the major enemy of diversity , which is suppressed by fuss . within a fitness level ,",
    "the individuals freely drift around ( by mutation ) .",
    "furthermore , there is a steady stream of individuals into and out of a level by ( d)evolution from ( higher)lower levels .",
    "consequently , fuss develops an equilibrium distribution which is nowhere zero .",
    "we expect fuss to somewhat lower ( but not to solve ) the problems associated with genetic drift .",
    "the above does also not mean that the distribution within a level is uniform .",
    "for instance , if there are two ( local ) maxima of same height , a very broad one and a very narrow one , the broad one may be populated much more than the narrow one , since it is much easier to `` find '' .",
    "[ [ steady - creation - of - individuals - from - every - fitness - level ] ] steady creation of individuals from every fitness level : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in std , a wrong step ( mutation ) at some point in evolution might cause further evolution in the wrong direction . once a local optimum has been found and all unfit individuals were eliminated it is very difficult to undo the wrong step . in fuss ,",
    "all fitness levels remain occupied from which new mutants are steadily created , occasionally one leading to further evolution in a more promising direction .",
    "[ [ transformation - properties - of - fuss ] ] transformation properties of fuss : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    fuss ( with continuous fitness ) is independent of a scaling and a shift of the fitness function , i.e.  fuss(@xmath34 ) with @xmath35 is identical to fuss(@xmath4 ) .",
    "this is true even for @xmath36 , since fuss searches for maxima _ and _ minima , as we have seen .",
    "it is not independent of a non - linear ( monotone ) transformation unlike tournament , ranking and truncation selection .",
    "the non - linear transformation properties are more like the ones of proportionate selection .",
    "in the following we compare the performance of fitness uniform selection ( fuss ) , random search ( rand ) and standard selection ( std ) with and without recombination on a simple test example .",
    "we regard it as a prototype for deceptive multimodal functions .",
    "the example should demonstrate why fuss can be superior to rand and std .",
    "numerical results are briefly discussed at the end of the section .    [",
    "[ simple-2d - example ] ] simple 2d example : + + + + + + + + + + + + + + + + + +    consider individuals @xmath37\\!\\times\\![0,1]$ ] , which are tupels of real numbers , each coordinate in the interval @xmath38 $ ] .",
    "the example models individuals possessing up to 2 `` features '' .",
    "individual @xmath21 possesses feature @xmath39 if @xmath40\\!\\times\\![0,1]$ ] , and feature @xmath41 if @xmath42\\!\\times\\![b , b\\!+\\!\\delta]$ ] .",
    "the fitness function @xmath43 is defined as @xmath44{4 } } \\put(12.5,30){\\makebox(0,0)[cc]{3 } } \\put(22.5,30){\\makebox(0,0)[cc]{1 } } \\put(32.5,30){\\makebox(0,0)[cc]{3 } } \\put(32.5,10){\\makebox(0,0)[cc]{3 } } \\put(12.5,10){\\makebox(0,0)[cc]{3 } } \\put(12.5,17.5){\\makebox(0,0)[cc]{2 } } \\put(32.5,17.5){\\makebox(0,0)[cc]{2 } } \\put(22.5,10){\\makebox(0,0)[cc]{1 } } \\put(44,2.5){\\makebox(0,0)[cc]{$x$ } } \\put(22.5,2.5){\\makebox(0,0)[cc]{$\\delta$ } } \\put(20,3.5){\\makebox(0,0)[cc]{$a$ } } \\put(2.5,17.5){\\makebox(0,0)[cc]{$\\delta$ } } \\put(4,14.5){\\makebox(0,0)[cc]{$b$ } } \\put(40,3){\\makebox(0,0)[cc]{1 } } \\put(3.5,40){\\makebox(0,0)[cc]{1 } } \\put(2.5,44){\\makebox(0,0)[cc]{$y$ } } \\put(22.5,42.5){\\makebox(0,0)[cc]{$f(x , y)$ } } \\end{picture } } \\ ] ] we assume @xmath45 .",
    "individuals with none of the two features ( @xmath46 ) have fitness @xmath47 .",
    "these `` local @xmath47 optima '' occupy most of the individual space @xmath3 , namely a fraction @xmath48 .",
    "it is disadvantageous for an individual to possess only one of the two features ( @xmath49 ) , since @xmath50 in this case . in combination ( @xmath51 )",
    ", the two features lead to the highest fitness , but the global maximum @xmath52 occupies the smallest fraction @xmath53 of the individual space @xmath3 . with a fraction @xmath54 ,",
    "the @xmath50 minima are in between .",
    "[ [ random - search ] ] random search : + + + + + + + + + + + + + +    individuals are created uniformly in the unit square .",
    "the `` local optimum '' @xmath47 is easy to `` find '' , since it occupies nearly the whole space .",
    "the global optimum @xmath52 is difficult to find , since it occupies only @xmath55 of the space .",
    "the expected time , i.e.  the expected number of individuals created and tested until one with @xmath52 is found , is @xmath56 .",
    "here and in the following , the `` time '' @xmath57 is defined as the number of created individuals until the _ first _ optimal individual ( with @xmath52 ) is found .",
    "@xmath57 is neither a takeover time nor the number of generations ( we consider steady - state eas ) .",
    "[ [ random - search - with - crossover ] ] random search with crossover : + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let us occasionally perform a recombination of individuals in the current population .",
    "we combine the @xmath58-coordinate of one uniformly selected individual @xmath59 with the @xmath60 coordinate of another individual @xmath61 .",
    "this crossover operation maintains a uniform distribution of individuals in @xmath38 ^ 2 $ ] .",
    "it leads to the global optimum if @xmath62 and @xmath63 .",
    "the probability of selecting an individual in @xmath64 is @xmath65 ( we assumed that the global optimum has not yet been found ) .",
    "hence , the probability that @xmath39 crosses with @xmath41 is @xmath53 .",
    "the time to find the global optimum by random search including crossover is still @xmath66 .",
    "[ [ mutation ] ] mutation : + + + + + + + + +    the result remains valid ( to leading order in @xmath67 ) if , instead of a random search , we uniformly select an individual and mutate it according to some probabilistic , sufficiently mixing rule , which preserves uniformity in @xmath38 $ ] .",
    "one popular such mutation operator is to use a sufficiently long binary representation of each coordinate , like in genetic algorithms , and flip a single bit . in the following ,",
    "we assume a mutation operator which mutates with probability @xmath68 the first / second coordinate , preserves uniformity , is sufficiently mixing , and leaves the other coordinate unchanged , like the single - bit - flip operator .",
    "[ [ standard - selection - with - crossover ] ] standard selection with crossover : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the @xmath69 and @xmath70 individuals contain useful building blocks , which could speedup the search by a suitable selection and crossover scheme .",
    "unfortunately , the standard selection schemes favor individuals of higher fitness and will diminish the @xmath50 population fraction .",
    "the probability of selecting @xmath50 individuals is even smaller than in random search .",
    "hence @xmath71 .",
    "standard selection does not improve performance , even not in combination with crossover , although crossover is well suited to produce the needed recombination .",
    "[ [ fuss ] ] fuss : + + + + +    at the beginning , only the @xmath47 level is occupied and individuals are uniformly selected and mutated . the expected time till an @xmath50 individual in @xmath72 is created is @xmath73 ( not @xmath74 , since only one coordinate is mutated ) . from this time on fuss",
    "will select one half ( ! ) of the time the @xmath50 individual(s ) and only the remaining half the abundant @xmath47 individuals . when level @xmath69 _ and _ level @xmath70 are occupied , the selection probability is @xmath75 for these levels . with probability",
    "@xmath76 the mutation operator will mutate the @xmath60 coordinate of an individual in @xmath39 or the @xmath58 coordinate of an individual in @xmath41 and produces a new @xmath77 individual .",
    "the relative probability of creating an @xmath52 individual is @xmath78 . the expected time to find this global optimum from the @xmath50 individuals ,",
    "hence , is @xmath79^{-1}$ ] .",
    "the total expected time is @xmath80 .",
    "fuss is much faster by exploiting unfit @xmath50 individuals .",
    "this is an example where ( local ) minima can help the search .",
    "examples where a low local maxima can help in finding the global maximum , but where standard selection sweeps over too quickly to higher but useless local maxima , can also be constructed .    [ [ fuss - with - crossover ] ] fuss with crossover : + + + + + + + + + + + + + + + + + + + +    the expected time till an @xmath69 individual in @xmath39 and an @xmath70 individual in @xmath41 is found is @xmath81 , even with crossover .",
    "the probability of selecting an @xmath82 individual is @xmath83 .",
    "thus , the probability that a crossing operation crosses @xmath39 with @xmath41 is @xmath84 .",
    "the expected time to find the global optimum from the @xmath50 individuals , hence , is @xmath85 , where the @xmath86 factor depends on the frequency of crossover operations .",
    "this is far faster than by std , even if the @xmath50 levels were local maxima , since to get a high standard selection probability , the level has first to be taken over , which itself needs some time depending on the population size . in fuss a single @xmath69 and a single @xmath70 individual suffice to guarantee a high selection probability and an effective crossover .",
    "crossover does not significantly decrease the _ total _ time @xmath87 , but for a suitable 3d generalization we get a large speedup by a factor of @xmath67 .",
    "[ [ simple-3d - example ] ] simple 3d example : + + + + + + + + + + + + + + + + + +    we generalize the 2d example to d - dimensional individuals @xmath88^d$ ] and a fitness function @xmath89 where @xmath90 is the characteristic function of feature @xmath91 @xmath92 for @xmath93 , @xmath4 coincides with the 2d example . for @xmath94 , the fractions of @xmath38 ^ 3",
    "$ ] where @xmath95 are approximately @xmath96 . with the same line of reasoning",
    "we get the following expected search times for the global optimum : @xmath97 @xmath98 this demonstrates the existence of problems , where fuss is much faster than rand and std , and that crossover can give a further boost in fuss , even when ineffective in combination with std .    [",
    "[ numerical - results ] ] numerical results : + + + + + + + + + + + + + + + + + +    an ea with fuss and std has been implemented .",
    "first experiments confirm the superiority of fuss also for other complicated multimodal and deceptive fitness functions .",
    "the asymptotic behavior of the convergence times @xmath57 for @xmath99 for the previous example has been verified .",
    "we got similar results for the function @xmath100 , which is a continuous version of the 2d example .",
    "we further applied fuss to the traveling salesman problem .",
    "we considered @xmath101 cities with random matrix distances , random initial paths , random 1-opt and 2.5-opt mutation operators , inverse length as fitness , but no crossover yet .",
    "the solutions found by fuss are consistently and significantly better than those found by std .",
    "the current implementation can in no way compete with up - to - date tsp - solvers @xcite , but this was not the intention of the comparison .",
    "the results are very preliminary yet .",
    "implementation details and detailed simulation results will be presented in a forthcoming publication .",
    "[ [ worst - case - analysis - without - recombination ] ] worst case analysis without recombination : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we now want to estimate the maximal possible slowdown of fuss compared to std .",
    "let us assume that all individuals in std have fitness @xmath4 , and once one individual with fitness @xmath102 has been found , takeover of level @xmath102 is quick .",
    "let us assume that this quick takeover is actually good ( e.g.  if there are no local maxima ) .",
    "the selection probability of individuals of same fitness is equal . for fuss",
    "we assume individuals in the range of @xmath103 and @xmath4 .",
    "uniformity is _ not _ necessary . in the worst case",
    ", a selection of an individual of fitness @xmath104 never leads to an individual of fitness @xmath105 , i.e.  is always useless .",
    "the probability of selecting an individual with fitness @xmath4 is @xmath106 .",
    "at least every @xmath107 fuss selection corresponds to a std selection .",
    "hence , we expect a maximal slowdown by a factor of @xmath108 , since fuss `` simulates '' std statistically every @xmath107 selection .",
    "it is possible to artificially construct problems where this slowdown occurs ( unimodal function , local mutation @xmath109 , no crossover ) .",
    "we have never observed this large slowdown in our experiments . for the more complicated multimodal and deceptive objective functions we were interested in",
    ", fuss often outperformed std in solution quality _ and _ time .",
    "[ [ quadratic - slowdown - due - to - recombination ] ] quadratic slowdown due to recombination : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we have seen that @xmath110 . in the presence of recombination , a _ pair _ of individuals has to be selected .",
    "the probability that fuss selects _ two _ individuals with fitness @xmath4 is @xmath111 .",
    "hence , in the worst case , there could be a slowdown by a factor of @xmath112  for _ independent _ selection we expect @xmath113 .",
    "this potential quadratic slowdown can be avoided by selecting one fitness value at random , and then two individuals of this single fitness value . for this _ dependent _ selection , we expect @xmath110 .",
    "one the other hand , crossing two individuals of different fitness can also be advantageous , like the crossing of @xmath69 with @xmath70 individuals in the 2d example of section [ secex ] .    [ [ scale - independent - pair - selection ] ] scale independent pair selection : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    it is possible to ( nearly ) have the best of independent and dependent selection : a high selection probability @xmath114 if @xmath115 and @xmath116 otherwise , with uniform marginal @xmath117 .",
    "the idea is to use a strongly correlated joint distribution for selecting a fitness pair .",
    "a `` scale independent '' probability distribution @xmath118 is appropriate .",
    "we define the joint probability @xmath119 of selecting two individuals of fitness @xmath4 and @xmath120 and the marginal @xmath121 as [ ptjoint ] p(f , f ) : = , @xmath122 we assume @xmath123 in the following .",
    "the @xmath124 in the denominator has been added to regularize the expression for @xmath125 .",
    "the factor @xmath126 ensures correct normalization for @xmath127 .",
    "more precisely , using @xmath128 , one can show that @xmath129 i.e.  @xmath130 is not strictly normalized to @xmath131 and the marginal @xmath121 is only approximately ( within a factor of 2 ) uniform . the first defect can be corrected by appropriately increasing the diagonal probabilities @xmath132 .",
    "this also solves the second problem .",
    "[ pjoint ] p(f , f ) : = \\ {    ll p(f , f ) & ff + p(f , f)+[1|f|-p(f ) ] & f = f    .    [ [ properties - of - pff ] ] properties of @xmath133 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath134 is normalized to @xmath131 with uniform marginal @xmath135 @xmath136 apart from a minor additional logarithmic suppression of order @xmath137 we have the desired behaviour @xmath138 for @xmath139 and @xmath116 otherwise : @xmath140 @xmath141 during optimization , the minimal / maximal fitness of an individual in population @xmath27 is @xmath28 .",
    "in the definition of @xmath134 one has to use @xmath142 instead of @xmath20 , i.e.  @xmath143 continuous fitness functions ----------------------------    [ [ effective - discretization - scale ] ] effective discretization scale : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    up to now we have considered a discrete valued fitness function with values in @xmath144 . in many practical problems ,",
    "the fitness function is continuous valued with @xmath145 $ ] .",
    "we generalize fuss , and some of the discussion of the previous sections to the continuous case by replacing the discretization scale @xmath146 by an effective ( time - dependent ) discretization scale @xmath147 . by construction ,",
    "fuss shifts the population towards a more uniform one .",
    "although the fitness values are no longer equi - spaced , they still form a discrete set for finite population @xmath10 . for a fitness uniform distribution ,",
    "the average distance between ( fitness ) neighboring individuals is @xmath148 .",
    "we define @xmath149 . @xmath150",
    "fuss : + + + + +    fitness uniform selection for a continuous valued function has already been mentioned in section [ secfuss ] .",
    "we just take a uniform random fitness @xmath4 in the interval @xmath151 $ ] .",
    "one may even take the limit @xmath152 in this case probably without harming fuss .",
    "independent and dependent fitness pair selection as described in the last section works analogously .",
    "an @xmath153 version of correlated selection does not exist ; a non - zero @xmath147 is important .",
    "a discrete pair @xmath154 is drawn with probability @xmath133 as defined in ( [ ptjoint ] ) and ( [ pjoint ] ) with @xmath146 and @xmath20 replaced by @xmath147 and @xmath155 .",
    "the additional suppression @xmath156 is small for all practical population sizes .    in all cases an individual with fitness nearest to @xmath4 ( @xmath120 )",
    "is selected from the population @xmath10 ( randomly if there is more than one nearest individual ) .",
    "[ [ discussion ] ] discussion : + + + + + + + + + + +    if we assume a fitness uniform distribution , a worst case bound @xmath157 seems plausible , since the probability of selecting the best individual is approximately @xmath158 . for constant population size",
    "we get a bound @xmath159 . for the preferred non - deletion case with population size @xmath160 the bound",
    "gets much worse @xmath161 . this possible ( but not necessary ! )",
    "slowdown has similarities to the slowdown problems of proportionate selection in later optimization stages .",
    "larger choices of @xmath147 may be favorable if the standard choice causes problems .",
    "we have addressed the problem of balancing the selection intensity in eas , which determines speed versus quality of a solution .",
    "we invented a new fitness uniform selection scheme fuss .",
    "it generates a selection pressure towards sparsely populated fitness levels .",
    "this property is unique to fuss as compared to other selection schemes ( std ) .",
    "it results in the desired high selection pressure towards higher fitness if there are only a few fit individuals .",
    "the selection pressure is automatically reduced when the number of fit individuals increases .",
    "a joint pair selection scheme for recombination has been defined , but not yet implemented . a heuristic worst case analysis of fuss compared to std has been given .",
    "fuss solves the problem of exponential takeover and the resulting loss of genetic diversity of std , while still generating enough selection pressure .",
    "it does not help in getting a more uniform distribution within a fitness level .",
    "we showed analytically by way of a simple example that fuss can be much more effective than std .",
    "fuss should be compared to std on other problems to further explore its efficacy and limitations .",
    "first results look encouraging . of special interest",
    "is whether fuss could improve up - to - date eas that solve difficult combinatoric optimization problems , like tsps .",
    "we expect fuss to be superior to std in cases where an ea with std effectively gets trapped into local optima .        j.  e. baker .",
    "adaptive selection methods for genetic algorithms . in j.",
    "j. grefenstette , editor , _ proceedings of the 1st international conference on genetic algorithms and their applications _ , pages 101111 , pittsburgh , pa , 1985 .",
    "lawrence erlbaum associates .",
    "t.  bck , f.  hoffmeister , and h.  p. schwefel .",
    "a survey of evolution strategies . in r.",
    "k. belew and l.  b. booker , editors , _ proceedings of the 4th international conference on genetic algorithms _ , pages 29 , san diego , ca , july 1991 .",
    "morgan kaufmann .",
    "t.  blickle and l.  thiele . a mathematical analysis of tournament selection . in l.  j. eshelman , editor , _ proceedings of the sixth international conference on genetic algorithms ( icga95 ) _ , pages 916 , san francisco , california , 1995 .",
    "morgan kaufmann publishers .",
    "r.  j. collins and d.  r. jefferson .",
    "selection in massively parallel genetic algorithms . in r.  k. belew and l.  b. booker , editors , _ proceedings of the fourth international conference on genetic algorithms _ , san mateo , ca , 1991 .",
    "morgan kaufmann publishers .",
    "l.  j. eshelman .",
    "the chc adaptive search algorithm : how to safe search when engaging in nontraditional genetic recombination . in g.  j.  e. rawlings , editor , _ foundations of genetic algorithms _ , pages 265283 .",
    "morgan kaufmann , san mateo , 1991 .",
    "d.  e. goldberg and k.  deb . a comparative analysis of selection schemes used in genetic algorithms . in g.",
    "j.  e. rawlings , editor , _ foundations of genetic algorithms _ , pages 6993 .",
    "morgan kaufmann , san mateo , 1991 .",
    "d.  e. goldberg and j.  richardson . genetic algorithms with sharing for multimodalfunction optimization . in j.",
    "j. grefenstette , editor , _ proceedings of the 2nd international conference on genetic algorithms and their applications _ , pages 4149 , cambridge , ma , july 1987 .",
    "lawrence erlbaum associates .",
    "m.  herdy .",
    "reproductive isolation as strategy parameter in hierarchically organized evolution strategies . in r.",
    "mnner and b.  manderick , editors , _ parallel problem solving from nature 2 _ , pages 207217 , amsterdam , 1992 .",
    "north - holland .",
    "d.  s. johnson and a.  mcgeoch .",
    "the traveling salesman problem : a case study . in e.  h.  l. aarts and j.  k. lenstra , editors , _ local search in combinatorial optimization _ , discrete mathematics and optimization , chapter  8 , pages 215310 .",
    "wiley - interscience , chichester , england , 1997 .",
    "maza and b.  tidor .",
    "an analysis of selection procedures with particular attention paid to proportional and boltzmann selection . in s.",
    "forrest , editor , _ proceedings of the 5th international conference on genetic algorithms _ , pages 124131 , san mateo , ca , usa , 1993 .",
    "morgan kaufmann .",
    "d.  schlierkamp - voosen and h.  mhlenbein .",
    "strategy adaptation by competing subpopulations . in y.",
    "davidor , h .-",
    "schwefel , and r.  mnner , editors , _ parallel problem solving from nature  ppsn iii _ , pages 199208 , berlin , 1994 .",
    "ecture notes in computer science 866 .",
    "d.  whitley .",
    "the genitor algorithm and selection pressure : why rank - based allocation of reproductive trials is best . in j.",
    "d. schaffer , editor , _ proceedings of the third international conference on genetic algorithms ( icga89 ) _ , pages 116123 , san mateo , california , 1989 .",
    "morgan kaufmann publishers , inc ."
  ],
  "abstract_text": [
    "<S> in evolutionary algorithms , the fitness of a population increases with time by mutating and recombining individuals and by a biased selection of more fit individuals . </S>",
    "<S> the right selection pressure is critical in ensuring sufficient optimization progress on the one hand and in preserving genetic diversity to be able to escape from local optima on the other . </S>",
    "<S> we propose a new selection scheme , which is uniform in the fitness values . </S>",
    "<S> it generates selection pressure towards sparsely populated fitness regions , not necessarily towards higher fitness , as is the case for all other selection schemes . </S>",
    "<S> we show that the new selection scheme can be much more effective than standard selection schemes .    </S>",
    "<S> technical report idsia-01 - 01 , 17 january 2001 + ftp://ftp.idsia.ch/pub/techrep/idsia-01-01.ps.gz   +    ' '' ''    </S>",
    "<S> height1pt fitness uniform selection to + preserve genetic diversity    ' '' ''    height1pt     + idsia , galleria 2 , ch-6928 manno - lugano , switzerland + marcus@idsia.ch http://www.idsia.ch/@xmath0marcus +    evolutionary algorithms , fitness uniform selection strategy , preserve diversity , local optima , evolution , correlated recombination , crossover . </S>"
  ]
}