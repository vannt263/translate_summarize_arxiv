{
  "article_text": [
    "since the discovery of a polynomial - time hard - decision list decoder for generalised reed  solomon ( grs ) codes by guruswami and sudan ( gs )  @xcite in the late 1990s , much work has been done to speed up the two main parts of the algorithm : interpolation and root - finding .",
    "notably , for interpolation beelen and brander  @xcite mixed the module reduction approach by lee and osullivan  @xcite with the parametrisation of zeh  _ et al . _",
    "@xcite , and employed the fast module reduction algorithm by alekhnovich  @xcite .",
    "bernstein  @xcite pointed out that an asymptotically faster variant can be achieved by using the reduction algorithm by giorgi  _ et al . _",
    "very recently chowdhury  _ et al . _",
    "@xcite used fast displacement - rank linear - algebraic solvers to achieve the fastest known approach .",
    "the gs approach was generalised by ktter and vardy to a soft - decision scenario  @xcite , and the same authors also presented a complexity - reducing re - encoding transformation  @xcite .",
    "cassuto  _ et al . _",
    "@xcite and tang  _ et al . _",
    "@xcite proposed modified interpolation - based list decoders with reduced average - complexity .    for the root - finding step",
    ", one can employ the method of roth and ruckenstein  @xcite in a divide - and - conquer fashion , as described by alekhnovich  @xcite .",
    "this step then becomes an order of magnitude faster than interpolation , leaving the latter as the main target for further optimisations .    for a given grs code",
    ", the gs algorithm has two parameters , both positive integers : the interpolation multiplicity @xmath0 and the list size @xmath1 . together with the code parameters they determine the decoding radius @xmath2 . to achieve a higher decoding radius for some given grs code",
    ", one needs higher @xmath0 and @xmath1 , and the value of these strongly influences the running time of the algorithm .    in this work , we present a novel iterative method : we first solve the interpolation problem for @xmath3 and then iteratively refine this solution for increasing @xmath0 and @xmath1 . in each step of our algorithm",
    ", we obtain a valid solution to the interpolation problem for these intermediate parameters .",
    "the method builds upon that of beelen ",
    "brander  @xcite , but a new analysis of the computational engine ",
    "alekhnovich s module minimisation algorithm  reveals that each iteration runs faster than otherwise expected .",
    "# 1#1 the method therefore allows a fast _ multi - trial _ list decoder when our aim is just to find the list of codewords with minimal distance to the received word . at any time during the refinement process , we will have an interpolation polynomial for intermediate parameters @xmath4 , @xmath5 yielding an intermediate decoding radius @xmath6 , where @xmath7 is the minimum distance .",
    "if we perform the root - finding step of the gs algorithm on this , all codewords with distance at most @xmath8 from the received are returned ; if there are any such words , we break computation and return those ; otherwise we continue the refinement .",
    "we can choose any number of these trials , e.g. for each possible intermediate decoding radius between @xmath9 and the target @xmath2 .",
    "since the root - finding step of gs is less complex than the interpolation step , this multi - trial decoder will have the same asymptotic worst - case complexity as the usual gs using the beelen  brander interpolation  @xcite .",
    "however , its average - case complexity is better since due to the properties of the underlying channel it is more probable to have a small number of errors rather than a big one .",
    "this contribution is structured as follows . in the next section",
    "we give necessary preliminaries and state the gs interpolation problem for decoding grs codes . in section  [ sec_modulemini ]",
    "we give a definition and properties of minimal matrices .",
    "we describe and reanalyse the conceptually simple mulders  storjohann algorithm  @xcite for bringing matrices to this form .",
    "we also give a fresh look at alekhnovich s algorithm  @xcite simply as a divide-&-conquer variant of mulders  storjohann , and our new analysis can carry over .",
    "our new iterative procedure is explained in detail in section  [ sec_iterative ] and the incorporation of the re - encoding transformation  @xcite is described in section  [ sec_re - encoding ] . in section  [ sec_simulation ]",
    "we present simulation results .",
    "parts of these results were presented at wcc 2013 @xcite ; compared to that article , this version contains the incorporation of the re - encoding scheme , a full example of the algorithm , simulation results , as well as a more detailed description of the module minimisation procedure .",
    "let @xmath10 be the finite field of order @xmath11 and let @xmath12}}}$ ] be the polynomial ring over @xmath10 with indeterminate @xmath13 .",
    "let @xmath14}}}$ ] denote the polynomial ring in the variables @xmath13 and @xmath15 and let @xmath16 be the @xmath17-weighted degree of @xmath18 .",
    "a vector of length @xmath19 is denoted by @xmath20 .",
    "if @xmath21 is a vector over @xmath12}}}$ ] , let @xmath22 .",
    "we introduce the leading position as @xmath23 and the leading term @xmath24 is the term at this position .",
    "an @xmath25 matrix is denoted by @xmath26 .",
    "the rows of such a matrix are denoted by bold lower - case letters , e.g. @xmath27 .",
    "furthermore , let the degree of such a polynomial matrix be @xmath28 .",
    "modules are denoted by capital letters such as @xmath29 .",
    "let @xmath30 be @xmath19 nonzero distinct elements of @xmath10 with @xmath31 and let @xmath32 be @xmath19 ( not necessarily distinct ) nonzero elements of @xmath10 .",
    "a grs code @xmath33 of length @xmath19 and dimension @xmath34 over @xmath10 is given by @xmath35}}},\\ , \\deg f(x ) < k \\big\\}.\\end{aligned}\\ ] ] grs codes are maximum distance separable ( mds ) codes , i.e. , their minimum hamming distance is @xmath36 .",
    "we shortly explain the interpolation problem of gs  @xcite for list decoding grs codes up to the johnson radius  @xcite in the following .",
    "[ thm_gsproblem ] let @xmath37 and @xmath38 be the corresponding information polynomial as defined in  .",
    "let @xmath39 be a received word where @xmath40 .",
    "let @xmath41 denote @xmath42 .",
    "let @xmath43}}}$ ] be a nonzero polynomial that passes through the @xmath19 points @xmath44 @xmath45 with multiplicity @xmath46 , has @xmath15-degree at most @xmath1 , and @xmath47",
    ". then @xmath48 .",
    "one can easily show that a polynomial @xmath49 that fulfills the above conditions can be constructed whenever @xmath50 , where @xmath51 is the difference between the maximal number of coefficients of @xmath49 , and the number of homogeneous linear equations on @xmath49 specified by the interpolation constraint .",
    "this determines the maximal number of correctable errors , and one can show that satisfactory @xmath0 and @xmath1 can always be chosen whenever @xmath52 .",
    "[ def_permiss ] an integer triple @xmath53 is _ permissible _ if @xmath50 .",
    "we define also the decoding radius - function @xmath54 as the greatest integer such that @xmath55 is permissible .",
    "it is well - known that @xmath50 for @xmath56 implies @xmath57 , which is half the minimum distance .",
    "therefore , it never makes sense to consider @xmath56 , and in the remainder we will always assume @xmath58 .",
    "furthermore , we will also assume @xmath59 since this e.g.  holds for any @xmath2 for the closed - form expressions in @xcite .",
    "let us illustrate the above .",
    "the following will be a running example throughout the article .",
    "[ ex_rs164param ] a @xmath60 code over @xmath61 can uniquely correct @xmath62 errors ; unique decoding corresponds to @xmath63 and one can confirm that @xmath64 . to attain a decoding radius @xmath65 , one can choose @xmath66 and @xmath67 in order to obtain a permissible triple . also @xmath68 is permissible , though less interesting since it does not give improved decoding radius .",
    "however , one finds @xmath69 and @xmath70 are permissible . since @xmath71 , there are no permissible triples for greater decoding radii .",
    "let @xmath72}}}$ ] denote the space of all bivariate polynomials passing through the points @xmath73 with multiplicity @xmath0 and @xmath15-degree at most @xmath1 .",
    "we are searching for an element of @xmath74 with low @xmath75-weighted degree .    following the ideas of lee and osullivan  @xcite",
    ", we can first remark that @xmath74 is an @xmath12}}}$]-module .",
    "second , we can give an explicit basis for @xmath74 .",
    "define first two polynomials @xmath76 as well as @xmath77 in @xmath12}}}$ ] as the unique lagrange interpolation polynomial going through the points @xmath78 for @xmath79 .",
    "denote by @xmath80}}(x)$ ] the @xmath81-coefficient of @xmath49 when @xmath82 is regarded over @xmath12}}}[y]$ ] .",
    "[ lem_qdivg ] let @xmath83}}(x)y^i \\in {    \\ifthenelse{\\equal{{{s,\\ell}}}{\\empty } }      { \\ensuremath{m } }      { \\ensuremath{m_{{{s,\\ell } } } } } } $ ] with @xmath84 .",
    "then @xmath85}}(x)$ ] .",
    "@xmath49 interpolates the @xmath19 points @xmath86 with multiplicity @xmath0 , so for any @xmath87 , @xmath88}}(x+\\alpha_j)(y+r_j^{\\prime})^j$ ] has no monomials of total degree less than @xmath0 .",
    "multiplying out the @xmath89-terms , @xmath80}}(x+\\alpha_j)y^t$ ] is the only term with @xmath15-degree @xmath90 .",
    "therefore @xmath80 } } ( x+\\alpha_j)$ ] can have no monomials of degree less than @xmath91 , which implies @xmath92}}(x)$ ] .",
    "as this holds for any @xmath87 , we proved the lemma .",
    "[ thm_mbasis ] the module @xmath74 is generated as an @xmath12}}}$]-module by the @xmath93 polynomials @xmath94}}}$ ] given by @xmath95    it is easy to see that each @xmath96 since both @xmath97 and @xmath98 go through the @xmath19 points @xmath78 with multiplicity one , and that @xmath97 and @xmath98 divide @xmath99 with total power @xmath0 for each @xmath90 .    to see that any element of @xmath74 can be written as an @xmath12}}}$]-combination of the @xmath100 ,",
    "let @xmath49 be some element of @xmath74 .",
    "then the polynomial @xmath101 } } ( x ) p{^{(\\ell)}}(x , y ) $ ] has @xmath15-degree at most @xmath102 .",
    "since both @xmath49 and @xmath103 are in @xmath74 , so must @xmath104 be in @xmath74 .",
    "since @xmath100 has @xmath15-degree @xmath90 and @xmath105}}(x ) = 1 $ ] for @xmath106 , we can continue reducing this way until we reach a @xmath107 with @xmath15-degree at most @xmath108 . from then on ,",
    "we have @xmath105}}(x ) = g(x)^{s - t}$ ] , but by lemma  [ lem_qdivg ] , we must also have @xmath109}}(x)$ ] .",
    "therefore , we can reduce by @xmath110 .",
    "this can be continued with the remaining @xmath100 , eventually reducing the remainder to 0 .",
    "we can represent the basis of @xmath74 by the @xmath111 matrix @xmath112}(x)\\|_{i=0,j=0}^{\\ell , \\ell}$ ] over @xmath12}}}$ ] ; more explicitly we have : @xmath113 any @xmath12}}}$]-linear combination of rows of @xmath114 thus corresponds to an element in @xmath74 by its @xmath90th position being the @xmath12}}}$]-coefficient to @xmath81 .",
    "all other bases of @xmath74 can similarly be represented by matrices , and these will be unimodular equivalent to @xmath114 , i.e. , they can be obtained by multiplying @xmath114 on the left with an invertible matrix over @xmath12}}}$ ] .    extending the work of lee and osullivan  @xcite , beelen and brander  @xcite gave a fast algorithm for computing a satisfactory @xmath49 :",
    "start with @xmath114 as a basis of @xmath74 and compute a different , `` minimal '' basis of @xmath74 where an element of minimal @xmath115-weighted degree appears directly .    in the following section , we give further details on how to compute such a basis , but our ultimate aim in section [ sec_iterative ] is different",
    ": we will use a minimal basis of @xmath74 to efficiently compute one for @xmath116 for @xmath117 and @xmath118 .",
    "this will allow an iterative refinement for increasing @xmath0 and @xmath1 , where after each step we have such a minimal basis for @xmath74 .",
    "we then exploit this added flexibility in our multi - trial algorithm .",
    "given a basis of @xmath74 , e.g. @xmath114 , the module minimisation here refers to the process of obtaining a new basis , which is the smallest among all bases of @xmath74 in a precise sense .",
    "we will define this and connect various known properties of such matrices .",
    "we will then show how to perform this minimisation using the mulders  storjohann algorithm  @xcite , reanalyse its performance and connect it to alekhnovich s algorithm  @xcite .",
    "[ def_weakpopov ] a matrix @xmath119 over @xmath12}}}$ ] is in _ weak popov form _ if the leading position of each row is different .",
    "we are essentially interested in short vectors in a module , and the following lemma shows that the simple concept of weak popov form will provide this .",
    "it is a paraphrasing of ( * ? ? ?",
    "* proposition 2.3 ) and we omit the proof .    [ lem_minrow ] if a square matrix @xmath119 over @xmath12}}}$ ] is in weak popov form , then one of its rows has minimal degree of all vectors in the row space of @xmath119 .",
    "denote now by @xmath120 the diagonal @xmath111 matrix over @xmath12}}}$ ] : @xmath121 since we seek a polynomial of minimal @xmath75-weighted degree , we also need the following corollary .",
    "[ cor_weightsol ] let @xmath122}}}^{(\\ell+1 ) \\times ( \\ell+1)}$ ] be the matrix representation of a basis of @xmath123 .",
    "if @xmath124 is in weak popov form , then one of the rows of @xmath125 corresponds to a polynomial in @xmath123 with minimal @xmath75-weighted degree .",
    "let @xmath126 .",
    "now , @xmath127 will correspond to the basis of an @xmath12}}}$]-module @xmath128 isomorphic to @xmath123 , where an element @xmath129 is mapped to @xmath130 . by lemma [ lem_minrow ]",
    ", the row of minimal degree in @xmath127 corresponds to an element of @xmath128 with minimal @xmath13-degree .",
    "therefore , the same row of @xmath125 corresponds to an element of @xmath123 with minimal @xmath75-weighted degree .",
    "if for some matrix @xmath122}}}^{(\\ell+1 ) \\times ( \\ell+1)}$ ] , @xmath124 is in weak popov form , we say that @xmath125 is in _ weighted weak popov form_.    we introduce what will turn out to be a measure of how far a matrix is from being in weak popov form .",
    "[ def_orthogonality ] the _ orthogonality defect _ of a square matrix @xmath119 over @xmath12}}}$ ] is defined as @xmath131    [ lem_popovreduces ] if a square matrix @xmath119 over @xmath12}}}$ ] is in weak popov form , then @xmath132 .",
    "let @xmath133 be the rows of @xmath134}}}^{m \\times m}$ ] and @xmath135 . in the alternating sum - expression for @xmath136 , the term @xmath137 will occur since the leading positions of @xmath138 are all different .",
    "thus @xmath139 unless leading term cancellation occurs in the determinant expression",
    ". however , no other term in the determinant has this degree : regard some ( unsigned ) term in @xmath136 , say @xmath140 for some permutation @xmath141 . if not @xmath142 for all @xmath87 ( as defined in  ) , then there must be an @xmath87 such that @xmath143 since @xmath144 is the same for all @xmath141 .",
    "thus , @xmath145 . as none of the other terms in @xmath90 can have greater degree than their corresponding row s leading term , we get @xmath146 .",
    "thus , @xmath132 .",
    "the weak popov form is highly related to minimal grbner bases of the row space module , using a term order where vectors in @xmath12}}}^m$ ] are ordered according to their degree ; indeed the rows of a matrix in weak popov form _ is _ such a grbner basis ( though the opposite is not always true ) .",
    "similarly , the weighted weak popov form has a corresponding weighted term order . in this light ,",
    "lemma [ lem_minrow ] is simply the familiar assertion that a grbner basis over such a term order must contain a `` minimal '' element of the module .",
    "see e.g.  ( * ? ? ?",
    "* chapter 2 ) for more details on this correspondence .",
    "the language of grbner bases was employed in the related works of @xcite .",
    "[ def_rowred ] applying a _ row reduction _ on a matrix over @xmath12}}}$ ] means to find two different rows @xmath147 , @xmath148 and such that @xmath149 , and then replacing @xmath150 with @xmath151 where @xmath152 and @xmath153 are chosen such that the leading term of the polynomial @xmath154 is cancelled .",
    "algorithm  [ alg_mulders ] is due to mulders and storjohann  @xcite .",
    "our proof of it is similar , though we have related the termination condition to the orthogonality defect , restricting it to only square matrices .",
    "apply row reductions as in definition  [ def_rowred ] on the rows of @xmath119 until no longer possible this matrix .",
    "introduce for the proof a _ value function _",
    "@xmath155}}}^m \\rightarrow { \\mathbb n}_0 $ ] as @xmath156 .",
    "first let us consider the following lemma .",
    "[ lem_rowreddec ] if we replace @xmath157 with @xmath158 in a row reduction , then @xmath159 .",
    "we can not have @xmath160 since all terms of both @xmath157 and @xmath161 have degree at most @xmath162 .",
    "if @xmath163 we are done since @xmath164 , so assume @xmath165 . let @xmath166 . by the definition of the leading position , all terms in both @xmath157 and @xmath161 to the right of @xmath167 must have degree less than @xmath162 , and so also all terms in @xmath158 to the right of @xmath167 satisfies this .",
    "the row reduction ensures that @xmath168 , so it must then be the case that @xmath169 .",
    "[ lem_mulders ] algorithm  [ alg_mulders ] is correct . for a matrix @xmath134}}}^{m \\times m}$ ] , it performs fewer than @xmath170 row reductions and has asymptotic complexity @xmath171 where @xmath172 is the maximal degree of any term in @xmath119 .",
    "if algorithm  [ alg_mulders ] terminates , the output matrix must be unimodular equivalent to the input since it is reached by a finite number of row - operations .",
    "since we can apply row reductions on a matrix if and only if it is not in weak popov form , algorithm  [ alg_mulders ] must bring @xmath119 to this form .",
    "termination follows directly from lemma [ lem_rowreddec ] since the value of a row decreases each time a row reduction is performed . to be more precise",
    ", we furthermore see that the maximal number of row reductions performed on @xmath119 before reaching a matrix @xmath173 in weak popov form is at most @xmath174 . expanding this ,",
    "we get @xmath175 where we use @xmath176 and that the @xmath177 are all different .    for the asymptotic complexity ,",
    "note that during the algorithm , no polynomial in the matrix will have larger degree than @xmath172 .",
    "the estimate is reached simply by remarking that one row reduction consists of @xmath178 times scaling and adding two such polynomials .",
    "let us consider an example to illustrate all the above .",
    "[ ex_weakpopov ] let us consider the following matrices @xmath179}}^{3 \\times 3}$ ] .",
    "from matrix @xmath180 to @xmath181 we performed one row - operation :    [ cols= \" < , < , < , < , < , < , < \" , ]     where the indexes @xmath182 on the arrow indicated the concerned rows .",
    "the orthogonality defect is decreasing ; @xmath183 , and @xmath184 is in weak popov form .    in @xcite",
    ", alekhnovich gave a divide-&-conquer variant of the mulders  storjohann - algorithm : the same row reductions are performed but structured in a binary computation tree , where work is done on matrices of progressively smaller degree towards the bottom , ending with essentially @xmath10-matrices at the leaves .",
    "alekhnovich does not seem to have been aware of the work of mulders and storjohann , and basically reinvented their algorithm before giving his divide-&-conquer variant .    for square matrices",
    ", we can improve upon the complexity analysis that alekhnovich gave by using the concept of orthogonality defect ; this will be crucial for our aims .",
    "[ lem_alekcompl ] alekhnovich s algorithm inputs a matrix @xmath134}}}^{m\\times m}$ ] and outputs a unimodular equivalent matrix which is in weak popov form .",
    "let @xmath172 be the greatest degree of a term in @xmath119 .",
    "if @xmath185 then the algorithm has asymptotic complexity : @xmath186    the description of the algorithm as well as the proof of its correctness can be found in  @xcite .",
    "we only prove the claim on the complexity .",
    "the method @xmath187 of @xcite computes a unimodular matrix @xmath173 such that @xmath188 or @xmath189 is in weak popov form . according to ( * ? ? ?",
    "* lemma 2.10 ) , the asymptotic complexity of this computation is in @xmath190 .",
    "due to lemma  [ lem_popovreduces ] , we can set @xmath191 to be sure that @xmath189 is in weak popov form .",
    "what remains is just to compute the product @xmath189 . due to",
    "* lemma 2.8 ) , each entry in @xmath173 can be represented as @xmath192 for some @xmath193 and @xmath194}}}$ ] of degree at most @xmath195 . if therefore @xmath185 , the complexity of performing the matrix multiplication using the naive algorithm is @xmath196 .",
    "the beelen  brander interpolation algorithm  @xcite works simply by computing @xmath114 and then applying alekhnovich s algorithm on @xmath197 ; a minimal @xmath75-weighted polynomial in @xmath74 can then be directly retrieved as a row in the reduced matrix , after removing @xmath198 .",
    "the algorithm s complexity therefore follows from the above theorem once we have computed the orthogonality defect of @xmath197 :    [ lem_odofa ] @xmath199 .",
    "we will compute first @xmath200 and then @xmath201 .    for the former , we have @xmath202 , where the @xmath203 are as in theorem [ thm_mbasis ] .",
    "note that whenever @xmath204 is not a codeword then @xmath205 .",
    "therefore , @xmath206 and so @xmath207 this gives @xmath208 since @xmath114 is lower triangular , the determinant is : @xmath209 the orthogonality defect can then be simplified to @xmath210    in the earlier work of lee and osullivan @xcite , they construct basically the same matrix as @xmath114 , but apply their own grbner basis algorithm on this . they also does not seem to have been aware of the work of mulders and storjohann  @xcite , but their algorithm is basically a variant of algorithm [ alg_mulders ] which keeps the rows in a specific order .",
    "using the results of the preceding section , we show in section  [ ssec_steptypeone ] that , given a basis of @xmath74 as a matrix @xmath211 in weighted weak popov form , then we can write down a matrix @xmath212 which is a basis of @xmath213 and where @xmath214 is much lower than @xmath215 .",
    "this means that reducing @xmath212 to weighted weak popov form using alekhnovich s algorithm  @xcite is faster than reducing @xmath216 .",
    "we call this kind of refinement a `` micro - step of type i '' . in section  [ ssec_steptypetwo ]",
    ", we similarly give a way to refine a basis of @xmath74 to one of @xmath217 , and we call this a `` micro - step of type ii '' .    if we first compute a basis in weighted weak popov form of @xmath218 using @xmath219 , we can perform a sequence of micro - steps of type i and ii to compute a basis in weighted weak popov form of @xmath123 for any @xmath220 with @xmath221 . after any step ,",
    "having some intermediate @xmath222 , @xmath223 , we will thus have a basis of @xmath224 in weighted weak popov form . by corollary  [ cor_weightsol ]",
    ", we could extract from @xmath225 a @xmath226 with minimal @xmath75-weighted degree . since it must satisfy the interpolation conditions of theorem  [ thm_gsproblem ] , and",
    "since the weighted degree is minimal among such polynomials , it must also satisfy the degree constraints for @xmath227 . by that theorem any codeword with distance at most @xmath228 from @xmath204 would then be represented by a root of @xmath229 .",
    "algorithm  [ alg_multitrial ] is a generalisation and formalisation of this method . for a given @xmath230 code ,",
    "one chooses ultimate parameters @xmath231 being a permissible triple with @xmath58 .",
    "one also chooses a list of micro - steps and chooses after which micro - steps to attempt decoding ; these choices are represented by a list @xmath232 consisting of @xmath233 , @xmath234 and @xmath235 elements .",
    "this list must contain exactly @xmath236 @xmath233-elements and @xmath108 @xmath234-elements , as it begins by computing a basis for @xmath218 and will end with a basis for @xmath74 .",
    "whenever there is a @xmath235 element in the list , the algorithm performs root - finding and finds all codewords with distance at most @xmath227 from @xmath204 ; if this list is non - empty , the computation breaks and the list is returned .",
    "the algorithm calls sub - functions which we explain informally : @xmath237 and @xmath238 will take @xmath239 and a basis in weighted weak popov form for @xmath224 and return a basis in weighted weak popov form for @xmath240 respectively @xmath241 ; more detailed descriptions for these are given in subsections  [ ssec_steptypeone ] and [ ssec_steptypetwo ] .",
    "@xmath242 finds a polynomial of minimal @xmath75-weighted degree in @xmath224 given a basis in weighted weak popov form ( corollary  [ cor_weightsol ] ) . finally , @xmath243 returns all @xmath15-roots of @xmath49 of degree less than @xmath34 and whose corresponding codeword has distance at most @xmath2 from the received word @xmath204 .",
    "the correctness of algorithm  [ alg_multitrial ] for any possible choice of @xmath244 and @xmath245 follows from our discussion as well as sections [ ssec_steptypeone ] and [ ssec_steptypetwo ] . before going to these two technical sections",
    ", we will discuss what possibilities the micro - steps of type i and ii offer , and in particular , do not , with regards to decoding radii .    in the following two subsections",
    "we explain the details of the micro - steps . in section [ ssec_complanalysis ]",
    ", we discuss the complexity of the method and how the choice of @xmath245 influences this .",
    "the choice of @xmath245 provides much flexibility to the algorithm .",
    "the two extreme cases are perhaps the most generally interesting : the one without any @xmath235 elements except at the end , i.e. ,  usual list - decoding ; and the one with a @xmath235 element each time the intermediate decoding radius @xmath246 has increased , i.e. ,  a variant of maximum - likelihood decoding up to a certain radius .    in section [ ssec_complanalysis ] , we discuss complexity concerns with regards to the chosen path ; it turns out that the price of either type of micro - step is very comparable , and the worst - case complexity is completely unchanged by the choice of @xmath245 .",
    "however , in the case where we have multiple @xmath235 elements we want to minimise the _ average _ computation cost : considering that few errors occur much more frequently than many , we should therefore seek to reach each intermediate decoding radius after as few micro - steps as possible .",
    "since we do not have a refinement which increases only @xmath0 , we are inherently limited in the possible paths we can choose , so the question arises if this limitation conflicts with our interest as given above .",
    "first  and most important  for any given final decoding radius @xmath2 , we mentioned in section [ ssec_ipdecoding ] that the corresponding parameters satisfy @xmath247 , and so we can reach these values using only micro - steps of type i and ii .    for the intermediate steps ,",
    "the strongest condition we would like to have satisfied is the following : let @xmath248 be the series of intermediate decoding radii where we would like to attempt decoding .",
    "let @xmath249 be chosen such that @xmath250 is permissible and either @xmath251 or @xmath252 is minimal possible for the given @xmath253 .",
    "can then the sequence of parameters @xmath249 be reached by a series of micro - steps of type i and ii ?",
    "unfortunately , we do not have a formal proof of this statement .",
    "however , we have verified for a large number of parameters that it is true .",
    "the function is based on the following lemma :    [ lem_microstepone ] if @xmath255}}}$ ] is a basis of @xmath74 , then the following is a basis of @xmath256 : @xmath257    in the basis of @xmath256 given in theorem  [ thm_mbasis ] , the first @xmath93 generators are the generators of @xmath74 .",
    "thus , all of these can be described by any basis of @xmath256 .",
    "the last remaining generator is exactly @xmath258 .    in particular , the above lemma",
    "holds for a basis of @xmath256 in weighted weak popov form , represented by a matrix @xmath211 .",
    "the following matrix thus represents a basis of @xmath256 : @xmath259        \\makebox[4cm][c]{$ {    \\ifthenelse{\\equal{{{s,\\ell}}}{\\empty } }      { \\ensuremath{\\mathcal{b } } }      { \\ensuremath{\\mathcal{b}_{{{s,\\ell } } } } } } $ }        &         \\makebox[1.5em][r]{$\\vec 0^t$ }        \\\\[-0.2 cm ] \\      \\end{array }      \\\\ \\hline \\\\[-.3 cm ]      \\begin{matrix }        0 & \\ldots & 0 & ( -r)^s & \\binom s 1 ( -r)^{s-1 } & \\ldots & 1      \\end{matrix }    \\end{array}\\right).\\ ] ]    [ lem_orthoi ] @xmath260 .",
    "we calculate the two quantities @xmath261 and @xmath262 .",
    "it is easy to see that @xmath263 for the row - degree , this is clearly @xmath264 plus the row - degree of the last row . if and only if the received word is not a codeword then @xmath205 , so the leading term of the last row must be @xmath265",
    "thus , we get @xmath266 where the last step follows from lemma  [ lem_popovreduces ] as @xmath267 is in weak popov form .",
    "[ cor_complmsi ] the complexity of @xmath268 is @xmath269",
    ".    follows by lemma  [ lem_alekcompl ] . since @xmath270",
    "we can leave out the @xmath0 in @xmath271-terms .",
    "the function is based on the following lemma :    [ lem_microsteptwo ] if @xmath255}}}$ ] is a basis of @xmath74 , then the following is a basis of @xmath273 : @xmath274    denote by @xmath275 the basis of @xmath74 as given in theorem  [ thm_mbasis ] , and by @xmath276 the basis of @xmath273 . then observe that for @xmath277 , we have @xmath278 . since the @xmath279 form a basis of @xmath74 ,",
    "each @xmath280 is expressible as an @xmath12}}}$]-combination of these , and thus for @xmath281 , @xmath282 is expressible as an @xmath12}}}$]-combination of the @xmath283 .",
    "remaining is then only @xmath284 .    as before , we can use the above with the basis @xmath211 of @xmath74 in weighted weak popov form , found in the previous iteration of our algorithm . recall that multiplying by @xmath15 translates in the matrix representation to shifting one column to the right ,",
    "so the following matrix represents a basis of @xmath273 : @xmath285          \\vec 0^t & \\makebox[1cm][c]{$\\vec 0 $ }            \\\\[0.1 cm ]      \\end{array}\\right )      +      \\left(\\begin{array}{@{}c|c@ { } }          0 &   \\vec 0 \\\\\\hline\\\\[-.2 cm ]          \\vec 0^t & \\makebox[1cm][c]{$ {    \\ifthenelse{\\equal{{{s,\\ell}}}{\\empty } }      { \\ensuremath{\\mathcal{b } } }      { \\ensuremath{\\mathcal{b}_{{{s,\\ell } } } } } } $ }            \\\\[0.1 cm ]      \\end{array}\\right )      - r\\cdot      \\left(\\begin{array}{@{}c|c@ { } }          \\vec 0 & 0 \\\\\\hline\\\\[-.2 cm ]          \\makebox[1cm][c]{$ {    \\ifthenelse{\\equal{{{s,\\ell}}}{\\empty } }      { \\ensuremath{\\mathcal{b } } }      { \\ensuremath{\\mathcal{b}_{{{s,\\ell } } } } } } $ } & \\vec 0^t            \\\\[0.1 cm ]      \\end{array}\\right).\\ ] ]    [ lem : cortho ] @xmath286 .",
    "we compute @xmath287 and @xmath288 .",
    "for the former , obviously the first row has degree @xmath289 .",
    "let @xmath290 denote the @xmath87th row of @xmath211 and @xmath291 denote the @xmath87th row of @xmath267 .",
    "the @xmath292th row of @xmath293 has the form @xmath294 {    \\ifthenelse{\\equal{\\ell+1}{\\empty } }      { \\ensuremath{\\mathcal{w } } }      { \\ensuremath{\\mathcal{w}_{\\ell+1 } } } }        = ( 0 \\mid \\vec{b}'_i)x^{k-1 } - r(\\vec{b}'_i \\mid 0).\\ ] ] if and only if the received word is not a codeword , then @xmath205 . in this case , the leading term of @xmath295 must have greater degree than any term in @xmath296 .",
    "thus the degree of the above row is @xmath297 . summing up we get @xmath298 for the determinant , observe that @xmath299 where @xmath300 and @xmath301 is all but the zeroth column of @xmath211 .",
    "this means @xmath302 can be obtained by starting from @xmath211 and iteratively adding the @xmath303th column of @xmath211 scaled by @xmath77 to the @xmath304th column , with @xmath304 starting from @xmath305 up to @xmath102 .",
    "since each of these will add a scaled version of an existing column in the matrix , this does not change the determinant .",
    "thus , @xmath306 .",
    "but then @xmath307 and so @xmath308 by lemma  [ lem_popovreduces ] since @xmath267 is in weak popov form . thus we get @xmath309 the lemma follows from the difference of the two calculated quantities .",
    "[ cor_complmsii ] the complexity of @xmath310 is @xmath311 .",
    "[ ex_algo164 ] we consider again the @xmath312 code over @xmath313 of example  [ ex_rs164param ] , and specify now that @xmath314 and @xmath315 for @xmath316 .",
    "the aimed decoding radius is @xmath317 and therefore the permissible triple @xmath318 should be reached iteratively by algorithm  [ alg_multitrial ] . to maximise the decoding radius during the procedure",
    ", we could choose the following sequence of intermediate parameters @xmath319 : @xmath320 we perform root - finding only if the decoding radius is increased .",
    "therefore , the list @xmath232 of operations becomes : @xmath321 with the information polynomial @xmath322 , we obtain with   the following codeword : @xmath323 consider that @xmath324 was received , i.e. ,  that the error @xmath325 of weight 8 occurred .",
    "we will depict the degrees of the polynomials in the matrices in the iterative decoding process .",
    "these are for this particular received word , but for a generic received word , the degrees are the same .",
    "for some @xmath194}}}$ ] , we will write @xmath326 for @xmath327 if @xmath328 , and @xmath329 if @xmath330 , and we extend @xmath331 element - wise to matrices . to begin with",
    ", we have : @xmath332 according to   and  .",
    "we then apply alekhnovich s algorithm on @xmath333 to obtain @xmath334 which is in weak popov form . from this",
    "we can easily scale down the columns again to obtain @xmath335 .",
    "it took 11 row reductions , while @xmath336 was the upper bound , according to lemma [ lem_mulders ] .",
    "we obtain @xmath337 the first element in @xmath245 is @xmath235 , so we pick the second row of @xmath335 , since it has weighted degree less than @xmath338 , and we interpret it as a polynomial : @xmath339 root - finding of @xmath340 yields no results .",
    "the next element in @xmath245 is @xmath233 , so we move to the next intermediate parameters @xmath341 . from  ,",
    "we get @xmath342[c]{$ {    \\ifthenelse{\\equal{1,1}{\\empty } }      { \\ensuremath{\\mathcal{b } } }      { \\ensuremath{\\mathcal{b}_{1,1 } } } } $ }          &           \\begin{matrix } 0 \\\\ 0 \\end{matrix }        \\end{array }        \\\\",
    "\\hline \\\\[-.4 cm ]        \\begin{matrix }          0 & -r & 1        \\end{matrix }      \\end{array}\\right )    \\qquad    \\textnormal{\\it and so }    \\qquad        {    \\ifthenelse{\\equal{1,2}{\\empty } }      { \\ensuremath{\\mathcal{c } } }      { \\ensuremath{\\mathcal{c}_{1,2 } } } } { ^\\mathrm i}\\preceq \\left(\\begin{matrix }        10 & 6 & \\bot \\\\        9 & 6 & \\bot \\\\",
    "\\bot & 15 & 0      \\end{matrix}\\right ) \\quad \\quad        {    \\ifthenelse{\\equal{1,2}{\\empty } }      { \\ensuremath{\\mathcal{c } } }      { \\ensuremath{\\mathcal{c}_{1,2 } } } } { ^\\mathrm i } {    \\ifthenelse{\\equal{2}{\\empty } }      { \\ensuremath{\\mathcal{w } } }      { \\ensuremath{\\mathcal{w}_{2 } } } } \\preceq \\left(\\begin{matrix }        10 & 9 & \\bot \\\\        9 & 9 & \\bot \\\\",
    "\\bot & 18 & 6      \\end{matrix}\\right).\\end{aligned}\\ ] ] running alekhnovich s algorithm on @xmath343 , we obtain : @xmath344 since @xmath345 , lemma  [ lem_mulders ] gives @xmath346 as the upper bound on the number of row reductions , but it was done with only 24 .    in the next iteration",
    "we again meet a @xmath235 . for our polynomial",
    "we can pick either the second or third row of @xmath347 since both have weighted degree @xmath348 ; we choose the second and obtain : @xmath349 again root - finding yields no results .",
    "the next element in @xmath245 is @xmath234 and we get intermediate parameters @xmath350 .",
    "we construct @xmath351 according to which gives : @xmath352 we needed 90 row reductions to reduce @xmath353 to weak popov form , while the upper bound is 160 , since we calculated @xmath354 . after row - reduction , we obtain @xmath355 : @xmath356 the next element in @xmath245 is @xmath234 , so we construct @xmath357 according to and get : @xmath358 we needed 86 row reductions for the module minimisation , while the upper bound was 145 since we calculated @xmath359 .    the last iteration is again a @xmath235 , and we can use either of the two last rows of @xmath357 since they have weighted degree @xmath360 . using the last ,",
    "the obtained polynomial is : @xmath361 indeed , @xmath362 and root - finding retrieves @xmath38 for us .",
    "as the example shows , performing module minimisation on a matrix can be informally seen to `` balance '' the row - degrees such that they all become roughly the same size .",
    "the complexity of this reduction depends on the number of row reductions , which in turn depends on the `` unbalancedness '' of the initial matrix .",
    "the matrices @xmath363 and @xmath357 are more balanced in row - degrees than using @xmath364 and @xmath365 directly .      using the estimates of the two preceding subsections",
    ", we can make a rather precise worst - case asymptotic complexity analysis of algorithm  [ alg_multitrial ] .",
    "the average running time will depend on the exact choice of @xmath245 but we will see that the worst - case complexity will not .",
    "first , it is necessary to know the complexity of performing a root - finding attempt .",
    "[ lem_rootcompl ] given a polynomial @xmath366}}}[y]$ ] of @xmath15-degree at most @xmath1 and @xmath13-degree at most @xmath172 , there exists an algorithm to find all @xmath12}}}$]-roots of complexity @xmath367 , assuming @xmath368 .",
    "we employ the roth ",
    "ruckenstein  @xcite root - finding algorithm together with the divide - and - conquer speed - up by alekhnovich  @xcite .",
    "the complexity analysis in  @xcite needs to be slightly improved to yield the above , but see @xcite for easy amendments .",
    "[ thm_complalg ] for a given @xmath230 code , as well as a given list of steps @xmath245 for algorithm  [ alg_multitrial ] with ultimate parameters @xmath231 , the algorithm has worst - case complexity @xmath369 , assuming @xmath370 .",
    "the worst - case complexity corresponds to the case that we do not break early but run through the entire list @xmath245 .",
    "precomputing @xmath219 using lagrangian interpolation can be performed in @xmath371 , see e.g. @xcite , and reducing to @xmath335 is in the same complexity by lemma  [ lem_alekcompl ] .",
    "now , @xmath245 must contain exactly @xmath236 @xmath233-elements and @xmath108 @xmath234-elements .",
    "the complexities given in corollaries  [ cor_complmsi ] and [ cor_complmsii ] for some intermediate @xmath239 can be relaxed to @xmath0 and @xmath1 . performing @xmath372 micro - steps of type i and @xmath373 of type ii",
    "is therefore in @xmath374 .",
    "it only remains to count the root - finding steps .",
    "obviously , it never makes sense to have two @xmath235 after each other in @xmath245 , so after removing such possible duplicates , there can be at most @xmath1 elements @xmath235 . when we perform root - finding for intermediate @xmath239 , we do so on a polynomial in @xmath224 of minimal weighted degree , and by the definition of @xmath224 as well as theorem [ thm_gsproblem ]",
    ", this weighted degree will be less than @xmath375 .",
    "thus we can apply lemma [ lem_rootcompl ] with @xmath376 .",
    "the worst - case complexity of our algorithm is equal to the average - case ( and worst - case ) complexity of the beelen ",
    "brander  @xcite list decoder .",
    "however , theorem  [ thm_complalg ] shows that we can choose as many intermediate decoding attempts as we would like without changing the worst - case complexity .",
    "one could therefore choose to perform a decoding attempt just after computing @xmath335 as well as every time the decoding radius has increased .",
    "the result would be a decoding algorithm finding all _ closest _ codewords within some ultimate radius @xmath2 .",
    "if one is working in a decoding model where such a list suffices , our algorithm will thus have much better average - case complexity since fewer errors occur more frequently than many .",
    "we now discuss how to adjust algorithm  [ alg_multitrial ] to incorporate the re - encoding transformation proposed in  @xcite .",
    "the basic observation is that we can correct @xmath204 if we can correct @xmath377 for any @xmath378 .",
    "if we chose @xmath379 such that @xmath377 for some reason is easier to handle in our decoder , we can save computational work .",
    "as in the original articles , we will choose @xmath379 such that it coincides with @xmath204 in the first @xmath34 positions ; this can be done since it is just finding a lagrange polynomial of degree @xmath380 that goes through these points .",
    "the re - encoded received word will therefore have 0 on the first @xmath34 positions .    for ease of notation ,",
    "assume that @xmath204 is this re - encoded received word with first @xmath34 positions zero , and we can reuse all the objects introduced in the preceding sections .",
    "define @xmath381 obviously @xmath382 so introduce @xmath383 .",
    "however , since @xmath384 for @xmath385 then also @xmath386 ; this will be the observation which will save us computations .",
    "introduce therefore @xmath387 .",
    "regard now @xmath114 of ; it is clear that @xmath388 divides every entry in the @xmath90th column for @xmath389 .",
    "this implies that the image of the following bijective map is indeed @xmath14}}}$ ] : @xmath390}}}\\nonumber \\\\ q(x , y ) \\quad & \\mapsto \\quad l(x)^{-s } q(x , l(x)y).\\end{aligned}\\ ] ] extend @xmath391 element - wise to sets of @xmath74 elements , and note that @xmath391 is therefore an isomorphism between @xmath74 and @xmath392 .",
    "the idea is now that the elements in @xmath392 have lower @xmath13-degree than those in @xmath74 , and we can therefore expect that working with bases of @xmath392 is computationally cheaper than with bases of @xmath74 .",
    "since we are searching a minimal @xmath75-weighted polynomial in @xmath74 , we need to be sure that this property corresponds to something sensible in @xmath392 .",
    "the following lemma and its corollary provides this :    [ lem_wdeg_reenc ] for any @xmath49 in @xmath74 @xmath393    we have @xmath394 } } ( x ) + i(k-1 ) \\big\\}$ ] so we obtain : @xmath395 } } ( x ) - s \\deg l(x ) + i \\deg l(x ) - i \\big\\ } \\\\   & = \\max_i \\big\\ { \\deg { q_{[i ] } } ( x ) + i(k-1 ) \\big\\}- sk.\\end{aligned}\\ ] ]    [ cor_wdeg_reenc ] @xmath49 has minimal @xmath75-weighted degree in @xmath74 if and only if @xmath396 has minimal @xmath397-weighted degree in @xmath392 .",
    "let us now describe the basis of @xmath392 corresponding to the one in  :    [ thm_mbasis_reenc ] the module @xmath392 is generated as an @xmath12}}}$]-module by the @xmath93 polynomials @xmath398}}}$ ] given by @xmath399    follows directly from theorem  [ thm_mbasis ] and the mapping as defined  .",
    "we can represent the basis of @xmath392 by the @xmath111 matrix over @xmath12}}}$ ] ( compare to  ): @xmath400 we need an analogue of corollary [ cor_weightsol ] for the @xmath397-weighted degree , i.e. ,  we should find a diagonal matrix to multiply on @xmath401 such that when module minimising the result , we will have a row corresponding to a polynomial in @xmath392 with minimal @xmath397-weighted degree .",
    "we can not use @xmath402 , since multiplying with negative powers of @xmath13 might cause us to leave the polynomial ring ; however , we can to this add the same power to all the diagonal elements such that they become non - negative : @xmath403 therefore , for a vector @xmath404 in the row - space of @xmath405 corresponds a polynomial @xmath406 , and we will have the identity @xmath407 . obviously then , a minimal degree vector in @xmath405 is a minimal @xmath397-weighted polynomial in @xmath392 .    finally , we need adjusted variants of the micro - steps i and ii .",
    "the necessary adaptions of algorithm  [ alg_multitrial ] are summarised in the following lemma :    [ lem_microstepsreenc ] let @xmath408}}}^{(\\ell+1 ) \\times ( \\ell+1)}$ ] be the matrix representation of a basis of @xmath409 .",
    "if @xmath410 is in weak popov form , then one of the rows of @xmath411 corresponds to a polynomial in @xmath409 with minimal @xmath397-weighted degree .",
    "modified micro - steps of type i and ii can be obtained from the following .",
    "let @xmath412}}}$ ] be a basis of @xmath74 .",
    "then the following is a basis of @xmath256 : @xmath413 similarly , the following is a basis of @xmath273 : @xmath414    the first part follows from the previous discussion and analogously to corollary [ cor_weightsol ] .",
    "the recursive bases of and follow completely analogous to lemmas [ lem_microstepone ] and [ lem_microsteptwo ] , given theorem [ thm_mbasis_reenc ] .    in the case of the @xmath312 code over @xmath313 with final decoding radius @xmath415 as shown in example  [ ex_algo164 ] , then @xmath416 and the initial matrix satisfies : @xmath417    brander briefly described in his thesis @xcite how to incorporate re - encoding into the beelen  brander interpolation algorithm by dividing out common powers of @xmath418 in the first @xmath0 columns of @xmath114 . here",
    "we construct instead @xmath419 where powers of @xmath418 are also multiplied on the latter @xmath236 columns , since we need the simple recursions of bases of @xmath392 which enables the micro - steps .",
    "however , before applying module minimisation , we could divide away this common factor from those columns and just adjust the weights accordingly ( i.e. , multiplying @xmath420 on the @xmath90th element of @xmath421 ) ; this will further reduce the complexity of the minimisation step .",
    "the micro - steps would then need to be modified ; the simplest way to repair this is to multiply back the powers of @xmath418 before applying a micro - step , and then remove them again afterwards . with a bit more care",
    "one can easily do this cheaper , though the details become technical .    in asymptotic terms",
    ", the computational complexity of the iterative interpolation method stays exactly the same with re - encoding as without it , since @xmath422 under the usual assumption of @xmath423 being constant .",
    "the same is true for the original re - encoding scheme of ktter ",
    "vardy  @xcite .",
    "however , most of the polynomials that are handled in the matrix minimisation will be of much lower degree than without re - encoding ; for relatively high - rate codes this will definitely be noticeable in real computation time .    in  ( * ? ? ?",
    "* thm . 10 ) , it was shown that the root - finding procedure of roth ",
    "ruckenstein  @xcite , or its divide-&-conquer variant by alekhnovich  @xcite can be directly applied to an interpolation polynomial in @xmath409 , so we can avoid to construct and work on the larger polynomial in @xmath123 . instead of finding @xmath38 , one will find the power series expansion of @xmath424 .",
    "the fraction in reduced form can be retrieved from the power series expansion using pad approximation : e.g.  by the berlekamp  massey algorithm or by module minimising a certain @xmath425 matrix .",
    "see e.g.  ( * ? ? ?",
    "* section 2.5 ) for a general description of the latter . from the reduced fraction",
    ", @xmath38 can be obtained by re - extending the fraction .",
    "interestingly , one can easily calculate that the orthogonality defects stays the same , i.e. ,  @xmath426 , where @xmath427 is the matrix corresponding to a micro - step of type i in the re - encoded version .",
    "the analogue equality holds for type ii .",
    "this means that , roughly , the number of row operations carried out by the module minimisation algorithm is unchanged .",
    "the proposed algorithm has been implemented in sage , version 5.13  @xcite , using the mulders  storjohann algorithm for module minimisation , and the roth ",
    "ruckenstein root - finding procedure @xcite . for comparison",
    ", we also implemented construction of @xmath114 , leading immediately to the lee ",
    "osullivan algorithm  @xcite .",
    "figure  [ fig_sim164 ] shows the total number of finite field multiplications performed for complete runs of the decoding algorithms , using the @xmath312 code over @xmath313 as considered in example  [ ex_rs164param ] . for each algorithm , and for each number of errors @xmath428 , 1000 random codewords were generated and subjected to a random error pattern of weight precisely @xmath429 .",
    "the solid line gives the number of operations of the proposed multi - trial algorithm for any number of errors .",
    "for the lee ",
    "osullivan decoder , one chooses the maximal decoding radius initially , and the figure depicts choosing both @xmath430 as dashed lines .",
    "the minimum - distance choice of @xmath431 coincides completely with the multi - trial algorithm since @xmath114 for @xmath432 and so is not shown .",
    "the figure demonstrate that the multi - trial algorithm provides a huge gain whenever there are fewer errors than lee ",
    "osullivan s target , while not having a disadvantage in the matching case .",
    "the right - hand graph shows the complexity when using the re - encoding transformation , and we can observe a speedup of between 30% and 50% .    the number of operations spent in constructing the matrices and for the root - finding step are relatively small compared to the number of operations needed for the row - reduction ( for the @xmath312 code , less than 5% ) .",
    "unfortunately , the performance of our operation - counting implementation for the decoding algorithm does not allow to run simulations with much larger codes . without counting , however",
    ", we can use optimised data structures in sage  @xcite which run much faster .",
    "we have observed for the short @xmath312 code that the system - clock time spent with these data structures correspond very well to the operations counted .",
    "extrapolating , we can , albeit with larger uncertainty , make comparisons on larger codes using system - clock measurements .",
    "doing so , we have observed behaviour resembling that of the @xmath312 code . for example , decoding a @xmath433 code up to 23 errors ( requiring @xmath434 ) showed the multi - trial being slightly faster than lee  osullivan in the worst case , while of course still giving a large improvement for fewer errors . when decoding a @xmath435 code up to 74 errors ( requiring @xmath436 ) , lee ",
    "osullivan  @xcite was slightly faster by about 15% in the worst case .",
    "it should also be noted that root - finding took up significantly more time for these larger codes , around 15% of the total time for lee  osullivan and 20% for the multi - trial .    as with any simulation",
    ", there are caveats to these results . in truth , only the wall - clock time spent by highly optimised implementations of various approaches can be fairly compared .",
    "also , we did not test the asymptotically fast alekhnovich s method for module minimisation .",
    "investigations performed by brander in magma indicated that the gain in using this algorithm in place of mulders ",
    "storjohann might only be present once the code length exceeds about 4000 @xcite .    the implementation of the algorithm , including the simulation setup , is freely available via http://jsrn.dk/code-for-articles .",
    "an iterative interpolation procedure for list decoding grs codes based on alekhnovich s module minimisation was proposed and shown to have the same worst - case complexity as beelen and brander s @xcite .",
    "we showed how the target module used in beelen  brander can be minimised in a progressive manner , starting with a small module and systematically enlarging it , performing module minimisation in each step .",
    "the procedure takes advantage of a new , slightly more fine - grained complexity analysis of alekhnovich s algorithm , which implies that each of the module refinement steps runs fast .",
    "the main advantage of the algorithm is its granularity which makes it possible to perform fast multi - trial decoding : we attempt decoding for progressively larger decoding radii , and therefore find the list of codewords closest to the received .",
    "this is done without a penalty in the worst case but with an obvious benefit in the average case .",
    "the beelen  brander approach for interpolation is not the asymptotically fastest : using the module minimisation algorithm by giorgi  _ et al . _",
    "@xcite , one gains a factor @xmath1 . by a completely different approach , chowdhury et al .",
    "@xcite further beat this by a factor @xmath437 , achieving @xmath438 .",
    "it is unclear for which sizes of the parameters these asymptotic improvements have concrete benefits , and whether a multi - trial approach can be developed for them .",
    "chowdhury , m.f.i .",
    ", jeannerod , c.p . ,",
    "neiger , v. , schost , e. , villard , g. : faster algorithms for multivariate interpolation with multiplicities and simultaneous polynomial approximations ."
  ],
  "abstract_text": [
    "<S> an iterated refinement procedure for the guruswami  </S>",
    "<S> sudan list decoding algorithm for generalised reed  </S>",
    "<S> solomon codes based on alekhnovich s module minimisation is proposed . </S>",
    "<S> the method is parametrisable and allows variants of the usual list decoding approach . in particular , finding the list of _ closest _ codewords within an intermediate radius can be performed with improved average - case complexity while retaining the worst - case complexity .    </S>",
    "<S> we provide a detailed description of the module minimisation , reanalysing the mulders  storjohann algorithm and drawing new connections to both alekhnovich s algorithm and lee  </S>",
    "<S> osullivan s . </S>",
    "<S> furthermore , we show how to incorporate the re - encoding technique of ktter and vardy into our iterative algorithm . </S>"
  ]
}