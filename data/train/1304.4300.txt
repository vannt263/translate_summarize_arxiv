{
  "article_text": [
    "in statistics , researchers are often interested in how a variable response @xmath2 may be concomitant with an explanatory variable @xmath1 . studying the relationship between @xmath2 given a new value of the explanatory variable @xmath1 is an important task in non - parametric statistics .",
    "for instance , regression function provides the mean value that takes @xmath2 given @xmath3 .",
    "some other characteristics of the conditional distribution , such as conditional median , conditional quantiles , conditional mode , maybe quite interesting in practice .",
    "furthermore , it is widely acknowledged that quantiles are more robust to outliers than regression function .",
    "conditional quantiles are widely studied when the explanatory variable @xmath1 lies within a _ finite _ dimensional space .",
    "there are many references on this topic ( see @xcite ) .    during the last decade , thanks to progress of computing tools , there is an increasing number of examples coming from different fields of applied sciences for which the _ data are curves_. for instance , some random variables can be observed at several different times .",
    "this kind of variables , known as _ functional variables _ ( of time for instance ) in the literature , allows us to consider the data as curves .",
    "the books by @xcite and @xcite ) propose an interesting description of the available procedures dealing with functional observations whereas @xcite present a completely non - parametric point of view .",
    "these functional approaches mainly rely on generalizing multivariate statistical procedures in functional spaces and have been proved to be useful in various areas such as chemiomertrics ( @xcite and @xcite ) , economy ( @xcite ) , climatology ( @xcite ) , biology ( @xcite ) , geoscience ( @xcite ) or hydrology ( @xcite ) .",
    "these functional approaches are generally more appropriate than longitudinal data models or time series analysis when there are , for each curve , many measurement points ( @xcite ) .    in the _ univariate _ case ( i.e. @xmath4 and @xmath1 is a functional covariable ) , among the lot of papers dealing with the nonparametric estimation of conditional quantiles ,",
    "one may cite papers by @xcite which introduced univariate quantile regression with functional covariate and @xcite estimates conditional quantile by inverting the conditional cumulative distribution function .",
    "@xcite establish the almost complete convergence and the asymptotic normality in the setting of independent and identically distributed ( i.i.d . )",
    "data as well as under @xmath5-mixing condition .",
    "@xcite stated the convergence in @xmath6-norm . in the same framework",
    ", @xcite estimated the conditional quantile nonparametrically , by adapting the @xmath7-norm method .",
    "recently @xcite have used the same approach proposed by @xcite to predict future stratospheric ozone concentrations and to estimate return levels of extreme values of tropospheric ozone .    over the past decades , researchers have shown increasing interest in studying _ multivariate _",
    "location parameters such as multivariate quantiles in order to find suitable analogs of univariate quantiles that used to construct descriptive statistics and robust estimations of location . in contrast to the univariate case , the order of observations @xmath8 laying in @xmath9 ( with @xmath10 ) is not total . consequently , several quantiles - type multivariate definitions have been formulated .",
    "the pioneer paper of @xcite considered a multivariate extension of the median defined as an @xmath11-estimator ( also called spatial or @xmath0-median ) .",
    "the reader is referred to @xcite for historical reviews and comparisons .",
    "@xcite and @xcite defined the geometric quantile as an extension of multivariate quantiles based on norm minimization and on the geometry of multivariate data clouds .",
    "in contrast , relative little attention has been paid to the multivariate conditional quantiles ( @xmath12 and @xmath13 ) and their large sample properties .",
    "@xcite defined the conditional @xmath0-median and provided its uniform consistency on a compact subsets of @xmath14 .",
    "recently , @xcite have introduced a multivariate conditional quantile notion , which extends the definition of unconditional quantiles by @xcite , to predict tails from bivariate time series .",
    "@xcite have generalized the notion of geometric quantiles , defined by @xcite , to the conditional setting .",
    "they have established a bahadur - type linear representation of the @xmath15-th geometric conditional estimator as well as the asymptotic normality in the i.i.d . case .",
    "the purpose of this paper is to add some new results to the non - parametric estimation of the conditional @xmath0-median when @xmath2 is a random vector with values in @xmath16 while the covariable @xmath1 take its values in some _ infinite _ dimensional space @xmath17 . as far as we know",
    ", this problem has not been studied in literature before and the results obtained here are believed to be novel . moreover , our motivation for studying this type of robust estimator is due to its interest in some practical applications .",
    "note also that , it would be better to predict all components of a vector of random variables simultaneously in order to take into account the correlation between them rather than predicting each of component separately .",
    "for instance , in edf ( french electricity company ) the estimation of the minimum and the maximum of the electricity power demand represents an important research issue for both economic and security reasons . because an underestimation of the maximum consumed quantity of electricity ( especially in winter ) may require importation of electricity from other european countries with high prices , while an over estimation of this maximum quantitiy may induce a negative effect on the electricity distribution network .",
    "the estimation of the minimum power demand is also an important task for the same reasons .",
    "notice that the minimum and the maximum of the electricity power demand are strongly correlated .",
    "thus , it is more appropriate to predict these variables simultaneously rather than predicting each of them separately . on the other hand , weather variables , like temperature curves , can play a key role to explain the minimum and the maximum of power demand . due to its robust properties",
    ", the conditional @xmath0-median may be used to solve this prediction problem using a temperature curve as covariate .",
    "the paper is organized as follows .",
    "section 2 outlines notations and the form of the new estimator .",
    "section 3 presents the main results concerning the asymptotic behavior of the estimator , including consistency , asymptotic normality and evaluation of the bias term .",
    "an estimation of the conditional confidence region is then deduced .",
    "section 4 is devoted to a simulation study giving an example of the estimated confidence region .",
    "an application to chemiometrical real data is proposed in section 5 , where we compare three approaches : @xmath18-median regression , the vector of marginal conditional median and non - functional multivariate median to predict a random vector .",
    "the proofs of the results in section 3 are relegated to the appendix .",
    "let us consider a random pair @xmath19 where @xmath1 and @xmath2 are two random variables defined on the same probability space @xmath20 . we suppose that @xmath2 is @xmath21-valued and @xmath1 is a _ functional random variable ( f.r.v . )",
    "_ takes its values in some infinite dimensional vector space @xmath22 equipped with a semi - metric @xmath23 .",
    "let @xmath24 be a fixed point in @xmath17 and @xmath25 be the conditional cumulative distribution function ( cond .",
    "c.d.f ) of @xmath2 given @xmath3 .",
    "the conditional @xmath0-median , @xmath26 , of @xmath2 given @xmath3 , is defined as the miminizer over @xmath15 of @xmath27    = \\arg\\min_{u \\in { \\ensuremath{\\mathbb{r}}}^d } \\displaystyle\\int ( \\|y - u\\| - \\|y\\| ) \\ ; df(y \\;| \\ ;   x ) .",
    "\\end{aligned}\\ ] ]    the general definition ( [ qdef ] ) does not assume the existence of the first order moment of @xmath28 . however , when @xmath2 has a finite expectation , @xmath29 becomes a minimizer over @xmath15 of @xmath30.$ ] notice that the existence and the uniqueness of @xmath29 is guaranteed , for @xmath31 provided that the conditional distribution function @xmath32 is not supported on a single straight line ( see theorem 2.17 of @xcite .",
    "hence , uniqueness holds whenever @xmath2 has an absolutely continuous conditional distribution on @xmath16 with @xmath33    without loss of generality , we suppose in the sequel , that @xmath34 .",
    "therefore for any fixed @xmath35 , the conditional @xmath0-median @xmath29 may be viewed as a minimizer of the function @xmath36 defined , for all @xmath37 , by @xmath38,\\ ] ]    which is assumed to be differentiable and uniformly bounded with respect to @xmath15 .",
    "we introduce now some further definitions and notations .",
    "denote by @xmath39 the transpose of the matrix @xmath40 , and let @xmath41 be the norm trace . notice that for any @xmath42",
    ", the function @xmath43 is differentiable everywhere except at @xmath44 , one may then define ( by continuity extension ) its derivative as @xmath45 when @xmath46 and @xmath47 whenever @xmath48 . for any @xmath49 ,",
    "define @xmath50 where @xmath51 is the @xmath52 identity matrix .",
    "we denote by @xmath53 the gradian of the function @xmath54 and by @xmath55 its hessian functional matrix ( with respect to @xmath15 ) . according to @xcite ,",
    "it is easy to see that @xmath56 \\quad \\mbox{and}\\end{aligned}\\ ] ] @xmath57.\\end{aligned}\\ ] ] notice that @xmath55 is bounded whenever @xmath58 < \\infty.$ ] according to ( [ qdef ] ) and ( [ gradian ] ) , the conditional @xmath0-median may be then implicitly defined as a zero with respect to @xmath15 of the following equation : @xmath59    to build our estimator , let @xmath60 be the statistical sample of pairs which are independent and identically distributed as @xmath19 .",
    "let us denote by @xmath61 the so - called nadaraya - watson weights , where @xmath62 , with @xmath63 a kernel function , @xmath64 is a sequence of positive real numbers which decreases to zero as @xmath65 tends to infinity .",
    "a kernel estimator of the function @xmath54 is given by @xmath66    when the denominator is not equal to 0 , where @xmath67 a kernel estimate of @xmath53 may be defined by @xmath68    according to the statement ( [ g ] ) , the estimator of the conditional @xmath0-median , @xmath69 , may be viewed as a minimizer over @xmath15 of the function @xmath70 , that is @xmath71 or as a zero with respect to @xmath15 of the equation @xmath72    similar to the fact @xmath73 in @xcite and remark @xmath74 in @xcite , the existence of the estimator @xmath69 is guaranteed by the fact that the function @xmath75 explodes to infinity as @xmath76 . on the other hand , since this function is continuous with respect to @xmath15 , then @xmath69 must be a minimizer over @xmath15 of @xmath77 .",
    "next comes the question of uniqueness , since @xmath16 is equipped with the euclidean norm that is a strictly convex banach space for @xmath78 , it follows from theorem @xmath79 of @xcite that unless all the data points @xmath80 fall on a straight line in @xmath16 , @xmath77 must be a strictly convex function of @xmath15 .",
    "this guarantees the uniqueness of the minimizer @xmath69 in @xmath16 , for any @xmath81 .",
    "let @xmath24 be a given point in @xmath82 and @xmath83 a neighbourhood of @xmath24 . denote by @xmath84 the ball of center @xmath24 and radius @xmath85 , namely @xmath86",
    ". for @xmath87 , denote by @xmath88 $ ] , for @xmath89 .",
    "our hypotheses are gathered here for easy reference .",
    "* @xmath63 is a nonnegative bounded kernel of class @xmath90 over its support @xmath91 $ ] such that @xmath92 the derivative @xmath93 exists on @xmath91 $ ] and satisfy the condition @xmath94 for all @xmath95 $ ] and @xmath96 for @xmath97 * for @xmath98 , there exists a deterministic nonnegative bounded function @xmath99 and a nonnegative real function @xmath100 tending to zero , as its argument tends to 0 , such that * * @xmath101 as @xmath102 * * there exists a nondecreasing bounded function @xmath103 such that , uniformly in @xmath104 $ ] , + @xmath105 as @xmath106 and , for @xmath107 , @xmath108 * * * for @xmath98 , @xmath109 uniformly in @xmath15 , for some @xmath110 and a constant @xmath111 , whenever @xmath112 , * * for @xmath113 , the hessian matrix @xmath114 is continuous in @xmath83 : + @xmath115 . * * for some integer @xmath116 , @xmath117 and @xmath118 is continuous in @xmath83 . * * for some integer @xmath119 and any @xmath120 , @xmath121 , @xmath122 , @xmath123 < \\infty$ ] and @xmath124 * @xmath125 for each @xmath126 , @xmath127 and @xmath128 is continuous in @xmath129 uniformly in @xmath15 : @xmath130 + @xmath131 for some @xmath132 and @xmath133 , the real function @xmath134 $ ] ( @xmath135 and @xmath136 ) is continuous in @xmath137    * for any @xmath138 , @xmath139 = : \\psi(v))$ ] , where @xmath140 and @xmath141 is a differentiable function such that @xmath142 .",
    "notice that , since @xmath143 is a semi - metric , we have @xmath144 $ ] . as a consequence",
    ", it follows from the definition of @xmath145 that @xmath146 .",
    "* comments on the hypotheses *    the above conditions are fairly mild . condition ( h1 ) is standard in the context of functional non - parametric estimation .",
    "contrarily to the real and vectorial cases ( for which we generally suppose the strict positivity of the explanatory variable s density , the concentration hypothesis ( h2)-(i ) acts directly on the distribution of the functional random variable rather than on its density function . the idea of writing the small ball probability @xmath147 as a product of two independent functions @xmath148 and @xmath149 was adopted by @xcite who reformulated the @xcite one . this assumption has been used by many authors where @xmath148 is interpreted as a probability density , while @xmath149 may be interpreted as a volume parameter . in the case of finite - dimensional space , that is @xmath150 ,",
    "it can be seen that @xmath151 , where @xmath152 is the volume of the unit ball in @xmath21 .",
    "furthermore , in _ infinite _ dimensions , there exist many examples fulfilling the decomposition mentioned in assumption ( h2)-(i ) ( see @xcite and @xcite for more details ) .",
    "the function @xmath153 , introduced in assumption ( h2)-(ii ) , plays a determinant role in asymptotic properties , in particular when we give the order of the conditional bias and the asymptotic variance term .",
    "conditions ( h3 ) and ( h4 ) are mild smoothness assumptions on the functionals @xmath154 and @xmath155 and continuity assumptions on certain second - order moments .",
    "a similar assumption to ( h3)-(iii ) has been supposed in @xcite ( see condition 6 in their paper ) .",
    "condition ( h5 ) is used to evaluate the bias term .",
    "the following result states the almost surely ( a.s . ) convergence ( with rate ) of the functional estimator @xmath70 .",
    "this result plays an instumental role to prove the almost sure consistency of @xmath69 for a fixed @xmath156 .",
    "[ resg ] assumes that conditions ( h1)-(h2 ) , ( h3)(i ) and ( h4)(i ) hold true and @xmath157 @xmath158 then , we have @xmath159    notice that the condition ( [ cond3.thm1 ] ) is standard when we deal with the uniform consistency of the density function on the whole space ( see , for instance , corollary 2.2 of @xcite ) .    here then , we give our first result of the conditional @xmath0-median estimator @xmath69 .",
    "[ thm2 ] assume ( h1)-(h2 ) , ( h3)(i ) and ( h4)(i ) and condition ( [ condthm1 ] ) hold true .",
    "then , we have @xmath160      to state the asymptotic normality of our estimator , some notations are required .",
    "let us first denote by @xmath161 set @xmath162 and @xmath163 .",
    "we have by the definition of @xmath164 that @xmath165 obviously the equation ( [ equivo ] ) is satisfied when the numerator is null .",
    "then , we can say also that @xmath166 thereafter , one may write @xmath167    for each @xmath168 , taylor s expansion applied to the real - valued function @xmath169 implies the existence of @xmath170 such that    @xmath171    define the @xmath52 matrix @xmath172 by setting    @xmath173    where , for all @xmath174 and @xmath175 , @xmath176 \\times \\frac{\\delta_i(x)}{n\\;\\mathbb{e}(\\delta_1(x ) ) } \\\\ & = & \\displaystyle\\frac{\\sum_{i=1}^n \\mathcal{m}_{k , j}(y_i , u ) \\delta_i(x)}{n\\;\\mathbb{e}(\\delta_1(x))},\\end{aligned}\\ ] ] with @xmath177 if @xmath178 and zero otherwise and @xmath179/\\|y_i - u\\|$ ] is the @xmath180-th element of the matrix @xmath181 .",
    "equation ( [ decomposition ] ) can be then rewritten as @xmath182    equation ( [ decomposition1 ] ) plays a key role to give the conditional bias and the asymptotic distribution of the conditional @xmath0-median estimator @xmath164 .",
    "[ variance ] under assumptions ( h1)-(h3 ) and ( h4)(i ) and condition ( [ condthm1])(i ) , we have @xmath183    using remark 4 and lemma @xmath184 of @xcite , we know that both the matrix @xmath185 itself and its inverse matrix exist whenever @xmath78 .",
    "it follows from this result combined with ( [ decomposition1 ] ) that , for n large enough , @xmath186^{-1}\\nabla_u \\widetilde g_n^x(\\mu)+ o_{\\mathbb{p}}(1)$ ]",
    ". one may then write , for large @xmath65 that @xmath187^{-1 }   \\left[- \\left(\\nabla_u \\widetilde g_n^x(\\mu ) -   \\mathbb{e}\\left[\\nabla_u \\widetilde g_n^x(\\mu)\\right ] \\right ) -   \\widetilde{\\mathcal{b}}_n(x)\\right ] + o_{\\mathbb{p}}(1),\\end{aligned}\\ ] ] where @xmath188.$ ]    the following proposition gives the order of the conditional bias term @xmath189^{-1}\\widetilde{\\mathcal{b}}_n(x)$ ] .",
    "[ b ] under assumptions @xmath190 , @xmath191 and @xmath192 , and the fact that + @xmath193 and @xmath194 , we have :    @xmath195^{-1 } \\nabla\\psi(0)}{m_1}\\left [ \\int_0 ^ 1 ( sk(s ) ) ' \\tau_0(s ) ds - k(1 ) + o_{a.s.}(1 ) \\right],\\ ] ] where for @xmath196 , @xmath197    the theorem below gives the asymptotic normality of our estimator .",
    "[ clt ] suppose assumptions ( h1)-(h5 ) and condition ( [ condthm1])(i ) hold .    if @xmath198 for some @xmath132 , then :    * @xmath199 + where @xmath200^{-1 } \\sigma^x(\\mu )   \\left [ h^x(\\mu)\\right]^{-1}\\ ] ] and @xmath201 * if in addition we impose the following stronger conditions on the bandwidth @xmath202 : @xmath203 one gets @xmath204    .",
    "( i ) notice that the constants @xmath205 and @xmath206 are strictly positive . indeed making use of the condition @xmath190 and the fact that the function @xmath207 is nondecreasing",
    ", it suffices to perform a simple integration by parts . also , from the point that the conditional distribution @xmath2 given @xmath3 is absolutely continuous , we know that @xmath208 is definite positive matrix .",
    "\\(ii ) whenever @xmath209 , @xmath210 , and if the probability density of the random variable @xmath1 , say @xmath211 , is of class @xmath90 , then @xmath212 , where @xmath213 is the volume of the unit ball of @xmath14 . in such case , the asymptotic variance expression takes the form    @xmath214^{-1 } \\sigma^x(\\mu )   \\left [ h^x(\\mu)\\right]^{-1}.\\ ] ] in such case the central limit theorem has the form given in the above theorem with convergence rate @xmath215 . notice",
    "that in the finite dimensional case , the function @xmath149 could decrease to zero as @xmath216 exponentially fast and the convergence rate becomes effectively @xmath217 .",
    "this fact may be used to solve the problem of the curse of dimensionality ( see @xcite , for details ) . as an example , consider in an infinite dimensional space setting , the random process defined by @xmath218 where @xmath219 is a @xmath220-random variable independent of the winer process @xmath221 .",
    "it is well - known ( see @xcite ) that the distribution @xmath222 of @xmath1 is absolutely continuous with respect to the wiener measure @xmath222 , which admets a radon - nikodym density @xmath223 . in this case ,",
    "hypothesis ( h2)(i ) is satisfied with @xmath224 ( see @xcite for details ) .",
    "the convergence rate in theorem [ clt ] being @xmath225 ( with @xmath226 ) by taking @xmath227 .",
    "observe now in theorem [ clt ] that the limiting variance contains the unknown function @xmath148 , therefore the normalization depends on the function @xmath100 which is not identifiable explicitly . to make this result operational in practice",
    ", we have to estimate the quantities @xmath228 , @xmath229 and @xmath230    for this purpose , we estimate the conditional variance matrix @xmath208 of @xmath231 by    @xmath232    and the matrix @xmath185 by @xmath233    making use of the decomposition of @xmath234 in @xmath235 , one may estimate @xmath236 by    @xmath237 subsequently , for a given kernel @xmath63 , the quantities @xmath205 and @xmath206 are estimated by @xmath238 and @xmath239 respectively replacing @xmath103 by @xmath240 in their respective expressions .",
    "corollary [ tclp ] below , which is a slight modification of theorem [ clt ] , allows to obtain usefull form of our results in practice .",
    "[ tclp ] assume that conditions of theorem [ clt ] hold true , @xmath93 and @xmath241 are integrable functions . if in addition we suppose that    @xmath242 and @xmath243 , as @xmath244 , + where @xmath245 is specified in the condition @xmath246 , then , for any @xmath175 such that @xmath193 , we have @xmath247^{-1/2 }   h^x_n(\\mu_n ) \\ ;",
    "\\left(\\mu_n(x ) - \\mu(x ) \\right ) \\stackrel{\\mathcal{d}}{\\longrightarrow } \\mathcal{n}(0,i_d).\\ ] ]      from corollary [ tclp ] , we can easily see that    @xmath248^{-1 } \\left(\\mu_n(x ) - \\mu(x ) \\right ) \\stackrel{\\mathcal{d}}{\\longrightarrow } \\chi_d^2,\\ ] ]    where @xmath249^{-1 } = \\frac{m_{1,n}^2 n f_{x , n}(h)}{m_{2,n}}\\;h_n^x(\\mu_n ) \\left[\\sigma_n^x(\\mu_n ) \\right]^{-1 } h_n^x(\\mu_n).\\ ] ] then , the asymptotic @xmath250 @xmath251 conditional confidence region for @xmath29 is given by @xmath252^{-1 } \\left(\\mu_n(x ) - \\mu(x ) \\right ) \\leq \\chi_d^2(\\alpha),\\end{aligned}\\ ] ]    where @xmath253 denotes the @xmath254-th percentile of a chi - squared distribution with @xmath255 degrees of freedom .",
    "this section is divided in two parts , in the first one we are interesting in the estimation of conditional confidence ellipsoid of the multivariate @xmath18-median regression .",
    "the second part is devoted to an application to chemiometrical real data and it consists in predicting a three - dimensional vector .",
    "let us consider a bi - dimensional vector @xmath256 and @xmath257 is a brownian motion trajectories defined on @xmath91 $ ] .",
    "the eigenfunctions of the covariance operator of @xmath1 are known to be ( see @xcite ) , for @xmath258 @xmath259.\\end{aligned}\\ ] ] let @xmath260}$ ] ( resp .",
    "@xmath261}$ ] ) be the first ( resp . the second ) eigenfunction corresponding to the first ( resp .",
    "second ) greater eigenvalue of the covariance operator of @xmath1 .",
    "it is well known that @xmath262 and @xmath263 are orthogonal by construction , i.e. @xmath264    we modelize then the dependence between @xmath265 and @xmath1 by the following model :    * @xmath266 * @xmath267    where @xmath268 is a standard normal random variable .    .",
    "the left box contains the covariates @xmath269 and in the right one we present their associated vectors @xmath270 .",
    ", width=642,height=245 ]    we have simulated @xmath271 independent realizations @xmath272 , @xmath273 to deal with the brownian random functions @xmath274 , their sample were discretized by 100 points equispaced in @xmath91 $ ] . in figure",
    "[ example ] , we plot a 200 simulated couples @xmath275 as described above .",
    "the left box contains the covariates @xmath269 and in the right one we present the associated vectors @xmath276 .",
    "we aim to assess , for a fixed curve @xmath3 , the performance of the asymptotic conditional confidence ellipsoid given by ( [ ellipse ] ) in finite sample . for",
    "that we have first to estimate @xmath29 .",
    "three parameters should be fixed in this step : the kernel @xmath63 , the bandwidth @xmath85 and the semimetric @xmath143 which measure the similarity between curves .",
    "* choice of the kernel * : there are many possible density kernel functions .",
    "specialists in non - parametric estimation agree that the exact form of the kernel function does not greatly affect the final estimate with regard to the choice of the bandwidth . in this section ,",
    "the so - called gaussian kernel will be used , which is defined by @xmath277 , for @xmath278 .    * choice of the bandwidth @xmath279 * : the bandwidth determines the smoothness of the estimator .",
    "the problem of the choice of the bandwidth has been widely studies in non - parametric literature .",
    "recently @xcite have proposed a data - driven criterion for choosing this smoothing parameter .",
    "the proposed criterion can be formulated in terms of a functional version of cross - validation ideas .",
    "@xcite treated the same problem in the context of time series prediction . in the following , the bandwidth @xmath279 is selected by @xmath18 cross - validation method : @xmath280    * choice of the semi - metric @xmath143 * : because of the roughness of our covariate curves we chose a semi - metric computed with the functional principal components analysis with dimension @xmath281 .",
    "when @xmath282 ( solid lines ) and @xmath283 ( dashed lines ) ; the centers of the ellipses at @xmath284 are denoted by triangle ( n=200 ) and cross ( n=700).,width=453,height=245 ]    in figure [ conf ] , we plot the @xmath285 confidence ellipses of @xmath29 when @xmath286 .",
    "we can remark from figure [ conf ] that the lengths of the major and the minor axes of the confidence ellipse decrease when the sample size @xmath65 increases .",
    "similar results were obtained for other sample sizes @xmath65 and values of the curve @xmath287      the purpose of this section is to apply our method based on multivariate @xmath0-median regression to some chemiometrical real data and to compare our results to those obtained by other definitions of conditional median studied in literature .",
    "for that , we used a sample of spectrometric data available on the web site : http://lib.stat.cmu.edu/datasets/tecator .",
    "we have a sample of @xmath288 pieces of meat and for each unit @xmath289 , we observe one spectrometric discretized curve @xmath290 which corresponds to the absorbance measured at a grid of 100 wavelengths ( i.e. @xmath291 ) .",
    "figure ( [ w ] ) plots the spectrometric curves . moreover , for each unit @xmath289 , we have at hand its moisture content @xmath292 , fat content @xmath293 and protein content @xmath294 obtained by analytical chemical processing .",
    "let us denote by @xmath295 the vector of specific chemical contents of meat .",
    "given a new spectrometric curve @xmath296 , our purpose is to predict simultaneously the corresponding vector of chemical contents @xmath297 using the multivariate @xmath0-median regression .",
    "obtaining a spectrometric curve is less expensive ( in terms of time and cost ) than analytical chemistry needed for determining the percentage of chemical contents .",
    "so , it is an important economic challenge to predict the hole vector @xmath265 from the spectrometric curve .",
    "let us consider 215 observations @xmath298 split into two samples : learning sample ( 160 observations ) and test sample ( 55 observations ) .",
    "we compare the following three methods , based on multivariate conditional median , to predict the vector of chemical contents @xmath265 of the test sample . in the following three approaches ,",
    "we choose the quadratic kernel @xmath63 defined by : @xmath299}.\\end{aligned}\\ ] ]    * * non - functional approach ( nf ) *    this method is based on the definition of conditional spatial median studied by @xcite and @xcite .",
    "this approach does not consider the covariate @xmath1 as a function but a vector of dimension 100 while the response variable @xmath265 is a vector .",
    "for each @xmath300 in the learning sample , the @xmath301 vector @xmath270 is predicted as follow : @xmath302 where @xmath303 and @xmath304 are the so - called nadaraya - watson weights . for the choice of the bandwidth @xmath279",
    ", @xcite gave the exact expression of the optimal bandwidth that minimizes the asymptotic mean square error .",
    "in this case @xmath279 is of the rate @xmath305 , where @xmath306 is a sufficiently small constant .    *",
    "* vector coordinate conditional median ( vccm ) *    this approach supposes that the covariate @xmath1 is considered as functional . for each @xmath300 in the learning sample , we predict each component of its vector response @xmath270 by the one - dimensional conditional median .",
    "then we obtain the vector of coordinate conditional medians ( vccms ) defined as @xmath307    where each component @xmath308 is the one - dimensional conditional median estimator .",
    "@xmath309 is the conditional distribution function estimator of the component @xmath310 given @xmath311 .",
    "@xcite , p. 56",
    ", have proposed a nadaraya - watson kernel estimator of the conditional distribution , @xmath312 , when covariate takes values in some infinite dimensional space .",
    "this estimator is given by @xmath313 to apply this approach , we used the ferraty and vieu s r / routine _ funopare.quantile.lcv _ to estimate @xmath314 the optimal bandwidth is chosen by the cross - validation method on the @xmath315 nearest neighbours ( see @xcite , p.102 for more details ) .    * * conditional multivariate median ( cmm ) *    the approach that we propose here supposes the covariate @xmath1 is a curve and the response @xmath2 is a vector . for each @xmath300 in the learning sample we take @xmath316 where @xmath317    to estimate the conditional multivariate median , @xmath318 , we have adapted the algorithm proposed by @xcite to the conditional case and used the function ` spatial.median ` from the r package ` icsnp ` . as in the previous approach , the optimal bandwidth is chosen by the cross - validation method on the @xmath315 nearest neighbours .",
    "+ * a common evaluation procedure * : + we have adapted , to the multivariate case , the algorithm proposed by @xcite and @xcite , p.103 ) in order to get the optimal smoothing parameter @xmath202 for each @xmath269 in the test sample .    *",
    "we compute the kernel estimator @xmath319 ( resp .",
    "@xmath320 ) , for all @xmath321 by using the training sample . * for each @xmath269 in the test sample , we set @xmath322 * for each @xmath323 , we take @xmath324    the used bandwidth for each curve @xmath325 in the test sample is the one obtained for the nearest curve in the learning sample . because the spectrometric curves presented in figure ( [ w ] ) are very smooth , we can choose as semi - metric @xmath23 the @xmath326 distance between the second derivative of the curves .",
    "this choice has been made by @xcite and @xcite for the same spectrometric curves .",
    "both ( cmm ) and ( nf ) methods take into account the covariance structure between variables of of the vector @xmath265 .",
    "in fact , the correlation coefficients between @xmath327 , @xmath328 and @xmath329 are given by @xmath330 , @xmath331 and @xmath332 . as we can see moisture , fat and protein contents in meat",
    "are strongly correlated then it will be more appropriate to predict these variables simultaneously rather than each one separately .",
    "+ to compare ( cmm ) , ( nf ) and ( vccm ) methods , we are based on the following criterias :    * the absolute error ( ae ) gives idea about the prediction of each component of @xmath265 @xmath333 * a global criteria ( @xmath334 ) gives idea about error made to predict the vector @xmath270 ( for @xmath335 ) @xmath336    where @xmath337 represents the estimator of each component of the vector @xmath265 obtained by ( vccm ) , ( nf ) or ( cmm ) method .",
    "+    .distribution of absolute errors for moisture , fat and protein and global estimation error of the vector @xmath265 . [ cols=\"<,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]     we can conclude from table [ table ] that our method is more appropriate to predict meat components than ( vccm ) . in fact ,",
    "the ( vccm ) approach predicts each component of @xmath265 separately using conditional univariate median .",
    "this method supposes independence of the components of @xmath265 and does nt take into account the correlation structure between variables .",
    "the non - functional approach gives the most important prediction errors and this is because of the dimension of the covariate ( 100 in this case ) .",
    "this problem is well - known in nonparametric estimation as curse of dimensionality .",
    "taking into account the functional aspect of the covariate seems to be necessary in such case .",
    "in this paper , we have introduced a kernel - based estimator for the @xmath0-median of a multivariate conditional distribution when covariates take values in an infinite - dimensional space .",
    "prediction using the least square estimates of regression parameters is highly sensitive to outlying points .",
    "therefore , there is no doubt that conditional @xmath0-median can be used to make prediction .",
    "we have shown that our estimator is well adapted to predict a multivariate response vector .",
    "in fact , in contrast to the vector coordinate conditional median method , the multivariate conditional @xmath0-median takes into account the inter - dependance of the coordinates of the response vector .",
    "asymptotic results , i.e. , almost sure consistency and asymptotic normality , has been given under some regularity conditions .",
    "many extensions can be given to this work .",
    "for instance , the same type of theoretical results could be obtained in a non - independence framework ( e.g. mixing dependence ) .",
    "furthermore , it is well known that quantiles are very useful tools to detect outliers and to modelize the dependence of the covariates in lower and upper tails of the response distribution . in future work",
    ", we aim to generalize our study to the multivariate quantiles regression when covariates take values in some infinite dimensional space .",
    "in order to prove our results we have to introduce some further notations .",
    "let @xmath338,\\ ] ] and define the bias of @xmath70 as @xmath339 consider now the following quantities @xmath340 and @xmath341 it is then clear that the following decomposition holds          the proof of proposition [ resg ] is split up into several lemmas , given hereafter , establishing respectively the convergence almost surely ( a.s . ) of @xmath345 to @xmath346 and that of @xmath347 , @xmath348 and @xmath349 ( with rate ) to zero .              of lemma [ lemma2 ] .",
    "let us denote by @xmath355 where @xmath356 and @xmath357 . to apply the exponential inequality given by corollary a.8(i ) of ferraty and vieu ( 2006 ) in appendix a we have first to show that for all @xmath116 there exist a positive constant @xmath358 such that @xmath359 .",
    "we have @xmath360 \\left[\\mathbb{e}(\\delta_1^\\star(x ) ) \\right]^{m - k}.\\end{aligned}\\ ] ] then using lemma @xmath361 we get @xmath362 therefore , we have @xmath363 now , for all @xmath306 , we have @xmath364 the desired result follows from borel cantelli lemma by choosing @xmath365 where @xmath366 is a large enough positive constant .          of lemma [ lemma3 ] .",
    "recall that @xmath369 conditioning by @xmath1 and using the definition of @xmath370 and condition ( h3)(i ) , one has @xmath371 the later quantity is independent of @xmath15 , this leads to @xmath372        of lemma [ lemma4 ] . for @xmath174 and @xmath377 , let @xmath378 be the sphere of radius @xmath379 centered at @xmath15",
    "let @xmath380^d$ ] , for @xmath381 , be an interval of @xmath21 .",
    "divide @xmath382 $ ] into @xmath383 subintervals each of length @xmath384 $ ] ( where @xmath385 $ ] is the integer part of @xmath386 ) . since the set @xmath387 is compact , it can be covered by @xmath388 bounded hypercubes of the form @xmath389 we have @xmath390 observe now that @xmath391 and @xmath392=b_n .",
    "\\end{aligned}\\ ] ] if we denote by @xmath393 the convergence rate , one gets by lemma [ lemma2 ] @xmath394 the choice of @xmath395 $ ] implies that @xmath396 in order to evaluate the term @xmath397 , let us denote by @xmath398 and @xmath399.\\ ] ] then , we have @xmath400    for all @xmath401 observe that @xmath402^{m - k}.\\ ] ] in order to apply an exponential type inequality , we have to give an upper bound for @xmath403 .",
    "it follows from the above inequality that @xmath404 \\left[\\mathbb{e}(\\|y_1-u_j\\|\\delta_1^\\star(x ) ) \\right]^{m - k}.\\end{aligned}\\ ] ] on the other hand , we have for any @xmath405 @xmath406 & = & \\mathbb{e}\\left[(\\delta_1^\\star(x))^k \\mathbb{e}\\left(\\|y_1-u_j\\|^k\\;|\\;x_1 \\right ) \\right]\\\\ & = & \\mathbb{e}\\left[(\\delta_1^\\star(x))^k g_k^{x_1}(u_j ) \\right].\\end{aligned}\\ ] ] using the first part of condition @xmath407 , which implies that @xmath408 is bounded uniformly for all @xmath321 , one may write    @xmath406 & \\leq & \\mathbb{e}\\left[(\\delta_1^\\star(x))^k |g^{x_1}_k(u_j ) - g^x_k(u_j)|   \\right ] + g^x_k(u_j ) \\mathbb{e}((\\delta_1^\\star(x))^k)\\\\ & \\leq & \\mathbb{e}((\\delta_1^\\star(x))^k ) \\left[\\max_{j}\\sup_{x'\\in b(x , h ) } |g^{x'}_k(u_j ) - g^x_k(u_j)| + \\max_{j } g^x_k(u_j)\\right]\\\\ & \\leq & c_0\\mathbb{e}\\left[(\\delta_1^\\star(x))^k \\right],\\end{aligned}\\ ] ]              now , applying corollary @xmath419 in ferraty & vieu ( 2006 ) @xmath388 times with @xmath420 we obtain , by choosing @xmath421 that @xmath422 \\right)\\leq 2k_n^d n^{-\\epsilon_0 ^ 2}. \\ ] ] one may choose @xmath366 large enough such that @xmath423 we conclude by borel - cantelli lemma and ( [ condition - vitesse1 ] ) that @xmath424      the last term in ( [ conuniform1 ] ) is zero for large @xmath65 , since conditioning by @xmath1 , one may write @xmath427 ( i ) whenever condition ( [ condthm1])(ii ) is satisfied . for the second term in ( [ conuniform1 ] ) , we have        to treat @xmath431 , denote by @xmath432 is nonempty if and only if there exists at least @xmath433 ( @xmath434 ) such that @xmath435 .",
    "thus @xmath436 .",
    "it follows from markov s inequality , if @xmath437 , that          @xmath443 is nonempty if and only if there exists at least @xmath433 ( @xmath434 ) such that @xmath444 .",
    "the later inequality implies that @xmath445 whenever @xmath446 .",
    "moreover , we have ( by triangle inequality ) , whenever the above conditions are hold , that @xmath447 therefore , @xmath448                we have from the definitions of @xmath29 and @xmath69 and the existence and the uniqueness of these quantities that : @xmath453 it follows then @xmath454 moreover , since for any fixed @xmath455 , the function @xmath456 is uniformly continuous and because @xmath29 is the unique minimizer of the function @xmath456 , we have then , for any @xmath457 @xmath458 which means that there exists for every @xmath459 , a number @xmath460 such that @xmath461 for every @xmath15 such that @xmath462 this implies that the event @xmath463 is included in the event @xmath464                      for the second term @xmath473 of the inequality ( [ decomph ] ) , we have by triangular inequality and the fact that @xmath474 , that @xmath475 since @xmath476\\ , \\mathcal{u}^{t}(y_{i } - \\mu)\\\\   & & + \\;\\mathcal{u}(y_{i}-\\xi_{n}(j ) ) \\left[\\,\\mathcal{u}^t(y_{i}-\\mu ) - \\mathcal{u}^t(y_{i}-\\xi_{n}(j ) ) \\,\\right ] ,   \\end{aligned}\\ ] ] and @xmath477 , we can conclude , by using theorem [ thm2 ] , that @xmath478 finally , using the same arguments as above ( concerning the proof of the term @xmath479 ) , we get @xmath480 and this is allows us to conclude that @xmath481 .",
    "now we are interesting to the second term of the right side term of ( [ inegalite ] ) .",
    "write @xmath482}_{k_{n,1 } } + \\underbrace{\\mathbb{e}[\\widetilde h_{n}^x(\\mu ) ] - h^x(\\mu)}_{k_{n,2}}.\\end{aligned}\\ ] ] we have to show that each term @xmath483 @xmath484 is asymptotically negligible .",
    "we have @xmath485 where @xmath486 is the general term of the matrix @xmath487 which may be can be written as @xmath488 .",
    "\\end{aligned}\\ ] ] using the assumption ( h3)-(iv ) , lemma [ lemma1 ] and corollary a.8 of @xcite , we can easily prove that for all @xmath489 , @xmath490 .    to handle @xmath491 , observe that @xmath492 - h^x(\\mu)\\right\\|\\\\ & \\leq&\\frac{1}{\\mathbb{e}(\\delta_1(x ) ) }   \\mathbb{e}\\left(\\|h^{x_1}(\\mu)-h^x(\\mu)\\| \\delta_1(x)\\right ) \\\\",
    "& \\leq & \\sup_{x ' \\in b(x , h ) } \\|h^{x'}(\\mu)-h^x(\\mu)\\|=o_{a.s.}(1)\\end{aligned}\\ ] ] in view of condition @xmath493 .",
    "@xmath499 then @xmath500\\right)= \\frac{1}{\\sqrt{n } } \\sum_{i=1}^n ( a_{i } - \\mathbb{e}(a_{i } ) ) : = \\frac{1}{\\sqrt{n } } \\sum_{i=1}^n \\widetilde a_{i}.\\ ] ] from the cramer - wold device , lemma [ l1 ] can be proved by finding the limit distribution of the real variables sequence @xmath501 , for all @xmath502 satisfying @xmath503 .    because the random variables @xmath504 are i.i.d . with zero mean and asymptotic variance @xmath505 the result",
    "may be obtained by applying the liapounov central theorem limit .",
    "for this propose , we have to prove the following lindeberg condition : @xmath506^{-(2+\\delta)/2 } \\sum_{i=1}^n \\mathbb{e}|\\ell^t \\widetilde a_i|^{2+\\delta } \\longrightarrow 0   \\quad \\mbox{as } \\quad n \\longrightarrow \\infty.\\ ] ] it is easy to see that : @xmath507^{-(2+\\delta)/2 } \\sum_{i=1}^n \\mathbb{e}|\\ell^t \\widetilde a_i|^{2+\\delta }   & = & n^{-\\delta/2 } \\left ( \\ell^t\\sigma^x(\\mu)\\ell\\right)^{-(2+\\delta)/2 } \\mathbb{e } |\\ell^t \\widetilde   a_1|^{2+\\delta}.   \\end{aligned}\\ ] ] moreover , using @xmath508 and jensen inequalities , we obtain @xmath509 @xmath510}_{= w_{2+\\delta}^x(\\mu ) } \\right\\}\\\\   & \\leq & c \\frac{(\\phi(h))^{(2+\\delta)/2}}{(\\mathbb{e}\\delta_1(x))^{2+\\delta } }    \\left[\\mathbb{e}(\\delta_1(x))^{2+\\delta } \\sup_{x'\\in b(x , h ) }    |w_{2+\\delta}^{x'}(\\mu ) - w_{2+\\delta}^x(\\mu)| +    w_{2+\\delta}^x(\\mu ) \\mathbb{e}(\\delta_1(x))^{2+\\delta } \\right].\\\\   \\end{aligned}\\ ] ] it follows then , by hypothesis ( h4)(ii ) and lemma [ lemma1 ] , that @xmath511 } \\left[\\phi(h ) ( m_{(2+\\delta)/2}g(x ) + o(1 ) ) \\right]\\\\ & = & \\mathcal{o}\\left((\\phi(h)^{-\\delta/2 } ) \\right).\\end{aligned}\\ ] ]                of lemma [ sigma2 ] . since the random variables @xmath517 are i.i.d . with mean zero",
    ", it follows that @xmath518 on the other hand , making use of the properties of conditional expectation one may write @xmath519 & = & \\frac{\\phi(h)}{(\\mathbb{e}\\delta_1)^2 } \\ ; \\mathbb{e}\\left[\\delta_1 \\ell^t \\mathcal{u}(y_1-\\mu)\\right]^2 = \\frac{\\phi(h)}{(\\mathbb{e}\\delta_1)^2 } \\;\\mathbb{e}\\left[\\delta^2_1    w_2^{x_1}(\\mu )   \\right]\\\\ \\ ] ] making use of the condition ( h4)(ii ) and the fact that the functions @xmath520 is bounded , we obtain @xmath521 \\\\ & = & w_2^x(\\mu)\\mathbb{e}\\left(\\delta^2_1\\right )   + o\\left ( \\mathbb{e}\\left(\\delta^2_1\\right)\\right).\\end{aligned}\\ ] ]          of proposition [ b ] . for each @xmath98 , since @xmath524 are i.i.d .",
    ", we have @xmath525 = \\frac{\\mathbb{e}\\left[\\mathcal{u}(y_1-\\mu ) \\delta_1(x ) \\right]}{\\mathbb{e}(\\delta_1(x))}\\ ] ] by conditioning with respect to real variable @xmath526 and using condition ( h5 ) , we have @xmath527}{\\mathbb{e}\\left(k\\left ( \\frac{d(x , x_1)}{h}\\right ) \\right)}.\\ ] ] integration with respect to the distribution of the real variable @xmath526 shows that    @xmath528 = \\int_0 ^ 1 k(t ) \\psi(th ) df(th),\\ ] ] where @xmath529 is the cumulative distribution function of the real random variable @xmath530 . on the other hand , taylor series expansion of the function @xmath531 up to the order one in the neighborhood of @xmath532 gives @xmath533 let us denote by @xmath534 ( resp .",
    "@xmath535 ) a d - dimensional vector where each component equal to @xmath536 ( resp .",
    "@xmath537 ) .      using hypothesis @xmath539 we get @xmath540 + h\\phi(h ) k(1 ) o_d(1)\\\\ & & - o_d(h\\phi(h ) )   \\int_0 ^ 1 k'(s ) ( \\tau_0(s ) g(x ) + o(1 ) ) ds\\\\ & = & h\\phi(h ) g(x ) \\nabla\\psi(0 ) \\left[k(1 ) - \\int_0 ^ 1 ( sk(s ) ) '   \\tau_0(s ) ds \\right ] + o_d^{a.s.}(h\\phi(h))\\end{aligned}\\ ] ] thus , making use of the lemma [ lemma1 ] , we obtain @xmath541\\end{aligned}\\ ] ]            write @xmath546^{-1 } \\times \\frac{m_1}{\\sqrt{m_2}}\\sqrt{n\\phi(h)g(x)}\\;t^{x}(\\mu ) \\left ( \\mu_{n}-\\mu\\right ) \\nonumber \\\\ & : = & v_{n,1}^x\\times v_{n,2}^x .",
    "\\end{aligned}\\ ] ] making use of theorem [ clt ] part ( ii ) , the term @xmath547 converges in distribution to @xmath548 .    now to get the result of the corollary it suffices to show that the first term @xmath549 converges to 1 in probability .",
    "following the same arguments as in @xcite combined with ( h1),(h2 ) , one gets + @xmath550 , @xmath551 and @xmath552 , as @xmath553 .",
    "+ now , we have to establish the consistency of @xmath554 .",
    "to do that , we will study separately the consistency of each term of @xmath554 .",
    "let us start by @xmath555 .",
    "for this , write      according to theorem [ thm2 ] , proposition [ variance ] , lemma 5.2 and the fact that the matrix @xmath185 is bounded , we can conclude that @xmath557 converges , in probability , to @xmath185 .",
    "the second term @xmath558 , can be treated similarly .",
    "finally , this leads to the convergence in probability of @xmath554 to @xmath559 .",
    "kemperman , j. h.  b. ( 1987 ) . the median of a finite measure on a banach space . in",
    "statistical data analysis based on the @xmath0-norm and related methods ( neuchtel , 1987 ) _ , pages 217230 .",
    "north - holland , amsterdam .",
    "laksaci , a. , lemdani , m. , and ould - sad , e. ( 2009 ) . a generalized @xmath7-approach for a kernel estimator of conditional quantile with functional regressors : consistency and asymptotic normality . ,",
    "* 79*(8 ) , 10651073 ."
  ],
  "abstract_text": [
    "<S> in this paper , a nonparametric estimator is proposed for estimating the @xmath0-median for multivariate conditional distribution when the covariates take values in an _ infinite _ dimensional space . </S>",
    "<S> the multivariate case is more appropriate to predict the components of a vector of random variables simultaneously rather than predicting each of them separately . </S>",
    "<S> while estimating the conditional @xmath0-median function using the well - known nadarya - waston estimator , we establish the strong consistency of this estimator as well as the asymptotic normality . </S>",
    "<S> we also present some simulations and provide how to built conditional confidence ellipsoids for the multivariate @xmath0-median regression in practice . some numerical study in chemiometrical real data </S>",
    "<S> are carried out to compare the multivariate @xmath0-median regression with the vector of marginal median regression when the covariate @xmath1 is a curve as well as @xmath1 is a random vector .    </S>",
    "<S> * keywords * : almost sure convergence , confidence ellipsoid , functional data , kernel estimation , small balls probability , multivariate conditional @xmath0-median , multivariate conditional distribution . </S>"
  ]
}