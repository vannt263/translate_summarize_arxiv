{
  "article_text": [
    "the collective behavior of natural insects - ants , bees , fireflies and termites mimic the problem solving capabilities of the swarms @xcite .",
    "these capabilities were adopted in various heuristics and meta - heuristics to solve difficult optimization problems .",
    "each meta - heuristic has a real world inspiration of optimization . as such ,",
    "the main inspiration for the ant colony system algorithm is the natural food finding strategy of ants .",
    "ants are capable of finding the shortest path from the food source to their nests .",
    "a chemical inside them call pheromone is the reason for this optimized behavior . following this real world strategy ,",
    "the ant colony system algorithm was developed by marco dorigo et al.@xcite to suit for path optimization problems .",
    "initially the algorithm was developed to solve the tsp .",
    "this original implementation supports the hypothesis that the ant colony algorithm is successful in finding the shortest path for the tsp .",
    "similar to any meta - heuristic , the ant colony system also has algorithm specific parameters .",
    "the initial implementation used the trial and error method to find the best collection of parameters .",
    "the values of the parameters depend on the problem at hand and hence at each instance , the most suitable parameter set for the problem should be evaluated .",
    "the task of parameter tuning again is an optimization where the optimal parameter set will give the optimum performance .",
    "though the initial study relied on trial and error , dorigo had stated some important features of parameters such as pheromone behavior , the number of ants and how they affect the performance of the algorithm @xcite .",
    "the original paper discusses the ranges for different parameters so that an idea about the distribution of each parameter is given .",
    "the results were in an encouraging position ascertaining that the algorithm is successful in solving the tsp .",
    "instances from tsplib and randomly generated tsps were used to evaluate the algorithm .    since the original acs works well with pre - tested parameter values , finding approaches to set better parameters without trial and error can improve the performance of the algorithm .",
    "the best way is to consider setting of parameters as another optimization problem . the same matter of tuning parameters of an acs",
    "is considered by many other researchers . yet",
    "none was successful in maintaining fully parameterless environment .",
    "an adaptive parameter control strategy for ant colony systems by zhi - feng hao et al . is a study carried out to enhance the performance of the ant system solving the tsp @xcite .",
    "although it has been mentioned as the ant colony system , they have used the ant system for the study .",
    "the particle swarm optimization ( pso ) has been used to optimize the parameters of the ant system ( psoacs ) .",
    "the parameters of the ant system were considered as a whole where one particle represents approximation for the set of parameters .",
    "the number of particles is the same as the number of ants , and once ants complete a tour the pso will update the parameters .",
    "the conclusions are based on the performance of the new algorithm and the existing acs .",
    "the results support the conclusions , but the following matters were not addressed .",
    "although the study focused on a parameter tuning technique , the effects of the method towards the parameters were not mentioned .",
    "basically the study was focused on improving the tsp results of the existing approach . for both psoacs and original acs , the results obtained conflict with the optimal results given in the tsplib .",
    "the reason may be the differences in the implementations .",
    "also in psoacs , the equations used are not clear enough to get an idea about the new algorithm .",
    "in evolving ant colony optimization , another research by hozefa m. botee and eric bonabeauy , they have made the use of genetic algorithm ( ga ) to evolve the best set of parameters @xcite . here",
    "also , one parameter set represents an individual of the genetic algorithm .",
    "however the implementation was tested only over two tsp instances .",
    "the results were encouraging , but the parameters of the acs depend on the selection of the parameters of ga such as crossover and mutation probability .",
    "apart from meta - heuristics , machine learning techniques have also been used to tune parameters of acs .",
    "for example ayse hande erol et al . in their research , have used artificial neural networks ( ann ) to find the best parameter set for acs solving a given tsp @xcite .",
    "the research focuses on only two parameters , @xmath0 : pheromone decay parameter and @xmath1 : the relative importance of the pheromone vs. distance .",
    "initially the acs - ann hybrid algorithm runs with different @xmath0 and @xmath1 values for 50 times .",
    "these parameters work as the inputs to the ann .",
    "then ann predicts the best parameter values for a given tsp instance .",
    "the hybrid algorithm was tested with several tsp instances from the tsplib @xcite .",
    "the results support the hypothesis that the hybrid algorithm performs well in finding better parameter values .",
    "however the study focused on tuning only two parameters .",
    "the information about the ann such as the training methods , weights and their effects are not mentioned in the research .",
    "as such there are other researches which have been conducted to find better parameter sets for the acs in solving tsp @xcite .",
    "but as a whole , all these methods rely on another algorithm or technique , where it again contains its own parameters .",
    "therefore the performance of the acs again depends on the parameters of the used algorithm . to overcome this issue",
    "we have designed an algorithm with the help of the firefly algorithm and the self - tuning framework for optimization algorithms proposed by xin - she yang , to optimize the parameters of the acs algorithm solving symmetric tsp instances .",
    "xin - she yang et al . , in the implementation of the self - tuning framework have used the firefly algorithm to apply the framework to tune fa s parameters @xcite . in their framework , the problem solved by the optimization algorithm and the parameter set of the algorithm both were considered as a single problem .",
    "the framework was initially tested for the firefly algorithm and proved its capability of tuning parameters of itself ( fa ) . in a research done by m.k.a .",
    "ariyaratne et al . , use this self tuning framework combined with the firefly algorithm to solve nonlinear equitations @xcite .",
    "they have solved univariate nonlinear equations having complex roots with the help of a modified firefly algorithm . to find the best parameters values ,",
    "the self tuning framework was implemented on the firefly algorithm . in their research",
    ", a firefly carries an approximation for a root as well as approximations to the parameter values .",
    "finally as the output , they receive best approximations for the roots in a given range as well as best approximations for the parameter values .",
    "the research again confirms the powerfulness of the self tuning framework in optimizing parameters .",
    "the significance of this research lies in the potential of the developed ant colony optimization algorithm for the tsp with the self tuning framework to optimize the parameters . despite the recent advancements in the field of route optimization and parameter optimization , the following issues have not been addressed by other researchers ( see table [ tab : tab1 ] for details of previously applied approaches ) where our research has accomplished .",
    "+    * none of the existing systems are capable of providing virtually parameter - free environments for the ant colony systems to solve tsps . * in most of the researches ,",
    "parameter optimization is done using another meta - heuristic algorithm whose parameters should be manually selected . *",
    "none of the approaches have used a designed framework for parameter optimization .    -2.0 cm        * author * & * year * & * parameter optimization method * & * # of tsp problems tested * & * advantages * & * limitations * + hozefa m. botee and eric bonabeauy & 1998 & ga & 2 & ga optimizes the parameters of acs & + raed abu zaitar and hussein hiyassat & 2005 & ga & 8 & ga optimizes the parameters of acs & only two parameters of acs ( @xmath0 and @xmath1 ) were updated in the first phase .",
    "+ d. gmez - cabrero and d. n. ranasinghe & 2005 & pso & 24 & pso optimizes the parameters of acs & + zhi - feng hao et al . &",
    "2006 & pso & 10 &    .previous work on parameter optimization of ant systems +   + ga - genetic algorithms , pso - particle swarm optimization , acs - ant colony systems , aco - ant colony optimization [ cols= \" < \" , ]     ` means that do not share a letter are significantly different . `",
    "+    both states support the conclusion that there is no any difference between acsfa and psoacs at 90% confidence level . considering the best case , acsfa and acs appeared to be different at 90% confidence level .",
    "finally the analysis support the facts that the performance of acsfa and psoacs is equally strong where the performance of acs is not as strong as acsfa and psoacs .",
    "but the results considering the best case , demonstrate that acsfa outperforms other two algorithms .",
    "however although there is no significant difference between acsfa and psoacs from the statistical viewpoint , there exists a strong advantage of acsfa over psoacs : the ability of performing well without considering the selection of suitable parameter values for both acs and fa .",
    "the statistical study emphasizes that there is no significant difference between acsfa and psoacs . but still acsfa is better since it does provide a parameter - free environment to the user .",
    "the firefly algorithm with the self - tuning framework tunes the necessary parameters of acs as well as fa .",
    "the figure [ fig : avgbetarawq0 ] represents the evolution of parameter values of acs over the iterations for the eil51 tsp instance . here the mean value of each parameter for each iteration is calculated .",
    ", @xmath2 and @xmath3 values over iterations for eil51 tsp instance ]    it is necessary to see the behavior of the parameters of the fa as well .",
    "figure [ fig : avggammadelta ] shows the evolution of the parameters of fa during iterations for the eil51 tsp instance . here also , the mean value of each parameter for each iteration is calculated .",
    "and @xmath4 values over iterations for eil51 tsp instance ]    figures [ fig : avgbetarawq0 ] and [ fig : avggammadelta ] point out that the parameter values varies up to some number of iterations and then stabilize over an optimum value .",
    "the study has focused on implementing an ant colony algorithm to solve symmetric tsp problems whose parameters are handled by a self tuning firefly algorithm . the algorithm was successfully implemented and tested with standard tsp problems . according to the results obtained , some key conclusions can be drawn . in terms of optimization ,",
    "the results show that the acsfa performs well in finding the shortest path for a given tsp instance .",
    "the comparisons done with acs and psoacs shows acsfa works well .",
    "although the statistical analysis concludes that both acsfa and psoacs have same performance , acsfa outperforms psoacs by providing a parameter free environment .",
    "the self tuning framework worked fine with the firefly algorithm in tuning both parameters of acs and fa .",
    "the graphical representations of the evolution of parameters of both acs and fa clearly demonstrates the ability of the self tuning firefly algorithm . with these we can consider the new acsfa as a better performer to solve tsps using acs . + for further development ,",
    "this research encourages us to study the performance of the self tuning framework with other nature inspired algorithms such as particle swarm optimization , bees algorithm etc .",
    "also since the increasing number of cities drops the performance of the algorithm , more experimentation should be done on the population size and the initialization of parameter ranges as well .",
    "the authors would like to thank dr .",
    "xin - she yang for his valuable suggestions and explanations on implementing the self tuning framework and ms .",
    "polegoda , lecturer at the faculty of animal science & export agriculture , uva wellassa university , sri lanka for the guidance given on the statistical analysis .",
    "m.  k.  a. ariyaratne , t.  g.  i. fernando , and s.  weerakoon . a self - tuning modified firefly algorithm to solve univariate nonlinear equations with complex roots . in",
    "_ 2016 ieee congress on evolutionary computation ( cec ) , vancouver , canada _ , july 2016 .",
    "joaqun derrac , salvador garca , daniel molina , and francisco herrera . a practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms .",
    ", 1(1):3  18 , 2011 .",
    "aye  hande erol , merve er , and serol bulkan . optimizing the ant colony optimization algorithm using neural network for the traveling salesman problem . in _",
    "actas de la conferencia internacional de _ , 2012 .",
    "d  gomez - cabrero and dn  ranasinghe .",
    "fine - tuning the ant colony system algorithm through particle swarm optimization . in _ proceedings of the international conference on information and automation _ , 2005 .",
    "adam south , kathrin stanger - hall , ming - luen jeng , and sara  m. lewis .",
    "correlated evolution of female neoteny and flightlessness with male spermatophore production in fireflies ( coleoptera : lampyridae ) .",
    ", 65(4):10991113 , 2011 .",
    "xin - she yang .",
    "firefly algorithms for multimodal optimization . in",
    "_ proceedings of the 5th international conference on stochastic algorithms : foundations and applications _ , saga09 , pages 169178 , berlin , heidelberg , 2009 .",
    "springer - verlag ."
  ],
  "abstract_text": [
    "<S> ant colony system ( acs ) is a promising approach which has been widely used in problems such as travelling salesman problems ( tsp ) , job shop scheduling problems ( jsp ) and quadratic assignment problems ( qap ) . in its original implementation </S>",
    "<S> , parameters of the algorithm were selected by trial and error approach . over the last few years </S>",
    "<S> , novel approaches have been proposed on adapting the parameters of acs in improving its performance . </S>",
    "<S> the aim of this paper is to use a framework introduced for self - tuning optimization algorithms combined with the firefly algorithm ( fa ) to tune the parameters of the acs solving symmetric tsp problems . </S>",
    "<S> the fa optimizes the problem specific parameters of acs while the parameters of the fa are tuned by the selected framework itself . with this approach </S>",
    "<S> , the user neither has to work with the parameters of acs nor the parameters of fa . using common symmetric tsp problems </S>",
    "<S> we demonstrate that the framework fits well for the acs . a detailed statistical analysis further verifies the goodness of the new acs over the existing acs and also of the other techniques used to tune the parameters of acs .    * a self - tuning firefly algorithm to tune the parameters of ant colony system ( acsfa ) *    m. k. a. ariyaratne^1^ , t. g. i. fernando^2^ and s. weerakoon^3^ +   _ ^1^department of computer science , faculty of computing , general sir john kotelawala defence university , sri lanka . </S>",
    "<S> + ^2^department of computer science , faculty of applied sciences , university of sri jayewardenepura , sri lanka . </S>",
    "<S> + ^3^ department of mathematics , faculty of applied sciences , university of sri jayewardenepura , sri lanka . + _ </S>"
  ]
}