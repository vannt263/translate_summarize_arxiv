{
  "article_text": [
    "in this paper we study the connection between two quantities , both called entropies and used in two different fields : the entropy of a thermodynamic system @xmath1 ( the entropy of boltzmann and clausius , the entropy of the second law of thermodynamics ) @xcite , and @xmath2 , the kolmogorov ",
    "sinai entropy , defined by the mathematicians as a measure of chaos and describing the dynamical instabilities of trajectories in the phase space @xcite . as a main difference the thermodynamic entropy is a function of time , depending not only on the particular dynamical system , but also on the choice of an initial probability distribution for the state of that system , while @xmath2 is a single number , a property solely of the chaotic dynamical system considered .",
    "moreover , the kolmogorov ",
    "sinai entropy it is not really an entropy but an entropy  rate , i.e. an entropy per unit time .    the connection between these two quantities has not been addressed extensively in the literature .",
    "only few and often very vague statements are present in the textbooks @xcite . though some similar ideas have appeared previously in the literature @xcite , a clarification of this connection has been proposed for strongly chaotic hamiltonian systems by two of the authors in ref .",
    "@xcite .",
    "here we consider conservative and non  conservative chaotic systems .",
    "we focus in particular on two two  dimensional conservative maps , the cat and the standard map , and on the logistic map , the simplest one  dimensional dissipative system .",
    "we start the system in far  from  equilibrium initial conditions , and we follow numerically the process of relaxation to equilibrium .",
    "when the dynamics is chaotic the variation with time of the physical entropy goes through three successive , roughly separated stages . in the first one , @xmath3 is dependent on the details of the dynamical system and of the initial distribution , and no generic statement can be made . in the second stage ,",
    "@xmath3 is a linear increasing function of time . in the third stage",
    ", @xmath3 tends asymptotically towards the constant value which characterizes equilibrium , for which the distribution is uniform in the available part of phase space .",
    "the actual connection requires @xmath3 to be averaged over many histories , so as to give equal weights to initial distributions from all regions of phase space .",
    "when such average is performed a perfect equality @xmath4 is obtained in the intermediate stage .    in this paper",
    "we also address a very special situation , i.e. the case of the logistic map at the edge of chaos .",
    "it has been shown that in order to be treated such a special border of chaos situation requires the nonextensive definition of entropy @xmath0 @xcite .",
    "as a first example we consider the `` generalized cat map '' , defined by the following iterative rule inside a unit square : @xmath5 where @xmath6 is a positive control parameter . in fig .  1 we consider an initial distribution very strongly localized in a tiny region of the phase space , and we let it evolve in time according to the eqs .",
    "( [ cat1 ] ) with @xmath7 .",
    "the distribution stretches in one direction and contracts in another .",
    "the volume of the distribution in phase space is conserved because of the liouville s theorem , while its shape keeps changing in time until the system reaches a stationary state with an uniform filling of the phase space .",
    "any fine  grained quantity ( for example an entropy defined as an integral over the phase space ) does not vary with time at all",
    ". however the shape of the volume becomes increasingly complicated due to the chaotic dynamics . in order to have an entropy which is increasing in time ( in agreement with the second principle of thermodynamics ) we simply need to perform a coarse  graining , i.e. a slight smearing , or smoothing , of the probability distribution in phase space before calculating @xmath1 @xcite .",
    "there are many ways to introduce a coarse  graining . in this paper",
    ", we assume that phase space is divided into a grid of a large number @xmath8 of cells @xmath9 with volumes @xmath10 , such that @xmath11 , the total volume of available phase space . in fig .  1 we report a grid of @xmath12x@xmath13 cells , though for the actual calculations of this paper we will use a much more refined coarse  graining .",
    "our definition for the out  of  equilibrium entropy is then the coarse  grained boltzmann - gibbs entropy : @xmath14 where @xmath15 is the probability that the state of the system falls inside cell @xmath9 of phase space at time @xmath16 .",
    "such a coarse  grained entropy is a quantity which is increasing in time , and the chaotic dynamics is the main reason of this increase . in the following of this paper",
    "we will show the fundamental importance of chaos in the relaxation to equilibrium : the entropy increases with a rate exactly equal to the kolmogorov ",
    "sinai entropy , the measure of chaos .",
    "n.s.krylov , already in the 1940 s @xcite , was the first one who understood clearly that the _ mixing _ property of chaos was essential for the foundations of statistical mechanics . in fig .",
    "2 we show @xmath3 for four values of @xmath6 ( see caption ) .",
    "now the coarse  graining grid is obtained by dividing each axis into 400 equal segments .",
    "the initial distribution consists of @xmath17 points placed at random inside a square whose size is that of a coarse  graining cell , and the center of that square is picked at random anywhere on the map . in this way",
    "the initial distribution is very strongly localized in phase space i.e. all the cells but a few contain initial zero probability .",
    "each of the four curves is an average over 100 runs , i.e. 100 histories with different initial distributions chosen at random , as mentioned .",
    "each curve shows clearly the stage2 linear behavior , the slope @xmath18 being accurately given by the ks entropy  rate @xmath2 . to calculate @xmath2 here",
    ", we have used the fact that it is equal to the sum of the positive lyapunov exponents @xcite . in the case of cat map",
    "we have only one positive analytically calculable lyapunov exponent @xmath19 , given by the equation : @xmath20 the values of @xmath2 are reported in the figure caption .",
    "the equality @xmath21 is valid in the intermediate stage for each of the four @xmath6 values considered in figure .",
    "moreover it can be shown that this result does not depend on the size of the initial distribution and on the size of the coarse  graining cells @xcite .",
    "the type of coarse  graining we adopted allows an alternative version of the significance of @xmath2 for the evolution of a physical system . starting from an initial distribution localized in phase space ( like in fig.1 ) , during the generic second stage mentioned earlier , the total number of occupied cells , i.e. cells with non - vanishing @xmath22 , varies proportionally to @xmath23 .",
    "our simulations verify this fact well @xcite .",
    "the second system we have studied is the standard map @xcite , again a two - dimensional conservative map in the unit square , but this time nonlinear : @xmath24 the map is only partially chaotic , but the percentage of chaos increases with the control parameter @xmath6 , and we consider large values of @xmath6 , namely 20 , 10 , and 5 . for @xmath25",
    "there are still two sizeable regular islands , associated with a period 2 stable trajectory while for @xmath26 and @xmath27 the phase space is completely chaotic . in fig .",
    "3 we report for the case @xmath25 the time evolution of an initial small distribution located in the chaotic region of the phase space . as a main difference with respect to fig .  1 , is that for a nonlinear system the stretching and contraction rates and directions vary appreciably in the phase space from place to place .",
    "the distribution bends on itself many times , nevertheless at the final time the system tends to occupy the whole chaotic part of the phase space in an uniform way .",
    "4 presents three single histories ( full lines )  for @xmath25 , as well as an average curve ( circles ) as in fig  .2 .",
    "the coarse  graining grid , the choice of initial distribution , and the averaging are the same used for the cat map , but it was necessary to include 1000 histories in order to obtain a good averaging .",
    "in fact , for a very nonlinear system as the standard map , the single curves can vary wildly and , differently from the case of the cat map , thus the averaging procedure is essential .",
    "5 shows the final average curves @xmath3 for three values @xmath6 : the one at the bottom corresponds to the smallest one .",
    "we calculated numerically the kolmogorov ",
    "sinai entropy from the lyapunov exponent , leaving out the regular islands for @xmath25 .",
    "this yielded @xmath28 0.98 ,  1.62 ,  2.30 , respectively for the three @xmath6 s .",
    "each curve has a stage2 linear portion whose slope is correctly given by @xmath2 .",
    "we return again to the need for averaging many histories starting from different parts of phase space .",
    "this has to be done whenever the local lyapunov exponents varies appreciably from place to place , which is the normal case for nonlinear systems . for linear maps ( like the generalized cat map below ) it is not necessary . for other systems",
    ", it would never be necessary if we could use a fine  enough coarse  graining , to give the probability time to spread throughout phase space before any appreciable increase in entropy .",
    "unfortunately such fine grain would require computers far more powerful than exist now . in the real thermodynamical world with many dimensions , what kind of coarse  graining",
    "should preferably be used is , we believe , a wide open question .",
    "we focus now on the dissipative case , and more specifically on the logistic map : @xmath29 despite being an extremely simple one  dimensional equation , the logistic map has always been used as a paradigmatic example of non  conservative chaotic systems , because it inglobes all the fundamental characteristics of a non  conservative system .",
    "the logistic map shows different regimes , according to the value of the control parameter @xmath6 @xcite . in particular it is regular ( negative lyapunov exponent @xmath19 ) for @xmath6 smaller than a critical value @xmath30 , and is chaotic for most part of the region @xmath31 . at the chaos threshold",
    "@xmath32 the lyapunov exponent vanishes and this is the famous _ edge of chaos _",
    "situation @xcite . before moving to the study of the entropy time evolution",
    "we need to discuss first the problem of the sensitivity to initial conditions .",
    "for all the cases in which the lyapunov exponent @xmath19 is positive we expect on the average an exponential increase of any small initial distance @xmath33 to hold : @xmath34 where @xmath35 and @xmath36 are the position at time @xmath16 of two initially close trajectories . this case will be referred in the following as _ strongly sensitive _ to the initial conditions .",
    "instead at the edge of chaos @xmath37 , and the following equation has been proven to be valid in ref .",
    "@xcite @xmath38^{\\frac{1}{1-q}}\\;\\;\\;(q \\in \\cal{r})\\ ] ] which recovers eq .",
    "( [ lya ] ) as the @xmath39 particular case .",
    "the case @xmath40 will be referred to as _ weakly sensitive _ to the initial conditions .",
    "so , _ strong _ and _ weak _ respectively stand for _ exponential _ and _ power - law _ time evolutions of @xmath41 .",
    "a _ weakly sensitive _ system is well described once @xmath42 , i.e.   the exponent of the power ",
    "law , is given .",
    "in particular at @xmath43 a value @xmath44 is obtained@xcite .",
    "we now apply to the logistic map the same kind of analysis used for conservative systems .",
    "the phase space interval @xmath45 is partitioned into @xmath46 equal cells @xmath9 .",
    "the initial distribution consists of @xmath47 points placed at random inside an interval picked at random anywhere on the phase space , and whose size is that of a cell . as the system evolves the probabilities @xmath48 are computed at each time step .    in order to study in the same framework either the chaotic case and the edge of chaos situation we consider a generalized non",
    " extensive entropy proposed a decade ago in ref .",
    "@xcite as a physical starting point to generalize statistical mechanics and thermodynamic : @xmath49^q}{q-1}\\;\\;\\;\\;(q \\in \\cal{r})\\ ; .\\ ] ] this entropy is a function of the entropic index @xmath42 and reduces to the boltzmann - gibbs entropy , defined in equation ( [ scoarse ] ) , when @xmath39 . a complete review of the existing theoretical",
    ", experimental and computational work about this entropy can be found in ref .",
    "in particular it has been shown that such an entropy covers some types of anomalies due to a possible multifractal structure of the relevant phase space .",
    "for example , whenever we have long - range interactions @xcite , long - range microscopic memory @xcite , or multifractal boundary conditions @xcite .",
    "we discuss in the rest of the paper the following results obtained for the logistic map @xcite :    \\1 ) in the chaotic regime @xmath39 : the boltzmann - gibbs entropy [ scoarse ] exhibits a linear increase in time , and the rate of increase is equal to @xmath2 .",
    "\\2 ) the standard boltzmann - gibbs entropy is inadequate to describe the edge of chaos situation .",
    "instead it is the non  extensive entropy which grows linearly with time for a particular value @xmath50 .      in fig .",
    "6 we present our results for the logistic map in correspondence of three values for @xmath6 , all of them in the chaotic regime , namely @xmath51  .",
    "fluctuations are of course present ( as @xmath16 increases ) , though their numerical importance can be cancelled by considering averages on the initial conditions .",
    "each of the curves is an average over 500 runs , i.e. , 500 histories with different initial distributions chosen at random , as mentioned .",
    "though the asymptotic value , corresponding to a smooth distribution in the available part of phase space , is different in the three cases , all the curves show a linear increase on entropy .",
    "the slope in the intermediate time stage does not depend on the dimension of the cells and on the distribution size @xcite and is equal to the predicted lyapunov exponent , respectively @xmath52 , @xmath53 and @xmath54  .",
    "therefore the same results found for conservative maps hold also for the logistic map , though the latter is a nonconservative one .    in fig .",
    "7 we focus on the case @xmath55 and instead of @xmath3 we consider the time evolution of @xmath56 , as defined by eq . [ stsallis ] , for three different values of @xmath42  .",
    "as @xmath16 evolves , @xmath0 tends to increase ( in all cases bounded by @xmath57 , or @xmath58 when @xmath39 ) .",
    "only the curve for @xmath39 shows a clear linear behavior and the slope is equal to the lyapunov exponent @xmath52  .",
    "for @xmath40 the curve is concave , while for @xmath59 the curve is convex .",
    "therefore for the logistic map in the chaotic regime the standard boltzmann ",
    "gibbs must be used as for any hamiltonian chaotic system or conservative map .",
    "so far we have shown that @xmath42 is 1 for all the cases in which the logistic curve is chaotic , i.e. strongly sensitive to the initial conditions .",
    "now we want to study the same system at its chaos threshold , i.e. at @xmath60 for which the feigenbaum attractor exists .",
    "we expect in this case a particular value @xmath50 , due to the fractality of phase space @xcite and power - law sensitivity to initial conditions .",
    "for such a value of @xmath6 , much bigger fluctuations than in the chaotic case are observed . to understand this it is sufficient to consider that the attractor occupies only a tiny part of phase space ( 844 cells out of the @xmath46 of our partition ) .",
    "we therefore require a very efficient and careful averaging over the initial conditions . here",
    "we adopt a selection method of the best histories based on how good is each initial condition at spreading itself .",
    "we obtain 1251 histories and we address to ref .",
    "@xcite for all the details about the selection method . in fig.8",
    "we plot @xmath0 for four different values of @xmath42  ; the curves are an average over the 1251 histories selected .",
    "the growth of @xmath0 is found to be linear when @xmath61 , while for @xmath62 ( @xmath63 ) the curve is concave ( convex ) .",
    "this behavior is similar to the one in fig.7 , with a major difference : _ the linear growth is not at @xmath39 , ( see inset in fig.8 ) , but at @xmath61 . _ to extract the particular value of q for which we get the best linear rise of the nonextensive entropy , we have fitted the curves @xmath0 in the time interval @xmath64 $ ] with the polynomial @xmath65  .",
    "we define the coefficient @xmath66 as a measure of the importance of the nonlinear term in the fit : if the points are on a perfect straight line , @xmath67 should be zero .",
    "we choose @xmath68 and @xmath69 for all @xmath42 s .",
    "fig.9 shows that the minimum of @xmath66 occurs for @xmath61 .",
    "the value of q which allows for a linear growth of @xmath0 , obtained through this procedure , happens to coincide with the value @xmath70 obtained in a completely different method by studying the power - law sensitivity to initial conditions @xcite .",
    "there exists also another method , based only on the geometrical description of the multifractal attractor existing at @xmath71 , which gives exactly the same value of @xmath42@xcite .",
    "the multifractal attractor can be characterized by using the multifractal function @xmath72 @xcite .",
    "this function is defined in the interval @xmath73 $ ] , and its maximum equals the fractal or hausdorff dimension @xmath74 . for a large class of systems the value of @xmath42",
    "can be calculated from @xmath75 where @xmath76 ( @xmath77 ) is the lowest ( highest ) value for which @xmath72 is defined .",
    "in particular for the logistic map at the edge of chaos @xmath78 , @xmath79 and @xmath80 .",
    "finally , it is also interesting to note , that our result for the linear growth of @xmath56 at the edge of chaos has been recently confirmed by using a different method @xcite .",
    "to summarize , we have illustrated , through several numerical examples for conservative and dissipative chaotic maps , the relationship existing between the boltzmann equilibrium thermodynamic entropy @xmath1 the kolmogorov ",
    "sinai one @xmath2 used for dynamical systems .",
    "as krylov already suggested in the early 40s @xcite , the mixing property characteristic of chaos is fundamental in order to reach the thermodynamical equilibrium . when using a coarse - graining procedure , the growth of @xmath3 averaged over many histories is linear and the slope gives just the kolmogorov ",
    "sinai entropy .",
    "this has been verified also for a dissipative case , i.e. the logistic map in the chaotic regime .",
    "finally , a very interesting generalization must be done at the chaos threshold , where the sensitivity to initial conditions is not exponential , but power  law like . in this case , in fact , in order to have a linear growth for the entropy , as for the full chaotic regime , the non  extensive entropic form introduced by tsallis should be adopted .",
    "the latter has been successfully checked for many cases where long  range correlations and a fractal phase space is found .",
    "we have shown that we get a linear growth for the generalized entropy only when the value @xmath81 ( and not @xmath39 for which the standard entropy is recovered ) is used .",
    "this fact confirms previous numerical studies and generalizes the connection between the two entropies also at the edge of chaos .",
    "we conclude hoping that our results could stimulate a deeper undestanding of the connections between dynamics and statistical mechanics .",
    "r. balian , _ from microphysics to macrophysics _",
    "i , springer ",
    "verlag , new york ( 1991 ) .",
    "a. n. kolmogorov , dokl .",
    "nauk sssr * 119 * , 861 ( 1958 ) ; * 124 * , 754 ( 1959 ) .",
    "c. beck and f. schlogl , _ thermodynamics of chaotic systems _ ( cambridge university press , cambridge , 1993 ) .",
    "one of the most explicit is on p. 39 of g. m. zaslavsky , _ chaos in dynamic systems _ , harwood , chur ( 1985 ) . c.dellago and h. a. posch , phys .",
    "e * 55 * , r9 ( 1997 ) .",
    "this paper really treats two subjects ; the second subject is the relevant one here .",
    "y. gu , j. wang , phys . lett.a * 229 * , 208 ( 1997 ) .",
    "v. latora and m. baranger , phys .",
    "lett . * 82 * , 520 ( 1999 ) .",
    "v. latora , m. baranger , a. rapisarda , c. tsallis , to appear in phys .",
    "lett.a , cond - mat/9907412 .",
    "r. balian , _ loc .",
    "_ works on the foundations of statistical physics _ , translated by a.b .",
    "migdal , ya .",
    "g. sinai and yu .",
    "l. zeeman , princeton university press ( 1979 ) .",
    "b. pesin , russian math .",
    "surveys * 32:4 * , 55 ( 1977 ) .",
    "m. tabor , sec .",
    "4.2.e in _ chaos and integrability in nonlinear dynamics _ ,",
    "wiley , new york ( 1989 ) .",
    "p.bak , _ how nature works : the science of self - organized criticality _ , ( springer  verlag , new york 1996 ) ; a. bhowal , physica a * 247 * , 327 ( 1997 ) .",
    "costa , m.l .",
    "lyra , a.r .",
    "plastino and c. tsallis , phys .",
    "e * 56 * , 245 ( 1997 ) and m.l .",
    "lyra and c. tsallis , phys .",
    "* 80 * , 53 ( 1998 ) . v. i. arnold ,",
    "_ mathematical methods of classical mechanics _ ,",
    "verlag , new york ( 1978 ) .",
    "g. benettin , l. galgani , a. giorgilli , and j.m .",
    "strelcyn , meccanica * 9 * , 21 ( 1980 ) ; a. wolf , j. swift , h. swinney , and j. vastano , physica d * 16 * , 285 ( 1985 ) . c. tsallis , j. stat . phys . *",
    "52 * , 479 ( 1988 .",
    "c. tsallis , in `` nonextensive statistical mechanics and thermodynamics '' , eds .",
    "salinas and c. tsallis , braz .",
    "* 29 * , 1 ( 1999 ) , physics today ( 2000 ) in press .",
    "/num1/index.htm ] .",
    "c. anteneodo and c. tsallis , phys .",
    "lett . * 80 * , 5313 ( 1998 ) ; v. latora , a. rapisarda and s. ruffo , phys . rev .",
    "* 83 * , 2104 ( 1999 ) , physica d*131 * , 38 ( 1999 ) , and phys .",
    "80 * , 692 ( 1998 ) .",
    "m. buiatti , p. grigolini and l. palatella , physica a * 268 * , 214 ( 1999 ) .",
    "s. montangero , l. fronzoni and p. grigolini , cond - mat/9911412 ."
  ],
  "abstract_text": [
    "<S> we consider several low  dimensional chaotic maps started in far - from - equilibrium initial conditions and we study the process of relaxation to equilibrium . in the case of conservative maps the boltzmann - gibbs entropy s(t ) </S>",
    "<S> increases linearly in time with a slope equal to the kolmogorov - sinai entropy rate . </S>",
    "<S> the same result is obtained also for a simple case of dissipative system , the logistic map , when considered in the chaotic regime . a very interesting results </S>",
    "<S> is found at the chaos threshold . in this case , the usual boltzmann - gibbs is not appropriate and in order to have a linear increase , as for the chaotic case , we need to use the generalized q - dependent tsallis entropy @xmath0 with a particular value of a q different from 1 ( when q=1 the generalized entropy reduces to the boltzmann - gibbs ) . </S>",
    "<S> the entropic index q appears to be characteristic of the dynamical system . </S>"
  ]
}