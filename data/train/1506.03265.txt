{
  "article_text": [
    "the analysis of very large ( typically sparse ) weighted graphs is becoming a central tool in numerous domains , including geographic information systems , social sciences , computational biology , computational linguistics , semantic search and knowledge discovery , and cyber security .",
    "a fundamental primitive for graph analytics is the estimation of a graph s diameter , defined as the maximum weighted distance between nodes in the same connected component . for this primitive , which is computationally intensive ,",
    "resorting to parallelism is inevitable as the graph size grows .",
    "unfortunately , state of the art parallel strategies for diameter estimation are either space inefficient or incur long critical paths .",
    "these strategies are thus unfeasible for dealing with huge graphs , especially on distributed platforms characterized by limited local memory and high communication costs , ( e.g. , clusters of loosely - coupled commodity servers supporting a mapreduce - like abstraction ) , which are widely used for big data tasks , and represent the target computational scenario of this paper . in this setting , the challenge is to minimize the number of communication rounds while using linear aggregate space and small ( i.e. , substantially sublinear ) space in the individual processors .",
    "_ previous work .",
    "_ for general graphs with arbitrary weights , the only known approach for the exact diameter computation requires the solution of the all - pairs shortest paths ( apsp ) problem , but all known apsp algorithms are characterized by space and/or time requirements which make them impractical for very large graphs . for unweighted graphs ,",
    "the hyperanf algorithm by @xcite computes a tight approximation to the eccentricity of each node ( i.e. , its maximum distance from every other node ) , which in turn yields a tight approximation to the graph diameter .",
    "hyperanf allows an efficient multithreaded implementation and runs fast on a shared memory platform .",
    "however , it has a critical path equal to the graph diameter and requires a ( small ) non constant memory blow - up .",
    "also , the algorithm can not be adapted to deal with weighted graphs . for these reasons ,",
    "hyperanf is not a viable competitor for the objectives of the present work .",
    "we observe that an upper bound to the diameter within a factor two can be easily computed by solving an instance of the single - source shortest path ( sssp ) problem starting from an arbitrary node .",
    "a number of recent works have explored the issue of reducing the approximation factor by running several sssp instances from carefully selected nodes @xcite . while in practice a few such instances suffice to obtain a very good approximation , worst - case approximation guarantees less than two are obtained at the expense of running a nonconstant number of sssp instances . in fact , there is strong theoretical evidence of the difficulty of approximating efficiently the diameter within a factor less than 3/2 ( see @xcite and references therein ) .    a number of parallel sssp algorithms have been devised in the last two decades @xcite ( a more extensive account of the literature can be found in @xcite ) . to the best of our knowledge",
    ", the most practical one is the _ @xmath0-stepping _ pram algorithm proposed in @xcite .",
    "the algorithm uses a design parameter @xmath0 to trade off parallel time and work . in a nutshell ,",
    "the role of @xmath0 is to stagger the computation of the sssp tree into zones of bounded depth @xmath0 .",
    "small values of @xmath0 reduce work at the expense of a longer critical path ( i.e. , parallel time ) with the algorithm approaching the behaviour of dijkstra s algorithm ; the reverse tradeoff is obtained when @xmath0 increases , approaching in this case the behaviour of algorithm @xcite .",
    "it can be shown that , irrespective of @xmath0 , if linear space is required , then the algorithm s parallel time is bounded from below by the unweighted diameter of the input graph .",
    "in fact , in @xcite the authors show that smaller parallel time can be achieved by introducing suitable shortcut edges connecting all node pairs at distance at most @xmath0 , which , however , have the potential of resulting into superlinear space complexity , especially for sparse graphs .",
    "in @xcite we devised a parallel @xmath1-approximation algorithm for computing the diameter of unweighted undirected graphs .",
    "the algorithm first determines a partition of the graph into @xmath2 disjoint clusters through a decomposition strategy based on growing the clusters from batches of centers progressively selected from yet uncovered nodes , which yields a provably small cluster radius .",
    "the diameter of the graph is then obtained through the diameter of a suitable quotient graph associated with the decomposition .",
    "the algorithm can be efficiently implemented in a mapreduce - like environment yielding good approximation quality in practice .",
    "a similar clustering - based approach for diameter estimation had been introduced in @xcite in the external - memory setting .",
    "we remark that no analytical guarantees would be provided by the weight - oblivious execution of these algorithms on a weighted graph since , for a given topology , the system of shortest paths may radically change once weights are introduced .",
    "_ our contribution .",
    "_ in this paper we address the more challenging scenario of weighted graphs , and devise a diameter approximation strategy for distributed machines supporting a mapreduce - like abstraction , with provable theoretical guarantees , providing extensive experimental evidence of its efficiency and effectiveness .    our algorithm adopts a cluster - based strategy similar to the one used in @xcite for the unweighted case .",
    "the main difficulty in the weighted case stems from the cluster growth process : in the unweighted case we included all nodes in the frontier of all active clusters at each round ; in the weighted case we need to avoid traversing heavy edges , which would increase the cluster radius and have an unpredictable impact on the approximation quality . on the other hand ,",
    "a high rate of cluster growth is crucial to enforce a small round complexity . in order to tackle these conflicting goals , we combine the following three main ingredients : ( 1 ) the progressive cluster - growing strategy of @xcite ; ( 2 ) an upper bound @xmath0 on the weight of the paths along which clusters are grown ( an idea inspired by the @xmath0-stepping algorithm ) ; and ( 3 ) a doubling strategy to guess a quasi - optimal value of @xmath0 .",
    "analytically , we prove that with high probability our algorithm attains an @xmath3 approximation ratio using a number of rounds which is @xmath4 , where @xmath5 is the maximum cluster radius and @xmath6 is the number of edges required to connect any pair of nodes at distance at most @xmath5 . both @xmath5 and @xmath6",
    "are nonincreasing functions of the number @xmath7 of clusters . to obtain the best round complexity",
    ", @xmath7 can be chosen as the maximum value for which the diameter of the quotient graph can be computed efficiently in a single processor s local memory in one round .",
    "the total memory space used by the algorithm is linear in the input graph size .",
    "we also show that on graphs of bounded doubling dimension  @xcite ( an important family including , for example , multidimensional arrays ) , under random edge weights and for some positive constants @xmath8 , if the local memory available to each processor is @xmath9 then the round complexity of our algorithm can be made asymptotically smaller than the unweighted diameter of the graph by a factor @xmath10 , outperforming by at least that factor the approximation strategy based on @xmath0-stepping , when linear space is required .",
    "we complement the analytical results with an extensive set of experiments on several large benchmark graphs ( of up to about one billion nodes and several billion edges ) , both real and synthetic , running on a 16-node cluster where the spark engine @xcite is employed to provide a mapreduce environment . for all graphs",
    ", our algorithm attains an approximation ratio never exceeding 1.4 , which is far less than the theoretical upper bound and comparable with the one ensured by the sssp - based approach .",
    "compared to an implementation of @xmath0-stepping in spark , our algorithm is up to two orders of magnitude faster .",
    "the better performance of our algorithm is also substantiated by more implementation - independent metrics such as the number of rounds and the aggregate work counted as number of node updates and messages generated .",
    "we performed scalability tests which , even in a somewhat small experimental testbed , demonstrate that our algorithmic strategy has the potential to exploit a much higher degree of parallelism , thus affording the analysis of much larger graphs .",
    "_ paper organization .",
    "_ section  [ sec - prelim ] introduces some basic terminology and defines our reference machine model .",
    "section  [ sec - cluster ] illustrates the graph decomposition at the core of the diameter approximation algorithm , which is described in the subsequent section  [ sec - diameter ] .",
    "the experimental analysis is presented in section  [ sec - experiments ] .",
    "let @xmath11 be a connected undirected weighted graph with @xmath12 nodes ( set @xmath13 ) , @xmath14 edges ( set @xmath15 ) , and a function @xmath16 which assigns a positive integral weight @xmath17 to each edge @xmath18 .",
    "we make the reasonable assumption that the edge weights are polynomial in @xmath12 .",
    "( in fact , our results immediately extend to the case of positive real - valued weights as long as the ratio between maximum and minimum weight is polynomial in @xmath12 . )",
    "the _ distance _ between two nodes @xmath19 , for short @xmath20 , is the weight of a minimum - weight path between @xmath19 .",
    "diameter _ of the graph , which we denote by @xmath21 , is the maximum distance between any two nodes .",
    "we remark that while for convenience in the theoretical analysis we consider only connected graphs , our results extend straightforwardly to disconnected graphs , by defining the diameter as the largest distance between any two nodes in the same connected component .    for any positive integer @xmath22 , a _ @xmath23-clustering _ of @xmath24 is a partition @xmath25 of @xmath13 into @xmath23 subsets called _",
    "each cluster @xmath26 has a distinguished node called _ center _ , and a _ radius _ @xmath27 .",
    "the _ radius of a @xmath23-clustering _ @xmath28 is @xmath29 .",
    "finally , denote by @xmath30 the minimum among the radii of all @xmath23-clusterings of @xmath24 .",
    "an important metric impacting the complexity of our algorithms is the number of edges required to connect nodes with minimum - weight paths .",
    "more formally , for a given distance parameter @xmath0 , we define @xmath31 to be the minimum value such that for any two nodes @xmath32 with @xmath33 there is a minimum - weight path between @xmath34 and @xmath35 with at most @xmath31 edges . it is easy to see that @xmath31 is a nondecreasing function of @xmath0 and that for any constant @xmath36 , @xmath37 .    the performance of the algorithms presented in this paper will be analyzed considering their distributed implementation on the _ mr model _ of @xcite .",
    "this model provides a rigorous computational framework based on the popular mapreduce paradigm @xcite , which is suitable for large - scale data processing on clusters of loosely - coupled commodity servers .",
    "similar models have been recently proposed in @xcite .",
    "an mr algorithm executes as a sequence of _ rounds _ where , in a round , a multiset @xmath38 of key - value pairs is transformed into a new multiset @xmath39 of pairs by applying a given reducer function ( simply called _ reducer _ ) independently to each subset of pairs of @xmath38 having the same key .",
    "the model features two parameters @xmath40 and @xmath41 , where @xmath40 is the total memory available to the computation , and @xmath41 is the maximum amount of memory locally available to each reducer .",
    "we use  to denote a given instance of the model .",
    "the complexity of an  algorithm is defined as the number of rounds executed in the worst case , and it is expressed as a function of the input size and of @xmath40 and @xmath41 . in the big data realm , practical  algorithms should use total space linear in the input size and significantly sublinear local space , while minimizing the round complexity .",
    "the following fact is proven in @xcite .",
    "[ prefixsorting ] the sorting and ( segmented ) prefix - sum primitives for inputs of size @xmath12 can be performed in @xmath42 rounds in  with @xmath43 .",
    "in this section we present a parallel algorithm to partition a connected undirected weighted graph @xmath11 into clusters of small radius .",
    "the algorithm generalizes the one presented in @xcite for the unweighted case .",
    "specifically , we grow clusters in stages , where in each stage a new randomly selected batch of cluster centers is added to the current clustering and the number of uncovered nodes halves with respect to the preceding stage .",
    "the challenge in the weighted case is to perform cluster growth by exploiting parallelism while , at the same time , limiting the weight of the edges considered in each growing step : the goal is to avoid increasing excessively the weighted radius of the clusters , which influences the approximation quality . in other words , unlike the strategy in @xcite for the unweighted case , we can not afford to boldly grow a cluster by adding all nodes connected to its frontier since some of these additions may entail heavy edges . to tackle this challenge",
    ", we use ideas akin to those employed in the @xmath0-stepping parallel sssp algorithm proposed in @xcite . in particular , we limit a cluster s growth by imposing a threshold @xmath0 on its radius .",
    "unlike the @xmath0-stepping algorithm , however , this threshold is not fixed a priori but automatically tuned to a quasi - optimal value during the clustering process .    before presenting the algorithm",
    ", we introduce some technical details .",
    "let @xmath0 be an integral parameter which we use as a guess for the radius of the clustering .",
    "as in @xcite , we call an edge _ light _ if its weight is @xmath44 , and _ heavy _ otherwise . with each node",
    "@xmath45 the algorithm maintains a _ state _ consisting of two variables @xmath46 : initially , @xmath47 is undefined and @xmath48 .",
    "whenever @xmath34 is assigned to a cluster , then @xmath47 is set to the cluster center and @xmath49 is set to an upper bound to @xmath50 .",
    "in particular , if @xmath34 is chosen as a cluster center , then @xmath51 and @xmath52 .",
    "the algorithm repeatedly applies , in parallel , edge relaxations of the kind used in the classical bellman - ford s algorithm .",
    "more precisely , we define the following _ @xmath0-growing step _ : for each node @xmath34 with @xmath53 and for each light edge @xmath54 , in parallel , if @xmath55 and @xmath56 then the status of @xmath35 is updated by setting @xmath57 , and @xmath58 . in case",
    "more than one node @xmath34 can provide an update to the status of @xmath35 , the update that yields the smallest value of @xmath59 and , secondarily , the one caused by the node @xmath34 such that @xmath47 has smallest index , is performed .",
    "suppose that a sequence of @xmath0-growing steps is performed starting from some set of centers @xmath60 .",
    "after the execution of these steps , we can contract the graph as follows ( procedure contract ) .",
    "for each center @xmath61 , all nodes @xmath45 with @xmath62 are removed , except @xmath63 itself . for each edge",
    "@xmath54 : if both @xmath47 and @xmath64 are defined , the edge is removed ; if both @xmath47 and @xmath64 are undefined , the edge is left unchanged ; and if @xmath47 is defined and @xmath64 is undefined , the edge is replaced by a new edge @xmath65 of weight @xmath66 .",
    "algorithm cluster@xmath67 , whose pseudocode is given in algorithm  [ alg : cluster_growing ] , grows clusters progressively in a number of stages , until all the nodes of the graph are covered . in each stage , which corresponds to an iteration of the outer while loop ,",
    "a sequence of @xmath0-growing steps is executed , each with the goal of including into the current clusters at least half of the nodes that are still uncovered but are reachable from some cluster through a path of weight at most @xmath0 .",
    "the set @xmath38 of centers of the current clusters includes clusters partially grown in previous stages ( if any ) , which are now contracted and represented only by their centers ( set @xmath26 ) , and a set of @xmath68 centers randomly selected from the uncovered nodes . in each stage , geometrically increasing values of @xmath0 , starting from a suitable initial value , are guessed until the coverage goal can be attained .",
    "( the sequences of @xmath0-growing steps for the various guesses of @xmath0 are performed in the inner while loop through procedure partialgrowth . ) when few nodes are left uncovered , these are added as singleton clusters and the algorithm terminates .",
    "observe that at most @xmath69 stages are executed and each contributes an additive factor @xmath0 to the clustering radius .",
    "we will show below that the largest guess for @xmath0 will be @xmath70 , with high probability .",
    "@xmath0 @xmath71 @xmath72 ; @xmath73 @xmath71 @xmath74 @xmath75 @xmath71 @xmath76 /*_current set of cluster centers _ * / @xmath77 @xmath71 @xmath78 @xmath79 @xmath71 1    assign each @xmath80 to a new singleton cluster centered at @xmath34 / * _ @xmath81 is the final set of cluster centers _ * / partialgrowth@xmath82    observe that when the algorithm terminates , each node @xmath45 is assigned to a cluster centered at some node @xmath47 .",
    "let @xmath83 denote the value of @xmath0 at the end of the execution of cluster@xmath67 . in the following lemma",
    ", we show that with high probability @xmath83 does not exceed @xmath30 by more than a constant factor .",
    "[ lem - clust2 ] @xmath84 , with high probability .",
    "consider an arbitrary iteration of the outer while loop and let @xmath85 be the ( contracted ) graph on which cluster growth is performed during the iteration .",
    "let @xmath86 be the nodes of @xmath87 representing clusters grown in previous iterations . clearly , we have that @xmath88 .",
    "refer to the nodes of @xmath89 as _ uncovered nodes_. we now show that , with probability at least @xmath90 , in @xmath87 at least half of the uncovered nodes can be reached by the new centers selected in the iteration or by nodes of @xmath26 with paths of weight at most @xmath91 traversing only uncovered nodes .",
    "let @xmath92 be a @xmath23-clustering of the whole graph with optimal radius @xmath93 . to avoid confusion",
    ", we refer to its clusters as _",
    "@xmath92-clusters _ , while simply call _ clusters _ those grown by our algorithm . consider the @xmath92-clusters that include some uncovered node . among these @xmath92-clusters , those that contain less than @xmath94 uncovered nodes account for a total of less than @xmath95 such nodes .",
    "we call _ large _ the @xmath92-clusters that contain @xmath94 or more uncovered nodes .",
    "therefore , large @xmath92-clusters account for more than @xmath96 uncovered nodes altogether .",
    "let @xmath97 be any such large @xmath92-cluster . by the choice of @xmath73 in the probability for center selection",
    ", we have that with probability @xmath98 at least one uncovered node @xmath99 is selected as a new center . since , for every uncovered node @xmath100 , there is a path in @xmath24 from @xmath101 to @xmath35 through @xmath102 of weight @xmath103 , there must be a path in @xmath87 from from @xmath101 to @xmath35 of weight at most @xmath16 in @xmath87 .",
    "note that the suffix of this path starting from the last cluster center has weight @xmath104 and traverses only unconvered nodes .",
    "the desired property follows by applying the union bound over all large @xmath92-clusters .    since in partialgrowth clusters",
    "are grown from the newly selected centers as well as from the nodes of @xmath26 , any value @xmath105 guarantees that half of the nodes in @xmath89 are covered by clusters .",
    "consequently , @xmath0 can never be doubled beyond @xmath106 .",
    "the lemma follows by applying the union bound over all iterations .",
    "the following theorem states the main result of this section .",
    "[ thm : radius_batched ] let @xmath23 be a positive integer . with high probability ,",
    "cluster@xmath67 returns an @xmath107-clustering of radius @xmath108 by performing @xmath109 @xmath0-growing steps , with @xmath110 .    by chernoff s bound each iteration of the outer",
    "* while * loop selects @xmath68 new cluster centers with high probability .",
    "hence , the bound on the number of clusters follows applying the union bound over the @xmath69 iterations of this loop . as for the bound on the clustering radius , we observe that the aggregate number of iterations of the inner * while * loop is at most @xmath111 , and this number is @xmath69 with high probability by virtue of lemma  [ lem - clust2 ] and the assumption on the polynomiality of the edge weights .",
    "the bound follows by observing that each such iteration increases the radius of cluster by an additive term at most @xmath84 .",
    "finally , observe that in every iteration of the inner * while * loop the number of @xmath0-growing steps executed by procedure partialgrowth is at most @xmath112 since , by the properties of edge relaxations , after those many growing steps all nodes at distance less than @xmath0 from some center of @xmath38 have been reached by the closest center in @xmath38 with a minimum - weight path , hence their state can not be further updated .",
    "therefore , the final number of @xmath0-growing steps will be @xmath113 , with high probability .",
    "in this section , we present an algorithm to estimate the diameter of a weighted graph as a function of the diameter of a suitable ( much smaller ) quotient graph of a clustering obtained through a refined version of the strategy devised in the previous section . as it will be clarified by the analysis , the refinement is introduced to achieve a provable bound on the approximation guarantee , by ensuring that not too many clusters have the potential to reach small neighborhoods of the graph .",
    "algorithm cluster2@xmath67 , whose pseudocode is given in algorithm  [ alg : cluster2 ] , builds the required clustering by first computing the radius @xmath114 of the clustering returned by cluster@xmath67 and then executing @xmath115 iterations where uncovered nodes are selected as new cluster centers with probability doubling at each iteration . in the @xmath79-th iteration , both previous and new clusters are grown using @xmath116-growing steps until _ all _ uncovered nodes at distance at most @xmath116 from them are reached ( procedure partialgrowth2 ) . at the end of the iteration",
    ", the graph is contracted using procedure contract2 , which is similar to procedure contract used in cluster with the only difference that each original edge @xmath54 of weight @xmath117 and such that @xmath47 is defined and @xmath64 is undefined , is replaced by a new edge @xmath65 with rescaled weight @xmath118 .",
    "( in fact , original edges of weight greater than @xmath116 are never used by cluster2 . )",
    "let @xmath114 be the radius of the clustering returned by cluster@xmath67 @xmath75 @xmath71 @xmath76 / * _ ( current set of cluster centers ) _ * / @xmath77 @xmath71 @xmath78 partialgrowth2@xmath82    the following lemma analyzes the quality of the clustering returned by cluster2@xmath67 and upper bounds the number of growing steps performed .    [ lem - cluster2 ]",
    "let @xmath23 be a positive integer . with high probability",
    ", cluster2@xmath67 computes an @xmath119-clustering of radius @xmath120 by performing @xmath121 @xmath0-growing steps with @xmath122 .    by theorem  [ thm : radius_batched ] we know that with high probability the invocation of cluster@xmath67 at the beginning of the algorithm computes a @xmath123-clustering , with @xmath124 , of radius @xmath125 . in what follows , we condition on this event .",
    "then , the bounds on the number of growing steps and on @xmath126 are straightforward . for @xmath127 , define @xmath128 as the smallest integer such that @xmath129 , and let @xmath130 .",
    "we now show that the number of original nodes of @xmath24 not yet reached by any cluster decreases at least geometrically at each iteration of the * for * loop after the @xmath128-th one . recalling that @xmath131 is the set of original nodes of @xmath24 that at the beginning of iteration @xmath132 have not been reached by any cluster , for @xmath133 , define the event @xmath134``at the beginning of iteration @xmath132",
    ", @xmath131 contains at most @xmath135 nodes '' .",
    "we now prove that the event @xmath136 occurs with high probability .",
    "observe that : @xmath137 since @xmath138 clearly holds with probability one .",
    "consider an arbitrary @xmath79 , with @xmath139 , and assume that @xmath140 holds .",
    "we prove that @xmath141 holds with high probability .",
    "since @xmath142 holds , we have that at the beginning of iteration @xmath132 , the number of nodes in @xmath131 is at most @xmath135 . clearly , if @xmath143 then @xmath141 trivially holds with probability one",
    "thus , we consider only the case @xmath144 in order to show that @xmath141 holds also in this case , we resort to the same argument used in the proof of lemma  [ lem - clust2 ] .",
    "let @xmath92 be a @xmath123-clustering of the whole graph with optimal radius @xmath145 and observe that @xmath146 . to avoid confusion",
    ", we refer to its clusters as _",
    "@xmath92-clusters _ , while simply call _ clusters _ those grown by cluster2 .",
    "consider the @xmath92-clusters that include some nodes of @xmath131 , and call one such cluster _ large _ if it contains at least @xmath147 nodes of @xmath131 .",
    "this implies that the large @xmath92-clusters contain , altogether , at least half of the nodes of @xmath131 .",
    "moreover , by the choice of @xmath73 , it is easy to argue that with probability @xmath148 at least one new center is selected from each large @xmath92-cluster in iteration @xmath132 . consider now an arbitrary large @xmath92-cluster centered at @xmath102 and let @xmath99 be a new center selected from this cluster in the iteration . for every @xmath149",
    "there is a path in @xmath24 from @xmath101 to @xmath35 ( through @xmath102 ) of weight @xmath150 , hence there must be a path in @xmath87 from from @xmath101 to @xmath35 of weight at most @xmath16 .",
    "it then follows that node @xmath35 will be covered by some cluster in iteration  @xmath132 .",
    "consequently , in the iteration at least half of the nodes of @xmath131 will be covered by clusters , with probability at least @xmath90 .    by multiplying the probabilities of the @xmath69 conditioned events",
    ", we conclude that event @xmath136 occurs with high probability .",
    "note that in the last iteration ( iteration  @xmath151 ) all uncovered nodes are selected as centers with probability 1 , and , if @xmath136 occurs , these are @xmath152 .",
    "now , one can easily show that , with high probability , in the first @xmath128 iterations , @xmath153 clusters are added and , by conditioning on @xmath154 , at the beginning of each iteration  @xmath132 , @xmath133 , @xmath155 new clusters are created , for a total of @xmath156 clusters .",
    "observe that for fixed @xmath23 , the clustering returned by cluster2 has a larger number of clusters and a weaker guarantee on its radius than the the clustering returned by cluster .",
    "as such , cluster2 does not appear to be a very desirable clustering strategy in itself .",
    "however , cluster2 enforces the following important property which will be needed for proving the diameter approximation . with reference to a specific execution of cluster2 ,",
    "define the _",
    "light distance _ between two nodes @xmath34 and @xmath35 as the weight of the minimum - weight path from @xmath34 and @xmath35 consisting only of edges of weight at most @xmath116 .",
    "( note that the light distance is not necessarily defined for every pair of nodes . )    due to the weight rescaling performed by contract2 at the end of each iteration , given a center @xmath63 selected at a certain iteration @xmath79 of the * for * loop , and a node @xmath35 at light distance @xmath157 from @xmath63 , the cluster centered at @xmath63 can not grow to reach @xmath35 in less than @xmath158 iterations and that in those many iterations @xmath35 will be reached by some cluster ( possibly the one centered at @xmath63 ) . consequently , no center selected at a later iteration at that same distance from @xmath35 as @xmath63 would be able to reach @xmath35 .",
    "we are now ready to present the main result of this section , which shows how cluster2 can be employed to determine a good approximation to the graph diameter .",
    "suppose we run cluster2 on a graph @xmath11 to obtain a clustering @xmath28 of radius @xmath126 . for each @xmath45",
    ", let @xmath47 be the center of the cluster assigned to @xmath34 , and let @xmath49 be distance between @xmath34 and @xmath47 returned by cluster2 . as in @xcite",
    ", we define the weighted quotient graph associated to @xmath28 as the graph @xmath159 where nodes correspond to clusters and , for each edge @xmath54 of @xmath24 with @xmath160 , there is an edge in @xmath159 between the clusters of @xmath34 and @xmath35 with weight @xmath161 .",
    "( in case of multiple edges between two clusters , it is sufficient to retain only the one yielding minimum weight . ) let @xmath21 ( resp .",
    ", @xmath162 ) be the weighted diameter of @xmath24 ( resp . , @xmath159 ) .",
    "we approximate @xmath21 through the value @xmath163 .",
    "it is easy to see that our estimate is conservative , that is , @xmath164 .",
    "we have :    [ segment ] with high probability , @xmath165    since @xmath166 ( by lemma  [ lem - cluster2 ] ) , and @xmath167 , we have that @xmath168 . in order to show that @xmath169 , let us fix an arbitrary pair of cluster centers and an arbitrary minimum - weight path @xmath170 between them in @xmath24 , and let @xmath171 be the weight of @xmath170 .",
    "let @xmath172 be the path of clusters in @xmath159 traversed by @xmath170 .",
    "we now show that with high probability the weight of @xmath172 in @xmath159 is @xmath173 .",
    "the bound on the approximation will then follow by applying the union bound over all pairs of cluster centers .",
    "consider first the case @xmath174 ( note that this can happen since the clustering yielding the radius @xmath114 determined at the beginning of cluster2 is built out of paths using only light edges of weight @xmath70 ) . in this case , it is easy to see that the first batch of centers ever selected in an iteration of the for loop of cluster2 will cover the entire graph , and these centers are @xmath69 with high probability .",
    "therefore , @xmath172 contains @xmath69 clusters and its weight is @xmath175 .",
    "suppose now that @xmath176 .",
    "we show that at most @xmath177 clusters intersect @xmath170 ( i.e. , contain nodes of @xmath170 ) , with high probability . it can be seen that @xmath170 can be divided into @xmath178 subpaths , where each subpath is either an edge of weight @xmath179 or a segment of weight @xmath180 .",
    "it is then sufficient to show that the nodes of each of the latter segments belong to @xmath181 clusters .",
    "consider one such segment @xmath182 .",
    "clearly , all clusters containing nodes of @xmath182 must have their centers at light distance at most @xmath126 from @xmath182 ( i.e. , light distance at most @xmath126 from the closest node of @xmath182 ) .",
    "recall that @xmath183 . for @xmath184 ,",
    "let @xmath185 be the set of nodes whose light distance from @xmath182 is between @xmath186 and @xmath187 , and observe that any cluster intersecting @xmath182 must be centered at a node belonging to one of the @xmath185 s .",
    "we claim that , with high probability , for any @xmath188 , there are @xmath69 clusters centered at nodes of @xmath185 which may intersect @xmath182 .",
    "fix an index @xmath188 , with @xmath184 , and let @xmath189 be the first iteration of the for loop of cluster2 in which some center is selected from @xmath185 . by the property of cluster2 discussed after lemma  [ lem - cluster2 ] , @xmath190 iterations are sufficient for any of these centers to cover the entire segment . on the other hand ,",
    "any center from @xmath185 needs at least @xmath191 iterations to touch the segment .",
    "hence , we have that no center selected from @xmath185 at iteration @xmath192 or higher is able to reach @xmath182 .",
    "it is easy to see that , due to the smooth growth of the center selection probabilities , the number of centers selected from @xmath185 in iterations @xmath189 and @xmath193 is @xmath69 , with high probability .",
    "this implies that the nodes of segment @xmath182 will belong to @xmath181 clusters , with high probability . by applying the union bound over all segments of @xmath170",
    ", we have that @xmath177 clusters intersect @xmath170 , with high probability .",
    "therefore , the weight of @xmath172 is @xmath194 .",
    "we now discuss the implementation of the above diameter approximation algorithm in the mr model using overall linear space and show that , for a relevant class of graphs , its round complexity can be made asymptotically smaller than the one required to obtain a 2-approximation through the state - of - the - art sssp algorithm by @xcite . for a given",
    "connected weighted graph @xmath11 , consider the  model with total memory @xmath40 linear in the graph size , and local memory @xmath195 , for some constant @xmath196 .",
    "we begin by observing that , regardless of the number of active clusters , a @xmath0-growing step , for any @xmath0 , can be implemented through a constant number of simple prefix and sorting operations which , by fact  [ prefixsorting ] , require @xmath197 rounds on . by combining this observation with the results of theorem  [ thm : radius_batched ] and lemma  [ lem - cluster2 ] , we obtain that cluster2@xmath67 can be implemented in @xmath121 rounds in .    for an arbitrary positive constant @xmath198 ,",
    "let @xmath199 and let @xmath200 be the weighted quotient graph associated with the clustering returned by cluster2@xmath67 .",
    "the diameter @xmath162 ( in fact , a constant approximation to this quantity ) , and , consequently , the value @xmath201 , can then be computed in @xmath197 rounds in  by adopting the same techniques described in @xcite .",
    "the following theorem summarizes the above discussion .",
    "[ mr - complexity ] let @xmath24 be a connected weighted graph with @xmath12 nodes , @xmath14 edges and weighted diameter @xmath21 .",
    "also , let @xmath202 be two arbitrary constants , and let @xmath199 . on the  model , with @xmath203 and @xmath204 , an upper bound @xmath205 to the diameter of @xmath24",
    "can be computed in @xmath121 rounds , with high probability .",
    "note that the round complexity depends on the characteristics of the graph and is nonincreasing in the number of clusters , which are in turn controlled by parameter @xmath23 .",
    "for general graphs , the value @xmath206 is @xmath207 while the analysis in @xcite implies that under the linear - space constraint a natural mr - implementation of @xmath0-stepping requires @xmath208 rounds .",
    "hence , our algorithm can not be asymptotically slower than @xmath0-stepping .",
    "however , we show below that our algorithm becomes considerably faster for an important class of graphs .",
    "the following definition introduces a concept that a number of recent works have shown to be useful in relating algorithms performance to graph properties  @xcite .",
    "[ doublingdim ] consider an undirected graph @xmath209 .",
    "the _ ball of radius @xmath5 _ centered at node @xmath35 is the set of nodes reachable through paths of at most @xmath5 edges from @xmath35 . also , the _ doubling dimension _ of @xmath24 is the smallest integer @xmath210 such that for any @xmath211 , any ball of radius @xmath212 can be covered by at most @xmath213 balls of radius @xmath5 .",
    "we can specialize the result of theorem  [ mr - complexity ] as follows .",
    "[ mr - complexity2 ] let @xmath24 be a connected graph with @xmath12 nodes , @xmath14 edges , maximum degree @xmath214 , doubling dimension @xmath215 , and positive integral edge weights chosen uniformly at random from a polynomial range .",
    "denote by @xmath21 and @xmath216 , respectively , the weighted and unweighted diameter of @xmath24 .",
    "also , let @xmath217 be two arbitrary constants . on the  model , with @xmath218 and @xmath204 , an upper bound @xmath219 to the diameter of @xmath24",
    "can be computed in @xmath220 rounds , with high probability .    by iterating the definition of doubling dimension starting from a single ball of unweighted radius @xmath216 containing the whole graph",
    ", we can decompose the graph into @xmath23 disjoint clusters of unweighted radius @xmath221 .",
    "letting @xmath222 be the maximum edge weight , we have that @xmath223 upper bounds @xmath30 . we know that our algorithm computes the diameter approximation in @xmath224 rounds .",
    "we will now give an upper bound on @xmath225 . by using results from the theory of branching processes",
    "@xcite we can prove that by removing all edges of weight @xmath226 with high probability the graph becomes disconnected and each connected component has @xmath69 nodes .",
    "( more details will be provided in the full version of the paper . ) as a consequence , with high probability any simple path in @xmath24 will traverse an edge of weight @xmath227 every @xmath69 nodes .",
    "this implies that a path of weight at most @xmath228 has @xmath229 edges .",
    "the theorem follows by setting @xmath199 .    for what concerns the comparison with @xmath0-stepping",
    ", the analysis in @xcite implies that under the linear - space constraint , for a graph @xmath24 with random uniform weights a natural mr - implementation of @xmath0-stepping requires @xmath230 rounds .",
    "thus , by the above corollary , if @xmath24 has bounded doubling dimension the round complexity of our algorithm can be made smaller by a sublinear yet polynomial factor which is a function of the available local space @xmath41 .",
    "we conclude this section by observing that in the case of very skewed graph topologies and/or weight distributions under which the hypotheses of corollary  [ mr - complexity2 ] do not hold , the factor @xmath225 in the round complexity of our algorithm can be large , thus reducing the competitive advantage with respect to @xmath0-stepping .",
    "we can somewhat overcome this limitation by imposing an upper limit @xmath231 ( resp . , @xmath232 ) to the number of growing steps performed in each execution of partialgrowth within cluster@xmath233 ( resp .",
    ", partialgrowth2 within cluster2@xmath233 ) .",
    "it can be shown that , in this case , the round complexity of our algorithm , for general graphs , becomes @xmath234 at the expenses of an extra @xmath235 factor in the approximation ratio .",
    "the argument revolves around the existence of quasi - optimal clusterings of bounded unweighted depth .",
    "( more details will be provided in the full version of this paper . )",
    "l@ r r r graph & @xmath12 & @xmath14 & @xmath21 +  @xcite & 23,947,347 & 29,166,673 & 55,859,820 + roads - cal  @xcite & 1,890,815 & 2,328,872 & 16,485,258 + livejournal@xmath236  @xcite & 3,997,962 & 32 , 681 , 189 & 9.41 + twitter@xmath236  @xcite & 41,652,230 & 1,468,365,182 & 9.07 + mesh(s)@xmath236 & @xmath237 & @xmath238 & @xmath239 + r - mat(s)@xmath236  @xcite & @xmath240 & @xmath241 & @xmath239 + roads(s ) & @xmath242 & @xmath243 & @xmath239 +    our experimental platform is a cluster of 16 nodes , each equipped with a 4-core i7 processor and 18 gb ram , connected by a 10gbit ethernet network .",
    "our algorithms are implemented using apache spark  @xcite , a popular framework for big data computations that supports the mapreduce abstraction adopted by our algorithms .",
    "the experiments have been run on several graphs whose properties are summarized in table  [ tab : benchmark - graphs ] and can be classified as follows : a ) road networks ( roads - usa and roads - cal ) , b ) social networks ( livejournal and twitter ) , c ) synthetic graphs ( mesh(s ) , r - mat(s ) , and roads(s ) , where s is a parameter controlling the size of the graph ) . the latter class contains artificially generated graphs whose size can be made arbitrarily large and whose topological properties reflect those of the real networks in the first two classes . in particular , r - mat(s ) are graphs with a power - law degree distribution and small diameter  @xcite , and roads(s ) are graphs obtained as the cartesian product of a linear array of @xmath182 nodes @xmath244 and unit edge weights with roads - usa .",
    "finally , mesh(s ) is an @xmath245 square mesh included since it is a graph of known doubling dimension @xmath246 for which the results of corollary  [ mr - complexity2 ] hold .",
    "all road networks come with original integer weights while for the other graphs , which are born unweighted , we assigned uniform random edge weights in @xmath247 $ ] according to the approach commonly adopted in the literature .",
    "we implemented a simplified version of our diameter approximation algorithm , dubbed cl - diam , where , for efficiency , we used cluster , rather than cluster2 , for computing the graph decomposition .",
    "in fact , cluster2 first runs cluster to obtain an estimate of the radius , and then computes a second decomposition which is instrumental to provide a theoretical bound to the approximation factor , but which does not seem to provide a significant improvement to the quality of the approximation in practice .    as a second optimization , we ran cluster using an initial value of @xmath0 larger than the minimum edge weight , as was specified in the pseudocode .",
    "we observe that by increasing the initial value of @xmath0 , the round complexity improves since less doublings are required before hitting the final value . on the other hand , setting the initial value of @xmath0 too large",
    "may yield a larger cluster radius , possibly incurring a worse diameter approximation . to explore this phenomenon , we experimented on mesh@xmath248 with @xmath249 and random edge weights , such that an edge has weight @xmath250 with probability @xmath251 and @xmath252 otherwise . with high probability , such a graph can be completely covered using clusters that do not contain edges with weight 1 : including one of those edges in a cluster would make its radius far bigger than it needs to be .",
    "we ran our algorithm with two configurations .",
    "the first configuration started with @xmath253 ( i.e. , the minimum edge weight ) so to let the algorithm tune itself to the final value @xmath0 ( @xmath254 ) ; the second configuration started with an inital @xmath0 equal to the graph diameter ( @xmath255 ) so that no doubling of @xmath0 was needed . the diameter approximation obtained by the second configuration was about @xmath256 times larger than the actual",
    "diameter , whereas the first configuration obtained an approximation ratio of @xmath257 .",
    "a set of experiments ( omitted here for brevity ) showed that a good initial guess for @xmath0 is the average edge weight , which reduces the round complexity without affecting the approximation quality significantly .",
    "therefore , all our experiments have been run with this initial guess of @xmath0 .",
    "finally , in all of our experiments the parameter @xmath23 was set to yield a number of nodes in the quotient graph @xmath258 .",
    "this choice of @xmath23 was made to ensure that , for all instances , the final diameter computation in the quotient graph would not dominate the running time .",
    "_ comparison with the sssp - based approximation .",
    "_ recall that an sssp algorithm can be used to yield a 2-approximation to the diameter by returning twice the weight of the heaviest shortest path .",
    "thus , we compared our algorithm cl - diamwith a spark implementation of the @xmath0-steppingsssp algorithm ( starting from a random node ) , which is the state of the art for parallel sssp and is in fact our only practical competitor on weighted graphs . in @xmath0-stepping",
    ", parameter @xmath0 can be set to control the tradeoff between parallel time ( i.e. , rounds in the mapreduce context ) and total work . for each graph , we tested @xmath0-steppingwith several values of @xmath0 , selecting the value yielding the best running time .",
    "since in mapreduce - like environments the number of rounds has a significant impact on the running time , not surprisingly , for all graphs the best value of @xmath0 was always the one minimizing the number of rounds .",
    "the results of the comparison are summarized in table  [ tab : comparison - dstepping ] and graphically represented in figures  [ fig : approximation ] , [ fig : num - rounds ] , and  [ fig : work ] . in the table",
    "we report , for each graph , the diameter approximation factor and the running time . along with these , we also report two additional measures , namely , the number of rounds and the work ( defined as the sum of node updates and messages generated ) , that allow to compare the two algorithms in a more platform - independent way .",
    "it has to be remarked that the approximation quality returned by cl - diam  on all benchmark graphs , a value always less that @xmath259 , is much better that the theoretical @xmath260 bound .",
    "also , our algorithm is from about one to two orders of magnitude faster than @xmath0-stepping , while featuring comparable approximation ratios ( figure  [ fig : approximation ] ) . as expected , the higher performance of cl - diamis consistent with the fact that it requires far less rounds than @xmath0-stepping , as shown in figure  [ fig : num - rounds ] ."
  ],
  "abstract_text": [
    "<S> we present a space and time efficient practical parallel algorithm for approximating the diameter of massive weighted undirected graphs on distributed platforms supporting a mapreduce - like abstraction . </S>",
    "<S> the core of the algorithm is a weighted graph decomposition strategy generating disjoint clusters of bounded weighted radius . </S>",
    "<S> theoretically , our algorithm uses linear space and yields a polylogarithmic approximation guarantee ; moreover , for important practical classes of graphs , it runs in a number of rounds asymptotically smaller than those required by the natural approximation provided by the state - of - the - art @xmath0-stepping sssp algorithm , which is its only practical linear - space competitor in the aforementioned computational scenario . </S>",
    "<S> we complement our theoretical findings with an extensive experimental analysis on large benchmark graphs , which demonstrates that our algorithm attains substantial improvements on a number of key performance indicators with respect to the aforementioned competitor , while featuring a similar approximation ratio ( a small constant less than 1.4 , as opposed to the polylogarithmic theoretical bound ) .    </S>",
    "<S> * keywords * graph analytics ; parallel graph algorithms ; weighted graph decomposition ; weighted diameter approximation ; mapreduce </S>"
  ]
}