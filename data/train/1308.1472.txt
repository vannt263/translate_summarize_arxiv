{
  "article_text": [
    "with the advent of many - core chips such as gpus and the mic architecture comes the opportunity to sustain unprecedented rates of floating point operations at comparably high integration density and low cost .",
    "these architectures , however , require careful structuring of the data layout and memory access patterns to exhaust their multithreading and vectorization capabilities .",
    "consequently , it is not clear a priori how to accelerate pde solvers that use adaptive mesh refinement .",
    "of course , it was realized early that it helps to aggregate degrees of freedom ( dof ) at the element level , as has been done with high - order spectral element @xcite , low order continuous galerkin methods that accumulate many elements simultaneously @xcite , or discontinuous galerkin @xcite methods .",
    "gpu implementations of the latter have been proposed recently @xcite .",
    "the finite volume method has typically been implemented using a single degree of freedom per cell on structured @xcite or unstructured meshes @xcite ; higher order methods have also been constructed by widening the stencil , for instance in weno methods @xcite . to facilitate hardware acceleration for parallel dynamic amr",
    ", we build upon the forest - of - octrees paradigm because of its low overhead and proven scalability @xcite .",
    "this approach identifies each octree leaf with a mesh element .",
    "the present work does not construct a traditional high - order element but defines each element to be a dense computational patch with @xmath1 dofs .",
    "in fact , this approach resembles block - structured amr @xcite except that the patches are not overlapping , which enables us to capitalize on our previous experience with scalable fe solvers for pdes @xcite .",
    "the clawpacksoftware @xcite provides a popular implementation of such a patch .",
    "it has been designed to solve hyperbolic conservation laws and successfully used in the context of block - structured amr @xcite . in this paper",
    "we describe our design for the coupling of forest - of - octrees amr with clawpackat the leaf level .",
    "we comment on challenges that arise in enabling multiblock geometries and efficient parallelism and conclude with a range of numerical examples that demonstrate the conceptual advantages .",
    "the starting point of our work is defined by the ` p4est`algorithms for forest - of - octrees amr on the one hand , and the clawpackalgorithms for the numerical solution of hyperbolic conservation laws on the other .",
    "both are specialized codes with the following characteristics :    [ cols= \" < , < , < \" , ]     to showcase a multiblock connectivity , we include results for the spherical example 2 in figure  [ fig : spherical ] , together with a strong scaling table from 16 to 256 mpi ranks .",
    "we have presented the integration of an mpi - based forest - of - octrees adaptive meshing code , ` p4est ` , with a numerical solver for hyperbolic conservation laws , clawpack / manyclaw , that implements threaded parallelism for a single compute patch .",
    "we abstract an interface to the parallel meshing code in order to derive the schedule of neighbor exchanges , averaging / interpolation , and time integration on the local patches .",
    "this approach naturally lends itself to mpi / thread hybridization .",
    "apart from its parallel scalability , we favor the presented strategy for its modularity , encapsulation , and versality .",
    "future work will continue to optimize the parallel neighbor exchange patterns and investigate a generic handling of arbitrary multi - block geometries .",
    "we would like to thank the texas advanced computing center ( tacc ) for access to the stampede supercomputer under allocations tg - dpp130002 and tg - asc130001 granted by the nsf xsede program .",
    "the authors acknowledge valuable discussion with randy leveque , marsha berger , and hans - petter langtangen .",
    "we also acknowledge david ketcheson and the kaust sponsored hpc@xmath3 numerics workshop at which the initial phases of this project were first discussed .",
    "the second author would like to also acknowledge the isaac newton institute ( cambridge , uk ) , where much of the preliminary development work for forestclawwas done .",
    "the fourth author recognizes simula research lab , norway , for funding .",
    "the leaf / patch paradigm was independently presented by b.  as part of a talk at the sci institute , salt lake city , utah , usa in july 2011 .",
    "carsten burstedde , omar ghattas , michael gurnis , tobin isaac , georg stadler , tim warburton , and lucas  c. wilcox .",
    "extreme - scale amr . in _",
    "sc10 : proceedings of the international conference for high performance computing , networking , storage and analysis_. acm / ieee , 2010 .",
    "phillip colella , daniel  t. graves , noel keen , terry  j. ligocki , daniel  f. martin , peter  w. mccorquodale , david modiano , peter  o. schwartz , theodore  d. sternberg , and brian van  straalen .",
    "applied numerical algoirthms group , nersc division , lawrence berkeley national laboratory , berkeley , ca , may 2007 .",
    "tobin isaac , carsten burstedde , and omar ghattas .",
    "low - cost parallel algorithms for 2:1 octree balance . in _ proceedings of the 26th ieee international parallel & distributed processing symposium_. ieee , 2012 .",
    "hari sundar , george biros , carsten burstedde , johann rudi , omar ghattas , and georg stadler .",
    "parallel geometric - algebraic multigrid on unstructured forests of octrees . in _",
    "sc12 : proceedings of the international conference for high performance computing , networking , storage and analysis_. acm / ieee , 2012 ."
  ],
  "abstract_text": [
    "<S> we present a new hybrid paradigm for parallel adaptive mesh refinement ( amr ) that combines the scalability and lightweight architecture of tree - based amr with the computational efficiency of patch - based solvers for hyperbolic conservation laws . </S>",
    "<S> the key idea is to interpret each leaf of the amr hierarchy as one uniform compute patch in @xmath0 with @xmath1 degrees of freedom , where @xmath2 is customarily between 8 and 32 . </S>",
    "<S> thus , computation on each patch can be optimized for speed , while we inherit the flexibility of adaptive meshes . in our work </S>",
    "<S> we choose to integrate with the ` p4est`amr library since it allows us to compose the mesh from multiple mapped octrees and enables the cubed sphere and other nontrivial multiblock geometries . </S>",
    "<S> we describe aspects of the parallel implementation and close with scalings for both mpi - only and openmp / mpi hybrid runs , where the largest mpi run executes on 16,384 cpu cores .    ,    ,    and    adaptive mesh refinement , hyperbolic conservation laws , clawpack , hpc , manycore </S>"
  ]
}