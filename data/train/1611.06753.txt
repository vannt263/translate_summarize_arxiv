{
  "article_text": [
    "the portfolio choice problem has been an important topic in modern financial economics ever since the pioneer contribution by markowitz ( 1952 ) .",
    "it is well - known in the literature that constructing an optimal portfolio requires a good estimate for the second moment of the future return distribution , i.e. , the covariance matrix of the future returns .",
    "the simplest situation for estimating the covariance matrix is when the returns are independent and identically normally distributed ( iid ) over time . in this case , the maximum likelihood estimator ( mle ) is the sample covariance matrix and the efficiency of mle is justified asymptotically .    however , there are at least two problems for using the sample covariance matrix to select the optimal portfolio in practice . first ,",
    "when the portfolio size is large , the sample covariance matrix is found to lead to poor performances in the selected portfolio ; see jobson and korkie ( 1980 ) and michaud ( 1989 ) . not surprisingly , the sample covariance matrix is rarely used by practitioners when the portfolio size is large .",
    "the reason for the poor performances is due to the degree - of - freedom argument .",
    "that is , too many parameters have to be estimated in the covariance matrix when the portfolio size is large .",
    "in fact , if the portfolio size is larger than the number of time series observations in each asset , the sample covariance is always singular .",
    "second , the returns are not iid over time .",
    "this is because typically the covariance is time varying . in this case",
    ", the asymptotic justification for using the sample covariance matrix is lost .",
    "many alternative estimators of the large dimensional covariance matrix for portfolio choice have been proposed in the literature .",
    "a rather incomplete list includes ledoit and wolf ( 2003 , 2004 , 2014 ) , frahm and memmel ( 2010 ) , demiguel , garlappi , and uppal ( 2009 ) , demiguel , garlappi , nogales , and uppal ( 2009 ) , kan and zhou ( 2007 ) , fan , fan and lv ( 2008 ) , pesaran and zaffaroni ( 2009 ) , tu and zhou ( 2011 ) .",
    "most studies use dimension reduction techniques .",
    "one of the techniques uses factor ( either observed factors or latent factors ) models .",
    "another approach uses a statistical technique known as shrinkage , a method first introduced by stein ( 1956 ) .",
    "murihead ( 1987 ) reviewed the literature on shrinkage estimators of the covariance matrix .",
    "all these estimators are constructed from low frequency data ( daily , weekly or monthly data ) over a long period ( one year or more ) .",
    "however , if the investment period of a portfolio is much shorter ( say one day or one week or one month ) which is empirically more relevant , given the time varying nature of the covariance , we expect the covariance in the near future to be similar to the average covariance over an immediate recent time period but not to that over a long time period .",
    "hence , even if data over a long time period is available , one may only prefer using data over a short period . if low frequency data over a short time period are used , however , the degree - of - freedom argument will be applicable .",
    "the recent availability of quality high - frequency data on financial assets has motivated a growing literature devoted to the model - free measurement of covariances . in a recent study , fan , li and yu ( 2012 ) proposed to use high - frequency data to estimate the icv over a short time period for the purpose of portfolio choice .",
    "their setup allows one to impose gross exposure constraints .",
    "the use of gross exposure constraints plays a similar role to the no - short - sale constraint in jagannathan and ma ( 2003 ) .",
    "fan , li and yu ( 2012 ) demonstrated the substantial advantages of using high - frequency date in both simulation and empirical studies .",
    "there are several reasons why it is better to use high frequency data to estimate the covariance matrix .",
    "first , the use of high frequency data drastically increases the sample size .",
    "this is especially true for liquid assets .",
    "second , one does not need to assume returns are iid any more for establishing the large sample theory for the estimator .",
    "this generalization is important due to the time - varying nature of spot covariance .",
    "not surprisingly , the literature on estimating the icv based on high frequency data is growing rapidly .",
    "in this paper , we also use high frequency data to estimate the icv for the purpose of portfolio choice . unlike fan , li and yu ( 2012 ) where portfolio choice is done under pre - specified exposure constraints ,",
    "we focus our attention on how to get a good shrinkage estimator of the icv without any pre - specified constraint .",
    "this shift of focus is due to the lack of guidance on how to specify the gross exposure constraints .",
    "our estimator designs the shrinkage function as in ledoit and wolf ( 2014 ) . however , we differ from ledoit and wolf ( 2014 ) in the following important ways .",
    "first , instead of applying the shrinkage function to the eigenvalues of sample covariance matrix by assuming the returns are iid , we regularize the eigenvalues of a designed time variation adjusted ( tva ) * *  * * realized covariance matrix under the assumption that the covariance matrix is time varying .",
    "second , instead of using low frequency data , we use high frequency data for constructing the designed tva realized covariance matrix and estimating its regularized eigenvalues . we show that our proposed estimator , which will be given in section 3 , not only has some desirable properties in terms of estimating the icv , but also asymptotically achieves the minimum out - of - sample portfolio risk .    the paper is organized as follows . in section 2",
    "we set up the portfolio choice problem .",
    "section 3 introduces our estimator and discusses its properties and implementations . in section 4 ,",
    "we compare the out - of - sample performance of our proposed method with several methods proposed in the literature using actual data , including the equal weight , the linear shrinkage estimator of ledoit and wolf ( 2004 ) , and the high frequency method of fan , li and yu ( 2012 ) .",
    "section 5 concludes .",
    "the appendix collects the proof of our theoretical results .",
    "suppose that a portfolio is constructed based on a pool of @xmath0 assets whose log - price is denoted by @xmath4 , where @xmath5 denotes the transpose of the vector or matrix @xmath6 . instead of assuming @xmath7 follows a brownian motion which means that the log - returns are iid , we assume @xmath7 follows a more general diffusion process as @xmath8where @xmath9 is a @xmath0-dimensional drift process at time @xmath10 , @xmath11 is a @xmath12 ( spot ) covolatility matrix at time @xmath10 , and @xmath13 is a @xmath0-dimensional standard brownian motion .    a portfolio is constructed based on @xmath7 with weight @xmath14 which satisfies @xmath15 at time @xmath16 and a holding period @xmath17 , where @xmath18 is a @xmath0-dimensional vector with all elements being 1 . over the period @xmath19 $ ] , it has a return @xmath20 , and has a risk ( variance ) @xmath21with @xmath22 being the ( spot ) covariance matrix at time @xmath10 and @xmath23 denotes the expectation conditional on information up to time @xmath16 ( see fan , li and yu , 2012 ) . typically , the holding period @xmath17 is short ( say one day or one week or one month ) .    to focus on finding a good approximation for @xmath24",
    ", we consider the following global minimum variance ( gmv ) problem : @xmath25by taking the derivative of @xmath26 , we have the following theoretical optimal weight , @xmath27which is a function of the expected icv conditional on the current time @xmath16 , i.e. , @xmath28 .    denote the icv over the period @xmath29 $ ] by @xmath30if @xmath31 is small , following fan , li and yu ( 2012 ) , we use the following approximation @xmath32consequently , the theoretical optimal weight becomes @xmath33    the reason for choosing a small @xmath31 from the historical sample ( i.e. a small time span for @xmath29 $ ] ) to approximate the expected icv is due to the time varying and persistent nature of the covariance matrix .",
    "if a big @xmath31 ( say 10 years ) is used and an average covariance matrix is used to approximate the expected icv , the approximation errors would be inevitably large .",
    "in fact , as rightly argued in fan , li and yu ( 2012 ) , even when the true covariance matrices are available , an average of them will still lead to large approximation errors .",
    "let @xmath34 denote a generic ( invertible ) estimator of the icv @xmath35 . the plug - in estimator of the optimal portfolio weight for @xmath26 in ( [ min_risk_optimal_weightb ] ) is @xmath36we need to find the optimal @xmath34 for portfolio choice .",
    "given that the optimal portfolio is typically meant to perform the best out - of - sample , following ledoit and wolf ( 2014 ) , we define a loss function for portfolio selection to be the out - of - sample variance of portfolio returns conditional on @xmath34 , @xmath37where we approximate @xmath28 by @xmath38 and ignore the scale @xmath39 without any loss .",
    "the best estimator of the icv is therefore the one that minimizes the loss function @xmath40 .",
    "although this paper mainly focuses on the gmv problem , our estimation technique has a much wider implications for other problems that also require the estimation of icv , including the markowitz portfolios with and without estimating the conditional mean . in the empirical studies",
    ", we will show the usefulness of our proposed method in the context of the markowitz portfolio .",
    "denote the trading time points for the @xmath41th asset by @xmath42 with @xmath43 .",
    "it is difficult to estimate the icv based on tick - by - tick high frequency data when the number of stocks ( @xmath0 ) is large for the following reasons .",
    "first , data are always non - synchronous .",
    "second , data are contaminated by microstructure noises .",
    "denote @xmath44 the log - price of the @xmath41th asset at time @xmath45 and @xmath46 the latent log efficient price of the @xmath41th asset . then @xmath47where @xmath48 is the market microstructure noise at time @xmath45 .",
    "third , the spot covariance matrix @xmath49 of returns of latent log - price @xmath7 is time varying .",
    "fourth , the returns of the efficient price are not independent over time . to find a good estimator for the icv , we first introduce an initial estimator , denoted the time variation adjust ( tva ) realized covariance matrix , and discuss its disadvantages for estimating the icv in subsection [ initial estimator ] . to improve the initial estimator",
    ", we propose to regularize its eigenvalues . in subsection",
    "[ theoretical background for regularizing ] , we provide the theoretical background for regularizing the eigenvalues of tva realized covariance matrix .",
    "we then demonstrate how to regularize its eigenvalues in subsection [ regularized estimators of eigenvalues ] .      to simplify the problem , we propose the following structural assumption for @xmath7 .",
    "the same assumption was also used in zheng and li ( 2011 ) .",
    "( class @xmath50 ) .",
    "[ class_c ] suppose that @xmath7 is a @xmath0-dimensional process satisfying equation .",
    "we say that @xmath51 belongs to class @xmath50 if , almost surely , there exist @xmath52;\\mathbb{r})$ ] and @xmath53 a @xmath12 matrix satisfying @xmath54 such that @xmath55where @xmath56;\\mathbb{r})$ ] stands for the space of c@xmath57dl@xmath57 g functions from @xmath29 $ ] to @xmath58 .",
    "class @xmath50 allows the covariance matrix to be time varying because @xmath59 is time varying .",
    "the assumption of @xmath60 may be too strong than necessary but facilitates the mathematical proof of the results in the present paper .    if @xmath7 belongs to class @xmath50 , we can decompose @xmath61where @xmath62 is a diagonal matrix , @xmath63 an orthogonal matrix , and @xmath64 the eigen - decomposition of @xmath65 such that the eigenvalues and eigenvectors of @xmath66 are time varying and invariant respectively .    to estimate @xmath67 , zheng and li ( 2011 )",
    "proposed to use the so - called tva realized covariance matrix over the period @xmath29 $ ] , which is defined as @xmath68@xmath69 , and @xmath70 denotes the log efficient price @xmath71 at time @xmath72 for @xmath73    zheng and li ( 2011 ) demonstrated that @xmath74 is a good estimator for @xmath75 and @xmath76 is similar to the sample covariance matrix with iid samples . here",
    "similarity means that @xmath76 is a consistent estimator of population covariance matrix @xmath65 when @xmath0 is fixed , while the limiting spectral distribution of @xmath76 , which will be introduced later in the paper , is equivalent to that of the sample covariance matrix of iid samples generated from a distribution with zeros mean and population covariance @xmath65 , when @xmath0 goes to @xmath77 together with the sample size @xmath1 .",
    "clearly , the construction of tva requires a synchronous record of @xmath0 assets at @xmath78 .",
    "since data is always non - synchronous , we need to synchronize them . in this paper",
    ", we use the previous tick method ( see zhang , 2011 ) to interpolate the prices . however , the efficient price is latent due to the presence of microstructure noise . to deal with this problem",
    ", we suggest using sparse sampling so that the impact of microstructure noise can be ignored . based on a hausman type test",
    ", at - sahalia and xiu ( 2016 ) showed that when data are sampled every 15 minutes , the observed prices are free of the microstructure noise problem . in this paper",
    ", we will follow this suggestion by sampling the interpolated data every 15 minutes .",
    "denote @xmath79 the time stamps at every 15 minutes .",
    "so @xmath80 .",
    "denote the sparsely - sampled log - prices by @xmath81 .",
    "the feasible tva realized covariance matrix is constructed as @xmath82with @xmath83 .",
    "since @xmath84 has the same properties as @xmath85 , we treat @xmath84 the same as @xmath85 and only use @xmath85 in the rest of this paper .",
    "it is well - known that the eigenvalues of the sample covariance matrix are more spread out than those of the population covariance matrix .",
    "this property is applicable not only to the sample covariance matrix but also to @xmath86 .",
    "in other words , the smallest eigenvalues of @xmath86 tend to be biased downwards , while the largest ones upwards . as a result",
    ", there is a need to regularize the eigenvalues of @xmath86 .",
    "let us first introduce some concepts in the random matrix theory .",
    "let @xmath0 denote the number of variables and @xmath88 the sample size .",
    "for any @xmath12 symmetric matrix @xmath89 , suppose that its eigenvalues are @xmath90 , sorted in the non - increasing order .",
    "then the empirical spectral distribution ( esd ) of @xmath89 is defined as @xmath91 where @xmath92 denotes the indicator function of a set .",
    "the limit of esd as @xmath93 , if exists , is referred to the limiting spectral distribution ( lsd hereafter ) .",
    "let @xmath94 denotes the support interval of distribution function @xmath95 .",
    "for any distribution @xmath95 , @xmath96 denotes its stieltjes transform defined as @xmath97where @xmath98 denotes the imaginary part of a complex number .",
    "suppose the eigen - decomposition of @xmath85 is @xmath99where @xmath100 are eigenvalues of @xmath85 sorted in the non - increasing order , @xmath101 are corresponding eigenvectors .",
    "let @xmath102 denote a diagonal matrix with the diagonal elements being the diagonal elements of @xmath6 if @xmath6 is a matrix or being @xmath6 if @xmath6 is a vector .    to regularize the eigenvalues of @xmath86 , following ledoit and wolf ( 2014 ) , we restrict our attention to a class of rotation - equivalent estimators which is defined below .",
    "this strategy allows us to use a nonlinear shrinkage method to regularize the eigenvalues .",
    "however , different from ledoit and wolf ( 2014 ) , we do not assume returns are iid .",
    "instead we assume that @xmath7 @xmath103 .",
    "[ class_s](class of estimators @xmath104 ) .",
    "we consider a generic positive definite estimator for @xmath67 of the type @xmath105 , with @xmath106 being the eigenvalues of @xmath107 , @xmath108 being corresponding eigenvectors . here",
    "@xmath109 is a real univariate function and can depend on @xmath85 .",
    "we assume that there exists a nonrandom real univariate function @xmath110 , defined on @xmath111 and continuously differentiable , such that @xmath112 , for all @xmath113 , where @xmath114 denotes the lsd of @xmath86 .    here , @xmath115 is called the _ shrinkage function _ because what it does is to shrink the eigenvalues of @xmath116 by reducing the dispersion around the mean , pushing up the small ones and pulling down the large ones .",
    "the high dimensional asymptotic properties of @xmath116 are fully characterized by its limiting shrinkage function @xmath117 .",
    "as noted in stein ( 1975 ) and ledoit and wolf ( 2014 ) , the estimators in this class are rotation equivalent , a property that is desired when the user does not have any prior preference about the orientation of the eigenvectors .    since we consider the case that @xmath0 goes to @xmath77 together with the sample size , finding the optimal estimator of @xmath118 within class @xmath104 for portfolio selection is equivalent to finding the optimal shrinkage function @xmath117 that minimizes the limit of the loss function @xmath119 for @xmath120 .",
    "we have the following theorem to show the limit of @xmath119 .",
    "[ thm : limit_loss ] suppose that @xmath121 is a @xmath0 -dimensional diffusion process in class @xmath50 for some drift process @xmath122 , covolatility process @xmath123 and @xmath0-dimensional brownian motion @xmath124 , which satisfies the following assumptions :    ( a.i ) : :    @xmath125 for    @xmath126 $ ] , and @xmath127 is independent    of @xmath124 .",
    "( a.ii ) : :    there exists @xmath128 such that for all    @xmath0 , @xmath129 for all    @xmath126 $ ] almost surely ; ( a.iii ) : :    all eigenvalues of @xmath130 are bounded uniformly from 0 and    infinity ; ( a.iv ) : :    @xmath131 almost surely ; ( a.v ) : :    almost surely , as @xmath93 , the esd of    @xmath132 converges to a probability distribution    @xmath133 on a finite support ; ( a.vi ) : :    the observation time points @xmath72 s are independent    of the brownian motion @xmath13 and there exists    a constant @xmath134 such that    @xmath135 .",
    "if @xmath136 , then the esd of @xmath86 converges almost surely to a nonrandom probability distribution @xmath114 .",
    "if equation ( [ eige - decom of tva ] ) is satisfied , then @xmath137 where @xmath138 is in class @xmath104 by regularizing @xmath86 , @xmath117 is the limiting shrinkage function of @xmath139 . in addition , for all @xmath140 , @xmath141 is defined as @xmath142 , and @xmath143 is the stieltjes transform of the limiting spectral distribution of @xmath86 .",
    "theorem [ thm : limit_loss ] extends the result in proposition 3.1 of ledoit and wolf ( 2014 ) from the iid case to class @xmath50 and from the sample covariance to the tva realized covariance .    without loss of generality , if we assume that all the eigenvalues of @xmath34 and @xmath118 are bounded , @xmath144 and @xmath145 , so that @xmath146 .",
    "this is why we investigate the limiting behavior of @xmath147 in theorem [ thm : limit_loss ] .",
    "[ lem : func_d]under the assumptions of theorem [ thm : limit_loss ] , a generic positive - definite estimator @xmath148 within class @xmath104 minimizes the almost sure limit of the loss function @xmath149 if and only if its limiting shrinkage function @xmath150 satisfies @xmath151    lemma [ lem : func_d ] is a direct conclusion from theorem thm : limit_loss and proposition 4.1 of ledoit and wolf ( 2014 ) .",
    "unfortunately , the above minimization problem does not yield a closed - form solution for @xmath117 because of @xmath152 is unknown .",
    "in addition , finding @xmath152 and then @xmath117 is numerically difficult in practice . finding a good algorithm for estimating @xmath152 is of great interest as it was done in ledoit and wolf ( 2014 ) that used a commercial package .",
    "however , in this paper we propose to find an alternative interpretation of @xmath117 , which offers an easier way to approximate @xmath117 .",
    "motivated from ledoit and pch ( 2011 ) , we can show that @xmath117 in ( [ limit eqn of eigenvalues ] ) is equivalent to the asymptotic quantity corresponding to the oracle nonlinear shrinkage estimator derived from the following frobenius norm of the difference between @xmath153 and @xmath154 , i.e. , @xmath155where the frobenius norm is defined as @xmath156 for any real matrix @xmath6 .",
    "elementary matrix algebra shows that the solution is @xmath157to characterize the asymptotic behavior of @xmath158 , following the idea of ledoit and pch ( 2011 ) , we define the following non - decreasing function @xmath159    [ thm : lsd_d]assume that assumptions ( a.i)-(a.vi ) in theorem thm : limit_loss hold true and let @xmath160 be defined as in . if @xmath136 , then there exists a nonrandom function @xmath161 defined over @xmath58 such that @xmath162 converges almost surely to @xmath163 for all @xmath164 .",
    "if in addition @xmath165 , then @xmath161 can be expressed as @xmath166 where @xmath114 is the lsd of @xmath116 , and if @xmath167 , @xmath168    theorem [ thm : lsd_d ] extends the result in theorem 4 of ledoit and pch ( 2011 ) from the iid case to class @xmath50 .",
    "theorem [ thm : lsd_d ] implies that the asymptotic quantity that corresponds to @xmath169 is @xmath170 provided that @xmath171 corresponds to @xmath172 .",
    "an interesting finding is that the results of lemma [ lem : func_d ] and theorem [ thm : lsd_d ] are consistent with each other , even though they are motivated from two different perspectives . given that it is much easier to work on the minimization problem in ( [ sol of min fro ] ) , we recommend to regularize the eigenvalues of @xmath86 by using ( [ sol of min fro ] ) , which is to find a good estimator for each @xmath173 with @xmath43 .      [",
    "estimating the eigenvalues ]    note that @xmath174 is actually the integrated volatility of process @xmath175 over @xmath176 $ ] for @xmath177 .",
    "a natural estimator of each @xmath178 is the realized volatility @xmath179 .",
    "unfortunately , this is not a good idea . to see the problem , note that @xmath180let us consider the simplest case where @xmath181 , @xmath182 with @xmath183 be a @xmath0-dimensional identity matrix , and @xmath184 for @xmath185 . we can write @xmath186 with @xmath187 s are iid @xmath0-dimensional standard normals such that @xmath188 . since @xmath189 as @xmath93 , we have @xmath190by denoting @xmath191 , we have @xmath192which is actually the sample covariance matrix of iid samples generated from @xmath193",
    ". hence , its eigenvalues are also more spread out than that of @xmath194 , a well - known result in the literature .",
    "to solve this problem , we use the idea from abadir et al .",
    "( 2014 ) and lam ( 2016 ) by splitting the sample into two parts .",
    "we use the estimated eigenvectors from a fraction of the data to transform the data into approximately orthogonal series .",
    ", we examine the effectiveness of this method using real data later . ]",
    "we then use the independence of two sample covariance matrices to regularize the eigenvalues of one of them .",
    "therefore , instead of based @xmath195 on @xmath196 for @xmath197 , we base @xmath198 on @xmath199 for @xmath200where @xmath201 are the eigenvectors of @xmath202 corresponding to the eigenvalues with the non - increasing order , and the tva realized covariance matrix @xmath203 in addition , since the eigenvectors of @xmath49 is assumed to be time invariant , we also consider the following optimization problem @xmath204and estimate each diagonal element of the oracle minimizer @xmath205 with @xmath206 based on the data over the time period @xmath29 $ ] . to get an accurate estimator for each @xmath207 with @xmath208 , we propose to use all the tick - by - tick high frequency data and take into account with the microstructure noises .",
    "let us first consider the case that the data are synchronous and equally recorded at time points @xmath209 , where the time interval @xmath210 for all @xmath211 as @xmath212 and @xmath31 fixed .",
    "notice that here @xmath213 may be quite different from @xmath214 and @xmath215 can be one second or a few seconds , and should be much smaller than @xmath216 which is 15 minutes .",
    "we assume each observation is contaminated by microstructure noise such that @xmath217 ( observed ) contains the true log - price @xmath7 ( latent ) and the microstructure noise @xmath218 in an additive form @xmath219 ,   \\label{observed and latent}\\]]where the @xmath0-dimensional noise @xmath220 is assumed to satisfy    the @xmath0-dimensional noise @xmath221 at different time points @xmath222 are iid random vectors with mean @xmath223 ( a @xmath0-dimensional vector with all elements being 0 ) , positive definite covariance matrix @xmath224 and finite fourth moment .",
    "in addition , @xmath220 and @xmath7 are mutually independent .",
    "this assumption has commonly been used in the literature ; see , for example , at - sahalia et al .",
    "( 2010 ) , zhang ( 2011 ) , liu and tang ( 2014 ) . to estimate @xmath225",
    ", we apply the quasi - maximum likelihood ( qml ) approach developed in xiu ( 2010 ) .",
    "based on ( [ eqref ] ) and ( [ observed and latent ] ) , we have @xmath226by letting @xmath227such that @xmath228 .    ignoring the impact of @xmath229 by considering @xmath230",
    ", we follow the idea in xiu ( 2010 ) to give two misspecified assumptions for each @xmath208 .",
    "first , the spot volatility is assumed to be time invariant : @xmath231 .",
    "second , the noise @xmath232 is assumed to be normally distributed with mean 0 and variance @xmath233 . then the quasi - log likelihood function for @xmath234 is @xmath235where @xmath236 is a tridiagonal matrix with the diagonal elements being @xmath237 and the tridiagonal elements being @xmath238 , @xmath239 .",
    "the qml estimator of @xmath240 is the value of @xmath241 which maximizes @xmath242 .",
    "we denote the estimator of @xmath243 by @xmath244 , which is positive .",
    "xiu ( 2010 ) proved that @xmath244 is consistent and asymptotically efficient for @xmath245 .",
    "as discussed in xiu ( 2010 ) , if @xmath246s for @xmath211 are random and iid , we can add another misspecified assumption that they are equal .",
    "we then apply the above approach to get @xmath244 which is also a consistent estimator of @xmath247 .",
    "since the tick - by - tick data over the time period @xmath29 $ ] is typically non - synchronous , we propose to first synchronize data by the refresh time scheme of barndorff - nielsen et al .",
    "( 2011 ) and then apply the qml procedure to obtain @xmath248 .",
    "the first refresh time @xmath249 during a trading day is the first time when all assets have been traded at least once since @xmath250 .",
    "the second refresh time @xmath251 is the first time when all assets have been traded at least once since the first refresh point in time @xmath249 . repeating this sequence yields in total @xmath252 refresh times ,",
    "@xmath253 , and corresponding @xmath252 sets of synchronized refresh prices @xmath254 with each @xmath255 being the log - price of the @xmath41th asset nearest to and previous to @xmath256 .",
    "barndorff - nielsen et al .",
    "( 2011 ) showed that if the trading time of @xmath0 assets arrive as independent standard poisson processes with common intensity @xmath257 such that the mean of trading frequency of each asset over @xmath29 $ ] is @xmath258 , then the synchronized data obtained by the refresh time scheme is @xmath259 .",
    "based on this observation , if each of 100 ( or1,000 ) assets have around 20,000 observations within a trading day , then the number of synchronized observations is around 4,342 ( or 2,895 ) .",
    "while this sampling strategy loses around 78.3% or 85.5% of observations , it keeps much more data than the sparsely sampling technique at every 15 minutes , where the size is only 26 within a trading day .",
    "therefore , our shrinkage qml estimators for @xmath67 and @xmath260 are , respectively , @xmath261and our estimated optimal weight @xmath262 is obtained by replacing @xmath260 in ( min_risk_optimal_weightb ) with @xmath263 , @xmath264notice that like @xmath195 , @xmath198 can not be obtained directly from observations .",
    "we therefore approximate @xmath198 by the eigenvectors of @xmath265where @xmath266 , and @xmath267 s are the log - prices obtained by synchronizing all the trading prices of @xmath0 assets during @xmath268 via the previous tick method .",
    "in this section , we demonstrate the performance of our proposed method using real data .",
    "three portfolio sizes are considered ( @xmath269 and @xmath270 ) based on stocks traded in the u.s . markets .",
    "these portfolios are 30 dow jones industrial average ( 30 djia ) constituent stocks , 30 djia stocks and 10 stocks with the largest market caps ( ranked on march 30 , 2012 ) from s&p 500 other than 30 djia stocks , 30 djia stocks and 20 stocks with the largest market caps from s&p 500 other than 30 djia stocks .",
    "we download daily data starting from march 19 , 2012 and ending on december 31 , 2013 ( 450 trading days ) from the center for research in security prices ( crsp ) and 200 days intra - day data staring on march 19 , 2013 and ending on december 31 , 2013 from the taq database .",
    "the daily data are used to implement some existing methods in the literature for the purpose of comparison . for the high frequency data , the same data cleaning procedure as in barndorff - nielsen et al .",
    "( 2011 ) is applied to pre - process the data by 1 ) deleting entries that have 0 or negative prices , 2 ) deleting entries with negative values in the column of correlation indicator , 3 ) deleting entries with a letter code in the column of cond , except for e  or f , 4 ) deleting entries outside the period 9:30 a.m. to 4 p.m. , and 5 ) using the median price if there are multiple entries at the same time .      given that , in the empirical applications ,",
    "the basic unit is daily , we can summarize the proposed method as follows .",
    "suppose we want to construct a portfolio strategy at the end of the @xmath271th day ( which is denoted @xmath16 in previous sections ) based on a pool of @xmath0 assets with a holding period of @xmath272 days .",
    "we use the icv in the most recent @xmath273 days ( which is denoted @xmath29 $ ] in previous sections ) multiplied by @xmath274 to approximate the expected icv during the holding period.*step 1 : * split data of @xmath271 days into two parts .",
    "the first part contains data of first @xmath275 days , recorded as the @xmath276st , ... , @xmath275th days .",
    "the rest of data of @xmath273 days belong to the second part.*step 2 : * synchronize data in the @xmath277th day for each @xmath278 using the previous tick method at the 15-minute interval .",
    "denote the log - price at the 15-minute frequency by @xmath279.*step 3 : * synchronize the data in @xmath277th day for each @xmath280 using the refresh time scheme to obtain synchronous data and denote the log - price by @xmath281 for each @xmath280.*step 4 : * obtain the eigenvectors of @xmath282 ( the corresponding eigenvalues are sorted in the non - increasing order ) , and put them together as a @xmath12 matrix which is denoted by @xmath198",
    ". here @xmath283 .",
    "* step 5 : * obtain @xmath284 for @xmath285 .",
    "estimate the integrated volatility of the @xmath286th element of @xmath287 during the @xmath277th day by qml that maximizes ( [ qmlf - xiu ] ) with @xmath288 being replaced by @xmath289 and with @xmath290 being the @xmath41th element of @xmath291 .",
    "denote the estimator by @xmath292.*step 6 : * the sqml estimator of the icv in the @xmath277th day is defined as @xmath293 .",
    "we then use @xmath294 to approximate the expected icv during the holding period , and its inverse to approximate @xmath295 in ( [ qml weight ] ) to get the estimated optimal weight .    for the purpose of comparison , we consider two different @xmath296s .",
    "we denote the two different sqml estimators by sqrm if @xmath198 in step 4 is obtained from 15-minute intra - day data and sqrd if @xmath297 are the daily closing log - prices .",
    "we first consider the gmv portfolio problem ( [ gmv ] ) whose theoretical optimal weight is chosen by ( [ min_risk_optimal_weight ] ) . following the choice of many practitioners ,",
    "we apply the plug - in method to estimate the optimal weight and replace @xmath298 by its approximation , @xmath299 with different @xmath31s .",
    "we refer to brandt ( 2010 ) for a review of the impacts of a plug - in method in portfolio choice .",
    "we compare the out - of - sample performance of our proposed method with some other methods in the literature , including the equal weight ( denoted by ew ) , the weight estimated by plugging in the optimal linear shrinkage of the sample covariance matrix ( denoted by ls ) , the weight derived by the procedure suggested in fan , li and yu ( 2012 ) ( denoted by ts ) .",
    "after the weights are determined , the portfolios are constructed accordingly .",
    "ls is obtained by replacing @xmath300 in ( [ min_risk_optimal_weight ] ) with the inverse of the linear shrinkage estimator @xmath301where @xmath302 is the sample covariance matrix of previous @xmath303 daily log - returns , @xmath304 are the eigenvalues of @xmath305 , @xmath306 contains corresponding eigenvectors , @xmath307 , and @xmath308 is determined by the asymptotic optimization results derived in ledoit and wolf ( 2004 ) .",
    "fan , li and yu ( 2012 ) considered the following risk optimization problem under gross - exposure constraints @xmath309where @xmath67 was also used to approximate @xmath28 .",
    "the pair - wise two scales covariance ( tscv ) estimator of @xmath67 was constructed based on the high frequency data synchronized by the pair - wise refresh time scheme over previous @xmath310 trading days .",
    "since this pair - wise estimator may not be positive semi - definite , they projected the estimator ( denoted by @xmath6 here ) by @xmath311where @xmath312 is the negative part of the minimum eigenvalue of the estimator @xmath6 .",
    "they then minimize @xmath313 to obtain the optimal weight @xmath314 for a given @xmath315 . in this paper , following the simulation and the empirical studies in fan , li and yu ( 2012 ) , we set @xmath316 .    in practice ,",
    "one choice that we have to make is the number of days over which we do the estimation . for our new developed approach ,",
    "we let @xmath317 when we use daily log - returns , and let @xmath318 5 ( one week ) , 6 , ... , 21 ( one month ) days when we use 15-minute intra - day log - returns in step 4 .",
    "moreover , we choose @xmath319 .",
    "the optimal result among all possible combinations is reported .",
    "similarly , we report the optimal results for ls when @xmath320 and ts when @xmath321 , and denote them by tso , lso respectively .    the following three measures are calculated to compare the out - of - sample performance of all the methods during 174 investment days ( we have 200 days intra - day data in total and we use 26 days intra - day data to get sqrm ) , from april 25 , 2013 to december 31 , 2013 : ( 1 ) the average of log - returns of the portfolio multiplied by 252 ( denoted by av ) ; ( 2 ) the standard deviation of log - returns of the portfolio multiplied by @xmath322 ( denoted by sd ) ; ( 3 ) information ratio calculated by av / sd ( denoted by ir ) .    in general ,",
    "a high av and a high ir with a low sd are expected for a good portfolio . since the gmv portfolio is designed to minimize the variance of a portfolio ,",
    "the most important performance measure for gmv is sd .",
    "therefore , we first compare the standard deviations of different methods and then compare the information ratios and the average returns .    reported in table 1 are the av , sd and ir for all the methods .",
    "the number in the bold face represents the lowest sd .",
    "several conclusions can be made from table 1 .",
    "first and foremost , sqrm outperforms all the other strategies in terms of sd .",
    "sqrm also achieves the highest information ratio when @xmath323 .",
    "second , as expected , the standard deviation of the gmv portfolio decreases , as @xmath0 increases from 30 to 50 , for most methods .",
    "the only exception is the ew .",
    "third , sqrm performs better than sqrd , indicating that high frequency data are useful in portfolio choice .",
    "we now consider a ` full ' markowitz portfolio without any short - sale constraint .",
    "the markowitz portfolio minimizes the variance of a portfolio under two conditions : @xmath324where @xmath325 is a target expected return chosen by an investor and @xmath326 is a signal to denote the vector of expected returns of @xmath0 assets .",
    "the above problem has the following analytical solution @xmath327where @xmath328to choose @xmath329 and @xmath325 , we follow ledoit and wolf ( 2014 ) . in particular , the @xmath41th element of @xmath329 is the momentum factor which is chosen as the arithmetic average of the previous 250 days returns on the @xmath41th stock .",
    "@xmath325 is the arithmetic average of the momentums of the top - quintile stocks according to @xmath329 . in table 2 , we report the annualized av , sd , and ir of the daily log - returns for all methods , namely , sqrm , sqrd , ls , the equal weight constructed on top - quintile stocks according to their momentums ( denoted by ew - tq ) , and the method with @xmath330 in ( [ markowtiz with momentum ] ) being replaced by the inverse of the sample covariance matrix of previous @xmath331 days daily log - returns ( denoted by sp when @xmath332 ) . similar to the gmv portfolio , we choose optimal @xmath271 and @xmath275 for sqrm and sqrd . for the markowitz portfolio ,",
    "a more relevant criterion for the comparison is ir . in this paper , we first compare the irs and then the sds .    in table 2 ,",
    "the number in bold face represents the highest ir while the number with a ` * ' represents the lowest sd .",
    "it can be seen that sqrm and sqrd perform better than other methods in terms of ir except the ew when @xmath333 .",
    "however , the sds of sqrm and sqrd are much lower than that of ew and also lower than that of the other methods .",
    "to check the robustness of our strategy , we split the entire 174 investment days into two subperiods , one from april 25 , 2013 to august 27 , 2013 and the other from august 28 , 2013 to december 31 , 2013 .",
    "the results of the gmv portfolio are reported in tables 3 and 4 .",
    "it can be seen that sqrm and sqrd continue to outperform other methods in terms of sd in all cases .",
    "empirical results of the markowitz portfolio with the momentum signal are reported in tables 5 and 6 .",
    "again sqrm and sqrd continue to outperform other methods in almost all cases in terms of ir and sd .",
    "we also perform a moving - window analysis to check the robustness of our empirical results . staring from april 25 , 2013 ,",
    "we calculate the standard deviation of daily log - returns of each method over 42 trading days and repeat this exercise by moving one trading day at each pass . to compare our method with other methods , we use figures to show the results of tso , lso , sqrd and sqrm for the gmv portfolio and spo , lso , sqrd and sqrm for the mwm portfolio , where the optimal numbers of days chosen for each method is to minimize or maximize the mean of sds or irs of 133 different investment periods ( each investment period is 42 days ) for the gmv and mwm portfolio , respectively .",
    "figures 1 , 2 , 3 plot the results when @xmath334 30 , 40 and 50 .",
    "we find that sqrm performs better and better as the portfolio size increases .",
    "in general , it has the lowest sd and the highest ir for both the gmv portfolio and the mwm portfolios .",
    "this result indicates that high frequency data are useful in portfolio choice , especially for controlling the risk .      from a statistical perspective",
    ", a longer span of historical data contains more information about the dynamic of an asset price so that it may be reasonable to believe that methods based on a longer span of data should perform better than those based on less data .",
    "however , the model specification is more likely to be wrong over a longer span .",
    "hence there is a trade off between the estimation error and the specification error . in this subsection",
    "we examine this trade off empirically in the context of the ls portfolio and the sqrd portfolio . in particular ,",
    "the ls portfolio and the sqrd portfolio are constructed based on different historical data sets for the gmv portfolio . for ls ,",
    "we set @xmath335 . for sqrd",
    ", we fix @xmath336 and set @xmath317 .",
    "figure 4 plots the risk of daily log - returns for the two gmv portfolios  as a function of @xmath303 or @xmath275 when @xmath337 and @xmath323 .",
    "some interesting findings emerge .",
    "first , the risk of log - returns of a portfolio does not necessarily decrease when a longer span of historical data is used .",
    "second , sqrd performs better than ls in almost all cases and is more stable across different time spans .",
    "this is especially true when @xmath323 .",
    "once again , there is an advantage for using our estimator for portfolio selection .",
    "third , when @xmath337 , the risk of the sqrd portfolio decreases when @xmath275 increases initially . this is because more data are used in estimation , reducing the estimation error .",
    "however , the risk increases when @xmath338 .",
    "this is because the construction of sqrd relies on the assumption that @xmath339 .",
    "as @xmath275 increases , the time span becomes longer , and hence the assumption that @xmath339 is more likely to be invalid .",
    "this can also explain why sqrm performs better than sqrd .",
    "this paper has developed a new estimator for the icv and its inverse from high frequency data when the portfolio size @xmath0 and the sample size of data @xmath1 satisfies @xmath2 as @xmath1 goes to @xmath77 .",
    "the use of high frequency data drastically increases the sample size and hence reduces the estimation error . to further prevent the estimation error from accumulating with @xmath0 , a new regularization method",
    "is applied to the eigenvalues of an initial estimator of the icv .",
    "our proposed estimator of the icv is always positive definite and its inverse is the estimator of the inverse of the icv .",
    "it minimizes the limit of the out - of - sample variance of portfolio returns within the class of rotation - equivalent estimators .",
    "it works when the number of underlying assets is larger than the number of time series observations in each asset and when the asset price follows a general stochastic process .",
    "the asymptotic optimality for our proposed method is justified under the assumption that @xmath2 as @xmath1 goes to @xmath77 .",
    "the usefulness of our estimator is examined in real data .",
    "the method is used to construct the optimal weight in the global minimum variance and the markowitz portfolio with momentum signal based on the djia 30 and another 20 stocks chosen from s&p500 .",
    "the performance of our proposed method is compared with that of some existing methods in the literature .",
    "the empirical results show that our method performs favorably out - of - sample .",
    "in the appendix we first prove theorem [ thm : lsd_d ] as the proof of theorem [ thm : limit_loss ] relies on theorem [ thm : lsd_d ] .    by assumption ( a.i ) , we can write @xmath340 where ` @xmath341 ' stands for ` equal in distribution ' , @xmath342 and @xmath343 consists of independent standard normals",
    ". then @xmath344 where @xmath345 , @xmath346 .",
    "denote @xmath347    from theorem 2 of ledoit and pch ( 2011 ) , we know that @xmath348 converges to @xmath349 almost surely , where @xmath133 is the lsd of matrices @xmath350 and @xmath114 is the lsd of matrices @xmath351 or @xmath352 , since they share the same lsd by theorem 2 of zheng and li ( 2011 ) .    on the other hand , we have that @xmath353 is the stieltjes transform of the bounded function @xmath354 defined in by theorem 4 of ledoit and pch ( 2011 ) and the stieltjes transform of function @xmath355 is @xmath356 therefore we only need to show that @xmath357 to prove this , it suffices to show the following two facts : @xmath358 and @xmath359    to prove , by assumption ( a.iii ) , all the eigenvalues of @xmath360 are bounded , so that @xmath361 for all @xmath362 . from lemma 2.7 of bai and silverstein ( 1998 )",
    ", we have @xmath363 where the last step comes from the fact that the higher order moments of @xmath364 s are finite since they are normally distributed .",
    "thus , follows by the borel - cantelli lemma",
    ".      then , @xmath366 from assumptions ( a.ii)-(a.v ) , and the facts that @xmath367 , @xmath368 with @xmath369 denoting the @xmath370 norm of a matrix , and , we have that both @xmath371 and @xmath372 converge to 0 , almost surely .",
    "therefore , the proof of theorem [ thm : lsd_d ] is completed .",
    "the convergence of esd of @xmath352 is shown in theorem 2 of zheng and li ( 2011 ) .",
    "note that @xmath373 for some fixed number @xmath374 when @xmath0 large enough by assumption ( a.v ) and the fact that @xmath375 belongs to class @xmath376 .",
    "thus , from lemma 2.7 of bai and silverstein ( 1998 ) and borel - cantelli lemma , we have @xmath377 moreover , we have @xmath378 therefore , @xmath379                barndorff - nielsen , o. e. , hansen , p. r. , lunde , a. , shepard , n. , 2011",
    ". multivariate realised kernels : consistent positive semi - definite estimators of the covariation of equity prices with noise and non - synchronous trading .",
    "journal of econometrics 162 , 149 - 169 .",
    "stein , c. , 1956 .",
    "inadmissibility of the usual estimator for the mean of a multivariate normal distribution .",
    "_ in proceedings of the third berkeley symposium on mathematical statistics and probability _ , pages 197 - 206 .",
    "university of california press .",
    "@xmath337 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 20.13 & 13.22 & 13.22 & 15.31 & 12.96 & 10.59 & 15.62 + sd & 10.17 & 9.65 & 9.65 & 9.80 & 9.52 & 9.34 & * 9.17 * + ir & 1.98 & 1.37 & 1.37 & 1.56 & 1.36 & 1.80 & 1.70 + @xmath384 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 21.00 & 16.51 & 17.80 & 16.00 & 11.84 & 19.06 & 18.09 + sd & 10.43 & 9.66 & 9.62 & 9.85 & 9.29 & 9.29 & * 9.10 * + ir & 2.01 & 1.71 & 1.85 & 1.62 & 1.27 & 2.05 & 1.99 + @xmath323 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 21.00 & 20.15 & 20.15 & 13.28 & 10.25 & 17.74 & 20.52 + sd & 10.36 & 9.40 & 9.40 & 9.47 & 9.18 & 9.26 & * 8.68 * + ir & 2.03 & 2.14 & 2.14 & 1.40 & 1.12 & 1.91 & 2.36 +     @xmath337 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 31.74 & 0.02 & 4.18 & 13.02 & 13.02 & 20.02 & 15.91 + sd & 13.27 & 12.10 & 12.06 & 11.59 & 11 56 & 11.37 & @xmath385 + ir & * 2.39 * & 0.00 & 0.35 & 1.12 & 1.12 & 1.76 & 1.43 + @xmath384 & ew & sp & spo & ls & lso & sqrd & sqrm + av & 36.49 & 6.86 & 8.94 & 18.98 & 18.98 & 24.67 & 20.21 + sd & 13.55 & 10.90 & 10.99 & 11.29 & 10.66 & 11.25 & @xmath386 + ir & * 2.69 * & 0.63 & 0.81 & 1.68 & 1.68 & 2.19 & 2.01 + @xmath323 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 28.64 & 7.53 & 11.33 & 15.81 & 15.81 & 22.65 & 23.35 + sd & 13.16 & 10.42 & 10.80 & 10.60 & 10.60 & 10.51 & @xmath387 + ir & 2.18 & 0.72 & 1.05 & 1.49 & 2.03 & 2.15 & * 2.38 * +     @xmath337 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 5.23 & 2.23 & 2.23 & 2.63 & 9.90 & 2.93 & 1.87 + sd & 10.93 & 10.05 & 10.05 & 10.64 & 9.85 & 9.97 & *  9.81 * + ir & 0.48 & 0.22 & 0.22 & 0.25 & 1.00 & 0.29 & 0.19 + @xmath384 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 5.04 & 3.64 & 4.35 & 0.48 & 4.49 & 0.43 & 0.42 + sd & 11.09 & 10.26 & 10.00 & 10.51 & 9.45 & 9.78 & * 9.73 * + ir & 0.45 & 0.36 & 0.43 & 0.05 & 0.48 & 0.04 & 0.04 + @xmath323 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 6.53 & 9.35 & 9.35 & -1.78 & 8.29 & 1.70 & 5.70 + sd & 11.06 & 10.12 & 10.12 & 10.18 & * 9.18 * & 9.89 &  9.30 + ir & 0.59 & 0.92 & 0.92 & -0.17 & 0.89 & 0.17 & 0.61 +     @xmath337 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 35.04 & 24.22 & 24.22 & 27.99 & 16.02 & 30.70 & 29.36 + sd & 9.31 & 9.24 & 9.24 & 8.87 & 9.17 & 8.64 & * 8.45 * + ir & 3.76 & 2.62 & 2.62 & 3.15 & 1.75 & 3.55 & 3.48 + @xmath384 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 36.97 & 29.37 & 31.25 & 31.52 & 19.19 & 20.15 & 25.94 + sd & 9.69 & 9.01 & 9.19 & 9.09 & 9.16 & 8.54 & * 8.32 * + ir & 3.82 & 3.26 & 3.40 & 3.47 & 2.09 & 4.411 & 4.30 + @xmath323 & ew & ts & tso & ls & lso & sqrd & sqrm + av & 35.47 & 30.95 & 30.95 & 28.33 & 12.20 & 33.78 & 35.34 + sd & 9.60 & 8.64 & 8.64 & 8.67 & 9.05 & 8.52 & *  7.95 * + ir & 3.70 & 3.58 & 3.58 & 3.27 & 1.35 & 3.96 & 4.44 +     @xmath337 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 8.70 & -10.05 & -1.43 & -2.99 & -2.99 & 1.73 & 0.13 + sd & 14.51 & 13.02 & 13.03 & 12.54 & 12.54 & @xmath388 & 12.06 + ir & *  0.60 * & -0.81 & -0.11 & -0.24 & -0.24 & 0.01 & 0.04 + @xmath384 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 9.21 & -11.39 & -9.39 & -4.04 & -4.04 & 4.14 & -2.69 + sd & 14.19 & 10.91 & 10.94 & 11.45 & 10.99 & 11.49 & @xmath389 + ir & * 0.65 * & -1.04 & -0.86 & -0.35 & -0.35 & 0.36 & -0.26 + @xmath323 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 3.50 & -8.15 & 1.71 & -6.25 & -6.25 & 6.98 & 4.16 + sd & 14.28 & 11.01 & 10.48 & 10.92 & 10.92 & 10.84 & @xmath390 + ir & 0.25 & -0.74 & 0.16 & -0.57 & -0.57 & * 0.64 * & 0.40 +     @xmath337 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 54.79 & 10.59 & 9.79 & 29.02 & 29.02 & 39.95 & 31.35 + sd & 11.82 & 11.14 & 11.06 & 10.53 & 10.53 & 10.69 & @xmath391 + ir & * 4.64 * & 0.95 & 0.89 & 2.76 & 2.76 & 3.74 &  3.11 + @xmath384 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 63.78 & 25.11 & 27.28 & 41.99 & 41.99 & 45.21 & 43.11 + sd & 12.73 & 10.84 & 10.97 & 11.00 & 11.00 & 10.92 & @xmath392 + ir & * 5.01 * & 2.32 & 2.49 & 3.82 & 3.82 & 4.14 & 4.51 + @xmath323 & ew - tq & sp & spo & ls & lso & sqrd & sqrm + av & 53.77 & 23.20 & 20.94 & 37.87 & 37.87 & 38.31 & 42.54 + sd & 11.80 & 9.76 & 11.13 & 10.16 & 10.16 & 10.14 & @xmath393 + ir & 4.56 & 2.38 & 1.88 & 3.73 & 3.73 & 3.78 & * 4.70 * +"
  ],
  "abstract_text": [
    "<S> this paper examines the usefulness of high frequency data in estimating the covariance matrix for portfolio choice when the portfolio size is large . </S>",
    "<S> a computationally convenient nonlinear shrinkage estimator for the integrated covariance ( icv ) matrix of financial assets is developed in two steps . </S>",
    "<S> the eigenvectors of the icv are first constructed from a designed time variation adjusted realized covariance matrix of noise - free log - returns of relatively low frequency data . </S>",
    "<S> then the regularized eigenvalues of the icv are estimated by quasi - maximum likelihood based on high frequency data . </S>",
    "<S> the estimator is always positive definite and its inverse is the estimator of the inverse of icv . </S>",
    "<S> it minimizes the limit of the out - of - sample variance of portfolio returns within the class of rotation - equivalent estimators . </S>",
    "<S> it works when the number of underlying assets is larger than the number of time series observations in each asset and when the asset price follows a general stochastic process . </S>",
    "<S> our theoretical results are derived under the assumption that the number of assets ( @xmath0 ) and the sample size ( @xmath1 ) satisfy @xmath2 as @xmath3 . </S>",
    "<S> the advantages of our proposed estimator are demonstrated using real data .    _ some key words _ : portfolio choice , high frequency data ; integrated covariance matrix ; shrinkage function .    </S>",
    "<S> _ jel classification _ : c13 ; c22 ; c51 ; g12 ; g14 </S>"
  ]
}