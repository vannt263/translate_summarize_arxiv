{
  "article_text": [
    "the readout probability @xmath30 can be computed by tracking the belief state @xmath98^\\mathsf{t}$ ] , where @xmath99 is the probability that we believe the memory to be charged at the @xmath21 time step .",
    "we have @xmath100 where @xmath101 ( @xmath102 ) is the probability that we believe an empty ( charged ) memory becomes charged ( empty ) over the course of one time step . in the steady state @xmath103 . on the other hand",
    ", readout occurs when we believe @xmath6 other photons to be available , so we can write @xmath104 , where @xmath105 is the probability that we believe a source has provided a photon , either directly or through its memory . combining these relations we obtain the consistency condition @xmath106 , the positive real root of which can be found numerically , which then fixes @xmath30 ."
  ],
  "abstract_text": [
    "<S> single photons are a vital resource for optical quantum information processing . </S>",
    "<S> efficient and deterministic single photon sources do not yet exist , however . to date , experimental demonstrations of quantum processing primitives have been implemented using non - deterministic sources combined with heralding and/or postselection . </S>",
    "<S> unfortunately , even for eight photons , the data rates are already so low as to make most experiments impracticable . </S>",
    "<S> it is well known that quantum memories , capable of storing photons until they are needed , are a potential solution to this ` scaling catastrophe ' . here , we analyze in detail the benefits of quantum memories for producing multiphoton states , showing how the production rates can be enhanced by many orders of magnitude . </S>",
    "<S> we identify the quantity @xmath0 as the most important figure of merit in this connection , where @xmath1 and @xmath2 are the efficiency and time - bandwidth product of the memories , respectively .    </S>",
    "<S> after two decades of rapid advances , quantum optics experiments are becoming increasingly challenging . </S>",
    "<S> as the interests of the community shift to higher - dimensional entanglement @xcite and information processing tasks beyond mere proof - of - principle @xcite , the demand for large numbers of simultaneous single photons is outstripping the capabilities of parametric sources @xcite . </S>",
    "<S> these sources , which so far have been the workhorse of the quantum optics lab , produce photons in pairs , but they also produce multiple unwanted photon - pairs with a probability that scales with the single - pair generation rate , which must therefore be kept low , so that most often no photons are emitted . </S>",
    "<S> the current record for photonic resources is an eight - photon experiment involving four parametric sources , in which statistics were accumulated over 40 hours @xcite . </S>",
    "<S> the approach of accessing higher photon numbers by simply waiting longer is not sustainable .    in this paper </S>",
    "<S> we study the use of quantum memories to store and synchronise randomly - emitted heralded single photons as a means to efficiently construct the multiphoton states needed for quantum information processing with light @xcite . </S>",
    "<S> the development of quantum memories has historically been motivated by applications in quantum communications , where signals traverse large distances and long storage lifetimes are therefore required @xcite . while no currently available memory has the performance characteristics necessary for these demanding communications applications , we find that even inefficient memories , which are available now , can enhance the generation rate of multiphoton states by enormous factors . in this context , long storage times are not necessary , but a large time - bandwidth product is a key parameter .    the photonics scalability problem is easily understood . </S>",
    "<S> suppose that a single photon is heralded with probability @xmath3 . </S>",
    "<S> the probability of producing @xmath4 single photons simultaneously using @xmath4 sources is then simply @xmath5 , which becomes exponentially small as @xmath4 increases , thus rendering complex experiments impossible .    </S>",
    "<S> some kind of multiplexing strategy is necessary to mitigate this problem . in _ </S>",
    "<S> spatial multiplexing _ , sources are operated in parallel and their outputs are combined via active switching @xcite . </S>",
    "<S> many identical sources are required to achieve efficient operation @xcite . </S>",
    "<S> this may be achievable with emerging integrated optics platforms @xcite , but it is well - known that _ </S>",
    "<S> temporal multiplexing _ </S>",
    "<S> , where sources are operated many times in series and their outputs are synchronised using quantum memories , offers an alternative solution @xcite . in general , a hybrid approach involving both spatial and temporal multiplexing could be adopted . here </S>",
    "<S> we consider how temporal multiplexing allows to re - time probabilistic sources and boost the @xmath4-photon generation rate .    to see how quantum memories can increase the rate of @xmath4-fold coincidences , consider the array of @xmath4 sources coupled to @xmath4 memories shown in fig .  </S>",
    "<S> [ fig : array ] . </S>",
    "<S> we suppose that each source produces photons in pairs by means of a parametric scattering process such as downconversion @xcite or spontaneous four - wave mixing @xcite , with one of each pair directed to a herald detector . with no memories , </S>",
    "<S> all @xmath4 heralds must fire simultaneously to produce an @xmath4-fold coincidence . however with memories </S>",
    "<S> , heralded photons can be stored whenever they are produced . </S>",
    "<S> once @xmath6 of the memories are charged with a photon , one only has to wait for the final source to produce a photon , and then all the memories can be read out and one has , again , an @xmath4-fold coincidence . </S>",
    "<S> this protocol may not optimal , but it is amenable to a straightforward analysis that captures the scaling enhancement : by lifting the requirement for simultaneous emission , the memories greatly enhance the coincidence probability . </S>",
    "<S> our purpose in this paper is to quantify the gain in coincidence rate afforded by using quantum memories to synchronize photon sources in this way . </S>",
    "<S> the time - bandwidth product @xmath7 proves to be critical in this context , where @xmath8 is the acceptance bandwidth of the memories , and @xmath9 is their coherence lifetime . </S>",
    "<S> if postselection on the final detection of @xmath4 photons is used , even relatively inefficient memories can dramatically enhance the multiphoton rate .     </S>",
    "<S> heralded parametric sources synchronized by quantum memories . </S>",
    "<S> the sources are repeatedly pumped , and each photon emitted is stored until all but one of the memories are charged </S>",
    "<S> . then emission of a photon by the final source triggers retrieval from the memories , in order to generate an @xmath4-fold coincidence.,width=188 ]    some additional assumptions are needed to fully specify the protocol . </S>",
    "<S> first , we assume that we always attempt to store a photon , if a herald detector fires , regardless of whether or not the memory concerned is already charged . </S>",
    "<S> this ensures that we always use the most recently emitted photons , which mitigates photon loss due to decoherence in the memories . </S>",
    "<S> second , to avoid ` clashes ' ( in fact , interference @xcite ) between incident and stored photons , we also assume that we clean each memory before storage is attempted ( _ e.g. _ by readout of the memory , or optical pumping ) so that we are always attempting to charge an empty memory . </S>",
    "<S> this allows us to use a classical model , in which individual photons are treated as particles that are probabilistically emitted , stored and retrieved . </S>",
    "<S> finally , we adopt the policy that if we are ready to read out the memories  that is , if @xmath6 memories have been charged and a photon is emitted from the @xmath10 source  and at the same time one or more of the other sources emits a photon , we bypass the relevant memories and use these ` serendipitous ' photons , rather than attempting to read out the memories .    </S>",
    "<S> the photon sources are pumped at a rate @xmath11 , limited by the minimum pulse duration that can be stored by the memories . </S>",
    "<S> the average waiting time @xmath12 between @xmath4-photon events can then be computed if we can find an expression for the @xmath4-fold coincidence probability @xmath13 , which is the probability that one photon is obtained from each of the @xmath4 source - memory units . </S>",
    "<S> we have defined @xmath14 as the probability that any source - memory unit provides a photon on demand , either directly , or through successful retrieval of a stored photon . here </S>",
    "<S> @xmath15 is the steady - state probability that any memory is charged with a stored photon , @xmath16 is the retrieval efficiency , and the overbar notation denotes the probabilistic complement , @xmath17 . </S>",
    "<S> the problem of computing the waiting time then reduces to that of finding @xmath15 . to proceed we assume that the decoherence processes in the memories are markovian ( _ i.e. _ exponential ) , since then the stochastic evolution of the charge - state @xmath18^\\mathsf{t}$ ] of each memory can be tracked using a transfer matrix : @xmath19 with @xmath20 the probability that the memory is charged at the @xmath21 time step , @xmath22 the probability that an empty memory becomes charged over the course of one time step , and @xmath23 the probability that a charged memory becomes empty . </S>",
    "<S> the steady state probabilities are given by the eigenvector @xmath24 of @xmath25 with eigenvalue @xmath26 , @xmath27^\\mathsf{t}/(r+s)$ ] , so that we have @xmath28 . </S>",
    "<S> the probability that an empty memory becomes charged is the probability that a heralded photon is emitted and that it is stored , provided that the rest of the set - up is not primed for readout , so we have @xmath29 , where @xmath30 is the probability that the system is ready to be read out ( the evaluation of @xmath30 is described in the appendix ) , and @xmath31 is the storage efficiency . </S>",
    "<S> note that this storage efficiency can include any coupling or propagation losses between the source and the memory input . </S>",
    "<S> the loss probability that a charged memory is emptied is more complicated . </S>",
    "<S> the probability of decoherence during any time step is @xmath32 , where generally the time - bandwidth product will be much larger than one , so that @xmath33 . </S>",
    "<S> there are then four loss processes to consider . </S>",
    "<S> first , decoherence in the memory during standby ( @xmath34 ) , second , decoherence in the memory during the readout stage , when a photon is heralded and the memory is bypassed , leaving the memory charged and vulnerable to decay ( @xmath35 ) , third , readout of the memory when we attempt to generate a coincidence ( @xmath36 ) , and finally , the loss of a stored photon during standby when a new photon comes along and we attempt to replace the stored photon but fail ( @xmath37 ) . </S>",
    "<S> the total loss probability is then @xmath38 + \\overline{q}r + q\\overline{r}\\overline{\\eta}_\\mathrm{s}$ ] , and we finally obtain @xmath39}\\right\\}^n.\\ ] ] in the limit of small photon generation rates such that @xmath40 , we have @xmath41 , which supports the intuition that each memory effectively boosts the photon generation probability by @xmath2 , moderated by its efficiency @xmath42 . in this regime the gain in the multiphoton rate is therefore exponential in @xmath4 with the base quantity @xmath0 , which highlights the importance of the time - bandwidth product for synchronization applications . as @xmath2 </S>",
    "<S> is increased so that @xmath43 , the rate eventually saturates and becomes independent of @xmath2 , limited finally by @xmath1 . note that if the heralding detectors suffer dark counts with probability @xmath44 , one simply replaces the leading factor of @xmath5 in eq .  </S>",
    "<S> ( [ multiphoton ] ) with @xmath45 .    to make a fair comparison with the unsynchronized case </S>",
    "<S> , we now consider the effect of higher photon number components on the quality of the states produced . </S>",
    "<S> typically , parametric sources generate photon pairs according to a thermal distribution , where @xmath46 is the probability of emitting @xmath47 photon pairs , and @xmath48 is a small real number . </S>",
    "<S> we also assume non - photon - number - resolving heralding detectors , such as apds , so that the conditional probability that @xmath47 photons are sent towards a memory , given a herald click , is @xmath49p_\\mathrm{source}(n)/q$ ] where @xmath50 is the efficiency of the heralding detector , and as before @xmath51 $ ] is the probability of a herald click . </S>",
    "<S> the charge state @xmath52 of the memory is now a vector of probabilities that the memory contains @xmath47 photons , with @xmath53 , which we truncate for numerical convenience . </S>",
    "<S> the transition probability that the number of excitations stored in a memory changes from @xmath54 to @xmath55 over the course of any time step is given by the transfer matrix element @xmath56 where the three terms represent decoherence , readout , and storage , respectively . </S>",
    "<S> here @xmath57 for @xmath58 and zero otherwise ( since excitations are only lost through decoherence ) , and @xmath59 is a kronecker delta that describes the erasure of the memory after a read - out event . we have also defined @xmath60 as the probability that @xmath47 photons are stored in the memory when read - in is attempted after a herald , @xmath61 . </S>",
    "<S> repeated application of @xmath25 to an arbitrary initial charge state converges to the steady state @xmath24 , and the probability that @xmath47 photons are retrieved from the memory is then given by @xmath62 . </S>",
    "<S> we can then write the @xmath4-fold coincidence probability as @xmath63 , where @xmath64 is the probability that @xmath47 photons are successfully extracted from each of the source - memory units . </S>",
    "<S> this result for @xmath65 represents only a minor correction to eq .  </S>",
    "<S> ( [ multiphoton ] ) , but the treatment of multi - pair emissions is important for the fidelity calculation below .    to compare synchronised and unsynchronised systems , </S>",
    "<S> we calculate the fidelity of the @xmath4-mode states they produce with the ideal state of exactly one photon in each mode . </S>",
    "<S> the fidelity decreases exponentially with @xmath4 , so that according to this measure , even very high quality sources would have low fidelity for large @xmath4 . to capture the performance of individual sources synchronised with our scheme , we therefore normalise the fidelity to the number of modes by taking the @xmath10 root . </S>",
    "<S> this yields a measure @xmath66 that does not decay exponentially with @xmath4 , which can then be applied to benchmark individual components of a large device against some error correction threshold .    for the synchronised system , </S>",
    "<S> we obtain @xmath67^{1/n}$ ] , where @xmath68 is the probability that we believe we have produced an @xmath4 photon state ( see appendix ) . without memories , the @xmath4-fold coincidence rate is @xmath69^n$ ] and the normalised fidelity is simply given by @xmath70 . </S>",
    "<S> note that here we have ignored any losses ( such as fibre - coupling losses ) that could reduce @xmath71 , and so the results below are a conservative estimate of the benefits of synchronisation .    in many photonic networks </S>",
    "<S> , successful operations can be postselected on the final detection of at least @xmath4 photons . in this case </S>",
    "<S> the fidelity of the postselected states is the fraction of these which contain @xmath26 photon per mode , and the normalised postselected fidelity @xmath72 of the unsynchronised system is simply @xmath73 , since we assumed that the heralding already completely removed the vacuum component . for the synchronised system , </S>",
    "<S> the normalised postselected fidelity is @xmath74^{1/n}=\\left[\\frac{c_\\mathrm{sync}}{q - p_{<n}}\\right]^{1/n}.\\ ] ] here @xmath75 is the probability that the state obtained from the memories / sources comprises @xmath4 photons or more , and we have re - written this in terms of @xmath76 , the probability that fewer than @xmath4 photons in total are emitted , given by @xmath77 here @xmath78 is the @xmath79 element of a vector @xmath80 containing @xmath4 real , non - negative integers whose sum is equal to @xmath55 . </S>",
    "<S> the summation @xmath81 runs over all such vectors .    in general , neither postselected nor unpostselected fidelities for </S>",
    "<S> either synchronized or unsynchronized systems will reach 1 , except in the limit @xmath82 . </S>",
    "<S> therefore one must choose a threshold fidelity @xmath83 that is acceptable , and then one should choose the largest value @xmath84 of @xmath48 such that @xmath85 , for each system . </S>",
    "<S> having done this , one can then compare the @xmath4-fold coincidence rates . </S>",
    "<S> assuming for simplicity @xmath86 , we have @xmath87^{1/2}\\}/2\\overline{h}$ ] for an unsynchronised system , independent of @xmath4 . for the same number of synchronized sources </S>",
    "<S> , @xmath84 depends on @xmath4 and needs to be determined by a numerical optimisation . </S>",
    "<S> figure  [ fig : waiting_times ] shows the resulting comparison of synchronized and unsynchronized systems .    </S>",
    "<S> the waiting times scale exponentially with the number @xmath4 of photons required , and without synchronization a 12 photon experiment would require more than 30 years in between coincidence events , so that quantum computing with photons using such a system is totally unfeasible . </S>",
    "<S> however the use of memories reduces the waiting time quite dramatically . for </S>",
    "<S> a postselected experiment one can use inefficient memories with @xmath88 ( @xmath89 ) and reduce the 12-fold waiting time to @xmath90100  @xmath91s . </S>",
    "<S> quantum memories based on raman scattering have already been demonstrated with @xmath92  ghz @xcite , @xmath93 @xcite and @xmath94 @xcite , while highly efficient and multiplexed storage in rare - earth memories is maturing @xcite , and so these dramatic enhancements lie well within the reach of current technology . without postselection </S>",
    "<S> more efficient memories are required to achieve the fidelity threshold ( @xmath95 ) , which puts the implementation beyond current technological capabilities since @xmath96 efficiency has not yet been demonstrated . </S>",
    "<S> but if this improved performance were achieved , the waiting time would be further reduced to @xmath971  @xmath91s .    in summary , </S>",
    "<S> we have analyzed the use of quantum memories for the synchronization of multiple single photon sources as a canonical application of quantum storage for the enhancement of photonic information processing . </S>",
    "<S> we derived an analytic formula for the multiphoton rate achievable and showed that the most important figure of merit for quantum memories is the product @xmath0 of the memory efficiency with its time - bandwidth product . </S>",
    "<S> finally we extended our model to include higher - order photon number contributions , so that the quality of the states produced with and without memories could be compared . </S>",
    "<S> we showed that even inefficient memories can produce enormous improvements in the multiphoton rate when combined with postselection . without postselection , </S>",
    "<S> highly efficient memories are required to match the quality of unsynchronized sources , but if these are available the gain in multiphoton rate becomes larger still . </S>",
    "<S> it would be interesting to consider the effects of noise in the memories , or extensions to more complicated synchronization protocols . </S>",
    "<S> it is expected that similar advantages could pertain to the scaling of other heralded quantum operations , such as entanglement generation or two - photon gates . </S>",
    "<S> while much attention in the quantum memory community has focussed on the need for long storage times and high efficiencies in the context of quantum repeaters @xcite , our analysis underlines the value of developing quantum memories for local synchronization , for which lower efficiencies still provide considerable advantages , and for which the time - bandwidth product @xmath2 is much more important than the absolute storage time . </S>",
    "<S> this work was supported by the epsrc ( ep / c51933/01 ) , the ec project q - essence ( 248095 ) , the royal society , and the afosr eoard . </S>",
    "<S> xmj acknowledges support from nsfc ( 11004183 ) and cpsf ( 201003327 ) . </S>",
    "<S> nkl was supported by an ec marie - curie fellowship . </S>",
    "<S> mrs was supported by a clarendon scholarship . </S>",
    "<S> psm was supported by the ec itn fastquast . </S>",
    "<S> jn is grateful to marco barbieri for wearing him down . </S>"
  ]
}