{
  "article_text": [
    "the problem of numerically integrating a function comes up frequently in science and engineering .",
    "we consider the standardized problem of approximating the integral @xmath0^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}$ ] , that is , we assume that any transformations necessary to change from different domains and density functions have already been carried out .",
    "monte carlo algorithms use i.i.d . uniformly distributed samples @xmath12^s$ ] to approximate the integral by @xmath13 . for functions @xmath14^s)$ ]",
    "the monte carlo method has a root mean square error ( rmse ) of @xmath15 .",
    "an alternative to monte carlo is quasi - monte carlo . in this method one",
    "designs sample points which are more uniformly distribution with respect to some criterion ( in one dimension this criterion is the kolmogorov smirnov distance between the uniform distribution and the sample point distribution ) .",
    "these achieve a worst case error which decays with @xmath16 for any @xmath17 , see @xcite .",
    "owen  @xcite introduced a randomization of qmc which achieves a rmse of @xmath18 .",
    "owen s randomization method uses a permutation applied to digital nets ( which is a construction scheme for sample points used in quasi - monte carlo ) called scrambling .",
    "a slight improvement of owen s scrambling method of digital nets can be obtained by combining this approach with local antithetic sampling , see @xcite .",
    "therein it was shown that one obtains a convergence of the rmse of @xmath19 ( @xmath20 is the dimension of the domain ) .",
    "the latter three methods require that the function @xmath21 has some smoothness ( for instance continuous partial mixed derivatives up to order @xmath22 in each coordinate in the first two methods and continuous partial mixed derivatives up to order @xmath23 in each coordinate in the third method ) .",
    "no further improvement on the rate of convergence is obtained when one assume that the integrand has continuous higher order partial mixed derivatives in each variable .    in this paper",
    "we introduce a randomization of quasi - monte carlo algorithms ( which use digital nets as quadrature points ) such that the rmse converges with @xmath24 ( for any @xmath17 ) if the integrand has square integrable partial mixed derivatives up to order @xmath9 in each variable .",
    "this result holds for any @xmath25 and it is known that this result is best possible , see @xcite .    for the reader familiar with scrambled digital nets ,",
    "we briefly describe the algorithm .",
    "the details on scrambled digital nets will be given in the next section .",
    "the underlying idea of the new randomized qmc algorithm stems from @xcite .",
    "central to this method is the digit interlacing function with interlacing factor @xmath26 given by @xmath27 where @xmath28 for @xmath29 .",
    "let @xmath30 be a randomly scrambled digital @xmath31 net over the finite field @xmath32 of prime order @xmath33 ( we present the theoretical background on scrambled digital nets in the next section ) .",
    "let @xmath34 .",
    "then one simply uses the sample points @xmath35 the integral is then estimated using @xmath36 in theorem  [ thm_convergence ] we show that if the integrand has square integrable partial mixed derivatives of order @xmath37 in each variable , then the variance of @xmath38 satisfies @xmath39 = \\mathcal{o}(n^{-2\\min(d,\\alpha)-1+\\varepsilon})\\ ] ] for any @xmath17 , where @xmath40 is the number of sample points .    since scrambled digital nets ( based on sobol points )",
    "are included in the statistics toolbox of matlab , this method is very easy to implement ( an implementation can be found at . )      before we introduce the theoretical background , we present some simple numerical results which verify the convergence results .      in this example the dimension is @xmath22 and the integrand is given by @xmath41 .",
    "figure  [ fig1 ] shows the rmse from 300 independent replications . here",
    ", the straight lines show the functions @xmath42 , @xmath10 and @xmath11 .",
    "the other lines are the rmse where the digit interlacing factor @xmath43 is given by @xmath22 for the upper dashed line , @xmath23 for the dashed line in the middle and @xmath44 for the lowest of the dashed lines .",
    "figure  [ fig1 ] shows that in each case the rmse converges approximately with order @xmath45 ( for large enough @xmath2 ) .",
    "( the result for @xmath46 appears to perform even better than @xmath42 . )     and the standard deviation where @xmath46 , the blue lines show @xmath10 and the standard deviation where @xmath47 and the red lines show @xmath11 and the standard deviation where @xmath48 . ]    [ fig1 ]      we consider now a @xmath23 dimensional example where the integrand is given by @xmath49 .",
    "this function was also used in @xcite where the sample points are obtained by scrambling and local antithetic sampling .",
    "figure  [ fig2 ] shows again the rmse for @xmath50 independent replications .",
    "the straight lines show the functions @xmath42 and @xmath10 .",
    "the two dashed lines show the rmse when @xmath46 ( upper dashed line ) and when @xmath47 ( lower dashed line ) .",
    "figure  [ fig2 ] shows that in each case the rmse converges approximately with order @xmath45 ( for large enough @xmath2 ) .     and the standard deviation where @xmath46",
    ", the blue lines show @xmath10 and the standard deviation where @xmath47 . ]",
    "[ fig2 ]    in the following section we give the necessary background on qmc , digital nets , scrambling and walsh functions .",
    "we then prove in section  [ sec_proof ] what can be observed from the numerical results , namely , that if the integrand has square integrable partial mixed derivatives of order @xmath9 in each variable , then we obtain a convergence of the rmse of @xmath51 for any @xmath17 .",
    "a short discussion of the results is presented in section  [ sec_discussion ] .",
    "some properties of the digit interlacing function @xmath52 necessary for the proof is presented in appendix  a and a technical proof on the convergence of the walsh coefficients is presented in appendix  b.",
    "in this section we give the necessary background on qmc methods .",
    "some notation is required , which we now present .    in this section ,",
    "@xmath53 stand for generic constants which may differ in different places .    throughout the paper we assume that @xmath54 is a prime number .",
    "we always have @xmath55 , @xmath56 , @xmath57 , @xmath58 , @xmath59 , @xmath60 .",
    "quasi - monte carlo algorithms @xmath61 are used to approximate integrals @xmath62^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}$ ] . the difference to monte carlo is the method by which the sample points @xmath63 are chosen .",
    "the aim of qmc is to chose those points such that the integration error @xmath64^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d}{\\boldsymbol{x}}- \\frac{1}{n } \\sum_{n=0}^{n-1 } f({\\boldsymbol{x}}_n ) \\right|\\ ] ] achieves the ( almost ) optimal rate of convergence as @xmath65 for a class of functions",
    "@xmath66^s \\to \\mathbb{r}$ ] .",
    "for instance , for the set of all such functions @xmath21 which have bounded variation in the sense of hardy and krause , which we write as @xmath67 , it is known that the best rate of convergence for the worst case error is @xmath68^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}- \\frac{1}{n } \\sum_{n=0}^{n-1 } f({\\boldsymbol{x}}_n ) \\right| \\asymp n^{-1+\\varepsilon } \\quad \\mbox{for all } \\varepsilon > 0.\\ ] ] ( more precisely , there are constants @xmath53 such that @xmath69 , see @xcite . )    choosing the points @xmath70 randomly as in mc , does not yield this rate of convergence . even if a function has bounded variation in the sense of hardy and krause one obtains only a convergence of order @xmath1 for randomly chosen sample points .",
    "there is an explicit construction of the sample points @xmath71 for which the optimal rate of convergence is achieved .",
    "the essential insight is that the quadrature points need to be more uniformly distributed than what one obtains by choosing the sample points by chance .",
    "one criterion for how uniformly a set of points @xmath72 is distributed is the star discrepancy @xmath73^s } \\left|\\frac{1}{n } \\sum_{n=0}^{n-1 } 1_{{\\boldsymbol{x}}_i \\in [ { \\boldsymbol{0}},{\\boldsymbol{z } } ) } - \\mathrm{vol}([{\\boldsymbol{0}},{\\boldsymbol{z } } ) ) \\right|,\\ ] ] where @xmath74 with @xmath75 , @xmath76 , the volume of @xmath77 and @xmath78 when @xmath79 this becomes the kolmogorov - smirnov distance between the empirical distribution of the points and the uniform distribution .",
    "further we call @xmath80 the local discrepancy ( of @xmath81 ) .    the connection of this criterion to the integration error is given by the koksma - hlawka inequality @xmath64^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}- \\frac{1}{n } \\sum_{n=0}^{n-1 } f({\\boldsymbol{x}}_n )",
    "\\right| \\le d_n^\\ast(p_n ) \\|f\\|_{\\mathrm{hk}}.\\ ] ]    an explicit construction of point sets @xmath82 for which @xmath83 is given by the concept of digital nets , which we introduce in the next subsection .",
    "notice that for such a point set , the koksma - hlawka inequality implies the optimal rate of convergence of the integration error , since for a given integrand , the variation @xmath84 does not depend on @xmath81 and @xmath2 .",
    "a comprehensive introduction to digital nets can be found in @xcite .",
    "the aim is to construct a point set @xmath72 such that the star discrepancy satisfies @xmath85 .",
    "to do so , we discretize the problem by choosing the point set @xmath81 such that the local discrepancy @xmath86 for certain @xmath87^s$ ] ( those @xmath88 in turn are chosen such that the star discrepancy of @xmath81 is small , as we explain below )",
    ".    it turns out that , when one chooses a base @xmath54 and @xmath89 , then for every natural number @xmath90 there exist point sets @xmath91 such that @xmath92 for all @xmath75 of the form @xmath93 where @xmath94 is an integer and @xmath95 with @xmath96 . crucially , the value of @xmath97 can be chosen independently of @xmath90 ( but depends on @xmath20 ) .",
    "a point set @xmath81 which satisfies this property is called a @xmath98-net in base @xmath33 . an equivalent description of @xmath98-nets in base @xmath33 is given in the following definition .",
    "let @xmath54 , @xmath99 and @xmath100 be integers . a point set @xmath101",
    "is called a @xmath98-net in base @xmath33 , if for all nonnegative integers @xmath102 with @xmath103 , the elementary interval @xmath104 contains exactly @xmath105 points of @xmath106 for all integers @xmath107 .",
    "it can be shown that a @xmath98-net in base @xmath33 satisfies @xmath108 see @xcite for details .",
    "explicit constructions of @xmath98-nets can be obtained using the digital construction scheme .",
    "such point sets are then called digital nets ( or digital @xmath98-nets if the point set is a @xmath98-net ) .    to describe the digital construction scheme ,",
    "let @xmath33 be a prime number and let @xmath32 be the finite field of order @xmath33 ( a prime power and the finite field @xmath109 could be used as well ) .",
    "let @xmath110 be @xmath20 matrices of size @xmath111 with elements in @xmath32 and @xmath26 .",
    "the @xmath112th coordinate @xmath113 of the @xmath114th point @xmath115 of the digital net is obtained in the following way . for @xmath116",
    "let @xmath117 be the base @xmath33 representation of @xmath114 .",
    "let @xmath118 denote the vector of digits of @xmath114 .",
    "then let @xmath119 for @xmath120 we set @xmath121 the construction described here is slightly more general to the classical concept to suit our needs ( the classical construction scheme uses @xmath46 ) .",
    "in this framework we have that if @xmath122 is a digital @xmath31-net , then @xmath123 is a digital @xmath98-net .",
    "the search for @xmath98-nets has now been reduced to finding suitable matrices @xmath124 .",
    "explicit constructions of such matrices are available , see @xcite .      to analyze the rmse we use the walsh series expansions of the integrands .",
    "in this subsection we recall some basic properties of walsh functions used in this paper .",
    "first we give the definition for the one - dimensional case .",
    "[ defwalshfunc1d ] let @xmath125 be an integer and represent @xmath126 in base @xmath33 , @xmath127 , with @xmath128 .",
    "further let @xmath129 .",
    "then the @xmath130th walsh function @xmath131 in base @xmath33 is given by @xmath132 for @xmath133 with base @xmath33 representation @xmath134 ( unique in the sense that infinitely many of the @xmath135 are different from @xmath136 ) .",
    "we now extend this definition to the multi - dimensional case .",
    "[ defwalshfuncsd ] for dimension @xmath137 , @xmath138 , and @xmath139 , we define @xmath140 by @xmath141    as can be seen from the definition , walsh functions are piecewise constant . for @xmath142",
    "they are also related to haar functions .",
    "we need some notation to introduce some further properties of walsh functions . by @xmath143",
    "we denote the digitwise addition modulo @xmath33 , i.e. , for @xmath144 with base @xmath33 expansions @xmath145 and @xmath146 , we define @xmath147 where @xmath148 is given by @xmath149 , and let @xmath150 denote the digitwise subtraction modulo @xmath33 . in the same manner we also define a digitwise addition and digitwise subtraction for nonnegative integers based on the @xmath33-adic expansion . for vectors in @xmath151 or @xmath152 , the operators @xmath143 and @xmath150 are carried out componentwise . throughout this paper , we always use base @xmath33 for the operations @xmath143 and @xmath150 .",
    "further we call @xmath133 a @xmath33-adic rational if it can be written in a finite base @xmath33 expansion . in the following proposition ,",
    "we summarize some basic properties of walsh functions .",
    "[ propwalshfunc ]    1 .   for all @xmath153 and all @xmath144 , with the restriction that if @xmath154 are not @xmath155-adic rationals , then @xmath156 is not allowed to be a @xmath33-adic rational",
    ", we have @xmath157 2 .",
    "we have @xmath158 3 .   for all @xmath159 we have the following orthogonality properties : @xmath160 4 .",
    "for any @xmath161 and any @xmath162 we have @xmath163 5 .   for @xmath164 ,",
    "the system @xmath165 is a complete orthonormal system in @xmath166^s)$ ] .",
    "the proofs of @xmath167 are straightforward , and for a proof of the remaining items see @xcite or @xcite for more information .",
    "let @xmath168 and @xmath169 .",
    "let @xmath170 , where @xmath171 and @xmath172 for @xmath173 large enough . to analyze the rmse , it is convenient to extend the digit interlacing function @xmath52 to @xmath174 then we have @xmath175      the scrambling algorithm which yields the optimal rate of convergence of the rmse uses the digit interlacing function and the scrambling introduced by owen  @xcite , which we describe in the following .",
    "owen s scrambling algorithm is easiest described for some generic point @xmath176 , with @xmath57 and @xmath177 .",
    "the scrambled point shall be denoted by @xmath178 , where @xmath179 and @xmath180 .",
    "the point @xmath181 is obtained by applying permutations to each digit of each coordinate of @xmath182 .",
    "the permutation applied to @xmath183 depends on @xmath184 for @xmath185 .",
    "specifically , @xmath186 , @xmath187 , @xmath188 , and in general @xmath189 where @xmath190 is a random permutation of @xmath191 .",
    "we assume that permutations with different indices are chosen mutually independent from each other and that each permutation is chosen with the same probability .    to describe owen s scrambling , for @xmath192 let @xmath193 where for @xmath194 we set @xmath195 , be a given set of permutations and let @xmath196 .",
    "then , when applying owen s scrambling using these permutations to some point @xmath176 , we write @xmath197 , where @xmath181 is the point obtained by applying owen s scrambling to @xmath182 using the set of permutations @xmath196 . for @xmath133 we drop the subscript @xmath112 and just write @xmath198 .    to analyze the rmse it is also convenient to generalize owen s scrambling to higher order .",
    "we now describe what we mean by owen s scrambling of order @xmath168 for a generic point @xmath176 .",
    "the scrambled point @xmath178 is given by @xmath199 that is , one applies the inverse mapping @xmath200 ( see appendix a for more information on @xmath52 ) to the point @xmath182 to obtain a point @xmath201 , applies owen s scrambling of section  [ subsec_owenscr ] to @xmath88 to obtain a point @xmath202 and then use the transformation @xmath52 to obtain the point @xmath203 .    assuming that the permutations are all chosen with equal probability , then the point @xmath181 is uniformly distributed in @xmath151 .",
    "[ prop_uniform ] let @xmath176 and let @xmath204 be a uniformly and i.i.d .",
    "set of permutations .",
    "then @xmath205 is uniformly distributed in @xmath151 , that is , for any lebesgue measurable set @xmath206 , the probability that @xmath205 , denoted by @xmath207 = \\lambda_s(g)$ ] , where @xmath208 denotes the @xmath20-dimensional lebesgue measure .",
    "this result follows along the same lines as the proof of ( * ? ? ?",
    "* proposition  2 ) .",
    "a key result on scrambled nets is owen s lemma ( see @xcite ) which we now generalize to include the case of scrambling of order @xmath43 .",
    "let @xmath209 have base @xmath33 representation @xmath210 .",
    "for @xmath211 let @xmath212 where @xmath213 is the largest integer such that @xmath43 divides @xmath214 . if @xmath215 we set @xmath216 .    for @xmath217 and @xmath218 and for @xmath211",
    "let @xmath219 be the largest integer such that @xmath220 , and @xmath221 .",
    "[ rand_owen_lem1 ] let @xmath222 be two points obtained by applying owen s scrambling algorithm of order @xmath168 to the points @xmath223 .",
    "* if @xmath224 , then @xmath225 = 0.\\ ] ] * if @xmath226 and there exists an @xmath211 such that @xmath227 , then @xmath228 = 0.\\ ] ] * if @xmath226 and @xmath229 for @xmath211 , then @xmath230 = ( 1-b)^{-v},\\ ] ] where @xmath231    the proof of this result follows immediately from ( * ? ? ?",
    "* lemma  13.23 ) .    in the next section",
    "we analyze the variance of the estimator @xmath232 .",
    "let @xmath14^s)$ ] have the following walsh series expansion @xmath233 although we do not necessarily have equality in , the completeness of the walsh function system @xmath234 ( see @xcite ) implies that we do have @xmath235 = \\sum_{{\\boldsymbol{k}}\\in { { \\mathbb n}}_0^s } |\\widehat{f}({\\boldsymbol{k}})|^2 = { \\mathrm{var}}[s(\\cdot , f)].\\ ] ]    we estimate the integral @xmath0^s } f({\\boldsymbol{x } } ) { \\,{\\rm d}}{\\boldsymbol{x}}$ ] by @xmath236 where @xmath237 is obtained by applying a random owen scrambling of order @xmath43 to the digital @xmath98-net @xmath238 ( below we shall assume that there is a digital @xmath31-net @xmath239 such that @xmath240 for @xmath116 , but for now the assumption that @xmath106 is a digital @xmath98-net is sufficient ) . from proposition  [ prop_uniform ]",
    "it follows that @xmath241 = \\int_{[0,1]^s } f({\\boldsymbol{x } } ) { \\,{\\rm d}}{\\boldsymbol{x}}.\\ ] ]    hence in the following we consider the variance of the estimator @xmath38 denoted by @xmath242 = { { \\mathbb e}}[(\\widehat{i}(f ) - { { \\mathbb e}}[\\widehat{i}(f)])^2].\\ ] ]    the following notation is needed for the lemma below .",
    "let @xmath168 and @xmath243 , where @xmath244 .",
    "let @xmath245    we set @xmath246    consider @xmath79 for a moment .",
    ". then lemma  [ rand_owen_lem1 ] implies that for @xmath248 we have @xmath249 \\nonumber   \\\\ & & = { { \\mathbb e}}\\left [ { \\,_b{\\rm wal}}_{(k'_{1 } , \\ldots , k'_{d})}(\\mathscr{d}_d^{-1}(x)_{{\\boldsymbol{\\pi } } } ) \\overline{{\\,_b{\\rm wal}}_{(k'_{1 } , \\ldots , k'_{d})}(\\mathscr{d}_d^{-1}(x')_{{\\boldsymbol{\\pi } } } ) } \\right].\\end{aligned}\\ ] ] hence , for @xmath7 and @xmath250 , choose an arbitrary @xmath251 , and set @xmath252.\\ ] ] equation   implies that this definition is independent of the particular choice of @xmath253 .",
    "we call @xmath254 the _ gain coefficient ( of @xmath106)(of order @xmath43)_.    [ lem_var ] let @xmath168",
    ". let @xmath14^s)$ ] and @xmath236 where @xmath237 is obtained by applying a random owen scrambling of order @xmath43 to the digital net @xmath91 . then @xmath242 = \\sum_{{\\boldsymbol{l}}\\in \\mathbb{n}_0^{d s } \\setminus \\{{\\boldsymbol{0}}\\ } } \\sigma^2_{d,{\\boldsymbol{l}},s}(f)\\ , \\gamma_{d,{\\boldsymbol{l}}}(p_{b^m}).\\ ] ]    using the linearity of expectation and lemma  [ rand_owen_lem1 ] we get @xmath255   & = & { { \\mathbb e}}\\left[\\sum_{{\\boldsymbol{k}},{\\boldsymbol{k } } ' \\in \\mathbb{n}_0^s \\setminus \\{{\\boldsymbol{0}}\\ } } \\widehat{f}({\\boldsymbol{k } } ) \\overline{\\widehat{f}({\\boldsymbol{k } } ' ) } \\frac{1}{b^{2 m } } \\sum_{n , n ' = 0}^{b^m-1 } { \\,_b{\\rm wal}}_{{\\boldsymbol{k}}}({\\boldsymbol{y}}_n ) \\overline{{\\,_b{\\rm wal}}_{{\\boldsymbol{k}}'}({\\boldsymbol{y}}_{n ' } ) } \\right ] \\\\ & = & \\sum_{{\\boldsymbol{k}},{\\boldsymbol{k } } ' \\in \\mathbb{n}_0^s \\setminus \\{{\\boldsymbol{0}}\\ } } \\widehat{f}({\\boldsymbol{k } } ) \\overline{\\widehat{f}({\\boldsymbol{k } } ' ) } \\frac{1}{b^{2 m } } \\sum_{n , n ' = 0}^{b^m-1 } \\prod_{i=1}^s { { \\mathbb e}}\\left [ { \\,_b{\\rm wal}}_{k_i}(y_{n , i } ) \\overline{{\\,_b{\\rm wal}}_{k'_i}(y_{n',i } ) } \\right ] \\\\ & = & \\sum_{{\\boldsymbol{k}}\\in \\mathbb{n}_0^s \\setminus \\{{\\boldsymbol{0}}\\ } }    \\prod_{i=1}^s { { \\mathbb e}}\\left [ { \\,_b{\\rm wal}}_{k_i}(y_{n , i } ) \\overline{{\\,_b{\\rm wal}}_{k_i}(y_{n',i } ) } \\right ] \\\\ & = & \\sum_{{\\boldsymbol{l}}\\in \\mathbb{n}_0^{d s } \\setminus \\{{\\boldsymbol{0}}\\ } } \\sum_{{\\boldsymbol{k}}\\in b_{d,{\\boldsymbol{l}},s } } |\\widehat{f}(\\mathscr{d}_d({\\boldsymbol{k}}))|^2 \\\\ & & \\frac{1}{b^{2 m } } \\sum_{n , n ' = 0}^{b^m-1 } \\prod_{i=1}^s { { \\mathbb e}}\\left [ { \\,_b{\\rm wal}}_{(k_{d ( i-1 ) + 1 } , \\ldots , k_{d i})}(\\mathscr{d}_d^{-1}(x_{n , i})_{{\\boldsymbol{\\pi } } } \\ominus \\mathscr{d}_d^{-1}(x_{n',i})_{{\\boldsymbol{\\pi } } } ) \\right ] \\\\ & = & \\sum_{{\\boldsymbol{l}}\\in \\mathbb{n}_0^{d s } \\setminus \\{{\\boldsymbol{0}}\\ } } \\sigma^2_{d,{\\boldsymbol{l}},s}(f ) \\gamma_{d,{\\boldsymbol{l}}}(p_{b^m}).\\end{aligned}\\ ] ] hence the result follows .    to obtain a bound on the variance",
    "@xmath256 $ ] we prove bounds on @xmath257 and @xmath254 , which we consider in the following two subsections .      in this section",
    "we prove a bound on @xmath254 , where the point set is a digital @xmath98-net as constructed in @xcite .    [ lem_gamma ]",
    "let @xmath239 be a digital @xmath258-net over @xmath32 .",
    "let @xmath259 for @xmath260 .",
    "then the gain coefficients of order @xmath43 for the digital net @xmath238 satisfy @xmath261    let @xmath262 and @xmath263 for some @xmath264 . then from the proof of (",
    "* corollary  13.7 ) and ( * ? ? ?",
    "* lemma  13.8 ) it follows that @xmath265 \\\\ & = & \\frac{1}{b^{2 m } } \\sum_{n , n ' = 0}^{b^m-1 } \\prod_{i=1}^s { { \\mathbb e}}\\left [ { \\,_b{\\rm wal}}_{{\\boldsymbol{k}}}({\\boldsymbol{z}}_{n})_{{\\boldsymbol{\\pi } } } ) \\overline{{\\,_b{\\rm wal}}_{{\\boldsymbol{k}}}({\\boldsymbol{z}}_{n'})_{{\\boldsymbol{\\pi } } } ) } \\right ] \\\\ & = & \\left\\{\\begin{array}{ll } 0 & \\mbox{if } |{\\boldsymbol{l}}|_1 \\le m - t , \\\\ b^{|q|-|{\\boldsymbol{l}}|_1 } & \\mbox{if } m - t < |{\\boldsymbol{l}}|_1 \\le m - t+ |q| , \\\\ b^{-m+t } & \\mbox{if } |{\\boldsymbol{l}}|_1 > m - t + |q| .",
    "\\end{array } \\right.\\end{aligned}\\ ] ] hence the result follows .      in this subsection we state",
    "a bound on @xmath266 .",
    "the rate of decay of @xmath266 depends on the smoothness of the function @xmath21 .",
    "we measure the smoothness using a variation based on finite differences , which we introduce in the following .",
    "since the smoothness of the function @xmath21 may be unknown , we can not assume that we can choose @xmath43 to be the smoothness .",
    "hence , in the following we use @xmath9 to denote the smoothness of the integrand @xmath21 .",
    "we use a slight variation from classical finite differences .",
    "let @xmath66\\to\\mathbb{r}$ ] and let @xmath267 be a sequence of numbers",
    ". then we define @xmath268 and for @xmath37 we set @xmath269 for instance , we have @xmath270 and in general @xmath271 where @xmath272 denotes the number of elements in @xmath273 .",
    "we always assume that @xmath274 $ ] for all @xmath275 .",
    "if @xmath21 is @xmath9 times continuously differentiable , then the mean value theorem implies that @xmath276 where @xmath277 . by induction",
    ", it then follows that @xmath278 where @xmath279    we generalize the difference operator to functions @xmath66^s\\to\\mathbb{r}$ ] .",
    "let @xmath25 be a nonnegative integer .",
    "let @xmath280 be the one - dimensional difference operator @xmath281 applied to the @xmath112th coordinate of @xmath21 .",
    "for @xmath282 and @xmath192 let @xmath283 . then we define @xmath284    if @xmath21 has continuous mixed partial derivatives up to order @xmath9 in each variable , then , as for the one - dimensional case , we have @xmath285 where we set @xmath286 for @xmath287 and where @xmath288 for @xmath192 .",
    "again we assume that @xmath289 $ ] for all @xmath290 , @xmath291 $ ] for all @xmath292 and @xmath192 .",
    "let @xmath66^s\\to\\mathbb{r}$ ] and @xmath25 be a nonnegative integer .",
    "let @xmath293 , with @xmath294 and @xmath295 for @xmath296 .",
    "apart from at most a countable number of points , the set @xmath297 is the product of a union of intervals .",
    "let @xmath298 .",
    "then we define the generalized vitali variation by @xmath299 where the first supremum @xmath300 is extended over all partitions of @xmath301 into subcubes of the form @xmath293 with @xmath294 and @xmath302 for @xmath296 , and the second supremum is taken over all @xmath303 and @xmath304 with @xmath305 where @xmath306 for @xmath307 and @xmath192 and such that all the points at which @xmath21 is evaluated in @xmath308 are in @xmath309 .",
    "in appendix a it is shown that @xmath310 , the volume ( i.e. lebesgue measure ) of @xmath311 . hence",
    ", if the partial derivative @xmath312 are continuous for a given @xmath313 , then it can be shown that and the mean value theorem imply that the sum   is a riemann sum for the integral @xmath314^s } \\left| \\frac{\\partial^{\\alpha_1 + \\cdots + \\alpha_s } f}{\\partial x_1^{\\alpha_1 } \\cdots \\partial x_s^{\\alpha_s}}({\\boldsymbol{x } } ) \\right|^2 \\,\\mathrm{d } { \\boldsymbol{x}}\\right)^{1/2}.\\ ] ]    for @xmath315 , let @xmath316 denote the number of elements in the set @xmath317 and let @xmath318 be the generalized vitali variation with coefficient @xmath319 of the @xmath316-dimensional function @xmath320^{s-|u| } } f(\\boldsymbol{x } ) \\,\\mathrm{d } \\boldsymbol{x}_{\\{1,\\ldots , s\\}\\setminus u}.\\ ] ] for @xmath321 we have @xmath322^s } f(\\boldsymbol{x})\\,\\mathrm{d } \\boldsymbol{x}$ ] and we define @xmath323 .",
    "then @xmath324 is called the generalized hardy and krause variation of @xmath21 of order @xmath9 . a function @xmath21",
    "for which @xmath325 is finite is said to be of bounded variation ( of order @xmath9 ) .",
    "if the partial derivatives @xmath326 are continuous for all @xmath327 , then variation coincides with the norm @xmath328^{|u| } } \\left|\\int_{[0,1]^{s-|u| } } \\frac{\\partial^{\\sum_{i\\in u } \\alpha_i }",
    "f}{\\prod_{i\\in u } \\partial x_i^{\\alpha_i } } \\,\\mathrm{d } { \\boldsymbol{x}}_{\\{1,\\ldots , s\\ } \\setminus u } \\right|^2 \\,\\mathrm{d } { \\boldsymbol{x}}_u \\right)^{1/2}.\\ ] ]      the following lemma gives a bound on @xmath266 for functions @xmath21 of bounded variation of order @xmath9 .",
    "[ sec_rand_bound_sigma ] let @xmath329 .",
    "let @xmath66^s \\to { { \\mathbb r}}$ ] with @xmath330 .",
    "let @xmath54 be an integer .",
    "let @xmath331 and let @xmath332 .",
    "let @xmath333 and @xmath334 for @xmath192 .",
    "let @xmath335 for @xmath336 and @xmath192 .",
    "let @xmath337 for @xmath192 be such that @xmath338 , that is , @xmath339 is just a reordering of the elements of the set @xmath340 .",
    "set @xmath341 .",
    "then @xmath342    the proof of this result is technical and is therefore deferred to appendix  b.      we can now use lemmas  [ lem_var ] , [ lem_gamma ] and [ sec_rand_bound_sigma ] to prove the main result of the paper .",
    "[ thm_convergence ] let @xmath329 .",
    "let @xmath66^s\\to\\mathbb{r}$ ] satisfy @xmath343 .",
    "let @xmath344 where @xmath345 with @xmath346 and @xmath347 is a digital @xmath31-net and the permutations in @xmath204 are chosen uniformly and i.i.d .. then @xmath39 \\le c_{b , s,\\alpha } v_\\alpha(f )   \\frac{(m - t)^{\\min(\\alpha , d ) s+ s}}{b^{-(2 \\min(\\alpha , d ) + 1)(m - t)}},\\ ] ] where @xmath348 is a constant which depends only on @xmath349 , but not on @xmath90 .",
    "let @xmath350 .",
    "then from lemmas  [ lem_var ] , [ lem_gamma ] , [ sec_rand_bound_sigma ] and the fact that @xmath351 we obtain that @xmath352 & \\le & v_\\alpha(f ) ( b-1)^{2d s } b^{s + d(d-1 ) } b^{-(m - t+1 ) } \\sum_{{\\boldsymbol{l}}\\in \\mathbb{n}_0^{d s } , |{\\boldsymbol{l}}|_1 > m - t } b^{-2 d |{\\boldsymbol{l}}|_1 } \\\\ & \\le &   v_\\alpha(f ) ( b-1)^{2 d s } b^{s",
    "+ d ( d - 1 ) } b^{-(m - t+1 ) } \\sum_{k = m - t+1}^\\infty b^{-2 d k } \\binom{k+ d s-1 } { d s-1 } \\\\",
    "& \\le & v_\\alpha(f ) ( b-1)^{2ds } ( b^{2d}-1)^{-ds } b^{2",
    "d^2 s + s + d ( d - 1 ) } b^{-(2d + 1)(m - t+1 ) } \\binom{m - t+ d s } { d s-1}\\end{aligned}\\ ] ] where we used ( * ? ? ?",
    "* lemma  13.24 ) . since @xmath353",
    "we obtain @xmath39   \\le   c_{\\alpha , b , d , s } v_\\alpha(f ) b^{-(2d + 1 ) ( m - t ) } ( m - t+2)^{d s-1},\\ ] ] for some constant @xmath354 which depends only on @xmath349 .",
    "let now @xmath355 . in the following we sum over all @xmath356 where @xmath244 , and such that @xmath357 .",
    "let @xmath358 be such that @xmath359 , that is , the @xmath360 are just a reordering of the elements @xmath361 .",
    "there are at most @xmath362 reorderings which yield the same @xmath363",
    ". then we have @xmath364    hence we have @xmath365   \\le v_\\alpha(f ) 4^{s(d-\\alpha ) } ( b-1)^{2\\alpha } b^{s+d(d-1 ) } ( d!)^s b^{-(m - t+1 ) } \\sum_{\\stackrel{{\\boldsymbol{l}}\\in \\mathbb{n}_0^{ds } , |{\\boldsymbol{l}}|_1 > m - t}{{\\boldsymbol{l}}\\mbox { { \\tiny ordered } } } } b^{-2d \\sum_{i=1}^s \\sum_{j=1}^\\alpha l_{(i-1)d+j}},\\ ] ] where @xmath366 ordered means that @xmath367 for @xmath192 .",
    "hence we have @xmath368 let now @xmath369 .",
    "then @xmath370 for @xmath371 and @xmath372 .",
    "hence @xmath373 thus the result follows from .",
    "in this paper we have extended the results of @xcite , by introducing an algorithm and proving that this algorithm can take advantage of the smoothness of the integrand @xmath9 , where @xmath374 can be arbitrarily large .",
    "theorem  [ thm_convergence ] shows the convergence rate of the standard deviation of the estimator @xmath38 of @xmath375 .",
    "the numerical results in section  [ sec_numerical ] using some toy examples also exhibit this rate of convergence .",
    "the upper bound is best possible ( apart from the power of the @xmath376 factor ) , since there is also a lower bound on the standard deviation , see @xcite .    the improvement in the rate of convergence in @xcite has been obtained by using variance reduction techniques .",
    "conversely , one might now ask whether the methods developed here can be used to obtain new variance reduction techniques .",
    "( some similarities between this approach and antithetic sampling can be found in @xcite . )",
    "this is an open question for future research .",
    "since the classical scrambling by owen  @xcite is computationally to expensive , variations of this scrambling scheme have been introduced which can easily be implemented .",
    "matouek  @xcite describes an alternative scrambling which uses less permutations and is therefore easier to implement , see also @xcite .",
    "another scrambling scheme which can be implemented is by tezuka and faure  @xcite .",
    "see also @xcite for overviews of various scramblings .",
    "the idea is to reduce the number of permutations required such that owen s lemma still holds .",
    "since the proof of lemma  [ rand_owen_lem1 ] follows along the same lines as the proof of owen s lemma , the simplified scramblings mentioned above also apply here .    the only alternative algorithm which achieves the same convergence rate of the rmse as proven here",
    "is based on using an approximation @xmath377 to the integrand @xmath21 and then applying mc to @xmath378 .",
    "the integral is then approximated by @xmath379^s } a(f)({\\boldsymbol{x}})\\,\\mathrm{d } { \\boldsymbol{x}}$ ] where @xmath0^s } a(f)({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}$ ] can be calculated analytically .",
    "see @xcite for details .",
    "the digit interlacing function has several properties which we investigate in the following and which we use below .",
    "let @xmath380 .",
    "then the mapping @xmath381 is injective but not surjective .",
    "it suffices to show the result for @xmath79 .",
    "first note that the digit expansion of @xmath382 is never of the form @xmath383 , since this would imply that there is a @xmath384 , @xmath385 , which is a @xmath33-adic rational .",
    "but in this case we use the finite digit expansions of @xmath384 and hence no vector @xmath386 gets mapped to this real number .",
    "thus @xmath52 is not surjective .    to show that @xmath52 is injective , let @xmath387 .",
    "hence there exists an @xmath388 such that @xmath389 , and hence there is a @xmath390 such that @xmath391 , where @xmath392 and @xmath393 ( and where we use the finite expansions for @xmath33-adic rationals ) .",
    "thus the digit expansions of @xmath394 and @xmath395 differ at least at one digit and hence @xmath396 .",
    "( notice that a countable number of elements could be excluded from the set @xmath397 such that @xmath52 becomes bijective . )",
    "let @xmath168 and @xmath398^{d s}$ ] with @xmath399 for @xmath400 .",
    "let @xmath401 denote the lebesgue measure on @xmath402",
    ". then @xmath403 .",
    "the result is trivial for @xmath404 .",
    "let now @xmath380 .",
    "consider @xmath79 .",
    "let @xmath405 , where @xmath406 is an integer and @xmath407 for some integers",
    "@xmath408 . let @xmath409 , @xmath410 and @xmath411",
    ". then @xmath412 .",
    "consider now @xmath413 .",
    "let @xmath414 .",
    "we have @xmath415 where the union is over all @xmath416 with expansion as above and where @xmath417 for @xmath418 and @xmath419 .",
    "hence there are @xmath420 free to choose .",
    "therefore @xmath421 therefore the result holds for intervals of the form @xmath311 .",
    "it follows that the result holds for intervals of the form @xmath422 , since this interval is simply a product of the previously considered intervals .",
    "let now @xmath423 , with @xmath424 for @xmath400 , be an arbitrary interval .",
    "since this interval can be written as a disjoint union of the elementary intervals used above , the result also holds for these intervals .",
    "let @xmath425 and @xmath426 for @xmath427",
    ". then @xmath428 . on the other hand",
    ", define @xmath429 where @xmath430 is large enough such that @xmath431 for all @xmath400 . set @xmath432 . then @xmath433 hence @xmath434",
    "assume first that @xmath435 . let @xmath436 and let @xmath437 . let @xmath438 .",
    "first assume that @xmath439 for @xmath440 .",
    "let @xmath450 , then @xmath451^s } f({\\boldsymbol{t } } ) \\sum_{{\\boldsymbol{k}}\\in a_{{\\boldsymbol{l } } } } { \\,_b{\\rm wal}}_{\\mathscr{d}_{d}({\\boldsymbol{k}})}({\\boldsymbol{x}}\\ominus { \\boldsymbol{t } } ) { \\,{\\rm d}}{\\boldsymbol{t}}\\\\ & = & b^{|{\\boldsymbol{l}}|_1 } \\int_{\\mathscr{d}_d([{\\boldsymbol{a}}b^{-{\\boldsymbol{l } } } , ( { \\boldsymbol{a}}+{\\boldsymbol{1}})b^{-{\\boldsymbol{l } } } ] ) } f({\\boldsymbol{t } } ) { \\,{\\rm d}}{\\boldsymbol{t}}.\\end{aligned}\\ ] ] for @xmath452 and @xmath453 let @xmath454 ) } f({\\boldsymbol{t}}){\\,{\\rm d}}{\\boldsymbol{t}}.\\ ] ]        we can simplify the inner sum further .",
    "let @xmath462 , i.e. the @xmath112th component of @xmath463 is given by @xmath464 .",
    "further let @xmath465 , i.e. the @xmath112th component of @xmath466 is given by @xmath467 .",
    "then we have @xmath468 where we extend the digit interlacing function @xmath52 to negative values by using digits in @xmath469 in case a component is negative . to shorten the notation we set @xmath470",
    "using cauchy - schwarz inequality we have @xmath472 ) } |\\delta_{{\\boldsymbol{k}}}({\\boldsymbol{t}})| { \\,{\\rm d}}{\\boldsymbol{t } } } \\\\ & \\le   & \\left ( \\int_{\\mathscr{d}_d([{\\boldsymbol{a}}b^{-{\\boldsymbol{l } } } , ( { \\boldsymbol{a}}+{\\boldsymbol{1 } } ) b^{-{\\boldsymbol{l } } } ] ) } 1 { \\,{\\rm d}}{\\boldsymbol{t}}\\right)^{1/2 } \\left ( \\int_{\\mathscr{d}_d([{\\boldsymbol{a}}b^{-{\\boldsymbol{l } } } , ( { \\boldsymbol{a}}+{\\boldsymbol{1 } } ) b^{-{\\boldsymbol{l } } } ] ) } |\\delta_{{\\boldsymbol{k}}}({\\boldsymbol{t}})|^2 { \\,{\\rm d}}{\\boldsymbol{t}}\\right)^{1/2 } \\\\ & = & b^{-|{\\boldsymbol{l}}|_1 /2 } \\left ( \\int_{\\mathscr{d}_d([{\\boldsymbol{a}}b^{-{\\boldsymbol{l } } } , ( { \\boldsymbol{a}}+{\\boldsymbol{1 } } ) b^{-{\\boldsymbol{l } } } ] ) } |\\delta_{{\\boldsymbol{k}}}({\\boldsymbol{t}})|^2 { \\,{\\rm d}}{\\boldsymbol{t}}\\right)^{1/2}.\\end{aligned}\\ ] ]    let @xmath473 ) } |\\delta_{{\\boldsymbol{k}}}({\\boldsymbol{t}})|^2 { \\,{\\rm d}}{\\boldsymbol{t}}\\right)^{1/2}$ ]",
    ". then we have @xmath474 where the last inequality follows as the cauchy - schwarz inequality is an equality for two vectors which are linearly dependent .",
    "let @xmath475 be the value of @xmath476 for which the sum @xmath477 takes on its maximum . hence @xmath478 ) } |\\delta_{{\\boldsymbol{k}}^\\ast}({\\boldsymbol{t}})|^2 { \\,{\\rm d}}{\\boldsymbol{t}}.\\end{aligned}\\ ] ]      [ lem_dddelta ] let @xmath480 , @xmath481 , @xmath463 , @xmath482 , @xmath483 and @xmath484 be defined as above",
    ". for @xmath485 we have @xmath486 where @xmath487 with @xmath488 , and the supremum",
    "is taken over all @xmath489 and @xmath490 with @xmath491 where @xmath492 for @xmath493 and @xmath192 and such that all the points at which @xmath21 is evaluated in @xmath494 are in @xmath495 .",
    "furthermore , we may assume that @xmath496 for @xmath192 .",
    "we show that @xmath497 can be written as divided differences .",
    "since the divided difference operators are applied to each coordinate separately , it suffices to show the result for @xmath79 . in this case",
    "we have @xmath498 where now @xmath499 .        for given @xmath512 let @xmath513 let @xmath514 and @xmath515 notice that if @xmath516 , then @xmath517 and hence we can exclude this case .",
    "then for @xmath518 we have @xmath519 therefore @xmath520 where @xmath521 .",
    "notice that the ordering of the elements in @xmath522 does not change the value of @xmath523 .",
    "hence assume that the elements in @xmath522 are ordered such that @xmath524 .",
    "for the case where @xmath525 we obtain from the definition of the divided differences that @xmath526 by taking the triangular inequality and the supremum over all @xmath527 in @xmath528 , we obtain @xmath529              & \\le & 2^{s(d-\\alpha ) } \\sum_{{\\boldsymbol{q}}\\in a_{{\\boldsymbol{l}}- { \\boldsymbol{1}}_k } } \\mathrm{vol}(\\mathscr{d}_d([{\\boldsymbol{q}}b^{-{\\boldsymbol{l}}+ { \\boldsymbol{1}}_k } , ( { \\boldsymbol{q}}+ { \\boldsymbol{1 } } ) b^{-{\\boldsymbol{l}}+ { \\boldsymbol{1}}_k } ] ) )   \\ , \\sup      let @xmath550 for @xmath336 and @xmath192 .",
    "let @xmath551 for @xmath192 be such that @xmath552 , that is , @xmath339 is just a reordering of the elements of the set @xmath340 .",
    "set @xmath553 . then @xmath554 ) )   \\sup \\frac{|\\delta_{\\boldsymbol{\\alpha}}({\\boldsymbol{t}};{\\boldsymbol{z}}_1,\\ldots , { \\boldsymbol{z}}_s)f|^2 } { \\prod_{i \\in k } |z_i|^2 } \\\\ & \\le & 2^{s(d-\\alpha ) } \\gamma^2({\\boldsymbol{l } } ) v^2_\\alpha(f),\\end{aligned}\\ ] ] where the supremum is over all admissible @xmath555 and @xmath546 as described in the lemma .",
    "consider now the case where @xmath556 for some @xmath557 .",
    "let @xmath558 .",
    "then the result follows by replacing @xmath21 with the function @xmath0^{|r| } } f({\\boldsymbol{x } } ) { \\,{\\rm d}}{\\boldsymbol{x}}_{r}$ ] in the proof above .",
    "p. lecuyer and c. lemieux , a survey of randomized quasi - monte carlo . in : _ modeling uncertainty : an examination of stochastic theory , methods , and applications .",
    "_ m. dror , p. lecuyer , and f. szidarovszki ( eds . ) , 419474 .",
    "kluwer academic , new york , 2002 .",
    "owen , randomly permuted @xmath98-nets and @xmath563-sequences . in : h. niederreiter and j .- s .",
    "shiue ( eds . ) , _ monte carlo and quasi - monte carlo methods in scientific computing _",
    "( las vegas , nv , 1994 ) , 299317 , lecture notes in statist .",
    ", 106 , springer , new york , 1995 .",
    "address : + josef dick + school of mathematics and statistics + the university of new south wales + sydney , 2052 nsw , australia + email : josef.dick@unsw.edu.au + web : http://profiles.unsw.edu.au/maths/jdick1 + blog : http://quasirandomideas.wordpress.com/"
  ],
  "abstract_text": [
    "<S> we study numerical approximations of integrals @xmath0^s } f({\\boldsymbol{x } } ) \\,\\mathrm{d } { \\boldsymbol{x}}$ ] by averaging the function at some sampling points . </S>",
    "<S> monte carlo ( mc ) sampling yields a convergence of the root mean square error ( rmse ) of order @xmath1 ( where @xmath2 is the number of samples ) . </S>",
    "<S> quasi - monte carlo ( qmc ) sampling on the other hand achieves a convergence of order @xmath3 , for any @xmath4 . </S>",
    "<S> randomized qmc ( rqmc ) , a combination of mc and qmc , achieves a rmse of order @xmath5 . </S>",
    "<S> a combination of rqmc with local antithetic sampling achieves a convergence of the rmse of order @xmath6 ( where @xmath7 is the dimension ) . </S>",
    "<S> qmc , rqmc and rqmc with local antithetic sampling require that the integrand has some smoothness ( for instance , bounded variation ) . </S>",
    "<S> stronger smoothness assumptions on the integrand do not improve the convergence of the above algorithms further .    </S>",
    "<S> this paper introduces a new rqmc algorithm , for which we prove that it achieves a convergence of the rmse of order @xmath8 if the integrand has square integrable partial mixed derivatives up to order @xmath9 in each variable . </S>",
    "<S> known lower bounds show that this rate of convergence can not be improved . </S>",
    "<S> we provide numerical examples for which the rmse converges approximately with order @xmath10 and @xmath11 , in accordance with the theoretical upper bound . </S>"
  ]
}