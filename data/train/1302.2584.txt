{
  "article_text": [
    "we are concerned in this paper with the task of reasoning about formal systems such as programming languages , proof systems and process calculi .",
    "the data objects that are of interest within such systems often embody binding constructs .",
    "higher - order abstract syntax ( ) provides an effective means for representing such structure . in an representation , which is based on using a well - calibrated as a metalanguage",
    ", the binding structure of object language expressions is encoded using abstractions in .",
    "for example , consider an object language that is itself a . letting be a type for the representation of these terms , their encoding can be built around two constructors , @xmath0 and @xmath1 : the object term @xmath2 would , for instance , be represented as @xmath3 .",
    "observe that there is no constructor for variables in this encoding ; object - level variables are directly represented by the variables of the meta - language , bound by an appropriate abstraction .",
    "the virtue of is that if the metalanguage is properly chosen , , if it incorporates @xmath4-conversion but is otherwise weak in a computational sense , then it provides a succinct and logically precise treatment of object - level operations such as substitution and analysis of binding structure .",
    "formal systems are usually defined by the relations that hold between the data objects that constitute them .",
    "such relations are conveniently presented through syntax - directed rules .",
    "when they pertain to data embodying binding structure , these specifications naturally tend to be higher - order , , their rule - based presentation involves the use of contexts .",
    "moreover , these contexts can contain conditional assertions whose use may require the construction of sub - derivations . towards understanding this issue , consider the alternative notation for due to de bruijn in which bound variables are not named and their occurrences are represented instead by indexes that count the abstractions up to the one binding them @xcite . using the type for the representation of in this form",
    ", we can encode them via the constructors @xmath5 ( for variables ) , @xmath6 and @xmath7 .",
    "now , there is a natural bijection between the named and nameless representation of .",
    "writing @xmath8 to denote the correspondence between the -encoded term @xmath9 that occurs at _ depth _ @xmath10 ( , under @xmath10 @xmath4-abstractions ) and the de bruijn term @xmath11 where @xmath12 determines the mapping between free variables in the two representations , we can define this relation via these rules : @xmath13    \\linfer {      \\g |- \\hodbrel{\\kabs~(\\lam x. m ) , h , \\kdabs~d }    } {      \\g , \\all i , k. ( ( h + k = i ) \\supset \\hodbrel{x , i , \\kdvar~k } )      |- \\hodbrel{m , h + 1,d }    }    \\label{rule : hodbrel - abs }    \\\\[1ex ]    \\linfer {      \\g |- \\hodbrel{x , i , \\kdvar~k }    } {      \\all i , k. ( ( h + k = i ) \\supset \\hodbrel{x , i , \\kdvar~k } ) \\in \\g      &       |- h + k = i    }    \\label{rule : hodbrel - var}\\end{gathered}\\ ] ] the rule for relating applications is straightforward . to relate @xmath14 to a de bruijn term at depth @xmath10",
    ", we must relate each occurrence of @xmath15 in @xmath9 , which must be at a depth @xmath16 for some @xmath17 , to the de bruijn term @xmath18 . to encode this correspondence ,",
    "the context is extended in the premise of rule ( [ rule : hodbrel - abs ] ) with a ( universally quantified ) implicational formula .",
    "note also that this rule carries with it the implicit assumption that the name @xmath15 used for the bound variable is fresh to @xmath12 , the context for the concluding judgment . eventually , when the term on the right of @xmath19 is a variable , rule ( [ rule : hodbrel - var ] ) provides the means to complete the derivation by using the relevant assumption from @xmath12 .",
    "observe that the use of this rule entails a construction of an auxiliary derivation for @xmath20 .",
    "our ultimate interest is in reasoning about such higher - order relational specifications .",
    "for example , we might be interested in showing that the relation that we have defined above identifies a bijective mapping between the two representations of .",
    "one part of establishing this fact is proving that the relation is deterministic from left to right , , that every term in the named notation is related to at most one term in the nameless notation .",
    "writing @xmath21 to denote derivability of the judgment @xmath22 by virtue of the rules ( [ rule : hodbrel - app ] ) , ( [ rule : hodbrel - abs ] ) and ( [ rule : hodbrel - var ] ) , this involves providing a proof for the following assertion : @xmath23 note that @xmath24 and @xmath25 in ( [ stmt : hodb - det - ltr - bad ] ) are logical constants at the reasoning level in contrast to the ones in ( [ rule : hodbrel - app ] )  ( [ rule : hodbrel - var ] ) that are at the object level .",
    "such a proof must obviously be based on an analysis of derivability using the rules that define the relation . to formalize such reasoning , we need a logic that can encode these rules in a way that allows case analysis to be carried out over their structure . furthermore , the logic must embody an induction principle since proofs of general theorems of the kind we are interested in must be inductive over the structure of object - level derivations . a particular difficulty in articulating such inductive arguments relative to higher - order relational specifications is that they may need to take into account derivations in the object system that rely on hypotheses in changing contexts .",
    "for example , a proof of ( [ stmt : hodb - det - ltr - bad ] ) must accommodate the fact that @xmath12 can be dynamically extended in a derivation of @xmath8 and that the particular content of @xmath12 influences the derivation in the variable case via the rule ( [ rule : hodbrel - var ] ) .    in this paper",
    "we develop a framework that provides an elegant solution to this reasoning problem .",
    "formally , our framework is a realization of the two - level logic approach  @xcite , which is based on embedding a _ specification logic _ inside a _ reasoning logic_. within this setup ,",
    "we take our specification logic to be that of hereditary harrop formulas ( ) .",
    "this logic extends the well - known logic of horn clauses essentially by employing simply typed as a means for representing data objects and by permitting universal quantification and implications in the bodies of clauses .",
    "as such , it provides an excellent basis for encoding rule - based higher - order specifications over representations  @xcite .",
    "moreover , these formulas can be given a proof - theoretic interpretation that simultaneously is complete with respect to intuitionistic logic and reflects the structure of derivations based on the object - level rules they encode .",
    "for the reasoning logic we use the system from  @xcite .",
    "this logic permits atomic predicates to be defined through clauses in a way that allows case analysis based reasoning to be carried out over them .",
    "the treatment of definitions in can also be specialized to interpret them inductively .",
    "the capability for formally proving properties about relational specifications is realized in this setting by first encoding derivability in via an inductive definition and then using this encoding to reflect reasoning based on object - level rules into reasoning over derivations that formalize these rules .",
    "the two - level logic approach has previously been implemented in the abella system and has been used successfully in several reasoning tasks  @xcite .",
    "however , the original version of abella uses a fragment of that is capable of treating syntax - directed rules only when the dynamic additions to their contexts is restricted to atomic formulas .",
    "there is an inherent difficulty in structuring the reasoning when contexts can be extended with formulas having an implicational structure .",
    "for example , as already noted , case analysis over the derivation of @xmath26 in a proof of ( [ stmt : hodb - det - ltr - bad ] ) must take into account the fact that the derivation can proceed by using a hypothesis that was dynamically added to @xmath12 . without well - defined constraints on @xmath12 , it is difficult to predict how such hypotheses might be used and indeed the assertion may not even be true .    in the example under consideration , there is an easy resolution to the dilemma described above .",
    "we are not interested in proving assertion ( [ stmt : hodb - det - ltr - bad ] ) for arbitrary @xmath12 but only for those @xmath12s that result from additions made through the rule ( [ rule : hodbrel - abs ] ) .",
    "the elements of @xmath12 must therefore all be of the form @xmath27 where @xmath10 is some depth and @xmath15 is some variable not otherwise present in @xmath12 .",
    "moreover , the use of such assumptions in derivations can occur only through rule ( [ rule : hodbrel - var ] ) that is in fact another instance of a backchaining step that is manifest explicitly in the rules ( [ rule : hodbrel - app ] ) and ( [ rule : hodbrel - abs ] ) .",
    "thus , the structure of @xmath12 can be encoded into an inductive definition in @xmath28 and treated in a finitary fashion by the machinery that @xmath28 already provides for reasoning about backchaining steps .    the key insight underlying",
    "this paper is that the above observation generalizes cleanly to other reasoning situations that involve contexts with higher - order hypotheses .",
    "concretely , the contexts that need to be considered in these situations are completely determined by the additions that can be made to them .",
    "further , the structure of such additions must already be manifest in the original specifications and can therefore always be encapsulated in an inductive definition . to take advantage of this observation",
    "we modify the encoding of derivations in abella to support reasoning also over the backchaining steps that result from using dynamically added assumptions .",
    "we then demonstrate the power of this extension through its use in explicitly proving the bijectivity property discussed above as well as another non - trivial property about paths in and their relation to reduction .",
    "these exercises also show the benefits of using a logic for specifications : the meta - theoretic properties of this logic greatly simplify the reasoning process .    in summary , we make three contributions through this work : we propose a methodology for reasoning about higher - order relational specifications , we present an implemented system for supporting this methodology and we show its effectiveness through actual reasoning tasks .",
    "the framework we describe exploits the representation style to structure and simplify the reasoning process . to the best of our knowledge , the only other systems that use such an approach to similar effect are twelf  @xcite and beluga  @xcite .",
    "in contrast to these systems , the one we develop here provides a rich language for stating meta - theoretic properties of specifications and an explicit logic for articulating their proofs .",
    "we elaborate on these comparisons in a later section .",
    "the rest of the paper is structured as follows . in the next two sections , we present the specification logic , the reasoning logic , and the two - level logic approach that is built out of their combination .",
    "illustrates the use of the resulting framework and the associated methodology for a novel and non - trivial example .",
    "the focus in this example is on specifications that have a rich higher - order character and on showing how context definitions and context relations can be used to structure and realize the reasoning process .",
    "the last two sections discuss related work and conclude the paper by providing a perspective on its technical contributions .    the extended abella system that is the outcome of this work is available at  @xcite .",
    "besides the examples described in this paper , this version of abella also contains a number of other examples of reasoning about higher - order relational specifications that illustrate our approach .",
    "in this section , we present the specification logic , show how it can be used to encode rule - based descriptions , and discuss some of its meta - theoretic properties that turn out to be useful in reasoning about specifications developed in it .      the logic of hereditary harrop formulas is a predicative fragment of church s simple theory of types  @xcite whose expressions are simply typed .",
    "types are built freely from primitive types , which must include the type of formulas , and the function type constructor @xmath29 .",
    "terms are built from a user - provided signature of typed constants , and are considered identical up to @xmath30-conversion .",
    "we write @xmath31 to denote that @xmath32 is a well - formed term of type @xmath33 relative to @xmath34 .",
    "well - formed terms of type @xmath35 relative to @xmath34 are called _",
    "@xmath34-formulas _ or just _ formulas _ when @xmath34 is implicit .",
    "logic is introduced into this background via a countable family of constants containing : @xmath36 ( written infix , and associating to the right and left , respectively ) , and for every type @xmath33 not containing , the ( generalized ) universal quantifier @xmath37 . an atomic formula , denoted by @xmath38 possibly with a subscript , is one that does not have a logical constant as its head symbol .",
    "we use the abbreviations @xmath39 for @xmath40 , @xmath41 for @xmath42 , and @xmath43 where @xmath44 and @xmath45 for @xmath46 .",
    "we will omit the types when they are irrelevant or can be inferred from context . finally , we will often write @xmath47 ( with `` @xmath48 '' associating to the left and pronounced `` if '' ) to mean @xmath49 .",
    "the proof system has two kinds of sequents :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ cols= \" < , < \" , ]    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here , @xmath50 is an representation of @xmath12 .",
    "the third column contains a convenient and evocative notation for the equivalent atom in the second column ; we shall often use this notation in the rest of this paper . note that while the contexts are unordered multisets , the representations are ordered .",
    "this is not a limitation because we will always reason about the contexts using @xmath51 .",
    "the static program clauses in @xmath52 are not part of the encoding of sequents .",
    "rather , we use the inductively defined predicate @xmath53 that has one clause of the form @xmath54 for each @xmath55",
    ".    the rules of the proof system in are used to build mutually inductive definitions of the @xmath56 and @xmath57 predicates .",
    "this definition is depicted in ; each clause of the definition corresponds to a single rule of .",
    "the goal reduction rules are systematically translated into the clauses , the only novelty being that universally quantified variables of the specification logic are represented as nominal constants in using the @xmath58 quantifier .",
    "this use of @xmath58 is necessary because the encoding must completely characterize provability in . in particular , in the sequent @xmath59 is _ not _ derivable , meaning that the formula @xmath60 should be true .",
    "this is achievable since it unfolds to @xmath61 . as a point of comparison , if we were to use this clause instead :    l  ( _  g ) x : .",
    "l  ( g  x )    then the non - derivability property of the sequent above , now encoded as @xmath62 , would not be true .",
    "( in particular , the antecedent is satisfiable in models with only a single inhabitant . )",
    "the backchaining rules of are encoded as clauses of in a straightforward manner .    for the structural rules of",
    ", we have to enforce the invariant that the right hand side of the sequent is atomic .",
    "this is achieved by means of a predicate @xmath63 defined by the following clause :    f & ( g . ( f = _",
    "g ) ) + & ( g_1 , g_2 .",
    "( f = ( g_1 g_2 ) ) ) + & ( g_1 , g_2 .",
    "( f = ( g_1 g_2 ) ) ) .    effectively , characterizes atomic formulas negatively by saying that an atomic formula can not be constructed with a connective .",
    "it is important to note that there is a small issue with all three of , , and : they treat @xmath64 as if it were a single object , but , since the reasoning and specification logics share the type system , it actually stands for all instances for the type @xmath33 . to keep these definitions finite ,",
    "we would require polymorphism , which currently lacks . in the abella implementation ,",
    "therefore , these definitions are treated specially .",
    "note that the meta - theory of does not require that inductive definition have finitely many clauses , so even an infinitary interpretation of the clauses of , as was done in  @xcite , is compatible with our approach .",
    "the faithfulness of our encoding allows us to state and prove known properties of in .",
    "for example , the meta - theoretic properties discussed in have the following counterparts relative to the encoding in .",
    "having proved them in , we can use the rule to invoke them as lemmas in arguments concerning particular specifications .",
    "[ thm : hhw - meta - formal ] the earlier discussed meta - theoretic properties of are validated by their encoding in . in other words ,",
    "each of the following is provable in .",
    "@xmath65 ( cut ) .",
    "@xmath66 ( instntiation ) .",
    "@xmath67 ( monotonicity ) .",
    "these are fairly straightforward inductive theorems of .",
    "we have proved them formally in the abella  @xcite implementation of ; the proofs can be found in the file hh_meta.thm .",
    "we are now in a position to formally verify that the relation presented in the introduction between the encodings of the named and nameless representations of actually specifies an isomorphism .",
    "we do this by showing that its rendition in described in is deterministic in both its first and third arguments . as expected , we work within with the encoding of described in the previous section .",
    "we also assume that the ( static ) clauses , , , and have been reflected into the definition of in this context .    as mentioned in the introduction",
    ", we will need to finitely characterize the possible dynamic context extensions during the derivation of .",
    "the inductive definition of these dynamic contexts of has the following pair of clauses .    &",
    "+ ( x. &  ( ( i , k.  x  i  (  k )  h  k  i ) l ) )  l.    as usual , the capitalized variables @xmath68 and @xmath50 are universally quantified over the entire clause . note the occurrence of @xmath69 at the head of the second clause of the definition : it guarantees that @xmath15 does not occur in @xmath68 or @xmath50 .",
    "therefore , in any @xmath50 for which @xmath70 holds , it must be the case that there is exactly one such dynamic clause for each such @xmath71 .",
    "it is easy to establish this fact in terms of a pair of lemmas .",
    "the first of these lemmas characterizes the dynamic clauses .",
    "l , e.  & l + x , h. e & = ( i , k.  x  i  (  k )  h  k  i ) + & .",
    "[ lab : hodb - ctx - inv ]    here , @xmath72 is a predicate that asserts that @xmath15 is a nominal constant ; this predicate can be defined in with the clause @xmath73 . to prove ( [ lab : hodb - ctx - inv ] ) , we proceed by induction on the first hypothesis , @xmath70 . as mentioned in , this",
    "is achieved by assuming a new _ inductive hypothesis _",
    "@xmath74 :    l , e. (  & l)^ * + x , h. e & = ( i , k.  x  i",
    "(  k )  h  k  i ) + & .    moreover ,",
    "the proof obligation is modified to the following sequent , where @xmath50 and @xmath75 are promoted to eigenvariables , and the assumptions of the lemma are converted to hypotheses .",
    "l , e ; (  l)^@ , ||- + x , h. e = ( i , k.  x  i  (  k )  h  k  i ) .    the can not be immediately used because the annotations of @xmath70 do not match . to make progress , the definition of @xmath70 needs to be _",
    "unfolded_. as explained in , this amounts to finding all ways of unifying @xmath70 with the heads of the clauses in the definition of @xmath76 .",
    "the complete set of unifiers is characterized by @xmath77 and @xmath78 for new eigenvariables @xmath68 and @xmath79 and a nominal constant @xmath80 . in the latter case",
    "we also have a new hypothesis , @xmath81 , that comes from the body of the second clause for @xmath76 .",
    "there are two things to note : first , the @xmath58 at the head of the second clause of @xmath76 is turned into a nominal constant in the proof obligation , and the second is that the new hypothesis in the second case is annotated with @xmath82 , which suits the .    in each case for @xmath50 , the argument proceeds by analyzing the second hypothesis , @xmath83 . the case of @xmath77",
    "is vacuous , because there is no way to infer @xmath84 , making that hypothesis equivalent to false . in the case of @xmath85",
    ", we have two possibilities for @xmath83 : either @xmath86 or @xmath87 .",
    "the former possibility is exactly the conclusion that we seek , so this branch of the proof finishes .",
    "the latter possibility lets us apply to the hypotheses @xmath81 and @xmath87 , which also yields the desired conclusion .",
    "the second necessary lemma asserts that there is at most a single clause for each variable in the dynamic context .    &",
    "l , x ,  h_1 , h_2 .",
    "l + & + & + & h_1 = h_2 .",
    "[ lab : hodb - ctx - sync ]    note that from @xmath88 , we are able to conclude that the two dynamic clauses relating @xmath15 to a de bruijn term must be the same . like the previous lemma , it is proved by induction on the hypothesis @xmath70 .",
    "armed with these lemmas , we can then show both directions of determinacy for . in the forward direction the statement is as follows .",
    "l , m , h , d , e.  l + d = e.    we prove this by induction on @xmath89 ; this amounts to assuming the lemma below :    l , m , h , d , e. &  l ^ * + & d = e    and proving the sequent    l , m , h , d , e ; &  l , ^@ , + & ||- d = e.    now , @xmath90 is just a notation for the atom @xmath91 whose definition is given by the clauses in .",
    "unfolding the definition amounts to finding all the clauses in whose heads match @xmath92 only the final two clauses of , corresponding to the rules and of , are therefore relevant .",
    "let us consider backchaining the static clauses first , , the applications of the rule .",
    "there are only a finite number of them , so the assumption @xmath93 can be immediately turned into a branched tree with one case for every static program clause . for the first static clause ,",
    "we are left with a new assumption :    \\ { l , |-  m  h  d } ^ *    the annotation @xmath82 here was obtained from unfolding the definition of a @xmath94-annotated atom per the technique outlined in .",
    "note that this is just a backchaining sequent ( @xmath57 ) whose definition in can be unfolded .",
    "doing this instantiates the @xmath95 prefix in the bakchaining clause in such a way that the head @xmath96 unifies with the formula on the right , @xmath97 ; this produces the substitutions @xmath98 , @xmath99 , and @xmath100 for fresh eigenvariables @xmath101 .",
    "moreover , by the second clause for in , we get this goal reduction sequent as a fresh hypothesis :    ^ *    which is reduced by the first clause for to :    ^ * ^ *    we can almost apply the induction hypothesis we know @xmath70 and @xmath102 already  but we still must find the third argument . to get this argument we need to case analyze the other hypothesis , @xmath103 , which becomes @xmath104 as a result of the previous unification .",
    "it has no size annotations because the induction was on the first hypothesis .",
    "nevertheless , we can perform a case analysis of its structure by unfolding its definition ( using the clauses in ) .",
    "once again , we have a choice of using a static program clause or a dynamic clause from @xmath50 .",
    "if we use a static clause , then by a similar argument to the above we will get the following fresh hypotheses , for new eigenvariables @xmath105 and @xmath106 such that @xmath107 :    we can now apply the twice , yielding @xmath108 and @xmath109 , so @xmath110 .",
    "if , on the other hand , we use a dynamic clause in @xmath50 , then the two fresh hypotheses we get are :    .    for some new eigenvariable @xmath111 .",
    "this is the first place where the context characterization hypothesis @xmath70 becomes useful . by lem .",
    "( [ lab : hodb - ctx - inv ] ) above , we should be able to conclude that @xmath111 is of the form @xmath112 for some term @xmath113 and nominal constant @xmath80 . by looking at the clauses for in",
    ", it is clear that there is no way to prove the sequent @xmath114 , because the term @xmath80 will never unify with @xmath115 .",
    "hence this hypothesis is vacuous , which closes this branch .",
    "we have now accounted for all the cases of backchaining a static clause for the inductive assumption @xmath90 - 3pt .",
    "this leaves only the dynamic clauses in @xmath50which are backchained using the rule  which corresponds to the following pair of new hypotheses :    ^ * ^ *",
    "as these hypotheses come from unfolding an inductive assumption , they are @xmath82-annotated .",
    "once again , we can apply lem .",
    "( [ lab : hodb - ctx - inv ] ) to conclude that    f = ( i , k.  i",
    "(  k )  h  k  i )    where denotes a nominal constant , we then continue using the definitional clauses for to get the fresh assumption    ^ *    for new eigenvariables @xmath116 and @xmath117 , and the equations @xmath118 and @xmath119 .",
    "then , since does not occur in the static clauses @xmath52 , the only way to prove the second hypothesis @xmath120 would be to use a dynamic clause in @xmath50 . once again , by lem  ( [ lab : hodb - ctx - inv ] ) and unfolding the definition of as above , we see that this clause must have been of the form @xmath121 for some eigenvariable @xmath122",
    ". we can now use the other lemma  ( [ lab : hodb - ctx - sync ] ) to show that @xmath123 . hence , @xmath120 backchains on the same clause in @xmath50 as @xmath124 , so it must be that @xmath125 as well , , @xmath126 .    `",
    "ctx_inv ` : @xmath127 + @xmath128 .",
    "+ ` ctx_unique ` : @xmath129 + @xmath130 + @xmath131",
    ". + ` add_det2 ` : @xmath132 + @xmath133 .",
    "+ ` hodb_det3 ` : @xmath134 + @xmath135 .",
    "+ induction on 2 .",
    "intros ch dh eh .",
    "dch : case dh .",
    "+   + ech : case eh .",
    "+ apply ih to ch dch ech . +",
    "apply ih to ch dch1 ech1 . search .",
    "+ bch : apply ctx_inv to ch .",
    "+   + ech : case eh .",
    "+ apply ih to _ dch ech . search .",
    "+ bch : apply ctx_inv to ch ech1 .",
    "+   + bch : apply ctx_inv to ch dch1 .",
    "ah : case dch . + ech : case eh .",
    "case bch . + uh : apply ctx_inv to ch bh1 .",
    "+ bh : case ech .",
    "apply ctx_unique to ch dch1 ech1 . +",
    "apply add_det2 to ch ah bh search .",
    "this proof , which has been explained here in some detail , is concisely expressed using the tactics language of abella  @xcite as shown in .",
    "induction and case analyses are indicated explicitly using the and tactics , while lemmas are applied using the tactic .",
    "the and definitions are used implicitly by the and tactics ; in particular handles reasoning on backchaining sequents .",
    "the tactics language of abella therefore remains unchanged from earlier versions that were designed to support only second - order hereditary harrop formulas .",
    "the relation is also deterministic in its first argument , given a de bruijn indexed term , there is at most a single term it corresponds to  which is proved in a similar fashion .",
    "thus , the relation is manifestly an isomorphism between the two representations of .",
    "if we were to specify the translations functionally , then we would not only have to repeat the clauses for both directions of the translation , but we would also have to prove separately that they are injective and inverses .",
    "we do not sacrifice any of the executable power of a functional specification : the program is directly executable in the language @xmath4prolog  @xcite .",
    "the example of the previous section was simple enough that the dynamic context could always be characterized directly by an inductive definition . in the general case , we will need to prove properties about a collection of higher - order relations where each relation has its own separate form of dynamic context .",
    "we will therefore need to generalize unary definitions such as @xmath76 of the previous section to _ context relations _ of higher arities .",
    "this section contains a case study of such an example , which is independently novel .",
    "the example is drawn from  ( * ? ? ?",
    "7.4.2 ) and involves a structural characterization of reductions on .",
    "a _ path _ through a is a way to reach any non - binding occurrence of a variable in the term  ( * ? ? ?",
    ", we can use a basic type @xmath136 for paths with the following constructors : @xmath137 to descend to the function or the argument sub - trees in an application , and @xmath138 to descend through a @xmath4-abstraction .",
    "crucially , @xmath139 has the same binding structure as the @xmath4-abstractions encountered along the path .",
    "the predicate @xmath140 asserts that a given contains a given path ; it is defined by the following three clauses .    &",
    "(  m  n )  (  p )  m  p. + &  (  m  n )  (  p )  n  p. + &  (  m )  (  p ) + & x , p.  ( m  x )  ( p  p )  x  p.    as these paths record the specific structure of a , @xmath141-reduction changes the paths in the term . on the other hand , a path through _ the result of reducing _",
    "@xmath142 would be a path through @xmath143 with the additional proviso that any path through @xmath144 is also a path through @xmath15 .",
    "paths are a useful tool for structural characterization of terms .",
    "for instance , if two terms have the same paths , then they must be identical ; this corresponds to the following theorem of :    & m , n. + & ( p . )",
    "+ & m = n.    [ lab : paths - same - nored ]    this theorem is provable in the version of abella described in  @xcite that only has the second - order fragment of as its specification logic .",
    "unfortunately , this structural characterization is not preserved by @xmath4-conversion .",
    "suppose we want to compute the paths in a term that result from reducing certain marked @xmath141-redexes .",
    "formally , we can add a new constructor for marked redexes , @xmath145 with the understanding that @xmath146 denotes the same as @xmath147 , except that the redex is marked .",
    "we can then define a relation @xmath148 that reduces all the marked @xmath141-redexes in a term , with the following clauses .    &",
    "(  m  n )  (  u  v )  m  u  n  v. + &  (  m )  (  u ) + & x.  ( m  x )  ( u  x )  x  x. + &  (  m  n )  v + & x.  ( m  x )  v u.  x  u  n  u.    we also need a static clause for a path in a marked redex .    &",
    "(  m  n )  p + & x.  ( m  x )  p q.  x  q  n  q.    since different terms can have the same paths as long as they reduce to the same term , the theorem ( [ lab : paths - same - nored ] ) will need to be updated to account for reduction .",
    "that is , if two terms have the same paths , then they are _ joinable _ by :    & m , n , u , v. + & ( p . ) + & u = v.    [ lab : paths - joinable ]    how would one prove ( [ lab : paths - joinable ] ) ?",
    "note that there are two different higher - order predicates : proofs of @xmath149 will add dynamic clauses involving @xmath150 , while proofs of @xmath151 will add dynamic clauses involving @xmath152 .",
    "we would like to prove that @xmath150 preserves @xmath152 , so the statement of the theorem would have to account for proofs of both kinds , and hence for both kinds of dynamic clauses .",
    "the general technique in for such situations is to _ relate _ the two kinds of dynamic contexts for the two different relations .",
    "the following definition of @xmath153 achieves this .    &",
    "+ & ( x , p.  (  x  x k )  (  x",
    "p l ) )  k  l ; + & ( x.  ( ( u .",
    "n  u  x  u ) k ) + & ( ( p .",
    "n  p  x  p ) l ) )  k  l.    it is important to note that the @xmath154 predicate not only says how two such contexts are related , but also contains a specification of the contexts themselves .",
    "a hypothesis @xmath155 where @xmath50 , say , is not used elsewhere in the theorem is equivalent to assuming just that @xmath156 is a dynamic context for @xmath150 .",
    "as before , the @xmath157-bound variables at the head guarantee that every such variable has a unique dynamic clause in both contexts , which we can establish separately using a lemma .",
    "the proof of ( [ lab : paths - joinable ] ) now proceeds as follows : first we note that if @xmath158 , then a path in @xmath159 must also be in @xmath144 and _ vice versa_. then , we separately show that if @xmath158 , then it must be that @xmath144 is free of any subterms involving @xmath160 . finally , we prove the lemma that if two @xmath160-free terms have the same paths , then they must be identical , which is essentially the same theorem as ( [ lab : paths - same - nored ] ) .",
    "let us consider the first of these lemmas : that @xmath150 preserves @xmath152 .",
    "in the encoding of , the statement of the theorem is :    & k , l , m , u , p. + &  k  l + & .",
    "[ lab : paths - preserve - l2r ]    this theorem is proved by induction on @xmath161 . just as in the inductive proofs in , there will be some cases for backchaining static program clauses and some for dynamic clauses .",
    "the static cases are fairly straightforward , so we concentrate below on the dynamic cases .    per the definition in , backchaining a dynamic clause for @xmath161 produces the new hypotheses :    ( ) ^ * ^ *    for some eigenvariable @xmath75 . from @xmath155 and @xmath162 , it must follow that :    & ( x. ( e =  x  x ) x ) + & ( n , x. e = ( u.  x  u  n  u ) x )    which is itself proven ( as a lemma ) by induction on the hypothesis @xmath155 .",
    "we therefore need to consider only these two cases for the dynamic clause @xmath75 .",
    "the first case where @xmath163 is easy to prove . for the second case , we are left with the following problem : although we can characterize the cases for @xmath75 , this is not enough to reason about @xmath152 because @xmath75 is a dynamic clause for @xmath150 .",
    "this is where we use the fact that @xmath154 is a relation to prove the following lemma .    &",
    "k , l , n. n.  ( k  n )  ( l  n ) + & + &    [ lab : paths - ctx2-sync ]    its proof is by induction on the hypothesis @xmath155 . it can be seen as a kind of translation between the formal relation , given as an inductive definition , to a way of reasoning about the elements of the related contexts .",
    "the lemma ( [ lab : paths - ctx2-sync ] ) states , in particular , that a dynamic clause about reduction of marked redexes in the dynamic contexts for @xmath150 must have a corresponding dynamic clause for paths through a marked redex in the dynamic contexts for @xmath152 .",
    "we now have nearly everything to finish the proof of ( [ lab : paths - preserve - l2r ] ) .",
    "the only remaining wrinkle is that in the case where the term @xmath159 is a variable that unifies with a nominal constant @xmath164 , we will need to look up its dynamic clause in a suitable dynamic context and continue by backchaining it .",
    "this amounts to the following _ inversion lemma _ :    & k , l , n , p. n.  ( k  n )  ( l  n ) + & + & .",
    "[ lab : paths - inversion ]    effectively , this lemma says that the only way that @xmath165 could have been proved is by backchaining on the given clause , which has the premise @xmath166 .",
    "we can show this lemma because we have completely characterized the dynamic context @xmath167 , and the static program has no clauses with nominal constants .",
    "note that the nesting order of @xmath168 and @xmath58 is crucial here : the nominal constant @xmath164 must not be allowed to occur in @xmath144 .",
    "however , it is obviously allowed to occur in the dynamic context , so we indicate this by means of an explicit dependency , indicated here using the application @xmath167 .",
    "this punning between the two levels is possibly because and are both based on a common .",
    "the proof of ( [ lab : paths - preserve - l2r ] ) can now be completed by using ( [ lab : paths - inversion ] ) for the variable case .",
    "the full development of this example in abella , including the formal proofs , can be found in examples / hhw / breduce.thm in the abella distribution  @xcite .",
    "the proof system presented in is largely similar to the focused sequent calculus  @xcite for the fragment of intuitionistic logic containing implication , universal quantification , negatively polarized atoms , and the negatively polarized variant of conjunction .",
    "it is also straightforwardly a version of the calculus formalizing _ uniform provability",
    "_  @xcite .",
    "the term `` logic of hereditary harrop formulas '' is often used to indicate an extended logic where disjunction and existential quantification are also allowed in a limited form  @xcite .",
    "specifications in the full language with these connectives can be compiled into our language , possibly with an increase in the number of static clauses in the specifications .",
    "representational techniques for data with binding can be broadly classified into two styles : first - order and higher - order .",
    "regardless of style , a primary requirement of the representation is that it not distinguish between terms that are @xmath169-equivalent .",
    "the traditional first - order approach to realizing this requirement is to represent bound variables by de bruijn indexes , which yields canonical representatives of @xmath169-equivalence classes of .",
    "a very different first - order alternative to de bruijn indexes is the approach of nominal logic that forgoes canonical representatives of the @xmath169-equivalence classes ; instead , two terms are considered identical if they are _ equivariant _ , meaning that the names used in one term can be permuted to the names in the other .",
    "this approach is the basis of nominal isabelle  @xcite , and there are also a number of libraries for programming with nominal data , such as fresh ocaml  @xcite and alpha prolog  @xcite . a drawback with first - order representations , whether of the de bruijn or the nominal logic kind , is that they typically do not offer support for binding related notions beyond @xmath169-equivalence .",
    "typical reasoning applications require a realization of operations such as substitution and analysis of syntactic structure that respects binding . with first - order approaches ,",
    "these have to be implemented explicitly and the reasoning process must also show their correctness . in particular , the operation of substitution of a term for a free variable , which is at the heart of much of the meta - theory of deductive systems , requires careful book - keeping and fairly detailed correctness arguments ( see  @xcite for a recent example done in coq ) .",
    "in contrast , higher - order representations reflect binding constructs into the meta - level abstraction operation and thereby absorb arguments about the correctness of binding related operations into a one - time argument , external to the object - level reasoning task , about the correctness of the the meta - language implementation .",
    "besides abella , there are three other systems designed to reason about specifications in :  @xcite ,  @xcite , and  @xcite .",
    "all of these systems are broadly two - level or nested systems , but they make different choices for the specification and reasoning formalisms . of these , only is integrated with popular existing formal reasoning systems ( coq and isabelle ) , which allows it to leverage the trusted kernels of the existing systems instead of implementing new trusted components . on the other hand , is limited to the second - order hereditary harrop fragment for the specification level ( which makes it similar in this respect to the earlier version of abella described in  @xcite ) and does not have support for generic reasoning .",
    "the second - order restriction is significant when reasoning about higher - order deductive systems : the dynamic clauses of higher - order specifications must be named and transferred to the static program beforehand .",
    "for example , the predicate in the second - order fragment requires an auxiliary predicate and the following clauses for marked redexes .    &  (  m  n )  p x.  ( m  x )  p  x  n. + &  x  p  x",
    "n  n  p.    writing such auxiliary predicates is not only error - prone and anti - modular , but they also complicate reasoning about the relations .",
    "for instance , in it is a direct consequence of cut that @xmath170 and @xmath171 imply @xmath172 . however , for the second - order encoding above , the fact that @xmath173 and @xmath174 imply @xmath172 would need a separate inductive proof .    and both use the dependent type theory for their specification languages .",
    "it is known that specifications can be systematically and faithfully translated into  @xcite .",
    "the encoding of an signature in uses higher - order features pervasively , and , indeed , was an early motivation for the present work of supporting reasoning over higher - order specifications in abella . the main difference between and",
    "is their type systems , which directly affects their reasoning principles .",
    "briefly , encourages a `` combined contexts '' reasoning approach , while encourages a `` context relations '' approach . because is dependently typed , the dynamic signature extensions for universally quantified goals can not be separated from other assumptions ; in fact , contexts in are interpreted as ordered .",
    "it is difficult to place the same term in two different contexts .    in both and",
    ", therefore , the most direct way to reason about different higher - order relations is to use a common dynamic context for the relations .",
    "this is achieved formally by specifying contexts _ schematically _ by means of regular grammars , and using _ subordination _ analysis on the signature to determine when one regular context may be _ subsumed _ by another .",
    "for example , since there is no way to embed a value inside a value using the provided constructors , and the clauses for do not mention , it must stand to reason that properties of must hold even in a context of assumptions about .",
    "such subsumption properties are often useful ; for examples , in the example of , if the required properties of are used in a non - empty dynamic context , we must separately prove that earlier theorems still hold , such as the theorem ` add_det2 ` in .",
    "in abella , context definitions are no different from any other inductive definition ; there is no automatic subsumption of context relations and such lemmas must be proven manually .",
    "on the other hand , reasoning about contexts is not part of the trusted base of abella , and many properties about arbitrary context relations can be separately proved and used in a modular fashion , as we have done in the examples in and [ sec : paths ] .    the differences between the abella approach and that of and taken together can be summarized by the following observations .",
    "firstly , and make many kinds of reasoning about context membership , such as ( [ lab : hodb - ctx - inv ] ) , automatic and available to the user for free . explicit reasoning about context members in abella can be tedious , so it is conceivable that some aspects of the context reasoning of and can be imported into abella in the future .",
    "in particular , theorems such as ( [ lab : hodb - ctx - inv ] ) , ( [ lab : hodb - ctx - sync ] ) , and ( [ lab : paths - ctx2-sync ] ) have entirely predictable proofs that should be easy to automate .    secondly , the reasoning logic has a well - developed proof - theory that includes a sequent calculus with a cut - admissibility result  @xcite .",
    "this logic has a number of features : an equality predicate at all types , generic reasoning , and both inductive and co - inductive fixed - point definitions .",
    "s meta - logic also has a sequent calculus with proof - terms , and the consistency of this logic is proved by giving the proof terms an operational semantics and verifying that they represent total functions under this interpretation .",
    "( as of version 0.5 ) supports only inductive reasoning in terms of recursive fixed - points , and does not support co - induction .",
    "supports inductive reasoning for @xmath175 theorems , but also has no support for co - induction .",
    "neither nor has a built - in equality predicate . for generic reasoning ,",
    "s contextual modal types can achieve many of the same goals as the @xmath157 quantifier of @xmath28 , but the global nature of nominal constants and equivariant unification makes it possible to reason about open terms with free variables , unaccompanied by any contexts  @xcite .",
    "much of the informal meta - theory of the uses open terms in this style , but a first order representation of variables requires an explicit treatment of @xmath169-equivalence and substitution .",
    "the @xmath157 quantifier lets us combine the benefits of and reasoning on open terms .",
    "finally , the type systems of and are endowed with an associated natural induction principle that allows reasoning by induction on the structure of well - typed terms . in abella ,",
    "typing is not treated as a definition , so if one wants to induct on the structure of , for example , one would have to use a well - formedness predicate @xmath176 with the following clauses :    &  (  m  n )  m  n. + &  (  m ) x.  ( m  x )  x.    then , whenever one needs to reason by induction on the structure of a term @xmath159 , one reasons instead on @xmath177 .",
    "because such predicates essentially reify the well - typedness relation , they will generally need higher - order clauses if the types of the constructors are higher - order .",
    "for instance , the constructor has a second - order type and requires a second - order clause for .",
    "note that such definitions can not be made in the reasoning logic because they are not stratified , , to prove @xmath178 , one needs to make assumptions of the form @xmath179 .",
    "it is of course possible to automatically generate predicates like for a given signature , but in any theorem that involves inductive reasoning on the structure of terms one would still need to make hypotheses such as @xmath177 explicit . note that @xmath180 is not a theorem of .",
    "we have presented an extension to the two - level logic approach that lets one use the full richness of to specify and formally reason about higher - order deductive formalisms .",
    "the essence of our method is characterizing the contexts of these higher - order formalisms as inductive relations , and a variant of the backchaining procedure that allows us to use properties of these inductive characterizations in a modular way .",
    "we have validated our design and methodology by implementing an extended abella system and by using it to develop a number of non - trivial examples of reasoning over higher - order specifications .    _",
    "acknowledgments _ : we thank dale miller , olivier savary - blanger and the anonymous reviewers for helpful discussions and comments on earlier drafts .",
    "this work has been partially supported by the nsf grants oise-1045885 ( reussi-2 ) and ccf-0917140 and by the inria associated team rapt .",
    "opinions , findings , and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the national science foundation .",
    "b.  accattoli .",
    "proof pearl : abella formalization of lambda calculus cube property . in c.",
    "hawblitzel and d.  miller , editors , _ second international conference on certified programs and proofs _ , volume 7679 of _ lncs _ , pages 173187 .",
    "springer , 2012 .",
    "j.  cheney and c.  urban .",
    "lpha - prolog : a logic programming language with names , binding , and alpha - equivalence . in b.",
    "demoen and v.  lifschitz , editors , _ logic programming , 20th international conference _ ,",
    "volume 3132 of _ lncs _ , pages 269283 .",
    "springer , 2004 .",
    "a.  felty and d.  miller .",
    "encoding a dependent - type @xmath4-calculus in a logic programming language . in m.",
    "stickel , editor , _ proceedings of the 1990 conference on automated deduction _ , volume 449 of _ lnai _ , pages 221235 .",
    "springer , 1990 .",
    "f.  pfenning and c.  schrmann .",
    "system description : twelf  a meta - logical framework for deductive systems . in h.",
    "ganzinger , editor , _ 16th conf .  on automated deduction ( cade )",
    "_ , number 1632 in lnai , pages 202206 , trento , 1999 .",
    "springer .",
    "b.  pientka and j.  dunfield .",
    "beluga : a framework for programming and reasoning with deductive systems ( system description ) . in j.",
    "giesl and r.  hhnle , editors , _ fifth international joint conference on automated reasoning _ , number 6173 in lncs , pages 1521 , 2010 .",
    "m.  r. shinwell , a.  m. pitts , and m.  j. gabbay .",
    "freshml : programming with binders made simple . in _",
    "eighth acm sigplan international conference on functional programming ( icfp 2003 ) , uppsala , sweden _ , pages 263274 .",
    "acm press , aug .",
    "z.  snow , d.  baelde , and g.  nadathur .",
    "a meta - programming approach to realizing dependently typed logic programming . in _",
    "acm sigplan conference on principles and practice of declarative programming ( ppdp ) _ , pages 187198 , 2010 .    c.  urban and j.  cheney . avoiding equivariance in alpha - prolog . in p.",
    "urzyczyn , editor , _ typed lambda calculi and applications , proceedings _ ,",
    "volume 3461 of _ lecture notes in computer science _ , pages 401416 .",
    "springer , 2005 ."
  ],
  "abstract_text": [
    "<S> the logic of hereditary harrop formulas ( ) has proven useful for specifying a wide range of formal systems that are commonly presented via syntax - directed rules that make use of contexts and side - conditions . </S>",
    "<S> the two - level logic approach , as implemented in the abella theorem prover , embeds the specification logic within a rich reasoning logic that supports inductive and co - inductive definitions , an equality predicate , and generic quantification . </S>",
    "<S> properties of the encoded systems can then be proved through the embedding , with special benefit being extracted from the transparent correspondence between derivations and those in the encoded formal systems . </S>",
    "<S> the versatility of relies on the free use of nested implications , leading to dynamically changing assumption sets in derivations . realizing an induction principle in this situation is nontrivial and the original abella system uses only a subset of for this reason . </S>",
    "<S> we develop a method here for supporting inductive reasoning over all of . </S>",
    "<S> our approach relies on the ability to characterize dynamically changing contexts through finite inductive definitions , and on a modified encoding of backchaining for that allows these finite characterizations to be used in inductive arguments . </S>",
    "<S> we demonstrate the effectiveness of our approach through examples of formal reasoning on specifications with nested implications in an extended version of abella . </S>"
  ]
}