{
  "article_text": [
    "probabilistic grammars are of great interest for computational natural language processing ( nlp ) , e.g. , because they allow the resolution of structural ambiguities by a probabilistic ranking of competing analyses .",
    "a prerequisite for such applications is parameter estimation , i.e , a method to adapt the model parameters to best account for a given language corpus .",
    "clearly , an estimation technique similar to the well - known maximization technique of @xcite for context - free models would be desirable also for constraint - based models .",
    "baum s maximization technique permits model parameters to be efficiently estimated from incomplete , i.e. , unparsed data rather than from complete , i.e. , fully parsed data .",
    "recently , an attempt to apply this estimation technique to a probabilistic version of the constraint logic programming ( clp ) scheme of @xcite has been presented by @xcite . as recognized by eisele",
    ", there is a context - dependence problem associated with applying this technique to constraint - based systems .",
    "that is , incompatible variable bindings can lead to failure derivations , which cause a loss of probability mass in the estimated probability distribution over derivations .",
    "this probability leakage prevents the estimation procedure from yielding the desired maximum likelihood values in the general case . a similar problem troubles",
    "every attempt to embed baum s maximization technique into an estimation procedure for probabilistic analogues of a constraint - based processing systems ( see , e.g. , @xcite , @xcite , @xcite , @xcite , or @xcite ) . from a mathematical point of view",
    ", all such constraint - based approaches contradict the inherent assumptions of baum s maximization technique which require that the derivation steps are mutually independent and that the set of licensed derivations is unconstrained .",
    "only recently , @xcite has shown how to overcome this problem by using the algorithm of @xcite for estimation .",
    "this method , however , applies only to complete data .",
    "unfortunately , the need to rely on large samples of complete data is impractical . for parsing applications",
    ", complete data means several person - years of hand - annotating large corpora with specialized grammatical analyses .",
    "this task is always labor - intensive , error - prone , and restricted to a specific grammar framework , a specific language , and a specific language domain . clearly , flexible techniques for parameter estimation of probabilistic constraint - based grammars from _ incomplete data _ are desirable .",
    "the aim of this paper is to solve the problem of parameter estimation from incomplete data for probabilistic constraint - based grammars . for this aim ,",
    "we present a log - linear probability model for clp .",
    "clp is used here to provide an operational treatment of purely declarative grammar frameworks such as patr , lfg or hpsg . a probabilistic clp scheme",
    "then yields a formal basis for probabilistic versions of various constraint - based grammar formalisms .",
    "the probabilistic model defines a probability distribution over the proof trees of a constraint logic program on the basis of weights assigned to arbitrary properties of the trees . in nlp applications ,",
    "such properties could be , e.g. , simply context - free rules or context - sensitive properties such as subtrees of proof trees or non - local head - head relations .",
    "the algorithm we will present is an extension of the estimation method for log - linear models of @xcite to incomplete - data settings .",
    "furthermore , we will present a method for automatic property selection from incomplete data .",
    "the rest of this paper is organized as follows .",
    "section [ clp ] introduces the basic formal concepts of clp .",
    "section [ loglinearmodel ] presents a log - linear model for probabilistic clp .",
    "parameter estimation and property selection of log - linear models from incomplete data is treated in sect .",
    "[ statisticalinference ] . concluding remarks are made in sect .",
    "[ conclusion ] .",
    "in the following we will quickly report the basic concepts of the clp scheme of @xcite .",
    "a constraint - based grammar is encoded by a constraint logic program with constraints from a grammar constraint language embedded into a relational programming constraint language .",
    "let us consider a simple non - linguistic example .",
    "the program of fig .",
    "[ program ] consists of five definite clauses with embedded -constraints from a language of hierarchical types .",
    "the ordering on the types is defined by the operation of set inclusion on the denotations ( @xmath0 ) of the types and @xmath1 , @xmath2 , and @xmath3 .",
    "[ cols= \" < \" , ]",
    "we have presented a probabilistic model for clp , coupled with an algorithm to induce the parameters and properties of log - linear models from incomplete data .",
    "this algorithm is applicable to log - linear probability distributions in general , and has been shown here to be useful to estimate the parameters of probabilistic context - sensitive nlp models .",
    "in contrast to related approaches such as that of @xcite or @xcite , our statistical inference algorithm provides the means for automatic and reusable training of probabilistic constraint - based grammars from unparsed corpora .",
    "furthermore , heuristic search algorithms for finding the most probable analysis in the clp model can be based upon this probability model .",
    "for example , a combination of the dynamic - programming techniques of earley deduction @xcite and viterbi - searching @xcite could be employed .",
    "depending on the class of constraint - based grammars under consideration , a considerable gain in search efficiency can be obtained .",
    "the statistical inference algorithm presented is fully implemented and has already been tested empirically with simple examples . clearly , the performance of the presented techniques in real - world nlp problems has to be thoroughly investigated .",
    "unfortunately , the current availability of broad - coverage constraint - based grammars limited so far the empirical evaluation of the presented techniques for the area of constraint - based parsing . in future work we also will investigate the applicability of the statistical methods here described to nlp problems other than constraint - based parsing .",
    "in the following , we assume that for each property function @xmath4 some proof tree @xmath5 with @xmath6 exists , and require @xmath7 to be strictly positive on @xmath8 , i.e. , @xmath9 for all @xmath5 . furthermore , @xmath10 denotes an extended log - linear model with @xmath11 $ ] .",
    "lemma [ a < l - l ] shows that the auxiliary function @xmath12 is a lower bound on the incomplete - data log - likelihood difference @xmath13 .    [ po]lemma    [ a < l - l ] @xmath14 .",
    "@xmath15 - \\ln p_{\\lambda } [ e^{\\gamma \\cdot \\nu } ] ) \\\\ &",
    "\\geq &   \\sum_{y \\in \\mathcal{y } } ( k_{\\lambda } [ \\gamma \\cdot \\nu ] + 1   -   p_{\\lambda } [ e^{\\gamma \\cdot \\nu } ] ) \\quad \\textrm{since } \\ln x \\leq x -1 \\\\ & = &   \\sum_{y \\in \\mathcal{y } } ( k_{\\lambda } [ \\gamma \\cdot \\nu ] + 1   - \\sum_{x \\in \\mathcal{x } } ( p_{\\lambda } ( x ) e^ { \\sum^n_{i=1 } \\gamma_i \\nu_i(x )    \\frac{\\nu_\\#(x)}{\\nu_\\#(x ) } } ) ) \\\\ & = &   \\sum_{y \\in \\mathcal{y } } ( k_{\\lambda } [ \\gamma \\cdot \\nu ] + 1   - \\sum_{x \\in \\mathcal{x } } ( p_{\\lambda } ( x ) e^ { \\sum^n_{i=1 } \\gamma_i \\bar\\nu_i(x ) \\nu_\\#(x ) } ) ) \\\\ & \\geq & \\sum_{y \\in \\mathcal{y } } ( k_{\\lambda } [ \\gamma \\cdot \\nu ] + 1   - \\sum_{x \\in \\mathcal{x } } ( p_{\\lambda } ( x ) \\sum^n_{i=1 } \\bar\\nu_i(x ) e^ {   \\gamma_i \\nu_\\#(x ) } ) )   \\textrm { by jensen 's inequality } \\\\ & = &   \\sum_{y \\in \\mathcal{y } } ( k_{\\lambda } [ \\gamma \\cdot \\nu ] + 1   - p_{\\lambda } [ \\sum^n_{i=1 } \\bar\\nu_ie^ {   \\gamma_i \\nu_\\ # } ] ) \\\\ & = &   a(\\gamma , \\lambda ) .",
    "\\qed\\end{aligned}\\ ] ]    lemma [ a0=0 ] shows that there is no estimated improvement in log - likelihood at the origin , and lemma [ da = dl ] shows that the critical points of interest are the same for @xmath16 and @xmath17 .",
    "[ a0=0 ] @xmath18 .    [ da = dl ] @xmath19 .",
    "theorem [ increasingimlikelihood ] shows the monotonicity of the i m algorithm .",
    "[ po]theorem    [ increasingimlikelihood ] for all @xmath20 : @xmath21 with equality iff @xmath22 is a fixed point of @xmath23 or equivalently is a critical point of @xmath17 .",
    "@xmath24    the equality @xmath25 holds iff @xmath22 is a fixed point of @xmath23 , i.e. , @xmath26 with @xmath27 .",
    "furthermore , @xmath22 is a fixed point of @xmath23 iff @xmath28 , + @xmath29 , + @xmath30 , + @xmath31 , by lemma [ da = dl ] + @xmath32    corollary [ maximumlikelihoodestimates ] implies that a maximum likelihood estimate is a fixed point of the mapping @xmath23 .    [ po]corollary    [ maximumlikelihoodestimates ] let @xmath33 .",
    "then @xmath34 is a fixed point of @xmath23 .",
    "theorem [ convergence ] discusses the convergence properties of the i m algorithm .",
    "in contrast to the improved iterative scaling algorithm , we can not show convergence to a global maximum of a strictly concave objective function . rather , similar to the em algorithm",
    ", we can show convergence of a sequence of i m iterates to a critical point of the non - concave incomplete - data log - likelihood function @xmath17 .",
    "[ convergence ] let @xmath35 be a sequence in @xmath36 determined by the i m algorithm . then all limit points of @xmath35 are fixed points of @xmath23 or equivalently are critical points of @xmath17 .",
    "let @xmath37 be a subsequence of @xmath35 converging to @xmath38 .",
    "then for all @xmath39 : @xmath40 and in the limit as @xmath41 , for continuous @xmath16 and @xmath17 : @xmath42 .",
    "thus @xmath43 is a maximum of @xmath44 , using lemma [ a0=0 ] , and @xmath38 is a fixed point of @xmath23 .",
    "furthermore , @xmath45 , using lemma [ da = dl ] , and @xmath38 is a critical point of @xmath17 .    from this and theorem [ increasingimlikelihood ]",
    "it follows immediately that each sequence of likelihood values , for which an upper bound exists , converges monotonically to a critical point of @xmath17 .",
    "let @xmath46 be a sequence of likelihood values bounded from above .",
    "then @xmath46 converges monotonically to a value @xmath47 for some critical point @xmath34 of @xmath17 .",
    "this work was supported by the graduiertenkolleg ils at the seminar fr sprachwissenschaft , tbingen .",
    "the author would like to thank steve abney , mark johnson , graham katz and detlef prescher for their valuable comments on this paper .              ted briscoe and nick waegner .",
    "robust stochastic parsing using the inside - outside algorithm . in _ proceedings of the aaai92 workshop on probabilistically - based natural language processing techniques _ , san jose , ca , 1992 .",
    "john carroll and ted briscoe .",
    "probabilistic normalisation and unpacking of packed parse forests for unification - based grammars . in _ proceedings of the aaai fall symposium on probabilistic approaches to natural language _ ,",
    "pages 3338 , cambridge , ma , 1992 .",
    "jochen drre and michael dorna . - a formalism for linguistic knowledge representation . in jochen drre , editor , _ computational aspects of constraint - based linguistic description i _ , pages 322",
    "dyana-2 deliverable r1.2.a , 1993 .",
    "andreas eisele . towards probabilistic extensions of constraint - based grammars . in jochen drre , editor , _",
    "computational aspects of constraint - based linguistic description ii _ , pages 321 .",
    "dyana-2 deliverable r1.2.b , 1994 .",
    "fernando pereira and yves schabes . inside - outside reestimation from partially bracketed corpora . in _ proceedings of the 30th annual meeting of the association for computational linguistics _ , pages 128135 , newark , delaware , 1992 ."
  ],
  "abstract_text": [
    "<S> in this paper we present a probabilistic model for constraint - based grammars and a method for estimating the parameters of such models from incomplete , i.e. , unparsed data . whereas methods exist to estimate the parameters of probabilistic context - free grammars from incomplete data ( @xcite ) , so far for probabilistic grammars involving context - dependencies only parameter estimation techniques from complete , </S>",
    "<S> i.e. , fully parsed data have been presented ( @xcite ) . </S>",
    "<S> however , complete - data estimation requires labor - intensive , error - prone , and grammar - specific hand - annotating of large language corpora . </S>",
    "<S> we present a log - linear probability model for constraint logic programming , and a general algorithm to estimate the parameters of such models from incomplete data by extending the estimation algorithm of @xcite to incomplete data settings . </S>"
  ]
}