{
  "article_text": [
    "the ability to predict has been the single most important qualifier of what constitutes scientific knowledge , all since the successes of babylonian and greek astronomy . indeed , the famous statement of laplace that an intelligent being with complete knowledge of the present and of the laws of nature will know the future for all time , assumes that the future is completely predicated by the past , and that perfect prediction would in principle be possible . in more mathematical terms",
    "one can say that in the physical sciences , whether in the classical or the quantum regime , one believes that nature is ultimately described by differential equations , and if one knows them and how to solve them , one knows all there is to know about the world@xcite .",
    "laplacian determinism is always conditioned by the fact that in the real world initial conditions can never be known to arbitrary accuracy .",
    "more recent is the general appreciation of the fact that in the presence of deterministic chaos , predictability is even more severely limited , because small errors typically grow exponentially in time@xcite .",
    "most sufficiently complex systems in the world display chaos . therefore",
    ", most sufficiently complex systems can only be predicted for a finite time .",
    "however , there may be some aspects of a system that are stable , while others vary . to take a familiar example , weather prediction is possible , typically for about ten days on temperate latitudes , but how the wind blows on the corner of the street is in practice unpredictable from one moment to the next@xcite .",
    "the words predictability and prediction are rather empty by themselves : one has to ask for predictability of what feature against what perturbation , in particular , against a perturbation of what size . in complex and",
    "spatially extended systems one can typically talk about large - scale features and small - scale features .",
    "the predictability of a small - scale feature against a small - scale perturbation is typically shorter than the predictability of a large - scale feature against a large - scale perturbation .",
    "certainly this is not always true , and we will consider a counter example , @xmath1 turbulence , below .",
    "but it seems to be a very common situation .",
    "that successful large - scale prediction essentially can mean just assuming that things do not change , is not _",
    "per se _ an argument against prediction in the large .",
    "also in weather prediction the assumption that the weather tomorrow will be like today is a fairly good one .    in this work , a further development of results presented in the a recent brief report @xcite , we will introduce a quantity which measures predictability in the large , and apply it to hydrodynamic turbulence . before we proceed to the definitions ,",
    "let us first recall some facts about predictability in the small , i.e. the effects of dynamical chaos .",
    "a system is said to be chaotic if small ",
    "i.e. infinitesimal  perturbations grow exponentially in time .",
    "if the initial perturbation is of size @xmath2 , and the accepted error tolerance is @xmath3 , still small , then a rough estimate gives that the predictability time is @xmath4 where @xmath5 is the leading lyapunov exponent@xcite .",
    "already within the framework of infinitesimal perturbations there are important modifications to ( [ eq : lyapunov - predict])@xcite .",
    "in fact , in typical chaotic systems , ( [ eq : lyapunov - predict ] ) is not quite true@xcite .",
    "the exponent @xmath5 is a global quantity which measures the _ average _ exponential rate of separation of nearby trajectories , and fluctuations of the local exponential grow should be taken into account @xcite , but these effects are not what concerns us here . in this paper",
    "we shall address the problem of predictability in systems with many characteristic times , e.g. the case of fully developed turbulence where a hierarchy of different eddy - turnover times do exist , or when the threshold @xmath2 is not small . in these cases",
    "the predictability time @xmath6 is determined by the details of the nonlinear mechanism responsible for the growth of the error @xcite .",
    "in particular , @xmath6 may have no relation with the maximum lyapunov exponent governed by the linearized equations for the infinitesimal error .",
    "in general , in this case the predictability time strongly depends on the details of the system @xcite .    according to oseledec theorem , the leading eigenvalue of the linearized equations of motion is @xmath7 , except on a set of points of measure zero .",
    "the sub - leading eigenvalues have the form @xmath8 , and , taken together , the leading and sub - leading lyapunov exponents measure the growth rate of @xmath9-dimensional volumes spanned by @xmath9 infinitesimal vectors , where @xmath9 can range from one to the dimensionality of the space where the motion takes place .    in dynamical systems , in addition to lyapunov exponents , an important dynamical characterization is given by the kolmogorov - sinai entropy , which measures the bandwidth necessary to observe a system over time , so that it could later be faithfully reproduced from the observations@xcite .",
    "arguing heuristically , new observations are necessary if an error grows in time , and the necessary rate of accumulation of information is the growth rate of the error , and therefore one expects pesin theorem , @xmath10 to hold true for a large class of systems .",
    "it was realized by shannon that with finite error tolerance , the relevant quantity is the bandwidth necessary to observe a system such that it could later by reproduced within this error , not to arbitrarily high accuracy .",
    "this quantity was called by `` source entropy with respect to a fidelity criterion '' by shannon@xcite , and `` @xmath11-entropy '' by kolmogorov@xcite , who found analytic formulae , valid for gaussian variables and gaussian stationary processes .",
    "recently the concept of @xmath11-entropy was taken up by gaspard and wang , who computed it from experimental data in thermal turbulence@xcite , and for a very large variety of model problems in stochastic processes and statistical physics@xcite .",
    "we especially recommend their lucid and remarkably complete review@xcite .",
    "however , the @xmath11-entropy does not say all one wants to know about predictability in the large .",
    "just as the lyapunov exponent is often more relevant , and more easily computable , than the kolmogorov - sinai entropy , so the predictability time with respect to a finite perturbation should be determined by a quantity analogous to the lyapunov exponent , and not by the @xmath11-entropy .    the natural starting point in looking for such a quantity",
    "is the time it takes for a perturbation to grow from an initial size @xmath2 to a tolerance @xmath3 .",
    "we call this the @xmath12 predictability time and denote it by @xmath13 . generally speaking",
    ", the predictability time will fluctuate .",
    "the natural definition of the finite - size lyapunov exponent is therefore an average of some function of the predictability time , such that if both @xmath2 and @xmath3 are in the infinitesimal range , we will recover the usual lyapunov exponent , and an obvious choice is then @xmath14 in appendix [ app : a ] we discuss other possible definitions for the finite - size lyapunov exponent and the relation with the @xmath11-entropy .",
    "in contrast to infinitesimal perturbations , for finite perturbations the threshold @xmath3 is typically not to be taken much larger than the perturbation @xmath2 .",
    "what is interesting , and what makes finite - size lyapunov exponents different from lyapunov exponents for infinitesimal perturbations , is the dependence on  @xmath2 .",
    "this paper is organized as follows : in section [ s : multifractal ] we recall the multifractal approach to turbulence , and lorenz approach to the predictability problem within the kolmogorov theory . we show that there are no multifractal corrections to the results of lorenz , but that the scaling range for the finite - size lyapunov exponents is shorter . in section",
    "[ s : shell - model ] we describe numerical experiments on predictability in shell models for @xmath0 and @xmath1 fully developed turbulence . in section [ s : edqnm ] we present the results from the eddy damped quasi normal markovian ( edqnm ) approximation for the shell model , and compare them with the results of section [ s : shell - model ] . in section [ s : conclusion ] we summarize our results and present conclusions . in appendix",
    "[ app : a ] we discuss alternative ways of defining the finite - size lyapunov exponent .",
    "appendix  [ s : kolmogorov ] contains a derivation of the kolmogorov results of @xmath11-entropy for gaussian processes and gaussian random fields . in appendix",
    "[ s : spacetime ] we apply the results of appendix  [ s : kolmogorov ] to space - time gaussian fields with spectra as in kolmogorov 1941 theory of @xmath0 turbulence , and to fictitious @xmath15-dimensional fields that describe shell models .",
    "we show that the finite - size lyapunov exponent is the the same for any dimensionality , but the @xmath11-entropy largely depends on the dimensionality - dependent density of degrees of freedom .",
    "the results of sections [ s : multifractal ] and [ s : shell - model ] were also presented in less generality in @xcite .",
    "our understanding of high reynolds - number turbulence is still mainly based on the fundamental contribution of kolmogorov in 1941@xcite .",
    "we will here just discuss on a phenomenological level the predictions of the kolmogorov theory and of its multifractal generalizations @xcite .",
    "turbulence is a statistically stationary state of matter on macroscopic scales maintained by external forces .",
    "one considers only effects that are captured in a hydrodynamic level of description , that is the time evolution is supposed to be completely described by the macroscopic navier - stokes equations@xcite @xmath16 from the typical length scale @xmath17 , the typical fluctuations of velocity on that scale @xmath18 , and the viscosity @xmath19 , we can form the reynolds number , @xmath20 which characterizes the flow .    the multifractal model @xcite consists in assuming that at scales much less than @xmath17 , however sufficiently large that the action of viscosity is weak",
    ", the velocity differences assume a scaling form @xmath21 different values of @xmath22 are assumed to occur according to a probability distribution , which also takes a scaling form @xmath23 \\right\\ }     \\sim                        \\left(\\frac{l}{l}\\right)^{3-d(h ) } dh .",
    "\\label{eq : probability - ansatz}\\ ] ] the function @xmath24 is the fractal dimension of the subset with scaling exponent @xmath22 .",
    "the moments of the velocity differences on length scale @xmath25 can be computed as @xmath26 and , for small-@xmath25 ( i.e. in the inertial range ) , the integral in ( [ eq : moment - q ] ) can be evaluated by saddle point method : @xmath27 .",
    "\\label{eq : zeta - q}\\end{aligned}\\ ] ]    the model is physically reasonable for a large set of possible choices of the function @xmath24 , but not entirely arbitrary . by normalization , the value of @xmath24 must always be less or equal than three , and the maximum must be obtained for some @xmath22 .",
    "that is @xmath28 the function @xmath24 can have support only at positive @xmath22 , because a negative value of @xmath22 implies that velocity fluctuations in a local inertial frame of size @xmath25 increase without limit as @xmath25 tends to zero .",
    "the navier - stokes equations are derived under the assumption that all velocities are much smaller than the velocity of sound , and this condition would then no longer hold @xcite .",
    "furthermore , an exact result of kolmogorov assures that @xmath29 , so that @xmath30 where equality is obtained for at least one value of @xmath22@xcite .",
    "the inequality ( [ eq : zeta-3-inequality ] ) is the analogous for turbulence of the inequality @xmath31 for multifractal measures @xcite .    in terms of the multifractal model , the kolmogorov theory",
    "is formulated by supposing that the function @xmath24 has support only at a single point . from ( [ eq : zeta-0-inequality ] ) and ( [ eq : zeta-3-inequality ] ) it then follows that this point must be @xmath32 , and that @xmath33 .",
    "it further follows the kolmogorov law @xmath34 energy dissipation per unit mass and time , @xmath11 , has dimension @xmath35 .",
    "we could therefore also write the right - hand side in ( [ eq : kolmogorov-41 ] ) in the more familiar form  @xmath36    from ( [ eq : kolmogorov-41 ] ) it follows by balancing in ( [ eq : navier - stokesa ] ) , that viscous forces become comparable with inertial forces at the kolmogorov scale @xmath37 which marks the lower end of the inertial range : @xmath38 if there exists more than one value of @xmath22 then each @xmath22 selects a different damping scale @xmath39 . by using ( [ eq : scaling - ansatz ] ) and balancing",
    ", one gets @xcite",
    "@xmath40    lorenz investigated the predictability problem within the framework of the kolmogorov theory@xcite .",
    "let us assume that we have a disturbance on scale @xmath25 , and that it grows at a characteristic rate given by the turn - over time at this scale : @xmath41 we can turn around ( [ eq : turn - over - time ] ) and say that after a time @xmath42 a disturbance will have grown large on all scales smaller than @xmath43 the size of the disturbance will then be @xmath44 , since all the smaller scales contribute relatively little .",
    "if we call the difference between two fields @xmath2 , we can rewrite ( [ eq : turn - over - time ] ) as the predictability time with respect to a perturbation of size @xmath2 : @xmath45 in other words , the predictability time of a perturbation of size @xmath2 grows as @xmath46 in lorenz scenario .",
    "the finite - size lyapunov exponent thus decreases with the error threshold as @xmath47 .",
    "finally , we can insert @xmath2 in ( [ eq : decorrelated - scale ] ) , and find how the error grows with time : @xmath48 the upshot of these simple estimates is that finite error growth and predictability in high reynolds number turbulence are characterized by _ algebraic _ laws , very different form the _ exponential _ laws characteristic of infinitesimal perturbations in chaotic dynamical systems .",
    "we now turn to possible consequences of a spectrum of @xmath22 s to the predictability problem , in direct analogy with the lorenz theory .",
    "we start by assuming the inverse of ( [ eq : probability - ansatz ] ) that is @xmath49 \\right\\ }                  \\sim \\left(\\frac{\\delta}{v}\\right)^{\\frac{3-d(h)}{h}}dh , \\label{eq : probability - ansatz - inverse}\\ ] ] where we have identified @xmath50 with @xmath2 , and used ( [ eq : scaling - ansatz ] ) to relate @xmath25 and @xmath2 .",
    "the length @xmath25 is now assumed a fluctuating quantity , and has the interpretation of a scale such that two fields are uncorrelated on all smaller scales , given that the distance of the two configurations is @xmath2 .",
    "the finite - size lyapunov exponent is , according to ( [ eq : predict ] ) , proportional to the expectation value of the inverse predictability time : @xmath51 in the small error limit we thus expect the finite - size lyapunov exponent to scale as a power of the error size : @xmath52 .",
    "\\label{eq : chi}\\end{aligned}\\ ] ] the exponent @xmath53 is always equal to the lorenz value of @xmath54 .",
    "this follows easily from ( [ eq : zeta-3-inequality ] ) , which can be rewritten in the form @xmath55 where the equality holds for the exponent @xmath56 which dominates the third order structure function .",
    "as far as we know this result is new .",
    "one could therefore conclude that the exponent @xmath53 for the scaling of the finite - size lyapunov exponent with error threshold is a new invariant of the multifractal approach to turbulence , and that the law @xmath57 can be easily observed in numerical experiments .",
    "this is not quite simple , due to the influence of the fluctuating cut - off ( [ eq : frisch - vergassola - scale ] ) .",
    "the smallest fluctuation in a field scaling with exponent @xmath58 is @xmath59 which inversely determines the smallest value of @xmath22 contributing to a fluctuation of size @xmath2 .",
    "a modified version of ( [ eq : multifractal - predict ] ) therefore reads @xmath60 the integral is dominated by @xmath56 as long as @xmath2 is much larger than @xmath61 . for smaller @xmath2 values ,",
    "the integral is dominated by the lower end - point in ( [ eq : multifractal - predict - intermediate ] ) , which leads to an intermediate dissipative range , in the sense of frisch and vergassola@xcite . as a consequence",
    ", we have @xmath62 with @xmath63 where @xmath58 and @xmath2 are related via ( [ eq : fluctuation - scale ] ) . from ( [ eq",
    ": zeta-3-inequality ] ) follows that @xmath56 is less or equal to @xmath64 in the multifractal approach , and therefore the bottom of the scaling range of the finite - size lyapunov exponent is larger than the corresponding error size in the kolmogorov theory .",
    "the scaling range for the finite - size lyapunov exponent thus is generally shorter in a multifractal model .",
    "simplified dynamical models of fluid turbulence with relatively few degrees of freedom , collectively referred to as _",
    "shell models _ , have been studied since the seventies .",
    "these models by construction typically include a richardson cascade of energy from large to small scales . some of the models are dynamically stable , with a fixed point which reproduces the kolmogorov law for the energy spectrum , @xmath65 .",
    "an historical overview , with references to much of the early work , can be found in a recent monograph @xcite .",
    "more interestingly , other models are dynamically unstable , with chaotic motion taking place on a strange attractor where the kolmogorov @xmath66 law holds to good accuracy , but not exactly .",
    "one of the simplest example is the family of models introduced by gledzer@xcite , and yamada and ohkitani @xcite , now commonly called the goy models@xcite .",
    "they have recently been the subject of several investigations @xcite .",
    "an in - depth description of this work can also be found in @xcite .",
    "the goy models are defined as follows : fourier space is divided into @xmath67 shells , labeled by the wave - vector modulus @xmath68 , where @xmath69 is a constant . the velocity difference over a length scale @xmath70",
    "are represented , each by one complex variable @xmath71 , which obey the following system of coupled ordinary differential equations : @xmath72 where @xmath73 is the strength of the external force , acting on large scales , and @xmath19 the viscosity . for any values of the three coefficients @xmath74 , @xmath75 and @xmath76 , phase space volume in preserved in the force - free inviscid limit .",
    "the restricted number of degrees of freedom is both the main advantage and disadvantage of shell models .",
    "it is an advantage , because it allows simulations at much lower viscosity and for much longer time than in the full navier - stokes equations .",
    "but it is also a severe departure .",
    "all spatial structure of the field is ignored .",
    "one of the coefficients in ( [ eq : sh3 ] ) , say @xmath74 , can be scaled to one and the condition of energy conservation fixes one more , such that , in terms of one parameter @xmath11 , @xmath75 is equal to @xmath77 and @xmath76 to @xmath78 . with @xmath11",
    "greater than one the goy equations conserve one more positive definite quantity besides energy , i.e. an analogous situation to @xmath1 hydrodynamics .",
    "the dynamical behavior of the goy models in this range is rather far removed from @xmath1 turbulence as was shown in recent papers@xcite .",
    "we include below a study of predictability in such shell models , but just as a simplified model to demonstrate one possible scaling behavior of the finite - size lyapunov exponent .    with parameter @xmath11 in the range between and zero and one , the goy models also preserve another invariant , but which is not positive definite .",
    "in the following we will look at the goy model with the standard choice of @xmath11 equal to @xmath79 , i.e. @xmath80",
    "the second invariant then has physical dimension of helicity@xcite .",
    "presumably that is the reason why this particular model has turned out to be so close to numerical and experimental data on navier - stokes turbulence in @xmath0 @xcite .",
    "before we turn to the numerical experiments , let us summarize some salient features of the system defined by ( [ eq : sh1])-([eq : goy_standard ] ) .",
    "energy is pumped into the system by the force , which acts only on shells with low values of @xmath81 , and is removed at high shells by viscosity . from @xmath69 , @xmath19 and the typical fluctuations of velocity on large scales , @xmath18 , we can form a reynolds number @xmath82 .",
    "we consider the situation where @xmath83 is large , such that there is a wide range in @xmath81 where the external and viscous forces are both negligible compared to the inertial forces . in this inertial range , we have @xmath84 , where the exponent @xmath85 is close to @xmath86@xcite .",
    "an estimate of the smallest excited scale is in analogy with the kolmogorov scale @xmath87 .",
    "the slowest dynamical scale is the time - scale of the the shells containing most energy , about @xmath88 , and the fastest is @xmath89 , or , about @xmath90 . from the fastest time - scale",
    "follows by dimensional analysis in the kolmogorov theory that the leading lyapunov exponent should grow with reynolds number as @xmath91 , a prediction due to ruelle@xcite . in the multifractal picture",
    "there are corrections to this estimate and that the leading lyapunov exponent of the goy shell model scales as @xmath92 where @xmath93.\\ ] ] it is indeed numerically observed to scale as @xmath94 , in good agreement with a computation of @xmath95 staring from a function @xmath24 , obtained by a parametric fit of measured values of the scaling exponents @xmath96 in experiments@xcite .    the mean square fluctuations at the kolmogorov scale are @xmath97 . if we compute the distance between two shell variable configurations as @xmath98 an error smaller than @xmath99 is relatively small all over the inertial range .",
    "it can be taken to be infinitesimal , and its growth rate will be the fastest linear growth rate .    if , however , the error is larger than @xmath99 , it could be larger than the typical size of the fluctuations at the kolmogorov scale .",
    "such an error would have to be concentrated on larger scales , since otherwise we have that for some @xmath81 @xmath71 and/or @xmath100 is much larger than the typical size .",
    "in other words , a physical perturbation larger than @xmath99 can not be obtained by a random perturbation of that size uniformly distributed over all the shells .    in the appendix [ app :",
    "a ] we discuss some possible definitions for the finite lyapunov - exponents . in what follows",
    "we adopt the following procedure : after a long integration time to let the system relax towards the statistically stationary state , we introduce a very small error .",
    "this is done by generating a new shell variable configuration @xmath101 differing from @xmath71 by a small fraction of @xmath102 .",
    "another possible approach would be , that if we want an initial error of size @xmath11 , we determine a shell @xmath103 such that @xmath104 is about @xmath11 , and we concentrate the perturbation on shells above @xmath103 .",
    "we then iterate @xmath71 and @xmath101 ( perturbed system ) for again a long time , such that the error has grown to a threshold , which is still small compared to @xmath105 .",
    "we thus have two realizations of configurations in the statistically stationary state , which only differ by a small error , which we call @xmath106 .",
    "further we define a series of thresholds @xmath107 , and we measure the times it takes for the error to grow from @xmath106 to @xmath108 , and so on . for brevity we will call these times error doubling times , even if @xmath109 can be different from two .",
    "the threshold rate @xmath109 should not be taken too large , because then the error has to grow through several different scales before reaching the next threshold .",
    "on the other hand , the rate @xmath109 can not be too close to one , so a sensible threshold rate is on the order of two .",
    "the most convenient choice of @xmath109 clearly depends on the how the fluctuations in the shell variable depend on @xmath81 , and in what way we measure the error . for our model ( [ eq : sh3 ] ) with error measured by ( [ eq : error_def ] ) , the range of error sizes in the inertial range is not large , scaling as @xmath110 . for 35 shells , which is the largest systems we simulate , we can take @xmath83 equal to @xmath111 , which gives an error range of about @xmath112 . with error threshold rate equal to two , that would give about @xmath113 data points , with some points lost on both ends due to boundary effects . for practical reasons",
    "we therefore take @xmath109 equal to @xmath114 .",
    "when we have performed @xmath115 error doubling experiments , we can form an estimate of the expectation value of some quantity @xmath116 : @xmath117 this is not the same as taking a time - average , since different error doubling experiments may take different times . indeed",
    ", we have @xmath118 a particular case of the above relation concerns the mean error doubling times themselves .",
    "let @xmath119 be the time it takes for an error to grow from threshold @xmath120 to @xmath121 .",
    "then @xmath122 where we have used the definition of ( [ eq : predict ] ) .",
    "the finite - size lyapunov exponents , @xmath123 , can be compared with shell turn - over times as follows : we first select a shell @xmath124 such that @xmath125 is about @xmath2 , and then estimate @xmath126 as @xmath127 , which scales as @xmath47 .",
    "this argument for typical error growth times is the same as lorenz argument for @xmath0 turbulence@xcite , discussed above in section [ s : multifractal ] .    in fig.[f :",
    "doubling - times ] we compare error doubling times and shell turn - over times , as a function of size of the perturbation and of the typical fluctuations in the corresponding shell . below the kolmogorov scale , the turn - over times increase : we are here in the dissipation range , where the shell amplitudes decrease quickly . on the other hand , the doubling times tend to a constant as the error threshold is small .",
    "we are here in the infinitesimal range , and the constant is approximatively the inverse of the lyapunov exponent . at the kolmogorov scale , there is rather large discrepancy between the lyapunov exponent and the turn - over time .",
    "this observation , that the lyapunov exponent obeys a scaling law with a sizeable numerical pre - factor , has been made before@xcite , but without a plausible explanation .",
    "we here find nice agreement with our prediction that the inertial range for the finite - size lyapunov exponent is shorter than the spectral inertial range , because the first is limited from below by the scaling exponent @xmath56 , as in equation ( [ eq : fluctuation - scale ] ) , while the second is limited from below by the scaling exponent @xmath128@xcite .    in fig .",
    "[ f : re - scaling ] we compare the error doubling times for different reynolds numbers . for small thresholds",
    "the doubling times scale as the lyapunov exponent , i.e. as @xmath129 .",
    "we also observe that the bend away from the infinitesimal growth rate occurs at smaller error scales for larger reynolds numbers .",
    "this suggests that a simple scaling ansatz can be sought in the following form : times and errors are scaled with the turn - over time and the typical scale of fluctuations at the kolmogorov scale , that is by @xmath129 and @xmath110 , respectively . in fig .",
    "[ f : re - data - collapse ] we show such re - scaled data .",
    "the data collapse is reasonable .    to improve the data collapse , taking into account multifractal corrections",
    ", we made a scaling based on multiscaling @xcite , i.e. of the form @xmath130 where @xmath131 , @xmath132 are parameter to be fixed , and @xmath133 is the scaling function . according the argument at the end of section [ s : multifractal ] , we have @xmath134 for large @xmath135 , while @xmath133 is constant for small values of @xmath135 . in the intermediate regime",
    "@xmath133 has a nontrivial form which depends on the shape of @xmath24 , as follows from eqs .",
    "( [ eq : multi - verg])-([eq : chi1 ] ) . the result",
    "is shown in fig .",
    "[ fig : multiscaling ] . the data collapse is clearly improved .",
    "we conclude this section discussing the case of @xmath1 turbulence .",
    "two dimensional euler equation has the peculiar property of an infinite number of invariants .",
    "two of them are retained in a finite fourier discretization , the energy and the average square vorticity , or enstrophy .",
    "as we previously discussed , the second conserved quantity in the goy shell model depends on the choice of the parameter @xmath11 . with",
    "the choice @xmath136 , leading to @xmath137 equations ( [ eq : sh1 ] ) conserve in the unforced and inviscid limit , in addition to the energy , the enstrophy here defined as @xmath138    despite the fact that the two - dimensional shell model has superficially the same physical justification of its three - dimensional corresponding model , it has been demonstrated that it has little to do with turbulence @xcite .",
    "moreover , all the numerical simulations of two - dimensional navier - stokes equation at sufficiently high reynolds number have demonstrated the dynamical relevance of coherent structures which emerge spontaneously from the turbulent flow .",
    "the predictability problem , which is more relevant for geophysical flows in this case than in @xmath0 turbulence , is also ruled by coherent vortex motion in the physical space , rather than modes dynamics in fourier space @xcite .    with this limitations , the study of the predictability problem , as addressed in the present paper , in two - dimensional shell model is nevertheless interesting because of the different scaling behavior with respect to the @xmath0 situation .",
    "dimensional analysis @xcite shows that in the enstrophy cascade one expects constant ",
    "i.e. independent on the scale  turn - over times .",
    "hence an argument similar to that of section [ s : multifractal ] shows that @xmath139 where @xmath5 is the largest lyapunov exponent .",
    "the predictability time for two - dimensional shell model is thus determined by a single value @xmath140 , where @xmath141 is the enstrophy flux toward small scales , up to a perturbation of the order of the large scale velocity field , where saturation effects are dominant .",
    "figure [ fig:2d ] shows the finite - size lyapunov exponent @xmath142 for a simulation with @xmath143 shells .",
    "the forcing term is now @xmath144 and @xmath145 . because of the inverse energy cascade we introduce in the equation ( [ eq : sh1 ] ) an artificial large - scale dissipation @xmath146 ( @xmath147 ) in the first shells @xmath148 @xcite .",
    "the velocity field shows a pseudo - cascade power law , see @xcite , @xmath149 in a wide range @xmath150 .",
    "the mean enstrophy flux in this range is @xmath151 which is in agreement with the dimensional evaluation of the eddy turnover time @xmath152 .",
    "the data plotted in figure [ fig:2d ] are obtained by using the method described in appendix [ app : a ] for computing the size dependent lyapunov exponent .",
    "the same results , not reported , can be obtained from the doubling time algorithm .",
    "we stress once more that , in the light of the results discussed in @xcite , two - dimensional shell model is not a good model for two - dimensional turbulence . as a consequence a discussion of the predictability problem for two - dimensional turbulence requires the direct study of navier - stokes equations @xcite .",
    "preliminary results show that this scenario remains , nevertheless , valid in the direct cascade @xcite .",
    "in this section we describe the results obtained from the eddy damped quasi - normal markovian approximation ( edqnm ) for the shell model .",
    "the basic idea of closure approximations is quite simple : write down the reynolds hierarchy for moments of the shell variables and truncate the chain to the lowest sensible order .",
    "the important point is that in the closure approximation intermittent effects are washed out , so we can directly test if the relevant mechanism is due to the existence of many characteristic times .",
    "we do not report the derivation of the edqnm equations for the shell model .",
    "the interested reader can find it in ref .",
    "@xcite .",
    "we consider two independent realizations of the shell model field , @xmath71 and @xmath153 , with the same energy spectrum @xmath154 , and both evolving according the shell model equations ( [ eq : sh1])-([eq : goy_standard ] ) .",
    "the distance between the two fields can be obtained from , cfr .",
    "( [ eq : error_def ] ) , the energy difference at shell @xmath81 : @xmath155 where @xmath156 , and @xmath157 denotes the real part . .",
    "from the definition it follows @xmath158^{1/2}.\\ ] ]    the evolution equations of @xmath159 and @xmath160 in the edqnm approximation read : @xmath161 \\\\          & \\,+ 2\\,\\epsilon\\,\\delta_{n,4 } ,    \\end{array}\\ ] ] and @xmath162 \\\\ & \\,+   2\\,\\epsilon\\,\\delta_{n,4 } ,   \\end{array}\\ ] ] where @xmath163\\,t }                  }                  { \\displaystyle                        \\nu ( k_n^2 + k_{n+1}^2 + k_{n+2}^2 ) +                        \\mu_n + \\mu_{n+1 } + \\mu_{n+2 }                    } ,           \\label{eq : theta}\\ ] ] and",
    "@xmath164 we have one free parameter , the dimensionless constant @xmath95 .",
    "it should be adjusted such that the spectrum is as similar as possible to the spectrum obtained in simulations of the full equation .",
    "the energy spectrum of the shell model in the edqnm approximation must therefore obey @xmath165 in the inertial range .",
    "the undetermined function @xmath166 is the kolmogorov constant .    on the other hand",
    "it has become clear in several independent investigations that intermittency corrections exist in shell models .",
    "the energy spectrum is therefore in reality more closely described by @xmath167 , where the exponent @xmath85 has been estimated to be @xmath168 @xcite .",
    "the function @xmath169 that gives the prefactor to the power law in the inertial range should not depend on viscosity , but depends on the forcing through @xmath11 , the mean dissipation of energy per unit time , or , equivalently , the mean energy input into the system from the force . in a really large inertial range",
    "the two power - laws are not good approximations to one other .",
    "the best that can be done is to demand that the spectra agree as closely as possible at the upper end of the inertial range .",
    "a reasonable agreement is obtained for @xmath170 , leading to @xmath171 which is the value observed both in simulations of the shell model and in experiments @xcite .",
    "the procedure described in the previous section to compute the scale dependent lyapunov exponent for the shell model can be adopted here for the closure equations . in practice after a long iteration time , to have a well stabilized energy spectrum @xmath159 , we take a small initial distance @xmath172 and perform the doubling experiment similar to those of the previous section iterating equations ( [ eq : wnedqnm ] ) .    in fig .",
    "[ fig : edqnmfig1 ] we show @xmath173 as a function of the rescaled distance @xmath174 , for different @xmath175 .",
    "the other parameters are @xmath176 shells , @xmath177 , integration step @xmath178 and @xmath179 . from fig .",
    "[ fig : edqnmfig1 ] we see that the closure approximation leads to the same scenario observed for the shell model , confirming that this is due to the existence of many characteristic scales .",
    "we note that the slope of the curve for @xmath180 is the lorenz value @xmath54 since in the edqnm approximation there are not intermittent corrections .",
    "we note that in this case , since there is not intermittency , the effective inertial range roughly coincides with the inertial range . in fig .",
    "[ fig : edqnmfig2 ] we compare @xmath181 and the inverse of the turnover time @xmath182 as a function of the distance @xmath183 . in the figure we used @xmath184 .",
    "we have introduced a generalization @xmath185 of the leading lyapunov exponent to finite perturbations of size @xmath2 . unlike the lyapunov exponent , @xmath185 contains direct information on the predictability time for an extended chaotic system and it is particularly useful in presence of several characteristic times .",
    "moreover , it is computationally no more expensive than the standard lyapunov exponent .    in the limit of infinitesimal perturbation @xmath2",
    ", the finite - size lyapunov exponent gives the leading lyapunov exponent .",
    "the way in which this limit is reached depends on the details of the particular system and gives informations about the characteristic time scales . in the case of @xmath0",
    "fully developed turbulence we have found an universal scaling law @xmath186 where the value @xmath54 of the exponent is an invariant of the multifractal approach .",
    "the scaling law is confirmed by extensive numerical simulations on shell model for turbulence at very high reynolds numbers , but we warn that it would be very difficult to observe such a scaling in experimental data because of the reduction of the scaling range in presence of intermittency .    we have also shown and discussed the relationship between our approach and the @xmath11-entropy results in literature . in conclusion , we think that it would be useful to compute the finite - scale lyapunov exponent in other complex dynamical systems , as a new tool for investigating the presence of characteristic times and the predictability properties .",
    "this work was supported by the swedish natural science research council through grant s - fo-1778 - 302 ( e.a . ) , by infn ( _ iniziativa specifica meccanica statistica fi11 _ ) and by cnr ( progetto coordinato _ predicibilit in turbolenza geofisica _ ) .",
    "thanks dipartimento di fisica , universit di roma `` la sapienza '' for hospitality . g.",
    "b. thanks the `` istituto di cosmogeofisica del cnr '' , torino , for hospitality .",
    "here we discuss some alternative ways of computing the finite - size lyapunov exponent beyond the definition ( [ eq : predict ] ) .    the first method is a modification of the standard technique @xcite .",
    "we integrate two trajectories @xmath187 and @xmath188 with initial euclidean distance @xmath189 until their separation becomes larger , at a given time @xmath190 than @xmath191 where @xmath109 is a given constant coefficient . the perturbed trajectory @xmath192 is then rescaled at the original distance @xmath2 , keeping the direction @xmath193 constant .",
    "the possible problem with this definition is that it assumes that the statistically stationary state of the system is homogeneous with respect to perturbations of finite size .",
    "one may plausibly argue that the structure of the attractor in phase space on which the motion takes place may be fractal , and not at all equally dense at all distances from a given point .",
    "the procedure outlined would then not necessarily sample in a faithful way the motion on the attractor . in practice , as it is showed by the numerical experiments , we do not find any difference with the numerical method presented in the main text , so the effect must be quite small . for",
    "the usual lyapunov exponent the problem does not exist since we only use small finite perturbations as an approximation to infinitesimal perturbations .    the finite - size lyapunov exponent at scale @xmath2",
    "is obtained by averaging the divergence rate @xmath194 along the unperturbed trajectory @xmath187 .",
    "the average @xmath195 is over many error - doubling experiments .    in the case of infinitesimal error @xmath2 , and not too large factor @xmath109",
    ", this definition leads to the maximal lyapunov exponent @xmath5 .    for maps ,",
    "the above methods have to be slightly modified since the distance between two states is not continuous in time . from eq .",
    "( [ eq : finite - lyapunov ] ) readily follows @xmath196 where @xmath190 is the minimum time such that the distance between two realizations is larger or equal to @xmath197 and @xmath198 is the distance at that time .    definition ( [ eq : alterna1 ] ) is valid for any value of @xmath109 , which however is generally assumed not too large to avoid the interference of different scales .",
    "in particular , one could think of removing the threshold condition used for defining @xmath190 and simply compute the average error growth rate at every time step .",
    "in other words , at every time step @xmath199 in the integration , the perturbed trajectory @xmath188 is rescaled to the original distance @xmath2 , keeping the direction @xmath200 constant .",
    "the finite - size lyapunov exponent is given by the average of the one - step exponential divergence : @xmath201 which is equivalent to the above definition ( [ eq : alterna1 ] ) .",
    "this method is indeed the one used for computing @xmath185 in the case of @xmath1 shell model .",
    "the one - step method ( [ eq : app3n ] ) has the advantage that it can be easily generalized to compute the sub - leading finite - size lyapunov exponent following the standard orthonormalization method @xcite .",
    "one introduces @xmath202 perturbed trajectories @xmath203 each at distance @xmath2 from @xmath204 and such that @xmath205 are orthogonal each to the others . at every time step",
    ", any difference @xmath205 is rescaled at the original value and orthogonalized , while the corresponding finite size lyapunov exponent is accumulated according to ( [ eq : app3n ] ) . here",
    "we have again the problem of the implicitly assumed homogeneity of the attractor , but also a problem of isotropy when we re - orthogonalize the perturbations .",
    "we note that this could be a more serious problem , which will not be discussed here any further .    for systems with only one positive lyapunov exponent",
    "the size dependent lyapunov exponent @xmath185 , definition ( [ eq : app2 ] ) , or ( [ eq : predict ] ) , coincides with the @xmath11-entropy widely described below in appendix [ s : kolmogorov ] and by gaspard and wang @xcite .",
    "we consider now few examples .",
    "consider a chaotic deterministic map perturbed by a gaussian term : @xmath206 where @xmath207 is a stochastic variable with gaussian distribution of zero mean and unit variance .",
    "the @xmath207 for different times @xmath81 are independent .",
    "when @xmath208 the map @xmath133 is chaotic with positive lyapunov exponent @xmath209 .",
    "a simple computation shows that @xmath210 for @xmath211 the noise term is negligible , so that @xmath212 . in the opposite limit , @xmath213 , the first term in ( [ eq : app4 ] )",
    "can be neglected so that @xmath214 .",
    "thus in one iteration of the map the distance between the two trajectories grows to @xmath215 , larger than the tolerance . from ( [ eq : app2 ] ) we have @xmath216 .",
    "these are the same result obtained for the @xmath11-entropy , see sect .",
    "3.5 of ref .",
    "@xcite .",
    "consider the gaussian process described by the langevin equation @xmath217 where @xmath218 and @xmath37 is a white noise with zero mean and correlation @xmath219 .",
    "the formal solution of ( [ eq : app5 ] ) reads @xmath220 so that the distance between two different process behaves in time as @xmath221 this implies that @xmath222 , and thus the predictability time @xmath223 behaves as @xmath224 so that @xmath225 , as found for the @xmath11-entropy , see below or sect .",
    "3.6.2 of @xcite .",
    "similar computations can be done for the yaglom noise , see sect .",
    "3.6.3 of @xcite .      the one - dimensional map",
    "@xmath226 presents deterministic diffusion .",
    "for example for @xmath227 the diffusion coefficient is @xmath228 .",
    "the size dependent lyapunov exponent for this map can be computed numerically using the definition ( [ eq : app2 ] ) . from fig .",
    "[ fig : det - diff ] we see that @xmath229 for small @xmath2 , while @xmath230 for large values of @xmath2 .",
    "the @xmath11-entropy shows the same behavior , see fig .",
    "25.b of ref . @xcite .",
    "note that in ref .",
    "@xcite the @xmath11-entropy is measured in unit of digit / iteration , so there is a multiplicative factor @xmath231 with @xmath185 of fig .",
    "[ fig : det - diff ] .",
    "the purpose of this appendix is to derive systematically on a physical level of rigor the results of kolmogorov on the @xmath11-entropy of gaussian variables and gaussian processes and random fields .",
    "these results were stated without proof by kolmogorov @xcite , and in the review by tikhomirov @xcite .",
    "the published proofs we are aware of are either not easily accessible , or carried out in such generality that the simple underlying idea may be lost to the less mathematically inclined reader .",
    "hence the interest of including a simple derivation here .",
    "let us just for completeness refer to comparatively recent paper @xcite .",
    "the general setting is that of two random variables @xmath232 and @xmath37 , taking values in spaces @xmath233 and @xmath234 .",
    "the values in two realizations of @xmath232 and @xmath37 are denoted @xmath135 and @xmath235 , respectively , where @xmath135 lies in @xmath233 and @xmath235 lies in @xmath234 . when @xmath233 and @xmath234 are continuous the probability distributions of @xmath232 and @xmath37 will be denoted @xmath236 and @xmath237 . except for the trivial case , the variables @xmath232 and @xmath37 are not independent , but characterized by the joint probability distribution @xmath238 .",
    "the single - variable probabilities are determined from the joint distribution as @xmath239    the conditional probabilities are @xmath240      we suppose in this subsection that the spaces @xmath233 and @xmath234 are discrete , and consist of finitely many points , @xmath241 and @xmath242 , and associated probabilities @xmath243 and @xmath244 .",
    "the _ entropy _ of the random variable @xmath232 is @xmath245 if we want to code a message of @xmath115 letters , which are given by @xmath115 consecutive independent realizations of @xmath232 , so taking values in @xmath246 , this can be done , in the limit when @xmath115 is large , by using @xmath247 bits per letter @xcite .",
    "the pair @xmath232 and @xmath37 specify both a source signal and the output after sending the signal through a channel of transmission .",
    "the joint probability distribution @xmath248 can be decomposed either to the pair @xmath232 ( an input ) and @xmath249 ( an output , given the input ) , or to the pair @xmath37 and @xmath250 . in the discrete case these second conditional probabilities",
    "are denoted @xmath251 , where @xmath252 ranges from one to @xmath81 , and @xmath253 ranges from one to @xmath254 .",
    "the _ equivocation _ is @xmath255 shannon @xcite considered a _",
    "experiment where we send an error - correcting message parallel to the transmission of @xmath232 to @xmath37 , and asked for the number of bits in the error - correcting message needed to transmit @xmath115 letters in the original message virtually without error . in the limit of large @xmath115 , the answer is @xmath256 bits per letter .",
    "suppose further that we have some source of information which we can recode into letters from @xmath232 , then transmit to @xmath37 , and then observe .",
    "the rate of transmission of information is not the source entropy , since we must correct for the equivocation , but the _ mutual information _ :",
    "@xmath257 if we introduce the discrete joint probabilities @xmath258 and rearrange terms , we see that ( [ eq : mutual - information ] ) can be rewritten as in a more symmetrical way , namely : @xmath259    a channel of transmission of information can be considered as a collection of pairs @xmath232 and @xmath37 , where the @xmath232 s are the possible inputs , and the @xmath37 s the corresponding outputs .",
    "the _ capacity _ of the channel is the maximum rate of information transfer : @xmath260 where the maximization is performed over the collection of pairs @xmath232 and @xmath37 that describe the channel .",
    "the fundamental shannon theorem says that a source signal can be transmitted over a channel , if the source entropy is less than the channel capacity .",
    "suppose finally that we have an input @xmath232 and we wish that the output @xmath37 contains only some partial information about @xmath232 , saying that some fidelity criterion is fulfilled .",
    "we consider all channels consisting of the fixed source @xmath232 and different outputs @xmath37 .",
    "the least rate of information transfer needed to specify @xmath232 in this way is _ source entropy with respect to the fidelity criterion _ : @xmath261 where the minimization is performed over all @xmath37 which satisfy the criterion with @xmath232 .    in practice",
    "many fidelity criteria can be written @xmath262 where @xmath263 is some suitable function and @xmath11 is a measure of the fidelity . in this case",
    "the source entropy is naturally considered as a function of @xmath11 , and we have the kolmogorov @xmath11-entropy @xmath264      suppose we have a random variable with a continuous distribution , that is @xmath265 with continuous density @xmath266 . then ( [ eq : entropy ] ) is infinite .    as stressed by kolmogorov , the mutual information , ( [ eq : mutual - information ] ) , the capacity , ( [ eq : capacity ] ) , and , in particular , the rate of information production with respect to a fidelity criterion , ( [ eq : source - entropy - shannon],[eq : source - entropy - kolmogorov ] ) , are all well - defined also in the continuous case . in other words , although a real number observed with infinite accuracy contains an infinite amount of information , a real number observed with finite accuracy contains only a finite amount of information .",
    "we can see this in a simple heuristic way as follows : if we introduce a discretization of the space @xmath233 into boxes with diameter @xmath2 , we have a new random variable that we can call @xmath267 with entropy @xmath268 where @xmath9 is the dimension of @xmath233 .    similarly , from the conditional variable @xmath250 we have a new random variable @xmath269 with equivocation @xmath270 rearranging terms as in ( [ eq : mutual - information - symmetrized ] ) , the mutual information between @xmath267 and @xmath37 is thus @xmath271 as the discretization tends to zero the mutual information tends to a finite value , provided that the joint probability @xmath238 is not singular with respect to the product @xmath272 , a result due to yaglom and gelfand@xcite",
    ".    we can give a meaning to the most random continuous distribution with respect some given constraints by maximizing the entropy of a discretized continuous variable , as in ( [ eq : entropy - discretized ] ) , subject to these constraints , and then letting the discretization tend to zero . the most random distribution with given first and second moments",
    "is thus , not surprisingly , a gaussian distribution with the same first and second moments .",
    "the entropy of a discretization of a @xmath9-dimensional real gaussian random variable @xmath232 with correlation matrix @xmath273 is @xmath274 all these results on the gaussian distributions are due to shannon@xcite .",
    "the spaces @xmath233 and @xmath234 are now identical .",
    "we consider first a one - dimensional gaussian random variable , and then a finite - dimensional variable and show that the kolmogorov formula holds in these cases . in the next subsection , we then observe that the fourier components of gaussian processes and gaussian random fields are independent gaussian random variables , and so , taking the the formal infinite - dimensional limit , we find the desired result",
    ".    the fidelity criterion will be the mean square deviation : @xmath275 let us first estimate the answer by dimensional arguments .",
    "if the finite - dimensional normal variable @xmath232 is decomposed in its principal components , a fluctuation in direction @xmath252 will be of typical size @xmath276 . to estimate the fluctuation in direction @xmath252 with an accuracy @xmath11 we need about @xmath277 bits .",
    "the answer should therefore be of the form @xmath278 the result of the analysis will be that @xmath116 is one and @xmath279 is zero .",
    "let @xmath232 be a gaussian one - dimensional random variable with variance @xmath280 .",
    "the random variable @xmath250 is defined on the support of @xmath281 .",
    "we suppose it to have mean @xmath282 and variance @xmath283 .",
    "we have the obvious inequality @xmath284 and the equality @xmath285 on the other hand , the equivocation , ( [ eq : equivocation - discretized ] ) , with fixed outcome @xmath235 of @xmath37 and given mean @xmath282 and variance @xmath283 is maximized if the variable is gaussian with variance @xmath283 .",
    "therefore , the mutual information between @xmath232 and @xmath37 is bounded from below by @xmath286 we can therefore pose a constrained minimization problem over the auxiliary positive function @xmath283 .",
    "strictly speaking , @xmath287 is only bounded from below by the minimization , but , as we will see , the solution can be realized in terms of variables @xmath232 and @xmath37 with desired properties .",
    "either one or the other of the two constraints will be satisfied at the minimum in ( [ eq : constrained - minimization ] ) .",
    "a variation with lagrange multipliers gives that @xmath283 must be constant , either equal to @xmath289 or to @xmath280 .",
    "we therefore have @xmath290.\\end{aligned}\\ ] ] the derivation also shows clearly that the solution can be realized as follows : if @xmath291 is less than @xmath11 , then @xmath250 is gaussian with mean zero and variance @xmath280 , and @xmath37 a delta function with support at the origin . if , on the other hand , @xmath291 is greater than @xmath11 , then @xmath250 is gaussian with mean @xmath282 equal to @xmath235 and variance @xmath289 , and @xmath37 is gaussian with mean zero and variance @xmath292 . by the semigroup property of gaussian kernels",
    "follows in both cases that @xmath232 is gaussian with mean zero and variance @xmath280 .",
    "the generalization to higher - dimensional case is as follows .",
    "the variable @xmath232 is gaussian with second moments @xmath293 , with principal components in a diagonal basis @xmath294 . at a point @xmath295 in the support of @xmath281 we consider the variable @xmath250 with first moments @xmath296 and second moments @xmath297 .",
    "we have , in analogy with the one - dimensional case , @xmath298 and @xmath299 the mutual information between @xmath232 and @xmath37 is bounded by @xmath300 some of the inequalities ( [ eq : sigma - equations ] ) may hold as equalities in the solution , some not .",
    "it does however follow from the diagonal structure of ( [ eq : sigma - equations ] ) and ( [ eq : epsilon - equation ] ) and the relation @xmath301 that when ( [ eq : mutual - information - gaussian - manyd ] ) is minimized , @xmath302 must be constant in @xmath235 and diagonal in @xmath252 and @xmath253 .",
    "let the diagonal elements of @xmath95 be @xmath303 .",
    "we then have the following simpler discrete constrained minimization problem : @xmath304 the minimum can be found by starting with all @xmath305 s very small and increasing them proportionally to the gradient , that is , at the same rate .",
    "when one of the @xmath305 s hits the constraint ( [ eq : sigma - constraints ] ) we keep it constant from thereon and increase the others .",
    "the constraint ( [ eq : epsilon - constraint ] ) will eventually be fulfilled when the @xmath305 s that still change are equal to @xmath306 , and there we stop .",
    "the solution is thus implicitly given in terms of @xmath306 , which can be interpreted as a cut - off threshold for modes where normal fluctuations are small : @xmath307 ,",
    "\\qquad       \\epsilon^2    =   \\sum_i \\min\\,\\left[\\sigma_i^2 , \\theta^2\\right ] \\label{eq : kolmogorov - formula}\\ ] ] the solution can be realized by taking @xmath37 a random variable with independent components , diagonal in the same basis as @xmath232 , and letting the @xmath252th component of @xmath232 only depend on the @xmath252th component of @xmath37 .",
    "the variables @xmath308 and @xmath309 are then constructed as in the one - dimensional case , with the only difference that the parameter @xmath306 substitutes for the error @xmath11 .",
    "let us now consider a scalar gaussian random field in @xmath310-dimensional space .",
    "a particular example ( @xmath311 ) is gaussian processes .",
    "we begin by the approximation that the field is periodic with period @xmath17 in all directions .",
    "fourier components of gaussian random fields are independently distributed gaussian random variables .",
    "therefore ( [ eq : kolmogorov - formula ] ) can be rewritten , using the volume element @xmath312 , equal to @xmath313 : @xmath314\\ , \\delta k , \\\\",
    "\\epsilon^2 \\left(\\frac{2\\pi}{l}\\right)^d & = &   \\sum_{\\bbox{k } } \\min\\ ,                     \\left[\\sigma_{\\bbox{k}}^2 , \\theta^2 \\right]\\ , \\delta k.\\end{aligned}\\ ] ] in the limit when @xmath17 tends to infinity the right hand sides turn into integrals , and the left hand sides to entropy and mean - square distance per unit volume .",
    "therefore we have @xmath315\\ , d^d k , \\label{eq : kolmogorov - entropy }   \\\\ \\epsilon^2 & = & \\left(\\frac{1}{2\\pi}\\right)^d \\int \\min\\ , \\left[e(\\bbox{k } ) , \\theta^2\\right]\\ , d^d k. \\label{eq : kolmogorov - error}\\end{aligned}\\ ] ] which , for @xmath310 equal to one , is the kolmogorov result for the @xmath11-entropy per unit time of a gaussian random process .",
    "we note that @xmath306 is still a cut - off to eliminate modes such that the energy of the fluctuations in these modes is less than @xmath316 . in fields with a power - law spectrum , such as turbulence",
    ", @xmath306 can simply be substituted for a wave - number cut - off @xmath317 .",
    "the mean square fidelity criterion is convenient for analytical computations , but it is not the only one possible .",
    "shannon lists also the maximum distance , another choice would be the mean absolute distance .    more interestingly , there may be cases where the most appropriate fidelity criteria is not simply proportional to the distance in the mean or in maximum value . if the signal @xmath232 is a lvy - process it will have a non - negligible probability of changing by a large amount over a short interval of time@xcite .",
    "in many applications one would then like an approximating signal @xmath37 to capture well the large jumps , but one would be less interested in a very precise approximation when @xmath232 changes comparatively little@xcite .",
    "a reasonable fidelity criterion would then be that there is only a small probability that the distance between @xmath232 and @xmath37 is large .",
    "as far as we know no investigations have been performed of the entropy of such sources with respect to such fidelity criteria .",
    "of course , for a lvy process a mean square error function is not possible , since the second moment is infinite . it would be possible to use mean absolute error , as was done implicitly by gaspard and wang in @xcite , but the relevance of such computation would have to be motivated in each case by the application at hand",
    "in this appendix we want to discuss and compare the finite - size lyapunov exponent and the @xmath11-entropy for a turbulent flow and for the shell model .",
    "we assume that the flow and the shell model are both gaussian as in appendix  [ s : kolmogorov ] , and we assume that the spectrum follows the kolmogorov theory , as described in section  [ s : multifractal ] .",
    "non gaussian effects and intermittency correction to the spectrum are not taken into account .    at a given error threshold @xmath2",
    ", we have seen that the finite - size lyapunov exponent scales as @xmath186 , and this holds as well for the shell model as for @xmath0 turbulence .",
    "let us now consider the @xmath11-entropy , and first give a simple dimensional estimate .",
    "it will then be seen that the expressions ( [ eq : kolmogorov - entropy ] ) ( [ eq : kolmogorov - error ] ) just reproduce this result .",
    "the dimensional estimate starts from the time scales in the kolmogorov theory , @xmath318 .",
    "the distance between two fields that only differ in wave numbers greater than @xmath202 is @xmath319 , that is , it does not depend on the dimensionality of space , but only of the form of the spectrum @xmath320 . on the other hand ,",
    "the number of degrees of freedom at wave numbers less than or equal to @xmath202 is proportional to @xmath321 .",
    "the system must be observed at a rate @xmath322 to capture all the motion in wave numbers less than @xmath202 .",
    "the amount of information per unit time and space needed to describe the system up to an error tolerance @xmath2 is thus @xmath323 .",
    "translating this into a functional dependence on @xmath2 we have @xmath324 which , for @xmath325 , leads to @xmath326 .",
    "as far as we can see there is an inconsistency between this result , also derived in @xcite , and the result stated in @xcite , which we believe is a misprint resulting from using an argument that really applies to the finite - size lyapunov exponent and not the @xmath11-entropy .",
    "the very different scaling laws @xmath327 and @xmath230 is also a further motivation why introducing the quantity finite - size lyapunov exponent .",
    "this straight - forward dimensional analysis can easily be generalized to a generic stationary gaussian processes with spectral density ( see section  6.2.6 of @xcite ) , @xmath328 the function @xmath169 is supposed to vanish for argument much larger and much smaller than unity , and its integral is on the order of unity .",
    "the energy spectrum is therefore @xmath329    we will here check that the previous dimensional estimates can also be obtained from the kolmogorov formulae ( [ eq : kolmogorov - entropy ] ) and ( [ eq : kolmogorov - error ] ) , that we write in this case as follows : @xmath330\\ , d^d k\\ , d\\omega , \\label{eq : space - time - entropy }   \\\\ \\delta^2 & = & \\left(\\frac{1}{2\\pi}\\right)^{d+1 } \\int \\min\\ , \\left[\\phi({\\bf k},\\omega ) , \\theta^2\\right]\\ , d^d k\\ , d\\omega .",
    "\\label{eq : space - time - error}\\end{aligned}\\ ] ]    the first observation is that the integral over @xmath331 in ( [ eq : space - time - error ] ) gives a contribution of order @xmath332 if @xmath333 is less than @xmath316 , but otherwise a contribution of order @xmath334 .",
    "the error is thus determined by a cut - off wave number @xmath317 such that @xmath335    the second observation is that the integral over @xmath331 in ( [ eq : space - time - entropy ] ) gives a vanishing contribution is @xmath333 is less than @xmath316 , that is , for wave numbers larger than the cut - off @xmath317 . for smaller wave numbers the integration over @xmath331 gives a contribution of the order of @xmath336 , up to a logarithmic correction that we do nt take into account .",
    "the @xmath11-entropy with cut - off wave number @xmath317 is thus @xmath337    combining ( [ eq : space - time - error ] ) and ( [ eq : space - time - entropy ] ) we find @xmath338 which is equation  ( 6.14 ) of @xcite . by inserting the values @xmath325 , @xmath339 and @xmath340 of the kolmogorov theory",
    "we reproduce the result ( [ eq : gaspard - wang - scaling ] ) ."
  ],
  "abstract_text": [
    "<S> we investigate the predictability problem in dynamical systems with many degrees of freedom and a wide spectrum of temporal scales . </S>",
    "<S> in particular , we study the case of @xmath0 turbulence at high reynolds numbers by introducing a finite - size lyapunov exponent which measures the growth rate of finite - size perturbations . for sufficiently small perturbations </S>",
    "<S> this quantity coincides with the usual lyapunov exponent . when the perturbation is still small compared to large - scale fluctuations , but large compared to fluctuations at the smallest dynamically active scales , the finite - size lyapunov exponent is inversely proportional to the square of the perturbation size . </S>",
    "<S> our results are supported by numerical experiments on shell models . </S>",
    "<S> we find that intermittency corrections do not change the scaling law of predictability . </S>",
    "<S> we also discuss the relation between finite - size lyapunov exponent and information entropy . </S>"
  ]
}