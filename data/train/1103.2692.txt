{
  "article_text": [
    "in this paper we study a bayesian approach to estimating a parameter @xmath0 from an observation @xmath1 following the model @xmath2 the unknown parameter @xmath0 is an element of a separable hilbert space @xmath3 , and is mapped into another hilbert space @xmath4 by a known , injective , continuous linear operator @xmath5 .",
    "the image @xmath6 is perturbed by unobserved , scaled gaussian white noise @xmath7 .",
    "there are many special examples of this infinite - dimensional regression model , which can also be viewed as an idealized version of other statistical models , including density estimation .",
    "the inverse problem of estimating @xmath0 has been studied by both statisticians and numerical mathematicians ( see , e.g. , @xcite for reviews ) , but rarely from a theoretical bayesian perspective ; exceptions are @xcite and @xcite .",
    "the bayesian approach to ( [ eqproblem ] ) consists of putting a prior on the parameter  @xmath0 , and computing the posterior distribution .",
    "we study gaussian priors , which are conjugate to the model , so that the posterior distribution is also gaussian and easy to derive .",
    "our interest is in studying the properties of this posterior distribution , under the `` frequentist '' assumption that the data @xmath1 has been generated according to the model ( [ eqproblem ] ) with a  given `` true '' parameter @xmath8 .",
    "we investigate whether and at what rate the posterior distributions contract to @xmath8 as @xmath9 ( as in @xcite ) , but have as main interest the performance of credible sets for measuring the uncertainty about the parameter .",
    "a bayesian _ credible set _ is defined as a central region in the posterior distribution of specified posterior probability , for instance , 95% . as a consequence of the bernstein ",
    "von mises theorem credible sets for smooth _ finite - dimensional _ parametric models are asymptotically equivalent to confidence regions based on the maximum likelihood estimator ( see , e.g. , @xcite , chapter  10 ) , under mild conditions on the prior .",
    "thus , `` bayesian uncertainty '' is equivalent to `` frequentist uncertainty '' in these cases , at least for large  @xmath10 .",
    "however , there is no corresponding bernstein ",
    "von mises theorem in nonparametric bayesian inference , as noted in @xcite .",
    "the performance of bayesian credible sets in these situations has received little attention , although in practice such sets are typically provided as indicators of uncertainty , for instance , based on the spread of the output of a ( converged ) mcmc run .",
    "the paper @xcite did tackle this issue and came to the alarming conclusion that bayesian credible sets have frequentist coverage zero .",
    "if this were true , many data analysts would ( justifiably ) distrust the spread in the posterior distribution as a measure of uncertainty . for other results see @xcite and  @xcite .",
    "the model considered in @xcite is equivalent to our model ( [ eqproblem ] ) , and a good starting point for studying these issues .",
    "more precisely , the conclusion of  @xcite is that _ for almost every parameter @xmath8 from the prior the coverage of a credible set _ ( _ of any level _ ) _ is _ 0 . in the present paper we show that this is only part of the story , and , taken by itself , the conclusion is misleading .",
    "the coverage depends on the true parameter @xmath8 and the prior together , and it can be understood in terms of a bias - variance trade - off , much as the coverage of frequentist nonparametric procedures",
    ". a nonparametric procedure that oversmoothes the truth ( too big a bandwidth in a  frequentist procedure , or a prior that puts too much weight on `` smooth '' parameters ) will be biased , and a confidence or credible region based on such a procedure will be both too concentrated and wrongly located , giving zero coverage .",
    "on the other hand , undersmoothing does work ( to a certain extent ) , also in the bayesian setup , as we show below . in this light",
    "we reinterpret the conclusion of @xcite to be valid only in the oversmoothed case ( notwithstanding a conjecture to the contrary in the introduction of this paper ; see page 905 , answer to objection  4 ) . in the undersmoothed case credible regions are conservative in general , with coverage tending to 1 .",
    "the good news is that typically they are of the correct order of magnitude , so that they do give a reasonable idea of the uncertainty in the estimate .    of course , whether a prior under- or oversmoothes depends on the regularity of  the true parameter . in practice",
    ", we may not want to consider this known , and adapt the prior smoothness to the data . in this paper",
    "we do consider the effect of changing the `` length scale '' of a prior , but do not study data - dependent length scales .",
    "the effect of setting the latter by , for example , an empirical or full bayes method will require further study .",
    "credible sets are by definition `` central regions '' in the posterior distribution .",
    "because the posterior distribution is a random probability measure on the hilbert space @xmath3 , a `` central ball '' is a natural shape of such a set , but it has the disadvantage that it is difficult to visualize . if the hilbert space is a function space , then _",
    "credible bands _ are more natural . these correspond to simultaneous credible intervals for the function at a point , and can be obtained from the ( marginal ) posterior distributions of a set of linear functionals . besides the full posterior distribution , we therefore study its marginals for linear functionals . the same issue of the dependence of coverage on under- and oversmoothing arises , except that `` very smooth '' linear functionals cancel the inverse nature of the problem , and do allow a  bernstein ",
    "von mises theorem for a large set of priors .",
    "unfortunately point evaluations are usually not smooth in this sense .    thus , we study two aspects of inverse problems  recovering the full parameter @xmath0 ( section [ sectionfull ] ) and recovering linear functionals ( section [ sectionlinear ] ) .",
    "we obtain the rate of contraction of the posterior distribution in both settings , in its dependence on parameters of the prior . furthermore , and most importantly , we study the `` frequentist '' coverage of credible regions for @xmath0 in both settings , for the same set of priors . in the next section",
    "we give a more precise statement of the problem , and in section  [ sectionpriorposterior ] we describe the priors that we consider and derive the corresponding posterior distributions . in section [ sectionvolterra ] we illustrate the results by simulations and pictures in the particular example that @xmath11 is the volterra operator .",
    "technical proofs are placed in sections  [ sectionproofs ] and [ sectiontechnical ] at the end of the paper .    throughout the paper @xmath12 and , and @xmath13 and",
    "denote the inner products and norms of the hilbert spaces @xmath3 and @xmath4 .",
    "the adjoint of an operator @xmath14 between two hilbert spaces is denoted by @xmath15 .",
    "the sobolev space @xmath16 with its norm is defined in ( [ eqdefsobolev ] ) . for two sequences @xmath17 and  @xmath18 of numbers",
    "@xmath19 means that @xmath20 is bounded away from zero and infinity as @xmath9 , and @xmath21 means that @xmath22 is bounded .",
    "the noise process @xmath7 in ( [ eqproblem ] ) is the standard normal or _ iso - gaussian process _ for the hilbert space @xmath4 . because this is not realizable as a random element in @xmath4 , the model ( [ eqproblem ] )",
    "is interpreted in process form ( as in @xcite ) .",
    "the iso - gaussian process is the zero - mean gaussian process @xmath23 with covariance function @xmath24 , and the measurement equation ( [ eqproblem ] ) is interpreted in that we observe a gaussian process @xmath25 with mean and covariance functions @xmath26 sufficiency considerations show that it is statistically equivalent to observe the subprocess @xmath27 , for any orthonormal basis @xmath28 of @xmath4 .",
    "if the operator @xmath11 is compact , then the _ spectral decomposition _ of the self - adjoint operator @xmath29 provides a convenient basis . in the compact case the operator",
    "@xmath30 possesses countably many positive eigenvalues @xmath31 and there is a corresponding orthonormal basis @xmath32 of @xmath3 of eigenfunctions ( hence , @xmath33 for @xmath34 ; see , e.g. , @xcite ) .",
    "the sequence @xmath35 defined by @xmath36 forms an orthonormal `` conjugate '' basis of the range of @xmath11 in @xmath4 .",
    "an element @xmath37 can be identified with its sequence @xmath38 of coordinates relative to the eigenbasis @xmath32 , and its image @xmath39 can be identified with its coordinates @xmath40 relative to the conjugate basis",
    "@xmath35 . if we write @xmath41 for @xmath42 , then ( [ eqmeancovy ] ) shows that @xmath43 are independent gaussian variables with means @xmath44 and variance @xmath45 .",
    "therefore , a  concrete equivalent description of the statistical problem is to _ recover the sequence @xmath38 from independent observations @xmath43 with @xmath46-distributions_.    in the following we do not require @xmath11 to be compact , but we do assume the existence of an orthonormal basis of eigenfunctions of @xmath30 .",
    "the main additional example we then cover is the _ white noise model _ , in which @xmath11 is the identity operator .",
    "the description of the problem remains the same .",
    "if @xmath47 , this problem is ill - posed , and the recovery of @xmath0 from @xmath1 an _ inverse problem_. the ill - posedness can be quantified by the speed of decay @xmath48 . although the tools are more widely applicable , we limit ourselves to the _ mildly ill - posed _ problem ( in the terminology of @xcite ) and assume that the decay is polynomial : for some @xmath49 , @xmath50 estimation of @xmath0 is harder if the decay is faster ( i.e. , @xmath51 is larger ) .",
    "the difficulty of estimation may be measured by the minimax risks over the scale of _ sobolev spaces _ relative to the orthonormal basis @xmath32 of eigenfunctions of @xmath30 . for @xmath52",
    "define @xmath53 then the sobolev space of order @xmath54 is @xmath55 .",
    "the minimax rate of estimation over the unit ball of this space relative to the loss @xmath56 of an estimate @xmath57 for @xmath0 is @xmath58 .",
    "this rate is attained by various `` regularization '' methods , such as generalized _ tikhonov _ and _ moore  penrose _ regularization @xcite .",
    "the bayesian approach is closely connected to these methods : in section  [ sectionpriorposterior ] the posterior mean is shown to be a regularized estimator .    besides recovery of the full parameter @xmath0 , we consider estimating linear functionals @xmath59 .",
    "the minimax rate for such functionals over sobolev balls depends on @xmath60 as well as on the parameter of the sobolev space .",
    "decay of the coefficients of @xmath60 in the eigenbasis may alleviate the level of ill - posedness , with rapid decay even bringing the functional in the domain of `` regular '' @xmath61-rate estimation .",
    "we assume a mean - zero gaussian prior for the parameter @xmath0 . in the next three paragraphs we recall some essential facts on gaussian distributions on hilbert spaces .",
    "a _ gaussian distribution _ @xmath62 on the borel sets of the hilbert space  @xmath3 is characterized by a _ mean _",
    "@xmath63 , which can be any element of @xmath3 , and a _ covariance operator _ @xmath64 , which is a nonnegative - definite , self - adjoint , linear operator _ of trace class _ : a compact operator with eigenvalues  @xmath65 that are summable @xmath66 ( see , e.g. , @xcite , pages 1820 ) . a random element @xmath67 in @xmath3 is @xmath62-distributed if and only if the stochastic process @xmath68 is a gaussian process with mean and covariance functions @xmath69 the coefficients @xmath70 of @xmath67 relative to an orthonormal eigenbasis @xmath71 of @xmath72 are independent , univariate gaussians with means the coordinates @xmath73 of the mean vector @xmath63 and variances the eigenvalues @xmath74",
    ".    the iso - gaussian process @xmath7 in ( [ eqproblem ] ) may be thought of as a @xmath75-distributed gaussian element , for @xmath76 the identity operator ( on @xmath4 ) , but as @xmath76 is not of trace class , this distribution is not realizable as a proper random element in @xmath4 .",
    "similarly , the data @xmath1 in ( [ eqproblem ] ) can be described as having a  @xmath77-distribution .    for a stochastic process @xmath78 and a continuous , linear operator @xmath79",
    ", we define the transformation @xmath80 as the stochastic process with coordinates @xmath81 , for @xmath82 .",
    "if the process @xmath83 arises as @xmath84 from a random element @xmath83 in the hilbert space @xmath4 , then this definition is consistent with identifying the random element @xmath85 in @xmath3 with the process @xmath86 , as in ( [ eqprocessg ] ) with @xmath87 .",
    "furthermore , if  @xmath14 is a _ hilbert  schmidt _ operator ( i.e. , @xmath88 is of trace class ) , and @xmath89 is the iso - gaussian process , then the process @xmath80 can be realized as a random variable in @xmath3 with a @xmath90-distribution .    in the bayesian setup",
    "the prior , which we take @xmath91 , is the marginal distribution of @xmath92 , and the noise @xmath7 in ( [ eqproblem ] ) is considered independent of @xmath0 .",
    "the joint distribution of @xmath93 is then also gaussian , and so is the conditional distribution of @xmath0 given @xmath1 , the posterior distribution of @xmath0 . in general , one must be a bit careful with manipulating possibly `` improper '' gaussian distributions ( see @xcite ) , but in our situation the posterior is a proper gaussian conditional distribution on @xmath3 .",
    "[ posterior ] if @xmath0 is @xmath91-distributed and @xmath1 given @xmath0 is @xmath94-distributed , then the conditional distribution of @xmath0 given @xmath1 is gaussian @xmath95 on @xmath3 , where @xmath96 and @xmath97 is the continuous linear operator @xmath98 the posterior distribution is proper ( i.e. , @xmath99 has finite trace ) and equivalent ( in the sense of absolute continuity ) to the prior .    identity ( [ a ] ) is a special case of the identity @xmath100 , which is valid for any compact , linear operator @xmath101 . that @xmath99 is of trace class is a consequence of the fact that it is bounded above by @xmath72 ( i.e. , @xmath102 is nonnegative definite ) , which is of trace class by assumption .",
    "the operator @xmath103 has trace bounded by @xmath104 and hence is of trace class .",
    "it follows that the variable @xmath105 can be defined as a random element in the hilbert space @xmath3 , and so can @xmath106 , for  @xmath14 given by the first expression in ( [ a ] ) .",
    "the joint distribution of @xmath93 is gaussian with zero mean and covariance operator @xmath107 using this with the second form of @xmath14 in ( [ a ] ) , we can check that the cross covariance operator of the variables @xmath108 and @xmath1 ( the latter viewed as a  gaussian stochastic process in @xmath109 ) vanishes and , hence , these variables are independent .",
    "thus , the two terms in the decomposition @xmath110 are conditionally independent and degenerate given @xmath1 , respectively .",
    "the distribution of @xmath108 is zero - mean gaussian with covariance operator @xmath111 , by the independence of @xmath108 and  @xmath106 .",
    "this gives the form of the posterior distribution .",
    "the final assertion may be proved by explicitly comparing the gaussian prior and posterior .",
    "easier is to note that it suffices to show that the model consisting of all @xmath112-distributions is dominated . in that case",
    "the posterior can be obtained using bayes rule , which reveals the normalized likelihood as a density relative to the ( in fact , _ any _ ) prior . to prove domination",
    ", we may consider equivalently the distributions @xmath113 on @xmath114 of the sufficient statistic @xmath115 defined as the coordinates of @xmath1 relative to the conjugate spectral basis .",
    "these distributions , for @xmath116 , are equivalent to the distribution @xmath117 , as can be seen with the help of kakutani s theorem , the affinity being @xmath118 .",
    "( this argument actually proves the well - known fact that the gaussian shift experiment obtained by translating the standard normal distribution on @xmath114 over its rkhs @xmath119 is dominated . )    in the remainder of the paper we study the asymptotic behavior of the posterior distribution , under the assumption that @xmath120 for a  fixed @xmath121 .",
    "the posterior is characterized by its _ center _",
    "@xmath106 , the posterior mean , and its _ spread _ , the posterior covariance operator @xmath99 .",
    "the first depends on the data , but the second is deterministic . from a frequentist - bayes perspective",
    "both are important : one would like the posterior mean to give a good estimate for @xmath8 , and the spread to give a good indication of the uncertainty in this estimate .",
    "the posterior mean is a regularization , of the tikhonov type , of the naive estimator @xmath122 .",
    "it can also be characterized as a penalized least squares estimator ( see @xcite ) : it minimizes the functional @xmath123 the penalty @xmath124 is interpreted as @xmath125 if @xmath0 is not in the range of @xmath126 . because this range is precisely the _ reproducing kernel hilbert space _ ( rkhs ) of the prior ( cf .",
    "@xcite ) , with @xmath124 as the rkhs - norm of @xmath0 , the posterior mean also fits into the general regularization framework using rkhs - norms ( see @xcite ) . in any case the posterior mean is a well - studied point estimator in the literature on inverse problems . in this paper",
    "we add a bayesian interpretation to it , and are ( more ) concerned with the full posterior distribution .",
    "next consider the posterior distribution of a linear functional @xmath59 of the parameter .",
    "we are not only interested in continuous , linear functionals @xmath127 , for some given @xmath128 , but also in certain discontinuous functionals , such as point evaluation in a hilbert space of functions .",
    "the latter entail some technicalities .",
    "we consider _ measurable linear functionals relative to the prior _ @xmath91 , defined in @xcite , pages 2729 , as borel measurable maps @xmath129 that are linear on a measurable linear subspace @xmath130 such that @xmath131 .",
    "this definition is exactly right to make the marginal posterior gaussian .",
    "[ posteriorlinear ] if @xmath0 is @xmath91-distributed and  @xmath1 given @xmath0 is @xmath94-distributed , then the conditional distribution of @xmath59 given @xmath1 for a @xmath91-measurable linear functional @xmath129 is a gaussian distribution @xmath132 on @xmath133 , where @xmath134 and @xmath97 is the continuous linear operator defined in ( [ a ] ) .    as in the proof of proposition",
    "[ posterior ] , the first term in the decomposition @xmath135 is independent of @xmath1 .",
    "therefore , the posterior distribution is the marginal distribution of @xmath136 shifted by @xmath137 .",
    "it suffices to show that this marginal distribution is @xmath138 .    by theorem 1 on page 28 in @xcite",
    ", there exists a sequence of continuous linear maps @xmath139 such that @xmath140 for all @xmath141 in a set with probability one under the prior @xmath142 .",
    "this implies that @xmath143 for _ every _ @xmath82 . indeed , if @xmath144 and @xmath145 , then @xmath146 and @xmath147 are disjoint measurable , affine subspaces of @xmath3 , where @xmath148 .",
    "the range of @xmath126 is the rkhs of @xmath149 and , hence , if @xmath150 is in this range , then @xmath151 , as @xmath149 shifted over an element from its rkhs is equivalent to @xmath149 .",
    "but then @xmath147 and @xmath152 are not disjoint .    therefore , from the first definition of @xmath14 in ( [ a ] ) we see that @xmath153 , and , hence , @xmath154 , almost surely .",
    "as @xmath155 is continuous , the variable @xmath156 is normally distributed with mean zero and variance @xmath157 , for @xmath99 given by ( [ postcov ] ) .",
    "the desired result follows upon taking the limit as @xmath158 .    as shown in the preceding proof",
    ", @xmath91-measurable linear functionals @xmath60 automatically have the further property that @xmath159 is a continuous linear map .",
    "this shows that @xmath160 and the adjoint operators @xmath161 and @xmath162 are well defined , so that the formula for @xmath163 makes sense .",
    "if @xmath60 is a  _ continuous _ linear operator , one can also write these adjoints in terms of the adjoint @xmath164 of @xmath60 , and express @xmath163 in the covariance operator @xmath99 of proposition  [ posterior ] as @xmath165 .",
    "this is exactly as expected .    in the remainder of the paper we study the full posterior distribution @xmath166 , and its marginals @xmath167",
    "we are particularly interested in the influence of the prior on the performance of the posterior distribution for various true parameters  @xmath8 .",
    "we study this in the following setting .",
    "[ common][ppp ] the operators @xmath168 and @xmath72 have the same eigenfunctions  @xmath32 , with eigenvalues @xmath169 and @xmath170 , satisfying @xmath171 for some @xmath172 , @xmath173 , @xmath174 and @xmath175 such that @xmath176 .",
    "furthermore , the true parameter @xmath8 belongs to @xmath16 for some @xmath52 : that is , its coordinates  @xmath177 relative to @xmath32 satisfy @xmath178 .",
    "the setting of assumption [ ppp ] is a bayesian extension of the _ mildly ill - posed inverse problem _ ( cf .",
    "we refer to the parameter @xmath54 as the `` regularity '' of the true parameter @xmath8 . in the special case",
    "that @xmath3 is a function space and @xmath32 its fourier basis , this parameter gives smoothness of @xmath8 in the classical sobolev sense .",
    "because the coefficients @xmath38 of the prior parameter @xmath0 are normally @xmath179-distributed , under assumption [ ppp ] we have @xmath180 if and only if @xmath181 .",
    "thus , @xmath182 is `` almost '' the smoothness of the parameters generated by the prior .",
    "this smoothness is modified by the _ scaling factor _ @xmath183 .",
    "although this leaves the relative sizes of the coefficients @xmath184 , and hence the qualitative smoothness of the prior , invariant , we shall see that scaling can completely alter the performance of the bayesian procedure .",
    "rates @xmath185 increase , and rates @xmath186 decrease the regularity .",
    "we denote by @xmath187 the posterior distribution @xmath166 , derived in proposition [ posterior ] .",
    "our first theorem shows that it contracts as @xmath9 to the true parameter at a rate @xmath188 that depends on all four parameters @xmath189 of the ( bayesian ) inverse problem .",
    "[ contrppp ] if @xmath190 , @xmath170 , @xmath191 and @xmath192 are as in assumption  [ ppp ] , then @xmath193 , for every @xmath194 , where @xmath195 the rate is uniform over @xmath8 in balls in @xmath16 . in particular :",
    "if @xmath196 , then @xmath197 .    if @xmath198 and @xmath199 , then @xmath200 .    if @xmath201 , then @xmath202 , for every scaling @xmath183 .",
    "the minimax rate of convergence over a sobolev ball @xmath16 is of the order @xmath58 ( see @xcite ) . by ( i ) of the theorem the posterior contraction rate is the same if the regularity of the prior is chosen to match the regularity of the truth ( @xmath203 ) and the scale @xmath183 is fixed .",
    "alternatively , the optimal rate is also attained by appropriately scaling ( @xmath199 , determined by balancing the two terms in @xmath188 ) a prior that is regular enough ( @xmath204 ) . in all other cases ( no scaling and @xmath205 , or any scaling combined with a rough prior @xmath201 ) ,",
    "the contraction rate is slower than the minimax rate .",
    "that `` correct '' specification of the prior gives the optimal rate is comforting to the true bayesian .",
    "perhaps the main message of the theorem is that even if the prior mismatches the truth , it may be scalable to give the optimal rate . here ,",
    "similar as found by @xcite in a different setting , a smooth prior can be scaled to make it `` rougher '' to any degree , but a rough prior can be `` smoothed '' relatively little ( namely , from @xmath182 to any @xmath204 ) .",
    "it will be of interest to investigate a full or empirical bayesian approach to set the scaling parameter .",
    "bayesian inference takes the spread in the posterior distribution as an expression of uncertainty .",
    "this practice is not validated by ( fast ) contraction of the posterior .",
    "instead we consider the frequentist coverage of credible sets . as the posterior distribution is gaussian",
    ", it is natural to center a  credible region at the posterior mean .",
    "different shapes of such a set could be considered .",
    "the natural counterpart of the preceding theorem is to consider balls . in the next section",
    "we also consider bands .",
    "( alternatively , one might consider ellipsoids , depending on geometry of the support of the posterior . )    because the posterior spread @xmath99 is deterministic , the radius is the only degree of freedom when we choose a ball , and we fix it by the desired `` credibility level '' @xmath206 .",
    "a _ credible ball _ centered at the posterior mean @xmath106 takes the form , where @xmath207 denotes a ball of radius @xmath208 around 0 , @xmath209 where the radius @xmath210 is determined so that @xmath211 because the posterior spread @xmath99 is not dependent on the data , neither is the radius  @xmath210 .",
    "the frequentist _ coverage _ or confidence of the set ( [ eqcredreg ] ) is @xmath212 where under the probability measure @xmath213 the variable @xmath1 follows ( [ eqproblem ] ) with @xmath214 .",
    "we shall consider the coverage as @xmath9 for fixed @xmath8 , uniformly in sobolev balls , and also along sequences @xmath215 that change with @xmath10 .",
    "the following theorem shows that the relation of the coverage to the credibility level @xmath216 is mediated by all parameters of the problem . for further insight , the credible region",
    "is also compared to the `` correct '' frequentist confidence ball @xmath217 , which has radius @xmath218 chosen so that the probability in ( [ eqcoverage ] ) with @xmath210 replaced by @xmath218 is equal to @xmath216 .",
    "[ crs][crns ] let @xmath190 , @xmath65 , @xmath191 , and @xmath183 be as in assumption  [ ppp ] , and set @xmath219 .",
    "the asymptotic coverage of the credible region ( [ eqcredreg ] ) is :    1 , uniformly in @xmath8 with @xmath220 , if @xmath221 ; in this case @xmath222 .    1 , for every fixed @xmath223 , if @xmath224 and @xmath225 ; @xmath226 , along some @xmath227 with @xmath228 , if @xmath225 ( any @xmath229 ) .    0 ,",
    "along some @xmath215 with @xmath230 , if @xmath231 .",
    "if @xmath232 , then the cases and arise if @xmath233 , @xmath203 and @xmath234 , respectively . in case",
    "the sequence @xmath215 can then be chosen fixed .",
    "the theorem is easiest to interpret in the situation without scaling ( ) . then oversmoothing the prior [ case ( iii ) : @xmath234 ] has disastrous consequences for the coverage of the credible sets , whereas undersmoothing [ case  ( i ) : @xmath233 ] leads to conservative confidence sets .",
    "choosing a prior of correct regularity [ case ( ii ) : @xmath203 ] gives mixed results .",
    "inspection of the proofs shows that the lack of coverage in case of oversmoothing arises from a bias in the positioning of the posterior mean combined with a posterior spread that is smaller even than in the optimal case .",
    "in other words , the posterior is off mark , but believes it is very right .",
    "the message is that ( too ) smooth priors should be avoided ; they lead to overconfident posteriors , which reflect the prior information rather than the data , even if the amount of information in the data increases indefinitely .",
    "under- and correct smoothing give very conservative confidence regions ( coverage equal to 1 ) .",
    "however , ( i ) and ( ii ) also show that the credible ball has the same order of magnitude as a correct confidence ball ( @xmath238 ) , so that the spread in the posterior does give the correct _ order _ of uncertainty .",
    "this at first sight surprising phenomenon is caused by the fact that the posterior distribution concentrates near the boundary of a  ball around its mean , and is not spread over the inside of the ball . the coverage is 1 , because this sphere is larger than the corresponding sphere of the frequentist distribution of @xmath106 , even though the two radii are of the same order .    by theorem [ contrppp ] the optimal contraction rate is obtained ( only ) by a prior of the correct smoothness .",
    "combining the two theorems leads to the conclusion that priors that slightly undersmooth the truth might be preferable .",
    "they attain a nearly optimal rate of contraction and the spread of their posterior gives a reasonable sense of uncertainty .",
    "scaling of the prior modifies these conclusions .",
    "the optimal scaling @xmath239 found in theorem [ contrppp ] , possible if @xmath240 , is covered in case ( ii ) .",
    "this rescaling leads to a balancing of square bias , variance and spread , and to credible regions of the correct order of magnitude , although the precise ( uniform ) coverage can be any number in @xmath241 .",
    "alternatively , bigger rescaling rates are covered in case ( i ) and lead to coverage 1 .",
    "the optimal or slightly bigger rescaling rate seems the most sensible .",
    "it would be interesting to extend these results to data - dependent scaling .",
    "we denote by @xmath242 the posterior distribution of the linear functional @xmath60 , as described in proposition [ posteriorlinear ] . a continuous",
    ", linear functional @xmath243 can be identified with an inner product @xmath244 , for some @xmath128 , and hence with a  sequence @xmath245 in @xmath119 giving its coordinates in the eigenbasis @xmath32 .    as shown in the proof of proposition [ posteriorlinear ] , for @xmath60 in the larger class of @xmath91-measurable linear functionals ,",
    "the functional @xmath246 is a continuous linear map on @xmath3 and hence can be identified with an element of @xmath3 .",
    "for such a functional @xmath60 we define a sequence @xmath245 by @xmath247 , for @xmath248 the coordinates of @xmath246 in the eigenbasis .",
    "the assumption that  @xmath60 is a  @xmath91-measurable linear functional implies that @xmath249 , but @xmath245 need not be contained in @xmath119 ; if , then @xmath60 is continuous and the definition of @xmath245 agrees with the definition in the preceding paragraph .",
    "we measure the smoothness of the functional @xmath60 by the size of the coefficients  @xmath250 , as @xmath251 .",
    "first we assume that the sequence is in @xmath252 , for some  @xmath253 .",
    "[ lincontrppp ] if @xmath190 , @xmath65 , @xmath191 and @xmath192 are as in assumption  [ ppp ] and the representer @xmath245 of the @xmath91-measurable linear functional @xmath60 is contained in @xmath252 for @xmath254 , then @xmath255 , for every sequence @xmath256 , where @xmath257 the rate is uniform over @xmath8 in balls in @xmath16 . in particular :",
    "if @xmath232 , then @xmath258 .    if @xmath259 and @xmath260 and @xmath261 , then @xmath262 .",
    "if @xmath263 and @xmath264 , then @xmath265 for every scaling @xmath183 .",
    "if @xmath266 and @xmath267 , where @xmath268 , then @xmath269 .",
    "if @xmath270 , then the smoothness of the functional @xmath60 cancels the ill - posedness of the operator @xmath11 , and estimating @xmath59 becomes a `` regular '' problem with an  @xmath61 rate of convergence . without scaling the prior ( @xmath271 ) , the posterior contracts at this rate [ see ( i ) or ( iv ) ] if the prior is not too smooth @xmath272 ) . with scaling ,",
    "the rate is also attained , with any prior , provided the scaling parameter @xmath183 does not tend to zero too fast [ see ( iv ) ] .",
    "inspection of the proof shows that too smooth priors or too small scale creates a bias that slows the rate .    if @xmath273 , where we take @xmath253 the `` biggest '' value such that @xmath274 , estimating  @xmath59 is still an inverse problem . the minimax rate over a ball in the sobolev space @xmath16",
    "is known to be bounded above by @xmath275 ( see @xcite ) .",
    "this rate is attained without scaling [ see ( i ) : @xmath271 ] if and only if the prior smoothness @xmath182 is equal to the true smoothness @xmath54 minus @xmath277 ( @xmath278 ) .",
    "an intuitive explanation for this apparent mismatch of prior and truth is that regularity of the parameter in the sobolev scale ( @xmath279 ) is not the appropriate type of regularity for estimating a linear functional @xmath59 .",
    "for instance , the difficulty of estimating a function at a point is determined by the regularity in a neighborhood of the point , whereas the sobolev scale measures global regularity over the domain .",
    "the fact that a sobolev space of order @xmath54 embeds continuously in a hlder space of regularity @xmath280 might give a quantitative explanation of the `` loss '' in smoothness by @xmath277 in the special case that the eigenbasis is the fourier basis . in our bayesian context",
    "we draw the conclusion that the prior must be adapted to the inference problem if we want to obtain the optimal frequentist rate : for estimating the global parameter , a good prior must match the truth ( @xmath203 ) , but for estimating a linear functional a good prior must consider a sobolev truth of order @xmath54 as having regularity @xmath281 .",
    "if the prior smoothness @xmath182 is not @xmath280 , then the minimax rate may still be attained by scaling the prior . as in the global problem",
    ", this is possible only if the prior is not too rough [ @xmath282 , cases ( ii ) and ( iii ) ] .",
    "the optimal scaling when this is possible [ case ( ii ) ] is the same as the optimal scaling for the global problem [ theorem [ contrppp](ii ) ] _ after _ decreasing @xmath54 by @xmath277 .",
    "so the `` loss in regularity '' persists in the scaling rate .",
    "heuristically this seems to imply that a simple data - based procedure to set the scaling , such as empirical or hierarchical bayes , can not attain simultaneous optimality in both the global and local senses .    in the application of the preceding theorem , the functional @xmath60 , and hence the sequence @xmath245 ,",
    "will be given .",
    "naturally , we apply the theorem with @xmath253 equal to the largest value such that @xmath274 .",
    "unfortunately , this lacks precision for the sequences @xmath245 that decrease exactly at some polynomial order : a  sequence @xmath283 is in @xmath284 for every @xmath285 , but not in @xmath252 . in the following theorem",
    "we consider these sequences , and the slightly more general ones such that @xmath286 , for some slowly varying sequence @xmath287 .",
    "recall that @xmath288 is _ slowly varying _ if @xmath289 as @xmath290 , for every @xmath291 .",
    "[ for these sequences @xmath292 for every @xmath285 , @xmath293 for @xmath294 , and @xmath295 if and only if @xmath296 .",
    "]    [ lincontrppprv ] if @xmath190 , @xmath65 , @xmath191 and @xmath192 are as in assumption  [ ppp ] and the representer @xmath245 of the @xmath91-measurable linear functional @xmath60 satisfies @xmath286 for a slowly varying function @xmath297 and @xmath298 , then the result of theorem [ lincontrppp ] is valid with @xmath299 where , for @xmath300 , @xmath301 this has the same consequences as in theorem [ lincontrppp ] , up to the addition of slowly varying terms .    because the posterior distribution for the linear functional @xmath59 is the one - dimensional normal distribution @xmath302 , the natural _ credible interval _ for @xmath59 has endpoints @xmath303 , for @xmath304 the ( lower ) standard normal @xmath305-quantile .",
    "the _ coverage _ of this interval is @xmath306 where @xmath1 follows ( [ eqproblem ] ) with @xmath214 . to obtain precise results concerning coverage , we assume that @xmath245 behaves polynomially up to a slowly varying term , first in the situation @xmath273 that estimating @xmath59 is an inverse problem .",
    "let @xmath307 be the ( optimal ) scaling @xmath183 that equates the two terms in the right - hand side of ( [ eqtaulrv ] ) .",
    "this satisfies @xmath308 , for a slowly varying factor  @xmath309 , where @xmath310 .",
    "[ lincrs ] let @xmath190 , @xmath65 , @xmath191 and @xmath192 be as in assumption  [ ppp ] , and let @xmath311 for @xmath312 and a slowly varying function  @xmath297 .",
    "then the asymptotic coverage of the interval @xmath303 is :    in @xmath313 , uniformly in @xmath8 such that @xmath314 if @xmath315 .    in @xmath313 , for every @xmath279 , if @xmath316 and @xmath317 ; in @xmath318 , along some @xmath319 with @xmath320 if @xmath316 [ any @xmath321 .",
    "@xmath322 along some @xmath215 with @xmath323 if @xmath324 .    in case",
    "the sequence @xmath215 can be taken a fixed element @xmath8 in @xmath16 if @xmath325 for some @xmath326 .",
    "furthermore , if @xmath232 , then the coverage takes the form as in and   if @xmath327 , @xmath281 , and @xmath328 , respectively , where in case   the sequence @xmath215 can be taken a fixed element .    similarly , as in the nonparametric problem , oversmoothing leads to coverage 0 , while undersmoothing gives conservative intervals . without scaling the cut - off for under- or oversmoothing is at @xmath281 ; with scaling the cut - off for the scaling rate is at the optimal rate @xmath307 .",
    "the conservativeness in the case of undersmoothing is less extreme for functionals than for the full parameter , as the coverage is strictly between the credibility level @xmath216 and 1 .",
    "the general message is the same : oversmoothing is disastrous for the interpretation of credible band , whereas undersmoothing gives bands that at least have the correct order of magnitude , in the sense that their width is of the same order as the variance of the posterior mean ( see the proof ) .",
    "too much undersmoothing is also undesirable , as it leads to very wide confidence bands , and may cause that @xmath329 is no longer finite ( see measurability property ) .",
    "the results ( i ) and ( ii ) are the same for every @xmath312 , even if @xmath330 .",
    "closer inspection would reveal that for a given @xmath331 the exact coverage depends on @xmath253 [ and @xmath287 ] in a complicated way .",
    "if @xmath270 , then the smoothness of the functional @xmath60 compensates the lack of smoothness of @xmath333 , and estimating @xmath59 is not a true inverse problem .",
    "this drastically changes the performance of credible intervals .",
    "although oversmoothing again destroys their coverage , credible intervals are exact confidence sets if the prior is not too smooth .",
    "we formulate this in terms of a  bernstein ",
    "von mises theorem .",
    "the bernstein ",
    "von mises theorem for parametric models asserts that the posterior distribution approaches a normal distribution centered at an efficient estimator of the parameter and with variance equal to its asymptotic variance .",
    "it is the ultimate link between bayesian and frequentist procedures .",
    "there is no version of this theorem for infinite - dimensional parameters @xcite , but the theorem may hold for `` smooth '' finite - dimensional projections , such as the linear functional @xmath59 ( see  @xcite ) .    in the present situation the posterior distribution of @xmath59 is already normal by the normality of the model and the prior",
    ": it is a @xmath167-distribution by proposition [ posteriorlinear ] .",
    "to speak of a bernstein ",
    "von mises theorem , we also require the following :    that the ( root of the ) spread @xmath334 of the posterior distribution is asymptotically equivalent to the standard deviation @xmath335 of the centering variable @xmath137 .    that the sequence @xmath336 tends in distribution to a standard normal distribution .    that the centering @xmath137 is an asymptotically efficient estimator of  @xmath59 .",
    "we shall show that ( i ) happens if and only if the functional @xmath60 cancels the ill - posedness of the operator @xmath11 , that is , if @xmath270 in theorem [ lincontrppprv ] .",
    "interestingly , the rate of convergence @xmath335 must be @xmath61 up to a slowly varying factor in this case , but it could be strictly slower than @xmath61 by a slowly varying factor increasing to infinity .    because @xmath137 is normally distributed by the normality of the model , assertion ( ii ) is equivalent to saying that its bias tends to zero faster than  @xmath335 .",
    "this happens provided the prior does not oversmooth the truth too much . for very smooth functionals ( @xmath337 )",
    "there is some extra `` space '' in the cut - off for the smoothness , which ( if the prior is not scaled : @xmath232 ) is at @xmath338 , rather than at @xmath281 as for the ( global ) inverse estimating problem .",
    "thus , the prior may be considerably smoother than the truth if the functional is very smooth .",
    "let denote the total variation norm between measures .",
    "say that @xmath339 if @xmath311 for a slowly varying function @xmath297 .",
    "write @xmath340 for the maximal bias of @xmath137 over a ball in the sobolev space @xmath16 .",
    "finally , let @xmath307 be the ( optimal ) scaling @xmath183 in that it equates the two terms in the right - hand side of  ( [ eqtaulrv ] ) .",
    "[ tbvm - reg ] let @xmath190 , @xmath65 , and @xmath191 be as in assumption [ ppp ] , and let @xmath341 be the representer of the @xmath91-measurable linear functional  @xmath60 :    if @xmath342 , then @xmath343 ; in this case @xmath344 .",
    "if @xmath339 , then @xmath343 if and only if @xmath270 ; in this case @xmath345 is slowly varying .    if @xmath346 for @xmath270 , then @xmath347 if either @xmath348 or ( @xmath232 and @xmath349 ) .",
    "if @xmath339 for @xmath270 , then @xmath347 if ( @xmath315 ) or ( @xmath232 and @xmath349 ) or ( @xmath350 , @xmath232 and @xmath338 ) or [ @xmath351 , @xmath232 and @xmath338 and @xmath352 as @xmath251 ] .",
    "if @xmath342 or @xmath354 and @xmath347 , then @xmath355 , @xmath356 and @xmath336 converges under @xmath8 in distribution to a standard normal distribution , uniformly in @xmath357 . if @xmath342 , then this is also true with @xmath137 and @xmath358 replaced by @xmath359 and its variance @xmath360 .    in both cases ,",
    "the asymptotic coverage of the credible interval @xmath303 is @xmath216 , uniformly in @xmath357 .",
    "finally , if the conditions under   fail , then there exists @xmath215 with @xmath361 along which the coverage tends to an arbitrarily low value .",
    "the observation @xmath1 in ( [ eqproblem ] ) can be viewed as a reduction by sufficiency of a random sample of size @xmath10 from the distribution @xmath362 .",
    "therefore , the model fits in the framework of i.i.d .",
    "observations , and `` asymptotic efficiency '' can be defined in the sense of semiparametric models discussed in , for example , @xcite and @xcite .",
    "because the model is shift - equivariant , it suffices to consider local efficiency at @xmath363 .",
    "the one - dimensional submodels @xmath364 on the sample space @xmath109 , for @xmath365 and a fixed `` direction '' @xmath82 , have likelihood ratios @xmath366 thus , their _ score function _ at @xmath367 is the @xmath368th coordinate of a single observation @xmath25 , the _ score operator _ is the map @xmath369 given by @xmath370 , and the _ tangent space _ is the range of  @xmath371 .",
    "[ we denote the score operator by the same symbol  @xmath11 as in ( [ eqproblem ] ) ; if the observation @xmath1 _ were _ realizable in  @xmath4 , and not just in the bigger sample space  @xmath109 , then @xmath372 would correspond to @xmath373 and , hence , the score would be exactly @xmath374 for the operator in ( [ eqproblem ] ) after identifying @xmath4 and its dual space . ]",
    "the adjoint of the score operator restricted to the closure of the tangent space is the operator @xmath375 that satisfies @xmath376 , where  @xmath377 on the right is the adjoint of .",
    "the functional @xmath378 has derivative @xmath341 .",
    "therefore , by @xcite asymptotically regular sequences of estimators exist , and the local asymptotic minimax bound for estimating @xmath59 is finite , if and only if @xmath341 is contained in the range of @xmath377 . furthermore , the variance bound is @xmath379 for @xmath380 such that @xmath381 .    in our situation",
    "the range of @xmath377 is @xmath382 , and if @xmath342 , then by theorem [ tbvm - reg](iii ) the variance of the posterior is asymptotically equivalent to the variance bound and its centering can be taken equal to the estimator @xmath383 , which attains this variance bound .",
    "thus , the theorem gives a semiparametric bernstein ",
    "von mises theorem , satisfying every of ( i ) , ( ii ) ,  ( iii ) in this case .",
    "if only @xmath354 and not @xmath342 , the theorem still gives a  bernstein ",
    "von mises type theorem , but the rate of convergence is slower than @xmath61 , and the standard efficiency theory does not apply .",
    "the classical _ volterra operator _ @xmath384 , @xmath385 \\to l^2[0,1]$ ] and its adjoint @xmath377 are given by @xmath386 the resulting problem ( [ eqproblem ] ) can also be written in `` signal in white noise '' form as follows : observe the process @xmath387)$ ] given by @xmath388 , for a brownian motion @xmath83 .",
    "the eigenvalues , eigenfunctions of @xmath30 and conjugate basis are given by ( see  @xcite ) , for @xmath389 @xmath390 the @xmath35 are the eigenfunctions of @xmath391 , relative to the same eigenvalues , and @xmath392 and @xmath393 , for every @xmath34 .    to illustrate our results with simulated data , we start by choosing a true function  @xmath8 , which we expand as @xmath394 on the basis @xmath32 .",
    "the data are the function @xmath395 it can be generated relative to the conjugate basis @xmath35 as a sequence of independent gaussian random variables @xmath396 with @xmath397 .",
    "the posterior distribution of @xmath0 is gaussian with mean @xmath106 and covariance operator @xmath99 , given in proposition [ posterior ] . under assumption [ ppp ] it can be represented in terms of the coordinates @xmath38 of @xmath0 relative to the basis @xmath32 as ( conditionally ) independent gaussian variables @xmath398 with @xmath399 the ( marginal ) posterior distribution for the function @xmath0 at a point @xmath400 is obtained by expanding @xmath401 , and applying the framework of linear functionals @xmath402 with @xmath403 .",
    "this shows that @xmath404 we obtained ( marginal ) posterior credible bands by computing for every @xmath400 a central @xmath405 interval in the normal distribution on the right - hand side .",
    "figure [ figure1 ] illustrates these bands for @xmath406 . in every one of the 10 panels in the figure the black curve represents the function @xmath8 , defined by the coefficients @xmath407 relative to @xmath408 ( @xmath409 ) .",
    "the 10 panels represent  10 independent realizations of the data , yielding 10 different realizations of the posterior mean ( the red curves ) and the posterior credible bands ( the green curves ) . in the left five panels the prior",
    "is given by @xmath410 with @xmath411 , whereas in the right panels the prior corresponds to @xmath412 .",
    "each of the 10 panels also shows 20 realizations from the posterior distribution .     and @xmath409 .",
    "left 5  panels : @xmath411 ; right 5 panels : @xmath412 .",
    "true curve ( black ) given by coefficients @xmath413 . ]    . left  5 panels : @xmath406 and @xmath414 ( top to bottom ) ; right 5 panels : @xmath415 and @xmath414 ( top to bottom ) .",
    "true curve ( black ) given by coefficients @xmath413 . ]",
    "clearly , the posterior mean is not estimating the true curve very well , even for @xmath406 .",
    "this is mostly caused by the intrinsic difficulty of the inverse problem : better estimation requires bigger sample size .",
    "a comparison of the left and right panels shows that the rough prior ( @xmath411 ) is aware of the difficulty : it produces credible bands that in ( almost ) all cases contain the true curve . on the other hand , the smooth prior ( @xmath412 )",
    "is overconfident ; the spread of the posterior distribution poorly reflects the imprecision of estimation .    specifying a prior that is too smooth relative to the true curve yields a posterior distribution which gives both a bad reconstruction and a misguided sense of uncertainty .",
    "our theoretical results show that the inaccurate quantification of estimation error remains even as @xmath9",
    ".    the reconstruction , by the posterior mean or any other posterior quantiles , will eventually converge to the true curve .",
    "however , specification of a too smooth prior will slow down this convergence significantly .",
    "this is illustrated in figure [ figure2 ] .",
    "every one of its 10 panels is similarly constructed as before , but now with @xmath406 and @xmath415 for the five panels on the left - hand and right - hand side , respectively , and with @xmath416 for the five panels from top to bottom . at first sight @xmath417",
    "seems better ( see the left column in figure [ figure2 ] ) , but leads to zero coverage because of the mismatch close to the bump ( see the right column ) , while @xmath418 captures the bump . for @xmath415",
    "the posterior for this optimal prior has collapsed onto the true curve , whereas the smooth posterior for @xmath412 still has major difficulty in recovering the bump in the true curve ( even though it `` thinks '' it has captured the correct curve , the bands having collapsed to a single curve in the figure).=-1",
    "[ sectionproofs ]      the second moment of a gaussian distribution on @xmath3 is equal to the square norm of its mean plus the trace of its  covariance operator . because the posterior is gaussian @xmath166 , it follows that @xmath419 by markov s inequality , the left - hand side is an upper bound to @xmath420 .",
    "therefore , it suffices to show that the expectation under  @xmath8 of the right - hand side of the display is bounded by a multiple of  @xmath421 .",
    "the expectation of the first term is the mean square error of the posterior mean  @xmath106 , and can be written as the sum @xmath422 of its square bias and `` variance . ''",
    "the second term @xmath423 is deterministic . under assumption [ common ]",
    "the three quantities can be expressed in the coefficients relative to the eigenbasis @xmath32 as @xmath424 by lemma [ normseries ] ( applied with @xmath425 , @xmath367 , @xmath426 , @xmath427 and @xmath428 ) , the first can be bounded by @xmath429 , which accounts for the first term in the definition of @xmath188 . by lemma [ rvseries ]",
    "[ applied with @xmath430 , @xmath431 , @xmath432 , @xmath433 , @xmath427 , and @xmath428 ] , and again lemma  [ rvseries ] [ applied with @xmath430 , @xmath431 , @xmath435 , @xmath433 , @xmath436 and @xmath437 , both the second and third expressions are of the order the square of the second term in the definition of @xmath188 .    the consequences ( i ) and ( ii ) follow by verification after substitution of  @xmath183 as given . to prove consequence ( iii ) , we note that the two terms in the definition of @xmath188 are decreasing and increasing in @xmath183 , respectively .",
    "therefore , the maximum of these two terms is minimized with respect to @xmath183 by equating the two terms .",
    "this minimum ( assumed at @xmath438 ) is much bigger than @xmath58 if @xmath439 .      by proposition [ posteriorlinear ]",
    "the posterior distribution is @xmath167 , and , hence , similarly as in the proof of theorem [ contrppp ] , it suffices to show that @xmath440 is bounded above by a multiple of @xmath421 . under assumption [ common ] the expressions on the right",
    "can be written @xmath441\\\\[-9pt ] & \\asymp & n{{\\tau}}_n^4 \\sum_i \\frac{l_i^2i^{-2 - 4{{\\alpha}}-2p}}{(1+n{{\\tau}}_n^2i^{-1 - 2{{\\alpha}}-2p})^2},\\nonumber\\\\[-2pt ] \\label{linpostspr } s_n^2 & = & \\sum_{i } \\frac{l_i^2{{\\lambda}}_i}{1+n{{\\lambda}}_i{{\\kappa}}_i^2 } \\asymp{{\\tau}}_n^2 \\sum_{i } \\frac{l_i^2 i^{-1 - 2{{\\alpha}}}}{1+n{{\\tau}}_n^2i^{-1 - 2{{\\alpha}}-2p}}.\\end{aligned}\\ ] ] by the cauchy ",
    "schwarz inequality the square of the bias ( [ linbias ] ) satisfies @xmath442 by lemma [ normseries ] ( applied with @xmath443 and @xmath428 ) the right - hand side of this display can be further bounded by @xmath444 times the square of the first term in the sum of two terms that defines @xmath188 . by lemma [ normseries ] ( applied with @xmath445 and @xmath446 ) and again lemma [ normseries ] ( applied with @xmath447 and @xmath428 ) ,",
    "the right - hand sides of ( [ linvar ] ) and ( [ linpostspr ] ) are bounded above by @xmath448 times the square of the second term in the definition of @xmath188.=-1    consequences ( i)(iv ) follow by substitution , and , in the case of ( iii ) , optimization over @xmath183 .",
    "this follows the same lines as the proof of theorem [ lincontrppp ] , except that we use lemma [ rvseries ] ( with @xmath449 , , and @xmath450 ) and lemma [ rvseries ] ( with @xmath451 , and @xmath428 ) and again lemma [ rvseries ] ( with @xmath452 , and @xmath428 ) to bound the three terms ( [ linvar])([eqsqbiaslinear ] ) .      because the posterior distribution is @xmath453 , by proposition [ posterior ] , the radius @xmath210 in ( [ eqradius ] ) satisfies @xmath454 , for  @xmath455 a random variable distributed as the square norm of an @xmath456-variable . under ( [ eqproblem ] )",
    "the variable @xmath106 is @xmath457-distributed , and , thus , the coverage ( [ eqcoverage ] ) can be written as @xmath458 for @xmath459 possessing a @xmath460-distribution .",
    "for ease of notation let @xmath461 .    the variables @xmath455 and @xmath462 can be represented as @xmath463 and @xmath464 , for @xmath465 independent standard normal variables , and @xmath466 and @xmath467 the eigenvalues of @xmath99 and @xmath468 , respectively , which satisfy @xmath469 therefore , by lemma [ rvseries ] ( applied with @xmath470 and @xmath431 ; always the first case ) , @xmath471 we conclude that the standard deviations of @xmath455 and @xmath462 are negligible relative to their means , and also relative to the difference @xmath472 of their means . because @xmath473 , we conclude that the distributions of @xmath455 and @xmath462 are asymptotically completely separated : @xmath474 for some @xmath475 [ e.g. , @xmath476 .",
    "the numbers @xmath477 are @xmath216-quantiles of @xmath455 , and , hence , .",
    "furthermore , it follows that @xmath478 the square norm of the bias @xmath479 is given in ( [ sqbias ] ) , where it was noted that @xmath480 the bias @xmath481 is decreasing in @xmath183 , whereas @xmath482 and @xmath483 are increasing .",
    "the scaling rate @xmath484 balances the square bias @xmath485 with the variance @xmath486 of the posterior mean , and hence with @xmath477 .    case ( i ) . in this case",
    "hence , @xmath488 , uniformly in the set of  @xmath8 in the supremum defining @xmath481 .",
    "case ( iii ) . in this case",
    "hence , @xmath490 for any sequence @xmath215 ( nearly ) attaining the supremum in the definition of @xmath481 .",
    "if @xmath232 , then @xmath481 and @xmath210 are both powers of @xmath45 and , hence , @xmath489 implies that @xmath491 , for some @xmath326 .",
    "the preceding argument then applies for a fixed @xmath8 of the form @xmath492 , for small @xmath493 , that gives a bias that is much closer than @xmath494 to @xmath481 .",
    "case ( ii ) . in this case @xmath495 . if @xmath240 , then by the second assertion ( first case ) of lemma [ normseries ] the bias @xmath496 at a fixed @xmath8 is of strictly smaller order than the supremum @xmath481 .",
    "the argument of ( i ) shows that the asymptotic coverage then tends to 1 .",
    "finally , we prove the existence of a sequence @xmath215 along which the coverage is a given @xmath229 . the coverage ( [ eqcoveragew ] ) with @xmath8 replaced by @xmath215 tends to @xmath226 if , for @xmath497 and @xmath498 a standard normal quantile , @xmath499 because @xmath459 is mean - zero gaussian , we have @xmath500 and @xmath501 . here",
    "@xmath502 and the distribution of @xmath503 is zero - mean gaussian with variance @xmath504 . with @xmath467",
    "the eigenvalues of @xmath468 , display ( [ eqconvergencerng ] ) can be translated in the coefficients @xmath505 of @xmath506 relative to the eigenbasis , as @xmath507 we choose @xmath505 differently in the cases that @xmath204 and @xmath508 , respectively . in both cases",
    "the sequence has exactly one nonzero coordinate .",
    "we denote this coordinate by @xmath509 , and set , for numbers @xmath510 to be determined , @xmath511 because @xmath477 , @xmath486 and @xmath512 are of the same order of magnitude , and  @xmath513 is of strictly smaller order , for bounded or slowly diverging @xmath510 the right - hand side of the preceding display is equivalent to @xmath514 .",
    "consequently , the left - hand side of ( [ hulp ] ) is equivalent to @xmath515 the remainder of the argument is different in the two cases .",
    "case @xmath204 .",
    "we choose @xmath516 .",
    "it can be verified that @xmath517 .",
    "therefore , for @xmath518 $ ] , there exists a bounded or slowly diverging sequence @xmath510 such that the preceding display tends to @xmath498 .",
    "the bias @xmath506 results from a parameter @xmath215 such that @xmath519 , for every @xmath520 .",
    "thus , @xmath215 also has exactly one nonzero coordinate , and this is proportional to the corresponding coordinate of @xmath506 , by the definition of @xmath521 .",
    "it follows that @xmath522 by the definition of @xmath183 .",
    "it follows that @xmath523 .",
    "case @xmath508 .",
    "we choose @xmath524 . in this case @xmath525 and it can be verified that @xmath526 . also , @xmath527 this is @xmath528 , because @xmath183 is chosen so that @xmath486 is of the same order as the square bias @xmath485 , which is @xmath529 in this case .",
    "it remains to prove the asymptotic normality ( [ eqnormality ] ) .",
    "we can write @xmath530 the second term is normal by construction .",
    "the first term has variance @xmath531 . with some effort",
    "it can be seen that @xmath532 therefore , by a slight adaptation of the lindeberg ",
    "feller theorem ( to infinite sums ) , we have that @xmath533 divided by its standard deviation tends in distribution to the standard normal distribution .",
    "furthermore , the preceding display shows that this conclusion does not change if the @xmath521th term is left out from the infinite sum .",
    "thus , the two terms converge jointly to asymptotically independent standard normal variables , if scaled separately by their standard deviations .",
    "then their scaled sum is also asymptotically standard normally distributed .      under ( [ eqproblem ] )",
    "the variable @xmath137 is @xmath534-distributed , for @xmath358 given in ( [ linvar ] ) .",
    "it follows that the coverage can be written , with @xmath83 a standard normal variable , @xmath535 the bias @xmath536 and posterior spread @xmath163 are expressed as a series in  ( [ linbias ] ) and ( [ linpostspr ] ) .    in the proof of theorem [ lincontrppprv ] @xmath334 and @xmath335",
    "were seen to have the same order of magnitude , given by the second term in @xmath188 given in ( [ eqtaulrv ] ) , with a slowly varying term @xmath537 as given in the theorem , @xmath538 furthermore , @xmath539 for every @xmath10 , as every term in the infinite series ( [ linvar ] ) is @xmath540 times the corresponding term in ( [ linpostspr ] ) .    because @xmath83 is centered , the coverage ( [ eqcoveragelinw ] ) is largest if the bias @xmath536 is zero .",
    "it is then at least @xmath216 , because @xmath541 ; remains strictly smaller than @xmath542 , because @xmath543 ; and tends to exactly @xmath216 iff @xmath544 . by theorem  [ tbvm - reg](i )",
    "the latter is impossible if @xmath312 .",
    "the analysis for nonzero @xmath8 depends strongly on the size of the bias relative to @xmath335 .",
    "the supremum of the bias satisfies , for @xmath545 the slowly varying term given in theorem [ lincontrppprv ] , @xmath546 that the left - hand side of ( [ eqsupbiaslinear ] ) is smaller than the right - hand side was already shown in the proof of theorem [ lincontrppprv ] , with the help of lemma [ rvseries ] . that this upper bound is sharp follows by considering the sequence @xmath215 defined by , with @xmath547 the right - hand side of the preceding display , @xmath548 [ this is the sequence that gives equality in the application of the cauchy ",
    "schwarz inequality to derive ( [ eqsqbiaslinear ] ) . ] using lemma [ rvseries ] , it can be seen that @xmath523 and that the bias at @xmath215 is of the order @xmath547 .    by lemma [ lemmatechnicalbias ] ,",
    "the bias at a _ fixed _",
    "@xmath279 is of strictly smaller order than the supremum @xmath481 if @xmath549 .",
    "the maximal bias @xmath481 is a decreasing function of the scaling parameter  @xmath183 , while the standard deviation @xmath335 and root - spread @xmath334 increase with @xmath183 .",
    "the scaling rate @xmath307 in the statement of the theorem balances @xmath481 with @xmath550 .",
    "case ( i ) . if @xmath551 , then @xmath552 .",
    "hence , the bias @xmath536 in ( [ eqcoveragelinw ] ) is negligible relative to @xmath553 , uniformly in @xmath357 , and the coverage is asymptotic to @xmath554 , which is asymptotically strictly between @xmath216 and  @xmath542 .",
    "case ( iii ) .",
    "if @xmath555 , then @xmath556 . if @xmath557 is the bias at a  sequence @xmath215 that ( nearly ) attains the supremum in the definition of  @xmath481 , then the coverage at @xmath215 satisfies @xmath558 , as @xmath559 . by the same argument , the coverage also tends to zero for a fixed @xmath8 in @xmath16 with bias @xmath560 . for this",
    "we choose @xmath561 for a slowly varying function such that @xmath562 .",
    "the latter condition ensures that @xmath563 . by another application of lemma [ rvseries ] , the bias at @xmath8 is of the order [ cf .",
    "( [ linbias ] ) ] @xmath564 where , for @xmath300 , @xmath565 therefore , the bias at @xmath8 has the same form as the maximal bias @xmath481 ;",
    "the difference is in the slowly varying factor @xmath566 . if @xmath567 , then @xmath568 for some @xmath569 and , hence , @xmath570 .",
    "case ( ii ) .",
    "if @xmath316 , then @xmath571 . if @xmath557 is again the bias at a sequence @xmath215 that nearly assumes the supremum in the definition of @xmath481 , we have that @xmath572 attains an arbitrarily small value if @xmath573 is chosen sufficiently large .",
    "this is the coverage at the sequence  @xmath574 , which is bounded in @xmath16 . on the other hand ,",
    "the bias at a fixed @xmath279 is of strictly smaller order than the supremum  @xmath481 , and , hence , the coverage at a fixed @xmath8 is as in case ( i ) .",
    "if the scaling rate is fixed to @xmath232 , then it can be checked from ( [ eqsntnlin ] ) and  ( [ eqsupbiaslinear ] ) that @xmath552 , @xmath571 and @xmath556 in the three cases @xmath327 , @xmath281 and @xmath328 , respectively . in the first and third cases the maximal bias and the spread",
    "differ by more than a polynomial term @xmath494 ; in the second case it must be noted that the slowly varying terms @xmath545 and @xmath537 are equal [ to @xmath575 .",
    "it follows that the preceding analysis ( i ) , ( ii ) , ( iii ) extends to this situation .",
    "the two quantities @xmath334 and @xmath335 are given as series in ( [ linpostspr ] ) and ( [ linvar ] ) .",
    "every term in the series ( [ linvar ] ) is @xmath540 times the corresponding term in the series ( [ linpostspr ] ) .",
    "therefore , @xmath343 if and only if the series are determined by the terms for which these numbers are `` close to '' 1 , that is , @xmath576 is large .",
    "more precisely , we show below that @xmath343 if and only if , for every @xmath577 , @xmath578 if @xmath342 , then the series on the left is as in lemma [ normseries ] with @xmath350 , @xmath433 , @xmath436 , @xmath579 and @xmath435 .",
    "hence , @xmath580 , and the display follows from the final assertion of the lemma . if @xmath581 for a slowly varying function @xmath297 , then the series is as in lemma [ rvseries ] , with the same parameters , and by the last statement of the lemma the display is true",
    "if and only if @xmath580 , that is , @xmath270 .    to prove that ( [ hulp1 ] ) holds iff @xmath343 , write @xmath582 , for @xmath583 and @xmath481 the sums over the terms in ( [ linpostspr ] ) with @xmath584 and @xmath585 , respectively , and , similarly , @xmath586",
    ". then @xmath587 it follows that @xmath588 because @xmath589 is strictly decreasing from 1 at @xmath590 to @xmath591 at @xmath592 ( if @xmath593 ) , the right - hand side of the equation is asymptotically  1 if and only if @xmath594 , and otherwise its liminf is strictly smaller .",
    "thus , @xmath595 implies that @xmath594 .",
    "second , @xmath596 it follows that @xmath597 if @xmath594 .",
    "this being true for every @xmath598 implies that @xmath595 .",
    "\\(i ) second assertion .",
    "if @xmath342 , then we apply lemma [ normseries ] with @xmath350 , @xmath435 , @xmath433 , @xmath436 and @xmath579 to see that @xmath599 .",
    "furthermore , the second assertion of the lemma with @xmath600 shows that @xmath601 in the case that @xmath602 .",
    "the proof can be extended to cover the slightly more general sequence @xmath191 in assumption  [ ppp ] .    if @xmath339 , then we apply lemma [ rvseries ] with @xmath350 , @xmath435 , @xmath433 , @xmath436 and @xmath579 to see that @xmath603 .",
    "\\(ii ) if @xmath346 , then the bias is bounded above in ( [ eqsqbiaslinear ] ) , and in the proof of theorem [ lincontrppp ] its supremum @xmath481 over @xmath357 is seen to be bounded by @xmath604 , the first term in the definition of @xmath188 in the statement of this theorem .",
    "this upper bound is @xmath605 iff the stated conditions hold .",
    "[ here we use that @xmath606 as @xmath607 , as noted in the proof of lemma  [ rvseries ] . ]",
    "the supremum of the bias @xmath481 in the case that @xmath339 is given in ( [ eqsupbiaslinear ] ) .",
    "it was already seen to be @xmath608 if @xmath609 in the proof of case ( i ) of theorem  [ lincrs ] .",
    "if @xmath610 , we have that @xmath611 , for @xmath545 the slowly varying factor given in the statement of theorem [ lincontrppprv ] .",
    "furthermore , we have @xmath612 , for @xmath537 the slowly varying factor in the same statement . under the present conditions , if @xmath337 and @xmath613 if @xmath350 .",
    "we can now verify that @xmath347 if and only if the conditions as stated hold .",
    "\\(iii ) the total variation distance between two gaussian distributions with the same expectation and standard deviations @xmath334 and @xmath335 tends to zero if and only if @xmath343 .",
    "similarly , the total distance between two gaussians with the same standard deviation @xmath334 and means @xmath614 and @xmath615 tends to zero if and only if @xmath616 .",
    "therefore , it suffices to show that @xmath617 if @xmath342 .",
    "because the bias was already seen to be @xmath608 and @xmath618 if @xmath342 , it suffices to show that @xmath619 . under assumption [ ppp ]",
    "this difference is equal to @xmath620 if @xmath621 , then the variance of this expression is seen to tend to zero by dominated convergence .",
    "the final assertion of the theorem follows along the lines of the proof of theorem [ lincrs ] .",
    "[ normseries ] for any @xmath622 , @xmath623 , @xmath624 and @xmath625 , as @xmath626 , @xmath627 moreover , for every fixed @xmath628 , as @xmath626 , @xmath629 the last assertion remains true if the sum is limited to the terms @xmath630 , for any @xmath598 .",
    "in the range @xmath631 we have @xmath632 , while @xmath633 in the range @xmath634 .",
    "thus , deleting either the first or second term , we obtain @xmath635 the inequality in the first line follows by bounding @xmath520 in @xmath636 by @xmath637 if @xmath638 , and by 1 otherwise .",
    "this proves the upper bound for the supremum .",
    "the lower bound follows by considering the two sequences @xmath639 given by @xmath640 for @xmath641 and @xmath642 otherwise ( showing that the supremum is bigger than @xmath643 ) , and given by @xmath644 and @xmath642 otherwise ( showing that the supremum is bigger than @xmath645 ) .",
    "the second line of the preceding display shows that the sum over the terms @xmath634 is @xmath646 .",
    "furthermore , the first line can be multiplied by @xmath647 to obtain @xmath648 if @xmath649 , then @xmath638 and this tends to zero by dominated convergence . also , @xmath650 if @xmath580 , then @xmath651 and , hence , @xmath652 , and the right - hand side tends to @xmath653 by dominated convergence .",
    "the final assertion needs to be proved only in the case that @xmath580 , as in the other case the whole sum tends to 0 .",
    "the sum over the terms @xmath634 was seen to be always @xmath646 , which is @xmath654 if @xmath580 .",
    "the final assertion for @xmath655 follows , because the sum over the terms @xmath631 was seen to have the exact order @xmath645 ( if @xmath656 ) . for general @xmath226",
    "the proof is analogous , or follows by scaling @xmath657 .",
    "[ rvseries ] for any @xmath658 , @xmath659 , and @xmath639 such that @xmath660 for @xmath661 and a slowly varying function @xmath662 , as @xmath663 , @xmath664 moreover , for every @xmath598 , the sum on the left is asymptotically equivalent to the same sum restricted to the terms @xmath665 if and only if @xmath580 .    as in the proof of the preceding lemma , we split the infinite series in the sum over the terms @xmath631 and @xmath634 . for the first part of the series @xmath666 if @xmath638 [ i.e. , @xmath649 ] , the right - hand side is of the order @xmath668 , by theorem 1(b ) on page 281 in @xcite , while if @xmath669 , it is of the order @xmath645 by lemma on page 280 in @xcite . finally , if @xmath670 , then the right - hand side is identical to @xmath671 .",
    "the other part of the infinite series satisfies , by theorem 1(a ) on page  281 in @xcite , @xmath672 this is never bigger than the contribution of the first part of the sum , and of equal order if @xmath673 . if @xmath674 , then the leading polynomial term is strictly smaller than @xmath645 .",
    "if @xmath675 , then the leading term is equal to @xmath645 , but the slowly varying part satisfies @xmath676 , by theorem 1(b ) on page 281 in @xcite .",
    "therefore , in both cases the preceding display is negligible relative to the first part of the sum .",
    "this proves the final assertion of the lemma for @xmath655 .",
    "the proof for general @xmath598 is analogous .    by the cauchy ",
    "schwarz inequality , for any @xmath677 , @xmath678 the preceding lemma gives the exact order of the right - hand side .",
    "the application of the cauchy ",
    "schwarz inequality is sharp , in that there is equality for some .",
    "however , this @xmath92 depends on @xmath657 . for fixed @xmath679",
    "the left - hand side is strictly smaller than the right - hand side .",
    "we split the series in two parts , and bound the denominator @xmath684 by @xmath685 or @xmath542 . by the cauchy ",
    "schwarz inequality , for any @xmath686 , @xmath687 the terms in the remaining series in the right - hand side of the first inequality are bounded by @xmath688 and tend to zero pointwise as @xmath607 if @xmath689 .",
    "if @xmath690 , then there exists @xmath686 such that the latter is true , and for this @xmath208 the sum tends to zero by the dominated convergence theorem .",
    "the other terms collect to @xmath691 .",
    "the sum in the right - hand side of the second inequality is bounded by @xmath692 ."
  ],
  "abstract_text": [
    "<S> the posterior distribution in a nonparametric inverse problem is shown to contract to the true parameter at a rate that depends on the smoothness of the parameter , and the smoothness and scale of the prior . </S>",
    "<S> correct combinations of these characteristics lead to the minimax rate . </S>",
    "<S> the frequentist coverage of credible sets is shown to depend on the combination of prior and true parameter , with smoother priors leading to zero coverage and rougher priors to conservative coverage . in the latter case </S>",
    "<S> credible sets are of the correct order of magnitude . </S>",
    "<S> the results are numerically illustrated by the problem of recovering a function from observation of a noisy version of its primitive .    ,    .    . </S>"
  ]
}