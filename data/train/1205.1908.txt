{
  "article_text": [
    "the etherington reciprocity theorem @xcite states that , if source and observer are in relative motion , solid angles subtended between the observer and the source are related by geometrical invariants where the redshift of the source as measured by the observer enters in the relation . first proven in the context of relativistic geometrical optics , it only relies on the two assumptions that light travels along null geodesics in a riemannian spacetime and that the number of photons is conserved @xcite .",
    "altough often underrated , the etherington reciprocity theorem actually plays a fundamental role in observational cosmology with applications ranging from gravitational lensing @xcite , to the cmbr temperature shift equation @xmath8 @xcite and the well known result that the surface brightness of a source does not depend on its distance to the observer . among its different incarnation ,",
    "a widely used formulation of the etherington reciprocity theorem is represented by the so called _ distance duality relation _",
    "( hereafter , ddr @xcite ) reading :    @xmath9    where @xmath1 and @xmath2 are the luminosity ( ld ) and angular diameter distance ( add ) . having been derived from the reciprocity law , the ddr holds in whatever cosmology provided the spacetime is riemannian and there are no source of attenuation ( like gray dust ) or brightening ( as gravitational lensing ) . as such , one can take it for granted , but a more interesting possibility is to test it against astronomical observations . to this end , one should be able to measure , for a given @xmath3 , both the ld and add by means of a standard candle and a standard ruler , respectively . from this point of view , type ia supernovae ( although standardizable rather than standard candles ) are the ideal tool to estimate the ld as is indeed routinely done when using their hubble diagram to constrain cosmological parameters . on the contrary",
    ", adds are much more difficult to measure , but some significant steps forward have been recently based on the sunyaev - zeldovich effect in galaxy clusters @xcite . unfortunately , while the method to estimate add from the measured temperature decrement is theoretically and observationally well understood , the impact of systematics related to the cluster geometry and the plasma physics is still quite strong leading to contrasting conclusions on the ddr validity at any redshift @xcite .    as a further issue , one has also to take care of the errors due to the mismatch between the cluster redshift and the closest sn in the companion sneia sample adopted .",
    "different strategies have been implemented to avoid this problem ( e.g. , by rejecting the clusters for which no sn at the same @xmath3 is available ) or reduce its impact relying on the ld value inferred from sneia with @xmath10 and @xmath11 . as a possible way out of this issue ,",
    "we present here a novel method relying on the _ local regression _",
    "technique @xcite to get a reliable ld estimate at exactly the same redshift as the cluster one .",
    "an alternative standard ruler is represented by the sound horizon @xmath12 , i.e. the comoving distance a sound wave could have traveled in a photon - baryon fluid by the time of decoupling .",
    "the importance of such a scale may be guessed noting that , at the time of recombination , baryons wave stop to freely propagate in the initial baryons - photons plasma thus leaving a density excess at the sound horizon scale . should galaxy form at the centre of density perturbations",
    ", we should have observed a peak in the galaxy correlation function at this scale .",
    "since the fourier transform of such a peak would appear as an oscillating feature , the matter power spectrum should present oscillations at the corresponding wavenumber .",
    "such oscillations have been indeed detected @xcite and are now referred to as _ baryon acoustic oscillations _ ( bao , see @xcite for a nice review ) .",
    "should one be able to measure the power spectrum as function of both the parallel and transverse wave number at different redshift @xmath3 , bao would allow to determine the values of @xmath13 and @xmath14 , where @xmath15 is the hubble expansion rate .",
    "although bao data actually determine adds only up to the unknown sound horizon @xmath12 , it is worth noting that this latter quantity is well constrained by present day cmbr data with a precision which will likely increase as the planck mission data @xcite will become available .",
    "moreover , the inferred adds from bao and the cmbr determination of @xmath12 will be free of the unknown systematics related to the cluster geometry and physics",
    ". we will therefore investigate here whether future bao and sneia surveys can be combined together to strengthen the constrains on @xmath4 and detect any ddr violation .",
    "the plan of the paper is as follows .",
    "the local regression technique is presented in section ii and then used to infer the @xmath4 values from the present day sneia and cluster data .",
    "section iii investigates the constraints these data put on two different parameterizations of @xmath4 highlighting to what extent they depend on the cluster geometry assumptions .",
    "the use of bao as alternative standard rulers is presented in section iv , where we also investigate the constraints this method can impose on @xmath4 relying on future sneia and bao data which will be collected by the euclid satellite .",
    "we then summarize and conclude in section v.",
    "since the ddr involves the ratio between the values of the ld scaled by @xmath16 and the add at the same redshift @xmath3 , the first issue one has to tackle off is the difficulty to exactly match the measurements of these two quantities . as an example , let us consider the add catalog assembled by bonamente et al .",
    "( hereafter , b06 ) @xcite from 38 galaxy clusters spanning the redshift range @xmath17 . to trace the ld",
    ", we will use the most updated sneia sample , namely the union2 @xcite , with 557 sneia over the range @xmath18 .",
    "should we decide to only use the ld and add measurements with exactly the same @xmath3 in the two catalogs , we would have obtained a sample of only 13 objects with large error bars so that the results on testing the ddr would likely be quite poor .    in an attempt to strengthen the constraints , one",
    "therefore adopt an approximate matching by selecting only those clusters which have at least one sn with @xmath19 . for @xmath20 ( @xmath21 ) ,",
    "one finds 32 ( 38 ) objects and then estimate the ld at @xmath22 from the sample of ld measurements approximately matched for each @xmath22 .",
    "two strategies are possible to this end .",
    "first , one can simply take a weighted mean ( with the inverse squared error as weights ) or linearly interpolate the data .",
    "as we will show later , the choice of the ld estimate method and the value of @xmath23 have a non negligible impact on the constraints on the ddr parameters . in order to reduce this bias",
    ", one should make @xmath23 as small as possible , but this comes at the price of weakening the constraints so that finding the right compromise is an hard issue .    as a possible way out of this problem ,",
    "we resort here to the _ local regression _ ( lr ) technique @xcite to infer the distance modulus @xmath24 at the cluster redshift @xmath22 from the companion sneia sample . the basic idea underlying lr relies on fitting simple models to localized subsets of the data to build up a function that describes the deterministic part of the variation in the data , point by point",
    "actually , one is not required to specify a global function of any form to fit a model to the data so that there is no ambiguity in the choice of the interpolating function .",
    "indeed , at each point , a low degree polynomial is fit to a subset of the data containing only those points which are nearest to the one whose response is being estimated .",
    "the polynomial is fit using weighted least squares with a weight function which quickly decreases with the distance from the point where the model has to be recovered .",
    "we use the union2 sneia sample as input to the local regression estimate of @xmath25 following the steps schematically sketched below .    1 .",
    "order the sneia according to increasing value of @xmath26 and select the first @xmath27 with @xmath28 a user selected value and @xmath29 the total number of sneia .",
    "define the weight function : + @xmath30 + where @xmath31 and @xmath32 the maximum value of the @xmath26 over the subset chosen before .",
    "fit a first order polynomial to the data selected at step ( ii ) weighting each sneia with the corresponding value of the function @xmath33 and take the zeroth order term as best estimate of @xmath25 .",
    "+ 4 .   estimate the error on @xmath25 as the root mean square of the weighted residuals with respect to the best fit zeroth order term .",
    "+    it is worth stressing that both the choice of the weight function and the order of the fitting polynomial are somewhat arbitrary .",
    "similarly , the value of @xmath28 to be used must not be too small in order to make up a statistical valuable sample , but also not too large to prevent the use of a low order polynomial . in @xcite ( which we refer the reader to for any detail ) , an extensive set of simulations",
    "were performed to both check the reliability of the lr method and look for a possible value of @xmath28 .",
    "it was there shown that setting @xmath34 allows to recover the input distance modulus typically within @xmath35 ( and with deviations never larger than @xmath36 ) independent on the redshift @xmath3 and the cosmological model adopted ( at least within the large class of dark energy equation of states considered ) .",
    "we will therefore adopt the above procedure to estimate the distance modulus and then the ld , @xmath37 $ ] ( with @xmath38 ) for all the clusters in the add catalogs we will use later .",
    "testing the validity of the ddr is the same as checking that the parameter @xmath4 defined in eq.([eq : ddr ] ) is strictly constant and unity at all @xmath3 . to this end , it is convenient to phenomenologically parameterize this quantity so that deviations from the validity of the ddr can be expressed in a quantitative way .",
    "inspired by the analogy with the dark energy equation of state , two common expressions adopted in literature read @xcite :    @xmath39    so that the ddr is never violated if @xmath40 .",
    "it is worth noting that , while the first formula predicts that @xmath4 asymptotically approaches the constant value @xmath41 at high @xmath3 ( so that one can formally have a violation of ddr at low redshift but recover it for @xmath42 if @xmath43 , the second expression formally diverges at infinity so that it must be considered as a low @xmath3 approximation only .",
    "we nevertheless include it both to compare our results with previous ones and to allow for a quickly varying @xmath4 ( noting that , for the same @xmath44 , the logarithmic ansatz increases faster than the first expression ) .    as a second remark ,",
    "it is worth spending some words on the value of @xmath7 .",
    "if one assumes that the robertson - walker metric holds ( i.e. , the universe is homogenous and isotropic on large scales ) , one gets @xmath45 and hence @xmath46 independent on whether the ddr holds or not .",
    "however , such a result breaks down if photons are absorbed or emitted along their light path or , put in other words , the effective opacity @xcite of the universe is not zero .",
    "in such a case , one can still have a homogenous and isotropic universe and nevertheless a value of @xmath47 so that we will explore both one parameter models forcing @xmath46 and two parameters cases constraining its value from the fit to the data .",
    "the two expressions in eq.([eq : etapar ] ) provide a purely phenomenological approach to testing the ddr . as a different method",
    ", it is also possible to assume a model for the absorption and/or production of photons due to interactions with , e.g. , axion - like particles or a work out a different mechanism leading to a non vanishing and redshift dependent effective opacity ( see , e.g. , @xcite and refs .",
    "therein for some interesting examples ) .",
    "the price to pay is , however , to introduce a dependence of the fitting results on both the underlying cosmological model and the opacity production phenomenon parameters .",
    "since the number and quality of the present day data is far from being good enough , we have here preferred to adopt a model independent approach relying on the above two phenomenological expressions .    as input dataset ,",
    "we follow the common approach using the union2 sneia sample as ld tracer and two different galaxy cluster samples with x - ray and sz data to measure the adds .",
    "the first one is the catalog of 25 clusters assembled by de filippis et al .",
    "( @xcite , hereafter def05 ) , while the second one is made out 38 clusters and will be referred to here as the b06 @xcite sample .",
    "it is worth stressing that , although the data and the method used to determine the add of each cluster are the same , the two samples differ for a critical assumption . indeed , while b06 assumes a spherical geometry , def05 explicitly correct their estimates taking care of their constraints on the ellipsoidal cluster geometry . as amply discussed in literature @xcite , the assumption of a spherical or ellipsoidal geometry has a great impact on the add determination so that the estimated @xmath48 values are not consistent with each other . as a consequence , the constraints on @xmath49 will also depend on which sample is used and can not be straightforwardly compared .    in order to constrain the parameters , we resort to the usual @xmath50 analysis , i.e. , we minimize the merit function :    @xmath51 ^ 2 } \\label{eq : defchi}\\ ] ]    with @xmath52 and @xmath53 the observed and theoretically predicted @xmath4 value at redshift @xmath54 , @xmath55 the measurement uncertainty and @xmath56 or @xmath57 for the one and two parameters models , respectively .",
    "eq.([eq : defchi ] ) contains an additional term @xmath58 which we have introduced to take into account a systematic uncertainty on the ld as inferred from the sn distance modulus .",
    "indeed , since the absolute sn magnitude is known up to @xmath59 , the ld can be shifted by a factor @xmath60 .",
    "we therefore add this as a nuisance parameter and marginalize over it with a gaussian prior centred on @xmath61 and with standard deviation @xmath62 . as a far as we know , this is the first time such a term is taken into account , while neglecting it can artificially reduce the uncertainties on the inferred constraints on the model parameters @xmath63",
    ".    the best fit parameters will be obtained by minimizing the @xmath50 merit function , while the @xmath64 ( @xmath65 ) confidence limits will be found by imposing @xmath66 @xmath67 . to this end",
    ", we first integrate the likelihood @xmath68 } \\exp{-[\\delta_0 ^ 2/(2 \\sigma_0 ^ 2)]}$ ] over all the parameters but the one of interest .",
    "we then define @xmath69 ( with @xmath70 the marginalized likelihood for the i - th parameter ) and find the @xmath64 and @xmath65 cl solving the above relations for @xmath71 .      before discussing the results on @xmath49 from fitting the above dataset",
    ", it is worth spending some time to explicitly show the impact of redshift mismatch and why we advice the reader to avoid it using the local regression technique ( or a whatever reliable method to estimate the ld at the same cluster redshift ) .    to this aim ,",
    "we build up simulated cluster and sneia samples as close as possible to the actual ones .",
    "first , we choose a fiducial cosmological model assuming a spatially flat universe with matter density parameter @xmath72 , constant dark energy equation of state , @xmath73 and hubble constant ( in units of @xmath74 ) @xmath75 , consistent with the recent wmap7 @xcite results .",
    "we then choose the b06 sample as a reference case and assign to each cluster in this sample an add equals to @xmath76 with @xmath2 the theoretical value and @xmath77 randomly chosen between @xmath78 to mimic a possible mismatch due to statistical and/or systematic errors .",
    "to each value , we then attach a measurement uncertainty in such a way that the relative error equals the one for the add of the cluster in the b06 sample having the same @xmath3 .",
    "for the simulated sneia sample , we adopt a similar procedure the only difference being that we generate the distance modulus ( rather than the ld ) from a gaussian distribution centred on the theoretical value and with variance @xmath79 , but never smaller than @xmath80 , this value being the intrinsic scatter of the sneia peak magnitude .",
    "the same scaling of the errors is then used to assign a statistical uncertainty to the simulated @xmath25 for each sn in the sample .",
    "the simulated cluster and sneia datasets are then used to estimate @xmath4 at the cluster redshifts using two different ways to deal with the problem of redshift mismatch .",
    "first , we take as ld at each @xmath22 the error weighted average of the sneia with @xmath10 thus obtaining model in eq.([eq : etapar ] ) , but our conclusions on the impact of redshift mismatch are qualitatively the same for the other parametrization .",
    "moreover , we report the values obtained by a single simulation , but we have checked that they are qualitatively the same running @xmath81 realizations of the ld and add datasets . ] :    @xmath82    when forcing @xmath46 , and    @xmath83    for the two parameters case with the reported errors referring to the @xmath64 confidence range confidence range may be taken as a @xmath84 error and @xmath65 cl obtained by doubling the @xmath84 uncertainty .",
    "hereafter , we will therefore report only this estimate of the @xmath84 error . ] .",
    "such a test shows that , although the value @xmath85 is well within the @xmath64 confidence ranges , the best fit value may be severely biased if one does not force @xmath46 .",
    "since it is reasonable to expect that the error bars will shrink with future data , we can argue that averaging over the sneia with @xmath10 can introduce a systematic bias which is larger than the statistical uncertainty .    [",
    "cols=\"^,^,^,^,^\",options=\"header \" , ]     actually , averaging is only zero order approximation so that one can suppose that a linear interpolation of the @xmath1 values within this range works much better .",
    "using this approach , we find :    @xmath86    for the one parameter model , and    @xmath87    when @xmath7 is left free .",
    "it is evident that the bias on @xmath44 is still present for the two parameters model .",
    "somewhat surprisingly , the linear interpolation method has worsened rather than ameliorated the situation . actually , this is partly a consequence of the smaller number of clusters used which makes the fit more sensible to deviations from the ddr ansatz because of statistical fluctuations .",
    "note that the dataset only contains now 28 clusters since , for ten of them , we have too few points ( less than four objects ) in the @xmath10 sneia subset to define a reliable interpolation .",
    "finally , let us consider the results obtained using local regression to estimate @xmath25 and then @xmath1 for each cluster in the simulated sample .",
    "fitting the one parameter model , we get :    @xmath88    while , when @xmath7 is fitted too , we find :    @xmath89    compared to the averaging method , we clearly see that the bias on @xmath44 is reduced both for one and two parameter models and , as a further positive outcome , we also get a median @xmath7 value quite close to the input one .",
    "we can therefore safely conclude that the local regression technique does not bias the constraints on @xmath49 and confidently advocate its use to test the ddr avoiding any systematic error due to the redshift mismatch problem .      motivated by the above discussion",
    ", we now use the local regression technique to infer the ld of the clusters in the b06 and def05 samples using the sneia union2 sample as input .",
    "we then fit the data thus obtained with the four models introduced in section ii and summarize the results in table i. not surprisingly , the confidence ranges are quite large so that it is not statistically possible to definitively conclude whether the ddr holds or not at any @xmath3 .",
    "it is worth noting that a qualitatively similar conclusion is also achieved in previous works .",
    "indeed , the constraints in table i are fully consistent with those in @xcite , although we remark that a straightforward comparison should be avoided given the radically different approach to the redshift mismatch problem .",
    "moreover , we have also included the term @xmath58 in eq.([eq : defchi ] ) which has the double impact of introducing a degeneracy in the parameters space and enlarging the confidence ranges .",
    "it is worth investigating how the constraints depend on the assumed @xmath4 parameterization . comparing the constraints on @xmath44 for both the one and two parameters models in the upper and lower half of table i",
    ", we see that the logarithmic ansatz may be reconciled with the data only if smaller @xmath44 values are used .",
    "this is an expected result considering that , for the same @xmath7 value ( as , e.g. , for the one parameter case ) , a smaller @xmath44 partially compensates for the different scalings with @xmath3 of the two cases considered .",
    "although somewhat expected , this result highlights the importance of choosing a reliable parameterization for @xmath4 in order to better check the ddr validity at any @xmath3 . on the contrary ,",
    "what is the functional expression for @xmath4 has only a minor impact on the @xmath7 constraints .",
    "indeed , for a fixed sample , the @xmath64 confidence ranges are well overlapped for the two @xmath4 expressions so that one could draw conclusions on @xmath7 in a roughly model independent way .",
    "table i shows that , actually , the larger impact on the constraints is due to the sample used , that is to say on the assumptions on the cluster geometry .",
    "indeed , both for models with @xmath46 or left free to fit , the b06 sample give values of @xmath44 closer to zero than the def05 one .",
    "moreover , when @xmath7 is free to vary , the b06 sample recovers @xmath46 within @xmath90 , while a significantly smaller value , @xmath91 , is obtained with the def05 sample leading to @xmath92 at more than @xmath93 .",
    "since the sneia companion sample used is the same , it is likely that the difference has to be ascribed to how the add has been estimated from the cluster data . in particular , since @xmath92 has been obtained , one should argue that the ld has been underestimated or the add is overestimated . investigating in details",
    "this issue is outside our aims .",
    "we only stress that the uncertainty on the cluster geometry is likely to not be reduced with improved observations being related to projection effects . as a consequence ,",
    "this source of systematic error is hard to be fully taken under control also with future data .",
    "in order to escape the uncertainties on the cluster geometry , one must rely on a different tracer to estimate the add at a given redshift @xmath3 .",
    "baryon acoustic oscillations immediately stand out as ideal candidates to this aim .",
    "indeed , the precise determination of the galaxy power spectrum as function of both the radial and tangential component of the wave vector allows to constrain @xmath94 and @xmath95 , @xmath12 being the sound horizon , and @xmath96 the median redshift of the survey .",
    "assuming that such a measurement is available , one can then rewrite the ddr in terms of the scaled add @xmath97 as :    @xmath98    this can be conveniently rewritten as    @xmath99    so that the rhs only contains observable quantities , while the lhs is a function of the sound horizon distance @xmath12 ( which is a constant ) and the parameters entering the adopted @xmath4 phenomenological expression .",
    "let us now suppose that a galaxy survey has the possibility to determine the power spectrum in @xmath100 bins with sufficient accuracy to provide @xmath100 measured values of the scaled add @xmath101 with @xmath3 a characteristic redshift of the bin ( e.g. , the central or the median value ) .",
    "we can then resort to local regression on sneia to estimate the ld at the sampled @xmath3 and then get a catalog of @xmath102 measurements . this sample",
    "could then be fitted to an assumed @xmath4 model , but this only gives constraints on @xmath103 and @xmath104 .",
    "however , the sound horizon distance @xmath12 is well constrained by cmbr data in a ( almost ) model independent way and with an error which can be as small as @xmath105 according to what is forecasted for planck .",
    "we can therefore assume that @xmath12 is known and directly use the add as @xmath106 so that the same fitting analysis used with cluster data can be implemented for adds traced by the bao .",
    "the combination of baos to infer adds and local regression to estimate ld at the same add redshift allows us to get a set of measured values for @xmath4 which is free from the two most problematic systematic errors that can mimic a deviation of the ddr even if such a violation of the etherington reciprocity theorem should not be present at all .",
    "unfortunately , while the available sneia samples are numerous enough to allow a decent reconstruction of @xmath25 through the local regression method , present day baos measurements only allow to constrain @xmath107 , with @xmath108^{1/3}$ ] the so called volume distance @xcite .",
    "we have therefore to rely on future data to apply the test outlined above .",
    "note that waiting for future data is a valid help also for improving ld estimates from sneia .",
    "indeed , next to come sneia surveys will both increase the statistics and offer a better control of the systematics so that we can reduce the errors on the reconstructed ld thanks to both a larger subsample for each @xmath3 and outliers rejection .      in order to investigate the potential of combined bao+sneia to constrain the ddr , we rely here on simulated data assuming an euclid - like survey .",
    "euclid @xcite is a candidate esa mission to map the geometry and the evolution of the dark universe to an unprecedented precision setting high accuracy constraints on dark matter , dark energy and modified gravity . to this end",
    ", two independent cosmological probes will be used , namely weak gravitational lensing and bao , measuring the shape and the spectra of galaxies over @xmath109 of extragalactic sky in both visible ( down to @xmath110 ab mag in the visible wide r+i+z filter ) and nir ( up to 24 mag in y , j , h filters ) , up to redshift @xmath111 . a deep survey ( two magnitudes deeper than the wide ) over a @xmath112 area will also be conducted for legacy science and could offer the possibility to detect @xmath113 sneia . the possibility to both measure bao and",
    "build up a sneia catalog makes euclid an ideal tool to provide all the ingredients we need to check the validity of the ddr so that we use this mission as test case for our proposed method assuming the fiducial cosmological model described in section ii .",
    "let us briefly describe how we simulate the sneia sample . as a first step , we choose template light curves for each sn type ( not only sneia , but also iip , iil , iin and ibc ) as well as sn rates as function of redshift . starting from the results of the loss @xcite survey for the magnitude peak and the gaussian sn mag distribution , montecarlo simulations are then performed generating artificial sne ( with expected total counts computed from the above template ) and random redshifts and explosion epochs .",
    "depending on the survey strategy , one can then compute the total number of sne of each type which are detected at least one time and then impose some cuts on the number of epoch each sn is detected .",
    "such cuts then allow to finally get the number of sneia which could be used for cosmology ( i.e. , that have a sufficiently well sampled lightcurve to determine their distance modulus ) and their redshift distribution . to this end , we assume an observational strategy consisting in a first two months phase spent monitoring a @xmath114 field to a depth of @xmath115 at a 4 days cadence .",
    "this is immediately followed by a period with a 10 days cadence for 15 epochs to a depth of @xmath116 .",
    "then this same setup is repeated over a second @xmath114 patch of the sky thus finally giving us a sample of @xmath117 sneia with @xmath118 and @xmath119 with a redshift distribution plotted in the left panel of fig.[fig : simplot ] .",
    "it is worth noting that the actual strategy that will be implemented by euclid has still to be decided .",
    "we nevertheless stress that the expected sneia number is the same as what we are getting here so that we can confidently rely on our simulated dataset as a first guess of an euclid - like catalog . to each sn in the sample , we estimate the error on the distance modulus as @xcite :    @xmath120    with @xmath121 the maximum redshift of the sample , @xmath122 an irreducible scatter and @xmath123 depending on the photometric accuracy .",
    "although these number have still to be computed for the euclid sn survey so that their uncertainties are likely smaller than our ones . as such , should their method turn out to be more reliable than our phenomenological formula , the results presented here would overestimate the impact of uncertainties thus leading to a conservative estimate of the final constraints on the ddr quantities . ] , we set here @xmath124 mimicking a typical space based survey . denoting with @xmath125 the predicted value from our fiducial cosmological model , we then assign to each sn , a distance modulus randomly generated from a gaussian distribution centred on @xmath125 and variance @xmath126 from eq.([eq : sigmamusn ] ) above . the measurement error is finally set to @xmath127 \\mu_{obs}(z)$ ] thus finally obtaining the simulated sneia dataset we need as input to the local regression technique .",
    "we now discuss the simulated add measurements from bao . to this end",
    ", we use the method developed and tested in @xcite to forecast the percentage error on @xmath14 from a bao survey as a function of both the fiducial cosmological model and the survey characteristics . to this end , it is worth first remembering that euclid will perform slitless spectroscopy for galaxies with an h@xmath28 flux down to @xmath128 so that its main target will be star forming galaxies .",
    "such an information is important to both estimate the redshift number distribution of detectable sources and the linear bias to be applied to match the matter and galaxy power spectra .",
    "following @xcite , we will assume a @xmath129 survey over the redshift range @xmath130 with @xmath131 obtained by multiplying the one in @xcite by a success rate @xmath132 for a conservative choice , while the linear bias varies with the redshift according to the model in @xcite .",
    "different from @xcite , we consider 16 equally spaced redshift bins with bin width @xmath133 in order to increase the number of @xmath2 measurements , but we stress that we can actually estimate @xmath4 only for the first 9 bins since the sneia sample does not extend to @xmath134 so that no ld determination is available for the higher redshift bins .",
    "two further ingredients are needed before using the @xcite code .",
    "first , one has to set the spectral index of scalar perturbations , denoted as @xmath135 , and the variance of density perturbations in a sphere of radius @xmath136 , usually referred to as @xmath137 . in agreement with the wmap/ results , we choose @xmath138 .",
    "finally , in order to avoid the problem of modeling nonlinear effects , we cut the power spectrum to a maximum wavenumber @xmath139 determined by solving @xmath140 , with @xmath141 the variance over the scale @xmath142 for the power spectrum at redshift @xmath3 .",
    "note that this leads to a redshift dependent upper limit on the usable power spectrum , although a conservative good approximation is to set @xmath143 independent on @xmath3 .",
    "the code then outputs @xmath144 , i.e. , the error on @xmath145 so that , if we assume that the error on @xmath12 is negligible , we simply get @xmath146 . as a simplifying ( but yet realistic assumption ) , we will associate this error to the add measurement at the centre of the redshift bin .",
    "we then generate @xmath2 from a gaussian distribution centred on the fiducial add and with variance equal to the one outputted from the code and finally scale the measurement error according to the ratio between the simulated and fiducial distance .",
    "the data thus generated are shown in the central panel of fig.[fig : simplot ] , while the right panel plots the inferred @xmath4 measurements using the local regression technique to estimate the ld for the bao adds measurements ( up to @xmath147 ) .      the above simulated dataset are input to the same fitting procedure analysis we have used for the present day data .",
    "we start by discussing the results for one representative realization of the sneia and bao data . for the one parameter models ( i.e. , with @xmath46 )",
    ", we get uncertainties .",
    "we have nevertheless preferred to give also the best fit @xmath49 in order to show that there is no bias induced by the simulations and the fitting method . ] :    @xmath148    for the first case in eq.([eq : etapar ] ) , and    @xmath149    for the second ansatz .",
    "a comparison with the results for the simulated case using local regression discussed at the end of section iiia shows that , although we now use a smaller dataset ( only 9 instead of 38 points ) , the errors on @xmath44 have been reduced by a factor two .",
    "such a large reduction is a consequence of two effects . on one hand",
    ", the increased size of the sneia sample ( by a factor ten ) allows to have more points in each of the local bins used to fit the low order polynomial used in the local regression method thus reducing the error on @xmath1 . on the other hand ,",
    "bao data allows to measure @xmath2 with an accuracy of order @xmath150 so that the final uncertainty on @xmath4 is quite small . as a result ,",
    "the lower statistics offered by this method is more than compensated by the far better precision thus shrinking the @xmath44 confidence ranges .",
    "when @xmath7 is left free , we find :    @xmath151    @xmath152    for the two models in eq.([eq : etapar ] ) . compared to the present day simulated data , we now find that the constraints on @xmath7 are actually poorer , while the opposite result is obtained , instead , for the @xmath44 parameters whose confidence ranges are smaller . while the first result is a consequence of the lower statistics which is no more compensated by the increased precision because of the presence of two parameters to fit , the improvement in the @xmath44 constraints is related to the larger redshift range probed by the bao data .",
    "it is , however , worth stressing that the statistical uncertainties on @xmath49 coming out from the fit are actually not the only source of error .",
    "as we have seen when fitting the present day data , systematic errors can also be larger than the statistical ones and bias the inferred best fit values . from this point of view , the bao method is free from this problem so that should be preferred over the clusters as an add tracer .    finally , we check whether the method used is able to recover the input parameters . to this end",
    ", we have run @xmath81 realizations of the sneia and bao future data and repeated the fit for each of them .",
    "for the one parameter models , averaging the median @xmath44 over the full set of simulations , we find :    @xmath153    for the linear and logarithmic @xmath4 ansatz , respectively , and where the error is the standard deviation of the ( approximately ) gaussian distribution of the results . leaving @xmath7 as a free parameter , we get :    @xmath154    for the linear model , and    @xmath155    for the logarithmic one .",
    "such results suggest that the median @xmath44 value outputted from the fit is on average consistent with the input one for both the linear and logarithmic model independent on the use of the @xmath46 assumption . on the contrary ,",
    "@xmath7 is less well recovered because of the degeneracy with the nuisance @xmath156 parameter .",
    "although this could add a note of caution in using the proposed method , it is nevertheless worth stressing that , for all the simulations , the statistical error on @xmath7 is roughly the same as the one reported above for the representative case . as a consequence ,",
    "the value @xmath46 is always well within the @xmath84 error so that we conclude that the bias is not statistically meaningful .",
    "it is common to say that we are living in the era of precision cosmology . while this is only partly true today",
    ", one can be confident that future data will us make enter an epoch where we can not only improve the precision on the constraints on a given cosmological model , but also test the cornerstones of observational cosmology .",
    "although its importance is usually underrated , the etherington reciprocity law stands out as one of the fundamental pillars our interpretation of astrophysical data is based on .",
    "next to come surveys will have the sufficient quality to promote the distance duality relation ( which is the most used incarnation of the etherington law ) from an _ a priori theoretical assumption _ to the rank of a _ relation which can be observationally validated_.    in order to test the validity of the ddr , one needs to trace both the luminosity and angular diameter distance for a set of redshift values .",
    "we have here followed the usual approach relying on clusters data to estimate the add and sneia as ld tracer .",
    "we have , however , improved the standard analysis by introducing the local regression technique to avoid the redshift mismatch problem ( i.e. , the difference between the redshift of the cluster and those of the sneia used to infer the corresponding ld ) .",
    "this simple and widely tested method allows to strongly reduce the bias on the @xmath4 parameters thus increasing the reliability of the constraints and hence the test of the ddr validity .",
    "unfortunately , the poor quality of the cluster adds determination still leads to large confidence ranges preventing to draw any statistically meaningful conclusion on the violation of the ddr over the redshift range probed by the available data .",
    "moreover , the results strongly depend on the assumptions on the cluster geometry so that one should first find a method to correct for this effect or propagate this uncertainty on the final error on the @xmath49 parameters introduced to quantitatively check the ddr validity .",
    "in an attempt to escape this problem , we have here proposed to use bao as an alternative add tracer .",
    "being the physics of bao well understood , the systematics connected with this method can be easily quantified and satisfactorily corrected for with future galaxy surveys data .",
    "since the present day data are too poor to implement this test in an efficient way , we have relied on simulated samples of both bao add measurements and sneia distance moduli determinations considering a fiducial euclid mission as source of both datasets .",
    "such an analysis has highlighted the virtues of the proposed approach showing that the error bars are halved if one forces @xmath46 .",
    "when this assumption is abandoned , we find only a modest decrease of the relative uncertainty on @xmath7 with respect to present day data , but the constraints on @xmath44 are still strengthened by a factor two .",
    "moreover , the lack of systematic errors makes this approach highly preferable over the use of cluster data as add tracers .",
    "it is worth noting that the proposed approach does not exploit the full potential of bao . indeed , while bao allows to determine the add up to redshift @xmath157 , the quantity @xmath4 can only be determined up to @xmath158 , this latter being the maximum redshift available tested by the sneia hubble diagram . in order to push further this limit",
    ", one could rely on a different sneia survey able to detect a statistically meaningful number of objects at @xmath159 with sufficient precision . as an alternative approach",
    ", one should find a different ld tracer .",
    "gamma ray bursts ( grbs ) stand out as ideal candidates from this point of view since they can be detected up to @xmath160 @xcite thanks to the huge energy released during the explosion .",
    "unfortunately , the use of grbs as standardizable candles is still in its infancy so that , notwithstanding the first released grbs hubble diagrams @xcite , a careful analysis of the systematics has still to be fully done ( but see , e.g. , @xcite for recent encouraging results ) .",
    "should future data validate the grbs as ld tracer , one could use them as input to the local regression technique and trace @xmath4 over the full redshift range probed by bao surveys .    as a final remark",
    ", it is worth noting that the proposed method will allow not only to check the foundations of observational cosmology by giving an empirical validation of the universally assumed etherington law , but also open the way to completely new physics should this test find out a statistically meaningful violation of the ddr .",
    "vfc and ss are funded by the italian space agency ( asi ) through contract euclid - ic ( i/031/10/0 ) .",
    "we thank e. cappellaro for help with developing the sneia simulation code and t. kitching and m. kunz for comments on an earlier version of the manuscript .                  f. de bernardis , e. giusarma , a. melchiorri , int . j. mod",
    "d , 15 , 759 , 2006 ; z. li , p. wu , h. yu , apj , 729 , l14 , 2011 ; r. nair , s. jhingan , d. jain , jcap , 05 , 023 , 2011 ; n.",
    "liang , s. cao , z.h .",
    "zhu , preprint arxiv:1104.2497 , 2011 ; x.l .",
    "meng , t.j .",
    "zhang , h. zhan , preprint arxiv:1104.2833 , 2011 ; s. cao , n. liang , preprint arxiv:1104.4942 , 2011    r.f.l .",
    "holanda , j.a.s .",
    "lima , m.b .",
    "ribeiro , apj , 722 , l233 , 2010 ; r.f.l .",
    "holanda , j.a.s .",
    "lima , m.b .",
    "ribeiro , a&a , 528 , l14 , 2011 ; s. cao , z.h .",
    "zhu , preprint arxiv:1102.2750 , 2011 ; r.f.l .",
    "holanda , j.a.s .",
    "lima , m.b .",
    "ribeiro , preprint arxiv:1104.3753 , 2011 ;                        w. li , et al . in _ cosmic explosions _ ,",
    "holt & w.w .",
    "zhang , ( new york , aip ) , 103 , 2000 ; a.v .",
    "filippenko , w. li , r.r .",
    "treffers , m. modjaz , in _ small - telescope astronomy on global scales _ , eds .",
    "chen , c. lemme & b. paczynski ( san francisco , asp ) , 121 , 2001 ; a.v .",
    "filippenko , in _ from twilight to highlight : the physics of supernovae _ ,",
    "w. hillebrandt & b. leibungudt ( berlin , springer - verlag ) , 171 , 2003"
  ],
  "abstract_text": [
    "<S> the assumptions that _ light propagates along null geodesics of the spacetime metric _ and _ the number of photons is conserved along the light path _ lead to the distance duality relation ( ddr ) , @xmath0 , with @xmath1 and @xmath2 the luminosity and angular diameter distances to a source at redshift @xmath3 . in order to test the ddr , we follow the usual strategy comparing the angular diameter distances of a set of clusters , inferred from x - ray and radio data , with the luminosity distance at the same cluster redshift using the local regression technique to estimate @xmath1 from type ia supernovae ( sneia ) hubble diagram . in order to both strengthen the constraints on the ddr and get rid of the systematics related to the unknown cluster geometry </S>",
    "<S> , we also investigate the possibility to use baryon acoustic oscillations ( bao ) to infer @xmath2 from future bao surveys . as a test case </S>",
    "<S> , we consider the proposed euclid mission investigating the precision can be afforded on @xmath4 from the expected sneia and bao data . </S>",
    "<S> we find that the combination of bao and the local regression coupled allows to reduce the errors on @xmath5 by a factor two if one @xmath6 is forced and future data are used . on the other hand , although the statistical error on @xmath7 is not significantly reduced , the constraints on this quantity will be nevertheless ameliorated thanks to the reduce impact of systematics . </S>"
  ]
}