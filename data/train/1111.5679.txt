{
  "article_text": [
    "fisher information ( fi ) is a measure of the minimum error in estimating an unknown parameter of a distribution , and its importance is related to the cramr - rao inequality for unbiased estimators @xcite . by introducing a location parameter , the de bruijn s identity indicates that the fundamental quantity of fi is affiliated with the differential entropy of the minimum descriptive complexity of a random variable @xcite .",
    "furthermore , in known weak signal detection , a locally optimum detector ( lod ) , as an alternative to the neyman - pearson detector , has favorable properties for small signal - to - noise ratios ( snrs ) @xcite .",
    "with sufficiently large observed data and using the central limit theorem , it is demonstrated that the lod is asymptotically optimum and its asymptotic efficiency is upper bounded by the fi of the distribution @xcite@xcite .",
    "however , the fundamental nature of fi is not adequately recognized for processing known weak signals . to extend the heuristic studies of @xcite@xcite , in this paper",
    ", we will theoretically demonstrate that , for a known weak signal buried in additive white noise , the performance of a locally optimum processor ( lop ) is completely determined by the fi of a standardized even probability density function ( pdf ) of noise .",
    "we show this for three signal processing case studies : ( i ) the maximum snr gain for a periodic signal ; ( ii ) the asymptotic relative efficiency ( are ) of a lod for signal detection ; ( iii ) the best cross - correlation gain ( cg ) for an aperidoic ( random ) signal transmission .",
    "moreover , for estimating an unknown parameter of a weak signal , the minimum mean square error of the unbiased estimator can be reduced to a straightforward form expressed by the fi of the distribution .",
    "the physical significance of fi , resulting from the reciprocal of fi delimiting the minimum mean square error of unbiased estimators , provides a upper bound of the performance for locally optimum processing .",
    "it is well known that a standardized gaussian pdf has minimum fi of unity @xcite . as a consequence , for any non - gaussian noise",
    ", it is always possible to achieve the performance ( snr gain , are or cg ) of a lop larger than unity for the three considered situations . in the sense of a realizable lop , an example of a gaussian mixture noise pdf",
    "is investigated @xcite .",
    "it is found that arbitrarily large fi can be achieved by the corresponding lop , and even when the noise is dichotomous noise associated with infinite fi .",
    "since the known weak signal might be periodic or aperiodic , three signal processing cases are illustrated for exploring the significance of fi in locally optimum processing .",
    "first , consider a static processor with its output @xmath0,\\ ] ] where the nonlinearity @xmath1 is odd @xcite and the input is a signal - plus - noise mixture @xmath2 .",
    "the component @xmath3 is a known weak periodic signal with a maximal amplitude @xmath4 ( @xmath5 ) and period @xmath6 .",
    "a zero - mean white noise @xmath7 , independent of @xmath3 , has an even ( symmetric ) pdf @xmath8 @xcite and the root - mean - square ( rms ) amplitude @xmath9 ( if it exists , or it is a scale parameter . ) .",
    "a family of even ( symmetric ) pdfs is frequently encountered in practical signal processing tasks @xcite . in the case of @xmath10",
    ", we have a taylor expansion around @xmath11 at a fixed time @xmath12 as @xmath13\\approx g(z)+s(t)g'(z),\\ ] ] where we assume the derivative @xmath14 exists for almost all @xmath15 ( similarly hereinafter ) @xcite .",
    "thus , we have @xmath16&\\approx & { \\rm e}[g(z)]+s(t){\\rm e}[g'(z)]=s(t){\\rm e}[g'(z ) ] , \\label{expectation}\\\\ { \\rm var}[y(t)]&= & { \\rm e } [ y^2(t)]-{\\rm e}[y(t)]^2 \\approx { \\rm e}[g^2(z)],\\label{variance}\\end{aligned}\\ ] ] where @xmath17=\\int_{-\\infty}^{\\infty}\\cdots f_z(z)dz$ ] . here , for an even pdf @xmath8 and the odd function @xmath1 , @xmath18=0 $ ] , @xmath19=0 $ ] @xcite . the higher order infinitesimal @xmath20-{\\rm e}^2[g'(z)]\\}$ ] is neglected @xcite , resulting in eq .",
    "( [ variance ] ) .",
    "the input snr at @xmath21 can be defined as the power contained in the spectral line @xmath22 divided by the power contained in the noise background in a small frequency bin @xmath23 around @xmath22 @xcite , this is @xmath24\\rangle|^2}{\\sigma_z^2 \\delta b \\delta t},\\ ] ] with @xmath25 indicating the time resolution or the sampling period in a discrete - time implementation and the temporal average defined as @xmath26 @xcite .",
    "since @xmath3 is periodic , @xmath27 is in general be a cyclostationary random signal with period @xmath6 @xcite .",
    "similarly , the output snr at @xmath27 is given by @xmath28\\exp[-i 2\\pi t / t]\\rangle|^2}{\\langle{\\rm var}[y(t)]\\rangle \\delta b \\delta t},\\ ] ] with nonstationary expectation @xmath29 $ ] and nonstationary variance @xmath30 $ ] @xcite .",
    "here , we assume the sampling time @xmath31 and observe the output @xmath27 for a sufficiently large time interval of @xmath32 ( @xmath33 ) @xcite . substituting eqs .",
    "( [ expectation ] ) and  ( [ variance ] ) into eq .",
    "( [ outsnr ] ) and noting eq .",
    "( [ insnr ] ) , we have @xmath34\\rangle|^2}{\\delta b \\delta t } \\frac{{\\rm e}^2[g'(z)]}{{\\rm e}[g^2(z)]}\\!=\\!r_{\\rm in }   \\;\\sigma_z^2 \\frac{{\\rm e}^2[g'(z)]}{{\\rm e}[g^2(z)]}.\\end{aligned}\\ ] ] thus , the output - input snr gain @xmath35 of eq .",
    "( [ system ] ) is @xmath36}{{\\rm e}[g^2(z ) ] } \\leq \\sigma_z^2 { \\rm e}\\left[\\frac{f'^2_z(z)}{f_z^2(z)}\\right]=\\sigma_z^2 i(f_z ) , \\end{aligned}\\ ] ] with the equality occurring as @xmath1 becomes a lop , viz .",
    "@xmath37 by the schwarz inequality for a constant @xmath38 and @xmath39 @xcite",
    ". it is noted that the lop @xmath40 of eq .",
    "( [ lop ] ) is odd and accords with the above assumption .",
    "more interestingly , the expectation @xmath41 $ ] in eq .",
    "( [ gain ] ) is just the fi @xmath42 of the even noise pdf @xmath8 @xcite .",
    "furthermore , for an even standardized pdf @xmath43 with zero mean and unity variance @xmath44 , the scaled noise @xmath45 has its pdf @xmath46 . since the fi satisfies @xmath47 @xcite , the output - input snr gain @xmath35 of eq .",
    "( [ gain ] is upper bounded by the fi @xmath48 of a standardized pdf @xmath49 , viz .",
    "@xmath50 with equality achieved when @xmath1 takes the lop @xmath40 of eq .",
    "( [ lop ] ) .",
    "secondly , we observe a data vector @xmath51 composed of @xmath52 observation components @xmath53 , which might be the white noise @xmath54 or the mixture of a signal @xmath55 plus white noise @xmath54 @xcite .",
    "consider a generalized correlated detector @xmath56 with a memoryless nonlinearity @xmath1 and the decision threshold @xmath57 for the hypotheses @xmath58 , otherwise the hypotheses @xmath59 @xcite .",
    "also , we assume that the odd function @xmath1 has zero mean under the even pdf @xmath8 , i.e.  @xmath60=0 $ ] , and there exists a finite bound @xmath4 such that @xmath61 . in the asymptotic case of @xmath62 and @xmath63 , the test statistic @xmath64 , according to the central limit theorem , converges to a gaussian distribution with mean @xmath65=0 $ ] and variance @xmath66\\approx{\\rm e}[g^2(x)]\\sum_{n=1}^ns_n^2 $ ] under the null hypotheses @xmath67 . using eqs .",
    "( [ expectation ] ) and  ( [ variance ] ) , @xmath64 is asymptotically gaussian with mean @xmath68\\approx{\\rm e}[g'(x)]\\sum_{n=1}^ns_n^2 $ ] and variance @xmath69={\\rm var}[t_{gc}|h_0]$ ] under the hypothesis @xmath70 @xcite .",
    "then , given a false alarm probability @xmath71 , the detection probability of the detector of eq .",
    "( [ gcd ] ) is expressed as @xmath72,\\end{aligned}\\ ] ] with @xmath73/\\sqrt{2\\pi}\\;dt$ ] and its inverse function @xmath74 @xcite .",
    "it is seen that @xmath75 is a monotonic increasing function of the deflection coefficient @xmath76 @xcite given by @xmath77-{\\rm e}[d|h_1])^2}{{\\rm var}[d|h_0 ] } \\approx \\frac{{\\rm e}^2[g'(x)]}{{\\rm e}[g^2(x)]}\\sum_{n=1}^ns_n^2\\nonumber \\\\ & \\leq & i(f_z ) \\sum_{n=1}^ns_n^2 = i(f_{z_0})\\sum_{n=1}^n s_n^2/\\sigma_z^2,\\end{aligned}\\ ] ] with equality being achieved when @xmath78 of eq .",
    "( [ lop ] ) @xcite .",
    "this result indicates that the asymptotic optimum detector is the lod established by the taylor expansion of the likelihood ratio test statistic @xmath79\\approx \\sum_{n=1}^n g_{\\rm opt}(x_n ) s_n$ ] ( @xmath80 ) in terms of the generalized neyman - pearson lemma @xcite .",
    "based on the bayesian criterion , two hypotheses @xmath67 and @xmath70 are endowed with prior probabilities @xmath81 and @xmath82 .",
    "similarly , for the weak signal @xmath55 and the sufficiently large @xmath52 , the test statistic @xmath64 in eq .",
    "( [ gcd ] ) has gaussian distribution and its performance is evaluated by the error probability @xcite @xmath83 which is also a monotonically decreasing function of @xmath76 and has a minimum as @xmath84 of eq .",
    "( [ eq : deflection ] ) for @xmath85 @xcite .",
    "interestingly , with @xmath86 ( called the signal energy - to - noise ratio of the data vector @xmath87 @xcite ) achieved by a matched filter as a benchmark @xcite , the asymptotic relative efficiency ( are ) @xmath88 provides an asymptotic performance improvement of a detector of eq .",
    "( [ gcd ] ) over the linear matched filter @xcite when both detectors operate in the same noise environment @xcite .",
    "the equality of eq .",
    "( [ arpf ] ) is achieved as @xmath78 @xcite .",
    "thirdly , we transmit a known weak aperiodic signal @xmath3 through the nonlinearity @xmath1 of eq .",
    "( [ system ] ) @xcite . here",
    ", the signal @xmath3 is with the average signal variance @xmath89=\\sigma_s^2\\ll \\sigma_z^2 $ ] , the zero mean @xmath90=0 $ ] and the upper bound a ( @xmath91 ) .",
    "for example , @xmath3 can be a sample according to a uniformly distributed random signal equally taking values from a bounded interval .",
    "the input cross - correlation coefficient of @xmath3 and @xmath2 is defined as @xcite @xmath92}{\\sqrt{{\\rm e}[s^2(t)]}\\sqrt{{\\rm e}[x^2(t)]}}= \\frac{\\frac{\\sigma_s}{\\sigma_z}}{\\sqrt{\\frac{\\sigma_s^2}{\\sigma_z^2}+1}}\\approx \\frac{\\sigma_s}{\\sigma_z}.\\end{aligned}\\ ] ] using eqs .",
    "( [ taylor])([variance ] ) , the output cross - correlation coefficient of @xmath3 and @xmath27 is given by @xmath93}{\\sigma_s \\sqrt{{\\rm var}[y(t)]}}\\approx\\frac{\\sigma_s { \\rm e}[g'(z)]}{\\sqrt{{\\rm e}[g^2(z)]}}.\\end{aligned}\\ ] ] then , the cross - correlation gain ( cg ) @xmath94 is given by @xmath95}{\\sqrt{{\\rm e}[g^2(z)]}}\\leq \\sqrt{i(f_{z_0})},\\end{aligned}\\ ] ] which has its maximal value as @xmath96 of eq .",
    "( [ lop ] ) .",
    "finally , for the @xmath52 observation components @xmath97 , we assume the signal @xmath98 are with an unknown parameter @xmath99 . as the upper bound @xmath100 ( @xmath101 )",
    ", the cramr - rao inequality indicates that the mean squared error of any unbiased estimator of the parameter @xmath99 is lower bounded by the reciprocal of the fi @xcite given by @xmath102 \\nonumber \\\\ & \\approx & \\sum_{n=1}^n { \\rm e}\\left[\\left(\\frac{df_z(z_n)/dz}{f_z(z_n)}\\bigr|_{z_n = x_n - s_n } \\bigl(-\\frac{\\partial s_n}{\\partial \\theta}\\bigr)\\right)^2\\right]\\nonumber \\\\ & = & i(f_z ) \\sum_{n=1}^n \\bigl(\\frac{\\partial s_n}{\\partial \\theta}\\bigr)^2= \\frac{i(f_{z_0})}{\\sigma_z^2 } \\sum_{n=1}^n \\bigl(\\frac{\\partial s_n}{\\partial \\theta}\\bigr)^2,\\end{aligned}\\ ] ] which indicates that the minimum mean square error of any unbiased estimator is also determined by the fi @xmath48 of distribution with a location shift , as @xmath103 is fixed .",
    "therefore , just as the fi represents the lower bound of the mean squared error of any unbiased estimator in signal estimation , the physical significance of the fi @xmath48 is that it provides a upper bound of the performance for locally optimum processing for the three considered problems .",
    "some interesting questions arise : which type of noise pdf has a minimal or maximal fi @xmath48 , and how large is the extreme value of @xmath48 ? does the corresponding lop in eq .",
    "( [ lop ] ) exist for the noise pdf with extreme @xmath48 ? these questions will be investigated as follows .      for a standardized even pdf @xmath43 , we have @xmath104 { \\rm e}\\left[z_0 ^ 2 \\right ] \\geq { \\rm e}\\left[\\frac{f'_{z_0}(z_0)}{f_{z_0}(z_0)}\\ ; z_0 \\right]^2\\!=\\!1,\\end{aligned}\\ ] ] with @xmath105\\!\\!=\\!\\!\\sigma_{z_0}^2\\!\\!=\\!\\!1 $ ] and the equality occurring if @xmath106 for a constant @xmath107",
    ". then , @xmath108 $ ] @xcite . in order to be a pdf , @xmath109 and @xmath110",
    "is the normalized constant @xcite .",
    "this is a standardized gaussian pdf @xmath111 .",
    "contrarily , any standardized non - gaussian pdf @xmath43 has the fi @xmath112 , which indicates that the performance ( snr gain , are or cg ) is certainly larger than unity via a lop of eq .",
    "( [ lop ] ) for processing a known weak signal @xcite .      a standardized generalized gaussian noise pdf @xcite @xmath113,\\end{aligned}\\ ] ] with @xmath114 and @xmath115 .",
    "the fi @xmath48 of eq .",
    "( [ ggauss ] ) becomes @xcite @xmath116 \\gamma\\left(\\frac{3}{2}-\\frac{1}{2}\\beta\\right)}{\\gamma^2\\left[\\frac{1}{2}(1+\\beta)\\right]},\\end{aligned}\\ ] ] with the corresponding normalized lop @xcite @xmath117 where @xmath118 is the sign or signum function .",
    "the curve of @xmath48 versus @xmath119 ( cf .",
    "fig .  10.10 of ref .",
    "@xcite ) clearly indicates that , for @xmath120 , @xmath121 is the minimum corresponding to the standardized gaussian pdf .",
    "it is also noted that , as @xmath122 or @xmath123 , @xmath124 . is the maximal @xmath48 infinite for @xmath125 and @xmath126 or not , and",
    "is the corresponding lop simply implemented ?",
    "the answer is negative , because the lop of eq .",
    "( [ nlop ] ) is not realizable as @xmath127 for @xmath128 and @xmath126 . when @xmath129 , the lop of eq .",
    "( [ nlop ] ) has a singularity at @xmath130 . in this sense",
    ", an arbitrary large fi can not be reached for the generalized gaussian noise given in eq .",
    "( [ ggauss ] ) .",
    "next , we consider gaussian mixture noise @xmath7 with its pdf @xmath131\\!,\\end{aligned}\\ ] ] with variance @xmath132 and parameters @xmath133 .",
    "note that eq .",
    "( [ gaussmix0 ] ) has another expression @xcite as @xmath134/\\sqrt{2\\pi\\epsilon^2},\\end{aligned}\\ ] ] with @xmath135 $ ] .",
    "based on eq .",
    "( [ gaussmixtan ] ) , the corresponding normalized lop can be expressed as @xmath136 for @xmath137 , assume @xmath138 and @xmath139 , eq .",
    "( [ gaussmixtan ] ) becomes a standardized gaussian mixture pdf @xcite @xmath140/\\sqrt{2\\pi(1-m^2)},\\end{aligned}\\ ] ] with @xmath141 $ ] .",
    "the function of fi @xmath48 versus @xmath142 is shown in fig .",
    "[ fig : one ] , and @xmath48 can be calculated as ( no explicit expression exists ) @xmath143 ^ 2\\right\\}.\\end{aligned}\\ ] ]     versus parameter @xmath142 of the gaussian mixture noise pdf of eq .",
    "( [ gaussmix ] ) . ]",
    "interestingly , fig .",
    "[ fig : one ] shows that , as @xmath144 , eq .",
    "( [ gaussmix ] ) is the standardized gaussian pdf with the fi @xmath121 . while , @xmath124 as @xmath145 . in eq .",
    "( [ gaussmix0 ] ) , for @xmath145 , @xmath146 and @xmath147 , the term @xmath148=\\delta(z)$ ] and @xmath149 is the dirac delta function . then , eq .  ( [ gaussmix0 ] ) becomes @xmath150,\\end{aligned}\\ ] ] which represents the pdf of dichotomous noise @xmath7 .",
    "we also note @xmath151 ( @xmath152 ) in eq .",
    "( [ processorgm ] ) , and the normalized lop for dichotomous noise @xmath7 is @xmath153 here , the normalized lop @xmath40 is not continuous at @xmath130 , but the above analysis is valid for processing a known weak signal in dichotomous noise .",
    "this point is like the lop @xmath154 for laplacian noise @xcite .",
    "when @xmath7 randomly takes two levels @xmath155 and @xmath156 and @xmath3 is weak compared with @xmath7 ( @xmath157 ) , the signs of input data @xmath2 always take the sign of @xmath7 , i.e.  @xmath158 in eq .",
    "( [ lopopt ] ) .",
    "therefore , the lop of eq .",
    "( [ lopopt ] ) at a fixed time @xmath12 can be solved as @xmath159=x(t)-\\sigma_z \\ ; { \\rm sign}[x(t)]=s(t)+z(t)-\\sigma_z { \\rm sign}[z(t)]=s(t)$ ] .",
    "moreover , refs .  @xcite have pointed out that there exists a scheme allowing a perfect recovery of @xmath3 corrupted by dichotomous noise @xmath7 with the pdf of eq .",
    "( [ gaussmix2 ] ) .",
    "however , a practical difficulty in eq .",
    "( [ nlop ] ) is that the rms @xmath9 needs to be known .",
    "the above analysis indicates that the lop of eq .",
    "( [ lopopt ] ) can recover the weak signal @xmath3 perfectly as @xmath157 .",
    "thus , according to the optimum performance of the lop of eq .",
    "( [ fisher ] ) ( eq .",
    "( [ arpf ] ) or eq .",
    "( [ cg ] ) ) , the fi @xmath160 contained in the type of pdf of eq .",
    "( [ gaussmix2 ] ) , as shown in fig .",
    "[ fig : one ] . using eq .",
    "( [ gaussmixtan ] ) , the fi @xmath48 of eq .",
    "( [ mgfisher ] ) can be computed as @xmath161={\\rm e}\\left[\\frac{d^2y(z_0)}{dz_0 ^ 2}\\right ] \\nonumber \\\\&=&\\lim\\limits _ { m\\rightarrow 1 } \\int_{-\\infty}^{\\infty}\\!\\!\\ !",
    "\\frac{\\bigl[\\ ! 1\\!-\\!m^2\\!-\\!m^2{\\rm sech}^2\\!\\bigl(\\frac{m z_0}{1\\!-\\!m^2}\\bigr)\\bigr]}{(1-m^2)^2}\\;\\frac{\\exp[-y(z_0)]}{\\sqrt{2\\pi ( 1-m^2 ) } } dz_0\\!=\\!\\infty,\\end{aligned}\\ ] ] where @xmath162=0 $ ] , the numerator is the infinitesimal @xmath163 and the denominator is a higher - order infinitesimal @xmath164 in the integral .",
    "in this paper , for a known weak signal in additive white noise , it was theoretically demonstrated that the optimum performance of a lop can be completely determined by the fi of the corresponding standardized even noise pdf , as illustrated by three signal processing case stuides : ( i ) the maximum snr gain for a periodic signal ; ( ii ) the optimal are for signal detection ; ( iii ) the best cg for signal transmission .",
    "thus , our study of the performance of a lop focused on the measure of the fi of a standardized noise pdf .",
    "it is well known that the minimal fi is unity for a standardized gaussian noise pdf , and the matched filter is the corresponding optimal processor . while , for any non - gaussian noise , the fi and hence the optimum performance of the lop is certainly larger than unity .",
    "illustratively , we observed that the generalized gaussian noise pdf and the gaussian mixture noise pdf have an arbitrary large fi .",
    "there are some types of noise pdf possessing an infinite fi , such as uniform noise and dichotomous noise .",
    "however , we argue that only if the lop is practically realizable , can the performance predicted by the fi be reached in practice . in this sense , it is found that the dichotomous noise has an infinite fi and also a simple lop structure can be realized in practice .",
    "some interesting questions arise .",
    "for instance , it is known that for a weak signal already corrupted by initial additive white noise , there is usually a lop that yields the maximal output - input gain .",
    "therefore , can the method of adding an extra amount of noise @xcite to the initial data improve the performance of the updated lop for the resulting noise pdf ?",
    "this interesting topic will invoke the stochastic resonance phenomenon @xcite .",
    "another important question is the influence of finite observation time on the performance of locally optimum processing @xcite ."
  ],
  "abstract_text": [
    "<S> for a known weak signal in additive white noise , the asymptotic performance of a locally optimum processor ( lop ) is shown to be given by the fisher information ( fi ) of a standardized even probability density function ( pdf ) of noise in three cases : ( i ) the maximum signal - to - noise ratio ( snr ) gain for a periodic signal ; ( ii ) the optimal asymptotic relative efficiency ( are ) for signal detection ; ( iii ) the best cross - correlation gain ( cg ) for signal transmission . </S>",
    "<S> the minimal fi is unity , corresponding to a gaussian pdf , whereas the fi is certainly larger than unity for any non - gaussian pdfs . in the sense of a realizable lop </S>",
    "<S> , it is found that the dichotomous noise pdf possesses an infinite fi for known weak signals perfectly processed by the corresponding lop . </S>",
    "<S> the significance of fi lies in that it provides a upper bound for the performance of locally optimum processing . </S>"
  ]
}