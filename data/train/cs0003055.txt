{
  "article_text": [
    "a large number of current language processing systems use a part - of - speech tagger for pre - processing .",
    "the tagger assigns a ( unique or ambiguous ) part - of - speech tag to each token in the input and passes its output to the next processing level , usually a parser .",
    "furthermore , there is a large interest in part - of - speech tagging for corpus annotation projects , who create valuable linguistic resources by a combination of automatic processing and human correction .    for both applications , a tagger with the highest possible accuracy",
    "is required .",
    "the debate about which paradigm solves the part - of - speech tagging problem best is not finished .",
    "recent comparisons of approaches that can be trained on corpora @xcite have shown that in most cases statistical aproaches @xcite yield better results than finite - state , rule - based , or memory - based taggers @xcite .",
    "they are only surpassed by combinations of different systems , forming a `` voting tagger '' .    among the statistical approaches , the maximum entropy framework has a very strong position .",
    "nevertheless , a recent independent comparison of 7 taggers @xcite has shown that another approach even works better : markov models combined with a good smoothing technique and with handling of unknown words .",
    "this tagger , , not only yielded the highest accuracy , it also was the fastest both in training and tagging .",
    "the tagger comparison was organized as a `` black - box test '' : set the same task to every tagger and compare the outcomes .",
    "this paper describes the models and techniques used by  together with the implementation .",
    "the reader will be surprised how simple the underlying model is .",
    "the result of the tagger comparison seems to support the maxime `` the simplest is the best '' .",
    "however , in this paper we clarify a number of details that are omitted in major previous publications concerning tagging with markov models . as two examples ,",
    "@xcite and @xcite give good overviews of the techniques and equations used for markov models and part - of - speech tagging , but they are not very explicit in the details that are needed for their application .",
    "we argue that it is not only the choice of the general model that determines the result of the tagger but also the various `` small '' decisions on alternatives .    the aim of this paper is to give a detailed account of the techniques used in .",
    "additionally , we present results of the tagger on the negra corpus @xcite and the penn treebank @xcite .",
    "the penn treebank results reported here for the markov model approach are at least equivalent to those reported for the maximum entropy approach in @xcite . for a comparison to other taggers ,",
    "the reader is referred to @xcite .",
    "uses second order markov models for part - of - speech tagging .",
    "the states of the model represent tags , outputs represent the words .",
    "transition probabilities depend on the states , thus pairs of tags .",
    "output probabilities only depend on the most recent category . to be explicit",
    ", we calculate @xmath0 p(t_{t+1}|t_t)\\ ] ] for a given sequence of words @xmath1 of length @xmath2 .",
    "@xmath3 are elements of the tagset , the additional tags @xmath4 , @xmath5 , and @xmath6 are beginning - of - sequence and end - of - sequence markers . using these additional tags , even if they stem from rudimentary processing of punctuation marks ,",
    "slightly improves tagging results .",
    "this is different from formulas presented in other publications , which just stop with a `` loose end '' at the last word .",
    "if sentence boundaries are not marked in the input ,  adds these tags if it encounters one of [ . ! ?",
    "; ] as a token .",
    "transition and output probabilities are estimated from a tagged corpus . as a first step ,",
    "we use the maximum likelihood probabilities @xmath7 which are derived from the relative frequencies : @xmath8 for all @xmath9 , @xmath10 , @xmath11 in the tagset and @xmath12 in the lexicon .",
    "@xmath13 is the total number of tokens in the training corpus .",
    "we define a maximum likelihood probability to be zero if the corresponding nominators and denominators are zero . as a second step , contextual frequencies are smoothed and lexical frequences are completed by handling words that are not in the lexicon ( see below ) .",
    "trigram probabilities generated from a corpus usually can not directly be used because of the sparse - data problem .",
    "this means that there are not enough instances for each trigram to reliably estimate the probability .",
    "furthermore , setting a probability to zero because the corresponding trigram never occured in the corpus has an undesired effect .",
    "it causes the probability of a complete sequence to be set to zero if its use is necessary for a new text sequence , thus makes it impossible to rank different sequences containing a zero probability .",
    "the smoothing paradigm that delivers the best results in  is linear interpolation of unigrams , bigrams , and trigrams .",
    "therefore , we estimate a trigram probability as follows : @xmath14 @xmath7 are maximum likelihood estimates of the probabilities , and @xmath15 , so @xmath16 again represent probability distributions .",
    "we use the context - independent variant of linear interpolation , i.e. , the values of the @xmath17s do not depend on the particular trigram .",
    "contrary to intuition , this yields better results than the context - dependent variant . due to sparse - data problems",
    ", one can not estimate a different set of @xmath17s for each trigram .",
    "therefore , it is common practice to group trigrams by frequency and estimate tied sets of @xmath17s .",
    "however , we are not aware of any publication that has investigated frequency groupings for linear interpolation in part - of - speech tagging .",
    "all groupings that we have tested yielded at most equivalent results to context - independent linear interpolation .",
    "some groupings even yielded worse results .",
    "the tested groupings included a ) one set of @xmath17s for each frequency value and b ) two classes ( low and high frequency ) on the two ends of the scale , as well as several groupings in between and several settings for partitioning the classes .",
    "the values of @xmath18 , @xmath19 , and @xmath20 are estimated by deleted interpolation .",
    "this technique successively removes each trigram from the training corpus and estimates best values for the @xmath17s from all other @xmath21-grams in the corpus .",
    "given the frequency counts for uni- , bi- , and trigrams , the weights can be very efficiently determined with a processing time linear in the number of different trigrams .",
    "the algorithm is given in figure [ fig : lambdaalg ] .",
    "note that subtracting 1 means taking unseen data into account . without this subtraction",
    "the model would overfit the training data and would generally yield worse results .    ' '' ''",
    "= set @xmath22 + foreach trigram @xmath23 with @xmath24 + depending on the maximum of the following three values : + case @xmath25 : increment @xmath20 by @xmath26 + case @xmath27 : increment @xmath19 by @xmath26 + case @xmath28 : increment @xmath18 by @xmath26 + end + end + normalize @xmath29    ' '' ''      currently , the method of handling unknown words that seems to work best for inflected languages is a suffix analysis as proposed in @xcite .",
    "tag probabilities are set according to the word s ending .",
    "the suffix is a strong predictor for word classes , e.g. , words in the wall street journal part of the penn treebank ending in _ able _ are adjectives ( jj ) in 98% of the cases",
    "( e.g.  fashionable , variable ) , the rest of 2% are nouns ( e.g.   cable , variable ) .",
    "the probability distribution for a particular suffix is generated from all words in the training set that share the same suffix of some predefined maximum length .",
    "the term suffix as used here means `` final sequence of characters of a word '' which is not necessarily a linguistically meaningful suffix .",
    "probabilities are smoothed by successive abstraction .",
    "this calculates the probability of a tag @xmath30 given the last @xmath31 letters @xmath32 of an @xmath21 letter word : @xmath33 .",
    "the sequence of increasingly more general contexts omits more and more characters of the suffix , such that @xmath34 , @xmath35 , ",
    ", @xmath36 are used for smoothing .",
    "the recursion formula is @xmath37 @xmath38 for @xmath39 , using the maximum likelihood estimates @xmath7 from frequencies in the lexicon , weights @xmath40 and the initialization @xmath41 the maximum likelihood estimate for a suffix of length @xmath42 is derived from corpus frequencies by @xmath43 for the markov model , we need the inverse conditional probabilities @xmath44 which are obtained by bayesian inversion .    a theoretical motivated argumentation uses the standard deviation of the maximum likelihood probabilities for the weights @xmath40 @xcite .    this leaves room for interpretation .",
    "\\1 ) one has to identify a good value for @xmath31 , the longest suffix used .",
    "the approach taken for  is the following : @xmath31 depends on the word in question .",
    "we use the longest suffix that we can find in the training set ( i.e. , for which the frequency is greater than or equal to 1 ) , but at most 10 characters .",
    "this is an empirically determined choice .",
    "\\2 ) we use a context - independent approach for @xmath40 , as we did for the contextual weights @xmath45 .",
    "it turned out to be a good choice to set all @xmath40 to the standard deviation of the unconditioned maximum likelihood probabilities of the tags in the training corpus , i.e. , we set @xmath46 for all @xmath47 , using a tagset of @xmath48 tags and the average @xmath49 this usually yields values in the range 0.03  0.10 .",
    "\\3 ) we use different estimates for uppercase and lowercase words , i.e. , we maintain two different suffix tries depending on the capitalization of the word .",
    "this information improves the tagging results .",
    "\\4 ) another freedom concerns the choice of the words in the lexicon that should be used for suffix handling .",
    "should we use all words , or are some of them better suited than others ? accepting that unknown words are most probably infrequent , one can argue that using suffixes of infrequent words in the lexicon is a better approximation for unknown words than using suffixes of frequent words .",
    "therefore , we restrict the procedure of suffix handling to words with a frequency smaller than or equal to some threshold value . empirically , 10 turned out to be a good choice for this threshold .",
    "additional information that turned out to be useful for the disambiguation process for several corpora and tagsets is capitalization information .",
    "tags are usually not informative about capitalization , but probability distributions of tags around capitalized words are different from those not capitalized . the effect is larger for english , which only capitalizes proper names , and smaller for german , which capitalizes all nouns .",
    "we use flags @xmath50 that are true if @xmath51 is a capitalized word and false otherwise .",
    "these flags are added to the contextual probability distributions .",
    "instead of @xmath52 we use @xmath53 and equations ( [ eq : uni ] ) to ( [ eq : tri ] ) are updated accordingly .",
    "this is equivalent to doubling the size of the tagset and using different tags depending on capitalization .",
    "the processing time of the viterbi algorithm @xcite can be reduced by introducing a beam search . each state that receives a @xmath54 value smaller than the largest @xmath54 divided by some threshold value @xmath55",
    "is excluded from further processing . while the viterbi algorithm is guaranteed to find the sequence of states with the highest probability ,",
    "this is no longer true when beam search is added .",
    "nevertheless , for practical purposes and the right choice of @xmath55 , there is virtually no difference between the algorithm with and without a beam .",
    "empirically , a value of @xmath56 turned out to approximately double the speed of the tagger without affecting the accuracy .",
    "the tagger currently tags between 30,000 and 60,000 tokens per second ( including file i / o ) on a pentium 500 running linux .",
    "the speed mainly depends on the percentage of unknown words and on the average ambiguity rate .",
    "we evaluate the tagger s performance under several aspects .",
    "first of all , we determine the tagging accuracy averaged over ten iterations . the overall accuracy , as well as separate accuracies for known and unknown words are measured .",
    "second , learning curves are presented , that indicate the performance when using training corpora of different sizes , starting with as few as 1,000 tokens and ranging to the size of the entire corpus ( minus the test set ) .",
    "an important characteristic of statistical taggers is that they not only assign tags to words but also probabilities in order to rank different assignments .",
    "we distinguish reliable from unreliable assignments by the quotient of the best and second best assignments if there is only one possible tag for a given word . ] .",
    "all assignments for which this quotient is larger than some threshold are regarded as reliable , the others as unreliable .",
    "as we will see below , accuracies for reliable assignments are much higher .",
    "the tests are performed on partitions of the corpora that use 90% as training set and 10% as test set , so that the test data is guaranteed to be unseen during training .",
    "each result is obtained by repeating the experiment 10 times with different partitions and averaging the single outcomes .    in all experiments ,",
    "contiguous test sets are used .",
    "the alternative is a round - robin procedure that puts every 10th sentence into the test set .",
    "we argue that contiguous test sets yield more realistic results because completely unseen articles are tagged . using the round - robin procedure ,",
    "parts of an article are already seen , which significantly reduces the percentage of unknown words .",
    "therefore , we expect even higher results when testing on every 10th sentence instead of a contiguous set of 10% .    in the following , accuracy denotes the number of correctly assigned tags divided by the number of tokens in the corpus processed .",
    "the tagger is allowed to assign exactly one tag to each token .",
    "we distinguish the overall accuracy , taking into account all tokens in the test corpus , and separate accuracies for known and unknown tokens .",
    "the latter are interesting , since usually unknown tokens are much more difficult to process than known tokens , for which a list of valid tags can be found in the lexicon .",
    "the german negra corpus consists of 20,000 sentences ( 355,000 tokens ) of newspaper texts ( frankfurter rundschau ) that are annotated with parts - of - speech and predicate - argument structures @xcite .",
    "it was developed at the saarland university in saarbrcken .",
    "part of it was tagged at the ims stuttgart .",
    "this evaluation only uses the part - of - speech annotation and ignores structural annotations .",
    "tagging accuracies for the negra corpus are shown in table [ tab : negraacc ] .",
    "figure [ fig : negra - learn ] shows the learning curve of the tagger , i.e. , the accuracy depending on the amount of training data .",
    "training length is the number of tokens used for training .",
    "each training length was tested ten times , training and test sets were randomly chosen and disjoint , results were averaged .",
    "the training length is given on a logarithmic scale .",
    "it is remarkable that tagging accuracy for known words is very high even for very small training corpora .",
    "this means that we have a good chance of getting the right tag if a word is seen at least once during training .",
    "average percentages of unknown tokens are shown in the bottom line of each diagram .    ' '' ''    [ cols= \" < , > , > , > , > , > , > , > \" , ]     ' '' ''    ' '' ''    * penn treebank : pos learning curve *    units <",
    "30mm,.8 mm > x from 3 to 6 , y from 50 to 100 bottom ticks withvalues 1 2 5 10 20 50 100 200 500 1000 / at 3 3.3 3.7 4 4.3 4.7 5 5.3 5.7 6 / / left ticks numbered from 50 to 100 by 10 / [ t ] < 0mm,-8.5 mm > at 3 50 [ t ] < 0mm,-8.5 mm > at 3.3 50 [ t ] < 0mm,-8.5 mm > at 3.7 50 [ t ] < 0mm,-8.5 mm > at 4 50 [ t ] < 0mm,-8.5 mm > at 4.3 50 [ t ] < 0mm,-8.5 mm > at 4.7 50 [ t ] < 0mm,-8.5 mm > at 5 50 [ t ] <",
    "0mm,-8.5 mm > at 5.3 50 [ t ] <",
    "0mm,-8.5 mm > at 5.7 50 [ t ] <",
    "0mm,-8.5 mm > at 6 50 [ tl ] < 3mm,-8.5 mm > at 6.05 50 = .4pt breadth < 0pt > from 3 60 to 6 60 breadth < 0pt > from 3 70 to 6 70 breadth",
    "< 0pt > from 3 80 to 6 80 breadth",
    "< 0pt > from 3 90 to 6 90 breadth",
    "< 0pt > from 3 100 to 6 100 [ r ] < -9mm,0 mm > at 3 75 [ lt ] < 4mm,-3 mm > at 6 50 [ l ] <",
    "5mm,0 mm > at 6 94 [ l ] <",
    "18mm,0 mm > at 6 95 [ l ] < 18mm,0 mm > at 6 87 [ l ] <",
    "5mm,0 mm > at 6 79 [ l ] < 9mm,0 mm > at 6 79 [ l ] < 18mm,0 mm > at 6 79 [ l ] <",
    "18mm,0 mm > at 6 71 [ l ] <",
    "5mm,0 mm > at 6 63 [ l ] <",
    "9mm,0 mm > at 6",
    "18mm,0 mm > at 6 63 [ l ] <",
    "18mm,0 mm > at 6 55 (    ' '' ''    ) 3.000 78.59 3.301 84.67 3.699 89.40 4.000 91.32 4.301 92.89 4.699 94.46 5.000 95.24 5.301 95.81 5.699 96.28 6.000",
    "96.65 / (    ' '' ''    ) 3.000 95.17 3.301 95.17 3.699 95.56 4.000 95.59 4.301 95.77 4.699 96.12 5.000 96.42 5.301 96.62 5.699 96.78 6.000 96.97 / at 3.000 95.17 3.301 95.17 3.699 95.56 4.000 95.59 4.301 95.77 4.699 96.12 5.000 96.42 5.301 96.62 5.699 96.78 6.000 96.91 / 3.000 62.18 3.301 70.62 3.699 77.12 4.000 79.66 4.301 81.54 4.699 83.54 5.000 84.38 5.301 84.89 5.699 85.30 6.000 85.46 / at 3.000 62.18 3.301 70.62 3.699 77.12 4.000 79.66 4.301 81.54 4.699 83.54 5.000 84.38 5.301 84.89 5.699 85.30",
    "6.000 85.46 /    ' '' ''    ' '' ''    * penn treebank : accuracy of reliable assignments *    units <",
    "23mm,10 mm > x from 0 to 4 , y from 96 to 100 bottom ticks withvalues 1 2 5 10 20 50 100 500 2000 10000 / at 0 .3 .7 1 1.3 1.7 2 2.7 3.3 4 / / bottom ticks at 2.3 3 3.7 / / left ticks numbered from 96 to 100 by 1 / = .4pt breadth < 0pt > from 0 97 to 4 97 breadth < 0pt > from 0 98 to 4 98 breadth < 0pt > from 0 99 to 4 99 breadth < 0pt > from 0 100 to 4 100 [ r ] < -9mm,0 mm > at 0 98 [ lt ] < 7mm,-2.6 mm > at 4 96 [ t ] <",
    "0mm,-8.5 mm > at 0 96 [ t ] <",
    "0mm,-8.5 mm > at .3 96 [ t ] <",
    "0mm,-8.5 mm > at .7 96 [ t ] <",
    "0mm,-8.5 mm > at 1 96 [ t ] <",
    "0mm,-8.5 mm > at 1.3 96 [ t ] < 0mm,-8.5 mm > at 1.7 96 [ t ] <",
    "0mm,-8.5 mm > at 2 96 [ t ] <",
    "0mm,-8.5 mm > at 2.3 96 [ t ]",
    "< 0mm,-8.5 mm > at 2.7 96 [ t ] < 0mm,-8.5 mm > at 3 96 [ t ] <",
    "0mm,-8.5 mm > at 3.3 96 [ t ] < 0mm,-8.5 mm > at 3.7 96 [ t ] <",
    "0mm,-8.5 mm > at 4 96 [ lt ] < 7mm,-8.5 mm > at 4 96 [ t ] <",
    "0mm,-13.5 mm > at 0 96 [ t ] < 0mm,-13.5 mm > at .3 96 [ t ] <",
    "0mm,-13.5 mm > at .7 96 [ t ] <",
    "0mm,-13.5 mm > at 1 96 [ t ] <",
    "0mm,-13.5 mm > at 1.3 96 [ t ] < 0mm,-13.5 mm > at 1.7 96 [ t ] < 0mm,-13.5 mm > at 2 96 [ t ] <",
    "0mm,-13.5 mm > at 2.3 96 [ t ] <",
    "0mm,-13.5 mm > at 2.7 96 [ t ]",
    "< 0mm,-13.5 mm > at 3 96 [ t ] <",
    "0mm,-13.5 mm > at 3.3 96 [ t ] <",
    "0mm,-13.5 mm > at 3.7 96 [ t ] < 0mm,-13.5 mm > at 4 96 [ lt ] < 7mm,-13 mm > at 4 96 [ lb ] < 5mm,0 mm > at 4 98.5 (    ' '' ''    ) 0.00 96.63 0.30 97.71 0.70 98.61 1.00 99.01 1.30 99.25 1.70 99.41 2.00 99.46 2.30 99.48 2.70 99.49 3.00 99.48 3.30 99.46 3.70 99.44",
    "4.00 99.42 / at 0.00 96.63 0.30 97.71 0.70 98.61 1.00 99.01 1.30 99.25 1.70 99.41 2.00 99.46 2.30 99.48 2.70 99.49 3.00 99.48 3.30 99.46 3.70 99.44 4.00 99.42 /    ' '' ''    we exploit the fact that the tagger not only determines tags , but also assigns probabilities .",
    "if there is an alternative that has a probability `` close to '' that of the best assignment , this alternative can be viewed as almost equally well suited .",
    "the notion of `` close to '' is expressed by the distance of probabilities , and this in turn is expressed by the quotient of probabilities .",
    "so , the distance of the probabilities of a best tag @xmath57 and an alternative tag @xmath58 is expressed by @xmath59 , which is some value greater or equal to 1 since the best tag assignment has the highest probability .",
    "figure [ fig : negra - cond ] shows the accuracy when separating assignments with quotients larger and smaller than the threshold ( hence reliable and unreliable assignments ) . as expected , we find that accuracies for reliable assignments are much higher than for unreliable assignments .",
    "this distinction is , e.g. , useful for annotation projects during the cleaning process , or during pre - processing , so the tagger can emit multiple tags if the best tag is classified as unreliable .",
    "we use the wall street journal as contained in the penn treebank for our experiments .",
    "the annotation consists of four parts : 1 ) a context - free structure augmented with traces to mark movement and discontinuous constituents , 2 ) phrasal categories that are annotated as node labels , 3 ) a small set of grammatical functions that are annotated as extensions to the node labels , and 4 ) part - of - speech tags @xcite .",
    "this evaluation only uses the part - of - speech annotation .",
    "the wall street journal part of the penn treebank consists of approx .",
    "50,000 sentences ( 1.2 million tokens ) .",
    "tagging accuracies for the penn treebank are shown in table [ tab : pennacc ] .",
    "figure [ fig : penn - learn ] shows the learning curve of the tagger , i.e. , the accuracy depending on the amount of training data .",
    "training length is the number of tokens used for training .",
    "each training length was tested ten times .",
    "training and test sets were disjoint , results are averaged .",
    "the training length is given on a logarithmic scale .",
    "as for the negra corpus , tagging accuracy is very high for known tokens even with small amounts of training data .",
    "we exploit the fact that the tagger not only determines tags , but also assigns probabilities .",
    "figure [ fig : penn - cond ] shows the accuracy when separating assignments with quotients larger and smaller than the threshold ( hence reliable and unreliable assignments ) .",
    "again , we find that accuracies for reliable assignments are much higher than for unreliable assignments .",
    "average part - of - speech tagging accuracy is between 96% and 97% , depending on language and tagset , which is at least on a par with state - of - the - art results found in the literature , possibly better . for the penn treebank ,",
    "@xcite reports an accuracy of 96.6% using the maximum entropy approach , our much simpler and therefore faster hmm approach delivers 96.7% .",
    "this comparison needs to be re - examined , since we use a ten - fold crossvalidation and averaging of results while ratnaparkhi only makes one test run .",
    "the accuracy for known tokens is significantly higher than for unknown tokens . for the german newspaper data , results are 8.7% better when the word was seen before and",
    "therefore is in the lexicon , than when it was not seen before ( 97.7% vs.  89.0% ) .",
    "accuracy for known tokens is high even with very small amounts of training data .",
    "as few as 1000 tokens are sufficient to achieve 95%96% accuracy for them .",
    "it is important for the tagger to have seen a word at least once during training .",
    "stochastic taggers assign probabilities to tags .",
    "we exploit the probabilities to determine reliability of assignments . for a subset that is determined during processing by the tagger we achieve accuracy rates of over 99% .",
    "the accuracy of the complement set is much lower .",
    "this information can , e.g. , be exploited in an annotation project to give an additional treatment to the unreliable assignments , or to pass selected ambiguities to a subsequent processing step .",
    "we have shown that a tagger based on markov models yields state - of - the - art results , despite contrary claims found in the literature .",
    "for example , the markov model tagger used in the comparison of @xcite yielded worse results than all other taggers . in our opinion",
    ", a reason for the wrong claim is that the basic algorithms leave several decisions to the implementor .",
    "the rather large amount of freedom was not handled in detail in previous publications : handling of start- and end - of - sequence , the exact smoothing technique , how to determine the weights for context probabilities , details on handling unknown words , and how to determine the weights for unknown words .",
    "note that the decisions we made yield good results for both the german and the english corpus .",
    "they do so for several other corpora as well .",
    "the architecture remains applicable to a large variety of languages .",
    "according to current tagger comparisons @xcite , and according to a comparsion of the results presented here with those in @xcite , the maximum entropy framework seems to be the only other approach yielding comparable results to the one presented here .",
    "it is a very interesting future research topic to determine the advantages of either of these approaches , to find the reason for their high accuracies , and to find a good combination of both .",
    "is freely available to universities and related organizations for research purposes ( see http://www.coli.uni-sb.de/126thorsten/tnt ) .",
    "many thanks go to hans uszkoreit for his support during the development of .",
    "most of the work on  was carried out while the author received a grant of the deutsche forschungsgemeinschaft in the graduiertenkolleg kognitionswissenschaft saarbrcken .",
    "large annotated corpora are the pre - requisite for developing and testing part - of - speech taggers , and they enable the generation of high - quality language models .",
    "therefore , i would like to thank all the people who took the effort to annotate the penn treebank , the susanne corpus , the stuttgarter referenzkorpus , the negra corpus , the verbmobil corpora , and several others . and , last but not least",
    ", i would like to thank the users of  who provided me with bug reports and valuable suggestions for improvements .",
    "eugene charniak , curtis hendrickson , neil jacobson , and mike perkowitz .",
    "equations for part - of - speech tagging . in _ proceedings of the eleventh national conference on artificial intelligence _ , pages 784789 , menlo park : aaai press / mit press .",
    "doug cutting , julian kupiec , jan pedersen , and penelope sibun . 1992 . a practical part - of - speech tagger . in _ proceedings of the 3rd conference on applied natural language processing ( acl ) _ , pages 133140 .",
    "wojciech skut , brigitte krenn , thorsten brants , and hans uszkoreit .",
    "an annotation scheme for free word order languages . in _ proceedings of the fifth conference on applied natural language processing anlp-97 _ ,",
    "washington , dc .",
    "hans van halteren , jakub zavrel , and walter daelemans . 1998 . improving data driven wordclass tagging by system combination . in _ proceedings of the international conference on computational linguistics",
    "coling-98 _ , pages 491497 , montreal , canada ."
  ],
  "abstract_text": [
    "<S> trigramsntags ( ) is an efficient statistical part - of - speech tagger . </S>",
    "<S> contrary to claims found elsewhere in the literature , we argue that a tagger based on markov models performs at least as well as other current approaches , including the maximum entropy framework . </S>",
    "<S> a recent comparison has even shown that  performs significantly better for the tested corpora . </S>",
    "<S> we describe the basic model of , the techniques used for smoothing and for handling unknown words . </S>",
    "<S> furthermore , we present evaluations on two corpora . </S>"
  ]
}