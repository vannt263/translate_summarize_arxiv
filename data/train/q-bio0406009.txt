{
  "article_text": [
    "sequence comparison gathers interest from a wide variety of fields such as molecular biology , biophysics , mathematics , and computer science .",
    "methods of comparison concern computer scientists who use string comparison for everything from file searches to image processing @xcite .",
    "biological sequence comparison provides details into the building blocks of life by allowing the functional identification of newly found sequences through similarity to already studied ones .",
    "thus , it has become a standard tool of modern molecular biology .    as with all pattern search algorithms ,",
    "a crucial component for the successful application of sequence comparisons is the ability to discern the biologically meaningful from randomly occurring patterns .",
    "thus , a thorough characterization of the strength of patterns within _ random data _ is mandatory to establishing a criterion for discerning meaningful data @xcite .",
    "the most commonly used sequence alignment algorithms are the closely related needleman - wunsch  @xcite and smith - waterman  @xcite algorithms .",
    "there have been numerous numerical and analytical studies that attempt to characterize the behavior of these algorithms on random sequence data  @xcite . however , there are difficulties with both kinds of approaches to the problem of characterizing sequence alignment algorithms statistically . the numerical methods are by far too slow to be useful in an environment where tens of thousands of searches are performed on a daily basis and",
    "users expect their results on interactive time scales .",
    "the analytical methods on the other hand , while in principle able to rapidly characterize sequence alignment statistics , are only valid in small regions of the vast parameter space of the sequence alignment algorithms .",
    "in addition to being restricted to a small region of parameter space , current analytical methods have another drawback : they rely on an approximation to the actual alignment algorithm that ignores some subtle correlations within the sequence disorder . here , we want to demonstrate that such correlations do matter and propose an analytical approach that can in principle deal with these correlations for certain finite size variants of sequence alignment introduced in section  [ sec : outline ] .",
    "we will concentrate on the simplest prototype of a sequence alignment algorithm , namely the longest common subsequence ( lcs ) problem",
    ". more complicated models of sequence alignment can be adapted to the methodology presented here in a straightforward manner .",
    "however , in the interest of clarity and efficiency , we proceed with the simple lcs problem in mind . in the longest common subsequence problem similarity between two randomly chosen sequences over an alphabet of size @xmath0",
    "is measured by the length of the longest string that can be constructed from both sequences solely by deleting letters .",
    "the central quantity characterizing the statistics of the lcs problem is the expected length of this longest common subsequence .",
    "its fraction of the total sequence length in the limit of infinitely long sequences is called the chvtal - sankoff constant @xmath1 .    although the lcs problem is one of the simplest alignment algorithms , the value of the chvtal - sankoff constant has been remarkably elusive .",
    "so far , analytical stabs at @xmath1 have led to exact solutions for very short lengths @xcite and proofs for upper and lower bounds @xcite .",
    "based on numerical results , there existed a long - standing conjecture for the value of the chvtal - sankoff constant .",
    "recently  @xcite , this conjecture has been proven to hold true for the approximation to the lcs problem that precisely ignores the disorder correlations mentioned above .",
    "very careful and extensive numerical treatments  @xcite have revealed that the true chvtal - sankoff constant ( including all disorder correlations ) deviates slightly from its value in the uncorrelated approximation .",
    "this paper seeks to introduce a systematic way of understanding the lcs problem with all disorder correlations included and to establish in an analytically tractable environment that uncorrelated and correlated disorder indeed lead to different results .",
    "the format of this paper will be to summarize the lcs problem in section  [ sec : review ] .",
    "this section includes a general description of the lcs problem and outlines a commonly used paradigm for solving for the lcs . in addition , several conventions which are utilized throughout the paper are defined here . in section",
    "[ sec : outline ] we introduce the finite width model ( fwm ) method . in order to spare the reader possibly distracting mathematical details",
    "we discuss only the overall ideas in the main text and reserve appendix  [ sec : howto ] for the more detailed discussion of the mathematical methods employed in fwm . in section  [ sec : results ] we give the results of the fwm method for the correlated and uncorrelated lcs problem and discuss the differences between these two problems that become obvious in the fwm treatment .",
    "section  [ sec : conclusion ] summarizes our findings .",
    "the lcs of two sequences is the longest sequence that can be formed solely by deletions in both sequences  @xcite .",
    "best described by example , the lcs of ` ' darling ' ` and ` ' airline ' ` is ` ' arlin ' ` , with a subsequence length of 5 . given two sequences of length @xmath2 and @xmath3 , @xmath4 and @xmath5 , over an alphabet of size c ,",
    "their lcs can be computed in @xmath6 time .",
    "this computation may be conveniently visualized with a rectangular grid such as the one shown in fig .  [ grid ] .",
    "in this example , for the two sequences , @xmath7 = ` ' 001001 ' ` and @xmath8 = ` ' 010110 ' ` , the lcs , ` ' 0100 ' ` , has a length of 4 . within the grid used to find the lcs ,",
    "all horizontal and vertical bonds are assigned a value of 0 .",
    "each diagonal bond is designated a value depending on the associated letters in its row and column . matching letters earn their diagonal bonds a value of 1 , while non - matching letters result in an assignation of 0 .",
    "then , each directed path across these various bonds from the first lattice point in the upper - left to the last in the lower - right as drawn in fig .",
    "[ grid ] corresponds to a common subsequence of the two sequences .",
    "the only restriction is that the path may never proceed against the order of the sequences .",
    "it may only move rightward , downward , or right - downward in fig .",
    "the length of a common subsequence corresponding to a path is the sum of the bonds which comprise that path .",
    "solving this visual game for the length of the lcs requires that we find the path of greatest value",
    ". this value will be the length of the lcs .",
    "recursively , we may define this problem by introducing the quantity @xmath9 as the lcs of the substrings @xmath10 and @xmath11 .",
    "defining the lcs of two substrings in this way allows us to find the lcs leading to each of the lattice points in fig .  [ grid ]",
    "this in turn breaks our path search down into the more manageable steps .",
    "grid representation of the longest common subsequence ( lcs ) problem .",
    "the dashed line highlights a solution to the lcs of the two binary sequences on the edges of the square .",
    "notice that there exist multiple solutions to this problem . ]",
    "@xmath12    where @xmath13 and @xmath14    of course , once we evaluate the final @xmath15 , we have solved for the length of the lcs .",
    "ultimately , we wish to evaluate the central quantity that characterizes the lcs problem , the chvtal - sankoff constant @xmath1 .",
    "it characterizes the ensemble of lcs s of pairs of randomly chosen sequences with @xmath16 independently identically distributed ( iid ) letters .",
    "if we denote averages over the ensemble by @xmath17 , the chvtal - sankoff constant may be defined as @xmath18 this can be interpreted as the average growth rate of the lcs of two random sequences .    as evident from fig . 1 and the recursive equations ( [ eq : recursion])-([eq : boundary ] ) the length of the lcs depends on the sequences only via the values of the @xmath19 s .",
    "if we define the probabilities of 0 or 1 occurring in our random sequences as @xmath20 or @xmath21 , respectively , where @xmath22 , each individual @xmath19 carries a @xmath23 probability of being zero , and a @xmath24 of being 1 . however , the different @xmath25 are not chosen independently according to those probabilities , but are subject to subtle correlations .",
    "it is very tempting to neglect these correlations in favor of choosing @xmath26 iid variables @xmath27 according to @xmath28 where @xmath29 , the probability of a bond value being 0 .",
    "we will call this the uncorrelated lcs problem and identify all quantities calculated for this problem by an additional hat ; specifically , we will call @xmath30 the analog of the chvtal - sankoff constant in the uncorrelated lcs problem .",
    "this approximation to the real lcs problem has been used in various theoretical approaches to sequence comparison statistics  @xcite . for the lcs problem itself",
    ", only very careful numerical studies could show that the chvtal - sankoff constant for the correlated and uncorrelated problem are actually different @xcite . however , there are very real differences .",
    "the differences arise due to the fact that the correlated and uncorrelated cases allow different sets of possible bond or @xmath19 values . in the uncorrelated case",
    "all combinations of bond values are allowed to exist .",
    "the grid in fig .  [ grid ]",
    "makes it obvious that there are @xmath31 bonds each with 2 possibilities .",
    "therefore , there must exist @xmath32 unique configurations of bond values .",
    "meager by comparison are the @xmath33 cases allowed by the two sequences of length m and n , with each letter having the capacity to take on one of two values in the correlated case .",
    "notice the missing factor of 2 in the correlated case arises due to the fact that one can alway replace all 0 s with 1 s in order to get the same sequences of matches cutting our possible number of bond value configurations in half .",
    "a more concrete realization of the limited possibilities in the correlated case comes simply by noticing that there are only two bond value configurations values any row or column can take up in fig .  [ grid ] .",
    "additionally , a column or row with a value of 0 must be a mirror opposite of a column or row with a value of 1 .",
    "and so we can see that not only does the uncorrelated case account for sets of bond values that can not exist , it can not mimic the specific relationship between different rows and columns of bond values .",
    "we will reveal these differences in a simple approximation to the lcs problem that allows for closed analytical solutions in the correlated and uncorrelated case .",
    "this picture shows our @xmath34 counter - clockwise rotation to achieve the orientation from which we will proceed .",
    "the blow up defines the lattice site values ( k - values ) , the match values ( @xmath19-values ) , and the lattice site difference values ( h - values ) .",
    "it also defines our time and width axes .",
    "the dashed lines connect the sites between which our h - values are measured . ]    the finite width model ( fwm ) we will use in the following overlays the grid presented in fig .  [ grid ] with the restriction in width presented in fig .",
    "[ fwm ]  @xcite .",
    "we will measure the width @xmath35 of such a grid by the number of bands that make up the lattice , i.e. @xmath36 in fig .",
    "although , the grid used to analyze the lcs must be truncated to a finite width w , our finite strip extends to an infinite length .",
    "thus , we can still define a width dependent chvtal - sankoff constant @xmath37 in addition to the width @xmath35 , the growth rate also depends on the sequence composition . in our case of alphabet size @xmath38 this",
    "is characterized by the probability @xmath20 to find a ` ' 0 ' ` on each site within the sequences . while the method we will present below in principle enables us to calculate any @xmath39 , we will , in the following , concentrate on the simple example @xmath40 shown in fig .",
    "notice that @xmath41 from below , and thus @xmath42 produces a series of lower bounds to the chvtal - sankoff constant .    on the finite width lattice shown in fig .",
    "[ fwm ] , it is convenient to redefine our quantities .",
    "aside from the narrower scope under which we investigate the lcs problem , all other properties of the grid problem remain the same . instead of referring to our lattice points by the coordinates @xmath43 and @xmath44 ,",
    "we now utilize a time axis , @xmath45 , which points along the allowed , sequence forward , direction as well as a coordinate axis , @xmath46 , which lies perpendicular to the @xmath45-axis . in place of old @xmath47-values , in this new coordinate system",
    "we introduce @xmath48-values . keeping track of these @xmath48-values",
    "can be simplified to a new set of recursive relationships at each time step . in the notation defined by fig .",
    "[ fwm ] for width @xmath36 , @xmath49 @xmath50 @xmath51 where the @xmath19 s take on values of either 1 or 0 in the same way that we assigned values to our diagonal lines in fig",
    ".  [ grid ] .",
    "our set of recursive relationships gives us the longest path value up to each lattice site .",
    "the length of the fwm lcs then becomes @xmath52 .",
    "related to our @xmath48-values by equations ( [ eq : h1 ] ) and ( [ eq : h0 ] ) , we define the @xmath53-values in order to describe the relative values of our lattice sites within any given time frame . utilizing the diagrammed definitions of fig .",
    "[ fwm ] , @xmath54 the recursion relations ( [ eq : topline]),([eq : midline ] ) and ( [ eq : botline ] ) , can be expressed entirely via this new quantity as @xmath55 @xmath56 where @xmath57    several properties conveniently arise from these definitions .",
    "first , notice that the @xmath53-values are independent of the absolute @xmath48-values .",
    "furthermore , it may be shown by inspection that the @xmath53-values may only take on the values @xmath58 . inspecting fig .",
    "[ fwm ] , we note that each adjacent set of @xmath48-values share a nodal @xmath48 .",
    "this node attaches itself to the adjacent sites via a bond of value 0 or 1 .",
    "since the nodal @xmath48 holds only a single value and the single bonds leading to the adjacent sites can only change this value by + 1 , the only @xmath53-values allowed then become 0 or 1 . having detached the absolute @xmath48-values from the fwm - lcs problem entirely , we may further detach the entire fwm from the grid in fig .  [",
    "originally we noted that our fwm - lcs on this grid becomes @xmath52 .",
    "however , in order to calculate @xmath59 , the length of the lcs problem has to be increased infinitely along the time axis .",
    "time now becomes an unbounded axis in the fwm .",
    "since the difference @xmath60 is bounded by @xmath35 for all @xmath46 and @xmath61 , the length of the lcs may be measured at any @xmath46 . the growth rate",
    "may then be expressed as the average @xmath48-values increase along any coordinate , i.e. @xmath62 notice that @xmath63 and that as a result our newly defined @xmath59 carries the condition @xmath64 .",
    "the diagram maps the influence of letters from the two sequences ... , @xmath65 , @xmath66 , ... and ... , @xmath67 , @xmath68 , ... on the new orientation .",
    "the letter information required for the evolution from time @xmath69 to time @xmath45 is shown here .",
    "the dashed lines represent the chosen configuration for the @xmath53 s . ]    the formulation given by equations ( [ eq : h1rec ] ) , ( [ eq : h0rec ] ) make it clear that @xmath70 and @xmath71 can be calculated if @xmath72 , and @xmath73 are known .",
    "this allows us to write the time evolution as a markov model .",
    "in order to do so , the information required for the time evolution at each time step must be included in the states . for our uncorrelated states , where the @xmath19 s occur randomly , only @xmath74 and",
    "@xmath75 are required to determine the probable time evolution .",
    "therefore , the uncorrelated states simply read ( @xmath74 , @xmath75 ) . the probabilities for the time evolution into the state ( @xmath70 , @xmath71 ) may then be calculated based on the @xmath19-value probabilities given in equation ( [ eq : eta ] ) . however , in the correlated case , the @xmath19 s are not randomly chosen . instead",
    ", the letters in each sequence are according to the probability @xmath20 of a 0 occurring at a single site within the sequences .",
    "some letters affect @xmath19 s across multiple time steps as shown by fig .",
    "[ states ] . in order to calculate the time evolution to time @xmath45 , @xmath76 , and @xmath73 must be known .",
    "these @xmath19 s depend on the subsequences @xmath77 and @xmath78 .",
    "once these four letters are known , the state at time @xmath45 may be determined .",
    "since these letters cast an influence across multiple time steps , their information must be retained in order to accurately forecast the upcoming possibilities for the @xmath19 s and our states .",
    "redefining our states as ( @xmath79 ) preserves the necessary information .",
    "the remaining information for calculating the @xmath19 s needed for the time evolution , mainly @xmath80 and @xmath81 , arise according to the letter probabilities .",
    "these probabilities contribute to the probable time evolution into the next @xmath82 state ( @xmath83 ) .",
    "it can be shown that correlated states must always contain @xmath35 @xmath53-values and @xmath35 letter values , and that uncorrelated states must always contain @xmath35 @xmath53-values .    though the number of elements in a state depends only on the width ,",
    "there exist alternative means of writing our states .",
    "we are free to choose whatever configuration of continuous lines to define our @xmath53-values across .",
    "fig .  [ shapes ] show the other possible configurations in width 2 fwm . naturally , the letter effects differ for each shape , and the proper letters for each configuration are also illustrated .",
    "the various states we may form all contain the same number of @xmath53 and letter values and obey the same principles .",
    "only the specified set of @xmath53 and letter values differ .",
    "the dashed lines represent the various configurations by which the @xmath53-values can be defined .",
    "note that each of the various sets of @xmath53-values implies a different definition of the state , and thus requires a different set of letters .",
    "the arrows represent the letters which are required in each different configuration . ]",
    "whatever state we choose to define , the markov process  describing fwm - lcs is characterized by a transfer matrix @xmath84 .",
    "this matrix describes the transitions from a state in one time to a state in it s immediate future .",
    "it is a representation of the dynamics given by eqs .",
    "( [ eq : h1rec])-([eq : s0def ] ) .",
    "we leave the mechanics of obtaining this transfer matrix to appendix [ sec : howto ] and focus here on the results .",
    "once we have found the transfer matrix we may solve for the vector @xmath85 describing the steady state by solving the linear system of eigenvalue equations @xmath86 subject to the normalization condition @xmath87 where @xmath88 .",
    "note that the size of these vectors depends on the number of states needed to describe the problem .",
    "more specifically , 16 elements are needed for the correlated width 2 fwm while the uncorrelated width 2 case only requires 4 elements .",
    "this steady state vector must contain the probabilities to observe every single state in the random ensemble .",
    "note that the directness of this technique allows for it s ready adaptation to more complex sequence comparison algorithms along the lines of ref .",
    "however , this generally requires a significantly larger number of states thus incurring a greater computational cost .    in order to describe the growth rate , we utilize a growth matrix @xmath89 to mark the transitions which result in growth along some chosen coordinate . the process by which we construct the growth matrix bears great similarity to the process by which we construct the transfer matrix .",
    "in fact , the growth matrix only omits those elements of the transfer matrix that do not contribute to the growth along a chosen coordinate .",
    "further detail regarding the construction of the growth matrix has been left for appendix [ sec : howto ] .",
    "the growth matrix allows us to define the growth vector , @xmath90 @xmath91 this growth vector describes the probable growth from each of the states .",
    "coupled with the steady state , which provides us with the likelihood of each state , this allows us to solve for @xmath59 directly as @xmath92 since the probability of growth from @xmath93 , as described by the growth matrix , is independent of the probability to be in a certain state at time @xmath45 .",
    "before we discuss the results of this approach , we would like to point out that this technique is not limited to the calculation of the growth rate @xmath59 .",
    "since the dynamics of the scores is a markov process , any quantity can be calculated once the transfer matrix @xmath94 and the steady state vector @xmath95 are known .",
    "e.g. , any equal - time correlation function of interest can be obtained directly from the steady - state vector @xmath95 simply by summing over the degrees of freedom that are not to be included in the correlation function while a time - correlation function like @xmath96 ( the probability to be in state @xmath43 at time @xmath45 given that the system was in state @xmath44 at time @xmath97 ) is simply given by @xmath98 where @xmath99 and @xmath100 are vectors , all entries of which are zero except for a one in the row for state @xmath43 or @xmath44 , respectively .    solving the correlated width @xmath36 fwm - lcs problem utilizing the process given by equations ( [ eq : eigen])-([eq : lcs ] )",
    ", we arrive at the equation @xmath101 where @xmath20 represents the probability of the first letter occurring . the same methodology may be applied to the uncorrelated case , where we describe the transition probabilities using the bond probability q defined by equation ( [ eq : q ] ) .",
    "@xmath102 notice that the specifics of the state that we choose does not impact the result in any way .",
    "nor does the choice we make with respect to measuring the growth .",
    "any combination of choices result in equations ( [ eq : lcsc ] ) and ( [ eq : lcsu1 ] ) for the correlated and uncorrelated cases respectively .",
    "we explicitly verified this independence in the choice of configurations and definitions of the growth .",
    "these independent results serve as a powerful check for the correctness of the algebraic manipulations . substituting @xmath103 into equation ( [ eq : lcsu2 ] )",
    ", the probability of getting two different letters , or a bond value of 0 , gives a an equation expressed in the same quantities as the correlated chvtal - sankoff constant given by equation ( [ eq : lcsc ] ) , mainly @xmath104    analytical and numerical data provided by fwm .",
    "this plot shows further evidence verifying the correctness of fwm .",
    "numerical modeling obtained by passing many random sequences through an fwm evaluation produces the data points represented .",
    "the analytical fwm model matches the numerical data with high precision for both the correlated and uncorrelated cases at width @xmath36 .",
    "the error for the numerical data presented is smaller than the symbol size . ]",
    "now , we will apply our method to various small width cases and discuss the implications of the results for the longest common subsequence problem .",
    "first , we check our computations , and plot the results eqs .",
    "( [ eq : lcsc ] ) and  ( [ eq : lcsu2 ] ) alongside numerical data obtained by random sampling in fig .  [ plot ] .",
    "the numerical data obtained by choosing @xmath105 pairs of random sequences of length @xmath105 , calculating their width @xmath106 lcs and averaging shows no discernable deviation from the analytical results over the whole range of the parameter @xmath20 .",
    "already in this plot for @xmath36 , the differences between the correlated and uncorrelated cases are apparent . coinciding only for @xmath107 and @xmath108 where growth is certain in every step ,",
    "the two cases differ at all other points .    [",
    "cols=\"<,<,<\",options=\"header \" , ]     then , we look at the width dependence of the growth rates at the symmetric point @xmath109 . they are summarized in table [ tab : growth ] .",
    "the results again verify the difference between the correlated and uncorrelated cases with the growth rate in the uncorrelated case being systematically higher than in the correlated case .",
    "they also highlight two rather interesting exceptions .",
    "the first occurs for the case @xmath110 in which correlations play no role and indeed have no meaning . assigning a random bond value ( uncorrelated ) or two random letters ( correlated ) lead to the same effect .",
    "thus , as expected , the correlated and uncorrelated cases plot identically for @xmath110 .",
    "the second exception , occurring for @xmath111 , narrows the scope of equality to three values of @xmath20 , namely @xmath112 and @xmath113 . in these cases ,",
    "the equality arises from the exactly similar bond values being produced from each case . in all other respects ,",
    "the correlated and uncorrelated versions of @xmath111 differ .",
    "viewing the solutions of table [ tab : growth ] also shows that the growth rate @xmath1 increases with width @xmath35 .",
    "this agrees with perfectly with the expectations of the fwm . as width increases",
    "so do the possibilities for growth .",
    "in fact , in the limit @xmath114 we recover the chvtal - sankoff constant - the infinite width growth rate . along the way",
    ", these finite width values of @xmath1 provide lower bounds to the chvtal - sankoff constant . in this way",
    ", fwm conveniently provides a method for gathering systematic solutions for obtaining lower bounds to the chvtal - sankoff constant .",
    "the values given for @xmath1 in this table may be read as a series of ever increasing analytically solved lower bounds . in this",
    "systematics , fwm displays one of it s advantages over conventional methods .",
    "however , the power and exactness of these solutions exacts a computational cost that grows as @xmath115 .",
    "finite width growth rates as a function of the letter probability @xmath20 for different widths.,title=\"fig : \" ] finite width growth rates as a function of the letter probability @xmath20 for different widths.,title=\"fig : \" ]    next , we consider the dependence of the growth rates on the letter probability @xmath20 . fig .",
    "[ allwidths ] shows the full analytical solutions for various widths plotted as a function of @xmath20 .",
    "these graphs verify the trend noted from the discussion of table [ tab : growth ] .",
    "however , they allow another interesting observation : while the difference in values in the correlated and uncorrelated cases may be immediately perceived , the shape of each of the curves appears to not depend on @xmath35 . with increasing @xmath35 the curve simply appears to come closer and closer to one . in order to verify this , we rescale the difference @xmath116 of the growth rate from one by its value @xmath117 at @xmath109 . as shown in fig .",
    "[ rescale ] these rescaled curves are indeed indistinguishable for @xmath118 and @xmath119 .",
    "they clearly fall into two distinct classes , namely a curve for the correlated case and a curve for the uncorrelated case . for the uncorrelated case , where the result @xmath120 $ ] for infinite width is known  @xcite , fig .",
    "[ rescale ] also shows perfect agreement between the finite @xmath35 and the infinite @xmath35 results .",
    "thus , at least in the uncorrelated case there are no noticeable finite size effects in the scaling function even for widths as small as @xmath36 . assuming the absence of finite size effects even for small widths also holds true for the correlated case for which we can not independently verify this assumption , the results shown in fig .",
    "[ rescale ] support two important conclusions : ( i ) the correlated and uncorrelated systems truly and systematically differ for all widths and thus also in the limit @xmath121 , and ( ii ) these curve shapes can be understood as universal properties of the correlated and uncorrelated fwm - lcs system independent of the width @xmath35 .",
    "it implies that , given the value of @xmath1 for any @xmath122 or @xmath113 one may plot @xmath1 for all values of p. in other words , a single data point suffices to define a finite width system whether it be correlated or uncorrelated .    rescaled growth rate for @xmath123 in the correlated and uncorrelated case as well as the @xmath124 result for the uncorrelated case .",
    "all results for the correlated case and all results of the uncorrelated case are virtually indistinguishable from each other while the correlated growth rate clearly follows a pattern that is distinctly different from the uncorrelated growth rate . ]",
    "the differences between the correlated and uncorrelated case , highlighted by fig .",
    "[ rescale ] , result from the subtle restrictions that correlations place on bond values . as an example , for width 2 fwm , three bond values contribute to a single transition .",
    "thus @xmath125 unique sets of bond values exist .",
    "uncorrelated bond values allow for any of these @xmath126 possibilities at any given time .",
    "however , because the letters effect correlated bonds in multiple time steps , each correlated state has only @xmath127 allowed transitions .",
    "in fact , in any width the fwm provides a maximum of @xmath127 allowed transitions for all correlated states .",
    "the reasons for this are elucidated in appendix [ sec : howto ] .",
    "in addition to the number of possibilities lacking in the correlated case , the allowed transitions create subtle relationships creating patterns of growth that differ significantly from the uncorrelated case .",
    "these differences account for the systematic separation viewed in fig .",
    "[ rescale ] .",
    "we conclude that within the fwm method differences between the correlated and uncorrelated lcs problem can be established analytically .",
    "the dependence of the finite width growth rate on the letter probability @xmath20 follows a scaling law already for the relatively small widths which are analytically accessible .",
    "these scaling laws are distinctively different for the correlated and uncorrelated case within fwm thereby providing an analytical argument that the differences between the correlated and uncorrelated case explicitly revealed for small finite widths here may persist in the limit of infinite widths .",
    "this is the first piece of analytical evidence that hints at the distinctness of the chvtal - sankoff constants in the correlated and uncorrelated cases .",
    "however , though there exists an analytical solution for the infinite width uncorrelated case , it should be noted that no such solution for the infinite width correlated case is available .",
    "thus this evidence has only been analytically verified for widths up to 5 for correlated finite width systems , and the pattern suggested by this data set may yet be the result of some finite width effect .",
    "nonetheless , the fwm method in itself provides a systematic means to deal with these correlations that can be generalized from the lcs to other sequence comparison problems .",
    "above the four possible futures or transitions available to the state ( 0,0,0,0 ) are obtained diagrammatically .",
    "these transitions , reading from the upper left , are ( 0,0,0,0 ) , ( 1,0,1,0 ) , ( 0,1,0,1 ) and ( 1,1,1,1 ) .",
    "note that the states are organized with h values first , then letters both written in from the top to the bottom in this diagram . in order to help clarify the origin of these four sets of numbers ,",
    "the quantities relevant to the new states have been starred . ]    our transfer matrix , as discussed in the main text , describes transitions from one state into the next .",
    "it allows us to determine the probable fraction of time spent in any state , i.e. the steady state , and coupled with the growth matrix it allows us to calculated the growth rate .",
    "obtaining the matrix elements involves finding all transition probabilities and placing them into our matrix . to begin",
    ", one simply takes a state and writes all possible transitions out of this state . when one has done this for all possible states , then the transfer matrix is complete . as an example",
    "we have calculated the first column of the transfer matrix in the correlated case @xmath36 .",
    "starting with the first column , which represents our ( 0 , 0 , 0 , 0 ) state , we note that there exist only four possible futures .",
    "once we choose the two remaining letters as ( 0 , 0 ) , ( 1 , 0 ) , ( 0 , 1 ) or ( 1 , 1 ) the differences @xmath53 are completely determined .",
    "[ example ] , shows the determination of the state transitions that result from these four sets of letters .",
    "these four transition then become the matrix elements of the first column .",
    "the probability weighing each transition is determined by the new set of letters that bring about the new state , or the starred letters in fig .",
    "[ example ] . in the order listed above , the states they bring about",
    "are weighed by the probabilities @xmath128 , @xmath129 , @xmath130 , and @xmath131 .    in order to formulate a growth matrix",
    ", we pick the line defining the growth , and delete the elements of the transfer matrix which do not contribute to the growth on this line . in this example",
    "we have chosen to measure our growth along the bottom line .",
    "as an example , in fig .",
    "[ example ] , the two top diagrams contribute to growth because the lattice value along the bottom line grows in both these cases .",
    "however , for the bottom pair , the lower lattice value remains static , thus their contributions are missing from the growth matrix shown below .",
    "@xmath132 0 & \\omp p & \\omp p & 0 & 0 & \\omp p & 0 & \\omp p & \\omp p & \\omp p & 0 & 0 & \\omp p & \\omp p & \\omp p & \\omp p \\\\[1 mm ] 0 & \\omp p & \\omp p & 0 & \\omp p & 0 & \\omp p & 0 & 0 & 0 & \\omp p & \\omp p & \\omp p & \\omp p & \\omp p & \\omp p \\\\[1 mm ] 0 & 0 & 0 & \\omp^2 & 0 & 0 & 0 & 0 &   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & p^2 & 0 & p^2 & 0 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] \\omp p & 0 & 0 & 0 & \\omp p & 0 & \\omp p & 0 &   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & \\omp p & 0 & \\omp p & 0 & \\omp p &   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & \\omp^2 & 0 & 0 & 0 & \\omp^2 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 & p^2 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & \\omp p & \\omp p & 0 & 0 & 0 & 0 \\\\[1 mm ] \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\omp p & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\omp^2 & \\omp^2 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & p^2 & 0 & p^2 & 0 & p^2 & 0 & 0 & p^2 & p^2 & p^2 & p^2 & p^2 & p^2 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] \\omp^2 & 0 & 0 & 0 & \\omp^2 & 0 & \\omp^2 & 0 &   \\omp^2 & \\omp^2 & 0 & 0 & \\omp^2 & \\omp^2 & \\omp^2 & \\omp^2 \\end{array }   \\right)\\ ] ]    @xmath133 0 & 0 & \\omp p & 0 & 0 & \\omp p & 0 & \\omp p & 0 & 0 & 0 & 0 & \\omp p & \\omp p & \\omp p & \\omp p \\\\[1 mm ] 0 & \\omp p & 0 & 0 & \\omp p & 0 & \\omp p & 0 & 0 & 0 & 0 & 0 & \\omp p & \\omp p & \\omp p & \\omp p \\\\[1 mm ] 0 & 0 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & p^2 & 0 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & \\omp p & 0 & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & \\omp p & 0 & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & \\omp^2 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 & p^2 & p^2 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & \\omp p & \\omp p & 0 & 0 & 0 & 0 \\\\[1 mm ] \\omp p & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\omp p & \\omp p & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\omp^2 & \\omp^2 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & p^2 & 0 & p^2 & 0 & 0 & 0 & 0 & p^2 & p^2 & p^2 & p^2 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\[1 mm ] 0 & 0 & 0 & 0 & \\omp^2 & 0 & \\omp^2 & 0 & 0 & 0 & 0 & 0 & \\omp^2 & \\omp^2 & \\omp^2 & \\omp^2 \\end{array } \\right)\\ ] ]    99 m. paterson and v. dank _ mathematical foundations of computer science _ ( springer verlag , kosice , slovakia , 1994 ) , p. 127 .",
    "waterman , _ introduction to computational biology _",
    "( chapman & hall , london , uk , 1994 ) .",
    "v. dank , m. paterson , in _ stacs94 .",
    "lecture notes in computer science _ * 775 * ( springer , berlin , 1994 ) , p. 669 .",
    "v. dank , phd thesis , university of warwick , 1994 .",
    "s. karlin , s. altschul , _ proc .",
    "usa _ * 87 * , 2264 ( 1990 ) .",
    "needleman , c.d .",
    "biol . _ * 48 * , 443 ( 1970 ) .",
    "smith and m.s .",
    "waterman , comparison of biosequences , _ adv .",
    "_ * 2 * , 482 ( 1981 ) .",
    "waterman and m. vingron , _ stat .",
    "sci . _ * 9 * , 367 ( 1994 ) .",
    "waterman and m. vingron , _ proc .",
    "_ * 91 * , 4625 ( 1994 )",
    ". s.f . altschul and w. gish , _",
    "methods in enzymology _ * 266 * , 460 ( 1996 ) .",
    "r. olsen , r. bundschuh , and t. hwa , _ proceedings of the seventh international conference on intelligent systems for molecular biology _ ,",
    "t. lengauer _",
    "et al . _ ,",
    "eds . , 211 , aaai press , ( menlo park , ca , 1999 ) .",
    "r. mott and r. tribe , _",
    "biol . _ * 6 * , 91 ( 1999 ) .",
    "r. mott , _",
    "biol . _ * 300 * , 649 ( 2000 ) .",
    "d. siegmund and b. yakir , _ ann .",
    "_ * 28 * , 657 ( 2000 ) .",
    "r. bundschuh , _ phys .",
    "e _ * 65 * , 031911 ( 2002 ) .",
    "d. metzler , s. grossmann , and a. wakolbinger , _ stat .",
    "letters . _ * 60 * , 91 ( 2002 ) .",
    "v. chvtal , d. sankoff , _ j. appl",
    "* 12 * , 306 ( 1975 ) .",
    "hirschberg , _ inf .",
    "lett . _ * 7 * , 40 ( 1978 ) .",
    "v. chvtal , d. sankoff , in _ time warps , string edits , and macromolecules : the theory and practice of sequence comparison _ , edited by d. sankoff and j.b .",
    "kruskal ( addison - wesley , reading , mass . , 1983 ) ,",
    "deken , in _ time warps , string edits , and macromolecules : the theory and practice of sequence comparison _ , edited by d. sankoff and j.b .",
    "kruskal ( addison - wesley , reading , mass . , 1983 ) ,",
    "alexander , _ ann .",
    "_ * 4 * , 1074 ( 1994 ) .",
    "j. boutet de monvel , _ europ .",
    "j. b _ * 7 * , 293 ( 1999 ) .",
    "r. bundschuh and t. hwa , _ disc .",
    "_ * 104 * , 113 ( 2000 ) .",
    "j. boutet de monvel , _ phys .",
    "* 62 * , 204 ( 2000 ) .",
    "r. bundschuh , _ europ .",
    "j. b _ * 22 * , 533 ( 2001 ) .",
    "d. drasdo , t. hwa and m. lassig , _ j. comp . biol . _",
    "* 7 * , 115 ( 2001 ) ."
  ],
  "abstract_text": [
    "<S> sequence comparison is a widely used computational technique in modern molecular biology . in spite of the frequent use of sequence comparisons </S>",
    "<S> the important problem of assigning statistical significance to a given degree of similarity is still outstanding . </S>",
    "<S> analytical approaches to filling this gap usually make use of an approximation that neglects certain correlations in the disorder underlying the sequence comparison algorithm . here , we use the longest common subsequence problem , a prototype sequence comparison problem , to analytically establish that this approximation does make a difference to certain sequence comparison statistics . in the course of establishing this difference we develop a method that can systematically deal with these disorder correlations . </S>"
  ]
}