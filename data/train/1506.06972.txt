{
  "article_text": [
    "forecasting electricity prices is a difficult task as they reflect the actions of various participants both inside and outside the market .",
    "both producers and consumers use day - ahead price forecasts to derive their unique strategies and make informed decisions in their respective businesses and on the electricity market .",
    "high precision short - term price forecasting models are beneficial in maximizing their profits and conducting cost - efficient business .",
    "day - ahead market forecasts also help system operators to match the bids of both generating companies and consumers and to allocate significant energy amounts ahead of time .",
    "the methodology of the current research paper originates from the gefcom 2014 forecasting contest . in last year s contest our team achieved a high ranking position by ensembling multiple regressors using the gradient boosted regression trees paradigm .",
    "promising results encouraged us to further explore potential of the initial approach and establish a framework to compare results with one of the most popular forecasting methods ; armax .",
    "global energy forecasting competition is a well - established competition first announced in 2012 @xcite with worldwide success .",
    "the 2014 edition @xcite put focus on renewal energy sources and probabilistic forecasting .",
    "the gefcom 2014 probabilistic electricity price forecasting track offered a unique approach to forecasting energy price outputs , since competition participants needed to forecast not a single value but a probability distribution of the forecasted variables .",
    "this methodological difference offers more information to stakeholders in the industry to incorporate into their daily work . as a side effect new methods had to be used to produce probabilistic forecasts .",
    "the report contains five sections :    1 .",
    "methods show the underlying models in detail with references .",
    "2 .   data description provides some statistics and description about the target variables and the features used in research .",
    "3 .   experiment methodology summarizes the training and testing environment and evaluation scheme the research was conducted on .",
    "results are presented in a the corresponding section .",
    "conclusions are drawn at the end .",
    "previous experience showed us that oftentimes multiple regressors are better than one@xcite .",
    "therefore we used an ensemble method that was successful in various other competitions : gradient boosted regression trees@xcite .",
    "experimental results were benchmarked using armax ; a model widely used for time series regression .",
    "gbr implementation was provided by python s scikit - learn@xcite library and armax by statsmodels@xcite .",
    "we used armax to benchmark our methods because it is a widely applied methodology for time series regression @xcite .",
    "this method expands the arma model with ( a linear combination of ) exogenic inputs ( x ) .",
    "arma is an abbreviation of auto - regression ( ar ) and moving - average ( ma ) .",
    "arma models were originally designed to describe stationary stochastic processes in terms of ar and ma to support hypothesis testing in time series analysis @xcite . as the forecasting task in question has exogenic inputs by specification",
    "therefore armax is a reasonable candidate to be used as a modeler .    using the armax model ( considering a linear model wrt .",
    "the exogenous input ) the following relation is assumed and modeled in terms of @xmath0 which is the variable in question at the time denoted by @xmath1 . according to this the value of @xmath2",
    "is a combination of @xmath3 ( auto - regression of order @xmath4 ) , @xmath5 ( moving average of order @xmath6 ) and a linear combination of the exogenic input .",
    "@xmath7    the symbol @xmath8 in the formula above represents an error term ( generally regarded as gaussian noise around zero ) .",
    "@xmath9 represents the autoregression submodel with the order of @xmath4 : @xmath10 is the @xmath11-th parameter to weight a previous value .",
    "the elements of the sum @xmath12 are the weighted error terms of the moving average submodel with the order of @xmath6 .",
    "the last part of the formula is the linear combination of exogenic input @xmath13 .",
    "usually @xmath4 and @xmath6 are chosen to be as small as they can with an acceptable error . after choosing the values of @xmath4 and @xmath6 the armax model can be trained using least squares regression to find a suitable parameter setting which minimizes the error .",
    "gradient boosting is another ensemble method responsible for combining weak learners for higher model accuracy , as suggested by friedman in 2000 @xcite .",
    "the predictor generated in gradient boosting is a linear combination of weak learners , again we use tree models for this purpose .",
    "we iteratively build a sequence of models , and our final predictor will be the weighted average of these predictors . boosting generally results in an additive prediction function :    @xmath14    in each turn of the iteration the ensemble calculates two set of weights :    1 .",
    "one for the current tree in the ensemble 2 .",
    "one for each observation in the training dataset    the rows in the training set are iteratively reweighted by upweighting previously misclassified observations .",
    "the general idea is to compute a sequence of simple trees , where each successive tree is built for the prediction residuals of the preceding tree .",
    "each new base - learner is chosen to be maximally correlated with the negative gradient of the loss function , associated with the whole ensemble .",
    "this way the subsequent stages will work harder on fitting these examples and the resulting predictor is a linear combination of weak learners .",
    "utilizing boosting has many beneficial properties ; various risk functions are applicable , intrinsic variable selection is carried out , also resolves multicollinearity issues , and works well with large number of features without overfitting .",
    "the original competition goal was to predict hourly electricity prices for every hour on a given day .",
    "the provided dataset contained information about the prices on hourly resolution for a roughly 3 year long period between 2011 and 2013 for an unknown zone . beside the prices two additional variables",
    "were in the dataset .",
    "one was the forecasted zonal load ( @xmath15 ) and the other was the forecasted total load ( @xmath16 ) .",
    "the first attribute is a forecasted electricity load value for the same zone where the price data came from .",
    "the second attribute contains the forecasted total electricity load in the provider network .",
    "the unit of measurement for these variables remain unknown , as is the precision of the forecasted values .",
    "also , no additional data sources were allowed to be used for this competition .",
    "lrrr & price & forecasted total load & forecasted zonal load + * count * & 25944 & 25944 & 25944 + * mean * & 48.146034 & 18164.103299 & 6105.566181 + * std * & 26.142308 & 3454.036495 & 1309.785562 + * min * & 12.520000 & 11544 & 3395 + * 25% * & 33.467500 & 15618 & 5131 + * 50% * & 42.860000 & 18067 & 6075 + * 75% * & 54.24 & 19853 & 6713.25 + * max * & 363.8 & 33449 & 11441 +    in table [ tab : inpstat ] we can see the descriptive statistic values for the original variables and the target .",
    "the histogram of the target variable ( figure [ fig : p_hist ] ) is a bit skewed to the left with a long tail on the right and some unusual high values . due to this characteristic we decided to take the natural log value of the target and build models on that value .",
    "the model performance was better indeed when they were trained on this transformed target .",
    "the distribution of the other two descriptive variables are far from normal as we can see on figure [ fig : tz_hist ] .",
    "as we can see the shapes are very similar for these variables with the peak , the left plateau and the tail on the right .",
    "they are also highly correlated with a correlation value of ~0.97 , but not so much with the target itself ( ~0.5 - 0.58 ) .",
    "lrrr & * price * & * forecasted zonal load * & * forecasted total load * + * price * & 1.0 & 0.501915 & 0.582029 + * forecasted zonal load * & 0.501915 & 1.0 & 0.972629 + * forecasted total load * & 0.582029 & 0.972629 & 1.0 +    beside the variables of table [ tab : inpstat ] we also calculated additional attributes based on them : several variables derived from the two exogenous variable @xmath15 and @xmath16 , also date and time related attributes were extracted from the timestamps ( see table [ tab : attrs ] for details ) .     _ = 13    ll * variable name * & * description * + dow & day of the week , integer , between 0 and 6 + doy & day of the year , integer , between 0 and 365 + day & day of the month , integer , between 1 and 31 + woy & week of the year , integer , between 1 and 52 + hour & hour of the day , integer , 0 - 23 + month & month of the year , integer , 1 - 12 + t_m24 & t value from 24 hours earlier + t_m48 & t value from 48 hours earlier + z_m24 & z value from 24 hours earlier + z_m48 & z value from 48 hours earlier + tzdif & the difference between t and z + tdif & the difference between t and t_m24 + zdif & the difference between z and z_m24 +    during the analysis we observed from the autocorrelation plots that some variables value have stronger correlation with its + /-",
    "1 hour value , so we also calculated these values for every row .",
    "figure [ fig : autocorr ] shows 3 selected variables to be shifted as the autocorrelation values are extremely high when a lagging window of less than 2 hours is used .",
    " _ = 13    [ fig : autocorr ]    in figure [ fig : autocorr2 ] figure we can see an autocorrelation plot of price values in specific hours and they are shifted in days ( 24 hours ) .",
    "it is clearly seen that the autocorrelation values for the early and late hours are much higher than for the afternoon hours .",
    "that means it is worth to include shifted variables in the models as we did .",
    "not surprisingly the errors at the early and late hours were much lower than midday and afternoon .",
    "gradient boosting regression trees also provided intrinsic variable importance measures .",
    "table [ tab : attrimportance ] shows that ( apart from the original input variables ) the calculated differences were found to be important .",
    "the relatively high importance of the hour of day suggests strong within - day periodicity .    ",
    "_ = 13    lr * attribute * & * gbr variable importance * + tzdif & 0.118451 + tdif & 0.092485 + zdif & 0.090757 + z & 0.090276 + hour & 0.085597 + t & 0.078957 + z_m48 & 0.078718 + t_m48 & 0.076352 + t_m24 & 0.069791 + z_m24 & 0.069072 + doy & 0.067103 + day & 0.056018 + dow & 0.024973 + month & 0.001449 +",
    "in our research framework we abandoned the idea of probabilistic forecasting as this is a fairly new approach and our goal was to gain comparable results with well - established conventional forecasting methods ; armax in this case .",
    "we used all data from 2013 as a validation set in our research methodology ( unlike in the competition where specific dates were marked for evaluation in each task ) . to be on a par with armax we decided to use a rolling window of 30 days to train gbr .",
    "this means much less training data ( a substantial drawback for the gbr model ) , but yields comparable results between the two methods .",
    "the target variable is known until 2013 - 12 - 17 , leaving us with 350 days for testing . for each day",
    "the training set consisted of the previous 1 month period , and the subsequent day was used for testing the 24 hourly forecasts . on some days",
    "the armax model did not converge leaving us with 347 days in total to be used to assess model performance .",
    "the forecasts are compared to the known target variable , we provide 2 metrics to compare the two methods : mean absolute error ( mae ) and root mean squared error ( rmse ) .",
    "gradient boosting and armax optimizes mean squared error directly meaning that one should focus more on rmse than mae .",
    "figure [ fig : rmse_plot ] compares the model outputs with actual prices for a single day . while table [ tab : errors ] shows the descriptive statistics of the error metrics : @xmath17 , @xmath18 , @xmath19 and @xmath20 are the mean absolute errors and root mean squared errors of armax and gbr models respectively .",
    "the average of the 24 forecasted observations are used for each day , and the average of daily means are depicted for all the 347 days . in terms of both rmse and mae",
    "the average and median error is significantly lower for the gbr model ; surpassing armax by approx .",
    "20% on average .    during the evaluation we came across several days that had very big error measures , filtering out these outliers represented by the top and bottom 5% of the observed errors",
    "we have taken a t - test to confirm that the difference between the two models is indeed significant ( @xmath21 , @xmath22 for rmse ) .",
    "lrrrr & mae_p_armax & rmse_p_armax & mae_p_gbr & rmse_p_gbr + count & 347 & 347 & 347 & 347 + mean & 8.640447 & 10.395176 & 7.126920 & 8.496357 + std & 11.809438 & 13.822071 & 10.396122 & 11.627084 + min & 1.223160 & 1.781158 & 1.020160 & 1.302484 + 5.0% & 2.083880 & 2.673257 & 1.439134 & 1.785432 + 50% & 5.152181 & 6.088650 & 3.520733 & 4.144649 + 95% & 27.049138 & 31.339932 & 27.171626 & 31.122828 + max & 101.081747 & 106.317998 & 77.819519 & 83.958518 +      _ = 13    [ fig : rmse_plot ]",
    "the gefcom competition offered a novel way of forecasting ; probabilistic forecasts offer more information to stakeholders and is an approach worth investigating in energy price forecasting .",
    "our efforts in the contest were focused on developing accurate forecasts with the help of well - established estimators in the literature used in a fairly different context .",
    "this approach was capable of achieving roughly 10^th^ place in the gefcom 2014 competition price track and performs surprisingly well when compared to the conventional and widespread benchmarking method armax overperforming it by roughly 20% .",
    "the methodology used in this paper can be easily applied in other domains of forecasting as well . applying the framework and observing model performance on a wider range of datasets yields more robust results and",
    "shall be covered in future work .    during the competition we filtered",
    "the gbr training set to better represent the characteristics of the day to be forecasted , which greatly improved model performance .",
    "automating this process is also a promising and chief goal of ongoing research .",
    "s. a. s. l. aggarwal , `` solar energy prediction using linear and non - linear regularization models : a study on ams ( american meteorological society ) 201314 solar energy prediction contest , '' energy , 2014 .",
    "t. e. a. graepel , `` web - scale bayesian click - through rate prediction for sponsored search advertising in microsoft s bing search engine .",
    ", '' proceedings of the 27th international conference on machine learning , pp .",
    "13 - 20 , 2010 .",
    "ian k. t. tan , poo kuan hoong , and chee yik keong .",
    "2010 . towards forecasting low network traffic for software patch downloads : an arma model forecast using cronos . in proceedings of the 2010 second international conference on computer and network technology ( iccnt 10 ) .",
    "ieee computer society , washington , dc , usa , 88 - 92 .",
    "doi=10.1109/iccnt.2010.35 http://dx.doi.org/10.1109/iccnt.2010.35    gao feng .",
    "liaoning province economic increasing forecast and analysis based on arma model . in proceedings of the 2010 third international conference on intelligent networks and intelligent systems ( icinis 10 ) .",
    "ieee computer society , washington , dc , usa , 346 - 348 .",
    "doi=10.1109/icinis.2010.107 http://dx.doi.org/10.1109/icinis.2010.107    yajun hou .",
    "2010 . forecast on consumption gap between cities and countries in china based on arma model . in proceedings of the 2010 third international conference on intelligent networks and intelligent systems ( icinis 10 ) .",
    "ieee computer society , washington , dc , usa , 342 - 345 .",
    "doi=10.1109/icinis.2010.137 http://dx.doi.org/10.1109/icinis.2010.137    shuxia yang .",
    "the forecast of power demand cycle turning points based on arma . in proceedings of the 2009 second international workshop on knowledge discovery and data mining ( wkdd 09 ) .",
    "ieee computer society , washington , dc , usa , 308 - 311 ."
  ],
  "abstract_text": [
    "<S> energy price forecasting is a relevant yet hard task in the field of multi - step time series forecasting . in this paper </S>",
    "<S> we compare a well - known and established method , arma with exogenous variables with a relatively new technique gradient boosting regression . </S>",
    "<S> the method was tested on data from global energy forecasting competition 2014 with a year long rolling window forecast . </S>",
    "<S> the results from the experiment reveal that a multi - model approach is significantly better performing in terms of error metrics . </S>",
    "<S> gradient boosting can deal with seasonality and auto - correlation out - of - the box and achieve lower rate of normalized mean absolute error on real - world data .    </S>",
    "<S> series , forecasting , gradient boosting regression trees , ensemble models , arma , competition , gefcom </S>"
  ]
}