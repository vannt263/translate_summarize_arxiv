{
  "article_text": [
    "in high - dimensional time series analysis , the need to define time - varying patterns of sparsity in model parameters has proven challenging .",
    "dynamic latent thresholding , introduced in  @xcite , provides a general approach that induces parsimony into time series model structures with potential to reduce effective parameter dimension and improve model interpretations as well as forecasting performance .",
    "the utility of various classes of latent threshold models ( ltms ) has been demonstrated in recent applied studies in macroeconomics  @xcite and financial forecasting and portfolio decisions  @xcite .",
    "the scope of the approach includes dynamic regressions , dynamic latent factor models , time - varying vector autoregressions , and dynamic graphical models of multivariate stochastic volatility , and also opens a path to new approaches to dynamic network modeling  @xcite .",
    "this paper adapts the latent thresholding approach to different classes of multivariate factor models with a one main interest in dynamic transfer response analysis .",
    "our detailed case - study concerns time - varying lag / lead relationships among multiple time series in electroencephalographic ( eeg ) studies . here the latent threshold analysis of such models induces relevant , time - varying patterns of sparsity in otherwise time - varying factor loadings matrices , among other model features .",
    "we evaluate and compare two different classes of models in the eeg study , and explore a number of posterior summaries in relation to this main interest .",
    "time series factor modeling has been an area of growth for bayesian analysis in recent years .",
    "two key themes are : ( i ) dynamic factor models , where latent factors are time series processes underlying patterns of relationships among multiple time series  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) ; and ( ii ) sparse factor models , where the bipartite graphs representing conditional dependencies of observed variables on factors are not completely connected  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , increasingly applied in problems of classification and prediction .    here",
    "we combine dynamics with sparsity .",
    "some of the practical relevance of models with time - varying factor loadings is evident in recent studies  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . as the number of variables and factors increase",
    ", so does the need to induce sparsity in loadings matrices to reflect the view that variables will typically be conditionally dependent on only a subset of factors . in a time series setting , however , the patterns of occurrence of zeros in otherwise time - varying factor loadings matrices may also be time - varying .",
    "one factor may relate to one particular variable with a time - varying loading over a period of time , but be insignificant for that variable in other time periods . thus the need to develop models of time - varying sparsity of loadings matrices in dynamic factor models .",
    "all vectors are column vectors .",
    "we use @xmath0 , @xmath1 , @xmath2 , @xmath3 , @xmath4 , for the normal , uniform , beta , gamma , and wishart distributions , respectively .",
    "succinct notation for ranges uses @xmath5 to denote @xmath6 when @xmath7 e.g. , @xmath8 denotes @xmath9 .",
    "the indicator function is @xmath10 and @xmath11 is the diagonal matrix with diagonal elements in the argument and hence dimension implicit .",
    "elements of any @xmath12vector time series @xmath13 are @xmath14 , @xmath15 and those of any @xmath16 matrix time series @xmath17 are @xmath18 @xmath19",
    "in a general setting , the @xmath20vector time series @xmath21 , ( @xmath22 ) is modeled as @xmath23 where :    * @xmath24 is a @xmath25vector of predictor variables known at time @xmath26 ; * @xmath27 is the @xmath28 matrix of regression coefficients at time @xmath26 ; * @xmath29 is the @xmath30 vector of latent factors , arising from some underlying latent factor process over time ; * @xmath31 is the @xmath32 matrix of factor loadings at time @xmath26 ; * @xmath33 is the residual term , assumed zero - mean normal with diagonal variance matrix @xmath34 of volatilities @xmath35 at time @xmath36    complete specification requires models for @xmath29 , @xmath27 , @xmath31 and @xmath35 over time .",
    "typically , @xmath37 , and models are identified via constraints on @xmath31 , such as fixing @xmath31 to have zeros above a unit upper diagonal : @xmath38 and @xmath39 for @xmath40 in section  [ sec : modelsmandm+ ] , there is interpretable structure to @xmath29 and alternative assumptions are natural . special cases and assumptions now follow .",
    "* constant and sparse factor models : * much past work uses constant coefficients @xmath41 and loadings @xmath42 the pure factor model , with @xmath43 and @xmath44 typically assumes the factors @xmath29 are zero - mean and independent , yielding a linear factor representation of the conditional variance matrix of @xmath45 sparsity in @xmath46 then begins development of more parsimonious models for larger @xmath47  ( e.g. * ? ? ?",
    "* favar models : * when @xmath24 concatenates past values @xmath48 @xmath49 to lag @xmath50 and @xmath51 are constant , the model is a factor - augmented vector autoregression ( favar ) .",
    "variants based on differing models for @xmath29 are becoming of increasing interest in macroeconomics  @xcite .",
    "* factor stochastic volatility models : * traditional bayesian multivariate volatility models have @xmath52 @xmath44 and @xmath53 where @xmath54 model completion involves stochastic volatility model for the @xmath55 and @xmath56 based on either log - ar(1 ) models or bayesian discounting  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* time - varying regression and factor loadings models : * variants of models with time - varying @xmath57 are well - used  ( e.g * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "typically , the elements @xmath58 are ar(1 ) processes . within this class ,",
    "random walk models have flexibility to adapt to change over time , while stationary ar(1 ) models can have longer - term predictive value and interpretation  @xcite .",
    "* process models for factors : * models of factor processes @xmath29 typically involve either conditionally independent factors over time , with or without time - varying conditional variances , or stationary vector autoregressive ( var ) models .",
    "we highlight example models that incorporate elements noted in section  [ sec : dfms ] , while being customized to the eeg study : a response variable is hierarchically linked to current and lagged values of an underlying latent process of scientific interest .",
    "a first latent factor model is discussed , then extended with a time - varying vector autoregressive component ; these two models are customized examples of time - varying favar processes .",
    "a dynamic transfer response factor model ( dtrfm ) relates the outcome variables to a foundational , scalar latent process @xmath59 by specifying @xmath29 to be a vector of recent values of this underlying scalar process .",
    "each outcome variable relates to potentially several recent and lagged values of @xmath59 through time - varying loadings coefficients ; at any instant in time , these coefficients define the transfer response of the variable to the history of the underlying process . as the loadings vary in time",
    ", the form of this response then naturally varies .",
    "the basic structure of the model is described here .    in , set @xmath43 for all @xmath36 suppose also that @xmath60 for some @xmath61 where the scalar series @xmath59 is modeled as a time - varying autoregressive ( tvar ) process of order @xmath62 .",
    "that is , @xmath63 where @xmath64 is the vector of ar coefficients at time @xmath36 conditional on the variance elements @xmath65 and @xmath66 , the @xmath33 , @xmath67 and @xmath68 sequences are assumedly independent over time and mutually independent .",
    "equation  ( [ eq : delta ] ) indicates that the @xmath69 coefficients follow a vector random walk over time , permitting time variation but not anticipating its direction or form .",
    "coupled with we have the traditional specification of a bayesian tvar@xmath70 model for the latent @xmath59 process .    for the @xmath71 scalar response variable , the above model implies @xmath72 showing the transfer of responses from past values of @xmath59 via the possibly quite widely time - varying loadings @xmath73 , the latter specific to series @xmath74 for each @xmath75    model identification is straightforward . from  , it is clear that an identification problem exists with respect to the lag / lead structure , i.e. , the time origin for the latent @xmath59 process , as well as the scale of @xmath59 relative to the @xmath76 fixing elements of one row of @xmath31 to specified values obviates this .",
    "here we do this on the first row : for one factor ( lag ) index @xmath77 we set @xmath78 and @xmath79 for @xmath80 this way , @xmath81 is a direct , unbiased measurement of @xmath82 , subject to residual noise , so that we have formal identification and a quantitative anchor for prior specification .    beyond the need for priors for model hyper - parameters ,",
    "we need structures for the error volatility processes @xmath83 in and the tvar innovations variance process @xmath84 in . for routine analysis that is not inherently focused on volatility prediction , standard bayesian variance discount learning models effective",
    "random walks whose variability is controlled by a single discount factor are defaults .",
    "specified to describe typically slowly , randomly changing variances , the inverse gamma / beta bayesian model has the ability to track time - varying variances over time , and to deliver full posterior samples from relevant conditional posteriors for volatility sequences in mcmc analyses .",
    "we use variance discount models here , based on standard theory in , for example ,  @xcite and  @xcite ; these are simply specified via two discount factor hyper - parameters : @xmath85 , for each of the set of observation volatilities , and @xmath86 for the tvar innovations volatility .",
    "substantive interpretation is aided by investigating the more detailed structure that theoretically underlies the latent tvar process @xmath87 specifically , well - known ( and well - exploited ) time series decomposition theory  ( e.g * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) shows that , given the model parameters , the @xmath59 series has the decomposition @xmath88 where the @xmath89 are simpler  component time series processes and @xmath90 are non - negative integers such that @xmath91 the values of these integers and the nature of the component processes depend on the model parameters @xmath69 . typically , slow variation over time in these yields stable numbers @xmath90 and the resulting processes are computable directly from ( posterior samples or estimates of ) the @xmath59 and @xmath92 the component processes @xmath93 have the ( approximate ) forms of time - varying autoregressive moving averages ",
    "tvarma(2,1 ) processes exhibiting quasi - periodic behavior : each @xmath93 is a stochastic sine wave whose amplitude , phase and frequency varies in time ; the time variation in frequency is directly related to that in @xmath69 , while the amplitude and phase variation is inherent and driven by the levels of variation controlled by @xmath94 further , posterior inferences for the time - varying frequencies , amplitude and phase are directly available from posterior simulations that generate samples of the @xmath59 and @xmath69 at each time . in parallel , each @xmath95 is a tvar(1 ) process , with time variation in short - term autocorrelations driven by that in @xmath69 . as with the @xmath96 we have direct access to posterior inferences on the tvar(1 ) parameters of these component processes from simulations of the posterior for @xmath97 at each time .",
    "this decomposition therefore gives inferences on underlying time - frequency and short - term dependency structures underlying @xmath59 and its dynamic behavior .    from it",
    "follows that @xmath98 where , for each @xmath99 in the ranges displayed , @xmath100 thus the transfer response pattern defined by the time - varying factor loadings translates the nature of the inherent , underlying components of the driving ",
    "@xmath59 process to each of the output / response variables .",
    "the above shows that this class of models provides broad scope for capturing multiple time - varying patterns of component structure including several or many components with dynamically varying time - frequency characteristics via a single latent process filtered to construct the latent factor vector process @xmath29 in the general framework .",
    "the flexibility of these models for increasingly high - dimensional response series @xmath101 is then further enhanced through the ability of models with series - specific and time - varying loadings @xmath73 to differentiate both instantaneous and time - varying patterns in the transfer responses .",
    "a direct model extension adds back a non - zero dynamic regression term to provide an example of time - varying favar models .",
    "that is , with the dynamic factor component as specified via model m ,",
    "suppose @xmath101 now follows where @xmath102 the @xmath103 matrix @xmath27 contains time - varying autoregressive parameters and @xmath104 that is , @xmath101 is dynamically regressed on the immediate past value @xmath105 as well as the underlying components of a driving latent process through the dynamic transfer response mechanism : we denote this as a tv - var(1 ) component of the model .",
    "this extension of model m allows for the transfer response effects of the fundamental , driving @xmath59 process to be overlaid with spill - over effects between individual response series from one time point to the next , modeled by a basic tv - var(1 ) component .",
    "this can be regarded as a model extension to assess whether the empirical tv - var component is able to explain structure in the response data not adequately captured by the structure dynamic factor component .",
    "for increasingly large @xmath106 the tv - var(1 ) model component alone ( i.e. , setting @xmath107 implies what can be quite flexible marginal processes for the individual @xmath108 in contrast , the dynamic transfer response factor component while also quite flexible represents structurally related processes .",
    "there is thus opportunity to for evaluation of the latter in the extended model m+ .",
    "as the dimension @xmath109 of response variables and the number @xmath110 of effective latent factors increases , it becomes increasingly untenable to entertain models in which all loadings in @xmath31 are non - zero .",
    "further , depending on context , it is also scientifically reasonable to entertain models in which one or more variables may relate in a time - varying manner to a particular element of the latent factor vector for some periods of time , but that the relationships may be practically negligible at other epochs .",
    "this is the concept of dynamic sparsity : a particular @xmath73 may be non - zero over multiple , disjoint time periods , and adequately modeled by a specified stochastic process model when non - zero , but effectively zero in terms of the effect of @xmath111 on @xmath112 in other periods .",
    "the same idea applies to dynamic regression and/or autoregressive parameters in @xmath113 analysis that permits this will allow for adaptation over time to zero / non - zero periods as well as to inference on actual values when non - zero .",
    "this includes extreme cases when a @xmath73 may be inferred as effectively zero ( or non - zero ) over the full time period of interest .",
    "dynamic latent thresholding  @xcite addresses this question of _ time - varying sparsity _ in some generality ; this approach is now developed in our context of dynamic transfer response factor models .",
    "we anchor the development on basic ar(1 ) process models for the free elements of the dynamic factor loadings matrix @xmath114 recalling that the first row of elements is constrained to fixed ( 0/1 ) values as noted in section  [ subsec : dtrfm ] . for @xmath115",
    "the @xmath73 are modeled via what we denote by the lt - ar(1 ) processes defined as follows : @xmath116 where the latent process @xmath117 is ar(1 ) with @xmath118 and where @xmath119 the processes are assumed independent over @xmath120 the latent threshold structure allows each time - varying factor loading to be shrunk fully to zero when its absolute value falls below a threshold @xmath121 .",
    "this way , a factor loads in explaining a response only when the corresponding @xmath117 is `` large enough '' .",
    "inference on the latent @xmath117 processes and threshold parameters make this data - adaptive , neatly embodying and yielding data - informed time - varying sparsity / shrinkage and parameter reduction .",
    "the same approach applies to the time - varying autoregressive parameters in the extension to model m+ .",
    "that is , the effective model parameters @xmath122 are modeled as thresholded values of ar(1 ) processes @xmath123 in precisely the same way as for the @xmath76 details are left to the reader as they follow the development for @xmath31 with simple notational changes",
    ".      it will be evident that prior specification for threshold parameters @xmath121 are key in defining practical models .",
    "we can do this by referencing the expected range of variation of the corresponding @xmath117 process . under the ar(1 ) process model detailed above",
    ", @xmath117 has a stationary normal distribution with mean @xmath124 and variance @xmath125 given the hyper - parameters @xmath126 this allows us to compute the probability that @xmath117 exceeds the threshold i.e. , the probability of a practically significant coefficient across any range of possible thresholds .",
    "@xcite follow this logic to specify informative , structured priors for @xmath121 that depend explicitly on @xmath127 we use this specification here ; in particular , take conditional uniform priors @xmath128 for some @xmath129 direct evaluation then yields marginal ( with respect to @xmath121 ) sparsity probabilities @xmath130 where @xmath131 is the standard normal cdf .",
    "this is trivially evaluated . for large @xmath132 , this is also very well approximated by @xmath133 ( this is extremely accurate for @xmath132 as low as 2 and practically relevant values of @xmath132 exceeding that ) .",
    "the sparsity probability strictly decreases in @xmath132 and decays to values of about 0.25 , 0.20 and 0.15 , respectively , at about @xmath134 and 5.3 , respectively .",
    "this gives us assessment of what a particular choice of @xmath132 implies in terms of overall expected levels of sparsity _ a priori_. in our studies , we find strong robustness in posterior inferences to specified values of @xmath132 above 3 or so , and use that value as a default .",
    "note also that there is flexibility to customize the prior to use different @xmath132 values for each threshold , to cater for contexts in which we aim to favor higher thresholds ( and hence higher probabilities of zero parameter process values ) for some @xmath135 than for others .",
    "mcmc computations extend and modify those developed for time - varying autoregressions and multivariate stochastic volatility factor models in  @xcite .",
    "the overall mcmc integrates a series of steps that use standard simulation components from bayesian state space models  ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) and from traditional ( static loadings ) latent factor models  @xcite .",
    "customization here involves modifications to resample the latent tvar factor process in our dynamic transfer responses factor context , and other elements including metropolis hastings steps as in  @xcite for the latent threshold components .",
    "the appendix accompanying this paper describes key details , and notes how the mcmc directly extends previously described strategies for dynamic latent threshold models .",
    "electroencephalographic ( eeg ) traces are time series of electrical potential fluctuations at various scalp locations of a human subject , reflecting the complex dynamics of underlying neural communication .",
    "analysis of multichannel eeg traces is key to understanding the impact of electroconvulsive therapy ( ect ) , one of the most effective treatments known for major depression with electrically induced seizures in patients  @xcite .",
    "the convulsive seizure activity drives multichannel eeg traces and statistical interest is to model such multivariate time series in order to reveal underlying characteristics and effects of ect .",
    "various models have been studied to explore features of eeg time series  ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "univariate tvar models are well - used and proven as models of individual eeg channels  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) ; they can adequately represent what can be considerable changes in the patterns of evolution of time - frequency structure in such series , as well as differences and changes in relationships across the eeg channels .",
    "such studies highlight the need for multivariate models of the time - varying commonalities across channels , with latent process structure reflecting the inherent , underlying mechanisms of neural communication .",
    "our analysis adapts the earlier approach of  @xcite .",
    "that work was the first bayesian approach to multivariate time series analysis that incorporated the key scientific feature of a single , focal latent process driving  the eeg signals across multiple channels .",
    "the authors used a novel dynamic distributed lag approach that aimed to capture time - varying lag - lead structures across the eeg channels , introducing a customized model specific to that context .",
    "though effective , that approach was very specific and empirical the authors developed dynamic regressions of @xmath136 of the channels on the _ observed signal _ of one selected channel , the latter chosen as an empirical proxy for the underlying latent driving process @xmath87 the developments of the current paper provide a general , flexible and in terms of the specific goals of the dynamic lag / lead study almost perfectly suited context that can be seen , in part , as an outgrowth from that prior work . here",
    "the identification of dynamically adaptive lag / lead structure is driven by combining time variation in non - zero factor loadings with the latent threshold approach .",
    "the study here explores @xmath137-channel eeg times series recorded in one seizure of one patient , as reported and earlier analyzed in  @xcite and @xcite .",
    "the eeg channels are @xmath137 electrodes located around and over the patient s scalp ; see figure  [ fig : map ] .",
    "the original data set has sampling rate 256hz over a period of 1 - 2 minutes ; following and to compare directly with  @xcite , we analyze the series subsampled every sixth observation after removing about 2,000 observations from the beginning ( up to a higher amplitude portion of the seizure ) yielding @xmath138 observations .",
    "representative graphs of data on two of the channels over selected epochs appear in figure  [ fig : eegdata ] .",
    "visual inspection of the substantial time - varying , quasi - periodic trajectories of the data indicates that signals on some eeg channels are obviously delayed  with respect to other channels , and the apparent delays ( lags ) vary substantially through time .",
    "this is perfectly consistent with the dynamic patterns of relationships of individual channels ( the @xmath139 with an underlying seizure process ( the latent @xmath59 ) captured by our model structure ( section  [ subsec : dtrfmcomps ] ) ; the latent @xmath59 process represents a range of dynamic quasi - periodicities characterizing multiple brain wave components overlaid by , and modified by , the induced seizure , and the time - varying lag / lead relationships among channels are represented by channel - specific and time - varying factor loadings , some of which may be negligible for all time or for periods of time , and relevant elsewhere .",
    "series are measurements of electrical potential fluctuations taken in parallel at each of these locations , defining the eeg channels ( international 10 - 20 eeg system).,width=192 ]     +      our analysis summaries are based on @xmath140 effective lags , i.e. , the model has a @xmath141dimensional latent factor vector @xmath142 and the first row of @xmath31 set to @xmath143 as the basis for model identification .",
    "this precisely parallels the setup in the empirical model of  @xcite .",
    "as discussed in section  [ subsec : dtrfm ] , some constraints of this form are needed on elements of @xmath31 to formally identify the single latent factor process model . there is no loss of generality nor any superfluous structure imposed on the model here ; we could choose any element of the first row of @xmath31 to insert the 1 , with different choices simply shifting the implied time origin of the @xmath59 process . under this structure ,",
    "the first eeg channel @xmath81 loads only @xmath144 , while the other channels have loadings in the first ( last ) two columns of @xmath31 related to the leading ( lagged ) values of the @xmath59 process .",
    "our analysis takes the so - called vertex channel cz as series @xmath145 .",
    "see figure  [ fig : map ] .",
    "this parallels the use of the observed data on this specific channel as an empirical factor process in  @xcite .",
    "the other channels are ordered from the centre out .",
    "one further modeling detail relates to a modification for a further , subtler soft  identification question .",
    "the model so far implies that @xmath146 so the conditional variation expected in channel 1 is the sum of time - varying contributions from the @xmath59 process plus @xmath147 as in all state - space models with multiple components contributing to variability in observed data , distinguishing and partitioning the contributions requires care in prior specification ; the picture is complicated here as time variation in @xmath148 competes  with the intricate dynamics of the @xmath69 and time variation in @xmath84 .",
    "a specification that controls this more usefully in the current latent factor models is to fix as constant the measurement error in series 1 , i.e. , set @xmath149 constant over time .",
    "this ensures the interpretation of @xmath150 as pure measurement error ( there being no reason to expect time variation in pure measurement error variances , as opposed to the characteristics of the underlying factor processes and transfer response / loadings parameters ) .",
    "we do this , maintaining the stochastic variance discount model for the other @xmath151 @xmath152 the latter combine pure measurement error and any other identified changes in residual volatility across these channels .",
    "then , posterior inferences indicating substantial patterns of time variation in the latter then indicate the ability of the discount models to account for relative variability not captured by the underlying , identified latent factor process . the mcmc analysis of section  [ sec : computation ] is trivially modified ; a traditional inverse gamma prior on @xmath153 leads to an inverse gamma complete conditional posterior .",
    "the analyses summarized are based on model order @xmath154 for the latent @xmath59 process . while formal order selection approaches could be entertained  ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , our philosophy based on applied work with tvar and related models in many areas is to fit successively larger models and assess practical relevant of resulting inferences .",
    "here we fit the dtrfm with model orders up to @xmath155 and for each analysis examine the posterior estimates of components @xmath156 as detailed in section  [ subsec : dtrfmcomps ] . with successively higher values of model order @xmath157",
    "we find robust estimation of @xmath158 quasi - periodic components with estimated frequencies varying over time in ranges consistent with known ranges of seizure and normal brain wave activity .",
    "model order @xmath154 is needed to identify these three components , and they persist in models of higher order ; in addition to their substantive relevant , the estimated components are sustained over time and vary at practically relevant levels in terms of their contributions to each of the eeg series . however , moving beyond @xmath154 leads to increasing numbers of estimated components that are very ephemeral , of low amplitudes and higher inferred frequencies beyond the range of substantive relevance .",
    "this signals over - fitting as the model caters to finer aspects of what is really noise in the data .    and",
    "then disregarding such estimated noise components is certainly acceptable , we prefer to cut - back to the model order @xmath154 that identifies the main component structures without these practically spurious  elements .    model specification is completed with priors for hyper - parameters .",
    "we take @xmath159 , supporting a range of values for @xmath160 and with prior mean for @xmath160 near 4.5 .",
    "seizure eeg data typically range over 300 - 600 units on the potential scale , with sample standard deviations over selected epochs varying from 40 - 100 or more .",
    "hence an expectation of measurement error standard deviation around 4 - 5 is consistent with prior expectations that measurement error constitutes in the range of 4 - 12% of the signal uncertainty in the traces . for the stochastic discount variance models ,",
    "we set values of the discount factors as @xmath161 ; this is based in part on examination of analyses with various values , and consistent with relatively modest levels of volatility in variance components .",
    "priors for the hyper - parameters of the latent ar(1 ) parameter processes are as follows : @xmath162 , @xmath163 , and @xmath164 independently , for @xmath165 .",
    "this anticipates persistence in non - thresholded latent factor loadings , while allowing for some of the loadings to exhibit notable patterns of change . finally , we take @xmath166 and set @xmath167 in the conditional uniform priors for thresholds .",
    "summaries here come from @xmath168 mcmc draws after a burn - in period of @xmath169 .",
    "computations were performed using custom code in ox  @xcite .",
    "figure [ fig : factor ] displays time trajectories of the posterior means of the factor process @xmath59 , and the volatility @xmath170 of its driving innovations . the figure displays similar trajectories for the time - varying characteristic frequency and modulus for each of the three identified quasi - periodic components in @xmath59 , the @xmath171 of section  [ subsec : dtrfmcomps ] .",
    "the @xmath171 component of lowest frequency has oscillations in the so - called seizure  or slow wave  band , considerably decaying toward the end of the seizure episode .",
    "notably , the other two inferred components have characteristic frequencies and moduli that are rather stable over time though exhibit minor variation .    .",
    ", width=480 ]    .",
    ", width=480 ]    the frequency trajectories of the three quasi - periodic components show that each lies in one of the expected neuropsychiatric categories : the so - called _ delta _ band ( roughly 0 - 4hz ) , _ theta _ band ( 4 - 8hz ) , and _ alpha _ band ( 8 - 13hz )  @xcite .",
    "each component process @xmath171 is defined by the corresponding characteristic frequency , while being broad - band in the spectral domain with time - varying spectra that can be understood to peak at the characteristic frequencies themselves .",
    "the lowest - frequency component stays in the _ delta _ range and gradually decreases over time ; its modulus is close to one ( solid line in figure [ fig : factor](iv ) ) , which indicates a considerably persistent component ; this so - called delta - slow wave dominates the factor process during the course of the seizure , while its frequency content slides towards lower values towards the end of the seizure episode .",
    "the other two quasi - periodic components lie in the _ theta _ and _ alpha _ ranges ; their moduli and amplitudes are lower than those of the dominant component over the whole seizure course , and show only limited changes over time .",
    "these reflect known frequency ranges of normal brain signaling , being dominated through much of the period by the strong seizure waveform .",
    "the innovations volatility rises in the initial part of the seizure to drive increased amplitude fluctuations throughout the central section , and then decays in later stages corresponding to the control and dissipation of the brain seizure effects .",
    "these features are consistent with expected structure in the seizure process , and with the broad results of  @xcite .",
    "figure [ fig : tvar ] provides the trajectories of the posterior means and 95% credible intervals for the tvar coefficients @xmath172 .",
    "all are markedly time - varying .",
    "the 95% credible intervals are slightly wider during the late time periods , which feeds through to increased uncertainties in features of the quasi - periodic components ; figures [ fig : factor](v ) and ( vi ) , displaying the posterior means and 95% credible intervals of the frequency and modulus for the lowest - frequency component respectively , showing somewhat increased uncertainties towards the end of the seizure .     for channel f7 , index @xmath173 , indicating the inferred probabilities of lag - lead structure in transfer response to @xmath59 as they vary over time.,width=480 ]    to generate some insights into the nature of dynamic sparsity under the latent threshold model , we select one channel f7 at @xmath173, and plot the corresponding trajectories of the estimated posterior probabilities @xmath174 over time ; i.e. , the probability of a non - zero loading of channel f7 on each of the values @xmath175 for @xmath176 see figure  [ fig : s ] where we indicate the loadings on @xmath177 by lead(@xmath178 ) and ( @xmath179 ) respectively , that on @xmath144 by sync , and those on @xmath180 by lag(@xmath181 ) and ( @xmath182 ) respectively .",
    "the annotation here refers to lead / lag relative to the vertex location cz that reads - out an unbiased estimate of @xmath144 .",
    "so a non - zero loading of f7 on @xmath59 , for example , defines a 2-period lead of that channel relative to the vertex , whereas a non - zero loading on @xmath183 represents a 1-period lag relative to the vertex channel cz , and so forth . from the figure",
    ", it is clearly inferred that there is strong synchrony between f7 and cz in their transfer responses to fluctuations in @xmath59 based on the sync trajectory .",
    "also , f7 also has a reasonable probability of responding to the latent factor process @xmath59 1-period ahead of cz , and almost surely does not lag cz in the transfer response over most of the time period , nor lead by more than 1 period until perhaps later in the seizure episode .",
    "the ability of latent thresholding to adaptively indicate existence of non - zero loadings during some periods and not others , while also operating as a global  variable selection mechanism as well , is nicely exemplified here .",
    "figure  [ fig : st ] provides a visual display of posterior probabilities @xmath174 across all the channels @xmath184 , and drawn at selected snapshots in time , with images created by linearly interpolating between the estimates at the electrode locations .",
    "note that the model says nothing about spatial relationships between channels .",
    "the marked patterns of shrinkage in the latent threshold model analysis does nevertheless indicate strong spatial relationships , while the relationships also show marked patterns of change over time .",
    "for example , loadings of lead(+2 ) are commonly and globally shrunk to zero from left frontal to right occipital sites . the lead(+2 )",
    "loadings around right frontal and prefrontal areas exhibit evolving degree of shrinkage .",
    "similar changes are found in the parietal and occipital regions of lag(-2 ) loadings .",
    "meanwhile , almost no shrinkage is found in the synchronized loadings except for the channel t3 ( left temporal ) .",
    "interpolating from values at the channels @xmath185 each row corresponds to the values at a selected time point , and the columns represent the indices @xmath186 in relation to the transfer responses to @xmath175 for @xmath176,width=480 ]     with the lag - lead structure at selected time points .",
    "the row - column layout of images corresponds to that in figure  [ fig : st ] .",
    ", width=480 ]    figure  [ fig : beta ] is a companion to figure  [ fig : st ] that exhibits aspects of estimated factor loadings with the lag - lead structure at selected time points .",
    "the images represent estimates @xmath187 where @xmath188 if @xmath189 and zero otherwise .",
    "recall that the factor loading of vertex channel cz is fixed at 1 for the basis and 0 for lagged / leaded times .",
    "the estimates show strong patterns of positive spatial dependencies with cz at the synchronized state ( zero lag / lead ) , with concurrent loadings on the @xmath59 process decaying towards the exterior regions .",
    "the approximate centroid of the higher loadings region moves from front to back through the course of the seizure , consistent with what is understood to be the typical progression of seizure waveforms  @xcite . in the third row of the figure ( @xmath190 ) , the highest loadings appears at and near channel pz , and the parietal region exhibits rising intensity .",
    "another higher intensity is detected around the right temporal area in lead(+2 ) and in the channel c4 in lead(+1 ) .",
    "this indicates dynamics of the driving latent process exhibited earlier in right temporal / central areas and followed in the occipital region ; this spatial asymmetry in estimated transfer response loadings again links to experimental expectations for the progression of seizure activity . in the last row of the figure ( @xmath191 , a late stage of the seizure ) , the major lead / lag loadings diminish while the synchronized loadings persist .",
    "two animated figures , available as online supplementary material , provide more insight into the patterns of variation over time in factor loadings , the differences across channels , and the nature of the dynamic latent thresholding in particular .",
    "the first animation http://www.stat.duke.edu/~mw/.downloads/nakajimawest2016eeg/animate-st.avi[(linked at the external site here ) ] shows a movie of patterns of @xmath174 interpolating from values at the channels @xmath185 this shows how these patterns evolve over time @xmath26 , providing a dynamic display from which the snapshots in figure  [ fig : st ] are selected at four specific times .",
    "the second animation http://www.stat.duke.edu/~mw/.downloads/nakajimawest2016eeg/animate-betat.avi[(linked at the external site here ) ] shows the corresponding movie for the interpolated estimates of factor loadings @xmath192 over all time ; the snapshots in figure  [ fig : beta ] are selected at four specific times .",
    "the animations clearly show and highlight regions of the brain surface where there is very low or negligible probability of lag or lead effects of the @xmath59 process , other regions where sustained effects are very evident and regions in which there is more uncertainty about potential effects , together with inferences on the quantified lag / lead effects in terms of the temporal evolution of the spatial patterns in estimated factor loadings .",
    "figure  [ fig : sigma ] plots @xmath193 i.e. , estimated standard deviations of the idiosyncratic shocks in each channel @xmath185 each graph is roughly located at the corresponding electrode placement .",
    "recall that @xmath194 , the innovation standard deviation for the channel cz , is assumed time - invariant , representing measurement error only , as part of the model specification to define and identify the latent driving process @xmath59 .",
    "the model allows for potential variations over time in standard deviations at other channels , with opportunity to identify variability in the data not already captured through the time - varying loadings and latent process structure .     across all channels",
    "@xmath185 for clarity in presentation , the y - scale has been omitted ; each standard deviation is graphed on the scale of @xmath195 for comparability across channels .",
    "recall that the anchor channel cz has constant standard deviation representing pure measurement error around the latent process at that channel .",
    "each graph is roughly located at the corresponding electrode placement and the @xmath196-axes represent the full time period @xmath197.,width=307 ]    from figure  [ fig : sigma ] , there do appear to be variations across channels and they show some local spatial dependence .",
    "trajectories of the neighboring channels f4 and f8 are clearly similar , exhibiting a major hike in the middle of the seizure .",
    "it is evident that some parietal and occipital sites ( t3 , p3 , o1 , o2 and p4 ) share a common trajectory , which marks a peak in an early stage of the seizure then gradually decrease towards the end of the seizure . as seen in figures  [ fig : st ] and [ fig : beta ] , these sites also share some relationships in the latent threshold - induced shrinkage and loadings at lag(-1 ) .",
    "further , the estimate shows similarities among the channels pz , c4 and t6 , whose patterns differ from those in the occipital region .",
    "this suggests an intrinsic difference between the central sites ( pz , c4 and t6 ) and the occipital sites ( t3 , p3 , o1 , o2 and p4 ) , also suggested by figures  [ fig : st ] and [ fig : beta ] . across all but the vertex channel @xmath198 at @xmath199 the idiosyncratic error terms @xmath200",
    "represent a compound of measurement error and of additional patterns including local sub - activity of the seizure that is not explained by the latent factor process .",
    "there are also experimental and physiological noise sources that are likely to induce local / spatial residual dependencies in the data not forming part of the main driving process @xmath201 including electrical recording / power line noise and scalp - electrode impedance characteristics ; these presumably also contribute to the time - variation patterns in the @xmath83 identified and their spatial dependencies .",
    "model m+ has @xmath202 where @xmath27 is the @xmath103 matrix of lag-1 time - varying coefficients modeled using latent threshold ar(1 ) processes .",
    "model m+ extends model m to potentially capture data structure not fully explained by the factor and residual component .",
    "one interest is to more structurally explain the time variation in estimated residual volatilities @xmath83 exhibited in the analysis of the baseline model m. a contextual question is that of representing potential spill - over  effects between eeg channels as the seizure waves cascade around the brain ; that is , local ( in terms of the neural network and perhaps in part , though not necessarily , physically spatially ) transmission of signals between subsets of channels that represent delayed responses to the latent @xmath59 process not already captured by the dynamic latent factor model form .",
    "the matrix @xmath27 is expected to be sparse and modeled via latent threshold dynamic models , as earlier described .     across all channels @xmath184 for the extended model m+ .",
    "details as in as in figure  [ fig : sigma ] for model m.,title=\"fig:\",width=480 ] +   across all channels @xmath184 for the extended model m+ .",
    "details as in as in figure  [ fig : sigma ] for model m.,title=\"fig:\",width=480 ]    .4 in     across all channels @xmath184 for the extended model m+ .",
    "details as in as in figure  [ fig : sigma ] for model m.,width=307 ]    figure [ fig : at ] plots the posterior means of the states @xmath203 and the posterior probabilities @xmath204 , where @xmath205 and @xmath206 is the latent threshold for each state @xmath207 .",
    "the matrix @xmath27 is evidently sparse and exhibits considerable changes in the state and the posterior shrinkage probability among the selected time points .",
    "figure [ fig : sigma - var ] shows the estimated standard deviations of the idiosyncratic shocks @xmath208 .",
    "compared with figure [ fig : sigma ] , the trajectories of standard deviations are generally somewhat smoother over time ; some of the variation in the data not already captured by the @xmath209 is now absorbed by the @xmath210 .    to explore some practical implications of the extended model m+ and compare with the baseline model m",
    ", one aspect of interest is predicted behavior of the time series based on _ impulse response analysis _ relative to the underlying @xmath59 process . standing at a current , specified time @xmath211",
    "this simply asks about the nature of expected development of the series @xmath212 over the next @xmath213 time points based on an assumed level of the impulse ",
    "@xmath214 to the driving innovations of the latent process . in applied work in economics ,",
    "impulse responses are often primary vehicles for communicating model implications , comparing models , and feeding into decisions .",
    "the use of latent thresholding in macroeconomic models has focused on this , in part , and clearly demonstrated the utility of dynamic latent thresholding in inducing more accurate predictions and , in particular , more statistically and substantively reliable impulse response analyses  @xcite .",
    "we do this here from three time points @xmath215 chosen in the early , middle and later sections of the eeg series ; this exhibits differences in the model projections / implications over time due to the dynamics , as well as differences between the two models in each of these periods .",
    "computations are easily done by using the posterior mcmc samples to project forward in time ; predictive expectations are then computed as monte carlo averages .",
    "the impulse value @xmath216 is taken as the average over @xmath217 of the estimated historical innovations standard deviations @xmath218 . figure  [ fig : imp ] plots the impulse responses of the 19 eeg channels with @xmath219 and from each of the two models .",
    "note that , for our comparison purposes here , we are interested in the _ forms _ of the impulse responses over the horizon specified , not their specific values .",
    "we already know that the innovations variance @xmath84 shows marked changes over time and , in particular , decays to rather low values in the later stages of the seizure .",
    "hence the shock size @xmath216 taken here is larger than relevant and realized innovations over the latter part of the time period , and the amplitudes of impulse responses should therefore not be regarded as pertinent .",
    "the form of the projections are the focus .",
    "\\(i ) model m +   eeg channels to a shock to the underlying factor process @xmath59 obtained from ( i ) model m , ( ii ) model m+ . the impulse response functions computed at three different time points throughout the seizure are shown ( columns ) . for each model ,",
    "the impulse response projections are made from the time point indicated by column header up to 80 time periods ahead ( lower rows in ( i ) and ( ii ) ) ; the same responses are shown on a truncated time period up to only 30 time periods ahead ( upper rows in ( i ) and ( ii ) ) , for clarity.,title=\"fig:\",width=364 ] + ( ii ) model m+ +   eeg channels to a shock to the underlying factor process @xmath59 obtained from ( i ) model m , ( ii ) model m+ .",
    "the impulse response functions computed at three different time points throughout the seizure are shown ( columns ) .",
    "for each model , the impulse response projections are made from the time point indicated by column header up to 80 time periods ahead ( lower rows in ( i ) and ( ii ) ) ; the same responses are shown on a truncated time period up to only 30 time periods ahead ( upper rows in ( i ) and ( ii ) ) , for clarity.,title=\"fig:\",width=364 ]    \\(i ) @xmath220 +   and @xmath221 , respectively.,title=\"fig:\",width=384 ] + ( ii ) @xmath222 +   and @xmath221 , respectively.,title=\"fig:\",width=384 ]    patterns of the impulse response are clearly time - varying across the three exhibited time points ; variation is evident with respect to wave frequency , persistence / decay speed , and variation across the channels . in early periods of the seizure ,",
    "the responses decay slowly with a high - frequency cyclical wave , while in later periods the decay is more rapid and the oscillations at lower frequency .",
    "while there are , as we have discussed above , marked patterns of variation in lag / lead relationships across channels , there is the appearance of stronger synchronicity earlier in the seizure episode , and this deteriorates towards end of the seizure .",
    "the responses from the tv - var extended model m+ model exhibit more variation across the channels than those from the model m. this is attributable to the induction of some spill - over effects of the shock . through the latent factor model component alone",
    ", the shock @xmath223 has an impact on each of the channels through its immediate influence on @xmath224 and the consequent transfer response of these effects via @xmath225 and so forth . in the extended model",
    ", additional feed - forward effects are passed through the channels via the tv - var component .",
    "some additional insights into the nature of impulse responses can be gained from figure  [ fig : impulses ] that shows images interpolating the 9 channel responses across the brain areas , based on analysis of the extended model m+ .",
    "these are shown at six time points across the seizure period , and for selected horizons @xmath220 and @xmath221 , respectively ; these images clearly show the time variation of the responses spreading over the channels .",
    "an animated figure , available as online supplementary material , provides a dynamic display over impulse response horizons 1:80 , with a movie that more vividly exhibits the differences due to time period .",
    "the animations http://www.stat.duke.edu/~mw/.downloads/nakajimawest2016eeg/animate-impulse.avi[(linked at the external site here ) ] represent the six time points in figure  [ fig : impulses ] , and show images of the impulse responses as the projections are made over @xmath226 to horizon @xmath227",
    "the eeg time series analysis highlights the utility of latent thresholding dynamic models in constraining model parametrization adaptively in time , with resulting improvements in intepretation and inferences on inter - relationships among series and transfer response characteristics .",
    "an additional comment on model comparison in the case study is worth mentioning .",
    "statistical evaluation and comparison of model m@xmath228 with model m is implicit since the latter is a special case of the former .",
    "the analysis results of m@xmath228 explicitly show the relevance of the extensions and hence support the more general model .",
    "this is separately supported by values of the deviance information criterion ( dic ; see @xcite ) computed from the mcmc results for each model separately ; this yields estimated dic is 996,191.7 for model m and 988,435.9 for model m@xmath228 , which indicates strong evidence that model m@xmath228 dominates model m.    a number of methodological and computational areas remain for further study . among them , we note potential for integrating spatially - dependent structures with latent threshold factor models , motivated in part by the spatial - temporal findings in the eeg study . also , incorporating two or more common latent processes might allow evaluation of more complex latent factor structures for these and other applications .",
    "computational challenges are clear in connection with applying these models to higher dimensional time series such as are becoming increasing common in neuroscience as they are other other areas . that said , we expect the dynamic latent thresholding approach to become increasing relevant and important in constraining and reducing effective parameter dimension via dynamic sparsity in model parameters in contexts with higher - dimensional time series .",
    "based on the observations @xmath8 , the full set of latent state parameters and model parameters for the posterior analysis of dtrfm model m is as follows :    * the latent factor process states @xmath229 including uncertain initial values ; * the latent tvar coefficient process @xmath230 ; * the variance processes @xmath231 and @xmath65 ; * the latent factor loading process @xmath232 , including the uncertain initial state ; * the hyper - parameters @xmath233 and @xmath66 ; * the latent threshold hyper - parameters @xmath234 .      the model of can be written in a conditionally linear , gaussian dynamic model form with a modified state @xmath235 and a state transition @xmath236 where @xmath237 generation of the full sets of states is obtained by the standard forward filtering , backward sampling ( ffbs ) algorithm  ( e.g. * ? ? ?",
    "* ) , which is efficient in the sense that the full trajectories of the states over time are regenerated at each iterate of the overall mcmc .",
    "conditional on @xmath238 and the variances @xmath239 , reduce to a univariate , linear and gaussian dynamic regression model with respect to the state process @xmath240 .",
    "we sample the states using the ffbs algorithm .    based on the standard inverse gamma / beta bayesian discount model for the variance sequence @xmath65 over time",
    "as noted in section  [ subsec : dtrfm ] , the corresponding ffbs for volatilities provides a full sample from the conditional posterior for @xmath65 given all other quantities .",
    "similarly , the full conditional posterior for the @xmath231 factorizes into @xmath109 components involving the individual @xmath241 separately over @xmath74 and the discount variance ffbs applies to each in parallel to generate full conditional posterior samples .",
    "following @xcite , we sample each @xmath242 from its conditional posterior distribution given @xmath243 and all other parameters . recall that the elements of @xmath244 follow standard ar(1 ) processes , but are linked to the observation equation by the latent threshold structure .",
    "the resulting conditional posterior for @xmath244 is a non - standard distribution that we can not directly sample .",
    "we use a metropolis - within - gibbs sampling strategy with the proposal distribution derived in the _ non - threshold _",
    "case by assuming @xmath245 ; i.e. , we generate the candidate from a standard linear dynamic model for @xmath244 without the latent thresholds  ( see section 2.3 of * ? ? ?",
    "priors for the latent ar hyper - parameters @xmath246 assume prior independence across series @xmath247 with traditional forms : normal or log - gamma priors for @xmath124 , truncated normal or shifted beta priors for @xmath248 and inverse gamma priors for @xmath249 . on this basis ,",
    "the full conditional posterior for @xmath246 breaks down into conditionally independent components across @xmath250 we then resample the @xmath251 in parallel across @xmath74 using direct sampling from the conditional posterior in cases that the priors are conditionally conjugate , or alternatively via metropolis hastings steps .",
    "as discussed in section  [ subsec : dtrfm ] , the structured prior for the thresholds @xmath121 takes them as conditionally independent over @xmath115 with marginal priors that depend on the parameters of the corresponding latent ar processes , viz .",
    "@xmath252 where @xmath125 the set of thresholds are then also independent in the complete conditional posterior ; they are resampled in parallel via metropolis hastings independence chain steps using the conditional uniform priors as proposals .",
    "this is precisely as pioneered in @xcite in other latent threshold models , and its efficacy has been borne out in a number of examples there .",
    "finally , note that the above requires a slight modification and extension to generalize the mcmc for the extended dtrfm model m+ of section  [ subsec : tvvardtrfm ] .",
    "the extension now involves the tv - var parameter matrices @xmath253 in with @xmath254 together with the required latent initial missing  vector @xmath255 the above development applies conditional on these elements with the obvious modifications to subtract @xmath210 from @xmath101 throughout .",
    "then additional mcmc steps are needed .",
    "first , @xmath256 is generated from a complete conditional normal posterior under a suitably diffuse normal prior .",
    "second , the latent thresholded elements of the sequence @xmath257 and the set of hyper - parameters of the underlying ar(1 ) processes as well as the corresponding thresholds , are treated just as are the elements of @xmath258 discussed above .",
    "this component is a special case of the mcmc analysis for more general tv - var models as developed in  @xcite .",
    "some insights into the convergence of the mcmc sampling are gained by viewing trace plots for selected parameters . as an example",
    ", some such plots from the analysis of the extended model m@xmath228 are shown in figure [ fig : trace ] ."
  ],
  "abstract_text": [
    "<S> we discuss bayesian analysis of multivariate time series with dynamic factor models that exploit time - adaptive sparsity in model parametrizations via the latent threshold approach . </S>",
    "<S> one central focus is on the transfer responses of multiple interrelated series to underlying , dynamic latent factor processes . </S>",
    "<S> structured priors on model hyper - parameters are key to the efficacy of dynamic latent thresholding , and mcmc - based computation enables model fitting and analysis . a detailed case study of electroencephalographic ( eeg ) data from experimental psychiatry highlights the use of latent threshold extensions of time - varying vector autoregressive and factor models . </S>",
    "<S> this study explores a class of dynamic transfer response factor models , extending prior bayesian modeling of multiple eeg series and highlighting the practical utility of the latent thresholding concept in multivariate , non - stationary time series analysis .    </S>",
    "<S> _ msc 2010 subject classifications : _ </S>",
    "<S> 62f15 , 62m10 , 62p10    _ key words & phrases : _ dynamic factor models ; dynamic sparsity ; eeg time series ; factor - augmented vector autoregression ; impulse response ; multivariate time series ; sparse time - varying loadings ; time - series decomposition ; transfer response factor models . </S>"
  ]
}