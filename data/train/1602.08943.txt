{
  "article_text": [
    "optimization problems constrained by partial differential equations ( pdes ) arise from many applications in engineering and science , e.g. the optimal control of fluid flows , or shape optimization .",
    "since the boundary conditions or material parameters are often not precisely known we consider optimal control problems ( ocps ) constrained by pdes with random or parametrized coefficients . by this",
    "we mean that the coefficients , source terms and/or boundary values associated with the pde are modeled as random fields or parameter - dependent functions where we postulate a certain probability distribution for the parameters .",
    "the motivation for this setup is uncertainty quantification ( uq ) in complex pde - based simulations where it is crucial to account for imprecise or missing information in the input data .",
    "elliptic pdes with random coefficients are well studied to date and there is a large body of literature on efficient approximation techniques and solvers , see e.g. @xcite , ( * ? ? ?",
    "* chapter 9 ) and the references therein .",
    "however , pde - constrained optimization problems with random coefficients have been studied only very recently .",
    "we consider a distributed control problem with tracking - type cost functional constrained by an elliptic pde with a random coefficient together with box constraints for the control . a similar problem setup with elliptic and parabolic pde constraint has been considered in @xcite and @xcite , respectively .    for each fixed realization of the random coefficient in the pde constraint",
    "we solve an ocp .",
    "we then estimate the statistics , e.g. the expected value or variance of the ensemble of pathwise optimal controls .",
    "this allows us to study the sensitivity of the controls with respect to random fluctuations in the pde constraint and provides practical information on the design of control devices subject to uncertain inputs .",
    "it is clear , however , that the expected value of the pathwise optimal controls does not solve an ocp in general and is not necessarily a robust control .",
    "we give further motivation and background information on various ocps with random coefficients in  [ sec : background ] .    in this paper",
    "we describe and analyze a multilevel monte carlo ( mlmc ) estimator for the expected value of the pathwise optimal controls .",
    "mlmc is an efficient and versatile alternative to standard monte carlo ( mc ) estimation .",
    "it has been successfully used to estimate the statistics of output functionals generated by elliptic pdes with random coefficients ; see e.g. the pioneering works @xcite .",
    "in further developments , mlmc has been used for e.g. mixed finite element ( fe ) approximations of random diffusion problems @xcite , random obstacle problems @xcite , markov chains @xcite , or for the approximation of the distribution function of random variables @xcite .",
    "the basic idea of mlmc is _ variance reduction_. the mlmc estimator employs a hierarchy of approximations to the desired output quantity associated with certain levels . from one level to the next the approximation quality of the output increases but so does the cost to compute it . by a clever combination of additive corrections with decreasing variance",
    "the total cost of the mlmc estimator can be reduced dramatically compared to standard mc . by construction ,",
    "the variance of the corrections is large on coarse levels and small on fine levels .",
    "hence the mlmc estimator requires a large number of inexpensive output samples with a coarse resolution and only a modest number of highly resolved , expensive output samples . in our setting the levels",
    "are defined by fe discretizations of the pathwise optimal control problems on nested triangulations of the computational domain .",
    "the major contribution of this work is a careful error analysis of the mlmc approximation to the expected value of the pathwise optimal controls .",
    "this requires bounds on the fe error and the sampling error .",
    "we extend the classical fe analysis of pde - based ocps with deterministic inputs ( see e.g. @xcite ) to a setting with random pde coefficients .",
    "along the way we make novel contributions . for example , we prove that the pathwise optimal controls are realizations of a well - defined random field .",
    "this requires nontrivial arguments from set - valued analysis .",
    "we mention that other statistical information , e.g. the variance of the optimal controls , could also be estimated using the multilevel monte carlo framework ( cf .",
    "@xcite ) .    to analyze the total approximation error we begin by carrying out a fe error analysis for a fixed realization of the random pde coefficient .",
    "then we extend the error estimates to the entire sample space using hlder s inequality .",
    "this procedure is well established by now and follows e.g. @xcite .",
    "however , it is nontrivial for two reasons .",
    "first , it requires the careful tracking of all constants in the standard fe error estimates .",
    "these `` generic '' constants are usually not precisely specified in deterministic analyses . in our setting they can not be ignored since they depend on the realization of the random coefficient in the pde constraint .",
    "second , we assume that the realizations of the random coefficient are not uniformly bounded over the sample space and are only hlder continuous with exponent @xmath0 .",
    "hence the underlying elliptic pde in the pathwise ocp is not uniformly elliptic with respect to the random inputs .",
    "this scenario is typical for lognormal coefficients @xmath1 where @xmath2 is a mean - zero gaussian random field with a certain non - smooth covariance function .",
    "the fe error analysis of pde - based ocps relies heavily on the fe error associated with the state approximation . of course",
    ", the limited smoothness of the pde coefficient results in a limited regularity of the state ; standard textbook @xmath3-regularity is only achieved for @xmath4 .",
    "this reduces the convergence rate of the @xmath5-error of the pathwise optimal control .",
    "this situation is not ideal since the variance reduction and hence the efficiency of the mlmc estimator is determined by the fe error convergence rate of the output quantity of interest ; the faster the fe error decays the larger is the variance reduction . for this reason we employ the variational discretization @xcite for the control together with piecewise linear continuous finite elements for the state .",
    "then it can be proved that the @xmath5-error of the ( pathwise ) optimal control converges with rate @xmath6 for any @xmath7 .",
    "this is in fact the optimal rate in our this setting .",
    "alternatively , for the classical discretizations with piecewise constant or piecewise linear continuous controls the @xmath5-error of the pathwise optimal control converges only with the rates @xmath8 and @xmath9 , respectively , in the best case ( cf .",
    "@xcite and @xcite ) .",
    "the remainder of this paper is organized as follows . in  [ sec : background ] we review ocps with random coefficients and comment on the state of the art . in  [ sec : problem ] we formulate the pathwise ocp together with the state equation and first order optimality conditions .",
    "the regularity of the state and the optimal control is also investigated . in  [ sec : fe ] we focus on the discretization of the pathwise ocp .",
    "we discuss the variational discretization and prove an priori estimate for the @xmath5-error of the pathwise optimal controls . in ",
    "[ sec : mc ] we describe mc and multilevel mc estimators for the expected value of the pathwise optimal controls and analyze the computational costs of these estimators . finally , in  [",
    "sec : example ] we discuss a 2d test problem .",
    "we confirm numerically the @xmath5-error bound for the expectation of the controls and the complexity bound for the mlmc estimator .",
    "various formulations for pde - constrained ocps with random coefficients have appeared in the literature to date .",
    "these can be distinguished by assumptions on the optimal control ( deterministic or stochastic ) and the form of the cost functional whose minimum is sought . in the following we give an informal overview to put our work in context .",
    "in addition we comment on solvers for these problems .",
    "consider a cost functional @xmath10 where @xmath11 denotes the control , @xmath12 denotes the state and @xmath1 is some parameter associated with the pde constraint .",
    "note that we could write @xmath13 in reduced form as a function of the control only . in our setting",
    ", @xmath1 is a random function with realizations denoted by @xmath14 .",
    "we distinguish the following problem formulations :    * mean - based control , see @xcite : replace @xmath1 by its expected value @xmath15 $ ] . minimize @xmath16)$ ] by a deterministic optimal control . *",
    "individual or `` pathwise '' control , see @xcite : fix @xmath14 , minimize @xmath17 and obtain a realization @xmath18 of the stochastic optimal control @xmath19 . in a postprocessing step ,",
    "compute the statistics of @xmath19 , e.g. @xmath20 $ ] .",
    "* averaged control , see @xcite : control the averaged ( expected ) state by minimizing @xmath21,a)$ ] using a deterministic optimal control . * robust deterministic control ,",
    "see @xcite : minimize the expected cost @xmath22 $ ] by a deterministic optimal control . * robust stochastic control , see @xcite : minimize the expected cost @xmath22 $ ] by a stochastic optimal control .",
    "the mean - based control problem ( a ) does not account for the uncertainties in the pde and it is not clear if the resulting deterministic optimal control is robust with respect to the random fluctuations .",
    "the pathwise control problem ( b ) is highly modular and can be combined easily with sampling methods , e.g. monte carlo or sparse grid quadrature .",
    "however , the expected value @xmath20 $ ] does not solve an ocp and is in general not a robust control .",
    "the average control problem ( c ) introduced by zuazua @xcite seeks to minimize the distance of the expected state to a certain desired state .",
    "this is an interesting alternative to the robust control problem in ( d ) where the expected distance of the ( random ) state to a desired state is minimized . since the cost functional in ( c ) uses a weaker error measure than the cost functional in ( d ) the average optimal control does not solve the robust control problem in general . _",
    "stochastic _ optimal controls in ( e ) are of limited practical use since controllers typically require a _",
    "deterministic _ signal .",
    "this can , of course , be perturbed by a _ known _ mean - zero stochastic fluctuation which models the uncertainty in the controller response . for these reasons ,",
    "deterministic , robust controls in ( d ) are perhaps most useful in practice and have attracted considerable attention compared to the other formulations .",
    "however , the robust ocp in ( d ) or the average ocp in ( c ) involve an infinite number of pde constraints which are coupled by a single cost functional .",
    "the approximate solution of such problems is extremely challenging and requires much more computational resources than e.g. a deterministic ocp with a single deterministic pde constraint .",
    "for this reason it is worthwhile to explore alternative problem formulations .    in this paper",
    "we consider a pathwise control problem of the form ( b ) .",
    "( the precise problem formulation is given in ",
    "[ sec : ocp ] . )",
    "we are interested in the statistical properties of the pathwise optimal controls , e.g. the expected value @xmath20 $ ] or variance @xmath23 $ ] . observe that @xmath20 $ ] can be used as initial guess for the robust control problem in ( d ) if the variance @xmath23=\\mathbb{e}[u^\\ast-\\mathbb{e}[u^\\ast]]^2 $ ] is small .",
    "this is justified by the taylor expansion @xmath24 = \\widehat{j}(\\mathbb{e}[u^\\ast])+ \\frac12 \\frac{d^2 \\widehat{j}}{d u^2}(\\mathbb{e}[u^\\ast ] ) \\operatorname{var}[u^\\ast ] \\",
    "+ \\ \\text{higher order moments},\\ ] ] where we have used the reduced cost functional @xmath25 and the assumption that @xmath26 is smooth . however , we re - iterate that @xmath20 $ ] is in general not the solution of an optimization problem .",
    "the control problems ( a)(e ) have been tackled by a variety of solver methodologies .",
    "we mention stochastic galerkin approaches in @xcite , stochastic collocation in @xcite , low - rank , tensor - based methods in @xcite , and reduced basis / pod methods in @xcite . in this paper",
    ", we employ multilevel monte carlo to estimate the expected value of the pathwise controls , see  [ sec : mlmc ] .",
    "in the sequel , @xmath27 denotes a probability space , where @xmath28 is a sample space , @xmath29 is a @xmath30-algebra and @xmath31 $ ] is a probability measure . given a banach space @xmath32 , the space @xmath33 is the set of strongly measurable functions @xmath34 such that @xmath35 , where @xmath36 for @xmath37 we write @xmath38 .",
    "for a bounded lipschitz domain @xmath39 , the spaces @xmath40 and @xmath41 are the usual spaces of uniformly continuous functions and continuously differentiable functions , respectively , with their standard norms .",
    "the space @xmath42 with @xmath43 denotes the space of hlder continuous functions with the norm @xmath44 for @xmath45 , the space @xmath46 is the classical sobolev space , on which we define the norm and semi - norm , respectively , as @xmath47 recall that , for bounded domains @xmath39 , the norm @xmath48 and semi - norm @xmath49 are equivalent on the subspace @xmath50 of @xmath46 . for @xmath51 with @xmath52 and @xmath45 ,",
    "we denote by @xmath53 the space of all functions @xmath54 such that @xmath55 , where the norm @xmath56 is defined by @xmath57 finally , for any two positive quantities @xmath1 and @xmath58 , we write @xmath59 to indicate that @xmath60 is uniformly bounded by a positive constant independent of the realization @xmath61 or the discretization parameter @xmath62 .",
    "let @xmath63 denote a bounded convex domain with lipschitz boundary @xmath64 . for simplicity",
    "we assume that @xmath65 is polyhedral .",
    "we consider the following linear elliptic pde with random coefficients : @xmath66 for @xmath67-a.s .",
    "@xmath68 , where @xmath27 is a probability space .",
    "the @xmath30-algebra @xmath69 associated with @xmath28 is generated by the random variables @xmath70 .",
    "the differential operators @xmath71 and @xmath72 are with respect to @xmath73 .",
    "let us formally define for all @xmath68 , @xmath74 we make the following assumptions on the data .    a1 .",
    ": :    @xmath75 almost surely and    @xmath76 , for all    @xmath77 , a2 .",
    ": :    @xmath78 for some    @xmath79 and for all @xmath77 , a3 .",
    ": :    @xmath80 .",
    "notice that assumption  a2 implies that the quantities @xmath81 and @xmath82 are well defined and that @xmath83 for all @xmath77 since @xmath84 .",
    "moreover , together with assumption  a1 , it follows that @xmath85 and @xmath86 for almost all @xmath68 .    from now on , for simplicity of notation , the subscript @xmath87 denotes the dependence on @xmath87 .",
    "the variational formulation of , parametrized by @xmath68 , is @xmath88 we say that for any @xmath68 , @xmath89 is a weak solution of if and only if @xmath90 and satisfies . for completeness we restate here a special case of ( * ? ? ?",
    "* theorem 2.1 ) on the regularity of the solution to .",
    "[ thm:1 ] let assumptions a1-a3 hold for some @xmath91 .",
    "then , for @xmath67-a.s .",
    "@xmath68 , there exists a unique weak solution @xmath90 to .",
    "it holds @xmath92 for all @xmath7 except @xmath93 , where @xmath94 moreover , @xmath95 , for all @xmath96 . if @xmath4 , then @xmath97 and the bound holds with @xmath98 .",
    "let s define for @xmath67-a.s .",
    "@xmath68 the bilinear form @xmath99 and the linear functional @xmath100 by @xmath101 it is clear that assumption a3 implies @xmath102 ( the dual space of @xmath103 ) .",
    "moreover , from assumptions a1-a2 we have @xmath104 such that @xmath105    for the @xmath106 regularity of @xmath89 and the estimate , we refer the reader to @xcite . from , assumptions a1-a2 and the hlder inequality , it follows that @xmath95 .",
    "this completes the proof .    in the light of theorem  [ thm:1 ] , we introduce the following weak solution operator of for @xmath67-a.s .",
    "@xmath68 @xmath107 such that @xmath108 is the weak solution of for a given right hand side @xmath80 and a realization @xmath14 . obviously , the operator @xmath109 is bounded and linear .      for @xmath67-a.s .",
    "@xmath68 , we consider the following optimal control problem parametrized by @xmath68 @xmath110 where @xmath111 is the weak solution operator of the elliptic pde as introduced in , @xmath112 is the closed convex set of admissible controls defined by @xmath113 with @xmath114 are given . finally , the desired state @xmath115 is a given deterministic function and @xmath116 is a given real number . to begin we establish the existence and uniqueness of the solution to @xmath117 .",
    "[ thm:10 ] suppose that @xmath118 is non - empty .",
    "then , for @xmath67-a.s .",
    "@xmath68 , there exists a unique global solution @xmath119 for the problem  @xmath117 .    for a fixed @xmath68 ,",
    "the problem  @xmath117 is a deterministic infinite dimensional optimization problem .",
    "since the set @xmath118 is closed and convex and the cost functional @xmath120 is strictly convex , due to the linearity of @xmath109 and @xmath121 , it is enough to consider a minimizing sequence and argue in a classical way to verify the existence of a global solution for @xmath117 .",
    "the uniqueness follows from the strict convexity of @xmath120 .",
    "for the details we refer the reader to [ @xcite , chapter  1 ] .",
    "the subscript in @xmath122 is only to indicate that @xmath122 is the solution of @xmath117 for a given @xmath68 .",
    "the next result gives the first order optimality conditions of @xmath117 .",
    "for the proof we refer the reader to [ @xcite , chapter  1 ] .",
    "[ thm:11 ] a feasible control @xmath119 is a solution of @xmath117 if and only if there exist a state @xmath123 and an adjoint state @xmath124 such that there holds @xmath125    now we define a map @xmath126 where @xmath127 is the solution of @xmath117 for the given @xmath68 .",
    "precisely , let @xmath128 next we prove that @xmath19 is a random field and establish some properties of it .",
    "[ thm : extra ] for each @xmath68 the map @xmath129 is measurable .",
    "subsequently , we write @xmath130 instead of @xmath131 for any @xmath132 for convenience .    recall that for a fixed control @xmath80 the map @xmath133 is measurable .",
    "this implies , by ( * ? ? ?",
    "* proposition  1.2 ) , that @xmath134 is measurable as well . from this",
    ", we can easily see that the map @xmath135 defined in problem  @xmath117 is carathodory , i.e. , for every @xmath80 , @xmath136 is measurable and for every @xmath68 , @xmath137 is continuous .",
    "since @xmath13 is carathodory , we deduce from ( * ? ? ?",
    "* theorem  8.2.11 ) that the set valued map @xmath138 defined by @xmath139 is measurable and there exists a measurable selection of @xmath138 by ( * ? ? ?",
    "* theorem  8.1.3 ) .",
    "however , since theorem  [ thm:10 ] guarantees that for every @xmath68 , the set @xmath140 has a unique element which we denote by @xmath127 , we conclude that the map @xmath141 is the measurable selection of @xmath138 .",
    "this is the desired conclusion .",
    "[ thm:15 ] let assumptions a1-a3 hold for some @xmath91 and let @xmath19 be the random field defined in . then for any @xmath142 there holds @xmath143 moreover , @xmath144 for all @xmath96 .",
    "we begin by establishing the bound in . from the optimality of @xmath127 together with the estimate it follows that for any @xmath142 there holds @xmath145 from which we obtain the desired result . finally , from the estimate together with assumption  a1 and the hlder inequality",
    "it follows that @xmath146 for all @xmath96 .",
    "this completes the proof .",
    "[ rem : more ] under the assumptions of theorem  [ thm:15 ] and assuming that either the bounds @xmath147 and @xmath148 are finite , or @xmath118 is bounded , or @xmath149 , it is possible to prove that @xmath150 .",
    "the estimate in holds for any @xmath142 . in the proof of theorem  [ thm:3 ]",
    "we will see that it is desirable to choose @xmath142 such that the constant @xmath151 in is small .",
    "this can be achieved by using the projection of @xmath152 onto @xmath118 , that is @xmath153 in .",
    "[ sec:1 ]    let @xmath154 be a triangulation of @xmath65 with maximum mesh size @xmath155 such that @xmath156 in addition , we assume that the triangulation is quasi - uniform in the sense that there exists a constant @xmath157 ( independent of @xmath62 ) such that each @xmath158 is contained in a ball of radius @xmath159 and contains a ball of radius @xmath160 .",
    "finally , we define the space of linear finite elements @xmath161      for @xmath67-a.s .",
    "@xmath68 , the finite element discretization of is defined as follows : find @xmath162 such that @xmath163    [ thm:7 ] let assumptions a1-a3 hold for some @xmath91 . then , for @xmath67-a.s .",
    "@xmath68 , there exists a unique solution @xmath162 to .",
    "moreover , @xmath164    the result follows from applying the lax - milgram lemma as in the proof of theorem  [ thm:1 ] .",
    "thanks to theorem  [ thm:7 ] , we introduce the following solution operator of for @xmath67-a.s",
    ". @xmath68 @xmath165 such that @xmath166 is the solution of for a given @xmath80 and a realization @xmath14 .",
    "notice that the operator @xmath167 is bounded and linear .",
    "the following result provides the error estimate in @xmath168 associated with approximating @xmath169 by @xmath170 .",
    "[ thm:8 ] let assumptions a1-a3 hold for some @xmath91",
    ". then latexmath:[\\[\\label{eqn:15 }    for @xmath67-a.s .",
    "@xmath68 and for all @xmath172 except @xmath93 , where @xmath173 if @xmath4 , the above estimate holds with @xmath98 .",
    "the statement follows by combining theorem 2.2 and theorem 2.1 in @xcite .    in the next theorem",
    "we investigate the error in the difference @xmath174 in @xmath175 , but before that we need the following lemma which can be found for instance in ( * ? ? ?",
    "* chapter 8) .",
    "[ thm:9 ] let @xmath176 for some @xmath177 .",
    "then @xmath178 where the hidden constant is independent of @xmath179 and @xmath62 .",
    "[ thm:2 ] let assumptions a1-a3 hold for some @xmath91 . then @xmath180 for @xmath67-a.s .",
    "@xmath68 and for all @xmath172 except @xmath93 , where @xmath181 moreover , @xmath182 with @xmath183 independent of @xmath87 and @xmath62 .",
    "if @xmath4 , the above two estimates hold with @xmath98 .    the key idea is a duality argument . for @xmath67-a.s .",
    "@xmath68 , let @xmath184 and let @xmath185 be the solution of the problem @xmath186 where @xmath187 is the bilinear form defined in . observe that @xmath188 according to theorem  [ thm:1 ] .",
    "moreover , from the galerkin orthogonality there holds @xmath189 hence , we have @xmath190 dividing both sides of the previous inequality by @xmath191 gives the estimate from which we get after applying the hlder inequality together with the assumptions a1-a2 .",
    "this completes the proof .",
    "the order of convergence @xmath192 in the estimate is obtained while assuming that the integrals in are computed exactly . in general ,",
    "those integrals ca nt be computed exactly , instead , they are approximated by quadrature which introduces another sort of error that one should consider .",
    "however , it is still possible to achieve the order @xmath192 in even with quadrature provided that @xmath193 belongs to at least @xmath194 as it was explained in @xcite .",
    "it is important to mentioned this at this stage because all the upcoming error estimates related to the optimal control problem are heavily depending on .      in this section",
    "we discretize the problem @xmath117 via the variational discretization approach developed in @xcite . for @xmath67-a.s .",
    "@xmath68 , the variational discretization of @xmath117 reads @xmath195 where @xmath196 is the solution operator of as introduced in .",
    "the key idea of the variational discretization is to discretize only the state equation by finite elements ( usually piecewise linear continuous fes ) while the control is still sought in @xmath118 .",
    "hence problem @xmath197 is again an optimization problem in infinite dimensions .",
    "thus all techniques we used previously to study problem @xmath198 can also be used for @xmath197 .",
    "a detailed study of the variational discretization together with its numerical implementation and comparisons to classical discretizations can be found in @xcite and ( * ? ? ?",
    "* chapter 3 ) .",
    "analogously to theorem  [ thm:10 ] , one can show that for @xmath67-a.s .",
    "@xmath68 the problem @xmath197 admits a unique global solution which we denote by @xmath199 . the next theorem gives the first order optimality conditions of @xmath197 . for the proof",
    "we refer the reader to ( * ? ? ?",
    "* chapter  3 ) .",
    "[ thm:12 ] a feasible control @xmath200 is a solution of @xmath197 if and only if there exist a state @xmath201 and an adjoint state @xmath202 such that there holds @xmath203    the next result provides a key ingredient to establish the error estimate in approximating the solution of @xmath198 by the one of @xmath197 for a given @xmath68 .",
    "[ thm:4 ] for @xmath67-a.s .",
    "@xmath68 , let @xmath204 satisfy the optimality conditions of @xmath198 and let @xmath205 satisfy the optimality conditions of @xmath197",
    ". then @xmath206    for a given @xmath68 , the systems in theorem  [ thm:11 ] and theorem  [ thm:12 ] are deterministic .",
    "hence , it is sufficient to apply ( * ? ? ?",
    "* theorem  3.4 ) .",
    "analogously to the random field @xmath19 defined in , we introduce the discrete random field @xmath207 whose realization @xmath208 is the solution of @xmath197 for the given @xmath68 and mesh size @xmath62 .",
    "precisely , let @xmath209 that @xmath210 is indeed a random field can be proved analogously to the proof of theorem  [ thm : extra ] .",
    "next , we establish some properties of @xmath210 .",
    "[ thm:16 ] let assumptions a1-a3 hold for some @xmath91 and let @xmath210 be the random field defined in . then for any @xmath142 there holds @xmath211 moreover , @xmath212 for all @xmath96 .",
    "the proof is very similar to that of theorem  [ thm:15 ] with few obvious modifications .",
    "@xmath213 can be proved analogously to remark  [ rem : more ] .",
    "we can now show that the random field @xmath214 converges to @xmath19 in @xmath215 as the discretization parameter @xmath62 tends to zero and we derive the corresponding error estimate .",
    "[ thm:3 ] let assumptions a1-a3 hold for some @xmath91 and let @xmath216 be the random fields defined in and , respectively",
    ". then @xmath217 [ eqn:19 ] for almost all @xmath68 and for all @xmath172 except @xmath93 , where @xmath218 moreover , @xmath219 with @xmath220 independent of @xmath87 and @xmath62 and depending only on the deterministic data @xmath221 and @xmath118 .",
    "if @xmath4 , the above two estimates hold with @xmath98 .",
    "we start the proof by recalling that for a given @xmath61 the realizations @xmath222 are , by definition , the solutions of @xmath198 and @xmath197 , respectively .",
    "hence , utilizing theorem  [ thm:4 ] we obtain @xmath223 where we define here and subsequently @xmath224 and @xmath225 .",
    "we start by estimating the first term in . to achieve this",
    ", we see that from theorem  [ thm:2 ] we have @xmath226 the second term can be estimated as follows : @xmath227 inserting the above estimates into gives the estimate from which one obtains after using the hlder inequality together with assumptions a1-a2 as well as recalling .",
    "this completes the proof .",
    "[ sec : mc fe methods ] in this section we study the approximation of the expected value @xmath20 $ ] of the random field @xmath19 defined by via multilevel monte carlo methods .",
    "we start first by reviewing the classical monte carlo method , but before that we make the following assumptions and notation .",
    "let @xmath228 be a sequence of triangulations of @xmath65 such that @xmath229 is obtained from @xmath230 via uniform refinement with @xmath231 for @xmath232 , where @xmath233 denotes the maximum mesh size of @xmath229 and @xmath234 is the mesh size of an initial coarse triangulation @xmath235 .",
    "for any triangulation @xmath229 we assume that @xmath236 furthermore , on each @xmath229 we construct the space of linear finite elements @xmath237 defined by @xmath238 denoting by @xmath239 the inner nodes in the triangulation @xmath229 , we have @xmath240 , where @xmath241 denotes the dimension of the space @xmath237 .",
    "it is clear that for the spaces @xmath237 constructed this way there holds @xmath242    finally , adopting the convention @xmath243 with @xmath244 being the dimension of the computational domain @xmath65 , we make the following assumption on the computational cost of solving the problem @xmath245 .    a4 . : :    for a given @xmath68 and mesh size    @xmath233 , the solution of    @xmath245 satisfying the estimate can be    computed with a computational cost @xmath246 which    is asymptotically , as @xmath247 , bounded by    @xmath248    with some real number @xmath249 , where    @xmath250 and @xmath244 is the dimension    of the computational domain @xmath65 .",
    "it is worth to mention that the ideal value of @xmath251 in the previous assumption would be @xmath252 , in this case for instance , doubling the number of unknowns @xmath253 should result in doubling the computational cost @xmath246 .",
    "let @xmath254 be the random field defined by .",
    "the classical monte carlo estimator to @xmath20 $ ] is the sample average @xmath255 $ ] defined by @xmath256:= \\frac{1}{m}\\sum_{i=1}^m u^\\ast_{\\omega_i},\\ ] ] where @xmath257 are @xmath258 independent identically distributed samples of @xmath19 .",
    "notice that , for a fixed @xmath258 , the estimator can be interpreted as a @xmath175-valued random variable . the next result gives the _ statistical error _ associated with the estimator .",
    "[ thm:5 ] let @xmath259 .",
    "then , for any @xmath260 , we have @xmath261-e_m[u]\\|_{l^2(\\omega , l^2(d ) ) } \\leq m^{-\\frac{1}{2 } } \\|u\\|_{l^2(\\omega , l^2(d))}.\\ ] ]    using the fact that @xmath262 are independent , identically distributed random samples , we obtain @xmath263-e_m[u]\\|^2_{l^2(d ) } \\big ] & = \\mathbb{e}\\big[\\big\\|\\mathbb{e}[u]-\\frac{1}{m}\\sum_{i=1}^m   u_{\\omega_i } \\big\\|^2_{l^2(d ) } \\big ] \\\\ & = \\frac{1}{m^2 } \\mathbb{e}\\big[\\big\\|\\sum_{i=1}^m \\big(\\mathbb{e}[u]- u_{\\omega_i}\\big ) \\big\\|^2_{l^2(d ) } \\big ] \\\\ & = \\frac{1}{m^2 } \\sum_{i=1}^m \\mathbb{e}\\big[\\big\\| \\mathbb{e}[u]- u_{\\omega_i } \\big\\|^2_{l^2(d ) } \\big ] \\\\ & = \\frac{1}{m }   \\mathbb{e}\\big[\\big\\| \\mathbb{e}[u]- u \\big\\|^2_{l^2(d ) } \\big ] \\\\ & = \\frac{1}{m } \\big ( \\mathbb{e}\\big[\\| u \\|^2_{l^2(d ) } \\big ] - \\| \\mathbb{e}[u ] \\|^2_{l^2(d ) } \\big)\\\\ & \\leq \\frac{1}{m }   \\mathbb{e}\\big[\\| u \\|^2_{l^2(d ) } \\big ] .",
    "\\end{aligned}\\ ] ] taking the square root of both sides of the previous inequality gives the desired result .",
    "it might be difficult in practice to obtain samples from the random field @xmath19 since it is not known most of the time . to overcome this problem we consider sampling from its finite element approximation @xmath264 at a given level @xmath265 .",
    "we use the classical finite element monte carlo estimator to @xmath20 $ ] defined by @xmath266:= \\frac{1}{m}\\sum_{i=1}^m u^\\ast_{\\omega_i , h_l},\\ ] ] where @xmath267 are @xmath258 independent identically distributed samples of @xmath264 .",
    "the next theorem states the error estimate associated with .",
    "[ thm:6 ] let assumptions a1-a3 hold for some @xmath91",
    ". then @xmath268-e_m [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } \\leq c(\\alpha , z,{u_{ad } } ) ( m^{-\\frac{1}{2 } } + h^{2s}_l ) \\ ] ] for all @xmath172 except @xmath93 where @xmath269 is a constant independent of @xmath270 and depending only on the data @xmath221 and on @xmath118 .",
    "if @xmath4 , the above estimate hold with @xmath98 .",
    "we start the proof by using the triangle inequality to obtain @xmath271-e_m [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } \\leq \\|\\mathbb{e}[u^\\ast]-\\mathbb{e } [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } + \\|\\mathbb{e } [ u^\\ast_{h_l}]-e_m[u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d))}.\\ ] ] the task is now to estimate the two terms on the right hand side of the previous inequality .",
    "the estimate for the first term follows from theorem  [ thm:3 ] after utilizing the cauchy - schwarz inequality .",
    "in fact , we have @xmath272-\\mathbb{e } [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } & = \\|\\mathbb{e}[u^\\ast - u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } = \\|\\mathbb{e}[u^\\ast - u^\\ast_{h_l}]\\|_{l^2(d ) } \\\\ & \\leq \\mathbb{e } [ \\|u^\\ast - u^\\ast_{h_l}\\|_{l^2(d ) } ] \\leq \\| u^\\ast - u^\\ast_{h_l}\\|_{l^2(\\omega , l^2(d ) ) } \\\\ & \\leq c(\\alpha , z,{u_{ad } } )   h^{2s}_l.\\end{aligned}\\ ] ] for the second term , we use theorem  [ thm:5 ] together with the bound to obtain @xmath273-e_m[u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } & \\leq m^{-\\frac{1}{2 } } \\|u^\\ast_{h_l}\\|_{l^2(\\omega , l^2(d ) ) } \\\\ & \\leq c(\\alpha , z,{u_{ad } } ) m^{-\\frac{1}{2}}.\\end{aligned}\\ ] ] combining the estimates of the two terms gives the desired result .",
    "the previous theorem tells us that the total error resulting from using as an approximation to @xmath20 $ ] can be decomposed into two parts ; a statistical part which is of order @xmath274 and a discretization part of order @xmath275 .",
    "this suggests that the number of samples @xmath258 should be related to the mesh size @xmath270 in order to achieve a certain overall error .",
    "we state this more rigorously in the next theorem and we give the total computational cost of using .",
    "let assumptions a1-a4 hold for some @xmath91 .",
    "then , the mc estimator with the following choice of number of samples @xmath276 yields the error bound @xmath277-e_m [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } \\leq c(\\alpha , z,{u_{ad } } ) h^{2s}_l \\end{aligned}\\ ] ] for all @xmath172 except @xmath93 , with a total computational cost @xmath278 which is asymptotically , as @xmath279 , bounded by @xmath280 for some @xmath220 depending on the data @xmath221 and on @xmath118 . if @xmath4 , the above estimates and hold with @xmath98 .",
    "the estimate follows from theorem  [ thm:6 ] after choosing @xmath281 . to obtain the bound ,",
    "it is sufficient to multiply the computational cost of one sample from assumption a4 by the total number of samples @xmath282 .",
    "we start by observing that the random field @xmath264 can be written as @xmath283 where @xmath284 .",
    "the linearity of the expectation operator @xmath285 $ ] implies @xmath286=   \\sum^l_{l=0 } \\mathbb{e}[u^\\ast_{h_l}-u^\\ast_{h_{l-1}}].\\ ] ] in the multilevel monte carlo method , we approximate @xmath287 $ ] in by the classical monte carlo estimator with a number of samples @xmath288 that depends on the mesh level @xmath289 .",
    "therefore , the mlmc estimator to @xmath20 $ ] reads @xmath290:=   \\sum^l_{l=0 } e_{m_l}[u^\\ast_{h_l}-u^\\ast_{h_{l-1}}],\\ ] ] where the samples over all levels are independent of each other .",
    "the next theorem gives the error estimate associated with the estimator .",
    "[ thm:13 ] let assumptions a1-a3 hold for some @xmath91",
    ". then @xmath291-e^l [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } \\leq c(\\alpha , z,{u_{ad } } )   \\big ( h^{2s}_l +   \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l h^{2s}_l \\big),\\end{aligned}\\ ] ] for all @xmath172 except @xmath93 , where @xmath220 depends on the data @xmath221 and on @xmath118 .",
    "if @xmath4 , the above estimate holds with @xmath98 .    throughout the proof , we use the notation @xmath292 .",
    "we start by observing that using the triangle inequality together with , gives @xmath293-e^l [ u^\\ast_{h_l}]\\|_v & \\leq \\|\\mathbb{e } [ u^\\ast]-\\mathbb{e } [ u^\\ast_{h_l}]\\|_v + \\|\\mathbb{e } [ u^\\ast_{h_l}]-e^l [ u^\\ast_{h_l}]\\|_v \\nonumber \\\\",
    "& \\leq i + ii , \\end{aligned}\\ ] ] where we define @xmath294-\\mathbb{e } [ u^\\ast_{h_l}]\\|_v \\quad \\mbox { and } \\quad ii:=\\sum^l_{l=0 } \\|\\mathbb{e } [ u^\\ast_{h_l}-u^\\ast_{h_{l-1}}]-e_{m_l } [ u^\\ast_{h_l}-u^\\ast_{h_{l-1}}]\\|_v.\\ ] ] the aim is now to estimate the terms @xmath295 and @xmath296 .",
    "we start by estimating @xmath295 . to this end , it is enough to argue like in the proof of theorem  [ thm:6 ] to obtain @xmath272-\\mathbb{e } [ u^\\ast_{h_l}]\\|_v \\leq c(\\alpha , z,{u_{ad } } ) h^{2s}_l.\\end{aligned}\\ ] ] to estimate the term @xmath296 , we utilize theorem  [ thm:5 ] , the triangle inequality , theorem  [ thm:3 ] and the fact that @xmath297 to get @xmath298-e_{m_l } [ u^\\ast_{h_l}-u^\\ast_{h_{l-1}}]\\|_v   & \\leq   \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l   \\|u^\\ast_{h_l}-u^\\ast_{h_{l-1}}\\|_v   \\\\ & \\leq   \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l   \\big(\\| u^\\ast_{h_l}-u^\\ast\\|_v + \\|u^\\ast - u^\\ast_{h_{l-1}}\\|_v \\big ) \\\\ & \\leq c(\\alpha , z,{u_{ad } } ) \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l ( h^{2s}_l +   h^{2s}_{l-1 } ) \\\\ & = c(\\alpha , z,{u_{ad}})\\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l ( 1 +   2^{2s})h^{2s}_l.\\end{aligned}\\ ] ] hence , combining the estimates of the terms @xmath295 , @xmath296 and inserting them in gives @xmath272-e^l [ u^\\ast_{h_l}]\\|_v \\leq   c(\\alpha , z,{u_{ad } } ) \\big ( h^{2s}_l + \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l h^{2s}_l \\big),\\end{aligned}\\ ] ] which is the desired result and the proof is complete .",
    "the previous theorem holds for any choice of @xmath299 in , where @xmath288 is the number of samples over the refinement level @xmath289 .",
    "however , it is desirable that @xmath299 is chosen in such a way that the statistical error and the discretization error in are balanced .",
    "the next theorem suggests a choice of @xmath299 such that the overall error in is of order @xmath275 and it gives the associated computational cost .",
    "[ thm:14 ] let assumptions a1-a4 hold for some @xmath91 . then , the mlmc estimator with the following choice of @xmath299 where @xmath300 yields the error bound @xmath301-e^l [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } \\leq c(\\alpha , z,{u_{ad } } ) h^{2s}_l \\end{aligned}\\ ] ] for all @xmath172 except @xmath93 , with a total computational cost @xmath278 which is asymptotically , as @xmath279 , bounded by @xmath302 here , @xmath269 depends on the data @xmath221 and on @xmath118 . if @xmath4 , the above estimates and hold with @xmath98",
    "we give the proof only for the case @xmath303 ; the other two cases @xmath304 and @xmath305 can be treated analogously . to verify the estimate it is enough to utilize theorem  [ thm:13 ] together with the choice @xmath306 and the approximation @xmath307 to obtain @xmath272-e^l [ u^\\ast_{h_l}]\\|_{l^2(\\omega , l^2(d ) ) } & \\leq c(\\alpha , z,{u_{ad } } ) \\big ( h^{2s}_l +   \\sum^l_{l=0 }   m^{-\\frac{1}{2}}_l h^{2s}_l \\big)\\\\ & = c(\\alpha , z,{u_{ad } } ) \\big ( h^{2s}_l + h^{2s}_l \\sum^l_{l=0 }   h_l^{\\frac{4s-\\gamma}{4 } } \\big)\\\\ & = c(\\alpha , z,{u_{ad } } )",
    "\\big ( h^{2s}_l + h^{2s}_l \\sum^l_{l=0 }   2^{-(\\frac{4s-\\gamma}{4 } ) l } \\big)\\\\ & = c(\\alpha , z,{u_{ad } } ) h^{2s}_l    \\bigg ( 1 +   \\dfrac{2^{-(\\frac{4s-\\gamma}{4})(l+1)}-1}{2^{-\\frac{4s-\\gamma}{4}}-1 }   \\bigg ) \\\\ &   \\leq c(\\alpha , z,{u_{ad } } ) h^{2s}_l.\\end{aligned}\\ ] ]    it remains to verify the asymptotic upper bound for the total computational cost . to achieve this",
    ", we see that from assumption a4 together with the choice and @xmath307 , we have @xmath308 which is the desired result .",
    "importantly , by comparing the total cost of mc in and mlmc in we see that the multilevel estimator achieves the same accuracy as classical monte carlo at a fraction of the cost .",
    "we remark that the hidden constant in @xmath309 in the sequence @xmath299 from theorem  [ thm:14 ] plays a crucial rule in determining the size of the statistical error .",
    "this can be seen in where it is clear that the larger the value of the constant in @xmath309 , the smaller the statistical error . in order to obtain a minimal choice of @xmath299",
    "we adapt the strategy presented in ( * ? ? ?",
    "* remark  4.11 ) , that is , @xmath299 is chosen to be the solution of the following minimization problem @xmath310 where @xmath311 the problem @xmath312 is a convex minimization problem .",
    "moreover , for a fixed @xmath313 , the set @xmath314 is non - empty since @xmath299 from theorem  [ thm:14 ] belongs to @xmath314 if the hidden constant in @xmath309 is large enough .",
    "it should be clear that the solution @xmath315 of @xmath312 is also satisfying since @xmath316 .",
    "observe that the admissible set of controls @xmath118 is a _",
    "convex _ set .",
    "however , it is clear that the mlmc estimate for @xmath20 $ ] in is in general not admissible since the corrections in are computed using different realizations of the random coefficient . in contrast , the classical mc estimate in is always admissible since it is a convex combination of admissible controls .",
    "this has already been observed in the context of random obstacle problems @xcite .",
    "in this section we verify numerically the assertion of theorem  [ thm:14 ] , namely , the order of convergence and the upper bound for the computational cost . for this purpose , we consider the optimal control problem @xmath317 subject to @xmath318 where we define @xmath319 and @xmath320 . the data is chosen as follows : @xmath321 with the random field @xmath322 defined by @xmath323 where @xmath324 are independent normally distributed random variables .",
    "in fact , the random field @xmath322 approximates a _ gaussian _",
    "random field with zero mean and covariance function @xmath325 , where @xmath326 denotes the @xmath327-norm in @xmath328 .",
    "the terms in @xmath329 are the four leading terms in the associated karhunen - love expansion , see @xcite for more details . as a consequence ,",
    "the random field @xmath1 in is a ( truncated ) lognormal field .",
    "assumptions a1a2 are satisfied for all @xmath330 for any lognormal random field @xmath1 where @xmath2 has a lipschitz continuous , isotropic covariance function and a mean function in @xmath331 , see ( * ? ? ?",
    "* proposition  2.4 ) .",
    "the property @xmath332 for all @xmath333 is proved in ( * ? ? ?",
    "* proposition  2.3 ) . in our example",
    "the covariance function of @xmath322 is in fact analytic in @xmath334 .",
    "this gives realizations of @xmath335 ( and thus @xmath1 ) which belong to @xmath336 almost surely .",
    "hence assumption a2 is satisfied for @xmath337 .    for a given realization of the coefficient @xmath338 , the problem in is discretized by means of the variational discretization as described in ",
    "[ sec : fe ] .",
    "the resulting discrete optimality system is solved numerically by a semi - smooth newton method , see for instance @xcite .",
    "all the computations are done using a matlab implementation running on 3.40 ghz 4@xmath339intel core i5 - 3570 processor with 7.8 gbyte of ram . for solving the linear system in each iteration of the semi - smooth newton method",
    ", we use the matlab backslash operation .",
    "note that the linear system is a @xmath340 block system of order @xmath341 with sparse blocks .",
    "hence the backslash costs about @xmath342 operations in @xmath244-dimensional space .",
    "a numerical study in @xcite reveals that the number @xmath343 of semi - smooth newton iterations is independent of the mesh size @xmath233 ; in fact it depends on the input data , the tolerance , and the initial guess . in our context",
    "this means that @xmath343 depends on the realization @xmath14 of the diffusion coefficient , on the parameter @xmath344 and on the desired state @xmath345 in the cost functional in . since @xmath344 and @xmath345 are in general supplied by the user we do not consider variations of these parameters here . for our numerical example we found that @xmath343 does not vary significantly across the realizations @xmath14 , see  [ sec : cost ] .",
    "in summary , assuming that the number of semi - smooth newton iterations is independent of the realizations @xmath14 and the level @xmath289 , the cost to obtain one sample of the optimal control is @xmath346 . hence assumption a4 is satisfied with @xmath347 .",
    "we mention that it is possible to achieve the ideal value @xmath252 by using a multigrid based method ( see e.g. @xcite ) .",
    "observe that theorem  [ thm:14 ] requires the values of @xmath251 and @xmath8 a priori .",
    "these can be estimated easily via numerical computations as illustrated in figure  [ fig:1 ] .",
    "the value of @xmath251 for our solver can be deduced from figure  [ fig:1a ] where we plot of the average cost ( cpu - time in seconds ) for computing @xmath348 , the solution of , for a given realization @xmath338 and mesh size @xmath233 versus the number of degrees of freedom @xmath239 in the mesh when @xmath349 for @xmath350 .",
    "we see in the figure that the asymptotic behavior of the average cost is @xmath351 and thus @xmath352 .",
    "this is slightly better than @xmath353 which we expect in 2d space . here",
    ", the average cost at a given @xmath239 is considered to be the average of the total cpu - time in seconds required to solve for 500 independent realizations of the coefficient @xmath338 at the given mesh size @xmath233 . to confirm that the cost per sample does not vary significantly across the realizations",
    "@xmath14 we plot the cpu - time in seconds with respect to @xmath239 for individual realizations of @xmath14 in figure  [ fig:1c ] .",
    "the value of @xmath8 can be obtained from figure  [ fig:1b ] where we plot @xmath354 $ ] versus @xmath355 for @xmath356 . here ,",
    "@xmath357 $ ] denotes the sample average of @xmath358 independent samples .",
    "furthermore , @xmath359 is the solution of at a given mesh size @xmath360 and realization of @xmath338 .",
    "the control @xmath361 with @xmath362 is a reference solution since the exact solution of is not known .",
    "we see clearly from the plot that the asymptotic behavior of the error is @xmath363 as @xmath364 , and thus @xmath98 .",
    "in fact , this quadratic order of convergence should be expected since the realizations of belong to @xmath365 with @xmath4 and according to theorem  [ thm:3 ] we have @xmath98 if @xmath4 .",
    "furthermore , we observe that the error enters the asymptotic regime when the mesh size is @xmath366 or smaller .",
    "this suggests that in the mlmc estimator one should choose the mesh size @xmath234 of the coarsest level to be @xmath367 . finally , for all the experiments used in figure  [ fig:1 ] , the triangulation of the domain @xmath65 for @xmath368 consists of four triangles with only one degree of freedom located at the origin .",
    "having estimated the values of @xmath251 and @xmath8 , we are in a position to verify the error estimate and the upper bound for the computational cost in for the mlmc estimator @xmath369 $ ] , where @xmath264 is the random field associated to as defined in . to this end , let @xmath228 , for @xmath370 , be sequences of triangulations of the domain @xmath65 as described at the beginning of  [ sec : mc ] . here , we choose the mesh size @xmath234 of the initial coarse triangulation @xmath235 to be @xmath367 ( see the previous paragraph for the reason of this choice ) .",
    "since the expected value @xmath20 $ ] is not known explicitly , we consider the mlmc estimator @xmath371 $ ] to be the reference expected value where @xmath372 and @xmath373 .",
    "it is clear that the asymptotic behavior of the error @xmath20-e^l[u^\\ast_{h_l}]$ ] in the @xmath374-norm and in the @xmath175-norm is the same . to simplify the computations we thus calculate the error in the @xmath175-norm",
    "finally , for any given value of @xmath375 , we obtain the sequence @xmath299 of number of samples per refinement level through solving with the choice @xmath376 by the ` fmincon ` function from the matlab optimization toolbox .",
    "we round non - integer values in the sequence using the ceiling function . in table",
    "[ table:1 ] , we report the sequences @xmath299 , for @xmath370 , used in computing @xmath369 $ ] , where @xmath288 is the number of samples for a refinement level with mesh size @xmath377 .",
    "figure  [ fig:2a ] presents the plot of the cpu - time ( in seconds ) for the computation of @xmath369 $ ] vs. the number of degrees of freedom @xmath378 in triangulations with mesh size @xmath379 , for @xmath370 .",
    "it is clear from the figure that the computational cost is asymptotically bounded by @xmath380 as @xmath279 .",
    "since @xmath381 , this confirms the theoretical cost bound in in the case @xmath382 ( recall that @xmath98 and @xmath352 in problem ) .",
    "in fact , the theoretical cost bound is sharp in this case .",
    "note that we did not verify the cost bound for the mc estimator in due to limited computational time . in our example",
    "the mc estimator requires @xmath383 more operations on level @xmath375 than the mlmc estimator to achieve the same accuracy .",
    ".the sequences @xmath299 , for @xmath370 , used in computing @xmath369 $ ] , where @xmath288 is the number of samples over a refinement level with mesh size @xmath377 . [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> this work is motivated by the need to study the impact of data uncertainties and material imperfections on the solution to optimal control problems constrained by partial differential equations . </S>",
    "<S> we consider a pathwise optimal control problem constrained by a diffusion equation with random coefficient together with box constraints for the control . for each realization of the diffusion coefficient </S>",
    "<S> we solve an optimal control problem using the variational discretization [ m. hinze , comput . </S>",
    "<S> optim . </S>",
    "<S> appl . , 30 ( 2005 ) , pp . </S>",
    "<S> 45 - 61 ] . </S>",
    "<S> our framework allows for lognormal coefficients whose realizations are not uniformly bounded away from zero and infinity . </S>",
    "<S> we establish finite element error bounds for the pathwise optimal controls . </S>",
    "<S> this analysis is nontrivial due to the limited spatial regularity and the lack of uniform ellipticity and boundedness of the diffusion operator . </S>",
    "<S> we apply the error bounds to prove convergence of a multilevel monte carlo estimator for the expected value of the pathwise optimal controls . </S>",
    "<S> in addition we analyze the computational complexity of the multilevel estimator . </S>",
    "<S> we perform numerical experiments in 2d space to confirm the convergence result and the complexity bound .    </S>",
    "<S> * keywords : * pde - constrained optimization , uncertainty quantification , lognormal random fields , control constraints , variational discretization    * mathematics subject classification : * 35r60 , 49j20 , 60h35 , 65c05 , 65n30 </S>"
  ]
}