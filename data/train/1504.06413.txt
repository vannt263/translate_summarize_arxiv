{
  "article_text": [
    "in this paper , we will consider initial value problems @xmath0 with @xmath1 and @xmath2 , @xmath3 . a fundamental class of numerical solvers",
    "are one - step methods of the form @xmath4 where @xmath5 is referred to as the _ increment function_. important examples of one - step methods are runge  kutta methods .",
    "the increment function of a general @xmath6-stage runge ",
    "kutta method is given by    [ eq : rkode ] @xmath7 where @xmath8    the coefficients @xmath9 , @xmath10 , and @xmath11 are often arranged in form of the so - called _ butcher tableau _ @xmath12            & b^t      \\end{array }      \\qquad      { \\mathrel{\\mathop:}=}\\qquad      \\begin{array}{c|cccc }          c_1     & a_{11 } & a_{12 } & \\dots   & a_{1s } \\\\",
    "c_2     & a_{21 } & a_{22 } & \\dots   & a_{2s } \\\\",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\",
    "c_s     & a_{s1 } & a_{s2 } & \\dots & a_{ss } \\\\",
    "\\hline                 & b_1     & b_2     & \\dots & b_s      \\end{array}.\\ ] ] if the matrix @xmath13 is strictly lower triangular , then the runge  kutta method is called explicit .",
    "otherwise , the method is said to be implicit .",
    "without loss of generality , the ordinary differential equation can be rewritten as @xmath14 with external variables @xmath15 and internal variables @xmath16 .",
    "that is , we split the system into two subsystems and introduce additional variables which can be explicitly written as a function of the time @xmath17 .",
    "the dimension of the input vector @xmath18 depends on the number of different time - dependent terms , the dimension of the internal vector @xmath19 is equal to the number of equations of the original system .",
    "we introduce this partitioning to measure the influence of the input signals on the internal variables and to generate a model of the signal flow .    from now on , for the sake of simplicity , we will write the system  to which we will refer as a _ time - driven ordinary differential equation_as @xmath20 thus , @xmath21 and @xmath22 . let @xmath23 denote the size of the whole system again .    for a time - driven ordinary differential equation ,",
    "a one - step method is of the form @xmath24 with @xmath25 the increment function of a runge  kutta method can now be rewritten as    [ eq : rktdode ] @xmath26 where @xmath27",
    "given a time - driven ordinary differential equation , we want to analyze how changes of the input variables @xmath18 affect the internal variables @xmath19 and how the signals propagate through the system .",
    "to this end , we derive a directed graph which represents the structure of the system .    define @xmath28 to be the set of indices . since in general the functions @xmath29 , @xmath30 , do not depend on all variables @xmath31 , @xmath32 , we introduce input and output sets for each variable to describe the dependency on other variables .",
    "define the _ input set _ of @xmath33 , @xmath30 , to be @xmath34 analogously , define the _ output set _ to be @xmath35    that is , the variable @xmath33 depends on @xmath31 if the value of @xmath31 is required for the evaluation of @xmath29 .",
    "the input and output sets induce a directed graph with the vertices being the variables and the edges being the dependency relations between the variables .    for a given time - driven ordinary differential equation ,",
    "define the _ dependency graph _ by @xmath36 , with @xmath37 and @xmath38 .",
    "if it is clear which differential equation is meant , we will simply write @xmath39 . the dependency graph of large - scale dynamical networks can be very sparse since the subsystems are often strongly coupled inside but only connected to a few other subsystems of the network .    1 .",
    "consider the linear differential equation @xmath40 which is equivalent to the first - order system @xmath41 the input and output sets are @xmath42 + the differential equation is an equation of order three in @xmath43 .",
    "this can also be seen in the dependency graph , which is shown in figure  [ fig : linearsystemdependency ] , since @xmath44 depends only on @xmath45 and can be obtained by integration . moreover , the transposed system matrix @xmath46 is the adjacency matrix of @xmath39 , i.e.  @xmath47 .",
    "+   of the linear system.,scaledwidth=20.0% ] 2 .   given the inverter chain of length @xmath48 shown in figure  [ fig : inverterchain ] , the corresponding circuit equations can be written as a time - driven ordinary differential equation with @xmath49.\\ ] ] here , @xmath50 and @xmath51 .",
    "the function @xmath52 consists of the characteristic equations of the modules connected to the individual nodes and can be written as @xmath53 we use the shichman  hodges model @xcite to describe the drain - source current @xmath54 of the pmos and nmos transistors .",
    "+ .,scaledwidth=70.0% ] + although the ground voltage and the positive supply voltage @xmath55 are constant over time , we introduce additional variables since this assignment leads to a natural correlation between the nodes @xmath56 and the vertices @xmath57 .",
    "in addition , it allows for a straightforward graph - based approach to generate the system of equations and the dependency graph .",
    "the jacobian @xmath58 exhibits the following structure @xmath59,\\ ] ] where empty places denote partial derivatives identical to zero .",
    "figure  [ fig : inverterchaindependency ] shows the dependency graph of the inverter chain . since the constant voltages @xmath60 and @xmath61 have no influence on the dynamic signal flow , the corresponding vertices and associated edges have been omitted due to visualization reasons .",
    "+   of the inverter chain.,scaledwidth=50.0% ]    in the following , we often identify @xmath33 with @xmath57 .",
    "each internal vertex of the dependency graph represents a one - dimensional ordinary differential equation that is coupled to other one - dimensional systems . generally speaking , a time - driven ordinary differential equation together with its dependency graph",
    "can be regarded as a coupled cell system  @xcite with additional time - dependent inputs .",
    "during the simulation of big and loosely coupled networks , different subsystems often exhibit different rates of activity .",
    "that is , the values in some parts of the network change rapidly , while in other parts the values change very slowly or do not change at all .",
    "the active regions usually vary over time so that a previously inactive region undergoes quick changes and vice versa .",
    "consider for example the inverter chain .",
    "if we apply an input signal , then , generally speaking , this input signal is reversed repeatedly with a small time delay so that it seems to flow continuously through the circuit .",
    "the step size control of standard integration schemes depends mainly on the fastest changing variables . as a result",
    ", even the inactive signals have to be recomputed at every time step unless multirate integration schemes or other techniques to exploit the latency are used .",
    "we will propose an integration scheme which utilizes the underlying structure of the system .    with the definitions in section  [ sec : dependency graph ] ,",
    "it is possible to determine which values of @xmath62 are necessary to compute the new values of @xmath63 , namely , for the update of @xmath64 , all values of the variables of the input set @xmath65 are required .",
    "since the external variables @xmath66 , @xmath67 , depend only on the time @xmath17 , the input sets are empty , i.e.  @xmath68 .",
    "the update of the internal values @xmath69 , @xmath70 , requires the evaluation of @xmath71 and thus the values of @xmath72 . to identify latent regions",
    ", we have to distinguish between the different vertex types .",
    "let @xmath73 be the current time point and @xmath74 the previous time point .    1 .",
    "an external variable @xmath66 , @xmath67 , is said to be _ semi - latent _ at @xmath73 if @xmath75 for all @xmath76 .",
    "an internal variable @xmath69 , @xmath70 , is defined to be _ semi - latent _ if @xmath77    the definition implies that @xmath78 for all semi - latent internal variables .",
    "whether a vertex is semi - latent at a specific time point is not known until all the values have been evaluated , but since our aim is to reduce the number of function evaluations , we want to mark vertices which need not be recomputed .",
    "therefore , we introduce an additional concept .    a variable @xmath33 , @xmath30 , is called _ latent of order _ @xmath79 if @xmath33 and all variables of the set @xmath65 are semi - latent .",
    "additionally , a latent variable @xmath33 is defined to be _ latent of order _",
    "@xmath80 if all variables in @xmath65 are at least latent of order @xmath81 .",
    "let @xmath82 be a user - defined error tolerance . for numerical computations ,",
    "the semi - latency conditions are replaced by @xmath83 and @xmath84 , respectively . in order to illustrate the different states of activity",
    ", we simulate the inverter chain .",
    "[ ex : inverterchainsimulation ] if the inverter chain is excited with a given input signal , then this signal flows  reversed at each inverter  through the circuit , as described above .",
    "figure  [ fig : inverterchainsimulation ] shows the voltages and activity states resulting when the circuit is excited with the displayed piecewise linear function . with a view to a better visualization ,",
    "the respective activity states of the vertices are slightly shifted upward .",
    "clearly , only a few vertices are active at each time point and these active regions flow through the dependency graph .",
    "+    denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +     +    denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +     +    denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +   denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +   denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +   denotes active , @xmath79 semi - latent , and @xmath85 latent , respectively .",
    "b ) structure of @xmath86 and @xmath87 at time 1 , 2 , 3 , and 4 for a threshold of @xmath88 .",
    "c ) activity states at time 1 , 2 , 3 , and 4 , where red vertices represent active , yellow vertices semi - latent , and green vertices latent regions.,title=\"fig:\",scaledwidth=90.0% ] +    the example shows that the vertices are latent during the major part of the simulation , but each vertex at a different time .",
    "below , we will propose modified runge  kutta methods for time - driven ordinary differential equations which take into account the dependency graph and the signal flow of the underlying system .",
    "the aim is to reduce the number of function evaluations without a huge loss of accuracy by exploiting the inherent latency . since for some applications",
    "the function evaluations are time - consuming , whereas the update of the dependency graph can be accomplished in linear time , this approach offers the possibility to conceivably speed up the simulation .      for the computation of the vectors @xmath89 and @xmath90 , @xmath76 , in ,",
    "it is necessary to evaluate the functions @xmath91 and @xmath92 , respectively .",
    "the functions @xmath93 , @xmath70 , have to be recomputed if only one of the variables of the input set @xmath94 is active or semi - latent .",
    "if @xmath69 is latent of a certain order , then we can reuse the previous value .    given a time - driven ordinary differential equation , a _ signal - flow based runge ",
    "kutta method _ is defined by @xmath95 for all @xmath70 . here",
    ", @xmath6 is again the number of stages .",
    "the vectors @xmath96 and @xmath97 are as defined in .    provided that we use exact computation , the following theorem holds .",
    "[ th : erk = sferk ] the explicit runge  kutta methods and the corresponding signal - flow based methods are equivalent .    in the proof",
    ", we add the superscript @xmath98 or @xmath99 to the stages to differentiate between the different time points .",
    "let @xmath69 be latent at @xmath73 , i.e.  @xmath100 and @xmath101 for @xmath102 , we have @xmath103 and thus @xmath104 since @xmath71 depends only on the values of the input set @xmath72 and these values are the same as in the previous time step by definition .",
    "now , assume that @xmath69 is latent of order @xmath85 , i.e.  all inputs of @xmath69 are at least latent of order @xmath79 .",
    "if follows that @xmath105 using the same reasoning again .",
    "furthermore , by induction it can be shown that @xmath106 if @xmath69 is latent of order @xmath107 and @xmath108 if @xmath69 is latent of order @xmath6 .    for numerical computations",
    ", we do not update a variable if it is latent of order at least one assuming that the influence of longer paths is negligibly small . in the following ,",
    "we will abbreviate the standard classical fourth - order runge  kutta method as rk and the corresponding signal - flow based method as sfrk .",
    "[ ex : inverterchain_sfrk ] consider once again the inverter chain , which is a popular benchmark problem for multirate integration schemes .",
    "to analyze the efficiency of the signal - flow based standard runge  kutta method , we simulate the inverter chain of length @xmath109 with variably time - consuming function evaluations and different rates of inherent latency . to vary the amount of latency",
    ", we apply periodic input functions with different delays between two adjacent pulse signals , as shown in figure  [ fig : inverterchainpwlinput ] .",
    "the complexity of the transistor model is increased by artificially adding terms which do not affect the solution of the system .     to emulate latency.,scaledwidth=50.0% ]    the runtimes of the simulation with both the standard runge ",
    "kutta method and the corresponding signal - flow based method for varying model complexities and input functions are shown in figure  [ fig : inverterchain_sfrk ] . here",
    ", the time interval is @xmath110 $ ] , the step size @xmath111 , and the latency parameter @xmath112 .",
    "while the runtime of rk does not depend on the inherent latency , the runtime of sfrk decreases with increasing latency .",
    "furthermore , the more complex the transistor model , the bigger the speedup of the signal - flow based integration scheme due to the reduced number of function evaluations .",
    "table  [ tab : inverterchain_sfrk ] contains the number of transistor model evaluations for different values of @xmath113 .",
    "the influence of @xmath82 on the speedup of sfrk and the average difference per step between rk and sfrk for a fixed delay @xmath114 are shown in figure  [ fig : inverterchainepsilon_rk ] .",
    "+       +       +     +       rk & @xmath115 & @xmath115 & @xmath115 & @xmath115 & @xmath115 + sfrk & @xmath116 & @xmath117 & @xmath118 & @xmath119 & @xmath120 +    [ tab : inverterchain_sfrk ]    we can reduce the number of function evaluations even for @xmath121 since at the beginning of the simulation the circuit is in a steady state and it takes a short time until the input signal reaches the last inverter . during that time , parts of the circuit are inactive and need not be evaluated .     +   .,title=\"fig : \" ]     +   .,title=\"fig : \" ]    note that the deviation does not depend on the complexity since only artificial terms were introduced to model different complexities of the transistor model .",
    "the stages of implicit runge  kutta methods can not be evaluated successively . at each time point , a system of nonlinear equations has to be solved . to solve these systems with the newton ",
    "raphson method , the jacobian @xmath86 has to be computed . for the transient analysis of integrated circuits ,",
    "this can be accomplished efficiently using so - called element stamps  @xcite .",
    "every time the right - hand side @xmath92 is evaluated , the jacobian @xmath122if needed  is generated simultaneously .",
    "however , only the nonlinear equations that correspond to active regions will be solved assuming that the influence of and on the latent regions is negligibly small .",
    "furthermore , it is then only necessary to compute and factorize the fraction of the jacobian which represents the active part .",
    "that is , we can exploit the latency also on the level of the nonlinear and linear systems of equations . in our implementation ,",
    "a variable is not updated if it is at least latent of order one , the influence of longer paths is neglected again .    in the following",
    ", we will consider in particular the trapezoidal rule , which is frequently used for the simulation of integrated circuits .",
    "since the second version of spice most circuit simulators apply either the trapezoidal rule or bdf schemes to solve the circuit equations  @xcite .",
    "we will denote the trapezoidal rule abbreviatory as tr and the signal - flow based trapezoidal rule as sftr .",
    "the increment function of the trapezoidal rule tailored to time - driven ordinary differential equations can be written as @xmath123 that is , at each time step a system of nonlinear equations @xmath124 has to be solved .",
    "using the newton  raphson method , this leads to the iteration @xmath125 where @xmath126 is the solution of the linear system of equations @xmath127 as a starting point for the iteration , we use @xmath128 .    [ ex : inverterchain_sftr ] to facilitate comparisons of the explicit runge  kutta method and the implicit trapezoidal rule , we repeat the simulation of the inverter chain of length @xmath109 with the settings described in example  [ ex : inverterchain_sfrk ] . figure  [ fig : inverterchain_sftr ] shows the runtimes of the simulation with both the standard trapezoidal rule and the signal - flow based trapezoidal rule for varying model complexities and input functions again .",
    "we use the newton  raphson method to solve the nonlinear systems and the lu factorization to solve the resulting linear systems of equations . for the signal - flow",
    "based simulation , only the active and semi - latent parts of the nonlinear and linear systems of equations are generated and solved . here , the influence of the model complexity is negligible since the runtime of the lu factorizations is dominating .",
    "table  [ tab : inverterchain_sftr ] contains the number of required transistor model evaluations .",
    "the influence of @xmath82 on the speedup of sftr and the average deviation per step for a fixed delay @xmath114 are shown in figure  [ fig : inverterchainepsilon_tr ] .",
    "if the delay @xmath113 of the input function is bigger than @xmath129 or the period is bigger than @xmath130 , respectively , then the trapezoidal rule depends on the latency .",
    "this is due to the fact that the signal needs approximately this period of time to pass all inverters . for larger values of @xmath113",
    ", there is a small time interval where all vertices are latent and thus the newton ",
    "raphson method needs less iterations to converge .",
    "+       +       +     +       tr & @xmath131 & @xmath131 & @xmath131 & @xmath132 & @xmath133 + sftr & @xmath134 & @xmath135 & @xmath136 & @xmath137 & @xmath138 +    [ tab : inverterchain_sftr ]     +   .,title=\"fig : \" ]     +   .,title=\"fig : \" ]",
    "in power electronic circuits , diodes and semiconductor switches are constantly changing their status and a steady state condition is by definition reached when the waveforms are periodic with a time period @xmath139 which depends on the specific nature of the circuit  @xcite .",
    "the time scales of these circuits may differ by several orders of magnitude and the simulation requires very small step sizes to cover the dynamics of the fastest subsystems .",
    "the maximum simulation time , on the other hand , is usually determined by the slowest subsystems .",
    "thus , a detailed simulation of power electronic circuits is in general very time - consuming .",
    "now , we want to extend the signal - flow based approach to identify and exploit not the latency but the periodicity of subsystems in order to reduce the runtime of the simulation .",
    "let @xmath139 be the fundamental period of the system and @xmath140 , @xmath141 , the step size .    1 .",
    "an external variable @xmath66 , @xmath67 , is said to be _ semi - periodic _ at @xmath73 if @xmath142 for all @xmath76 .",
    "an internal variable @xmath69 , @xmath70 , is defined to be _ semi - periodic _ if @xmath143    in contrast to the definition of semi - latency , the variables are not compared to the previous time step , but to the corresponding time step of the previous period . roughly speaking",
    ", latency can be regarded as a special case of periodicity for which @xmath144 .",
    "a variable @xmath33 , @xmath30 , is called _ periodic of order _",
    "@xmath79 , if @xmath33 and all variables of the set @xmath65 are semi - periodic .",
    "additionally , a periodic variable @xmath33 is defined to be _ periodic of order _",
    "@xmath80 if all variables in @xmath65 are at least periodic of order @xmath81 .",
    "let @xmath82 be again a given error tolerance . for numerical computations ,",
    "the semi - periodicity conditions are replaced by @xmath145 and @xmath146 , respectively .",
    "analogously to the latency - based methods , we do not update a variable if it is periodic of order one or higher . to illustrate the different activity states",
    ", we use the inverter chain .",
    "the inverter chain is excited with a piecewise linear function which is periodic with @xmath147 for @xmath148 . the input function and the resulting node voltages at intermediate vertices",
    "are shown in figure  [ fig : inverterchainsimulationp ] .     +   , @xmath149 , and @xmath150 , the thin horizontal lines the corresponding states of the variables . here , @xmath151 denotes active , @xmath79 semi - latent or semi - periodic , and @xmath85 latent or periodic , respectively.,title=\"fig : \" ]     +   , @xmath149 , and @xmath150 , the thin horizontal lines the corresponding states of the variables . here",
    ", @xmath151 denotes active , @xmath79 semi - latent or semi - periodic , and @xmath85 latent or periodic , respectively.,title=\"fig : \" ]    an explicit _ signal - flow based periodic runge ",
    "kutta method _ for a time - driven ordinary differential equation is defined by @xmath152 for @xmath70 .    to exploit the periodicity of subsystems and to reduce the number of function evaluations , we store the vectors @xmath153 in a circular buffer .",
    "[ th : perk = sfperk ] the explicit runge  kutta methods and the corresponding signal - flow based methods for periodic systems are equivalent .",
    "the proof is almost identical to the proof of theorem  [ th : erk = sferk ] .",
    "we add again the superscript @xmath98 or @xmath154 to the stages to differentiate between the time points .",
    "let @xmath69 be periodic at @xmath73 , i.e.  @xmath155 and @xmath156 for @xmath102 , this yields @xmath157 and hence by induction @xmath158 for each variable @xmath69 which is periodic of order @xmath107 .",
    "consequently , @xmath159 for each @xmath69 which is periodic of order @xmath6 .",
    "now , let sfprk denote the signal - flow based standard fourth - order runge ",
    "kutta method for periodic systems .",
    "[ ex : inverterchain_sfprk ] to compare the signal - flow based method for periodic systems with the standard runge ",
    "kutta method , we simulate the inverter chain as described in example  [ ex : inverterchain_sfrk ] .",
    "the results are shown in figure  [ fig : inverterchain_sfprk ] and table  [ tab : functioneval_sfprk ] . here",
    ", the number of function evaluations rises with increasing @xmath113 since the time interval in which the system is periodic according to our definition decreases .",
    "+       +       +     +       rk & @xmath115 & @xmath115 & @xmath115 & @xmath115 & @xmath115 + sfprk & @xmath160 & @xmath161 & @xmath162 & @xmath163 & @xmath164 +    [ tab : functioneval_sfprk ]",
    "the efficiency of the signal - flow based runge  kutta methods depends strongly on the characteristic properties of the system .",
    "the inverter chain example shows that if during the simulation large parts of the system are latent and function evaluations are comparatively time - consuming , then the signal - flow based methods result in a substantially reduced runtime while introducing only a small deviation compared to the corresponding standard runge  kutta methods . if , on the other hand , large parts are periodic with a fundamental period @xmath139 , then the signal - flow based methods for periodic systems can be used to speed up the simulation .",
    "the following example summarizes these results .",
    "[ ex : inverterchain_sfrk_sfprk ] figure  [ fig : inverterchain_sfrk_sfprk ] shows a comparison of the signal - flow based standard runge  kutta method and the corresponding method for periodic systems .",
    "if @xmath139 is small , then the periodicity - oriented runge  kutta method is more efficient since the circuit is active most of the time . with increasing @xmath139 ,",
    "the latency exploitation becomes more efficient .",
    "to utilize not only the temporal latency , i.e.  inactivity over a period of time , but also the spatial latency , i.e.  inactivity during the newton ",
    "raphson iterations , the proposed techniques might be applicable as well .",
    "this could , for example , be used to speed up the dc analysis , exploiting the fact that some parts of the circuit possibly converge rapidly to a solution while other parts converge only very slowly .",
    "m.  gnther and p.  rentrop . partitioning and multirate strategies in latent electric circuits . in r.",
    "e. bank , r.  burlisch , h.  gajewski , and k.  merten , editors , _ mathematical modelling and simulation of electrical circuits and semiconductor devices _ , volume 117 .",
    "birkhuser , 1994 ."
  ],
  "abstract_text": [
    "<S> complex dynamical networks appear in a wide range of physical , biological , and engineering systems . </S>",
    "<S> the coupling of subsystems with varying time scales often results in multirate behavior . during the simulation of highly integrated circuits , for example </S>",
    "<S> , only a few elements underlie changing signals whereas the major part  usually up to 80 or even 90 per cent  remains latent . </S>",
    "<S> standard integration schemes discretize the entire circuit with a single step size which is mainly limited by the accuracy requirements of the rapidly changing subcircuits @xcite . </S>",
    "<S> it is of a particular interest to speed up the simulation without a significant loss of accuracy . by exploiting the latency of the system </S>",
    "<S> , only a fraction of the equations has to be formulated and solved at a given time point .    </S>",
    "<S> gnther and rentrop @xcite suggest that multirate strategies must be based both on the numerical information of the integration scheme and on the topology of the circuit . in this paper </S>",
    "<S> , we will introduce a directed graph describing the interdependency of the underlying system and propose runge  </S>",
    "<S> kutta methods which utilize the signal flow of the system in order to identify and exploit inactive regions . </S>",
    "<S> furthermore , we describe an extension of these methods to identify and exploit periodic subsystems .    </S>",
    "<S> stefan klus    ( communicated by the associate editor name ) </S>"
  ]
}