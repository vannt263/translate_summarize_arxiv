{
  "article_text": [
    "nowadays , artwork items are considered investment assets similarly to stocks , bonds and real estates . for this reason , in the recent past , the analysis of this new market segment was performed by resorting to tools for the analysis of financial markets . however , such tools miss some essential aspects of the art market . indeed , contrarily to stocks that are exchanged a high number of times in each instant , artworks are one - off pieces of their kind , hardly comparable with each other , and they pass through the market only a handful of times ( usually only one ) . a further substantial difference with respect to financial assets",
    "is that works of art provide aesthetic pleasure and social status to its owner other than mere monetary returns @xcite .",
    "moreover , there are considerable transaction costs and , last but not least , there are no publicly available good databases on this segment . hence , the study of the art market requires new tools and renovated research efforts .",
    "one of the most important problems in the analysis of art markets is the study of price indexes for artwork items . in the art economics literature",
    "several proposals have been discussed , especially for paintings . among the most important contributions we mention _ sotheby s art index _ ( and similar others ) , the _ average painting methodology _",
    "@xcite , the _ representative painting method _",
    "@xcite , the _ repeated sales regression _  @xcite and the _ hedonic regression _ , called also the _ grey painting method_. the hedonic regression model is the most used approach for modelling art prices ; the idea is due to  @xcite , whereas developments and applications can be found in  @xcite .",
    "the method assumes that the price of an artwork depends both on the market trend and on certain object characteristics .",
    "such dependence is modelled through a fixed effect regression .",
    "in particular , the estimated regression coefficients are interpreted as the price of each feature , the so - called _ shadow price _",
    ", assumed to be constant over time .",
    "hence , it is possible to predict the price of a given object by summing the prices of its features .",
    "also , a time - dependent intercept can represent the value of the _ grey painting _ in that period , that is , the value of an artwork created by a standard artist , through standard techniques , with standard dimensions , etc .",
    "the final market price index is built from the prices of the _ grey painting _ in different periods .",
    "the hedonic regression model has the advantage of solving the problem of artwork heterogeneity by explaining prices through object features ; also , it allows to derive a price index by neutralizing the effect of quality .",
    "nevertheless , such method presents several drawbacks .",
    "first of all , it is difficult to account for all the relevant features that determine the price of an object , so that only a part of the price is explained .",
    "moreover , most of the object features are categorical , such as , for example , the artist s name that in western art strongly affects the price of artworks . therefore , the regression equation will contain many dummy variables and , consequently , a high number of parameters to be estimated , so that the resulting models are not parsimonious .",
    "most importantly , it is not possible to forecast prices as the time dynamics is not modelled explicitly .",
    "in fact the price index relies only on the estimated coefficients of time - dependent dummy variables .    in order to overcome the limits of the hedonic regression model",
    ", we propose a multilevel approach .",
    "multilevel data  @xcite consist of units of analysis of different type , one hierarchically clustered within the other . at the lowest level ( level-1 observations ) such units can be described by some variables ; furthermore , they are also grouped into larger units ( higher level observations ) , which in turn could be described by other variables .",
    "the general specification of multilevel models  @xcite allows a large variety of applications .",
    "in particular , repeated measures data can be seen as a specific case of multilevel data with occasions @xmath0 at level-1 and units @xmath1 at level 2  @xcite .",
    "the dependence among level-1 errors that characterize panel data can be handled by including correlation structures at level-1  @xcite .",
    "for instance , @xcite and  @xcite model the residual errors through a first - order autoregression or autoregressive moving - average ( arma ) processes .",
    "moreover , it is possible to allow heteroscedastic within - group errors through variance functions  @xcite .",
    "this flexibility in the specification of covariance structures represents an important feature of linear mixed - effect models for longitudinal data . in all these cases ,",
    "any time dependence is modelled at the first level .",
    "since auction data do not constitute a proper panel the multilevel approach for longitudinal data described above can not be applied .",
    "indeed , auction data have a structure similar to that of repeated cross - sectional surveys .",
    "the main aim of this work is to propose a multilevel model specification that is particularly suitable to handling prices of artworks sold at auctions over time .",
    "such data consist of observations on individual survey respondents drawn from the same context ( e.g. the same country ) at many different time - points ; therefore , they can be clustered in time - points @xcite so that , even if it is not possible to follow specific individuals over time , they allow to catch social changes . @xcite",
    "were the first to adopt a multilevel framework to analyze repeated cross - sectional data .",
    "they called their model _ single - context multilevel model _ as opposed to the traditional _ multiple - contexts _ model . the substantial difference with traditional models is the serial correlation among level-2 units / time - points .",
    "the authors took into account this case by deriving a generalized least - square estimator .",
    "a similar idea has been considered by @xcite but for spatial correlations and in a bayesian framework . in their work ,",
    "the independence assumption among level-2 disturbances is relaxed and the correlation between pairs of clusters is modelled through an explicit function of the distance between them .",
    "however , to our knowledge , such approaches are not implemented in any software handling multilevel model . moreover ,",
    "a full maximum likelihood approach for this specification has not been considered . for these reasons , despite the wide potential interest , multilevel models for this kind of data are poorly developed and seldom applied .    in this paper",
    "we aim to fill in these gaps in many respects .",
    "we derive full maximum likelihood estimators with known desirable properties for the multilevel specification similar to that presented in @xcite .",
    "we treat auction data as repeated cross - sections by taking individuals ( in our case artwork items ) as level-1 units and time - points as level-2 units .",
    "hence , the price dynamics over time are modelled at the second level by means of an autoregressive structure of first order between random effects , as required by the case under investigation .",
    "the proposal combines the flexibility of mixed effect models together with the predicting performance of time series components .",
    "this specification turns out to be a natural and more convenient choice over the hedonic regression for modelling artwork prices .",
    "the overall result is a parsimonious yet powerful specification that can also reveal a useful tool to forecast the future values of the price .",
    "we obtain model estimates through an em iterative algorithm and derive robust standard errors by means of a bootstrap scheme .",
    "the work has been motivated by the analysis of the first world database of tribal art prices .",
    "such database has been built by a team of researchers of the university of bologna , faculty of economics ",
    "rimini , in conjunction with other institutions , and contains information on over 20000 artwork items sold by the most important auction houses from 1998 onwards .",
    "the paper is organized as follows .",
    "the database of tribal art prices is described in the next section . in section  [ application ]",
    "we present the multilevel specification for tribal art data and compare it with the traditional hedonic approach .",
    "section  [ newmodel ] contains the main theoretical contribution of this paper , that is the extension of the multilevel model to deal with the time dependence at the second level through a maximum likelihood approach .",
    "section  [ app ] describes the results of the new model fitted on tribal art data and compares them with those of the classic version .",
    "also , the predictive performance of the three models is assessed .",
    "finally , conclusions and discussions of future research are provided in section  [ sec : concl ] .",
    "the important problem of the construction of price indexes for art markets requires data on sales of artworks . at present",
    ", the only available information in this area comes from auction exchanges . nowadays",
    ", there are private companies ( e.g. artnet.com , artinfo.com , arsvalue.com , artprice.com ) that publish and sell information about auctions and price indexes , as well as art evaluations and other services .",
    "however , most of these companies deal with western art . in this scenario , for a long time , there has not been a database on the ethnic art . in recent years",
    ", the turnover of the tribal art market ( see figure  [ fig : series](left ) ) attracted the interest of investors and economists .",
    "the first database on ethnic artworks has been created in 2006 from the agreement of four institutions : the department of economics of the university of the italian switzerland , the museum of the extraeuropean cultures in lugano , the museo degli sguardi in rimini , and the faculty of economics of the university of bologna , campus of rimini . for each object ,",
    "37 variables are recorded from the paper catalogues released by the auction houses before the auctions ; such variables include physical , historical and market characteristics . after the auction , the information on the selling price is added to the record .        in figure",
    "[ fig : series](left ) we report the boxplots of logged prices aggregated by year ( inside the boxes , the total amount of item sold in each year ) .",
    "the plot provides a visual description of the structure of the dataset : a different group of artworks is sold each year ; e.g. 1322 items were auctioned in 1998 , 1347 objects different from the first set are sold in 1999 , and so on .",
    "it is clear that tribal art data do not constitute either a panel or a time series but has a structure like that of repeated cross - sectional surveys .",
    "moreover , the medians ( black lines ) give an idea of the trend of prices over time .",
    "2003 has been the most unsatisfying year but also the one with the highest number of sold artworks . after this period , the market experienced a gradual increase in prices and overall turnover .",
    "the fall in turnover in 2009 , instead , is likely due to the decrease of the number of auctioned items .",
    "however , although the object supply has become scarcer in recent years ( compare the low number of sold items in the boxplots and the quite high percentage of sales of figure  [ fig : series](right ) ) , the turnover is not suffering the same decline due to higher prices .",
    "overall , the positive trend gives an idea of the great potential of the tribal art market .",
    "in this paper we study the dependence of prices of artworks on available characteristics over the time span 1998 - 2011 for an overall 14206 items .",
    "all hammer prices have been deflated through the hicp ( harmonized index of consumer prices ) and transformed in euro .",
    "the characteristics of items used as explanatory variables are listed in table [ tab : data1 ] . also , based on theoretical arguments we include the interactions of the pairs `` illustration type''``width of the illustration '' and `` auction house''``venue '' . indeed , the cramer s @xmath2 pairwise association index for such variables is quite high ( 0.71 and 0.69 respectively ) . for further details and descriptive analysis of the dataset",
    "see  @xcite and  @xcite .",
    "among the existing proposals for modelling art prices , the hedonic regression model is suitable for tribal art data .",
    "indeed , such approach seems more suitable for ethnic art than for western art data .",
    "one reason for this is that tribal art is considered an _ anonymous art _ since ethnic objects are not characterized by their artist s name ( unknown ) but by their ethnic provenance . since the number of ethnic groups is generally smaller than the number of artists names , the hedonic model for the tribal art results in less dummy variables than those applied to other art segments .",
    "moreover , the amount of iconographic subjects and materials is more limited . therefore , some of the drawbacks of the hedonic regression method are less pronounced when applied to tribal data",
    ". the regression model for the price of artworks corresponding to the hedonic regression specification , that we call `` fe '' ( standing for fixed effects ) , can be expressed as    @xmath3    where @xmath4 is the observed price for the time - point @xmath5 and the item @xmath6 and @xmath7 the correspondent set of covariates listed in table  [ tab : data1 ] .",
    "@xmath8 represents the mean price of the time - points @xmath9 . in our specific case ,",
    "we have chosen to take the semesters as time - points rather than the auction dates , mainly due to three reasons :    1 .",
    "the auctions are organized in two sessions , one during the winter and one during the summer , and each session contains two to four auctions quite close in time ; the concentration in time and space allows to exploit scale economies ; 2 .   in general , the stakeholders look at the performance of the previous semester ; 3 .",
    "auction dates are not equally spaced in time and this feature is important for modelling time dependence .    in the dataset",
    ", the number of semesters is @xmath10 , and @xmath11 , the number of items sold in the semester @xmath9 , varies between 80 ( semester 2010 - 2 ) and 915 ( semester 1998 - 2 ) ; the overall sample size of sold items ( ) is 14206 .",
    "the fe model fails to capture some essential features of the price dynamics .",
    "first , such model is not parsimonious in that both time - effects and categorical covariates are included as dummy variables .",
    "also , the time dummy approach does not allow to model directly the dynamics of prices over time and all the effects are assumed constant over time  @xcite .",
    "furthermore , potential sources of heterogeneity and heteroscedasticity can not be accounted for by the hedonic regression model .",
    "last but not least , tribal art data possess a hierarchical structure which is completely disregarded .",
    "for these reasons we propose a multilevel specification which is capable of addressing the aforementioned issues .",
    "the task requires a suitable modification of the classic multilevel model .",
    "as already highlighted , since we observe different artworks sold at every auction , tribal art data do not constitute either a panel or a time series .",
    "rather , they can be thought to have a two - level structure in that items , level-1 units , are grouped in time points , level-2 units .",
    "hence , the idea is to exploit the multilevel model to explain heterogeneity of prices among time points .",
    "the two - level model , that we call `` re '' ( standing for random effects ) , has eq .",
    "( [ eq : hedonic ] ) as the level-1 model , whereas the level-2 model is @xmath12 where @xmath13 is the overall mean price and @xmath14 is a random intercept for the semester @xmath9 .",
    "note that @xmath4 and @xmath15 do not represent the price of item @xmath0 observed at successive time points , rather , @xmath4 indicates the price of the @xmath0-th object observed at time - point @xmath9 , whereas @xmath15 is the price of the @xmath0-th object at time - point @xmath16 .",
    "the two objects are physically different .",
    "one could even specify the temporal dependence of the subscript @xmath0 by changing it in @xmath17 .",
    "however , as this would lead to an unnecessary complication in the notation we have chosen the present form .    in the first and in the second column of table  [ tab : results ] we present the results of the hedonic regression fit ( fe ) and the multilevel model ( re ) respectively , both of which have been fit through the maximum likelihood method to allow comparisons .",
    "the current specification has been driven by both theoretical ( art economics ) and empirical arguments . in practice ,",
    "all the parameters result significant .",
    "also , notice the magnitude of the effects ( with interaction ) related to market characteristics such as auction house , venue and illustration .",
    "the two models produce similar results . in particular , besides the estimated coefficients , also the time effects ( semester effect ) are very close , although in the fe model these values are estimated coefficients @xmath18 whereas in the re model they are best linear unbiased predictions @xmath19  @xcite .",
    "this is due to the very high _ shrinkage factor _  @xcite .",
    "in fact , if we consider the cluster means of model  ( [ eq : hedonic ] ) : @xmath20 we have that the estimates of time - specific intercepts correspond to the group means @xmath21 on the other hand , the group means for the re model are obtained as @xmath22 where @xmath23 is the _ shrinkage factor _ that can be interpreted as the estimated reliability of the mean raw residual as a predictor of @xmath14 .",
    "indeed , the _ shrinkage factor _ takes values in @xmath24 $ ] and pulls the group means towards the overall mean by an amount depending both on @xmath11 and on the variance components . since , in our case , the group sample sizes are big as compared to the variance components , the _ shrinkage factor _ is close to one for each @xmath9 .",
    "therefore , the time - effects are almost coincident for the two models because each group - specific mean dominates over the population mean .    besides the similar parameter estimates , the multilevel model includes a further variability component , the between - group variance , @xmath25 .",
    "the significance of its estimate has been positively assessed through a likelihood ratio test between this model and its unrestricted version ( eq .  ( [ eq : hedonic ] ) with @xmath26 ) ; since the null hypothesis of zero variance is on the boundary of the feasible parameter space , we used half of the @xmath27-value obtained from the tables of the chi - squared distribution  @xcite .",
    "the proportion of the total variability of prices explained by the variability among semesters results , that , in a two - level random - intercept model , corresponds to the _ intra - class correlation _ ( icc ) , the correlation between two observations in the same semester .",
    "the existence of a non - zero icc reveals the inadequacy of traditional modelling frameworks  @xcite .    as concerns",
    "the diagnostic analysis , the shapiro - wilk test points to a deviation from normality in level-1 residuals whereas it does not reject the assumption of normality for level-2 residuals . given the non - normality at level-1 , in order to test the assumption of homogeneity of the variance across clusters",
    ", we use a non - parametric version of the homogeneity test of @xcite which is rank - based @xcite .",
    "the results indicate that level-1 variances change over time . to cope with these problems ,",
    "we have computed robust standard errors for the estimates through a modified version of the _ wild bootstrap _ procedure , described in subsection  [ subsec : wild ] .",
    "such scheme is robust with respect to heteroscedastic and non gaussian errors .    in order to assess the assumption that the error process @xmath14 is a white noise ( conditionally to the covariates ) ,",
    "we have computed the global and partial autocorrelation functions of level-2 residuals ( figure  [ fig : acf_ind ] ) . clearly , the correlograms point to an autoregressive - like structure , similar to that of an ar(1 ) process .        in summary , the re model ( [ eq : hedonic ] ) and ( [ eq : mixed ] ) produces results very similar to those of the traditional fe model  ( [ eq : hedonic ] ) in terms of estimates and residuals , but with greater parsimony .",
    "in addition , the multilevel model is able to explain a proportion of variability of the price through the variability among semesters .",
    "the assumptions of normality and homogeneity of variance across groups for level-1 errors of both models are not satisfied so that we have used robust bootstrap standard errors . on the other hand ,",
    "the predicted random effects are normally distributed with zero mean , but they are not independent for different groups as they show a peculiar autocorrelation structure . improving the classical multilevel model to deal with the latter issue",
    "requires relaxing the assumption of independence among random effects . since in the analysis of tribal art data",
    "these represent time effects , the inclusion of such correlations implies treating them as a time series . as mentioned above , the correlograms of the residuals suggest the specification of an ar(1 ) model .",
    "section [ newmodel ] is devoted to the specification and the estimation of such model .",
    "the _ wild bootstrap _ was developed by @xcite following suggestions in @xcite and @xcite .",
    "further evidences and refinements for classic regression models are provided in @xcite and @xcite . here",
    ", we adopt the wild bootstrap procedure adapted to the case of hierarchical data in @xcite .",
    "consider the random - intercept model for the ( @xmath28 ) response of the generic group @xmath9 : @xmath29 where @xmath30 for all @xmath5 .",
    "the disturbances are assumed to be mutually independent and to have zero expectation , but they are allowed to be heteroscedastic .",
    "moreover , the covariates are assumed to be strictly exogenous .",
    "+ denoting with @xmath31 the orthogonal projection matrix corresponding to design matrix @xmath32 , we replace the residual vector @xmath33 by the vector @xmath34 where the operator `` @xmath35 '' denotes the hadamard ( or entrywise ) product .",
    "then , the bootstrap procedure used is as follows :    1 .   draw independently @xmath36 values , @xmath37 , for @xmath5 , from the following two - point auxiliary distribution : @xmath38 with zero mean and unitary variance ; 2 .   generate the bootstrap samples as @xmath39 where @xmath40 , 3 .",
    "compute estimates on the bootstrap sample @xmath41 ; 4 .",
    "repeat steps 1 - 3 b times and compute bootstrap standard errors as @xmath42 where @xmath43 is the vector of the ml estimates .",
    "@xcite show that this version of the wild bootstrap behave well in case of heteroscedasticity and non - normality , and , most of all , outperforms the other bootstrap schemes used for multilevel data .",
    "in this section we propose an extension of the multilevel model , proposed in section [ application ] , that consists in relaxing the assumption of independence among random effects and treating them as a time series at the second level .",
    "the section has two subsections : the first one describes the specification of the model whereas the second subsection presents the implementation of the estimators in the maximum likelihood framework .      consider a random intercept model with @xmath44 level-1 covariates : @xmath45 for @xmath46 and @xmath5 .",
    "the slopes @xmath47 are fixed ; the intercepts @xmath8 are group - specific and random , and they are modeled as @xmath48 where @xmath14 represents the deviation of the group - specific intercept @xmath8 from the overall mean , @xmath13 .",
    "the usual assumption of independence for the random effects in  ( [ eq : mixed ] ) is relaxed by assuming an autoregressive process of order 1 for level-2 errors : @xmath49 with @xmath50 ( that guarantees stationarity ) , @xmath51 and @xmath52 for all @xmath53 and for all @xmath0 .    under these assumptions",
    "the dependent variable has the following distribution @xmath54 with @xmath55 in matrix form , the composite model for the whole response vector is @xmath56 where @xmath57 is known as random effect design matrix and @xmath58 is the correspondent vector of random intercepts with covariance matrix @xmath59.\\ ] ] thus , we have : @xmath60      model estimation is performed by using the full maximum likelihood estimation method through the e - m algorithm , since the random effects are unobserved .",
    "the set of parameters of the multilevel model with ar(1 ) random effects to be estimated is @xmath61 .",
    "the log - likelihood function associated with the response vector @xmath62 is given by @xmath63 where @xmath64 is the covariance matrix of @xmath62 , and @xmath65 \\qquad \\text{and } \\qquad \\dot{\\boldsymbol{\\beta}}=\\left[\\begin{array}{cc}\\beta_0 & \\boldsymbol{\\beta}\\end{array}\\right]^{{\\scriptscriptstyle \\mathrm{t}}}\\ ] ] are the matrix design and the coefficients vector including the intercept , respectively .",
    "to simplify the notation , we separate the set of parameters of the model into two subsets : @xmath66 , where the subset @xmath67 includes the level-1 parameters , and @xmath68 is the set of level-2 parameters .    the complete log - likelihood of the observed and unobserved data can be expressed as the sum of two separate components @xmath69 where @xmath70 and @xmath71    the matrix @xmath72 and it is straightforward to show that  @xcite @xmath73.\\ ] ] the estimation of @xmath74 through the e - m algorithm consists of two steps , the expectation ( e ) and maximization ( m ) step described in detail in the following .    *",
    "e step * : :    in the expectation step the expected score functions of the parameter    conditioned to the observed data are computed on the basis of current    value of @xmath75 , denoted as    @xmath76 , as follows :    @xmath77={\\mbox{e}}\\big[s_{1}(\\boldsymbol{\\theta}_{1})|{\\mathbf{y}},\\boldsymbol{\\theta}^{(h)}\\big]+{\\mbox{e}}\\big[s_{2}(\\boldsymbol{\\theta } _ { 2})|{\\mathbf{y}},\\boldsymbol{\\theta}^{(h)}\\big]\\ ] ]    where    @xmath78 ,    @xmath79    and    @xmath80 .",
    "+    the expressions of the expected score functions with respect to    level-1 parameters of the model are given by    @xmath81 the expression of the expected score functions with    respect to the level-2 parameters of the model are    @xmath82 - \\frac{\\rho}{1-\\rho^2 }      \\end{aligned}\\ ] ] where +    @xmath83 * m step * : :    it consists in maximizing the conditional expected value of the    log - likelihood  ( [ modifloglik ] ) computed in the e - step , getting maximum    likelihood estimates of the model parameters . in detail , the current    values of vector of parameters    @xmath84 are updated as follows    @xmath85 since we get non linear maximum likelihood equation    for the parameter @xmath86 , we update its current value    through an iteration of the newton - raphson scheme .",
    "+    the e - m algorithm consists of the following steps    1 .",
    "choose an initial value for the parameters @xmath74 ; 2 .",
    "compute the expected score functions for all the parameters ( e - step ) ; 3 .",
    "obtain improved parameter estimates ( m - step ) ; 4 .",
    "repeat steps 2 and 3 until convergence , that is , until @xmath87 is arbitrarily small .",
    "the em algorithm produces the empirical bayes prediction for the random effects @xmath88 , namely , the mean of their conditional distribution with respect to the observed data @xmath62 as in  ( [ eq : posterior ] )  @xcite .",
    "the whole algorithm has been implemented in r with an original code .",
    "further details on the implementation and a monte carlo study based on the code can be found in @xcite .",
    "in this section , we present the results of the fit of the new model upon the tribal art dataset .",
    "moreover , we will compare the predicting capability of the three models under scrutiny .",
    "consider the model in equations  ( [ eq_random_interc ] ) , ( [ eq : beta0 ] ) and  ( [ eq : ar ] ) , with the same set of covariates as in the fe specification reported in table  [ tab : data1 ] .",
    "we call it `` are '' standing for autoregressive random effects .",
    "the results are shown in the third column of table  [ tab : results ] .",
    "the estimates and the predicted random effects are quite close to those from the re model ( second column ) . in this case , the estimated between - group variance , that takes the form @xmath89 , results @xmath90 , slightly bigger than that of the re model ( @xmath91 ) .",
    "consequently , the proportion of variability explained by the between - semesters variance ( icc ) is bigger for the new model , 17.3% against 14.5% .",
    "also , the level-2 residual variability of the are model @xmath92 is smaller than that of the re model , @xmath91 .",
    "this confirms that the structure at the second level has been taken into account by the new specification .",
    "furthermore , the estimate of the autoregressive parameter @xmath86 is quite high , @xmath93 and agrees with the evidence of the correlograms of the residuals of the re model ( see figure  [ fig : acf_ind ] ) . the last column reports @xmath19 of the are model to facilitate the comparison with the fe semester effects .",
    "note that when @xmath86 is zero , the random effects are independent and the multilevel model reduces to the re specification .",
    "hence , the are and the re models are nested so that we can use the likelihood ratio test for assessing the significance of @xmath86 . according both to the lr test and to the information criteria ( see table  [ tab : results ] )",
    ", the are model provides a better fit than the re model .",
    "the diagnostic checks show that the are - model presents the same features of non - normality and non - homogeneity of variance among groups as the fe - model ( section [ application ] ) .",
    "therefore , also in this case , we have computed robust standard errors through the wild bootstrap procedure .",
    "the presence of ar(1 ) random effects requires a further extension of the wild bootstrap for hierarchical data @xcite that consists in replacing step ( b ) of subsection [ subsec : wild ] with the following :    1 .",
    "generate the bootstrap samples as @xmath94 for @xmath95 and for @xmath5 , where @xmath96 is an autoregressive process with disturbances equal to @xmath97 and @xmath98 @xmath99 is @xmath0-th diagonal element of the orthogonal projection matrix of @xmath100 ;    such modification takes into account both the time dependence at the second level and the heteroscedasticity at the first level .",
    "the autocorrelation functions ( global and partial ) of level-2 residuals ( see figure  [ fig : acf_ar ] ) do not reveal any structure as the values lie within the rejection bands at level 95% at all lags .",
    "hence , our novel specification has successfully captured the time dependence of the price dynamics by means of the autoregressive specification at the second level .",
    "finally , table  [ tab : prediction ] summarizes and compares the prediction capability of the three models under study .",
    "the aggregate measures of prediction error are the mean absolute ( prediction ) error @xmath101 and the root mean square ( prediction ) error @xmath102 .",
    "the first two rows of table  [ tab : prediction ] report the prediction error over 100 ( out of sample ) items within the time span 1998 - 2011 . in this instance",
    ", the three models present the same performance .",
    "the last two rows of the table show the forecast performance over all the 281 observations of the semester 2011 - 1 .",
    "such observations have not been included in the model so that the measures reflect a genuine one - step - ahead forecast performance .",
    "clearly , the are model allows to obtain better forecasts of the prices of artwork objects through the autoregressive specification .",
    "lccc & * fe * & * re * & * are * +   + mae & 0.280 & 0.280 & 0.280 + rmse & 0.342 & 0.342 & 0.342 +   + mae & 0.494 & 0.489 & 0.454 + rmse & 0.423 & 0.419 & 0.358 +    in conclusion , if compared to the other two models , our new are model presents a better fit and superior forecasting performance .",
    "although the estimates are similar to those of the hedonic regression model , the multilevel framework is more parsimonious and provides a natural flexible approach through the decomposition of the total variability of the response .",
    "the autoregressive specification is backed up by art economics theory that confirms that the process of formation of auction prices has short memory : indeed , in the case of tribal art , the dependence is upon the previous semester .",
    "in the present work , we have introduced a multilevel framework for the analysis of prices of artworks sold at auctions over time .",
    "the proposal combines the flexibility of mixed effect models , in that it allows to account for various sources of heterogeneity , together with the predicting performance of time series models .",
    "the latter component allows to specify a substantive model for the price dynamics over time .",
    "since auction data do not constitute a proper panel or a time series we need a multilevel specification with items at the first level and time points at the second level .",
    "we have applied such specification to analyse the tribal art market by using the first database on ethnic artworks that contains information on more than 20000 items sold in the most important auction houses in the world .",
    "the results show that our approach gives a substantial advantage over the traditional hedonic regression model , especially in terms of degrees of freedom , parsimony and interpretability .",
    "in fact , the multilevel model retains the ease of interpretation of the hedonic regression model since the estimated regression coefficients can be still seen as _ shadow prices _ for each feature , and a price index for the art market is easily provided through the predictions of the time - effects . on the other hand , it has less parameters to be estimated and provides a decomposition of the total variability of the response .",
    "the dependence of the price over time has been modelled by means of an autoregressive specification at the second level .",
    "hence , we have extended the classic multilevel model by relaxing the assumption of independence among random effects and treating them as a time series at the second level . in order to achieve the task ,",
    "we have derived full maximum likelihood estimators through the e - m algorithm and have implemented them in an original r - code .",
    "the results show that the new specification fully captures the temporal dependence structure among group - effects .",
    "moreover , such model presents superior forecasting performance with respect to other proposals . in conclusion",
    ", we advocate the use of our specification as a natural choice for modelling artwork prices and possibly , obtain forecasts / predictions that might be valuable to auction houses , banks and investors .    the work presented here can be extended in different directions ; also , many applications are possible .",
    "first , it could be interesting to explore further the nature of the deviation from normality of level-1 residuals .",
    "this might be accomplished by inserting further variance components in the model , especially those related to the interactions between covariates .",
    "also , possible volatility effects ( arch / garch ) can be inserted as to extend considerably the flexibility of the model and make it appealing from the point of view of financial applications .",
    "moreover , the model could be applied to characterize and forecast other art markets .",
    "lastly , in order to promote the usage of our model and to facilitate the reproducibility of the research we plan to release the software implemented as an r package . the latter project would contribute to fill the lack that hindered the practical use of multilevel models for repeated cross - sectional data .",
    "we would like to thank leonardo grilli , cinzia viroli , guido candela and antonello e. scorcu for their useful comments and discussions . this work has been partially supported by the firb research project `` mixture and latent variable model for causal inference and analysis of socio - economic data '' ."
  ],
  "abstract_text": [
    "<S> in this paper we propose a multilevel model specification with time series components for the analysis of prices of artworks sold at auctions . </S>",
    "<S> since auction data do not constitute a panel or a time series but are composed of repeated cross - sections they require a specification with items at the first level nested in time points . </S>",
    "<S> an original feature of our approach is the derivation of full maximum likelihood estimators through the e - m algorithm . </S>",
    "<S> the data analysed come from the first database of ethnic artworks sold in the most important auctions worldwide . </S>",
    "<S> the results show that the new specification improves considerably over existing proposals both in terms of fit and prediction . </S>"
  ]
}