{
  "article_text": [
    "imaging surveys are limited by depth , angular coverage and angular resolution .",
    "there are currently several proposals for wide field telescopes and instrumentation which promise great gains in the first two of these variables ( the cfht megaprime project (; ) ; megacam on the mmt (; ; ; ) ; the uk ` vista ' project @xcite ; the ` dark matter telescope ' @xcite ; suprime - cam for subaru @xcite ; omega - cam for the eso vst at paranal @xcite ; the canadian cfht 8 m upgrade proposal ) .",
    "unfortunately , these designs are hampered by the limited angular resolution available from the ground ; at @xmath4 most faint galaxies are poorly resolved at even the best sites , and we know from e.g.  the hubble deep field that galaxies become still smaller as one pushes fainter , and there is a wealth of data lying tantalizingly beyond the resolution of conventional ground - based telescopes .",
    "atmospheric seeing arises from spatial fluctuations in the refractive index associated with turbulent mixing of air with inhomogeneous entropy and/or water vapor content ( e.g  ) .",
    "high order adaptive optics ( ao ) can achieve spectacular improvement in angular resolution on large telescopes ( see e.g.  the reviews of ; ) , but has not been applied to wide - field imaging due to the limited ` isoplanatic angle ' this being the angular distance around the guide star within which target objects sample effectively the same refractive index fluctuations .",
    "there have been discussions of ` multi - conjugate ' systems to increase the field of view ( e.g.  ) , but little concrete has yet to emerge from this . here",
    "we shall explore the possibility of of achieving a more modest but still valuable gain in resolution by using an array of small telescopes with fast guiding or ` tip - tilt ' correction . in what follows",
    "we will first review why one would want to use tit - tilt on small telescopes , we then discuss the ` isoplanatic angle ' problem for fast - guiding , and how this can be overcome using multiple telescopes and new technology in the form of ` orthogonal transfer ' ccd technology .    fast guiding is a common feature of modern large telescope designs , and can be quite useful for dealing with ` wind shake ' or other local sources of image wobble .",
    "however , for realistic turbulence spectra , and for most sensible measures of image quality , fast guiding has relatively little effect on the _ atmospheric _ contribution to seeing for large telescopes .",
    "for fully developed kolmogorov turbulence ( e.g.  ) the structure function for phase fluctuations is @xmath5 .",
    "this says that the rms phase difference between two points grows in proportion to the @xmath6 power of their separation .",
    "the character of the phase fluctuations imposed on wavefronts is shown in figure [ fig : phaseplot ] .",
    "the amplitude of the phase fluctuations is characterized by the ` fried length ' @xmath7 @xcite , which is the separation for which the rms phase difference is of order unity ( actually @xmath8 radians ) , and is on the order of 20 cm at good sites in the visible ) .",
    "the rapidly growing amplitude of the structure function means that the phase variations are dominated by the lowest order modes .",
    "for example , if we ignore piston , the phase variance averaged over a circular aperture of diameter @xmath9 is @xmath10 but this drops to @xmath11 if the lowest order zernike modes of tip and tilt are removed @xcite . thus applying tip - tilt correction reduces the phase variance by a factor @xmath12 which is both substantial and independent of the diameter of the telescope .",
    "we can safely conclude from this that a telescope with @xmath9 less than a few times @xmath7 will , after tip - tilt correction , have residual phase variance which is small compared to unity and will therefore give close to diffraction limited performance .    what about larger telescopes ? if @xmath13 a few then the residual phase variation is large compared to unity , so such telescopes will not be diffraction limited . as with a small telescope ,",
    "the primary effect of tip - tilt is to reduce the phase fluctuations on scales of order the telescope diameter .",
    "this will cause a dramatic improvement in the transmission of the telescope for frequencies approaching the diffraction limit , but the uncorrected transmission for such frequencies is essentially zero , so even a large gain here does little good .",
    "there is some reduction in phase variations on smaller scales  separations on the order of @xmath7 that is  with some corresponding increase in useful image quality which we can estimate as follows : the root mean squared tilt of the wavefront averaged over the aperture is on the order of @xmath14 .",
    "more precisely , we find the variation in position the uncorrected psf centroid to be a gaussian @xmath15 with @xmath16 whereas the uncorrected psf has fwhm @xmath17 for @xmath18 , which is the same as for a gaussian with variance @xmath19 . to a crude approximation , which actually becomes quite good for @xmath18 , one might expect the corrected psf to approximate a gaussian with @xmath20 with corresponding improvement in image quality ( which we take to be the inverse of the area of the psf ) of [ eq : imagequalityvsd ] _",
    "total^2 _ total^2 - _ tilt^2 so the gain from tip / tilt is predicted to decrease , albeit somewhat slowly , for large @xmath21 .",
    "this theoretical expectation @xcite has been widely discussed and studied in detail (; ; ; ) and it turns out that , for a filled aperture , a pupil diameter @xmath22 maximizes the normalized strehl ratio , this being defined as the central value of the normalized psf as compared to that for a large telescope , and the gain for @xmath23 is a factor @xmath24 . for @xmath25",
    "the gain is @xmath26 and for @xmath27 the gain is a factor @xmath28 .",
    "these latter numbers are in quite good agreement with the crude estimate ( [ eq : imagequalityvsd ] ) .",
    "this expectation has also been confirmed in practice by who used hrcam on the cfht with the pupil stopped down to @xmath29 m , and by with the uh adaptive optics system working in tip / tilt mode again with the cfht stopped down to 1 m aperture .",
    "these conclusions are somewhat dependent on the assumption of fully developed kolmogorov turbulence . recently",
    "have reported deviations from the @xmath30 law at la silla which they characterize , in the context of the von - karman model , as an ` outer - scale ' of @xmath31 m , and a number of the measurements reviewed by , have also given fairly small values . a finite value for the outer scale will tend to further reduce the effect of tip - tilt correlation on large telescopes .",
    "another way to look at this problem is in terms of ` speckles ' .",
    "a snapshot of the psf for a large telescope consists of a set of speckles , each of which is about the size of the diffraction limited psf , and there being on the order of @xmath32 speckles in total , i.e.  on the order of the number of @xmath33 sized patches within the pupil .",
    "these speckles dance around on the focal plane ( see http://www.ifa.hawaii.edu/~kaiser/wfhri[http://www.ifa.hawaii.edu/@xmath34kaiser/wfhri ] for an animated movie showing the evolution of psfs for a range of telescope diameters ) .",
    "for @xmath35 it is found that much of the time a substantial fraction of the light ( say 25% or so ) is in a single bright central speckle , and by tracking the centroid  or better still tracking the peak of the brightest speckle @xcite  one can keep this bright dominant speckle at a fixed point on the focal plane , resulting in a psf with a diffraction limited core component .    for kolmogorov turbulence the seeing angle ( defined as the fwhm of the psf ) is @xmath36 with @xmath37 .",
    "analysis of scidar measurements at mauna kea by gave a median @xmath38 at @xmath39 corresponding to @xmath40 cm or , in the i - band , @xmath41 cm for which the optimal telescope diameter is then @xmath42 m .",
    "a similar value of the mean free atmosphere fried length ( @xmath43 cm at @xmath44 ) was inferred by from correlation of the modulation transfer function for wide binary stars of various separations .",
    "this would suggest a 20% larger optimal diameter , but the result is dependent on their assumed model for the vertical distribution of seeing .",
    "racine also found an approximately log - normal distribution of seeing angle with 1-sigma points of @xmath45 corresponding to a range of @xmath46 cm , and to a range in wavelength for which @xmath7 is optimally matched to a 1.6 m telescope of @xmath47 m .",
    "thus in the normal range of seeing conditions a @xmath48 m diameter fast guiding telescope could operate optimally over the range of passbands v , r , i , z. note that in a multi - color survey performed in this way the resolution for the different passbands scales as fwhm @xmath49 rather than fwhm @xmath50 as in a conventional survey .",
    "applying fast image - motion correction to a small telescope should therefore greatly enhance image quality , but only over a limited distance from the guide star used to measure the motion .",
    "studies of the atmosphere using scidar and thermosonde probes (; ; ; ; ; ; ) have shown that the source of seeing ( conventionally characterized by @xmath51 , the intensity of the power spectrum of refractive index fluctuations @xcite ) is highly structured and stratified . in the typical situation",
    "there is a substantial contribution from very low level turbulence  the planetary boundary layer and ` dome seeing '  but there are also comparable contributions from higher altitude layers at @xmath52 km .",
    "the indications are that the layers are thin with thickness on the order of 100 m or so .",
    "the low level turbulence causes a coherent motion of all objects in the field , and is relatively easy to deal with .",
    "the higher altitude seeing is more problematic , since the angular scale over which images move coherently  the ` isokinetic ' angle  is on the order of @xmath53 . for @xmath54 km",
    "say and @xmath55 m this is roughly 1 arc - minute .",
    "it is perhaps worth mentioning at this point that the experiment seemed to show a substantially larger isokinetic scale than the simple estimate given here .",
    "this is encouraging , as it would indicate a predominance of low - level turbulence , which would make our job easier , but it may well be that they were lucky and observed at a time when the high altitude seeing contribution was relatively quiescent .",
    "the limited isokinetic angle has serious implications for wide field imaging . for a 1-degree field",
    "say , the focal plane will consist of @xmath56 isokinetic patches moving independently , so one needs some kind of ` rubber focal plane ' detector to track these motions .",
    "moreover , at high galactic latitudes at least , the mean separation of stars which are sufficiently bright to guide on ( @xmath57 ) is on the order of @xmath58 , so there are two few guide stars with which to determine the deflection field at all points on the focal plane",
    ".    one way to avoid the latter problem would be to work at lower galactic latitude , where bright guide stars are more abundant , or to peer through globular clusters , but these approaches seem rather unsatisfactory .",
    "the solution to these problems that we propose here has two key features .",
    "the first is to use otccd @xcite technology to implement the rubber focal plane .",
    "the second is to use an array of telescopes to provide multiple samples of the atmospheric turbulence to provide the information needed to accurately guide out image motion at all points in the field of view .    in an otccd device , as in an ordinary ccd , the electrons created by impinging photons are are trapped in a grid of potential wells .",
    "the difference is that the origin of the grid can be shifted with respect to the physical pixels by fractional pixel displacements , and the accumulating charge can therefore be moved around quasi - continuously , and in multiple directions , to accommodate drifting of the images due to the atmosphere . a camera made of a large number of such devices",
    "could then shift charge on different parts of the focal plane independently .    to see how an array of telescopes might solve the problem of limited guide stars consider the simple case of a single thin layer of high - altitude turbulence at height @xmath59 above the telescope . a single small telescope monitoring",
    "a set of guide stars will provide a set of samples of the the image deflection field , scattered over a region of size @xmath60 where @xmath61 is the angular field size , but with spacing somewhat larger than the deflection coherence scale .",
    "a neighboring telescope observing the same set of stars will provide another set of samples of the deflection field with the same pattern as the first , but displaced by the vector separation of the telescopes as illustrated in figure [ fig : beamsplot ] . with an array of telescopes one can further increase the density of sampling of the deflection field until one has full coverage . in this scheme then",
    ", the information needed to guide out the motion of a target object image seen through some patch of the turbulent layer by a particular telescope would be provided by one or more other telescopes in the array which are viewing bright guide stars through the same patch of turbulence .",
    "a single thin layer of turbulence is something of an idealization , and with multiple or thick layers one clearly needs more information .",
    "however , there _ is _ much more information at our disposal :",
    "a generic feature of kolmogorov turbulence is that the turnover time for small scale eddies is long as compared to the time - scale for winds to convect the eddies through their length , so to some approximation we can adopt the ` frozen turbulence ' assumption and use the additional information from positions of guide stars viewed at earlier times at points upwind of the point in question to constrain the deflection field .",
    "consider then an array of perhaps a few tens of small telescopes each acting as an incoherent detector  there being no attempt here to co - phase the signals from separate telescopes as is done with a interferometer array  but sharing the image motion data needed to implement low order ao in the form of fast guiding .",
    "such an array , monitoring of order several hundred guide stars ( for a nominal 1-degree field say ) would provide many thousands of skewer like samples through the layers of turbulence flowing over the array .",
    "how though is one to make sense of this huge torrent of data in practice ?",
    "we believe the answer is to exploit the statistically gaussian nature of the turbulent layers .",
    "the eddy size which dominates the deflection here is on the order of the telescope diameter @xmath9 . assuming that the thickness of the turbulent layer exceeds this",
    "then the central limit theorem effectively guarantees that the phase perturbation @xmath62 imposed on a wavefront passing through such a layer should be a statistically homogeneous and isotropic ( though flowing ) gaussian random field .",
    "for fully developed kolmogorov turbulence the power spectrum is @xmath63 though this may flatten at low wave - number to something like the von karman form @xmath64 parameterized by @xmath65 . in reality ,",
    "atmospheric turbulence is intermittent , with the strength of the turbulence varying on time - scales of tens of minutes @xcite , and this will break the very large - scale spatial homogeneity , but the process may well be effectively stationary on smaller length scales .",
    "the deflection of the image centroid @xmath66 is , as we shall see below , obtained by taking the derivative of the phase perturbation and averaging over the telescope pupil .",
    "this is a linear function of the phase fluctuation field and so should also have gaussian statistics , so this allows one to write down the joint probability distribution for a set of @xmath67 deflections @xmath68 where @xmath69 is a compound index specifying the object , the telescope , the time of observation , and also the cartesian component of the deflection : [ eq : multivariatepdf ] p(_0 , _ 1 ,  ) d^n = 1 ( -_i m_ij^-1 _ j / 2 ) where the covariance matrix is m_ij _ i _ j . this covariance matrix is a smooth and well defined function of the vector separation of the telescopes @xmath70 ; the vector angular separation of the objects @xmath71 ; and the time difference @xmath72 . for sufficiently large fields",
    "one can obtain sufficiently dense sampling in @xmath71 and by integrating over several minutes , it should be possible to accurately determine the deflection covariance function @xmath73 . from this covariance matrix one can then compute the conditional probability for the deflection of a target object viewed with a given telescope at the current instant of time @xmath74 given the measured deflections of a set of guide stars for @xmath75 . from this conditional probability @xmath76",
    "one can extract both the mean conditional deflection @xmath77  which is the signal one uses to guide out the target object motion  and also the covariance matrix for the errors in the guide signal @xmath78 which , as we shall see , allows one to compute the final psf and thus monitor the performance of the system .    to summarize , the concept which emerges is of an array of telescopes , each equipped with its own wide field detector divided into a large number of segments , each of which is either continuously monitoring the position of a guide star or integrating .",
    "the guide star data is fed to a multi - variate gaussian ` probability engine ' , which feeds back to the telescopes the necessary information for moving the accumulated charge on each integrating segment of the detector .",
    "as we shall see , under good conditions , such an instrument should allow @xmath0 fwhm image quality over large fields ; while only a modest  roughly a factor 3  increase in resolution over conventional telescopes we believe that this is well worth having as much of the information of interest in faint galaxy studies lies at spatial frequencies tantalizingly close to , but beyond the resolution attainable with a large aperture single mirror telescope .",
    "a nice feature of this design is that it scalable to arbitrarily large collecting area with cost proportional to area .    in the rest of this paper",
    "we will discuss in more detail the practicality of this approach . in ",
    "[ sec : psf ] we present calculations of the psf and optical transfer function ( otf ) for fast guiding .",
    "we present a number of objective measures of the image quality which are relevant for different types of observation .",
    "we discuss the constraint on pixel size and telescope design imposed by the requirement that the image quality not be degraded by detector resolution .",
    "we also quantify how the psf degrades with distance from the guide star . in ",
    "[ sec : guidestars ] we consider the constraints imposed by the limited numbers of sufficiently bright guide stars . in ",
    "[ sec : correlations ] we discuss the spatial and temporal correlations of image motions .",
    "we outline our guiding algorithm and what constraints are imposed on the telescope array geometry .",
    "we find that there are currently insufficient data on the detailed structure and statistics of atmospheric turbulence to definitively determine the performance and optimize the design for the type of system we have in mind , but we describe the kinds of experiments that should be done to resolve this . in  [ sec : detectors ] we discuss the otccd ` rubber focal plane ' detector .",
    "we consider the costs of software development in ",
    "[ sec : software ] , and summarize the overall system cost in  [ sec : costs ] . in  [ sec : science ] we outline some of the scientific opportunities that this kind of instrument makes possible .",
    "according to elementary diffraction theory ( e.g.  ) , the electric field amplitude at some position @xmath79 on the focal plane of a telescope is the fourier transform of the product of the telescope pupil function @xmath80 with the atmospheric phase factor @xmath81 , so @xmath82 . here",
    "@xmath83 is the focal length and @xmath84 is the wavelength .",
    "squaring this gives the intensity which , suitably normalized , is the psf @xmath85 . in what follows it",
    "is convenient to work in rescaled focal plane coordinates @xmath86 .",
    "the psf is then the inverse fourier transform of the otf @xmath87 where @xmath88}\\ ] ] where we have normalized the pupil function so that @xmath89",
    ". these results are valid in the ` near - field ' limit , which should be quite accurate for our purposes @xcite .    in an idealized fast guiding telescope ,",
    "the instantaneous psf is measured from a bright ` guide star ' , and its position is determined and used to guide the telescope . in this section our goal is to determine the final corrected psf averaged over a long integration time . since the statistical properties of the phase fluctuation field @xmath90 are given by kolmogorov theory this is a well posed problem .",
    "it is however somewhat complicated , and the details of the psf depend on the method used to determine the center .",
    "we first review the calculation of the ` natural ' or uncorrected psf in  [ subsec : naturalpsf ] .",
    "we discuss the approximation to the corrected otf given by @xcite in  [ subsec : friedmodel ] . in ",
    "[ subsec : centroidpsf ] we compute the otf and psf for the case of guiding on the image centroid . in ",
    "[ subsec : isoplanatism ] we show how the psf for centroid guiding depends on the distance from the guide star . in ",
    "[ subsec : alternativecentering ] we discuss alternatives to the image centroid such as peak tracking , which yield somewhat superior image quality . finally , in ",
    "[ subsec : pixelization ] we consider the effect of finite pixel size .",
    "the long - exposure uncorrected otf was first given in the classic paper of and is obtained by taking the time average of ( [ eq : otf0 ] ) .",
    "this requires the average of the complex exponential of the phase difference @xmath91 . at fixed @xmath92",
    "this is a stationary ( in time ) gaussian random process with with probability distribution @xmath93 and so the time average of the complex exponential is @xmath94 where the final equality follows on integrating by completing the square . now",
    "since the phase fluctuation field is also a statistically spatially homogeneous process , the phase difference variance or ` structure function ' @xmath95 is a function only of the separation of the points : @xmath96 , and so in this special case the otf factorizes into the product of the diffraction limited otf @xmath97 and the ` atmospheric transfer function ' @xmath98 . for fully developed kolmogorov turbulence",
    "the structure function is a power law @xmath99 and the otf therefore has the form @xmath100 .",
    "a large part of the width of the natural psf can be attributed to ` wandering ' of the instantaneous psf .",
    "this is illustrated in figure [ fig : psfexamples ] which shows a set of realizations of the instantaneous psf for a telescope with @xmath101 .",
    "a series of animated images showing the continuous evolution of atmosphere limited psfs can be viewed at http://www.ifa.hawaii.edu/~kaiser/wfhri[http://www.ifa.hawaii.edu/@xmath34kaiser/wfhri ] .",
    "fried argued that the corrected or ` short - exposure ' otf , i.e.  that obtained after taking out any net shift in these instantaneous images before temporal averaging , should be of the form [ eq : friedotf ] g_c(z ) ( -z^5/3 + z^2 ) .",
    "this result has a very simple and intuitively reasonable physical interpretation : think of the uncorrected psf as the convolution of the short exposure psf with the distribution @xmath102 of the image shifts caused by any net tilt to the incoming wavefronts . for steady turbulence",
    "this distribution is a gaussian , so in fourier space its transform is also a gaussian , and so the short exposure otf should be the long - exposure form divided by a gaussian which , for suitably chosen @xmath103 , @xmath104 , is exactly what equation ( [ eq : friedotf ] ) states .",
    "the flaw in this argument  as acknowledged by fried in a footnote  is that it assumes that the image shift is statistically independent of the other components of the wavefront distortion , which is not strictly correct ( though for some purposes it is a pretty good model ) .",
    "another limitation of fried s analysis is that it identifies the image shift with the tip and tilt zernike coefficients of the wavefront . while this is qualitatively correct , the shift of the centroid of the image  which is the quantity most readily measured in the type of system considered here  differs somewhat from the tip / tilt coefficients .",
    "this problem has been reconsidered by several authors (; ; ; ) using a variety of approximations and/or simulation techniques .",
    "we now present a simple analytic calculation of the otf and psf for fast centroid guiding .",
    "the photon weighted centroid is defined as [ eq : centroiddefinition ] d^2 x g ( ) .",
    "now since @xmath105 , the gradient of the instantaneous otf is @xmath106 , so the instantaneous centroid is given by the gradient of the otf at the origin : @xmath107 where the second equality is obtained by direct differentiation of ( [ eq : otf0 ] ) , and the final result follows on integrating by parts and defining the vector valued function @xmath108 . the centroid is the average of the wavefront slope weighted by @xmath109 @xcite ; the so - called ` g - tilt ' .",
    "note that this is not quite the same as the ` z - tilt ' defined as the tip / tilt components of the zernike decomposition of the wavefront ; for a simple filled disk pupil function the z - tilt coefficients are the integral of @xmath110 times @xmath90 whereas in ( [ eq : centroid ] ) the function @xmath111 is non - zero only at the pupil edge . for low spatial frequency phase fluctuations the wavefront tip - tilt coefficients and",
    "the centroid are effectively identical , but they couple to high spatial frequency fluctuations rather differently .",
    "a key feature of the centroid is that it is a _ linear _ function of the random phase fluctuation field , a fact which greatly facilitates the following calculation .",
    "we shall need the covariance matrix for the centroid deflections , which , from ( [ eq : centroid ] ) , is [ eq : centroidcovariance0 ] _ ij _",
    "i x_j = d^2r d^2 r w_i ( ) w_j ( ) ( ) (  ) and the trace of which gives the variance of the centroid . for atmospheric turbulence",
    "@xmath90 is a statistically isotropic and homogeneous random field so @xmath112 where @xmath113 is the two - point function of the phase , and depends only on @xmath114 . for kolmogorov turbulence the phase two - point function",
    "is formally ill - defined ( in reality its value depends on the outer - scale cut - off ) and it is more convenient to work with the phase structure function @xmath115 which is well defined and has a power - law form @xmath116 , where @xmath7 is the fried length . to evaluate ( [ eq : centroidcovariance0 ] )",
    "then we replace @xmath117 by @xmath118 .",
    "the dependence on the cut - off dependent but constant term @xmath119 drops out , and in terms of the structure function @xmath120 the centroid covariance matrix is then [ eq : centroidcovariance ] _",
    "ij = - d^2r w_i ( ) ( w_j s ) _ where we have defined the convolution operator @xmath121 such that @xmath122 .",
    "the centroid covariance matrix has dimensions of @xmath123 . for kolmogorov turbulence _",
    "ij = _ ij d^-1/3 r_0",
    "^ -5/3 where @xmath124 is a dimensionless matrix depending only on the shape of the telescope input pupil . for a circularly symmetric pupil",
    "this matrix is diagonal and for a filled circular aperture we find , from numerical integration , that _",
    "ij = 6.68 _ ij ( d / r_0)^-1/3 r_0 ^ -2 .",
    "the instantaneous centroid corrected psf is , from ( [ eq : otf0 ] ) , @xmath125}\\ ] ] so the average centroid corrected otf for a long exposure , which we shall denote by @xmath126 , can be written as @xmath127 where @xmath128 just as before , for given @xmath129 , @xmath130 , the phase factor @xmath131 is a stationary ( in time ) gaussian random process so again @xmath132 but where now @xmath133 + \\bz \\cdot \\bsigma \\cdot \\bz \\cr = s(\\bz ) + \\bz \\cdot [ ( \\bw \\otimes s)_\\br - ( \\bw \\otimes s)_{\\br + \\bz } ] +   \\bz \\cdot \\bsigma \\cdot \\bz } \\end{matrix}\\ ] ] and so the corrected otf is @xmath134 +   \\bz \\cdot \\bsigma \\cdot \\bz ] / 2}.\\ ] ]    this equation , along with ( [ eq : centroidcovariance])and the definition @xmath135 , allows one to compute the otf @xmath136 for a given spectrum of phase fluctuations @xmath120 and pupil function @xmath80 .",
    "for isotropic turbulence , and for a circularly symmetric input pupil , @xmath137 is only a function of @xmath138 , so one can take @xmath130 to lie along the @xmath139-axis say in ( [ eq : fastguidingotf ] ) .",
    "note that the terms involving @xmath140 in ( [ eq : fastguidingotf ] ) are not independent of @xmath129 and so one can not factorize the fast guiding otf into a product of @xmath141 and a purely atmospheric dependent term as was the case for the uncorrected otf .",
    "the ` normalized strehl ratio ' is shown in figure [ fig : strehlplot ] .",
    "this is the ratio of the central intensity of the normalized corrected psf @xmath142 to that for a very large telescope , and is a useful measure of the image quality .",
    "this figure displays the well known result that according to this criterion the best image quality is obtained for telescope diameter @xmath22 ; for smaller telescopes the seeing is limited by the size of the airy disk while for larger telescopes tip / tilt or fast guiding becomes ineffective at reducing the phase variance .",
    "the point spread function @xmath143 computed as the fourier transform of the otf given by equation ( [ eq : fastguidingotf ] ) is shown in figure [ fig : psf3d ] for fast guiding with a telescope of optimal diameter @xmath144 .",
    "figure [ fig : otf ] shows the otf and figure [ fig : psf ] shows the radial profile of the psf . to set the physical scales in these examples",
    "the fried length was taken to be @xmath145 cm as appropriate for a good site like mauna kea at @xmath146 m and which gives uncorrected fwhm @xmath147 .",
    "there is no unique way to characterize the image quality of a telescope .",
    "it is clear from figure [ fig : otf ] that the gain in signal ( and therefore in signal to noise ) is huge for frequencies approaching the diffraction limit of the telescope , where the natural seeing otf is exponentially suppressed . comparing the natural seeing and fast guiding psfs we find :    *",
    "the normalized strehl ratio is increased by a factor @xmath148 . *",
    "the fwhm is reduced by a factor @xmath149 from @xmath150 to @xmath151 .",
    "* the resolution , according to the rayleigh - style measure of the separation of a pair of equally bright stars which just produce separate maxima after convolution , is improved by a factor @xmath152 from @xmath153 to @xmath154 . * the efficiency for detection of isolated point sources against a sky background , which is proportional to @xmath155 ,",
    "is increased by a factor @xmath156 . *",
    "the variance in position for a point source of flux @xmath157 , detected as a peak of the image smoothed with the psf , and seen on a noisy background with sky variance ( per unit area ) @xmath158 is @xmath159 ^ 2}\\ ] ] and is decreased by a factor @xmath160 .",
    "* the efficiency for weak - lensing measurements is also increased by up to about a factor 120 for small galaxies as we show in more detail in  [ subsec : lensing ] .",
    "it is apparent that there is spectacular improvement in the quality of the core of the psf . crudely speaking",
    ", one can characterize the psf as a near diffraction limited core , which , for @xmath161 , contains about @xmath162 of the light , superposed on an extended halo with width similar to the uncorrected psf .",
    "the low frequency ` halo ' can be removed by spatial filtering , and images with effectively diffraction limited resolution can thereby be generated .",
    "equation ( [ eq : fastguidingotf ] ) applies exactly only in the immediate vicinity of a guide star . what happens if we guide on the centroid of a certain star , but observe an object some finite angular distance @xmath71 away ? for a single deflecting screen at altitude @xmath59 , equation ( [ eq : fastguidingotf ] ) still holds , but with the understanding that @xmath163 be displaced from the origin by @xmath164 .",
    "( it is also relatively straightforward to generalize the analysis here to allow for finite guide star sampling frequency , or to guide using some linear combination of centroids of a number of guide stars , but we shall not elaborate on that at this point ) .",
    "the result , for a range of distances from the guide star , is shown in figures [ fig : isoplanatism1 ] , [ fig : isoplanatism2 ] .",
    "it is interesting to note that if the range of the phase deflection correlations is limited to some correlation scale length @xmath165 , as in the von karman model for instance , so the structure function becomes flat at @xmath166 , then the terms involving @xmath140 become negligible if we guide on a star which lies at distance far from the target object and we find the simple and intuitively reasonable result that the otf is the product of the uncorrected otf with @xmath167 or equivalently that the psf is the convolution of the uncorrected psf with @xmath168 which is just the distribution of the centroid deflections @xmath169 .",
    "it is interesting to compare figure [ fig : isoplanatism1 ] with the results of @xcite .",
    "they measured shapes of several stars up to @xmath170 from the guide star and saw an increase in ellipticity with distance but very little increase in size .",
    "this suggests that their @xmath170 separation corresponds to a physical separation of @xmath171 m and this would be consistent with a layer of turbulence at @xmath172 km .",
    "we have also compared the exact results obtained using ( [ eq : fastguidingotf ] ) with the ` friedian ' approximation ( that the uncorrected psf is the convolution of the corrected psf with @xmath169 ) , which is [ eq : friedotf2 ] g_fried ( ) = e^- ( s(z ) - ) g_diff ( ) . we find that the approximate otf agrees asymptotically with the exact calculation for small argument , but there are sizeable departures at large @xmath173 , and consequently the high spatial frequency features of the psf are not accurately reproduced .      in the previous sections we considered in detail the case of guiding on the _ centroid_. this was largely for the sake of mathematical convenience ,",
    "as it allowed us to derive fairly simple but exact ( at least in the near field limit ) formulae for the psf and otf , but these may not be optimal .",
    "alternatives to centroid guiding have been considered by , who has performed simulations to compare tip - tilt , centroid guiding and also the so called ` shift and add ' or ` peak tracking ' procedure where the image is centered on the peak of the brightest speckle . by construction , peak tracking will optimize the strehl ratio .",
    "other possibilities that will tend to give more weight to the central parts of the psf , and which might therefore be expected to sharpen up the image quality near the peak , are to take the average of @xmath174 , but weighted by some non - linear function of the psf . for instance , one possibility would be to define the image center as = d^2 x g^2 ( ) / d^2 x g^2 ( ) .    to explore the performance of these alternative centering algorithms",
    " which are more difficult to treat analytically  we have made simulations similar to those of christou in which we generate a large number of realizations of gaussian random field phase screens with kolmogorov spectrum and compute the integrals ( [ eq : psffromotf ] ) , ( [ eq : otf0 ] ) numerically to obtain realizations of the speckly psfs which we then re - center using various different algorithms and then sum the result .",
    "some example psfs were shown in figure [ fig : psfexamples ] .",
    "the result of averaging thousands of such psfs with various re - centering schemes are shown in figures [ fig : altpsf_3d ] and [ fig : altpsf_pro ] .",
    "the result of this analysis is that with the more sophisticated centering schemes considered here one can obtain a 15 - 25% improvement over centroid guiding and therefore an overall improvement in normalized strehl ratio of about 5 .",
    "so far we have ignored the effect of read - noise and photon counting uncertainty in the guide star position determination . of the schemes considered here these are most problematic for the centroid , and so noise considerations further favor peak tracking or some non - linear centroiding scheme .",
    "as we have seen , the photon weighted centroid is somewhat special in that it is a _ linear _ function of the atmospheric phase fluctuation , and as a consequence , should have accurately gaussian statistical properties . for non - linear centroiding or peak tracking the deflection will not be strictly gaussian  the peak displacement will have discontinuities for instance  but this does not seem to be a serious problem .    there is another subtle difference between peak tracking and centroiding which is how the evolutionary time - scale , and therefore the necessary sampling rate , depends on the height distribution of seeing . if the wind speed is @xmath175 then the time - scale for centroid motions is on the order of @xmath176 , i.e.  just the time it takes for the wind to cross the telescope pupil , regardless of whether the seeing arises in a single screen or in multiple layers .",
    "the speckle persistence time is also on the order @xmath176 for a single screen , but for multiple screens or a continuous distribution the persistence time is predicted to be @xmath177 @xcite .",
    "this is rather worrying as it would suggest that one would need much faster temporal sampling than the single screen calculation suggests .",
    "however , from numerical realizations of evolving psfs ( see  [ sec : guidestars ] below ) we find this not to be the case ; for @xmath35 we find that the timescale for peak motions is very similar for both single and multiple layer seeing , and that a sampling rate @xmath178 is adequate in either case .      in a regular ccd and with perfect guiding , the output image is a set of point like samples of the convolution of the true sky with a box - like pixel function . in an otccd device",
    "there is an additional degree of smoothing because the image moves continuously , yet the charge is shifted in discrete steps of finite size , so there is some fluctuation in image position about the effective pixel center which will have a box - like distribution function . in the design described in  [ sec : detectors ] below there are @xmath179 positions at which one can set the origin per physical pixel so this extra smoothing is relatively minor , corresponding to a 10% increase in the pixel area . to obtain a continuously sampled image",
    "it is necessary to combine a number of exposures .",
    "the image combination may involve interpolation and this will introduce some further smoothing of the image . the interpolation is however applied to the images after the photon counting noise is realized , so there is no information loss in this step , and the net effect of pixelization on signal to noise is the same as applying a single convolution with the pixel function .",
    "this sets a constraint on the pixel angular scale if the pixelization is not to undo the improvement in image quality provided by guiding . to quantify this",
    "we have taken the exact fast guiding psf and re - convolved with pixel functions of various sizes and measured the reduction in strehl ratio .",
    "we find that a pixel size of @xmath180 gives a reduction in strehl of about 20% , which we feel is just acceptable .",
    "this sampling rate is about one half of the critical sampling rate for this combination of telescope diameter and wavelength .",
    "the main constraints on the design of the telescope are that it should have a primary mirror diameter of about @xmath181 m and should be able to give diffraction limited images over a square field of side 1 degree or thereabouts .",
    "a further constraint is imposed by the cost of the detectors . since their cost scales",
    "roughly as the area of silicon ( rather than as the number of pixels ) one would like to make the pixels as small as is practical . as we discuss below in  [ sec : detectors ] a pixel size of @xmath182 m seems reasonable .    in order to meet these requirements ,",
    "we have explored several modified ritchey - chretien telescope designs employing a refractive aspheric corrector located near the focal plane .",
    "the designs give diffraction limited images over the required field of view , and we have concluded that these designs are readily buildable for a reasonable cost ( see section 7 ) .",
    "we can also consider all - reflective systems to avoid diffraction spikes and scattered light from bright stars that may be a problem with refractive correctors .",
    "such all reflective designs exist and we expect that they could be implemented for a comparable cost .",
    "as discussed , in the introduction , each telescope needs to measure positions of hundreds of guide stars scattered over the field .",
    "this is possible if the primary detector ( a segmented otccd as described in more detail in ",
    "[ sec : detectors ] ) also serves as the guide star sensor .",
    "this has the advantage of avoiding the complication and expense of pick - off mirrors and auxiliary detector , and by fast read - out of a small patch around each guide star one can sample at rates in excess of 100  hz which is more than adequate .",
    "disadvantages of this approach are that one then loses that element of the ccd array , of say an arc - minute in size , for science , and that the guide stars must be observed through whatever filter is needed for the science measurements , with concurrent loss of photons .",
    "the purpose of this section is to provide estimates of the rate at which photons are collected as a function of telescope aperture and guide star brightness , the rate at which we must sample image motions , and the constraints these place on the number of usable guide stars .    scaling from the performance of existing thinned ccd cameras on mauna kea",
    ", we expect that a good , backside illuminated ccd will accumulate about one electron per second from a source of @xmath183 magnitude m_1 = 24.6 + 5(d/1.5 ) , ( in the i - band the corresponding value is @xmath184 ) . hence an exposure of @xmath72 of a source of magnitude @xmath185 should yield @xmath67 electrons : n = t 10 ^ -0.4(m - m_1 ) .",
    "this is the total number of electrons . with fast guiding ,",
    "what is more relevant is the number of electrons in the diffraction limited core of the psf which is @xmath186 with @xmath187 for peak tracking .",
    "the centroid or peak position will vary with time primarily because the deflecting screen is being convected along at the wind speed . in what follows",
    "we will adopt a fiducial speed of @xmath188 m/s .",
    "this converts to a coherence time for peak motions of @xmath189 . for given guide star brightness",
    "there is an optimal choice of sampling rate , since if the sampling rate is too high then the star centroid or peak location will be uncertain because of measurement error , while if the sampling rate is too slow the time averaged position will not accurately track the instantaneous position . to make this more quantitative",
    "we have made simulations in which we generated a large kolmogorov spectrum phase screen from which extracted a sequence of closely spaced pupil - sized sub - samples , and for each of which we computed the instantaneous psf using ( [ eq : otf0 ] ) .",
    "this stream of psfs was averaged in pixels with appropriate angular size according to subsection [ subsec : pixelization ] above , and averaged in time with with some chosen integration time , and the result was then converted to a photon count by sampling in a poissonian manner and adding read noise , the mean of which was taken to be @xmath190 .",
    "a simple peak - tracking algorithm  locate the hottest pixel and then refine the position using 1st and 2nd derivative information computed from the neighboring pixels  was then applied to the simulated pixellated images , and the psf for target objects was calculated by shifting the instantaneous psfs to track the peak and then averaging .",
    "this calculation was performed for a coarse grid of star luminosities and integration times .",
    "as expected , for bright objects we find the optimal sampling rate is quite high , while for fainter objects the measurement uncertainty tilts the balance towards longer integration times .",
    "a good compromise for realistic guide stars is to take an integration time of about @xmath191 corresponding to a sampling rate of about 10 hz for our fiducial @xmath188 m/s wind speed and diameter of @xmath55 m .",
    "for very bright stars this is not optimal , but the gain obtained by sampling faster is rather small . with this sampling , we find negligible reduction in strehl ( as compared to rapid sampling of a very bright guide star ) for stars which generate about 4000 electrons per second , or about 400@xmath192 per sample time , of which @xmath193 are in the diffraction limited core .",
    "this corresponds to an @xmath183 magnitude limit of m_4000 = 15.6 + 7.5(d/1.5 ) ( @xmath194 in the i - band ) .",
    "the number of stars per square degree at the north galactic pole brighter than @xmath183 magnitude @xmath195 is approximately [ eq : bscountsmodel ]     n(<m_r ) = 2.810 ^ -9 m^9.2 n(<m_i ) = 5.610 ^ -9 m^9.1    equation ( [ eq : bscountsmodel ] ) is a good fit to the model over the range @xmath196 , and gives a number of sufficiently bright guide stars per square degree of approximately n(<m_4000 ) = 265(1 + 4.4(d/1.5 ) ( @xmath197 in the i - band ) .",
    "this number density corresponds to a mean separation @xmath198 .",
    "as this is greater than the coherence angle for turbulence at altitudes higher than a few km , an instantaneous measurement of the deflections of a set of guide stars does not provide sufficient information to fully determine the deflection field . in making these estimates",
    "we have erred somewhat on the side of caution .",
    "for example , for stars which are a factor 4 ( @xmath199 magnitudes ) fainter than the limiting magnitude quoted above the resulting target image strehl is reduced by about 30% , so there is still a reasonable fraction of light in the diffraction limited core ( around @xmath31% rather than @xmath200% of the total ) and this increased the number density of stars by about a factor 2.5 .",
    "this result is illustrated in figure [ fig : peaktracking ] .",
    "also , observations at lower galactic latitude will yield higher guide star densities by a factor @xmath201 , but the conclusion remains that over most of the sky the sampling provided by natural guide stars is somewhat too low to fully determine the deflection field from high altitude seeing . in the next section we explore how one can obtain complete sampling of the deflection  and therefore guide out image motions for all objects  using an array of telescopes and using the past history of guide star motions .",
    "in this section we explore the correlations between neasured deflections of guide stars and how to use these to compute the deflection field needed to control the otccd charge shifting .",
    "we first discuss the properties of conditional mean field estimators which seem particularly appropriate for the problem .",
    "we then consider the case of a single thin layer of high altitude turbulence , and then discuss the generalization to multiple or thick layers of turbulence , including ground level turbulence .",
    "the problem here is that we wish to infer the deflection for a target object from measurements of the deflection for a set of guide stars .",
    "there are various ways one might do this .",
    "the approach we prefer is to use the _",
    "conditional mean deflection_.    consider first the simple case of a 1-component gaussian field @xmath202 with correlation function @xmath203 and where we have a single measurement of @xmath204 .",
    "the conditional probability distribution for the field @xmath205 at some point @xmath206 given a measurement of the field @xmath207 at some other point @xmath208 is p(f_1 | f_2 ) = p(f_1 , f_2 ) / p(f_2 ) which is bayes theorem .",
    "according to the central limit theorem , the joint probability distribution @xmath209 is given by ( [ eq : multivariatepdf ] ) . here",
    "the covariance matrix is simply @xmath210 so ( [ eq : multivariatepdf ] ) yields [ eq : conddef ] p(f_1 |",
    "f_2 ) = ( - ) this conditional pdf is just a shifted gaussian with conditional mean @xmath211 and with variance @xmath212 . at small separations",
    "the conditional mean field is equal to the measured field , but relaxes to zero with increasing separation as @xmath213 . thus the conditional mean estimator fails gracefully in the absence of useful information ( i.e.  far from the measurement point ) .",
    "compare this with the behavior for an alternative , which is to use a maximum likelihood estimator .",
    "the likelihood is defined as the probability of the ` data ' , in our case @xmath207 , as a function of the parameter @xmath205 .",
    "the likelihood is therefore l(f_1 ) = p(f_2 | f_1 ) = p(f_1 , f_2 ) / p(f_1 ) which is the same as the expression for the conditional probability , but with @xmath205 and @xmath207 interchanged so from ( [ eq : conddef ] ) it follows that the value of @xmath205 which maximizes the likelihood is @xmath214 . like the conditional mean ,",
    "this is effectively equal to the measured field if the separation @xmath215 is much less than a correlation length , so @xmath216 , but the solution blows up when the separation becomes large and @xmath217 , which is clearly undesirable for our application .",
    "a rather general feature illustrated by this simple example is that the conditional probability also provides one with a measure of the variance in the conditional mean field estimator @xmath158 , which is zero close to the measurement point and rises to become equal to the unconstrained variance @xmath218 at points sufficiently distant from the measurement point that the correlation with the measurement effectively vanishes .",
    "the simple example of a single measurement of a 1-component field is readily generalized to the case where we have multiple measurements and wish to constrain multiple target field values ( the two components of the target deflection for example ) .",
    "let us assume that one has @xmath219 target values @xmath220 ,",
    "@xmath221 which one would like to constrain with @xmath185 measurements @xmath222 , @xmath223 .",
    "let the covariance matrix be @xmath224 , where @xmath69 , @xmath225 range from @xmath226 to @xmath227 with @xmath228 . the joint conditional mean probability distribution is p(f_0 , f_1 ",
    "f_n-1 | f_n , f_n+1 ",
    "f_n+m-1 ) p(f_0 , f_1 , ",
    "f_n+m-1 ) ( - m_ij^-1 f_i f_j / 2 ) ignoring factors which are independent of the target values @xmath229 this can be written as p (  f_i  |  f_l  )",
    "( - m^-1_ij ( f_i - f_i ) ( f_j - f_j ) / 2 ) where @xmath230 , @xmath231 range from @xmath226 to @xmath232 and repeated indices are summed over .",
    "this is a shifted gaussian with conditional mean [ eq : conditionaldef ] f_i = m_ij _ i = n^n - 1 m^-1_ji f_i and with @xmath233 error matrix [ eq : errormatrix ] m_ij ( f_i - f_i ) ( f_j - f_j ) = ( m^-1_ij)^-1 .",
    "note that the meaning of this equation is to take the upper - left @xmath233 sub - matrix from the inverse of the large matrix @xmath234 and to invert this .",
    "equation ( [ eq : conditionaldef ] ) provides our estimate of the target values , while equation ( [ eq : errormatrix ] ) provides the uncertainty in these estimates .",
    "source motions due to high altitude turbulence are expected to be correlated only over limited angular separations .",
    "the statistical character of the centroid deflection field is illustrated in figure [ fig : deflection ] which shows the deflection field expected for a single turbulent layer .",
    "the patch shown here is @xmath235 m on a side and would subtend about @xmath236 at an altitude of @xmath237 km . with typical wind velocities of",
    "say @xmath188 m/s this patch would be convected through its own length in a few seconds .",
    "the range of correlations between deflections is shown more quantitatively in figure [ fig : covariance ] .",
    "since the deflection is a vector , its covariance function is a tensor : @xmath238 . in a frame",
    "in which the lag @xmath129 is parallel to the @xmath139-axis this is diagonal and we define @xmath239 and @xmath240 .",
    "one can then obtain @xmath241 in the general frame by applying the rotation operator .",
    "the parallel and perpendicular deflection correlation functions are given by [ eq : xidef ]     _ ( r ) = k^2 p(k ) w^2(k ) ( j_0(kr ) - j_2(kr ) ) _ ( r ) = k^2 p(k ) w^2(k ) ( j_0(kr ) + j_2(kr ) )    where @xmath242 , @xmath243 are bessel functions , and with w(k ) = _ 0^d/2 dr r j_0(kr ) and where @xmath30 for kolmogorov turbulence .",
    "while one should really use diffraction theory to compute how the image quality degrades with imperfect guiding information , to an approximation which should be sufficiently accurate for our present purposes we will adopt the ` friedian ' approximation and assume that the real psf will be the psf for perfect guiding convolved with the distribution of errors in the centroid estimate which can be inferred from figure [ fig : covariance ] .    in standard tip / tilt implementations the whole image",
    "is shifted , with the shift determined from a single guide star . according to figure [ fig : covariance ] this will give good image quality within the angular scale which projects to one telescope beam width at the altitude of the deflecting layer , or about @xmath2 or so . at larger separations",
    "the image quality will deteriorate , with a tendency for the psf to first become elongated in the radial direction ( because the radial component of the deflections decoheres more rapidly with distance ) , and at very large separations the centroid motion will be totally uncorrelated with the motion of the distant guide star and this ` over - guiding ' will actually cause a deterioration of the image quality as shown in figures [ fig : isoplanatism1 ] , [ fig : isoplanatism2 ] . with an otccd array one can guide separate parts of the focal plane independently , and",
    "this opens up many possibilities for improvement .",
    "even with a single guide star , one can do better by using a guiding signal which is the conditional mean deflection at the point in question , given the measured deflection of the star at some other point .",
    "as discussed , the conditional mean will relax towards zero at large distance from the guide star , and this will at least solve the over - guiding problem .",
    "more interestingly , we can use the multi - variate conditional probability machinery to compute a conditional mean deflection field given measurements of a number of guide stars .",
    "unfortunately , with a single telescope , most target points are too far from guide stars to gain much improvement .",
    "this is illustrated in the lower left panel figure [ fig : conddef ] which shows the variation in image quality , which was computed from the uncertainty in the conditional mean deflection , given a set of measurements of the deflection  assumed to be due to a single layer of turbulence  for a set of randomly placed guide stars with realistic number density . aside from generally small islands of small error very close to the guide stars ,",
    "there is large uncertainty in the centroid motion and the most probable deflection will be quite small in these uncertain regions and the increase in image quality quite meager .",
    "more complete sky coverage is possible with an array of telescopes .",
    "adding extra telescopes which monitor the motions of the same set of guide stars will provide additional samples of the deflection field with the same pattern as for a single telescope , but stepped across the deflecting screen by the telescope separation , as was illustrated in figure [ fig : beamsplot ] .",
    "if the telescope spacing is much greater than the mean separation of guide stars then the result is essentially a poisson sample of deflections with sampling density enhanced by a factor @xmath244 , this being the number of telescopes in the array .",
    "the results for various @xmath244 values are shown in figure [ fig : conddef ] .",
    "the image quality increases dramatically with the number of telescopes . with @xmath245 ,",
    "the typical fractional position variance is @xmath246 , which is very accurate indeed , and essentially all points on the sky have image quality close to the maximum allowed , so with this sampling density one can accurately predict the motion of any target object . note that as the sampling density is increased there is a rather sharp transition as the area wherein the deflection is well determined ` percolates ' across the field .",
    "figure [ fig : conddef ] can also be interpreted as giving the performance of a single telescope for a single deflecting layer at altitude @xmath247 km .",
    "thus , under favorable conditions one could expect to obtain good performance with a single instrument , but this would be the exception rather than the rule .    in this analysis only the instantaneous guide star deflections were used . under the ` frozen turbulence ' or",
    "` taylor flow ' assumption there is more information at our disposal encoded in the history of the guide - star deflections , which provide a set of line - like samples of the deflection fields lying parallel to the wind direction . for a given target point ,",
    "the most valuable information will come from those guide - stars lying up - wind and at a time lag given by the spatial separation divided by the wind speed . in the frozen turbulence assumption",
    "the mean number of such trails passing within say @xmath248 of a given point is roughly @xmath249 , where @xmath219 is the number density of guide stars , and @xmath61 is the field size ( using angular units of arc - minutes ) . for a field size of one degree and @xmath250",
    "say , this we expect about @xmath251 trails on average passing within a correlation length of a typical target point . for @xmath252 this would give a very dense sampling rate .",
    "however , it may be over - optimistic , as it assumes that the turnover time for @xmath253 sized eddies is as long as the time - scale for the layer to sweep across the whole field @xmath254 which is several seconds .",
    "if the turnover time is shorter , then the correlations will decay more rapidly , and one should replace @xmath61 in the sampling density estimate by the angular distance an eddy propagates in one turnover time .",
    "anecdotal evidence suggests that the frozen turbulence approximation appears to be well obeyed over scales of several meters , so this would suggest that one should expect to obtain a substantial gain in sampling density by using temporal information .",
    "the improvement of image quality afforded by temporal history is shown in figure [ fig : conddefx ] assuming that the turbulence is effectively frozen for displacements of 5 m and 10 m respectively , corresponding to times of @xmath255s for wind speed of 10 m/s .",
    "this is quite promising as it shows that even with a single telescope one can obtain good image quality over large areas of the sky , and that with just a few telescopes one should be able to obtain essentially full coverage .",
    "we caution , however , that this conclusion is strongly dependent on the assumption of a single deflecting screen .    in the calculations shown in figures [ fig :",
    "conddef ] , [ fig : conddefx ] the height of the deflecting layer was assumed known and the covariance matrix @xmath234 was computed from ( [ eq : xidef ] ) . in reality",
    "we would need to measure the covariance matrix from the actual measured guide star deflections . for a thin deflecting layer at height @xmath59 and moving with velocity @xmath256",
    "the deflection covariance function is _ i ( , , t ) _",
    "j( ,  , t ) = c _ ij ( + h + t ) where @xmath257 is the deflection of a guide star with position @xmath258 on the sky seen with a telescope at position @xmath259 at time @xmath260 , @xmath261 etc .  and @xmath262 is a measure of the intensity of the layer .",
    "the covariance function can be estimated by averaging products of pairs of deflections . for a regular grid array of telescopes and uniform sampling in time , one obtains samples of the covariance on a uniform grid in @xmath263 , @xmath72 space , which is just what one needs .",
    "the sampling in angle space @xmath71 is a little more problematic since the guide stars are randomly distributed , and yet one needs to evaluate the covariance at the angular separation between a guide star and the target object , which will not in general coincide with the separation between any particular pair of guide stars . to solve this",
    "one can bin the pairs into a grid of finite cells in @xmath71 space and , if necessary , interpolate to obtain the covariance at the desired separation .",
    "this should not be too difficult .",
    "if one has say @xmath264 guide stars on a @xmath265 field then the number of pairs per @xmath266 correlation area is @xmath267 which should be adequate ; the probability of having an empty cell if we bin into cells of @xmath268 size is very small , and interpolation over any patches should be fairly safe .    in principle , one could compute the covariance matrix for all pairs of observations and then invert the resulting matrix . computing",
    "the full covariance matrix would be time consuming , but not insurmountably so . for @xmath269 guide stars , and @xmath270 telescopes , and if we keep a running history of say @xmath271 previous measurements then we have @xmath272 pairs of measurements at any one time .",
    "since the time history will be uniformly sampled the @xmath72 correlations can be performed with a fft , and similarly for the @xmath273 correlations if the telescopes are laid out on a regular grid . with this simplification ,",
    "the time complexity of the covariance matrix accumulation is essentially that of performing @xmath274 small ( @xmath275 ) ffts every second or so which is not overwhelming since commercially available dsp devices perform ffts at a rate of @xmath276 m floating point data values per second .",
    "the real problem with this ` sledgehammer ' approach is that to compute the conditional mean we will need to _ invert _ this huge @xmath277 matrix , which is prohibitively expensive in computational effort and is probably also numerically unstable .",
    "luckily we do not need to do this .",
    "as discussed , the most valuable information pertaining to the deflection of a target object will come from the relatively small number of guide stars that are seen through the same patch of turbulence at some up - stream position .",
    "it is easy to identify which these observations are since they are those for which the correlation with the target object deflection is particularly strong , and so one need only work with the small subset of the full covariance matrix that involve these critical observations , and this greatly reduces the amount of computation .",
    "this was the approach used in computing figure [ fig : conddef ] where only a subset of the guide stars were used for each pixel of the image .",
    "the matrix inversion need only be done infrequently ; on the rather long time - scale for macroscopic conditions such as wind speed , turbulence strength etc .  to change .",
    "an instantaneous measurement of the covariance function will of course be noisy as we are sampling a single realization of a random process with finite extent in size and time .",
    "however , since the correlation time is on the order of the eddy turnover time of perhaps a few seconds , we can obtain statistically independent samples at intervals of order this time , so by averaging over several minutes say one should be able to determine the ensemble average covariance very accurately .",
    "the computation of the mean deflection needs to be done on a very short time - scale ( a few tens of hertz ) but this is computationally a much easier task .",
    "a pleasant feature of this approach is that one can be fairly liberal in selection of guide stars ; faint stars give more uncertain positions which therefore correlate less with other more precisely measured motions .",
    "the correlation matrix machinery ` knows ' this and will automatically give these stars the weight they deserve .",
    "equation ( [ eq : conditionaldef ] ) provides the guide signal for the target cell of the detector . as discussed , in the friedian approximation",
    ", the actual psf is the psf for perfect fast guiding convolved with a gaussian ellipsoid @xmath278 .",
    "this is useful since the image quality for a given patch of sky will vary from telescope to telescope and with position within the field , so ( [ eq : errormatrix ] ) provides a useful criterion for rejecting or down - weighting poor images or sections thereof .",
    "the procedure outlined above is somewhat inefficient in that it requires the computation of a fairly large matrix for each target .",
    "neighboring target cells will tend to correlate strongly with the same set of guide stars , so the set of stars which correlate strongly with one or more of a cluster of neighboring cells will likely be not much larger than the set which correlate strongly with any individual cell .",
    "if so , then a great saving in computational effort can be made by computing the conditional probability for the deflections for the cluster of target cells at one go .",
    "the foregoing analysis was somewhat idealized in that a single thin layer of turbulence was assumed .",
    "if there are multiple or thick layers then the situation is somewhat more complicated .",
    "nonetheless , given the huge amount of information at our disposal we believe that the conditional probability approach should still work , though depending on the nature of the turbulence there may be non - trivial constraints on the layout of the telescope array .",
    "consider first the case of a single _ thick _ layer at high altitude .",
    "the procedure outlined in the previous section will then fail if the baselines between the telescopes are too large .",
    "the problem is that the deflection for a target object at the zenith say will sample a vertical tube through the layer while a guide star seen from a different telescope at distance @xmath70 will sample a tube which is inclined at an angle @xmath279 , and even if these two tubes overlap exactly in the center of the layer the deflections will tend to decohere if the thickness of the layer exceeds the value @xmath280 .",
    "unfortunately , the observational situation is somewhat unclear as e.g.  scidar measurements tend to be limited in height resolution . for a width",
    "@xmath281 m say , and @xmath282 km this implies the constraint on the size of the array @xmath283 m .",
    "this is not very restrictive .",
    "a further possible complication is wind shear across a thick layer which will tend to modify the deflection correlations .",
    "now consider multiple deflecting layers . according to the admittedly rather patchy observational studies reviewed above ,",
    "one quite common situation is for there to be an additional strong component of seeing coming from the planetary boundary layer and from the immediate environment of the telescope , the so - called ` dome seeing ' .",
    "this is quite easy to deal with since it causes a common deflection for all of the guide stars for each telescope .",
    "if we simply take the mean deflection and subtract this , provided we have numerous guide stars and a sufficiently wide field then the residual guide star deflections after we subtract the mean should be essentially those due to the high altitude turbulent layer alone , and we can proceed as before .",
    "there are other means at ones disposal to further reduce the effect of low level turbulence .",
    "very low level refractive index fluctuations can be homogenized by means of louvred enclosures and/or fans .",
    "the telescopes here are light and are auto - guiding , so it is not unreasonable to consider some kind of elevated support to raise them above very low level seeing .",
    "also , since the isoplanatic angle for low level seeing is very large one can consider doing higher order wavefront correction with a deformable secondary .",
    "one way to implement this would be to augment the individual telescopes with smaller telescopes deployed around the periphery of the primary mirror which measure the average deflection of say a few tens of bright guide stars within the field . by taking the average , one effectively isolates the effect of the dome and boundary layer , and one can show that with say 6 such auxiliary telescopes  which provide an extra 12 constraints in the form of samples the peripheral wavefront tilt  one can effectively negate the effect of even quite strong low - level seeing .",
    "provided low level seeing can be effectively eliminated by one or other of these approaches , one would then tune the aperture of the main telescopes such that they have diameter 4 times the @xmath7 for the ` free - atmosphere ' seeing alone , as we have assumed above .",
    "more difficult is the case where there are two or more high altitude layers giving a significant and comparable contribution to the deflection",
    ". it would be tempting to argue that since the strength of individual layers appears to have a highly non - gaussian distribution with large dynamic range , having several layers of very similar strength is statistically improbable .",
    "however , this is probably over - complacent for the following reason : in the scheme outlined above , and with a relatively weak secondary deflecting layer , the correlation machinery will ` lock on ' to the primary layer , with the net result that the sharp corrected image will get convolved with the natural seeing psf for the second level .",
    "this can result in a significant loss of image quality even for a rather weak secondary layer . as a specific example , a secondary layer contributing only 4% of the total deflection power produces a reduction in strehl of about 25% , so it is clearly highly desirable to have a guiding algorithm which can cope with multiple layers .",
    "the problem here is not lack of information ; with tens of telescopes , hundreds of guide stars and many time - steps in the history of the deflections one has a huge amount of information with which one should be able to separate the effects of multiple layers . in principle",
    "one could simply compute and invert the full covariance matrix to obtain the conditional deflection .",
    "indeed , a rather nice feature of this sledgehammer approach is that there is then no need to try to solve for a set of discrete layer heights and intensities ; the probability engine takes care of it automatically , as all the relevant information is encoded in the covariance matrix that one measures .",
    "the real problem here is how to decipher the information in a realistic amount of time . for a single layer",
    "it is relatively easy to identify and isolate a relatively small number of critical measurements which have a bearing on a given target object deflection . for multiple layers",
    "this is not the case , and a different approach is required .",
    "what is needed is some way to at least approximately diagonalize the covariance matrix , so that one can avoid having to invert it all at once . given the statistical translational invariance of the gaussian random deflection screens we are dealing with , a natural approach is to work in fourier space .",
    "let us assume that we have a set of discrete deflecting layers at heights @xmath59 , streaming across the field with velocities @xmath284 , and let us model the deflection field ( which we will denote by @xmath285 here ) as a function of telescope position @xmath259 , angular position @xmath258 and time @xmath260 as [ eq : multilayermodel ] * f * ( , , t ) = _ h * f*_h(+ h + _ h t , t ) . in the perfect frozen flow limit @xmath286 would depend on time only implicitly through the spatial coordinate @xmath287 .",
    "the inclusion of an explicit dependence of @xmath286 on time @xmath260 here allows for the evolution of the deflection field due to the turnover of eddies , though as discussed , we expect that the explicit time dependence will be rather slow as compared to the typical induced time dependence due to the motion of the screen .",
    "the deflection field is a random function of position and time and can be expressed as a fourier synthesis [ eq : fouriersynthesis ] * f*_h ( , t ) = _ h ( , ) e^-i(+ t ) where the statistical homogeneity , stationarity and isotropy of the individual phase screens and their assumed mutual independence implies that distinct fourier modes are statistically independent : [ eq : powerspectrumdefinition ] f_hi ( , ) f^*_hj( , )= ( 2 ) ^3",
    "_ hh _ ij ( -  ) ( -  ) p_h(k , ) where @xmath288 is the spatio - temporal power spectrum of the layer at height @xmath59 , and reality of @xmath289 imposes the symmetry @xmath290 . for kolmogorov turbulence the spatial power spectrum",
    "@xmath291 is a power law @xmath292 at low spatial frequencies , with the smoothing with the telescope pupil introducing a high-@xmath293 cut - off at @xmath294 .",
    "kolmogorov theory also tells us that the typical eddy velocity scales as the @xmath295 power of the eddy size , or equivalently as @xmath296 , so the width of @xmath288 in temporal frequency must scale as @xmath297 .",
    "an acceptable model for @xmath288 for a thin layer of turbulence is then [ eq : pkwmodel ] p_h(k , ) = p_h ( , ) ( , ) = k^-5/3 t^2(k ) ( / _ * ) / _ * ( k ) with @xmath298 and where @xmath299 is the fourier transform of the telescope pupil , which , for a simple filled circular aperture , is the ` airy - disk ' function .",
    "this model is parameterized by an overall intensity @xmath300 and by @xmath301 which is the turnover time for eddies of spatial frequency @xmath294 .",
    "the function @xmath302 is dimensionless , bell - shaped , and of unit width , which we take here to be approximately gaussian . in 3-dimensional @xmath303 space",
    "the model ( [ eq : pkwmodel ] ) is a disk of with axis parallel to the @xmath304-axis , radius @xmath305 , and with scale height @xmath306 .",
    "the assumed gaussian form of the vertical profile @xmath307 here is crude guess , and one would want to modify this in the light of either empirical observations and/or more sophisticated theoretical modeling .    consider a particular telescope at position @xmath308 and at the present time , which we take to be @xmath309 , and define the angular transform of the deflection at angular frequency @xmath310 as @xmath311 , where the subscript @xmath61 on the integral indicates that the integration is taken over the field of size @xmath61 . using ( [ eq : multilayermodel ] ) , ( [ eq : fouriersynthesis ] ) we can express @xmath312 in terms of the spatio - temporal fourier mode coefficients as [ eq : f0 ] * f*_0 ( ) = _ h _ h ( , ) e^-i_0 w_(- h ) where @xmath313 .",
    "if we take the field to be a square of side @xmath61 then this is a 2-dimensional sinc function : [ eq : wbar ] w _ ( ) = ^2 ^2 _ x / 2 ( _ x / 2)^2 ^2 _ y / 2 ( _ y / 2)^2 this function has a ` central lobe ' at @xmath314 of height @xmath315 and width @xmath316 flanked by side lobes of oscillating sign which diminish rapidly with increasing @xmath310 , so @xmath312 depends only on those fourier modes in a small range of spatial frequency of size @xmath317 around @xmath318 , this being the spatial frequency which maps to the chosen angular frequency @xmath310 at altitude @xmath59 .",
    "if @xmath319 then the complex phase factor @xmath320 in ( [ eq : f0 ] ) is nearly constant and so @xmath312 is the product of @xmath321 with a cylindrical window function which is infinitely long in @xmath304 and has width @xmath317 .",
    "if on the other hand @xmath322 then the variation of the phase factor is appreciable for typical @xmath323 and the window function has oscillatory modulation with scale length @xmath324 .",
    "similarly , if we define the 5-dimensional fourier transform of the measured deflections as [ eq : fdef ] ( , , ) = _ , , t * f * ( , , t ) e^i ( + + t ) then , in terms of the transform of the deflection screens @xmath325 , this is [ eq : ffromtildef ] ( , , ) = _ h _ h( ,  ) w_x(-  ) w_(- h  ) w_t(-  -  _ h ) where @xmath326 is the fourier transform of the telescope array ; @xmath327 is the transform of the guide star distribution and @xmath328 is the transform of the of the temporal sampling pattern . now all of these functions are quite strongly peaked at zero argument , @xmath329 has width @xmath330 of order the inverse of the telescope array size @xmath83 , @xmath331 has width @xmath316 ( like @xmath332 ) and @xmath333 has width @xmath334 equal to the inverse of the time period @xmath335 over which we choose to integrate .",
    "consequently , and like @xmath312 , @xmath336 receives a large contribution from a restricted region of spatial frequency around @xmath337 . unlike @xmath312",
    "however , the contribution to @xmath336 is also restricted in altitude and temporal frequency since for the argument of @xmath331 to be small requires both that @xmath310 point in approximately the same direction as @xmath338 and that the ratio of angular to spatial frequency @xmath339 should coincide with the altitude of an actual layer of turbulence . finally , @xmath340 is most sensitive to temporal frequencies of the deflection screen @xmath341 which means , if we assume that the intrinsic deflection screen evolution time - scale is long compared to @xmath191 , that @xmath336 is only sensitive to a screen at altitude @xmath59 if the screen velocity satisfies @xmath342 , where @xmath343 is on the order of the inverse of the eddy turnover time",
    ".    equations ( [ eq : f0 ] ) and ( [ eq : ffromtildef ] ) above give @xmath344 and @xmath336 respectively as integrals of @xmath345 times some window function .",
    "however , the window function for @xmath336 is in all dimensions at least as narrow as the window function for @xmath344 , and therefore @xmath312 , from which we can trivially extract the desired guide signal @xmath346 by inverse transforming , should be well constrained by measurements of @xmath336 taken at appropriate spatial , angular and temporal frequencies .",
    "since these are both linear functions of @xmath347 they should have gaussian statistics , and so one can write down the conditional probability [ eq : poffk ] p(*f*_0 ( ) | (  ,  ,  ) , (  ,  ,  )  ) from which one can determine the conditional mean value of @xmath312 , very much as was done before for a single deflecting layer . let us assume for the moment that @xmath348 and the velocities @xmath284 are known .",
    "if so , the covariance matrix in the multi - variate gaussian distribution ( [ eq : poffk ] ) has components like     f^*_0i( ) f_j ( , , ) = _ ij _ h p_h(k ,  ) e^-i _ 0 w_x(-  ) w_(- h  ) w_t(-  -  _ h ) w_^*( - h  )    since the various window functions here are known and compact , it is straightforward to enumerate the limited number of 5-dimensional transform modes which are relevant for any given @xmath310 , evaluate the appropriate covariance matrix and thereby obtain an accurate conditional mean estimator for @xmath312 as a linear combination of a limited subset of the @xmath336 values .    to implement this program",
    "we need some way of determining @xmath288 .",
    "if we evaluate @xmath336 at @xmath349 , square it and take the expectation value : @xmath350 , then from ( [ eq : powerspectrumdefinition ] ) , ( [ eq : ffromtildef ] ) we have [ eq : tildepestimate ] p_f(h , , ) = n_t^2 _ h d^2 k(2 ) ^2 p_h(k , - _ h  ) w_x^2(-  ) w_^2(h- h  ) where we have taken the integration time to be greater than the eddy turnover time - scale to effect an integration over spatial frequency .",
    "as already discussed , a layer of turbulence has a spatio - temporal power spectrum which is a flaring disk of thickness @xmath343 so the quantity @xmath351 appearing above is also a disk , but is inclined with respect to the @xmath352 plane with mid - plane gradient @xmath353 .",
    "furthermore , if the @xmath9-sized eddy turnover time is much less than the translation time - scale @xmath354 , as the observations indicate , then @xmath355 , so the vertical displacement of the disk is large compared to its thickness .",
    "if @xmath59 coincides with an actual deflecting layer , and if we consider for the moment only the contribution from that layer @xmath356 , then @xmath357 is a 2-dimensional convolution of this thin tilted disk with the function @xmath358 .",
    "now this function has width @xmath359 whereas the intersection of the inclined disk with a plane @xmath360 constant has width @xmath361 so provided @xmath362 ( i.e.  the eddy turnover time is short compared to the time - scale for the eddy to be convected across either the entire field or the overall extent of the array , whichever is greater ) then @xmath363 and the convolution has little effect and therefore p_f(h , , ) p_h(k , - _ h ) and one can determine @xmath364 by fitting for inclined versions of disk models of the form ( [ eq : pkwmodel ] ) directly to the measured power spectrum @xmath357 one particularly simple way to achieve this would be to compute p(h , ) d^2 k d ( , - ) p_f(h , , ) the local maxima of which should coincide with the heights , velocities of the various layers .",
    "it is important in what follows to have a clear picture of the form of the power spectrum @xmath357 which , being four dimensional , is somewhat difficult to visualize . to this end , imagine you are sitting in the control room of a wide field imaging array .",
    "measurements of guide star deflections have been recorded and transformed to produce @xmath365 and you are viewing a graphics device with a 3-d renderer displaying an isodensity surface of the measured power @xmath357 in @xmath338 , @xmath304 space , integrated over perhaps ten minutes or so , for a given altitude @xmath59 .",
    "a widget on the screen allows you to control the altitude . at first",
    "you see nothing . as you slowly vary the altitude suddenly a disk like structure springs into view , as shown schematically in figure [ fig : diskplot ] .",
    "the radial extent of the disk has an airy disk form as given by the model ( [ eq : pkwmodel ] ) , and it has the expected bell - shaped vertical profile . wiggling the altitude control you estimate that the width of this structure is @xmath366 .",
    "this is the signature of a horizontally convecting layer of seeing .",
    "the disk is tilted ( actually sheared ) , from which you can read off the wind velocity vector , and the thickness tells you how fast it is evolving internally .",
    "further variation of the altitude reveals a number of further layers with different strengths and velocities and perhaps thicknesses , but otherwise matching the pre - determined template .",
    "results of the kind described would lend credence to the idea that the behaviour of the atmosphere can indeed be characterised by a tiny subset of all the fourier components computed , and that the fourier transform of the actual deflection at the present instant @xmath312 may be accurately given by a linear combination of a small set of @xmath336 values , and that this might allow one to freeze out the motion of all the images in the field .",
    "however , the display device also has a widget to control the level of the isodensity contour plotted .",
    "as you increase the contrast the picture changes radically . the disk centered on the origin swells as expected , but rather suddenly a set of additional low level structures appear laid out on a grid in the @xmath352 plane .",
    "the spacing of these structures is @xmath367 where @xmath273 is the spacing of the telescopes  so the spacing is small compared to the extent of the disk  and on closer inspection they are seen to be well modeled by superpositions of weak replicas of the disks seen in the high iso - surface level scan , but with seemingly random strengths .",
    "this background of low level ghost images also persists when you tune the altitude control to arbitrary positions .",
    "what is happening here is aliasing of deflection power from spatial frequencies differing from the target frequency by integer multiples of @xmath368 , and from different heights @xmath369 . in the foregoing",
    "we have assumed that @xmath329 , @xmath331 are narrow functions of their arguments , and we have approximated the values of various integrals by simply integrating over the ` central lobe ' of these functions .",
    "this is a good first approximation to be sure , but in fact both of these functions have extended side - lobes . for a regular grid telescope array , @xmath370 has the form of a 2-dimensional sinc function with central value @xmath371 and width @xmath372 but this pattern repeats with period @xmath368 .",
    "similarly , @xmath373 has a central lobe of height @xmath374 and width @xmath316 , but for @xmath375 the function @xmath376 is effectively the sum of @xmath377 random plane waves with random phases , so it resembles a gaussian random field with coherence length @xmath378 and with mean square value @xmath379 .",
    "these weak but extended side - lobes will alias power from different spatial frequencies @xmath380 and from different layers @xmath369 into @xmath381 but not into @xmath312 .",
    "this leakage of power will result in imprecision in the conditional mean estimator .    to understand the conditions for obtaining an accurate deflection model let us assume that we have correctly identified the the strengths and velocities of the deflecting layers , and that we have computed @xmath381 for a spatial frequency @xmath382 and a temporal frequency lying within a particular layer ;",
    "i.e.  for a point lying within the disk shown in figure [ fig : diskplot ] . the key question is what fraction of @xmath381 actually arises within the layer at the height @xmath59 and what fraction is aliased from entirely different layers ?",
    "we can infer the answer to this question from inspection of equation ( [ eq : tildepestimate ] ) .",
    "this integral will have a central lobe or ` primary ' contribution and an integrated side - lobe or ` aliased ' contribution .",
    "the primary contribution comes from @xmath337 and is @xmath383 or p_f(primary ) p_h n_s^2 n_t^2 ( 1/l^2 , 1/h^2 ^2 ) ( we have ignored the prefactor @xmath384 ) .",
    "the periodic form of @xmath385 results in a series of ` ghost images ' of the power for all of the discrete layers , each with the appropriate tilt , and replicated on a periodic grid in @xmath338 with spacing @xmath386 .",
    "the aliased power therefore appears where @xmath387 , where @xmath388 is a vector with integer values components .",
    "these aliased contributions are individually weak , because typically the argument of @xmath331 will be large compared to @xmath389 so @xmath390 rather than @xmath374 . if there are @xmath391 layers then there will be @xmath392 ghost images located within the region of interest which is of size @xmath393 , so they are quite numerous . on the other hand , the probability that",
    "a given point @xmath338 , @xmath304 falls within any one of these ghost images is @xmath394 which is small if @xmath395 which we expect to be the case .",
    "putting all these factors together we find for this integrated aliased power p_f(aliased ) p_h n_s n_t^2 ( 1 / l^2 ) ( 1 , d / v t_d ) ( x / d)^2 where we have assumed that the velocities of the distinct layers are randomly distributed .",
    "aliasing will be stronger from another layer which has nearly the same velocity , but this is an unlikely situation .",
    "the requirement that the primary contribution to @xmath396 ( which correlates strongly with the thing we are trying to predict ) greatly exceed the aliased contribution ( which does nt ) is then simply [ eq : aliasingcondition ] n_s n_t d ( d , v t_d ) n_l(l^2 , h^2 ^2 ) .",
    "this is a key result of this section and is physically very reasonable .",
    "the rhs is the total area of all of the deflecting layers , whereas the lhs is the total area of the samples of the deflection provided by @xmath377 guide stars seen through @xmath244 telescopes . for aliasing to be unimportant we need to sample the layers sufficently well",
    ".    equation ( [ eq : aliasingcondition ] ) provides the following important constraint on the configuration of the array : one should not choose @xmath83 to be much greater than @xmath397 , which is about 100 m for our canonical @xmath54 km and a @xmath398 degree field .",
    "primarily this is because taking @xmath399 would unneccessarily increase the total area of deflection screen that one must deal with .",
    "this equation suggests that aliasing is independent of the array size for smaller @xmath83 .",
    "however , this is not the whole story .",
    "what we have neglected here is the possibility of aliasing of power in ( [ eq : tildepestimate ] ) from a nearby layer @xmath400 through the central lobe of @xmath401 .",
    "imagine we have taken @xmath83 to be very small so the array is compact .",
    "that means that the transform of the array @xmath401 will be correspondingly wide , with width @xmath402 , so in ( [ eq : tildepestimate ] ) the factor @xmath403 will limit the contribution to the integral to a small region of size @xmath404 around @xmath405 .",
    "more restrictive however is the factor @xmath406 which clearly has a narrow peak for @xmath356 of width @xmath317 around @xmath405 .",
    "however , there will also be secondary peaks of @xmath373 centered on @xmath407 , and these will fall within the more extended central lobe of @xmath401 if @xmath408 .",
    "this would be problematic : according to ( [ eq : f0 ] ) @xmath312 receives a contribution from each layer which is restricted to a region of size @xmath317 around @xmath409 whereas for @xmath410 , the measured @xmath411 receives comparable contributions from neighboring regions and this will destroy the precision of our conditional mean estimate for @xmath312 .",
    "this is slightly over - pessimistic since the contribution from these secondary layers may in fact be suppressed if their velocity difference is such that @xmath412",
    ". this will _ usually _ be the case if the internal evolution time - scale is small compared to the convection time - scale , and if @xmath413 , but this can not be guaranteed , and in any case there will still be a range of @xmath338 values ( lying perpendicular to @xmath414 ) for which the confusion can not be resolved .",
    "the solution to this problem is straightforward : choose an array size @xmath83 which is satisfies @xmath415 .",
    "for a separation @xmath416 m say this gives @xmath417 m .",
    "there is a simple way to understand this latter constraint .",
    "what we are doing here is disentangling the deflections from distinct layers by evaluating the 5-dimensional transform @xmath336 at the angular frequency @xmath349 coresponding to a spatial frequency @xmath338 at height @xmath59 .",
    "if we use too small an array then we have poor resolution in spatial frequency @xmath402 and this converts to a corresponding lack of resolution in height .",
    "this harks back to the observation made at the start of this section , that a layer of thickness @xmath418 is only effectively thin if @xmath410 .",
    "thus , if the nature of the refractive index fluctuations is slowly evolving ( and therefore highly predictable ) streaming layers of thickness @xmath418 with separation @xmath419 then we want to be able to resolve the separate layers . if we fail to resolve two layers moving with different velocities , then we obtain a single effective layer with enhanced width in temporal frequency , which consequently has less predictable evolution . on the other hand",
    ", we do not want to resolve the individual layers further into sub - layers .",
    "if we take @xmath420 m and @xmath416 m then this would argue for an array size @xmath421 m or so , this choice also being consistent with the independent constrain that @xmath422 .",
    "these considerations answer a question that may have occurred to the reader .",
    "why not retro - fit an existing 10 m class telescope with some kind re - imaging optics with stops to generate sub - pupils and with an array of cameras to synthesise an array of 1.5 m aperture telescopes ? while this approach is attractive on grounds of cost ,",
    "if the values @xmath418 , @xmath419 characterizing the stratification of seeing given above are at all accurate then such a design would be sub - optimal as compared to a purpose built array with larger baselines because it would be unable to resolve the separation between layers . in the context of ( [ eq : aliasingcondition ] )",
    "such an instrument would benefit from having a smaller effective number of layers @xmath391 , but the short effective coherence time for the ` composite ' layers @xmath423 would tend to outweigh this gain .    returning to the case of an array , and assuming that the condition @xmath422 is satisfied , equation ( [ eq : aliasingcondition ] ) becomes independent of the field size @xmath61 since @xmath424 , and gives then the number of telescopes required to deal with a certain number of layers distributed over some range of heights .",
    "as already emphasised , the sensitivity of the image quality to imprecision of conditional deflection means that we want to satisfy the inequality ( [ eq : aliasingcondition ] ) strongly , but even so we find equation ( [ eq : aliasingcondition ] ) encouraging .",
    "the arguments leading to ( [ eq : aliasingcondition ] ) are admittedly hand - waving , and it would be nice to quantify the dimensionless factors we have brushed over , but it is probably reasonable to scale from the case of a single layer which we have analysed quantitatively . as we saw in  [ subsec : singlethinlayer ] for a high altitude ( @xmath282 km ) deflection layer a single layer is essentially fully constrained with @xmath179 telescopes even in the absence of useful temporal correlations .",
    "so it should not be too difficult to satisfy the condition ( [ eq : aliasingcondition ] ) for realistic sized arrays . with say 30 telescopes one should be able to deal with several high altitude layers and even more layers at low altitude .    with more detailed knowledge for the properties of the atmosphere it should be possible to accurately compute the performance of this type of imaging system and predict the resulting image quality .",
    "this would then allow one to configure the telescope array to optimize the performance . unfortunately the data that are currently available from scidar studies etc .",
    "are sparse and do not necessarily address the key issues here such as what is the time - scale for the layers to evolve etc .",
    "what are critically needed are measurements of the deflection correlation function which sample the range of spatial , angular and temporal separations relevant here , and also over a period of time in order to properly understand the statistics of these meteorological processes .",
    "some of these issues can be addressed simply with drift scan observations on small telescopes , or with measurements from wavefront sensors on @xmath425 m class telescopes , but also needed are measurements with two or more telescopes ( or with a single large telescope equipped with pupil stops and optics in order to simulate a number of small telescopes ) in order to determine , for example , the decorrelation at large angular separations due to finite thickness of the deflecting layers .",
    "experiments of this kind will be able to address the important , and to a large degree open , question of intermittency and non - gaussianity of the atmospheric deflections .",
    "given data of this kind one can then accurately establish the performance of the type of instrument we are proposing before embarking on construction .",
    "the detectors for this array of telescopes must be able to compensate for independent image motion on a scale of about 1 arc - minute , which for a field of view of about a degree requires 34000 independent image motion compensation elements .",
    "the other important consideration is that the detector must have _ many _ pixels ( approximately @xmath426 per square degree for @xmath180 pixels ) for each of @xmath427 telescopes , so the detectors must be reasonably inexpensive .",
    "our proposed solution to these challenges is a monolithic device consisting of say a @xmath428 array of independently addressable @xmath429 pixel multi - directional or ` orthogonal transfer ' ccds @xcite . with a pixel size of @xmath430",
    "m the resulting @xmath431 pixel device would measure @xmath34100mm@xmath432100 mm and would fill an entire 150 mm diameter silicon wafer . with the optical system designed to deliver a plate scale of @xmath433 m pixel",
    ", a @xmath434 array of @xmath431 otccds butted together into a mosaic would provide the desired 1@xmath435 field subdivided into independently - controllable 1@xmath436@xmath4321@xmath436 patches .",
    "figure [ fig : otarray ] illustrates this idea .",
    "the pixel size of @xmath182 m is a factor 3 times smaller than those commonly used in astronomical applications , but similar to the pixel sizes commonly used in consumer electronics applications .",
    "should manufacturing considerations force one to larger pixels one would need to use a correspondingly larger array of chips to maintain the desired field of view , with corresponding increase in costs .",
    "the real limitations on physical pixel size is one of the major unknowns in costing and optimizing this system .    in the subsequent sections",
    "we will describe how the otccd works and how it can answer our need for a `` rubber focal plane '' , the new step of making a monolithic array of independent ccds , how these arrays would be operated in practice , and finally some estimates of feasibility and yields .      in any ccd",
    "the charge is localized into discrete pixels by application of potentials to adjacent electrodes ( `` gates '' ) which are separated from the charge collecting region by very thin layers of dielectric .",
    "a ccd is read out by systematically changing the gate potentials in such a way that the charge is moved laterally while maintaining each pixel s identity by keeping at least one gate negative ( potential maximum ) between each pixel .",
    "a conventional 3-phase ccd achieves this by using permanent implants ( `` channel stops '' ) which divide the ccd into vertical columns and then three gates per pixel in the horizontal direction .",
    "this process of shifting the charge ( `` parallel clocking '' ) is essentially noiseless ( extra `` spurious '' charge created by the process is typically unmeasurable for modest gate voltages ) , highly efficient ( charge transfer inefficiency ( cti ) is typically less than 1 part in @xmath437 or charge transfer efficiency @xmath438 ) , and extremely fast ( rates of @xmath439 pixel / sec are common ) .",
    "there is no reason that this parallel clocking can not take place while the ccd is collecting light , and indeed this is the basis of time - delay integration ( tdi ) or `` drift scanning '' where a field of view is moved steadily down a column and the ccd is read out at precisely the same rate so that the image is not blurred ( e.g. the sdss ccd mosaic array ) .",
    "the orthogonal transfer ccd ( otccd ) goes one step further in discarding the permanent channel stop but introducing a fourth gate , and by making the layout of the gates symmetric to @xmath440 rotations .",
    "the otccd is therefore capable of tracking image motion in an arbitrary direction .",
    "as the optical image dances about over the ccd , the accumulating charge can be shifted in synchronism and any blurring from image motion will be removed .",
    "the device is bordered by a scupper which removes any charge which is shifted off of the array . figure [ fig : otccd_clock ] shows how the charge is moved in such a device , either for transport to the serial register for readout or for tracking image motion , and the inset in figure [ fig : otarray ] shows a photomicrograph of the gates of an actual device with 15@xmath441 m pixels .",
    "this layout of gates also lends itself well to fractional pixel sub - stepping , which is important since we are expecting images with @xmath151 fwhm and the pixel size is @xmath180 .",
    "figure [ fig : otccd_substep ] shows how a collection pixel can be shifted by a fraction of a pixel .",
    "making a monolithic mosaic array of otccds should not present serious problems in design or manufacture .",
    "the overall layout of the array would have @xmath428 independent @xmath429 otccds separated by gaps for common bus lines which might need to be as large as about 30 pixels or 3 , which is about a 10 percent effective dead area on the array .",
    "the individually addressable otccds would share common connections for a number of signals such as serial gates and amplifier drain and reset , but each must have independently addressable parallel gates ( to effect the necessary shifts for each ccd ) and independent amplifier outputs .",
    "this can be accomplished by equipping each ccd with a set of transistors which lie between these connections and the common bus lines .",
    "using an x - y addressing scheme these transistors can be turned on or off and any individual ccd connected or disconnected from the external pins of the array .",
    "as far as the external electronics is concerned , once 10 bits worth of x - y address has been decoded and the appropriate ccd activated , the array looks like a single , small ccd .",
    "one challenge of making such an array work is that a ccd must maintain the potentials on its gates or else it can not keep the charge within individual pixels .",
    "however , the x - y multiplexing means that all but one ccd is normally disconnected from the external drive electronics .",
    "we do not expect that this will be a problem , because the capacitance of ccd gates is such that they will maintain their potentials for many seconds after being disconnected .",
    "thus , as long as the ccds are each periodically reconnected to the external gate voltages they can continue to do their job .",
    "this mandates that the external electronics continuously ripple through the array , much like dynamic ram .",
    "since we need to visit each ccd ten or more times a second to apply shifts , and since we need many copies ( perhaps 10 per array ) of the external electronics for speed in acquiring guide star information , this should not be a problem .",
    "a very significant advantage to this sort of ccd array is it is very tolerant of manufacturing defects that would otherwise destroy a large monolithic device .",
    "typical wafer defects are very localized , so a defect that might render a conventional wafer - scale ccd unusable will only ruin a single @xmath341@xmath436@xmath4321@xmath436 subarray on the otccd array . given that we are thinking of @xmath442 telescopes each with its own focal plane otccd arrays , the loss of a square arcminute from a single detector is negligible . likewise the gaps between the ccds will not appear in the image produced by the entire telescope array , since it is simple to offset the pointings of each telescope so that the gaps do not overlap .",
    "some number of the ccds in this array will contain sufficiently bright stars around which small patches will be read out for guiding information , thus sacrificing the rest of that 1@xmath436@xmath4321@xmath436 cell for science .",
    "this can be done in ` shutterless video ' mode and we have already demonstrated that it is possible to work at 100  hz sampling with relatively slow electronics and relatively large ccds on available guide stars ( see  [ sec : guidestars ] ) .",
    "an example of the observational strategy follows : first , one would identify the stars which are sufficiently bright to serve as guide stars and identify the @xmath429 pixel otccd cells which contain these guide stars",
    ". then one would start the following observing sequence .",
    "first all the ccds are erased .",
    "then a 3@xmath4323sub - array surrounding each guide star is read out from each otccd cell on each of the telescopes , and these are pushed into @xmath443 buffers of length @xmath444 which store the most recent @xmath444 coordinates .    for each telescope , and for each cell of the detector ,",
    "a deflection vector is computed as a linear combination of the data currently in the buffers ( with matrix of coefficients computed on the rather slow time - scale over which the deflection covariance matrix evolves ) .",
    "the charge is then shifted in each of the otccd cells ( those integrating , and not those guiding ) at each telescope to track the motion .",
    "a suitably filtered and averaged version of this guide signal is fed to the telescope drives , so that the otccds remove only the rapid motion , and the guiding of the telescope keeps the overall amplitude of otccd offset small .",
    "note that it is only this very low frequency correction that is performed ` closed - loop ' .",
    "the rapid image motion correction is ` open - loop ' , in the sense that there is no feed - back from the guiding process on the guide stars themselves , and this renders the high - frequency correction relatively stable .",
    "since this whole operation is completely parallelizable , the system can be run as fast as necessary by using enough drive electronics and computers .",
    "the communication between computers can easily be handled by conventional ethernet technology ( with suitable attention to latencies ) since each telescope will have a local computer which reduces all of the guide star images to a vector of @xmath445 offsets every 50@xmath446msec or so .",
    "when the exposure is finished the shutter is closed and the arrays read out . because we must necessarily have many read - out channels to follow the guide stars , and since each @xmath447 ccd has its own amplifier , the readout can be quite fast , possibly limited only by computer and memory bandwidth . the ccd electronics",
    "should be able to read the entire array in under 30 seconds .",
    "an alternative is to keep the shutter open and read out the integrating cells in some kind of ripple - through sequence after relatively short ( say 1 - 2 minute ) exposures . since the individual cell read - out time is finite ( about a second or so )",
    "this will result in low level extensions of bright object images along the read - out direction , but these can be removed without difficulty .",
    "advantages of this approach are that it allows one to reject poor data if there are short bursts of bad image quality , and it also allows greater time resolution for transient events .      to date",
    "otccds have been produced in arrays as large as 2k@xmath4324k with 15@xmath441 m pixels .",
    "current lithographic techniques should allow the production of @xmath182 m pixel devices which are similar in scale to commercial consumer electronics applications , but whether this would have significant impact on yield , quantum efficiency , and blue mtf remains to be seen .",
    "one unavoidable effect will be a reduction in full well capacity to perhaps 2050@xmath446ke@xmath448/pixel .",
    "this however is not a serious problem when we consider that for this application the final telescope beam will be fairly slow , with focal ratio @xmath449 or thereabouts , and that the otccd cells can be read out after quite short integration times .",
    "ideally , one would actually prefer even smaller pixels in order to sample the psf better , and that is a tradeoff which should be explored .    despite the large size of such an otccd array",
    ", we believe the yield for such devices would actually be relatively high .",
    "we are already at the stage where manufacturers are achieving extraordinary yields on large format devices .",
    "for example , it is not uncommon for a lot of 150 mm wafers filled with 2k@xmath4324k ccds to have a yield exceeding 90% and for more than 50% of these devices to be of scientific grade after thinning and packaging ( burke , private communication ) .",
    "it now appears to be feasible to fabricate a single wafer - scale device with a high probability of success .",
    "moreover , because of the otccd array s high tolerance to defects , we expect that these devices would have a much higher yield than a conventional ccd .",
    "the software required by this project naturally breaks into two parts : the software necessary to process the multiple guide star information and carry out the fast guiding with the otccd detector arrays , and the software necessary to combine and process the resultant images .",
    "the software required to operate the ccd hardware is straightforward . to the external world",
    "the ccd array would have a single set of the usual gate and amplifier connections as well as @xmath450 @xmath451 addressing lines which are set to access a given chip ( we would probably include a 5-bit decoder for each of @xmath139 and @xmath452 on the substrate ) .",
    "thus , once @xmath451 addresses are set , the ccd array acts like no more than a conventional @xmath453 pixel otccd .",
    "this straightforward task could be carried out by dedicated dsp - based ccd controller electronics , much like those in used to operate current large ccd mosaics .",
    "the software necessary to process the guide star information and carry out the on - chip fast guiding at first seems daunting , but in fact the massively parallel nature of this process makes it much simpler than it might appear . for example , each telescope could have its control system interfaced to a master process which will ensure that that telescope is pointing in the right direction and assemble housekeeping information for the exposure .",
    "this master process would also be responsible for shutters , filter wheels , and directing the overall flow of guide star information from the ccd computers to the covariance processes .",
    "the rest of the software to run the otccd detectors is straightforward and for the most part already exists .",
    "routines have been developed to read out guide stars in shutterless video mode , determine the centroid of the stars , and apply shifts to otccds .",
    "the only new features that would be needed would involve addressing individual cells to access the guide star information and apply the otccd shifts .",
    "however , this is precisely the same code that is used for one ccd with a particular @xmath451 address enabled . the natural loop that will be carried out in accessing guide star information and applying shifts",
    "will also keep the gate voltages on the individual ccds refreshed .",
    "if not for the necessity to combine all the data from all the guide stars to compute the required shifts , the software task would be very simple .",
    "the most challenging software task is the assembly of all the guide star information into a covariance matrix .",
    "each of the ccd control computers will be computing centroid information on perhaps 60 stars on a time scale of perhaps ( 50 - 100 )  msec . with 36 telescopes and 4 arrays per telescope ,",
    "this is about 5000 sets of coordinate pairs which are collected by two different processes .",
    "the first process uses an existing covariance matrix and these new coordinate offsets to compute shifts for each ccd in each array at each telescope .",
    "these are shipped back to the ccd control computers which apply them .",
    "( note that this does not have to be synchronous ",
    "it is better to ripple through the ccds in the arrays in a systematic manner . )",
    "the second process computes the covariance matrix .",
    "since this matrix depends on things like the geometry of where the telescopes are sited , the positions of the stars , and things like the upper atmosphere wind direction and speed , or motions of eddies driving the outer scale of turbulence , we expect that a given covariance matrix will be valid for many minutes before its accuracy decays .",
    "the time complexity of this procedure was discussed in  [ sec : correlations ] .",
    "finally , the images must be combined and analyzed . the data combination and analysis software for the most part already exists .",
    "the issues of ccd image processing , image registration and combination , and psf circularization are either solved problems or will be by the time such a telescope array might actually be built . in many respects ( e.g. good optical quality images and massive redundancy in the number of images being combined ) this telescope array eases many of the difficulties typically encountered in ccd image combination .",
    "although the purpose of this paper is to outline a new strategy for high - resolution wide field imaging , it is nevertheless useful to estimate the cost of such a system to investigate whether it is feasible to build .",
    "the system consists of @xmath244 telescopes , @xmath244 large otccd mosaic cameras ( 1 per telescope ) , a network of computers , the software to run the facility , and some kind of building / enclosure .",
    "each of these is addressed below :      the modified rc telescope design with aspheric corrector presents no significant problems . similar sized units ( with faster beams and wider fields ) have been constructed in recent years ( e.g.  usno 1.3 m telescope with a 1@xmath454.7 field ) for $ 0.7 m or thereabouts . for this array , each telescope , including the entire optical system , telescope mount , and telescope control system should cost under $ 1 m .",
    "the cost for a filled aperture , off - axis design may be somewhat higher .",
    "it is worth re - emphasizing here that the cost of this system scales linearly with the collecting area , rather than as some higher power as is the case for filled aperture large telescope designs .",
    "the otccd detector mosaic array is one area that presents a significant technical challenge and at first would appear to be a very expensive development .",
    "however , as discussed earlier , the architecture of the independently addressable array will likely have very high yield because of its tolerance to defects that would render a conventional large - format ccd useless .",
    "the estimate can therefore be based on the costs to fabricate current , large 2k@xmath4324k otccds .",
    "presently , it takes approximately $ 500k to fabricate a lot of devices on twelve 150  mm diameter wafers and thin and package them .",
    "the large otccd array would fill one wafer , so a lot would consist of 12 devices .",
    "it is perfectly reasonable to expect that at least 1/2 of the devices produced in such a lot will be usable ( the actual number of good devices could be higher given our tolerance to defects we mention above ) , therefore each @xmath431 otccd array will cost less than or of order $ 100k .",
    "this is in accord with the idea that an otccd array should be of comparable cost to a single 2k@xmath4324k otccd device because of the similar yields .",
    "four such detectors are needed for each camera to fill the one square degree field , making the total cost for the detectors alone of order $ 400k / telescope .",
    "the additional costs per camera are substantially lower than the detector costs .",
    "these include the cost of the cryostat , the controller electronics , a filter wheel , filters and a shutter .",
    "all of these components are similar to those for other large mosaic cameras currently in existence or under construction , and so can be accurately costed .",
    "the cryostat would employ a closed - cycle cooler and can be readily built for under $ 75k .",
    "the controller electronics would cost a similar amount ( @xmath34$100k , assuming @xmath200 channels at $ 2k apiece , clocking electronics , dsp controller , enclosure , etc . ) , and each camera would require a filter wheel with filters and a shutter for about $ 50k bringing the additional hardware cost per camera to $ 225k .",
    "all together , it is reasonable to expect that the total detectors and camera hardware cost will not exceed $ 625k / telescope , and thus is comparable to the cost of the telescopes themselves .",
    "as previously mentioned , a big uncertainty here is the feasibility of @xmath182 m pixels .",
    "should we need to use say @xmath455 m pixels then the cost of the detectors would increase by about $ 500k / telescope      the system would require a large network of parallel computers , probably 1 per otccd array or 4 per telescope . fortunately , these computers would be extremely inexpensive as compared to the rest of the hardware .",
    "the computer cost should not exceed $ 10k / telescope",
    ".      as expected , the hardware cost of the computers needed to process the guide star information , carry out the fast guiding on the otccds , and combine and analyze the images , is small compared to the software effort that will be needed .",
    "nevertheless , the actual software tasks are manageable and can be costed fairly accurately .",
    "as discussed earlier , much of the software one can envision needing already exists or will soon exist ; image combination and analysis software can be adapted from the other data processing pipelines currently being designed and written .",
    "the most difficult task will be in handling the guide star information .",
    "not enough is known about exactly what the atmosphere does to tip - tilt , particularly the questions most pertinent here such as intermittency time scales , outer scale sizes , stratification of turbulence , etc .",
    "such an effort will likely involve both scientists as well as computer specialists , and pilot project experiments will need to be carried out to learn about how to combine multiple guide star information from multiple apertures to compute image motion beyond the isokinetic angle .",
    "it seems reasonable to expect that it will take some 30 man - years to develop the software needed to process the guide star information , and another 5 - 10 man - years to assemble the data analysis pipeline for the image combination and analysis .",
    "developing the dsp code to run the otccds will take approximately 1 man - year and other miscellaneous tasks might occupy another 1 - 2 man - years for a total of less than 43 man - years or approximately $ 6.5 m .      unlike other large telescopes with rotating domes , the building for this telescope array can be very simple . depending on the spacing of the telescopes ( for which the optimal strategy needs to be worked out depending on the outcome of some experiments outlined in  [ sec : correlations ] above )",
    "there are several options for the enclosure : 1 ) if the telescopes are arranged in a close - packed array , they could be mounted on some kind of elevated frame with a roof and sidings which roll back to allow the low - level boundary layer fluctuations to pass safely underneath .",
    "2 ) if the telescopes are widely spaced , then each telescope might have its own small enclosure ; or 3 ) the telescopes might be grouped in several clusters , each with its own building . in all cases , the building(s )",
    "can be relatively simple , and should be substantially lower cost that the typical 8 m telescope dome . a reasonable upper limit would seem to be $ 5 m for the enclosure .",
    "the collecting area of the telescope array scales as the number of telescopes @xmath244 . ignoring the enclosure and software ,",
    "the cost of this telescope array also scales as @xmath244 .",
    "ideally one would determine the cost and performance as a function of @xmath244 and other parameters such as the number of chips per camera and then solve for the optimal performance and price . unfortunately however , determining the performance as a function of @xmath244 say requires knowledge of the atmospheric conditions which is not yet available . in the absence of reliable information",
    "we will assume that @xmath270 telescopes is adequate for which the total cost would be @xmath456 and would yield the equivalent of a 9 m aperture telescope that can deliver @xmath151 fwhm images over a 1@xmath457@xmath4321@xmath457 field of view .",
    "for @xmath458 m pixels the cost would be larger by about @xmath459 m , as would also be the case for detectors with @xmath460 m pixels but twice the field of view .",
    "one huge advantage of this approach is that the aperture can grow to arbitrarily large size simply by adding more telescopes .",
    "conversely , one can start building such an array and start using it once only a fraction of the full complement of telescopes are in place .",
    "science observations can begin before the final configuration is completed .",
    "the original motivation for the wide - field high resolution imager ( wfhri ) that we have described here was to give enhanced resolution images for weak lensing .",
    "however , it is potentially an exceedingly powerful instrument for many other applications .",
    "it can be used in two different modes : the `` high resolution mode '' described here where all telescopes point in the same direction in order to improve the psf , and a `` wide field mode '' where the telescopes are pointed in different directions and accept the natural seeing at the site .",
    "note that in wide field mode one can observe 36 square degrees simultaneously with a 1.5-m aperture .",
    "a major driver for this imaging system was to provide enhanced performance for weak lensing observations , which are particularly hampered by poor resolution . in high resolution mode",
    "we expect to obtain fwhm @xmath151 images much of the time over a 1 degree field , with an effective 9-m aperture .",
    "this is _ much _ more effective for measuring weak lensing than a conventional large single aperture telescope images which of much poorer resolution .",
    "the net result is that we will measure more galaxies , which gives us more spatial resolution and precision for measuring weak shear , and as we will now show , the improvement in sharpness of the psf results in an increase in performance for shear measurements from small faint galaxies of better than a factor 100 .",
    "it is possible to define a quantitative figure of merit , the inverse shear variance per unit solid angle , which measures the power of given image data for weak lensing shear measurements @xcite .",
    "a detailed analysis is beyond the scope of this paper , but the following simple argument should give a reasonable indication of the increase in shear precision that will be allowed by fast guiding .    consider a population of objects , which we will model as small gaussian ellipsoids with semi - major axes @xmath461 , so the intrinsic brightness distribution is @xmath462 . now model the psf as either a single gaussian for uncorrected imaging , or as a double gaussian for fast guiding . in the latter case , and for small objects which we know from e.g.  the hdf dominate the faint galaxy population , essentially all the information will be contained in the core component , so we can equally compare the performance of two single gaussian psfs , where the fast guiding psf has a smaller scale length @xmath463 but contains only a fraction @xmath204 of the light .",
    "after convolving with the psf , the object will be a gaussian ellipsoid with semi - major axes @xmath464 where @xmath465 , @xmath466 .",
    "a shear @xmath467 gives a net asymmetry for galaxies @xmath468 .",
    "a simple shear estimator is then @xmath469 .",
    "when we average over a large number of similar galaxies the denominator converges to @xmath470 , the average intrinsic area of the objects and , for small shear at least , the uncertainty in the shear estimator is dominated by fluctuations in the numerator .",
    "the fractional measurement error in @xmath464 is @xmath471 where @xmath472 is the number of photons from the sky over the object , assumed to dominate over the count of photons from the galaxy , and is proportional to @xmath473 and @xmath474 is the number of photons detected from the object , which is proportional to @xmath204 , hence as far as the dependence on psf properties is concerned we expect @xmath475 ( we are assuming that the measurement error is of similar order to the intrinsic noise due to the inherent shapes of galaxies ) .",
    "the uncertainty in the shear estimator is then @xmath476 and the performance of the instrument @xmath477 is proportional to the inverse square of the shear error , that is @xmath478 . for poorly resolved objects the post convolution size is @xmath479 , so the performance therefore scales as @xmath480 .    for the pixellated peak - tracking psf ( with @xmath481 cm and @xmath482",
    "m ) we find that the core has @xmath483 and contains about @xmath484% of the light whereas a single gaussian fit to the uncorrected psf gives @xmath485 so we find that @xmath486 .",
    "thus , holding all other factors such as net collecting area , detector efficiency etc .",
    "constant , this says that sharper shape of the psf as compared to the uncompensated case yields better than two orders of magnitude improvement in efficiency .",
    "equivalently , to achieve the same precision in shear measurement from small , faint galaxies one would need to integrate on the order of 100 times longer with a conventional telescope than with the system we are proposing here .",
    "high resolution mode is also valuable for many other projects .",
    "for example , with fwhm @xmath151 images at @xmath487 m , we can measure distances of galaxies out to about 10,000  km / s with 5% accuracy using surface brightness fluctuations .",
    "the 1 degree field of view means that we can observe much of an entire galaxy cluster at once , obtaining hundreds of distances , and the 9-m aperture will give us sufficient photons for this measurement at 10,000  km / s with an exposure time of about 20 minutes .",
    "clearly the wfhri has incredible potential for mapping out the large scale flows in our local universe .",
    "another project for high resolution mode is simply to select a non - trivial piece of sky and take very deep images in multiple colors .",
    "the value of the hubble deep fields for e.g.  studying internal structure in young , high redshift galaxies can not be underestimated , but they were very expensive to obtain , and it is clear from the differences between the northern and southern fields that a @xmath488 field is too small compared to cosmological structures . the wfhri compares favorably with hst for this project",
    ". the imaging performance will be slightly worse , due to the slightly smaller aperture , although the pixel sizes are comparable . however , the wfhri is a factor of about 50 more sensitive than hst and wfpc2 in collecting photons , and it has a field of view which is 500 times larger . given that much of the science from the hubble deep fields is not compromised by a factor of two worse resolution , the wfhri is arguably a factor of 25,000 more efficient than hst , while being considerably less expensive .",
    "there are many other projects which could be tackled with the wfhri , for example micro - lensing in the galactic bulge or m31 in order to detect machos .",
    "the essential figure of merit in these studies is the number of stars you can monitor .",
    "the wfhri has a huge advantage over any other telescope existing or planned because of its large aperture and superior psf .",
    "another project for which the wfhri is very well adapted is searching for high redshift supernovae . at redshifts greater than about 0.5 ( and even more so for @xmath489 )",
    "a 1 degree field of view is more than adequate , but discovery and followup is _ vastly _ easier with fwhm @xmath151 imaging than with @xmath490 .    in wide field mode , one can point the 36 telescopes in a square array covering 36 square degrees , and accept the 0.40.5  seeing which results from being restricted to high - speed tip - tilt compensation over an entire array .",
    "the array can also be operated in this mode whenever high altitude turbulence is relatively weak , and the image quality would then be similar to high resolution mode . in this mode",
    "the wfhri could survey the entire northern sky in only @xmath491 pointings .",
    "the sensitivity of a 1.5-m aperture in the @xmath183 band with 0.5  imaging and an exposure time of 300 sec is @xmath492 for a 5-@xmath463 detection . given that one could expect to get @xmath493 such observations per night , the wfhri could survey the visible sky ( 20,000 square degrees ) in 5 nights",
    ".    in wide field mode the wfhri would be extremely useful for searching for kuiper belt objects , both faint and bright , and for searching for near earth objects ( neos ) . as is true with the dark matter telescope , following a systematic survey scheme means that finding and obtaining orbits for asteroids and comets is done automatically by the fact that the entire sky is surveyed repeatedly .",
    "a useful figure of merit for survey telescopes is @xmath494 , where @xmath495 is the collecting aperture , @xmath496 is the survey area , @xmath497 is the detector quantum efficiency , and @xmath498 is the solid angle of the point spread function .",
    "the difficulty , as we have seen , is that there is no unique way to characterize the psf area ; the gain in performance depends strongly on the application .",
    "the faint galaxy application for which the enhanced resolution is _ least _ useful is simply detection , for the purposes of making counts of galaxies and performing angular correlation studies etc .",
    "it is interesting to compare the performance of the wfhri for this task with other specialized proposals for wide - field survey instruments .",
    "a `` dark matter telescope '' has recently been proposed by tyson and angel @xcite which would have a 6.9 m effective aperture , a @xmath499 diameter field of view ( 7 square degrees ) and which would be expected to provide a typical psf of @xmath500 fwhm . in wide field mode ,",
    "the wfhri covers 5 times as much field of view as the dmt ( @xmath501 versus @xmath499 diameter ) , has 1/20 the collecting area ( 1.5-m aperture versus 6.9-m effective aperture ) , has similar quantum efficiency detectors , and will have distinctly better imaging performance due to the smaller apertures and the ability to do fast tip - tilt compensation for the entire array ( amounting to an improvement of perhaps a factor of 0.7 in psf size for given atmospheric conditions ) .    in high resolution mode",
    ", the wfhri covers 1/7 times as much field of view as the dmt ( @xmath502 versus @xmath499 diameter ) , has 1.7 the collecting area ( 9-m aperture versus 6.9-m effective aperture ) , has similar quantum efficiency detectors , and will have imaging performance which will be better by a factor of 3 ( 0.2  versus 0.6 ) .",
    "putting these together for the dmt yields 260  ( m - deg)@xmath503 , taking @xmath497 and @xmath498 to be unity .",
    "in wide field mode , the figure of merit is 130  ( m - deg)@xmath503 for the wfhri ( applying the factor of 0.7 to the psf size ) , and in high resolution mode , the figure of merit is 400  ( m - deg)@xmath503 ( applying the factor of 1/3 to the psf size ) .",
    "thus , for shallow , very wide field surveys the wfhri is slower than the dmt by a factor of 2 ( although the dmt may have trouble achieving a high duty factor because of detector readout and telescope slew time ) , and for deeper surveys the wfhri is faster than the dmt by a factor of 2 . these numbers should not be considered definitive since the optimal configuration for the wfhri is as yet not well known . in particular",
    ", it is quite feasible to increase the field of view substantially , though with some increase in detector costs .",
    "both the dmt and the wfhri are orders of magnitude better survey telescopes than anything existing or currently planned .",
    "as figure [ fig : surveys ] illustrates , the wfhri can achieve the depth of the hdf in one night , except over a square degree and in @xmath504 , @xmath505 , @xmath183 , and @xmath69 ( each to an ab magnitude of 28.7 ) .",
    "alternatively , in wide field mode the wfhri can rival the breadth of the sdss , except going four magnitudes deeper .",
    "we believe therefore that the wfhri is a superior concept because it offers much better performance for key scientific projects ( and is applicable to many additional projects ) , it is a faster survey telescope for many applications such as searching for very faint rare objects , and it is extremely flexible in the way it can be deployed for a particular scientific objective .",
    "we have outlined a strategy for wide field imaging at optical wavelengths with high angular resolution by means of low - order ao in the form of fast guiding .",
    "any ao system for wide - field applications must address the ` isoplanatic angle ' problem  that different parts of a wide field will suffer largely independent wavefront distortions  and so it is necessary to multiplex the wavefront correction process .",
    "the solution here is limited in that we only attempt to correct for the very lowest order wavefront distortions ( though we do this separately for a large number of small telescopes ) but exploit the new technology of otccd devices to efficiently apply fast guiding independently to each of a huge number of isoplanatic patches .",
    "the key feature of this strategy is the ability to provide a psf where roughly 30% of the light is in a very small , diffraction limited core with fwhm of about @xmath151 .",
    "this is modest resolution compared to full ao on a large telescope , but nonetheless would provide great gains in performance for many applications within the general context of wide field imaging .    in this paper",
    "we have made detailed analytic and numerical calculations of the expected image quality and we have quantified the constraints implied by the limited numbers of potential guide stars .",
    "we have computed in some detail how image quality can be improved for the simple case of a single deflecting layer and we have described one possible approach for extending this to the multi - layer case . in particular ,",
    "we have tried to set out the general constraints that a system of this kind must satisfy in order to give the full improvement in image quality . in common with multi - conjugate ao systems , a key assumption here",
    "is that the source of seeing is highly stratified ; the type of system we have proposed would be impractical if the source of atmospheric seeing were distributed quasi - uniformly with altitude .",
    "thankfully strong stratification is indicated by the currently available results of site testing using scidar etc . , but more information is needed .",
    "we have argued that a modest program to measure deflection correlations over the range of angular , spatial and temporal separations relevant here would allow one to definitively establish the performance of this kind of instrument before constructing the full scale instrument .",
    "once these meteorological parameters are better determined the next logical step would be to make a detailed cost _ vs _ performance analysis to compare this approach with e.g.  a specialized wide field survey telescope in space .",
    "we have described the design and operation of orthogonal transfer ccds ; how these can be combined in large numbers in single wafer - scale devices with high yield , and we have outlined the operating procedure for contolling and collecting data from such a mosaic camera .",
    "we have given what we feel to be a fairly conservative estimate of the various component costs for a wfhri .",
    "we have tried to quantify the gain in performance for various faint object applications as compared to conventional terrestrial observing . crudely speaking these fall into two categories . for simple detection and counting studies ,",
    "the gain is the least with a factor 2 - 3 improvement from image quality .",
    "the relatively modest gain in efficiency in the face of a fairly large decrease in fwhm is not too surprising when one recognizes that the effective area for collecting target object photons into the psf core is a fraction of the actual collecting area , but the full area is effective for collecting sky background photons . for sky noise",
    "dominated photometry the performance is poorer than for a hypothetical telescope with @xmath295 the collecting area but which can concentrate 100% of the photons in a similarly compact psf . the applications for which the gain is the greatest  up to about 2 orders of magnitude gain from image quality alone  are those that really demand high resolution .",
    "such applications are those that need the spatial frequencies in the image which are exponentially suppressed in uncorrected imaging by a huge factor but are preserved in the wfhri at levels only a few times lower than for a diffraction limited telescope .",
    "examples that require this very high resolution are typically those which explore the _ structure _ of galaxies , such as weak lensing and studies of star formation and related morphological evolution in faint galaxies , or those applications which require highly accurate positional data .",
    "one of the real strengths of the wfhri is its flexibility .",
    "we have described high resolution and wide field modes , but of course it is possible to use a wfhri in other modes as well .",
    "for example , under favorable conditions and with say clusters of six telescopes , wfhri can survey 6 square degrees simultaneously with an effective aperture of 3.6  m , and nearly full improvement in strehl ratio .",
    "also , as we have stressed , the wfhri is not an `` all or nothing '' proposition . for not much more than 1/6",
    "the cost , a working array of six telescopes could be put into operation which would be comparable to the megaprime imager being built for the cfht , except that the psf would be a factor of 23 better . before",
    "new large telescopes are built for wide field imaging , this new alternative approach deserves serious consideration .",
    "we would like to thank steve ridgway for constructive criticism of an early draft of this paper .",
    "buzz graves explored several optical designs for wide - field telescopes that convinced us that such systems are straighforward to build with current technology .",
    "we also gratefully acknowledge many helpful discussions with malcolm northcott and helpful comments from chris stubbs ."
  ],
  "abstract_text": [
    "<S> we propose a new strategy for obtaining enhanced resolution ( fwhm @xmath0 ) deep optical images over a wide field of view . </S>",
    "<S> as is well known , this type of image quality can be obtained in principle simply by fast guiding on a small ( @xmath1 m ) telescope at a good site , but only for target objects which lie within a limited angular distance of a suitably bright guide star . for high altitude turbulence this ` isokinetic angle ' is approximately @xmath2 . with a 1 degree field </S>",
    "<S> say one would need to track and correct the motions of thousands of isokinetic patches , yet there are typically too few sufficiently bright guide stars to provide the necessary guiding information . </S>",
    "<S> our proposed solution to these problems has two novel features . </S>",
    "<S> the first is to use orthogonal transfer charge - coupled device ( otccd ) technology to effectively implement a wide field ` rubber focal plane ' detector composed of an array of cells which can be guided independently . </S>",
    "<S> the second is to combine measured motions of a set of guide stars made with an array of telescopes to provide the extra information needed to fully determine the deflection field . </S>",
    "<S> we discuss the performance , feasibility and design constraints on a system which would provide the collecting area equivalent to a single @xmath3 m telescope , a 1 degree square field and @xmath0 fwhm image quality .    </S>",
    "<S> [ fig : array ] </S>"
  ]
}