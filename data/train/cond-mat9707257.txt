{
  "article_text": [
    "in the preceding paper @xcite , the problem of finding ground state energies and configurations for a frenkel - kontorova model in a periodic potential formed by parabolic segments of identical ( positive ) curvature , was reduced to that of minimizing a certain convex function over a finite simplex .",
    "while various aspects of the corresponding phase diagram in the @xmath1 case can be worked out in a relatively straightforward manner @xcite , minimizing the convex function for larger values of @xmath0 represents a non - trivial problem in numerical analysis .",
    "the basic reason is that the convex function of interest does not have continuous derivatives , and in the case of an irrational winding number , it possesses a dense set of singularities . hence standard gradient methods run into difficulties .",
    "the approach we employ is based upon the concepts of subdifferential and subgradient from the theory of convex functions @xcite , as explained in sec .",
    "the algorithm itself , described in detail in sec .",
    "[ s3 ] , is motivated by a physical model involving quasiparticles , sec .",
    "an essential part of the procedure is a standard linear programming procedure which we have simplified and adapted to the problem at hand , app .  a , so as to speed it up substantially . as a result",
    ", ground states for @xmath0 on the order of 100 are readily calculated , and larger values of @xmath0 are accessible with , of course , a longer running time ; see sec .",
    "as in part i , with some minor changes in notation , we assume the energy per particle can be written in the form @xmath2 where @xmath3 @xmath4 with @xmath5 equal to zero , @xmath6 and @xmath7 the boldface letters denote @xmath0-component vectors , for example , @xmath8 a constant term independent of  has been omitted from ( [ e2.2 ] ) , and bars have been added to * h *  and  in ( [ e2.3 ] ) to distinguish them from quantities which we shall define later . note that @xmath9 because @xmath10 , and @xmath11 is periodic in @xmath12 , with period @xmath0 .",
    "our task is to find the , or equivalently , which minimize @xmath13 for a given @xmath14 , or equivalently @xmath15 .",
    "the function @xmath16 is convex on the interval @xmath17 .",
    "if its derivative @xmath18 were a continuous function , the minimum would satisfy the equation : @xmath19 obtained by differentiating ( [ e2.1 ] ) , where the components of  are given by @xmath20 @xmath21 @xmath22    but in fact @xmath23 has lots of discontinuities , see fig .  [ fg1 ] , and therefore we need some way to interpret the ( formal ) solution ( [ e2.9 ] ) in this case . for this purpose",
    "it is convenient to employ the concepts of subgradient and subdifferential as defined by rockafellar @xcite .",
    "suppose that @xmath24 is a real - valued function ( which need not be convex ) defined on some domain in @xmath25 .",
    "we shall say that  is a _ subgradient _ of @xmath26 at the point @xmath27 provided @xmath28 for all  where @xmath26 is defined .",
    "the collection of all  values for which this inequality is satisfied for a given @xmath29 is easily shown to be a convex subset of @xmath25 , and is called the _ subdifferential _ of @xmath26 at @xmath29 , denoted by @xmath30 .    given this definition , it is easy to show that @xmath13 in ( [ e2.1 ] ) has a minimum at @xmath31 if and only if @xmath14 is an element of @xmath32 , the subdifferential of @xmath33 at @xmath29 .",
    "in addition , the subdifferential of a sum ( @xmath34 ) of convex functions is the sum of the subdifferentials of the individual functions @xcite , understood as sums of sets of @xmath35 ; thus : @xmath36 together with its obvious generalization to the sum of three or more sets .",
    "these observations provide the key for interpreting equations ( [ e2.10 ] ) to ( [ e2.12 ] ) . at some point @xmath37 where @xmath23 is discontinuous ,",
    "the subdifferential of @xmath16 , for @xmath38 in the range @xmath17 , consists of all points @xmath39 lying in the interval @xmath40 where @xmath41 and @xmath42 are the left and right derivatives of @xmath16 at @xmath37 , that is , the bottom and top of the discontinuity in the graph of @xmath43 .",
    "more generally , for @xmath44 we interpret @xmath45 in ( [ e2.12 ] ) as any point in the interval @xmath46 where the lower limit is set equal to @xmath47 if @xmath48 , and the upper limit is @xmath49 if @xmath50 , as a consequence of the constraints @xmath51 for @xmath52 , we define @xmath53 .",
    "of course , if @xmath54 is continuous at @xmath55 , then @xmath45 is the single point @xmath56 .",
    "consequently , @xmath57 is simply the collection of all @xmath58 obtained using ( [ e2.10 ] ) , where for each @xmath59 , @xmath45 in ( [ e2.12 ] ) is allowed to vary over the interval ( [ e2.16 ] ) , and for @xmath60 , @xmath53 .",
    "notice that this means that @xmath61 is zero , and therefore @xmath62 for any @xmath58 in the subdifferential @xmath57 , which corresponds to ( [ e2.7 ] ) .",
    "note that the @xmath45 are allowed to vary _ independently _ , aside from the restriction @xmath53 .",
    "as there are thus @xmath63 independent variables , some of which may be constant because they do not correspond to discontinuities of @xmath43 , @xmath57 is , in general , a fairly complicated polyhedron , of dimension less than or equal to @xmath64 , the dimension of the space in @xmath35 satisfying the constraint ( [ e2.18 ] ) .    in the case",
    "@xmath65 , the subdifferentials @xmath57 are closed sets , either hexagons , lines , or points , depending upon the value of @xmath66 .",
    "some of the lines and hexagons extend to infinity .",
    "a hexagon occurs provided @xmath67 where @xmath68 , @xmath69 , @xmath70 , and @xmath71 are integers , in which case @xmath72 and @xmath73 , as well as @xmath74 , are at discontinuities of @xmath43 .",
    "a line occurs when @xmath43 is discontinuous at one of the three values @xmath72 , @xmath73 , or @xmath75 , but not at the other two , and @xmath57 is a point if @xmath43 is continuous at all three values .",
    "if @xmath76 is irrational , the discontinuities of @xmath23 are a dense set in @xmath38 , and consequently the subdifferentials of @xmath33 for different @xmath66 have no points in common . if @xmath76 is rational , adjacent hexagons overlap at their common edges and vertices , and each edge and each vertex is itself a subdifferential of @xmath33 for a range of @xmath66 values . for both rational and irrational @xmath76 , the hexagons cover the entire plane satisfying the constraint ( [ e2.18 ] ) , with the exception , when @xmath76 is irrational , of a set of zero measure . a similar comment applies to larger values of @xmath0 , and therefore in numerical studies it suffices to consider the @xmath64 dimensional polyhedra obtained when every @xmath77 falls on a discontinuity of @xmath43 .",
    "it is sometimes helpful to think of the collection of subdifferentials @xmath57 as @xmath78 varies as generated by placing a set of @xmath63 points on the graph of @xmath23 at positions @xmath79 .",
    "note that the @xmath77 can not be varied independently , as they are determined by a set of @xmath64 parameters , see ( [ e2.4 ] ) .",
    "however , each of the @xmath63 points on the graph can be moved independently in the vertical direction , as long as it is on a discontinuity of @xmath43 , to form the collection of @xmath45 values which generate the subdifferential for a fixed @xmath66 .",
    "the problem of finding the @xmath66 which minimizes @xmath13 , ( [ e2.1 ] ) , for a given @xmath58 is equivalent , as noted in sec .",
    "[ s2 ] above , to finding the @xmath66 such that @xmath14 falls in the subdifferential @xmath57 .",
    "furthermore , the @xmath64 dimensional polyhedra which arise when all the @xmath77 fall at the discontinuities of @xmath23 fill up the relevant @xmath64 dimensional hyperplane ( [ e2.18 ] )  except for a set of measure zero , and as we assume that @xmath58 is only specified with some limited numerical precision , we can in practice limit ourselves to a consideration of such polyhedra .",
    "the general idea of the algorithm is as follows .",
    "starting from some @xmath66 with all @xmath77 at discontinuities of @xmath80 , test whether the target @xmath14 lies inside @xmath57 .",
    "if it does , the problem has been solved .",
    "if it does not , use the information obtained from the test in order to choose a new  closer to the desired value , and repeat the test .",
    "the test itself , steps 3 and 5 in the algorithm as summarized below , involves a linear optimization procedure with an execution time which ( typically ) varies as @xmath81 , which is relatively expensive when @xmath0 is large .",
    "consequently , the test is preceded in our algorithm by various steps whose aim is to provide , with a relatively small number of operations , a value of @xmath66 close to the final solution .    to begin with ,",
    "we replace the actual @xmath23 with an approximate , piecewise constant function @xmath82 which has discontinuities at the points @xmath83 where @xmath84 and @xmath85 are integers , and @xmath86 for some finite bound @xmath87 , which can be increased later if necessary .",
    "this is a sensible procedure , because the size of the discontinuities decreases exponentially with @xmath88 . between two successive discontinuities",
    "@xmath37 and @xmath89 , the function @xmath90 is defined to be a constant lying halfway between @xmath42 and @xmath91 , see fig .  [ fg1 ] . consequently , the discontinuities of @xmath90 are somewhat larger than those of the exact @xmath43 , and ( [ e2.16 ] ) is replaced by : @xmath92    note that if @xmath93 is a rational number , with @xmath94 and @xmath95 relatively prime positive integers , the discontinuities of @xmath43 , ( [ e3.1 ] ) , are the points @xmath96 where @xmath97 is any integer ( and may have factors in common with @xmath95 ) .",
    "the definition of @xmath90 is the same as before ; though it should be noted that the discontinuity interval of @xmath43 at a point ( [ e3.5 ] ) is made up of contributions from an infinite number of discontinuities from derivatives of terms on the right side of ( [ e2.5 ] ) . of course , if @xmath87 in ( [ e3.2 ] ) is equal to @xmath98 ( or larger ) , @xmath90 and @xmath43 are identical , and step 5 can be eliminated from the algorithm described below .    in order to motivate the initial steps in the algorithm , it is helpful to think of @xmath99 as representing the positions of a set of @xmath0 quasiparticles located on a circle of unit circumference , fig .",
    "[ fg2 ] , and subjected to two kinds of forces , corresponding to @xmath33 and @xmath100 , thought of as potential energies . in this picture",
    ", @xmath101 represents an external force exerted on particle @xmath102 , and @xmath103 , ( [ e2.11 ] ) , the force which particle @xmath102 exerts on particle @xmath12 . the minimization condition ( [ e2.9 ] )",
    "can then be interpreted as stating that , for every @xmath102 , the external force exerted on particle @xmath102 is equal to the sum @xmath104 of the forces which it exerts on the other particles , which is the same as saying that the net force on particle @xmath102 is zero .",
    "the pair force @xmath103 is constant as long as @xmath77 is not at a discontinuity of @xmath90 , while if it is at such a discontinuity , it can take any value , see ( [ e2.11 ] ) , corresponding to @xmath45 in the range ( [ e3.3 ] ) .",
    "in addition , there is a hard core interaction which prevents two quasiparticles from passing through each other , and ensures that the inequalities ( [ e2.17 ] ) are satisfied .",
    "note that there can very well be solutions to the minimization problem in which some of these inequalities are equalities .",
    "if , for example , @xmath105 , then @xmath106 can be very large and negative , see the remarks following ( [ e2.16 ] ) , corresponding to the fact that the hard core allows particle 3 to exert a very large ( negative ) force on particle 2 .",
    "the initial steps of the algorithm consist of a number of horizontal and vertical shifts ; the terminology comes from the picture of points on the graph of @xmath43 , sec .",
    "a _ horizontal shift _ is a change in the positions of the quasiparticles , and thus the @xmath77 , with the @xmath45 ( and thus the @xmath103 ) held fixed , while a _ vertical shift _ is a change in the set of @xmath45 values with the quasiparticle positions , and thus the @xmath77 , held fixed .",
    "in addition , we shall make use of the concept of a _ cluster _ , which means a collection of quasiparticles , with their labels belonging to an index set @xmath107 containing @xmath108 members , with the property that the collection is connected by a set of `` pair bonds '' @xmath109 , @xmath102 and @xmath12 members of @xmath107 , with @xmath77 at one of the discontinuities of @xmath90 .",
    "for example , if @xmath75 and @xmath110 fall on discontinuities of @xmath90 , then it is possible , but not necessary , to define a cluster @xmath111 of @xmath112 quasiparticles , as in fig .",
    "we shall always think of the entire collection of quasiparticles as divided up among a set of mutually disjoint clusters , where a quasiparticle which does not belong to a larger cluster constitutes its own cluster containing only one element .",
    "if all the quasiparticles belong to a single cluster of @xmath113 elements , we shall call this a _",
    "complete cluster_. in any horizontal shift , the clusters are moved rigidly , in the sense that @xmath114 does not change if @xmath12 and @xmath102 belong to the same cluster .",
    "( this must obviously be the case whenever the cluster is linked together by bonds for which the @xmath45 fall in the interiors of the corresponding discontinuity intervals ( [ e3.3 ] ) . )",
    "conversely , a vertical shift is always applied to a single cluster .",
    "the algorithm for finding a minimum consists of the following steps , details of which are given below in sec .",
    "[ s3c ] .",
    "initialization :    choose an initial approximate @xmath90 by , for example , setting @xmath115 in ( [ e3.2 ] ) , and some initial values for the @xmath116 satisfying ( [ e2.17 ] ) , with a set of clusters specified ( e.g. , each quasiparticle might belong to its own cluster ) .",
    "\\1 . horizontal shift i :    calculate a `` velocity '' for each cluster , and use this to carry out a horizontal shift until for the first time some @xmath77 for @xmath12 and @xmath102 belonging to different clusters reaches a discontinuity of @xmath90 , in which case we shall say that these two clusters have `` collided '' to form a temporary combined cluster .",
    "go to step 2 .",
    "vertical shift :    carry out a vertical shift on the temporary combined cluster following the prescription given in ( [ e3.8 ] ) below and in the remarks which follow , and apply the test which is described there .",
    "if the result of the test is negative , the combined cluster is rejected , the collection of clusters is defined to be the same as it was before the collision , and the algorithm returns to step 1 .",
    "if the result of the test is positive , the temporary combined cluster becomes permanent , and is considered part of the collection of clusters for the next step in the algorithm .",
    "if this cluster is complete , go to step 3 ; if not , return to step 1 .",
    "linear optimization i :    with all the quasiparticles in a single cluster , apply linear optimization , as discussed in sec .",
    "[ s3c ] below , to produce a vertical shift which maximizes a non - negative parameter @xmath117 .",
    "if @xmath118 , then the target @xmath14 is inside the polyhedron @xmath57 associated with the current @xmath66 in the approximation in which @xmath43 has been replaced by @xmath90 ; go to step 5 .",
    "if @xmath119 , then @xmath14 is not inside the polyhedron ; go to step 4 .",
    "horizontal shift ii :    use the @xmath45 resulting from the linear optimization in 3 to divide the collection of quasiparticles into two clusters , which undergo a horizontal shift relative to each other until they collide ( as in step 1 ) to form a new , combined cluster which is a complete cluster . return to step 3 .",
    "linear optimization ii :    repeat the linear optimization step 4 , but with each @xmath45 now restricted to the corresponding _ exact _ interval ( [ e2.16 ] ) .",
    "if , however , @xmath77 falls at a point",
    "where @xmath90 , unlike @xmath43 , has no discontinuity , then the corresponding @xmath45 is placed at the center of the corresponding discontinuity of @xmath43 , and is treated as a constant , not a variable , during the linear optimization . if the optimization yields @xmath118 , the current @xmath66 is the desired solution to the minimization problem , and the algorithm stops .",
    "if @xmath117 is less than 1 , @xmath90 is replaced by another approximation to @xmath43 constructed in the same way , but using a larger value of @xmath87 in ( [ e3.2 ] ) .",
    "the current @xmath66 values are changed by very small amounts so that none of the @xmath77 fall at discontinuities of the new @xmath90 , and the algorithm returns to step 1 .",
    "the explanations given below are numbered in the same way as the steps in the preceding summary .",
    "\\1 . given a set of @xmath103 values , the net force on the @xmath102th quasiparticle",
    "is @xmath120 were the force given by a continuous function , it would be possible to find the energy minimum by assigning to each quasiparticle a velocity proportional to the force acting on it , and then solving the resulting dynamics .",
    "what is actually done in the algorithm is to assign to each cluster a velocity given by the total force acting on all the quasiparticles in the cluster divided by the number of particles in the cluster , which is the average force per particle : @xmath121 it is only the relative cluster velocities which are of interest in determining the horizontal shift ; adding the same constant to every @xmath122 will make no difference , and one can arrange ( for example ) that the cluster containing @xmath123 remains fixed .",
    "the clusters are then shifted by amounts proportional to their respective velocities until the first `` collision '' occurs , in the sense that @xmath77 for @xmath102 in one cluster and @xmath12 in another reaches a discontinuity of @xmath90 .",
    "\\2 . once the temporary ,",
    "combined cluster @xmath124 has been formed , a vertical shift is applied to the @xmath103 for @xmath102 and @xmath12 in @xmath124 .",
    "this is done by first calculating a preliminary value for the shift of the @xmath103 or @xmath45 values from the formula @xmath125 / |j_c| .",
    "\\label{e3.8}\\ ] ] the motivation for this choice is the following .",
    "if all the quasiparticles were in a single cluster , @xmath126 , the change ( [ e3.8 ] ) would result in a new set of pair forces @xmath127 with the property that @xmath128 that is , one would have solved the minimization problem . with @xmath129 , the result",
    "would , instead , be to make the difference @xmath130 , the sum of the forces acting on quasiparticle k , independent of @xmath102 for all @xmath102 in @xmath124 , and to minimize @xmath131 as much as is possible by changing only the pair interactions @xmath103 inside the cluster @xmath124",
    ".    however , formula ( [ e3.8 ] ) does not take account of the possibility that the @xmath132 in ( [ e3.9 ] ) might lie outside the interval ( [ e3.3 ] ) determined by @xmath90 . when this is the case , the new @xmath132 is placed at whichever end of the discontinuity interval lies closest to the value given by ( [ e3.9 ] ) .",
    "the test for rejecting or retaining the combined cluster @xmath124 is then the following . if for each of the pairs @xmath102 and @xmath12 for which @xmath102 belongs to one of the clusters involved in the collision and @xmath12 to the other , the new @xmath132 is at one of the ends of the interval ( [ e3.3 ] ) , the combined cluster @xmath124 is rejected , whereas if at least one of these values falls in the interior of the corresponding interval , @xmath124 is accepted . note that whether the cluster @xmath124 is accepted or rejected , the new values of @xmath132 , and thus the corresponding @xmath133 , produced in the vertical shift are retained when going on to the next step of the algorithm , which is either step 1 or , in the case in which @xmath124 is accepted and @xmath126 , step 3 .",
    "the algorithm would still function correctly if a combined cluster were never rejected . however , this would mean having to apply linear optimization , step 3 , more often , and would result in a slower computation .",
    "the process of allowing clusters to move relative to each other past discontinuities which represent relatively small changes compared to the large forces representing a situation `` far from equilibrium '' helps to achieve a better preliminary value of @xmath66 before going on to step 3 .    3 , 4 .",
    "the linear optimization step is basically a test to see whether the target @xmath14 lies inside the polyhedron representing @xmath57 in the approximation in which @xmath43 is replaced by @xmath90 .",
    "the idea is to begin at a particular vertex @xmath134 of the polyhedron , fig .",
    "[ fg3 ] , and draw a straight line from @xmath134 to the target @xmath14 .",
    "points along this line are of the form @xmath135 where @xmath117 is a number between 0 and 1 .",
    "the linear optimization procedure , the details of which are given in the appendix , determines the largest value of @xmath117 for which a point of the form ( [ e3.12 ] ) lies inside or on the boundary of the polyhedron . if this value is less than 1 , as in fig .",
    "[ fg3 ] , the target lies outside the polyhedron , and the point ( [ e3.12 ] ) determined by the maximum value of @xmath117 specifies a facet of the polyhedron lying in the direction of the target , as viewed from the starting vertex @xmath136 .",
    "this facet is generated by letting ( @xmath137 ) of the @xmath45 vary over their entire discontinuity intervals , while the remaining @xmath45 are fixed either at the top or at the bottom of their discontinuity intervals .",
    "the @xmath77 corresponding to the former are `` rigid '' in the sense that they can not be altered by a horizontal shift ( which , by definition , must leave the @xmath45 unchanged ) , and one can identify two clusters of quasiparticles , each one connected by such rigid bonds .",
    "once these two clusters have been identified , they can be shifted relative to each other , in a direction which is obvious , until they collide at the first discontinuity of @xmath90 .",
    "this collision results in a new , complete cluster , and the corresponding @xmath57 is a polyhedron adjacent to the one considered earlier , and shares with it the facet which was identified in the previous linear optimization step .",
    "note that this new cluster is accepted without carrying out the test used in step 2 of the algorithm .",
    "also , in the unlikely event that the maximum @xmath117 corresponds to the intersection of two or more facets of the polyhedron , the actual optimization algorithm described in the appendix will , in effect , `` choose '' one of these facets , and thus the polyhedron adjacent to it in the direction of the target @xmath14 .",
    "if the optimization carried out in step 3 yields @xmath138 , the target @xmath14 lies inside the polyhedron generated by the discontinuities of @xmath90 , but it may or may not lie inside the corresponding polyhedron generated by restricting the @xmath45 to lie in the exact interval ( [ e2.16 ] )  for the corresponding discontinuity . to test whether this is the case , one repeats the linear optimization technique of step 3 , but now starting with each @xmath45 at its _ exact _ maximum possible value , and constrained to be greater than or equal to its _ exact _ minimum possible value , with the exception of those @xmath45 for which @xmath77 does not fall at a discontinuity of @xmath90 , which are assigned fixed values at the center of the appropriate ( exact ) discontinuity intervals of @xmath43 . one",
    "could , of course , make _ all _ of the @xmath45 variable during the linear optimization process .",
    "however , as the discontinuity intervals in @xmath43 which are not in @xmath90 are , by construction , relatively small , the main effect of using a larger set of variables would be to slow down the linear optimization without much hope of actually finding a solution with @xmath138 when the restricted search yields one with @xmath119 .",
    "note that if such a restriction does result in overlooking a @xmath138 solution , this solution , or one equivalent to it , will nevertheless be found later when the number of discontinuities of @xmath90 is increased .",
    "if the maximum value of @xmath117 obtained by using linear optimization with the exact discontinuity intervals of @xmath43 is still greater than or equal to 1 , then the current @xmath66 , and thus the current set of @xmath77 , represents an actual solution to the minimization problem , and this does not depend upon the approximations used in constructing @xmath90 , because the resulting @xmath45 values all fall within the range where @xmath90 is identical to @xmath43 .",
    "if , on the other hand , one finds that @xmath117 is less than 1 , this means that the current @xmath66 is not a solution to the true minimization problem ; instead , it is as good as one can do using the approximate @xmath139 . to do better",
    ", it is necessary to increase the number of discontinuities .",
    "our procedure at this point is to throw away all the information associated with the @xmath45 values obtained in the immediately preceding step of linear optimization , and simply start over again at step 1 using the current @xmath66",
    ". one might be able to improve the algorithm in this respect , but since the initial steps of the algorithm are relatively fast , it does not seem likely that one would obtain a significant increase in speed .",
    "the program we constructed to implement the algorithm described above was tested in the following way .",
    "we chose a winding number equal to the inverse golden mean ( 0.618  ) and a value of @xmath140 , see @xcite , of 0.6 , resulting in a set of 60 pairs ( @xmath38 and @xmath141 ) of discontinuities of @xmath43 in the interval @xmath17 with a magnitude greater than a resolution of @xmath142 .",
    "( some tests used alternative values for @xmath140 , 0.1 , 0.5 , and 1.0 , for which there are 146 , 66 , and 47 pairs of discontinuities , respectively , exceeding this resolution . )",
    "the parabolas were assumed to be equally spaced , with @xmath143 independent of @xmath144 .",
    "then we employed the following `` inverse strategy '' . with",
    "@xmath0 fixed , random values of @xmath145 , lying on the full set of discontinuities of @xmath43 were chosen , subject to the constraints ( [ e2.17 ] ) , and values @xmath103 inside the discontinuity intervals were also chosen randomly , thus defining  see ( [ e2.10 ] ) , ( [ e2.9 ] ) , and ( [ e2.3])@xmath14 for a model of @xmath0 parabolas with the solution to its energy minimization problem already known . the algorithm was then applied to this model starting at the initialization step 0 , with a ( different ) random collection of @xmath146 , and a choice of @xmath87 ( the number of pairs of discontinuities in the approximate @xmath90 ) to search for the correct solution .",
    "note that the running time increases linearly with @xmath87 .",
    "but since as @xmath87 increases , the size of the discontinuities in @xmath90 is decreasing , the probability that a random choice of @xmath14 will actually require a larger value of @xmath87 goes to zero exponentially with increasing @xmath87 .",
    "we found that using an initial value of @xmath147 when @xmath0 is small saves a lot of running time , and in almost all cases @xmath148 was sufficient to find a ground state with @xmath0 up to 100 .",
    "to determine the @xmath0 dependence of the running time , we generated and timed 10 distinct potentials for each @xmath0 in an increasing series up to @xmath149 . using an hp 9000 model 735 workstation with 64 mb of ram and a cpu with 20 mflops , the average time in seconds required to find a solution was approximately @xmath150 , or a quarter of an hour for @xmath151 .",
    "the time required for linear optimization varies as @xmath81 , but as @xmath0 becomes larger , `` quasiparticle dynamics '' takes up a larger fraction of the time : 60 - 70% for @xmath151 .",
    "the algorithm found the correct ground state in particular cases for @xmath0 as large as 200 .",
    "we would like to thank s. aubry , p. delaly , a. hamm , r. s. mackay and p. rujan for useful discussions .",
    "this work was supported by the deutsche forschungsgemeinschaft ( bonn , germany ) .",
    "the linear optimization procedure used in steps 3 and 5 of the algorithm functions in the following way . written out in terms of components , eq.([e3.12 ] ) has the form : @xmath152 for @xmath153 .",
    "the equation for @xmath154 can be omitted because of the constraints ( [ e2.7 ] ) and ( [ e2.18 ] ) . in turn , the @xmath45 for @xmath155 can be written as @xmath156 , \\label{ea.2}\\ ] ] where the @xmath63 variables @xmath157 take values on the closed interval @xmath158 in step 5 of the algorithm , @xmath90 in ( [ ea.2 ] ) should be replaced with the exact function @xmath43 .",
    "the vertex @xmath136 of the polyhedron is defined as the value of @xmath58 when @xmath159 , and is obtained by setting all the @xmath157 in ( [ ea.2 ] ) equal to zero , and inserting the resulting @xmath45 in the right side of ( [ ea.1 ] ) .",
    "it is , thus , a known quantity , as is also the target @xmath14 .",
    "by contrast , the @xmath157 and @xmath117 are considered as variables subject to the @xmath64 equalities obtained by inserting ( [ ea.2 ] ) in ( [ ea.1 ] ) , and the inequalities ( [ ea.3 ] ) , along with @xmath160 . if we define the objective function to be equal to @xmath117 , maximizing @xmath117 subject to these constraints becomes a standard problem in the theory of linear optimization . for a compact but clear description , see @xcite .",
    "the usual approach is to replace the second set of inequalities in ( [ ea.3 ] ) by the requirement that the `` slack '' variables @xmath161 be non - negative .",
    "however , in order to minimize the number of variables , we have modified the formulation in @xcite , as discussed below , so that at any point in the calculation , either @xmath157 or @xmath162 , but not both , appears as a variable in the tableau .    the first task is to construct a tableau in restricted normal form , in which the @xmath64 equalities ( [ ea.1 ] ) , expressed in terms of the @xmath157 using ( [ ea.2 ] ) , are transformed into expressions in which @xmath64 of the @xmath157 variables are expressed as linear functions of the remaining @xmath163 s and @xmath117 . to see how this is done ,",
    "note that since the @xmath154 equation is missing from the set ( [ ea.1 ] ) , @xmath164 occurs only in the @xmath102th equation , and in none of the others .",
    "therefore , if , for each @xmath165 , the coefficient of @xmath164 in ( [ ea.2 ] ) is non - zero , we can rewrite the @xmath64 equalities in the form @xmath166 for @xmath153 , with no @xmath167 appearing anywhere on the right side of any of these equations .    it may , however , happen that the coefficient of some @xmath164 in ( [ ea.2 ] ) vanishes , because @xmath82 does not have a discontinuity at @xmath168 . in this case",
    "the following strategy can be employed .",
    "construct a graph in which the @xmath0 quasiparticles are vertices , and they are connected together in one cluster using @xmath64 edges @xmath169 chosen so that for each edge the coefficient of @xmath157 in ( [ ea.2 ] ) does not vanish .",
    "such a graph is a tree with no closed loops , because a connected graph of @xmath0 vertices which includes a loop will have at least @xmath0 edges .",
    "one then chooses some vertex @xmath170 which has only one edge connecting it to another vertex @xmath171 , and solves the equation ( [ ea.1 ] ) with @xmath172 for @xmath173 ( or @xmath174 ) in terms of the other @xmath163 s .",
    "after this , eliminate vertex @xmath170 and the edge @xmath175 from the graph , and repeat the process . at each stage one",
    "finds ( it is useful to work out an example ) that the only @xmath163 s appearing on the right side of the equation either do not correspond to edges of the original graph , or else to edges which have already been eliminated . the latter , however , can be expressed ( recursively ) as functions of the @xmath163 s corresponding to edges which were not present in the original graph , thus leading to a set of @xmath64 equalities of a form similar to ( [ ea.5 ] ) .",
    "note that the @xmath157 whose coefficients are zero in ( [ ea.2 ] ) can be completely eliminated in constructing the linear optimization tableau , as they play no role .",
    "once the tableau has been constructed for the restricted normal form , the optimization is carried out as indicated in @xcite , with the following difference . when considering increasing the variable associated with a particular column , it is necessary to take account of both positive and negative entries in the column in order to test whether one of the left @xmath157 will reach either the upper or lower limit in ( [ ea.3 ] ) . if the choice is to set a left variable @xmath157 equal to 1 , it is replaced as a right variable by the corresponding @xmath162 , which is 0 , and the tableau is appropriately transformed ."
  ],
  "abstract_text": [
    "<S> a procedure is described for efficiently finding the ground state energy and configuration for a frenkel - kontorova model in a periodic potential , consisting of @xmath0 parabolic segments of identical curvature in each period , through a numerical solution of the convex minimization problem described in the preceding paper . </S>",
    "<S> the key elements are the use of subdifferentials to describe the structure of the minimization problem ; an intuitive picture of how to solve it , based on motion of quasiparticles ; and a fast linear optimization method with a reduced memory requirement . </S>",
    "<S> the procedure has been tested for @xmath0 up to 200 .    </S>",
    "<S> amssym.def amssym.tex </S>"
  ]
}