{
  "article_text": [
    "in the information retrieval domain , the combination of search results is a long studied problem , and can effectively increase the precision of the resulting system . as a result",
    ", many ir systems are designed to use multiple querying methods , and then combine the retrieved results , which is also called data fusion .",
    "fox and shaw showed the effectiveness of combining multiple retrieval runs as opposed to selecting only one of them .",
    "lee combined search strategies using a simple , non - weighed sum .",
    "vogt and cotrell used a linear combination model , for which they optimized the weights to maximize the system s precision .",
    "tiedemann employs a genetic algorithm to perform a similar optimization .    in this paper , we demonstrate a method to optimally combine the components of a paragraph retrieval system . our approach is similar to those listed above , as we use a simple linear combination model : however , we include all our system s components in this model , and not only the querying modules .",
    "this allows us to not only optimize the mixture of querying methods , but also of filters and scorers .",
    "we built our system using a multi - indexing architecture ( several indices are being used for the same text corpus ) , and including some state - of - the - art query generators and filters .",
    "our system retrieves a set of paragraphs from the text corpus based on the input query , which are then ranked according to their confidence scores and constitute the results list .",
    "all components are treated on the same level , and can equally contribute to the final confidence score associated to each retrieved paragraph .",
    "the components are combined using the linear combination model , and its weights are tuned using a heuristic optimization algorithm .",
    "finally , we evaluate the results on a paragraph selection task using a question answering dataset .",
    "the rest of the paper is organized as follows : in the next section , we present the architecture of our paragraph retrieval system . in section [ sec : scoring ] , we explain how all the components can be combined and tuned .",
    "finally , section [ sec : expresults ] presents our experimental results , while section [ sec : conclu ] contains the conclusion and discussion on future work .",
    "the architecture of our paragraph retrieval system is illustrated in figure [ fig1 ] .",
    "it is based on the typical design of a question answering system ( see for instance @xcite ) , without answer extraction , as we try to retrieve a paragraph containing the correct answer to an input question instead of extracting the exact answer string from the text .",
    "we do however use multi - indexing , which is , to our knowledge , not so commonly studied in qa literature .",
    "starting from a single text corpus , we create a set of indices which will be used for querying . for each index ,",
    "the text corpus is pre - processed in a distinct way .",
    "so far , our system implements the following four indices :    * * baseline * : standard inverted index on the text corpus , built using lucene , which includes stopwords removal and simple tokenization .",
    "only unigrams are indexed in this case * * lemmatization * : same as the baseline index but with a lemmatization step applied to the text corpus during pre - processing * * ngrams * : same as the baseline index but with 2-grams and 3-grams added to the indexing terms * * ngrams + coreference resolution * : same as ngrams , but with a coreference resolution step before indexing    we chose this multi - indexing approach in order to maximize the probability of retrieving the right paragraph in the querying stage ( through at least one index ) .",
    "typically , indexing in any specific way has its pros and cons ; either we generalize too much ( linking many similar terms to the same indexed term , for instance their common lemma ) , or not enough ( indexing all words or ngrams separately ) . as queries will sometimes work better with more generalization , and sometimes with less , we are trying to get the best of both worlds by creating multiple indices and using them in parallel .",
    "although there is a cost associated to creating and maintaining multiple indices , both in terms of disk space and pre - processing time , we believe that , even if the resulting improvements in recall are minimal , the benefits will outweigh the costs as long as the number of indices used is not excessively large .    in the querying stage , the input question is transformed into several queries , which is a common technique in ir and qa ( see for instance @xcite ) .",
    "one query is generated for each index to match its specificities .",
    "for instance , to query the lemmatization index , the input question needs to undergo the same lemmatization step as did the text corpus .",
    "furthermore , two additional query generation approaches are implemented , and both are used on the baseline index ;    * * named entity recognition * : builds a query containing only the named entities found in the input question * * synonyms * : query expansion with synonyms based on wordnet @xcite    each query will return a list of paragraphs ; in the last stage of our system , those paragraphs will be evaluated using a set of criteria , and then re - ranked in order to provide the most relevant list of paragraphs with regards to the original question .",
    "this re - ranking is based on our scoring framework , which is presented in the next section .",
    "the criteria we use at this stage are based on word counts ( used extensively in ir and qa literature , for instance in @xcite ) and latent dirichlet allocation ( lda ) @xcite .    *",
    "* common words * : number of common words between the paragraph and the input question * * common 2-grams * : same as above but with 2-grams instead of single words * * common 3-grams * : same as above but with 3-grams * * lda-10 * : cosine similarity between the probability vectors of the paragraph and the input question , based on a lda model with 10 topics , trained on the text corpus * * lda-100 * : same as above but with a 100 topics model",
    "our method to score a paragraph is a simple application of the linear combination model to all the components of our system .",
    "we compile a list of criteria ( we will call them features through the rest of the paper ) consisting of all the query generators from the querying stage and the evaluators from the re - ranking stage .",
    "each of those features gives a distinct score to each paragraph . for queries ,",
    "the score of a paragraph is given by the lucene confidence score if this paragraph was returned in the results list when using this query , and it is set to @xmath0 otherwise . for evaluators ,",
    "this is straightforward .",
    "each of these scores is then normalized using the z - score normalization method @xcite .",
    "finally , the overall score of a paragraph @xmath1 is computed as a linear combination of the features @xmath2 , as shown below :",
    "@xmath3    where @xmath4 is the number of components ( evaluators and query generators ) of the system ( in our case @xmath5 ) ; @xmath6 is the score given by component @xmath7 to paragraph @xmath8 ; and @xmath9 are weights such that @xmath10    the actual ranking of the paragraph can be done by simply sorting them according to their score .",
    "this approach allows us to easily combine all the components of our system to obtain a global score for each paragraph .      in ( [ linearcomb ] )",
    ", the weights should be tuned to maximize precision .",
    "they could be defined manually according to the quality of each feature ( how relevant are the scores given by the feature ) , but unfortunately we do not have this knowledge beforehand . also , evaluating each feature individually does not account for their diversity and complementarity when combined .",
    "therefore , we decided to treat the tuning of those weights as a multivariate optimization problem , where the objective is to find the set of weights @xmath9 maximizing the overall performance of the system , according to an evaluation metric of interest .",
    "though the cost function is not differentiable , we can still apply a wide variety of heuristic optimization methods ( coordinate ascent , simulated annealing , ... ) to find the ( approximate ) best set of weights . for this work",
    ", we used a differential evolution algorithm @xcite to perform this task , as it would allow us to demonstrate the effectiveness of our approach while being relatively simple to implement .",
    "we used the dataset from the respubliqa 2010 competition @xcite , containing a text corpus of 10,700 european parliament transcripts ( taken from the jrc - acquis and europarl collections ) , accompanied with a set of 200 questions , each having the correct answer provided ( gold standard ) .",
    "the text documents are structured in numbered paragraphs of a few sentences each .",
    "we focused on the paragraph selection task ( finding the paragraph containing the correct answer ) , which made it possible to perform automated assessment , by comparing the identifiers of the retrieved paragraphs to the gold standard .",
    "we compared our results with the work of @xcite , who perform the same paragraph selection task on the same dataset .",
    "table [ table1 ] shows the results obtained by our system , first with all components combined in a naive way ( all weights @xmath9 from ( [ linearcomb ] ) being equal ) , and then with weight tuning as described in section [ sec : tuning ] .",
    "our metric of choice is the mean reciprocal rank ( mrr ) , which gives a score of @xmath11 for each question , where @xmath12 is the position of the paragraph containing the right answer in the results list . for the weight tuning experiment",
    ", we used @xmath13 rounds of cross - validation to avoid over - fitting . in each round ,",
    "the tuning was done on @xmath14 questions , and then evaluated on the remaining @xmath15 .",
    "the result shown in the table is the average of those @xmath13 mrr scores .",
    ".[table1 ] evaluation of our system , with and without weight tuning , and comparison with the questioncube system from @xcite .",
    "[ cols= \" < , > \" , ]",
    "in this paper , we demonstrated our method to efficiently combine the components of a paragraph retrieval system .",
    "we showed that using a heuristic optimization algorithm to tune this combination had a positive effect on the performance of our system .",
    "the overall performance is also in line with previous evaluations on the same dataset .",
    "finally , we showed how this methodology could be used to evaluate the added value of each component which could be useful in our future work .",
    "now that we have this framework as a backbone , we can easily add new components to the system to make it more competitive in the future , as only the basic components have been integrated so far .",
    "as was shown in the weight tuning experiment , some effort may be required to understand why some of our components do not bring so much added value , and modify them to address this situation .",
    "different optimization methods could also be implemented .",
    "we would like to thank david verborgh for providing valuable input during the development of our application .",
    "this work is part of a phd project funded by the innoviris institute , via their doctiris program , and carried out in cooperation with mentis .",
    "chu - carroll , j. , czuba , k. , prager , j. , itterycheriah , a. : in question answering , two heads are better than one .",
    "naacl 03 proceedings of the 2003 conference of the north american chapter of the association for computational linguistics on human language technology , volume 1 , 2431 ( 2003 )      dumais , s. , banko , m. , brill , e. , lin , j. , ng , a. : web question answering : is more always better",
    "? proceedings of the 25th annual international acm sigir conference on research and development in information retrieval ( 2002 )        lee , j. : combining multiple evidence from different properties of weighting schemes .",
    "sigir 95 proceedings of the 18th annual international acm sigir conference on research and development in information retrieval ( 1995 )            penas , a. , forner , p. , rodrigo , a. , sutcliffe , r. , forascu , c. , mota , c. : overview of respubliqa 2010 : question answering evaluation over european legislation .",
    "working notes of respubliqa 2010 , conference and labs of the evaluation forum ( clef ) ( 2010 )"
  ],
  "abstract_text": [
    "<S> we demonstrate a method to optimize the combination of distinct components in a paragraph retrieval system . </S>",
    "<S> our system makes use of several indices , query generators and filters , each of them potentially contributing to the quality of the returned list of results . </S>",
    "<S> the components are combined with a weighed sum , and we optimize the weights using a heuristic optimization algorithm . </S>",
    "<S> this allows us to maximize the quality of our results , but also to determine which components are most valuable in our system . </S>",
    "<S> we evaluate our approach on the paragraph selection task of a question answering dataset . </S>"
  ]
}