{
  "article_text": [
    "path tracking is the task of tracing out a 1 real dimensional solution curve described implicitly by a system of equations , typically @xmath0 equations in @xmath1 variables , given an initial point on , or close to , the path .",
    "this can arise in many ways , but our motivation is the solution of systems of polynomials via homotopy continuation ( see @xcite ) . in this method , to find the isolated solutions of the system @xmath2 for given polynomials @xmath3 , one constructs a homotopy , @xmath4 , @xmath5 such that @xmath6 is the target system to be solved while @xmath7 is a starting system whose isolated solutions are known .",
    "there is a well - developed theory on how to construct such homotopies to guarantee , with probability one , that every isolated solution of @xmath2 is the endpoint in the limit as @xmath8 of at least one smooth path @xmath9 , where @xmath10 on @xmath11 $ ] and where @xmath12 , @xmath13 , are the known isolated solutions of @xmath14 . similar constructions arise in other contexts , where the existence of a path leading to the desired solutions may or may not be guaranteed .",
    "even when there is no guarantee , experience shows that in some application domains continuation techniques yield solutions more reliably than newton s method , especially when good initial guesses are not available .",
    "while in our applications the path is just a means of arriving at the endpoint , in other applications one may desire to accurately trace out the path itself , such as when plotting the response of a mathematical model as one of its parameters is varied .",
    "the most common path tracking algorithms are predictor - corrector methods : from an approximate solution point on the path , a predictor gives a new approximate point a given step size along the path , then a corrector brings this new point closer to the path . for example , one may use an euler predictor , which steps ahead along the tangent to the path , or a higher order predictor that uses several recent points and the derivatives of the homotopy function at them to extrapolate to the predicted point .",
    "typically , the prediction is then used as the initial point for correction by newton s method .",
    "since the solution set is one - dimensional , an extra constraint is introduced to isolate the target of the correction . for general homotopies ,",
    "a useful constraint is to find where the solution path intersects the hyperplane normal to the last computed tangent direction . in the more restrictive setting of polynomial systems ,",
    "the homotopy can be designed such that the paths advance monotonically with @xmath15 , that is , there are no turning points , in which case it is acceptable ( and simpler ) to perform corrections by holding @xmath15 fixed .",
    "the adaptive precision algorithm we discuss here is compatible with any of these prediction and correction schemes .    for good results",
    ", the predictor step size must be chosen appropriately .",
    "too large a step size may result in a prediction outside the zone of convergence of the corrector , while too small a step size means progress is slow and costly .",
    "consequently , it has long been recognized that adaptive control of the step size is crucial for obtaining good reliability without undue computational cost .",
    "while step size control is well established , less attention has been paid to efficient handling of precision . with wider availability of software packages for higher precision arithmetic , along with faster computers to execute the software ,",
    "it becomes interesting to consider how adjustable precision might be deployed to improve the performance of path tracking algorithms .",
    "the issue at stake is analogous to step size control : without enough precision , path tracking will fail , but the use of excessive precision is inefficient . to address this tradeoff , this paper proposes an algorithm that dynamically adjusts the number of digits used in computations according to the evolution of the numerical conditioning of the homotopy function .    in our primary application of interest ,",
    "the solution of polynomial systems , there are several factors driving the need for higher precision .",
    "it is well known that high degree polynomials often lead to ill - conditioned problems . when treating polynomial systems in several variables , the total degree of the system , being the product of the degrees of the individual equations , quickly becomes large even for low degree polynomials , which can also lead to ill - conditioning .",
    "thus , one driving force is the desire to solve larger systems of higher total degree .",
    "a second motivation is that our systems often have some , or possibly many , singular solutions , and thus , the solution paths leading to these solutions are necessarily ill - conditioned near the end . while endgame methods exist for enhancing the accuracy with which such endpoints can be estimated , for singularities of high enough multiplicity more precision",
    "is required .",
    "finally , although the homotopy constructions guarantee , with probability one , that no path passes exactly through a singularity before reaching its endpoint , there is always a chance that a near singular condition can be encountered . to obtain the highest reliability possible , we need to detect this and allocate sufficient digits to successfully track past such obstructions .",
    "the paper is organized as follows . in section 2",
    ", we review the behavior of newton s method in floating point , revealing how its accuracy and convergence properties depend on precision . in section 3",
    ", we discuss path tracking with adaptive step size control and identify how it fails when precision is insufficient .",
    "this leads , in section 4 , to a novel technique for path tracking using adaptive precision .",
    "this new adaptive precision path tracking algorithm has been implemented in a software package , bertini , currently under development by the authors .",
    "several examples are presented in section 5 to illustrate the usefulness of adaptive precision .",
    "finally , in section 6 , a few related ideas that would make interesting studies are discussed .",
    "the core numerical process in the path tracker is the corrector , which in our case is newton s method .",
    "a good predictor speeds up the path tracker by allowing a large step while still supplying an initial guess within the convergence region of the corrector .",
    "however , it is the loss of convergence that causes path tracking to fail . in exact arithmetic ,",
    "as long as the path remains nonsingular , there must be a region surrounding the path within which newton s method converges quadratically . with a small enough step @xmath16 in @xmath15",
    ", we can be assured of advancing along the path , although possibly very slowly .",
    "this holds even if we use only a zero - th order predictor , i.e. , if the point from the last value @xmath17 is used to initialize the corrector for the new value @xmath18 .",
    "in contrast , in inexact floating point arithmetic , the convergence region can disappear , thus halting the path tracker .",
    "short of this , an unacceptably slow linear rate of convergence might dominate , causing the step size to plummet . it can also happen that the corrector converges but to an answer that is outside the desired tolerance .",
    "due to these considerations , an analysis of newton s method in floating point is of interest and will help us derive rules for setting the precision used in our path tracker .",
    "the following analysis resembles that of @xcite .",
    "let @xmath19 be continuously differentiable , and denote its jacobian matrix of partial derivatives as @xmath20 .",
    "to solve @xmath21 by newton s method given an initial guess @xmath22 , one iteratively updates @xmath23 , @xmath24 , as @xmath25    suppose that we work in floating point with unit roundoff @xmath26 .",
    "in other words , if we compute with a mantissa of @xmath27 bits in binary or with @xmath28 digits in decimal , @xmath29 .",
    "we may consider evaluating the residuals @xmath30 in higher precision , say @xmath31 .",
    "let @xmath32 be the floating point output of the procedure that evaluates @xmath33 .",
    "we assume that there exists a function @xmath34 depending on @xmath35 , @xmath26 , and @xmath36 such that the error @xmath37 obeys @xmath38 by definition , at a solution point @xmath39 , we have @xmath40 , so it is clear that the function @xmath34 drives the final error . to determine @xmath34 ,",
    "one must examine the function @xmath41 and the program that implements it .",
    "we will give a rough rule of thumb later for the systems we treat .    in solving eq .",
    "[ eq : newton ] for the correction @xmath42 , there is error in evaluating @xmath43 and in solving the linear system .",
    "both errors can be absorbed into an error matrix @xmath44 such that the computed correction is @xmath45 we assume this error is bounded by @xmath46 for some constant @xmath47 and positive function @xmath48 .",
    "we expect the first term because of roundoff of the jacobian , whereas @xmath48 accounts for errors in evaluating @xmath49 that do not vanish even when @xmath49 does .",
    "the constant @xmath50 accounts for the subsequent growth in the error during the linear solve .    for simplicity of notation ,",
    "let @xmath51 be the current guess , @xmath52 the new guess after a single iteration , and let @xmath53 be the solution point near @xmath54 .",
    "also , let s use the shorthand notations @xmath55 , @xmath56 , @xmath57 , @xmath58 and @xmath59 . in the next paragraph , we will establish a bound on @xmath60 in terms of @xmath61 .",
    "whenever @xmath62 , the newton step successfully reduces the error in the estimate of the root @xmath53 .    since @xmath63 , the taylor series of @xmath33 at @xmath53 gives @xmath64 where the higher order terms , @xmath65 , are quadratic or higher in @xmath66 .",
    "similarly , @xmath67 where the higher order terms are linear in @xmath66 .",
    "consequently , in a ball @xmath68 centered on @xmath53 with @xmath69 , there exist positive constants @xmath70 and @xmath71 such that @xmath72 in newton s method , we solve @xmath73 for @xmath74 and take the step @xmath75 where @xmath76 is the error in forming the sum .",
    "the standard model of round - off error in floating point addition @xcite gives @xmath77 so subtracting @xmath53 from both sides of eq .",
    "[ eq : vbarupdate ] , we have @xmath78 if @xmath49 is nonsingular and @xmath79 , then @xmath80 is nonsingular , the newton step is well defined , and @xmath81 accordingly , from eq .",
    "[ eq : newtonstepwitherror ] we have @xmath82 also , after adding @xmath83 to both sides of eq .",
    "[ eq : newtonstepwitherror ] and simplifying using eqs .",
    "[ eq : alpha1][eq : beta1 ] , we have @xmath84 substituting from eqs .",
    "[ eq : dnorm],[eq : dvdnorm ] into eq .",
    "[ eq : dbar1 ] and using eqs .",
    "[ eq : errorf],[eq : errorebound ] , we obtain the bound @xmath85+u \\right){\\delta}+",
    "k{\\|j^{-1}\\|}(1 + u)\\psi + u\\|v_*\\|.\\end{aligned}\\ ] ] this relation holds as long as @xmath79 , so that the linear solve in the newton step is well - defined , and @xmath54 is in the ball @xmath86 , so that eqs .",
    "( [ eq : alpha1][eq : beta1 ] ) hold .    if @xmath62 , the newton step reduces the error in the approximation of the root . in exact arithmetic",
    ", we have @xmath87 and @xmath88 , so @xmath89 . the error contracts if the initial guess is accurate enough so that @xmath90 .",
    "if we also have @xmath91 , it is clear that all subsequent iterates are nonsingular and contractive , from which one has the well - known result that newton s method converges quadratically to a nonsingular solution for a sufficiently accurate initial guess .",
    "one sees that the more singular the jacobian is at the root , the slower the convergence and the smaller the convergence zone .    in floating point arithmetic",
    ", we can not expect the error to converge to zero . from eq .",
    "[ eq : dbar ] , one may expect the error to contract until @xmath92 the second term is the error inherent in representing @xmath53 in floating point .",
    "the first term depends on the accuracy , @xmath34 , with which the function is evaluated .",
    "this can be reduced by using higher precision , @xmath36 , in the function evaluation per eq .",
    "[ eq : errorf ] .",
    "the precision of the jacobian and the linear solve do not affect the final error .",
    "on the other hand , the precision of the jacobian and the linear solve do affect convergence . without enough precision , @xmath93 may approach or surpass 1 , which means that the linear solve may fail due to singularity or may yield such an inaccurate step that the error diverges .",
    "notice that @xmath94 , where @xmath95 .",
    "the first term , @xmath96 , reflects the well - known result that in solving a linear system , floating point roundoff is magnified by the condition number of the matrix .",
    "to produce an improved path tracking algorithm , it is useful to first examine a standard predictor / corrector algorithm to see why adaptive step length control generally succeeds when conditioning is mild and why it may fail when conditioning is adverse .",
    "a simple and effective approach for step length control is to adjust the step length up or down according to the success or failure of a complete prediction / correction cycle .",
    "suppose the homotopy function @xmath97 defines a one - dimensional nonsingular path @xmath98 .",
    "we are given a start point approximately on the path , @xmath99 , an ending value of @xmath15 , and a tolerance to which points on the path are to be found .",
    "then , in brief , a predictor / corrector path tracker with adaptive step length control may be constructed as follows .",
    "initialize : :    select : an initial step size , @xmath100 ; the number of corrector    iterations allowed per step , @xmath101 ; the step adjustment    factor , @xmath102 ; the step expansion integer ,    @xmath103 ; and a minimum step size    @xmath104 .",
    "predict : :    estimate a new point near the path whose distance from the current    point is the step size .",
    "correct : :    iteratively improve the new path point , constraining its distance from    the prior path point .",
    "allow at most @xmath105 iterations to    reach the specified tolerance . on success",
    ": :    if the tolerance is achieved :    +    * update the current path point to be the newly found path point .    *",
    "if we have reached the final value of @xmath15 , exit with    _",
    "success_.    * if there have been @xmath106 successes in a row , expand the    step size by @xmath107 . on failure",
    ": :    if the tolerance is not achieved :    +    * cut the step length by @xmath108 .    *",
    "if @xmath109 , exit with _ failure_. loop : :    go back to * predict*.    the key is to allow only a small number of iterations in the corrector , typically only @xmath110 or @xmath111 .",
    "this forces the prediction to stay within a good convergence region surrounding the path .",
    "if a large number of iterations is allowed , a bad prediction might ultimately converge , but it may wander first and become attracted to a completely different path in the homotopy . keeping @xmath105 small",
    ", the step size adaptation slows down to negotiate sharp turns in the path and accelerates whenever the path is relatively straight .",
    "properly implemented , this results in a robust and efficient path tracking algorithm .",
    "we can be a bit more precise .",
    "let us do so by specifically considering an euler predictor with a newton corrector .",
    "both of these derive from the linearized local model of the path .",
    "the taylor series at @xmath112 is @xmath113 where the higher order terms , @xmath65 , are quadratic or higher in @xmath114 .",
    "ignoring the higher order terms and setting @xmath115 , one has the basic euler predictor and newton corrector relations .",
    "these are a system of @xmath0 equations in @xmath1 unknowns ; as long as the combined matrix @xmath116 $ ] is rank @xmath0 , there is a well - defined tangent direction and tracking may proceed .",
    "the predictor adds a constraint on the length of the step along the tangent , whereas corrector steps are constrained to move transverse to the tangent .",
    "the extra constraints are particularly simple in the case where @xmath117 is rank @xmath0 , for then the path progresses monotonically in @xmath15 , and the step can be controlled via the advance of @xmath15 .",
    "accordingly , one has a linear system to be solved for @xmath118 : @xmath119{{\\delta z}}=        -\\left ( h(z_1,t_1 ) +          \\frac{\\partial h}{\\partial t}(z_1,t_1){{\\delta t}}\\right).\\ ] ] for prediction , we set @xmath120 , the current step size , and for correction , we set @xmath121 .",
    "since the neglected terms are quadratic , the prediction error is order @xmath122 .",
    "thus , in the case of a failed step , cutting the step size from @xmath100 to @xmath123 reduces the prediction error by a factor of @xmath124 . in this way , cuts in the step size quickly reduce the prediction error until it is within the convergence region of the corrector . with a @xmath125th order predictor ,",
    "the prediction error scales as @xmath126 , potentially allowing larger step sizes . in any case",
    ", the adaptive approach quickly settles to a step size @xmath100 just small enough so that the corrector converges , while the next larger step of @xmath127 fails . with @xmath128 and @xmath129 ,",
    "the step size adapts to within a factor of 2 of its optimum , with an approximate overhead of 20% spent checking if a larger step size is feasible .",
    "failure of path tracking with an adaptive step size can be understood from the discussion of newton s method in   [ sec : newton ] . for small enough initial error and infinite - precision arithmetic",
    ", the newton corrector gives quadratic convergence to a nonsingular root .",
    "near a singularity , @xmath130 is large , which can lead to a small quadratic convergence zone and a slower rate of quadratic convergence .",
    "inexact arithmetic can further shrink the convergence zone , degrade the convergence rate from quadratic to linear , and introduce error into the final answer . from these considerations , we see that there are two ways for the adaptive step size path tracker to halt prematurely near a singularity .    1 .   the predictor is limited to a tiny step size to keep the initial guess within the convergence zone of the corrector .",
    "if this is too small , we may exceed the allotted computation time for the path .",
    "2 .   the path may approach a point where the final error of the corrector is as large as the requested path tracking tolerance .",
    "the first mode of failure can occur even with infinite precision , but degradation of the convergence properties with too low a precision increases the occurrence of this failure .",
    "the second mode of failure is entirely a consequence of lack of precision . by allocating enough precision",
    ", we can eliminate the second mode of failure and reduce the occurrence of the first mode .",
    "it is important to note that in some applications there is flexibility in the definition of the homotopy , which can be used to enlarge convergence zones and thereby speed up path tracking .",
    "for example , re - scaling of the equations and variables can sometimes help .",
    "however , such maneuvers are beyond the scope of this paper , which concentrates only on tracking the path of a given homotopy .",
    "the use of high precision can largely eliminate both types of path tracking failure identified above . however , high precision arithmetic is expensive , so it must be employed judiciously .",
    "one might be tempted to rachet precision up or down in response to step failures as in the adaptive step size algorithm .",
    "this presents the difficulty that there is just one stimulus , step failure , and two possible responses , cut the step size or increase precision . in the following paragraphs",
    ", we outline two possible algorithms for adapting both step size and precision .      the simplest approach to adapting precision , shown in figure 1 ,",
    "is to run the entire path in a fixed precision with adaptive re - runs .",
    "that is , if the path tracking fails , one re - runs it in successively higher precision until the whole path is tracked successfully or until limits in computing resources force termination .",
    "the advantage of this approach is that adaptation is completely external to the core path tracking routine .",
    "thus , this strategy can be applied to any path tracker that enables requests for higher precision .",
    "for example , in the polynomial domain , the package phc @xcite offers multiple precision , although the precision must be set when calling the program .",
    "the adaptation algorithm of figure  1 has two main disadvantages .",
    "first , when too low a precision is specified , the tracker may waste a lot of computation near the point of failure before giving up and initiating a re - run in higher precision .",
    "second , the whole path is computed in high precision when it may be needed only in a small section of the path , often near the end in the approach to a singular solution .",
    "a slightly more sophisticated treatment can avoid re - computing the segment of the path leading up to the failure point by requesting the tracker to return its last successful path point .",
    "the re - run in higher precision can then be initiated from that point on .",
    "[ fig : fixed_flow ]    ( 14.000000,11.000000)(0.000000,-11.000000 ) ( 3.0000,-1.0000)(6.0000,2.0000 ) ( 0.0000,-2.0000)(6.0000,2.0000)[c ] ( 3.0000,-2.0000)(0,-1)1.0000 ( 1.0000,-5.0000)(4.0000,2.0000)[c ] ( 3.0000,-5.0000)(0,-1)1.0000 ( 1.6250,-7.3750)(1,1)1.3750 ( 1.6250,-7.3750)(1,-1)1.3750 ( 4.3750,-7.3750)(-1,-1)1.3750 ( 4.3750,-7.3750)(-1,1)1.3750 ( 1.6250,-8.7500)(2.7500,2.7500)[c ] ( 4.3750,-6.9625)(0,0)[lt]no ( 3.4125,-8.7500)(0,0)[lb]yes ( 3.0000,-8.7500)(0,-1)1.0000 ( 1.5000,-11.0000)(3.0000,1.2500)[c ] ( 4.3750,-7.3750)(1,0)4.0000 ( 8.3750,-7.3750)(0,1)1.0000 ( 6.7500,-4.7500)(1,1)1.6250 ( 6.7500,-4.7500)(1,-1)1.6250 ( 10.0000,-4.7500)(-1,-1)1.6250 ( 10.0000,-4.7500)(-1,1)1.6250 ( 6.7500,-6.3750)(3.2500,3.2500)[c ] ( 8.8625,-3.1250)(0,0)[lt]y ( 10.0000,-4.2625)(0,0)[lt]n ( 10.0000,-4.7500)(1,0)1.0000 ( 11.0000,-5.3750)(3.0000,1.2500)[c ] ( 8.3750,-3.1250)(0,1)0.5000 ( 8.3750,-2.6250)(0,1)1.0000 ( 6.8750,-1.6250)(3.0000,1.2500)[c ] ( 6.8750,-1.0000)(-1,0)0.8750      instead of waiting for the adaptive step size method to fail before initiating higher precision , we propose to continuously monitor the conditioning of the homotopy to judge the level of precision needed at each step . in this way , the computational burden of higher precision is incurred only as needed , adjusting up and down as the tracker proceeds , while obtaining superior reliability .    to decide how much precision is needed",
    ", we turn to the analysis of newton s method from   [ sec : newton ] .",
    "we wish to ensure that the achievable accuracy is within the specified tolerance and that convergence is fast enough .    in what follows ,",
    "we need to evaluate @xmath131 and @xmath132 .",
    "these do not need to be very accurate , as we will always include safety margins in the formulas that use them .",
    "@xmath131 is readily available in the max norm , where we use the maximum magnitude of any of its entries .",
    "@xmath132 is more difficult , as we do not wish to compute the full inverse of the matrix .",
    "this issue has been widely studied in terms of estimating the condition number @xmath133 .",
    "a relatively inexpensive method , suggested in @xcite and elsewhere , is to choose a unit vector @xmath27 at random and solve @xmath134 for @xmath135 .",
    "then , we use the estimate @xmath136 .",
    "although this underestimates @xmath132 , tests of matrices up to size @xmath137 show the approximation to be reliably within a factor of 10 of the true value , which is easily absorbed into our safety margins .",
    "one requirement is that @xmath93 should be small enough to ensure that the error - perturbed jacobian is nonsingular .",
    "minimally , we require @xmath79 , but by requiring it to be a bit smaller , say @xmath138 for some @xmath139 , we force @xmath140 .",
    "this removes the growth of @xmath141 as one possible source of failure .",
    "suppose that the error function @xmath48 in eq .",
    "[ eq : errorebound ] is of the form @xmath142 .",
    "then , our first rule is to require @xmath143 using @xmath28 decimal digits of arithmetic results in precision @xmath144 , so we may restate this rule as    @xmath145.\\ ] ]    a second requirement is that the corrector must converge within @xmath105 iterations , where we keep @xmath105 small as in the usual adaptive step size algorithm , typically 2 or 3 .",
    "let us say that the tolerance for convergence is @xmath146 . recall that",
    "in each step of newton s method , we compute @xmath74 and take the step @xmath147 . the best estimate available of the accuracy is @xmath148 , so we declare success when @xmath149 .",
    "suppose that after @xmath150 iterations this is not yet satisfied .",
    "we still have @xmath151 iterations to meet the tolerance , and we would like to be sure that a lack of precision does not prevent success .",
    "pessimistically , we assume that the linear factor in @xmath61 in eq .",
    "[ eq : dbar ] dominates the quadratic one and that the rate of convergence does not improve with subsequent iterations .",
    "we force @xmath140 , and we have @xmath152 . including the same safety margin as before , @xmath153 , the requirement becomes @xmath154 as before , let s assume @xmath142 .",
    "taking logarithms , the number of decimal digits of precision must satisfy    @xmath155    since we only apply this formula when the tolerance is not yet satisfied , we have @xmath156 , or equivalently , @xmath157 .",
    "this implies that between corrector iterations , requirement  [ eq : setconvergencelog ] is always more stringent than eq .",
    "[ eq : setklog ] . however , we still use eq .",
    "[ eq : setklog ] outside the corrector , because @xmath158 is not then available .",
    "our third requirement is that the precision must be high enough to ensure that the final accuracy of the corrector is within the tolerance at full convergence . for this , eq .",
    "[ eq : finalerror ] is binding , so including a safety margin of @xmath159 and using the norm of the current approximate solution , @xmath160 , as the best available estimate of @xmath161 , we require @xmath162 suppose the error in evaluating the homotopy function is given by @xmath163 . if the function is evaluated in the same precision as the rest of the calculations , i.e. , @xmath164 , we have the requirement    @xmath165    if instead we evaluate the function to higher precision , say @xmath166 , we have the dual criteria    @xmath167    the effect of adding the two errors is absorbed into the safety factor @xmath168 .",
    "conditions a , b , and c ( or c@xmath169 ) allow one to adjust the precision as necessary without waiting for the adaptive step size to fail . if necessary , the precision can even be increased between corrector iterations .",
    "an algorithm using these criteria is described by the flowchart in figure 2 . in this flowchart ,",
    "`` failure '' in the predictor or corrector steps means that the linear solve of eq .",
    "[ eq : basicstep ] has aborted early due to singularity .",
    "using the magnitude of the largest entry in @xmath49 as @xmath131 , gaussian elimination with row pivoting may declare such a failure when the magnitude of the largest available pivot is smaller than @xmath170 , for then the answer is meaningless .",
    "this is more efficient than completing the linear solve and checking condition a or b , as these are sure to fail .",
    "[ fig : stepwiseflowchart ]    ( 15.375000,24.250000)(0.000000,-24.125000 ) ( 2.5000,-0.7500)(5.0000,1.5000 ) ( 0.0000,-1.5000)(5.0000,1.5000)[c ] ( 5.0000,-0.7500)(1,0)1.0000 ( 6.8750,-0.7500)(1.7500,1.7500 ) ( 6.0000,-1.6250)(1.7500,1.7500)[c ] ( 6.8750,-1.6250)(0,-1)1.0000 ( 4.8750,-4.6250)(1,1)2.0000 ( 4.8750,-4.6250)(1,-1)2.0000 ( 8.8750,-4.6250)(-1,-1)2.0000 ( 8.8750,-4.6250)(-1,1)2.0000 ( 4.8750,-6.6250)(4.0000,4.0000)[c ] ( 8.8750,-4.0250)(0,0)[lt]yes ( 7.4750,-6.6250)(0,0)[lb]no ( 8.8750,-4.6250)(1,0)1.0000 ( 9.8750,-5.3750)(2.0000,1.5000)[c ] ( 6.8750,-6.6250)(0,-1)1.0000 ( 5.6250,-8.8750)(1,1)1.2500 ( 5.6250,-8.8750)(1,-1)1.2500 ( 8.1250,-8.8750)(-1,-1)1.2500 ( 8.1250,-8.8750)(-1,1)1.2500 ( 5.6250,-10.1250)(2.5000,2.5000)[c ] ( 5.6250,-8.5000)(0,0)[rt]failure ( 7.2500,-10.1250)(0,0)[lb]success ( 5.6250,-8.8750)(-1,0)1.0000 ( 4.6250,-8.8750)(-1,0)1.0000 ( 1.6250,-9.6250)(2.0000,1.5000)[c ] ( 2.6250,-8.1250)(0,1)1.0000 ( 2.6250,-7.1250)(1,0)4.2500 ( 6.8750,-10.1250)(0,-1)1.0000 ( 5.8750,-12.1250)(1,1)1.0000 ( 5.8750,-12.1250)(1,-1)1.0000 ( 7.8750,-12.1250)(-1,-1)1.0000 ( 7.8750,-12.1250)(-1,1)1.0000 ( 5.8750,-13.1250)(2.0000,2.0000)[c ] ( 5.8750,-11.8250)(0,0)[rt]violated ( 7.1750,-13.1250)(0,0)[lb]ok ( 5.8750,-12.1250)(-1,0)3.2500 ( 2.6250,-12.1250)(0,1)2.5000 ( 6.8750,-13.1250)(0,-1)1.0000 ( 5.6250,-15.3750)(1,1)1.2500 ( 5.6250,-15.3750)(1,-1)1.2500 ( 8.1250,-15.3750)(-1,-1)1.2500 ( 8.1250,-15.3750)(-1,1)1.2500 ( 5.6250,-16.6250)(2.5000,2.5000)[c ] ( 5.6250,-15.0000)(0,0)[rt]failure ( 7.2500,-16.6250)(0,0)[lb]success ( 5.6250,-15.3750)(-1,0)3.0000 ( 2.6250,-15.3750)(0,1)5.0000 ( 6.8750,-16.6250)(0,-1)1.0000 ( 5.6250,-18.8750)(1,1)1.2500 ( 5.6250,-18.8750)(1,-1)1.2500 ( 8.1250,-18.8750)(-1,-1)1.2500 ( 8.1250,-18.8750)(-1,1)1.2500 ( 5.6250,-20.1250)(2.5000,2.5000)[c ] ( 5.6250,-18.5000)(0,0)[rt]violated ( 8.1250,-18.5000)(0,0)[lt]ok ( 5.6250,-18.8750)(-1,0)3.0000 ( 2.6250,-18.8750)(0,1)5.0000 ( 8.1250,-18.8750)(1,0)2.0000 ( 10.1250,-18.8750)(0,1)6.0000 ( 10.1250,-12.8750)(1,0)1.0000 ( 11.1250,-12.8750)(1,0)1.0000 ( 12.1250,-12.8750)(1,1)1.2500 ( 12.1250,-12.8750)(1,-1)1.2500 ( 14.6250,-12.8750)(-1,-1)1.2500 ( 14.6250,-12.8750)(-1,1)1.2500 ( 12.1250,-14.1250)(2.5000,2.5000)[c ] ( 13.7500,-11.6250)(0,0)[lt]no ( 13.7500,-14.1250)(0,0)[lb]yes ( 13.3750,-14.1250)(0,-1)1.0000 ( 12.3750,-16.6250)(2.0000,1.5000)[c ] ( 13.3750,-16.6250)(0,-1)1.0000 ( 11.3750,-19.6250)(1,1)2.0000 ( 11.3750,-19.6250)(1,-1)2.0000 ( 15.3750,-19.6250)(-1,-1)2.0000 ( 15.3750,-19.6250)(-1,1)2.0000 ( 11.3750,-21.6250)(4.0000,4.0000)[c ] ( 11.3750,-19.0250)(0,0)[rt]no ( 13.9750,-21.6250)(0,0)[lb]yes ( 13.3750,-21.6250)(0,-1)1.0000 ( 12.3750,-24.1250)(2.0000,1.5000)[c ] ( 11.3750,-19.6250)(-1,0)1.0000 ( 10.3750,-19.6250)(0,-1)2.0000 ( 10.3750,-21.6250)(-1,0)1.0000 ( 6.3750,-22.6250)(3.0000,2.0000)[c ] ( 6.3750,-21.6250)(-1,0)1.0000 ( 2.3750,-22.6250)(3.0000,2.0000)[c ] ( 2.3750,-21.6250)(-1,0)1.0000 ( 1.3750,-21.6250)(0,1)14.5000 ( 1.3750,-7.1250)(1,0)2.0000 ( 13.3750,-11.6250)(0,1)1.0000 ( 11.8750,-9.1250)(1,1)1.5000 ( 11.8750,-9.1250)(1,-1)1.5000 ( 14.8750,-9.1250)(-1,-1)1.5000 ( 14.8750,-9.1250)(-1,1)1.5000 ( 11.8750,-10.6250)(3.0000,3.0000)[c ] ( 13.8250,-7.6250)(0,0)[lt]no ( 11.8750,-8.6750)(0,0)[rt]yes ( 11.8750,-9.1250)(-1,0)2.2500 ( 9.6250,-9.1250)(0,-1)6.2500 ( 9.6250,-15.3750)(-1,0)1.5000 ( 13.3750,-7.6250)(0,1)3.7500 ( 13.3750,-3.8750)(0,1)1.0000 ( 12.1250,-2.8750)(2.5000,1.5000)[c ] ( 12.1250,-2.1250)(-1,0)5.2500    the algorithm does not attempt corrections at @xmath171 . this is because in our applications the target system @xmath172 often has singular solutions .",
    "it is safer to sample the incoming path while it is still nonsingular and predict to @xmath171 based on these samples . in this situation",
    ", it helps to employ a more sophisticated predictor than euler s method .",
    "for example , endgames that estimate the winding number of the root and use it to compute a fractional power series can be very effective  @xcite .      to use the foregoing procedures , we need the function evaluation error , @xmath34 , and the errors contributing to @xmath173 , namely , @xmath50 and @xmath48 .",
    "there is a trade - off between using rigorously safe bounds for highest reliability or using less stringent figures reflecting typical behavior to avoid the overuse of high precision .",
    "rough figures are acceptable as this is just a means of setting the precision .",
    "also , a user of the path tracker will not usually wish to expend a lot of effort in developing error bounds .",
    "a rigorous and automated way of establishing error bounds is to use interval arithmetic .",
    "following that approach , one may wish go all the way and use interval techniques to obtain a path tracker with fully rigorous step length control , as in @xcite .",
    "however , this can be expensive , due partially to the cost of interval arithmetic but more significantly due to the cost of overconservative error bounds , which slow the algorithm s progress by driving the step size smaller than necessary .",
    "still , when rigorous results are desired , it may be worth the cost .",
    "the method of @xcite does not explicitly include adaptive precision , so something along the lines discussed here could be useful in modifying that approach .    instead of using interval methods , we may approximate errors by accumulating their effects across successive operations .",
    "suppose the program to evaluate @xmath33 has been parsed into a straight line program , that is , a sequence of unary and binary operations free of branches or loops .",
    "suppose that at some intermediate stage of computation , we have computed a value @xmath174 for a real number @xmath175 , such that @xmath174 lies between @xmath176 and @xmath177 .",
    "( for a floating point complex number , this applies to both the real and imaginary parts . )",
    "let s use the shorthand @xmath178 to mean this entire interval . if @xmath179 and @xmath180 , the product @xmath181 is computed in floating point with unit round - off @xmath36 as @xmath182)$ ] , where the quadratic round - off term @xmath183 is neglected . the absolute error @xmath184 thus has the approximate bound @xmath185|a| |b|$ ] .",
    "similarly , @xmath186 is computed as @xmath187 which has an absolute error bounded by @xmath188 $ ] . using just these relations , an error bound for any straight - line polynomial function can be calculated in parallel with the function evaluation itself .",
    "similar relations can be developed for any smooth elementary function , such as the basic trigonometric functions . assuming that the inputs to the function , including both the input variables @xmath35 and any internal parameters of the function , are all known either exactly or with relative round - off error @xmath36 , the output of the error analysis is @xmath189 such that the error in the computed value @xmath32 is @xmath190 .",
    "when the result is rounded off to a possibly lower precision @xmath26 , the total error becomes the form shown in eq .",
    "[ eq : errorf ] .",
    "it is important to note that the error in the function depends on the error in its parameters .",
    "for example , consider the simple function @xmath191 .",
    "if this is rounded off to @xmath192 before we use high precision to solve @xmath193 , we will obtain an accurate value of @xmath194 but we will never get an accurate value of @xmath195 . although this is an obvious observation , it can easily be forgotten in passing a homotopy function from some application to the adaptive precision path tracking algorithm .",
    "if coefficients in the function are frozen at fixed precision , the algorithm tracks the solutions of the frozen function , not the exact problem that was intended . whether the difference is significant depends on the nature of the application and the sensitivity of the function .    while @xmath34 and @xmath48 concern the errors in evaluating the function and its jacobian , the factor @xmath50 concerns the stability of the linear solve .",
    "round - off errors can accumulate through each stage of elimination .",
    "when gaussian elimination with partial pivoting is used , the worst - case error bound grows as @xmath196 for solving an @xmath197 system @xcite .",
    "however , as indicated in @xcite , @xmath50 rarely exceeds @xmath0 with the average case around @xmath198 or @xmath199 .",
    "setting @xmath200 should therefore be sufficient for almost all cases .      to avoid program complexity and save computation time , it is preferable not to perform a full error analysis of the type just described .",
    "in many cases a rough analysis is sufficient and easily derived .",
    "this is indeed possible for the case of most interest to us : polynomial systems .",
    "suppose @xmath201 is a degree @xmath202 homogeneous polynomial @xmath203 where @xmath204 is just an index set for the coefficients @xmath205 . since @xmath206 is homogeneous , @xmath207 , so if @xmath208 , then also @xmath209 .",
    "consequently , the solution set of a system of homogeneous polynomials can be said to lie in projective space @xmath210 , the set of lines through the origin in @xmath211 .",
    "similarly , the solutions of multihomogeneous polynomials lie in a cross product of projective spaces , see @xcite",
    ".    any inhomogeneous polynomial @xmath212 can be easily homogenized to obtain a related function @xmath213 , with @xmath214 hence , for any solution @xmath39 of @xmath215 there is a corresponding solution @xmath216 of @xmath217 .",
    "one advantage of homogenization is that we can re - scale any solution @xmath218 of @xmath217 to make @xmath219 , which often helps numerical conditioning .",
    "error bounds for homogeneous polynomials can be estimated easily . if we rescale @xmath220 so that the maximum entry in @xmath221 has magnitude 1 , then the error in evaluating the degree @xmath202 homogeneous polynomial @xmath222 as in eq .",
    "[ eq : homogh ] is approximately @xmath223 similarly , the derivatives have an approximate error bound of @xmath224    at first glance , it may seem that errors can be reduced by simply scaling the functions , and thereby scaling their coefficients , by some small factor .",
    "but @xmath130 will scale oppositely , so the error predicted by eq .",
    "[ eq : finalerror ] is unchanged .",
    "this section contains a brief discussion of the implementation details for multiprecision arithmetic and for evaluating the rules for adapting precision .",
    "then we discuss the results of applying the adaptive precision path tracker to three example polynomial systems .",
    "bertini is a software package for computation in numerical algebraic geometry currently under development by the authors and with some early work by christopher monico .",
    "bertini is written in the c programming language and makes use of straight - line programs for the representation , evaluation , and differentiation of polynomials .",
    "all the examples discussed here were run using an unreleased version of bertini on an opteron 250 processor running linux .",
    "the adaptation rules , a , b , and c ( or c@xmath169 ) , leave some choices open to the final implementation . for the runs reported here ,",
    "we chose to evaluate function residuals to the same precision as the computation of newton corrections , so rule c applied , not rule c@xmath169 . also , in rules a and b , we chose to use @xmath225 , where @xmath0 is the number of variables , which is somewhat conservative for typical cases but underestimates the worst pathological cases .",
    "( see section  [ sec : errorestimates ] for more on this issue . )",
    "the rules require formulas for evaluating the error bounds @xmath226 and @xmath227 .",
    "these are problem dependent , so we report our choices for each of the example problems below .    to adaptively change precision ,",
    "bertini relies on the open source mpfr library for multiprecision support .",
    "bertini has data types and functions for regular precision ( based on the ieee `` double '' standard ) and higher precision ( using mpfr ) .",
    "although the program would be simpler if mpfr data types and functions were used exclusively , the standard double precision types and functions in c are more efficient , so bertini uses these whenever the adaptation rules indicate that double precision is sufficient .",
    "additional details regarding the use of multiple precision may be found using links from the bertini website .",
    "since the use of adaptive precision variables is highly implementation - specific , no other details are described here .",
    "mpfr requires the addition of precision to the mantissa in packets of 32 bits . since the discussion of the examples below involves",
    "both binary and decimal digits , table  [ tab : bits2digits ] shows how to convert between the two .",
    ".number of digits for mantissas at various levels of precision [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     the level of precision used by the step - adaptive precision path tracking algorithm developed above was degree- and path - dependent for the chebyshev polynomials , although all paths for a given degree needed approximately the same level of precision . in each degree that was considered ,",
    "the path ending nearest @xmath228 was one of the paths needing the highest level of precision for that degree .",
    "( this occurs because the spacing between the roots is smallest near @xmath229 . ) the levels of precision used for that path are displayed in figure 4 .",
    "it should be noted that for every degree considered , a complete solution set with all solutions correct to at least 10 digits was found .",
    "[ fig : chebyprec ]    we note that to solve the high degree chebyshev polynomials , a small initial step size was required to get the path tracker started . with too large an initial step , the predicted point was so far from the path that the adaptive precision rules increased precision to an unreasonable level without ever exiting the corrector loop .",
    "as diagrammed in figure  2 , the algorithm must exit the corrector loop before a decrease in step length can be triggered .",
    "various ad hoc schemes could detect and recover from this type of error , but we would prefer a step size control method based on an analysis of the predictor . for the moment , we defer this for future work .",
    "on some problems , endgames can speed convergence to the point that singular endpoints can be estimated accurately in double precision .",
    "it should be noted that is not generally the case . without enough precision , the `` endgame operating zone '' is empty @xcite .",
    "likewise , endgames based on deflating the system to derive a related nonsingular one @xcite may need higher than double precision to make a correct decision on the rank of the jacobian at each stage of deflation @xcite . moreover , if some other sort of singularity is encountered during path tracking , away from @xmath171 , endgames will not be useful while adaptive precision will be . in the case of tight final tolerances or endpoints of paths having high multiplicity",
    ", endgames will again need assistance from higher ( and therefore adaptive ) precision methods .",
    "conversely , high precision is expensive and floating point precision can never be made truly infinite , so to get the most out of whatever precision one uses , endgames are indispensable .",
    "the theory going into this new adaptive precision method revolves around newton s method or corrector methods in general .",
    "however , corrector methods are only one half of basic path tracking . a careful study of predictor methods is certainly warranted .",
    "the use of different predictor schemes , e.g. , adams - bashforth rather than euler , is well worth considering .",
    "a careful analysis of the predictor might be combined with the convergence criteria of the corrector to automatically determine a safe step length in place of the trial - and - error step length adaptation method we have used here .",
    "this might give an efficient alternative to @xcite , which presents a rigorous step length control algorithm based on interval arithmetic .",
    "allgower and k.  georg . , volume  13 of _ springer ser . in comput .",
    "_ springer ",
    "verlag , berlin heidelberg new york , 1990 . reprinted in 2003 by siam as volume 45 in the classics in applied mathematics series .",
    "a. leykin , j. verschelde , and a. zhao .",
    "evaluation of jacobian matrices for newton s method with deflation for isolated singularities of polynomial systems . in _",
    "snc 2005 proceedings .",
    "international workshop on symbolic - numeric computation .",
    "_ xian , china , july 19 - 21 , 2005 . edited by dongming wang and lihong zhi .",
    "19 - 28 .",
    "li . numerical solution of polynomial systems by homotopy continuation methods . in _ handbook of numerical analysis .",
    "volume xi .",
    "special volume : foundations of computational mathematics _ , edited by f. cucker , pp . 209304 , 2003 ."
  ],
  "abstract_text": [
    "<S> a path tracking algorithm that adaptively adjusts precision is presented . by adjusting the level of precision in accordance with the numerical conditioning of the path , </S>",
    "<S> the algorithm achieves high reliability with less computational cost than would be incurred by raising precision across the board . </S>",
    "<S> we develop simple rules for adjusting precision and show how to integrate these into an algorithm that also adaptively adjusts the step size . </S>",
    "<S> the behavior of the method is illustrated on several examples arising as homotopies for solving systems of polynomial equations .    </S>",
    "<S> * 2000 mathematics subject classification . * primary 65h10 ; secondary 65h20 , 65g50 , 14q99 .    * </S>",
    "<S> key words and phrases . </S>",
    "<S> * homotopy continuation , numerical algebraic geometry , polynomial systems .    </S>",
    "<S> homotopy continuation , numerical algebraic geometry , polynomial systems </S>"
  ]
}