{
  "article_text": [
    "_ logical frameworks _ provide general languages in which it is possible to represent a wide variety of logics , programming languages , and other formal systems .",
    "they are designed to capture uniformities of the deductive systems of these object logics and to provide support for implementing and reasoning about them .",
    "one application of particular interest of such frameworks is the specification of programming languages and the formalization of their semantics in view of formal reasoning about important properties of these languages , such as their soundness .",
    "programming languages that enjoy such properties provide a solid basis for building software systems that avoid a variety of harmful defects , leading to systems that are significantly more reliable and trustworthy .",
    "the mechanism by which object - logics are represented in a logical framework has a paramount importance on the success of a formalization .",
    "a naive choice of representation can seriously endanger a project almost from the start , making it almost impossible to move beyond the very first step of the developments of a case study ( see @xcite , which barely goes beyond encoding the syntax of the @xmath1-calculus ) .",
    "higher - order abstract syntax ( hoas ) is a representation technique used in some logical frameworks .",
    "using hoas , whose idea dates back to church  @xcite , binding constructs in an object logic are encoded within the function space provided by a meta - language based on a @xmath0-calculus .",
    "for example , consider encoding a simple functional programming language such as mini - ml @xcite in a typed meta - language , where object - level programs are represented as meta - level terms of type @xmath2 .",
    "we can introduce a constant @xmath3 of type @xmath4 to represent functions of one argument .",
    "using such a representation allows us to delegate to the meta - language @xmath5-conversion and capture - avoiding substitution .",
    "further , object logic substitution can be rendered as meta - level @xmath6-conversion .",
    "however , experiments such as the one reported in  @xcite suggest that the full benefits of hoas can be enjoyed only when the latter is paired with support for _ hypothetical _ and _ parametric _ judgments  @xcite .",
    "such judgments are used , for example , in the well - known encoding of inference rules assigning simple types to mini - ml programs .",
    "both the encoding of programs and the encoding of the typing predicate typically contain _ negative _ occurrences of the type or predicate being defined ( , the underlined occurrence of @xmath2 in the type of @xmath3 above ) .",
    "this rules out any naive approach to view those set - theoretically as least fixed points  @xcite or type - theoretically as inductive types , which employ strict positivity @xcite to enforce strong normalization . as much",
    "as hoas sounds appealing , it raises the question(s ) : how are we going to reason about such encodings , in particular are there induction and case analysis principles available ?    among the many proposals  that we will survey in section  [ sec : rel]one solution that has emerged in the last decade stands out : _ specification _ and ( inductive ) _ meta - reasoning _ should be handled within a single system but at different _",
    "levels_. the first example of such a meta - logic was @xmath7  @xcite , soon to be followed by its successor , @xmath8  @xcite .",
    "to get rid of the local signatures required by linc s @xmath9 quantifier .",
    "even more recently gacek , miller & nadathur presented the logic @xmath10 to ease reasoning on open terms and implemented it in the _ abella system _ @xcite .",
    "however , as this overdue report of our approach describes with an undeniable tardiness a system that was developed before the aforementioned new contributions , we will take the liberty to refer to @xmath8 as the `` canonical '' two - level system .",
    "we will discuss new developments in more depth in section  [ ssec:2lr ] .",
    "] they are both based on intuitionistic logic augmented with introduction and elimination rules for _ defined _ atoms ( partial inductive definitions , pids  @xcite ) , in particular _",
    "definitional reflection _",
    "( _ defl _ ) , which provides support for case analysis . while @xmath7 has only induction on natural numbers as the primitive form of inductive reasoning , the latter generalizes that to standard forms of induction and co - induction @xcite",
    "; @xmath8 also introduces the so - called `` nabla '' quantifier @xmath9  @xcite to deal with parametric judgments .",
    "this quantifier accounts for the dual properties of eigenvariables , namely _ freshness _",
    "( when viewed as constants introduced by the quantifier right rule ) and _ instantiability _ as a consequence of the left rule and case analysis .",
    "consistency and viability of proof search are ensured by cut - elimination  @xcite . inside the meta - language , a _ specification logic _ ( sl )",
    "is developed that is in turn used to specify and ( inductively ) reason about the _ object logic / language _ ( ol ) under study .",
    "this partition avoids the issue of inductive meta - reasoning in the presence of negative occurrences in ol judgments , since hypothetical judgments are intensionally read in terms of object - level provability .",
    "the price to pay is coping with this additional layer where we explicitly reference the latter .",
    "were we to work with only a bare proof - checker , this price could be indeed deemed too high ; however , if we could rely on some form of automation such as tactical theorem proving , the picture would be significantly different .",
    "the first author has proposed in  @xcite that , rather than implementing an interactive theorem prover for such meta - logics from scratch , they can be simulated within a modern proof assistant .",
    "( coq  @xcite in that case . )",
    "the correspondence is roughly as follows : the ambient logic of the proof assistant in place of the basic ( logical ) inference rules of @xmath7 , introduction and elimination ( inversion ) rules of inductive types ( definitions ) in place of the _ defr _ and _ defl _ rules of pids .",
    "both approaches introduce a minimal sequent calculus @xcite as a sl , and a prolog - like set of clauses for the ol .",
    "nevertheless , in a traditional inductive setting , this is not quite enough , as reasoning by inversion crucially depends on simplifying in the presence of constructors .",
    "when such constructors are non - inductive , which is typically the case with variable - binding operators , this presents a serious problem .",
    "the approach used in that work was axiomatic : encode the hoas signature with a set of constants and add a set of axioms stating the freeness and extensionality properties of the constants . with the critical use of those axioms , it was shown that it is possible to replicate , in the well - understood and interactive setting of coq , the style of proofs typical of @xmath7 .",
    "in particular , subject reduction for mini - ml is formalized in  @xcite following this style very closely ; this means that the theorem is proved immediately without any `` technical '' lemmas required by the choice of encoding technique or results that may be trivial but are intrinsically foreign to the mathematics of the problem .",
    "moreover , hoas proofs of subject reduction typically do not require weakening or substitutions lemmas , as they are implicit in the higher - order nature of the encoding .",
    "however , this approach did not offer any formal justification to the axiomatic approach and it is better seen as a proof - of - concept more than foundational work .",
    "the tool  @xcite was developed around the same time : it implements a higher - order meta - language within  @xcite that provides a form of hoas for the user to represent ols .",
    "the user level is separated from the infrastructure , in which hoas is implemented _ definitionally _ via a de bruijn style encoding .",
    "lemmas stating properties such as freeness and extensionality of constructors are _ proved _ and no additional axioms are required .",
    "( 4692,2010)(34,-1198 ) ( 1936,-556)(0,0)[lb ] ( 1601,-1006)(0,0)[lb ] ( 3376,504)(0,0)[lb ] ( 3376,279)(0,0)[lb ]    ( 3601,299)(0,0)[lb ]    ( 3626 , 10)(0,0)[lb ] ( 4051,-151)(0,0)[lb ] ( 4000,-421)(0,0)[lb ] ( 4000,-601)(0,0)[lb ] ( 4500,-871)(0,0)[lb ] ( 4500,-1071)(0,0)[lb ] ( 4500,-1271)(0,0)[lb ] ( 1800,344)(0,0)[lb ] ( 1800,-106)(0,0)[lb ]    it was therefore natural to combine the hoas meta - language provided by with miller & mcdowell s two - level approach , modified for inductive proof assistants .",
    "we implement this combined architecture in both and coq , but we speculate that the approach also works for other tactic - based inductive proof assistants , such as pvs  @xcite , lego  @xcite .",
    "we describe mainly the version here , though we compare it in some detail with the coq implementation .. ] a graphical depiction of the architecture is shown in figure  [ fig : arch ] .",
    "we often refer to the and levels together as the meta - logic . when we need to distinguish the level on its own , we call it the meta - meta - logic .",
    "when we say _ two - level _ reasoning , we are referring to the object and specification levels , to emphasize that there are two separate reasoning levels in addition to the meta - level .",
    "moreover , we suggest a further departure in design ( section  [ ssec : variation ] ) from the original two - level approach  @xcite : when possible , , when the structural properties of the meta - logic are coherent with the style of encoding of the ol , we may reserve for the specification level only those judgments that can not be adequately encoded inductively and leave the rest at the level . we claim that this framework with or without this variation has several advantages :    * the system is more trustworthy : freeness of constructors and , more importantly , extensionality properties at higher - order types are not assumed , but proved via the related properties of the infrastructure , as we show in section  [ using ] ( mc - theorem  [ thm : clash ] ) . *",
    "the mixing of meta - level and specification - level judgments makes proofs more easily mechanizable ; more generally , there is a fruitful interaction between ( co)-induction principles , meta - logic datatypes , classical reasoning , and hypothetical judgments , which lends itself to a good deal of automation .",
    "* we are not committed to a single monolithic sl , but we may adopt different ones ( linear , relevant , bunched , . ) according to the properties of the ol we are encoding .",
    "the only requirement is consistency , to be established with a formalized cut - elimination argument .",
    "we exemplify this methodology using non - commutative linear logic to reason about continuation machines ( section  [ sec : olli ] ) .    our architecture",
    "could also be seen as an approximation of _ twelf _",
    "@xcite , but it has a much lower mathematical overhead , simply consisting of a small set of theories ( modules ) on top of a proof assistant . in a sense , we could look at  as a way to `` represent '' twelf s meta - proofs in the well - understood setting of higher - order logic as implemented in ( or the calculus of ( co)inductive constructions as implemented in coq ) .",
    "note that by using a well - understood logic and system , and working in a purely definitional way , we avoid the need to justify _ consistency _ by syntactic or semantic means .",
    "for example , we do not need to show a cut - elimination theorem for a new logic as in  @xcite , nor prove results such as strong normalization of calculi of the @xmath11 family @xcite or about the correctness of the totality checker behind twelf  @xcite .",
    "hence our proofs are easier to trust , as far as one trusts isabelle / hol and coq .",
    "additionally , we can view our realization of the two - level approach as a way of `` fast prototyping '' hoas logical frameworks .",
    "we can quickly implement and experiment with a potentially interesting sl ; in particular we can do meta - reasoning in the style of tactical theorem proving in a way compatible with induction .",
    "for example , as we will see in section  [ sec : olli ] , when experimenting with a different logic , such as a sub - structural one , we do not need to develop all the building blocks of a usable new framework , such as unification algorithms , type inference or proof search , but we can rely on the ones provided by the proof assistant .",
    "the price to pay is , again , the additional layer where we explicitly reference provability , requiring a sort of meta - interpreter ( the sl logic ) to drive it .",
    "this indirectness can be alleviated , as we shall see , by defining appropriate tactics , but this is intrinsic to the design choice of relying on a general ambient logic ( here or coq , in  @xcite some variation of @xmath8 ) .",
    "this contrasts with the architecture proposed in  @xcite , where the meta - meta - logic is itself sub - structural ( linear in this case ) and , as such , explicitly tailored to the automation of a specific framework .",
    "we demonstrate the methodology by first formally verifying the subject reduction property for the standard simply - typed call - by - value @xmath0-calculus , enriched with a recursion operator .",
    "while this property ( and the calculus as well ) has been criticized as too trivial to be meaningful  @xcite  and , to a degree , we agree with that  we feel that the familiarity of the set - up will ease the understanding of the several layers of our architecture .",
    "secondly we tackle a more complex form of subject reduction , that of a continuation machine , whose operational semantics is encoded sub - structurally , namely in non - commutative linear logic .    [",
    "[ outline ] ] outline + + + + + + +    the paper is organized as follows : section  [ sec : introh ] recalls some basic notions of  and its implementation in and coq .",
    "section  [ using ] shows how it can be used as a logical framework . in section  [ sec:2lev ]",
    "we introduce a two - level architecture and present the first example sl and subject reduction proof , while section  [ sec : olli ] introduces a sub - structural sl and uses it for encoding continuation machines .",
    "we follow that up with an extensive review and comparison of related work in section  [ sec : rel ] , and conclude in section  [ sec : future ] .",
    "this paper is an archival documentation of 0.1 ( see section  [ ssec : h - v ] for the terminology ) , extending previous joint work with simon ambler and roy crole  @xcite , jeff polakow  @xcite and venanzio capretta  @xcite .",
    "we use a pretty - printed version of concrete syntax .",
    "a type declaration has the form .",
    "we stick to the usual logical symbols for connectives and quantifiers ( @xmath12 , @xmath13 , @xmath14 , @xmath15 , @xmath16 , @xmath17 ) .",
    "free variables ( upper - case ) are implicitly universally quantified ( from the outside ) as in logic programming . the sign @xmath18 ( isabelle meta - equality ) is used for _ equality by definition _ , and @xmath19 for isabelle universal meta - quantification .",
    "a rule ( a sequent ) of the schematic form : @xmath20 is represented as @xmath21 . a rule with discharged assumptions such as conjunction elimination is represented as @xmath22 . the keyword * mc - theorem ( lemma ) * denotes a machine - checked theorem ( lemma ) , while _ inductive _ introduces an inductive relation in , and _ datatype _ introduces a new datatype .",
    "we freely use infix notations , without explicit declarations .",
    "we have tried to use the same notation for mathematical and formalized judgments .",
    "the proof scripts underlying this paper are written in the so - called `` isabelle old style '' , , they are exclusively in the tactical - style , , sequences of commands .",
    "this was still fashionable and supported by 2005 , as opposed to the now required isar @xcite idioms of the new versions .",
    "however , in the interest of time , intellectual honesty ( and also consistency with coq ) , we have decided to base the paper on the original code of the project , which had as a fundamental goal the _ automation _ of two - level reasoning .",
    "naturally , some of the comments that we make about concrete features of the system , ( as well as interactions with it ) are by now relevant only to that version .",
    "when those happen to be obsolete , we will try to make this clear to the reader .",
    "we expect , however ( and indeed we already are in the process , see section  [ ssec : h - v ] ) to carry over this work to the current version of , possibly enhanced by the new features of the system .",
    "we keep coq s notation similar to s where possible .",
    "we use the same syntax for type declarations , though of course the allowable types are different in the two languages .",
    "we also use @xmath18 for equality by definition and @xmath23 for equality .",
    "there is no distinction between a functional type arrow and logical implication in coq , though we use both @xmath24 and @xmath25 depending on the context . in",
    ", there is a distinction between notation at the isabelle meta - level and the hol object - level , which we do not have in coq . whenever an formula has the form @xmath26 , and we say that the coq version is the same , we mean that the coq version has the form @xmath27 , or equivalently @xmath28 , where implication is right - associative as usual .",
    "source files for the and coq code can be found at hybrid.dsi.unimi.it/jar  @xcite .",
    "the description of the layer of our architecture is taken fairly directly from previous work , @xcite .",
    "central to our approach is the introduction of a binding operator that ( 1 ) allows a direct expression of @xmath0-abstraction , and ( 2 ) is _ defined _ in such a way that expanding its definition results in the conversion of a term to its de bruijn representation .",
    "the basic idea is inspired by the work of gordon  @xcite , and also appears in collaborative work with melham  @xcite .",
    "gordon introduces a @xmath0-calculus with constants where free and bound variables are named by _",
    "strings _ ; in particular , in a term of the form @xmath29 , @xmath30 is a string representing a variable bound in @xmath31 , and @xmath32 is a function of two arguments , which when applied , converts free occurrences of @xmath30 in @xmath31 to the appropriate de bruijn indices and includes an outer de bruijn abstraction operator .",
    "not only does this approach provide a good mechanism through which one may work with _ named _ bound variables under @xmath5-renaming , but it can be used as a meta - logic by building it into an type , say of _ proper terms _ , from which other binding signatures can be defined , as exemplified by gillard s encoding of the object calculus  @xcite . as in the logical framework tradition , every ol binding operator is reduced to the @xmath0-abstraction provided by the type of proper terms .",
    "our approach takes this a step further and exploits the built in  which is available in systems such as and coq .",
    "@xmath33 constructor is similar to gordon s @xmath32 except that @xmath33 is a _ binding _ operator .",
    "the syntax @xmath34 is actually notation for @xmath35 , which makes explicit the use of bound variables in the meta - language to represent bound variables in the ol .",
    "thus the @xmath36 in @xmath34 is a meta - variable ( and not a string as in gordon s approach ) .    at the base level , we start with an inductive definition of de bruijn expressions , as gordon does .",
    "@xmath37 in our setting , @xmath38 and @xmath39 are defined to be the natural numbers , and @xmath40 provides names for constants .",
    "the latter type is used to represent the constants of an ol , as each ol introduces its own set of constants .    to illustrate the central ideas , we start with the @xmath0-calculus as an ol . to avoid confusion with the meta - language ( , @xmath0-abstraction at the level of or coq )",
    ", we use upper case letters for variables and a capital @xmath41 for abstraction .",
    "for example , consider the object - level term @xmath42 .",
    "the terms @xmath43 and @xmath44 below illustrate how this term is represented using gordon s approach and , respectively .",
    "@xmath45 in we also choose to denote object - level free variables by terms of the form @xmath46 , though this is not essential . in either case",
    ", the abstraction operator ( @xmath32 or @xmath33 ) is defined , and expanding definitions in both @xmath47 and @xmath48 results in the same term , shown below using our de bruijn notation .",
    "@xmath49 in the above term all the variable occurrences bound by the first @xmath50 , which corresponds to the bound variable @xmath51 in the object - level term , are underlined .",
    "the @xmath52 operator is central to this approach and its definition includes determining correct indices .",
    "we return to its definition in section  [ defh ] .    in summary , provides a form of hoas where object - level :    * free variables correspond to expressions of the form @xmath46 ; * bound variables correspond to ( bound ) meta - variables ; * abstractions @xmath53 correspond to expressions @xmath54 , defined as @xmath55 ; * applications @xmath56 correspond to expressions @xmath57 .",
    "consists of a small number of theories ( actually two , for a total of about 130 lines of definitions and 80 lemmas and theorems ) , which introduce the basic definition for de bruijn expressions ( @xmath58 ) given above and provide operations and lemmas on them , building up to those that hide the details of de bruijn syntax and permit reasoning on hoas representations of ols . in this section",
    "we outline the remaining definitions , and give some examples .",
    "note that our theories do not contain any axioms which require external justification , as in some other approaches such as the theory of contexts  @xcite .",
    "as mentioned , the operator @xmath59 is central to our approach , and we begin by considering what is required to fill in its definition",
    ". clearly @xmath60 must expand to a term with at the head .",
    "furthermore , we must define a function @xmath61 such that @xmath60 is @xmath62 where @xmath61 replaces occurrences of the bound variable in @xmath63 with de bruijn index @xmath64 , taking care to increment the index as it descends through inner abstractions .",
    "in particular , we will define a function of two arguments such that formally : @xmath65 and @xmath66 replaces occurrences of the bound variable in @xmath63 with de bruijn index @xmath67 , where recursive calls on inner abstractions will increase the index . as an example , consider the function @xmath68 . in this case ,",
    "application of with argument index @xmath64 should result in a level 1 expression : @xmath69 and thus : @xmath70    we define as a total function operating on all functions of type @xmath71 , even _ exotic _",
    "ones that do not encode @xmath0-terms .",
    "for example , we could have @xmath72 where @xmath73 counts the total number of variables and constants occurring in @xmath74 .",
    "only functions that behave _ uniformly _ or _ parametrically _ on their arguments represent @xmath0-terms .",
    "we refer the reader to the careful analysis of this phenomenon ( in the context of coq ) given in  @xcite and to section  [ sec : rel ] for more background .",
    "we will return to this idea shortly and discuss how to rule out non - uniform functions in our setting .",
    "for now , we define so that it maps non - uniform subterms to a default value .",
    "the subterms we aim to rule out are those that do not satisfy the predicate @xmath75 , defined as follows : . ]",
    "@xmath76    we do not define directly , but instead define a relation and prove that this relation defines a function mapping the first two arguments to the third .",
    "@xmath77 in showing that this relation is a function , uniqueness is an easy structural induction .",
    "existence is proved using the following abstraction induction principle .",
    "@xmath78 [ thm : abstractioninduct ]    we now define @xmath79 as follows , thus completing the definition of : @xmath80 where @xmath81 is isabelle s notation for the definite description operator @xmath82 . from these definitions , it is easy to prove a `` rewrite rule '' for every de bruijn constructor .",
    "for example , the rule for is :    @xmath83    these rules are collected under the name , and thus can be used directly in simplification .    ruling out non - uniform functions , which was mentioned before , will turn out to be important for a variety of reasons . for example",
    ", it is necessary for proving that our encoding adequately represents the @xmath0-calculus . to prove adequacy , we identify a subset of the terms of type @xmath58 such that there is a bijection between this subset and the @xmath0-terms",
    "that we are encoding .",
    "there are two aspects we must consider in defining a predicate to identify this subset .",
    "first , recall that @xmath84 corresponds to a bound variable in the , and @xmath46 to a free variable ; we refer to _ bound _ and _ free _ _ indices _ respectively .",
    "we call a bound index @xmath67 _ dangling _ if @xmath67 or less @xmath85 labels occur between the index @xmath67 and the root of the expression tree",
    ". we must rule out terms with dangling indices .",
    "second , in the presence of the constructor , we may have functions of type @xmath86 that do not behave uniformly on their arguments .",
    "we must rule out such functions .",
    "we define a predicate , which rules out dangling indices from terms of type @xmath58 , and a predicate , which rules out dangling indices and exotic terms in functions of type @xmath86 .",
    "to define we first define .",
    "expression @xmath87 is said to be at _ level _ @xmath88 , if enclosing @xmath87 inside @xmath89 @xmath85 nodes ensures that the resulting expression has no dangling indices .",
    "@xmath90 then , @xmath91 is defined simply as : @xmath92    to define , we first define @xmath93 as follows : @xmath94 given @xmath95 , we set : @xmath96 when an expression @xmath87 of type @xmath97 satisfies this predicate , we say it is an _",
    "abstraction_. ) , although this formalization has , in our notation , the `` weaker '' type @xmath98 . ]",
    "in addition to being important for adequacy , the notion of an abstraction is central to the formulation of induction principles at the meta - level .    it s easy to prove the analogue of @xmath99 introduction rules in terms of @xmath100 , for example : @xmath101 a simple , yet important",
    "lemma is :    @xmath102    [ mclem : proper_abst ]    so any function is a legal abstraction if its body is a proper expression .",
    "this strongly suggests that were we to turn the predicate @xmath103 into a _",
    "@xmath104 , then any function with source type @xmath105 would be de facto a legal abstraction . ] .",
    "it follows directly from the inductive definition of de bruijn expressions that the functions @xmath106 , @xmath107 , @xmath108 , and @xmath109 are injective , with disjoint images . with the introduction of",
    ", we can now also prove the following fundamental theorem :    @xmath110 [ thm : inj ]    which says that @xmath111 is injective on the set of abstractions .",
    "this follows directly from an analogous property of @xmath112 :    @xmath113    this is proved by structural induction on the @xmath114 predicate using simplification with .    finally , it is possible to perform induction over the quasi - datatype of proper terms .",
    "[ thm : proper - induct ] @xmath115    the proof is by induction on the size of @xmath63 , and follows from the following two lemmas .",
    "@xmath116    @xmath117    note that mc - theorem  [ thm : proper - induct ] does not play any active role in the two - level architecture , as induction will be performed on the derivability of judgments .      in this section",
    "we comment briefly on the differences between the and coq implementations of , which arise mainly from the differences in the meta - languages .",
    "implements a polymorphic version of church s higher - order ( classical ) logic plus facilities for axiomatic classes and local reasoning in the form of _ locales _ @xcite .",
    "coq implements a constructive higher - order type theory , but includes libraries for reasoning classically , which we used in order to keep the implementations as similar as possible .",
    "note that the definition of @xmath112 uses s definite description operator , which is not available in coq .",
    "the use of this operator is the main reason for the differences in the two libraries . in coq",
    ", we instead use the description axiom available in coq s classical libraries : @xmath118 with @xmath119 as relation @xmath120 . the coq version of is larger than the version , mainly due to showing uniqueness for the @xmath121 relation .",
    "we then eliminate the existential quantifier in the description theorem to get a function that serves as the coq version of @xmath122 . to be a coq @xmath123 .",
    "]    in more detail , if we consider the theory just described , the operations and predicates @xmath124 , @xmath119 , @xmath125 , @xmath126 , @xmath127 , and @xmath128 are defined nearly the same as in the version . for predicates such as @xmath125",
    ", we have a choice that we did not have in .",
    "in coq , _ prop_is the type of logical propositions , whereas _ set_is the type of datatypes . _ prop_and _ set_allow us to distinguish _ logical _ aspects from _ computational _ ones our libraries . the datatype @xmath129 for example , distinct from _ prop _ ,",
    "is defined inductively in the coq standard library as a member of _",
    "one option in defining @xmath125 is to define it as a function with target type @xmath130 , which evaluates via conversion to @xmath131 or @xmath132 .",
    "the other is to define it as an inductive predicate ( in _ prop _ ) , and then we will need to provide proofs of @xmath125 subgoals instead of reducing them to @xmath131 .",
    "we chose the latter option , using _",
    "prop_in the definition of @xmath125 and all other predicates .",
    "this allowed us to define inductive predicates in coq that have the same structure as the definitions , keeping the two versions as close as possible . for our purposes , however , the other option should have worked equally well .    for predicates @xmath124 , @xmath119 , @xmath127 , and @xmath128 , which each have an argument of functional type",
    ", there is one further difference in the coq definitions .",
    "equality in is extensional , while in coq , it is not .",
    "thus , it was necessary to define extensional equality on type @xmath71 _ explicitly _ and use that equality whenever it is expressed on this type , @xmath133 formally , @xmath134 .",
    "for example , this new equality appears in the definition of @xmath127 . in the coq version ,",
    "we first define an auxiliary predicate @xmath135 defined exactly as @xmath127 in , and then define @xmath127 as : @xmath136 the predicate @xmath128 has the same definition as in , via this new version of @xmath137 .",
    "the definition of @xmath119 parallels the one for @xmath127 , in this case using @xmath138 . for the @xmath124 predicate",
    ", we obtain the coq version from the definition simply by replacing @xmath23 with @xmath139 .    the proof that @xmath119 is a total relation is by induction on @xmath140 and the induction case uses a proof by cases on whether or not a term of type @xmath71 is ordinary .",
    "note that the @xmath124 property is not decidable , and thus this proof requires classical reasoning , which is a second reason for using coq s classical libraries .",
    "coq provides a module which helps to automate proofs using user - defined equalities that are declared as _",
    "setoids_. a setoid is a pair consisting of a type and an equivalence relation on that type . to use this module ,",
    "we first show that @xmath139 is reflexive , symmetric , and transitive .",
    "we then declare certain predicates as morphisms .",
    "a morphism is a predicate in which it is allowable to replace an argument by one that is equivalent according to the user - defined equality .",
    "such replacement is possible as long as the corresponding compatibility lemma is proved .",
    "for example , we declare @xmath124 , @xmath119 , @xmath127 , and @xmath128 as morphisms .",
    "in particular , the lemma for @xmath119 proves that if @xmath141 , then for all terms @xmath142 that are extensionally equal to @xmath63 , we also have @xmath143 .",
    "setoid rewriting then allows us to replace the second argument of @xmath119 by extensionally equal terms , and is especially useful in the proof that every @xmath63 is related to a unique @xmath31 by @xmath119 .",
    "as stated above , we obtain @xmath112 by eliminating the existential quantifier in the description theorem .",
    "once we have this function , we can define @xmath111 as in and prove the coq version of the _ abstr_lam_simp _ theorem : @xmath144\\ ] ] note the use of logical equivalence ( @xmath145 ) between elements of _ prop_. extensional equality is used between elements of type @xmath71 and coq equality is used between other terms whose types are in _",
    "set_. similarly ,",
    "extensional equality replaces equality in other theorems involving expressions of type @xmath146 .",
    "for example _ abstraction_induct _ ( mc - theorem  [ thm : abstractioninduct ] ) is stated as follows : @xmath147",
    "in this section we show how to use as a logical framework , first by introducing our first ol ( section  [ ssec : coding ] ) and discussing the adequacy of the encoding of its syntax ( section  [ ssec : adeq ] ) . representation and adequacy of syntax are aspects of encoding ols that are independent of the two - level architecture .",
    "we then show that some object - level judgments can be represented directly as inductive definitions ( section  [ ssec : oljudg ] ) .",
    "we also discuss the limitations of encoding ol judgments in this way , motivating the need for the two - level architecture of section  [ sec:2lev ] .",
    "the system at this level provides :    * a suite of theorems : roughly three or four dozens propositions , most of which are only intermediate lemmas leading to the few that are relevant to our present purpose : namely , injectivity and distinctness properties of constants . * definitions and , which are important for s adequate representation of ols . * a very small number of automatic tactics : for example ( resp .  )",
    "automatically recognizes whether a given term is indeed proper ( resp .",
    "an abstraction ) .",
    "we report here the ( slightly simplified ) code for , to give an idea of how lightweight such tactics are :    .... fun abstr_tac defs =         simp_tac ( simpset ( )                   addsimps defs @ [ abstr_def , lambda_def ] @ lbind_simps )          then '          fast_tac(claset ( )                  addds [ abst_level_lbind ]                  addis abstset.intrs                  addes [ abstr_abst , proper_abst ] ) ; ....    first the goal is simplified ( ` simp_tac ` ) using the definition of , , other user - provided lemmas ( ` defs ` ) , and more importantly the `` rewrite rules '' ( ) . at this point , it is merely a question of resolution with the introduction rules for ( ` abstset.intrs ` ) and a few key lemmas , such as mc - lemma  [ mclem : proper_abst ] , possibly as elimination rules . in 2005 , a tactic , even a user defined one , could also be `` packaged '' into a _",
    "solver_. in this way , it can be combined with the other automatic tools , such as the simplifier or user defined tactics , .",
    "( see section  [ ssec : tac ] . )",
    "the ol we consider here is a fragment of a pure functional language known as mini - ml .",
    "as mentioned , we concentrate on a @xmath0-calculus augmented with a fixed point operator , although this ol could be easily generalized as in  @xcite .",
    "this fragment is sufficient to illustrate the main ideas without cluttering the presentation with too many details .",
    "the types and terms of the source language are given respectively by : @xmath148 we begin by showing how to represent the syntax in hoas format using . since types for this language have no bindings , they are represented with a standard datatype , named _",
    "tp _ and defined in the obvious way ; more interestingly , as far as terms are concerned , we need constants for abstraction , application and fixed point , say @xmath149 , @xmath150 , and @xmath151 .",
    "recall that in the meta - language , application is denoted by infix @xmath152 , and abstraction by @xmath153 .",
    "the above grammar is coded in verbatim , provided that we declare these constants to belong to the enumerated datatype @xmath40 @xmath154 add the type abbreviation @xmath155 and the following _ definitions _ : @xmath156 \\fs   \\uexp   \\\\",
    "\\ikw{fix } & \\oftype &   [ \\uexp \\fs   \\uexp ] \\fs   \\uexp   \\\\    \\llapp{e_1}{e_2 } & \\idef &   \\con{capp } \\app e_1 \\app e_2\\\\    \\llfun{x}{e\\ x } & \\idef &   \\con{cabs } \\app \\lam{x}{e\\ x}\\\\    \\llrec{e\\ x } & \\idef &   \\con{cfix } \\app \\lam{x}{e\\ x } \\end{array}\\ ] ] where @xmath3 ( resp .",
    "@xmath157 ) is indeed an binder , , @xmath158 is a syntax translation for @xmath159 . for example",
    ", @xmath160 abbreviates : @xmath161    note again that the above are only _ definitions _ and by themselves would not inherit any of the properties of the constructors of a datatype .",
    "however , thanks to the thin infra - structural layer that we have interposed between the @xmath0-calculus natively offered by isabelle and the rich logical structure provided by the axioms of , it is now possible to _ prove _ the freeness properties of those definitions as if they were the constructors of what would ordinarily consider an `` impossible '' datatype as discussed earlier .",
    "more formally :    consider the constructors :    * the constructors have distinct images .",
    "for example : @xmath162 * every non binding constructor is _",
    "injective_. * every _ binding _ constructor is _ injective _ on _",
    "abstractions_. for example : @xmath163    [ thm : clash ]    by a call to s standard simplification , augmented with the left - to - right direction of the crucial property",
    "_ abstr_lam_simp _",
    "( mc - theorem  [ thm : inj ] ) .",
    "this result will hold for any signature containing at most second - order constructors , provided they are encoded as we have exhibited .",
    "these `` quasi - freeness '' properties  meaning freeness conditionally on whether the function in a binding construct is indeed an abstraction  are added to s standard simplifier , so that they will be automatically applied in all reasoning contexts that concern the constructors . in particular ,",
    "clash theorems are best encoded in the guise of _ elimination _ rules , already incorporating the `` ex falso quodlibet '' theorem .",
    "for example , _",
    "fa_clash _ of mc - theorem  [ thm : clash ] is equivalent to : @xmath164      it is a customary proof obligation ( at least ) higher - order encoding to show that the syntax ( and later the judgments ) of an ol such as mini - ml are _ adequately _ represented in the framework .",
    "while this is quite well - understood in a framework such as lf , the `` atypical '' nature of requires a discussion and some additional work .",
    "we take for granted ( as suggested in @xcite , then painstakingly detailed in @xcite ) that provides an adequate representation of the @xmath0-calculus .",
    "yet , it would not be possible to provide a `` complete '' proof of the adequacy of as a theory running on a complex tool such as . here",
    "we take a more narrow approach , by working with a convenient fiction , , a _ model _ of as a simply - typed @xmath0-calculus presented as a logical framework .",
    "this includes :    * a `` first - order '' @xmath0-calculus ( , where _ bool _ can only occur as the target of a legal arrow type ) as our term language ; * introduction and elimination rules for atoms generated by their inductive definition ; * simplification on the level and modulo other decidable theories such as linear arithmetic .",
    "we can use this as our framework to represent ols ; further this model is what we consider when we state meta - theoretical properties of ol encodings and prove them adequate .",
    "we follow quite closely pfenning s account in the _ handbook of automated reasoning _  @xcite . by adequacy of a language representation",
    "we mean that there is an _ encoding _ function @xmath165 from ol terms with free variables in @xmath166 to the canonical forms of the framework in an appropriate signature , as well as its inverse @xmath167 such that :    1 .",
    "validity : for every mathematical object @xmath31 with free variables in @xmath166 , @xmath168 is a canonical ( and thus unique , modulo @xmath5-conversion ) representation in the framework . note that we use @xmath166 both for the and the ol s variables context ; 2 .",
    "completeness : for every canonical term @xmath169 over @xmath166 , @xmath170 , results in a unique ol term @xmath31 ; furthermore @xmath171 and @xmath172 .",
    "compositionality : the bijection induced by @xmath173 and @xmath174 commutes with substitution ; formally @xmath175 { t_2 } } = { [ \\encode      \\gamma { t_1}/x ] } \\ ; \\encode \\gamma { t_2}$ ] and @xmath176 { e_2 } } = { [ \\decode \\gamma { e_1}/x ] } \\ ; \\decode \\gamma    { e_2}$ ]",
    ".    clearly the first requirement seems easier to satisfy , while the second one tends to be more problematic . in general",
    ", there could be two main obstacles when representing an ol s signature with some form of hoas in a logical framework , both related to the existence of `` undesirable '' canonical terms in the framework , , honest - to - goodness terms that are _ not _ in the image of the desired encoding :    1 .   if the framework is _ uni - typed _",
    ", we need predicates to express the well - formedness of the encoding of expressions of the ol . such well - formedness properties must now be _ proved _ , differently from settings such as lf , where such properties are handled by type - checking .",
    "in particular , constants are not part of a datatype , so they do not enjoy the usual closure condition .",
    "moreover there are proper terms such as @xmath177 that are not in the image of the encoding , but are still canonical forms of type @xmath58 .",
    "2 .   if the framework is strong enough , in particular if its type system supports at least a primitive recursive function space , _ exotic _ terms do arise , as discussed earlier , , terms containing irreducible functions that are not parametric on their arguments , , @xmath178 .",
    "as far as the second issue is concerned , we use annotations to get rid of such `` non - parametric '' functions . as mentioned by @xcite and",
    "is standard practice in concrete approaches ( , the ` vclosed ` and ` term ` predicate in the `` locally named / nameless '' representation of @xcite ) , we introduce well - formedness predicates ( as inductive definitions in ) to represent ol types .    to make clear the correspondence between the ol and its encoding , we re - formulate the bnf grammar for mini - ml terms as a well - formedness judgment : @xmath179 based on this formulation , the definition of encoding of a mini - ml term into and its decoding is unsurprising @xcite .",
    "notation - wise , we overload the comma so that @xmath180 means @xmath181 ; we also use @xmath166 for both the context of ol variables and of variables of type @xmath182 : @xmath183 @xmath184    we then introduce an inductive predicate @xmath185 of type @xmath186 , which addresses at the same time the two aforementioned issues .",
    "it identifies the subset of @xmath182 that corresponds to the open terms of mini - ml over a set of ( free ) variables .",
    "@xmath187 \\prems{x\\in\\gamma }    & \\implies & \\isterm{\\gamma}{({x } ) } \\\\     \\prems{\\isterm{\\gamma}{e_1 } ; \\ ; \\isterm{\\gamma}{e_2 } } & \\implies &       \\isterm{\\gamma } { ( \\llapp{e_1}{e_2})}\\\\       \\prems{\\forall x.\\ \\proper x \\limp\\isterm{\\gamma , x}{(e~x ) } ;        \\ ; \\ikw{abstr\\ e } } & \\implies &       \\isterm{\\gamma}{(\\llfun{x}{e\\ x } ) } \\\\      \\prems{\\forall x.\\ \\proper x \\limp\\isterm{\\gamma , x}{(e~x ) } ;        \\ ; \\ikw{abstr\\",
    "e } } & \\implies &       \\isterm{\\gamma}{(\\llrec{e\\ x } ) }    \\end{array}\\ ] ]    we can now proceed to show the validity of the encoding in the sense that @xmath188 entails that @xmath189 is provable in . however , there is an additional issue : the obvious inductive proof requires , in the binding case , the derivability of the following fact : @xmath190 a proof by induction on the structure of @xmath31 relies on @xmath191 this holds once @xmath192 is a _ biabstraction _ , namely : @xmath193 biabstractions are the generalization of abstractions to functions of type @xmath194 .",
    "the inductive definition of this notion simply replays that of and we skip it for the sake of space .",
    "we note however that the above theorem follows by structural induction using only introduction and elimination rules for @xmath195 .",
    "we therefore consider proven the above fact ( [ le : abstr - adeq ] ) .",
    "if @xmath196 , we write @xmath197 ) to denote the context @xmath198 .",
    "[ le : exp - sound ] if @xmath188 , then @xmath199 is provable in .",
    "[ lem : valid ]    by the standard induction on the derivation of @xmath188 , using fact ( [ le : abstr - adeq ] ) in the binding cases .    as far as the converse of lemma  [ lem : valid ] goes , we need an additional consideration .",
    "as opposed to intentionally weak frameworks @xcite , has considerable expressive power ; various features of the underlying logic , such as classical reasoning and the axiom of choice , can be used to construct proofs about an ol that do not correspond to the informal constructive proofs we aim to formalize .",
    "we therefore need to restrict ourselves to a second - order intuitionistic logic .",
    "the issue here is guaranteeing that _ inverting _ on hypothetical judgments respects the operational interpretation of the latter , , the deduction theorem , rather than viewing them as classical tautologies .",
    "we call such a derivation _ minimal_. since does have proof terms @xcite , this notion is in principle checkable .    [",
    "le : complete ] let @xmath166 be the set @xmath200 ; if @xmath201 has a _ minimal _ derivation in , then @xmath202 is defined and yields a mini - ml expression @xmath31 such that @xmath188 and @xmath203 .",
    "furthermore , @xmath172 .",
    "the main statement goes by induction on the minimal derivation of @xmath204 ; we sketch one case : assume @xmath205 ; by inversion , @xmath206 holds for a parameter @xmath74 under the assumption @xmath207 . by definition @xmath208 . by the i.h .",
    "the term @xmath209 is defined and there is a @xmath31 s.t .",
    "@xmath210 and @xmath211 . by the bnf rule for @xmath212 , @xmath213 and",
    "again by the i.h .  and definition , @xmath214 .",
    "finally , @xmath172 follows by a straightforward induction on @xmath31 .",
    "[ le : comp ]    1 .",
    "@xmath175 { t_2 } } = { [ \\encode \\gamma { t_1}/x ] } \\    \\encode \\gamma { t_2}$ ] , where @xmath74 may occur in @xmath166 .",
    "if @xmath215 and @xmath216 are defined , then @xmath217 { e_2 } } = { [ \\decode \\gamma { e_1}/x ] } \\    \\decode \\gamma { e_2}$ ] .",
    "the first result may be proved by induction on @xmath218 as in lemma 3.5 of @xcite , since the encoding function is the same , or we can appeal to the compositionality property of , proved as theorem 4.3 of @xcite , by unfolding the definition of the constructors .",
    "the proof of the second part is a similar induction on @xmath219 .",
    "note that completeness and compositionality do not depend on fact ( [ le : abstr - adeq ] ) .",
    "@xmath220e_1 ' } { v}}{\\eval{e_1\\ \\at \\       e_2}{v}}{\\mathbf{ev\\_app}}\\vsk     \\ianc { } { \\eval{{\\mathbf{fun\\ x.\\ } } e}{{\\mathbf{fun\\ x.\\ } } e } } { \\mathbf{ev\\_fun } } \\qquad \\ianc{\\eval{[\\rec{e}/x]e}{v}}{\\eval{\\rec{e}}{v}}{\\mathbf{ev\\_fix}}\\vsk \\dotfill\\vsk \\ianc{\\gamma , x\\oftp \\tau \\vd e \\hastype \\tau'}{\\gvd { \\mathbf{fun\\ x.\\ } } e \\hastype \\tau \\fsp \\tau'}{\\mathbf{tp\\_fun } } \\qquad   \\ianc{\\gamma , x\\oftp \\tau \\vd e",
    "\\hastype \\tau}{\\gvd \\rec{e } \\hastype     \\tau } { \\mathbf{tp\\_fix}}\\vsk    \\ianc{\\gamma(x ) = \\tau}{\\gvd x \\hastype \\tau}{\\mathbf{tp\\_var } }   \\qquad   \\ibnc{\\gvd e_1 \\hastype \\tau ' \\arrow \\tau}{\\gvd e_2 \\hastype     \\tau'}{\\gvd e_1\\ \\at \\   e_2 \\hastype \\tau }   { \\mathbf{tp\\_app } } \\end{array}$}\\ ] ]      we now turn to the encoding of object - level _ judgments_. in this and the next section , we will consider the standard judgments for big - step call - by - value operational semantics ( @xmath221 ) and type inference  ( @xmath222 ) , depicted in figure  [ fig : dyn - st ] .",
    "evaluation can be directly expressed as an _ inductive _ relation ( figure  [ fig : hoas - eval1 ] ) in full hoas style .",
    "note that substitution is encoded via meta - level @xmath6-conversion in clauses for * ev_app * and * ev_fix*.    @xmath223\\hline \\end{array}\\ ] ]    this definition is an honest to goodness inductive relation that can be used as any other one in an hol - like setting : for example , queried in the style of prolog , as in @xmath224 , by using only its introduction rules and abstraction solving .",
    "further this kind of relations can be reasoned about using standard induction and case analysis .",
    "in fact , the very fact that evaluation is recognized by as inductive yields _ inversion principles _ in the form of elimination rules .",
    "this would correspond , in meta - logics such as @xmath8 , to applications of _ definitional reflection_. in ( as well as in coq ) case analysis is particularly well - supported as part of the datatype / inductive package .",
    "each predicate ` p ` has a general inversion principle ` p.elim ` , which can be specialized to a given instance @xmath225 by an ml built - in function ` p.mk\\_cases ` that operates on the current simplification set ; specific to our architecture , note again the _ abstraction _ annotations as meta - logical premises in rules mentioning binding constructs . to take this into account",
    ", we call this ml function modulo the quasi - freeness properties of constructors so that it makes the appropriate discrimination . for example",
    "the value of ` meval\\_mk\\_cases ` ( @xmath226 ) is : @xmath227 note also that the inversion principle has an explicit equation @xmath228 ( whereas definitional reflection employs full higher - order unification ) and such equations are solvable only under the assumption that the body of a @xmath0-term is well - behaved ( , is an abstraction ) .    finally , using such elimination rules , and more importantly the structural induction principle provided by s inductive package",
    ", we can prove standard meta - theorems , for instance uniqueness of evaluation .",
    "@xmath229 .    by induction on the structure of the derivation of @xmath230 and",
    "inversion on @xmath231 .",
    "the mechanized proof does not appeal , as expected , to the functionality of substitution , as the latter is inherited by the meta - logic , contrary to first - order and `` weak '' hoas encodings ( see section  [ ssec : oth ] ) .",
    "compare this also with the standard paper and pencil proof , which usually ignores this property .",
    "we can also prove some `` hygiene '' results , showing that the encoding of evaluation preserves properness and well - formedness of terms :    @xmath232 [ mclem : evalproper ]    note the absence in figure  [ fig : hoas - eval1 ] of any assumptions at all : only the assumptions in the application and fixed point cases are needed .",
    "we have included just enough assumptions to prove the above results . in general , this kind of result must be proven for each new ol , but the proofs are simple and the reasoning steps follow a similar pattern for all such proofs .    with respect to the adequacy of object - level judgments , we can establish first the usual statements , for example soundness and completeness of the representation ; for the sake of clarity as well as brevity in the statement and proof of the lemma we drop the infix syntax in the definition of evaluation , and omit the obvious definition of the encoding of said judgment :    [ le : adeq - eval ] let @xmath63 and @xmath233 be _ closed _ mini - ml expressions such that @xmath234 ; then we can prove in @xmath235 .    by induction on the derivation of @xmath234 .",
    "consider the * ev_fun * case : by definition of the encoding on expressions and its soundness ( lemma  [ le : exp - sound ] ) we have that @xmath236 is provable in ; by definition and inversion @xmath237 and @xmath238 holds , hence by the introduction rules of the inductive definition of evaluation @xmath239 is provable , that is , by definition , @xmath240 .",
    "the other two cases also use compositionality ( lemma  [ le : comp ] ) and the induction hypothesis .",
    "[ le : complete - eval ] if @xmath241 has a minimal derivation in , then @xmath242 and @xmath243 are defined and yield mini - ml expressions @xmath63 and @xmath233 such that @xmath221 .",
    "it follows from mc - lemma  [ mclem : evalproper ] that @xmath244 and @xmath245 , and thus from lemma  [ le : complete ] that @xmath242 and @xmath243 are defined .",
    "the proof of @xmath221 follows directly by induction on the minimal derivation of @xmath241 , using compositionality ( lemma  [ le : comp ] ) .",
    "now that we have achieved this , does that mean that all the advantages of hoas are now available in a well - understood system such as ?",
    "the answer is , unfortunately , a qualified `` no '' . recall the three `` tenets '' of hoas :    1 .   @xmath5-renaming for free , inherited from the ambient @xmath0-calculus identifying meta - level and object - level bound variables ; 2 .",
    "object - level substitution as meta - level @xmath6-reduction ; 3 .",
    "object - level contexts as meta - level assumptions .    as of now",
    ", we have achieved only the first two . however , while accomplishing in a consistent and relatively painless way the first two points above is no little feat ,- conversion by constructing equivalence classes  @xcite in a proof assistant . ] the second one , in particular , being in every sense novel , no hoas system can really be worth its name without an accounting and exploiting of reasoning in the presence of _ hypothetical and parametric judgments_. we consider the standard example of encoding type inference ( figure  [ fig : dyn - st ] ) in a language such as twelf .",
    "using -like syntax ( where we use @xmath129 for twelf s @xmath246 , the @xmath247 , @xmath248 , and @xmath249 rules would be represented as follows : @xmath250 each typing judgment @xmath251 in an object - level context ( @xmath166 in figure  [ fig : dyn - st ] ) is represented as a logical assumption of the form @xmath252 . in the spirit of higher - order encoding , there is no explicit representation of contexts and no need to encode the @xmath253 rule .",
    "however , because of the underlined negative recursive occurrences in the above formulas , there is simply no way to encode this directly in an inductive setting , short of betraying its higher - order nature by introducing ad - hoc datatypes ( in this case lists for environments ) and , what s worse , all the theory they require . the latter may be trivial on paper , but it is time - consuming and has little to do with the mathematics of the problem .. ]    moreover , at the level of the meta - theory , it is only the coupling of items 2 and 3 above that makes hoas encodings  and thus proofs  so elegant and concise ; while it is nice not to have to encode substitution for every new signature , it is certainly much nicer not to have to _ prove _ the related substitution lemmas .",
    "this is precisely what the pervasive use of hypothetical and parametric judgments makes possible  one of the many lessons by martin - lf .    even when hypothetical judgments are stratified and therefore inductive , using directly within ( , at a single level as will become clear shortly ) has been only successful in dealing with predicates over _ closed _ terms ( such as simulation )",
    "however , it is necessary to resort to a more traditional encoding , , via explicit environments , when dealing with judgments involving _ open _ objects .",
    "these issues became particularly clear in the case - study reported in  @xcite , where the syntax allowed the following elegant encoding of _ closed _ applicative ( bi)simulation  @xcite : @xmath254 together with easy proofs of its basic properties ( for example , being a pre - order ) . yet , dealing with _",
    "( bi)simulation required the duplication of analogous work in a much less elegant way .",
    "this does not mean that results of some interest can not be proved working at one level .",
    "for example , the aforementioned paper ( painfully ) succeeded in checking non - trivial results such as a howe - style proof of congruence of applicative ( bi)simulation  @xcite .- calculus to more interesting calculi such as  @xcite . ]",
    "another example  @xcite is the quite intricate verification of subject reduction of mil - lite @xcite , the intermediate language of the mlj compiler @xcite .",
    "in those experiments , hoas in seemed only a nice interlude , soon to be overwhelmed by tedious and non - trivial ( at least mechanically ) proofs of list - based properties of open judgments and by a number of substitutions lemmas that we had hoped to have eliminated for good .",
    "these are the kinds of issues we address with the two - level architecture , discussed next .",
    "the _ specification _ level mentioned earlier ( see figure  [ fig : arch ] ) is introduced to solve the problems discussed in the previous section of reasoning in the presence of negative occurrences of ol judgments and reasoning about open terms .",
    "a _ specification logic _ ( sl ) is defined inductively , and used to encode ol judgments . since",
    "hypothetical judgments are encapsulated within the sl , they are not required to be inductive themselves .",
    "in addition , sl contexts can encode assumptions about ol variables , which allows reasoning about open terms of the ol .",
    "we introduce our first example sl in section  [ ssec : nseq ] .",
    "then , in section  [ ssec : prog ] , we continue the discussion of the sample ol introduced in section  [ using ] , this time illustrating the encoding of judgments at the sl level . in section  [ ssec : tac ]",
    ", we discuss proof automation and in section  [ ssec : variation ] we present a variant of the proof in section  [ ssec : prog ] that illustrates the flexibility of the system .",
    "we introduce our first sl , namely a fragment of second - order hereditary harrop formulas  @xcite .",
    "this is sufficient for the encoding of our first case - study : subject reduction for the sub - language of mini - ml that we have introduced before ( figure  [ fig : dyn - st ] ) .",
    "the sl language is defined as follows , where @xmath255 is a ground type and @xmath256 is an atomic formula . @xmath257",
    "the @xmath255 in the grammar for goals is instantiated with @xmath58 in this case .",
    "thus , quantification is over a ground type whose exact elements depend on the instantiation of @xmath40 , which , as discussed in section  [ ssec : prog ] , is defined at the ol level .",
    "quantification in clauses includes second - order variables .",
    "we will use it , for instance , to encode variables @xmath169 of type @xmath97 that appear in terms such as @xmath258 .",
    "quantification in clauses may also be over first - order variables of type @xmath58 , as well as over variables of other ground types such as _ tp_. in this logic , we view contexts as _ sets _ , where we overload the comma to denote adjoining an element to a set .",
    "not only does this representation make mechanical proofs of the standard proof - theoretic properties easier compared to using lists , but it is also appropriate for a sequent calculus that enjoys contraction and exchange , and designed so that weakening is an admissible property .",
    "this approach will also better motivate the use of lists in sub - structural logics in the next section .",
    "further , in our setting , contexts are particularly simple , namely sets of _ atoms _ , since only atoms are legal antecedents in implications in goals .",
    "the syntax of _ goal _ formulas can be directly rendered with an datatype : @xmath259 we write @xmath260 to represent the type of atoms ; @xmath261 coerces atoms into propositions .",
    "the definition of @xmath260 is left as an implicit parameter at this stage , because various instantiations will yield the signature of different ols , specifically predicates used to encode their judgments .",
    "this language is so simple that its sequent calculus is analogous to a logic programming interpreter .",
    "all clauses allowed by the above grammar can be normalized to ( a set of ) clauses of the form : @xmath262 where @xmath263 , and for @xmath264 , @xmath265 is either a ground type , or has the form @xmath266 where @xmath267 and @xmath268 are ground types . in analogy with logic programming , when writing clauses , outermost universal quantifiers will be omitted , as those variables are implicitly quantified by the meta - logic",
    "; implication will be written in the reverse direction , , we write simply @xmath269 , or when we need to be explicit about the quantified variables , we write @xmath270 where @xmath271}. this notation yields a more proof - search oriented notion of clauses . in fact , we can write inference rules so that the only left rule is similar to prolog s backchaining . sequents have the form @xmath272 , where @xmath273 is the current signature of eigenvariables and we distinguish clauses belonging to a static database , written @xmath274 , from atoms introduced via the right implication rule , written @xmath166 .",
    "the rules for this logic are given in figure  [ fig : minlogbc ] . in the @xmath275 rule ,",
    "@xmath276 $ ] is the set of all possible instances of clauses in @xmath274 obtained by instantiating outermost universal quantifiers with all closed terms of appropriate types .",
    "@xmath277 \\qquad\\qquad \\ibn{\\iseqp{\\sigma;\\g}{g_1}}{\\iseqp{\\sigma;\\g}{g_2 } }        { \\iseqp{\\sigma;\\g}{g_1\\with g_2}}{\\with_r}\\\\[1em ]    \\ian{}{\\iseqp{\\sigma;\\g}{\\top}}{\\top_r } \\qquad\\qquad\\qquad    \\ian{\\iseqp{(\\sigma , a : \\tau);\\g}{g[a / x]}}{\\iseqp{\\sigma;\\g}{\\forall^\\tau x   \\ldot g } } { \\forall_r } \\\\[1em ] \\qquad\\qquad\\qquad    \\ibn{\\iseqp{\\sigma;\\g}{g } } { a \\if g \\in [ \\pi ] }        { \\iseqp{\\sigma;\\g}{a } }        { \\ir{bc } } \\end{array}$}}\\ ] ]    this inference system is equivalent to the standard presentation of minimal logic @xcite , where the right rules are the same and the left rules ( given below ) for conjunction , implication and universal quantification replace the * bc * rule .",
    "@xmath278}{g } }    { \\iseqp{\\sigma;\\g,\\forall x\\ldot d}{g } }         { \\ir{\\forall_l } } \\\\[1em ] \\ibn{\\sigma;\\iseqp{\\g}{g}}{\\sigma;\\iseqp { \\g , b}{a } }         { \\sigma;\\iseqp{\\g , ( g \\imp b)}{a } }         { \\ir{\\imp_l } } \\end{array}$}}\\ ] ]    in fact , the rule is derivable by eliminating the universal quantifiers until the head of a clause matches the atom on the right and then applying @xmath279 .",
    "the reader should remember that we are working in an ambient logic modulo some equational theory ( in the case of isabelle @xmath280 ) and that both atomic rules ( @xmath281 and @xmath275 ) are applicable in the case when an atom on the right appears as an assumption and unifies with the head of a definite clause in the program @xmath274 .",
    "thus , we can inherit the completeness of _ uniform provability _",
    "@xcite an ordinary sequent calculus , which holds for a much more expressive conservative extension of our sl , namely higher - order harrop formulas .",
    "we encode this sl in figure  [ fig : nseq ] .",
    "@xmath282\\hline\\end{aligned}\\ ] ]    we use the symbol @xmath283 for the sequent arrow , in this case decorated with natural numbers that represent the _ height _ of a proof ; this measure allows us to reason by complete induction .. ] for convenience we write @xmath284 if there exists an @xmath285 such that @xmath286 , and furthermore we simply write @xmath287 when @xmath288 .",
    "the first four clauses of the definition directly encode the introduction ( @xmath120 ) rules of the figure . in the encoding of the @xmath289 rule ,",
    "when we introduce new eigenvariables of type @xmath58 , we need to assume that they are @xmath126 .",
    "this assumption might be required for proving subgoals of the form @xmath290 for subterms @xmath291 that appear in the goal as arguments to binding constructors ; see mc - lemma  [ mclem : proper_abst ] ( _ proper_abst)_.    we remark that the only dependence on in this layer is on the definition of @xmath126",
    ". this will also be true of the sl we consider in section  [ sec : olli ] .",
    "although we do not discuss it here , we could use sls with ( different ) kinds of quantifiers that could not be implemented via a datatype but only with constants ; for example universal quantification in higher - order logic . in this case",
    ", the specification layer would have a much greater dependence on . on the other hand , if we take the alternative solution to proper terms mentioned earlier ( when discussing mc - lemma  [ mclem : proper_abst ] ) and replace @xmath58 with a type @xmath104 containing exactly the terms that satisfy @xmath126 , and consider only the sls presented in this paper , then these sls can be parameterized by the type of terms used in quantification , and can be instantiated with types other than @xmath104 .",
    "in the last two rules in figure  [ fig : nseq ] , atoms are provable either by assumption or via _ backchaining _ over a set of prolog - like rules , which encode the properties of the ol in question as an inductive definition of the predicate of type @xmath292 , which will be instantiated in section  [ ssec : prog ] .",
    "the sequent calculus is parametric in those clauses and so are its meta - theoretical properties . because is static it will be mentioned explicitly only in adequacy proofs .",
    "the notation @xmath293 in figure  [ fig : nseq ] represents an instance of one of the clauses of the inductive definition of .    as a matter of fact our encoding of the judgment @xmath286",
    "can be seen as a simple extension of the so - called `` vanilla '' prolog meta - interpreter , often known as @xmath294 ; similarly , the * bc * rule would correspond to the following clause , using the predicate @xmath295 in place of prolog s built - in @xmath296 : @xmath297    existential quantification could be added to the grammar of goals , as follows : @xmath298 but this yields no real increase in expressivity , as existentials in the body of goals can be safely transformed to outermost universal quantifiers , while ( continuing the logic programming analogy ) the above rule simply delegates the witness choice to the ambient logic unification algorithm .",
    "as before , the fact that provability is inductive yields inversion principles as elimination rules .",
    "for example the inversion theorem that analyzes the shape of a derivation ending in an atom from the _ empty _ context is obtained simply with a call to the standard @xmath299 function , namely @xmath300 is : @xmath301    the adequacy of the encoding of the sl can be established adapting the analogous proof in  @xcite .",
    "to do so , we overload the decoding function in several ways .",
    "first , we need to decode terms of types other than @xmath58 . for example , decoding terms of type @xmath97 is required for most ols . for mini - ml",
    ", we also need to decode terms of type _",
    "tp_. the decoding is extended in the obvious way .",
    "for example , for decoding second - order terms , we define @xmath302 .",
    "second , to decode both goals and clauses , we extend @xmath273 to allow both first- and second - order variables .",
    "we can then extend the decoding so that if @xmath303 is a term of type @xmath304 with free variables in @xmath273 , then @xmath305 is its translation to a formula of minimal logic , and if @xmath166 is a set of terms of type @xmath306 , then @xmath307 is its translation to a set of atomic formulas of minimal logic .",
    "in addition , we restrict the form of the definition of so that every clause of the inductive definition is a closed formula of the form : @xmath308 where @xmath273 is a set of variables including at least @xmath309 , each of type @xmath97 , with @xmath263 . to obtain a theory in minimal logic that corresponds to the definition of , we decode each clause to a formula of minimal logic of the form @xmath310 . for sl adequacy",
    ", we also need to introduce two conditions , which become additional proof obligations when establishing ol adequacy .",
    "they are :    1 .",
    "it is only ever possible to instantiate universal quantifiers in clauses with terms for which the decoding is defined .",
    "2 .   for every term @xmath291",
    "used to instantiate universal quantifiers in clauses , @xmath290 holds .",
    "the latter will follow from the former and the fact that for _ all _ terms @xmath291 for which the decoding is defined , @xmath290 holds .",
    "let be an inductive definition of the restricted form described above , and let @xmath274 be the corresponding theory in minimal logic .",
    "let @xmath303 be a formula of type @xmath304 and let @xmath166 be a set of atoms .",
    "let @xmath273 be a set of variables of type @xmath58 that contains all the free variables in @xmath166 and @xmath303 .",
    "then the sequent @xmath311 has a minimal derivation in ( satisfying conditions 1 and 2 above ) if and only if there is a derivation of @xmath312 according to the rules of figure  [ fig : minlogbc ] . [",
    "lem : sladeq ]    the proof of the forward direction follows directly by induction on the minimal derivation of @xmath311 .",
    "compositionality ( lemma  [ le : comp ] ) is needed for the case when @xmath313 is proved by the last clause of figure  [ fig : nseq ] .",
    "the proof of the backward direction is by direct induction on the derivation of @xmath312 .",
    "compositionality ( lemma  [ le : comp ] ) and conditions 1 and 2 are needed for the @xmath275 case .",
    "the following rules are admissible :    1 .",
    "height weakening : @xmath314 .",
    "rule . ] 2 .",
    "context weakening : @xmath315 .",
    "atomic cut : @xmath316 .",
    "[ mcthm : struct ]    1 .",
    "the proof , by structural induction on sequents , consists of a one - line call to an automatic tactic using the elimination rule for successor ( from the library ) and the introduction rules for the sequent calculus .",
    "2 .   by a similar fully automated induction on the structure of the sequent derivation , combining resolution on the sequent introduction rules with simplification in order to discharge some easy set - theoretic subgoals .",
    "3 .   atomic cut is a corollary of the following lemma : @xmath317 easily proved by complete induction on the height of the derivation of @xmath318 .",
    "the whole proof consists of two dozen instructions , with very little ingenuity required from the human collaborator .",
    "recall the rules for call - by - value operational semantics ( @xmath221 ) and type inference  ( @xmath319 ) given in figure  [ fig : dyn - st ] .",
    "the subject reduction for this source language is stated as usual .",
    "[ thm : infsubred ] if @xmath221 and @xmath320 , then @xmath321 .    by structural induction on evaluation and inversion on typing , using weakening and a substitution lemma in the * ev_app * and * ev_fix * cases .",
    "we now return to the encoding of the ol , this time using the sl to encode judgments .",
    "the encoding of ol syntax is unchanged .",
    "( see section  [ using ] . )",
    "recall that it involved introducing a specific type for @xmath40 . here",
    ", we will also instantiate type @xmath260 and predicate . in this section and the next , we now also make full use of the definitions and theorems in both and the sl layers .",
    "type @xmath260 is instantiated as expected , defining the atomic formulas of the ol .",
    "@xmath322 the clauses for the ol deductive systems are given as rules of the inductive definition in figure  [ fig : prog1 ] ( recall the notation @xmath323 ) .",
    "@xmath324\\hline\\end{aligned}\\ ] ]    recall that the encoding of evaluation in figure  [ fig : hoas - eval1 ] and the encoding of the predicate for adequacy purposes both used inductive definitions . here",
    "we define them both at the sl level along with the ol level typing judgment .",
    "note that no explicit variable context is needed for this version of .",
    "they are handled implicitly by the contexts of atomic assumptions of the sl , resulting in a more direct encoding .",
    "as before , in the evaluation clauses , there are no assumptions and two assumptions .",
    "neither kind of assumption appears in the clauses for the typing rules .",
    "none is required to prove the analogue of mc - lemma  [ mclem : evalproper ] for both evaluation and typing .",
    "@xmath325 [ mclem : twoleveladeq ]    all the proofs are by standard induction on the given derivation , except the last one , whose statement needs to be generalized as follows : @xmath326    with the new version of , we restate the validity and completeness of representation lemmas ( lemmas  [ lem : valid ] and  [ le : complete ] ) .",
    "let @xmath166 be the set @xmath200 and let @xmath327 be the set of atoms @xmath328 .    if  @xmath329 , then the following is provable in : @xmath330    if there is a minimal derivation in of @xmath331 , then @xmath202 is defined and yields a mini - ml expression @xmath31 such that @xmath188 and @xmath332 .",
    "furthermore , @xmath172 .",
    "[ lem : comp2level ]    we will skip the statement and proof of two - level adequacy of the other ol judgments , hoping that the reader will spot the similarity with the above two lemmas . note that , although we do not state it formally , condition 1 of lemma  [ lem : sladeq ] follows from completeness lemmas such as lemma  [ lem : comp2level ] . the and assumptions added to the clauses of figure  [ fig : prog1 ] are exactly the ones needed to establish this fact for this ol .",
    "we remark again that the combination of with the use of an sl allows us to simulate definitional reflection @xcite via the built - in elimination rules of the inductive definition _ without _ the use of additional axioms .",
    "for example the inversion principle of the function typing rule is : p    before turning to the proof of theorem  [ thm : infsubred ] , we first illustrate the use of this encoding with the following simple ol typing judgment .",
    "[ le : sl - ex ] @xmath333 [ lem : olsimple ]    this goal is equivalent to : @xmath334 .",
    "it can be proved fully automatically by a simple tactic described below . here , we describe the main steps in detail to acquaint the reader with the ol / sl dichotomy and in particular to show how the two levels interact .",
    "we use the instantiations for @xmath335 and @xmath285 that would be generated by the tactic and show : @xmath336 we apply the last rule of the sl in figure  [ fig : nseq ] , instantiating the first premise with the ol clause from figure  [ fig : prog1 ] encoding the @xmath248 rule for typing abstractions , leaving two premises to be proved : @xmath337 the first now matches directly the clause in figure  [ fig : prog1 ] for @xmath248 , resulting in the proof obligation @xmath338 which is handled automatically by discussed in section  [ using ] . to prove the second",
    ", we apply further rules of the sl to obtain the goal : @xmath339 we now have a subgoal of the same `` shape '' as the original theorem . repeating the same steps ,",
    "we obtain : @xmath340 along the way , the proof obligation @xmath341 is proved by .",
    "the assumption @xmath342 is needed to complete this proof . at this point",
    ", we again apply the sl backchain rule using the ol clause for @xmath247 , obtaining two subgoals , the first of which is again directly provable from the ol definition . the second : @xmath343 is completed by applying the rules in figure  [ fig : nseq ] encoding the @xmath344 and @xmath281 rules of the sl .",
    "the code for the tactic automating this proof and others involving ol goals using the sl is a simple modification of the standard @xmath345 tactic :    .... fun 2lprolog_tac defs i =          fast_tac(hol_cs addis seq.intrs @ prog.intrs                  ( simpset ( ) addsolver ( abstr_solver defs ) ) ) i ; ....    it is based on logic programming style depth - first search ( although we could switch to breadth - first or iterative deepening ) using a small set of initial axioms for the core of higher - order logic ( ` hol_cs ` ) , the rules of the sl ( ` seq.intrs ` ) and of the ol ( ` prog.intrs ` ) .",
    "additionally , it also employs simplification augmented with as discussed in section  [ using ] .",
    "now we have all the elements in place for a formal hoas proof of theorem  [ thm : infsubred ] .",
    "note that while a substitution lemma for typing plays a central role in the informal subject reduction proof , here , in the hoas tradition , it will be subsumed by the use of the cut rule on the hypothetical encoding of the typing of an abstraction .",
    "@xmath346 [ mcthm : olsr ]    the proof is by complete induction on the height of the derivation of evaluation .",
    "it follows closely the proofs in  @xcite , although those theorems are for the lazy @xmath0-calculus , while here we consider eager evaluation . applying meta - level introduction rules and induction on @xmath285 , we obtain the sequent : @xmath347 where @xmath348 is the induction hypothesis :    @xmath349 since the right side of the sl sequent in the middle hypothesis is an atom and the left side is empty , any proof of this sequent must end with the last rule of the sl in figure  [ fig : nseq ] , which implements the * bc * rule .",
    "also , since the right side is an evaluation judgment , backchaining must occur on one of the middle three clauses of the ol in figure  [ fig : prog1 ] , thus breaking the proof into three cases . in the formal proof , we obtain these three cases by applying standard inversion tactics : @xmath350;\\,\\,\\abstr{e'_1};\\,\\ ,   ( \\slvdn{}{i }    { \\sland{\\slat{\\eval{e_1}{\\llfun{x}{e'_1\\ x } } } }    { \\sland{\\slat{\\eval{e_2}{v_2}}}{\\slat{\\eval{(e'_1\\        v_2)}{v}}}}});\\nonumber\\\\ \\slvde{\\slat{(e_1\\ \\oat\\ e_2)\\hastype t } } \\eprems \\implies   \\slvde{\\slat{v \\hastype t } } \\label{eq : appcase}\\\\[10pt ] \\prems{ih[i+1/n];\\,\\,\\abstr{e};\\,\\ , \\slvdn{}{i}{\\slat{\\istermtwo{(\\llfun{x}{e\\ x})}}};\\,\\ , \\slvde{\\slat{(\\llfun{x}{e\\ x})\\hastype t } } } \\nonumber \\\\ \\implies",
    "\\slvde{\\slat{(\\llfun{x}{e\\ x})\\hastype t}}\\nonumber \\\\[10pt ] \\bprems ih[i+1/n];\\,\\,\\abstr{e};\\,\\ ,    ( \\slvdn{}{i }     { \\sland{\\slat{\\eval{e\\ ( \\llrec{e\\ x})}{v } } }            { \\slat{\\istermtwo{(\\llrec{e\\ x})}}}});~~   \\nonumber \\\\",
    "\\slvde{\\slat{(\\llrec{e \\ x})\\hastype t } } \\eprems \\implies   \\slvde{\\slat{v \\hastype t } } \\nonumber\\end{aligned}\\ ] ] where @xmath351 $ ] denotes @xmath348 with the single occurrence of @xmath285 replaced by @xmath352 .",
    "the theorems mentioned earlier about injectivity and distinctness of the constructors @xmath3 , @xmath353 , and @xmath157 are used by the inversion tactics . in contrast , in the proof in  @xcite , because these constructors were not defined inductively , specialized inversion theorems were proved from axioms stating the necessary injectivity and distinctness properties , and then applied by hand .",
    "the second subgoal above is directly provable .",
    "we illustrate the first one further .",
    "applying inversion to both the third and fourth hypotheses of the first subgoal , the subgoal reduces it to : @xmath354;\\,\\,\\abstr{e'_1};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_1}{\\llfun{x}{e'_1\\ x}}}};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_2}{v_2}}};\\,\\,\\\\   \\slvdn{}{i}{\\slat{\\eval{(e'_1\\ v_2)}{v } } } ; \\slvde{\\slat{e_1\\hastype t'\\fsp t}};\\,\\ , \\slvde{\\slat{e_2\\hastype t ' } } \\eprems\\\\   \\implies   \\slvde{\\slat{v \\hastype t}}. \\end{array}\\ ] ] it is now possible to apply the induction hypothesis to the typing and evaluation judgments for @xmath355 and @xmath219 to obtain : @xmath354;\\,\\,\\abstr{e'_1};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_1}{\\llfun{x}{e'_1\\ x}}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{e_2}{v_2}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{(e'_1\\ v_2)}{v}}};\\ldots;~~ \\\\",
    "~~\\slvde{\\slat{\\llfun{x}{e'_1\\ x}\\hastype t'\\fsp t}};\\,\\ , \\slvde{\\slat{v_2\\hastype t'}}\\eprems\\\\   \\implies   \\slvde{\\slat{v \\hastype t}}. \\end{array}\\ ] ] we can now apply inversion to the hypothesis with the arrow typing judgment involving both the @xmath3 constructor of the ol and the @xmath356 constructor of the sl .",
    "inversion at the ol level gives : @xmath354;\\,\\,\\abstr{e'_1};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_1}{\\llfun{x}{e'_1\\ x}}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{e_2}{v_2}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{(e'_1\\ v_2)}{v}}};\\ldots;~~\\\\ ~~\\slvde{\\slat{v_2\\hastype t'}};\\,\\ , \\abstr{e};\\,\\ , \\llambda{e}=\\llambda{e'_1};\\,\\ , \\slvde{\\slall{x}(\\slimp{x\\hastype t'}{\\slat{(e\\ x)\\hastype t } } ) } \\eprems\\\\   \\implies   \\slvde{\\slat{v \\hastype t}}. \\end{array}\\ ] ] the application of the inversion principle ` prog.mkh\\_cases ` similar to the one from section  [ using ] is evident here .",
    "mc - theorem  [ thm : inj ] can be applied to conclude that @xmath357 . applying inversion at the sl level",
    "gives : @xmath354;\\,\\,\\abstr{e};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_1}{\\llfun{x}{e\\ x}}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{e_2}{v_2}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{(e\\ v_2)}{v}}};\\ldots;~~\\\\ ~~\\slvde{\\slat{v_2\\hastype t'}};\\,\\ , \\forall x.\\ , ( \\proper{x}\\limp \\slvde{\\slimp{x\\hastype t'}{\\slat{(e\\ x)\\hastype t } } } ) \\eprems\\\\ \\implies   \\slvde{\\slat{v \\hastype t}}. \\end{array}\\ ] ] inversion can not be applied directly under the universal quantification and implication of the last premise , so we prove the following inversion lemma , which is also useful for the @xmath212 case of this proof .",
    "@xmath358 from this lemma , and the fact that @xmath359 holds by mc - lemma  [ mclem : evalproper ] , we obtain : @xmath354;\\,\\,\\abstr{e};\\,\\ ,   \\slvdn{}{i+1}{\\slat{\\eval{e_1}{\\llfun{x}{e\\ x}}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{e_2}{v_2}}};\\,\\ ,   \\slvdn{}{i}{\\slat{\\eval{(e\\",
    "v_2)}{v}}};\\ldots;~~\\\\ ~~\\slvde{\\slat{v_2\\hastype t'}};\\,\\ ,   ( \\slvdn{(v_2\\hastype t')}{j}{\\slat{(e\\ v_2)\\hastype t } } ) \\eprems\\\\   \\implies   \\slvde{\\slat{v \\hastype t}}. \\end{array}\\ ] ] applying the cut rule of mc - theorem  [ mcthm : struct ] allows us to conclude @xmath360 .",
    "we can then complete the proof by applying the induction hypothesis a third time using this fact and @xmath361 .",
    "a key point in this section , perhaps worth repeating , is that the clauses for typing are not inductive and would be rejected in an inductive - based proof assistant , or at best , asserted with no guarantee of consistency . here , instead",
    ", the typing rules are encapsulated into the ol level ( the predicate ) and executed via the sl , so that ol contexts are implicitly represented as sl contexts .",
    "therefore , we are able to reproduce full hoas proofs , at the price of a small degree of indirectness  the need for an interpreter ( the sl ) for the clauses ( the ol ) .",
    "one may argue that this seems at first sight a high price to pay , since we lose the possibility of attacking the given problem directly within the base calculus and its tools .",
    "however , very simple tactics , including a few _ safe _ additions to s default simplifier and rule set make the use of the sl in ol proofs hardly noticeable , as we explain next .      we chose to develop as a package , rather than a stand - alone system mainly to exploit all the reasoning capabilities that a mature proof assistant can provide : decision procedures , rewrite rules , counter - model checking , extensive libraries , and support for interactive theorem proving .",
    "contrast this with a system such as twelf , where proofs are manually coded and post - hoc checked for correctness .",
    "moreover , in twelf as well as in abella , any domain specific knowledge has to be coded as logic programming theories and all the relevant theorems proven about them . at the same time , our aim is to try to retain some of the conciseness of a language such as lf , which for us means hiding most of the administrative reasoning concerning variable binding and contexts .",
    "because of the `` hybrid '' nature of our approach , this can not be completely achieved , but some simple - minded tactics go a long way toward mechanizing most of boilerplate scripting . we have already explained how to use specific tactics to recognize _ proper _ terms and _ abstractions_. now , we can concentrate on assisting two - level reasoning , which would otherwise be encumbered by the indirection in accessing ol specifications via the sl .",
    "luckily , twelf - like reasoning consists , at a high - level , of three basic steps : inversion , which subsumes instantiation of ( meta - level ) eigenvariables as well as ( case ) analysis on the shape of a given judgment , backchaining ( filling , in twelf s terminology ) and recursion .",
    "this corresponds to highly stereotyped proof scripts that we have abstracted into :    1 .",
    "an _ inversion _ tactic , which goes through the sl inverting on the * bc * rule and applies as an elimination rule one of the ol clauses .",
    "this is complemented by the eager application of other _",
    "safe _ elimination rules ( invertible sl rules such as conjunction elimination ) .",
    "this contributes to keeping the sl overhead to a minimum ; 2 .   a dual _ backchaining _",
    "tactic , that calls * bc * and the applicable rule . the latter is the basic single step into the tactic , which performs automatic depth first search ( or other searches supported by isabelle ) on prolog - like goals ; 3",
    ".   a _ complete induction _ tactic , to be fired when given the appropriate derivation height by the user and yielding as additional premise the result of the application of the ih .",
    "as mentioned , the main reason to explicitly encode a separate notion of provability is the intrinsic incompatibility of induction with non - stratifiable hypothetical judgments . on the other hand , as remarked in @xcite , our definition of ol evaluation , though it exploits s hoas to implement ol substitution , makes no use of hypothetical judgments .",
    "in fact , our encoding in figure  [ fig : hoas - eval1 ] showed that it is perfectly acceptable to define evaluation of the ol at the meta - level .",
    "now , we can give a modified version of this definition using the new defined at the sl level .",
    "the new definition is given in figure  [ fig : hoas - eval2 ] .",
    "@xmath362\\hline \\end{array}\\ ] ]    moreover , it is easy to show ( formally ) that the encoding in figure  [ fig : hoas - eval2 ] is equivalent to the one in figure  [ fig : prog1 ] :    @xmath363 if and only if @xmath364 .",
    "left - to right holds by straightforward structural induction on evaluation using introduction rules over sequents and clauses .",
    "the converse is a slightly more delicate complete induction on the height of the derivation , requiring some manual instantiations .",
    "the same remark applies also to hypothetical and parametric judgments , provided they are stratified ( see the previously cited definition of applicative bisimulation ) .",
    "this suggests that we can , in this case , take a different approach from mcdowell & miller s architecture  @xcite and opt to delegate to the ol level _ only _ those judgments , such as typing , that would not be inductive at the meta - level .",
    "this has the benefit of limiting the indirectness of using an explicit sl .",
    "moreover , it has the further advantage of replacing complete induction with structural induction , which is better behaved from a proof - search point of view .",
    "complete induction , in fact , places an additional burden on the user by requiring him / her to provide the correct instantiation for the height of the derivation in question , so that the inductive hypothesis can be fired .",
    "while this is not an intellectual issue , it often limits the possibility of a complete , , without user intervention , mechanization of a proof via the automatic tools provided by the proof assistant .",
    "as it turns out , this approach is again reminiscent of a fairly old idea from the theory of logic programming , namely the _ amalgamation _ of object and meta - language as initially suggested in @xcite , where clauses can be written interspersing ordinary prolog predicates with calls to a specific meta - interpreter of the @xmath294 sort .",
    "this clearly also pertains to goals , , in our setting , theorems : subject reduction at the meta - level ( , amalgamated subject reduction ) has the form :    @xmath365    the proof is similar but slightly simpler than the proof of mc - theorem  [ mcthm : olsr ] . instead of complete induction ,",
    "we proceed by structural induction on the evaluation judgment , which breaks the proof into three cases .",
    "we again consider the application case : @xmath366 where @xmath367 , @xmath368 , and @xmath369 are the following three induction hypotheses : @xmath370 this subgoal corresponds to subgoal  ( [ eq : appcase ] ) in the proof of mc - theorem  [ mcthm : olsr ] , with several differences .",
    "for instance , subgoal  ( [ eq : appcase ] ) was obtained by an application of complete induction followed by inversion on the ol and sl , while the above subgoal is a direct result of applying structural induction .",
    "also , although both subgoals have three evaluation premises , in  ( [ eq : appcase ] ) they are inside conjunction at the sl level .",
    "finally , the general induction hypothesis @xmath348 on natural numbers in  ( [ eq : appcase ] ) is replaced by three induction hypotheses here , generated from the premises of the meta - level definition of the evaluation rule for application .",
    "the remaining steps of the proof of this case are essentially the same as the steps for mc - theorem  [ mcthm : olsr ] .",
    "inversion on the typing judgment is used exactly as before since in both proofs , typing is expressed via the sl .",
    "also , the three induction hypotheses in this proof are used to reach the same conclusions as were obtained using the single induction hypothesis three times in the previous proof .",
    "now that we have seen some proofs of properties of ols , we can ask what the minimal set of theorems and tactics is that the two - level architecture needs from .",
    "the answer is : very little .",
    "essentially all we need is the quasi - freeness properties of the type , which are inherited from the ol :    * clash rules to rule out impossible cases in elimination rules ; * injectivity facts , all going back to _ abstr_lam_simp _ to simplify equations of the form @xmath371 for second - order functions @xmath169 and @xmath372 ; * an abstraction solver",
    ".    the reader may find in  @xcite other examples , such as the verification of properties of compilation , of encoding ols using inductive predicates ( types ) at the meta - level for all stratifiable object - level judgments .",
    "however , this style of reasoning is viable only when there is a substantial coincidence between the meta - logical properties of the sl and the ambient ( meta- ) logic . were such properties to clash with an encoding that could benefit from being driven by a more exotic logic , then _ all _ ol predicates will have to be embedded as clauses .",
    "this , it may be argued , is a relatively small price to pay for the possibility of adopting an sl that better fits the logical peculiarities of interesting ols , as we investigate next .",
    "in this section we aim to show the flexibility of the two - level architecture by changing sl in order to have a better match with the encoding on hand ; the case - study we consider here is the operational semantics of a _",
    "continuation_-based abstract machine , where evaluation is sequentialized : an instruction is executed in the context of a continuation describing the rest of the computation and eventually returning an answer .",
    "we will adopt an _ ordered logical framework _ ( olf )  @xcite .",
    "the general methodology consists of refining a logical framework in a _ conservative _ way , so as to capture different object - level phenomena at the right level of abstraction .",
    "conservativity here guarantees that if a new feature ( such as order ) is not required , it does not interfere with the original system .",
    "although frameworks based on intuitionistic logic have been fairly fruitful , it so happens that the _ structural _ properties of the framework , namely weakening , contraction and exchange , are inherited by the object - level encodings .",
    "we have argued that one of the keys to the success of an encoding lies in the ability of specifying judgments `` in - a - context '' exploiting the context of the sl itself ; however those properties may not always be appropriate for every domain we want to investigate .",
    "another case in point is the meta - theory of languages with imperative features , where the notion of ( updatable ) _ state _ is paramount .",
    "it has been frequently observed that an elegant representation of the store may rely on a _ volatile _ notion of context . _",
    "linear logic _ is then the natural choice , since it offers a notion of context where each assumption must be used exactly once ; a declarative encoding of store update can be obtained via linear operations that , by accessing the context , consume the old assumption and insert the new one .",
    "this is one of the motivations for proposing frameworks based on linear logics ( see  @xcite for an overview ) such as lolli  @xcite , forum  @xcite , and llf  @xcite , a _ conservative _ extension of lf with multiplicative implication , additive conjunction , and unit . yet , at the time of writing this article , work on the _ automation _ of reasoning in such frameworks is still in its infancy  @xcite and may take other directions , such as hybrid logics @xcite .",
    "the literature offers only a few formalized meta - theoretical investigations with linear logic as a framework , an impressive one being the elegant encoding of type preservation of mini - ml with references ( mlr ) in llf  @xcite . however",
    ", none of them comes with anything like a formal certification of correctness that would make people _ believe _ they are in the presence of a proof .",
    "encoding in llf lacks an analogue of twelf s totality checker .",
    "moreover this effort may be reserved to llf s extension , the concurrent logical framework  @xcite .",
    "a proof of a similar result is claimed in @xcite , but not only the proof is not available , but it has been implemented with eriksson s pi , a proof checker  @xcite for the theory of partial inductive definitions , another software system that seems not to be available anymore .",
    "this alone would more than justify the use of a fragment of linear logic as an sl on top of , whose foundation , we have argued , is not under discussion .",
    "however , we want to go beyond the logic of state , towards a logic of _ order_. in fact , a continuation - based abstract machine follows an order , a stack - like discipline ; were we able to also _ internalize _ this notion , we would be able to simplify the presentation , and hence , the verification of properties of the continuation itself , taking an additional step on the declarative ladder .",
    "our contribution here to the semantics of continuation machines is , somewhat paradoxically , to dispose of the notion of continuation itself via internalization in an ordered context , in analogy with how the notion of state is realized in the linear context . in particular , the ordered context is used to encode directly the stack of continuations to be evaluated , rather than building an explicit stack - like structure to represent a continuation .",
    "while this is theoretically non - problematic , it introduces entities that are foreign to the mathematics of the problem and which bring their own numerous , albeit trivial , proof obligations .",
    "further and more importantly , machine states can be mapped not into ol data , but ol _",
    "provability_.    ordered ( formerly known as non - commutative ) linear logic @xcite combines reasoning with unrestricted , linear and ordered hypotheses .",
    "unrestricted ( , intuitionistic ) hypotheses may be used arbitrarily often , or not at all regardless of the order in which they were assumed .",
    "linear hypotheses must be used exactly once , also without regard to the order of their assumption .",
    "ordered hypotheses must be used exactly once , subject to the order in which they are assumed .",
    "this additional expressive power allows the logic to handle directly the notion of _ stack_. stacks of course are ubiquitous in computer science and in particular when dealing with abstract and virtual machines .",
    "olf has been previously applied to the meta - theory of programming languages , but only in paper and pencil proofs : polakow and pfenning  @xcite have used olf to formally show that terms resulting from a cps translation obey `` stackability '' and linearity properties  @xcite .",
    "polakow and yi  @xcite later extended these techniques to languages with exceptions .",
    "remarkably , the formalization in olf provides a simple proof of what is usually demonstrated via more complex means , , an argument by logical relations .",
    "polakow  @xcite has also investigated proof - search and defined a first - order logic programming language with ordered hypotheses , called _ olli _ , based on the paradigm of abstract logic programming and _ uniform _ proofs , from which we draw inspiration for our ordered sl , , a second - order minimal ordered linear sequent calculus .",
    "we exemplify this approach by implementing a fragment of polakow s ordered logic as an sl and test it with a proof of type preservation of a continuation machine for mini - ml , as we sketched in @xcite . for the sake of presentation we shall deal with a call - by - name operational semantics .",
    "it would not have been be unreasonable to use mlr as a test case , where all the three different contexts would play a part .",
    "however , linearity has already been thoroughly studied , while we wish to analyze ordered assumptions in isolation , and for that aim , a basic continuation machine will suffice ( but see @xcite for a thorough investigation of the full case ) . further , although the sl implementation handles all of second - order olli and in particular proves cut - elimination for the whole calculus , we will omit references to the ( unordered ) linear context and linear implication , as well as to the ordered left implication , since they do not play any role in this case - study .",
    "@xmath373   \\ian{\\seq{(a,\\g)}{\\o}{g } }       { \\seq{\\g}{\\o}{a\\imp g } }       { \\imp_r }   \\qquad\\qquad   \\ian{\\seq{\\g}{{(\\o , a ) } } { g } }        { \\seq{\\g}{\\o}{a \\roimp g } }        { \\roimp_r }   \\\\[1em ]   \\ibn{\\seq{\\g}{\\o}{g_1}}{\\seq{\\g}{\\o}{g_2 } }       { \\seq{\\g}{\\o}{g_1\\with g_2}}{\\with_r}\\\\[1em ]   \\ian{}{\\seq{\\g}{\\o}{\\top}}{\\top_r } \\qquad\\qquad   \\ian{\\seq{\\g}{\\o}{g[a / x]}}{\\seq{\\g}{\\o}{\\forall x\\ldot       g}}{\\forall_r^a }   \\\\[1em ]   \\ian {    \\begin{array}{l } ( { a \\if [ g_1,\\ldots , g_m ] { \\mid}[g'_1,\\ldots , g'_n ] } ) \\in [ \\pi]\\\\   \\seq{\\g}{\\cdot}{g_1 } \\:\\ldots\\ : \\seq{\\g}{\\cdot}{g_m}\\\\    { \\seq{\\g}{{\\o}_1}{g'_1 } \\:\\ldots\\ : \\seq{\\g}{{\\o}_n}{g'_n } }    \\end{array } }        { \\seq{\\g}{{\\o}_n\\ldots{\\o}_1}{a } }        { \\ir{bc } } \\end{array}$}\\ ] ]    we call our specification logic , as it corresponds to the aforementioned fragment of olli , where @xmath374 denotes right - ordered implication .",
    "we follow @xcite again in representing the syntax as : @xmath375 { \\mid}[g'_1,\\ldots , g'_n ] } ) \\end{array}\\ ] ] the body of a clause @xmath376 { \\mid}[g'_1,\\ldots , g'_n]})$ ] consists of two _ lists _ , the first one of intuitionistic goals , the other of ordered ones .",
    "it represents the `` logical compilation '' of the formula @xmath377 .",
    "we choose this compilation to emphasize that if one views the calculus as a non - deterministic logic programming interpreter , the latter would solve subgoals from innermost to outermost .",
    "note also that this notion of clause makes additive conjunction useless , although we allow it in goals for a matter of style and consistency with the previous sections .",
    "our sequents have the form : @xmath378 where @xmath379 contains the program clauses , which are unrestricted ( , they can be used an arbitrary number of times ) , @xmath380 contains unrestricted atoms , @xmath381 contains ordered atoms and @xmath303 is the formula to be derived .",
    "contexts are lists of hypotheses , where we overload the comma to denote adjoining an element to a list at both ends . to simplify matters further ,",
    "we leave eigenvariable signatures implicit .",
    "one may think of the two contexts as one big context where the ordered hypotheses are in a fixed relative order , while the intuitionistic ones may float , copy or delete themselves .",
    "the calculus is depicted in figure  [ fig : oseq ] . again in this fragment of the logic , implications have only atomic antecedents .",
    "there are obviously two implication introduction rules , where in rule @xmath382 the antecedent @xmath256 is appended to the _ right _ of @xmath383 , while in the other rule we have @xmath384 , but it could have been the other way around , since here the order does not matter .",
    "then , we have all the other usual right sequent rules to break down the goal and they all behave additively .",
    "note how the @xmath385 rule can be used in discharging any unused ordered assumptions . for atomic goals",
    "there are two initial sequent rules , for the leaves of the derivation : @xmath386 enforces linearity requiring @xmath383 to be a singleton list , while @xmath387 demands that all ordered assumptions have been consumed .",
    "additionally , there is a single backchaining rule that simultaneously chooses a program formula to focus uponand derives all the ensuing subgoals ; rule @xmath388 is applied provided there is an _ instance _ @xmath389 { \\mid}[g'_1    \\ldots g'_n]}$ ] of a clause in the program @xmath274 .",
    "note that the rule assumes that every program clause must be placed to the _ left _ of the ordered context .",
    "this assumption is valid for our fragment of the logic because it only contains right ordered implications ( @xmath374 ) and the ordered context is restricted to atomic formulas .",
    "furthermore , the ordering of the @xmath390 in the conclusion of the rule is forced by our compilation of the program clauses .",
    "we leave to the keen reader the task to connect formally our backchain rule to the focused uniform proof system of @xcite .",
    "we encode this logical language extending the datatype from section  [ ssec : nseq ] with right implication , where again outermost universal quantifiers will be left implicit in clauses .",
    "@xmath391    our encoding of the sequent calculus uses three mutually inductive definitions , motivated by the compilation of the body of clauses into additive and multiplicative lists : could have easily been a set , as in section  [ sec:2lev ] . ]",
    "@xmath392 the rendering of the first judgment is completely unsurprising , rule will _ not _ introduce the assumption , but the reader should keep in mind the fact that morally every eigenvariable is indeed proper . ] except , perhaps , for the backchain rule , which calls the list predicates required to recur on the body of a clause : @xmath393 the notation @xmath394 corresponds to the inductive definition of a set this time of type @xmath395 , see figure  [ fig : tph ] . backchaining uses the two list judgments to encode , as we anticipated , execution of the ( compiled ) body of the focused clause .",
    "intuitionistic list provability is just an additive recursion through the list of intuitionistic subgoals : @xmath396}}\\\\    \\prems { \\slvdn{\\gamma{\\mid } { [ \\ ] } } { n}{g}\\ ; ; \\ ;    \\islvdn{\\gamma}{n}{gs } } & \\implies & \\islvdn{\\gamma}{n+1}{(g , gs ) }   \\end{array}\\ ] ] ordered list consumption involves an analogous recursion , but it behaves multiplicatively the ordered context .",
    "reading the rule bottom up , the current ordered context @xmath397 is non - deterministically split into two ordered parts , one for the head @xmath398 and one @xmath399 for the rest of the list of subgoals . @xmath400}}{n } { { [ \\ ] } } \\\\[0.3em ] \\prems { \\osplit{\\omega}{\\omega_r}{\\omega_g}\\ ; ; \\ ;   \\slvdn{\\gamma{\\mid}\\omega_g}{n}{g}\\ ; ; \\ ;    \\oslvdn{\\gamma}{\\omega_r}{n}{gs}}\\\\ \\qquad\\qquad   \\implies \\oslvdn{\\gamma}{\\omega}{n+1}{(g ,   gs ) } \\end{array}\\ ] ] therefore the judgment relies on the inductive definition of a predicate for order - preserving splitting of a context .",
    "this corresponds to the usual logic programming predicate @xmath401 called with mode @xmath402 .",
    "@xmath403}}{\\omega}\\\\    \\osplit{\\omega_1}{\\omega_2}{\\omega_3 }   & \\implies & \\osplit{(a ,   \\omega_1)}{(a ,   \\omega_2)}{\\omega_3 } \\end{array}\\ ] ] the rest of the sequent rules are encoded similarly to the previous sl ( figure  [ fig : nseq ] ) and the details are here omitted ( and left to the web appendix of the paper , see hybrid.dsi.unimi.it/jar ) .",
    "again we define @xmath404 iff there exists an @xmath285 such that @xmath405 and simply @xmath287 iff @xmath406}{\\mid } { [ \\ ] } } { g}$ ] . similarly for the other judgments .",
    "[ mcg : str ] the following rules are admissible :    * weakening for numerical bounds : 1 .",
    "@xmath407 2 .",
    "@xmath408 3 .   @xmath409 . *",
    "context weakening , where @xmath410 denotes the set underlying the context @xmath380 . 1 .",
    "@xmath411 2 .",
    "@xmath412 3 .",
    "@xmath413 . *",
    "intuitionistic atomic cut : 1 .",
    "@xmath414 } } j { \\slat a } }         \\implies",
    "\\slvdn { \\gamma'{\\mid}\\omega } { i + j } g $ ] .",
    "2 .   @xmath415 } } j { \\slat a } }         \\implies",
    "\\oslvdn { \\gamma'}{\\omega } { i + j } gs $ ] .",
    "3 .   @xmath416 } } j { \\slat a } }         \\implies \\islvdn { \\gamma ' } { i + j } gs $ ] .",
    "all the proofs are by mutual structural induction on the three sequents judgments .",
    "for the two forms of weakening , all it takes is a call to s classical reasoner .",
    "cut requires a little care in the implicational cases , but nevertheless it does not involve more then two dozens instructions .",
    "although the sequent calculus in  @xcite enjoys other forms of cut - elimination , the following :    @xmath417    is enough for the sake of the type preservation proof ( mc - theorem  [ thm : sr ] ) .",
    "further , admissibility of contraction and exchange for the intuitionistic context is a consequence of context weakening .",
    "we avail ourselves of the continuation machine for mini - ml formulated in  @xcite ( chapters 6.5 and 6.6 ) , which we refer to for motivation and additional details .",
    "we use the same language and we repeat it here for convenience : @xmath418    the main judgment @xmath419 ( figure  [ fig : kopsem ] ) describes how the state of the machine evolves into a successor state @xmath420 in a _ small - step _ style .",
    "the machine selects an expression to be executed and a _ continuation _",
    "@xmath421 , which contains all the information required to carry on the execution . to achieve this we use the notion of _ instruction _ , , an intermediate command that links an expression to its value .",
    "the continuation is either empty ( ) or it has the form of a stack ( @xmath422 ) , each item of which ( but the top ) is a _ function _ from values to instructions .",
    "instruction ( e ) starts the first step of the computation , while ( v ) tells the current continuation to apply to the top element on the continuation stack the newly found value .",
    "other instructions sequentialize the evaluation of subexpressions of constructs with more than one argument ; in our language , in the case of application , the second argument is postponed until the first is evaluated completely .",
    "this yields the following categories for the syntax of the machine : @xmath423 \\mbox{continuations } & k & \\bnfas & \\ir{init } \\bnfalt k;\\ilam{x}{i } \\\\[1ex ] \\mbox{machine states } & s & \\bnfas & k\\:\\diamond\\ : i \\bnfalt \\ir{answer}\\ , v \\end{array}\\ ] ]    @xmath424   \\ir{st\\_return } \\;\\;::\\;\\ ; & k;\\ilam{x}{i}\\:\\diamond\\:\\ir{return}\\,v   \\;\\hra\\ ; k\\:\\diamond\\:i[v / x ] \\\\[1em ] \\ir{st\\_fun } \\;\\;::\\;\\ ; & k\\:\\diamond\\:\\ir{ev}\\,(\\ir{fun}\\,x\\ldot e ) \\;\\hra\\ ;   k\\:\\diamond\\ : \\ir{return}\\,(\\ir{fun}\\ , x\\ldot e ) \\\\[1em ] \\ir{st\\_fix } \\;\\;::\\;\\ ; & k\\:\\diamond\\:\\ir{ev}\\,(\\ir{fix}\\,x\\ldot e ) \\;\\hra\\ ;   k\\:\\diamond\\ : \\ir{ev}\\,(e[\\ir{fix}\\ , x\\ldot e / x ] ) \\\\[1em ] \\ir{st\\_app } \\;\\;::\\;\\ ; & k\\:\\diamond\\:\\ir{ev}\\,(e_1\\ \\at\\ e_2 ) \\;\\hra\\ ;   k;\\ilam{x_1}{\\ir{app}_1\\,x_1\\,e_2 } \\:\\diamond\\ : \\ir{ev}\\,e_1 \\\\[1em ] \\ir{st\\_app_1 } \\;\\;::\\;\\ ; & k\\:\\diamond\\ : \\ir{app}_1\\,(\\ir{fun}\\,x\\ldot e)\\,e_2 \\;\\hra\\ ;   k \\:\\diamond\\ : \\ir{ev}\\,e[e_2/x]\\\\[1em ] \\end{array } $ } \\ ] ]    @xmath425        \\ianc{\\ir{init}\\:\\diamond\\:\\ir{ev}\\,e \\;\\hra^*\\ir{answer}\\,v } { \\cev         e v } { \\ir { cev } } \\end{array}$}\\ ] ]    the formulation of the subject reduction property of this machine follows the statement in  @xcite , although we consider sequences of transitions by taking the reflexive - transitive closure @xmath426 of the small - step relation , and a top level initialization rule * cev * ( figure  [ fig : cev ] ) .",
    "of course , we need to add typing judgments for the new syntactic categories , namely instructions , continuations and states . these can be found in figure  [ fig : tp ] , whereas we refer the reader to figure  [ fig : dyn - st ] as far as typing of expressions goes .",
    "@xmath427 and @xmath428 and @xmath429 implies @xmath430 .    by induction on the length of the execution path using inversion properties of the typing judgments .",
    "@xmath431 and @xmath432 entails @xmath433 .    as a matter of fact",
    "we could have obtained the same result by showing the _ soundness _ of the operational semantics of the continuation machine big step evaluation , that @xmath431 entails @xmath434 ( see theorem 6.25 in @xcite ) and then appealing to type preservation of the latter .",
    "that would be another interesting case study : the equivalence of the two operational semantics ( thoroughly investigated by pfenning in chapter 6 but in the intuitionistic setting of lf ) , to gauge what the `` olli '' approach would buy us .",
    "@xmath435    \\hspace*{-6em }   \\ibn{\\g\\vd_e e_1\\hastype \\tau'\\imp\\tau }        { \\g\\vd_e e_2\\hastype\\tau ' }        { \\g \\vd _ i\\ir{app}_1\\,e_1\\,e_2 \\hastype \\tau }        { ofi\\_\\ir{app}_1 }   \\mbox{}\\\\[1em].\\dotfill\\\\[1em ] \\prooftree \\mbox{}\\justifies { \\vd_k\\ir{init } \\hastype \\tau\\imp\\tau } \\using{ofk\\_\\ir{init}}\\endprooftree   \\qquad\\qquad \\qquad \\prooftree { x\\oftp\\tau_1\\vd_i i\\hastype \\tau}\\qquad      { \\vd_k k\\hastype\\tau\\imp\\tau_2 } \\justifies      { \\vd_k k;\\ilam{x}{i } \\hastype \\tau_1\\imp\\tau_2 } \\using     { ofk\\_\\ir{cont } } \\endprooftree     \\\\[2em ] .\\dotfill\\\\[1em ]",
    "\\ibnc{\\vd_i i \\hastype \\tau_1 } { \\vd_k k \\hastype \\tau_1\\ \\fsp \\",
    "\\tau_2}{\\vd_s k\\:\\diamond\\ : i \\hastype   \\tau_2}{ofs\\_\\diamond }   \\qquad\\qquad \\ianc{\\vd_e v\\hastype \\tau } { \\vd_s \\ir{answer}\\ , v\\hastype    \\tau}{ofs\\_\\ir{answer } } \\end{array}$}\\ ] ]      we now show how to write the operational semantics of the continuation machine as an olli program , or more precisely as ol clauses . rather than representing",
    "the continuation @xmath421 an explicit stack , we will simply _ store instructions in the ordered context_. this is particularly striking as we map machine states not into ol data , but ol _ provability_. in particular we will use the following representation to encode machine states : @xmath436}{\\mid}\\rep{k}}{\\slat{\\exec { \\rep{i}}}}\\ ] ] where @xmath437 is the representation , described below , of the continuation ( stack ) @xmath421 and @xmath438 the obvious representation of the instruction . for the lighter @xmath439 .",
    "it is likely that the faithfulness of our representation could be obtained following the approach in  @xcite  see in particular theorem @xmath440 .",
    "] in fact , if we retain the usual abbreviation @xmath155 the encoding of instructions can be simply realized with an datatype , whose adequacy is standard : @xmath441    to describe the encoding of continuations , we use our datatype _ atm _ , which describes the atomic formulas of the ol .",
    "this time , it is more interesting and consists of : @xmath442 we have _ atoms _ to describe the initial continuation `` @xmath443 '' of type @xmath444 , the continuation that simply returns its value .",
    "otherwise @xmath421 is an ordered context of atoms `` @xmath445 '' of type @xmath446 .",
    "the top level of evaluation ( @xmath447 ) unfolds to the initial goal @xmath448 ; our program will evaluate the expression @xmath449 and instantiate @xmath450 with the resulting value .",
    "in other words , we evaluate @xmath63 with the initial continuation .",
    "the other instructions are treated as follows : the goal @xmath451 means : pass @xmath233 to the top continuation on the stack ( , the rightmost element in the ordered context ) : the instruction in the goal @xmath452 sequentializes the evaluation of application .",
    "we have the following representations of machine states : @xmath453}{\\mid } [ \\init{w } ] } { \\slat { \\exec{(\\ret { \\rep{v}})}}}\\ ] ] where the logic variable @xmath454 will be instantiated to the final answer ; @xmath455}{\\mid}(\\rep{k } , \\cont { ( \\ilam{x}{\\rep{i } } ) } ) } { \\slat{\\exec{(\\ret { \\rep{v}})}}}\\ ] ] where the ordering constraints force the proof of @xmath456 to focus on the rightmost ordered formula .    @xmath457   \\mathit{inductive}\\ { \\ _ \\if \\ _ { \\mid}\\ _ } & \\hoftype &   \\fsprems{\\atm , \\ilist{\\oo } ,      \\ilist{\\oo}}\\fs \\bool\\\\[0.5em ] & \\implies & { \\of{(e_1\\ \\oat\\ e_2)}{t } \\if { [ \\ ] } { \\mid}[{\\slat{\\of{e_1}{(t'\\fsp t ) } } } , { \\slat{\\of{e_2}{t'}}}]}\\\\ \\prems { \\abstr e } & \\implies & { \\of{(\\llfun x { e\\ x } ) } { ( t_1 \\fsp   t_2 ) } \\if { [ \\ ] } { \\mid}[\\slall { x}\\slimp{(\\of{x}{t_1 } ) } { \\slat{\\of{(e\\   x)}{t_2}}}]}\\\\ \\prems { \\abstr e } & \\implies & { \\of{(\\llrec { e \\ x } ) } { ( t ) } \\if { [ \\ ] } { \\mid}[\\slall { x}\\slimp{(\\of{x}{t } ) }   { \\slat{\\of{(e\\   ( \\llrec { e\\ x})}{t}}}]}\\\\ & \\implies & { \\ofi{(\\ev{e})}{t } \\if { [ \\ ] } { \\mid}[\\slat{\\of{e}{t}}]}\\\\ & \\implies & { \\ofi{(\\ret{v})}{t } \\if { [ \\ ] } { \\mid}[\\slat{\\of{v}{t}}]}\\\\ & \\implies & { \\ofi{(\\appone{v}{e})}{t } \\if { [ \\ ] } { \\mid}[\\slat{\\of{v } { ( t_2\\fsp t ) } } , \\slat{\\of{e}{t_2}}]}\\\\ & \\implies & { \\ofk ( t \\fsp t ) \\if [ \\slat{\\init { v } } ] { \\mid } { [ \\ ] } } \\\\   & \\implies & { \\ofk ( t_1 \\fsp t_2 ) \\if [ { \\slat{\\cont      { k } } } , { \\slat{\\ofk { t\\fsp t_2 } } } ] { \\mid}\\\\ } & & \\qquad\\qquad\\qquad\\qquad\\quad\\ \\ { [ \\slall { x}\\slimp{(\\of{x}{t_1 } ) } { \\slat{\\ofi{(k\\ x)}{t}}}]}\\\\[1em ] & \\implies & { \\ceval { e}{v } \\if [ \\init { v}\\roimp\\exec { ( \\ev { e } ) } ] { \\mid } { [ \\ ] } } \\\\ & \\implies &   { \\exec{(\\ret{v } ) } \\if [ \\slat{\\init { v } } ] { \\mid } { [ \\ ] } } \\\\ \\prems { \\abstr k } & \\implies & { \\exec{(\\ret{v ) } } \\if [ { \\slat{\\cont { k } } } , { \\slat{\\exec{(k\\ v ) } } } ] { \\mid } { [ \\ ] } } \\\\ \\prems { \\abstr e } & \\implies & { \\exec{(\\ev{(\\llfunc { e } ) ) } } \\if [ \\slat{\\exec{(\\ret{(\\llfunc { e } ) } ) } } ] { \\mid } { [ \\ ] } } \\\\ & \\implies &   { \\exec{(\\ev ( e_1\\ \\oat\\ e_2 ) ) } \\if [ \\cont { ( \\lambda v.\\ \\appone{v}{e_2 } ) } \\roimp \\slat{\\exec { ( \\ev{e_1 } ) } } ] { \\mid } { [ \\ ] } } \\\\",
    "\\prems { \\abstr e } & \\implies & { \\exec{(\\appone{(\\llfunc e)}{e_2 } ) } \\if [ \\slat{\\exec { ( \\ev { ( e\\ e_2 ) } ) } } ] { \\mid } { [ \\ ] } }   \\\\[.5ex]\\hline\\end{aligned}\\ ] ]    we can now give the clauses for the ol deductive systems in figure  [ fig : tph ] , starting with typing .",
    "these judgments are intuitionistic , except typing of continuations .",
    "the judgments for expressions and instructions directly encode the corresponding judgments and derivation rules .",
    "the judgments for continuations differ from their analogs in figure  [ fig : tp ] in that there is no explicit continuation to type ; instead , the continuation to be typed is in the ordered context .",
    "thus , these judgments must first get a continuation from the ordered context and then proceed to type it .",
    "the evaluation clauses of the program fully take advantage of ordered contexts .",
    "the first one corresponds to the * cev * rule .",
    "the rest directly mirror the machine transition rules .",
    "a sample derivation is probably in order and so it follows as mc - lemma  [ mcl : silly - ceval ] .",
    "note that as far as examples of evaluations go , this is not far away from total triviality , being the evaluation of something which is already a value .",
    "however , our intention here is not to illustrate the sequentialization of evaluation steps typical of a continuation machine ( for which we refer again to @xcite ) ; rather we aim to emphasize the role of the ordered context , in particular the effect of non - deterministic splitting on the complexity of proof search .",
    "[ mcl : silly - ceval ] @xmath458    after introducing the logic variable @xmath459 ( here we pay no attention to the height of the derivation ) we apply rule * bc * , , backchaining , obtaining the following 3 goals : @xmath460 } { \\mid } { [ \\ ] } } \\\\ 2.\\ \\ \\oslvd { [ \\ ] } { [ \\ ] } { { [ \\init \\ ? v\\roimp\\exec { ( \\ev          { ( \\llfun{x}{x})})}]}}\\\\ 3.\\ \\ \\islvd { [ \\ ] } { [ \\ ] } \\end{array}\\ ] ] goals such as the third one ( the base case of intuitionistic list evaluation ) will always arise when back - chaining on evaluation , as the intuitionistic context plays no role , , it is empty ; since they are trivially true , they will be resolved away without any further mention .",
    "so we have retrieved the body of the relevant clause and passed it to ordered list evaluation :    @xmath461 } } { { [ \\ ] } } { [ \\init \\ ?",
    "v\\roimp\\exec { ( \\ev          { ( \\llfun{x}{x})})}]}\\ ] ] this leads to splitting the ordered context , , @xmath462 } { og } { or}\\\\ 2 . \\ \\ \\slvd { { [ \\ ] } { \\mid}og } { \\init \\ ? v\\roimp\\slat{\\exec { ( \\ev        { ( \\llfun{x}{x } ) } ) } } } \\\\ 3 . \\ \\ \\oslvd { { [ \\ ] } } { or } { { [ \\ ] } } \\end{array}\\ ] ] in this case , ordered splitting is deterministic as it can only match the base case and the two resulting contexts @xmath463 and @xmath464 are both set to empty :    @xmath465}{\\mid } { [ \\ ] } } { \\init \\",
    "? v\\roimp\\slat{\\exec { ( \\ev         { ( \\llfun{x}{x})})}}}\\ ] ] the introduction rule for ordered implication ( and simplification ) puts the goal in the form :    @xmath465}{\\mid}[\\init \\ ?",
    "v ] } { \\slat{\\exec { ( \\ev          { ( \\llfun{x}{x})})}}}\\ ] ] which corresponds to the execution of the identity function with the initial continuation .",
    "another backchain yields :    @xmath466 } { og_{1 } } { or_{1}}\\\\ 3 . \\ \\ \\slvd { { [ \\ ] } { \\mid } { og_{1 } } } { \\slat{\\exec { ( \\ret         { ( \\llfun{x}{x } ) } ) } } }   \\end{array}\\ ] ] as usual ,  takes care of the first goal , while now we encounter the first interesting splitting case . to be able to solve the goal by assumption in the sl , we need to pass the ( singleton ) context to the left context @xmath467 .",
    "one way to achieve this is to gently push the system by proving the simple lemma @xmath468}{[a ] } { { [ \\ ] } } $ ] . using the latter as an introduction rule for subgoal @xmath469",
    ", we get :    @xmath465}{\\mid}[\\init ?",
    "v ] } { } { \\slat{\\exec { ( \\ret         { ( \\llfun{x}{x})})}}}\\ ] ] more backchaining yields :    @xmath461}}{[\\init ?",
    "v ] } [ { \\slat{\\init { ( \\llfun{x}{x})}}}]\\ ] ] and with another similar ordered split to the left we have    @xmath465}{\\mid}[\\init ?",
    "v ] } { \\slat{\\init { ( \\llfun{x}{x})}}}\\ ] ] which is true by the @xmath470 rule .",
    "this concludes the derivation , instantiating @xmath459 with @xmath471 .    if we collect in ` sig_def ` all the definitions pertaining to the signature in question and bundle up in ` olli_intrs ` all the introduction rules for the sequent calculus , ( ordered ) splitting and the program database :    .... fast_tac(claset ( )   addis olli_intrs          ( simpset ( ) addsolver ( abstr_solver sig_defs ) ) ) ; ....    the above tactic will automatically and very quickly prove the above lemma , by backtracking on all the possible ordered splittings , which are , in the present case , preciously few",
    ". however , this will not be the case for practically any other goal evaluation , since splitting is highly non - deterministic in so far as all the possible partitions of the contexts need to be considered . to remedy this ,",
    "we could encode a variant of the _ input - output _ sequent calculus described in  @xcite and further refined in @xcite , which describes efficient resource management  and hence search  in linear logic programming .",
    "then , it would be a matter of showing it equivalent to the base calculus , which may be far from trivial . in the end ,",
    "our system will do fine for its aim , , investigation of the meta - theoretic properties of our case study .",
    "the example may have shed some light about this peculiarity : the operational semantics of the continuation machine is small - step ; a sequence of transitions are connected ( via rules for its reflexive transitive closure ) to compute a value , whereas our implementation looks at first sight big - step , or , at least , shows no sign of transitive closure .",
    "in fact , informally , for every transition that a machine makes from some state @xmath472 to @xmath473 , there is a bijective function that maps the _ derivation _ of @xmath474 , , the sequent encoding @xmath472 to the derivation of @xmath475 .",
    "the interpreter essentially simulates the informal trace of the machine obtained by transitive closure of each step @xmath476 for some @xmath420 with a tree of attempts to establish @xmath477}{\\mid}\\rep k}{\\slat{\\rep i}}$ ] by appropriate usage of the available ordered resources ( the rest of @xmath478 ) . in the above example",
    ", the paper and pencil proof is a tree with * cev * at the root , linked by the * step * rule to the * st_fun * and * st_init * axioms .",
    "this corresponds to the proof we have described , whose skeleton consists of the statement of the lemma as root and ending with the axiom @xmath470 .",
    "@xmath479}{\\mid}[\\init \\ ?",
    "v ] } { \\slat{\\exec { ( \\ev          { ( \\llfun{x}{x})})}}}\\leadsto \\\\ \\qquad \\slvd { { [ \\ ] } { \\mid}[\\init ? v ] } { } { \\slat{\\exec { ( \\ret         { ( \\llfun{x}{x})})}}}\\leadsto \\\\ \\qquad\\qquad \\slvd { { [ \\ ] } { \\mid}[\\init ?",
    "v ] } { \\slat{\\init { ( \\llfun{x}{x } ) } } } \\end{array}\\ ] ]    now we can address the meta - theory , namely the subject reduction theorem :    [ thm : sr ] @xmath480}{\\mid}(\\init{v},\\omega ) \\ } { i}{\\slat{\\exec{i } } }   \\implies}\\\\ & &   \\forall t_1t_2 . \\slvd{}{\\slat { \\ofi{i}{t_1}}}\\longrightarrow \\\\ & &   ( \\slvd { { [ \\ ] } { \\mid}(\\init{v},\\omega ) } { \\slat{\\ofk{(t_1\\fsp t_2 ) } } } ) \\longrightarrow\\slvd{}{\\slat{\\of{v}{t_2}}})\\end{aligned}\\ ] ]    the proof of subject reduction again follows from first principles and does not need any weakening or substitution lemmas .",
    "the proof and proof scripts are considerably more manageable if we first establish some simple facts about typing of various syntax categories and instruct the system to aggressively apply every deterministic splitting , , @xmath481 } } { og } { or};\\,\\ , \\bprems og = { [ \\ ] } ; \\,\\,or = { [ \\ ] } \\eprems \\implies p \\eprems \\implies p\\ ] ] as well as a number of elimination rules stating the impossibility of some inversions such as @xmath482 the human intervention that is required is limited to providing the correct splitting of the ordered hypotheses and selecting the correct instantiations of the heights of sub - derivations in order to apply the ih .",
    "the proof is by complete induction on the height of the derivation of the premise .",
    "the inductive hypothesis is : @xmath483}{\\mid}(\\init v , \\o)}{\\slat{\\exec i } } \\longrightarrow\\\\ \\qquad\\qquad\\forall",
    "t_1\\ t_2.\\\\ \\qquad\\qquad\\qquad \\slvd { { [ \\ ] } } { \\slat{\\ofi i t_1}}\\land\\mbox{}\\\\ \\qquad\\qquad\\qquad\\slvd { ( \\init v , \\o)}{\\slat{\\ofk { t_1\\arrow        t_2}}}\\longrightarrow \\slvd{}{\\slat{\\ofv{v}{t_2 } } } ) \\end{array}\\ ] ] not only we will omit the ih in the following , but we will also gloss over the actual height of the derivations , hoping that the reader will trust to apply the ih correctly .",
    "we remark that in contexts we overload the comma to denote adjoining an element to a list at both ends .",
    "we begin by inverting on @xmath406}{\\mid}(\\init v , \\o)}{\\slat{\\exec i}}$ ] and then on the ` prog ` clauses defining execution , yielding several goals , one for each evaluation clause .",
    "the statement for the case is as follows : @xmath484}{\\mid } { [ \\ ] } } { \\slat{\\ofi { ( \\ret v ' ) } t_1}};\\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init v , \\o)}{\\slat{\\ofk { t_1\\arrow   t_2}}};\\\\",
    "\\qquad\\oslvd { { [ \\ ] } } { ( \\init v , \\o)}{[\\slat{\\exec ( k\\ v')},\\slat{\\cont      k}]}\\eprems\\\\   \\qquad\\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv{v}{t_2 } } } \\end{array}\\ ] ] we start by applying the typing lemma : @xmath485}{\\mid } { [ \\ ] } } { \\slat{\\ofi { ( \\ret v ) } t } } & \\implies & \\slvd{}{\\slat{\\ofi { v } t}}\\end{aligned}\\ ] ] inverting of the derivation of @xmath486}}{\\init v ,   \\o}{[\\slat{\\exec ( k\\ v')},\\slat{\\cont k}]}$ ] yields : @xmath487};\\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}og}{\\slat{\\exec   { k\\ v ' } } } ; \\\\ \\qquad\\slvd { { [ \\ ] } { \\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } \\eprems\\\\ \\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv v { t_2 } } } \\end{array}\\ ] ] now , there is only one viable splitting of the first premise , where @xmath488 } ; \\,\\ ,    og = ( \\init{v } ,   l ) \\eprems \\implies p$ ] , as the impossibility of the first one , entailing @xmath489 , is ruled out by the freeness properties of the encoding of atomic formulas .",
    "this results in @xmath490}{\\mid}(\\init{v } ,   l)}{\\slat{\\exec   { k\\           v ' } } } ; \\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init v , \\o)}{\\slat{\\ofk { t_1\\arrow   t_2}}};\\\\ \\qquad\\slvd { { [ \\ ] } { \\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } ; \\\\ \\qquad\\osplit \\o{l } { [ \\cont k]}\\eprems\\\\ \\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv v { t_2 } } } \\end{array}\\ ] ] we now use the reading of ordered split as `` reversed '' append to force @xmath383 to be the concatenation of @xmath491 and @xmath492 $ ] , denoted here as in the sl logic , @xmath493 : @xmath490}{\\mid}(\\init{v } ,   l)}{\\slat{\\exec   { k\\           v ' } } } ; \\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init v , l , \\cont k)}{\\slat{\\ofk      { t_1\\arrow   t_2}}};\\\\   \\qquad\\slvd { { [ \\ ] } { \\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } \\eprems\\\\ \\qquad \\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv v { t_2 } } } \\end{array}\\ ] ] we now invert on the typing of continuation : @xmath494 } } { { [ \\ ] } } { [ \\slall v { \\ofv v { t_1 } }   \\       \\mathsf{imp}\\   \\slat{\\ofi{(k ' \\ v)}{t } } ] } ; \\\\",
    "\\qquad \\slvd { { [ \\ ] } { \\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } ; \\\\ \\qquad\\oslvd { { [ \\ ] } } { ( \\init v , l,\\cont k)}{[\\slat{\\ofk      { t\\arrow   t_2}},\\slat{\\cont k'}]};\\\\   \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init{v } ,   l)}{\\slat{\\exec   { ( k\\ v ' ) }    } } \\eprems\\\\   \\qquad\\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv v { t_2 } } } \\end{array}\\ ] ] the informal proof would require an application of the substitution lemma",
    ". instead here we use cut to infer : @xmath495}{\\mid } { [ \\ ] } } { \\slat { \\ofi { ( k'\\ v ' ) } t}}\\ ] ] we first have to invert on the hypothetical statement @xmath496 and instantiate @xmath497 with @xmath498 : @xmath490}{\\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } ; \\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init{v } ,   l)}{\\slat{\\exec   { ( k\\           v ' ) } } } ; \\\\    \\qquad\\oslvd { { [ \\ ] } } { ( \\init v , l,\\cont k)}{[\\slat{\\ofk      { t\\arrow   t_2}},\\slat{\\cont k'}]};\\\\   \\qquad\\slvd{[\\ofv { v'}{t_1}]{\\mid } { [ \\ ] } } { \\slat { \\ofi { ( k'\\ v ' ) }      t}}\\eprems\\\\ \\qquad\\implies",
    "\\slvd{}{\\slat{\\ofv v { t_2 } } }   \\end{array}\\ ] ] now one more inversion on @xmath499}}{(\\init v , l , \\cont    k)}{[\\slat{\\ofk { t\\arrow t_2}},\\slat{\\cont k ' } ] } $ ] brings us to split @xmath500}$ ] so that @xmath501 and @xmath502 : @xmath503}{\\mid } { [ \\ ] } } { \\slat{\\ofv { v ' } { t_1 } } } ; \\\\   \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init{v } ,   l)}{\\slat{\\exec   { ( k'\\ v ' ) }     } } ;",
    "\\\\    \\qquad\\slvd { { [ \\ ] } { \\mid } { [ \\ ] } } { \\slat { \\ofi { ( k'\\ v ' ) } t}};\\\\ \\qquad\\slvd { { [ \\ ] } { \\mid}(\\init v , l)}{\\slat{\\ofk      { t\\arrow   t_2}}}\\eprems\\\\   \\qquad \\qquad\\qquad\\implies \\slvd{}{\\slat{\\ofv v { t_2 } } }   \\end{array}\\ ] ] this final sequent follows from complete induction for height @xmath67 .    @xmath504",
    "there is nowadays extensive literature on approaches to representing and reasoning about what we have called `` object logics , '' where the notion of variable bindings is paramount .",
    "these approaches are supported by implementations in the form of proof checkers , proof assistants and theorem provers .",
    "we will compare our approach to others according to two categories : whether the system uses different levels for different forms of reasoning and whether it is relational ( , related to proof search ) or functional ( based on evaluation ) .",
    "our work started as a way of porting most of the ideas of @xmath7  @xcite into the mainstream of current proof assistants , so that they can enjoy the facilities and support that such assistants provide .",
    "as mentioned in the introduction , or coq plays the role of @xmath7 , the introduction / elimination rules of inductive definitions ( types ) simulate the _ defr _ and _ defl _ rules of pids and the meta - language provides @xmath7 s @xmath0-calculus . in addition , our approach went beyond @xmath7 , featuring meta - level induction and co - induction , which were later proved consistent with the theory of ( partial ) inductive definitions  @xcite .",
    "these features are now standard in @xmath7 s successor , _ linc _  @xcite .",
    "one of the more crucial advances given by _",
    "linc_-like logic lies in the treatment of induction over _ open _ terms , offered by the proof - theory of @xcite .",
    "the latter has been recently modified  @xcite to simplify the theory of @xmath9-quantification by removing local contexts of @xmath9-bounded variables so as to enjoy properties closer to the _ fresh _ quantifier of nominal logic , such as strengthening and permutation ( see later in this section ) .",
    "finally the @xmath505 logic @xcite brings fully together pids and @xmath9-quantification by allowing the latter to occur in the head of definitions .",
    "this gives excellent new expressive power , allowing for example to _ define _ the notion of freshness .",
    "furthermore it eases induction over open terms and even gives a logical reading to the notion of `` regular worlds '' that are crucial in the meta - theory of twelf .",
    "recently , _",
    "linc_-like meta - logics and the two - level approach have received a new implementation from first principles .",
    "firstly , _ bedwyr _",
    "@xcite is a model - checker of higher - order specifications , based on a logic programming interpretation of @xmath9-quantification and case analysis .",
    "coinductive reasoning is achieved via _ tabling _ , although no formal justification of the latter is given .",
    "typical applications are in process calculi , such as bisimilarity in @xmath1-calculus .",
    "the already cited _ abella _",
    "@xcite is emerging a real contender in this category : it implements a large part of the @xmath505 logic and sports a significant library of theories , including an elegant proof of the poplmark challenge @xcite as well as a proof of strong normalization by logical relations @xcite , an issue which has been contentious in the theorem proving world .",
    "this proof is based on a notion of arbitrarily cascading substitutions , which shares with nominal logic encodings the problem that once nominal constants have been introduced , the user often needs to spend some effort controlling their spread .",
    "in fact , there is currently some need to control occurrences of names in terms and thus to rely on `` technical '' lemmas that have no counterpart in the informal proof .",
    "this is not a problem of the prover itself , but it is induced by the nominal flavor that logics such as linc s successors lg@xmath506 and @xmath505 have introduced .",
    "more details can be found in  @xcite .",
    "the so far more established competitor in the two - level relational approach is _ twelf _  @xcite . here",
    ", the lf type theory is used to encode ols as judgments and to specify meta - theorems as relations ( type families ) among them ; a logic programming - like interpretation provides an operational semantics to those relations , so that an external check for totality ( incorporating termination , well - modedness , coverage  @xcite ) verifies that the given relation is indeed a realizer for that theorem . in this sense",
    "the twelf totality checker can be seen to work at a different level than the ol specifications .",
    "hickey  @xcite built a theory for two - level reasoning within the metaprl system , based on reflection .",
    "a hoas representation is used at the level of reflected terms .",
    "a computationally equivalent de bruijn representation is also defined .",
    "principles of induction are automatically generated for a reflected theory , but it is stated that they are difficult to use interactively because of their size .",
    "in fact , there is little experience using the system for reasoning about ols .",
    "there exists a second approach to reasoning in lf that is built on the idea of devising an explicit ( meta-)meta - logic for reasoning ( inductively ) about the framework , in a fully automated way  @xcite .",
    "@xmath507 can be seen as a constructive first - order inductive type theory , whose quantifiers range over possibly open lf objects over a signature . in this calculus",
    "it is possible to express and inductively prove meta - logical properties of an ol . by",
    "the adequacy of the encoding , the proof of the existence of the appropriate lf object(s ) guarantees the proof of the corresponding object - level property .",
    "@xmath507 can be also seen as a dependently - typed functional programming language , and as such it has been refined first into the _ elphin _",
    "programming language  @xcite and finally in _ delphin _ @xcite . @xmath508",
    "@xcite is an instantiation of xi s _ applied type systems _ combining programming with proofs and can be used as a logical framework . in a similar vein the contextual modal logic of pientka , pfenning and naneski",
    "@xcite provides a basis for a different foundation for programming with hoas based on hereditary substitutions .",
    "this has been explicitly formulated as the programming language _ beluga _  @xcite . because all of these systems are programming languages , we refrain from a deeper discussion .",
    "see  @xcite for a comparison of twelf , beluga , and on some benchmark examples .",
    "modal @xmath0-calculi were formulated in the early attempts by schrmann , despeyroux , and pfenning @xcite to develop a calculus that allows the combination of hoas with a primitive recursion principle in the _ same _ framework , while preserving the adequacy of representations . for every type @xmath256",
    "there is a type @xmath509 of _ closed _ objects of type @xmath256 .",
    "in addition to the regular function type @xmath510 , there is a more restricted type @xmath511 of `` parametric '' functions .",
    "functions used as arguments for higher - order constructors are of this kind and thus roughly correspond to our notion of abstraction .",
    "the dependently - typed case is considered in  @xcite but the approach seems to have been abandoned in view of @xcite .",
    "washburn and weirich  @xcite show how standard first - class polymorphism can be used instead of a special modal operator to restrict the function space to `` parametric '' functions .",
    "they encode and reason about higher - order iteration operators .",
    "we have mentioned earlier the work by gordon and melham  @xcite , which we used as a starting point for .",
    "building on this work , norrish improves the recursion principles  @xcite , allowing greater flexibility in defining recursive functions on this syntax .      _",
    "_ weak _ _ higher - order abstract syntax  @xcite is an approach that strives to co - exist with an inductive setting , where the positivity condition for datatypes and hypothetical judgments must be obeyed . in weak hoas , the problem of negative occurrences in datatypes is handled by replacing them with a new type .",
    "for example , the @xmath3 constructor for mini - ml introduced in section  [ using ] has type @xmath512 , where @xmath39 is a type of variables , isomorphic to natural numbers . _",
    "validity _ predicates are required to weed out exotic terms , stemming from case analysis on the @xmath39 type , which at times is inconvenient .",
    "the approach is extended to hypothetical judgments by introducing distinct predicates for the negative occurrences .",
    "some axioms are needed to reason about hypothetical judgments , to mimic what is inferred by the cut rule in our architecture .",
    "framework  @xcite embraces an _ axiomatic _ approach to meta - reasoning with weak in an inductive setting .",
    "it has been used within coq , extended with a `` theory of contexts '' ( toc ) , which includes a set of axioms parametric to an  signature .",
    "the theory includes the reification of key properties of names akin to _ freshness_. exotic terms are avoided by taking the @xmath39 to be a parameter and assuming axiomatically the relevant properties .",
    "furthermore , higher - order induction and recursion schemata on expressions are also assumed .",
    "to date , the consistency with respect to a categorical semantics has been investigated for higher - order logic  @xcite , rather than a ( co)inductive dependent type theory such as the one underlying coq  @xcite .    from our perspective",
    ", toc can be seen as a stepping stone towards gabbay and pitts _ nominal logic _ , which aims to be a foundation of programming and reasoning with _",
    "names _ , in a one - level architecture .",
    "this framework started as a variant of the frankel - mostowski set theory based on permutations  @xcite , but it is now presented as a first - order theory  @xcite , which includes primitives for variable renaming and variable freshness , and a ( derived ) new `` freshness '' quantifier .",
    "using this theory , it is possible to prove properties by structural induction and also to define functions by recursion over syntax  @xcite .",
    "the proof - theory of nominal logic has been thoroughly investigated in  @xcite , and the latter also investigates the proof - theoretical relationships between the @xmath9 and the `` freshness '' quantifier , by providing a translation of the former to the latter .",
    "gabbay has tried to implement nominal sets on top of isabelle  @xcite .",
    "a better approach has turned out to be urban s ; namely to engineer a _ nominal datatype package _ inside",
    "isabelle / hol  @xcite analogous to the standard datatype package but defining equivalence classes of term constructors . in more recent versions ,",
    "principles of primitive recursion and strong induction have been added  @xcite and many case studies tackled successfully , such as proofs by logical relations ( see  @xcite for more examples ) .",
    "the approach has also been compared in detail with de bruijn syntax  @xcite and in hindsight owes to mckinna and pollack s `` nameless '' syntax  @xcite .",
    "nominal logic is beginning to make its way into coq ; see  @xcite .",
    "it is fair to say that while urban s nominal package allows the implementation of informal proofs obeying the barendregt convention almost literally , a certain number of lemmas that the convention conveniently hides must still be proved the judgment involved ; for example to choose a _ fresh _ atom for an object @xmath74 , one has to show that @xmath74 has _ finite support _ , which may be tricky for @xmath74 of functional type , notwithstanding the aid of general tactics implemented in the package .",
    "hoas , instead , aims to make @xmath5-conversion disappear and tries to extract the abstract higher - order nature of calculi and proofs thereof , rather than follow line - by - line the informal development . on the other hand , it would be interesting to look at versions of the freshness quantifier at the sl level , especially for those applications where the behavior of the ol binder is not faithfully mirrored by hoas , namely with the traditional universal quantification at the sl - level ; well known examples of this case include ( mis)match in the @xmath1-calculus and closure - conversion in functional programming .",
    "chlipala  @xcite recently introduced an alternate axiomatic approach to reasoning with weak hoas .",
    "object - level terms are identified as meta - terms belonging to an inductive type family , where the type of terms is parameterized by the type of variables .",
    "exotic terms are ruled out by parametricity properties of these polymorphic types .",
    "clever encodings of ols are achieved by instantiating these type variables in different ways , allowing data to be recorded inside object - level variables ( a technique borrowed from  @xcite ) .",
    "example proofs developed with this technique include type preservation and semantic preservation of program transformations on functional programming languages .",
    "some of our own related work has involved alternative versions of as well as improvements to , which we describe here .",
    "[ [ constructive- . ] ] constructive .",
    "+ + + + + + + + + + + + + +    a _ constructive _ version of implemented in coq  @xcite provides an alternative that could also serve as the basis for a two - level architecture .",
    "this version provides a new approach to defining induction and non - dependent recursion principles aimed at simplifying reasoning about ols .",
    "in contrast to  @xcite , where built - in primitives are provided for the reduction equations for the higher - order case , the recursion principle is defined on top of the base de bruijn encoding , and the reduction equations proved as lemmas .    in order to define induction and recursion principles for particular ols , terms of type @xmath513 are paired with proofs showing that they are in a form that can represent an object - level term . a dependent type is used to store such pairs ; here we omit the details and just call it @xmath514 , and sometimes oversimplify and equate @xmath514 with @xmath513 . for terms of mini - ml for example , in addition to free variables and bound variables , terms of the forms @xmath515 , @xmath516 and @xmath517 , which correspond to the bodies of the definitions of @xmath518 , @xmath3 , and @xmath157 , are the only ones that can be paired with such a proof .",
    "analogues of the definitions for constructing object - level terms of type @xmath513 are defined for type @xmath514 .",
    "for example , @xmath519 is defined to be the dependent term whose first component is an application ( using @xmath518 ) formed from the first components of @xmath520 and @xmath521 , and whose second component is formed from the proof components of @xmath520 and @xmath521 .    instead of defining a general operator , a version of that does not rely on classical constructs",
    "is defined for each ol .",
    "roughly , @xmath522 is obtained by applying @xmath63 to a _ new _",
    "free variable and then replacing it with de bruijn index @xmath64 .",
    "a new variable for a term @xmath63 of type @xmath97 is defined by adding @xmath523 to the maximum index in subterms of the form @xmath524 in @xmath525 .",
    "note that terms that do not satisfy may have a different set of free variables for every argument , but for those which do satisfy , choosing @xmath526 as the argument to which @xmath63 is applied does give an authentic free variable .",
    "replacing free variable @xmath527 in @xmath528 with @xmath526 involves defining a substitution operator that increases bound indices as appropriate as it descends through operators .",
    "this description of is informal and hides the fact that these definitions are actually given on dependent pairs , , @xmath63 has type @xmath529 .",
    "thus , the definition of depends on the ol because @xmath514 is defined for each ol .",
    "induction and recursion are also defined directly on type @xmath514 . to obtain a recursion principle ,",
    "it is shown that for any type @xmath31 , a function @xmath530 of type @xmath531 can be defined by specifying its results on each `` constructor '' of the ol .",
    "for example , for the @xmath518 and @xmath3 cases of mini - ml , defining @xmath530 involves defining @xmath532 and @xmath533 of the following types : @xmath534 and then the following reduction equations hold .",
    "@xmath535 in these equations we oversimplify , showing functions @xmath530 , @xmath532 , and @xmath533 applied to terms of type @xmath513 ; in the actual equations , proofs paired with terms on the left are used to build proofs of terms appearing on the right .",
    "the function in the equation for @xmath3 uses another substitution operator to obtain a `` canonical form , '' computed by replacing de bruijn index @xmath64 in @xmath536 with @xmath74 .",
    "this function is the identity function on terms that satisfy .",
    "another version of constructive  @xcite in coq has been proposed , in which theorems such as induction and recursion principles are proved once at a general level , and then can be applied directly to each ol .",
    "an ol is specified by a _ signature _ , which can include sets of sorts , operation names , and even built - in typing rules .",
    "a signature specifies the binding structure of the operators , and the recursion and induction principles are formulated directly on the higher - order syntax .    [",
    "[ pa : ho2 ] ] @xmath537 .",
    "+ + + + + + + + + + + + + + + + + +    during the write - up of this report , the infrastructure of has developed significantly , thanks to the work by alan martin ( see @xcite ) , so that we informally talk of @xmath537 . because those changes have been recent and only relatively influence the two - level approach , we have decided not to update the whole paper , but mention here the relevant differences .",
    "the main improvement concerns an overall reorganization of the infrastructure described in section  [ sec : introh ] , based on the internalization as a type of the set of _ proper _ terms . using s _ typedef _ mechanism ,",
    "the type @xmath104 is defined as a _ bijective image _ of the set @xmath538 , with inverse bijections @xmath539 and @xmath540 . in effect , _ typedef _ makes @xmath104 a subtype of @xmath58 , but since s type system does not have subtyping , the conversion function must be explicit .",
    "now that ol terms can only be well - formed de bruijn terms , we can replace the _",
    "proper_abst _ property ( mc - lemma  [ mclem : proper_abst ] ) with the new lemma    @xmath541    from the standpoint of two - level reasoning this lemma allows us to dispose of all assumptions : in particular the sl universal quantification has type @xmath542 and the relative sl clause ( figure  [ fig : nseq ] ) becomes : @xmath543 therefore , in the proof of mc - lemma  [ le : sl - ex ] no assumptions are generated .",
    "the proof of ol subject reduction ( mc - theorem  [ mcthm : olsr ] ) does not need to appeal to property  ( [ eq : ol - prop ] ) or , more importantly , to part 1 of mc - lemma  [ mclem : evalproper ] . while this is helpful , it does not eliminate the need for adding well - formedness annotations in ol judgments for the sake of establishing adequacy of the encoding .",
    "further , a structural definition of abstraction allows us to state the crucial quasi - injectivity property of the binder @xmath33 , strengthening mc - theorem  [ thm : inj ] by requiring only one of @xmath63 and  @xmath61 to satisfy this condition ( instead of both ) , thus simplifying the elimination rules for inductively defined ol judgments :    @xmath544    the new definition allows us to drop for plain simplification , and the same applies , to .",
    "a significant case study using this infrastructure has being tackled by alan martin @xcite and consists of an investigation of the meta - theory of a functional programming language with references using a variety of approaches , culminating with the usage of a linearly ordered sl .",
    "this study extends the work in section  [ sec : olli ] and  @xcite , as well as offering a different encoding of mini - ml with references than the one analyzed with a linear logical framework  @xcite .",
    "martin s forthcoming doctoral thesis  @xcite also illustrates that it is possible to use alternate techniques for induction at the sl level . instead of natural number induction ,",
    "some proofs of the case study are carried out by structural induction on the definition of the sl . in these proofs",
    ", it was necessary to strengthen the desired properties to properties of arbitrary sequents , and to define specialized weakening operators for contexts along with lemmas supporting reasoning in such contexts .",
    "it is not clear how well this technique generalizes ; this is the subject of future work . in another technique ,",
    "natural numbers are replaced by ordinals in the definition of the sl , and natural number induction is replaced by transfinite induction .",
    "this technique is quite general and simplifies proofs by induction that involve relating the proof height of one derivation in the sl to one or more others .",
    "[ [ induction - over - open - terms ] ] induction over open terms + + + + + + + + + + + + + + + + + + + + + + + + +    in this paper s examples , proofs by induction over derivations were always on closed judgment such as evaluation , be it encoded as a direct inductive definition at the meta - level or as clauses used by the sl . in both cases ,",
    "this judgment was encoded without the use of hypothetical and parametric judgments , and thus induction was over _ closed _ terms , although we essentially used case analysis on open terms .",
    "inducting over open terms and hypothetical judgments is a challenge that has required major theoretical work  @xcite .",
    "statements have to be generalized to non - empty contexts , and these contexts have to be of a certain form , which must enforce the property in question . in  @xcite",
    "we showed how to accomplish this in with only a surprisingly minimal amount of additional infrastructure : we can use the @xmath545 constructor to encode free variables of ols , and simply add a definition ( ) that provides the capability of creating a variable which is _ fresh _ , in particular w.r.t .  a context .",
    "we express the induction hypothesis as a `` context invariant , '' which is a property that must be preserved when adding a fresh variable to the context .",
    "the general infrastructure we build is designed so that it is straightforward to express context invariants and prove that they are preserved when adding a fresh variable .",
    "very little overhead is required , namely a small library of simple lemmas , where no reasoning about substitution or @xmath5-conversion is needed as in first - order approaches .",
    "yet the reasoning power of the system and the class of properties that can be proved is significantly increased .",
    "we have presented a multi - level architecture that allows reasoning about objects encoded using hoas in well - known systems such as and coq that implement well - understood logics .",
    "the support for reasoning includes induction and co - induction as well as various forms of automation available in such systems such as tactical - style reasoning and decision procedures .",
    "we have presented several examples of its use , including an arguably innovative case study .",
    "as we have demonstrated , there are a variety of advantages of this kind of approach :    * it is possible to replicate in a well - understood and interactive setting the style of proof used in systems such as @xmath8 designed specially for reasoning using higher - order encodings .",
    "the reasoning can be done in such a way that theorems such as subject reduction proofs are proven without `` technical '' lemmas foreign to the mathematics of the problem . *",
    "results about the intermediate layer of specification logics , such as cut elimination , are proven once and for all ; in fact it is possible to work with different specification logics without changing the infrastructure . *",
    "it is possible to use this architecture as a way of `` fast prototyping '' hoas logical frameworks since we can quickly implement and experiment with a potentially interesting sl , rather than building a new system from scratch .    since our architecture",
    "is based on a very small set of theories that definitionally builds an hoas meta - language on top of a standard proof - assistant , this allows us to do without any axiomatic assumptions , in particular freeness of hoas constructors and extensionality properties at higher - order types , which in our setting are now theorems .",
    "furthermore , we have shown that mixing of meta - level and ol specifications make proofs more easily mechanizable .",
    "finally , by the simple reason that the system sits on top of or coq , we benefit from the higher degree of automation of the latter .    some of our current and future work will concentrate on the practical side , such as continuing the development and the testing of the new infrastructure to which we have referred as @xmath537 ( see section  [ pa : ho2 ] and @xcite ) , especially to exploit the new features offered by 2010 .",
    "further , we envisage developing a package similar in spirit to urban s nominal datatype package for @xcite . for , such a package would automatically supply a variety of support from a user specification of an ol , such as validity predicates like , a series of theorems expressing freeness of the constructors of such a type including injectivity and clash theorems , and an induction principle on the shape of expressions analogous to mc - theorem  [ thm : proper - induct ] .",
    "to work at two levels , such a package would include a number of pre - compiled sls ( including cut - elimination proofs and other properties ) as well as some lightweight tactics to help with two - level inference .",
    "ideally , the output of the package could be in itself generated by a tool such as _ ott _",
    "( @xcite ) so as to exploit the tool s capabilities of supporting work on large programming language definitions , where `` the scale makes it hard to keep a definition internally consistent , and hard to keep a tight correspondence between a definition and implementations '' , .",
    "we clearly need to explore how general our techniques for induction over open terms @xcite are , both by attempting other typical case studies such as the poplmark challenge or the church - rosser theorem , as well as analyzing the relationship with theoretical counterpart such as the regular world assumptions and context invariants in abella .",
    "this may also have the benefit of a better understanding and `` popularization '' of proofs in those less known frameworks .",
    "in twelf , in particular , much of the work in constructing proofs is currently handled by an external check for properties such as termination and coverage  @xcite .",
    "we are investigating as the target of a sort of `` compilation '' of such proofs into the well - understood higher - order logic of .",
    "more in - depth comparisons with nominal logic ideas such as freshness and the gabbay - pitts quantifier are also in order . in fact , any concrete representation of bound variables does not fit well with hoas , where the former have no independent identities .",
    "however , there are relevant applications ( , mismatch in the @xmath1-calculus , see @xcite for other examples ) where names of bound variables do matter .",
    "most of the material in this paper is based on previous joint work with simon ambler and roy crole  @xcite , jeff polakow  @xcite and venanzio capretta  @xcite , whose contributions we gratefully acknowledge .",
    "the paper has also benefited from discussions with andy gordon , alan martin , marino miculan , dale miller , brigitte pientka , randy pollack , frank pfenning and carsten schrman .",
    "we thank the anonymous reviewers for many useful suggestions .",
    "s.  j. ambler , r.  l. crole , and alberto momigliano .",
    "a definitional approach to primitive recursion over higher order abstract syntax . in _",
    "mer@xmath0 in 03 : proceedings of the 2003 acm sigplan workshop on mechanized reasoning about languages with variable binding _ , pages 111 , new york , ny , usa , 2003 .",
    "acm press .",
    "brian  e. aydemir , aaron bohannon , matthew fairbairn , j.  nathan foster , benjamin  c. pierce , peter sewell , dimitrios vytiniotis , geoffrey washburn , stephanie weirich , and steve zdancewic .",
    "mechanized metatheory for the masses : the poplmark challenge . in joe hurd and t.",
    "melham , editors , _ theorem proving in higher order logics , 18th international conference _ , lecture notes in computer science , pages 5065 .",
    "springer , 2005 .",
    "david baelde , andrew gacek , dale miller , gopalan nadathur , and alwen tiu .",
    "the bedwyr system for model checking over syntactic expressions . in frank pfenning ,",
    "editor , _ cade _ , volume 4603 of _ lecture notes in computer science _",
    ", pages 391397 .",
    "springer , 2007 .",
    "stefan berghofer and tobias nipkow .",
    "proof terms for simply typed higher order logic . in j.",
    "harrison and m.  aagaard , editors , _ theorem proving in higher order logics _",
    ", volume 1869 of _ lncs _ , pages 3852 .",
    "springer , 2000 .",
    "k.  a. bowen and r.  a. kowalski .",
    "amalgamating language and metalanguage in logic programming . in k.",
    "l. clark and s.  a. tarnlund , editors , _ logic programming , vol 16 of apic studies in data processing _ , pages 153172 . academic press , 1982 .",
    "venanzio capretta and amy  p. felty .",
    "combining de bruijn indices and higher - order abstract syntax in coq . in thorsten altenkirch and conor",
    "mcbride , editors , _ types _ , volume 4502 of _ lecture notes in computer science _ , pages 6377 .",
    "springer , 2006 .",
    "d.  clement , j.  despeyroux , t.  despeyroux , and g.  kahn . a simple applicative language : mini - ml . in _ proceedings of the 1986 acm conference on lisp and functional programming _ , pages 1327 .",
    "acm , acm , august 1986 .",
    "karl crary and susmit sarkar .",
    "foundational certified code in a metalogical framework .",
    "in franz baader , editor , _ cade _ , volume 2741 of _ lecture notes in computer science _ , pages 106120 .",
    "springer , 2003 .",
    "sa  cui , kevin donnelly , and hongwei xi . : a language that combines programming with theorem proving . in bernhard gramlich , editor , _",
    "frocos _ , volume 3717 of _ lecture notes in computer science _ , pages 310320 .",
    "springer , 2005 .",
    "olivier danvy , belmina dzafic , and frank pfenning . on proving syntactic properties of cps programs .",
    "in andrew gordon and andrew pitts , editors , _ proceedings of hoots99 _ , paris , september 1999 .",
    "electronic notes in theoretical computer science , volume 26 .",
    "jolle despeyroux , amy felty , and andr hirschowitz .",
    "higher - order abstract syntax in coq . in _",
    "second international conference on typed lambda calculi and applications _ , pages 124138 .",
    "springer , _ lecture notes in computer science _ , april 1995 .",
    "lars - henrik eriksson .",
    "pi : an interactive derivation editor for the calculus of partial inductive definitions . in alan bundy , editor , _ cade _ , volume 814 of _ lecture notes in computer science _ , pages 821825 .",
    "springer , 1994 .",
    "amy felty and brigitte pientka .",
    "reasoning with higher - order abstract syntax and contexts : a comparison . in m.",
    "kaufmann and l.  paulson , editors , _ international conference on interactive theorem proving _ , volume 6172 of _ lecture notes in computer science _ , pages 228243 .",
    "springer , 2010 .",
    "andrew gacek .",
    "the abella interactive theorem prover ( system description ) . in alessandro armando ,",
    "peter baumgartner , and gilles dowek , editors , _ ijcar _ , volume 5195 of _ lecture notes in computer science _ ,",
    "pages 154161 .",
    "springer , 2008 .",
    "guillaume gillard .",
    "a formalization of a concurrent object calculus up to @xmath5-conversion . in david",
    "a. mcallester , editor , _ cade _ , volume 1831 of _ lecture notes in computer science _ , pages 417432 .",
    "springer , 2000 .",
    "andrew gordon .",
    "a mechanisation of name - carrying syntax up to @xmath5-conversion . in j.j .",
    "joyce and c .- j.h .",
    "seger , editors , _ international workshop on higher order logic theorem proving and its applications _ , volume 780 of _ lecture notes in computer science _ , pages 414427 , vancouver , canada , august 1994 .",
    "university of british columbia , springer .",
    "andrew  d. gordon and tom melham .",
    "five axioms of @xmath5-conversion . in j.",
    "von wright , j.  grundy , and j.  harrison , editors , _ proceedings of the 9th international conference on theorem proving in higher order logics ( tphols96 ) _ , pages 173191 , turku , finland , august 1996 .",
    "springer - verlag lncs 1125 .",
    "p.  m. hill and j.  gallagher .",
    "meta - programming in logic programming . in dov gabbay , christopher  j. hogger , and j.  a. robinson , editors , _ handbook of logic in artificial intelligence and logic programming , volume 5 : logic programming _ , pages 421498 .",
    "oxford university press , oxford , 1998 .",
    "furio honsell , marino miculan , and ivan scagnetto .",
    "an axiomatic approach to metareasoning on nominal algebras in hoas . in fernando",
    "orejas , paul  g. spirakis , and jan van leeuwen , editors , _ icalp _ , volume 2076 of _ lecture notes in computer science _ , pages 963978 .",
    "springer , 2001 .",
    "daniel  k. lee , karl crary , and robert harper . towards a mechanized metatheory of standard ml . in _",
    "popl 07 : proceedings of the 34th annual acm sigplan - sigact symposium on principles of programming languages _ , pages 173184 , new york , ny , usa , 2007 .",
    "acm press .",
    "alan  j. martin .",
    "case study : subject reduction for mini - ml with references , in isabelle / hol + hybrid .",
    "workshop on mechanizing metatheory , link :    www.cis.upenn.edu/~sweirich/wmm/wmm08/martin.pdf [    www.cis.upenn.edu/~sweirich/wmm/wmm08/martin.pdf ] , retrieved 1/7/2010 , september 2008 .",
    "dale miller .",
    "overview of linear logic programming . in thomas ehrhard , jean - yves girard , paul ruet , and phil scott , editors , _ linear logic in computer science _",
    ", volume 316 of _ london mathematical society lecture note _ , pages 119150 . cambridge university press , 2004 .",
    "alberto momigliano , simon ambler , and roy crole .",
    "a comparison of formalisations of the meta - theory of a language with variable binding in isabelle . in r.",
    "j. boulton and p.  jackson , editors , _ 14th international conference on theorem proving in higher order logics ( tphols01 ) , supplemental proceedings _ , pages 267282 .",
    "informatics research report edi - inf - rr-01 - 23 , 2001 .",
    "michael norrish .",
    "recursive function definition for types with binders . in _",
    "seventeenth international conference on theorem proving in higher order logics _ ,",
    "pages 241256 .",
    "springer - verlag lecture notes in computer science , 2004 .",
    "owre , j.  m. rushby , and n. shankar . prototype verification system . in deepak kapur , editor , _ proceedings of the 11th international conference on automated deduction _ ,",
    "pages 748752 .",
    "springer - verlag lnai 607 , 1992 .",
    "christine paulin - mohring .",
    "inductive definitions in the system coq : rules and properties . in m.",
    "bezem and j.  f. groote , editors , _ proceedings of the international conference on typed lambda calculi and applications _ , pages 328345 ,",
    "utrecht , the netherlands , march 1993 .",
    "springer - verlag lncs 664 .",
    "lawrence  c. paulson .",
    "a fixedpoint approach to implementing ( co)inductive definitions . in alan bundy , editor , _ proceedings of the 12th international conference on automated deduction _ , pages 148161 , nancy , france , june 1994 .",
    "springer - verlag lnai 814 .",
    "brigitte pientka .",
    "beluga : programming with dependent types , contextual data , and contexts . in matthias blume ,",
    "naoki kobayashi , and germn vidal , editors , _ flops _ , volume 6009 of _ lecture notes in computer science _ , pages 112 .",
    "springer , 2010 .",
    "jeff polakow and frank pfenning .",
    "relating natural deduction and sequent calculus for intuitionistic non - commutative linear logic . in andre scedrov and achim jung ,",
    "editors , _ proceedings of the 15th conference on mathematical foundations of programming semantics _ , new orleans , louisiana , april 1999 . .",
    "jeff polakow and frank pfenning .",
    "properties of terms in continuation - passing style in an ordered logical framework . in jolle despeyroux ,",
    "2nd workshop on logical frameworks and meta - languages ( lfm00 ) _ , santa barbara , california , june 2000 .",
    "proceedings available as inria technical report .",
    "jeff polakow and kwangkeun yi . proving syntactic properties of exceptions in an ordered logical framework . in herbert kuchen and kazunori ueda , editors ,",
    "_ proceedings of the 5th international symposium on functional and logic programming ( flops01 ) _ , pages 6177 , tokyo , japan , march 2001 .",
    "springer - verlag lncs 2024 .",
    "adam poswolsky and carsten schrmann .",
    "practical programming with higher - order encodings and dependent types . in sophia",
    "drossopoulou , editor , _ esop _ , volume 4960 of _ lecture notes in computer science _ , pages 93107 .",
    "springer , 2008 .",
    "carsten schrmann .",
    "the twelf proof assistant . in stefan berghofer ,",
    "tobias nipkow , christian urban , and makarius wenzel , editors , _ tphols _ , volume 5674 of _ lecture notes in computer science _ , pages 7983 .",
    "springer , 2009 .",
    "carsten schrmann and frank pfenning .",
    "a coverage checking algorithm for lf . in david  a. basin and burkhart wolff , editors , _ tphols _ , volume 2758 of _ lecture notes in computer science _ , pages 120135 .",
    "springer , 2003 .",
    "carsten schrmann , adam poswolsky , and jeffrey sarnat .",
    "the @xmath548-calculus .",
    "functional programming with higher - order encodings . in _",
    "seventh international conference on typed lambda calculi and applications _ , pages 339353 .",
    "springer , _ lecture notes in computer science _ , april 2005 .",
    "peter sewell , francesco  zappa nardelli , scott owens , gilles peskine , tom ridge , susmit sarkar , and rok strnisa .",
    "ott : effective tool support for the working semanticist .",
    "in ralf hinze and norman ramsey , editors , _ icfp 2007 _ , pages 112 .",
    "acm , 2007 .",
    "christian urban and stefan berghofer . a recursion combinator for nominal datatypes implemented in isabelle / hol . in ulrich furbach and natarajan shankar , editors , _",
    "ijcar _ , volume 4130 of _ lecture notes in computer science _ , pages 498512 .",
    "springer , 2006 .",
    "christian urban and christine tasson .",
    "nominal techniques in isabelle / hol . in r.",
    "nieuwenhuis , editor , _ proceedings of the 20th international conference on automated deduction ( cade ) _ , volume 3632 of _ lncs _ , pages 3853 .",
    "springer , 2005 ."
  ],
  "abstract_text": [
    "<S> combining higher - order abstract syntax and ( co)-induction in a logical framework is well known to be problematic . </S>",
    "<S> we describe the theory and the practice of a tool called , within and coq , which aims to address many of these difficulties . </S>",
    "<S> it allows object logics to be represented using higher - order abstract syntax , and reasoned about using tactical theorem proving and principles of ( co)induction . </S>",
    "<S> moreover , it is definitional , which guarantees consistency within a classical type theory . </S>",
    "<S> the idea is to have a de bruijn representation of @xmath0-terms providing a definitional layer that allows the user to represent object languages using higher - order abstract syntax , while offering tools for reasoning about them at the higher level . in this paper </S>",
    "<S> we describe how to use in a multi - level reasoning fashion , similar in spirit to other systems such as _ twelf _ and _ </S>",
    "<S> abella_. by explicitly referencing provability in a middle layer called a specification logic , we solve the problem of reasoning by ( co)induction in the presence of non - stratifiable hypothetical judgments , which allow very elegant and succinct specifications of object logic inference rules . </S>",
    "<S> we first demonstrate the method on a simple example , formally proving type soundness ( subject reduction ) for a fragment of a pure functional language , using a minimal intuitionistic logic as the specification logic . </S>",
    "<S> we then prove an analogous result for a continuation - machine presentation of the operational semantics of the same language , encoded this time in an ordered linear logic that serves as the specification layer . </S>",
    "<S> this example demonstrates the ease with which we can incorporate new specification logics , and also illustrates a significantly more complex object logic whose encoding is elegantly expressed using features of the new specification logic . </S>"
  ]
}