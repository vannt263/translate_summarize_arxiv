{
  "article_text": [
    "optimization for multiple conflicting objectives results in more than one optimal solutions ( known as pareto - optimal solutions ) .",
    "although one of these solutions is to be chosen at the end , the recent trend in evolutionary and classical multi - objective optimization studies have focused on approximating the set of pareto - optimal solutions . however , to assess the quality of pareto approximation set , special measures are needed  @xcite .",
    "hypervolume indicator is a commonly accepted quality measure for comparing approximation set generated by multi - objective optimizers .",
    "the indicator measures the hypervolume of the dominated portion of the objective space by pareto approximation set and has received more and more attention in recent years  @xcite .",
    "there have been some studies that discuss the issue of fast hypervolume calculation  @xcite .",
    "these algorithms partition the covered space into many cuboid - shaped regions , within which the approach considering the dominated hypervolume as a special case of klee s measure problem is regarded as the current best one .",
    "this approach  @xcite adopts orthogonal partition tree which requires @xmath2 storage and streaming variant  @xcite .",
    "conceptual simplification of the implementation are concerned and thus the algorithm achieves an upper bound of @xmath6 for the hypervolume calculation . ignoring the running time of sorting the points according to the @xmath1-th dimension",
    ", @xmath7 , the running time of this approach is exponential of the dimension of space @xmath1 .",
    "this paper develops novel heuristics for the calculation of hypervolume indicator .",
    "special technologies are applied and the novel approach yields upper bound of @xmath4 runtime and consumes @xmath5 storage .",
    "the paper is organized as follows . in the next section",
    ", the hypervolume indicator is defined , and some background on its calculation is provided . then , an algorithm is proposed which uses the so - called vertex - splitting technology to reduce the hypervolume .",
    "the complexities of the proposed algorithm are analyzed in section  [ sec : complexity ] .",
    "the last section concludes this paper with an open problem .",
    "without loss of generality , for multi - objective optimization problems , if the @xmath1 objective functions @xmath8 are considered with @xmath9 to be minimized , not one optimal solution but a set of good compromise solutions are obtained since that the objectives are commonly conflicting .",
    "the compromise solutions are commonly called pareto approximation solutions and the set of them is called the pareto approximation set . for a pareto approximation set @xmath10 produced in a run of a multi - objective optimizer , where @xmath11 , all the solutions are non - comparable following the well - known concept of pareto dominance . specially , we say that @xmath12 dominates @xmath13 at the @xmath14-th dimension if @xmath15 .",
    "the unary hypervolume indicator of a set @xmath16 consists of the measure of the region which is simultaneously dominated by @xmath16 and bounded above by a reference point @xmath17 such that @xmath18 . in the context of hypervolume indicator , we call the solutions in @xmath16 as the dominative points . as illustrated in fig .",
    "[ fig:2d - set ] , the shading region consists of an orthogonal polytope , and may be seen as the union of three axis - aligned hyper - rectangles with one common vertex , i.e. , the reference point @xmath19 .",
    "another example in three dimensional space is shown in fig .",
    "[ fig:3d - set ] , where five dominative points , @xmath20 , and the reference point @xmath21 are considered .",
    "the volume is the union of the volumes of all the cuboids each of which is bounded by a vertex , where the common regions are counted only once .",
    "if a point @xmath13 is dominated by another point @xmath12 , the cuboid bounded by @xmath13 is completely covered by the cuboid bounded by @xmath12 . and thus only the non - dominated points contribute to the hypervolume .",
    "in other works , e.g. the work of beume and rudolph  @xcite , the hyper - cuboid in @xmath1-dimensional space are partitioned into child hyper - cuboids along the @xmath1-th dimension and then all these child hypervolumes are gathered together by the inclusion - exclusion principle  @xcite .    in this paper , we step in another way .",
    "the hyper - cuboid is partitioned into child hyper - cuboids at some splitting reference points and then all the child hypervolumes are gathered directly .",
    "more detailed , given a point @xmath22 , each of other points in @xmath16 must dominated @xmath12 at some dimensions for the non - comparable relation .",
    "if the parts over @xmath12 are handled , the problem of calculating the hypervolume bounded by @xmath16 and the reference point is figured out .",
    "the additional part partitioned out at the @xmath14-th dimension is also a @xmath1-dimensional hyper - cuboid whose vertices are ones beyond @xmath12 at such dimension .",
    "their projections on the hyperplane orthogonal to dimension @xmath14 are all dominated by @xmath12 , and thus are free from consideration .",
    "it should be noted that the reference point of child hyper - cuboid is altered to @xmath23 , namely the @xmath14-th coordinate is replaced by @xmath24 .",
    "the other child hyper - cuboids are handled in the similar way . in these processes ,",
    "the given point is called the splitting reference point .    obviously",
    ", the hyper - cuboids with more dominative points require more run time to calculate the hypervolumes . to reduce the whole run time for calculating all these child hyper - cuboids ,",
    "the splitting reference point should be carefully selected .",
    "the strategy adopted in this paper is described as follows .",
    "\\(1 ) let @xmath25 and choose a point with the least dimensions on which the point dominated by other @xmath26 points .",
    "\\(2 ) if some points tie , update @xmath26 as @xmath27 and then within these points , choose a point with the least dimensions on which the point dominated by other @xmath26 points .",
    "\\(3 ) repeat the similar process until only single point is left or @xmath28 . and",
    "if @xmath28 and several points are left , the first found point is selected .    by the above principle , as an example , not @xmath29 or other points but",
    "@xmath30 is chosen as the first splitting reference point for the case shown in fig .",
    "[ fig:3d - set ] .",
    "two child cuboids each bounded by one points and another child cuboid bounded by two points are generated by splitting along @xmath30 .",
    "this is the optimal strategy in such case .",
    "the algorithm to calculate the hypervolume is shown in algorithm  [ algo : calchypervolume ] .",
    "some major parameters are as follows .    *",
    "* int[n][d ] order * the orders of all the dominative points at each dimension are represented by a two - dimensional array of integer .",
    "* * int split * the index of the point at which the hyper - cuboid is cut to generate multiple child hyper - cuboids is called @xmath31 . *",
    "* int[n ] splitcount * the numbers of @xmath26 present in the @xmath31-th row of the array @xmath32 are saved in @xmath33 , where @xmath34 .",
    "* * int[n ] coveredcount * the numbers of @xmath26 present in the current checked row of the array @xmath32 are save in @xmath35 , where @xmath34 .",
    "moreover , some conventions are explained as follows .    *",
    "the subscript of @xmath24 begins with @xmath36 while the index of array begins with @xmath37 .",
    "thus @xmath24 is same as @xmath38[j-1]$ ] . *",
    "assume @xmath39 and @xmath40 are two arrays and @xmath0 is an element .",
    "@xmath41\\leftarrow n$ ] means setting each element of @xmath39 as @xmath0 , while @xmath42 \\leftarrow b [ ] $ ] means copying all the elements of @xmath40 to @xmath39 pairwise . *",
    "assume @xmath43 is a set and @xmath44 is an element .",
    "@xmath45 means appending a copy of @xmath44 to @xmath43 .",
    "the inputs of the algorithm are a set of non - dominated ( dominative ) points and a reference point , thus the hyper - cuboids are represented implicitly .",
    "the hyper - cuboid @xmath46 defined by the dominative points @xmath47 where @xmath48 , and the reference point @xmath49 , namely @xmath50 .",
    "the initial number @xmath0 of dominative points can be obtained from the length of @xmath46 and the dimension @xmath1 is known too.the hypervolume of @xmath46 , @xmath51 .",
    "@xmath52 ; @xmath53;@xmath54 \\leftarrow n$ ] ; sort @xmath55;@xmath56[j-1 ] \\leftarrow $ ] number of points dominating @xmath24 strictly ; @xmath57 \\leftarrow 0 $ ] ; @xmath58$]++ ; @xmath59 ; @xmath54 \\leftarrow coveredcount[]$ ] ; * break * ; @xmath60 ; @xmath61 ; @xmath62 ;",
    "@xmath63 ; @xmath64 \\leftarrow y_{split , j}$ ] ; @xmath65 ; @xmath66 ; @xmath67;@xmath51 ;    in fact , when the hyper - cuboid is cut into two child hyper - cuboids , there may be some points dominated by the splitting reference point in the bigger cuboid , and thus such points could be removed from the points set @xmath46 . in the proposed algorithm , it does not matter whether those points are removed or not .",
    "before discussing the time - space complexity of the proposed algorithm , some properties are presented firstly .",
    "[ lemma : delta ] let @xmath68 be the number of points dominating @xmath12 at the @xmath14-th dimension .",
    "then    \\(1 ) for @xmath69 and each @xmath70 , @xmath71 .",
    "\\(2 ) for @xmath69 and each @xmath72 , @xmath73 .",
    "\\(3 ) for @xmath74 and each @xmath70 , @xmath75 .",
    "\\(4 ) @xmath76 .",
    "\\(5 ) for @xmath69 and each @xmath70 , @xmath77 .",
    "it is clear that ( 2 ) @xmath78 ( 4 ) @xmath78 ( 5 ) .",
    "the follows show ( 1 ) , ( 2 ) and ( 3 ) .",
    "\\(1 ) ( by contradiction . )",
    "assume to the contrary there is some @xmath79 , @xmath80 .",
    "if this is the case , there are at least one @xmath13 where @xmath81 such that each @xmath24 dominates @xmath82 for all @xmath83 .",
    "it follows that @xmath12 dominates @xmath13 , which contradicts our assumption that all the elements in @xmath84 are non - comparable .",
    "\\(2 ) given @xmath14 , sort all @xmath24 where @xmath85 and label each @xmath24 a sequence number @xmath86 which ranges from 0 to @xmath87 . thus @xmath88 .",
    "there are two cases to consider .",
    "firstly , if all @xmath24 are different each other , then @xmath89 .",
    "it follows that @xmath90 . secondly , if there are same elements within @xmath91 , without loss of generality , suppose @xmath92 and @xmath93 .",
    "then @xmath94 , it follows that @xmath95 .",
    "this completes the proof .",
    "\\(3 ) ( by contradiction . ) for any @xmath12 , @xmath80 is excluded by ( 1 ) of this lemma .",
    "thus @xmath96 for some @xmath12 is considered .",
    "if this is the case , we obtain @xmath97 , contradicting ( 2 ) of this lemma , which implies @xmath98 , namely @xmath99 .",
    "[ lemma : omega ] let @xmath100 be the amount of @xmath26 in all @xmath68 where @xmath101 , namely @xmath102 .",
    "then    \\(1 ) @xmath103 for any @xmath104 and @xmath26 ;    \\(2 ) @xmath105 for any @xmath26 ;    \\(3 ) @xmath106 for any @xmath104 .    by the definition of @xmath107 ,",
    "it is clear that all statements follows lemma  [ lemma : delta ] .",
    "[ lemma : runtime ] let @xmath108 be the runtime of algorithm  [ algo : calchypervolume ] to compute a hypervolume with @xmath0 dominative points in a @xmath1-dimensional space .",
    "then    \\(1 ) @xmath109 where @xmath110 ;    \\(2 ) @xmath111 where @xmath112 ;    \\(3 ) @xmath108 is minimal when @xmath113 and @xmath114 for any @xmath14 and @xmath26 ;    \\(4 ) @xmath108 is maximal when @xmath115 for any @xmath104 and @xmath116 for any @xmath104 and each @xmath34 .",
    "\\(1 ) and ( 2 ) are clear .",
    "\\(3 ) by the process of algorithm  [ algo : calchypervolume ] , given some @xmath104 , @xmath117 by ( 1 ) of lemma  [ lemma : delta ] , @xmath71 .",
    "it is clear that for a given @xmath104 , it is necessary that @xmath118 to minimize @xmath108 .",
    "in addition , all the @xmath68 must share alike , i.e. @xmath114 for any @xmath14 and @xmath26 .",
    "if this is not the truth , suppose @xmath119 .",
    "thus by ( 1 ) of this lemma , @xmath120 let @xmath121 and @xmath122 .",
    "@xmath123 and @xmath124 can be modified in the similar way until @xmath125 .",
    "this completes the proof .",
    "\\(4 ) by ( 5 ) of lemma  [ lemma : delta ] , @xmath126 .",
    "it is clear that for a given @xmath104 , it is necessary that @xmath115 to maximize @xmath108 .",
    "hence eqn .",
    "( [ eqn : fnd1 ] ) is written as follows , @xmath127 suppose @xmath12 is the splitting reference point chosen by algorithm  [ algo : calchypervolume ] , @xmath128 , or else contradicting @xmath129 . to maximize @xmath108 in eqn .",
    "( [ eqn : fnd2 ] ) , let @xmath130 . similarly , we get @xmath131 , @xmath132 , @xmath133 , and so on .",
    "it is exactly @xmath134 .",
    "this completes the proof .",
    "first of all , it is clear that @xmath135 . by ( 3 ) of lemma  [ lemma : runtime ] , the algorithm performs best when each @xmath68 shares alike for the chosen @xmath104 . if @xmath136 , @xmath137 for any @xmath14 .",
    "thus @xmath138 which implies @xmath139 . if @xmath140 , @xmath141 for any @xmath14 . in the rough ,",
    "we get @xmath142 it can be obtained from eqn .",
    "( [ eqn : lowerruntime ] ) that @xmath143 even when @xmath144 is relaxed to @xmath145 .",
    "fredman and weide  @xcite have shown that klee s measure problem has a lower bound of @xmath146 for arbitrary @xmath147 . just as beume and rudolph",
    "@xcite have mentioned , although it is unknown what the lower bound for calculating the hypervolume is , it is definitely not harder than solving kmp because it is a special case of kmp . therefore , there is a gap between the lower bound of the proposed algorithm and the actual lower bound of calculating the hypervolume .    in the average cases ,",
    "suppose that for the given splitting reference point @xmath12 , @xmath148 .",
    "meanwhile , each @xmath68 shares alike , i.e. @xmath149 .",
    "thus , @xmath150 which implies the runtime of the proposed algorithm is @xmath151 at the given cases .      by ( 2 ) of lemma  [ lemma : runtime ] , @xmath152 for any @xmath153 . and by ( 4 ) of lemma  [ lemma : runtime ] , at the worst cases , we have @xmath154 which implies that the proposed algorithm for computing the hypervolume bounded by @xmath0 points and a reference point in @xmath1-dimensional space has a runtime of @xmath4 at the worst cases .",
    "let @xmath155 be the used storage by algorithm  [ algo : calchypervolume ] . in the proposed algorithm ,",
    "every child hypervolume is calculated one by one . since the storage can be reused after the former computation has been completed , @xmath155 is only related to the maximum usage of all the computations of child hypervolumes .",
    "hence , @xmath156 thus the upper bound of space is as follows .",
    "@xmath157 where @xmath158 .",
    "it is easy to obtain an @xmath5 space upper bound for the proposed algorithm .    combining the above analyses together",
    ", we obtain the time - space complexity of the proposed algorithm .",
    "the hypervolume of a hyper - cuboid bounded by @xmath0 non - comparable points and a reference point in @xmath1-dimensional space can be computed in time @xmath4 using @xmath5 storage .",
    "a fast algorithm to calculate the hypervolume indicator of pareto approximation set is proposed . in the novel algorithm ,",
    "the hyper - cuboid bounded by non - comparable points and the reference point is partitioned into many child hyper - cuboids along the carefully chosen splitting reference point at each dimension .",
    "the proposed approach is very different to the technique used in other works where the whole @xmath1-dimensional volume is calculated by computing the @xmath159-dimensional volume along the dimension @xmath1 .",
    "such difference results in very different time bounds , namely @xmath4 for our work and @xmath160 for the best previous result .",
    "neither kind of technique can exceed the other completely and each has his strong point .",
    "additionally , the amount of storage used by our algorithm is only @xmath5 even no special technique is developed to reduce the space complexity .",
    "as the context has mentioned , it is very important to choose appropriate splitting reference point for our algorithm .",
    "well selected point can reduce number of points in separated parts and thus cut down the whole runtime .",
    "we do not know whether the strategy adopted in this paper is optimal or near optimal .",
    "further investigations should be worked on .",
    "zitzler , e. , thiele , l. , laumanns , m. , fonseca , c.m . ,",
    "da  fonseca , v.g .",
    ": performance assessment of multiobjective optimizers : an analysis and review .",
    "ieee transactions on evolutionary computation * 7*(2 ) ( 2003 ) 117132    zitzler , e. , thiele , l. : multiobjective optimization using evolutionary algorithms  a comparative study . in eiben , a.e . , ed . :",
    "parallel problem solving from nature v , amsterdam , springer - verlag ( 1998 ) 292301      zitzler , e. , brockhoff , d. , thiele , l. : the hypervolume indicator revisited : on the design of pareto - compliant indicators via weighted integration . in : proceedings of the 4th international conference on evolutionary multi - criterion optimization ( emo 2007 ) .",
    "volume 4403 .",
    ", springer - verlag ( 2007 ) 862876    while , l. , bradstreet , l. , barone , l. , hingston , p. : heuristics for optimising the calculation of hypervolume for multi - objective optimisation problems . in : the 2005 ieee congress on evolutionary computation",
    ". volume  3 .",
    "( 2005 ) 22252232        beume , n. , rudolph , g. : faster s - metric calculation by considering dominated hypervolume as klee s measure problem . in kovalerchuk ,",
    "b. , ed . : proceedings of the second iasted conference on computational intelligence , anaheim , acta press ( 2006 ) 231236"
  ],
  "abstract_text": [
    "<S> hypervolume indicator is a commonly accepted quality measure for comparing pareto approximation set generated by multi - objective optimizers . </S>",
    "<S> the best known algorithm to calculate it for @xmath0 points in @xmath1-dimensional space has a run time of @xmath2 with special data structures . </S>",
    "<S> this paper presents a recursive , vertex - splitting algorithm for calculating the hypervolume indicator of a set of @xmath0 non - comparable points in @xmath3 dimensions . </S>",
    "<S> it splits out multiple child hyper - cuboids which can not be dominated by a splitting reference point . in special , the splitting reference point </S>",
    "<S> is carefully chosen to minimize the number of points in the child hyper - cuboids . </S>",
    "<S> the complexity analysis shows that the proposed algorithm achieves @xmath4 time and @xmath5 space complexity in the worst case . </S>"
  ]
}