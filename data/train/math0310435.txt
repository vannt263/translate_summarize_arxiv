{
  "article_text": [
    "a spelunker has an accident in the cave .",
    "his lamp goes out , he can not move , all he can hear is a bat flying by every now and then on its random flight around the cave . what can he learn about the shape of the cave ?",
    "in other words : what can we learn about the structure of a finite graph using only information obtained by observing the returns of a random walk on the graph to this node ?",
    "let @xmath0 be a connected simple graph with @xmath1 vertices , and let @xmath2 be a fixed node .",
    "let @xmath3 be the steps of a simple random walk on @xmath4 starting from @xmath5 .",
    "assume that we observe the _ return time sequence _ , the infinite sequence of ( random ) times @xmath6 when the walk visits @xmath5 .",
    "alternatively this can be described as a sequence @xmath7 of bits , where @xmath8 if the walk is at @xmath5 at time @xmath9 , @xmath10 otherwise .",
    "note that @xmath11 are independent samples from the same distribution as @xmath12 , which we call the _ return distribution _ of @xmath4 to @xmath5 .",
    "we say that a parameter @xmath13 of the graph @xmath4 and root @xmath5 can be reconstructed ( from the return time sequence ) , if for every two rooted graphs @xmath14 and @xmath15 for which the return time sequence has the same distribution , we have @xmath16 .",
    "which graph parameters can be reconstructed from the return time sequence ? there is a trivial way to construct different graphs with the same return sequence : take two isomorphic copies and glue them together at the root .",
    "sometimes it makes sense to assume that we also know the degree @xmath17 of the root . in this case",
    ", we can reconstruct the number of edges through @xmath18    another trivial example is to observe if all the numbers @xmath19 are even .",
    "this is so if the graph is bipartite , and it happens with probability 0 otherwise .",
    "a natural candidate for a reconstructible quantity is the spectrum of the transition matrix @xmath20 of the random walk on @xmath4 .",
    "let @xmath21 be the eigenvalues of @xmath20 , arranged in decreasing order .",
    "bipartiteness is equivalent to saying that @xmath22 .",
    "we are going to show by a simple example that the spectrum is not reconstructible in general . on the other hand",
    ", we show that if @xmath23 is an eigenvalue of @xmath4 which has an eigenvector @xmath24 such that @xmath25 , then @xmath23 is reconstructible .",
    "we note that the _ multiplicity _ of @xmath23 is not necessarily reconstructible .",
    "a special case where the eigenvector condition above is satisfied for all eigenvalues is when @xmath4 is node - transitive .",
    "we do nt know whether in this case the multiplicities are reconstructible .    of particular interest",
    "is the issue of _ efficient reconstruction _ , by which we mean observing a polynomial ( or expected polynomial ) number of returns .",
    "we consider this question in the case of the _ spectral gap _ @xmath26 . assuming the graph is node transitive",
    ", we describe a procedure to estimate @xmath27 up to a constant factor , using just polynomially many ( in @xmath28 ) of the first values of the @xmath19 .",
    "we give an example of a graph where the spectral gap can not be recovered _",
    "at all _ from observations made at one particular node .",
    "this question was first mentioned , together with other related problems , in @xcite .",
    "another related work is that of feige @xcite which presents a randomized space - efficient algorithm that determines whether a graph is connected .",
    "his method uses return times of random walks to estimate the size of connected components .",
    "[ trees ] consider the two trees in figure [ 2-trees ] .",
    "the distribution of the return time to the root is the same in both trees ( see later ) .",
    "the eigenvalues of the tree on the left are @xmath29 while the eigenvalues of the tree on the right are @xmath30 note that the eigenvalues are the same , but their multiplicities are different .        [ expand ] let @xmath31 be a tree in which all internal nodes have degree @xmath32 and which has a `` root '' @xmath5 such that all leaves are at distance @xmath33 from the root .",
    "we construct a graph @xmath4 by adding a @xmath34-regular graph on the leaves .    for a fixed @xmath33 and @xmath34 , all graphs obtained this way are @xmath35-regular graphs , and",
    "the distribution of the return time to the root is the same in all such graphs . on the other hand",
    ", graphs obtained this way can have very different properties .",
    "if we add an expander on the leaves , the graph @xmath4 will be an expander .",
    "( recall that g is a @xmath36-expander iff @xmath37 for every non empty set of vertices @xmath38 with @xmath39 .",
    "for background on expanders and spectral gap see e.g.  @xcite . )",
    "if we connect `` twin '' leaves to each other , and also match up `` cousins '' to get @xmath34 new edges at each node , then for @xmath40 the root will be a cutpoint . for expanders ,",
    "the eigenvalue gap @xmath41 is bounded from below by a positive function of @xmath34 , while for the graphs with cutpoints in the middle the eigenvalue gap tends to 0 as @xmath42 .",
    "denote by @xmath43 the probability that a simple random walk on @xmath4 starting at @xmath44 will be at @xmath45 at time @xmath46 .",
    "clearly @xmath47 here @xmath20 is not symmetric , but we can consider the symmetrized matrix @xmath48 , where @xmath49 is a diagonal matrix with the positive numbers @xmath50 in the diagonal .",
    "the matrix @xmath51 has the same eigenvalues as @xmath20 , and so we have @xmath52 where @xmath53 is an orthonormal basis of eigenfunctions of @xmath51 corresponding to the eigenvalues @xmath54 .",
    "we note that if the graph is node - transitive , then the value @xmath55 is the same for all @xmath5 , and hence by averaging ( [ ret - exp ] ) we get the simpler formula @xmath56    at some point , it will be convenient to consider the _ lazy version _ of our chain , i.e. , the markov chain with transition matrix @xmath57 ( before doing a step , we flip a coin to decide if we want to move at all ) . the observer can easily pretend that he or she is watching the lazy version of the chain : after each step , he flips a coin in quick succession until he tosses a head , and advances his watch by the number of coinflips .",
    "the distribution after @xmath46 lazy steps is easy to compute from ( [ hit ] ) : @xmath58    the main advantage of the lazy chain is that its eigenvalues are nonnegative .",
    "furthermore , for a lazy chain we have @xmath59 and hence @xmath60 if @xmath61 .",
    "let us introduce the generating function @xmath62 there are several other useful expressions for @xmath63 ; for example , we get from ( [ hit ] ) that @xmath64 and expressing this in terms of determinants , we get @xmath65 where @xmath66 is the matrix obtained from @xmath20 by deleting the row and column corresponding to the root , and @xmath67 is the @xmath68 identity matrix",
    ".    it will be convenient to do a little algebraic manipulation .",
    "the reciprocal of this function is also an interesting generating function : @xmath69 where @xmath70 is the probability that the first return to the root occurs at the @xmath46-th step .",
    "this function has a root at @xmath71 , so it makes sense to divide by @xmath72 , to get the analytic function @xmath73 where @xmath74 is the probability that the random walk does not return to the root during the first @xmath46 steps .",
    "it is these formulas which form the basis of learning about the spectrum of @xmath4 from the visiting times of the random walk at @xmath75 , since @xmath55 is determined by the distribution of return times , and can be easily estimated from the visiting times ( see section [ efficient ] ) .",
    "we call an eigenvalue of @xmath20 _ nondegenerate _ if at least one of the corresponding eigenfunctions @xmath76 satisfies @xmath77 .",
    "one can see from ( [ ret - exp ] ) that the non zero nondegenerate eigenvalues are determined by the distribution of return times .",
    "using @xmath78 for the orthonormal basis @xmath79 we conclude that whether zero is a nondegenerate eigenvalue of @xmath20 is also determined .",
    "the return time distribution determines @xmath63 and this can also be used to find the nondegenerate eigenvalues : the poles of @xmath63 are exactly the reciprocals of the non zero , nondegenerate eigenvalues of @xmath20 .",
    "zero is a nondegenerate eigenvalue if and only if @xmath80",
    ". then we get    [ nonzero ] if two rooted graphs have the same return time distribution , then they have the same nondegenerate eigenvalues .",
    "let us remark that if @xmath4 has a node - transitive automorphism group , then _ every eigenvalue of @xmath20 is nondegenerate .",
    "_ indeed , every eigenvalue has an eigenvector , which does not vanish at some node ; by node - transitivity , it also has an eigenvector that does not vanish at the root .",
    "let us also remark that the _ multiplicity _ of a nondegenerate eigenvalue is not uniquely determined : @xmath10 is a nondegenerate eigenvalue of both trees in example [ trees ] , but it has different multiplicities in the two .",
    "furthermore , degenerate eigenvalues are not determined by the return times : the second largest eigenvalues of the transition matrices of the two @xmath35-regular graphs constructed in example [ expand ] are different .",
    "it follows from proposition [ nonzero ] that at least for the second graph , the second largest eigenvalue is degenerate .",
    "we want to put example [ trees ] in broader context . for trees",
    ", we can simplify the generating function a bit : since trees are bipartite , we have @xmath81 , and hence it makes sense to divide by @xmath82 and then substitute @xmath83 .",
    "it will be convenient to scale by the degree of the root , and to work with the function @xmath84 it is easy to see that we did not lose any information here : we have @xmath85 for two trees @xmath86 and @xmath87 if and only if they have the same return time distribution and their roots have the same degree .    for a rooted tree with a single edge , @xmath88 .",
    "if a rooted tree @xmath4 is obtained by gluing together the roots of two rooted trees @xmath86 and @xmath87 , then @xmath89 this is easily seen by conditioning on which tree the random walk starts in .",
    "furthermore , if we attach a new leaf @xmath90 to the root @xmath5 of a tree @xmath4 and make this the root to get a new rooted tree @xmath91 , then @xmath92 to see this , consider a walk on @xmath91 starting at @xmath90 , and the probability @xmath93 that it does not return to @xmath90 in the first @xmath94 steps ( @xmath95 ) .",
    "the first step leads to @xmath5 ; the second step has to use a different edge , which has a probability of @xmath96 .",
    "we can view the walk now as a random walk on @xmath4 until it returns to @xmath5 .",
    "the probability that this happens after @xmath97 steps is @xmath98 .",
    "if @xmath99 then the walk will certainly not return to @xmath90 in the first @xmath94 steps .",
    "if @xmath100 , then we can think of the situation as just having made a step from @xmath90 , and so the probability that we do nt return to @xmath90 in the next @xmath101 steps is @xmath102 .",
    "hence we get the equation @xmath103 multiplying by @xmath104 and summing over all @xmath105 , we get ( [ add - root ] ) .",
    "these formulas can be verified from the definition of @xmath106 .",
    "they imply that @xmath107 is a rational function with integral coefficients .",
    "they also provide us with a fast way to compute @xmath107 , and through this , to verify that the two trees in example [ trees ] have the same return distribution .",
    "but we can get more , a way to generate many such pairs .",
    "suppose that we find a linear dependence between functions @xmath107 for various trees @xmath4 .",
    "this can be written as @xmath108 with some positive integers @xmath109 .",
    "now if we glue together the roots of @xmath110 copies of @xmath86 , @xmath111 , @xmath112 copies of @xmath113 to get @xmath4 , and the roots of @xmath114 copies of @xmath115 , @xmath111 , @xmath116 copies of @xmath117 to get @xmath91 , then by ( [ glue - tree ] ) we ll have @xmath118 we can add a new root to both if we prefer to have an example rooted at a leaf .    obviously , we only need to look for trees rooted at leaves . to find such linear dependencies , it is natural to find trees for which @xmath119 is `` simple '' , namely the ratio of two linear functions , and then find three with a common denominator .",
    "a general example is a tree @xmath120 of height @xmath121 , where the neighbor of the root has degree @xmath122 and has @xmath123 neighbors of degree @xmath124 .",
    "we can allow the degenerate cases @xmath125 ( when @xmath4 is a star rooted at a leaf ) and @xmath126 ( when @xmath4 is a single edge ) .",
    "it is easy to compute that has rational numerator and denominator ?",
    "can one say anything about quadratic ?",
    "what about depth 4 ? ] @xmath127    so if we fix a @xmath46 which is not a prime , and consider trees @xmath120 with @xmath128 , they all have the same denominator @xmath129 , and so for any three of them their functions @xmath107 will be linearly dependent .",
    "the simplest choice is @xmath130 , when we get the trees @xmath131 ( a single edge ) , @xmath132 ( a path of length 3 ) and @xmath133 ( a 4-star ) .",
    "simple computation shows that @xmath134 gluing these together as described above , and adding a new root for good measure , gives the two trees in example [ trees ] .    using ( [ ret - det ] ) and ( [ def - h ] ) , it is not hard to see that the roots of the numerator of @xmath119 are the squared reciprocals of the nondegenerate non zero eigenvalues of @xmath4 , except for the trivial nondegenerate eigenvalues @xmath135 .",
    "the multiplicities , as we have seen , are not necessarily determined by @xmath107 .    in the special trees constructed above ,",
    "the squareroots of the root of the denominator are exactly the degenerate eigenvalues of @xmath4 .",
    "we do nt know if this is always so . an interesting open question seems to be whether the degenerate eigenvalues are reconstructible for trees .",
    "in the previous section , we assumed that the exact distribution of the return time is known , which is the same as saying that we can observe the random walk forever . in this section",
    "we are concerned with determining quantities after observing a polynomial number of returns .",
    "we show that we can estimate @xmath55 from the observation of polynomially many return times .",
    "fix @xmath46 and observe the returns @xmath136 until the first @xmath137 with @xmath138 ; call this period an _ experiment_. call the experiment _ successful _ if @xmath139 . the probability that an experiment is successful is @xmath55 .",
    "note that observing the next @xmath46 steps and then until the first return ( i.e. , @xmath140 with the smallest @xmath141 such that @xmath142 ) is an independent experiment .",
    "so we have a sequence of independent events with the same probability @xmath143 , and we want to estimate @xmath144 . by standard results , observing @xmath145 of them , the relative frequency will be closer than @xmath146 to @xmath144 with probability @xmath147 .",
    "the amount of time a particular trial takes is a random variable , whose expectation is @xmath46 plus the time it takes to get back to @xmath5 after @xmath46 steps .",
    "this can be bounded by the maximum hitting time between nodes , which is @xmath148 . summing up ,    [ pkfind ] in an expected time of @xmath149",
    "we can compute an estimate of @xmath55 which is within an ( additive ) error of @xmath146 with probability @xmath147 .",
    "we restrict our attention to node - transitive graphs , in which case we can use the trace formula ( [ ret - trace ] )",
    ". we can use ( [ nodenum ] ) to reconstruct the number of nodes @xmath28 .",
    "furthermore , we assume that the chain is lazy , so that its eigenvalues are nonnegative , and their sum is @xmath150 .    for a lazy chain",
    ", @xmath55 tends to @xmath151 monotone decreasing .",
    "furthermore , ( [ ret - trace ] ) implies that setting @xmath152 we have @xmath153 and hence @xmath154 for @xmath155 ( which we assume without loss of generality ) .    we can try to compute recursively @xmath156 and @xmath157^{1/k}.\\ ] ] this , however , does not seem to give an effective means of estimating @xmath158 in polynomial time . but to estimate at least the eigenvalue gap @xmath159 we can use the following fact .",
    "[ gap ] we have @xmath160    it is not hard to see that these bounds imply the weaker but more informative bounds @xmath161    from ( [ ret - trace ] ) , @xmath162 and hence @xmath163 thus @xmath164 using the elementary inequality @xmath165 valid for @xmath166 , ( [ taubound ] ) follows .",
    "let @xmath167 .",
    "it follows that if we find an integer @xmath168 such that @xmath169 , then @xmath170 is an estimate for the eigenvalue gap @xmath27 which is within a factor of @xmath171 to the true value .",
    "but of course we do nt know @xmath172 exactly , only with an additive error : by proposition [ pkfind ] , we can estimate @xmath172 in polynomial time with an additive error less than ( say ) @xmath173 , with high probability .",
    "so to get valuable information , we need to find a value of @xmath46 for which @xmath174 .",
    "it is well known that the eigenvalue gap of a graph with @xmath28 nodes is at least @xmath175 , so we get that for @xmath176 , @xmath177    applying proposition [ pkfind ] , we can compute an approximation @xmath178 of @xmath172 that is within an additive error of @xmath179 with probability @xmath180 . by binary search",
    ", we can find a @xmath46 in the interval @xmath181 $ ] for which @xmath182 but @xmath183 .    for the value of @xmath46 computed above",
    ", @xmath184 is within a factor of @xmath185 of @xmath27 with probability at least @xmath147 .    with large probability",
    ", we have @xmath186 for all @xmath187 for which we compute @xmath188 , in particular for @xmath189 and @xmath190 . using ( [ qdecrease ] ) ,",
    "@xmath191 and also @xmath192 similarly , @xmath193 we claim that @xmath194 to show the upper bound , we may assume that @xmath195 . then using ( [ qhatq1 ] ) ,",
    "@xmath196 the lower bound in ( [ qhatq2 ] ) follows similarly .",
    "hence by lemma [ gap ] , @xmath197 and @xmath198",
    "\\1 . we can estimate for every node - transitive graph , by similar means , the value @xmath199 , which governs the mixing time of the chain .",
    "the trick is to consider the matrix @xmath200 instead of @xmath20 , i.e. , observe the chain only every other step .",
    "a little care is in order , since this new chain may not be connected ; but by node - transitivity , its eigenvalue gap is the eigenvalue gap of the component containing the observation node .",
    "the second moment of the first return time also has some more direct meaning .",
    "let @xmath201 denote the expected number of steps before a random walk starting from the stationary distribution hits the root @xmath5 .",
    "then it is not hard to show using that the walk is close to stationary at a far away time that @xmath202 it is not clear whether any of the higher moments have any direct combinatorial significance .",
    "* problem : * let @xmath4 be a connected graph of size @xmath28 .",
    "we label the vertices randomly by @xmath203 colors and observed the colors as they are visited by a simple random walk random walk : after each step , the walker tells you `` now i m at red '' , `` now at blue '' , and so on .",
    "how many colors are needed in order to recover the shape of g a.s . from this sequence of colors ?    *",
    "problem : * consider an @xmath28-node connected graph . take @xmath28 particles labeled @xmath204 . in a configuration , there is one particle at each node .",
    "the interchange process introduced in @xcite is the following continuous time markov chain on configurations : for each edge @xmath205 at rate @xmath206 the particles at @xmath9 and @xmath207 interchanged .",
    "assume you observed the restriction of the interchange process to a fixed node , what graph properties can be recovered ? obviously you get more information than in the case discussed in the paper , which corresponds to noticing only one of the particles .",
    "but is it really possible to use this information to discover more about the graph ?",
    "a. lubotzky , cayley graphs : eigenvalues , expanders and random walks",
    ". surveys in combinatorics , 1995 ( stirling ) , 155189 , london math .",
    "lecture note ser .",
    ", 218 , cambridge univ . press , cambridge , 1995"
  ],
  "abstract_text": [
    "<S> we observe returns of a simple random walk on a finite graph to a fixed node , and would like to infer properties of the graph , in particular properties of the spectrum of the transition matrix . </S>",
    "<S> this is not possible in general , but at least the eigenvalues can be recovered under fairly general conditions , e.g. when the graph has a node - transitive automorphism group . </S>",
    "<S> the main result is that by observing polynomially many returns , it is possible to estimate the spectral gap of such a graph up to a constant factor . </S>"
  ]
}