{
  "article_text": [
    "a sequence @xmath0 formed as the concatenation of @xmath1 non - overlapping segments is given , where @xmath2 .",
    "each segment is generated by some unknown stochastic process distribution .",
    "the process distributions that generate every pair of consecutive segments are different . the index @xmath3 where one segment ends and another starts is called a _",
    "change point_. the parameters @xmath4 specifying the change points @xmath5 are unknown and have to be estimated .",
    "change point analysis is one of the core problems in classical mathematical statistics @xcite . in a typical formulation of the problem ,",
    "the samples within each segment @xmath6 are assumed to be i.i.d . and the change refers to a change in the mean . in the literature on nonparametric methods for dependent data , the form of the change and/or the nature of dependence",
    "are usually restricted , for example , strong mixing conditions are imposed @xcite . moreover , even for dependent time series , the finite - dimensional marginals are almost exclusively assumed different @xcite .",
    "however , such strong assumptions do not necessarily hold in most of such real - world applications as bioinformatics , network traffic , market analysis , audio / video segmentation , fraud detection etc .",
    "methods used in these applications are thus usually model - based or employ application - specific ad hoc algorithms .",
    "more specifically , a theoretical framework to allow for the understanding of what is possible and under which assumptions is entirely lacking .    in this paper",
    ", we consider highly dependent time series , making as little assumptions as possible on how the data are generated .",
    "each segment is generated by an ( unknown ) stationary ergodic process distribution .",
    "the joint distribution over the samples can be otherwise arbitrary .",
    "we make no such assumptions as independence , finite memory or mixing ; the samples can be arbitrarily dependent .",
    "the marginal distributions of any given fixed size before and after the change points may be the same : the change refers to that in the time - series distribution .",
    "we aim to construct an asymptotically consistent algorithm that simultaneously estimates all @xmath7 parameters @xmath8 consistently .",
    "an estimate @xmath9 of a change point parameter @xmath10 is _ asymptotically consistent _ if it becomes arbitrarily close to @xmath10 in the limit as the length @xmath11 of the sequence approaches infinity .",
    "the asymptotic regime means that the error is arbitrarily small if the sequence is sufficiently long , i.e. the problem is  offline \" and @xmath12 does not grow with time .",
    "note that , in general , for stationary ergodic processes , rates of convergence are provably impossible to obtain ( see , for example , @xcite ) .",
    "therefore , the asymptotic results of this work can not be strengthened .    as follows from an impossibility result by @xcite , it is impossible to estimate the number of change points in the general setting that we consider .",
    "thus , we assume that @xmath7 is known .",
    "the case of @xmath13 has been addressed in @xcite where a simple consistent algorithm to estimate one change point is provided .",
    "the general case of @xmath14 turns out to be much more complex . with the sequence containing multiple change points ,",
    "the algorithm is required to simultaneously analyze multiple segments of the input sequence , with no a - priori lower bound on their lengths . in this case",
    "the main challenge is to ensure that the algorithm is robust with respect to segments of arbitrarily small lengths .",
    "usually in statistics this is done using methods based on the speed of convergence of sample averages to expectations . in the context of stationary ergodic processes ,",
    "such tools are unavailable as no guarantees on the speed of convergence exist .",
    "hence , the simultaneous analysis of segments of arbitrarily small lengths is conceptually much more difficult .",
    "the problem is considerably simplified if additionally a lower bound on the minimum separation of the change points is provided . under this assumption",
    ", an algorithm is proposed in @xcite that gives a list of possibly more than @xmath7 candidate estimates , whose first @xmath7 elements are asymptotically consistent , but it makes no attempt to estimate @xmath7 .",
    "we use empirical estimates of the so - called distributional distance @xcite , which have proved useful in various statistical learning problems involving stationary ergodic time series @xcite . our method has a computational complexity that is at most quadratic in each argument .",
    "we evaluate it on synthetic data generated by processes that , while being stationary ergodic , do not belong to any  simpler \" class , and can not be modeled as hidden markov processes with countable state spaces . moreover , the single - dimensional marginals before and after each change point are the same . to the best of our knowledge , none of the existing change point estimation algorithms work in this scenario .",
    "the remainder of this paper is organized as follows . in section  [ sec : pre ] we introduce preliminary notations and definitions . in section  [ sec : protocol ]",
    "we formalize the problem and describe the general framework considered . in section  [ sec : results ] we present our algorithm , state the main consistency result , and informally describe how the algorithm works . in section  [ sec : exp ] we provide some experimental results .",
    "we prove the consistency of the proposed method in section  [ sec : proofs ] .",
    "let @xmath15 be a measurable space ( the domain ) ; in this work we let @xmath16 but extensions to more general spaces are straightforward . for a sequence @xmath17 we use the abbreviation @xmath18 .",
    "consider the borel @xmath19-algebra @xmath20 on @xmath21 generated by the cylinders @xmath22 , where the sets @xmath23 are obtained via the partitioning of @xmath24 into cubes of dimension @xmath25 and volume @xmath26 ( starting at the origin ) .",
    "let also @xmath27 .",
    "process distributions are probability measures on the space @xmath28 . for @xmath29 and @xmath30",
    "let @xmath31 denote the _ frequency _ with which @xmath12 falls in  @xmath32 , i.e. @xmath33 a process @xmath34 is _ stationary _ if for any @xmath35 and @xmath36 , we have @xmath37 a stationary process @xmath34 is called _ stationary ergodic _",
    "if for all @xmath38 with probability  1 we have @xmath39 by virtue of the ergodic theorem ( see , e.g. , @xcite ) , this definition can be shown to be equivalent to the standard definition for the stationary ergodic processes ( see , e.g. , @xcite ) . for a given @xmath40",
    "we can define distributions on the space @xmath41 where the borel sigma - algebra @xmath42 is generated by @xmath43    the distributional distance between a pair of process distributions @xmath44 is defined as follows  @xcite @xmath45 we let @xmath46 , but any summable sequence of positive weights may be used .    in words , we partition the sets @xmath24 , @xmath47 into cubes of decreasing volume ( indexed by @xmath48 ) and take a weighted sum over the differences in probabilities of all the cubes in these partitions .",
    "the differences in probabilities are weighted : smaller weights are given to larger @xmath25 and finer partitions .",
    "we use _ empirical estimates _ of this distance defined as follows .",
    "[ emd ] the empirical estimate of @xmath49 between @xmath50 and a process @xmath34 is given by @xmath51 and that between a pair of sequences @xmath52 .",
    "is defined as @xmath53 where @xmath54 and @xmath55 are any sequences of integers that go to infinity with @xmath11 .",
    "[ thm : constd ] let a pair of sequences @xmath56 and @xmath57 be generated by a distribution @xmath34 whose marginals @xmath58 are stationary and ergodic .",
    "then @xmath59    the triangle inequality holds for the distributional distance @xmath60 and its empirical estimates @xmath61 , so that for all distributions @xmath62 and all sequences @xmath63 we have , @xmath64    the distributional distance @xmath60 and its empirical estimates @xmath61 are convex functions : for every @xmath65 for all distributions @xmath66 and all sequences @xmath67 with @xmath68 we have @xmath69    [ rem1 ] consider a pair of sequences @xmath70 with @xmath71 .",
    "the computational complexity of @xmath72 is of order @xmath73 , where @xmath74 .",
    "let @xmath75 correspond to the partition where each cell @xmath76 contains at most one element i.e. @xmath77 indeed , in   all summands corresponding to @xmath78 are equal to 0 ; moreover , all summands corresponding to @xmath79 are equal .",
    "thus , we already see that the number of required calculations is finite .",
    "note that in practice @xmath75 is bounded by the length of the binary precision in approximating real numbers ( i.e. , the length of the mantissa ) . for a fixed @xmath80 for every sequence @xmath81 the frequencies @xmath82 for all @xmath83 may be calculated using suffix trees with @xmath84 worst case construction and search complexity ( see , e.g. , @xcite ) .",
    "this brings the overall computational complexity of to @xmath85 .",
    "furthermore , the practically meaningful choices of @xmath54 are of order @xmath86 . to see this , observe that for a fixed @xmath87 the frequencies @xmath88 of cells in @xmath89 corresponding to higher values of @xmath25 are not consistent estimates of their probabilities ( and thus only add to the error of the estimate ) .",
    "indeed , for a pattern @xmath90 with @xmath91 of length @xmath25 the probability @xmath92 is asymptotically of the order @xmath93 where @xmath94 denotes the entropy rate of @xmath58 . by the above argument , one can set @xmath95 and @xmath96 in , bringing the overall complexity of calculating @xmath97 to @xmath98 .",
    "we formalize the problem as follows . the sequence @xmath99 , generated by an unknown arbitrary process distribution , is formed as the concatenation of @xmath1 of sequences @xmath100 where @xmath2 , and @xmath7 is assumed known .",
    "each of the sequences @xmath101 , is generated by an",
    "_ unknown stationary ergodic _ process distribution .",
    "formally , consider the matrix @xmath102 of random variables generated by some ( unknown ) stochastic process distribution @xmath34 such that ,    1 .",
    "the marginal distribution over every one of its rows is an unknown stationary ergodic process distribution ; 2 .",
    "the marginal distributions over the consecutive rows are different , so that every two consecutive rows are generated by different process distributions .",
    "note that the requirements are only on the marginal distributions over the rows ; the distribution @xmath34 is otherwise completely arbitrary .",
    "the process distributions are unknown and may be dependent .",
    "moreover , the means , variances , or , more generally , the finite - dimensional marginal distributions of any fixed size before and after the change points are not required to be different .",
    "we consider the most general scenario where the _ process distributions are different_. the sequence @xmath12 is obtained by first fixing a length @xmath103 and then concatenating the segments @xmath104 that is , @xmath105 where for each @xmath106 , the _ segment _",
    "@xmath107 is the sequence obtained as the first @xmath108 elements of the @xmath109 row of @xmath110 with @xmath111 .    the parameters @xmath4",
    "specify the _ change points _",
    "@xmath5 which separate consecutive segments @xmath112 generated by different process distributions .",
    "the change points are _ unknown _ and to be estimated .",
    "let the minimum separation of the change point parameters @xmath113 be defined as @xmath114 since the consistency properties we are after are asymptotic in  @xmath11 , we require that @xmath115 . note that this condition is standard in the change point literature , although it may be unnecessary when simpler formulations of the problem are considered , for example when the samples are i.i.d .",
    "however , conditions of this kind are inevitable in the general setting that we consider , where the segments and the samples within each segment are allowed to be arbitrarily dependent : if the length of one of the sequences is constant or sub - linear in @xmath11 then asymptotic consistency is not possible in this setting .",
    "however , @xmath116 is assumed unknown , and no ( lower ) bounds on it are available .",
    "we also make no assumptions on the distance between the process distributions : they can be arbitrarily close .",
    "our goal is to devise an algorithm that provides estimates @xmath117 for the parameters @xmath4 .",
    "the algorithm must be _ asymptotically consistent _ so that @xmath118",
    "in this section we present our method given by algorithm  [ alg : kk ] , which as we show in theorem  [ thm : kk ] , is asymptotically consistent under the general assumptions stated in section  [ sec : protocol ] .",
    "the proof of the consistency result is deferred to section  [ sec : proofs ] . in this section",
    "we give describe the algorithm , and intuitively explain why it works .",
    "the following two operators namely , the score function denoted @xmath119 and the single - change point - estimator denoted @xmath120 are used in our method .",
    "let @xmath121 be a sequence and consider a subsequence @xmath122 of @xmath12 with @xmath123 .    1 .",
    "define the score function as the intra - subsequence distance of @xmath122 , i.e. @xmath124 2 .",
    "define the single - change point estimator of @xmath122 as @xmath125    let us start by giving an overview of what algorithm  [ alg : kk ] aims to do .",
    "the algorithm attempts to simultaneously estimate all @xmath7 change points using the single - change point - estimator @xmath126 given by applied to appropriate segments of the sequence . for @xmath126 to produce asymptotically consistent estimates in this setting , each change point must be isolated within a segment of @xmath12 ,",
    "whose length is a linear function of @xmath11 .",
    "moreover , each segment containing a change point must be `` sufficiently far '' from the rest of the change points , w where `` sufficiently far '' means within a distance linear in @xmath11 .",
    "this may be obtained by dividing @xmath12 into consecutive non - overlapping segments , each of length @xmath127 with @xmath128 for some @xmath129 $ ] where @xmath116 is given by . since , by definition , @xmath116 specifies the minimum separation of the change point parameters , the resulting partition has the property that every three consecutive segments of the partition contain _ at most one _ change point .",
    "however , @xmath116 is not known to the algorithm . moreover , even if @xmath130 , not all segments in the partition contain a change point .",
    "the algorithm uses the score function @xmath131 given by ( [ defn : delta ] ) to identify the segments that contain change points . as for @xmath116 , instead of trying to find it , the algorithm produces many partitions of @xmath12 ( using different guesses of @xmath116 ) , and produces a set of candidate change point estimates using each of them .",
    "finally , a weighted combination of the candidate estimates is produced .",
    "the weights are designed to converge to zero on iterations where our guess for a lower bound on @xmath116 is incorrect .",
    "this last step of combining multiple estimates may be reminiscent of prediction with expert advice , @xcite , with the important difference that performance ( loss ) can not be measured directly in our setting .",
    "* input : * @xmath132 , number @xmath7 of change points * initialize : * @xmath133 [ gamma : kk ] [ alg : estim ] * return : * @xmath134    algorithm  [ alg : kk ] works as follows . given @xmath135 ,",
    "it iterates over @xmath136 and at each iteration , produces a guess @xmath137 as a lower - bound on @xmath116 . for every fixed @xmath138 , a total of @xmath1 grids",
    "are generated , each composed of evenly - spaced boundaries @xmath139 , that are @xmath140 apart for @xmath141 .",
    "the grids have distinct starting positions @xmath142 for @xmath143 .",
    "( as shown in the proof of theorem  [ thm : kk ] , this ensures that for a fixed @xmath138 at least one of the grids for some @xmath144 has the property that the change points are not located at the boundaries . ) among the segments of the grid , @xmath7 segments of highest _ score _ , @xmath131 are selected ; @xmath131 is given by ) .",
    "the single - change point estimator @xmath126 is used to seek a candidate change point parameter in each of the selected segments .",
    "the weighted combination is given as the final estimate for every change point parameter @xmath4 .",
    "two sets of weights are used , namely , an iteration weight @xmath145 and a score @xmath146 .",
    "the former gives lower precedence to finer grids . to calculate the latter , at each iteration on @xmath138 and @xmath147 , for every fixed @xmath148 ,",
    "a partition of the grid is considered , which is composed of the boundaries @xmath149 .",
    "each partition , in turn , specifies a set of non - overlapping consecutive segments of length @xmath150 , for each of which a parameter @xmath151 is calculated as the @xmath152 highest intra - distance value @xmath153 of its segments ; the performance weight @xmath146 is obtained as @xmath154 .",
    "( as shown in the proof , @xmath146 converges to zero on the iterations where either @xmath155 or there exists some change point on the boundary of one of the segments of the partition . )    [ thm : kk ] algorithm  [ alg : kk ] is asymptotically consistent , provided that the correct number @xmath7 of change points is given : @xmath156    the proof is given in section  [ sec : proofs ] ; an intuitive description follows .",
    "first observe that the empirical estimate @xmath61 of the distributional distance is consistent .",
    "thus , the empirical distributional distance between a given pair of sequences converges to the distributional distance between their generating processes . from this",
    "we can show that the intra - subsequence distance @xmath131 corresponding to the segments in the grid that do not contain a change point converges to zero .",
    "this is established in lemma  [ prelem : nochpt : ii ] , provided in section  [ sec : proofs ] . on the other hand ,",
    "since the generated grid becomes finer as a function of @xmath138 , from some @xmath138 on , we have @xmath157 so that every three consecutive segments of the grid contain _ at most _ one change point . in this case , for every segment that contains a change point , the single - change point estimator @xmath126 produces an estimate that , for long enough segments , becomes arbitrarily close to the true change point .",
    "this is shown in lemma  [ lem2 ] , provided in section  [ sec : proofs ] . moreover , for large enough @xmath11 , the performance scores associated with these segments are bounded below by some non - zero constant .",
    "thus , the @xmath7 segments of highest @xmath131 , each contain a change point which can be estimated consistently using @xmath126 .",
    "however , the estimates produced at a given iteration for which @xmath158 may be arbitrarily bad . moreover ,",
    "even for @xmath159 , an appropriate grid to provide consistent estimates must be such that no change point is exactly at the start or at the end of a segment .",
    "however , can not identify such grids directly .",
    "we make the following observation .",
    "the following observation is key to achieving this objective indirectly .",
    "+ consider the partitioning of @xmath12 into @xmath7 consecutive segments where there exists at least one segment with more than one change point .",
    "since there are exactly @xmath7 change points , there must exist at least one segment in this partitioning that does not contain any change points at all .",
    "as follows from lemma  [ prelem : nochpt : i ] , the segment that contains no change points has an intra - subsequence distance @xmath119 that converges to  @xmath160 . on the iterations for which @xmath161 ,",
    "at least one of the three partitions has the property that among every set of @xmath7 segments in the partition , there is _ at least _",
    "one segment that contains no change points . in this case",
    ", @xmath119 corresponding to the segment without a change point converges to  @xmath160 .",
    "the same argument holds for the case where @xmath162 , while at the same time a change point happens to be located exactly at the boundary of a segment in the grid .",
    "observe that for a fixed @xmath138 , the algorithm forms a total of @xmath1 different grids , with the same segment size , but distinct starting points @xmath163 .",
    "since there are @xmath7 change points , for all @xmath138 such that @xmath164 there exists at least one appropriate grid ( for some @xmath165 ) , that simultaneously contains all the change points within its segments . in this case",
    ", @xmath166 converges to a non - zero constant .",
    "the final estimate @xmath9 for each change point parameter @xmath10 is obtained as a weighted sum of the candidate estimates produced at each iteration .",
    "two sets of weights are used in this step , namely @xmath146 and @xmath167 , whose roles can be described as follows .    1 .",
    "@xmath146 is used to penalize for the ( arbitrary ) results produced on iterations on @xmath168 and @xmath144 where , either @xmath169 , or while we have @xmath164 there exists some @xmath10 for some @xmath170 such that @xmath171 .",
    "as discussed , @xmath146 converges to zero only on these iterations , while it is bounded below by a non - zero constant on the rest .",
    "@xmath167 is used to give precedence to estimates sought in longer segments .",
    "since the grids are finer for larger @xmath138 , at some higher iterations the segments may not be long enough to produce consistent estimates .",
    "thus , if @xmath11 is large enough , the final estimates @xmath172 converge to the true parameters , @xmath4 .",
    "* computational complexity .  *",
    "the proposed method can be easily and efficiently implemented . for a fixed @xmath138 , a total of @xmath173 distance calculations",
    "are done on segments of length @xmath174 , and a total of @xmath175 distance calculations are done to estimate each change point ; the procedure is repeated @xmath1 times . by remark  [ rem1 ] , and summing over @xmath168 iterations , the overall complexity is of order @xmath176 .",
    "the rest of the computations are of negligible order .",
    "in this section we evaluate our method using synthetically generated data .",
    "* generating the synthetic time - series . *   in order to generate the data we use stationary ergodic process distributions that do not belong to any  simpler \" general class of time - series , and can not be approximated by finite state models , such as hidden markov processes with finite state - spaces .",
    "moreover , the single - dimensional marginals of all distributions are the same throughout the generated sequence . to the best of our knowledge",
    ", none of the existing algorithms are designed to work in this scenario , and as a result are bound to fail under this framework .",
    "hence , we can not compare our method against other change point estimation algorithms .",
    "we generate a segment @xmath177 as follows .",
    "+    1 .   fix a parameter @xmath178 and two uniform distributions @xmath179 and @xmath180 .",
    "2 .   let @xmath181 be drawn randomly from @xmath182 $ ] .",
    "3 .   for each @xmath183 obtain @xmath184 ; draw @xmath185 from @xmath186 .",
    "set @xmath187    if @xmath188 is irrational by a long double with a long mantissa . ]",
    "this produces a real - valued stationary ergodic time - series .",
    "similar families are commonly used as examples in this framework , ( e.g. @xcite ) .    for the purpose of our experiment",
    ", we fixed four parameters @xmath189 , @xmath190 and @xmath191 ( with long mantissae ) to correspond to @xmath192 different process distributions ; we used uniform distributions @xmath179 and @xmath180 over @xmath193 $ ] and @xmath194 $ ] respectively , ( deliberately chosen to overlap ) . to produce @xmath195 we randomly generated @xmath196 change point parameters @xmath4 at least @xmath197 apart .",
    "every segment of length @xmath198 with @xmath111 was generated with @xmath199 , and using @xmath179 and @xmath180 . by this procedure ,",
    "the single - dimensional marginals are the same throughout @xmath12 .",
    "figure  [ fig : synth ] demonstrates the average estimation error - rate of algorithm  [ alg : kk ] as a function of the sequence length @xmath11 .",
    "we calculate the error rate as @xmath200",
    "in this section , we prove the main consistency result .",
    "the proof depends upon some technical lemmas stated below .",
    "[ prelem : nochpt : i ] let @xmath132 be generated by a stationary ergodic process @xmath34 . for all @xmath178",
    "the following statements hold with @xmath34-probability 1 :    1 .",
    "[ prelem : nochpt : i1 ] @xmath201 for every @xmath202 .",
    "[ prelem : nochpt : i1d ] @xmath203 .",
    "[ prelem : nochpt : ii ] @xmath204    to prove part we proceed as follows .",
    "assume by way of contradiction that the statement is not true .",
    "therefore , there exists and some @xmath205 , @xmath202 and sequences @xmath206 and @xmath207 with @xmath208 , such that with probability @xmath209 we have @xmath210 using the definition of @xmath211 it is easy to see that the following inequalities hold @xmath212 for every @xmath213 and all @xmath214 .",
    "fix @xmath215 . for each @xmath216",
    "we can find a finite subset @xmath217 of @xmath218 such that @xmath219 for every @xmath220 , there exists some @xmath221 such that for all @xmath222 with probability one we have @xmath223 define @xmath224 and let @xmath225 ; observe that @xmath226 .",
    "let @xmath227 consider the sequence @xmath228 .    1 .   for every @xmath216 we have @xmath229 2 .   on the other hand , by all @xmath230 we have @xmath231    increase @xmath232 if necessary to have @xmath233 for all @xmath234 and @xmath235",
    "for all @xmath230 we obtain @xmath236 where follows from ; follows from and ; and follows from , , , summing over the probabilities , and observing that @xmath237 for all @xmath238 . observe that holds for any @xmath215 , and it particular it holds for @xmath239 .",
    "therefore , we have @xmath240 contradicting .",
    "part follows .",
    "fix @xmath241 , @xmath178 and @xmath242 .",
    "we can find some @xmath202 such that @xmath243 by part of lemma  [ prelem : nochpt : i ] , there exists some @xmath232 such that for all @xmath230 we have @xmath244 + from and , for all @xmath230 we have @xmath245 and part of the lemma follows .",
    "fix @xmath241 , @xmath178 . without loss of generality assume that @xmath246 .",
    "observe that for every @xmath247 we have @xmath248 .",
    "therefore , by there exists some @xmath232 such that for all @xmath249 we have @xmath250 it remains to use the definition of @xmath131 ( [ defn : delta ] ) and the triangle inequality to observe that @xmath251 for all @xmath230 , and follows .",
    "[ prelem : chpt : dist ] assume that a sequence @xmath121 has a change point @xmath252 for some @xmath253 so that the segments @xmath254 , @xmath255 are generated by two different process distributions @xmath34",
    ", @xmath256 respectively .",
    "if @xmath34 , @xmath256 are both stationary ergodic then with probability one , for every @xmath257 we have    1 .",
    "[ prelem : chpt : dist : i ] @xmath258 2 .",
    "[ prelem : chpt : dist : iii ] @xmath259    fix @xmath241 , @xmath253 , @xmath257 .",
    "there exists some @xmath202 such that @xmath260 to prove part we proceed as follows . by the definition of @xmath211 given by , for all",
    "@xmath261 and all @xmath262 we have @xmath263 therefore , for all @xmath261 and all @xmath262 we obtain @xmath264 where the first inequality follows from the fact that @xmath265 , the second inequality follows from the definition of @xmath211 given by @xmath266 and the third inequality follows from .",
    "observe that @xmath267 for all @xmath268 .",
    "therefore , by part of lemma  [ prelem : nochpt : i ] , there exists some @xmath269 such that for all @xmath270 we have @xmath271 similarly , @xmath272 for all @xmath273 .",
    "therefore , by part of lemma  [ prelem : nochpt : i ] , there exists some @xmath274 such that for all @xmath275 we have @xmath276 note that @xmath277 for all @xmath261 .",
    "therefore , we have @xmath278 for all @xmath279 , @xmath268 and @xmath273 we have @xmath280 let @xmath281 . by , , , and , for all @xmath230 we have @xmath282 finally , by and for all @xmath230 we obtain @xmath283 and part of lemma",
    "[ prelem : chpt : dist ] follows .",
    "the proof of the second part is analogous .",
    "[ lem2 ] consider a sequence @xmath284 with @xmath7 change points .",
    "let @xmath285 , be a sequence of indices with @xmath286 for some @xmath178 , such that @xmath287 for some @xmath242 .    1 .",
    "[ lem2:i ] with probability one we have @xmath288 where @xmath289 denotes the minimum distance between the distinct distributions that generate @xmath12 .",
    "[ lem2:ii ] assume that we additionally have @xmath290 \\subseteq [ \\theta_{k-1},\\theta_{k+1}]\\ ] ] where @xmath291 denote the elements of @xmath292 that appear immediately to the left and to the right of @xmath5 respectively . with probability",
    "one we obtain @xmath293 ) .",
    "fix some @xmath170 .",
    "define @xmath294 . following the definition of @xmath295 given by we have @xmath296 to prove part of lemma  [ lem2 ] ,",
    "we show that for large enough @xmath11 , with probability @xmath297 we have @xmath298 let @xmath299 .",
    "to prove for the case where @xmath300 we proceed as follows .",
    "by assumption of the lemma , we have @xmath301 hence , it is easy to see that @xmath302 fix @xmath241 .",
    "observe that as follows from the definition of @xmath303 and @xmath304 , and our assumption that @xmath300 , the segment @xmath305 is fully generated by @xmath306 . by ,",
    "the condition of part   of lemma  [ prelem : nochpt : i ] hold for @xmath305 .",
    "therefore , there exists some @xmath307 such that for all @xmath249 we have @xmath308 similarly , from and we have @xmath309 by and , the conditions of part of lemma  [ prelem : chpt : dist ] hold for @xmath310 .",
    "therefore , there exists some @xmath311 such that for all @xmath312 we have @xmath313 by we have @xmath314 moreover , we obtain @xmath315 where the inequality follows from ( [ lem2:fract ] ) and the definition of @xmath289 as the minimum distance between the distributions . let @xmath316 . for all @xmath230",
    "we obtain @xmath317 where and follow from applying the triangle inequality on @xmath61 , follows from and , and follows from .",
    "since holds for every @xmath215 , this proves ( [ objective1 ] ) in the case where @xmath300 . the proof for the case where @xmath318 is analogous .",
    "since holds for every @xmath170 , part of lemma  [ lem2 ] follows .",
    "+ ( [ lem2:ii ] ) .",
    "fix some @xmath170 .",
    "following the definition of @xmath126 given by ( [ defn : phi ] ) we have @xmath319 to prove part of the lemma , it suffices to show that for every @xmath320 with probability @xmath297 , for large enough @xmath11 , we have @xmath321 for all @xmath322 . to prove ( [ objective ] ) for @xmath323 we proceed as follows .",
    "fix some @xmath324 and @xmath241 .",
    "first note that for all @xmath325 we have @xmath326 note that by the sequence @xmath327 is a subsequence of @xmath328 .",
    "consider the segment @xmath327 .",
    "observe that by the conditions of part of lemma  [ prelem : nochpt : i ] are satisfied by all @xmath329 .",
    "therefore , there exists some @xmath307 such that for all @xmath249 we have @xmath330 similarly , consider @xmath331 .",
    "observe that by definition of @xmath304 we have @xmath332 ; moreover , by the segment is a subsequent of @xmath333 .",
    "therefore , by part of lemma  [ prelem : nochpt : i ] , there exists some @xmath311 such that for all @xmath312 we have @xmath334 by , there is a single change point @xmath335 within @xmath336 .",
    "therefore , every @xmath337 has a linear distance from @xmath338 , i.e. @xmath339 for all @xmath337 . on the other hand , @xmath340 .",
    "therefore by part of lemma  [ prelem : chpt : dist ] there exists some @xmath341 such that @xmath342 let @xmath343 . by ( [ lem2ii : firstdiff1 ] ) , ( [ lem2ii : firstdiff2 ] ) and the subsequent application of the triangle inequality on @xmath61 for all @xmath230 we obtain @xmath344 by applying the triangle inequality on @xmath61 , for all @xmath230 we obtain @xmath345 where follows from , and follows from .",
    "we also have @xmath346 where the inequality follows from and the definition of @xmath289 as the minimum distance between the distributions that generate the data .",
    "finally , from ( [ lem2ii : firsthalf ] ) , ( [ lem2ii:2ndhalf ] ) and ( [ lem2ii : dr ] ) for all @xmath230 we obtain , @xmath347 since ( [ lem2ii : final ] ) holds for every @xmath215 , this proves ( [ objective ] ) for @xmath323 . the proof for the case where @xmath348 is analogous .",
    "since ( [ objective ] ) holds for every @xmath170 , part follows .    on each iteration",
    "@xmath349 the algorithm produces a set of estimated change points .",
    "we show that on some iterations these estimates are consistent , and that estimates produced on the rest of the iterations are negligible .",
    "we partition the set of iterations into three sets as described below .",
    "first recall that for every @xmath168 and @xmath144 the algorithm generates a grid of boundaries @xmath350 such that for all @xmath168 and @xmath144 we have @xmath351 therefore , the segments @xmath352 have lengths that are linear functions of @xmath11 .",
    "more specifically , for @xmath136 and @xmath144 define @xmath353 ( note that @xmath354 can also be zero . ) for all @xmath355 we have @xmath356 such that @xmath357 this first subset of the set of iterations @xmath136 corresponds to the higher iterations where @xmath137 is too small . in this case",
    "the resulting grids are too fine , and the segments may not be long enough for the estimates to be consistent .",
    "these iterations are penalized by small weights @xmath167 , so that the corresponding candidate estimates become negligible .",
    "* the second subset corresponds to the iterations where * a. *  @xmath358 $ ] _ and _ * b. *  the segments are long enough for the candidate change point parameter estimates to be consistent .",
    "let @xmath359 where @xmath116 defined by specifies the minimum separation of the change points . for all @xmath360 we have @xmath361 .",
    "therefore , at every iteration on @xmath360 and @xmath144 , for every change point @xmath362 we have @xmath363 \\subseteq [ \\theta_{k-1},\\theta_{k+1}]\\ ] ] where @xmath364 and @xmath365 are defined in lemma  [ lem2 ] .",
    "we further partition the set of iterations on @xmath144 into two subsets as follows .",
    "for every fixed @xmath366 we identify a subset @xmath367 of the iterations on @xmath368 at which the change point parameters @xmath4 are estimated consistently and the performance scores @xmath146 are bounded below by a nonzero constant .",
    "moreover , we show that if the set @xmath369 is nonempty , the performance scores @xmath146 for all @xmath366 and @xmath370 are arbitrarily small .    1 .   to define @xmath367 we proceed as follows . for every @xmath4 we can uniquely define @xmath371 and @xmath372 so that @xmath373 .",
    "therefore , for any @xmath374 with @xmath375 , we have @xmath376 . observe that we can only have @xmath7 distinct residues @xmath377 . therefore , any subset of @xmath378 with @xmath1 elements , contains at least one element @xmath379 such that @xmath380 .",
    "it follows that for every @xmath381 there exists at least one @xmath144 such that @xmath382 . for every @xmath383 ,",
    "define @xmath384 let @xmath385 and define @xmath386 .",
    "note that @xmath387 . by , and hence part of lemma  [ lem2 ] , for every @xmath383 there exists some @xmath388 such that for all @xmath389 we have @xmath390 where @xmath289 denotes the minimum distance between the distinct distributions that generate the data . recall that , as specified by algorithm  [ alg : kk ] we have @xmath391 .",
    "hence by ( [ thm : constj1 ] ) for all @xmath230 we have @xmath392 by lemma  [ lem2 ] there exists some @xmath393 such that for all @xmath394 we have @xmath395 2 .",
    "define @xmath369 for @xmath383 .",
    "it may be possible for the set @xmath396 to be nonempty on some iterations on @xmath366 . without loss of generality ,",
    "define @xmath397 for all @xmath366 with @xmath398 .",
    "observe that by definition , for all @xmath366 such that @xmath399 , we have @xmath400 where @xmath354 is given by .",
    "this means that on each of these iterations , there exists some @xmath335 for some @xmath170 such that @xmath401 for some @xmath402 . since @xmath130 for all @xmath383",
    ", we have @xmath403 and @xmath404 .",
    "therefore , by part of lemma  [ prelem : nochpt : i ] , there exists some @xmath405 such that for all @xmath406 we have , @xmath407 thus , for every @xmath383 and all @xmath406 we have @xmath408    * step 3 . *",
    "consider the set of iterations , @xmath409 . recall that it is desired for a grid to be such that every three consecutive segments contain at most one change point .",
    "this property is not satisfied for @xmath410 , since by definition on these iterations we have @xmath411 .",
    "we show that for all these iterations , the performance score @xmath412 becomes arbitrarily small . for all @xmath413 and @xmath143 , define the set of intervals @xmath414 and consider its partitioning into @xmath415 . observe that , by construction for every fixed @xmath416 , every pair of indices @xmath417 specifies a segment @xmath418 of length @xmath419 and the elements of @xmath420 index non - overlapping segments of @xmath12 . since for all @xmath409 we have @xmath411 , at every iteration on @xmath421 and @xmath422 , there exists some @xmath423 such that the segment @xmath418 contains more than one change point . since there are exactly @xmath7 change points , in at least one of the partitions @xmath424 for some @xmath148 we have that within any set of @xmath7 segments indexed by a subset of @xmath7 elements of @xmath424 , there exists at least one segment that contains no change points .",
    "therefore , by ( [ thm : lem1cond ] ) , ( [ thm : lineardist ] ) and hence lemma  [ prelem : nochpt : ii ] , for every @xmath421 there exists some @xmath425 such that for all @xmath426 we have @xmath427 let @xmath428 and @xmath429 .",
    "let @xmath430 . by , and that @xmath431 , for all @xmath230 we have @xmath432 recall that by definition we have @xmath433 which , as follows from is nonzero .",
    "therefore we have @xmath434 by and for all @xmath230 we have @xmath435 note that @xmath436 and that @xmath437 . therefore , by and for all @xmath230 we obtain @xmath438 similarly , from and we obtain @xmath439 let @xmath440 . by , ,",
    "and we have @xmath441 since the choice of @xmath442 is arbitrary , the statement of the theorem follows .",
    "we have presented an asymptotically consistent method to locate the changes in highly dependent time - series data .",
    "the considered framework is very general and as such is suitable for real - world applications .",
    "note that , in the considered setting , rates of convergence ( even of frequencies to respective probabilities ) are provably impossible to obtain .",
    "therefore , unlike in the traditional settings for change - point analysis , the algorithms developed for this framework are forced not to rely on any rates of convergence .",
    "we see this as an advantage of the framework as it means that the algorithms are applicable to a much wider range of situations . at the same time",
    ", it may be interesting to derive the rates of convergence of the proposed algorithm under stronger assumptions ( e.g. , i.i.d .   data , or some mixing conditions ) .",
    "we conjecture that our method is optimal ( up to some constant factors ) in such settings ( although it is clearly suboptimal under parametric assumptions ) ; however , this is left as future work ."
  ],
  "abstract_text": [
    "<S> given a heterogeneous time - series sample , it is required to find the points in time ( called change points ) where the probability distribution generating the data has changed . </S>",
    "<S> the data is assumed to have been generated by arbitrary , unknown , stationary ergodic distributions . </S>",
    "<S> no modeling , independence or mixing are made . </S>",
    "<S> a novel , computationally efficient , nonparametric method is proposed , and is shown to be asymptotically consistent in this general framework ; the theoretical results are complemented with experimental evaluations . </S>"
  ]
}