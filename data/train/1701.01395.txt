{
  "article_text": [
    "when data are missing not at random ( mnar ) ( @xcite ) , appropriate likelihood - based inference requires explicit models for the _ full - data distribution _ , i.e. , the joint distribution of the study variables and their missingness indicators . because of the missing data , this distribution is not uniquely identified from the observed data alone ( @xcite ) . to enable inference",
    ", analysts must impose restrictions on the full - data distribution .",
    "such assumptions generally are untestable ; however , a minimum desideratum is that they result in a unique full - data distribution for the _ observed - data distribution _ at hand , i.e. , the distribution that can be identified from the incomplete data .",
    "we present a strategy for constructing identifiable full - data distributions with nonignorable missing data . in its most general form ,",
    "the strategy is to expand the observed - data distribution sequentially by identifying parts of the full - data distribution associated with blocks of variables , one block at a time .",
    "this partitioning of the variables allows analysts to specify different missingness mechanisms in the different blocks ; for example , use the missing at random ( mar , @xcite ) assumption for some variables and a nonignorable missingness assumption for the rest to obtain a partially ignorable mechanism ( @xcite ) .",
    "we ensure that the resulting full - data distributions are _ non - parametric saturated _",
    "( nps , @xcite ) , that is , their implied observed - data distribution matches the actual observed - data distribution , as detailed in section [ ss : nps ] .",
    "related approaches to partitioning variables with missing data have appeared previously in the literature .",
    "@xcite proposed to model blocks of study variables and their missingness indicators in a sequential manner ; however , their approach does not guarantee identifiability of the full - data distribution .",
    "@xcite mentioned the possibility of treating the missingness in blocks of variables differently , but they do not provide results on identification .",
    "@xcite proposed the group permutation missingness mechanism , which assumes mar sequentially for blocks of variables and results in a nps model .",
    "this is a particular case of our more general procedure , as we describe in section [ ss : robins ] .",
    "the remainder of the article is organized as follows . in section [",
    "s : background ] , we describe notation and provide more details on the nps property . in section [ s :",
    "seqident ] , we introduce our strategy for identifying a full - data distribution in a sequential manner . in section [ s : examples ] we present some examples of how to use this strategy for the case of two categorical study variables , for the construction of partially ignorable mechanisms , and for sensitivity analyses .",
    "finally , in section [ s : disc ] we discuss possible future uses of our identifying approach .",
    "let @xmath0 denote @xmath1 random variables taking values on a sample space @xmath2 .",
    "let @xmath3 be the missingness indicator for variable @xmath4 , where @xmath5 when @xmath6 is missing and @xmath7 when @xmath6 is observed .",
    "let @xmath8 , which takes values on @xmath9 .",
    "let @xmath10 be a dominating measure for the distribution of @xmath11 , and let @xmath12 represent the product measure between @xmath10 and the counting measure on @xmath9 .",
    "the full - data distribution is the joint distribution of @xmath11 and @xmath13 .",
    "we call its density @xmath14 with respect to @xmath12 the _ full - data density_. in practice , the full - data distribution can not be recovered from sampled data , even with an infinite sample size .",
    "an element @xmath15 is called a _",
    "missingness pattern_. given @xmath16 we define @xmath17 to be the indicator vector of observed variables , where @xmath18 is a vector of ones of length @xmath1 .",
    "for each @xmath19 , we define @xmath20 to be the missing variables and @xmath21 to be the observed variables , which have sample spaces @xmath22 and @xmath23 , respectively .",
    "the observed - data distribution is the distribution involving the observed variables and the missingness indicators , which has density @xmath24 , where @xmath25 represents a generic element of the sample space , and we define @xmath26 and @xmath27 similarly as with the random vectors .    an alternative way of representing the observed - data distribution is by introducing the _ materialized variables _ @xmath28 , where @xmath29 and `` @xmath30 '' is a placeholder for missingness .",
    "the sample space @xmath31 of each @xmath32 is the union of @xmath33 and the sample space @xmath34 of @xmath6 .",
    "the materialized variables contain all the observed information : if @xmath35 then @xmath6 was not observed , and if @xmath36 for any value @xmath37 then @xmath6 was observed and @xmath38 .",
    "given @xmath16 and @xmath39 , we define @xmath40 , such that @xmath41 and @xmath42 , where @xmath43 is a vector with the appropriate number of @xmath30 symbols . for example , if @xmath44 and @xmath45 , then @xmath46 . the event @xmath47 is equivalent to @xmath48 and @xmath49 , which implies that the distribution of @xmath50 is equivalent to the observed - data distribution .",
    "therefore , with some abuse of notation , the observed - data density can be written in terms of @xmath50 , that is @xmath51 . when there is no need to refer to the @xmath19 and @xmath27 that define @xmath52 , we simply write @xmath53 to denote the observed - data density evaluated at an arbitrary point .    in what follows we often write @xmath54 simply as @xmath55 , @xmath53 as @xmath56 , and likewise for other expressions , provided that there is no ambiguity . for the sake of simplicity , we use `` @xmath14 '' for technically different functions , but their actual interpretations should be clear from the arguments passed to them .",
    "for example , we denote the _ missingness mechanism _ as @xmath57 , or simply @xmath58 .",
    "since the true joint distribution of @xmath11 and @xmath13 can not be identified from observed data alone , we need to work under the assumption that the full - data distribution falls within a class defined by a set of restrictions .    consider a class of full - data distributions @xmath59 defined by a set of restrictions @xmath60 .",
    "we say that the class @xmath59 is identifiable if there is a mapping from the set of observed - data distributions to @xmath59 .",
    "if we only require identifiability from a set of full - data distributions , two different observed - data distributions could map to the same full - data distribution .",
    "@xcite introduced the stricter concept of a class of full - data distributions being non - parametric saturated  also called non - parametric identified ( @xcite ) .",
    "consider a class of full - data distributions @xmath59 defined by a set of restrictions @xmath60 .",
    "we say that the class @xmath59 is non - parametric saturated if there is a _ one - to - one _ mapping from the set of observed - data distributions to @xmath59 .",
    "the set @xmath60 of restrictions , or identifiability assumptions , that define a nps class allow us to build a full - data distribution , say with density @xmath61 , from an observed - data distribution with density @xmath62 , so that @xmath63 , where by definition @xmath64 . in terms of @xmath50 ,",
    "the nps property is expressed as @xmath65 .",
    "nps is a desirable property , particularly for comparing inferences under different approaches to handling nonignorable missing data .",
    "when two missing data models satisfy nps , we can be sure that any discrepancies in inferences are due entirely to the different assumptions on the non - identifiable parts of the full - data distribution .",
    "in contrast , without nps , it can be difficult to disentangle what parts of the discrepancies are due to the identifying assumptions and what parts are due to differing constraints on the observed - data distribution .",
    "thus , nps greatly facilitates sensitivity analysis ( @xcite ) .    for a given @xmath19",
    ", we refer to the conditional distribution of the missing study variables given the observed data as the _ missing - data distribution_also known as the extrapolation distribution ( @xcite)with density @xmath66 .",
    "these distributions correspond to the non - identifiable parts of the full - data distribution .",
    "a nps approach is equivalent to a recipe for building these distributions from the observed - data distribution without imposing constraints on the latter .",
    "nps models can be constructed in many ways .",
    "for example , in pattern mixture models , one can use the complete - case missing - variable restriction ( @xcite ) , which sets @xmath67 , for all @xmath16 .",
    "although @xcite considered parametric models for each @xmath68 , this does not have to be the case , and therefore pattern mixture models can be nps .",
    "another example is the permutation missingness model of @xcite , which for a specific ordering of the study variables assumes that the probability of observing the @xmath69th variable depends on the previous study variables and the subsequent observed variables .",
    "the group permutation missingness model of @xcite is an analog of the latter for groups of variables and is also nps .",
    "@xcite introduced a missingness mechanism where each variable and its missingness indicator are conditionally independent given the remaining variables and missingness indicators , which leads to a nps model .",
    "@xcite proposed a nps approach based on discrete choice models .",
    "finally , we note that mar models also can be nps , as shown by @xcite .",
    "we consider the @xmath1 variables as divided into @xmath70 blocks , @xmath71 , where @xmath72 , which contains @xmath73 variables . as our results only concern the identification of full - data distributions starting from an observed - data distribution , we assume that @xmath74 is known .",
    "the identification strategy consists of specifying a sequence of assumptions @xmath75 , one for each block of variables , where each @xmath76 allows us to identify the conditional distribution of @xmath77 and @xmath78 given @xmath79 , @xmath80 , and a carefully chosen subset of the missingness indicators @xmath81 described below .",
    "we first provide a general description of how @xmath75 allow us to identify parts of the full - data distribution in a sequential manner , and then in theorem [ th : ident ] present the formal identification result .",
    "we now present the steps needed to implement the identification strategy .",
    "a graphical summary of the procedure is provided in figure [ fig : seqident ] .",
    "_ step 1_. write @xmath82 .",
    "consider an identifiability assumption @xmath83 on the distribution of @xmath84 and @xmath85 given @xmath86 that allows us to obtain a distribution with density @xmath87 with the nps property @xmath88 .",
    "from this we can define @xmath89 .",
    "_ step 2_. suppose we divide the @xmath90 variables in @xmath84 into two sets indexed by @xmath91 and @xmath92 , where @xmath93 and @xmath94 ; see remark 1 below for discussion of why one might want to do so .",
    "let @xmath95 and @xmath96 be the corresponding missingness indicators .",
    "we can write @xmath97 , where @xmath98 .",
    "consider an identifiability assumption @xmath99 on the distribution of @xmath100 and @xmath101 given @xmath102 and @xmath103 that allows us to obtain a distribution with density @xmath104 with the nps property @xmath105 . from this",
    "we can define @xmath106 the notation @xmath107 emphasizes that the distribution relies on @xmath83 and @xmath99 .",
    "_ step @xmath108_. at the end of the @xmath69th step we have @xmath109 .",
    "let @xmath110 , @xmath111 , and @xmath112 and @xmath113 be the corresponding missingness indicators .",
    "we can write @xmath114 , where @xmath115 now , consider an identifiability assumption @xmath116 on the distribution of @xmath117 and @xmath118 given @xmath119 and @xmath120 that allows to obtain a distribution with density @xmath121 with the nps property @xmath122 . from this we can define @xmath123    _ step @xmath70_. for the final step , assumption @xmath124 is on the distribution of @xmath125 and @xmath126 given @xmath127 and @xmath128 .",
    "following the previous generic identifying step , we obtain @xmath129 . we can obtain the implied distribution of the study variables , with density @xmath130 , from this last equation .",
    "= [ rectangle , rounded corners , minimum width=3 cm , minimum height=.8cm , text centered , draw = black , fill = blue!10 ] = [ rectangle , rounded corners , minimum width=3 cm , minimum height=.8cm , text centered ] = [ thick,->,>=stealth ] ( step0 ) [ startstop ] @xmath56 ; ( step1 ) [ startstop , below of = step0 ] @xmath131 ; ( step2 ) [ startstop , below of = step1 ] @xmath132 ; ( step3 ) [ empty , below of = step2 ] @xmath133 ; ( step4 ) [ startstop , below of = step3 ] @xmath134 ; ( step5 ) [ startstop , below of = step4 ] @xmath135 ;    ( step0 ) ",
    "node[anchor = west ] @xmath136 ( step1 ) ; ( step1 ) ",
    "node[anchor = west ] @xmath137 ( step2 ) ; ( step2 ) ",
    "node[anchor = west ] @xmath138 ( step3 ) ; ( step3 ) ",
    "node[anchor = west ] @xmath139 ( step4 ) ; ( step4 ) ",
    "node[anchor = west ] @xmath140 ( step5 ) ;    the main characteristic of the @xmath141 subsets is that if an index does not appear in @xmath142 , then it can not appear in @xmath143 , unless it is one of @xmath144 .",
    "the flexibility in the choosing of these subsets gives flexibility in the setting up of the identifiability assumptions : different versions of our identification approach can be obtained by making assumptions conditioning on different subsets of the missingness indicators .",
    "as long as the @xmath141 subsets satisfy @xmath145 , theorem [ th : ident ] guarantees that the final full - data distribution is nps .",
    "the sequence for @xmath146 follows the order of the blocks @xmath147 . in many cases",
    "these blocks may not have a natural order .",
    "different orderings of the blocks lead to different sets of assumptions , thereby leading to different final full - data distributions and implied distributions of the study variables . to clarify this point ,",
    "suppose that we have three blocks of variables : demographic variables @xmath148 , income variables @xmath149 , and health - related variables @xmath150 .",
    "when @xmath148 is first in the order , @xmath83 concerns the distribution of @xmath148 and @xmath151 given @xmath152 and @xmath153 ; likewise , when @xmath149 is first in the order , @xmath83 concerns the distribution of @xmath149 and @xmath154 given @xmath155 and @xmath153 .",
    "similarly , @xmath99 and @xmath156 also will change depending on the order of the variables , thereby implying changes in the final full - data distribution .",
    "the previous presentation makes it clear that the identifying assumptions @xmath146 allow us to identify @xmath135 , and furthermore , @xmath157 for each @xmath158 , although each of these conditional densities remains unused after step @xmath69 in the procedure .",
    "a full - data distribution with density @xmath159 that encodes @xmath146 can be expressed as @xmath160 where the second factor can be written as @xmath161 , with @xmath162 , and @xmath163 . from the definition of the sets @xmath164 and @xmath141 , it is easy to see that @xmath165 , and therefore we can rewrite @xmath166 .    the sequential identification procedure does not identify any @xmath167 , but only @xmath157",
    ", that is , it identifies the distribution of @xmath113 given the variables @xmath168 , the missingness indicators @xmath169 , and the materialized variables @xmath170 , but not given the missing variables among @xmath171 according to @xmath172 . nevertheless , the full specification of @xmath167 is irrelevant given that any such conditional distribution that agrees with @xmath157 would lead to the same @xmath130 .",
    "one such distribution is one where @xmath173 that is , where the conditional distribution of @xmath113 given @xmath174 and @xmath172 does not depend on the missing variables among @xmath171 according to @xmath172 .",
    "this guarantees the existence of a full - data distribution with density @xmath175 which encodes the assumptions @xmath146 .",
    "theorem [ th : ident ] guarantees that this construction leads to nps full - data distributions .",
    "[ th : ident ] let @xmath176 be a sequence of subsets such that @xmath145 .",
    "let @xmath146 be a sequence of identifying assumptions , with each @xmath76 being an assumption on the conditional distribution of @xmath77 and @xmath78 given @xmath177 , and @xmath178 , such that for a given density @xmath179 , it allows the construction of a density @xmath180 with the nps property @xmath181 then , given an observed - data density @xmath56 , there exists a full - data density @xmath159 that encodes the assumptions @xmath146 and satisfies the nps property @xmath182 .",
    "we explained how assumptions @xmath146 along with the extra assumption in lead to the full - data density in .",
    "we now show the nps property of . to start , we integrate over the missing variables in @xmath125 according to @xmath126 . since none of the factors in @xmath183 depend on these missing variables , we obtain @xmath184    similarly , we now integrate over the missing variables in @xmath185 according to @xmath186 .",
    "given that none of the factors in @xmath187 , depend on these missing variables , and given the way @xmath134 is constructed ( see generic step @xmath108 in section [ ss : description ] ) , we obtain @xmath188    these arguments and process can be repeated , sequentially integrating over the missing variables in @xmath189 according to @xmath190 , @xmath191 , finally obtaining the observed - data density @xmath56 .",
    "it is worth describing two special sequential identification schemes that can be derived from our general presentation .",
    "one is obtained when we take all @xmath192 , @xmath193 , and therefore @xmath194 . in this case , each @xmath116 is on the distribution of @xmath117 and @xmath118 given @xmath195 and @xmath120 , that is , the assumption conditions on the whole set of missingness indicators",
    "@xmath196 and not just on a subset of these . the other is obtained when we take all @xmath197 , @xmath198 , and therefore @xmath199 .",
    "in this case , each @xmath116 is on the distribution of @xmath117 and @xmath118 given @xmath168 and @xmath120 , that is , each assumption conditions on none of the missingness indicators @xmath196 .",
    "an important particular case of our sequential identification strategy is obtained when all @xmath199 and each @xmath76 is taken to be a conditional mar assumption , that is , when we assume that @xmath200 .",
    "along with , this leads to the combined assumption @xmath201 the missingness mechanism derived from this approach corresponds to the group permutation missingness of @xcite .",
    "when each block contains only one variable , it corresponds to the permutation missingness mechanism of @xcite .",
    "if the ordering of the variables or blocks of variables is regarded as temporal , as in a longitudinal study or a survey that asks questions in a fixed sequence , @xcite interpreted as follows : the nonresponse propensity at the current time period depends on the values of study variables in the previous time periods , whether observed or not , but not on what is missing in the present and future time periods .",
    "if the order of the blocks of variables was reversed , that is , if @xmath83 was on the distribution of @xmath202 and @xmath203 given @xmath204 , @xmath99 was on the distribution of @xmath185 and @xmath186 given @xmath205 and @xmath202 , and so on , then we would have the following interpretation : the nonresponse propensity at the current time period depends on the values of study variables in the future time periods , whether observed or not , but not on what is missing in the present and past time periods .",
    "this interpretation is arguably easier to explain in the context of respondents answering a questionnaire .",
    "the nonresponse propensity for question @xmath206 can depend on the respondent s answers to questions that appear later in the questionnaire and to questions that she has already answered , but not on the information that she has not revealed .",
    "consider two categorical random variables @xmath207 and @xmath208 .",
    "let @xmath209 and @xmath210 be their missingness indicators .",
    "let @xmath211 denote the joint distribution of @xmath212 .",
    "the observed - data distribution corresponds to the probabilities @xmath213 for @xmath214 , @xmath215 .",
    "we seek to construct a full - data distribution @xmath216 from the observed - data distribution @xmath217 by imposing some assumptions @xmath83 and @xmath99 .",
    "the goal is a full - data distribution such that @xmath218 , that is , we want @xmath219 to be nps .    to use the general identification strategy presented in section [ s : seqident ]",
    "we define each variable as its own block",
    ". with only two variables , set @xmath91 can be either @xmath220 or @xmath221 .",
    "we present two examples below corresponding to these two options .",
    "we first consider @xmath220 , @xmath222 , and the following identifying assumptions : @xmath223 ; and @xmath224    under @xmath83 , @xmath225 , where @xmath226 and @xmath227 are identified from the observed data distribution .",
    "when @xmath228 , @xmath229 , and @xmath230 .",
    "similarly , when @xmath231 we find @xmath232 and @xmath233 . since @xmath234 can be obtained from the observed - data distribution as @xmath235 when @xmath228 , and as @xmath236 when @xmath237 , using @xmath238 we obtain a joint distribution for @xmath239 that relies on @xmath83 , defined as @xmath240 .",
    "note that @xmath241 can be written as an explicit function of the observed - data distribution .",
    "we now use @xmath241 and identifying assumption @xmath99 to obtain @xmath242 from the definition of @xmath243 , @xmath244 can be written as @xmath245 when @xmath246 and @xmath247 when @xmath237 . from this",
    "we can obtain @xmath248 and @xmath249 we then obtain @xmath250 , which gives us a way to obtain @xmath251 as a function of the distribution @xmath241 , which in turn is a function of the observed - data distribution .",
    "the final full - data distribution is obtained as @xmath252 , where @xmath253 can be obtained from @xmath254 .",
    "after some algebra we find @xmath255 it is easy to see that @xmath219 is nps , that is @xmath218 . from the final distribution @xmath216 we can now obtain @xmath256 which is the distribution of inferential interest .    in closing this example",
    ", we stress that the final full - data distribution is not invariant to the order in which the blocks of variables appear in the sequence of assumptions . from expression",
    "it is clear that the final distribution of the study variables would be different had we identified a distribution for @xmath257 first . indeed ,",
    "if we were to follow the steps in the previous example but reversing the order of the variables , then we would be assuming that @xmath258 and @xmath259 , which are different from @xmath83 and @xmath99 in this example .",
    "we now consider @xmath221 , @xmath260 , and the identifying assumptions @xmath261 , and @xmath262 .",
    "assumption @xmath263 is the same as @xmath83 in example 1 , and so @xmath264 .",
    "assumption @xmath265 is made conditioning only on @xmath266 , so we need to marginalize over @xmath209 to obtain @xmath267 : @xmath268 from this we can obtain @xmath269 and @xmath270    using assumption @xmath265 , we obtain @xmath271 . from this",
    "we obtain @xmath272 as @xmath273 marginalizing over @xmath210 , we get @xmath274    assumptions @xmath263 and @xmath265 are enough to identify @xmath275 , and thereby a distribution of the study variables @xmath276 .",
    "although irrelevant for obtaining the distribution of the study variables , it is worth noticing that @xmath263 and @xmath265 do not allow us to fully identify @xmath277 .",
    "from @xmath278 we have @xmath279 and @xmath280 , but @xmath281 remains unidentified .",
    "a full - data distribution @xmath282 becomes identified under the extra assumption @xmath283 which corresponds to the extra assumption in .",
    "the set of assumptions that we used in this example can be summarized in terms of the missingness mechanism @xmath284 where @xmath285 , @xmath286 , and @xmath287 .",
    "this corresponds to the permutation missingness ( pm ) mechanism of @xcite .    as in example 1",
    ", the full - data distribution changes when we modify the order in which the blocks of variables appear in the identifying assumptions .",
    "changing the order of the variables in this example would correspond to making the assumptions @xmath258 and @xmath288 .",
    "@xcite introduced different notions of the missing data being _ partially ignorable_. in particular , in some scenarios one may think that the missingness is ignorable for some , but not for all the variables . for example , consider a survey with two blocks of items @xmath289 and @xmath290 , which contain responses to sensitive and non - sensitive questions , respectively . given the nature of these variables",
    ", one may think that the missingness among the @xmath290 variables could be ignored , but not among @xmath289 .",
    "our sequential identification procedure can be used to guarantee identifiability under such partially ignorable mechanisms .",
    "our goal here is to show that we can identify a nps full - data distribution @xmath291 with the property that the missingness mechanism for @xmath290 is partially mar given @xmath292 ( @xcite ) , that is , @xmath293 while @xmath294 is determined by some nonignorable assumption .",
    "as before , we consider @xmath295 to be known .",
    "following our sequential identification procedure , we first consider an identifying assumption for the distribution of @xmath290 and @xmath296 given @xmath297 .",
    "we use the conditional mar assumption : @xmath298 this assumption guarantees the existence of a distribution of the variables @xmath299 , and @xmath297 with density @xmath300 , where @xmath301 can be obtained from @xmath302 as described in page 28 of @xcite .",
    "taking @xmath221 in our identification procedure , we can now consider any identifying assumption , say @xmath99 , for the distribution of @xmath289 and @xmath292 given @xmath290 that allows us to obtain @xmath303 with the nps property @xmath304 .",
    "for example , @xmath99 could come from one of the approaches mentioned in section [ ss : nps ] .",
    "we then define @xmath305 .    to fully identify a full - data distribution @xmath291 that encodes assumptions @xmath83 and @xmath99",
    ", we further require the conditional missingness mechanism @xmath306 . under the extra assumption @xmath307 and then using @xmath83 we have identified a full - data distribution with density @xmath308 .",
    "the nps property of this distribution is guaranteed by theorem [ th : ident ] .",
    "a possibility for the @xmath99 assumption could come from the itemwise conditionally independent nonresponse ( icin ) mechanism of @xcite , which is nps . denoting @xmath309 ,",
    "the icin assumption for @xmath289 and @xmath292 given @xmath290 can be written as @xmath310 where @xmath311 is the vector obtained from removing the @xmath4th entry of @xmath312 , likewise for @xmath313 .",
    "our sequential identification procedure guarantees that assumptions in and jointly identify a nps full - data distribution .",
    "[ ex : pim ] for simplicity , consider @xmath314 and @xmath315 .",
    "the observed - data density can be written as the product of the density of the observed variables given each missingness pattern times the probability of the missingness pattern , that is @xmath316 , which for three variables is given by @xmath317 , @xmath318 , @xmath319 , @xmath320 , @xmath321 , and @xmath322 .",
    "assumption @xmath83 in in this case becomes @xmath323 , which for all @xmath324 and @xmath325 can be expanded as @xmath326 ; @xmath327 ; @xmath328 ; and @xmath329 .",
    "using @xmath83 and the observed - data distribution we can obtain @xmath330 as @xmath331 , where @xmath332 is obtained from @xmath333 @xmath334 ; and @xmath335 from @xmath336^{i(m_1=0)}[f_{100}(x_2,x_3)\\pi_{100}]^{i(m_1=1)},\\\\ f(m_1=m_1|m_2=1,m_3=0,x_3)&\\propto [ f_{010}(x_3)\\pi_{010}]^{i(m_1=0)}[f_{110}(x_3)\\pi_{110}]^{i(m_1=1)},\\\\ f(m_1=m_1|m_2=0,m_3=1,x_2)&\\propto [ f_{001}(x_2)\\pi_{001}]^{i(m_1=0)}[f_{101}(x_2)\\pi_{101}]^{i(m_1=1)},\\\\ f(m_1=m_1|m_2=1,m_3=1)&\\propto [ \\pi_{011}]^{i(m_1=0)}[\\pi_{111}]^{i(m_1=1)}.\\end{aligned}\\ ] ] from this we can define @xmath337 , where @xmath338 is obtained from @xmath339 , @xmath340 , @xmath341 , and @xmath342 .",
    "we now incorporate the icin assumption for the distribution of @xmath343 given @xmath266 .",
    "we have @xmath344 ; and @xmath345 .",
    "the identification results of @xcite guarantee that assumption @xmath99 leads to a conditional distribution @xmath346 with the nps property @xmath347 , where @xmath348 can be obtained easily from @xmath349 .",
    "section 5.1 of @xcite provides explicit formulae for the full - data distribution under the icin assumption as a function of the observed - data distribution , in the case of two variables .",
    "we can use those formulae here with @xmath350 to obtain conditional icin full - data distributions that depend on @xmath266 . to simplify the notation below we replace @xmath351 by @xmath352 , and @xmath107 by @xmath353 , and we denote @xmath354 and @xmath355 . following the formulae of @xcite",
    "we obtain @xmath356 , @xmath357 , @xmath358 , @xmath359 and @xmath360 .    putting everything together",
    ", we obtain @xmath361 from which we can obtain the distribution of the study variables @xmath362 .",
    "a full - data density @xmath363 becomes identified under the extra assumption .",
    "this distribution therefore encodes the partial ignorability assumption for the missingness in @xmath266 and the icin assumption for @xmath343 given @xmath266 .      to illustrate how this approach could be used for sensitivity analysis , we use data related to the 1991 plebiscite where slovenians voted for independence from yugoslavia ( @xcite ) .",
    "the data come from the slovenian public opinion survey , which contained the questions : @xmath364 : are you in favor of slovenia s independence ?",
    "@xmath365 : are you in favor of slovenia s secession from yugoslavia ?",
    "@xmath366 : will you attend the plebiscite ?",
    "we call these the independence , secession , and attendance questions , respectively .",
    "the possible responses to each of these were yes , no , and do nt know .",
    "we follow @xcite in treating do nt know as missing data .",
    "we use the missingness mechanism presented in example [ ex : pim ] , and compare it with an ignorable approach , a pattern mixture model ( pmm ) under the complete - case missing - variable restriction ( @xcite ) , and the icin approach of @xcite which here corresponds to assuming @xmath367 .",
    "the attendance question is arguably the less sensitive of the three questions studied here , so it seems reasonable to consider a partially ignorable mechanism where the nonresponse for @xmath366 is ignorable given @xmath368 and @xmath369 , as in , and the nonresponse for @xmath364 and @xmath365 satisfy the icin assumption conditioning on @xmath366 , as in in example [ ex : pim ] .",
    "nothing prevents us from using this approach exchanging the roles of the variables , so we also consider two other partially ignorable missingness mechanisms , depending on whether we take the nonresponse for @xmath364 or for @xmath365 as ignorable .",
    "to implement these approaches , we first use a bayesian approach to estimate the observed - data distribution .",
    "the observed data can be organized in a three - way contingency table with cells corresponding to each element of @xmath370yes , no , do nt know@xmath371 , as presented in @xcite . treating these data as a random sample from a multinomial distribution ,",
    "we take a conjugate prior distribution for the cell probabilities : symmetric dirichlet with parameter @xmath372 .",
    "we take 5,000 draws from the posterior distribution of the observed - data distribution , and for each of these we apply the formulae presented in example 3 to obtain posterior draws of the full - data distribution under each of the three partially ignorable mechanisms .",
    "we use a similar approach to obtain posterior draws of the full - data distribution under icin , pmm , and ignorability . for each of the approaches",
    "we then obtain draws of the implied probabilities for the items .",
    "figure [ fig : slovenia ] displays 5,000 draws from the joint posterior distribution of @xmath211(independence = yes , attendance = yes ) and @xmath211(attendance = no ) under each of the six missingness mechanisms considered here .",
    "despite the fact that all of these approaches agree in their fit to the observed data , we obtain quite different inferences under each assumption .",
    "when inferences are so sensitive to the identifying assumptions , perhaps the most honest way to proceed is to report all the results under all assumptions deemed plausible given the context .",
    "0.32  ignorability + [ fig : slovmar ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]    0.32  pattern mixture + [ fig : slovpmm ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]    0.32  icin + [ fig : slovimar ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]     +    0.32  pim - attendance + [ fig : slovpim_att ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]    0.32  pim - independence + [ fig : slovpim_ind ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]    0.32  pim - secession + [ fig : slovpim_sec ] ( independence = yes , attendance = yes ) and @xmath211(attendance = no ) .",
    "pattern mixture model under the complete - case missing - variable restriction .",
    "the three partially ignorable missingness ( pim ) mechanisms correspond to which variable we take as having ignorable missingness .",
    "the plebiscite results are represented by @xmath373 .",
    "these are shown to illustrate differences between approaches and not to declare better vs worse assumptions for these data.,title=\"fig:\",scaledwidth=100.0% ]",
    "the sequential identification procedure can be set up in many different ways , leading to different possibilities for constructing nonignorable missingness mechanisms .",
    "the main differences among these possibilities lie in the assumptions about how missingness from any one block of variables affects missingness in other blocks , as illustrated in the examples of section [ ss : extreme_cases ] and section [ s : examples ] . in general , the procedure allows for different levels of dependence on missing variables while ensuring non - parametric saturated models , which provides a useful framework for sensitivity analysis .",
    "although we presented our identification strategy for arbitrary @xmath70 blocks of variables , we expect that in practice most analysts would use @xmath374 blocks when the variables do not naturally fall into ordered blocks of variables .",
    "for example , analysts may want to partition variables into one group that requires careful assessment of sensitivity to various missingness mechanisms , such as outcome variables in regression modeling with high fractions of missingness , and a second group that can be treated with generic missingness mechanisms like conditional mar , such as covariates with low fractions of missingness .",
    "these cases require partially ignorable mechanisms like those in section [ s : partialigno ] .",
    "another scenario where two blocks naturally might arise is when analysts have prior information on how the missingness occurs for a set of variables but not for the rest . related",
    ", analysts might have auxiliary information on the marginal distribution of a few variables , perhaps from a census or other surveys , that enable the identification of mechanisms where the probability of nonresponse for a variable depends explicitly on the variable itself ( @xcite ) .",
    "our sequential identification procedure provides a constructive way of obtaining estimated full - data distributions from estimated observed - data distributions while ensuring non - parametric saturated models . to implement these approaches in practice",
    ", one needs sufficient numbers of observations for each missing data pattern , so as to allow accurate non - parametric estimation of the observed - data distribution .",
    "this can be challenging in modest - sized samples with large numbers of variables .",
    "of course , this is the case with most methods for handling missing data , including pattern mixture models . in such cases ,",
    "one may have to sacrifice non - parametric saturated modeling of the observed data in favor of parametric models .",
    "this research was supported by the grant nsf ses 11 - 31897 .",
    "gill , r.  d. , van der laan , m.  j. and robins , j.  m. ( 1997 ) .",
    "coarsening at random : characterizations , conjectures , counter - examples . in _ proceedings of the first seattle symposium in biostatistics : survival analysis _ , pages 255 - 294 . edited by lin , d. y. and fleming , t. r. \""
  ],
  "abstract_text": [
    "<S> with nonignorable missing data , likelihood - based inference should be based on the joint distribution of the study variables and their missingness indicators . </S>",
    "<S> these joint models can not be estimated from the data alone , thus requiring the analyst to impose restrictions that make the models uniquely obtainable from the distribution of the observed data . </S>",
    "<S> we present an approach for constructing classes of identifiable nonignorable missing data models . </S>",
    "<S> the main idea is to use a sequence of carefully set up identifying assumptions , whereby we specify potentially different missingness mechanisms for different blocks of variables . </S>",
    "<S> we show that the procedure results in models with the desirable property of being non - parametric saturated .    _ </S>",
    "<S> key words and phrases : _ identification ; non - parametric saturated ; missing not at random ; partial ignorability ; sensitivity analysis . </S>"
  ]
}