{
  "article_text": [
    "characteristic polynomials of random matrices have found considerable attention in recent years , one reason being that their correlations seem to reflect the correlations of the eigenvalues @xcite .    in this article",
    "we investigate the second - order correlation function of the characteristic polynomial of a sample covariance matrix",
    ".    * complex sample covariance matrices .",
    "* let @xmath0 be a distribution on the real line with expectation @xmath1 , variance @xmath2 and finite fourth moment @xmath3 , and for given @xmath4 with @xmath5 , let @xmath6 denote the @xmath7 matrix whose entries @xmath8 are complex random variables whose real and imaginary parts are independent , each with distribution @xmath0 .",
    "let @xmath9 denote the conjugate transpose of @xmath10 .",
    "then the hermitian @xmath11 matrix @xmath12 is called the ( complex ) _ sample covariance matrix _ associated with the distribution @xmath0 . for @xmath13 , let @xmath14 denote the second - order correlation function of the characteristic polynomial of the `` unrescaled '' sample covariance matrix .    * real sample covariance matrices . *",
    "let @xmath0 be a distribution on the real line with expectation @xmath1 , variance @xmath15 and finite fourth moment @xmath3 , and for given @xmath4 with @xmath5 , let @xmath6 denote the @xmath7 matrix whose entries @xmath8 are real random variables with distribution @xmath0 .",
    "let @xmath16 denote the transpose of @xmath17 .",
    "then the symmetric @xmath11 matrix @xmath18 is called the ( real ) _ sample covariance matrix _ associated with the distribution @xmath0 . for @xmath13 , let @xmath19 denote the second - order correlation function of the characteristic polynomial of the `` unrescaled '' sample covariance matrix .    in the special case",
    "where @xmath0 is the gaussian distribution , the random matrix @xmath10 is also called a ( complex or real ) _ wishart matrix _ , since its distribution is the ( complex or real ) _ wishart distribution _",
    "( see anderson @xcite or muirhead @xcite )",
    ".    it will always be clear from the context whether we are considering the complex or real case .",
    "more precisely , we are interested in the asymptotic behavior of the  values @xmath20 as @xmath21 , where @xmath22 , @xmath23 for some fixed natural number @xmath24 , and the parameters @xmath25 and @xmath26 are finally used to `` zoom in '' at certain interesting regions of the spectrum of the ( unrescaled ) sample covariance matrix , namely the bulk of the spectrum , the soft edge of the spectrum , and the hard edge of the spectrum .",
    "( see section  3 for details . )    in the complex setting , we will recover , in all the regions previously mentioned , the well - known kernels for the `` correlation functions '' of the eigenvalues , namely the sine kernel , the airy kernel and the bessel kernel .",
    "( see section  3 for details . ) thus , our results indicate that these kernels are _ universal _ in that they arise in connection with quite general sample covariance matrices ( as  described at the beginning of this section ) , albeit at the level of the characteristic polynomial .",
    "it is conjectured that this universality also holds at the level of the eigenvalue themselves , but so far this conjecture has only been proven for a restricted class of sample covariance matrices in the bulk of the  spectrum ( see ben arous and pch @xcite ) and under stronger moment conditions than ours for the edges of the  spectrum ( see soshnikov @xcite and tao and vu @xcite , respectively ) .",
    "similar results will also be obtained in the real setting .",
    "however , the results for the correlation functions of the characteristic polynomial are somewhat more different from the results for the eigenvalues here .",
    "to obtain our results , we follow the strategy proposed by gtze and ksters @xcite in the context of wigner matrices .",
    "first , we obtain an explicit expression for an exponential - type generating function of the second - order correlation function of the characteristic polynomial .",
    "second , we recover the well - known kernels from random matrix theory by asymptotic analysis .",
    "in this section we derive the generating function of the second - order correlation function of the characteristic polynomial . since the derivation is very similar for complex and real sample covariance matrices , we present the details only for the complex setting and restrict ourselves to a few comments for the real setting",
    ".    the following well - known representation will prove useful :    [ chiral ] let @xmath27 .",
    "then , for @xmath28 , @xmath29    this is an immediate consequence of the matrix factorizations @xmath30 @xmath31 where @xmath32 , @xmath33 , @xmath34 , @xmath35 , and @xmath36 and @xmath37 are invertible .    a matrix of the form @xmath38 , where @xmath17 is a ( complex ) random matrix with entries , is also called a ( complex ) _ chiral matrix_.",
    "thus , lemma [ chiral ] establishes a  connection between the characteristic polynomial of a sample covariance matrix and that of a chiral matrix .",
    "chiral matrices seem more convenient for our purposes , as they give rise to neater row and column expansions .    to illustrate our approach , we start with the first moment of the characteristic polynomial , which has already been determined by forrester and gamburd @xcite by means of a combinatorial argument . fix @xmath39 , and put @xmath40 where @xmath41 is a matrix of size @xmath7 with matrix entries satisfying our standing moment conditions . note that this definition is meaningful even if @xmath42 or @xmath43 ; we then have @xmath44 and @xmath45 .",
    "( in particular , the  determinant of the @xmath46 matrix is defined to be @xmath15 . )",
    "let us derive a recursive equation for @xmath47 .",
    "suppose that @xmath48 .",
    "then , doing a  row  and  column  expansion about the last row and the last column , we  have @xmath49 } \\\\ ( x^{[\\,\\cdot\\,:m]})^ * & \\lambda i_{m-1 } \\end{array } \\right ) \\nonumber \\\\ & + \\sum_{i , j=1}^{n } ( -1)^{i+j-1 } x_{i , m } \\overline{x}_{j , m } \\det \\left ( \\begin{array}{cc } \\lambda i_{n}^{[i : j ] } & x^{[i : m ] } \\\\ ( x^{[j : m]})^ * & \\lambda i_{m-1 } \\end{array } \\right ) \\",
    ", , \\label{double - expansion}\\end{aligned}\\ ] ] where an upper index @xmath50 $ ] indicates that the @xmath51th row and the @xmath52th column of the corresponding matrix are deleted .",
    "taking expectations , using independence and noting that @xmath53 ( as follows from our standing moment conditions ) , we obtain @xmath54 observe that this is meaningful even if @xmath42 , since the second term vanishes in this case .",
    "hence , recalling the identity @xmath55 we see that the values @xmath47 are completely determined by recursion over @xmath56 .    for arbitrary @xmath57 , the laguerre polynomials @xmath58",
    "are defined by @xmath59 ( see equation ( 5.1.6 ) in szeg @xcite ) .",
    "it is well - known that the laguerre polynomials satisfy the relations @xmath60 @xmath61 ( see equations ( 5.1.10 ) and ( 5.1.14 ) in szeg @xcite ) , through which they are completely determined by recursion over @xmath56 .    comparing , with ,",
    ", it is easy to see ( by induction on @xmath56 ) that for any @xmath62 , @xmath63 hence , using lemma [ chiral ] , we find that the first moment of the characteristic polynomial of a ( complex ) sample covariance matrix satisfies @xmath64 in fact , this was already proved by forrester and gamburd @xcite by means of a  combinatorial argument .    equation ( [ firstorder ] ) remains true for real sample covariance matrices ( under the respective moment conditions ) .",
    "we have obtained a recursive equation over @xmath56 for the moments @xmath47 of course , for symmetry reasons , it is clear that it is equally possible to derive a recursive equation over @xmath65 .",
    "indeed , starting with a row and column expansion about the first row and the first column , we obtain @xmath66 instead of , together with the initial condition @xmath67 since the laguerre polynomials satisfy the relation @xmath68 @xmath69 ( see equations ( 5.1.13 ) and ( 5.2.1 ) in szeg @xcite ) , they can also be calculated by  recursion over @xmath65 , and ( [ fnm ] ) follows ( by induction on @xmath65 ) .",
    "let us now turn to the second moment of the characteristic polynomial .",
    "similarly as above , we first consider @xmath70 a similar expansion of the determinants as in yields @xmath71 } \\\\ ( x^{[\\,\\cdot\\,:m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) + \\sum_{i , j=1}^{n } ( -1)^{i+j-1 } x_{i , m } \\overline{x}_{j , m } \\det \\left ( \\begin{array}{cc } \\mu i_{n}^{[i : j ] } & x^{[i : m ] } \\\\ ( x^{[j : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\right ) \\\\ & \\mskip24mu \\,\\cdot\\ , \\left ( \\nu \\det \\left ( \\begin{array}{cc } \\nu i_{n } & x^{[\\,\\cdot\\,:m ] } \\\\ ( x^{[\\,\\cdot\\,:m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) + \\sum_{k , l=1}^{n } ( -1)^{k+l-1 } x_{k , m } \\overline{x}_{l , m } \\det \\left ( \\begin{array}{cc } \\nu i_{n}^{[k : l ] } & x^{[k : m ] } \\\\",
    "( x^{[l : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\right ) \\,.\\end{aligned}\\ ] ]    note that due to our standing moment assumptions , we have @xmath72 hence , expanding the product and taking expectations , we obtain @xmath73 } \\\\ ( x^{[\\sdot : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n } & x^{[\\sdot : m ] } \\\\",
    "( x^{[\\sdot : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\\\ & \\mskip24mu \\,-\\ , \\mu \\sum_{k=1}^{n } \\ee |x_{k , m}|^2   \\det \\left ( \\begin{array}{cc } \\mu i_{n } & x^{[\\sdot : m ] } \\\\",
    "( x^{[\\sdot : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n-1 } & x^{[k : m ] } \\\\",
    "( x^{[k : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\\\ & \\mskip24mu \\,-\\ , \\nu \\sum_{i=1}^{n } \\ee |x_{i , m}|^2   \\det \\left ( \\begin{array}{cc } \\mu i_{n-1 } & x^{[i : m ] } \\\\",
    "( x^{[i : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n } & x^{[\\sdot : m ] } \\\\",
    "( x^{[\\sdot : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\\\ & \\mskip24mu \\,+\\ , \\sum_{i } \\ee |x_{i , m}|^4   \\det \\left ( \\begin{array}{cc } \\mu i_{n-1 } & x^{[i : m ] } \\\\",
    "( x^{[i : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n-1 } & x^{[i : m ] } \\\\",
    "( x^{[i : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\\\ & \\mskip24mu \\,+\\ , \\sum_{i \\ne k } \\ee |x_{i , m}|^2 |x_{k , m}|^2 \\det \\left ( \\begin{array}{cc } \\mu i_{n-1 } & x^{[i : m ] } \\\\",
    "( x^{[i : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n-1 } & x^{[k : m ] } \\\\ ( x^{[k : m]})^ * & \\nu i_{m-1 } \\end{array } \\right ) \\\\ & \\mskip24mu \\,+\\ , \\sum_{i \\ne j } \\ee |x_{i , m}|^2 |x_{j , m}|^2 \\det \\left ( \\begin{array}{cc } \\mu i_{n}^{[i : j ] } & x^{[i : m ] } \\\\",
    "( x^{[j : m]})^ * & \\mu i_{m-1 } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_{n}^{[j : i ] } & x^{[j : m ] } \\\\",
    "( x^{[i : m]})^ * & \\nu i_{m-1 } \\end{array } \\right)\\,.\\end{aligned}\\ ] ] to shorten notation , let us introduce the auxiliary functions @xmath74 } & x^{[\\alpha_1:\\sdot ] } \\\\ ( x^{[\\alpha_2:\\sdot]})^ * & \\mu i_m \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_n^{[\\alpha_3:\\alpha_4 ] } & x^{[\\alpha_3:\\sdot ] } \\\\ ( x^{[\\alpha_4:\\sdot]})^ * & \\nu i_m \\end{array } \\right ) \\right ) \\,,\\ ] ] where @xmath75 ( a dot representing no deletion ) , as well as the abbreviations @xmath76 11_a : = ( 1,1,2,2),\\ 11_b : = ( 1,2,1,2),\\ 11_c : = ( 1,2,2,1 ) . $ ] ( no  other  values of @xmath24 will be needed .",
    "moreover , the value @xmath77 will be needed for the real setting only . )",
    "note that @xmath78 .",
    "we then have @xmath79 note that the preceding formula was obtained by starting with an expansion `` in the @xmath56-dimension '' .",
    "of course , it is possible to derive an analogous formula by starting with an expansion `` in the @xmath65-dimension '' ; we then have @xmath80 where @xmath81 is defined by @xmath82 } \\\\ ( x^{[\\sdot:\\alpha_2]})^ * & \\mu i_m^{[\\alpha_2:\\alpha_1 ] } \\end{array } \\right ) \\det \\left ( \\begin{array}{cc } \\nu i_n & x^{[\\sdot:\\alpha_3 ] } \\\\ ( x^{[\\sdot:\\alpha_4]})^ * & \\nu i_m^{[\\alpha_4:\\alpha_3 ] } \\end{array } \\right ) \\right ) \\,,\\ ] ] and the possible values @xmath83 for @xmath24 are the same as before .",
    "here is a list of recursive relations which can be derived using the above arguments : @xmath84 f(n , m,\\sdot,01 ) & = ( + \\mu ) f(n , m-1,\\sdot,\\sdot ) \\nonumber\\\\ & - n f(n , m-1,10,\\sdot ) & ( n \\geq 0 , m \\geq 1 ) \\",
    ", ,   \\label{fnm - b } \\\\[+3pt ] f(n , m,\\sdot,10 ) & = ( + \\nu ) f(n , m-1,\\sdot,\\sdot ) \\nonumber\\\\ & - n f(n , m-1,01,\\sdot ) & ( n \\geq 0 , m \\geq 1 ) \\ , ,   \\label{fnm - c } \\allowdisplaybreaks \\\\[+3pt ]     f(n , m,\\sdot,11^a ) & = \\mu \\nu f(n , m-2,\\sdot,\\sdot ) \\nonumber\\\\ & - \\mu n f(n , m-2,01,\\sdot ) \\nonumber\\\\ & - \\nu",
    "n f(n , m-2,10,\\sdot ) \\nonumber\\\\ & + n f(n-1,m-2,\\sdot,\\sdot ) \\nonumber\\\\ & + n(n-1 ) f(n , m-2,11^a,\\sdot ) & ( n \\geq 0 , m \\geq 2 ) \\ , , \\label{fnm - d } \\\\[+3pt ]     f(n , m,\\sdot,11^c ) & = n f(n-1,m-2,\\sdot,\\sdot ) \\nonumber\\\\ & + n(n-1 ) f(n , m-2,11^c,\\sdot ) & ( n \\geq 0 , m \\geq 2 ) \\ , , \\label{fnm - e } \\allowdisplaybreaks \\\\[+3pt ]     f(n , m,\\sdot,\\sdot ) & = \\mu \\nu f(n-1,m,\\sdot,\\sdot ) \\nonumber\\\\ & - \\mu m f(n-1,m,\\sdot,01 ) \\nonumber\\\\ & - \\nu m f(n-1,m,\\sdot,10 ) \\nonumber\\\\ & + ( 2b+\\tfrac12 ) m f(n-1,m-1,\\sdot,\\sdot ) \\nonumber\\\\ & + m(m-1 ) f(n-1,m,\\sdot,11^a ) \\nonumber\\\\ & + m(m-1 ) f(n-1,m,\\sdot,11^c ) & ( n \\geq 1 , m \\geq 0 ) \\ , ,   \\label{fnm - f } \\\\[+3pt ] f(n , m,01,\\sdot ) & = ( + \\mu ) f(n-1,m,\\sdot,\\sdot ) \\nonumber\\\\ & - m f(n-1,m,\\sdot,10 ) & ( n \\geq 1 , m \\geq 0 ) \\ , ,   \\label{fnm - g } \\\\[+3pt ] f(n , m,10,\\sdot ) & = ( + \\nu ) f(n-1,m,\\sdot,\\sdot ) \\nonumber\\\\ & - m f(n-1,m,\\sdot,01 ) & ( n \\geq 1 , m \\geq 0 ) \\ , , \\label{fnm - h } \\\\[+3pt ]     f(n , m,11^a,\\sdot ) & = \\mu \\nu f(n-2,m,\\sdot,\\sdot ) \\nonumber\\\\ & - \\mu m f(n-2,m,\\sdot,01 ) \\nonumber\\\\ & - \\nu m f(n-2,m,\\sdot,10 ) \\nonumber\\\\ & + m f(n-2,m-1,\\sdot,\\sdot ) \\nonumber\\\\ & + m(m-1 ) f(n-2,m,\\sdot,11^a ) & ( n \\geq 2 , m \\geq 0 ) \\ , , \\label{fnm - i } \\\\[+3pt ]",
    "f(n , m,11^c,\\sdot ) & = m f(n-2,m-1,\\sdot,\\sdot ) \\nonumber\\\\ & + m(m-1 ) f(n-2,m,\\sdot,11^c ) & ( n \\geq 2 , m \\geq 0 ) \\ , .",
    "\\label{fnm - j}\\end{aligned}\\ ] ] ( when evaluating these recursive relations , there may arise some undefined terms with negative arguments , but this poses no problem as these terms are always accompanied by the factor zero .",
    "similar remarks apply to the formulas below . ) together with the initial conditions @xmath85 the equations  determine the values @xmath47 completely .",
    "we will now derive a recursive equation involving the values @xmath47 only . by and with @xmath56 replaced by @xmath86",
    ", we have , for @xmath87 , @xmath88 , @xmath89 by ( [ fnm - f ] ) with @xmath90 replaced by @xmath91 , the two summands involving @xmath92 satisfy , for @xmath93 , @xmath88 , @xmath94 whence , for @xmath93 , @xmath88 , @xmath95 plugging this into and rearranging terms , we find that , for @xmath88 , @xmath96 ( for @xmath42 and @xmath97 , follows directly from . )",
    "thus , we  have eliminated the terms involving @xmath98 and @xmath99 .",
    "the terms involving @xmath100 and @xmath101 can be eliminated by a similar substitution . using and with @xmath56 replaced by @xmath86 , and with",
    "@xmath90 replaced by @xmath91 and finally with @xmath90 replaced by @xmath91 , we  have , for @xmath102 , @xmath88 , @xmath103 plugging this into and rearranging terms , it follows that , for @xmath88 , @xmath104 ( for @xmath42 , follows immediately from . ) by symmetry , we  also  have , for @xmath102 , @xmath105 hence , the values @xmath47 may be computed recursively starting from and using either or .    from now on , for @xmath106 , let @xmath47 denote the second - order correlation function of the characteristic polynomial of the ( complex ) sample covariance matrix as defined in the introduction .",
    "( for the rest of this section , we will usually omit the parameters @xmath107 , which are regarded as fixed . ) then , by lemma [ chiral ] , we have to make the replacements @xmath108 , @xmath109 , @xmath110 in the  preceding two equations , thereby obtaining @xmath111 for @xmath88 and @xmath112 for @xmath102 , respectively , along with the initial conditions @xmath113 ( observe that in contrast to the equations for the chiral matrix , the equations for the sample covariance matrix are not fully symmetrical in @xmath65 and @xmath56 . )",
    "let @xmath114 denote the difference of @xmath65 and @xmath56 and assume that @xmath115 .",
    "( the  case @xmath116 could be reduced to this case by exchanging the roles of @xmath65  and  @xmath56 and by multiplying with the appropriate power of @xmath117 . )",
    "we  will determine , for any @xmath118 , the generating function @xmath119 where @xmath120 .",
    "put @xmath121 we will show that for any @xmath118 , the generating function @xmath122 is given by @xmath123 to begin with , observe that @xmath124 defines an analytic function on the unit disc in the complex plane , with power series representation @xmath125 say .",
    "next , differentiating ( [ smartguess ] )  @xmath126 , we  obtain @xmath127 since @xmath128 it follows that @xmath129 or ( equivalently ) @xmath130 in terms of the power series coefficients @xmath131 defined by , this translates into the recursive relation , for @xmath88 , @xmath132 where terms with a negative argument are to be regarded as zero . for @xmath43 ,",
    "we  clearly  have @xmath133 comparing , and , , it is easy to see that the coefficients @xmath131 satisfy the same recursive equations as the values @xmath134 thus , as all values are uniquely determined by these recursive equations , it follows that the generating function is given by , for any @xmath118 .",
    "let us summarize our result for the complex setting as follows :    [ complex - scm ] for any @xmath118 , the second - order correlation function @xmath47 of the characteristic polynomial of an unrescaled complex sample covariance matrix satisfies @xmath135 where @xmath136 .",
    "also , let us state the analogous result for the real setting :    [ real - scm ] for any @xmath118 , the second - order correlation function @xmath47 of the characteristic polynomial of an unrescaled real sample covariance matrix satisfies @xmath137 where @xmath138 .",
    "as already mentioned at the beginning of this section , the derivation in the real setting is essentially the same as that in the complex setting .",
    "that is why we do not give the full details of the proof of proposition [ real - scm ] , but only mention some noteworthy changes :    \\(i ) in the real case , we have @xmath139 in particular , as the second moment is not equal to zero anymore , we get an extra term @xmath140 in equation , and an extra term @xmath141 f(n-1,m,\\,\\cdot\\,,11_b)$ ] in equation . also , the factor @xmath142 must be replaced with the factor @xmath3 everywhere .",
    "\\(ii ) similar changes arise in equations  .",
    "the recursive equation for the @xmath77-terms is the same as that for the @xmath143-terms , except that all occurrences of @xmath143 must be replaced with occurrences of @xmath77 . in fact , it is not hard to see that @xmath144 and @xmath145 for all @xmath62 .",
    "\\(iii ) the analogue of reads @xmath146 consequently , the analogue of reads @xmath147 and the analogue of reads @xmath148 similar modifications are required for equations  .",
    "\\(iv ) defining @xmath124 as in proposition and denoting by @xmath131 the coefficients in the power series representation @xmath149 , it follows by the  same arguments as for that for @xmath88 , @xmath150 similarly as in the complex setting , this is the same recursive relation as that for the values @xmath151",
    "from now on , we will always assume that @xmath152 and @xmath153 depend on @xmath154 , where @xmath24 is a fixed natural number .",
    "in particular , @xmath155 and @xmath156 as @xmath21 .",
    "let us begin with the complex setting .",
    "it is well - known from random matrix theory that under the above assumptions , the spectrum of the properly rescaled sample covariance matrix @xmath157 is asymptotically concentrated on the interval @xmath158 $ ] , with distribution given by the _ marenko - pastur density _",
    "@xmath159 moreover , it is well - known from random matrix theory that the following 3 regions deserve particular attention :    a.   * the bulk of the spectrum * , + the region around a point @xmath160 , b.   * the soft edge of the spectrum * , + the region around the point @xmath161 , c.   * the hard edge of the spectrum * , + the region around the point @xmath162 .",
    "more precisely , it is widely expected that in these regions , the correlation function of the eigenvalues ( see mehta @xcite or forrester @xcite ) is asymptotically given ( after the appropriate rescaling so that the mean spacing between the eigenvalues is of order @xmath15 ) by    a.   the sine kernel @xmath163 b.   the airy kernel @xmath164 c.   the bessel kernel @xmath165    typically , these results were first obtained for wishart matrices ( ,  gaussian sample covariance matrices ) and then extended to more general sample covariance matrices :    a.   for the bulk of the spectrum , ben arous and pch @xcite established the emergence of the sine kernel for sample covariance matrices @xmath166 such that the distributions of the entries of the matrix @xmath17 are gaussian convolutions .",
    "b.   for the soft edge of the spectrum , soshnikov @xcite established the emergence of the airy kernel by means of the method of moments and a sophisticated comparison with the gaussian case .",
    "c.   for the hard edge of the spectrum ,",
    "tao and vu @xcite established the emergence of the bessel kernel ( in the special case where the matrix @xmath17 is a square  matrix ) , also via a sophisticated reduction to the gaussian case .",
    "it is the purpose of the following sections to show that the same kernels show up at the level of the characteristic polynomial , for quite general sample covariance matrices .",
    "thus , our results add some support to the universality conjecture that the kernels _ always _ occur , irrespective of the choice of the underlying distribution  @xmath0 .",
    "also , our proofs are comparatively simple , and they are based on rather weak moment conditions , considerably weaker ones than those for the above - mentioned results from the literature",
    ".    the starting point for our asymptotic analysis will also be the integral representation @xmath167 which follows from by cauchy s formula .",
    "here , @xmath168 is defined as in , @xmath114 , and @xmath169 denotes a  counterclockwise circular path of radius @xmath170 , @xmath171 around the origin .",
    "( the precise choice of the radius will be specified in the  following sections . ) since @xmath172 where @xmath173 denotes the modified bessel function of order @xmath24 , may be rewritten as @xmath174 we will always use the parametrization @xmath175 , @xmath176 , and we will always assume that @xmath177 is chosen such that @xmath178 on the positive real axis and @xmath179 is continuous otherwise , so @xmath180 $ ] as @xmath126 traverses the  path @xmath175 , @xmath176 .",
    "similar remarks apply to the choice of the  branch of the modified bessel function .    in the course of our asymptotic analysis",
    ", we will use the following classical results about the asymptotic behavior of the modified bessel function : for fixed @xmath115 , @xmath181 and @xmath182 is an absolute constant .",
    "( see chapter  7 in olver @xcite . ) in fact , our results could even be extended to the more general situation where @xmath183 tends to some constant @xmath184 as @xmath21 .",
    "however , this requires a more careful treatment of remainder terms ( particularly the remainder terms originating from the modified bessel functions ) and will therefore not be pursued here .",
    "we will show that in all the above - mentioned cases , given the appropriate specialization of the shift parameters @xmath107 and the radius @xmath185 , the main contribution to the integral comes from a small neighborhood of the point @xmath186 and that we  asymptotically end up with the above - mentioned kernels from random matrix theory .",
    "furthermore , by essentially the same proofs , we obtain similar results for real sample covariance matrices . in this setting the correlation function of the characteristic polynomial is asymptotically given ( after the appropriate rescaling ) by    a.   the `` differentiated '' sine kernel @xmath187 b.   the `` differentiated '' airy kernel @xmath188 c.   the `` differentiated '' bessel kernel @xmath189    these kernels are obtained from the corresponding kernels for the complex setting by applying the differential operators @xmath190 ( in  cases ( i ) and ( ii ) ) and @xmath191 ( in  case ( iii ) ) .",
    "( besides that , to  obtain the above formulas for the `` differentiated '' kernels , we have to use the  differential equation for the airy  and  bessel function . ) since the derivation of the results for real sample covariance matrices is essentially the same as for complex sample covariance matrices , we will refrain from giving the details of the  proofs , but only state the final results .",
    "in order to zoom in around a point in the bulk of the spectrum , we have to make the replacements @xmath192 for some @xmath160 , @xmath193 .",
    "( recall that our sample covariance matrices are unrescaled and that @xmath194 denotes density of the marenko - pastur distribution . )",
    "moreover , we have to multiply by the proper scaling factor in order to obtain a  non - degenerate limit .",
    "we then have the following result :    [ complex - s ] let @xmath195 denote the second - order correlation function of a complex sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath160 , @xmath193 ,",
    "setting @xmath196 we have @xmath197 where @xmath198 and @xmath199 is defined as in .    by ( [ intrep2 ] ) , we have @xmath200 where we have put @xmath201 for abbreviation . we take @xmath202 .",
    "we reduce the proof of theorem [ complex - s ] to  the following two claims :    on the one hand , we will show that , for any ( fixed ) @xmath203 , @xmath204 where @xmath205 denotes the restriction of the path @xmath169 to the set @xmath206 , and @xmath207    on the other hand , we will show that for any @xmath208 , there exists some @xmath209 such that for @xmath210 , we have @xmath211 for all @xmath212 large enough . here",
    ", @xmath213 denotes the restriction of the path @xmath169 to the set @xmath214 .",
    "it is easy to see that the main result follows by combining and and by using laplace inversion .",
    "indeed , firstly ,  and   imply that @xmath215 where @xmath216 secondly , by laplace inversion , for @xmath217 , @xmath218 , @xmath219 ( see p.245 in @xcite ) , whence @xmath220 replacing the local shift parameters @xmath107 with @xmath221 , dividing by @xmath194 and noting that @xmath222 yields .    to prove and",
    ", it turns out convenient to rewrite the integrand in as @xmath223 where @xmath224 and @xmath225 since @xmath226 and @xmath227 we find that @xmath228 here and in the sequel , we take the convention that the implicit constants in the @xmath229-terms may depend on @xmath230 ( which are regarded as fixed ) .    we first prove ( [ claim11 ] ) . in doing so",
    ", we use the notation @xmath231 to denote a bound involving an implicit constant depending also on @xmath232 ( in addition to @xmath230 ) . substituting @xmath233 and @xmath234 on the left - hand side in",
    ", we obtain @xmath235 now , by straightforward taylor expansion , we have the approximations , for @xmath236 , @xmath237 for the second approximation , we have used the observation that for @xmath236 , @xmath238 as well as the asymptotic approximation for the modified bessel function . inserting the preceding approximations into",
    ", it  follows that the left - hand side in converges to @xmath239 which proves .",
    "we now turn to the proof of ( [ claim12 ] ) .",
    "it suffices to show that for @xmath210 , @xmath240 \\,\\cup\\ , [ + a / n,+\\pi ] } \\frac{|f_1(re^{it})||f_2(re^{it})|}{|1-re^{it}|^2 \\ , |re^{it}|^{(n+m)/2 } } \\ dt \\leq \\delta \\,.\\end{aligned}\\ ] ] write @xmath241 with @xmath242 , @xmath243 $ ] .",
    "then , @xmath244 @xmath245 @xmath246 from which it follows that @xmath247 also , for @xmath212 sufficiently large , @xmath248 and @xmath249 from which it follows using that latexmath:[\\[\\begin{aligned } \\label{step12c }    finally , latexmath:[\\[\\begin{aligned } \\label{step12d }    thus , by , , and symmetry , it remains to show that for @xmath210 , @xmath251 to this end , let @xmath252 be a  small constant such that @xmath253 for all @xmath254 .",
    "then we have @xmath255 and therefore @xmath256 which entails by choosing @xmath209 large  enough .",
    "this completes the proof of theorem [ complex - s ] .    with essentially the same proof",
    ", we obtain the following result :    [ real - s ] let @xmath195 denote the second - order correlation function of a real sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath160 , @xmath193 , setting @xmath196 we have @xmath257 where @xmath258 and @xmath259 is defined as in .",
    "in order to zoom in at the soft edge of the spectrum , we have to make the replacements @xmath260 where @xmath193 .",
    "( the factor @xmath261 is for convenience . )",
    "we then have the following result :    [ complex - a ] let @xmath195 denote the second - order correlation function of a complex sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath193 , setting @xmath262 we have @xmath263 where @xmath198 and @xmath264 is defined as in .    by ( [ intrep2 ] ) , we have @xmath265 where now @xmath266 this time we take @xmath267 .",
    "similarly as for the bulk of the spectrum , we  reduce the proof to the following two claims :    on the one hand , we will show that for any ( fixed ) @xmath203 , @xmath268 where @xmath205 denotes the restriction of the path @xmath169 to the set @xmath269 , and @xmath270    on the other hand , we will show that for any @xmath208 , there exists some @xmath209 such that for @xmath210 , we have @xmath271 for all @xmath272 large enough . here",
    "@xmath213 denotes the restriction of the path @xmath169 to the set @xmath273 .    using the integral representation for the airy kernel given in @xcite , the theorem",
    "may then be deduced using similar arguments as in the previous section . indeed , first of all , and imply that @xmath274 where @xmath275 substituting @xmath276 , @xmath277 , and shifting the path back to the line @xmath278 ( which is easily justified by cauchy s theorem ) , we obtain @xmath279 making the replacements @xmath280 , @xmath281 and multiplying by @xmath261 , we further obtain @xmath282 by proposition 2.2 in @xcite , the latter expression is equal to @xmath283 , whence .    to prove and , we proceed similarly as in the last section .",
    "first of all , we rewrite the integrand as @xmath284 where now @xmath285 and @xmath225 similarly as in the previous section , we find have @xmath286    to prove ( [ claim21 ] ) , we use taylor expansion .",
    "straightforward calculations show that , for @xmath236 , @xmath287 for the second approximation , we have used the observation that for @xmath236 , @xmath288 as well as the asymptotic approximation for the modified bessel function . putting it all together",
    ", the highest - order terms cancel out , and we find that the left - hand side of is asymptotically given by @xmath289 which establishes .    it remains to show . to this end",
    ", we will first show that @xmath290 write @xmath241 , where @xmath291 , @xmath243 $ ] .",
    "then , since @xmath292 @xmath293 the proof of is reduced to showing that @xmath294 now , for sufficiently large @xmath212 , @xmath295 @xmath296 where @xmath297 denotes a constant depending only on @xmath24 which need not be the same at  each occurrence .",
    "it follows that @xmath298 ( here some uniformly bounded terms have been absorbed into the constant @xmath297 . ) since @xmath299 , the numerator is bounded above by @xmath300 and is proved .",
    "furthermore , the same arguments as those leading to yield latexmath:[\\[\\begin{aligned } \\label{step22b }    hence , by , , and symmetry , in order to complete the proof of , it  remains to show that for @xmath210 , @xmath302 but this can be proved in the same way as .    with essentially the same proof",
    ", we obtain the following result :    [ real - a ] let @xmath195 denote the second - order correlation function of a real sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath193 , setting @xmath262 we have @xmath303 where @xmath258 and @xmath304 is defined as in .",
    "in order to zoom in at the hard edge of the spectrum , we have to make the replacements @xmath305 where @xmath306 .",
    "we then have the following result :    [ complex - j ] let @xmath195 denote the second - order correlation function of a complex sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath306 , setting @xmath307",
    ", we have @xmath308 where @xmath198 and @xmath309 is defined as in .    by ( [ intrep2 ] )",
    ", we have @xmath310 where now @xmath311 for the radius @xmath185 we make the same choice as for the bulk of the spectrum , namely @xmath312 .",
    "similarly as in the preceding sections , we reduce the proof to  the  following two claims :        once these two claims are established , the proof of theorem [ complex - j ] is completed using similar arguments as in the preceding section . and imply that @xmath316 where @xmath317 substituting @xmath318 , @xmath319 , and shifting the path back to the line @xmath278 ( which is easily justified by cauchy s theorem ) , we obtain @xmath320 making the replacements @xmath321 , @xmath322 and dividing by @xmath323 , we further obtain @xmath324 the subsequent lemma [ lemma ] states that this is equal to @xmath325 , thereby proving .",
    "to prove ( [ claim31 ] ) , we proceed by taylor expansion once more . a major difference to the previous situations",
    "is given by the fact that , for @xmath236 , @xmath326 remains bounded . since , for @xmath236 , @xmath327 we obtain @xmath328 whence .",
    "we start from the following integral representation for the product of two bessel functions ( see p.  281 in @xcite ) : @xmath332 differentiating with respect to @xmath333 and @xmath334 , we obtain @xmath335 and @xmath336 respectively . multiplying the former equation by @xmath333 and the latter equation by @xmath334 , taking the difference and dividing by @xmath337 yields @xmath338 the assertion now follows by letting @xmath339 , @xmath340 , and @xmath341 .",
    "[ real - j ] let @xmath195 denote the second - order correlation function of a real sample covariance matrix satisfying our standing moment conditions . for any @xmath118 , @xmath306 , setting @xmath307 , we have @xmath342 where @xmath258 and @xmath343 is defined as in ."
  ],
  "abstract_text": [
    "<S> we investigate the second - order correlation function of the characteristic polynomial of a sample covariance matrix . starting from an explicit formula for a generating function , </S>",
    "<S> we re - obtain several well - known kernels from random matrix theory . </S>"
  ]
}