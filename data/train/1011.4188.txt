{
  "article_text": [
    "action potentials are stereotyped all - or - nothing events , meaning that their amplitude is not considered to transmit any information and only the exact time of occurrence matters .",
    "this view suggests to model neurons responses in the mathematical framework of point processes . an observation is a sequence of spike times and their stochastic properties",
    "are captured by a single function , the conditional intensity @xcite . for point processes on the time line , several approaches for evaluating goodness - of - fit",
    "have been proposed @xcite .",
    "the most popular in the neuroscientific community has been a test based on the time - rescaling theorem @xcite .    in practice",
    ", neural data is binned such that a spike train is represented as a sequence of spike counts per time bin .",
    "specifically , generalized linear models ( glms ) are built on this representation .",
    "such discretized models of time series have mostly been seen as an approximation to continuous point processes and hence , the time - rescaling theorem was also applied to such models @xcite .    here",
    "we ask the question whether the time - rescaling theorem can be translated to discrete time .",
    "we review the approximations necessary for the transition to discrete time and point out a procedure to create surrogate point processes even when these approximations do not hold ( section  [ sec : methods ] ) .",
    "two novel tests based on two different operations on point processes are introduced : random thinning and random complementing .",
    "these ideas are applied to a series of examples ( section  [ sec : results ] ) , followed by a discussion ( section  [ sec : discussion ] ) .",
    "we characterize a neuron by its response in terms of trains of action potentials using the theory of _ point processes _ ( figures  [ fig : spiketrainrepresentations]a and [ fig : spiketrainrepresentations]b ) .",
    "an observation consists of a list of times , each denoting the time point of one action potential . following a common notation @xcite ,",
    "let @xmath0 $ ] be the time interval of the measurement and @xmath1 be the set of @xmath2 event times .",
    "the stochastic properties of a point process are characterized by its conditional intensity function @xmath3 , defined as @xcite :    @xmath4}{\\delta } , \\ ] ]    where @xmath5 is the history of the stochastic process up to time @xmath6 and possibly includes other covariates of interest . for fitting and evaluating different parameter sets of the conditional intensity function , a maximum - likelihood approach",
    "is followed @xcite .",
    "the log - likelihood of a point process model is given by @xcite :    @xmath7    one possibility are binning - free models ( like renewal processes or other parametric models ) .",
    "alternatively , @xmath8 can be modeled as a piece - wise constant function with each piece having length @xmath9 . in this case",
    ", the history term @xmath5 covers the history up to the time of the left edge of the current bin . inside the bin",
    ", the process locally behaves like a poisson process with constant rate @xmath10 with @xmath11 and @xmath12 .",
    "using the number of spikes @xmath13 per bin as a representation of the observation , the discretized version of equation  [ eq : likelihoodforcond ] is equivalent to the log - likelihood of a series of poisson samples ( apart from terms that are not dependent on @xmath8 ) . hence , for finding the maximum - likelihood solution for the point process , it is equivalently sufficient to maximize the likelihood of such a poisson regression model .",
    "the result of fitting will be a sequence of @xmath14 for each bin , where @xmath14 is the expected number of counts .",
    "since a local poisson process is assumed within the bins , @xmath14 is related to @xmath15 via : @xmath16 .",
    "a complementary approach to the point process framework is to see spike trains as _ time series _ , e.  g.  as a sequence of counts @xmath17 or binary events @xmath18 ( figures  [ fig : spiketrainrepresentations]c and [ fig : spiketrainrepresentations]d ) . for poisson - glms , a sequence of poisson - distributed count variables @xmath19",
    "is modeled and the linear sum of covariates is linked to the expected mean of the poisson distribution @xmath14 .",
    "binary time series can be modeled as a sequence of conditionally independent bernoulli trials with outcomes 0 and 1 and success probabilities @xmath20 . for bernoulli - glms , the @xmath21s",
    "are linked via a non - linear transfer function to a linear sum of covariates .",
    "defined this way , the likelihood for an observed sequence @xmath22 given a particular model of @xmath21 is given by @xmath23 .",
    "in the approximation of @xmath24 , @xmath14 becomes approximately @xmath21 and the likelihoods of the bernoulli and poisson series become equivalent .",
    "moreover , using the same approximation , it is possible to link the bernoulli series to the conditional intensity function @xmath8 via @xmath25 .",
    "traditionally , this path was chosen to relate the time series to the theory of point processes and to be able to use goodness - of - fit analyses available for such point processes @xcite .",
    "statistical tests are usually evaluated using two measures : the _ specificity _ ( fraction of correct models that pass the test ) and the _ sensitivity _ or _ test power _ ( fraction of wrong models that are properly rejected by the test ) .",
    "the specificity is set by the significance level : with significance level @xmath26 , the specificity is @xmath27 .",
    "the sensitivity of a given test depends on the strength of the departure from the modeled intensity function to the true intensity .",
    "a popular way for verifying point - process - based models has been the time - rescaling theorem @xcite .",
    "it states that if @xmath1 is a realization of events from a point process with conditional intensity @xmath8 , then rescaling via the transformation @xmath28 will yield a unit - rate poisson process .",
    "we call the following transformation the _ nave time - rescaling _ when it is applied to binary sequences .",
    "the spike time @xmath29 falling into bin @xmath30 , is transformed into : @xmath31 .",
    ", spikes of the original spike train are thinned by keeping a spike only with probability @xmath32 .",
    "( c ) assuming that the conditional intensity function has an upper limit @xmath33 , a complementary process @xmath34 can be constructed . adding samples from this inhomogeneous poisson process to the observed spikes results in a homogeneous poisson process with rate @xmath33 . ]",
    "it is well known that an inhomogeneous point process can be simulated by generating a homogeneous poisson process with constant intensity @xmath33 with @xmath35 ( the so - called dominant process ) and keeping every spike at time @xmath36 with probability @xmath37 @xcite . in reverse , this can be used to do model - checking @xcite : let @xmath38 be a lower bound of the fitted conditional intensity @xmath3 . now take @xmath3 as the dominant process with samples @xmath29 .",
    "thin the process by keeping a spike with probability @xmath39 . for a correctly specified model @xmath8",
    ", the thinned process will be a homogeneous poisson process with rate @xmath38 ( figure  [ fig : scheme]b ) .",
    "typically , @xmath40 ( due to absolute refractoriness in most renewal process models and glms ) , such that the thinned process will have a prohibitively low rate and only very few spikes will be selected .",
    "testing the poisson hypothesis on a handful of spikes will result in a vanishingly low power .    to circumvent this problem",
    ", we propose the following remedy : let @xmath41 be a threshold which may be higher than the lower bound @xmath38 .",
    "then consider only the intervals of @xmath42 for which @xmath43 and concatenate those into a new point process .",
    "after applying the thinning procedure on all spikes of the stitched process , the thinned process should be a poisson process with rate @xmath41 .",
    "this procedure can be repeated @xmath44 times for a range of uniformly spaced @xmath41s ranging from @xmath38 to @xmath33 ( upper bound ) .",
    "stretching each thinned process by a factor of @xmath41 creates a set of @xmath44 unit - rate processes .",
    "each of them is tested for the poisson hypothesis by a kolmogorov - smirnov test on the inter - spike intervals .",
    "the model is rejected when there is at least one significant rejected null hypothesis . to correct for the multiple tests",
    ", we employ simes procedure .",
    "it tests the global null hypothesis that all tested sub - hypotheses are true against the alternative hypothesis that at least one hypothesis is false . to this end",
    ", it transforms the ordered list of p - values @xmath45 into @xmath46 .",
    "if any of the transformed p - values is less than the significance level @xmath47 , the model is rejected @xcite tests contain overlapping regions of the same spike train , hence , we expect the statistical tests to be correlated . in these cases , a simple bonferroni - correction would be too conservative @xcite . ] .",
    "the idea of thinning might also be used the other way round . assume the observations",
    "@xmath29 have been generated by thinning a homogeneous poisson process with rate @xmath33 using the modeled conditional intensity @xmath8 as the lower bound .",
    "then we can define a complementary process @xmath48 such that adding spikes from the complementary point process to the observed spikes , the resulting process will be a homogeneous poisson process with rate c. this algorithm is a straight - forward inversion of the thinning algorithms discussed in @xcite .",
    "it might happen that the upper bound @xmath33 of the modeled intensity is much larger than the average @xmath49 .",
    "in that case , the observed spike pattern would be distorted with high number of poisson spikes from the complementary process and the test power would be low . to avoid this ,",
    "a similar technique as for the thinning procedure can be employed .",
    "define a threshold @xmath50 and consider only the region of the spike train for which @xmath51 .",
    "apply the complementing procedure on these parts of the spike train to obtain a point process with rate @xmath52 when concatenating the intervals .",
    "this process can be repeated @xmath44 times with values @xmath52 ranging from @xmath38 to @xmath33 .",
    "a multiple - test correction has to be used , again we propose simes method ( see previous section ) .",
    "since the time - rescaling theorem can only be used when @xmath8 the exact spike times @xmath1 are known , it is not a priori clear how it applies to discretized time - series models . for such cases ,",
    "we propose to generate surrogate point process samples that are equivalent to the observed time series .",
    "to apply the time - rescaling theorem on discretized models such as glms , the integral of the time transformation is replaced by a discrete sum over bins ( the _ nave time - rescaling _ ) .",
    "taking the simplest example of a homogeneous poisson process , it is evident that the possible values for the rescaled intervals form a finite set .",
    "this contradicts the time - rescaling theorem that states that the intervals are ( continuously ) exponentially distributed .",
    "hence , using the time - rescaling theorem on discretized data produces a bias @xcite .    while haslinger et al .",
    "considered a modification of the time - rescaling theorem to explicitly account for the discrete nature of the model @xcite , we propose a general , simple scheme how to form surrogate point processes from poisson- and bernoulli - glms that can be used for the continuous time - rescaling theorem as well as for any other goodness - of - fit test designed for point - process data ( figure  [ fig : flowchart ] ) .",
    "* poisson - glms * : the observation consists of a sequence of count variables @xmath19 that is modeled as a sample from poisson distributions with mean @xmath14 . hence , the modeled process can be regarded as a piecewise - constant intensity function . the expected number of spikes of a poisson process is related to its intensity via @xmath53 such that we can construct the conditional intensity function as piece - wise constant with values @xmath54 . conditioned on the number of spikes that occurred in a homogeneous poisson process of rate @xmath15 , the exact spike times are uniformly distributed inside bin @xmath55 .",
    "a surrogate point process can be constructed from a poisson - glm by generating random spike times @xmath56 for each spike within bin i ( @xmath57 ) for all bins with @xmath58 .",
    "one can then proceed to the point - process - based goodness - of - fit tools using the surrogate spike train and its conditional intensity @xmath15 .",
    "* bernoulli - glms * : based on the observed binary spike train @xmath18 , the sequence of probabilities @xmath21 of spiking within bin @xmath55 is modeled .",
    "we can relate this to the point process framework using the following observations : assume that @xmath21 denotes the probability of finding at least one spike within each bin and that locally , the process behaves like a poisson process .",
    "then , @xmath59 .",
    "the conditional intensity is given by @xmath60 .",
    "in practice , for each bin with @xmath61 , we draw the amount of spikes within the bin by first sampling from the distribution @xmath62 and sample exact spike times uniformly as in the case of the poisson - glms",
    ".     is available , goodness - of - fit tests for point processes can be readily applied . for poisson - glms",
    ", exact spike times are drawn inside each bin for the specified number of spikes that were observed .",
    "the piece - wise constant conditional intensity function is linked to the modeled number of counts per bin via @xmath63 . for bernoulli - glms ,",
    "the probability of obtaining at least one spike per bin @xmath21 is modeled .",
    "for each bin with spikes ( @xmath61 )  assuming a local poisson process  a sample @xmath19 from a biased poisson distribution with mean @xmath64 is drawn together with corresponding spike times .",
    "finally , point - process based goodness - of - fit tests may be applied to this surrogate spike train . ]",
    "here , we compare the performance of the three different approaches in detecting wrongly specified models , using examples of models that are commonly applied in neural data analysis . for the thinning and complementing procedure ,",
    "@xmath65 partitions were chosen ( see section  [ sec : gof_thinning ] ) . unless otherwise noted , we report the test power at a specificity of @xmath66 . the poisson hypothesis in the proposed procedures",
    "is tested by a kolmogorov - smirnov test on the inter - spike intervals of the transformed process .",
    "consider an inhomogeneous poisson process with band - limited intensity : @xmath67 with @xmath68  hz and @xmath69 coefficients that were randomly drawn from a uniform distribution on the interval @xmath70 $ ] .",
    "the process was simulated over a length of @xmath71  s and the intensity was discretized with @xmath72  ms .",
    "negative intensities were clipped to zero .",
    "a binary spike train was generated by calculating the probability of at least one spike in each time bin as @xmath73 and drawing samples from a bernoulli distribution with specified probabilities @xmath21 .",
    "for evaluating the different algorithms , wrong models for the intensity were created with jittered coefficients @xmath74 where @xmath75 indicates the strength of the deviation from the true model . for each jitter strength ,",
    "@xmath76 spike trains were generated from the true model and @xmath8 was constructed using the wrong model ( figure  [ fig : exinhomo]a ) . for any @xmath77 , the fraction of rejected models defines the sensitivity or test power . for @xmath78 ,",
    "the fraction of accepted models defines the specificity which was controlled to be at @xmath79 for each test .",
    "all three methods ( rescaling , thinning , complementing ) show a specified type - i error of approximately 5% ( @xmath78 ) and progressively detect the wrong models .",
    "notably , the complementing and thinning procedures detect a departure from the correct model earlier than the classical rescaling ( figure  [ fig : exinhomo]b ) . for comparison , also the nave implementation of the rescaling transformation",
    "is shown . the significance level for the ks test used for the nave time - rescaling",
    "was adjusted to @xmath80 to achieve a 95% specificity .",
    "the adjustment was necessary due to the discretization bias ( see section  [ sec : surrogate ] ) .    for models with an intermediate jitter strength ( @xmath81 ) ,",
    "roc curves were constructed . here , for a given significance level @xmath26 , a pair of true and false positive rates can be calculated and plotted for each test ( taking @xmath76 repetitions using the true model and the model with jittered coefficients ) .",
    "it can be seen that especially for intermediate jitter strengths , complementing and thinning outperform time - rescaling ( figure  [ fig : exinhomo]c ) , independent of the chosen significance level .      in a second example",
    ", we consider renewal processes , i.  e.  inter - spike intervals are an i.  i.  d. sample from a specific probability distribution @xmath82 . in this case , the conditional intensity is given by @xmath83 where @xmath84 denotes the time of the last spike prior to time t. for this example , we chose the gamma distribution as it is commonly used to model real spike trains @xcite .",
    "the spike train was generated from a true model , following a gamma distribution with scale parameter @xmath85 and shape parameter @xmath86 : @xmath87 .",
    "wrong models were generated by scaling the shape and scale parameter by a factor of @xmath88 ( `` jitter '' ) while keeping the expected value of the distribution constant ( i.  e.  @xmath89 , @xmath90 ) ( figure  [ fig : exgamma]a ) .",
    "for each jitter strength , @xmath76 data sets of length @xmath91 were generated from the true model and the wrong model and the tests were applied .",
    "the analysis of test power for each test and the roc curve analysis for an intermediate jitter strength reveal that time - rescaling is slightly superior to thinning and complementing ( figure  [ fig : exgamma]b and c ) . the nave time - rescaling performs worst ( adjusted significance level for the ks test , @xmath92 ) .",
    "we model an inhomogeneous spike response model with escape noise using a bernoulli - glm @xcite .",
    "the spiking probability is modulated by an inhomogeneous rate @xmath93 . additionally , for each spike",
    ", a post - spike kernel is added to the process intensity .",
    "the rate function is modeled like in the first example as a band - limited function @xmath94 with @xmath95  hz and @xmath96 coefficients that were randomly drawn from a uniform distribution on the interval @xmath97 $ ] .",
    "the post - spike kernel @xmath98 is modeled as a sum of three exponential functions ( @xmath99  ms , @xmath100  ms and @xmath101  s ) with appropriate amplitudes as to mimick a relative refractory period , a small rebound and a slow ( inhibitory ) adaptation . to construct the bernoulli - glm ,",
    "the spiking probability @xmath21 per bin of length @xmath102  ms is @xmath103 with @xmath104 .",
    "a binary time series ( the spike train ) was generated for a duration of @xmath105  s. the jittered models were constructed by adding a jitter @xmath75 on the coefficients of the inhomogeneous rate modulation ( figure  [ fig : exsrm]a ) .",
    "for each jitter strength , @xmath106 data sets were generated from the true model and the wrong model and the tests were applied .",
    "both thinning and complementing are able to detect smaller distortions than both the time - rescaling on the surrogate and discrete data ( figure  [ fig : exsrm]b , adjusted significance level for the nave rescaling , @xmath107 ) . a roc curve analysis for an intermediate jitter strength ( @xmath108 ) supports this finding ( figure  [ fig : exsrm]c ) .",
    "assessing goodness - of - fit for generalized linear models has mostly been done by applying the time - rescaling transformation that is defined for point processes , assuming a match between those approaches .",
    "when the per - bin probability of spiking can not be regarded as low , this approximation breaks down and creates a bias when applying the time - rescaling transformation @xcite . in a first step , we proposed a procedure to create surrogate point processes from discretized models , such as bernoulli- and poisson - glms , that do not exhibit this bias . throughout all the examples , the time - rescaling theorem applied to the surrogate point process was systematically better than applying the nave time - rescaling on the discrete data .",
    "since only the adjusted time - rescaling procedure allows to reliably control the specificity of the test , it should be preferred over the classical time - rescaling in all cases where discretized models are used .",
    "we have presented two alternatives to an application of the time - rescaling theorem : for the first procedure , the observed spike train is thinned according to the value of the conditional intensity at the time of spikes .",
    "the resulting process is then a homogeneous poisson process with a rate that is equal to the lower bound on the conditional intensity .",
    "the second proposed method builds on the idea that an intensity function @xmath49 with an upper bound @xmath33 can be filled up to a homogeneous poisson process of rate @xmath33 by adding spike samples from the complementary process @xmath109 .",
    "the proposed tests work best if the lower and upper bounds are tight .",
    "however , in most practical cases , especially the lower bound will be prohibitively low to apply any statistical test on the thinned process . as a remedy",
    ", we proposed to consider only regions of @xmath3 for which the intensity exceeds a given threshold and repeat the thinning for different thresholds .",
    "this successfully overcomes the limitation that may have  up to now  prevented the use of the thinning algorithm as a goodness - of - fit measure for neural models .",
    "the three tests are complementary in the sense that they are sensitive to different deviations of the modeled and true intensity function .",
    "time - rescaling is only sensitive to the total integral of the intensity function between spikes , while thinning exclusively considers the intensity function at the time of spikes and is insensitive to its value at places where no spikes occurred .",
    "complementing is sensitive to the exact shape of @xmath49 regardless of where the spikes from the original observations are .    for the examples of an inhomogeneous poisson process and the spike response model , thinning and complementing outperform the sensitivity of the simple time - rescaling procedure .",
    "they can detect deviations from the model that are only half as large as the ones necessary to alert the test based on time - rescaling . for modeling renewal processes ,",
    "time - rescaling was slightly advantageous compared to the to other methods .",
    "this should not come as a surprise since the time - rescaling test is known to be sensitive to modeling the distribution of inter - spike intervals @xcite .    beside from likelihood criteria @xcite",
    ", there exist few goodness - of - fit tools for neural models based on generalized linear models @xcite . with the proposed procedure for surrogate point processes",
    ", we bridge the gap between such discrete models and point processes .",
    "that enables to make use of additional tests from this domain , such as thinning and complementing procedures .",
    "we expect these to be valuable contributions to the general practice of statistical evaluation in modeling single neurons as well as neural populations ."
  ],
  "abstract_text": [
    "<S> generalized linear models ( glms ) are an increasingly popular framework for modeling neural spike trains . </S>",
    "<S> they have been linked to the theory of stochastic point processes and researchers have used this relation to assess goodness - of - fit using methods from point - process theory , e.g. the time - rescaling theorem . however , high neural firing rates or coarse discretization lead to a breakdown of the assumptions necessary for this connection . here , we show how goodness - of - fit tests from point - process theory can still be applied to glms by constructing equivalent surrogate point processes out of time - series observations . </S>",
    "<S> furthermore , two additional tests based on thinning and complementing point processes are introduced . </S>",
    "<S> they augment the instruments available for checking model adequacy of point processes as well as discretized models . </S>"
  ]
}