{
  "article_text": [
    "wavelet synopsis techniques have become extremely popular in query optimization , approximate query answering and a large number decision support systems .",
    "wavelets , specially haar wavelets , are one - one mappings and admit a natural multi - resolution interpretation , as well as fast algorithms for the forward and inverse transforms .    given a set of @xmath0 numbers @xmath1 the wavelet synopsis construction problem seeks to choose a synopsis vector @xmath2 with at most @xmath3 non - zero entries , such that the inverse wavelet transform of @xmath2 ( denoted by @xmath4 ) gives a good estimate of the data .",
    "the typical objective measures are ( suitably weighted with weights @xmath5 and wlog @xmath6 minimizes @xmath7 . ] ) @xmath8 norm of @xmath9 . in an early paper @xcite , demonstrated a number of different applications for wavelet synopsis and proposed greedy algorithms .",
    "however for objective measures other than the @xmath10 measure , the greedy algorithm does not necessarily provide the optimum solution .",
    "the problem is quite non - trivial , primarily due the fact that the wavelet basis vectors overlap and cancellations ( subtractions ) occur .",
    "this means that we can have two coefficients that cancel out each other leaving a significantly ( exponentially ) smaller contribution , which needs to be accounted for .",
    "the precision of the coefficients in the optimum solution can be much larger than the precision of the data .",
    "in fact there are no known bounds or promising techniques for quantifying the precision - this is the biggest stumbling block in the synopsis construction .",
    "most of the literature focuses on the * restricted case * where the non - zero entries of @xmath2 are equal to the corresponding entries in the transform of the original data , @xmath11 .",
    "a natural question remains : _",
    "why should we be optimizing under the restriction of retaining the coefficients of the data  with no guarantees that such a restriction does not compromise the quality of the final synopsis ?",
    "_ this is clearly suboptimal  a comparable example would be to optimize the synopsis for point queries , and use it for range queries .",
    "a simple example renders the discussion concrete ; @xmath12 and @xmath13 illustrates that choosing any single coefficient of @xmath14 ( non - normalized ) does not give the optimum answer for @xmath15 or @xmath16 norm .",
    "normalization does not help .",
    "the normalized transform is @xmath17  but choosing the first coefficient as @xmath18 in the normalized setting implies assigning @xmath19 everywhere .",
    "thus dynamic program approaches that seek to see the effect of the coefficient on the data come to the same conclusion in both settings .",
    "the optimum choices of @xmath2 are @xmath20 for any @xmath21 and @xmath22 for @xmath15 and @xmath16 respectively .",
    "the same example applies to * weighted * @xmath23 , e.g. , if @xmath24 then the best error achieved by retaining any single entry of @xmath11 is @xmath25 whereas @xmath26 gives an error of @xmath27 .",
    "the example can be extended to any @xmath3 ( by repetition and scaling ) .",
    "the restriction of only retaining the coefficients of the data is significantly self defeating .",
    "however the restriction does ease the search for a solution , and as this paper shows , is an important stepping stone towards the final result .",
    "for the restricted case , @xcite gave a probabilistic scheme ( the space constraint is preserved in expectation only , along with the error ) and very recently @xcite gave an optimal solution .",
    "this has been extended and improved in @xcite .",
    "_ however , the solution to the unrestricted case has remained elusive and we provide the first near optimal solutions . _ in the process , we also improve upon previous algorithms for the restricted case as well .",
    "however our algorithm is best explained by taking a different path , which brings us to the _ major theme _ of the paper .",
    "synopsis construction is perhaps most relevant in context of massive data sets . in some scenarios we can justify that the synopsis is created using a `` scratch '' space larger than the synopsis and stored .",
    "however a _ quadratic _ or extremely superlinear space complexity is near infeasible for large @xmath0 .",
    "the dependence on synopsis size @xmath3 is also important in this context  the smaller the dependence is , the larger is the synopsis that can be computed in the environment of a particular system .",
    "further , _",
    "space is typically a more inflexible resource _ , and not just a matter of wait .",
    "however a natural conceptual question arises : _ we are only given @xmath0 numbers ,  do we really need to save so much information to compute the optimum answer ?",
    "_    all previous algorithms ( for the restricted case ) are expensive in space ( see table below ) .",
    "this ( super - linearity in @xmath28 ) is also seen in context of histogram construction ( we provide a detailed table in section  [ sec : hist ] ) . to avoid this expensive space complexity ,",
    "several researchers have introduced the notion of _ working space _ , which is the amount of space required to compute the error  the rest of the space is used to construct the answer ( coefficients , representatives , etc . ) . in case of wavelets",
    "the working space used by previous algorithms is @xmath29 . in case of histograms ,",
    "known algorithms reconstruct the answer only using the @xmath30 working space , but _ with a penalty of an extra factor of @xmath3 in the running time_. in this paper , we reduce the space for wavelets and eliminate the penalty for histograms , in fact our results show that the _ working space notion is not needed _ for a wide range of problems . to summarize * our contributions",
    "* :    * we provide the first near optimum algorithm for the wavelet synopsis construction problem .",
    "the algorithm naturally extends to multiple dimensions .",
    "* for the restricted case @xcite provided approximation algorithms , however the space constraints were obeyed in expectation .",
    "the results for ( optimum ) algorithms with strict space bounds are : as well .",
    "the authors of @xcite consider the same problem for a non - haar basis , and is excluded from the discussion here ] + [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]      we follow the previous algorithms and introduce a few small changes and a more careful analysis .",
    "for each item @xmath31 we compute the best profit if @xmath31 is allocated size @xmath32 .",
    "this is done in time @xmath33 as in @xcite .",
    "for each @xmath34 we maintain the top @xmath35 items corresponding to size @xmath32 .",
    "for each @xmath32 we can achieve this in @xmath36 space and @xmath30 running time ( using details from @xcite ) , using overall @xmath37 time and @xmath38 space .",
    "the optimum answer uses items and sizes from this list only .",
    "the total number of item - size pairs are @xmath39 .",
    "we can sort this list in lexicographic order .",
    "suppose item @xmath31 has @xmath40 occurrences ( thus @xmath41 ) .",
    "the dynamic program to extend the answer to @xmath31 ( from the item before @xmath31 ) first needs to guess / choose which of the @xmath42 occurrences are used ( or none ) and compute the best solution for each @xmath3 .",
    "the time taken is @xmath43 at @xmath31 , which totals to at most @xmath44 .",
    "we maintain a @xmath45 array where @xmath46 $ ] corresponds to the best profit for space @xmath47 up to the current @xmath31 .",
    "for _ space efficiency _ , for @xmath48 we keep track of @xmath49 $ ] which contains the pair @xmath50 s.t .",
    "the optimum solution for space @xmath47 for current @xmath31 uses space @xmath51 upton @xmath52 and a size @xmath53 copy of @xmath52 with @xmath54 . in other words ,",
    "the _ crossing point _ where we crossed @xmath55 space for that solution ( which remains same even if we extend it later ) .",
    "we now recurse with @xmath56 on the two parts .",
    "now each item contributes @xmath57 adding up to less than @xmath58 .",
    "once again we have a geometric sum which sums up to @xmath59 for the entire recursion .",
    "+ * acknowledgments : * we would like to thank hyoungmin park and kyuseok shim for many interesting discussions ."
  ],
  "abstract_text": [
    "<S> in this paper we consider the wavelet synopsis construction problem without the restriction that we only choose a subset of coefficients of the original data . </S>",
    "<S> we provide the first near optimal algorithm .    </S>",
    "<S> we arrive at the above algorithm by considering space efficient algorithms for the restricted version of the problem . in this context </S>",
    "<S> we improve previous algorithms by almost a linear factor and reduce the required space to almost linear . </S>",
    "<S> our techniques also extend to histogram construction , and improve the space - running time tradeoffs for v - opt and range query histograms . </S>",
    "<S> we believe the idea applies to a broad range of dynamic programs and demonstrate it by showing improvements in a knapsack - like setting seen in construction of extended wavelets . </S>"
  ]
}