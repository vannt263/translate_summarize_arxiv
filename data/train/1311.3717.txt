{
  "article_text": [
    "metagenomics is an area of microbial genomics devoted to the unified study of complex cultures found in the human body and the ecosystem .",
    "the main difference between classical genomics and metagenomics is the fact that in the latter , no attempt is made to separate the organisms in a sample .",
    "the reasons for using such a holistic approach are either of purely technical nature  in cases when single sample isolation is technically implausible to accomplish  or they may be governed by the desire to explore the interactions , dynamical co - regulation and joint evolution of microbes in a given environment  @xcite .",
    "unlike the field of genomics , metagenomics is still in its infancy , despite recent intense research efforts in the areas of metagenomic sampling , sequencing and assembly  @xcite .",
    "the main challenges in the field are a still fairly large cost of high - coverage metagenomic sequencing , although cost constraints are likely to diminish in the near future ; and the extremely large file sizes produced by high - throughput sequencers such as illumina , when applied to metagenomic data . as an illustration , the size of the human gut microbial population is estimated to be several hundreds , while average bacterial genome lengths are between @xmath0 kbp ( kilobasepairs ) and @xmath1 mbp ( megabasepairs ) . with a coverage of",
    "at least @xmath0 reads per base pair , one arrives at a rough estimate of @xmath0 gbp ( gigabasepairs ) of genomic data . analyzing , storing and transmitting such volumes of data is a formidable task , and most efforts on metagenome assembly require powerful and parallelized computer clusters to perform even the most basic operations .    in parallel ,",
    "an extensive effort is underway to develop efficient means for lossless and lossy compression of whole genomes  @xcite , as well as for compression of reads sampled from a single genome  @xcite .",
    "specialized methods for compressing protein - coding regions as well as regions with frequent repeats were reported in  @xcite , using methods as diverse as modified lempel - ziv encoding , the burrows - wheeler transform and wavelet - based decomposition .",
    "compression of reads is mainly achieved by using a reference genome , with an initial study based on golomb codes reported in  @xcite and extensions thereof reported in  @xcite .",
    "we propose the first algorithmic solution to the problem of _ de novo _ metagenomic compression that mitigates the need for computationally demanding _ full _ metagenomic assembly by using a read classification technique and subsequent reference - based single genome compression .",
    "the gist of the classification method is to use a microbe identification tool  _ metaphyler _",
    "@xcite  that can accurately identify the order of a high percentage of organisms from a metagenomic mix . by aligning the reads to _ all genomes _ of organisms within the identified orders via _ bowtie2 _",
    "@xcite , one can provide a rough classification map for reference - based compression . for moderate size samples ,",
    "unaligned reads usually amount to less than @xmath2 of the reads , and can be assembled through existing metagenome assembly software such as idba - ud  @xcite .",
    "starting positions of aligned reads and their differences from the reference genome are encoded using techniques outlined in  @xcite .",
    "the paper is organized as follows . in section  [ sec : algorithm ] , we describe the first algorithmic solution for metagenomic read compression . in section  [ sec : example ] , we demonstrate the performance of the method on synthetic illumina sequencer data , using a randomly selected set of @xmath3 bacterial organisms .",
    "concluding remarks are given in section  [ sec : conclusion ] .",
    "throughout the paper , we refer to an ordered sequence of symbols from the alphabet @xmath4 as a _ genome _ or _ genomic sequence_. elements of the sequence are indexed from @xmath5 to @xmath6 , the length of the sequence .",
    "a _ read _ is a _ substring _ of a genome , generated by some sequencing system .",
    "the starting and terminal location of a read correspond to the index of the first and last element of the read in the underlying genome .",
    "the support of the read is the set of indices of the genome between the starting and terminal location of a read .",
    "the _ coverage _ of an element in a given genome equals the number of reads that contain the index of the element in their support .",
    "_ assembly _ refers to the process of overlapping reads  suffix to prefix  in order to reconstruct the original sequence the reads came from .",
    "_ alignment _ refers to mapping reads onto a given genome .",
    "an example of a genome and a set of reads aligned to the sequence are depicted in figure  [ fig : single - genome ] .",
    "a similar alignment involving two genomes is depicted in figure  [ fig : two - genomes ] , also depicting several misaligned reads between species .",
    "given that metagenomic data carries valuable information about the population dynamics of microbes in a given environment , even small aberrations in the composition of the sample have to be observed and recorded for in - depth study of the underlying phenomena . also , given the cost of acquiring samples to sequence and laboratory work necessary for sequencing , it is also valuable to preserve and share the sequencing experiment in its entirety .",
    "hence , the goal of any compression method should be to preserve the reads intact , i.e. , to perform lossless read compression .",
    "the main issues associated with individual lossless read compression is that the reads  as generated by illumina , roche454 , iontorrent  are usually of length not exceeding @xmath7 bps , and that the number of reads is extremely large . the former property of reads does not allow any known compression algorithm to take full advantage of inherent patterns or data structures , since such algorithms offer good performance only for sufficiently long sequence lengths  @xcite . on the other hand , the existence of a huge volume of reads creates the problem of efficiently using their overlaps .",
    "such overlaps arise due to the requirement of large genome coverage , given that large coverage is needed for accurate sequence reconstruction .",
    "one simple method to mitigate the aforementioned problems is to perform _ reference based compression _",
    "reference based compression is based on the assumption that one knows some rough form of the genome the reads were generated from , without knowing the exact identity of the organism .",
    "such an approach can not be used for _ de novo _ compression , where the origin of the reads is unknown .",
    "such is the case for most metagenomic datasets currently available .",
    "one obvious solution would be to first apply a metagenomic assembly process to create an adequate number of reference genomes , and subsequently compress all the reads using the `` closest '' genome as a reference .",
    "this is infeasible in the long term due to the reduction of costs in sequencing technology , increases in sequencing depth and a desire to sequence more complex metagenomic samples . a current next generation sequencer such as",
    "the illumina hiseq 2500 system can produce up to 4.5 gb / hr  @xcite , a rate which will be quickly exceeded by future sequencers .",
    "thus , a laboratory running multiple sequencers must archive and distribute petabytes of data per year .",
    "since the read lengths are short , techniques such as de brujin graph assemblers  @xcite are needed for assembly at the cost of high memory and cpu time for large data sets , requiring prohibitively expensive computers .",
    "one approach to mitigate a related problem via distributed computing is described in tiger  @xcite for large single genomes , though this approach has not been validated on metagenomic samples .",
    "the insight towards the composition of the metagenomic sample is also deferred until after assembly .",
    "one approach that mitigates this issue  and the one pursued in this paper  is to perform a rough classification of the reads into subgroups that may individually be processed more efficiently for the purpose of both identifying a proper reference and for subsequent compression .",
    "the structure of such an algorithm is depicted in figure  [ fig : mcuiuc ] , with a brief description of the blocks provided in what follows .",
    "* * step 1 ( classification ) : * the first step of the procedure is a `` rough '' identification of the mixture of species in the metagenomic sample .",
    "one well established method for bacterial genome identification is the use of the so called 16s rrna regions  @xcite .",
    "although this method is helpful for basic taxonomic identification , it does not allow for the precision of methods based on multiple marker identification , such as metaphyler  @xcite .",
    "the gist of the approach in  @xcite is that almost every genomic substring of length exceeding @xmath8 is unique to a species .",
    "metaphyler hence scans for markers in excess of this length and links them to them to markers of documented species .",
    "therefore , known organisms have a high chance of being identified by this method up to a given taxonomic order , in this case , their genus .",
    "as will be shown in the next section , metaphyler reports the number of identified markers of genera as well as their corresponding abundance levels , but the algorithm often misses a number of species ( most often , undocumented species ) while introducing a large number of false positives . in order to optimize the performance of the subsequent steps of the algorithm , the selection of genera most likely contained in the mixture",
    "has to be performed using the identified number of markers , the length of the genome and other criteria .",
    "we elaborate on this issue in the following section . * * step 2 ( partitioning of the dataset ) : * 1 .",
    "once a group of genera is selected according to the procedure in step 1 , a set of reference genomes `` best '' aligned to the reads has to be selected . given that metaphyler produces predictions only up to the level of genera , one possible way to identify representative genomes in the mixture is to _ select all species of the identified genera _ and perform quick testing of alignment quality with the given reads .",
    "this task can be accomplished by using _ bowtie2 _",
    "@xcite , a specialized software for ultra - fast alignment of _ short _ reads to _ long _ genomes .",
    "bowtie2 was designed as an alternative to the blast ( basic local alignment search tool )  @xcite for cases when one has a very large number of short query sequences to be aligned with a small number of genomes .",
    "running bowtie2 on the metagenomic reads and reference genomes from all species within the identified genera allows for performing read classification up to the genus level in terms of best alignment score .",
    "it is worth pointing out that some reads will be reported as unaligned , i.e. , as not having sufficiently high similarity to any of the species to which alignment was performed .",
    "a means for parallelizing _",
    "single genome _",
    "assembly that shares some of the classification ideas of step 2 was first reported in  @xcite .",
    "2 .   in order to keep the number of reference genomes used for compression reasonably small ,",
    "the next step is to combine the reads assigned to members within one single genus , independent on which species they were identified to belong to .",
    "the species of each genus which had the most reads aligned to it is called the _ representative of the genus _ and is used for reference - based compression of all the reads mapped to the genus .",
    "unaligned reads are treated differently . given that their number is relatively small compared to the number of aligned reads , metagenomic assembly of such reads",
    "may be performed in a computationally efficient manner using a metagenomic assembler such as idba - ud  @xcite .",
    "the assembler produces _ contigs _  overlapped strings of reads of long lengths  that may subsequently be queried in blast to identify the organisms they most likely originated from . steps 2.1 and 2.2 are repeated using as input the unaligned reads from step 2.1 as well as the genera of organisms associated with the longest contigs .",
    "* * step 3 ( compression and distribution ) : * the number of unaligned reads remaining after step 2.3 is relatively small and can be compressed using a standard tool such as bzip2 .",
    "the reads associated with each genus are aligned to their representative using bowtie2 and outputted into the sam ( sequence alignment / map ) format .",
    "the resulting sam files are converted to the sorted and indexed bam format ( a binary format for sequencing data ) via samtools  @xcite .",
    "the bam file for each genus is compressed via reference - based compression against its representative to the cram format using the cram toolkit  @xcite .",
    "the cram toolkit provides a practical reference - based compression procedure and file format based on  @xcite .",
    "note a simple extension to the algorithm akin to  @xcite is to use some of the contigs as references for compression .",
    "these references would be packaged for distribution .",
    "the compressed unaligned reads , cram files , list of representatives for the genera , the corresponding genomes ( if they are not available through a standard database such as ncbi s microbial genome database ) and metaphyler taxonomic classification are packaged into a tar archive .",
    "the resulting archive can be distributed and the reads losslessly reconstructed via the cram toolkit , given the cram files and representative genomes .",
    "the representative genomes may be compressed using standard compressors such as bzip2 or specialized compressors such as dnacompress  @xcite .",
    ".a randomly selected set of @xmath3 species used to illustrate the operating principles of mcuiuc . [ cols=\"^,^,^\",options=\"header \" , ]     [ compression ]",
    "we described the first _ de novo _ metagenomic read compression algorithm .",
    "the algorithm was based on four major subroutines : genera identification , species identification , read classification and reference based single - genome compression .",
    "the performance of the method was illustrated on a simulated metagenomic sample with @xmath3 species , for which overall compression ratio on the order of 12.5 were reported .",
    "further work includes integrating side information such as genera known to be present in a sample with high likelihood , selection rules for using multiple representatives for a genus and integration of phylogenic aligners to mitigate the `` other '' category used in metaphyler at the genus level .",
    "this work was supported in part by nsf grants ccf 0809895 , ccf 1218764 , emerging frontiers for science of information center , ccf 0939370 and u.s .",
    "defense threat reduction agency through subcontract 147755 at the university of illinois from prime award hdtra1 - 10 - 1 - 0086 .",
    "the authors also gratefully acknowledge many useful discussions with prof .",
    "jian ma and xiaolong wu at the university of illinois , urbana - champaign .",
    "liu et al . , `` characterization of microbial diversity by determining terminal restriction fragment length polymorphisms of genes encoding 16s rrna , '' _ applied and environmental microbiology _ , 63 , no .",
    "11 , 4516 - 4522 , 1997 .                          c. xin , m. li , b. ma , and j. tromp , `` dnacompress : fast and effective dna sequence compression , '' _ bioinformatics _ 18 , no .",
    "12 , pp . 1696 - 1698 , 2002 .",
    "european molecular biology laboratory - european bioinformatics institute , `` cram format specification '' , ver .",
    "june 12 , 2013 [ online ] .",
    "available : http://www.ebi.ac.uk/ena/sites/ebi.ac.uk.ena/files/documents/cram_format_2_0.pdf"
  ],
  "abstract_text": [
    "<S> metagenomics is an emerging field of molecular biology concerned with analyzing the genomes of environmental samples comprising many different diverse organisms . </S>",
    "<S> given the nature of metagenomic data , one usually has to sequence the genomic material of all organisms in a batch , leading to a mix of reads coming from different dna sequences . in deep high - throughput sequencing experiments , </S>",
    "<S> the volume of the raw reads is extremely high , frequently exceeding 600 gb . with an ever increasing demand for storing such reads for future studies , </S>",
    "<S> the issue of efficient metagenomic compression becomes of paramount importance . </S>",
    "<S> we present the first known approach to metagenome read compression , termed mcuiuc ( metagenomic compression at uiuc ) . </S>",
    "<S> the gist of the proposed algorithm is to perform classification of reads based on unique organism identifiers , followed by reference - based alignment of reads for individually identified organisms , and metagenomic assembly of unclassified reads . </S>",
    "<S> once assembly and classification are completed , lossless reference based compression is performed via positional encoding . </S>",
    "<S> we evaluate the performance of the algorithm on moderate sized synthetic metagenomic samples involving 15 randomly selected organisms and describe future directions for improving the proposed compression method . </S>"
  ]
}