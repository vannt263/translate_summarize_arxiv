{
  "article_text": [
    "in the real - world applications such as e - commerce and online ad , a user s activity is not frequent , and item properties change dynamically over time . in a context of item recommendation ,",
    "such scenario is referred to as _ persistent cold - start_. for instance , booking.com @xcite shows an example of users rare activity and mixed personas ( _ * user - side * persistent cold - start _ ) , and rakuten gora @xcite demonstrates price fluctuation and short life - span of packaged items ( _ * item - side * persistent cold - start _ ) .",
    "most importantly , classical recommendation techniques have some drawbacks under the persistent cold - start setting .",
    "in fact , matrix factorization ( mf ) @xcite is one of the most typical and promising techniques , but mf only holds latent vectors for every user / item ids ; there is no way to make meaningful recommendation under an unforeseen condition .",
    "by contrast , context - aware recommender systems have been recently studied in order to profile more essential users preferences with auxiliary features . in particular , factorization machines ( fms ) @xcite are alternative effective factorization models which enable us to make context - aware recommendation with flexible feature representation . since the persistent cold - start problem commonly occurs in real applications , high feasibility of fms",
    "is attractive compared to more specific methods developed by industrial researchers .",
    "however , the captured context by fms is still static , and thus fm is incomplete in terms of robustness against persistently cold - starting data .    in order to adjust the model parameters according to variation of context , this paper extends fms into online algorithms .",
    "it should be noticed that the persistent cold - start problem is closely related to _ concept drift _",
    ", a phenomenon of `` the relation between the input data and the target variable changes over time '' @xcite in data streams . on the user - side ,",
    "since users interests may be changed , systems must recommend different items even for the same user .",
    "meanwhile , due to the instability of item trends and properties , one item can be preferred by totally different users at a different point in time .",
    "past studies proved that online algorithms are effective to the unpredictable phenomena @xcite , so the author assumes that incremental update of fms yields better accuracy compared to the static recommenders . in practice , online recommender systems behave as illustrated in fig .  [",
    "fig : stream - recommender ] .",
    "list to a user , ( 2 ) interact with an item ( e.g. click , buy , rate ) , and ( 3 ) update parameters based on the interaction . ]    more concretely , the author generalizes prior work in incremental mf ( imf ) @xcite , an online extension of a mf - based item recommender , to incremental fms ( ifms ) . here",
    ", the framework specially equips the following properties :    * * positive - only feedback * : model update is fast thanks to an one - pass online learning scheme . * * incremental adaptive regularization * : regularization parameters are automatically adjusted on - the - fly .",
    "this section introduces the different factorization techniques which compose the proposed framework .",
    "vinagre et  al .",
    "@xcite proposed an efficient imf algorithm for item recommendation , which is achieved by solving mf with a unique target value @xmath0 over the stochastic gradient descent ( sgd ) optimization .",
    "moreover , they evaluated the method in a _ test - then - learn _ scheme as outlined in alg .",
    "[ alg : prequential ] . for each pair of a user @xmath1 and an item @xmath2 ,",
    "evaluation is first launched before updating the parameters .",
    "data stream or finite set of positive events @xmath3 , size of recommendation list @xmath4 , window size @xmath5 @xmath6 @xmath7 if @xmath8 , otherwise @xmath9 @xmath10 avg .",
    "recall@@xmath4 for latest @xmath5 samples    more specifically , imf incrementally factorizes a binary matrix @xmath11 into @xmath12 and @xmath13 as :    * learn @xmath14 and @xmath15 as the standard mf * score items by @xmath16 , and +  recommend @xmath4 closest items to @xmath17 * @xmath18 +  @xmath19    where @xmath20 are respectively a user , item latent vector .",
    "the vectors are updated with a regularization parameter @xmath21 and a learning rate @xmath22 .",
    "fms @xcite have been recently developed as a general predictor .",
    "for an input vector @xmath23 , let us first imagine a linear model parameterized by @xmath24@xmath25 .",
    "in addition , by incorporating interactions of the @xmath26 input variables , the linear model is extended to fms as : @xmath27 where @xmath28 is a rank-@xmath29 matrix which has @xmath30 .",
    "arbitrary feature representation @xmath31 ( e.g. concatenation of one - hot vectors for several categorical variables ) work well with fms , and mf is actually a subset of the predictor .",
    "at the beginning , the general ifm is proposed in sec .  [",
    "sec : fms - model ] and [ sec : fms - reg ] .",
    "next , sec .",
    "[ sec : ifms - pos ] optimizes it for positive - only - feedback - based online item recommendation .",
    "this paper focuses on running fms in an incremental fashion .",
    "generally , learning fm requires a set of parameters @xmath32 and a loss function @xmath33 , and the parameters can be optimized by sgd .",
    "specifically , for a set of samples @xmath34 , the parameters of fm are updated as alg .",
    "[ alg : fms - model ] . for simplicity",
    ", @xmath33 is written as @xmath35 .",
    "@xmath34 , learning rate @xmath22 , regularization parameters @xmath36 @xmath37 @xmath38 @xmath39    notice that of imf in sec .",
    "[ sec : imf ] is sgd update for single sample , so the basic idea of this paper is that we replace the step with in alg .",
    "[ alg : fms - model ] . as a result , ifm which can be evaluated in the _ test - then - learn _ scheme is derived without loss of generality .",
    "rendle @xcite proposed an adaptive regularization scheme for fms .",
    "as shown in alg .",
    "[ alg : fms - reg ] , the technique adjusts the regularization parameters by using a sample @xmath40 in a validation set @xmath41 , an extra set of samples which is different from @xmath34 .    using @xmath40",
    "sampled from @xmath41 @xmath42 @xmath43 @xmath44    normally , alg .",
    "[ alg : fms - reg ] is launched after in alg .",
    "[ alg : fms - model ] .",
    "however , when we consider incremental adaptive regularization , there is a difficulty that the validation set @xmath41 will be gradually outdated in a streaming environment . a key idea to conquer",
    "the problem is that a newly observed sample @xmath45 is handled as a _ pseudo _",
    "validation sample , so the regularization parameters are adjusted before updating @xmath46 as demonstrated in fig .  [",
    "fig : adapt - then - learn ] .",
    "this section considers a particular combination of an output @xmath47 and a loss function @xmath35 to utilize ifms for online item recommendation . as the author explained in sec .",
    "[ sec : imf ] , imf actually solves mf with @xmath0 .",
    "similarly to the approach , let us again consider the unique output for a set of positive events @xmath3 . as a consequence , for a sample @xmath48 , our loss function is defined as : @xmath49 .",
    "eventually , for arbitrary design of a feature vector @xmath31 , the proposed ifm - based item recommender which is feasible in a streaming environment can be described in the _ test - then - learn _ framework as :    * learn @xmath50 , @xmath51 and @xmath52 as the standard fms * predict @xmath53 for every items , +  and recommend @xmath4 closest items to @xmath17 * @xmath54 with @xmath55    importantly , since the number of users and items on real - world online applications is not constant , our systems must incorporate new users and items into a current model somehow . for example , imf handles a new user ( item ) as an additional row of @xmath14 ( @xmath15 ) ( i.e. @xmath56 for a new user , @xmath57 for a new item obtained from gaussian ) .",
    "hence , ifms also take the simple approach that a zero and random vector are respectively inserted into @xmath51 and @xmath52 as the initial parameters of new features .",
    "[ fig : new - feature ] depicts detection and insertion of new features in a stream of input vectors .",
    "it is notable that , beyond new users and items , adding new contextual variables is also possible in the middle of data streams .",
    "is increased by new users , items and/or contexts , initial values fill the corresponding parameters . ]    in terms of computational complexity , ifms compute the interaction term @xmath58 in @xmath59 by letting the number of nonzero elements in @xmath31 be @xmath60 .",
    "in fact , this complexity is efficient enough due to sparsity of @xmath31 , but running time will be relatively long compared to the single vector updating of imf . therefore , there is trade - off between running time and context - awareness in practice .",
    "in the experiments , the _ test - then - learn _ procedure described in sec .",
    "[ sec : imf ] is launched for time - stamped unstable datasets . as shown in fig .",
    "[ fig : sample - split ] , the samples are separated similarly to what matuszyk et  al . @xcite did . at the beginning",
    ", a batch train / test step is executed for the first 20% training and following 10% validation samples .",
    "next , the 10% samples are just used for one - pass model updating , and the incremental evaluation step is finally performed for the remaining 70% .",
    "[ fig : sample - split ]    additionally , the 70% samples are also evaluated by mean percentile rank ( mpr ) in order to assess an ordered list of items obtained from .",
    "the metric is calculated based on percentile rank of the correct items in the ordered lists ; that is , @xmath61 indicates the best result that a recommender always gives the highest rank to a correct item , and @xmath62 is opposite .",
    "in contrast to recall@@xmath4/@xmath5 which evaluates top-@xmath4 items , mpr can measure users overall satisfaction from all items .",
    "following methods were employed as the competitors :    * * static mf * : the traditional mf , * * imf * : a fast extension of mf introduced in sec .",
    "[ sec : imf ] , * * static fms * : the parameters are not updated in the incremental stage similarly to * static mf*.    the author implemented all of the methods in python 3.5.1 , and the code was run in a typical personal computer with the 2.7 ghz intel  core  i7 cpu and 4 gb ram .",
    "datasets used in the experiments were binarized version of movielens 100k ( ml100k ) and synthetic click data ; the former is a real - world example of user - side volatility , and the latter shows item - side instability .",
    "table  [ tab : data ] summarizes statistics of the data .",
    "each pair of a method and a dataset was tested five times with different initial parameters .",
    ".statistics of the datasets . [ cols= \" <",
    ", > , > , > , > , > \" , ]     [ tab : result ]    * ml100k . *",
    "since we focus on item recommendation , ml100k was binarized by extracting 5-starred rating events .",
    "an input vector of ifms was designed as : @xmath63{\\strut user id}}},}_{1/|u| }    \\underbrace{\\textrm{\\colorbox{myorange!50}{\\makebox[6em]{\\strut demographics}}},}_{3/23 }     \\underbrace{\\textrm{\\colorbox{mypink!50}{\\makebox[4em]{\\strut movie id}}},}_{1/|i| } \\\\    & &    \\underbrace{\\textrm{\\colorbox{mypink!50}{\\makebox[3em]{\\strut genre}}},}_{18/18 }     \\underbrace{\\textrm{\\colorbox{mypink!50}{\\makebox[7em]{\\strut last rated genre}}},}_{18/18 }    \\underbrace{\\textrm{\\colorbox{mypurple!50}{\\makebox[2em]{\\strut day}}},}_{1/7 }    \\underbrace{\\textrm{\\colorbox{mypurple!50}{\\makebox[6em]{\\strut last rated day}}}}_{1/7 }   \\ ) .",
    "\\label{eq : vector_ml}\\end{aligned}\\ ] ] `` demographics '' includes user s occupation ( 1/21 ) , sex ( 1/1 ) and age ( 1/1 ) , and `` day '' is day of week in the timestamps . note that the numbers below the underbraces indicate \\{_max .",
    "# of nonzero dimensions_}/\\ { _ # of total dimensions_}.    most users on ml100k report positive events just for the initial rating activity , and they do not rate any more . even if some users continuously rate movies , intuition tells us that their interests change over time .",
    "thus , ml100k is a real - world example of user - side persistent cold - start .",
    "[ fig : result_ml100k ] shows the best recall behaviors on ml100k obtained from the five _ test - then - learn _ trials .",
    "ml100k is rich in both user and item features , and we also considered time - related contexts . consequently ,",
    "static fms and ifms respectively outperformed static mf and imf , especially in terms of mpr .",
    "in addition , it is clear that online recommenders ( imf and ifms ) worked effectively compared to the static counterparts .",
    "[ fig : result_ml100k ]    * synthetic . * synthetic click data was generated as an example of item - side persistent cold - start , based on a rule - based procedure demonstrated in @xcite .",
    "in particular , our generator first produced 0.5 million impressions of five ad variants , and additional half million impressions were also generated after updating a rule for the most popular ad . as a result , from the one million impressions ,",
    "3,570 synthetic clicks were observed as positive events with erratic trend .",
    "here , @xmath31 for the synthetic data was : @xmath64{\\strut age}}},}_{1/1 }     \\underbrace{\\textrm{\\colorbox{myorange!50}{\\makebox[2em]{\\strut sex}}},}_{1/1 }    \\underbrace{\\textrm{\\colorbox{myorange!50}{\\makebox[5em]{\\strut geo ( state)}}},}_{1/50 }    \\underbrace{\\textrm{\\colorbox{mypink!50}{\\makebox[3em]{\\strut ad id}}},}_{1/|i| }    \\underbrace{\\textrm{\\colorbox{mypink!50}{\\makebox[4em]{\\strut category}}}}_{1/3 } \\ ) .",
    "\\label{eq : vector_ad}\\end{aligned}\\ ] ]    the best result on the synthetic data is illustrated in fig .",
    "[ fig : result_synthetic ] .",
    "all methods were easily fit to the batch training samples due to the simplicity of data , but the difference can be observed after the most popular ad was changed .",
    "while recall of the static methods declined significantly , imf and ifms evidently adapted to the variation as expected .",
    "moreover , mpr and recall of ifms were even better than imf .",
    "it should be noted that , even though static mf and fms demonstrated the similar recall behavior , fms showed reasonably lower mpr compared to mf .",
    "finally , table  [ tab : result ] summarizes the results of 5 trials .",
    "the positive effect of context - awareness and online model updating was validated in terms of accuracy . on the other hand , running time of fms was more than 100 times slower than mf .",
    "ifms updated the parameters in a millisecond range , and recommendation for a user was done at least 30 milliseconds .",
    "ifm thus seems to satisfy practical time requirements for now , but higher - dimensional and denser input vectors may lead worse results in the future . as the author mentioned in sec .",
    "[ sec : ifms - pos ] , the fact proved trade - off between context - awareness and efficiency .    overall , the proposed online item recommender based on ifms worked well as generalization of imf . in case that an organization develops production recommender systems",
    ", our highly feasible framework can be an easy - to - implement baseline .",
    "furthermore , availability of many third - party libraries ( e.g. @xcite ) is an important advantage of fms .",
    "this paper has proposed an ifm - based context - aware online item recommender .",
    "experimental results have demonstrated not only feasibility and effectiveness of the technique but also a new challenge in computational efficiency ."
  ],
  "abstract_text": [
    "<S> real - world item recommenders commonly suffer from a persistent cold - start problem which is caused by dynamically changing users and items . in order to overcome the problem , </S>",
    "<S> several context - aware recommendation techniques have been recently proposed . in terms of both feasibility and performance , factorization machine ( fm ) </S>",
    "<S> is one of the most promising methods as generalization of the conventional matrix factorization techniques . </S>",
    "<S> however , since online algorithms are suitable for dynamic data , the static fms are still inadequate . </S>",
    "<S> thus , this paper proposes incremental fms ( ifms ) , a general online factorization framework , and specially extends ifms into an online item recommender . </S>",
    "<S> the proposed framework can be a promising baseline for further development of the production recommender systems . </S>",
    "<S> evaluation is done empirically both on synthetic and real - world unstable datasets .    </S>",
    "<S> < ccs2012 > < concept > < concept_id>10002951.10003317.10003347.10003350</concept_id > < concept_desc > information systems  recommender systems</concept_desc > < concept_significance>500</concept_significance > </S>",
    "<S> < /concept > < concept > < concept_id>10002951.10002952.10002953.10010820.10003208</concept_id > < concept_desc > information systems  data streams</concept_desc > < concept_significance>300</concept_significance > </S>",
    "<S> < /concept > < concept > </S>",
    "<S> < concept_id>10010147.10010257.10010293.10010309</concept_id > < concept_desc > computing methodologies  factorization methods</concept_desc > < concept_significance>300</concept_significance > < /concept > </S>",
    "<S> < /ccs2012 > </S>"
  ]
}