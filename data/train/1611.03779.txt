{
  "article_text": [
    "as mentioned in the main text , our cmps gradient optimization works best when using porperly prepared initial states . the purpose of the following chapter is to introduce a novel method that employs dmrg energy minimization to obtain cmps on a discretized system .",
    "these discrete states are then taken as initial states to a cmps optimization in the continuum .",
    "the main result here is that dmrg can be used to optimize an mps with tensors of the form @xmath128 in such a way that the cmps structure , i.e. the matrices @xmath129 , is always explicitly available .",
    "we use @xmath130 instead of @xmath56 to highlight that this is a lattice mps . note that even though we are treating soft core bosons here , we are restricting the local hilbert space dimension to @xmath131 ( see below ) .",
    "we start by discretizing the hamiltonian @xmath13 from eq.([eq : ham ] ) on a grid with spacing @xmath130 . with the replacement @xmath132 , and using a first order discretization of the kinetic energy , this results in the following local hamiltonian terms : @xmath133 note that we have replaced the local interaction term with a nearest neighbor interaction term .",
    "this replacement becomes exact in the limit @xmath134 . by comparing the cmps expressions for the local energy density @xmath135\\otimes[q^*,r^*]|r)+\\nonumber\\\\    g(l|r^2\\otimes r^{*2}|r)+\\mu ( l|r\\otimes r^*|r)\\nonumber\\end{aligned}\\ ] ] where @xmath136 and @xmath137 are the left and right reduced density matrices ( see below ) , with the ones obtained using the above discretization eqs.([eq : disckin])-([eq : discpot ] ) and mps tensors of the form eq.([eq : disccmps2 ] )",
    ", it is easy to see that they can be made to coincide if in the numerical derivative eq.([eq : disckin ] ) one makes the replacement @xmath138 where @xmath139 is a projector onto the state with no particles at position @xmath140 .",
    "thus , using eq.([eq : discint ] ) and eq.([eq : discpot ] ) and a modified kinetic energy eq.([eq : modisckin ] ) with mps matrices of the form eq.([eq : disccmps2 ] ) is almost identical to a discretized cmps description as obtained in @xcite .",
    "the difference lies in the normalization : whereas mps tensors eq.([eq : disccmps2 ] ) are normalized according to a finite @xmath130 , a true cmps is normalized with respect to @xmath141 .",
    "the use of the projector @xmath142 is crucial to the restriction of the local hilbert space dimension to @xmath131 .",
    "the final hamiltonian then assumes the form @xmath143 for a given @xmath130 , we then use standard idmrg on a two site unit cell @xcite to obtain the ground state .",
    "we note that our proposed gradient optimization for cmps could , with minor modifications , also be applied to the discrete setting , and to homogeneous lattice systems in general @xcite .",
    "once the idmrg has been sufficiently converged , one can use the matrices @xmath144 to initialize a new dmrg run for a finer discretization @xmath145 by simply changing @xmath130 to @xmath146 in eq.([eq : disccmps2 ] ) , and renormalizing the mps tensor . using the termonology of ref.@xcite",
    ", we call this operation a prolongation of the state . even for @xmath130 as large as @xmath147 and for the parameter values used in this letter",
    ", this gives already good initial states for a cmps optimization at @xmath141 .",
    "note that since the matrices @xmath129 depend on @xmath130 , so does the quality of the prolonged initial state .",
    "this proposed fine graining procedure generalizes the approach presented in @xcite to arbitrary prolongations . prior to prolonging the state to a finer discretization",
    ", it is vital to bring it into the canonical form @xcite to remove any gauge jumps at the boundaries of the two - site unit cell .",
    "note that in the diagonal gauge there is still a gauge freedom with diagonal , complex gauge matrices that has to be removed as well before prolongation .",
    "these gauge jumps originate from a unitary freedom in the svd and qr decompositions , which are used heavily in lattice mps optimizations .",
    "in this section we elaborate on the determination of the gradient of the energy expectation value using cmps methods ( see also @xcite for details on lattice mps gradients ) .",
    "the goal is to optimize the matrices @xmath148 to lower the energy @xmath149 see eq.([eq : e ] ) in the main text .",
    "similar to dmrg @xcite , we calculate the gradient of this expression with respect to @xmath150 .",
    "taking the derivative @xmath151 gives @xmath152 we normalize our state in such a way that @xmath153 ( see eqs.([eq : renorml ] ) and ( [ eq : renormr ] ) below ) , and thus the second term vanishes identically . since the energy depends non - linearly on @xmath154 , we have to apply the chain rule when calculating @xmath155 .",
    "however , due to translational invariance , this full gradient decomposes into a sum of @xmath3 identical terms , where each term corresponds to a _",
    "gradient , and @xmath3 is the number of discretization points : @xmath156 @xmath157 is a _ local _ derivative , similar to dmrg , with respect to @xmath158 . note that for inhomogeneous systems , this local gradient would contain derivatives of the matrix @xmath22 @xcite .",
    "knowledge of this local gradient is thus sufficient to calculate the gradient of @xmath159 . to obtain the local gradient @xmath157 , it is convenient to consider the state in the _ center site form _ @xmath160 where @xmath161 .",
    "@xmath35 is a diagonal matrix containing the schmidt values . @xmath162 and @xmath163 are left / right normalized cmps matrices , i.e. @xmath164 here we have defined the left / right cmps transfer operator @xcite @xmath165 the energy expectation @xmath159 with respect to now _",
    "@xmath154 ( at the position where we want to take the local derivative ) can be evaluated to @xmath166 +    \\bigg [    \\begin{array}{c }      \\left (        \\begin{array}{c }          \\lambda + \\eps q_c\\\\          \\sqrt{\\eps } r_c        \\end{array }      \\right)\\\\        |\\\\      \\left (        \\begin{array}{c }          { } { \\lambda^ * } + \\eps { } { q_c^*}\\\\          \\sqrt{\\eps } { } { r_c^ * }        \\end{array }      \\right )    \\end{array }    \\begin{array}{c }      \\rceil\\\\      |h_r)\\\\      \\rfloor    \\end{array}+\\nonumber\\\\    & \\frac{\\eps}{2m}\\bigg(\\big [    \\begin{array}{c }      q_lr_c - r_lq_c\\\\      \\\\      { } q_l^*{}{r_c^*}-{}r_l^*{}{q_c^ * }    \\end{array }    \\big ]    +    \\big [    \\begin{array}{c }      q_cr_r - r_cq_r\\\\      \\\\      { } { q_c^ * } { } r_r^*-{}{r_c^*}{}q_r^ *    \\end{array }    \\big]\\bigg)\\nonumber\\\\    & + \\eps g\\bigg(\\big [    \\begin{array}{c }      r_lr_c\\\\      \\\\      { } r_l^*{}{r_c^ * }    \\end{array }    \\big]+    \\big [    \\begin{array}{c }      r_cr_r\\\\      \\\\      { } { r_c^*}{}r_r^ *    \\end{array }    \\big]\\bigg)+    \\eps\\mu    \\big [    \\begin{array}{c }      r_c\\\\      \\\\      { } { r_c^ * }    \\end{array }    \\big]\\end{aligned}\\ ] ] symbols @xmath167,|,\\lceil,\\rceil,\\lfloor,\\rfloor$ ] represent tensor contractions . in dmrg ,",
    "the matrices @xmath168 and @xmath169 in eq.([eq : update0 ] ) are known as the left and right block hamiltonians .",
    "below we describe how to calculate them in our context .",
    "we use a particular renormalization of these left and right block hamiltonians , such that @xmath170=0\\label{eq : renorml } ,    \\\\",
    "\\bigg [    \\begin{array}{c }      \\lambda\\\\      \\\\      \\\\      { } { \\lambda^ * }    \\end{array }    \\begin{array}{c }      \\rceil\\\\      |h_r)\\\\      \\rfloor    \\end{array}=0.\\label{eq : renormr}\\end{aligned}\\ ] ] due to this renormalization , the expectation value @xmath171",
    ". the local derivative of @xmath159 with respect to @xmath150 is then given by @xmath172 +    \\bigg [    \\begin{array}{c }        \\begin{array}{c }          \\lambda\\\\          \\\\          \\\\",
    "\\bullet \\\\",
    "\\end{array }    \\end{array }    \\begin{array}{c }      \\rceil\\\\      |h_r)\\\\      \\rfloor    \\end{array}+\\label{eq : update_q}\\\\    & \\frac{\\eps}{2m}\\bigg(-\\big [    \\begin{array}{c }      q_lr_c - r_lq_c\\\\      \\\\",
    "r_l^*\\quad\\quad\\quad\\bullet    \\end{array }    \\big ]    +    \\big [    \\begin{array}{c }      q_cr_r - r_cq_r\\\\      \\\\",
    "\\bullet\\quad\\quad\\quad r_r^ *    \\end{array }    \\big]\\bigg)\\nonumber\\\\    \\frac{\\partial \\mathcal{h}}{\\partial r_c^*}= &    \\begin{array}{c }      \\lceil\\\\      ( h_l|\\\\      \\lfloor    \\end{array }    \\begin{array}{c }        \\begin{array}{c }          r_c\\\\          \\\\          \\\\          \\bullet",
    "\\\\        \\end{array }    \\end{array }    \\bigg]+    \\bigg [    \\begin{array}{c }        \\begin{array}{c }          r_c\\\\          \\\\          \\\\          \\bullet \\\\",
    "\\end{array }    \\end{array }    \\begin{array}{c }      \\rceil\\\\      |h_r)\\\\      \\rfloor    \\end{array}+\\label{eq : update_r}\\\\    & + \\eps g\\bigg(\\big [    \\begin{array}{c }      r_lr_c\\\\      \\\\      { } r_l^*\\bullet    \\end{array }    \\big]+    \\big [    \\begin{array}{c }      r_cr_r\\\\      \\\\      \\bullet{}r_r^ *    \\end{array }    \\big]\\bigg)+    \\eps\\mu    \\big [    \\begin{array}{c }      r_c\\\\      \\\\      \\bullet    \\end{array }    \\big].\\nonumber\\end{aligned}\\ ] ] @xmath173 signs denote free matrix indices due to the removal of a matrix at this point in the tensor network . @xmath174 and @xmath175 are then used to update @xmath148 : @xmath176 at this point , the new state is of the form @xmath177 the matrices @xmath178 are now absorbed back into the cmps tensors from e.g. the right side , i.e. @xmath179 @xmath180 are then brought back into the central canonical gauge ( see below ) , which produces a new triplet of matrices @xmath181 and completes one update step .",
    "convergence is measured by the norm of the gradient @xmath182}\\nonumber.\\end{aligned}\\ ] ] this measure is similar to , but more stringent than , the one used in the tdvp , in general @xmath183 ( see below for a definition of @xmath184 , the latter does not take @xmath174 into account ) .",
    "next we adress the calculation of the matrices @xmath168 and @xmath169 in eqs.([eq : update_q ] ) and ( [ eq : update_r ] ) . in the context of dmrg , they are known as the left and right block hamiltonians , respectively . for an infinite , translationally invariant system",
    "they are given by an infinite sum of the form @xmath185 where @xmath186 is an infinitesimal mps transfer operation , i.e. @xmath187 ( see eq.([eq : cmpsto_0 ] ) ) and @xmath188   \\frac{1}{2m}+    \\begin{array}{c }      r_r^2\\\\      \\\\",
    "r_r^{*2 }    \\end{array }    \\big]g    +    \\begin{array}{c }      r_r\\\\      \\\\",
    "r_r^ *    \\end{array}\\nonumber    \\big]\\mu\\end{aligned}\\ ] ] is related to the energy content of an infinitesimal interval @xmath56 . since @xmath189 has a left and right eigenvector @xmath190 and @xmath191 to eigenvalue 1 ( and similarly @xmath192 has eigenvectors @xmath193 and @xmath194 ) the two sums in eqs.([eq : geosum1 ] ) and ( [ eq : geosum2 ] ) are divergent .",
    "these divergences can be regularized by removing the subspace @xmath195 from @xmath196 and @xmath197 , and @xmath198 from @xmath199 and @xmath200 , i.e. by replacing @xmath201 the geometric series can then be summed to @xmath202 ( note the cancellation of @xmath56 in eqs.([eq : hlhr ] ) ) which is equivalent to @xmath203|h_r)=-|h_r)_{\\perp}\\label{eq : hl}\\\\    ( h_l|\\big[t_l-|\\lambda^2)(\\mathbbm{1}|\\big]=-(h_l|_{\\perp}\\label{eq : hr}\\end{aligned}\\ ] ] with @xmath204 the left / right cmps transfer operator eq.([eq : cmpsto ] ) .",
    "we solve eqs.([eq : hl ] ) and ( [ eq : hr ] ) using the lgmres routine provided by the scipy.sparse.linalg module @xcite .",
    "here is a summary of our proposed optimization scheme :    1 .",
    "initialize a cmps with matrices @xmath129 and bring them into central canonical gauge .",
    "set a desired convergence @xmath205 .",
    "2 .   calculate @xmath168 and @xmath169 according to eq.([eq : hl ] ) and eq.([eq : hr ] ) .",
    "[ iterate ] 3 .",
    "calculate @xmath174 and @xmath175 from eqs .",
    "( [ eq : update_q ] ) and ( [ eq : update_r ] ) .",
    "update:[enum : update ] @xmath206 5 .",
    "regauge @xmath180 into the central canonical form and measure @xmath207}$ ] .",
    "if @xmath208 stop , otherwise go back to [ iterate ] .    during simulations",
    "we dynamically adapt the parameter @xmath209 , i.e. if we detect a large increase in @xmath210 we reject the update and redo the step with a smaller value of @xmath209 .",
    "in the following we summarize the time dependent variational principle ( tdvp ) @xcite for homogeneous cmps ( see also the appendix in @xcite for more details ) . to obtain the ground state of e.g. eq.([eq : ham ] ) in the main text , one employs euclidean time evolution using the tdvp .",
    "the general strategy is the following : given a cmps @xmath211}$ ] at time @xmath212 , one finds an approximation @xmath213}$ ] that can be used to evolve @xmath211}$ ] : @xmath214}=    \\ket{\\psi[q(\\tau),r(\\tau)]}-d\\tau \\ket{\\phi}\\nonumber\\end{aligned}\\ ] ] the most general ansatz ansatz for @xmath215 is to superimpose local perturbations on the state @xmath211}$ ] : @xmath216 where we @xmath217 is @xmath218 @xmath219 and @xmath220 are irrelevant boundary vectors at @xmath221 .",
    "the optimal @xmath222 and @xmath223 are found from minimizing the norm @xmath224 with @xmath225 defined in eq.([eq : tangentvec ] ) .",
    "this amounts to the calculation of tensor network expressions similar to eqs.([eq : update_q ] ) and ( [ eq : update_r ] ) .",
    "the non - local nature of the perturbations in @xmath225 leads to a complication in the minimization , that can be overcome by resorting to a new parametrization @xmath226 ( or @xmath227 ) such that the norm @xmath228 has non - vanishing contributions only when @xmath226 and @xmath229 act at the same position in space .",
    "two possible parametrizations are given by @xmath230 these are called the left or right tangent - space gauges , respectively .",
    "we note that this parametrization covers the full tangent - space to the state @xmath2 @xcite . here , the only free parameter left is @xmath231 . @xmath232 and @xmath233 are the left and right reduced density matrices obtained as the left and right eigenvectors of the cmps transfer operator @xmath234 to eigenvalue @xmath235 , i.e. @xmath236 in braket notation . in the tdvp for cmps ,",
    "one further simplifies all expressions in the minimization by reparametrizing @xmath231 as @xmath237 where @xmath238 is now the free parameter .",
    "the convergence measure used in tdvp is given by the norm @xmath239 for left normalized matrices @xmath240 , the update step is given by @xmath241 with @xmath71 a small time step in imaginary time .",
    "@xmath242 and @xmath231 correspond to @xmath174 and @xmath175 in the gradient optimization approach .     and",
    "we used a time step @xmath74 .",
    "( a ) energy density @xmath75 ( main figure ) and particle density @xmath76 ( inset ) as a function of iteration number .",
    "( b ) convergence of @xmath66 to the exact value from bethe ansatz as a function of iteration number.,title=\"fig : \" ]   and @xmath243 .",
    "we used a time step @xmath74 .",
    "( a ) energy density @xmath75 ( main figure ) and particle density @xmath76 ( inset ) as a function of iteration number .",
    "( b ) convergence of @xmath66 to the exact value from bethe ansatz as a function of iteration number.,title=\"fig : \" ]     and @xmath244 .",
    "the tdvp would take several @xmath245 steps to converge .",
    "the gradient optimization without dmrg - preconditioning and dynamically adapted @xmath209 took roughly 2500 iterations ( 4h runtime on a desktop pc @xcite ) . with preconditioning it finished after 354 iterations ( which took @xmath246 second or 17.4 min ) .",
    "the dmrg preconditioner was run for @xmath247 , and took roughly 140 seconds to converge @xcite we used @xmath74 for @xmath248 and @xmath249 for @xmath250 .",
    "( b ) @xmath251 of _ steepest descent _ gradient optimization as a function of iteration number for different bond dimensions @xmath0 , with dmrg - preconditioning ( total run time ( including dmrg preconditioning ) for @xmath101 was 2.6h on a desktop pc @xcite).,title=\"fig : \" ]   and @xmath244 .",
    "the tdvp would take several @xmath245 steps to converge .",
    "the gradient optimization without dmrg - preconditioning and dynamically adapted @xmath209 took roughly 2500 iterations ( 4h runtime on a desktop pc @xcite ) . with preconditioning it finished after 354 iterations ( which took @xmath246 second or 17.4 min ) .",
    "the dmrg preconditioner was run for @xmath247 , and took roughly 140 seconds to converge @xcite we used @xmath74 for @xmath248 and @xmath249 for @xmath250 .",
    "( b ) @xmath251 of _ steepest descent _ gradient optimization as a function of iteration number for different bond dimensions @xmath0 , with dmrg - preconditioning ( total run time ( including dmrg preconditioning ) for @xmath101 was 2.6h on a desktop pc @xcite).,title=\"fig : \" ]     as a function of iteration number for different bond dimensions @xmath0 , and @xmath244 .",
    "for @xmath88 we used an adaptive @xmath71 scheme .",
    "( b ) cmps _ steepest descent _ gradient optimization : @xmath251 as a function of iteration number for different bond dimensions @xmath0 , and @xmath244 .",
    "for @xmath88 we used the same adaptive @xmath209 scheme as in ( a).,title=\"fig : \" ]   as a function of iteration number for different bond dimensions @xmath0 , and @xmath244 .",
    "for @xmath88 we used an adaptive @xmath71 scheme .",
    "( b ) cmps _ steepest descent _ gradient optimization : @xmath251 as a function of iteration number for different bond dimensions @xmath0 , and @xmath244 .",
    "for @xmath88 we used the same adaptive @xmath209 scheme as in ( a).,title=\"fig : \" ]     and ( c ) order parameter @xmath97 vs. bond dimension @xmath0",
    ", for @xmath252 , and @xmath253.,title=\"fig : \" ]    and ( c ) order parameter @xmath97 vs. bond dimension @xmath0 , for @xmath252 , and @xmath253.,title=\"fig : \" ]    and ( c ) order parameter @xmath97 vs. bond dimension @xmath0 , for @xmath252 , and @xmath253.,title=\"fig : \" ]    our gradient calculation includes one additional computational step as compared to the tdvp .",
    "there , depending on the choice of tangent - gauge , the calculation of one of the two expressions containing @xmath168 or @xmath169 in eqs.([eq : update_q ] ) and ( [ eq : update_r ] ) can be omitted . in our case",
    "we need to calculate both of them .",
    "this adds however only a small overhead in computational time .",
    "an important ingredient to our gradient optimization is the _ central canonical form _ , introduced in the main text .",
    "here we describe how to obtain the central canonical form for cmps .",
    "the procedure is a straight forward adaption of the corresponding lattice algorithm . starting from unnormalized matrices",
    "@xmath129 , one first calculates the left and right eigenvectors @xmath254 ( @xmath255 in matrix notation ) of the transfer operator @xmath256 eq.([eq : cmpsto ] ) to the largest real eigenvalue @xmath257 , @xmath258 where @xmath259 .",
    "next , the cmps is normalized by @xmath260 this shifts the eigenvalue of @xmath136 and @xmath137 to @xmath261 . using @xmath255 , compute @xmath262 and use a singular value decomposition to obtain @xmath263 where @xmath35 contains the schmidt values .",
    "normalize @xmath35 by @xmath264    the left or right normalized cmps matrices @xmath240 or @xmath265 are then obtained from @xmath266 with @xmath267 note that @xmath268 .",
    "the non - linear conjugate gradient approach is an improvement of the steepest descent method that reuses gradient information from previous iterations , see e.g. @xcite , and has recently been proposed as an improvement of the tdvp @xcite . at iteraton @xmath77 , the new search direction @xmath269 is given by a linear combination of the current gradient @xmath270 and the previous search direction @xmath271 from step @xmath272 : @xmath273 the parameter @xmath274 is calculated from a semi - empirical formula . in our case , we use the fletcher - reeves form @xmath275 in a regular implementation , one uses a line search method to find the minimum in the direction @xmath269 of @xmath75 , which is then taken to be the starting point for the next iteration .",
    "we omit this line search in our implementation .",
    "the procedure is initialized with @xmath276 . in our case",
    ", there is a small caveat due to a gauge change of the state between iterations @xmath272 and @xmath77 when regauging the state into the central canonical form . due to this gauge change",
    ", the current gradient and the previous search direction can only be added after the latter has been transformed into the gauge of the current state @xcite .",
    "this is achieved using the matrices @xmath277 and @xmath278 from eq.([eq : gs ] ) . consider an update for the state @xmath46},q_c^{[n ] } , r_c^{[n]})$ ] at iteration @xmath77 . for the case of a left - sided update where the state is connected back by multiplication of @xmath279}]^{-1}$ ] from the right ( see [ enum : update ] . in the summary of our proposed algorithm ) , the new search direction is given by @xmath280}\\\\      \\frac{\\partial \\mathcal{h}}{\\partial r_c^*}^{[n ] }    \\end{array}\\nonumber    \\right)[\\lambda^{[n]}]^{-1 }    +    \\beta_n g_l^{[n ] } \\vec v_{n-1}[g_l^{[n]}]^{-1}\\end{aligned}\\ ] ] where @xmath281}$ ] is the gauge matrix obtained from gauging the state from the previous iteration @xmath272 into the central canonical form at iteration @xmath77 ( see eq.([eq : gs ] ) ) i.e. @xmath282}=g_l^{[n]}\\tilde q^{[n-1]}[g_l^{[n]}]^{-1}\\nonumber\\\\    r_l^{[n]}=g_l^{[n]}\\tilde r^{[n-1]}[g_l^{[n]}]^{-1}\\nonumber\\end{aligned}\\ ] ] ( see eq.([eq : qr ] ) in the main text ) .",
    "the matrices @xmath283},r_c^{[n]}$ ] are then updated according to @xmath284}\\\\      \\tilde r^{[n ] }    \\end{array}\\nonumber    \\right )    =    \\left (    \\begin{array}{c }      q_c^{[n]}\\\\      r_c^{[n ] }    \\end{array}\\nonumber    \\right)[\\lambda^{[n]}]^{-1}-\\alpha\\vec v_n.\\end{aligned}\\ ] ] this algorithm only works reliably for @xmath251 below a certain threshold which we empirically find to be @xmath285 .",
    "further more , the fletcher - reeves update is prone to jamming , i.e. stagnation of convergence rates .",
    "one way to overcome this is by resetting the method after a certain number of @xmath286 steps by setting @xmath287 , thereby discarding all previous information after @xmath286 iterations .",
    "we found @xmath288 to work best in our simulations .",
    "in this section we show further comparisons of the cmps steepest descent gradient optimization with the tdvp .",
    "[ fig : tdvp_vs_newopt_old ] shows results for convergence of @xmath75 and @xmath76 with iteration number similar to fig .",
    "[ fig : tdvp_vs_newopt ] in the main text , but with a random common initial state as opposed to one that has been preconditioned with dmrg .",
    "the results are in qualitative agreement with the ones in the main text .    in fig .",
    "[ fig : dmrgprecond ] ( a ) we compare the convergence of regular tdvp ( blue ) without dmrg - preconditioning , the cmps steepest descent gradient optimization scheme without dmrg - preconditioning ( green ) and cmps steepest descent gradient optimization scheme with dmrg - preconditioning ( red ) . in all simulations we used an adaptive @xmath209 scheme to keep the simulation stable .",
    "we ran our dmrg preconditioner for a lattice discretization @xmath289 and 0.1 for 400 and 2000 dmrg steps , respectively ( the total run time of the two dmrg runs was roughly 140 seconds @xcite ) .",
    "we then prolonged the resulting state to @xmath290 and took it as initial state for a cmps optimization .",
    "we stopped the cmps optimization once @xmath291 .",
    "the simulation with dmrg - preconditioning converged within 354 iterations ( 17.4 min @xcite ) , as compared to 2500 iterations without preconditioning , and several ten thousand iterations for tdvp without preconditioning .",
    "[ fig : dmrgprecond ] ( b ) shows @xmath251 for the cmps steepest descent gradient optimization with dmrg - preconditioning for different values of @xmath0 .",
    "the total runtime for the largest bond dimension @xmath101 was roughly 2.6h on a desktop pc @xcite .",
    "the plot demonstrates that the number of steps to converge a cmps ground state does not depend on the bond dimension @xmath0 for our new scheme .    in fig .",
    "[ fig : tdvp_vs_newopt_diffd ] ( a ) we show convergence of tdvp for different bond dimensions @xmath292 and 64 , fig .  [ fig : tdvp_vs_newopt_diffd ] ( b ) shows results for the cmps steepest descent gradient optimization for the same cases . for @xmath292",
    ", we used a single time step @xmath74 throughout the simulation , whereas for @xmath88 we resorted to an adaptive scheme .",
    "the computational gain of our proposed scheme clearly increases with increasing @xmath0 .",
    "we note that the total reachable accuracy of the ground state in both the tdvp and our proposed scheme depends on the accuracy of the eigensolvers used to obtain @xmath293 and @xmath168 @xcite . by using a higher accuracy in these solvers ,",
    "the accuracy can be increased at the cost of a longer run time per iteration step .    in fig .",
    "[ fig : dscaling ] ( a ) to ( c ) we plot the relative error of the reduced ground state energy , the entanglement entropy @xmath81 and the order parameter @xmath97 for different values of @xmath252 and @xmath294 ."
  ],
  "abstract_text": [
    "<S> the generalization of matrix product states ( mps ) to continuous systems , as proposed in the breakthrough paper [ f. verstraete , j.i . </S>",
    "<S> cirac , phys . </S>",
    "<S> rev . </S>",
    "<S> lett . </S>",
    "<S> 104 , 190405(2010 ) ] , provides a powerful variational ansatz for the ground state of strongly interacting quantum field theories in one spatial dimension . a continuous mps ( cmps ) approximation to the ground state </S>",
    "<S> can be obtained by simulating an euclidean time evolution . in this letter </S>",
    "<S> we propose a cmps optimization algorithm based instead on energy minimization by gradient methods , and demonstrate its performance by applying it to the lieb liniger model ( an integrable model of an interacting bosonic field ) directly in the thermodynamic limit . </S>",
    "<S> we observe a very significant computational speed - up , of more than two orders of magnitude , with respect to simulating an euclidean time evolution . as a result , much larger cmps bond dimension @xmath0 </S>",
    "<S> can be reached ( e.g. @xmath1 with moderate computational resources ) thus helping unlock the full potential of the cmps representation for ground state studies .    over the last 25 years , </S>",
    "<S> progress in our understanding of quantum spin chains and other strongly interacting quantum many - body systems in one spatial dimension has been dominated by a variational ansatz : the _ matrix product state _ ( mps ) @xcite . </S>",
    "<S> the wave - function @xmath2 of a quantum spin chain made of @xmath3 spin-@xmath4 degrees of freedom depends on @xmath5 complex parameters @xmath6 , @xmath7 accordingly , an exact numerical simulation has a computational cost that grows exponentially with the size @xmath3 of the chain . in an mps , </S>",
    "<S> the @xmath5 coefficients are expressed in terms of the trace of a product of matrices . </S>",
    "<S> for instance , in a translation invariant system the mps reads @xmath8,\\ ] ] where @xmath9 and @xmath10 are @xmath11 complex matrices . </S>",
    "<S> thus , the state @xmath2 of @xmath3 spins is specified by just @xmath12 variational parameters , allowing for the study of arbitrarily large , even infinite , systems @xcite .    a generic state of the spin chain can not be expressed as an mps , because the bond dimension @xmath0 limits how entangled @xmath2 can be . however , ground states of local hamiltonians happen to be weakly entangled ( e.g. they obey an entanglement area law @xcite ) in a way that allows for an accurate approximation by an mps . given a hamiltonian @xmath13 , white s revolutionary _ density matrix renormalization group _ ( dmrg ) @xcite algorithm provided the first systematic way of obtaining a ground state mps approximation by minimizing the energy , see also @xcite . </S>",
    "<S> subsequently , refs . </S>",
    "<S> @xcite proposed an algorithm to simulate time evolution with an mps , which in euclidean time also produces a ground state approximation , see also refs . </S>",
    "<S> @xcite . </S>",
    "<S> an improved formulation of the time evolution simulation by mps was obtained in terms of the _ time - dependent variational principle _ ( tdvp ) @xcite .      in this letter </S>",
    "<S> we propose an energy minimization algorithm to find a cmps approximation for ground states , based on gradient descent techniques , and demonstrate its performance with the lieb liniger model in the thermodynamic limit ( @xmath24 ) . </S>",
    "<S> we also propose a useful cmps initialization scheme , of interest on its own , based on lattice mps algorithms . </S>",
    "<S> these proposals result in a very significant computational speed - up with respect to euclidean time evolution  e.g. converging a cmps with bond dimension </S>",
    "<S> @xmath25 requires less time than a @xmath26 computation with tdvp . for simplicity </S>",
    "<S> we consider a single bosonic field . </S>",
    "<S> generalization to a fermionic field and to multiple fields is straightforward .    </S>",
    "<S> _ continuum limit and central canonical form_. in order to describe the algorithm , we must first adjust the notation in two ways . </S>",
    "<S> firstly , following @xcite , we discretize the interval @xmath27 in eq.([eq : cmps ] ) into a regular lattice made of @xmath28 sites and with inter - site spacing @xmath29 , and produce an mps with matrices @xmath30 and @xmath31 @xcite given , in vectorized form , by @xmath32 such that the original cmps is recovered in the limit @xmath33 @xcite . here </S>",
    "<S> , @xmath30 and @xmath31 corresponds to having 0 or 1 particle at the lattice site . </S>",
    "<S> this lattice visualization is useful in order to manipulate the cmps with regular mps techniques , provided the latter have a well - defined continuum limit ( @xmath33 ) . </S>",
    "<S> secondly , we use the lattice visualization to re - express the cmps of an infinite system ( @xmath24 ) in the _ central canonical form _ </S>",
    "<S> @xcite , eq.([eq : centralmps ] ) below . for this purpose </S>",
    "<S> , we consider the schmidt decomposition of @xmath2 according to a left / right partition of the resulting infinite lattice @xcite , @xmath34 and denote by @xmath35 a diagonal matrix with the @xmath0 schmidt coefficients @xmath36 in its diagonal . in the central canonical form , </S>",
    "<S> the mps @xmath2 is expressed as the infinite product of ( vectorized ) matrices @xmath37 the matrices @xmath38 and @xmath39 are chosen such that @xmath40 are in the _ left _ and _ right canonical form _ </S>",
    "<S> @xcite , namely @xmath41 from eqs.([eq : centralmps])-([eq : translate ] ) the standard mps form eq.([eq : mps ] ) ( in the @xmath42 limit ) for e.g. a _ left normalized _ mps is recovered , @xmath43    in the central canonical form , familiar to dmrg and mps practitioners working with so - called single - site updates , a change in the matrices @xmath38 and @xmath39 on a single site produces an equivalent change in @xmath2 , in the sense that the scalar product in the lattice hilbert space and in the effective one - site hilbert space are equivalent ( they are related by an isometry ) . </S>",
    "<S> this is important when applying gradient methods , because two gradients , calculated in two different gauges of the same state , are in general not related by a gauge transformation and are not equivalent . </S>",
    "<S> the importance of the central gauge has been realized early on in dmrg @xcite and also time evolution methods @xcite .    finally , in the continuum limit </S>",
    "<S> , the central canonical form is given by ( _ c.f . </S>",
    "<S> _ eqs.([eq : disccmps ] ) and ( [ eq : translate ] ) ) @xmath44    _ gradient descent_. given a quantum field hamiltonian @xmath13 , see e.g. eq.([eq : ham ] ) , our goal is to iteratively optimize the cmps in such a way that the energy @xmath45 is minimized . </S>",
    "<S> each iteration updates a triplet @xmath46 } , q^{[n]}_c , r^{[n]}_c)$ ] and is made of two steps . </S>",
    "<S> _ ( i ) _ first , keeping @xmath35 fixed , we update @xmath47 and @xmath48 in the direction of _ steepest descent _ given by the gradient , namely @xmath49 } \\\\ \\\\ \\tilde{r}^{[n]}\\end{array } \\right ) =   \\left ( \\begin{array}{c } q^{[n]}_c \\\\ \\\\ </S>",
    "<S> r^{[n]}_c\\end{array } \\right ) - \\alpha_n   \\left ( \\begin{array}{c } \\partial e/\\partial q_c^ * \\\\ \\\\ \\partial e/\\partial r_c^ * \\end{array } \\right),\\end{aligned}\\ ] ] where @xmath50 is some adjustable parameter and @xmath51 denotes complex conjugation . </S>",
    "<S> crucially , the gradients @xmath52 and @xmath53 can be efficiently computed using standard cmps contraction techniques . </S>",
    "<S> we dynamically choose the largest possible factor @xmath54 by requiring consistency with some simple stability conditions ( alternatively , @xmath54 can be determined by a line search ) . _ </S>",
    "<S> ( ii ) _ then , from @xmath46},\\tilde{q}^{[n]},\\tilde{r}^{[n]})$ ] we obtain @xmath55},q_c^{[n+1]},r_c^{[n+1]})$ ] by bringing the cmps representation back into the central canonical form . </S>",
    "<S> this completes an iteration , which has a cost comparable to one time step in tdvp . we emphasize that all manipulations are implemented directly in the continuum limit i.e. @xmath56 is treated as an analytic parameter throughout the optimization , and the @xmath57 limit can be taken _ </S>",
    "<S> exactly _ due to exact cancellation of all divergencies .    </S>",
    "<S> overall , the proposed energy minimization algorithm proceeds as follows ( see @xcite for technical details ) .    _ </S>",
    "<S> ( a ) initialization : _ an initial triplet of matrices @xmath58},q_c^{[0]},r_c^{[0]})$ ] is obtained , either from a random initialization or , as in this letter , through eq.([eq : centralcmps ] ) from an mps optimized on the lattice .    </S>",
    "<S> _ ( b ) iteration : _ the above update @xmath59},q_c^{[n]},r_c^{[n ] } ) \\mapsto ( \\lambda^{[n+1]},q_c^{[n+1]},r_c^{[n+1]})$ ] is iteratively applied until attaining a suitably converged triplet @xmath60 .    _ </S>",
    "<S> ( c ) final output : _ a standard cmps representation as in eq.([eq : cmps ] ) is recovered by transforming the result into @xmath61 . </S>",
    "<S> for instance , @xmath62 as in eq.([eq : translate ] ) for a final cmps in the left canonical form ( see also @xcite ) .    as usual in such optimization methods </S>",
    "<S> , convergence can be accelerated by replacing the gradient descent in eq.([eq : qr ] ) with e.g. a non - linear conjugate gradient update , which re - uses the gradient computed in previous steps ( see @xcite ) .    _ </S>",
    "<S> example._ to benchmark the above algorithm , we have applied it to obtain a cmps approximation to the ground state of the lieb liniger model @xcite , @xmath63 which is both of theoretical and of experimental interest and has been realized in several cold atom experiments @xcite . </S>",
    "<S> this integrable hamiltonian has a critical , gapless ground state that can be described by luttinger liquid theory @xcite and can be exactly solved by bethe ansatz @xcite .    </S>",
    "<S> fig .  </S>",
    "<S> [ fig : tdvp_vs_newopt ] ( a ) ( blue dots ) illustrates the fast and robust convergence of the cmps with the number of iterations of steepest descent , by showing the energy density @xmath64 , particle density @xmath65 , and reduced energy density @xmath66 , @xmath67 for bond dimension @xmath68 and the choice of parameters @xmath69 . for comparison , we also show the same quantities when the cmps is optimized instead by an euclidean time evolution using the tdvp algorithm ( green crosses ) , starting from the same initial state and using values @xmath70 for tdvp and for the steepest descent optimization @xcite , respectively . </S>",
    "<S> these values for @xmath71 are typically used in common tdvp calculations for cmps @xcite . </S>",
    "<S> fig .  </S>",
    "<S> [ fig : tdvp_vs_newopt ] ( b ) then shows the convergence of the energy @xmath66 to the exact value @xmath72 obtained from the bethe ansatz solution @xcite as a function of iteration number , again for a steepest descent ( blue dots ) and tdvp ( green crosses ) optimization . in this example </S>",
    "<S> , energy minimization converges towards the ground state roughly a hundred times faster than tdvp . </S>",
    "<S> the difference in performance is even bigger for larger bond dimension @xmath0 , and/or when no lattice optimization is used to initialize the cmps , in which case tdvp may even fail to converge .     and @xmath69 . </S>",
    "<S> we used @xmath73 as time step for tdvp and @xmath74 for the steepest descent optimization @xcite . </S>",
    "<S> ( a ) energy density @xmath75 ( main figure ) and particle density @xmath76 ( inset ) as a function of iteration number @xmath77 . </S>",
    "<S> ( b ) convergence of reduced energy density @xmath66 towards the exact value @xmath72 as a function of iteration number @xmath77 @xcite . </S>",
    "<S> , title=\"fig : \" ]   and @xmath69 . </S>",
    "<S> we used @xmath73 as time step for tdvp and @xmath74 for the steepest descent optimization @xcite . </S>",
    "<S> ( a ) energy density @xmath75 ( main figure ) and particle density @xmath76 ( inset ) as a function of iteration number @xmath77 . </S>",
    "<S> ( b ) convergence of reduced energy density @xmath66 towards the exact value @xmath72 as a function of iteration number @xmath77 @xcite . </S>",
    "<S> , title=\"fig : \" ]     as a function of the dimensionless interaction strength @xmath78 and cmps bond dimensions @xmath0 . </S>",
    "<S> the solid line is the exact result from a bethe ansatz calculation . </S>",
    "<S> data points for different @xmath0 are on top of each other . </S>",
    "<S> the inset shows the error @xmath79 . </S>",
    "<S> ( b ) relative error @xmath80 in the reduced energy density ( filled circles ) and bipartite entanglement @xmath81 ( empty squares ) of a left / right bipartition , as a function of the bond dimension . </S>",
    "<S> ( c ) superfluid correlation function , showing saturation to a constant at a finite for correlation length @xmath82 , which diverges with growing @xmath0 . </S>",
    "<S> , title=\"fig : \" ]   as a function of the dimensionless interaction strength @xmath78 and cmps bond dimensions @xmath0 . </S>",
    "<S> the solid line is the exact result from a bethe ansatz calculation . </S>",
    "<S> data points for different @xmath0 are on top of each other . </S>",
    "<S> the inset shows the error @xmath79 . </S>",
    "<S> ( b ) relative error @xmath80 in the reduced energy density ( filled circles ) and bipartite entanglement @xmath81 ( empty squares ) of a left / right bipartition , as a function of the bond dimension . </S>",
    "<S> ( c ) superfluid correlation function , showing saturation to a constant at a finite for correlation length @xmath82 , which diverges with growing @xmath0 . </S>",
    "<S> , title=\"fig : \" ]   as a function of the dimensionless interaction strength @xmath78 and cmps bond dimensions @xmath0 . </S>",
    "<S> the solid line is the exact result from a bethe ansatz calculation . </S>",
    "<S> data points for different @xmath0 are on top of each other . </S>",
    "<S> the inset shows the error @xmath79 . </S>",
    "<S> ( b ) relative error @xmath80 in the reduced energy density ( filled circles ) and bipartite entanglement @xmath81 ( empty squares ) of a left / right bipartition , as a function of the bond dimension . </S>",
    "<S> ( c ) superfluid correlation function , showing saturation to a constant at a finite for correlation length @xmath82 , which diverges with growing @xmath0 . </S>",
    "<S> , title=\"fig : \" ]    fig .  </S>",
    "<S> [ fig : lles](a ) illustrates the performance of the proposed energy minimization algorithm as a function of the bond dimension @xmath0 . for @xmath83 </S>",
    "<S> , we computed the reduced energy density @xmath84 for several values of the dimensionless interaction strength @xmath85 in the range @xmath86 $ ] and observed a uniform pattern of convergence towards the exact @xmath87 . for reference , a @xmath88 optimization employing a non - linear conjugate gradient optimization @xcite ( stopped once </S>",
    "<S> the energy @xmath75 has converged to 9 digits ) takes @xmath896 minutes on a desktop computer @xcite , including both the lattice initialization ( @xmath892 minutes ) and the non - linear conjugate gradient optimization in the continuum ( @xmath894 minutes ) . </S>",
    "<S> this value of the bond dimension is the largest reported so far using tdvp @xcite .    </S>",
    "<S> fig .  </S>",
    "<S> [ fig : lles](b)-(c ) specializes to @xmath90 , @xmath91 , and considers even larger values of the bond dimensions @xmath0 , up to @xmath92 , to reproduce well - understood finite-@xmath0 effects of the cmps representation @xcite . fig .  </S>",
    "<S> [ fig : lles](b ) shows the relative error @xmath80 in the reduced energy density and the entanglement entropy @xmath93 across a left / right bipartition , eq.([eq : schmidt ] ) . as expected , @xmath80 vanishes with @xmath0 as a power - law , @xmath94 , whereas the entanglement entropy diverges logarithmically , @xmath95 . </S>",
    "<S> fig .  </S>",
    "<S> [ fig : lles](c ) shows the superfluid correlation function @xmath96 , which is seen to saturate to a finite value @xmath97 at some distance @xmath82 , another well - understood artefact of the ( c)mps representation at finite bond dimension @xmath0 @xcite . </S>",
    "<S> this artificial finite correlation length @xmath82 is seen to diverge with growing @xmath0 as a power - law , @xmath98 .    </S>",
    "<S> , for @xmath99.,title=\"fig : \" ] , for @xmath99.,title=\"fig : \" ]    once we have established that the optimized cmps is an accurate approximation to the ground state , we can move to exploring other properties of the model . </S>",
    "<S> fig .  </S>",
    "<S> [ fig : corrs ] shows the superfluid correlation function @xmath96 and pair correlation function @xmath100 , respectively , for @xmath101 and different values of the dimensionless interaction strength @xmath102 . </S>",
    "<S> with growing @xmath102 we observe an increasingly rapid decay in the superfluid correlation function . </S>",
    "<S> the pair correlation function develops typical oscillations that are related to the fermionic nature of the ground state of the tonks - girardeau gas @xcite at @xmath103 . </S>",
    "<S> we can also estimate both the central charge @xmath104 and the luttinger parameter @xmath105 , which can be used to uniquely identify the conformal field theory that characterizes the universal low energy / large distance features of the model . </S>",
    "<S> the central charge @xmath104 can be estimated from the slope of @xmath106 ( see ref . </S>",
    "<S> @xcite ) . for @xmath107 </S>",
    "<S> we obtain a value of @xmath108 , to be compared with the exact value @xmath109 . </S>",
    "<S> the luttinger parameter @xmath105 @xcite is obtained from fitting @xmath110 vs @xmath111 @xcite , where we choose @xmath112 to lie in the region where @xmath96 exhibits power - law decay . for @xmath25 and @xmath107 </S>",
    "<S> we obtain @xmath113 . </S>",
    "<S> the exact value is @xmath114 and was obtained from the weak - coupling approximation of the bethe ansatz solution @xcite . </S>",
    "<S> the relative error of our result is @xmath115 .    _ </S>",
    "<S> discussion._ the cmps is a powerful variational ansatz for strongly interacting quantum field theories in 1 + 1 dimensions @xcite . in this letter </S>",
    "<S> we have proposed a cmps energy minimization algorithm with much better performance , in terms of convergence and the attainable bond dimension @xmath0 , than previous optimization algorithms based on simulating an euclidean time evolution . </S>",
    "<S> we envisage that this algorithm will play a decisive role in unlocking the full potential of the cmps representation for ground state studies in the continuum .    </S>",
    "<S> our algorithm works best by initializing the cmps through an energy optimization on the lattice and by translating the resulting mps from the lattice to the continuum through eq.([eq : disccmps ] ) . </S>",
    "<S> a natural question is then whether the continuum algorithm is needed at all . </S>",
    "<S> that is , perhaps one may wonder an mps algorithm working at finite lattice spacing @xmath29 can already provide a cmps representation ( through eq.([eq : disccmps ] ) ) that can be made arbitrarily close to the one obtained with the continuum algorithm by decreasing @xmath29 sufficiently . </S>",
    "<S> the answer is that this is not possible : lattice algorithms necessarily become unstable as the lattice spacing @xmath29 is reduced . </S>",
    "<S> this can be understood from a simple scaling argument . in discretizing e.g. hamiltonian </S>",
    "<S> @xmath13 of eq.([eq : ham ] ) into a lattice , the non - relativistic kinetic term @xmath116 is seen to diverge with @xmath29 as @xmath117 , while the rest of terms in the hamiltonian have a milder scaling . for small @xmath29 </S>",
    "<S> this creates a large range of energy scales that lead to numerical instability . </S>",
    "<S> this effect is compounded with a second fact , revealed by eq.([eq : disccmps ] ) . for small @xmath29 </S>",
    "<S> the mps matrix @xmath118 is made of two pieces : a constant part @xmath119 made of @xmath120 s and @xmath121 s and the variational parameters @xmath122 , which are of order @xmath29 . </S>",
    "<S> thus the first part @xmath119 _ shadows _ the second one , in that the numerical precision on the variational parameters @xmath21 is reduced by a factor @xmath29 when embedded in matrix @xmath30 . </S>",
    "<S> the observant reader may then wonder if these problems could be prevented by just changing variables , to work instead with @xmath123 . </S>",
    "<S> this is indeed the case , and also the essence of working with the cmps representation directly , as we do in the proposed energy minimization algorithm . </S>",
    "<S> notice that lattice mps techniques can be succesfully applied to ground states @xcite and real time evolution @xcite of discretized field theories . </S>",
    "<S> however , these simulations are conducted at sufficiently large @xmath29 and are often plagued with finite @xmath56-scaling analysis , which is not necessary when working directly with a cmps .    </S>",
    "<S> we have seen that the cmps energy minimization algorithm drastically outperforms tdvp at the task of approximating the ground state ( we emphasize that the tdvp remains an extremely useful tool e.g. to simulate real time evolution , for which no other method exists ) . </S>",
    "<S> this result did not come as a surprise : on the lattice , mps energy minimization algorithms , including dmrg , have long been observed to converge to the ground state much faster than time evolution simulation algorithms @xcite . </S>",
    "<S> we conclude by mentioning that the proposed energy minimization algorithm has other significant advantages over tdvp when applied to both inhomogeneous hamiltonians ( where matrices @xmath124 and @xmath125 depend on space @xcite ) , or to a theory of multiple fields @xmath126 ( where each field is represented by a different matrix @xmath127 @xcite ) , as we will discuss in future work .    </S>",
    "<S> the authors thank d. draxler , v. zauner - stauber , j. haegeman , f. verstraete , and e. m. stoudenmire for useful comments and discussions . </S>",
    "<S> the authors also acknowledge support by the simons foundation ( many electron collaboration ) . </S>",
    "<S> computations were made on the supercomputer mammouth parallle ii from university of sherbrooke , managed by calcul qubec and compute canada . </S>",
    "<S> the operation of this supercomputer is funded by the canada foundation for innovation ( cfi ) , the ministre de lconomie , de la science et de linnovation du qubec ( mesi ) and the fonds de recherche du qubec - nature et technologies ( frq - nt ) . </S>",
    "<S> some earlier computations were conducted at the supercomputer of the center for nanophase materials sciences , which is a doe office of science user facility . </S>",
    "<S> this research was supported in part by perimeter institute for theoretical physics . </S>",
    "<S> research at perimeter institute is supported by the government of canada through industry canada and by the province of ontario through the ministry of economic development & innovation .    </S>",
    "<S> 62 natexlab#1#1bibnamefont # 1#1bibfnamefont # 1#1citenamefont # 1#1url # 1`#1`urlprefix[2]#2 [ 2][]#2    , , , * * , ( ) .    </S>",
    "<S> , * * , ( ) .    , * * , ( ) .    , , , ( ) .    , </S>",
    "<S> ( ) .    , * * , ( ) .    , </S>",
    "<S> * * , ( ) , issn .    , , , * * , ( ) .    , </S>",
    "<S> * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , , , </S>",
    "<S> , * * , ( ) .    , </S>",
    "<S> * * , ( ) .    , * * , ( ) .    , , , , , , * * , ( ) .    , * </S>",
    "<S> * , ( ) .    </S>",
    "<S> , , , , * * , ( ) .    , , , , , * * , ( ) .    , , , , , , * * , ( ) .    , , , * * , ( ) .    </S>",
    "<S> , , , , ( ) .    , * * , ( ) .    , , , , , </S>",
    "<S> * * , ( ) .    .    , </S>",
    "<S> ( ) , .    .    , , , * * ( </S>",
    "<S> ) .    , </S>",
    "<S> * * , ( ) .    , </S>",
    "<S> * * , ( ) .    , , , , , * * , ( ) .    , </S>",
    "<S> * * , ( ) .    , , , * * , ( ) .    </S>",
    "<S> , , , , , * * , ( ) .    , , , , , , , , , </S>",
    "<S> * * , ( ) .    , , , , , , , ( ) .    , .    </S>",
    "<S> .    </S>",
    "<S> , , , , , * * , ( ) .    , , , , * * , ( ) .    , , , , * * , ( ) .    , , , , </S>",
    "<S> * * , ( ) .    , </S>",
    "<S> * * , ( ) .    , </S>",
    "<S> * * , ( ) , issn .    </S>",
    "<S> , , , , * * , ( ) .    , , , , * * , ( ) .    , , , , * * ( ) .    , , , , , * * , ( ) .    , , , , , </S>",
    "<S> * * , ( ) .    , , , , , * * , ( ) .    , * * , ( ) .    , , , , , , ( ) .    , ( ) .    </S>",
    "<S> , , , * * , ( ) .    , * * , ( ) .    , , , * * , ( ) .    , , , </S>",
    "<S> .    </S>",
    "<S> * supplementary material * </S>"
  ]
}