{
  "article_text": [
    "a lossless binary prefix coding problem takes a probability mass function @xmath1 , defined for all @xmath2 in the input alphabet @xmath3 , and finds a binary code for  @xmath3 . without loss of generality , we consider an @xmath4-item source emitting symbols drawn from the alphabet @xmath5 where @xmath6 is the sequence of probabilities for possible symbols ( @xmath7 for @xmath8 and @xmath9 ) in monotonically nonincreasing order ( @xmath10 for @xmath11 ) .",
    "the source symbols are coded into binary codewords .",
    "the codeword @xmath12 in code  @xmath13 , corresponding to input symbol  @xmath2 , has length @xmath14 , defining length vector  @xmath15 .",
    "the goal of the traditional coding problem is to find a prefix code minimizing expected codeword length @xmath16 , or , equivalently , minimizing average redundancy @xmath17 where @xmath18 is @xmath19 , shannon entropy , and @xmath20 .",
    "a prefix code is a code for which no codeword begins with a sequence that also comprises the whole of a second codeword .",
    "this problem is equivalent to finding a minimum - weight external path @xmath21 among all rooted binary trees , due to the fact that every prefix code can be represented as a binary tree . in this tree representation ,",
    "each edge from a parent node to a child node is labeled @xmath22 ( left ) or @xmath23 ( right ) , with at most one of each type of edge per parent node .",
    "a leaf is a node without children ; this corresponds to a codeword , and the codeword is determined by the path from the root to the leaf .",
    "thus , for example , a leaf that is the right - edge ( @xmath23 ) child of a left - edge ( @xmath22 ) child of a left - edge ( @xmath22 ) child of the root will correspond to codeword  @xmath24 .",
    "leaf depth ( distance from the root ) is thus codeword length .",
    "the weights are the probabilities ( i.e. , @xmath25 ) , and , in fact , we will refer to the problem inputs as @xmath26 for certain generalizations in which their sum , @xmath27 , need not be  @xmath23 .",
    "if formulated in terms of @xmath15 , the constraints on the minimization are the integer constraint ( i.e. , that codes must be of integer length ) and the kraft inequality@xcite ; that is , the set of allowable codeword length vectors is @xmath28    drmota and szpankowski@xcite investigated a problem which , instead of minimizing average redundancy @xmath29 , minimizes maximum pointwise redundancy @xmath30 related to a universal modeling problem @xcite , the idea here is that , given a symbol to be compressed , we wish the length of the compressed data ( @xmath14 ) to exceed self - information ( @xmath31 ) by as little as possible , and thus consider the worst case in this regard .",
    "this naturally relates to shannon coding , as a code with lengths @xmath32 would never exceed self - information by more than @xmath23 bit .",
    "any solution , then , would necessarily have no codeword longer than its shannon code counterpart .",
    "indeed , drmota and szpankowski used a generalization of shannon coding to solve the problem , which satisfies @xmath33 we will improve the bounds , given @xmath34 , for minimum maximum pointwise redundancy and discuss the related issue of the length of the most likely codeword in these coding problems .",
    "these bounds are the first of their kind for this objective , analogous to those for traditional huffman coding@xcite and other nonlinear codes@xcite .",
    "the bounds are derived using an alternative solution to this problem , a variation of huffman coding@xcite derived from that in @xcite . in order to explain this variation",
    ", we first review the huffman algorithm and some of the ways in which it can be modified .",
    "it is well known that the huffman algorithm@xcite finds a code minimizing average redundancy .",
    "the huffman algorithm is a greedy algorithm built on the observation that the two least likely symbols will have the same length and can thus be considered siblings in the coding tree .",
    "a reduction can thus be made in which the two symbols with weights @xmath35 and @xmath36 can be considered as one with combined weight @xmath37 , and the codeword of the combined item determines all but the last bit of each of the items combined , which are differentiated by this last bit .",
    "this reduction continues until there is one item left , and , assigning this item the null string , a code is defined for all input symbols . in the corresponding optimal code tree",
    ", the @xmath2^th^ leaf corresponds to the codeword of the @xmath2^th^ input item , and thus has weight @xmath35 , whereas the weight of parent nodes are determined by the combined weight of the corresponding merged item .",
    "van leeuwen gave an implementation of the huffman algorithm that can be accomplished in linear time given sorted probabilities@xcite .",
    "shannon@xcite had previously shown that an optimal @xmath38 must satisfy @xmath39    simple changes to the huffman algorithm solve several related coding problems which optimize for different objectives .",
    "generalized versions of the huffman algorithm have been considered by many authors@xcite .",
    "these generalizations change the combining rule ; instead of replacing items @xmath2 and @xmath40 with an item of weight @xmath37 , the generalized algorithm replaces them with an item of weight @xmath41 for some function  @xmath42 .",
    "thus the weight of a combined item ( a node ) no longer need be equal to the sum of the probabilities of the items merged to create it ( the sum of the leaves of the corresponding subtree ) .",
    "this has the result that the sum of weights in a reduced problem need not be  @xmath23 , unlike in the original huffman algorithm .",
    "in particular , the weight of the root , @xmath43 , need not be  @xmath23 .",
    "however , we continue to assume that the sum of @xmath44 , the inputs before reduction , will always be  @xmath23 .",
    "one such variation of the huffman algorithm was used in humblet s dissertation@xcite for a queueing application ( and further discussed in @xcite ) .",
    "the problem this variation solves is as follows : given probability mass function @xmath45 and @xmath46 , find a code minimizing @xmath47 this growing exponential average problem is solved by using combining rule @xmath48 this problem was proposed ( without solution ) by campbell@xcite , who later noted that this formulation can be extended to decaying exponential base @xmath49@xcite ; humblet noted that the huffman combining method ( [ expcomb ] ) finds the optimal code for ( [ one ] ) with @xmath49 as well@xcite .",
    "another variation , proposed in @xcite and solved for in @xcite , can be called @xmath0^th^ exponential redundancy@xcite , and is the minimization of the following : @xmath50 here we assume that @xmath51 , although @xmath52 is also a valid problem .",
    "clearly , this can be solved via reduction to ( [ one ] ) by assigning @xmath53 and using input weights @xmath54 .",
    "minimizing maximum redundancy is equivalent to minimizing @xmath0^th^ exponential redundancy for @xmath55 .",
    "this observation leads to a huffman - like solution with the combination rule @xmath56 as in @xcite .    in the next section ,",
    "we find tight exhaustive bounds for the values of optimal @xmath57 and corresponding @xmath58 in terms of  @xmath34 , then find how we can extend these to exhaustive  but not tight  bounds for optimal @xmath59 .",
    "it is useful to come up with bounds on the performance of an optimal code , often in terms of the most probable symbol , @xmath34 . in minimizing average redundancy ,",
    "such bounds are often referred to as `` redundancy bounds '' because they are in terms of this average redundancy , @xmath60 .",
    "the simplest bounds for the optimal solution to the minimum maximum pointwise redundancy problem @xmath61 can be combined with those for the average redundancy problem : @xmath62 where @xmath63 is the average redundancy of the average redundancy - optimal code .",
    "the average redundancy case is a lower bound because the maximum ( @xmath57 ) of the values ( @xmath64 ) that average to a quantity ( @xmath65 ) can be no less than the average ( a fact that holds for all @xmath15 and  @xmath45 ) .",
    "the upper bound is found similarly to the average redundancy case ; we can note that shannon code @xmath66 results in @xmath67 .",
    "1 .   items are always merged by nondecreasing weight .",
    "2 .   the weight of the root @xmath43 of the coding tree determines the maximum pointwise redundancy , @xmath68 .",
    "the total probability of any subtree is no greater than the total weight of the subtree .",
    "if @xmath69 , then a minimum maximum pointwise redundancy code can be represented by a complete tree , that is , a tree with leaves at depth @xmath70 and @xmath71 only ( with @xmath72 ) .",
    "we use an inductive proof in which base cases of sizes @xmath23 and @xmath73 are trivial , and we use weights  @xmath74 , instead of probabilities @xmath45 , to emphasize that the sums of weights need not necessarily add up to  @xmath23 .",
    "assume first that all properties here are true for trees of size @xmath75 and smaller .",
    "we wish to show that they are true for trees of size  @xmath4 .",
    "the first property is true because @xmath76 for any @xmath2 and  @xmath40 ; that is , a compound item always has greater weight than either of the items combined to form it .",
    "thus , after the first two weights are combined , all remaining weights , including the compound weight , are no less than either of the two original weights .",
    "consider the second property ; after merging the two least weighted of @xmath4 ( possibly merged ) items , the property holds for the resulting @xmath75 items . for the @xmath77 untouched items , @xmath78 remains the same .",
    "for the two merged items , let @xmath79 and @xmath80 denote the maximum depth / weight pair for item @xmath75 and @xmath81 and @xmath82 the pair for @xmath4 .",
    "if @xmath83 and @xmath84 denote the depth / weight pair of the combined item , then @xmath85 , so the two trees have identical maximum redundancy , which is equal to @xmath86 since the root node is of depth  @xmath22 .",
    "consider , for example , @xmath87 , which has optimal codewords with lengths @xmath88 .",
    "the first combined pair has @xmath89 .",
    "this value is identical to that of the maximum redundancy , @xmath90 .    for the third property , the first combined pair yields a weight that is no less than the combined probabilities .",
    "thus , via induction , the total probability of any ( sub)tree is no greater than the weight of the ( sub)tree .    in order to show the final property , first note that @xmath91 for any tree created using the huffman - like procedure , since all internal nodes have two children .",
    "now think of the procedure as starting with a queue of input items , ordered by nondecreasing weight from head to tail .",
    "after merging two items , obtained from the head of the queue , into one compound item , that item is placed back into the queue as one item , but not necessarily at the tail ; an item is placed such that its weight is no smaller than any item ahead of it and is smaller than any item behind it . in keeping items ordered , this results in an optimal coding tree .",
    "a variant of this method can be used for linear - time coding@xcite .    in this case , we show not only that an optimal complete tree exists , but that , given an @xmath4-item tree , all items that finish at level @xmath71 appear closer to the head of the queue than any item at level @xmath92 ( if any ) , using a similar approach to the proof of lemma  2 in @xcite .",
    "suppose this is true for every case with @xmath75 items for @xmath93 , that is , that all nodes are at levels @xmath94 or @xmath95 , with the latter items closer to the head of the queue than the former .",
    "consider now a case with @xmath4 nodes .",
    "the first step of coding is to merge two nodes , resulting in a combined item that is placed at the end of the combined - item queue , as we have asserted that @xmath96 . because it is at the end of the queue in the @xmath75 case ,",
    "this combined node is at level @xmath94 in the final tree , and its children are at level @xmath97 . if @xmath4 is a power of two , the remaining items end up on level @xmath98 , satisfying this lemma . if @xmath75 is a power of two , they end up on level @xmath99 , also satisfying the lemma",
    "otherwise , there is at least one item ending up at level @xmath100 near the head of the queue , followed by the remaining items , which end up at level @xmath101 . in any case",
    ", all properties of the lemma are satisfied for @xmath4 items , and thus for any number of items .      for any distribution",
    "in which @xmath102 , @xmath103 . if @xmath104 , then @xmath105 and these bounds are tight .",
    "define @xmath106 , which , for @xmath107 , is greater than  @xmath23 . for this range",
    "the following bounds for @xmath108 are tight : @xmath109 \\left[\\frac{1}{2^{\\lu}},\\frac{1}{2^{\\lu}-1}\\right ) & \\left[\\lu+\\lg p(1),1+\\lg \\frac{1-p(1)}{1 - 2^{-\\lu}}\\right ) \\\\[6pt ] \\left[\\frac{1}{2^{\\lu}-1},\\frac{2}{2^{\\lu}+1}\\right ) & \\left[\\lg \\frac{1-p(1)}{1 - 2^{-\\lu+1}},1+\\lg \\frac{1-p(1)}{1 - 2^{-\\lu}}\\right ) \\\\[6pt ] \\left[\\frac{2}{2^{\\lu}+1},\\frac{1}{2^{\\lu-1}}\\right ) & \\left[\\lg \\frac{1-p(1)}{1 - 2^{-\\lu+1}},\\lu+\\lg p(1 ) \\right]\\\\ ~&~\\\\ \\end{array}\\ ] ] [ mmprbetter ]        _ upper bound _ :",
    "let us define what we call a _ first - order shannon code _ : @xmath111 this code , previously presented in the context of finding _ average _ redundancy bounds given _ any _ probability @xcite , improves upon the original `` zero - order '' shannon code @xmath112 by taking the length of the first codeword into account when designing the rest of the code .",
    "the code satisfies the kraft inequality , and thus , as a valid code , its redundancy is an upper bound on the redundancy of an optimal code .",
    "note that @xmath113 if @xmath114 , the maximum pointwise redundancy of the first item is no less than @xmath115 , and thus @xmath116 .",
    "otherwise , @xmath117 .",
    "the tightness of the upper bound in @xmath118 is shown via @xmath119 for which the bound is achieved in @xmath120 for any @xmath121 $ ] and approached in @xmath122 as @xmath123 . if @xmath124 and @xmath114 , use probability mass function @xmath125 where @xmath126 because @xmath127 , @xmath128 , and @xmath129 .",
    "similarly , @xmath130 assures that @xmath131 , so the probability mass function is monotonic . since @xmath132 , by lemma  [ complete ] , an optimal code for this probability mass function",
    "is @xmath133 for all  @xmath2 , achieving @xmath134 , with item @xmath23 having the maximum pointwise redundancy .",
    "this leaves only @xmath135 , for which we consider @xmath136 where @xmath123 .",
    "this is a monotonic probability mass function for sufficiently small  @xmath137 , for which we also have @xmath138 , so ( again from lemma  [ complete ] ) this results in optimal code where @xmath133 for @xmath139 and @xmath140 , and thus the bound is approached with item @xmath75 having the maximum pointwise redundancy .      _",
    "lower bound _ : consider all optimal codes with @xmath141 for some fixed @xmath142 . if @xmath143 , @xmath144 . if @xmath145 , consider the weights at level @xmath146 ( i.e. , @xmath146 edges below the root ) .",
    "one of these weights is @xmath34 , while the rest are known to sum to a number no less than @xmath147 .",
    "thus at least one weight must be at least @xmath148 and @xmath149 .",
    "thus , @xmath150 for @xmath141 , and , since @xmath146 can be any positive integer , @xmath151 which is equivalent to the bounds provided .    for @xmath152 for some @xmath146 ,",
    "consider @xmath153 by lemma  [ complete ] , this will have a complete coding tree and thus achieve the lower bound for this range ( @xmath154 ) .",
    "similarly @xmath155 has a fixed - length optimal coding tree for @xmath156 , achieving the lower bound for this range ( @xmath157 ) .",
    "note that the bounds of ( [ mmprbounds ] ) are identical to the tight bounds at powers of two .",
    "in addition , the tight bounds clearly approach @xmath22 and @xmath23 as @xmath158 .",
    "this behavior is in stark contrast with average redundancy , for which bounds get closer , not further apart , due to gallager s redundancy bound@xcite  @xmath159  which can not be significantly improved for small @xmath34@xcite .",
    "moreover , approaching @xmath23 , the upper and lower bounds on minimum average redundancy coding converge but never merge , whereas the minimum maximum redundancy bounds are identical for @xmath102 .",
    "in addition to finding redundancy bounds in terms of @xmath34 , it is also often useful to find bounds on the behavior of @xmath58 in terms of @xmath34 , as was done for optimal average redundancy in @xcite .",
    "any optimal code for probability mass function @xmath45 , where @xmath160 , must have @xmath161",
    ". this bound is tight , in the sense that , for @xmath162 , one can always find a probability mass function with @xmath163 .",
    "conversely , if @xmath164 , there is an optimal code with @xmath165 , and this bound is also tight .",
    "[ mmprl1 ]      for tightness of the bound , suppose @xmath170 and consider @xmath171 and @xmath172 if @xmath161 , then , by the kraft inequality , one of @xmath173 through @xmath79 must exceed @xmath174 .",
    "however , this contradicts the simple bounds of ( [ mmprbounds ] ) . for @xmath175 , a uniform distribution results in @xmath176 .",
    "thus , since these two results hold for any @xmath174 , this extends to all @xmath177 , and this bound is tight .",
    "suppose @xmath178 and consider an optimal length distribution with @xmath179 .",
    "consider the weights of the nodes of the corresponding code tree at level @xmath58 .",
    "one of these weights is @xmath34 , while the rest are known to sum to a number no less than @xmath147 .",
    "thus there is one node of at least weight @xmath180 and thus , taking the logarithm and adding @xmath58 to the right - hand side , @xmath181 note that @xmath182 , a direct consequence of @xmath183 .",
    "thus , if we replace this code with one for which @xmath184 , the code is still optimal .",
    "the tightness of the bound is easily seen by applying lemma  [ complete ] to distributions of the form @xmath185 for @xmath186 .",
    "this results in @xmath187 and thus @xmath188 , which no code with @xmath189 could achieve .",
    "we now briefly address the @xmath0^th^ exponential redundancy problem .",
    "recall that this is the minimization of @xmath194 this can be rewritten as @xmath195 a straightforward application of lyapunov s inequality for moments yields @xmath196 for @xmath197 , which , taking limits to @xmath22 and @xmath198 , results in @xmath199 for any valid @xmath45 , @xmath200 , and @xmath15 , resulting in an extension of ( [ mmprbounds ] ) , @xmath201 where @xmath202 is the optimal @xmath0^th^ exponential redundancy , an improvement on the bounds found in @xcite .",
    "this implies that this problem can be bounded in terms of the most likely symbol using the upper bounds of theorem  [ mmprbetter ] and the lower bounds of average redundancy ( huffman ) coding@xcite : @xmath203 where @xmath204 for @xmath205 ( and , recall , @xmath206 ) ."
  ],
  "abstract_text": [
    "<S> this paper presents new lower and upper bounds for the optimal compression of binary prefix codes in terms of the most probable input symbol , where compression efficiency is determined by the nonlinear codeword length objective of minimizing maximum pointwise redundancy . </S>",
    "<S> this objective relates to both universal modeling and shannon coding , and these bounds are tight throughout the interval </S>",
    "<S> . the upper bounds also apply to a related objective , that of @xmath0^th^ exponential redundancy . </S>"
  ]
}