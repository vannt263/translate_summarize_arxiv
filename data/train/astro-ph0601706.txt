{
  "article_text": [
    "over the last 15 years , it has become possible to observe molecular emission in nearby galaxies with sufficient resolution and sensitivity to distinguish individual giant molecular clouds ( gmcs ) .",
    "the immediate goal of such studies is to determine whether ( and how ) the gmcs in other galaxies differ from those seen in the solar neighborhood .",
    "the most common method used to address this question has been to use molecular - line tracers of h@xmath1 , in particular @xmath2co(@xmath3 ) , to compare the macroscopic properties ( size , line width , and luminosity ) of gmcs in other galaxies to those of milky way gmcs .",
    "unfortunately , a wide variety of methods have been used to reduce data from spectral line data cubes into macroscopic gmc properties . as a result , many of the differences between gmc populations found in the literature can be attributed , at least partially , to observational artifacts or methodological differences .",
    "it is therefore difficult to assess what the real differences between gmc populations are based on the reported data in the literature .    for gmcs",
    "that are either marginally resolved or marginally detected , observational biases can be severe .",
    "figure [ resbias ] shows the variation of the measured spatial size and line width with the resolution for a model cloud .",
    "typical galactic gmcs have sizes of a few 10s of parsecs , comparable to the spatial resolution of many data sets used to study extragalactic gmcs ( e.g.   * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "figure [ resbias ] shows that when the size of the beam is comparable to the size of the object , the measured size is much higher than the true size of the object .",
    "millimeter spectrometers and correlators often have excellent frequency resolution , so the spectral resolution bias is usually less important for gmc studies , but it can become substantial when data are binned to increase signal - to - noise .",
    "figure [ extrapmoms ] shows that the measured spatial size , line width , and flux of a real gmc in m  33 ( eprb1 from * ? ? ?",
    "* ) are all strong functions of the sensitivity of the data .",
    "we discuss another major source of bias , the method by which emission is decomposed into gmcs , in the appendix .",
    "to place these biases in the the context of real molecular cloud studies , figure [ distcomp ] shows the peak flux and angular size of typical gmcs ( those of * ? ? ?",
    "* ) as a function of distance .",
    "the sensitivities and resolutions of a representative sample of molecular cloud studies have been indicated as horizontal lines in these plots .",
    "distances to commonly observed objects have also been labeled .",
    "figure [ distcomp ] demonstrates that most studies of extragalactic gmcs are conducted where the clouds of interest are only marginally resolved and are found at low sensitivity .",
    "even future observations of gmcs in the virgo cluster using the atacama large millimeter array ( alma ) will be affected by resolution and sensitivity biases .    in this paper",
    ", we examine the effects of biases stemming from finite spatial resolution , spectral resolution , and sensitivity in molecular - line observations of gmcs .",
    "we recommend data analysis methods to produce a standardized set of observed cloud properties that account for these biases .",
    "most of the methods used in this paper have been adopted piecemeal and _ ad hoc _ in previous studies . here",
    ", we endeavor to justify our choice of methodologies and to synthesize various author s techniques for approaching the problems of molecular cloud data analysis . in section [ moments ] , we describe a standardized method to measure three basic properties of an emission distribution  size , line width , and flux  while accounting for the sensitivity and resolution of a data set . in section",
    "[ physical ] , we discuss how these measurements can be transformed into physical quantities  radius , line width , luminosity , and implied mass . finally , we consider the effects of using interferometers to derive cloud properties in section [ interf ] .",
    "the results in these three sections are applicable to all observations of molecular clouds .",
    "in contrast , the methods used for decomposing emission into molecular clouds vary widely , and there is little basis for favoring one method over another in all cases . hence , we defer a presentation of our decomposition algorithm to the appendix of the paper , leaving only a brief discussion of the decomposition problem in section [ decompsect ] .",
    "we conclude the paper by exhibiting several examples of the application of our standardized methods to previously observed data and making recommendations for future observations ( section [ applications ] ) .",
    "the methods described in this paper require a computer program to apply .",
    "a documented software version of the decomposition and measurement algorithms is available from the authors as an idl package .",
    "this section describes how to derive the spatial size , line width , and flux from a region of emission within a spectral line map ( a `` data cube '' ) while accounting for the finite sensitivity and resolution of the data set .",
    "we use moment methods ( e.g.   * ? ? ?",
    "* ) , which make full use of position and intensity information without assuming a functional form for the cloud .",
    "they are therefore robust to pathologies in the data _ within _ the cloud .",
    "moments are , however , sensitive to the inclusion of false emission ( noise ) at the edge of a cloud . including noise has the effect of artificially increasing the values of the moment .",
    "therefore the methods outlined here should be employed in conjunction with careful signal identification so that the calculations include as little noise as possible .",
    "we assume throughout this section that the algorithm is being applied to a distribution of real emission that we label a `` cloud '' ( we discuss signal identification and decomposition in the appendix ) .",
    "this subsection describes how to apply moment methods to derive the size , line width , and flux from a distribution of emission ( a `` cloud '' ) within a position - position - velocity data cube .",
    "the data cube consists of a number of pixels that have sizes of @xmath4 , @xmath5 , and @xmath6 in the two spatial dimensions and the velocity dimension , respectively .",
    "the @xmath7th pixel in the data cube has positions @xmath8 and @xmath9 , velocity @xmath10 , and brightness temperature @xmath11 .",
    "we assume that the cloud is contiguous and bordered by an isosurface in brightness temperature of value @xmath12 , so that all of the pixels in the cloud have @xmath13 and the pixels outside the cloud have @xmath14 or are separated from the cloud by emission with @xmath14 .",
    "we begin by rotating the spatial axes so that the @xmath15 and @xmath16 axes align with the major and minor axis of the cloud , respectively .",
    "we determine the orientation of the major axis using principal component analysis .",
    "we find the eigenvectors of the intensity - weighted covariance matrix for the cloud ,    @xmath17 \\mbox { .}\\ ] ]    in the equations above the sum @xmath18 runs over all pixels within the cloud and @xmath19 and @xmath20 are the intensity weighted mean positions within the cloud ( defined below ) .",
    "we define the new @xmath15 axis to lie along the eigenvector with the largest eigenvalue  the major axis of the cloud .",
    "the @xmath16 axis lies perpendicular to the @xmath15 axis along the minor axis of the cloud . in the discussion below",
    ", @xmath15 refers to position along the major axis and @xmath16 refers to position along the minor axis .",
    "rotating the axes in this manner yields information about the axis ratio of the cloud and allows a more careful deconvolution .",
    "this method for determining the position angle of molecular clouds has also been adopted by @xcite .    to measure of the size of the cloud , we compute the geometric mean of the second spatial moments along the major and minor axis .",
    "this is @xmath21 , the root - mean - squared ( rms ) spatial size :    @xmath22    where @xmath23 and @xmath24 are the rms sizes ( second moments ) of the intensity distribution along the two spatial dimensions .",
    "we adopt this particular functional form since it has been used in previous observational studies @xcite and explored in depth by @xcite with respect to inclination , aspect ratio , and virialization .",
    "we calculate @xmath23 and @xmath25 by :    @xmath26 ^ 2}{\\sum_{i}^{cloud } t_i } } , \\mbox { where } \\\\",
    "\\bar{x }    ( t_{edge } ) & = & \\frac{\\sum_{i}^{cloud } t_i x_i}{\\sum_{i}^{cloud } t_i }    \\mbox{~and } \\\\",
    "\\sigma_{min } ( t_{edge } ) & = & \\sqrt{\\frac{\\sum_{i}^{cloud } t_i    \\left [ y_i - \\bar{y } ( t_{edge } ) \\right]^2}{\\sum_{i}^{cloud } t_i } } \\mbox { , where } \\\\",
    "\\bar{y } ( t_{edge } ) & = & \\frac{\\sum_{i}^{cloud } t_i    y_i}{\\sum_{i}^{cloud } t_i } \\mbox{.}\\end{aligned}\\ ] ]    in the equations above the sum @xmath27 runs over all pixels within the cloud .",
    "we have written each of the moments as a function of @xmath12 because changing the isosurface that defines the boundary of the cloud ( @xmath12 ) will change the set of pixels included in the sum and therefore the values of the moments .",
    "note that @xmath21 is not the rms distance ( @xmath28 ) from the center of the cloud .",
    "rather it is the analogous to the rms size of the cloud along an arbitrarily chosen axis .",
    "thus , @xmath29 for a perfectly round cloud , while the rms distance from the center for such a distribution is larger , @xmath30 .",
    "also note that @xmath31 is the axis ratio of the cloud and will be @xmath32 for round clouds and @xmath33 for elongated or filamentary clouds .",
    "we calculate the velocity dispersion , @xmath34 in the same manner as the size :    @xmath35 ^ 2}{\\sum_{i}^{cloud } t_i } } \\mbox { , where } \\\\",
    "\\bar{v } ( t_{edge } ) & = & \\frac{\\sum_{i}^{cloud } t_i v_i}{\\sum_{i}^{cloud } t_i } \\mbox { .}\\end{aligned}\\ ] ]    the sums again run over all emission in the cloud . for a gaussian line profile , such as that found for most clouds , the full - width half - maximum ( fwhm ) line width ,",
    "@xmath36 will be related to @xmath37 by    @xmath38    finally , we calculate the flux of the cloud , @xmath39 using the zeroth moment :    @xmath40    if @xmath4 and @xmath5 are in units of arcseconds , @xmath6 in km s@xmath41 , and @xmath11 in k , then the resulting flux will have units of k km s@xmath41 arcsecond@xmath42 .      the sensitivity of a dataset influences the cloud properties derived from that data , a fact that we have emphasized in the previous section by explicitly writing the moments as functions of @xmath12 , the cloud boundary ( usually set by the signal - to - noise ratio of the data ) .",
    "figure [ extrapmoms ] shows the variation of spatial size , line width , and flux as a function of sensitivity for a bright cloud in m33 .",
    "the data for this cloud shows a substantial _ sensitivity bias _ ; all of the derived properties are strong functions of the boundary isosurface ( @xmath12 ) . in order to compare data sets with different sensitivities ,",
    "one must account for this bias . in this section",
    "we describe a method to do this by extrapolating the measured properties of a cloud@xmath23 , @xmath24 , @xmath37 , and @xmath43to those we would expect to measure for a cloud within a boundary isosurface of @xmath44 kelvin ( i.e. , perfect sensitivity ) .",
    "we estimate the values of the moments at @xmath45  k by extrapolating from higher values of @xmath12 . this technique was originally suggested for inferring total cloud areas by @xcite and applied to molecular cloud properties by @xcite .",
    "we calculate each of the moments for a sample of boundary temperatures , @xmath12 , ranging from near the peak temperature of the cloud to the lowest boundaries allowed by the data .",
    "thus , we measure the variations of the moments as a function of the boundary temperature , @xmath12 , within the cloud ( this is how we constructed the plot shown in figure [ extrapmoms ] ) .",
    "below , we assume that we have measured each of the four moments for values of @xmath12 ranging from @xmath46 ( the minimum allowed by the data , that is the sensitivity limit ) to @xmath47 ( near the peak temperature of the cloud ) .",
    "we estimate the value of the moments at @xmath44  k by performing a weighted , linear least - squares fit to the measured moments . as an example , we consider @xmath23 .",
    "the data are modeled as @xmath48 and the fit determines the extrapolated moment , @xmath49 . for the fit ,",
    "each pair of data @xmath50 is assigned a weight proportional to the number of data in the cloud with @xmath51 , so that measurements of the moment using more data are weighted more heavily .",
    "practically , this means that points to the left in figure [ extrapmoms ] have higher weights than those to the right .",
    "we use this linear extrapolation for @xmath52 , @xmath53 , and @xmath54 , but we find that a quadratic extrapolation ( including a @xmath55 term ) gives better results for the zeroth moment , @xmath56 ( though we revert to a linear extrapolation when the extrapolated flux is lower than the measured flux ) .",
    "we plot the flux of a gaussian cloud as a function of @xmath12 in figure [ fluxfig ] for an uncorrected zeroth moment and the linear and quadratic extrapolations to illustrate the appropriateness of the quadratic fit to the zeroth moment . at very low sensitivities ( signal - to - noise ratios near unity ) ,",
    "the quadratic extrapolation is very noisy , but for signal - to - noise ratios of @xmath57 or better it does a dramatically better job of recovering the true flux of the cloud ( @xmath58 ) than either the linear extrapolation or no extrapolation .",
    "figure [ extrapmoms ] also shows these extrapolations for a bright cloud in m  33 .",
    "the result of this extrapolation is a set of four moments  @xmath59 , @xmath60 , @xmath61 , and @xmath62  that correspond to those we would expect to measure given infinite sensitivity .",
    "the values of these moments should be directly comparable even among datasets with different sensitivities ( values of @xmath46 ) .",
    "note that diffuse emission surrounding a gmc may confuse this method .",
    "if one data set is measured with sensitivity sufficient to detect diffuse emission surrounding a gmc , while another lacks the sensitivity to do so then this approach may not be sufficient to correct for the sensitivity bias",
    ". this problem may be particularly acute when comparing galactic gmcs observed with very good sensitivity to extragalactic clouds with worse signal - to - noise ratios .",
    "interferometric data `` resolves out '' emission significantly more extended than the synthesized beam ( see  [ interf ] ) , representing another bias against detecting diffuse emission .",
    "@xcite , @xcite , @xcite , and @xcite find evidence for diffuse emission surrounding gmcs in the milky way and the local group galaxies m  31 , m  33 , and ic  10 , respectively .",
    "any astronomical data set represents the convolution of the intensity of the source with the profile of the instrument used to observe it .",
    "care must therefore be taken in measuring sizes and line widths when the extent of the intensity distribution is comparable to the instrumental profile . in a typical spectral line data cube",
    "two profiles are important : the spatial beam and the width of a velocity channel . in this section ,",
    "we describe simple corrections to account for the effects of finite spatial and spectral resolution .",
    "we `` deconvolve '' the spatial beam from the measured cloud size by subtracting the rms beam size , @xmath63 , from the extrapolated spatial moments , @xmath64 and @xmath65 , in quadrature  an approach that is exact for gaussians .",
    "the deconvolved second moment is given by :    @xmath66^{1/2 } ~ [ \\sigma_{min}^2 \\left(0~\\mathrm { k } \\right ) - \\sigma_{beam}^2 ] ^{1/2}}~\\mbox { , } \\ ] ]    where @xmath67 and @xmath68 are extrapolated to the 0 kelvin isosurface as described in  [ extrapsect ] .",
    "this extrapolation is necessary to make this deconvolution valid : subtracting the full @xmath63 from the spatial moment measured for only part of the cloud will lead to an overcorrection and thus to an underestimate of the cloud size .",
    "measuring the spatial size along the minor axis is also necessary to ensure that the cloud is indeed resolved in all dimensions .",
    "this is an advantage of the choice of axes ( major / minor ) described above . with sufficient signal - to - noise , this method of deconvolution",
    "provides a robust measurement of cloud size even for marginally resolved clouds .",
    "instrumental resolution also affects the measured line width .",
    "spectrometers measure the average intensity across a channel , rather than sampling the intensity at the center ( nominal frequency ) of that channel .",
    "when the width of the spectral line under consideration is comparable to the bandwidth of a single channel , the line strength varies significantly across an individual channel . in this case",
    ", the average value may differ substantially from the value at line center .",
    "the output of the spectrometer is thus a convolution of the true spectral profile with the profile of an individual channel .",
    "we account for this potential bias towards higher line widths by a simple deconvolution of the channel width from the extrapolated second moment :    @xmath69    where @xmath70 is the second moment of the cloud in the @xmath71 dimension extrapolated to 0 kelvin as described in  [ extrapsect ] and @xmath72 is the width of a velocity resolution element . although the channel profiles are usually square in shape and not gaussian , we simplify the deconvolution by approximating the channel shape as a gaussian with integrated area equal to that of a square channel with width @xmath72 .",
    "for such a gaussian , @xmath73 .",
    "we use extrapolated moments to measure gmc properties rather than employing an established method from the literature . in this section , we justify our choice by comparing several methods of measuring gmc properties .",
    "we focus on the performance of these methods at marginal resolution and low signal - to - noise , conditions typical of extragalactic gmc observations .    determining the radius of a cloud is particularly difficult because gmcs are often asymmetrical with poorly defined boundaries .",
    "several authors have devised methods to return a single characteristic size for complicated emission distributions .",
    "the intensity - weighted second moments in the spatial directions have been used in many studies ( e.g.   * ? ? ?",
    "* ) , but are sensitive to both noise and convolution effects . the other commonly used method ( e.g.   * ? ? ?",
    "* ; * ? ? ?",
    "* ) is to infer the radius based on the area of the cloud : @xmath74 here @xmath75 is the area of a point source that has been convolved with a beam and measured with the same signal - to - noise as the emission in the map .",
    "finally , @xcite and @xcite adopted the size of the cloud as the mean of the deconvolved fwhms of the emission distribution along two perpendicular directions .",
    "we compare these three methods to the extrapolated moment method presented above across a range of resolutions and sensitivities .",
    "we measure the size of a galactic gmc using each method after convolving it to a desired resolution and adding noise to produce a particular signal - to - noise ratio . for the data , we use the @xmath2co data from the rosette molecular cloud @xcite , which we clip at 2@xmath76 ( the rms noise in the original data set ) and integrate in the velocity dimension to produce a map of integrated intensity . for a range of sensitivities and resolutions , we convolve this map with a gaussian beam and add noise .",
    "we measure the size of the cloud in 100 realizations of the noise for each such \\{resolution , sensitivity } pair using ( a ) the extrapolated moment method , ( b ) the moment of the data without extrapolation , ( c ) the area method and ( d ) the fwhm method .",
    "wherever possible we corrected for the effects of beam convolution and signal - to - noise for each of the methods .",
    "the results of the analysis are shown in figure [ radplot ] .",
    "figure [ radplot ] shows the recovered radius as a function of resolution and sensitivity , with the `` true '' radius defined as that measured at very high sensitivity and very good resolution ( i.e. in the original data , the top right corner of each plot ) .",
    "the hashed region of parameter space shows the range of parameters over which each algorithm recovers a radius within 10% of the true value .",
    "the extrapolated moment method has the largest hashed region and so is remarkably robust , recovering the true radius over a large range of sensitivities and resolutions . only at low sensitivity ( @xmath77 ) and marginal resolution ( @xmath78 ) ,",
    "does the derived radii depart systematically from the true radius .",
    "notably , the extrapolated second moment performs quite well at signal - to - noise ratios from 5 to 10 ( in the integrated intensity map ) , values typical of extragalactic co data sets .",
    "by contrast , the uncorrected moment method ( panel b in figure [ radplot ] ) underestimates the size at low signal - to - noise since ( by construction ) the uncorrected moment does not account for emission below the noise level .",
    "similarly , the area method ( panel c ) shows systematic variation at both low signal - to - noise ( where emission drops below the noise level ) and low resolution ( where the convolved area of the emission distribution grows disproportionately because of the filamentary nature of the cloud ) .",
    "finally , the fwhm method ( panel d ) shows large systematic variations since it depends only on the location of the fwhm contour and not on the remainder of the emission distribution .",
    "the region of systematic underestimation at low signal - to - noise but reasonable resolution shows the effects of missing the diffuse emission mentioned in  [ extrapsect ] .",
    "the rosette includes more co emission at low intensities than the extrapolated moment predicts from the high intensity data . as a result , when that diffuse emission is not included in the measurement ,",
    "the algorithm underestimates the true radius of the gmc .",
    "this effect is seen panels ( a ) and ( b )  the extrapolated and uncorrected second moments  and is more pronounced in the uncorrected second moment , panel ( b ) .",
    "we perform a similar experiment on recovering the line width of an emission line in noisy data .",
    "we measure the recovered line width of a gaussian line of known width using three methods ( a ) the extrapolated moment method ( b ) an uncorrected second moment and ( c ) a gaussian fit to the line . for a range of signal - to - noise levels ( @xmath79 ) and channel widths @xmath72 we measure the recovered line width relative to the known line width .",
    "the mean values of the recovered line for 1000 realizations of the noise are plotted in figure [ dvplot ] .",
    "the extrapolated moment does not show the systematic variation with signal - to - noise seen in the uncorrected moment .",
    "the extrapolated moment is nearly as robust a measure as the gaussian fit for a perfectly gaussian line and will prove superior if the line is not gaussian .",
    "robust recovery of the line width using any method requires @xmath80 .",
    "the formal uncertainty associated with each moment measurement is quite small .",
    "cloud identification and extrapolation represent larger sources of uncertainty , but their effects are difficult to assess formally .",
    "we use bootstrapping methods to estimate the uncertainties in our measurements of cloud properties .",
    "the bootstrapping method determines errors by generating several trial clouds from the original cloud data .",
    "a trial cloud is generated by considering the cloud to be a collection of data @xmath81 for @xmath82 , the number of points in the cloud .",
    "the data are sampled for @xmath83 random values of @xmath7 , allowing for @xmath7 to be repeated .",
    "the properties of the cloud are measured for each trial cloud .",
    "we estimate the uncertainty from the variance of the cloud properties derived from these resampled and remeasured data sets .",
    "the final uncertainty in each property is the standard deviation of the bootstrapped values scaled up by the square root of the oversampling rate .",
    "the oversampling rate , which is usually equal to the number of pixels per beam , accounts for the fact that not all of the data in each cloud are independent . for many interferometric data sets",
    "this is an important effect , since these data can have @xmath84 or more pixels per beam .",
    "we compare the uncertainties produced by the bootstrapping to those derived from repeatedly adding noise to and then reanalyzing a data set .",
    "we use the bright cloud in m  33 shown in figure [ extrapmoms ] .",
    "we conduct 100 realizations of the data plus random noise .",
    "the resulting uncertainties in @xmath52 , @xmath53 , @xmath54 , and the flux are @xmath85 , @xmath86 , @xmath85 , and @xmath85 . repeatedly bootstrapping the same data set ( adjusted to have the same final noise level ) yields average uncertainties of @xmath87 , @xmath87 , @xmath88 , and @xmath89 .",
    "the bootstrapping estimates are higher for this bright cloud because they reflect both the formal uncertainty and the robustness of the result to the removal of a given piece of data . in the low signal - to - noise regime ,",
    "the values for the two methods converge as noise dominates the uncertainty derived from bootstrapping  for example , performing the same experiment in a dimmer m  33 cloud with @xmath90 the luminosity of the bright cloud and comparable noise , bootstrapping yields errors of @xmath91 , @xmath92 , @xmath93 , and @xmath94 in the four moments while repeated realizations produces scatters of @xmath95 , @xmath96 , @xmath97 , and @xmath98 .",
    "the bootstrapping method produces a robust , believable estimate of the uncertainty in the measurement of the properties of a particular , defined cloud .",
    "it does not account for uncertainties in the assignment of emission to a cloud either as a result of noise or choice of algorithm .",
    "these uncertainties are more systematic than random in nature and may be best assessed by analyzing the emission distribution using several methods .",
    "the bootstrapping estimate may be treated as an accurate estimate of the uncertainties in the results _ given _ that one adopts the methods presented in this paper .",
    "in this section , we outline how to use the measured size , line width , and flux to calculate several physical quantities of interest : the effective spherical radius , the virial mass , and the luminous mass . throughout this section",
    "we assume that clouds can be described as self - gravitating spheres with density profiles @xmath99 and negligible support from magnetic fields or confinement by external pressure .",
    "we assume below that the data consists of observations of the  transition , in units of brightness temperature , but the method is readily adaptable to analogous data sets .",
    "we define a factor @xmath100 that relates the one - dimensional rms size , @xmath101 , to the radius of a spherical cloud @xmath102 : @xmath103 .",
    "it is possible to derive an estimate for @xmath100 based on spherical cloud of radius @xmath102 with a density profile @xmath104 . in this model ,",
    "@xmath105    for a cloud with @xmath106 , @xmath107 , somewhat higher than the empirical correction of @xmath108 derived by solomon et al .",
    "the difference arises , in part , from using @xmath2co as a density tracer .",
    "since @xmath2co emission saturates in dense regions and vanishes from low density regions , the apparent density profile in @xmath2co is shallower than the true density profile .",
    "hence , an appropriate value of @xmath100 likely falls in the range between @xmath108 and @xmath109 . for tracers like @xmath110co with higher critical densities ,",
    "a different value of @xmath100 may be appropriate . since comparison to this `` anchoring '' data set",
    "may be more important than adopting a self - consistent  but grossly oversimplified  model for a cloud , we recommend the solomon et al .",
    "( 1987 ) definition of the cloud radius , @xmath111 .",
    "note , that adjusting the definition of the radius renders the virial mass formula we present below inexact .",
    "we convert the cloud properties @xmath112 , @xmath113 , and @xmath114 to the physical quantities @xmath102 , @xmath115 , and @xmath116 . for a cloud at a distance of @xmath117 ( in parsecs ) , the physical radius will be    @xmath118 = \\frac{r ( 0~\\mathrm{k } ) [ \\mathrm{arcsec}]}{3600 } \\times \\frac{\\pi}{180 } \\times d [ \\mathrm{pc}]~\\mathrm{,}\\ ] ]    the fwhm line width will be    @xmath119    and the luminosity of the cloud , @xmath116 , will be    @xmath120 & = &      f_{\\mathrm{co}}(0~\\mathrm{k } ) [ \\mathrm{k~km~      s}^{-1}~\\mathrm{arcsec}^2 ] \\\\",
    "\\nonumber & \\times & ( d[\\mathrm{pc}])^2\\\\ & \\times & \\left(\\frac{\\pi}{180\\cdot 3600}\\right)^2.\\end{aligned}\\ ] ]    a particular co luminosity , @xmath116 , implies a mass of molecular gas , @xmath121 , of    @xmath122 & = & \\frac{x_{\\mathrm{co}}}{2    \\times 10^{20 } [ \\mathrm{cm}^{-2}/(\\mathrm{k~km~s}^{-1 } ) ] } \\times    4.4~l_{\\mathrm{co}}\\\\ & \\equiv & 4.4~x_2~l_{\\mathrm{co}}\\end{aligned}\\ ] ]    where @xmath123 is the assumed co - to - h@xmath1 conversion factor .",
    "this calculation includes a factor of 1.36 ( by mass ) to account for the presence of helium . including helium is important to facilitate comparison with the virial mass , which should reflect all of the gravitating mass in the cloud .",
    "we have adopted a fiducial value of the co - to - h@xmath1 conversion factor of @xmath124 and express changes relative to this value in terms of the parameter @xmath125 .",
    "we compute the virial masses under the assumption that each cloud is spherical and virialized with a density profile described by a truncated power law of the form @xmath104 with no magnetic support or pressure confinement . as with the spherical radius correction ,",
    "the exact density profile of the cloud will affect the correct form of the virial theorem mass .",
    "for @xmath106 , the virial mass is given by the formula ( solomon et al .",
    "1987 ) :    @xmath126    and more generally by    @xmath127    where @xmath115 is the fwhm velocity line width in , @xmath102 is the radius in pc , and the cloud has a density profile of @xmath128 .",
    "clouds exhibit a range of non - spherical geometries and may be supported by magnetic fields or confined by pressure . therefore , the studying the virial parameter may be more useful than the virial mass itself .",
    "the virial parameter is a constant of order unity that characterizes deviations from the virial theorem applied to a non - magnetic cloud with no external pressure and constant density .",
    "following @xcite , we define the virial parameter as @xmath129 larger - than - unity virial parameters can result from pressure confinement , while @xmath130 may result from significant magnetic support .",
    "incorrect values of the co - to - h@xmath1 conversion factor may skew the result in either direction .",
    "finding @xmath131 means that the clouds are gravitationally bound in the absence of significant magnetic support .",
    "millimeter - wave interferometers are required to resolve even the most massive molecular clouds in galaxies beyond the magellanic clouds ( see figure [ distcomp ] ) .",
    "unfortunately , interferometers are not sensitive to spatial frequencies outside the limited region of the @xmath0 plane that they sample .",
    "practically , this means interferometers do not measure the total flux from the emission distribution ; and structures are resolved out , usually on large angular scales that correspond to small separations in the @xmath0 plane .",
    "ideally , interferometer observations are combined with single - dish observations that supply the missing information . in practice",
    "such observations are conducted infrequently and the unknown total flux and short - spacing information is estimated using deconvolution algorithms such as clean or maximum entropy ( see * ? ? ?",
    "* and references therein ) .",
    "@xcite simulate the results of using only an interferometer to observe galactic gmcs as if these well - studied clouds were located in m31 .",
    "they find that interferometers experience significant ( 50% ) flux loss for their simulated observation , primarily from extended emission around clouds .",
    "however , they find that the flux loss does not change the size and line width of the cloud .",
    "@xcite examine the recovery of large - scale flux distributions from interferometer measurements in more depth and explore the effectiveness of deconvolution algorithms at low signal - to - noise .",
    "they find that deconvolution algorithms recover flux nonlinearly at low sensitivities , finding much less flux at low sensitivities than one would expect .",
    "since much of the data on extragalactic gmcs have low signal - to - noise , this may represent an important bias .",
    "we assess the effects of interferometric biases on the methods presented here by extending the method of @xcite .",
    "we use @xmath132 observations of three galactic gmcs : the orion molecular complex @xcite , the rosette molecular cloud @xcite , and an excerpt from the outer galaxy survey of @xcite which contains the molecular clouds associated with the w3/w4/w5 regions .",
    "we simulate observing these three molecular complexes in m31 ( @xmath133 kpc ) with the bima interferometer .",
    "we fourier transform each plane of each data set into the @xmath0 domain and resample the data along the @xmath0 tracks that would be sampled by bima observations of the data provided the gmcs were in m31 .",
    "the @xmath0 coverage reflects typical observing strategies for extragalactic clouds , such as interleaving observations of the source with calibrators and other sources .",
    "we add thermal noise and phase noise to the @xmath0 data , including a phase noise component with a magnitude that depends on the length of the baseline .",
    "we adjust the scale of the thermal and phase noise to produce the desired peak signal - to - noise ( we find our results depend only weakly on whether the noise is thermal or phase ) . we invert the resulting @xmath0 data using the miriad software package @xcite producing maps separated by 2 km s@xmath41 , and then we deconvolve the dirty maps using a clean algorithm that terminates at the 2@xmath76 level . for each trial cloud",
    ", we then calculate the cloud properties using the methods of   [ moments ] and [ physical ] .    for comparison , we compute cloud properties using the same procedure to simulate single - dish observations with signal - to - noise and effective resolution identical to the mock interferometer data .",
    "we generate the mock single - dish observations by sampling the transformed image data for an equal number of @xmath0 points as the interferometer data , but the points are normally distributed in the @xmath0 plane and one point is forced to lie at @xmath134 thus sampling the total power .",
    "the width of the @xmath0 point distribution is chosen to give a beam size similar to that of the mock interferometer data .",
    "random thermal and phase noise is added to these data in the same fashion as for the interferometer data .",
    "then the data are inverted using natural weighting and deconvolved in the exact same fashion as the interferometer data ( though the deconvolution step has little effect ) .",
    "again , we extract cloud properties using the methods of   [ moments ] and [ physical ] .    with these simulations ,",
    "we compare the cloud properties derived from interferometer data to single - dish data that are equivalent in every other fashion , thereby isolating the effects of interferometers on the derived properties .",
    "the additional biases imposed by limited resolution and sensitivity are discussed separately in  [ compare ] . here",
    "we focus on mock bima observations of the three molecular complexes using three antenna configurations : the c array ( extended ) , the d ( compact ) array , and a combination of c and d array ( see * ? ? ?",
    "* for details on the configurations ) .",
    "the synthesized beam sizes for these configurations are @xmath135 , @xmath136 and @xmath137 for the d , c and c+d hybrid array observations respectively , corresponding in turn to 54 , 22 and 33 parsecs at 770  kpc .",
    "we conduct 10 sample observations for each cloud in each array at a range of sensitivities ranging from @xmath138 to @xmath139 .",
    "figure [ interf_props ] shows the properties recovered by mock observations of the orion molecular complex for each array and a range of sensitivities .",
    "the values of each properties are normalized by the value recovered by mock single - dish observations at the same sensitivity and resolution .",
    "thus , the only difference between the four sets of properties ( c , d , c+d , and single dish ) is the @xmath0 coverage of the simulated observations .",
    "we find that the derived properties from mock single - dish observations follow the same behavior as the simulations in  [ compare ] .",
    "thus , it is possible to decouple the two sets of biases  those arising from marginal resolution and sensitivity and those arising from using interferometers  and examine only the latter .",
    "we plot the results for orion because these observations show the most dramatic variation of the three complexes studied , but the results are qualitatively the same for all three data sets .",
    "orion is the most sensitive of the three to spatial filtering because it consists of three gmcs and therefore shows more structure than the other two targets .",
    "based on the results of the mock observations , we make the following comments regarding the use of interferometer data alone in measuring cloud properties .",
    "most of these points can be seen visually in figure [ interf_props ] .    1 .",
    "cloud properties measured from interferometric data are biased .",
    "the degree of bias is affected by the sensitivity of the array as well as the @xmath0 coverage of the observations .",
    "a minimum signal - to - noise of 10 is required for stable recovery of cloud properties .",
    "below this level , errors in cloud properties , can approach 100% for interferometer data .",
    "3 .   even for intermediate signal - to - noise values ( @xmath140 )",
    "there are significant systematic effects on the cloud properties .",
    "the most extreme effects are on the luminosity measurement , which can be 40% lower than a single - dish observation .",
    "this effect is much less pronounced for measurements of the line width and the radius , which show @xmath141 variations .",
    "this result , that the radius and line width are relatively robust to the spatial filtering of the interferometer , confirms the qualitative results of @xcite .",
    "the values of derived properties are always _ underestimated _ relative to single - dish observations .",
    "4 .   even at high sensitivities ,",
    "the spatial filtering of interferometers affects property recovery at the 10% level .",
    "for example , c - array observations of orion systematically underestimate the radius of the cloud by 10% even for very high signal to noise ratios and d - array observations underestimate the flux of the orion by 5% even at high sensitivity .",
    "5 .   for interferometer observations ,",
    "the dynamical mass measurements of gmcs are more robust than the luminosity measurements .",
    "this behavior will bias interpretations of the virial parameter in extragalactic observations .",
    "estimates of the co - to - h@xmath1 conversion factor based on the assumption that gmcs are bound or virialized are likely to _ overestimate _ @xmath123 .",
    "6 .   for a given signal - to - noise value , observations with the widest range of @xmath0 coverage provide the most robust measurement of cloud properties .",
    "thus , in achieving a given sensitivity , observers should favor arrays with more antennae or observations made in multiple configurations .",
    "the choice of how to decompose an emission distribution into individual clouds may be the most important source of bias in gmc property measurements .",
    "many different methods have been applied to identify gmcs in blended emission , the most prevalent being decomposition by eye and the application of the gaussclumps @xcite or the clumpfind algorithm @xcite . when comparing gmcs between two data sets",
    ", care must be taken to decompose emission in a consistent way across both data sets , preferably using the same algorithm on both data sets .",
    "furthermore , the physical values of any tuning parameters in the algorithms should be matched where possible so that both algorithms search for peaks in the emission over the same spatial scale ( rather than angular or resolution - units ) or intensity range .",
    "this will avoid , for example , comparing `` clumps '' in a galactic molecular cloud to gmcs in another galaxy .",
    "a more extreme method to ensure accurate comparison is to convolve the higher ( spatial ) resolution data set to the spatial resolution of the other data ( e.g.   * ? ? ?",
    "* ) . however , this approach clearly sacrifices accuracy of the derived parameters to allow a more careful comparison between two data sets .    in the appendix to this paper",
    "we present a robust , conservative , new decomposition algorithm .",
    "this algorithm is designed to avoid creating spurious clouds from noise and to remain sensitive to non - gaussian structures in the data .",
    "additionally , the parameters of the algorithm are fixed to physical values rather than being determined by the data .",
    "this algorithm is designed explicitly with the goal of decomposing emission into gmcs ( rather than clumps or other structures ) with extragalactic data in mind .",
    "the methods for measurement of cloud properties described above  including the sensitivity and resolution corrections  are independent of the decomposition algorithm and are important no matter what decomposition algorithm is chosen . in order to avoid confusion between these two separate problems , we choose to describe the decomposition algorithm in the appendix .",
    "we conclude the paper by applying these methods to molecular line data sets that have been previously published . in future studies",
    ", the algorithm will be used to evaluate the differences between gmc populations between galaxies . here , we simply present an analysis designed to demonstrate the method s utility .",
    "we present the median corrections found for a large set of extragalactic ( local group ) observations and a test application of our methods to galactic data .",
    "we use all the methods discussed in the previous sections and the decomposition algorithm discussed in the appendix .",
    "we apply the methods outlined here to an array of data from across the local group and measure the properties of 110 spatially resolved clouds to estimate the typical magnitude of the sensitivity and resolution corrections for extragalactic data .",
    "we use bima data on m  33 and m  31 @xcite ; nanten observations of the lmc @xcite ; ovro observations of ic  10 @xcite ; and a sest map of n83 in the smc @xcite .",
    "table [ corrections ] shows the number of clouds measured in each galaxy along with the median sensitivity and resolution corrections applied to the radius , line width , and flux . for comparison",
    ", we also measure the properties of a number of clouds in the outer galaxy ( quadrant 2 , see below ) from the @xcite co survey of the milky way .",
    "table [ corrections ] includes all spatially resolved clouds with masses ( derived from the co luminosity ) of @xmath142 m@xmath143 or more ( @xmath144 of the @xmath145 extragalactic clouds are above this mass ) .    the numbers quoted in table [ corrections ] are `` correction factors , ''    @xmath146    table [ corrections ] shows that throughout the local group data the corrections suggested in this paper have magnitudes of a few tens of percent .",
    "we draw several conclusions based on these data :    1 .",
    "resolution effects on the size of clouds tend to be significant  we would overestimate cloud sizes by @xmath147%  if we did not apply a deconvolution . in the milky way data ,",
    "this effect is much less severe .",
    "the sizes of milky way clouds are measured to within @xmath89 before the resolution correction .",
    "unresolved clouds do not contribute to table [ corrections ] , so if the effects of the resolution bias were completely neglected this would be much larger ( a naive approach would measure these clouds to have the size of the spatial beam ) .",
    "2 .   resolution effects on the line width are negligible throughout the local group data .",
    "sensitivity effects are also significant . without a correction for the sensitivity bias , the size , line width , and luminosity of clouds",
    "would all be significantly underestimated .",
    "this sensitivity bias is least severe  only about 20  30%   for the line width , and most significant ( and variable ) for the luminosity .",
    "sensitivity corrections to the luminosity vary from 20% to more than 100% .",
    "the resolution and sensitivity biases for the size measurement tend to cancel out , so that the completely uncorrected radius measurement is often within 10  20%  of the corrected value .",
    "this is a happy coincidence of resolution and sensitivity within the local group , not evidence that sensitivity and resolution corrections are unimportant .",
    "the magnitude of corrections across the local group data are fairly uniform .",
    "this is because gmcs near the resolution limit tend to outnumber higher mass gmcs .",
    "unresolved gmcs are not included in the analysis , so the median cloud through all the data sets appears marginally resolved .",
    "6 .   in order to compare extragalactic data to galactic data ( with very good sensitivity and resolution and therefore small corrections )",
    "it is crucial to correct for the sensitivity and resolution biases .",
    "l c c c c c c    lmc & 46 & @xmath148 & @xmath149 & @xmath150 & @xmath151 & @xmath152 + m  31 & 28 & @xmath153 & @xmath154 & @xmath155 & @xmath156 & @xmath152 + ic  10 & 17 & @xmath150 & @xmath154 & @xmath157 & @xmath156 & @xmath152 + m  33 & 15 & @xmath148 & @xmath149 & @xmath153 & @xmath156 & @xmath152 + smc & 4 & @xmath158 & @xmath149 & @xmath149 & @xmath156 & @xmath152 + mw & 107 & @xmath158 & @xmath158 & @xmath148 & @xmath152 & @xmath152 +      the method described in this paper has been designed with extragalactic data in mind . however , a crucial step in interpreting extragalactic measurements is to make a fair comparison with galactic data . in this section",
    "we report some results of applying our decomposition and measurement algorithms to the survey of the second galactic quadrant by @xcite .",
    "we compare the results of this analysis to the results by @xcite and show that our analysis recovers results that are consistent with theirs .",
    "we decompose and analyze @xmath2co(@xmath3 ) from the second quadrant ( survey 17 in table 1 of * ? ? ?",
    "the data set covers the galactic plane from @xmath159 to @xmath160 with a noise level of @xmath161 k. we measure the distance to the molecular emission using the kinematic distances by adopting a flat rotation curve with @xmath162  km  s@xmath41 and @xmath163  kpc .",
    "we omit local emission by discarding all elements of the data cube with a kinematic distance less than 2 kpc as well as all elements in the data cube that are connected by significant emission in position or velocity space to such pixels .",
    "we apply the decomposition algorithm described in the appendix and measured sizes , line widths , and luminosities of gmcs using the methods of  [ extrapsect ] and  [ beamdcsect ] .",
    "the analysis recovers 431 clouds with resolved angular sizes and line widths located within 10 kpc of the sun .",
    "we include the median sensitivity and resolution corrections for massive ( @xmath164 m@xmath143 ) clouds in table [ corrections ] above .",
    "do the results from our algorithm agree with previous studies of galactic gmcs ? the data set covers the region studied by @xcite using the @xmath165 resolution of the fcrao 14 m .",
    "that data set has a lower sensitivity than the @xcite data , so we apply a rudimentary sensitivity correction ( assuming that the gmcs are gaussian and using their peak temperature and boundary isosurface ) to their results and scale to @xmath166 before comparing gmc properties .",
    "we focus on a comparison of the virial parameter between the two studies  a full treatment of the galactic `` larson s laws '' is beyond the scope of this paper .",
    "we draw several conclusions from the comparison :    1 .",
    "figure [ virparams ] shows that the virial parameters derived in our analysis largely agree with those found by @xcite .",
    "below masses of @xmath167 m@xmath143 , both surveys find the same virial parameter in a given mass bin .",
    "2 .   above @xmath167 m@xmath143",
    ", our analysis of the @xcite data set may yield a slightly higher virial parameter , on average .",
    "this may be evidence for the diffuse emission mentioned in  [ extrapsect ]  the higher sensitivity @xcite data may include diffuse emission surrounding the gmcs while the @xcite data may miss this effect .",
    "it may also reflect inadequacies in the simple sensitivity correction we apply to the @xcite data .",
    "resolution effects may also play a role  the @xcite data set has @xmath168 times better resolution than the @xcite data and so the lower resolution data may tend to lump unbound clouds together .",
    "the number of clouds in the high mass bins is relatively low , so the discrepancy may not be particularly significant .",
    "3 .   we apply our algorithm to a small portion of the ogs data and find our corrections for resolution and sensitivity bias increase the mean virial parameter to be consistent with the results from the @xcite data .",
    "this suggests that the differences in the virial parameters for the high mass clouds in figure [ virparams ] may simply be methodological .",
    "both catalogs of outer galaxy clouds find an inverse relationship between luminous mass and the virial parameter , approximately @xmath169  a relationship that was also observed by @xcite for inner galaxy molecular clouds .",
    "thus we find agreement with the results of previous studies of galactic molecular clouds .",
    "our methods applied to galactic data find the same behavior observed in earlier work and we find agreement among the method applied to several data sets .",
    "we have presented a method for measuring macroscopic gmc properties  spatial size , line width , and luminosity  from a region of emission in a spectral line data cube .",
    "this method corrects for biases from limited sensitivity and resolution and produces reliable results that are directly comparable among a wide variety of data sets .",
    "we correct for limited sensitivity via an extrapolation to a theoretical 0 kelvin isosurface .",
    "we apply a simple quadratic deconvolution to the extrapolated values to account for resolution biases .",
    "we find that bootstrapping methods yield believable estimates of the uncertainties in the derived parameters .",
    "we present a set of suggestions for transforming the derived properties into physical quantities of interest . in the appendix to this paper",
    "we present a new method for decomposing emission into individual gmcs .",
    "this method is conservative and robust , designed to produce robust results from low resolution / sensitivity data . in this section",
    "we have applied all of these methods to an array of extragalactic ( local group ) and galactic data .",
    "we find that the algorithm reproduces established results for galactic gmcs and that the sensitivity and resolution biases are potentially significant  often @xmath170  for even the most recent local group gmc measurements .    based on this investigation of the observational biases in measuring molecular cloud properties , we note several important points that should be considered in planning observations of gmcs and interpreting the results .",
    "first , resolution and sensitivity biases can be corrected to @xmath171 error provided the cloud has a modest peak signal - to - noise ( @xmath172 ) and is marginally resolved @xmath173 , where @xmath174 is the full width at half maximum extent of the beam .",
    "given current and future telescope capabilities , even the properties of extragalactic gmcs can be accurately measured . from figure [ distcomp ] , we can see that single dish surveys can accurately study clouds more massive than @xmath175 in the magellanic clouds and careful interferometer observations can recover cloud properties for clouds with mass @xmath176 in m31 and m33 .",
    "however , interferometer observations systematically underestimate molecular cloud properties .",
    "all else being equal , interferometers can underestimate fluxes by 40% and cloud radii by 10% relative to single - dish observations .",
    "line widths are largely unaffected by interferometer observations .",
    "the magnitude of the systematic bias depends on the array configuration and the sensitivity of the observations . in general , wider coverage of the @xmath0 plane produces better property recovery . to minimize bias",
    ", observers should favor observations from several array configurations or from arrays with many elements .",
    "if possible , the interferometer data should be supplemented with single - dish observations .",
    "finally , the decomposition algorithm used to separate emission into physically relevant structures will systematically affect molecular cloud properties .",
    "to date , there is no algorithm that should be favored in all circumstances , but any comparative study of gmc properties should be consistent in the choice of algorithm .",
    "for example , the results of a clumpfind algorithm applied to an extragalactic data set are not directly comparable to a catalog produced by a simple contouring method applied to milky way data . provided the same algorithm is used across multiple data sets , referencing algorithm parameters to a common physical scale will minimize systematic differences .",
    "we will make a software version of the decomposition and measurement algorithm available as an idl package .",
    "further , since methodology can affect the results of gmc studies so strongly , we encourage authors working in the field to make their data available to the community after publication in order to facilitate future rigorous comparisons .",
    "we are extremely grateful to tom dame and the millimeter - wave group at the center for astrophysics for providing both the orion data and the quadrant 2 data used in the paper .",
    "we also thank the nanten group at nagoya , especially yasuo fukui and akiko kawamura , providing us with the lmc co data .",
    "we are grateful to fabian walter for providing us with the ovro ic  10 data .",
    "alberto bolatto , jason wright , jon swift , and leo blitz all offered helpful comments on drafts of the paper .",
    "we thank ronak shah for helping us compare our idl version of gaussclumps to the original implementation of the algorithm .",
    "the informed comments of an anonymous referee greatly improved the paper , particularly in encouraging us to explore the effects of interferometers .",
    "er is grateful for support through the national science foundation astronomy & astrophysics postdoctoral fellows program ( ast-0502605 ) .",
    "this work is partially supported by nsf grant 0228963 to the radio astronomy laboratory at uc berkeley .",
    "12 natexlab#1#1    bertoldi , f. , & mckee , c.  f.  1992 , , 395 , 140    blitz , l.  1985 , , 296 , 481    , l. & stark , a.  a. 1986 , , 300 , l89    blitz , l. , & thaddeus , p.  1980",
    ", , 241 , 676    bolatto , a.  d. , leroy , a. , israel , f.  p. , & jackson , j.  m.  2003 , , 595 , 167    , c.  m. , kerton , c.  r. , & pomerleau , c. 2003 , , 144 , 47    , t.  m. , elmegreen , b.  g. , cohen , r.  s. , & thaddeus , p. 1986",
    ", , 305 , 892    dame , t.  m. , hartmann , d. , & thaddeus , p.  2001",
    ", , 547 , 792    fukui , y. , et al .  1999 , , 51 , 745    helfer , t.  t. , vogel , s.  n. , lugten , j.  b. , & teuben , p.  j.  2002 , , 114 , 350    heyer , m.  h. , brunt , c. , snell , r.  l. , howe , j.  e. , schloerb , f.  p. , & carpenter , j.  m.  1998 , , 115 , 241    , m.  h. , carpenter , j.  m. , & snell , r.  l. 2001 , , 551 , 852    israel , f.  p. , et al .",
    "1993 , , 276 , 25    koda , j. , sawada , t. , hasegawa , t. , & scoville , n.  2005 , , in press .    , c. , stutzki , j. , rohrig , r. , & corneliussen , u. 1998 , , 329 , 249    leroy , a. , bolatto , a. , walter , f. , & blitz , l.  2005 , in preparation    lin , g. , adiga , u. , olson , k. , guzowski , j. , barnes , c. , & roysam , b. 2003 , cytometry a , 56 , 23    , c.  f. & zweibel , e.  g. 1992 , , 399 , 551    polk , k.  s. , knapp , g.  r. , stark , a.  a. , & wilson , r.  w.  1988 , , 332 , 432    rosolowsky , e. , engargiola , g. , plambeck , r. , & blitz , l.  2003 , , 599 , 258    rosolowsky , e. , , submitted .    , d.  b. , scoville , n.  z. , & solomon , p.  m. 1985 , , 289 , 373    sanders , d.  b. , clemens , d.  p. , scoville , n.  z. , & solomon , p.  m.  1986 , , 60 , 1    , r.  j. , teuben , p.  j. , & wright , m.  c.  h. 1995 , in asp conf . ser .",
    "77 : astronomical data analysis software and systems iv , 433+    sheth , k. , vogel , s.  n. , wilson , c.  d. , & dame , t.  m.  2000 , proceedings 232 .",
    "we - heraeus seminar , 37    , p.  m. , rivolo , a.  r. , barrett , j. , & yahil , a. 1987 , , 319 , 730    , j. & gsten , r. 1990 , , 356 , 513    scoville , n.  z. , yun , m.  s. , sanders , d.  b. , clemens , d.  p. , & waller , w.  h.  1987 , , 63 , 821    taylor , c.  l. , httemeister , s. , klein , u. , & greve , a.  1999 , , 349 , 424    thompson , a.  r. , moran , j.  m. , & swenson , g.  w.  2001 , interferometry and synthesis in radio astronomy by a.  richard thompson , james m.  moran , and george w.  swenson , jr .",
    "2nd ed .",
    "new york : wiley , c2001.xxiii , 692 p.  : ill .  ; 25 cm .",
    "`` a wiley - interscience publication . '' includes bibliographical references and indexes .",
    "isbn : 0471254924 ,    vogel , s.  n. , boulanger , f. , & ball , r.  1987 , , 321 , l145    , f. 2005 , in preparation    , j.  p. , de geus , e.  j. , & blitz , l. 1994 , , 428 , 693    wilson , b.  a. , dame , t.  m. , masheder , m.  r.  w. , & thaddeus , p.  2005",
    ", , 430 , 523    , c.  d. & scoville , n. 1990 , , 363 , 435    wilson , c.  d. , & reid , i.  n.1991 , , 366 , l11    wilson , c.  d. , & rudolph , a.  l.  1993 , , 406 , 477    wright , m.  c.  h.  1998 , bima memorandum series , 69    [ ouralg ]",
    "the choice of what emission to identify as a gmc may be the single largest source of uncertainty in measuring and comparing gmc properties .",
    "a number of methods have been employed over the years , from simple contouring methods ( e.g.   * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) to fitting three - dimensional gaussians ( gaussclumps , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , to modified watershed algorithms ( clumpfind and its kin , * ? ? ?",
    "* ; * ? ? ?",
    "in this section we present a new decomposition algorithm that is designed to identify clouds at low sensitivities while avoiding the introduction of a false clouds due to noise .",
    "this algorithm consists of two parts : identifying regions of significant emission in the data set and then assigning this emission to individual `` clouds . ''",
    "we first identify regions of contiguous , significant emission in our position - position - velocity data cube .",
    "we estimate the noise in the data set by measuring the rms intensity , @xmath76 , from a signal - free region of the data cube .",
    "we then construct a high - significance mask .",
    "this mask includes only adjacent channels that both have intensities above @xmath177 .",
    "we expand that mask to include all emission above a lower threshold  typically two channels above @xmath178 significance  that is connected to the original high significance mask through pixels with @xmath179 significance .",
    "the resulting mask contains most of the significant emission in the data cube . lowering the threshold below two channels at @xmath180 runs the risk of biasing the moment measurements towards high values by including false emission ( noise with positive values ) in the cloud .      in this section",
    ", we describe the algorithm used to decompose a region of emission into individual subsections representing the physically distinct entities in the data ( `` clouds '' ) . through the description of the algorithm",
    ", there are several parameters that can be varied to produce changes in the resulting decomposition . in general , we set these parameters using physical prior knowledge of the gmcs we are seeking to catalog .",
    "we discuss the choice of these parameters in the following section .    1 .",
    "_ discard small or low contrast regions : _ if a region is too small for us to measure meaningful properties from it , we discard the region .",
    "we require that each region has an area larger than two beam sizes , so that we can measure its size ; and a velocity width of more than a single channel , so that we can measure its line width .",
    "if the intensity contrast between the peak and the edge of the region is less than a factor of two , we lack the dynamic range needed to correct the sensitivity bias and we therefore discard the region .",
    "if a region is not discarded we proceed to the next step .",
    "[ xform]_rescale the data to reduce the effects of substructure : _ molecular clouds contain significant substructure that confuses the decomposition of these sources .",
    "the substructure is often significantly brighter than bulk of the gas in the cloud .",
    "we rescale the data to reduce the contrast between this substructure and the cloud as a whole .",
    "the data are rescaled using the following transform : @xmath181 & ; ~ t\\ge t_{clip}. \\\\ \\end{array } \\right.\\ ] ] this transform reduces the contrast pixels with @xmath182 while preserving the relative brightness distribution .",
    "the value of @xmath183 is left as a free parameter .",
    "the transformed data are used in the decomposition algorithm .",
    "such brightness transforms are frequently used in the decomposition algorithms used in other fields such as medical imaging ( e.g.   * ? ? ?",
    "3 .   _ identify independent local maxima : _ we identify potential local maxima , by identifying the elements in the data cube that are larger than all their neighbors .",
    "we consider neighbors to be all data that lie within a box with side length @xmath184 in position and @xmath185 in velocity centered on the local maximum .",
    "these are our `` candidate maxima . ''",
    "the parameters @xmath184 and @xmath186 are free parameters . if we find more than one candidate maximum in a region of emission , we proceed to the next steps to further verify each maximum s independence .",
    "if we find a single candidate maximum then we label the region as a cloud and measure its properties as described in the main paper.[locmax ] 4 .",
    "_ find shared isosurfaces and reject small clouds or those with smooth mergers : _ for each _ pair _ of candidate maxima we calculate the value of the highest intensity isosurface to contain both maxima .",
    "we refer to this highest shared isosurface as the _ merge level_. using this set of highest shared isosurfaces , we calculate three properties of interest : 1 .",
    "the area uniquely associated with each maximum ( i.e. the area above the merge level for that maximum ) .",
    "the antenna temperature interval between the merge level and each maximum , referred to as the _ contrast interval_. [ decimate ] 3 .",
    "the fractional amount by which each of the ( unextrapolated ) moment values changes across each shared isosurface ( i.e. @xmath187 for each maximum across each shared isosurface ) .",
    "we consider the two clouds to merge smoothly across the isosurface only if : 1 .",
    "none of the second moments increase by more than 100% for both maxima .",
    "2 .   no two of the second moments increase by more than 50% for both maxima .",
    "the flux increases by less 200% for both maxima .",
    "+ we use these three properties to pare maxima from the region .",
    "we reject maxima associated with small areas ( less than two beam sizes , as for the region above ) and contrast intervals less than @xmath188 , a free parameter . choosing @xmath189",
    "significantly reduces the effects of noise on decomposition ( e.g.   * ? ? ?",
    "* ) since noise is associated with low contrast intervals .",
    "finally , when a pair of maxima merge smoothly across a shared isosurface , we keep the higher intensity maximum and discard the lower one .",
    "this is a conservative choice in the decomposition algorithm : unless merging the two kernels significantly alters the properties of one of the clouds associated with the separate kernels , we assume the kernels are not physically distinct .",
    "the effect of removing kernels that merge smoothly from our data set is to reduce the algorithm s sensitivity to substructure within clouds .",
    "we iterate this step until we have a set of maxima associated with the required areas and separated from each other by significant jumps in their properties . 5 .",
    "_ define clouds using shared isosurfaces : _ the surviving maxima each correspond to a `` cloud . ''",
    "that cloud consists of the emission within the lowest intensity isosurface uniquely associated with the cloud .",
    "emission that lies below this isosurface is part of a `` watershed '' shared among clouds and we do not assign it to any cloud . by not considering contested emission , i.e.  emission that could be associated with distinct local maxima , we avoid the problem of how to properly assign this emission to local maxima .",
    "measure cloud properties : _ finally , we apply the methods described in  2 and 3 to derive spatial sizes , line widths , and luminosities for each cloud .",
    "the transformed data ( step [ xform ] ) are inverse transformed into the original brightness units for this analysis .",
    "several of the algorithm s parameters are left to the choice of the user . without any prior knowledge of the physical objects in the data , we establish default values for these parameters that will produce a reasonable decomposition based solely on the characteristics of the data .",
    "these defaults are chosen to provide sensitivity to real substructure within the data without contamination by noise and can be regarded as the _ minimum _ appropriate values for these parameters in most cases .",
    "the free parameters in the algorithm are the brightness transform threshold ( @xmath183 , step [ xform ] ) position and velocity window size used in searching for local maxima ( @xmath184 and @xmath185 , step [ locmax ] ) , and the minimum contrast temperature ( @xmath190 , step [ decimate ] ) . without prior knowledge of substructure in the data ,",
    "no brightness transform should be applied ( @xmath191 ) .",
    "the minimum values for the parameters in the search for initial local maxima are set by the resolution of the data : @xmath192 and @xmath193 or else separations between local maxima can not be resolved .",
    "finally , we use @xmath194 to prevent the noise in the data set from being recognized by the algorithm as legitimate structure and becoming the basis for the decomposition .",
    "in the main section of the paper , we developed methods that measured physical properties of molecular emission without observational bias .",
    "ideally , the decomposition algorithm used in the analysis would also be free of observational bias .",
    "a good algorithm would , for example , decompose the same emission into similar structures regardless of the resolution and sensitivity of the observations .",
    "to progress towards this goal , we set the parameters of the decomposition algorithm to have similar values in physical units ( pc , km s@xmath41 , k ) rather than data units ( beam widths , channels , @xmath76 ) .    in the molecular ism , which has structure on a range of scales , the choice of the physical values for the algorithm parameters must be motivated by prior knowledge of the objects that we wish to identify . the choice of parameters for identifying gmcs would be different from the choice of parameters for identifying clumps and cores . as a population ,",
    "gmcs have size scales of 10s of parsecs , line widths of several km s@xmath41 , and brightness temperatures of @xmath195  k ( e.g.   * ? ? ?",
    "in contrast , the clumpy substructure within clouds has a size scale of 1 pc , line widths of order 1 km s@xmath41 and can have brightness temperatures of 30 k or higher ( e.g.   * ? ? ?",
    "we select the parameters of the algorithm to find molecular clouds rather than the clumps within them .",
    "in particular , we set the minimum separation between local maxima as @xmath196  pc and the velocity separation to be @xmath197  km s@xmath41 .",
    "we also fix a contrast interval in antenna temperature of @xmath198  k rather than the data - driven value of @xmath199 . finally , we must account for the presence of bright molecular gas substructure within molecular clouds .",
    "for example , orion a has a few distinct regions separated by @xmath200 pc with antenna temperatures in excess of 15 k @xcite .",
    "these are associated with hot molecular gas around young stars like the trapezium cluster . in general , the typical kinetic temperature of gas in gmcs is @xmath201  k so brightness temperatures in excess of 10 k are usually associated with structure _ within _ molecular clouds not changes from cloud to cloud .",
    "hence , to catalog clouds and not substructure , we must reduce the influence of the high @xmath202 data with the parameter @xmath183 .",
    "we use @xmath203  k to maintain the full sensitivity for the gas separating gmcs ( which typically has @xmath204  k in the @xcite data ) while reducing the influence of brighter gas associated with a single gmc . using @xmath205",
    "k has little influence on extragalactic data where beam deconvolution typically averages out the presence of bright substructure within the clouds .",
    "we summarize our choices of parameters in table [ params ] when the parameters are motivated by the data ( data - based ) or by physical assumptions about the structures being extracted ( gmc physical priors ) .",
    "the resolution or the sensitivity of a data set may be sufficiently poor that the physical parameters are unattainable in the data set ( e.g.  @xmath206pc , @xmath207  k ) . in this case , the decomposition must be regarded with caution as it may not be directly comparable to other data sets .",
    "the adopted values are appropriate for decomposing data sets of @xmath2co emission .",
    "the values of @xmath183 and @xmath190 would be different for other tracers .        to demonstrate that the proposed algorithm is actually an improvement on existing methods , we analyze trial data sets with known properties using this algorithm and compare the results to those from the gaussclumps and clumpfind algorithms to the trial data .",
    "we use the clfind algorithm implemented in miriad @xcite and our own idl implementation of the @xcite gaussclumps algorithm , which we have compared to the standard algorithm operating on a real data set with satisfactory results .",
    "we first examine how adept the three algorithms are at decomposing a pair of blended clouds .",
    "we construct a series of data cubes with two unresolved model clouds separated in position by a variable distance .",
    "the model clouds each have a peak signal - to - noise ratio of 10 with a gaussian line profile . for each value of the separation",
    ", we decompose 100 data cubes with different realizations of the noise using the three algorithms , using data based choices for the algorithm parameters .",
    "figure [ nclplot ] ( left ) shows the mean number of clouds recovered by each algorithm as a function of the separation ( we count clouds with peak signal - to - noise larger than 5 as `` recovered '' ) . as the trial clouds are moved farther apart , the typical number of clouds detected by each algorithm increases by 1 .",
    "however , only the algorithm presented here consistently recovers a single cloud at low separations .",
    "gaussclumps and clumpfind produce false clouds from the noise .",
    "the jump in the number of clouds detected by the gaussclumps algorithm occurs where the separation equals the resolution , whereas both the current algorithm and clumpfind are able to distinguish the clouds only if their separation is over 1.5 times the resolution .",
    "gaussclumps appears to be able to distinguish tight blends of clouds but is the most susceptible to noise .    as a second test of the algorithms",
    ", we compared the number of clouds that the algorithms recover from a single cloud with a circular top - hat brightness profile ( @xmath209 otherwise ) and peak signal - to - noise of 10 .",
    "the size of the cloud is varied with respect to the resolution of the data set and 100 data sets for each value of @xmath210 are decomposed by each algorithm .",
    "the non - gaussian brightness profile confounds all of the algorithms but to varying degrees .",
    "clumpfind detects an increasing number of spurious clouds as the cloud grows , suggesting that the number of false clouds grows with the volume studied . despite the non - gaussian profile",
    ", gaussclumps does surprisingly well with large sources . the current algorithm , however , does the best job of detecting a single source in the presence of noise . for analyzing data with a relatively low signal - to - noise",
    ", we find the decomposition algorithm presented in this appendix should be favored for identifying clouds .",
    "the orion molecular cloud is among the best studied of all gmcs , so it is an good place to compare the results of our methods to those of previous work . for this comparison ,",
    "we use the data and results of the recent , uniform survey of the entire orion - monoceros region by @xcite .",
    "we analyze their final data set using the methods in this paper ( with physical priors for the decomposition algorithm parameters ) and summarize the results in figure [ orion_fig ] , an integrated intensity map of the region . the decomposition results in 81 molecular clouds , most of which are associated with the galactic plane at the top of the figure .",
    "the results of the algorithms decomposition of the region are good : major molecular clouds are identified as single entities in the decomposition .",
    "the algorithm succeeds where other cloud identification schemes would face difficulty .",
    "nearly all of the emission in the data is connected above a single isosurface so that simple contouring methods would identify the entire orion - monoceros region as a single molecular cloud , though more complicated algorithms @xcite may succeed .",
    "clumpfind and gaussclumps would isolate individual peaks and decompose clouds into their substructure  as was intended by their design ( clumpfind identifies 617 clumps in the same data ) .",
    "the properties of the clouds agree well with the values published for a human decomposition of the emission .",
    "the results of the analysis are given in table [ orion_props ] .",
    "for comparison , we adopt the distances of @xcite .",
    "we compare the results of the algorithm to their results , after scaling their mass up by 10% to account for a difference in the adopted co - to - h@xmath1 conversion factors . in several cases",
    "the masses agree quite well ( to within 5% , orion a , mon r2 , scissors ) , while other features show @xmath211 differences .",
    "these systematic discrepancies arise from differences in how emission is assigned into structures .",
    "for example , the algorithm only identifies the central region of orion b as a molecular cloud ; it does not include emission near the location of orion east that is nominally part of the orion b cloud because the assignment of this emission is contested with neighboring clouds .",
    "similarly , the algorithm characterizes the northern filament region as five distinct clouds rather than the single large cloud that a human decomposition produced . despite these differences ,",
    "the results of the algorithm are reassuring  in most cases , the well - known molecular clouds are identified as single clouds and there is good agreement between their derived physical properties and the results of previous studies .",
    "lcccccc orion a & 480 & 12 . &",
    "@xmath212 & @xmath213 & @xmath214 & @xmath215 + orion b & 500 & 9.1 & @xmath216 & @xmath217 & @xmath218 & @xmath219 + orion east & 120 & 0.013 & @xmath220 & @xmath221 & & + mon r2 & 800 & 12 . & @xmath222 & @xmath223 & @xmath224 & @xmath225 + crossbones & 470 & 1.9 & @xmath226 & @xmath227 & @xmath228 & @xmath229 + northern filament & 390 & 1.9 & @xmath230 & @xmath231 & @xmath232 & @xmath233 +      as a final test of the decomposition and analysis algorithm , we apply the algorithm to simulated observations of the orion - monoceros region with beam sizes and signal - to - noise values typical of extragalactic gmc observations .",
    "we simulate observations by convolving the data set to the desired resolution and adding a convolved data cube of noise which is scaled up to give the desired peak signal - to - noise ratio in the data .",
    "we perform this for a peak signal - to - noise ( @xmath234 ) values of 10 and 30 combined with beam sizes of 10 , 20 and 50 pc .",
    "the results of the decompositions are displayed in figure [ decompdemo ] .    at coarse resolution and low sensitivity",
    ", the fainter clouds are undetectable .",
    "however , the algorithm identifies each of orion a , orion b , mon r2 and the northern filament in at least one of the trial data sets . at high resolution",
    "( 10 pc ) and peak signal - to - noise ( @xmath235 ) , the algorithm successfully identifies the clouds with properties that are consistent , within the uncertainties determined by the algorithm , with the masses of the clouds in table [ orion_props ] .",
    "the systematic effects of poor resolution manifest themselves for beam sizes @xmath236 pc where the decomposition of blended emission results in @xmath237 variations in the properties of the clouds relative to those found in the original data set for both high and low @xmath234 . for a beam size of 20 pc ,",
    "the clouds are not resolved since this is over twice the size of the clouds along their minor axes .",
    "finally , at 50 pc resolution , mon r2 is not found by the algorithm and high @xmath234 is required to distinguish orion a and orion b. there is a variation of 100% ( 0.3 dex ) in the derived physical parameters for the clouds ; this variation is reflected in the estimates of the uncertainties . as expected based on the 20 pc resolution data ,",
    "the clouds are not spatially resolved for a beam size of 50 pc .",
    "an accurate decomposition of emission into typical galactic gmcs requires a beam size @xmath238 pc though only a modest sensitivity is required : @xmath239 ."
  ],
  "abstract_text": [
    "<S> we review methods for measuring the sizes , line widths , and luminosities of giant molecular clouds ( gmcs ) in molecular - line data cubes with low resolution and sensitivity . </S>",
    "<S> we find that moment methods are robust and sensitive  making full use of both position and intensity information  and we recommend a standard method to measure the position angle , major and minor axis sizes , line width , and luminosity using moment methods . without corrections for the effects of beam convolution and sensitivity to gmc properties , the resulting properties may be severely biased . </S>",
    "<S> this is particularly true for extragalactic observations , where resolution and sensitivity effects often bias measured values by 40% or more . </S>",
    "<S> we correct for finite spatial and spectral resolutions with a simple deconvolution and we correct for sensitivity biases by extrapolating properties of a gmc to those we would expect to measure with perfect sensitivity ( i.e.  the 0  k isosurface ) . </S>",
    "<S> the resulting method recovers the properties of a gmc to within 10% over a large range of resolutions and sensitivities , provided the clouds are marginally resolved with a peak signal - to - noise ratio greater than 10 . </S>",
    "<S> we note that interferometers systematically underestimate cloud properties , particularly the flux from a cloud . </S>",
    "<S> the degree of bias depends on the sensitivity of the observations and the @xmath0 coverage of the observations . in the appendix to the paper we present a conservative , new decomposition algorithm for identifying gmcs in molecular - line observations </S>",
    "<S> this algorithm treats the data in physical rather than observational units ( i.e.  parsecs rather than beams or arcseconds ) , does not produce spurious clouds in the presence of noise , and is sensitive to a range of morphologies . as a result , the output of this decomposition should be directly comparable among disparate data sets . </S>"
  ]
}