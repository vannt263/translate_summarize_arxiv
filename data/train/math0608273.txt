{
  "article_text": [
    "this paper is a sequel of our earlier papers @xcite .",
    "we assume that the reader is familiar with those papers ; however , we repeat the most important definitions .    for two finite sets , @xmath0 and @xmath1 ,",
    "let us be given a @xmath1-valued random variable @xmath2 for every @xmath3 .",
    "we call the vector of random variables @xmath4 a _ random function _ @xmath5 .",
    "ordinary functions are specific instances of random functions .    given another random function , @xmath6 , from @xmath1 to @xmath7 , we can speak about the composition of @xmath6 and @xmath8 , @xmath9 , which is the vector variable @xmath10 . in this paper",
    "we are concerned with inverting random functions . in other words",
    ", we look for random functions @xmath11 in order to obtain the best approximations of the identity function @xmath12 by @xmath13 .",
    "we always assume that @xmath8 and @xmath14 are independent .",
    "_ this assumption holds for free if either @xmath8 or @xmath14 is a deterministic function .",
    "consider the probability of returning @xmath15 from @xmath15 by the composition of two random functions , that is , @xmath16 $ ] .",
    "the assumption on the independence of @xmath8 and @xmath6 immediately implies @xmath17\\cdot { { \\mathbb p}}[\\gamma_u = a].\\ ] ] a natural criterion is to find @xmath6 for a given @xmath8 in order to maximize @xmath18 .",
    "more generally , we may have a weight function @xmath19 and we may wish to maximize @xmath20",
    ". this can happen if we give preference to returning certain @xmath15 s , or , if we have a prior probability distribution on @xmath0 and we want to maximize the expected return probability for a random element of @xmath0 selected according to the prior distribution .",
    "the following random function @xmath21 , defined below , will do this job : for any fixed @xmath22 , @xmath23w(a^*)\\geq { { \\mathbb p}}[\\xi_{a}=u]w(a).\\ ] ] ( in case there is more than one element @xmath24 that satisfies ( [ mlenonpar ] ) , we may select uniformly at random from the set of such elements . )",
    "this function @xmath25 is called the _ maximum a posteriori estimator _ ( map ) in the literature @xcite . the special case when the weight function @xmath26 is constant , is known as the _ maximum likelihood estimation _ ( mle ) @xcite .",
    "for @xmath27 , @xmath28 , let @xmath29-{{\\mathbb p}}[\\xi_b = u ] \\biggl\\vert,\\ ] ] which is called the _ variational distance _ of the random variables @xmath2 and @xmath30 .",
    "a given @xmath31 will have an @xmath32 _ associated matrix _",
    "@xmath33 , such that @xmath34 $ ] . given a @xmath35 with associated matrix @xmath36",
    ", the composition of @xmath6 and @xmath8 , @xmath9 , will have the associated matrix @xmath37 .",
    "our motivation for the study of random functions came from phylogeny reconstruction @xcite .",
    "stochastic models define how biomolecular sequences are generated at the leaves of a binary tree .",
    "if all possible binary trees on @xmath38 leaves come equipped with a model for generating biomolecular sequences of length @xmath39 , then we have a random function from the set of binary trees with @xmath38 leaves to the ordered @xmath38-tuples of biomolecular sequences of length @xmath39 .",
    "_ phylogeny reconstruction _ can be viewed as a random function from the set of ordered @xmath38-tuples of biomolecular sequences of length @xmath39 to the set of binary trees with @xmath38 leaves .",
    "it is a natural assumption that random mutations in the past are independent from any random choices in the phylogeny reconstruction algorithm .",
    "criteria for phylogeny reconstruction may differ according to what one wishes to optimize .",
    "however , in the practice of phylogeny reconstruction there are no fixed , preconceived models on the possible trees ; instead , we also try to find out the model parameters .",
    "our paper @xcite introduced a new abstract model for phylogeny reconstruction : inverting parametric random functions .",
    "most of the work done on the mathematics of phylogeny reconstruction can be discussed in this context .",
    "this model is more structured than random functions , and hence is better suited to describe details of models of phylogeny and the evolution of biomolecular sequences .",
    "assume that for a finite set @xmath0 , for every @xmath3 , an ( arbitrary , finite or infinite ) set @xmath40 is assigned , and moreover , @xmath41 for @xmath42 . set @xmath43 and let @xmath44 denote the natural projection from @xmath45 to @xmath0 .",
    "parametric random function _ is the collection @xmath8 of random variables such that    for @xmath3 and @xmath46 , there is a ( unique ) @xmath1-valued random variable @xmath47 in @xmath8 .",
    "[ hybridfig ]    [ overview ]    we are interested in random functions @xmath48 independent from @xmath8 so that @xmath49 best approximates @xmath44 under certain criteria .",
    "call @xmath50 the probability @xmath51 $ ] .",
    "maximum likelihood estimation , as it is used in situations where there is a discrete parameter of interest to estimate , in the presence of other parameters ( such as phylogeny reconstruction ) , would take the @xmath52 , for which for every fixed @xmath53 , @xmath54 for sure , if @xmath55\\geq { { \\mathbb p}}[\\xi_{(a,\\theta)}=u].\\ ] ] in case there is more than one element @xmath56 that satisfies ( [ mlepara ] ) , we may select uniformly at random from the set of such elements .",
    "( we avoided using the more natural looking quantification @xmath57 , since @xmath58 $ ] may not take a maximum value ! ) we denote by @xmath59 the probability that from the pair @xmath60 the maximum likelihood estimation @xmath52 returns @xmath15 , i.e. @xmath61.\\ ] ]    if a random function @xmath5 ( @xmath62 ) is to have @xmath39 independent evaluation , we denote the resulting random function by @xmath63 ( @xmath64 ) , and the random variable associated with @xmath15 will be @xmath65 .",
    "we will study the invertibility of @xmath66 both in the non - parametric and the parametric setting . for a @xmath67 random function",
    ", we use the notation @xmath68 $ ] in the non - parametric case , @xmath69 $ ] in the parametric case , and @xmath70'_{(a,\\theta)}$ ] , if @xmath52 is the maximum likelihood estimation .    in section",
    "[ two ] we will show that in the non - parametric setting several natural definitions of invertibility of a random function are , in fact , equivalent . furthermore , we determine when composition of invertible random functions is invertible .",
    "the main result of this section is an explicit bound on how invertibility `` improves '' as the variational distances between elements of @xmath0 have increasing separation from zero .    in section  [ three ] we revisit our study of the worst - case behavior of mle in @xcite .",
    "( this is a very natural question in situations where a prior distribution is not given on @xmath0 , or the inverting of the random function is to be carried out only once .",
    "such a situation arises in phylogeny reconstruction , where , arguably , we do not have a prior distribution on alternative evolutionary scenarios , and the reconstruction is not going to be repeated  there is only one ` tree of life ' that we want to know . ) a certain amount of controversy and debate has surrounded the statistical consistency of mle in phylogeny , as described in @xcite , pp .",
    "felsenstein s claim ( from the early 1970s ) of the consistency of mle in phylogeny for simple ( ` identifyable ' ) models is correct , but it was only formally established in 1996 by @xcite .",
    "this result , like wald s earlier result @xcite , relies on a compactness argument , continuity , and limit theory , that does not give an explicit bound on @xmath39 .",
    "other proofs in the biological literature have generally been less rigorous and led to criticism and debate ( see eg .",
    "one oversight has been to treat the mle - estimated continuous parameters ( branch lengths ) of alternative trees as fix ed rather than as random variables dependent on the data ; such arguments are satisfying for practical purposes but call for more rigor .",
    "the significance of theorem 5.1 @xcite is that it gives the first explicit bounds for mle , both in the phylogenetic setting and beyond .",
    "however , this result depended on an unnatural parameter , namely the smallest positive probability that an image of the object to be reconstructed can have . here in theorem  [ mainpara ]",
    "we get rid of this dependence , and provide a simple and immediate application of this new result to phylogeny reconstruction .",
    "we study two examples that show how subtle is mle for inverting parametric random functions .",
    "the first example shows that theorem  [ mainpara ] is `` near optimal '' in one of its parameters .",
    "the second example shows that in contrast to the non - parametric setting , the vanishing of variational distance does not by itself preclude mle ( or other ) estimation for certain random functions .",
    "our approach is information - theoretic , we focus on the possibility or impossibility of inverting random functions , and not on the computational complexity issues .",
    "our results can also be re - stated in the language of decision theory , by talking about ` loss functions ' and ` risk function ' associated to the decision rule .",
    "let us say that a random function @xmath71 is _ invertible _ if there exists a random function @xmath72 such that for all @xmath73 , @xmath74 $ ] takes strict maximum when @xmath75 , or equivalently , @xmath76 - \\max_{x \\neq a } \\{{{\\mathbb p}}[\\gamma_{\\xi_a } = x]\\ } > 0 \\mbox { for all   $ a \\in a$}.\\ ] ] informally , @xmath8 is invertible , if there is some reconstruction method that is always more likely to pick the generating object in @xmath0 than any other element of @xmath0 .",
    "a sufficient condition for @xmath8 to be invertible is that there exists a @xmath6 so that for all @xmath73 , the following two conditions apply :    * @xmath77 > \\frac{1}{|a|},$ ] * @xmath78 < \\frac{1}{|a| } , \\mbox { for all } b \\neq a.$ ]    note that invertibility implies ( @xmath79 ) , and is equivalent to it when @xmath80 , but not equivalent for @xmath81 .",
    "we say @xmath8 _ separates _",
    "@xmath0 , if , for each distinct pair @xmath82 , the variational distance @xmath83 of the probability distributions of @xmath2 and @xmath30 is strictly positive .",
    "[ main1 ] the following properties are equivalent for an @xmath84 random function :    * @xmath8 separates @xmath0 * for all @xmath85 there is a value of @xmath86 so that for all @xmath87 there is a random function @xmath88 for which @xmath89 > 1-\\epsilon$ ] . *",
    "@xmath8 is invertible * for some @xmath90 , @xmath66 is invertible .",
    "the equivalence between ( i ) and ( ii ) follows easily from results in our earlier papers @xcite and @xcite and standard arguments .",
    "we will show that ( iv ) @xmath91 ( ii ) and that ( i ) @xmath91 ( iii ) .",
    "since ( iii ) @xmath91 ( iv ) is trivial this will establish the claimed four - way equivalence .",
    "_ proof of ( iv ) @xmath91 ( ii ) _ suppose that @xmath66 is invertible .",
    "select @xmath6 to satisfy ( [ difference ] ) for @xmath66 . for positive integer @xmath92 , generate @xmath93 independent samples in @xmath1 according to @xmath8 .",
    "define @xmath94 as follows : select the elements of @xmath0 that are reconstructed most often according to @xmath6 and choose one of them uniformly at random . by standard probability arguments ,",
    "the probability that the correct element @xmath15 will be selected by this process converges to 1 as @xmath92 tends to infinity .",
    "_ proof of ( i ) @xmath95 _ suppose that @xmath84 separates @xmath0 .",
    "let @xmath33 denote the associated matrix of @xmath8 , and let @xmath96 , @xmath97 denote the rows of @xmath33 . recall that @xmath96 gives the distribution of @xmath98 .",
    "we will describe the inverse random function @xmath99 with its associated matrix , i.e. in the form of a @xmath100 matrix @xmath36 , whose rows represent the distribution of the element of @xmath1 corresponding to the row .",
    "we write @xmath101 and will give @xmath7 explicitly .",
    "( if we were to take @xmath102 , then ( [ difference ] ) yields uniformly @xmath103 instead of the desired @xmath104 ) .",
    "we denote the columns of @xmath7 by @xmath105 , @xmath97 .",
    "we define each vector @xmath106 as follows : @xmath107 where @xmath108 is the usual euclidean vector norm .",
    "then it can be checked that this choice of @xmath7 provides a solution to the following system : @xmath109 and these are precisely the conditions ( [ difference ] ) requires for invertibility .",
    "a natural question is whether the composition of invertible functions is also invertible .",
    "the next result shows that in general the answer is ` no ' , though we can provide a precise characterization based on the rank of an associated matrix .",
    "let @xmath110 be a random function matrix @xmath111 , and let @xmath112 denote the extension of @xmath111 by an all-1 row .",
    "if @xmath113 , then for all @xmath114 invertible random functions , the composition @xmath115 is invertible , and if rank is less than @xmath116 , then there exist invertible random functions @xmath114 such that @xmath115 is not invertible .",
    "assume first that @xmath117 is not invertible , i.e. there exist @xmath118 , such that the distributions @xmath119 and @xmath120 are identical .",
    "then we have the following homogeneous system of linear equations , where the coefficients are the numbers @xmath121 $ ] and 1 s , and the variables are the @xmath122 s : @xmath123x_u & = & 0 \\hbox{\\ \\ \\   for all $ z\\in z$.}\\\\ \\sum_{u\\in u } x_u & = & 0 .",
    "\\label{identity2}\\end{aligned}\\ ] ] the matrix @xmath112 is the matrix of the system of homogeneous linear equations ( [ identity])-([identity2 ] ) .",
    "observe that @xmath124-{{\\mathbb p}}[\\xi_b = u]$ ] solves the system ( [ identity])-([identity2 ] ) .",
    "if the rank of @xmath112 is @xmath116 , then it has only trivial solution , i.e. for all @xmath22 @xmath125 .",
    "this amounts to @xmath2 and @xmath30 having the same distribution , contrary to the assumption of @xmath8 being invertible .",
    "assume now that @xmath112 has rank less than @xmath116 .",
    "then the system ( [ identity])-([identity2 ] ) has a non - trivial solution @xmath122 .",
    "set @xmath126 and @xmath127 .",
    "clearly @xmath128 .",
    "take @xmath129 , @xmath130= { x_u\\over p } $ ] if @xmath131 , and 0 otherwise ; and @xmath132= { x_u\\over n } $ ] if @xmath133 , and 0 otherwise .",
    "it is clear that this @xmath134 is invertible , as it separates @xmath15 and @xmath135 .",
    "however , according to the argument above ( [ identity ] ) , the distributions @xmath119 and @xmath120 are identical .      from proposition  [ main1 ] , if @xmath8 separates @xmath0 then there is a random function @xmath72 for which @xmath136 -\\frac{1}{|a| } > 0.\\ ] ] we now consider putting an explicit lower bound on the right hand side of this inequality .",
    "that is , we show that for a specific continuous positive function @xmath137 ( dependent only on @xmath138 ) the following holds : suppose that @xmath139 for all @xmath140 .",
    "then there is a random function @xmath72 for which @xmath136 -\\frac{1}{|a| } > h(\\delta)\\ ] ] for all @xmath73 . note that we can not insist the @xmath6 be mle ( maximum likelihood estimation ) , even when @xmath80 . to see this ,",
    "let @xmath141 and let @xmath142 take the value @xmath143 with probability 1 , and let @xmath144 take the values @xmath145 with probabilities @xmath146 and @xmath147 , respectively ; then if @xmath148 is mle , we have @xmath149 = \\frac{1}{3}$ ] .    for every random function @xmath71 , with @xmath150 ,",
    "there exists a @xmath151 , such that @xmath152 in particular , if for all @xmath153 , @xmath154 , then @xmath155 .",
    "recall the characterization of the random inverse function maximizing @xmath156 from theorem 5 @xcite : @xmath157 $ ] , where @xmath158 is a probability distribution on @xmath0 . in",
    "the rest of the proof @xmath158 refers to this minimizing distribution .",
    "( note that theorem 5 in @xcite contains an annoying typo , it shows maximization for @xmath158 instead of minimization ) .",
    "we are going to use the following lemma .",
    "[ bnums ] let us be given real numbers @xmath159 .",
    "assume that @xmath160 then @xmath161 \\geq { \\epsilon \\over n}.$ ]    without loss of generality we may assume @xmath162 .",
    "the conditions of the lemma can be rewritten as the conditions of the following primal linear program : @xmath163 recall the duality theorem of linear programming @xcite : @xmath164 if both optimization problems have feasible solutions .",
    "the dual linear program is as follows : @xmath165 it is easy to see that the for the dual problem a feasible solution is the following setting : @xmath166 for @xmath167 , and @xmath168 ; with value @xmath169 .",
    "this implies that @xmath170 for any feasible solution of the primal problem .",
    "we are going to apply lemma  [ bnums ] in the following setting .",
    "fix an arbitrary @xmath22 , and for @xmath97 , let @xmath171 $ ] .",
    "the lemma yields @xmath172-{1\\over |a|}\\sum_{i\\in a } \\mu(i){{\\mathbb p}}[\\xi_i = u]\\biggl ) \\\\ & \\geq & { 1\\over |a|(|a|-1 ) } \\sum_{1\\leq i < j \\leq |a| } \\bigl|\\mu(i){{\\mathbb p}}[\\xi_i = u]-\\mu(j){{\\mathbb p}}[\\xi_j = u]\\bigl| . \\label{kilenc}\\end{aligned}\\ ] ] observe the identity @xmath173= { 1\\over |a| } \\sum_{i\\in a}\\mu(i)\\sum_{u\\in u } { { \\mathbb p}}[\\xi_i = u ] = { 1\\over |a|}.\\ ] ] now identity ( [ tiz ] ) implies ( [ tizenegy ] ) and inequalities ( [ nyolc]-[kilenc ] ) imply inequality ( [ weidiff ] ) : @xmath174 - { 1\\over |a| } \\sum_{i\\in a } \\mu(i){{\\mathbb p}}[\\xi_i = u]\\biggl\\}\\\\ & \\geq   & { 1\\over |a| } + { 1\\over |a|(|a|-1)}\\sum_{u\\in u } \\sum_{1\\leq i < j \\leq |a| } \\bigl|\\mu(i){{\\mathbb p}}[\\xi_i = u]-\\mu(j){{\\mathbb p}}[\\xi_j = u]\\bigl| . \\label{weidiff}\\end{aligned}\\ ] ] fix an arbitrary @xmath27 , and set @xmath175-\\mu(b){{\\mathbb p}}[\\xi_b = u]\\bigl|$ ] .",
    "define @xmath176>{{\\mathbb p}}[\\xi_b = u]\\biggl\\},\\\\ u^= & = & \\biggl\\{u\\in u : \\ { { \\mathbb p}}[\\xi_a = u]={{\\mathbb p}}[\\xi_b = u]\\biggl\\},\\\\ u^- & = & \\biggl\\{u\\in u : \\",
    "{ { \\mathbb p}}[\\xi_a = u]<{{\\mathbb p}}[\\xi_b = u]\\biggl\\}.\\end{aligned}\\ ] ] define further @xmath177 $ ] , @xmath178 $ ] ,    @xmath179 $ ] , @xmath180 $ ] .",
    "observe that @xmath181-{{\\mathbb p}}[\\xi_b = u]\\bigl|=a^+-b^++b^--a^-.\\ ] ] on the other hand , @xmath182=   1-\\sum_{u\\in      u^=}{{\\mathbb p}}[\\xi_b = u]=b^+ + b^- . \\ ] ] from the last two equations we conclude that @xmath183 .",
    "we finish the proof by setting a lower bound on @xmath184 with a case analysis .    * if @xmath185 , @xmath186 . * if @xmath187 , @xmath188-{{\\mathbb p}}[\\xi_a = u]={1\\over 2 } \\mu(a ) d(a , b).\\ ] ] * if @xmath189 , @xmath190 -{{\\mathbb p}}[\\xi_b = u ] =   { 1\\over 2 } \\mu(a)d(a , b).\\ ] ]    in all cases , we have @xmath191 . returning to ( [ weidiff ] )",
    ", we find @xmath192 and through ( [ tizenegy ] ) , ( [ weidiff ] ) and ( [ tizenot ] ) , we have @xmath193",
    "in this section we reconsider the question of how many i.i.d .",
    "samples are required in order for parametric maximum likelihood to accurately recover elements of a finite set .",
    "assume @xmath194 , and @xmath195 is a parametric random function , where @xmath0 and @xmath1 are finite sets .",
    "define @xmath196>0\\},\\\\ \\alpha & : = & \\alpha_{(a,\\theta ) } = \\min_{u \\in   \\label{alph } u^{+}}\\{{{\\mathbb p}}[\\xi_{(a,\\theta ) } = u]\\},\\end{aligned}\\ ] ] and assume @xmath197 - { { \\mathbb p}}[\\xi_{(b,\\theta')}=u]|>0.\\ ] ] in our earlier work , theorem 5 in @xcite , we showed that for @xmath198 @xmath39 samples suffice to reconstruct @xmath73 , from @xmath199 with probability at least @xmath200 using mle , more formally , for @xmath201 , @xmath70'_{(a , \\theta)}\\geq 1-\\epsilon$ ] .",
    "our function @xmath202 in ( [ suffice ] ) tends to infinity when either ( or both ) @xmath203 or @xmath204 .",
    "this dependence on @xmath205 is reasonable ( though not always necessary , see section  [ sup ] ) , however the dependence on @xmath206 is not clear , and raises two questions .    * is there an bound on @xmath39 ( like ( [ suffice ] ) ) but which depends only on @xmath207 and @xmath205 and not on @xmath206 ? * moreover , can the function @xmath202 in ( [ suffice ] ) be replaced by a function of just @xmath205 and @xmath208 ( and not @xmath206 and @xmath209 ) so that the resulting function is still a valid bound for @xmath39 ?    in this section we show that the answer to the first question is ` yes ' ( theorem  [ mainpara ] ) while the answer to the second is ` no ' ( example  [ examp ] ) .",
    "we begin by introducing some further notation .",
    "for any two probability distributions @xmath210 on a set @xmath1 let @xmath211 denote the kullback - leibler distance of @xmath212 and @xmath213 , and recall the standard inequality : @xmath214 where @xmath215 denotes as usual the variational distance , @xmath216 .",
    "we will also use @xmath217    [ seqlem ] let @xmath218 be a sequence of i.i.d .",
    "random variables taking values in a finite set @xmath1 . assume further that if @xmath219 takes a value with probability zero , then it never takes this value . for each @xmath220 , let @xmath221 ( the normalized multinomial counts ) and let @xmath222 $ ] .",
    "let @xmath223 .",
    "then ,    * @xmath224 \\leq \\frac{|u^{+}|}{k\\delta}$ ] , * @xmath225 \\leq \\frac{|u^{+}|}{k\\delta^2}$ ] .    _ part ( i ) _ let @xmath226 . for @xmath227 ,",
    "set @xmath228 if @xmath229 , while if @xmath230 set @xmath231 recall markov s inequality , which states that if @xmath33 is non - negative random variable , and @xmath232 , then @xmath233 \\leq \\frac{{{\\mathbb e}}[x]}{a}.\\ ] ] note that @xmath234   = var[\\hat{p}_u]=    \\frac{p_u(1-p_u)}{k}$ ] , and applying ( [ markov ] ) to @xmath235 and noting that @xmath236 = \\frac{|u^{+}|-1}{k}$ ] gives @xmath237 \\leq \\frac{|u^{+}|}{k\\delta}$ ] . by definition , @xmath238 and",
    "this is less or equal to @xmath33 ( by ( [ qu ] ) , and the identity @xmath239 ) , which leads to the required inequality .",
    "_ part ( ii ) _ by the cauchy - schwartz inequality , @xmath240 and so , @xmath241 \\leq { { \\mathbb p}}\\bigl[d_2 ^ 2(\\hat{p } , p ) \\geq \\delta^2/|u^{+}|\\bigl ] \\leq \\frac{|u^{+}|}{\\delta^2}{{\\mathbb e}}\\bigl[d_2 ^ 2(\\hat{p } , p)\\bigl],\\ ] ] by markov s inequality ( [ markov ] ) . now , @xmath242 = { { \\mathbb e}}[\\sum_{u \\in u}(\\hat{p}_u -p_u)^2 ] = \\sum_{u \\in u } var[\\hat{p}_u ] = \\sum_{u \\in u } \\frac{1}{k}p_u(1-p_u ) \\leq \\frac{1}{k}.\\ ] ]    [ corostreet ] under the assumptions of lemma  [ seqlem ] , if @xmath243 , @xmath85 and @xmath244 , then with probability at least @xmath200 , the inequalities @xmath245 and @xmath246 simultaneously hold .",
    "[ mainpara ] assume @xmath194 , and @xmath195 is a parametric random function , where @xmath0 and @xmath1 are finite sets .",
    "recall definition ( [ u ] ) and condition ( [ dtheta ] ) .",
    "provided @xmath247 with @xmath248 , the probability that mle correctly returns @xmath15 from @xmath66 is at least @xmath200 , i.e. @xmath70'_{(a , \\theta)}\\geq 1-\\epsilon$ ] .",
    "let @xmath212 be the probability distribution on @xmath1 induced by @xmath249 , @xmath250 , @xmath251 be the event that @xmath252 .",
    "for the probability distribution @xmath253 induced by @xmath254 where @xmath255 , by the triangle inequality we have @xmath256 now , by assumption @xmath257 , and so , conditional on @xmath251 , @xmath258 . invoking the inequality ( [ ineqkl ] )",
    "gives @xmath259 thus , conditional on @xmath251 we have : @xmath260 for @xmath261 , consider @xmath262.\\ ] ] @xmath263 is @xmath264 times the natural logarithm of the probability that the observed sequence of @xmath1-elements came from @xmath265 .",
    "therefore @xmath266 is proportional to the log - likelihood of @xmath265 . now consider the log likelihood ratio @xmath267 conditional on @xmath251 we have , by ( [ likelin ] ) , @xmath268 so if we select @xmath269 in corollary  [ corostreet ] we can ensure that with probability at least @xmath200 that event @xmath251 occurs and also ( since @xmath270 ) that @xmath271 , and so , by ( [ likelq ] ) we have @xmath272 .",
    "the value of @xmath39 that corollary  [ corostreet ] requires is precisely that given in the statement of this theorem .",
    "this completes the proof .    * remarks *    * theorem  [ mainpara ] also implies that for mle in the _ non_parametric setting , the number @xmath39 of i.i.d . samples required to reconstruct an element @xmath73 correctly with probability at least @xmath200 is bounded above by a function that depends just on @xmath207 and @xmath273 . in @xcite an upper bound on @xmath39",
    "was also derived , however it depended just on @xmath274 and @xmath275 .",
    "comparing these results suggests an interesting question : is there an upper bound for @xmath39 ( in the non - parametric setting ) which depends just on @xmath275 and @xmath208 ? * we show below that the linear dependence of @xmath39 on @xmath276 in theorem  [ mainpara ] is best possible in the sense that no sublinear dependence is possible .",
    "it is possible however that the exponent of 4 for @xmath205 in theorem  [ mainpara ] might be reduced .",
    "we now show that theorem  [ mainpara ] can not be improved by replacing the dependence of @xmath39 on @xmath277 with a sublinear function ( like the logarithmic dependence on @xmath278 in theorem 5.1 @xcite ) , even when @xmath279 and @xmath208 are held constant .",
    "let @xmath280 , with @xmath281 , and @xmath282 let @xmath283 .",
    "fix @xmath284 and consider the random function @xmath8 defined as follows .",
    "@xmath285 = \\begin{cases } \\delta , & \\mbox{if $ u=0 $ ; } \\\\ \\frac{1-\\delta}{n } , & \\mbox{if $ u \\in \\{1 , \\ldots , n\\}$ ; } \\end{cases } \\end{aligned}\\ ] ] @xmath286 = \\begin{cases } 2\\delta , & \\mbox{if $ u=0 $ ; } \\\\ \\lambda_u(1 - 2\\delta ) , & \\mbox { if $ u   \\in \\{1,\\ldots , n\\}$. } \\end{cases } \\end{aligned}\\ ] ] we assume that @xmath287 , otherwise we have nothing to prove . for @xmath288 , let @xmath289 .",
    "we have : @xmath290 = \\delta^{x({\\bf u})}\\left(\\frac{1-\\delta}{n}\\right)^{k - x({\\bf u})},\\ ] ] and @xmath291 \\geq ( 2\\delta)^{x({\\bf u})}\\left(\\frac{1 - 2\\delta}{k - x({\\bf   u})}\\right)^{k - x({\\bf u})},\\ ] ] since we are free to select @xmath292 to be the uniform distribution on @xmath293 for those @xmath294 for which @xmath295 .",
    "we will select @xmath296 sufficient small that @xmath297 now , suppose we generate @xmath53 randomly from @xmath298 .",
    "note that the value of @xmath299 is at least @xmath296 , since @xmath300-{{\\mathbb p}}[\\xi_{(b,\\theta ' ) }   = 0]| = \\delta.\\ ] ]    then mle will ( incorrectly ) reconstruct @xmath135 whenever @xmath301 .",
    "we will show that this occurs with probability at least @xmath200 , if @xmath39 is less than @xmath302 , for any @xmath296 satisfying ( [ epseq ] ) and any sufficiently large @xmath277 .",
    "note that by replacing @xmath303 by its lower bound ( [ szam ] ) , we can write @xmath304 where @xmath305^{1-\\rho},\\ ] ] where @xmath306 . now , if @xmath307 , then since @xmath308 , @xmath309 now , for @xmath310 fixed , there exists a value of @xmath39 , for which , with probability at least @xmath200 , we have @xmath311 thus for this value of @xmath39 , and any @xmath312 inequality ( [ epseq ] ) gives @xmath313 and so @xmath314 ; that is mle will make an incorrect decision .",
    "thus , we must have @xmath315 in order to avoid this .      in the _",
    "non_-parametric setting , given a random function @xmath316 , suppose that @xmath317 for two elements @xmath82 . then for _ any",
    "_ random function @xmath318 it is easily shown ( eg . by theorem 3.1 of @xcite ) that @xmath319 , { { \\mathbb p}}[\\gamma_{\\xi_{a_2 } } = a_2]\\ } \\leq \\frac{1}{2}.\\ ] ] that is , if the probability distribution induced by @xmath320 and @xmath321 is the same , no method can recover both @xmath320 and @xmath321 more accurately than by a toss of a fair coin .",
    "we can ask if a similar result holds for _ parametric _ mle . that is ,",
    "suppose that @xmath322 and for a value @xmath323 , and @xmath324 we have @xmath325 where @xmath279 is defined as in ( [ dtheta ] ) .",
    "note that theorem  [ mainpara ] does not give a finite bound on @xmath39 for mle to accurately reconstruct @xmath320 or @xmath321 .",
    "however it turns out that for certain random functions satisfying ( [ vanish ] ) , if parametric mle is used to estimate @xmath320 and @xmath321 from @xmath39 independent trials , then for any parameter @xmath326 chosen , and for even @xmath39 , the probability that the selection is correct is always strictly greater than @xmath327 , moreover in all but one choice of the parameter settings ( for @xmath320 ) the probability the selection is correct tends to @xmath328 as @xmath329 ( in the other setting it tends to @xmath327 from above ) .",
    "for this example th ere is a more pedestrian approach for estimating @xmath320 or @xmath321 from the @xmath39 independent trials , for which the probability of making the correct reconstruction tends to @xmath328 as @xmath39 tends to infinity , for all parameter settings ( in contrast to mle which has problems at one particular parameter settings  this illustrates again the care required in consistency arguments for mle ) .",
    "note also that in this example , with any parameters @xmath330 , @xmath331 holds .",
    "let @xmath332 , @xmath333 , @xmath334 , and @xmath335.$ ] for @xmath336 , let @xmath337=\\sin^2 t$ ] , @xmath338=\\cos^2 t$ ] ; and for @xmath339 , let @xmath340=\\cos^2 t$ ] , @xmath341=\\sin^2 t$ ] .",
    "the key observation for the argument that follows is that @xmath342 in @xmath343 , while in the endpoints @xmath344 .",
    "it is easy to see that @xmath345 , and hence @xmath346 .",
    "a similar argument shows that @xmath347 .",
    "it is also easy to see that the distributions of all @xmath348 random variables are different",
    ". the only possible problem would be the distributions of @xmath349 and @xmath350 however in this case we have the second coordinates in the elements of @xmath1 to separate these distributions .",
    "there is a pedestrian way to guess where an element of @xmath1 came from .",
    "count the ones and twos in the first coordinates after @xmath39 independent trials . if there are more ones , then select @xmath320 , if there are more @xmath351 s then select @xmath321 , while in the case of a tie , if @xmath352 , then select @xmath320 , otherwise select @xmath321 .",
    "( note that @xmath352 is constant over the trials ) .",
    "mle pretty much does the same , the only thing that requires more careful analysis is whether mle correctly returns @xmath353 and @xmath354 .",
    "focus on @xmath353 , as the other problem is analogous .",
    "let # 1 and # 2 denote the number of ones and twos in the first coordinates in @xmath355 .",
    "let @xmath212 be the probability of the event @xmath356 `` # 1 @xmath357 # 2 '' ; by symmetry it is also the probability of the event @xmath358 `` # 1 @xmath359 # 2 '' , and let @xmath253 be the probability of the event @xmath360 `` # 1 @xmath361 # 2 '' .",
    "note that mle correctly returns @xmath320 for events @xmath362 and @xmath363 ( but not for @xmath364 , and hence @xmath70 ' _ { ( a_1 , \\pi/4 )   } \\geq p+q=\\frac{1+q}{2 } > \\frac{1}{2}$ ] .",
    "the claim holds for @xmath363 for the following reason . the probability that @xmath365 yields the particular observed",
    "@xmath39-sequence conditional on @xmath363 is @xmath366 , while the probability that @xmath367 generated the particular observed @xmath39-sequence conditional on event @xmath363 is @xmath368 for some @xmath369 , and this second probability is strictly smaller than @xmath366 .    informally , the reason for this phenomena is that the parameter space associated to @xmath370 is tuned for ` fitting ' data that is produced by the pair @xmath326 .    despite this somewhat surprising result",
    ", one can easily derive a parametric analogue of ( [ halfbound ] ) for any random function @xmath371 ( where @xmath372 as usual ) under the stronger condition that @xmath373 where @xmath374 is the variational distance between the distributions of the @xmath1valued random variables @xmath375 and @xmath376 . in this case , for any random function ( not just parametric mle ) @xmath377 that is independent of @xmath8 it is easily shown that @xmath378 , { { \\mathbb p}}[\\gamma_{\\xi_{(a_2 ,   \\theta_2 ) } } = a_2]\\ } \\leq \\frac{1}{2}.\\ ] ] of course this bound applies also for @xmath39 i.i.d .",
    "trial experiments .      as a simple illustration of the use of theorem  [ mainpara ] , we describe an application to the reconstruction of phylogenetic trees from binary sequences according to a simple markov process ( the cfn model ) .",
    "such processes are central to much of molecular biology ( see eg .",
    "let @xmath0 denote the three binary phylogenetic trees that have leaf set @xmath379 .",
    "for a tree @xmath380 , @xmath381 is the set of functions @xmath382 $ ] which assign to each edge @xmath383 of @xmath384 an associated _ substitution probability_. under the cfn model a state is assigned uniformly at random to a leaf ( eg . leaf 1 ) and states are assigned recursively to the remaining vertices of the tree by ( independently ) changing the state ( @xmath385 to @xmath328 or @xmath328 to @xmath385 ) across each edge @xmath383 of @xmath384 with probability @xmath386 .",
    "this gives a ( marginal ) probability distribution on each of the 16 site patterns @xmath387 ( further details concerning this model can be found in @xcite or @xcite ) .",
    "thus if we generate @xmath39 site patterns i.i.d . from the pair",
    "@xmath388 we can ask how large @xmath39 must be in order for mle to accurately reconstruct @xmath384 . to ensure that @xmath389 one must impose the following condition on @xmath212 .",
    "* for each of the four edges @xmath383 of @xmath384 incident with a leaf we have @xmath390 ; and for the central edge @xmath383 of @xmath384 , @xmath391 .    from @xcite ( lemma 6.3 ) we have @xmath392 for a continuous function @xmath393",
    "note that condition ( p ) can allow arbitrarily small values for @xmath394\\}$ ] even when @xmath202 and @xmath395 take fixed values ( since condition ( p ) allows two adjacent edges incident with leaves of @xmath384 to both have arbitrarily small @xmath386 values , and the probability of any site pattern that assigns these two leaves different states can therefore be made as close to zero as we wish ) .",
    "consequently , the main result from @xcite does not provide any ( finite ) estimate for the site patterns required for mle to correctly reconstruct a tree .",
    "however we may applying theorem  [ mainpara ] in this setting , and since @xmath396 , we obtain an explicit upper bound on the number of site patterns required to reconstruct each phylogenetic tree on four leaves correctly with probability at least @xmath397 .",
    "we would like to thank linyuan ( lincoln ) lu , for suggesting a shorter proof of the implication @xmath398 of proposition  [ main1 ] ."
  ],
  "abstract_text": [
    "<S> this paper continues our earlier investigations into the inversion of random functions in a general ( abstract ) setting . in section  [ two ] </S>",
    "<S> we investigate a concept of invertibility and the invertibility of the composition of random functions . in section  </S>",
    "<S> [ three ] we resolve some questions concerning the number of samples required to ensure the accuracy of parametric maximum likelihood estimation ( mle ) . a direct application to phylogeny reconstruction is given . </S>"
  ]
}