{
  "article_text": [
    "with the current state of politics , economics , and conflicting ideologies , security has become an ever increasing concern and the driving force behind much strategic development .",
    "for example , the security game solving algorithm of dobss [ 1 ] serves as the core of the armor system , which has been successfully utilized in security patrol schedule at los angeles international airport [ 2,3 ] .",
    "in such situation , limited resources pose a constant challenge issue to providing full security coverage .",
    "examples of limitations include restricted finances , man power , supplies , etc . in these situations",
    ", defenders must often recruit outside agents to aid in the protection of their targets .",
    "so , defenders need to do a decision making process to choose some outside agents as cooperator .",
    "the situation becomes further exacerbated when information on the outside agents is unavailable or ambiguous .",
    "ambiguous information refers to the uncertainty of the defender in relation to the objective and behavior of outside agents were they to engage in such cooperation process .",
    "much literature on the topic of security games attempts to address the issues involved with ambiguous information . in these games",
    ", the defenders can not assign a value for the probability of the outside agent s objective(i.e .",
    ", whether these agents will behave more like attackers or defenders in a cooperation process ) . here",
    "bayesian models can not be applied as they require that the defenders be able to assign a precise probability value for the outside agents [ 4 ] .",
    "for example , consider a battlefield in which security forces try to protect vital resources , while the enemy tries to penetrate their defence and commit espionage .",
    "when the security forces employ outside forces to reinforce their strength , they can not determine for certain whether the i.e. , which resources are being targeted .",
    "in this article , we will refer to the agents who are responsible to protect the target as `` defenders '' and the outside agents who are asked by the defenders to enhance the protection process are refered to `` potential assistants '' .",
    "based on the need of defenders to form cooperation processes to enhance protection , and also ambiguity of the decision framework , we propose a model to handle uncertainty in security games . in order to handle such situations ,",
    "we use the choquet expected utility [ 5 ] .",
    "furthermore , we will define two factors of the agents which are used by the others to choose appropriate agents as cooperators . from the agent s point of view , an appropriate agent is one with whom cooperation leads to an increase in payoff for the defender .    in this article ( i )",
    "we deal with ambiguous information of the agents about the other agents of different types , ( ii ) we propose two notions that are based on human behavior , to calculate the ambiguity degree of one agent s belief about the other one , ( iii ) we propose an algorithm for solving security games with such ambiguous information , ( iv ) we evaluate our algorithm - and find that our model is efficient and safe for handling security games .",
    "the rest of the article is organized as follows .",
    "section 2 recaps the choquet expected utility and its usage in decision making .",
    "section 3 introduces our security game as a formal game and proposes an algorithm to solve it .",
    "section 4 describes the experiments conducted to evaluate the performance of the algorithm .",
    "finally , section 5 concludes our article .",
    "this section outlines some backgrounds and describes some key components of decision making under ambiguity . in this",
    "study the cooperation process model is based on that employed by shehory and sykara and sless , hazon , and kraus in their respective studies[6,7 ] . to serve their goals",
    ", the agents have to participate in a cooperation process by some amount of their capabilities . in this model ,",
    "the agents request a percent of the obtained payoff from their cooperation and they gain from the cooperation in accordance to their level of participation and the amount of request they suggest .",
    "marinacci el al studied details of cooperation of the agents in the presence of ambiguity [ 5 ] .",
    "the ambiguous setting was described by paolo ghirardato [ 8 ] as an extension of maximum expected utility which is introduces by savage[9 ] .",
    "the ellsberg paradox [ 10 ] is an example that shows the importance of studying ambiguous situations and how they differ from certain situations .",
    "the ellsberg paradox concerns subjective probability theory , which fails to follow the expected utility theory . to handle ambiguous situations , they defined some real - valued function as neo - additive probabilities , which are called capacities . using these capacities",
    ", they introduced the choquet expected utility as a generalization of expected utility .",
    "+ in the presence of ambiguity , the majority of agents respond by behaving cautiously . such cautious behavior is referred to as ambiguity - aversion .",
    "bade [ 11 ] explains the effect of ambiguity aversion on equilibrium outcomes based on the relaxation of randomized strategy .",
    "in contrast , a minority of agents behave more carelessly , which is referred to as ambiguity - preference .",
    "the majority of the time , agents do not act purely in accordance to either ambiguity aversion or ambiguity preference , but rather somewhere in between . also , wakker [ 12 ] extends the notions of ambiguity to arbitrary events and characterizes optimistic and pessimistic attitudes .",
    "+ to better understanding the rest of the article , we present below some review of the works done on the field of ambiguity .",
    "we assume the uncertainty a decision maker faces can be described by a non - empty set of states , denoted by @xmath0 .",
    "this set maybe finite or infinite .",
    "associated with the set of states is the set of events , taken by sigma - algebra of subsets of @xmath0 , denoted by @xmath1 .",
    "we assume for each @xmath2 in @xmath0 , @xmath3 is in @xmath1 .",
    "capacities are real - valued functions defined on @xmath1 that generalize the notion of probability distributions .",
    "formally , a capacity is a normalized monotone set function [ 13 ] .",
    "a capacity is a function @xmath4 which assigns real numbers to events , such that @xmath5 and @xmath6 implies @xmath7 .",
    "also @xmath8 and @xmath9 .",
    "let @xmath10 be a @xmath1-measurable real - valued function .",
    "according to the state @xmath2 the decision maker(agent ) decides to execute an action whose results lead to a state from a finite set of states @xmath11 and obtaining payoff @xmath12 .",
    "that is , the set @xmath13 is finite .",
    "the choquet integral can therefore be written in the following intuitive form .",
    "+    for any simple function @xmath14 the choquet integral with respect to the capacity @xmath15 is defined as : @xmath16.\\end{aligned}\\ ] ]    the choquet integral is interpreted as the expected value of the function @xmath14 with respect to the capacity @xmath15 [ 5 ] .",
    "our research make use of a special kind of capacity called the neo - additive capacity .",
    "neo - additive capacities can be viewed as a convex combination of an additive capacity and a special capacity that only distinguishes between whether an event is impossible , possible or certain . to introduce this kind of capacity , suppose the set of events , is partitioned into three subsets : the set of all null events ( @xmath17 ) , the set of universal events ( @xmath18 ) and the set of special events(@xmath19 ) .",
    "the null set of events is the set of events that are impossible to occur . also , the universal set is the set of events which are certain to occur .",
    "finally , every other set is essential in the sense that it is neither impossible nor certain .",
    "the hurwitz capacity can be viewed as a convex combination of two capacities , one of which reflects complete ignorance or complete ambiguity in everything bar a universal event occurring and the second which reflects complete self - confidence in everything bar null events .",
    "formally , we define a neo - additive capacity as a convex combination of a hurwitz capacity and a congruent additive capacity .",
    "+    for a given set of null events @xmath20 , a finitely additive probability distribution @xmath21 on @xmath22 , which is congruent with @xmath17 and a pair of numbers @xmath23 $ ] , a neo - additive capacity @xmath24 is defined as : + @xmath25    for the purpose of this research , each agent shall have a set of possible types @xmath1 which can take one of them as its career to participate in a cooperation .",
    "it can be interpreted as mathematical definition of various intentions of agent when it starts a cooperation .",
    "@xmath26 is equivalent to one specific type that the agent can choose , @xmath21 is the probability distribution that an agent assigns over types of the others initially .",
    "meanwhile , @xmath27 is the ambiguity degree that the agent has about assigning a probability distribution over types of the others .",
    "finally @xmath28 is the optimistic or pessimistic attitude toward making decision about types of the others .",
    "it is straightforward to derive the choquet integral of a simple function @xmath14 with respect to a neo - additive capacity :    the choquet expected value of a simple function @xmath29 with respect to the neo - additive capacity @xmath30 is given by : @xmath31+\\sigma(\\alpha max\\{x : f^{-1}(x ) \\notin \\mathcal{n}\\ } \\nonumber\\\\ + ( 1-\\alpha ) min\\{y : f^{-1}(y ) \\notin \\mathcal{n}\\})\\end{aligned}\\ ] ]    it is important to note that neo - additive capacities satisfy three conditions : @xmath32 they are additive for pairs of disjoint events which are not null and do not form a partition of a universal event.@xmath33 they exhibit uncertainty aversion for some events .",
    "@xmath34 they exhibit uncertainty preference for some other events .",
    "the ambiguous information of agents represented by neo - additive capacities face some decision problems optimistically and face others pessimistically , i.e. , there may exist two agents with the same belief and ambiguity degree @xmath35 .",
    "the one with smaller @xmath28 is more ambiguity - averse .",
    "this section explains our security game model and its corresponding details .",
    "it presents a method to solve such games .",
    "consider a domain that contains a set of @xmath36 targets and a set of agents .",
    "the set of agents is partitioned into a set of defenders and a set of potential assistants .",
    "each defender is responsible for protecting only one target .",
    "based on the amount of energy that the agents use in target protection , the owner of the target must reward or punish them accordingly .",
    "the amount of reward or punishment is referred to as payoff . due to the limitation of the defenders on power supply , they must rely on outside assistance to enhance their ability to protect .",
    "the main issue in this context is that there are diverse types of agents that precise probability can not be assigned to them by the others .",
    "thus the goal of the defenders becomes finding a way to choose the appropriate cooperators among the set of potential assistants , that will result in an increase in the obtained payoff .      for this experiment",
    ", we assumed that there are three types of agents : the good , the bad , and the worst .",
    "these types show the true objectives of the agents and their tendencies in target protection .",
    "the good type of the agent is defined as a non - attacker that intends to fully protect the target .",
    "there defender experiences no reduction in payoff .",
    "the bad type of agent is an attacker with whom cooperating leads to modest loss in the payoff of its cooperators .",
    "the worst type of the agent is the one with whom cooperating leads to significant loss in payoff .",
    "since the defender is uncertain of the type ( i.e. , intentions ) of its cooperators , it is possible and likely that the real payoff cooperation will differ from the initial amount expected .",
    "when the defender @xmath37 cooperates with type @xmath38 of a potential assistant which uses @xmath39 percent of its ability to protect the target @xmath40 , the payoff the defender obtains from such a cooperation is shown by @xmath41 , in which @xmath42 and @xmath43 is the percent of the amount of ability the defender uses in the target protection .",
    "this value is assigned by the owner of the target to the defender @xmath37 according to the specifications of the cooperator ( i.e. , its type and the amount of ability used in the protection process ) .",
    "suppose potential assistant @xmath44 is chosen by the defender @xmath37 of type @xmath45 as a cooperator .",
    "the obtained payoff of potential assistant @xmath44 is shown by @xmath46 . since good types of potential assistants",
    "employ more ability in the protection process , the defender obtains higher payoff that what it obtained before cooperation .",
    "however if the defender @xmath37 assesses the type @xmath38 incorrectly , i.e. , assessing the type @xmath38 the worst type as a good type , then the real payoff obtained by defender @xmath47 might be lower than what it obtained previously .",
    "this is true about the payoff which is obtained by the assistant @xmath44 when cooperates with type @xmath45 of a defender .",
    "essentially , the decrease in payoff of the defender @xmath37 is interpreted as failure of the defender in choosing the best type of potential assistant as a cooperator and the consequent decrease in payoff depends on the type of potential assistant selected .",
    "conversely an increase in the payoff of the defender @xmath37 is seen as a success in choosing the appropriate type of assistant .",
    "the increase in payoff depends on how potential assistants can be helpful in the protection process(i.e .",
    ", how much ability they employ in the protection process ) .",
    "this situation is true about the increase and decrease in payoff of potential assistants in a cooperation process .",
    "all of the agent(defenders and potential assistants ) use two important notions to assess the other agents before participating any cooperation .",
    "the first notion is the `` behavior '' of the agents in reference to a certain target .",
    "this notion is defined as an ordered pair of the amount of ability the agent uses to protect the target and the requested amount of payoff from the what expected to obtain from cooperation while protecting the target .",
    "defenders utilize this notion as an index to measure the loyalty of the agent to the target .",
    "the other important notion is known as the `` tolerance threshold , '' which is an index between zero and one .",
    "this notion is applied by each agent in target protection to obtain a value representing the degree of self - confidence the agent has in regards to the amount of ability it uses in the protection process .",
    "to better understand the notions , consider the following example :    suppose the behavior of the agent @xmath48 about the target @xmath40 is represented by ( @xmath49 ) , also the tolerance threshold of the defender @xmath50 about the ability it uses in protecting the target @xmath40 is @xmath51 .",
    "the concept behind these two notions and the method in which agents make their selections is based upon human behavior .",
    "these notions are selected by the agent subjectively according to its needs .",
    "for example the agent may need to increase its payoff by @xmath52 , so its decides to protect the target by increasing the amount of its participating ability in the cooperation process , and request its expected payoff .",
    "furthermore , if resources are restricted , the agent will exercise more caution in utilizing its ability to protect the target(the agent would be aware not to waste its resources carelessly ) , while the degree of self - confidence or the tolerance threshold decreases .",
    "note that confidence is inversely related to ambiguity , i.e. , more confidence means less ambiguity and vice versa . in our model , the agents can precisely recognize the behavior and the tolerance threshold of one another .",
    "in addition , they can calculate the real payoffs given various situations .",
    "the application of these notions to evaluate the ambiguity degree is as follows :    if @xmath53 holds , the agent @xmath50 can confidently determine the type of the agent @xmath48 with which it is interacting in order to protect the target @xmath40 .",
    "there is no ambiguity ; the agent is loyal . on the other hand ,",
    "if @xmath54 holds , the agent @xmath50 can not verify the loyalty of the agent @xmath48 , i.e. , ambiguity about type of the agent is present . in this scenario , the ambiguity degree of agent @xmath50 about agent @xmath48 in cooperation to protect target @xmath40 , @xmath55 , can be computed as follows :    @xmath56    we can verify the behavior of this function by exploring the impact of different variables , such as tolerance threshold .",
    "+ suppose the agent @xmath48 has a specific behavior @xmath57 to deal with the target @xmath40 .",
    "as more impatient the agent @xmath50 is to deal with the target @xmath40 , the lower its tolerance threshold becomes and the numerator of the fraction increases . moreover",
    "a decrease in the tolerance threshold results in a decrease in the denominator .",
    "meanwhile , increase in the numenator and decrease in the denumenator lead to increase in the ambiguity degree of agent @xmath50 about agent @xmath48 , @xmath58 .",
    "inversely , the more patient the agent @xmath50 is , the higher it s tolerance threshold . in this case",
    "the numerator of the function will be lower and the denominator higher , which translates to a decrease in the ambiguity degree .",
    "as shown earlier , the ambiguity degree of the agents towards the types of potential assistants is computed using notions of tolerance threshold and behavior .",
    "there we have defined our game as an ambiguous security game in which each agent has some ambiguity degree in respect to its potential assistants in different cooperations .      using the information obtained from the game , we define our game as @xmath59 such that : +    * @xmath60 is the set of players , where @xmath37 stands for defender and @xmath61 stands for potential assistants .",
    "* @xmath62 contains elements of @xmath63 which shows the type set of agent @xmath48 . *",
    "@xmath64 represents the behavior set of each agent .",
    "* @xmath65 where @xmath66 is the pure strategy set of the attacker and the defender representing the different values for the tolerance threshold of each agent . *",
    "@xmath67 and @xmath68 is the real payoff obtained by player @xmath48 when it cooperate with player @xmath50 .",
    "@xmath69 is the ordered pair of the amount of ability used by the player @xmath50 and the amount of ability used by the player @xmath48 .",
    "* @xmath70 is the payoff that the player @xmath48 expects to obtain according to strategy profile @xmath0 while it cooperates with @xmath50 whose behavior is @xmath71 .",
    "* @xmath72 is the set of initial beliefs @xmath21 of players about type of each other .",
    "the goal of the defender is to examine different possible values for its tolerance threshold and select the one which maximizes payoff . in our security game ,",
    "first the defender commits an optimal strategy ( selects its optimal tolerance threshold ) to the potential assistants , and then the potential assistants try to find the optimal strategy for themselves [ 14 ] . because each defender is responsible for protecting only one target",
    ", we suppose that its expected payoff is obtained through all available potential assistants in the cooperation .",
    "it is also worth mentioning that the expected payoff of the potential assistant is to be received from the defender regardless of the attendance of the other potential assistants in the cooperation .",
    "given the above definition , the payoff that the defender @xmath37 expects to obtain with tolerance threshold @xmath73 when taking agent @xmath74 with behavior ( @xmath75 ) as its assistant to protect the target @xmath40 @xmath76 is expressed by the following : @xmath77.\\end{aligned}\\ ] ] this formula is a variant of formula ( 4 ) . in this formula , @xmath78 is the ambiguity degree of the defender in relation to the potential assistant @xmath74 , this value can be computed by formula ( 5 ) .",
    "@xmath79 is the initial belief of the defender on the types of the opponents , which @xmath80 shows a specific type from all available types of the potential assistant .",
    "@xmath28 is the degree of optimism , which shows how optimistic the defender is in its computations .",
    "suppose the set of potential assistants who cooperate with the defender to protect the target @xmath40 is shown by @xmath81 , then the total payoff which is obtained by defender @xmath37 to protect target @xmath40 is represented by :    @xmath82     + the payoff of the potential assistant , as it begins to assist the defender , is computed by :    @xmath83).\\end{aligned}\\ ] ]     + this formula is a variant of formula ( 4 ) .",
    "note to the difference between the number of arguments of function @xmath84 and @xmath85 .",
    "it is important to know that in formula ( 6 ) and ( 8) , if @xmath86 , these formulas are reduced to savage expected utility .",
    "if @xmath87 the agent is on pessimistic view and if @xmath88 , it is in its optimistic view . given the defenders strategy @xmath73 the optimal strategy of the potential assistant is @xmath89 if :    @xmath90    in the ambiguous security game , given the defender strategy @xmath73 , if the optimal response strategies of the potential assistant are @xmath89 , then @xmath91 is the defender s optimal strategy if :    @xmath92      as mentioned previously , the defender executes its optimal strategy first . to accomplish this , it must evaluate the strategies of the potential assistants and choose the best one based on the strategies which are chosen by the potential assistants .",
    "the defender finds its optimal strategy in two phases .",
    "in the first phase , he needs to recognize which one of the potential assistants is willing to cooperate with him in the cooperation process .",
    "the potential assistant is willing to cooperate with defender @xmath37 , if the payoff the defender expects to obtain from this cooperation is higher than its previously obtained payoff . in the second phase ,",
    "the defender @xmath37 starts to compare its different strategies on the basis of the amount of payoff it expects to get .    in the first phase ,",
    "the defender calculates the ambiguity degree for each potential assistant and all possible strategies they can choose using formula ( 5 ) . according to the different values obtained , the defender uses formula(8 ) to compute the expected payoff for each potential assistant .",
    "the defender then compares , for each potential assistant , the different strategies that they can choose on the basis of their corresponding expected payoff and determines their optimal strategy .",
    "the defender finds , for each potential assistant , their optimal strategy and their corresponding expected payoff ( formula 9 ) .",
    "if the maximum expected payoff of a potential assistant is higher than its previously obtained payoff , the defender will know that the potential assistant is willing to cooperate with him .",
    "the first phase concludes with the defender having identified the set of potential assistants who are willing to cooperate .",
    "this set is shown by @xmath81 where @xmath40 is the target that the defender is responsible to protect .    in the second phase",
    ", the defender evaluates its options through a similar process to the first phase .",
    "using formula ( 5 ) , it quantifies ambiguity degrees and from formula ( 6 ) the corresponding expected payoff for each strategy .",
    "the winning strategy of the defender is the one that maximizes its expected payoff ( formula 10 ) .",
    "the algorithmic process of the game solution is shown in algorithm 1 .",
    "@xmath93 + @xmath94 @xmath95 use formula ( 8) and ( 9 ) to find the optimal strategy of the potential assistant and his expected payoff in the view of the defender .",
    "compare the expected payoff of potential assistants with their previous payoff and find the set of agents who are willing to cooperate with defender @xmath96    find the maximum payoff of the defender obtained while he cooperates with the set of willing potential assistants using formulas ( 6 ) and ( 7 ) , @xmath97    the time complexity of the algorithm is computed in the theorem below .",
    "+    in security games with ambiguous agent types , the complexity of finding optimal pure strategies of a selected defender , is @xmath98 .",
    "each pure strategy to which the first player may commit will induce a subgame for the remaining players .",
    "we can solve each such subgame recursively to find all of its optimal strategy profiles ; each of these will give the original first player some utility .",
    "those that give the first player maximum utility correspond exactly to the optimal strategy profiles of the original game .",
    "note that if the defender @xmath37 assesses the type of the potential assistant ( @xmath44 ) as a cooperator wrongly , it means @xmath38 is the worst type but the defender miscategorizes it as a good type , the real obtained payoff by the defender would decrease .",
    "the defender @xmath37 inaccurately assesses the type of the others when it miscalculates the expected payoff .",
    "an error in computation is a result of flawed initial beliefs apropos the other agents",
    "in this section , we are going to evaluate our model via experimentation .",
    "one of the more realistic works is done by zhang and his colleagues in[14 ] .",
    "they use a model ( d - s theory based model ) to handle the ambiguous information about the types of the attacker in a security game .",
    "they define a basic probability assignment or a mass function and use it to define a preference degree of each agent over different strategies . in order to prove the efficiency of our proposed algorithm we are going to evaluate our model by the d - s theory based solution concept .",
    "to use d - s theory , the mass function that the agents assign to different events must include capacities used in our algorithm . in order to incorporate capacity from our algorithm to the mass function , we used the following method [ 15 ] :    @xmath99    now we use the experiments to show that , the worst case in our model is better than the method which uses d - s theory based model .    to perform our evaluations , we suppose that there are five targets and a set of agents who want to protect the targets and gain payoff from their owners . at first",
    ", every target is protected by only one agent as defender .",
    "the remaining agents are called potential assistants which are going to be used when necessary . for simplicity",
    ", we assume that at first , agents who work as defender gain a fixed amount of payoff from owners of the targets and potential assistants gain zero payoff .",
    "also , we suppose that all of our agents can be in one of three types which are the good type , the bad type and the worst type .",
    "for simplicity of programming , we initialize each argument of the ordered pair of the behavior of agents by random values in the interval [ 0,1 ] .",
    "these values show the percentage of expected payoff the agent requested and the percent of the employed ability to protect the target respectively .",
    "in addition , each agent has a tolerance threshold about their amount of employed ability to protect the target .",
    "the value which is assigned to the tolerance threshold of the agent is relevant to the amount of its employed ability in the target protection . the higher the amount of employed ability of the agent , the lower the tolerance threshold of the agent will be in the target protection .",
    "for example in our algorithm if @xmath100 holds , the agent assigns value @xmath101 to its tolerance threshold in the cooperation process .",
    "if @xmath102 holds the assigned value to the tolerance threshold @xmath103 will be @xmath104 and so on .    due to the randomly assigned values to the behavior of the agents , we run our experiments 100 times according to the mentioned algorithm in previous section and use the average of the experiments as the outcome of the algorithm .",
    "first of all , we evaluate the impact of changing the number of agents on the outcome of our proposed algorithm(ceu - based solution algorithm ) and d - s theory based algorithm .",
    "we observe that in the worst case , the number of true detections in our algorithm is more than the number of true detections in d - s theory based algorithm . in one of the comparison",
    "we assume all the agents are ambiguity - preference ( the degree of optimism of all agent is high ) and ih the other one we assume the agents are neither ambiguity averse nor ambiguity preference(the degree of optimism of all agent is moderated ) .",
    "it shows that being ambiguity averse or ambiguity preference has no impact of the goodness of ceu - based algorithm ( see figure 1(a ) , ( b ) ) .",
    "it is important to know that in our implementation , the true detections of the defender @xmath37 are based on comparing the amount of payoff the defender expects to obtain before participating in the cooperation and what it really obtains after participating . if its expected payoff is equal to the real payoff it will obtain after cooperating with a potential assistant , the defender truly detects the type of its assistant .",
    "another evaluation which is done in our experiments is exploring the impact of changing the number of strategies agents can choose ( changing the values can be assigned to tolerance threshold ) on the outcome of two algorithms .",
    "the result of this evaluation shows that changing the number of strategies has no impact on the goodness of ceu based algorihm to do more true detections ( see figure 2(a),(b ) ) .    also , we use two metrics to shows how the ceu - based algorithm is better than the d - s theory based algorithm",
    ". one of the metrics is `` sensitivity '' which we use it to compare the two algorithms.(see figure(3 ) ) .",
    "regardless of different number of strategies and different number of types the agent can have , the figure shows that the ceu based algorithm is more sensitive than d - s theory based algorithm .",
    "we find the sensitivity measure using the formula : @xmath105   + to explore the errors in the two algorithms , we use mrse measure(mean root square error ) .",
    "we find the value of normalized mrse for each algorithm and refer to the difference between them as distance of the worst penalties(see figure ( 4 ) ) .",
    ".5     .5     .5     .5     .5     .5     .5",
    ".5      + observation1 : our model guarantees more safety than the model based on d - s theory by considering different degrees of optimism .     + observation 2 : the choquet expected utility solution based algorithm is safer than the model based on d - s theory , by considering different number of types and strategies for each agent .",
    "+ some evaluations have been done in [ 14 ] in order to prove the efficiency of d - s theory based algorithm against the algorithm based on uniform random probability . based on these experiments",
    ", we can conclude that the choguet expected utility based algorithm is safer that the algorithm based on uniform random probability algorithm .",
    "this paper proposes a new paradigm of security games , in which the defenders on one hand they need the help of potential assistants in order to have incessant protection of their vital targets against attackers due to their limited capabilities .",
    "on the other hand , regard to the presence of ambiguous information of the agents about their tendencies , the defenders can not decide precisely about selection of their cooperators .",
    "we consider that at first the defender execute his optimal strategies and then potential assistants do their tasks , since that the strategies of the defenders are known to potential assistants , so the defender must first consider the strategies that can be chosen by potential assistants to have the better understanding of the situation .",
    "we develop an algorithm based on the choquet expected utility to find the defender s optimal strategy and discuss their computing complexity .",
    "furthermore , we evaluate our model by lots of experiments , we find : ( i ) the agents face their ambiguity by defining the two notions , behavior and tolerance threshold .",
    "( ii ) our model guarantee more safety than the model based on d - s theory by regardless of agents being ambiguity - averse or ambiguity - preference .",
    "( iii ) we show that our model is more sensitive than d - s theory based model and as a result it is more efficient then uniform random probability based algorithm.(iv ) we use the mean root square error ( rmse ) to show that errors in ceu - based algorithm are less than d - s theory based algorithm .",
    "so our model can well handle the interaction of agents to protect a common target in the presence of ambiguous information .",
    "as the future works we are going to deal with equilibria issues in our proposed framework according to the work done by weber [ 16 ] that they investigated the difference among equilibria with respect to various attitudes toward ambiguity , and showed that different types of contingent ambiguity affect equilibrium behavior , and based on what kilka [ 17 ] , and wu and gonzalez [ 18 ] experimented about this topic .",
    "[ 1 ] paruchuri , p. , pearce , j.p . ,",
    "marecki , j. , tambe , m. , ordonez , f. , kraus , s. : playing games for security : an efficient exact algorithm for solving bayesian stackelberg games .",
    "proceedings of the 7th international joint conference on autonomous agents and multiagent systems , vol .",
    "2 , pp . 895902 ( 2008 ) . +",
    "[ 2 ] tambe , m. : security and game theory : algorithms , deployed systems , lessons learned .",
    "cambridge university press , cambridge , ( 2011 ) . +",
    "[ 3 ] zimmermann , e. : globalization and terrorism .",
    "european journal of political economy 27(suppl .",
    "1 ) , s152s161 ( 2011 ) . +",
    "[ 4 ] marinacci , m.:ambiguous games .",
    "games and economic behavior , ( 31:2 ) , 191 - 219 ( 2000 ) . + [ 5 ] marinacci , m . , montrucchio , l . :",
    "introduction to the mathematics of ambiguity .dipartimento di statistica e matematica applicata and icer universit di torino , ( 2003 ) .",
    "+ [ 6 ] shehory , o . , sykara , s.:multi - agent coordination through coalition formation , lecture notes in artificial intelligence no .",
    "1365 , intelligent agents iv , a. rao , m. singh and m. wooldridge ( eds . ) , pages 143 - 154 .",
    "springer , ( 1997 ) . +",
    "[ 7 ] sless , l . ,",
    "hazon , n . , kraus , s . ,",
    "wooldridge , m . : forming coalitions and facilitating relationships for completing tasks in social networks , aamas , ( 2014 ) . +",
    "[ 8 ] ghirardato , p . : ambiguity .",
    "dipartimento di matematica applicata and collegio carlo alberto , universitate di torino , ( 2010 ) . +",
    "[ 9 ] leonard j. savage.:the foundations of statistics .",
    "wiley , new york , ( 1954 ) .",
    "+ [ 10 ] segal , u .",
    ": the ellsberg paradox and risk aversion : an anticipated utility approach .",
    "university of toronto , department of economics , ( 1985 ) . +",
    "[ 11 ] bade , s. : ambiguous act equilibria .",
    "games and economic behavior , 71(2):246260 , ( 2011 ) . +",
    "[ 12 ] wakker , p . : testing and characterizing properties of nonadditive measures through violations of the sure thing principle .",
    "econometrica , 69:10391060 , ( 2001 ) .",
    "+ [ 13 ] chateauneuf , a. , eichberger , j. , grant , s.:choice under uncertainty with the best and worst in mind : neo - additive capacities .",
    "journal of economic theory , 137 , 538 - 567(2007 ) .",
    "+ [ 14 ] zhang , y. , luo x. , ma , m. : security games with ambiguous information about attacker types .",
    "australasian conference on artificial intelligence , volume 8272 of lecture notes in computer science , page 14 - 25 .",
    "springer , ( 2013 ) . +",
    "[ 15 ] de marco , g. , maria r. : beliefs correspondences and equilibria in ambiguous games",
    ". international journal of intelligent systems , 27(2):86102 , ( 2012 ) .",
    "+ [ 16 ] abdellaoui , m. , vossmann f. , weber , m. : choice - based elicitation and decomposition of decision weights for gains and losses under uncertainty .",
    "management science , 51:13841399 , ( 2005 ) ."
  ],
  "abstract_text": [
    "<S> currently the dempster - shafer based algorithm and uniform random probability based algorithm are the preferred method of resolving security games , in which defenders are able to identify attackers and only strategy remained ambiguous . </S>",
    "<S> however this model is inefficient in situations where resources are limited and both the identity of the attackers and their strategies are ambiguous . </S>",
    "<S> the intent of this study is to find a more effective algorithm to guide the defenders in choosing which outside agents with which to cooperate given both ambiguities . </S>",
    "<S> we designed an experiment where defenders were compelled to engage with outside agents in order to maximize protection of their targets . </S>",
    "<S> we introduced two important notions : the behavior of each agent in target protection and the tolerance threshold in the target protection process . from these </S>",
    "<S> , we proposed an algorithm that was applied by each defender to determine the best potential assistant(s ) with which to cooperate . </S>",
    "<S> our results showed that our proposed algorithm is safer than the dempster - shafer based algorithm . </S>"
  ]
}