{
  "article_text": [
    "em reconstruction is the process of extracting a connectome from an em dataset .",
    "a structural connectome derivable from em data typically consists of neurons and their connections / synapses . to decipher the intricacy of neuronal structures in a brain ,",
    "the imaging is at nanometer resolution generating vast amounts of data to be analyzed . because of this , reconstruction is very time consuming and significant advances are needed to handle larger volumes @xcite .",
    "two main approaches exist for reconstructing connectomes from an em dataset : manual skeletonization and refinement of automatic segmentation .",
    "skeletonization requires a proofreader to manually trace the shape of the cell @xcite .",
    "catmaid @xcite achieves some scalability success by making collaborative , web - based tracing very accessible to interested , well - trained biologists . in @xcite",
    ", skeletonization is accomplished through a consensus of , generally , less well - trained students .",
    "segmentation - driven tracing has been successfully deployed in a partial reconstructions of the fly optic lobe @xcite and mouse retina @xcite .",
    "reconstruction is achieved by merging and splitting incorrectly segments , which still results in effort .",
    "* the manual tracing dilemma . * despite a potentially large available workforce , the difficulty of manual tracing in traditional approaches often requires more expertise than is feasible .",
    "some approaches that use consensus skeletonization @xcite attempt to expand the available workforce by averaging the often less - than - optimal tracings of multiple proofreaders .",
    "a ) this requires even more proofreaders , b ) there is still a verification bottleneck , and c ) important features could be averaged out.,scaledwidth=100.0% ]    in the ideal case , automatic segmentation would produce a perfect connectome . while recent advances in em segmentation @xcite ( particularly in isotropic fib - sem datasets @xcite ) produce very good results , the segmentations are still far from perfect .",
    "this is due , in part , to the sensitivity of the connectome to small segmentation errors .",
    "for instance , a small false merger in a small part of the image can cause two separate neurons to be merged together greatly affecting the connectivity map .",
    "even with near - perfect segmentation , extensive verification is likely to be required .",
    "better segmentation , alone , will not solve scalability .    crowd - sourcing has been pursued in different ways @xcite as a potential solution .",
    "however , these strategies are fundamentally unscalable .",
    "figure [ fig : pyramid ] illustrates the dilemma of crowd - sourcing em reconstruction .",
    "traditionally , em tracing requires a high - level of expertise requiring weeks of training ( or more ) , unreasonable for a general crowd - source community .",
    "catmaid @xcite tries to expand the expert base through its accessibility but is not meant for beginner tracers .",
    "consensus tracing , as in @xcite can access a wider pool but requires even more proofreaders to account for errors .",
    "also , an averaged result could lead to a sub - optimal connectome or require extensive expert verification .",
    "the approach in @xcite attempts to make proofreading accessible to the novice community . despite tremendous involvement from the community",
    ", the efforts were primarily used for validation , and the reconstruction still required a group of trained proofreaders .    to address these scalability challenges ,",
    "we propose _ focused proofreading_. focused proofreading is a segmentation - driven proofreading that attempts to discern the regions of the segmentation that are both relevant to the connectome and least - likely to be correct . in the process , it distills the task of proofreading to a more digestible series of yes / no decisions . by redefining proofreading ,",
    "we hope to expand the base of potential proofreaders as shown in figure [ fig : pyramid ] .",
    "our work has some similarities to the uncertainty - driven proofreading suggested in @xcite .",
    "however , we propose a more practical approach that uses efficiently computed local constraints to guide proofreading rather than a global strategy .",
    "furthermore , we exploit synapse information and other biological priors to greatly enhance proofreading and the quality of the final reconstruction .    to effectively guide proofreading ,",
    "we introduce several metrics aimed at understanding what it means to complete a reconstruction .",
    "in particular , we propose a new , connectivity - based similarity metric to assess the quality of a segmentation and to subsequently guide efforts .",
    "previous segmentation efforts were primarily concerned with producing highly similar segmentation at only the voxel level .",
    "this paper attempts to add more biological relevance to this analysis .",
    "focused proofreading leads to significant improvements compared to random or other proofreading strategies .     * reconstruction pipeline to produce a connectome .",
    "* this paper introduces focused proofreading methodology and considers using synapse annotations to guide proofreading.,scaledwidth=100.0% ]    in this paper , we apply our focused proofreading techniques to reconstruct seven medulla columns in the drosophila optic lobe . through the combination of improved imaging @xcite and the methodology introduced here",
    ", we finished more in less time than the one - column reconstruction in @xcite .",
    "our best estimates indicate 3 - 5x speedup in reconstruction with improved accuracy .",
    "the general flow is depicted in figure [ fig : reconoverview ] .",
    "the paper is organized as follows .",
    "we first investigate similarity metrics and provide more context on the challenges of segmentation - driven reconstruction .",
    "then we introduce metrics to help better define what is meant by a good , or complete , reconstruction .",
    "we next introduce the focused proofreading algorithm and discuss its practical deployment .",
    "results are given for a ground truth subvolume , and statistics are provided from the entire reconstruction .",
    "since the goal of this paper is to introduce techniques to best guide manual annotation , we first examine what it means for manual annotation ( and similarly automatic segmentation ) to be close to the correct result .",
    "we can consider the general case of assessing the quality of a labeled image volume compared to a gold - standard , or so - called ground truth . in production ( test ) workflows , such ground truth is obviously unavailable in general . however , groundtruth on small regions of image data can act as a proxy for algorithms or methodology in similar regions .    the differences between a segmented label volume ( s ) and ground truth ( g )",
    "can be quantified by considering the variation of information ( vi ) @xcite :    @xmath0    where h is the entropy function .",
    "the first term , @xmath1 gives the information of the underlying segmentation compared to ground truth and indicates over - segmentation .",
    "likewise , @xmath2 indicates under - segmentation .",
    "@xmath3 information means high similarity .",
    "plotting both terms will produce a precision / recall - like curve . while other similarity metrics are used to compare label volumes , such as rand index @xcite and warping index @xcite",
    ", vi is both simple to compute and has interpretability advantages as highlighted by the authors in @xcite . as with computing the rand index ,",
    "careful use of hash - map datastructures enable vi to be computed in time roughly linear to the dataset size .",
    "while this paper will emphasize vi , other measures , like rand index , could be adapted .",
    "typically , the metric is applied to partitions over the voxel space where all pixels are considered . as suggested in @xcite , we can decompose the over - segmentation components of vi by :    @xmath4    this allows introspection as to which ground truth label @xmath5 observes the greatest over - segmentation .",
    "note that the impact of a given labeling with respect to a ground truth label @xmath5 is weighted by @xmath6 .",
    "consequently , big incorrect bodies contribute significantly more than small bodies .",
    "this detail will be explored later .",
    "a similar analysis can be done for @xmath2 .",
    "as imaging and machine learning algorithms have improved , annotating datasets with the help of automatic segmentation is more prevalent @xcite .",
    "as explained in @xcite , the ability to extend analyses to increasingly large datasets depends on effectively exploiting what the computer can extract automatically .",
    "the primary mechanism involves creating an initial segmentation .",
    "this segmentation is then revised often by merging label regions that were erroneously split . in practice",
    ", it is much easier to refine an oversegmented label volume than an under - segmented volume .",
    "a problem arises when reconstructing connectomes in this manner .",
    "which segments should be examined ? where should an annotator focus his / her attention ? if the initial segmentation is poor , everything must be examined and extensive effort must be spent correcting it , as captured by the so - called _ nuisance metric_. under these circumstances , it is hard to see how this approach is more scalable than manually annotating datasets using skeletonization @xcite .",
    "in fact , skeletonization could be faster since the annotator can ignore parts of the dataset irrelevant to a specific connection pathway .",
    "if the initial segmentation is good and few corrections are needed , any segmentation - driven strategy is likely superior to skeletonization . however , even with 100 percent correct segmentation ( zero nuisance ) , verifying that it is really 100 percent correct on a large dataset could still require thorough inspection by an army of annotators . to improve this , the annotators could be focused to examine only areas where the segmentation likely erred .",
    "the concept of optimizing which regions to examine was first considered in @xcite .",
    "that work defines metrics for determining the correctness of segmentation in the absence of ground truth .",
    "in practice , the segmentation will significantly deviate from ground truth .",
    "furthermore , any strategy that selectively examines the segmentation , unless it is an oracle , will likely miss errors .",
    "consider figure [ fig : hardtrace ] , where it appears that there are two complete neuron shapes .",
    "it is only through detailed inspection can one find the small connection that joins these two neuron segments together .",
    "but as we noted previously , examining everything is intractable .",
    "therefore , we attempt to better quantify errors like this one and other less important , inconsequential errors and their relevance to the connectome .     here a ground truth cell is falsely split at a small branch that results into two segments that look like individual neurons .",
    "segmentation errors like this ( even if they are very rare ) are not always evident and may require exhaustive verification without adequate proofreading guidance.,scaledwidth=100.0% ]    the barebone definition of a connectome is a graph whereby each node represents a disjoint neuron and the edges represent synaptic connections .",
    "however , the actual shape of the neuron is also useful for identifying like nodes and comparing neurons between datasets",
    ". furthermore , volumetric accuracy , as well as actual synaptic locations could be useful for circuit modeling .",
    "additional detail might be sought depending on the application ( e.g. , distribution of synaptic vesicles , mitochondria , etc ) .",
    "the metrics defined in this paper will consider a connectome as one that contains most of the neurons and most of their volume and connections .",
    "because pixel - perfect accuracy is unnecessary to identify neurons and most neuronal pathways contain multiple connections , we can create metrics that tolerate some errors .",
    "we will adjust the input to the vi metric so that some _ errors _ do not penalize the similarity between ground truth and label volume .",
    "the following considers the problem of over - segmentation .",
    "the reverse is assumed to happen infrequently by construction .",
    "this section will focus on the completeness of a connectome with respect to the neurons volume and shape .",
    "given an over - segmentation with a set of labels @xmath7 , a complete volumetric proofreading involves assigning ( merging ) each @xmath8 to some final @xmath5 ( typically a connected component ) .",
    "each @xmath5 constitutes a distinct neuron .",
    "however , if only the shape is desired , a skeletonized representation can often ignore several @xmath8 .",
    "figure [ fig : smallbodies]a shows an example of an oversegmented neuron where various `` unimportant '' segments are highlighted .",
    "note , though , that a small @xmath8 can be important as in figure [ fig : smallbodies]b .",
    "we can modify the vi metric in equation [ eq : vioverseg ] by considering only the errors that impact shape .",
    "@xmath9}\\ ] ]    where @xmath10 and @xmath11 refer to the set of points ( or lines ) that define the skeletons of @xmath5 and @xmath8 .",
    "@xmath12 could then define some correspondence function between @xmath11 and @xmath10 . for this paper ,",
    "we still desire volumetric accuracy .",
    "we redefine @xmath10 and @xmath11 to @xmath13 and @xmath14 which now denote the sets of voxels associated with each label , as in the traditional usage of vi .",
    "@xmath12 is then the intersection between these voxel sets .",
    "@xmath15}\\ ] ]    analogous to ignoring segments irrelevant to the shape in equation [ eq : skel ] , unimportant @xmath8 can be de - emphasized by removing voxels from @xmath8 and @xmath5 that are close to the surface of @xmath5 through a label erosion image operation . in this manner , noisy boundaries that have little impact on the volume or correspondence between @xmath8 and @xmath5 are ignored .",
    "a ) shows small incorrectly assigned segments that do not impact the shape ( and the resulting skeleton ) of the neuron .",
    "b ) shows a small segment that connects two different larger regions.,scaledwidth=100.0% ]    the preceding formulae more accurately reflect the true similarity between @xmath16 and @xmath7 .",
    "but volumetric differences will still exist .",
    "we attempt to define a threshold for an acceptable number of differences ( completeness ) with the following :    @xmath17\\ ] ]    where @xmath6 is the importance or frequency of @xmath5 in @xmath16 and @xmath18 is the indicator function .",
    "in other words , automatic segmentation and subsequent proofreading refinement should be considered complete when there are less than @xmath19 bodies incorrect with threshold @xmath20 .",
    "unlike just setting up a global threshold for equation [ eq : skel ] , this formula attempts to decompose the problem into something more biologically interpretable , a per body constraint .",
    "it also distinguishes between scenarios where several small differences ( all insignificant to every body of importance ) exceed some global threshold .",
    "equation [ eq : compl ] leads to two questions : 1 ) what is a good @xmath20 and 2 ) what happens when @xmath16 is unavailable ?",
    "the answer to the second question is mainly considered in the next section .",
    "plot that shows that a small number of bodies ( a few hundred ) contribute to over 90% of the volume for a typical example .",
    "the long tail is due to bodies near the edge of this ground truth volume and small inaccuracies or untraceable processes .",
    "we can estimate completeness by ensuring we see a similar distribution of large neurons in our proofread .,scaledwidth=80.0% ]    we can better understand @xmath20 and @xmath16 by analyzing the distribution of expected neuron sizes for a representative region as in figure [ fig : gtdist ] .",
    "notice that a small number of bodies constitute a large fraction of the volume .",
    "the small bodies consist of untraceable , _ orphan _ processes , or neuronal arbors clipped by the edge of the volume .",
    "any chosen threshold should ensure that a given region would have several large or non - orphan neurons consistent with the distribution in figure [ fig : gtdist ] .",
    "@xmath20 can then be derived where a ) segments larger than @xmath21 are deemed important and where b ) we expect the average size of @xmath5 to be @xmath22 :    @xmath23    where @xmath24 is the size of the whole volume and can be factored away .",
    "this equation expands the @xmath1 for a given @xmath25 defining an undesirable two - way partitioning of the body .",
    "this formula is somewhat academic since a given body can be partitioned into many pieces .",
    "however , this formulation is relevant as a stopping condition for focused proofreading as defined in the next section . in practice",
    ", we just note that small orphan ( disconnected ) segments are biologically implausible and should be ignored below a certain size @xmath21 .",
    "we introduce a new metric for analyzing the quality of segmentation that considers the connectivity .",
    "the concepts and motivation are analogous to those presented in the previous section .",
    "we define the synaptic @xmath26 as :    @xmath27}\\ ] ]    where @xmath28 and @xmath29 are just a subset of @xmath8 and @xmath5 that contain synaptic annotations .",
    "figure [ fig : synapsevi ] above shows a body with three presynaptic regions and multiple post synaptic bodies as partners .",
    "for example , the middle segment @xmath30 would have @xmath31 while @xmath32 would be the number of voxels in @xmath8 .",
    "equation [ eqn : visyn ] does not distinguish between pre and post - synaptic regions .",
    "@xmath33 can be analogously defined , and likewise @xmath34 .",
    "while previous segmentation efforts focus exclusively on volume , synapse vi is probably the most relevant single measure for connectome similarity .",
    "synapse vi similarity metric .",
    "similarity is computed over a segmentation by examining the number of synapse annotations in each segment .",
    "the middle segment has weight @xmath35 since it has three pre - synaptic regions .",
    "the outputs to these synapses are each assigned a weight of @xmath36 .",
    "the importance of the bodies is not determined by their size in voxels.,scaledwidth=100.0% ]    since synaptic completeness is similar to volume , we just note the following . first , unlike the volume measure there is little ambiguity about the relevance of this measure .",
    "every difference corresponds to a concrete change in the connectome . despite this",
    ", there may be considerable flexibility when defining completeness . in examined drosophila nervous systems",
    ", there is often considerable redundancy of connections in the strongest pathways .",
    "coupling that with inherent variability and plasticity , we can set a threshold to a level acceptable for subsequent analysis . as with volumetric completeness",
    ", we also note that a biologically correct connectome can not have synapses in small , orphan segments .",
    "the previous section defines what is `` good enough '' .",
    "this section defines how to get there .",
    "we consider the case where a proofreader is given @xmath7 and must revise it to @xmath37 , so that it is reasonably close to @xmath16 .",
    "however , for simplicity of analysis , this proofreader is restricted to merge - only operations ( we consider workflows handling splits in the next section ) .",
    "more specifically , we consider the proofreading problem as an assignment of _ yes _ or _ no _ for edges in @xmath7 , where an edge connects two neighboring @xmath8",
    ".    we can define an optimal similarity after @xmath38 decisions as :    @xmath39    where @xmath40 denotes an optimal ordering of @xmath38 @xmath41 decisions .",
    "since we are starting from an oversegmented @xmath7 , @xmath42 consists of an ordering of only @xmath38 no ( merge ) decisions .",
    "we define @xmath43 as the optimal number of decisions to achieve @xmath44 .",
    "we do not attempt to solve @xmath42 optimally .",
    "instead we favor greedy - based orderings that have the greatest impact on @xmath1 .",
    "however , simple , greedy - based approaches have two problems .",
    "first , explicit @xmath16 is unavailable for measuring impact .",
    "second , as figure [ fig : smallbodies]b illustrates , sometimes two large @xmath8 are disconnected requiring a _ smaller _ decision to be made first .",
    "we address these concerns in the following two parts .",
    "assuming a greedy - based decision ordering , we seek an impact measure for ranking an edge .",
    "the impact of the edge between segments @xmath45 and @xmath46 is analogous to the threshold equation defined in equation [ eq : thres ] :    @xmath47    @xmath48 , and @xmath49 could represent the number of voxels or synaptic annotations in @xmath45 , and @xmath46 respectively .",
    "note that we removed the normalizing @xmath24 in equation [ eq : thres ] as it does not affect the ordering .",
    "we can view @xmath50 as being a speculative ground truth , @xmath51 .",
    "figure [ fig : impacteq ] shows a plot of equation [ eq : impact ] where @xmath51 is substituted and @xmath30 is meant to be the smaller of @xmath45 and @xmath46 .",
    "it indicates that impact increases as both @xmath51 and @xmath30 increase .",
    "notably , a given edge can be more impactful than another edge if @xmath51 is larger , even if the ratio between @xmath30 and @xmath51 is smaller .",
    "is this desirable ?",
    "first , this impact measure better optimizes the vi similarity measure .",
    "second , it suggestions that bigger , more complete bodies , should be examined first .",
    "for example , if @xmath52 and @xmath45 and @xmath53 represent a single missing synapse , the impact measure tries to fix errors in the , likely , more - complete @xmath54 first .",
    "impact as a function of the total body size and the smaller partition as in equation [ eq : impact ] but with @xmath55 substituted for @xmath56 .",
    "the plot shows that larger ground truth bodies , logically , are more impactful .",
    "less intuitively , the horizontal line of equal impact indicates that a smaller fragment in a larger neuron is more impactful than a larger fragment in smaller neuron.,scaledwidth=100.0% ]    examining the most impactful true edges is undesirable since the quality of @xmath7 will not improve .",
    "the risk of each edge needs to be quantified .",
    "@xmath57    the riskiest edges define the edges that will likely have the greatest impact on this segmentation .",
    "there is some similarity between this and the impact measures defined in @xcite .",
    "however , that work focused on measures that reduced the uncertainty in a segmentation , so that additional automatic segmentation could be performed .",
    "this work does not leverage additional segmentation and tries to minimize the likelihood that false mergers will occur .",
    "this formulation is also more computationally economical as it does not require a global model of uncertainty . in other words ,",
    "our approach is more practically deployable .    to determine @xmath58",
    ", we first train a classifier on the edges of an oversegmented volume .",
    "the resulting prediction determines the confidence in the edge .",
    "this classifier is trained similarly to those discussed in @xcite .",
    "we chose the random forest classifier since it performs well , while being fast and easy to deploy .",
    "its predicted uncertainties also conform reasonably well to the actual ground truth as shown in the experiments .",
    "we define _ focused proofreading _ as the examination of a subset edges where @xmath59 , where @xmath20 is determined by equation [ eq : thres ] .",
    "the greedy - based strategy introduced previously is flawed since two labels @xmath60 and @xmath61 might belong to the same neuron but have no direct edge ( as seen in figure [ fig : smallbodies]b ) . as in @xcite , we avoid this problem by considering the probability that a set of edges connect @xmath60 and @xmath61 :    @xmath62    where @xmath63 is the probability of a path existing between @xmath60 and @xmath61 . by finding potential paths between pairs of labels , the greedy - based strategy of choosing the riskiest pair can have more global awareness .    for certain over - segmentations , examining all paths where @xmath64 will still not produce a good reconstruction , even if the predictions are exact .",
    "an extreme is example would be oversegmenting a given body into individual voxels . in this case ,",
    "no two segments are important ; the collection is important .",
    "while it might be possible to define a strategy that determines whether a set of segments has affinity , we note that such circumstances should be rare in a reasonable segmentation and its existence would likely strain the quality of any uncertainty estimation .",
    "we can define a reasonable segmentation with the following two conditions :    @xmath65    @xmath66    the first equation is a constraint that says that a certain number of neurons ( @xmath67 ) should be covered by segments of at least @xmath68 size to reach the desirable threshold @xmath21 . in the degenerate case",
    ", @xmath68 could be chosen to be really small , which would always satisfy this condition . but this may increase the amount of spurious proofreading required and might violate the second equation .",
    "the second equation says that these important segments of size @xmath21 must be connected within @xmath69 hops .",
    "ideally , the @xmath70 should also be within some threshold as well . when using @xmath71 we often set the threshold to just one annotation trivially satisfying the first condition .",
    "when using @xmath72 , not all pixels are important and we set the threshold in a manner that gives us good coverage .",
    "we show this result in the experiment section .",
    "* algorithm *    we organize the previous thoughts and now present an algorithm for proofreading an oversegmentation .",
    "[ alg : fp ]    the algorithm uses a threshold @xmath20 determined heuristically .",
    "since completeness is desired , it is not as relevant to choose the best order to examine edges .",
    "it suffices to examine all edges within a threshold .",
    "( we can effectively show the quality of the algorithm as a function of decisions by successively lowering this threshold or by constraining the algorithm to ignore low @xmath73 . )",
    "the algorithm starts by iterating through all segments considering the _ largest _ first .",
    "then , all potential segments connected to this body ( within some uncertainty threshold ) are determined through function findneighbors .",
    "the proofreader is given edges along the riskiest path in decide .",
    "after each decision , the graph and list of candidate edges are updated .",
    "if the segmentation is reasonable , the focused proofreading can still perform poorly if the uncertainties are poor .",
    "if the uncertainties favor false merging , the algorithm will lead to inefficiency , as many true edges will be examined .",
    "if the uncertainties favor false splitting , errors will occur in the final segmentation .",
    "this affect is mitigated slightly since very impactful decisions can still be examined even if the true edge probability is high . the next section discusses how this algorithm is deployed in practice .",
    "we deployed the algorithm described previously to reconstruct the neuronal pathways in the medulla columns of the drosophila optic lobe , which contained hundreds of partial neurons and several hundred thousand synaptic connections . in practice , there are many challenges to reconstruction .",
    "1 ) the initial segmentation will falsely merge some regions .",
    "2 ) focused proofreading will miss some important areas .",
    "3 ) proofreaders will make errors .",
    "* segmentation - based proofreading methodology . *",
    "the input is a subdivided dataset with synapse annotations already provided.,scaledwidth=100.0% ]    to address these concerns , we implemented the workflow shown in figure [ fig : segmentationflow ] . because of the size of the volume",
    ", we divided it into several subvolumes .",
    "each subvolume was separately proofread .",
    "three rounds of proofreading were performed : 1 ) volume - threshold focused proofreading , 2 ) synapse - threshold focused proofreading , and 3 ) orphan ( small - body ) tracing .",
    "the first two rounds closely follow the algorithm in the preceding section but with different weighting strategies ( we will investigate the advantage of doing volume - threshold before synapse - threshold in the experiments ) .",
    "we also add some synapse connectivity constraints to eliminate unnecessary work .",
    "for instance , in the synapse focused proofreading pass we ignore edges that would result in a rare autapse ( a reflexive connection where a neuron drives itself ) .",
    "subsequent proofreading would uncover remaining orphan synapse processes .",
    "focused proofreading uses a special tool raveler @xcite that highlights only the important edge , as shown in figure [ fig : focusedtool ] .",
    "the goal is to reduce proofreading errors and variability between proofreaders of different experience levels .",
    "the orphan ( small - body ) tracing is a quality control that has the proofreader examine disconnected segments that either contain synapses are of at least a certain size .",
    "therefore if focused proofreading failed to connect certain regions , there is some redundancy to ensure _ important _ areas are examined .",
    "tool that implements focused protocol brings proofreaders to specific sites to render a yes / no decision.,scaledwidth=100.0% ]    while proofreading these subvolumes , proofreaders note areas of false merging .",
    "these areas were split in a separate pass after focused proofreading . after proofreading each subvolume , we stitched them together to form a global segmentation . in principle , it is possible to work off of an initial , global segmentation , but our workflow is computationally simple and easier to parallelize . after stitching the region , additional quality controls and revisions",
    "are done on the reconstruction .",
    "these quality controls involve looking for anomalies in connectivity and cell shape @xcite .",
    "we implement the focused algorithms in a publicly available c++ tool called _",
    "neuroproof_. the thresholds and ordering strategy are primarily examined on a ground truth dataset from the drosophila medulla volume produced from fib - sem imaging @xcite .",
    "fib - sem imaging produces volumes of near isotropic resolution , ideal for performing high - quality image segmentation .",
    "we evaluate the consistency of proofreaders and reconstruction rates over several subvolumes in the medulla and compare to a previous reconstruction strategy .",
    "the initial segmentation is generated using ilastik @xcite for voxel prediction and agglomeration algorithms introduced in @xcite ( and available in neuroproof ) .",
    "the synapses were annotated before segmentation using the methodology defined in @xcite .",
    "proofreading and the focused proofreading protocols were performed with the open - source tool raveler @xcite .      in this section , we show that the proposed focused proofreading strategies are more efficient than other proofreading strategies .",
    "we also validate some of our assumptions by showing the quality of the initial segmentation and predicted uncertainty .",
    "the results are collected for a volume 500x500x500 .",
    "the difficulty of producing near - pixel perfect ground truth limits our ability to validate on more datasets .",
    "we effectively increase our test set by running many of the experiments on @xmath74 random initial segmentations .",
    "quality of the predicted edge confidences .",
    "the plot show that the true edge prediction corresponds well with the actual true edge percentage . at higher confidences",
    "the predictor tends to conservatively underestimate the number of true edges , which will result in more work.,scaledwidth=80.0% ]    before we show the effectiveness of the focused proofreading strategies in this paper , we justify some of our assumptions .",
    "figure [ fig : uncertainty ] shows the quality of the uncertainty estimation produced by the segmentation classifier averaged over @xmath74 runs .",
    "our algorithms depend on edge uncertainty predictions that closely reflect ground truth .",
    "our results show close correspondence between the predicted percentage of true edges and the number of actual true edges . at higher true edge confidence",
    ", the distribution tends to under - estimate resulting in a conservative prediction of the actual percentage of true edges .",
    "this could potentially result in more proofreading work since the segmentation appears more connected than it is .",
    "we next justify our choice of parameters for our experiment . despite the formalisms describing reasonable segmentations and completeness",
    ", the choice of thresholds often comes down to heuristics and what looks reasonable . through inspection , we determine bodies of size @xmath75 voxels to be important .",
    "figure [ fig : coverage ] shows that bodies greater than @xmath76 voxels need to be included to ensure that all important ground truth bodies are covered up to this @xmath75 threshold .",
    "( we consider important bodies , the largest @xmath77 bodies that entail 90% of the volume  over @xmath78 voxels in this example . )",
    "the final focused threshold value should be probably be between the conservative @xmath79 , @xmath80 and @xmath81 , @xmath82 as defined in equation [ eq : thres ] . the chosen synapse threshold chosen is more straightforward .",
    "since @xmath83 effectively reduces the number of important points to only a few thousand , every synaptic point is important .",
    "we set @xmath21 to @xmath36 and @xmath84 to @xmath85 .     choosing focused proofreading thresholds to achieve high coverage .",
    "based on ground truth , @xmath84 is determined to be around 105,000 voxels .",
    "this plot shows the percentage of bodies adequately covered by segments at least of the given size @xmath68 . around @xmath86 voxels , @xmath87 of the ground truth bodies",
    "are covered .",
    "we choose this as the cut - off for the rest of our experiments . @xmath68",
    "need not equal @xmath21.,scaledwidth=80.0% ]    with adequate thresholds and good uncertainties , we now evaluate the trade - off between proofreading effort and proofreading quality using different focused proofreading heuristics in figure [ fig : vitrends ] .",
    "we consider only the over - segmentation vi since the under - segmentation error is small and minimally impacted by our merge - only technique ( under - segmentation proofreading will be discussed in the next section ) .",
    "for these tests , proofreading effort is determined by automatically deciding on each edge presented .     * improvements in vi over - segmentation similarity metric as a function of proofreader decisions . *",
    "four ordering strategies are considered .",
    "a ) shows slightly faster improvement using volume - based decision compared to using only edge confidence when considering volume vi .",
    "b ) shows significantly faster improvement to synapse vi using synapse - based decisions .",
    "this suggest that the edge probabilities are probably biased and more confident for larger bodies , not particularly useful when measuring connectivity that involves smaller processes.,scaledwidth=100.0% ]    in figure [ fig : vitrends]a , we show volume vi trends .",
    "expectedly , the focused strategy that uses synapses for guidance does not do a good job improving the volume vi .",
    "the two volume - guided focused strategies , volume - local and volume - path , do much better .",
    "volume - local only considers local bodies when making a decision . both perform similarly though volume - path achieves slightly lower vi by having a slightly longer cut - off .",
    "we compared these approaches to a straightforward technique of using just edge probabilities .",
    "the most confident false edges are chosen first .",
    "this results in slightly worse , but comparable , results under @xmath88 decisions",
    ". however , more improvements are possible if one is willing to examine more edges .",
    "does this suggest that simple edge ordering is potentially sufficient ?",
    "first , focused proofreading explicitly chooses a stopping condition that trades - off errors .",
    "the simplistic stopping condition for just using edge probability could result in a lot of unnecessary work .",
    "second , it appears that edges between big bodies ( presumably where there is more boundary evidence ) have more confidence .",
    "this is apparently not the case for the smaller processes often important in tracing synapses .",
    "the synapse vi plot in figure [ fig : vitrends]b , shows that the synapse - guided mode is much better than all of the other techniques . we note that random decision heuristics ( not shown ) perform much much worse than the above strategies .     shows the improvement to the over - segmented vi metric after performing the workflow of volume plus synapse focused proofreading .",
    "a ) shows changes to volume vi ( log scale ) .",
    "b ) shows changes to synapse vi ( log scale ) .",
    "in both cases , the distribution shifts to the right indicating improvement at the per body level .",
    "the largest outliers are being improved.,scaledwidth=100.0% ]    figure [ fig : vihist ] shows the distributions of over - segmented bodies before and after proofreading for one of our random runs .",
    "we perform volume - path followed by synapse focused proofreading .",
    "the @xmath68-axis is the @xmath89 of the vi .",
    "notice that for both volume and synapse vi , the distribution decisively shifts to the right after focused proofreading indicating that the worst bodies improved  the goal of focused proofreading .    in general , the ordering of focused proofreading strategies seems to have a small effect on the final similarity and effort required .",
    "we notice a small , but statistically significant reduction in all @xmath74 trials in the number of examined edges of around @xmath90 when performing volume focused proofreading before synapse focused proofreading compared to trying synapse guidance first .",
    "we also noticed a small increase in the average edge size of around @xmath91 when performing volume focused proofreading first .",
    "we speculate that edges of larger size are generally easier for a proofreader to evaluate since there is more edge evidence . for these reasons ,",
    "we decide to perform volume proofreading first .",
    "we deployed the focused proofreading strategies in a practical workflow to densely reconstruct seven columns of the drosophila medulla optic lobe  about @xmath92 cubic microns of em data .",
    "the reconstruction work described here ( for synapse annotation times see @xcite ) was primarily completed within 6 months . to perform this work",
    ", we have a staff of 5 - 10 trained proofreaders .",
    "we first compare the decisions between multiple proofreaders on a subvolume and achieve agreement rates slightly over @xmath93 .",
    "the high consistency is motivation for applying only one proofreader per subvolume , followed by quality control that exploit biological priors and spot checking by senior biological experts .",
    "while some specific pathways were revised by subsequent spot checking , we note that many motifs and connectivity patterns were unchanged .    .",
    "[ tab:7col ] breakdown of proofreading effort in seven column medulla reconstruction ( ignores time to annotate synapses and downstream quality control ) . focused",
    "proofreading includes body and synapse vi , as well as , orphan tracing .",
    "synapse qc involves verifying and fixing some local connectivity anomalies observed in the data .",
    "body split is when under - segmentation is fixed .",
    "all of these tasks are performed on subvolumes 125 microns in size . [ cols=\"<,>,>,>,>\",options=\"header \" , ]     we report the time to proofread the seven column medulla in table [ tab:7col ] .",
    "proofreading was performed over @xmath94 subvolumes each @xmath95 cubic microns and assigned randomly to the proofreaders . the column session hrs gives the amount time taken to complete the task .",
    "working hrs gives the amount of time that the proofreader interacted with the proofreading tool ( attempting to normalize for normal work distractions and circumstances where a proofreader needs to ask for help ) .",
    "the ratio of working hours to session hours gives the efficiency .",
    "in general , 100% efficiency is only possible for a robot .",
    "frustratingly challenging tasks tend to have a lower efficiency .",
    "this could also be seen as a _",
    "frustration factor_. microns / day gives the rate of cubic microns per session hour .",
    "we show results for the following tasks : focused proofreading ( also includes the effort for orphan tracing ) , synapse qc , and body split .",
    "synapse qc has proofreaders review synaptic connections that seem suspicious , such as autapses .",
    "body split shows the time required to fix under - segmentation errors detected while focus proofreading . despite each subvolume",
    "requiring only 10s of splits , the task is time - consuming and has reduced efficiency .    comparing our reconstruction efforts to the work in @xcite",
    "is difficult since the dataset in @xcite was produced using serial section tem imaging resulting in a lower quality of segmentation .",
    "the rate for proofreading subvolumes in @xcite is around 10 - 20 microns per day ( unpublished ) .",
    "we believe the proofreading in this paper to be more comprehensive and results in a rate 3 - 5 times faster .",
    "while much of the improvement likely stems from improved segmentation , our methodology is much more focused , systematic , and less frustrating .",
    "the time - consuming nature of em reconstruction stymies our ability to understand larger , complex neurological systems .",
    "this paper introduces a strategy called focused proofreading to greatly improve reconstruction speed allowing the analysis of much larger regions .",
    "we demonstrated the effectiveness by reconstructing a complete connectome from a region of the drosophila optic lobe , the largest such reconstruction ever performed .",
    "the proposed workflow is amenable to large - scale , crowd - sourcing efforts .",
    "this work is one of the first to focus on the quality of the uncertainty estimates of the segmentation engine , rather than just the resulting segmentation .",
    "future work should be directed at optimizing these confident intervals .",
    "furthermore , this work pioneers efforts at using biological priors and synaptic connectivity to guide proofreading process .",
    "we believe exploiting more biological rules or priors can lead to great speedups .",
    "finally , this work emphasizes the need to decompose a complex task ( proofreading ) into a series of digestable decisions . additional work on improving visualization and making the task accessible to an even larger workforce should be explored .",
    "j. funke , b. andres , f. hamprecht , a. cardona , m. cook , `` efficient automatic 3d - reconstruction of branching neurons from em data . '' _ proc .",
    "ieee conference on computer vision and pattern recognition _",
    ", 2012 , pp . 10041011 .",
    "j. nunez - iglesias , r. kennedy , t. parag , j. shi , d. chklovskii , `` machine learning of hierarchical clustering to segment 2d and 3d images , '' _ plos one _ , august 2013 , 8(8 ) : e71715 .",
    "doi : 10.1371/journal.pone.0071715",
    ".            s. plaza , l. scheffer , m. saunders , `` minimizing manual image segmentation turn - around time for neuronal reconstruction by embracing uncertainty , '' _ plos one _ , september 2012 , 7(9 ) : e44448 .",
    "doi : 10.1371/journal.pone.0044448              * acknowledgements : * we thank zhiyuan lu for sample preparation , shan xu and harald hess for fib - sem imaging ; pat rivlin , shin - ya takemura , and the flyem proofreading team ( roxanne aniceto , lei - ann chang , shirley lauchie , mathew saunders , christopher sigmund , satoko takemura , julie tran ) for biological guidance and the reconstruction efforts ; donald olbris for help with the proofreading tools ; louis scheffer and toufiq parag for useful discussions and suggestions ; and ting zhao for visualizations ."
  ],
  "abstract_text": [
    "<S> identifying complex neural circuitry from electron microscopic ( em ) images may help unlock the mysteries of the brain . </S>",
    "<S> however , identifying this circuitry requires time - consuming , manual tracing ( proofreading ) due to the size and intricacy of these image datasets , thus limiting state - of - the - art analysis to very small brain regions . </S>",
    "<S> potential avenues to improve scalability include automatic image segmentation and crowd sourcing , but current efforts have had limited success . in this paper , we propose a new strategy , focused proofreading , that works with automatic segmentation and aims to limit proofreading to the regions of a dataset that are most impactful to the resulting circuit . </S>",
    "<S> we then introduce a novel workflow , which exploits biological information such as synapses , and apply it to a large dataset in the fly optic lobe . with our techniques , we achieve significant tracing speedups of 3 - 5x without sacrificing the quality of the resulting circuit . </S>",
    "<S> furthermore , our methodology makes the task of proofreading much more accessible and hence potentially enhances the effectiveness of crowd sourcing . </S>"
  ]
}