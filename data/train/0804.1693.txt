{
  "article_text": [
    "convex and concave functions appear naturally in many branches of science such as biology ( growth ) , medicine ( dose - response ) , or economics ( utility , production or costs ) , spurring in turn the interest of other areas , for example , statistics .",
    "it is no surprise , then , that many problems of theoretical and practical interest involve the optimization of a functional over a family of convex functions .",
    "a particularly important case is when the functional to be minimized is the norm of some normed function space @xmath1 , i.e. , given @xmath2 find @xmath3 where @xmath4 is a family of convex functions in @xmath1 .",
    "typical choices are the spaces @xmath5 or @xmath6 , and , in general , the @xmath7 spaces , where @xmath8 is a convex domain in @xmath9 .",
    "sometimes the convexity is a reasonable shape assumption on the model , which could be replaced by or added to other shape constraints such as radial symmetry , harmonicity or upper and lower bounds .",
    "this is the case , for example , of newton s problem of minimal resistance ( see , e.g. , @xcite ) .",
    "more surprisingly perhaps , the convexity constraint may be a consequence of the model , as in the design of some mechanisms in economics  @xcite .",
    "actually , our interest in the subject arose from one of these problems , which we will call the _ monopolist problem _ , and is described in some detail in section  [ sec : economics ] . in this problem",
    "we wish to find @xmath10 where @xmath11^d$ ] , @xmath12 is a non - negative probability density function over @xmath13 , and @xmath4 is a family of convex functions on @xmath13 with some further properties .",
    "the monopolist problem is numerically very challenging since , unlike the problems coming from physics , the space dimension @xmath14 may be much higher than @xmath15 or @xmath16 .",
    "there is a big qualitative jump going from one to more dimensions when dealing with convexity constraints .",
    "this can be appreciated readily by looking at the statistics literature , where the one dimensional convex regression or density problem has been considered both theoretically and numerically , and using different measuring functionals ( see , e.g. , @xcite ) , but very little has been done numerically in two or more dimensions . in this regard ,",
    "it is worth mentioning the work by shih , chen and kim  @xcite , who use appropriate splines in the mars ( multivariate adaptive regression splines ) algorithm .",
    "one of the main difficulties in obtaining discrete approximations to optimization problems over convex functions lies in giving a local and finite description of convex functions if @xmath17 .",
    "though this could be done for smooth functions of continuous variables by asking the hessian matrix to be positive semidefinite at all points , there is no similar characterization for discrete functions on meshes . as a matter of fact",
    ", we show in examples  [ example : hessnoconv ] and  [ example : convnohess ] that this can not be done easily .",
    "it goes without saying that there is a lot of work done on convex functions of continuous variables , as exemplified by the classical book by rockafellar  @xcite .",
    "traditionally , this work leans more on properties satisfied by convex functions rather than on properties that imply convexity .",
    "in particular , very little has been done on local properties guaranteeing convexity .    for discrete variables ,",
    "there is a rather large work done by the discrete mathematics community for fixed lattices , and a number of definitions for discrete convex functions have been proposed ( see , e.g. , @xcite ) .",
    "again , usually these definitions are non - local .",
    "as far as we know , there exists very few literature on optimization problems on convex functions in dimensions two or more , either theoretically or numerically .",
    "besides those already mentioned ( and the references therein ) , let us cite three more which are prominent in the context of our work .",
    "* carlier and lachand - robert  @xcite obtained the @xmath18 regularity of a variant of the monopolist problem , substituting the functional in   for @xmath19 under some restrictions on the domain @xmath8 and the density @xmath12 .",
    "they obtained also @xmath18 regularity for convex minimizers of functionals of the form @xmath20 * carlier , lachand - robert and maury  @xcite proposed a numerical scheme for minimizers of functionals of the type @xmath21 on closed convex subsets of convex functions of @xmath6 or @xmath5 , where @xmath22 is a quadratic function of @xmath23 and @xmath24 , and @xmath25 .",
    "we will discuss their approach in the next section ( after the inequalities  ) . + as carlier et al .",
    "@xcite point out , their work encompasses the problem of finding @xmath26 for given @xmath27 , i.e. , a @xmath28-norm projection , and this problem is equivalent to that of finding the convex envelope @xmath29 of @xmath12 .",
    "thus , minimizing over convex functions and finding the convex envelope of a function are two quite related tasks . *",
    "being one of the main problems in computational geometry , there are a number of well established codes for finding the convex hull of a set of points in @xmath9 , which are very efficient in low dimensions .",
    "hence , it is natural to try to use these codes to approximate optimization problems on convex functions , an approach which lachand - robert and oudet  @xcite applied to several problems .",
    "+ it would be very interesting to see whether these ideas could be carried over , since the convex hull codes are quite fast in low dimensions .",
    "our approach , based on semidefinite programming , takes a different direction from those mentioned .",
    "let us recall that a semidefinite program is an optimization problem of the form @xmath30 where @xmath31 , @xmath32 are symmetric @xmath33 matrices , and @xmath34 indicates that the symmetric matrix @xmath35 is positive semidefinite . by letting the matrices",
    "@xmath36 be diagonal , we see that the program   is a generalization of linear programming ( and includes it strictly ) .",
    "thus , in a semidefinite program the constraints can be a mixture of linear inequalities and positive semidefinite requirements .    in this paper",
    "we give a theoretical framework for approximating many optimization problems on convex functions using a finite differences scheme which imposes a positive semidefinite constraint on a discretization of the hessian matrix .",
    "although not linear , our approach seems very natural and has many advantages .",
    "being of a local nature , the number of constraints grows only linearly with the number of nodes , and it works for any dimension of the underlying space . notwithstanding the already mentioned counterexamples ( [ example : hessnoconv ] and  [ example : convnohess ] ) of the relation between convexity and positive semidefinite hessian , we will show that for many problems we obtain convergence to a continuous optimum .",
    "this convergence holds even for non - smooth optima , as those arising when projecting in the @xmath37 norm or in some problems of the type given by equation  .    in practice",
    ", our definition can be used to advantage by using the existing efficient semidefinite codes and , furthermore , it is very simple to program in higher dimensions .    as a final remark",
    ", we think that our approach might be a first step to deal with other problems where convexity is a consequence of the model , such as transportation problems where the cost is quadratic , i.e. , for solving the monge - ampre equations , a prime example of fully non - linear differential equations .",
    "this article is organized as follows .    in section  [ sec : review ] we summarize some techniques that could be used to deal with the numerical approximation of optimal convex functions , showing their strengths and weaknesses , and introduce the discrete hessian .",
    "in section  [ sec : convex : cont ] we give different characterizations of smooth convex functions of continuous variables , which allow us to extend the definition of the hessian to @xmath18 functions in terms of averages .",
    "the heart of the paper is section  [ sec : approxs ] : in order to have a good definition of discrete convexity , we need to show that any convex function of continuous variables may be approximated by its discrete counterparts , and conversely , that a converging sequence ( in a suitable norm ) of discrete convex functions will do so to a convex function of continuous variables .",
    "we show in this section that the approximation of the discrete functions to the limit @xmath23 is uniform in @xmath23 and its derivatives if @xmath23 is smooth , and uniform in @xmath23 over compact subsets of @xmath8 , if @xmath23 is merely convex and bounded ( and hence continuous ) .",
    "although our definition is stated using the hessian , if a sequence of discrete functions converges to a function which is not @xmath38 or even @xmath18 , still convexity of the limit function is guaranteed .",
    "in section  [ sec : functionals ] we pose a general structure for optimization problems on convex functions which fits the results of the previous sections , and may be applied to several important problems . in addition , error bounds may be obtained if the continuous optimal solution is smooth .",
    "the results of sections  [ sec : convex : cont][sec : functionals ] are somewhat independent of semidefinite programming .",
    "however , as explained in section  [ sec : review ] , for many problems of interest the functional and constraints involved may be expressed as a semidefinite program , and we present in section  [ sec : numerical ] numerical examples showing that the current codes make it feasible to use our scheme on them .",
    "we begin section  [ sec : numerical ] by considering the monopolist problem in two and three dimensions , comparing our results to the analytical solution when @xmath39 in  .",
    "we continue by showing some norm projections , exploring the behavior under different functionals of an example given by carlier , lachand - robert and maury  @xcite .",
    "moreover , we exhibit an explicit example in which the @xmath37 projection is not unique .",
    "we finish the section on numerical examples by showing how our scheme could be used to fit a ( discrete ) convex function to noisy data given on the nodes of a regular mesh , using the @xmath28 norm ( i.e. , a least squares approach ) , and also the @xmath40 and @xmath37 norms , which are not often seen .",
    "in this section we present some ideas and techniques that could be used to approximate numerically an optimal convex function . for the sake of simplicity , we will work on the unit @xmath14-dimensional cube in @xmath9 , @xmath11^d$ ] .",
    "if @xmath41 and @xmath42 is a discretization of @xmath43 $ ] , then a convex function @xmath23 defined on @xmath43 $ ] satisfies the inequalities @xmath44    conversely , if a function @xmath23 defined only in the mesh points @xmath45 satisfies the inequalities  , we can always extend it linearly in the intervals @xmath46 $ ] , @xmath47 , so that the resulting piecewise linear function will be convex on @xmath43 $ ] .    thus , the inequalities   may be used to define discrete convexity in one dimension .",
    "it is clear that  via the piecewise linear extension  we can approximate any convex function in @xmath43 $ ] . on the other hand ,",
    "as we show in lemma  [ lemma:1d : convergence:1 ] , under some adequate assumptions if a sequence of discrete convex functions ( satisfying   for each corresponding subdivision ) converges pointwise , then the limit defines a unique convex function in @xmath43 $ ] .",
    "let @xmath48 be given , @xmath49 , and suppose @xmath50 is a subdivision of @xmath43 $ ] satisfying   and such that @xmath51 let @xmath23 be defined on @xmath52 and satisfy  .",
    "for a given @xmath53 , @xmath54 , let us consider @xmath55 from   we see that @xmath56 for all @xmath57 such that @xmath58 , @xmath59 .",
    "therefore , if @xmath60 we have @xmath61 where @xmath62 and @xmath63 are constants depending only on @xmath53 and @xmath64 ( but not on @xmath23 or @xmath52 ) . in other words , if @xmath23 is extended as a piecewise linear function to all of @xmath43 $ ] , the resulting function is uniformly lipschitz on compact subsets of @xmath65 .",
    "hence ,    [ lemma:1d : convergence:1 ] let @xmath66 be a sequence of meshes in @xmath43 $ ] , @xmath67 , satisfying   for each @xmath48 , and such that @xmath68 for @xmath69 .",
    "suppose @xmath70 is defined in @xmath71 for each @xmath48 , and the sequence @xmath72 is such that for all @xmath73 , @xmath74 exists and is finite , and let @xmath75    then @xmath23 may be extended to all of @xmath43 $ ] as a continuous convex function in a unique way . moreover , the convergence of @xmath70 ( extended piecewise linearly ) to @xmath23 is uniform in compact subsets of @xmath65 .",
    "also , by the arzela - ascoli theorem ,    [ lemma:1d : convergence:2 ] let @xmath66 be a sequence of meshes as in the previous lemma .",
    "suppose @xmath76 is given , and that for each @xmath48 a function @xmath70 is defined in @xmath71 so that @xmath77 and assume @xmath70 is extended to all of @xmath43 $ ] piecewise linearly .",
    "then , there exists a subsequence of @xmath78 of @xmath79 converging to a continuous convex function @xmath23 defined on @xmath43 $ ] .",
    "moreover , the convergence of the subsequence @xmath78 to @xmath23 is uniform in compact subsets of @xmath65 .",
    "thus , from a theoretical point of view , the discrete functions satisfying   are well understood .    from the numerical point of view , when used in a discretization of an optimization problem , the constraints coming from the inequalities   are linear , and solving the resulting discrete optimization problem with them is usually not much harder than solving it without them .",
    "hence , the case @xmath41 poses no major trouble .",
    "for @xmath17 it will be more convenient to work only with regular meshes ( or grids ) on @xmath11^d$ ] .",
    "thus , for fixed @xmath80 ( @xmath81 for some @xmath82 ) , the mesh @xmath71 will consist of all points @xmath83 of the form @xmath84 with @xmath85 . denoting by @xmath86 the interior of @xmath13 , we set @xmath87 and denote by @xmath88 the set of real valued functions defined on @xmath71 .",
    "a first simple idea to extend the inequalities   to more dimensions , is to consider the set of functions @xmath89 satisfying the convexity constraints @xmath90 where @xmath91 denotes the @xmath92-th vector of the canonical basis of @xmath9 .",
    "this set of discrete functions is very appealing because the convexity is modelled by using only @xmath93(number of mesh points ) linear constraints , as in the case @xmath41 . as we have seen , this approach is exact in one dimension , and gives satisfactory results in many cases in more dimensions ( in particular for some of the specific examples treated later in section  [ sec : economics ] ) , but there is no guarantee of convexity in the limit function if @xmath17 .",
    "in fact , by taking the interpolant , with this set we can certainly approximate any function of continuous variables which is convex , but we can also approximate other functions .",
    "for example , we may approximate @xmath94 which is linear  and thus convex  in each coordinate direction , but not convex in @xmath95 .",
    "this shows that the definition of discrete convexity should be done with more care : when @xmath17 , we have to take into account every possible direction .",
    "it is reasonable , then , to say that a discrete function is convex if @xmath96 since as @xmath48 goes to @xmath97 the possible directions become dense , it is possible ( under some conditions ) to regain convexity in the limit as we had for one dimension .    in a way , this is the approach followed by carlier , lachand - robert and maury  @xcite . in a two dimensional setting , they consider discrete convex functions which are restrictions to a mesh of convex functions of continuous variables , and show that this definition is equivalent to an intrinsic one , stated only in terms of the value of the function at the grid points , similar to  .",
    "the problem with this description is that it is non - local , and the number of constraints needed in two dimensions ( after pruning ) reportedly grows approximately as @xmath98 , where @xmath99 is the number of nodes in the grid .",
    "moreover , this approach is very difficult to extend to higher dimensions .    in order to keep the definition of discrete convexity local ,",
    "another possibility is to consider discretizations of the hessian matrix , as we do in this work .    for @xmath100 and @xmath101 , we define the ( forward ) first order finite differences by @xmath102 and the second order finite differences by @xmath103 or , if @xmath104 , by @xmath105    clearly , not all of these finite differences are defined for points in @xmath106 . therefore , when mentioning @xmath107 or @xmath108 for @xmath101 , we will implicitly assume that @xmath109 and @xmath92 ( and eventually @xmath22 ) are such that the corresponding finite difference is well defined at @xmath109 .",
    "finally , we define the discrete hessian of @xmath100 at @xmath110 , as the symmetric matrix @xmath111 whose @xmath112 entry is @xmath113 .",
    "we are faced now with two issues :    how can a discrete optimization problem with positive semidefinite discrete hessian constraints be solved ?",
    "once we found a discrete solution , how does it approximate the continuous solution ?    as mentioned in the introduction , for the first issue we will use the semidefinite programming model  , where the objective is linear and the constraints are positive semidefinite .",
    "thus , if the objective of the continuous problem is not linear , we must rewrite it as a constraint",
    ". however , it is worth mentioning that not every functional may be readily modelled as a positive semidefinite constraint , an example of such functionals being @xmath114 arising in newton s problem of minimal resistance .",
    "although this method may not be used for _ all _ functionals , it can be used in _",
    "many _ cases as we now illustrate .",
    "the interested reader is referred to the article by vandenberghe and boyd  @xcite for other possibilities .    in what follows we associate with each mesh node @xmath115 , @xmath116 , the unknown value @xmath117 , the discrete hessian @xmath118 , and a @xmath14-dimensional cube @xmath119 centered at @xmath115 of measure @xmath120 , so that @xmath121 .",
    "the program @xmath122 subject to @xmath23 convex , is modeled by adding @xmath99 more unknowns @xmath123 ( for a total of @xmath124 ) as @xmath125    in turn , the constraints of the form @xmath126 are lumped as @xmath127 , and finally modeled as the linear inequalities @xmath128    this is analogous to the @xmath40 projection : @xmath129 and the constraints of the form @xmath130 are written in the form @xmath131    the @xmath132 projection is handled in a similar way .",
    "this is analogous to the other projections , except that we only need to add one more variable @xmath133 ( instead of @xmath99 ) , obtaining the discrete program @xmath134    the next issue is to see how well the discrete solutions of the semidefinite program approximate the continuous convex solution .",
    "our first hope is that @xmath135 will be equivalent to some version of convexity of discrete functions , for example to the one given by the inequalities  .",
    "the next examples show that this is not true .",
    "the first one shows that a non - convex function may have a positive semidefinite discrete hessian , and the second one shows that the discrete hessian may not be positive semidefinite for some convex functions .",
    "[ example : hessnoconv ] let us consider @xmath136 , and @xmath23 defined on the 2-dimensional @xmath137 grid @xmath138 by @xmath139    we may check that ( with @xmath140 ) , @xmath141 whose eigenvalues are @xmath15 and @xmath97 ( with eigenvectors @xmath142 and @xmath143 ) , and is thus positive semidefinite .",
    "however , the restriction to the diagonal @xmath144 is not convex : @xmath145    notwithstanding these examples , in section  [ sec : approxs ] we will show that , under suitable conditions , by asking for positive semidefinite discrete hessians we may conveniently approximate continuous convex functions , and obtain variants of lemmas  [ lemma:1d : convergence:1 ] and  [ lemma:1d : convergence:2 ] .    however",
    ", we will need some previous results which are tackled in the following section .",
    "in this section we deal with variants of the hessian matrix , initially defined for @xmath38 functions , which allow us to characterize convexity for @xmath18 functions locally .",
    "let us start by introducing some more precise notation :    the distance from a point @xmath109 to a set @xmath35 will be denoted by @xmath146 .    if @xmath147 and @xmath80 , @xmath148    the gradient of @xmath23 is denoted by @xmath149 , and we write @xmath150 for @xmath151 .",
    "if @xmath152 is an open set , we denote by @xmath153 the set of functions having all derivatives up to order @xmath154 continuous on @xmath8 , and by @xmath155 the set of functions having all derivatives up to order @xmath154 uniformly continuous in @xmath8 .",
    "if @xmath8 is omitted , @xmath156 .",
    "let @xmath157 be a non - negative , real valued function in @xmath158 , vanishing outside @xmath159 , and such that @xmath160 and for @xmath161 define @xmath162 the function @xmath163 defined for functions @xmath23 and points @xmath109 whenever the right hand side makes sense , has many interesting well known properties , and we state some of them without proof , referring the reader to , e.g. , the book by ziemer  ( * ? ? ?",
    "* theorem  1.6.1 and remark  1.6.2 ) .",
    "[ theorem : ziemer ]    if @xmath164 , then for every @xmath161 , @xmath165 and @xmath166 for every multi - index @xmath167 , where for @xmath168 , @xmath169 .    if @xmath170 then @xmath171 is defined for @xmath172 and @xmath173 .",
    "@xmath174 whenever @xmath109 is a lebesgue point of @xmath23 .",
    "if @xmath175 , and @xmath176 is a compact subset of @xmath8 , then @xmath177 converges uniformly to @xmath23 on @xmath176 as @xmath178 .",
    "the functions @xmath177 , also called regularizations or mollifiers of @xmath23 , will make us work often with the sets @xmath179 where @xmath180 , @xmath181 .",
    "our first result is a simple characterization of continuous convex functions using the regularizations @xmath177 , and we omit its proof .",
    "[ lemma : cont:1 ] suppose @xmath182 and @xmath177 is defined as in  .",
    "we have ,    if @xmath23 is convex , then @xmath177 is convex in @xmath183 for all @xmath161 .",
    "conversely , if for a sequence of @xmath53 s converging to @xmath97 , @xmath177 is convex in @xmath183 , then @xmath23 is convex .",
    "the hessian of @xmath184 at @xmath109 is the symmetric matrix @xmath185 whose @xmath186 entry is @xmath187 , and convex functions in @xmath38 are characterized by the positive semidefinite condition @xmath188    also , for @xmath184 , and @xmath189 , the average @xmath190 defined for @xmath191 , converges to @xmath192 for all @xmath193 , as @xmath194 .",
    "thus the condition @xmath195 implies the convexity of @xmath23 .",
    "actually , since the average of positive semidefinite matrices is positive semidefinite , is equivalent to convexity for @xmath196 .",
    "the definitions of @xmath197 and @xmath198 involve second order derivatives which are not defined if @xmath23 is not smooth enough .",
    "however , we may express @xmath198 merely in terms of @xmath23 and @xmath24 integrating by parts , and the resulting formula will make sense for @xmath199 .",
    "thus , for @xmath200 and @xmath191 let us define @xmath201 as the symmetric @xmath202 matrix whose diagonal entries are    [ equs : cont:2 ] @xmath203 and , if @xmath104 , @xmath204      -      \\int_{f^{-}_{\\delta , i}(x)\\cap f^{+}_{\\delta , j}(x ) } u(y)\\,{\\mathrm{d}}{y }        + \\int_{f^{-}_{\\delta , i}(x)\\cap f^{-}_{\\delta , j}(x ) } u(y)\\,{\\mathrm{d}}{y }        \\bigr),\\end{gathered}\\ ] ] where @xmath205 denotes the @xmath206 dimensional face of the cube @xmath207 having outward normal @xmath208 .    of course ,",
    "since the equations   were obtained integrating by parts , we have :    [ lemma : cont:2 ] if @xmath184 then @xmath209 .    as we show now",
    ", the extension @xmath210 of @xmath211 to functions in @xmath18 , still gives a local characterization of convexity .",
    "[ theorem : cont:1 ] the following are valid if @xmath200 :    if @xmath23 is convex , then @xmath212 for all @xmath189 and @xmath191 .",
    "if for a sequence @xmath213 , @xmath214 for all @xmath215 , then @xmath23 is convex .",
    "suppose @xmath200 , and consider the regularization @xmath177 defined in  . since we can interchange derivatives and integrals with the convolution , @xmath216    if @xmath23 is convex , by the first part of lemma  [ lemma : cont:1 ] we know that @xmath177 is convex in @xmath217 , and since @xmath218 , for @xmath219 we have @xmath220 .",
    "thus , by lemma  [ lemma : cont:2 ] , @xmath221 using theorem  [ theorem : ziemer ] , since @xmath177 and their derivatives converge uniformly to @xmath23 in compact subsets of @xmath222 , we must have @xmath223 for @xmath109 in compact subsets of @xmath224 , and therefore in the whole of @xmath224 .    on the other hand ,",
    "if @xmath225 for @xmath191 , since an integral mean of positive semidefinite matrices is positive semidefinite , using   and lemma  [ lemma : cont:2 ] , we see that @xmath226 which implies that @xmath177 is convex in @xmath227",
    ". letting @xmath228 go to @xmath97 while keeping @xmath53 fixed , we see that @xmath177 is convex in @xmath183 , and by the second part of lemma  [ lemma : cont:1 ] , @xmath23 must be convex .",
    "there are two main issues when defining the set of discrete approximants to be used :    we want it to be rich enough to approximate every convex function , and    we want this set to be not too large , to avoid convergence to non - convex functions .",
    "the first point is very natural , and necessary to approximate the solution to the problem .",
    "the second point might look artificial at first sight , but if not enforced , then we could be approximating a non - convex function .",
    "this is the case , for instance , if we only require convexity along the coordinate axes , as we stated in section  [ sec : review ] .",
    "our discrete approximations will be a subset of functions having positive semidefinite discrete hessians , and the main purpose of this section is to address the two issues mentioned above .",
    "we will show in theorem  [ theorem : discrete : approx ] that , despite the examples  [ example : hessnoconv ] and  [ example : convnohess ] , the discrete hessian @xmath229 may be used to obtain very good approximations to convex functions of continuous variables .",
    "this is not surprising since we can approximate , say , @xmath230 , by discrete functions whose finite differences up to order @xmath15 converge to the derivatives up to order @xmath15 of @xmath23 , and then add a small perturbation to bring up the eigenvalues of the discrete hessians .",
    "this is the main idea of the proof , and in its course , we will use the following part of the hoffman - wielandt theorem  @xcite .    [",
    "theorem : hoffman ] there exists a positive constant @xmath231 , depending only on the dimension @xmath14 , such that if @xmath232 $ ] and @xmath233 $ ] are symmetric @xmath234 matrices , and @xmath235 and @xmath236 are their minimum eigenvalues , then @xmath237    [ theorem : discrete : approx ] let @xmath230 be convex .",
    "then , for any @xmath161 , there exists @xmath238 such that for any @xmath48 , @xmath239 , there exists a function @xmath70 defined on @xmath71 satisfying for all @xmath101 , @xmath240 and @xmath241    let us recall that in the inequality  , for @xmath242 we consider only the finite differences that are defined at that @xmath109 .",
    "if @xmath23 is convex and smooth , given @xmath243 there exists @xmath244 such that for all @xmath245 and @xmath246 , @xmath247 where @xmath231 is the constant in theorem  [ theorem : hoffman ] .",
    "hence , since @xmath23 is convex and therefore @xmath248 , the minimum eigenvalue of @xmath249 is uniformly bounded below by @xmath250 .",
    "now consider the function @xmath251 for which , if @xmath48 small enough , @xmath252 where @xmath253 is the identity matrix in @xmath254 .",
    "if @xmath255 , the function @xmath256 defined on @xmath71 , satisfies @xmath257 and @xmath258    thus , for some constant @xmath259 depending only on @xmath14 , the inequality   holds with @xmath53 replaced by @xmath260 .",
    "the result follows now by taking @xmath261 and @xmath262 appropriately .    the main implication of theorem  [ theorem : discrete : approx ] is that any smooth convex function is a limit of a sequence of functions with positive semidefinite discrete hessians , giving an affirmative answer to the first issue mentioned at the beginning of this section .",
    "moreover , an application of lemma  [ lemma : cont:1 ] implies this result also for non - smooth convex functions , with convergence in @xmath263 on compact subsets of @xmath8 ( see definitions below ) .",
    "we would like to show next that our set of approximants also solves the second issue .",
    "that is , if we have a convergent ( in certain norm ) sequence of functions with positive semidefinite discrete hessians , then the limit is convex . on the other hand ,",
    "if the sequence is not convergent , we would like also to understand under which further conditions on the sequence we may extract a subsequence converging to a convex function .    in what follows , we will work with sequences of functions defined on finer and finer meshes , that is , sequences @xmath264 with @xmath265 for every @xmath266 , such that @xmath267 and @xmath268 decreases to @xmath97 .",
    "we will denote by @xmath269 the set of all such sequences , and use the notation @xmath270 so as not to clutter even more the notation , usually we will drop the index @xmath266 , writing @xmath271 for @xmath272 , when this does not lead to confusion .",
    "if @xmath273 and @xmath274 , we will say that @xmath275 if for any @xmath161 , there exists @xmath276 , so that @xmath277 for all @xmath278 and @xmath279 , that is , @xmath280 as @xmath281 .",
    "in this case we will write , with a little abuse of notation , @xmath282    if in addition @xmath199 , we write , similarly , @xmath283 to indicate that @xmath284 and @xmath285 uniformly for all @xmath286 for which the finite differences make sense and @xmath287 .",
    "[ lemma : discrete : convergence ] suppose @xmath288 and @xmath199 are such that @xmath289 and @xmath290 then @xmath23 is convex .",
    "we follow closely what was done in section  [ sec : convex : cont ] , using a variant of the divergence theorem for discrete variables , so that only approximations to the function or its derivatives  but not the second derivatives  are needed .    for @xmath291 and @xmath292 ,",
    "let us define @xmath293 where the sum is over all @xmath294 such that @xmath295 .",
    "since the sum of positive semidefinite matrices is a positive semidefinite matrix , we have @xmath296    in one dimension we have just one entry in @xmath297 , involving a term of the form @xmath298 that is , if @xmath41 then @xmath299    if @xmath136 and @xmath300 , the diagonal entries are similar to the one dimensional case .",
    "for instance , @xmath301 where both sums are on @xmath154 s such that @xmath302 . on the other hand ,",
    "the off - diagonal terms are of the form @xmath303 where @xmath304    for @xmath305 we get similar expressions to those of equations   and   for the diagonal terms , and   for the off - diagonal terms , except that  as when going from   to  they must be summed over mesh points on @xmath206 dimensional surfaces perpendicular to the ( say ) @xmath92-th direction , or @xmath306 dimensional surfaces perpendicular to the ( say ) @xmath186 plane .",
    "this was also the case in the equations   for the continuous case , and so we can think of these sums as approximations to those integrals , where small @xmath14-dimensional cubes of side length @xmath48 centered at mesh points have been used . in order to do this we must multiply the entries by @xmath307 so as to obtain the correct dimensions .    in fact , since we are assuming @xmath308 and @xmath309 involves either no finite differences ( off the diagonal ) or only first order differences ( in the diagonal ) which converge uniformly to ( respectively ) @xmath23 or its first derivatives , @xmath310 where @xmath311 since the limit of positive semidefinite matrices is positive semidefinite .",
    "on the other hand , due to the convergence of @xmath70 to @xmath23 in the @xmath312 norm , we can see that , as @xmath67 , @xmath313 & \\qquad     -      \\int_{f^{-}_{\\delta , i}(x)\\cap f^{+}_{\\delta , j}(x ) } u(y)\\,{\\mathrm{d}}{y }        + \\int_{f^{-}_{\\delta , i}(x)\\cap f^{-}_{\\delta , j}(x ) } u(y)\\,{\\mathrm{d}}{y }        \\bigr),\\end{aligned}\\ ] ] if @xmath314 .",
    "thus , @xmath315 which implies @xmath316 for all @xmath291 .",
    "the result now follows from theorem  [ theorem : cont:1 ] .",
    "the convergence in @xmath317 should be guaranteed by the definition of the discrete problem and is problem dependent .",
    "we make now a general assumption on an algorithm to ensure convergence in @xmath317 .",
    "let us denote by @xmath318 the space of lipschitz continuous functions defined on @xmath13 , recalling that @xmath319 , the space of continuous functions having derivatives in the weak sense up to order one bounded . if @xmath320 , we let @xmath321 be the set of functions @xmath322 such that both @xmath323 for all @xmath245 and @xmath324 for all @xmath287 and @xmath325 whenever @xmath326 . of course , the condition @xmath324 is equivalent to @xmath327 .",
    "similarly , let us denote by @xmath328 the space of functions whose first derivatives are in @xmath318 , and by @xmath329 the set of all functions in @xmath330 which have all weak derivatives up to order @xmath15 bounded by @xmath331 . in particular , we have @xmath332 .    by analogy to the continuous case ,",
    "let us define for @xmath48 and @xmath331 positive the following spaces of discrete functions : @xmath333 with the understanding that on the right hand sides we take @xmath334 or @xmath335 for all @xmath336 and @xmath22 where it makes sense .",
    "the following result is a version of the arzela - ascoli theorem , and we omit its proof .    [",
    "theorem : arzela ] if @xmath273 for which @xmath337 for all @xmath80 , then there exists @xmath338 and a subsequence @xmath339 of @xmath340 such that @xmath341    combining the previous results , we have :    [ theorem : discrete : converge ] if @xmath273 is such that @xmath342 for all @xmath343 and @xmath80 , then there exists @xmath344 , and a subsequence @xmath339 of @xmath340 such that @xmath345    applying theorem  [ theorem : arzela ] to the functions @xmath346 , perhaps on some smaller meshes @xmath347 with @xmath348 , we may find functions @xmath349 and a subsequence of @xmath340 , @xmath339 , such that @xmath350    to show that there exists @xmath23 such that @xmath351 ( in the classical sense ) , we define for @xmath352 , @xmath353    since for @xmath287 , @xmath354 is bounded ( by @xmath331 ) and continuous , @xmath23 is well defined and continuous .",
    "using that @xmath355 converge uniformly to @xmath354 , for @xmath356 we may write @xmath357    but , for a given @xmath358 and all @xmath359 we have @xmath360 and therefore @xmath361    arguing as in equation   and taking limits , we may also verify the `` independence of path '' , that is , for @xmath362 and @xmath363 we may write , @xmath364    using the continuity of @xmath23 , we see that the last equation is valid for all @xmath193 and @xmath358 small enough , and , using once more the continuity of @xmath23 , that @xmath365 for all @xmath193 and all @xmath189 , and therefore @xmath366    the convexity of @xmath23 follows from lemma  [ lemma : discrete : convergence ] .    [ remark : noconvergenceof2 ] if @xmath367 is a sequence of convex functions converging pointwise to @xmath23 , then @xmath23 must be convex .",
    "however it is not true in general that the second derivatives or the hessian of @xmath367 will converge to that of @xmath23 , even if we have uniform convergence of @xmath367 and its derivatives to those of @xmath23 . in this sense ,",
    "theorem  [ theorem : discrete : converge ] can not be bettered too much .",
    "for example , consider in @xmath41 the functions @xmath368 and , with @xmath81 for @xmath82 , @xmath369    we have , @xmath370     0 \\le u_h'(x ) = u'(x ) - \\dfrac{\\sin ( \\pi",
    "n x)}{n\\pi } \\le 1 ,     &    \\lim_{h\\to 0}\\,u'_h(x ) = u'(x ) ,     \\end{array}\\ ] ] where the limits are uniform in @xmath109 . also ,",
    "@xmath371    taking @xmath372 , @xmath373 , for @xmath374 we obtain @xmath375 and so the second order differences at dyadic points converge to this constant value .",
    "however , also at these points , @xmath376 .     on the other hand , we may weaken the conditions on convergence , following what was done for the one - dimensional case in section  [ sec : review ] .    if @xmath70 is defined in @xmath71 and @xmath377 for @xmath101 , its restriction to the one - dimensional line obtained by fixing all coordinates except the @xmath92-th one , satisfies @xmath378 for @xmath287 , since these are coefficients in the main diagonal of @xmath379 .",
    "that is , the inequalities   are satisfied , and hence if for some @xmath76 , @xmath380 then for any given @xmath161 we may find a constant @xmath381 , depending on @xmath64 and @xmath53 but not on @xmath23 , such that @xmath382    therefore , by applying theorem  [ theorem : arzela ] to @xmath14-dimensional cubes contained in @xmath222 , we may strengthen lemma  [ lemma : discrete : convergence ] to obtain a variant of lemma  [ lemma:1d : convergence:1 ] :    [ corollary : discrete : convergence ] let @xmath383 such that @xmath384 and suppose @xmath23 is a ( finite ) function defined on @xmath385 satisfying @xmath386 then , the convergence of @xmath70 to @xmath23 is uniform on compact subsets of @xmath222 , and @xmath23 may be uniquely extended to a convex function defined on all of @xmath13 .",
    "similarly , we may weaken the conditions of theorem  [ theorem : arzela ] to obtain the following version of lemma  [ lemma:1d : convergence:2 ] :    [ corollary : arzela ] if @xmath76 and @xmath273 are such that @xmath387 then there exists a continuous convex function @xmath23 defined on @xmath13 and a subsequence @xmath339 of @xmath340 such that @xmath388 moreover , the convergence is uniform on compact subsets of @xmath222 .",
    "we conclude this section with some comments .    [",
    "remark : bdy ] if @xmath184 , @xmath187 is defined initially for @xmath193 , but the very definition of @xmath38 as the set of those functions in @xmath389 having second order derivatives uniformly continuous on @xmath222 , makes it possible to define @xmath187 for @xmath390 by a limiting argument .",
    "and the same goes for lower order derivatives , and even @xmath192 .",
    "the situation is different for discrete functions defined on @xmath71 for fixed @xmath80 , since we can not take limits .",
    "however , the particular geometry of @xmath13 makes it possible ( as we did ) to consider for @xmath242 as many finite differences as we can .",
    "for instance , @xmath391 is well defined for @xmath242 as long as @xmath392 .    pushing the definitions a little further",
    ", we may define the discrete hessian @xmath249 for @xmath393 , by including as many second derivatives as we can .",
    "for example ,",
    "if @xmath394 and @xmath140 , we can define @xmath395        \\operatorname{\\delta}^2_{h,12 } u(x ) & \\operatorname{\\delta}^2_{h,22 } u(x)\\\\[2pt ]        \\end{bmatrix }     & \\quad     & \\text{if $ x = ( 1/2,1/2,0)$},\\\\[14pt ]     h_h u(x )     =        \\begin{bmatrix }        \\operatorname{\\delta}^2_{h,11 } u(x )        \\end{bmatrix }     & & \\text{if $ x = ( 1/2,0,0)$ } ,     \\end{array}\\ ] ] leaving @xmath249 undefined if @xmath396 .",
    "as the reader may verify , our previous results involving @xmath229 remain valid with this interpretation of the discrete hessian .",
    "we are in position now to use finite difference approximations of a wide class of optimization problems on convex functions .",
    "let us describe this technique by assuming , for instance , that @xmath397 is a banach space of real valued functions on @xmath13 , the functional @xmath398 is defined and continuous on @xmath1 , and we are interested in the optimization problem @xmath399 where @xmath4 is a family of convex functions , @xmath400 .    if the functions in @xmath4 may be approximated by convex functions in @xmath401 , then using theorem  [ theorem : discrete : approx ] it may be not too difficult to define for each @xmath80 ( or a sequence converging to @xmath97 of such @xmath48 s ) , a family @xmath402 , @xmath403 , and a functional @xmath404 defined on @xmath402 , such that :    @xmath405 for all @xmath406 and @xmath110 ,    for any @xmath407 and any @xmath161 , there exists @xmath80 and @xmath408 such that @xmath409 .",
    "condition 2 immediately implies that @xmath410    to prove the converse , we observe that @xmath411 where @xmath412 . keeping @xmath320 fixed , we may find a sequence @xmath413 , with @xmath414 such that @xmath415 and using theorem  [ theorem : discrete : converge ] , a subsequence @xmath416 and a convex function @xmath417 with @xmath418 converging to @xmath97 .",
    "if @xmath419 and @xmath404 are such that @xmath420 letting @xmath421 we will have @xmath422    putting together the inequalities   and  , we will have discrete approximations of the problem  .",
    "let us give some more concrete examples .",
    "suppose , for instance that @xmath423 is the set of functions @xmath424 with finite norm @xmath425 and suppose @xmath4 is the set of all convex functions in @xmath132 .",
    "given @xmath2 we would like to find its projection on @xmath4 , that is , find @xmath426 such that @xmath427 and , getting rid of the square roots , we may set @xmath428    in this example we actually have a unique minimum , since the norm is strictly convex . we may consider then @xmath402 as the set of discrete functions @xmath429 with @xmath430 for all @xmath110",
    ".    assuming for simplicity that @xmath431 , for @xmath429 we define @xmath432    then , it is easy to see that   and   hold .",
    "in fact , the convex functions of @xmath1 may be approximated by @xmath433 convex functions , so that , given @xmath161 there exists @xmath434 such that @xmath435 and use theorem  [ theorem : discrete : approx ] to find @xmath48 small enough and @xmath406 such that @xmath436 thus we will have @xmath437 for some @xmath406 .",
    "in this section we illustrate the behavior of the numerical scheme by applying it to the problems mentioned in the introduction , namely , the monopolist problem , norm projections on the set of convex functions , and fitness of data by discrete convex functions .    in all of the following examples , we associate with each mesh node @xmath115 , @xmath116 , the unknown value @xmath117 , and the square @xmath438 , of area @xmath120 .",
    "we also consider the discrete hessian @xmath118 as discussed in the remark  [ remark : bdy ] , i.e. , imposing convex constraints on the boundary whenever they make sense .",
    "even though theorem  [ theorem : discrete : converge ] requires us to impose upper bounds on the second order differences in order to ensure convergence , the following numerical experiments were carried on without this requirement .",
    "convergence was nevertheless observed at optimal rates .",
    "the times reported correspond to the experiments being run on a pc , with a 2.8ghz pentium  iv processor and 2 gb of ram , running _ linux_.",
    "the matrices were assembled using _ octave _",
    "@xcite and the semidefinite program was solved using _ csdp _  5  @xcite with the default parameters .",
    "the graphics were obtained using _ mathematica _",
    "@xcite .",
    "since this problem is not widely known in the mathematics community , let us start by giving a brief description of it following the one given in  @xcite , where it is referred to as the _ revenue maximization in a multiple - good monopoly _ problem .",
    "[ prob : monopolist ] a seller with @xmath14 different objects faces a single buyer , whose preferences over consumption and money transfers are given by @xmath439 , where @xmath440^d$ ] is the vector of the buyer s valuations , @xmath441 is the vector of quantities consumed for each good , and @xmath442 is the monetary transfer made to the seller .",
    "the valuations @xmath109 are only observed by the buyer , and a density function @xmath443 represents the seller s belief on the buyer s private information @xmath109 .",
    "the seller s problem is to design a revenue maximizing mechanism to carry out the sale , and it is enough to consider only direct revelation mechanisms : the buyer must prefer to reveal its information truthfully ( incentive compatibility ) and to participate voluntarily ( individual rationality ) . under these conditions , it can be proved that the seller s problem may be written as @xmath444 where @xmath11^d$ ] , @xmath12 is a non - negative probability density function over @xmath13 , and @xmath4 is the set of functions @xmath23 satisfying    @xmath23 is convex ,    @xmath445 for all @xmath446 ( the gradient taken in the weak sense and the inequalities componentwise ) , and    @xmath447 .",
    "the functional to be maximized is the seller s expected revenue . for a buyer of type @xmath109 , the solution @xmath23 to this optimization problem represents the utility received by her , and the @xmath92-th component of @xmath24 denotes the probability that she will obtain good @xmath92 .",
    "the restriction of convexity stems from incentive compatibility , and the condition @xmath448 from individual rationality .",
    "we show now some numerical results for the problem  [ prob : monopolist ] for the special case @xmath39 , for which analytic solutions in 2 and 3 dimensions are known , allowing us to judge the behavior of the discrete approximations .",
    "that is , the functional to be minimized is @xmath449    in both 2 and 3 dimensions , the solutions are piecewise linear convex functions whose partial derivatives are either @xmath97 or @xmath450 .",
    "for example , for @xmath136 the solution is @xmath451 where @xmath452 and the value at the optimum is @xmath453    in figure  [ fig : econo:2d ] we show the contour lines obtained . in ( a ) the analytic solution , and then the discrete solution for @xmath454 , @xmath455 and @xmath456 in , respectively , ( b ) , ( c ) and ( d ) , with the contours of the analytic solution shown in a lighter gray . the contours are @xmath457 ( the csdp solution is always positive due to the way it is solved ) .",
    "( b ) , @xmath458 ( c ) , @xmath459 ( d ) . , title=\"fig : \" ] + ( a )     ( b ) , @xmath458 ( c ) , @xmath459 ( d ) . ,",
    "title=\"fig : \" ] + ( b )     +     ( b ) , @xmath458 ( c ) , @xmath459 ( d ) .",
    ", title=\"fig : \" ] + ( c )     ( b ) , @xmath458 ( c ) , @xmath459 ( d ) .",
    ", title=\"fig : \" ] + ( d )    we observe that the scheme introduces quite a bit of diffusion at lower resolutions , and , in particular , the heights at the point @xmath143 increase to the analytic solution at that point as @xmath48 decreases .",
    "however , the jump in the gradients is well captured , especially at higher resolutions , even though we are asking for conditions on the discrete hessians which are unbounded from above .    in table",
    "[ tab : econo:2d ] we give some comparative results at different mesh sizes . in this table",
    "we indicate by @xmath460 the discrete functional evaluated at @xmath461 , the interpolant in @xmath71 of the exact solution , and the error column refers to @xmath462 ( @xmath37 error ) .",
    "it is interesting to notice that even though the solution is not smooth ( @xmath23 is only lipschitz ) the error in the @xmath37 norm is smaller or approximately equal to @xmath48 . in the last column of the table we show the quantity @xmath463 which is approximately @xmath464 for all the values of @xmath48 reported , showing that even under such low regularity assumptions on @xmath23 , the error in the functional behaves as @xmath465 .",
    "rlllcrc @xmath266 & @xmath81 & @xmath466 & @xmath460 & error ( @xmath37 ) & & @xmath467 +    ' '' ''    8 &  0.125 & 0.5319 & 0.5444 & 0.0769 & 0.190s & 0.14 + 16 &  0.0625 & 0.5404 & 0.5478 & 0.0300 & 0.990s & 0.14 + 32 &  0.03125 & 0.5449 & 0.5488 & 0.0336 & 17.000s & 0.14 + 64 &  0.015625 & 0.5470 & 0.5491 & 0.0174 & 751.100s & 0.14 + @xmath468 &  0 & 0.5492    in three dimensions there is also a solution with partial derivatives which are either @xmath97 or @xmath450 , of the form @xmath469    this time the coefficients can not be expressed in a simple form , since they involve roots of polynomials of high degree , and we just give numerical approximations : @xmath470 so that @xmath471 , and the value of the functional is @xmath472    in figure  [ fig : econo3d ] we show the regions where @xmath473 is @xmath474 or @xmath16 in , different shades of gray .",
    "we illustrate the regions with wire frames viewed from the positive octant in ( a ) , and exploded views of the solid regions from the positive octant in ( b ) and the negative octant in ( c ) .     + ( a )     + ( b )     + ( c )    in table  [ tab : econo:3d ] we give some comparative results at different mesh sizes .",
    "it is interesting to notice here that the @xmath37 error is not converging to zero with order @xmath465 .",
    "nevertheless , the quantity @xmath463 ( shown in the last column ) decreases slowly as @xmath48 goes to @xmath97 , meaning that the error @xmath475 in the functional behaves as @xmath465 in this range , exhibiting a similar behavior to that of the two dimensional case .",
    "rlcccrc @xmath266 & @xmath81 & @xmath466 & @xmath460 & error ( @xmath37 ) & & @xmath467 +    ' '' ''    4 &  0.25 & 0.8195 & 0.8449 & 0.1356 & 0.21s & 0.20 + 8 &  0.125 & 0.8484 & 0.8605 & 0.1281 & 3.87s & 0.16 + 12 &  0.0833 & 0.8578 & 0.8647 & 0.1130 & 10.29s & 0.13 + 16 &  0.0625 & 0.8622 & 0.8661 & 0.1135 & 7 m 20s & 0.10 + 20 &  0.0500 & 0.8648 & 0.8671 & 0.1177 & 50 m 23s & 0.07 + @xmath468 &  0 & 0.8684    theoretically , semidefinite programs are polynomial time solvable . however , as the tables  [ tab : econo:2d ] and  [ tab : econo:3d ] show , in practice we can not go too far with the number of unknowns .",
    "a reasonable size for the two dimensional problems we considered is a mesh of about @xmath476 subdivisions .",
    "carlier , lachand - robert and maury  @xcite gave several examples of @xmath132 and @xmath477 projections , and in this section we consider one of the functions they considered , namely , @xmath478    we show the graph of the original function in figure  [ fig : fig2-f ] , and that of the resulting @xmath40 , @xmath28 , @xmath37 , @xmath132 and @xmath477 projections in figure  [ fig : fig2 ] . as in the original article",
    ", these graphs are shown upside down .",
    "the interested reader may observe that our results are qualitatively different from those in  @xcite .    }",
    "$ ] , shown upside down . ]    @xmath40 projection    , shown upside down . ]    , shown upside down . ]",
    "+    @xmath28 projection    , shown upside down . ]    , shown upside down . ]     +    @xmath37 projection    , shown upside down . ]    , shown upside down . ]     +    @xmath132 projection    , shown upside down . ]    , shown upside down . ]",
    "+    @xmath477 projection    , shown upside down . ]    , shown upside down . ]    using a similar function , but with more symmetries , @xmath479 we show in figure  [ fig : nonu ] that the @xmath37 projection need not be unique .",
    "the solution in  ( b ) is the one obtained by the semidefinite programming code .     projection .",
    "( a ) original function , ( b ) and ( c ) two optimal solutions.,title=\"fig : \" ] + ( a )     projection .",
    "( a ) original function , ( b ) and ( c ) two optimal solutions.,title=\"fig : \" ] + ( b )     projection .",
    "( a ) original function , ( b ) and ( c ) two optimal solutions.,title=\"fig : \" ] + ( c )    in all these examples , we used a mesh with @xmath480 nodes .",
    "the times ranged from about @xmath481 seconds for the @xmath37 projections to about @xmath482 seconds for the @xmath28 projection .",
    "the @xmath132 and @xmath477 projections took about the same time , near @xmath483 seconds .",
    "as mentioned in the introduction , many problems in science are modelled via convex functions , raising the question of how measured data ( usually non convex ) can be approximated by a convex function .",
    "often the fitness to data is done parametrically .",
    "for example , by assuming that the underlying function is a linear combination of some given polynomials , and minimizing over all possible parameters in a convenient norm . even in this case",
    ", approximating the data by a linear combination which is also convex  but otherwise arbitrary  may be challenging .    in this section",
    "we show how our numerical scheme could be used for fitting data on a regular mesh by discrete functions having a positive semidefinite discrete hessian .",
    "though the resulting discrete functions may not be extended to a convex function of continuous variables , as shown in example  [ example : hessnoconv ] , the underlying `` true '' convex function might be well captured by the discrete function .    in the tests we show , we perturbed with random noise the values of the function @xmath484 on a regular mesh of @xmath480 nodes .",
    "the original function and the perturbed data are represented in figure  [ fig : noise ]  ( a ) and ( b ) , respectively .",
    "projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( a )     projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( b )     +     projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( c )     projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( d )     +     projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( e )     projection ( c ) , level curves of the @xmath28 projection ( d ) , level curves of the @xmath37 projection ( e ) , 3d graphs of the unperturbed function and @xmath37 projection ( f).,title=\"fig : \" ] + ( f )    we chose to use a uniformly distributed noise between @xmath485 and @xmath53 for each node , where @xmath486 ( @xmath48 being the mesh size ) . in this way",
    "we simulate some intrinsic measurement noise whose distribution is presumably known , and that the mesh has been chosen finer than the measurement noise .",
    "needless to say , our choice of noise is quite arbitrary , and there are many other possibilities to choose from .    in figure",
    "[ fig : noise ]  ( c ) , ( d ) and  ( e ) we show the resulting level curves for the @xmath40 , @xmath28 and @xmath37 discrete projections ( respectively ) , with the contours of the original unperturbed function in a lighter gray .",
    "the @xmath28 discrete projection may be considered as a variant of a least squares approximation , but the others are not seen as often .",
    "the times spent by the semidefinite code were similar to those of section  [ sec : projections:2 ] , about @xmath487 , @xmath482 and @xmath481 seconds ( respectively ) .",
    "as is to be suspected , for the same mesh but smaller noise ( e.g. , taking @xmath488 ) , the results are better and the times smaller .    comparing the level curves with those of the unperturbed function ( figure  [ fig : noise ]  ( c ) , ( d ) and  ( e ) ) , it is apparent that the @xmath37 discrete projection seems to give the closest fit .",
    "notice that this projection is also faster than the @xmath40 or @xmath28 discrete projections by a factor of @xmath489 to @xmath490 .    for the run shown , the maximum absolute value of the differences between the perturbed data and the original function on the mesh is about @xmath491 ( @xmath492 times the mesh size , as designed ) ,",
    "whereas the maximum absolute value of the differences between the @xmath37 projection and the original function is @xmath493 , attained at @xmath65 .    however , as can be seen in figure  [ fig : noise ]  ( e ) , the @xmath37 projection gives a good fit to the unperturbed function in the interior nodes , and is actually between @xmath494 ( somewhat smaller than the mesh size ) for nodes of the square @xmath495 , but deteriorates near the boundary ( as do the other projections ) .",
    "this is perhaps better appreciated in figure  [ fig : noise ]  ( f ) , where the graph of the @xmath37 discrete projection is compared to that of the unperturbed original function .",
    "the `` overshooting '' at the boundary is a typical and known phenomenon when fitting data by convex functions .",
    "see , for instance , the article by meyer  @xcite , where the one dimensional case is discussed .",
    "* our gratitude to a.  manelli for bringing the monopolist problem  [ prob : monopolist ] to our attention , and for his many enlightening comments on the subject . * our thanks to the anonymous referees for their comments which made the presentation more clear , and for suggesting the applications in section  [ sec : fit ] .",
    "nstor e. aguilera : : :    consejo nacional de investigaciones cientficas y tcnicas and    universidad nacional del litoral , argentina .",
    "+    e - mail : aguilera@santafe-conicet.gov.ar pedro morin ( corresponding author ) : : :    consejo nacional de investigaciones cientficas y tcnicas and    universidad nacional del litoral , argentina .",
    "+    e - mail : pmorin@santafe-conicet.gov.ar"
  ],
  "abstract_text": [
    "<S> many problems of theoretical and practical interest involve finding an optimum over a family of convex functions . </S>",
    "<S> for instance , finding the projection on the convex functions in @xmath0 , and optimizing functionals arising from some problems in economics .    </S>",
    "<S> in the continuous setting and assuming smoothness , the convexity constraints may be given locally by asking the hessian matrix to be positive semidefinite , but in making discrete approximations two difficulties arise : the continuous solutions may be not smooth , and functions with positive semidefinite discrete hessian need not be convex in a discrete sense .    </S>",
    "<S> previous work has concentrated on non - local descriptions of convexity , making the number of constraints to grow super - linearly with the number of nodes even in dimension 2 , and these descriptions are very difficult to extend to higher dimensions .    in this paper </S>",
    "<S> we propose a finite difference approximation using positive semidefinite programs and discrete hessians , and prove convergence under very general conditions , even when the continuous solution is not smooth , working on any dimension , and requiring a linear number of constraints in the number of nodes .    </S>",
    "<S> using semidefinite programming codes , we show concrete examples of approximations to problems in two and three dimensions . </S>"
  ]
}