{
  "article_text": [
    "in the last decade , human action recognition has been a very active research area in computer vision due to its various potential applications . a large body of work is dedicated to recognizing singleton activities in videos , whereas some recent work focus on recognizing singleton actions within still images .",
    "human interaction recognition , which constitutes up a significant subset of multi - person activities , is a relatively less studied area . especially for still images ,",
    "the prior work is almost non - existent . in this paper",
    ", we address this problem of multi - person interaction recognition in images .",
    "when recognizing interactions in still images , the problem gets more complex and harder to solve , due to the explicit need to discriminate foreground from background clutter without the motion information . in videos , motion is shown to be a great clue for identifying the type of the interactions ( @xcite ) . without motion ,",
    "the foremost cue becomes the appearance . in this paper , we explore how we can extract and leverage multiple forms of appearance information for interaction recognition in images .    in this context , we propose several novel visual features that captures the intrinsic layout and orientation of face regions .",
    "faces tend to play a great role in characterizing human interactions .",
    "people look at each other when they are talking , faces come together when people are kissing , and more .",
    "figure [ fig : interactionswithonlyfaces ] includes some examples .",
    "@xcite use faces in video sequences to describe interactions in a day - long first - person(egocentric ) video of a social event .",
    "based on inspiration from this work , we explore whether facial features can also be helpful in discriminating multi - person interactions in still images .    another reason to explore facial features",
    "is that , face detection technology is considerably advanced and is able to locate a great deal of faces in images , especially those that are not too small or significantly occluded .",
    "our designed descriptors are based on the observation that relative positions , size and locations of the faces are likely to be important for characterizing human interactions . to extract these descriptors ,",
    "we first use a face detector .",
    "we also estimate the orientations of the faces if possible using the face detector of  @xcite . in this way",
    ", we estimate the size , spatial location and the orientation of the face in a [ -90,90 ] range with 15resolution .",
    "we then make use of these features to propose image - level facial interaction descriptors . for recognition , we combine these multi - person facial descriptors with standard scene descriptors extracted globally from the images . in this context , we also investigate the effect of the state - of - the - art deep learning based features , aka , convolutional neural network ( cnn ) features to this new problem domain . since there is no available dataset in this relatively new domain , a new and comprehensive dataset , which includes a total of ten human interaction classes , such as boxing , dining , kissing , partying , talking ,",
    "is collected .",
    "this dataset has also been enriched with the manual annotations of the ground truth face locations and orientations to facilitate further comparisons .",
    "our contributions in this paper are two - fold : ( 1 ) we collect a new image dataset for human interaction categorization which includes multi - person interaction instances and ( 2 ) we present novel descriptors based on facial regions for human interaction recognition .",
    "our experimental results show that , deep learning based features are effective in recognition of human - human interactions in images , and the proposed facial features that aim to encode the relative configurations of faces also provide useful information , especially when combined with global image features . in the rest of the paper , we first",
    "there is a vast literature on human action / activity recognition ( for a recent survey , see @xcite ) , whereas human interaction recognition is a relatively less studied topic .",
    "there are a number of studies that propose models for interaction recognition in videos , and in general , two types of interactions are considered .",
    "these are human - object and human - human interactions . for human - object interaction recognition , @xcite propose to use probabilistic models for simultaneous object and action recognition . for recognizing human - human interactions , @xcite propose to simultaneously segment and track multiple body parts of interacting humans in videos .",
    "@xcite builds their model on matching of local spatio - temporal features .",
    "@xcite focus on a single type of interaction , i.e. , looking at each other , and propose several methods for detecting this interaction effectively in videos .",
    "recently ,  @xcite utilize configuration detection of upper body detections for better interaction recognition in edited tv material .    in image domain ,",
    "human - object interactions are the focus of a number of studies , which handle the problem by extraction of distinctive feature groups  @xcite , by bag - of - features and part - based representations  @xcite and by weakly supervised learning  @xcite .",
    "object - person interactions have also been explored in  @xcite .",
    "one of the earliest works to recognize the human interactions in still images is the work of @xcite . in their paper , four classes are defined : shaking hands , pointing at the opposite person , standing hand - in - hand and intermediate - transitional state between them , and k - nearest neighbor classifier is used to recognize the interactions . recently ,  @xcite has focused on how people interact by investigating the proxemics between them .",
    "they claim that complex interactions can be modeled as a single representation and a joint model of body poses can be learned .",
    "@xcite look into the problem of detecting social roles in videos in a weakly supervised setting via a crf model . in our work ,",
    "we approach the human - human interaction recognition problem by means of several descriptors that encode facial region configurations .",
    "another study area that could be related to our work is event recognition in still images (  @xcite ,  @xcite ,  @xcite ) .",
    "event recognition research aims to recognize a certain scene or event in images or videos .",
    "datasets in this field are different from ours .",
    "event recognition datasets describe an event like christmas , wedding , etc .",
    "in such images , the main focus is not the people , but visual elements for an event . in multi - person interaction recognition problem",
    ", we focus on the presence of people , and try to infer the interaction based on images of people .    in this work ,",
    "we are inspired from the recent work of @xcite , which uses face detection responses to recognize social human interactions in video sequences from a first person perspective camera .",
    "they propose to use markov random field for frame based feature representations and a hidden conditional random field to represent sequence based features . in our work , we propose several simple features based on face regions for recognizing human - human interactions in the images .",
    "in this section , we describe the facial descriptors and the learning procedure that we have proposed for the purpose of interaction recognition .",
    "our approach begins with the detection of the faces . for this purpose",
    ", we first apply the recent algorithm of @xcite , since it outputs three essential information about the faces :  ( 1 ) orientation of the face in the range of [ -90 , 90 ] with a resolution of 15 ,  ( 2 ) location of the face in the image and  ( 3 ) size of the face in pixels .",
    "the orientation of a face is defined as the angle of the face with respect to the imaginary axis that crosses from the midpoint of the chin and the forehead . for reducing the number of false negatives in face detection",
    ", we also employ the opencv implementation of @xcite , which only gives the location and size of the images , and whether they are frontal or profile .",
    "the face detections from these two approaches are combined in the following way :  ( 1 ) if both of the detectors find a face in the same region , @xcite s output is used , since it is shown to be more accurate and it outputs face orientation estimates as well as face locations .",
    "( 2 ) while using viola - jones face detector , if only frontal face is detected , the orientation is assumed to be 0 .",
    "if a profile face is detected , then the orientation is assumed to be 90 .",
    "if both frontal and profile face detectors fire within the same region , it means that the orientation of the face is between [ 0 , + /-90 ] . to quantize the angle ,",
    "the intersection ratio is normalized to [ 0 - 90 ] interval .    after detecting the faces ,",
    "we extract several mid - level descriptors based on the facial regions .",
    "below , we introduce each of these descriptors .    *",
    "histogram of face orientations ( hfo ) : * in order to account of the distribution of the face orientations , we propose to use histogram of face orientations ( hfo ) , which simply is based on the count of face orientations for each angle in an image . in another words",
    ", it is the distribution of face orientation frequencies in an image .",
    "this descriptor has 13 feature dimensions ( 13 histogram bins ) , which corresponds to 15resolution in [ -90- 90 ] interval .",
    "figure [ fig : orientationhist ] shows some example hfo descriptors .",
    "* histogram of face directions ( hfd ) : * we observe that using orientations with a lower resolution can also be useful to discriminate interactions .",
    "based on this observation , we form a coarser histogram representation of the face orientations , and call it histogram of face directions ( hfd ) .",
    "this hfd feature comprises the distribution of direction frequencies in the images .",
    "directions are defined as left , front and right which correspond to the angle intervals [ -90 , -45 ] , [ -30 , 30 ] and [ 45 , 90 ] respectively .",
    "this descriptor is basically a coarser form of hfo and it has 3 dimensions .    [ cols=\"^,^,^ \" , ]     [ table : comparison2 ]    results in table [ table : comparison1 ] and table  [ table : comparison2 ] show that , compared to the facial descriptors , scene features carry quite a lot of information for predicting the type of interaction .",
    "proposed face descriptors contribute to the recognition of human interactions , and together with bow and gist features , they achieve a reasonable map of @xmath0 , which would rise to @xmath1 in the presence of a perfect face detector . on the other hand ,",
    "the deep features are the most effective for human interaction recognition , places - cnn achieving @xmath2 ap and hybrid - cnn feature achieving an ap of @xmath3 .",
    "an interesting observation at this point is that , when combining deep features with regular scene descriptors such as gist and bow , the performance slightly drops .",
    "this result suggests that gist or bow features does not carry any complementary information to the deep features . on the contrary ,",
    "combining proposed facial descriptors with cnn features improves the performance , achieving @xmath4 using output of face detectors , and @xmath5 when the ground truth face locations are used .",
    "these results show that , it is not easy to describe human interactions by looking at facial regions and their spatial layouts only ( as demonstrated in fig  [ fig : interactionswithonlyfaces ] ) .",
    "nevertheless , when used in combination with scene elements extracted from the whole image , the facial descriptors can boost the recognition performance .",
    "we also present per class average precisions in fig .",
    "[ fig : apclassall ] and in fig .",
    "[ fig : apclassallgt ] .",
    "we observe that some of the interactions , such as boxing and high - five are more difficult to recognize , having average precisions lower than 0.6 .",
    "on the other hand , recognition performance on some interaction classes , such as dining and speech , are quite high .",
    "this is likely to be due to the similar spatial configurations present in these interactions . in all of the interaction classes ,",
    "cnn features are very effective .",
    "qualitative results that are obtained as a result of using ` facedesc + gist + bow - spm + hybrid - cnn ` combination are presented in fig .",
    "[ fig : qualex ] . as it can be seen in these images ,",
    "high five interaction is mostly confused with handshaking and punching , whereas kissing interaction is mostly confused with hugging .",
    "+   +   +   +    one of the important characteristics of the proposed facial descriptors is their efficiency .",
    "table  [ table : descdimensions ] shows the dimensionalities of each of the utilized descriptors .",
    "our proposed 31-dimensional face descriptors provides 2 - 6% points increase in average precision when used with bow+spm and/or gist , and 1 - 3% points increase when used with the cnn features , without requiring excessive training .",
    "[ table : descdimensions ]",
    "in this paper , we look into a rarely studied area of computer vision , namely human interaction recognition in still images . we investigate whether we can infer the correct label of an interaction image by looking at the facial regions , their relative positions and spatial layout . in order to capture such information ,",
    "we propose several descriptors based on facial regions .",
    "our experimental results show that , facial descriptors provide meaningful information , however , using them in isolation yields less effective results .",
    "when combined with global scene features , especially deep features , proposed facial descriptors are shown to have improved recognition performance .    in this context",
    ", we introduce a new image dataset which can be used for human interaction recognition , and also for evaluating face detectors performance on further tasks .",
    "the faces in the dataset are annotated with both locations and orientations , and will be made available upon publication .",
    "this work was supported in part by the scientific and technological research council of turkey ( tubitak ) career development award numbered 112e149 .    26 natexlab#1#1[1]`#1 ` [ 2]#2 [ 1]#1 [ 1]http://dx.doi.org/#1 [ ] [ 1]pmid:#1 [ ] [ 2]#2 , , . . .",
    ", , , . , in : . , , , . , in : . , , ,",
    ", in : . , , , . , in : . , , , . , in : , ,",
    "pp . . , , ,",
    ". . , . , , . , in : . , , , . , in : , . pp . . , , ,",
    ", in : , pp . . , , , , . , in : , pp . .",
    ", , , , . . ,",
    ", , . , in : , pp . .",
    ", , , . . ,",
    ", , , . , in : , pp . .",
    ", , . , in : , pp . .",
    ", , , , , .",
    ", in : , pp . . , , . . ,",
    ", , . , in : , .",
    "pp . . , , , ,",
    "a. , in : , .",
    ", , b. , in : , .",
    ", , , , , .",
    ", in : . , , . ."
  ],
  "abstract_text": [
    "<S> this paper presents a novel approach in a rarely studied area of computer vision : human interaction recognition in still images . </S>",
    "<S> we explore whether the facial regions and their spatial configurations contribute to the recognition of interactions . in this respect , </S>",
    "<S> our method involves extraction of several visual features from the facial regions , as well as incorporation of scene characteristics and deep features to the recognition . </S>",
    "<S> extracted multiple features are utilized within a discriminative learning framework for recognizing interactions between people . </S>",
    "<S> our designed facial descriptors are based on the observation that relative positions , size and locations of the faces are likely to be important for characterizing human interactions . since there is no available dataset in this relatively new domain , a comprehensive new dataset which includes several images of human interactions </S>",
    "<S> is collected . </S>",
    "<S> our experimental results show that faces and scene characteristics contain important information to recognize interactions between people .    human interaction recognition , facial features , interaction recognition in still images </S>"
  ]
}