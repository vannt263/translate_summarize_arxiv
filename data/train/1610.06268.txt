{
  "article_text": [
    "computing ( rc ) is a set of methods for designing and training artificial recurrent neural networks @xcite that brings a drastic simplification of the system design .",
    "a typical reservoir is a randomly connected fixed network with arbitrary coupling coefficients between the input signal and the nodes .",
    "these parameters remain fixed and only readout weights are optimised .",
    "this greatly simplifies the training process - that is , computing the coefficients of the readout layer - which often reduces to solving a system of linear equations . despite these simplifications , the rc approach can yield performances equal , or even better than other machine learning algorithms @xcite . the rc algorithm has been applied to speech and phoneme recognition , equalling other approaches @xcite , and won an international competition on financial time series prediction @xcite .    optical computing has been investigated for decades as photons propagate faster than electrons , without generating heat or magnetic interference , and thus promise higher bandwidth than conventional computers @xcite . the possibility of optical implementation of reservoir computing was studied using numerical simulations in @xcite . a major breakthrough occurred by the end 2011  beginning 2012  when",
    "experimental implementations of reservoir computers with performance comparable to state of the art digital implementations were reported . in quick succession appeared an electronic implementation @xcite , and then three opto - electronic implementations @xcite . since then",
    "all - optical reservoir computers have been reported using as nonlinearity the saturable gain of a semiconductor optical amplifier @xcite , a semiconductor laser with delayed feedback @xcite , the saturation of absorption @xcite , integrated on an optical chip @xcite , and based on a coherently driven passive optical cavity @xcite .",
    "the performance of a reservoir computer greatly relies on the training technique used to compute the readout weights .",
    "offline learning methods , used up to now in experimental implementations @xcite , provide good results , but become detrimental for real - time applications , as they require large amounts of data to be transferred from the experiment to the post - processing computer .",
    "this operation may take longer than the time it takes the reservoir to process the input sequence @xcite .",
    "moreover , offline training is only suited for time - independent tasks , which is not always the case in real - life applications .",
    "the alternative ( and more biologically plausible ) approach is to progressively adjust the readout weights using various online learning algorithms such as gradient descent , recursive least squares or reward - modulated hebbian learning @xcite . such procedures require minimal data storage and have the advantage of being able to deal with a variable task : should any parameters of the task be altered during the training phase , the reservoir computer would still be able to produce good results by properly adjusting the readout weights .    in the present work we apply this online learning approach to an opto - electronic reservoir computer and",
    "show that our implementation is well suited for real - time data processing .",
    "the system is based on the opto - electronic reservoir , introduced in @xcite , coupled to an fpga chip , that implements input and output layers .",
    "it generates the input sequence in real time , collects the reservoir states and computes optimal readout weights using a simple gradient descent algorithm .",
    "real - time generation of reservoir inputs allows the system to be trained and tested on an arbitrary long input sequence , and the replacement of the personal computer by a dedicated fpga chip significantly reduces the experimental runtime",
    ". we apply our system to a specific real - world task : the equalisation of nonlinear communication channel .    wireless communications is by far the fastest growing segment of the communications industry .",
    "the increasing demand for higher bandwidths requires pushing the signal amplifiers close to the saturation point which , in turn , adds significant nonlinear distortions into the channel .",
    "these have to be compensated by a digital equaliser on the receiver side @xcite .",
    "the main bottleneck lies in the analog - to - digital converters ( adcs ) that have to follow the high bandwidth of the channel with sufficient resolution to sample correctly the distorted signal @xcite .",
    "current manufacturing techniques allow producing fast adcs with low resolution , or slow ones with high resolution , obtaining both being very costly .",
    "this is where analog equalisers become interesting , as they could equalise the signal before the adc and significantly reduce the required resolution of the converters , thus potentially cutting costs and power consumption @xcite .",
    "moreover , optical devices may outperform digital devices in terms of processing speed @xcite .",
    "it can for instance be shown that reservoir computing implementations can reach comparable performance to other digital algorithms ( namely , the volterra filter @xcite ) for equalisation of a nonlinear satellite communication channel @xcite .",
    "our reservoir computer is used to equalise a simple wireless channel introduced in @xcite .",
    "this model is described by a simple set of equations ( see section [ subsec : cheq ] ) and can be easily implemented on the fpga chip .",
    "this task has also been extensively studied in the rc community , both numerically @xcite and experimentally @xcite . our system performs better than previously reported rc implementations on this task and we report error rates up to two orders of magnitude lower than previous results @xcite .",
    "furthermore , we demonstrate the great advantage of online training , namely that it is suitable for solving non - stationary tasks , such as a variable wireless channel .",
    "this is particularly interesting for real - life applications , as physical communication channels vary depending on fluctuating environmental conditions .",
    "we show that even under such variable conditions , our system performs as well as in the stationary case .    in previous work we programmed the simple gradient descent algorithm on an fpga chip to train a digital reservoir computer @xcite , and we have reported preliminary results on an online - trained physical reservoir computer @xcite . compared to the latter work , the experimental setup has been improved , the fpga design has been further optimised , and a new dedicated clock generation device is used . as a consequence",
    "the system is more stable , more efficient , and the reservoir size has been increased to 50 neurons ( as in @xcite ) .",
    "we also report what is , to the best of our knowledge , the lowest error rates ever obtained with a physical reservoir computer on the channel equalisation task .",
    "finally we present a much more in depth analysis of the time - dependent case .",
    "the paper is structured as follows .",
    "section [ sec : basic ] introduces the basic principles of the reservoir computing , the channel equalisation task and the simple gradient descent algorithm . the experimental setup and the fpga design are outlined in sections [ sec : expsetup ] and [ sec : design ] .",
    "finally , the experimental results and the conclusion are presented in sections [ sec : results ] and [ sec : ccl ] .",
    "a typical reservoir computer is depicted in figure [ fig : rc ] .",
    "it contains a large number @xmath0 of internal variables @xmath1 evolving in discrete time @xmath2 , as given by @xmath3 where @xmath4 is a nonlinear function , @xmath5 is some external signal that is injected into the system , and @xmath6 and @xmath7 are time - independent coefficients , drawn from some random distribution with zero mean , that determine the dynamics of the reservoir . the variances of these distributions are adjusted to obtain the best performances on the task considered .",
    "is injected into a dynamical system , composed of a large number @xmath0 of internal variables @xmath1 .",
    "the dynamics of the system is defined by the nonlinear function @xmath4 and the coefficients @xmath6 and @xmath7 .",
    "the readout weights @xmath8 are trained to obtain an output signal @xmath9 , given by their linear combination with the reservoir states @xmath1 , as close as possible to the target signal @xmath10.,scaledwidth=45.0% ]    the nonlinear function used here is @xmath11 , as in @xcite . to simplify the interconnection matrix @xmath6",
    ", we exploit the ring topology , proposed in @xcite , so that only the first neighbour nodes are connected .",
    "this architecture provides performances comparable to those obtained with complex interconnection matrices , as demonstrated numerically in @xcite and experimentally in @xcite . under these circumstances",
    "we obtain    @xmath12    [ eq : rcevo2 ]    with @xmath13 , @xmath14 and @xmath15 parameters are used to adjust the feedback and the input signals , respectively , and @xmath16 is the input mask , drawn from a uniform distribution over the the interval @xmath17 $ ] , as in @xcite .",
    "a bias @xmath18 is used to shift the sine function from its symmetric point to compensate for the asymmetric channel output symbol distribution , as explained in section [ subsubsec : cheqconst ] .",
    "the reservoir computer produces an output signal @xmath9 , given by a linear combination of the states of its internal variables @xmath19 where @xmath20 are the readout weights , trained either offline ( using standard linear regression methods ) , or online , as described in section [ subsec : gd ] , in order to minimise the square error between the output signal @xmath9 and the target signal @xmath10 .",
    "the channel equalisation task @xcite , in addition to its practical interest , does nt require the use of large reservoirs to obtain state - of - the - art results @xcite .",
    "the channel input signal @xmath10 contains 2-bit symbols with values picked randomly from @xmath21 .",
    "the channel is modelled by a linear system with memory of length 10 @xcite @xmath22 followed by an instantaneous memoryless nonlinearity @xmath23 where @xmath5 is the channel output signal and @xmath24 is the added noise of amplitude @xmath25 , where @xmath26 is drawn from a uniform distribution over the interval @xmath27 $ ] ( for ease of implementation on an fpga chip ) .",
    "noise amplitude values @xmath25 are chosen to produce the same signal - to - noise ratios as in @xcite , where gaussian noise was used .",
    "the reservoir computer has to restore the clean signal @xmath10 from the distorted noisy signal @xmath5 .",
    "the performance is measured in terms of wrongly reconstructed symbols , called the symbol error rate ( ser ) .",
    "the results are presented in section [ subsec : constch ] and compared to a previous implementation based on the same opto - electronic setup .",
    "note that although the input signal @xmath10 has a symmetric symbol distribution around @xmath28 , the output signal @xmath5 loses this property , with the symbols lying within the @xmath29 $ ] interval .",
    "the equaliser must take this shift into account and correct the symbol distribution properly .",
    "equations and model a particular channel with certain amounts of symbol interference and nonlinear distortion , defined by the numerical values of the coefficients employed . to obtain a better understanding of this particular channel model , and to show which stages of input signal distortion are the most difficult to equalise",
    ", we introduce a more general channel model , given by @xmath30 and we investigate the equalisation performance for different values of parameters @xmath31 and @xmath32 . to preserve the general shape of the channel impulse response we keep the coefficient of @xmath10 fixed at @xmath33 in equation .",
    "figure [ fig : mmshape ] shows the resulting impulse responses , given by equation , for several values of @xmath32 .",
    "the results of these investigations are presented in the appendix .    .",
    "note that the @xmath10 coefficient is kept fixed at @xmath33 .",
    "dotted curve shows the default shape defined by equation .,scaledwidth=44.0% ]      the model given by equations and describes an idealistic stationary noisy wireless communication channel , that is , the channel remains the same during the transmission .",
    "however , in wireless communications , the environment has a great impact on the received signal .",
    "given its highly variable nature , the properties of the channel may be subject to important changes in real time .    to investigate this scenario",
    ", we performed a series of experiments with a `` drifting '' channel model , where parameters @xmath31 or @xmath34 were varying in real time during the signal transmission .",
    "these variations occurred at slow rates , much slower than the time required to train the reservoir computer .",
    "we studied two variation patterns : a monotonic increase ( or decrease ) and slow oscillations between two fixed values .",
    "section [ subsec : driftchan ] shows the results we obtained with our implementation .",
    "in addition to slowly drifting parameters , the channel properties may be subject to abrupt variations due to sudden changes of the environment . for better practical equalisation performance ,",
    "it is crucial to be able to detect significant channel variations and adjust the rc readout weights in real time .",
    "we consider here the case of a `` switching '' channel , where the channel model switches instantaneously .",
    "the reservoir computer has to detect such changes and automatically trigger a new training phase , so that the readout weights get adapted for the equalisation of the new channel .    specifically , instead of a constant channel , given by equations and",
    ", we introduce three channels differing in nonlinearity    @xmath35    [ eq : varch ]    and switch regularly from one channel to another , keeping equation unchanged .",
    "the results of this experiment are presented in section [ subsec : swch ] .",
    "this section describes the basic idea of the online training algorithm used here and introduces two modifications we investigated in our new implementation .",
    "the gradient , or steepest , descent method is an algorithm for finding a local minimum of a function using its gradient @xcite . for the channel equalisation task considered here ,",
    "the rule for updating the readout weights is given by @xcite @xmath36 where @xmath37 is the step size , used to control the learning rate .",
    "at high values of @xmath37 , the weights get close to the optimal values very quickly ( in a few steps ) , but keep oscillating around these values . at low values ,",
    "the weights converge slowly to the optimal values . in practice , we start with a high value @xmath38 , and then gradually decrease it during the training phase until a minimum value @xmath39 is reached , according to the equation @xmath40 with @xmath41 and @xmath42 , where @xmath43 is the decay rate and @xmath44 is the update rate for the parameter @xmath37 .",
    "the gradient descent algorithm suffers from a relatively slow convergence towards the global minimum , but its simplicity , with few simple computational steps , and flexibility , as the convergence rate and the resulting performance can be improved by tuning the parameters @xmath37 and @xmath45 , make it a reasonable choice for a first implementation on a fpga chip .",
    "future investigations may focus on other online training algorithms , such as recursive least squares @xcite ( a more computationally intensive method that converges faster ) or unsupervised learning @xcite ( which does nt require exact knowledge of the target output , but only an estimation of the reservoir performance ) .",
    "the step size parameter @xmath37 is used to control the learning rate , and can also be employed to switch the training on or off .",
    "that is , setting @xmath37 to zero stops the training process .",
    "this is how experiments on a stationary channel are performed : @xmath37 is programmed to decay from @xmath46 to @xmath28 during a defined period , and then the reservoir computer performance is tested over a sequence of symbols , with constant readout weights .      when equalising a drifting channel , the reservoir should be able to follow the variations and adjust the readout weights accordingly",
    "this can be achieved by setting @xmath47 and thus letting the training process continue during the drift of the channel parameters .",
    "this procedure was used for experiments described in section [ subsec : driftchan ] .      as mentioned in the previous paragraph",
    ", the equalisation of a non - stationary channel requires keeping @xmath47 .",
    "however , this worsens the equalisation performance , as the readout weights keep oscillating around the optimal values .",
    "this can be seen from equation , that defines the update rule for the readout weights : at each time step @xmath48 , a small correction @xmath49 is added to every weight @xmath20 .",
    "these corrections are gradually reduced by decreasing the learning rate @xmath50 , so that the weights converge to their asymptotic values . in the case of a constant @xmath37 ,",
    "the corrections @xmath51 are only damped by the error @xmath52 , which stops decreasing at some point , leaving the @xmath20 oscillating around the optimal values .    to check the impact of a constant @xmath37 on the equalisation performance we performed several experiments with a simplified version of the training algorithm by setting @xmath53 , and hence @xmath54 for all @xmath48 .",
    "although this method will increase the error slightly , it has several advantages . with @xmath37 constant",
    ", there is no need to search for an optimal decay rate @xmath44 , which results in fewer experimental parameters to scan and thus shorter overall experiment runtime . keeping @xmath37 at a constant",
    ", non - zero value would also allow the equaliser to follow a drifting channel , as described in section [ subsec : cheqdrift ] .",
    "the results obtained with this simplified version of the algorithm are shown in section [ subsec : ressimptrain ] .",
    "our experimental setup is depicted in figure [ fig : exp ] .",
    "it contains three distinctive components : the optoelectronic reservoir , the fpga board implementing the input and the readout layers and the computer used to setup the devices and record the results .",
    "the following sections present detailed overviews of these components , and section [ subsec : expparams ] outlines the experimental parameters , tuned to obtain the best results .",
    "beam splitter , an optical attenuator ( att ) , an approximately @xmath55 fibre spool , two photodiodes ( @xmath56 and @xmath57 ) , a resistive combiner ( comb ) and an amplifier ( amp ) . the optical and electronic components are shown in red and green , respectively .",
    "the fpga board implements both the input and output layers , generating the input symbols and training the readout weights .",
    "the computer controls the devices and records the results.,scaledwidth=45.0% ]      the optoelectronic reservoir is based on the same scheme as in @xcite .",
    "these implementations use essentially the same hardware , but differ as to whether a low - pass filter is present in the cavity , and whether the input is desynchronised with respect to the cavity roundtrip .",
    "we use here the desychronised version of @xcite , without low - pass filter .",
    "the reservoir states are encoded into the intensity of incoherent light signal , produced by a superluminiscent diode ( thorlabs sld1550p - a40 ) .",
    "the mach - zehnder ( mz ) intensity modulator ( photline mxan - ln-10 ) implements the nonlinear function , its operating point is adjusted by applying a bias voltage , produced by a hameg hmp4040 power supply . a fraction ( 10% ) of the signal is extracted from the loop and sent to the readout photodiode and the resulting voltage signal is sent to the fpga .",
    "the optical attenuator ( jds ha9 ) is used to set the feedback gain @xmath14 of the system ( see equations ) .",
    "the fibre spool consists of approximately @xmath55 single mode fibre , giving a round trip time of @xmath58 .",
    "the resistive combiner sums the electrical feedback signal , produced by the feedback photodiode ( tti tia-525i ) , with the input signal from the fpga to drive the mz modulator , with an additional amplification stage of @xmath59 ( coaxial pulse amplifier zpul-30p ) to span the entire @xmath60 interval of the modulator .",
    "the sled pump current is set to @xmath61 , in order to keep the optical power at the readout photodiode limited to @xmath62 to ensure a linear response .",
    "the mz modulator bias voltage is set to @xmath63 , which yields a slightly shifted transfer function in order to compensate the input symbols distribution ( see section [ subsubsec : cheqconst ] ) . the optical attenuation can be set up to @xmath64 with @xmath65 precision .",
    "the attenuator is controlled by a matlab script running on the computer .          for our implementation",
    ", we use the xilinx ml605 evaluation board ( see figure [ fig : fpga ] ) , powered by the virtex 6 xc6vlx240 t fpga chip .",
    "the board is equipped with a jtag port , used to load the fpga design onto the chip , and a uart port , that we use to communicate with the board ( as described in section [ sec : design ] ) .",
    "the lpc ( low pin count ) fmc ( fpga mezzanine card ) connector is used to attach the 4dsp fmc151 daughter card , containing one two - channel adc ( analog - to - digital converter ) and one two - channel dac ( digital - to - analog converter ) .",
    "the adc s maximum sampling frequency is @xmath66 with 14-bit resolution , while the dac can sample at up to @xmath67 with 16-bit precision .",
    "the synchronisation of the fpga board with the reservoir delay loop is crucial for the performance of the experiment . for proper acquisition of reservoir states ,",
    "the adc has to output an integer number of samples per roundtrip time .",
    "the daughter card contains a flexible clock tree , that can drive the converters either from the internal clock source , or an external clock signal .",
    "as the former is limited to the fixed frequencies of the onboard oscillator , we employ the latter option .",
    "the clock signal is generated by a hewlett packard 8648a signal generator . with a reservoir of @xmath68 neurons",
    "( one neuron is added to desynchronise the inputs from the reservoir , as in @xcite ) and a roundtrip time of @xmath58 , the sampling frequency is set to @xmath69 , thus producing @xmath70 samples per reservoir state .",
    "to get rid of the transients , induced mainly by the finite bandwidths of the adc and dac , the 6 first and 6 last samples are discarded , and the neuron value is averaged over the remaining 8 samples .",
    "the tensions of the electric signal to and from the mezzanine card need to be adjusted in order to achieve the most efficient interface without damaging the hardware .",
    "the dac output voltage of @xmath71 is sufficient for this experiment , as typical voltages of the input signal range between @xmath72 and @xmath73 .",
    "the adc is also limited to @xmath71 input voltage . with settings described in the previous section",
    ", the output voltage of the readout photodiode does nt exceed @xmath74 .      to achieve the best performance , we scan the most influential parameters , which are : the input gain @xmath15 , the decay rate @xmath44 , the channel signal - to - noise ratio and the feedback attenuation , that corresponds to the feedback gain parameter @xmath14 in equations .",
    "the first three parameters are set on the fpga board , while the last one is tuned on the optical attenuator .",
    "the input gain @xmath15 is stored as a 18-bit precision real in @xmath75 and was scanned in the @xmath76 $ ] interval .",
    "the decay rate @xmath44 is an integer , typically scanned from @xmath77 up to @xmath78 in a few wide steps .",
    "the noise ratios were set to several pre - defined values , in order to compare our results with previous reports .",
    "the feedback attenuation was scanned finely between @xmath79 and @xmath80 .",
    "lower values would allow cavity oscillations to disturb the reservoir states , while higher values would not provide enough feedback to the reservoir .",
    "table [ tab : gdparams ] contains the values of parameters we used for the gradient descent algorithm ( defined in section [ subsec : gd ] ) .",
    ".gradient descent algorithm parameters [ cols=\"^,^,^,^\",options=\"header \" , ]     [ tab : fpgares ]",
    "this section presents the results of different investigations outlined in sections [ subsec : cheq ] and [ subsec : gd ] .",
    "all results presented here were obtained with the experimental setup described in section [ sec : expsetup ] .",
    "figure [ fig : oldvsfpga ] presents the performance of our reservoir computer for different signal - to - noise ratios ( snrs ) of the wireless channel ( green squares ) .",
    "we investigated realistic snr values for real world channels such as @xmath81 lan @xcite and wi - fi @xcite . for each snr",
    ", the experiment was repeated 20 times with different random input masks .",
    "average sers are plotted on the graph , with error bars corresponding to maximal and minimal values obtained with particular masks .",
    "we used noise ratios from @xmath82 up to @xmath83 , and also tested the performance on a noiseless channel , that is , with infinite snr .",
    "the rc performance was tested over one million symbols , and in the case of a noiseless channel the equaliser made zero error over the whole test sequence with most input masks .",
    "the experimental parameters , such as the input gain @xmath15 and the feedback attenuation @xmath14 , were optimised independently for each input mask .",
    "figure [ fig : servsparams ] shows the dependence of the ser on these parameters .",
    "the plotted ser values are averaged over 10 random input masks .",
    "for this figure , we used data from a different experiment run with more scanned values . for each curve ,",
    "the non - scanned parameter was set to the optimal value .",
    "the equaliser shows moderate dependence on both parameters , with an optimal input gain located within @xmath84 and an optimal feedback attenuation of @xmath85 .",
    "we compare our results to those reported in @xcite , obtained with the same optoelectronic reservoir , trained offline ( blue dots ) .",
    "for high noise levels ( @xmath86 ) our results are similar to those in @xcite . for low noise levels ( @xmath87 )",
    "the performance of our implementation is significantly better .",
    "note that the previously reported results are only rough estimations of the equaliser s performance as the input sequence was limited by hardware to @xmath88 symbols @xcite . in our experiment",
    "the ser is estimated more precisely over one million input symbols .",
    "for the lowest noise level ( @xmath89 ) an ser of @xmath90 was reported in @xcite , while we obtained an error rate of @xmath91 with our setup .",
    "one should remember that common error detection schemes , used in real - life applications , require the ser to be lower than @xmath92 in order to be efficient .    to the best of our knowledge ,",
    "the results presented here ( at @xmath83 snr ) are the lowest error rates ever obtained with a physical reservoir computer .",
    "sers around @xmath93 have been reported in @xcite and a recently reported passive cavity based setup @xcite achieved a @xmath94 rate ( this values is limited by the use of a @xmath95-symbol test sequence ) , but no results below @xmath96 have been published so far .",
    "however , this is nt the main achievement of this experiment .",
    "indeed , had it been possible to test @xcite on a longer sequence , it is possible that comparable sers would have been obtained .",
    "the strength of this setup resides in the adaptability to changing environment , as will be shown in the following sections .    ) , for most choices of input mask , the rc made no errors over the test sequence .",
    "blue dots show the results of the optoeletronic setup with offline training @xcite . for low noise levels ,",
    "our system produces error rates significantly lower than @xcite , and for noisy channels the results are similar .",
    "brown diamonds depict the sers obtained with the simplified version of the training algorithm ( see section [ subsubsec : simptrain ] ) .",
    "the equalisation is less efficient than with the full algorithm , but the optimisation of experimental parameters takes less time.,scaledwidth=44.0% ]     snr ) on the experimental parameters .",
    "average sers ( over 10 random input masks ) are plotted against the input gain ( blue dots ) and the feedback attenuation ( green squares ) .",
    "the optimal feedback attenuation has to be set around @xmath85 , outside this region the ser deteriorates by roughly one order of magnitude .",
    "the input gain shows a minimum around @xmath84.,scaledwidth=44.0% ]      the performance of the simplified training algorithm is shown in figure [ fig : oldvsfpga ] ( brown dots ) .",
    "the equaliser was tested with 10 random input masks and one million input symbols , the training was performed over @xmath97 symbols .",
    "only three parameters were scanned during these experiments : the input gain @xmath15 , the feedback attenuation @xmath14 and the signal - to - noise ratio .",
    "the learning rate @xmath37 was set to @xmath98 .",
    "the overall experimental runtime was significantly shorter : while an experiment with full training algorithm would last for about 50 hours , these results were obtain in approximately 10 hours ( which is due to five different values of @xmath44 tested in the former case ) .    for high noise levels the results of the two algorithms are close and for low noise levels the simplified version yields slightly worse error rates .",
    "the performance is much worse in the noiseless case and strongly depends on the input mask : we notice a difference of almost two orders of magnitude between the best and the worst result .",
    "this performance loss is the price to pay for the simplified algorithm and shorter experimental runtime .      besides the environmental conditions , the relative positions of the emitter and the receiver can have a significant impact on the properties of a wireless channel .",
    "a simple example is a receiver moving away from the transmitter , causing the channel to drift more or less slowly , depending on the relative speed of the receiver .",
    "here we show that our reservoir computer is capable of dealing with drifts with time scales of order of a second .",
    "this time scale is in fact slow compared to those expected in real life situations , but the setup could be sped up by several orders of magnitude , as will be shown in the next section .",
    "a drifting channel is a good example of a situation where training the reservoir online yields better results than offline .",
    "we have previously shown in numerical simulations that training a reservoir computer offline on a non - stationary channel results in an error rate ten times worse than with online training @xcite .",
    "we demonstrate here that an online - trained experimental reservoir computer performs well even on a drifting channel if @xmath39 is set to a small non - zero value ( see section [ subsubsec : gdnonstationary ] ) .    at first , we investigated the relationship between the channel model coefficients and the lowest error rate achievable with our setup .",
    "that is , would the equalisation performance be better or worse if one of the numerical values in equations and was changed by , for instance , @xmath99 . given the vast amount of possibilities of varying the 4 parameters @xmath31 and @xmath32 , we picked those that seemed most interesting and most significant .",
    "we thus tested the amplitude of the linear part , given by the parameter @xmath100 , the amplitude of the quadratic and cubic parts , given by @xmath101 and @xmath102 , and the memory @xmath32 of the impulse response .",
    "for each test , only one aspect of the channel was varied and other parameters were set to default values ( as in equations and ) .",
    "the results of these investigations are presented in the appendix .",
    "we then programmed these parameters to vary during experiments in two different ways : a monotonic growth ( or decay ) and a periodic linear oscillation between two defined values .",
    "the results of these experiments are depicted in figure [ fig : driftchan ] .",
    "figure [ fig : driftchan](a ) shows the experimental results for the case of monotonically decreasing @xmath100 from @xmath33 to @xmath103 .",
    "the blue curve presents the resulting ser with @xmath104 , that is , with training process stopped after @xmath105 input symbols .",
    "the green curve depicts the error rate obtained with @xmath106 , so that the readout weight can be gradually adjusted as the channel drifts . note",
    "that while in the first experiment the ser grows up to @xmath107 , it remains much lower in the second case .",
    "the increasing error rate in the latter case is due to the decrease of @xmath100 resulting in a more complex channel .",
    "brown curves show the best possible error rate obtained with our setup for different values of @xmath100 , as presented in the appendix . with @xmath100 approaching @xmath103 ,",
    "the obtained error rate is @xmath108 , which is the lowest error rate possible for this value of @xmath100 , as demonstrated in figure [ subfig : p1ser ] .",
    "this shows that the non - stationary version of the training algorithm allows a drifting channel to be equalised with the lowest error rate possible .",
    "ll     ( 0,0 ) ( -225,115)(a )    &     ( 0,0 ) ( -230,115)(b )     +     ( 0,0 ) ( -225,115)(c )    &     ( 0,0 ) ( -230,115)(d )     +     ( 0,0 ) ( -225,115)(e )    &     ( 0,0 ) ( -230,115)(f )     +     ( 0,0 ) ( -225,115)(g )    &     ( 0,0 ) ( -230,115)(h )     +    figure [ fig : driftchan](b ) depicts error rates obtained with @xmath100 linearly oscillating between @xmath33 and @xmath109 . with @xmath104 ( blue curve )",
    "the error rate is as low as @xmath110 when @xmath100 is around @xmath33 , and grows very high elsewhere . with @xmath111 ,",
    "the obtained ser is always at the lowest value possible : at the point where @xmath112 , it stays at @xmath113 , which again is close to the best performance for such channel , illustrated by the brown curve .",
    "we obtained similar results with parameters @xmath101 , @xmath102 and @xmath32 , as shown in figures [ fig : driftchan](c)-(d ) . letting the reservoir computer adapt the readout weights by setting @xmath114 produces the lowest error rates possible for a given channel , while stopping the training with @xmath115 results in quickly growing sers .",
    "figure [ fig : swch ] shows the error rate produced by our experiment in case of a switching noiseless communication channel .",
    "the parameters of the channel are programmed to switch in cycle among equations every @xmath116 symbols .",
    "every switch is followed by a steep increase of the ser , as the reservoir computer is no longer optimised for the channel it is equalising .",
    "the performance degradation is detected by the algorithm , causing the learning rate @xmath37 to be reset to the initial value @xmath117 , and the readout weights are re - trained to new optimal values",
    ".     symbols , produced by the fpga in case of a switching channel .",
    "the value of @xmath100 ( right axis , green curve ) is modified every @xmath116 symbols .",
    "the change in channel is followed immediately by a steep increase of the ser .",
    "the @xmath37 parameter ( right axis , orange curve ) is automatically reset to @xmath118 every time a performance degradation is detected , and then returns to its minimum value , as the equaliser adjusts to the new channel , bringing down the ser to its asymptotic value . after each variation of @xmath100 , the reservoir re - trains .",
    "the lowest error rate possible for the given channel is shown by the dashed brown curve.,scaledwidth=44.0% ]    for each value of @xmath100 , the reservoir computer is trained over @xmath105 symbols , then its performance is evaluated over the remaining @xmath119 symbols . in case of @xmath120 , the average ser is @xmath121 , which is the expected result . for @xmath122 and @xmath123",
    "we compute average sers of @xmath124 and @xmath125 , respectively , which are the best results achievable with such values of @xmath100 according to our previous investigations ( see figure [ subfig : p1ser ] ) .",
    "this shows that after each switch the readout weights are updated to new optimal values , producing the best error rate for the given channel .",
    "note that the current setup is rather slow for practical applications . with a roundtrip time of @xmath126 ,",
    "its bandwidth is limited to @xmath127 and training the reservoir over @xmath105 samples requires @xmath128 to complete .",
    "however , it demonstrates the potential of such systems in equalisation of non - stationary channels . for real - life applications , such as for instance wi - fi 802.11 g , a bandwidth of @xmath129 would be required .",
    "this could be realised with a @xmath130 fibre loop , thus resulting in a delay of @xmath131 .",
    "this would also decrease the training time down to @xmath132 and make the equaliser more suitable for realistic channel drifts .",
    "the speed limit of our setup is set by the bandwidth of the different components , and in particular of the adc and dac .",
    "for instance with @xmath133 and keeping @xmath134 , reservoir states should have a duration of @xmath135 , and hence the adc and dac should have bandwidths significantly above @xmath136 ( such performance is readily available commercially ) .",
    "as an illustration of how a fast system would operate , we refer to the optical experiment @xcite in which information was injected into a reservoir at rates beyond @xmath136 .",
    "in the present work we applied the online learning approach to training an opto - electronic reservoir computer .",
    "we programmed the simple gradient descent algorithm on an fpga chip and tested our system on the nonlinear channel equalisation task .",
    "we obtained error rates up to two orders of magnitude lower than previously reported rc implementations on the channel equalisation task , while significantly reducing the experimental runtime .",
    "we also demonstrated that our system is well - suited for non - stationary tasks by equalising a drifting and a switching channel . in both cases",
    ", we obtained the lowest error rates possible with our setup .",
    "such flexibility is more complex to achieve with offline methods , and would require improving the algorithm by adding several computational steps .",
    "the online learning methods , on the other hand , need little modifications to successfully solve this task .",
    "moreover , in case of a slowly drifting channel the algorithm can be set to fine - tune the readout weights without performing a complete re - training of the reservoir , which would be hard to achieve with offline learning .",
    "this shows that the technique presented here is more suitable for real - life tasks with variable parameters .",
    "our realisation opens several new research directions .",
    "using the fpga to drive the opto - electronic reservoir gives more control over the experiment .",
    "such a system could , for instance , implement a full optimisation of the readout weights and the input mask , as suggested in @xcite .",
    "the real - time training makes it possible to feed the output signal back into the reservoir .",
    "this additional feedback would highly enrich the dynamics of the system , allowing one to tackle new tasks such as pattern generation or chaotic series prediction @xcite .",
    "the high speed of dedicated electronics offers the opportunity to develop very fast , autonomous reservoir computers with ghz data rates .",
    "the present work thus paves the way towards autonomous , very - high speed , fully analog reservoir computers with a wider range of possible applications .",
    "[ sec : inflparams ]    figure [ subfig : p1ser ] shows the equalisation results for different values of @xmath100 .",
    "we tested each value over 10 random input masks , with independent experimental parameters optimisation for each run .",
    "average values are presented on the plot , with error bars depicting best and worst results obtained among different masks . the equaliser performance",
    "was tested on a sequence of one million inputs , and in several cases we obtained zero misclassified symbols .",
    "note that the observed increase of the ser with reduction of @xmath100 is natural as the linear part contains the signal to be extracted . when decreasing @xmath100 , not only the useful signal gets weaker , but the nonlinear distortion also becomes relatively more important .",
    "figures [ subfig : p2ser ] and [ subfig : p3ser ] present the dependence of the ser on parameters @xmath101 and @xmath102 , respectively .",
    "these parameters define the amplitude of the nonlinear distortion of the signal , and as they grow , the channel becomes more nonlinear and thus more difficult to equalise .",
    "the results of equalisations with different values of @xmath32 are shown in figure [ subfig : mmser ] , higher values of @xmath32 increase the temporal symbol mixing of the channel , hence worse results .",
    "we acknowledge financial support by interuniversity attraction poles program of the belgian science policy office under grant iap p7 - 35 `` photonics@be '' , by the fonds de la recherche scientifique frs - fnrs and by the action de la recherche concerte of the acadmie universitaire wallonie - bruxelles under grant auwb-2012 - 12/17-ulb9 .",
    "b.  hammer , b.  schrauwen , and j.  j. steil , `` recent advances in efficient learning of recurrent networks , '' in _ proceedings of the european symposium on artificial neural networks _ , bruges ( belgium ) , april 2009 , pp",
    ". 213216 .",
    "d.  verstraeten , b.  schrauwen , and d.  stroobandt , `` reservoir - based techniques for speech recognition , '' in _ ijcnn06 .",
    "international joint conference on neural networks _ , vancouver , bc , july 2006 , pp .",
    "10501053 .",
    "k.  vandoorne , w.  dierckx , b.  schrauwen , d.  verstraeten , r.  baets , p.  bienstman , and j.  van  campenhout , `` toward optical signal processing using photonic reservoir computing , '' _ optics express _ , vol .",
    "16 , pp . 1118211192 , 2008 .",
    "l.  appeltant , m.  c. soriano , g.  van  der sande , j.  danckaert , s.  massar , j.  dambre , b.  schrauwen , c.  r. mirasso , and i.  fischer , `` information processing using a single dynamical node as complex system , '' _ nat .",
    "_ , vol .  2 , p. 468",
    ", 2011 .",
    "l.  larger , m.  soriano , d.  brunner , l.  appeltant , j.  m. gutirrez , l.  pesquera , c.  r. mirasso , and i.  fischer , `` photonic information processing beyond turing : an optoelectronic implementation of reservoir computing , '' _ opt . express _",
    "20 , pp . 32413249 , 2012 .",
    "a.  dejonckheere , f.  duport , a.  smerieri , l.  fang , j .- l .",
    "oudar , m.  haelterman , and s.  massar , `` all - optical reservoir computer based on saturation of absorption , '' _ opt .",
    "22 , pp . 1086810881 , 2014 .",
    "k.  vandoorne , p.  mechet , t.  van  vaerenbergh , m.  fiers , g.  morthier , d.  verstraeten , b.  schrauwen , j.  dambre , and p.  bienstman , `` experimental demonstration of reservoir computing on a silicon photonics chip , '' _ nat .",
    "_ , vol .  5 , p. 3541",
    ", 2014 .",
    "q.  vinckier , f.  duport , a.  smerieri , k.  vandoorne , p.  bienstman , m.  haelterman , and s.  massar , `` high - performance photonic reservoir computer based on a coherently driven passive cavity , '' _ optica _ , vol .  2 , no .  5 , pp . 438446 , 2015 .",
    "l.  bottou , `` online algorithms and stochastic approximations , '' in _ online learning and neural networks_.1em plus 0.5em minus 0.4em cambridge university press , 1998 .",
    "[ online ] .",
    "available : http://leon.bottou.org/papers/bottou-98x          x.  feng , g.  he , and j.  ma , `` a new approach to reduce the resolution requirement of the adc for high data rate wireless receivers , '' in _ signal processing ( icsp ) , 2010 ieee 10th international conference on_.1em plus 0.5em minus 0.4emieee , 2010 , pp .",
    "15651568 .",
    "k.  hassan , t.  s. rappaport , and j.  g. andrews , `` analog equalization for low power 60 ghz receivers in realistic multipath channels , '' _ ieee global telecommunications conference ( globecom 2010 ) , pp",
    ". 1 - 5 _ , december 2010 .",
    "j.  malone and m.  a. wickert , `` practical volterra equalizers for wideband satellite communications with twta nonlinearities , '' _ ieee digital signal processing workshop and ieee signal processing education workshop ( dsp / spe ) _ , january 2011 .",
    "v.  j. mathews and j.  lee , `` adaptive algorithms for bilinear filtering , '' in _",
    "spie s 1994 international symposium on optics , imaging , and instrumentation_.1em plus 0.5em minus 0.4eminternational society for optics and photonics , 1994 , pp .",
    "317327 .",
    "p.  antonik , a.  smerieri , f.  duport , m.  haelterman , and s.  massar , `` fpga implementation of reservoir computing with online learning , '' in _",
    "24th belgian - dutch conference on machine learning _",
    ", 2015 , http://homepage.tudelft.nl/19j49/benelearn/papers/paper_antonik.pdf .",
    "p.  antonik , f.  duport , a.  smerieri , m.  hermans , m.  haelterman , and s.  massar , `` online training of an opto - electronic reservoir computer , '' in _",
    "apnna s 22th international conference on neural information processing _ ,",
    "lncs , vol . 9490 , 2015 , pp . 233240 .",
    "l.  boccato , a.  lopes , r.  attux , and f.  j. von  zuben , `` an echo state network architecture based on volterra filtering and pca with application to the channel equalization problem , '' in _ neural networks ( ijcnn ) , the 2011 international joint conference on_.1em plus 0.5em minus 0.4em ieee , 2011 , pp . 580587 .",
    "r.  legenstein , s.  m. chase , a.  b. schwartz , and w.  maass , `` a reward - modulated hebbian learning rule can explain experimentally observed network reorganization in a brain control task , '' _ j. neurosci .",
    "_ , vol .  30 , pp .",
    "84008410 , 2010 .",
    "m.  duarte , a.  sabharwal , v.  aggarwal , r.  jana , k.  ramakrishnan , c.  w. rice , and n.  shankaranarayanan , `` design and characterization of a full - duplex multiantenna system for wifi networks , '' _ vehicular technology , ieee transactions on _ , vol .",
    "63 , no .  3 , pp .",
    "11601177 , 2014 .",
    "m.  hermans , j.  dambre , and p.  bienstman , `` optoelectronic systems trained with backpropagation through time , '' _ ieee transactions on neural networks and learning systems _ , vol .  26 , no .  7 , pp . 15451550 , 2015 .",
    "antonik , m.  hermans , f.  duport , m.  haelterman , and s.  massar , `` towards pattern generation and chaotic series prediction with photonic reservoir computers , '' in _",
    "spie s 2016 laser technology and industrial laser conference _ , vol . 9732 , 2016 ."
  ],
  "abstract_text": [
    "<S> reservoir computing is a bio - inspired computing paradigm for processing time dependent signals . </S>",
    "<S> the performance of its analogue implementation are comparable to other state of the art algorithms for tasks such as speech recognition or chaotic time series prediction , but these are often constrained by the offline training methods commonly employed . here </S>",
    "<S> we investigated the online learning approach by training an opto - electronic reservoir computer using a simple gradient descent algorithm , programmed on an fpga chip . </S>",
    "<S> our system was applied to wireless communications , a quickly growing domain with an increasing demand for fast analogue devices to equalise the nonlinear distorted channels . </S>",
    "<S> we report error rates up to two orders of magnitude lower than previous implementations on this task . </S>",
    "<S> we show that our system is particularly well - suited for realistic channel equalisation by testing it on a drifting and a switching channels and obtaining good performances .    </S>",
    "<S> artificial neural networks , channel equalisation , fpga , online learning , opto - electronic systems , reservoir computing </S>"
  ]
}