{
  "article_text": [
    "the largely accepted method for evaluating how much some available data @xmath3 ( typically forensic evidence ) is helpful in discriminating between two hypotheses of interest ( the prosecution hypothesis @xmath4 and the defense hypothesis @xmath5 ) , is the calculation of the _ likelihood ratio _ ( lr ) , a statistic that expresses the relative plausibility of the data under these hypotheses , defined as @xmath6    widely considered the most appropriate framework to report a measure of the ` probative value ' of the evidence regarding the two hypotheses @xcite , it indicates the extent to which data is in favor of one hypothesis over the other .",
    "forensic literature presents many approaches to calculate the lr , mostly divided into bayesian and frequentist methods ( see @xcite for a careful differentiation between these two approaches ) .",
    "this paper proposes a bayesian nonparametric method for the lr assessment in the rare type match case , the challenging situation in which there is a match between some characteristic of the recovered material and of the control material , but this characteristic has not been observed yet in previously collected samples ( i.e. database of reference ) .",
    "this constitutes a problem because the lr value depends on the proportion of the matching characteristic in a reference population , and this proportion is , in standard practice , estimated using the relative frequency of the characteristic in the available database . in particular , we will focus on y - str dna profile matches , for which the rare type match problem is often recurring @xcite . in this case data to evaluate",
    "is made of the information about the matching profile and of the list of dna profile in the database .",
    "the use of a bayesian nonparametric method is justified by the fact that the parameter of the model is the infinite dimensional vector @xmath1 , made of the ( unknown ) sorted population proportions of all possible y - str profiles , assumed to be infinitely many . as prior over @xmath1 we choose the two parameter poisson dirichlet distribution , and treat its parameters as hyperparameters ,",
    "hence provided with a hyperprior .",
    "moreover , we will discard the information contained in the names of the profiles , and this will lead to a reduction of the data @xmath3 to a smaller amount of information @xmath7 . the reduction of the data can be a wise practice in presence of many nuisance parameters as explained in @xcite , and sometimes the likelihood ratio based on the data reduction is much more precisely estimated than the likelihood ratio based on all data .    the paper is structured in the following way : section  [ bnpm ] introduces the notation , the assumptions of our model and the prior distribution chosen for parameter @xmath1 .",
    "section  [ m ] displays the model , via bayesian network representation , along with some theory on random partitions useful to define a clever and compact representation of the reduced data @xmath7 .",
    "an alternative representation of the same model via the chinese restaurant process is also described .",
    "section  [ gm ] introduces relevant known results regarding the two parameter poisson dirichlet distribution , along with a new lemma , which can be used for all the situations in which prosecution and defense agree on the distribution of part of the data and disagree on the distribution of the rest , given the parameter(s ) .",
    "this result will allow to derive the lr in a very elegant way ( section  [ lr ] ) .",
    "section  [ ard ] displays some experiments of application of this model on a real database of y - str profiles , such as model fitting , asymptotic power law behavior , study of the loglikelihood function , and comparison with the lr values obtained in the ideal situation in which vector @xmath1 is known .",
    "lastly , section  [ frq ] proposes questions for future research .",
    "in order to evaluate the match between the profile of a particular piece of evidence and a suspect s profile , it is necessary to estimate the proportion of that profile in the population of potential perpetrators . indeed , it is intuitive that the rarer the matching profile , the more the suspect is in trouble .",
    "problems arise when the observed frequency of the profile in a sample from the population of interest ( i.e. , in a reference database ) is 0 .",
    "such characteristic is likely to be rare , but it is challenging to quantify how rare it is .",
    "the rare type problem is particularly important in case a new kind of forensic evidence , such as results from dip - str markers ( see for instance @xcite ) is involved , and for which the available database size is still limited .",
    "the same happens when y - chromosome ( or mitochondrial ) dna profiles are used since the set of possible y - str profiles is extremely large . as a consequence ,",
    "most of the y - str haplotypes are not represented in the database .",
    "the y - str marker system will thus be retained here as an extreme but in practice common and important way in which the problem of assessing evidential value of rare type match can arise .",
    "this problem is so substantial that it has been defined `` the fundamental problem of forensic mathematics '' @xcite .",
    "the _ empirical frequency estimator _ , also called _ naive estimator _ , that uses the frequency of the characteristic in the database , puts unit probability mass on the set of already observed characteristics , and it is thus unprepared for the observation of a new type .",
    "a solution could be the _ add - constant _ estimators ( in particular the well known _",
    "add - one _ estimator , due to @xcite , and the _ add - half _ estimator of @xcite ) , which add a constant to the count of each type , included the unseen ones .",
    "however , this method requires to know the number of possible unseen types , and it is also not very performing when this number is large compared to the sample size ( see @xcite for additional discussion ) .",
    "alternatively , @xcite , based on an intuition on a.m. turing , proposed the _ good turing estimator _ for the total unobserved probability mass , based on the proportion of singleton observations in the sample .",
    "an extension of this estimator is applied to the lr assessment in the rare type match in @xcite . for",
    "a comparison between _ add one _ and _ good - turing _ estimator , see @xcite .",
    "as pointed out in @xcite , the _ naive estimator _ , and the _ good turing estimator _ are in some sense complementary : the first gives a good estimate for the observed types , and the second for the probability mass of the unobserved ones .",
    "more recently , @xcite have introduced the _ high profile estimator _ , which extends the tail of the _ naive estimator _ to the region of unobserved types .",
    "@xcite improved this estimator and provided the consistency proof .",
    "papers that address the rare y - str haplotype problem in forensic context are for instance @xcite , @xcite , and @xcite , which applied classical bayesian approach ( the beta binomial and the dirichlet multinomial problem ) to the lr assessment in the rare haplotype case .",
    "moreover , the discrete laplace method presented in @xcite , even though not specifically designed for the rare type case can be successfully applied to that extent @xcite .",
    "bayesian nonparametric estimators for the probability of observing a new type have been proposed by @xcite , using dirichlet process , by @xcite using general gibbs prior , and by @xcite with specific interest to the two parameter poisson dirichlet prior .",
    "however , for the lr assessment it is required not only the probability of observing a new species but also the probability of observing this same species twice ( according to the defense the crime stain profile and the suspect profile are two independent observations ) , and to our knowledge , this paper is the first one to address the problem of lr assessment in the rare haplotype case using bayesian nonparametric models .",
    "as prior we will use the poisson dirichlet distribution , which is proving useful in many discrete domain , in particular language modelling @xcite .",
    "in addition , it shows a power law behaviour which describe a incredible variety of phenomena @xcite .      throughout the paper",
    "the following notation is chosen : random variables and their values are denoted , respectively , with uppercase and lowercase characters : @xmath8 is a realization of @xmath9 .",
    "random vectors and their values are denoted , respectively , by uppercase and lowercase bold characters : @xmath1 is a realization of the random vector @xmath2 .",
    "probability is denoted with @xmath10 , while density of a continuous random variable @xmath9 is denoted alternatively by @xmath11 or by @xmath12 when the subset is clear from the context . for a discrete random variable @xmath13 ,",
    "the density notation @xmath14 and the discrete one @xmath15 will be alternately used .",
    "moreover , we will use shorthand notation like @xmath16 to stand for the probability density of y with respect to the conditional distribution of @xmath13 given @xmath17 .",
    "notice that when using the notation in  , @xmath3 is regarded as events .",
    "however , later in the paper , it will be regarded as a random variables . in that case",
    ", the following notation will thus be preferred : @xmath18",
    "lastly , notice that `` dna types '' is used throughout the paper as a general formula to indicate y - str profiles .",
    "our model is based on the two following assumptions :    assumption 1 : :    there are infinitely many dna types in nature .",
    "the reason for this assumption is that there are so many possible dna types that they can be considered infinite .",
    "this assumption , already used by e.g.  @xcite in the ` infinite alleles model ' , allows to use bayesian nonparametric methods and avoids the problem of specifying how many different types there are in nature .",
    "assumption 2 : :    the names of the different dna types do not contain information .    the specific sequence of numbers that forms a dna profile carries information : if two profiles show few differences this means that they are separated by few mutation drifts , hence the profiles share a relatively recent common ancestor",
    ". however , this information is difficult to exploit and may be not so relevant for the lr assessment .",
    "this is the reason why we will treat dna types as `` colors '' , and only consider the repartition into different categories .",
    "stated otherwise , we put no topological structure on the space of the dna types .",
    "notice that this assumption makes the model a priori suitable for any characteristic which shows many different possible types , thus what written still holds , in principle , also replacing ` dna types ' with any other type .",
    "however , we will only test the model with y - str data .      in bayesian statistics , parameter(s ) of interest are modeled through random variables . the ( prior ) distribution over the parameter(s ) should represent the uncertainty about its ( their ) value(s ) .",
    "lr assessment for the rare type match involves two unknown parameters of interest : one is @xmath19 , representing the unknown true hypothesis , the other is @xmath20 , the vector of the unknown population frequencies of all dna profiles in the population of potential perpetrators .",
    "the dichotomous random variable @xmath21 is used to model parameter @xmath22 , and the posterior distribution of this random variable , given data , is the ultimate aim of a forensic inquiry . in a similar way , random variable @xmath23 can be used to model @xmath20 .",
    "because of assumption  1 , @xmath20 is an infinite dimensional parameter , hence the need of bayesian nonparametric methods @xcite . in particular @xmath24 , with @xmath25 a countable set of indexes , @xmath26 , and @xmath27 .",
    "moreover , because of assumption  2 , data will be reduced to random partitions , as explained in section  [ partitions ] , and it will turn out that the distribution of these partitions does not depend on the order of the @xmath28 . hence , we can force the parameter @xmath1 to have values in @xmath29 , the ordered infinite dimensional simplex .",
    "the ordered random vector @xmath1 describes an infinite population randomly partitioned into dna types .",
    "the randomness is described by the prior distribution over @xmath1 , for which we choose the two - parameter poisson dirichlet distribution @xcite , defined in the following way :    given @xmath30 and @xmath31 satisfying the following conditions : @xmath32 the vector @xmath33 is said to be distributed according to the _ gem(@xmath34 ) _ , if @xmath35 where @xmath36 , @xmath37 , ... are independent random variables distributed according to @xmath38 it holds that @xmath39 , and @xmath40    the gem distribution ( short for griffin - engen - mccloskey distribution ) is well known in literature as the `` stick breaking prior '' , since it measures the random sizes in which a stick is broken iteratively .",
    "this distribution is invariant under size biased permutation @xcite , the random permutation defined by sampling from the population and assigning to each type a label , based on the order in which it is first sampled .",
    "[ pd ] given @xmath30 and @xmath31 satisfying condition  , and a vector @xmath41 , the random vector @xmath42 obtained by ordering @xmath43 , such that @xmath44 , is said to be _ poisson dirichlet distributed _ pd@xmath45 .",
    "parameter @xmath30 is called _ discount parameter _ , while @xmath31 is the _ concentration parameter . _",
    "notice that the vector @xmath46 is obtained by sorting the vector @xmath43 in non increasing order , while the vector @xmath43 can be obtained by the so - called _ size biased permutation _ of the indexes of @xmath46 @xcite .",
    "the two parameter poisson dirichlet distribution pd@xmath45 is the generalization of the well known poisson dirichlet distribution with a single parameter @xmath31 introduced by @xcite , which is the representation measure @xcite of the celebrated _ ewens sampling formula _",
    "@xcite , widely applied in genetics @xcite . for our model we will not allow @xmath47 , hence we will assume @xmath48 .",
    "it is worth mentioning that an alternative choice for the parameters space is @xmath49 , @xmath50 for some @xmath51 @xcite .",
    "it corresponds to a model with finitely many ( @xmath52 ) dna types , where the prior over @xmath53 is dirichlet with @xmath52 parameters equal to @xmath54 .",
    "lastly , we point out that , in practice , we can not assume to know parameters @xmath30 and @xmath31 : this is why we will treat them as hyperparameters on which we will put an hyperprior .",
    "\\(t ) at ( -4,4 ) @xmath55 ; ( h ) at ( 3,2 ) @xmath21 ; ( p ) at ( -4,2 ) @xmath46 ; ( y1 ) at (-8 , -1 ) @xmath56 ; ( y2 ) at ( -6,-1 ) @xmath57 ; ( yn ) at ( -1,-1 ) @xmath58 ; ( yn33 ) at ( 1,-1 ) @xmath59 ; ( yn34 ) at ( 3,-1 ) @xmath60 ; ( d ) at ( -3,-3 ) @xmath7 ;    \\(t )  ( p ) ; ( p )  ( y1 ) ; ( p )  ( y2 ) ; ( p )  ( yn ) ; ( p )  ( yn33 ) ; ( p )  ( yn34 ) ; ( h )  ( yn34 ) ; ( yn33 )  ( yn34 ) ; ( y1 ) ",
    "( d ) ; ( y2 ) ",
    "( d ) ; ( yn )  ( d ) ; ( yn33 ) ",
    "( d ) ; ( yn34 )  ( d ) ;    the bayesian network of figure  [ berhnt ] encapsulates the conditional dependencies of the variables of the proposed model .",
    "they are defined through random variables defined as follows :    * @xmath21 is a dichotomous random variable that represents the hypotheses of interest and can take values @xmath61 , according to the prosecution or the defense , respectively .",
    "a uniform prior on the hypotheses is chosen : @xmath62 * ( @xmath55 ) is the random vector that represents the hyperparameters @xmath30 and @xmath63 , satisfying condition  .",
    "the joint distribution of these two parameters ( hyperprior ) will be generically denoted as @xmath64 : @xmath65 * the random vector @xmath46 with values in @xmath66 , represents the ranked population frequencies .",
    "@xmath67 means that @xmath68 is the frequency of the most common dna type in the population , @xmath69 is the frequency of the second most common dna type , and so on . as a prior for @xmath46 we use the two - parameter poisson dirichlet distribution as in definition  [ pd ] : @xmath70 * integer valued random variables @xmath56 , ... ,",
    "@xmath58 represent the ranks of the population proportions of the dna types of the individuals in the database ( after some arbitrary ordering for profiles in the database is chosen ) .",
    "for instance , @xmath71 means that the third individual in the database has the fifth most common dna type in the population . since @xmath72 is unknown these random variables can not be observed .",
    "given @xmath72 they are an i.i.d . sample from @xmath72 : @xmath73 * @xmath59 represents the rank of the suspect s dna type .",
    "it is again a draw from @xmath72 .",
    "+ @xmath74 * @xmath60 represents the rank of the crime stain s dna type . according to the prosecution , given @xmath59 , this random",
    "variable is deterministic ( it is equal to @xmath75 with probability 1 ) . according to the defense it is another sample from @xmath72 : + @xmath76    as already mentioned , @xmath77 can not be observed .",
    "they represent the database ranked according to the unknown rank in @xmath20 and constitute an intermediate layer that helps in expressing the data in terms of observable partitions .",
    "section  [ partitions ] recalls some notions about random partitions , useful before defining node @xmath7 , representing the ` reduced ' data we want to evaluate .",
    "a _ partition of a set @xmath78 _ is an unordered collection of nonempty and disjoint subsets of @xmath78 the union of which forms @xmath78 .",
    "particularly interesting for our model are partitions of the set @xmath79=\\{1 , ... , n\\}$ ] , denoted as @xmath80}$ ] .",
    "the set of all partitions of @xmath81 $ ] will be denoted as @xmath82}$ ] .",
    "random partitions of @xmath81 $ ] will be denoted as @xmath83}$ ] . in addition , a _ partition of @xmath84 _ is a finite non increasing sequence of positive integers that sum up to @xmath84 .",
    "partitions of @xmath84 will be denoted as @xmath85 .",
    "given a sequence of integer valued random variables @xmath86 , let @xmath83}(x_1 , x_2 , ... , x_n)$ ] be the random partition defined by the equivalence classes of their indexes using the random equivalence relation @xmath87 iff @xmath88 .",
    "this construction allows to build a map from the set of values of @xmath86 to the set of the partitions of @xmath81 $ ] as in the following example ( @xmath89 ) : @xmath90 }   \\\\",
    "x_1 , ... , x_{10 }   & \\longmapsto   \\pi_{[10]}(x_1 , x_2 , ... , x_{10",
    "} ) \\\\ ( 3 , 1 , 3 , 1 , 2 , 2 , 6 , 9 , 4 , 1)&\\longmapsto \\ { \\{1,3\\ } , \\{2 , 4 , 10 \\ } , \\{5 , 6\\ } , \\{7\\ } , \\{8\\ } , \\{9\\ } \\ } \\end{aligned}\\ ] ]    typical data to evaluate in case of a match is @xmath91 , where @xmath92 , and    * @xmath93 = the database of size @xmath84 , which contains a sample of dna types , indexed by @xmath94 , from the population of possible perpetrators , * @xmath95 = suspect s dna type , * @xmath96 = crime stain s dna type ( matching with the suspect s type ) .    in agreement with assumption  2",
    ", we can consider the reduction of data which ignores information about the names of the dna types : this is achieved , for instance , by retaining only the equivalence classes of the relation `` to have the same dna type '' .",
    "the database can thus be reduced to the partition of @xmath81 $ ] , denoted @xmath80}^{\\text{db}}$ ] , and obtained using the equivalence classes of the indexes .",
    "notice that the same partition is obtained via random variables @xmath86 , as defined in .",
    "stated otherwise , we can reduce @xmath93 to @xmath80}^{\\text{db}}$ ] , the partition of @xmath81 $ ] obtained from the database .",
    "however , data is actually made of the background data along with the evidence , two new observations that match . in a similar way ,",
    "when the suspect profile is considered we obtain the partition @xmath97}$ ] , where the first @xmath84 integers are partitioned as in @xmath98}$ ] , and @xmath99 constitutes a single subset ( at least in the rare type match case ) .",
    "when the crime stain profile is considered we obtain the partition @xmath100}$ ] where the first @xmath84 integers are partitioned as in @xmath98}$ ] , and @xmath99 and @xmath101 belongs to the same ( new ) subset .",
    "random variables @xmath102}$ ] , @xmath103}$ ] , and @xmath104}$ ] are used to model @xmath80}^{\\text{db}}$ ] , @xmath105}^{\\text{db}+}$ ] , and @xmath106}^{\\text{db}++}$ ] , respectively .",
    "notice that , given @xmath30 and @xmath31 , prosecution and defense agree on the distribution of @xmath103}$ ] but disagree on the distribution of @xmath104}$ ] .",
    "it is worth noticing that , by construction , the same random partitions can be defined through random variables @xmath56 , ... , @xmath60 :    @xmath107}^{\\text{db}}&= \\pi_{[n]}(x_1 , ... , x_n),\\\\ \\pi_{[n+1]}^{\\text{db}+}&= \\pi_{[n+1]}(x_1 , ... , x_{n+1}),\\\\ \\pi_{[n+2]}^{\\text{db}++}&= \\pi_{[n+2]}(x_1 , ... , x_{n+2}).\\\\\\end{aligned}\\ ] ]    to clarify , consider the following example of a database ( db ) with @xmath108 different dna types , from @xmath89 individuals : @xmath109 where @xmath110 is the name of the @xmath111th dna type in the order chosen for the database .",
    "this can be reduced to the partition of @xmath112 $ ] : @xmath113}^{\\text{db}}=\\{\\{1,3\\ } , \\{2 , 4 , 10\\ } , \\{5,6\\ } , \\{7\\ } , \\{8\\ } , \\{9\\}\\}.\\ ] ] then , the part of data prosecution and defense agree on is @xmath114}^{\\text{db}+}=\\{\\{1,3\\ } , \\{2 , 4 , 10\\ } , \\{5,6\\ } , \\{7\\ } , \\{8\\ } , \\{9\\ } ,   \\{11\\ } \\},\\ ] ] while the entire data @xmath7 can be represented as @xmath115}^{\\text{db}++}=\\{\\{1,3\\ } , \\{2 , 4 , 10\\ } , \\{5,6\\ } , \\{7\\ } , \\{8\\ } , \\{9\\ } ,   \\{11 , 12\\ } \\}.\\ ] ]    now , assume that @xmath20 is known , thus we know also that @xmath116 is , for instance , the fourth most frequent type , @xmath117 is the second most frequent type , and so on .",
    "stated otherwise , we are now able to observe the variables @xmath56 , ... , @xmath60 : @xmath118 , @xmath119 , @xmath120 , @xmath121 , @xmath122 , @xmath123 , @xmath124 , @xmath125 , @xmath126 , @xmath127 , @xmath128 , @xmath129 .",
    "it is easy to check that @xmath83}(x_1 , ... , x_n)=\\pi_{[n]}^{\\text{db}}$ ] , @xmath130}(x_1 , ... , x_{n+1})=\\pi_{[n+1]}^{\\text{db+}}$ ] , @xmath131}(x_1 , ... , x_{n+2})=\\pi_{[n+2]}^{\\text{db++}}.$ ]",
    "data @xmath7 can now be defined as :    * @xmath132}$ ] , the partition of @xmath133 $ ] obtained from the database enlarged with the two new observations .",
    "node @xmath7 of figure  [ berhnt ] is defined accordingly .",
    "notice that , given @xmath134 , @xmath7 is deterministic .",
    "a very relevant result is that , according to proposition 4 in @xcite it is possible to describe directly the distribution of @xmath135 .",
    "hence , we can get rid of the intermediate layer of nodes @xmath56 , ... , @xmath60 .",
    "in particular , it holds that if @xmath136 and @xmath137 then , for all @xmath84 , the random partition @xmath83}=\\pi_{[n]}(x_1 , ... , x_{n})$ ] has the following distribution : @xmath138}):=\\pr(\\pi_{[n]}=\\pi_{[n]}| \\alpha , \\theta)=\\frac{[\\theta+ \\alpha]_{k-1 ; \\alpha}}{[\\theta+ 1]_{n-1 ; 1}}\\prod_{i=1}^k[1-\\alpha]_{n_i-1;1},\\ ] ] where @xmath139 is the size of the @xmath111th block of @xmath80}$ ] ( the blocks are here ordered according to the least element ) , and @xmath140 , @xmath141_{a , b}:=\\begin{cases } \\prod_{i=1}^{a-1 } ( x+ib ) & \\text{if } a\\in \\mathbb{n}\\backslash \\{0\\}\\\\ 0 & \\text{if } a=0 \\end{cases}.$ ] this formula is also known as the _ pitman sampling formula _ , further studied in @xcite .",
    "the model of figure  [ berhnt ] can thus be simplified ( see figure  [ bernt2c ] ) .",
    "\\(t ) at ( -2,0 ) @xmath55 ; ( h ) at ( -1,-1 ) @xmath21 ; ( d ) at ( -2,-2 ) @xmath7 ;    \\(t )  ( d ) ; ( h )  ( d ) ;    \\(t )  ( d ) ;    it holds that @xmath142}^{\\text{db+}})$ ] , and @xmath143}^{\\text{db++}})$ ] .    notice",
    "that for @xmath47 we obtain the ewens s sampling formula .",
    "there is an alternative characterization of this model , called `` chinese restaurant process '' , due to @xcite for the one parameter case , and studied in details for the two parameter version in @xcite .",
    "it is defined as follows : consider a restaurant with infinite tables , each one infinitely large .",
    "let @xmath144 be integer valued random variables that represent the seating plan : tables are ranked in order of occupancy , and @xmath145 means that the @xmath111th customer seats at the @xmath146th table to be created .",
    "the process is described by the following transition matrix : @xmath147 @xmath148    where @xmath149 is the number of tables occupied by the first @xmath84 customers , and @xmath139 is the number of customers that occupy table @xmath111 .",
    "@xmath150 are not i.i.d . , nor exchangeable , but it holds that @xmath83}(y_1 , ... , y_n)$ ] has the same distribution as @xmath83}(x_1 , ... , x_n)$ ] , with @xmath86 defined as in ( in particular they are distributed according to the pitman sampling formula  )",
    ".    stated otherwise , we can use the seating plan of @xmath84 customers to obtain the same partition @xmath80}^{\\text{db}}$ ] built through the database ( or by partitioning @xmath86 ) .",
    "then @xmath97}$ ] is obtained when a new customer has chosen an unoccupied table ( remember we are in the rare type case ) , and @xmath100}$ ] is obtained when the @xmath101nd customer goes to the same table of the @xmath99st ( suspect and crime stain have the same dna type ) .",
    "in particular , thanks to , we can write @xmath151}^{\\text{db++}}\\mid h_p , \\pi_{[n+1]}^{\\text{db+ } } , \\alpha , \\theta)=1,\\ ] ] and @xmath152}^{\\text{db++}}\\mid h_d , \\pi_{[n+1]}^{\\text{db+ } } , \\alpha , \\theta)=\\frac{1-\\alpha}{n+1+\\theta}\\ ] ]    since the @xmath101nd customer goes to the same table of the @xmath99st where he seats alone .",
    "this section presents some useful results that will be used in the forthcoming sections .",
    "in particular , lemma  [ lemma1 ] , suitable to broader applications , is here applied to simplify the lr development .",
    "then , some results from @xcite regarding the two parameter poisson dirichlet distribution , are listed .",
    "the following lemma is a result regarding four general random variables @xmath78 , @xmath9 , @xmath13 , @xmath21 whose conditional dependencies are described by the bayesian network of figure  [ figure1 ] . the importance of this result is due to the possibility of applying it to a very common forensic situation : the prosecution and the defense disagree on the entirety of data ( @xmath13 ) but agree on a part of it ( @xmath9 ) ( indeed , as already noticed , defense and prosecution agree on the distribution of @xmath105}^{\\text{db+}}$ ] , but not on the distribution of @xmath106}^{db++}$ ] ) .",
    "data depends on parameters ( @xmath78 ) .",
    "\\(t ) at ( -1,0 ) @xmath78 ; ( h ) at ( 1.5,0 ) @xmath21 ; ( d ) at ( -1,-2 ) @xmath9 ; ( dr ) at ( 1.5,-2 ) @xmath13 ; ( t )  ( d ) ; ( h )  ( dr ) ; ( t )  ( dr ) ; ( d )  ( dr ) ;    [ figure1 ]    [ lemma1 ] given four random variables @xmath78 , @xmath21 , @xmath9 and @xmath13 , whose conditional dependencies are represented by the bayesian network of figure  [ figure1 ] , the likelihood function for @xmath22 , given @xmath153 and @xmath154 satisfies @xmath155    the model of figure  [ figure1 ] represents four variables @xmath78 , @xmath21 , @xmath9 and @xmath13 whose joint probabilty density can be factored as @xmath156    by bayes formula , @xmath157 .",
    "this rewriting corresponds to reversing the direction of the arrow between @xmath78 and @xmath9 :    \\(a ) at ( -1,0 ) @xmath78 ; ( h ) at ( 1.5,0 ) @xmath21 ; ( x ) at ( -1,-2 ) @xmath9 ; ( y ) at ( 1.5,-2 ) @xmath13 ;    \\(x )  ( a ) ; ( a )  ( y ) ; ( h )  ( y ) ; ( x )  ( y ) ;    the random variable @xmath9 is now a root node .",
    "this means that when we probabilistically condition on @xmath153 , the graphical model changes in a simple way : we can delete the node @xmath9 , but just insert the value @xmath8 as a parameter in the conditional probability tables of the variables @xmath78 and @xmath13 which formerly had an arrow from node @xmath9 .",
    "the next graph represents this model :    \\(a ) at ( -1,0 ) @xmath78 ; ( h ) at ( 1.5,0 ) @xmath21 ; ( x1 ) at ( -1,-1.5 ) @xmath8 ; ( x2 ) at ( 0,-2 ) @xmath8 ; ( y ) at ( 1.5,-2 ) @xmath13 ;    ( x1 )  ( a ) ; ( a )  ( y ) ; ( h )  ( y ) ; ( x2 )  ( y ) ;    this tells us , that conditional on @xmath153 , the joint density of @xmath78 , @xmath13 and @xmath21 is equal to @xmath158 the joint density of @xmath21 and @xmath13 is obtained by integrating out the variable @xmath159 .",
    "it can be expressed as a conditional expectation value , since @xmath160 is the density of @xmath78 given @xmath153 .",
    "we find : @xmath161    recall that this is the joint density of two of our variables , @xmath21 and @xmath13 , after conditioning on the value @xmath153 .",
    "let us now also condition on @xmath154 .",
    "it follows that the density of @xmath21 given @xmath153 and @xmath154 is proportional ( as function of @xmath21 , for fixed @xmath8 and @xmath162 ) to the same expression , @xmath163 .",
    "this is a product of the prior for @xmath22 with some function of @xmath8 and @xmath162 . since posterior odds",
    "equals prior odds times likelihood ratio , it follows that the likelihood function for @xmath22 , given @xmath153 and @xmath154 satisfies @xmath164    [ lemma21 ] given four random variables @xmath78 , @xmath21 , @xmath9 and @xmath13 , whose conditional dependencies are represented by the network of figure  [ figure1 ] , the likelihood ratio for @xmath165 against @xmath166 given @xmath153 and @xmath154 satisfies @xmath167      we will now list some theoretical results which will be useful in the forthcoming analysis .",
    "most of these results can be found in @xcite .",
    "denote as @xmath168 the random number of blocks of a partition @xmath83}$ ] distributed according to the pitman sampling formula with parameters @xmath30 and @xmath31 .",
    "* it exists a positive random variable @xmath169 such that @xmath170 the distribution of @xmath169 is a generalization of the mittag leffler distribution @xcite . * if @xmath171 , then @xmath172 for a random variable @xmath173 such that @xmath174 . * for a fixed @xmath175 , the pd(@xmath34 ) ( for different @xmath31 ) are all mutually absolutely continuous .",
    "this means that @xmath31 can not be consistently estimated for @xmath30 in the range of interest . on the other hand",
    ", the power law behavior described above tells us that @xmath30 can be consistently estimated . *",
    "studying one can see that when @xmath84 increases , the parameter @xmath31 becomes less and less important .",
    "however , it describes how much `` social '' are the customers : the smaller @xmath31 the more the customers tend to seat to already occupied tables .",
    "thus , it determines the sizes of the big tables , but it wo nt be much important for our application ( the more rare dna types ) .",
    "* given @xmath176 distributed according to pitman sampling formula , it holds that @xmath177 where @xmath178 , @xmath179 the random number of blocks of the partition @xmath83}$ ] of size @xmath146 .",
    "this result is presented in @xcite , based on @xcite .",
    "the hypotheses of interest are :    * @xmath4 = the crime stain was left by the suspect . *",
    "@xmath5 = the crime stain was left by someone else .",
    "the lr will thus be defined as @xmath180}^{\\text{db}++}|h_p)}{p(\\pi_{[n+2]}^{\\text{db}++}|h_d)}= \\frac{p(\\pi_{[n+1]}^{\\text{db}+},\\pi_{[n+2]}^{\\text{db}++}|h_p)}{p(\\pi_{[n+1]}^{\\text{db}+},\\pi_{[n+2]}^{\\text{db}++}|h_d)}.\\ ] ]    where the last equality is due to the fact that @xmath130}^{\\text{db}+}$ ] is deterministic , given @xmath131}^{\\text{db}++}$ ] .",
    "corollary  [ lemma21 ] with @xmath181 , @xmath182}^{\\text{db}+}$ ] , @xmath183}^{\\text{db}++}$ ] , and @xmath184 allows to obtain the lr as : @xmath185}^{\\text{db}++}\\mid \\pi_{[n+1]}^{\\text{db}+ } , a , \\theta , h_p ) \\mid \\pi_{[n+1]}^{\\text{db}+}= \\pi_{[n+1]}^{\\text{db}+ } ) } { \\mathbb{e}(p(\\pi_{[n+2]}^{\\text{db}++}\\mid \\pi_{[n+1]}^{\\text{db}+ } , a , \\theta , h_d ) \\mid \\pi_{[n+1]}^{\\text{db}+}= \\pi_{[n+1]}^{\\text{db}+ } ) } \\\\[11pt ] & = \\frac{1}{\\mathbb{e}\\big(\\frac{1-a}{n+1+\\theta}\\mid \\pi_{[n+1]}^{\\text{db}+}= \\pi_{[n+1]}^{\\text{db}+}\\big)}. \\end{aligned}\\ ] ] where the last equality is due to and . by defining the random variable @xmath186 we can write the lr as @xmath187}=\\pi_{[n+1]})}.\\ ] ]      in order to evaluate the performance of this method one would like to compare the lr values obtained with with the ` true ' ones , meaning the lr values obtained when vector @xmath1 is known , which means that we have the list of the frequencies of all the dna types in the population of interest .",
    "the lr in this case can be obtained in the following way : @xmath188}^{\\text{db++}}|\\pi_{[n+1]}^{\\text{db+}},h_p , \\mathbf{p})}{p(\\pi_{[n+2]}^{\\text{db++}}|\\pi_{[n+1]}^{\\text{db+}},h_d , \\mathbf{p})}=\\frac{1}{p(\\pi_{[n+2]}^{\\text{db++}}|\\pi_{[n+1]}^{\\text{db+ } } , h_d , \\mathbf{p})}\\\\ & = \\frac{1}{\\pr(x_{n+2}=x_{n+1}|\\pi_{[n+1]}^{\\text{db+ } } , h_d , \\mathbf{p})}\\\\ & = \\frac{1}{{\\displaystyle \\sum_{(x_1 , ... , x_{n+1 } ) } \\pr(x_{n+2}=x_{n+1}|x_1 , ... ,",
    "x_{n+1},\\pi_{[n+1]}^{\\text{db+ } } , h_d , \\mathbf{p } } ) p(x_1 , ... ,",
    "x_{n+1}|\\pi_{[n+1]}^{\\text{db+ } } , \\mathbf{p})}\\\\ & = \\frac{1}{{\\displaystyle \\sum_{(x_1 , ... , x_{n+1 } ) } } p_{x_{n+1 } } p(x_1 , ... ,",
    "x_{n+1}|\\pi_{[n+1]}^{\\text{db+ } } , \\mathbf{p})}\\\\ & = \\frac{1}{\\mathbb{e}(p_{x_{n+1}}|\\pi_{[n+1]}^{\\text{db+ } } , \\mathbf{p})}. \\label{ddd2 }   \\end{aligned}\\ ] ]    notice that in the rare type case @xmath75 is observed only once among the @xmath189 , ... ,",
    "hence we call it a singleton",
    ". let @xmath190 denote the number of singletons , and @xmath191 the set of all singletons",
    ". given @xmath1 and @xmath105}^{\\text{db+}}$ ] , it holds that the distribution of @xmath59 is the same as the distribution of all other @xmath190 singletons .",
    "this implies that :    @xmath192}^{\\text{db+ } } , \\mathbf{p } ) =   \\mathbb{e}(\\sum_{x_i \\in \\mathcal{s}}p_{x_{i}}|\\pi_{[n+1]}^{\\text{db+ } } , \\mathbf{p}).\\ ] ]    let us denote as @xmath193 , .. , @xmath194 the @xmath195 different values taken by @xmath56 , ... , @xmath59 , ordered according to the frequency of their values .",
    "stated otherwise , if @xmath139 is the frequency of @xmath196 among @xmath197 then @xmath198 .",
    "moreover , in case @xmath199 and @xmath200 have the same frequency ( @xmath201 ) , than they are ordered according to their values .",
    "for instance , if @xmath118 , @xmath119 , @xmath120 , @xmath121 , @xmath122 , @xmath123 , @xmath124 , @xmath125 , @xmath126 , @xmath127 , @xmath128 , then @xmath202 .    by definition",
    ", it holds that @xmath203}^{\\text{db+ } } , \\mathbf{p } ) = \\mathbb{e}(\\sum_{j : \\ , n_j=1}p_{x_{j}^*}|\\pi_{[n+1]}^{\\text{db+ } } , \\mathbf{p}).\\ ] ]    notice that @xmath204 is a partition of @xmath99 , which will be denoted as @xmath205 . in the example , @xmath206 .",
    "a more compact representation for @xmath205 can be obtained by using two vectors @xmath207 and @xmath208 where @xmath209 are the distinct numbers occurring in the partition , ordered , and each @xmath210 is the number of repetitions of @xmath209 .",
    "@xmath211 is the length of these two vectors , and it holds that @xmath212 in the example above we have that @xmath213 with @xmath214 and @xmath215 .",
    "since the distribution of @xmath216 only depends on @xmath205 , the latter can replace @xmath105}^{\\text{db+}}$ ] .",
    "thus , it holds that @xmath217    notice that the knowledge of @xmath1 , is not enough to observe @xmath218 : @xmath1 is sorted in decreasing order , and even if we know the different values @xmath28 , we do nt know to which category each value belongs .",
    "there is a function , @xmath219 , treated here as latent variable , which assigns all dna types , ordered according to their frequency in nature , to one of the number @xmath220 corresponding to the position in @xmath207 of its frequency in the sample , or to @xmath221 if the type if not observed .",
    "stated otherwise , @xmath222",
    "@xmath223    given @xmath213 , @xmath219 must satisfy the following conditions : @xmath224    the map @xmath219 can be represented by a vector @xmath225 made of its values : @xmath226 . in the example above we have that @xmath227 .",
    "notice that , given @xmath228 , the knowledge of @xmath229 implies the knowledge of @xmath193 , ... ,",
    "@xmath230 : indeed it is enough to sort the positive values among the @xmath231 and take their positions in @xmath219 solving ties by considering the position themselves ( if @xmath232 , than the order is given by @xmath111 and @xmath146 ) .",
    "for instance , in the example , if we sort the values of @xmath219 and we collect their positions we get @xmath233 : the reader can notice that we got back to the @xmath234 .",
    "this means that to obtain the distribution of @xmath235 , which appears in  , it is enough to obtain the distribution of @xmath236 .",
    "actually , we are only interested in the mean of the sum of singletons in samples of size @xmath99 from the distribution of @xmath235 : this means that we can just simulate samples from the distribution of @xmath237 and sum those @xmath238 such that @xmath239    to simulate samples from the distribution of @xmath237 we use a metropolis - hasting algorithm , on the space of the vectors satisfying condition  .",
    "notice that for the model we assumed @xmath1 to be infinitely long , but for simulations we will use a finite @xmath240 , of length @xmath241 .",
    "this is equivalent to assume that only @xmath241 elements in the infinite @xmath1 are positive , and the remaining infinite tail is made of zeros .",
    "then the state space of the metropolis hasting markov chain is made of all vectors of length @xmath241 whose elements belong to @xmath242 , and satisfy the condition  .",
    "if we start with a initial point @xmath243 which satisfies   and , at each allowed move of the metropolish hasthing , we swap two different values @xmath244 and @xmath245 inside the vector , condition remains satisfied .",
    "the algorithm is based on a similar one proposed in  @xcite .",
    "this method allows us to obtain the ` true ' lr when the vector @xmath1 is known .",
    "this is rarely the case , but we can put ourselves in a fictitious world where we know @xmath1 , and compare the true values for the lr with the one obtained by applying our model when @xmath1 is unknown .",
    "this will be done in the forthcoming section .",
    "in this section we present the study we made on a database of 18,925 y - str 23-loci profiles from 129 different locations in 51 countries in europe @xcite .",
    "different analyses are performed by considering only 7 y - str loci ( dys19 , dys389 i , dys389 ii , dys3904 , dys3915 , dy3926,dy3937 ) but similar results have been observed with the use of 10 loci .    first the maximum likelihood estimators @xmath246 and @xmath247 using the entire database are obtained .",
    "their values are @xmath248 and @xmath249    in order to check if the choice of the two parameter poisson dirichlet prior is a sensible one we first compare the ranked frequencies from the database with the relative frequencies of several samples of size @xmath84 obtained from realisations of pd(@xmath250 ) .",
    "the asymptotic behaviour described in is also checked .",
    "lastly , we will analyse the loglikelihood function for data @xmath105}^{\\text{db}+}$ ] in order to study the denominator of the lr",
    ".       obtained from realization of pd(@xmath250 ) ( thin lines ) .",
    "asymptotic power law behavior is also displayed ( dotted lines ) . ]    in figure  [ 3figs ] , the ranked frequencies from the database are compared to the relative frequencies of samples of size @xmath84 obtained from several realizations of pd(@xmath250 ) .",
    "to do so we run several times the chinese restaurant seating plan ( up to @xmath251 customers ) : each run is equivalent to generate a new realization @xmath20 from the pd(@xmath250 ) .",
    "the partition of the customers into tables is the same as the partition obtained from an i.i.d .",
    "sample of size @xmath84 from @xmath20 .",
    "the ranked relative sizes of each table ( thin lines ) are compared to the ranked frequencies of our database ( thick line ) .      the asymptotic behavior described in",
    "is also analyzed in figure  [ 3figs ] .",
    "this behavior is expected in the tail ( the limit is over @xmath111 ) and clearly the number of customers ( @xmath251 ) is not big enough for the small @xmath252 to follow the power law .",
    "it is also interesting to investigate the shape of the loglikelihood function for @xmath30 and @xmath31 given @xmath105}^{\\text{db}++}$ ] .",
    "it is defined as    @xmath253}^{\\text{db}++}| \\alpha , \\theta).\\ ] ] in figure  [ 2figs ] ( a ) , the loglikelihood function is compared to the gaussian distribution centered in the maximum likelihood estimates for @xmath30 and @xmath31 , with the observed fisher information as covariance matrix . in figure  [ 2figs ] ( b ) the loglikelihood reparametrized using @xmath254 , and @xmath31 instead of @xmath30 and @xmath31 , is displayed and compared to the corresponding gaussian distribution .",
    "the posterior distribution for ( @xmath255,@xmath256 ) given @xmath130}^\\text{db+}$ ] is proportional to the loglikelihood @xmath257}(\\phi , \\theta)$ ] times the prior @xmath258 .",
    "the gaussian behavior of @xmath257}(\\phi , \\theta)$ ] is particularly interesting since it allows to conclude that if the prior @xmath258 is smooth around @xmath259 , we can approximate @xmath260}^{\\text{db}++})$ ] with @xmath261 .",
    "hence , one can approximate the lr itself in the following way : @xmath262    notice that this is equivalent to an hybrid approach , in which the parameters are estimated through the mle ( frequentist ) and their value plugged into the bayesian lr .      as explained in section  [ tlr ] , a metropolis hasting algorithm , based on @xcite ,",
    "can be used to obtain the ` true lr ' , that is the lr when the vector @xmath1 is known , as defined in - .",
    "the latter will be denoted as @xmath263 .",
    "this can be compared to the lr obtained with the method described in this paper , when @xmath1 is unknown , as defined in - .",
    "notice that errors appear at different levels @xcite : error due to limitedness of samples , error in the model , error in the choice of the parameters of the model .",
    "the following three tests will explore these levels .",
    "instead of using the big database of @xcite we consider its restriction to the dutch population ( of size 2085 ) : we pretend this to be the entire population of possible perpetrators , and compare the distribution of @xmath264 and @xmath265 obtained by 100 samples of size 100 from this population .      in order to avoid error due to model selection",
    ", we use as entire population a sample from a realization from pd(@xmath34 ) distribution .",
    "this is done by running the two parameter chinese restaurant process up to 2085 customers .",
    "then , again , 100 samples of size 100 from this population are sampled and @xmath264 and @xmath265 are compared .",
    "this procedure is repeated 5 times to use 5 different poisson dirichlet populations .      the same as in test 2 , but in order to avoid also error due to mle parameter estimations , we use as parameters @xmath30 and @xmath31 for @xmath265 exactly those which have been used to generate the chinese restaurant process .",
    "when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ] when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ]   when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ] when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ]   when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ] when the population proportions @xmath1 are known ( lr@xmath266 ) , and when they are not ( lr ) .",
    "( b ) the error @xmath267.,title=\"fig:\",scaledwidth=40.0% ]",
    "[ frq ]    because of the mutual absolute continuity results we know that @xmath31 can not be consistently estimated . however , there exists at least one consistent estimator for @xmath30 @xcite , namely : @xmath268 moreover , @xmath30 can be estimated consistently also from the power law of .",
    "we are interested in the consistency of @xmath269 , at least when @xmath31 is known , although literature @xcite is quite skeptical about its performance .",
    "the observed fisher information for @xmath30 grows with @xmath84 and this gives some hope for the consistency of @xmath269 .",
    "the gaussian behavior of figure  [ 2figs ] was unexpected .",
    "at least , we expect that increasing @xmath84 , @xmath30 and @xmath31 would become independent , thus the ellipses will rotate .",
    "i am indebted to jim pitman and alexander gnedin for their help in understanding their important theoretical results , and to mikkel meyer andersen for providing a cleaned version of the database of @xcite .",
    "this research was supported by the swiss national science foundation , through grants no .",
    "105311 - 144557 and 10531a-156146 , and carried out in the context of a joint research project , supervised by franco taroni ( university of lausanne , ecole des sciences criminelles ) , and richard gill ( mathematical institute , leiden university ) .",
    "favaro , s. , lijoi , a. , mena , r.  h.  pruenster , i. 2009 , ` bayesian nonparametric inference for species variety with a two parameter poisson - dirichlet process prior ' , _ journal of the royal statistical society : series b ( methodological ) _ * 71 * ,  9931008 .",
    "purps , j. , siegert , s. , willuweit , s. , nagy , m. , alves , c. , salazar , r. , angustia , s. m.  t. , santos , l.  h. , anslinger , k. , bayer , b. , ayub , q. , wei , w. , xue , y. , tyler - smith , c. , bafalluy , m.  b. , martnez - jarreta , b. , egyed , b. , balitzki , b. , tschumi , s. , ballard , d. , court , d.  s. , barrantes , x. , bler , g. , wiest , t. , berger , b. , niedersttter , h. , parson , w. , davis , c. , budowle , b. , burri , h. , borer , u. , koller , c. , carvalho , e.  f. , domingues , p.  m. , chamoun , w.  t. , coble , m.  d. , hill , c.  r. , corach , d. , caputo , m. , damato , m.  e. , davison , s. , decorte , r. , larmuseau , m. h.  d. , ottoni , c. , rickards , o. , lu , d. , jiang , c. , dobosz , t. , jonkisz , a. , frank , w.  e. , furac , i. , gehrig , c. , castella , v. , grskovic , b. , haas , c. , wobst , j. , hadzic , g. , drobnic , k. , honda , k. , hou , y. , zhou , d. , li , y. , hu , s. , chen , s. , immel , u .- d . , lessig , r. , jakovski , z. , ilievska , t. , klann , a.  e. , garca , c.  c. , de  knijff , p. , kraaijenbrink , t. , kondili , a. , miniati , p. , vouropoulou , m. , kovacevic , l. , marjanovic , d. , lindner , i. , mansour , i. , al - azem , m. , andari , a.  e. , marino , m. , furfuro , s. , locarno , l. , martn , p. , luque , g.  m. , alonso , a. , miranda , l.  s. , moreira , h. , mizuno , n. , iwashima , y. , neto , r. s.  m. , nogueira , t. l.  s. , silva , r. , nastainczyk - wulf , m. , edelmann , j. , kohl , m. , nie , s. , wang , x. , cheng , b. , nez , c. , pancorbo , m. m.  d. , olofsson , j.  k. , morling , n. , onofri , v. , tagliabracci , a. , pamjav , h. , volgyi , a. , barany , g. , pawlowski , r. , maciejewska , a. , pelotti , s. , pepinski , w. , abreu - glowacka , m. , phillips , c. , crdenas , j. , rey - gonzalez , d. , salas , a. , brisighelli , f. , capelli , c. , toscanini , u. , piccinini , a. , piglionica , m. , baldassarra , s.  l. , ploski , r. , konarzewska , m. , jastrzebska , e. , robino , c. , sajantila , a. , palo , j.  u. , guevara , e. , salvador , j. , ungria , m. c.  d. , rodriguez , j. j.  r. , schmidt , u. , schlauderer , n. , saukko , p. , schneider , p.  m. , sirker , m. , shin , k .- j .",
    ", oh , y.  n. , skitsa , i. , ampati , a. , smith , t .-",
    ", calvit , l. s.  d. , stenzl , v. , capal , t. , tillmar , a. , nilsson , h. , turrina , s. , de  leo , d. , verzeletti , a. , cortellini , v. , wetton , j.  h. , gwynne , g.  m. , jobling , m.  a. , whittle , m.  r. , sumita , d.  r. , wolaska - nowak , p. , yong , r. y.  y. , krawczak , m. , nothnagel , m.  roewer , l. 2014 , ` a global analysis of y - chromosomal haplotype diversity for 23 str loci ' , _ forensic science international : genetics _ * 12 * ,  1223 ."
  ],
  "abstract_text": [
    "<S> the evaluation of a match between the dna profile of a stain found on a crime scene and that of a suspect ( previously identified ) involves the use of the unknown parameter @xmath0 , ( the ordered vector which represents the frequencies of the different dna profiles in the population of potential donors ) and the names of the different dna types . </S>",
    "<S> we propose a bayesian nonparametric method which models @xmath1 through a random variable @xmath2 distributed according to the two - parameter poisson dirichlet distribution , and discards the information about the names of the different dna types . the ultimate goal of this model is to evaluate the so - called ` probative value ' of dna matches in the rare type case , that is the situation in which the suspect s profile , matching the crime stain profile , is not in the database of reference . </S>"
  ]
}