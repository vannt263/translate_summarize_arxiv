{
  "article_text": [
    "let us suppose that we are dealing with a system with deterministic dynamics , on which external noise is acting .",
    "that means that , in case we could remove the noise ( by switching it off if possible , by isolating the system , etc ) , its equations of motion would be purely deterministic :    @xmath2    now , let us consider that gaussian white noise is acting on the system . to include its effects",
    ", we add to ( [ eq : deterministic ] ) a term @xmath3 :    @xmath4    where the functions of @xmath5 are determined by some physical considerations , and the components of @xmath6 are independent wiener processes .",
    "a wiener process @xcite is a gaussian stochastic process , almost surely continuous , where non - overlapping increments are independent , and with    @xmath7      equation ( [ eq : stochastic ] ) can be written as    @xmath8    an issue arises when defining the integral over the wiener processes .",
    "if we take a partition @xmath9 of the interval @xmath10 $ ] ( where @xmath11 ) , and being @xmath12 a value between @xmath13 and @xmath14 , @xmath15 , we would define the integral of any function @xmath16 as @xcite    @xmath17,\\ ] ]    where @xmath18 .",
    "the issue is that the limit above is different for different choices of @xmath19 .",
    "the most common interpretations are the ito scheme , in which the function is evaluated at the left - hand endpoint of each sub - interval ( @xmath20 ) , and the stratonovich scheme , in which the function is evaluated at the midpoint of each sub - interval ( @xmath21 ) .",
    "we usually write the stratonovich calculus with a circle before @xmath22 .",
    "the solutions to the stochastic differential equations are different for both interpretations , given that the stochastic integrals have a different value for each one .",
    "for example , the integral bellow in the ito calculus is @xcite ,    @xmath23 - \\frac{1}{2}(t - t_0),\\ ] ]    while for stratonovich calculus ,    @xmath24.\\ ] ]    chosen one interpretation , one can always do the calculus in the other interpretation by modifying @xmath25 with the _ ito - stratonovich drift correction formula _ :",
    "the two equations bellow    @xmath26    have the same solution if their drifts fulfil the relationship    @xmath27    when the equations ( [ eq : stochastic ] ) model a physical system , the  white noise \" @xmath22 is actually an idealization of noise with a small correlation time : the autocorrelation function of @xmath28 is not really a delta function , but a sharply peaked one ; i.e. , its correlation time is small , but positive .",
    "therefore , the stochastic function @xmath28 is actually not singular , and the stochastic differential equations ( [ eq : stochastic ] ) have a well - defined solution . in the limit of correlation time of @xmath28",
    "going to zero , such solution tends to the integration of the equations with the stratonovich interpretation ( see more details and a discussion in chapter ix.5 of @xcite , _ discussion of the ito - stratonovich dilemma _ ) .",
    "that is why we will use the stratonovich interpretation .",
    "we will consider three light - weight ( in terms of the complication of the formulae ) numerical integration methods leading to the stratonovich interpretation .",
    "they all require using a sample of the discretized wiener process at each integration step .",
    "let @xmath29 be the length of the time step used for the numerical integration .",
    "therefore , according to the properties of the wiener process ( [ wiener_process ] ) , we need a sample of independent random variables @xmath30 at each of the values of the time @xmath31 in the discretization , distributed as @xmath32 , where @xmath33 stands for the normal distribution with mean @xmath34 and variance @xmath35 .",
    "one of the simplest discretization schemes leading to the stratonovich interpretation is the heun method .",
    "this is a predictor - corrector method : given the value of @xmath36 at a time @xmath37 of the discretization , we first obtain the predictors , or supporting values , with the euler integration scheme    @xmath38    where @xmath39 .",
    "then , we obtain @xmath40 as    @xmath41\\ , h\\nonumber\\\\ & & \\quad +   \\frac{1}{2}\\left [ g_{ij } ( x(t_n ) , t_n)+ g_{ij } ( \\bar{x } ( t_{n+1 } ) , t_{n+1})\\right]\\ , \\xi_j(t_n).\\end{aligned}\\ ] ]    note that we are using einstein s tensor convention of summing over repeated indices .",
    "the milstein scheme requires the use of the derivatives of the diffusion coefficients . in the general case ,",
    "it reads    @xmath42    where all the terms at the right hand side of ( [ milstein_general ] ) are taken at time @xmath37 , and @xmath43 is a multiple stratonovich integral    @xmath44    ( when using the ito interpretation , the corresponding multiple ito integral is defined in the same way as in ( [ multiple_strat_integral ] ) , but with the ito interpretation , and written as @xmath45 . )    these integrals can not be easily expressed in terms of the increments @xmath46 and @xmath47 of the components of the wiener process .",
    "nevertheless , we can consider the particular case of diagonal noise , where each component of the system has its own , independent , noise , i.e. : there are as many independent wiener processes ( number of components of @xmath6 ) as the number of variables in the system ( the number of components of @xmath36 ) , each component @xmath48 of @xmath36 is affected only by the corresponding component @xmath49 of the wiener process , and the diagonal diffusion coefficient @xmath50 depends only on @xmath48 and maybe on time ( but not on the other components of @xmath36 ) .",
    "in such a case , @xmath51 in ( [ milstein_general ] ) is not equal to zero only where @xmath52 , @xmath53 only where @xmath54 , and @xmath55 only where @xmath56 .",
    "putting all things together , the last term in ( [ milstein_general ] ) is equal to    @xmath57    ( it is clear that we are not summing over @xmath58 in the expression above , given that @xmath58 is an external index in ( [ milstein_general ] ) ; we will omit this remark wherever it would be easy to figure out over which repeated indices we are not summing up . ) regarding the last factor in the product above , ( [ multiple_strat_integral ] ) becomes for @xmath59 ,    @xmath60\\circ \\mathrm{d}w_i ( s_1)\\nonumber\\\\ & = & \\int_{t_n}^{t_{n+1 } } w_i ( s_1)\\circ \\mathrm{d}w_i ( s_1 ) - w_i(t_n)\\int_{t_n}^{t_{n+1}}\\circ\\ , \\mathrm{d}w_i ( s_1)\\nonumber\\\\ & = & \\frac{1}{2}[w_i(t_{n+1})^2 - w_i(t_n)^2 ] - w_i(t_n ) [ w_i(t_{n+1})-w_i(t_n ) ] \\nonumber\\\\ & = &   \\frac{1}{2}[w_i(t_{n+1 } ) - w_i(t_n)]^2.\\end{aligned}\\ ] ]    where ( [ integral_stratonovich ] ) has been used at the third equality .",
    "therefore , for the numerical integration , we set @xcite @xmath61 as a result , for diagonal noise the milstein method ( [ milstein_general ] ) becomes , in the stratonovich interpretation ,    @xmath62    it is also possible to simplify the general expression ( [ milstein_general ] ) for the case of commutative noise @xcite , a case slightly more general than our case of diagonal noise .",
    "the milstein method above requires the analytic specification of the first derivative of the diffusion term",
    ". this can be sometimes inefficient , either because the analytic expression of the derivative is highly complex , or because we are trying many different functions for @xmath63 , etc .",
    "in such cases , we can use a numerical approximation for the derivative of @xmath63 for use in the milstein scheme .    here , we will only give the expression for diagonal noise .",
    "the formulae for the ito interpretation can be seen on equations ( 1.3 ) and ( 1.4 ) of chapter 11 in @xcite .",
    "first of all , the supporting values are obtained as    @xmath64    then , starting from ( [ milstein_diagonal ] ) for the stratonovich interpretation , we get    @xmath65\\ , \\xi_i^{\\ 2}.\\ ] ]",
    "for each method , we are interested in checking its degree of strong convergence , or convergence over the path .",
    "that means that , for any single realisation @xmath66 of the wiener process on a given time interval @xmath67 $ ]  that must be chosen as the biggest time interval that we will use among all our simulations  , and starting with given initial conditions @xmath68 for the system , the final point @xmath69 obtained with a good integration scheme , using a number of time steps big enough , must be close to the real solution of the differential equation , at time @xmath70 ( for that particular realisation of the wiener process @xmath66 and for this particular initial condition @xmath68 ) .",
    "of course , when selecting any other realisation of the wiener process and any other initial condition , the final point at time @xmath70 obtained by the integration method must be close to the one of the real solution as well .    of course",
    ", we can not know the value of @xmath69 obtained with the real solution but , still , we can test whether the integration method gives something close enough to it , by studying the self - consistence .",
    "if we have chosen a small number of integration steps ( a big value for the time step @xmath29 ) , the obtained @xmath69 will not be reliable and , when repeating the integration with more time steps ( but the same wiener process and the same initial conditions ) , we will obtain a new @xmath69 which will considerably differ from the previous one . on the other hand , we can be reasonably sure that we have already chosen a number of integration steps big enough , and therefore we have obtained a reliable value of @xmath69 if , after repeating the integration once more with a considerably bigger number of time steps ( e.g. , twice the former number of time steps , with same wiener process and same initial conditions ) , the new obtained @xmath69 stays close to the value previously obtained .",
    "we are using here this method of self - consistency via the _ brownian tree _ : we will start with the maximum number of timesteps @xmath71 , for a chosen natural number @xmath72 , and we will then progressively reduce the number of integration steps by a half each time , i.e. , we will integrate with @xmath71 , @xmath73 , @xmath74 , etc , time steps , until the desired minimum power of 2 ( that can be , if desired , as little as @xmath75 , i.e. , a single time step ) . given the discretised wiener process @xmath76 for @xmath0 time steps , we obtain the discretisation of the same wiener process for half the number of time steps by summing up the two members of each couple , i.e.    @xmath77    sometimes , one may first take a signal of gaussian white noise @xmath78 with mean zero and variance 1 ( i.e. , @xmath78 is distributed as @xmath79 ) , so the integration routine gets the increments @xmath80 of the wiener process from the 1correlated signal @xmath78 as @xmath81 , where @xmath29 is the time step that is used at that moment to integrate the differential equation ( see introduction to section [ sec : integration_methods ] ) .",
    "then , when halving the total number of time steps ( and therefore doubling the time step to @xmath82 ) , the new signal @xmath78 still has to be 1correlated , so we have to make    @xmath83,\\quad   j=0 , \\dots , 2^{n-1}-1,\\ ] ]    so that @xmath84 is 1correlated as well as @xmath85 . also , that way , given that @xmath86 and @xmath87 , equation ( [ eq : brownian_correl_steps ] ) yields ( [ eq : brownian_wiener_steps ] ) .    for a desired precision @xmath88 for the @xmath58-th component @xmath48 in the stochastic differential equation , we will consider that @xmath1 is a number of steps big enough if @xmath89 . in order to check that such accuracy holds for different realisations of the noise",
    ", we will repeat the comparison of the @xmath0 and @xmath1integrations with different brownian paths @xmath90 : we call @xmath91 to the trajectory with the wiener process @xmath92 .",
    "we will always use the same initial conditions @xmath93 .    as a result",
    ", we have for each component @xmath58 and each exponent @xmath94 a set of @xmath95 values consisting of the differences between the state at the final time @xmath70 with @xmath0 integration steps minus the state with @xmath1 integration steps : each value corresponds to each realisation of the wiener process . to be clear : we have for each component @xmath58 and each exponent @xmath96 a set @xmath97 , where @xmath98 . from each set @xmath99",
    ", we can assess the reliability of the integration with @xmath100 time steps .",
    "normally , if @xmath96 is not too small , the mean value of those differences @xmath101 will be around 0 , otherwise we can say that there is a preferred sign in the values of the differences @xmath102 and , therefore , a noticeable systematic error at the numerical integration",
    ". then , the quality of the numerical integration is better the smaller the absolute values of the differences @xmath103 , i.e. , the narrower the distribution , and this being peaked around 0 . a way of measuring this is to obtain the mean and some central momenta ,    @xmath104    of the distribution .",
    "given that , for a number of integration steps big enough , the absolute values of the differences @xmath105 should be as small as possible , we can say that the reliability is better the smaller ( in absolute value ) the mean and the central momenta . of course , a number of time steps that is acceptable for a given integration method ( heun , milstein , etc ) will be in general insufficient or , contrarily , higher than necessary , for another integration method .",
    "we are using here a dynamical system as a model for paleoclimate .",
    "our system consists of three variables : the volume of the ice @xmath106 , the @xmath107 concentration @xmath108 , and the variable @xmath109 that is related to the ocean s temperature and circulation .",
    "the oscillatory astronomical forcing acting on the system can be approximated by two functions @xcite : @xmath110 carrying the effect of the precession of the earth s axis , and @xmath111 carrying the effect of the obliquity .",
    "both functions are approximated by a sum of harmonic oscillations , @xmath112 , where the parameters @xmath113 , @xmath114 and @xmath115 are arranged as rows in two data files ( a file for precession and another one for obliquity ) , and we sum for each function the number of oscillations that we like according to the desired precision and computation time .",
    "nine parameters appear in the equations that govern the deterministic system : an offset @xmath116 in the coupling of the variable @xmath109 to the ice volume , a coupling @xmath117 of the ice volume to the obliquity , a coupling @xmath118 of the ice volume to the precession , an offset @xmath119 in the coupling to the ice volume , a coupling @xmath120 of the @xmath107 to the precession , the relaxation times of each variable @xmath121 , @xmath122 , @xmath123 , and a parameter @xmath124",
    "playing a role in the coupling to the variable @xmath106 .    we will add to each equation a gaussian white noise variable : @xmath125 , @xmath126 , @xmath127 to the variables @xmath106 , @xmath108 , @xmath109 respectively .",
    "the functions @xmath128 are independent , with zero mean and variance one ( the actual variances of the noises will be included in the functions that multiply the @xmath128 s ) :    @xmath129    ( these functions @xmath128 correspond to the wiener processes @xmath22 in ( [ eq : stochastic ] ) . ) after inserting the noise , we will also have to take into account the variances of the noises , and maybe some more extra parameters in the functions that couple the variables @xmath106 , @xmath108 , @xmath109 to the noises ( i.e. , the functions that multiply the noises ) .",
    "putting all things together , the equations of the system read :    @xmath130 + g_v(v , t)\\ , \\eta_v\\nonumber\\\\ \\frac{\\mathrm{d}c}{\\mathrm{d}t } & = & - \\frac{1}{\\tau_c } ( c + v -\\frac{1}{2}d - c_p\\ , \\pi)+ g_c(c , t)\\ , \\eta_c\\nonumber\\\\ \\frac{\\mathrm{d}d}{\\mathrm{d}t } & = & - \\frac{1}{\\tau_d } [ \\varphi_3 ( 2d ) - ( v - v_t)]+ g_d(d , t)\\ , \\eta_d,\\end{aligned}\\ ] ]    where the function @xmath131 is defined as :    @xmath132    and the potentials are :    @xmath133    as stated before , the variance of each noise is taken into the function that multiplies it . in the simplest case of additive noise ,",
    "we just make @xmath134 , where @xmath135 is the variance of the noise acting on the component @xmath58 .",
    "it is worth mentioning that we are performing two corrections  by hand \" at each integration step . on the first hand , in order to prevent @xmath136 , which would be devoid of physical meaning , we shall make @xmath137 by hand whenever we end up with @xmath138 after an integration step . on the other hand , in an attempt to reduce computing divergences , we will bound @xmath139 and make it actually be @xmath140 .",
    "when coding , we have of course tried to avoid redundant calculations as much as possible .",
    "this specially includes the figures that just depend on time ( and not on the state variables @xmath106 , @xmath108 , @xmath109 ) .",
    "given that , in most cases , we will be propagating many particles , we will first obtain once and for all the values that depend only on time and are therefore the same for all the particles .",
    "we start by generating the array @xmath141 of all the times at which the integration steps will take place , and then we calculate at all such times : the precession @xmath142 , the obliquity @xmath143 , and also the combination @xmath144 appearing in ( [ eq : function_r ] ) .",
    "this will imply passing these three extra parameters to all the functions ( instead of passing just the parameter time ) and adds complexity to the code , but it saves invaluable time when running the programme , specially when the number of particles is high .      for the tests that will follow in the next sections , we took 50 terms for the precession and 20 terms for the obliquity .",
    "given that we are comparing three methods of numerical integration , we do not want to stay in the simple case of additive noise , but we want to test the different methods in the more general case of multiplicative noise .",
    "we therefore use a simple kind of multiplicative noise :    @xmath145    the values of the parameters used here for the comparison of the numerical integration schemes are the following ( one unit of time corresponding to 1000 years ) :    @xmath146    the initial conditions used are @xmath147 , @xmath148 , @xmath149 .",
    "the code was written in c and compiled with the intel compiler ( icc ) in order to take advantage of vectorisation .",
    "the compilation commands were    ` ice & & icc file.c -l / opt / gsl / lib -lgsl -lgslcblas `    ` -i / opt / gsl / include -o file `    ( we use the first command ` ice ` to switch to 64 bits . )",
    "the cpu is ` intel(r ) xeon(r ) x5450 @ 3.00ghz ` running on ` suse linux 11.0 x86_64 ` .",
    "trajectories for three particles were generated using the three integration schemes , with the same wiener process for the three schemes .",
    "we integrated up to time equal to 2000 , using @xmath150 time steps per trajectory .",
    "the time used to generate the data file for each integration scheme on the computing scenario described above was :    * heun scheme : 0.335 seconds . * milstein scheme : 0.304 seconds . *",
    "derivative - free milstein scheme : 0.357 seconds .",
    "nevertheless , such small times are not reliable for comparing the different integration schemes in terms of time expenses , given that such execution times vary from one execution to another of the same executable file , depending on the other jobs in the whole computer .",
    "we will compare the time expenses in section [ subsec : precision_brownian ] .",
    ", scaledwidth=70.0% ]     , scaledwidth=70.0% ]     , scaledwidth=70.0% ]     , scaledwidth=70.0% ]     , scaledwidth=70.0% ]     , scaledwidth=70.0% ]    in order to check the agreement between the different integration schemes , we have plotted , in figures [ fig : trajectories - heun - milstein ] and [ fig : trajectories - heun - milstein - df ] , a two - by - two superposition of the same trajectories generated with the different integration schemes . for clarity",
    ", we have only plotted the second half , from time 1000 to time 2000 .",
    "the space between consecutive points has been intentionally made relatively large , in order to be able to see the overlapping in the same trajectory obtained from two different integration schemes .",
    "we can see in figures [ fig : trajectories - heun - milstein ] and [ fig : trajectories - heun - milstein - df ] that all the trajectories overlap perfectly with the corresponding same trajectory obtained with the other integration scheme .",
    "this says that the three integration methods are reliable for the number of integration steps stated above ( @xmath150 ) .",
    "now , we will make in section [ subsec : precision_brownian ] a quantitative study of accuracy versus time expense of each integration scheme .      to compare the rate of strong convergence of the three integration schemes",
    ", we followed the method described in section [ sec : convergence_check ] .",
    "we integrated @xmath151 particles from time 0 to time 400 with each integration scheme .",
    "the maximum number of time steps was @xmath152 , and the minimum @xmath153 ( the biggest power of 2 , as we will see , that is small enough to cause divergences in the numerical integration for the three schemes ) . the same wiener processes were used for the three integration schemes . for the sample of differences , at the final time 400 , between the integrations with @xmath0 and @xmath1 time steps , we obtain the mean and central momenta ( [ central_momenta ] ) , for @xmath154 .",
    "the time used to generate the data file for each integration scheme on the computing scenario described above was :    * heun scheme : real 4m44.192s , user 4m29.721s , sys 0m4.396s . * milstein scheme : real 3m45.887s , user 3m41.430s , sys 0m4.008s . *",
    "derivative - free milstein : real 4m21.324s , user 4m9.640s , sys 0m4.296s .",
    "given that the most time consuming task of the programme is the numerical integrations , we can say from the figures above that , for the same number of time steps , the milstein scheme is the fastest method ; the next one would be the derivative - free milstein taking around 1.13 times longer than the former , and the slowest one is the heun scheme taking around 1.22 times longer than the milstein scheme ( beware , though , that these ratios may change if we use another computing environment ) . given that these ratios are close to 1 ( i.e. , the time expense of the integration schemes is roughly the same for the three ) , we shall choose the most accurate of our integration schemes .    in order to compare the accuracies , we have rearranged the tables to display together the same relevant variables derived after integrating with the three different methods .",
    "the means and central momenta explained above are displayed in tables [ table : mean][table : fourth - momenta ] .",
    "the columns are named after the system s variable ( @xmath106 , @xmath108 or @xmath109 ) , and after the integration method : suffix `` -h '' for heun , `` -m '' for milstein , and `` -df '' for derivative - free milstein .",
    "the names of the rows correspond to `` the small power of 2 '' , i.e. , @xmath96 means that we are considering the distribution of the differences , at the final time 400 , between the integrations with @xmath155 and @xmath100 time steps : small absolute values in the mean and central momenta indicate that the integration with @xmath100 time steps is in principle reliable . also , for the sake of visual clarity , all the means and central momenta have been multiplied by @xmath156 before displaying them in the tables .",
    ".mean values times @xmath156 ; for the different variables , integration methods , and time steps . see text for an explanation on the notation . [",
    "cols=\"^,>,>,>,>,>,>,>,>,>\",options=\"header \" , ]     we can see that the numerical integration yields divergencies when done with a small number of time steps : in our case , they appear when we descend to @xmath157 integration steps for the two milstein methods , and when we descend to @xmath158 steps for the heun method . as we have stated in section [ subsec : manual - corrections ] , we have tried to remove the divergences coming from the equations , so we should think that the divergences found are due in principle only to the integration using too few , too big , time steps .      if we check a given row ( corresponding a given number of integration steps ) in tables [ table : mean][table : fourth - momenta ] , we see that the mean and central momenta for the heun scheme are always smaller ( in absolute value ) compared to the figures for the other two schemes ( with a couple of exceptions in table [ table : third - momenta ] ) .",
    "not only smaller , but the figures for the heun scheme are almost always ( except for some rows corresponding to a small number of time steps ) at least _ one order of magnitude smaller _ than the figures for the two milstein schemes .",
    "if we were too strict , one might object that the heun scheme is ( just slightly ) more expensive in terms of computing time : however , in most cases , the figure for the heun scheme in a given row of the tables is smaller than the figure for the other schemes displayed one row above ( which corresponds to an integration with double number of time steps ) , so the slightly bigger time expense of running the heun scheme is largely made up for by the accuracy of the method .    as a result",
    ", we can state that the heun method is the best performing as we get much better accuracy , for a given computation time , compared to the milstein methods .",
    "the better performance of the heun method was to some extend expectable , given that , in the case of additive noise , the milstein scheme reduces to the basic euler scheme ( as the derivative in ( [ milstein_diagonal ] ) vanishes ) , whereas heun s scheme is always ( also for additive noise , and even for no noise at all ) a second - order predictor - corrector method .",
    "also , the idea of heun s method is easy to understand , and the method is easy to code ( in particular , it does not use any derivative ) .",
    "all this makes the heun s scheme a very suitable and attractive method in our opinion .",
    "the author would like to thank michel crucifix ( universit catholique de louvain ) and jonathan rougier ( university of bristol ) for useful advice .",
    "the work was funded by the erc - starting grant  integrated theory and observations of the pleistocene \" ."
  ],
  "abstract_text": [
    "<S> three schemes , whose expressions are not too complex , are selected for the numerical integration of a system of stochastic differential equations in the stratonovich interpretation : the integration methods of heun , milstein , and derivative - free milstein . </S>",
    "<S> the strong ( path - wise ) convergence is studied for each method by comparing the final points after integrating with @xmath0 and @xmath1 time steps . </S>",
    "<S> we also compare the time that the computer takes to carry out the integration with each scheme . putting both things together , </S>",
    "<S> we conclude that , at least for our system , the heun method is by far the best performing one . </S>"
  ]
}