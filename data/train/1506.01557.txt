{
  "article_text": [
    "in the last decade , both functional data analysis ( fda ) and high - dimensional ( hd ) problems have known an unprecedented expansion both from a theoretical point of view ( as they offer many mathematical challenges ) and for the applications ( where data have complex structure and grow larger every day ) .",
    "therefore , both areas share a large number of trends , see @xcite and the review by @xcite , like regression models with functional or large - dimensional covariates , supervised or unsupervised classification , testing procedures , covariance operators .",
    "functional data analysis proceeds very often by discretizing curve datasets in time domain or by projecting on suitable orthonormal systems and produces large dimensional vectors with size possibly larger than the sample size .",
    "hence methods and techniques from hd problems can be successfully implemented ( see e.g.  @xcite).however , in some cases , hd vectors can be transformed into stochastic processes , see @xcite , and then techniques from fda bring new insights into hd problems .",
    "our work is of the former type .",
    "we observe independent , identically distributed gaussian vectors @xmath19 , @xmath20 , which are @xmath1-dimensional , centered and with a positive definite toeplitz covariance matrix @xmath4 .",
    "we denote by @xmath21 the coordinates of the vector @xmath22 in @xmath23 for all @xmath24 .",
    "our model is that of a stationary gaussian time series , repeatedly and independently observed @xmath0 times , for @xmath25 .",
    "we assume that @xmath0 and @xmath1 are large .",
    "in functional data analysis , it is quite often that curves are observed in an independent way : electrocardiograms of different patients , power supply for different households and so on , see other data sets in @xcite .",
    "after modelisation of the discretized curves , the statistician will study the normality and the whiteness of the residuals in order to validate the model .",
    "our problem is to test from independent samples of high - dimensional residual vectors that the standardized gaussian coordinates are uncorrelated .",
    "let us denote by @xmath26 , for all integer numbers @xmath27 and @xmath28 , for all @xmath29 , where @xmath30 is the set of positive integers .",
    "we assume that @xmath31 , therefore @xmath32 are correlation coefficients .",
    "we recall that @xmath33 is a sequence of non - negative type , or , equivalently , the associated toeplitz matrix @xmath4 is non - negative definite .",
    "we assume that the sequence @xmath33 belongs to to @xmath34 , where @xmath35 ( resp .",
    "@xmath36 ) is the set all absolutely ( resp .",
    "square ) summable sequences .",
    "it is therefore possible to construct a positive , periodic function @xmath37 belonging to @xmath38 the set of all square - integrable functions @xmath39 over @xmath40 .",
    "this function is known as the spectral density of the stationary series @xmath41 .",
    "we solve the following test problem , @xmath42 versus the alternative @xmath43 for @xmath44 a positive sequence converging to 0 .",
    "from now on , @xmath45 denotes the set of squared symmetric and positive definite matrices .",
    "the set @xmath46 is an ellipsoid of sobolev type @xmath47 we shall also test ( [ h_0 ] ) against @xmath48 where the ellipsoid of covariance matrices is given by @xmath49 this class contains the covariance matrices whose elements decrease exponentially , when moving away from the diagonal .",
    "we denote by @xmath50 either @xmath51 the set of matrices under the alternative ( [ h1 ] ) or @xmath52 under the alternative ( [ h1e ] ) .",
    "we stress the fact that a matrix @xmath4 in @xmath53 is such that @xmath54 , i.e. @xmath4 is outside a neighborhood of @xmath55 with radius @xmath56 in frobenius norm .    our test can be applied in the context of model fitting for testing the whiteness of the standard gaussian residuals . in this context , it is natural to assume that the covariance matrix under the alternative hypothesis has small entries like in our classes of covariance matrices .",
    "such tests have been proposed by @xcite , where it is noted that weighted test statistics can be more powerful .",
    "note that , most of the literature on testing the null hypothesis , either focus on finding the asymptotic behavior of the test statistic under the null hypothesis , or control in addition the type ii error probability for one fixed unknown matrix under the alternative , whereas our main interest is to quantify the worst type ii error probabilities , i.e. uniformly over a large set of possible covariance matrices .",
    "various test statistics in high dimensional settings have been considered for testing , as it was known for some time that likelihood ratio tests do not converge when dimension grows .",
    "therefore , a corrected likelihood ratio test is proposed in @xcite when @xmath57 , and its asymptotic behavior is given under the null hypothesis , based on the random matrix theory . in @xcite",
    "the result is extended to @xmath58 .",
    "an exact test based on one column of the covariance matrix is constructed by @xcite .",
    "a series of papers propose test statistics based on the frobenius norm of @xmath59 , see @xcite , @xcite , @xcite and @xcite .",
    "different test statistics are introduced and their asymptotic distribution is studied . in particular in @xcite the test statistic is a u - statistic with constant weights .",
    "an unbiased estimator of @xmath60 is constructed in @xcite , where @xmath61 , in order to develop a test statistic for the problem of testing the bandedness of a given matrix .",
    "another extension of our test problem is to test the sphericity hypothesis @xmath62 , where @xmath63 is unknown .",
    "@xcite introduced a test statistic based on functionals of order 4 of the covariance matrix .",
    "motivated by these results , the test @xmath64 is revisited by @xcite .",
    "the maximum value of non - diagonal elements of the empirical covariance matrix was also investigated as a test statistic .",
    "its asymptotic extreme - value distribution was given under the identity covariance matrix by @xcite and for other covariance matrices by @xcite .",
    "we propose here a new test statistic to test which is a weighted u - statistic of order 2 and study its probability errors uniformly over the set of matrices given by the alternative hypothesis .",
    "the test problem with alternative ( [ h1 ] ) and with one sample ( @xmath65 ) was solved in the sharp asymptotic framework , as @xmath6 , by @xcite .",
    "indeed , @xcite studies sharp minimax testing of the spectral density @xmath39 of the gaussian process .",
    "note that under the null hypothesis we have a constant spectral density @xmath66 for all @xmath67 and the alternative can be described in @xmath68 norm as we have the following isometry @xmath69 .",
    "moreover , the ellipsoid of covariance matrices @xmath70 are in bijection with sobolev ellipsoids of spectral densities @xmath39 .",
    "let us also recall that the adaptive rates for minimax testing are obtained for the spectral density problem by @xcite by a non constructive method using the asymptotic equivalence with a gaussian white noise model .",
    "finding explicit test procedures which adapt automatically to parameters @xmath71 and/or @xmath72 of our class of matrices will be the object of future work .",
    "our efforts go here into finding sharp minimax rates for testing .",
    "our results generalize the results in @xcite to the case of repeatedly observed stationary gaussian process .",
    "we stress the fact that repeated sampling of the stationary process @xmath73 to @xmath74 can be viewed as one sample of size @xmath75 under the null hypothesis .",
    "however , this sample will not fit the assumptions of our alternative .",
    "indeed , under the alternative , its covariance matrix is not toeplitz , but block diagonal .",
    "moreover , we can summarize the @xmath0 independent vectors into one @xmath1-dimensional vector @xmath76 having gaussian distribution @xmath77 .",
    "the results by @xcite will produce a test procedure with rate that we expect optimal as a function of @xmath1 , but more biased and suboptimal as a function of @xmath0 .",
    "the test statistic that we suggest removes cross - terms and has smaller bias .",
    "therefore , results in @xcite do not apply in a straightforward way to our setup .    a conjecture in the sense of asymptotic equivalence of the model of repeatedly observed gaussian vectors and a gaussian white noise model was given by @xcite .",
    "our rates go in the sense of the conjecture .",
    "the test of @xmath78 against ( [ h1 ] ) , with @xmath4 not necessary toeplitz , is given in @xcite .",
    "their rates show a loss of a factor @xmath1 when compared to the rates for toeplitz matrices obtained here . this can be interpreted heuristically by the size of the set of unknown parameters which is @xmath79 for @xcite whereas",
    "here it is @xmath1 .",
    "we can see that the family of toeplitz matrices is a subfamily of general covariance matrices in @xcite .",
    "therefore , the lower bounds are different , they are attained through a particular family of toeplitz large covariance matrices .",
    "the upper bounds take into account as well the fact that we have repeated information on the same diagonal elements .",
    "the test statistic is different from the one used in @xcite .",
    "the test problem with alternative hypothesis ( [ h1e ] ) has not been studied in this model .",
    "the class @xmath80 contains matrices with exponentially decaying elements when further from the main diagonal .",
    "the spectral density function associated to this process belongs to the class of functions which are in @xmath68 and admit an analytic continuation on the strip of complex numbers @xmath81 with @xmath82 .",
    "such classes of analytic functions are very popular in the literature of minimax estimation , see @xcite .    in times",
    "series analysis such covariance matrices describe among others the linear arma processes .",
    "the problem of adaptive estimation of the spectral density of an arma process has been studied by @xcite ( for known @xmath71 ) and adaptively to @xmath71 via wavelet based methods by @xcite and by model selection by @xcite . in the case of an arfima process , obtained by fractional differentiation of order @xmath83 of a casual invertible arma process , @xcite gave adaptive estimators of the spectral density based on the log - periodogram regression model when the covariance matrix belongs to @xmath80 .    before describing our results",
    "let us define more precisely the quantities we are interested in evaluating .",
    "let @xmath84 be a test , that is a measurable function of the observations @xmath85 taking values in @xmath86 and recall that @xmath53 corresponds to the set of covariance matrice under the alternative hypothesis .",
    "let @xmath87 we consider two criteria to measure the performance of the test procedure .",
    "the first one corresponds to the classical neyman - pearson criterion . for @xmath88 , we define , @xmath89 the test @xmath90 is asymptotically minimax according to the neyman - pearson criterion if @xmath91    the second criterion is the total error probability , which is defined as follows : @xmath92 define also the minimax total error probability @xmath93 as @xmath94 , where the infimum is taken over all possible tests .    note that the two criteria are related since @xmath95 ( see ingster and suslina  @xcite ) .    @xmath96    where @xmath97 . [ table ]",
    "a test @xmath98 is asymptotically minimax if : @xmath99 we say that @xmath100 is a ( asymptotic ) separation rate , if the following lower bounds hold @xmath101 together with the following upper bounds : there exists a test @xmath102 such that , @xmath103    the sharp optimality corresponds to the study of the asymptotic behavior of the maximal type ii error probability @xmath104 and the total error probability @xmath105 . in our study",
    "we obtain asymptotic behavior of gaussian type , i.e. we show that , under some assumptions , @xmath106 where @xmath107 is the cumulative distribution function of a standard gaussian random variable , @xmath108 is the @xmath109 quantile of the standard gaussian distribution for any @xmath110 , and @xmath111 has an explicit form for each ellipsoid of toeplitz covariance matrices .",
    "separation rates and sharp asymptotic results for different testing problem were studied under this formalism by @xcite .",
    "we refer for precise definitions of sharp asymptotic and non asymptotic rates to @xcite .",
    "note that throughout this paper , asymptotics and symbols @xmath112 , @xmath113 , @xmath114 and @xmath115 are considered as @xmath1 tends to infinity , unless we specify that @xmath0 tends to infinity . recall that , given sequences of real numbers @xmath116 and real positive numbers @xmath117 , we say that they are asymptotically equivalent , @xmath118 , if @xmath119 .",
    "moreover , we say that the sequences are asymptotically of the same order , @xmath120 , if there exist two constants @xmath121 such that @xmath122 and @xmath123 .      in this paper",
    ", we describe the separation rates @xmath124 and sharp asymptotics for the error probabilities for testing the identity matrix against @xmath125 and @xmath126 respectively .",
    "we propose here a test procedure whose type ii error probability tends to 0 uniformly over the set of @xmath53 , that is even for a covariance matrix that gets closer to the identity matrix at distance @xmath127 as @xmath0 and @xmath1 increase .",
    "the radius @xmath128 in table  [ table ] is the smallest vicinity around the identity matrix which still allows testing error probabilities to tend to 0 .",
    "our test statistic is a weighted quadratic form and we show how to choose these weights in an optimal way over each class of alternative hypotheses .    under mild assumptions",
    "we obtain the sharp optimality in ( [ sharp ] ) , where @xmath111 is described in table  [ table ] and compared to the case of non toeplitz matrices in @xcite .",
    "this paper is structured as follows . in section",
    "[ sec : toeplitz ] , we study the test problem with alternative hypothesis defined by the class @xmath129 , @xmath130 , @xmath131 . we define explicitly the test statistic and give its first and second moments under the null and the alternative hypotheses .",
    "we derive its gaussian asymptotic behavior under the null hypothesis and under the alternative submitted to the constraints that @xmath56 is close to the separation rate @xmath124 and that @xmath4 is closed to the solution of an extremal problem @xmath132 .",
    "we deduce the asymptotic separation rates .",
    "their optimality is shown only for @xmath17 .",
    "our lower bounds are original in the literature of minimax lower bounds , as in this case we can not reduce the proof to the vector case , or diagonal matrices .",
    "we give the sharp rates for @xmath133 .",
    "our assumptions imply that necessarily @xmath134 as @xmath6 . that does not prevent @xmath0 to be larger than @xmath1 for sufficiently large @xmath71 .    in section",
    "[ sec : testprob2 ] , we derive analogous results over the class @xmath135 , with @xmath136 .",
    "we show how to choose the parameters in this case and study the test procedure similarly .",
    "we give asymptotic separation rates .",
    "the sharp bounds are attained as @xmath133 .",
    "our assumptions involve that @xmath137 which allows @xmath0 to grow exponentially fast with @xmath1 .",
    "that can be explained by the fact that the elements of @xmath4 decay much faster over exponential ellipsoids than over the polynomial ones . in section  [ sec : simu ] we implement our procedure and show the power of testing over two families of covariance matrices .",
    "the proofs of our results are postponed to the section [ sec : proofs ] and to the supplementary material .",
    "we introduce a weighted u - statistic of order 2 , which is an estimator of the functional @xmath138 that defines the separation between a toeplitz covariance matrix under the alternative hypothesis from the identity matrix under the null .",
    "indeed , in nonparametric estimation of quadratic functionals such as @xmath138 weighted estimators are often considered ( see e.g. @xcite ) .",
    "these weights have finite support of length @xmath139 , where @xmath139 is optimal in some sense .",
    "intuitively , as the coefficients @xmath140 belong to an ellipsoid , they become smaller when @xmath28 increases and thus the bias due to the truncation and the weights becomes as small as the variance for estimating the weighted finite sum .",
    "let us denote by @xmath141 the symmetric @xmath142 toeplitz matrix @xmath143_{1 \\leq l , k \\leq p}$ ] such that the diagonal elements of @xmath144 are equal to 1 , and @xmath145 , for all @xmath146 .",
    "now we define the weighted test statistic in this setup @xmath147 where the weights @xmath148 and the parameters @xmath149 are obtained by solving the following extremal problem : @xmath150 this extremal problem appears heuristically as we want that the expected value of our test statistic for the worst parameter @xmath4 under the alternative hypothesis ( closest to the null ) to be as large as possible for the weights we use",
    ". this problem will provide the optimal weights @xmath151 in order to control the worst type ii error probability , but also the critical matrix @xmath152 that will be used in the lower bounds .",
    "indeed , @xmath132 is positive definite for small enough @xmath56 ( see @xcite ) .",
    "the solution of the extremal problem ( [ probopt ] ) can be found in @xcite : @xmath153 remark that @xmath139 is a finite number but grows to infinity as @xmath154 .",
    "moreover , the test statistic will have optimality properties under the additional condition that @xmath155 which is equivalent to @xmath156 .",
    "it is obvious that in practice it might happen that @xmath157 and then we have no solution but to use @xmath158 , with the inconvenient that the procedure does not behave as well as the theory predicts .",
    "[ prop : esttoeplitz ] under the null hypothesis , the test statistic @xmath159 is centered , @xmath160 , with variance : @xmath161    moreover , under the alternative hypothesis with @xmath162 , if we assume that @xmath154 we have : @xmath163 uniformly over @xmath4 in @xmath164 , where @xmath165    in the next proposition we prove asymptotic normality of the test statistic under the null and under the alternative hypothesis with additional assumptions .",
    "more precisely , we need that @xmath56 is of the same order as the separation rate and that the matrix @xmath4 is close to the optimal @xmath132 .",
    "this is not a drawback , since the asymptotic constant for probability errors are attained under the same assumptions or tend to 0 otherwise .",
    "[ prop : asymptoticnormality ] suppose that @xmath166 , @xmath167 , @xmath154 , @xmath168 and moreover assume that @xmath169 , the test statistic @xmath170 defined by ( [ esttetplitz ] ) with parameters given in ( [ parameters1 ] ) , verifies : @xmath171 for all @xmath172 , such that @xmath173 .",
    "moreover , @xmath174 has asymptotical @xmath175 distribution under @xmath176 , as @xmath177 for any fixed @xmath25 .      based on the test statistic @xmath170 , we define the test procedure @xmath178 for conveniently chosen @xmath179 , where @xmath170 is the estimator defined in ( [ esttetplitz ] ) with parameters in ( [ parameters1 ] ) .",
    "the next theorem gives the separation rate under the assumption that @xmath180 , or equivalently , that @xmath181 .",
    "the upper bounds are attained for arbitrary @xmath162 , but the lower bounds require @xmath17 .",
    "[ theo : optimalrates ] suppose that asymptotically @xmath182    * lower bound .",
    "* @xmath183 then @xmath184 where the infimum is taken over all test statistics @xmath98 .",
    "* upper bound .",
    "* the test procedure @xmath185 defined in ( [ testtoeplitz * ] ) with @xmath186 has the following properties :    type i error probability : if @xmath187 then @xmath188 .",
    "type ii error probability : if @xmath189 then , uniformly over t such that @xmath190 , for some constant @xmath191 , we have @xmath192    under the assumptions given in ( [ conditionasym ] ) and ( [ conditionbornesup1 ] ) , with @xmath193 verifying the assumptions of theorem  [ theo : optimalrates ] , we get : @xmath194    as a consequence of the previous theorem , we get that @xmath185 is an asymptotically minimax test procedure if @xmath195 . from the lower bounds we deduce that , if @xmath196 , there is no test procedure to distinguish between the null and the alternative hypotheses , with errors tending to @xmath14 .",
    "the minimax separation rate @xmath100 is therefore : @xmath197 it is obtained from the relation @xmath198 .",
    "naturally the constant does not play any role here .",
    "remark that the condition @xmath199 implies that @xmath200 .",
    "the maximal type ii error probability either tends to 0 , see theorem  [ theo : optimalrates ] , or is less than @xmath201 when @xmath202 .",
    "the latter case is the object of the next theorem giving sharps bounds for the asymptotic errors .",
    "the upper bounds are attained for arbitrary @xmath20 and for @xmath130 , while our proof of the sharp lower bounds requires additionally that @xmath5 and @xmath17 .",
    "[ theo : sharprates ] suppose that @xmath203 such that @xmath204 and , moreover , that @xmath205     * lower bound .",
    "* if @xmath17 , then @xmath206 where the infimum is taken over all test statistics @xmath98 with type i error probability less than or equal to @xmath207 .",
    "moreover , @xmath208     * upper bound . * the test procedure @xmath185 defined in ( [ testtoeplitz * ] ) with @xmath186 has the following properties .",
    "type i error probability : @xmath209 .",
    "type ii error probability : under the assumption ( [ conditionbornesup2 ] ) , and for all @xmath167 , we have that , uniformly over @xmath193 : @xmath210    in particular , for @xmath211 , such that @xmath212 , we have @xmath213 and also , @xmath214 another important consequence of the previous theorem , is that the test procedure @xmath185 , with @xmath215 is such that @xmath216 then we can deduce that the minimax separation rate @xmath217 defined in ( [ sharprate ] ) is sharp .",
    "in this section we want to test ( [ h_0 ] ) against ( [ h1e ] ) , where the alternative set is @xmath218 , for some @xmath219 .",
    "it is well known in the nonparametric minimax theory that @xmath80 is in bijection with ellipsoids of analytic spectral densities admiting analytic continuation on the strip @xmath220 of the complex plane . on this class",
    "nearly parametric rates are attained for testing in the gaussian noise model , see ingster  @xcite .",
    "let us define @xmath221 in @xmath222 where the weights @xmath223 , are obtained by solving the optimization problem ( [ probopt ] ) , with the class @xmath224 replaced by @xmath80 .",
    "the solution given in @xcite is as follows : @xmath225 note that all parameters above are free of the radius @xmath10 .",
    "moreover , we have : @xmath226    under the null hypothesis , we still have @xmath227 and @xmath228 in the following proposition , we see how the upper bounds of the variance have changed under @xmath4 in @xmath229 .    [ prop : est2 ]    under the alternative , for all @xmath230 , we have : @xmath231 where , for all @xmath232 , and as @xmath233 : @xmath234 moreover , if @xmath235 , we show that @xmath236 , for all @xmath237 , such that @xmath238 .",
    "now we define the test procedure as follows , @xmath239 we describe next the separation rate .",
    "we stress the fact that lemma  [ lem1 ] shows that the optimal sequence @xmath240 in ( [ parameters ] ) provides a toeplitz positive definite covariance matrix .",
    "the sharp results are obtained under the additional assumption that @xmath133 and the lower bounds require that @xmath0 tends also to infinity .",
    "[ theoremanalyticaltern ] suppose that asymptotically @xmath154 and @xmath241 .",
    "* 1 . separation rate . *",
    "* lower bound : * @xmath242 then @xmath243 where the infimum is taken over all test statistics @xmath244 .",
    "* upper bound : * the test procedure @xmath245 defined previously with @xmath186 has the following properties :    type i error probability : if @xmath187 then @xmath246 .",
    "type ii error probability : @xmath247 then , uniformly over t such that @xmath248 , for some constant @xmath249 , @xmath250    * 2 . sharp asymptotic bounds . *   * lower bound : * suppose that @xmath251 and that @xmath252 then we get @xmath253 where the infimum is taken over all test statistics @xmath244 with type i error probability less than or equal to @xmath207 for @xmath110 . moreover , @xmath254    * upper bound : * we have    type i error probability : @xmath255 .",
    "type ii error probability : under the condition ( [ conditionsharprate ] ) , we get that , uniformly over t , @xmath256    in particular , the test procedure @xmath257 , is such that @xmath258 we get the sharp minimax separation rate : @xmath259 remark that , in this case the condition @xmath155 implies that @xmath260 , which is considerably less restrictive than the condition @xmath261 of the previous case and allows for exponentially large @xmath0 , e.g. @xmath262 .",
    "in this section we implement the test procedure @xmath98 in ( [ testtoeplitz * ] ) with empirically chosen threshold @xmath186 and study its numerical performance over two families of covariance matrices .",
    "we estimate the type i and type ii errors by monte carlo sampling with 1000 repetitions .",
    "first , we choose @xmath263_j$ ] ; @xmath264 under the alternative hypothesis , for various values of @xmath265 .",
    "we implement the test statistic @xmath266 defined in and , for parameters @xmath267 and @xmath268 .",
    "our choice of the values for @xmath269 provides positive definite matrices .",
    "we denote by @xmath270 the random variable @xmath271 when @xmath272 , and by @xmath273 when @xmath274 .",
    "note that large values of @xmath269 give @xmath275 with small off - diagonal entries , which is very close to the identity matrix .     for @xmath276 and @xmath277 , when @xmath278 and @xmath279.,width=377,height=226 ]    figure [ boxplotdeest ] , shows that @xmath280 is distributed as a standard normal random variable , when @xmath274 and @xmath275 close enough to the identity .",
    "and as a non - centered normal distribution when @xmath275 is far from the identity matrix .    to evaluate the performance of our test procedure we compute it s power .",
    "for each value of @xmath0 and @xmath1 , we estimate the 95th percentile @xmath193 of the distribution of @xmath271 under the null hypothesis @xmath274 .",
    "we use @xmath193 previously defined to estimate the type ii error probability , and then plot the associated power . in figure [ plusieursp ] , we plot the power function of our test procedure @xmath98-test as function of @xmath281 , for a fixed value of @xmath0 and different values of @xmath1 .",
    "the vertical lines in figure [ plusieursp ] represent the different @xmath282 associated to different values of @xmath1 and @xmath283 .",
    "we remark that , on the one hand the power grows with @xmath281 for all @xmath284 . on the other hand",
    "the power is an increasing function of @xmath1 for a fixed covariance matrix @xmath275 .",
    "we also compare our test procedure with the one defined in @xcite .",
    "recall that the test statistic defined by @xcite is given by : @xmath285 note that for matrices @xmath286 , we have @xmath287 , thus we implement @xmath288 as cm - test statistic . to have fair comparison , we estimate the 95th percentile under the null hypothesis for both tests",
    ". figures [ polynomiallydecrease ] , shows that when @xmath0 is bigger than or equal to @xmath1 the powers of the @xmath98-test and the cm - test take close values . while when @xmath0 is smaller then @xmath1 , the gap between the power values of the two tests is large , and the @xmath98-test is more powerful than the cm - test",
    "second , we consider tridiagonal matrices under the alternative . we define",
    "@xmath289_j$ ] ; @xmath290 , for @xmath291 . in this case",
    "the parameter @xmath56 is @xmath292 , for a grid of 10 points @xmath293 belonging to the interval @xmath294 $ ] and as previously we take @xmath295 and @xmath296 .",
    "figure [ tridiagonal ] shows that , the @xmath98-test performs better than the u - test , in the three cases : @xmath1 smaller than @xmath0 , @xmath1 equal @xmath0 and @xmath1 larger than @xmath0 .",
    "moreover , we see that the power curves of the @xmath98-test and the cm - test are closer , when the ratio @xmath297 is smaller",
    ". we expect even better results in this particular example if we use a larger value of @xmath71 , or the procedure defined by and .",
    "the question arises of a test statistic free of parameters @xmath71 , respectively @xmath298 , which is beyond the scope of this paper .",
    "recall the assumptions @xmath299 , @xmath300 and @xmath301 . * lower bounds * : in order to show the lower bound , we first reduce the set of parameters to a convenient parametric family .",
    "let @xmath302 be the toeplitz matrix such that , @xmath303 with @xmath304 and @xmath139 are given by ( [ parameters1 ] ) .",
    "let us define @xmath305 a subset of @xmath125 as follows @xmath306 where @xmath307 the cardinality of @xmath308 is @xmath309 .    from proposition 3 in @xcite",
    ", we can see that if @xmath310 , for all @xmath311 , the matrix @xmath312 is positive definite , for @xmath313 small enough .",
    "in contrast with @xcite , we change the signs randomly on each diagonal of the upper triangle of @xmath132 and not of all its elements .",
    "that allows us to stay into the model of toeplitz covariance matrices and will actually change the rates of these lower bounds .",
    "assume that @xmath314 under the null hypothesis and denote by @xmath315 the likelihood of these random variables .",
    "moreover assume that @xmath316 under the alternative , and we denote @xmath317 the associated likelihood . in addition let @xmath318 be the average likelihood over @xmath305 .",
    "the problem can be reduced to the test @xmath319 against the averaged distribution @xmath320 , in the sense that @xmath321 and that @xmath322 where , with an abuse of notation , @xmath323 and @xmath324 .",
    "it is therefore sufficient to show that , when @xmath325 , @xmath326 and that @xmath327 while , for @xmath328 , we need that @xmath329    [ lemma : loglike ] assume that @xmath154 such that @xmath330 and let @xmath331 be the probability density associated to the likelihood @xmath332 previously defined",
    ". then @xmath333 where @xmath334 is asymptotically distributed as a standard gaussian distribution and @xmath335 is such that either @xmath336 or @xmath325.moreover , @xmath337 is uniformly integrable .    in order to obtain ( [ beta ] ) and ( [ gamma ] ) , we apply results in section 4.3.1 of @xcite giving the sufficient condition is ( [ lan ] ) .",
    "it is known that @xmath338 and we bound the @xmath339 norm by the kullback - leibler divergence @xmath340 therefore to show ( [ gammatendsto1 ] ) , we apply lemma  [ lemma : loglike ] to see that the log likelihood @xmath341 is an uniformly integrable sequence .",
    "this implies that @xmath342 .    * upper bounds",
    "* : by the proposition [ prop : esttoeplitz ] , we have that under the null hypothesis @xmath343",
    ". then we can deduce that the type i error probability of @xmath185 has the following form : @xmath344 for the type ii error probability of @xmath185 , we shall distinguish two cases , when @xmath345 tends to infinity or is bounded by some finite constant .",
    "first , assume that @xmath346 or , equivalently , that @xmath347 . then by the markov inequality , @xmath348 for all @xmath349 and @xmath350 such that @xmath351 .",
    "recall that under the alternative , we have @xmath352 which gives : @xmath353 therefore from the first part of the inequality ( [ denominateur ] ) and the variance expression of @xmath170 under @xmath354 , given in proposition 1 , we have : @xmath355 let us bound from above @xmath356 , using ( [ r_1 ] ) and the second part of the inequality ( [ denominateur ] ) : @xmath357 we have @xmath358 which proves that : @xmath359 indeed , @xmath360 , since @xmath361 and @xmath362    we can check using ( [ r_2 ] ) that the term @xmath363 tends to zero as well : @xmath364    finally , when @xmath365 is of the same order of the separation rate , i.e. @xmath366 , we may have either @xmath367 tends to infinity , or @xmath368 . in the first case it is easy to see that @xmath369 . in the latter the proposition [ prop : asymptoticnormality ]",
    "gives the asymptotic normality of @xmath370 .",
    "thereby , @xmath371    99    germn aneiros and philippe vieu .",
    "variable selection in infinite - dimensional problems .",
    ", 94:1220 , 2014 .",
    "zhidong bai , dandan jiang , jian - feng yao , and shurong zheng .",
    "corrections to lrt on large - dimensional covariance matrix by rmt . , 37(6b):38223840 , 12 2009 .    c.  butucea and r.  zgheib .",
    "sharp minimax tests for large covariance matrices . ,",
    "cristina butucea and katia meziani .",
    "quadratic functional estimation in inverse problems .",
    ", 8(1):3141 , 2011 .",
    "t.  tony cai and tiefeng jiang .",
    "limiting laws of coherence of random matrices with applications to testing covariance structure and construction of compressed sensing matrices .",
    ", 39(3):14961525 , 2011 .",
    "t.  tony cai and zongming ma .",
    "optimal hypothesis testing for high dimensional covariance matrices .",
    ", 19(5b):23592388 , 11 2013 .",
    "tony cai , zhao ren , and harrison zhou .",
    "optimal rates of convergence for estimating toeplitz covariance matrices .",
    ", 156:101143 , 2013 .",
    "kun chen , kehui chen , hans - georg mller , and jane - ling wang .",
    "stringing high - dimensional data for functional analysis .",
    ", 106(493):275284 , 2011 .",
    "song  xi chen , li - xin zhang , and ping - shou zhong .",
    "tests for high - dimensional covariance matrices . , 105(490):810819 , 2010 .",
    "fabienne comte .",
    "adaptive estimation of the spectrum of a stationary gaussian sequence .",
    ", 7(2):pp . 267298 , 2001 .",
    "antonio cuevas . a partial overview of the theory of statistics with functional data . ,",
    "147:123 , 2014 .",
    ", a. goia , e. salinelli , and p. vieu , editors . .",
    "societ editrice esculapio , 2014 .    m.  s. ermakov . a minimax test for hypotheses on a spectral density . ,",
    "68(4):475483 , 1994 .    thomas",
    "j. fisher . on testing for an identity covariance matrix when the dimensionality equals or exceeds the sample size . , 142(1):312326 , 2012 .",
    "thomas  j. fisher and colin  m. gallagher .",
    "new weighted portmanteau statistics for time series goodness of fit testing . , 107(498):777787 , 2012 .",
    "thomas  j. fisher , xiaoqian sun , and colin  m. gallagher . a new test for sphericity of the covariance matrix for high dimensional data .",
    ", 101(10):2554  2570 , 2010 .",
    "g.  golubev .",
    "nonparametric estimation of smooth spectral densities of gaussian stationary sequences .",
    ", 38(4):630639 , 1994 .",
    "golubev , m.  nussbaum , and h.h .",
    "asymptotic equivalence of spectral density estimation and gaussian white noise .",
    ", 38:181214 , 2010 .",
    "yuri  k. golubev , boris  y. levit , and alexander  b. tsybakov .",
    "asymptotically efficient estimation of analytic functions in gaussian noise . _ bernoulli _ , 2(2):167181 , 06 1996 .    arjun  k. gupta and taras bodnar .",
    "an exact test about the covariance matrix .",
    "_ journal of multivariate analysis _ , 125(0):176  189 , 2014 .    peter hall .",
    "central limit theorem for integrated square error of multivariate nonparametric density estimators .",
    "_ j. multivariate anal .",
    "_ , 14(1):116 , 1984 .",
    "i. ingster and t.  sapatinas .",
    "minimax goodness - of - fit testing in multivariate nonparametric regression .",
    "methods statist .",
    "_ , 18(3):241269 , 2009 .",
    "i. ingster and i.  a. suslina . _ nonparametric goodness - of - fit testing under gaussian models _ ,",
    "volume 169 of _ lecture notes in statistics_. springer - verlag , new york , 2003 .",
    "yuri  i. ingster .",
    "asymptotically minimax hypothesis testing for nonparametric alternatives .",
    "i. _ mathem .",
    "methods statist .",
    "_ , 2:85114 , 171189 , 249268 , 1993 .",
    "dandan jiang , tiefeng jiang , and fan yang .",
    "likelihood ratio tests for covariance matrices of high - dimensional normal distributions .",
    "_ j. statist .",
    "plann . inference _",
    ", 142(8):22412256 , 2012 .",
    "olivier ledoit and michael wolf . some hypothesis tests for the covariance matrix when the dimension is large compared to the sample size .",
    "_ , 30(4):10811102 , 2002 .    c.  marteau and t.  sapatinas . a unified treatment for non - asymptotic and asymptotic approaches to minimax signal detection . _ arxiv e - prints _ , jun 2014",
    ".    michael  h. neumann .",
    "spectral density estimation via nonlinear wavelet methods for stationary non - gaussian time series",
    ". _ journal of time series analysis _",
    ", 17(6):601633 , 1996 .",
    "yumou qiu and song  xi chen .",
    "test for bandedness of high - dimensional covariance matrices and bandwidth estimation .",
    "statist . _ , 40(3):12851314 , 06 2012 .",
    "a.  n. shiryaev .",
    "_ probability _ , volume  95 of _ graduate texts in mathematics_. springer - verlag , new york , second edition , 1996 .",
    "translated from the first ( 1980 ) russian edition by r. p. boas .",
    ". soulier . adaptive estimation of the spectral density of a weakly or strongly dependent gaussian process . _ math .",
    "methods statist .",
    "_ , 10(3):331354 , 2001 .",
    "meeting on mathematical statistics ( marseille , 2000 ) .",
    "muni  s. srivastava .",
    "some tests concerning the covariance matrix in high dimensional data .",
    "_ j. japan statist .",
    "_ , 35(2):251272 , 2005 .",
    "muni  s. srivastava , hirokazu yanagihara , and tatsuya kubokawa .",
    "tests for covariance matrices in high dimension with less sample size .",
    "_ journal of multivariate analysis _ , 130(0):289  309 , 2014 .    h.  xiao and w.b .",
    "asymptotic theory for maximum deviations of sample covariance matrix estimation .",
    "_ stochastic processes and their applications _ , 123:28992920 , 2013",
    "the matrix taylor expansion gives @xmath379 on the one hand , @xmath380 does not depend on @xmath373 .",
    "moreover , @xmath381 thus we get @xmath382 on the other hand , we see that @xmath383 and that @xmath384 in the term @xmath385 , we change the variables @xmath386 and @xmath28 into @xmath387 and @xmath388 and due to the constraints we have @xmath389 and @xmath390 , while @xmath27 varies in the set @xmath391 for each fixed pair @xmath392 . therefore , @xmath393 we split the previous sums over @xmath394 such that sign@xmath395 and get @xmath396 respectively , over @xmath397 of opposite signs : sign@xmath398 and get @xmath399 in conclusion , we can group terms differently and write @xmath400 where @xmath401 now , let us see that : @xmath402 and recall ( [ trd3 ] ) to get @xmath403 moreover , we have @xmath404 by proposition a.1 in @xcite , which implies that @xmath405 then , using chebyshev s inequality we obtain , @xmath406 thus we replace ( [ p1 ] ) to ( [ p4 ] ) in @xmath337 and get @xmath407 denote by @xmath408 .",
    "now , we evaluate the expected value with respect to the i.i.d .",
    "rademacher variables @xmath409 , @xmath410 for all @xmath411 and @xmath412 to get @xmath413 we get that @xmath414 note that @xmath415 we use several times the taylor expansion @xmath416 for @xmath417 . on the one hand , by chebyshev s inequality , @xmath418 , as soon as @xmath154 .",
    "then , @xmath419 on the other hand , @xmath420    & \\leq & o_p ( \\lambda \\ds\\sqrt{np } ) = o_p ( \\psi^{1 /2 \\alpha } \\ds\\sqrt{npb(\\psi ) } ) = o_p(1 ) .",
    "\\nonumber    \\end{aligned}\\ ] ] thus we have to study now @xmath421 let us treat each term of ( [ lr1 ] ) separately .",
    "we first decompose @xmath422 as follows , @xmath423 & : = & a_1 + a_2 + a_3 \\nonumber\\end{aligned}\\ ] ] the term @xmath424 will be taken into account as it is later on .",
    "the dominant term giving the asymptotic distribution is : @xmath425 recall that @xmath426 and then @xmath427 . by proposition [ prop : esttoeplitz ] ,",
    "@xmath428 and thus @xmath429 can be written @xmath430 with @xmath431 .    next , under @xmath432",
    "all variables in the multiple sums of @xmath433 are uncorrelated ( as well as for @xmath434 ) .",
    "thus , @xmath435 and , similarly , @xmath436 therefore , @xmath437 where @xmath431 .",
    "for the same reason , we have , @xmath438 as soon as @xmath439 or @xmath336 .",
    "we want to show that @xmath440 indeed , @xmath441 [ e(b ) ] recall that @xmath442 , thus @xmath443 moreover , @xmath444 as in the calculation of the expected value of @xmath445 , we can see that the term of higher order is obtained when we gather the indices into distinct pairs .",
    "thus following the same reasoning we get @xmath446 through a very technical calculation , and using similar arguments as previously , we can prove that , for @xmath447 , @xmath448 thus , @xmath449 by chebyshev s inequality we deduce that @xmath450 also using that @xmath451 , we get @xmath452   & = &    o_p ( \\lambda^2 t^2 np   )   = o_p ( \\psi^{(2 - \\frac 1{2 \\alpha } ) } \\cdot u_n ) = o_p(1 ) \\nonumber \\quad \\text { for } \\alpha > 1/4 \\text { and   since }    \\psi \\to 0",
    ".    \\end{aligned}\\ ] ] moreover , @xmath453 finally , we group the remaining terms of ( [ lr1 ] ) as follows , @xmath454 let us note that throughout the previous proof we also showed that the likelihood ratio @xmath337 has a variance which tends to 0 , for all @xmath20 , when @xmath336 .    under the null hypothesis , @xmath170 is centered , and @xmath455 recall that @xmath456 to get the desired result . under the alternative , for all @xmath457 , we decompose @xmath458 into a sum of two uncorrelated terms .",
    "@xmath459 then the variance of @xmath170 will be given as a sum of two terms , @xmath460 where @xmath461 let us deal first with @xmath462 : @xmath463\\\\   & & \\cdot \\underset{t + 1 \\leq i_2 , i_4 \\leq p}{\\ds\\sum } \\mathbb{e}_{\\sigma } [ ( x_{2 , i_2}x_{2 , i_2-j } - \\sigma_j)(x_{2 , i_4}x_{2 , i_4-j ' } - \\sigma_j ' ) ] \\\\   & = & 2 \\underset{1 \\leq j , j ' < t}{\\ds\\sum } w_j^ *   w_{j'}^ *   \\big ( \\underset{t + 1 \\leq i_1 , i_3 \\leq p}{\\ds\\sum }   ( \\sigma_{|i_1 -i_3| } \\sigma_{|i_1 -i_3 -j+j'| } + \\sigma_{|i_1 -i_3-j|}\\sigma_{|i_1 -i_3+j'| } ) \\big)^2 \\\\   & = & 2   \\underset{1 \\leq j , j ' < t}{\\ds\\sum }   w_j^ *   w_{j'}^ * \\big ( \\ds\\sum_{r =- p+t+1}^{p-(t+1 ) } ( p - t-|r| ) ( \\sigma_{|r|}\\sigma_{|r - j+j'| } + \\sigma_{|r - j|}\\sigma_{|r+j'| } ) \\big)^2 \\end{array}\\ ] ] our aim here is to find an upper bound of @xmath462 . in @xmath462",
    "we distinguish two cases : the first one when for @xmath464 and the second one when @xmath465 .",
    "let us begin with the case when @xmath464 : @xmath466 \\nonumber .",
    "\\end{aligned}\\ ] ] let us bound from above each term on the right - hand side of the previous equality : @xmath467 & \\leq & 2 ( p - t)^2 \\big ( \\ds\\frac{1}{2 } + 3 l \\cdot ( \\sup\\limits_{j } w_j^*)^2   \\big ) = ( p - t)^2 ( 1 + o(1 ) ) .",
    "\\label{r_{1,1,1}}\\end{aligned}\\ ] ] now we give an upper bound for the second term of ( [ r_1,1 ] ) . using cauchy - schwarz inequality we get , @xmath468 ^ 2   \\nonumber \\\\ & \\leq &   8 ( p - t)^2 \\ds\\sum_{j=1}^t   w_j^{*2 }   \\big [ \\sum_{r=1}^{p-(t+1 ) } \\sigma_{r}^2 + ( \\sum_{r=1}^{p-(t+1 ) } \\sigma_{|r - j|}^2)^{1/2 } ( \\sum_{r=1}^{p-(t+1 ) } \\sigma_{|r+j|}^2)^{1/2 } \\big]^2 \\nonumber \\\\ & \\leq & 16 ( p - t)^2 \\ds\\sum_{j=1}^t   w_j^{*2 } \\big [ \\big ( \\sum_{r=1}^{p-(t+1 ) } \\sigma_{r}^2 \\big)^2 +   ( \\sum_{r=1}^{p-(t+1 ) } \\sigma_{|r - j|}^2 ) ( \\sum_{r=1}^{p-(t+1 ) } \\sigma_{|r+j|}^2 ) \\big ] .",
    "\\nonumber \\\\\\end{aligned}\\ ] ] again we will treat each term of the previous inequality apart . let us see first , that if @xmath469 .",
    "in addition to the previous remark we use the class property to get : @xmath470 indeed , for @xmath130 , we have , @xmath471 and we can take @xmath472 . using similar arguments we prove that , @xmath473 the third term in @xmath474 is treated by similar arguments : @xmath475 put together bounds in ( [ r_1,1,1 ] ) to ( [ r_1,1,3 ] ) , we can deduce that , @xmath476 now , we will treat the case when , @xmath465 .",
    "@xmath477 . \\end{array}\\ ] ] these last two terms are treated similarly , so let us deal with the first one . by using the same arguments as previously , we have @xmath478 we decompose the sum over @xmath479 over sets where @xmath480 and @xmath481 and use @xmath482 over the later , then similarly for sums over @xmath483 : @xmath484 as consequence , for all @xmath167 , @xmath485 finally put together ( [ r_1,1 ] ) and ( [ r_1,2 ] ) to get ( [ r_1 ] ) . in order to find an upper bound for the variance of @xmath170 we still have to bound from above @xmath486 .",
    "@xmath487 \\\\ & = & 4    \\underset{1 \\leq \\ , j , j ' < t}{\\ds\\sum }   w^*_j w^*_{j'}\\sigma_j \\sigma_{j ' } \\underset{t+1 \\leq i_1 , i_2",
    "\\leq p}{\\ds\\sum } ( \\sigma_{|i_1 -i_2| } \\sigma_{|i_1 -i_2 -j+j'| } + \\sigma_{|i_1 -i_2-j|}\\sigma_{|i_1 -i_2+j'| } ) \\\\ & = & 4   \\underset{1 \\leq \\ , j , j ' < t}{\\ds\\sum } w^*_j w^*_{j'}\\sigma_j \\sigma_{j ' }    \\ds\\sum_{r =- p+t+1}^{p-(t+1 ) } ( p - t-|r| ) ( \\sigma_{|r|}\\sigma_{|r - j+j'| } + \\sigma_{|r - j|}\\sigma_{|r+j'| } ) .",
    "\\end{array}\\ ] ] let us begin by the first case when @xmath464 .",
    "it is easily seen that , @xmath488 while , when @xmath465 , we can prove that , @xmath489 we use the bound obtained in ( [ r_1,2 ] ) to deduce that : @xmath490 put together ( [ r_2,1 ] ) and ( [ r_2,2 ] ) to get ( [ r_2 ] ) .",
    "assume that @xmath491 , to prove the asymptotic normality of @xmath492 , we use the decomposition ( [ decomposition ] ) of the test statistic .",
    "first let us show that , @xmath493 by markov inequality we have , @xmath494 , @xmath495 according to ( [ r_2 ] ) , and under the assumption that @xmath496 , we can see that , @xmath497 which involves by slutsky theorem that for proving the asymptotic normality it is sufficient to show that , @xmath498 in order to prove this previous convergence , we are led to apply theorem 1 of @xcite .",
    "this result is an application of the more general theorem of asymptotic normality for martingale differences , see e.g. @xcite .",
    "@xmath499 is a centered , 1-degenerate , u - statistic of second order , with kernel @xmath500 defined by , @xmath501 therefore we should check that @xmath502 and @xmath503 where @xmath504 , for @xmath505 .",
    "the proof of is given separately hereafter .",
    "the asymptotic normality under @xmath506 ( the null hypothesis ) is only simpler as @xmath507 for all @xmath508 , for @xmath509 .",
    "however , under the null hypothesis we prove separately ( hereafter ) that @xmath510    to show , we first calculate @xmath511 and @xmath512 .",
    "that is , @xmath513 note that , under the assumption @xmath496 , @xmath514 , @xmath515 and using ( [ r_1 ] ) , we have , @xmath516 now , let us verify that , uniformly over @xmath517 , @xmath518 we write @xmath519 & &   \\cdot   ( \\sigma_{|r_1|}\\sigma_{|r_1- j_1 + j_2| } + \\sigma_{|r_1- j_1|}\\sigma_{|r_1 + j_2| } ) ( \\sigma_{|r_2|}\\sigma_{|r_2- j_3 + j_4| } + \\sigma_{|r_2- j_3|}\\sigma_{|r_2 + j_4| } ) \\nonumber \\\\[0.2 cm ]   & &   \\cdot \\underset{t+1 \\leq i_1 , i_3 \\leq p } { \\ds\\sum }   \\mathbb{e}_{\\sigma } [ ( x_{1_,i_1 } x_{1 , i_1 - j_1}- \\sigma_{j_1 } ) ( x_{1_,i_3 } x_{1 , i_3 - j_3}- \\sigma_{j_3 } ) ]   \\nonumber \\\\[0.2 cm ]    & & \\cdot \\underset{t+1 \\leq i_2 , i_4 \\leq p } { \\ds\\sum } \\mathbb{e}_{\\sigma}[(x_{2 , i_2 } x_{2 , i_2-j_2 } - \\sigma_{j_2 } ) ( x_{2 , i_4 } x_{2 , i_4-j_4 } - \\sigma_{j_4 } ) ]   \\end{aligned}\\ ] ] we calculate each expected value , and bound from above by the absolute value , we obtain : @xmath520 in ( [ firstratio ] ) there are sixteen terms , that are all treated the same way , then we deal with , @xmath521 to bound from above this previous quantity , we distinguish four cases , based on the indices @xmath522 and @xmath523 .",
    "let us begin by the the first case , when @xmath524 : @xmath525 we consider the second case , where there are two different values of indices , either two groups of two , or one group of three and one separate index .",
    "for the first one , let us assume that ( @xmath526 , @xmath527 and @xmath528 , @xmath529 we apply the cauchy - schwarz inequality with respect to @xmath530 and @xmath531 separately to get : @xmath532 similar argument to prove that for @xmath533 and @xmath534 , we have , @xmath535 which finishes the second case .",
    "now let us assume that we have three different values , ( @xmath526 and @xmath536 ) , we obtain , @xmath537 and hence @xmath538 note that @xmath539 and by cauchy - schwarz we have @xmath540 .",
    "thus we get , @xmath541 moreover , @xmath542 and @xmath543 similarly we show that @xmath544 finally , when all indices are pairwise distinct .",
    "we use the same arguments as previously , and we get , @xmath545 now , we treat each term of @xmath546 separately : @xmath547 and @xmath548 we use similar argument as previously to show that the remaining terms in @xmath549 tend to zero . to complete the proof , we need to verify that , @xmath550 we write @xmath551 \\nonumber \\\\ & & \\cdot \\mathbb{e}_{\\sigma}[(x_{2 , i_2}x_{2 , i_2-j_1 } - \\sigma_{j_1 } ) ( x_{2 , i_4}x_{2 , i_4-j_2 } - \\sigma_{j_2 } ) ( x_{2 , i_6}x_{2 , i_6-j_3 } - \\sigma_{j_3})(x_{2 , i_8}x_{2 , i_8-j_4 } - \\sigma_{j_4 } ) ] \\nonumber \\end{aligned}\\ ] ] to bound from above the previous sum , we replace the expected value by it s value , which is a sum of many terms , that are all treated similarly .",
    "so let us give an upper bound for the following one : @xmath552 we see that @xmath553 can be treated in the same way as @xmath554 .",
    "however , we show that @xmath555 .",
    "let us deal with one of the terms of @xmath556 , consider the term for which we have @xmath557 , @xmath558 , and @xmath559 thus we get @xmath560 it is easily seen that @xmath561 . and so on , we show that all terms in @xmath553 are @xmath562 and thus we get the desired result . together with ( [ conditionna1 ] ) , this proves ( [ conditionna ] ) . in consequence , we apply theorem 1 of @xcite , to get ( [ convinlaw ] ) .",
    "we define @xmath563 as follows , @xmath564 we set @xmath565 note that the @xmath566 is a sequence of martingale differences with respect to the sequence of @xmath567 fields @xmath568 such that @xmath569 , we denote by @xmath570 , where @xmath571 is the expected value under the null hypothesis . indeed , for all @xmath572 , we have , @xmath573 we use sufficient conditions to show the asymptotic normality of a sum of martingale differences @xmath563 for all @xmath20 , as @xmath574 , see e.g. @xcite .",
    "thus it suffices to show that , @xmath575 we first show the first part of .",
    "@xmath576 giving @xmath577 thus , to show that @xmath578 , it is sufficient to show that @xmath579 .",
    "indeed , @xmath580 where @xmath581 , @xmath582 and @xmath583 are given by the following .",
    "@xmath584 now we decompose @xmath585 into five sums that depends on the indices @xmath586 and @xmath587 .",
    "we begin by the first case when @xmath588 and @xmath589 , @xmath590 when @xmath591 and @xmath592 , we have using similar arguments as previously that , @xmath593 we move to the term , when @xmath588 and @xmath594 , @xmath595 now we treat the case when , @xmath596 and @xmath589 , @xmath597 finally , we treat the term for @xmath596 and @xmath594 , @xmath598 we group the previous result to get , @xmath599 where , @xmath600 now , let us bound from above the term @xmath601 in : @xmath602 we treat the two cases @xmath588 and @xmath596 each one apart .",
    "we begin by the case when @xmath596 , @xmath603 when @xmath596 , @xmath604 as consequence @xmath605 similarly we get , @xmath606 the term @xmath583 of is treated as follows , @xmath607 finally we group all the previous terms and obtain , @xmath608 to achieve the proof , we show that the second condition given in is also verified .",
    "indeed , @xmath609      to show the upper bound for the variance of @xmath610 , we follow the line of proof of proposition [ prop : esttoeplitz ] .",
    "we use that @xmath611 for all @xmath232 and @xmath0 finite integer . as an example , let us bound from above one term of the variance of @xmath610 : @xmath612 the proof of the asymptotic normality of @xmath613 , when @xmath235 and for @xmath614 such that @xmath238 , is also due to theorem 1 of @xcite .",
    "that is , we have to check ( [ conditionna ] ) as in proposition [ prop : asymptoticnormality ] . as an example , let us bound from above the term @xmath615 in with the parameters given in : @xmath616 & \\leq &   4 \\underset{1 \\leq j_1 \\neq j_2 < t}{\\ds\\sum }      w_{j_1}^{*2 } w_{j_2}^{*2 }   ( \\sum_{r_1 } \\sigma_{|r_1|}^2)^{2 } ( \\sum_{r_1 } \\sigma_{|r_1 - j_1 + j_2|}^2 ) ( \\sum_{r_2 } \\sigma_{|r_2 - j_2   + j_1|}^2 ) \\nonumber \\\\ & \\leq & 16l^2 \\underset{1 \\leq j_1 \\neq j_2 < t}{\\ds\\sum }      w_{j_1}^{*2 } w_{j_2}^{*2 }   ( \\sum _ { \\substack{r_1 \\\\ |r_1| \\leq j_1 } } \\sigma_{|r_1|}^2 + \\sum _ { \\substack{r_1 \\\\ |r_1| > j_1 } } \\sigma_{|r_1|}^2 ) ^{2 } \\nonumber \\\\ & \\leq &   16l^2 \\big\\ { \\underset{1 \\leq j_1 \\neq j_2 <   t}{\\ds\\sum }     w_{j_2}^{*2 } ( \\sum _ { \\substack{r_1 \\\\ |r_1| \\leq j_1 } } w_{|r_1|}^ * \\sigma_{|r_1|}^2)^2 +    \\underset{1 \\leq j_1 \\neq j_2 < t}{\\ds\\sum }     w_{j_1}^{*2 } w_{j_2}^{*2 } ( \\sum _ { \\substack{r_1 \\\\ |r_1| > j_1 } } \\frac{e^{2ar_1}}{e^{2aj_1 } } \\sigma_{|r_1|}^2 ) ^{2 } \\big \\ } \\nonumber \\\\ & \\leq & 16 l^2 \\big\\ { \\sum_{j_1}(\\sum_{j_2 } w_{j_2}^{*2 } ) \\cdot \\mathbb{e}^2_{\\sigma}(\\widehat{\\mathcal{a}}_n )   + 4l^2   ( \\sum_{j_2 }   w_{j_2}^ * ) \\cdot ( \\sum_{j_1 } w_{j_1}^{*2 } \\ds\\frac{1}{e^{2aj } } ) \\ } \\nonumber \\\\ & \\leq & 16 l^2 \\big\\ { \\frac { t}{2 }    \\cdot   \\mathbb{e}^2_{\\sigma}(\\widehat{\\mathcal{a}}_n^{\\mathcal{e } } ) + 4l^2\\cdot \\frac{1}{2 } \\cdot ( \\sup\\limits_{j } w_j^{*2 } )   \\cdot \\frac{1}{e^{2a}-1 } \\big\\ } \\nonumber \\\\ & \\leq & \\mathbb{e}^2_{\\sigma}(\\widehat{\\mathcal{a}}_n^{\\mathcal{e } } ) \\cdot o ( t ) + o(1 ) = o(\\frac{t}{n^2(p- t)^2 } ) + o(1 ) = o(1).\\end{aligned}\\ ] ]      to bound from above the type ii error probability , we shall distinguish 2 cases .",
    "first , when @xmath620 , we use the markov inequality , and , to show that @xmath621 . then , when @xmath622 , we have two possibilities : either @xmath623 , or @xmath624 .",
    "we show respectively that either type ii error probability tends to zero , or we use the asymptotic normality of @xmath625 to get that @xmath626    to show the lower bound , we follow the same sketch of proof of lower bounds of theorems [ theo : optimalrates ] and [ theo : sharprates ] . the key point for ellipsoids @xmath80 is to check the positivity of the matrix @xmath627 then we create a parametric family of matrices by changing the sign randomly on each diagonal of @xmath132 , with parameters given in .",
    "[ lem1 ] for @xmath18 , the symmetric toeplitz matrix @xmath628 , where @xmath629 with @xmath630 , @xmath631 for all @xmath632 , and @xmath633 defined as previously , is positive definite , for @xmath634 small enough .",
    "moreover , denote by @xmath635 the eigenvalues of @xmath636 , then @xmath637 , for all @xmath386 from 1 to @xmath1 .    using gershgorin s theorem",
    "we get that each eigenvalue of @xmath638 verifies , @xmath639 .",
    "we have , @xmath640 & = & o(1 ) \\sqrt{\\lambda } \\cdot t \\asymp \\psi \\cdot \\ds\\sqrt{\\ln ( 1/ \\psi)}. \\end{array}\\ ] ] we deduce that the smallest eigenvalue is bounded from below by @xmath641 which is strictly positive for @xmath313 small enough ."
  ],
  "abstract_text": [
    "<S> we observe a sample of @xmath0 independent @xmath1-dimensional gaussian vectors with toeplitz covariance matrix @xmath2_{1 \\leq i , j \\leq p}$ ] and @xmath3 . </S>",
    "<S> we consider the problem of testing the hypothesis that @xmath4 is the identity matrix asymptotically when @xmath5 and @xmath6 . </S>",
    "<S> we suppose that the covariances @xmath7 decrease either polynomially ( @xmath8 for @xmath9 and @xmath10 ) or exponentially ( @xmath11 for @xmath12 ) .    </S>",
    "<S> we consider a test procedure based on a weighted u - statistic of order 2 , with optimal weights chosen as solution of an extremal problem . we give the asymptotic normality of the test statistic under the null hypothesis for fixed @xmath0 and @xmath13 and the asymptotic behavior of the type i error probability of our test procedure . </S>",
    "<S> we also show that the maximal type ii error probability , either tend to @xmath14 , or is bounded from above . in the latter case , the upper bound is given using the asymptotic normality of our test statistic under alternatives close to the separation boundary . </S>",
    "<S> our assumptions imply mild conditions : @xmath15 ( in the polynomial case ) , @xmath16 ( in the exponential case ) .    </S>",
    "<S> we prove both rate optimality and sharp optimality of our results , for @xmath17 in the polynomial case and for any @xmath18 in the exponential case . </S>",
    "<S> a simulation study illustrates the good behavior of our procedure , in particular for small @xmath0 , large @xmath1 .    </S>",
    "<S> * key words : * toeplitz matrix , covariance matrix , high - dimensional data , u - statistic , minimax hypothesis testing , optimal separation rates , sharp asymptotic rates </S>",
    "<S> .    * msc 2000 : * 62g10 , 62h15 , 62g20 , 62h10 </S>"
  ]
}