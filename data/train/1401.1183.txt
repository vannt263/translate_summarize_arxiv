{
  "article_text": [
    "suppose @xmath2 is a real - valued , @xmath0th - order , @xmath1-dimensional tensors and @xmath8 is a real - valued @xmath1-vector .",
    "we let @xmath9 denote the @xmath1-vector defined by @xmath10 we let @xmath11 denote the scalar defined by @xmath12 .",
    "we say the tensor @xmath2 is _ symmetric _ if its entries are invariant under permutation .",
    "we say the tensor @xmath2 is _ positive definite _ if @xmath13 for all @xmath14 .    the notion of generalized eigenpairs has been defined for tensors by chang , pearson , and zhang @xcite as follows .",
    "let @xmath2 and @xmath3 be real - valued , @xmath0th - order , @xmath1-dimensional symmetric tensors .",
    "assume further that @xmath0 is even and @xmath3 is positive definite .",
    "we say @xmath15 is a",
    "_ generalized eigenpair _ ( also known as a _ @xmath3-eigenpair _ ) if @xmath16 taking the dot product with @xmath8 , it is clear that any solution satisfies @xmath17 the advantage of the generalized eigenpair framework is that it nicely encapsulates multiple definitions of tensor eigenvalues , as follows .    a _",
    "z - eigenpair _",
    "@xcite is defined as a pair @xmath18 such that @xmath19 this is equivalent to a generalized tensor eigenpair with @xmath20 , the identity tensor such that @xmath21 for all @xmath22 @xcite .",
    "note that , unlike ordinary tensor z - eigenpairs , generalized tensor eigenpairs allow arbitrary rescaling of the eigenvector @xmath8 with no effect on the eigenvalue @xmath23 . in this way ,",
    "the generalized tensor eigenvalue problem preserves the homogeneity of the corresponding matrix eigenproblem .",
    "an _ h - eigenpair _ is defined as a pair @xmath15 such that @xmath24}.\\ ] ] here @xmath25}$ ] denotes elementwise power , i.e. , @xmath26})_i    \\equiv { { { \\bm { \\mathbf{\\makelowercase{x}}}}}}_i^{m-1}$ ] , for @xmath27 .",
    "this is equivalent to a generalized tensor eigenpair with @xmath28 @xcite .",
    "let @xmath29 be a symmetric @xmath30 matrix and assume @xmath31 .",
    "we say @xmath32 is a _",
    "d - eigenpair _",
    "@xcite if @xmath33 this is equivalent to a @xmath3-eigenpair where @xmath3 is the symmetrized tensor outer product of @xmath29 with itself @xcite .    in this paper ,",
    "we describe a method for computing generalized eigenpairs .",
    "our method is a generalization of the shifted symmetric higher - order power method ( ss - hopm ) that we previously introduced for computing z - eigenvalues @xcite .",
    "in addition to generalizing the method , we have also significantly improved it by adding an adaptive method for choosing the shift . to derive the method",
    ", we reformulate the generalized eigenproblem , , as a nonlinear program such that any generalized eigenpair is equivalent to a kkt point in .",
    "we develop an adaptive , monotonically convergent , shifted power method for solving the optimization problem in .",
    "we call our method the generalized eigenproblem adaptive power ( geap ) method . in",
    ", we show that the geap method is much faster than the ss - hopm method for finding z - eigenpairs due to its adaptive shift selection .",
    "furthermore , the geap method is shown to find other types of generalized eigenpairs , by illustrating it on examples from related literature as well as a randomly generated example .",
    "this is the only known method for finding generalized eigenpairs besides direct numerical solution ; we survey related work in .",
    "a symmetric tensor has entries that are invariant under any permutation of its indices . more formally , a real - valued , @xmath0th - order",
    ", @xmath1-dimensional tensor @xmath2 is _ symmetric _ if @xmath34 where @xmath35 denotes the space of all @xmath0-permutations .",
    "we let @xmath36}}$ ] denote the space of all symmetric , real - valued , @xmath0th - order , @xmath1-dimensional tensors .",
    "let @xmath37}}$ ] , then we can define the following tensor - vector products .",
    "@xmath38 observe that the derivatives of the tensor - vector product w.r.t .",
    "@xmath8 are given by @xmath39 we say a tensor @xmath37}}$ ] is _ positive definite _",
    "if @xmath40 we let @xmath36}}_+$ ] denote the space of positive definite tensors in @xmath36}}$ ] .",
    "we use the symbol @xmath41 to mean symmetrized outer product , i.e. , @xmath42",
    "let @xmath43 denote the unit sphere , i.e. , @xmath44 let @xmath37}}$ ] and @xmath45}}_+$ ]",
    ". then we may define the nonlinear program @xmath46 the constraint makes the term @xmath47 in @xmath48 superfluous ; nevertheless , we retain this form since choosing @xmath20 yields @xmath49 , as in @xcite .",
    "the details of computing the derivatives are provided in .",
    "here we simply state the results as a theorem .",
    "let @xmath48 be as defined in . for @xmath50 ,",
    "the gradient is @xmath51.\\ ] ] for @xmath50 , the hessian is @xmath52 \\\\    - \\frac{m}{({{{\\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m})^2 }     \\biggl [    ( m-1 ) { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m}{{\\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-2 }    + m \\bigl ( { { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1}}\\circledcirc { { { \\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1 } } } \\bigr ) \\\\    + m { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m}\\bigl ( { { { { \\bm { \\mathbf{\\makelowercase{x}}}}}}\\circledcirc { { { \\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1 } } } \\bigr )    \\biggr].\\end{gathered}\\ ] ]    these complicated derivatives reduce for @xmath20 . in that case , we have @xmath53 and @xmath54 , so these equations become .",
    "@xmath55 these match the derivatives of @xmath49 , as proved in @xcite .",
    "note that we have used the fact that @xmath56 for all @xmath50 .",
    "we are considering the nonlinear program in because there is a correspondence between it and the generalized tensor eigenvalue problem in .",
    "note that the @xmath8 in can be arbitrarily rescaled .",
    "any pair @xmath57 is a solution to iff the scaled version with @xmath58 is a kkt point of with @xmath23 as the lagrange multiplier .",
    "first , assume @xmath57 is a solution to .",
    "let constraint @xmath50 be expressed as @xmath59 .",
    "then the lagrangian is @xmath60 hence , using the derivatives in , we have @xmath61 - m \\lambda { { { \\bm { \\mathbf{\\makelowercase{x}}}}}}= 0.\\ ] ] so , @xmath8 is a kkt point of with lagrange multiplier @xmath23 as defined in .    to prove the reverse ,",
    "assume @xmath8 is a kkt point of with lagrange multiplier @xmath23",
    ". then , must hold .",
    "if we multiply each term in by @xmath8 , then the third and fourth terms cancel out , and we conclude that @xmath23 satisfies . substituting that back into , we see that is satisfied .",
    "hence , the claim .    from the previous theorem",
    ", there is an equivalence between generalized tensor eigenpairs and kkt points of .",
    "hence , solving yields eigenpairs .",
    "an eigenpair may correspond to a local maximum , a local minimum , or a saddle point . for a given eigenpair @xmath57 normalized so that @xmath50 , we can categorize it by considering the projected hessian of the lagrangian , i.e. , @xmath62 where @xmath63 is an orthonormal basis for @xmath64 .",
    "we can then say the following : @xmath65{(\\ref*{eq : opt } ) } } } , \\\\",
    "{ { \\bm { \\mathbf{\\makeuppercase{c}}}}}(\\lambda,{{{\\bm { \\mathbf{\\makelowercase{x } } } } } } ) & \\text { negative definite } & \\rightarrow & \\text { local maximum of { \\hyperref[eq : opt]{(\\ref*{eq : opt } ) } } } , \\\\",
    "{ { \\bm { \\mathbf{\\makeuppercase{c}}}}}(\\lambda,{{{\\bm { \\mathbf{\\makelowercase{x } } } } } } ) & \\text { indefinite } & \\rightarrow & \\text { saddle point of { \\hyperref[eq : opt]{(\\ref*{eq : opt})}}}. \\end{aligned}\\ ] ] the argument is very similar to that presented in @xcite and so is omitted .",
    "optimization approaches can not easily find saddle points , but they can find local minima and maxima .",
    "we describe such an optimization approach in the next section .",
    "we propose to use a property of convex functions of the sphere to develop a monotonically convergent method .",
    "we consider an idea originally from @xcite ; see also @xcite for a proof .",
    "we have modified the theorem here to focus on its _ local _ applicability by considering just an open neighborhood of @xmath66 rather than all of @xmath67 .",
    "[ thm : cvx ] let @xmath68 be a given function , and let @xmath69 such that @xmath70 .",
    "let @xmath71 be an open neighborhood of @xmath66 , and assume @xmath72 is convex and continuously differentiable on @xmath71 .",
    "define @xmath73 . if @xmath74 and @xmath75 , then @xmath76 .",
    "[ cor : cnv ] let @xmath77 be a given function , and let @xmath69 such that @xmath70 .",
    "let @xmath71 be an open neighborhood of @xmath66 , and assume @xmath72 is concave and continuously differentiable on @xmath71 .",
    "define @xmath78 . if @xmath74 and @xmath75 , then @xmath79 .",
    "hence , if @xmath72 is locally convex , then a simple algorithm , i.e. , @xmath80 will yield ascent .",
    "conversely , if @xmath72 is locally concave , we can expect descent from @xmath81 .",
    "unfortunately , the function @xmath48 in may not be convex or concave .    to fix this",
    ", we work with a shifted function , @xmath82 from @xcite , we have that for @xmath50 , @xmath83 if we choose @xmath84 appropriately , then we can ensure that @xmath85 is positive or negative definite , ensuring that @xmath86 is locally convex or concave . in @xcite for the special case of @xmath87 , we proposed choosing a single value for @xmath84 in ss - hopm that ensured convexity on the entire sphere .",
    "but it is difficult to choose a reasonable value in advance , and poor choices lead to either very slow convergence or a complete lack of convergence . in this work ,",
    "we propose to choose @xmath84 adaptively .",
    "for an arbitrary matrix @xmath30 symmetric matrix @xmath88 , the following notation denotes its eigenvalues : @xmath89 .",
    "assume @xmath50 .",
    "let @xmath90 and @xmath85 be defined as in and , respectively . for @xmath91 ,",
    "the eigenvalues of @xmath92 are bounded as @xmath93 for @xmath94 .",
    "likewise , for @xmath95 , the eigenvalues of @xmath92 are bounded as @xmath96 for @xmath94 .",
    "the proof follows immediately from weyl s inequality .    in the convex case ,",
    "our goal is to choose @xmath84 so that @xmath92 is positive semi - definite in a local neighborhood of the current iterate , @xmath8 . by the smoothness of @xmath86 when @xmath8 is away from zero , we may argue that for every @xmath97 , there exists and @xmath98 such that @xmath92 is positive semi - definite for all @xmath99 whenever @xmath100 .",
    "in other words , @xmath101 is the threshold for positive definiteness .",
    "assume @xmath50 .",
    "let @xmath97 . if @xmath102 then @xmath103 .    in the concave case , our goal is to choose @xmath84 so that @xmath92 is negative semi - definite in a local neighborhood of the current iterate .",
    "assume @xmath50 .",
    "let @xmath97 . if @xmath104 then @xmath105 .    from ,",
    "if @xmath84 is selected to make @xmath86 locally convex , we have @xmath106 so long as @xmath107 , the convex neighborhood of @xmath8 .",
    "even though we are adaptively changing @xmath84 , we see increase in the original function at each step .",
    "a similar argument applies in the concave case , with the function decreasing at each step .",
    "the potential problem with this approach is that it may be the case that @xmath108 .",
    "if that happens , we may observe that the function values ( i.e. , @xmath109 ) are not increasing ( or decreasing ) monotonically as expected . to fix this , we make a more conservative choice for @xmath101 ( at least temporarily ) , which will in turn enforce a more conservative choice of @xmath84 .",
    "if @xmath101 is large enough , then we will satisfy the lower bound on @xmath84 that guarantees convergence for the shifted algorithm ( this is proven for z - eigenvalue in @xcite ; the proof for the general problem is similar and so omitted ) . thus far in our experiments , such contingencies have not been necessary , so we have not included the details in the algorithm .",
    "the full algorithm is presented in .    given tensors @xmath37}}$ ] and @xmath45}}_+$ ] and",
    "an initial guess @xmath110 .",
    "let @xmath111 if we want to find local maxima ( and the function is convex ) ; otherwise , let @xmath112 , indicating that we are seeking local minima ( and the function is concave ) .",
    "let @xmath101 be the tolerance on being positive / negative definite .",
    "@xmath113 precompute @xmath114 , @xmath115 , @xmath116 , @xmath117 , @xmath118 , @xmath119 @xmath120 @xmath121 @xmath122 @xmath123 @xmath124    the cost per iteration of is as follows .",
    "assuming @xmath2 and @xmath3 are dense , the dominant cost is computing products with these tensors . computing",
    "the hessian requires six products : @xmath125 .",
    "recall that @xmath126 is given by @xmath127 the cost is @xmath128 multiplies and @xmath129 additions per each of @xmath130 entries ; therefore , the total cost is @xmath131 operations .",
    "exploiting symmetry yields reduces the cost to @xmath132 @xcite .",
    "we can compute @xmath133 for an additional cost of @xmath134 and @xmath135 operations , respectively .",
    "( these can also be computed directly , but at a cost of @xmath131 operations each . )",
    "these values have to be computed for both @xmath2 and @xmath3 at every iteration for a total cost ( ignoring symmetry ) of @xmath136 .",
    "once these six products are computed , the cost for computing @xmath137 is a series of matrix operations , for a total cost of @xmath138 .",
    "the cost of computing the eigenvalues of the symmetric matrix @xmath137 is @xmath139 , which is less than the cost of the products .",
    "updating @xmath8 requires a 5 vector operations at a cost of @xmath1 operations each .",
    "hence , cost of the method is dominated by the computation of @xmath126 and @xmath140 , at an expense of @xmath132 .      in",
    ", we show the specialization of the method to the z - eigenvalue problem .",
    "this is the same as ss - hopm , except for the adaptive shift .",
    "note that unlike , this algorithm can be used even when @xmath0 is odd .",
    "the cost per iteration of is the same order as for , but it does not need to do any computations with @xmath141 .    given tensor @xmath37}}$ ] and an initial guess @xmath110 .",
    "let @xmath111 if we want to find local maxima ( and the function is convex ) ; otherwise , let @xmath112 , indicating that we are seeking local minima ( and the function is concave ) .",
    "let @xmath101 be the tolerance on being positive / negative definite .",
    "@xmath113 precompute @xmath114 , @xmath116 , @xmath118 @xmath142 @xmath143 @xmath122 @xmath144 @xmath124",
    "all numerical tests were done using matlab version r2012b and the tensor toolbox version 2.5 @xcite .",
    "the experiments were performed a laptop computer with an intel dual - core i7 - 3667ucpu ( 2ghz ) and 8 gb of ram .    in all numerical experiments , we used the following settings .",
    "we set @xmath145 , where @xmath101 is the tolerance on being positive or negative definite .",
    "we consider the iterates to be converged once @xmath146 .",
    "the maximum iterations is 500 .",
    "the following example is originally from @xcite and was used in evaluating the ss - hopm algorithm in @xcite .",
    "our goal is to compute the z - eigenpairs using the z - eigenpair adaptive power method in and show that it is faster than ss - hopm  @xcite using a fixed value for the shift .",
    "kofidis and regalia @xcite [ ex : kore02ex1 ] our objective is to compute the z - eigenpairs .",
    "let @xmath147}}$ ] be the symmetric tensor given by kofidis and regalia ( * ? ? ?",
    "* example 1 ) whose entries are specified in ( ) . since we are computing z - eigenpairs , we have @xmath20 .",
    "a complete list of the 11 z - eigenpairs is provided in ( ) ; there are three maxima and three minima .",
    "a comparison of the fixed and adaptive shift results are provided in .",
    "there are six different experiments looking at maxima ( @xmath111 ) and minima ( @xmath112 ) and different shifts ( @xmath148 ) in .",
    "note that using a fixed shift means that is equivalent to ss - hopm and no adaptive update of the shift is performed in step 5 .",
    "we used 100 random starting guesses , each entry selected uniformly at random from the interval @xmath149 $ ] ; the same set of random starts was used for each set of experiments .",
    "for each eigenpair , the table lists the number of occurrences in the 100 experiments , the median number of iterations until convergence , the number of runs that violated monotonicity , the average error and standard deviation in the final result , and the average run time and standard deviation .",
    "the error is computed as @xmath150 .",
    "the two monotinicity violations were both extremely small , i.e. , o(@xmath151 ) .",
    "these violations indicate that a step went outside the region of local convexity .",
    "@xmath84 adaptive , @xmath1113 53 & 0.8893 & 0.6672 & 0.2471 & -0.7027 & 30 & & 9e-09 & 3e-09 & 0.05 & 0.02 + 29 & 0.8169 & 0.8412 & -0.2635 & 0.4722 & 34 & & 1e-08 & 3e-09 & 0.04 & 0.01 + 18 & 0.3633 & 0.2676 & 0.6447 & 0.7160 & 26 & & 7e-09 & 2e-09 & 0.03 & 0.00 +    @xmath152 , @xmath1113 53 & 0.8893 & 0.6672 & 0.2471 & -0.7027 & 49 & 1 & 1e-15 & 2e-08 & 3e-09 & 0.07 & 0.03 + 29 & 0.8169 & 0.8412 & -0.2635 & 0.4722 & 45 & & 2e-08 & 3e-09 & 0.04 & 0.00 + 18 & 0.3633 & 0.2676 & 0.6447 & 0.7160 & 57 & & 2e-08 & 2e-09 & 0.06 & 0.00 +    @xmath153 , @xmath1113 48 & 0.8893 & 0.6672 & 0.2471 & -0.7027 & 192 & & 5e-08 & 6e-09 & 0.24 & 0.12 + 29 & 0.8169 & 0.8412 & -0.2635 & 0.4722 & 185 & & 5e-08 & 5e-09 & 0.17 & 0.02 + 18 & 0.3633 & 0.2676 & 0.6447 & 0.7160 & 261 & & 5e-08 & 2e-09 & 0.24 & 0.02 + 5 & & & & 0.43 & 0.01 +    @xmath154 , @xmath1123 22 & -0.0451 & 0.7797 & 0.6135 & 0.1250 & 18 & & 4e-09 & 2e-09 & 0.02 & 0.00 + 37 & -0.5629 & 0.1762 & -0.1796 & 0.9678 & 17 & & 6e-09 & 2e-09 & 0.02 & 0.00 + 41 & -1.0954 & 0.5915 & -0.7467 & -0.3043 & 17 & & 6e-09 & 3e-09 & 0.02 & 0.01 +    @xmath155 , @xmath1123 22 & -0.0451 & 0.7797 & 0.6135 & 0.1250 & 34 & & 1e-08 & 2e-09 & 0.03 & 0.00 + 37 & -0.5629 & 0.1762 & -0.1796 & 0.9678 & 20 & & 7e-09 & 2e-09 & 0.02 & 0.00 + 41 & -1.0954 & 0.5915 & -0.7467 & -0.3043 & 21 & 1 & 1e-15 & 8e-09 & 4e-09 & 0.02 & 0.00 +    @xmath156 , @xmath1123 22 & -0.0451 & 0.7797 & 0.6135 & 0.1250 & 186 & & 5e-08 & 2e-09 & 0.16 & 0.01 + 37 & -0.5629 & 0.1762 & -0.1796 & 0.9678 & 103 & & 4e-08 & 4e-09 & 0.09 & 0.01 + 41 & -1.0954 & 0.5915 & -0.7467 & -0.3043 & 94 & & 4e-08 & 6e-09 & 0.09 & 0.01 +    the first three experiments use @xmath111 to look for local maxima .",
    "the first experiment varies @xmath84 , the second uses @xmath152 ( as in @xcite ) , and the third uses @xmath153 .",
    "all three variations find all three local maxima .",
    "the results for @xmath152 and the adaptive method are nearly identical  they find the same local maxima with the same frequency .",
    "the difference is that @xmath152 uses more iterations than the adaptive shift .",
    "choosing @xmath153 is similar , except now five of the runs do not converge within the allotted 500 iterations .",
    "there was no breakdown in monotonicity , and these runs would converge eventually . if the shift is too small ( e.g. , @xmath157 ) , then some or all of the runs may fail to converge  @xcite .",
    "the last three experiments use @xmath112 to find local minima .",
    "again , we vary @xmath84 using an adaptive choice along with @xmath155 and @xmath156 .",
    "the adaptive method requires the fewest number of iterations .",
    "each experiments finds all three local minima with the exact same frequencies .    to compare the convergence in terms of the number of iterations , shows sample results for one run for computing z - eigenpairs of @xmath2 from .",
    "the left hand plot shows the selected shift values at each iteration .",
    "the right hand plot shows the convergence of the eigenvalue .",
    "the adaptive shift is the fastest to converge .",
    "here we demonstrate that the geap method in calculates h - eigenpairs with an appropriate choice for @xmath141 .",
    "[ ex : heig ] we generate a random symmetric tensor @xmath158}}$ ] as follows : we select random entries from @xmath149 $ ] , symmetrize the result , and round to four decimal places .",
    "the tensor entries are specified in ( ) . since we are computing h - eigenpairs , we specify @xmath141 as @xmath28 .",
    "a complete list of the h - eigenpairs is provided in ( ) ; there are five maxima and five minima .",
    "a summary of the results are provided in .",
    "there are two different experiments looking at maxima ( @xmath111 ) and minima ( @xmath112 ) .",
    "we used 1000 random starting guesses , each entry selected uniformly at random from the interval @xmath149 $ ] ; the same set of random starts was used for each experiment .",
    "the columns are the same as for .",
    "the error is computed as @xmath159 } \\|_2 $ ] .",
    "@xmath1114 211 & 14.6941 & 0.5426 & -0.4853 & 0.4760 & 0.4936 & 28 & 124 & 2e-15 & 2e-09 & 2e-09 & 0.08 & 0.02 + 144 & 9.6386 & 0.5342 & -0.5601 & 0.5466 & -0.3197 & 110 & 53 & 4e-15 & 9e-09 & 3e-09 & 0.27 & 0.04 + 338 & 8.7371 & 0.4837 & 0.5502 & 0.6671 & -0.1354 & 100 & 143 & 4e-15 & 1e-08 & 5e-09 & 0.26 & 0.06 + 169 & 5.8493 & 0.6528 & 0.5607 & -0.0627 & -0.5055 & 54 & 19 & 2e-15 & 8e-09 & 3e-09 & 0.13 & 0.02 + 138 & 4.8422 & 0.5895 & -0.2640 & -0.4728 & 0.5994 & 66 & 13 & 8e-01 & 6e-09 & 1e-09 & 0.16 & 0.01 +    @xmath1124 130 & -2.9314 & 0.3161 & 0.5173 & 0.4528 & -0.6537 & 76 & 3 & 2e-15 & 7e-09 & 1e-09 & 0.18 & 0.02 + 149 & -3.7179 & 0.6843 & 0.5519 & 0.3136 & 0.3589 & 59 & 10 & 1e-15 & 7e-09 & 2e-09 & 0.15 & 0.02 + 152 & -4.1781 & 0.4397 & 0.5139 & -0.5444 & 0.4962 & 99 & 7 & 2e-15 & 5e-09 & 1e-09 & 0.23 & 0.03 + 224 & -8.3200 & 0.5970 & -0.5816 & -0.4740 & -0.2842 & 65 & 73 & 2e-15 & 8e-09 & 3e-09 & 0.16 & 0.02 + 345 & -10.7440 & 0.4664 & 0.4153 & -0.5880 & -0.5140 & 47 & 181 & 2e-15 & 4e-09 & 3e-09 & 0.12 & 0.03 +    the first experiment uses @xmath111 to look for local maxima .",
    "we find all five local maxima .",
    "there are several monotonicity violations , including at least one for @xmath160 that is relatively large .",
    "these violations indicate that a step went outside the region of local convexity .",
    "nevertheless , in all cases the algorithm is able to recover and converge , as can be seen from the small error . in general , these monotonicity violations",
    "do not cause the algorithm to fail .",
    "however , such violations can be avoided by increasing @xmath101 , the tolerance on the definiteness of the hessian matrix .",
    "once @xmath101 is large enough , the shift will be so great that the function will be convex over the entire unit sphere .",
    "the downside of choosing a large value for @xmath101 ( and the shift @xmath161 ) is that convergence will be slow .",
    "the second experiment uses @xmath162 to look for local minima .",
    "we find all five local minima .",
    "there are several monotinicity violations , but they are all small .      next we consider a different type of tensor eigenapair that also conforms to the generalized tensor eigenpair framework .",
    "d - eigenpairs @xcite [ ex : deig ] qi , wang , and wu @xcite propose d - eigenpairs for diffusion kurtosis imaging ( dki ) .",
    "the tensors @xmath163}}$ ] are specified in ( and , respecitively ) .",
    "we consider this example here since it can be expressed as a generalized tensor eigenproblem . and",
    "@xmath29 are provided in @xcite .",
    "we were unable to validate the solutions provided in the original paper .",
    "it is not clear if this is to a lack of precision or a typo in paper . here ,",
    "the problem is rescaled as well : @xmath29 is multiplied by @xmath164 , @xmath23 is divided by @xmath165 , and @xmath8 is divided by @xmath166 .",
    "] there are a total of 13 distinct real - valued d - eigenpairs , computed by solving the polynomial equations using mathematica and listed in ( ) ; there are four maxima and three minima",
    ".    shows the eigenpairs calculated by .",
    "the error is computed as @xmath167 .",
    "with 100 random starts , we find the four local maxima with @xmath111 . likewise , with 100 random starts , we find the three local minima with @xmath112 .",
    "there are no violations to monotonicity .",
    "@xmath1113 31 & 0.5356 & 0.9227 & -0.1560 & -0.3526 & 39 & & 4e-08 & 5e-09 & 0.08 & 0.01 + 19 & 0.4359 & 0.5388 & 0.8342 & -0.1179 & 48 & & 3e-08 & 4e-09 & 0.09 & 0.02 + 25 & 0.2514 & 0.3564 & -0.8002 & 0.4823 & 67 & & 4e-08 & 3e-09 & 0.13 & 0.01 + 25 & 0.2219 & 0.2184 & 0.3463 & 0.9124 & 34 & & 6e-08 & 8e-09 & 0.07 & 0.01 +    @xmath1123 39 & -0.0074 & 0.3669 & 0.5346 & -0.7613 & 13 & & 1e-08 & 4e-09 & 0.03 & 0.01 + 37 & -0.1242 & 0.9439 & 0.1022 & 0.3141 & 51 & & 5e-08 & 5e-09 & 0.10 & 0.01 + 24 & -0.3313 & 0.2810 & -0.9420 & -0.1837 & 27 & & 2e-08 & 4e-09 & 0.06 & 0.01 +      here we consider a randomly generated problem .",
    "we use the randomly generated @xmath158}}$ ] described in . however , we need a method to generate a positive definite @xmath3 .",
    "we use the notation @xmath168}}$ ] to denote tensor - matrix multiplication in which the tensor @xmath169 is multiplied by a matrix @xmath170 in every mode , i.e. , @xmath171    [ thm : posdef ] let @xmath172 be symmetric . for @xmath0 even , define @xmath45}}$ ] as @xmath173 .",
    "if @xmath174 is a real - valued eigenpair of @xmath175 and @xmath58 , then @xmath57 is a z - eigenpair of @xmath141 with @xmath176 .",
    "furthermore , @xmath177 for any @xmath178 with @xmath179 .",
    "let @xmath174 be an eigenpair of @xmath175 such that @xmath180 .",
    "noting that @xmath181 , we have @xmath182 to prove the lower bound , let @xmath178 with @xmath179 .",
    "we can write @xmath183 as a linear combination of the eigenvectors of @xmath175 , i.e. , @xmath184 and @xmath185",
    ". then @xmath186 hence , the claim .",
    "random[ex : random ] we use the same randomly - generated symmetric tensor @xmath187}}$ ] as for and listed in ( ) . to generate a random positive definite symmetric tensor @xmath188}}_+ = { \\mathbb{s}^{[6,4]}}_+$ ] , we use .",
    "( note that this approach samples a convenient subset of @xmath36}}_+$ ] and does not draw from the entire space . )",
    "we compute a matrix @xmath189 , where @xmath190 is a random orthonormal matrix and @xmath191 is a diagonal matrix with entries selected uniformly at random from @xmath192 \\cup [ \\gamma,1]$ ] with @xmath193{0.1 } = \\sqrt[6]{0.1}$ ] .",
    "we let @xmath194 , so that @xmath3 has all its z - eigenvalues in @xmath195 $ ] and is positive definite . in this case , the randomly selected diagonal for @xmath29 is @xmath196 .",
    "the random @xmath141 is then rounded to four decimal places , and the entries are given in ( ) .",
    "its minimum z - eigenvalue ( computed by geap ) is @xmath197 , as expected .",
    "there are a total of 26 real - valued @xmath3-eigenpairs of @xmath2 , listed in ( ) .",
    "there are three maxima and four minima",
    ".    shows the generalized eigenpairs calculated by .",
    "the error is computed as @xmath167 . with 1000 random starts ,",
    "we find the three local maxima with @xmath111 .",
    "likewise , with 1000 random starts , we find the four local minima with @xmath112 .",
    "there are only small violations to monotonicity ; the maximum of any violation was o(@xmath198 ) .",
    "@xmath1114 683 & 11.3476 & 0.4064 & 0.2313 & 0.8810 & 0.0716 & 59 & 420 & 4e-15 & 5e-09 & 4e-09 & 0.14 & 0.03 + 128 & 3.7394 & 0.2185 & -0.9142 & 0.2197 & -0.2613 & 140 & 11 & 2e-15 & 1e-08 & 3e-09 & 0.30 & 0.04 + 189 & 2.9979 & 0.8224 & 0.4083 & -0.0174 & -0.3958 & 23 & 9 & 1e-15 & 3e-09 & 1e-09 & 0.06 & 0.01 +    @xmath1124 151 & -1.1507 & 0.1935 & 0.5444 & 0.2991 & -0.7594 & 88 & & 8e-09 & 8e-10 & 0.19 & 0.02 + 226 & -3.2777 & 0.6888 & -0.6272 & -0.2914 & -0.2174 & 33 & 14 & 1e-15 & 6e-09 & 2e-09 & 0.08 & 0.01 + 140 & -3.5998 & 0.7899 & 0.4554 & 0.2814 & 0.2991 & 22 & 21 & 1e-15 & 2e-09 & 1e-09 & 0.05 & 0.01 + 483 & -6.3985 & 0.0733 & 0.1345 & 0.3877 & 0.9090 & 82 & 73 & 2e-15 & 9e-09 & 3e-09 & 0.17 & 0.03 +",
    "like its predecessor ss - hopm @xcite , the geap method has the desirable qualities of guaranteed convergence and simple implementation .",
    "additionally , the adaptive choice of @xmath84 in geap ( as opposed to ss - hopm ) means that there are no parameters for the user to specify .    also like ss - hopm , the geap method can only converge to local maxima and minima of and so will miss any saddle point solutions .",
    "nevertheless , the largest and smallest magnitude eigenvalues can always be discovered by geap since they will not be saddle points .",
    "an alternative to geap is to solve or using a numerical nonlinear , homotopy , or optimization approach .",
    "the advantage of geap is that is guarantees decrease at each iteration _ without _ any globalization techniques ( like line search or trust region ) and is generally as cheap or cheaper per iteration than any competing numerical method .",
    "the disadvantage is that the rate of convergence of geap is only linear , as opposed to quadratic for , say , newton s method .",
    "han @xcite proposed an unconstrained variations principle for finding generalized eigenpairs . in the general case ,",
    "the function to be optimized is @xmath199 the @xmath200 has the same meaning as for geap : choosing @xmath111 finds local maxima and @xmath112 finds local minima . for comparison ,",
    "the final solution is rescaled as @xmath201{{{{\\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m}}$ ] , and then we calculate @xmath202 ( since @xmath53 ) .",
    "the computational experiment settings are the same as specified in .",
    "han used the matlab optimization toolbox , and we use version 2.6.1 .",
    "folliwng han , we use the ` fminunc ` function and the default settings from calling ` optimset(fminunc ) ` except that we explicitly specify    * ` gradobj : on ` * ` largescale : off ` * ` tolx:1e-10 ` * ` tolfun:1e-8 ` * ` maxiter:10000 ` * ` display : off `    this means that the toolbox uses a quasi - newton method with a line search which should have superlinear convergence .",
    "the results of han s method for are shown in .",
    "for each eigenpair , the table lists the number of occurrences in the 1000 experiments , the median number of function evaluations ( fevals ) until convergence , the average error and standard deviation in the final result , and the average run time and standard deviation .",
    "the error is computed as @xmath167 ; both methods achieved comparable errors .",
    "@xmath1114 718 & 11.3476 & 0.5544 & 0.3155 & 1.2018 & 0.0977 & 45 & 1e-08 & 2e-08 & 0.17 & 0.06 + 134 & 3.7394 & 0.2642 & -1.1056 & 0.2657 & -0.3160 & 31 & 4e-09 & 7e-09 & 0.12 & 0.05 + 144 & 2.9979 & 1.0008 & 0.4969 & -0.0212 & -0.4817 & 31 & 4e-09 & 5e-09 & 0.12 & 0.05 + 4 & & 0.21 & 0.10 +    @xmath1124 72 & -1.1507 & 0.2291 & 0.6444 & 0.3540 & -0.8990 & 34 & 9e-09 & 3e-08 & 0.14 & 0.06 + 150 & -3.2777 & 0.8349 & -0.7603 & -0.3532 & -0.2635 & 33 & 5e-09 & 7e-09 & 0.14 & 0.07 + 148 & -3.5998 & 1.0486 & 0.6046 & 0.3736 & 0.3971 & 41 & 6e-09 & 8e-09 & 0.16 & 0.08 + 624 & -6.3985 & 0.1003 & 0.1840 & 0.5305 & 1.2438 & 48 & 7e-09 & 1e-08 & 0.19 & 0.08 + 4 & & 0.10 & 0.11 + 2 & & 0.23 & 0.02 +    for @xmath111 , han s method finds all three local maxima , though it fails to converge within 10,000 iterations for four starting points .",
    "there are no consistent results with respect to time .",
    "han s method is faster than geap for @xmath203 but slower for the other two eigenpairs",
    ". this is consistent if we compare the number of function evaluations and the number of iterations for geap , which are measuring comparable amounts of work .    for @xmath112 ,",
    "han s method finds all four local minima , but it fails to converge for two starting points and converges to wrong solutions for four starting points . in those four cases , it terminated because the gradient was small ( flag = 1 ) for three cases and the fourth it stopped because it could no improve the function value ( flag = 5 ) . in this case , geap was faster on average for all eigenpairs .",
    "in general , han s method represents an alternative approach to solving the generalized tensor eigenpair problem . in @xcite , han s method",
    "was compared to ss - hopm with a fixed shift ( for z - eigenpairs only ) and was superior .",
    "however , geap is usually as fast as han s method and perhaps a little more robust in terms of its convergence behavior .",
    "the speed being similar is thanks to the adaptive shift in geap .",
    "it may be that han s method could avoid problems of converging to incorrect solutions with tighter tolerances , but then the speed would be slower .      since is a polynomial system of equations , we can also consider a polynomial solver approach .",
    "this does not scale to larger problems and may be slow even for small problems .",
    "nevertheless , it finds _ all _ solutions ( even saddle points ) . we have used the grbner basis polynomial solver ` nsolve ` in mathematica to compute the full set of solutions for the problems discussed in this paper .    in terms of methods specifically geared to tensor eigenvalues ,",
    "most work has focused on computing the largest h - eigenvalue for a _ nonnegative _ tensor : @xcite .",
    "the method of liu , zhou , and ibrahim @xcite is guaranteed to always find the largest eigenvalue and also uses a `` shift '' approach .",
    "the paper has proposed two improvements to the ss - hopm method @xcite .",
    "first , we have adapted the method to the _ generalized _ tensor eigenproblem .",
    "second , we have proposed a method for adaptively and automatically selecting the shift , overcoming a major problem with the ss - hopm method because choosing the shift too large dramatically slows convergence whereas choosing it too small can cause the method to fail completely .",
    "we have tested our method numerically on several problems from the literature , including computing of z- , h- , and d - eigenpairs .",
    "we have also proposed a novel method for generating random symmetric positive definite tensors .",
    "as this paper was in review , a new method has been proposed to compute _ all _ real general eigenvalues using jacobian semidefinite programming relaxations @xcite .",
    "comparing to this method will be a topic of future study .",
    "first , we consider the gradient and hessian of the general function @xmath204 let @xmath205 denote @xmath206 . from matrix calculus , the gradient of @xmath48 is    @xmath207    here we have dropped the argument , @xmath8 , to simply the notation .",
    "let @xmath208 denote @xmath209 .",
    "the hessian of @xmath48 is @xmath210\\\\    -\\frac{1}{{f_3{}}^2 }    \\bigl [    { f_1{}}{f_2{}}{{{\\bm { \\mathbf{\\makeuppercase{h}}}}}_3{}}+ { f_2{}}({{{{\\bm { \\mathbf{\\makelowercase{g}}}}}_1{}}\\circledcirc { { { \\bm { \\mathbf{\\makelowercase{g}}}}}_3 { } } } )     + { f_1{}}({{{{\\bm { \\mathbf{\\makelowercase{g}}}}}_2{}}\\circledcirc { { { \\bm { \\mathbf{\\makelowercase{g}}}}}_3 { } } } )     \\bigr].\\end{gathered}\\ ] ] now we specialize @xmath48 to : let @xmath211 , @xmath212 , and @xmath213 .",
    "the following derivatives are proved in @xcite : @xmath214 we need only consider the case for @xmath50 , so we may assume @xmath215 putting everything together , we have for @xmath50 , @xmath216.\\ ] ] for the hessian , assuming @xmath50 , we have @xmath217 \\\\    - \\frac{m}{({{{\\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m})^2 }     \\biggl [    ( m-1 ) { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m}{{\\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-2 }    + m \\bigl ( { { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1}}\\circledcirc { { { \\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1 } } } \\bigr )    + m { { { \\boldsymbol { \\mathscr{\\makeuppercase{a}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^m}\\bigl ( { { { { \\bm { \\mathbf{\\makelowercase{x}}}}}}\\circledcirc { { { \\boldsymbol { \\mathscr{\\makeuppercase{b}}}}}{{{\\bm { \\mathbf{\\makelowercase{x}}}}}}^{m-1 } } } \\bigr )    \\biggr].\\end{gathered}\\ ] ]",
    "the tensor for comes from example 1 in kofidis and regalia @xcite and is specified in .",
    "@xmath218    the tensor @xmath219 used for is randomly generated as described in ; its entries are specified in .",
    "@xmath220    the tensor used in .",
    "the dki tensor @xmath147}}$ ] ( called @xmath221 in the original paper ) is the symmetric tensor defined by the unique elements shown in .",
    "the tensor @xmath141 is the symmetrized outer product of the matrix @xmath29 with itself where @xmath222 so @xmath3 is the tensor whose unique elements are given in    @xmath223    @xmath224    the tensor @xmath219 used in is the same as is used in and specified in .",
    "the tensor @xmath141 is a random positive definite tensor from ; it entries are specified in .",
    "a polynomial system solver ( ` nsolve ` ) using a grbner basis method is available in mathematica and has been employed to generate a complete list of eigenpairs for the examples in this paper in tables [ tab : kore02ex1_ep][tab : random_eigs ] .",
    "-1.0954 & 0.5915 & -0.7467 & -0.3043 & 1.86 & 2.75 & minima + -0.5629 & 0.1762 & -0.1796 & 0.9678 & 1.63 & 2.38 & minima + -0.0451 & 0.7797 & 0.6135 & 0.1250 & 0.82 & 1.25 & minima + 0.1735 & 0.3357 & 0.9073 & 0.2531 & -1.10 & 0.86 & saddle + 0.2433 & 0.9895 & 0.0947 & -0.1088 & -1.19 & 1.46 & saddle + 0.2628 & 0.1318 & -0.4425 & -0.8870 & 0.62 & -2.17 & saddle + 0.2682 & 0.6099 & 0.4362 & 0.6616 & -1.18 & 0.79 & saddle + 0.3633 & 0.2676 & 0.6447 & 0.7160 & -1.18 & -0.57 & maxima + 0.5105 & 0.3598 & -0.7780 & 0.5150 & 0.59 & -2.34 & saddle + 0.8169 & 0.8412 & -0.2635 & 0.4722 & -2.26 & -0.90 & maxima + 0.8893 & 0.6672 & 0.2471 & -0.7027 & -1.85 & -0.89 & maxima +     @xmath226 & @xmath227 & @xmath228 & @xmath229 & @xmath230 & @xmath231 & @xmath232 & @xmath233 & minima + @xmath234 & @xmath235 & @xmath236 & @xmath237 & @xmath238 & @xmath239 & @xmath240 & @xmath241 & minima + @xmath242 & @xmath243 & @xmath244 & @xmath245 & @xmath246 & @xmath247 & @xmath248 & @xmath249 & minima + @xmath250 & @xmath251 & @xmath252 & @xmath253 & @xmath254 & @xmath255 & @xmath256 & @xmath257 & minima + @xmath258 & @xmath259 & @xmath260 & @xmath261 & @xmath262 & @xmath263 & @xmath264 & @xmath265 & saddle + @xmath266 & @xmath267 & @xmath268 & @xmath269 & @xmath270 & @xmath271 & @xmath272 & @xmath273 & saddle + @xmath274 & @xmath275 & @xmath276 & @xmath277 & @xmath278 & @xmath279 & @xmath280 & @xmath281 & minima + @xmath282 & @xmath283 & @xmath284 & @xmath285 & @xmath286 & @xmath287 & @xmath288 & @xmath289 & saddle + @xmath290 & @xmath291 & @xmath292 & @xmath293 & @xmath294 & @xmath295 & @xmath296 & @xmath297 & saddle + @xmath298 & @xmath299 & @xmath300 & @xmath301 & @xmath302 & @xmath303 & @xmath304 & @xmath305 & saddle + @xmath306 & @xmath307 & @xmath308 & @xmath309 & @xmath310 & @xmath311 & @xmath312 & @xmath313 & saddle + @xmath314 & @xmath315 & @xmath316 & @xmath317 & @xmath318 & @xmath319 & @xmath320 & @xmath321 & saddle + @xmath322 & @xmath323 & @xmath324 & @xmath325 & @xmath326 & @xmath327 & @xmath328 & @xmath329 & saddle + @xmath330 & @xmath331 & @xmath332 & @xmath333 & @xmath334 & @xmath335 & @xmath336 & @xmath337 & saddle + @xmath338 & @xmath339 & @xmath340 & @xmath341 & @xmath342 & @xmath343 & @xmath344 & @xmath345 & saddle + @xmath346 & @xmath347 & @xmath348 & @xmath349 & @xmath350 & @xmath351 & @xmath352 & @xmath353 & saddle + @xmath354 & @xmath355 & @xmath356 & @xmath357 & @xmath358 & @xmath359 & @xmath360 & @xmath361 & saddle + @xmath362 & @xmath363 & @xmath364 & @xmath365 & @xmath366 & @xmath367 & @xmath368 & @xmath369 & saddle + @xmath370 & @xmath371 & @xmath372 & @xmath373 & @xmath374 & @xmath375 & @xmath376 & @xmath377 & saddle + @xmath378 & @xmath379 & @xmath380 & @xmath381 & @xmath382 & @xmath383 & @xmath384 & @xmath385 & saddle + @xmath386 & @xmath387 & @xmath388 & @xmath389 & @xmath390 & @xmath391 & @xmath392 & @xmath393 & saddle + @xmath394 & @xmath395 & @xmath396 & @xmath397 & @xmath398 & @xmath399 & @xmath400 & @xmath401 & saddle + @xmath402 & @xmath403 & @xmath404 & @xmath405 & @xmath406 & @xmath407 & @xmath393 & @xmath408 & saddle + @xmath409 & @xmath410 & @xmath411 & @xmath412 & @xmath413 & @xmath414 & @xmath415 & @xmath416 & saddle + @xmath417 & @xmath418 & @xmath419 & @xmath420 & @xmath421 & @xmath422 & @xmath423 & @xmath424 & saddle + @xmath425 & @xmath426 & @xmath427 & @xmath428 & @xmath429 & @xmath430 & @xmath431 & @xmath432 & saddle + @xmath433 & @xmath434 & @xmath435 & @xmath436 & @xmath437 & @xmath438 & @xmath439 & @xmath440 & saddle + @xmath441 & @xmath442 & @xmath443 & @xmath444 & @xmath445 & @xmath446 & @xmath447 & @xmath448 & maxima + @xmath449 & @xmath450 & @xmath451 & @xmath452 & @xmath453 & @xmath454 & @xmath455 & @xmath456 & saddle + @xmath457 & @xmath458 & @xmath459 & @xmath460 & @xmath461 & @xmath462 & @xmath463 & @xmath464 & maxima + @xmath465 & @xmath466 & @xmath467 & @xmath468 & @xmath469 & @xmath470 & @xmath471 & @xmath472 & maxima + @xmath473 & @xmath474 & @xmath475 & @xmath476 & @xmath477 & @xmath478 & @xmath479 & @xmath480 & saddle + @xmath481 & @xmath482 & @xmath483 & @xmath484 & @xmath485 & @xmath486 & @xmath487 & @xmath488 & maxima + @xmath489 & @xmath490 & @xmath491 & @xmath492 & @xmath493 & @xmath494 & @xmath495 & @xmath496 & maxima +     -0.3313 & 0.2309 & -0.7741 & -0.1509 & 1.02 & 2.11 & minima + -0.1242 & 0.6577 & 0.0712 & 0.2189 & 0.35 & 1.25 & minima + -0.0074 & 0.2161 & 0.3149 & -0.4485 & 0.36 & 0.46 & minima + 0.0611 & 0.6113 & -0.4573 & 0.1181 & -0.63 & 1.14 & saddle + 0.1039 & 0.3314 & 0.5239 & 0.3084 & -0.46 & 0.63 & saddle + 0.2009 & 0.2440 & -0.1250 & 0.4601 & -0.32 & 0.07 & saddle + 0.2056 & 0.1211 & -0.2367 & -0.4766 & -0.29 & 0.13 & saddle + 0.2219 & 0.1143 & 0.1812 & 0.4773 & -0.08 & -0.20 & maxima + 0.2431 & 0.0943 & -0.6840 & 0.2905 & 0.18 & -1.11 & saddle + 0.2514 & 0.2485 & -0.5579 & 0.3363 & -0.14 & -0.71 & maxima + 0.3827 & 0.6236 & 0.3954 & -0.1678 & -1.58 & 0.32 & saddle + 0.4359 & 0.4336 & 0.6714 & -0.0949 & -0.43 & -1.64 & maxima + 0.5356 & 0.6638 & -0.1123 & -0.2537 & -0.48 & -1.43 & maxima +     -6.3985 & 0.0733 & 0.1345 & 0.3877 & 0.9090 & 20.43 & 4.93 & 11.20 &",
    "minima + -3.5998 & 0.7899 & 0.4554 & 0.2814 & 0.2991 & 8.05 & 10.39 & 12.41 & minima + -3.2777 & 0.6888 & -0.6272 & -0.2914 & -0.2174 & 8.27 & 3.65 & 5.95 & minima + -1.7537 & 0.6329 & -0.2966 & -0.6812 & -0.2180 & -4.25 & 3.00 & 5.56 & saddle + -1.1507 & 0.1935 & 0.5444 & 0.2991 & -0.7594 & 0.73 & 3.54 & 4.20 & minima + -1.0696 & 0.1372 & 0.5068 & 0.0665 & -0.8485 & -1.54 & 3.30 & 3.64 & saddle + -1.0456 & 0.2365 & 0.4798 & -0.7212 & 0.4402 & -1.16 & 1.54 & 2.57 & saddle + -0.7842 & 0.5409 & 0.3388 & 0.4698 & 0.6099 & 16.02 & 8.79 & -12.47 & saddle + -0.7457 & 0.6348 & 0.5354 & -0.4388 & 0.3434 & 2.49 & 0.94 & -1.59 & saddle + -0.2542 & 0.3900 & -0.1333 & 0.4946 & -0.7652 & -2.51 & 2.99 & 0.93 & saddle + -0.2359 & 0.6956 & -0.1369 & 0.3550 & -0.6094 & 6.38 & 2.23 & -1.27 & saddle + 0.0132 & 0.3064 & 0.0541 & 0.3111 & -0.8980 & -5.33 & -2.36 & 2.21 & saddle + 0.1633 & 0.4278 & -0.6578 & -0.2545 & 0.5652 & -2.42 & 3.86 & 2.36 & saddle + 0.3250 & 0.5265 & 0.4653 & 0.0927 & 0.7055 & 7.50 & -12.05 & -3.41 & saddle + 0.5206 & 0.3738 & -0.4806 & -0.6066 & 0.5111 & 3.19 & -2.27 & -1.47 & saddle + 0.5463 & 0.5157 & -0.3055 & -0.3313 & -0.7287 & -9.91 & -3.67 & 1.37 & saddle + 0.5945 & 0.4015 & 0.8447 & 0.1782 & -0.3058 & -3.70 & 4.95 & 1.87 & saddle + 0.6730 & 0.9634 & -0.0009 & 0.2396 & -0.1204 & -5.84 & 7.88 & 1.78 & saddle + 0.8862 & 0.3559 & 0.8571 & -0.1675 & -0.3326 & 3.55 & -2.24 & -2.63 & saddle + 1.2962 & 0.9849 & 0.0018 & -0.1681 & 0.0419 & 2.20 & -5.97 & -3.18 & saddle + 1.4646 & 0.7396 & 0.4441 & 0.4009 & -0.3083 & 8.41 & -2.08 & -7.72 & saddle + 2.9979 & 0.8224 & 0.4083 & -0.0174 & -0.3958 & -4.00 & -5.46 & -6.56 & maxima + 3.5181 & 0.4494 & -0.7574 & 0.4502 & -0.1469 & -9.40 & 1.89 & -2.83 & saddle + 3.6087 & 0.0340 & -0.8989 & -0.0373 & -0.4353 & 0.87 & -8.03 & -5.77 & saddle + 3.7394 & 0.2185 & -0.9142 & 0.2197 & -0.2613 & -8.72 & -0.90 & -3.34 & maxima + 11.3476 & 0.4064 & 0.2313 & 0.8810 & 0.0716 & -7.20 & -18.98 & -21.53 & maxima +            , _ an unconstrained optimization approach for finding real eigenvalues of even order symmetric tensors _ , numerical algebra , control and optimization ( naco ) , 3 ( 2012 ) , pp .",
    "583599 , http://dx.doi.org/10.3934/naco.2013.3.583[doi : ] .",
    ", _ on the best rank-1 approximation of higher - order supersymmetric tensors _ , siam journal on matrix analysis and applications , 23 ( 2002 ) , pp .",
    "863884 , http://dx.doi.org/10.1137/s0895479801387413[doi : ] .      ,",
    "_ singular values and eigenvalues of tensors : a variational approach _ , in camsap05",
    ": proceeding of the ieee international workshop on computational advances in multi - sensor adaptive processing , 2005 , pp .",
    "129132 , http://dx.doi.org/10.1109/camap.2005.1574201[doi : ] .",
    ", _ an always convergent algorithm for the largest eigenvalue of an irreducible nonnegative tensor _ , journal of computational and applied mathematics , 235 ( 2010 ) , pp .",
    "286292 , http://dx.doi.org/10.1016/j.cam.2010.06.002[doi : ] ."
  ],
  "abstract_text": [
    "<S> several tensor eigenpair definitions have been put forth in the past decade , but these can all be unified under generalized tensor eigenpair framework , introduced by chang , pearson , and zhang ( 2009 ) . </S>",
    "<S> given @xmath0th - order , @xmath1-dimensional real - valued symmetric tensors @xmath2 and @xmath3 , the goal is to find @xmath4 and @xmath5 such that @xmath6 . </S>",
    "<S> different choices for @xmath3 yield different versions of the tensor eigenvalue problem . </S>",
    "<S> we present our generalized eigenproblem adaptive power ( geap ) method for solving the problem , which is an extension of the shifted symmetric higher - order power method ( ss - hopm ) for finding z - eigenpairs . </S>",
    "<S> a major drawback of ss - hopm was that its performance depended in choosing an appropriate shift , but our geap method also includes an adaptive method for choosing the shift automatically .    </S>",
    "<S> tensor eigenvalues , e - eigenpairs , z - eigenpairs , @xmath7-eigenpairs , generalized tensor eigenpairs , shifted symmetric higher - order power method ( ss - hopm ) , generalized eigenproblem adaptive power ( geap ) method    15a18 , 15a69    adaptive shifted power method for computing generalized tensor eigenpairs </S>"
  ]
}