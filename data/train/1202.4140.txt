{
  "article_text": [
    "in a control system , a controller interacts with its environment through sensors and actuators .",
    "the controller observes the state of the environment through a set of sensors , computes a control signal that depends on the history of observed sensor readings , and feeds the control signal to the environment through actuators .",
    "the state of the environment is then updated as a function of the control signal as well as a disturbance signal that models external inputs to the environment . in a _ reactive _ setting",
    ", the sense - compute - actuate cycle repeats forever , resulting in an infinite trace of environment states .",
    "the objective of the controller is to ensure that the trace belongs to a given specification of `` good '' traces .",
    "the controller synthesis problem asks , given the dynamical law that specifies how the environment state changes according to the controller inputs and external disturbances , and a specification of good traces , to synthesize a control law that ensures that the environment traces are good , no matter how external disturbances behave .    controller synthesis has been studied extensively for deterministic games with @xmath0-regular specifications  @xcite . in this",
    "setting , the problem is modeled as a game on a graph .",
    "the vertices of the graph represent system states , and are divided into `` controller states '' and `` disturbance states . '' at a controller state , the controller chooses an outgoing edge and moves to a neighboring vertex along this edge . at a disturbance state , the disturbance chooses an outgoing edge and moves along this edge .",
    "this continues ad infinitum , defining a sequence of states .",
    "if this sequence satisfies the specification , the controller wins ; otherwise , the disturbance wins .",
    "the games are called _ perfect observation _ , since both players have exact knowledge of the current state and the history of the game .",
    "the study of perfect - observation deterministic games have been extended to systems with _ partial observation _ , in which the controller can only observe part of the environment s state  @xcite , and to _ stochastic dynamics _",
    "@xcite , in which the state updates happen according to a probabilistic law .",
    "the `` standard model '' of partial - observation stochastic games  @xcite is described as an extension to the above graph model , by fixing an equivalence relation on the vertices ( the `` observation function '' ) , and stipulating that the controller only sees the equivalence class of the current vertex , not the particular vertex the state is in .",
    "in addition , the transitions of the graph are stochastic : the controller and the disturbance each choose some move , and the next vertex is chosen according to a probability distribution based on the current vertex and the chosen move .    in this paper",
    ", we introduce a different , albeit natural , model of probabilistic uncertainty in controller synthesis .",
    "consider a state given by @xmath1 bits .",
    "the sensors used to measure the state are typically not perfect , and observing the state through the sensor results in some bits being flipped with some known probability ( probabilistic noise ) . in applications where the controller observes the state bits through a network , then the probabilistic noise in the communication channels results in bits being flipped with some known probability ( according to the classical shannon s communication channel model ) .",
    "thus , the controller observes @xmath1 bits through the sensor , and this estimate defines a probability distribution over the state space for the current state . in contrast , we allow the disturbance to precisely observe the state , corresponding to a worst case assumption on the disturbance .",
    "the objective of the controller is to find a strategy that ensures that the system satisfies the specification under this probabilistic uncertainty on the current state .",
    "we distinguish between two models of the disturbance . in the first model , the disturbance observes the correct sequence of states as well as both the observation of the controller and the sequence of controller moves . in the second model",
    ", the disturbance observes the correct sequence of states as well as the sequence of controller moves ( but not the observation of the controller ) .",
    "it turns out that the two models give rise to subtle differences in defining the probability measures on the games , as well as different complexities in the solution algorithms .    our model ( which we refer to as games with probabilistic uncertainty )",
    "is inspired by analogous models of state estimation under probabilistic noise in continuous control systems .",
    "we believe this model of games with probabilistic uncertainty naturally captures the behavior of many sensor - based control systems .",
    "intuitively , the standard model of partial - observation games represent `` partial but correct information '' where the controller can observe correctly only the first @xmath2 bits of the state ( i.e. , the observation is partial as the controller observes only a part of the state bits , but the information about the observed state bits is always correct ) . in contrast , our model of games with probabilistic uncertainty represent `` complete but uncertain information '' where the controller can observe all the @xmath1 bits of the state but with uncertainty of observation ( i.e. , the controller can observe all the bits , but each bit is correct with some probability ) . since the type of uncertain information in our model is very different from the standard models of partial - observation games studied in the literature , the relationship between them is not immediate .",
    "our main contribution , along with the introduction of the natural model of games with probabilistic uncertainty , is establishing the equivalence of the new class of games and partial - observation games .",
    "our main technical result is a polynomial - time reduction from this new model of games with probabilistic uncertainty to standard partial - observation games , and a converse reduction from partially - observable markov decision processes ( pomdps ) to games with probabilistic uncertainty .",
    "the results to establish the equivalence of the two classes of games which represent two different notions of information ( partial but correct vs complete but uncertain ) are quite intricate .",
    "for example , for the new class of games the inductive definition of probability measure is subtle and different from the classical definition of probability measure for probabilistic systems  @xcite .",
    "this is because the controller observes a history that can be completely different from the actual history , whereas the environment ( or disturbance ) observes the actual history .",
    "we first inductively define a probability measure of observed history , given the actual history , and use it to define the probability measure inductively .",
    "we show how our polynomial constructions for reduction capture the subtleties in the probability measure , and by establishing precise mapping of strategies ( which is at the heart of the proof of correctness of the reduction ) we obtain the desired equivalence result .    in the positive direction ,",
    "our reduction allows us to solve controller synthesis problems for games with probabilistic uncertainty against @xmath0-regular specifications , using algorithms of  @xcite . in the negative direction , we get lower bounds on the hardness of problems by using known lower bounds for pomdps using the hardness results of  @xcite . in particular , with our reductions",
    "we establish precisely the decidability frontier of games with probabilistic uncertainty for various classes of parity objectives ( a canonical form to express @xmath0-regular specifications ) ; and for most of the decidable problems we establish exptime - complete bounds , and in some cases 2exptime upper bounds and exptime lower bounds ( see table  [ tab : complexity ] ) .",
    "moreover , our reduction allows the rich body of algorithms ( such as symbolic and anti - chain based algorithms  @xcite ) for partial - observation games , along with any future algorithmic developments for partial - observation games , to be applicable to solve games with probabilistic uncertainty . in summary ,",
    "our results provide precise decidability frontier , optimal complexity ( in most cases ) , and algorithmic solutions for games with probabilistic uncertainty , that is a natural model for control problems with state estimation under probabilistic noise .",
    "in this section we introduce a class of games with probabilistic imperfect information , and call them games with probabilistic uncertainty .    _ probability distribution . _",
    "a _ probability distribution _ on a finite set @xmath3 is a function @xmath4 $ ] such that @xmath5 .",
    "we denote by @xmath6 the set of probability distributions on @xmath3 .    _ game structures with probabilistic uncertainty . _ a game structure with probabilistic uncertainty consists of a tuple @xmath7 , where ( a )  @xmath8 is a set of _ locations _ ; ( b )  @xmath9 and @xmath10 are two sets of input and output alphabets , respectively ; ( c )  @xmath11 is a probabilistic transition function that given a location , an input and an output letter gives the probability distribution over the next locations ; and ( d )  @xmath12 is the _ probabilistic uncertainty function _ that given the true current location describes the probability distribution of the observed location .",
    "if @xmath13 is the identity function we obtain perfect - observation games .",
    "intuitively , a game proceeds as follows .",
    "the game starts at some location @xmath14 .",
    "player  1 observes a state drawn from the distribution @xmath15 , which represents a potentially faulty observation process .",
    "intuitively , at every step the player can observe the value of all variables that corresponds to the state of the game , but there is a probability that the observed value of some variables is incorrect .",
    "player  2 observes the `` correct '' state @xmath16 .",
    "given the observation of the history of the game so far , player  1 picks an input alphabet @xmath17 .",
    "player  2 then picks an output letter @xmath18 : we consider two variants , ( 1 )  player  2 only observes the history of correct locations and the moves of the players ; and ( 2 )  player  2 observes the history of correct locations , the moves of the players , and also observes the history of observed locations of player  1 .",
    "the state of the game is updated to @xmath19 with probability @xmath20 .",
    "this process is repeated ad infinitum .",
    "_ a _ play _ of @xmath21 is a sequence @xmath22 of locations , input letter , and output letter , such that for all @xmath23 we have @xmath24 .",
    "the _ prefix up to @xmath25 _ of the play  @xmath26 is denoted by @xmath27 , its _ length _ is @xmath28 and its _ last element _ is @xmath29 .",
    "the set of plays in @xmath21 is denoted by @xmath30 , and the set of corresponding finite prefixes is denoted @xmath31 .",
    "_ strategies .",
    "_ a strategy for player  1 observes the finite prefix of a play and then selects an input letter ( pure strategies ) or a probability distribution over input letters in @xmath32 .",
    "formally , a pure strategy for player  1 is a function @xmath33 , and a randomized strategy for player  1 is a function @xmath34 .",
    "similarly , pure and randomized strategies for player  2 are defined as functions @xmath35 and @xmath36 , respectively .",
    "note that player  2 sees player  1 s choice of input action at each step . in the case where player  2 observes also",
    "the history of observed locations , the pure and randomized strategies are defined as functions @xmath37 and @xmath38 , respectively , where the output letter is chosen based on the original history and observed history .",
    "we refer to strategies that observes both histories as `` all - powerful '' strategies for player  2 .",
    "_ outcomes . _",
    "the _ outcome _ of two randomized strategies @xmath39 for player  1 and @xmath40 for player  2 from a location @xmath14 is the set of plays @xmath41 such that ( 1 ) @xmath42 , ( 2 ) there exists a sequence @xmath43 such that @xmath44 for each @xmath45 , ( 3 ) for each @xmath23 , we have @xmath46 and @xmath47 ( if @xmath40 is an all - powerful strategy , then @xmath48 ) , and @xmath49 . the primed sequence @xmath50 gives the sequence of observations made by player  1 using the probabilistic uncertainty function .",
    "note that this sequence may be incorrect with some probability due to probabilistic uncertainty in the observation .",
    "we denote this set of plays as @xmath51 . the outcome of two pure strategies is defined analogously , considering pure strategies as degenerate randomized strategies which pick a letter with probability one .",
    "outcome set _ of the pure ( resp .",
    "randomized ) strategy @xmath39 for player  @xmath52 in @xmath21 is the set @xmath53 of plays @xmath26 such that there exists a pure ( resp .",
    "randomized ) strategy @xmath40 for player  @xmath54 with @xmath55 .",
    "the outcome set @xmath56 for player  2 is defined symmetrically .",
    "_ probability measure .",
    "_ given strategies @xmath39 and @xmath40 , we define the probability measure @xmath57 .",
    "the definition of the probability measure is subtle and non - standard as the prefix that player  1 observes can be completely different from the original history . for a finite prefix @xmath58 ,",
    "let @xmath59 denote the set of plays with @xmath26 as prefix .",
    "we will define @xmath57 for cones , and then by caratheodory extension theorem  @xcite there is a unique extension to all measurable sets of paths . to define",
    "the probability measure we also need to define a function @xmath60 , that given a finite prefix @xmath26 , gives the probability distribution over finite prefixes @xmath61 , such that @xmath62 denotes the probability of observing @xmath61 given the correct prefix is @xmath26 .",
    "the base case is as follows : @xmath63 the inductive definition of @xmath64 is as follows : for a prefix @xmath26 of length @xmath65 @xmath66 given a sequence @xmath67 , we define @xmath68 the sequences of same length as @xmath26 such that the sequence of input and output letter matches ( i.e. , the set of action - matching prefixes ) . note that for non action - matching prefixes the observation sequence function always assigns probability zero .",
    "the inductive case for the probability measure is as follows : for a prefix @xmath26 of length @xmath65 with last state @xmath25 , we have @xmath69 i.e. , @xmath62 gives the probability to observe @xmath61 , then @xmath70 denotes the probability to play @xmath71 given the strategy and observed sequence @xmath61 , and since player  2 observes the correct sequence the probability to play @xmath72 is given by @xmath73 ( player  2 observes @xmath26 ) , and the final term @xmath74 gives the transition probability .",
    "if @xmath40 is an all - powerful strategy , then @xmath40 observes both the correct history @xmath26 and the observed history @xmath61 , and then the definition is as follows : @xmath75    _ winning objectives .",
    "_ an _ objective _ for player  @xmath52 in @xmath21 is a set @xmath76 of plays .",
    "a play @xmath77 _ satisfies _ the objective @xmath78 , denoted @xmath79 , if @xmath80 .",
    "we consider @xmath0-regular objectives specified as parity objectives ( a canonical form to express all @xmath0-regular objectives  @xcite ) . for a play @xmath41 ,",
    "we denote by @xmath81 the @xmath82-th location @xmath83 of the play and denote by @xmath84 the set of locations that occur infinitely often in @xmath26 , that is , @xmath85 .",
    "we consider the following classes of objectives .    1",
    ".   _ reachability and safety objectives . _ given a set @xmath86 of target locations , the _ reachability _ objective @xmath87 requires that a location in @xmath88 be visited at least once , that is , @xmath89 .",
    "dually , the _ safety _ objective @xmath90 requires that only states in @xmath88 be visited .",
    "formally , @xmath91 .",
    "bchi and cobchi objectives .",
    "_ let @xmath86 be a set of target locations .",
    "the _ bchi _",
    "objective @xmath92 requires that a state in @xmath88 be visited infinitely often , that is , @xmath93 .",
    "dually , the _ cobchi _ objective @xmath94 requires that only states in @xmath88 be visited infinitely often .",
    "formally , @xmath95 .",
    "parity objectives .",
    "_ for @xmath96 , let @xmath97 be a _ priority function _ , which maps each state to a nonnegative integer priority .",
    "the _ parity _",
    "objective @xmath98 requires that the minimum priority that occurs infinitely often be even .",
    "formally , @xmath99 .",
    "the bchi and cobchi objectives are the special cases of parity objectives with two priorities , @xmath100 and @xmath101 , respectively .    _ sure , almost - sure and positive winning .",
    "_ an _ event _ is a measurable set of plays , and given strategies @xmath39 and @xmath40 for the two players , the probabilities of events are uniquely defined .",
    "for an objective  @xmath78 , assumed to be borel , we denote by @xmath102 the probability that @xmath78 is satisfied by the play obtained from the starting location @xmath16 when the strategies @xmath39 and @xmath40 are used . given a game @xmath21 , an objective @xmath78 , and a location @xmath16",
    ", we consider the following winning modes : ( 1 )  a strategy @xmath39 for player  1 is _ sure winning _ for the objective @xmath78 from @xmath14 if @xmath103 for all strategies @xmath40 for player  @xmath54 ; ( 2 )  a strategy @xmath39 for player  @xmath52 is _ almost - sure winning _ for the objective @xmath78 from @xmath14 if @xmath104 for all strategies @xmath40 for player  @xmath54 ; and ( 3 )  a strategy @xmath39 for player  @xmath52 is _ positive winning _ for the objective @xmath78 from @xmath14 if @xmath105 for all strategies @xmath40 for player  @xmath54",
    ".    qualitative analysis of a game consists of the computation of the sure , almost - sure and positive winning sets .",
    "the sure ( resp . almost - sure and positive ) winning decision problem for an objective consists of a game and a starting location @xmath16 , and asks whether there is a sure ( resp .",
    "almost - sure and positive ) winning strategy from @xmath16 .",
    "we now recall the usual definition of partial - observation games and their subclasses .",
    "we focus on partial - observation turn - based probabilistic games , where at each round one of the players is in charge of choosing the next action and the transition function is probabilistic",
    ". we will present a polynomial time reduction of games with probabilistic uncertainty to these games .",
    "* partial - observation games . *",
    "a _ partial - observation stochastic game _",
    "( for short partial - observation game or simply a _ game _ ) is a tuple @xmath106 with the following components :    1 .   _",
    "( state space ) .",
    "_ @xmath107 is a finite set of states , where @xmath108 ( i.e. , @xmath109 and @xmath110 are disjoint ) , states in @xmath109 are player  1 states , and states in @xmath110 are player  2 states .",
    "2 .   _ ( actions ) . _",
    "@xmath111 ( @xmath112 ) is a finite set of actions for player  @xmath113 .",
    "( transition function ) .",
    "_ for @xmath114 , the probabilistic transition function for player  @xmath113 is the function @xmath115 that maps a state @xmath116 and an action  @xmath117 to the probability distribution @xmath118 over the successor states in @xmath119 ( i.e. , games are alternating ) .",
    "( observations ) .",
    "_ @xmath120 is a finite set of observations for player  @xmath52 that partitions the state space  @xmath121 , and similarly @xmath122 is the observations for player  2 .",
    "these partitions uniquely define functions @xmath123 , for @xmath124 , that map each state to its observation such that @xmath125 for all @xmath126 .",
    "we will also consider the special case of one - sided games , where player  2 is perfectly informed ( has complete observation ) , i.e. , @xmath127 , and @xmath128 for all @xmath129 ( i.e. , the partition consists of singleton states ) .",
    "* special class : pomdps .",
    "* we will consider one special class of partial - observation games called _ partial - observable markov decision processes _",
    "( pomdps ) , where the action set for player  2 is a singleton ( i.e. , there is effectively only player  1 and stochastic transitions ) .",
    "hence we will omit the action set and observation for player  2 and represent a pomdp as the following tuple @xmath130 , where @xmath131 .",
    "_ in a game , in each turn , for @xmath124 , if the current state @xmath132 is in @xmath133 , then player  @xmath113 chooses an action @xmath134 , and the successor state is chosen by sampling the probability distribution @xmath135 .",
    "a _ play _ in @xmath136 is an infinite sequence of states and actions @xmath137 such that for all @xmath45 , if @xmath138 , for @xmath114 , then @xmath139 such that @xmath140 .",
    "the definitions of prefix and length are analogous to the definitions in section  [ sec : probimperfect ] . for @xmath124 , we denote by @xmath141 the set of finite prefixes in @xmath136 that end in a state in @xmath133 .",
    "observation sequence _ of @xmath142 for player  @xmath113 ( @xmath112 ) is the unique infinite sequence of observations and actions , i.e. , @xmath143 such that @xmath144 for all @xmath45 .",
    "the observation sequence for finite sequences ( prefix of plays ) is defined analogously .",
    "_ strategies .",
    "_ a _ pure strategy _ in @xmath136 for player  @xmath52 is a function @xmath145 .",
    "a _ randomized strategy _ in @xmath136 for player  @xmath52 is a function @xmath146 .",
    "a ( pure or randomized ) strategy @xmath39 for player  @xmath52 is _ observation - based _ if for all prefixes @xmath147 , if @xmath148 , then @xmath149 . we omit analogous definitions of strategies for player  @xmath54 .",
    "we denote by @xmath150 , @xmath151 , @xmath152 , @xmath153 , @xmath154 , @xmath155 the set of all player-@xmath52 strategies in  @xmath136 , the set of all observation - based player-@xmath52 strategies , the set of all pure player-@xmath52 strategies , the set of all player-@xmath54 strategies in  @xmath136 , the set of all observation - based player-@xmath54 strategies , and the set of all pure player-@xmath54 strategies , respectively . in the setting",
    "where player  @xmath52 has partial - observation and player  @xmath54 has complete observation , the set @xmath153 of all strategies coincides with the set @xmath154 of all observation - based strategies .",
    "we will require the players to play observation - based strategies .",
    "_ outcomes . _",
    "the _ outcome _ of two randomized strategies @xmath39 ( for player  @xmath52 ) and @xmath40 ( for player  @xmath54 ) from a state @xmath132 in @xmath136 is the set of plays @xmath156 , with @xmath157 , where for all @xmath45 , if @xmath158 ( resp .",
    "@xmath159 ) , then @xmath160 ( resp .",
    "@xmath161 ) and @xmath162 ( resp .",
    "@xmath163 ) .",
    "this set is denoted @xmath164 .",
    "the outcome of two pure strategies is defined analogously by viewing pure strategies as randomized strategies that play their chosen action with probability one .",
    "outcome set _ of the pure ( resp .",
    "randomized ) strategy @xmath39 for player  @xmath52 in @xmath136 is the set @xmath165 of plays @xmath26 such that there exists a pure ( resp .",
    "randomized ) strategy @xmath40 for player  @xmath54 with @xmath166 .",
    "the outcome set @xmath167 for player  2 is defined symmetrically .",
    "_ probability measure .",
    "_ we define the probability measure @xmath168 as follows : for a finite prefix @xmath26 , let @xmath59 denote the set of plays with @xmath26 as prefix .",
    "then we have @xmath169 , and for a prefix of length @xmath1 ending in a player  1 state @xmath170 we have @xmath171 and the definition when @xmath170 is a player  2 state is similar . for a set @xmath172 of finite prefixes , we write @xmath173 for @xmath174 .    the winning modes",
    "sure , almost - sure , and positive are defined analogously to section  [ sec : probimperfect ] , where we restrict the players to play an observation - based strategy . from the results of  @xcite we obtain the following theorem summarizing the results for partial - observation games and pomdps .",
    "[ thrm1 ] the following assertions hold :    1 .   _",
    "( one - sided games and pomdps ) . _ the sure , almost - sure and positive winning for safety objectives ; the sure and almost - sure winning for reachability objectives and bchi objectives ; the sure and positive winning for cobchi objectives ; and the sure winning for parity objectives are exptime - complete for one - sided partial - observation games ( player  2 perfectly informed ) and pomdps .",
    "the positive winning problem for reachability objectives is ptime - complete both for one - sided partial - observation games and pomdps .",
    "( general partial - observation games ) . _ the sure , almost - sure winning for safety objectives , the sure winning for parity objectives are exptime - complete for partial - observation games ; the almost - sure winning for reachability objectives and bchi objectives , and the positive winning for safety and cobchi objectives are 2exptime - complete for partial - observation games .",
    "the positive winning problem for reachability objectives is exptime - complete .",
    "( undecidability results ) . _ the positive winning problem for bchi objectives , the almost - sure winning problem for cobchi objectives , and the positive and almost - sure winning problems for parity objectives are undecidable for pomdps .",
    "we now present a reduction of games with probabilistic uncertainty to classical partial - observation games .",
    "let @xmath175 be a game with probabilistic uncertainty and we construct a partial - observation game @xmath176 as follows ( below as @xmath177 and @xmath178 would be clear from context , we simply use @xmath179 for simplicity ) :    1 .",
    "the transition function @xmath177 is deterministic and for @xmath180 and @xmath181 we have @xmath182 2 .",
    "the transition function @xmath178 captures both @xmath183 and @xmath13 and is defined as follows : for @xmath184 and @xmath185 we have @xmath186 intuitively , the first component of the game @xmath187 keeps track of the real state of the game @xmath136 , and the second component keeps track of the information available from probabilistic uncertainty . hence player  1 is only allowed to observe the second component which is the probability distribution over the observable state given the current state .",
    "the observation mapping is as follows : we have @xmath188 ; and @xmath189 , i.e. , only the second component is observable .",
    "we will consider two cases for @xmath122 : for the reduction of all - powerful strategies we will consider player  2 has complete - observation , and in the other case we have @xmath190 and player  2 observes the first component that represents the correct history : i.e. , @xmath191 .",
    "4 .   for a parity objective in @xmath136 given by priority function @xmath192",
    ", we consider the priority function @xmath193 in @xmath187 as follows : @xmath194 , for all @xmath195 and @xmath181 .",
    "* correspondence of strategies .",
    "* we will now establish the correspondence of probabilistic uncertain strategies in @xmath136 and the observation based strategies in @xmath187 .",
    "we present a few notations .",
    "for simplicity of presentation , we will use a slight abuse of notation : given a history ( or finite prefix ) @xmath196 in @xmath187 we will represent the history as @xmath197 as the intermediate state is always uniquely defined by the state and the action . intuitively this is removing the stuttering and does not affect parity objectives .",
    "_ mapping of strategies from @xmath136 to @xmath187 . _ given a history @xmath198 in @xmath187 , such that @xmath199 , we consider two histories in @xmath136 as follows : @xmath200 intuitively , @xmath201 gives the first component ( which is the correct history ) and @xmath202 gives the second component ( which is the observed history ) .",
    "we now define the mapping of strategies from @xmath136 to @xmath187 : given strategy @xmath203 for player  1 , a strategy @xmath204 for player  2 , and an all - powerful strategy @xmath205 for player  2 , in the game @xmath136 , we define the corresponding strategies in @xmath187 as follows : for a history @xmath206 and an action @xmath207 for player  1 we have @xmath208 { \\beta}_h(\\rho_h \\ a_i ) & = & { \\beta}_g(g_1(\\rho_h ) \\",
    "a_i ) ; \\\\[2ex ] { \\beta}_h^c(\\rho_h\\ a_i ) & = & { \\beta}_g^a(g_1(\\rho_h ) , g_2(\\rho_h),a_i ) .",
    "\\end{array}\\ ] ] note that @xmath209 and @xmath210 are observation - based strategies , and @xmath211 is a strategy with complete - observation , i.e. , all - powerful strategies are mapped to complete - observation strategies .",
    "hence for all - powerful strategies the reduction is to one - sided games .",
    "we will use @xmath212 to denote the mapping of strategies , i.e. , @xmath213 , @xmath214 , and @xmath215 .",
    "_ mapping of strategies from @xmath187 to @xmath136 .",
    "_ we now present the mapping in the other direction . let @xmath216 , and @xmath217 be two prefixes in @xmath136",
    ". intuitively , the first represent the correct history and the second the observed history",
    ". then we consider the following set of histories in @xmath187 : @xmath218 and @xmath219 we now define the mapping of strategies . given an observation - based strategy @xmath220 for player  1 , observation - based strategy @xmath221 for player  2 , and complete observation - based strategy @xmath222 , we define the following strategies in @xmath136 : for a correct history @xmath223 , observed history @xmath224 , and input @xmath225 we have @xmath226 { \\alpha}_g(\\rho_g^2 ) & = & { \\alpha}_h(\\rho_h ) ; \\qquad",
    "\\rho_h\\in h_2(\\rho_g^2 ) ; \\\\[2ex ] { \\beta}_g^a(\\rho_g^1,\\rho_g^2,\\sigma^i ) & = & { \\beta}_h^c(h_{12}(\\rho_g^1,\\rho_g^2),\\sigma_i ) . \\end{array}\\ ] ] note that since @xmath210 is observation - based it plays the same for all @xmath227 , and similarly , since @xmath209 is observation - based it plays the same for all @xmath228 . also observe that the strategy @xmath205 is an all - powerful strategy .",
    "we will use @xmath229 to denote the mapping of strategies , i.e. , @xmath230 , @xmath231 , and @xmath232 .    given a starting state @xmath233 , consider the following probability distribution @xmath234 in @xmath187 : @xmath235 .",
    "given the mapping of strategies , our goal is to establish the equivalences of the probability measure .",
    "we introduce some notations required to establish the equivalence . for @xmath23 , we denote by @xmath236 the pair of random variables to denote the @xmath237-th player  1 state of the game @xmath187 , and by @xmath238 and @xmath239 the random variables for the actions following the @xmath237-th state .",
    "our first lemma establishes a connection of the probability of observing the second component in @xmath187 given the first component along with function @xmath64 .",
    "we introduce notations to define two events : given two prefixes @xmath216 , and @xmath217 in @xmath136 , let @xmath240 denote the event that for all @xmath241 we have @xmath242 and for all @xmath243 we have @xmath244 ; and @xmath245 denote the event that for all @xmath241 we have @xmath246 and for all @xmath243 we have @xmath244 .",
    "[ lemm - proof1 ] let @xmath216 , and @xmath217 be two prefixes in @xmath136 .",
    "then for all strategies @xmath209 and @xmath210 , the probability that the second component sequence in @xmath187 is @xmath224 , given the first component sequence is @xmath223 is @xmath247 , i.e. , formally @xmath248    the proof is by induction on the length of the prefixes .",
    "the base case is as follows : let the length of prefixes @xmath223 and @xmath224 be 1 , with @xmath249 and @xmath250 .",
    "then we have @xmath251 as required .",
    "we now consider the inductive case : we consider prefixes @xmath252 and @xmath253 .",
    "let us consider the events @xmath254 and @xmath255 .",
    "let @xmath256 denote the event that @xmath257 , @xmath258 , @xmath259 , and @xmath260 ; and @xmath261 denote the event that @xmath257 , @xmath262 , and @xmath260 .",
    "then by definition we have @xmath263    & & \\quad \\qquad \\text{(in the numerator all choices are fixed , and } \\\\[2ex ]    & & \\quad \\qquad \\text{in denominator are all possible choices   of the second component ) } \\\\[3.5ex ] & = &   \\displaystyle \\frac { \\delta(\\ell_n^1 , \\sigma_n^i,\\sigma_n^o)(\\ell_{n+1}^1 ) \\cdot { \\mathsf{un}}(\\ell_{n+1}^1)(\\ell_{n+1}^2 ) } { \\delta(\\ell_n^1 , \\sigma_n^i,\\sigma_n^o)(\\ell_{n+1}^1 ) \\cdot   \\sum_{{\\widetilde}{\\ell}_{n+1}^2 }   { \\mathsf{un}}(\\ell_{n+1}^1)({\\widetilde}{\\ell}_{n+1}^2 ) } \\\\[3.5ex ] & = &   { \\mathsf{un}}(\\ell_{n+1}^1)(\\ell_{n+1}^2 )    \\qquad \\quad \\text{(since $ \\sum_{{\\widetilde}{\\ell}_{n+1}^2 } { \\mathsf{un}}(\\ell_{n+1}^1)({\\widetilde}{\\ell}_{n+1}^2)=1 $ ) } \\end{array}\\ ] ] note that the crucial fact used in the above proof is in the second equality and the fact is that for all @xmath264 we have @xmath265 ( i.e. , it is independent of @xmath264 ) . hence using the above equality and inductive hypothesis we have : @xmath266 & = &   { \\mathsf{obsseq}}(\\rho_g^1)(\\rho_g^2 ) \\cdot   { \\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\overline}{{\\mathcal{e}}}_{n+1}^1 \\mid { \\overline}{{\\mathcal{e}}}_{n+1}^2 ) \\qquad\\text{(by inductive hypothesis ) } \\\\[2ex ] & = &   { \\mathsf{obsseq}}(\\rho_g^1)(\\rho_g^2 ) \\cdot   { \\mathsf{un}}(\\ell_{n+1}^1)(\\ell_{n+1}^2 ) \\qquad \\text{(by previous equality ) } \\\\[2ex ]   & = & { \\mathsf{obsseq}}(\\rho_g^1 \\sigma_n^i \\sigma_n^o \\ell_{n+1}^1)(\\rho_g^2 \\sigma_n^i \\sigma_n^o \\ell_{n+1}^2 )   \\end{array}\\ ] ] the desired result follows .",
    "we will now establish the equivalences of the probabilities of the cones .",
    "[ lemm - proof2 ] for all finite prefixes @xmath223 in @xmath136 ,",
    "the following assertions hold :    1 .   for all strategies @xmath203 , @xmath204 , @xmath205 ( all - powerful )",
    ", we have @xmath267 2 .   for all strategies @xmath209 , @xmath210 , @xmath211 ( complete - observation ) , we have @xmath268    we will present the result for the first item , and the proof for second item is identical . let us denote by @xmath213 and @xmath214 .",
    "we will prove the result by induction on the length of the prefixes .",
    "the base case is as follows : let the length of the prefix @xmath223 be 1 , with @xmath249 .",
    "we observe that @xmath269 , and @xmath270 , and for all other cones of length @xmath52 the probability is zero .",
    "this completes the base case .",
    "we now consider the inductive case : by inductive hypothesis we assume that @xmath271 ; and show that @xmath272 let @xmath25 be the last state of @xmath223 .",
    "we first consider the left - hand side ( lhs ) : @xmath273 & = &   \\displaystyle{\\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\mathsf{cone}}(h_1(\\rho_g^1 ) ) ) \\cdot \\bigg ( \\sum_{\\rho'\\in { \\mathsf{actmt}}(\\rho_g^1 ) }   { \\mathsf{obsseq}}(\\rho^{1}_{g})(\\rho ' )   \\cdot { \\alpha}_{g}(\\rho')(a_{n } ) \\cdot { \\beta}_{g}(\\rho^{1}_{g } a_{n } ) ( b_{n } ) \\cdot \\delta(\\ell_{n } , a_{n } , b_{n})(\\ell_{n+1})\\bigg ) \\\\[3ex ] & = &   \\displaystyle \\sum_{\\rho'\\in { \\mathsf{actmt}}(\\rho_g^1 ) } { \\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\mathsf{cone}}(h_{12}(\\rho_g^1,\\rho ' ) ) )   \\cdot { \\alpha}_{g}(\\rho')(a_{n } ) \\cdot { \\beta}_{g}(\\rho^{1}_{g } a_{n } ) ( b_{n } ) \\cdot \\delta(\\ell_{n } , a_{n } , b_{n})(\\ell_{n+1 } ) \\end{array}\\ ] ] above the first equality is by definition , the second equality by inductive hypothesis , and the last equality is obtained from lemma  [ lemm - proof1 ] as follows : by lemma  [ lemm - proof1 ] we have @xmath274 , and hence @xmath275 & = &     \\displaystyle \\sum_{\\rho'\\in { \\mathsf{actmt}}(\\rho_g^1 ) } { \\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\mathsf{cone}}(h_1(\\rho_g^1 ) ) ) \\cdot    { \\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\mathcal{e}}_{1,2}(\\rho_g^1,\\rho ' ) \\mid { \\mathcal{e}}_1(\\rho_g^1 ) ) \\\\[3ex ] & = &   \\displaystyle \\sum_{\\rho'\\in { \\mathsf{actmt}}(\\rho_g^1 ) } { \\mathrm{pr}}^{{\\alpha}_h,{\\beta}_h}_{\\mu}({\\mathsf{cone}}(h_{12}(\\rho_g^1,\\rho ' ) ) ) .",
    "\\end{array}\\ ] ]    we now consider the right - hand side ( rhs ) @xmath276 and the rhs can be expanded as : ( below for brevity we write @xmath277 ) @xmath278 since we have @xmath279 the above expression for rhs is equivalently described as : @xmath280 since @xmath281 , it follows that lhs is equal to the rhs .",
    "the result for correspondence for all - powerful strategy @xmath205 is essentially copy - paste of the above proof replacing appropriately @xmath204 by @xmath205 .",
    "this completes the proof and the desired result follows .",
    "it follows that there is a sure , almost - sure , positive winning strategy in @xmath136 for @xmath282 iff there is a corresponding one in @xmath187 for @xmath283 and hence from theorem  [ thrm1 ] we obtain the following result .",
    "[ lemm1 ] the following assertions hold :    1 .   _",
    "( all - powerful player  2 ) . _ the sure , almost - sure and positive winning for safety objectives ; the sure and almost - sure winning for reachability objectives and bchi objectives ; the sure and positive winning for cobchi objectives ; and the sure winning for parity objectives can be solved in exptime for games with probabilistic uncertainty with all - powerful strategies for player  2 .",
    "the positive winning for reachability objectives can be solved in ptime .",
    "( not all - powerful player  2 ) .",
    "_ the sure , almost - sure winning for safety objectives ; and the sure winning for parity objectives can be solved in exptime ; the almost - sure winning for reachability objectives and bchi objectives ; the positive winning for safety and cobchi objectives can be solved in 2exptime for games with probabilistic uncertainty without all - powerful strategies for player  2 .",
    "the positive winning for reachability objectives can be solved in exptime .",
    "in this section we present a reduction in the reverse direction and show that pomdps with parity objectives can be reduced to games with probabilistic uncertainty and parity objectives .",
    "we first present the reduction and then show the correctness of the reduction by mapping prefixes , strategies , and establishing the equivalence of the probability measure .",
    "* reduction : pomdps to games with probabilistic uncertainty .",
    "* let @xmath284 be a pomdp with a parity objective @xmath78 , we construct the game of probabilistic uncertainty @xmath285 as follows :    * @xmath286 ; * @xmath287 ; * @xmath288 ; * for @xmath289 and @xmath290",
    "let @xmath291 , i.e. , the transition function is same as the transition function of the pomdp . in other words ,",
    "the state space is the same , the action choices of the pomdp corresponds to the input action choice , and the output action set is singleton , and the transition function mimics the transition function of the pomdp .",
    "below we use the probabilistic uncertainty to capture the partial - observation of the pomdp . *",
    "the uncertainty function is as follows : @xmath292    the parity objective is the same as the original parity objective .    *",
    "mapping of prefixes .",
    "* given a prefix ( or a finite history ) @xmath293 in @xmath187 we construct a prefix in @xmath136 as @xmath294 by simply inserting the @xmath295 actions .",
    "this construction defines a bijection @xmath296 between prefixes .",
    "we can naturally extend the mapping to sets of prefixes .",
    "let @xmath297 , then @xmath298    [ lem : prefix ] for prefixes @xmath299 in @xmath136 the following assertion holds :    @xmath300 0 & \\qquad \\text{otherwise } \\\\",
    "\\end{array } \\right .",
    "$ ]    we prove the result by induction on the length of prefixes .",
    "we will only consider @xmath26 and @xmath61 that have the same length , as otherwise by definition the observation sequence probability is  0 .",
    "we first consider the base case .",
    "_ base case .",
    "_ let @xmath301 be the initial state .",
    "then @xmath302 and let @xmath303 for some @xmath289 .",
    "then : @xmath304 if @xmath301 and @xmath16 have the same observation and @xmath305 otherwise .",
    "this proves the base case .",
    "_ inductive step .",
    "_ we now consider prefixes of length @xmath65 , and by inductive hypothesis the result holds for prefixes of length @xmath1 . then @xmath306 we now consider two cases to complete the proof .    * if @xmath307 , then either @xmath308 or @xmath309 .",
    "it follows that one of the factors ( @xmath62 or @xmath310 ) ) is equal to @xmath305 and hence : @xmath311 * otherwise , we have @xmath312 .",
    "then : @xmath313    the desired result follows .",
    "* mapping of strategies .",
    "* we first present the mapping of strategies from @xmath187 to @xmath136 and then from @xmath136 to @xmath187 .",
    "note that in the game @xmath136 , there is no choice for player  2 , and hence we remove the player  2 strategies in the descriptions below .    _ mapping strategies from @xmath187 to @xmath136 .",
    "_ let @xmath314 be an observation - based player-1 strategy in @xmath187 and @xmath315 be a prefix in @xmath136 .",
    "we define a player-1 strategy @xmath316 in @xmath136 as follows : @xmath317 .    _ mapping strategies from @xmath136 to @xmath187 .",
    "_ let @xmath318 be a player-1 strategy in @xmath136 and @xmath319 be a prefix in @xmath187 with @xmath320 as its observation sequence .",
    "note that as player  2 has only one strategy ( always playing @xmath295 ) we omit it from discussion .",
    "note that every @xmath321 can have different actions with different probabilities enabled .",
    "we define a player-1 strategy @xmath322 in @xmath187 as follows : for an action @xmath323 we have @xmath324 we now show that the strategy @xmath209 is an observation - based strategy for player  1 in the pomdp .    the strategy @xmath209 obtained from strategy @xmath203 is an observation - based strategy for player  1 in @xmath187 .",
    "let @xmath206 and @xmath325 be two prefixes in @xmath187 that match in observation sequence and we need to argue that @xmath209 plays the same for both prefixes @xmath206 and @xmath325 .",
    "observe that since @xmath206 and @xmath325 has the same observation sequence , we have @xmath326 .",
    "moreover it follows from lemma  [ lem : prefix ] that @xmath327 only depends on the observation sequence of @xmath206 and hence for all @xmath328 we have @xmath329 .",
    "it follows that for all actions @xmath323 we have @xmath330 .",
    "it follows that @xmath209 is observation based .",
    "* correspondence of probabilities . * in the following two lemmas we establish the correspondence of the probabilities for the mappings .",
    "[ lem : htog ] let us consider the mapping of strategies from @xmath331 to @xmath332",
    ". for all prefixes @xmath333 in @xmath187 we have @xmath334    the proof is based on induction on the length of the prefix @xmath333 .",
    "we denote the last state of @xmath333 by @xmath335 .    _ base case . _ for prefixes of length 1 where @xmath336 we get @xmath337 and @xmath338 . for all other prefixes",
    "both sides are equal to @xmath305 .",
    "hence the base case follows .",
    "_ inductive step .",
    "_ by inductive hypothesis we assume the result for prefixes @xmath206 of length @xmath1 ( i.e. , we assume that @xmath339 ) and will show that @xmath340 first we expand the left hand side ( lhs ) and by definition we get that : @xmath341 we now expand the right hand side ( rhs ) and get that : @xmath342 using the inductive hypothesis , the definition of the game , and the mapping of strategies we get on the rhs : @xmath343 for all @xmath61 that do not match the observation sequence of @xmath344 , we have @xmath345 ( by lemma  [ lem : prefix ] ) , and as @xmath322 is observation based for all @xmath346 that matches the observation sequence of @xmath344 , the strategy @xmath209 plays the same .",
    "let us denote by @xmath347 that @xmath61 matches the observation sequence of @xmath344 .",
    "then we have @xmath348 & = & \\displaystyle \\sum_{\\rho ' \\in { \\mathsf{actmt}}(h(\\rho_h ) ) , \\rho ' \\approx h(\\rho_h ) } { \\mathsf{obsseq}}(h(\\rho_{h}))(\\rho ' )   \\cdot { \\alpha}_{h}(\\rho_h)(a_n ) \\\\[4ex ] & = & { \\alpha}_{h}(\\rho_h)(a_n ) ;   \\end{array}\\ ] ] where the first equality follows as for all sequences @xmath61 that do not match the observation sequence of @xmath344 we have @xmath345 ; the second equality follows as for all @xmath347 we have @xmath349 ( as @xmath209 is observation based ) ; and the last equality follows because as @xmath64 is a probability distribution we have @xmath350 .",
    "hence we have @xmath351 thus we have that lhs and rhs coincide and this completes the proof .",
    "let us consider the mapping of strategies from @xmath352 to @xmath353 .",
    "for all prefixes @xmath354 in @xmath136 we have @xmath355    the inductive proof is as follows and we will denote the last state of @xmath356 as @xmath25 .",
    "the base case is similar to the base case of lemma  [ lem : htog ] .",
    "we now present the inductive case .",
    "_ inductive step .",
    "_ by inductive hypothesis we assume the result for prefixes @xmath356 of length @xmath1 ( i.e. , we assume that @xmath357 ) and will show that @xmath358 first we expand the right hand side ( rhs ) and by definition we get that : @xmath359 as @xmath360 does not depend on @xmath61 we get : @xmath361 we will now show that the expansion of the left hand side ( lhs ) also gives the same expression .",
    "let @xmath362 .",
    "by expanding the lhs we get : @xmath363 & = &   { \\mathrm{pr}}^{{\\alpha}_h}_{\\mu}({\\mathsf{cone}}(\\rho_h ) ) \\cdot { \\alpha}_{h}(\\rho_h)(a_{n } ) \\cdot \\delta(\\ell_{n},a_{n})(\\ell_{n+1 } ) \\\\[2ex ] & = &   { \\mathrm{pr}}^{{\\alpha}_h}_{\\mu}({\\mathsf{cone}}(\\rho_h ) ) \\cdot { \\alpha}_{h}(\\rho_h)(a_{n } ) \\cdot \\delta(\\ell_{n},a_{n},\\bot)(\\ell_{n+1 } ) \\\\[2ex ] & = &   { \\mathrm{pr}}^{{\\alpha}_g}_{\\ell_0}({\\mathsf{cone}}(\\rho_g ) ) \\cdot { \\alpha}_{h}(\\rho_h)(a_{n } ) \\cdot \\delta(\\ell_{n},a_{n},\\bot)(\\ell_{n+1 } ) ;   \\end{array}\\ ] ] where the first equality is by definition ; the second equality is by simply re - writing @xmath364 as @xmath206 ; the third equality is by the definition of @xmath183 and @xmath365 ; and the final equality is the inductive hypothesis . by definition of @xmath209 we have @xmath366 ; and hence it follows that lhs and rhs coincide .",
    "thus the desired result follows .",
    "the previous two lemmas establish the equivalence of the probability measure and completes the reduction of pomdps to games with probabilistic uncertainty .",
    "hence the lower bounds for pomdps also gives us the lower bound for games with probabilistic uncertainty .",
    "hence theorem  [ lemm1 ] , along with the reduction from pomdps and theorem  [ thrm1 ] gives us the following result for games with probabilistic uncertainty ( the results are also summarized in table  [ tab : complexity ] ) .",
    "[ thrm2 ] the following assertions hold :    1 .   _",
    "( all - powerful player  2 ) . _ the sure , almost - sure and positive winning for safety objectives ; the sure and almost - sure winning for reachability objectives and bchi objectives ; the sure and positive winning for cobchi objectives ; and the sure winning for parity objectives are all exptime - complete for games with probabilistic uncertainty with all - powerful strategies for player  2 .",
    "the positive winning for reachability objectives is ptime - complete .",
    "( not all - powerful player  2 ) . _ the sure , almost - sure winning for safety objectives ; and the sure winning for parity objectives are all exptime - complete ; the almost - sure winning for reachability objectives and bchi objectives ; the positive winning for safety and cobchi objectives can be solved in 2exptime and is exptime - hard for games with probabilistic uncertainty without all - powerful strategies for player  2 .",
    "the positive winning for reachability objectives can be solved in exptime .",
    "( undecidability results ) .",
    "_ the positive winning problem for bchi objectives , the almost - sure winning problem for cobchi objectives , and the positive and almost - sure winning problem for parity objectives are undecidable for games with probabilistic uncertainty .",
    "& & & + & all - powerful & not - all - powerful & all - powerful & not - all - powerful & all - powerful & not - all - powerful + safety    & exp - complete & exp - complete & exp - complete & exp - complete & exp - complete & 2exp , exp + reachability    & exp - complete & exp - complete & exp - complete & 2exp , exp & ptime - complete & exp , ptime + bchi    & exp - complete & exp - complete & exp - complete & 2exp , exp & undec . &",
    "+ cobchi    & exp - complete & exp - complete & undec . &",
    "undec . & exp - complete & 2exp , exp + parity    & exp - complete & exp - complete & undec . &",
    "& undec . +",
    "in this work we considered games with probabilistic uncertainty , which is natural for many problems , and has not been considered before .",
    "we present a reduction of such games to classical partial - observation games and a reduction of pomdps to games with probabilistic uncertainty . as a consequence",
    "we establish the precise decidability frontier for games with probabilistic uncertainty .",
    "table  [ tab : complexity ] summarizes our results . for most problems we establish exptime - complete bounds . for some decidable problems we establish 2exptime upper bounds , and exptime lower bounds , and establishing the precise complexity results are interesting open problems .",
    "o.  kupferman and m.y . vardi .",
    "@xmath234-calculus synthesis . in _ proc .",
    "25th international symp . on mathematical foundations of computer science _ ,",
    "volume 1893 of _ lecture notes in computer science _ ,",
    "pages 497507 .",
    "springer - verlag , 2000 ."
  ],
  "abstract_text": [
    "<S> we introduce games with probabilistic uncertainty , a natural model for controller synthesis in which the controller observes the state of the system through imprecise sensors that provide correct information about the current state with a fixed probability . that is , in each step , the sensors return an observed state , and given the observed state , there is a probability distribution ( due to the estimation error ) over the actual current state . </S>",
    "<S> the controller must base its decision on the observed state ( rather than the actual current state , which it does not know ) . on the other hand , </S>",
    "<S> we assume that the environment can perfectly observe the current state . </S>",
    "<S> we show that our model can be reduced in polynomial time to standard partial - observation stochastic games , and vice - versa . as a consequence </S>",
    "<S> we establish the precise decidability frontier for the new class of games , and for most of the decidable problems establish optimal complexity results . </S>"
  ]
}