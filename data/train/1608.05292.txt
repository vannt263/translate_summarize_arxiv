{
  "article_text": [
    "a pandemic influenza outbreak has the potential to place a significant burden upon healthcare systems .",
    "therefore , the capacity to monitor and predict the evolution of an epidemic as data progressively accumulate is a key component of preparedness strategies for prompt public health response .",
    "statistical inferential approaches have been used in a real - time monitoring context for a number of infectious diseases .",
    "examples include : prediction of swine fever cases in a classical framework @xcite ; online estimation of a time - evolving effective reproduction number @xmath3 for sars @xcite and for a generic emerging disease @xcite ; and bayesian inference on the transmission dynamics of avian influenza in the uk poultry industry @xcite .",
    "these models rely on the availability of direct data on the number of new cases of an infectious disease over time . in practice , as illustrated by the 2009 outbreak of pandemic a / h1n1pdm influenza in the united kingdom ( uk ) , direct data are seldom available .",
    "more likely , multiple sources of data exist , each indirectly informing the epidemic evolution , each subject to possible sources of bias .",
    "this calls for more complex modelling , requiring the synthesis of information from a range of data sources in real time .    in this paper",
    "we tackle the problem of online inference on an influenza pandemic in this more realistic situation . to address this problem",
    "we develop the work of @xcite who retrospectively reconstructed the a / h1n1 pandemic in a bayesian framework using multiple data streams collected over the course of the pandemic . in @xcite posterior distributions of relevant epidemic parameters and related quantities",
    "are derived through markov chain monte carlo ( mcmc ) methods which , if used in real - time , pose important computational challenges .",
    "mcmc is notoriously inefficient for online inference as it requires repeat browsing of the full history of the data as new data accrues .",
    "this motivates a more efficient algorithm .",
    "potential alternatives include refinements of mcmc ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) and bayesian emulation as in @xcite , where the model is replaced by an easily - evaluated approximation that can be readily prepared in advance of the data assimilation process . here , we explore sequential monte carlo ( smc ) methods @xcite as an alternative to the expensive mcmc simulations .",
    "as batches of data arrive at times @xmath4 , smc techniques allow computationally efficient online inference by combining the posterior distribution @xmath5 at time @xmath6 with the incoming batch of data to obtain an estimate for @xmath7 .    use of smc in the real time monitoring of an emerging epidemic is not new .",
    "@xcite , @xcite , @xcite , @xcite , and @xcite are examples of real time estimation and prediction for deterministic and stochastic epidemic systems describing the dynamics of influenza and ebola epidemics .",
    "their models , however , also only include a single source of information that has either been pre - smoothed or is free of any sudden or systematic changes .",
    "in what follows we advance existing literature in two ways : we include a number of data streams , realistically mimicking the 2009 pandemic in the uk ; and we consider the situation where a public health intervention introduces a shock to the system , critically disrupting the ability to track the posterior distribution over time .",
    "the paper is organised as follows : in section [ sec : recon ] the model in @xcite is reviewed focusing on the data available and the computational limitations of the mcmc algorithm in a real time context ; in section [ sec : smc ] the idea of smc is introduced and an algorithm based on the work in @xcite described ; in sections [ sec : sim ] and [ sec : analysis ] results are presented from the application of a naive smc algorithm to data simulated to mimic the 2009 outbreak and illustrate the challenges posed by the presence of the informative observations induced by system shocks ; in sections [ sec : inf.theory ] and [ sec : informative ] adapted smc approaches that address such challenges are assessed ; we conclude with section [ sec : discussion ] in which the ideas explored in the paper are critically reviewed and outstanding issues discussed .",
    "@xcite describe the transmission of a novel influenza virus among a fixed population stratified into @xmath8 age groups and the subsequent reporting of infections .",
    "this is achieved through using a deterministic age - structured susceptible ( s ) , exposed ( e ) , infectious ( i ) , recovered ( r ) transmission model , with the e and i states split into two sub - states , @xmath9 and @xmath10 and @xmath11 . at time @xmath12 @xmath13 the vector @xmath14 gives the number of individuals in age group @xmath15 @xmath16 in each model state .",
    "the dynamics of the system are governed by a set of difference equations , such that for suitably small increments @xmath17 : @xmath18 where @xmath19 and @xmath20 are the mean latent and the mean infectious periods respectively .",
    "transmission is driven by the time- and age - varying force of infection , @xmath21 , the rate at which susceptible individuals become infected : @xmath22 here , @xmath23 is the basic reproduction number , the expected number of secondary infections caused by a single primary infection in a fully susceptible population , parameterised in terms of the epidemic growth rate @xmath24 .",
    "the pattern of transmission between age groups is determined by time - varying mixing matrices @xmath25 , with @xmath26 giving relative rates of effective contacts between individuals of each pair of age groups @xmath27 .",
    "these matrices are scaled to have elements @xmath28 where @xmath29 is the dominant eigenvalue of the time-0 next generation matrix whose @xmath30 entry is @xmath31 , with @xmath32 being the population size of the @xmath33 age stratum .",
    "the initial conditions of the system are determined by : parameter @xmath34 , the total number of infectious individuals across all age groups at time @xmath35 ; an assumed equilibrium distribution of infections over the age groups ; and an assumption of initial exponential growth that determines the relationship between the numbers in the four disease states .",
    "for ease of implementation , a reparameterisation is made from @xmath34 to a parameter denoted @xmath36 , the details of which can be found in the supplementary information to @xcite .",
    "denote by @xmath37 the vector of transmission dynamics parameters where @xmath38 parameterise the mixing matrices @xmath25 , defining any time variation .",
    "note , parameter @xmath19 is notoriously difficult to estimate and is therefore assumed fixed at two days .",
    "figure [ fig : link_schema ] illustrates how surveillance data from multiple sources relate to the age - structured seir transmission model , allowing estimation of the transmission dynamics parameters .",
    "the transmission process is unobserved .",
    "however , there are a number of surveillance sources informing aspects of this process .",
    "as system dynamics are assumed to be deterministic , there is no system error and outputs ( see equations - ) are deterministic functions of @xmath39 , e.g. @xmath40 .",
    "the available surveillance data are ` imperfect observations on a perfect system ' and are linked to the system s outputs via observational models as follows .    the number of susceptibles in age group @xmath15 at the end of the @xmath41 time - step , @xmath42 , is informed directly by a series of cross - sectional survey data @xmath43 on the presence of immunity - conferring antibodies in the general population . denoting by @xmath44 the number of blood sera samples tested in time interval @xmath45 , it is assumed that @xmath46 the number of new age - specific infections in interval @xmath45 expressed as @xmath47 are indirectly related to surveillance data on health - care burden . a proportion",
    ", @xmath48 ( see figure [ fig : link_schema ] ) of these new infections will develop symptoms .",
    "of those symptomatic , a proportion @xmath49 will be virologically confirmed through admission to hospital and/or to an intensive care unit ( icu ) .",
    "alternatively a proportion @xmath50 will choose to contact primary care practitioners and will be reported as consultations for influenza - like illness ( ili ) together with individuals attending for non - pandemic pathogen ili . as a result",
    ", primary consultation data will be contaminated by a background consultation component strongly influenced by the public s volatile sensitivity to governmental advice .",
    "the consultation data are , therefore , less directly related to the severity and incidence of infection than the confirmed cases . to identify the consultations attributable to the pandemic strain , complementary data from a sub - sample of swabbed ili patients provide information on the proportion of consultations with pandemic virus .    using a generic @xmath51 to denote counts of confirmed cases or primary care consultations , the model in @xcite outputs quantities of the type @xmath52 representing the number of surveillance counts in the interval @xmath45 attributable to the pandemic .",
    "expression results from the process of becoming infected and subsequently experiencing a delay ( of mean @xmath53 , variance @xmath54 with discretised probability mass function @xmath55 ) , which includes the time from infection to symptoms ( the incubation period ) , the time from symptoms to the healthcare event , and the time from diagnosis to the report of the healthcare event of interest . note that in the parametric dependence of output quantities has been omitted for ease of notation and will be done throughout .",
    "the count data @xmath56 are assumed to have negative binomial distribution expressed here in mean - dispersion @xmath57 parameterisation , such that if @xmath58 , then @xmath59 , @xmath60 and @xmath61 so , for the confirmed cases @xmath62 : @xmath63 and for the primary care consultations @xmath64 , which include contamination by a non - pandemic ili background component @xmath65 : @xmath66 where the contamination @xmath65 is appropriately parameterised in terms of parameters @xmath67 , and the signal @xmath68 is identified by virological data from sub - samples of size @xmath69 of the primary care consultations .",
    "the number of swabs testing positive for the presence of the pandemic strain @xmath70 in each sample is assumed to be distributed as : @xmath71      let @xmath72 denote the vector of all free parameters",
    "_ i.e. _ @xmath73 .",
    "@xcite develop a bayesian approach and use a markov chain - monte carlo ( mcmc ) algorithm to derive the posterior distribution of @xmath72 on the basis of @xmath74 days of primary care consultation and swab positivity data , confirmed case and cross - sectional serological data .",
    "the mcmc algorithm is a naively adaptive random walk metropolis algorithm , requiring @xmath75 iterations , taking over four hours .",
    "mcmc is not easily adapted for parallelised computation , although a small speed up can be achieved by parallelising the likelihood component of the posterior distribution of @xmath72 over a small number of cpus . in total , this required in excess of @xmath76 evaluations of the transmission model and/or convolutions of the kind in equation .",
    "implementation of mcmc in an online fashion , as new data arrive involves the re - analysis of the entire dataset , requiring time for multiple markov chains to converge .",
    "although , the runtime might not be prohibitive for real - time inference , the current implementation leaves little margin to consider multiple code runs or alternative model formulations . in a future pandemic",
    "there will be a greater wealth of data facilitating a greater degree of stratification of the population @xcite . with increasing model complexity comes rapidly increasing mcmc run - times , which can be efficiently addressed through use of smc methods .",
    "smc is commonly used for inference from models that can be cast in a state - space formulation , where expressions of the form : @xmath77 govern the evolution of the latent state vector @xmath78 and the its relation to the observed data @xmath79 for @xmath80 . here the @xmath81 are conditionally independent given knowledge of the @xmath78 .",
    "on observing @xmath82 batches of data , @xmath83 at times @xmath84 , the main interest in this set - up is the filtering problem i.e. estimating the state vector @xmath78 through posterior distributions @xmath85 .",
    "note the conditioning on the parameters @xmath72 , which are typically assumed to be fixed and known @xcite , although methods for the estimation of static @xmath72 are very much an active area of research ( for example * ? ? ?",
    "the model in section [ sec : recon ] is a deterministic model , designed for use at a time in a pandemic when stochastic effects are uninfluential . in this case",
    "@xmath86 with data being imperfect observations distributed around model outputs .",
    "the inferential focus is here on @xmath72 .",
    "online inference involves the sequential estimation of posterior distributions @xmath87 , where @xmath88 indicates the prior for @xmath89 .",
    "estimation of any epidemic feature , _",
    "e.g. _ the assessment of the current state of the epidemic or prediction of its future course , follows from estimating @xmath72 ( or components thereof ) .",
    "suppose at time @xmath6 a set of particles @xmath90 , where each particle @xmath91 carries a weight @xmath92 , approximates a sample from the target distribution @xmath5 .",
    "on the arrival of the next batch of data , @xmath5 is then used as an importance sampling distribution to sample from @xmath7 . in practice , this involves a re - weighting of the particle set . from the conditional independence assumption of , the particles are reweighted according to the importance ratio : @xmath93 which reduces to the likelihood of the incoming data batch . eventually , many particles will begin to carry relatively very low weight , leading to sample degeneracy as progressively fewer particles contribute meaningfully to the estimation of @xmath5 . a measure of this degeneracy is the effective sample size ( ess ) @xcite , @xmath94 values for the ess that are small in comparison to @xmath95 are indicative of degeneracy or impoverishment of the current particle set .",
    "this degeneracy can be tackled in different ways .",
    "@xcite introduced a resampling step , removing low weight particles and re - setting particle weights , and proposed jittering the particles .",
    "this jittering step was later formalised by @xcite with the introduction of metropolis - hastings ( mh ) steps to rejuvenate the sample . @xcite and @xcite provide more general treatises of this sequential monte carlo method , with @xcite labelling the algorithm ` iterated batch importance sampling ' .",
    "this approach has since been extended by @xcite who unify the static estimation with the filtering problem ( estimation of @xmath78 ) .",
    "here we adapt the resample - move algorithm of @xcite and investigate its potential efficiency saving when compared to successive use of mcmc .",
    "mh steps provide the computational bottle - neck in resample - move as they require the browsing of the whole history of the data to evaluate the full likelihood , not just the latest batch of observations . to achieve fast inference , it is preferable to limit the number of such steps , without introducing monte carlo error through having a degenerate sample .",
    "the algorithm is laid out in full below .",
    "it is presumed that it is straightforward to sample prior distribution @xmath96 .      1 .",
    "* set * @xmath97 .",
    "draw a sample @xmath98 from the prior distribution , @xmath96 , set the weights @xmath99 .",
    "* set*[pt : init ] @xmath100 .",
    "observe a new batch of data @xmath101 .",
    "re - weighted the particles so that the @xmath102 particle now has weight @xmath103 3 .",
    "* calculate the effective sample size*. set @xmath104 .",
    "if @xmath105 set @xmath106 , @xmath107 , @xmath108 and return to point ( [ pt : init ] ) , else go next .",
    "4 .   * resample*. choose @xmath95 and sample @xmath109 from the set of particles @xmath110 with corresponding probabilities @xmath111 .",
    "here , we have used residual resampling @xcite .",
    "re - set @xmath112 .",
    "[ pt : rejuvenation ] 5 .",
    "* move * : for each @xmath113 , move from @xmath114 to @xmath115 via a mh kernel @xmath116 .",
    "if @xmath117 , return to point ( [ pt : init ] ) .",
    "* end*.    there are a number of algorithmic choices to be made , including tuning the parameters of the mh kernel ( @xmath118 above ) or the rejuvenation threshold , @xmath119 . in a real - time setting , it may not be possible to tune an algorithm `` on the fly '' , so the system has to be able to work `` out of the box '' , either through prior tuning or through adaptation . in what follows we set @xmath120 @xcite and we focus on the key factor affecting the performance of the algorithm in real - time , _ i.e. _ the mh kernel .      [ [ correlated - random - walk ] ] correlated random walk + + + + + + + + + + + + + + + + + + + + + +    a correlated random walk proposes values : @xmath121 in the neighbourhood of the current particle , where @xmath122 is the sample variance - covariance matrix for the weighted sample @xmath123 . the parameter @xmath118 can be tuned _ a priori _ to guarantee a reasonable acceptance rate , or , alternatively , asymptotic results for the optimal scaling of covariance matrices @xcite can be used .",
    "localised moves keep acceptance rates high and will quickly restore the value of the ess . however , if after re - sampling there are few unique particles then the rejuvenation will result in a highly clustered sample , providing an inaccurate representation of the target distribution .    [",
    "[ approximate - gibbs ] ] approximate gibbs + + + + + + + + + + + + + + + + + +    an independence sampler that proposes @xcite : @xmath124 where @xmath125 is the sample mean for the @xmath123 .    here ,",
    "moves are proposed to a region of the sample space only weakly dependent on the current position and proposals are drawn from a distribution chosen to approximate the target distribution .",
    "an accept - reject step is still required to correct for this approximation , so it is perhaps more accurate to refer to this proposal kernel as approximate metropolis - within - gibbs. the quality of the approximation depends on @xmath126 being well represented by the current particle set , there being sufficient richness in the particle weights after the re - weighting step and the target density being sufficiently near - gaussian .",
    "assuming that the multivariate normal approximation to the target is adequate ( and it should be increasingly so as more data are acquired ) this type of proposal allows for more rapid exploration of the sample space .",
    "if the multivariate normal approximation is not good , particles of high posterior or low proposal density will not be easily moved by this kernel , and , as acceptance rates can not be adapted to ensure a minimum level of acceptance , there is no guarantee that the ess will be restored above the level at which rejuvenations are required ( see section [ sec : analysis ] ) .",
    "both the correlated random walk and the approximate gibbs methods will be used , both as block updates where a new value for the entire parameter vector is proposed at once , and component - wise updates where individual or small groups of parameter components are proposed in turn , using the appropriate conditional distributions derived from and .",
    "the smc algorithm s performance against the gold - standard mcmc is evaluated via simulation , through its application to data arising from an epidemic simulated to mimic the timing and dynamics of the 2009 a / h1n1 pandemic in england .",
    "anomalously , this epidemic started with an initial burst of infection in spring , so we assume that the starting date is the @xmath127 may .",
    "the epidemic occurs in two waves of infection , the first reaches a peak immediately prior to the summer school holidays . after the holiday ,",
    "the growth of the epidemic is far slower , reaching a second peak in the autumn .",
    "we consider two scenarios . in the first scenario",
    "we have direct information on confirmed cases , as might arrive in the surveillance of severe disease ( e.g. hospitalisation , icu admissions ) . in the second scenario we observe ili consultations in primary care which are noisy and contaminated by non - pandemic infections ( see section [ sec : intro.inference ] ) . both confirmed case and consultation data",
    "are assumed to exist alongside serological data measuring the overall level of cumulative infection over the course of the pandemic to date . in the second scenario",
    ", we also assume the existence of a companion dataset of virological swabbing data from a sub - sample of the noisy data . in both scenarios ,",
    "observations are assumed to be made on 245 consecutive days and the underlying epidemic curve is characterised by the same parameters , so both confirmed case and primary care consultation data are subject to similar trends and shocks .",
    "one such shock arises from an assumed sudden change in the way case counts , whether they are confirmed cases or gp consultations , are reported .",
    "this could occur due to some public health intervention , as happened in 2009 with the launch of the national pandemic flu service ( npfs ) , designed to alleviate the burden placed on primary care services .",
    "table [ tbl : parameters ] presents the model parameters common to both scenarios and the values used for simulation .      for a given set of parameters @xmath72 ,",
    "the number of confirmed cases , @xmath128 , in interval @xmath45 is given by equation .",
    "count data @xmath62 are then generated as negative binomially distributed with mean @xmath129 and variance @xmath130 .",
    "the degree of overdispersion , defined by the dispersion parameters @xmath131 and @xmath132 ( table [ tbl : parameters ] ) , is piecewise constant over time , with a breakpoint at the time of the system shock , taken to be @xmath133 .",
    "these data contain a significant amount of contamination . as with the confirmed case data , the number of consultations due to the pandemic strain is calculated via the convolution equation to give @xmath134 .",
    "the contamination component is added by assuming ` background ' consultation rates that follow a log - linear spline with a discontinuity at @xmath133 , with additional age effects to generate separate consultation rates for children ( @xmath135 year - olds ) and adults .",
    "the background rates over the interval @xmath45 , @xmath65 , depend on spline parameters @xmath67 , such that , for a suitable design matrix @xmath136 @xmath137 where @xmath138 is a suitably vectorised collection of the @xmath65 .",
    "aggregated over ages , the log - linear spline used for simulation is plotted in figure [ fig : gp.data](d ) . in this example , @xmath67 is a 9-dimensional parameter .",
    "as already anticipated above , these counts will also drop markedly due to an intervention to reduce the burden on primary care services , resulting in a sudden change in the parameter @xmath139 , the proportion of symptomatic cases that seek consultation . in reality , this parameter will show more heterogeneity over time than its analog for the confirmed case data as it depends on behavioural factors and is not a property of the virus .",
    "however , in the examples presented here , @xmath49 and @xmath50 are parameterised similarly ( see table [ tbl : parameters ] ) .    [ cols= \" < , > \" , ]",
    "this paper addresses the substantive real world problem of online tracking of an emergent epidemic , assimilating multiple sources of information through the development of a suitable smc algorithm .",
    "when incoming data are stable , this process can be automated using standard smc algorithms , confirming current knowledge ( _ e.g. _ * ? ? ?",
    "* ; * ? ? ?",
    "however , in the likely presence of interventions or any other event that may provide a system shock , it is necessary to adapt the algorithm appropriately . on observing the impact that a new batch of data has on the ess of a particle set , tailoring of the mh - kernel and selection of suitable thresholds",
    "can ensure efficient performance .",
    "however , as we have seen , given that not all prior distributions are well chosen and not all models well conceived this might necessitate some careful , yet ad hoc tinkering . the end result is an algorithm that is a hybrid of particle filter and population mcmc @xcite .    having simulated an epidemic where a public health intervention provides a sudden change to the pattern of case reporting , we have constructed a more robust smc algorithm by tailoring    1 .   the choice of rejuvenation times through tempering ; 2 .   the choice of the mh - kernel by hybridising local random walk and gibbs proposals ; and 3 .   by introducing the use of the intra - class correlation to provide a stopping rule for the mcmc steps to limit the number of mcmc steps within each rejuvenation .",
    "our experience suggests , real time epidemic tracking will involve switching between a simple , automated , smc to an smc specifically tailored to the nature of any impending shock .",
    "throughout we have inevitably made pragmatic choices and alternative strategies could have been adopted .",
    "we reflect on these , lessons learned and outstanding questions in what follows .      in the motivating example ,",
    "a system `` shock '' occurred at @xmath133 .",
    "this shock represents a systematic change in the way the data are generated , affecting a number of parameters that , at this time , have a step - change in their values . the first few observations in the new parametric regime after the shock typically cause the greatest disturbance to the marginal posterior distribution for these parameters .",
    "posterior @xmath140 is no longer a good importance distribution to sample from @xmath141 and proposal kernels based on a reweighted sample from @xmath140 may not be useful .",
    "this will be reflected in a severe drop in the ess .",
    "a low value for the ess is always indicative of depletion , whereas a high value does not guarantee that the sample is adequate .",
    "section [ sec : analysis ] illustrated how the ess can be artificially rejuvenated even when the particle set is not . for the ess to be useful , it is essential that previous rejuvenation steps result in a sufficiently independent set of values for the margins of interest .",
    "after resampling , many mh - steps may be needed to remove any clustering .",
    "this motivates the use of the analysis of variance intra - class correlation coefficient , @xmath142 , to define a stopping rule for the mh - steps .",
    "currently this rule relies on two algorithmic choices : the choice of a univariate function of interest , @xmath143 ( see equation ) , and the choice of the threshold @xmath144 , the largest acceptable value for @xmath142 at the end of the rejuvenation process .",
    "the function @xmath143 should depend on model outputs of particular relevance .",
    "the predicted attack rate of an epidemic is a quantity that will be reported to public health policymakers throughout an epidemic and is dependent on all the transmission parameters .",
    "however , when the parameter vector is high - dimensional , as in this case , is it reasonable to condense this into a univariate summary to use as a basis for a stopping rule ?",
    "convergence of mcmc is typically diagnosed by looking at marginal distributions , so should we be doing something similar here ?",
    "does this necessitate the use of multivariate analogs for the intra - class correlation coefficient ( for example , see * ? ? ?",
    "* ; * ? ? ?",
    "it is felt here that the univariate @xmath145 is adequate as the parameters introduced at the ` shock ' time are largely nuisance parameters not strongly correlated with the transmission parameters that influence @xmath145 .",
    "once @xmath142 has been suitably defined , a suitable stopping threshold , @xmath144 has to be chosen . given the antecendent prescription for defining clusters used here , then @xmath142 truly is a measure of how well the particles have collectively ` forgotten ' their starting points . in situations",
    "where the target posterior is well - matched by its gaussian approximation , we could use a higher threshold than when starting from a poor estimate for the target distribution .",
    "a value of @xmath146 is a sufficiently small threshold except for extreme cases of departure between two successive distributions .",
    "a possible alternative to @xmath142 is an extension of the sampling variance @xmath147 in @xcite @xmath148 where @xmath149 gives the number of common ancestors of particles @xmath150 and @xmath151 within the interval , and @xmath152 is the function of interest , with @xmath153 an estimate of @xmath154 .",
    "@xmath147 was initially proposed to identify suitable rejuvenation times , but it is not clear how this can be done prospectively .",
    "it could , however , provide a stopping rule for the mh - sampler .",
    "as the clusters are defined by starting position , running mh - steps until there are no longer any cluster effects will minimise this variation .",
    "this has been borne out by calculations based on the simulations of section [ sec : informative ] .",
    "therefore , one could run the mh - sampler until @xmath147 is suitably small .",
    "the alternative to running long mcmc chains within each particle when there are new parameters in the model such as those introduced by the ` shock ' at @xmath133 , is to expand the particle set by cloning each of the particles a number of times , each cloned particle having a fresh draw from the prior for each of the new parameter components . upon observing the next batch of data , the expanded particle set",
    "could then be reduced down to a more manageable size . however",
    ", it is not clear _ a priori _ how many cloned copies of each particle to take and if the number of clones required exceeds the length of the parallel mcmc chains , then this does not represent a computational efficiency . furthermore , this would not solve the problem in scenario 2 where some parameters are not immediately identifiable .",
    "a hybrid mh - kernel is introduced in section 6 .",
    "first , long - range , low - acceptance proposals are made , followed by short - range high - acceptance componentwise proposals . in many instances ,",
    "this hybrid is replaced by a mixture distribution , a mixture of similar short and long - range moves .",
    "the adaptive proposal distributions of fearnhead and taylor ( 2013 ) might take this a step further , tuning the mixture probabilities so that the moves that have the largest expected jumps are proposed more often .",
    "this would be an attractive extension to this case , but through monitoring intra - class correlation it is clear that full block approximate gibbs proposals maximise this expected jump size amongst the kernels we consider .",
    "however , we would still suggest moving at least a proportion of the particles according to random walk proposals , to guard against @xmath140 being a degenerate approximation for @xmath141 .",
    "a further problem of having step - changes in parameter values is the potential for a lack of identifiability .",
    "scenario 2 provides two such examples .",
    "firstly , we consider parameter @xmath132 , the dispersion in the immediate aftermath of @xmath133 .",
    "the prior for @xmath132 is a @xmath155 distribution chosen independently of @xmath131 ( the dispersion preceding the shock ) .",
    "the sheer number of new parameters introduced in the aftermath of the shock ensures that the data on days 84 , 85 , 86 are ( over-)fitted with very little error .",
    "the combination of this over - fitting and the unbounded nature of the prior close to zero pushes the initial posterior distributions for @xmath132 very close to zero .",
    "as data accumulate , the posterior mass gradually moves towards the value used to generate the data .",
    "this movement of posterior mass is difficult for sequential algorithms to track , particularly so because of the non - gaussian nature of the prior , even on the log - scale .",
    "when performing real - time inference , therefore , the choice of a prior distribution more robust to this initial over - fitting may be preferred .",
    "alternatively , a flat prior would need to be bounded to ensure that it can be sampled from . from a practical point of view , in the example of this paper , the choice of the @xmath155 distribution is meaningful as it attaches significant probability to the data being poisson , rather than negative binomial , distributed .",
    "the second example is the case of the background consultation parameters .",
    "the background rate of non - pandemic consultation is modelled using a log - linear spline , taking separate value for adults and children , with knots at @xmath156 84 , 128 , 176 , and 245 days .",
    "the value of the spline at these knots is given by @xmath157 with linear interpolation giving the value of the spline at the intervening points .",
    "this results in background consultation rates for days 84 , 85 , and 86 respectively of the form ( neglecting the age effects ) : @xmath158 so , over this period there is very little identifiability of parameters @xmath159 and @xmath160 .",
    "this parameterisation , as shown in figure [ fig : bij.evo ] , can induce convergence problems for mcmc but not for smc .",
    "jasra et al ( 2011 ) claim that , for their example , smc may well be superior to mcmc and this is one case where this is certainly true .",
    "the population mcmc carried out in the rejuvenation stage achieves good coverage of the sample space , without the individual chains having to do likewise . to improve the mcmc mixing",
    ", this lack of identifiability would require a reparameterisation , which becomes unnecessary when using smc .      throughout ,",
    "we have compared candidate mh - kernels via the kl - like statistics measuring the divergence between smc posteriors from posteriors generated by the `` gold - standard '' mcmc .",
    "we have also constructed a reference distribution for the kl statistic to assess informally the significance of the observed divergences .",
    "this , however , rather presumes that the mcmc is the gold - standard .",
    "this superiority is , however , called into question by the better performance of the smc algorithm particularly in the presence of the unidentifiability around shock times as discussed above .    from a computational efficiency point of view , the smc algorithm , because of its highly parallel nature , is , at its worst , no slower than the full mcmc analysis .",
    "however , this may be an unfair comparison as the mcmc algorithm is based on `` plain vanilla '' random - walk metropolis updates and could benefit from significant tuning itself .",
    "more sophisticated mcmc algorithms could be used , as exemplified in an epidemic context by jewell et al .",
    "the use of differential geometric mcmc ( girolami & calderhead , 2011 ) or advances in the parallelisation of mcmc ( banterle et al , 2015 ) , for example , could assist with improving mcmc run times . on the other hand , as mcmc steps are the main computational overhead of the smc algorithm , any development of the mcmc algorithm may lead to a similar improvement to the smc algorithm also .",
    "up to now the discussion has centred on algorithmic development and the availability of all data sources in a timely manner has been assumed .",
    "particularly crucial to the feasibility of real - time modelling is the role of the serology data .",
    "this is shown in figure [ fig : gradeds ] , where epidemic projections have been sequentially made using only noisy primary care consultation data in the absence of serological data .",
    "a clear and realistic picture of the epidemic is not available until the epidemic has almost entirely been observed .",
    "this poses some key questions : are serological samples going to be available in a timely manner , in sufficient quantity and quality , and in the right format ?",
    "in reality , serological data can be slow to come online .",
    "a test has to be developed to identify the antibodies of a ( probably ) novel virus in blood sera ; and there needs to be sufficient time to test samples and report results according to a protocol that ensures unbiased data collection and analysis .",
    "+    from a computational point of view , under the assumption that all data become immediately available , each particle , in addition to its likelihood , weight and parameter value , stores a matrix representing the current state of the seir transmission model and a sub - history of values @xmath161 , long enough to evaluate equation at all current and future times . in the more realistic setting to accommodate the ` slow ' serological data , particles will have to store the full historical values of @xmath162 in addition to the current state of the epidemic .",
    "finally , should external information that can not be incorporated directly into the model become available at any time , it can easily be assimilated through appropriate adaptation of the prior distributions : particles would be reweighted according to the ratio of the new to old prior ; and depending on the ess , resampling and moving steps could follow .",
    "this provides a clear advantage of smc over mcmc where the entire dataset would have to be re - analysed .",
    "the analyses in this paper have neglected the first fifty days of the epidemic , concentrating on a period when there is substantial transmission in the population and appropriate data are becoming available . as a result",
    ", a deterministic system can adequately describe the future evolution of the pandemic .",
    "stochastic effects are significant and need to be incorporated into the model if monitoring is needed in the earlier stages . amongst others ,",
    "@xcite provide a prescription for particle learning in the presence of ` shocks ' in such a setting .",
    "alternatively , to improve the robustness of the inferences , the piecewise linear quantities describing population reporting behaviour ( @xmath163 ) could be described by linked stochastic noise processes .",
    "this has the potential to reduce the sensitivity of estimates to the presence of changepoints that are not , for whatever reason , foreseeable .      in answer to",
    "the question initially posed , we have provided a recipe for online tracking of an emergent epidemic using imperfect data from multiple sources .",
    "we have discussed many of the challenges to efficient inference , with particular focus on scenarios where the available information is rapidly evolving and is subject to sudden shocks .",
    "we have focused on an epidemic scenario likely to arise in the uk .",
    "nevertheless , our approach addresses modelling concerns common globally ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) and can form a flexible basis for real - time modelling strategies elsewhere .",
    "real - time modelling is , however , more than just a computational problem",
    ". it does require the timely availability of relevant data , but also needs a sound understanding of any likely biases , and effective interaction with experts . in any country ,",
    "only interdisciplinary collaboration between statisticians , epidemiologists and database managers can turn cutting edge methodology into a critical support tool for public health policy .",
    "paul birrell was supported by the national institute for health research ( hta project:11/46/03 ) the uk medical research council ( unit programme numbers u105260566 and mc_up_1302/3 ) and public health england ."
  ],
  "abstract_text": [
    "<S> a prompt public health response to a new epidemic relies on the ability to monitor and predict its evolution in real time as data accumulate . </S>",
    "<S> the 2009 a / h1n1 outbreak in the uk revealed pandemic data as noisy , contaminated , potentially biased , and originating from multiple sources , seriously questioning the capacity for real - time monitoring . </S>",
    "<S> here we assess the feasibility of real - time inference based on such data by constructing an analytic tool combining an age - stratified seir transmission model with various observation models describing the data generation mechanisms . </S>",
    "<S> as batches of data become available , a sequential monte carlo algorithm is developed to synthesise multiple imperfect data streams and iterate epidemic inferences amidst rapidly evolving epidemic environments , heuristically minimising computation time to ensure timely delivery of real - time epidemic assessments .    </S>",
    "<S> keywords : sequential monte - carlo , resample - move , real - time inference , pandemic influenza , seir transmission model    _ @xmath0mrc biostatistics unit , institute of public health , university forvie site , robinson way , cambridge cb2 0sr , uk _ + _ @xmath1public health england , london , uk _ + _ </S>",
    "<S> @xmath2centre for research in statistical methodology , university of warwick , coventry , uk _ + e - mail for correspondence : daniela.deangelis@mrc-bsu.cam.ac.uk </S>"
  ]
}