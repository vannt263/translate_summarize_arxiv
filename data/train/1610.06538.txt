{
  "article_text": [
    "optimization problems where the objective function can be written as a difference of two convex functions arise naturally in several applications , such as image processing @xcite , machine learning @xcite , optimal transport @xcite and sparse signal recovering @xcite . generally , the class of d.c .",
    "functions is rather broad and contains for example every twice continuously differentiable function . for an overview over d.c .",
    "functions , see e.g. @xcite .    the classical approach to iteratively find local extrema of d.c .",
    "problems was described by tao and an @xcite in 1997 under the name dca ( d.c .",
    "algorithms ) .",
    "one of the most recent papers on this topic is @xcite , where an accelerated variant of the dca method is proposed under the supplementary assumption that both the convex and the concave part are continuously differentiable . in 2003 ,",
    "sun , sampaio and candido introduced a proximal point approach into the theory of d.c .",
    "algorithm @xcite , where the convex part is evaluated by its proximal point operator , while its concave part is still evaluated by one of its subgradients .",
    "later on , the approach in @xcite has been extended in @xcite by considering in the convex part a further convex smooth summand that is evaluated via its gradient .    in this paper , we go one step further by proposing an algorithm , where both convex and concave part are evaluated via proximal steps . in convex",
    "optimisation , using proximal steps instead of subgradient steps has several advantages :    * the subdifferential at a point may be a non - singleton set , in particular it may be empty or may consist of several distinct elements . in an algorithm ,",
    "one may get stuck or have to choose one , respectively .",
    "* even if the subdifferential is a singleton in each step , it might be highly discontinuous , so small deviations might lead to a very different behaviour of the iterations . *",
    "better convergence rates can be guaranteed for proximal algorithms than for subgradient algorithms ( compare @xcite and ( * ? ? ?",
    "* theorem 3.2.3 ) ) .",
    "in addition , we consider a linear operator in the concave part of the objective function , which is evaluated in a forward manner in the spirit of primal - dual splitting methods .    in section [ sec :",
    "problem ] , we present the problem to be solved together with its toland dual and attach to them a primal - dual formulation in form of a minimization problem , too . we derive first - order optimality conditions and relate the optimal solutions and the critical points of the primal - dual minimization problems to the optimal solutions and , respectively , the critical points of both primal and dual optimization problems .    in section [ sec : algorithm ] , we propose a double - proximal d.c .",
    "algorithm , which generates both a primal and a dual sequence of iterates and show several properties which make it comparable to dca .",
    "more precisely , we prove a descent property for the objective function values of a primal - dual formulation and that every cluster point of the sequence of primal iterates is a critical point of the primal problem , while every critical point of the sequence of dual iterates is a critical point of the dual problem .    in section [ sec : kl ] , we show global convergence of our algorithm and convergence rates for the iterates in some certain cases , provided that the objective function of the primal - dual reformulation satisfies the kurdyka ",
    "ojasiewicz property ; in other words , it is a _",
    "k function_. the convergence analysis relies on methods and concepts of real algebraic geometry introduced by ojasiewicz @xcite and kurdyka @xcite and later developed in the nonsmooth setting by attouch , bolte and svaiter @xcite and bolte , sabach and teboulle @xcite .",
    "one of the remarkable properties of the k functions is their ubiquity in applications ( see @xcite ) .",
    "the class of k functions contains semi - algebraic , real sub - analytic , semiconvex , uniformly convex and convex functions satisfying a growth condition .",
    "we close our paper with some numerical examples addressing an image deblurring and denoising problem in the context of different dc regularizations .",
    "for the theory of convex analysis in finite - dimensional spaces , see the book @xcite .",
    "we shall consider functions taking values in the _ extended real line _",
    "we agree on the order @xmath1 for any real number @xmath2 and the operations @xmath3 for arbitrary @xmath4 ( see @xcite ) .",
    "let @xmath5 be a real finite - dimensional hilbert space .",
    "for a function @xmath6 , we denote by @xmath7 its _ domain_. the function @xmath8 is called _ proper _ if it does not take the value @xmath9 and @xmath10 .",
    "it is called _ convex _ if @xmath11 for all @xmath12 and @xmath13 .",
    "the _ conjugate function _",
    "@xmath14 of @xmath6 is defined by @xmath15 if @xmath8 is proper , convex and lower semicontinuous , then @xmath16 by the fenchel ",
    "moreau theorem .",
    "the _ convex subdifferential _",
    "@xmath17 at @xmath18 of a function @xmath6 is empty if @xmath19 and @xmath20 otherwise",
    ". let @xmath21 and @xmath6 be proper , convex and lower semicontinuous .",
    "the _ proximal point _",
    "@xmath22 of @xmath23 at @xmath18 is defined as @xmath24 the set of minimizers in the definition above is a singleton ( * ? ? ?",
    "* proposition 12.15 ) , and the proximal point is characterised by the variational inequality ( * ? ? ?",
    "* proposition 12.26 ) @xmath25 for all @xmath26 , which is equivalent to @xmath27    when dealing with nonconvex and nonsmooth functions , we have to consider subdifferentials more general than the convex one .",
    "the _ frchet subdifferential _",
    "@xmath28 at @xmath18 of a proper and lower semicontinuous function @xmath6 is empty if @xmath19 and @xmath29 otherwise . the _ limiting ( mordukhovich )",
    "@xmath30 at @xmath18 of a proper and lower semicontinuous function @xmath6 is empty if @xmath31 and @xmath32 otherwise .",
    "let @xmath33 and @xmath5 be real finite - dimensional hilbert spaces , let @xmath34 and @xmath35 be proper , convex and lower semicontinuous functions , let @xmath36 be a convex , frchet differentiable function with @xmath37-lipschitz continuous gradient , for some @xmath38 , and let @xmath39 be a linear mapping ( and @xmath40 its adjoint ) .",
    "we consider the problem @xmath41 together with its toland dual problem @xcite @xmath42 the following primal - dual formulation will turn out to be useful in the sequel : @xmath43 where @xmath44 is proper and lower semicontinuous .",
    "let us derive necessary optimality conditions for the problems , and :    1 .",
    "the optimal values of , and are equal .",
    "2 .   for all @xmath45 and @xmath46 , @xmath47 3 .   let @xmath48 be a solution of",
    ". then @xmath49 .",
    "4 .   let @xmath50 be a solution of",
    ". then @xmath51 . 5 .",
    "let @xmath52 be a solution of .",
    "then @xmath53 is a solution of , and @xmath54 is a solution of .",
    "furthermore , the inclusions @xmath55 hold .    1 .   by the fenchel ",
    "moreau theorem , applied to @xmath56 , we have @xmath57 2 .",
    "let @xmath45 and @xmath46 .",
    "then , @xmath58 and the other inequality is verified by an analogous calculation .",
    "3 .   let @xmath48 be a solution of , i.e. , @xmath59 if @xmath60 , then , by definition , @xmath61 , and the inclusion automatically holds .",
    "if @xmath62 , then the optimal value of must be @xmath63 , which implies @xmath64 now let @xmath65 . then @xmath66 adding and yields @xmath67 if @xmath68 , then is automatically satisfied , otherwise @xmath69 and , by , @xmath70 , and both sides of both and are finite . in either case , we have shown @xmath71 .",
    "the proof of this statement is analogous .",
    "let @xmath72 be a solution of .",
    "( in particular , if such a solution exists , the common optimal value of , and must be finite . )",
    "the function @xmath73 is convex and takes a minimum at @xmath53 .",
    "therefore @xmath74 which proves .",
    "the same argument works for the function @xmath75 and implies @xmath76 which is . for these inclusions , we obtain equality in the young  fenchel inequality , i.e. , @xmath77 therefore , @xmath78 since @xmath72 is a solution of , the last expression equals the common optimal value of , and .",
    "we say that @xmath79 is a _",
    "critical point _ of the objective function @xmath80 of if the inclusions and are satisfied .",
    "we denote by @xmath81 the set of critical points of the function @xmath80 .",
    "[ rem : critical ] if @xmath79 is a critical point of @xmath80 , then @xmath82 by adopting the terminology of e.g. @xcite , we denote by @xmath83 the set of critical points of the objective function @xmath84 of and by @xmath85 the set of critical points of the objective function @xmath86 of .",
    "( recall that @xmath87 and @xmath88 . )",
    "thus , if @xmath79 is a critical point of the objective function @xmath80 , then @xmath53 is a critical point of @xmath84 and @xmath54 is a critical point of @xmath86 .",
    "let @xmath89 , and let @xmath90 and @xmath91 be sequences of positive numbers .",
    "we propose the following iterative scheme : for all @xmath92 set @xmath93    by the inequalities for the proximal points , we have , for every @xmath12 and @xmath92 , @xmath94 moreover , using ( * ? ? ? * theorem 18.15 ( iii ) ) and the subdifferential inequality , we have for every @xmath45 and @xmath92 , @xmath95 we consider the auxiliary function @xmath44 defined by @xmath96 by the inequalities above , we have , for arbitrary @xmath18 , @xmath46 and @xmath92 , @xmath97 furthermore , for any @xmath98 , @xmath99 the last two inequalities give rise to the following statement .",
    "[ prop : fbcd_monotonicity ] for each @xmath92 , we have @xmath100 provided that @xmath101 .",
    "[ prop : fbcd_summability ] let @xmath102 furthermore , let @xmath103 . then , @xmath104    let @xmath105 be an integer .",
    "sum up and for @xmath106 and obtain @xmath107 by assumption , the expression on the left - hand side is bounded below by a fixed real number @xmath108 for any @xmath105 , and so is the right - hand side .",
    "the numbers @xmath109 and @xmath110 are bounded below by a positive number , say @xmath111 , so @xmath112 since @xmath113 is arbitrary , the series converge .",
    "[ prop : fbcd_clusterponts ] let @xmath103 and be satisfied .",
    "if @xmath114 and @xmath115 are bounded , then    1 .",
    "every cluster point of @xmath114 is a critical point of , 2 .",
    "every cluster point of @xmath115 is a critical point of and 3 .",
    "every cluster point of @xmath116 is a critical point of .",
    "let @xmath53 be a cluster point of @xmath114 .",
    "let @xmath117 be a subsequence of @xmath114 such that @xmath118 . by another transition to a subsequence",
    ", we can guarantee @xmath119 for some @xmath120 , since @xmath121 is bounded . by and ,",
    "we obtain , for every @xmath122 , @xmath123 respectively . by proposition [ prop : fbcd_summability ]",
    ", the first summands on the left - hand side of the above inclusions tend to zero as @xmath124 . using the continuity of @xmath125 and the closedness of the graphs of @xmath126 and @xmath127 and passing to the limit",
    ", we get @xmath128 and @xmath129 , which means that @xmath72 is a critical point of @xmath80 .",
    "the first statement follows by considering remark [ rem : critical ] . for the second statement",
    ", one has to choose @xmath53 and @xmath54 in reverse order , for the third one , they are chosen at the same time .",
    "it is clear that one can not expect the cluster points to be minima , since it is easy to see that @xmath72 is a fixed point of the iteration  if and only if and are satisfied , i.e. , if and only if @xmath72 is a critical point for @xmath80 ( independent of the choice of the parameters @xmath90 and @xmath91 ) .",
    "[ prop : fixed_points ] let be satisfied .",
    "for any @xmath92 , the following statements are equivalent :    1 .",
    "@xmath130 is a critical point of @xmath80 ; 2 .",
    "@xmath131 ; 3 .",
    "@xmath132 .",
    "it is easily seen by the formula that the first two items are equivalent .",
    "the equivalence of the latter two items follows by and .",
    "next , we summarise the convergence properties of the prox - prox algorithm . to this end , we denote by @xmath133 the set of cluster points of the iteration generated by and with the initial points @xmath134 and @xmath135 .",
    "see also ( * ? ? ?",
    "* lemma 5 ) for an analogous result for a nonconvex forward - backward scheme .",
    "[ lem : fbdc_properties ] let @xmath5 and @xmath33 be two real finite - dimensional hilbert spaces , let @xmath34 and @xmath35 be proper , convex and lower semicontinuous functions , let @xmath36 be a convex , frchet differentiable function with a @xmath37-lipschitz continuous gradient , for some @xmath136 , and let @xmath39 be a linear mapping .",
    "let the sequences @xmath90 and @xmath91 satisfy .",
    "moreover , assume that the sequence @xmath137 generated by and is bounded .",
    "then the following assertions hold :    1 .",
    "@xmath138 , 2 .",
    "@xmath139 , 3 .",
    "if the common optimal value of the problems , and is @xmath63 , then @xmath133 is a nonempty , compact and connected set , and so are the sets of the limit points of the sequences @xmath114 and @xmath115 , 4 .",
    "[ item : lem : fbdc_properties_const ] the objective function @xmath80 is finite and constant on @xmath133 provided that the optimal value is finite .",
    "it is clear that the set of cluster points of a bounded sequence is nonempty . that every cluster point is critical for @xmath80 , is the statement of proposition [ prop : fbcd_clusterponts ] .",
    "the last inclusion is discussed in remark [ rem : critical ] .",
    "2 .   assume that the assertion does not hold .",
    "in this case , there exists an @xmath111 and a subsequence @xmath140 of @xmath116 with @xmath141 for all @xmath122 .",
    "the subsequence is bounded , so it has a cluster point , which is a cluster point of the original sequence @xmath116 as well , thus an element of @xmath133 .",
    "this contradicts the assumption @xmath141 for all @xmath122 .",
    "3 .   since the sequence @xmath116 is bounded , the sets @xmath142 are bounded and closed , hence compact for any @xmath122 .",
    "their intersection @xmath143 , which equals the set of cluster points of @xmath116 , is therefore compact , too .",
    "the connectedness follows from proposition [ prop : fbcd_summability ] .",
    "see the proof of ( * ? ? ?",
    "* lemma 5 ( iii ) ) for the details .",
    "according to proposition [ prop : fbcd_monotonicity ] , the function values @xmath144 are monotonically decreasing , thus convergent , say @xmath145 .",
    "let @xmath72 be an arbitrary limit point of the sequence @xmath116 , and let @xmath140 be a subsequence converging to @xmath72 as @xmath124 . by lower semicontinuity , we have @xmath146 . on the other hand , consider with @xmath147 and @xmath148 .",
    "the right - hand side converges to @xmath149 as we let @xmath150 along the subsequence @xmath151 , so @xmath152 .    to guarantee the boundedness of the iterates",
    ", one could assume that the objective function of the primal - dual minimization problem is coercive , i.e. , the lower level sets are bounded .",
    "in the next step , we shall assume the kurdyka ",
    "ojasiewicz property for the functions involved .",
    "let us recall the definition and some basic properties .",
    "by @xmath153 , for @xmath154}}$ ] , we denote the set of all concave and continuous functions @xmath155 with the following properties :    1 .",
    "@xmath156 , 2 .",
    "@xmath157 is continuously differentiable on @xmath158 and continuous at @xmath149 , 3 .",
    "@xmath159 for all @xmath160 .",
    "let @xmath5 be a real finite - dimensional hilbert space , and let @xmath161 be a proper and lower semicontinuous function .",
    "we say that @xmath80 satisfies the _ kurdyka  ojasiewicz property _ at @xmath162 if there exists some @xmath154}}$ ] , a neighbourhood @xmath163 of @xmath53 and a function @xmath164 such that for all @xmath165 the following inequality holds @xmath166 we call @xmath80 a _ k function _ if it satisfies the kurdyka ",
    "ojasiewicz property at each point @xmath167 .",
    "the following uniform k property is according to ( * ? ? ?",
    "* lemma 6 ) .",
    "[ lem : uniform_kl ] let @xmath168 be a compact set , and let @xmath161 be a proper and lower semicontinuous function .",
    "assume that @xmath80 is constant on @xmath168 and satisfies the k property at each point of @xmath168 .",
    "then there exist @xmath111 , @xmath169 and @xmath164 such that for all @xmath170 and all @xmath171 in the intersection @xmath172 one has @xmath173    in the k property , we need the distance of a subgradient from zero . in our algorithm , we have the following result .",
    "[ lem : subgradient_estimation ] for each @xmath174 with @xmath175 , there exist @xmath176 with @xmath177 and @xmath178    from the definition of the algorithm , we have , for each @xmath179 , @xmath180 consider the function @xmath181 . by the usual calculus of the convex subdifferential and ( * ?",
    "* proposition 8.12 ) , for each @xmath179 @xmath182 by ( * ? ? ?",
    "* exercise 8.8 ) , we have for each @xmath179 @xmath183 thus , @xmath184 now , we estimate for each @xmath179 @xmath185 by the baillon",
    " haddad theorem ( * ? ? ?",
    "* corollary 18.16 ) , @xmath125 is @xmath186-cocoercive . by ( * ? ? ? * proposition 4.33 ) , @xmath187 is nonexpansive for @xmath175 , which leads to the desired conclusion .",
    "[ th1 ] let @xmath188 suppose that @xmath80 is in addition a k function bounded from below .",
    "then @xmath116 is a cauchy sequence , thus convergent to a critical point of @xmath80 .",
    "let @xmath189 , and let @xmath190 be the value of @xmath80 on @xmath168 ( see item [ item : lem : fbdc_properties_const ] of lemma [ lem : fbdc_properties ] ) . if @xmath191 for some @xmath98 , then , by and , @xmath192 and @xmath193 , and the assertion holds .",
    "therefore , we assume @xmath194 for all @xmath92 .    let @xmath111 , @xmath169 and @xmath164 be as provided by lemma [ lem : uniform_kl ] . since @xmath145 as @xmath195 , we find @xmath196 with @xmath197 for @xmath198 . since @xmath199 as @xmath195 , we find @xmath200 with @xmath201 for @xmath202 .",
    "in the following , fix an arbitrary @xmath203 .",
    "then @xmath130 is an element of the intersection .",
    "consequently , @xmath204 by the concavity of @xmath157 , we get , for all @xmath205 , @xmath206 so , setting in particular @xmath207 , @xmath208 moreover , by and , @xmath209 let us define the following shorthands @xmath210 for @xmath211 to obtain the inequality @xmath212 by the arithmetic - geometric inequality , for any @xmath213 and @xmath211 @xmath214 ( recall that , by proposition [ prop : fbcd_monotonicity ] and the properties of @xmath157 , the sequence @xmath215 is decreasing , so @xmath216 ) .",
    "on the other hand , by lemma [ lem : subgradient_estimation ] and the inequality @xmath217 ( @xmath218 ) , for any @xmath211 @xmath219 with @xmath220 for all @xmath211 , @xmath221 combined with , we obtain @xmath222 for any @xmath223 , we have , by iteration , @xmath224 therefore , for any @xmath225 and @xmath226 , @xmath227 the right - hand side does not depend on @xmath113 , thus , we conclude that @xmath228 is finite , and so are @xmath229 and @xmath230 .",
    "assume that @xmath80 is a k function with @xmath231 for some @xmath232 and @xmath233 .",
    "let @xmath53 and @xmath54 the limit points of the sequences @xmath114 and @xmath115 , respectively ( which exist due to theorem [ th1 ] ) .",
    "then the following convergence rates are guaranteed :    1 .   if @xmath234 , then there exists @xmath235 , such that @xmath236 and @xmath237 for @xmath211 ; 2 .   if @xmath238 , then there exist @xmath239 and @xmath240 such that @xmath241 for all @xmath98 ; 3 .   if @xmath242 , then there exists @xmath239 such that @xmath243 for all @xmath98 .    1 .",
    "first , let @xmath234 .",
    "assume to the contrary ( see proposition [ prop : fixed_points ] ) that for any @xmath98 , @xmath244 .",
    "we have @xmath245 for all @xmath246 and thus , by , @xmath247 which contradicts either lemma [ lem : subgradient_estimation ] or proposition [ prop : fbcd_summability ] .    before considering the other cases , assume from now on that @xmath130 is not a critical point of @xmath80 for any @xmath92 .",
    "notice that @xmath248 . in the proof of theorem [ th1 ]",
    ", we have shown that for @xmath249 @xmath250 where the last inequality follows from the k property ( notice that @xmath251 because we assumed that @xmath252 is not a critical point of @xmath80 ) .",
    "we can repeat this calculation for any @xmath253 instead of @xmath254 , because such an @xmath255 would meet the criteria according to which we chose @xmath254 .",
    "thus , we obtain from , for @xmath253 , @xmath256 the rest of the proof follows in the lines of ( * ? ? ?",
    "* theorem 2 ) :    1 .",
    "let @xmath238 . then @xmath257 , so @xmath258 as @xmath150 implies that the first term on the right - hand side of is the dominant one . therefore , we find @xmath259 and @xmath260 such that @xmath261 for any @xmath198 .",
    "thus , for any @xmath198 , @xmath262 by induction , for any @xmath263 , @xmath264 which proves the assertion .",
    "2 .   let @xmath242 . then @xmath265 , so @xmath258 as @xmath150 implies that the second term on the right - hand side of is the dominant one . therefore , we find @xmath259 and @xmath260 such that @xmath266 for any @xmath198 .",
    "then , for any @xmath198 , @xmath267 we define @xmath268 , @xmath269 and notice that @xmath56 is monotonically decreasing as is the sequence @xmath270 .",
    "therefore , for any @xmath198 , @xmath271 thus , by induction , for any @xmath263 , @xmath272 the assertion follows by @xmath273",
    "consider an image of the size @xmath274 pixels .",
    "( for the sake of simplicity , we consider gray - scale pictures only . ) it can be represented by a vector @xmath275 of size @xmath276 with entries in @xmath277}}$ ] ( where @xmath149 represents pure black and @xmath278 represents pure white ) .    the original image @xmath45 is assumed to be blurred by a linear operator @xmath279 ( e.g. the camera is out of focus or in movement during the exposure ) .",
    "furthermore , it is corrupted with a noise @xmath280 , so that only the result @xmath281 is known to us . we want to reconstruct the original image @xmath282 by considering the minimisation problem @xmath283 where @xmath284 denotes the usual euclidean norm , @xmath285 is a regularisation parameter , @xmath286 is the discrete gradient operator given by @xmath287 , where @xmath288 and @xmath289 is a regularising functional penalising noisy images .",
    "we want to compare several choises of the functional @xmath290 proposed by @xcite , all of which have in common that they want to induce sparsity of @xmath291 , i.e. having many components equal to zero .",
    "the _ smoothly clipped absolute deviation _",
    "( scad ) penalty was introduced by fan and li in @xcite .",
    "it is defined by @xmath292 where @xmath293 , @xmath294 and @xmath295 denoting the part after the curly brace as @xmath296 and @xmath297 , we have @xmath298    the _ zhang penalty _ @xcite is defined by @xmath299 where @xmath300 and @xmath301 denoting the part after the curly brace as @xmath302 and @xmath303 , we have @xmath304    the _ lzox penalty _ @xcite is defined by @xmath305 where @xmath306 denotes ( as usual ) the sum of the absolute values and @xmath307 where @xmath308 is the splitting according to the definition of @xmath309 .",
    "the algorithm  can now be applied to any of the models described above , since the models are written as d. c. problems and the components are easily accessible for computation , with the exception of the function @xmath310 , see @xcite . for the latter , see the following section .      in order to apply algorithm  to any of the problems",
    ", we have to calculate the proximal point of the anisotropic total variation by solving the optimization problem @xmath311 for some @xmath21 and @xmath312 in each step . the fenchel dual problem ( * ? ? ?",
    "* chapter 19 ) is given by @xmath313 instead of solving , we could also solve ( see @xcite ) , as the following result shows .",
    "let @xmath314 be a solution of .",
    "then @xmath315 is a solution of .",
    "see ( * ? ? ?",
    "* example 19.7 ) . in short : @xmath316    to the formulation , the forward - backward algorithm can be applied , since the objective function is differentiable and the feasible set is easy to project on .",
    "we implemented the fbdc algorithm applied to the model described above and tested the matlab code on a pc with intel core i5 4670s ( @xmath317 3.10ghz ) and 8 gb ddr3 ram ( 1600mhz ) .",
    "our implementation used the method described in section [ sec : submethod ] until the @xmath318 distance between two iterations was smaller than @xmath319 .",
    "both stepsizes were chosen as @xmath320 for all @xmath92 .",
    "as initial value , we chose @xmath321 and picked @xmath322 .",
    "we picked the image ` texmos3 ` from http://sipi.usc.edu/database/database.php?volume=textures&image=64 and convolved it with a gaussian kernel with 9 pixels standard devitation .",
    "afterwards we added white noise with standard deviation @xmath323 , projected the pixels back to the range @xmath277}}$ ] and saved the image in tiff format , rounding the brightness values to multiples of @xmath324 .",
    "see figure [ fig : images_lzox ] for original , blurry and reconstructed image .",
    "the _ improvement in signal - to - noise ratio _ or _ isnr value _ of a reconstruction is given by @xmath325 where @xmath282 is the ( usually unknown ) original , @xmath326 is the known blurry and noisy and @xmath327 is the reconstructed image . for the isnr values after 50 iterations , see tables [ tab : lzox ] and [ tab : zhang ] .",
    "the development of the isnr values over the iterations is shown in figure [ fig : development ] .",
    "we see that the nonconvex models provide reasonable reconstructions of the original image and the best numerical performance for this particular choice of the stepsizes and the number of iterations is not achieved for the convex model ( lzox with @xmath328 ) , but for the nonconvex models .",
    ".lzox after 50 iterations [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]",
    "the authors are grateful to joseph salmon for pointing their attraction on the paper @xcite .",
    "hdy attouch , jrme bolte , and benar fux svaiter . convergence of descent methods for semi - algebraic and tame problems : proximal algorithms , forward - backward splitting , and regularized gauss - seidel methods .",
    ", 137(1 - 2):91129 , february 2013 ."
  ],
  "abstract_text": [
    "<S> the possibilities of exploiting the special structure of d.c . programs , which consist of optimizing the difference of convex functions , are currently more or less limited to variants of the dca proposed by pham dinh tao and le thi hoai an in 1997 . </S>",
    "<S> these assume that either the convex or the concave part , or both , are evaluated by one of their subgradients .    </S>",
    "<S> in this paper we propose an algorithm which allows the evaluation of both the concave and the convex part by their proximal points . </S>",
    "<S> additionally , we allow a smooth part , which is evaluated via its gradient . in the spirit of primal - dual splitting algorithms , the concave part might be the composition of a concave function with a linear operator , which are , however , evaluated separately .    for this algorithm </S>",
    "<S> we show that every cluster point is a solution of the optimization problem . </S>",
    "<S> furthermore , we show the connection to the toland dual problem and prove a descent property for the objective function values of a primal - dual formulation of the problem . convergence of the iterates is shown if this objective function satisfies the kurdyka  </S>",
    "<S> ojasiewicz property . in the last part </S>",
    "<S> , we apply the algorithm to an image processing model .    </S>",
    "<S> * key words . * </S>",
    "<S> d.c . </S>",
    "<S> programming , toland dual , proximal - gradient algorithm , kurdyka  </S>",
    "<S> ojasiewicz property , convergence analysis    * ams subject classification . </S>",
    "<S> * 90c26 , 90c30 , 65k05 </S>"
  ]
}