{
  "article_text": [
    "we are happy to help celebrate stein s stunning , deep and significant contribution to the statistical literature . in 1956 ,",
    "charles stein ( @xcite ) proved a  result that astonished many and was the catalyst for an enormous and rich literature of substantial importance in statistical theory and practice .",
    "stein showed that when estimating , under squared error loss , the unknown mean vector @xmath0 of a @xmath1-dimensional random vector @xmath2 having a normal distribution with identity covariance matrix , estimators of the form @xmath3 dominate the usual estimator @xmath0 , @xmath2 , for @xmath4 sufficiently small and @xmath5 sufficiently large when @xmath6 .",
    "james and stein ( @xcite ) sharpened the result and gave an explicit class of dominating estimators , @xmath7 for @xmath8 , and also showed that the choice of @xmath9 ( the james  stein estimator ) is uniformly best . for future reference recall that `` the usual estimator , '' @xmath2 , is a  minimax estimator for the normal model , and more generally for any distribution with finite covariance matrix.=1    stein ( @xcite ) , considering general estimators of the form @xmath10 , gave an expression for the risk of these estimators based on a key lemma , which has come to be known as stein s lemma .",
    "numerous results on shrinkage estimation in the general spherically symmetric case followed based on some generalization of stein s lemma to handle the cross product term @xmath11 $ ] in the expression for the risk of the estimator .",
    "a substantial number of papers for the multivariate normal and nonnormal distributions have been written over the decades following stein s monumental results . for an earlier expository development of stein estimation for nonnormal location models see brandwein and strawderman ( @xcite ) .",
    "this paper covers the development of stein estimation for spherically symmetric distributions since brandwein and strawderman ( @xcite ) .",
    "it is not encyclopedic , but touches on only some of the significant results for the nonnormal case .    given an observation , @xmath2 , on a @xmath1-dimensional spherically symmetric multivariate distribution with unknown mean , @xmath0 and whose density is @xmath12 ( for @xmath13 ) , we will consider the problem of estimating @xmath0 subject to the squared error loss function , that is , @xmath14 is a measurable ( vector - valued ) function , and the loss given by @xmath15 where @xmath16 and @xmath17.the risk function of @xmath18 is defined as @xmath19 unless otherwise specified , we will be using the loss defined by ( [ eq11 ] ) .",
    "other loss functions such as the loss @xmath20 will be occasionally used , especially when there is also an unknown scale parameter , and minimaxity , as opposed to domination , is the main object of study .",
    "we will have relatively little to say about the important case of confidence set loss , or of loss estimation .",
    "in section [ sec2 ] we provide some additional intuition as to why the stein estimator of the mean vector @xmath0 makes sense as an approximation to an optimal linear estimator and as an empirical bayes estimator in a general location problem .",
    "the discussion indicates that normality need play no role in the intuitive development of stein - type shrinkage estimators .",
    "section [ sec3 ] is devoted to finding improved estimators of @xmath0 for spherically symmetric distributions with a known scale parameter using results of brandwein and strawderman ( @xcite ) and berger ( @xcite ) to bound the risk of the improved general estimator @xmath21 .",
    "section [ sec4 ] considers estimating the mean vector for a general spherically symmetric distribution in the presence of an unknown scale parameter , and , more particularly , when a residual vector is available to estimate the scale parameter .",
    "it extends some of the results from section [ sec3 ] to this case as well as presenting new improved estimators for this problem .",
    "the results in this section indicate a remarkable robustness property of stein - type estimators in this setting , namely , that certain of the improved estimators dominate @xmath2 uniformly for all spherically symmetric distributions simultaneously ( subject to risk finiteness ) .    in section [ sec5 ] we consider the restricted parameter space problem , particularly the case where @xmath0 is restricted to a polyhedral cane , or more generally a  smooth cone .",
    "the material in this section is adapted from fourdrinier , strawderman and wells ( @xcite ) .",
    "in section [ sec6 ] we consider some of the advancements in bayes estimation of location vectors for both the known and unknown scale cases .",
    "we present an intriguing result of maruyama maruyama ( @xcite)which is related to the ( distributional ) robustness of stein estimators in the unknown scale case treated in section  [ sec4 ] .",
    "section [ sec7 ] contains some concluding remarks .",
    "we begin by adding some intuition as to why stein estimation is both reasonable and compelling , and refer the reader to brandwein and strawderman ( @xcite ) for some earlier developments .",
    "the reader is also referred to stigler ( @xcite ) and to meng ( @xcite ) .",
    "the following is a very simple intuitive development for optimal linear estimation of the mean vector in @xmath22 that leads to the stein estimator .",
    "suppose @xmath23 = \\theta$ ] , @xmath24 ( @xmath25 known ) , and consider the linear estimator of the form @xmath26 .",
    "what is the optimal value of @xmath4 ?",
    "the risk is given by @xmath27 and the derivative , with respect to @xmath4 , is @xmath28 hence , the optimal @xmath4 is @xmath29 and the optimal `` estimator '' is @xmath30 , which is , of course , not an estimator because it depends on @xmath0",
    ".    however , @xmath31 = p \\sigma^ 2 + \\|\\theta\\|^2 $ ] , so @xmath32 is a  reasonable estimator of @xmath33 .",
    "hence , an approximation to the optimal linear `` estimator '' is @xmath34 which is the james  stein estimator except that @xmath1 replaces @xmath35 .",
    "note that as  @xmath1 gets larger , @xmath36 is likely to improve as an estimator of @xmath37 and , hence , we may expect that the dimension , @xmath1 , plays a role .",
    "strawderman ( @xcite ) considered the following general location model .",
    "suppose @xmath38 , where @xmath23 = \\theta$ ] , @xmath39 ( @xmath40 known ) but that @xmath41 is otherwise unspecified .",
    "also assume that the prior distribution for @xmath0 is given by @xmath42 , the @xmath43 fold convolution of @xmath41 with itself .",
    "hence , the prior distribution of @xmath0 can be represented as the distribution of a sum of  @xmath43 i.i.d .",
    "variables @xmath44 , where each @xmath45 is distributed as @xmath46 . also , the distribution of @xmath47 has the same distribution and is independent of the other @xmath45 s .",
    "the bayes estimator can therefore be thought of  as @xmath48 = e[\\theta|x - \\theta + \\theta ] \\\\ & = & e\\biggl[\\sum_{i = 1}^n u_i \\big| \\sum_{i = 0}^n u_i \\biggr]\\end{aligned}\\ ] ] and , hence , @xmath49 } \\\\ & = & \\frac{n}{n + 1}e\\biggl[\\sum_{i = 0}^n u_i \\big|\\sum_{i = 0}^n u_i\\biggr ] \\\\ & = & \\frac{n}{n + 1 } e[x|x ] = \\frac{n}{n + 1}x\\end{aligned}\\ ] ] or , equivalently , @xmath50 = ( 1 - 1/\\{n+1\\})x$ ] .",
    "assuming that @xmath43 is unknown , we may estimate it from the marginal distribution of @xmath2 , which has the same distribution as @xmath51 . in particular , @xmath52 & = & e\\biggl [ \\biggl\\|\\sum_{i = 0}^n { u_i } \\biggr\\| ^2 \\biggr ] \\\\ & = & \\sum_{i = 0}^n e [ \\| u_i \\|^2 ] = ( n + 1)p\\sigma^2,\\end{aligned}\\ ] ] since @xmath53 = 0 $ ] and @xmath54 , @xmath55=p\\sigma^2 $ ] .",
    "therefore , @xmath56 can be estimated by @xmath57 . substituting this estimator of @xmath56 in the expression for",
    "the bayes estimator , we have an empirical bayes estimator @xmath58 which is again the james  stein estimator , save for the substitution of @xmath1 for @xmath35 .",
    "note that in both of the above developments , the  only assumptions were that @xmath59 and@xmath39 .",
    "the stein - type estimator thus appears intuitively , at least , to be a reasonable estimator in a  general location problem .",
    "let @xmath60 , the loss be @xmath61 so the risk is @xmath62 $ ] .",
    "suppose an estimator has the general form @xmath21",
    ". then @xmath63 \\\\ & = & e_{\\theta } [ \\| x + \\sigma^2 g ( x ) - \\theta\\|^2 ] \\\\ & = & e_\\theta [ \\|x - \\theta\\|^2 ] + \\sigma^4 e_\\theta[\\| g(x ) \\|^2]\\\\ & & { } + 2\\sigma^2 e_{\\theta } [ ( x-\\theta)'g(x)].\\end{aligned}\\ ] ] in the normal case , stein s lemma , given loosely as follows , is used to evaluate the last term .",
    "[ lem31 ] if @xmath64,then @xmath65 = \\sigma^2 e_{\\theta } [ \\nabla'g(x)]$ ] [ where @xmath66 denotes the gradient of @xmath67 , provided , say , that @xmath68 is continuously differentiable and that all expected values exist .",
    "the proof is particularly easy in one dimension , and is a simple integration by parts . in higher dimensions",
    "the proof may just add the one - dimensional components or may be a bit more sophisticated and cover more general functions , @xmath68 . in the most general version known to us , the proof uses stokes theorem and requires @xmath69 to be weakly differentiable .    using the stein lemma",
    ", we immediately have the following result .",
    "[ prop31 ] if @xmath70 , then @xmath71 + \\sigma^4 e_{\\theta}[\\|g(x)\\|^2 + 2 \\nabla'g(x)]\\end{aligned}\\ ] ] and , hence , provided the expectations are finite , a  sufficient condition for @xmath14 to dominate @xmath2 is @xmath72 a.e .",
    "( with strict inequality on a set of positive measures ) .",
    "the key to most of the literature on shrinkage estimation in the general spherically symmetric case is to find some generalization of ( or substitution for ) stein s lemma to evaluate ( or bound ) the cross product term @xmath73 $ ] .",
    "we indicate two useful techniques below .",
    "brandwein and strawderman ( @xcite ) extended the results of stein ( @xcite ) to spherically symmetric distributions for estimators of the form @xmath74 .",
    "the following two preliminary lemmas are necessary to prove the result in theorem [ thmm31 ] .",
    "[ lem32 ] let @xmath2 have a distribution that is spherically symmetric about @xmath75",
    ". then @xmath76 \\\\ & & \\quad = p^{-1}r^2\\mathrm{ave}_{b(r,\\theta ) } \\nabla'g(x),\\end{aligned}\\ ] ] provided @xmath77 is weakly differentiable .",
    "notation for this lemma : @xmath78and  @xmath79 are , respectively , the ( surface of the ) sphere and ( solid ) ball , of radius @xmath80 centered at @xmath0 .",
    "note also that @xmath81 is the unit outward normal vector at @xmath2 on @xmath78 .",
    "also @xmath82 is the area measure on  @xmath78 , while @xmath83 and @xmath84 denote area and volume , respectively .",
    "since the conditional distribution of @xmath85 given @xmath86 is uniform on the sphere of radius @xmath80 , it follows that @xmath87 \\\\ & & \\quad= \\operatorname{ave}_{s(r,\\theta ) } \\{(x - \\theta)'g(x)\\ } \\\\ & & \\quad= \\frac{r}{{a(s(r,\\theta ) ) } } \\oint_{s(r,\\theta ) } \\frac{(x - \\theta)'g(x)}{r } \\,d\\sigma(x ) \\\\ & & \\quad = \\frac{r}{a(s(r,\\theta ) ) } \\int_{b(r,\\theta ) } \\nabla'g(x ) \\,dx\\\\ & & \\hspace*{86pt}\\qquad { } \\biggl(\\mbox{since } \\frac{v(b(r,\\theta))}{a(s(r,\\theta ) ) } = r / p\\biggr)\\\\ & & \\quad = \\frac{r^2 } { pv(b(r,\\theta ) ) } \\int_{b(r,\\theta ) } { \\nabla'g(x ) } \\,dx\\\\ & & \\hspace*{119pt}\\qquad { } ( \\mbox{by stokes ' theorem } ) \\\\ & & \\quad = p^{-1}r^2 \\operatorname{ave}_{b(r,\\theta ) } \\nabla'g(x).\\end{aligned}\\ ] ]    the following result is basic to the study of superharmonic functions and is well known ( see , e.g. , du  plessis , @xcite , page  54 ) .",
    "[ lem33 ] let @xmath88 be superharmonic on @xmath89 , [ i.e. , @xmath90 , then @xmath91 .    consider , now , an estimator of the general form @xmath92 , where @xmath4 is a scalar , and @xmath93 maps .",
    "[ thmm31 ] let @xmath2 have a distribution that is spherically symmetric about @xmath0 . assume the following :    1 .",
    "@xmath94 , [ as1thmm31 ] 2 .",
    "@xmath95 is superharmonic , @xmath96 $ ] is nonincreasing in @xmath80 for each @xmath0 , where @xmath97 has a uniform distribution on @xmath98 , [ as2thmm31 ] 3 .",
    "@xmath99\\}$].[as3thmm31 ]    then @xmath92 is minimax with respect to quadratic loss , provided @xmath69 is weakly differentiable and all expectations are finite .",
    "@xmath100 \\bigr ] \\\\ & & \\quad \\le e\\bigl [ e_\\theta [ - 2a^2 h(x)\\\\ & & \\hspace*{28pt}\\qquad { } + 2a(x - \\theta)'g(x )    & & \\quad = e\\bigl [ e_\\theta [ - 2a^2 h(x ) | \\|x - \\theta\\|^2 = r^2 ] \\\\ & & \\quad\\qquad { } + 2ae[\\{r^2/p\\ } \\operatorname{ave}_{b(r,\\theta ) } \\nabla'g(x ) | r^2 ] \\bigr ] \\\\ & & \\quad \\le e\\bigl [ e_\\theta [ - 2a^2 h(x ) | \\|x - \\theta\\|^2 = r^2 ] \\\\ & & \\quad\\hspace*{10pt}\\qquad { } + 2ae_\\theta [ \\{r^2/p\\}e_\\theta h(w ) | r^2 ] \\bigr ] \\\\ & & \\quad \\le e\\bigl [ e_\\theta [ - 2a^2 h(w ) | r^2 ] \\\\ & & \\quad\\qquad{}+ 2ae_\\theta [ \\{r^2/p\\}e_\\theta h(w ) | r^2 ] \\bigr ] \\\\ & & \\hspace*{142pt}\\qquad{}(\\mbox{by lemma \\ref{lem33 } } ) \\\\ & & \\quad = 2ae\\bigl [ e_\\theta [ r^2 h(w ) | r^2 ] ( -a / r^2 + 1/p ) \\bigr ] \\\\ & & \\quad = 2ae [ e_\\theta [ r^2 h(w ) | r^2 ] ] e[-a / r^2 + 1/p ] \\\\ & & \\quad \\le0\\end{aligned}\\ ] ]    by the covariance inequality since @xmath101 $ ] is nonincreasing and @xmath102 is increasing and since @xmath103 .",
    "[ exam31 ] james  stein estimators @xmath104 $ ] : in this case both @xmath105 and @xmath106 are equal to @xmath107",
    ". conditions  1 and 2 of theorem [ thmm31 ] are satisfied for @xmath108 , provided @xmath109 since @xmath110 is superharmonic if @xmath109 , and since @xmath111 =   e_{\\theta / r } [ 1/\\allowbreak\\|x\\|^2]$ ] is increasing by anderson s theorem .    hence , by condition 3 , for any spherically symmetric distribution , the james  stein estimator @xmath112 is minimax  for @xmath113\\}$ ] and @xmath114 .",
    "the domination over @xmath2 is strict  for @xmath115\\}$ ] , and also for @xmath116\\}$ ] , provided the distribution is not normal .",
    "baranchik ( @xcite ) , for the normal case , considered estimators of the form @xmath117 under certain conditions on @xmath118 . under the assumption that @xmath118 is monotone nondecreasing , bounded between @xmath119 and @xmath120 , and concave , theorem [ thmm31 ] applies to these estimators as well , and establishes minimaxity for @xmath121\\}$ ] and for @xmath114 .",
    "we note in passing that the results in this subsection hold for an arbitrary spherically symmetric distribution with or without a density .",
    "the calculations rely only on the distribution of @xmath2 conditional on @xmath122 , and , of course , finiteness of @xmath123 $ ] and @xmath124 $ ] .",
    "[ subsec32 ] berger ( @xcite ) gave a useful expression for the risk of a james  stein estimator which is easily generalized to the case of a general estimator , provided the spherically symmetric distribution has a density  @xmath125 .",
    "some form of this generalization ( and extensions to unknown scale case and the elliptically symmetric case ) has been used by several authors , including fourdrinier , strawderman and wells ( @xcite ) , fourdrinier , kortbi and strawderman ( @xcite ) , fourdrinier and strawderman ( @xcite ) , maruyama ( @xcite ) and kubokawa and srivastava ( @xcite ) , among others .",
    "[ lem34 ] suppose @xmath126 , and let @xmath127 and @xmath128 .",
    "then @xmath129\\\\ & & \\qquad{}+ e_\\theta [ \\| { g(x ) } \\|^2 + 2q(\\| x-\\theta\\|^2 ) \\nabla'g(x)].\\end{aligned}\\ ] ]    the lemma follows immediately with the following identity for the cross product term : @xmath130\\\\ & & \\quad= \\int_{r^p } ( x - \\theta)'g(x)f(\\|x - \\theta\\|^2)\\,dx \\\\ & & \\quad= \\int_{r^p } g(x)'\\nabla f(\\|x - \\theta\\|^2 ) \\,dx\\\\ & & \\quad= \\int_{r^p } \\nabla'g(x)f(\\|x - \\theta\\|^2 ) \\,dx \\vadjust{\\goodbreak}\\\\ & & \\hspace*{96pt}\\qquad(\\mbox{by green 's theorem } ) \\\\ & & \\quad= e [ q(\\|x - \\theta\\|^2)\\nabla'g(x)].\\end{aligned}\\ ] ]    berger ( @xcite ) , maruyama ( @xcite ) and fourdrinier , kortbi and strawderman ( @xcite ) used the above result for distributions for which @xmath131 is bounded below by a positive constant . in this case",
    ", the next result follows immediately from lemma  [ lem34 ] .",
    "[ thmm32 ] @xmath132suppose @xmath133 , and  that @xmath134",
    ". then the estimator @xmath135 dominates @xmath2 provided @xmath136 for all @xmath137 .    as noted by berger ( @xcite ) ,",
    "if @xmath41 is a scale mixture of normals , then @xmath131 is bounded below . to see this ,",
    "note that if @xmath138and @xmath139 , then @xmath140 .",
    "similarly , @xmath141 hence , @xmath142",
    "\\ge e_0 [ v ] = \\frac{\\int_0^\\infty v^{1 - p/2 } g(v)\\,dv } { \\int_0^\\infty v^ { - p/2 } g(v)\\,dv } \\\\ & = & \\frac{e[v^{1-p/2}]}{e[v^{-p/2 } ] } = c > 0,\\end{aligned}\\ ] ] where @xmath143 denotes expectation with respect to the density proportional to @xmath144 .",
    "the inequality follows since the family has monotone likelihood ratio in @xmath145 .",
    "hence , for the james  stein class @xmath7 , this result gives dominance over @xmath2 for @xmath146}{e[v^ { - p/2 } ] } \\le0\\ ] ] or @xmath147}{e[v^ { - p/2 } ] } .\\ ] ] this bound on the shrinkage constant , @xmath4 , compares poorly with that obtained by strawderman ( @xcite ) , @xmath148 $ ] , which may be obtained by using stein s lemma conditional on @xmath149 and the fact that @xmath150 $ ] is monotone nondecreasing in @xmath149 .",
    "note that , again by monotone likelihood ratio properties ( or the covariance inequality),@xmath151)^{-1 } > e[v^{1 - p/2 } ] /e[v^ { - p/2 } ] $ ] .",
    "it is therefore somewhat surprising that maruyama ( @xcite ) and fourdrinier , kortbi and strawderman ( @xcite ) were able to use theorem [ thmm32 ] , applied to baranchik - type estimators , to obtain generalized and proper bayes minimax estimators . without going into details",
    ", the advantage of the cruder bound is that it requires only that @xmath152 be monotone , while strawderman s result for mixtures of normal distributions also requires that @xmath153 be monotone decreasing .",
    "other applications of lemma [ lem34 ] give refinedbounds on the shrinkage constant in the james  stein or baranchik estimator depending on monotonicity properties of @xmath131 .",
    "typically , additional conditions are required on the function @xmath152 as well .",
    "see , for example , brandwein , ralescu and strawderman ( @xcite ) ( the calculations in that paper are somewhat different than those in this section , the basic idea is quite similar )",
    ".    applications of the risk expression in lemma [ lem34 ] are complicated relative to those in the normal case using stein s lemma , in that the mean vector , @xmath0 , remains to complicate matters through the function @xmath154 .",
    "it is both surprising and interesting that matters become essentially simpler ( in a certain sense ) when the scale parameter is unknown , but a residual vector is available .",
    "we investigate this phenomenon in the next section .",
    "[ sec4 ] in this section we study the model @xmath155 , where @xmath156 , and @xmath157 .",
    "the classical example of this model is , of course , the normal model @xmath158 .",
    "however , a variety of other models have proven useful .",
    "perhaps the most important alternatives to the normal model in practice and in theory are the generalized distributions @xmath159 or , more generally , scale mixture of normals of the form @xmath160    these models preserve the spherical symmetryabout the mean vector and , hence , the covariance matrix is a multiple of the identity .",
    "thus , the coordinates are uncorrelated , but they are not independent except for the case of the normal model .",
    "we look ( primarily ) at estimators of the form @xmath161 .",
    "the main result may be interpreted as follows : if , when @xmath162 ( @xmath40 known ) , the estimator @xmath163 dominates @xmath2 , then , under the model @xmath164 , the estimator @xmath165 dominates @xmath2 . that is , substituting the estimator @xmath166 for @xmath40 preserves domination uniformly for all parameters @xmath167 and ( somewhat astonishingly ) simultaneously for all distributions , @xmath41 .",
    "note that , interestingly , @xmath166 is the minimum risk equivariant estimator of @xmath40 in the normal case under the usual invariant loss .",
    "this wonderful result is due to cellier and fourdrinier ( @xcite ) .",
    "we refer the reader to their paper for the original proof based on stokes theorem applied to the distribution of @xmath2 conditional on @xmath168 .",
    "one interesting aspect of that proof is that even if the original distribution has no density , the conditional distribution of @xmath2 does have a density for all @xmath169 .",
    "we will approach the above result from two different directions .",
    "the first approach is essentially an extension of lemma [ lem34 ] . as in that case ,",
    "the resulting expression for the risk still involves both the data and @xmath0 inside the expectation , but the function @xmath170 is a common factor .",
    "this allows the treatment of the remaining terms as if they are an unbiased estimate of the risk difference .",
    "the second approach is due to fourdrinier , strawderman and wells ( @xcite ) , and is attractive because it is essentially statistical in nature , depending on completeness and sufficiency .",
    "it may be argued also that this approach is somewhat more general in that it may be useful even when the function @xmath77 is not necessarily weakly differentiable . in this case",
    "an unbiased estimator of the risk difference is obtained which agrees with that in cellier and fourdrinier ( @xcite ) .",
    "this is in contrast to the above method  whereby the expression for the risk difference still has a  factor @xmath171 inside the expectation .",
    "@xmath172technically , our use of the term `` unknown scale '' is somewhat misleading in that the scale parameter may , in fact , be known .",
    "we typically think of @xmath41 as being a known density , which implies that the scale is known as well .",
    "it may have been preferable to write the density as @xmath173 , emphasizing the unknown scale parameter .",
    "this is more in keeping with the usual canonical form of the general linear model with spherically symmetric errors .",
    "what is of fundamental importance is the presence of the residual vector , @xmath174 , in allowing uniform domination over the estimator  @xmath2 simultaneously for the entire class of spherically symmetric distributions .",
    "since the suppression of the scale parameter makes notation a bit simpler , we will , for the most part , use the above notation in this section .",
    "additionally , we continue to use the un - normalized loss , @xmath175 , and state results in terms of dominance over @xmath2 instead of minimaxity , since the minimax risk is infinite . in order to speak meaningfully of minimaxity in the unknown scale case",
    ", we should use a normalized version of the loss , such as @xmath176 .",
    "[ lem41 ] @xmath132suppose @xmath177 , where @xmath178 , @xmath179 .",
    "then , provided @xmath180 is weakly differentiable in each coordinate :    1 .   @xmath181 = e_\\theta[\\|u\\|^2 \\nabla'_x g(x,\\break \\|u\\|^2 ) q(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ] $ ] .",
    "[ 1lem41 ] 2 .",
    "@xmath182=e_\\theta[h(x,\\|u\\| ^2)\\cdot   q(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ] $ ] , [ 2lem41 ] where @xmath183 and @xmath184    the proof of part 1 is essentially the same as the proof of lemma [ lem34 ] , holding @xmath174 fixed throughout .",
    "the same is true of part 2 , where the roles of @xmath2 and @xmath174 are reversed and one notes that @xmath185 which is given by ( [ eq41 ] ) , and , hence , @xmath186\\\\ & & \\quad= e_\\theta [ ( \\|u\\|^2 u)'u \\|g(x,\\|u\\|^2)\\|^2 ] \\\\ & & \\quad = e_\\theta [ \\nabla'_u \\{(\\|u\\|^2 u)\\|g(x,\\|u\\|^2 ) \\|^2 \\ } \\\\ & & \\hspace*{44pt}\\qquad{}\\cdot q(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ] \\\\ & & \\quad= e_\\theta [ h(x,\\|u\\|^2 ) q(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ] .\\end{aligned}\\ ] ]    one version of the main result for estimators of the form @xmath187 is the following theorem .    [ thmm41 ] suppose ( x , u ) is as in lemma  [ lem41 ] . then :    1",
    ".   the risk of an estimator @xmath188 is given by @xmath189\\\\ & & \\qquad{}+ e_\\theta \\biggl[\\frac{{\\|u\\|^2 } } { { k + 2}}\\{\\|g(x)\\|^2 + 2\\nabla'g(x)\\ } \\\\ & & \\hspace*{52pt}\\qquad{}\\cdot q(\\|x - \\theta\\|^2 +",
    "\\|u\\|^2 ) \\biggr],\\end{aligned}\\ ] ] 2 .",
    "@xmath190 dominates @xmath2 provided @xmath191 .",
    "note that @xmath192 & & \\quad= e_\\theta[\\|x - \\theta\\|^2 ] \\\\[-1pt ] & & \\qquad{}+ e_\\theta\\biggl [ \\frac{{\\|u\\|^4 } } { { ( k + 2)^2 } } \\|g(x)\\|^2 \\\\[-1pt ] & & \\hspace*{30pt}\\qquad{}+ 2\\frac{{\\|u\\|^2 } } { { k + 2}}(x - \\theta)'g(x ) \\biggr ] \\\\[-1pt ] & & \\quad= e_\\theta [ \\|x - \\theta\\|^2 ] \\\\[-1pt ] & & \\qquad{}+ e_\\theta \\biggl [ \\{\\|g(x)\\|^2 + 2\\nabla'g(x)\\ } \\\\[-1pt ] & & \\hspace*{28pt}\\qquad{}\\cdot \\frac{\\|u\\|^2q(\\|x - \\theta\\|^2 + \\|u\\|^2)}{k+2 } \\biggr]\\end{aligned}\\ ] ] by successive application of parts 1 and 2 of lemma  [ lem41 ] .    baranchik - type estimators : suppose the estimator is given by @xmath193 , where @xmath152 is nondecreasing , and @xmath194 , then for @xmath195 the estimator dominates @xmath2 simultaneously for all spherically symmetric distributions for which the risk of @xmath2 is finite .",
    "this follows since , if @xmath196,then @xmath197    james  stein estimators : if@xmath198 , the baranchik estimator is a james  stein estimator , and , since @xmath199 , the risk is given by @xmath200 + \\frac{a^2 - 2a(p - 2)}{k+2}\\\\[1pt ] & & \\hspace*{64pt}\\quad{}\\cdot e\\biggl [ \\frac{\\|u\\|^2}{\\|x\\|^2 } q(\\|x - \\theta\\|^2 + \\|u\\|^2 ) \\biggr].\\end{aligned}\\ ] ] just as in the normal case , @xmath201 is the uniformly best choice to minimize the risk .",
    "but here it is the uniformly best choice for every distribution .",
    "hence , the estimator @xmath202 is uniformly best , simultaneously for all spherically symmetric distributions among the class of james  stein estimators !    a more refined version of theorem [ thmm41 ] which uses the full power of lemma [ lem41 ]",
    "is proved in the same way .",
    "we give it for completeness and since it is useful in the study of risks of bayes estimators .",
    "[ thmm42 ] suppose @xmath203 is as in lemma  [ lem41 ] .",
    "then , under suitable smoothness conditions on @xmath69 :    1",
    ".   the risk of an estimator @xmath204 is given by @xmath205 & & \\quad = e_\\theta [ \\|x - \\theta\\|^2 ] \\\\[1pt ] & & \\qquad{}+ e_\\theta [ \\{(k+2)^{-1 } \\|u\\|^2 \\|g(x,\\|u\\|^2 ) \\|^2 \\\\[1pt ] & & \\hspace*{32pt}\\qquad{}+ 2\\nabla'_x g(x,\\|u\\|^2 )   \\\\[1pt ] & & \\hspace*{32pt}\\qquad { } + 2(k+2)^{-2}\\|u\\|^4(\\partial/\\partial\\|u\\|^2)\\\\[1pt ] & & \\hspace*{91pt}\\qquad{}\\cdot\\| g(x,\\|u\\|^2 ) \\|^2 \\ } \\\\[1pt ] & & \\hspace*{68pt}\\qquad\\cdot { } q(\\|x-\\theta\\|^2 + \\|u\\|^2)],\\end{aligned}\\ ] ] 2 .",
    "@xmath206 dominates @xmath2 provided @xmath207    [ cor41 ] suppose @xmath208 .",
    "then @xmath209 dominates @xmath2 provided :    1 .",
    "@xmath210 and 2 .",
    "@xmath118 is nondecreasing .",
    "the result follows from theorem [ thmm42 ] by a straightforward calculation .",
    "we largely follow fourdrinier , strawderman and wells ( @xcite ) in this subsection .",
    "the nature of the conclusions for estimators is essentially as in theorem [ thmm41 ] , but the result is closer in spirit to the result of cellier and fourdrinier ( @xcite ) in that we obtain an unbiased estimator of risk difference ( from @xmath2 ) instead of the expression in theorem [ thmm41 ] where the function @xmath211 , which depends on @xmath0 , intervenes .",
    "the following lemma is the key to this development .",
    "[ lem42 ] let @xmath212 , where @xmath156 and @xmath157 .",
    "suppo - se  @xmath69 and @xmath213 are such that when @xmath214,@xmath65 = e_\\theta [ h(x)]$ ] .",
    "then , for @xmath203 as above , @xmath215\\\\ & & \\quad= \\{1/(k+2)\\}e_\\theta [ \\|u\\|^4 h(x)],\\end{aligned}\\ ] ] provided the expectations exist .    typically , of course",
    ", @xmath88 is the divergence of @xmath77 , and , in all cases known to us , this remains essentially true .",
    "we choose this form of expressing the lemma because in certain instances of restricted parameter spaces the lemma applies even though the function @xmath69 may not be weakly differentiable , but the equality still holds for @xmath216 and @xmath217 , where @xmath218 is the indicator function of a set @xmath219 .",
    "proof of lemma [ lem42 ] suppose first , that the distribution of @xmath203 is @xmath220 and that  @xmath0 is considered known",
    ". then by the independence of  @xmath2 and  @xmath174 we have by assumption that @xmath221\\\\ & & \\quad = e_\\theta [ ( 1/k)\\| u \\|^2 ( x - \\theta)'g(x ) ] \\\\ & & \\quad= e_\\theta [ \\{k(k+2)\\}^{-1 } \\| u \\|^4 h(x ) ] .\\end{aligned}\\ ] ] hence , the claimed result of the theorem is true for the normal case .",
    "now use the fact that in the normal case ( for @xmath0 known ) , @xmath222 is a complete sufficient statistic .",
    "so it must be that @xmath223\\\\ & & \\quad= e_\\theta \\biggl [ \\frac{\\| u \\|^4 h(x ) } { k + 2 } \\big| \\| x - \\theta\\|^2 + \\| u \\|^2 \\biggr]\\end{aligned}\\ ] ] for all @xmath224 except on a set of measure @xmath119 , since each function of @xmath225 has the same expected value .",
    "actually , it can be shown that these conditional expectations are continuous in @xmath80 and , hence , they agree for all @xmath80 ( see fourdrinier , strawderman and wells , @xcite ) .",
    "but the distribution of @xmath203 conditional on @xmath226 is uniform on the sphere centered at @xmath227 of radius @xmath80 , which is the same as the conditional distribution of @xmath203 conditional on @xmath226 for any spherically symmetric distribution .",
    "hence , the equality which holds for the normal distribution holds for all distributions @xmath41 .",
    "lemma [ lem42 ] immediately gives the following unbiased estimator of risk difference and a condition for dominating @xmath2 for estimators of the form @xmath228 .",
    "suppose @xmath229 and @xmath88 are as in lemma [ lem42 ] .",
    "then , for the estimator @xmath230 :    1 .",
    "the risk difference is given by @xmath231 \\\\ & & \\quad= e_\\theta \\biggl [ \\frac{\\|u\\|^4 } { ( k + 2)^2 } \\{\\|g(x)\\|^2 + 2\\nabla'g(x)\\ } \\biggr],\\end{aligned}\\ ] ] 2 .",
    "@xmath14 beats @xmath2 provided @xmath232 , with strict inequality on a set of positive measure , and provided all expectations are finite .",
    "we consider a simple version of the general restricted parameter space problem which illustrates what types of results can be obtained .",
    "suppose @xmath233 is distributed as in theorem [ thmm41 ] but it is known that @xmath234 , @xmath235 , that is ,  @xmath236 the first orthant .",
    "what follows can be generalized to the case where  @xmath0 is restricted to a polyhedral cone , and more generally a smooth cone .",
    "the material in this section is adapted from fourdrinier , strawderman and wells ( @xcite ) .    in the normal case , the mle of @xmath0 subject to the restriction that @xmath237 is @xmath238 , where the @xmath239th component is @xmath240 if @xmath241 and @xmath119 otherwise . here , as in the case of the more general restriction to a convex cone , the mle is the projection of @xmath2 onto the restricted cone .",
    "chang ( @xcite ) considered domination of the mle of @xmath0 when @xmath2 has a @xmath242 distribution and @xmath236 via certain stein - type shrinkage estimators .",
    "sengupta and sen ( @xcite ) extended chang s results to stein - type shrinkage estimators of the form @xmath243 , where  @xmath244 is nondecreasing , and @xmath245 , and where  @xmath246 is the ( random ) number of positive components of  @xmath2 .",
    "hence , shrinkage occurs only when @xmath246 , the number of positive components of @xmath2 , is at least @xmath247 and the amount of shrinkage is governed by the sum of squares of the positive components .",
    "a similar result holds if @xmath0 is restricted to a general polyhedral cone where  @xmath238 is replaced by the projection of @xmath2 onto the cone and @xmath246 is defined to be the dimension of the face onto which @xmath2 is projected .",
    "we choose the simple polyhedral cone @xmath237 because it will be reasonably clear that some version of the stein lemma [ lem31 ] applies in the normal case .",
    "we first indicate a convenient , but complicated looking , alternate representation of an estimator of the above form in this case .",
    "denote the @xmath248 orthants of @xmath22 , by @xmath249 , and let @xmath250 be @xmath251 . then we may rewrite ( a slightly more general version of ) the above estimator as @xmath252 where @xmath253 is the linear projection of @xmath2 onto @xmath254 , where @xmath254 is the @xmath246-dimensional face of @xmath255 onto which @xmath256 is projected .",
    "note that if @xmath257 , @xmath258 , the estimator is just the mle .",
    "[ lem51 ] suppose @xmath259 , and leteach  @xmath260 be smooth and bounded .",
    "then :    1 .   for each @xmath256 , @xmath261 is weakly differentiable in @xmath137 .",
    "[ 1lem51 ] 2 .",
    "further , @xmath262 \\\\ & & \\quad = e_\\theta \\biggl[\\biggl\\ { \\frac{(s - 2)r_i ( \\|p_i ( x)\\|^2 ) } { \\|p_i ( x)\\|^2 } \\\\ & & \\hspace*{38pt}\\qquad{}+ 2r'_i ( \\|p_i ( x)\\|^2 ) \\biggr\\ } i_{o_i } ( x)\\biggr],\\end{aligned}\\ ] ] provided expectations exist .",
    "[ 2lem51 ] 3 .",
    "@xmath263 as given above dominates themle  @xmath238 , provided @xmath264 is nondecreasing and bounded between 0 and @xmath265 .",
    "[ 3lem51 ]    weak differentiability in part  1 follows since the function is smooth away from the boundary of @xmath256 and is continuous on the boundary except at the origin .",
    "part  2 follows from stein s lemma [ lem31 ] and the fact that ( essentially ) @xmath266 , since @xmath267 of the coordinates are @xmath119 .",
    "part  3 follows by stein s lemma  [ lem31 ] as in proposition [ prop31 ] applied to each orthant .",
    "we omit the details .",
    "the reader is referred to sengupta and sen ( @xcite ) or fourdrinier , strawderman and wells ( @xcite ) for details in the more general case of a polyhedral cone .",
    "next , essentially applying lemma [ lem42 ] to each orthant and using lemma [ lem51 ] we have the following generalization to the case of a general spherically symmetric distribution .",
    "let @xmath268 where @xmath156 and @xmath157 and suppose that @xmath237 .",
    "then @xmath269 dominates the @xmath238 , provided @xmath264 is nondecreasing and bounded between 0 and @xmath265 .",
    "there have been advancements in bayes estimation of location vectors in several directions in the past 15 years .",
    "perhaps the most important advancements have come in the computational area , particularly markov chain monte carlo ( mcmc ) methods .",
    "we do not cover these developments in this review .",
    "admissibility and inadmissibility of ( generalized ) bayes estimators in the normal case with known scale parameter was considered in berger and strawderman ( @xcite ) and in berger , strawderman andtang ( @xcite ) where brown s ( @xcite ) condition for admissibility ( and inadmissibility ) was applied for a  variety of hierarchical bayes models .",
    "maruyama and takemura ( @xcite ) also give admissibility results for the general spherically symmetric case .",
    "at least for spherically symmetric priors , the conditions are , essentially , that priors with tails no greater than@xmath270 give admissible procedures .",
    "fourdrinier , strawderman and wells ( @xcite ) , using stein s ( @xcite ) results ( especially proposition [ prop31 ] above , and its corollaries ) , give classes of minimax bayes ( and generalized bayes ) estimators which include scaled multivariate-@xmath145 priors under certain conditions .",
    "berger and robert ( @xcite ) give classes of priors leading to minimax estimators .",
    "kubokawa and strawderman ( @xcite ) give classes of priors in the setup of berger and strawderman ( @xcite ) that lead  to admissible minimax estimators .",
    "maruyama ( @xcite ) and fourdrinier , kortbi and strawderman ( @xcite ) , in the scale mixture of normal case , find bayes and  generalized bayes minimax estimators , generalizing results of strawderman ( @xcite ) .",
    "as mentioned in section [ sec3 ] , these results use either berger s ( @xcite ) ( a version of which is given in theorem  [ thmm32 ] ) or strawderman s ( @xcite ) result for mixtures of normal distributions .",
    "fourdrinier and strawderman ( @xcite ) proved minimaxity of generalized bayes estimators corresponding to certain harmonic priors for classes  of spherically symmetric sampling distributions which are not necessarily mixtures of normals .",
    "the results in this paper are not based directly on the discussion of section [ sec3 ] but are somewhat more closely related in spirit to the approach of stein ( @xcite ) .",
    "we give below an intriguing result of maruyama ( @xcite ) for the unknown scale case ( see also maruyama and strawderman , @xcite ) , which is related to the ( distributional ) robustness of stein estimators in the unknown scale case treated in section [ sec4 ] .",
    "first , we give a lemma which will aid in the development of the main result .",
    "[ lem61 ] suppose @xmath271 , the ( location - scale invariant ) loss is given by @xmath272 and the prior distribution on @xmath273 is of the form @xmath274",
    ". then provided all integrals exist , the generalizedbayes estimator does not depend on @xmath41 .",
    "@xmath275 & & \\quad= e[\\theta\\eta|x , u]/e[\\eta|x , u ] \\\\[-2pt ] & & \\quad = \\biggl[\\int_{r^p } \\int_0^\\infty \\theta\\eta^{(p + k)/2 + b+1}\\\\[-2pt ] & & \\hspace*{38pt}\\qquad{}\\cdot f(\\eta\\{\\|x - \\theta\\|^2 + \\|u\\|^2 \\})\\rho(\\theta)\\,d\\eta \\,d\\theta\\biggr]\\\\[-2pt ] & & \\qquad{}\\cdot \\biggl[\\int_{r^p } \\int_0^\\infty \\eta^{(p + k)/2 + b+1 } \\\\[-2pt ] & & \\hspace*{48pt}\\qquad{}\\cdot f(\\eta\\{\\|x - \\theta\\|^2\\\\[-2pt ]   & & \\hspace*{82pt}\\qquad{}+ \\|u\\|^2 \\})\\rho(\\theta)\\,d\\eta   \\,d\\theta\\biggr]^{-1}.\\vspace*{-2pt}\\end{aligned}\\ ] ]    making the change of variables @xmath276 , we have @xmath277 & & \\quad= \\biggl[\\int_{r^p } \\theta(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ^ { - ( p + k)/2 + b + 2}\\\\[-2pt ] & & \\hspace*{9pt}\\quad\\qquad{}\\cdot\\rho(\\theta)\\,d\\theta\\int_0^\\infty w^{(p + k)/2 + b + 1 } f(w)\\,dw \\biggr]\\\\[-2pt ] & & \\qquad{}\\cdot\\biggl[\\int_{r^p } ( \\|x - \\theta\\|^2 +",
    "\\|u\\|^2 ) ^ { - ( p + k)/2 + b + 2}\\\\[-2pt ] & & \\hspace*{16pt}\\quad\\qquad{}\\cdot\\rho(\\theta)\\,d\\theta\\int_0^\\infty w^{(p + k)/2 + b + 1 } f(w)\\,dw \\biggr]^{-1 } \\\\[-2pt ] & & \\quad = \\frac{\\int_{r^p } \\theta(\\|x - \\theta\\|^2 + \\|u\\|^2 ) ^ { - ( p + k)/2 + b + 2 } \\rho(\\theta)\\,d\\theta } { \\int_{r^p } ( \\|x - \\theta\\|^2 + \\|u\\|^2 ) ^ { - ( p + k)/2 + b + 2 } \\rho(\\theta)\\,d\\theta}.\\vspace*{-3pt}\\end{aligned}\\ ] ]    hence , for ( generalized ) priors of the above form , the bayes estimator is independent of the sampling distribution provided the bayes estimator exists;thus , they may be calculated for the most convenient density , which is typically the normal .",
    "our next lemma calculates the generalized bayes estimator for a normal sampling density and for a class of priors for which @xmath278 is a scale mixture of normals .",
    "[ lem62 ] suppose the distribution of @xmath233  is normal with variance @xmath279 .",
    "suppose also that  the conditional distribution of @xmath0 given @xmath280 and @xmath281 is  normal with mean 0 and covariance @xmath282 , and the density of @xmath283 is proportional to @xmath284 , where @xmath285 .    1 .",
    "then the bayes estimator is given by @xmath286 , where @xmath287 and @xmath288 is given  by @xmath289 & & \\hspace*{26pt}{}\\cdot(1 + w\\lambda)^ { - k/2 - a - b/2 - 2 } \\,d\\lambda\\biggr ] \\nonumber \\\\[-10pt ] \\\\[-10pt ] \\nonumber & & { } \\cdot\\biggl[\\int_0 ^ 1 \\lambda^{b/2 - 1 } ( 1 - \\lambda)^{p/2 - b/2 - 1 } \\\\[-2pt ] & & \\hspace*{26pt}{}\\cdot ( 1 + w\\lambda)^ { - k/2 - a - b/2 - 2 } \\,d \\lambda\\biggr]^{-1}.\\nonumber\\end{aligned}\\ ] ] this is well defined for @xmath290 , and @xmath291 . [ 1lem62 ] 2 .",
    "furthermore , this estimator is generalized bayes corresponding to the generalized prior proportional to @xmath292 , for any spherically symmetric density  @xmath41 for which @xmath293 .",
    "[ 2lem62 ]    part  1 . in the normal case , @xmath294}{e[\\eta|x , u ] }",
    "\\\\ & = & x - \\frac{\\nabla_x m(x , u)}{2(\\partial/\\partial\\|u\\|^2 ) m(x , u)},\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] where the marginal @xmath295 is proportional to @xmath296 & & \\hspace*{32pt}\\qquad { } \\cdot\\exp ( - \\eta\\{\\|x - \\theta\\|^2 + \\|u\\|^2 \\}/2 ) \\\\[-2pt ] & & \\hspace*{32pt}\\qquad{}\\cdot \\exp\\biggl ( - \\frac{\\eta\\lambda\\|\\theta\\|^2}{2(1 - \\lambda)}\\biggr ) \\,d\\theta\\ , d\\eta\\ , d\\lambda\\\\[-2pt ] & & \\quad = k ' \\int_0 ^ 1 \\int_0^\\infty \\eta^{b/2 + k/2 + a } \\lambda^{b/2 - 1 } ( 1 - \\lambda)^{p/2 - b/2 - 1}\\\\[-2pt ] & & \\hspace*{70pt}{}\\cdot\\exp ( - \\eta\\{\\lambda\\|x\\|^2 + \\|u\\|^2 \\}/2 ) \\,d\\eta\\ , d\\lambda\\\\[-2pt ] & & \\quad= k \\int_0 ^ 1 ( \\lambda\\|x\\|^2 + \\|u\\|^2 ) ^{- b/2-k/2-a-1 } \\lambda^{b/2 - 1 } \\\\[-2pt ] & & \\hspace*{46pt}{}\\cdot(1 - \\lambda)^{p/2 - b/2 - 1}\\ , d\\lambda.\\end{aligned}\\ ] ] hence , we may express the bayes estimator as @xmath297 , where @xmath298 & & \\hspace*{34pt}{}\\cdot\\lambda^{b/2- 1 } ( 1 - \\lambda)^{p/2-b/2 - 1 } \\,d\\lambda\\biggr]\\\\[-3pt ] & & { } \\cdot\\biggl[- 2(d / d\\|u\\|^2)\\\\[-3pt ] & & \\quad{}\\cdot\\int_0 ^ 1 ( \\lambda\\|x\\|^2 + \\|u\\|^2)^{-b/2-k/2-a-1}\\\\[-3pt ] & & \\hspace*{36pt}{}\\cdot\\lambda^{b/2 - 1 } ( 1-\\lambda)^{p/2-b/2 - 1 } \\,d\\lambda\\biggr]^{-1 } \\\\[-3pt ] & = & -x\\biggl[\\int_0 ^ 1 ( \\lambda\\|x\\|^2 + \\|u\\|^2)^{-b/2-k/2-a-2 } \\\\[-3pt ] & & \\hspace*{48pt}{}\\cdot\\lambda^{b/2 } ( 1-\\lambda)^{p/2-b/2 - 1}\\ , d\\lambda\\biggr]\\\\[-3pt ] & & { } \\cdot \\biggl[\\int_0 ^ 1 ( \\lambda\\|x\\|^2 + \\|u\\|^2 ) ^{-b/2-k/2-a-2 } \\\\[-3pt ] & & \\hspace*{18pt}\\quad{}\\cdot\\lambda^{b/2 - 1}(1 - \\lambda)^{p/2-b/2 - 1 } \\,d\\lambda\\biggr]^{-1 } \\\\[-3pt ] & = & -x\\biggl[\\int_0 ^ 1(\\lambda w + 1)^{-b/2-k/2-a-2}\\\\[-3pt ] & & \\hspace*{33pt}{}\\cdot\\lambda^{b/2 } ( 1-\\lambda)^{p/2-b/2 - 1}\\,d\\lambda\\biggr]\\\\[-3pt ] & & { } \\cdot\\biggl[\\int_0 ^ 1 ( \\lambda w + 1)^{-b/2-k/2-a-2}\\\\[-3pt ] & & \\hspace*{26pt}{}\\cdot\\lambda^{b/2 - 1 } ( 1-\\lambda)^{p/2-b/2 - 1 } \\,d\\lambda\\biggr]^{-1 } \\\\[-3pt ] & = & - \\frac{x}{w}r(w).\\end{aligned}\\ ] ] part",
    "a straightforward calculation shows that the unconditional density of @xmath273 is proportional to @xmath299 .",
    "hence , part  2 follows from lemma [ lem61 ] .",
    "the following lemma gives properties of @xmath288 .",
    "[ lem63 ] suppose @xmath300 and that @xmath301 .",
    "then , ( 1 ) @xmath288 is nondecreasing , and ( 2 )  @xmath302 .    by a change of variables ,",
    "letting @xmath303 in ( [ eq61 ] ) , then @xmath304\\\\ & & { } \\cdot\\biggl[\\int_0^w { ( v + 1 ) } ^ { - b/2 - k/2 - a - 2}\\\\ & & \\hspace*{28pt}{}\\cdot v^{b/2 - 1 } ( 1 - v /w)^{p/2 - b/2 - 1 } \\,dv\\biggr]^{-1}.\\end{aligned}\\ ] ] so , we may rewrite @xmath288 as @xmath305 $ ] , where @xmath306 has density proportional to @xmath307}(v)$ ] .",
    "this density has increasing monotone likelihood ratio in @xmath308 as long as @xmath309 .",
    "hence , part 1 follows .",
    "the conditions of the lemma allow interchange of limit and integration in both numerator and denominator of @xmath288 as @xmath310 .",
    "hence , @xmath311\\\\ & = & \\frac{\\operatorname{beta}(b/2 + 1,k/2 + a + 1)}{\\operatorname{beta}(b/2,k/2 + a + 2 ) } \\\\ & = & \\frac{b/2}{k/2 + a + 1}.\\end{aligned}\\ ] ]    combining lemmas [ lem61][lem63 ] with corollary [ cor41 ] gives as the main result a class of estimators which are generalized bayes and minimax simultaneously for the entire class of spherically symmetric sampling distributions ( subject to integrability conditions ) .",
    "suppose that the distributionof  @xmath203 and the loss function are as in lemma  [ lem61 ] , and that the prior distribution is as in lemmas [ lem62 ] and [ lem63 ] with a satisfying @xmath312 , and with @xmath300 .",
    "then the corresponding generalized bayes estimator is minimax for all densities @xmath41 such that the @xmath313th moment of the distribution of @xmath203 is finite , that is , @xmath314 .",
    "we note that the above finiteness condition,@xmath315 , is equivalent to the finiteness condition , @xmath316 in lemma [ lem62 ] .",
    "this paper has reviewed some of the developments in shrinkage estimation of mean vectors for spherically symmetric distributions , mainly since the review paper of brandwein and strawderman ( @xcite ) .",
    "other papers in this volume review other aspects of the enormous literature generated by or associated with stein s stunning inadmissibility result of 1956 .",
    "most of the developments we have covered are , or can be viewed as , outgrowths of stein s papers of 1973 and 1981 , and , in particular , of stein s lemma which gives ( an incredibly useful ) alternative expression for the cross product term in the quadratic risk function .    among the topics which we have not covered is the closely related literature for elliptically symmetric distributions ( see , e.g. , kubokawa and srivastava , @xcite , and fourdrinier , strawderman and wells , @xcite , and the references therein ) .",
    "we also have not included a discussion of hartigan s ( @xcite ) beautiful result that the ( generalized or proper ) bayes estimator of a normal mean vector with respect to the uniform prior on any convex set in @xmath22 dominates @xmath2 for squared error loss . nor have we discussed the very useful and pretty development of the kubokawa ( @xcite ) ierd method for finding improved estimators , and , in particular , for dominating james stein estimators ( see also marchand and strawderman , @xcite , for some discussion of these last two topics ) .",
    "we nonetheless hope we have provided some intuition for , and given a flavor of the developments and rich literature in the area of improved estimators for spherically symmetric distributions .",
    "the impact of stein s beautiful 1956 result and his innovative development of the techniques in the 1973 and 1981 papers have inspired many researchers , fueled an enormous literature on the subject , led to a deeper understanding of theoretical and practical aspects of `` sharing strength '' across related studies , and greatly enriched the field of statistics .",
    "even  some of the early ( and later ) heated discussions of  the theoretical and practical aspects of `` sharing strength '' across unrelated studies have had an ultimately positive impact on the development of hierarchical models and computational tools for their analysis .",
    "we are very pleased to have been asked to contribute  to this volume commemorating fifty years of development of one of the most profound results in the statistical literature in the last half of the 20th century.=-1"
  ],
  "abstract_text": [
    "<S> this paper reviews advances in stein - type shrinkage estimation for spherically symmetric distributions . </S>",
    "<S> some emphasis is placed on developing intuition as to why shrinkage should work in location problems whether the underlying population is normal or not . </S>",
    "<S> considerable attention is devoted to generalizing the `` stein lemma '' which underlies much of the theoretical development of improved minimax estimation for spherically symmetric distributions . </S>",
    "<S> a main focus is on distributional robustness results in cases where a residual vector is available to estimate an unknown scale parameter , and , in particular , in finding estimators which are simultaneously generalized bayes and minimax over large classes of spherically symmetric distributions . </S>",
    "<S> some attention is also given to the problem of estimating a location vector restricted to lie in a polyhedral cone .    . </S>"
  ]
}