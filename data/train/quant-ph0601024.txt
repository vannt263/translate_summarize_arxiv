{
  "article_text": [
    "propagation of quantum wave functions , i.e. , direct integration of the time dependent schrdinger equation , is a fundamental numeric task .",
    "this time dependent method exhibits many numeric advantages in first principle calculations .",
    "for example , one is able to extract energy spectrum efficiently from the correlation function via fourier transformation  @xcite , or more advanced filter diagonalization algorithm  @xcite .",
    "the efficiency is more evident when one needs excited energy spectrum in large scale first principle calculations .    for wave function propagation ,",
    "the most expansive numeric operations are products of the hamiltonian matrix and state vectors , namely , the hamiltonian operator acting on state vectors .",
    "it is a long standing efforts to develop efficient algorithm for wave function propagation that uses minimum number of such matrix - vector product operations .    among the popular algorithms , such as split operator method  @xcite and chebyshev expansion method  @xcite ,",
    "the lanczos method  @xcite is a robust and flexible scheme for wave function propagation  @xcite .",
    "this method is in principle applicable to any kind of systems , including the time dependent hamiltonian  @xcite , and there is virtually no need for preparing knowledge about the considered system to apply the lanczos method .",
    "furthermore , the performance of the lanczos method is relatively insensitive to the considered system and the initial wave function . in many cases ,",
    "the lanczos method is the best choice to do time dependent calculations .",
    "for example , if one need to compute a quantity ( such as the entropy of a subsystem ) changing continuously with time , and the corresponding hamiltonian is not suitable to break into two parts to apply the split operator algorithm , one may consider to employ the lanczos method for the task .",
    "the lanczos algorithm transforms a hermitian matrix into a tri - diagonal form iteratively  @xcite .",
    "it has many applications in first principle calculations , see , e.g.  @xcite .",
    "the basic idea of wave function propagation by lanczos method is to solve the schrdinger equation for a given small time step in a low dimensional subspace , namely , the krylov subspace .",
    "the basis states of the krylov subspace , @xmath0 , are generated by the lanczos iteration , @xmath1 , where @xmath2 is the expectation value of the hamiltonian @xmath3 with respect to the vector @xmath4 , @xmath5 is the norm of the vector @xmath6 with @xmath7 and @xmath8 being the wave function obtained from previous step .",
    "the dimension of the krylov subspace is usually less than @xmath9 in most cases .",
    "this dimension depends on the time step and the accuracy requirement .",
    "higher accuracy needs either small time step or large krylov subspace . for a given dimension of the krylov subspace ,",
    "the error accumulates linearly with time in lanczos method  @xcite .",
    "if one needs wave function in longer time scale , one must increase accuracy of each time step to keep the error of the final wave function within required range .",
    "this means the numeric operations are not simply linearly proportional to the time .",
    "there is an optimal choice for the dimension of the krylov subspace and the time step to reach the accuracy requirement of the final state .",
    "however , practical situations , e.g. calculations of correlation function , often need other time steps .",
    "the dimension of the krylov subspace , or the number of matrix - vector product operations in a time step , is a key factor to affect the numeric cost for the lanczos propagation scheme . like other algorithms ,",
    "the operations of the hamiltonian acting on the state vectors are the major numerical cost of lanczos propagation scheme .",
    "higher accuracy demands for more such hamiltonian operations . in the view point of efficiency",
    ", one should keep the number of the hamiltonian operations as small as possible for a given time step and accuracy requirement .    in this paper",
    ", we present an alternative to the lanczos method .",
    "it can improve the accuracy by several orders without extra matrix - vector product operations . to this end",
    ", we reformulate the lanczos method in terms of variational principle with the krylov subspace being the variational subspace .",
    "the basic idea of improvement is to enlarge the variational subspace by including basis states of previous time steps into the variational subspace .",
    "since the required matrix elements are already calculated in previous time steps , such enlargement of the variational subspace has virtually no extra numeric cost .",
    "in fact , including basis states of previous steps into the variational subspace is an efficient method for iteratively diagonalizing large matrix  @xcite .",
    "we first note that one is able to formulate the lanczos propagation scheme from the variational principle . for short time",
    "@xmath10 , one can approximate the evolution operator @xmath11 by a polynomial of the hamiltonian operator @xmath3 . in other words , one can approximate the wave function at time @xmath12 , @xmath13 , by a vector in the krylov subspace spanned by @xmath14 , @xmath15 the expansion coefficients @xmath16 are yet to be determined by the variational principle , @xmath17 one solves the resultant equation of motion to obtain the expansion coefficients . instead of @xmath18 ,",
    "the basis states in original lanczos scheme are generated by the lanczos iteration , and the resultant hamiltonian matrix in the variational subspace is tri - diagonal .",
    "of course , the subspace generated by lanczos iteration is the same as that spanned by states @xmath18 .",
    "another way of arriving at the ansatz ( [ eq1 ] ) is to relate @xmath19 with the @xmath20-th order derivatives of state @xmath21 with respects to the time , @xmath22 .",
    "one can approximate the state at time @xmath12 , @xmath23 , by a linear combination of the state @xmath21 and its derivatives up to order @xmath24 .",
    "such observation may be useful for time dependent systems .",
    "a direct way to improve accuracy of the lanczos propagation scheme is to enlarge the variational subspace , i.e. , adding more states into the basis states of variational subspace .",
    "this usually means more numerical operations of matrix - vector product to obtain the basis states and the correspondent matrix elements of the hamiltonian .",
    "however , there exist a way to enlarge the variational subspace with virtually no extra numeric cost .",
    "we achieve this by making using of matrix - vector product operations of previous steps .",
    "to this end , we first note that one can propagate a wave function backward from @xmath21 to @xmath25 . in other words , a wave function at time @xmath26 , @xmath25 , is approximately a linear combination of states @xmath27 . here",
    "@xmath28 is the number of matrix - vector product operations in a time steps . at time @xmath29",
    ", we already have states @xmath30 , @xmath31 .",
    "each of these states is approximately equivalent to a linear combination of states @xmath32 , @xmath33 .",
    "if one includes some of these states into the variational subspace , one has effectively products of higher order power of the hamiltonian acting on the state vector @xmath21 . using the same arguments",
    ", one can also include @xmath34 , @xmath35 , @xmath36 , into the variational subspace .",
    "implementation of the above scheme is straightforward .",
    "it involves similar procedures as that of original lanczos propagation scheme .",
    "each step of propagation is to solve the schrdinger equation in the variational subspace .",
    "the variational subspace is spanned by the basis states of the original krylov subspace , @xmath19 , and some basis states of previous time steps , @xmath37 .",
    "the solution of the schrdinger equation in the variational subspace determines the expansion coefficients of next step s wave function with respect to the basis states of the variational subspace .",
    "the practical calculation includes the following steps :    \\(1 ) choose the time step @xmath10 and the dimension of the variational subspace , @xmath24 , as well as the number of matrix - vector product operations , @xmath28 , for each step .",
    "the basis states of the variational subspace are @xmath38 with @xmath39 , @xmath40 . here",
    "@xmath41 , and @xmath21 is the current state at time @xmath29 . for practical applications ,",
    "it is enough to set @xmath42 and @xmath43 , i.e. , one usually needs only some of last step s basis states to form the variational subspace . in our implementation of choosing previous time steps basis states ,",
    "the order is @xmath44 , @xmath45 , @xmath36 .",
    "this is because that @xmath44 is closer to @xmath19 , @xmath46 , than other states , and has less overlap with the basis states of the original krylov subspace , @xmath19 , @xmath47 .",
    "\\(2 ) calculate the matrix - vector products @xmath48 , @xmath49 .",
    "these states and some states obtained in previous time steps form the basis states , @xmath38 , of the variational subspace . here",
    "@xmath50 is only for calculation of the hamiltonian s matrix elements in the variational subspace .",
    "calculation of the @xmath51 matrix - vector products in this step consumes the major cpu time of the whole procedure .",
    "\\(3 ) calculate the matrix elements of the hamiltonian in the variational subspace , @xmath52 , and the overlap between the basis states , @xmath53 . here",
    "@xmath54 is normalized form of @xmath55 . for indices",
    "@xmath57 , the matrix elements of @xmath58 and @xmath59 are already calculated in previous time steps , one needs only to calculate the terms @xmath60 , and @xmath61 in this step .",
    "the trade off of reusing previous steps matrix element is that the basis states is not orthogonal with each other .",
    "\\(4 ) solve the schrdinger equation in the variational subspace @xmath62 to obtain the expansion coefficients @xmath63 of next time step s wave function with respect to the basis states @xmath54 .",
    "the computation cost in this step is negligibly small in comparison with other step s operations .",
    "\\(5 ) perform linear combination of the basis states to form next step s wave function @xmath64    at the first time step , @xmath65 , there is no previous basis states .",
    "all the basis states are formed by states @xmath66 , @xmath67 , with @xmath8 being the initial state . in next step ,",
    "we remove the first @xmath51 states @xmath68 from the basis states , and add another @xmath51 states @xmath69 into the basis states . in following time steps",
    ", we update the basis states of the variational subspace in the same way , i.e. , replacing @xmath51 oldest basis states with states @xmath27 .    in case @xmath70 ,",
    "i.e. , the variational subspace including no previous time step s basis states , the above procedure is essentially the same as the original lanczos propagation scheme . in such case ,",
    "numerical cost , storage requirement , and resulted accuracy are indeed the same as the original one . in the original lanczos scheme ,",
    "the hamiltonian matrix in the variational subspace is tri - diagonal , and the overlap matrix is unit .",
    "since the dimension of the variational subspace is usually small , such difference results in virtually no extra numerical cost .",
    "similar to the original lanczos scheme , the above procedure is more suitable for small time step propagation which needs only small variational subspace .",
    "the storage requirement is also similar to the original lanczos scheme .",
    "one needs to store the basis states of the variational subspace , as well as information about the hamiltonian .",
    "other informations , such as matrix elements of the hamiltonian in the variational subspace and the overlap matrix , need little memory .",
    "for an given time step and accuracy requirement , there is an optimal choice of the dimension , @xmath24 , of the variational subspace and the number , @xmath28 , of the matrix - vector product operations in a time step .",
    "if @xmath28 is inadequately small , i.e. , one includes too many previous time steps basis states into the variational subspace , the overlap matrix may become singular .",
    "this means that there is a limit accuracy for a given time step @xmath10 and the number of matrix - vector product operations in a time step .",
    "we use this property of the overlap matrix to determine the dimension @xmath24 for a given @xmath28 and @xmath10 .",
    "we test the performance of the alternative lanczos method via hnon - heiles model .",
    "it is a particle of unit mass moving in the 2-dimensional hnon - heiles potential  @xcite , @xmath71 , where @xmath72 , @xmath73 , @xmath74 , @xmath75 , and the planck constant is set to @xmath76 .",
    "this system has a chaotic classical limit .",
    "it is widely used to study the quantum - classical correspondence .",
    "similar to ref .",
    "@xcite , we estimate the accuracy of the current method by the overlap between the numeric result and the `` exact '' result . we obtain the `` exact '' result via chebyshev expansion method  @xcite .",
    "the chebyshev method is a global propagator that can reach an accuracy of machine s limit with a single time step .    in figure 1 , we show the auto - correlation function @xmath77 , i.e. , overlap between initial state @xmath78 and the state at time @xmath29 , @xmath21 .",
    "the initial state is a gaussian wave packet whose center positions are @xmath79 , and center momentums vanish .",
    "we use a @xmath80 grid to represent the 2-dimensional wave function in spatial representation .",
    "the action of momentum operator on the state is performed via fast fourier transformation ( fft ) to transform the state into momentum representation .",
    "thus the action of the hamiltonian operator on a state vector needs two ffts to transform the state back and forth between coordinate and momentum representations .",
    "such matrix - vector product operation is the major numerical cost of the wave function propagation . the thin solid line in fig .",
    "1 is a well converged result for comparison .",
    "the dashed line is result of alternative lanczos method , and the thick solid line is result of the original lanczos method .",
    "both the original and alternative lanczos methods use 2 matrix - vector product operations in one time step to obtain the auto - correlation function in fig .",
    "the time step is @xmath81 .",
    "it is evident that 2 matrix - vector product operations are not enough to converge for the original lanczos method .",
    "in fact , one needs at least 4 to 5 matrix - vector product operations in a time step to make the original lanczos method converge . on the other hand ,",
    "the dashed line from alternative lanczos method is almost indistinguishable from the well converged result .",
    "here we include 8 previous basis states , @xmath82 , @xmath83 , @xmath84 , into the variational subspace ( @xmath85 is not included ) .",
    "the total dimension of the variational subspace is 11 .    by reducing the time step to @xmath86",
    ", one can obtain the above converged auto - correlation with only a single matrix - vector product operation in a time step . for such time step ,",
    "we achieve similar accuracy as that in fig . 1 by including 5 previous time steps basis states into the variational subspace .",
    "in contrast , for such time step and accuracy , the original lanczos method still needs about 3 to 4 matrix - vector products in one time step .",
    "generally , one can increase the accuracy with virtually no extra numeric cost by including more previous basis states into the variational subspace . however , in calculation of fig . 1",
    ", including more than @xmath87 previous basis states makes the overlap matrix singular , i.e. , the basis states are no longer independent from each other . in fact , for a given time step @xmath10 and the number @xmath28 of matrix - vector product in a time step , there is always a limit number of previous basis states that one can include into the variational subspace . in other words , the time step @xmath10 and the number",
    "@xmath28 determine limit of the accuracy .    in our test calculations of fig .",
    "1 , the overlap matrix becomes singular occasionally .",
    "when this happens , one can simply remove the non - independent basis vectors .",
    "this can be done by , e.g. , cholesky decomposition of the overlap matrix . in our implementations",
    ", we replace each non - independent vector by one more state @xmath19 of the krylov subspace .",
    "such treatment preserves the accuracy at the expense of one extra matrix - vector product .    practical implementation of the alternative lanczos method is indeed more stable and robust than the calculation of fig .",
    "1 . in fact , calculation of fig .",
    "1 includes several previous time steps basis states into the variational subspace .",
    "this treatment almost reaches the accuracy limit with 2 matrix - vector product operations in a time step .",
    "practically , one needs only including some of last step s basis states into the variational subspace .",
    "this can increase the accuracy by several orders with virtually no extra numeric cost .",
    "the overlap matrix , and thus the whole numeric procedures , are usually well behaved .",
    "2 shows the numeric errors accumulate with time for situations similar to practical calculations .",
    "the solid lines are results of the alternative lanczos method , and the dashed lines are results of corresponding original lanczos method which uses the same number of matrix - vector product operations .",
    "same as ref .",
    "@xcite , we use the overlap between numeric result @xmath88 and `` exact '' result @xmath89 as the measure of error , @xmath90 we obtain the `` exact '' state vector by chebyshev expansion method with accuracy of machine s limit . we propagate the `` exact '' states with a time step @xmath91 , and using 1024 chebyshev polynomials to expand the evolution operator @xmath92 .",
    "this is well beyond the accuracy requirement of the machine s limit . from our tests , 512 chebyshev polynomials",
    "are indeed well converged . from top to bottom of fig .",
    "2 , @xmath93 is the total dimension of the variational subspace for the alternative lanczos method , and @xmath28 is the number of matrix - vector product operations in a time step for both methods .",
    "the time step is set to @xmath81 for both methods .",
    "the initial states , as well as states representation are the same as that of fig .",
    "it is easy to see that the behavior of the original lanczos method is similar to that described in ref .",
    "@xcite , i.e. , the error accumulates about linearly with the time @xmath29 , and the accuracy increases quickly with the number @xmath28 .",
    "it is evident that , when including some of last step s basis states into the variational subspace , the accuracy improves drastically .",
    "we see that , for @xmath94 , the alternative method is about @xmath95 orders more accurate than the original one after time @xmath96 . and for @xmath97 , the alternative method is about 4 orders more accurate after time @xmath98 . the original method is well converged within the time scale @xmath99 for @xmath100 .",
    "even so , the alternative method is still about one order more accurate after time @xmath101 .",
    "another encouraging property of the alternative method is that its error accumulates much slower than the original one .",
    "this means numeric result of the alternative method is more reliable in long time scale .    from fig . 2 and other test calculations ,",
    "we conclude that the alternative lanczos method is suitable for small step wave function propagation .",
    "it improves the accuracy by several orders with almost no extra numeric cost . in calculation of fig .",
    "2 , the variational subspace is about 10 dimensional , and includes only 4 last step s basis states . for such setting ,",
    "the resultant overlap matrix and thus the overall numeric procedure are well behaved .",
    "in fact , the included basis states , @xmath102 , from previous step play the role of high order power of the hamiltonian acting on the state vector , @xmath19 , of the original lanczos method . from the dashed lines in fig .",
    "2 , we see that basis states , @xmath19 ( @xmath39 ) , of the original lanczos method span the major part ( @xmath103 ) of the exact wave function @xmath23 . other basis states , @xmath102 , included from previous step span only very small portion ( @xmath104 ) of the exact wave function . thus , these included basis states @xmath102 have a relatively lower accuracy requirement to represent the high order terms @xmath19 , ( @xmath105 ) .",
    "this explains the success of the alternative method",
    ".    in general , implementation of the alternative method is stable and robust , provided that the basis states @xmath18 span major part of the next step s wave function @xmath23 .",
    "in fact , for a given time step @xmath10 , the accuracy of both alternative and original lanczos methods is determined by the dimension of the variational subspace @xmath24 .",
    "one chooses @xmath10 and @xmath24 in the same way as that of the original lanczos algorithm . in the alternative implementation",
    ", one must specify additionally the number , @xmath28 , of matrix - vector production in a time step .",
    "it is usually enough to set @xmath28 larger than half of @xmath24 , i.e. , @xmath106 .",
    "if @xmath28 is too small , and one includes too many basis states , @xmath107 , of previous steps into the variational subspace , these basis states may be not independent .",
    "even this happens , the alternative method still works .",
    "if a basis state from previous step is linearly dependent on other basis states of the variational subspace , we replace this state by an extra state @xmath19 with @xmath105 .",
    "this keeps the dimension of the variational subspace , and hence the accuracy of the implementation .",
    "the expense of such treatment is one more matrix - vector product operation for each linearly dependent state .",
    "we implement this treatment during the cholesky decomposition of the matrix @xmath108 which is a necessary step to solve eq .",
    "( [ eq3 ] ) .",
    "when the basis states are linearly dependent , the overlap matrix @xmath108 becomes singular .",
    "the cholesky decomposition of @xmath108 can find all the non - independent states .",
    "by properly specify the threshold value of the cholesky decomposition , this numerically cheap operation can even find the states that are close to linear superposition of other basis states .",
    "in summary , we present an alternative to the lanczos method for quantum wave function propagation in terms of variational principle .",
    "this method approximates short time evolution operator , @xmath11 , by a polynomial of the hamiltonian . in other words ,",
    "the wave function @xmath23 , resulted from a small time step propagation from @xmath21 , @xmath13 , is approximately a vector in the krylov subspace spanned by @xmath109 .",
    "one can employ the variational principle to determine the expansion coefficients .",
    "the original lanczos method needs to calculate all the basis states @xmath19 explicitly .",
    "construction of theses basis states is the major numeric cost .",
    "the alternative method needs only to calculate some of the basis states , @xmath19 , @xmath110 , which span the major part of the wave function @xmath23 .",
    "we use basis states of previous step to play the role of the other basis states , @xmath19 , @xmath105 .",
    "practically , it is enough to include some of last step s basis states , @xmath102 , @xmath111 , into the variational subspace .",
    "the accuracy of the alternative method is several orders higher than the original lanczos method with same matrix - vector product operations in a time step .",
    "this alternative method is especially efficient for small time step wave function propagation .",
    "the error accumulation in the alternative method is much slower than that in the original lanczos method , which increases about linearly with time .",
    "the efficiency of the alternative method comes from the fact that the basis states included from previous steps only span very small portion of the wave function , and thus the accuracy requirement for construction of these basis sates is relatively lower .",
    "this alternative method has useful applications in large scale time dependent calculations in which the numeric cost for the hamiltonian acting on state vectors is expensive .",
    "this work is supported in part by the national natural science foundation ( grant no .",
    "10375042 ) , the research fund of the state education ministry of china , and the research fund of the wuhan university ."
  ],
  "abstract_text": [
    "<S> we reformulate the lanczos algorithm for quantum wave function propagation in terms of variational principle . by including some basis states of previous time steps into the variational subspace , the resultant accuracy increases by several orders . </S>",
    "<S> numerical errors of the alternative method accumulate much slower than that of the original lanczos method . </S>",
    "<S> there is almost no extra numeric cost for the gaining of the accuracy , i.e. , the accuracy increase needs no extra operations of the hamiltonian acting on state vectors , which are the major numeric cost for wave function propagation . a wave packet moving in a 2-dimensional hnon - heiles model serves as an illustration . </S>",
    "<S> this method is suitable for small time step propagation of quantum wave functions in large scale time dependent calculations where the operations of the hamiltonian acting on state vectors are expensive . </S>"
  ]
}