{
  "article_text": [
    "arikan s _ polar codes _",
    "@xcite are a class of ` symmetric capacity'-achieving codes for binary - input channels .",
    "their block error probability behaves roughly like @xmath5 @xcite , where @xmath6 is the blocklength , and they achieve this performance at an encoding / decoding complexity of order @xmath7 .",
    "polar codes for non - binary input channels were considered in @xcite . as in the binary case ,",
    "their construction is based on recursively creating new channels from several copies of the original : let @xmath1 be a discrete memoryless channel with input alphabet @xmath8 . throughout this note",
    ", @xmath0 will be assumed to be a prime number .",
    "the output alphabet @xmath9 may be arbitrary .",
    "we will let @xmath10 $ ] denote the mutual information developed across @xmath1 with uniformly distributed inputs .",
    "] , i.e. , @xmath11 let @xmath12 , @xmath13 be independent , uniformly distributed inputs to two independent copies of @xmath1 , and let @xmath14 , @xmath15 be the corresponding outputs . consider the one - to - one mapping @xmath16",
    "@xmath17 where ` @xmath18 ' denotes modulo-@xmath0 addition .",
    "observe that @xmath19 and @xmath20 are independent and uniformly distributed over @xmath21 .",
    "define the channels @xmath22 described through the conditional output probability distributions @xmath23 it follows from the chain rule of mutual information that @xmath24 .",
    "it is also easy to see that @xmath3 is better than @xmath1 , whereas @xmath2 is worse , in the sense that @xmath25 since @xmath2 and @xmath3 are also @xmath0-ary input channels , the above procedure can be applied to each of them , creating the channels @xmath26 , @xmath27 , @xmath28 , and @xmath29 . repeating this procedure @xmath30 times , one obtains @xmath31 channels , @xmath32 , @xmath33 , with @xmath34 .",
    "the main observation that leads the author of @xcite to construct polar codes is that these channels are _ polarized _ in the following sense :    [ thm : q - polarization ] @xmath35\\big\\}=i(w),\\ ] ] @xmath36 for all @xmath37 .",
    "the proofs given in @xcite and @xcite for theorem  [ thm : q - polarization ] are based on the following arguments : the symmetric mutual informations of the channels @xmath38 created by the above procedure have a martingale property , from which it follows that they must converge for almost all paths in the construction .",
    "this shows that both limits in theorem  [ thm : q - polarization ] exist .",
    "to prove the claim on these limits values , it would be sufficient to show that holds with strict inequalities for all @xmath38 , unless @xmath39 .",
    "observe , however , that since the output alphabets of channels @xmath38 grow as the construction size increases , this approach would require the aforementioned inequality to hold uniformly for all @xmath0-ary input channels .",
    "this difficulty is circumvented in @xcite and @xcite by appropriately defining an auxiliary channel parameter @xmath40 and proving the convergence of @xmath41 to @xmath42 by the above arguments , which then implies the convergence of @xmath43 to @xmath42 .",
    "the purpose of this note is to provide a proof of theorem  [ thm : q - polarization ] that avoids this indirect approach . in order to do so",
    ", we will need the following theorem .",
    "[ thm : main ] if @xmath44 for some @xmath37 , then there exists an @xmath45 such that @xmath46 the dependence of @xmath47 on the channel @xmath1 is only through @xmath48 , and not through particular channel specifications ( e.g. , output alphabet size )",
    ".    theorem  [ thm : main ] will be proved as a corollary to the following lemma , which is the main result reported here .",
    "[ lem : entropy ] let @xmath49 , @xmath50 be random variables with joint probability density @xmath51 if @xmath52 for some @xmath37 , then there exists an @xmath45 such that @xmath53    we will prove lemma  [ lem : entropy ] in section  [ sec : proof ] .",
    "it suffices to show that @xmath54 , as the equality @xmath24 will then imply the second half of the claim .",
    "let @xmath49 denote two independent and uniformly distributed inputs to two copies of @xmath1 , and let @xmath50 be the corresponding outputs . since @xmath1 is memoryless , @xmath55 are jointly distributed as in .",
    "further , @xmath44 implies @xmath56 it then follows from lemma  [ lem : entropy ] that @xmath57 completing the proof .",
    "let @xmath58 be @xmath59-valued i.i.d .",
    "random variables with @xmath60=\\pr[b_1=+]=\\tfrac12 $ ] .",
    "let @xmath61 be random variables defined as @xmath62 note that @xmath63 takes values in @xmath64 $ ] .",
    "further , it follows from the relation @xmath24 that @xmath65=i_n$ ] .",
    "hence , the process @xmath61 is a bounded martingale , and therefore converges almost surely to a @xmath64$]-valued random variable @xmath66 .",
    "note , on the other hand , that @xmath67=\\frac1{2^n}\\#\\big\\{\\mathbf{s}\\in\\{-,+\\}^n\\colon i(w^\\mathbf{s})\\in(\\delta,1-\\delta)\\big\\}.\\ ] ] to conclude the proof , it thus suffices to show that @xmath68=i(w)$ ] and @xmath69=1-i(w)$ ] . to that end , note that the almost sure convergence of @xmath63 implies @xmath70=\\mathbb{e}[i(w^{b_1\\dotsc b_n+})-i(w^{b_1\\dotsc b_n})]\\to0 $ ] .",
    "it follows from theorem  [ thm : main ] that the latter convergence implies @xmath71 with probability @xmath72 . due to the martingale property of @xmath63",
    "we have @xmath73=\\mathbb{e}[i_0]=i(w)$ ] , from which it follows that @xmath68=1-\\pr[i_\\infty=0]=i(w)$ ] , completing the proof .",
    "in what follows , @xmath74 and @xmath75 will both denote the entropy of a random variable @xmath76 with probability distribution @xmath77 .",
    "we will let @xmath78 , @xmath79 denote the probability distribution with @xmath80 the cyclic convolution of vectors @xmath77 and @xmath81 will be denoted by @xmath82 .",
    "that is , @xmath83 we will also let @xmath84 denote the uniform distribution over @xmath21 .",
    "we will use the following lemmas in the proof :    [ lem : variation - divergence ] let @xmath77 be a distribution over @xmath21 .",
    "then , @xmath85 .\\ ] ]    lemma  [ lem : variation - divergence ] partially complements pinsker s inequality by providing a lower bound to the @xmath86 distance between an arbitrary probability distribution and the uniform distribution by their kullback  leibler divergence .",
    "@xmath87\\\\ & \\le q\\log e \\sum_i p(i)|p(i)-1/q|\\\\ & \\le q\\log e\\|p-\\uni(\\mathcal{x})\\|_1,\\end{aligned}\\ ] ]    where we used the relation @xmath88 in the first inequality",
    ".    lemma  [ lem : variation - divergence ] holds for distributions over arbitrary finite sets . that @xmath89 is a prime number has no bearing on the above proof .",
    "[ lem : shift - distance ] let @xmath77 be a distribution over @xmath21 . then , @xmath90 for all @xmath91 , @xmath92 . that is , unless @xmath77 is the uniform distribution , its cyclic shifts will be separated from each other in the @xmath86 distance .",
    "let @xmath93 for some @xmath94 .",
    "we will show that there exists a @xmath95 satisfying @xmath96 which will yield the claim since @xmath97 .",
    "suppose that @xmath98 , as the claim is trivial otherwise .",
    "let @xmath99 denote the @xmath100th largest element of @xmath77 , and let @xmath101 .",
    "note that @xmath102 is a proper subset of @xmath21 .",
    "we have @xmath103&=p^{(1)}-p^{(|s|+1)}\\\\ & \\ge p^{(1)}-1/q\\\\ & \\ge \\frac1{2(q-1)}\\|p-\\uni(\\cx)\\|_1\\\\ & \\ge \\frac{1-h(p)}{2q(q-1)\\log e}.\\end{aligned}\\ ] ] in the above , the second inequality is obtained by observing that @xmath104 is smallest when @xmath105 , and the third inequality follows from lemma  [ lem : variation - divergence ] .",
    "therefore , there exists at least one @xmath106 such that @xmath107 given such an @xmath100 , let @xmath108 . since @xmath0 is prime , @xmath21 can be written as @xmath109 for any @xmath95 and @xmath110 .",
    "therefore , since @xmath111 is a proper subset of @xmath21 , there exists a @xmath112 such that @xmath113 , implying @xmath114 which yields the claim .",
    "[ lem : h - convolution ] let @xmath77 and @xmath81 be two probability distributions over @xmath21 , with @xmath115 and @xmath116 for some @xmath117 .",
    "then , there exists an @xmath118 such that @xmath119    let @xmath120 denote the distribution with a unit mass on @xmath79 . since @xmath121 , it follows from the continuity of entropy that @xmath122 for some @xmath123 . on the other hand , since @xmath116 , we have by lemma  [ lem : shift - distance ] that @xmath124 for all pairs @xmath92 .",
    "relations , , and the strict concavity of entropy implies the existence of @xmath118 such that @xmath125    let @xmath126 and @xmath127 be two random probability distributions on @xmath21 , with @xmath128 it is then easy to see that @xmath129,\\\\ h(x_2\\mid y_2)&=\\mathbb{e}[h(p_2)],\\\\ h(x_1+x_2\\mid y_1,y_2)&=\\mathbb{e}[h(p_1\\ast p_2)].\\end{aligned}\\ ] ] suppose , without loss of generality , that @xmath130 .",
    "it suffices to show that if @xmath131,\\mathbb{e}[h(p_2)]\\in(\\delta,1-\\delta)$ ] for some @xmath37 , then there exists an @xmath45 such that @xmath132\\ge\\mathbb{e}[h(p_1)]+\\epsilon(\\delta)$ ] . to that end , define the event @xmath133 observe that @xmath134\\\\ & \\le \\big(1-\\pr[h(p_1)>\\delta/2]\\big)\\cdot\\delta/2+\\pr[h(p_1)>\\delta/2],\\end{aligned}\\ ] ] implying @xmath135>\\tfrac{\\delta}{2-\\delta}$ ] .",
    "it similarly follows that @xmath136>\\tfrac{\\delta}{2-\\delta}$ ] .",
    "note further that @xmath137 and @xmath138 are independent since @xmath14 and @xmath15 are .",
    "thus , @xmath111 has probability at least @xmath139 . on the other hand , lemma  [ lem : h - convolution ] implies that conditioned on @xmath111 we have @xmath140 for some @xmath141 .",
    "thus , @xmath142\\\\&=\\pr[a]\\cdot\\mathbb{e}[h(p_1\\ast p_2)\\mid a]+\\pr[a^c]\\cdot\\mathbb{e}[h(p_1\\ast p_2)\\mid a^c]\\\\ & \\ge\\pr[a]\\cdot \\mathbb{e}[\\big(h(p_1)+\\epsilon_1(\\delta/2)\\big)\\mid a]\\\\ & \\hspace{10em}+\\pr[a^c]\\cdot\\mathbb{e}[h(p_1)\\mid a^c]\\\\ & \\ge \\mathbb{e}[h(p_1)]+\\epsilon_1(\\delta/2)\\epsilon_2(\\delta),\\end{aligned}\\ ] ] where in the first inequality we used and the relation @xmath143 . setting @xmath144 yields the result .",
    "the proof of theorem  [ thm : main ] does not extend trivially to the case of composite input alphabet sizes .",
    "in particular , that the cyclic group @xmath145 is generated by each of its non - zero elements is crucial to the proof of lemma  [ lem : shift - distance ] . on the other hand ,",
    "a weaker statement holds when the input alphabet size is composite : consider replacing the mapping with @xmath146 where @xmath147 is a permutation over @xmath21 , and define the channels @xmath148 and @xmath149 accordingly .",
    "then , it can be shown that there exists a permutation @xmath147 for which theorem  [ thm : main ] holds , irrespective of the input alphabet size .",
    "the proof of this statement is similar to that of theorem  [ thm : main ] , and therefore is omitted .",
    "it then follows that channels with composite input alphabet sizes can be polarized in the sense of theorem  [ thm : q - polarization ] if the mapping in is chosen appropriately at each step of construction . whether such channels can be polarized by recursive application of a _ fixed _",
    "mapping is an open question .",
    "i would like to thank emre telatar for helpful discussions",
    ".    1 e.  arkan , `` channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans .",
    "inform . theory _",
    "it-55 , pp .",
    "30513073 , july 2009 ."
  ],
  "abstract_text": [
    "<S> it is shown that given two copies of a @xmath0-ary input channel @xmath1 , where @xmath0 is prime , it is possible to create two channels @xmath2 and @xmath3 whose symmetric capacities satisfy @xmath4 , where the inequalities are strict except in trivial cases . </S>",
    "<S> this leads to a simple proof of channel polarization in the @xmath0-ary case .    </S>",
    "<S> channel polarization , polar codes , entropy inequality . </S>"
  ]
}