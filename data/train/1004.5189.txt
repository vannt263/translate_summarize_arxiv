{
  "article_text": [
    "has been well known for many years that the derivation of the rate  distortion function of a given source and distortion measure , does not lend itself to closed form expressions , even in the memoryless case , except for a few very simple examples @xcite,@xcite,@xcite,@xcite .",
    "this has triggered the derivation of some upper and lower bounds , both for memoryless sources and for sources with memory .",
    "one of the most important lower bounds on the rate  distortion function ,",
    "which is applicable for difference distortion measures ( i.e. , distortion functions that depend on their two arguments only through the difference between them ) , is the shannon lower bound in its different forms , e.g. , the discrete shannon lower bound , the continuous shannon lower bound , and the vector shannon lower bound .",
    "this family of bounds is especially useful for semi - norm  based distortion measures ( * ? ? ?",
    "* section 4.8 ) . the wyner ",
    "ziv lower bound @xcite for a source with memory is a convenient bound , which is based on the rate ",
    "distortion function of the memoryless source formed from the product measure pertaining to the single ",
    "letter marginal distribution of the original source and it may be combined elegantly with the shannon lower bound .",
    "the autoregressive lower bound asserts that the rate  distortion function of an autoregressive source is lower bounded by the rate  distortion function of its innovation process , which is again , a memoryless source .",
    "upper bounds are conceptually easier to derive , as they may result from the performance analysis of a concrete coding scheme , or from random coding with respect to ( w.r.t . ) an arbitrary random coding distribution , etc .",
    "one well known example is the gaussian upper bound , which upper bounds the rate  distortion function of an arbitrary memoryless ( zero  mean ) source w.r.t .  the squared error distortion measure by the rate  distortion function of the gaussian source with the same second moment .",
    "if the original source has memory , then the same principle generalizes with the corresponding gaussian source having the same autocorrelation function as the original source ( * ? ? ?",
    "* section 4.6 ) .    in this paper , we focus on a simple general parametric representation of the rate  distortion function which seems to set the stage for the derivation of a rather wide family of both upper bounds and lower bounds on the rate  distortion function . in this parametric representation ,",
    "both the rate and the distortion are given by integrals whose integrands include the minimum mean square error ( mmse ) of the distortion based on the source symbol , with respect to a certain joint distribution of these two random variables .",
    "more concretely , given a memoryless source designated by a random variable ( rv ) @xmath1 , governed by a probability function @xmath2 , a reproduction variable @xmath3 , governed by a probability function @xmath4 , and a distortion measure @xmath5 , the rate and the distortion can be represented parametrically via a real parameter @xmath6 as follows : @xmath7 and @xmath8 where @xmath9 is the distortion pertaining to parameter value @xmath10 , @xmath11 is the rate  distortion function w.r.t .",
    "reproduction distribution @xmath12 , computed at @xmath9 , @xmath0 , and @xmath13 is the mmse of estimating @xmath14 based on @xmath1 , where the joint probability function of @xmath15 is induced by the following joint probability function of @xmath16 : @xmath17 where @xmath18 is a normalization constant , given by @xmath19 in the continuous case , or @xmath20 in the discrete case .    at first glance ,",
    "( [ rate ] ) looks somewhat similar to the i  mmse relation of @xcite , which relates the mutual information between the input and the output of an additive white gaussian noise ( awgn ) channel and the mmse of estimating the channel input based on the noisy channel output . as we discuss later on",
    ", however , eq .  ( [ rate ] ) is actually very different from the i - mmse relation in many respects . in this context , it is important to emphasize that a relation analogous to ( [ rate ] ) applies also to channel capacity , as will be discussed in the sequel .    the relations ( [ distortion ] ) and ( [ rate ] ) have actually already been raised in a companion paper @xcite ( see also @xcite for a conference version ) .",
    "their derivation there was triggered and inspired by certain analogies between the rate  distortion problem and statistical mechanics , which were the main theme of that work .",
    "however , the significance and the usefulness of these rate  distortion - mmse relations were not explored in @xcite and @xcite .",
    "it is the purpose of the present work to study these relations more closely and to demonstrate their utility , which is , as said before , in deriving upper and lower bounds .",
    "the underlying idea is that bounds on @xmath21 ( and sometimes also on @xmath22 ) may be obtained via relatively simple bounds on the mmse of @xmath14 based on @xmath1 .",
    "these bounds can either be simple technical bounds on the expression of the mmse itself , or bounds that stem from pure estimation ",
    "theoretic considerations .",
    "for example , upper bounds may be derived by analyzing the mmse of a certain sub - optimum estimator , e.g. , a linear estimator , which is easy to analyze .",
    "lower bounds can be taken from the available plethora of lower bounds offered by estimation theory , e.g. , the cramr ",
    "rao lower bound .",
    "indeed , an important part of this work is a section of examples , where it is demonstrated how to use the proposed relations and derive explicit bounds from them . in one of these examples , we derive two sets of upper and lower bounds , one for a certain range of low distortions and the other , for high distortion values . at both edge - points of the interval of distortion values of interest , the corresponding upper and lower bound asymptotically approach the limiting value with the same leading term , and so , they sandwich the exact asymptotic behavior of the rate  distortion function , both in the low distortion limit and in the high distortion limit .",
    "the outline of this paper is as follows . in section",
    "ii , we establish notation conventions . in section iii ,",
    "we formally present the main result , prove it , and discuss its significance from the above  mentioned aspects . in section iv , we provide a few examples that demonstrate the usefulness of the mmse relations .",
    "finally , in section v , we summarize and conclude .",
    "throughout this paper , rv s will be denoted by capital letters , their sample values will be denoted by the respective lower case letters , and their alphabets will be denoted by the respective calligraphic letters . for example , @xmath1 is a random variable , @xmath23 is a specific realization of @xmath1 , and @xmath24 is the alphabet in which @xmath1 and @xmath23 take on values .",
    "this alphabet may be finite , countably infinite , or a continuum , like the real line @xmath25 or an interval @xmath26\\subset{{\\rm i\\!r}}$ ] .",
    "sources and channels will be denoted generically by the letter @xmath27 , or @xmath12 , which will designate also their corresponding probability functions , i.e. , a probability density function ( pdf ) in the continuous case , or a probability mass function ( pmf ) in the discrete case .",
    "theoretic quantities , like entropies and mutual informations , will be denoted according to the usual conventions of the information theory literature , e.g. , @xmath28 , @xmath29 , and so on . if a rv is continuous  valued , then its differential entropy and conditional differential entropy will be denoted with @xmath30 instead of @xmath31 , i.e. , @xmath32 is the conditional differential entropy of @xmath1 , @xmath33 is the conditional differential entropy of @xmath1 given @xmath3 , and so on . the expectation operator will be denoted , as usual , by @xmath34 .    given a source rv @xmath1 , governed by a probability function @xmath2 , @xmath35 , a reproduction rv @xmath3 , governed by a probability function @xmath4 , @xmath36 , and a distortion measure @xmath37 , we define the rate  distortion function of @xmath1 w.r.t .",
    "distortion measure @xmath38 and reproduction distribution @xmath12 as @xmath39 where @xmath40 and the minimum is across all channels @xmath41 that satisfy @xmath42 and @xmath43 for all @xmath36 .",
    "clearly , the rate  distortion function , @xmath44 , is given by @xmath45 .",
    "we will also use the notation @xmath46 .",
    "obviously , since @xmath1 and @xmath3 are rv s , then so is @xmath14 .",
    "throughout this section , our definitions will assume that both @xmath24 and @xmath47 are finite alphabets .",
    "extensions to continuous alphabets will be obtained by a limit of fine quantizations , with summations eventually being replaced by integrations .    referring to the notation defined in section [ notation ] , for a given positive real @xmath10 ,",
    "define the conditional probability function @xmath48 where @xmath49 and the joint pmf @xmath50 further , let @xmath51 ^ 2\\}\\nonumber\\\\ & = & { \\mbox{\\boldmath $ e$}}_s\\{[d(x , y)-{\\mbox{\\boldmath $ e$}}_s\\{d(x , y)|x\\}]^2\\}\\end{aligned}\\ ] ] where @xmath52 is the expectation operator w.r.t .",
    "@xmath53 , and defining @xmath54 as the conditional expectation @xmath55 w.r.t .",
    "@xmath56 , @xmath57 is defined as @xmath58 .",
    "our main result , in this section , is the following ( the proof appears in the appendix ) :    [ thm1 ] the function @xmath21 can be represented parametrically via the parameter @xmath6 as follows :    * the distortion is obtained by @xmath59 where @xmath60 and @xmath61 * the rate is given by @xmath62    in the remaining part of this section , we discuss the significance and the implications of theorem 1 from several aspects .",
    "+ _ some general technical comments _ + the parameter @xmath10 has the geometric meaning of the negative local slope of the function @xmath21 .",
    "this is easily seen by taking the derivatives of ( [ dist1 ] ) and ( [ rate1 ] ) , i.e. , @xmath63 and @xmath64 , whose ratio is @xmath65 .",
    "this means also that the parameter @xmath10 plays the same role as in the well known parametric representations of @xcite and @xcite , which is to say that it can also be thought of as the lagrange multiplier of the minimization of @xmath66 $ ] subject to the reproduction distribution constraint .    on a related note ,",
    "we point out that theorem [ thm1 ] is based on the following representation of @xmath21 : @xmath67,\\ ] ] which we prove in the appendix as the first step in the proof of theorem 1 .    it should be emphasized that the pmf @xmath12 , that plays a role in the definition of @xmath68 ( and hence also the definition of @xmath69 ) should be kept _ fixed _ throughout the integration , independently of the integration variable @xmath70 , since it is the same pmf as in the definition of @xmath21 .",
    "thus , even if @xmath12 is known to be optimum for a given target distortion @xmath71 ( and then it yields @xmath44 ) , the pmf @xmath12 must be kept unaltered throughout the integration , in spite of the fact that for other values of @xmath70 ( which correspond to other distortion levels ) , the optimum reproduction pmf might be different .",
    "in particular , note that the marginal of @xmath3 , that is induced from the joint pmf @xmath72 , may not necessarily agree with @xmath12 .",
    "thus , @xmath73 should only be considered as an auxiliary joint distribution that defines @xmath69 .",
    "+ _ using theorem 1 for bounds on @xmath21 _ + as was briefly explained in the introduction ( and will also be demonstrated in the next section ) , theorem [ thm1 ] may set the stage for the derivation of upper and lower bounds to @xmath21 for a general reproduction distribution @xmath12 , and hence also for the rate ",
    "distortion function @xmath44 when the optimum @xmath12 is happened to be known or is easily derivable ( e.g. , from symmetry and convexity considerations ) .",
    "the basic underlying idea is that bounds on @xmath21 may be induced from bounds on @xmath69 across the integration interval .",
    "the bounds on the mmse may either be derived from purely technical considerations , upon analyzing the expression of the mmse directly , or by using estimation  theoretic tools . in the latter case",
    ", lower bounds may be obtained from fundamental lower bounds to the mmse , like the bayesian cramr ",
    "rao bound , or more advanced lower bounds available from the estimation theory literature , for example , the weiss ",
    "weinstein bound @xcite,@xcite , whenever applicable .",
    "upper bounds may be obtained by analyzing the mean square error ( mse ) of a specific ( sub - optimum ) estimator , which is relatively easy to analyze , or more generally by analyzing the performance of the best estimator within a certain limited class of estimators , like the class of linear estimators of the ` observation ' @xmath1 , or a certain fixed function of @xmath1 .    in theorem 1",
    "we have deliberately presented two integral forms for both the rate and the distortion . as @xmath9 is monotonically decreasing and @xmath11 is monotonically increasing in @xmath10 , the integrals at the first lines of both eqs .",
    "( [ dist1 ] ) and ( [ rate1 ] ) , which include relatively small values of @xmath70 , naturally lend themselves to derivation of bounds in the low  rate ( high distortion ) regime , whereas the second lines of these equations are more suitable in low  distortion ( high resolution ) region .",
    "for example , to derive an upper bound on @xmath21 in the high  distortion range , one would need a lower bound on @xmath69 to be used in the first line of ( [ dist1 ] ) and an upper bound on @xmath69 to be substituted into the first line of ( [ rate1 ] ) .",
    "if one can then derive , from the former , an upper bound on @xmath10 as a function of @xmath71 , and substitute it into the upper bound on the rate in terms on @xmath10 , then this will result in an upper bound to @xmath21 .",
    "a similar kind of reasoning is applicable to the derivation of other types of bounds .",
    "this point will be demonstrated mainly in examples c and d in the next section .",
    "+ _ comparison to the i  mmse relations _",
    "+ in the more conceptual level , item ( b ) of theorem 1 may remind the familiar reader about well  known results due to guo , shamai and verd @xcite , which are referred to as i  mmse relations ( as well as later works that generalize these relations ) .",
    "the similarity between eq .",
    "( [ rate1 ] ) and the i  mmse relation ( in its basic form ) is that in both cases a mutual information is expressed as an integral whose integrand includes the mmse of a certain random variable ( or vector ) given some observation(s ) .",
    "however , to the best of our judgment , this is the only similarity .    in order to sharpen the comparison between the two relations ,",
    "it is instructive to look at the special case where all random variables are gaussian and the distortion measure is quadratic : in the context of theorem 1 , consider @xmath3 to be a zero  mean gaussian rv with variance @xmath74 , and let @xmath75 .",
    "as will be seen in example b of the next section , this then means that @xmath76 can be described by the additive gaussian channel @xmath77 , where @xmath78 and @xmath79 is a zero  mean gaussian rv , independent of @xmath1 , and with variance @xmath80 . here , we have @xmath81 ^ 2 $ ] .",
    "thus , the integrand of ( [ rate1 ] ) includes the mmse in estimating @xmath82 ^ 2 $ ] based on the _ channel input _ @xmath1 .",
    "it is therefore about estimating a certain function of @xmath79 and @xmath1 , where @xmath1 is the observation at hand and @xmath79 is independent of @xmath1 .",
    "this is very different from the paradigm of the i  mmse relation : there the channel is @xmath83 , where @xmath79 is standard normal , the integration variable is @xmath84 , and the estimated rv is @xmath1 ( or equivalently , @xmath79 ) based on the _ channel output _ , @xmath3 .",
    "also , by comparing the two channels , it is readily seen that the integration variable @xmath10 , in our setting , can be related to the integration variable , @xmath84 , of the i - mmse relation according to @xmath85 and so , the relation between the two integration variables is highly non  linear .",
    "we therefore observe that the two mmse results are fairly different .",
    "+ _ analogous mmse formula for channel capacity _ + eq .",
    "( [ lgd1 ] ) can be understood conveniently as an achievable rate using a simple random coding argument ( see appendix ) : the coding rate @xmath86 should be ( slightly larger than ) the large deviations rate function of the probability of the event @xmath87 , where @xmath88 is a typical source sequence and @xmath89 are drawn i.i.d .  from @xmath12 .",
    "as is well known , a similar random coding argument applies to channel coding ( see also @xcite ) : channel capacity can be obtained as the large deviations rate function of the event @xmath90 , where now @xmath91 is a channel output sequence typical to @xmath12 , @xmath92 are drawn i.i.d .  according to a given input pmf @xmath93",
    ", the distortion measure is chosen to be @xmath94 ( @xmath95 being the channel transition probabilities ) and @xmath96 .",
    "thus , the analogue of ( [ lgd1 ] ) is @xmath97\\ ] ] where @xmath98 and the minimizing @xmath10 is always @xmath99 .",
    "consequently , the corresponding integrated mmse formula would read @xmath100,\\ ] ] where @xmath101 $ ] is defined w.r.t .",
    "the joint pmf @xmath102 eq .",
    "( [ cp ] ) seems to be less useful than the analogous rate ",
    "distortion formulas , for a very simple reason : since the channel is given , then once the input pmf @xmath27 is given too ( which is required for the use of ( [ cp ] ) ) , one can simply compute the mutual information , which is easier than applying ( [ cp ] ) .",
    "this is different from the situation in the rate ",
    "distortion problem , where even if both @xmath27 and @xmath12 are given , in order to compute @xmath21 in the direct way , one still needs to minimize the mutual information w.r.t .",
    "the channel between @xmath1 and @xmath3 .",
    "( [ cp ] ) is therefore presented here merely for the purpose of drawing the duality .",
    "+ _ analogies with statistical mechanics _ + as was shown in @xcite and further advocated in @xcite , the legendre relation ( [ lgd1 ] ) has a natural statistical ",
    "mechanical interpretation , where @xmath18 plays the role of a partition function of a system ( indexed by @xmath23 ) , @xmath5 is an energy function ( hamiltonian ) and @xmath10 plays the role of inverse temperature ( normally denoted by @xmath103 in the physics literature ) .",
    "the minimizing @xmath10 is then the equilibrium inverse temperature when @xmath104 systems ( each indexed by @xmath23 , with @xmath105 particles and hamiltonian @xmath106 ) are brought into thermal contact and a total energy of @xmath107 is split among them . in this case",
    ", @xmath108 is the thermodynamical entropy of the combined system and the mmse , which is @xmath109 , is intimately related to the heat capacity of the system .",
    "an alternative , though similar , interpretation was given in @xcite,@xcite , where the parameter @xmath10 was interpreted as being proportional to a generalized force acting on the system ( e.g. , pressure or magnetic field ) , and the distortion variable is the conjugate physical quantity influenced by this force ( e.g. , volume in the case of pressure , or magnetization in the case of a magnetic field ) . in this case",
    ", the minimizing @xmath10 means the equal force that each one of the various subsystems is applying on the others when they are brought into contact and they equilibrate ( e.g. , equal pressures between two volumes of a gas separated by piston which is free to move ) . in this case , @xmath108 is interpreted as the free energy of the system , and the mmse formulas are intimately related to the fluctuation ",
    "dissipation theorem in statistical mechanics .",
    "more concretely , it was shown in @xcite that given a source distribution and a distortion measure , we can describe ( at least conceptually ) a concrete physical system that emulates the rate  distortion problem in the following manner : when no force is applied to the system , its total length is @xmath110 , where @xmath111 is the number of particles in the system ( and also the block length in the rate  distortion problem ) , and @xmath112 is as defined above .",
    "if one applies to the system a contracting force , that increases from zero to some final value @xmath113 , such that the length of the system shrinks to @xmath107 , where @xmath114 is analogous to a prescribed distortion level , then the following two facts hold true : ( i ) an _ achievable lower bound _ on the total amount of mechanical work that must be carried out by the contracting force in order to shrink the system to length @xmath107 , is given by @xmath115 where @xmath116 is boltzmann s constant and @xmath117 is the temperature .",
    "( ii ) the final force @xmath113 is related to @xmath71 according to @xmath118 , where @xmath119 is the derivative of @xmath120 .",
    "thus , the rate  distortion function plays the role of a fundamental limit , not only in information theory , but in physics as well .",
    "in this section , we provide a few examples for the use of theorem 1 .",
    "the first two examples are simple and well known , and their purpose is just to demonstrate how to use this theorem in order to calculate rate  distortion functions .",
    "the third example is aimed to demonstrate how theorem 1 can be useful as a new method to evaluate the behavior of a certain rate  distortion function ( which is apparently not straightforward to derive otherwise ) at both the low distortion ( a.k.a .",
    "high resolution ) regime and the high distortion regime .",
    "specifically , we first derive , for this example , upper and lower bounds on @xmath44 , which are applicable in certain ranges of high  distortion .",
    "these bounds have the same asymptotic behavior as @xmath71 tends to its maximum possible value , and so , they sandwich the exact high  distortion asymptotic behavior of the true rate  distortion function .",
    "a similar analysis in then carried out in the low distortion range , and again , the two bounds have the same limiting behavior in the very low distortion limit . in the fourth and last example , we show how theorem 1 can easily be used to evaluate the high  resolution behavior of the rate distortion function for a general power ",
    "law distortion measure of the form @xmath121 .",
    "perhaps the simplest example is that of the binary symmetric source ( bss ) and the hamming distortion measure . in this case , the optimum @xmath12 is also symmetric . here",
    "@xmath0 is a binary rv with @xmath122 independently of @xmath23 .",
    "thus , the mmse estimator of @xmath123 based on @xmath1 is @xmath124 regardless of @xmath1 , and so the resulting mmse ( which is simply the variance in this case ) is easily found to be @xmath125 accordingly , @xmath126 and @xmath127 where @xmath128 is the binary entropy function .",
    "another classic example concerns a general source with @xmath129 , the quadratic distortion @xmath75 , and a gaussian reproduction distribution , namely , @xmath4 is the pdf of a zero  mean gaussian rv with variance @xmath130 , for a given @xmath131 . in this case , it well known that @xmath132 ( even without assuming that the source @xmath1 is gaussian ) .",
    "we now demonstrate how this result is obtained from the mmse formula of theorem 1 . in this example",
    ", the purpose is merely to demonstrate how theorem 1 can be used . ]    first , observe that since @xmath4 is the pdf pertaining to @xmath133 , then @xmath134 is easily found to correspond to the gaussian additive channel @xmath135 where @xmath79 is a zero  mean gaussian rv with variance @xmath136 $ ] , and @xmath79 is uncorrelated with @xmath1 .",
    "now , @xmath137",
    "^ 2\\nonumber\\\\ & = & ( z-\\alpha x)^2\\nonumber\\\\ & = & z^2 - 2\\alpha xz+\\alpha^2x^2\\end{aligned}\\ ] ] where @xmath138 $ ] .",
    "thus , the mmse estimator of @xmath14 given @xmath1 is obtained by @xmath139 which yields @xmath140 ^ 2}+ \\frac{4\\sigma_x^2(\\sigma_x^2-d)}{[1 + 2s(\\sigma_x^2-d)]^3}.\\end{aligned}\\ ] ] now , in our case , @xmath141 , and so , for @xmath142 , we get @xmath143 ^ 2}-\\nonumber\\\\ & & 4\\sigma_x^2(\\sigma_x^2-d)\\int_0^{1/2d}\\frac{\\mbox{d}{\\hat{s}}}{[1 + 2{\\hat{s}}(\\sigma_x^2-d)]^3}\\nonumber\\\\ & = & 2\\sigma_x^2-d+\\nonumber\\\\ & & ( \\sigma_x^2-d)\\left[\\frac{1}{1 + 2s(\\sigma_x^2-d)}\\right]_0^{1/2d}+\\nonumber\\\\ & & \\sigma_x^2\\left\\{\\frac{1}{[1 + 2s(\\sigma_x^2-d)]^2}\\right\\}_0^{1/2d}\\end{aligned}\\ ] ] which , after some straightforward algebra , gives @xmath144 .",
    "i.e. , @xmath10 and @xmath71 are indeed related by @xmath142 , or @xmath145 . finally , @xmath146",
    "^ 2}+\\nonumber\\\\ & & 4\\sigma_x^2(\\sigma_x^2-d)\\int_0^{1/2d } \\frac{{\\hat{s}}\\mbox{d}{\\hat{s}}}{[1 + 2{\\hat{s}}(\\sigma_x^2-d)]^3}\\nonumber\\\\ & = & \\frac{1}{2}\\left\\{\\ln[1 + 2s(\\sigma_x^2-d)]+\\right.\\nonumber\\\\ & & \\left.\\frac{1}{1 + 2s(\\sigma_x^2-d)}\\right\\}_0^{1/2d}+\\nonumber\\\\ & & \\frac{\\sigma_x^2}{\\sigma_x^2-d } \\left[\\frac{1}{2[1 + 2s(\\sigma_x^2-d)]^2}-\\right.\\nonumber\\\\ & & \\left.\\frac{1}{1 + 2s(\\sigma_x^2-d)}\\right]_0^{1/2d}\\end{aligned}\\ ] ] which yields , after a simple algebraic manipulation , @xmath132 .      in this example",
    ", we again assume the quadratic distortion measure , but now , instead of gaussian reproduction codewords , we impose binary reproduction , @xmath147 , where @xmath148 is a given constant . clearly , if the pdf of the source @xmath1 is symmetric about the origin , then the best output distribution is also symmetric , i.e. , @xmath149 .",
    "thus , @xmath150 for every @xmath71 , given this choice of @xmath12 .",
    "the channel @xmath76 is now given by @xmath151 note that in this case , the minimum possible distortion ( obtained for @xmath152 ) is given by @xmath153 ^ 2\\}$ ] .",
    "thus , the rate ",
    "distortion function is actually defined only for @xmath154 .",
    "the maximum distortion of interest is @xmath155 , pertaining to the choice @xmath156 , where @xmath1 and @xmath3 are independent . to the best of our knowledge",
    ", there is no closed form expression for @xmath44 in this example . the parametric representation of @xmath9 and @xmath157 , both as functions of @xmath10 , does not seem to lend itself to an explicit formula of @xmath44 .",
    "the reason is that @xmath158 and there is no apparent closed ",
    "form expression of @xmath10 a function of @xmath71 , which can be substituted into the expression of @xmath157 .",
    "consider the mmse estimator of @xmath159 : @xmath160 the mmse is then @xmath161 ^ 2\\}\\nonumber\\\\ & = & 4a^2[\\sigma_x^2-{\\mbox{\\boldmath $ e$}}\\{x^2\\tanh^2(2asx)\\}].\\end{aligned}\\ ] ] we first use this expression to obtain upper and lower bounds on @xmath44 which are asymptotically exact in the range of high distortion levels ( small @xmath10 ) .",
    "subsequently , we do the same for the range of low distortion ( large @xmath10 ) . + _ high distortion .",
    "_ consider first the high distortion regime . for small @xmath10 , we can safely upper bound @xmath162 by @xmath163 and get @xmath164 where @xmath165 .",
    "this results in the following lower bound to @xmath157 : @xmath166\\nonumber\\\\ & = & 2a^2\\sigma_x^2s^2 - 4a^4\\rho_x^4s^4{\\stackrel{\\delta } { = } } r(s).\\end{aligned}\\ ] ] to get a lower bound to @xmath9 , we need an upper bound to the mmse . an obvious upper bound ( which is tight for small @xmath10 ) is given by @xmath167 , which yields : @xmath168 or @xmath169 consider now the range @xmath170 $ ] , which is the range where @xmath171 is monotonically increasing as a function of @xmath10 . in this range ,",
    "a lower bound on @xmath10 would yield a lower bound on @xmath171 , and hence a lower bound to @xmath157 . specifically , for @xmath172 $ ] , we get @xmath173 in other words , we obtain the lower bound @xmath174 for the range of distortions @xmath175 $ ] .",
    "it is obvious that , at least in some range of high distortion levels , this bound is better than the shannon lower bound , @xmath176 where @xmath32 is the differential entropy of @xmath1 .",
    "this can be seen right away from the fact that @xmath177 vanishes at @xmath178 , whereas the bound @xmath179 of ( [ lowerbound ] ) vanishes at @xmath155 , which is strictly larger .    by applying the above",
    " mentioned upper bound to the mmse in the rate equation , and the lower bound to the mmse  in the distortion equation , we can also get an upper bound to @xmath44 in the high  distortion range , in a similar manner .",
    "specifically , @xmath180 and @xmath181 considering again the range @xmath170 $ ] , where @xmath182 is monotonically decreasing , the inverse function @xmath183 is monotonically decreasing as well , and so an upper bound on @xmath44 will be obtained by substituting @xmath183 instead of @xmath10 in the bound on the rate , i.e. , @xmath184 ^ 2 $ ] . to obtain an explicit expression for @xmath183",
    ", we need to solve a cubic equation in @xmath10 and select the relevant solution among the three . fortunately , since this cubic equation has no quadratic term , the expression of the solution can be found trigonometrically and it is relatively simple ( see , e.g. , @xcite ) : specifically , the cubic equation @xmath185 has solutions of the form @xmath186 , where @xmath187 and @xmath188 is any solution to the equation @xmath189 . in other words ,",
    "the three solutions to the above cubic equation are @xmath190 , where @xmath191 with @xmath192 being defined as the unique solution to the equation @xmath193 in the range @xmath194 $ ] . in our case , @xmath195 and so , the relevant solution for @xmath10 ( i.e. , the one that tends to zero as @xmath196 ) , which is @xmath183 , is given by @xmath197\\nonumber\\\\ & = & \\frac{\\sigma_x}{a\\rho_x^2}\\cos\\left [ \\frac{1}{3}\\left(\\frac{\\pi}{2}+\\sin^{-1}\\left ( \\frac{3\\rho_x^2(d_0-d)}{4a\\sigma_x^3}\\right)\\right)+\\frac{4\\pi}{3}\\right ] \\nonumber\\\\ & = & \\frac{\\sigma_x}{a\\rho_x^2}\\sin\\left [ \\frac{1}{3}\\sin^{-1}\\left ( \\frac{3\\rho_x^2(d_0-d)}{4a\\sigma_x^3}\\right)\\right],\\end{aligned}\\ ] ] where @xmath198 is defined as the unique solution to the equation @xmath199 in the range @xmath200 $ ] .",
    "this yields the upper bound @xmath201\\nonumber\\\\ & { \\stackrel{\\delta } { = } } & r_u(d).\\end{aligned}\\ ] ] for the range of distortions @xmath202 $ ] .    for very small @xmath10 , since the upper and the lower bound to the mmse asymptotically coincide ( namely , @xmath203 ) , then both @xmath204 and @xmath179 exhibit the same behavior near @xmath205 , and hence so does the true rate  distortion function , @xmath44 , which is @xmath206 or , stated more rigorously , @xmath207 note that the high  distortion behavior of @xmath44 depends on the pdf of @xmath1 only via its second order moment @xmath208 . on the other hand , the upper and lower bounds , @xmath204 and @xmath179 ,",
    "depend only on @xmath208 and the fourth order moment , @xmath209 .    in fig .",
    "[ bounds ] , we display the upper bound @xmath204 ( solid curve ) and the lower bound @xmath179 ( dashed curve ) for the choice @xmath210 ( hence @xmath211 ) and @xmath212 , which is suitable for the gaussian source .",
    "the range of displayed distortions , @xmath213 $ ] , is part of the range where both bounds are valid in this numerical example .",
    "as can be seen , the functions @xmath179 and @xmath204 are very close throughout the interval @xmath214 $ ] , which is a fairly wide range of distortion levels .",
    "the corresponding shannon lower bound , in this case , which is @xmath215 , vanishes for all @xmath216 and hence also in the range displayed in the graph .",
    "+     ( solid curve ) and the lower bound @xmath179 ( dashed curve ) in the high  distortion regime for @xmath210 and @xmath212",
    ". the shannon lower bound vanishes in this distortion range.,width=321,height=321 ]    _ low distortion .",
    "_ we now consider the small distortion regime , where @xmath10 is very large .",
    "define the function @xmath217 and consider the taylor series expansion of @xmath218 around @xmath219 , which , for the sake of convenience , will be represented as @xmath220 the coefficients @xmath221 will be determined explicitly in the sequel .",
    "now , clearly , @xmath222 , and so we have @xmath223\\nonumber\\\\ & = & 4a^2\\left[\\sigma_x^2-{\\mbox{\\boldmath $ e$}}\\left\\{x^2\\left(1-\\sum_{n=1}^\\infty \\phi_ne^{-4ans|x|}\\right)\\right\\}\\right]\\nonumber\\\\ & = & 4a^2\\sum_{n=1}^\\infty\\phi_n{\\mbox{\\boldmath $ e$}}\\left\\{x^2 e^{-4ans|x|}\\right\\}.\\end{aligned}\\ ] ] to continue from this point , we will have to let @xmath1 assume a certain pdf .",
    "for convenience , let us select @xmath1 to have the laplacian pdf with parameter @xmath188 , i.e. , @xmath224 we then obtain @xmath225 thus , @xmath226.\\end{aligned}\\ ] ] thus far , our derivation has been exact .",
    "we now make an approximation that applies for large @xmath10 by neglecting the terms proportional to @xmath227 and by neglecting @xmath188 compared to @xmath228 in the denominators of @xmath229 .",
    "this results in the approximation @xmath230 let us denote @xmath231 .",
    "then , @xmath232 .",
    "applying a similar calculation to @xmath233 , yields , in a similar manner , the approximation @xmath234 it is easy now to express @xmath10 as a function of @xmath71 and substitute into the rate equation to obtain @xmath235 finally , it remains to determine the coefficients @xmath221 and then the constant @xmath236 .",
    "the coefficients can easily be obtained by using the identity @xmath237 ( @xmath238 ) , which yields , after simple algebra , @xmath239 .",
    "thus , @xmath240 and we have obtained a precise characterization of @xmath44 in the high  resolution regime : @xmath241 by applying a somewhat more refined analysis , one obtains ( similarly as in the above derivation in the high distortion regime ) upper and lower bounds to @xmath157 and @xmath9 , this time , as polynomials in @xmath242 . these again lend themselves to the derivation of upper and lower bounds on @xmath44 , which are applicable in certain intervals of low distortion . specifically , the resulting upper bound is @xmath243 where @xmath244 , and it is valid in the range @xmath245 $ ] .",
    "the obtained lower bound is @xmath246},\\ ] ] and it applies to the range @xmath247 $ ] .",
    "both bounds have the same leading term in asymptotic behavior , which supports eq .",
    "( [ highreslim ] ) .",
    "the details of this derivation are omitted since they are very similar to those of the high  distortion analysis .",
    "consider the case where the distortion measure is given by the @xmath248 metric , @xmath121 for some fixed @xmath249 .",
    "let the reproduction symbols be selected independently at random according to the uniform pdf @xmath250 then @xmath251 and so @xmath252.\\end{aligned}\\ ] ] now , in the high  resolution limit , where @xmath10 is very large , the integrand @xmath253 decays very rapidly as @xmath254 takes values away from @xmath23 , and so , for every @xmath255 ( which for large enough @xmath256 , is the dominant interval for the outer integral over @xmath257 ) , the boundaries , @xmath258 and @xmath259 , of the inner integral can be extended to @xmath260 and @xmath261 within a negligible error term ( whose derivative w.r.t . @xmath10 is negligible too ) . having done this , the inner integral no longer depends on @xmath262 , which also means that the outer integration over @xmath23 becomes superfluous .",
    "this results in @xmath263\\nonumber\\\\ & = & -\\frac{\\partial}{\\partial s}\\ln\\left[s^{-1/r}\\int_{-\\infty}^{+\\infty } \\mbox{d}(s^{1/r}y)e^{-|s^{1/r}y|^r}\\right]\\nonumber\\\\ & = & -\\frac{\\partial}{\\partial s}\\ln\\left[s^{-1/r}\\int_{-\\infty}^{+\\infty } \\mbox{d}t\\cdot e^{-|t|^r}\\right]\\nonumber\\\\ & = & -\\frac{\\partial}{\\partial s}\\ln(s^{-1/r})\\nonumber\\\\ & = & \\frac{1}{rs}.\\end{aligned}\\ ] ] thus , @xmath264 which yields @xmath265 and so @xmath266 where @xmath267 is an integration constant .",
    "we have therefore obtained that in the high  resolution limit , the rate  distortion function w.r.t .",
    "@xmath12 behaves according to @xmath268 with @xmath269 .",
    "while this simple derivation does not determine yet the constant @xmath270 , it does provide the correct characteristics of the dependence of @xmath21 upon @xmath71 for small @xmath71 .",
    "for the case of quadratic distortion , where @xmath271 , one easily identifies the familiar factor of @xmath272 in front of the log  distortion term .",
    "the exact constant @xmath267 ( or @xmath270 ) can be determined by returning to the original expression of @xmath21 as the legendre transform of the log  moment generating function of the distortion ( eq .",
    "( [ lgd1 ] ) , and setting there @xmath273 as the minimizing @xmath10 for the given @xmath71 .",
    "the resulting expression turns out to be @xmath274-\\frac{1}{r}\\ln(er).\\ ] ]",
    "in this paper , we derived relations between the rate  distortion function @xmath21 and the mmse in estimating the distortion given the source symbol .",
    "these relations have been discussed from several aspects , and it was demonstrated how they can be used to obtain upper and lower bounds on @xmath21 , as well as the exact asymptotic behavior in very high and very low distortion .    the bounds derived in our examples were induced from purely mathematical bounds on the expression of the mmse directly .",
    "we have not explored , however , examples of bounds on @xmath21 that stem from estimation  theoretic bounds on the mmse , as was described in section iii . in future work , it would be interesting to explore the usefulness of such bounds as well . another interesting direction for further",
    "work would be to make an attempt to extend our results to rate ",
    "distortion functions pertaining to more involved settings , such as successive refinement coding , and situations that include side information .",
    "_ proof of theorem 1 . _",
    "+ consider a random selection of a codebook of @xmath275 codewords , where the various codewords are drawn independently , and each codeword , @xmath276 , is drawn according to the product measure @xmath277 .",
    "let @xmath278 be a typical source vector , i.e. , the number of times each symbol @xmath35 appears in @xmath262 is ( very close to ) @xmath279 .",
    "we now ask what is the probability of the event @xmath280 ? as this is a large deviations event whenever @xmath281 , this probability must decay exponentially with some rate function @xmath282 , i.e. , @xmath283.\\ ] ] the function @xmath284 can be determined in two ways .",
    "the first is by the method of types @xcite , which easily yields @xmath285,\\ ] ] where the @xmath286 is an auxiliary random variable governed by @xmath287 and the minimum is over all conditional pmf s @xmath95 that satisfy the inequality @xmath288 .",
    "the second method is based on large deviations theory @xcite ( see also @xcite ) , which yields @xmath289.\\ ] ] we first argue that @xmath290 . the inequality @xmath291 is obvious , as @xmath21 is obtained by confining the minimization over the channels in ( [ mot ] ) so as to comply with the additional constraint that @xmath292 for all @xmath36 .",
    "the reversed inequality , @xmath293 , is obtained by the following coding argument : on the one hand , a trivial extension of the converse to the rate  distortion coding theorem @xcite , shows that @xmath21 is a lower bound to the rate  distortion performance of any code that satisfies @xmath294 for all @xmath36 . ,",
    "@xmath295 ( each of which is defined as equal one for @xmath296 and zero otherwise ) as @xmath297 distortion measures , indexed by @xmath298 , and consider the rate ",
    "distortion function w.r.t .  the usual distortion constraint and the @xmath297 additional `` distortion constraints '' @xmath299 for all @xmath298 , which",
    ", when satisfied , they all must be achieved with equality ( since they must sum to unity ) . the rate",
    " distortion function w.r.t .  these @xmath300 constraints , which is exactly @xmath21 ,",
    "is easily shown ( using the standard method ) to be jointly convex in @xmath71 and @xmath12 . ] on the other hand , we next show that @xmath284 is an achievable rate for codes in this class .",
    "consider the the random coding mechanism described in the first paragraph of this proof , with @xmath301 , with @xmath302 being arbitrarily small . since the probability that for a single randomly drawn codeword , @xmath303 is of the exponential order of @xmath304 , then the random selection of a codebook of size @xmath305}$ ] constitutes @xmath305}$ ] independent trials of an experiment whose probability of success is of the exponential order of @xmath304",
    ". using standard random coding arguments , the probability that at least one codeword , in that codebook , would fall within distance @xmath107 from the given typical @xmath262 becomes overwhelmingly large as @xmath306 . since this randomly selected codebook satisfies also @xmath307 in probability ( as @xmath306 ) for all @xmath36 ( by the weak law of large numbers ) , then @xmath284 is an achievable rate within the class of codes that satisfy @xmath307 for all @xmath308 .",
    "thus , @xmath293 , which together with the reversed inequality proved above , yields the equality @xmath290 . consequently , according to eq .",
    "( [ ldt ] ) , we have established the relation ) appears also in ( * ? ? ?",
    "* , corollary 4.2.3 ) , with a completely different proof , for the special case where @xmath12 minimizes both sides of the equation ( and hence it refers to @xmath44 ) .",
    "however , the extension of that proof to a generic @xmath12 is not apparent to be straightforward because here the minimization over the channels is limited by the reproduction distribution constraint . ]",
    "@xmath309.\\ ] ] as this minimization problem is a convex problem ( @xmath310 is convex in @xmath10 ) , the minimizing @xmath10 for a given @xmath71 is obtained by taking the derivative of the r.h.s .",
    ", which leads to @xmath311 this equation yields the distortion level @xmath71 for a given value of the minimizing @xmath10 in eq .",
    "( [ lgdr ] ) .",
    "let us then denote @xmath312 this notation obviously means that @xmath313 taking the derivative of ( [ ds ] ) , we readily obtain @xmath314\\nonumber\\\\ & = & -\\sum_{x\\in{{\\cal x}}}p(x ) \\left[\\frac{\\sum_{y\\in{{\\cal y}}}q(y)d^2(x , y)e^{-sd(x , y)}}{\\sum_{y\\in{{\\cal y}}}q(y)e^{-sd(x , y)}}-\\right.\\nonumber\\\\ & & \\left.\\left(\\frac{\\sum_{y\\in{{\\cal y}}}q(y)d(x , y)e^{-sd(x , y ) } } { \\sum_{y\\in{{\\cal y}}}q(y)e^{-sd(x , y)}}\\right)^2\\right]\\nonumber\\\\ & = & -\\sum_{x\\in{{\\cal x}}}p(x)\\cdot\\mbox{var}_s\\{d(x , y)|x = x\\}\\nonumber\\\\ & = & -\\mbox{mmse}_s(\\delta|x),\\end{aligned}\\ ] ] where @xmath315 is the variance of @xmath316 w.r.t.the conditional pmf @xmath56 .",
    "the last line follows from the fact the expectation of @xmath317 w.r.t .",
    "@xmath93 is exactly the mmse of @xmath123 based on @xmath1 .",
    "the integral forms of this equation are then precisely as in part ( a ) of the theorem with the corresponding integration constants . finally , differentiating both sides of eq .",
    "( [ rds ] ) , we get @xmath318 which when integrated back , yields part ( b ) of the theorem .",
    "this completes the proof of theorem [ thm1 ] .",
    "n.  merhav , `` an identity of chernoff bounds with an interpretation in statistical physics and applications in information theory , '' _ ieee trans .",
    "theory _ , vol .",
    "54 , no .  8 , pp.37103721 , august 2008"
  ],
  "abstract_text": [
    "<S> we derive a simple general parametric representation of the rate  distortion function of a memoryless source , where both the rate and the distortion are given by integrals whose integrands include the minimum mean square error ( mmse ) of the distortion @xmath0 based on the source symbol @xmath1 , with respect to a certain joint distribution of these two random variables . at first glance , these relations may seem somewhat similar to the i  mmse relations due to guo , shamai and verd , but they are , in fact , quite different . </S>",
    "<S> the new relations among rate , distortion , and mmse are discussed from several aspects , and more importantly , it is demonstrated that they can sometimes be rather useful for obtaining non  trivial upper and lower bounds on the rate  distortion function , as well as for determining the exact asymptotic behavior for very low and for very large distortion . </S>",
    "<S> analogous mmse relations hold for channel capacity as well </S>",
    "<S> .    rate  distortion function , legendre transform , estimation , minimum mean square error . </S>"
  ]
}