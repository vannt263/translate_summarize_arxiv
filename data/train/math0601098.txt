{
  "article_text": [
    "in this paper , we consider the problem of the nonparametric density deconvolution of @xmath0 , the density of identically distributed variables @xmath1 , from a sample @xmath7 in the model @xmath8 where the @xmath1 s and @xmath9 s are independent sequences , the @xmath9 s are i.i.d . centered random variables with common density @xmath10 , that is @xmath11 is a noise with known density @xmath12 and known noise level @xmath13 .    due to the independence between the @xmath1 s and the @xmath9 s ,",
    "the problem is to estimate @xmath0 using the observations @xmath14 with common density @xmath15 the function @xmath16 is often called the convolution kernel and is completely known here .    denoting by @xmath17 the fourier transform of @xmath18 ,",
    "it is well known that since @xmath19 , two factors determine the estimation accuracy in the standard density deconvolution problem : the smoothness of the density to be estimated , and the one of the error density which are described by the rate of decay of their fourier transforms . in this context ,",
    "two classes of errors are usually considered : first the so called  ordinary smooth \" errors with polynomial decay of their fourier transform and second , the  super smooth \" errors with fourier transform having an exponential decay .    for further references about density deconvolution see e.g. carroll and hall  ( 1988 ) , devroye ( 1989 ) , fan  ( 1991a , b ) , liu and taylor  ( 1989 ) , masry  ( 1991 , 1993a , b ) , stefansky  ( 1990 ) , stefansky and carroll  ( 1990 ) , taylor and zhang  ( 1990 ) , zhang  ( 1990 ) and cator  ( 2001 ) , pensky and vidakovic  ( 1999 ) , pensky  ( 2002 ) , fan and koo  ( 2002 ) , butucea  ( 2004 ) , butucea and tsybakov  ( 2004 ) , koo  ( 1999 ) .    the aim of the present paper is to provide a complete simulation study of the deconvolution estimator constructed by a penalized contrast minimization on a model @xmath20 , a space of square integrable functions having a fourier transform with compact support included into @xmath21 $ ] with @xmath22 .",
    "comte et al .",
    "( 2005 ) show that for @xmath23 being a positive integer , this penalized contrast minimization selects the relevant projection space @xmath20 without any prior information on the unknown density @xmath0 . in most cases",
    ", it is an adaptive estimator in the sense that it achieves the optimal rate of convergence in the minimax sense , studied by fan  ( 1991a ) , butucea  ( 2004 ) and butucea and tsybakov  ( 2004 ) .",
    "it is noteworthy that , contrary to what usually happens , @xmath24 does not correspond here to the dimension of the projection space but to the length of the support of the fourier transform of the functions of @xmath25 .",
    "thus we will refer in the following to @xmath24 as the `` length '' of the model @xmath25 .    moreover , in the context of integer @xmath23 , comte et al .",
    "( 2005 ) provide a brief simulation which shows that the selected @xmath23 are rather small and therefore far from the asymptotic .",
    "our present study shows that it is relevant to choose @xmath22 on a thinner grid than one included in @xmath26 .",
    "thus we start by stating a modification of the results in comte et al .",
    "( 2005 ) to take into account this thinner grid of values @xmath24 and we show that the resulting penalized minimum contrast estimator is an adaptive estimator in the sense that it achieves the optimal rate of convergence in the minimax sense . here , the penalty depends on the smoothness of the errors density and therefore we consider two cases : laplace density ( ordinary smooth ) and gaussian density ( super smooth ) .",
    "we illustrate , through examples , the influence of over - penalization and under - penalization and propose practical calibrations of the penalty in all considered cases",
    ".    then we study in very large simulations the non asymptotic properties of our estimator by considering various types of densities @xmath0 , with various smoothness properties like cauchy distribution , gaussian density and finally fjer - de - la - valle poussin - type density .",
    "we present some examples , that illustrate how the algorithm works .",
    "we give the mean integrated squared error ( mise ) for the two types of errors density , for all the test densities , for various @xmath13 , and for various sample size .",
    "our results present global tables of mise and comparisons between mise and the theoretical expected rates of convergence .",
    "lastly , the robustness of our procedure is tested in various ways : when the observations are dependent , when @xmath13 is very small ( leading to a problem of density estimation ) and when the errors density @xmath27 is misspecified or not taken into account . in those cases ,",
    "we compare our procedure with previous results of delaigle and gjibels  ( 2004a , 2004b ) and dalelane  ( 2004 ) ( direct density estimation ) .",
    "the conclusions of our study are the following .",
    "our estimation procedure provides very good results ; better than the kernel deconvolution methods described and studied in delaigle and gijbels  ( 2004a ) .",
    "our estimation procedure is robust when the @xmath28 s are no longer independent and even not strongly mixing .",
    "we underline the importance of the noise level in the quality of estimation , and we check that , in the case of a very small noise , we obtain mise s that have the same order as some recent results obtained by dalelane  ( 2004 ) for direct density estimation .",
    "lastly our results show that a misspecification of the errors density slightly increases the error of estimation , but less than the use of the direct density estimator ( without deconvolving ) , as it was already mentioned in hesse  ( 1999 ) .",
    "> from a practical point of view it is important to note that our algorithm is a fast algorithm ( @xmath29 operations ) based on the inverse fast fourier transform ( ifft ) .    the paper is organized as follows . in section 2 , we present the model , the assumptions , the adaptive estimator and its expected rates of convergence . in section 3 , we describe the implementation of the estimates ( see [ descri ] ) and the computations of the associated integrated squared errors ( [ mise ] ) .",
    "section 4 presents the chosen penalties ( see [ penalites ] ) and describes the framework of our simulations .",
    "the simulation results are gathered in section 5 and an appendix is devoted to the proof of our theorem .",
    "for @xmath18 and @xmath30 two square integrable functions , we denote by @xmath17 the fourier transform of @xmath18 , @xmath31 and by @xmath32 the convolution product , @xmath33 .",
    "moreover , we denote by @xmath34 .",
    "consider model ( [ model ] ) under the following assumptions .",
    "@xmath35 under assumption ( [ iid ] ) , the @xmath28 s are independent and identically distributed random variables . assumption ( [ fepspair ] ) , usual for the construction of an estimator in density deconvolution",
    ", ensures that @xmath0 is identifiable .    the rate of convergence for estimating @xmath0 is strongly related to the rate of decrease of the fourier transform of the errors density @xmath36 as @xmath37 goes to infinity . more precisely , the smoother @xmath27 , the quicker the rate of decay of @xmath38 and the slower the rate of convergence for estimating @xmath0 .",
    "indeed , if @xmath27 is very smooth , so is @xmath39 the density of the observations @xmath40 and thus it is difficult to recover @xmath0 .",
    "this decrease of @xmath41 is described by the following assumption .",
    "@xmath42 when @xmath43 in assumption ( [ regufeps ] ) , @xmath27 is usually called `` ordinary smooth '' , and when @xmath44 and @xmath45 , the error density is usually called `` super smooth '' . indeed densities satisfying assumption ( [ regufeps ] ) with @xmath45 and @xmath44",
    "are infinitely differentiable .",
    "for instance , gaussian or cauchy distributions are super smooth of order @xmath46 and @xmath47 respectively , and the symmetric exponential ( also called laplace ) distribution with @xmath48 and @xmath49 is an ordinary smooth density .",
    "furthermore , when @xmath50 , ( [ fepspair ] ) requires that @xmath51 in ( [ regufeps ] ) . by convention , we set @xmath52 when @xmath43 and we assume that @xmath44 when @xmath53 . in the same way , if @xmath54 , the @xmath1 s are directly observed without noise and we set @xmath55 .    for the construction of the estimator",
    "we need the following more technical assumption .",
    "@xmath56 this assumption ( [ momg ] ) , quite unusual but unrestrictive , already appears in density deconvolution in a slightly different way in pensky and vidakovic  ( 1999 ) who assume , instead of ( [ momg ] ) that @xmath57 .",
    "the main drawback of this condition is that it is not stable by translation , but an empirical centering of the data seems to avoid practical problems . since rates of convergence depend on the smoothness of @xmath0 we introduce regularity conditions .",
    "@xmath58}(x)\\right\\}.\\notag\\end{aligned}\\ ] ] note that densities satisfying ( [ super ] ) with @xmath59 belong to some sobolev class of order @xmath60 , whereas densities satisfying ( [ super ] ) with @xmath61 are infinitely differentiable .",
    "moreover , such densities admit analytic continuation on a finite width strip when @xmath62 and on the whole complex plane if @xmath63 .",
    "the densities satisfying ( [ entiere ] ) , often called entire functions , admit analytic continuation on the whole complex plane ( see ibragimov and hasminskii  ( 1983 ) ) .    in order to clarify the notations , we denote by greek letters the parameters related to the known distribution of the noise @xmath64 and by latin letters the parameters related to the unknown distribution @xmath0 of @xmath65 .",
    "let @xmath66 and @xmath67 .",
    "using that @xmath68 is an orthonormal basis of the space of square integrable functions having a fourier transform with compact support included into @xmath69=[-\\ell_m , \\ell_m]$ ] ( see meyer  ( 1990 ) ) , we denote by @xmath25 such a space and consider the collection of linear spaces @xmath70 , with @xmath71 , @xmath72 , and @xmath73 with @xmath74 , as projection spaces .",
    "consequently , @xmath75\\},\\end{aligned}\\ ] ] and the orthogonal projection of @xmath0 on @xmath25 , @xmath76 is given by @xmath77 , with @xmath78 . since",
    "this orthogonal projection involves infinite sums , we consider in practice , the truncated spaces @xmath79 defined as @xmath80 where @xmath81 is an integer to be chosen later .",
    "associated to those spaces we consider the orthogonal projection of @xmath0 on @xmath79 denoted by @xmath82 and given by @xmath83      associate this collection of models to the following contrast function , for @xmath84 belonging to some @xmath25 of the collection @xmath85 @xmath86 since @xmath87 = \\langle t , g\\rangle,$ ] we find that @xmath88 which is minimum when @xmath89 .",
    "since @xmath90 estimates the @xmath91 distance between @xmath84 and @xmath0 , it is well adapted for estimating @xmath0 .",
    "associated to the collection of models , the collection of the non penalized estimators @xmath92 is defined by @xmath93 by using that @xmath94 is linear , and that @xmath95 is an orthonormal basis of @xmath79 , we have @xmath96 with @xmath97      the adaptive estimator is computed by using the following penalized criteria @xmath98,\\ ] ] where pen ( . ) is a penalty function based on the observations and the known distribution of @xmath99 without any prior information on @xmath0 .",
    "first , the variance term @xmath102 depends , as usual in deconvolution problems , on the rate of decay of the fourier transform of @xmath27 , with larger variance for smoother @xmath27 . under assumption ( [ regufeps ] ) , for @xmath103 , the variance term satisfies @xmath104 where @xmath105    second , under assumption ( [ momg ] ) , @xmath106 is of order @xmath107 .",
    "consequently , under ( [ regufeps ] ) , @xmath108 ensures that the risk @xmath109 has the order @xmath110 finally , the bias term @xmath111 depends on the smoothness of the function @xmath0 and has the expected order for classical smoothness classes since it is given by the distance between @xmath0 and the classes of entire functions having fourier transform compactly supported on @xmath112 $ ] ( see ibragimov and hasminskii  ( 1983 ) ) .",
    "consequently , under ( [ momg ] ) , if @xmath108 , the rate of convergence of @xmath92 is obtained by selecting the space @xmath79 , and thus @xmath117 , that minimizes @xmath118 one can see that if @xmath24 becomes too large , the risk explodes , due to the presence of the second term .",
    "hence @xmath24 appears to be the cut between the relevant low frequencies used in the fourier transforms to compute the estimate and the high frequencies which are not used ( and may even degrade the quality of the risk ) .",
    "we give the resulting rates in table [ rates ] . for a density",
    "@xmath0 satisfying ( [ super ] ) , rates are , in most cases , known to be the optimal one in the minimax sense ( see fan  ( 1991a ) , butucea  ( 2004 ) , butucea and tsybakov  ( 2004 ) ) .",
    "we refer to comte et al .",
    "( 2005 ) for further discussion about optimality ."
  ],
  "abstract_text": [
    "<S> we consider the problem of estimating the density @xmath0 of identically distributed variables @xmath1 , from a sample @xmath2 where @xmath3 , @xmath4 and @xmath5 is a noise independent of @xmath1 with known density @xmath6 . </S>",
    "<S> we generalize adaptive estimators , constructed by a model selection procedure , described in comte et al .  </S>",
    "<S> ( 2005 ) . </S>",
    "<S> we study numerically their properties in various contexts and we test their robustness . </S>",
    "<S> comparisons are made with respect to deconvolution kernel estimators , misspecification of errors , dependency , ... </S>",
    "<S> it appears that our estimation algorithm , based on a fast procedure , performs very well in all contexts .     </S>",
    "<S> universit paris v , map5 , umr cnrs 8145 . ]     iut de paris v et universit dorsay , laboratoire de probabilits , statistique et modlisation , umr 8628 . ]    </S>",
    "<S> adaptive estimation </S>",
    "<S> . density deconvolution . </S>",
    "<S> model selection . </S>",
    "<S> penalized contrast . </S>",
    "<S> projection estimator . simulation study . </S>",
    "<S> data - driven . </S>"
  ]
}