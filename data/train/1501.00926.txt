{
  "article_text": [
    "multi - target filtering / tracking involves the simultaneous estimation of the number of targets along with their states , based on a sequence of noisy measurements such as radar or sonar waveforms @xcite . to reduce complexity and facilitate tractability ,",
    "the sensor waveforms are typically processed into a sequence of detections .",
    "the key challenges in multi - target filtering / tracking thus include _ detection uncertainty _ , _",
    "clutter _ , and",
    "_ data association uncertainty_. to date , three major approaches to multi - target tracking / filtering have emerged as the main solution paradigms . these are , multiple hypotheses tracking ( mht ) , @xcite , joint probabilistic data association ( jpda ) @xcite , and random finite set ( rfs ) @xcite .",
    "the rfs or finite set statistics ( fisst ) approach pioneered by mahler provides principled recursive bayesian formulation of the multi - target filtering / tracking problem .",
    "the essence of the rfs approach is the modeling of the collection of target states and measurements , referred to as the multi - target state and multi - target measurement , as finite set valued random variables @xcite .",
    "the centerpiece of the rfs approach is the _ bayes multi - target filter _",
    "@xcite , which recursively propagates the filtering density of the multi - target state forward in time . the phd @xcite , cphd @xcite and cardinality - balanced and labeled multi - bernoulli filters @xcite are tractable approximations to the bayes multi - target filter which are synonymous with the rfs framework .",
    "their tractability however largely hinges on the approximate form for the posterior which can not accommodate statistical dependencies between targets .",
    "the bayes multi - target filter is also a ( multi - target ) tracker when target identities or labels are incorporated into individual target states . in @xcite , the notion of _ labeled rfss _",
    "is introduced to address target trajectories and their uniqueness .",
    "the key results include conjugate priors that are closed under the chapman - kolmogorov equation , and an analytic solution to the bayes multi - target tracking filter known as the @xmath0-generalized labeled multi - bernoulli ( @xmath0-glmb ) filter @xcite . with detection based measurements , the computational complexity in the @xmath0-glmb filter is mainly due to the presence of explicit data associations . for certain applications such as tracking with multiple sensors , partially observable measurements or decentralized estimation , the application of a @xmath0-glmb filter may not be possible due to limited computational resources .",
    "thus cheaper approximations to the @xmath0-glmb filter are of practical significance in multi - target tracking",
    ".    in this paper we present a new approximation to the @xmath0-glmb filter .",
    "our result is based on the approximation proposed in @xcite where it was shown that the glmb distribution can be used to construct a principled approximation to an arbitrary labeled rfs density that matches the phd and the cardinality distribution .",
    "we refer to the resultant filter as a marginalized @xmath0-glmb ( m@xmath0-glmb ) filter since it can be interpreted as a _ marginalization over the data associations_. the proposed filter is consequently computationally cheaper than the @xmath0-glmb filter while still preserving key summary statistics of the multi - target posterior .",
    "importantly the m@xmath0-glmb filter facilitates tractable multi - sensor multi - target tracking . unlike phd / cphd and multi - bernoulli based filters , the proposed approximation accommodates statistical dependence between targets .",
    "we also present an alternative derivation of the lmb filter proposed in @xcite based on the newly proposed m@xmath0-glmb filter .",
    "simulations results verify the proposed approximation .",
    "this section briefly presents background material on multi - object filtering and labeled rfs , which form the basis for the formulation of our multi - target tracking problem .",
    "suppose that at time @xmath1 , there are @xmath2 object states @xmath3 , each taking values in a state space @xmath4 . in the random finite set ( rfs )",
    "framework , the _ multi - object state _ at time @xmath1 is represented by the finite set @xmath5 , and the multi - object state space is the space of all finite subsets of @xmath6 , denoted as @xmath7 .",
    "an rfs is simply a random variable that take values the space @xmath7 that does not inherit the usual euclidean notion of integration and density .",
    "mahler s finite set statistics ( fisst ) provides powerful yet practical mathematical tools for dealing with rfss @xcite based on a notion of integration / density that is consistent with point process theory @xcite .",
    "let @xmath8 denote the _ multi - target posterior density _ at time @xmath1 , and @xmath9 denote the _ multi - target prediction density _ to time k + 1 ( formally @xmath10 and @xmath9 should be written respectively as @xmath11 , and @xmath12 , but for simplicity the dependence on past measurements is omitted ) .",
    "then , the _ multi - target bayes recursion _ propagates @xmath10 in time @xcite , according to the following update and prediction @xmath13 where @xmath14 is the _ multi - object transition density _ to time @xmath15 , @xmath16 is the _ multi - object likelihood function _ at time @xmath1 , and the integral is a _ set integral _ defined for any function @xmath17 by @xmath18 an analytic solution to the multi - object bayes filter for labeled states and track estimation from the multi - object filtering density was given in @xcite .      to perform tracking in the rfs framework we use the label rfs model that incorporates a unique label in the object s state vector to identify its trajectory @xcite .",
    "in this model , the single - object state space @xmath4 is a cartesian product @xmath19 , where @xmath20 is the feature / kinematic space and @xmath21 is the ( discrete ) label space .",
    "a finite subset set @xmath22 of @xmath19 has distinct labels if and only if @xmath22 and its labels @xmath23 have the same cardinality .",
    "an rfs on @xmath19 with distinct labels is called a _ labeled rfs _ @xcite .    for the rest of the paper",
    ", we use the standard inner product notation @xmath24 , and multi - object exponential notation @xmath25 , where @xmath26 is a real - valued function , with @xmath27 by convention .",
    "we denote a generalization of the kroneker delta and the inclusion function that take arbitrary arguments such as sets , vectors , etc , by @xmath28 we also write @xmath29 in place of @xmath30 when @xmath31 .",
    "single - object states are represented by lowercase letters , e.g. @xmath32 , @xmath33 while multi - object states are represented by uppercase letters , e.g. @xmath34 , @xmath22 , symbols for labeled states and their distributions are bolded to distinguish them from unlabeled ones , e.g. @xmath33 , @xmath22 , @xmath35 , etc , spaces are represented by blackboard bold e.g. @xmath20 , @xmath36 , @xmath21 , etc .",
    "an important class of labeled rfs is the generalized labeled multi - bernoulli ( glmb ) family @xcite , which is the basis of an analytic solution to the bayes multi - object filter @xcite . under the standard multi - object measurement model ,",
    "the glmb is a conjugate prior that is also closed under the chapman - kolmogorov equation . if we start with a glmb initial prior , then the multi - object prediction and posterior densities at any time are also glmb densities .",
    "let @xmath37 be the projection @xmath38 , and @xmath39@xmath40 denote the _ distinct label indicator_. a glmb is a labeled rfs on @xmath19 distributed according to @xmath41^{{\\mathbf{x}}}\\label{eq : glmb}\\ ] ] where @xmath42 is a discrete index set , @xmath43 and @xmath44 satisfy : @xmath45 the glmb density ( @xmath46 ) can be interpreted as a mixture of multi - object exponentials .",
    "each term in ( @xmath46 ) consists of a weight @xmath47 that depends only on the labels of @xmath22 , and a multi - object exponential @xmath48^{{\\mathbf{x}}}$ ] that depends on the entire @xmath22 .",
    "the phd ( or intensity function ) of the unlabeled version of generalized labeled multi - bernoulli rfs is given by @xmath49    the labeled multi - bernoulli ( lmb ) family is a special case of the glmb family with one term : @xmath50 where @xmath51 , @xmath52 , is a given set of parameters with @xmath53 representing the existence probability of track @xmath54 , and @xmath55 the probability density of the kinematic state of track @xmath54 given its existence @xcite .",
    "note that the index space @xmath42 has only one element , in which case the @xmath56 superscript is not needed .",
    "the lmb family is the basis of the lmb filter , an effective approximation of the bayes multi - target tracking filter , which is highly parallelizable and capable of tracking large number of targets @xcite .",
    "the lmb filter , however , is an approximation of the bayes multi - target tracking filter which only preserves the unlabeled phd of the multi - target posterior @xcite .",
    "the information lost ( e.g. the cardinality distribution of multi - target posterior and the approximate construction of the individual tracks ) can lead to poor performance in cases of low observability and/or signal - to - noise ratio ( snr ) which will be demonstrated in section [ sec : results ] .      an efficient approach to multi - target tracking was presented in @xcite using a special form of the glmb distribution in eq .",
    "( [ eq : glmb ] ) called @xmath0-glmb , i.e. @xmath57^{\\mathbf{x}},\\label{eq : dglmb}\\\\   & = \\delta(\\mathbf{x})\\sum_{i\\in\\mathcal{f}\\left(\\mathbb{l}\\right)}\\delta_{i}\\left(\\mathcal{l}\\left(\\mathbf{x}\\right)\\right)\\sum_{\\xi\\in\\xi}w^{\\left(i,\\xi\\right)}\\left[p^{\\left(\\xi\\right)}\\right]^{\\mathbf{x}}.\\label{eq : dglmb2}\\end{aligned}\\ ] ] the @xmath0-glmb density naturally arises in multi - target tracking problems when using the standard detection based measurement model . in the following we briefly recall the prediction and update steps for the @xmath0-glmb filter",
    ", additional details can be found in @xcite . to ensure distinct labels we assign each target an ordered pair of integers @xmath58 , where @xmath1 is the time of birth and @xmath59 is a unique index to distinguish targets born at the same time .",
    "the label space for targets born at time @xmath15 is denoted as @xmath60 , and a target born at time @xmath15 , has state @xmath61 .",
    "the label space for targets up to time @xmath15 ( i.e. including those born prior to @xmath15 ) , denoted as @xmath62 , is constructed recursively by @xmath63 ( note that @xmath64 and @xmath60 are disjoint ) . a multi - object state @xmath22 at time",
    "@xmath15 , is a finite subset of @xmath65 @xmath66 .",
    "suppose that at time @xmath1 , there are @xmath67 objects with states @xmath68 , each taking values in the ( labeled ) state space @xmath69 , and @xmath70 measurements @xmath71 each taking values in an observation space @xmath72 .",
    "the _ multi - object state _ and _ multi - object observation _",
    ", at time @xmath1 , @xcite are , respectively , the finite sets @xmath73 the @xmath0-glmb filter recursively propagates a @xmath0-glmb posterior density forward in time according to the following bayesian update and prediction @xmath74 which is the labeled counterpart of the bayesian recursion ( [ eq : mtbayesupdate])-([eq : mtbayespred ] ) .",
    "given the current multi - object state @xmath75 , each state @xmath76 @xmath77 either continues to exist at the next time step with probability @xmath78 and evolves to a new state @xmath79 with probability density @xmath80 , or dies with probability @xmath81 .",
    "note that the label of the objects is preserved in the transition , only the kinematic part of state changes . assuming that @xmath82 has distinct labels and that conditional on @xmath82 , the transition of the kinematic states are mutually independent , then the set @xmath83 of surviving objects at the next time is a labeled multi - bernoulli rfs @xcite @xmath84^{\\mathbf{x } } \\ , , \\label{eq : survivorpdf}\\ ] ] where @xmath85 \\left ( 1 - p_{s}\\left ( x^{\\prime } , \\ell^{\\prime }",
    "\\right ) \\right ) \\ , .\\ ] ] the @xmath86 in ( [ eq : survivorpdf ] ) ensures that only @xmath82 with distinct labels are considered .",
    "the set of new objects born at the next time step is distributed according to @xmath87^{{\\mathbf{y}}}\\label{eq : birth_transition}\\ ] ] the birth density @xmath88 is defined on @xmath89 and @xmath90 if @xmath91 contains any element @xmath92 with @xmath93 . the birth model ( [ eq : birth_transition ] ) covers both labeled poisson and labeled multi - bernoulli .",
    "the multi - object state at the next time @xmath82 is the superposition of surviving objects and new born objects , i.e. @xmath94 . since the label spaces @xmath95 and @xmath96 are disjoint , the labeled birth objects and surviving objects are independent . thus the multi - target transition density turns out to be the product of the transition density ( [ eq : survivorpdf ] ) and the density of new objects ( [ eq : birth_transition ] ) @xmath97 additional details can be found in @xcite .    if the current multi - object prior density is a @xmath0-glmb of the form ( [ eq : dglmb ] ) , then the multi - object prediction density is a @xmath0-glmb given by @xmath98^{\\mathbf{x}}\\label{eq : dglmbpredictedpdf}\\ ] ] where @xmath99^{l}\\sum_{j\\subseteq{\\mathbb{l}}_{0:k}}1_{j}(l)[1-\\eta_{s}^{(\\xi)}]^{j - l}w_{k}^{(i,\\xi ) } \\ , .\\end{aligned}\\ ] ]      the standard multi - object observation model is described as follows . for a given multi - object state @xmath82 , each state @xmath100 is either detected with probability @xmath101 and generates a point @xmath102 with likelihood @xmath103 , or missed with probability @xmath104 , i.e. @xmath105 generates a bernoulli rfs with parameter @xmath106 . assuming that conditional on @xmath82 these bernoulli rfss are independent , then the set @xmath107 of detected points ( non - clutter measurements ) is a multi - bernoulli rfs with parameter set @xmath108 : @xmath109 .",
    "the set @xmath110 of false observations ( or clutter ) , assumed independent of the detected points , is modeled by a poisson rfs with intensity function @xmath111 .",
    "the multi - object observation @xmath112 is the superposition of the detected points and false observations , i.e. @xmath113 , and the multi - target likelihood can be derived as shown in @xcite .",
    "assuming that , conditional on @xmath82 , detections are independent , and that clutter is independent of the detections , the multi - object likelihood is given by @xmath114 ^{\\mathbf{x } } \\ , , \\label{eq : rfsmeaslikelihood0}\\ ] ] where @xmath115 is the set of mappings @xmath116 such that @xmath117 implies @xmath118 , and @xmath119 note that an association map @xmath120 specifies which tracks generated which measurements , i.e. track @xmath54 generates measurement @xmath121 , with undetected tracks assigned to @xmath122 .",
    "the condition `` @xmath123 implies @xmath118 '' , means that a track can generate at most one measurement , and a measurement can be assigned to at most one track , at one time instant .    if the current multi - object prediction density is a @xmath0-glmb of the form ( [ eq : dglmb ] ) , then the multi - object posterior density is a @xmath0-glmb given by @xmath124^{\\mathbf{x}}\\label{eq : dglmbupdatedpdf}\\ ] ] where @xmath125 denotes the subset of the current maps with domain @xmath126 , and @xmath127^{i } \\",
    ", , \\label{eq : updateweight}\\\\ \\eta_{z}^{(\\xi,\\theta)}(\\ell ) & = \\left\\langle p_{k+1|k}^{(\\xi)}(\\cdot,\\ell),\\psi_{z}(\\cdot,\\ell;\\theta)\\right\\rangle \\ , , \\nonumber \\\\",
    "p_{k}^{\\left(\\xi,\\theta\\right)}\\left(\\cdot|z\\right ) & = \\frac{p_{k+1|k}^{(\\xi)}(x,\\ell)\\psi_{z}(x,\\ell;\\theta)}{\\eta_{z}^{(\\xi,\\theta)}(\\ell ) } \\ , .\\nonumber\\end{aligned}\\ ] ] notice that the new association maps @xmath120 can be added ( stacked ) to their respective association histories @xmath128 in order to have again the more compact form ( [ eq : dglmb ] ) for the updated @xmath0-glmb ( [ eq : dglmbupdatedpdf ] ) .",
    "in this section we present a new solution for recursive multi - target tracking based on the glmb approximation technique presented in @xcite .",
    "the resultant filter is called the marginalized @xmath0-glmb ( m@xmath0-glmb ) filter since the result can be interpreted as performing a marginalization with respect to the association histories .",
    "we present two important justifications for the new algorithm , namely , a computationally efficient approximation of the bayes optimal @xmath0-glmb filter which directly facilitates multi - sensor updates , and a theoretical result showing that the proposed approximation matches exactly the ( labeled ) phd and the cardinality distribution of the filtering density .",
    "furthermore we show a connection with the lmb filter by presenting an alternative derivation of the lmb filter based on extracting individual tracks from the m@xmath0-glmb filter .",
    "one of the main factors contributing to the computational complexity of the @xmath0-glmb filter @xcite is the exponential growth of the number of hypotheses in the update of the prior ( [ eq : updateweight ] ) which gives rise to the an explicit sum over an association history variable .",
    "moreover , in multi - sensor scenarios the number of association histories is further increased due to successive update steps ( as detailed in subsection [ sec : dmglmb - msensor ] ) .",
    "the idea behind the proposed m@xmath0-glmb filter is to construct a principled glmb approximation @xmath129 to the posterior density @xmath130 which results in a marginalization over the association histories thereby drastically reducing the number of components required to represent the posterior or filtering density .    a marginalized @xmath0-glmb density @xmath131 corresponding to the @xmath0-glmb density @xmath132 in ( [ eq : dglmb ] )",
    "is a probability density of the form @xmath133^{\\mathbf{x}}\\label{eq : mdglmb}\\ ] ] where @xmath134    [ thm : mdglmb ] the marginalized @xmath0-glmb density @xmath131 in ( [ eq : mdglmb])-([eq : mdglmb_p ] ) preserves both phd and cardinality distribution of the original @xmath0-glmb density @xmath132 in ( [ eq : dglmb ] ) .",
    "we apply the result in proposition 2 of @xcite which can be used to calculate the parameters of the marginalized @xmath0-glmb density .",
    "notice that the result in @xcite applies to any labeled rfs density and our first step is to rewrite the @xmath0-glmb density ( [ eq : dglmb ] ) in the general form for a labeled rfs density specified in @xcite , i.e. @xmath135 where @xmath136 and @xmath137^{\\left\\ { ( x_{1},\\ell_{1}),\\ldots,(x_{n},\\ell_{n})\\right\\ } } } { w(\\left\\ { \\ell_{1},\\ldots,\\ell_{n}\\right\\ } ) } \\label{eq : p}\\end{aligned}\\ ] ] applying proposition 2 of @xcite , the parameters @xmath138 and @xmath139 for the m@xmath0-glmb approximation that match the cardinality and phd are @xmath140 and @xmath141 where we enumerate @xmath142 . substituting the expression ( [ eq : p ] )",
    "in ( [ eq : pmarignal ] ) we have @xmath143^{\\left\\ { ( x,\\ell),(x_{1},\\ell_{1}),\\ldots,(x_{j},\\ell_{j})\\right\\ } } d(x_{1},\\ldots , x_{j})\\\\      & = 1_{i}(\\ell)\\delta(\\left\\ { ( x,\\ell),(x_{1},\\ell_{1}),\\ldots,(x_{j},\\ell_{j})\\right\\ } ) \\frac{1}{w(\\left\\ { \\ell,\\ell_{1},\\ldots,\\ell_{j}\\right\\ } ) } \\sum_{j\\in\\mathcal{f}\\left(\\mathbb{l}\\right)}\\delta_{j}\\left(\\left\\ { \\ell,\\ell_{1},\\ldots,\\ell_{j}\\right\\ } \\right)\\sum_{\\xi\\in\\xi}w^{\\left(j,\\xi\\right)}p^{(\\xi)}(x,\\ell)\\end{aligned}\\ ] ] and noting that @xmath144 it follows that only one term in the sum over @xmath145 is non - zero thus giving @xmath146 consequently , the m@xmath0-glmb approximation is given by @xmath147^{\\mathbf{x}}\\\\   & = \\delta(\\mathbf{x})\\sum_{i\\in\\mathcal{f}(\\mathbb{l})}\\delta_{i}(\\mathcal{l}(\\mathbf{x}))\\sum_{\\xi\\in\\xi}w^{(i,\\xi)}\\left[1_{i}(\\cdot)\\frac{1}{\\displaystyle\\sum_{\\xi\\in\\xi}w^{(i,\\xi)}}\\sum_{\\xi\\in\\xi}w^{\\left(i,\\xi\\right)}p^{(\\xi)}(\\cdot,\\cdot)\\right]^{\\mathbf{x}}\\\\   & = \\delta(\\mathbf{x})\\sum_{i\\in\\mathcal{f}(\\mathbb{l})}\\delta_{i}(\\mathcal{l}(\\mathbf{x}))w^{(i)}\\left[p^{(i)}\\right]^{\\mathbf{x}}\\end{aligned}\\ ] ] where @xmath148      the m@xmath0-glmb density can be exploited to construct an efficient recursive multi - object tracking filter by calculating the m@xmath0-glmb approximation step after the @xmath0-glmb update , and predicting forward in time using the @xmath0-glmb prediction .",
    "given an updated density of the form ( [ eq : mdglmb ] ) the m@xmath0-glmb prediction step turns out to be @xmath149^{\\mathbf{x}}\\label{eq : mdglmbpredictedpdf}\\ ] ] where @xmath150^{l}\\sum_{j\\subseteq{\\mathbb{l}}_{0:k}}1_{j}(l)[1-\\eta_{s}^{(i)}]^{j - l}w_{k}^{(i ) } \\ , , \\end{aligned}\\ ] ] which is exactly the @xmath0-glmb prediction step ( [ eq : dglmbpredictedpdf ] ) with no association histories from previous time step , i.e. @xmath151 , and with the convention of having the superscript @xmath152 instead of @xmath153 due to the marginalization ( [ eq : mdglmb_w])-([eq : mdglmb_p ] ) .",
    "[ rem : maxhppred ] the number of components @xmath154 computed after the m@xmath0-glmb prediction step ( [ eq : mdglmbpredictedpdf ] ) is @xmath155 . on the other hand , the number of components @xmath156 after the @xmath0-glmb prediction ( [ eq : dglmbpredictedpdf ] ) is @xmath157 for @xmath158 and @xmath159 for @xmath160 .",
    "notice that the number of weights @xmath161 of the m@xmath0-glmb is substantially lower than the @xmath158 of @xmath0-glmb . as for the number of location pdfs @xmath162 ,",
    "it is worth noticing that the growth rate of the association histories @xmath163 is super - exponential with time @xcite , while the growth rate of the cardinality of @xmath164 is by far more restrained .",
    "the use of the m@xmath0-glmb approximation further reduces the number of hypotheses in the posterior density while preserving the phd and cardinality distribution @xcite . moreover , the m@xmath0-glmb is in a form that it is suitable for efficient and tractable information fusion ( i.e. multi - sensor processing ) which will be shown in the next subsection .",
    "consider now a multi - sensor setting in which the sensors ( indexed with @xmath165 ) convey all the measurement sets @xmath166 to a central fusion node .",
    "assuming that such a measurement sets taken by the sensors are conditionally independent on the states , the multi - object bayesian filtering update ( [ eq : lmtbayesupdate ] ) can be naturally extended as follows : @xmath167 where @xmath168 is the multi - object likelihood of sensor @xmath165 .",
    "thus , at each time instant @xmath1 , the m@xmath0-glmb update step ( [ eq : mdglmbupdatedpdf ] ) ( and equivalently for the @xmath0-glmb update step ( [ eq : dglmbupdatedpdf ] ) ) is sequentially repeated exploiting the measurement sets @xmath169 provided by the sensors .",
    "let us now focus on the single update step to be carried out for each sensor @xmath165 . if the current multi - object prior density is a m@xmath0-glmb of the form ( [ eq : mdglmb ] ) , then the multi - object posterior density is a @xmath0-glmb given by @xmath170^{\\mathbf{x}}\\label{eq : mdglmbupdatedpdf}\\ ] ] where @xmath125 ( see ( [ eq : rfsmeaslikelihood0 ] ) ) denotes the subset of the current maps with domain @xmath126 , and @xmath171^{i } \\",
    ", , \\label{eq : mdglmbupdateweight}\\\\      \\eta_{z}^{(i,\\theta)}(\\ell ) & = \\left\\langle p_{k+1|k}^{(i)}(\\cdot,\\ell),\\psi_{z}(\\cdot,\\ell;\\theta)\\right\\rangle \\ , , \\\\",
    "p_{k}^{\\left ( i , \\theta \\right)}\\left ( \\cdot | z \\right ) & = \\frac{p_{k+1|k}^{(i)}(x,\\ell ) \\ , \\psi_{z}(x,\\ell;\\theta)}{\\eta_{z}^ { ( i , \\theta ) } ( \\ell ) } \\ , , \\\\",
    "\\psi_{z } ( x , \\ell ; \\theta ) & =   \\begin{cases }                              \\dfrac{p_{d}(x,\\ell ) \\",
    ", g(z_{\\theta(\\ell)}|x,\\ell)}{\\kappa(z_{\\theta(\\ell ) } ) } , & \\mbox{if}\\ \\theta(\\ell)>0\\\\                              1-p_{d}(x,\\ell ) , & \\mbox{if}\\ \\theta(\\ell)=0                          \\end{cases } \\ , .",
    "\\end{aligned}\\ ] ] using now ( [ eq : mdglmb_w])-([eq : mdglmb_p ] ) , the m@xmath0-glmb density corresponding to the @xmath0-glmb density in ( [ eq : mdglmbupdatedpdf ] ) is a probability density of the form ( [ eq : mdglmb ] ) with @xmath172 the m@xmath0-glmb density provided by ( [ eq : mdglmbweight])-([eq : mdglmbpdf ] ) preserves both phd and cardinality distribution of the original @xmath0-glmb density . summing up , at each time instant @xmath1 , ( [ eq : mdglmbupdatedpdf])-([eq : mdglmbpdf ] )",
    "have to be carried sequentially for each sensor @xmath165 to evaluate ( [ eq : msmtbayesupdate ] ) .",
    "[ rem : maxhpup ] each hypothesis @xmath173 generates a set of @xmath174 new measurement - to - track association maps for the @xmath0-glmb posterior .",
    "the number of components @xmath175 stored / computed after the m@xmath0-glmb update step ( [ eq : mdglmbupdatedpdf ] ) is @xmath176 . on the other hand ,",
    "the number of hypotheses @xmath177 after the @xmath0-glmb update ( [ eq : dglmbupdatedpdf ] ) is @xmath178 for @xmath179 and @xmath180 for @xmath181 .",
    "the same conclusions along the lines of remark [ rem : maxhppred ] hold .",
    "[ rem : maxhpmarginal ] after the marginalization procedure ( [ eq : mdglmbweight])-([eq : mdglmbpdf ] ) only @xmath182 hypotheses are retained , as all the new contributions provided by the association maps @xmath174 are aggregated in a single component .",
    "notice that @xmath182 is the exact same number of hypotheses produced during the prediction step ( [ eq : mdglmbpredictedpdf ] ) ( see remark [ rem : maxhppred ] ) .",
    "thus , the prediction step ( [ eq : mdglmbupdatedpdf ] ) sets the upper bound of the total hypotheses that will be retained after each full m@xmath0-glmb step .    from remark [ rem : maxhpup ] and [ rem : maxhpmarginal ] , the m@xmath0-glmb is preferable over the @xmath0-glmb in terms of stored information and computational burden , since the number of remaining hypotheses after each sensor update step in ( [ eq : msmtbayesupdate ] ) is always set to @xmath182 .",
    "note that this does not apply to the @xmath0-glmb due to the super - exponential growth as reported in remark [ rem : maxhppred ] .",
    "this is an important property of the m@xmath0-glmb since it yields a principled approximation which greatly decreases the need of pruning hypotheses w.r.t .",
    "the @xmath0-glmb @xcite .",
    "in fact , pruning in the @xmath0-glmb might lead to poor performance in multi - sensor scenarios with low snr ( e.g. high clutter intensity , low probability of detection , etc . ) and limited storage / computational capabilities .",
    "for instance , this may happen if a subset of the sensors do not detect one or more targets and hypotheses associated to the true tracks are removed due to pruning .",
    "furthermore , from a mathematical viewpoint , pruning between corrections generally produces a less informative and order - independent approximation to the posterior distribution in eq .",
    "( [ eq : msmtbayesupdate ] ) .",
    "the @xmath0-glmb filter implementation @xcite applies directly to m@xmath0-glmb . for a linear gaussian multi - target model",
    "it is assumed that i ) the single target transition density , likelihood and birth intensity are assumed to be gaussian ; ii ) survival and detection probabilities are constants ; iii ) each single target density is represented as a gaussian mixture .",
    "the corresponding gaussian mixture predicted and updated densities are computed using the standard gaussian mixture update and prediction formulas based on the kalman filter @xcite . in the case of having non - linear single target transition density and/or likelihood , one can resort to the well known extended or unscented kalman filters @xcite . on the other hand , for non - linear non - gaussian multi - target models ( with state dependent survival and detection probabilities ) , each single target density can be represented by a set of weighted particles .",
    "the corresponding predicted and updated densities are computed by the standard particle ( or sequential monte carlo ) filter @xcite .",
    "the lmb filter introduced in @xcite is a single component approximation to a @xmath0-glmb density that matches the unlabeled phd . in this subsection",
    "we show an alternative derivation of the lmb approximation first proposed in @xcite through a connection with the m@xmath0-glmb approximation .",
    "recall that a lmb density is uniquely parameterized by a set of existence probabilities @xmath183 and corresponding track densities @xmath184 : @xmath185 where @xmath186    in the following we show that by extracting individual tracks from the m@xmath0-glmb approximation , we can obtain the same expressions for the existence probabilities and state densities originally proposed for the lmb filter in @xcite : @xmath187 @xmath188 where the notation for the numerator in ( [ eq : defphd ] ) is defined as per ( * ? ? ? * eq .",
    "11.111 ) , while the numerator of ( [ eq : phd ] ) follows from ( * ? ? ?",
    "notice that the numerator is precisely the phd @xmath189 corresponding to @xmath131 , which by proposition 2 of @xcite exactly matches the phd @xmath190 corresponding to @xmath191 . using the results in @xcite , it can be verified that @xmath192 and consequently @xmath193    notice that , however , the property of matching the labeled phd of the @xmath0-glmb does not hold for the lmb filter , as shown in ( * ? ? ?",
    "* section iii ) , due to the imposed multi - bernoulli structure for the cardinality distribution .",
    "to assess performance of the proposed marginalized @xmath0-glmb ( m@xmath0-glmb ) , a @xmath194-dimensional multi - object tracking scenario is considered over a surveillance area of @xmath195 $ ] .",
    "two sensor sets are used to represent scenarios with different observability capabilities . in particular : i ) a single radar in the middle of the surveillance region is used as it guarantee observability ; ii ) a set of @xmath196 _ range - only _ ( time of arrival , toa ) , deployed as shown in fig .",
    "[ fig:3toa ] , are used as they do not guarantee observability individually , but information from different sensors need to be combined to achieve it .",
    "the scenario consists of @xmath197 targets as depicted in fig .",
    "[ fig:5trajectories ] .    .",
    "the @xmath198 indicates a rendezvous point . ]    .",
    "the @xmath198 indicates a rendezvous point . ]    for the sake of comparison , the m@xmath0-glmb is also compared with the @xmath0-glmb ( @xmath0-glmb ) @xcite and lmb ( lmb ) @xcite filters .",
    "the three tracking filters are implemented using gaussian mixtures to represent their predicted and updated densities @xcite . due to the non linearity of the sensors , the _ unscented kalman filter _ ( ukf )",
    "@xcite is exploited to update means and covariances of the gaussian components .",
    "the kinematic object state is denoted by @xmath199^{\\top}$ ] , i.e. the planar position and velocity .",
    "the motion of objects is modeled according to the nearly - constant velocity ( ncv ) model @xcite : @xmath200 x_{t } + w_{t } \\ , , \\qquad q = \\sigma_{w}^{2 } \\left [ \\begin{array}{cccc } \\frac{1}{4}t_{s}^{4 } & \\frac{1}{2}t_{s}^{3 } & 0 & 0 \\\\ \\frac{1}{2}t_{s}^{3 } & t_{s}^{2 } & 0 & 0 \\\\ 0 & 0 & \\frac{1}{4}t_{s}^{4 } & \\frac{1}{2}t_{s}^{3}\\\\ 0 & 0 & \\frac{1}{2}t_{s}^{3 } & t_{s}^{2 } \\end{array } \\right]\\ ] ] where @xmath201 $ ] and the sampling interval is @xmath202 $ ] .",
    "the radar has the following measurement function : @xmath203 \\\\[0.5em ]                                      \\sqrt { \\left ( p_{x } - x^{r } \\right)^2 + \\left ( p_{y } - y^{r } \\right)^2 }              \\end{array } \\right ] \\end{array}\\ ] ] where @xmath204 represents the known position of the radar and its measurement noise is @xmath205 \\ , , 100 \\ , [ m]\\right]^{\\top}$ ] .",
    "the measurement functions of the @xmath196 toa of fig .",
    "[ fig:3toa ] are : @xmath206 where @xmath207 represents the known position of sensor ( indexed with ) @xmath165 .",
    "the standard deviation of the toa measurement noise is taken as @xmath208 $ ] .",
    "the clutter is characterized by a poisson process with parameter @xmath209 .",
    "the probability of target detection is @xmath210 .    in the considered scenario ,",
    "targets pass through the surveillance area with partial prior information for target birth locations . accordingly , a @xmath211-component lmb rfs @xmath212 has been hypothesized for the birth process .",
    "table [ tab : borderlineinit ] gives detailed summary of such components .",
    "@xmath213 + @xmath214 + @xmath215 +   +   +   +    due to the partial prior information on the object birth locations , some of the lmb components cover a state space region where there is no birth .",
    "therefore , clutter measurements are more prone to generate false targets .",
    "multi - target tracking performance is evaluated in terms of the _ optimal subpattern analysis _ ( ospa )",
    "metric @xcite with euclidean distance , @xmath216 , and cutoff @xmath217 $ ] .",
    "the reported metric is averaged over @xmath218 monte carlo trials for the same target trajectories but different , independently generated , clutter and measurement noise realizations .",
    "the duration of each simulation trial is fixed to @xmath219 $ ] ( @xmath220 samples ) .",
    "the three tracking filters are coupled with the _ parallel cphd look ahead strategy _ described in @xcite . the cphd @xcite filter",
    ".      figs .",
    "[ fig:1:cardmdglmb ] , [ fig:1:carddglmb ] and [ fig:1:cardlmb ] display the statistics ( mean and standard deviation ) of the estimated number of targets obtained , respectively , with the m@xmath0-glmb , the @xmath0-glmb and the lmb .",
    "as it can be seen , all the algorithms estimate the target cardinality accurately , with no substantial differences .",
    "this result indicates that , in the presence of a single sensor guaranteeing observability , the approximations made by both m@xmath0-glmb and lmb are not critical in that they provide performance comparable to the @xmath0-glmb with the advantage of a cheaper computational burden and reduced storage requirements .",
    "note that the problems introduced by the rendezvous point ( e.g. merged or lost tracks ) are correctly tackled by all the algorithms .",
    "[ fig:1:ospa ] shows the ospa distance of the algorithms .",
    "note again that , in agreement with the estimated cardinality distributions , the ospa distances are nearly identical .",
    "-glmb tracking filter using 1 radar . ]    -glmb tracking filter using 1 radar . ]",
    "$ ] , @xmath216 ) using 1 radar . ]",
    "$ ] , @xmath216 ) using 1 radar . ]      figs .",
    "[ fig:2:cardmdglmb ] , [ fig:2:carddglmb ] and [ fig:2:cardlmb ] display the statistics ( mean and standard deviation ) of the estimated number of targets obtained , respectively , with the m@xmath0-glmb , the @xmath0-glmb and the lmb .",
    "the m@xmath0-glmb and the @xmath0-glmb tracking filters estimate the target cardinality accurately , while the lmb exhibits poor performance and higher standard deviation due to losing some tracks when 4 or 5 targets are jointly present in the surveillance area .",
    "it is worth noticing that the m@xmath0-glmb performs as nearly as identical to the @xmath0-glmb and that the problems introduced by the rendezvous point are again correctly tackled .",
    "[ fig:2:ospa ] shows the ospa distance .",
    "note that the ospa of the m@xmath0-glmb is close to the one of @xmath0-glmb , while the lmb shows an overall higher error in agreement with the cardinality error due to losing tracks .",
    "-glmb tracking filter using 3 toa . ]    -glmb tracking filter using 3 toa . ]    $ ] , @xmath216 ) using 3 toa . ]    $ ] , @xmath216 ) using 3 toa . ]",
    "this paper has proposed a novel approximation to the @xmath0-glmb filter with standard point detection measurements .",
    "the result is based on a principled glmb approximation to the labeled rfs posterior that matches exactly the posterior phd and cardinality distribution .",
    "the proposed approximation can be interpreted as performing a marginalization with respect to the association histories arising from the @xmath0-glmb filter .",
    "the key advantage of the new filter lies in the reduced growth rate of the number of new components generated at each filtering step .",
    "in particular , the approximation ( or marginalization ) step performed after each update is guaranteed to reduce the number of generated components which normally arise from multiple measurement - to - track association maps .",
    "typically , the proposed m@xmath0-glmb filter requires much less computation and storage especially in multi - sensor scenarios compared to the @xmath0-glmb filter .",
    "furthermore the proposed m@xmath0-glmb filter inherits the same implementation strategies and parallelizability of the @xmath0-glmb filter . a connection and alternative derivation of the lmb filter is also provided .",
    "future works will consider distributed estimation with the m@xmath0-glmb filter .",
    "m. mallick , s. coraluppi , and c. carthel ,  multi - target tracking using multiple hypothesis tracking ,   in _ integrated tracking , classification , and sensor management : theory and applications _ , m. mallick , v. krishnamurthy , b .-",
    "n . vo ( eds . ) , wiley / ieee , pp . 165201 , 2012 .",
    "vo , and b .-",
    " a random finite set conjugate prior and application to multi - target tracking ,   proc .",
    "intelligent sensors , sensor networks & information processing _ ( issnip2011 ) , adelaide , australia , dec . 2011 .",
    "l. a. mcgee , s. f. schmidt and g. l. smith , `` applications of statistical filter theory to the optimal estimation of position and velocity on board a circumlunar vehicle , '' nasa technical report r-135 , tech .",
    "rep . , 1962",
    ".    s. j. julier and j. k. uhlmann , `` a non - divergent estimation algorithm in the presence of unknown correlations , '' _ proc . of the ieee american control conference ( acc 1997 )",
    "4 , pp . 23692373 , 1997 ."
  ],
  "abstract_text": [
    "<S> the multi - target bayes filter proposed by mahler is a principled solution to recursive bayesian tracking based on rfs or fisst . </S>",
    "<S> the @xmath0-glmb filter is an exact closed form solution to the multi - target bayes recursion which yields joint state and label or trajectory estimates in the presence of clutter , missed detections and association uncertainty . due to presence of explicit data associations in the @xmath0-glmb filter </S>",
    "<S> , the number of components in the posterior grows without bound in time . in this work </S>",
    "<S> we propose an efficient approximation to the @xmath0-glmb filter which preserves both the phd and cardinality distribution of the labeled posterior . </S>",
    "<S> this approximation also facilitates efficient multi - sensor tracking with detection - based measurements . </S>",
    "<S> simulation results are presented to verify the proposed approach .    </S>",
    "<S> rfs , fisst , @xmath0-glmb filter , lmb filter , phd </S>"
  ]
}