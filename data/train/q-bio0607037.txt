{
  "article_text": [
    "imagine that we are handed a `` perfect sample '' of configurations of a protein  perfect , we are told , because it is made up of configurations that are fully independent of one another .",
    "how could we test this assertion ?",
    "the key is to note that , for any arbitrarily defined partitioning of the sample of @xmath13 configurations into @xmath14 subsets ( or bins ) , subsamples of these @xmath13 configurations obey very simple statistics . in particular ,",
    "the expected variance in the population of a bin , as estimated from many subsamples , depends only on the population of the bin and size @xmath15 of the subsample , as long as @xmath16 .    of course , a sample generated by a typical simulation is not made up of independent configurations .",
    "but since we know how the variance of subsamples should behave for an ideal sample of independent configurations , we are able to determine how much simulation time must elapse before configurations may be considered independent .",
    "we call this time the structural decorrelation time , @xmath6 .",
    "below , we show how to partition the trajectory into structurally defined subsets for this purpose , and how to extract @xmath6 .",
    "there is some precedence for using the populations of structurally defined bins as a measure of convergence@xcite .",
    "et al _ considered the number of structural clusters as a function of time as a way to evaluate the breadth and convergence of conformational sampling , and found this to be a much more sensitive indicator of sampling than other commonly used measures@xcite .",
    "simmerling and coworkers went one step further , and compared the populations of the clusters as sampled by different simulations@xcite . here , we go another step , by noting that the statistics of populations of structurally defined bins provide a unique insight into the quality of the sample .",
    "our analysis of a simulation trajectory proceeds in two steps , both described in sec .",
    "[ methods ] :      a `` structural histogram '' is a one - dimensional population analysis of a trajectory based on a partitioning ( classification ) of configuration space .",
    "such classifications are simple to perform based on proximity of the sampled configurations to a set of reference structures taken from the trajectory itself@xcite .",
    "the structural histogram will form the basis of the decorrelation time analysis .",
    "it defines a distribution , which is then used to answer the question , `` how much time must elapse between frames before we are sampling randomly from this distribution ? ''",
    "details are given in sec .",
    "[ methods ] .",
    "does the the equilibration of a structural histogram reflect the equilibration of the underlying conformational substates ( cs ) ? certainly , several cs s will be lumped together into the same bin , while others may be split between one or more bins . but",
    "clearly , equilibration of the overlying histogram bins requires equilibration of the underlying cs s .",
    "we will present evidence that this is indeed the case in sec .",
    "[ results ] .",
    "furthermore , since the configuration space distribution ( and the statistical error associated with our computational estimate thereof ) controls _ all _ ensemble averages , it determines the precision with which these averages are calculated .",
    "we will show that the convergence of a structural histogram is very sensitive to configuration space sampling errors .",
    "in this section we define an observable , @xmath19 , which depends very sensitively on the equilibration of the bins of a structural histogram as a function of simulation time @xmath20 .",
    "importantly , @xmath19 can be exactly calculated for a histogram of fully decorrelated structures .",
    "plotting @xmath19 as a function of @xmath20 , we identify the time at which the observed value equals that for fully decorrelated structures as the structural decorrelation time .    given a trajectory of @xmath13 frames , we build a uniform histogram of @xmath14 bins @xmath17 , using the procedure described in sec .",
    "[ methods ] . by construction ,",
    "the likelihood that a randomly selected frame belongs to bin ` @xmath21 ' of @xmath22 is simply @xmath23 .",
    "now imagine for a moment that the trajectory was generated by an algorithm which produced structures that are completely independent of one another",
    ". given a subsample of @xmath15 frames of this correlationless trajectory , the expected number of structures in the subsample belonging to a particular bin is simply @xmath24 , regardless of the `` time '' separation of the frames .    as the trajectory does not consist of independent structures , the statistics of subsamples depend on how the subsamples are selected .",
    "for example , a subsample of frames close together in time are more likely to belong to the same bin , as compared to a subsample of frames which span a longer time .",
    "frames that are close together ( in simulation time ) are more likely to be in similiar conformational substates , while frames separated by a time which is long compared to the typical inter - state transition times are effectively independent .",
    "the difference between these two types of subsamples  highly correlated vs. fully independent  is reflected in the _ variance _ among a set of subsampled bin populations ( see fig .",
    "[ subsamplefig ] ) . denoting the population of bin",
    "@xmath21 obseved in subsample @xmath25 as @xmath26 , the fractional population @xmath27 is defined as @xmath28 .",
    "the variance @xmath29 in the fractional population @xmath30 of bin @xmath21 is then defined as @xmath31 where overbars denote averaging over subsamples : @xmath32 .",
    "since here we are considering only uniform probability histograms , @xmath33 is the same for every @xmath21 : @xmath34 .    the expected variance of bin populations when allocating @xmath13 _ fully independent _ structures to @xmath14 bins is calculated in introductory probability texts under the rubric of `` sampling without replacement@xcite . ''",
    "the variance in fractional occupancy of each bin of this ( hypergeometric ) distribution depends only on the total number of _ independent _ structures @xmath5 , the size @xmath15 of the subsamples used to `` poll '' the distribution , and the fraction @xmath35 of the structures which are contained in each bin : @xmath36 but can we use this exact result to infer something about the correlations that are present in a typical trajectory ? following the intuition that frames close together in time are correlated , while frames far apart are independent , we compute the variance in eq .  [ variancedef ] for different sets of subsamples , which are distinguished by a fixed time @xmath20 between subsampled frames ( fig .",
    "[ subsamplefig ] ) .",
    "we expect that averaging over subsamples that consist of frames close together in time will lead to a variance which is higher than that expected from an ideal sample ( eq .",
    "[ hypervar ] ) . as @xmath20 increases",
    ", the variance should decrease as the frames in each subsample become less correlated . beyond some @xmath20 ( provided",
    "the trajectory is long enough ) , the subsampled frames will be independent , and the computed variance will be that expected from an i.i.d .  sample .    in practice ,",
    "we turn this intuition into a ( normalized ) observable @xmath37 in the following way :    plotting @xmath37 as a function of @xmath20 , we identify the subsampling interval @xmath20 at which the variance first equals the theoretical prediction as the structural decorrelation time , @xmath6 . for frames which are separated by at least @xmath6 ,",
    "it is as if they were drawn independently from the distribution defined by @xmath17 .",
    "the effective sample size @xmath5 is then the number of frames @xmath38 in the trajectory divided by @xmath18 .",
    "statistical uncertainty on thermodynamic averages is proportional to @xmath39 .    but",
    "does @xmath6 correspond to a physically meaningful timescale ?",
    "below , we show that the answer to this question is affirmative , and that , for a given trajectory , the same @xmath6 is computed , regardless of the histogram .",
    "indeed , @xmath6 does not depend on whether it is calculated based on a uniform or a nonuniform histogram .",
    "in the previous section , we introduced an observable , @xmath37 , and argued that it ought to be sensitive to the conformational convergence of a molecular simulation .",
    "however , we need to ask whether the results of the analysis reflect physical processes present in the simulation . after all",
    ", it may be that good sampling of a structural histogram is not indicative of good sampling of the conformation space .",
    "our strategy is to first test the analysis on some models with simple , known convergence behavior .",
    "we then turn our attention to more complex systems , which sample multiple conformational substates on several different timescales .",
    "perhaps the simplest nontrivial model we can imagine has two - states , with rare transitions between them . if we specify that the likelihood of a transition in a unit interval of time is a small constant @xmath40 ( poisson process ) , then the average lifetime of each state is simply @xmath41 .",
    "transitions are instantaneous , so that a `` trajectory '' of this model is simply a record of which state ( later , histogram bin ) was occupied at each timestep .",
    "our decorrelation analysis is designed to answer the question , `` given that the model is in a particular state , how much time must elapse before there is an equal probability to be in either state ? ''    figure  [ bernoullifig ] shows the results of the analysis for several different values of @xmath42 .",
    "the horizontal axis measures the time between subsampled frames .",
    "frames that are close together are likely to be in the same state , which results in a variance higher than that expected from an uncorrelated sample of the two states . as the time between subsampled frames increases ,",
    "the variance decreases , until reaching the value predicted for independent samples , where it stays .",
    "the inset demonstrates that the time for which the variance first reaches the theoretical value is easily read off when the data are plotted on a log - log scale . in all three cases , this value correlates well with the ( built - in ) transition time @xmath41 .",
    "it is noteworthy that , in each case , we actually must wait a bit longer than @xmath41 before the subsampled elements are uncorrelated .",
    "this likely reflects the additional waiting time necessary for the poisson trajectory to have equal likelihood of being in either state .",
    "as @xmath20 gets larger , the number of subsamples which `` fit '' into a trajectory decreases , and therefore @xmath19 is averaged over fewer subsamples .",
    "this results in some noise in measured value of @xmath19 , which gets more pronounced with increasing @xmath20 . to quantify this behavior",
    ", we added an @xmath43% confidence interval to the theoretical prediction , indicated by the error bars in the inset of fig .",
    "[ bernoullifig ] . given an @xmath15 and @xmath20 ,",
    "the number of subsamples is fixed .",
    "the error bars indicate the range where @xmath43 % of variance estimates fall , based on this fixed number of ( hypothesized ) independent samples from the hypergeometric distribution defined by @xmath17 .",
    "our approach readily obtains the physical timescale governing conformational equilibration in molecular systems .",
    "implicitly solvated leucine dipeptide ( ace - leu@xmath44-nme ) , having fifty atoms , is an ideal test system because a thorough sampling of conformation space is possible by brute force simulation .",
    "the degrees of freedom that distinguish the major conformations are the @xmath45 and @xmath46 dihedrals of the backbone , though side - chain degrees of freedom complicate the landscape by introducing many locally stable conformations within the major ramachandran basins .",
    "it is therefore intermediate in complexity between a `` toy - model '' and larger peptides .    two independent trajectories of @xmath47 @xmath48sec each were analyzed ;",
    "the simulation details have been reported elsewhere@xcite . for each trajectory , @xmath49",
    "independent histograms consisting of @xmath50 bins of uniform probability were built as described in sec .",
    "[ sec - histo ] . for each histogram , @xmath51 ( eq .  [ sigmadef ] )",
    "was computed for @xmath52 .",
    "we then averaged @xmath51 over the @xmath49 independent histograms separately for each @xmath15 and each trajectory  these averaged signals are plotted in fig .",
    "[ dileufig ] .",
    "when the subsamples consist of frames separated by short times @xmath20 , the subsamples are made of highly correlated frames .",
    "this leads to an observed variance greater than that expected for a sample of independent snapshots , as calculated for each @xmath15 from eq .",
    "[ hypervar ] and shown as a thick black horizontal line .",
    "@xmath51 then decreases monotonically with time , until it matches the theoretical prediction for decorrelated snapshots at about @xmath53 psec .",
    "the agreement between the computed and theoretical variance ( with no fitting parameters ) indicates that the subsampled frames are behaving as if they were sampled at random from the structural histogram .",
    "we therefore identify @xmath54 psec , giving an effective sample size of just over @xmath55 frames .",
    "does the decorrelation time correspond to a physical timescale ?",
    "first , we note that @xmath18 is independent of the subsample size @xmath15 , as shown in fig .",
    "[ dileufig ] .",
    "second , we note that the decorrelation times agree between the two independent trajectories .",
    "this is expected , since the trajectories are quite long for this small molecule , and therefore should be very well - sampled .",
    "finally , the decorrelation time is consistent with the typical transition time between the @xmath56 and @xmath57 basins of the ramachandran map , which is on the order of @xmath58 psec in this model . as in the poisson process",
    ", @xmath6 is a bit longer than the @xmath59 transition time .    how would the data look if we had a much shorter trajectory , of the order of @xmath6 ?",
    "this is also answered in fig .",
    "[ dileufig ] , where we have analyzed a dileucine trajectory of only @xmath47 nsec in length .",
    "frames every @xmath50 fsec , so that this trajectory had the same total number of frames as each of the @xmath47 @xmath48sec trajectories .",
    "the results are striking  not only does @xmath51 fail to attain the value for independent sampling , but the values appear to connect smoothly ( apart from some noise ) with the data from the longer trajectories .",
    "( we stress that the @xmath47 nsec trajectory was generated and analyzed independently of both @xmath47 @xmath48sec trajectories  it is not simply the first nsec of either . ) in the event that we had only the @xmath47 nsec trajectories , we could state unequivocably that they are poorly converged , since they fail to attain the theoretical prediction for a well - converged trajectory .",
    "we also investigated whether the decorrelation time depends on the number of reference structures used to build the structural histogram .",
    "as shown in fig .",
    "[ diff - num - refs ] , @xmath6 is the same , whether we use a histogram of @xmath50 bins or @xmath9 bins .",
    "[ dileufig ] used @xmath50 bins . )",
    "it is interesting that the data are somewhat smoothed by dividing up the sampled space among more reference structures .",
    "while this seems to argue for increasing the number of reference structures , it should be remembered that increasing the number of references by a factor of @xmath10 increases the computational cost of the analysis by the same factor , while @xmath6 is robustly estimated based on a histogram containing @xmath50 bins .",
    "we next considered a previously developed united - residue model of the n - terminal domain of calmodulin@xcite . in the `` double native '' g",
    "potential used , both the apo ( ca@xmath60free)@xcite and holo ( ca@xmath60bound)@xcite structures are stabilized , so that occasional transitions are observed between the two states .",
    "in contrast with the dileucine model just discussed , our coarse - grained calmodulin simulation has available a much larger conformation space .",
    "the apo - holo transition represents a motion entailing @xmath61   rmsd , and involves a collective rearrangement of helices .",
    "in addition to apo - holo transitions , the trajectories include partial unfolding events , which do not lend themselves to an interpretation as transitions between well - defined states . in light of these different processes , it will be interesting to see how our analysis fares .",
    "two independent trajectories were analyzed , each @xmath62 monte carlo sweeps ( mcs ) in length .",
    "each trajectory was begun in the apo configuration , and approximately @xmath63 transition events were observed in each . for both trajectories ,",
    "the analysis was averaged over @xmath64 independent histograms , each with @xmath50 bins of uniform probability .",
    "the results of the analysis are shown in fig .",
    "[ doublegofig ] .",
    "it is interesting that the decorrelation time estimated from fig .",
    "[ doublegofig ] is about a factor of @xmath8 _ shorter _ than the average waiting time between @xmath65 transitions .",
    "this is perhaps due to the noisier signal ( as compared to the previous cases ) , which is in turn due to the small number of transition events observed  about @xmath63 in each trajectory , compared to about @xmath66 events in the dileucine trajectories .",
    "alternatively , it may be that there are other , longer timescale processes , such as partial unfolding and refolding events , which must be sampled before convergence is attained .    in either case , our analysis yields a robust estimate of the decorrelation time , regardless of the underlying processes .",
    "the conclusion we draw from this data is that one should only interepret the decorrelation analysis as `` logarithmically accurate '' ( up to a factor of @xmath67 ) when the data are noisy .      in the previous examples , we considered models which admit a description in terms of two dominant states with occasional transitions between them . here",
    ", we study the highly flexible pentapeptide met - enkephalin ( nh@xmath68-tyr-[gly]@xmath44-phe - met - coo@xmath69 ) , which does not lend itself to such a simple description .",
    "our aim is to see how our convergence analysis will perform in this case , where multiple conformations are interconverting on many different timescales .    despite the lack of a simple description in terms of a few , well - defined states connected by occasional transitions , our decorrelation analysis yields an unambiguous signal of the decorrelation time for this system . the data ( fig .",
    "[ metenkfig ] ) indicate that @xmath64 or @xmath10 nsec must elapse between frames before they be considered statistically independent , which in turn implies that each of our @xmath47 @xmath48sec trajectories has an effective sample size of @xmath70 or @xmath71 frames .",
    "we stress that this is learned from a `` blind '' analysis , without any knowledge of the underlying free energy surface .",
    "we have developed a new tool for assessing the quality of molecular simulation trajectories , quantifying `` structural correlation '' , the tendency for snapshots which are close together in simulation time to be similiar .",
    "the analysis first computes a structural decorrelation time , which answers the question , `` how much simulation time must elapse before the sampled structures display the statistics of an i.i.d sample . ''",
    "this in turn implies an effective sample size , @xmath72 , which is the number of frames in the trajectory that are statiscally independent , in the sense that they may be thought of as independent and identically distributed .    in several model systems ,",
    "for which the timescale needed to decorrelate snapshots was known in advance , we have shown that the decorrelation analysis is consistent with the `` built - in '' timescale .",
    "we have also shown that the results are not sensitive to the details of the structural histogram or to the subsampling scheme used to analyze the resulting timeseries .",
    "there are no adjustable parameters .",
    "finally , we have demonstrated a calculation of an effective sample size for a system which can not be approximately described in terms of a small number of well - defined states and a few dominant timescales .",
    "this is critically important , since the important states of a system are generally not known in advance .",
    "our method may be applied in a straightforward way to discontinuous trajectories , which consist of several independent pieces@xcite .",
    "the analysis would be carried forward just as for a continuous trajectory . in this case , a few subsamples will be corrupted by the fact that they span the boundaries between the independent pieces . the error introduced will be minimal , provided that the correlation time is shorter than the length of each independent piece .",
    "the analysis is also readily applicable to exchange - type simulations , in which configurations are swapped between different simulations running in parallel . for a ladder of @xmath73 replicas , one would perform the analysis on each of the @xmath73 _ continuous _ trajectories that are had by following each replica as it wanders up and down the ladder . if the ladder is well - mixed , then all of the trajectories should have the same decorrelation time . and",
    "if the exchange simulation is more efficient than a standard simulation , then each replica will have a shorter decorrelation time than a `` standard '' simulation .",
    "this last observation attains considerable exigence , in light of the fact that exchange simulations have become the method of choice for state - of - the - art simulation .",
    "there is a growing sense in the modeling and simulation community of the need to standardize measures of the quality of simulation results@xcite .",
    "our method , designed specifically to address the statistical quality of an _ ensemble _ of structures , should be useful in this context .",
    "previously , we presented an algorithm which generated a histogram based on clustering the trajectory with a fixed cutoff radius@xcite , resulting in bins of varying probability . here , we present a slightly modified procedure , which partitions the trajectory into bins of _ uniform _ probability , by allowing the cutoff radius to vary . for a particular continuous trajectory of @xmath13 frames ,",
    "the following steps are performed :      we analyzed two coarse - grained simulations of the n - terminal domain of calmodulin .",
    "full details and analysis of the model have been published previously@xcite , here we briefly recount only the most relevant details .",
    "the model is a one bead per residue model of @xmath12 residues ( numbers @xmath74 in pdb structure 1cfd ) , linked together as a freely jointed chain .",
    "conformations corresponding to both the apo ( pdb i d 1cfd ) and holo ( pdb i d 1cll ) crystal structures@xcite are stabilized by go interactions@xcite .",
    "since both the apo and holo forms are stable , transitions are observed between these two states , ocurring on average about once every @xmath75 monte carlo sweeps ( mcs ) .",
    "we analyzed two independent @xmath47 @xmath48sec trajectories and a single @xmath47 nsec trajectory , each started from the pdb structure 1plw , model @xmath47 .",
    "the potential energy was described by the oplsaa potential@xcite , with solvation treated implicitly by the gb / sa method@xcite .",
    "the equations of motion were integrated stochastically , using the discretized langevin equation implemented in tinker v. @xmath76 , with a friction constant of @xmath10 psec@xmath77 and the temperature set to @xmath78 k@xcite .",
    "a total of @xmath79 evenly spaced configurations were stored for each trajectory .",
    "asim okur , lauren wickstrom , melinda layten , raphel geney , kun song , victor hornak , and carlos simmerling .",
    "improved efficiency of replica exchange simulations through use of a hybrid explicit / implicit solvation model .",
    ", 2:420433 , 2006 .                             and intervals @xmath20 . in the top figure , the pink highlighted frames belong to an @xmath80 , @xmath81 subsample , the blue frames to another subsample of the same type .",
    "the bottom figure shows two @xmath82 , @xmath83 subsamples .",
    "the frame index ( simulation time ) is labelled by @xmath84 . ]",
    "@xmath48sec dileucine trajectories ( distinguished by dashed and solid lines ) and a single @xmath47 nsec trajectory ( dash - dot lines ) for @xmath85 different subsample sizes : @xmath82 ( blue ) , @xmath86 ( red ) , and @xmath87 ( green ) .",
    "the solid horizontal line indicates the expected variance for i.i.d",
    ".  samples .",
    "the average time between @xmath65 transitions is indicated .",
    "an @xmath43 % confidence interval on the ( @xmath86 , red ) theoretical prediction for independent samples is indicated by the error bars . ]",
    "@xmath48sec met - enkephalin trajectories , distinguished by solid and dashed lines , for subsample sizes @xmath86 ( red ) and @xmath87 ( green ) .",
    "error bars indicate @xmath43 % confidence intervals for uncorrelated subsamples of size @xmath86 . ]"
  ],
  "abstract_text": [
    "<S> although atomistic simulations of proteins and other biological systems are approaching microsecond timescales , the quality of trajectories has remained difficult to assess . </S>",
    "<S> such assessment is critical not only for establishing the relevance of any individual simulation but also in the extremely active field of developing computational methods . </S>",
    "<S> here we map the trajectory assessment problem onto a simple statistical calculation of the `` effective sample size '' - i.e. , the number of statistically independent configurations . </S>",
    "<S> the mapping is achieved by asking the question , `` how much time must elapse between snapshots included in a sample for that sample to exhibit the statistical properties expected for independent and identically distributed configurations ? '' the resulting `` structural de - correlation time '' is robustly calculated using exact properties deduced from our previously developed `` structural histograms , '' without any fitting parameters . </S>",
    "<S> we show the method is equally and directly applicable to toy models , peptides , and a 72-residue protein model . </S>",
    "<S> variants of our approach can readily be applied to a wide range of physical and chemical systems .    </S>",
    "<S> what does convergence mean ? </S>",
    "<S> the answer is not simply of abstract interest , since many aspects of the biomolecular simulation field depend on it . when parameterizing potential functions , it is essential to know whether inaccuracies are attributable to the potential , rather than under - sampling . in the extremely active area of methods development for equilibrium sampling , </S>",
    "<S> it is necessary to demonstrate that a novel approach is better than its predecessors , in the sense that it equilibrates the relative populations of different conformers in less cpu time@xcite . and </S>",
    "<S> in the important area of free energy calculations , under - sampling can result in both systematic error and poor precision .    to rephrase the basic question , given a simulation trajectory ( an ordered set of correlated configurations ) , </S>",
    "<S> what characteristics should be observed if convergence has been achieved ? the obvious , if tautological , answer is that all states should have been visited with the correct relative probabilities , as governed by a boltzmann factor ( implicitly , free energy ) in most cases of physical interest . yet given the omnipresence of statistical error , it has long been accepted that such idealizations are of limited value . </S>",
    "<S> the more pertinent questions have therefore been taken to be : does the trajectory give reliable estimates for quantities of interest ? </S>",
    "<S> what is the statistical uncertainty in these estimates@xcite ? </S>",
    "<S> in other words , _ convergence is relative _ , and in principle , it is rarely meaningful to describe a simulation as not converged , in an absolute sense . </S>",
    "<S> ( an exception is when a priori information indicates the trajectory has failed to visit certain states . )    </S>",
    "<S> accepting the relativity of convergence points directly to the importance of computing statistical uncertainty . </S>",
    "<S> the reliability of ensemble averages typically has been gauged in the context of basic statistical theory , by noting that statistical errors decrease with the square - root of the number of independent samples . </S>",
    "<S> the number of independent samples @xmath0 pertinent to the uncertainty in a quantity @xmath1 , in turn , has been judged by comparing the trajectory length to the timescale of @xmath1 s correlation with itself@xmath1 s autocorrelation time@xcite . </S>",
    "<S> thus , a trajectory of length @xmath2 with an auto - correlation time for @xmath1 of @xmath3 can be said to provide an estimate for @xmath1 with relative precision of roughly @xmath4 .    </S>",
    "<S> however , the estimation of correlation times can be an uncertain business , as good measurements of correlation functions require a lot of data@xcite . </S>",
    "<S> furthermore , different quantities typically have different correlation times . </S>",
    "<S> other assessment approaches have therefore been proposed , such as the ergodic measure@xcite , analysis of principle components@xcite and , more recently , structural histograms@xcite . </S>",
    "<S> although these approaches are applicable to quite complex systems without invoking correlation functions , they attempt only to give an overall sense of convergence rather than quantifying precision .    </S>",
    "<S> flyvbjerg and petersen provided perhaps the most satisfying approach to quantifying the precision of an estimate in any particular quantity without relying on correlation functions@xcite . the sophisticated block averaging scheme they present gauges whether correlation effects have been removed by considering a range of block sizes . </S>",
    "<S> the reasoning underlying their analysis is that , once the block length is longer than any correlation time(s ) , the estimated precision ( statistical uncertainty ) will no longer depend on block size .    </S>",
    "<S> our approach generalizes the logic implicit in the flyvbjerg - petersen analysis by developing an overall structural de - correlation time which can be estimated , simply and robustly , in biomolecular and other systems . </S>",
    "<S> the key to our method is to view a simulation as sampling an underlying distribution ( typically a boltzmann factor ) of the configuration space , from which all equilibrium quantities follow . </S>",
    "<S> our approach builds implicitly on the multi - basin picture proposed by frauenfelder and coworkers@xcite , in which conformational equilibration requires equilibrating the relative populations of the various conformational substates .    on the basis of the configuration - space distribution , we can define the general effective sample size @xmath5 and the associated ( de-)correlation time @xmath6 associated with a particular trajectory . </S>",
    "<S> specifically , @xmath6 is the minimum time that must elapse between configurations for them to become fully decorrelated ( i.e. , with respect to any quantity ) . here , fully decorrelated has a very specific meaning , which leads to testable hypotheses : a set of fully decorrelated configurations will exhibit the statistics of an independently and identically distributed ( i.i.d . ) </S>",
    "<S> sample of the governing boltzmann - factor distribution . </S>",
    "<S> below , we detail the tests we use to compute @xmath6 , which build on our recently proposed structural histogram analysis@xcite ; see also @xcite .    </S>",
    "<S> the key point is that the expected i.i.d .  </S>",
    "<S> statistics must apply to any assay of a decorrelated sample . </S>",
    "<S> the contribution of the present paper is to recognize this , and then to describe an assay directly probing the configuration - space distribution for which analytic results are easily obtained for any system , assuming an i.i.d .  </S>",
    "<S> sample . </S>",
    "<S> procedurally , then , we simply apply our assay to increasing values hypothesized for @xmath6 . </S>",
    "<S> when the value is too small , the correlations lead to anomalous statistics ( fluctuations ) , but once the assayed fluctuations match the analytic i.i.d . </S>",
    "<S> predictions , the de - correlation time @xmath6 has been reached . </S>",
    "<S> hence , _ there is no fitting of any kind_. importantly , by a suitable use of our `` structural histograms''@xcite , which directly describe configuration - space distributions , we can map a system of any complexity to an exactly soluble model .    in practical terms , our analysis readily computes the configurational / structural decorrelation time @xmath6 ( and hence the number of independent samples @xmath5 ) for a long trajectory many times the length of @xmath6 . in turn </S>",
    "<S> , this provides a means for estimating statistical uncertainties in observables of interest , such as relative populations . of equal importance </S>",
    "<S> , our analysis can reveal when a trajectory is dominated by statistical error , i.e. , when the simulation time @xmath7 . </S>",
    "<S> we note , however , that our analysis remains subject to the intrinsic limitation pertinent to all methods which aim to judge the quality of conformational sampling  of not knowing about parts of configuration space never visited by the trajectory being analyzed .    </S>",
    "<S> in contrast to most existing quantitative approaches , which attempt to assess convergence of a single quantity , our general approach enables the generation of ensembles of known statistical properties . </S>",
    "<S> these ensembles in turn can then be used for many purposes beyond ensemble averaging , such as docking , or developing a better understanding of native protein ensembles .    in the remainder of the paper , we describe the theory behind our assay , and then successfully apply it to a wide range of systems . </S>",
    "<S> we first consider a two - state poisson process for illustrative purposes , followed by molecular systems : di - leucine peptide ( @xmath8 residues ; @xmath9 atoms ) , met - enkephalin ( @xmath10 residues ; @xmath11 atoms ) , and a coarse - grained model of the n - terminal domain of calmodulin ( @xmath12 united residues ) . </S>",
    "<S> for all the molecules , we test that our calculation for @xmath6 is insensitive to details of the computation . </S>"
  ]
}