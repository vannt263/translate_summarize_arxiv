{
  "article_text": [
    "in general , the redshifts of galaxy are measured spectroscopically . in order to achieve high signal - to - noise spectra , long integration time is required . for those large and faint sets of galaxies ,",
    "however , spectra of galaxies are not easy or impractical to obtain . in the absence of spectroscopic data , redshifts of galaxies",
    "may be estimated using medium- or broadband photometry , which may be thought of as very low - resolution spectroscopy",
    ". though such photometric redshifts are necessarily less accurate than true spectroscopic redshifts , they nonetheless are sufficient to determine the formation and evolution properties of large number of galaxies rather than to study accurate redshift of individual galaxy ( gwyn 1990 ) .",
    "photometric redshifts may be obtained less expensively and for much larger samples than is possible with spectroscopy . in the nineties",
    ", photometric redshifts is rapidly becoming a crucial tool in mainstream observational cosmology . to date",
    ", some photometric redshift catalogs have been used to deal with several scientific issues , e.g. the evolution of the luminosity density and the number of massive galaxies already assembled at early epochs ( fontana et al .",
    "2000 ) , the evolution of galaxy size ( poli et al .",
    "1999 ; giallongo et al .",
    "2000 ) , the determination of cosmological baryonic and matter densities ( blake et   al . 2007 ) , and the clustering of luminous red galaxies in sdss imaging data ( padmanabhan et al .",
    "2007 ) .",
    "techniques for deriving photometric redshifts were pioneered by baum ( 1962 ) .",
    "subsequent implementations of these basic techniques have been made by couch et al .",
    "( 1983 ) and koo ( 1985 ) .",
    "photometric redshift techniques have been divided into two broad categories : template matching method and empirical training - set method .",
    "there are advantages and disadvantages to each approach .",
    "the former approach relies on fitting model galaxy spectral energy distributions ( seds ) to the photometric data , where the models span a range of expected galaxy redshifts and spectral types ( e.g. , sawicki , lin & yee 1997 ) . a library of template spectra ( e.g. bruzual & charlot 1993 ; coleman , wu & weedman 1980 ) are employed .",
    "a @xmath4 fit is used to obtain the optimal template pairs for each galaxy .",
    "the various techniques in this kind is different from their choice of template sed s and in the procedure for fitting .",
    "template sed s may come from population synthesis models ( eg .",
    "bruzual & charlot 1993 ) or from spectra of real objects ( eg .",
    "coleman , wu & weedman 1980 ) .",
    "both kinds of templates have their weaknesses - template sed s from population synthesis models may include unrealistic combinations of parameters or exclude known cases .",
    "the real galaxy templates are almost always derived from data on bright low redshift galaxies , and may be poor representations of the high redshift galaxy population ( wadadekar 2005 ) .",
    "the latter approach depends on using an existing spectroscopic redshift sample as a training set to derive photometric redshifts as the function of photometric data .",
    "some typical training - set methods employed include : artificial neural networks ( anns , colister & lahav 2004 ; firth , lahav & somerville 2003 ; vanzella et al .",
    "2004 ; li et al .",
    "2006 ) , support vector machines ( svms , wadadekar 2005 ) , ensemble learning and gaussian process regression ( way & srivastava 2006 ) and linear and non - linear polynomial fitting ( brunner et al . 1997 ; wang , bahcall , & turner 1998 ; budav@xmath5ri et al . 2005 ; hsieh et al . 2005 ; connolly et al .",
    "such techniques have strengthes that they are automatically constructed by the properties of galaxies in the real universe and require no additional assumptions about their formation and evolution .",
    "however for the empirical best fit method , such as linear and non - linear polynomial fitting , it is difficult to extrapolate to objects fainter than the spectroscopic limit . for the ann approach ,",
    "its optimal architecture is not easy to obtain , moreover and it is easy to get stuck in local minima during training stage . unlike anns , svms do not need choice of architecture before training , but the optimal parameters in their models are obtained with much effort .",
    "another interpolative training - set methods are instance - based learning techniques , applied to predict photometric redshifts ( eg .",
    "csabai et al .",
    "2003 ; ball et al .",
    "instance - based learning methods base their predictions directly on ( training ) data that has been stored in the memory .",
    "usually they store all the training data in the memory during the learning phase , and defer all the essential computation until the prediction phase .",
    "examples of such techniques are @xmath6-nearest neighbor , kernel regression and locally weighted regression .",
    "if setting @xmath6 to @xmath7 ( the number of data points ) and optimizing weights by gradient descent , @xmath6-nearest neighbor turns into kernel regression , while locally weighted regression generalized kernel regression , not just obtains local average values . in general , irrelevant features are often killers for instance - based approaches . but",
    "anns can be trained directly on problems with hundreds or thousands of inputs .",
    "instance - based learning methods can fit low dimensional , very complex functions very accurately while anns require considerable tweaking to do this . when adding new data , training is almost free for instance - based learning methods , but anns and svms need retraining the data .",
    "we put forward a kernel regression method to estimate photometric redshifts .",
    "this paper is organized as follows . in section  2",
    "we describe the data we use .",
    "a brief overview of kernel regression is addressed in section 3 .",
    "section 4 illustrates the results and discussion , and the conclusion is presented in section 5 .",
    "the sloan digital sky survey ( sdss , york et al .",
    "2000 ) is the most ambitious astronomical survey ever undertaken . when completed , it will provide detailed optical images covering more than a quarter of the sky , and a 3-dimensional map of about a million galaxies and quasars , with a dedicated 2.5-meter telescope located on apache point , new mexico .",
    "the first stage of sdss is already complete ( with dr5 ) .",
    "it has imaged 8,000 square degrees in five bandpasses ( @xmath8 ) and measured spectra of more than 675,000 galaxies , 90,000 quasars and 185,000 stars . in its second stage , sdss will carry out three new surveys in different research areas , such as the nature of the universe , the origin of galaxies and quasars and the formation and evolution of the milky way . in order to construct a representative sample set",
    ", we collected all objects satisfying the follow criteria from sdss data release 5 ( adelman - mccarthy et al . 2007 ) .",
    "all following mentioned magnitudes are magnitudes corrected by galaxy extinction using the dust maps of schlegel et al . 1998 .",
    "after these restrictions that the spectroscopic redshift confidence must be greater than or equal to 0.95 , and the redshift flags should be zero , we obtained a sample containing 399,929 galaxies .",
    "the photometry properties discussed below are available in all five sdss bandpasses ( @xmath0 ) , however the @xmath9-bandpass values for these quantities are usually applied for the @xmath9-band result generally has the lowest error and gives more consistent results ( way & srivastava 2006 ) .",
    "the petrosian 50% ( 90% ) radius is the radius where 50% ( 90% ) of the flux of the object contributes .",
    "@xmath10 is petrosian 50% radius in @xmath9 band , @xmath11 is petrosian 90% radius in @xmath9 band .",
    "the ratio of these quantities is called petrosian concentration index @xmath12=@xmath13 , which is an indicator of the galaxy type : early - type galaxy with @xmath14 2.5 and late - type galaxy with @xmath15 2.5 ( strateva et al .",
    "the petrosian radii are also utilized together with a measure of the profile type from the sdss photometric pipeline reduction named fracdev .",
    "fracdev results from a linear combination of the best exponential and de vaucouleus profiles that are fit to the image in each band .",
    "fracdev is a floating point number between zero and 1 .",
    "fracdev is closely related to galaxy type while it is 1 for a pure de vaucouleurs profile typical of early - type galaxies and zero for a pure exponential profile typical of late - type galaxies .",
    "eclass is a spectroscopic parameter giving the spectral type from a principal component analysis , which is a continuous value ranging from about -0.5 ( early - type galaxies ) to 1 ( late - type galaxies ) .",
    "kernel regression ( watson , 1964 ; nadaraya , 1964 ) belongs to the family of instance - based learning algorithms , which simply store some or all of the training examples and  delay learning \" till prediction time . given a query point @xmath16",
    ", a prediction is obtained using the training samples that are  most similar \" to @xmath16 .",
    "similarity is measured by means of a distance metric defined in the hyper - space of @xmath17 predictor variables .",
    "kernel regressors obtain the prediction for a query point @xmath16 , by a weighted average of the @xmath18 values of its neighbors .",
    "the weight of each neighbor is calculated by a function of its distance to @xmath16 ( called the kernel function ) .",
    "these kernel functions give more weight to neighbors that are nearer to @xmath16 .",
    "the notion of neighborhood ( or bandwidth ) is defined in terms of distance from @xmath16 .",
    "the prediction for query point @xmath16 is obtained by @xmath19 where @xmath20 is the distance function between two instances ; @xmath21 is a kernel function ; @xmath22 is a bandwidth value ; @xmath23 are training samples ; @xmath24 and @xmath16 are vectors ; @xmath25 is the number of datapoints used in the model . in this paper , we use euclidian distance and gaussian kernel function .",
    "@xmath24 is the feature for each training sample , @xmath26 is the spectroscopic redshift for each training set sample , @xmath27 is the redshift of each query sample .",
    "one important design decision when using kernel regression is the choice of the bandwidth @xmath22 . the larger @xmath22 results in the flatter weight function curve , which indicates that many points of training set contribute quite evenly to the regression .",
    "as the @xmath22 tends to infinity the predictions approach the global average of all points in the database .",
    "if the @xmath22 is very small , only closely neighboring datapoints make a significant contribution .",
    "if the data is relatively noisy , we expect to obtain smaller prediction errors with a relatively larger @xmath22 .",
    "if the data is noise free , then a small @xmath22 will avoid smearing away fine details in the function .",
    "there exists mature algorithms for choosing the bandwidth for kernel regression that minimize a statistical measure of the difference between the true underlying distribution and the estimated distribution .",
    "usually bandwidth selection in regression is done by cross - validation ( cv ) or the penalized residual sum of squares .",
    "cross - validation is the statistical method of dividing a sample of data into subsets such that the analysis is initially performed on a single subset , while the other subset(s ) are retained for subsequent use in confirming and validating the initial analysis .",
    "@xmath28-fold cross - validation is one important cross - validation method .",
    "the data is divided into @xmath28 subsets of ( approximately ) equal size .",
    "each time , one of the @xmath28 subsets is used as the test set and the other @xmath291 subsets are put together to form a training set .",
    "cross - validation is designed to choose the bandwidth by minimizing the cross - validation score cv(@xmath22 ) defined by @xmath30 @xmath31\\ ] ] where @xmath32 is the spectroscopic redshift for each test set sample , @xmath33 is the predicted photometric redshift of each test sample , @xmath34 is the number of objects in each subset ( @xmath35 ) , @xmath28 is the number of subsets for cross - validation . in general , the @xmath34 values are identical .",
    "here we adopt 10-fold cross - validation for the bandwidth choice , i.e. @xmath28=10 , firstly divide the sample of 399,929 galaxies into 10 subsets , then 9 subsets of 10 subsets are taken as training set and the rest subset as testing set for ten times .",
    "we adopt the sample described in section 2 , applying four color indexes ( @xmath36 , @xmath37 , @xmath38 and @xmath39 ) and spectroscopic redshifts as input parameters .",
    "then we implement kernel regression on this sample and compute the 10-fold cross - validated score for different bandwidths in table 1 . as shown by table  1 , the cross - validated score cv(@xmath22 ) reaches the minimum @xmath40 when @xmath22 is equal to 0.02 .",
    "therefore , 0.02 has been assigned to the optimal fixed bandwidth for the sample in this case .      in this work ,",
    "we choose the input parameters using the akaike information criterion ( aic ) .",
    "aic ( akaike 1974 ) is a measure of the goodness of fit of an estimated statistical model .",
    "the aic methodology attempts to find the model that best explains the data with a minimum of free parameters . in the general case , aic is @xmath41 where _",
    "l@xmath42 _ is the maximized likelihood function , and _",
    "k _ is the number of free parameters in the model .",
    "the purpose of model selection is to identify a model that best fits the available data set .",
    "a model is better than another model if it has a smaller aic value .",
    "when a model approach the lowest values of aic , the model is regarded as the best model .",
    "several recent works in astrophysics have used aic for model selection ( e.g. liddle 2004 , 2007 ) . in section 4.1",
    ", aic will be used to select the optimal input pattern .",
    ".bandwidth determination using the cross - validated ( cv ) method [ cols=\"<,^\",options=\"header \" , ]     note.- sdss - edr = early data release ( stoughton et al . 2002 ) , sdss - dr1 = data release 1 ( abazajian et al . 2003 ) , sdss - dr2 = data release 2 ( abazajian et al . 2004 ) , sdss - dr5 = data release 5 ( adelman - mccarthy et al . 2007 ) .",
    "@xmath10 is petrosian 50% radius in @xmath9 band , @xmath11 is petrosian 90% radius in @xmath9 band , fracdev@xmath43 is fracdev in @xmath9 band , color is the color indexes , i.e. @xmath36 , @xmath37 , @xmath38 , @xmath39",
    ". + ( 1 ) csabai et al . 2003 ; ( 2 ) suchkov , hanisch & margonet 2005 ; + ( 3 ) wadadekar 2005 ; ( 4 ) collister & lahav 2004 ; ( 5 ) budav@xmath5ri et al .",
    "2005 .    with large and deep photometric surveys are carried out , it seems that kernel regression will offer some significant advantages over other approaches , as shown in table 4 .",
    "the performance of kernel regression to predict photometric redshifts is comparable to anns and svms , superior to kd - tree , classx and polynomial regression , and more preferable than cww and bruzual - charlot ( wadadekar 2005 ; collister & lahav , 2004 ; csabai et al .",
    "2003 ; see their tables 1 ) .",
    "a major problem for empirical training - set method is the difficulty in extrapolating to regions where the input parameters are not well represented by the training data .",
    "but for kernel regression , even though a few high - redshift galaxies exists in the sample , one can appropriately adjust bandwidth to obtain much more accurate redshifts .",
    "in addition , compared to other training - set methods , kernel regression has another advantage that it need nt retraining when a new query point appears .",
    "we have presented an instance - based learning method called kernel regression to predict photometric redshifts of galaxies with the data from sdss broadband photometry . important work in kernel regression",
    "is how to determine the bandwidth .",
    "we use 10-fold cross - validation to choose the optimal bandwidth .",
    "our experiments show that the optimal bandwidth is different for different input parameters , the color+eclass pattern is the best when the rms error of photometric redshift estimation adds up to 0.0189 , the @xmath0+eclass is better when the rms error is 0.0198 . except these two situations ,",
    "the color@xmath1 pattern is the best when the rms scatter is 0.0206 .",
    "the parameters , such as @xmath10 , @xmath11 , fracdev@xmath43 and @xmath12 , contribute little information , however eclass shows much importance .",
    "moreover kernel regression achieves high accuracy to predict photometric redshifts for early - type galaxies and the photometric eclass . for anns , the more parameters considered , the accuracy of photometric redshifts is higher ( way & srivastava 2006 ; li et al .",
    "2006 ) . while for kernel regression and svms ,",
    "the accuracy is satisfactory only when appropriate parameters are chosen . to our satisfaction , kernel regression is able to measure photometric redshifts of galaxies , accurately .",
    "this is helpful to construct the sample of galaxies for the study of cosmology with minimal contamination from objects at seriously incorrect redshifts .",
    "similarly kernel regression may be applied to predict photometric redshifts of quasars .",
    "kernel regression has a number of flexibilities .",
    "it is possible to make different queries with not only different kernel widths @xmath22 , but also different distance metrics , with subsets of attributes ignored , or with some other distance metrics such as manhattan distance , canberra distance .",
    "it is also possible to apply the same technique with different kernel functions for classification instead of regression . unlike the traditional training methods ,",
    "its best merit is the ability to make predictions with different parameters without needing a retraining phase , moreover it does nt seriously depend on the size of sample .",
    "nevertheless it has the obvious disadvantage of instance - based learning that is a significant computational cost on large data sets . in the future work",
    "we will explore different functions or other kinds of distance metric for kernel regression on the regression problems .",
    "in addition , we may use multiresolution instance - based learning as suggested by deng & moore ( 1995 ) .",
    "this method succeeds in reducing the cost of instance - based learning , moreover it has two advantages : flexibility to work throughout the local / global data ; the ability to make predictions with different parameters without needing a retraining phase",
    ".    0.5 cm",
    "the authors are very grateful to the anonymous referee whose insightful and detailed comments led to the improvement of our work .",
    "this paper is funded by national natural science foundation of china under grant no.90412016 , no.60603057 and 10778623 .",
    "funding for the sdss and sdss - ii has been provided by the alfred p. sloan foundation , the participating institutions , the national science foundation , the u.s .",
    "department of energy , the national aeronautics and space administration , the japanese monbukagakusho , the max planck society , and the higher education funding council for england .",
    "the sdss web site is http://www.sdss.org/.    the sdss is managed by the astrophysical research consortium for the participating institutions .",
    "the participating institutions are the american museum of natural history , astrophysical institute potsdam , university of basel , university of cambridge , case western reserve university , university of chicago , drexel university , fermilab , the institute for advanced study , the japan participation group , johns hopkins university , the joint institute for nuclear astrophysics , the kavli institute for particle astrophysics and cosmology , the korean scientist group , the chinese academy of sciences ( lamost ) , los alamos national laboratory , the max - planck - institute for astronomy ( mpia ) , the max - planck - institute for astrophysics ( mpa ) , new mexico state university , ohio state university , university of pittsburgh , university of portsmouth , princeton university , the united states naval observatory , and the university of washington .",
    "abazajian k. et al . , 2003 ,",
    "aj , 126 , 2081 abazajian k. et al . , 2004 , aj , 128 , 502 adelman - mccarthy j. et al . , 2007 ,",
    "submitted to apjs akaike h. 1974 , ieee t. automat .",
    "contr . , 19 , 716 ball n. m. , brunner r. j. , myers a. d. , strand n. e. , alberts s. l. , tcheng d. , lior@xmath5 x. , 2007 , preprint(astro - ph/0612471 ) baum w. a. , 1962 , in george c. m. , eds , proc .",
    "15 , photoelectric magnitudes and red - shifts .",
    "macrmillan press , new york , p. 390 ben@xmath44tez , n. , 2000 , apj , 536 , 571 blake c. , colister a. , bridle s. , lahav o. , 2007 , mnras , 374 , 1527 brunner r. j. , connolly a. j. , szalay a. s. , bershady m. a. , 1997 , apj , 482 , l21 bruzual a. g. , charlot s. , 1993 , apj , 405 , 538 budav@xmath5ri t. et al . , 2005 , apj , 619 , l31 coleman g. d. , wu c. c. , weedman d. w. , 1980 , apjs , 43 , 393 collister a. a. , lahav o. , 2004 , pasp , 116 , 345 connolly a. j. , csabai i. , szalay a. s. , koo d. c. , kron r. g. , munn j. a. , 1995 , aj , 110 , 2655 couch w. j. , ellis r. s. , godwin j. , carter d. , 1983 , mnras , 205 , 1287 csabai i. et al .",
    "2003 , apj , 125 , 580 deng k. , moore a. , 1995 , proceedings of the twelfth international joint conference on artificial intellingence , san francisco : morgan kaufmann , 1233 firth a. e. , lahav o. , somerville r. s. , 2003 , mnras , 339 , 1195 fontana a. , @xmath45odorico s. , poli f. , giallongo e. , arnouts s. , cristiani s. , moorwood a. , saracco p. , 2000 , aj , 120 , 2206 giallongo e. , menci n. , poli f. , @xmath45odorico s. , fontana a. , 2000 , apj , 530 , l73 gwyn s. , 1990 , master thesis , university of victoria , canada hsieh b. c. , yee h. k. c. , lin h. , gladders m. d. , 2005 , apjs , 158 , 161 koo d. c. , 1985 , aj , 90 , 418 li l. , zhang y. , zhao y. , yang d. , 2006 , preprint(astro - ph/0612749 ) liddle a. r. , 2004 , mnras , 351 , l49 liddle a. r. , 2007 , preprint(astro - ph/0701113 ) nadaraya e. a. , 1964 , theory of probability and its applications , 9 , 141 padmanabhan n. et al . , 2007 , preprint(astro - ph/0605302 ) poli f. , giallongo e. , menci n. , @xmath45odorico s. , fontana a. , 1999 , apj , 527 , 662 sawicki m. j. , lin h. , yee h. k. c. , 1997 , aj , 113 , 1 schlegel d. j. , finkbeiner d. p. , davix m. , 1998 , apj , 500 , 525 stoughton c. et al . , 2002 , aj , 123 , 485 strateva i. et al . , 2001 , aj , 122 , 1861 suchkov a. a. , hanisch r. j. , margon b. , 2005 , aj , 130,2439 vanzella e. et al . , 2004 , a&a , 423 , 761 wadadekar y. , 2005 , pasp , 117 , 79 wang y. , bahcall n. , turner e. l. , 1998 , aj , 116 , 2081 watson g. s. , 1964",
    ", the indian journal of statistics , series a , 26 , 359 way m. j. , srivastava a. n. , 2006 , apj , 647 , 102 york d. g. et al , 2000 , aj , 120 , 1579"
  ],
  "abstract_text": [
    "<S> we present a new approach , kernel regression , to determine photometric redshifts for 399,929 galaxies in the fifth data release of the sloan digital sky survey ( sdss ) . in our case , </S>",
    "<S> kernel regression is a weighted average of spectral redshifts of the neighbors for a query point , where higher weights are associated with points that are closer to the query point . </S>",
    "<S> one important design decision when using kernel regression is the choice of the bandwidth . we apply 10-fold cross - validation to choose the optimal bandwidth , which is obtained as the cross - validation error approaches the minimum . </S>",
    "<S> the experiments show that the optimal bandwidth is different for diverse input patterns , the least rms error of photometric redshift estimation arrives at 0.019 using color+eclass as the inputs , the less rms error amounts to 0.020 using @xmath0+eclass as the inputs . here </S>",
    "<S> eclass is a galaxy spectra type . </S>",
    "<S> then the little rms scatter is 0.021 with color@xmath1 as the inputs . as a result , except the parameters ( e.g. magnitudes and colors ) , eclass is a valid parameter to predict photometric redshifts . </S>",
    "<S> moreover the results also suggest that the accuracy of estimating photometric redshifts is improved when the sample is divided into early - type galaxies and late - type ones , especially for early - type ones , the rms scatter amounts to 0.016 with color+eclass as the inputs . </S>",
    "<S> in addition , kernel regression achieves high accuracy to predict the photometric eclass ( @xmath2 = 0.034 ) using color@xmath1 as the input pattern . for kernel regression , </S>",
    "<S> the more parameters considered , the accuracy of photometric redshifts is not always higher , but satisfactory only when appropriate parameters are chosen . </S>",
    "<S> kernel regression is comprehensible and accurate regression models of the data . </S>",
    "<S> experiments reveal the superiority of kernel regression when compared to other empirical training approaches .    </S>",
    "<S> = 10000    4cen  x@xmath34 e1e 1207.4 - 5209    c    739 xte j1739 - 285    galaxies : distances and redshifts  methods : statistical </S>"
  ]
}