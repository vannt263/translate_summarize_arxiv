{
  "article_text": [
    "characterizing a physical system at the most fundamental level requires specifying its quantum mechanical state .",
    "arriving at such a description from measured data is called quantum tomography and the output of such a process is often a single point in the space of allowed parameters . in theory , by considering an infinite amount of data , a unique state can be identified .",
    "in practice , however , only a finite amount of data can be obtained . in such cases , it is impossible for a single reported state to coincide with the true state . in classical data fitting , _ error bars _ give a measure of the _ accuracy _ of the estimate . in the quantum state tomography setting , _ regions _ generalize this concept @xcite .",
    "a region of quantum states should colloquially be understood to contain the true state with high probability ( with the exact interpretation depending subtly on how the region is constructed ) .",
    "although this idea is quite simple , formalizing the concept of region estimation is not straightforward and there exists many competing alternatives , each with its own set of advantages and drawbacks . for example , _ bootstrap resampling _ is a common technique to produce error bars in tomographic experiments .",
    "however , as in @xcite for example , bootstrapping has so far been exclusively used to calculate statistics on quantities derived from state estimates , such as fidelity to some target state .",
    "bootstrapping is conceptually simple and easy to implement .",
    "however , the errors bootstrapping estimate come with no guarantees and it can grossly underestimate errors for estimators which produce states near the boundary @xcite .",
    "the fisher information ( matrix ) is most often used , via the cramer - rao inequality , to lower bound the variance of unbiased estimators . in this sense",
    ", it gives the errors one would expect in the asymptotic limit , provided an efficient estimator is used . in terms of regions ,",
    "the fisher information matrix is also asymptotically the inverse of the covariance matrix of the posterior distribution of parameters , which in turn defines an error ellipse @xcite . for most problems , however , even computing",
    "the fisher information numerically is an intractable problem . in some estimation strategies , such as compressed sensing @xcite ( also @xcite ) ,",
    "the estimate of the state comes with a _",
    "certificate_. that is , an estimated state is provided along with an upper bound on the distance to the true state .",
    "this implicitly defines a ball in state space centered on the estimated state .",
    "however , the statistical meaning of this ball is not clear nor does a ball provide information about correlated errors .",
    "confidence regions @xcite ( and comparable constructions @xcite ) are the most stringently defined regions from a statistical perspective",
    ". these regions would be ideal if they admitted a method of construction which is computationally tractable .",
    "there is one overarching theme to notice here : trade - offs . on one end of the spectrum",
    "is conceptual simplicity , ease of implementation and computational tractability ; on the other is statistical rigor , precision , accuracy and optimality .",
    "here we take the approach of constructing statistically rigorous region estimators via a numerical algorithm which possess tunable parameters to control the trade - off between optimality and computational efficiency .",
    "the regions we construct here are approximations to _ high posterior density credible regions _ and are in some sense the bayesian analogs of confidence regions . to aid in the descriptive simplicity of the regions , we use _ ellipsoids _ which are well understood and easy to conceptualize geometrical objects",
    "moreover , ellipsoids provide a useful summary of how the state parameters are correlated .",
    "the numerical algorithm we use is a monte carlo approximation to bayesian inference and has been used to in the tomographic estimation of one and two qubit states @xcite as well as in the continuous measurement of a qubit @xcite .",
    "it has also been recently used to construct point _ and _ region estimates of hamiltonian parameters in @xcite .",
    "in particular , the region used was the ellipse defined by the posterior covariance matrix .",
    "here we show that the same method can be applied to quantum states and , more importantly , such regions approximate high posterior density credible regions .",
    "one of the major advantages to this approach is that it naturally accommodates the possibility of unknown errors in modeling .",
    "for example , we might assume that the source of quantum states is fixed when it is not ; or , we might assume that the measurements are known exactly when they are not .",
    "previous analysis of errors in quantum state estimation have focused on assessing its effect @xcite ; _ detecting _ its presence @xcite ; and , most recently , selecting the best model for it @xcite . here",
    "we demonstrate that the our approach can estimate and construct regions for both quantum mechanical state and error model parameters _ simultaneously_. that is , our algorithm produces a region in the space defined by all parameters .",
    "this work is outlined as follows . in section",
    "[ sec : bayes ] we overview the precise problem and theoretical solution . in section [ sec : smc ] we give the numerical algorithm which constructs the regions . in section [ sec : ex ]",
    "we describe the examples used to test the method and in section [ sec : results ] the results of the numerical experiments are presented .",
    "finally , in section [ sec : end ] we conclude discussion .",
    "each quantum mechanical problem specification produces a probability distribution @xmath0 , where @xmath1 is the data obtained and @xmath2 are the experimental designs ( or _ controls _ ) chosen for measurement @xmath3 , and where @xmath4 is a vector parameterizing the system of interest .",
    "suppose we have performed experiments with control settings @xmath5 and obtained data @xmath6 .",
    "the model specifies the likelihood function @xmath7 however , we are ultimately interested in @xmath8 , the probability distribution of the model parameters @xmath4 given the experimental data .",
    "we achieve this using use bayes rule : @xmath9 where @xmath10 is the _ prior _ , which encodes any _ a priori _ knowledge of the model parameters .",
    "the final term @xmath11 can simply be thought as a normalization factor . since",
    "each measurement is statistically independent given @xmath4 , the processing of the data can be done on or off - line .",
    "that is , we can sequentially update the probability distribution as the data arrive or post - process it afterward .    in many scenarios the mean of the posterior distribution : @xmath12=\\int f(x)\\pr(x ) dx$ ] . ]",
    "@xmath13\\ ] ] is the optimal _ point _",
    "estimator @xcite .",
    "but we desire more than point estimates . in this scenario ,",
    "the most powerful region estimators are _ high posterior density _",
    "( hpd ) regions .",
    "let @xmath14 be the indicator function of the set @xmath15 .",
    "that is , @xmath16 then , the probability that @xmath4 lies in some set @xmath15 is @xmath17.\\ ] ] the set @xmath15 is an @xmath18-credible region if @xmath19 that is , a set is @xmath18-credible region if no more than @xmath18 probability mass exists outside the region or , equivalently , at least @xmath20 probability mass is contained within the region .",
    "the set @xmath15 is an hpd @xmath18-credible region if @xmath21 where @xmath22 is the largest number such that @xmath15 is a @xmath18-credible interval . under natural notions of `` size '' , hpd @xmath18-credible are the _ smallest _ ( that is , most powerful ) @xmath18-credible regions .",
    "being optimal , hpd regions are the solutions to computationally intractable optimization problems  at least if we require a deterministic algorithm . in this work",
    ", we will explore a monte carlo algorithm to numerically approximate hpd regions .",
    "in particular , we use _ posterior covariance ellipsoids _ ( pces ) .",
    "these are defined via the mean and covariance matrix of the posterior probability distribution as follows is denoted @xmath23 = \\mathbb e_x[(x-\\mathbb e[x])(x-\\mathbb e[x])^{\\rm t}]$ ] . ] : @xmath24)^{\\rm t}{\\rm cov}_{\\vec{x}|d;c}[\\vec{x}]^{-1}(\\vec{x}-\\mathbb{e}_{\\vec{x}|d;c}[\\vec{x } ] ) \\leq z_\\alpha^2\\}\\ ] ] where @xmath25 is the @xmath18-quantile of the @xmath26 distribution @xcite , the values of which are readily available in countless tables .",
    "note that this is simply the covariance ellipse under a gaussian approximation to the posterior @xmath27,{\\rm cov}_{\\vec{x}|d;c}[\\vec{x}])$ ] .",
    "in addition to being hpd credible regions in the asymptotic limit , pces are computationally tractable and , even for modest numbers of experiments , they are remarkably close in size and coverage probability to true hpd regions .",
    "the remainder of this work is devoted to detailing the algorithm and demonstrating the above claims via simulated experiments on qubits .",
    "our numerical algorithm fits within the subclass of monte carlo methods called _ sequential monte carlo _ or smc . we approximate the posterior distribution by a weighted sum of delta - functions : @xmath28 where the weights at each step are iteratively calculated from the previous step via @xmath29 followed by a normalization step .",
    "the elements of the set @xmath30 are called _ particles _ and are initially chosen by sampling the prior distribution @xmath10 and setting each weight @xmath31 . in the equations above , @xmath32 is the number of particles and controls the accuracy of the approximation .",
    "note that the approximation in equation is not a particularly good one _ per se _",
    "( we are approximating a continuous function by a discrete one after all ) .",
    "however , it does allow us to calculate some quantities of interest with arbitrary accuracy .",
    "like all monte carlo algorithms , it was designed to approximate expectation values , such that @xmath33 \\approx \\sum_{j=1}^n w_j(d;c ) f(\\vec{x}_j).\\ ] ] in other words , it allows us to efficiently evaluate difficult multidimensional integrals with respect to the measure defined by the posterior distribution .",
    "the smc approximation provides a nearly trivial method to approximate hpd credible regions , which surprisingly has been overlooked .",
    "since the smc approximate distribution is a discrete distribution , the credible regions will be ( at least initially ) discrete sets .",
    "in particular , the hpd @xmath18-credible set , @xmath34 , is defined by the following construction :    1 .",
    "sort the particles according to their weights : @xmath35 ; 2 .   collect particles ( starting with the highest weighted ) until the sum of the collected particle weights is at least @xmath20 .",
    "the resulting set is @xmath34 .",
    "the proof that this an hpd @xmath18-credible set is as follows . assuming the particles are sorted as above .",
    "begin with the highest weighted particle @xmath36 with weight @xmath37 .",
    "then , the set @xmath38 clearly has weight @xmath37 and the largest @xmath3 satisfying equation , in the definition of hpd credible regions , is @xmath39 .",
    "now take the set @xmath40 with weight @xmath41 .",
    "the largest @xmath3 is now @xmath42 .",
    "iterate this process until we reach the first weight @xmath43 such that set @xmath44 satisfies @xmath45 .",
    "this set will have largest @xmath46 .",
    "the set @xmath47 is clearly an @xmath18-credible set but it is also an hpd @xmath18-credible set since any @xmath48 will result in a set excluding all particles @xmath49 with @xmath50 and necessarily have weight less than @xmath20 .",
    "the immediate problem with @xmath34 is that it is a discrete set of points and while it is hpd @xmath18-credible set for the smc approximated distribution , _ any _ discrete set has zero measure according the true posterior @xmath8 .",
    "the resolution is quite simple .",
    "suppose we have some region @xmath51 which contains @xmath34 .",
    "then , according to the smc approximation , @xmath52\\approx \\sum_j w_j\\mathbbm 1_{\\hat x}(\\vec{x}_j ) \\geq 1- \\alpha,\\ ] ] since @xmath53 for all @xmath54 in @xmath34 .",
    "thus , any region enclosing the points in @xmath34 will be a @xmath18-credible region .",
    "but we do not want just any @xmath18-credible region .",
    "the hpd requirement is conceptually similar to asking for the region to be as small as possible while maintaining @xmath20 weight .",
    "if we assume ( relaxed later on ) the credible regions are convex , then we seek the smallest convex set containing @xmath34 .",
    "this defines the _ convex hull _ of @xmath34 : @xmath55 since @xmath56 is a convex polytope in @xmath57 , it can be most compactly represented by a list of its vertices , which in the absolute worst cases is the entire set of smc particles .",
    "that is , we require @xmath58 numbers to specify @xmath56 .",
    "although certain classes of convex polytopes contain many symmetries and are easy to conceptualize geometrically , specifying the vertices of the convex hull of a random set of points is not most convenient representation for credible regions .    the most efficient way to describe",
    "this hull is the smallest ball containing it since this would be described by a location and single radial parameter .",
    "however , a ball would not account for large covariances in the posterior distribution . to account for these covariances",
    ", we will use ellipsoidal regions where @xmath59 and @xmath60 define an ellipsoid via the set of states satisfying @xmath61 .",
    "in other words , @xmath59 is the center of the ellipsoid and @xmath60 its covariance matrix .",
    "crucially , we want the smallest ellipse containing the hull , the so - called _ minimum volume enclosing ellipse _ ( mvee ) : @xmath62 to numerically construct the mvee , we use the algorithm of khachiyan @xcite .    to summarize , @xmath63 is the numerical approximation to the hpd credible region .",
    "the posterior covariance regions , @xmath64 , defined earlier in equation , are far less computationally intensive to construct than @xmath63 and are expected to be hpd credible regions in the asymptotic limit . in order to show that they are also approximately hpd credible regions for finite data , we compare @xmath63 and @xmath64 in a number of examples and also look at the performance in cases where limited computational resources prohibit constructing @xmath63 over many simulations .",
    "finally , we note that to compare the sizes of various ellipsoids , we will use the volume @xmath65 where @xmath66 is the dimension of the parameter space and @xmath67 is the well - known gamma function .",
    "consider repeated preparations of a qubit subjected to random pauli measurements .",
    "we label the pauli operators @xmath68 such that an arbitrary operator can be written @xmath69 and @xmath70 for many qubits , the situation is similar .",
    "the reconstruction is given by @xmath71 where @xmath72 and we index by @xmath73 .",
    "then the parameterization is equivalent to that in equation .",
    "since each pauli is idempotent , @xmath74 , each individual measurement has @xmath75 possible outcomes which we label @xmath76 for the @xmath77 and @xmath78 eigenvalues .",
    "the likelihood function of a single measurement is then @xmath79 we also consider the effect of errors .",
    "we will not assume a particular model for the errors since any error model , for our two outcome measurements , manifests as a bit flip , or equivalently , randomization channel .",
    "for simplicity we assume the process is symmetric so we have a single parameter @xmath80 , called the _ visibility _ , which has the following effect on the likelihood function : @xmath81 we consider two cases : the visibility in known and fixed or the visibility is unknown but still fixed run - to - run . in the former case ,",
    "the task is to compute the pce @xmath64 for the state only , while in the latter case the task is to compute the pce over the _ joint distribution _ of @xmath82 .",
    "if only a region of states is desired , we can orthogonally project the pce onto the subspace of the parameter space defining the state ( and similarly for @xmath80 ) .",
    "hence , we will have separate marginal pces for the state and visibility separately .",
    "examples of how the regions are constructed are presented in figures [ fig : eq_rebit ] and [ fig : eq_qubit ] .",
    "we first look at a comparison of @xmath63 and @xmath64 .",
    "these results are presented in figures [ fig : qubit_sizes_known_vis],[fig : qubit_size_known_vis ] and [ fig : qubit_pr_known_vis ] . in figures [ fig : qubit_sizes_known_vis ] and [ fig : qubit_size_known_vis ] , the size of the two classes of regions is compared .",
    "initially the volume of the pce is not smaller than that of the entire parameter space , which is to be expected since it is motivated from asymptotic normality .",
    "however , it rapidly converges in volume to , and becomes slightly smaller than , @xmath63 .",
    "both sets of regions decrease in size at the same rate as a function of the number of measurements .",
    "this suggests that the pces are approximate hpd credible regions .",
    "this is important because , as opposed to all other region estimators , pce regions are computationally tractable . that the pces remain valid in higher dimensions is shown in figure [ fig:23 ] . in figure",
    "[ fig:23 ] the probability for the state to lie in the constructed pce region is shown to be consistent with the target of 95% containment probability for two and three - qubits subjected to random pauli measurements .     the volume of the constructed ellipsoid for ( left ) perfect measurements and ( right ) limited visibility measurements .",
    "for all constructed regions , @xmath83 particles where used .",
    "the results are from 100 simulations , where the line represents the mean and the shaded areas are those volumes one standard deviation from the mean . ]",
    "the relative size @xmath84 of the 95% credible regions , where @xmath63 is a numerical approximation to the hpd 95% credible region . for both strategies , @xmath83 particles where used .",
    "the results are from 100 simulations , where the line represents the mean and the shaded area are ratios one standard deviation from the mean .",
    "note that the posterior covariance ellipsoid is on average 10% smaller than the hpd region after about 100 measurements . ]",
    "the probability of the state lying in the constructed ellipsoid for ( left ) perfect measurements and ( right ) limited visibility measurements . in all cases ,",
    "the target was a 95% credible region .",
    "for all constructed regions , @xmath83 particles where used .",
    "the results are from 100 simulations , where the line represents the mean and the shaded area is ( just to be meta ) the hpd 95% credible region of the probability ( derived from the beta distribution and a uniform prior ) . ]",
    "the probability of the state lying in the constructed posterior covariance ellipsoid ( approximating the 95% hpd region ) for the two and three qubit model described in the text and using a visibility parameter @xmath85 . for all constructed regions , @xmath83 particles where used .",
    "the results are from 25 simulations , where the line represents the mean and the shaded area is the hpd 95% credible region of the probability ( derived from the beta distribution and a uniform prior ) . ]    in the above mentioned cases , the visibility @xmath80 was assumed to be known . in figure",
    "[ fig : qubit_pr_unknown_vis ] , the case of unknown visibility is considered . when the visibility in known relatively accurately , the pce captures the state and visibility accurately . however , as the initial variance in the prior on the visibility increases , the ability of the pce to capture the both the state and visibility diminishes .",
    "surprisingly , the pce still finds the state even when it can not resolve the visibility accurately .",
    "the probability of the state lying in the constructed ( 95% credible ) posterior covariance ellipse for varying levels of knowledge of the visibility parameter . in the upper left ,",
    "the visibility is known ( this is identical to figure [ fig : qubit_pr_known_vis ] ) . in all other figures , the visibility in unknown ( but known to lie in the specified interval  with a uniform prior ) .",
    "for both the state and the visibility parameter , a marginal posterior covariance ellipse is constructed and the tested against the true state and parameter . ]",
    "the problem is easily identified to be the assumption that this posterior has a single mode with a convex hpd credible region . to illustrate the problem graphically , we need to reduce the dimensionality . to this end",
    ", we assume the state is of the form @xmath86 , with @xmath87 unknown and to be estimated along with the visibility @xmath80 .",
    "a typical example of a posterior distribution and the possible regions is shown in figure [ fig : nc ] .",
    "there are two things to note : ( 1 ) the posterior distribution has two modes ; ( 2 ) even within each mode , the distribution is not well approximated by a gaussian",
    ". both of these are due to the degeneracy in the posterior distribution of @xmath88 arising from the symmetry in of @xmath87 and @xmath80 in the likelihood function .",
    "for example , an outcome could equally well be explained by a large @xmath87 and small @xmath80 as a small @xmath80 and large @xmath87 .",
    "the problem of many modes in the posterior can be resolved by reporting disjoint ellipsoidal regions , one for each mode .",
    "the discrete set of highest weighted smc points @xmath89 naturally find themselves within the modes .",
    "given this set , the task is to then identify which particles belong to which modes . in machine learning parlance",
    ", this is the problem of _",
    "clustering_. many solutions to this problem exist , each with its own set of advantages and drawbacks . here",
    "we have used dbscan @xcite , as it seems to require the fewest number of assumptions .",
    "construction of regions for qubit ( known to be of the form @xmath86 ) with unknown visibility subjected to 1000 randomly selected @xmath90 measurements . on the left , we have the initial 1000 particles ( blue ) randomly select according to a uniform prior and the randomly generated `` true '' state ( red ) . in the middle figure , we have the posterior smc particle cloud after 1000 randomly selected @xmath90 measurements along with the following regions : the green line is the convex hull of those highest weighted particles comprising at least 95% of the particle weight ( this is @xmath56 ) ; the red ellipse is @xmath63 , the smallest ellipse containing @xmath56 ; and , in black is the ellipse defined by the estimated convariance matrix of the particle cloud , @xmath64 . when the posterior is disjoint , all regions poorly approximate the hpd credible region . on the right , the same distribution of particles",
    "is shown along with the convex hull and mvee regions after the modes of the distribution have been identified via the dbscan clustering algorithm . ]    when the visibility is known fairly well only the first problem , disjoint regions , is automatically resolved . in other words , it is not likely that the pce will be the optimal region estimator unless the visibility is relatively well - known .",
    "practically , when the noise is known with some  but not perfect  accuracy , the mvee region @xmath63 still behaves properly even when the pce region @xmath64 does not .",
    "this is demonstrated in figure [ fig : mveevis ] where we see that @xmath63 contains the true state with the correct probability but @xmath64 does not . in practice",
    "then , the recommendation is to identify whether the problem specifies convex credible regions .",
    "if so , then the pce is the appropriate choice ; if not , then a clustering algorithm should be used to identify the modes of the distribution first .",
    "the probability of the state lying in the ( 95% credible ) posterior covariance ellipse @xmath64 or the minimum volume enclosing ellipse @xmath63 for varying levels of knowledge of the visibility parameter .",
    "the visibility in unknown ( but known to lie in the specified interval  with a uniform prior ) .",
    "for both the state and the visibility parameter , a marginal posterior covariance ellipse is constructed and the tested against the true state and parameter . ]",
    "for the three qubit data shown in figure [ fig:23 ] , the constructed pces were ellipsoids in a @xmath91 dimensional parameters space . that these simulations were performed on an average laptop computer lends credence to the claim that the regions discussed here , constructed via the smc algorithm , are a computationally attractive solution to the problem of providing region estimators of quantum states .",
    "for the implementation given in @xcite , further optimization of the code itself would be required to move beyond 100-or - so parameters for conventional computing resources .",
    "alternative to this is the `` throw money at it '' solution and run the code on high performance computing machines .",
    "the key obstacle to a fully scalable solution is the _ curse of dimensionality _ , which is ever - present in quantum theory .",
    "the problem that the parameter space grows exponentially presents a challenge in representing the quantum state and simulating the dynamics of the quantum system . both of these obstacles can be overcome within the computational framework presented here . to address these problems",
    ", we follow the already many ingenious methods reducing the complexity of identifying and characterizing quantum states and processes . these include identifying stabilizer states @xcite ; tomography for matrix product states @xcite ; tomography for permutationally invariant states @xcite ; learning local hamiltonians @xcite ; tomography for low - rank states via compressed sensing @xcite ; and tomography for multi - scale entangled states @xcite .",
    "these techniques employ efficient simulation algorithms which propagate efficient representations of the state vector to calculate of the probabilities defining the likelihood function . physical constraints and careful engineering lead to such drastic dimensional reductions that we can use along with additional prior information in the bayesian method .",
    "the above mentioned methods aimed at reducing the complexity of estimating parameters has relied on the notion of _ strong _ simulation , where the likelihood function is computed exactly . on the other hand",
    "is _ weak _ simulation , where the likelihood is not computed but is instead sampled from .",
    "the distinction between strong and weak simulation has been a topic of recent interest in quantum computational complexity where it has been shown , for example , that there is exists subtheories of quantum mechanics which admit efficient weak simulation but do not allow for efficient strong simulation @xcite . it has recently been shown that the bayesian sequential monte carlo algorithm can also be used in the case where one only has access to a weak simulator @xcite .    finally , we might find ourselves with a quantum system which does not admit efficient strong nor weak simulation .",
    "in that case , it still may be possible to efficiently characterize the system using a trusted _ quantum _ simulator . for the case of estimating dynamical parameters",
    ", it has been shown that the bayesian smc approach can also perform estimation tasks efficiently using a quantum simulator @xcite .    in this work",
    "we have considered supplementing point estimates of quantum states with _",
    "regions _ of state space .",
    "these regions contain the true state with a pre - determined probability and within the tolerance of the numerical algorithm .",
    "the numerical algorithm has tunable parameters which trades accuracy for computational efficiency and thus can be determined based on desired optimality and available computational resources . when the noise is known with relatively high accuracy , the optimal regions are the _ posterior covariance ellipsoids_. when the noise is unknown , more complex techniques are available to construct ellipsoids which capture the state . in any case , the constructed regions are ellipsoids which are easily described and conceptualized .    in the context of classical statistics ,",
    "quantum state estimation can simply be thought of as overly ambitious parameter estimation .",
    "that is , quantum state estimation is just classical parameter estimation with a specific model and , perhaps , oddly appearing constraints .",
    "the point is that the framework presented here for region estimation is suitable to any parameter estimation problem . in particular , we have already shown that additional noise on the measurements can be estimated _ simultaneously _ with the unknown state .",
    "more generally , the framework possesses a beautiful modularity which allows arbitrary statistical models to be learned .",
    "the algorithm presented here has been implemented in a software package called _ qinfer _ @xcite using the python programming language and the scientific computation library _ scipy _ @xcite .",
    "the author thanks chris granade for many discussions , timely advice and the majority of contributions necessary to make this open - source software a reality , which has indeed proven useful in many of our collaborations .",
    "this work was supported by the national science foundation grant nos .",
    "phy-1212445 and  phy-1314763 , by office of naval research grant no .",
    "n00014 - 11 - 1 - 0082 , and by the canadian government through the nserc pdf program .",
    "construction of regions for a rebit subjected to 100 randomly selected @xmath15 and @xmath92 . on the left , we have the initial 100 particles ( blue ) randomly select according to the hilbert - schmidt prior and the randomly generated `` true '' state ( red ) .",
    "in the middle figure , we have the posterior smc particle cloud after 100 randomly selected @xmath15 and @xmath92 measurements and the estimated state , the mean of distribution , is shown in teal .",
    "the larger weighted particles are represented as larger dots . on the right ,",
    "the same distribution of particles is presented along with the regions discussed in the text .",
    "the green line is the convex hull of those highest weighted particles comprising at least 95% of the particle weight ( this is @xmath56 ) .",
    "the red ellipse is @xmath63 , the smallest ellipse containing @xmath56 .",
    "finally , in black , is the ellipse defined by the estimated convariance matrix of the particle cloud , @xmath64 .",
    "these objects are blown up below the figure to show details . ]",
    "construction of regions for qubit subjected to 20 randomly selected pauli measurements using the smc approximation with 100 particles .",
    "on the left , we have the initial 100 particles ( blue ) randomly select according to the hilbert - schmidt prior and the randomly generated `` true '' state ( red ) . in the middle and right figure",
    ", we have the posterior smc particle cloud after 20 randomly selected pauli measurements and the estimated state , the mean of distribution , is shown in teal .",
    "the larger weighted particles are represented as larger dots . in the middle figure ,",
    "the gray object is the convex hull of those highest weighted particles comprising at least 95% of the particle weight ( this is @xmath56 ) . in the right figure ,",
    "the blue ellipsoid is @xmath63 , the smallest ellipse containing @xmath56 while the red ellipsoid is the posterior covariance ellipsoid @xmath64 . ]"
  ],
  "abstract_text": [
    "<S> regions of quantum states generalize the classical notion of error bars . </S>",
    "<S> high posterior density ( hpd ) credible regions are the most powerful of region estimators </S>",
    "<S> . however , they are intractably hard to construct in general . </S>",
    "<S> this paper reports on a numerical approximation to hpd regions for the purpose of testing a much more computationally and conceptually convenient class of regions : posterior covariance ellipsoids ( pces ) . </S>",
    "<S> the pces are defined via the covariance matrix of the posterior probability distribution of states . </S>",
    "<S> here it is shown that pces are near optimal for the example of pauli measurements on multiple qubits . moreover , </S>",
    "<S> the algorithm is capable of producing accurate pce regions even when there is uncertainty in the model . </S>"
  ]
}