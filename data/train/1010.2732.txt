{
  "article_text": [
    "recent advances in computation , communication , sensing and actuation have stimulated an intensive research in networked multi - agent systems . in the systems and control",
    "community , this has been translated into how to solve global control problems , expressed by global objective functions , by means of local agent actions .",
    "more specifically , problems considered include multi - agent consensus or agreement  @xcite , coverage control  @xcite , formation control  @xcite and sensor fusion  @xcite .    in the optimization community , a problem of focus is to minimize a sum of local objective functions by a group of agents , where each function depends on a common global decision vector and is only known to a specific agent .",
    "this problem is motivated by others in distributed estimation  @xcite  @xcite , distributed source localization  @xcite , and network utility maximization  @xcite .",
    "more recently , consensus techniques have been proposed to address the issues of switching topologies in networks and non - separability in objective functions ; see for instance  @xcite ,  @xcite ,  @xcite ,  @xcite ,  @xcite .",
    "more specifically , the paper  @xcite presents the first analysis of an algorithm that combines average consensus schemes with subgradient methods . using projection in the algorithm of  @xcite",
    ", the authors in  @xcite further solve a more general setup that takes local state constraint sets into account .",
    "further , in  @xcite we develop two distributed primal - dual subgradient algorithms , which are based on saddle - point theorems , to analyze a more general situation that incorporates global inequality and equality constraints .",
    "the aforementioned algorithms are extensions of classic ( primal or primal - dual ) subgradient methods which generalize gradient - based methods to minimize non - smooth functions .",
    "this requires the optimization problems under consideration to be convex in order to determine a global optimum .",
    "the focus of the current paper is to relax the convexity assumption in  @xcite .",
    "the challenges induced by the presence of non - convexity will be circumvented by the integration of lagrangian dualization and subgradient schemes .",
    "these two techniques have been popular and efficient approaches to solve large - scale , structured convex optimization problems , e.g. ,  @xcite .",
    "however , subgradient methods do not automatically generate primal solutions for nonsmooth convex optimization problems , and numerous approaches have been designed to construct primal solutions ; e.g. , by removing the nonsmoothness  @xcite , by employing ascent approaches  @xcite , and the generation of ergodic sequences  @xcite .",
    "_ statement of contributions .",
    "_ here , we investigate a multi - agent optimization problem where agents are trying to minimize a sum of local objective functions subject to a global inequality constraint and a global state constraint set .",
    "the objective and constraint functions as well as the state - constraint set could be non - convex . a distributed approximate dual subgradient algorithm is introduced to find a pair of approximate primal - dual solutions . specifically , the update rule for dual estimates combines an approximate dual subgradient scheme with average consensus algorithms . to obtain primal solutions from dual estimates ,",
    "we propose a novel recovery scheme : primal estimates are not updated if the variations induced by dual estimates are smaller than some predetermined threshold ; otherwise , primal estimates are set to some solutions in dual optimal solution sets .",
    "this algorithm is shown to asymptotically converge to a pair of approximate primal - dual solutions over a class of switching network topologies under the assumptions of the slater s condition and the strong duality property .",
    "consider a networked multi - agent system where agents are labeled by @xmath0 .",
    "the multi - agent system operates in a synchronous way at time instants @xmath1 , and its topology will be represented by a directed weighted graph @xmath2 , for @xmath3 . here , @xmath4 \\in { \\mathbb{r}}^{n\\times n}$ ] is the adjacency matrix , where the scalar @xmath5 is the weight assigned to the edge @xmath6 , and @xmath7 is the set of edges with non - zero weights .",
    "the set of in - neighbors of agent @xmath8 at time @xmath9 is denoted by latexmath:[${\\mathcal{n}}_i(k ) = \\{j\\in v \\ ;    set of out - neighbors of agent @xmath8 at time @xmath9 as @xmath11 .",
    "we here make the following assumptions on network communication graphs :    [ non - degeneracy ] there exists a constant @xmath12 such that @xmath13 , and @xmath14 , for @xmath15 , satisfies @xmath16,\\;$ ] for all @xmath17 .",
    "[ asm20 ]    it holds that @xmath18 for all @xmath19 and @xmath17 , and @xmath20 for all @xmath21 and @xmath17.[asm30 ]    [ periodical strong connectivity ] there is a positive integer @xmath22 such that , for all @xmath23 , the directed graph @xmath24 is strongly connected .",
    "[ asm10 ]    the above network model is standard in the analysis of average consensus algorithms ; e.g. , see  @xcite , and distributed optimization in  @xcite .",
    "recently , an algorithm is given in  @xcite which allows agents to construct a balanced graph out of a non - balanced one under certain assumptions .",
    "the objective of the agents is to cooperatively solve the following primal problem ( @xmath25 ) : @xmath26 where @xmath27 is the global decision vector .",
    "the function @xmath28 is only known to agent  @xmath8 , continuous , and referred to as the objective function of agent  @xmath8 .",
    "the set @xmath29 , the state constraint set , is compact . the function @xmath30 are continuous , and the inequality @xmath31 is understood component - wise ; i.e. , @xmath32 , for all @xmath33 , and represents a global inequality constraint",
    ". we will denote @xmath34 and @xmath35 .",
    "we will assume that the set of feasible points is non - empty ; i.e. , @xmath36 .",
    "since @xmath37 is compact and @xmath38 is closed , then we can deduce that @xmath39 is compact .",
    "the continuity of @xmath40 follows from that of @xmath41 . in this way , the optimal value @xmath42 of the problem ( @xmath25 ) is finite and @xmath43 , the set of primal optimal points , is non - empty . throughout this paper , we suppose the following slater s condition holds :    there exists a vector @xmath44 such that @xmath45 .",
    "such @xmath46 is referred to as a slater vector of the problem ( @xmath25).[asm5 ]    all the agents can agree upon a common slater vector @xmath46 through a maximum - consensus scheme .",
    "this can be easily implemented as part of an initialization step , and thus the assumption that the slater vector is known to all agents does not limit the applicability of our algorithm .",
    "specifically , the maximum - consensus algorithm is described as follows :    initially , each agent  @xmath8 chooses a slater vector @xmath47 such that @xmath48 . at every time @xmath17 ,",
    "each agent  @xmath8 updates its estimates by using the following rule : @xmath49 where we use the following relation for vectors : for @xmath50 , @xmath51 if and only if there is some @xmath52 such that @xmath53 for all @xmath54 and @xmath55 .",
    "the periodical strong connectivity assumption  [ asm10 ] ensures that after at most @xmath56 steps , all the agents reach the consensus ; i.e. , @xmath57 for all @xmath58 . in the remainder of this paper , we assume that the slater vector @xmath46 is known to all the agents .",
    "[ rem2 ]    in  @xcite , in order to solve the convex case of the problem ( @xmath25 ) ( i.e. ; @xmath41 and @xmath59 are convex functions and @xmath37 is a convex set ) , we propose two distributed primal - dual subgradient algorithms where primal ( resp .",
    "dual ) estimates move along subgradients ( resp",
    ". supgradients ) and are projected onto convex sets .",
    "the absence of convexity impedes the use of the algorithms in  @xcite since , on the one hand , ( primal ) gradient - based algorithms are easily trapped in local minima .",
    "; on the other hand , projection maps may not be well - defined when ( primal ) state constraint sets are non - convex . in this paper",
    ", we will employ lagrangian dualization to circumvent the challenges caused by non - convexity .    towards this end , we construct a directed cyclic graph @xmath60 where @xmath61 .",
    "we assume that each agent has a unique in - neighbor ( and out - neighbor ) . the out - neighbor ( resp . in - neighbor ) of agent @xmath8",
    "is denoted by @xmath62 ( resp .",
    "@xmath63 ) . with the graph @xmath64",
    ", we will study the following approximate problem of problem ( @xmath25 ) : @xmath65 where @xmath66 , with @xmath67 a small positive scalar , and @xmath68 is the column vector of @xmath69 ones .",
    "the problem   reduces to the problem ( @xmath25 ) when @xmath70 , and will be referred to as problem ( @xmath71 ) .",
    "its optimal value and the set of optimal solutions will be denoted by @xmath72 and @xmath73 , respectively .",
    "similarly to the problem ( @xmath25 ) , @xmath72 is finite and @xmath74 .",
    "the cyclic graph @xmath64 can be replaced by any strongly connected graph .",
    "each agent @xmath8 is endowed with two inequality constraints : @xmath75 and @xmath76 , for each out - neighbor @xmath77 . for notational simplicity",
    ", we will use the cyclic graph @xmath64 , which has a minimum number of constraints , as the initial graph .",
    "[ rem1 ]      before introducing dual problems , let us denote by @xmath78 , @xmath79 , @xmath80 , @xmath81 and @xmath82 .",
    "the dual problem ( @xmath83 ) associated with @xmath84 is given by @xmath85 where @xmath86 , @xmath87 and @xmath88 . here",
    ", the dual function @xmath89 is given as @xmath90 where @xmath91 is the lagrangian function @xmath92 we denote the dual optimal value of the problem ( @xmath83 ) by @xmath93 and the set of dual optimal solutions by @xmath94 . in what follows we will assume that the duality gap is zero .    for the introduced problems @xmath84 and @xmath95 , it holds that @xmath96.[asm11 ]    we endow each agent @xmath8 with the local lagrangian function @xmath97 and the local dual function @xmath98 defined by @xmath99    in the problem ( @xmath71 ) , the introduction of approximate consensus constraints @xmath100 , @xmath19 , renders the @xmath41 and @xmath59 separable . as a result",
    ", the global dual function @xmath101 can be decomposed into a simple sum of the local dual functions @xmath102 .",
    "more precisely , the following holds : @xmath103 it is worth mentioning that @xmath104 is not separable since @xmath102 depends upon neighbor s multipliers @xmath105 and @xmath106 .",
    "the slater s condition ensures the boundedness of dual solution sets for convex optimization ; e.g. ,  @xcite .",
    "we will shortly see that the slater s condition plays the same role in non - convex optimization . to achieve this ,",
    "we define the function @xmath107 as follows : @xmath108    let @xmath46 be a slater vector for problem ( @xmath25 )",
    ". then @xmath109 with @xmath110 is a slater vector of the problem ( @xmath71 ) . similarly to ( 3 ) and ( 4 ) in  @xcite , which make use of lemma  3.2 in the same paper , we have that for any @xmath111 , it holds that @xmath112 where @xmath113 .",
    "let @xmath114 , @xmath115 and @xmath116 be zero in  , and it leads to the following upper bound on @xmath94 : @xmath117 where @xmath118 and it can be computed locally . since @xmath41 and @xmath59 are continuous and @xmath37 is compact , it is known that @xmath102 is continuous ; e.g. , see theorem 1.4.16 in  @xcite .",
    "similarly , @xmath101 is continuous .",
    "since @xmath94 is also bounded , then we have that @xmath119 .",
    "the requirement of exact agreement on @xmath120 in the problem @xmath25 is slightly relaxed in the problem @xmath71 by introducing a small positive scalar @xmath67 . in this way , on the one hand , the global dual function @xmath101 is a sum of the local dual functions @xmath102 , as in  ; on the other hand , @xmath94 is non - empty and uniformly bounded .",
    "these two properties play important roles in the devise of our sequent algorithm.[rem4 ]      denote by _ the approximate dual optimal solution set _ @xmath121 .",
    "similar to  , we have the following upper bound on @xmath122 : @xmath123 in the algorithm we will present in the following section , agents will compute @xmath124    define the set - valued map @xmath125 in the following way @xmath126 ; i.e. , given @xmath127 , the set @xmath128 is the collection of solutions to the following local optimization problem : @xmath129 here , @xmath130 is referred to as the _ marginal map _ of agent @xmath8 . since @xmath37 is compact and @xmath41 , @xmath59",
    "are continuous , then @xmath131 in   for any @xmath132 . in the algorithm we will develop in next section ,",
    "each agent is required to solve the local optimization problem   at each iterate .",
    "we assume that this problem   can be easily solved .",
    "this is the case for problems of @xmath133 , or @xmath41 and @xmath59 being smooth ( the extremum candidates are the critical points of the objective function and isolated corners of the boundaries of the constraint regions ) or having some specific structure which allows the use of global optimization methods such as branch and bound algorithms .",
    "for some @xmath134 , we define the set - valued map @xmath135 as follows : @xmath136 which is referred to as the _ approximate marginal map _ of agent @xmath19 .    in the space @xmath137",
    ", we define the distance between a point @xmath27 to a set @xmath138 as @xmath139 , and the hausdorff distance between two sets @xmath140 as @xmath141 .",
    "we denote by @xmath142 and @xmath143 where @xmath144 .",
    "in this section , we devise a distributed approximate dual subgradient algorithm which aims to find a pair of approximate primal - dual solutions to the problem ( @xmath71 ) .",
    "its convergence properties are also summarized .    for each agent @xmath8 ,",
    "let @xmath145 be the estimate of the primal solution @xmath146 to the problem ( @xmath147 ) at time @xmath3 , @xmath148 be the estimate of the multiplier on the inequality constraint @xmath149 , @xmath150 ( resp .",
    "@xmath151 ) to indicate that @xmath152 and @xmath153 are estimates of some global variables . ] be the estimate of the multiplier associated with the collection of the local inequality constraints @xmath154 ( resp .",
    "@xmath155 ) , for all @xmath21 .",
    "we let @xmath156 , for @xmath19 , and @xmath157 where @xmath158 and @xmath159 .",
    "the _ distributed approximate dual subgradient _ ( dads , for short ) algorithm is described as follows :    initially , each agent @xmath8 chooses a common slater vector @xmath46 , computes @xmath160 and obtains @xmath161 through a max - consensus algorithm .",
    "after that , each agent @xmath8 chooses initial states @xmath162 and @xmath163 .",
    "agent @xmath8 updates @xmath164 and @xmath165 as follows :    for each @xmath166 , given @xmath167 , solve the local optimization problem  , obtain a solution in @xmath168 and the dual optimal value @xmath169 . produce the primal estimate @xmath164 in the following way : if @xmath170 , then @xmath171 ; otherwise , choose @xmath172 .    for each @xmath17 ,",
    "generate the dual estimate @xmath173 according to the following rule : @xmath174,\\label{e48}\\end{aligned}\\ ] ] where the scalar @xmath175 is a step - size .",
    "the supgradient vector of agent @xmath8 is defined as @xmath176 , where @xmath177 , @xmath178 has components @xmath179 , @xmath180 , and @xmath181 for @xmath182 , while the components of @xmath183 are given by : @xmath184 , @xmath185 , and @xmath186 , for @xmath182 .",
    "the set @xmath187 in the projection map , @xmath188 , above is defined as @xmath189 for some @xmath190 .    in the initialization of the dads algorithm ,",
    "the quantity @xmath191 is an upper bound on @xmath122 .",
    "note that in step  1 , the check @xmath192 reduces to verifying that @xmath193 .",
    "then , only if @xmath194 , it is necessary to find _ one solution _ in @xmath168 .",
    "that is , it is unnecessary to compute all the set @xmath168 . in step 2 ,",
    "since @xmath187 is closed and convex , the projection map @xmath188 is well - defined .",
    "[ rem3 ]    the primal and dual estimates in the dads algorithm will be shown to asymptotically converge to a pair of approximate primal - dual solutions to the problem ( @xmath71 ) .",
    "we formally state this in the following .",
    "consider the problem ( @xmath25 ) and the corresponding approximate problem ( @xmath71 ) with some @xmath195 .",
    "we let the non - degeneracy assumption  [ asm20 ] , the balanced communication assumption  [ asm30 ] and the periodic strong connectivity assumption  [ asm10 ] hold .",
    "in addition , suppose the slater s condition  [ asm5 ] holds for the problem ( @xmath25 ) and the strong duality assumption  [ asm11 ] holds for the problem ( @xmath71 ) .",
    "consider the dual sequences of @xmath196 , @xmath197 , @xmath198 and the primal sequence of @xmath199 of the distributed approximate dual subgradient algorithm with the step - sizes @xmath200 satisfying @xmath201 , @xmath202 , and @xmath203 .",
    "then , there exists a feasible dual pair @xmath204 such that @xmath205 , @xmath206 , and @xmath207 , for all @xmath19 .",
    "moreover , there is a feasible primal vector @xmath208 such that @xmath209 , for all @xmath19 .",
    "in addition , @xmath210 is a pair of approximate primal - dual solutions in the sense that @xmath211.[the2 ]    the analysis of theorem  [ the2 ] will be provided in next section . before doing that",
    ", we would like to discuss several possible extensions of theorem  [ the2 ] .",
    "firstly , the step - size scheme in the dads algorithm can be slightly generalized to the following : @xmath212 , @xmath213 , @xmath214 , @xmath215 where @xmath216 is the step - size of agent  @xmath8 at time @xmath9 and @xmath217 $ ] .",
    "secondly , the periodic strong connectivity assumption  [ asm10 ] can be weakened into the eventual strong connectivity assumption , e.g. assumption 6.1 in  @xcite , if @xmath218 is undirected .",
    "thirdly , each agent can use a different @xmath219 in step 1 of the dads algorithm , which would lead to replacing @xmath220 in the approximate solution by @xmath221 .",
    "lastly , each agent @xmath8 could have different constraint functions @xmath222 and constraint sets @xmath223 if a slater vector is known to all the agents .",
    "for example , consider the case that @xmath59 is convex , @xmath223 is convex and potentially different , and there is a slater vector @xmath224 .",
    "then the solution @xmath225 to the following problem is such that @xmath226 : @xmath227    through implementing the distributed primal subgradient algorithm in  @xcite , agents can solve the problem   in a distributed fashion and agree upon the minimizer @xmath225 which coincides with a slater vector .",
    "in such a way , theorem  [ the2 ] still holds and the corresponding proof is a slight variation of those in next section .",
    "recall that @xmath59 is continuous and @xmath37 is compact . then there are @xmath228 such that @xmath229 and @xmath230 for all @xmath231 .",
    "we start our analysis of the dads algorithm from the computation of supgradients of @xmath102 .",
    "if @xmath232 , then @xmath233 is an approximate supgradient of @xmath102 at @xmath234 ; i.e. , the following holds for any @xmath132 : @xmath235 [ lem2 ]    the proof is analogous to the computation of dual subgradients , e.g. , in  @xcite , and omitted here due to the space limitation .    since @xmath236 , it is clear that @xmath237 for all @xmath17 .",
    "a direct result of lemma  [ lem2 ] is that the vector @xmath238 is an approximate supgradient of @xmath102 at @xmath167 ; i.e. , the following approximate supgradient inequality holds for any @xmath239 : @xmath240 now we can see that the update rule of dual estimates in the dads algorithm is a combination of an approximate dual subgradient scheme and average consensus algorithms .",
    "the following establishes that @xmath102 is lipschitz continuous with some lipschitz constant @xmath241 .",
    "there is a constant @xmath242 such that for any @xmath243 , it holds that @xmath244[lem6 ]    similarly to lemma  [ lem2 ] , one can show that if @xmath245 , then @xmath246 is a supgradient of @xmath102 at @xmath234 ; i.e. , the following holds for any @xmath132 : @xmath247 since @xmath248 and @xmath249 , there is @xmath242 such that @xmath250 .",
    "similarly , @xmath251 .",
    "the combination of these two relations renders the desired result .    in the dads algorithm ,",
    "the error induced by the projection map @xmath188 is given by : @xmath252 - v_i(k).{\\nonumber}\\end{aligned}\\ ] ] we next provide a basic iterate relation of dual estimates in the dads algorithm .",
    "[ basic iterate relation ] under the assumptions in theorem  [ the2 ] , for any @xmath253 with @xmath254 for all @xmath19 , the following estimate holds for all @xmath255 : @xmath256 [ lem4 ]    recall that @xmath187 is closed and convex .",
    "the proof is an application of lemma  [ lem5 ] in the appendix .",
    "the lemma below shows that dual estimates asymptotically converge to some approximate dual optimal solution .    under the assumptions in theorem  [ the2 ]",
    ", there exist a feasible dual pair @xmath257 such that @xmath258 , @xmath206 , and @xmath207 .",
    "furthermore , the vector @xmath259 is an approximate dual solution to the problem @xmath260 in the sense that @xmath261.[lem1 ]    by the dual decomposition property   and the boundedness of dual optimal solution sets , the dual problem @xmath260 is equivalent to the following : @xmath262 note that @xmath102 is affine and @xmath187 is convex , implying that the problem   is a constrained convex programming where the global objective function is a simple sum of local ones and the local state constraints are compact .",
    "since @xmath37 and @xmath187 are compact , there is some @xmath263 which is an upper bound of the norm of the last sum on the right - hand side of  . in this way",
    ", inequality   leads to : @xmath264 where @xmath265 .",
    "it is not difficult to see that the sequence of @xmath266 is uniformly bounded .",
    "since @xmath267 , then we take the limits on @xmath268 , and @xmath269 in  , and it renders that @xmath270 .",
    "therefore , we have @xmath271 exists .    by using this property and taking the limit on both sides of",
    ", we then have @xmath272 . by using proposition  [ pro1 ] in the appendix",
    ", we conclude that the consensus on @xmath273 and @xmath274 is asymptotically achieved ; i.e. , @xmath275 and @xmath276 for any @xmath277 . combining these with the convergence of @xmath278 and the closedness of @xmath187",
    ", we can deduce that there exist a feasible dual pair @xmath279 such that @xmath280 , @xmath281 , and @xmath282 , for all @xmath19 .",
    "furthermore , we have @xmath283 .",
    "substitute the approximate supgradient inequality   into  , rearrange terms , and we have @xmath284    let @xmath285 and @xmath286 . by lipschitz continuity of @xmath102",
    ", it follows from   that @xmath287    now we follow a contradiction argument , and state @xmath259 is not approximate dual optimal .",
    "that is , assume that @xmath288 .",
    "then @xmath289 . let @xmath127 in   be some dual optimal solution .",
    "since @xmath290 and @xmath291 , there is @xmath292 such that for all @xmath293 , there holds @xmath294 sum   over @xmath295 $ ] and rearrange it .",
    "it gives that @xmath296 since @xmath297 converges , it is uniformly bounded .",
    "recall that @xmath200 is not summable but square summable .",
    "when @xmath268 is sufficiently large , the above inequality leads to a contradiction .",
    "hence , it must be that @xmath298 .",
    "the remainder of this section is dedicated to characterizing the convergence properties of primal estimates . toward this end , we present the closedness and upper semicontinuity properties of @xmath299 .    the approximate set - valued marginal map @xmath299 is closed .",
    "in addition , it is upper semicontinuous at @xmath239 ; i.e. , for any @xmath300 , there is @xmath195 such that for any @xmath301 , it holds that @xmath302.[lem3 ]    consider sequences @xmath199 and @xmath297 satisfying @xmath303 , @xmath304 and @xmath305 . since @xmath306 is continuous , then we have @xmath307 where in the inequality we use the property of @xmath304 , and in the last equality we use the continuity of @xmath102",
    ". then @xmath308 and the closedness of @xmath299 follows .",
    "note that @xmath309 .",
    "recall that @xmath299 is closed and @xmath37 is compact .",
    "then it is a result of theorem  [ the6 ] in the appendix that @xmath310 is upper semicontinuous at @xmath239 ; i.e , for any neighborhood @xmath311 in @xmath312 of @xmath310 , there is @xmath195 such that @xmath313 , it holds that @xmath314 .",
    "let @xmath315 , and we obtain the property of upper semicontinuity at @xmath127 .",
    "upper semicontinuity of @xmath299 ensures that each accumulation point of @xmath199 is a point in the set @xmath316 ; i.e. , the convergence of @xmath199 to the set @xmath316 can be guaranteed . in what follows",
    ", we further characterize the convergence of @xmath199 to a point in @xmath316 within a finite time .    for each @xmath19",
    ", there are a finite time @xmath317 and @xmath318 such that @xmath319 for all @xmath320.[lem3 ]    choose @xmath321 and @xmath322 such that @xmath323 . since @xmath102 is continuous and @xmath324 , then there is @xmath325 such that for all @xmath326 , it holds that @xmath327    the time instant @xmath317 is defined as follows : if there is some finite time @xmath328 such that @xmath329 , then @xmath330 is the smallest one among such @xmath9 ; otherwise , @xmath331 . in what follows",
    "we prove that @xmath330 is the time in the statement of the lemma .",
    "consider the first case of @xmath330 . in this case , @xmath332 ; i.e. , @xmath333 .",
    "then @xmath334 ; i.e. , @xmath335 . by using this property",
    ", we have that for any @xmath336 , it holds that @xmath337    notice that the term @xmath338 can be upper bounded in the following way : @xmath339    substituting   and   into   gives that @xmath340    this implies that for any @xmath336 , it holds that @xmath341 hence , we conclude that @xmath342 for all @xmath336 , and thus @xmath343 for all @xmath344 .",
    "we now consider the second possibility for @xmath330 . in this case ,",
    "@xmath345 for all @xmath346 .",
    "therefore , we have @xmath342 and then @xmath347 for all @xmath336 .    in both cases , the chosen finite @xmath317 guarantees that for all @xmath336 , @xmath343 and @xmath348 .",
    "upper semicontinuity of @xmath299 ensures @xmath349 .",
    "now we are ready to show the main result of this paper , theorem  [ the2 ] .",
    "in particular , we will show the property of complementary slackness , primal feasibility of @xmath350 , and characterize its primal suboptimality .",
    "* proof for theorem  [ the2 ] : *    * claim 1 : * @xmath351 , @xmath352 and @xmath353 .    rearranging the terms",
    "related to @xmath273 in   leads to the following inequality holding for any @xmath253 with @xmath254 for all @xmath19 : @xmath354    sum   over @xmath355 $ ] , divide by @xmath356 , and we have @xmath357    we now proceed to show @xmath358 for each @xmath19 . notice that we have shown that @xmath359 for all @xmath19 , and it also holds that @xmath360 for all @xmath19 .",
    "let @xmath361 , @xmath362 for @xmath363 and @xmath364 , @xmath365 in  . recall that @xmath200 is not summable but square summable , and @xmath366 is uniformly bounded .",
    "take @xmath367 , and then it follows from lemma  [ lem8 ] in the appendix that : @xmath368    on the other hand , since @xmath369 , we have @xmath370 by  .",
    "then we could choose a sufficiently small @xmath371 and @xmath372 in   such that @xmath373 where @xmath374 is given in the definition of @xmath187 and @xmath375 is given by : @xmath376 , @xmath362 for @xmath363 , @xmath365 , @xmath377 .",
    "following the same lines toward  , it gives that @xmath378 .",
    "hence , it holds that @xmath379 . the rest of the proof is analogous and thus omitted .    * claim 2 : * @xmath350 is primal feasible to the problem ( @xmath71 ) .",
    "we have known that @xmath380 .",
    "we proceed to show @xmath381 by contradiction .",
    "since @xmath370 , we could choose a sufficiently small @xmath371 and @xmath375 with @xmath373 in   as follows : if @xmath382 , then @xmath383 ; otherwise , @xmath384 , and @xmath365 , @xmath377 .",
    "the rest of the proofs is analogous to claim 1 .",
    "similarly , one can show @xmath385 and @xmath386 by applying analogous arguments .",
    "* claim 3 : * it holds that @xmath387 .",
    "since @xmath350 is primal feasible , then @xmath388 .",
    "on the other hand , @xmath389 .",
    "in this section , we examine a numerical example to illustrate the performance of our algorithm . consider a network of four agents and let the objective functions of agents @xmath390 be equal and defined as follows : @xmath391 , \\\\",
    "z-1 , & z\\in[1,2 ] , \\\\                           1 , & z\\in[2,+\\infty ) .                         \\end{array}\\right.{\\nonumber}\\\\                         & f_2(z ) = \\left\\{\\begin{array}{ll }                           1 , & z\\in[0,2 ] , \\\\",
    "z-1 , & z\\in[2,3 ] , \\\\                           2 , & z\\in[3,+\\infty ) .",
    "\\end{array}\\right.{\\nonumber}\\\\ & f_3(x ) = ( z+0.25)^2,\\quad f_4(x ) = ( z-0.5)^2.{\\nonumber}\\end{aligned}\\ ] ]    it is easy to verify that @xmath392 and @xmath393 are not convex and @xmath394 and @xmath395 are convex .",
    "the primal problem of interest is given by : @xmath396.\\label{e35}\\end{aligned}\\ ] ] the objective function of problem   is piecewise convex , and it is not difficult to check that it has a unique solution @xmath397 and the optimal value is @xmath398 .",
    "the associated approximate problem to   is then : @xmath399,\\quad \\forall i\\in v,{\\nonumber}\\\\    & x_1 - x_2 \\leq \\delta , \\quad x_2 - x_1 \\leq \\delta,{\\nonumber}\\\\    & x_2 - x_3 \\leq \\delta , \\quad x_3 - x_2 \\leq \\delta,{\\nonumber}\\\\    & x_3 - x_4 \\leq \\delta , \\quad x_4 - x_3 \\leq \\delta,{\\nonumber}\\\\    & x_4 - x_1 \\leq \\delta , \\quad x_1 - x_4 \\leq \\delta,\\label{e36}\\end{aligned}\\ ] ] where the scalar @xmath400 .",
    "it can be seen that for any value @xmath44 , @xmath401^t$ ] is a slater vector of problem   and all the agents can agree upon the value @xmath46 through the max - consensus algorithm within a finite number of iterations . here , we choose @xmath402 .",
    "we further choose the tolerance level @xmath403 , and then compute @xmath404 and @xmath405 , @xmath406 .",
    "therefore , we have @xmath407 and then choose @xmath408 for the set @xmath187 .",
    "we now proceed to check the strong duality of problem  .",
    "to do this , we first define the lagrangian function @xmath409 as follows : @xmath410 where @xmath411 .",
    "the dual function is given by @xmath412 .",
    "notice that @xmath413 .",
    "the primal and dual optimal values of problem   are denoted by @xmath414 and @xmath415 , respectively .",
    "note that @xmath416 with @xmath417^t$ ] being one of primal solutions and thus @xmath418 .",
    "this establishes that @xmath419 . on the other hand",
    ", it follows from weak duality that @xmath420 .",
    "we now conclude that @xmath421 and thus the duality gap of problem   is zero .",
    "figure  [ fig1 ] and  [ fig2 ] show that the evolution of states @xmath164 and the global objective function of problem  .",
    "after @xmath422 iterations , states @xmath164 converge to @xmath423 , @xmath424 , @xmath424 and @xmath425 , respectively which consist of a feasible solution .",
    "figure  [ fig2 ] indicates that @xmath426 converges to the value @xmath427 which is in the interval of @xmath428 = [ 0.6625,\\;\\;1.4625]$ ] and is a good approximation of @xmath42 and @xmath429 .",
    "we have studied a multi - agent optimization problem where the goal of agents is to minimize a sum of local objective functions in the presence of a global inequality constraint and a global state constraint set .",
    "objective and constraint functions as well as constraint sets are not necessarily convex .",
    "we have presented the distributed approximate dual subgradient algorithm which allow agents to asymptotically converge to a pair of approximate primal - dual solutions provided that the slater s condition and strong duality property are satisfied .",
    "@xcite let @xmath430 be a non - empty , closed and convex set in @xmath431 .",
    "for any @xmath432 , the following holds for any @xmath433 : @xmath434 - y \\|^2 \\leq \\| z - y \\|^2 - \\| p_z[z ] - z    \\|^2 $ ] .",
    "[ lem5 ]          we let @xmath442 and @xmath443 denote hausdorff topological spaces .",
    "a set - valued map @xmath444 is a map that associates with any @xmath445 a subset @xmath446 of @xmath447 .",
    "the following definitions and theorem are adopted from  @xcite .",
    "let @xmath448 and @xmath458 be two set - valued maps from @xmath459 to @xmath447 .",
    "assume that @xmath448 is closed , @xmath460 is compact and @xmath458 is upper semicontinuous at @xmath445 .",
    "then @xmath461 is upper semicontinuous at @xmath462.[the6 ]        @xcite let the periodic strong connectivity assumption  [ asm10 ] , the non - degeneracy assumption  [ asm20 ] and the balanced communication assumption  [ asm30 ] hold .",
    "assume that @xmath467 for all @xmath468 and all @xmath17 .",
    "then the implementation of algorithm   achieves consensus , i.e. , @xmath469 for all @xmath470.[pro1 ]                              b.  johansson , t.  keviczky , m.  johansson , and k.  h. johansson .",
    "subgradient methods and consensus algorithms for solving convex optimization problems . in _ ieee conf . on decision and control _ , pages 41854190 , cancun , mexico , december 2008 .",
    "l.  xiao , s.  boyd , and s.  lall . a scheme for robust distributed sensor fusion based on average consensus . in _ symposium on information processing of sensor networks _ , pages 6370 , los angeles , ca , april 2005 ."
  ],
  "abstract_text": [
    "<S> we consider a multi - agent optimization problem where agents aim to cooperatively minimize a sum of local objective functions subject to a global inequality constraint and a global state constraint set . </S>",
    "<S> in contrast to existing papers , we do not require that the objective , constraint functions , and state constraint sets are convex . </S>",
    "<S> we propose a distributed approximate dual subgradient algorithm to enable agents to asymptotically converge to a pair of approximate primal - dual solutions over dynamically changing network topologies . </S>",
    "<S> convergence can be guaranteed provided that the slater s condition and strong duality property are satisfied . </S>"
  ]
}