{
  "article_text": [
    "the british government recently announced plans to sequence the genomes of up to one hundred thousand citizens  @xcite .",
    "although sequencing so many people is still a challenge , the cost has dropped sharply in the past few years and the decline is expected to continue .",
    "now scientists must consider how to store such a massive genomic database in a useful form .",
    "since human genomes are very similar , this database will be highly repetitive and easy to compress well with , e.g. , lz77",
    "unfortunately , conventional indexes ( e.g. ,  @xcite ) for approximate pattern matching  a basic operation in bioinformatics  are based on fm - indexes  @xcite or other technologies that do not take good advantage of repetitive structure .",
    "therefore , these indexes quickly outgrow internal memory when applied to many genomes and must then reside on disk , which slows them down by orders of magnitude .",
    "there are already some experimental lz- and grammar - based compressed indexes for exact pattern matching ( e.g. ,  @xcite ) and these could eventually provide a basis for approximate pattern matching as well ( see  @xcite ) , but science can not wait . in this paper we introduce a simple technique , hybrid indexing , for reducing the size of conventional indexes on highly repetitive texts while preserving most or all of their functionality .    given upper bounds on pattern lengths and edit distances , we preprocess the text with lz77 to obtain a filtered text , for which we store a conventional index .",
    "later , given a query , we find all matches in the filtered text , then use their positions and the structure of the lz77 parse to find all matches in the original text .",
    "we describe our hybrid index in more detail in section  [ sec : main ] ; this includes details of our implementation . in section  [ sec : experiments ] we present experimental results , which show our technique also significantly reduces query times .",
    "suppose we are given upper bounds on pattern lengths and edit distances , and asked to index a text @xmath0 $ ] .",
    "a query to the index consists of a pattern and an edit distance ( which is 0 in the case of exact matching ) . we store different data structures to be able to find queries primary matches and secondary matches .",
    "a match for a query is a substring within the given edit distance of the given pattern ; it is primary if it contains the first occurrence of a distinct character in @xmath1 or crosses a phrase boundary in the lz77 parse of @xmath1 , and secondary otherwise .    to be able to find primary matches , we preprocess the text with lz77 to obtain a filtered text , which is essentially the subsequence of @xmath1 containing characters close enough to phrase boundaries in @xmath1 s lz77 parse , where `` close enough '' depends on the given upper bounds . we store a conventional index on this filtered text , and a mapping from it to @xmath1 . to be able to find secondary matches , we store a data structure by krkkinen and ukkonen  @xcite .",
    "later , given a query , we use the conventional index to find all matches in the filtered text ; use the mapping to determine which of those matches correspond to primary matches in @xmath1 ; use the mapping again to find those primary matches positions in @xmath1 ; and apply krkkinen and ukkonen s data structure .",
    "we briefly describe lz77 in subsection  [ subsec : lz77 ] . in subsection",
    "[ subsec : primaries ] we give more details about the filtered text and how we find primary matches .",
    "we describe krkkinen and ukkonen s data structure in subsection  [ subsec : secondaries ] .",
    "finally , in subsection  [ subsec : implementation ] we describe details of our implementation .",
    "we use the variant of lz77 according to which , for each phrase @xmath2 $ ] in the parse of @xmath1 , either @xmath3 and @xmath4 $ ] is the first occurrence of that distinct character , or @xmath2 $ ] occurs in @xmath5 $ ] but @xmath6 $ ] does not occur in @xmath7 $ ] . in the first case ,",
    "@xmath4 $ ] is encoded as itself . in the second case , @xmath2 $ ]",
    "is encoded as the pair @xmath8 , where @xmath9 is the starting point of the leftmost occurrence of @xmath2 $ ] in @xmath1 ; we call this leftmost occurrence @xmath2 $ ] s source .    for example",
    ", if @xmath1 is @xmath10 then the parse of @xmath1 ( with parentheses around phrases ) is @xmath11 and @xmath1 s encoding is    9 @xmath12 -bot @xmath13 les @xmath14 @xmath15 f @xmath16 @xmath17 @xmath17 r @xmath18 n @xmath14 @xmath13 h @xmath17 @xmath14 wa @xmath19 @xmath19 @xmath14 @xmath20 @xmath13 @xmath21 k @xmath22 @xmath23 @xmath22 d @xmath15 @xmath24 @xmath25 @xmath21 @xmath26 @xmath27 @xmath14 p @xmath21 @xmath28 @xmath29 i @xmath13 @xmath30 @xmath31 @xmath15 u @xmath32 @xmath12 8 @xmath33 @xmath34 @xmath35 7 @xmath33 @xmath36 @xmath35 6 @xmath33  .    notice some phrases  e.g. , 8-bottles - of - beer - on - the - wall-98-bottles - of - beer-  overlap their own sources . also ,",
    "while the first verse takes the first four lines of the encoding , the next three verses together take only the last line .",
    "this is typical of lz77 s performance on repetitive inputs . finally , although these verses are annoyingly similar , they are much less similar than human genomes .",
    "let @xmath37 and @xmath38 be the given upper bounds on pattern lengths and edit distances .",
    "let @xmath39 be the text containing the characters of @xmath1 within distance @xmath40 of their nearest phrase boundaries ; characters not adjacent in @xmath1 are separated in @xmath41 by @xmath42 copies of a special character @xmath43 not in the normal alphabet .",
    "for example , if @xmath1 is the example given above then @xmath44 is @xmath45 or , with parentheses indicating the phrases of @xmath1 , @xmath46    notice that , for any substring of @xmath1 with length at most @xmath47 that contains the first occurrence of a distinct character in @xmath1 or crosses a phrase boundary in the lz77 parse of @xmath1 , there is a corresponding and equal substring in @xmath39 .    we do not store @xmath39 itself explicitly , but we store a conventional index @xmath48 on @xmath39 .",
    "we assume @xmath48 can handle queries with pattern lengths up to @xmath37 and edit distances up to @xmath38 .",
    "since @xmath39 consists of at most @xmath49 characters for each phrase , if @xmath1 is highly repetitive and @xmath37 and @xmath38 are reasonable , then @xmath48 should be smaller than a conventional index on all of @xmath1 .",
    "also , for any valid query and any match in @xmath39 , there is at least one match ( primary or secondary ) in @xmath1 , so querying @xmath48 should be faster than querying a conventional index for all of @xmath1 .",
    "let @xmath50 be the sorted list containing the positions of the first character of each phrase in the parse of @xmath1 , and let @xmath51 be sorted lists containing the positions of the corresponding characters in @xmath39 .",
    "we store @xmath50 and @xmath51 .",
    "if @xmath4 $ ] is the first occurrence of a distinct character in @xmath1 and @xmath52 $ ] is the corresponding character in @xmath39 , then we mark @xmath53 in @xmath51 .    for our example",
    ", @xmath50 is @xmath54 \\end{array}\\ ] ] and @xmath55 ( with asterisks indicating marked numbers ) is @xmath56\\ , .",
    "\\end{array}\\ ] ]    given the endpoints @xmath57 and @xmath53 of a substring @xmath58 $ ] of @xmath39 that does not include any occurrences of # , we can use @xmath51 to determine whether the corresponding substring @xmath59 $ ] of @xmath1 contains the first occurrence of a distinct character in @xmath1 or crosses a phrase boundary in the lz77 parse of @xmath1 . to do this ,",
    "we use binary search to find @xmath57 s successor @xmath60 $ ] .",
    "there are three cases to consider :    * if @xmath61 \\leq j$ ] then @xmath59 $ ] crosses a phrase boundary ; * if @xmath62 $ ] then @xmath59 $ ] neither contains the first occurrence of a distinct character nor crosses a phrase boundary ; * if @xmath63 \\leq j$ ] then @xmath59 $ ] contains the first occurrence of a distinct character or crosses a phrase boundary if and only if @xmath60 $ ] is marked or @xmath64 \\leq j$ ] .    also , if @xmath59 $ ] contains the first occurrence of a distinct character or crosses a phrase boundary , then @xmath65 - l_{m , k } + i$ ] and @xmath66 . in other words , we can use @xmath50 and @xmath51 as a mapping from @xmath39 to @xmath1 .    given a query consisting of a pattern @xmath67 $ ] with @xmath68 and an edit distance @xmath69 , we use @xmath48 , @xmath50 and @xmath51 to find all primary matches in @xmath1 .",
    "first , we query @xmath48 to find all matches in @xmath39 .",
    "we then discard any matches containing copies of # .",
    "we use binary search on @xmath51 , as described above , to determine which of the remaining matches correspond to primary matches in @xmath1 . finally , we use @xmath50 and @xmath51 , as described above , to find those primary matches positions in @xmath1 .",
    "krkkinen and ukkonen observed that , by definition , any secondary match is completely contained in some phrase .",
    "also , a phrase contains a secondary match if and only if that phrase s source contains an earlier match ( primary or secondary ) .",
    "it follows that each secondary match is an exact copy of some primary match and , more importantly , once we have found all the primary matches then we can find all the secondary matches from the structure of the lz77 parse .    to do this , for each primary match @xmath70 $ ] , we find each phrase @xmath2 $ ] whose source @xmath71 $ ] includes @xmath70 $ ]  i.e. , such that @xmath72 .",
    "notice @xmath73 = t [ \\ell .. r]$ ] , where @xmath74 and @xmath75 .",
    "we record @xmath73 $ ] as a secondary recurrence and recurse on it .    to be able to find quickly all the sources that cover a match , we store a data structure for 2-sided range reporting on the @xmath76 grid containing a marker at @xmath77 for every phrase s source @xmath59 $ ] . with each marker we store as a satellite datum the starting point of the actual phrase .",
    "in other words , if a phrase @xmath2 $ ] is encoded as @xmath8 by lz77 , then there is a marker on the grid at @xmath78 with satellite datum @xmath57 .",
    "for example , for the phrases shown in subsection  [ subsec : lz77 ] there are markers at    ( 1 , 1 ) ( 6 , 6 ) ( 3 , 3 ) ( 5 , 5 ) ( 3 , 4 ) ( 9 , 9 ) ( 9 , 9 ) ( 11 , 12 ) ( 3 , 3 ) ( 6 , 6 ) ( 9 , 9 ) ( 3 , 3 ) ( 8 , 8) ( 8 , 8) ( 3 , 3 ) ( 1 , 19 ) ( 6 , 6 ) ( 28 , 28 ) ( 25 , 26 ) ( 20 , 21 ) ( 25 , 26 ) ( 5 , 5 ) ( 27 , 27 ) ( 21 , 22 ) ( 28 , 28 ) ( 21 , 21 ) ( 60 , 60 ) ( 3 , 3 ) ( 28 , 28 ) ( 10 , 10 ) ( 10 , 11 ) ( 6 , 6 ) ( 64 , 65 ) ( 18 , 18 ) ( 5 , 5 ) ( 66 , 68 ) ( 1 , 1 ) ( 3 , 32 ) ( 85 , 133 ) ( 51 , 84 ) ( 3 , 32 ) ( 199 , 247 ) ( 51 , 84 ) ( 3 , 32 )     with satellite data",
    "@xmath79    notice the markers are simply the encodings of the phrases not consisting of the first occurrences of distinct characters in @xmath1 ( see subsection  [ subsec : lz77 ] ) with each second component @xmath80 replaced by @xmath81 , where @xmath9 is the first component .",
    "also , the satellite data are the positions of the first characters in those phrases , which are a subset of @xmath50 .      recall that , to be able to find primary matches , we store the conventional index @xmath48 on @xmath39 , the list @xmath50 , and the list @xmath51 .",
    "because we want our hybrid index to be flexible , we do not consider how @xmath48 works .",
    "( however , we note that it may sometimes be better to use fewer than @xmath42 copies of # as separators , as they serve only to limit the worst - case number of matches in @xmath39 . )",
    "we store @xmath50 and @xmath51 using gap coding  i.e. , storing the differences between consecutive values  with every @xmath82th value stored un - encoded , where @xmath82 is a parameter .",
    "we write the differences as @xmath83-bit integers , where @xmath84 is the largest difference in the list , and we write the un - encoded values as @xmath85-bit integers . to speed up binary search in @xmath51",
    ", we also sample every @xmath86th value in it , where @xmath86 is another parameter ( typically a multiple of @xmath82 ) .    instead of marking values in @xmath51 , we store an array containing the position in @xmath51 of the first occurrence of each distinct character , in order of appearance .",
    "we note , however , that this array is only necessary if there may be matches of length 1 .    to be able to find secondary matches , we store a data structure for 2-sided range reporting on the grid described in subsection  [ subsec : secondaries ] . to build this data structure , we sort the points by their x - coordinates . we store the sorted list @xmath87 of x - coordinates using gap encoding with every @xmath82th value stored un - encoded as before , and every @xmath86th value sampled to speed up binary search .",
    "we store a position - only range - maximum data structure over the list @xmath88 of y - coordinates , sorted by x - coordinate . finally , we store each satellite datum as a @xmath89-bit pointer to the cell of @xmath50 holding that datum , where @xmath90 is the number of phrases .",
    "we need not store points y - coordinates explicitly because , if a point has x - coordinate @xmath9 and satellite datum @xmath57 , then that point s y - coordinate is @xmath81 , where @xmath91 is the value that follows @xmath57 in @xmath50 .",
    "( we append @xmath92 to @xmath50 to ensure we can always compute @xmath53 this way , although this is not necessary when the last character of @xmath1 is a special end - of - file symbol . )",
    "since we can access @xmath9 , @xmath57 and @xmath53 , we can access @xmath88 .",
    "once we have found all primary matches , we apply recursive 2-sided range reporting . to do this",
    ", we put the endpoints of the primary matches in a linked list and set a pointer to the head of the list . until we reach the end of the list , for each match @xmath70 $ ] in the list , we repeat the following procedure :    1 .",
    "we use binary search to find @xmath93 s predecessor @xmath94 $ ] in @xmath87 ; 2 .",
    "we use recursive range - maximum queries to find the values in @xmath95 $ ] at least @xmath96 ; 3 .   for each point",
    "@xmath77 we find with @xmath97 , we compute @xmath98 and @xmath99 as described in subsection  [ subsec : secondaries ] ; 4 .",
    "we append the pair @xmath100 of endpoints to the list and move the pointer forward one element in the list .",
    "when we finish , the list contains the endpoints of all primary matches followed by the endpoints of all secondary matches .",
    "in our experiments , we compared a hybrid index based on an fm - index for the filtered text , to an fm - index for the original text .",
    "we always used the same implementation of an fm - index with default parameters .",
    "we used an fm - index instead of a popular index for compressed pattern matching because the latter are usually heavily optimized to take advantage of , e.g. , multiple processors ; we plan to compare against them after we have parallelized the hybrid index .",
    "we performed our experiments on an intel xeon with with 96 gb ram and 8 processors at 2.4 ghz with 12 mb cache , running linux 2.6.32 - 46-server .",
    "we compiled both indexes with g++ using full optimization .",
    "we used benchmark datasets from the repetitive corpus of the pizza&chili website .",
    "specifically , we used the following files :    cere  37 _ saccharomyces cerevisiae _ genomes from the saccharomyces genome resequencing project ; +    einstein  versions of the english wikipedia page on albert einstein up to november 10th , 2006 ; +    fib41  the 41st fibonacci word @xmath101 , where @xmath102 , @xmath103 , @xmath104 ; +    kernel  36 versions of the linux 1.0.x and 1.1.x kernel .",
    "we generally set @xmath105 , as that seemed a reasonable value for many applications .",
    "since standard fm - indexes do not support approximate pattern matching , we set @xmath106 throughout .",
    "based on preliminary tests , we set the sampling parameters @xmath82 and @xmath86 for our hybrid index to 32 and 512 , respectively .",
    "notice these parameters have no effect on the fm - indexes .",
    "table  [ tab : sizes ] shows the sizes of the uncompressed files , the files compressed with 7zip ( which does not support pattern matching ) , the fm - indexes , and the hybrid indexes .",
    "it also shows the construction times for the fm - indexes and hybrid indexes . the times to build the hybrid indexes include the times to compute the files lz77 parses ( which , in turn , include the times to build the files suffix arrays ) .",
    ".sizes of the uncompressed files , the files compressed with 7zip , the fm - indexes , and the hybrid indexes ; also construction times for the fm - indexes and hybrid indexes . [ cols=\">,^,^,^,^ \" , ]     to estimate how well hybrid indexing takes advantage of repetitive structure , relative to fm - indexing , we truncated cere at 100 , 200 , 300 and 400 mb , then built fm - indexes and hybrid indexes for those prefixes .",
    "figure  [ fig : growth ] shows the sizes of those indexes .        for 10 , 20 , 40 and 80",
    ", we randomly chose 3000 non - unary substrings that length from cere and searched for them with its fm - index and hybrid . figure  [ fig : queries ] shows the average query times , using a logarithmic scale .",
    "the large difference between the query times for patterns of length 10 and those of length 20 seems to be because there are usually far more matches for patterns of length 10 ; the average time per match stayed roughly the same for all four lengths .        on reflection , it is not surprising that the hybrid index performs well here : while the fm - index finds all matches with its locate functionality , the hybrid index finds secondary matches with 2-sided range reporting , which is relatively fast ; since cere consists of 37 genomes from individuals of the same species , most matches are secondary .",
    "we have introduced a simple technique , hybrid indexing , for reducing the size of conventional indexes on highly repetitive texts . in our experiments , this technique worked well on benchmark datasets and seemed to scale well .",
    "it also significantly reduced query times .",
    "we plan to optimize our implementation to use , e.g. , parallelism across multiple processors ; use a more powerful conventional index on the filtered texts ; and then compare our hybrid index to popular conventional indexes for approximate pattern matching .",
    "we are also working to optimize hybrid indexing in other ways .",
    "for example , readers may have noticed that , in our example @xmath44 , there are many copies of # # eer - take##. including all these copies seems wasteful , since they could be replaced by , e.g. , dummy phrases .",
    "we are currently testing whether this noticeably further reduces the size of hybrid indexes in practice .",
    "many thanks to pawe  gawrychowski , juha krkkinen , veli mkinen , gonzalo navarro , jouni sirn and jorma tarhio , for helpful discussions .",
    "h.  h. do , j.  jansson , k.  sadakane , and w .- k . sung .",
    "2012 . fast relative lempel - ziv self - index for similar sequences .",
    "_ proceedings of the 2nd conference on frontiers in algorithmics and algorithmic aspects in information and management _ , pages 291302 .",
    "t.  gagie , p.  gawrychowski , j.  krkkinen , y.  nekrich , and s.  j. puglisi .",
    "2012 . a faster grammar - based self - index .",
    "_ proceedings of the 6th conference on language and automata theory and applications _ , pages 240251 ."
  ],
  "abstract_text": [
    "<S> advances in dna sequencing mean databases of thousands of human genomes will soon be commonplace . in this paper we introduce a simple technique for reducing the size of conventional indexes on such highly repetitive texts . given upper bounds on pattern lengths and edit distances , we preprocess the text with lz77 to obtain a filtered text , for which we store a conventional index . </S>",
    "<S> later , given a query , we find all matches in the filtered text , then use their positions and the structure of the lz77 parse to find all matches in the original text . </S>",
    "<S> our experiments show this also significantly reduces query times . </S>"
  ]
}