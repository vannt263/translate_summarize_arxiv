{
  "article_text": [
    "today water is an essential commodity , for growing food , providing drinking water , and countless other uses .",
    "as climate change progresses , past historical records of rainfall totals may not be altogether great estimates of future rainfall total .",
    "so how can we tell , how much rain actually fell ?",
    "one option is direct measurement of rainfall total , the thing we really care about , via rain gauges .",
    "however these are expensive and limited in time and location .",
    "an alternative source is information from radar arrays , which is cheap and abundant .",
    "but currently this alternate approach suffers a big drawback , in that the existing algorithms to infer actual rainfall total from radar data do not perform that well .",
    "as an example , some current algorithms actually predict negative rainfall totals some the time , which is clearly an impossible total accumulated rainfall prediction .",
    "furthermore for some downstream agricultural and climate models , having a probabilistic density estimate is desired , instead of the point prediction the currently used algorithms provide .",
    "hence there is a need to squeeze as much useful data from the clouds of data as possible , meteorological pun intended .",
    "the machine learning problem , then , is given radar measurements for a location and time , such as radar reflectivity , precipitation type , and average precipitation shape , predict a probability density of how much rain fell .",
    "this is the challenge that we address here .",
    "the data set consists of 1,126,694 training points .",
    "each data point is a collection of numerical radar features collected in one hour for some particular location .",
    "these locations vary amongst several midwestern states in the united states , and were taken between april and november 2013 .",
    "the data set provides no location or time features , and were shuffled , so that there is no immediate way to recover location or time features .",
    "there are 19 provided features , with three of these features being rain rates predicted from three current algorithms .",
    "these three past algorithm features , rr1 , rr2 , and rr3 , are respectively , the ` hca - based ' , ` zdr - based ' , and ` kdp - based ' algorithms .",
    "the other 16 features are given as time series numerical data .",
    "an example data point could have its ` timetoend ' feature s ` 58.0 55.0 52.0 49.0 41.0 , ' indicating radar information taken at 58 , 55 , @xmath0 , 41 minutes from the end of the hour .",
    "for this same row , the features ` reflectivity ' as ` 0.0 , 0.0 , 1.2 , 4.5 , 0.0 ' and ` rr1 ' as ` 0.0 .",
    "0.0 , 2.2 , 0.3 , 0.0 ' mean these measurements taken at the time points in the ` timetoend ' series .",
    "the label for each row is one float number , the amount in mm of rain collected for that hour .",
    "the test set consists of 630,521 points .",
    "the test set draws from the same collection of radars covering the same region , but in the next year , 2014 .",
    "it is not indicated whether the test points were drawn according to the same time or location distribution as in the training set for 2013 .",
    "for the online kaggle competition , submissions are predictions of the probabilistic distribution of the hourly rain total .",
    "each row of the submission is a list of values @xmath1 , for @xmath2 integer values @xmath3 , and @xmath4 the rainfall total , in mm .",
    "each submission matrix @xmath5 with rows consisting of entries @xmath6 , @xmath7 , @xmath0 , @xmath8 is evaluated according to the function    @xmath9    for @xmath10 the number of test points , @xmath11 the number of bins , in this case 70 , @xmath12 our predicted probability , @xmath13 the true label for the @xmath14th row , and @xmath15 the heavyside step function , which is 1 for @xmath16 and 0 otherwise .",
    "the score can be thought of as the squared loss , averaged across all the data points and bins , either from 0 if the bin label is less than the true label , or 1 if the true label is less than the bin label .",
    "for instance a perfect prediction for the true label of @xmath17 would be the row @xmath18 corresponding to @xmath19 and @xmath20 . as we are seeking to minimize a squared loss function , and will not in general have complete certainty in our predicted label , so we will ` hedge our bets ' with each prediction , and predict according to our estimated probabilities of the test point landing in each of the seventy bins .",
    "the relatively large amount of training points , about 1 million , and the low amounts of provided features , about 30 , put us in a situation where @xmath21 , for @xmath10 the number of training samples , and @xmath11 the number of features .",
    "this suggests that overfitting should be less an issue with this data set than with smaller data sets . for parametric models , if we adopt the rough rule of thumb that 15 - 30 data points are enough to train a model with acceptable variance ,  1,000,000 data points should be enough to train models with roughly  33,000 - 66,000 parameters .",
    "we note that this rule of thumb is only a heuristic , and we explored the effect of training set size on our parametric model to see if this would lead to improved performance whenever possible .",
    "given the somewhat large amount of training points and test points , classifiers with algorithms that scale well were preferred in exploring classifiers .",
    "unlike problems in computational vision or audio , feature selection does not seem to be a major issue with this data set , hence classifiers such as neural networks were not explored . for our @xmath22-n neighbor approach , as the number of features is relatively small , while the number of training and test samples is relatively large , we prebuilt a @xmath23 tree to aid to make the problem computationally efficient .      one major issue with this data set , and a vexing one in general is , how to deal with missing data .",
    "should we ignore these data points , or to fill them in in some coherent way ?",
    "for instance , discarding all data points with some missing value leaves only  200k of the original 1.1 m data points , with the number of missing values per column ranging from 0 to  900k .",
    "the worst offending columns in this regard were the two past algorithm prediction columns rr2 and rr3 . our approach ,",
    "unless otherwise noted , was to discard these two columns , since we are seeking to improve upon the existing predictors .",
    "then , again unless otherwise noted , we filled in the rest of the missing column values with zeros .",
    "though heavy - handed , this lead to competitive classifier performance .",
    "more complicated schemes of inferring missing data , from column averages through building separate predictors for missing data , were not pursued , though appear as promising ways to improve performance .",
    "inspection of a histogram of the training set labels gives us that about 87.64% of the time , the rain label was 0.0 mm .",
    "this makes intuitive sense , in that most of the time , for most regions of the united states , it is not raining , under the assumption that the training samples were not favorably drawn from rainy periods or locations .",
    "hence we tried a ` no rain ' null - hypothesis prediction on the test data consisting of all 1 predictions , i.e.  the predicted probability that it rained less than any amount was always 1 .",
    "somewhat surprisingly this classifier was competitive . with a score of 0.01017651",
    ", this submission ranks tied between places 207 through 220 on the online leaderboard , among 331 total entries , as of may 10 , 2015 .",
    "clearly this prediction is only a first - order approximation , but it provides a useful benchmark , and illustrates the point taking a common - sense look at the data set and simple statistics about it can provide simple models that outperform more complicated ones .",
    "a sample solution , which we dubbed ` sigmoid , ' was provided by the competition administrators , with strategy as follows .",
    "consider the rr1 values of each test point , which were the rainfall rates predicted by the first past algorithm , average these , normalize by the time period covered by the radar , and use this point estimate to generate a density function using a sigmoid function .",
    "this solution scores 0.01177621 , good for 252 out of 331 entries .",
    "this was worse than the ` no rain ' submission , and we think this may be due to some combination of the following factors : a ) normalizing by the time period of radar coverage instead of the whole 60 minutes overestimates the hourly rainfall total , since the time series under ` rr1 ' gives hourly rainfall estimates , b ) the sigmoid function is a c.d.f .  of a tail - heavy normal - like distribution , and may not model the real distribution of rainfall averages that well , and c ) no estimate of the variance of the data was considered , so the parameter of the sigmoid function was constant for each test point , and hence not sufficiently tuned .",
    "further improvements to this classifier were not pursued .",
    "the next approach tried was ` histogram ' strategy .",
    "this was to compute the proportion of the training set in each of the bins , and use this as the prediction for each test sample , regardless of the feature given . in this case",
    "we have a parametric model with a naive parameter estimation algorithm linear in @xmath24 , the number of training points , and @xmath25 complexity for making a prediction on a test sample , which is computationally excellent .",
    "` histogram ' did even better than the two previous solutions , scoring 0.00971225 , which was good for 184 out of 331 .",
    "again this emphasized the value of thinking about the problem , in particular the squared - loss in the score function , for making cheaply computed , yet competitive classifiers .",
    "as has been noticed for this and other kaggle competitions , it is possible to use a submission scores to infer non - trivial information about the test sample .",
    "for instance , knowing the returned score of the all 1 s ` no rain ' submission above , submitting a solution with all 0 s for the first column and all 1 s elsewhere , and comparing these two scores , it is possible to determine the proportion of test samples in bin 0 . likewise given 70 total samples , it would be possible to infer the entire test sample histogram .",
    "furthermore since for this competition , the scores returned for a submission are based on about 70% of the test data , these estimates would be quite good .",
    "one iteration of this approach gave an estimated 85.67% of test data in bin 0 , while 87.64% of the training set were in bin 0 .",
    "this difference is interesting in its own right in that it might indicate real differences between the 2013 training and 2014 test data , and place an upper bound on the accuracy of any machine learning algorithm that learns solely on the training data . further querying the kaggle website for test set histogram estimates",
    "though were not further pursued in favor of creating an algorithm that actually learned from the training data .",
    "since each test sample came equipped with three features rr1 , rr2 , rr3 , the rain rate estimates given by the past algorithms , we tried predictions based on an ensemble of these past algorithms .",
    "we first tried ` simple average , ' which preprocessed the data by computing the arithmetical mean of the time series of predictions of each algorithm , and then averaged the three algorithms predictions with equal voting weights .",
    "inspection of the predictions revealed some negative values , so that this simple average was floored at zero .",
    "no statistical estimates of bin probabilities were obtained , so the point prediction was transformed into a step probability distribution by predicting @xmath26 for @xmath2 less than our estimate at @xmath27 otherwise .",
    "the submission based on this approach scored 0.01080682 , which places 224th .",
    "this approach did somewhat better than ` sigmoid , ' but also somewhat worse than either ` no rain ' or ` histogram . '",
    "an improvement on ` simple average ' is to give the rain rate estimates given by the past algorithms differential voting weights .",
    "hence we constructed ` optimal voting , ' based on solving the following optimization problem : given the training set labels @xmath4 , features @xmath28 rr1 , rr2 , rr3 , what are the voting weights @xmath29 that minimize the distance between @xmath29 and @xmath4 ? taking the distance to be the @xmath30 norm , this is equivalent to the problem :    @xmath31    for @xmath28 the matrix of past algorithm predictions .",
    "since least squares can be overly sensitive to outliers , we pre - processed the data by throwing out outliers . in our case , we used the world record rainfall rate over one hour as an a priori bound , which as of 2015 is 305 mm in one hour , recorded in holt , missouri in 1947 .",
    "these outliers were suspected to be gauge errors .",
    "the coefficient obtained for rr1 was larger than the other coefficients by roughly three order of magnitude , and were insensitive to retraining based on randomly selecting subsets of the data .",
    "this is some evidence that rr1 is the best predictor of the three past algorithms .",
    "` optimal voting ' scored 0.01014877 , good enough for 206th , beating both ` sigmoid ' and ` sample avg ' by good margins , ` no rain ' by a small margin , but doing worse than ` histogram ' .",
    "we note that an immediate extension to these two ensemble approaches is to get good statistical estimates of the probabilistic distribution of the rainfall total , and not just using step distribution based on a point prediction , though this was not pursued in this report .",
    "to obtain a probability distribution estimates , we fitted parametric models to the data , in this case multinomial logistic regression models .",
    "logistic regression models take the log odds of each class relative to some reference class as a linear function of the feature vector , so that these are a particular kind of generalized linear models . in the multinomial",
    "setting , once parameters @xmath32 are estimated , the probability class @xmath33 among @xmath22 class is given as    @xmath34    where each feature vector is bundled with a constant number to allow fitting a constant bias , and normalized by the denominator to give some probability estimate between 0 and 1 .",
    "the reference class , whose choice does not matter , has probability prediction given by replacing the above fraction by 1 .",
    "the parameters are fit by maximal likelihood estimation , which amount to solving a numerical optimization problem by , for instance , the newton - raphson method .",
    "fitting for @xmath22 classes and @xmath11 features amounts to finding estimates for roughly @xmath35 parameters .      we did not obtain promising results from fitting our logistic regression .",
    "results from our logistic regression model were worse than simple benchmarks .",
    "increasing training set size did not seem to help much , which seemed to use like a sample size saturation effect .",
    "adding @xmath36 regularization did not help much either .",
    "our diagnosis is that this logistic regression model appeared to be predicting equal probabilities for the first few bins , so it suffered a big score hit due to this . proposed possible fixes include try other kinds of regularization , another numerical solver , or randomizing initial starting points in mle search , though we did not have the resources to pursue these additional avenues .",
    "the @xmath22-nearest neighbors algorithm , on a high level , finds the @xmath22 nearest points to a test vector , and assigns the test vector as some function of its neighbors labels . in our case",
    ", we estimate the probability distribution of the test point label into the 70 bins by tallying the proportion of the neighbor s labels that fall into each bin . hence this is a kind of ` local ' extension of the histogram approach above , where we are taking histograms of only the test point s nearest neighbors .",
    "given that our test sample is about 600k points , and we have a relatively small number of features , we first built a @xmath22-d tree based on the training data , which then allows us to perform much speedier test sample predictions .",
    "to find an optimal @xmath22 value , we randomly split off a training set of 33,000 points and a validation set of 100,000 points from the training data .",
    "this asymmetry of sizes was a rough guess given the relative costs associated with @xmath22-d tree construction versus test sample evaluation .",
    "iterative searches for @xmath22 values produced the following figure of a @xmath37 shaped performance curve .",
    "convolutions windows of around 150 performed best , with smaller values in general not providing enough context , and large values washing out too many details .",
    "see figure  [ fig : scoresvsk ] .     in nearest neighbors , scaledwidth=95.0% ]",
    "once a nearly optimal @xmath22 was identified , we measured the effect that increasing the training set size had on classifier score on a 100,000 point validation set for this particular @xmath22 .",
    "we searched by factors of @xmath38 from 3.33e2 to 1.00e5 and found performance increased monotonically with larger training set sizes .",
    "one salient feature of this graph is that large initial gains in performance eventually gave way to much smaller later gains , so that the model seems to have some a threshold effect as data size increases .",
    "see figure  [ fig : scoresvss ] .",
    "in particular , we observed less than a unit increase in score performance for a unit log increase in training set size .",
    "one possible explanation for this is that the classifier is approaching the bayes error .",
    "predictions on the test set were carried out using the 100,000 point training set on the far right end of the graph .",
    "on 150-@xmath11 neighbors , scaledwidth=95.0% ]      for our near optimal @xmath22 of 150 and training set size of 100,000 , we obtained a validation set score of 0.00857948 .",
    "a score of 0.00857948 is much better than all the other algorithms tested , would be good enough for 73 world - wide out of 331 in the kaggle competition , placing it in the top 25% of submissions world - wide .",
    "further improvements are expected to give more gains .",
    "first among these is that we have a training set size of  1 million to build a bigger , better k - d tree , though this effect is expected to be limited as noted above .",
    "another approach is parameter optimization , in particular @xmath39 , the @xmath40 notion of distance used in the nearest neighbor search .",
    "a further avenue towards improvement is filling in missing data in some more intelligent way than as was done simply with zeros , for instance with either column means or medians .",
    "we hope to pursue all of these avenues .",
    "figure  [ fig : summary ] summarizes the scores and ranking for the various classifiers tried .",
    "nearest neighbors was the best classifier tested , followed by ` histogram ' .",
    "an immediate area for further exploration is a richer set of derived features from the given time series features .",
    "only series averages were computed as derived features , and this is suspected as one bottleneck in predictor performance .",
    "linear discriminant analysis ( lda ) and quadratic discriminant analysis ( qda ) are two further parametric models to explore , with qda providing greater decision boundary flexibility .",
    "both approaches however assume more than logistic regression models do , in particular a gaussian distributions of labels , and suffer in performance to varying degrees when this assumption does not hold .      a whole slew of other machine learning approaches could be applied to these data .",
    "support vector ( machine ) regressors , or svr s , stand out , given their computational efficiency and other favorable theoretical features .",
    "neural networks would be intriguing to explore , in particular their ability for automatic feature detection .",
    "an approach for using classifiers like svm s in this problem to produce probability distributions is sketched below .",
    "one standard way to turn classifiers into regressors is to create many classification labels .",
    "another idea for this problem is to use classifiers to update some prior probability density estimates : first we take some posterior probability density estimates drawn from the training histogram or from a nearest neighbor search",
    ". then we update the estimate based on what the classifier predicts .",
    "the strength of the update can be take as a tunable parameter optimized through cross - validation .",
    "one concrete way to think about this update would be that the posterior probability density estimate is 100 votes about which bin the test sample is at . if a classifier predicts the test sample is in bin @xmath41 , then add @xmath42 many votes for bin @xmath41 .",
    "one last approach is always to take an ensemble of all the best performing classifiers from each of the above approaches .",
    "thank you to professor bartlett and professor efros for very useful and insightful discussions all the way from thinking about ideas for the project through working out particular algorithms for this data set .",
    "i felt like i learned so much in the course and through this project , and very much appreciated your help !",
    "cifelli , r. , chandrasekar , v. , lim , s. , kennedy , p.c . ,",
    "wang , y. , rutledge , s.a .",
    ", _ a new dual - polarization radar rainfall algorithm : application in colorado precipitation events _ , j. atmos . oceanic technol .",
    "doi : 10.1175 , 2010jtecha1488.1 , 2011 .",
    "lakshmanan , v , a. kleeman , j. boshard , r. minkowsky , a. pasch , _ the ams - ai 2015 - 2016 contest : probabilistic estimate of hourly rainfall from radar _ , 13th conference on artificial intelligence , american meteorological society , phoenix , az , 2015 ."
  ],
  "abstract_text": [
    "<S> we applied a variety of parametric and non - parametric machine learning models to predict the probability distribution of rainfall based on 1 m training examples over a single year across several u.s . </S>",
    "<S> states . </S>",
    "<S> our top performing model based on a squared loss objective was a cross - validated parametric k - nearest - neighbor predictor that took about six days to compute , and was competitive in a world - wide competition . </S>"
  ]
}