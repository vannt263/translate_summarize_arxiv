{
  "article_text": [
    "suppose @xmath0 is an @xmath1 matrix with real or complex entries and eigenvalues @xmath2 , repeated by multiplicities .",
    "a linear statistic of the eigenvalues of @xmath0 is a function of the form @xmath3 , where @xmath4 is some fixed function .",
    "central limit theorems for linear statistics of eigenvalues of large dimensional random matrices have received considerable attention in recent years . a very curious feature that makes these results unusual and interesting",
    "is that they usually _ do not require normalization _ , i.e.  one does not have to divide by  @xmath5 ; only centering is enough .",
    "moreover , they have important applications in statistics and other applied areas ( see e.g.  the recent survey by johnstone  @xcite ) .",
    "the literature around the topic is quite large . to the best of our knowledge ,",
    "the investigation of central limit theorems for linear statistics of eigenvalues of large dimensional random matrices began with the work of jonsson  @xcite on wishart matrices .",
    "the key idea is to express @xmath6 as @xmath7 where @xmath0 is an @xmath8 wishart matrix , and then apply the method of moments to show that this is gaussian in the large @xmath9 limit .",
    "in fact , jonsson proves the joint convergence of the law of @xmath10 to a multivariate normal distribution ( where @xmath11 is fixed ) .",
    "a similar study for wigner matrices was carried out by sina  and soshnikov @xcite .",
    "a deep and difficult aspect of the sina - soshnikov results is that they get central limit theorems for @xmath12 , where @xmath13 is allowed to grow at the rate @xmath14 , instead of remaining fixed .",
    "they also get clts for @xmath15 for analytic @xmath4 .",
    "incidentally , for gaussian wigner matrices , the best available results are due to johansson  @xcite , who characterized a large ( but not exhaustive ) class of functions for which the clt holds .",
    "in fact , johansson proved a general result for linear statistics of eigenvalues of random matrices whose entries have a joint density with respect to lebesgue measure of the form @xmath16 , where @xmath17 is a polynomial function and @xmath18 is the normalizing constant .",
    "these models are widely studied in the physics literature .",
    "johansson s proof relies on a delicate analysis of the joint density of the eigenvalues , which is explicitly known for this class of matrices .",
    "another important contribution is the work of diaconis and evans @xcite , who proved similar results for random unitary matrices . again",
    ", the basic approach relies on the method of moments , but the computations require new ideas because of the lack of independence between the matrix entries .",
    "however , as shown in @xcite , strikingly exact computations are possible in this case by invoking some deep connections between symmetric function theory and the unitary group .",
    "an alternative approach , based on stieltjes transforms , has been developed in bai and yao @xcite and bai and silverstein @xcite .",
    "this approach has its roots in the semi - rigorous works of girko @xcite and khorunzhy , khoruzhenko , and pastur @xcite .",
    "yet another line of attack , via stochastic calculus , was initiated in the work of cabanal - duvillard @xcite .",
    "the ideas were used by guionnet @xcite to prove central limit theorems for certain band matrix models . far reaching results for a very general class of band matrix models",
    "were later obtained using combinatorial techniques by anderson and zeitouni @xcite .",
    "other influential ideas , sometimes at varying levels of rigor , come from the papers of costin and lebowitz @xcite , boutet de monvel , pastur and shcherbina @xcite , johansson @xcite , keating and snaith @xcite , hughes et .",
    "@xcite , soshnikov @xcite , israelson @xcite and wieand  @xcite .",
    "the recent works of anderson and zeitouni @xcite , dumitriu and edelman @xcite , rider and silverstein @xcite , rider and virg  @xcite , jiang @xcite , and hachem et .",
    "@xcite provide several illuminating insights and new results .",
    "the recent advances in the theory of second order freeness ( introduced by mingo and speicher @xcite ) are also of great interest .    in this paper we introduce a result ( theorem [ matrix ] ) that may provide a unified ` soft tool ' for matrices that can be easily expressed as smooth functions of independent random variables .",
    "the tool is soft in the sense that we only need to calculate various upper and lower bounds rather than perform exact computations of limits as required for existing methods .",
    "( in this context , it should be noted that soft arguments are possible even in the combinatorial techniques , if one works with cumulants instead of moments , e.g.  as in @xcite , lemma 4.10 ) .",
    "we demonstrate the scope of our approach with applications to generalized wigner matrices , gaussian matrices with arbitrary correlation structure , gaussian toeplitz matrices , wishart matrices , and double wishart matrices .",
    "let us now briefly describe the main idea .",
    "suppose @xmath19 is a vector of independent standard gaussian random variables , and @xmath20 is a smooth function .",
    "let @xmath21 denote the gradient of @xmath22 .",
    "we know that if @xmath23 is typically small , then @xmath24 has small fluctuations .",
    "in fact , the gaussian poincar inequality says that @xmath25 thus , the size of @xmath21 controls the variance of @xmath24 . based on this , consider the following speculation : is it possible to extend the poincar inequality to the ` second order ' , as a method of determining whether @xmath24 is approximately gaussian by inspecting the behavior of the second order derivatives  of  @xmath22 ?",
    "the speculation turns out to be correct ( and useful for random matrices ) , although in a rather mysterious way .",
    "the following example is representative of a general phenomenon .",
    "suppose @xmath26 is a fixed @xmath8 real symmetric matrix , and the function @xmath20 is defined as @xmath27 where @xmath28 denotes the transpose of the vector @xmath29 .",
    "let @xmath19 be a vector of independent standard gaussian random variables , and let us ask the question `` when is @xmath24 approximately gaussian ? '' .",
    "now , if @xmath30 are the eigenvalues of @xmath26 with corresponding eigenvectors @xmath31 , then @xmath32 where @xmath33 . since we can assume without loss of generality that @xmath34",
    "are mutually orthogonal , therefore @xmath35 are again i.i.d .",
    "standard gaussian .",
    "this seems to suggest that @xmath24 is approximately gaussian if and only if ` no eigenvalue dominates in the sum ' .",
    "in fact , one can show that @xmath24 is approximately gaussian if and only if @xmath36 now @xmath37 , where @xmath38 denotes the hessian matrix of @xmath22 .",
    "thus , the question about the gaussianity of @xmath24 can be reduced to a question about the negligibility of the operator norm squared of @xmath39 @xmath40 in comparison to the variance of @xmath24 @xmath41 .    in theorem  [ poincare1 ]",
    "we generalize this notion to show that for any smooth @xmath22 , @xmath24 is approximately gaussian whenever _ the typical size of the operator norm squared of @xmath42 is small compared to @xmath43 _ , and a few other conditions are satisfied .",
    "an outline of the rigorous proof is given in the next subsection .",
    "the idea is applied to random matrices as follows .",
    "we consider random matrices that can be easily expressed as functions of independent random variables , and think of the linear statistics of eigenvalues as functions of these independent variables .",
    "the setup can be pictorially represented as @xmath44 the main challenge is to evaluate the second order partial derivatives of @xmath22 .",
    "however , our task is simplified ( and the argument is ` soft ' ) because we only need bounds and not exact computations .",
    "still , a considerable amount of bookkeeping is involved .",
    "we provide a ` finished product ' in theorem [ matrix ] for the convenience of potential future users of the method .",
    "a discrete version of this idea is investigated in the author s earlier paper  @xcite .",
    "however , no familiarity with  @xcite is required here .",
    "the argument for general @xmath22 is not as intuitive as for quadratic forms .",
    "it begins with stein s method  @xcite : if a random variable @xmath45 satisfies @xmath46 for a large class of functions @xmath47 , then @xmath45 is approximately standard gaussian .",
    "the idea stems from the fact that if @xmath45 is _ exactly _ standard gaussian , then @xmath48 for all absolutely continuous @xmath47 for which both sides are well defined .",
    "stein s lemma ( lemma  [ steins ] in this paper ) makes this precise with error bounds .",
    "now suppose we are given a random variable @xmath45 , and there is a function @xmath49 such that for all a.c .",
    "@xmath47 , @xmath50 for example , if @xmath45 has a density @xmath51 with respect to lebesgue measure , and @xmath52 , @xmath53 , then the function @xmath54 serves the purpose .",
    "now if @xmath55 in a probabilistic sense , then we can conclude that @xmath56 and it would follow by stein s method that @xmath45 is approximately standard gaussian .",
    "this idea already occurs in the literature on normal approximation  @xcite .",
    "however , it is not at all clear how one can infer facts about @xmath57 when @xmath45 is an immensely complex object like a linear statistic of eigenvalues of a wigner matrix .",
    "one of the main contributions of this paper is an explicit formula for @xmath57 when @xmath45 can be expressed as a differentiable function of a collection of independent gaussian random variables .",
    "[ basiclmm ] suppose @xmath19 is a vector of independent standard gaussian random variables , and @xmath20 is an absolutely continuous function .",
    "let @xmath58 , and suppose that @xmath52 and @xmath53 .",
    "suppose @xmath49 is a function satisfying for all lipschitz @xmath47 .",
    "then @xmath59 , where @xmath60    barring the technical details , the proof of this lemma is surprisingly simple . to establish",
    ", we only have to show that for all lipschitz @xmath47 , @xmath61 this is achieved via gaussian interpolation .",
    "let @xmath62 be an independent copy of @xmath63 , and let @xmath64 . since @xmath52 , we have @xmath65 integration by parts on the right hand side gives the desired result .",
    "the details of the proof are contained in the proof of the more elaborate lemma  [ gaussian ] in section [ proofs ] .    since @xmath53",
    ", taking @xmath66 it follows that @xmath67 . combining this with the fact that @xmath68",
    ", we see that we only have to bound @xmath69 to show that @xmath45 is approximately gaussian . now ,",
    "if @xmath22 is a complicated function , @xmath70 is even more complicated .",
    "hence , we can not expect to evaluate @xmath69 . on the other hand",
    ", we can always use the gaussian poincar inequality to compute a bound on @xmath69 .",
    "this involves working with @xmath71 .",
    "since @xmath70 already involves the first order derivatives of @xmath22 , @xmath71 brings the second order derivatives into the picture .",
    "this is how we relate the smallness of the hessian of @xmath22 to the approximate gaussianity of @xmath24 , leading to theorem [ poincare1 ] in the next section .",
    "we should mention here that a problem with lemma [ basiclmm ] is that we have to know how to center and scale @xmath45 so that @xmath52 and @xmath72 .",
    "this may not be easy in practice .",
    "it is also worth noting that lemma [ basiclmm ] can , in fact , be used to prove the gaussian poincar inequality  just by taking @xmath66 and applying the cauchy - schwarz inequality to bound the terms inside the integral in the expression for @xmath73 . in this sense",
    ", one can view lemma [ basiclmm ] as a generalization of the gaussian poincar inequality .",
    "incidentally , the first proof of the gaussian poincar inequality in the probability literature is due to h.  chernoff @xcite who used hermite polynomial expansions .",
    "however , such inequalities have been known to analysts for a long time under the name of ` hardy inequalities with weights ' ( see e.g.  muckenhoupt @xcite ) .",
    "we should also mention two other concepts from the existing literature that may be related to this work .",
    "the first is the notion of the ` zerobias transform ' of @xmath45 , as defined by goldstein and reinert @xcite .",
    "a random variable @xmath74 is called a zerobias transform of @xmath45 if for all @xmath47 , we have @xmath75 a little consideration shows that our function @xmath49 is just the density of the law of @xmath74 with respect to the law of @xmath45 when the laws are absolutely continuous with respect to each other .",
    "however , while it is quite difficult to construct zerobias transforms ( not known at present for linear statistics of eigenvalues ) , lemma [ basiclmm ] gives a direct formula for @xmath49 .",
    "the second related idea is the work of borovkov and utev @xcite which says that if a random variable @xmath45 with @xmath52 and @xmath53 satisfies a poincar inequality with poincar constant close to @xmath76 , then @xmath45 is approximately standard gaussian ( if the poincar constant is exactly @xmath76 , the @xmath45 is exactly standard gaussian ) .",
    "as shown by chen @xcite , this fact can be used to prove central limit theorems in ways that are closely related to stein s method .",
    "although it seems plausible , we could not detect any apparent relationship between this concept and our method of extending poincar inequalities to the second order .",
    "all our results are for functions of random variables belonging to the following class of distributions .    for each @xmath77 ,",
    "let @xmath78 be the class of probability measures on @xmath79 that arise as laws random variables like @xmath80 , where @xmath81 is a standard gaussian r.v .  and",
    "@xmath82 is a twice continuously differentiable function such that for all @xmath83 @xmath84    for example , the standard gaussian law is in @xmath85 .",
    "again , taking @xmath86 the gaussian cumulative distribution function , we see that the uniform distribution on the unit interval is in @xmath87 . for simplicity",
    ", we just say that a random variable @xmath63 is `` in @xmath88 '' instead of the more elaborate statement that `` the distribution of @xmath63 belongs to  @xmath88 '' .",
    "recall that for any two random variables @xmath63 and @xmath89 , the supremum of @xmath90 as @xmath26 ranges over all borel sets is called the total variation distance between the laws of @xmath63 and @xmath89 , often denoted simply by @xmath91 .",
    "note that the total variation distance remains unchanged under any transformation like @xmath92 where @xmath4 is a measurable bijective map .",
    "next , recall that the operator norm of an @xmath93 real or complex matrix @xmath94 is defined as @xmath95 recall that @xmath96 is the largest eigenvalue of @xmath97 .",
    "if @xmath94 is a hermitian matrix , @xmath98 is just the spectral radius ( i.e.  the eigenvalue with the largest absolute value ) of @xmath94 .",
    "this is the default norm for matrices in this paper , although occasionally we use the hilbert - schmidt norm @xmath99 the following theorem gives normal approximation bounds for general smooth functions of independent random variables whose laws are in @xmath88 for some finite @xmath100 .",
    "[ poincare1 ] let @xmath19 be a vector of independent random variables in @xmath88 for some finite @xmath101 .",
    "take any @xmath102 and let @xmath21 and @xmath38 denote the gradient and hessian of @xmath22 .",
    "let @xmath103 suppose @xmath104 has a finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable having the same mean and variance as @xmath45 . then @xmath106 if we slightly change the setup by assuming that @xmath63 is a gaussian random vector with mean @xmath107 and covariance matrix @xmath108 , keeping all other notation the same , then the corresponding bound is @xmath109    note that when @xmath110 are gaussian , we have @xmath111 , and the first bound becomes simpler . for an elementary illustrative application of theorem [ poincare1 ] ,",
    "consider the function @xmath112 then @xmath113 with the convention that @xmath114 .",
    "again , @xmath115 it follows that @xmath116 , @xmath117 , and @xmath118 , which gives a total variation error bound of order @xmath119 .",
    "note that the usual way to prove a clt for @xmath120 is via martingale arguments , but total variation bounds are not trivial to obtain along that route .",
    ".1 in _ remarks . _",
    "( i ) theorem [ poincare1 ] can be viewed as a second order analog of the gaussian poincar inequality . while the poincar inequality implies that @xmath24 is concentrated whenever the individual coordinates have small ` influence ' on the outcome , theorem [ poincare1 ]",
    "says that if in addition , the ` interaction ' between the coordinates is small , then @xmath24 has gaussian behavior .",
    "the magnitude of @xmath121 is a measure of this interaction .",
    "( ii ) the smallness of @xmath121 does not seem to imply that @xmath24 has any special structure , at least from what the author understands .",
    "in particular , it does not imply that @xmath24 breaks up as an approximately additive function as in hjek projections @xcite .",
    "it is quite mysterious , at the present level of understanding , as to what causes the gaussianity .",
    "( iii ) a problem with theorem [ poincare1 ] is that it does not say anything about @xmath122 .",
    "however , in practice , we only need to know a lower bound on @xmath122 to use theorem [ poincare1 ] for proving a clt .",
    "sometimes this may be a lot easier to achieve than computing the exact limiting value of @xmath122 .",
    "this is demonstrated in some of our examples in section [ examples ] .",
    "( iv ) one may wonder why we work with random variables in @xmath88 instead of just gaussian random variables .",
    "indeed , the main purpose of this limited generality is simply to pre - empt the question ` does your result extend to the non - gaussian case ? ' .",
    "however , it is more serious than that : the true rate of convergence may actually differ significantly depending on whether @xmath63 is gaussian or not , as demonstrated in the case of wigner matrices in section [ examples ] .",
    "( v ) there is a substantial body of literature on central limit theorems for general functions of independent random variables .",
    "some examples of available techniques are : ( a ) the classical method of moments , ( b ) the martingale approach and skorokhod embeddings , ( c ) the method of hajk projections and some sophisticated extensions ( e.g.  @xcite , @xcite , @xcite ) , ( d ) stein s method of normal approximation ( e.g.  @xcite , @xcite , @xcite ) , and ( e )  the big - blocks - small - blocks technique and its modern multidimensional versions ( e.g.  @xcite , @xcite ) . for further references  particularly on stein s method , which is a cornerstone of our approach  we refer to @xcite . apart from the method of moments , none of the other techniques have been used for dealing with random matrix problems .",
    "let @xmath9 be a fixed positive integer and @xmath123 be a finite indexing set .",
    "suppose that for each @xmath124 , we have a @xmath125 map @xmath126 . for each @xmath127 ,",
    "let @xmath128 be the complex @xmath1 matrix whose @xmath129 element is @xmath130 .",
    "let @xmath131 be an analytic function on the complex plane .",
    "let @xmath132 be a collection of independent random variables in @xmath88 for some finite @xmath101 . under this very general setup , we give an explicit bound on the total variation distance between the laws of @xmath133 and a gaussian random variable with matching mean and variance ( here as usual , @xmath134 and @xmath135 denote the real and imaginary parts of a complex number @xmath136 ) .    as mentioned before , the method involves some bookkeeping , partly due to the quest for generality .",
    "the algorithm requires the user to compute a few quantities associated with the matrix model , step by step as described below .",
    "first , let @xmath137 next , define three functions @xmath138 , @xmath139 and @xmath140 on @xmath141 as follows .",
    "@xmath142 define two entire functions @xmath143 and @xmath144 as @xmath145 let @xmath146 and @xmath147 .",
    "usually , of course , we will just have @xmath148 .",
    "next , define three more functions @xmath149 finally , define three quantities @xmath150 , @xmath151 , and @xmath152 as @xmath153 let us pacify the possibly disturbed reader with the assurance that we only need _ bounds _ on @xmath150 , @xmath151 , and @xmath152 , as oppposed to exact computations .",
    "this turns out to be particularly easy to achieve in all our examples .",
    "we are now ready to state the theorem .",
    "[ matrix ] let all notation be as above .",
    "suppose @xmath154 has finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable with the same mean and variance as @xmath45 . then @xmath155 if we slightly change the setup by assuming that @xmath63 is a gaussian random vector with mean @xmath107 and covariance matrix @xmath108 , keeping all other notation the same , then the corresponding bound is @xmath109    _ remarks . _",
    "( i ) a problem with theorem [ matrix ] is that it does not give a formula or approximation for @xmath122 .",
    "however , central limit theorems can still be proven if we can only compute suitable _ lower bounds _ for @xmath122 . in section",
    "[ examples ] , we show that this is eminently possible in a variety of situations ( e.g.  theorems [ wignerthm ] and [ toeplitz ] ) .",
    "( ii ) although the result is stated for entire functions , the concrete error bound , combined with appropriate concentration inequalities , should make it possible to prove limit theorems for general @xmath156 functions wherever required .",
    "( iii ) note that the matrices need not be hermitian , and the random variables need not be symmetric around zero .",
    "however , it is a significant restriction that the @xmath157 s have to belong to @xmath88 for some finite @xmath101 . in particular , they can not be discrete .",
    "( iv ) by considering @xmath158 instead of @xmath4 for arbitrary @xmath159 , we see that the normal approximation error bound can be computed for any linear combination of the real and imaginary parts of the trace .",
    "this allows us to prove central limit theorems for the complex statistic @xmath160 via wold s device .",
    "( v ) it is somewhat surprising that such a general result can give useful error bounds for familiar random matrix models .",
    "unfortunately , the case of random unitary and orthogonal matrices seems to be harder because of the complexity in expressing them as functions of independent random variables .",
    "this is under the scope of a future project .",
    "this section is devoted to working out a number of applications of theorem [ poincare1 ] . in all cases ,",
    "we produce a total variation error bound where the variance of the linear statistic , @xmath122 , appears as an unknown quantity . in some of the examples ( e.g.  wigner and wishart matrices ) ,",
    "the limiting value of @xmath122 is known from the literature . in other cases , they are yet unknown , and the central limit theorems are proven modulo this lack of knowledge about  @xmath122 .",
    "the following simple lemma turns out to be very useful for bounding @xmath138 , @xmath139 , and @xmath140 in the examples .",
    "recall the definitions of the operator norm and the hilbert - schmidt norm of matrices from section [ general ] .    [",
    "trivial ] suppose @xmath161 @xmath162 are real or complex matrices of dimensions such that the product @xmath163 is defined .",
    "then @xmath164 moreover , for any @xmath165 , @xmath166\\backslash\\{i , j\\ } } \\|a_k\\|.\\ ] ]    let @xmath167 be the columns of @xmath168 . then @xmath169",
    "similarly , we have @xmath170 . for",
    "the other inequality , note that a simple application of the cauchy - schwarz inequality shows that @xmath171 now by the inequality , @xmath172 similarly , @xmath173 this completes the proof .",
    "suppose @xmath174 is a collection of independent random variables .",
    "let @xmath175 for @xmath176 and let @xmath177 a matrix like @xmath0 is called a wigner matrix .",
    "central limit theorems for linear statistics of eigenvalues of wigner matrices have been extensively studied in the literature ( see e.g.  @xcite ) .",
    "while the case of gaussian entries can be dealt with using analytical techniques @xcite , the general case requires heavy combinatorics . to give a flavor of the results in the literature ,",
    "let us state one key theorem from @xcite ( although , technically , it is not a clt for a fixed linear statistic ) .",
    ".1 in * theorem . *",
    "( sinaand soshnikov @xcite , theorem 2 ) _ let @xmath157 and @xmath0 be as above .",
    "suppose that the @xmath157 s have symmetric distributions around zero , @xmath178 for all @xmath179 , and there exists a constant @xmath180 such that for every positive integer @xmath181 and all @xmath179 , @xmath182 .",
    "let @xmath183 as @xmath184 such that @xmath185 . then _",
    "@xmath186 _ and the distribution of @xmath187 converges weakly to the normal law @xmath188 .",
    "_ .1 in as remarked in @xcite and demonstrated in @xcite , the normal approximation result can be extended to the joint distribution of the traces of various powers , and then to general analytic functions .",
    "we wish to extend the above result to the scenario where @xmath189 is not the same for all @xmath179 .",
    "a wide generalization of this problem has been recently investigated by anderson and zeitouni @xcite under the assumption that @xmath190 where @xmath4 is a continuous function on @xmath191 ^ 2 $ ] . under further assumptions ,",
    "explicit formulas for the limiting means and variances are also obtained in @xcite .",
    "if the structural assumptions are dropped and we just assume that @xmath189 is bounded above and below by positive constants , then there does not seem to be much hope of getting limiting formulas .",
    "surprisingly , however , theorem [ matrix ] still allows us to prove central limit theorems .",
    "[ wignerthm ] let @xmath0 be the wigner matrix defined in .",
    "suppose that the @xmath157 s are all in @xmath88 for some finite @xmath100 , and have symmetric distributions around zero .",
    "suppose there are two positive constants @xmath192 and @xmath193 such that @xmath194 for all @xmath179 .",
    "let @xmath13 be a sequence of positive integers such that @xmath195 .",
    "let @xmath196 .",
    "then as @xmath197 , @xmath198 moreover , @xmath199 stays bounded away from zero .",
    "the same results are true also if @xmath200 , where @xmath4 is a fixed nonzero polynomial with nonnegative coefficients .",
    "note that the rate of growth allowed for @xmath13 is @xmath201 , which is significantly worse than the sina - soshnikov condition @xmath185 .",
    "we do not know how to improve that at present .",
    "neither do we know how to produce asymptotic formulas for @xmath202 and @xmath199 as in anderson and zeitouni @xcite . on the positive side , the assumption that @xmath203 is more general than any available result , as far as we know .",
    "in particular , we do not require asymptotic ` continuity ' of @xmath189 in @xmath204 .",
    "the proof of theorem  [ wignerthm ] will follow from the following finite sample error bound .",
    "[ wigner ] fix @xmath9 .",
    "let @xmath205 be the wigner matrix defined in .",
    "suppose the @xmath157 s are in @xmath88 for some finite @xmath101 .",
    "take an entire function @xmath4 and define @xmath143 , @xmath144 as in theorem  [ matrix ] .",
    "let @xmath206 denote the spectral radius of @xmath94 .",
    "let @xmath207 and @xmath208 .",
    "suppose @xmath209 has finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable with the same mean and variance as @xmath45 .",
    "then @xmath210    _ remarks . _",
    "( i ) it is well known that under mild conditions , @xmath206 converges to a finite limit as @xmath197 ( see e.g.  @xcite , section 2.2.1 ) .",
    "even exponentially decaying tail bounds are available @xcite .",
    "thus @xmath211 and @xmath212 are generally @xmath213 in the above bound .",
    "( ii ) sinaand soshnikov ( @xcite , corollary 1 ) showed that @xmath122 converges to a finite limit under certain conditions on  @xmath4 and the distribution of the @xmath157 s .",
    "if these conditions are satisfied and the limit is nonzero , then we get a bound of order @xmath119 .",
    "moreover , for gaussian wigner matrices we have @xmath111 and hence a bound of order @xmath214 .",
    "the difference between the gaussian and non - gaussian cases is not an accident . with @xmath215 , we have @xmath216 in this case we know that the error bound in the non - gaussian case is exactly of order @xmath119",
    ". .1 in before proving lemma [ wigner ] , let us first prove theorem [ wignerthm ] using the lemma .",
    "the main difference between lemma [ wigner ] and theorem [ wignerthm ] is that the assumption of symmetry on the distributions of the entries allows us to compute a lower bound on the unknown quantity @xmath122 and actually prove a clt in theorem [ wignerthm ] .",
    "let @xmath217 , and let @xmath218 let @xmath219 denote the matrix @xmath220 .",
    "now take any collections of nonnegative integers @xmath221 and @xmath222 .",
    "then @xmath223 where the products are taken over @xmath224 .",
    "now note that if @xmath225 is odd , then @xmath226 . if @xmath227 and @xmath228 are both odd , then @xmath229 and @xmath230 .",
    "finally , if @xmath227 and @xmath228 are both even , then @xmath231 thus , under all circumstances , we have @xmath232 therefore , @xmath233 from this , it follows easily that for any positive integer @xmath13 , @xmath234 now , by , @xmath235 if @xmath236 are distinct numbers , then @xmath237 thus , @xmath238 and so , if @xmath13 is a sequence of integers such that @xmath239 , then @xmath240 where @xmath180 is a positive constant that does not vary with @xmath9 .",
    "now note that for any nonnegative integer @xmath227 , @xmath241 .",
    "thus , @xmath242 in particular , for any positive integer @xmath243 , @xmath244 let @xmath245 denote the spectral radius of @xmath0 .",
    "then for any positive integer @xmath181 and any positive even integer @xmath243 , @xmath246 now let @xmath247 $ ] . if @xmath248 is a sequence of positive integers such that @xmath249 , it follows from the sina - soshnikov result stated above that for all @xmath9 , @xmath250 where @xmath251 and @xmath180 are constants that do not depend on @xmath9 .",
    "note that we could apply the theorem because @xmath252 s are symmetric and @xmath253 for all @xmath181 due to the @xmath88 assumption .",
    "the @xmath254 term arises because @xmath255 instead of @xmath256 as required in the sina - soshnikov theorem .",
    "combined with the previous step , this gives @xmath257 now let us apply lemma [ wigner ] to @xmath258 .",
    "first , let us fix @xmath9 .",
    "we have @xmath259 , and hence @xmath260 and @xmath261 .",
    "it follows that both @xmath262 and @xmath263 are bounded by @xmath264 , which according to , is bounded by @xmath265 . on the other hand , by , @xmath122 is lower bounded by @xmath266 . combining , and using lemma [ wigner ] , we get @xmath267 where @xmath180 is a constant depending only on @xmath192 , @xmath193 , @xmath268 and @xmath269 , and @xmath81 is a gaussian random variable with the same mean and variance as @xmath45 .",
    "if @xmath195 , the bound goes to zero .",
    "when @xmath200 , where @xmath4 is a fixed polynomial with nonnegative coefficients , the proof goes through almost verbatim , and is in fact simpler .",
    "the nonnegativity of the coefficients is required to ensure that all monomial terms are positively correlated , so that we can get a lower bound on the variance .",
    "let @xmath270 .",
    "let @xmath271 denote a typical element of @xmath141 .",
    "for each such @xmath29 , let @xmath272 denote the matrix whose @xmath129 element is @xmath273 if @xmath274 and @xmath275 if @xmath276 .",
    "then the matrix @xmath94 considered above is simply @xmath277 , and this puts us in the setting of theorem  [ matrix ] .",
    "now , @xmath278 therefore , for any matrix @xmath26 with @xmath279 , and @xmath280 , @xmath281 it is clear that the same bound holds even if @xmath282 .",
    "thus , @xmath283 next , let @xmath284 and @xmath285 be as in , and take any @xmath286 , @xmath287 .",
    "then by the cauchy - schwarz inequality , we have @xmath288 thus , @xmath289 now , it is clear that @xmath290 and @xmath291 .",
    "thus , if we define @xmath292 , @xmath293 , and @xmath294 as in theorem [ matrix ] , and let @xmath295 be the spectral radius of @xmath128 , then for all @xmath127 we have @xmath296 this gives @xmath297 plugging these values into theorem [ matrix ] , we get the result .",
    "suppose we have a collection @xmath298 of jointly gaussian random variables with mean zero and @xmath299 covariance matrix @xmath108 .",
    "let @xmath300 . note that @xmath94 may be non - symmetric .",
    "limiting behavior of the spectrum in such matrices have been recently investigated by anderson and zeitouni @xcite under special structures on @xmath108 .",
    "we have the following general result .    [ corrwigner ]",
    "take an entire function @xmath4 and define @xmath143 , @xmath144 as in theorem  [ matrix ] .",
    "let @xmath206 denote the operator norm of @xmath94 .",
    "let @xmath207 and @xmath208 .",
    "suppose @xmath209 has finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable with the same mean and variance as @xmath45 .",
    "then @xmath301    the computations of @xmath151 and @xmath152 are exactly the same as for wigner matrices .",
    "the only difference is that we now apply the second part of theorem [ matrix ] .    of course , the limiting behavior of @xmath122 is not known , so this does not prove a central limit theorem as long as such results are not established .",
    "the term @xmath302 can often be handled by the well - known gershgorin bound for the operator norm : @xmath303 where @xmath304 .",
    "the next example gives a concrete application of the above result .",
    "fix a number @xmath9 and let @xmath305 be independent standard gaussian random variables .",
    "let @xmath0 be the matrix @xmath306 this is a gaussian toeplitz matrix , of the kind recently considered in bryc , dembo , and jiang @xcite and also in m.  meckes @xcite and bose and sen @xcite .",
    "although toeplitz determinants have been extensively studied ( see e.g.  basor @xcite and references therein ) , to the best of our knowledge , there are no existing central limit theorems for general linear statistics of eigenvalues of random toeplitz matrices .",
    "we have the following result .    [ toeplitz ] consider the gaussian toeplitz matrices defined above .",
    "let @xmath13 be a sequence of positive integers such that @xmath307 .",
    "let @xmath196 . then",
    ", as @xmath197 , @xmath198 moreover , there exists a positive constant @xmath193 such that @xmath308 for all @xmath9 .",
    "the central limit theorem also holds for @xmath200 , when @xmath4 is a fixed nonzero polynomial with nonnegative coefficients . in that case , @xmath309 for some positive constant @xmath193 depending on @xmath4 .",
    "_ remarks .",
    "_ ( i ) note that the theorem is only for _ gaussian _ toeplitz matrices .",
    "in fact , considering the function @xmath310 , we see that a clt need not always hold for linear statistics of non - gaussian toeplitz matrices .",
    "\\(ii ) this is an example of a matrix ensemble where nothing is known about the limiting formula for @xmath199 .",
    "theorem [ matrix ] enables us to prove the clt even without knowing the limit of @xmath199 . as before , this is possible because we can easily get lower bounds on @xmath199 .    in the notation of the previous subsection , @xmath311 thus",
    ", @xmath312 let @xmath245 denote the spectral norm of @xmath0 . using proposition [ corrwigner ] and the above bound on @xmath313 , we have @xmath314 where @xmath18 is a gaussian random variable with the same mean and variance as @xmath315 and @xmath193 is a universal constant .    in the rest of the argument we will write @xmath11 instead of @xmath13 to ease notation .",
    "first , note that @xmath316 as in the proof of theorem [ wignerthm ] , it is easy to verify that all terms in the above sum are positively correlated with each other , and hence , for any partition @xmath317 of the set @xmath318 into disjoint subcollections , @xmath319 for any collection of distinct positive integers @xmath320 , let @xmath321 be the set of all @xmath322 such that @xmath323 for @xmath324 and @xmath325 . clearly , @xmath326 . again , since the @xmath327 s are distinct , @xmath328 next , note that the number of ways to choose @xmath329 satisfying the restrictions is @xmath330 since we can assume , without loss of generality , that @xmath331 , the above quantity can be easily seen to be lower bounded by @xmath332 .",
    "finally , noting that if @xmath333 , then @xmath321 and @xmath334 are disjoint , and applying , we get @xmath335 where @xmath193 is a positive universal constant .    next , let @xmath245 denote the spectral norm of @xmath0 . by theorem 1 of m.  meckes @xcite , we know that  @xmath336 .",
    "now , it is easy to verify that the map @xmath337 has lipschitz constant bounded irrespective of @xmath9 . by standard gaussian concentration results ( e.g.  ledoux @xcite , sections 5.1 - 5.2 )",
    ", it follows that for any @xmath338 , @xmath339 where , again , @xmath193 is a universal constant . combining with result for @xmath340",
    ", it follows that for any @xmath9 and @xmath338 , @xmath341 thus , the term @xmath342 in is bounded by @xmath343 .",
    "therefore , from and , it follows that @xmath344 where @xmath193 is a universal constant . clearly , if @xmath345 , this goes to zero .",
    "this completes the proof for @xmath196 .",
    "when @xmath346 , where @xmath4 is a fixed polynomial with nonnegative coefficients , the proof goes through exactly as above .",
    "if @xmath347 , the nonnegativity of the coefficients ensures that @xmath348 , and we can re - use the bounds computed before to show that @xmath349 .",
    "the rest is similar .",
    "let @xmath350 be two positive integers , and let @xmath351 be a collection of independent random variables in @xmath88 for some finite @xmath101 .",
    "let @xmath352 in statistical parlance , the matrix @xmath94 is called the _ wishart matrix _ or _ sample covariance matrix _ corresponding to the _ data matrix _ @xmath63 .",
    "just as in the wigner case , linear statistics of eigenvalues of wishart matrices also satisfy unnormalized central limit theorems under certain conditions .",
    "this was proved for polynomial @xmath4 by jonsson @xcite , and for a much larger class of functions in bai and silverstein @xcite . a different proof was recently given by anderson and zeitouni @xcite .",
    "we have the following error bound .",
    "[ covprop ] let @xmath206 be the largest eigenvalue of @xmath94 .",
    "take any entire function @xmath4 and define @xmath143 , @xmath144 as in theorem  [ matrix ] .",
    "let @xmath353 and @xmath354 .",
    "suppose @xmath209 has finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable with the same mean and variance as @xmath45 . then @xmath355 if we now change the setup and assume that the entries of @xmath63 are jointly gaussian with mean @xmath107 and @xmath356 covariance matrix @xmath108 , keeping all other notation the same , then the corresponding bound is @xmath357    _ remarks . _",
    "( i ) as in the wigner case , it is well known that under mild conditions , @xmath358 as @xmath359 with @xmath360 .",
    "we refer to section 2.2.2 in the survey article @xcite for details .",
    "it follows that @xmath211 and @xmath212 are  @xmath213 .",
    "( ii ) it is shown in @xcite that in the case of independent entries , if @xmath361 , then @xmath122 converges to a finite positive constant under fairly general conditions ( an explicit formula for the limit is also available ) .",
    "therefore under such conditions , the first bound above is of order  @xmath362 .",
    "\\(iii ) we should remark that the spectrum of @xmath363 is often studied by studying the block matrix @xmath364 because @xmath365 thus , in principle , we can derive proposition [ covprop ] using the information contained in lemma [ wigner ] . however , for expository purposes , we prefer carry out the explicit computations necessary for applying theorem [ matrix ] without resorting to the above trick .",
    "the computations will also be helpful in dealing with the double wishart case in the next subsection .",
    "first , let us define the indexing set @xmath366 from now on , we simply write @xmath367 instead of @xmath368 .",
    "let @xmath369 be a typical element of @xmath141 . in the following , the collection @xmath29 is used as a matrix , and it seems that the only way to avoid confusion is to write @xmath63 instead of  @xmath29 , so we do that . generally , there is no harm in confusing this @xmath63 with the collection of random variables defined at the onset .",
    "let @xmath138 , @xmath139 , and @xmath140 be defined as in .",
    "for each @xmath181 and @xmath370 , let @xmath371 be the @xmath372 coordinate vector in @xmath373 , i.e.  the vector whose @xmath372 component is @xmath76 and the rest are zero .",
    "then @xmath374 and @xmath375 now take any @xmath1 matrix @xmath26 with @xmath376 .",
    "then for any @xmath377 , @xmath378 this shows that @xmath379 next , let @xmath380 , @xmath381 , and @xmath382 be arbitrary matrices of complex numbers such that @xmath383",
    ". then @xmath384 by lemma [ trivial ] , we have @xmath385 again , by the formula for second derivatives of @xmath94 , @xmath386 this shows that @xmath387 finally , note that @xmath388 .",
    "combining the bounds we get @xmath389 from this , we get @xmath390 with the aid of theorem [ matrix ] , this completes the proof .",
    "let @xmath391 be three positive integers , and let @xmath351 be and @xmath392 be two collections of independent random variables in @xmath88 for some finite @xmath101 .",
    "let @xmath393 a matrix like @xmath94 is called a _",
    "double wishart matrix_. double wishart matrices are very important in statistical theory of canonical correlations ( see the discussion in section 2.2 of @xcite ) .    if the matrices @xmath63 and @xmath89 had independent standard gaussian entries , the matrix @xmath394 would be known as a _",
    "jacobi _ matrix . in a recent preprint ,",
    "jiang @xcite proves the clt for the jacobi ensemble .",
    "we have the following result .    [ double ]",
    "let @xmath395 and @xmath396 be the largest eigenvalues of @xmath397 and @xmath398 , and let @xmath399 be the smallest eigenvalue of @xmath398 .",
    "let @xmath400 .",
    "take any entire function @xmath4 and define @xmath143 , @xmath144 as in theorem  [ matrix ] .",
    "let @xmath401 and @xmath402 suppose @xmath209 has finite fourth moment and let @xmath105 .",
    "let @xmath81 be a normal random variable with the same mean and variance as @xmath45",
    ". then @xmath403    _ remarks . _",
    "( i ) assume that @xmath9 , @xmath404 , and @xmath405 grow to infinity at the same rate ( we refer to this as the ` large dimensional limit ' ) .",
    "from the results about the extreme eigenvalues of wishart matrices ( @xcite , section 2.2.2 ) , it is clear that @xmath358 , and hence @xmath211 , @xmath212 are stochastically bounded .",
    "( ii ) there are no rigorous results about the behavior of @xmath122 in the large dimensional limit , other than in the gaussian case , which has been settled in @xcite , where it is shown that @xmath122 converges to a finite limit . (",
    "iii ) when the entries of @xmath63 and @xmath89 are jointly gaussian and some conditions on the dimensions are satisfied , the exact joint distribution of the eigenvalues of @xmath94 is known ( see @xcite , section 2.2 for references and an interesting story ) . while it may be possible to derive a clt for the gaussian case using the explicit form of this density , it is hard to see how the non - gaussian case can be handled by either the method of moments or stieltjes transforms .",
    "\\(iv ) in principle , it seems something could be said using the second order freeness results of mingo and speicher @xcite .",
    "however , to the best of our knowledge , an explicit clt for double wishart matrices has not been worked out using second order freeness .    for convenience ,",
    "let @xmath406 and @xmath407 .",
    "note that @xmath408 , @xmath409 and @xmath410 .",
    "let the other notation be as in the proof of proposition [ covprop ] .",
    "now @xmath411 again , using the formula @xmath412 we have @xmath413 now take any @xmath1 matrix @xmath26 with @xmath376 . then for any @xmath377 , @xmath414 similarly , @xmath415 since @xmath416 and @xmath417 , @xmath418 next , let @xmath419 , @xmath420 , @xmath421 , @xmath422 , and @xmath423 be arbitrary arrays of complex numbers such that @xmath424 , @xmath425 , and @xmath426",
    ". then @xmath427 similarly , @xmath428 combining , and using the inequality @xmath429 we get @xmath430 next , let us compute the second derivatives .",
    "first , note that @xmath431 using lemma [ trivial ] in the last step below , we get @xmath432 thus , we have @xmath433 next , note that @xmath434 when we open up the brackets in the above expression , we get four terms .",
    "let us deal with the first term : @xmath435 it can be similarly verified that the same bound holds for the other three terms as well . combining , we get @xmath436 finally , note that @xmath437 proceeding exactly as before , it is quite easy to get the following bound.it seems reasonable to omit the details .",
    "@xmath438 combining , , and , and noting that @xmath417 , @xmath416 , and the hs - norms of @xmath439 , @xmath440 , @xmath441 , and @xmath442 are all bounded by @xmath76 , it is now easy to get that @xmath443 finally , note that @xmath388 . combining everything we get @xmath444 from this , we get @xmath445 an application of theorem [ matrix ] completes the proof .",
    "take any @xmath447 $ ] .",
    "it can be verified that the function @xmath448 is a solution to the equation @xmath449 thus for each @xmath29 , @xmath450 it follows that @xmath451 it can be verified that the same bound holds for @xmath452 by replacing @xmath29 with @xmath453 .",
    "therefore , we have @xmath454 since @xmath455 this completes the proof .",
    "suppose we have proved theorem [ poincare1 ] under the said assumption .",
    "take any @xmath456 such that @xmath122 is finite .",
    "now , if any one among @xmath150 , @xmath151 , and @xmath152 is infinite , there is nothing to prove .",
    "so let us assume that they are all finite .",
    "let @xmath457 $ ] be a @xmath458 function such that @xmath459 when @xmath460 and @xmath461 when @xmath462 .",
    "for each @xmath463 let @xmath464 clearly , as @xmath465 , @xmath466 note that for any finite @xmath439 , @xmath467 and its derivatives are uniformly bounded over  @xmath468 .",
    "now , since @xmath469 is finite , @xmath470 for all @xmath29 , and @xmath467 converges to @xmath22 pointwise , the dominated convergence theorem gives @xmath471 again , since @xmath472 and @xmath150 , @xmath151 and @xmath152 are all finite , the same logic shows that @xmath473 these three steps combined show that if theorem [ poincare1 ] holds for each @xmath467 , it must hold for @xmath22 as well .",
    "this completes the proof .",
    "[ gaussian ] let @xmath474 be a vector of i.i.d .",
    "standard gaussian random variables .",
    "let @xmath475 be an absolutely continuous function such that @xmath476 has zero mean and unit variance .",
    "assume that @xmath4 and its derivatives have subexponential growth at infinity .",
    "let @xmath477 be an independent copy of @xmath89 and define the function @xmath478 as @xmath479 let @xmath480 . then @xmath481 .",
    "if @xmath81 is standard gaussian , then @xmath482^{1/2},\\ ] ] where @xmath483 is the total variation distance .",
    "take any @xmath484 so that @xmath485 exists and is bounded .",
    "then we have @xmath486 now fix @xmath487 , and let @xmath488 , and @xmath489",
    ". then @xmath490 and @xmath491 are independent standard gaussian random vectors and @xmath492 . taking any @xmath370 , and using the integration - by - parts formula for the gaussian measure ( in going from the second to the third line below ) ,",
    "we get @xmath493 note that we need the growth condition on the derivatives of @xmath4 to carry out the interchange of expectation and integration and the integration - by - parts . from the above",
    ", we have @xmath494 the assertion that @xmath495 now follows by taking @xmath496 and using the hypothesis that @xmath497 .",
    "also , easily , we have the upper bound @xmath498 a simple application of lemma [ steins ] completes the proof .",
    "first off , by lemma [ techlmm ] , we can assume that @xmath22 , @xmath21 , and @xmath38 are uniformly bounded and hence apply lemma [ gaussian ] without having to check for the growth conditions at infinity .",
    "let @xmath500 be independent standard gaussian random variables and @xmath501 be functions such that @xmath502 and @xmath503 , @xmath504 for each  @xmath370 .",
    "define a function @xmath505 as @xmath506 and let @xmath507 then @xmath508 .",
    "it is not difficult to see , through centering and scaling , that it suffices to prove theorem [ poincare1 ] under the assumptions that @xmath52 and @xmath509 ( this is where the @xmath122 appears in the error bound ) .",
    "now define @xmath70 as in lemma [ gaussian ] : @xmath510 where @xmath477 is an independent copy of @xmath89 .",
    "our strategy for bounding @xmath511 is to simply use the gaussian poincar inequality : @xmath512 the boundedness of @xmath38 ensures that we can move the derivative inside the integrals when differentiating @xmath70 : @xmath513 now for each @xmath514 $ ] , let @xmath488 . with several applications of jensen s inequality and the inequality @xmath515 ,",
    "we get @xmath516 now , we have @xmath517 thus , if @xmath518 , @xmath519 on the other hand , @xmath520 thus , for any @xmath521 , @xmath522 let us now fix @xmath514 $ ] , replace @xmath523 by @xmath89 and @xmath82 by @xmath490 and use the above inequality to bound the first integrand on the right hand side of .",
    "first , note that since @xmath490 has the same law as @xmath89 , @xmath524 for the same reason , we also have @xmath525 & \\le \\kappa_0 ^ 2.\\end{aligned}\\ ] ] combining , we get @xmath526 since this does not depend on @xmath527 , it is now easy to see that the first term on the right hand side is bounded by @xmath528 . in a very similar manner ,",
    "the second term can be bounded by @xmath529 .",
    "combining , and applying the inequality @xmath530 , we finish the proof of first part of the theorem .    to prove the second part ,",
    "let @xmath531 , where @xmath89 is a vector of independent standard gaussian random variables and @xmath94 is a matrix such that @xmath532 .",
    "define @xmath533 as @xmath534 .",
    "it is easy to verify that @xmath535 the rest is straightforward from the first part of the theorem applied to @xmath536 instead of @xmath24 , noting that for the standard gaussian distribution we have @xmath537 and @xmath111 .",
    "[ bd1 ] let @xmath538 be an arbitrary square matrix with complex entries .",
    "let @xmath539 be an entire function .",
    "define two associated entire functions @xmath143 and @xmath144 as @xmath540 and @xmath541 .",
    "then for each @xmath179 , we have @xmath542 this gives the bounds @xmath543 next , for each @xmath544 , let @xmath545 let @xmath546 be the @xmath299 matrix @xmath547",
    ". then @xmath548 .    for each @xmath370 ,",
    "let @xmath549 be the @xmath372 coordinate vector in @xmath468 , i.e.  the vector whose @xmath372 component is @xmath76 and the rest are zero . take any integer @xmath550 .",
    "a simple computation gives @xmath551 thus , @xmath552 the first inequality follows from this , since @xmath553 .",
    "next , recall that if @xmath26 is a square matrix and @xmath554 , then @xmath555 .",
    "this holds because @xmath556 where @xmath557 are the singular values of @xmath26 , whereas @xmath558 .",
    "thus , if we let @xmath559 , then @xmath560 this proves the first claim .",
    "next , fix some @xmath561 .",
    "another simple computation shows that @xmath562 now let @xmath563 and @xmath564 be arbitrary arrays of complex numbers such that @xmath565 . using the above expression , we get @xmath566 now , by lemma [ trivial ] , it follows that @xmath567 thus , @xmath568 since this holds for all @xmath569 such that @xmath570 , the proof is done .",
    "let all notation be as in the statement of the theorem .",
    "for any @xmath1 matrix @xmath26 , let @xmath571 .",
    "define the map @xmath572 as @xmath573 , that is , @xmath574 it is useful to recall the following basic fact for the subsequent computations : for any @xmath338 and any vector @xmath575 , @xmath576",
    "using this and the definition of @xmath139 we get @xmath577 now suppose @xmath143 is defined as in lemma [ bd1 ] . applying the second bound from lemma [ bd1 ] to the last term in the above expression",
    ", we get @xmath578 again note that for any @xmath579 , by lemma [ bd1 ] and the definition of @xmath138 , we have @xmath580 thus , @xmath581 next , note that @xmath582 thus , if @xmath38 denotes the hessian matrix of @xmath22 , then @xmath583 now , by the definition of @xmath584 and lemma [ bd1 ] , we have @xmath585 for the second term , note that by the definition of the operator norm and the identity , @xmath586 using the third bound from lemma [ bd1 ] and the definition of @xmath587 , we now get @xmath588 combining the bounds obtained in the last two steps , we have @xmath589 finally , since @xmath22 is defined on a real domain , therefore @xmath590 and @xmath591 .",
    "thus , @xmath592 and @xmath593 .",
    "the proof is now completed by using , , and to bound @xmath151 , @xmath150 , and @xmath152 in theorem [ poincare1 ] . the second part follows from the second part of theorem [ poincare1 ] .",
    "toeplitz determinants , fisher - hartwig symbols , and random matrices .",
    "_ recent perspectives in random matrix theory and number theory , _ 309336 , london math",
    "lecture note ser .",
    ", * 322 * , _ cambridge univ . press , cambridge_.                                                                                      a bound for the error in the normal approximation to the distribution of a sum of dependent random variables . _",
    "proc . of the sixth berkeley symp . on math .",
    "statist . and probab . ,",
    "ii : probability theory .",
    "_ 583602 ."
  ],
  "abstract_text": [
    "<S> linear statistics of eigenvalues in many familiar classes of random matrices are known to obey gaussian central limit theorems . </S>",
    "<S> the proofs of such results are usually rather difficult , involving hard computations specific to the model in question . in this article </S>",
    "<S> we attempt to formulate a unified technique for deriving such results via relatively soft arguments . in the process , we introduce a notion of ` second order poincar inequalities ' : just as ordinary poincar inequalities give variance bounds , second order poincar inequalities give central limit theorems . </S>",
    "<S> the proof of the main result employs stein s method of normal approximation . </S>",
    "<S> a number of examples are worked out , some of which are new . </S>",
    "<S> one of the new results is a clt for the spectrum of gaussian toeplitz matrices . </S>"
  ]
}