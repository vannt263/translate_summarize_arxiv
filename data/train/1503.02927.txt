{
  "article_text": [
    "unlike in point - to - point communication systems where the source - channel separation architecture is optimal @xcite , in multi - user systems , a separation - based architecture is usually suboptimal . in such scenarios ,",
    "hybrid schemes have emerged as a promising approach to gain performance improvement over either pure digital schemes ( separation - based schemes ) or pure analog schemes , e.g. , in @xcite for bandwidth - mismatch gaussian source broadcast ( see also @xcite for variants of this problem ) , and in @xcite for sending a bivariate gaussian source over a gaussian multiple access channel .",
    "recently , building upon the important work by bross _",
    "@xcite as well as @xcite and @xcite , tian _ et al . _",
    "@xcite showed that , for the problem of broadcasting a bivariate gaussian source , hybrid schemes are not only able to provide such performance improvement , they can in fact be optimal .",
    "in this paper , we consider the problem of sending two correlated vector gaussian sources over a bandwidth - matched two - user scalar gaussian broadcast channel , where each receiver wishes to reconstruct its target source under a covariance distortion constraint ( see fig .",
    "[ fig : system ] ) . this can be viewed as a vector generalization of the problem studied in @xcite .",
    "we derive a lower bound on the optimal tradeoff between the transmit power and the achievable reconstruction distortion pair .",
    "furthermore , it is shown that this lower bound is tight for the scenario , referred to as the vector - scalar case , where the weak receiver wishes to reconstruct a scalar source under the mean squared error distortion constraint .",
    "it is worth noting that the brute - force proof method in @xcite is difficult to generalize to the problem being considered .",
    "therefore , instead of seeking explicit upper and lower bounds and showing their tightness by direct comparison , we take a more conceptual approach in the present work . in particular ,",
    "the derivation of our lower bound is based on a new bounding technique which involves the introduction of appropriate remote sources ; moreover , to obtain a matching upper bound in the vector - scalar case , we construct a scheme with its parameters specified according to an optimization problem motivated by the lower bound .",
    "another finding is that the optimal scheme is in general not unique .",
    "indeed , we show that , in the vector - scalar case , the optimal tradeoff between the transmit power and the reconstruction distortion pair is achievable by a class of hybrid schemes , which includes the scheme proposed by tian _",
    "@xcite as an extremal example .    , width=359 ]",
    "let @xmath0 be an @xmath1 zero - mean random vector , @xmath2 .",
    "we assume that @xmath3 and @xmath4 are jointly gaussian with covariance matrix @xmath5 \\\\                                                  \\mathbb{e}[\\mathbf{s}_2\\mathbf{s}^t_1 ] & \\mathbf{\\sigma}_{\\mathbf{s}_2 } \\\\",
    "\\end{array }                                              \\right),\\end{aligned}\\ ] ] where @xmath6 $ ] , @xmath7 .",
    "let the broadcast channel additive noises @xmath8 and @xmath9 be two zero - mean gaussian random variables , jointly independent of @xmath10 , with variances @xmath11 and @xmath12 , respectively ; it is assumed that @xmath13 .",
    "let @xmath14 be i.i.d .",
    "copies of @xmath15 .",
    "an @xmath16 source - channel broadcast code consists of an encoding function @xmath17 and two decoding function @xmath18 , @xmath7 , such that @xmath19\\leq p,\\\\ & \\frac{1}{n}\\mathbb{e}[(\\mathbf{s}^n_i-\\hat{\\mathbf{s}}^n_i)(\\mathbf{s}^n_i-\\hat{\\mathbf{s}}^n_i)^t]\\preceq\\mathbf{d}_i,\\quad i=1,2,\\end{aligned}\\ ] ] where @xmath20 and @xmath21 , @xmath7 , with @xmath22 , @xmath7 .",
    "it is clear that the performance of any source - channel broadcast code depends on @xmath23 only through their marginal distributions .",
    "therefore , we shall assume the broadcast channel is physically degraded and write @xmath24 , where @xmath25 is a zero - mean gaussian random vector with i.i.d .",
    "entries of variance @xmath26 and is independent of @xmath27 .",
    "it is also clear ( * ? ? ?",
    "3.a ) that there is no loss of optimality in assuming @xmath28 $ ] , @xmath7 .",
    "we say @xmath29 is achievable if there exists an @xmath16 source - channel broadcast code .",
    "let @xmath30 denote the closure of the set of all achievable @xmath29 .",
    "let @xmath31 .    with the above definitions ,",
    "it is clear that the fundamental problem in this joint source - channel coding scenario is to determine the function @xmath32 , which characterizes the optimal tradeoff between the transmit power and the achievable reconstruction distortion pair is fixed , and the tradeoff between the reconstruction distortion pair is considered .",
    "we find the current formulation more suitable here , since both receivers are to reconstruct vector sources . ] . unless specified otherwise , we assume @xmath33 and @xmath34 , @xmath7 .    the remainder of this paper is organized as follows .",
    "we derive a lower bound on @xmath32 in section [ sec : lower ] .",
    "it is shown in section [ sec : upper ] that , for the vector - scalar case , this lower bound is achievable by a class of hybrid schemes .",
    "we conclude the paper in section [ sec : conclusion ] . throughout this paper ,",
    "the logarithm function is to base @xmath35 .",
    "let @xmath36 be an @xmath1 zero - mean random vector , @xmath2 .",
    "we assume that @xmath37 and @xmath38 are jointly gaussian with covariance matrix @xmath39 \\\\                                                  \\mathbb{e}[\\mathbf{u}_2\\mathbf{u}^t_1 ] & \\mathbf{\\sigma}_{\\mathbf{u}_2 } \\\\",
    "\\end{array }                                              \\right),\\end{aligned}\\ ] ] where @xmath40 $ ] , @xmath7 .    the main result of this section is the following theorem .    [ thm : lower ] @xmath41 with the infimum taken over @xmath42 matrix @xmath43 subject to the constraints",
    "@xmath44 here we assume that @xmath43 is partitioned to the form @xmath45 where @xmath46 is of size @xmath47 for @xmath7 .    _",
    "remark : _ it is interesting to note that the objective function on the right - hand side of ( [ eq : objective ] ) depends on @xmath48 only through @xmath49 .",
    "therefore , one can simply take the supremum in ( [ eq : objective ] ) over @xmath50 .",
    "_ remark : _ theorem [ thm : lower ] is in fact closely related to ( * ? ? ?",
    "* th . 1 ) .",
    "a detailed explanation of the connections between these two results can be found in @xcite .",
    "the following two elementary inequalities are needed for the proof of theorem [ thm : lower ] . for completeness",
    ", their proofs are given in appendices [ app : entropybound ] and [ app : condentropy ] .",
    "[ lem : entropybound ] for any @xmath51 random matrices @xmath52 and @xmath53 , @xmath54\\right|.\\end{aligned}\\ ] ]    [ lem : condentropy ] let @xmath55 be an @xmath56 zero - mean random matrix , @xmath7 . if @xmath57\\succ\\mathbf{0}$ ] , then @xmath58\\right|}{\\left|\\frac{2\\pi e}{n}\\mathbb{e}[\\mathbf{w}_2\\mathbf{w}^t_2]\\right|}.\\end{aligned}\\ ] ]    now we proceed to prove theorem [ thm : lower ] .    for any @xmath16 source - channel broadcast code , let @xmath28 $ ] , @xmath7 , and @xmath59 $ ] ; furthermore , let @xmath60 with @xmath61 $ ] , @xmath62 $ ] , and @xmath63 $ ] .",
    "note that @xmath43 satisfies ( [ eq : thetacont1 ] ) and ( [ eq : thetacont2 ] ) .",
    "therefore , it suffices to show that @xmath64 for all @xmath65 .",
    "let @xmath66 be i.i.d .",
    "copies of @xmath67 .",
    "we assume that @xmath68 is independent of @xmath69 .",
    "define @xmath70 , @xmath7 . here",
    "@xmath71 and @xmath72 can be understood as the remote sources that should be reconstructed , yet the encoder only has access to @xmath3 and @xmath4 .",
    "the introduction of @xmath73 is partly inspired by ozarow s converse argument for the gaussian multiple description problem @xcite ( see also @xcite ) .",
    "we shall first bound @xmath74 . in view of the fact that @xmath75 we have @xmath76 for some @xmath77 $ ] . on the other hand , @xmath78\\right|\\label{eq : entropybound}\\\\ & \\geq\\frac{n}{2}\\log|\\mathbf{\\sigma}_{\\mathbf{s}_2}+\\mathbf{\\sigma}_{\\mathbf{u}_2}|\\nonumber\\\\ & \\quad-\\frac{n}{2}\\log\\left|\\frac{1}{n}\\mathbb{e}[(\\mathbf{s}^n_2-\\hat{\\mathbf{s}}^n_2)(\\mathbf{s}^n_2-\\hat{\\mathbf{s}}^n_2)^t]+\\mathbf{\\sigma}_{\\mathbf{u}_2}\\right|\\nonumber\\\\ & \\geq\\frac{n}{2}\\log\\frac{|\\mathbf{\\sigma}_{\\mathbf{s}_2}+\\mathbf{\\sigma}_{\\mathbf{u}_2}|}{|\\mathbf{d}_2+\\mathbf{\\sigma}_{\\mathbf{u}_2}|},\\label{eq : comb1}\\end{aligned}\\ ] ] where ( [ eq : entropybound ] ) follows from lemma [ lem : entropybound ] . combining ( [ eq : comb2 ] ) and ( [ eq : comb1 ] ) gives @xmath79 now we proceed to bound @xmath80 .",
    "since @xmath81 , it follows from ( [ eq : comb2 ] ) that @xmath82 by the entropy power inequality , @xmath83 which , together with ( [ eq : imply ] ) , implies @xmath84 note that @xmath85 where ( [ eq : worstnoise ] ) is due to lemma [ lem : condentropy ] . on the other hand , @xmath86 where ( [ eq : entropybound2 ] ) follows from lemma [ lem : condentropy ] . combining ( [ eq : comb3 ] ) and",
    "( [ eq : comb4 ] ) yields @xmath87 one can readily obtain ( [ eq : proof1 ] ) from ( [ eq : main1 ] ) and ( [ eq : main2 ] ) by eliminating @xmath88 .",
    "this completes the proof of theorem [ thm : lower ] .",
    "this theorem leads us to the following ( potentially weakened ) lower bound on @xmath32 .",
    "somewhat surprisingly , this lower bound turns out to be tight in the vector - scalar case .",
    "[ cor : lowersimplified ] @xmath89    note that @xmath90 for any @xmath43 satisfying ( [ eq : thetacont1 ] ) and ( [ eq : thetacont2 ] ) , we have @xmath91 where ( [ eq : sub1 ] ) is due to the fact that @xmath92 for @xmath93 and @xmath94 , and the first inequality in ( [ eq : sub2 ] ) is a consequence of fischer s inequality . substituting ( [ eq : sub1 ] ) and ( [ eq : sub2 ] ) into ( [ eq : identity ] ) yields @xmath95 from which corollary [ cor : lowersimplified ] follows immediately .    it is also possible to derive this lower bound by taking a shortcut in the proof of theorem [ thm : lower ] .",
    "note that @xmath96 on the other hand , @xmath97 where ( [ eq : invokelem1 ] ) follows from lemma [ lem : entropybound ] . combining ( [ eq : tobecomb1 ] ) and ( [ eq : tobecomb2 ] ) yields @xmath98 which , together with ( [ eq : main1 ] ) , proves corollary [ cor : lowersimplified ] .    in order for the inequalities in ( [ eq : ineq1 ] ) and ( [ eq : ineq2 ] ) to become equalities , we need to have @xmath99 it will be seen that these two conditions provide important guidelines for constructing hybrid schemes that achieve the lower bound in corollary [ cor : lowersimplified ] .",
    "note that the derivation of this lower bound is based on a consideration of the scenario where @xmath72 is provided to the strong receiver by a genie .",
    "intuitively , a necessary condition for this lower bound to be tight is that the side information provided by the genie is superfluous , which is exactly the implication of ( [ eq : para2 ] ) .",
    "we shall show in this section that the lower bound in corollary [ cor : lowersimplified ] is tight for the vector - scalar case , i.e. , the scenario where the weak receiver wishes to reconstruct a scalar source ( i.e. , @xmath100 ) under the mean squared error distortion constraint . in this special setup , we denote @xmath101 by @xmath102 , respectively .",
    "[ thm : vectorscalar ] @xmath103      to the end of proving theorem [ thm : vectorscalar ] , it suffices to show that the right - hand side of ( [ eq : achievable ] ) is ( asymptotically ) achievable and consequently is an upper bound on @xmath104 .",
    "our achievability argument is based on a hybrid scheme , which bears some resemblance to the one proposed by puri _",
    "_ in a different setting @xcite ( see also @xcite ) .",
    "it will be seen that this hybrid scheme is semi - universal in the sense that the encoder only needs to know @xmath11 but not @xmath12 .",
    "let us first introduce a zero - mean random vector @xmath105 and a zero - mean random variable @xmath106 that are jointly gaussian .",
    "they are related with @xmath107 via a backward gaussian test channel @xmath108 , where @xmath109 is independent of @xmath110 .",
    "the covariance matrix of @xmath110 , parametrized by a scalar variable @xmath111 , is to be specified later .",
    "we assume that @xmath112 is independent of @xmath113 .",
    "note that we can write @xmath114+\\mathbf{w}_1\\\\ & = \\mathbf{a}_1\\mathbf{s}_1+\\mathbf{a}_2s_2+\\mathbf{a}_3s_2(\\gamma)+\\mathbf{w}_1,\\\\ s_2(\\gamma)&=\\mathbb{e}[s_2(\\gamma)|\\mathbf{s}_1,s_2]+w_2\\\\ & = \\mathbf{b}^t_1\\mathbf{s}_1+b_2s_2+w_2,\\end{aligned}\\ ] ] where @xmath115 is independent of @xmath116 , and @xmath117 is independent of @xmath107 .",
    "next define @xmath118        we are now in a position to describe the scheme ( see fig . [",
    "fig : hybrid1 ] ) .",
    "since the scheme is a combination of some well - known coding techniques , e.g. , wyner - ziv codes @xcite and dirty paper codes @xcite , we only provide an outline of the encoding and decoding steps , and then focus on the condition that guarantees correct decoding .    *",
    "encoding : * let the channel input @xmath119 , with average power @xmath120 , be a superposition of an analog signal @xmath121 and a digital signal @xmath122 ( i.e. , @xmath123 ) .",
    "the analog portion is given by @xmath124 for some non - negative number @xmath125 to be specified later .",
    "for the digital portion @xmath122 , the encoder first uses a wyner - ziv code of rate @xmath126 with codewords generated according to @xmath127 , with @xmath128 as the input , and with @xmath129 as the decoder side information ; the encoder then determines the digital portion of the channel input @xmath122 to send the bin index of the chosen wyner - ziv codeword @xmath130 by using a dirty paper code of rate @xmath126 with @xmath121 treated as the channel state information known at the encoder .",
    "we define @xmath131 $ ] and @xmath132 $ ] , where @xmath133 and @xmath134 are mutually independently zero - mean gaussian random variables , and @xmath135 .",
    "* decoding : * receiver 1 first decodes the dirty paper code ; it then further recovers @xmath130 by decoding the wyner - ziv code with @xmath136 as the side information . in view of the fact that the linear mmse estimate of @xmath3 based on @xmath127 and @xmath137 is @xmath138 , receiver 1 can use @xmath139 as the reconstruction of @xmath140 . since the linear mmse estimate of @xmath141 based on @xmath142 is @xmath143 with @xmath144(p(\\gamma)+n_2)^{-1}$ ]",
    ", receiver 2 can simply use @xmath145 as the reconstruction of @xmath146 , where @xmath147 ; the resulting distortion is denoted by @xmath148 .",
    "* coding parameters : * for a given covariance matrix of @xmath110 , three parameters @xmath125 , @xmath149 , and @xmath126 still need to be specified for the aforedescribed scheme .",
    "equivalently , we shall specify @xmath125 , @xmath120 , and @xmath126 , since @xmath125 determines @xmath150 and @xmath151 .",
    "let us first choose @xmath120 such that @xmath152 the parameter @xmath125 is then chosen such that @xmath153 which is always possible because @xmath154 and one can let @xmath155 take any value in @xmath156 $ ] by varying @xmath125 .",
    "finally set @xmath157 now the scheme is fully specified for any given covariance matrix of @xmath110 .    * conditions for correct decoding : * the wyner - ziv code and the dirty paper code need to be decoded correctly at receiver 1 .",
    "it is easily seen that the wyner - ziv code is ensured to be decoded correctly by ( [ eq : wzrate ] ) , and thus we focus on the decodability of dirty paper code . first note that ( [ eq : statisticequi ] ) , together with the fact that @xmath158",
    ", implies that @xmath159 ; moreover , since both @xmath160 and @xmath117 , which are gaussian random variables , are independent of @xmath107 , it follows that the joint distributions of @xmath161 and @xmath116 are identical , which , in view of the fact that @xmath115 is independent of @xmath162 , further implies that the joint distributions of @xmath163 and @xmath164 are identical>0 $ ] ( which implies that the @xmath150 and the @xmath125 determined by ( [ eq : statisticequi ] ) are positive ) . for the degenerate case @xmath165 ( which is possible if and only if @xmath166 ) , one can simply set @xmath167 and @xmath168 . ] .",
    "therefore , we have @xmath169 furthermore , note that @xmath170 which , together with ( [ eq : dprate ] ) , ensures that receiver 1 can correctly decode the dirty paper code .",
    "* optimizing the covariance matrix of @xmath110 : * now only the covariance matrix of @xmath110 remains to be specified . to this end",
    "we formulate the following maximization problem .",
    "it will become clear that this maximization problem is motivated by the lower bound in corollary [ cor : lowersimplified ] .",
    "in particular , it will be seen that the hybrid scheme and the remote sources induced by the optimal solution ( and the associated lagrangian multipliers ) of this maximization problem possess the desired properties ( see ( [ eq : para1 ] ) and ( [ eq : para2 ] ) ) .",
    "given @xmath171 , let @xmath172 denote the solution must be positive definite . since @xmath173 is strictly concave over the domain of positive definite matrices , it follows that @xmath172 is uniquely defined .",
    "] to @xmath174 where @xmath175 is the first @xmath176 diagonal submatrix of @xmath43 , and @xmath177 is the @xmath178 entry of @xmath43 . it can be shown ( see appendix [ app : theta ] ) that @xmath172 is a continuous function of @xmath111 .",
    "we denote the first @xmath176 diagonal submatrix of @xmath172 by @xmath179 , and the @xmath178 entry of @xmath172 by @xmath180 .",
    "now choose the covariance matrix of @xmath110 to be @xmath181 ; as a consequence , the covariance matrix of @xmath105 is @xmath182 , and the variance of @xmath106 is @xmath183 . accordingly ,",
    "( [ eqn : information ] ) reduces to @xmath184    * evaluating the distortions and the transmit power : * for the distortion at receiver 1 , it is readily seen that @xmath185\\nonumber\\\\ & = \\mathbb{e}[(\\mathbf{s}_1-\\mathbf{s}_1(\\gamma))(\\mathbf{s}_1-\\mathbf{s}_1(\\gamma))^t]\\label{eqn : equivalences1}\\\\ & = \\mathbf{\\theta}_{1}(\\gamma)\\nonumber\\\\ & \\preceq\\mathbf{d}_1,\\nonumber\\end{aligned}\\ ] ] where ( [ eqn : equivalences1 ] ) is true because the joint distributions of @xmath186 and @xmath187 are identical ( which is further due to the fact that the joint distributions of @xmath188 and @xmath189 are identical ) .",
    "it is worth noting that the linear mmse estimate of @xmath107 based on @xmath190 is @xmath191 . in view of this",
    "fact , receiver 1 can use @xmath192 as the reconstruction of @xmath128 .",
    "since the joint distributions of @xmath193 and @xmath112 are identical , we have @xmath194\\nonumber\\\\ & = \\mathbb{e}[(\\mathbf{s}^t_1-\\hat{\\mathbf{s}}^t_1(\\gamma),s^t_2-s^t_2(\\gamma))^t\\nonumber\\\\ & \\hspace{0.32in}(\\mathbf{s}^t_1-\\hat{\\mathbf{s}}^t_1(\\gamma),s^t_2-s^t_2(\\gamma))]\\nonumber\\\\ & = \\mathbf{\\theta}(\\gamma).\\label{eq : d2p}\\end{aligned}\\ ] ] therefore , @xmath111 can be interpreted as an auxiliary constraint on the reconstruction distortion for @xmath146 at receiver 1 , and @xmath172 is the actual covariance distortion achieved at receiver 1 for reconstructing @xmath128 .    note that @xmath120 is a continuous function of @xmath172 ( which is implied by ( [ eq : direct ] ) ) and consequently is a continuous function of @xmath111 for @xmath171 .",
    "moreover , it can be verified that @xmath195)^2]}\\nonumber\\\\ & = \\frac{1}{2}\\log\\frac{p(\\gamma)+n_2}{\\mathbb{e}[(y_1-\\mathbb{e}[y_1|s_2])^2]+n_2-n_1}\\nonumber\\\\ & = \\frac{1}{2}\\log(p(\\gamma)+n_2)-\\frac{1}{2}\\log\\left(\\frac{1}{2\\pi e}e^{2h(y_1|s_2)}+n_2-n_1\\right)\\nonumber\\\\ & = \\frac{1}{2}\\log(p(\\gamma)+n_2)\\nonumber\\\\ & \\quad-\\frac{1}{2}\\log\\left(\\frac{1}{2\\pi e}e^{2(h(y_1)-i(s_2;y_1))}+n_2-n_1\\right)\\nonumber\\\\ & = \\frac{1}{2}\\log(p(\\gamma)+n_2)\\nonumber\\\\ & \\quad-\\frac{1}{2}\\log\\left(\\frac{p(\\gamma)+n_1}{2\\pi e\\sigma^2_{s_2}}e^{2h(s_2|y_1)}+n_2-n_1\\right)\\nonumber\\\\ & = \\frac{1}{2}\\log(p(\\gamma)+n_2)\\nonumber\\\\ & \\quad-\\frac{1}{2}\\log\\left(\\frac{(p(\\gamma)+n_1)\\theta_2(\\gamma)}{\\sigma^2_{s_2}}+n_2-n_1\\right),\\label{eq : d2pderive}\\end{aligned}\\ ] ] where ( [ eq : d2pderive ] ) is due to the fact that @xmath196 ( which is implied by ( [ eq : d2p ] ) ) .",
    "hence , @xmath197 note that both @xmath120 and @xmath198 are continuous in @xmath111 ; furthermore , @xmath120 and @xmath198 tend to infinity and zero , respectively , as @xmath199 .",
    "therefore , @xmath148 is a continuous function of @xmath111 for @xmath171 , and @xmath148 tends to zero as @xmath200",
    ".    we shall show that @xmath201 for @xmath171 . to this end",
    "we revisit the maximization problem in ( [ eq : opt ] ) .",
    "note that @xmath172 must satisfy the following kkt conditions @xcite @xmath202 where @xmath203 , @xmath204 , @xmath205 , and @xmath206 .",
    "let @xmath207 be the eigenvalue decomposition of @xmath208 , where @xmath209 is a unitary matrix , and @xmath210 with @xmath211 , @xmath212 .",
    "define @xmath213 and @xmath214 .",
    "let @xmath215 be a positive semidefinite diagonal matrix obtained by subtracting @xmath216 from each positive diagonal entry of @xmath217 , where @xmath216 is an arbitrary positive number smaller than the minimum non - zero diagonal entry of @xmath217 .",
    "since @xmath218 , it follows that @xmath219 is positive definite .",
    "moreover , in view of ( [ eq : kkt1 ] ) , we have @xmath220 .",
    "therefore , @xmath221 is positive definite when @xmath216 is sufficiently small . for any @xmath216 with @xmath222 ,",
    "we choose a positive number @xmath223 , which is a function of @xmath216 and tends to zero as @xmath224 , such that @xmath225 where @xmath226 is a positive definite diagonal matrix obtained by adding @xmath223 to each zero diagonal entry of @xmath215 .",
    "now let @xmath227 and @xmath228 .",
    "note that @xmath229 therefore , @xmath230 is positive definite when @xmath216 is sufficiently small .",
    "let @xmath231 and @xmath232 be jointly gaussian with mean zero and covariance matrix @xmath230 , where @xmath231 is an @xmath233 gaussian random vector with covariance matrix @xmath234 ( which is the first @xmath176 diagonal submatrix of @xmath230 ) and @xmath232 is a gaussian random variable with variance @xmath235 ( which is the @xmath178 entry of @xmath230 ) .",
    "we assume that @xmath236 is independent of @xmath237 .",
    "note that @xmath238 where ( [ eq : usekkt1 ] ) and ( [ eq : usekkt3 ] ) are due to ( [ eq : kkt1 ] ) and ( [ eq : kkt3 ] ) , respectively .",
    "moreover , by the definition of @xmath230 , we have @xmath239    it is clear that @xmath240 where @xmath241)^2]$ ] . on the other hand , @xmath242 therefore , @xmath243 note that @xmath244 where ( [ eq : condind2 ] ) is due to ( [ eq : diag ] ) . on the other hand , @xmath245 where ( [ eq : condind ] ) is due to ( [ eq : diag ] ) . combining ( [ eq : combine2 ] ) and ( [ eq : tbj3 ] )",
    "gives @xmath246 which , together with ( [ eq : tobeused1 ] ) and ( [ eq : combine1 ] ) , implies that @xmath247 note that @xmath248 which further implies that @xmath249 is of the form @xmath250 , where @xmath251 denotes an @xmath252 all - zero matrix .",
    "also note that @xmath253 . therefore ,",
    "@xmath254 now one can readily prove ( [ eq : tobeproved ] ) by combining ( [ eq : pxi ] ) and ( [ eq : one ] ) .",
    "this completes the proof of theorem [ thm : vectorscalar ] for the case @xmath255 .    by restricting @xmath256 to the form @xmath257 and letting @xmath258",
    ", we can obtain the following lower bound from corollary [ cor : lowersimplified ] : @xmath259 note that if @xmath260 , then @xmath261 and @xmath262 ; moreover , in this case we have @xmath263 ( which implies that @xmath235 tends to infinity as @xmath224 ) , and consequently @xmath264 therefore , the lower bound in ( [ eq : separation ] ) is tight when @xmath265 , which completes the proof of theorem [ thm : vectorscalar ] .",
    "it is instructive to note that the role of @xmath266 and @xmath267 in the achievability argument is similar to that of @xmath74 and @xmath80 in the proof of corollary [ cor : lowersimplified ] .",
    "one can also readily see that ( [ eq : usekkt3 ] ) and ( [ eq : diag ] ) imply @xmath268 respectively .",
    "these two equations can be viewed as the counterparts of ( [ eq : para1 ] ) and ( [ eq : para2 ] ) .",
    "it is implicitly assumed in our construction that @xmath269 , @xmath270 , and @xmath271 .",
    "in fact , theorem [ thm : vectorscalar ] also holds in the degenerate case where the source covariance matrix and the distortions are not strictly positive definite , i.e. , we can relax the condition to @xmath272 ( which includes the case where @xmath141 is a linear function of @xmath3 ) , @xmath273 , and @xmath274 .",
    "it is straightforward to verify that corollary [ cor : lowersimplified ] is directly applicable in this setup .",
    "for the achievability part , one can leverage the construction for the non - degenerate case via a simple perturbation argument .",
    "the details are left to the interested reader .",
    "it turns out that in the vector - scalar case the hybrid scheme that achieves the optimal tradeoff between the transmit power and the reconstruction distortion pair is in general not unique .",
    "specifically , we shall show that if the optimal solution to ( [ eq : opt ] ) is of the form . in this case",
    "it follows by fischer s inequality that @xmath275 . ]",
    "@xmath276 , then there exists a class of hybrid schemes with the same performance as that in section [ subsec : upper ] .",
    "some additional notation needs to be introduced first .",
    "recall @xmath105 , @xmath106 , @xmath277 , and @xmath278 defined in section [ subsec : upper ] , and define @xmath279 $ ] .",
    "now write @xmath280 , where @xmath281 , @xmath282 , and @xmath283 are mutually independent zero - mean gaussian random variables with variances to be specified .",
    "furthermore , let @xmath284+\\delta_0 $ ] and @xmath285 .",
    "note that @xmath109 is independent of @xmath286 ; moreover , since @xmath276 , it follows that @xmath277 and @xmath278 are mutually independent .",
    "therefore , @xmath287 form a markov chain .",
    "note that @xmath288+\\bar{w}_0\\\\ & = \\bar{\\mathbf{a}}^t_1\\mathbf{s}_1+\\bar{a}_2s_2+\\bar{w}_0,\\\\ \\mathbf{s}_1(\\gamma)&=\\mathbb{e}[\\mathbf{s}_1(\\gamma)|\\mathbf{s}_1,s_0(\\gamma)]+\\bar{\\mathbf{w}}_1\\\\ & = \\bar{\\mathbf{b}}_1\\mathbf{s}_1+\\bar{\\mathbf{b}}_2s_0(\\gamma)+\\bar{\\mathbf{w}}_1,\\\\ s'_2(\\gamma)&=\\mathbb{e}[s'_2(\\gamma)|s_2,s_0(\\gamma)]+\\bar{w}_2\\\\ & = \\bar{c}_1s_2+\\bar{c}_2s_0(\\gamma)+\\bar{w}_2,\\end{aligned}\\ ] ] where @xmath289 is independent of @xmath107 , @xmath290 is independent of @xmath291 , and @xmath292 is independent of @xmath293 .",
    "we define @xmath294        we are now in a position to describe the scheme ( see fig .",
    "[ fig : hybrid2 ] ) .    *",
    "encoding : * let the channel input @xmath119 , with average power @xmath120 , be a superposition of an analog signal @xmath121 and two digital signals @xmath295 and @xmath296 ( i.e. , @xmath297 ) . the analog portion is given by @xmath298 for some non - negative number @xmath299 to be specified later .",
    "for the digital portion @xmath296 , the encoder first uses a wyner - ziv code of rate @xmath300 with codewords generated according to @xmath301 , with @xmath146 as the input , and with @xmath302 as the decoder side information ; the encoder then determines @xmath296 to send the bin index of the chosen wyner - ziv codeword @xmath303 by using a channel code of rate @xmath300 . for the digital portion @xmath295 ,",
    "the encoder first uses a wyner - ziv code of rate @xmath304 with codewords generated according to @xmath305 , with @xmath140 as the input , and with @xmath306 as the decoder side information ; the encoder then determines @xmath295 to send the bin index of the chosen wyner - ziv codeword @xmath307 by using a dirty paper code of rate @xmath304 with @xmath121 treated as the channel state information known at the encoder .",
    "we define @xmath131 $ ] and @xmath308 $ ] , @xmath7 , where @xmath309 , @xmath310 , @xmath311 are mutually independent zero - mean gaussian random variables , and @xmath312 .",
    "* decoding : * receiver 2 decodes the channel code @xmath296 , subtracts it from the channel output @xmath313 , and recovers @xmath314 by decoding the wyner - ziv code ( the one of rate @xmath300 ) with @xmath302 as the side information .",
    "furthermore , in view of the fact that the linear mmse estimate of @xmath141 based on @xmath315 is @xmath316 , where @xmath317 is an arbitrary solution to the following equation @xmath318 & \\mathbb{e}[\\bar{s}_2(\\gamma)x_a ] \\\\",
    "\\mathbb{e}[\\bar{s}_2(\\gamma)x_a ] & p_a+p_{d,1}+n_2 \\\\",
    "\\end{array }                 \\right)\\\\                 & = ( \\mathbb{e}[s_2\\bar{s}_2(\\gamma)],\\mathbb{e}[s_2x_a ] ) ,   \\end{aligned}\\ ] ] receiver 2 can use @xmath319 as the reconstruction of @xmath146 ; the resulting distortion is denoted by @xmath148 .",
    "receiver 1 also decodes the channel code @xmath296 and subtracts it from the channel output @xmath320 .",
    "then receiver 1 decodes the dirty paper code and recovers @xmath307 by decoding the wyner - ziv code ( the one of rate @xmath304 ) with @xmath306 as the side information .",
    "furthermore , in view of the fact that the linear mmse estimate of @xmath3 based on @xmath321 is @xmath322 , receiver 1 can use @xmath323 as the reconstruction of @xmath140 .    * coding parameters : * seven parameters @xmath324 $ ] , @xmath325 $ ] , @xmath299 , @xmath304 , @xmath300 , @xmath326 , and @xmath327 still need to specified .",
    "equivalently , we shall specify @xmath324 $ ] , @xmath325 $ ] , @xmath150 , @xmath304 , @xmath300 , @xmath120 , and @xmath327 .",
    "we again choose @xmath120 such that @xmath328 let @xmath329 be an arbitrary number in @xmath330 $ ] , where @xmath331 is determined by the following equation @xmath332 note that @xmath331 is nonnegative since @xmath333 now choose @xmath324 $ ] such that @xmath334 the existence of such @xmath324 $ ] is guaranteed by the fact that one can let @xmath335 take any value in @xmath336 $ ] ( i.e. , @xmath337 $ ] ) by varying @xmath324 $ ] .",
    "we then choose @xmath338 $ ] ( which further determines @xmath326 and @xmath299 ) such that @xmath339 which is always possible in view of ( [ eq : delta2 ] ) and the fact that one can let @xmath340 take any value in @xmath341 $ ] by varying @xmath150 .",
    "next we set @xmath342 we finally choose @xmath325 $ ] such that @xmath343 and set @xmath344    it is not immediately clear that our particular choice of @xmath325 $ ] always exists . to stress the dependence of @xmath345 on @xmath325 $ ] , we shall denote it by @xmath346)$ ] . note that ( [ eq : statisticequi2 ] ) , together with the fact that @xmath347 , implies that @xmath348 ; moreover , since both @xmath349 and @xmath289 , which are gaussian random variables , are independent of @xmath107 , it follows that the joint distributions of @xmath350 and @xmath351 are identical , which , in view of the fact that @xmath290 and @xmath292 are independent of @xmath352 , further implies that the joint distributions of @xmath353 and @xmath354 are identical>0 $ ] ( which implies that the @xmath150 and the @xmath299 determined by ( [ eq : statisticequi2 ] ) are positive ) . for the degenerate case @xmath355 ( which is possible if and only if @xmath356 ) , one can simply set @xmath167 and @xmath357 . ] .",
    "therefore , we have @xmath358)\\nonumber\\\\ & = i(x_a+x_{d,1}+z_2,s_2;\\bar{s}_2(\\gamma))\\nonumber\\\\ & \\quad - i(x_a+x_{d,1}+z_2;\\bar{s}_2(\\gamma))\\nonumber\\\\ & = i(s_2;\\bar{s}_2(\\gamma))-i(x_a+x_{d,1}+z_2;\\bar{s}_2(\\gamma))\\label{eq : duetomarkov}\\\\ & \\geq i(s_2;\\bar{s}_2(\\gamma))-i(x_a+x_{d,1}+z_1;\\bar{s}_2(\\gamma))\\nonumber\\\\ & = i(s_2;\\bar{s}_2(\\gamma))-i(s_0(\\gamma);\\bar{s}_2(\\gamma))\\nonumber\\\\ & = i(s_2;\\bar{s}_2(\\gamma)|s_0(\\gamma))\\nonumber\\\\ & = i(s_2;s'_2(\\gamma)|s_0(\\gamma)),\\nonumber\\end{aligned}\\ ] ] where ( [ eq : duetomarkov ] ) is due to the fact that @xmath359 form a markov chain . clearly , @xmath346)$ ] is a continuous function of @xmath325 $ ] .",
    "when @xmath325=0 $ ] , we have @xmath360 ( which implies @xmath361 ) and consequently @xmath362 ; when @xmath325=\\mathbb{e}[(\\delta)^2]-\\mathbb{e}[(\\delta_0)^2]$ ] , we have @xmath363 and consequently @xmath364-\\mathbb{e}[(\\delta_0)^2])\\geq i(s_2;s_2(\\gamma)|s_0(\\gamma))$ ] . note that @xmath365 where ( [ eq : useinfo ] ) and ( [ eq : usestat ] ) are due to ( [ eq : poweragain ] ) and ( [ eq : delta2 ] ) , respectively .",
    "this implies @xmath366 therefore , we have @xmath367-\\mathbb{e}[\\delta^2_0])&\\geq\\frac{1}{2}\\log\\frac{p(\\gamma)+n_1}{p_a+p_{d,1}+n_1}\\\\ & \\geq\\frac{1}{2}\\log\\frac{p(\\gamma)+n_2}{p_a+p_{d,1}+n_2}.\\end{aligned}\\ ] ] hence , our choice of @xmath368 $ ] indeed exists .    * conditions for correct decoding : * receiver 2 needs to decode the channel code and the corresponding wyner - ziv code of rate @xmath300 , and the correct decoding of these two components are guaranteed by ( [ eq : channelcode ] ) and ( [ eq : wz2 ] ) . since receiver 1 is stronger than receiver 2 , it can also decode the channel code and subtract it from the channel output .",
    "receiver 1 additionally needs to decode the dirty paper code and the corresponding wyner - ziv code of rate @xmath304 , the latter of which is guaranteed by ( [ eq : wz1 ] ) .",
    "recall that the joint distributions of @xmath353 and @xmath354 are identical .",
    "therefore , we have @xmath369 where ( [ eq : inserts2 ] ) follows by the fact that @xmath370 form a markov chain ( which is implied by the fact that @xmath371 form a markov chain ) , and ( [ eq : plugin ] ) is due to ( [ eq : delta2 ] ) and ( [ eq : statisticequi2 ] ) . thus indeed",
    "receiver 1 can decode the dirty paper code correctly .",
    "* optimality of this class of schemes : * since the joint distributions of @xmath186 and @xmath187 are identical ( which is due to the fact that the joint distributions of @xmath372 and @xmath373 are identical ) , it follows that the resulting distortion at receiver 1 is @xmath374 , which is the same as that achieved by the optimal scheme given in section [ subsec : upper ] .",
    "we next focus on the distortion achieved at receiver 2 .",
    "note that we have the freedom to choose @xmath329 from @xmath330 $ ] .",
    "in particular , one can recover the hybrid scheme in section [ subsec : upper ] by setting @xmath375 .",
    "we shall show ) does not depend on @xmath329 ] that the reconstruction distortion at receiver 2 ( i.e. , @xmath148 ) does not depend on @xmath329 ; as a consequence , this class of schemes have exactly the same performance , and can all achieve the optimal tradeoff between the transmit power and the reconstruction distortion pair .",
    "note that @xmath377)(\\mathbf{s}_1-\\mathbb{e}[\\mathbf{s}_1|s_2])^t]|}{|\\mathbf{\\theta}_1(\\gamma)|}\\nonumber\\\\ & = h(\\mathbf{s}_1|s_2)-h(\\mathbf{s}_1|\\mathbf{s}_1(\\gamma))\\nonumber\\\\ & = h(\\mathbf{s}_1|s_2)-h(\\mathbf{s}_1|s_2,s_0(\\gamma),\\mathbf{s}_1(\\gamma))\\label{eq : toexp1}\\\\ & = i(\\mathbf{s}_1;s_0(\\gamma),\\mathbf{s}_1(\\gamma)|s_2)\\nonumber\\\\ & = i(\\mathbf{s}_1;x_a+x_{d,1}+z_1,\\hat{\\mathbf{s}}_1(\\gamma)|s_2)\\label{eq : suff}\\\\ & = i(\\mathbf{s}_1;x_a+x_{d,1}+z_1,\\bar{\\mathbf{s}}_1(\\gamma)|s_2)\\nonumber\\\\ & = i(\\mathbf{s}_1;x_a+x_{d,1}+z_1|s_2)\\nonumber\\\\ & \\quad+i(\\mathbf{s}_1;\\bar{\\mathbf{s}}_1(\\gamma)|x_a+x_{d,1}+z_1)\\nonumber\\\\ & = i(\\mathbf{s}_1;x_a+x_{d,1}+z_1|s_2)+\\frac{1}{2}\\log\\frac{p_{d,1}+n_1}{n_1}\\label{eq : r1touse2}\\\\ & = \\frac{1}{2}\\log\\frac{\\mathbb{e}[(x_a-\\mathbb{e}[x_a|s_2])^2]+p_{d,1}+n_1}{p_{d,1}+n_1}\\nonumber\\\\ & \\quad+\\frac{1}{2}\\log\\frac{p_{d,1}+n_1}{n_1}\\nonumber\\\\ & = \\frac{1}{2}\\log\\frac{\\mathbb{e}[(x_a-\\mathbb{e}[x_a|s_2])^2]+p_{d,1}+n_1}{n_1},\\nonumber\\end{aligned}\\ ] ] where ( [ eq : toexp1 ] ) follows from the fact that @xmath378 form a markov chain , ( [ eq : suff ] ) follows from the fact that the joint distributions of @xmath379 and @xmath293 are identical , and ( [ eq : r1touse2 ] ) is due to ( [ eq : r1touse ] ) .",
    "therefore , @xmath380)^2]+p_{d,1}$ ] is not affected by the choice of @xmath329 .",
    "since @xmath381)^2]+p_{d,1}+n_2}\\nonumber\\\\ & \\quad+\\frac{1}{2}\\log\\frac{p(\\gamma)+n_2}{p_a+p_{d,1}+n_2}\\nonumber\\\\ & = \\frac{1}{2}\\log\\frac{p(\\gamma)+n_2}{\\mathbb{e}[(x_a-\\mathbb{e}[x_a|s_2])^2]+p_{d,1}+n_2},\\label{eq : diffentr}\\end{aligned}\\ ] ] where ( [ eq : r2 ] ) is due to ( [ eq : channelcode ] ) , it follows that @xmath148 does not depend on @xmath329 .    * a variant of this class of optimal schemes : * for each @xmath382 $ ] , the aforedescribed scheme has the following variant ( see fig .",
    "[ fig : hybrid3 ] ) . now for the digital portion @xmath296 , the encoder simply uses a lossy source code of rate @xmath383 with codewords generated according to @xmath301 and with @xmath146 as the input , and sets @xmath296 to be the output codeword @xmath303 multiplied by some non - negative number @xmath384 , where @xmath384 is chosen such that @xmath385=p(\\gamma)$ ] .",
    "the remaining part of the encoder is still the same .",
    "define @xmath386 , @xmath7 .",
    "note that @xmath387)^2]+p_{d,1}+n_2}\\label{eq : dist}\\\\ & = h(y_2)-h(y_2|s_2,\\bar{s}_2(\\gamma))\\nonumber\\\\ & = i(s_2,\\bar{s}_2(\\gamma);y_2)\\nonumber\\\\ & = i(\\bar{s}_2(\\gamma);y_2)+i(s_2;y_2|\\bar{s}_2(\\gamma))\\nonumber\\\\ & = i(\\bar{s}_2(\\gamma);y_2)+i(s_2;x_a+x_{d,1}+z_2|\\bar{s}_2(\\gamma)),\\nonumber\\end{aligned}\\ ] ] where ( [ eq : dist ] ) is due to ( [ eq : diffentr ] ) .",
    "this implies @xmath388 hence , receiver 2 can decode the lossy source code and recover @xmath303 .",
    "furthermore , receiver 2 can from @xmath303 and @xmath389 .",
    "] use @xmath390 as the reconstruction of @xmath146 , and the resulting distortion is @xmath148 .",
    "receiver 1 can also decode the lossy source code and obtain @xmath306 based on @xmath303 and @xmath391 .",
    "then receiver 1 decodes the dirty paper code and recovers @xmath307 by decoding the wyner - ziv code ( the one of rate @xmath304 ) with @xmath306 as the side information .",
    "moreover , receiver 1 can use @xmath392 as the reconstruction of @xmath140 , and the resulting distortion is @xmath374 .",
    "therefore , this scheme has exactly the same performance as the original one .",
    "it is worth mentioning that the scheme in @xcite can be viewed as an extremal case of this scheme with @xmath393 and @xmath394 .",
    "we have obtained a lower bound on the optimal tradeoff between the transmit power and the achievable distortion pair for the problem of sending correlated vector gaussian sources over a gaussian broadcast channel , where each receiver wishes to reconstruct its target source under a covariance distortion constraint .",
    "this lower bound is shown to be achievable by a class of hybrid schemes for the vector - scalar case , i.e. , the scenario where the weak receiver wishes to reconstruct a scalar source under the mean squared error distortion constraint . for certain classes of sources and distortion matrices ,",
    "it is possible to extend our hybrid schemes to obtain a characterization of the optimal power - distortion tradeoff for the case where the weak receiver also wishes to reconstruct a vector source .",
    "however , a complete solution for this general setup remains elusive .",
    "let @xmath395 and @xmath396 be the @xmath397-th columns of @xmath52 and @xmath53 , respectively , @xmath398 .",
    "note that @xmath399\\right|\\\\ & \\leq\\frac{n}{2}\\log\\left|\\frac{2\\pi e}{n}\\sum\\limits_{t=1}^n\\mathbb{e}[(\\mathbf{w}(t)-\\hat{\\mathbf{w}}(t))(\\mathbf{w}(t)-\\hat{\\mathbf{w}}(t))^t]\\right|\\\\ & = \\frac{n}{2}\\log\\left|\\frac{2\\pi e}{n}\\mathbb{e}[(\\mathbf{w}-\\hat{\\mathbf{w}})(\\mathbf{w}-\\hat{\\mathbf{w}})^t]\\right|,\\end{aligned}\\ ] ] which completes the proof of lemma [ lem : entropybound ] .",
    "let @xmath400 and @xmath401 be the @xmath397-th columns of @xmath115 and @xmath402 , respectively , @xmath398 .",
    "let @xmath403 be uniformly distributed over @xmath404 and independent of @xmath405 .",
    "we have @xmath406 it is easy to see that @xmath407\\\\ & = \\frac{1}{n}\\mathbb{e}[(\\mathbf{w}^t_1,\\mathbf{w}^t_2)^t(\\mathbf{w}^t_1,\\mathbf{w}^t_2)].\\end{aligned}\\ ] ] let @xmath408 be the linear mmse estimate of @xmath409 based on @xmath410 .",
    "note that @xmath411\\right|}{\\left|\\mathbb{e}[\\mathbf{w}_2(\\gamma)\\mathbf{w}^t_2(\\gamma)]\\right|}\\nonumber\\\\ & = \\frac{\\left|\\frac{1}{n}\\mathbb{e}[(\\mathbf{w}^t_1,\\mathbf{w}^t_2)^t(\\mathbf{w}^t_1,\\mathbf{w}^t_2)]\\right|}{\\left|\\frac{1}{n}\\mathbb{e}[\\mathbf{w}_2\\mathbf{w}^t_2]\\right|}.\\label{eq : covariancetbu}\\end{aligned}\\ ] ] now continuing from ( [ eq : continue ] ) , @xmath412\\right|}{\\left|\\frac{2\\pi e}{n}\\mathbb{e}[\\mathbf{w}_2\\mathbf{w}^t_2]\\right| } , \\label{eq : covariance}\\end{aligned}\\ ] ] where ( [ eq : covariance ] ) is due to ( [ eq : covariancetbu ] ) .",
    "this completes the proof of lemma [ lem : condentropy ] .",
    "if @xmath172 is not continuous at @xmath413 for some @xmath414 , then there exists a sequence @xmath415 with @xmath416 and @xmath417 as @xmath418 .",
    "clearly , @xmath419 satisfies the constraints for the maximization problem ( with @xmath413 ) in ( [ eq : opt ] ) .",
    "therefore , we must have @xmath420 .",
    "now let @xmath421 .",
    "note that @xmath422 satisfies the constraints for the maximization problem ( with @xmath423 ) in ( [ eq : opt ] ) when @xmath424 is sufficiently close to @xmath425 .",
    "therefore , @xmath426 on the other hand , it is clear that @xmath427 therefore , we must have @xmath428 , which , together with the uniqueness of @xmath429 , implies @xmath430 .",
    "this leads to a contradiction .",
    "v. m. prabhakaran , r. puri , and k. ramchandran ,  hybrid digital - analog codes for source - channel broadcast of gaussian sources over gaussian channels , \" _ ieee trans .",
    "inf . theory _ ,",
    "57 , no . 7 , pp .",
    "45734588 , jul .",
    "h. behroozi , f. alajaji , and t. linder ,  on the performance of hybrid digital - analog coding for broadcasting correlated gaussian sources , \" _ ieee trans .",
    "33353342 , dec . 2011 .",
    "y. gao and e. tuncel ,  separate source - channel coding for transmitting correlated gaussian sources over degraded broadcast channels , \" _ ieee trans .",
    "inf . theory _ ,",
    "59 , no . 6 , pp .",
    "36193634 , jun . 2013 .",
    "c. tian , s. diggavi , and s. shamai ( shitz ) ,  the achievable distortion region of sending a bivariate gaussian source on the gaussian broadcast channel , \" _ ieee trans .",
    "inf . theory _ ,",
    "57 , no .",
    "10 , pp .",
    "64196427 , oct .",
    "2011 .",
    "k. khezeli and j. chen ,  a source - channel separation theorem with application to the source broadcast problem , \" in _ proc .",
    "inform . theory ( isit ) _ , honolulu , hi , usa , jun./jul .",
    "2014 , pp . 21322136 .",
    "r. puri , k. ramchandran , and s. s. pradhan ,  on seamless digital upgrade of analog transmission systems using coding with side information , \" in _ proc .",
    "40th annu .",
    "allerton conf .",
    "commun . , control , comput .",
    "( allerton ) _ , monticello , il , oct .",
    "v. m. prabhakaran , r. puri , and k. ramchandran ,  colored gaussian source  channel broadcast for heterogeneous ( analog / digital ) receivers , \" _ ieee trans .",
    "inf . theory _ , vol .",
    "4 , pp . 1807-1814 , apr . 2008 ."
  ],
  "abstract_text": [
    "<S> the problem of sending two correlated vector gaussian sources over a bandwidth - matched two - user scalar gaussian broadcast channel is studied in this work , where each receiver wishes to reconstruct its target source under a covariance distortion constraint . </S>",
    "<S> we derive a lower bound on the optimal tradeoff between the transmit power and the achievable reconstruction distortion pair . </S>",
    "<S> our derivation is based on a new bounding technique which involves the introduction of appropriate remote sources . </S>",
    "<S> furthermore , it is shown that this lower bound is achievable by a class of hybrid schemes for the special case where the weak receiver wishes to reconstruct a scalar source under the mean squared error distortion constraint . </S>"
  ]
}