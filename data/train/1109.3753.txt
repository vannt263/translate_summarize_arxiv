{
  "article_text": [
    "the marinatto - weber ( mw ) idea of quantum @xmath0 games introduced in @xcite has found application in many branches of game theory .",
    "the mw approach to evolutionary games @xcite and stackelberg equilibrium @xcite are merely two of many applications . in the papers @xcite and @xcite",
    "we have shown that the mw idea is applicable as well to finite games in extensive form .",
    "consequently , this scheme of playing quantum games can be applied to many other game - theoretical problems . in this paper",
    "we deal with the problem of quantization of twice repeated @xmath0 games .",
    "since a finitely repeated game is just a  particular case of a finite extensive game , we apply the method based on @xcite and @xcite to play the repeated game in the quantum way .",
    "the idea of quantum repreated games was first introduced in @xcite , where the authors adapt the mw scheme for the twice repeated prisoner s dilemma .",
    "then , they investigate if results that are unavailable when the game is played classically can occur in the quantum area .",
    "the point of the paper @xcite is to provide sufficient conditions for players cooperation in the prisoner s dilemma game .",
    "we examine the idea of @xcite before we define our scheme .",
    "firstly , we study the problem of cooperation considered by the authors of and we prove that player s cooperation in the game defined by the protocol proposed in @xcite is not possible .",
    "secondly , we check whether that scheme is actually in accordance with the concept of repeated game . as we will show , the discussed scheme does not include the classical twice repeated prisoner s dilemma , hence it can not be the quantum realization of this game in the spirit of the mw approach . to support our arguments we propose the new protocol for a twice repeated @xmath1 game and prove that our idea generalizes the classical twice repeated game .",
    "our paper also contains the proof of the advantage of the quantum scheme over the classical one : we prove that both players can benefit from playing game via our protocol .",
    "moreover , we show that contrary to the situation encountered in the classical game , the cooperation of the players is possible for some sort of prisoner s dilemma games played repeatedly when our quantum approach is used .",
    "studying our paper requires little background in game theory .",
    "all notions like extensive game , information set , strategy , equilibrium , subgame perfect equilibrium etc . used in the paper are explained in an accessible way , for example , in @xcite and @xcite .",
    "the adequate preliminaries can also be found in the paper @xcite , where quantum games in an extensive form are examined .",
    "the prisoner s dilemma ( pd ) is one of the most fundamental problems in game theory ( the general form of the pd according to @xcite is given in fig .",
    "[ figure1](a ) .",
    "it demonstrates why the rationality of players can lead them to an inefficient outcome .",
    "although the payoff vector @xmath2 is better to both players than @xmath3 , they can not obtain this outcome since each player s strategy @xmath4 ( cooperation ) is strictly dominated by @xmath5 ( defection ) . as a result , the players end up with payoff @xmath6 corresponding to the unique nash equilibrium @xmath7 .",
    "a similar scenario occurs in a case of finitely repeated pd .",
    "the concept of a finitely repeated game assumes playing a static game ( a stage of the repeated game ) for a fixed number of times .",
    "additionally , the players are informed about results of consecutive stages . in the twice repeated case",
    "it means that each player s strategy specify an action at the first stage and four actions at the second stage where a particular action is chosen depending on what of the four outcomes of the first stage has occurred .",
    "it is clearly visible when we write twice repeated game in the extensive form ( see fig .",
    "[ figure2 ] ) .",
    "the first stage of the twice repeated pd in the extensive form is simply the game depicted in fig .",
    "[ figure1](b ) where the players specify an action @xmath4 or @xmath5 at the information set 1.1 and 2.1 , respectively ( the information sets of player 2 are distinguished by dotted line connecting the nodes to show lack of knowledge of the second player about the previous move of the first player ) .",
    "when the players choose their actions , the result of the first stage is announced .",
    "since they have knowledge about the results of the first stage , they can choose different actions at the second stage depending on the previous result , hence the next four game trees from fig .",
    "[ figure1 ] are required to describe the repeated game .",
    "the game tree exhibits ten information sets ( five for each player labelled @xmath8 and @xmath9 , respectively ) at which each of the players has two moves .",
    "thus , each of them has @xmath10 strategies as they specify @xmath4 or @xmath5 at their own five information sets .    to find the nash equilibrium in finitely repeated game it is convenient to use the property that the equilibrium profile always implies the nash equilibrium at the last stage of the game .",
    "therefore , to find the nash equilibrium in the twice repeated pd it is sufficient to consider strategy profiles that generate the profile @xmath7 at the second stage .",
    "then it follows that @xmath5 is the best response for players at the first stage as well . by induction",
    "it can be shown that playing the action @xmath5 at each stage of finitely repeated pd constitutes the unique nash equilibrium .",
    "it is worth noting that if a single stage of repeated game has more than one equilibrium , different nash equilibria may be played at the last stage depending on results of previous stages .",
    "for example , let us consider the battle of the sexes ( bos ) game given by the following bimatrix : @xmath11 , \\quad $ where$ \\quad \\alpha >",
    "\\beta > \\gamma .",
    "\\end{array}\\ ] ] it has two pure nash equilibria , namely , @xmath12 and @xmath13 . let us examine now the twice repeated bos . obviously , its game tree is the same as one in fig .",
    "[ figure2 ] .",
    "let us assign appropriate sum of two stage payoff outcomes to each possible profile ( like it has been done in the case of the twice repeated pd ) .",
    "then we find many different nash equilibria .",
    "one of these is to play the nash equilibrium @xmath12 at the first stage , keep playing @xmath12 at the second stage if the outcome of the first one is @xmath12 or @xmath14 , otherwise to play stage - game nash equilibrium @xmath13 .",
    "let us remind the mw approach to playing the pd repeatedly introduced in @xcite . according to this concept the two - stage pd",
    "is placed in @xmath15 complex hilbert space with the computational basis .",
    "the game starts with preparing 4-qubit pure state represented by a unit vector in @xmath16 .",
    "the general form of this state is described as follows : @xmath17 players moves are identified with the identity operator @xmath18 and the bit flip pauli operator @xmath19 .",
    "player 1 is allowed to act on the first and third qubit , and player 2 acts on the second and fourth one . in the first stage of the game",
    "the two first qubits are manipulated .",
    "let @xmath20 be the density operator for the initial state ( [ drinitialstate ] ) .",
    "then the state @xmath21 after the players actions takes the form @xmath22 where @xmath23 ( @xmath24 ) is the probability of applying @xmath25 ( @xmath26 to the first ( second ) qubit .",
    "next , the other two qubits are manipulated which , according to iqbal and toor , corresponds to the second stage of the classical game . the operation @xmath27 on the third qubit with probability @xmath28 and operation @xmath29 on the fourth qubit with probability @xmath30 change the state @xmath21 to @xmath31",
    "the next step is to measure the final state @xmath32 in order to determine final payoffs .",
    "the measurement is defined by the four payoffs operators @xmath33 , @xmath34 associated with particular : player @xmath35 and stage @xmath36 .",
    "that is @xmath37 then the expected payoff @xmath38 for player @xmath35 at stage @xmath36 when player 1 chooses strategy @xmath39 and player 2 chooses @xmath40 is obtained by the following formula : @xmath41    the authors took up the issue of cooperation in two - stage pd .",
    "given the initial state @xmath42 and fixed payoffs @xmath43 they identify @xmath18 and @xmath19 as actions of cooperation and defection , respectively , and claim that conditions @xmath44 are sufficient to choose @xmath18 by both players ( thereby cooperating ) at the first stage given that the players have chosen @xmath19 at the second one .",
    "we raise below two objections concerning the results of the paper @xcite .",
    "the main fault of the protocol ( [ drinitialstate])-([drpayoff ] ) is that the twice repeated game can not be described in this way .",
    "in fact , it quantizes the game pd played twice when the players are not informed about a result of the first stage .",
    "it is noticeable , for example , when we re - examine the way of finding the optimal solution provided in @xcite .",
    "the authors analyze the game backwards , first by focusing on the nash equilibria at the second stage .",
    "they set condition for the profile @xmath45 to be the nash equilibrium at the second stage .",
    "next , given that @xmath45 is fixed , they determine the set of amplitudes for which the profile @xmath46 is the nash equilibrium of the game implied by ( [ drinitialstate])-([drpayoff ] ) .",
    "this method to find the nash equilibria is not correct since it does nt include the possibility that players make their actions depending on a result of the first stage .",
    "although the problem seems to be insignificant where a stage of a repeated game has unique nash equilibrium , it becomes visible in remaining cases .",
    "let us consider the initial state ( [ initialstateiqbal ] ) satisfying the requirement @xmath47)-([drpayoff ] ) are as follows : @xmath48 where @xmath49 and @xmath50 .",
    "results of ( [ 2stage ] ) imply continuum of nash equilibria in the second stage ( it is easy to note , for example , when we draw a @xmath0 bimatrix with entries defined by ( [ 2stage ] ) ) , among them @xmath51 and @xmath52 . bearing in mind the remark in section [ sectiondwa ] about possible profiles in the bos game ,",
    "the correct protocol for quantum repeated games should be able to assign a payoff outcome ( by the measurement ( [ drpayoffoperator ] ) ) to a strategy profile , where different nash equilibria are played at the second stage depending on actions chosen at the first one .",
    "however , an example of a profile where the players play @xmath51 at the second stage if a result of the first stage is @xmath53 , and they play @xmath54 in other cases can not be measured by the scheme ( [ drinitialstate])-([drpayoff ] ) .",
    "since there is two qubit register allotted to the second stage , it allows to write only one pair of actions @xmath55 before the measurement is made .    an argument against the scheme in @xcite can be expressed in another way .",
    "namely , all results included in @xcite can be obtained by considering simplified protocol ( [ drinitialstate])-([drpayoff ] ) where the sequential procedure ( [ samoro ] ) and ( [ finalro ] ) for determining the final state @xmath32 is simply replaced with @xmath56 in this case , the first and the second player simultaneously pick @xmath57 and @xmath40 , respectively , having essentially only four strategies each . however , as we mentioned in the previous section , each player has 32 strategies in the classical twice repeated game . as a result ,",
    "the protocol ( [ drinitialstate])-([drpayoff ] ) can not coincide with the classical case if @xmath58 . despite the fact that the authors assume that a player knows her opponent s action taken previously",
    ", the scheme ( [ drinitialstate])-([drpayoff ] ) does not take it into consideration . in consequence ,",
    "a game being quantized by ( [ drinitialstate])-([drpayoff ] ) differs from the game in fig .",
    "[ figure2 ] in that the nodes 1.2 , 1.3 , 1.4 and 1.5 ( 2.2 , 2.3 , 2.4 and 2.5 ) lie at the same information set ( are connected with dotted line ) .      the another fault , we are going to discuss , is based on misinterpreting the operators @xmath18 and @xmath19 as cooperation and defection in the protocol given by ( [ drinitialstate])-([drpayoff ] ) .",
    "let us consider the initial state @xmath59 where the two first qubits associated with the first stage are prepared in the state @xmath60 , for @xmath61 .",
    "then the first stage of the game given by ( [ drinitialstate])-([drpayoff ] ) is isomorphic to the classical pd game .",
    "when the initial state is @xmath62 then @xmath18 corresponds to the action  @xmath4 and @xmath19 corresponds to @xmath5 .",
    "however , when the initial state is @xmath63 , the action ` cooperate ' are identified with @xmath19 and the action ` defect ' with @xmath18 since by putting @xmath64 into the formula ( [ drpayoff ] ) we have @xmath65 that is , the outcome of the game does not depend intrinsically on the operators but depends on the initial state and on what the final state @xmath32 can be obtained through the available operators .",
    "thus identification of operators with actions taken in classical game without taking into consideration the form of the initial state is not correct .",
    "the misidentification assumed in @xcite implies that the condition ( [ wrongcondition ] ) can not solve the problem formulated in this paper .",
    "it is clearly visible when we take , for example , the initial state @xmath66 .",
    "it satisfies the inequalities ( [ wrongcondition ] ) thus , @xmath18 is optimal at the first stage for each player . in fact , @xmath18 is the action ` defect ' as it is shown in ( [ prostyprzyklad ] ) .",
    "note also that the payoff corresponding to the profile @xmath67 at the first stage and @xmath68 at the second one is @xmath69 for each player - total payoff for the defection .",
    "thus , the condition ( [ wrongcondition ] ) does not ensure the cooperation at the first stage .",
    "quite the opposite , it turns out that the players never cooperate when they play the game defined by ( [ drinitialstate])-([drpayoff ] ) .",
    "let us consider any initial state ( [ drinitialstate ] ) in which the first and the second qubit are prepared in a way that for @xmath70 we have @xmath71 where the values @xmath72 meet the requirements of the pd given in fig.[figure1](a ) , so the operators @xmath18 and @xmath19 can be regarded as cooperation and defection , respectively .",
    "next , let us estimate the difference @xmath73 where @xmath74 .",
    "since the same actions are taken on the third and the fourth qubit , we have @xmath75 , therefore , the value @xmath76 depends only on @xmath77 , thus , for @xmath78 , we obtain from ( [ prostyprzyklad2 ] ) that @xmath79 in similar way we can prove that the strategy @xmath80 of player 1 is strictly dominated by @xmath81 . as a result , we conclude that @xmath82 is the best response of player 1 at the first stage .",
    "symmetry of payoffs in pd implies that strategy @xmath83 of player 2 is strictly dominated by @xmath84 , as well as @xmath85 is strictly dominated by @xmath86 .",
    "thus , there is no nash equilibrium in which the players choose @xmath18 ( cooperation ) at the first stage .",
    "in this section we propose a scheme of playing a twice repeated @xmath0 quantum game that is free from the faults we have pointed in the previous section .",
    "our construction is based on the protocol that we proposed in @xcite where general finite extensive quantum games were considered . since",
    "a repeated game is a special case of an extensive game , we can adapt this concept .",
    "next , we examine what results can be obtained from such protocol . in particular , we re - examine the problem of cooperation studied in @xcite .",
    "let us consider a @xmath1 game defined by the outcomes @xmath88 , @xmath89 .",
    "the twice repeated @xmath0 quantum game played according to the mw approach is as follows :    let @xmath90 be a hilbert space with the computational basis @xmath91 , @xmath92 .",
    "then the initial state of the game is a ten - qubit pure state represented by a  unit vector in the space @xmath16 : @xmath93 where the sum is over all possible decimal values of @xmath94 .",
    "the players are allowed to apply operators @xmath18 and @xmath19 .",
    "the qubits with odd indices are manipulated by player 1 and the qubits labelled by even indices are manipulated by player 2 .",
    "such assignment implies 32 possible strategies for each players as they specify five operations @xmath95 ( where @xmath36 and @xmath96 indicate qubit number and operation number , respectively ) on their own qubits .",
    "we denote a player @xmath35 s strategy by @xmath97 where @xmath98 .",
    "the profile @xmath99 gives rise to the final state : @xmath100 if the players each take @xmath101 and @xmath102 with probability @xmath103 and @xmath104 , respectively , that corresponds to the state @xmath105 ( defined by ( [ drpureinitialstate ] ) ) with probability @xmath106 , then the final state is the density operator associated with the ensemble @xmath107 .",
    "that is @xmath108 till now , a difference between the concept in @xcite and our protocol lies in the dimension of the space @xmath16 .",
    "the next difference is clearly visible in a description of measurement operators .",
    "the measurement on @xmath32 that determines an outcome of the game is described by a collection @xmath109 , where its components are defined as follows : @xmath110 then the expected outcomes : @xmath111 at the first stage and @xmath112 at the second stage are calculated by using the following formulae : @xmath113 let us give justification of our construction .",
    "notice that @xmath114 is a minimal dimension of the space @xmath16 in order to play the twice repeated @xmath0 game .",
    "since a player s strategy in a twice repeated @xmath0 game specifies action at the first stage and at each of four subgames fixed by the outcome of the first stage , the quantum protocol needs a five - qubit register to write a player s strategy .",
    "the first two qubits are used to perform operations at the first stage of the repeated game . then given",
    "the form of @xmath115 and strategies of players restricted to manipulate the first and the second qubit , in fact , the protocol ( [ drpsi])-([dreprotocol ] ) coincides with the mw scheme of playing @xmath1 quantum game @xcite .",
    "the remaining eight qubits are used to define players moves at the second stage .",
    "that is , by pairing consecutive qubits from the third qubit onwards , actions at the second stage are defined on appropriate pair of qubits depending on the outcome at the previous stage .",
    "for example , given the outcome @xmath116 has occurred at the first stage ( that is the outcome 10 on the first two qubits has been measured ) , the expected outcome @xmath112 depends only on operation on @xmath117 and @xmath118 , i.e , @xmath119 .",
    "then the players play the second stage in the same way as in the protocol ( [ drinitialstate])-([drpayoff ] ) .",
    "however , contrary to the previous idea , each player specifies her move for each possible outcome @xmath120 . + a game generated by our scheme naturally coincides with the classical case when appropriate initial state is prepared .",
    "we prove this fact by means of a convenient sequential approach to ( [ drpsi])-([dreprotocol ] ) provided in the next section .",
    "the protocol ( [ drpsi])-([dreprotocol ] ) allows to put a game into an extensive form by using a similar method to what was described in @xcite .",
    "the extensive form is obtained through sequential calculating the final state @xmath32 according to the following procedure . at first",
    "the players manipulate the first pair of qubits .",
    "then the measurement in the computational basis is made on these qubits ( as a result , an outcome @xmath88 of the first stage is returned ) .",
    "the measured outcome is sent to the players .",
    "depending on the measurement outcome @xmath121 that occurs with probability @xmath122 the players act on the next pair of qubits : if @xmath123 is observed then player 1 and player 2 manipulate qubits @xmath124 and @xmath125 , respectively , where @xmath126 is a decimal representation of a binary number @xmath127 .",
    "the procedure can be formally described as follows :    [ algorithmostatni ]    [ cols= \" < , < , < , < \" , ]     it turns out that we can prove    the density operator @xmath128 associated with state ( [ drpureinitialstate ] ) and the density operator for the ensemble @xmath129 in algorithm  [ algorithmostatni ] determine the same outcomes @xmath111 and @xmath112 with regard to the measurement ( [ drduzyiks])([drduzeiksy ] ) .",
    "let us put @xmath130 .",
    "given that @xmath131 the state @xmath132 can be written as : @xmath133 since the first and the second qubits are measured , any operation @xmath95 for which @xmath134 does not influence the measurement .",
    "therefore we have @xmath135 note that @xmath136 , where @xmath137 is the kronecker s delta , and @xmath138 , and @xmath139 , using the form ( [ drequality ] ) of @xmath132 we have @xmath140 for each @xmath141 the trace of each term of the sum on the right - hand side of equation ( [ drequation2 ] ) depends only on an operation @xmath95 on a qubit @xmath36 , where @xmath142 .",
    "thus , the equation ( [ drequation2 ] ) holds when also the rest of operations @xmath95 are added : @xmath143 as a result , the left - hand side of ( [ drequation3 ] ) is equal to the expected outcome @xmath112 associated with the final state @xmath144 . to prove that @xmath132 also determines the expected outcome @xmath111",
    "let us see that @xmath115 and @xmath145 are the same projective measurement up to the eigenvalues .",
    "hence @xmath146 since @xmath147 , we obtain @xmath148 equations ( [ drequation3 ] ) and ( [ drequation4 ] ) show that the state determined by the sequential procedure and state ( [ drpureinitialstate ] ) set the same outcomes @xmath111 and @xmath112 for @xmath98 . using the same way as above and the linearity of the trace",
    "it can be proved that the equivalence is true if the players pick nondegenerate mixed strategies as well .",
    "having a sequential approach that is in conformity with protocol ( [ drpsi])-([dreprotocol ] ) we are able to analyze a quantum repeated game through an extensive form .",
    "it can facilitate the work significantly bearing in mind @xmath149 bimatrix associated with the normal representation of twice repeated @xmath0 game .",
    "let us study the game tree drawn from the sequential procedure if the initial state ( [ drpsi ] ) takes the form @xmath150 let us use the sequential procedure step by step . at first",
    "the players manipulate @xmath25 and @xmath151 .",
    "hence we obtain the following state : @xmath152 is the negation of @xmath96 .",
    "a game tree at this phase is just the game tree corresponding to a  @xmath0 game ( see fig .",
    "[ figure1](b ) ) , where @xmath95 for @xmath153 , @xmath154 are associated with respective branches of that game tree . after a sequence of actions @xmath155 the measurement @xmath156 is made .",
    "let us focus on the cases when the measurement outcome 00 or 11 has been observed .",
    "the form of ( [ dr2state ] ) tells us that the measurement outcomes 00 and 11 are possible only if the profile at the first stage takes the form of @xmath157 , where @xmath158 .",
    "then , the probability @xmath159 ( @xmath160 ) that the measurement outcome 00 ( 11 ) will occur is equal to @xmath161 ( @xmath162 ) .",
    "thus , the game tree is extended to include random actions 00 and 11 with associated probabilities after the both histories @xmath163 .",
    "since further moves of the players depend only on the measurement , the pair of histories @xmath164 , @xmath165 and the pair @xmath166 , @xmath167 constitute two separate information sets . next ,",
    "given that 00 ( 11 ) has occurred , following the sequential procedure , the players manipulate third and fourth ( ninth and tenth ) qubit at the second stage .",
    "therefore another extensive form of @xmath0 is added to each sequence @xmath168 , where @xmath169 . in consequence",
    "we obtain a game tree shown in fig .",
    "[ figure3 ] ( a part of the game tree after histories of @xmath170 , @xmath158 is similar ) .    )",
    "-([dreprotocol ] ) when the initial state is on the form of ( [ drsplatany ] ) .",
    "]    each outcome associated with a terminal sequence are determined by a pure state from the ensemble given by the sequential procedure .",
    "for example , after sequence @xmath171 the post - measurement state takes the form of @xmath172 ( up to a global phase factor ) with probability @xmath173 , and the players choose sequence @xmath174",
    ". then the total outcome @xmath175 associated with a sequence @xmath176 is calculated according to formulae ( [ dreprotocol ] ) : @xmath177 the extensive approach allows us to see directly that our scheme coincides with the classical twice repeated @xmath0 game when @xmath178 . without loss of generality ,",
    "let the outcomes @xmath179 be the payoff outcomes corresponding to the pd game . then putting @xmath180 in ( [ drsplatany ] ) and assuming @xmath181 , @xmath182 the game in fig .",
    "[ figure3 ] depicts exactly the classical twice repeated pd game ( compare fig .",
    "[ figure2 ] and fig .",
    "[ figure3 ] ) .",
    "let us study the twice repeated pd game played with the use of our scheme .",
    "analysis of our protocol with the general form initial state ( [ drpsi ] ) is a laborious task and it deserves a separate paper to report about .",
    "nevertheless , we can derive many interesting features with less effort considering the initial state of the form @xmath183 let us consider first the problem of optimization of the equilibrium payoffs , given a  space of initial states as a domain .",
    "there are infinitely many settings of the initial state ( [ drpsi ] ) for which the twice repeated pd game played with the use of the protocol ( [ drpsi])-([dreprotocol ] ) has a unique subgame perfect equilibrium with the equilibrium payoff @xmath184 such that @xmath185 .",
    "[ drproposition ]    let us put the initial state ( [ drprostyinitialstate ] ) into the protocol ( [ drpsi])-([dreprotocol ] ) assuming that @xmath186 for any @xmath36 .",
    "then , the measurement @xmath145 on the first pair of qubits does affect others qubits .",
    "moreover , given that the outcome @xmath179 has occurred , the expected outcome @xmath112 depends only on manipulating on one pair of qubits @xmath187 due to the form of ( [ drduzeiksy ] ) .",
    "therefore , regardless of the first stage outcome @xmath179 , the players are faced with a  @xmath0 quantum game at the second stage ( played via the mw approach ) .",
    "that is , the players are faced with the problem @xmath188 where player 1 and 2 apply operators from the set @xmath189 on the first and the second qubit of @xmath187 , respectively .",
    "the outcome operator @xmath190 takes the form @xmath191 and the expected outcome is equal to @xmath192 obviously , the first stage game is also described exactly as the triple ( [ drpdmw ] ) . since",
    "a  quantum game according to the mw approach is a game expressed by a bimatrix , it leads us to the conclusion that protocol ( [ drpsi])-([dreprotocol ] ) with the initial state @xmath193 , in fact , can be treated as a twice repeated bimatrix game generated by ( [ drpdmw ] ) .",
    "let us substitute @xmath194 for the payoffs of the pd game in the game ( [ drpdmw ] ) and examine it towards uniqueness of nash equilibria .",
    "putting a state @xmath195 , for which the amplitudes of @xmath187 satisfy the condition : @xmath196 the inequalities @xmath197 are true for any @xmath198 . inequalities ( [ inequalities ] ) imply the unique nash equilibrium @xmath199 .",
    "moreover , the first inequality of condition ( [ drconditionend ] ) ensures that @xmath200 since the game constructed in the proof can be regarded as a classical twice repeated game , we are allowed to use all facts of classical repeated game theory .",
    "one of these tells us that a unique stage - game nash equilibrium implies , for any finite number of repetitions , a unique subgame perfect equilibrium in which the stage - game nash equilibrium is played in every stage .",
    "this completes the proof .",
    "of course , the protocol ( [ drpsi])-([dreprotocol ] ) can be re - formulated for any finitely repeated @xmath0 game and then statement analogical to proposition [ drproposition ] can be articulated .",
    "unfortunately , the number of qubits required in our protocol grows exponentially with number of stages .",
    "for example , in the case of a game repeated three times , the protocol ( [ drpsi])-([dreprotocol ] ) needs next 32 qubits to describe the third stage . in general , the number of @xmath201 qubits is required for a @xmath0 game repeated @xmath202 times .",
    "we shall re - examine now the problem of cooperation considered in @xcite .",
    "we demonstrated in section 3 that the cooperation at the first stage is not possible in the game defined by the iqbal and toor scheme .",
    "however , we also showed that this protocol does not take into consideration a player s move at the second stage as a function of the first stage result .",
    "therefore , in fact it does not allow to study the cooperation problem in a  proper way .",
    "the following example proves that the cooperation of players is possible if the twice repeated pd game is played via our scheme .",
    "[ drexample ]    example [ drexample ] shows that the cooperation of players is possible when the twice repeated pd game is played according to our scheme .",
    "unfortunately , the example does not solve this problem for any pd game .",
    "the condition @xmath203 imposed on the payoffs allows to select an arbitrary large finite number @xmath204 ( if a sufficiently small number @xmath205 is selected ) .",
    "we suppose that an appropriately large @xmath204 may convince the players to defect even if the game is played in quantum domain .",
    "our paper proves that repeated games can be quantized .",
    "that is , we have shown that appropriately modified the mw scheme for @xmath0 quantum games can indeed generalize a twice repeated game .",
    "in addition , such quantized game can be further analyzed by strategic as well as extensive form games .",
    "our results also indicate ( with the use of the twice repeated prisoner s dilemma ) that playing repeated games in the quantum domain can give superior results in comparison with the classical ones . at the same time",
    "we have answered why the previous approach can not be treated as a correct protocol for quantum repeated games .",
    "the main objection is that the protocol is unable to consider a full set of strategies available to players . in contrary to the iqbal and toor s scheme , the protocol defined in this paper is free from the mentioned fault .",
    "the author is very grateful to his supervisor prof .",
    "j. pykacz from the institute of mathematics , university of gdask , poland for his great help in putting this paper into its final form .",
    "100 l. marinatto and t. weber ( 2000 ) , _ a quantum approach to static games of complete information _ , phys .",
    "a , 272 , pp .",
    "291 - 303 .",
    "a. iqbal and a.h toor ( 2002 ) , _ quantum repeated games _ , phys .",
    "a , 300 , pp . 541 - 546 .",
    "a. iqbal and t. cheon ( 2008 ) , _ evolutionary stability in quantum games _ , chapter 13 in _ quantum aspects of life _ , edited by d. abbott , p. c. w. davies and a. k. pati , imperial college press .",
    "a. iqbal and a.h toor ( 2002 ) , _ backwards - induction outcome in a quantum game _ ,",
    "phys . rev .",
    "a , 65 , 052328 .",
    "p. frackiewicz ( 2011 ) , _ quantum approach to normal representation of extensive game _ , submitted to int .",
    "j. quantum inf .",
    ", arxiv:1107.3245v2 .",
    "p. frackiewicz ( 2011 ) , _ application of the eisert - wilkens - lewenstein quantum game scheme to decision problems with imperfect recall _ , j. phys .",
    "a : math . theor . ,",
    "44 , 325304 .",
    "osborne and a. rubinstein ( 1994 ) , _ a course in game theory _ , mit press , cambridge , ma . h. peters ( 2008 ) , _ game theory : a multi - leveled approach _ , springer - verlag , berlin .",
    "a. rapoport and a. chammah ( 1970 ) , _ prisoner s dilemma _ , university of michigan press ."
  ],
  "abstract_text": [
    "<S> we present a scheme for playing quantum repeated @xmath0 games based on the marinatto and weber s approach @xcite to quantum games . as a potential application , we study twice repeated prisoner s dilemma game . </S>",
    "<S> we show that results not available in classical game can be obtained when the game is played in the quantum way . </S>",
    "<S> before we present our idea , we comment on the previous scheme of playing quantum repeated games proposed in @xcite . </S>",
    "<S> we point out the drawbacks that make results in @xcite unacceptable . </S>",
    "<S> +    [ section ] [ section ] [ proposition]example [ proposition]algoritm </S>"
  ]
}