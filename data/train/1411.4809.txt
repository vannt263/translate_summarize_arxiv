{
  "article_text": [
    "consider the simple linear model @xmath8 where    1 .",
    "@xmath9 are known constants , supposed to be all distinct and increasingly ordered 2 .",
    "@xmath10 are mutually independent random variables with the same distribution function @xmath3 3 .",
    "@xmath11 and @xmath4 are unknown parameters .",
    "the usual estimators of @xmath11 and @xmath4 are those derived from the least squares method .",
    "as known , if the @xmath12 s have finite variance , such estimators possess some good properties .",
    "more specifically , they are unbiased and have minimum variance in the class of linear estimators ( blue ) .",
    "when , in addition , the @xmath12 s are assumed to be normal , the above estimators coincide with the ones obtained by the maximum likelihood method and , besides being unbiased , they have minimum variance in the class of all unbiased estimators ( mvue ) and they are normally distributed .",
    "consider then the least squares estimator of @xmath4 : @xmath13 as the corresponding estimate of @xmath4 strongly depends on the observed values @xmath14 the occurrence of outliers , that is of observations deviating from the main core of data , will likely influence such a procedure .",
    "this chance will often arise when the distribution of the disturbances @xmath12 has heavy tails , like in the case of the cauchy , the double - exponential and other distributions .",
    "it is quite a serious drawback of the estimator @xmath15 and attempts are occasionally made to remedy it by unconventionally deleting the most extreme observations .",
    "another completely different problem of least squares concerns the interval estimation of @xmath16 the possibility of producing a confidence interval for @xmath17 or equivalently of testing the hypothesis @xmath18 rests indeed on the assumption of normality for the variables @xmath12 s , so that , at least for limited values of @xmath19 the whole procedure proves to be fairly  unrobust \" when such an assumption is not met ( even if the asymptotic normality of @xmath15 is assumed ) .",
    "the asymptotic theory for such intervals can not be always invoked , besides , for such a theory rests on the asymptotic normality of @xmath15 which is not always ensured ( [ 1 ] ) .",
    "two distinct methods can be used to solve the first of the problems above : two distinct ways can be tried : one can decide to delete outliers or , alternatively , to base the estimation of @xmath4 on suitable functions of ranks , which are possibly unaffected by the extreme observations .",
    "common thinking is that the deletion of outliers must follow rules that are clearly stated before , and not after , data are available ; this task can not then rely on a subjective judgment , which will deprive the researcher of any foundation to study the related procedure .",
    "the papers by brown and mood ( [ 2 ] ) , adichie ( [ 3 ] ) , theil ( [ 4 ] ) and sen ( [ 5 ] ) are framed , instead , in the logic of ranks , which proved to be able to overcome both the drawbacks outlined above .    to introduce such kinds of procedures , notice that the estimator ( [ uno ] ) can be rewritten so that the slopes @xmath20 are explicitly shown . indeed",
    ", @xmath21 the above equality shows that @xmath15 can be regarded as a mean of the @xmath22 s with weights @xmath23 to solve the problem of outliers , one can then obviously substitute such a weighted mean with a suitable function of the slopes @xmath24 so as to result unaffected ( at least less affected ) by the extreme observations .",
    "this approach is substantially the one used by theil , who proposed , as an estimator of @xmath17 the median of the slopes @xmath22 , or the central value of the median interval when dealing with an even number of slopes .",
    "theil s procedure is related to the one by sen , who derived an estimator of @xmath4 by using a measure of concordance , which is essentially kendall s @xmath25 between the ranks of @xmath26 and those of @xmath27 @xmath28 the obtained estimator is the same proposed by theil , but it can be applied under the general assumption that the @xmath1 s are not all distinct .",
    "it is interesting to note that the same result can be obtained by starting from a completely different point of view , namely by using the minimax estimator with a non - quadratic loss function ( [ 6 ] ) .",
    "the study of the asymptotic properties of both the point and the interval estimators is due to sen as well , along with the determination of the asymptotic relative efficiency of the proposed estimator with respect to the one of least squares and to other estimators , proposed by adichie ( [ 3 ] ) , which were generalized , somehow under a more general framework , by koul ( [ 7 ] ) .",
    "to have an idea of the efficiency gained by the theil - sen estimator , @xmath29 with respect to that of least squares , @xmath30 it suffices to notice that there are cases where @xmath31 and that , even in the normal case , if the constants @xmath1 s are conveniently chosen , @xmath32    instead of measuring the concordance between the residuals @xmath26 and @xmath27 @xmath33 by means of @xmath34 or other indices , as later proposed ( [ 8 ] ) , one can obviously consider gini s cograduation index @xmath35 this procedure is quite different from the one proposed by adichie , who used a class of indices which are functions of the ranks of residuals @xmath26 and of the values @xmath27 while @xmath36 is based , as known , on the ranks of @xmath26 and on the _ ranks _ of @xmath27 @xmath37 in addition , the results gained using @xmath36 are likely to be structurally different from the ones obtained from @xmath34 or spearman s @xmath38 because @xmath36 is believed to locate some aspects of cograduation which neither @xmath34 nor @xmath39 can account for .",
    "this statement , in effect , is also confirmed by the fact that the correlation coefficient between @xmath36 and @xmath34 ( or between @xmath36 and @xmath39 ) , as shown in ( [ 9 ] ) and in ( [ 10 ] ) , even though quite large for a limited value of @xmath40 ( in absence of cograduation ) , never reaches one , not even asymptotically .",
    "let @xmath41 be a realization of @xmath42 @xmath43 be gini s cograduation index computed from the residuals @xmath44 and @xmath27 @xmath33 and @xmath45 be the function of data obtained by making @xmath46 as close to zero as possible .",
    "is actually a non increasing step function ; hence the stated condition does not imply that @xmath7 is a root of the equation @xmath47 which might not admit any root . ]",
    "@xmath48 can then be regarded as a minimum @xmath49dependence estimate or , more correctly , as a maximum @xmath49indifference estimate of @xmath16 the same notation can be used for the estimator @xmath50 this terminology is coherent with the term `` indifference '' proposed by gini ( [ 11 ] , p. 330 ) to indicate the lack of concordance or discordance between two rankings , in comparison with the term  ( stochastic ) independence \" which should instead be used to indicate lack of connection .",
    "indeed , the two conditions ( independence and indifference ) are not equivalent , though w. hoeffding ( [ 12 ] , p. 555 ) showed that , under suitable assumptions , they imply each other .",
    "this paper aims at proposing the estimator @xmath7 and at analyzing its properties . in section 2",
    ", the main problem is framed and the stochastic process @xmath51 whose properties are studied in section 3 , is introduced . in section 4 the estimator @xmath7 is formally defined and some properties of its distribution are analyzed . in section 5 the task of building a confidence interval for @xmath4 is faced , for every sample size and independently of the distribution function of disturbances , @xmath52 which will be exclusively assumed to be continuous . as the proposed estimator does not possess a closed form as a function of data , section 6 gives some hints to fasten its computation for a given sample realization .",
    "section 7 deals with the asymptotic distribution of @xmath53 such distribution is closely related to the one of @xmath54 whose analysis is rather long and hence is developed in the appendix , to simplify the structure of the paper .",
    "finally , section 8 focuses on the comparison , based on the asymptotic relative efficiency ( are ) , of the estimator @xmath7 with the one of least squares and the one by theil and sen .",
    "the drawn conclusions are quite interesting , as the asymptotic efficiency of @xmath55 relative to the other two estimators is shown to be ( for the chosen values of the @xmath1 s ) greater than 1 when the distribution has tails heavier than the normal case ; this fact recommends a wide use of @xmath7 , even if its computation might seem somehow unpractical .",
    "let @xmath56 be @xmath40 mutually independent random variables with distribution functions @xmath57 where @xmath3 is any continuous distribution function and @xmath58 are known constants . as the main interest is the estimation of @xmath17 in the following @xmath59",
    "will be supposed , without loss of generality .    for every real @xmath60",
    "consider the new variables @xmath61 and use them to build the function ( of @xmath62 ) @xmath63 with @xmath64 where @xmath65 denotes the rank of @xmath66 in the sorting of @xmath67 and @xmath68 if @xmath40 is even or @xmath69 if @xmath40 is odd .",
    "the function @xmath54 is not defined in the set @xmath70 which is clearly finite . for every chosen @xmath71 the function ( [ due ] )",
    "is the known gini s cograduation index between @xmath72 and @xmath73 conversely , as a function of @xmath60 it is a stochastic process whose realizations correspond to the events @xmath74    as the random variables @xmath75 @xmath76 are iid , @xmath77 has the known distribution of gini s index in case of indifference and hence @xmath78 one can then naturally estimate the parameter @xmath4 by making @xmath54 as close to zero as possible , that is by letting @xmath79 equivalently , the estimator proposed in this paper is a function @xmath80 so that the sequence @xmath81 will result as indifferent as possible to @xmath27 @xmath82 in effect , this is a natural requirement when considering that the least squares estimator can be regarded as a function @xmath83 which makes the usual sample covariance between @xmath84 and @xmath1 @xmath85 vanish .",
    "such a covariance plays then , in another framework , the same role of @xmath86    of course , to implement the proposed procedure one must be sure that the obtained estimator is , in some sense , unique",
    ". this could be the case if the realizations of the process @xmath54 resulted strictly monotonic functions of @xmath87 in the following section , such realizations are shown to be non increasing functions of @xmath87 this fact implies that a whole interval of values of @xmath62 may exist where @xmath88 or , alternatively , two consecutive intervals @xmath89 and @xmath90 so that @xmath91",
    "as claimed in the previous section , @xmath54 is not defined for every real @xmath92 more specifically , if @xmath93 is a realization of @xmath42 @xmath46 turns out to be undefined in the set @xmath94 which will be referred to , in the following , as @xmath95    for any @xmath96tuple",
    "@xmath97 the function @xmath46 is constant inside each interval @xmath98 to prove such a claim , it suffices to show that , inside each of the intervals above , @xmath99 is the same permutation of the set of integers @xmath100 @xmath101    let @xmath102 @xmath103 there are at least two couples of indices @xmath104 and @xmath105 with @xmath106 @xmath107 such that @xmath108 this fact implies that , for every @xmath62 belonging to the interval @xmath109 @xmath110 the former of the above inequalities holds equivalently for every couple whose slope is less than or equal to @xmath111 ; the latter inequality holds for those couples whose slope is greater than or equal to @xmath112 this remark shows that , for every @xmath62 belonging to the considered interval , the permutation taken by @xmath113 @xmath114 does not change , which suffices to state that @xmath46 does not change its value .",
    "the same conclusions can be drawn when considering the first and the last intervals for @xmath87 specifically , as @xmath115 one gets @xmath116    obviously the definition of @xmath54 can be supplemented by setting @xmath117 so as to let every realization of the process be right continuous . in the following",
    ", @xmath54 will be supposed to be defined for every real @xmath87    consider now two adjacent intervals @xmath118 and @xmath119 @xmath120 and let @xmath121 @xmath122 when shifting from @xmath62 to @xmath123 the above discussion shows that the ranks of @xmath66 will be only partially modified .",
    "specifically , suppose that @xmath124 with @xmath125 which means that the observations @xmath126 lie on the same straight line .",
    "when shifting from @xmath62 to @xmath123 only the ranks of @xmath127 will be modified , that is @xmath128 furthermore @xmath129 the above equalities derive immediately after considering that the rank of the generic @xmath130 equals the number of observations @xmath131 which lie under or on the straight line with slope @xmath62 passing through @xmath132    if @xmath133 @xmath134 then @xmath135    consider the functions @xmath136 and define @xmath137 } \\left ( \\phi_i(\\xi ) + \\phi_{m - i } ( \\xi ) \\right).\\ ] ] for every @xmath138,$ ] one gets @xmath139 hence @xmath140 from which the proof follows .",
    "@xmath141    the following theorem can now be stated .    for every @xmath96tuple @xmath97",
    "the function @xmath46 is non increasing .",
    "it suffices to prove that the function @xmath142 is non decreasing and that the function @xmath143 is non increasing .",
    "only the statement for @xmath144 will be proved ; the one for @xmath145 follows similarly .",
    "suppose that @xmath146 @xmath147 with @xmath148 @xmath149 @xmath150 and @xmath151 when shifting from @xmath62 to @xmath123 only the ranks of @xmath152 will change ; hence @xmath153 by ( [ tre ] ) and ( [ quattro ] ) , @xmath154 according to the lemma stated above , the quantity in brackets is non negative for every value of @xmath155 and hence @xmath156 which holds for all intervals and thus gives the proof .",
    "section 3 showed that all trajectories of the stochastic process @xmath54 are non increasing functions of @xmath62 and that @xmath157 for any observed @xmath96tuple @xmath97 the following two cases will then arise :    * a whole interval of @xmath62 exists where @xmath158 pointwise * two adjacent intervals exist such that @xmath159    when in case a ) , one could choose the central value of the interval as an estimate of @xmath160 in case b ) , the value @xmath161 could instead be chosen .",
    "the two cases can then be unified by defining the following maximum @xmath49indifference estimator : @xmath162\\ ] ] which is similar to the estimator proposed in ( [ 13 ] ) for the location parameter .",
    "one of the following sections will show how to get a fast computation of @xmath163 first of all , the next propositions will give three quite immediate properties of the distribution of @xmath53    the distribution of @xmath164 does not depend on the parameter @xmath16    let @xmath165 from the definition of @xmath51 @xmath166 similarly , if @xmath167 one gets @xmath168 and , by definition ( [ cinque ] ) , @xmath169 however , the lhs of the above equality is a function of the variables @xmath170 whose distributions , by hypothesis , do not depend on @xmath16 @xmath141    proposition 1 equivalently states that , if @xmath171 then @xmath172 namely @xmath4 is a location parameter of the distribution of @xmath53 this fact will allows setting @xmath173 in the following , without loss of generality .",
    "@xmath7 has a continuous distribution .",
    "it suffices to prove that the two variables @xmath174 are both continuous .",
    "the continuity of @xmath175 and @xmath176 indeed , implies that the joint distribution of @xmath177 is continuous and similarly for @xmath178    as every realizations of @xmath54 is non - increasing with at least a jump at a point of the form @xmath179 @xmath180 the event @xmath181 implies that @xmath54 has a jump at @xmath182 hence @xmath183 as , by hypothesis , the variables @xmath184 s are continuous ( and independent ) , the same is true for the variables @xmath185 hence @xmath186 similarly , one can show that @xmath187 @xmath141    notice that , by following the same steps as for the proof of proposition 2 , a similar result can be obtained for the variables @xmath188 where @xmath189 is a given constant .    before stating another property concerning the distribution of @xmath190 the following equality should be considered : @xmath191 indeed , @xmath192 \\right| - \\sum_i \\left|",
    "i - r[-(y_i - b\\ , x_i ) ] \\right| \\right\\ }   \\end{aligned}\\ ] ] from which the above result follows , as it is obviously @xmath193 = n+1 -   r(y_i - b\\ , x_i).\\ ] ]    if @xmath194 are symmetrically distributed , @xmath195",
    "according to proposition 1 , it can be assumed that @xmath196 now notice that @xmath197 indeed , @xmath198\\ ] ] and , by ( [ sei ] ) , @xmath199 = \\\\   & = \\frac 12 \\left [ -\\inf \\left\\ { b : \\ , g(\\underline y;b ) < 0 \\right\\ } -    \\sup \\left\\ { b : \\ , g(\\underline y;b ) > 0 \\right\\ } \\right ] = \\\\   & = -\\tilde{\\beta } ( \\underline y )   \\end{aligned}\\ ] ] by the symmetry of @xmath200 the variables @xmath201 and @xmath202 share the same distribution . by using ( [ sette ] ) and",
    "this latter property , one can then claim that @xmath201 has a distribution symmetric around zero ( which is the value of @xmath4 ) ; this fact completes the proof .",
    "as the variables @xmath203 @xmath204 are iid , @xmath205 has the known distribution of gini s cograduation index under indifference .",
    "there exist quite complete tables of such a distribution . by using these tables , a constant @xmath189 such that , for a suitable @xmath206 @xmath207 can be easily determined .",
    "consider now the variables @xmath208 from ( [ otto ] ) , as @xmath46 is non increasing , @xmath209 similarly , from ( [ nove ] ) , @xmath210 it follows that @xmath211 hence , from ( [ dieci ] ) , @xmath212 and , by the continuity of @xmath213 and @xmath214 @xmath215 the variables ( [ otto ] ) and ( [ nove ] ) are then respectively the lower and the upper bounds of the confidence interval for @xmath17 for any continuous distribution function @xmath216",
    "in the previous sections , the point estimator for @xmath4 and the bounds of the confidence interval for the same parameter were defined . however",
    ", a closed expression for such statistics as functions of the elements of the sample , was not provided .",
    "this fact makes it difficult to study further properties of the considered statistics for a finite value of @xmath217 the following section will then deal with the asymptotic distribution of @xmath53 before doing that , this section aims at providing an easy scheme to determine the values taken by @xmath190 @xmath213 and @xmath218 for any given sample realization .",
    "let @xmath219 denote the observations on the response variable corresponding to @xmath220 and suppose computing the @xmath221 slopes @xmath222 @xmath223 which are not necessarily all distinct . denote with @xmath224 the distinct sorted values of such slopes , @xmath225 of course the same slope can correspond to more than a couple of indices @xmath226 with the aid of equality ( [ tre ] ) in section 3 , one can then produce a table displaying , for each row @xmath33 the ranks of @xmath227 when @xmath62 belongs to the possible intervals determined by the slopes @xmath228 to illustrate the construction of such a table , suppose that the observed values are @xmath229 the six possible slopes are @xmath230 so that the sorted distinct slopes are @xmath231 a table with @xmath232 rows can now be produced as follows .",
    "first of all a vertical line is built for every slope @xmath224 and , on this line , the @xmath233th row is marked with a circle and the @xmath234th row is marked with a square . for every @xmath235th row , one can then put suitable integer values , starting from @xmath236 by adding a unit if a circle is met and by subtracting a unit if a square is met .",
    "if more than a single circle or square is met , the number in the previous column will be simply increased by the number of circles and decreased by the number of squares . as an example , on the third row , when passing from the second to the third column , a circle and a square are met ; the number on the second column ( 3 ) should then be increased by 1 and decreased by 1 , so that the same value ( 3 ) is reported in the third column .",
    "( 8,8)(0,0 ) ( 1,4.1)(1,0)5(1,5.1)(1,0)5 ( 1,6.1)(1,0)5 ( 1,7.1)(1,0)5 ( 2,3.5)(0,1)4.5(3,3.5)(0,1)4.5 ( 4,3.5)(0,1)4.5 ( 5,3.5)(0,1)4.5 ( 0.5,4)4(0.5,5)3 ( 0.5,6)2 ( 0.5,7)1 ( 6.5,4.5)@xmath237(6.5,5.5)@xmath238 ( 6.5,6.5)@xmath239 ( 6.5,7.5)@xmath240 ( 1.5,4.5)4(1.5,5.5)3 ( 1.5,6.5)2 ( 1.5,7.5)1 ( 2.5,4.5)4 ( 2.5,5.5)3 ( 2.5,6.5)1 ( 2.5,7.5)2 ( 3.5,4.5)2 ( 3.5,5.5)3 ( 3.5,6.5)1 ( 3.5,7.5)4 ( 4.5,4.5)1 ( 4.5,5.5)3 ( 4.5,6.5)2 ( 4.5,7.5)4 ( 5.5,4.5)1 ( 5.5,5.5)2 ( 5.5,6.5)3 ( 5.5,7.5)4 ( 1.5,3)@xmath241(2.5,2.6)@xmath242 ( 3.5,3)@xmath243 ( 4.5,3)@xmath244 ( 2,7.1)(3,7.1 ) ( 3,7.1 ) ( 4,6.1 ) ( 5,6.1 ) ( 3,5.1 ) ( 1.9,6.0)(0.2,0.2 ) ( 2.9,5.0)(0.2,0.2 ) ( 4.9,5.0)(0.2,0.2 ) ( 2.9,4.0)(0.2,0.2 ) ( 2.825,3.925)(0.35,0.35 ) ( 3.9,4.0)(0.2,0.2 )    the figures on the @xmath235th row of the above table are the ranks of @xmath245 as long as @xmath62 ranges in the intervals @xmath246",
    "@xmath247 @xmath248 @xmath249 @xmath250 for example , @xmath251 after the above table , two further tables can be produced by computing , for the @xmath233th row , the quantities @xmath252 one then gets    ( 12,3.5)(0,0 ) ( 1,0.7)(1,0)5(1,1.4)(1,0)5 ( 1,2.1)(1,0)5 ( 1,2.8)(1,0)5 ( 2,0)(0,1)3.5(3,0)(0,1)3.5 ( 4,0)(0,1)3.5 ( 5,0)(0,1)3.5 ( 1.5,0.2)*8 * ( 1.5,0.9)3 ( 1.5,1.6)1 ( 1.5,2.3)1 ( 1.5,3.0)3 ( 2.5,0.2)*8 * ( 2.5,0.9)3 ( 2.5,1.6)1 ( 2.5,2.3)2 ( 2.5,3.0)2 ( 3.5,0.2)*4 * ( 3.5,0.9)1 ( 3.5,1.6)1 ( 3.5,2.3)2 ( 3.5,3.0)0 ( 4.5,0.2)*2 * ( 4.5,0.9)0 ( 4.5,1.6)1 ( 4.5,2.3)1 ( 4.5,3.0)0 ( 5.5,0.2)*0 * ( 5.5,0.9)0 ( 5.5,1.6)0 ( 5.5,2.3)0 ( 5.5,3.0)0 ( 0.5,0.2)*tot . * ( 7,0.7)(1,0)5(7,1.4)(1,0)5 ( 7,2.1)(1,0)5 ( 7,2.8)(1,0)5 ( 8,0)(0,1)3.5(9,0)(0,1)3.5 ( 10,0)(0,1)3.5 ( 11,0)(0,1)3.5 ( 7.5,0.2)*0 * ( 7.5,0.9)0 ( 7.5,1.6)0 ( 7.5,2.3)0 ( 7.5,3.0)0 ( 8.5,0.2)*2 * ( 8.5,0.9)0 ( 8.5,1.6)0 ( 8.5,2.3)1 ( 8.5,3.0)1 ( 9.5,0.2)*6 * ( 9.5,0.9)2 ( 9.5,1.6)0 ( 9.5,2.3)1 ( 9.5,3.0)3 ( 10.5,0.2)*6 * ( 10.5,0.9)3 ( 10.5,1.6)0 ( 10.5,2.3)0 ( 10.5,3.0)3 ( 11.5,0.2)*8 * ( 11.5,0.9)3 ( 11.5,1.6)1 ( 11.5,2.3)1 ( 11.5,3.0)3 ( 6.5,0.2)*tot . *",
    "the total of every column in the left table above gives the value of @xmath253 when @xmath62 ranges in each interval ; similarly , the totals in the right table give the values of @xmath254 such totals provide an easy computation of the value taken by @xmath53 indeed , after noticing that in the considered example @xmath255 one gets @xmath256 so that @xmath257 notice that @xmath258 is also the median of the possible slopes , even if this coincidence is not a general rule .",
    "the least - squares estimate is @xmath259 instead .    concerning the determination of the confidence interval for @xmath4 and thus of the bounds @xmath213 and @xmath214 notice that the tables of the distribution of @xmath36 under indifference provide @xmath260 by ( [ undici ] )",
    ", one can then deduce that @xmath261 so that the confidence interval for @xmath4 with level @xmath262 whatever the distribution function @xmath52 is @xmath263 notice that the least squares method can not provide a similar result , without any further assumptions .",
    "in order to compare the estimator @xmath7 with the other cited estimators for @xmath17 some information about its asymptotic distribution is needed .",
    "the following theorem , whose proof is found in the appendix , will be of use    [ t2 ] let @xmath264 be independent variables with a common distribution function @xmath3 and absolutely continuous density @xmath265 whose support is @xmath266 and suppose that    1 .",
    "@xmath267 2 .",
    "@xmath268    and that @xmath269 with @xmath270 then @xmath271 where @xmath272 denotes the normal cdf with zero mean and unit variance and @xmath273 \\ , f'(y ) \\ , dy \\\\ \\psi(y ) & = \\lim_{n \\rightarrow + \\infty } \\ , \\frac{1}{n^{3/2 } t } \\ , \\sum_{i=1}^{[ny ] } ( x_i - \\bar x ) ( ny - i ) \\qquad 0 < y \\leq 1\\end{aligned}\\ ] ]    _ remark . _ the quantity @xmath274 \\ , f'(y ) \\ , dy\\ ] ] is negative or null .",
    "it suffices to notice that the function @xmath275 is non - decreasing and bounded with @xmath276 and that @xmath277 one then gets @xmath278 when @xmath279 is an even function , in addition , it immediately follows that @xmath280 the function @xmath281 may also happen to be identically null for peculiar sequences of the @xmath1 s , so that it is trivially @xmath282 this chance may arise when the sequence of the @xmath1 s grows  too fast \" wrt @xmath283 for example when @xmath284 with @xmath285    if the assumptions of theorem 2 are met and if @xmath286 then @xmath287    according to proposition 1 , @xmath288 can be assumed . as the realizations of @xmath54 are non - increasing and by ( [ cinque ] ) , @xmath289 so",
    "that , by theorem 2 , @xmath290    theorem 3 assures that , under the stated assumptions , the estimator @xmath7 is asymptotically normally distributed with mean @xmath4 and variance @xmath291",
    "some comparisons of the proposed estimator @xmath7 with other known estimators will now be conducted in the very important case @xmath292 @xmath293 comparisons with other kinds of sequences can be produced analogously .",
    "first of all , notice that , in the considered case , @xmath294 to develop suitable comparisons , the asymptotic relative efficiency ( are ) can be used .",
    "as known , this technique compares the sample sizes corresponding to two unbiased estimators having the same asymptotic variance . more specifically ,",
    "if two estimators @xmath295 and @xmath296 both asymptotically unbiased for the same parameter @xmath297 and with variances @xmath298 and @xmath299 need @xmath300 and @xmath301 observations respectively to obtain the same variance , then @xmath302 for the considered sequence of the @xmath1 s , the least squares estimator @xmath15 is known to be asymptotically normally distributed with mean @xmath4 and variance @xmath303 where @xmath304 denotes the population variance depending on @xmath216 hence @xmath305 the asymptotic efficiency of @xmath7 relative to the theil s estimator @xmath306 can be obtained using theorem 6.1 in [ 5 ] ( p. 1385 ) which , for the considered sequence of the @xmath1 s , states that @xmath306 is asymptotically normally distributed with mean @xmath4 and variance @xmath307 where @xmath308 one then gets @xmath309 it is easy to prove that ( [ sedici ] ) and ( [ diciotto ] ) are invariant under location and scale shifts .",
    "the following propositions are of interest :    for any @xmath3 possessing finite and positive variance , @xmath310 where @xmath311 denotes the population mean difference depending on @xmath216    after integrating by parts , ( [ dodici ] ) gives @xmath312 now notice that @xmath313 the function @xmath314 is such that , by the definition of @xmath315 @xmath316 so that it can be considered as a density function . hence @xmath317 where @xmath318 is a random variable with density @xmath319 by a trivial inequality , one has then @xmath320 and hence @xmath321 formula ( [ sedici ] ) gives @xmath322 and the proof follows by remembering ( [ 14 ) ) that , for any distribution , @xmath323    for any @xmath52 @xmath324    one can obtain @xmath325 by using ( [ diciotto ] ) , @xmath326    in the following , the values taken by ( [ sedici ] ) and ( [ diciotto ] ) will be computed for three specific distributions :    1 .",
    "normal 2 .",
    "double exponential or laplace 3 .",
    "cauchy    which are characterized by a different tail behavior .",
    "more specifically , when @xmath327 the cauchy density tends to zero very slowly , in the same manner as @xmath328 the double exponential distribution , instead , has a density tending to zero rather faster than the cauchy , but more slowly than the normal density .",
    "\\1 ) _ normal with zero mean and unit variance _    by applying ( [ tredici ] ) , one gets @xmath329 being that @xmath330 one has also @xmath331 so that ( [ sedici ] ) gives @xmath332 and ( [ diciotto ] ) gives @xmath333 hence , in the normal case the least squares estimator is better than both @xmath7 and @xmath29 even if none of the latter two estimators shows a substantial loss of efficiency .",
    "\\2 ) _ double exponential _    in this case , @xmath334 so that @xmath335 after some more computations , one gets @xmath336 hence @xmath337    \\2 ) _ cauchy _    obviously this is an extreme case , because the density @xmath338 does not possess finite variance , so the least squares estimator is not consistent . by definition",
    ", one has then @xmath339 however , it makes sense to compare @xmath7 and @xmath306 .",
    "this task results again in favor of @xmath7 .",
    "some tedious but trivial computations indeed give @xmath340 and @xmath341    the above results clearly show that the asymptotic efficiency of @xmath7 relative to @xmath30 but also to @xmath29 tend to grow as distributions with more and more heavy tails are considered .",
    "to prove theorem [ t2 ] of section [ s7 ] , some preliminary results will be considered .",
    "let @xmath279 be a probability density function with support in @xmath342 and define the two probability measures @xmath343 where @xmath344 as usual , @xmath345 is finite , @xmath346 is any event and @xmath347    [ lemma1app ] ( [ 15 ] , p. 208 ) ( [ 16 , p. 1134 ] ) + if the vector @xmath348 converges , with the measure @xmath349 , to the normal distribution with parameters @xmath350 then the variable @xmath351 converges , with the measure @xmath352 , to the normal distribution with mean @xmath353 and variance @xmath354    [ lemma2app ] ( [ 15 ] , p. 213 ) , ( [ 16 ] , p. 1136 ) .",
    "+ if @xmath355 and if @xmath356 then @xmath357 where @xmath358 denotes the limit in @xmath349probability .",
    "_ remark to lemma [ lemma2app ] _ + according to the measure @xmath359 the variable @xmath360 has the following variance @xmath361 and expectation ( [ 16 ] , p. 1125 ) @xmath362 moreover , the variable @xmath363 satisfies the lindeberg - feller condition .",
    "indeed , after defining @xmath364 where @xmath365 and @xmath366 equals 1 if @xmath367 and @xmath368 elsewhere , such a condition can be written as @xmath369 however , by putting @xmath370 one gets @xmath371 because , by hypothesis , @xmath372    [ lemma3app ] if @xmath373 and if @xmath374 then @xmath375    by using the identity @xmath376 @xmath377 the definition in ( [ due ] ) and the expression of @xmath378 one gets @xmath379 where @xmath380 \\\\",
    "b_n & = - \\frac{4 \\ , n^{3/2}}{d } \\ , \\sum_{1 \\leq i \\leq n } \\left(\\frac in - f(y_i ) \\right )   \\left [ s(i - r(y_i ) ) - s(i - n\\ , f(y_i ) ) \\right ] \\\\   c_n & = \\frac{4 \\ , n^{3/2}}{d } \\ ,",
    "\\sum_{1 \\leq i \\leq n } \\left ( \\frac{r(y_i)}{n } - f(y_i ) \\right ) \\left [ s(i - r(y_i ) ) - s(n+1-i - r(y_i ) ) \\right ] \\\\   d_n & = \\frac{2 \\ , n^{1/2}}{d } \\ ,",
    "\\sum_{1 \\leq i \\leq n }   s(n+1-i - r(y_i ) ) .",
    "\\end{aligned}\\ ] ] it follows that @xmath381 by using the joint distribution of @xmath382 that is @xmath383^{r-1 } \\ , [ 1-f(y)]^{n - r } \\ , f(y ) \\ , dy    \\quad r=1,2 , \\ldots , n ; y \\in \\re ,    \\end{aligned}\\ ] ] one gets @xmath384 \\ , dv    \\end{aligned}\\ ] ] where @xmath385 is the @xmath233th order statistic of a @xmath386sized random sample drawn from a uniform population in @xmath387 by partitioning the integration interval , after some trivial passages , one gets @xmath388 so that @xmath389 by following similar steps , one can prove that @xmath390 now let @xmath391 \\qquad i = 1 , \\ldots , n .\\ ] ] and simply consider that @xmath392 moreover , @xmath393 and @xmath394 ^ 2 \\ , g_{y_{(r ) } } ( y ) \\ , dy \\\\   & \\leq & \\sum_{1 \\leq",
    "r \\leq n } \\int_{-\\infty}^{+\\infty } \\left ( \\frac rn - f(y ) \\right)^2 \\ ,    g_{y_{(r)}}(y)\\,dy \\\\     & \\leq & \\sum_{1 \\leq",
    "r \\leq n } \\mbox e \\left\\ { \\left ( f(y_{(r ) } ) -\\frac rn \\right)^2 \\right\\ } \\ , \\rightarrow \\ ,    a < + \\infty   \\end{aligned}\\ ] ] being that @xmath395 the first summand in the rhs of ( [ asterisco ] ) thus tends to zero .",
    "moreover , @xmath396 \\sum_{i \\leq i \\leq n } \\left ( s(i - r ) -s(n+1-i - r ) \\right ) \\ , \\left ( s(i - k ) - s(n+1-i - k ) \\right ) \\big| .   \\end{aligned}\\ ] ] now , as @xmath397 one obtains @xmath398 so that the second summand in ( [ asterisco ] ) tends to zero as well .",
    "the proof follows then by applying thchebycheff s inequality in its suitable form to the four variables . @xmath141    _ remark to lemma [ lemma3app ] _",
    "+ lemma [ lemma3app ] makes it possible to obtain the asymptotic distribution of gini s cograduation index under indifference in an alternative way with respect to a former paper ( [ 17 ] ) .",
    "indeed , lemma [ lemma3app ] assures that @xmath399 is asymptotically equally distributed as @xmath400 for which the classical limit theorems can be applied , because it can be regarded as a sum of independent variables . as a matter of fact , the variable @xmath401 has the following mean and variance @xmath402 and , by letting @xmath403 and , for every @xmath404 @xmath405 the lindeberg condition is satisfied : @xmath406    [ lemma4app ] if @xmath407 @xmath408 @xmath409 and @xmath410 then the vector @xmath411 converges in distribution , with the measure @xmath359 to the bivariate normal with parameters @xmath412 where @xmath413 \\ , f'(y ) \\ , dy \\\\",
    "\\psi(y ) & = \\lim_{n \\rightarrow + \\infty } \\ , \\frac{1}{n^{3/2 } \\ , t } \\ , \\sum_{i=1}^{[ny ] } ( x_i - \\bar x ) ( ny - i ) \\qquad \\qquad 0 < y \\leq 1 \\end{aligned}\\ ] ]    by following lemmas [ lemma2app ] and [ lemma3app ] , it suffices to show that the vector @xmath414 converges in distribution to the bivariate normal with parameters @xmath415 by the remarks following lemma [ lemma2app ] and lemma [ lemma3app ] , the limiting distribution surely takes the first four parameters listed above .",
    "moreover , consider that @xmath416 \\ , dy = \\\\ & & = 4b \\ , \\int_{- \\infty}^{+ \\infty } f'(y ) \\left [ \\frac{n^{3/2}}{d \\ , t } \\left ( \\sum_{i=1}^{[n\\ , ( 1-f(y ) ) ] }   ( x_i - \\bar x ) \\left ( 1-f(y ) - \\frac in \\right ) + \\right .",
    "\\\\ & & \\hspace{6 cm }   - \\left .",
    "\\sum_{i=1}^{[n\\ , f(y ) ] } ( x_i - \\bar x ) \\left ( f(y ) - \\frac in \\right ) \\right ) \\right ] \\ , dy \\end{aligned}\\ ] ] by passing to the limit ( with @xmath40 ) under the integral sign , one gets @xmath417 \\ ,",
    "f'(y ) \\ , dy = \\\\ & = 4b \\ , \\int_0 ^ 1 \\left [ \\psi(1-v ) - \\psi(v ) \\right ] \\ , \\dfrac{f'(f^{-1}(v))}{f(f^{-1}(v ) ) } \\ , dv\\end{aligned}\\ ] ] to prove that the limiting distribution is normal , one can then show that , for every real @xmath418 and @xmath419 the following variable is asymptotically normally distributed : @xmath420 however , as both the variables @xmath421 satisfy the lindeberg condition , one can get the aimed result as in [ 15 ] , page 218 .",
    "@xmath141    the proof of theorem [ t2 ] in section [ s7 ] now immediately follows from lemmas [ lemma1app ] and [ lemma4app ] . indeed , for every real @xmath422 @xmath423 and , by lemmas [ lemma1app ] and [ lemma4app ] , @xmath424",
    "[ 1 ] f. eicker , _ asymptotic normality and consistency of least squares estimators for families of linear regressions . _",
    "ann . of math .",
    "stat . , _ 34 _ , 1963 , pp . 447456 .",
    "[ 9 ] p. muliere , _ una nota intorno al coefficiente di correlazione tra lindice g di cograduazione di gini e lindice _ @xmath34 _ di kendall .",
    "_ giornale degli economisti e annali di economia , 1976 , pp .",
    "627633 .",
    "[ 17 ] d. m. cifarelli and e. regazzini , _ on a distribution - free test of independence based on gini s rank association coefficient .",
    "_ recent developments in statistics .",
    "proceedings of the european meeting of statisticians ( grenoble , 6 - 11 sept .",
    "1976 ) , north - holland , amsterdam , 1977 , pp ."
  ],
  "abstract_text": [
    "<S> the simple linear model @xmath0 is considered , where the @xmath1 s are given constants and @xmath2 are iid with continuous distribution function @xmath3 . </S>",
    "<S> an estimator of @xmath4 is proposed , based on the stochastic process in ( [ due ] ) and defined as @xmath5 @xmath6 the properties of @xmath7 and of the related confidence interval are studied . </S>",
    "<S> some comparisons are given , in terms of asymptotic relative efficiency , with other estimators of @xmath4 including that obtained with the method of least squares .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}