{
  "article_text": [
    "a gravitational many - body simulation technique is fundamental in astrophysical simulations because gravity force drives the structure formation in the universe .",
    "length scales arisen in the structure formation range from less than 1 cm at aggregation of dust to more than @xmath4 cm at formation of cosmological structure . in all scales , gravity is a key physical process to understand the structure formation .",
    "the reason behind this is long - range nature of gravity .",
    "suppose we simulate the structure formation with @xmath5 particles , a flow of a many - body simulation is as follows .",
    "first we calculate mutual gravity force between @xmath5 particles then integrate orbits for @xmath5 particles and repeat this process as necessary .",
    "although it is simple , the force - calculation is a challenging task in regarding computational science . a simple and exact method to do the force - calculation requires @xmath0 computational complexity , which is prohibitively compute intensive with large @xmath5 .",
    "the exact force - calculation is necessary in some types of simulations such as a few - body problems , numerical integration of planets orbiting around a star ( e.g. , the solar system ) , and evolution of dense star clusters . for simulations that do not require exact force , a several approximation techniques",
    "have been proposed @xcite . the particle - mesh / particle - particle - mesh method @xcite and the oct - tree method @xcite reduce the computational complexity of the force - calculation to @xmath1 . the fast - multipole method ( fmm )",
    "further reduces it to @xmath6 . among these methods ,",
    "the oct - tree method has been used extensively in astrophysical simulations since its adaptive nature is essential to deal with clumpy structure in the universe ( e.g. , @xcite ) .    despite @xmath1 complexity , computational optimization to the oct - tree method such as vectorization and parallelization",
    "is necessary to accommodate demands for simulations with larger and large @xmath5 . in @xcite , they have reported various techniques to vectorize the force - calculation with the oct - tree method . in @xcite , they have reported their parallel oct - tree method for massively parallel processors ( mpp ) . in a recent work @xcite , with a parallel oct - tree code running on mpp ,",
    "they have reported the simulation of large - scale structure formation in the universe with more than ten billions particles .",
    "another computational technique that speed - up the oct - tree method is to utilize special purpose computers grape@xcite . a combination of vectorization techniques of the oct - tree method and grape",
    ", one can execute the oct - tree method efficiently on grape @xcite    notably , the cosmological simulation is a grand challenge problem .",
    "in fact , the cosmological simulations were awarded many times in the gordon bell prizes @xcite . in those work ,",
    "both parallel tree codes @xcite and a tree code with grape @xcite have been adopted to do cosmological simulations .    in the present paper",
    ", we describe our implementation of the oct - tree method on a graphic processing unit ( gpu ) .",
    "the rise of the gpu forces us to re - think a way of parallel computing on it since a performance of recent gpus is impressive at @xmath7 tflops .",
    "acceleration techniques for many - body simulations with gpu have been already reported ( @xcite and many others ) , however , they have implemented the exact but brute force method with @xmath0 complexity .",
    "apparently , for applications that do not require the exact force , it is possible to do much efficient computation with the oct - tree method .",
    "we have implemented the oct - tree method on gpu so that we can enjoy the speed of @xmath1 algorithm on gpu . with small @xmath8 ,",
    "the brute force method on gpu is faster than the oct - tree method on gpu due to extra work concerning tree data structure .",
    "however , our result show the oct - tree on gpu significantly outperform the brute force method with @xmath9 at which a standard size of @xmath5 in current astrophysical simulations is . as an application of our code ,",
    "we present a result of a cosmological simulation with our tree code running on rv770 gpu .",
    "our computing system used in the present paper consists of a host computer and an extension board .",
    "a main component of the extension board is a gpu processor that is acted as an accelerator attached to the host computer .",
    "a program running of the host computer cooperates with a program running on the gpu to do useful tasks .      in this section ,",
    "we briefly summarize a gpu that we used to implement the oct - tree method for cosmological simulations .",
    "rv770 processor from amd / ati is the company s latest gpu ( r700 architecture ) with many enhancements for general purpose computing on gpu ( gpgpu ) .",
    "it has 800 arithmetic units ( called a stream core ) , each of which is capable of executing single precision floating - point ( fp ) multiply - add in one cycle . at the time of writing",
    ", the fastest rv770 processor is running at 750 mhz and offers a peak performance of @xmath10 tflops .",
    "internally , there are two types of the stream cores in the processor .",
    "one is a simple stream core that can execute only a fp multiply - add and integer operations and operates on 32 bit registers .",
    "another is a transcendental stream core that can handle transcendental functions in addition to the above simple operations .",
    "moreover , these units are organized hierarchically as follows . at one level higher from the stream cores , a five - way very long instruction word unit called a thread processor ( tp ) , that consists of four simple stream cores and one transcendental stream core .",
    "therefore , one rv770 processor has 160 tps",
    ". the tp can execute either at most five single - precision / integer operations , four simple single - precision / integer operations with one transcendental operation , or double - precision operations by combinations of the four stream cores .",
    "moreover , a unit called a simd engine consists of 16 tps .",
    "each simd engine has a memory region called a local data store that can be used to explicitly exchange data between tps .    at the top level rv770 , there are 10 simd engines , a controller unit called an ultra - threaded dispatch processor , and other units such as units for graphic processing , memory controllers and dma engines .",
    "an external memory attached to the rv770 in the present work is 1 gb gddr5 memory with a bus width of 256 bit .",
    "it has a data clock rate at 3600 mhz and offers us a bandwidth of 115.2 gb sec@xmath11 .",
    "in addition to this large memory bandwidth , each simd engine on rv770 has two - level cache memory .",
    "figure [ rv770 ] shows a block diagram of rv770 .",
    "the rv770 processor with memory chips is mounted on an extension board .",
    "the extension board is connected with a host computer through pci - express gen2 x16 bus .",
    "a theoretical communication speed between the host computer and rv770 gpu is at most 8 gb sec@xmath11 ( in one - way ) . the measured communication speed of our system ( shown in table [ conf ] )",
    "is @xmath12 gb sec@xmath11 for data size larger than 1 mb .      in 2008",
    ", amd / ati has released a software development kit ( sdk ) for stream computing / gpgpu on their gpu products .",
    "the sdk consists of two levels as a compute abstraction layer ( cal ) and a high - level language ( called brook+ ) similar to the c language .",
    "the cal is more or less close to a bare hardware and offers us a basic library that enables us to access , manage and control gpu(s ) and to generate machine instructions from an assembly like language called il ( intermediate language ) .",
    "the il is like a virtual instruction set for gpu from amd / ati . in the present work ,",
    "we program the rv770 gpu using the il to gain full control of rv770 gpu .",
    "a programming model supported by cal and il is a single instruction and multiple data ( simd ) at the level of tp . in this programming model , a sequence of instructions generated from an il program",
    "is executed on all tps simultaneously with different input data from a viewpoint of a user .",
    "internally , the ultra - threaded dispatch processor controls a flow of processing .",
    "it can supply different instructions to different simd engines so that tps in a simd engine executes the same instructions but other simd engines can execute different instructions .",
    "therefore , actual execution of a program on rv770 is like a multiple program and multiple data ( mpmd ) model .    a code written in il",
    "is called a compute kernel . in a compute kernel ,",
    "we explicitly declare which type of variable input data is . in a main - body of the il code",
    ", we write arithmetic operations on input data .",
    "logically , each tp is implicitly assigned data that is different each other . in a simple compute kernel , it operates on the assigned data . an operation like this , such as",
    "a pure stream computing , seems to work in highest efficiency . in a complex compute kernel , which we explore in the present work , each tp not only operates on the assigned data but also explicitly load random data that might be assigned to another tp . to accomplish a random access to external memory , we explicitly calculate an address of data in our compute kernel .",
    "so far , we have developed a several il codes that can be used to do astrophysical many - body simulations . in this section ,",
    "we report a performance of our implementation of the brute force method for computing gravity .",
    "this code served as fundamental for us to implement an algorithm that is more sophisticated later .",
    "precisely , we have implemented conventional equations expressed as @xmath13 where @xmath14 and @xmath15 are force vector and potential for a particle @xmath16 , and @xmath17 , @xmath18 , @xmath19 are position of a particle , the mass , and a parameter that prevents division by zero , respectively .",
    "we can calculate these equations as a two - nested loop on a general purpose cpu . in the most inner loop , by simultaneously evaluating functions @xmath20 and @xmath21 , we require 22 arithmetic operations , which include one square root and one division , to compute an interaction between particle @xmath16 and @xmath22 .",
    "since previous authors starting from @xcite used a conventional operational count for evaluation of @xmath14 and @xmath15 , we also adopt the conventional counts of 38 throughout the paper .",
    "we simply implemented the summations eq.([gravity ] ) on rv770 and have obtained a performance of @xmath23 gflops for @xmath24 .",
    "since the peak performance of rv770 is more than four times larger , we have tried to optimize the simple implementation to get full utilization of the system . in @xcite , they have reported their implementation of the brute force method for gravity and other forces on an older gpu from amd / ati .",
    "a main insight they have obtained was that a loop unrolling technique greatly enhanced the performance of their code .",
    "we have followed their approach and tried a several different ways of the loop unrolling .",
    "details of optimization will be presented elsewhere .    in figure",
    "[ bare ] , we plot a computing speed of our optimized il code for computing eq.([gravity ] ) as a function of @xmath5 .",
    "we have tested two configurations as one rv770 gpu running at 625 and 750 mhz , respectively .",
    "so far , we have obtained a maximum performance of @xmath25 gflops with @xmath26 . with @xmath27 ,",
    "our optimized brute force method took roughly 2 seconds on one rv770 running at 750mhz . as far as we know , the performance we obtained is fastest ever with one gpu chip .",
    "even with massive computing force available on gpu , we can not escape from a computational complexity of @xmath0 .",
    "therefore , if we need to do an astrophysical many - body simulation with large @xmath5 , we need a smart algorithm to do the job provided that recent standard of @xmath5 in astrophysical simulations is at least @xmath28 for a complex simulation with baryon physics and @xmath29 for a simple many - body simulation .",
    "the oct - tree method @xcite is a special case of the general kd - tree algorithm .",
    "this method is optimized to efficiently calculate mutual force between particles and reduce computational complexity of the force - calculation from @xmath0 with the brute force method to @xmath1 .",
    "a trick is that instead of computing exact force with the brute force method , it approximates the force from distant particles with multipole expansion generated by those distant particles .",
    "apparently , there is a trade - off between approximation error and a way in which we replace a group of distant particles with their multipole expansion .",
    "a tree structure that contains all particles is used to efficiently judge this trade - off as we briefly explained .    the force - calculation with the oct - tree method is executed in two steps .",
    "( 1 ) tree construction and ( 2 ) the force - calculation . in the tree construction",
    ", we equally divide a cube that encloses whole particles into eight sub - cells .",
    "this first cell is a root of a tree that we construct .",
    "it is called a root cell .",
    "then , each sub - cell is recursively sub - divided in the same say until a cell has zero or one particle . as the result of this procedure ,",
    "we obtain the oct - tree .",
    ".... procedure treewalk(i , cell )    if cell has only one particle      force + = f(i , cell )    else       if cell is far enough from i         force + = f_multipole(i , cell )      else         for i = 0 , 7          if cell->subcell[i ] exists            treewalk(i , cell->subcell[i ] ) ....    in the force - calculation , we traverse the oct - tree to judge whether we replace a distant cell , which has a group of particles that are geometrically close , with their multipole expansion .",
    "if we do not replace , we further traverse sub - cells of the distant cell .",
    "if we do replace , we calculate particle - cell interaction .",
    "when we encounter a particle , we immediately calculate particle - particle interaction . given a particle ( expressed as index ` i ` )",
    "on which we want to compute the force acting , this procedure is expressed as a pseudo code in figure [ treewalk ] .",
    "note ` subcell [ ] ` are pointers to own sub - cells . in this pseudo code , ` f ` is a function that computes particle - particle interaction .",
    "in addition ` f_multipole ` is a function that computes particle - cell interaction . in the present work ,",
    "since we only consider monopole moment of a cell , both functions are exactly expressed as eq.([gravity ] ) . in principle , we can use any high order moment in particle - cell interaction .",
    "we use this procedure starting from the root cell with the following condition that tests whether a cell is far enough .",
    "let the distance between the particle and the cell is @xmath30 .",
    "the cell is well separated from the particle if @xmath31 , where @xmath32 is the size of the cell and @xmath33 is a parameter that controls the trade - off .",
    "since smaller @xmath34 the cell is more distant from the particle , this condition ( called opening condition ) geometrically tests whether the cell is far from the particle .",
    "this recursive force - calculation procedure is almost same as the original algorithm by @xcite",
    ".    an important nature of the oct - tree method is that the force - calculation with tree traversal for different particles is completely independent each other .",
    "therefore , after we complete the tree construction , the force - calculation is a massively parallel problem . to take an advantage of this nature , there are two possibilities to implement the oct - tree method on gpu .",
    "one is a method proposed by @xcite .",
    "this method has been proposed as a tree method for a special purpose computer grape .",
    "a system with grape consists of a host computer and grape board(s ) .",
    "the host computer controls the grape . for a program running on the host ,",
    "the grape acts like a subroutine that calculates gravity with given particles .",
    "so we need the following two steps to use grape for the force - calculation using the tree .",
    "( 1 ) construction of interaction list on the host computer and ( 2 ) actual force - calculation on the grape .",
    "the interaction list is a list of particles and distant cells that are supposed to interact with a given particle .",
    "after construction of interaction lists for each particles are completed , we compute the force for each particles with grape by sending interaction lists to grape .",
    "these two steps are necessary because the grape does not have ability to traverse the tree .",
    "many authors have extensively used this method .",
    "two winners and a finalist of gorden - bell have used a variant of this method with different version of grape @xcite . in principle",
    ", we can adopt this method for gpu . actually , many authors have somehow emulated grape with gpus ( e.g. , @xcite ) and they all have obtained a good performance .",
    "a drawback of this approach is that the performance is limited by a speed of a host computer that is responsible for the tree traversal .",
    "this possible bottleneck similar to the amdahl s law might be critical without highly tuned ` treewalk ( ) ` implementation running on the host .",
    "furthermore , in all results by @xcite , they have required a factor of two extra force evaluations to obtain their best performance . note because of extra force evaluations , they have reported that maximum error in force was better than the error obtained by the conventional oct - tree method with given @xmath33 .",
    "another way that we have taken in the present work is to implement the whole procedure shown in figure [ treewalk ] on gpu .",
    "advantage of our approach is that only the tree construction , which requires relatively little time , is executed on a host so that we utilize massive computing power of gpu as much as possible .",
    "more importantly , we can apply our method to implement an application that requires short - range force interaction @xcite .",
    "this is because it is possible to implement neighbor search algorithm as a general treewalk procedure shown in figure [ general_treewalk ] .",
    "two procedures ` proc_particle ` and ` proc_cell ` are used to process particle - particle and particle - cell interaction , respectively .",
    "in addition , a function ` distance_test ` is used to control the treatment of a distant cell .",
    "the gravity force - calculation is an application of the general treewalk procedure that is very successful .",
    ".... procedure general_treewalk(i , cell )    if cell has only one particle      proc_particle(i , cell )    else       if distance_test(i , cell ) is true        proc_cell(i , cell )      else         for i = 0 , 7          if cell->subcell[i ] exists            general_treewalk(i , cell->subcell[i ] ) ....      in our implementation of the oct - tree method on gpu , we first construct an oct - tree on a host computer that controls rv770 . at this stage",
    ", there is no difference between our original tree code and a newly developed code for rv770 .",
    "we need a special care to implement the treewalk procedure on rv770 .",
    "currently , the il does not support a recursive procedure except when it is possible to fully expand a recursion .",
    "such full expansion is only possible if a level of the recursion is definite but in the tree method , we ca nt know how deep the recursion without a tree traversal is .",
    "so we adopt a method proposed by @xcite that transform a recursion in ` treewalk ( ) ` into an iteration .",
    "a key is that for a given cell we does not need whole pointers ( ` subcell [ ] ` ) to traverse the tree .",
    "we only need two pointers to cells that we will visit next when the opening condition is true and false , respectively .",
    "these two pointers ( hereafter we call ` next [ ] ` and ` more [ ] ` ) are easily obtained by a breath - first traversal on the tree .",
    "figure [ tree ] shows ` next [ ] ` and ` more [ ] ` schematically .",
    "note a cell that has sub - cells has both ` next [ ] ` and ` more [ ] ` pointers while a leaf cell ( a particle in the present case ) with no sub - cell has only ` next [ ] ` pointer .",
    "with the two pointers , an iterative form of ` treewalk ( ) ` is shown in figure [ treewalk_iterative ] .        .... procedure treewalk_iterative(i )    cell = the root cell    while cell is not null      if cell has only one particle        force",
    "+ = f(i , cell )        cell = cell->next      else         if cell is far enough from i           force + = f_multipole(i , cell )          cell = cell->next        else           cell = cell->more ....    the il allow us to implement the iterative ` treewalk ( ) ` rather directly .",
    "input data for this compute kernel is four arrays .",
    "first is a position and mass of particles and cell .",
    "we pack a position and mass into a vector variable with four - element .",
    "therefore , it is the array of four - element vectors .",
    "the mass of the cell equals to the total mass of particles in the cell . and",
    "the position of the cell is at the center of mass of the particles .",
    "second and third arrays are the next and more pointers , respectively .",
    "both of them are a simple array . and fourth array is the size of the cells .",
    "the size of the cell is necessary for testing the opening condition . in the present work ,",
    "we adopt a following modified opening condition expressed as @xmath35 where @xmath36 is a distance between the center of a cell and the center of mass of the cell @xcite .",
    "the modified condition eq.([mac ] ) takes into account particle distribution in a cell through @xmath36 since if particles gathers at a corner of a cell , the effective size of the cell become larger . in figure [ cell - theta ] , we present a schematic view of a distant cell and a particle on which we are trying to calculation force acting .",
    "practically , we pre - compute the square of effective size @xmath37 as @xmath38 and send @xmath37 instead of @xmath32 for each cell . with @xmath37",
    ", we do nt need to computer square root of @xmath30 so that we simply compare @xmath37 and @xmath39 during the tree traversal .    in figure [ treegpu ]",
    ", we present an abstracted version of our compute kernel written in il . in the computing model of cal , each tp execute the compute kernel with assigned data in parallel . in this code , ` own ` represents the specific cell assigned to each tp . `",
    "= ` , ` load ` and ` - > ` and are not a real il instruction or operation but conventional idioms used here for explanation .",
    "we omit a calculation of load address for arrays since it is somehow too detailed .",
    "in addition the particle - particle and particle - cell interaction codes are omitted because they simply compute functions @xmath21 and @xmath20 in eq.([gravity ] ) .",
    "as far as we understood , programming in il is as much like programming an inner - most loop for a vector processor in an assembly language . in this analogy",
    ", a group of tps corresponds to a vector - processing unit .    .... ... declaration of i / o arrays and constants ... ... initialize variables for accumulation ...",
    "xi = load own->x yi = load own->y zi = load own->z    cell = root whileloop    break if cell is null      xj = load cell->x    yj = load cell->y    zj = load cell->z    mj = load cell->m    s_eff = load cell->s_eff      dx = xj - xi    dy = yj - yi    dz = zj - zi    r2 = dx*dx + dy*dy + dz*dz      if cell is a particle      ... compute particle - particle interaction ...      cell = load next    else       if r2 > s_eff        ... compute particle - cell interaction ...        cell = load cell->next      else         cell = load cell->more    endif endloop ....    with the compute kernel we have shown , a flow of our oct - tree method on rv770 gpu is as follows .    1 .",
    "construct a tree ( * host * ) 2 .   compute the total mass , the center of mass , the effective size of each cell ( * host * ) 3 .",
    "compute the next and more pointers ( * host * ) 4 .",
    "send input data to gpu ( * host * ) 5 .",
    "iterative treewalk associated with the force - calculation for each particle ( * gpu * ) 6 .",
    "receive the force for each particle from gpu ( * host * )    we indicate whether the corresponding part is executed on either the host or rv770 gpu with the bold text at the end of each step .",
    ".the configuration and cost of our system [ cols=\"^,^,^\",options=\"header \" , ]",
    "as an application of the oct - tree method on gpu , we have done an astrophysical many - body simulation using our method .",
    "we report the performance statistics of the simulation in this section .",
    "we did a simulation of large - scale structure formation in the universe with a many - body simulation technique that utilizes the oct - tree method .",
    "we cut out a spherical region of particles from an initial data that represents initial density fluctuations in the early universe .",
    "we used cosmics @xcite to generate the initial data .",
    "the radius of the sphere is 45 mega parse ( mpc ) and the number of particles is 2,874,551 .",
    "therefore , each particle represents @xmath40 solar masses .",
    "we set the initial redshift of the run at @xmath41 and evolved the particles until @xmath42 ( the present time ) with 3,584 timesteps . the total duration in physical unit",
    "is @xmath43 years so that one timestep corresponds to @xmath44 years . in this run",
    ", we set @xmath45 and the softening length ( @xmath19 in eq.([gravity ] ) ) at the present time 4 kpc .",
    "we present a several snapshots of the run in figure [ snap ] ,     and @xmath46 , respectively .",
    "the size of panels is 30 mpc.,width=566 ]    our initial condition is not identical but basically same to initial conditions that have been used in previous entries to gordon bell prize @xcite . precisely , we used larger @xmath5 and more timesteps than @xcite .",
    "we believe such differences do not significantly affect the performance .",
    "we measured the wall - clock time reported from the host computer .",
    "this run took 20,860 seconds ( 5.79 hours ) from @xmath41 to @xmath42 .",
    "this time includes the time required for file i / o and miscellaneous calculations . during the run",
    ", we made the program to dump a snapshot every 128 timesteps . in total , we have obtained 29 snapshots including an initial snapshot .",
    "we used the snapshots to estimate the total number of interaction counts as follows . for each snapshot , we separately run our code without utilizing gpu to count a number of force interactions required to calculate gravity for one timestep . as structure emerged from initial density fluctuations ,",
    "a number of force interactions per a step was increasing as shown in figure [ count ] .",
    "based on this data , we estimated the total number of force interaction of the gpu run by integrating a function obtained by connecting points shown in figure [ count ] with lines .",
    "the result was @xmath47 force interactions .",
    "with a conventional floating - point operations count of 38 adopted by previous authors , the whole run effectively executed @xmath48 flops .",
    "therefore , we have obtained a sustained performance of 21.8 gflops .",
    "the price per performance is $ 41.6/gflops that is two and half times better than the most recent result of $ 105/gflops @xcite .",
    "in @xcite , they have implemented oct - tree data structure for a texture mapping and traversal algorithm of the tree on gpu . due to limitations of a gpu and software for gpu programming at that time",
    ", their method seems to be restricted to applications of computer graphics .",
    "a critical point is that they limit the possible depth of the tree so that we can not directly employ their implementation for our purpose .      in @xcite , they have reported an implementation of a fast multipole method ( fmm ) on gpu .",
    "the fmm is a sophisticated algorithm to evaluate long - range force interaction with computational complexity of @xmath6 . in the fmm , in addition to the replacement of distant particles with multipole expansions , it utilizes local expansions to evaluate force acting on a group of particles .",
    "they have reported for @xmath49 it took 0.98 sec with @xmath50 in their table 9 where @xmath20 is a parameter that controls error bound .",
    "their figure 10 indicates that the average relative error obtained with @xmath50 is @xmath51 that is comparable to the relative error obtained with the oct - tree method with @xmath52 . note they have used a randomly distributed particle distribution in a cube .",
    "we did a test with a similar particle distribution for comparison .",
    "our code with the size of width 256 took 0.73 sec for @xmath49 with @xmath45 .",
    "the cache - hit rate of the test is 70 % .",
    "there are many possible explanations to the better performance we obtained such as ( 1 ) the rv770 gpu used in the present work is different from and newer than their nvidia g80 gpu and ( 2 ) even though the fmm is better computational complexity than the tree method , its algorithmic complexity may cause slower performance on gpu .    generally , the fmm is well suitable to applications that require long - range force interaction with uniformly distributed particles / sources while the oct - tree method is more robust to highly clustered particles that typically arises in astrophysical many - body simulations .",
    "furthermore , the oct - tree method is also efficient to compute general short - range force interaction .",
    "a typical example in astrophysical simulations is the smoothed particle hydrodynamics ( sph ) method @xcite .",
    "we believe that our method is more suitable than @xcite for our purpose of astrophysical applications .",
    "in this paper , we describe our implementation of the oct - tree method on rv770 gpu . by transforming a recursive tree traversal into an iterative procedure",
    ", we show the execution of the tree traversal with the force - calculation is practical and efficient on gpu . as an application of our method",
    ", we have done a cosmological simulation .",
    "the sustained performance of the simulation is 21.8 gflops .",
    "the cost per gflops obtained with the simulation is $ 41.6/gflops that is two and half times better than a recent result .",
    "in addition , our implementation shows better performance than the recently reported fmm code on gpu",
    ". we will get further performance gains by fully utilizing four - vector simd operations of tps and newer gpu with more stream cores .",
    "moreover , since 10 - 20 % of t@xmath53 is spent on the tree construction , parallelization of this part using multiple cores will be effective to boost the total performance .",
    "provided that we can easily extend our code to implement a force - calculation for short - range interaction such the sph method , we believe that a future extended version of our code will enable us to do a realistic astrophysical simulation that involves baryon physics with @xmath54 very rapidly .",
    "the author would like to thank m.  sato and k.  fujiwara for their efforts to utilize rv770 gpu for astrophysical many - body simulations . a part of this work is based on their undergraduate thesis 2008 at the university of aizu",
    ".                  m.  s.  warren , p.  j.  quinn , j.  k.  salmon and w.  h.  zurek , _ dark halos formed via dissipationless collapse .",
    "i - shapes and alignment of angular momentum _ , astrophysical journal , vol .",
    "399 , pp.405 - 425 , 1992                                  r.  g.  belleman , j.  bedorf , and s.  f.  portegies zwart , _ high performance direct gravitational n - body simulations on graphics processing units ii : an implementation in cuda _ , new astronomy , vol . 13 , pp103 - 112"
  ],
  "abstract_text": [
    "<S> the kd - tree is a fundamental tool in computer science . among others , </S>",
    "<S> an application of the kd - tree search ( oct - tree method ) to fast evaluation of particle interactions and neighbor search is highly important since computational complexity of these problems are reduced from @xmath0 with a brute force method to @xmath1 with the tree method where n is a number of particles . in this paper , we present a parallel implementation of the tree method running on a graphic processor unit ( gpu ) . </S>",
    "<S> we successfully run a simulation of structure formation in the universe very efficiently . on our system , which costs roughly $ 900 , the run with @xmath2 particles took 5.79 hours and executed @xmath3 force evaluations in total . </S>",
    "<S> we obtained the sustained computing speed of 21.8 gflops and the cost per gflops of $ 41.6/gflops that is two and half times better than the previous record in 2006 . </S>"
  ]
}