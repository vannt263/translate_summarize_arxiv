{
  "article_text": [
    "in traditional data analysis a unit is usually described with a list of ( numerical , ordinal or nominal ) values of selected variables . in symbolic data analysis ( sda ) a unit of a data set can be represented , for each variable , with a more detailed description than only a single value .",
    "such structured descriptions are usually called ( sos ) @xcite , @xcite ) .",
    "a special type of symbolic objects are descriptions with frequency or probability distributions . in this way we can at the same time consider both  a single value variables and variables with richer descriptions .",
    "computerization of data gathering worldwide caused the data sets getting huge . in order to be able to extract ( explore ) as much information as possible from such kind of data",
    "the predefined aggregation ( preclustering ) of the raw data is getting common .",
    "for example if a large store chain ( that records each purchase its customers make ) wants information about patterns of customer purchases , the very likely way would be to aggregate purchases of customers inside a selected time window .",
    "a variable for a customer can be a yearly shopping pattern on a selected item .",
    "such a variable could be described with a single number ( average yearly purchase ) or with a symbolic description  purchases on that item aggregated according to months .",
    "the second description is richer and allows for better analyses .    in order to retain and use more information about each unit during the clustering process , we adapted two classical clustering methods :    * leaders method , a generalization of k - means method ( @xcite , @xcite , @xcite ) * ward s hierarchical clustering method ( @xcite ) .",
    "both methods are  they are based on the same criterion function",
    ". therefore they are solving the same clustering optimization problem .",
    "they can be used in combination : using the leaders method the size of the set of units is reduced to a manageable number of leaders that can be further clustered using the compatible hierarchical clustering method .",
    "it enables us to reveal the relations among the clusters / leaders and also to decide , using the dendrogram , upon the right number of final clusters .",
    "since clustering objects into similar groups plays an important role in the exploratory data analysis , many clustering approaches have been developed in sda .",
    "symbolic object can be compared using many different dissimilarities with different properties .",
    "based on them many clustering approaches were developed .",
    "review of them can be found in basic books and papers from the field : @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "although most attention was given to clustering of interval data ( de carvalho , f.a.t . and",
    "his collaborators ) some methods were developed also for modal valued data that are close to our approach ( @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite    ) .",
    "the very recent paper of @xcite describes the dynamic clustering approach to histogram data based on wasserstein distance .",
    "this distance allows also for automatic computation of relevance weights for variables .",
    "the approach is very appealing but can not be used when clustering general ( not necessarily numerical ) modal valued data . in the paper",
    "@xcite the authors present an approach with dynamic clustering that could be ( with a pre - processing step ) used to cluster any type of symbolic data . for the dissimilarities adaptive",
    "squared euclidean distance is used .",
    "one drawback to this approach is in the fact that when using dynamic clustering one has to determine the number of clusters in advance . in the paper @xcite",
    "the authors propose ichino - yaguchi dissimilarity measure extended to histogram data and in the paper @xcite two measures ( ichino - yaguchi and gowda - diday ) extended to general modal valued data .",
    "they use these measures with divisive clustering algorithm and propose two cluster validity indexes that help one decide for the optimal number of final clusters . in the paper @xcite",
    "even more general dissimilarity measures are proposed to use with mixed histogram , multi valued and interval data .",
    "the aim of this paper is to provide a theoretical basis for a generalization of the compatible leaders and agglomerative hierarchical clustering methods for modal valued data with meaningful interpretations of clusters leaders .",
    "the novelty in our paper is in proposed additional dissimilarity measures ( stemming directly from squared euclidean distance ) that allow the use of weights for each so ( or even its variable s component ) in order to consider the size of each so .",
    "it is shown that each of these dissimilarities can be used in a leaders and agglomerative hierarchical clustering method , thus allowing the user to chain both methods . in dealing with big data sets we can use leaders methods to shrink the big data set into a more manageable number of clusters ( each represented by its leader ) which can be further clustered via hierarchical method . thus the number of final cluster",
    "is easily determined from the dendrogram .",
    "when clustering units described with frequency distributions , the following problems can occur :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * problem 1 : * the values in descriptions of different variables can be based on different number of original units .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    a possible approach how to deal with this problem is presented in an application in @xcite , where two related data sets ( teachers and their students ) are combined in an ego - centered network , which is presented with symbolic data description .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * problem 2 : * the representative of a cluster is not a meaningful representative of the cluster . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for example , this problem appears when clustering units are age - sex structures of the world s countries ( e.g. @xcite ) . in @xcite authors used a weighted agglomerative clustering approach , where clusters representatives are real age - sex structures , for clustering population pyramids of the world s countries .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * problem 3 : * the squared euclidean distance favors distribution components with the largest values . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in clustering of citation patterns @xcite showed that the selection of the squared euclidean distance does nt give very informative clustering results about citation patterns .",
    "the authors therefore suggested to use relative error measures .    in this paper",
    "we show that all three problems can be solved using the generalized leaders and ward s methods with an appropriate selection of dissimilarities and with an appropriate selection of weights .",
    "they produce more meaningful clusters representatives .",
    "the paper also provides theoretical basis for compatible usage of both methods and extends methods with alternative dissimilarities ( proposed in @xcite for classical data representation ) on modal valued sos with general weights ( not only cluster sizes ) .    in the following section we introduce the notation and the development of the adapted methods",
    "is presented .",
    "the third section describes an example analysis of the european social survey data set @xcite .",
    "section four concludes the paper . in the appendix we provide proofs that the alternative dissimilarities",
    "can also be used with the proposed approach .",
    "the _ set of units _ @xmath0 consists of symbolic objects ( sos ) .",
    "an so @xmath1 is described with a list of descriptions of variables @xmath2 . in our general model ,",
    "each variable is described with a list of values @xmath3 @xmath4,\\ ] ] where @xmath5 denotes the the number of variables and @xmath6,\\ ] ] with @xmath7 being the number of terms ( frequencies ) @xmath8 of a variable @xmath2 .",
    "let @xmath9 be the count of values of a variable @xmath10 @xmath11 then we get the corresponding probability distribution @xmath12    in general , a frequency distribution can be represented as a vector or graphically as a barplot ( histogram ) .",
    "to preserve the same description for the variables with different measurement scales , the range of the continuous variables or variables with large range has to be categorized ( partitioned into classes ) . in our model the values na ( not available ) are treated as an additional category for each variable , but in some cases use of imputation methods for nas would be a more recommended option .    clustering data with leaders method or hierarchical clustering method are two approaches for solving the clustering optimization problem .",
    "we are using the criterion function of the following form @xmath13 the _ total error _ @xmath14 of the clustering @xmath15 is the sum of _ cluster errors _ @xmath16 of its clusters @xmath17 .",
    "there are many possibilities how to express the cluster error @xmath16 . in this paper",
    "we shall assume a model in which the error of a cluster is a sum of differences of its units from the cluster s @xmath18 .",
    "for a given representative @xmath18 and a cluster @xmath19 we define the cluster error with respect to @xmath18 : @xmath20 where @xmath21 is a selected dissimilarity measure .",
    "the best representative @xmath22 is called a @xmath23 then we define @xmath24    assuming that the leader @xmath18 has the same structure of the description as sos ( i.e. it is represented with the list of nonnegative vectors @xmath25 of the size @xmath7 for each variable @xmath10 ) .",
    "we do not require that they are distributions , therefore the representation space is @xmath26 .",
    "we introduce a dissimilarity measure between sos and @xmath18 with @xmath27 where @xmath28 are weights for variables ( i.e. to be able to determine a more / less important variables ) and @xmath29 where @xmath30 are weights for each variable s component . this is a kind of a generalization of the . using an alternative @xmath31",
    "we can address the .",
    "some examples of basic dissimilarities @xmath31 are presented in table  [ t : relative ] .",
    "it lists the basic dissimilarities between the unit s component and the leader s component that were proposed in @xcite for classical data representation . in this paper",
    "we extend them to modal valued sos",
    ".    the weight @xmath30 can be for the same unit @xmath1 different for each variable @xmath10 and also for each of its components . with weights we can include in the clustering process different number of original units for each variable ( solving and/or ) and they also allow a regulation of importance of each variable s category .",
    "for example , the population pyramid of a country @xmath1 can be represented with two symbolic variables ( one for each gender ) , where people of each gender are represented with the distribution over age groups . here",
    ", @xmath32 is the number of all men and @xmath33 is the number of all women in the country @xmath1 .    to include and preserve the information about the variable distributions and their size throughout the clustering process ( )",
    ", the following has to hold when merging two disjoint clusters @xmath34 and @xmath35 ( a cluster may consist of one unit only ) : @xmath36 where @xmath37 denotes the relative distribution of the variable @xmath10 of the joint cluster @xmath38 the frequency distribution of variable @xmath10 in the joint cluster and @xmath39 the weight ( count of values ) for that variable in the joint cluster .",
    "although we are using the notation @xmath40 which is usually used for frequencies , other interpretations of @xmath40 and @xmath41 are possible .",
    "for example @xmath41 is the money spent , and @xmath40 is the distribution of the money spent on a selected item in a given time period .",
    "leaders method , also called dynamic clouds method @xcite , is a generalization of a popular nonhierarchical clustering k - means method @xcite .",
    "the idea is to get the `` optimal '' clustering into a pre - specified number of clusters with an iterative procedure . for a current clustering the leaders",
    "are determined as the best representatives of its clusters ; and the new clustering is determined by assigning each unit to the nearest leader .",
    "the process stops when the result stabilizes . in the generalized approach ,",
    "two steps should be elaborated :    * how to determine the new leaders ; * how to determine the new clusters according to the new leaders .      given a cluster @xmath19 ,",
    "the corresponding leader @xmath42 is the solution of the problem ( eq . [ eqp ] ) @xmath43 @xmath44_{i=1}^m\\ ] ] denoting @xmath45 $ ] , where @xmath46 , we get the following requirement : @xmath47 . because of the additivity of the model we can observe each variable separately and simplify the notation by omitting the index @xmath48 .",
    "@xmath49 @xmath50_{j=1}^k\\ ] ] since in our model also the components are independent we can optimize component - wise and omit the index @xmath51 @xmath52 @xmath53 is a kind of frchet mean ( median ) for a selected basic dissimilarity @xmath31 .",
    "this is a standard optimization problem with one real variable .",
    "the solution has to satisfy the condition @xmath54    [ [ leaders - for - delta_1 ] ] leaders for @xmath55 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    here we present the derivation only for the basic dissimilarity @xmath55 .",
    "the derivations for other dissimilarities @xmath31 from table  [ t : relative ] are given in the appendix .",
    "the traditional clustering criterion function in @xmath56-means and ward s clustering methods is based on the squared euclidean distance dissimilarity @xmath21 that is based on the basic dissimilarity @xmath57 . for it",
    "we get from  ( [ leadereq ] ) @xmath58 therefore @xmath59    the usage of selected weights in the dissimilarity @xmath55 provides meaningful cluster representations , resulting from the following two properties :    [ [ property-1 ] ] property 1 + + + + + + + + + +    let @xmath60 then for each @xmath61 : @xmath62 if the weight @xmath30 is the same for all components of variable @xmath10 , @xmath60 , then for @xmath55 the leaders vectors @xmath63 are .",
    "[ [ property-2 ] ] property 2 + + + + + + + + + +    let further @xmath64 then for each cluster c , @xmath61 and @xmath65 :    @xmath66 note that in this case the weight @xmath30 is constant for all components of the same variable .",
    "this result provides a solution to the . for each basic dissimilarity @xmath31 the corresponding optimal leader ,",
    "the leader of the merged clusters , and the dissimilarity @xmath67 between clusters are given in table  [ t : relative ] .",
    "given leaders @xmath68 the corresponding optimal clustering @xmath69 is determined from @xmath70 where @xmath71 .",
    "we assign each unit @xmath1 to the closest leader @xmath72 .    in the case",
    "that some cluster becomes empty , usually the most distant unit from some other cluster is assigned to it . in the current version of r package * clamix",
    "* @xcite the most dissimilar unit from all the cluster leaders is assigned to the empty cluster .",
    "the idea of the agglomerative hierarchical clustering procedure is a step - by - step merging of the two closest clusters starting from the clustering in which each unit forms its own cluster .",
    "the computation of dissimilarities between the new ( merged ) cluster and the remaining other clusters has to be specified .      to obtain the compatibility with the adapted leaders method",
    ", we define the dissimilarity between clusters @xmath34 and @xmath35 , @xmath73 , as @xcite @xmath74    let us first do some general computation . @xmath75 and @xmath76 are @xmath48-th variables of the leaders @xmath77 and @xmath78 of clusters @xmath34 and @xmath35 , and @xmath79 is a component of the leader @xmath80 of the cluster @xmath81 . then    @xmath82 @xmath83   = \\sum_i \\alpha_i d_i(c_u , c_v)\\ ] ] since @xmath73 we have @xmath84 +      \\sum_{x \\in c_v } \\left[d_i(x , z ) - d_i(x , v)\\right ]          = s_{ui } + s_{vi}\\ ] ]",
    "let us expand the first term @xmath85 = \\sum_j s_{uij}\\ ] ]      now we consider a selected basic dissimilarity @xmath57 .",
    "we get ( omitting @xmath86-s ) @xmath87     = \\sum_{x \\in c_u }   w_{x } ( z^2 - 2p_{x } z + 2 p_{x } u -u^2 ) = \\ ] ] as we know ( [ t2 ] ) : @xmath88 @xmath89 therefore @xmath90 @xmath91",
    "@xmath92    we can express the new cluster leader s element @xmath93 also in a different way .",
    "@xmath94 therefore @xmath95 this relation is used in the expression for @xmath96 : @xmath97 @xmath98 @xmath99 and finally , reintroducing @xmath48 and @xmath51 , we get @xmath100 a . note that this relations holds also for singletons @xmath101 or @xmath102 ,   @xmath103 .",
    "[ [ special - cases - of - the - generalized - wards - relation ] ] special cases of the generalized ward s relation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    when @xmath104 is the same for all variables @xmath105 , the ward s relation ( [ wardrel ] ) can be simplified . in this case",
    "we have @xmath106 where the sum of weights @xmath107  is independent of @xmath48 .",
    "therefore we have @xmath108    in the case when for each variable @xmath10 all @xmath109 , further simplifications are possible .",
    "since @xmath110 we get @xmath111 and @xmath112      huygens theorem has a very important role in many fields . in statistics",
    "it can be related to the decomposition of sum of squares , on which the analysis of variance is based . in clustering it",
    "is commonly used for deriving clustering criteria .",
    "it has the form @xmath113 where @xmath114 is the , @xmath115 is the and @xmath116 is the .",
    "let @xmath117 denote the leader of the cluster consisting of all units @xmath0 .",
    "then we define @xcite @xmath118    for a selected dissimilarity @xmath21 and a given set of units @xmath0 the value of total inertia @xmath114 is fixed .",
    "therefore , if huygens theorem holds , the minimization of the within inertia @xmath119 is equivalent to the maximization of the between inertia @xmath116 .    to prove that huygens theorem holds for @xmath55 we proceed as follows .",
    "because of the additivity of @xmath114 , @xmath115 and @xmath116 and the component - wise definition of the dissimilarity @xmath21 , the derivation can be limited only to a single variable and a single component .",
    "the subscripts @xmath48 and @xmath51 are omitted .",
    "we have @xmath120    \\\\              & = & \\sum_{c \\in { \\mathbf{c } } } \\sum_{x \\in c } w_{x } \\left (   -2p_x \\ t_{\\mathbf{u}}+ t_{\\mathbf{u}}^2 + 2p_x \\ t_c + t_c^2    \\right ) \\\\              & =   & \\sum_{c \\in { \\mathbf{c } } } \\left ( -2 w_c \\   t_c \\   t_{\\mathbf{u}}+ w_c",
    "\\   t_{\\mathbf{u}}^2 + 2 w_c \\   t_c^2 + w_c \\",
    "t_c^2   \\right ) \\\\             & = & \\sum_{c \\in { \\mathbf{c } } } w_c ( t_c - t_{\\mathbf{u}})^2 = \\sum_{c \\in { \\mathbf{c } } } d(t_c , t_{\\mathbf{u } } ) = bi \\end{aligned}\\ ] ] this proves the theorem",
    ". in the transition from the second line to the third line we considered that for @xmath55 holds ( eq . ( [ t2 ] ) ) @xmath121 .",
    "the proposed methods were successfully applied on different data sets : population pyramids , timss , cars , foods , citation patterns of patents , and others . to demonstrate some of the possible usages of the described methods ,",
    "some results of clustering of selected subset of the european social survey data set are presented .",
    "the data set @xcite is an output from an academically - driven social survey .",
    "its main purpose is to gain insight into behavior patterns , belief and attitudes of europe s populations @xcite .",
    "the survey covers over 30 nations and is conducted biennially .",
    "the survey data for the round 5 ( conducted in 2010 ) consist of 662 variables and include more than 50,000 respondents . for our purposes we focused on the variables that describe household structure : ( a ) the gender of person in household , ( b ) the relationship to respondent in household ( c ) the year of birth of person in household and ( d ) the country of residence for respondent , therefore also the country of the household . from these variables",
    "( the respondent answered the first three questions for every member of his / her household ) symbolic variables ( with counts of household members ) were constructed .",
    "variable @xmath122 was the only numeric variable and therefore a decision had to be made of how to choose the category borders . from the economic point of view categorization into economic groups of working population is the most meaningful , therefore we chose this categorization in the first variant ( @xmath123 according to working population denoted with wp ) .",
    "but since demographic data about age are usually aggregated into five - year or ten - year groups , we also consider ten - year intervals as a second option of a categorization of the age variable ( @xmath124 in 10-year intervals denoted with ag ) .    * @xmath125 : gender ( 2 components ) : + @xmath126 * @xmath127 : categories of household members ( 7 components , respondent constantly 1 ) : + @xmath128 * @xmath129 : year of birth for every household member : * * @xmath130 : according to working population ( 5 components ) : + @xmath131 + or * * @xmath132 : 10-year groups ( 10 components ) : + @xmath133 * @xmath134 : country of residence ( 26 components , all but one with value zero ) : + @xmath135    there were 641 respondents with missing values at year of birth therefore it seemed reasonable to add the category na to variable @xmath122 .",
    "that variant of handling missing values is very naive and could possibly lead to biased results ( i.e. it could be conjectured that birth years of very old or non - related family members are mostly missing so they could form a special pattern ) .",
    "a refined clustering analysis would better use one of the well known imputation methods ( e.g. multiple imputation , @xcite ) . note that for each unit ( respondent ) in the data set the components of variables @xmath136 to @xmath122 sum into a constant number ( the number of all household members of that respondent ) . for the last variable @xmath137",
    ", the sum equals 1 .",
    "design and population weights are supplied by the data set for each unit  respondent . in order to get results that are representative of the eu population , both weights should be used also for households . because special weights for households are not available , we used weights provided in data set in our demonstration : each unit s ( respondent s ) symbolic variables were before clustering multiplied by design and population weight .",
    "@xmath138 ( used in the clustering process ) for variables @xmath136 to @xmath122 was then the number of household members multiplied by both supplied weights and for @xmath137 the product of both weights alone .",
    "our motivation for clustering this data set was the question what are the main european household patterns ? and further , does the categorization of ages of people from households influence the outcome of best clustering results a lot ? to answer this part , two data sets with different variable sets were constructed : ( a ) data set with ages according to working population ( further denoted as variable set wp ) and ( b ) with ages split in nine 10-year groups ( further denoted as variable set ag ) .",
    "clustering was done on the three variables ( gender , category of household members and age - groups of household members ) .    since we were interested",
    "also whether the household patterns differ according to countries , we inspected variable country after clustering .",
    "however this does not answer the following question _ does the country influence the household patterns ? _ to be able to say something about that , country has to be included in the data set and a third clustering on data with all four variables was performed .",
    "the set of units is relatively large  50,372 units .",
    "therefore the clustering had to be done in two steps :    1 .",
    "cluster units with non - hierarchical leaders method to get smaller ( 20 ) number of clusters with their leaders ; 2 .",
    "cluster clusters from first point ( i.e. leaders ) using hierarchical method to get a small number of final clusters .",
    "the methods are based on the same criterion function ( minimization of the cluster errors based on the generalized squared euclidean distance with @xmath139 ) .",
    "10 runs of leaders clustering were run for each data set ( two data sets with three variables and one with four variables ( including country ) ) .",
    "the best result ( 20 leaders ) of them for each data set was further clustered with hierarchical clustering . the dendrogram and final clusters were visually evaluated . where variable country was not included in the data set it was plotted later for each of the four groups and its pattern was examined .",
    "generally more runs of leaders algorithm are recommended . since this example serves as an illustrative case and in ten runs the result",
    "was shown to be very stable we used ten runs only , but in actual application more runs of the leaders method would be recommended .",
    "the number of final clusters was selected with eyeballing the dendrogram selecting to cut where dissimilarity among clusters had the highest jump ( apart from clustering in only two groups ) .",
    "the results were very stable . in figure",
    "[ f : dendro rgy4 ] the dendrogram on the best leaders ( with minimal leaders criterion function ) for the variable set wp with ages according to working population @xmath140 is presented .",
    "for other two clusterings , i.i.e.e .",
    "for the variable set ag with 10-year age groups @xmath141 and the variable set co with country included @xmath142 the dendrograms look similar and are not displayed .",
    "the variable distributions of the final clusters are presented on figure [ f : var rgy4 ] for the variable set wp , on figure [ f : var rgy9 ] for the variable set ag , and on figure [ f : var rgyc9 ] for the variable set with co.    there is one large ( @xmath143 with 24,049 households ) , one middle sized ( @xmath144 with 11,909 households ) and two small clusters ( @xmath145 with 7,134 and @xmath146 with 7,280 households ) in the result for the variable set wp . for the variable set ag , three relatively medium size clusters ( @xmath147 with 12,658 , @xmath148 with 14,975 , and @xmath149 with 15,800 households ) and a small one ( @xmath150 with 6,939 households ) were detected .    inspecting variable distributions",
    ", one can see ( as expected ) that gender is not a significant separator variable .",
    "the other two variables however both reveal household patterns . from figure  [ f : var rgy4 ] and figure  [ f : var rgy9 ] we see that most of the patterns can be matched between the clustering results with wp ( working population age groups ) and ag ( 10-year age groups ) : @xmath146 with @xmath150 ; @xmath143 with @xmath149 ; cluster @xmath148 is split into two clusters in the wp clustering @xmath145 and @xmath144 .",
    "we see that @xmath147 would fit well with @xmath143 too which is not surprising because the working population category is very broad ( it includes 30 years , so three to four 10-year age groups ) .",
    "the differences in clustering results are observed due to different categorization .",
    "the wp categorization reveals less due to less categories , however it does show the separation of two household patterns where mostly two people ( couples ) live , @xmath145 and @xmath144 .",
    "some are still at work and the others ( that sometimes live with some other family member ) are already retired .",
    "ag categorization puts these two groups in the same cluster @xmath148 .",
    "we see that those still at work are actually near retirement ( they are about 5060 years old ) and they naturally fall into the same group .",
    "ag categorization on the other hand due to more age categories shows some more difference in the case of relationship patterns ( a ) _ respondent - parent - sibling _ , @xmath150 , and ( b ) _ respondent - partner - offspring _ ,",
    "these two relationship patterns reveal core families with ( a ) a respondent being in his / hers twenties and ( b ) a respondent being around 3050 years old . in these two types of families @xmath150",
    "are about 10 to 15 years older than @xmath149 .",
    "the cluster @xmath147 however shows additional pattern that wp categorization does not reveal  the extended families with more females and a very specific household age pattern .",
    "considering also supplementary variable country which was not included in the these two clusterings ( figure [ f : ctry rgy9 ] ) we found that household pattern @xmath147 ( extended family ) has the largest percentage in ukraine , russian federation , bulgaria and poland . @xmath150 with younger questionnaire respondent in the core family is relatively most frequent in israel , slovenia , spain and czech republic and with older respondent , @xmath149 , in the netherlands , greece , spain and norway .",
    "respondents living in mostly two - person families are most frequently interviewed in finland , sweden , denmark and portugal .",
    "since ess is one of the surveys that should represent the whole population the very large ( and very small ) relative values for country should exhibit a kind of household pattern that can be observed in each country ( i.e. large families in russian federation , spain and ukraine ) .         with 7,134 , @xmath143 with 24,049 , @xmath146 with 7,280 , and @xmath144 with 11,909 households ) with working population age groups .",
    "]     with 14,975 , @xmath150 with 6,939 , @xmath149 with 15,800 , and @xmath147 with 12,658 households ) with 10-year age categories . ]        these differences should be even more pronounced when country is included in the clustering process .",
    "the best clustering split the data set co ( with included additional variable country ) into one very large cluster ( @xmath151 with 27,759 households ) , one medium sized ( @xmath152 with 14,488 households ) and two small clusters ( @xmath153 with 2,120 and @xmath154 with 6,005 households ) . figures [ f : ctry rgyc9 ] and [ f : var rgyc9 ] show the results .",
    "note that for easier observation scales for percentages in the horizontal coordinates are different .",
    "immediately we can notice the cluster @xmath153 with dominating extended families in russian federation .",
    "this cluster is also the smallest .",
    "the largest cluster @xmath151 ( core family with small proportion of other members in the household ) is most evenly distributed among countries , but most pronounced in ukraine and spain .",
    "shares in the second smallest cluster @xmath154 with core families and younger respondent are still large in israel , slovenia , czech republic but now also for poland and croatia .",
    "we could conjecture that in these countries offspring stay with parents long before becoming independent .",
    "the cluster @xmath152 belongs to older two- to three - person families with large proportions of german , finnish , swedish and danish households .",
    "this type of households is the least evenly distributed among countries .",
    "in the paper versions of well known leaders nonhierarchical and ward s hierarchical methods , adapted for modal valued symbolic data , are presented .",
    "since the data measured in traditional measurement scales ( numerical , ordinal , categorical ) can all be transformed into modal symbolic representation the methods can be used for clustering data sets of mixed units .",
    "our approach allows the user to consider , using the weights , also the original frequency information .",
    "the proposed clustering methods are compatible  they solve the same optimization problem and can be used each one separately or in combination ( usually for large data sets ) .",
    "the optimization criterion function depends on a basic dissimilarity @xmath31 that enables user to specify different criteria . in principle , because of the additivity of components of criterion function , we could use different @xmath31s for different symbolic variables .",
    "presented methods were applied on the example of household structures from the ess 2010 data set .",
    "the clustering was done on nominal ( gender , relationships , country ) and interval data ( age groups ) .",
    "when clustering such data information on size ( which is important when design and population weights have to be used to get the sample representative of a population ) was included into the clustering process .",
    "the proposed approach is partially implemented in the r - package * clamix * @xcite .",
    "anderberg ,  m.r .",
    "( 1973 ) , _ cluster analysis for applications_. academic press , new york    batagelj ,  v. ( 1988 ) , generalized ward and related clustering problems , _ classification and related methods of data analysis h.h .",
    "bock ( editor ) _",
    ", p. 67 - 74 , north - holland , amsterdam + batagelj ,  v. and kejar ,  n. , clamix  clustering symbolic objects . program in r ( 2010 ) + https://r-forge.r-project.org/projects/clamix/    bock ,  h.  h. , diday ,  e. ( editors and coauthors ) ( 2000 ) , analysis of symbolic data .",
    "exploratory methods for extracting statistical information from complex data .",
    "springer , heidelberg    billard ,  l. , diday ,  e. ( 2003 ) , from the statistics of data to the statistics of knowledge : symbolic data analysis , jasa .",
    "journal of the american statistical association , 98 , 462 , p. 470",
    "- 487    billard ,  l. , diday ,  e. ( 2006 ) , symbolic data analysis .",
    "conceptual statistics and data mining .",
    "wiley , chichester    de carvalho ,  f.a.t .",
    ", brito ,  p. , bock ,  h - h .",
    "( 2006 ) , dynamic clustering for interval data based on l2 distance , computational statistics , 21 , 2 , p. 231 - 250",
    "de carvalho ,  f.a.t . , sousa ,  r.m.c.r .",
    "( 2010 ) , unsupervised pattern recognition models for mixed feature - type symbolic data , pattern recognition letters , 31 , p. 430 - 443 .",
    "diday ,  e. and noirhomme - fraiture ,  m. ( 2008 ) , symbolic data analysis and the sodas software .",
    "wiley , chichester    diday ,  e. ( 1979 ) , optimisation en classification automatique , tome 1.,2 .. inria , rocquencourt ( in french )    ess round 5 : european social survey round 5 data ( 2010 ) , _ data file edition 2.0 .",
    "norwegian social science data services _ , norway  data archive and distributor of ess data ess website , http://www.europeansocialsurvey.org/ , last accessed : 27th september , 2012    everitt ,  b.s . , landau ,  s. , leese ,  m. ( 2001 ) , cluster analysis , fourth edition .",
    "arnold , london    gowda ,  k.  c. , diday ,  e. ( 1991 ) , symbolic clustering using a new dissimilarity measure , pattern recognition , 24 , 6 , p. 567",
    "- 678    hartigan ,  j.  a. ( 1975 ) , clustering algorithms , wiley - interscience , new york    ichino ,  m. , yaguchi ,  h. ( 1994 ) , generalized minkowski metrics for mixed feature type data analysis , ieee transactions on systems , man and cybernetics , 24 , 4 , p. 698",
    "- 708    irpino ,  a. , verde ,  r. ( 2006 ) , a new wasserstein based distance for the hierarchical clustering of histogram symbolic data , data science and classification , p. 185 - 192",
    "irpino ,  a. , verde ,  r. , de carvalho ,  f.a.t .",
    "( 2014 ) , dynamic clustering of histogram data based on adaptive squared wasserstein distances . _ expert systems with applications_. vol .",
    "3351 - 3366 .",
    "kim ,  j. and billard ,  l. ( 2011 ) , a polythetic clustering process and cluster validity indexes for histogram - valued objects , computational statistics and data analysis , 55 , p. 2250 - 2262",
    "kim ,  j. and billard ,  l. ( 2012 ) , dissimilarity measures and divisive clustering for symbolic multimodal - valued data , computational statistics and data analysis , 56 , 9 .",
    "- 2808    kim ,  j. and billard ,  l. ( 2013 ) , dissimilarity measures for histogram - valued observations , communications in statistics : theory and methods , 42 , 2    kejar ,  n. , korenjak - erne ,  s. , and batagelj ,  v. ( 2011 ) , clustering of distributions : a case of patent citations , _ journal of classification _",
    ", 28 , 2 , p. 156",
    "- 183    korenjak - erne , s. , batagelj , v. ( 1998 ) , clustering large data sets of mixed units . in : _ rizzi , a. , vichi , m. , bock , h - h .",
    "( eds . ) .",
    "6th conference of the international federation of classification societies ( ifcs-98 ) universit `` la sapienza '' , rome , 21 - 24 july , 1998 .",
    "advances in data science and classification _ , p. 43 - 48 , springer , berlin    korenjak - erne , s. , batagelj , v. ( 2002 ) , symbolic data analysis approach to clustering large datasets , in : _",
    "jajuga , k. , sokoowski , a. , bock , h - h .",
    "( eds . ) .",
    "8th conference of the international federation of classification societies , july 16 - 19 , 2002 , cracow , poland , classification , clustering and data analysis _ ,",
    "p. 319 - 327 , springer , berlin    korenjak - erne , s. , batagelj , v. , japelj pavei , b. ( 2011 ) , clustering large data sets described with discrete distributions and its application on timss data set .",
    "_ , 4 , 2 , p. 199",
    "- 215    korenjak - erne , s. , kejar ,  n. , batagelj , v. ( 2015 ) , a weighted clustering of population pyramids for the world s countries , 1996 , 2001 , 2006 . _ population studies _ , 69 , 1 , p. 105",
    "- 120    komelj ,  k. and billard ,  l. ( 2011 ) , clustering of population pyramids using mallows l2 distance , metodoloki zvezki , 8 , 1 , p. 1",
    "- 15    noirhomme - fraiture ,  m. , brito ,  p. ( 2011 ) , far beyond the classical data models : symbolic data analysis , statistical analysis and data mining , 4 , 2 , p. 157",
    "- 170    rubin ,  d.b .",
    "( 1987 ) , multiple imputation for nonresponse in surveys .",
    "new york , wiley    verde ,  r. , de carvalho ,  f.  a.  t. and lechevallier ,  y. ( 2000 ) , a dynamic clustering algorithm for multi - nominal data . in data",
    "analysis , classification , and related methods .",
    "kiers , h.a.l . , rasson , j .-",
    ", groenen , p.j.f . ,",
    "schader , m. ( eds . ) , springer , berlin    verde ,  r. , irpino ,  a. ( 2010 ) , ordinary least squares for histogram data based on wasserstein distance . in proc .",
    "compstat2010 , p. 581 - 589 , springer - verlag , berlin heidelberg    ward ,  j.  h. ( 1963 ) , hierarchical grouping to optimize an objective function , journal of the american statistical association , 58 , p. 236244",
    "in this appendix we present derivations of entries @xmath155 , @xmath93 and @xmath156 from table  [ t : relative ] for different basic dissimilarities @xmath31 .    since in our approach",
    "the clustering criterion function @xmath14 is additive and the dissimilarity @xmath21 is defined component - wise , all derivations can be limited only to a single variable and a single its component .",
    "therefore , the subscripts @xmath48 ( of a variable ) and @xmath51 ( of a component ) will be omitted from the expressions .    in derivations we are following the same steps as we used for @xmath55 in section  2 .",
    "to obtain the component @xmath155 of representative of cluster @xmath19 we solve for a selected @xmath31 the one dimensional optimization problem ( [ leaderopt ] ) .",
    "let us denote its criterion function with @xmath157 @xmath158 then the optimal solution is obtained as solution of the equation @xmath159      finally , to determine the between cluster dissimilarity @xmath156 for a selected @xmath31 we will use the relation ( [ eqduv ] ) and following the scheme for @xmath55 the auxiliary quantity @xmath161 from ( [ su ] ) ( after omitting indices @xmath48 and @xmath51 )      for different combinations of the weights used in the expressions , the abbreviations @xmath163 and @xmath164 from table  [ t : relative ] are used .",
    "note that for @xmath165 and @xmath73 , we have @xmath166 , for @xmath167 .      * the derivation of the leader @xmath169 : * in this case @xmath170 the leader s component is determined with @xmath171 * the derivation of the leader @xmath93 of the merged disjoint clusters @xmath34 and @xmath35 : * from the eq .",
    "( [ eqtc2 ] ) and @xmath73 follows @xmath172 * the derivation of the dissimilarity @xmath156 between the disjoint clusters @xmath34 and @xmath35 : * since @xmath173 is the leader of the cluster @xmath34 it holds @xmath174 ( see eq .",
    "( [ eqtc2 ] ) ) .",
    "we can replace @xmath175 in the expression @xmath161 ( eq .",
    "( [ suij ] ) ) @xmath176\\ ] ] with @xmath177 and get @xmath178 similary @xmath179 . combining both expressions ( eq .",
    "( [ suv ] ) ) we get @xmath180      * the derivation of the leader @xmath169 : * in this case @xmath182 the square of the leader s component is determined with @xmath183 and from it @xmath184 * the derivation of the leader @xmath93 of the merged disjoint clusters @xmath34 and @xmath35 : * from eq .",
    "( [ eqtc3 ] ) and @xmath73 follows @xmath185 * the derivation of the dissimilarity @xmath156 between the disjoint clusters @xmath34 and @xmath35 : * since @xmath173 is the leader of the cluster @xmath34 and @xmath186 ( see eq .",
    "( [ eqtc3 ] ) ) , we can replace @xmath175 in the expression @xmath161 @xmath187\\ ] ] with @xmath188 and get @xmath189 similary @xmath190 . combining both expressions",
    "we get @xmath191      * the derivation of the leader @xmath169 : * in this case @xmath193 for @xmath194 ( this is also the condition for @xmath195 to be defined ) , the leader s component is determined with @xmath196 in the case @xmath197 we set @xmath198 and @xmath199 .    * the derivation of the leader @xmath93 of the merged disjoint clusters @xmath34 and @xmath35 : * from eq .",
    "( [ eqtc4 ] ) and @xmath73 follows @xmath200 * the derivation of the dissimilarity @xmath156 between the disjoint clusters @xmath34 and @xmath35 : * since @xmath173 is the leader of the cluster @xmath34 and @xmath201 ( see eq .",
    "( [ eqtc4 ] ) ) , we can replace @xmath202 in the expression @xmath161 @xmath203\\ ] ] with @xmath204 and get @xmath205 similary @xmath206 . combining both expressions",
    "we get @xmath207      * the derivation of the leader @xmath169 : * in this case @xmath209 for @xmath194 ( this is also the condition for @xmath210 to be defined ) , the leader s component is determined with @xmath211 in the case @xmath197 we set @xmath198 and @xmath212 .",
    "* the derivation of the leader @xmath93 of the merged disjoint clusters @xmath34 and @xmath35 : * from eq .",
    "( [ eqtc5 ] ) and @xmath73 follows @xmath213 * the derivation of the dissimilarity @xmath156 between the disjoint clusters @xmath34 and @xmath35 : * since @xmath173 is the leader of the cluster @xmath34 and @xmath214 ( see eq .",
    "( [ eqtc5 ] ) ) , we can replace @xmath215 in the expression @xmath161 @xmath216\\ ] ] with @xmath217 and get @xmath218 similary @xmath219 . combining both expressions we get @xmath220      * the derivation of the leader @xmath169 : * in this case @xmath222 for @xmath194 ( this is also the condition for @xmath223 to be defined ) , the leader s component is determined with @xmath224 and from it @xmath225 in the case @xmath197 we set @xmath198 and @xmath226 .    * the derivation of the leader @xmath93 of the merged disjoint clusters @xmath34 and @xmath35 : * from eq .",
    "( [ eqtc6 ] ) and @xmath73 follows @xmath227 * the derivation of the dissimilarity @xmath156 between the disjoint clusters @xmath34 and @xmath35 : * since @xmath173 is the leader of the cluster @xmath34 and @xmath228 ( see eq .",
    "( [ eqtc6 ] ) ) , we can replace @xmath229 in the expression @xmath161 @xmath230\\ ] ] with @xmath231 and get @xmath232 similary @xmath233 .",
    "combining both expressions we get @xmath234"
  ],
  "abstract_text": [
    "<S> symbolic data analysis is based on special descriptions of data  symbolic objects ( so ) . such descriptions preserve more detailed information about units and their clusters than the usual representations with mean values . </S>",
    "<S> a special kind of symbolic object is a representation with frequency or probability distributions ( modal values ) . </S>",
    "<S> this representation enables us to consider in the clustering process the variables of all measurement types at the same time . in the paper a clustering criterion function for sos is proposed such that the representative of each cluster is again composed of distributions of variables values over the cluster . </S>",
    "<S> the corresponding leaders clustering method is based on this result . </S>",
    "<S> it is also shown that for the corresponding agglomerative hierarchical method a generalized ward s formula holds . </S>",
    "<S> both methods are compatible  they are solving the same clustering optimization problem . </S>",
    "<S> + the leaders method efficiently solves clustering problems with large number of units ; while the agglomerative method can be applied alone on the smaller data set , or it could be applied on leaders , obtained with compatible nonhierarchical clustering method . </S>",
    "<S> such a combination of two compatible methods enables us to decide upon the right number of clusters on the basis of the corresponding dendrogram . + </S>",
    "<S> the proposed methods were applied on different data sets . in the paper , </S>",
    "<S> some results of clustering of ess data are presented . </S>"
  ]
}