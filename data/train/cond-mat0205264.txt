{
  "article_text": [
    "the potential resolution of monte carlo ( mc ) computer simulations has increased substantially over the past few years.@xcite this has been due , in part , to the dramatic rise in the performance of computers , but , more importantly , to the development of more powerful data analysis and computer simulation techniques.@xcite histogram methods allow us to extract much more information from simulation data than was previously possible.@xcite by providing the ability to continuously vary the temperature or other intensive parameters of a simulation , these techniques have greatly simplified the analysis of simulation data by traditional means and , in addition , have also played an important role in the development of new methods of analyzing simulation data.@xcite these methods are most effective when very large numbers of spin configurations have been generated , and it is the common belief that the number needed is enlarged by correlations between successive states.@xcite more recently , a new generation of algorithms to calculate the density of states accurately via a random walk in energy space have been devised for producing canonical averages of thermodynamical quantities at essentially any temperature .",
    "@xcite simulation techniques have also improved immensely .",
    "fast implementations of local update ( metropolis@xcite ) algorithms have been developed for a variety of models , while cluster - flipping algorithms @xcite , which can dramatically reduce the correlation time in a simulation , now exist for several classes of models .    a different approach to increasing the performance of computer simulations is to combine several different algorithms into a single , hybrid algorithm .",
    "this idea is not new ; hybrid monte carlo@xcite , hybrid molecular dynamics@xcite , metropolis with overrelaxation@xcite and multi - hit swendsen - wang@xcite are some examples of hybrid algorithms . in these cases , however , the two algorithms that are combined perform the simulation in different ensembles , either canonical / microcanonical or canonical / fixed - cluster - distribution . the approach we consider here is to combine algorithms that work in the same ensemble , for our examples the canonical ensemble , so that each of the individual component algorithms is a self - sufficient simulation technique .",
    "this eliminates any concerns about how the mixing of ensembles could potentially affect the quality or correctness of the results .",
    "we will , however , discuss the generalization of these `` proper '' hybrid algorithms to include mixed - ensemble cases .",
    "our aim in this work is two - fold .",
    "we first discuss , in the next section , the efficiency of a general hybrid algorithm and show how it can be improved in the case when wolff plus metropolis is applied to the spin-1/2 two - dimensional ising model .",
    "second , in section iii , we apply a hybrid algorithm to the spin-3/2 two - dimensional ising model for which a correct single cluster algorithm is not immediately obvious since the simple version does not take into account transitions between states having different spin moduli ( for instance , transitions between @xmath0 and @xmath1 spin values ) . further discussion and some concluding remarks are given in the last section .",
    "consider a mc study of some model in which @xmath2 measurements of some observable quantity @xmath3 ( energy , magnetization , susceptibility , cumulants , @xmath4 ) are made , and for which there exist several different algorithms that could be used to perform the simulation . in order to compare the efficiency of the different techniques",
    ", one needs to know both the speed with which measurements are made and the degree to which successive measurements are correlated.@xcite for this section , we will define the efficiency @xmath5 for an algorithm as @xmath6 where the integrated autocorrelation time @xmath7 is given by @xmath8 with the time - displaced correlation function @xmath9 for the quantity @xmath3 calculated as @xmath10 note that the correlation time , and therefore the efficiency of an algorithm , can depend strongly on the particular quantity @xmath3 measured .",
    "now consider a hybrid simulation algorithm that combines several different component algorithms .",
    "to set up some notation , let @xmath11 represent the number of different algorithms used , @xmath12 the number of measurements made with simulation technique @xmath13 and @xmath14 the time ( in seconds ) required for performing the update and making a measurement for technique @xmath13 .",
    "this time will , of course , depend strongly on the implementation of the algorithms and the particular computers on which they are run .    the time in seconds needed to produce a measurement using the hybrid algorithm is @xmath15 so that the efficiency of the hybrid algorithm becomes @xmath16",
    "please note that the correlation time , and therefore the efficiency , of the algorithm will depend on its specific implementation .",
    "for example , in a hybrid algorithm consisting of two components , @xmath17 and @xmath18 , the correlation time for the sequence @xmath19 would , most likely , be different from the sequence @xmath20 which of the two would produce the smaller correlation time would depend on the dynamics ( kinetics ) of the individual algorithms .",
    "we now demonstrate the development of the above hybrid algorithms by considering a specific example , the spin -1/2 nearest - neighbor square - lattice ising model at its critical temperature , @xmath21 . the ising model has traditionally been used to test new simulation algorithms and data analysis techniques because of its simplicity and the exact finite and infinite - system solutions in the two - dimensional model.@xcite because of the large amount of work done with the ising model ,",
    "there exist several different simulation algorithms for it .",
    "these can be broken up into two major classes : 1 ) single - spin update algorithms , including metropolis , heat bath and microcanonical algorithms , and 2 ) cluster algorithms , including the swendsen - wang@xcite and wolff algorithms.@xcite we will concentrate on two of these algorithms@xcite : metropolis@xcite and wolff@xcite .",
    "each of these algorithms has its strengths and weaknesses .",
    "the metropolis algorithm is very efficient at equilibrating short - range fluctuations in the system , and there exist highly - optimized multi - spin coding implementations of the metropolis algorithm.@xcite unfortunately , the metropolis method is not efficient at decorrelating the long - range clusters that characterize the behavior of the system near the critical point .",
    "the wolff algorithm , on the other hand , concentrates its effort on the large clusters leading to greatly reduced correlation times and a much smaller dynamic critical exponent @xmath22 .",
    "however , smaller - scale structures in the system , in particular regions of disorder , are not handled efficiently by the wolff algorithm .",
    "the speed of the wolff algorithm , based on the number of spins updated per second , is also lower for wolff than for multi - spin coding implementations of metropolis . because of the wolff algorithm s smaller dynamic exponent",
    ", it is clear that it will become more efficient than metropolis for sufficiently large lattices ; however , `` sufficiently large '' might well be larger than the range of sizes of interest in a particular study .",
    "work by ito and kohring@xcite estimates that metropolis remains more efficient than wolff , in terms of independent measurements per second , for system sizes as large as @xmath23 in two dimensions and @xmath24 in three dimensions ( running on a scalar workstation ) .",
    "this is , of course , strongly dependent on the type of computer and the particular implementation of the algorithms used .",
    "for example , with the programs , algorithms and computers used in this study , we estimate that wolff becomes more efficient than metropolis for @xmath25 for @xmath26 and @xmath27 for @xmath28 .",
    "another concern with the wolff algorithm is its sensitivity to flaws in the random number generator used in the simulation .",
    "small but significant systematic deviations from the exactly - known answer in the @xmath29 ising model and other systems have been reported and investigated@xcite-@xcite using a variety of popular random number generators.@xcite-@xcite while the results of any simulation method can be biased by subtle correlations in the random numbers@xcite , the wolff algorithm was found to be particularly susceptible . despite these concerns about the wolff algorithm ,",
    "the dramatic reduction in the correlation time is a very tantalizing effect . if the speed and efficiency at equilibrating small - scale structures of the metropolis algorithm is combined with the strength in decorrelating large - scale structures of the wolff algorithm , the resulting hybrid algorithm could , in fact , be more efficient than either metropolis or wolff individually .    to test this possibility",
    ", we implemented a scalar hybrid algorithm which combines the metropolis and wolff algorithms .",
    "simulations were performed on ibm risc/6000 , dec alpha , pc linux and sgi power challenge workstations .",
    "the spins were stored as bit variables , with up to 32 spin variables packed into a single computer word.@xcite note that the metropolis algorithm can take advantage of this packing arrangement by effectively updating many spins in parallel using multi - spin coding techniques . this will result in substantial improvement in performance for increasing system size until all 32 bits are filled ( for @xmath30 in this implementation ) . while the wolff algorithm can not make full use of the multi - spin coding , it does benefit from the smaller memory requirements of the packed - spin representation .",
    "( smaller memory means that more of the system can be stored in the computer s cache memory which results in much better performance . )",
    "the random number generators used for the simulation must be chosen with great care , especially for the wolff algorithm.@xcite after performing extensive tests of several generators , we selected the following as being the fastest random number generators that would give us the correct answer within the precision of our testing .",
    "for the wolff algorithm , we used a combination generator by lecuyer@xcite that was recommended as a `` perfect '' random number generator in the numerical recipes column in computers in physics.@xcite with this program , we can produce a random number in 840.2 nsec on an sgi power challenge workstation with a 194 mhz r10000 processor . for the metropolis part of the simulation",
    ", we used a faster , shift - register generator , r1279 , which can produce a random number in 21.4 nsec.@xcite    to see how the hybrid algorithm behaves when poor random numbers are used , we ran a series of simulations deliberately using a bad random number generator for the wolff algorithm .",
    "we thus used the r250 shift - register generator@xcite which is known to introduce significant systematic errors for the d=2 ising model.@xcite we performed hybrid updates consisting of one wolff update followed by 0 , 1 , 2 , 3 and 4 metropolis updates .",
    "( a simulation consisting of only metropolis was also performed for completeness . ) for each hybrid , 16 independent simulations consisting of @xmath31 hybrid steps were performed .",
    "the results for @xmath32 are shown in fig .",
    "[ fig1 ] for the energy and specific heat . for the internal energy the wolff algorithm yields the wrong answer by an amount which is more than 35 times the calculated error bar . with the inclusion of @xmath33 of metropolis",
    "flips this error is reduced by a factor of 10 , and with @xmath34 metropolis flips , no discernible error is seen .",
    "very much the same behavior is seen in the specific heat , although the rate of convergence to the correct answer is slightly different .",
    "not only are the results like to be more correct if the different flipping mechanisms are mixed , but the performance is also improved . for the magnetization the relative efficiency of the hybrid algorithm , with @xmath35 metropolis flips added , is about @xmath36 greater than for wolff alone , as can be seen from fig .",
    "it is surprising that even for @xmath37 , where the metropolis algorithm is much less efficient than the wolff algorithm , the hybrid is significantly * more * efficient .",
    "although for pure metropolis , the relative performance becomes markedly worse as the lattice size increases , the same is not true for the hybrid algorithm . for the internal energy the relative efficiency ,",
    "also shown in fig .",
    "[ fig2 ] , is much better still for the hybrid algorithm , by more than a factor of two .",
    "for models with higher values of spin , not only are monte carlo simulations , as well as specific algorithms , less ubiquitous than for their two - state counterpart , but no exact solution is still available for their critical temperatures .",
    "thus , the basic ideas of the last section need to be extended to more general models , e.g. the spin-@xmath38 ising model , where each spin state can assume values @xmath39 .",
    "although some spin-@xmath17 @xcite-@xcite and spin-@xmath38 @xcite-@xcite models have already been studied through metropolis technique and cluster spin - flipping @xcite , there is still a lack of a detailed analysis of the statistical and systematic errors even in the simple ising limit .",
    "so , before starting to implement a hybrid algorithm to this model it is interesting to see first what one gets with single - spin flipping procedures .    to analyse the statistical errors of some observable thermodynamic quantity @xmath3 we first applied just the metropolis algorithm to the spin-@xmath38 ising model .",
    "we ran @xmath40 monte carlo steps ( mcs ) per spin with @xmath41 configurations discarded for thermalization on different lattice sizes @xmath42 ( @xmath43 ) and using the `` perfect '' random - number generator.@xcite we measured the energy @xmath44 , magnetization @xmath45 , fourth - order cumulant of the magnetization @xmath46 and the quadrupole moment @xmath47 ( the mean value of the square of the spins ) .",
    "typical results of the relative error @xmath48 for different lattice sizes @xmath42 are shown in fig .",
    "[ fig5 ] at @xmath49 , a value close to the critical temperature . using coarse - graining @xcite",
    "we have estimated @xmath50 through @xmath51 for large enough @xmath2 , where we divided our data into @xmath52 bins of different lengths @xmath53 ( @xmath53 ranging from @xmath54 to @xmath55 ) . the relative error in the magnetization and its cumulant increases as @xmath42 increases while for the energy and the quadrupole moment it stays almost constant . in terms of different degrees of self - averaging , @xmath45 and @xmath46",
    "are non - self - averaging while @xmath44 and @xmath47 exhibit a lack of self - averaging ( the number of ` effectively ' independent measurements through the computation of the correlation time @xmath56 is certainly necessary @xcite for a more detailed analysis of the errors .",
    "this is , however , outside of the scope of the present work ) .",
    "we have also noted no significant changes in the errors by using different random number generators , even taking the poorer congruential one , and the data are also depicted fig .",
    "[ fig6 ] shows the results of the magnetization cumulant @xmath46 as a function of temperature for different mcs for the lattice size @xmath57 . here",
    ", we have used the histogram technique at @xmath58 in order to obtain estimates for other values of temperatures close to @xmath59 .",
    "it is worthwhile to analyse such behavior since we will use the crossings of the cumulants @xmath46 to locate the critical temperature of the present model .",
    "besides having large error bars one can see that the mean value of the cumulant is strongly dependent on the number of mcs used to obtain the statistics .",
    "the dependence with the number of states generated for this lattice size is more pronounced by using the perfect random generator ( note that the mean values of @xmath46 with @xmath60 mcs and perfect generator are comparable to those with @xmath61 mcs and the congruential one ) although both converge to the same limit as the number of mcs gets very large . within the error bars we also notice almost no systematic error due to the use of different random number generators , in contrast to the case of the wolff algorithm which , with a bad random number generator for the spin-1/2 model , gives wrong results for the energy and specific heat ( see fig .",
    "[ fig1 ] ) . the same qualitative behavior of fig .",
    "[ fig6 ] ( large error bars and a strong dependence of the cumulant with the number of mcs ) is also seen for other lattice sizes @xmath42 . even by substantially increasing the mcs per spin one",
    "still gets large errors , mainly for the magnetization and its cumulant ( see also fig .",
    "[ fig5 ] ) .",
    "we show in fig .",
    "[ fig7 ] the reduced pseudo - critical temperature @xmath62 as a function of @xmath63 ( in fact @xmath64 , where @xmath65 for the two - dimensional ising universality class ) obtained from the crossings of the fourth - order cumulant of the magnetization for different values of @xmath42 using just the metropolis algorithm .",
    "each point in that figure represents the crossing point of the cumulant @xmath66 of the lattice size @xmath67 with the corresponding cumulant of the smallest lattice @xmath68 .",
    "only a poor estimate of the critical reduced temperature can be achieved in this case which can be ascribed to the large error bars obtained in computing @xmath66 as well as its strong dependence on the number of mcs taken in the statistics . in particular , we have @xmath69 with perfect and @xmath70 with congruential random number generators which are , even so , comparable to the more recent series expansion result @xmath71.@xcite we can see that , in general , no systematic error due to random number generator is observed for the metropolis algorithm .",
    "moreover , within the error bars , very similar results are also obtained by running the symmetric heat bath single spin - flip procedure .",
    "it is clear that one way to improve the accuracy of the location of the critical temperature with metropolis can be done by increasing the mcs in order to achieve better statistics .",
    "this will require , of course , much more computer time , mainly for large lattice sizes .",
    "we can , however , use the results of the previous section in order to construct a hybrid algorithm where , with not much extra computer time , more precise results could be obtained .",
    "the first step is thus to implement a wolff algorithm for this model . in a straightforward way",
    ", this implementation can be done by activating bonds between parallel nearest - neighbors spins @xmath72 and @xmath73 according to the probability @xmath74 and , when the full cluster has been activated , all its spins are reversed .",
    "this procedure has , however , two main differences regarding the spin-1/2 systems which we have to keep in mind : i ) now , the probability @xmath75 depends on the particular configuration of the parallel spins and can have three possibilities , depending on whether @xmath76 are @xmath77 , @xmath78 and @xmath79 ( and also the corresponding reversed configurations ) ; ii ) this procedure alone is not ergodic in the sense that it does not take into account transitions between spin states with different spin magnitudes ( it keeps fixed the number of @xmath80 and @xmath81 spins in each configuration and , for instance , the quadrupole @xmath82 is always a constant ) .",
    "while the former is just a generalization of the bond probabilities activation for systems with more degrees of freedom , the latter is really a problem since we can not generate all possible configurations for the model .",
    "a mixed cluster algorithm has already been proposed to overcome such a non - ergodicity in the case of the spin-1 blume - emery - griffths model.@xcite however , a natural hybridization procedure , based on the discussion of the last section , and also from embedding algorithms @xcite proposed to study of spin-1 models @xcite can be worked out here by simply alternating one metropolis sweep with @xmath83 wolff steps where @xmath83 , in principle , can depend on the system size .",
    "the inclusion of alternate single spin - flip sweeps will make this hybrid algorithm ergodic and much simpler than a possible generalization of the mixed cluster procedure to the present spin-@xmath38 model . in order to test the efficiency of this hybrid algorithm we have done extensive simulations for the @xmath84 lattice where we can compare the results of the simulations with the exact ones .",
    "we ran a total of @xmath85 hybrid mcs per spins each one including @xmath83 wolffs intercalated by one metropolis sweep .",
    "the results are shown in fig .",
    "[ fig8 ] for the perfect random generator .",
    "one can readily see that all the results are in general compatible to the exact ones within the error bars .",
    "however , by including some wolff steps the mean values initially oscillate for small @xmath83 , have a better agreement for @xmath86 and finally deviate for large @xmath83 .",
    "we also note that the errors are almost the same for @xmath87 and @xmath88 and are slightly smaller around @xmath86 .",
    "the slight deviation of the error as a function of @xmath83 reflects the fact that we have a reasonable number of mcs per spin to obtain a good statistics for this small lattice , even with just the metropolis algorithm ( this is not the case for larger values of @xmath42 , as we shall see below ) .",
    "moreover , the worse results for large values of @xmath83 can be ascribed to the non - ergodicity of the present simple wolff algorithm ( nothing is gained by increasing the number of wolff steps since we get stuck in the configurations having the same number of @xmath80 and @xmath81 spins ) .",
    "the overall picture then suggests the use of this hybrid algorithm with @xmath86 ( although @xmath83 can also vary with @xmath42 ) . in order to test this assumption",
    "we applied this procedure to the @xmath57 lattice ( and close to the critical temperature ) and obtained the magnetization cumulant @xmath46 with @xmath54 wolff steps .",
    "the corresponding results are also shown in fig .",
    "there is , in this case , no sensitive difference in the data by taking @xmath61 or @xmath60 mcs with the hybrid algorithm .",
    "surprisingly , the statistical errors are now almost two orders of magnitude smaller than those with just the metropolis algorithm ( the errors in fig .",
    "[ fig6 ] for @xmath57 are in fact much smaller than the symbol sizes ) . to get this same precision with only metropolis one would have to compute an order of @xmath89 configurations for this lattice size . the relative error of the energy , magnetization and its cumulant , and the quadrupole for other values of @xmath42 are shown in fig . [ fig9 ] .",
    "while now they are almost constant for @xmath45 and @xmath46 ( exhibiting lack of self - averaging ) , they decrease for @xmath44 and @xmath47 ( behaving now as self - averaging quantities ) .",
    "it is also important to notice that the hybridization process is again almost insensitive to the quality of the random number generator .",
    "the above results strongly indicate @xmath90 as a good trial also for other lattice sizes .    in fig .",
    "[ fig10 ] we present the reduced pseudo - critical temperature @xmath62 as a function of @xmath63 obtained from the hybrid algorithm described above with the perfect random generator through the crossings of the fourth - order cumulant of the magnetization @xmath66 .",
    "it was possible , in this case , to get a good resolution from crossings of @xmath91 with three different smaller lattices , namely @xmath68 , @xmath92 and @xmath93 .",
    "the quality of the results are now apparent and yields the extrapolated value @xmath94 . just for completeness , in fig .",
    "[ fig10 ] we also give the corresponding values by taking the congruential generator with the present hybrid algorithm . as it is faster , we were able to use , with the same computing time , lattices as large as @xmath95 to get @xmath96 .",
    "we have then , so far , the best estimate for the critical temperature of the two - dimensional spin-3/2 ising model : @xmath97 .",
    "it is worthwhile now to address some comments regarding the universality of these models .",
    "regardless the number of states each spin can assume , all @xmath98-dimensional systems are in the same ( ising ) universality class .",
    "this fact is apparent in figs .",
    "[ fig7 ] and [ fig10 ] , ( mainly the latter one ) where the temperatures are all along a straight line as a function of @xmath64 with @xmath65 in two dimensions .",
    "however , two more universal quantities can be readily observed from the present simulations .",
    "first , the magnetization fourth - order cumulant @xmath99 at the transition temperature can also be estimated from our data to give @xmath100 , a value expected for @xmath29 ising systems undergoing a second - order phase transition .",
    "this result comes from fig .",
    "[ fig12 ] where each point was obtained by fixing @xmath101 at our estimate @xmath62 and looking the cumulant there for different lattices .",
    "second , a quantity which is studied less often , is the probability distribution of the magnetization @xmath102 , @xmath103 which , for large enough systems at the critical temperature is a universal function.@xcite in this equation @xmath104 is a non - universal constant chosen to give a unity variance for the distribution @xmath105 . fig .",
    "[ fig13 ] shows the fixed - point order parameter distribution for the two - dimensional ising universality class obtained from models with spin-1/2,1,3/2 at the critical temperature and lattice size @xmath106 . for each model",
    "@xmath107 steps were performed with metropolis algorithm and using the r1279 random number generator .",
    "the quality of this match clearly reveals the hallmark of the @xmath105 distribution for the ising universality class .",
    "the results shown in the previous sections supply strong support for the use of hybrid algorithms as a means of effectively speeding up simulations and also improving the quality of the results .",
    "another advantage is that efficient , parallel implementation of the hybrid algorithm on distributed memory machines is straightforward .",
    "a wolff process running on one processor can  feed \" states to other processors which then perform multiple metropolis updates .",
    "the number of metropolis updates can be varied to maximize load balancing .",
    "data are gathered together from all states which have been generated and then used to construct histograms .",
    "this procedure can be enhanced still further by the inclusion of microcanonical updates which require no random numbers !",
    "one hybrid update would then consist of , _",
    "e.g. _ 1 wolff update plus 5 metropolis updates plus 10 microcanonical updates .",
    "although we have described hybrid algorithms for one of the simplest models in statistical mechanics ( ising ) , we believe that the lessons drawn from these studies will be more broadly applicable .",
    "for example , continuous spin systems may be ( randomly ) projected onto ising models which can be easily simulated using these hybrid algorithms .",
    "histogram analysis of the data can also be used in a similar fashion to produce extremely high resolution results .",
    "of course , the relative performance of each component of the hybrid algorithm will depend upon the specific model , so that  tuning \" will be required for each study .",
    "furthermore , these single ensemble hybrid methods can be combined with other algorithms to further improve performance . for the ising model",
    "the microcanonical method is extremely fast and can be easily included . for a classical heisenberg model ,",
    "the over - relaxation method provides an effective microcanonical simulation component to a hybrid algorithm .    in summary",
    ", we have demonstrated that hybrid monte carlo spin - flip algorithms , which include `` slower '' metropolis steps , can be made to be effectively faster than cluster flipping algorithms .",
    "furthermore , and perhaps more significantly , they yield substantially more accurate results than does the simple wolff algorithm ( for the spin-1/2 model ) or single metropolis algorithm because the alternation of updating methods breaks up random number correlations .          , d. p. landau and k. binder , cambridge university press ( cambridge , 2000 ) . , k. binder ed .",
    "( springer , berlin , 1995 ) . r.h .",
    "swendsen , j .- s .",
    "wang and a.m. ferrenberg , `` new monte carlo methods for improved efficiency of computer simulations in statistical mechanics '' in ref .",
    "@xcite and references therein . a.m. ferrenberg and r.h .",
    "swendsen , phys .",
    "* 61 * , 2635 ( 1988 ) ; * 63 * , 1195 ( 1989 ) .",
    "a.m. ferrenberg and d. p. landau , phys .",
    "b * 44 * , 5081 ( 1991 ) . c. holm and w. janke , phys . rev b * 48 * , 936 ( 1993 ) .",
    "k. chen , a.m. ferrenberg and d.p .",
    "landau , phys rev .",
    "b , * 48 * , 3249 ( 1993 ) .",
    "a. m. ferrenberg , d. p. landau , and k. binder , j. stat . phys . * 63 * , 867 ( 1991 ) .",
    "a.m. ferrenberg , d.p .",
    "landau and r.h .",
    "swendsen , phys .",
    "e * 51 * , 5092 ( 1995 ) .",
    "m. c. de oliveira , t. j. p. penna , and h. j. herrmann , braz .",
    "* 26 * , 677 ( 1996 ) ; ibid eur .",
    "j. b * 1 * , 205 ( 1998 ) ; p. m. c. oliveira , eur .",
    "j. b * 6 * , 111 ( 1998 ) .",
    "fugao wang and d. p. landau , phys .",
    "86 * , 2050 ( 2001 ) .",
    "n. metropolis , a.w .",
    "rosenbluth , a.h .",
    "teller and e. teller , j. chem . phys . * 21 * , 1087 ( 1953 ) .",
    "r. h. swendsen and j .- s .",
    "wang , phys .",
    ". lett . * 58 * , 86 ( 1987 ) .",
    "u. wolff , phys .",
    "lett . * 62 * , 361 ( 1989 ) .",
    "s. duane , a.d .",
    "kennedy , b.j .",
    "pendelton , and d. roweth , phys . lett . *",
    "195b * , 216 ( 1987 ) .",
    "heermann , p. nielaba , and m. rovere , comp .",
    ". commun . *",
    "60 * , 311 ( 1990 ) .",
    "brown and t.j .",
    "woch , phys .",
    "58 , 2394 ( 1987 ) .",
    "m. creutz , phys .",
    "d * 36 * , 515 ( 1987 ) .",
    "s. chen , a.m. ferrenberg and d.p .",
    "landau , `` multi - hit swendsen - wang monte carlo algorithm '' in _",
    "computer simulation studies in condensed matter physics , iv _ d.p .",
    "landau , k.k .",
    "mon and h .- b .",
    "schttler , eds .",
    "( springer - verlag , heidelberg , 1993 ) .",
    "a. e. ferdinand and m. e. fisher , phys",
    ". rev . * 185 * , 832 ( 1969 ) .",
    "l. onsager , phys . rev . * 65 * , 117 ( 1944 ) .",
    "note that for the swendsen - wang and metropolis algorithms , one update means one complete update of the lattice ( mcs ) ; in the wolff algorithm , one update is less than one mcs and depends on the temperature . for simulations at @xmath21 , and",
    "the system sizes considered in this study , a wolff update is approximately 0.55  mcs .",
    "landau , `` vectorization of monte carlo programs for lattice models using supercomputers '' in ref .",
    "@xcite , and references therein .",
    "n. ito and g.a.kohring , int .",
    "c5 * , 1 ( 1994 ) .",
    "a. hoogland , j. spaa , b. selman and a. compagner , j. comp . phys . *",
    "51 * , 250 ( 1983 ) .",
    "g. parisi and f. rapuano , phys .",
    "157b * , 301 ( 1985 ) .",
    "a.m. ferrenberg , d.p .",
    "landau , and y.j .",
    "wong , phys .",
    "lett . * 69 * , 3382 ( 1992 ) .",
    "coddington , int j. mod .",
    "c * 5 * , 547= ( 1994 ) .",
    "p. grassberger , phys .",
    "a * 181 * , 43 ( 1993 ) .",
    "i. vattulainen , t. ala - nissila and k. kankaala , phys .",
    "lett * 73 * , 2513 ( 1994 ) ; phys .",
    "e 52 3205 ( 1995 ) .",
    "f. schmid and n.b .",
    "wilding , ing j. mod .",
    "c * 6 * , 781 ( 1995 ) .",
    "a. heuer , b. dnweg and a.m. ferrenberg , comp .",
    ". comm . * 103 * , 1 ( 1997 ) .",
    "g. marsaglia , _ computer science and statistics : the interface _ , ed",
    ". l. billard ( elsevier , amsterdam , 1985 ) .",
    "g. marsaglia , proc .",
    "sci.*61 * , 25 ( 1968 ) .",
    "s. kirkpatrick and e. stoll , j. comp .",
    "phys . * 40 * , 517 ( 1981 ) .",
    "g. marsaglia , b. narasimhan and a. zaman , comp .",
    "comm . * 60 * , 345 ( 1990 ) .",
    "barber , r.b .",
    "pearson , d. toussaint , and j.l .",
    "richardson , phys .",
    "rev . b*32 * , 1720 ( 1985 ) .",
    "p. lecuyer , commun .",
    "acm * 31 * , 742 ( 1988 ) .",
    "w.h . press and s.a .",
    "teukolsky , `` portable random number generators '' in _ computers in physics _ , vol .",
    "5 , 523 ( 1992 ) . because of the sensitivity of the wolff algorithm to small imperfections in the random number generator , it is vital to use a very good generator .",
    "in addition , the lecuyer generator produces one number per call , while our implementation of r1279 produces an entire vector of numbers .",
    "this reduces the computing overhead and thus makes the r1279 generator even faster in comparison .",
    "a. k. jain and d. p. landau , phys .",
    "rev . b*22 * , 445 ( 1980 ) .",
    "d. p. landau and r. h. swendsen , phys .",
    ". lett . * 46 * , 1437 ( 1981 ) . o. f. de alcantara bonfim and c. h. obcemea , z. phys . * b64 * , 469 ( 1986 ) . h. w. j. blte , e. luijten and r. heringa , j. phys .",
    "a : math . gen . * 28 * , 6289 ( 1995 ) .",
    "m. m. tsypin and h. w. j. blte , phys .",
    "e * 62 * , 73 ( 2000 ) .",
    "f. c. s barreto and o. f. de alcantara bonfim , physica * a172 * , 378 ( 1991 ) .",
    "s. bekhechi , a. benyoussef , phys .",
    "b * 56 * , 13954 ( 1997 ) . j. c. xavier , f. c. alcaraz , d. pea lara and j. a. plascak , phys . rev .",
    "b * 57 * , 11575 ( 1998 ) .",
    "d. horvth , a. orendcov , m. orendc , m. jascur , b. brutovsk and a. feher , phys .",
    "b * 60 * , 1167 ( 1999 ) .",
    "j. a. plascak and d. p. landau , springer proceedings in physics , vol .",
    "computer simulation studies in condensed matter physics xii",
    "d. p. landau , s. p. lewis and h .- b .",
    "shttler , springer - verlag berlin heidelberg ( 2000 ) .",
    "m. b. bouabci and c. e. i. carneiro , phys .",
    "b * 54 * , 359 ( 1996 ) . i. jensen , a. j. guttmann and i. g. enting , j. phys.:math gen .",
    "* 29 * , 3805 ( 1996 ) .",
    "r. c. brower and p. tamayo , phys .",
    "lett . * 62 * , 1087 ( 1989 ) .",
    "j. adler and i. g. enting , j. phys . a : math .",
    "* 17 * , l275 ( 1984 ) .",
    "a. d. bruce , j. phys .",
    "c : solid state physics * 14 * , 3667 ( 1981 ) . k. binder , z. phys .",
    "b * 43 * , 119 ( 1981 ) .",
    "d. nicolaides and a. d. bruce , j. phys .",
    "a : math . gen . * 21 * , 233 ( 1988 ) ."
  ],
  "abstract_text": [
    "<S> we show that addition of metropolis single spin - flips to the wolff cluster flipping monte carlo procedure leads to a dramatic * increase * in performance for the spin-1/2 ising model . </S>",
    "<S> we also show that adding wolff cluster flipping to the metropolis or heat bath algorithms in systems where just cluster flipping is not immediately obvious ( such as the spin-3/2 ising model ) can substantially * reduce * the statistical errors of the simulations . </S>",
    "<S> a further advantage of these methods is that systematic errors introduced by the use of imperfect random number generation may be largely healed by hybridizing single spin - flips with cluster flipping .    </S>",
    "<S> 16.5 cm    * cluster hybrid monte carlo simulation algorithms * +    pacs02.70.uu,05.10.ln,05.50.+q,05.70.jk </S>"
  ]
}