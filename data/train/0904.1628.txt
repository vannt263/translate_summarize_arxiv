{
  "article_text": [
    "perhaps the most fundamental problem in quantum statistical inference ( qsi ) is the reconstruction of the density matrix of a quantum system on the basis of a finite number of quantum observations . due to the rapidly growing interest in quantum computation and quantum control ,",
    "the ability to retrieve the maximum amount of information about a quantum state based on the smallest number of measurements is a subject of paramount importance .",
    "the accuracy of all derivative forms of qsi , including process estimation , is ultimately determined by that of the underlying state estimation .",
    "methods for quantum state estimation can be formally subdivided into three categories .",
    "the first , tomographic inversion @xcite , is the least computationally expensive and most popular technique .",
    "however , tomographic inversion can not enforce the constraints on the density matrix during estimation , and hence the estimates produced are often not physically meaningful .",
    "the second class consists of frequentist techniques of inference based on a likelihood function , the most notable of which is maximum likelihood ( ml ) estimation @xcite .",
    "this class of methods avoids the problems associated with tomography and is asymptotically more efficient than the latter ( as explained in section iii e ) .",
    "however , it delivers distributional results for the estimators of the parameters of interest under the assumption of an infinite number of measurements .",
    "hence , for finite sample sizes , the estimated confidence intervals for the parameters may have actual coverages quite different from the corresponding asymptotic ones and , as is well known in the statistics literature , this divergence typically tends to become more pronounced as the number of parameters and nonlinearity of the model increases .",
    "all forms of frequentist inference , including tomographic inversion and ml estimation , require a complete observation level , i.e. @xmath0 linearly independent observable operators where @xmath1 is the hilbert space dimension , in order to estimate all the parameters .",
    "the third type , bayesian estimation @xcite , which is based on updating a prior plausibility distribution of the parameters based on observed data , lends itself readily to both incomplete observation levels and a finite number of measurements .",
    "moreover , the estimation error that arises in bayesian methods is typically lower , reflected in shorter lengths of bayesian confidence intervals compared to their frequentist counterparts , due to the use of such priors .    in this paper",
    ", we investigate the finite sample properties of ml estimators of the density matrix of finite - dimensional , spin-1/2 ( one qubit ) and spin-1 quantum systems . among frequentist estimation techniques",
    ", ml is usually preferred on the basis of its asymptotic properties - ( i ) the ml estimator is asymptotically efficient in the sense that its asymptotic variance achieves the cramer - rao lower bound for consistent estimators , ( ii ) likelihood based testing approaches are optimal , in the sense of the neyman - pearson fundamental lemma and the large deviation principle , for a broad class of hypothesis testing problems",
    ". however , the finite sample properties of ml estimators and test statistics are often less than optimal .",
    "existing literature on quantum ml has not rigorously examined the finite sample performance of the estimators and associated methods of hypothesis testing .",
    "to our knowledge , there is only one extant study on the efficiency of frequentist quantum state estimation @xcite , and robust numerical techniques are lacking .",
    "minimizing finite sample estimation errors is essential for making optimal quantum decisions , which underlie emerging quantum feedback control and computation strategies @xcite .",
    "lack of rigorous understanding of the small sample estimation errors has inhibited the application of ml to practical problems in quantum information and control .",
    "we shed light on the following issues :    * how are the small sample biases of the ml estimators affected by the sample size ? * how do the finite - sample standard errors , and hence the associated @xmath2 confidence intervals , compare to the corresponding asymptotic ones and how does the coverage of the intervals change with increase in the sample size ? * how does the small sample behavior of the test statistics for physical quantities of interest in quantum decision theory compare to their known asymptotic behavior for different sample sizes ?",
    "we show that the finite sample properties of ml differ significantly from the corresponding asymptotic ones for experimentally realistic sample sizes .",
    "in particular , the finite - sample standard errors are orders of magnitude bigger than the corresponding asymptotic ones .",
    "this feature holds for sample sizes approaching the limit of experimental feasibility .",
    "consequently , the asymptotic confidence intervals grossly undercover in finite samples and the test statistics exhibit severe size distortions .",
    "in addition , the assessment of the estimation error in qsi is complicated by the existence of multiple measurement strategies due to the noncommutativity of the probability space , and ambiguities regarding the optimal measurement strategy .",
    "we compare the relative efficiencies of average - case optimal ( mub ) and representative suboptimal measurement strategies .",
    "we show that the asymptotically predicted advantages of optimal measurements are diminished in finite samples , to the extent that measurement strategies that are experimentally simpler to implement may perform almost as well as asymptotically optimal measurements .",
    "the paper is organized as follows .",
    "section ii discusses the asymptotic properties of the ml and compares it to the alternative estimation approaches .",
    "section iii details the properties of ml estimators of the quantum density matrix .",
    "section iv describes the bloch vector parameterization , mutually unbiased measurement bases ( mub ) , and representative suboptimal measurement strategies considered in this paper .",
    "section v discusses the details of the globally convergent newton - raphson and quasi - newton algorithms used for constrained parameter optimization , along with methods for kernel density estimation of finite sample distributions . in section",
    "vi , we present the estimation results for general mixed spin-1/2 and spin-1 density matrices , comparing the finite sample versus asymptotic properties of estimators and test statistics for physical quantities of interest in quantum decision theory . finally , in the concluding section vii , we draw conclusions regarding the efficiency of frequentist quantum state estimation and discuss bayesian extensions .",
    "let @xmath3 be an @xmath4 sample of size @xmath5 from a population with probability density function @xmath6 , which depends on the unknown parameter vector @xmath7 whose true value is @xmath8 .",
    "the value of the parameter vector that maximizes the likelihood function - the joint density of the sample defined as a function of the unknown parameter vector @xmath7 - is called the ml estimator of @xmath7 : @xmath9where @xmath10 denotes the admissible parameter space .",
    "typically , the logarithm of the likelihood function , @xmath11 , is easier to maximize numerically because of its separability . by maximizing the log likelihood",
    ", the ml estimator minimizes the kullback - leibler distance between the estimated and true probability distributions .",
    "ml has several properties that make it an attractive frequentist estimation procedure :    1 .",
    "_ consistency : _ an estimator @xmath12 is _ consistent _ for the parameter @xmath7 ( written as plim @xmath13 ) if for every @xmath14 , @xmath15 .",
    "invariance : _ the ml estimator of @xmath16 is @xmath17 , for a continuous and continuously differentiable function @xmath18 .",
    "asymptotic normality .",
    "_ for a sequence of estimators @xmath12 , if @xmath19 as @xmath20 , where @xmath21 denotes convergence in distribution and @xmath22 is any function of @xmath5 , @xmath12 is said to be @xmath23-consistent for @xmath7 and has an asymptotic normal distribution with asymptotic covariance matrix @xmath24 .",
    "+ the ml estimator is asymptotically normally distributed:@xmath25 & \\rightarrow & \\mathcal{n}[0,i^{-1}(\\theta_0 ) ] \\text { , } \\\\",
    "\\text{where } i(\\theta_0 ) & = & -\\mathrm{e}\\left [ \\frac{\\partial ^{2}\\ln l(\\theta_0 |x)}{\\partial \\theta \\partial \\theta ^{\\prime } } \\right ] \\text{.}\\end{aligned}\\ ] ] + @xmath26 is called the expected fisher information matrix .",
    "note that the asymptotic covariance matrix of the ml estimator is a function of the unknown parameters .",
    "two approaches exist for consistent estimation of the expected fisher information matrix thereby providing feasible versions of the observed fisher information matrix .",
    "the first estimator replaces the expected second derivatives matrix of the log likelihood function with its sample mean evaluated at the maximum likelihood estimates,@xmath27 \\label{observed fisher}\\ ] ] + the second estimator is based on the result that the expected second derivatives matrix is the covariance matrix of the first derivatives vector,@xmath28 \\label{observed fisher 2}\\ ] ] 4 .   _ asymptotically efficient .",
    "_ a sequence of consistent estimators @xmath12 is asymptotically efficient if @xmath29\\overset{d}{\\rightarrow } \\mathcal{n}[0,i^{-1}(\\theta_0 ) ] $ ] where @xmath30 $ ] ; @xmath31^{-1}$ ] is called the cramer - rao lower bound ( crb ) for consistent estimators .",
    "property 4 is the subject of the following classic lemma of frequentist inference .",
    "[ crb ] the eigenvalues of the covariance matrix of parameter estimates of an asymptotically unbiased frequentist estimator are bounded from below by the eigenvalues of @xmath32 \\right\\}^{-1}$ ] . the maximum likelihood estimator asymptotically ( i.e. , in the limit of an infinite number of measurements ) achieves this lower bound .    in addition ,",
    "likelihood based testing approaches are optimal , in the sense of the neyman - pearson fundamental lemma and the large deviation principle , for a broad class of hypothesis testing problems .",
    "a hypothesis test @xmath33 , based on a test statistic @xmath34 - a function of the data - is a rule that specifies for which values of @xmath35 ( the acceptance region @xmath36 ) the null hypothesis @xmath37 is accepted , and for which values ( the rejection region @xmath38 ) it is rejected ( and the alternative hypothesis @xmath39 , where @xmath40 is the complement of @xmath41 , is accepted ) .",
    "the _ size _ @xmath42 of a hypothesis test @xmath33 is the probability of rejecting the null hypothesis given that it is true .",
    "the _ power _ @xmath43 of a hypothesis test @xmath33 is given by the probability of rejecting the null hypothesis given that it is false .",
    "typically , when defining the power of a test , one assigns the test to a _ class _ based on its size .",
    "for @xmath44 a test with power function @xmath45 is a size @xmath46 test if @xmath47 .    given a class of hypothesis tests for testing @xmath37 versus @xmath39 , where @xmath48 , the admissible parameter space , a test in that class with power function @xmath45 is _ uniformly most powerful ( ump ) _ if @xmath49 for every @xmath50 in that class .",
    "an important type of hypothesis test based on ml is the likelihood ratio test .",
    "likelihood ratio test statistics take the form @xmath51where @xmath52 is the constrained ml estimator .",
    "it can be shown @xcite that likelihood ratio tests are ump _ _  _ _ in their respective classes . in our simulation analysis ,",
    "we rely on an alternative testing procedure , namely the wald test , which inherits the optimality properties of the likelihood ratio test on account of their asymptotic equivalence @xcite .",
    "this choice is made primarily on the basis of the ease of computation .",
    "the likelihood ratio test requires calculation of both restricted and unrestricted estimators .",
    "the wald test , on the other hand , requires only the unrestricted estimator .",
    "since some of our hypothesis tests involve nonlinear constraints and estimation of the constrained model is cumbersome , we rely on the wald testing procedure .    because of properties 1 - 4 and the fact that likelihood ratio tests are ump , the maximum likelihood estimation methodology is considered the most desirable among frequentist estimation techniques .",
    "an alternative method of frequentist inference , which may be used to estimate the parameters of the quantum density matrix , is the method of moments approach .",
    "suppose that although the probability density function @xmath53 is unknown , @xmath54 moments of the density function have analytical representations in terms of the parameter vector @xmath7 .",
    "let these @xmath54 population moments be denoted by @xmath55 = \\mu ( \\theta ) $ ] , where @xmath56 and @xmath57 .",
    "the _ method of moments _ ( mm ) estimator of @xmath7 , denoted @xmath58 , is the value of the parameter vector that equates the population moments with the corresponding sample moments :    @xmath59    note that the method of moments approach involves solving a system of @xmath54 ( possibly nonlinear ) equations in @xmath54 unknown parameters . like the ml estimator ,",
    "the mm estimator is consistent and asymptotically normally distributed .",
    "however , while the ml estimator exploits all the information contained in the likelihood of the data , the mm estimator only uses the information in a chosen set of moments of the data . hence , unlike the ml estimator , the mm estimator is not asymptotically efficient , i.e. its asymptotic variance does not attain the cramer - rao lower bound .",
    "the asymptotic distribution of the mm estimaor is:@xmath60 \\rightarrow \\mathcal{n}[0,v]\\text{,}\\ ] ] where @xmath61 \\text { , \\ } \\\\ \\omega & = & \\mathrm{e}\\left [ \\left ( f(x_{i})-\\mu ( \\theta _ { 0})\\right ) \\left ( f(x_{i})-\\mu ( \\theta _ { 0})\\right ) ^{t}\\right ] \\text{.}\\end{aligned}\\ ] ]      in the alternative paradigm of bayesian estimation , the estimation error that arises is typically lower than that in frequentist estimation .",
    "bayesian estimation differs fundamentally from frequentist methods in that the parameters @xmath62 are treated as random variables .",
    "the goal is not to estimate a unique probability distribution , which can only truly be known in the limit of an infinite number of measurements , but to update a so - called prior plausibility distribution to a posterior plausibility distribution based ( only ) on the observed data .",
    "the posterior plausibility distribution is given by @xmath63 where @xmath64 denotes the prior plausibility distribution , i.e. , the probability of the parameter vector taking on the value @xmath65 given our prior information @xmath66 regarding the parameter space , @xmath67 denotes the joint probability density , and @xmath10 denotes the space of admissible parameters @xmath65 .",
    "conditional simulation is required to retrieve quantities of interest , including the parameter estimates , which are given formally by the posterior means @xmath68    unlike frequentist estimators , the notion of a confidence or credible interval can be rigorously defined for finite samples only for bayesian estimators .",
    "this allows one to rigorously report finite sample uncertainties . the @xmath69 bayesian credible interval for the parameter",
    "@xmath70 is the interval @xmath71 $ ] such that @xmath72",
    "in this section we apply and extend the classical estimation framework in section ii to estimation of the quantum density matrix .",
    "quantum statistical inference is based on the notion of a quantum probability space .",
    "consider a measurable space @xmath73 , where @xmath74 is the set of all possible measurement outcomes and @xmath75 is the @xmath76-algebra of subsets of @xmath74 .",
    "an _ operator - valued probability measure ( povm ) _ is a ( set ) function @xmath77 , where @xmath78 is the set of bounded positive semidefinite , hermitian linear operators on a hilbert space @xmath79 .",
    "a _ quantum probability space _ is a measurable space @xmath80 , together with an operator - valued probability measure @xmath81 , such that the outcome @xmath82 has probability density function @xmath83 , where @xmath84 and @xmath85 is a positive - semidefinite , unit trace , hermitian matrix ( parametrized by a vector @xmath65 of parameters ) called the density matrix .",
    "note that @xmath35 in this context denotes the outcome of a single measurement .",
    "the measure @xmath81 is explicitly defined in terms of the operators @xmath86 , and an associated scalar - valued probability measure @xmath87 satisfying @xmath88 , through the relation @xmath89 . for @xmath1-dimensional ( finite ) quantum systems , we write @xmath90 , and denote the outcome of the @xmath91-th measurement by @xmath92 .",
    "@xmath93 is then a @xmath94 positive - semidefinite hermitian matrix .",
    "the outcomes @xmath35 are indexed by the set of integers @xmath95 . in this case",
    ", we have @xmath96 .    for simplicity of exposition , we collect all the distinct parameters of the density matrix , @xmath97 , into the @xmath98-dimensional vector , @xmath65 .",
    "the most convenient parameterization of @xmath99 differs based on the state estimation method ; various parameterizations are discussed in section iv .",
    "the likelihood function for quantum state estimation is then @xmath100 which may be interpreted as the probability of obtaining the set of observed outcomes for a given density matrix @xmath85 .",
    "the ml estimator of the density matrix seeks to identify the admissible parameter vector @xmath65 at which this likelihood is maximal .",
    "a _ resolution of the identity _ on a hilbert space @xmath79 of quantum states is a normalized operator - valued measure .",
    "generally , the resolution of the identity satisfies @xmath101 for finite - dimensional systems , to which we restrict our attention , @xmath102 where @xmath103 denotes the @xmath94 identity matrix .",
    "an important feature of quantum probability is that the operators @xmath93 do not all mutually commute .",
    "the subsets @xmath104 of the space of possible measurement outcomes @xmath74 may be chosen to be pairwise disjoint and associated with subsets @xmath105 of commuting observables whose members do not commute with those of any other subset .",
    "the @xmath106 are then said to constitute distinct measurement  bases \" .    writing each @xmath93 as an @xmath107 hermitian matrix , it is convenient to represent each basis @xmath108 in terms of an @xmath107 matrix of common eigenvectors @xmath109 . given that the density matrix is a function of @xmath110 independent parameters , the minimal cardinality resolution of the identity must be composed of @xmath111 subsets @xmath112 .",
    "we note , however , that many resolutions of the identity are redundant in that they are associated with @xmath113 bases @xmath106 .    in the current work , the data @xmath35 consist of @xmath114 measurement outcomes in each of @xmath115 measurement bases with @xmath116 .",
    "the measurement bases used are discussed further in section [ bases ] .      among frequentist estimation techniques ,",
    "ml has been employed most extensively for reconstruction of quantum states . in quantum ml estimation , we aim to identify the maximum of the likelihood function ( [ likelihood ] ) over the set of _ admissible _ density matrices .",
    "all parametrizations of the density matrix require the imposition of constraints on parameter vector @xmath65 ( see section iv ) ; these constraints are necessary for expression ( [ likelihood ] ) to be a well - defined likelihood . assuming the constraints on the parameter vector @xmath65 are of the general form @xmath117",
    ", the problem can be formulated in terms of the lagrangian function @xmath118 + \\sum_{j=1}^{n}\\lambda_j\\left(a_j(\\theta ) - \\gamma_j^2\\right),\\ ] ] where the first term is @xmath119 in the absence of constraints ( i.e. , @xmath85 need not be an admissible density matrix and @xmath120 need not be a well - defined likelihood ) , the @xmath121 denote slack variables ( @xmath122 in the case of an equality constraint ) and the @xmath123 denote lagrange multipliers .",
    "it is convenient to order the @xmath1 constraints such that the first constraint enforces the unit trace of @xmath124 , and the following @xmath125 constraints enforce its positive semidefiniteness .",
    "note that @xmath126 is a well - defined likelihood function only in the presence of these constraints . for parameterizations where positive semidefiniteness is implicit in the parametrization ( such as the cholesky parametrization @xcite ) , @xmath127 , and for parameterizations where the unit trace constraint is implicit in the parameterization ( such as the bloch vector parametrization , sect .",
    "iv ) , @xmath128 .",
    "we denote the vector of parameters @xmath129 .",
    "finding the optimum corresponding to this lagrangian entails searching for parameter vector @xmath130 that renders the gradient vectors @xmath131 and a linear combination of @xmath132 , @xmath133 parallel .",
    "there are two common approaches to solving this problem : 1 ) minimization of the  sum of squares \" ( of the first - order conditions ) function @xmath134 ; 2 ) finding the roots of the system of nonlinear equations @xmath135 using the newton - raphson ( nr ) method .",
    "in fact , methods 1 ) and 2 ) may be combined to produce a globally convergent nr algorithm .",
    "further details on solving the constrained optimization problem are provided in section [ numerical ] .",
    "note that the ml estimator obtained by maximizing the likelihood defined by the lagrangian ( [ lagrangian ] ) is consistent , asymptotically normally distributed , and has an asymptotic covariance matrix equal to the inverse of @xmath5 times the expected fisher information matrix , @xmath136 ( see section ii for details ) .",
    "we estimate the expected fisher information using equation ( [ observed fisher ] ) in section ii .      in quantum statistics ,",
    "there are multiple cramer - rao type inequalities , each with its own associated ( quantum ) fisher information .",
    "some of these correspond to particular measurement strategies , whereas others are in fact unachievable .",
    "work in quantum probability theory @xcite has indicated that @xmath137 for an arbitrary choice of measurement bases is generally not the tightest asymptotic lower bound achievable in quantum ml estimation .",
    "however , the measurements that maximize the fisher information depend on the true , unknown state of the quantum system , rendering the practical utility of the notion of the tightest possible cramer - rao bound questionable .",
    "although the choice of measurement bases that can achieve the tightest possible cramer - rao bound depends on the true @xmath124 , there exists an approach to optimal measurement that is agnostic to the true value of @xmath124 .",
    "wootters @xcite proposed a construction of measurement bases that maximizes the _ average _ information ( over the set of all possible density matrices ) obtained via a set of @xmath5 measurements . these so - called mutually unbiased measurement bases ( mub )",
    "are  maximally noncommutative \" in the sense that a measurement in one basis provides no information as to the outcome of a measurement over a basis unbiased with respect to the current one .",
    "let @xmath138 denote the fisher information given true state @xmath139 .",
    "mub aims to maximize the average fisher information over all possible @xmath140 s : @xmath141 where @xmath10 again denotes the admissible parameter space and @xmath142 is the volume of @xmath10 , by an appropriate choice of measurement bases ( as discussed in section parameterization , @xmath143 , the @xmath110 dimensional bloch vector space of admissible @xmath94 dimensional density matrices ) .",
    "it can be shown that this is equivalent to maximizing the average _ kullback - leibler ( kl ) information gain _",
    "@xmath144 upon updating the flat prior distribution to the asymptotic multivariate normal distribution .",
    "the kl information gain is given by @xmath145 where in the present case @xmath146 is the asymptotic multivariate normal distribution over the bloch vector space after measurements and estimation , and @xmath147 is the uniform distribution on the bloch vector space .",
    "the kl gain is defined in terms of the shannon information of a distribution , @xmath148 .",
    "a measurement in each basis restricts the variance in @xmath125 directions , leaving it infinitely broad in the other @xmath149 . for estimation of a single parameter ,",
    "the shannon entropy of the asymptotic normal distribution of parameter estimates is @xmath150 .",
    "maximizing the information gain is equivalent to minimizing the  uncertainty volume \" in the parameter space ; in the absence of measurements , this is equal to the volume of the bloch vector space .",
    "the uncertainty distance for estimation of a single parameter is the standard deviation of the estimator ; the uncertainty volume is the product of the standard deviations of the estimators for each of the parameters . in terms of uncertainty volumes ,",
    "the information gained by measurements is @xmath151 where @xmath152 is the uncertainty volume after measurements and estimation and @xmath153 is volume of the bloch vector space .",
    "denote by @xmath154 the @xmath155-dimensional subspace of @xmath156 or @xmath157 associated with measurement basis @xmath158 .",
    "the total uncertainty volume is diminished by overlaps between the subspaces @xmath154 .",
    "it can be shown wootters1989 that this total volume @xmath152 may be written @xmath159 where @xmath154 is the @xmath155-dimensional subspace of @xmath156 associated with measurement basis @xmath158 and @xmath160 denotes the @xmath98-dimensional parallelipiped whose edges are the @xmath111 sets of eigenvectors associated with each of the subspaces @xmath154 .",
    "thus the kullback - leibler information gain ( [ kullback - leibler ] ) in updating the flat prior distribution to the asymptotically normal distribution is then @xmath161+\\ln(w_0)-\\left(\\frac{n^2 - 1}{2}\\right)\\ln(\\pi e).$ ]    @xmath162 , the log of the average uncertainty volume in subspace @xmath154 , does not depend on the choice of measurements since it is the log of the product of standard deviations of multinomial parameters in a single measurement basis , averaged over all possible multinomial parameters @xmath163 .",
    "thus the average kullback - leibler or fisher information is a function of only @xmath164 , which in turn is determined by the relative orientations of the bases ( and not the parameters ) .",
    "the total uncertainty volume is minimized when @xmath160 is a rectangular solid with all the unit vectors defining the edges being orthogonal ; this is equivalent to the condition that the subspaces @xmath165 are mutually orthogonal .",
    "wootters showed wootters1989 that this condition is equivalent to requiring that @xmath166 are column vectors in the bases @xmath167 respectively , and @xmath168 denotes the modulus of the hermitian inner product . whereas mutual nonorthogonality of the edges of the parallelipiped may decrease the asymptotic uncertainty volume in particular subspaces @xmath154 , the total asymptotic uncertainty volume is always increased by such nonorthogonality .",
    "explicit formulas for measurement bases that satisfy ( [ mub condition ] ) are known in the cases where the hilbert space dimension @xmath169 is the power of a prime , and are discussed in section ivb .",
    "an unresolved question in the literature is the magnitude of the information loss for finite sample sizes incurred due to not using mub or other approaches to optimal quantum measurement .",
    "in many experimental setups , it is not convenient to use these specialized bases .",
    "we aim to clarify the practical utility of optimal quantum measurements in ml estimation , and assess the extent to which frequentist quantum estimation can effectively make use of the associated optimal efficiencies .",
    "an alternative frequentist method of quantum state estimation that is not based on a likelihood function is tomographic inversion @xcite .",
    "this involves an application of the method of moments approach described in section ii . adopting the notation @xmath170 for the @xmath171 observation returning outcome @xmath172 , let the mm estimator functions @xmath173 be given by @xmath174 .",
    "we then have @xmath175 = p_{i}={{\\rm tr}}(\\rho ( \\theta ) f(x_{i_k}))$ ] , where @xmath176 denotes the probability of observing outcome @xmath177 .",
    "the tomographic inversion method estimates the parameters by equating these population moments to the corresponding sample moments : the parameter estimates @xmath178 are obtained by inverting a system of equations of the form @xmath179where @xmath180 denotes the frequency with which outcome @xmath181 is observed in the sample . introducing the notation @xmath182",
    ", we may solve for the estimated parameter vector as @xmath183 for any parameterization @xmath184 that is linear in @xmath7 ( see section [ parameterization ] ) .",
    "however , this method has two major drawbacks .",
    "first , since no parametrization @xmath99 guarantees satisfaction of each of the positive - semidefiniteness , unit trace , and hermiticity constraints on @xmath97 ( see section [ parameterization ] ) , direct inversion can yield unphysical density matrix estimates .",
    "second , while the ml estimator exploits all the information contained in the likelihood of the data , the mm estimator only uses the information in a chosen set of moments of the data .",
    "hence , unlike the ml estimator , the mm estimator is not asymptotically efficient , i.e. its asymptotic variance does not attain the cramer - rao lower bound .",
    "for these reasons , we do not consider tomographic inversion in our assessment of the performance of frequentist quantum estimation .      in the alternative , bayesian approach to quantum state estimation",
    ", the posterior distribution @xmath185 ( [ genpost ] ) takes the form :    @xmath186p(\\theta)\\mathrm{d } \\theta}{\\int_{\\theta } \\left[\\prod_k\\mathrm{tr}(f_{i_k}\\rho(\\theta))\\right]p(\\theta)~\\mathrm{d } \\theta}.\\end{aligned}\\ ] ]    the density matrix can be estimated by the posterior mean of each of its elements ( corresponding to a quadratic  loss function \" ) , namely    @xmath187 p(\\theta ) ~\\mathrm{d}\\theta } { \\int_{\\theta } \\left [ \\prod_{k}\\mathrm{tr}(f_{i_{k}}\\rho ) \\right ] p(\\theta ) ~\\mathrm{d}\\theta}\\end{aligned}\\ ] ]    alternative loss functions can be used to retrieve other estimable quantities of interest .",
    "bayesian credible intervals can be obtained according to expression ( bayescred ) by sampling from the posterior density ( [ posterior ] ) .",
    "these credible intervals do not rely on asymptotic results / fisher information .",
    "we do not compute bayesian integrals in this work ; our goal is rather to determine whether such a need exists given the finite sample performance of the computationally simpler frequentist estimators .",
    "in maximum likelihood estimation of the quantum density matrix , a constrained optimization must be carried out , where the constraints correspond to preservation of the unit trace and/or positive semidefiniteness properties of the density matrix .",
    "the dimension of the parameter space increases quadratically with the hilbert space dimension , necessitating the use of efficient parameterizations of the density matrix .",
    "the three most commonly used parameterizations are the bloch vector @xcite , euler angle @xcite and the cholesky @xcite parameterizations . within the last few years",
    ", considerable advancements have been made in extending the bloch and euler parameterizations to arbitrary @xmath1-dimensional hilbert spaces .",
    "the euler angle parameterization of the density matrix , which is based on the euler angle parameterization of the special unitary group @xmath188 , employs the generators in the lie algebra @xmath156 to parameterize @xmath124 in terms of the lie algebra exponential map .",
    "the constraint equations are linear in the parameters , but because the parameters appear as exponents , the likelihood takes on a complicated form . in the cholesky parameterization , @xmath189 with @xmath36 upper triangular has real elements on the diagonal .",
    "@xmath124 is then is automatically positive - semidefinite , but is associated with a nonlinear expression for the likelihood , and is not standard in other applications . here",
    ", we employ the so - called bloch vector parameterization , where the probability of an observable outcome according to the born rule , @xmath190 , is a simple linear function of the parameter vector @xmath65 . moreover , the bloch vector parameterization is perhaps the most commonly used in the statistical physics of finite - dimensional quantum systems ( especially in quantum information applications ) .",
    "most importantly , asymptotic standard errors in the bloch vector parameterization can be computed using the standard methods described in section ii because the positive - semidefiniteness constraints are inequality restrictions that are nonbinding at the optimum .    in the bloch vector parameterization @xcite , the hermitian operator @xmath124 is parameterized in terms of an orthogonal basis @xmath191 for the vector space of traceless hermitian operators on an @xmath1-dimensional hilbert space . in two dimensions ,",
    "these are the familiar pauli spin matrices , whereas in three dimensions they are the so - called gell - mann matrices .",
    "@xmath124 can then be written    @xmath192    where the @xmath110 matrices @xmath123 satisfy the conditions a ) @xmath193 , b ) @xmath194 , c ) @xmath195 .",
    "these are the defining conditions of the generators of the lie group @xmath188 that generalize the pauli spin matrices .",
    "the @xmath196 are given by @xmath197 ( i.e. , are expectation values of the observable generators ) .",
    "the vector @xmath198 is called the bloch vector .",
    "@xmath157 is a compact convex subset of @xmath199 .",
    "let @xmath200 denote the coefficients of the characteristic polynomial of @xmath124 , @xmath201 , where @xmath124 takes the form above .",
    "the unit trace constraint is automatically satisfied in the bloch vector parameterization .",
    "it can be shown that the conditions of hermiticity and positive - semidefiniteness of @xmath124 correspond to the following definition of the ",
    "bloch vector set \" @xmath157 of admissible values of @xmath65 @xmath202 this follows from the standard result that the roots of a characteristic polynomial are positive semidefinite iff the coefficients of the polynomial are positive semidefinite @xcite .",
    "the @xmath203 in the above definition of @xmath204 are themselves polynomials in @xmath65 whose coefficients can be expressed in terms of the structure constants of the lie algebra @xmath156 of traceless hermitian matrices , and will be written explicitly below for @xmath205 .",
    "the structure constants , which characterize the generators of @xmath156 , are the elements of the completely antisymmetric and completely symmetric tensors @xmath206 and @xmath207 , respectively defined by the relations :    @xmath208= 2\\imath f_{ijk } \\lambda_k\\ ] ]    @xmath209_+ = \\frac{4}{n}\\delta_{ij } i_n + 2g_{ijk } \\lambda_k,\\ ] ]    which can be solved @xcite for @xmath210 , @xmath211 : @xmath212\\lambda_k\\ } \\\\ g_{ijk}&=&\\frac{1}{4 } \\mathrm{tr}\\{([\\lambda_i,\\lambda_j]_+-\\frac{4}{n}\\delta_{ij})\\lambda_k\\}.\\end{aligned}\\ ] ] where @xmath213 $ ] denotes the antisymmetric commutator and @xmath213_+$ ] denotes the symmetric commutator , and where we have used the einstein ( implicit ) summation convention for repeated indices .",
    "it can be shown @xcite that the @xmath214 that satisfy these conditions can be expressed : @xmath215 where    @xmath216      when @xmath217 , the conditions @xmath218 ( equation ( [ bloch space ] ) ) correspond to @xmath219 and @xmath220 the latter condition defines the familiar bloch sphere for spin-@xmath221 systems .",
    "the lagrangian ( [ lagrangian ] ) in this case becomes @xmath222+\\lambda_2\\left(\\frac{n-1}{n}-\\frac{1}{2}|\\theta|^2-\\gamma_2 ^ 2\\right),\\ ] ] where we have omitted the constant term originating from @xmath223 since it is independent of @xmath65 .      for @xmath224 , in addition to the constraint ( [ 2d bounds ] )",
    ", we have @xmath225 where the structure constants @xmath211 are components of the completely symmetric tensor of the lie algebra @xmath156 ( eq . [ structure constants ] ) .",
    "the lagrangian ( [ lagrangian ] ) for spin-1 systems then becomes @xmath226 + \\\\",
    "\\lambda_2\\left(\\frac{n-1}{n}-\\frac{1}{2}|\\theta|^2-\\gamma_2 ^ 2\\right)+\\\\ \\lambda_3\\left[\\frac{(n-1)(n-2)}{n^2}-\\frac{3(n-2)}{2n}|\\theta|^2+\\frac{1}{2}g_{ijk}\\theta_i\\theta_j\\theta_k-\\gamma_3 ^ 2\\right],\\end{gathered}\\ ] ] where we have ( again ) used the einstein summation convention for repeated indices , i.e. , @xmath227 .    note",
    "that while for @xmath217 , the bloch vector space is exactly a ball , the additional constraints starting with @xmath228 restrict the bloch vector space for @xmath224 and higher dimensions to a proper subset of a ball . since the structure constants of @xmath156 for @xmath229 have no rotational invariance , neither do these conditions .",
    "the bloch vector space has an asymmetric structure in @xmath199 for @xmath229 .    in the bloch vector parameterization",
    ", the fisher information takes on a particularly simple analytical form . for @xmath217",
    ", we have for the score vectors @xmath230",
    "\\\\ \\frac{\\partial \\ln l(\\theta|x)}{\\partial \\theta_2}=\\frac{1}{2}\\sum_{k=1}^m \\frac{k}{\\mathrm{tr}(\\rho f_{i_k})}\\left[f_{i_k}(1,2)+f_{i_k}(2,1)\\right ] \\\\",
    "\\frac{\\partial \\ln l(\\theta|x)}{\\partial \\theta_3}=\\frac{1}{2}\\sum_{k=1}^m \\frac{1}{\\mathrm{tr}(\\rho f_{i_k})}\\left[f_{i_k}(1,1)+f_{i_k}(2,2)\\right]\\end{aligned}\\ ] ] with @xmath231_{ij}=\\frac{\\partial \\ln l(\\hat \\theta)}{\\partial \\theta_i}\\left(\\frac{\\partial \\ln l(\\hat \\theta)}{\\partial \\theta_j}\\right)^t$ ] .",
    "the fisher information decomposes similarly to @xmath217 for @xmath224 due to the linearity of the born probability in @xmath65 .      as discussed in section iiib , quantum measurement strategies capable of fully reconstructing the density matrix",
    "can be characterized by a set of @xmath111 measurement bases ( matrices of eigenvectors ) @xmath232 .",
    "each such choice yields a different asymptotic variance for the ml estimator , i.e. , a different fisher information matrix . in the present work ,",
    "we focus on the use of mutually unbiased measurement bases . for 1-qubit systems ( @xmath217 ) , mub bases",
    "@xmath232 can be written @xmath233 the observables are then simply the standard pauli spin operators .    for @xmath224 , or more generally when @xmath1 is the power of an odd prime , these bases @xmath158 are given by @xcite @xmath234,~~ & 1\\leq r\\leq n. \\\\ & \\end{array}\\right.\\ ] ] the orthonormal observables can then be taken to be @xmath235 recall that the mub measurements maximize the average fisher information over the set of all true density matrices @xmath140 , and hence are  average - case optimal \" as discussed in section iiid .      in order to interrogate the asymptotic and finite sample losses induced by using biased or suboptimal measurement bases ,",
    "the mub bases are rotated , causing the associated parallelipiped @xmath160 in section iii d to no longer be a rectangular solid and the average fisher information to decrease .",
    "after rotation , the new bases can be written @xmath236 where @xmath237 , @xmath36 being a random hermitian matrix specifying a random axis of rotation in the @xmath1-dimensional hilbert space ; @xmath238 is a scalar parameter specifying the extent of rotation ( magnitude of the solid angle ) . to generate a set of measurement bases that is sufficiently different from the mub",
    ", @xmath1 measurement bases were rotated according to the above formula ; for basis @xmath239 , the parameter @xmath238 was incrementally increased until @xmath240 runs over all the other bases and @xmath241 is a chosen scalar , for at least one pair of eigenvectors @xmath242 from bases @xmath239 and @xmath243 , respectively . if necessary , this procedure was iterated self - consistently .",
    "we refer to the resulting bases as mutually biased measurement bases ( mbb ) .",
    "in the bloch vector parametrization , the maximum of the likelihood corresponding to lagrangian function ( lagrangian ) can be found by solving for roots of the nonlinear system of @xmath244 equations @xmath245 in @xmath244 unknowns @xmath246 .",
    "the number of constraints and hence unknowns will differ in other parametrizations ; for example , for parameterizations where positive semidefiniteness is implicit in the parametrization ( such as the cholesky parametrization ) , @xmath247 in equation ( [ lagrangian ] ) .",
    "the newton - raphson algorithm can be used to find the roots of this nonlinear system . writing @xmath248 , the newton step for @xmath249 is @xmath250 with @xmath251 , where @xmath252 is the jacobian matrix . denoting the rows of @xmath253 by @xmath254",
    ", we have    @xmath255    in order to faciliate global convergence of the newton - raphson algorithm , the  sum - of - squares \" function @xmath256 is evaluated after each iteration , and the step length progressively shortened until the value of this function is found to decrease ( the existence of such a step length is guaranteed ) @xcite .",
    "alternatively , the  sum - of - squares `` function @xmath257 may be minimized directly to locate the constrained maximum of the likelihood . in general , direct minimization of this function may be prone to encountering local traps . in the present case ,",
    "minimization using an optimization algorithm capable of escaping from traps was employed .",
    "the quasi - newton algorithm , in which the algorithic step @xmath258 is given by @xmath259 , where @xmath260 denotes the approximate inverse hessian computed with the broyden - fletcher - goldfarb - shanno ( bfgs ) update , was first used to search for a zero of @xmath261 until convergence slowed  below a specified stepwise tolerance '' , again using an adaptive line search strategy to identify the optimal step size .",
    "traps were often encountered that could not be escaped from using the above technique . to surmount them , a fixed number of stochastic simulated annealing steps were applied .    in order to have a scalar measure of the accuracy of the entire density matrix estimate , the josza fidelity ( generalized overlap ) @xmath262 , which is related to the statistical distance on the space of density matrices , was used . the convergence tolerance ( i.e. , objective function value below which the optimized parameter estimate was accepted as an estimator ) for each @xmath97 was chosen by running a set of ml optimizations with a very large sample size ( @xmath263 observations ) , and determining the objective function value below which @xmath264 for all cases . in order to make the convergence tolerance compatible across difference sample sizes ,",
    "the log of the unconstrained likelihood function was scaled as @xmath265 .",
    "kernel density estimators ( kdes ) , nonparametric density estimators that avoid some of the deficiencies of histograms , were used to estimate finite sample probability density functions . unlike histograms , they are smooth .",
    "kdes center a kernel function at each data point ; the contribution of data point @xmath266 to the estimate at @xmath267 depends on @xmath268 .",
    "the estimated density takes the form @xmath269 with @xmath270 .",
    "bandwidth ( @xmath271 ) optimization , which avoids values of @xmath271 that lead to spiky estimates ( undersmoothing ) or oversmoothing , was based on minimization of the asymptotic mean integrated squared error ( amise ) vaneeden1985 , i.e. , @xmath272 .",
    "a gaussian kernel @xmath273 was used .",
    "codes implementing the above algorithms , including both optimization and hypothesis testing , are available upon request from the author .",
    "we consider several monte carlo simulation environments in order to assess the asymptotic and finite - sample properties of the maximum likelihood estimators of the density matrix and test statistics for various physical quantities of interest . for both spin-1/2 and spin-1 systems , we report results for full rank , nondegenerate mixed states . the true @xmath97 s ( see tables i , ii ) are randomly chosen and ,",
    "hence , the results may be considered representative for any true underlying density matrix ] . for each @xmath97 , @xmath274",
    "hypothetical samples of i.i.d quantum observations each of size @xmath275 were simulated with the observations evenly distributed between the @xmath111 measurement bases . for simulating quantum observations from a given basis @xmath158",
    ", the multinomial distribution probabilities @xmath276 were computed as @xmath277 where @xmath278 denotes the observable associated with the multinomial outcome @xmath172 obtained in draw @xmath91 from basis @xmath239 .",
    "the parameters of @xmath97 were then estimated using the maximum likelihood approach for each sample . among the types of possible optimal measurement strategies , mutually unbiased measurement bases ( mub )",
    "minimizes the ( asymptotic ) estimation error across the widest range of hilbert space dimensions and true @xmath97 s ( as discussed section iii d ) .",
    "mub s are therefore used for the simulations in section ii b , and the performance of suboptimal mbb bases are then compared to the former in section c.      the primary goal in this subsection is to determine whether the limiting asymptotic normal distribution of the parameter estimates provides a good approximation to the finite - sample distribution when mub s are used to generate quantum observations , and how the approximation improves with increase in the sample size .",
    "note that frequentist inferential methods are based on the notion of hypothetical repeated samples .",
    "hence , an important practical consideration when assessing the finite - sample performance of these methods is the choice of the number of simulated samples .",
    "in particular , the number of samples should be large enough such that the finite - sample statistics adequately characterize the corresponding population quantities and the finite - sample distributions are sufficiently smooth .",
    "to obtain such a choice , figure 1 compares the finite - sample distributions for the ml estimator of @xmath279 for the mixed spin-1/2 system for 100 , 500 , 1000 , and 1500 simulated samples .",
    "figure @xmath280 reveals that the finite - sample performance of the ml estimator is quite insensitive to the choice of the number of simulated samples .",
    "note that the finite - sample pdf s for different numbers @xmath281 of simulated samples are barely distinguishable .",
    "therefore , in all subsequent analysis , we set the number of hypothetical samples to @xmath274 .    , mixed spin-1/2 system , mub bases , for various numbers q of hypothetical simulated samples .",
    "( a ) m=100 ; ( b ) m=400 . in each panel ,",
    "the finite sample distributions for q=100 , 500 , 1000 , and 1500 simulations are shown.,title=\"fig:\",width=144,height=144 ] , mixed spin-1/2 system , mub bases , for various numbers q of hypothetical simulated samples .",
    "( a ) m=100 ; ( b ) m=400 . in each panel ,",
    "the finite sample distributions for q=100 , 500 , 1000 , and 1500 simulations are shown.,title=\"fig:\",width=144,height=144 ]    we next turn our attention to mixed spin-1/2 systems ( @xmath217 ) .",
    "table ii reports statistics from the asymptotic and finite - sample distributions of the ml estimators of the parameters and diagonal elements of the density matrix .",
    "panels a , b , and c report results for @xmath282 @xmath283 and @xmath274 , respectively . in particular ,",
    "we report the following statistics from the finite - sample distribution : bias , standard deviation ( std ) , root mean square errors ( rmse ) , and @xmath2 confidence intervals .",
    "these statistics broadly summarize a probability distribution and are defined as follows .",
    "let @xmath284 denote the estimator of @xmath285 in sample @xmath286 .",
    "we have @xmath287 , @xmath288 where @xmath289 , @xmath290^{2}+\\left [ \\textmd{bias}(\\hat { \\theta}_{i})\\right ] ^{2}\\right\\}^{1/2}$ ] , and the @xmath2 confidence interval is the region bounded by the @xmath291 and @xmath292 quantiles of the finite - sample distribution of @xmath293 .",
    "note that the diagonal elements of the density matrix are smooth real functions of the parameter vector @xmath7 .",
    "let @xmath294 denote the @xmath295-th element of the density matrix .",
    "given the invariance property of the ml estimator ( see section ii ) , the maximum likelihood estimator of @xmath294 is @xmath296 .",
    "also , the asymptotic distribution of the estimators of the diagonal elements of @xmath97 can be obtained using the continuous mapping theorem : @xmath297 has an asymptotic normal distribution with asymptotic variance given by @xmath298 where @xmath299 is the asymptotic variance of @xmath300 .",
    "row 1 of panel a reports the true values of the parameters and the diagonal elements of the density matrix .",
    "the row labeled `` asymptotic '' in each panel reports the point estimates of the parameters and diagonal elements , along with the asymptotic standard errors in parentheses and asymptotic @xmath2 confidence intervals in square brackets .",
    "we estimate the asymptotic covariance matrix consistently using the observed fisher information given by equation ( [ observed fisher ] ) .",
    "as mentioned above , the asymptotic distribution of the estimators of the diagonal elements of @xmath97 are obtained using the continuous mapping theorem . for the computation of the asymptotic distribution",
    ", 1 out of the 1000 hypothetical samples was selected randomly .",
    "note that the asymptotic standard errors are very small , ranging from @xmath301 for @xmath279 to @xmath302 for @xmath303 and @xmath304 in panel a. consequently , the asymptotic @xmath2 confidence intervals are tightly centered around the point estimates .",
    "the asymptotic standard errors decrease with the increase in sample size to @xmath305 and @xmath306 in panels b and c , respectively .",
    "consequently , as predicted by asymptotic theory , the distributions get narrower with increase in the sample size .",
    "however , note that , with the exceptions of @xmath303 in panel a , none of the asymptotic confidence intervals contain the true value of the parameter .    [ cols=\"<,^,^,^,^,^,^ \" , ]      an important application of quantum state estimation is optimal decision making and control , and by extension , quantum information processing .",
    "control logic is often boolean , in that decisions are made based on whether a hypothesis is true or false , rather than the precise state of the system .",
    "therefore , in this subsection , we examine the finite - sample performance of maximum likelihood - based hypothesis testing procedures that aid in making decisions .",
    "hypothesis testing problems may involve a single restriction or multiple restrictions on the parameters .",
    "we consider first the case of single restrictions .",
    "the appropriate hypothesis test for testing a single restriction is the @xmath307-test .",
    "the @xmath307-test statistic for the null hypothesis @xmath308 against the alternative hypothesis @xmath309 , where @xmath310 is a known constant , is @xmath311where @xmath312 is a consistent estimate of the asymptotic standard error of @xmath313 .",
    "asymptotically , under the null hypothesis , the @xmath307-statistic converges in distribution to the standard normal distribution ; thus , for a two - sided size @xmath314 test , the null hypothesis is rejected if @xmath315 .",
    "the finite - sample _ size _ and _ power _ of the @xmath307-test vis - a - vis their corresponding asymptotic values provide a means of interrogating the finite sample performance of quantum state ml inferential methods .",
    "recall from section ii a that the size of a hypothesis test is the probability of rejecting the null hypothesis given that it is true .",
    "therefore , the finite sample size of the two - sided @xmath307-test for the hypothesis testing problem - @xmath316 : @xmath317 against the alternative hypothesis @xmath318 : @xmath319 - is given by the fraction of times @xmath320 is greater than @xmath321 in absolute value ; the @xmath307-test has an asymptotic size of @xmath322 .",
    "similarly , as defined in section ii a , the power of a hypothesis test is the probability of rejecting the null hypothesis given that it is false .",
    "hence , the finite - sample power for the hypothesis testing problem - @xmath323 against the alternative hypothesis @xmath324 , where @xmath325 - is given by the fraction of times @xmath326 is greater than @xmath321 in absolute value ; the @xmath307-test has an asymptotic power of @xmath280 .",
    "it can be shown @xcite that the @xmath307-test based on ml estimates is ump ; it is therefore ideal for interrogating finite sample performance of frequentist hypothesis testing .",
    "we consider single hypothesis testing problems involving restrictions on the parameters @xmath65 of the density matrix .",
    "in particular , for the spin-1/2 system , we test the hypothesis @xmath316 : @xmath327 against the alternative @xmath318 : @xmath328 . for the spin-1 system , the hypothesis tested is @xmath316 : @xmath329 against the alternative @xmath318 : @xmath330 .",
    "these hypotheses provide information about the finite - sample size of the testing procedure . for the finite - sample power",
    ", we test the hypothesis @xmath316 : @xmath331 against the alternative @xmath318 : @xmath332 for the spin-1/2 system and the hypothesis @xmath316 : @xmath333 against the alternative @xmath318 : @xmath334 for the spin-1 system .",
    "note that the true values of both @xmath335 for the spin-1/2 system and @xmath336 for the spin-1 system are sufficiently different from @xmath337 to ensure a proper size and power comparison of the tests .",
    "tables iv and v report the finite - sample size and power of the @xmath307-tests for the above hypotheses for the mixed spin-1/2 and spin-1 systems , respectively .",
    "panels a , b , and c in each table report results for @xmath282 @xmath283 and @xmath274 , respectively .",
    "consider first table iv .",
    "the finite - sample size of the @xmath307-test is 0.87 for @xmath338 , i.e. the probability of rejecting the null , @xmath316 : @xmath327 , given that it is true is @xmath339 .",
    "this is more than @xmath340 times bigger than the theoretically predicted asymptotic value of @xmath322 .",
    "this is a reflection of the fact that the asymptotic standard errors grossly underestimate the estimation error in finite - samples .",
    "the asymptotic standard error for @xmath303 is about @xmath302 - an order of magnitude smaller than the finite - sample value @xmath341 ( see table ii , panel a )",
    ". consequently , the @xmath291 and @xmath292 quantiles from the finite - sample distribution of the @xmath307-statistic are @xmath342 and @xmath343 , respectively , whereas the corresponding asymptotic values are only @xmath344 and @xmath321 , respectively .",
    "the increase in sample size to @xmath345 and @xmath274 does not improve the size of the test .",
    "in fact , the finite - sample distribution of the @xmath307-statistic widens relative to the asymptotic standard normal distribution . the @xmath291 and @xmath292 quantiles from the finite - sample distribution of the @xmath307-statistic",
    "are @xmath346 and @xmath347 , respectively , for @xmath305 and @xmath348 and @xmath349 , respectively , for @xmath306 .",
    "this is because , although the finite - sample standard errors decrease with the increase in the sample size , the rate of convergence is much slower than the theoretically predicted rate @xmath350 .",
    "the asymptotic standard errors for @xmath303 for @xmath305 and @xmath306 relative to @xmath338 are @xmath351 and @xmath352 , respectively . however , the finite - sample standard errors for @xmath303 for @xmath305 and @xmath306 relative to @xmath338 are much higher at @xmath337 and @xmath353 , respectively ( see table ii ) .",
    "this is also shown in panel a of figure 11 that plots the finite sample @xmath307-statistic distribution for different sample sizes , along with the asymptotic standard normal distribution .",
    "similar results are obtained for the spin-1 system in table v and panel a of figure 12 .",
    "the power of the t - test is @xmath354 for @xmath338 , close to the asymptotic value of @xmath280 . for higher sample sizes ,",
    "both the finite sample and asymptotic powers coincide at @xmath280 .",
    "however , note that the finite sample size ( above ) is also @xmath355 in spite of @xmath337 being substantially different from @xmath356 , indicating that the testing procedure is incapable of distinguishing between the two hypotheses .",
    "similar results are obtained for the spin-1 system ( table v ) .    in certain applications , such as quantum information processing ,",
    "it is important to simultaneously test whether several elements or parameters of the density matrix have prescribed values . for these testing problems involving multiple parameter restrictions",
    ", we rely on the wald test . as an example , for the spin-1/2 system , we test the hypothesis that each of the parameters @xmath357 is equal to its true known value : @xmath358 against the alternative @xmath359 . the wald statistic is given by @xmath360where @xmath361 and @xmath362 is the estimated asymptotic covariance matrix of the parameter estimates .",
    "asymptotically , under the null , the wald statistic converges in distribution to a chi - squared random variable @xmath363 , with the number of degrees of freedom @xmath91 equal to the number of parameter restrictions ( in this case @xmath364 ) .",
    "a size @xmath365 wald test has a rejection region corresponding to the tail of the @xmath363 distribution beyond which the cumulative probability density is @xmath322 . for @xmath366",
    ", the null hypothesis is rejected if @xmath367 .",
    "the wald test at significance level @xmath314 has asymptotic size @xmath322 and power @xmath280 .",
    "the finite sample size of the test for the hypothesis testing problem - @xmath368 against the alternative hypothesis @xmath369 - is given by the fraction of times @xmath370 where @xmath361 , is greater than 7.81 .",
    "the finite - sample power for the hypothesis testing problem - @xmath371 against the alternative hypothesis @xmath372 , where @xmath373 - is given by the fraction of times @xmath370 , where @xmath374 , is greater than 7.81 .",
    "the wald test based on ml estimates is asymptotically equivalent to a likelihood ratio test , and hence is ump ( see section ii for details ) .    the finite - sample size and power of the wald test for the above hypothesis for different sample sizes",
    "is reported in table iv , for the spin-1/2 system .",
    "the finite - sample size of the wald test for @xmath338 is @xmath354 , almost 20 times bigger than the asymptotic value of @xmath322 .",
    "the @xmath2 quantile from the finite - sample distribution of the wald - statistic is @xmath375 , whereas the corresponding asymptotic value is only @xmath376 .",
    "as with the @xmath307-test , the increase in sample size to @xmath345 and @xmath274 does not improve the size of the wald test .",
    "the finite - sample distribution of the wald- statistic shifts further away from the asymptotic chi - squared distribution with increase in sample size .",
    "this is also revealed in panel b of figure 11 that plots the finite sample wald - statistic distribution for different sample sizes , along with the asymptotic chi - squared distribution .",
    "similar results are obtained for the spin-1 system in table v and panel b of figure 12 , although the power of the test improves for @xmath306 .",
    "the finite sample performance of the wald statistic is also poor for the spin-1 system as reported in table v and panel b of fig .",
    "finally , another important conjecture to test regarding the density matrix is whether an eigenvalue of @xmath124 has a given value .",
    "hence , we also test the hypothesis @xmath316 that an eigenvalue of @xmath97 equals its true ( known ) value .",
    "we denote the @xmath172-th eigenvalue of the estimated density matrix @xmath377 by @xmath378 .",
    "the hellmann - feynman theorem can be used to compute @xmath379 . denoting the eigenvectors of @xmath124 by @xmath380",
    ", we have : @xmath381 since @xmath382 , @xmath383 .    for spin-1/2 systems ,",
    "the exact analytical solution for the eigenvalue derivatives is available directly since the characteristic polynomial is a quadratic : @xmath384 where @xmath385 .",
    "however , it is difficult to analytically compute asymptotic standard errors for the estimated eigenvalues of higher - dimensional quantum states by using the hellmann - feynman theorem since the characteristic polynomial is of higher order . here ,",
    "eigenvalue test statistics , along with the size and power of the associated tests , were computed for the spin-1 system under consideration ( table v ) , because they are representative of the higher - order nonlinearity common in applied problems .",
    "note that hypothesis tests involving a single eigenvalue are t - tests .",
    "the finite sample performance of the eigenvalue tests are roughly identical to those of the above parameter tests , indicating that decisions ( such as control logic ) based on density matrix eigenvalues or state entropy estimated by frequentist methods are expected to perform poorly for such sample sizes .    a hypothesis of practical interest is the purity of the state . in this case ,",
    "parameter values in the null hypothesis lie on the boundary of the maintained hypothesis .",
    "hence , standard regularity conditions ( the parameter value in the null should be an interior point of a compact set ) that ensure asymptotic convergence of the null distributions of the t - statistic and the wald statistic to standard normal and chi - squared distributions , respectively , fail to hold .",
    "andrews @xcite provides general asymptotic results for testing problems of this sort .",
    "he derives the asymptotic null and local alternative distributions of the test statistics under a set of high level conditions .",
    "although the distributions are non - standard , the critical values can be obtained by simulation .",
    "the salient conclusion from the above examples is that the size and power of hypothesis tests fall substantially far from the asymptotically predicted values , and that the finite sample test statistic distributions are not normal and chi - squared , as would be expected from asymptotic theory . in finite samples of practical size",
    ", hypothesis testing performs rather poorly for parameters , @xmath124 elements or eigenvalues , underscoring the inadequacy of the frequentist quantum state estimation approach for such sample sizes .    .",
    "the asymptotic t - statistic distribution is standard normal ( superimposed ) .",
    "( b ) wald - statistic distribution for null hypothesis @xmath386 .",
    "the asymptotic wald statistic distribution is chi - squared with degrees of freedom equal to 3 , the number of restrictions ( superimposed).,width=326,height=384 ]    .",
    "the asymptotic t - statistic distribution is standard normal ( superimposed ) .",
    "( b ) wald - statistic distribution for null hypothesis @xmath387 .",
    "the asymptotic wald statistic distribution is chi - squared with degrees of freedom equal to 3 , the number of restrictions ( superimposed).,width=326,height=384 ]",
    "in this paper we have examined the performance of frequentist estimators of the density matrix of a quantum system using quantum observations simulated using different measurement strategies .",
    "we provided numerical techniques for likelihood optimization under multiple constraints that are robust across arbitrary spin-1/2 and spin-1 system density matrices .",
    "in addition , we have presented methodologies and prescriptions for hypothesis testing in the frequentist quantum framework , an essential requirement for optimal decision making and control .    performing inference in the frequentist framework , we find that the finite sample variances are signficantly larger than the asymptotic bounds ( predicted by the cramer - rao theorem ) for typical experimental sample sizes , and that these bounds are not approached at the rate predicted by asymptotic theory .",
    "this finding is robust to the choice of the density matrix and is more pronounced for small datasets .",
    "a prior study @xcite showed close correspondence between asymptotic and finite sample performance in a single example , but did not consider the rate of convergence to the crb , or higher - dimensional systems .",
    "a unique feature of quantum statistics is the quantum cramer - rao bound , a generalization of the classical cramer - rao bound that originates due to the dependence of the quantum fisher information on the mode of measurement . in prior work",
    ", considerable attention has been devoted to understanding the asymptotic relative efficiencies of different quantum measurement strategies .",
    "our results warrant a careful re - examination of the relative efficiencies of these measurement strategies in finite samples .",
    "recent studies @xcite have aimed to assess the resource requirements of various quantum tomography implementations employing different measurement strategies ; future efforts along these lines would benefit from attention to finite sample losses and the rate at which asymptotic predictions are approached .",
    "given that the finite sample variances are order(s ) of magnitude bigger than the corresponding asymptotic ones , we conclude that in order to improve parameter estimates in finite samples , it is important to incorporate additional information that exploits the information geometry of quantum states into the estimation procedure . an ideal approach in this regard",
    "is bayesian estimation .",
    "since it is based on updating a prior plausibility distribution about the parameters based on observed data , bayesian methods are generally more reliable than standard frequentist methods away from the asymptotic limit .",
    "the prior plausibility distribution permits the introduction of auxiliary information about the parameter space that is not contained within the likelihood .",
    "by contrast , such information is impossible to incorporate in frequentist estimation techniques .",
    "consequently , due to the incorporation of prior knowledge , the credible intervals produced by bayesian inference are generally shorter than their asymptotic frequentist counterparts .",
    "moreover , as we have seen , bayesian credible intervals do not refer to the asymptotic limit of an infinite number of measurements .",
    "the following complete , nonoptimal measurement bases were used in section [ measure ] in order to assess the finite sample losses incurred due to not using mutually unbiased measurements for spin-1 systems : @xmath388 these bases were generated through rotation of mub measurement bases according to the method described in section iv c , with @xmath389 in equation ( [ nonmub condition ] ) ."
  ],
  "abstract_text": [
    "<S> we undertake a detailed study of the performance of maximum likelihood ( ml ) estimators of the density matrix of finite - dimensional quantum systems , in order to interrogate generic properties of frequentist quantum state estimation . </S>",
    "<S> existing literature on frequentist quantum estimation has not rigorously examined the finite sample performance of the estimators and associated methods of hypothesis testing . </S>",
    "<S> while ml is usually preferred on the basis of its asymptotic properties - it achieves the cramer - rao ( cr ) lower bound - the finite sample properties are often less than optimal . </S>",
    "<S> we compare the asymptotic and finite - sample properties of the ml estimators and test statistics for two different choices of measurement bases : the average case optimal or mutually unbiased bases ( mub ) and a representative set of suboptimal bases , for spin-1/2 and spin-1 systems . </S>",
    "<S> we show that , in both cases , the asymptotic standard errors of the ml estimators grossly underestimate the estimation error in finite samples , rendering inference based on the asymptotic properties of the ml unreliable and misleading for experimentally realistic sample sizes . </S>",
    "<S> the results indicate that in order to fully exploit the information geometry of quantum states and achieve smaller reconstruction errors , the use of bayesian state reconstruction methods - which , unlike frequentist methods , do not rely on asymptotic properties - is necessary , since the estimation error is typically lower due to the incorporation of prior knowledge . </S>"
  ]
}