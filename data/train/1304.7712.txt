{
  "article_text": [
    "the geometry representations in finite element methods ( fem ) and computer aided design ( cad ) have been developed independent of each other , and are optimized for the purposes within their respective fields . as a consequence ,",
    "the representations are different from each other , and a transfer of geometry information from cad to fem programmes ( and vice versa ) requires a transformation of geometry data .",
    "these transformations are , in general , not only costly , but also prone to approximation errors , and may require manual input .    _ isogeometric analysis _ ( iga ) , introduced by hughes et al .",
    "@xcite , see also @xcite , aims at closing this gap between fem and cad .",
    "the key observation is that it is a widespread standard in cad to use geometry representations based on non - uniform rational b - splines ( nurbs ) , and that these nurbs basis functions have properties which make them suitable as basis functions for fem . instead of transforming the geometry data to a conventional fem representation",
    ", the original geometry description is used directly , and the underlying nurbs functions are used as basis for the discrete solution .",
    "this way , the geometry is represented _ exactly _ in the sense that the geometry obtained from cad is not changed .",
    "thus , the need for data transformation is eliminated , and furthermore , the exact representation from the coarsest mesh is preserved throughout the refinement process .",
    "iga has been thoroughly studied and analyzed ( see , e.g. , @xcite ) , and its potential has been shown by successful applications to a wide range of problems ( see , e.g. , @xcite ) .    as mentioned above ,",
    "the most widely used spline representations in cad are based on nurbs .",
    "the straightforward definition of nurbs basis functions leads to a tensor - product structure of the basis functions , and thus of the discretization . since naive mesh refinement in a tensor - product setting",
    "has global effects , the development of local refinement strategies for isogeometric analysis is a subject of current active research .",
    "such local refinement techniques include , for example , t - splines @xcite , truncated hierarchical b - splines ( thb - splines ) @xcite , polynomial splines over hierarchical t - meshes ( pht - splines ) @xcite , and locally - refineable splines ( lr - splines ) @xcite .",
    "the issue of adaptive , local refinement is closely linked to the question of efficient a posteriori error estimation ( see , e.g. , @xcite for a general overview on error estimators ) . in the light of adaptive refinement , an error estimator has to identify the areas where further refinement is needed due to the local error being significantly larger than in the rest of the domain .",
    "hence , an accurate indication of the error distribution is essential .",
    "another important objective in computing a posteriori error estimates is to address the _ quality assurance _ ,",
    "i.e. , to quantify the error in the computed solution with certain degree of _",
    "guarantee_. however , a posteriori error estimation in isogeometric analysis is still in an infancy stage . to the best of the authors knowledge ,",
    "the only published results are @xcite .",
    "a posteriori error estimates based on hierarchical bases , proposed by bank and smith @xcite , have been used in @xcite .",
    "the reliability and efficiency of this approach is subjected to the saturation assumption on the ( enlarged ) underlying space and the constants in the strengthened cauchy inequality .",
    "as the authors remarked , the first assumption is critical and its validity depends on the considered example .",
    "moreover , an accurate estimation of constants in the strengthened cauchy inequality requires the solution of generalized minimum eigenvalue problem . as noted in (",
    "* page 41 ) , this approach delivers _ less than satisfactory _ results .",
    "residual - based a posteriori error estimates have been used in @xcite .",
    "this approach requires the computation of constants in clement - type interpolation operators .",
    "such constants are mesh ( element ) dependent , often generic / unknown or incomputable for general element shape ; and the global constant often over - estimates the local constants , and thus the exact error .",
    "this fact has been explicitly stated by the authors in ( * ? ? ?",
    "* pages 42 - 43 ) and in ( * ? ? ?",
    "* remark 1 ) .",
    "goal - oriented error estimation approach has been studied in @xcite .",
    "the results presented in these studies show that neither the estimates of this approach are _ guaranteed _ to be an upper bound , nor the efficiency indices of the estimates are sharp .",
    "moreover , this approach also requires the solution of an adjoint problem , the cost of which can not be entirely neglected .",
    "the approach of zienkiewicz - zhu type a posteriori error estimates is based on post - processing of approximate solutions , and depend on the superconvergence properties of the underlying basis .",
    "to the best of authors knowledge , superconvergence properties for b - splines ( nurbs ) functions are not yet known .",
    "summarily , in general situations , the reliability and efficiency of these methods often depend on undetermined constants , which is not suitable for quality assurance purposes . in this paper , we present _ functional - type a posteriori error estimates _ for isogeometric discretizations .",
    "these error estimates , which were introduced in @xcite and have been studied for various fields ( see @xcite and the references therein ) , provide guaranteed , sharp and fully computable bounds ( without any generic undetermined constants ) .",
    "these estimates are derived on purely functional grounds ( based on integral identities or functional analysis ) and are thus applicable to any conforming approximation in the respective space . for elliptic problems with the weak solution @xmath0",
    ", these error bounds involve computing an auxiliary function @xmath1 . in order to get a sharp estimate , this function @xmath2 is computed by solving a _",
    "global _ problem .",
    "this could be perceived as a drawback when compared to error estimation techniques which rely on local computations and are thus apparently cheaper .",
    "however , as briefly explained above , our emphasis is not only on adaptivity , but also on _ quantifying the error in the computed solution _ ( and thus guaranteeing the quality of the computed solution ) .",
    "therefore , the associated cost should be weighed against the stated objectives .",
    "to the best of authors knowledge , there is no other , particularly cheaper , method available which can fulfill these objectives in general situations . in this paper",
    ", we will elaborate how such estimates can be computed efficiently by a proper set - up of the global problem .",
    "two aspects motivate the application of functional - type error estimates in iga .",
    "firstly , unlike the standard lagrange basis functions , nurbs basis functions of degree @xmath3 are , in general , globally @xmath4-continuous .",
    "hence , nurbs basis functions of degree @xmath5 are , in general , at least @xmath6-continuous , and therefore , their gradients are automatically in @xmath7 .",
    "thereby , we avoid constructing complicated functions in @xmath7 , in particular for higher degrees ( see , e.g. , @xcite ) . secondly ,",
    "since the considered problem is solved in an isogeometric setting , an efficient implementation of nurbs basis functions is readily available , which can be used to construct the above mentioned function @xmath2 .",
    "hence , applying the technique of functional - type a posteriori error estimation in a setting that relies only on the use of already available nurbs basis functions is greatly appealing .",
    "the remainder of this paper is organized as follows . in section  [ sec_prelims ]",
    ", we define the model problem , and recall the definition and some important properties of b - spline and nurbs basis functions .",
    "in section  [ sec_funcee ] , we first recall functional - type a posteriori error estimates and known implementation issues .",
    "then , we derive a quality criterion and the local error indicator . in section  [ sec_effcomp ]",
    ", we discuss a cost - efficient realization of the proposed error estimator using an illustrative numerical example .",
    "further numerical examples are presented in section  [ sec_numex ] , and finally , conclusions are drawn in section  [ sec_conc ] .",
    "in order to fix notation and to provide an overview , we define the model problem and recall the definition and some aspects of isogeometric analysis in this section .",
    "let @xmath8 be an open , bounded and connected lipschitz domain with boundary @xmath9 .",
    "we shall consider the following model problem :    find the scalar function @xmath10 such that@xmath11 where @xmath12 , @xmath13 and @xmath14 are given data .",
    "we assume that @xmath12 is a symmetric positive definite matrix and has a positive inverse @xmath15 , and that there exist constants @xmath16 such that @xmath17 then , the norms @xmath18 are equivalent to the @xmath19-norm @xmath20 .",
    "the weak form of problem can be written as follows :    find @xmath21 , such that @xmath22 where @xmath23 contains the functions which vanish on @xmath24 , and @xmath25 contains the functions satisfying the dirichlet boundary conditions @xmath26 on @xmath24 .",
    "we assume that the problem data @xmath12 , @xmath13 and @xmath14 are given such that the bilinear form @xmath27 is bounded , symmetric and positive definite , and that @xmath28 is a bounded linear functional .",
    "the energy norm of a function @xmath29 is given by @xmath30 .",
    "note that we have considered the dirichlet problem only for the sake of simplicity .",
    "functional - type error estimates can be easily generalized to problems with mixed boundary conditions , see , e.g. , @xcite .",
    "we discretize the problem in the standard way by choosing a finite - dimensional manifold @xmath31 and looking for a _ discrete solution _ @xmath32 .",
    "this leads to a linear system of equations of the form @xmath33 where @xmath34 is the stiffness matrix induced by the bilinear form @xmath27 , @xmath35 is the load vector , and @xmath36 is the coefficient vector of the discrete solution @xmath37 .",
    "we briefly recall the definition of b - spline basis functions and nurbs mappings .",
    "we only provide the basic definitions and properties relevant for the scope of this paper . for detailed discussions of nurbs basis functions , geometry mappings and their properties , we refer to , e.g. , @xcite and the references therein .",
    "the following standard definitions and statements can also be found there .",
    "let @xmath3 be a non - negative _ degree _ and let @xmath38 be a _ knot vector _ with @xmath39 for all @xmath40 .",
    "we consider only _ open knot vectors _ ,",
    "i.e. , knot vectors @xmath41 where the multiplicity of a knot is at most @xmath3 , except for the first and last knot which have multiplicity @xmath42 . for simplicity , we assume that @xmath43 and @xmath44 , which can be easily achieved by a suitable scaling . the @xmath45 univariate _ b - spline basis functions _",
    "@xmath46 , @xmath47 , are defined recursively as follows : @xmath48 whenever a zero denominator appears in the definition above , the corresponding function @xmath49 is zero , and the whole term is considered to be zero . for open knot vectors , the first and last basis function are interpolatory at the first and the last knot , respectively .",
    "the derivatives of b - spline basis functions are given by the following formula : @xmath50    b - spline basis functions of degree @xmath3 are , in general , globally @xmath4-continuous . in the presence of repeated knots , the continuity reduces according to the multiplicity , i.e. , if a knot appears @xmath51 times , the continuity of a b - spline basis function of degree @xmath3 at that knot is @xmath52 .",
    "let @xmath53 and @xmath54 be two families of b - spline basis functions defined by the degrees @xmath3 and @xmath55 , and the open knot vectors @xmath56 respectively .",
    "we denote the set of all double - indices @xmath57 by @xmath58 let @xmath59 , @xmath60 , be positive _ weights_. the _ bivariate nurbs basis functions _",
    "@xmath61 , @xmath60 are defined as follows : @xmath62 the continuity of the b - spline basis functions is inherited by the nurbs basis functions .",
    "note that b - splines can be seen as a special case of nurbs with all weights being equal to one .",
    "hence , we will not distinguish between these two and we will only use the term _ nurbs _ in the remainder of the paper .",
    "the set of functions @xmath63 associated with the _ parameter domain _ @xmath64 , is uniquely determined by the degrees @xmath3 and @xmath55 , the knot vectors @xmath41 and @xmath65 , and the weights @xmath66 . to reflect the associated polynomial degrees in respective dimensions , we will also use the notation @xmath67 for @xmath68 , which denotes the nurbs function of degree @xmath3 and @xmath4-continuity in the first coordinate , degree @xmath55 and @xmath69-continuity in the second coordinate , and where the parameter @xmath70 is the characteristic cell size ( non - vanishing knot - span ) of the mesh for @xmath68 .",
    "given the set of functions @xmath68 and a _ control net _ of _ control points _",
    "@xmath71 , where @xmath72 , the two - dimensional _ nurbs - surface _",
    "@xmath73 is defined by @xmath74 we refer to @xmath75 as the _ physical domain_. we assume that the geometry mapping is continuous and bijective ( i.e. , not self - penetrating ) , which are natural assumptions for cad - applications .    in isogeometric analysis ,",
    "the isoparametric principle is applied by using the same basis functions for the discrete solution @xmath37 which are used for representing the geometry . for detailed discussion , we refer the reader to , e.g. , @xcite .",
    "the discrete solution @xmath37 on the physical domain @xmath76 is represented as follows : @xmath77 where @xmath78 are real - valued coefficients which form the coefficient vector @xmath36 .",
    "the discrete functions space is thus defined by @xmath79    the initial mesh , and thereby the basis functions on this initial mesh , are assumed to be given via the geometry representation of the computational domain , i.e. , the initial discretization is already determined by the problem domain .",
    "the exact representation of the geometry on the initial ( coarsest ) level is preserved in the process of mesh refinement .    as mentioned in the introduction",
    ", the straightforward definition of nurbs basis functions , leads to a tensor - product structure of the discretization , which is the focus of this paper .",
    "nevertheless , the error estimator presented herein is also applicable to local refinement techniques ( e.g. , t - splines , thb - splines , pht - splines , lr - splines , see section  [ sec_intro ] ) since it is derived purely on functional grounds .",
    "in the first two parts of this section , we will discuss the well - known theoretical upper bound for the error in the energy norm ( see , e.g. , @xcite ) , and we recall how to minimize this upper bound in order to get a sharp error estimate ( see , e.g. , @xcite ) .",
    "thereafter , in section  [ sec_qualcrit ] , we will derive a quality criterion from the discussed theory .",
    "we will comment on the realization in the isogeometric context in section  [ sec_effcomp ] .",
    "the starting point for the proposed method is the following main result , which gives an upper bound for the error in the energy norm .",
    "it can be found , e.g. , in @xcite .",
    "[ thm_est1 ] let @xmath80 be the constant in the friedrich s type inequality @xmath81 .",
    "let @xmath82 be the exact solution of the problem , and let @xmath83 be an approximate solution .",
    "then , the following estimate holds : @xmath84 where @xmath2 is an arbitrary vector - valued function in @xmath7 , and the norms are as defined in .",
    "the constant @xmath80 depends only on the domain @xmath76 and the coefficient matrix @xmath12 ( but not on the underlying mesh ) , see , e.g. , @xcite .",
    "note that @xmath80 can be computed either numerically or , if one can find a domain @xmath85 , where @xmath86 is a square domain with side - length @xmath87 , then @xmath88 , where @xmath89 is the dimension and @xmath90 is the constant in .",
    "note that , if we choose @xmath2 via the ( unknown ) exact solution @xmath91 , both sides of coincide .",
    "hence , the estimate is sharp in the sense that , for any fixed @xmath37 , we can find a function @xmath2 such that the upper bound is as close to the exact error as desired .",
    "the estimate given in theorem  [ thm_est1 ] is a guaranteed and fully computable upper bound for any conforming approximation @xmath92 .    in the following ,",
    "we describe some approaches to construct the function @xmath2 and discuss their relative merits . for this reason",
    ", we consider a numerical example , referred to as _",
    "example  [ ex : sin_6pix_3piy ] _ in the remainder , whose solution is a smoothly varying function in both directions .",
    "[ ex : sin_6pix_3piy ] * sinus function in a unit square : * in this numerical example , the computational domain is the unit square @xmath93 and @xmath94 , i.e. , a piecewise quadratic function in both directions .",
    "the coefficient matrix is the identity matrix , i.e. , @xmath95 , and the exact solution is given by @xmath96 the right - hand - side @xmath13 and the ( homogeneous ) boundary conditions @xmath14 are determined by the prescribed exact solution @xmath82 .",
    "it is possible to obtain good error _",
    "indicators _ by constructing a function @xmath2 by some post - processing of the discrete solution @xmath37 , see @xcite and the references therein . since @xmath97",
    ", we have @xmath98 for @xmath99",
    ". choosing @xmath100 will thus result in @xmath101 once we have calculated @xmath102 for each cell @xmath103 of the mesh , we can compare the local errors and choose a criterion for selecting cells which will be marked for further refinement .",
    "typically , one chooses a threshold @xmath104 and marks all cells @xmath103 for refinement , where the local error is above this threshold .",
    "there are several possibilities for determining @xmath104 , e.g. , the bulk - criterion proposed in @xcite . for simplicity , we choose a percentage @xmath105 and mark a cell @xmath103 for refinement , if @xmath106 the @xmath107-percentile of a set @xmath108 denotes the value @xmath109 below which @xmath107 percent of all values @xmath110 fall .",
    "for example , if we choose @xmath111 in , then @xmath104 is chosen such that @xmath112 holds for 20% of all cells @xmath103 .    .[fig_conv_esterr ] ]    to show the efficiency of the estimator , in figure  [ fig_nexsu_ex ] , we present the cells marked for refinement by the exact error .",
    "the cells marked for refinement by the majorant given in are presented in figure  [ fig_nexsu_graduh ] .",
    "we see that starting from the mesh @xmath113 , the majorant is able to nicely capture the refinement pattern of exact error .",
    "however , from a closer look at the convergence of the exact error and the majorant , see figure  [ fig_conv_esterr ] , we find that though such an estimate is a guaranteed upper bound and very cheap to compute , it over - estimates the exact error , and its convergence is slower than the exact error ( due to a lack of proper scaling , different operators acting on @xmath114 on both sides ) . ) nor does it result in desired efficiency indices in the proximity of @xmath115 , and therefore , we do not present its results . ]      in order to obtain a sharp estimate ( and not just an indicator ) , therefore , one has to find a function @xmath2 which minimizes the right - hand - side of . for minimizing the estimate numerically , we first rewrite the estimate in the following form @xmath116 where @xmath117 is a free parameter @xcite .",
    "note that the upper bound in holds true for _ any _ fixed @xmath118 and @xmath119 .",
    "hereinafter , for simplicity , we will refer to @xmath120 as the _ majorant_. introducing @xmath121 we can briefly write the majorant as @xmath122 the _ efficiency index _ , defined by @xmath123 indicates how close the calculated majorant is to the exact error .",
    "the closer @xmath124 is to 1 , the better the estimate .",
    "therefore , obtaining a _ sharp _ estimate requires to find @xmath118 and @xmath125 as solutions to the global minimization problem @xmath126 the technique for finding such minimizing parameters @xmath2 and @xmath127 will be discussed in sections  [ sec_minmaj ] and  [ sec_numrealiga ] . before proceeding further ,",
    "we give the following lemma  [ lem_moconv ] , which can be found in ( * ? ? ?",
    "it provides an analytical result on the sharpness of the bound @xmath120 . for later reference",
    ", we also sketch the proof .",
    "a sequence of finite - dimensional subspaces @xmath128 of a banach - space @xmath129 is called _ limit dense in @xmath129 _ , if for any @xmath130 and any @xmath131 , there exists an index @xmath132 , such that @xmath133 for all @xmath134 .",
    "[ lem_moconv ] let the spaces @xmath135 be limit dense in @xmath7 . then @xmath136    recall that the @xmath7-norm @xmath137 is defined by @xmath138 .",
    "let @xmath139 be arbitrarily small , but fixed .",
    "let @xmath132 be the index such that , for all @xmath140 , there exists a @xmath141 with @xmath142 . then , @xmath143 since @xmath144 , we can write @xmath145 the norm @xmath146 is equivalent to the @xmath19-norm , so there exists a constant @xmath147 , such that the second term in the right - hand side can be bounded by @xmath148 hence , we obtain the following estimate for the first term in : @xmath149 since @xmath150 , we can bound the second term in as follows : @xmath151 with and , we can rewrite as @xmath152 hence , the bound @xmath153 as @xmath154 .      as mentioned above ,",
    "we need to find parameters @xmath2 and @xmath127 which minimize the majorant . to do this",
    ", we apply an interleaved iteration process in which we alternately fix one of the variables and minimize with respect to the other .",
    "this process , which we summarize in the following , has been described , e.g. , in @xcite .",
    "step 1 : :    minimization with respect to @xmath2 : assume that    @xmath125 is given and fixed , either by an initial guess    or as a result of step 2 below .",
    "we view the majorant    @xmath155 as a quadratic function of @xmath2    and calculate its gateaux - derivative @xmath156 with    respect to @xmath2 in direction @xmath157 .",
    "setting @xmath158 , we obtain    @xmath159 where @xmath160    and @xmath161 , as defined in    . in order to solve ,",
    "we choose a finite - dimensional subspace    @xmath162 and search for a    solution @xmath163 .",
    "testing in all directions    @xmath164 leads to a linear system of equations    which we write as @xmath165 here , @xmath166    and @xmath167 are the matrix and the vector    induced by the left hand side and the right hand side of equation ,    respectively . by solving ,",
    "we obtain the coefficient vector    @xmath168 for the discrete function    @xmath169 minimizing @xmath155 in    @xmath162 .",
    "note that this    process requires non - negligible cost as we need to assemble    @xmath166 and @xmath167 and    solve the system .",
    "step 2 : :    minimization with respect to @xmath127 : assume that    @xmath169 is given from step 1 . by direct calculation , we see    that @xmath170 is minimized with respect to    @xmath127 by setting @xmath171 where @xmath172 and    @xmath173 are as defined in .",
    "note that the evaluation of    @xmath172 and @xmath173 ( and thus @xmath127 )    requires only the evaluation of integrals , and thus involves    negligible cost .",
    "steps  1 and 2 are repeated iteratively .",
    "we will refer to one loop of applying step  1 and step  2 as one _ interleaved iteration_. once we have computed minimizers @xmath169 and @xmath127 , the computation of the majorant @xmath174 is straight - forward as it requires only the evaluation of the integrals .",
    "note that the matrix @xmath166 can be written as @xmath175 where @xmath176 and @xmath177 correspond to the terms @xmath178 and @xmath179 in , respectively . since the matrices @xmath176 and @xmath177 in do not change in the interleaved iteration process , they need to be assembled only once .",
    "analogously to , we can write @xmath167 as @xmath180 where @xmath181 and @xmath182 correspond to the terms @xmath183 and @xmath184 in , respectively . the terms @xmath181 and @xmath182 also need to be assembled only once since they also do not change in the interleaved iteration process . the full matrix @xmath166 and vector @xmath167 , however",
    ", do change in each iteration , because of the change in @xmath127 and @xmath169 . based on past numerical studies ,",
    "see , e.g. , @xcite , and the results presented in sections  [ sec_effcomp ] and [ sec_numex ] , it has been found that for linear problems , one or two such interleaved iterations are enough for obtaining a sufficiently accurate result .    to recapitulate , we summarize the steps for computing the majorant in algorithm  [ algo : mplus ] .",
    "@xmath37 , @xmath13 , @xmath80 , @xmath185 @xmath186 @xmath187 initial guess assemble and store @xmath176 , @xmath177 , @xmath181 , @xmath182 @xmath188 @xmath189 solve @xmath190 for @xmath168 @xmath191 @xmath192 @xmath193 @xmath194    [ rem_yglobal ] note that the space @xmath7 , where the auxiliary quantity @xmath2 is sought , is a global space , and for a general complicated problem , it is not immediately clear how to locally compute @xmath2 without global effect",
    ". that being said , a local version of our estimator can be devised for specific problems and data ( like equilibration of flux approach ) , however , that will restrict its generality , which is not very appealing to us . therefore , in the remainder of the paper",
    ", we will focus on computing the majorant from the global minimization problem .",
    "so far , we have defined the majorant and discussed how we minimize ( numerically ) the majorant over @xmath185 .",
    "another important question , especially in the light of adaptive , local refinement , is whether a calculated majorant does correctly capture the error distribution . from the proof of lemma  [ lem_moconv ] , we recall the following observation : @xmath195 from this , we deduce the following quality indicator .",
    "the distribution of the exact error is captured correctly , if @xmath196 with some constant @xmath197 .",
    "this criterion is easy to check , since the terms appearing in are evaluated in the process of minimizing @xmath120 .",
    "it was found from extensive numerical studies ( see examples presented in sections  [ sec_effcomp ] and [ sec_numex ] ) that an accurate distribution of the error is obtained for @xmath198 .    [ rem_cplus ] for the choice of @xmath199 , we have @xmath200 , and therefore , @xmath201 .",
    "one can see from all the tables in sections  [ sec_effcomp ] and [ sec_numex ] , that whenever this criterion is satisfied , we have @xmath202 ( the ratio of @xmath203 appears to be of the same magnitude as @xmath204 .",
    "note that this criterion does not require @xmath205 to be close to zero , but just less than @xmath206 .",
    "since these approximations ( of the original problem and the auxiliary problem in @xmath207 ) are monotonically convergent , the approximation at any level will only improve at the next refinement level , and this is why the results get better for any further refinement .",
    "clearly , all the terms are fully computable , and thus , usable in an algorithm .",
    "we define the local error indicator @xmath208 on a cell @xmath103 as the restriction of the first component of the majorant to the cell @xmath103 , i.e. , by @xmath209 the factor @xmath210 is omitted , since this scalar factor is the same for all cells of the domain . as remarked in the observation , the first component will converge to the exact error , thus providing a good indicator for the error distribution . a more detailed discussion of this indicator can be found in ( * ? ? ?",
    "3.6.4 ) . for refinement based on @xmath211",
    ", we again use the criterion .",
    "we now discuss the efficiency and the computational cost of the proposed estimator based on the global minimization steps presented in section  [ sec_minmaj ] . through out this section , we again consider example  [ ex : sin_6pix_3piy ] from section  [ sec : majorant ] .",
    "all the computations for this example and the examples presented in section  [ sec_numex ] are performed in matlab@xmath212 on an hp workstation z420 with intel xeon cpu e5 - 1650 , 3.2 ghz , 12 cores and 16 gb ram , and the linear systems and are solved using the in - built direct solver .",
    "the right - hand - side @xmath13 and the boundary conditions @xmath14 are determined by the prescribed exact solution @xmath82 .",
    "we study the efficiency of the majorant based on _ straight forward _ computational procedure , as discussed in section  [ sec_proc0 ] , and based on _ cost - efficient _ procedure , as discussed in section  [ sec_numrealiga ] , which coarsens the mesh and increases the polynomial degree simultaneously .",
    "this alternative cost - efficient procedure will then be used in section  [ sec_numex ] for further numerical examples . in all the numerical results of example  [",
    "ex : sin_6pix_3piy ] in this section , the initial guess for @xmath127 is @xmath213 .    in the tables ,",
    "we indicate the mesh - size by the number of interior knot spans of the knot vectors @xmath41 and @xmath65 , respectively . by this",
    ", we mean the number of knot spans without counting the vanishing knot spans at the beginning and the end of the open knot vectors .",
    "for example , if @xmath214 then the mesh - size is @xmath215 , since the empty knot span @xmath216 in @xmath65 is also counted as an interior knot span .",
    "we compare the timings for assembling and for solving the linear systems and , as well as the total time for assembling and solving . in the presented tables ,",
    "these timings are shown in the columns labeled assembling - time , solving - time , and sum , respectively .",
    "the label _ pde _ indicates that the column corresponds to solving the partial differential equation , i.e. , to assembling @xmath34 and solving for @xmath36 .",
    "the label _",
    "est _ indicates that the timings correspond to the estimator , i.e , assembling @xmath166 and solving for   @xmath168 . in the column labeled @xmath217 , we present the ratio of these timings .",
    "note that these ratios were computed _ before _ rounding the numbers , i.e. , taking the ratios of the reported numbers may result in slightly different values .",
    "the computed efficiency indices @xmath124 ( see ) are presented in tables . in order to check the quality criterion discussed in section  [ sec_qualcrit ] , we present the values of @xmath218 and @xmath205 and see whether the inequality is fulfilled or not . to indicate the quality of the error distribution captured by the majorant , we plot which cells are marked for refinement based on the exact local error and the criterion , and compare this to the refinement marking based on",
    "the criterion applied to the computed error estimate ( plotted in magenta ) .",
    "[ ex : case_0 ] * ( straightforward procedure ) * for the first choice for @xmath219 , we use the same mesh as for @xmath68 , and choose @xmath220 the function space @xmath185 is then defined by the well known piola transformation @xcite .",
    "we consider the same setting as presented in example  [ ex : sin_6pix_3piy ] in section  [ sec : majorant ] . in table",
    "[ nexsueff_0 ] , we present the computed efficiency indices obtained with this choice of @xmath185 , which show that upper bound approaches @xmath115 ( representing exact error ) as the mesh is refined .",
    "the dashed line in table  [ nexsueff_0 ] indicates that the criterion is fulfilled with @xmath221 ( actually @xmath222 ) starting from the mesh @xmath223 .",
    "the cells marked by the error estimator are shown in figure  [ fig_nexsu_0 ] .",
    "when comparing these plots to those presented in figure  [ fig_nexsu_ex ] , we see that the error distribution is captured accurately starting from the mesh @xmath224 .",
    "the timings presented in table  [ nexsutime_0 ] , however , show that the computation of the error estimate is costlier ( about @xmath225 times ) than assembling and solving the original problem .",
    "this is not surprising , since , when @xmath226 denotes the number of degrees of freedom ( dof ) of @xmath37 , the number of dof of @xmath169 , which is vector - valued , is asymptotically @xmath227 .",
    "this results in higher assembly time and the solution time for the linear system ( where a direct solver is used ) .",
    "clearly , this straightforward approach is not cost - efficient . in the next section , therefore , we discuss some cost - efficient approaches for computing @xmath228 .    .efficiency index and components of the majorant in example  [ ex : sin_6pix_3piy ] , case  [ ex : case_0 ] , @xmath229.[nexsueff_0 ] [ cols=\"^,>,>,>\",options=\"header \" , ]     the magnitudes of the components @xmath230 and @xmath231 , which are presented in table  [ nexlseff ] for uniform refinement , and in table  [ nexlseff_ada ] for adaptive refinement , show that the criterion with @xmath221 is fulfilled on all the considered meshes .",
    "the error plots presented in figure  [ fig_lada_errconv ] show the expected faster convergence on the adaptively refined mesh , even though we are only using tensor - product splines . in figure  [ fig_lada_meshes ] , meshes and marked cells are shown for steps 2 and 6 , again indicating that the error indicator correctly identifies the corner singularity .",
    ", case  [ ex : case_1].[fig_lada_errconv ] ]     +    in our final example , we consider an advection dominated advection diffusion equation to see the performance of the estimator for sharp boundary layers .",
    "[ ex : adv_diff ] * advection dominated advection diffusion equation : * we consider the advection diffusion equation with dirichlet boundary conditions on the unit square @xmath93 , with @xmath232 , i.e. , @xmath233 where @xmath234    we use the standard streamline upwind petrov - galerkin ( supg ) scheme for the stabilization .",
    "the stabilization parameter @xmath235 is set to @xmath236 , where @xmath237 is the diameter of the cell @xmath103 in direction of the flow @xmath238 , and @xmath239 is the magnitude of the vector @xmath238 .",
    "for advection diffusion problems , we have to adapt the majorant . since the principle method is the same , we refer the reader to ( * ? ? ? * section  4.3.1 ) for a detailed discussion . in this special case , where @xmath240 with @xmath241 , and with constant velocity vector @xmath238 , the majorant @xmath242 for the advection diffusion problem is given by @xmath243 the strong advection and the discontinuous boundary conditions result in sharp layers . in figure",
    "[ fig_e4_lay ] , the expected positions of the layers are indicated by dashed lines .      + @xmath244 & 1.98e-07 & 3.18e-10 + @xmath223 & 6.45e-07 & 1.15e-09 + @xmath245 & 2.28e-06 & 4.33e-09 +   + @xmath244 & 1.83e-06 & 9.66e-10 + @xmath223 & 6.50e-06 & 3.65e-09 + @xmath245 & 1.86e-05 & 1.24e-08 +   + @xmath244 & 3.24e-06 & 1.29e-09 + @xmath223 & 2.07e-05 & 6.52e-09 + @xmath245 & 6.86e-05 & 2.38e-08 +     & @xmath37 & @xmath169 & & & & & & & & & +   + @xmath244 & 324 & 722 & 0.25 & 0.39 & 1.56 & @xmath2460.01 & 0.01 & 6.38 & 0.25 & 0.40 & 1.59   + @xmath223 & 4356 & 8978 & 3.25 & 5.32 & 1.63 & 0.03 & 0.26 & 8.64 & 3.28 & 5.58 & 1.70   + @xmath245 & 66564 & 134162 & 51.22 & 94.15 & 1.84 & 0.85 & 8.84 & 10.35 & 52.07 & 102.99 & 1.98   +   + @xmath244 & 324 & 288 & 0.21 & 0.14 & 0.67 & @xmath2460.01 & @xmath2460.01 & 0.50 & 0.21 & 0.14 & 0.67   + @xmath223 & 4356 & 2592 & 3.26 & 2.10 & 0.64 & 0.03 & 0.06 & 2.01 & 3.29 & 2.16 & 0.66   + @xmath245 & 66564 & 34848 & 50.83 & 35.58 & 0.70 & 0.85 & 2.30 & 2.70 & 51.68 & 37.87 & 0.73   +   + @xmath244 & 324 & 200 & 0.26 & 0.10 & 0.39 & @xmath2460.01 & @xmath2460.01 & 0.58 & 0.26 & 0.10 & 0.40   + @xmath223 & 4356 & 968 & 3.41 & 1.21 & 0.35 & 0.04 & 0.01 & 0.26 & 3.44 & 1.22 & 0.35   + @xmath245 & 66564 & 9800 & 52.40 & 19.83 & 0.38 & 1.02 & 0.91 & 0.89 & 53.42 & 20.74 & 0.39   +    the magnitudes of @xmath218 and @xmath231 presented in table  [ nexadeff ] indicate that the criterion with @xmath221 is fulfilled on all the considered meshes .",
    "the distribution of the marked cells presented in figures  [ fig_e4_064 ] and [ fig_e4_256 ] provides the visual indication that the expected layers are accurately detected by the error estimator .    for this example , the timings presented in table  [ nexadtime ] show that , unlike the previous examples , assembling and solving the system for the estimator is faster than for the original problem not only in case  [ ex : case_3 ] ( less than @xmath247 of the original cost ) , but also in case  [ ex : case_2 ] ( about @xmath248 of the original cost ) .",
    "this is due to the supg stabilization which is costlier than computing the additional term @xmath249 in the majorant @xmath242 .",
    "we have proposed a method for cost - efficient computation of guaranteed and sharp a posteriori error estimates in iga .",
    "this method relies only on the use of nurbs basis functions , without the need for constructing complicated basis functions in @xmath7 .",
    "we have discussed different settings which allow the user to balance the sharpness of the bound and accurate error distribution on the one hand , and the required computational cost of the error estimator on the other hand ( see remark  [ rmk_balance ] ) . for the presented settings ,",
    "we have derived a quality criterion , which is easy to check numerically and which indicates whether the computed estimate is sharp or not ( see remark  [ rmk_coplus ] ) .",
    "two properties of nurbs basis functions are exploited .",
    "firstly , the basis functions are , in general , automatically in @xmath7 due to their high smoothness . without this property ,",
    "we could not use nurbs of equal degree for both components as basis functions for the minimizing function @xmath169 . secondly",
    ", increasing the polynomial degree of nurbs basis functions adds only few dofs .",
    "this fact is necessary for keeping the computational cost of the majorant as low as possible ( see remark  [ rem_choiceyh ] ) .",
    "it is important to note that none of these properties are possible in fem discretizations based on @xmath250 basis functions .",
    "apart from the topical interest of a posteriori error estimation and adaptivity , the presented method should also be of interest in parametrization of computational domain .",
    "for example , for @xmath251- refinement in iga , i.e. , to optimize the placement of inner control points , the proposed estimator can be used to accurately detect the regions with large error and then use the optimization algorithm to reposition the control points .",
    "such a problem of @xmath251- refinement has been studied in @xcite . finally , in this paper , we have only considered tensor - product nurbs discretizations .",
    "while the extension of this method to locally refined isogeometric discretizations and also to three dimensions is , in theory , straightforward , the actual performance and efficiency of the error estimator on such methods and meshes is the subject of further studies .",
    "the authors are grateful to prof .",
    "sergey i.  repin , v.a .",
    "steklov institute of mathematics , st .",
    "petersburg , for helpful discussions .",
    "authors are also thankful to unknown referees for their helpful comments .",
    "the support from the austrian science fund ( fwf ) through the project p21516-n18 is gratefully acknowledged .",
    "y.  bazilevs , l.  beiro  da veiga , j.a .",
    "cottrell , t.j.r .",
    "hughes , and g.  sangalli .",
    "isogeometric analysis : approximation , stability and error estimates for @xmath70-refined meshes .",
    ", 16(7):10311090 , 2006 .",
    "y.  bazilevs , v.m .",
    "calo , j.a .",
    "cottrell , t.j.r .",
    "hughes , a.  reali , and g.  scovazzi .",
    "variational multiscale residual - based turbulence modeling for large eddy simulation of incompressible flows .",
    ", 197(1 - 4):173201 , 2007 ."
  ],
  "abstract_text": [
    "<S> we present functional - type a posteriori error estimates in isogeometric analysis . </S>",
    "<S> these estimates , derived on functional grounds , provide guaranteed and sharp upper bounds of the exact error in the energy norm . </S>",
    "<S> moreover , since these estimates do not contain any unknown / generic constants , they are fully computable , and thus provide quantitative information on the error . by exploiting the properties of non - uniform rational b - splines , we present efficient computation of these error estimates . the numerical realization and the quality of the computed error distribution </S>",
    "<S> are addressed . </S>",
    "<S> the potential and the limitations of the proposed approach are illustrated using several computational examples . </S>"
  ]
}