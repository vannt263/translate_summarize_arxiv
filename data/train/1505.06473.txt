{
  "article_text": [
    "we congratulate the authors for a stimulating paper , accessible to laypersons , and thank them for sharing their code .",
    "we would like to comment on the potential implication of sqmc in bayesian nonparametrics .",
    "nonparametric mixtures are commonly used for density estimation and can be thought of as an extension of finite mixture models when the number of clusters is unknown .",
    "the setting is as follows : observations @xmath0 are spread out into @xmath1 clusters ; the cluster labels , or allocation variables , are denoted by @xmath2 , and are interpreted as the _ states _ of @xmath0 in the context of smc .",
    "note that the states are discrete and elements of @xmath3 , where @xmath1 denotes the number of clusters .",
    "the @xmath4 observations allocated to the same cluster @xmath5 are iid from a given parametric kernel @xmath6 .",
    "this model is static in the sense that data are usually not recorded sequentially .",
    "however , plya urn type schemes @xcite essentially formulate this model sequentially by artificially thinking of observation @xmath7 to occur at time @xmath8 .",
    "so the nonparametric mixture model can be cast as an smc sampler as follows ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ) @xmath9 the predictive distribution @xmath10 is particularly simple for the dirichlet process @xcite .",
    "denote by @xmath11 and @xmath12 the precision parameter and the base measure of the dirichlet process .",
    "then the kernel for the states is given by the following probability mass function on @xmath13 @xmath14 where @xmath15 and @xmath16 involve integrals of @xmath17 and @xmath12 which can be calculated in conjugate cases and approximated otherwise .",
    "note that @xmath18 is also available in closed - form expression for broader classes of random probability measures including the two - parameter poisson ",
    "dirichlet process @xcite and normalised random measures with independent increments @xcite .    as stressed by gerber and chopin ,",
    "the key ingredient of sqmc is the deterministic transform @xmath19 .",
    "a possible choice for is @xmath20 where @xmath21 .",
    "the case of discrete proposal @xmath18 does not seem to be discussed in the paper .",
    "would the authors expect a gain in efficiency by considering a quasi - monte carlo alternative as   instead of standard smc ?",
    "quasi - monte carlo methods are ignored by the statistical community , despite regular attempts by well - respected researchers to induce a broader use of those methods .",
    "the authors are to be congratulated and will hopefully contribute to a wider diffusion of qmc methods .    at a purely mathematical level , that randomised low discrepancy sequences",
    "produce both unbiased estimators and error rates of order @xmath22 at cost @xmath23 implies that sqmc methods should _ always _ be replace regular monte carlo methods . since this is not the case , we may wonder at the reasons . the major difficulty with qmc stands in its requirement to expressing monte carlo estimators as deterministic transforms of a fixed number of uniforms .",
    "this is a strong deterrent to the dissemination of qmc alternatives , as moving to a random number of baseline uniforms does not seem achievable in full generality .",
    "it is thus no surprise that the proposal appears in connection with particle filters .",
    "indeed , this field centres on dynamic importance sampling and hence enjoys a local iid - ness that relates better to qmc integrators than single - chain mcmc algorithms .",
    "for instance , each particular resampling step consists in multinomial simulation , hence could be turned into qmc .",
    "actually , lower variance solutions that amount to qmc , like systematic and residual sampling @xcite , have been proposed in the particle literature .    here ,",
    "the authors apply qmc to the particles themselves , using a _",
    "global _ low discrepancy sequence for the resampling and the move steps : as the cost of using the hilbert curve grows quickly with dimension , two sequences in lieu of one would bring a significant cost reduction .",
    "moreover , they still assume the deterministic transform representation @xmath24 which is a stumbling block for those contemplating switching to qmc , as illustrated in the paper using only normal baseline distributions .",
    "in a sequential setting with unknown parameters @xmath25 , the transform @xmath26 changes each time @xmath25 is modified , which impacts computing cost when the inverse cdf is not available . since simulating",
    "@xmath25 is unlikely to benefit from qmc improvements , one may question the relevance of the overall scheme : the most variable item in the gibbs sampling steps expands its inefficiency to the joint kernel .    in connection with lemma 1 and the sqmc approximation of the evidence ,",
    "rao - blackwellisation using all _ proposed _ moves could be considered : is this easier and significant within qmc since the gain may be of a lower order ?",
    "similarly , the trick at the end of  4.2.1 , using sqmc on a single instead of @xmath27 vectors , is unclear , but i wonder at a connection with the particle learning literature @xcite .    in conclusion",
    ", i am looking forward the aftermath of this read paper that will expose whether qmc is bound to become the reference in simulation computational statistics or to remain a niche activity away from mainstream simulation .",
    "one of the reasons why the authors are so successful in their new methodology is the ability to know in advance the number of uniform variables which are needed for one step of the algorithm .",
    "this allows greater efficiency and , to use the terminology at the end of section 1.2 of the paper , the use of qmc point sets ( fixed length ) instead of qmc sequences ( unbounded length ) .",
    "nonetheless , as noted by the authors , the use of qmc sequences is at least theoretically possible .    when reading the paper , i was immediately curious about the possibility of adapting this methodology in an abc ( approximate bayesian computation ) setting . in an attempt to develop a naive abc population quasi monte carlo algorithm ,",
    "it is natural to use qmc sequences instead of qmc point sets , as shown in algorithm [ algo : abcsqmc ] , which is adapted from @xcite .",
    "input : observations @xmath28 , decreasing sequence @xmath29 , prior @xmath30 with cdf @xmath31 . at iteration @xmath32 ,",
    "set @xmath33 generate @xmath34 as the @xmath5th element in an 1 dimensional rqmc sequence .",
    "set @xmath35 and @xmath36 .",
    "increment @xmath5 . @xmath37 set @xmath38 take @xmath39 as twice the empirical variance of the @xmath40 s set @xmath33 generate @xmath41 as the @xmath5th element in a 2 dimensional rqmc sequence .",
    "select an ancestor @xmath42 from the @xmath43 using @xmath44 as for sqmc generate @xmath45 using @xmath42 and @xmath34 as for sqmc increment j. @xmath46 + set @xmath47 take @xmath48 as twice the weighted variance of the @xmath45 s    i tried this algorithm on a toy example : @xmath49 where @xmath50 is a markov chains taking values in @xmath51 , with probability of switching at any iteration equal to @xmath25 , and attempted to estimate @xmath25 . for the generation of qmc sequences , i used the ` randtoolbox ` r package @xcite .      1 .",
    "the qmc version systematically outperforms the basic population abc sampler , with a variance typically about 30 times smaller for an equal number of particles .",
    "the computational time of the qmc version explodes in a non - linear fashion when the number of particles increases , as shown in figure [ fig : comptime ] .",
    "this is intriguing , and might be due to the cost of generating a qmc sequence , at least in the implementation i used .",
    "there is certainly much more work to be done to adapt these new ideas to an abc setting . in particular , there is one situation where qmc point sets could certainly be useful : in abc , one typically accepts a proposed value @xmath52 it that value leads to simulated data @xmath53 which is close to the observed data @xmath28 , in the sense that @xmath54 for some pseudometric @xmath55 and threshold @xmath56 .",
    "the threshold @xmath56 is note always chosen in advance , but is sometimes a quantile from a fixed number of attempts : there must surely be situation where qmc could be used to improve the estimator for such flavours of abc .",
    "i was surprised not to find any investigation of this idea in the literature ."
  ],
  "abstract_text": [
    "<S> this is a collection of three written discussions of the paper  sequential quasi - monte carlo sampling \" by m. gerber and n. chopin , following the presentation given before the royal statistical society in london on december 10th , 2014 . </S>"
  ]
}