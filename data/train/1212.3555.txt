{
  "article_text": [
    "byzantine fault - tolerant ( bft ) distributed protocols have recently been attracting considerable research attention , due to their appealing promise of masking various system issues ranging from simple crashes , through software bugs and misconfigurations , all the way to intrusions and malware . however , there are many issues that render the use of existing bft protocols questionable in practice ; these include , e.g. , weak guarantees under failures ( e.g. , @xcite ) or high cost in performance , deployment and maintenance when compared to _ crash - tolerant _ protocols @xcite .",
    "this can help us derive the following requirements for the design of future bft protocols :    * a bft protocol should be _ robust _ , i.e. , it should tolerate actual byzantine faults and actual _ asynchrony _ ( modeling network outages ) while maintaining correctness and providing sustainable progress even under _ worst - case _ conditions that still meet the protocol assumptions .",
    "this requirement has often been neglected in bft protocols that focus primarily on _ common _ , failure - free operation modes ( e.g. , @xcite ) .",
    "* a _ robust _ protocol should be _ efficient _ ( e.g. , @xcite ) .",
    "we believe that the efficiency of a robust bft protocol is best compared to the efficiency of its _ crash - tolerant _ counterpart .",
    "ideally , a robust protocol should not incur significant performance and resource cost penalty with respect to a crash - tolerant implementation , hence making the replacement of a crash - tolerant protocol a viable option .",
    "we stand to the point that achieving these goals may require challenging existing approaches and revisiting the use of fundamental abstractions ( such as cryptographic primitives ) .    in this paper , we focus on read / write _ storage _ @xcite , where a set of client ( readers and writers ) processes share data leveraging a set of storage _ server _ processes . besides being fundamental",
    ", the read / write storage abstraction is also practically appealing given that it lies at the heart of the key - value store ( kvs ) apis  a de - facto standard of modern cloud storage offerings .    in this context ,",
    "we tackle the problem of developing a _ robust _ and _ efficient _ asynchronous distributed storage protocol . more specifically ,",
    "storage _ robustness _ implies @xcite : _ (",
    "i ) _ _ wait - freedom _",
    "@xcite , i.e. , read / write operations invoked by correct _",
    "clients _ always eventually return , and _",
    "( ii ) _ _ optimal resilience _ , i.e. , ensuring correctness despite the largest possible number @xmath0 of byzantine server failures ; in the byzantine model , this mandates using @xmath1 servers @xcite .",
    "our main contribution is powerstore , the first efficient robust storage protocol that achieves _ optimal latency _ , measured in _ maximum _ ( worst - case ) number of communication _ rounds _ between a client and storage servers , without using digital signatures .",
    "perhaps surprisingly , the efficiency of powerstore  does not come from sacrificing consistency ; namely , powerstore  ensures _ linearizability _ @xcite ( or _ atomicity _",
    "@xcite ) of read / write operations .",
    "in fact , the efficiency of powerstore stems from combining",
    "_ lightweight authentication _ , _ erasure coding _ and _ metadata write - backs _ where readers write - back only metadata , avoiding much expensive data write - backs .    at the heart of powerstore  is a novel data storage technique we call _ proofs of writing _ ( pow ) .",
    "pow are inspired by commitment schemes  @xcite ; pow incorporate a 2-round write procedure , where the second round of write effectively serves to `` prove '' that the first round has actually been completed before it is exposed to a reader .",
    "more specifically , pow rely on the construction of a secure token that is _ committed _ in the first write round , but can only be verified after it is _ revealed _ in the second round . here , token security means that the adversary can not predict nor forge the token before the start of the second round .",
    "we construct pow using cryptographic hash functions and efficient message authentication codes ( macs ) ; in addition , we also propose an instantiation of pow using shamir s secret sharing scheme @xcite .    as a result ,",
    "pow allow powerstore  to achieve 2-round read / write operations in the single writer ( sw ) case .",
    "this , in case of reads , matches the theoretical minimum for _ any _ robust atomic storage implementation that supports arbitrary number of readers , _ including _ crash - only implementations @xcite .",
    "notably , powerstore  is the first robust bft storage protocol to achieve the 2-round latency of reading without using digital signatures . on the other hand , we prove the 2-round write inherent , by showing a 2-round write lower bound for any robust bft storage that features metadata write - backs using less than @xmath2 storage servers .",
    "in addition , powerstore  employs _ erasure coding _ at the client side to offload the storage servers and to reduce the amount of data transferred over the network . besides being the first robust bft storage protocol to feature metadata write - backs ,",
    "powerstore  is also the first robust bft storage protocol to tolerate an unbounded number of byzantine readers @xcite and unbounded number of writers crash - faults .",
    "finally , while our sw variant of powerstore  demonstrates the utility of pow , for practical applications we propose a multi - writer ( mw ) variant of powerstore  ( referred to as m - powerstore ) .",
    "m - powerstore  features 3-round writes and reads , where the third read round is invoked only under active attacks .",
    "m - powerstore also resists attacks specific to multi - writer setting that exhaust the timestamp domain @xcite .",
    "we evaluate m - powerstore  and demonstrate its superiority even with respect to existing crash - tolerant robust atomic storage implementations .",
    "our results show that in typical settings , the peak throughput achieved by m - powerstore improves over existing crash - tolerant @xcite and byzantine - tolerant @xcite atomic storage implementations , by 50% and 100% , respectively .",
    "the remainder of the paper is organized as follows . in section",
    "[ sec : model ] , we outline our system model . in section  [ sec : pow ] , we introduce powerstore and we analyze its correctness . in section",
    "[ sec : mpow ] , we present the multi - writer variant of powerstore , m - powerstore . in section",
    "[ sec : implementation ] , we evaluate an implementation of m - powerstore . in section  [ sec : relwork ] , we overview related work and we conclude the paper in section  [ sec : conclusion ] .",
    "we consider a distributed system that consists of three _ disjoint _ sets of processes : a set _ servers _ of size @xmath3 , where @xmath0 is the failure threshold parameter , containing processes @xmath4 ; a collection _ writers _ @xmath5 and a collection _ readers _ @xmath6 . the collection _ clients _ is the union of writers and readers .",
    "we assume the _ data - centric _ model @xcite where every client may _ asynchronously _ communicate with any server by message passing using point - to - point reliable communication channels ; however , servers can not communicate among each other , nor send messages to clients other than in reply to clients messages .",
    "we further assume that each server @xmath7 pre - shares one symmetric group key with all writers in the set @xmath8 ; in the following , we denote this key by @xmath9 .",
    "in addition , we assume the existence of a cryptographic ( i.e. , one way and collision resistant ) hash function @xmath10 , and a secure message authentication function @xmath11 , where @xmath12 is a @xmath13-bit symmetric key .",
    "we model processes as probabilistic i / o automata @xcite where a distributed algorithm is a collection of such processes .",
    "processes that follow the algorithm are called _ correct_. we assume that any number of readers exhibit _ byzantine _",
    "@xcite ( or _ arbitrary _",
    "@xcite ) faults",
    ". moreover , up to @xmath0 servers may be byzantine .",
    "byzantine processes can exhibit arbitrary behavior ; however , we assume that byzantine processes are computationally bounded and can not break cryptographic hash functions or forge message authentication codes",
    ". finally , any number of writers may fail by crashing .",
    "we focus on a read / write storage abstraction @xcite which exports two operations : write(@xmath14 ) , which stores value @xmath14 and read ( ) , which returns the stored value .",
    "while every client may invoke the read operation , we assume that writes are invoked only by writers .",
    "we say that an operation ( invocation ) @xmath15 is _ complete _ if the client receives the _ response _ , i.e. , if the client returns from the invocation .",
    "we further assume that each correct client invokes at most one operation at a time ( i.e. , does not invoke the next operation until it receives the response for the current operation ) .",
    "we further assume that the initial value of a storage is a special value @xmath16 , which is not a valid input value for a write operation .    in any execution of an algorithm",
    ", we say that a complete operation @xmath17 _ precedes _ operation @xmath18 ( or @xmath18 _ follows _",
    "@xmath17 ) if the response of @xmath19 precedes the invocation of @xmath18 in that execution .",
    "we focus on the strongest storage progress consistency and progress semantics , namely _ linearizability _",
    "@xcite ( or _ atomicity _",
    "@xcite ) and _ wait - freedom _",
    "wait - freedom states that if a correct client invokes an operation @xmath15 , then @xmath15 eventually completes .",
    "linearizability gives an illusion that a complete operation @xmath15 by a correct client is executed instantly at some point in time between its invocation and response , whereas the operations invoked by faulty clients appear either as complete or not invoked at all .",
    "finally , we measure the time - complexity of an atomic storage implementation in terms of number of _ communication round - trips _ ( or simply _ rounds _ ) between a client and servers .",
    "intuitively , a _ round _ consists of a client sending the message to ( a subset of ) servers and receiving replies . a formal definition can be found in , e.g. ,  @xcite .",
    "in this section , we provide a detailed description of the powerstore  protocol and we analyze its correctness . in addition , we show that powerstore exhibits optimal ( worst - case ) latency in both read and write operations .      at the heart of powerstore",
    "is a novel technique we call proofs of writing ( pow ) .",
    "intuitively , pow enable powerstore to complete in a 2-round write procedure , where the second round of write effectively serves to `` prove '' that the data is written in a quorum of servers ( at least @xmath20 ) before it is exposed to a client .",
    "as such , pow obviate the need for writing - back data , enabling efficient metadata write - backs and support for byzantine readers .",
    "pow are inspired by commitment schemes  @xcite ; pow consist of the construction of a secure token that can only be verified after the second round is invoked . here",
    ", token security means that the adversary can not predict nor forge the token before the start of the second round .",
    "more specifically , our pow implementation relies on the use of one - way collision - resistant functions seeded with pseudo - random input .",
    "we construct pow as follows .    in the first round ,",
    "the writer first generates a pseudo - random nonce and stores the hash of the nonce together with the data in a quorum of servers .",
    "the writer then discloses the nonce to the servers in the second round ; this nonce provides sufficient _ proof _ that the first round has actually completed .",
    "in fact , during the first round of a read operation , the client collects the received nonces into a set and sends ( writes - back ) this set to the servers in the second round .",
    "the server then verifies the pow by checking whether the received nonce matches the hash of the stored nonce .",
    "note that since the writer keeps the nonce secret until the start of the second round , it is computationally infeasible for the adversary to acquire the nonce unless the first round of write has been completed .",
    "pow are not restricted to the use of cryptographic hash functions . in section  [ subsec : shamir ]",
    ", we propose another possible instantiation of pow using shamir s secret sharing scheme @xcite .      in powerstore",
    ", the write operation completes in two rounds , called store and complete .",
    "likewise , the read performs in two rounds , called collect and filter . for the sake of convenience , each round @xmath21store , complete , collect , filter@xmath22 is wrapped by a procedure @xmath23 . in each round @xmath23",
    ", the client sends a message of type @xmath23 to all servers .",
    "a round completes at the latest when the client receives messages of type @xmath24 from @xmath20 correct servers .",
    "the server maintains a variable @xmath25 to store the timestamp of the last completed write , and a variable @xmath26 , of the same structure , to maintain a set of timestamps written - back by clients .",
    "in addition , the server keeps a variable @xmath27 storing the history of the data written by the writer in the store round , indexed by timestamp .",
    "the write implementation is given in algorithm  [ alg : writer ] . to write a value @xmath28",
    ", the writer increases its timestamp @xmath29 , computes a nonce @xmath30 and its hash @xmath31 , and invokes store with @xmath29 , @xmath28 and @xmath32 .",
    "when the store procedure returns , the writer invokes complete with @xmath29 and @xmath30 .",
    "after complete returns , the write completes .    in store ,",
    "the writer encodes @xmath28 into @xmath33 fragments @xmath34 ( @xmath35 , such that @xmath28 can be recovered from any subset of @xmath36 fragments .",
    "furthermore , the writer computes a cross - checksum @xmath37 consisting of the hashes of each fragment .",
    "for each server @xmath7 @xmath38 , the writer sends a store@xmath39 message to @xmath7 . on reception of such a message",
    ", the server writes @xmath40 into the history entry @xmath41 $ ] and replies to the writer . after the writer receives @xmath20 replies from different servers , the store procedure returns , and the writer proceeds to complete .    in complete",
    ", the writer sends a complete@xmath42 message to all servers . upon reception of such a message",
    ", the server changes the value of @xmath25 to @xmath43 if @xmath44 and replies to the writer .",
    "after the writer receives @xmath20 replies from different servers , the complete procedure returns .",
    "@xmath29 : structure @xmath45 initially @xmath46    c    @xmath47 [ alg : writer : timestamp ] @xmath48 @xmath49 @xmath50 [ alg : writer : store ] @xmath51 [ alg : writer : complete ] return ok    @xmath52 @xmath53 $ ] * for * @xmath54 * do * send store@xmath39 to @xmath7 * wait for * store_ack@xmath55 from @xmath20 servers    send complete@xmath42 to all servers * wait for * complete_ack@xmath55 from @xmath20 servers    c    @xmath25 : structure @xmath43 , initially @xmath56//last completed write @xmath26 : set of structure @xmath43 , initially @xmath57//set of written - back candidates @xmath58 $ ] : vector of @xmath59 indexed by @xmath29 , initially @xmath60",
    "=   ( \\textsc{null},\\textsc{null},\\textsc{null})$ ]    c    @xmath41 \\leftarrow ( fr , cc , { \\overline{n}})$ ] [ alg : server : hist - store ] send store_ack@xmath55 to the writer    * if * @xmath44 * then * @xmath61 [ alg : server : update - complete ] send complete_ack@xmath55 to the writer    @xmath62 @xmath63@xmath64@xmath65 } ) [ alg : server : valid - check ] * if * @xmath66 * then * @xmath67 [ alg : server : update - gc ] @xmath68 = \\textsc{null}\\}$ ] [ alg : server : gc ]    gc@xmath69 send collect_ack@xmath70 to client @xmath71    @xmath72 //write - back @xmath62 @xmath73@xmath64@xmath74 [ alg : server : valid - check2 ] @xmath75.fr , hist[c_{hv}.ts].cc)$ ] send filter_ack@xmath76 to client @xmath71 [ alg : server : ret ]    ( @xmath77 ) @xmath78 @xmath79.{\\overline{n}})$][alg : server : valid - pred ]    c      the read implementation is given in algorithm  [ alg : reader ] ; it consists of the collect procedure followed by the filter procedure . in collect ,",
    "the client reads the tuples @xmath43 included in the set @xmath80 at the server , and accumulates these tuples in a set @xmath81 together with the tuples read from other servers .",
    "we call such a tuple a _ candidate _ and @xmath81 a _ candidate set_. before responding to the client , the server garbage - collects old tuples in @xmath26 using the @xmath82 procedure .",
    "after the client receives candidates from @xmath20 different servers , collect returns .    in filter",
    ", the client submits @xmath81 to each server . upon reception of @xmath81 ,",
    "the server performs a write - back of the candidates in @xmath81 ( _ metadata write - back _ ) .",
    "in addition , the server picks @xmath83 as the candidate with the highest timestamp in @xmath81 such that ( @xmath83 ) holds .",
    "the predicate ( @xmath77 ) holds if the server , based on the history , is able to verify the integrity of @xmath77 by checking that @xmath84 equals @xmath85.{\\overline{n}}$ ] .",
    "the server then responds to the client with a message including the timestamp @xmath86 , the fragment @xmath87.fr$ ] and the cross - checksum @xmath87.cc$ ] .",
    "the client waits for the responses from servers until there is a candidate @xmath77 with the highest timestamp in @xmath81 such that ( @xmath77 ) holds , or until @xmath81 is empty , after which collect returns .",
    "the predicate ( @xmath77 ) holds if at least @xmath36 different servers @xmath7 have responded with timestamp @xmath88 , fragment @xmath34 and cross - checksum @xmath37 such that @xmath89 $ ] .",
    "if @xmath90 , the client selects the candidate with the highest timestamp @xmath91 and restores value @xmath28 by decoding @xmath28 from the @xmath36 correct fragments received for @xmath77 . otherwise , the client sets @xmath28 to the initial value @xmath16 .",
    "finally , the read returns @xmath28 .",
    "@xmath92 : @xmath45 , initially @xmath93 @xmath94 : set of @xmath95 , initially @xmath57 @xmath81 : set of @xmath43 , initially @xmath57 @xmath96 $ ] : vector of @xmath97 , initially @xmath98 $ ]    c    @xmath99 @xmath100 @xmath101 @xmath102",
    "@xmath103  [ alg : reader : select ] @xmath104  [ alg : reader : restore ] * else * @xmath105 return @xmath28    send collect@xmath106 to all servers * wait until * @xmath107 return @xmath81    @xmath108 @xmath109    send filter@xmath110 to all servers * wait until * @xmath111 + @xmath112 return @xmath81    @xmath113 ; @xmath114 \\leftarrow ( ts , fr , cc)$ ] @xmath115    @xmath116 s.t .",
    "@xmath117 + @xmath118.ts = ts \\wedge w[i].cc = cc')$ ] [ alg : reader : cc ] @xmath119.fr : i $ ] @xmath120@xmath121.ts $ ] @xmath64@xmath122.fr ) $ ] @xmath64@xmath123\\}$ ] [ alg : reader : fr ] @xmath124 [ alg : reader : decode ] return @xmath28    ( @xmath77 ) @xmath78 ( @xmath125 ( @xmath77 ) @xmath78 @xmath126 + [ alg : reader : safe ] @xmath127.ts = c.ts)\\ \\bigwedge$ ] + @xmath128@xmath129@xmath114.cc $ ] @xmath64@xmath130.cc \\wedge h(w[i].fr ) $ ] @xmath64@xmath130.cc[i])$ ] ( @xmath77 ) @xmath78",
    "@xmath131.ts < c.ts \\}| \\geq s - t$ ]    c      in what follows , we show that powerstore satisfies linearizability and wait - freedom in all filter . due to lack of space",
    ", we refer the readers to the appendix for a detailed proof of powerstore s correctness .",
    "we first explain why linearizability is satisfied by arguing that if a read follows after a completed write(@xmath28 ) ( resp . a completed read that returns @xmath28 ) then the read does not return a value older than @xmath28 .    [ [ readwrite - linearizability ] ]",
    "read / write linearizability + + + + + + + + + + + + + + + + + + + + + + + + + +    suppose a read @xmath132 by a correct client follows after a completed write(@xmath28 ) .",
    "if @xmath29 is the timestamp of write@xmath133 , we argue that @xmath132 does not select a candidate with a timestamp lower than @xmath29 .",
    "since a correct server never changes @xmath25 to a candidate with a lower timestamp , after write@xmath133 completed , @xmath36 correct servers hold a valid candidate with timestamp @xmath29 or greater in @xmath25 . hence , during collect in @xmath132 , a valid candidate @xmath77 with timestamp @xmath29 or greater is included in @xmath81 . since @xmath77 is valid , at least @xmath36 correct servers hold history entries matching @xmath77 and none of them respond with a timestamp lower than @xmath88 . consequently , at most @xmath134 timestamps received by the client in filter are lower than @xmath88 and thus @xmath77 is never excluded from @xmath81 . by algorithm  [ alg : reader ]",
    ", @xmath132 does not select a candidate with timestamp lower than @xmath135 .",
    "[ [ read - linearizability ] ] read linearizability + + + + + + + + + + + + + + + + + + + +    suppose a read @xmath136 by a correct client follows after @xmath132 .",
    "if @xmath77 is the candidate selected in @xmath132 , we argue that @xmath136 does not select a candidate with a timestamp lower than @xmath88 . by the time @xmath132 completes , @xmath36 correct servers hold @xmath77 in @xmath26 . according to algorithm  [ alg : server ] ,",
    "if a correct server excludes @xmath77 from @xmath26 , then the server changed @xmath25 to a valid candidate with timestamp @xmath88 or greater .",
    "as such , @xmath36 correct servers hold in @xmath137 a valid candidate with timestamp @xmath88 or greater and during collect in @xmath136 , a valid candidate @xmath138 with timestamp @xmath88 or greater is included in @xmath81 . by applying the same arguments as above , @xmath132 does not select a candidate with timestamp lower than @xmath139 .",
    "we now show that powerstore satisfies wait - freedom ; here , we argue that the read does not block in filter while waiting for the candidate @xmath77 with the highest timestamp in @xmath81 to become ( @xmath77 ) or @xmath81 to become empty .",
    "[ [ wait - freedom ] ] wait - freedom + + + + + + + + + + + +    suppose by contradiction that @xmath132 blocks during filter after receiving filter_ack messages from all correct servers .",
    "we distinguish two cases : ( case 1 ) @xmath81 contains a valid candidate and ( case 2 ) @xmath81 contains no valid candidate .",
    "* * case 1 : * let @xmath77 be the valid candidate with the highest timestamp in @xmath81 . as @xmath77 is valid ,",
    "at least @xmath36 correct servers hold history entries matching @xmath77 . since no valid candidate in @xmath81 has a higher timestamp than @xmath88 , these @xmath36 correct servers responded with timestamp @xmath88 , corresponding erasure coded fragment @xmath34 and cross - checksum @xmath37 such that @xmath89 $ ] . therefore , @xmath77 is @xmath140 .",
    "furthermore , all correct servers ( at least @xmath20 ) responded with timestamps at most @xmath88 .",
    "hence , every candidate @xmath141 such that @xmath142 becomes @xmath143 and is excluded from @xmath81 . as such , @xmath77 is also @xmath140 and we conclude that @xmath132 does not block . * * case 2 : * since none of the candidates in @xmath81 is valid , all correct servers ( at least @xmath20 ) responded with timestamp @xmath144 , which is lower than any candidate timestamp .",
    "as such , every candidate @xmath91 becomes @xmath140 is excluded from @xmath81 .",
    "we therefore conclude that @xmath132 does not block .",
    "in what follows , we propose an alternative construction of pow based on shamir s secret sharing scheme  @xcite . here",
    ", the writer constructs a polynomial @xmath145 of degree @xmath0 with coefficients @xmath146 chosen at random from @xmath147 , where @xmath148 is a public parameter .",
    "that is , @xmath149 .",
    "the writer then constructs the pow as follows : for each server @xmath7 , the writer picks a random point @xmath150 , and constructs the share @xmath151 , where @xmath152 . as such",
    ", the writer constructs @xmath33 different shares , one for each server , and sends a store@xmath153 message to each server @xmath7 over a _",
    "confidential channel_. upon reception of such a message , server @xmath7 stores @xmath154 in @xmath41 $ ] .",
    "note that since there are at most @xmath0 byzantine servers , these servers can not reconstruct the polynomial @xmath145 from their shares , even if they collude . in the complete round",
    ", the writer reveals the polynomial @xmath145 in a complete@xmath155 message .",
    "this enables a client to determine for a candidate @xmath77 = @xmath156 that the corresponding store round completed by checking that @xmath36 servers @xmath7 stored @xmath157 , without the servers revealing their share . for this purpose , the predicate at server @xmath7 changes to @xmath158.x_i ) = hist[c.ts].p_i)$ ] .    by relying on randomly chosen @xmath150 , and the fact that correct servers never divulge their share",
    ", our construction prevents an adversary from fabricating a _ partially corrupted _ polynomial after the disclosure of @xmath145 . to see why , note that with the knowledge of @xmath145 and @xmath159 held by a correct server @xmath7 , the adversary could fabricate a partially corrupted polynomial @xmath160 that intersects with @xmath145 only at @xmath159 ( i.e. , @xmath161 ) .",
    "this would lead to a situation in which a candidate @xmath77 is neither @xmath140 nor @xmath140 and thus , the read would block .",
    "we point that , unlike the solution based on hash functions , this construction provides information - theoretic guarantees for the pow  @xcite during the store round .      in this section",
    ", we prove that powerstore  features optimal write latency , by showing that writing in two rounds is necessary .",
    "we start by giving some informal definitions .",
    "a distributed algorithm @xmath162 is a collection of automata @xcite , where automaton @xmath163 is assigned to process @xmath164 .",
    "computation proceeds in steps of @xmath162 and a _ run _ is an infinite sequence of steps of @xmath162 .",
    "a _ partial run _ is a finite prefix of some run .",
    "we say that a ( partial ) run @xmath71 _ extends _ some partial run @xmath165 if @xmath165 is a _ prefix _ of @xmath71 .",
    "we say that an implementation of linearizable storage is _ selfish _ , if readers write - back only metadata instead of the full value .",
    "intuitively the readers are selfish because they do not help the writer complete a write . for a formal definition ,",
    "we refer the readers to  @xcite .",
    "furthermore , we say that a write operation is _ fast _ if it completes in a single round .",
    "we now proceed to proving the main result .",
    "[ theo : lb ] there is no _ fast _ write implementation @xmath166 of a multi - reader _ selfish _ robust linearizable storage that makes use of less than @xmath2 servers .",
    "* preliminaries*. we prove theorem  [ theo : lb ] by contradiction assuming at most @xmath167 servers .",
    "we partition the set of servers into four distinct subsets ( we call _ blocks _ ) , denoted by @xmath168 , @xmath169 , @xmath170 each of size exactly @xmath0 , and @xmath171 of size at least @xmath172 and at most @xmath0 . without loss of generality",
    "we assume that each block contains at least one server .",
    "we say that an operation @xmath15 _ skips _ a block @xmath173 , ( @xmath174 ) when all messages by @xmath15 to @xmath173 are delayed indefinitely ( due to asynchrony ) and all other blocks @xmath175 receive all messages by @xmath15 and reply .",
    "we construct a series of runs of a linearizable implementation @xmath166 towards a partial run that violates linearizability .",
    "* let @xmath176 be the partial run in which all servers are correct except @xmath168 which crashed at the beginning of @xmath176 .",
    "let @xmath177 be the operation invoked by the writer @xmath178 to write a value @xmath179 in the storage .",
    "the write @xmath177 is the only operation invoked in @xmath176 and @xmath178 crashes after writing @xmath14 to @xmath170 .",
    "hence , @xmath177 skips blocks @xmath168 , @xmath169 and @xmath171 .",
    "* let @xmath180 be the partial run in which all servers are correct except @xmath171 , which crashed at the beginning of @xmath180 . in @xmath180 ,",
    "@xmath178 is correct and @xmath177 completes by writing @xmath14 to all blocks except @xmath171 , which it skips . * let @xmath181 be the partial run similar to @xmath180 , in which all servers except @xmath169 are correct , but due to asynchrony , all messages from @xmath178 to @xmath171 are delayed .",
    "like in @xmath180 , @xmath177 completes by writing @xmath14 to all servers except @xmath171 , which it skips . to see why , note that @xmath177 can not distinguish @xmath181 from @xmath180 .",
    "after @xmath177 completes , @xmath169 fails byzantine by reverting its memory to the initial state .",
    "* let @xmath182 extend @xmath176 by appending a complete read @xmath183 invoked by @xmath184 . by our assumption , @xmath166 is wait - free .",
    "as such , @xmath183 completes by skipping @xmath168 ( because @xmath168 crashed ) and returns ( after a finite number of rounds ) a value @xmath185 .",
    "* let @xmath186 extend @xmath181 by appending @xmath183 . in @xmath186 ,",
    "all servers except @xmath169 are correct , but due to asynchrony all messages from @xmath184 to @xmath168 are delayed indefinitely . moreover , since @xmath169 reverted its memory to the initial state , @xmath14 is held only by @xmath170 .",
    "note that @xmath184 can not distinguish @xmath186 from @xmath182 in which @xmath168 has crashed .",
    "as such , @xmath183 completes by skipping @xmath168 and returns @xmath185 . by linearizability , @xmath187 . *",
    "let @xmath188 be similar to @xmath182 in which all servers except @xmath170 are correct but , due to asynchrony , all messages from @xmath184 to @xmath168 are delayed .",
    "note that @xmath184 can not distinguish @xmath188 from @xmath182 . as such , @xmath183 returns @xmath185 in @xmath188 , and by @xmath186 , @xmath187 .",
    "after @xmath183 completes , @xmath170 fails by crashing .",
    "* let @xmath189 extend @xmath188 by appending a read @xmath190 invoked by @xmath191 that completes by returning @xmath192 .",
    "note that in @xmath188 , _",
    "@xmath170 is the only server to which @xmath14 was written , _",
    "( ii ) _ @xmath183 did not write - back @xmath14 ( to any other server ) before returning @xmath14 , and _ ( iii ) _",
    "@xmath170 crashed before @xmath190 is invoked .",
    "as such , @xmath190 does not find @xmath14 in any server and hence @xmath193 , violating linearizability .",
    "notice that theorem  [ theo : lb ] applies even to implementations relying on self - verifying data and/or not tolerating byzantine readers .",
    "furthermore , the proof extends to crash - tolerant storage when deleting the byzantine block @xmath169 in the above proof ; the result being that there is no selfish implementation of a multi - reader crash - tolerant linearizable storage with less than @xmath1 servers in which every write is fast .",
    "the powerstore  protocol , as presented in section  [ sec : pow ] , has a drawback in having potentially very large candidate sets that servers send to clients and that clients write - back to servers . as a result",
    ", a malicious adversary can exploit the fact that in powerstore  candidate sets can ( theoretically ) grow without bounds and mount a denial of service ( dos ) attack by fabricating huge sets of bogus candidates . while this attack can be contained by a robust implementation of the point - to - point channel assumption using , e.g. , a separate pair of network cards for each channel ( in the vein of @xcite ) , this may impact practicality of powerstore . to rectify this issue , and for practical applications , we propose a multi - writer variant of our protocol called m - powerstore .",
    "m - powerstore  ( algorithms  [ alg2:writer ] ,  [ alg2:server ] and  [ alg2:reader ] ) supports an unbounded number of clients . in addition , m - powerstore  features optimal read latency of two rounds in the _ common case _",
    ", where no process is byzantine .",
    "outside the common case , under active attacks , m - powerstore  gracefully degrades to guarantee reading in at most three rounds .",
    "the write has a latency of three rounds , featuring non - skipping timestamps @xcite , which prevents attacks specific to multi - writer setting that exhaust the timestamp domain .",
    "the main difference between m - powerstore  and powerstore  is that , here , servers keep a single written - back candidate instead of a set . to this end , it is crucial that servers are able to determine the validity of a written - back candidate without consulting the history . for this purpose ,",
    "we enhance our original pow scheme by extending the candidate with message authentication codes ( macs ) to authenticate the timestamp and the nonce s hash , one for each server , using the corresponding group key .",
    "as such , a valid mac proves to a server that the timestamp has been issued by a writer in complete , and thus , constitutes a pow that a server can obtain even without the corresponding history entry .",
    "note that in case of a candidate incorporating corrupted macs , servers might disagree about the validity of a written - back candidate .",
    "hence , a correct client might not be able to write - back a candidate to @xmath36 correct servers as needed . to solve this issue",
    ", m - powerstore  `` pre - writes '' the macs in the store round , enabling the client to repair the broken macs of a selected candidate .",
    "we point out that the adversary can not forge the macs ( and therefore bypass the pow ) before the start of the complete , since the constructed macs , besides the timestamp , also include the nonce s hash .",
    "to support multiple - writers , write in m - powerstore  comprises an additional clock synchronization round , called clock , which is prepended to store .",
    "the read performs an additional round called repair , which is appended to collect .",
    "the purpose of repair is to repair and write - back candidates if necessary , and is invoked only under active attack by a malicious adversary that actually corrupts candidates .    similarly to powerstore",
    ", the server maintains the variable @xmath27 to store the history of the data written by the writer in the store round , indexed by timestamp .",
    "in addition , the server keeps the variable @xmath25 to store the timestamp of the last completed write .",
    "the full write implementation is given in algorithm  [ alg2:writer ] . in the following ,",
    "we simply highlight the differences to powerstore .    as outlined before",
    ", m - powerstore  is resilient to the adversary skipping timestamps .",
    "this is achieved by having the writer authenticate the timestamp of a write with a key @xmath194 shared among the writers .",
    "note that such a shared key can be obtained by combining the different group keys ; for instance , @xmath195 .    to obtain a timestamp , in the clock procedure , the writer retrieves the timestamp ( held in variable @xmath25 ) from a quorum of @xmath20 servers and picks the highest timestamp @xmath29 with a valid mac .",
    "then , the writer increases @xmath29 and computes a mac for @xmath29 using @xmath194 . finally , clock returns @xmath29 .    to write a value @xmath28 , the writer , _ ( i ) _ obtains a timestamp @xmath29 from the clock procedure , _",
    "( ii ) _ authenticates @xmath29 and the nonce s hash @xmath32 by a vector of macs @xmath196 , with one entry for each server @xmath7 using group key @xmath9 , and _",
    "stores @xmath196 both in store and complete . upon reception of a store@xmath197 message",
    ", the server writes the tuple @xmath198 into the history entry @xmath41 $ ] . upon reception of a complete@xmath199 message , the server changes the value of @xmath25 to @xmath200 if @xmath44 .",
    "@xmath201 : set of @xmath95 , ( process i d ) initially @xmath57 @xmath29 : structure @xmath202 , + initially @xmath144",
    "@xmath78 @xmath203    c    @xmath204 @xmath205 [ alg2:writer : clock ] @xmath48 @xmath49 @xmath206 $ ] @xmath207 [ alg2:writer : store ] @xmath208 [ alg2:writer : complete ] return ok    send clock@xmath55 to all servers * wait until * @xmath107 @xmath209 @xmath210 return @xmath29    @xmath211 * if * @xmath212 * then * @xmath213 [ alg2:writer : ts - integrity ]    @xmath52 @xmath53 $ ] * foreach * server @xmath7 send store@xmath214 to @xmath7 * wait for * store_ack@xmath55 from @xmath20 servers    send complete@xmath199 to all servers * wait for * complete_ack@xmath55 from @xmath20 servers    c    @xmath25 : structure @xmath200 , initially @xmath215 @xmath58 $ ] : vector of @xmath216 indexed by @xmath29 , initially @xmath60",
    "=   ( \\textsc{null } , \\textsc{null } , \\textsc{null } , \\textsc{null})$ ]    c    send clock_ack@xmath217 to writer @xmath178",
    "( fr , cc , { \\overline{n } } , vec)$ ] send store_ack@xmath55 to writer @xmath178    * if * @xmath44 * then * @xmath218[alg2:server : update - complete ] send complete_ack@xmath219 to writer @xmath178    send collect_ack@xmath220 to client @xmath71    @xmath221 @xmath222@xmath64@xmath223 [ alg2:server : valid - filter ] * if * @xmath224 * then * @xmath225[alg2:server : update - filter ] //write - back @xmath226@xmath64@xmath227 [ alg2:server : valid - nonce ] @xmath228.fr , hist[c_{rt}.ts].cc , hist[c_{rt}.ts].vec)$ ] send filter_ack@xmath229 to client @xmath71 [ alg2:server : ret ]    * if * @xmath230 * then * @xmath231 [ alg2:server : update - repair][alg2:server : valid - repair ] send repair_ack@xmath232 to client @xmath71    ( @xmath77 ) @xmath78 ( @xmath233 @xmath234 @xmath235 , c.ts , h(c.{n } ) , k_i)$ ] ) [ alg2:server : valid - pred ] ( @xmath77 ) @xmath78 ( @xmath236.{\\overline{n}}$ ] )    c      the full read implementation is given in algorithm  [ alg : reader ] . the read consists of three consecutive rounds , collect , filter and repair . in collect , a client reads the candidate triple @xmath237 stored in variable @xmath25 in the server , and inserts it into the candidate set @xmath81 together with the candidates read from other servers .",
    "after the client receives @xmath20 candidates from different servers , collect returns .    in filter",
    ", the client submits @xmath81 to each server . upon reception of @xmath81 ,",
    "the server chooses a candidate @xmath238 to write - back , as the candidate with the highest timestamp in @xmath81 such that ( @xmath238 ) holds , and sets @xmath25 to @xmath238 if @xmath224 . roughly speaking , the predicate ( @xmath77 ) holds if the server , verifies the integrity of the timestamp @xmath88 and nonce @xmath239 either by the mac , or by the corresponding history entry .",
    "besides that , the server chooses a candidate @xmath240 to return , as the candidate with the highest timestamp in @xmath81 such that @xmath241 holds . the predicate ( @xmath77 ) holds , if the server keeps a matching history entry for @xmath77 .",
    "the server then responds to the client with a message including the timestamp @xmath242 , the fragment @xmath243.fr$ ] , the cross - checksum @xmath243.cc$ ] and the vector of macs @xmath243.vec$ ] .",
    "the client waits for the responses from servers until there is a candidate @xmath77 with the highest timestamp in @xmath81 such that ( @xmath77 ) holds , or until @xmath81 is empty , after which filter returns .",
    "the predicate ( @xmath77 ) holds if at least @xmath36 different servers @xmath7 have responded with timestamp @xmath88 , fragment @xmath34 , cross - checksum @xmath37 such that @xmath89 $ ] , and vector @xmath196 .",
    "if @xmath81 is empty , the client sets @xmath28 to the initial value @xmath16 . otherwise , the client selects the highest candidate @xmath91 and restores value @xmath28 by decoding @xmath28 from the @xmath36 correct fragments received for @xmath77 .    in repair , the client verifies the integrity of @xmath244 by matching it against the vector @xmath196 received from @xmath36 different servers .",
    "if @xmath244 and @xmath196 match then repair returns .",
    "otherwise , the client repairs @xmath77 by setting @xmath244 to @xmath196 and invokes a round of write - back by sending a repair@xmath245 message to all servers . upon reception of such a message ,",
    "the server sets @xmath25 to @xmath77 if @xmath246 and @xmath140 holds and responds with an repair_ack message to the client . once the client receives acknowledgements from @xmath247 different servers , repair returns .",
    "after repair returns , the read returns @xmath28 .",
    "@xmath92 : @xmath45 , initially @xmath93 @xmath94 : set of @xmath95 , initially @xmath57 @xmath81 : set of @xmath200 , initially @xmath57 @xmath96 $ ] : vector of @xmath248 , initially @xmath98 $ ]    c    @xmath99 @xmath100 @xmath101 @xmath102 @xmath103  [ alg2:reader : select ] @xmath104  [ alg2:reader : restore ] @xmath249 * else * @xmath105 return @xmath28    send collect@xmath106 to all servers * wait until * @xmath107 return @xmath81    @xmath108 * if * @xmath250 * then * @xmath251    send filter@xmath110 to all servers * wait until * @xmath111 + @xmath112 return @xmath81    @xmath113 ; @xmath114 \\leftarrow ( ts , fr , cc , vec)$ ] @xmath115    @xmath116 s.t .",
    "@xmath117 + @xmath118.ts = ts \\wedge w[i].cc = cc')$ ] [ alg2:reader : cc ] @xmath119.fr : i $ ] @xmath120@xmath121.ts $ ] @xmath64@xmath122.fr ) $ ] @xmath64@xmath123\\}$ ] [ alg2:reader : fr ] @xmath124 [ alg2:reader : decode ] return @xmath28    @xmath252 s.t . @xmath117 + @xmath118.ts = c.ts \\wedge w[i].vec = vec')$ ] [ alg2:reader : vec - integrity ] @xmath253 [ alg2:reader : repair]//repair send repair@xmath245 to all servers * wait for * repair_ack@xmath106 from @xmath20 servers    ( @xmath77 ) @xmath78 ( @xmath125 ( @xmath77 ) @xmath78 @xmath126 + [ alg2:reader : safe ] @xmath127.ts = c.ts)\\ \\bigwedge$ ] + @xmath128@xmath129@xmath114.cc $ ] @xmath64@xmath130.cc \\wedge h(w[i].fr ) $ ] @xmath64@xmath130.cc[i])\\bigwedge$ ] + @xmath254.vec = w[j].vec$ ] ) ( @xmath77 ) @xmath78",
    "@xmath131.ts < c.ts \\}| \\geq s - t$ ]    c      we show that m - powerstore  satisfies read linearizability as follows .",
    "we show that if a completed read @xmath132 returns @xmath28 then a subsequent read @xmath136 does not return a value older than @xmath28 .",
    "note that the arguments for read / write linearizability and wait - freedom are very similar to those of powerstore ( section  [ sec : pow - sketch ] ) , and therefore omitted .",
    "suppose a read @xmath136 by a correct client follows after @xmath132 that returns @xmath28 .",
    "if @xmath77 is the candidate selected in @xmath132 , we argue that @xmath136 does not select a candidate with a timestamp lower than @xmath88 . note that besides @xmath77 being a valid candidate , in repair , the client also checks the integrity of @xmath244 .",
    "if @xmath244 passes the integrity check in @xmath132 ( line  [ alg2:reader : vec - integrity ] of algorithm  [ alg2:reader ] ) , then the integrity of @xmath77 has been fully established .",
    "otherwise , @xmath244 fails the integrity check . in that case",
    "the client repairs @xmath77 ( line  [ alg2:reader : repair ] of algorithm  [ alg2:reader ] ) and subsequently writes - back @xmath77 to @xmath36 correct servers . in both cases , @xmath36 correct servers have set @xmath25 to @xmath77 or to a valid candidate with a higher timestamp .",
    "as such , during collect in @xmath136 , a valid candidate @xmath138 such that @xmath139 is included in @xmath81 .",
    "since @xmath138 is valid , @xmath36 correct servers hold history entries matching @xmath138 and none of them responds with a timestamp lower than @xmath255 .",
    "consequently , at most @xmath134 timestamps received by the client in filter are lower than @xmath255 and thus @xmath138 is never excluded from @xmath81 . by algorithm  [ alg2:reader ] , @xmath136 does not select a candidate with timestamp lower than @xmath139 .",
    "in this section , we describe an implementation modeling a key - value store ( kvs ) based on m - powerstore .",
    "more specifically , to model a kvs , we use multiple instances of m - powerstore  referenced by keys .",
    "we then evaluate the performance of our implementation and we compare it both : _",
    "( i ) _ m - abd , the multi - writer variant of the crash - only atomic storage protocol of  @xcite , and _",
    "( ii ) _ phalanx , the multi - writer robust atomic protocol of  @xcite .",
    "our kvs implementation is based on the java - based framework neko  @xcite that provides support for inter - process communication , and on the jerasure  @xcite library for constructing the dispersal codes . to evaluate the performance of our m - powerstore we additionally implemented two kvss based on m - abd and phalanx . in our implementation , we relied on 160-bit sha1 for hashing purposes , 160-bit keyed hmacs to implement macs , and 1024-bit dsa to generate signatures .",
    "for simplicity , we abstract away the effect of message authentication in our implementations ; we argue that this does not affect our performance evaluation since data origin authentication is typically handled as part of the access control layer in all three implementations , when deployed in realistic settings ( e.g. , in wide area networks ) .",
    "we deployed our implementations on a private network consisting of a 4-core intel xeon e5443 with 4 gb of ram , a 4 core intel i5 - 3470 with 8 gb of ram , an 8 intel - core i7 - 37708 with 8 gb of ram , and a 64-core intel xeon e5606 equipped with 32 gb of ram .",
    "in our network , the communication between various machines was bridged using a 1 gbps switch .",
    "all the servers were running in separate processes on the xeon e5606 machine , whereas the clients were distributed among the xeon e5443 , i7 , and the i5 machines .",
    "each client invokes operation in a closed loop , i.e. , a client may have at most one pending operation . in all kvs implementations , all",
    "write and read operations are served by a local database stored on disk .",
    "we evaluate the peak throughput incurred in m - powerstore  in write and read operations , when compared to m - abd and phalanx with respect to : _",
    "( i ) _ the file size ( 64 kb , 128 kb , 256 kb , 512 kb , and 1024 kb ) , and _",
    "( ii ) _ to the server failure threshold @xmath0 ( 1 , 2 , and 3 , respectively ) . for better evaluation purposes",
    ", we vary each variable separately and we fix the remaining parameters to a default configuration ( table  [ tab : nominal ] ) .",
    "we also evaluate the latency incurred in m - powerstore  with respect to the attained throughput .",
    "[ tab : nominal ]    we measure peak throughput as follows .",
    "we require that each writer performs back to back write operations ; we then increase the number of writers in the system until the aggregated throughput attained by all writers is saturated .",
    "the peak throughput is then computed as the maximum aggregated amount of data ( in bytes ) that can be written / read to the servers per second .",
    "each data point in our plots is averaged over 5 independent measurements ; where appropriate , we include the corresponding 95% confidence intervals . as data objects . on the other hand ,",
    "read operations request the data pertaining to randomly - chosen keys . for completeness",
    ", we performed our evaluation _",
    "( i ) _ in the local area network ( lan ) setting comprising our aforementioned network ( section  [ subsec : lan ] ) and _ ( ii ) _ in a simulated wide area network ( wan ) setting ( section  [ subsec : wan ] ) .",
    "our evaluation results are presented in figure  [ fig : results ] .",
    "+    figure  [ fig : latency ] depicts the latency incurred in m - powerstore when compared to m - abd and phalanx , with respect to the achieved throughput ( measured in the number of operations per second ) .",
    "our results show that , by combining metadata write - backs with erasure coding , m - powerstore achieves lower latencies than m - abd and phalanx for both read and write operations .",
    "as expected , read latencies incurred in powerstore are lower than those of write operations since a write requires an extra communication round corresponding to the clock round .",
    "furthermore , due to pow and the use of lightweight cryptographic primitives , the read performance of powerstore considerably outperforms m - abd and phalanx .",
    "on the other hand , writing in m - powerstore compares similarly to the writing in m - abd .",
    "figure  [ fig : newfaulty ] depicts the peak throughput achieved in m - powerstore with respect to the number of byzantine servers @xmath0 . as @xmath0 increases , the gain in peak throughout achieved in m - powerstore s read and write increases compared to m - abd and phalanx .",
    "this mainly stems from the reliance on erasure coding , which ensures that the overhead of file replication among the servers is minimized when compared to m - abd and phalanx . in typical settings , featuring @xmath256 and the default parameters of table  [",
    "tab : nominal ] , the peak throughput achieved in m - powerstore s read operation is almost twice as large as that in m - abd and phalanx .    in figure",
    "[ fig : newfile ] , we measure the peak throughout achieved in m - powerstore with respect to the file size .",
    "our findings clearly show that as the file size increases , the performance gain of m - powerstore compared to m - abd and phalanx becomes considerable .",
    "for example , when the file size is 1 mb , the peak throughput of read and write operations in m - powerstore approaches the ( network - limited ) bounds of 50 mb / s .",
    "] and 45 mb / s , respectively .",
    "we now proceed to evaluate the performance of m - powerstore when deployed in wan settings . for that purpose ,",
    "we rely on a 100 mbps switch to bridge the network outlined in section  [ subsec : setup ] and we rely on netem  @xcite to emulate the packet delay variance specific to wans .",
    "more specifically , we add a pareto distribution to our links , with a mean of 20 ms and a variance of 4 ms .",
    "we then measure the latency incurred in m - powerstore in the emulated wan setting .",
    "our measurement results ( figure  [ fig : latencypareto ] ) confirm our previous analysis conducted in the lan scenario and demonstrate the superior performance of m - powerstore compared to m - abd and phalanx in realistic settings . here",
    ", we point out that the performance of m - powerstore incurred in both read and write operations does not deteriorate as the number of byzantine servers in the system increases .",
    "this is mainly due to the reliance on erasure coding .",
    "in fact , the overhead of transmitting an erasure - coded file @xmath257 to the @xmath1 servers , with a reconstruction threshold of @xmath36 is given by @xmath258 .",
    "it is easy to see that , as @xmath0 increases , this overhead is asymptotically increases towards @xmath259 .",
    "a seminal crash - tolerant _ robust _ _ linearizable _ read / write storage implementation assuming a majority of correct processes was presented in @xcite . in the original single - writer variant of @xcite , read operations always take 2 rounds between a client and servers with _ data _ write - backs in the second round . on the other hand",
    "all write operations complete in a single round ; in the multi - writer variant @xcite , the second write round is necessary .",
    "server state modifications by readers introduced by @xcite are unavoidable ; namely , @xcite showed a @xmath36 lower bound on the number of servers that a reader has to modify in any wait - free linearizable storage .",
    "however , robust storage implementations differ in the strategy employed by readers : in some protocols readers write - back data ( e.g. , @xcite ) whereas in others readers only write metadata to servers ( e.g. , @xcite ) .",
    "the only two asynchronous storage protocols that feature _ metadata write - backs _ are multi - writer crash - tolerant protocols of @xcite and @xcite that are both also linearizable , wait - free and optimally resilient .",
    "the read / write protocol of @xcite fails to achieve optimal latency featuring 3-round writes and reads .",
    "vivace @xcite is a key - value storage system tailored for wans ( geo - replication ) ; it features 3-round reads and 2-round writes , saving on a communication round by relying on synchronized clocks ( ntp , gps ) , which are used as counters . in comparison ,",
    "powerstore  features optimal latency without synchronized clocks and is the first protocol to implement metadata write - backs while tolerating byzantine failures .",
    "data write - backs are also not needed in case of _ fast _ robust storage implementations that feature single round reads and writes @xcite .",
    "namely , @xcite presents fast single - writer crash - tolerant and bft storage implementations in which readers only write metadata _ while _ reading data in the single round of read and hence , without any write - back .",
    "however , fast implementations are fundamentally limited and can not be optimally resilient , since the number of required servers is inherently linear in number of readers @xcite .",
    "the limitation on the number of readers of @xcite was relaxed in  @xcite , where a single - writer crash - tolerant robust linearizable storage implementation was presented , in which most of the reads complete in a single round , yet a fraction of reads is permitted to be `` slow '' and complete in 2 rounds .    clearly , most bft storage implementations have been focusing on using as few servers as possible , ideally @xmath1 , which defines optimal resilience in the byzantine model @xcite .",
    "this is achieved by phalanx @xcite , a bft variant of @xcite .",
    "phalanx uses digital signatures , i.e. , _ self - verifying data _ , to port @xcite to the byzantine model , maintaining the latency of  @xcite , as well as its data write - backs .",
    "however , since digital signatures introduce considerable overhead  @xcite , research attention has shifted from protocols that employ self - verifying data @xcite to protocols that feature lightweight authentication , or no data authentication at all ( unauthenticated model ) .    in the unauthenticated model",
    ",  @xcite ruled out the existence of optimally resilient robust byzantine fault - tolerant storage implementation where all write operations finish after a single communication round .",
    "this explained the previous difficulties in reaching optimal resilience in unauthenticated bft storage implementations where several protocols have used @xmath2 servers @xcite .",
    "furthermore ,  @xcite showed the impossibility of reading from a robust optimally resilient linearizable storage in two communication rounds ; in addition , if write operations perform a constant number of rounds , even reading in three rounds is impossible  @xcite .",
    "these results imply that the optimal latency of a robust optimally resilient and linearizable bft storage in the unauthenticated model is 2 rounds for writes and 4 rounds for reads , even in the single writer case .",
    "this can be achieved by the regular - to - linearizable transformation of the regular @xcite storage protocol of @xcite .",
    "hence , it is not surprising that other robust bft storage protocols in the unauthenticated model focused on optimizing common - case latency with either an unbounded number of read rounds in the worst case @xcite or a number of read rounds dependent on the number of faulty processes @xmath0 @xcite .",
    "clearly , there is a big gap between storage protocols that use self - verifying data and those that assume no authentication .",
    "loft @xcite aims at bridging this gap and implements erasure - coded optimally resilient linearizable storage while optimizing the failure - free case .",
    "loft uses homomorphic fingerprints and macs ; it features 3-round wait - free writes , but reads are based on data write - backs and are only obstruction - free @xcite , i.e. , the number of read rounds is unbounded in case of read / write concurrency .",
    "similarly , our _ proofs of writing _ ( pow ) incorporate lightweight authentication that is , however , sufficient to achieve optimal latency and to facilitate metadata write - backs .",
    "we find pow to be a fundamental improvement in the light of bft storage implementations that explicitly renounce linearizability in favor of weaker regularity due to the high cost of data write - backs @xcite .",
    "in this paper , we presented powerstore , the first efficient robust storage protocol that achieves optimal latency , measured in maximum ( worst - case ) number of communication rounds between a client and storage servers , without resorting to digital signatures .",
    "we also separately presented a multi - writer variant of our protocol called m - powerstore .",
    "the _ efficiency _ of our proposals stems from combining _",
    "lightweight cryptography _ , _ erasure coding _ and _ metadata writebacks _ , where readers write - back only metadata to achieve linearizability .",
    "while robust bfts have been often criticized for being prohibitively inefficient , our findings suggest that efficient and robust bfts can be realized in practice by relying on lightweight cryptographic primitives without compromising _ worst - case _ performance .    at the heart of both powerstore  and m",
    "- powerstore protocols are _ proofs of writing ( pow ) _ : a novel storage technique  inspired by commitment schemes in the flavor of  @xcite , that enables powerstore  to write and read in 2 rounds in case of the single - writer powerstore  which we show optimal .",
    "similarly , by relying on pow , m - powerstore features 3-round writes / reads where the third read round is only invoked under active attacks . finally , we demonstrated m - powerstore s superior performance compared to existing crash and byzantine - tolerant atomic storage implementations .",
    "we point out that our protocols assume unbounded storage capacity to maintain a version history of the various updates performed by the writers in the system .",
    "we argue , however , that this limitation is not particular to our proposals and is inherent to all solutions that rely on erasure - coded data  @xcite .",
    "note that prior studies have demonstrated that it takes several weeks to exhaust the capacity of versioning systems  @xcite ; in case the storage capacity is bounded , the servers can rely on efficient garbage collection mechanisms  @xcite to avoid possible exhaustion of the storage system .",
    "https://github.com/tsuraan/jerasure , 2008 .    .",
    "http://ddsg.jaist.ac.jp/neko/ , 2009 .",
    "ittai abraham , gregory chockler , idit keidar , and dahlia malkhi . .",
    ", 18(5):387408 , 2006 .",
    "amitanand  s. aiyer , lorenzo alvisi , and rida  a. bazzi .",
    "ounded wait - free implementation of optimally resilient byzantine storage without ( unproven ) cryptographic assumptions . in _ proceedings of disc _ , 2007 .",
    "yair amir , brian  a. coan , jonathan kirsch , and john lane .",
    "prime : byzantine replication under attack .",
    ", 8(4):564577 , 2011 .",
    "hagit attiya , amotz bar - noy , and danny dolev .",
    "sharing memory robustly in message - passing systems .",
    ", 42:124142 , january 1995 .",
    "rida  a. bazzi and yin ding . .",
    "in _ proceedings of disc _ , pages 405419 , 2004 .",
    "alysson  neves bessani , miguel  p. correia , bruno quaresma , fernando andr , and paulo sousa .",
    "depsky : dependable and secure storage in a cloud - of - clouds . in _ proceedings of eurosys _ , pages 3146 , 2011 .",
    "christian cachin and stefano tessaro . .",
    "in _ proceedings of dsn _ , pages 115124 , 2006 .    brian cho and marcos  k. aguilera . surviving congestion in geo - distributed storage systems . in _ proceedings of usenix atc _ , pages 4040 , 2012 .",
    "gregory chockler , rachid guerraoui , idit keidar , and marko vukoli .",
    "reliable distributed storage .",
    ", 42(4):6067 , 2009 .",
    "gregory chockler , dahlia malkhi , and danny dolev .",
    "future directions in distributed computing .",
    "chapter a data - centric approach for scalable state machine replication , pages 159163 .",
    "allen clement , edmund  l. wong , lorenzo alvisi , michael dahlin , and mirco marchetti . making byzantine fault tolerant systems tolerate byzantine faults . in _ proceedings of nsdi _ , pages 153168 , 2009 .",
    "dan dobre , rachid guerraoui , matthias majuntke , neeraj suri , and marko vukoli . .",
    "in _ proceedings of podc _ , pages 5968 , 2011 .",
    "partha dutta , rachid guerraoui , ron  r. levy , and marko vukoli . .",
    ", 39:37523783 , december 2010 .    rui fan and nancy lynch . .",
    "in _ proceedings of disc _ , pages 7591 , 2003 .",
    "rui garcia , rodrigo rodrigues , and nuno  m. preguia .",
    "efficient middleware for byzantine fault tolerant database replication . in _ proceedings of eurosys _ , pages 107122 , 2011 .",
    "chryssis georgiou , nicolas  c. nicolaou , and alexander  a. shvartsman . . ,",
    "69(1):6279 , january 2009 .",
    "garth  r. goodson , jay  j. wylie , gregory  r. ganger , and michael  k. reiter . .",
    "in _ proceedings of dsn _ , 2004 .",
    "rachid guerraoui , ron  r. levy , and marko vukolic . .",
    "in _ proceedings of dsn _ , pages 125136 , 2006 .    rachid guerraoui and marko vukoli . in _ proceedings of podc _ , pages 248257 , 2006 .",
    "rachid guerraoui and marko vukoli . refined quorum systems . , 23(1):142 , 2010 .",
    "shai halevi and silvio micali .",
    "practical and provably - secure commitment schemes from collision - free hashing . in _ proceedings of crypto _ , pages 201215 , 1996 .",
    "james hendricks , gregory  r. ganger , and michael  k. reiter .",
    "low - overhead byzantine fault - tolerant storage . in",
    "_ proceedings of sosp _ , pages 7386 , 2007 .",
    "maurice herlihy .",
    "wait - free synchronization . , 13(1 ) , 1991 .",
    "maurice herlihy , victor luchangco , and mark moir .",
    "obstruction - free synchronization : double - ended queues as an example . in _ proceedings of icdcs _ , 2003 .",
    "maurice  p. herlihy and jeannette  m. wing .",
    "linearizability : a correctness condition for concurrent objects . ,",
    "12(3 ) , 1990 .",
    "prasad jayanti , tushar  deepak chandra , and sam toueg .",
    "fault - tolerant wait - free shared objects . , 45(3 ) , 1998 .",
    "ramakrishna kotla , lorenzo alvisi , michael dahlin , allen clement , and edmund  l. wong .",
    "zyzzyva : speculative byzantine fault tolerance .",
    ", 27(4 ) , 2009 .",
    "petr kuznetsov and rodrigo rodrigues .",
    "bftw@xmath260 : why ?",
    "workshop on the theory and practice of byzantine fault tolerance .",
    ", 40(4):8286 , 2009 .",
    "leslie lamport .",
    ", 1(2):77101 , 1986 .",
    "leslie lamport , robert  e. shostak , and marshall  c. pease .",
    "the byzantine generals problem .",
    ", 4(3):382401 , 1982 .",
    "harry  c. li , allen clement , amitanand  s. aiyer , and lorenzo alvisi . . in _ proceedings of srds",
    "_ , pages 114126 , 2007 .",
    "barbara liskov and rodrigo rodrigues . .",
    "in _ proceedings of icdcs _ , 2006 .",
    "nancy  a. lynch and alexander  a. shvartsman . .",
    "in _ proceedings of disc _ , pages 173190 , 2002 .",
    "nancy  a. lynch and mark  r. tuttle .",
    "an introduction to input / output automata .",
    ", 2:219246 , 1989 .",
    "dahlia malkhi and michael  k. reiter . .",
    ", 5(2):113127 , march 1997 .",
    "dahlia malkhi and michael  k. reiter .",
    "uorum systems . , 11(4):203213 , 1998 .",
    "dahlia malkhi and michael  k. reiter . .",
    "in _ proceedings of srds _ , pages 5158 , 1998 .",
    "jean - philippe martin , lorenzo alvisi , and michael dahlin . .",
    "in _ proceedings of disc _ , pages 311325 , 2002 .",
    "website , 2009 .",
    "available online at http://www.linuxfoundation.org/collaborate/workgroups/networking/netem .",
    "michael  k. reiter . .",
    "in _ proceedings of ccs _ , pages 6880 , 1994 .",
    "adi shamir . .",
    ", 22(11):612613 , november 1979 .",
    "alexander shraer , jean - philippe martin , dahlia malkhi , and idit keidar .",
    "data - centric reconfiguration with network - attached disks . in _ proceedings of ladis _ ,",
    "pages 2226 , 2010 .",
    "atul singh , tathagata das , petros maniatis , peter druschel , and timothy roscoe .",
    "bft protocols under fire . in _ proceedings of nsdi _ , pages 189204 , 2008 .",
    "craig a.  n. soules , garth  r. goodson , john  d. strunk , and gregory  r. ganger .",
    "metadata efficiency in versioning file systems . in _ proceedings of",
    "fast _ , pages 4358 , 2003 .",
    "john  d. strunk , garth  r. goodson , michael  l. scheinholtz , craig a.  n. soules , and gregory  r. ganger .",
    "self - securing storage : protecting data in compromised system . in _ proceedings of osdi _ , pages 1212 , 2000 .",
    "giuliana  santos veronese , miguel correia , alysson  neves bessani , lau  cheuk lung , and paulo verssimo .",
    "efficient byzantine fault - tolerance .",
    ", 62(1):1630 , 2013 .    sue - hwey wu , scott  a. smolka , and eugene  w. stark .",
    "composition and behaviors of probabilistic i / o automata . in _ proceedings of concur",
    "_ , concur 94 , pages 513528 , 1994 .",
    "a read operation @xmath132 by a correct reader has timestamp @xmath29 iff the reader in @xmath132 selected @xmath77 in line  [ alg : reader : select ] such that @xmath261 . a write operation",
    "@xmath177 has timestamp @xmath29 iff the writer increments its timestamp to @xmath29 in line  [ alg : writer : timestamp ] .",
    "we show that if @xmath28 is the value decoded in line  [ alg : reader : decode ] , then @xmath28 was indeed written . to show this",
    ", we argue that the fragments used to decode @xmath28 were written .",
    "note that prior to decoding @xmath28 from a set of fragments , the reader establishes the correctness of each fragment as follows .",
    "first , in line  [ alg : reader : cc ] , the reader chooses a cross - checksum that was received from @xmath36 servers . since one of these servers",
    "is correct , the chosen cross - checksum was indeed written .",
    "secondly , the reader checks in line  [ alg : reader : fr ] that each of the @xmath36 fragments used to decode @xmath28 hashes to the corresponding entry in the cross - checksum . by the collision - resistance of @xmath263 ,",
    "all fragments that pass this check were indeed written . therefore ,",
    "if @xmath28 is the value decoded from these fragments , we conclude that @xmath28 was written .      if @xmath77 is valid , then by definition  [ def : validcand ] , ( @xmath77 ) is true at some correct server @xmath266 .",
    "hence , @xmath267.n_h$ ] holds at @xmath266 . by the pre - image resistance of @xmath263 , no computationally bounded adversary",
    "can acquire @xmath268 from the sole knowledge of @xmath269 .",
    "hence , @xmath268 stems from the writer in a write operation @xmath177 with timestamp @xmath88 . by algorithm  [ alg : writer ] ,",
    "line  [ alg : writer : complete ] , the value of @xmath268 is revealed after the store phase in @xmath177 completed .",
    "hence , there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath265 .      as @xmath77 is valid , by lemma  [ la : pow ] a there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath270 .",
    "hence , ( @xmath77 ) is true at every server in @xmath201 .",
    "thus , no server in @xmath201 replies with a timestamp @xmath271 in line  [ alg : server : ret ] .",
    "therefore , at most @xmath272 timestamps received by the reader in the filter phase are lower than @xmath88 , and so @xmath77 is never excluded from @xmath81 .      if @xmath29 is the timestamp of write@xmath133 , it is sufficient to show that the timestamp of @xmath132 is not lower than @xmath29 . to prove this , we show that @xmath273 such that _ ( i ) _ @xmath274 and _ ( ii ) _ @xmath138 is never excluded from @xmath81 .    by the time @xmath275 completes , @xmath36 correct servers hold in @xmath25 a candidate",
    "whose timestamp is @xmath29 or greater . according to lines  [ alg : server : update - complete ] ,  [ alg : server : update - gc ] of algorithm  [ alg : server ] , a correct server never changes @xmath25 to a candidate with a lower timestamp .",
    "hence , when @xmath132 is invoked , @xmath36 correct servers hold candidates with timestamp @xmath29 or greater in @xmath25 .",
    "hence , during the collect phase in @xmath132 , some candidate received from a correct server with timestamp @xmath29 or greater is inserted in @xmath81 .",
    "such a candidate is necessarily valid because either the server received it directly from the writer , or the server checked its integrity in line  [ alg : server : valid - check ] .",
    "let @xmath138 be the valid candidate with the highest timestamp in @xmath81 . then by lemma  [ la : noexclusion ] , @xmath138 is never excluded from @xmath81 . by line  [ alg :",
    "reader : select ] , no candidate @xmath77 such that @xmath276 is selected . since @xmath274 , no candidate with a timestamp lower than @xmath29",
    "is selected in @xmath132 .",
    "[ la : ratomic ] let @xmath132 and @xmath136 be two completed operations by correct readers . if @xmath136 follows @xmath132 that returns @xmath28 , then @xmath136 does not return a value older than @xmath28 .    if @xmath77 is the candidate selected in @xmath132 , it is sufficient to show that the timestamp of @xmath136 is not lower than @xmath88 .",
    "we argue that @xmath81 contains a candidate @xmath138 such that _",
    "( i ) _ @xmath139 and _ ( ii ) _",
    "@xmath138 is never excluded from @xmath81 .    by the time @xmath132 completes , @xmath36 correct servers hold @xmath77 in @xmath26 .",
    "as @xmath77 was selected in @xmath132 in line  [ alg : reader : select ] , some correct server asserted that @xmath77 is valid in line  [ alg : server : valid - check ] . according to algorithm  [ alg : server ] , if a correct server excludes @xmath77 from @xmath26 in line  [ alg : server : gc ] , then the server changed @xmath25 to a valid candidate with timestamp @xmath88 or greater in line  [ alg : server : update - gc ] .",
    "consequently , @xmath36 correct servers hold in @xmath137 a valid candidate with timestamp @xmath88 or greater . as such , during collect in @xmath136 , a valid candidate @xmath138 such that @xmath139 is included in @xmath81 , and by lemma  [ la : noexclusion ] , @xmath138 is never excluded from @xmath81 . by line  [ alg :",
    "reader : select ] , no candidate with a timestamp lower than @xmath255 is selected . since @xmath139 , no candidate with a timestamp lower than @xmath88",
    "is selected in @xmath136 .",
    "we show that no operation invoked by a correct client ever blocks .",
    "the wait - freedom argument of the write is straightforward ; in every phase , the writer awaits acks from the least number @xmath20 of correct servers .",
    "the same argument holds for the collect phase of the read .",
    "hence , in the remainder of the proof , we show that no read blocks in the filter phase . by contradiction ,",
    "consider a read @xmath132 by reader @xmath71 that blocks during the filter phase after receiving filter_ack messages from all correct servers .",
    "we distinguish two cases : ( case 1 ) @xmath81 includes a valid candidate and ( case 2 ) @xmath81 includes no valid candidate .",
    "* case 1 : let @xmath77 be the highest valid candidate included in @xmath81 .",
    "we show that ( @xmath77 ) @xmath277 ( @xmath77 ) holds .",
    "since @xmath77 is valid , by lemma  [ la : pow ] , there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath265 .",
    "thus , during the filter phase , ( @xmath77 ) holds at every server in @xmath201 . as no valid candidate in @xmath81 has a higher timestamp than @xmath77 , _",
    "( i ) _ all servers @xmath264 ( at least @xmath36 ) responded with timestamp @xmath88 , corresponding erasure coded fragment @xmath34 , cross - checksum @xmath37 in line  [ alg : server : ret ] and _ ( ii ) _ all correct servers ( at least @xmath20 ) responded with timestamps at most @xmath88 . by _",
    "( i ) _ , @xmath77 is . by _",
    "( ii ) _ , every @xmath141 such that @xmath142 became and was excluded from @xmath81 , implying that @xmath77 is .",
    "* case 2 : here , we show that @xmath278 .",
    "as none of the candidates in @xmath81 is valid , during the filter phase , the integrity check in line  [ alg : server : valid - check ] failed for every candidate in @xmath81 at all correct servers .",
    "hence , at least @xmath20 servers responded with timestamp @xmath144 .",
    "since @xmath144 is lower than any candidate timestamp , all candidates were classified as and were excluded from @xmath81 .      by algorithm  [ alg : writer ]",
    ", the write completes after two phases , store and complete , each taking one communication round . by algorithm  [ alg : reader ] , the read completes after two phases , collect and filter , each incurring one communication round .",
    "a read operation @xmath132 by a non - malicious reader has timestamp @xmath29 iff the reader in @xmath132 selected @xmath77 in line  [ alg2:reader : select ] such that @xmath261 .",
    "a write operation @xmath177 has timestamp @xmath29 iff the clock procedure in @xmath177 returned @xmath29 in line  [ alg2:writer : clock ] .",
    "we show that if @xmath28 is the value decoded in line  [ alg2:reader : decode ] , then @xmath28 was indeed written .",
    "to show this , we argue that the fragments used to decode @xmath28 were written .",
    "note that prior to decoding @xmath28 from a set of fragments , the reader establishes the correctness of each fragment as follows .",
    "first , in line  [ alg2:reader : cc ] , the reader chooses a cross - checksum that was received from @xmath36 servers .",
    "since one of these servers is correct , the chosen cross - checksum was indeed written .",
    "secondly , the reader checks in line  [ alg2:reader : fr ] that each of the @xmath36 fragments used to decode @xmath28 hashes to the corresponding entry in the cross - checksum . by the collision - resistance of @xmath263 ,",
    "all fragments that pass this check were indeed written . therefore ,",
    "if @xmath28 is the value decoded from these fragments , we conclude that @xmath28 was written .",
    "[ la2:powr ] let @xmath15 be a completed operation by a correct client and let @xmath177 be a completed @xmath279 such that @xmath15 precedes @xmath177 . if @xmath280 and @xmath281 are the timestamps of @xmath15 and @xmath177 respectively , then @xmath282 .    by the time @xmath15 completes , @xmath36 correct servers hold in @xmath25 a candidate",
    "whose timestamp is @xmath280 or greater .",
    "according to lines  [ alg2:server : update - complete ] ,  [ alg2:server : update - filter ] ,  [ alg2:server : update - repair ] of algorithm  [ alg2:server ] , a correct server never updates @xmath25 with a candidate that has a lower timestamp . hence , the writer in @xmath177 obtains from the clock procedure a timestamp that is greater or equal to @xmath280 from some correct server @xmath7 .",
    "let @xmath77 be the candidate held in @xmath25 by server @xmath7 , and let @xmath88 be the timestamp reported to the writer .",
    "we now argue that @xmath88 is not fabricated . to see why , note that prior to overwriting @xmath25 with @xmath77 in line  [ alg2:server : update - filter ] ( resp .",
    "[ alg2:server : update - repair ] ) , server @xmath7 checks that @xmath77 is valid in line [ alg2:server : valid - filter ] ( resp .",
    "[ alg2:server : valid - repair ] ) .",
    "the predicate as defined in line  [ alg2:server : valid - pred ] subsumes an integrity check for @xmath88 .",
    "hence , @xmath88 passes the integrity check in line  [ alg2:writer : ts - integrity ] ; according to the write algorithm , @xmath283 .",
    "if @xmath77 is valid , then by definition  [ def2:validcand ] , ( @xmath77 ) is true at some correct server @xmath266 .",
    "hence , either @xmath267.n_h$ ] or @xmath285 , c.ts , h(c.n ) , k_j$ ] ) must hold at @xmath266 . by the pre - image resistance of @xmath263 ,",
    "no computationally bounded adversary can acquire @xmath268 from the sole knowledge of @xmath269 .",
    "hence , @xmath268 stems from some writer in a write operation @xmath177 with timestamp @xmath88 . by algorithm  [ alg2:writer ] ,",
    "line  [ alg2:writer : complete ] , the value of @xmath268 is revealed after the store round in @xmath177 completed .",
    "hence , there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath284 .",
    "as @xmath77 is valid , by lemma  [ la2:pow ] a there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath286 .",
    "hence , ( @xmath77 ) is true at every server in @xmath201 .",
    "thus , no server in @xmath201 replies with a timestamp @xmath271 in line  [ alg2:server : ret ] .",
    "therefore , at most @xmath272 timestamps received by the reader in the filter round are lower than @xmath88 , and so @xmath77 is never excluded from @xmath81 .      if @xmath29 is the timestamp of write@xmath133 , it is sufficient to show that the timestamp of @xmath132 is not lower than @xmath29 . to prove this , we show that @xmath273 such that _ ( i ) _ @xmath274 and _ ( ii ) _",
    "@xmath138 is never excluded from @xmath81 .    by the time @xmath275 completes , @xmath36 correct servers hold in @xmath25 a candidate",
    "whose timestamp is @xmath29 or greater .",
    "according to lines  [ alg2:server : update - complete ] ,  [ alg2:server : update - filter ] ,  [ alg2:server : update - repair ] of algorithm  [ alg2:server ] , a correct server never changes @xmath25 to a candidate with a lower timestamp .",
    "hence , when @xmath132 is invoked , @xmath36 correct servers hold candidates with timestamp @xmath29 or greater in @xmath25 .",
    "hence , during collect in @xmath132 , some candidate received from a correct server with timestamp @xmath29 or greater is inserted in @xmath81 .",
    "such a candidate is necessarily valid by the integrity checks in lines  [ alg2:server : valid - filter ] ,  [ alg2:server : valid - repair ] .",
    "let @xmath138 be the valid candidate with the highest timestamp in @xmath81 .",
    "then by lemma  [ la2:noexclusion ] , @xmath138 is never excluded from @xmath81 . by line  [ alg2:reader : select ] , no candidate @xmath77 such that @xmath276 is selected . since @xmath274 , no candidate with a timestamp lower than @xmath29",
    "is selected in @xmath132 .",
    "[ la2:rratomic ] _ ( read atomicity ) .",
    "_ let @xmath132 and @xmath136 be two completed operations by correct readers .",
    "if @xmath136 follows @xmath132 that returns @xmath28 , then @xmath136 does not return a value older than @xmath28 .    if @xmath77 is the candidate selected in @xmath132 , it is sufficient to show that the timestamp of @xmath136 is not lower than @xmath88 .",
    "we argue that @xmath81 contains a candidate @xmath138 such that _ ( i ) _ @xmath139 and _ ( ii ) _ @xmath138 is never excluded from @xmath81 .",
    "as @xmath77 is selected in @xmath132 in line  [ alg2:reader : select ] only if ( @xmath77 ) holds , some correct server verified the integrity of @xmath88 and @xmath268 in line  [ alg2:server : valid - nonce ] .",
    "in addition , in repair , the reader in @xmath132 checks the integrity of @xmath244 .",
    "we distinguish two cases :    * case 1 : if @xmath244 passes the integrity check in line  [ alg2:reader : vec - integrity ] , then the integrity of @xmath77 has been fully established .",
    "hence , by the time @xmath132 completes , @xmath36 correct servers validated @xmath77 in line  [ alg2:server : valid - filter ] and changed @xmath25 to @xmath77 or to a higher valid candidate .",
    "* case 2 : if vector @xmath244 fails the integrity check in line  [ alg2:reader : vec - integrity ] , then in repair , @xmath77 is repaired in line  [ alg2:reader : repair ] and subsequently written back to @xmath36 correct servers .",
    "hence , by the time @xmath132 completes , @xmath36 correct servers validated @xmath77 in line  [ alg2:server : valid - repair ] and changed @xmath25 to @xmath77 or to a higher valid candidate .    consequently , in the collect round in @xmath136 a valid candidate @xmath138 such that @xmath287 is included in @xmath81 , and by lemma  [ la2:noexclusion ] , @xmath138 is never excluded from @xmath81 . by line  [ alg2:reader : select ] ,",
    "no candidate with a timestamp lower than @xmath138 is selected . since @xmath139 , no candidate with a timestamp lower than @xmath88",
    "is selected in @xmath136 .",
    "we show that no operation invoked by a correct client ever blocks .",
    "the wait - freedom argument of the write is straightforward ; in every round , the writer awaits acks from the least number @xmath20 of correct servers .",
    "the same argument holds for the collect and the repair rounds of the read .",
    "hence , in the remainder of the proof , we show that no read blocks in the filter round . by contradiction , consider a read @xmath132 by reader @xmath71 that blocks during the filter round after receiving filter_ack messages from all correct servers .",
    "we distinguish two cases : ( case 1 ) @xmath81 includes a valid candidate and ( case 2 ) @xmath81 includes no valid candidate .    *",
    "case 1 : let @xmath77 be the highest valid candidate included in @xmath81 .",
    "we show that ( @xmath77 ) @xmath277 ( @xmath77 ) holds . since @xmath77 is valid , by lemma  [ la2:pow ] , there exists a set @xmath201 of @xmath36 correct servers such that each server @xmath264 changed @xmath85 $ ] to @xmath284 .",
    "thus , during the filter round , ( @xmath77 ) holds at every server in @xmath201 . as no valid candidate in @xmath81 has a higher timestamp than @xmath77 , _",
    "( i ) _ all servers @xmath264 ( at least @xmath36 ) responded with timestamp @xmath88 , corresponding erasure coded fragment @xmath34 , cross - checksum @xmath37 and repair vector @xmath196 in line  [ alg2:server : ret ] and _ ( ii ) _ all correct servers ( at least @xmath20 ) responded with timestamps at most @xmath88 . by _",
    "( i ) _ , @xmath77 is . by _",
    "( ii ) _ , every @xmath141 such that @xmath142 became and was excluded from @xmath81 , implying that @xmath77 is . * case 2 : here , we show that @xmath278 . as",
    "none of the candidates in @xmath81 is valid , during filter , the integrity check in line  [ alg2:server : valid - nonce ] failed for every candidate in @xmath81 at all correct servers .",
    "hence , at least @xmath20 servers responded with timestamp @xmath144 .",
    "since @xmath144 is lower than any candidate timestamp , all candidates were classified as and were excluded from @xmath81 .      by construction",
    ", a fabricated timestamp would fail the check in line  [ alg2:writer : ts - integrity ] .",
    "hence , no fabricated timestamp is ever used in a write .",
    "the lemma then directly follows from the algorithm of write .",
    "algorithms  [ alg2:writer ] ,  [ alg2:server ] and  [ alg2:reader ] feature a latency of _ three _ communication rounds for the write and _ two _ for the read in the absence of attacks . in the worst case , the read latency is _ three _ communication rounds .    by algorithm  [ alg2:writer ]",
    ", the write completes after three rounds , clock , store and complete , each taking one communication round . in the absence of attacks , by algorithm  [ alg2:reader ]",
    ", the read completes after two rounds , collect and filter , each taking one communication round . under bigmac",
    "@xcite attacks the read may go to the repair round , incurring one additional communication round ."
  ],
  "abstract_text": [
    "<S> we present powerstore , the first efficient robust storage protocol that achieves _ optimal latency _ without using digital signatures .    </S>",
    "<S> powerstore s _ robustness _ comprises tolerating asynchrony , maximum number of byzantine storage servers , any number of byzantine readers and crash - faulty writers , and guaranteeing _ wait - freedom _ and _ linearizability _ of read / write operations . </S>",
    "<S> furthermore , powerstore s _ efficiency _ stems from combining _ lightweight authentication _ , _ erasure coding _ and _ metadata write - backs _ where readers write - back only metadata to achieve linearizability .    at the heart of powerstore  </S>",
    "<S> are _ proofs of writing ( pow ) _ : a novel storage technique  based on lightweight cryptography . </S>",
    "<S> pow enable reads and writes in the single - writer variant of powerstore  to have latency of 2 rounds of communication between a client and storage servers in the _ worst - case _ ( which we show optimal ) .    </S>",
    "<S> we further present and implement a multi - writer powerstore  variant featuring 3-round writes / reads where the third read round is invoked only under active attacks , and show that it outperforms existing robust storage protocols , including crash - tolerant ones . </S>"
  ]
}