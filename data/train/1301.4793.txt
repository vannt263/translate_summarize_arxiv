{
  "article_text": [
    "consider the system model shown in fig .  [ fig : systemmodel ] :",
    "a continuous - time linear time - invariant system / filter is fed by a continuous - time signal @xmath0 .",
    "the system output @xmath1 is sampled ( at regular or irregular intervals ) and the samples are corrupted by discrete - time additive white gaussian noise . from the noisy samples",
    "@xmath2 , we wish to estimate the clean samples @xmath3 , or the clean signal @xmath1 at arbitrary instants @xmath4 , or the state trajectory of the system , or  of particular interest in this paper  the input signal @xmath0 at arbitrary instants @xmath4 .",
    "we will not assume that any of these signals is bandlimited ( in the strict sense required by the sampling theorem ) ; instead , the key assumption in this paper is that the given linear system has a finite - dimensional state space representation .    problems of this kind are ubiquitous . for example , fig .",
    "[ fig : systemmodel ] might model an analog - to - digital converter with a non - ideal anti - aliasing filter and with quantization noise @xmath5 ; indeed , this application is a main motivation for this paper . as another example ,",
    "[ fig : systemmodel ] might model a sensor with some internal dynamics which limits its temporal resolution of the desired quantity @xmath0 . in both examples , we are primarily interested in estimating the input signal @xmath0",
    ".    we will address these estimation problems under the further assumption that the input signal @xmath0 is white gaussian noise .",
    "it might perhaps seem at first that this assumption is problematic when @xmath0 is actually the signal of interest , as in the two mentioned examples .",
    "however , we will argue that this assumption is meaningful in such cases and that the lmmse ( linear minimum mean squared error ) estimate of @xmath0 is well defined and useful .",
    "an example of such an lmmse estimate of @xmath0 is shown in fig .",
    "[ fig : plotinpest ] . the nature of this estimate will further be illuminated by reformulating it as a regularized least - squares problem with a penalty term @xmath6 , as will be discussed in section  [ sec : inputestimation ] .",
    "( 84,32.5)(-2,-10 ) ( 0,2.5)(5,5 ) ( 2.5,0.5)(0,0)[ct]wgn ( 2.5,-4)(0,0)[ct]source ( 5,5)(1,0)15 ( 12.5,6)(0,0)[bc]@xmath0 ( 20,0)(15,10 ) ( 27.5,-2)(0,0)[ct]linear ( 27.5,-6)(0,0)[ct]system / filter ( 24,2.5 )    ( 0,0)(0,0 ) ( -5,0)(1,0)20 ( 16,2.7)(0,0)[tl]@xmath7 ( 0,-3)(0,1)15 ( 0,-1)system model.,title=\"fig : \" ]    ( 35,5)(1,0)12 ( 41,6)(0,0)[bc]@xmath1 ( 47,5)(0,1)0.5 ( 52,5)(-3,2)5 ( 52,5 ) ( 52,5)(1,0)11 ( 58,3)(0,0)[tc]@xmath3 ( 65,5 )    ( 0,0)(0,0 ) ( 0,0 ) ( -1,0)(1,0)2 ( 0,-1)(0,1)2    ( 62.5,17.5)(5,5 ) ( 69,20)(0,0)[tl]wgn ( 69,15.5)(0,0)[tl]source ( 65,17.5)(0,-1)10.5 ( 64,12)(0,0)[cr]@xmath5 ( 67,5)(1,0)15 ( 77,3.5)(0,0)[ct]@xmath2    the assumption that @xmath0 is white gaussian noise turns our system model ( fig .  [",
    "fig : systemmodel ] ) into a linear gaussian model , and lmmse estimation of the state trajectory or of the clean output signal @xmath1 amounts essentially to kalman filtering ( or rather kalman smoothing ) @xcite",
    ". however , estimation of the continuous - time input signal @xmath0 does not seem to have been addressed in the kalman filtering literature .",
    "we will also consider some extensions of the system model including time - varying systems , vector signals , and systems with internal noise sources .",
    "these extensions are required in some of the motivating applications , but the extensions are straightforward and standard in kalman filtering",
    ".    we will address these estimation problems ( as described above ) using factor graphs .",
    "factor graphs @xcite and similar graphical models @xcite allow a unified description of system models and algorithms in many different fields .",
    "in particular , gaussian message passing in factor graphs subsumes discrete - time kalman filtering and many variations of it @xcite .",
    "the graphical - model approach has facilitated the use of these techniques as components in more general inference problems and it has become a mode of teaching discrete - time kalman filtering itself .    in this paper , we extend the factor graph approach to continuous - time models with discrete - time observations as described above .",
    "this extension appears to be new , and it significantly enlarges the domain of graphical models .",
    "we note , in particular , that the lmmse estimates of the continuous - time signals associated with such models ( such as @xmath0 and @xmath1 in fig .",
    "[ fig : systemmodel ] ) become computational objects that can be handled with arbitrary temporal resolution by gaussian message passing .",
    "applications of the methods of this paper ( in addition to those already mentioned ) have been reported in @xcite and @xcite . in @xcite , a new method for sampling jitter correction",
    "is proposed that uses the slope of @xmath1 , which is available in the state space model , in an iterative algorithm . in @xcite , a new approach to analog - to - digital conversion",
    "is proposed which combines unstable analog filters with digital estimation of @xmath0 as proposed in the present paper . both of these applications",
    "build on @xcite ( which does not contain the proofs ) and rely on the present paper for a full justification of the proposed algorithms .",
    "further applications ( including beamforming with sensor arrays and hilbert transforms ) will be reported elsewhere .    in summary",
    ", this paper    * extends the factor graph approach to continuous - time models as in fig .",
    "[ fig : systemmodel ] ; * extends kalman smoothing ( forward - backward gaussian message passing ) to the estimation of input signals as @xmath0 in fig .",
    "[ fig : systemmodel ] ; * provides the necessary background for subsequent work such as @xcite and @xcite .",
    "the paper builds on , and assumes some familiarity with , the factor graph approach to discrete - time kalman filtering as given in @xcite .",
    "the paper is structured as follows .",
    "the system model is formally stated in section  [ sec : systemmodel ] and represented in factor graph notation in section  [ sec : fg ] .",
    "state estimation and output signal estimation are then essentially obvious , but some pertinent comments are given in section  [ sec : gaussmesspass ] .",
    "estimation of the input signal is discussed in section  [ sec : inputestimation ] . in section  [ sec : numericalexamples ] , the estimation algorithms are illustrated by some simple numerical examples .",
    "a number of extensions of the basic system model are outlined in section  [ sec : extensions ] , and section  [ sec : conclusion ] concludes the paper .    the following notation will be used : @xmath8 denotes the complex conjugate of @xmath9 ; @xmath10 denotes the transpose of the matrix @xmath11 ; @xmath12 denotes the hermitian transpose of @xmath11 ; @xmath13 denotes an identity matrix ; `` @xmath14 '' denotes equality up to a constant scale factor ; @xmath15 or @xmath16 denotes a normal ( gaussian ) distribution with mean @xmath17 and variance @xmath18 , or with mean vector @xmath17 and covariance matrix @xmath19 , respectively .",
    "let @xmath20 be the state of a linear system ( as , e.g. , in fig .",
    "[ fig : systemmodel ] ) which evolves in time according to @xmath21 where @xmath22 denotes the derivative with respect to time and where both the matrix @xmath23 and the vector @xmath24 are known .",
    "the system output is the discrete - time signal @xmath25 with @xmath26 where @xmath27 ( with @xmath28 ) are discrete instants of time and where @xmath29 is known .",
    "we will usually observe only the noisy output signal @xmath30 defined by @xmath31 where @xmath32 ( the noise ) are independent gaussian random variables , each of which takes values in @xmath33 and has a diagonal covariance matrix @xmath34 .",
    "the ( real and scalar ) input signal @xmath0 will be modeled as white gaussian noise , i.e. , for @xmath35 , the integral @xmath36 is a zero - mean gaussian random variable with variance @xmath37 , and any number of such integrals are independent random variables provided that the corresponding integration intervals are disjoint . in consequence , it is appropriate to replace ( [ eqn : contsystdiffeq ] ) by @xmath38 where @xmath39 is a zero - mean gaussian random variable with infinitesimal variance @xmath40 .    as stated in the introduction , we will argue later ( in section  [ sec : inputestimation ] ) that modeling @xmath0 as white gaussian noise is meaningful even when @xmath0 is a ( presumably smooth ) signal of interest that we wish to estimate .    for any fixed initial state @xmath41 , equation  ( [ eqn : contsystdiff ] )",
    "induces a probability density @xmath42 over the possible values of @xmath43 ( where @xmath44 and @xmath45 are unrelated to the discrete times @xmath46 in ( [ eqn : yk ] ) ) .",
    "specifically , integrating ( [ eqn : contsystdiff ] ) from @xmath47 to @xmath48 yields @xmath49 with @xmath50 .",
    "if @xmath0 is white gaussian noise ( with @xmath51 as above ) , then the integral in ( [ eqn : integrated ] ) is a zero - mean gaussian random vector with covariance matrix @xcite    rcl v_s & = & _ u^2 _ 0^t e^a(t- ) b b^(e^a(t-))^",
    "d [ eqn : integratedvariance1 ] + & = & _ u^2 _ 0^t e^a b b^(e^a)^ d. [ eqn : integratedvariance ]    it is thus clear that , for fixed @xmath41 , @xmath43 is a gaussian random vector with mean @xmath52 and covariance matrix @xmath53 , i.e. , @xmath54",
    "we will use forney factor graphs ( also known as normal factor graphs @xcite ) as in @xcite and @xcite .",
    "the nodes / boxes in such a factor graph represent factors and the edges in the graph represent variables .    in this notation , the system model of section  [ sec : systemmodel ]",
    "may be represented by the factor graph shown in fig .",
    "[ fig : systemmodelfactorgraph ] . more precisely , fig .",
    "[ fig : systemmodelfactorgraph ] represents the joint probability density of the variables in the system model at discrete times @xmath55 .    note",
    "that fig .",
    "[ fig : systemmodelfactorgraph ] shows only a section ( from @xmath56 to @xmath57 ) of the factor graph ; the complete factor graph starts at time @xmath44 and ends at some time @xmath58 , and it may contain additional nodes to represent any pertinent initial or final conditions . note also",
    "that , apart from the gaussian nodes / factors @xmath59 and @xmath60 , the nodes / boxes in fig .  [ fig : systemmodelfactorgraph ] represent linear constraints .    for details of this factor graph notation , we refer to @xcite .",
    "( 690,550)(0,0 ) ( 130,470)(0,0)[br]@xmath61 ( 40,455)(1,0)110 ( 150,430)(50,50)@xmath62 ( 200,455)(1,0)110    ( 310,415)(80,80 ) ( 350,530)(0,0)@xmath63    ( 390,455)(1,0)110 ( 500,430)(50,50)@xmath62 ( 550,455)(1,0)120 ( 565,470)(0,0)[bl]@xmath64    ( 175,430)(0,-1)100 ( 525,430)(0,-1)100 ( 135,250)(80,80)@xmath65 ( 485,250)(80,80)@xmath65    ( 175,250)(0,-1)100 ( 185,200)(0,0)[cl]@xmath3 ( 525,250)(0,-1)100 ( 535,200)(0,0)[cl]@xmath66    ( 0,100)(50,50 ) ( 25,85)(0,0)[ct]@xmath67 ( 50,125)(1,0)100 ( 100,135)(0,0)[cb]@xmath5 ( 150,100)(50,50)@xmath68 ( 350,100)(50,50 ) ( 400,125)(1,0)100 ( 450,135)(0,0)[cb]@xmath69 ( 500,100)(50,50)@xmath68    ( 185,45)(0,0)[cl]@xmath70 ( 175,100)(0,-1)100 ( 535,45)(0,0)[cl]@xmath71 ( 525,100)(0,-1)100    ( 10,350)(0,0 )  ( 700,350)(0,0 )     as shown in fig .",
    "[ fig : systemmodelfactorgraph ] , the function ( [ eqn : fgaussian ] ) can immediately be used as a node in a factor graph .",
    "however , the function ( [ eqn : fgaussian ] ) can itself be represented by nontrivial factor graphs . a first such factor graph is shown in fig .",
    "[ fig : summarizedfactorgraph ] , which corresponds to ( [ eqn : integrated])([eqn : integratedvariance ] ) .",
    "plugging fig .",
    "[ fig : summarizedfactorgraph ] into fig .",
    "[ fig : systemmodelfactorgraph ] results in a standard discrete - time linear gaussian factor graph as discussed in depth in @xcite .",
    "( 65,32.5)(0,0 ) ( 38,22.5)(5,5 ) ( 37,25)(0,0)[cr]@xmath72 ( 40.5,22.5)(0,-1)12 ( 0,8)(1,0)20 ( 7.5,9)(0,0)[bc]@xmath73 ( 20,4)(8,8)@xmath74 ( 28,8)(1,0)10 ( 38,5.5)(5,5)@xmath68 ( 43,8)(1,0)22 ( 57.5,9)(0,0)[bc]@xmath43 ( 15,0)(35,32.5 )    the factor graph of fig .",
    "[ fig : systemmodelfactorgraph ] is easily refined to arbitrary temporal resolution by splitting the node / factor @xmath63 as shown in fig .",
    "[ fig : splitnode ] . in this way ,",
    "both the state @xmath75 and the output signal @xmath76 become available for arbitrary instants @xmath4 between @xmath56 and @xmath57 .",
    "each of the factors in fig .",
    "[ fig : splitnode ] can , of course , be replaced by the corresponding decomposition according to fig .",
    "[ fig : summarizedfactorgraph ] .",
    "( 53,20)(0,-1.5 ) ( 0,-1.5)(53,20 ) ( -12,10)(1,0)23 ( -2,11)(0,0)[br]@xmath77 ( 11,7)(6,6 ) ( 14,5.5)(0,0)[ct]@xmath78 ( 17,10)(1,0)19 ( 26.5,11)(0,0)[cb]@xmath79 ( 36,7)(6,6 ) ( 39,5.5)(0,0)[ct]@xmath80 ( 42,10)(1,0)23 ( 55,11)(0,0)[bl]@xmath64    note that the input signal @xmath0 is not explicitly represented in figures [ fig : systemmodelfactorgraph][fig : splitnode ] . for the estimation of @xmath0",
    ", we will therefore need another decomposition of the node / factor @xmath63 .",
    "having thus obtained a discrete - time factor graph ( with an arbitrary temporal resolution ) , estimating @xmath75 or @xmath1 from the noisy observations , ,  by means of gaussian message passing is standard and discussed in detail in @xcite ( cf .  also @xcite and @xcite ) .",
    "we therefore confine ourselves to a few general remarks ( mostly excerpted from @xcite and @xcite ) and some additional remarks on message passing through the node / factor @xmath81 .      1 .   in linear gaussian factor graphs such as figures ( where all factors are either gaussians or linear constraints ) , all sum - product messages are gaussians and sum - product message passing coincides with max - product message passing",
    ". moreover , map ( maximum _ a posteriori _ ) estimation coincides both with mmse ( minimum mean squared error ) estimation and with lmmse ( linear / affine mmse ) estimation . 2 .   in general , every edge in the factor graph carries two messages , one in each direction .",
    "since all the edges in figures [ fig : systemmodelfactorgraph][fig : splitnode ] are directed ( i.e. , drawn with an arrow ) , we can unambiguously refer to the forward message @xmath82 and the backward message @xmath83 along the edge representing some variable  @xmath84 .",
    "gaussian messages have the form @xmath85 they are naturally parameterized by the mean vector @xmath17 and either the matrix @xmath86 or the covariance matrix @xmath19 ( @xmath87 ) .",
    "degenerate gaussians , where either @xmath86 or @xmath19 do not have full rank , are often permitted and sometimes unavoidable ; in such cases , only @xmath86 or @xmath19 , but not both , are well defined .",
    "we will use the symbols @xmath88 and @xmath89 ( or @xmath90 ) to denote the parameters of the forward message ( along some edge / variable @xmath84 ) and @xmath91 and @xmath92 ( or @xmath93 ) for the parameters of the backward message .",
    "the natural scheduling of the message computations in fig .",
    "[ fig : systemmodelfactorgraph ] consists of a forward recursion for @xmath94 and an independent backward recursion for @xmath95 .",
    "both of these recursions use the messages @xmath96 with parameters @xmath97 and @xmath98 ( assuming @xmath99 is known ; if @xmath2 is not observed / unknown , then @xmath100 and @xmath101 ) .",
    "5 .   since the factor graph in fig .",
    "[ fig : systemmodelfactorgraph ] has no cycles , the _",
    "a  posteriori _ distribution of any variable @xmath84 ( or @xmath102 , @xmath103 ,  ) in the factor graph is the product @xmath104 of the corresponding two messages , up to a scale factor .",
    "the parameters of this marginal distribution are @xmath105 and @xmath106 given by @xmath107 and @xmath108 .",
    "tabulated message computation rules ( in particular , tables 24 of @xcite ) allow to compose a variety of different algorithms to compute the same sum - product messages .",
    "the variety arises from different parameterizations of the messages and from local manipulations ( including splitting and grouping of nodes ) of the factor graph .",
    "gaussian message passing through the node / factor @xmath109 is summarized in table  [ tab : messagepassingrules ] . both the forward message ( with parameters ( [ tabeqn : msgfmx ] ) and ( [ tabeqn : msgfvx ] ) ) and the backward message ( with parameters ( [ tabeqn : msgbmx ] ) and  ( [ tabeqn : msgbvx ] ) ) are easily obtained from fig .  [",
    "fig : summarizedfactorgraph ] , ( [ eqn : integratedvariance1 ] ) and ( [ eqn : integratedvariance ] ) , and tables 2 and  3 of @xcite .",
    "if the matrix @xmath11 is diagonalizable , then the integrals in ( [ tabeqn : msgfvx ] ) and ( [ tabeqn : msgbvx ] ) can easily be expressed in closed form .",
    "specifically , if @xmath110 for some complex square matrix @xmath111 , then @xmath112 where the square matrix @xmath113 is given by @xmath114 and @xmath115 with @xmath116 note that , in ( [ eqn : thetaf ] ) and ( [ eqn : thetab ] ) , @xmath117 denotes the @xmath118-th component of the vector @xmath119 .",
    "the proof of ( [ eqn : intf ] ) and ( [ eqn : intb ] ) is given in appendix  [ appsec : proofintf ] .",
    "the remaining entry ( [ tabeqn : mu ] ) in table  [ tab : messagepassingrules ] is theorem  [ theorem : inputestimation ] of the next section .",
    "we now turn to estimating the input signal @xmath0 and to clarifying its meaning . to this end , we need the factor graph representation of @xmath109 that is shown in fig .  [",
    "fig : discretefactorgraph ] , which corresponds to the decomposition of ( [ eqn : integrated ] ) into @xmath120 discrete steps and where @xmath121 .",
    "note that this factor graph is only an approximate representation of @xmath109 , but the representation becomes exact in the limit @xmath122 .",
    "the variables @xmath123 in fig .",
    "[ fig : discretefactorgraph ] are related to @xmath0 by @xmath124 i.e. , @xmath123 is the average of @xmath0 over the corresponding interval .",
    "the proof of this decomposition is given in appendix  [ appsec : discretedecomp ] .",
    "( 88,53)(0,0 ) ( 30,36.5)(5,5 ) ( 36,42.5)(0,0)[br]@xmath125 ( 32.5,36.5)(0,-1)10 ( 31.5,31.5)(0,0)[rc]@xmath126 ( 28.5,18.5)(8,8)@xmath127 ( 32.5,18.5)(0,-1)8 ( 68,36.5)(5,5 ) ( 74,42.5)(0,0)[br]@xmath125 ( 70.5,36.5)(0,-1)10 ( 69.5,31.5)(0,0)[rc]@xmath128 ( 66.5,18.5)(8,8)@xmath127 ( 70.5,18.5)(0,-1)8 ( 0,8)(1,0)15 ( 9,9)(0,0)[br]@xmath73 ( 15,4)(8,8)@xmath129 ( 23,8)(1,0)7 ( 30,5.5)(5,5)@xmath68 ( 35,8)(1,0)5 ( 44,8)(0,0)[c]@xmath130 ( 48,8)(1,0)5 ( 53,4)(8,8)@xmath129 ( 61,8)(1,0)7 ( 68,5.5)(5,5)@xmath68 ( 73,8)(1,0)15 ( 79,9)(0,0)[lb]@xmath43 ( 10,0)(68,53 )    for finite @xmath120 , fig .",
    "[ fig : discretefactorgraph ] is a standard linear gaussian factor graph in which snapshots @xmath123 of @xmath0 according to ( [ eqn : discretetimeut ] ) appear explicitly and can therefore be estimated by standard gaussian message passing . in the resulting expression for the estimate of @xmath123",
    ", we can take the limit @xmath131 and thus obtain an estimate of @xmath0 .    [",
    "theorem : inputestimation ] the map / mmse / lmmse estimate of @xmath0 from observations @xmath70 according to the system model of section  [ sec : systemmodel ] is @xmath132 where @xmath133 , @xmath134 , and @xmath135 , @xmath136 are the parameters of the gaussian sum - product messages as discussed in section  [ sec : gaussmesspass ] .",
    "consider the factor graph in fig .",
    "[ fig : proofinputestim ] , which shows the relevant part of fig .",
    "[ fig : discretefactorgraph ] with suitably named variables .",
    "we determine the mean @xmath137 and the variance @xmath138 of the _ a posteriori _ distribution of @xmath123 as follows . from (",
    "* eq .  ( 54 ) and ( iii.5 ) ) , we have    rcl w_(t ) & = & _ ( t ) + _ ( t ) + & = & _ u^-2 + ( ) ^ 2 b^_(t ) b. [ eqn : proofinputmeanwu ]    ( 35,51)(0,-3 ) ( 15,35)(5,5 ) ( 17.5,41)(0,0)[bc]@xmath125 ( 17.5,35)(0,-1)11 ( 16.5,29.5)(0,0)[rc]@xmath123 ( 13.5,16)(8,8)@xmath127 ( 17.5,16)(0,-1)11 ( 16.5,10.5)(0,0)[rc]@xmath139 ( 0,2.5)(1,0)15 ( 7,1)(0,0)[ct]@xmath140 ( 15,0)(5,5)@xmath68 ( 20,2.5)(1,0)15 ( 28,1)(0,0)[ct]@xmath75    from ( * ? ? ?",
    "* eq .  ( 55 ) ) , we then have @xmath141 inserting @xmath142 and using ( * ? ? ?",
    "* eq .  ( iii.6 ) ) yields @xmath143 using ( [ eqn : proofinputmeanwu ] ) and ( [ eqn : proofinputmeanwumu ] ) , we obtain    rcl m_(t ) & = & ( w_(t))^-1 ( w_(t ) m_(t ) ) + & = & ( _ u^-2 + b^_(t ) b ) ^-1 b^_(t ) _",
    "(t ) + & & _",
    "u^2 b^_(t ) _",
    "(t ) [ eqn : proofinputmeanmu1 ]    and the approximation ( [ eqn : proofinputmeanmu1 ] ) becomes exact in the limit .    using ( * ? ? ?",
    "* eq .  ( ii.10 ) ) , we have    rcl _",
    "(t ) & = & _ x(t ) - _ x(t ) + & & _",
    "x(t ) - _ x(t ) , [ eqn : proofinputmu2 ]    and using ( * ? ? ? * eq .  ( ii.8 ) ) , we have    rcl _",
    "(t ) & = & ( _ (t ) ) ^-1 + & = & ( _ x(t ) + _ x(t ) ) ^-1 + & & ( _ x(t ) + _ x(t ) ) ^-1 .",
    "[ eqn : proofinputwu2 ]    again , the approximations ( [ eqn : proofinputmu2 ] ) and ( [ eqn : proofinputwu2 ] ) both become exact in the limit . inserting ( [ eqn : proofinputmu2 ] ) and ( [ eqn : proofinputwu2 ] ) into ( [ eqn : proofinputmeanmu1 ] )",
    "yields @xmath144 the mean of the _ a posteriori _ probability of @xmath123 is thus well defined even for and given by ( [ eqn : proofinputmean ] ) , and the theorem follows .",
    "while we have thus established that the mean ( [ eqn : proofinputmean ] ) of the _ a  posteriori _ distribution of @xmath123 is well - defined for @xmath122 , it should be pointed out that the variance of this distribution is infinite : taking the limit @xmath131 of ( [ eqn : proofinputmeanwu ] ) yields @xmath145 .",
    "however , this seemingly problematic result does not imply that the estimate ( [ eqn : inputestimationtheorem ] ) is useless ; it simply reflects the obvious fact that white noise can not be fully estimated from discrete noisy samples .",
    "the nature of the estimate ( [ eqn : inputestimationtheorem ] ) is elucidated by the following theorem , which reformulates the estimation problem of this paper as an equivalent regularized least - squares problem . for the sake of clarity , we here restrict ourselves to scalar observations",
    "@xmath3 where @xmath146 , @xmath147 is a row vector , and @xmath148 is a scalar .",
    "( the general case is given in @xcite . )",
    "[ theorem : globalcost ] assume that the factor graph in fig .",
    "[ fig : systemmodelfactorgraph ] consists of @xmath149 sections between @xmath44 and @xmath58 ( with observations starting at @xmath45 ) and assume that the observations @xmath3 are scalars .",
    "then the estimated pair @xmath150 with @xmath151 as in ( [ eqn : inputestimationtheorem ] ) minimizes @xmath152 subject to the constraints of the system model .",
    "recall the factor graph representation of a least squares problem as in fig .",
    "[ fig : proofglobalcost ] , where the large box on top expresses the given constraints . clearly , maximizing the function represented by fig .",
    "[ fig : proofglobalcost ] amounts to computing @xmath153 subject to the constraints .",
    "the right - hand side of ( [ eqn : costfunctiongeneral ] ) will be called `` cost function . ''",
    "recall that sum - product message passing in cycle - free linear gaussian factor graphs maximizes the left - hand side of ( [ eqn : costfunctiongeneral ] ) ( subject to the constraints ) and thus minimizes the cost function @xcite .",
    "( 60,30)(0,0 ) ( 0,15)(60,15)constraints ( 7.5,5)(0,1)10 ( 6.5,10)(0,0)[cr]@xmath154 ( 5,0)(5,5 ) ( 3.5,2.5)(0,0)[cr]@xmath155 ( 22.5,5)(0,1)10 ( 21.5,10)(0,0)[cr]@xmath156 ( 20,0)(5,5 ) ( 37.5,4)(0,0)[c ]  ( 52.5,5)(0,1)10 ( 51.5,10)(0,0)[cr]@xmath157 ( 50,0)(5,5 ) ( 56.5,2.5)(0,0)[cl]@xmath158    now plugging fig .  [",
    "fig : discretefactorgraph ] into the factor graph in fig .",
    "[ fig : systemmodelfactorgraph ] results in a factor graph as in fig .",
    "[ fig : proofglobalcost ] with cost function    rcl + & = & _ k=1^k ( z_k^2/_z^2 + _ t_k-1^t_k u(t)^2 dt ) ,    which is  ( [ eqn : globalcost ] ) .    according to theorem  [ theorem : globalcost ] , minimizing ( [ eqn : globalcost ] ) is mathematically equivalent to the statistical estimation problems of this paper ; in particular , modeling @xmath0 as white gaussian noise amounts to regularizing the second term in ( [ eqn : globalcost ] ) by penalizing power in @xmath151 .",
    "the functional ( [ eqn : globalcost ] ) is amenable to an informal frequency - domain analysis that considers the relative power in the different frequences of the input signal @xmath151 . in particular , the estimate @xmath151 fits the corresponding output signal @xmath159 to the observations @xmath160 preferably by those frequencies that appear with little damping in the output signal .",
    "since the transfer function from @xmath0 to @xmath161 of the system ( [ eqn : contsystdiffeq ] ) is necessarily a ( non - ideal ) low - pass filter , the estimate @xmath151 will contain little energy in very high frequencies . in this way",
    ", the spectrum of @xmath151 is shaped by the transfer function of the linear system .",
    "we also note that the problem of minimizing ( [ eqn : globalcost ] ) may be viewed as an offline control problem where an input signal @xmath162 is to be determined such that the resulting sampled output signal @xmath163 follows a desired trajectory @xmath164 .",
    "however , exploring this connection to control theory is beyond the scope of this paper .",
    "we illustrate the estimators of this paper by some simple numerical examples . in all these examples ,",
    "the output signal @xmath1 is scalar , we use regular sampling at rate @xmath165 , i.e. , @xmath166 , and the linear system in fig .",
    "[ fig : systemmodel ] is a butterworth lowpass filter of order 4 or  6 with cut - off frequency ( frequency ) @xmath167 @xcite .",
    "the amplitude response ( i.e. , the magnitude of the frequency response ) of these filters is plotted in fig .",
    "[ fig : exampleamplituderesponse ] .    in these examples",
    ", we use the signal - to - noise ratio ( snr ) as discussed in appendix  [ appsec : snr ] . using ( [ eqn : ey2diag ] ) , the snr of the discrete - time observations turns out to be @xmath168 for the 4th - order filter and @xmath169 for the 6th - order filter . we will measure the snr in db ( i.e. , @xmath170 ) . in some of these plots",
    ", the estimator deliberately assumes an incorrect snr , i.e. , an incorrect ratio @xmath171 , in order to illustrate the effect of this ratio on ( [ eqn : globalcost ] ) .",
    "frequency response ( magnitude ) of the filters used in section  [ sec : numericalexamples ] . ]    estimation of output signal @xmath1 from noisy samples @xmath160 ( fat dots ) at snr = 10  db .",
    "solid line : estimate of @xmath1 at correct snr . dashed line : estimation with assumed snr 100  db ; dotted line : estimation with assumed snr -10  db .",
    "]    estimation of the output signal @xmath1 is illustrated in fig .",
    "[ fig : plotoutest ] . in this example , the linear system is a butterworth filter of order  6 .",
    "the noisy samples @xmath160 are created with @xmath172 at an snr of 10  db .",
    "the corresponding estimate of @xmath1 is shown as solid line in fig .",
    "[ fig : plotoutest ] .    also shown in fig .",
    "[ fig : plotoutest ] is the effect of estimating with an incorrect snr , i.e. , of playing with the ratio @xmath171 as mentioned above . estimating with an assumed snr that is too high results in overfitting ; estimating with an assumed snr that is too low reduces the amplitude of the estimated signal .",
    "[ fig : oversampling ] shows the effect of @xmath173 on the normalized estimation error @xmath174}}{{\\mathrm{e}\\!\\left[{y_k^2}\\right]}}\\ ] ] for a butterworth filter of order  4 . for high snr , we clearly see a critical `` nyquist region '' where severe undersampling sets in . for large @xmath173 ,",
    "the estimate improves by about 2.62  db with every factor of 2 in @xmath173 , which is less than what would be expected ( viz .",
    ", 3  db ) for strictly bandlimited signals @xcite .    empirical estimation error ( [ eqn : normesterror ] ) vs.  normalized sampling frequency @xmath173 , parameterized by the snr ( [ eqn : snr ] ) , for a butterworth filter of order  4 . ]    estimation of the input signal @xmath0 is illustrated in fig .",
    "[ fig : plotinpest ] , for exactly the same setting ( with the same discrete - time observations @xmath160 ) as in fig .",
    "[ fig : plotoutest ] . the power and the spectral content for the three different plots in fig .",
    "[ fig : plotinpest ] illustrate the effect of the ratio @xmath171 on ( [ eqn : globalcost ] ) .",
    "input signal estimation for the same cases ( and the same time scale ) as in fig .",
    "[ fig : plotoutest ] .",
    "the solid line ( top ) is the correct mmse / lmmse estimate of @xmath0.,title=\"fig : \" ] +   input signal estimation for the same cases ( and the same time scale ) as in fig .",
    "[ fig : plotoutest ] .",
    "the solid line ( top ) is the correct mmse / lmmse estimate of @xmath0.,title=\"fig : \" ] +   input signal estimation for the same cases ( and the same time scale ) as in fig .",
    "[ fig : plotoutest ] .",
    "the solid line ( top ) is the correct mmse / lmmse estimate of @xmath0.,title=\"fig : \" ]",
    "we briefly mention a number of extensions and modifications of the system model that are required in some of the motivating applications and are easily incorporated in the estimation algorithms .",
    "the estimate ( [ eqn : inputestimationtheorem ] ) of the input signal @xmath0 is marked by an implicit spectral shaping ( cf .",
    "the discussion after theorem  [ theorem : globalcost ] ) .",
    "it may sometimes be desirable , however , to control the spectrum of the estimate more explicitly .",
    "this can be achieved by assuming that the input signal @xmath0 is not white gaussian noise , but white gaussian noise passed through a suitable ( finite - dimensional ) linear prefilter .",
    "the estimation of @xmath0 is easily adapted to this case by including the prefilter in the system model .",
    "in contrast to unfiltered - input estimation as in section  [ sec : inputestimation ] , estimation of a filtered input signal by means of kalman filtering / smoothing is standard .      in some applications , the dynamics of the system / filter in fig .",
    "[ fig : systemmodel ] may change at discrete instants in time ( but it is always known ) .",
    "this situation occurs , e.g. , when the analog system / filter is subject to digital control .",
    "an example of such a case is given in @xcite .",
    "we thus generalize the system model ( [ eqn : contsystdiff ] ) and ( [ eqn : yk ] ) to @xmath175 and @xmath176 which holds for @xmath177 , where @xmath178 and @xmath179 are known matrices , and where @xmath180 and @xmath181 are known column vectors .",
    "if @xmath182 , both the factor graph representations and the message computation rules remain unchanged except for the addition of subscripts to the involved matrices and vectors . the case @xmath183 is included below .",
    "we are also interested in the case where the system / filter in fig .",
    "[ fig : systemmodel ] has internal noise sources .",
    "( again , a main motivation are analog - to - digital converters , where the noise in the analog part can not be neglected . )",
    "such internal noise can be handled mathematically by extending the input signal @xmath0 to a vector @xmath184 , where the first component , @xmath185 , is the actual input signal while the remaining components model the internal noise . for @xmath35 ,",
    "the integral @xmath186 is a zero - mean gaussian random vector with diagonal covariance matrix @xmath187 .",
    "the corresponding generalization of ( [ eqn : contsystdiff ] ) is @xmath188 where @xmath189 is a matrix of suitable dimensions and where we have included a constant offset @xmath190 ( a column vector ) as in ( [ eqn : timevarsystem ] ) .",
    "note that power differences and correlations among the input signals can be expressed by a suitable matrix @xmath189 .",
    "the corresponding generalization of table  [ tab : messagepassingrules ] is shown in table  [ tab : genmessagerules ] .",
    "the proofs are straightforward modifications of the proofs of table  [ tab : messagepassingrules ] and are omitted .",
    "if the matrix @xmath11 is diagonalizable as in ( [ eqn : diaga ] ) , then the integrals in ( [ tabeqngen : msgfv ] ) and ( [ tabeqngen : msgbv ] ) can be written as stated in the table where the square matrices @xmath113 and @xmath191 are given by @xmath192 and by @xmath193 respectively , and where @xmath194 is the entry in row @xmath118 and column @xmath195 of the matrix @xmath196      mild nonlinearities in the system / filter in fig .",
    "[ fig : systemmodel ] can often be handled by extended kalman filtering @xcite , i.e. , by iterative estimation using a linearized model based on a tentative estimate of the state trajectory @xmath75 .",
    "we have pointed out that exact models of continuous - time linear systems driven by white gaussian noise can be used in discrete - time factor graphs .",
    "the associated continuous - time signals then become computational objects that can be handled with arbitrary temporal resolution by discrete - time gaussian message passing .",
    "motivated by applications such as dynamical sensors and analog - to - digital converters , we have been particularly interested in estimating the input signal , which does not seem to have been addressed in the prior kalman filtering literature .",
    "let @xmath197 from ( [ eqn : diaga ] ) , we have @xmath198 and @xmath199 and thus @xmath200 with @xmath201 the element in row @xmath118 and column @xmath195 of the matrix under the integral is @xmath202 where @xmath194 refers to the elements of the matrix @xmath203 , and elementwise integration yields @xmath204 which proves ( [ eqn : intf ] ) . the proof of ( [ eqn : intb ] ) follows from noting that changing @xmath205 into @xmath206 amounts to a sign change of @xmath207 .",
    "( 88,67)(0,-14 ) ( 14.5,36.5)(5,5 ) ( 13.5,42.5)(0,0)[bl]@xmath208 ( 17,36.5)(0,-1)10 ( 18,31.5)(0,0)[lc]@xmath126 ( 13,18.5)(8,8)@xmath127 ( 17,18.5)(0,-1)10.5 ( 17,8)(1,0)4 ( 35,36.5)(5,5 ) ( 37.5,36.5)(0,-1)10 ( 33.5,18.5)(8,8)@xmath127 ( 37.5,18.5)(0,-1)8 ( 68,36.5)(5,5 ) ( 74,42.5)(0,0)[br]@xmath208 ( 70.5,36.5)(0,-1)10 ( 69.5,31.5)(0,0)[rc]@xmath128 ( 66.5,18.5)(8,8)@xmath127 ( 70.5,18.5)(0,-1)8 ( 21,4)(8,8)@xmath129 ( 29,8)(1,0)6 ( 35,5.5)(5,5)@xmath68 ( 40,8)(1,0)2 ( 45.5,8)(0,0)[c]@xmath130 ( 49,8)(1,0)5 ( 54,4)(8,8)@xmath129 ( 62,8)(1,0)6 ( 68,5.5)(5,5)@xmath68 ( 70.5,5.5)(0,-1)9 ( 0,-6)(1,0)40 ( 9,-5)(0,0)[br]@xmath73 ( 40,-10)(8,8)@xmath74 ( 48,-6)(1,0)20 ( 68,-8.5)(5,5)@xmath68 ( 73,-6)(1,0)15 ( 79,-5)(0,0)[lb]@xmath43 ( 10,-14)(68,67 )    ( 88,16)(0,0 ) ( 0,8)(1,0)15 ( 15,4)(8,8)@xmath129 ( 23,8)(1,0)10 ( 33,4)(8,8)@xmath129 ( 41,8)(1,0)7 ( 52.5,8)(0,0 ) ",
    "( 57,8)(1,0)8 ( 65,4)(8,8)@xmath129 ( 73,8)(1,0)15    ( 10,0)(68,16 )    we split the integral ( [ eqn : integrated ] ) into @xmath120 parts , each of width @xmath209 with @xmath210 :    rcl x(t_1 ) & = & e^at x(t_0 ) + & & + _ k=1^n _ ( k-1)t / n^kt / n e^a(t- ) bu(t_0 + ) d + & & e^at x(t_0 ) + & & + _ k=1^n e^a(t - kt / n ) b _",
    "( k-1)t / n^kt / n u(t_0 + ) d [ eqn : intapprox ] + & = & e^at x(t_0 ) + & & + _",
    "k=1^n e^a(t - kt / n ) b ( t_0+kt / n ) , [ eqn : discretefactorgraphproved ]    where the approximation ( [ eqn : intapprox ] ) becomes exact in the limit and where @xmath123 is defined as in ( [ eqn : discretetimeut ] ) . the factor graph of ( [ eqn : discretefactorgraphproved ] ) is shown in fig .",
    "[ fig : discretefactorgraphproof ] .",
    "the term @xmath74 can also be decomposed into @xmath120 discrete steps as shown in fig .",
    "[ fig : decompexpat ] . plugging fig .",
    "[ fig : decompexpat ] into fig .",
    "[ fig : discretefactorgraphproof ] yields a factor graph that is easily seen to be equivalent to fig .",
    "[ fig : discretefactorgraph ] .",
    "for the system model of section  [ sec : systemmodel ] , we may wish to relate the input noise power @xmath51 to the signal - to - noise ratio ( snr ) of the discrete - time observations .",
    "for the sake of clarity , we restrict ourselves to scalar observations @xmath3 , i.e. , @xmath211 , @xmath147 is a row vector , and @xmath148 is a scalar .",
    "in addition , we assume that the continuous - time linear system is time - invariant and stable and any initial conditions can be neglected . in this case , we define @xmath212}}{\\sigma_z^2}\\ ] ] which ( under the stated assumptions ) is independent of @xmath118",
    ". we then have @xmath213 } = c { \\protect\\overrightarrow{v}_{\\!\\!x(\\infty ) } } c^{\\mathsf{t}}\\ ] ] with @xmath214 from ( [ tabeqn : msgfvx ] ) ; if , in addition , the system is diagonalizable as in ( [ eqn : diaga ] ) , then @xmath215 } = \\sigma_u^2   cq { \\protect\\overrightarrow{\\theta}_{\\!}}(\\infty ) q^{\\mathsf{h}}c^{\\mathsf{t}}\\ ] ] where @xmath216 is a square matrix with entries @xmath217      l.  bolliger , h .- a .",
    "loeliger , and c.  vogel , `` simulation , mmse estimation , and interpolation of sampled continuous - time signals using factor graphs , '' 2010 information theory & applications workshop , ucsd , la jolla , ca , usa , jan .  31  feb .  5 , 2010 .",
    "loeliger , j.  dauwels , junli  hu , s.  korl , li  ping , and f.  r.  kschischang , `` the factor graph approach to model - based signal processing , '' _ proceedings of the ieee , _ vol .",
    "95 , no .  6 , pp .",
    "12951322 , june 2007 .",
    "loeliger , l.  bolliger , g.  wilckens , and j.  biveroni , `` analog - to - digital conversion using unstable filters , '' _ 2011 information theory & applications workshop , _ ucsd , la jolla , ca , usa , feb .  611 , 2011 .",
    "n.  t.  thao and m.  vetterli , `` lower bound on the mean - squared error in oversampled quantization of periodic signals using vector quantization analysis , '' _ ieee trans .",
    "theory , _ vol .",
    "42 , no .  2 , pp .",
    "469479 , march 1996 ."
  ],
  "abstract_text": [
    "<S> the factor graph approach to discrete - time linear gaussian state space models is well developed . </S>",
    "<S> the paper extends this approach to continuous - time linear systems / filters that are driven by white gaussian noise . by gaussian message passing , </S>",
    "<S> we then obtain map / mmse / lmmse estimates of the input signal , or of the state , or of the output signal from noisy observations of the output signal . </S>",
    "<S> these estimates may be obtained with arbitrary temporal resolution . </S>",
    "<S> the proposed input signal estimation does not seem to have appeared in the prior kalman filtering literature . </S>"
  ]
}