{
  "article_text": [
    "the last few decades have witnessed an explosion of high - dimensional data in applied fields including biology , engineering , finance and many other areas . given a dataset consisting of @xmath0 where @xmath1 is the response and @xmath2 is the covariate for the @xmath3th observation , the main interest is often to conduct a regression analysis between @xmath4 and @xmath5 , the simplest model for which takes the linear form .    an important assumption in linear regression is usually that the observations are all generated from the same model . in many applications , however , the data collected often contain contaminated or noisy observations due to a plethora of reasons . those observations exerting great influence on statistical analysis , thus named influential points ,",
    "can seriously distort all aspects of data analysis such as alter the estimation of the regression coefficient and sway the outcome of statistical inference @xcite .",
    "thus , when influential points are present , fitting the model based on a clean data assumption leads to at best a very crude approximation to the model and at worst a completely wrong solution . for fixed dimensional models ,",
    "we refer the reader to @xcite , among many others . for high - dimensional models",
    ", @xcite found that influential observations could negatively impact many attractive methods recently developed for dealing with high - dimensionality , such as lasso for variable selection ( tibshirani , 1996 ) and sis for variable screening ( fan and lv , 2008 ) .",
    "as a result , influence diagnosis has been long recognized as a central problem and routinely recommended in statistical analysis .",
    "an entire line of research has been devoted to devising robust methods that are less prone to influential observations ; see , for example , two excellent books on robust regression by @xcite and @xcite when @xmath6 is fixed .",
    "when @xmath7 , @xcite and @xcite investigated m - estimation and proposed algorithms to find the optimal loss function . @xcite and @xcite , among others , devised robust methods for variable selection when heavy tailed noises are present .",
    "these papers made no attempt to quantify the influence of individual points , which can often be the main question of interest in practice .",
    "as highlighted by @xcite , it is worth investigating factors causing influentialness to determine the best course of action , as influential points often are the best indicators of the stability of a model . for multivariate data containing only @xmath8 s , @xcite proposed to find outliers in a high - dimensional space via projection , while @xcite used a robust covariance matrix estimator for defining distance for detecting outliers .",
    "@xcite is among the first to study outlier detection in regression by using nonconvex penalized likelihood .",
    "their method was mainly developed for @xmath9 problems and a theory on how successful their approach is in terms of identifying influential observations is lacking .",
    "it is also found that empirically she and owen s method is outperformed by the new approach studied in this paper ( section 4 ) .",
    "when @xmath6 is fixed , there are many measures proposed for quantifying the influence of each observation , noticeably , cook s distance @xcite , studentized residuals @xcite , dffits @xcite , and welsch s distance @xcite .",
    "these measures have now been implemented in most statistical software such as r and sas .",
    "since these measures are all based on the ordinary least squares ( ols ) estimation , they are not applicable to high - dimensional data due to lack of degrees of freedom . on the other hand ,",
    "the problem of influence diagnosis in a high - dimensional setting has received little attention despite its obvious importance .",
    "this is mainly due to the difficulty of establishing a coherent theoretical framework and the lack of easily implementable procedures .",
    "@xcite appears to be the the first work under this setting . in particular",
    ", they proposed a new high - dimensional influence measure ( him ) based on marginal correlations and established its asymptotic properties .",
    "the asymptotic theory further permits the development of a multiple testing based procedure for detecting influential points .",
    "similar to many fixed dimensional measures , him is based on the idea of leave - one - out .",
    "that is , to quantify the influence of an observation , one compares a predefined measure evaluated on the whole dataset and the measure evaluated on a subset of the data leaving out the observation under investigation . because of this , him is effective in detecting the presence of a single influential point . in practice , however , multiple influential observations are more commonly encountered and it is not appropriate to apply a test for a single influential point sequentially in order to detect multiple ones . on the other hand ,",
    "detecting multiple influential observations is much more challenging , due to the notorious  masking \" and  swamping \" effects @xcite .",
    "specifically , masking occurs when an influential point is undetected as such , while swamping occurs when a non - influential point is classified as an influential one .",
    "masking is one reason that trying to apply a single influential point test sequentially can fail .",
    "for example , if there are multiple influential points , masking may cause the influence test for the first influential point to return a conclusion of no influential points , causing testing for any additional influential points not performed . to handle the masking and swamping effects in fixed dimensional models , many group deletion methods have been proposed ( rousseeuw and zomeren , 1990 ; hadi and simonoff , 1993 ; imon , 2005 ; pan et al .",
    ", 2000 ; nurunnabi et al . , 2014 , roberts et al . ,",
    "dealing with masking and swamping effects for high - dimensional data , however , is much more challenging and is currently an open problem .",
    "the main aim of this paper is to propose a new procedure for detecting multiple influential points for high - dimensional data that is theoretically sound and operationally simple . to substantially extend the scope of the new method",
    ", we study the problem in the context of a multiple response linear model where @xmath10 .",
    "this encompasses the univariate response linear model in @xcite as a special case .",
    "the high - dimensional linear model with multiple responses has been extensively studied for statistical learning and dimension reduction @xcite , but not for influence diagnosis . in extending him to the multiple response context ,",
    "our first contribution is to define a new influence measure by explicitly taking into account the covariance structure of @xmath4 and derive its theoretical properties .",
    "based on this new influence measure and the idea of random group deletion , we propose a novel procedure named mip , short for ultiple nfluential oint detection for high - dimensional data . along the process , we propose two novel quantities named max and min statistics to assess the extremeness of each point when data are subsampled .",
    "our theoretical studies show that these two statistics have complementary properties .",
    "the min statistic is useful for overcoming the swamping effect but less effective for masked influential observations , while the max statistic is well suited for detecting masked influential observations but is less effective in handling the swamping effect . combining their advantages , we propose a computationally efficient yet simple min - max algorithm for obtaining a clean subset of the data that contains no influential points .",
    "this clean set of data is then served as the benchmark for assessing the influence of other observations , which in turn permits the use of false discovery rate approaches such as the benjamini - hochberg method @xcite for assessing influence .",
    "remarkably , the theoretical properties of max and min statistics can be studied and are rigorously established in this paper .",
    "we point out that establishing the theoretical results for the two extreme statistics is very challenging and that similar results even for fixed dimensional problems do not exist .",
    "this can be seen as our second contribution . to the best of our knowledge , mip is the first influence diagnosis procedure that is theoretically justified for multiple influential point dection in a high - dimensional setting .",
    "before we proceed , we highlight the usefulness of the max and min statistics via an analysis of the microarry data in section 4.3 .",
    "figure [ fig1 ] plots the logarithms of the @xmath6-values associated with the max statistic in ( a ) and the min statistic in ( b ) versus the observation indices , respectively . with a prespecified false discovery rate at @xmath11 , using the min statistic , we identify a set of @xmath12 influential observations , represented as the blue points in plot ( a ) and ( b ) .",
    "it is interesting that the mip procedure combining the strengths of the two statistics identifies the same set of @xmath12 influential points . on the other hand ,",
    "using the max statistic , @xmath13 additional observations , represented as red triangles in plot ( a ) , are declared influential .",
    "these findings are consistent with our theory that the max statistic tends to identify more influential observations , making it more suitable for overcoming the masking effect , but may suffer from the swamping effect . on the other hand",
    ", the fact that the min statistic gives the same set of influential points as mip in plot ( b ) implies that there may not exist any masking effect in this data .",
    "further analysis in section 4.3 shows that the reduced data , obtained by removing the influential observations identified by mip , results in a sparser model with a better fit , when lasso is applied for model fitting .",
    "in addition , the estimated coefficient based on the reduced data is almost orthogonal to that of full data .",
    "therefore , being able to detect influential observations may be helpful for achieving better variable selection and more accurate coefficient estimation .",
    ".45 -values by using the min statistic .",
    ", title=\"fig : \" ]    .45 -values by using the min statistic .",
    ", title=\"fig : \" ]    the main flow of this paper is organized as follows . in section 2",
    ", we review the high - dimensional influence measure in @xcite , extend it to the multiple response linear model accounting for the covariance of the responses , and establish the asymptotic behaviour of this new influence measure .",
    "in particular , we show in theorem 1 that , when there is no influential point , the proposed influence measure for each observation converges to a @xmath14 distribution where @xmath15 , the number of responses , is the degrees of freedom .    in section 3 , based on the idea of random group deletion or",
    "leave - many - out , we propose max and min statistics for assessing extremeness and establish their theoretical properties .",
    "the max and min statistics for a given point are the maximum and the minimum quantity , respectively , of the influence measures defined over randomly subsampled data .",
    "we show in theorem 2 that , surprisingly , when there is no influential point , these two statistics both follow a @xmath14 distribution . when there are influential points , theorem 3 and theorem 4 show that for a non - influential point , its max and min statistics still follow a @xmath14 distribution .",
    "furthermore with the presence of influential points , theorem 3 and 4 demonstrate that , under suitable conditions , the max and min statistics can identify the influential points with large probability .",
    "we then argue that these two statistics are complementary in detecting influential observations and the min - max algorithm can suitably combine their strengths .",
    "simulation results and data analysis , showing the competitive performance of mip in comparison to him and the method of @xcite , are presented in section 4 . in section 5 ,",
    "we provide further discussions , including the use of alternative quantities for defining influence , parallel computing for alleviating computational demand , and generalization of mip beyond linear models .",
    "finally , all the proofs are relegated to the appendix .",
    "here are the notations used throughout the paper . for any set @xmath16 , we write @xmath17 as its cardinality .",
    "let @xmath18 and @xmath19 be the set of the influential and non - influential observations , respectively .",
    "denote by @xmath20 the @xmath21 norm of a vector @xmath22 . for any matrix @xmath23 , @xmath24 and @xmath25 denote its frobenius norm and spectral norm , respectively .",
    "finally , let @xmath26 and we use @xmath27 to denote a generic constant that may change depending on the context .",
    "to motivate the development of a new influence measure for multiple response regression , we first give a short review of the high - dimensional influence measure ( him ) in @xcite for problems with @xmath28 . towards this end , consider the following linear model with a scalar response [ eq : model ] y_i= _ i^+_i , where the pair @xmath29 , @xmath30 , denotes the observation of the @xmath3th subject , @xmath31 is the response variable , @xmath32 is the associated @xmath6-dimensional predictor vector with zero mean , @xmath33 is the coefficient vector , and @xmath34 is a mean zero normally distributed random noise .    the idea of him is to define the influence of a point by measuring its contribution to the average marginal correlation between the response and the predictors .",
    "specifically , define the marginal correlation between variable @xmath35 and the response as @xmath36 .",
    "given the data , we can obtain its sample estimate as @xmath37 , for @xmath38 , where @xmath39 and @xmath40 are the sample estimates of @xmath41 and @xmath42 , respectively . the sample marginal correlation with the @xmath43th observation removed",
    "is similarly defined as @xmath44 for @xmath45 .",
    "him then measures the influence of the @xmath43th observation by comparing the sample correlations with and without this observation , defined as @xmath46 intuitively , the larger @xmath47 is , the more influential the corresponding observation is . when there is no influential point and @xmath48 , under mild conditions , it is proved that @xmath49 where @xmath50 is the chi - square distribution with one degrees of freedom .",
    "based on this result , we can formulate the problem of influential point detection as a multiple hypothesis testing problem where one tests @xmath51 hypotheses , one for each observation stating that the observation under invstigation is non - influential .",
    "subsequently , the benjamini - hochberg procedure @xcite for multiple testing can be used to control the false discovery rate .",
    "since him is based on the leave - one - out idea , the derived @xmath50 distribution is invalid whenever there are one or more influential points .",
    "that is , the presence of one single influential point can distort the null distribution of him for a non - influential point according to the definition above . similarly , the presence of more than one influential point can distort him of an influential point as well .",
    "this is the manifestation of a more general difficulty of multiple influential point detection where the masking and swamping effects greatly hinder the usefulness of any leave - one - out procedures . in the language of multiple testing",
    ", masking is the the problem of getting false negatives and swamping is the problem of getting false positives . to appreciate how masking and swamping effects negatively impact the performance of him , we quickly look at example 1 and 2 in section 4 .",
    "the data are generated such that there exists a strong masking effect for example 1 and a strong swamping effect for example 2 .",
    "the magnitude of these effects depends on a parameter denoted as @xmath52 .",
    "figure [ fig2 ] presents a comparison of him in @xcite and the proposed mip method proposed in this paper for detecting influence , when the nominal level used for declaring influential in the benjamini - hochberg procedure is set at @xmath53 .    from plot ( a ) of figure [ fig2 ]",
    ", we see that the true positive rates ( tprs ) of him are much lower than those of mip ; that is , him identifies much fewer influential points as influential and thus suffers severely from the masking effect .",
    "meanwhile , the false positive rates ( fprs ) of him are also much larger than the nominal level @xmath53 especially when @xmath52 becomes large ; that is , him identifies much more non - influential points as influential , meaning that him also suffers from the swamping effect . from plot ( b ) , we see that him suffers from the swamping effect greatly , as the fprs can be very close to 1 for large @xmath52 . on the other hand , for both examples",
    ", the fprs of the mip procedure are controlled well below the nominal level while its tprs are monotone functions of @xmath52 and eventually become one for large @xmath52 .",
    ".5     .5       we are now ready to extend him to deal with multiple response models .",
    "assume that the non - influential observations are @xmath54 from the following model @xmath55 where @xmath56 , @xmath57 , @xmath58 @xmath59 with @xmath60 . in this paper , we consider the situation when @xmath15 is fixed and @xmath6 diverges with @xmath51 such that both @xmath6 and @xmath51 diverge to infinity .",
    "denote @xmath61 , @xmath62 .",
    "without loss of generality , we assume that @xmath63 and @xmath64 ; otherwise , we can always center the data . write @xmath65 .    to detect the influential observations in a high - dimensional linear model with multiple responses , we need to define a proper measure .",
    "similar to him , to circumvent the unstableness of the ols estimator , we use the marginal correlations between @xmath66 with @xmath67 for all the covariates .",
    "different to him , however , by noting that @xmath68 is multivariate with a covariance matrix @xmath69 , the correlation among @xmath70 s must be taken into account .",
    "we introduce the notations used first .",
    "let @xmath71 be the standardized version of @xmath67 , @xmath72 .",
    "define the marginal correlation between the @xmath35th covariate and the response vector as @xmath73 with @xmath74 and write @xmath75 as the cross correlation between the responses and the predictors .",
    "denote by @xmath76 , @xmath77 , @xmath78 the estimate of @xmath79 , respectively .",
    "when @xmath80 and @xmath81 are unknown , a simple choice is to replace them by their corresponding sample moment estimates .",
    "another natural choice is to employ robust estimators , for example , the median , the median absolute deviation ( mad ) and robust covariance matrix estimate . regardless of what estimates are used , we denote the estimator of @xmath82 as @xmath83 , for @xmath72 .",
    "we define the estimator @xmath84 , where @xmath85 with @xmath86 .",
    "then we define another estimator by deleting the @xmath43-th observations as @xmath87 with @xmath88 where for @xmath89 _ js^(k ) = , and @xmath90 are the estimators of @xmath91 , respectively , obtained without the @xmath43th observation . then similar to him , we define our influence measure for the @xmath43th observation as @xmath92 that is , @xmath93 assesses the average difference between the two correlation matrices that are between the covariates and the responses , one defined on a complete dataset and the other a dataset without the @xmath43th observation .",
    "this is basically the delete - one - out idea .",
    "the statistic @xmath93 reduces to @xmath47 in section 2.1 if @xmath94 .",
    "if the @xmath43th observations is not influential , the value of @xmath93 will be small . in order to quantify",
    "how small is small , we need to study its asymptotic behavior .",
    "let @xmath95 , @xmath96 , @xmath97 and @xmath98 .",
    "furthermore , let @xmath99 , @xmath100 . similarly , let @xmath101 and @xmath102 . to study the properties of @xmath93",
    ", we make the following assumptions .    * for @xmath103 , @xmath104 is constant and does not change as @xmath6 increases .",
    "* for the covariance matrix of the covariates @xmath105 with eigen - decomposition @xmath106 , we assume @xmath107 for some @xmath108 . * the predictor @xmath8 follows a multivariate normal distribution and the random noise @xmath109 follows a multivariate normal distribution with mean zero and an unknown variance . * denote @xmath110 as the eigenvalues of @xmath111 .",
    "assume @xmath112 for some constant @xmath113 .",
    "* @xmath114 and @xmath115 are finite .",
    "assumption ( c1 ) is a natural extension of ( c.1 ) in @xcite as @xmath15 is assumed fixed .",
    "assumption ( c2 ) and the assumption on @xmath8 in ( c3 ) are also made in @xcite .",
    "the assumption on @xmath109 in ( c3 ) is an extension of the univariate linear model considered in @xcite .",
    "assumption ( c4 ) on the eigenvalues of @xmath69 is reasonable for a fixed @xmath15 .",
    "assumption ( c5 ) is a natural extension of ( c.4 ) in @xcite , which requires that the estimates of the means and variances are @xmath116 consistency and that certain moments exist .",
    "since @xmath117 are _ i.i.d .",
    "_ normal , it is shown that when @xmath118 and @xmath119 are moment estimates , the assumptions on @xmath120 and @xmath121 hold @xcite .",
    "if @xmath122 is the sample mean and @xmath123 is the sample covariance matrix , by similar arguments and noting ( c4 ) , it can be shown that assumptions on @xmath124 and @xmath125 in ( c5 ) also hold . in section 3 ,",
    "we strengthen ( c5 ) further as ( c7 ) .",
    "[ th1 ] assume a fixed @xmath15 . under assumptions ( c1)(c5 ) ,",
    "when there is no influential observations , we have @xmath126 as @xmath127 , where @xmath14 is the @xmath128 distribution with @xmath15 degrees of freedom .    as alternatives to the sample estimates , robust estimates of @xmath129 , @xmath130 , and @xmath69",
    "can also be used in practice .",
    "for example , we can estimate @xmath131 and @xmath132 by the sample median and @xmath130 by the median absolute deviation ( mad ) estimator , respectively .",
    "these estimates satisfy assumption ( c5 ) by noting the normality of @xmath133 s . for @xmath69 , write @xmath134 , where @xmath135 is the correlation matrix for response @xmath67 and @xmath136 is a diagonal matrix with @xmath137 .",
    "we use the mad estimator for @xmath138 , denoted as @xmath139 .",
    "the matrix @xmath140 can be estimated by the approach of @xcite as follows .",
    "write @xmath141 where @xmath142 is the pearson correlation between variables @xmath143 and @xmath144 .",
    "following @xcite , we have @xmath145 , where @xmath146 is kendall-@xmath147 correlation between @xmath143 and @xmath144 , when @xmath67 follows an elliptical distribution including the normal distribution as a special case . again by @xcite",
    ", we can estimate @xmath146 as @xmath148 and @xmath149 for @xmath150 .",
    "consequently , the robust estimate of @xmath151 is simply @xmath152 and that of @xmath140 is @xmath153 . combining everything ,",
    "a robust estimate of @xmath69 is @xmath154 .",
    "because @xmath67 is normal and @xmath15 is fixed , it has been shown that for any @xmath155 , @xmath156 decays to zero exponentially fast @xcite . combining this results with the property of the mad estimator @xmath139",
    ", it can be checked that ( c5 ) holds under the normality assumption of @xmath133 s .",
    "these robust estimates are the quantities used in our numerical examples .",
    "as discussed before , any measure based on the leave - one - out approach may be ineffective when there are multiple influential observations due to the  masking \" and  swamping \" effects .",
    "since the number of influential observations is generally unknown in practice , it is natural to employ a notion of leave - many - out or group deletion .",
    "group deletion has also been used for fixed dimensional problems in identifying multiple influential points @xcite , but is not employed in a way similar to how we define our statistics which are theoretically tractable .",
    "recall that @xmath18 and @xmath157 denote the indices of influential and non - influential observations such that @xmath158 .",
    "let @xmath159 be the size of influential point set and @xmath160 be the number of non - influential points .",
    "write @xmath161 as the @xmath43th data point . for any fixed @xmath43 , to check whether @xmath162 is influential or not , we draw at random with replacement some subsets @xmath163",
    "; that is , these subsets do not include @xmath162 .",
    "write @xmath164 where @xmath165 for some @xmath166 .",
    "these subsets are repeatedly drawn in the hope that there exists some subset that contains no influential observations .",
    "if such a clean set can be found , then the statistic associated with any non - influential point as developed in section 2.2 has the @xmath14 distribution as in theorem [ th1 ] .",
    "a conservative choice for @xmath167 is @xmath168 , because the number of non - influential points is usually larger than that of the influential points .",
    "formally , we make the following assumption on @xmath169 and @xmath167 .    * denote @xmath170 which is allowed to vary with @xmath51 .",
    "assume @xmath171 for some @xmath172 independent of @xmath51 .",
    "we take @xmath173 .",
    "assumption ( c6 ) allows @xmath174 . for @xmath175 ,",
    "let @xmath176 be the subset of non - influential observations in @xmath177 and denote its size as @xmath178 . under ( c6 )",
    ", we have @xmath179 , that is , for any subset @xmath177 , the number of non - influential observations does not vanish .",
    "for @xmath175 , let @xmath180 which is of size @xmath181 . for @xmath182 , we compute its generalized influence measure with respect to the @xmath183th random subset @xmath177 as @xmath184 where @xmath185 and @xmath186 denote the estimate of @xmath187 based on observations in @xmath177 and @xmath188 respectively .",
    "we are now ready to define the following two extreme statistics @xmath189 we name them the min and max statistic respectively as they measure the extremeness of the generalized influence measure in terms of the randomness of the subsampling scheme .",
    "to establish the asymptotic behaviours of @xmath190 and @xmath191 , we first study the behaviour of a key quantity @xmath192 in which @xmath193 is defined as @xmath194 where @xmath195 , @xmath196 , and @xmath197 is the estimate of @xmath198 , a diagonal matrix in @xmath199 . by definition",
    ", @xmath193 is the frobenius norm associated with the non - influential observations in @xmath177 only .",
    "denote @xmath200 as the population version of @xmath201 and note that @xmath202 is the population version of @xmath203 .",
    "we make assumptions on @xmath204 , and @xmath205 , which can be seen as strengthened assumptions in ( c5 ) .    *",
    "assume that assumptions on @xmath206 and @xmath207 in ( c5 ) still hold .",
    "furthermore , there exist constants @xmath208 , independent of @xmath209 and @xmath15 , such that for any @xmath155 , @xmath210 @xmath211    in assumption ( c7 ) , @xmath212 is assumed to have sub - gauassian tails and @xmath213 s have sub - exponential tails .",
    "this assumption is satisfied for the sample mean and the sample variance under the normality of @xmath133 s .",
    "the sub - exponential tails assumption is stronger than that in ( c5 ) where only the eighth moments are required .",
    "we now quantify the magnitude of @xmath214 , the maximum effect of the non - influential points , which is a key quantity for establishing the asymptotic properties of the min and max statistics .",
    "[ lemma1 ] assume that the non - influential observations satisfy ( c1)-(c4 ) and that ( c6 ) and ( c7 ) hold .",
    "assume further @xmath215 .",
    "then for any @xmath216 , @xmath217 obviously , @xmath218 if @xmath219 for some sufficiently small @xmath220 . here",
    "the number of the subsamples @xmath221 is allowed to grow to @xmath222 to help us understand the approach as explained in the next section , although in practice we only need @xmath221 to be large .",
    "based on lemma [ lemma1 ] , we have the following conclusion when there is no influential observation .",
    "[ th2 ] suppose that all observations are non - influential . under the assumptions of lemma [ lemma1 ]",
    ", it holds that , for any @xmath45 , @xmath223 and @xmath224    theorem [ th2 ] seems surprising at first glance , since we always have @xmath225 .",
    "an explanation is in place .",
    "it will be shown that @xmath226 can be decomposed into two parts .",
    "the first part , depending on the quantity @xmath227 defined in the next paragraph , represents the effect of the observation @xmath162 , and the second part is controlled by @xmath214 . since @xmath228 by lemma [ lemma1 ] , the asymptotic distributions of @xmath190 and @xmath191 are mainly determined by @xmath227 .",
    "thanks to the blessing of dimensionality , we can show that @xmath227 asymptotically has a @xmath14 distribution . from theorem [ th2 ] ,",
    "when @xmath191 or @xmath190 is larger than @xmath229 , the @xmath230 quantile of the @xmath14 distribution , for some prespecified @xmath231 such as @xmath11 , we can label @xmath162 as an influential observation .",
    "recall that @xmath176 is the set consisting of the indices of the non - influential observations in @xmath177 .",
    "let @xmath232 be its complment in @xmath177 .",
    "for each @xmath175 , it is obvious that @xmath233 , the latter equal to @xmath18 if @xmath234 . since @xmath235 ,",
    "similar to the proof of theorem [ th2 ] , we have [ dec_d_rk ] n_^2_r , k&=&p^-1-^(k)_f^2 + & = & p^-1_tk , ta_r",
    "_ t_t^-_k_k^_f^2 + & = & p^-1_tb_r _ t_t^+_to_r _",
    "t_t^-_k_k^_f^2 + & : = & p^-1w_non , k , r+w_,k , r-_k_k^_f^2 , where @xmath236 and @xmath237 are associated with influential and non - influential observations , respectively .",
    "define @xmath238 which represents the effect of the @xmath43-th observation @xmath162 .",
    "let @xmath239 quantify the maximum and minimum joint effect of the influential observations , respectively .",
    "the asymptotic behavior of @xmath191 and @xmath240 depends on the magnitude of @xmath227 , @xmath241 and @xmath242 when multiple influential observations are present .",
    "see theorem [ th3 ] in section 3.1 and theorem [ th4 ] in section 3.2 .",
    "we state the properties of @xmath191 and @xmath240 separately .      in theorem [ th2 ] , we derive the null distribution of @xmath191 and @xmath190 when there is no influential point .",
    "we now study @xmath191 when there are influential observations and develop the corresponding detection procedure .",
    "recall @xmath244 and @xmath245 in ( c6 ) .",
    "denote @xmath246 , the ratio of @xmath247 over @xmath248 , and let @xmath249 , for any @xmath250 .",
    "simple calculation in the proof of theorem [ th3 ] shows @xmath251 .",
    "we have the following results for @xmath191 . [ th3 ] under the assumptions of lemma [ lemma1 ] , when there are influential observations , the following two conclusions hold .",
    "* suppose further @xmath252 .",
    "if observation @xmath43 is non - influential , that is , @xmath234 , then both @xmath190 and @xmath191 converge to @xmath14 in distribution .",
    "* for an influential point @xmath253 , if @xmath254 holds for some small prespecified @xmath255 where @xmath229 is the @xmath256 quantile of a @xmath257 distribution , then @xmath258 .",
    "in addition , it holds that @xmath259 for some @xmath260 .    under the condition in @xmath261 , for any non - influential observation @xmath162 , the asymptotic distributions of @xmath190 and @xmath191 are the same as those in theorem 2 .",
    "that is , the distributions of the min and max statistics of a non - influential observation are not affected by the presence of influential observations . as such",
    ", a non - influential point can be identified as non - influential with high probability .",
    "that is , the swamping effect can be overcome under the condition in @xmath261 .",
    "since @xmath251 , a sufficient condition for @xmath262 is that @xmath263 , which holds if @xmath264 and @xmath265 .",
    "this condition might be violated , however , if @xmath266 does not vanish or some influential observations have large values in terms of @xmath267 .",
    "this condition implies that deleting points with large values in @xmath267 is helpful to alleviate the swamping effect .    for an influential observation @xmath162 ,",
    "the max - unmask condition in @xmath268 gives the requirement on its signal strength for it to be identified as influential .",
    "as @xmath269 decreases , the condition becomes weaker and easier to be satisfied , and @xmath162 is easier to be detected .",
    "this provides opportunity to identify the influential observations that are masked by others , as long as we can make @xmath269 small enough .",
    "in fact , as argued below , @xmath269 can be very small if @xmath221 is sufficiently large .",
    "now , we discuss the upper bound @xmath269 in @xmath268 of theorem [ th3 ] . recall that @xmath270 denotes the indices of the influential observations in @xmath177 and",
    "note @xmath271 .",
    "then we have @xmath272 .\\ ] ] define @xmath273 . by allowing @xmath274 ,",
    "it is easy to see that @xmath275 is a decreasing function of @xmath221 with @xmath276 , since there are many subsets @xmath177 that contain no influential observations under assumption ( c6 ) , i.e. @xmath277 . therefore , @xmath278 . of course , in practice @xmath274 is not achievable .",
    "assume further @xmath279 .",
    "then @xmath280 , which will be small for large @xmath221 and @xmath51 .",
    "if @xmath281 is unbounded but @xmath282 for some @xmath283 , we have @xmath284 , which converges to 0 , as @xmath285 . generally , when @xmath221 and @xmath51 are large , @xmath269 will be small under some mild conditions .",
    "therefore , @xmath191 has advantages in overcoming the masking effect if @xmath221 is large .",
    "we formally formulate a multiple testing problem to test the influentialness of individual observations with @xmath51 null hypotheses @xmath286 is non - influential , @xmath45 . by @xmath268 of theorem [ th3 ] and the above discussions",
    ", we can estimate the set of the influential observations as @xmath287 where @xmath288 is the @xmath6-value under @xmath289 and @xmath290 s are determined by the specific procedure used to control the error rate . here",
    "s can be independent of @xmath43 , if we aim to control the familywise error rate by the bonferroni test .",
    "alternatively , @xmath290 s can depend on @xmath43 , if we want to control the false discovery rate ( fdr ) at level @xmath291 .",
    "for example , for the procedure in @xcite , @xmath290 can be taken as the largest @xmath292 such that @xmath293 , where @xmath294 are the ordered @xmath295 s .",
    "we now state the theory of using the benjamini - hochberg procedure and will use it later for numerical illustration , although other procedures developed for controlling fdr can also be used .",
    "[ proposition2 ] suppose that the benjamini - hochberg procedure is used to control fdr at level @xmath291 .",
    "if the max - unmasking condition in @xmath268 of theorem [ th3 ] holds with @xmath296 but with @xmath241 replaced by the constant @xmath297 defined there , then under the conditions in lemma [ lemma1 ] , we have @xmath298 .",
    "note that @xmath269 discussed further after theorem [ th3 ] is independent of @xmath43 .",
    "proposition [ proposition2 ] shows that all the influential points will be identified as influential with high probability .",
    "that is , the true positive rate is well controlled .",
    "in addition , if @xmath299 , by @xmath261 in theorem [ th3 ] , there will be no swamping effect and then the statistic @xmath191 under @xmath289 follows @xmath14 distribution .",
    "let @xmath300 be the estimated fpr .",
    "when the benjamini - hochberg procedure is applied and there is no swamping effect , @xmath301 will be controlled .",
    "however , the condition @xmath299 is strong and it may fail if @xmath266 does not converge to zero . in this case , fpr may be out of control .    to summarize , the detection procedure based on the max statistic @xmath191 is effective in overcoming the masking effect , but it is somewhat aggressive in that the fpr may not be controlled well without strong conditions . on the other hand , we point out that the procedure based on @xmath191 is computationally efficient , compared with that based on @xmath190 below .",
    "we have argued that the statistic @xmath190 is effective in alleviating the swamping effect .",
    "we formally state this in the following theorem .",
    "[ th4 ] under the assumptions of lemma [ lemma1 ] , the following two conclusions hold .",
    "* assume @xmath303 .",
    "for any non - influential point @xmath234 , it holds that @xmath223 . * for any influential @xmath162 , if @xmath304 holds , then @xmath305 , where @xmath255 is a small constant .    compared with @xmath261 of theorem [ th3 ] where @xmath252 is required",
    ", the condition in @xmath261 of theorem [ th4 ] is much weaker . as discussed in section 3.1 , @xmath306",
    "when @xmath307 .",
    "therefore , the statistic @xmath190 is less sensitive to the swamping effect . on the other hand , @xmath242 is involved in the min - unmask condition in @xmath268 , which is much stronger than the max - unmask condition in @xmath268 of theorem [ th3 ] .",
    "that is , an influential observation @xmath162 will not be identified as influential unless its signal is very strong .",
    "thus , the min statistic is efficient in preventing the swamping effect but may be conservative for identifying influential points . combining with the result in section 3.2 that the max statistic @xmath191 is effective in overcoming the masking effect but is aggressive , we conclude that the max statistic @xmath191 and the min statistic @xmath190 are complementary to each other .",
    "if the min - unmask condition holds for all @xmath253 simultaneously , then @xmath162 with @xmath253 will be detected correctly , when certain error control procedure is used .",
    "for example , similar to proposition [ proposition2 ] , with @xmath308 , one can show that the benjamini - hochberg procedure can correctly detect the influential observations .",
    "however , the min - unmask condition is very strong and may not be satisfied for all @xmath253 simultaneously .",
    "we provide a sufficient condition for this condition to hold . without loss of generality ,",
    "we assume @xmath309 and write @xmath310 ranking @xmath311 in a decreasing order .",
    "[ prop3 ] if @xmath312 , then the min - unmask condition holds simultaneously for all the influential points @xmath253 .",
    "the condition in proposition [ prop3 ] is strong .",
    "when @xmath313 and @xmath314 is large , proposition [ prop3 ] needs @xmath315 not to be too small but this condition may be violated easily .",
    "a remedy is to sequentially remove the influential observations that have been detected so far and then apply the detecting procedure recursively on the remaining data , as we explain below .    to simplify the description , we introduce some notations . for any subset @xmath316 with cardinality @xmath317 and any observation @xmath318 with @xmath319",
    ", we can draw at random with replacement subsets @xmath320 , with the same cardinality @xmath321 , where @xmath322 .",
    "similar to @xmath190 , we define @xmath323 , where @xmath324 .",
    "denote by @xmath325 the indices of non - influential observations in @xmath326 and let @xmath327 , @xmath175 .",
    "let @xmath328 be such that @xmath329 . then similar to @xmath241 , we define @xmath330 , which denotes the minimum of the joint effect of influential observations with indices in @xmath331 . and similar to @xmath242",
    ", one can define @xmath332 . obviously , when @xmath333 , @xmath334 , @xmath335 and @xmath336 are exactly the same as @xmath337 , @xmath338 and @xmath339 , respectively .",
    "generally , suppose that @xmath340 s can be separated into several groups in successive order , that is , @xmath341 , such that @xmath342 .",
    "denote @xmath343 .",
    "let @xmath344 , @xmath345 and @xmath346 , @xmath347 . for simplicity",
    ", we assume that @xmath348 s are independent of @xmath35 , denoted still as @xmath181 , and that the sufficient condition in proposition [ prop3 ] holds for group @xmath349 , that is , [ gmin - unmaks ] e_(m_j)^1/2>r _ e_(m_j-1 + 1)^1/2+(^2_1-(q))^1/2 ,  1j , which is referred to as gmin - unmask condition for simplicity .",
    "then , similarly to the argument of proposition [ prop3 ] , we see that min - unmask condition holds simultaneously for any @xmath350 on the data set @xmath351 , that is , @xmath352 .",
    "consequently @xmath353 with @xmath354 will be large than @xmath229 with high probability .",
    "if influential observations in @xmath355 are detected correctly and removed sequentially , the influential observations in group @xmath356 can be detected successfully with high probability .",
    "we remark that the gunmask - condition is much weaker than the condition in proposition [ prop3 ] .",
    "this motivates us to consider the following multi - round procedure .",
    "define the set of influential observations identified in the @xmath35th round as @xmath357 where @xmath290 depends on the specific procedure used , similar to the discussion in section 3.1 , @xmath358 with @xmath359 , and @xmath360 .",
    "finally , we can estimate @xmath18 by @xmath361 , where @xmath362 is such that @xmath363 .",
    "let @xmath364 be the false positive rate associated with estimate @xmath365 .",
    "[ proposition3 ] suppose that ( c6 ) holds and that fdr is controlled at level @xmath291 in each round",
    ". then @xmath366 .",
    "although the above iterative procedure can improve the performance of @xmath190 to overcome the masking effect , requiring only weaker gmin - unmask condition in ( [ gmin - unmaks ] ) , the computation of this procedure will be more costly if the number of rounds @xmath362 is large .",
    "on the other hand , the gmin - unmask condition will be easier to satisfy for larger @xmath362 .",
    "theoretically , @xmath362 can be as large as @xmath169 , where gmin - unmask condition in ( [ gmin - unmaks ] ) becomes @xmath367 by noting that @xmath368 , which is much weaker than the condition in proposition [ prop3 ] . however , larger @xmath362 demands more intensive computing .",
    "if an early stopping strategy is adopted , it may still suffer from the masking effect .    as a quick summary ,",
    "the test statistic @xmath191 is more efficient in dealing with the masking effect , because the strength of the influential observations required by @xmath191 in ( ii ) of theorem [ th3 ] is much weaker than gmin - unmask condition ( [ gmin - unmaks ] ) required by @xmath190 , when @xmath221 is large .",
    "moreover , any procedure based on @xmath191 is computationally efficient , identifying the influential observations in just one round .",
    "however , @xmath191 may suffer from the swamping effect if the strong condition @xmath261 of theorem [ th3 ] is violated . on the other hand ,",
    "the estimate @xmath365 based on the statistic @xmath190 can maintain good fpr at the expense of more intensive computation .",
    "taking advantages of both statistics , we propose the following computationally efficient min - max - checking algorithm for identifying a clean set that contains no influential points and can serve as the benchmark for assessing the influence of other points .",
    "we propose the following algorithm to combine the strengths of the max and min statistics .    *",
    "min - max algorithm for estimating a clean set *    * .",
    "let @xmath369 and fix @xmath370 .",
    "repeat steps 1 and 2 until stop . *",
    "* * min - step*. for the data indices in @xmath371 , compute @xmath372 .",
    "alternatively we may simply take @xmath373 as the set of indices with the first @xmath374 smallest @xmath6-value for some small number @xmath374 .",
    "update @xmath375 . * * * max - step*. estimate @xmath376 as in section 3.1 based on observations in @xmath371 and denote its complement @xmath377 as an estimate of the clean set .",
    "if @xmath378 , then stop ; otherwise , go to min - step .",
    "this algorithm identifies a clean dataset containing no influential points with cardinality at least @xmath379 by successively removing potential influential points . here",
    "@xmath380 is specified by the procedure that controls the error rate , and can be determined in the same way as @xmath290 in section 3.1 .",
    "the main rational of this algorithm is , as argued , that the max statistic @xmath191 is aggressive in declaring influential while min statistic @xmath190 is conservative .",
    "we first run a min - step to eliminate those influential observations with strong strength to alleviate the swamping effect .",
    "combined with the efficiency of @xmath191 in overcoming the masking effect , it is highly possible to obtain a clean set with a large size in one iteration .",
    "if the clean set is not large enough , we run the min - step again to remove further influential observations with strong strength . in our numerical study , we find that this algorithm is computationally very efficient , usually stops in 1 or 2 rounds .    with some abuse of notations ,",
    "write @xmath381 as the final clean set obtained by the min - max algorithm",
    ". then its supplement , written as @xmath382 , is an estimate of the set which contains all potential influential observations .",
    "however , @xmath383 may still contain non - influential observations as the procedure for obtaining a clean set only aims to find a subset of the non - influential points . a further step to check whether any point in @xmath383 is truly influential if necessary .",
    "this step , however , is easy since we have now a clean dataset .",
    "we now outline the exact procedure . for any @xmath384 , consider the data with indices in @xmath381 and @xmath385 , respectively .",
    "we then compute statistic @xmath386 as in section 2 where @xmath387 and @xmath388 are computed on data set @xmath381 and @xmath389 , respectively . since @xmath381 is a good estimate of the clean data containing no influential point",
    ", this leave - one - out approach will be effective for testing multiple null hypotheses in the form of @xmath390 .",
    "if @xmath381 is good , according to the results in section 2 , @xmath391 will follow @xmath14 distribution under @xmath392 by theorem [ th1 ] , where @xmath393 .",
    "the benjamini - hochberg procedure can then be applied to control fdr .",
    "those whose corresponding hypotheses are rejected by the fdr procedure can be labeled as influential observations .",
    "the algorithm for detecting multiple influential observations , called min - max - checking algorithm , is summarized as follows .    *",
    "min - max - checking algorithm *    * estimate a clean subset @xmath381 by the min - max algorithm ; * check for each @xmath394 whether the @xmath43th observation is influential .",
    "we evaluate the performance of mip for detecting multiple influential points and compare it to him whenever possible . because him is only developed for @xmath94 and does not use any group deletion procedure , it is not applied to examples where @xmath395 . throughout the simulation study",
    ", we set the sample size as @xmath396 and the number of predictors as @xmath397 .",
    "we generate @xmath51 observations from [ model1 ] _ i = b_i+_i , 1 in , where @xmath56 , @xmath398 , @xmath399 , and @xmath400 .",
    "we then replace the first @xmath401 points in @xmath402 by @xmath403 which are generated differently .",
    "the resulting dataset denoted as @xmath404 thus may contain @xmath405 influential points . for , we set @xmath406 and @xmath407 where @xmath408 .",
    "the coefficient matrix @xmath409 and how @xmath410 is generated are specified below .",
    "we evaluate performance by assessing the success in identifying influential and non - influential points , the accuracy in estimating @xmath409 in model , and the success in identifying the support of @xmath409 .",
    "let @xmath18 be the index set of the influential points and @xmath411 as its estimate either by him or mip .",
    "we first compute @xmath412 , the true positive rate for influential observation detection , and @xmath413 , the false positive rate for detection .",
    "that is , @xmath414 and @xmath415 . denoting @xmath416 as the false negative rate",
    ", we also compute the @xmath417-score defined as @xmath418 .",
    "obviously , the larger @xmath417 , the better the corresponding method is .    denote @xmath419 as an estimate of @xmath409 which is based on the full data ( full ) , or based on a reduced dataset after him is applied ( him ) , or a reduced dataset after mip is applied ( mip ) . in this paper",
    ", we estimate @xmath409 via the lasso when @xmath94 or via the group lasso by treating the rows of @xmath409 as groups when @xmath395 @xcite .",
    "the accuracy of the estimation is evaluated by computing @xmath420 and we compare the accuracy of full , him and mip .",
    "let @xmath421 be the @xmath35-th row of @xmath409 and likewise @xmath422 for @xmath423",
    ". for @xmath424 , denote the support of @xmath409 as @xmath425 and its complement as @xmath426 .",
    "we report the success in identifying the support of @xmath409 by reporting @xmath427    in the following simulations , we set @xmath428 .",
    "that is , the random subsets @xmath429 all have cardinaltiy @xmath379 .",
    "we repeat each experiment @xmath430 times and report the means of the quantities defined above . in implementing mip , we set the number of random subsets as @xmath431 for example 24 . for example 1",
    ", we take @xmath432 or @xmath433 to assess the effect of @xmath221 . in table 2 , because the @xmath413 of him can be large , we decided not to compute the coefficient estimates based on the reduced data to save space as long as @xmath434 , finally , the fdr level is fixed at @xmath53 .",
    "in the following examples , example 1 and 2 focus on scalar responses ( i.e. @xmath94 ) , and example 3 and 4 on multiple responses ( @xmath395 ) .",
    "we simulate the data such that there exists a strong masking effect in example 1 and a strong swamping effect in example 2 .",
    "denote @xmath435 as a @xmath436-dimensional zero vector and @xmath437 as a @xmath436-dimensional vector of @xmath438 s .",
    "* example 1 * ( strong masking effect ) .",
    "we first generate @xmath396 non - influential observations from ( [ model1 ] ) with @xmath439 , @xmath440 . let @xmath441 .",
    "we then replace the first @xmath401 non - influential observations by @xmath442 where @xmath443 , with @xmath444 , are subsets of @xmath445 chosen independently with replacement , and @xmath446 .",
    "this example is designed such that the influential observations are clustered together and consequently many influential observations are masked by other influential ones .",
    "him based on leave - one - out will likely fail to identify many influential points .",
    "the simulation results are presented in table [ table1 ] and plot ( a ) of figure [ fig2 ] .",
    ".[table1]simulation results of example 1 with different @xmath52 . [ cols=\"<,<,^,^,^,^,^,^,^\",options=\"header \" , ]     from the above table , we see that in all cases , the computational time of the non - parallel algorithm is about 2.5 times more than that of the parallel algorithm . note that only 4 cpu are used for parallel computing in this simple comparison .",
    "a much higher computational gain is expected if more cpus are used .    *",
    "models beyond linear models*. the mip procedure may be extended beyond the linear model and here we provide a short discussion . motivated by the marginal correlation idea for linear regression , zhao et al .",
    "( 2013 ) discussed an extension of him to generalized linear models , by replacing the marginal correlation with the marginal maximum likelihood estimator which has been used for variable screening by @xcite .",
    "the group deletion procedure employed by mip may be then used for defining new min and max statistics . however , substantial theoretical challenges exist to understand their asymptotic distributions . generalizing the method in this paper to other models is an interesting topic for future research .",
    "* final comment*. in conclusion , we hope that this paper can bring to the attention of the statistics community the importance of influence diagnosis and how one might think about defining influence and devising automatic procedures for assessing influence , in a theoretically justified fashion . with the rapid advances of the big data analytics",
    ", we believe that the issue of influence diagnosis will only become more relevant and hope that this paper can serve as a catalyst to stimulate more research in this area .",
    "due to the complexity of the statistic @xmath93 , we complete the proof in two major steps . in step 1 , we first establish the asymptotic distribution of a statistic denoted as @xmath447 assuming that @xmath448 are known . in step 2 , we derive the results of @xmath93 by analyzing the difference between @xmath447 and @xmath93 . here",
    "@xmath447 is an intermediate quantity used only to simplify the proof .",
    "now we give the explicit expression of @xmath447 .",
    "when @xmath449 are known , without loss generality , we assume that @xmath450 and define @xmath447 as @xmath451 where @xmath452 with @xmath453 and @xmath454 @xmath455 with @xmath456 .    [ lemmadotdk ] under assumptions ( c1)-(c4 ) , we have @xmath457 .",
    "the proof of lemma [ lemmadotdk ] is similar to that of zhao et al .",
    "( 2013 ) , where @xmath458 is a scalar variable following a normal distribution .",
    "in fact , the main requirement on @xmath458 in the proof there is that the eighth moment of @xmath458 exists , which is equivalent to @xmath459 under the normal assumption . for the multivariate responses considered in this paper ,",
    "@xmath460 and @xmath461 has bounded eigenvalues . moreover , recall that @xmath462 , due to @xmath463 .",
    "therefore , the main argument of zhao et al .",
    "( 2013 ) can be applied here with some minor revision .",
    "we only give a simple description of the proof .",
    "let @xmath464 for any @xmath465 and @xmath466 .",
    "after some algebra , we have , for @xmath467 , _ k&=&p^-1-^(k)_f^2 , + & = & p^-1_j=1^p_1tn^tk _ tx_tj-_kx_kj",
    "^2 + & = & _ t=1^n _ t^2 k_p , tt+_k^2 k_p , kk + & & + _ ts _ t^_sk_p , ts-_t=1,tk^n _ k^_tk_p , tk + & : = & a_1+a_2+a_3 - 2a_4 . due to assumption ( c4 ) and the assumption @xmath468 , we know that @xmath469 and @xmath470 . under assumptions ( c1)(c3 ) , by nearly the same argument to prove proposition 1 of zhao et al .",
    "( 2013 ) , we have @xmath471^{-1}e(\\|\\dot \\by_k\\|^2)e(k_{p , kk } ) + o(n^{-2}p^{-1}l_p^{1/2 } ) $ ] .",
    "in addition , @xmath472 and @xmath473 .",
    "similar to the proof of theorem 1 in zhao et al .",
    "( 2013 ) , we have @xmath474e(k_{p , kk } ) + o_p(p^{r/2 - 1})\\}$ ] , @xmath475 , @xmath476 , and @xmath477 . then _ k&=&e(_k)+[_k - e(_k ) ] + & = & e(_k)+[_i=1,2,3(a_i - e(a_i))-2(a_4-e(a_4 ) ) ] + & = & e(_k^2)e(k_p , kk)+(_k^2-e(_k^2))e(k_p , kk ) + & & + o_p(p^r/2 - 1)+o_p(n^-3/2 ) + & = & _ k^2e(k_p , kk)+e(_k^2)e(k_p , kk)+o_p(p^r/2 - 1)+o_p(n^-3/2 ) + & = & _ k^2+o_p(1),where we use the fact that @xmath478 .",
    "since @xmath479 , we have @xmath480 .",
    "this completes the proof of lemma [ lemmadotdk ] .",
    "@xmath481    _ proof of theorem [ th1]_. now we establish the asymptotic results of @xmath93 by analyzing the difference between @xmath447 and @xmath93 .",
    "the proof is similar to that of proposition 1 in zhao et al .",
    "( 2013 ) . for clarity and simplicity",
    ", we use the general version by replacing @xmath482 , with @xmath483 and @xmath484 with @xmath485 in the definition of @xmath447 , @xmath486 and @xmath487 .",
    "obviously , this does not change the asymptotic distribution of @xmath447 .",
    "when @xmath488 and @xmath69 are unknown , we use the corresponding estimates and obtain @xmath489 and @xmath195 .",
    "the corresponding statistics are denoted as @xmath490 and @xmath93 .",
    "we show that @xmath491 is small with an argument similar to proposition 2 of zhao et al .",
    "( 2013 ) where @xmath94 .",
    "we briefly review the conditions required in proposition 2 of zhao et al .",
    "( 2013 ) . assumption ( c.2 ) and ( c.3 ) in zhao et al .",
    "( 2013 ) are for @xmath8 .",
    "the requirement on the response in zhao et al .",
    "( 2013 ) is that @xmath492 , which is met when @xmath458 is normal .",
    "furthermore , the estimators of parameters @xmath493 are required to satisfy some moment condition in ( c.4 ) there .    in the case of @xmath494 considered in this paper , the argument there still holds with some minor revisions on the requirement on @xmath133 .",
    "recall that assumptions ( c2 ) and ( c3 ) are exactly the same assumptions as ( c.2 ) and ( c.3 ) in zhao et al .",
    "therefore the requirement on @xmath8 in the proof of zhao et al .",
    "( 2013 ) is met under ( c2 ) and ( c3 ) of this paper .",
    "there are only two points that should be handled : ( i ) we need to show the eighth moments of @xmath495 exists .",
    "( ii ) assumption ( c5 ) in this paper is slightly different from ( c.4 ) of zhao et al .",
    "( 2013 ) , where condition ( c.4 ) is used to prove the assumption @xmath496 ( zhao et al . , 2013 ) with @xmath497 ^ 2 $ ] and @xmath498 ^ 2 $ ] .",
    "therefore , we need to show that @xmath496 still holds under ( c5 ) in this paper .    _ step 1_.we prove conclusion ( ii ) . recall @xmath499 . then ( x_tj-_xj)/_xj & = & + + & = & x_tj+x_tj(-1)+ + & : = & x_tj+e_1j+e_2j.we have k_p",
    ", tt - k_p , tt&=&2p^-1_j=1^p x_tj e_1j+2p^-1_j=1^p x_tj e_2j+p^-1_j=1^p(e_1j+e_2j)^2 + & : = & 2f_1n+2f_2n+f_3n.we only show that @xmath500 and other terms can be proved similarly .",
    "note that @xmath501 .",
    "obviously , due to the normality of @xmath502 , it holds that @xmath503 .",
    "moreover , due to ( c5 ) , we have @xmath504 ^ 4<\\infty.\\ ] ] combining them , we have @xmath505 and consequently @xmath506 . by the similar approach , one can show that @xmath507 and @xmath508 are of order @xmath509 .",
    "therefore , we still have @xmath496 ( zhao et al . , 2013 ) .",
    "_ step 2_.now we prove the final conclusion by showing that the eighth moment of @xmath510 exists . recalling the definition of @xmath124 , it is easy to see _ t & & _",
    "y^-1/2(_t-_y)+_y^-1/2(_y-_y)+(_y^-1/2-_y^-1/2)(_t-_y ) + & : = & _ t+q_y+b_n . since @xmath511 , the eighth moment of @xmath512 exists . by assumption",
    "( c4 ) that @xmath513 , we have b_n&&_y^-1/2-_y^-1/2 ( _ t-_y+_y-_y ) + & & _ y^-1/2-_y^-1/2_f .",
    "y^-1/2_y^1/2-i_q_f_y^-1/2_f .by assumptions ( c4 ) and ( c5 ) that @xmath514 and @xmath515 are finite , we have @xmath516 .",
    "consequently , similar to the proof in zhao et al .",
    "( 2013 ) , we have @xmath517 and @xmath518 , @xmath519 .",
    "consequently , we have @xmath520 this completes the proof of theorem [ th1 ] . @xmath481",
    "define @xmath521 .",
    "observe @xmath522 the main idea of the proof is to show that the two terms on the righthand are small . for simplicity ,",
    "we assume that each element of @xmath523 has population mean 0 and variance 1 , that is , @xmath524 and @xmath525 . before the proof , we review some facts . for any @xmath526 ,",
    "define @xmath527 then by lemma 1 of zhao et al .",
    "( 2013 ) , we have @xmath528 if @xmath529 and @xmath438 if @xmath530 . besides , @xmath531 and @xmath532 , for any @xmath529 .",
    "in addition , @xmath533 due to @xmath534 .",
    "it is easy to see that for @xmath537 , @xmath538 where @xmath539 and @xmath540 .",
    "let @xmath541 and @xmath542 . by ( c7 ) and",
    "simple calculation , we have , for some constant @xmath543 , [ eq_uni_sigm_mu ] p(n^1/2 w_x , n^(1)>cp)p^-3 ,",
    "p(n^1/2 w_x , n^(2)>cp)p^-3 . that is [ eq_max_sigm_mu ] w_x , n^(1)=o_p((p)n^-1/2 ) ,   w_x , n^(2)=o_p((p)n^-1/2 ) . similarly , let @xmath544 , which follows standard norma @xmath545 . then _",
    "t&=&_y^-1/2(_t-_y)=_t+(_y^-1/2_y^1/2-i_q)_t+_y^-1/2(_y-_y ) + & : = & _ t+u_n_t+_n , where @xmath546 and @xmath547 are defined accordingly . let @xmath548 .",
    "note that @xmath549 according to the assumption on @xmath207 in ( c7 ) .",
    "similarly , we have @xmath550 by ( c4 ) and ( c7 ) .",
    "recall the definition of @xmath552 , @xmath553 , @xmath554 and @xmath555 .",
    "define @xmath556 the we have |a_t_1t_2| & & |k_p , t_1t_2|",
    "| f_p , t_1t_2-f_p , t_1t_2|+ | f_p , t_1t_2| |k_p , t_1t_2- k_p , t_1t_2|.by assumption ( c6 ) , we see that @xmath557 for all @xmath175 , that is , @xmath558 has the same order as @xmath51 . by simple calculations",
    ", we have @xmath559 then it follows that [ max_r - dotr ] _",
    "1rm    & & _ r\\{n_b_r^-1_1tn|a_tt|+_t_1t_2,1t_1,t_2na_t_1t_2 } + & & _ r\\ { n_b_r^-1_1tn|a_tt|+_t_1t_2,1t_1,t_2n|a_t_1t_2|}. + & & ( _ r n_b_r^-1)_1tn|a_tt|+_t_1t_2,1t_1,t_2n|a_t_1t_2| . + _ step 3_. we study the terms in @xmath560 .      because @xmath202 s are _",
    "_ variables with distribution @xmath545 , @xmath563 and consequently , by the tail probability of @xmath14 distribution , we have @xmath564 . by cauchy - schwarz inequality , we see that @xmath561 holds .",
    "in addition , by the results in step 1 , applying cauchy - schwarz inequality and triangle inequality , we have _ t_t-_t^2 & & _ tu_n_t+_n^22 [ ( _ t_t^2)w_y^(1)+(w_y^(2))^2 ] + & = & o_p((n)/n ) + o_p(n^-1)=o_p((n)/n ) .",
    "moreover , for any @xmath565 , _ t_1,t_2|f_p , t_1t_2-f_p , t_1t_2|&=&_t|_t_1^(_t_2-_t_2)+(_t_1-_t_1)^_t_2+(_t_1-_t_1)^(_t_2-_t_2)| + & & 2_t_1t_2|_t_1^(_t_2-_t_2)|+_t_1t_2|(_t_1-_t_1)^(_t_2-_t_2)| + & & 2_t_1_t_1 _ t_2_t_2-_t_2+_t_1_t_1-_t_1)^2 + & = & o_p((n)/ )",
    ".    _ step 3.2_. we show @xmath566 in fact , it is easy to see _",
    "t_1,t_2|k_p , t_1t_2-k_p , t_1t_2|&=&_t_1,t_2|p^-1[_t_1^(_t_2-_t_2)+(_t_1-_t_1)^_t_2+(_t_1-_t_1)^(_t_2-_t_2)]| .",
    "+ for any @xmath567 , we have @xmath568 since @xmath569 are standard normal and @xmath569 s are independent with respect to @xmath537 , we have @xmath570 @xmath571 combining with ( [ eq_max_sigm_mu ] ) in step 1 , we have @xmath572 . by similar arguments and noting @xmath573",
    ", we have p^-1|(_t_1-_t_1)^(_t_2-_t_2)|&&_1jp        note @xmath576 the second term has been analyzed in step 3.2 .",
    "consider the first term which satisfies @xmath577 since @xmath569 s are standard normal , we have arguments similar to before that @xmath578 for @xmath579 , recall that @xmath580 and @xmath528 if @xmath529 .",
    "thus , we have the conclusion of step 3.3 . finally , combining all the results in step 3",
    ", it follows that @xmath581 combining with ( [ max_r - dotr ] ) , we have the conclusion of step 3 and it follows that @xmath582 this complets the proof of part i.        & & ( n_1)^-2 n e|f_t_1t_1 k_p , t_1t_1| + & & ( n_1)^-2 n [ e(f_t_1t_1)^2]^1/2 [ e(k_p , t_1t_1)^2]^1/2 . noting that @xmath533 ,",
    "we have that @xmath585 is bounded . moreover , noting @xmath580 and @xmath531 , we have @xmath586 then @xmath587 .",
    "similarly , we have t_2&:=&e\\{[_r n_b_r]^-2_1t_1,t_2n , t_1t_2 |f_t_1t_2 k_p , t_1t_2| } + & & ( n_1)^-2n(n-1 ) e|f_t_1t_2 k_p , t_1t_2| + & & _ 1 ^ 2 [ e(f_t_1t_2)^2]^1/2 [ e(k_p , t_1t_2)^2]^1/2 , where @xmath529 in the second inequality . by the cauchy - schwarz inequality , we have @xmath588 ^ 2<\\infty$ ] . on the other hand , @xmath532 .",
    "therefore , @xmath589 .",
    "combining , we have @xmath590 . finally combining the conclusions in part i and part ii , we have @xmath591      recall @xmath592 .",
    "similar to the proof of theorem [ th1 ] , we have @xmath593 consequently , it holds that n_^2_r , k&=&p^-1_tb_r\\{k } _",
    "k_k^_f^2 + & : = & p^-1w_r , non-_k_k^_f^2 . by lemma [ lemma1 ] , we have @xmath594 .",
    "therefore , _ 1rmn_^2_r ,",
    "k&=&p^-1_k_k^_f^2(1 + o_p(_n , p+p^-1l_p^1/2)).on the other hand , based on assumption ( c7 ) and the proof of lemma [ lemma1 ] , we have @xmath595",
    ". that is , @xmath596 . furthermore , by the argument on @xmath597 in the proof of theorem [ th1 ]",
    ", we have @xmath598 note that @xmath599 follows @xmath545 with fixed @xmath15 .",
    "therefore , @xmath600 consequently , @xmath601 . by nearly the same argument",
    ", it is easy to see that @xmath223 .",
    "this completes the proof .",
    "@xmath481      \\(1 ) we first prove the conclusion that @xmath602 mentioned just before theorem [ th3 ] .",
    "note that @xmath244 and that @xmath603 where @xmath245 by assumption ( c6 ) .",
    "denote @xmath604 .",
    "obviously we have @xmath605 , due to the fact @xmath233 .",
    "recall the definition of @xmath606 .",
    "then @xmath607 recall that @xmath608 .",
    "then , it holds that [ eq3.3 ] f_,k= r_^2p^-1_1rmw_,k , r_f^2r_^2 d_s_\\{k}r_^2 d_s_.    \\(2 ) we prove the conclusion of ( @xmath3 ) and ( @xmath609 ) . recall that @xmath610 by ( [ dec_d_rk ] ) . by lemma [ lemma1 ]",
    ", it follows that @xmath611 .",
    "consequently , by the cauchy - schwarz inequality , it holds that [ app_tmin ] t_,k & = & _ 1rm n_^2_r , k + & = & _ 1rm p^-1w_,k , r-_k_k^_f^2(1+o_p(1 ) ) , and [ app_tmax ] t_,k & = & _ 1rm n_^2_r , k + & = & _ 1rm p^-1w_,k , r-_k_k^_f^2(1+o_p(1 ) ) .",
    "we prove the conclusion in ( ii ) . due to the definition of @xmath241",
    ", we can always find some @xmath614 such that @xmath615 .",
    "when @xmath162 is influential , by ( [ app_tmax ] ) and the definition of @xmath616 , it follows that t_,k^1/2&&[n_^2_r_0,k]^1/2=p^-1/2(_k_k^_f - w_,k , r_0_f)(1+o_p(1))^1/2 + & = & ( e_k^1/2-f_,k^1/2)(1+o_p(1))^1/2 . since @xmath617",
    ", we have @xmath258 .",
    "this completes the proof .",
    "@xmath481      note that @xmath193 is defined for fixed @xmath43 , that is , @xmath193 depends on @xmath43 .",
    "checking step 2 of part i and part ii in the proof of lemma [ lemma1 ] , we see that both @xmath618 and @xmath619 have upper bounds independent of @xmath43 . therefore , lemma [ lemma1 ] actually holds uniformly over @xmath43 , that is , @xmath620 .    by the proof of ( ii ) in the proof of theorem",
    "[ th3 ] , @xmath621 , where the term @xmath622 depending on @xmath623 is independent of @xmath43 .",
    "therefore , @xmath624 .",
    "note that @xmath625 . since @xmath269 is independent of @xmath43",
    ", we have @xmath626 .",
    "consequently , according to the assumption @xmath627 , we have @xmath628 since @xmath14 is the limit distribution under the null hypothesis of no influential observations , the @xmath6-values associated with observations of indices in set @xmath18 are no more than @xmath231 in probability .",
    "therefore @xmath629 with probability tending to 1 .",
    "recall that @xmath630 s are the increasing order of @xmath6-value @xmath631 s .",
    "let @xmath632 be the largest @xmath3 such that @xmath633 .",
    "the benjamini - hochberg procedure rejects hypothesis @xmath634 , where @xmath635 .",
    "denote by @xmath636 $ ] as the rank of @xmath631 in the series @xmath630 s .",
    "let @xmath637 $ ] be the largest rank for @xmath638 .",
    "if @xmath639 is less than @xmath640/n$ ] for @xmath641 , then according to the rejection rule of the benjamini - hochberg procedure , all @xmath392 with @xmath641 will be rejected .",
    "noting that @xmath642 , we have in probability tending to one @xmath643 on the other hand , it is easy to see that @xmath637\\ge n_{\\inf}$ ] . thus , it follows that @xmath644/n$ ] in probability tending to 1 .",
    "therefore , all @xmath392 with @xmath641 will be rejected by the benjamini - hochberg procedure .",
    "@xmath481      the proof of theorem [ th4 ] is similar to that of theorem [ th3 ] .",
    "we first prove the conclusion in ( i ) of theorem [ th4 ] . by ( [ app_tmin ] ) and as @xmath303 , we see that @xmath645 and that @xmath646 for any @xmath234 .",
    "now we turn to conclusion ( ii ) of theorem [ th4 ] .",
    "note that @xmath647 . according to the argument in the proof of proposition [ proposition2 ] ,",
    "the term @xmath648 is independent of @xmath253 .",
    "therefore , @xmath649 . combining with the assumption @xmath650 , we have the conclusion as desired .",
    "finally , we prove proposition [ prop3 ] . recall that @xmath651 in ( [ eq3.3 ] ) .",
    "the sufficient condition in proposition [ prop3 ] is derived from the fact that @xmath652 and the min - unmask condition of theorem [ th4 ] .",
    "@xmath481      we consider only the case when @xmath653 .",
    "the proof of the general case is similar .",
    "denote by @xmath654 and @xmath655 as the number of hypothesis rejected in round 1 and 2 , respectively . since the fdr level is controlled at @xmath291 in each round , then for estimate @xmath656 ,",
    "the number of falsely rejected hypotheses is less than @xmath657 where @xmath658 is the total number of rejected ones",
    ". therefore fdr is still controlled at level @xmath291 , that is , @xmath659 , where @xmath660 is the number of non - influential observations that are falsely labeled as influential ones , and @xmath661 is the number of influential observations that are correctly identified . due to the fact @xmath662 , we have @xmath663",
    ". then @xmath664 where we use in the last equality the assumption that @xmath665 in ( c6 ) . @xmath481",
    "chiang , a. p. , beck j. s. , yen , h. j. , tayeh , m. k. , scheetz , t. e. , swiderski , r. e. , nishimura , d.y . , braun , t. a. , kim , k. y. , huang , j. elbedour , k. , carmi , r. , slusarski , d. c. , casavant , t. l. , stone , e. m. , and sheffield , v. c. ( 2006 ) .",
    "homozygosity mapping with snp arrays identifies trim32 , an e3 ubiquitin ligase , as a bardet - biedl syndrome gene ( bbs11 ) .",
    "_ proceedings of the national academy of sciences of the united states of america _ , * 103 * , 6287 - 6292 .                                        nurunnabi , a. a. m. , hadi , a. s. , and imon , a. h. m. r. ( 2014 )",
    ". procedures for the identification of multiple influential observations in linear regression .",
    "_ journal of applied statistics _ , * 41 * , 13151331 .",
    "yuan , m. , ekici , a. , lu , z. , and monteiro , r. ( 2007 ) .",
    "dimension reduction and coefficient estimation in multivariate linear regression .",
    "_ journal of the royal statistical society , series b _ , * 69 * , 329346 ."
  ],
  "abstract_text": [
    "<S> influence diagnosis should be routinely conducted when one aims to construct a regression model . despite its importance , the problem of influence quantification is severely under - investigated in a high - dimensional setting , mainly due to the difficulty of establishing a coherent theoretical framework and the lack of easily implementable procedures . </S>",
    "<S> although some progress has been made in recent years , existing approaches are ineffective in detecting multiple influential points especially due to the notorious  masking \" and  swamping \" effects . to address this challenge </S>",
    "<S> , we propose a new group deletion procedure referred to as mip by introducing two novel quantities named max and min statistics . </S>",
    "<S> these two statistics have complimentary properties in that the max statistic is effective for overcoming the masking effect while the min statistic is useful for overcoming the swamping effect . combining their strengths </S>",
    "<S> , we further propose an efficient algorithm that can detect influential points with prespecified guarantees . </S>",
    "<S> for wider applications , we focus on developing the new proposal for the multiple response regression model , encompassing the univariate response linear model as a special case . </S>",
    "<S> the proposed influential point detection procedure is simple to implement , efficient to run , and enjoys attractive theoretical properties . </S>",
    "<S> its effectiveness is verified empirically via extensive simulation study and data analysis .    * keywords * : false discovery rate , group deletion , high - dimensional linear regression , influential point detection , masking and swamping , multiple responses , robust statistics .    </S>",
    "<S> * running title * : multiple influential point detection . </S>"
  ]
}