{
  "article_text": [
    "memories , like eprom , eeprom , flash memory or phase - change memory ( pcm ) , are memories that can keep the data content even without power supply .",
    "this property enables them to be used in a wide range of applications , including cellphones , consumers , automotive and computers .",
    "many research studies have been carried out on nonvolatile memories because of their unique features , attractive applications and huge marketing demands .",
    "an important challenge for most nonvolatile memories is data reliability .",
    "the stored data can be lost due to many mechanisms , including cell heterogeneity , programming noise , write disturbance , read disturbance , etc . @xcite . from a long - term view",
    ", the change in data has an asymmetric property .",
    "for example , the stored data in flash memories is represented by the voltage levels of transistors , which drift in one direction because of charge leakage . in pcm , another class of nonvolatile memories , the stored data is determined by the electrical resistance of the cells , which drifts due to thermally activated crystallization of the amorphous material @xcite .",
    "all these mechanisms make the errors in nonvolatile memories be heterogeneous , asymmetric , time dependent and unpredictable .",
    "these properties bring substantial difficulties to researchers attempting to develop simple and efficient error - correcting schemes .    to date , existing coding schemes for nonvolatile memories commonly use fixed thresholds to read data .",
    "for instance , in flash memories , a threshold voltage level @xmath0 is predetermined ; when reading data from a cell , it gets ` 1 ' if the voltage level is higher than @xmath0 , and otherwise it gets ` 0 ' . to increase data reliability , error - correcting codes such as hamming code , bch code , reed - solomon code and ldpc code",
    "are applied in nonvolatile memories to combat errors . because of the asymmetric feature of nonvolatile memories , a fixed threshold usually introduces too many asymmetric errors after a long duration @xcite , namely , the number of @xmath1 errors is usually much larger than the number of @xmath2 errors . to overcome the limitations of fixed thresholds in reading data in nonvolatile memories ,",
    "dynamic thresholds are introduced in this paper . to better understand this , we use flash memories for illustration , see fig .",
    "[ fig_voltagedistribution ] .",
    "the top figure is for newly written data , and the bottom figure is for old data that has been stored for a long time @xmath3 . in the figures ,",
    "assume the left curve indicates the voltage distribution for bit ` 0 ' ( a bit ` 0 ' is written during programming ) and the right curve indicates the voltage distribution for bit ` 1 ' . at time @xmath4 ( the moment after programming ) , it is best to set the threshold voltage as @xmath5 , for separating bit ` 1 ' and ` 0 ' .",
    "but after a period of time , the voltage distribution will change .",
    "in this case , @xmath6 is no longer the best choice , since it will introduce too many @xmath1 errors .",
    "instead , we can set the threshold voltage as @xmath7 ( see the second plot in the figure ) , to minimize the error probability .",
    "this also applies to other nonvolatile memories , such as pcms .        although best dynamic reading thresholds lead to much less errors than fixed ones , certain difficulties exist in determining their values at a time @xmath8 .",
    "one reason is that the accurate level distributions for bit ` 1 ' and ` 0 ' at any the current time are hard to obtain due to the lack of time records , the heterogeneity of blocks , and the unpredictability of exceptions . another possible method is to classify all the cell levels into two groups based on unsupervised clustering and",
    "then map them into  1 s and  0 s .",
    "but when the border between bit  1 s and  0 s becomes fuzzy , mistakes of clustering may cause significant number of reading errors . in view of these considerations , in this paper , we introduce a simple and practical writing / reading scheme in nonvolatile memories , called _ balanced modulation _ , which is based on the construction of balanced codes ( or balanced error - correcting codes ) and it aims to minimize the asymmetric component of errors in the current block .",
    "balanced codes , whose codewords have an equal number of @xmath9s and @xmath4s , have been studied in several literatures .",
    "knuth , in 1986 , proposed a simple method of constructing balanced codes @xcite . in his method , given an information word of @xmath10-bits ( @xmath10 is even ) , the encoder inverts the first @xmath11 bits such that the modified word has an equal number of @xmath9s and @xmath4s .",
    "knuth showed that such an integer @xmath11 always exists , and it is represented by a balanced word of length @xmath12 .",
    "then a codeword consists of an @xmath12-bit prefix word and an @xmath10-bit modified information word .",
    "for decoding , the decoder can easily retrieve the value of @xmath11 and then get the original information word by inverting the first @xmath11 bits of the @xmath10-bit information word again .",
    "knuth s method was later improved or modified by many researchers @xcite .",
    "based on balanced codes , we have a scheme of balanced modulation .",
    "it encodes the stored data as balanced codewords ; when reading data from a block , it adjusts the reading threshold dynamically such that the resulting word to read is also balanced ( namely , the number of 1s is equal to the number of 0s ) or approximately balanced . here , we call this dynamic reading threshold as a _ balancing threshold_.    there are several benefits of applying balanced modulation in nonvolatile memories .",
    "first , it increases the _ safety gap _ of @xmath9s and @xmath4s . with a fixed threshold , the _ safety gap _",
    "is determined by the minimum difference between cell levels and the threshold . with balanced modulation ,",
    "the safety gap is the minimum difference between cell levels for @xmath9 and those for @xmath4 .",
    "since the cell level for an individual cell has a random distribution due to the cell - programming noise @xcite , the actual value of the charge level varies from one write to another . in this case ,",
    "balanced modulation is more robust than the commonly used fixed - threshold approach in combating programming noise .",
    "second , as we discussed , balanced modulation can is a very simple solution that minimizes the influence of cell - level drift .",
    "it was shown in @xcite that cell - level drift in flash memories introduces the most dominating errors .",
    "third , balanced modulation can efficiently reduce errors introduced by some other mechanisms , such as the change of external temperatures and the current leakage of other reading lines , which result in the shift of cell levels in a same direction . generally , balanced modulation is a simple approach that minimizes the influence of noise asymmetries , and it can be easily implemented on current memory devices without hardware changes . the balanced condition on codewords enables us to select a much better threshold dynamically than the commonly used fixed threshold when reading data from a block .",
    "the main contributions of the paper are    1 .",
    "we study balanced modulation as a simple , practical and efficient approach to minimize asymmetric component of errors in nonvolatile memories",
    "a new construction of balanced error - correcting codes , called balanced ldpc code , is introduced and analyzed , which has a higher rate than prior constructions .",
    "we investigate partial - balanced modulation , for its simplicity of constructing error - correcting codes , and then we extend our discussions from binary cells to multi - level cells .",
    "in the first part of this paper , including section [ section_bal_balancedscheme ] , section [ section_bal_biterrorrate ] and section [ section_bal_implementation ] , we focus on the introduction and performance of balanced modulation .",
    "in particular , we demonstrate that balanced modulation introduces much less errors than the traditional approach based on fixed thresholds .",
    "for any cell - level distributions , the balancing threshold used in balanced modulation is suboptimal among all the possible reading thresholds , in the term of total number of errors .",
    "it enables balanced modulation to be adaptive to a variety of channels characters , hence , it makes balanced modulation applicable for most types of nonvolatile memories . beyond storage systems , balanced modulation",
    "can also be used in optimal communication , where the strength of received signals shifts due to many factors like the transmitting distance , temperature , etc .",
    "a practical and very attractive aspect of balanced modulation is that it can be easily implemented in the current systems of nonvolatile memories .",
    "the only change is that , instead of using a fixed threshold in reading a binary vector , it allows this threshold to be adaptive .",
    "fortunately , this operation can be implemented physically , making the process of data reading reasonably fast . in this case , the reading process is based on hard decision .",
    "if we care less about reading speed , we can have soft - decision decoding , namely , reading data without using a threshold .",
    "we demonstrate that the prior knowledge that the stored codeword is balanced is very useful .",
    "it helps us to better estimate the current cell - level distributions , hence , resulting in a better performance in bit error rate .",
    "balanced modulation can efficiently reduce bit error rate when reading data from a block .",
    "a further question is how to construct balanced codes that are capable of correcting errors .",
    "we call such codes _ balanced error - correcting codes_. knuth s method can not correct errors . in @xcite ,",
    "van tilborg and blaum presented a family of balanced binary error - correcting codes .",
    "the idea is to consider balanced blocks as symbols over an alphabet and to construct error - correcting codes over that alphabet by concatenating @xmath13 blocks of length @xmath14 each . due to the constraint in the code construction",
    ", this method achieves only moderate rates .",
    "error - correcting balanced codes with higher rates were presented by al - bassam and bose in @xcite , however , their construction considers only the case that the number of errors is at most @xmath15 . in @xcite , mazumdar ,",
    "roth , and vontobel studied linear balancing sets , namely , balancing sets that are linear subspaces @xmath16 , which are applied in obtaining coding schemes that combine balancing and error correction .",
    "recently , weber , immink and ferreira extent knuth s method to let it equipped with error - correcting capabilities @xcite .",
    "their idea is to assign different error protection levels to the prefix and modified information word in knuth s construction .",
    "so their construction is a concatenation of two error - correct codes with different error correcting capabilities . in section [ section_bal_ldpc ]",
    ", we introduce a new construction of balanced error - correcting codes , which is based on ldpc code , so called balanced ldpc code .",
    "such a construction has a simple encoding algorithm and its decoding complexity based on message - passing algorithm is asymptotically equal to the decoding complexity of the original ( unbalanced ) ldpc code .",
    "we demonstrate that balanced ldpc code has error - correcting capability very close to the original ( unbalanced ) ldpc code .",
    "our observation is that the task of constructing efficient balanced error - correcting codes with simple encoding and decoding algorithms is not simple , but it is much easier to construct error - correcting codes that are partially balanced , namely , only a certain segment ( or subsequence ) of each codeword is balanced . motivated by this observation , we propose a variant of balanced modulation , called partial - balanced modulation . when reading from a block , it adjusts the reading threshold such that the segment of the resulting word is balanced .",
    "partial - balanced modulation has a performance very close to that of balanced modulation , and it has much simpler constructions of error - correcting codes than balanced modulation . another question that we address in the third part is how to extend the scheme of balanced modulation or partial - balanced modulation to be used in nonvolatile memories with multi - level cells .",
    "details will be provided in section [ section_bal_variant ] and section [ section_bal_multicell ] .",
    "for convenience , we consider different types of nonvolatile memories in the same framework where data is represented by cell levels , such as voltages in flash memories and resistance in phase - change memories .",
    "the scheme of balanced modulation is sketched in fig .",
    "[ fig_balancedmodulation ] .",
    "it can be divided into two steps : programming step and reading step .",
    "\\(1 ) in the programming step , we encode data based a balanced ( error - correcting ) code .",
    "let @xmath10 denote the dimension of the code and @xmath13 denote the number of cells in a block , then given a message @xmath17 , it is mapped to a balanced codeword @xmath18 such that @xmath19 where @xmath20 is the hamming weight of @xmath21 .",
    "\\(2 ) in the reading step , we let @xmath22 be the current levels of the @xmath13 cells to read .",
    "a balancing threshold @xmath0 is determined based on @xmath23 such that the resulting word , denoted by @xmath24 , is also balanced , namely , @xmath25 . for each @xmath26 , @xmath27 if and only if @xmath28 , otherwise @xmath29 .",
    "by applying the decoder of the balanced ( error - correcting ) code , we get a binary output @xmath30 , which is the message that we read from the block .     and",
    "@xmath4 , and the reading threshold.,width=345 ]    let us intuitively understanding the function of balanced modulation based on the demonstration of fig .",
    "[ fig_balancingthreshold ] , which depicts the cell - level distributions for those cells that store @xmath4 or @xmath9 . given a reading threshold @xmath0 ,",
    "we use @xmath31 denote the number of @xmath1 errors and use @xmath32 denote the number of @xmath2 errors , as the tails marked in the figure .",
    "then @xmath33 @xmath34    we are ready to see @xmath35 where @xmath20 is the hamming weight of @xmath21 .",
    "according to the definition , a balancing threshold is the one that makes @xmath36 being balanced , hence , @xmath37 i.e. , a balancing threshold results in the same number of @xmath1 errors and @xmath2 errors .",
    "we define @xmath38 as the total number of errors based on a reading threshold @xmath0 , then @xmath39 if the cell - level distributions for those cells that store",
    "@xmath9 and those cells that store @xmath4 are known , then the balancing threshold may not be the best reading threshold that we can have , i.e. , @xmath38 may not be minimized based on the balancing threshold .",
    "let @xmath40 denote the balancing threshold , as a comparison , we can have an optimal threshold @xmath41 , which is defined by @xmath42 unfortunately , it is almost impossible for us to know the cell - level distributions for those cells that store @xmath9 and those cells that store @xmath4 without knowing the original word @xmath21 . from this sense , the optimal threshold @xmath41 is imaginary .",
    "although we are not able to determine @xmath41 , the following result shows that the balancing threshold @xmath40 has performance comparable to that of @xmath41 . even in the worst case ,",
    "the number of errors introduced based on @xmath40 is at most two times that introduced by @xmath41 , implying the suboptimality of the balancing threshold @xmath40 .    given any balanced codeword @xmath18 and cell - level vector @xmath43 , we have @xmath44    given the balancing threshold @xmath40 , the number of @xmath2 errors equals the number of @xmath1 errors , hence , the total number of errors is @xmath45    if @xmath46 , the number of @xmath1 errors @xmath47 .",
    "therefore , @xmath48    similarly , if @xmath49 , by considering only @xmath2 errors , we get the same conclusion .",
    "now we compare the balancing threshold @xmath40 with a fixed threshold , denoted by @xmath50 .",
    "as shown in fig .",
    "[ fig_balancingthreshold ] , if we set the reading threshold as fixed @xmath51 , then it will introduce much more errors then the balancing threshold .",
    "given a fixed threshold @xmath50 , after a long duration , we can characterize the storage channel as a binary asymmetric channel , as shown in fig .",
    "[ fig_channelchange](a ) , where @xmath52 .",
    "balanced modulation is actually a process of modifying the channel to make it being symmetric . as a result ,",
    "balanced modulation results in a binary symmetric channel with crossover probability @xmath12 such that @xmath53 .",
    "when @xmath54 , it has @xmath55 . in this case",
    ", the bit error rate is reduced from @xmath56 to @xmath12 , where @xmath57 .     into a binary symmetric channel with @xmath53.,width=345 ]",
    "to better understand different types of reading thresholds as well as their performances , we study them from the expectation ( statistical ) perspective .",
    "assume that we write @xmath13 bits ( including @xmath10 ones ) into a block at time @xmath4 , let @xmath58 denote the probability density function ( p.d.f . ) of the cell level at time @xmath8 that stores a bit @xmath4 , and let @xmath59 denote the p.d.f . of the cell level at time @xmath8 that stores @xmath9 .",
    "then at time @xmath8 , the bit error rate of the block based on a reading threshold @xmath0 is given by @xmath60    according to our definition , a balancing threshold @xmath40 is chosen such that @xmath61 , i.e. , the number of @xmath1 errors is equal to the number of @xmath2 errors .",
    "as the block length @xmath13 becomes sufficiently large , we can approximate @xmath62 as @xmath63 and approximate @xmath64 as @xmath65 .",
    "so when @xmath13 is large , we approximately have @xmath66    differently , an optimal reading threshold @xmath41 is the one that minimizes the total number of errors .",
    "when @xmath13 is large , we approximately have @xmath67 when @xmath58 and @xmath59 are continuous functions , the solutions of @xmath41 are @xmath68 that means @xmath41 is one of the intersections of @xmath58 and @xmath59 or one of the infinity points .    generally , @xmath58 and @xmath59 are various for different nonvolatile memories and different blocks , and they have different dynamics over time .",
    "it is not easy to find a perfect model to characterize @xmath58 and @xmath59 , but there are two trends about them in timescale .",
    "the change of a cell level can be treated as a superposition of these two trends .",
    "first , due to cell - level drift , the difference between the means of @xmath58 and @xmath59 becomes smaller .",
    "second , due to the existence of different types of noise and disturbance , their variances increases over time . to study the performance of balanced modulation",
    ", we consider both of the effects separately in some simple scenarios .",
    "let @xmath69 and @xmath70 , as illustrated in fig .",
    "[ fig_balancedexample1 ] .",
    "we assume that the fixed threshold is @xmath51 , which satisfies @xmath71 .     and",
    "@xmath70.,width=345 ]    in the above example , the cell - level distribution corresponding to bit ` 1 ' drifts but its variance does not change .",
    "we have @xmath72    at time @xmath8 , the bit error rate based on a reading threshold @xmath0 is @xmath73 where @xmath74 .    , under the first model with @xmath69 and @xmath70.,width=345 ]    for different selections of reading thresholds , @xmath75 is plotted in fig .",
    "[ fig_errorprobability2 ] .",
    "it shows that the balancing threshold and the optimal threshold have the same performance , which is much better than the performance of a fixed threshold .",
    "when cell levels drift , balanced modulation can significantly reduce the bit error rate of a block .",
    "let @xmath69 and @xmath76 , as illustrated in fig .",
    "[ fig_balancedexample2 ] .",
    "we assume that the fixed threshold is @xmath51 , which satisfies @xmath71 .     and @xmath76.,width=345 ]    in this example , the variance of the cell - level distribution corresponding to bit ` 1 ' increases as the time @xmath8 increases .",
    "we have @xmath77    at time @xmath8 , the bit error rate based on a threshold @xmath0 is @xmath78 which is plotted in fig .",
    "[ fig_errorprobability1 ] for different thresholds .",
    "it shows that balancing thresholds introduce much less errors than fixed thresholds when bit ` 1 ' and ` 0 ' have different reliability ( reflected by their variances ) , although they introduce slightly more errors than optimal thresholds .",
    ", under the second model with @xmath69 and @xmath76.,width=345 ]    in practice , the cell - level distributions at a time @xmath8 are much more complex than the simple gaussian distributions , and the errors introduced are due to many complex mechanisms .",
    "however , the above analysis based two simple models are still useful , because they reflect the trends of the cell level changes , which is helpful for analyzing the time - dependent errors in nonvolatile memories .",
    "balanced modulation can be easily implemented on the current architecture of nonvolatile memories .",
    "the process described in the previous sections can be treated as a hard decision approach , where a reading threshold is selected to separate all the cell levels as zeros and ones . in this section ,",
    "we discuss a few methods of determining balancing thresholds quickly , as well as their implementations in nonvolatile memories .",
    "furthermore , we discuss soft decision implementation of balanced modulation , namely , we do not read data based on a reading threshold , and the decoder can get access into all the cell levels ( cell - level vector @xmath23 ) directly . in this case , we want to know how the prior information that the stored codeword is balanced can help us to increase the success rate of decoding .      given",
    "a block of @xmath13 cells , assume their current levels are @xmath79 .",
    "our problem is to determine a threshold @xmath40 such that there are @xmath80 cells or approximately @xmath80 cells will be read as ones .",
    "a trivial method is to sort all the @xmath13 cell levels in the decreasing order such that @xmath81",
    ". then @xmath82 is our desired balancing threshold .",
    "the disadvantage of this method is that it needs @xmath83 computational time , which may slow down the reading speed when @xmath13 is large . to reduce the reading time , we hope that the balancing threshold can be controlled by hardware .",
    "half - interval search is a simple approach of determining the balancing threshold .",
    "assume it is known that @xmath40 is @xmath84 $ ] with @xmath85 .",
    "first , we set the reading threshold as @xmath86 , based on which a simple circuit can quickly detect the number of ones in the resulting word , denoted by @xmath10 . if @xmath87 , we reset the interval @xmath88 $ ] as @xmath89 $ ] . if @xmath90 , we reset the interval @xmath88 $ ] as @xmath91 $ ] .",
    "then we repeat this procedure until we get a reading threshold such that @xmath92 or @xmath93 for a reading precision @xmath94 .",
    "half - interval search is an iterative approach of determining the balancing threshold such that the resulting word is well balanced . to further reduce the reading time",
    ", we can relax the constraint on the weight of the resulting word , namely , we can let the number of ones in the resulting word be approximately @xmath80 , instead of accurately @xmath80 .    for instance",
    ", we can simply set the balancing threshold as @xmath95 obviously , such @xmath40 reflects the cell - level drift and it can be easily implemented by a simple circuit .    more precisely , we can treat @xmath96 as the first - order approximation , in this way , we write @xmath40 as @xmath97 where @xmath98 is a constant depending on the noise model of memory devices .",
    "reading data based on hard decision is preferred in nonvolatile memories , regarding to its advantages in reading speed and computational complexity compared to soft decision decoding . however , in some occasions , soft decision decoding is still useful for increasing the decoding success rate .",
    "we demonstrate that the prior knowledge that the stored codewords are balanced can help us to better estimate the cell - level probability distributions for @xmath4 or @xmath9 .",
    "hence , it leads to a better soft decoding performance .",
    "we assume that given a stored bit , either @xmath4 or @xmath9 , its cell level is gaussian distributed .",
    "( we may also use some other distribution models according to the physical properties of memory devices , and our goal is to have a better estimation of model parameters ) .",
    "specifically , we assume that the cell - level probability distribution for @xmath4 is @xmath99 and the cell - level probability distribution for @xmath9 is @xmath100 . since the codewords are balanced , the probability for a cell being @xmath4 or @xmath9 is equal .",
    "so we can describe cell levels by a gaussian mixture model .",
    "our goal is to find the maximum likelihood @xmath101 based on the cell - level vector @xmath23 , namely , the parameters that maximize @xmath102    expectation - maximization ( em ) algorithm is an iterative method that can easily find the maximum likelihood @xmath101 .",
    "the em iteration alternates between performing an expectation ( e ) step and a maximization ( m ) step .",
    "let @xmath103 be the codeword stored in the current block , and let @xmath104 $ ] be the estimation of the parameters in the @xmath8th iteration",
    ". in the e - step , it computes the probability for each cell being @xmath4 or @xmath9 based on the current estimation of the parameters , namely , for all @xmath26 , it computes @xmath105 in the m - step , it computes parameters maximizing the likelihood with given the probabilities obtained in the e - step .",
    "specifically , for @xmath106 , @xmath107 @xmath108 these estimations of parameters are then used to determine the distribution of @xmath109 in the next e - step .",
    "assume @xmath110 are the maximum - likelihood parameters , based on which we can calculate the log - likelihood for each variable @xmath109 , that is @xmath111 where @xmath112 is the probability density function .",
    "based on the log - likelihood of each variable @xmath109 , some soft decoding algorithms can be applied to read data , including message - passing algorithms @xcite , linear programming @xcite , etc .",
    "it will be further discussed in the next section for decoding balanced ldpc code .",
    "balanced modulation can significantly reduce the bit error rate of a block in nonvolatile memories , but error correction is still necessary .",
    "so we study the construction of balanced error - correcting codes . in the programming step ,",
    "we encode the information based on a balanced error - correcting code and write it into a block . in the reading step ,",
    "the reading threshold is adjusted such that it yields a balanced word , but probably erroneous .",
    "then we pass this word to the decoder to further retrieve the original information .      in this section ,",
    "we introduce a simple construction of balanced error - correcting codes , which is based on ldpc codes , called _ balanced ldpc code_. ldpc codes , first introduced by gallager @xcite in 1962 and rediscovered in 1990s , achieve near shannon - bound performances and allow reasonable decoding complexities .",
    "our construction of balanced ldpc code is obtained by inverting the first @xmath11 bits of each codeword in a ldpc code such that the codeword is balanced , where @xmath11 is different for different codewords .",
    "it is based on knuth s observation @xcite , that is , given an arbitrary binary word of length @xmath10 with @xmath10 even , one can always find an integer @xmath11 with @xmath113 such that by inverting the first @xmath11 bits the word becomes balanced .",
    "different from the current construction in @xcite , where @xmath11 is stored and protected by a lower - rate balanced error - correcting codes ( the misdecoding of @xmath11 may lead to catastrophic error propagation in the information word ) , we do not store @xmath11 in our construction .",
    "the main idea is that certain redundancy exists in the codewords of ldpc codes that enables us to locate @xmath11 or at last find a small set that includes @xmath11 with a very high probability , even some errors exist in the codewords .",
    "it is wasteful to store the value of @xmath11 with a lower - rate balanced error - correcting code . as a result ,",
    "our construction is more efficient than the recent construction proposed in @xcite .",
    "let @xmath114 be the message to encode and its length is @xmath10 , according to the description above , the encoding procedure consists of two steps , as shown in fig .",
    "[ fig_balanceencoding ] :    1 .   apply an @xmath115 ldpc code @xmath116 to encode the message @xmath114 into a codeword of length @xmath13 , denoted by @xmath117 , where @xmath118 is the generator matrix of @xmath116 .",
    "2 .   find the minimal integer @xmath11 in @xmath119 such that inverting the first @xmath11 bits of @xmath120 results in a balanced word @xmath121 where @xmath122 denotes a run of @xmath11 bits @xmath123 and @xmath124 bits @xmath125 .",
    "then we denote @xmath21 as @xmath126 .",
    "this word @xmath21 is a codeword of the resulting balanced ldpc code , denoted by @xmath127 .",
    "we see that a balanced ldpc code is constructed by simply balancing the codewords of a ldpc code , which is called the original ldpc code .",
    "based on the procedure above we can encode any message @xmath114 of length @xmath10 into a balanced codeword @xmath21 of length @xmath13 .",
    "the encoding procedure is very simple , but how to decode a received word ?",
    "now , we focus on the decoding of this balanced ldpc code .",
    "let @xmath36 be an erroneous word received by the decoder , then the output of the maximum likelihood decoder is @xmath128 where @xmath129 is the distance between @xmath36 and @xmath21 depending on the channel , for instance , hamming distance for binary symmetric channels .",
    "the balanced code @xmath127 is not a linear code , so the constraint @xmath130 is not easy to deal with .",
    "a simpler way is to think about the codeword @xmath131 that corresponds to @xmath21 . by inverting the first @xmath132 bits of @xmath36 with @xmath133",
    ", we can get a set of words @xmath134 of size @xmath13 , namely , @xmath135 in which @xmath136 for all @xmath137 .",
    "then there exists an @xmath138 such that @xmath139 the output of the maximum likelihood decoder is @xmath140 subject to @xmath141 is the minimum integer that makes @xmath142 being balanced .",
    "if we ignore the constraint that @xmath11 has to be the minimum integer , then the output of the decoder is the codeword in @xmath116 that has the minimum distance to @xmath143 .",
    "[ fig_demonstration ] provides a simple demonstration , where the solid circles are for the codewords of the lpdc code @xmath116 , the triangles are for the words in @xmath134 that are connected by lines .",
    "our goal is to find the solid circle that is the closest one to the set of triangles .",
    "it is different from traditional decoding of linear codes whose goal is to find the closest codeword to a single point .",
    "ldpc codes achieve near shannon bound performances .",
    "a natural question is whether balanced ldpc codes hold this property .",
    "certain difficulties exist in proving it by following the method in @xcite ( section 2 and section 3 ) , since balanced ldpc codes are not linear codes and the distance distributions of balanced ldpc codes are not easy to characterize .",
    "fortunately , this statement looks correct because if the first @xmath11 bits of a codeword have been inverted ( we assume that the interger @xmath11 is unknown ) , then the codeword can be recovered with only little cost , i.e. , a very small number of additional redundant bits .",
    "let us consider the ensemble of an @xmath144 parity - check matrix given by gallager @xcite , which has @xmath98 ones in each column , @xmath145 ones in each row , and zeros elsewhere .",
    "according to this construction , the matrix is divided into @xmath98 submatrices , each containing a single @xmath9 in each column .",
    "all the submatrices are random column permutations of a matrix that has a single one in each column and @xmath145 ones in each row . as a result",
    ", we have @xmath144 ldpc codes .    given a codeword @xmath120 of an @xmath144 ldpc code",
    ", we get @xmath146 by inverting the first @xmath11 bits of @xmath120 with @xmath147 .",
    "let @xmath148 be the error probability that @xmath120 can not be correctly recovered from @xmath21 if @xmath11 is unknown . as @xmath149 , @xmath150 for any integers @xmath98 and @xmath145 .",
    "let @xmath151 be the parity - check matrix of the ldpc code , and let @xmath152 for all @xmath153 .",
    "we can recover @xmath120 from @xmath21 if and only if @xmath154 for all @xmath155 and @xmath156 .",
    "hence , @xmath157 @xmath158    let us first consider the case of @xmath159 .",
    "we have @xmath160 if and only if @xmath161 where @xmath162 so @xmath160 is equivalent to @xmath163    as we described , @xmath151 is constructed by @xmath98 submatrices , namely , we can write @xmath151 as @xmath164    let @xmath165 be one of the @xmath98 submatrices of @xmath151 , then @xmath151 contains a single one in each columns and @xmath145 ones in each row . and",
    "it satisfies @xmath166 i.e. , in each row of @xmath165 , there are even number of ones from the @xmath167th column to the @xmath132th column .",
    "according to the construction of @xmath144 ldpc codes , @xmath168 so we can use @xmath169 to denote @xmath170 .",
    "first , we consider the case that @xmath145 is even . in this case , @xmath171 hence , without loss of generality , we can assume that @xmath172 .",
    "it is easy to see that @xmath173 only if @xmath174 is even .",
    "assume that the one in the first column of @xmath165 is in the @xmath8th row , and let @xmath175 be the number of ones in the @xmath8th row from the first @xmath176 columns .",
    "then we can get @xmath177 @xmath178 where @xmath179 if @xmath180 or @xmath181 .    if @xmath182 , then @xmath183 .",
    "if @xmath184 , then @xmath185 iteratively , we can prove that @xmath186    similar as above , when @xmath187 , we can get @xmath188    finally , we have @xmath189    so if @xmath145 is even , as @xmath149 , @xmath190",
    ".    if @xmath145 is odd , in each row , there exists at least one @xmath9 in the last @xmath191 elements . as a result ,",
    "@xmath192 . using a same idea as above",
    ", we can also prove that as @xmath149 , @xmath193 .",
    "so the statement in the theorem is true for any rate @xmath194 .",
    "this completes the proof .",
    "the above theorem considers an extreme case that if the codeword of a balanced ldpc code does not have errors , then we can recover the original message with little cost of redundancy .",
    "it implies that balanced ldpc codes may achieve almost the same rates as the original unbalanced ldpc codes . in the following subsections ,",
    "we discuss some decoding techniques for binary erasure channels and binary symmetric channels .",
    "simulation results on these channels support the above statement .      in this subsection",
    ", we consider binary erasure channels ( bec ) , where a bit ( @xmath4 or @xmath9 ) is either successfully received or it is deleted , denoted by  @xmath195 \" .",
    "let @xmath196 be a word received by a decoder after transmitting a codeword @xmath197 over a bec .",
    "then the key of decoding @xmath36 is to determine the value of the integer @xmath11 such that @xmath21 can be obtained by inverting the first @xmath11 bits of a codeword in @xmath116 .",
    "a simple idea is to search all the possible values of @xmath11 , i.e. , we decode all the possible words @xmath198 separately and select the best resulting codeword that satisfies all the constraints as the final output . this idea is straightforward , but the computational complexity of the decoding increases by a factor of @xmath13 , which is not acceptable for most practical applications .",
    "our observation is that we might be able to determine the value of @xmath11 or at least find a feasible set that includes @xmath11 , based on the unerased bits in @xmath36 .",
    "for example , given @xmath199 , assume that one parity - check constraint is @xmath200 if all @xmath201 are observed ( not erased ) , then we can have the following statement about @xmath11 :    \\(1 ) if @xmath202 , then @xmath203.\\ ] ]    \\(2 ) if @xmath204 , then @xmath205        by combining this observation with the message - passing algorithm , we get a decoding algorithm for balanced ldpc codes under bec .",
    "similar as the original ldpc code , we present a balanced ldpc code as a sparse bipartite graph with @xmath13 variable nodes and @xmath206 check nodes , as shown in fig .",
    "[ fig_decodinggraph ] . additionally , we add an inversion node for representing the value or the feasible set of @xmath11 .",
    "let us describe a modified message - passing algorithm on this graph . in each round of the algorithm ,",
    "messages are passed from variable nodes and inversion nodes to check nodes , and then from check nodes back to variable nodes and inversion nodes .",
    "we use @xmath207 denote the feasible set consisting of all possible values for the integer @xmath11 , called inversion set . at the first round , we initialize the @xmath132th variable node @xmath208 and initialize the inversion set as @xmath209 $ ]",
    ". then we pass message and update the graph iteratively . in each round",
    ", we do the following operations .",
    "\\(1 ) for each variable node @xmath0 , if its value @xmath210 is in @xmath211 , it sends @xmath210 to all its check neighbors . if @xmath212 and any incoming message @xmath175 is @xmath4 or @xmath9 , it updates @xmath210 as @xmath175 and sends @xmath175 to all its check neighbors .",
    "if @xmath212 and all the incoming messages are @xmath195 , it sends @xmath195 to all its check neighbors .",
    "\\(2 ) for each check node @xmath23 , assume the messages from its variable neighbors are @xmath213 , where @xmath214 are the indices of these variable nodes s.t .",
    "then we define @xmath216 @xmath217 if all the incoming messages are in @xmath211 , then we update @xmath207 in the following way : if @xmath218 , we update @xmath207 as @xmath219 ; otherwise , we update @xmath207 as @xmath220 . in this case , this check node @xmath23 is no longer useful , so we can remove this check node from the graph .",
    "\\(3 ) for each check node @xmath23 , if there are exactly one incoming message from its variable neighbor which is @xmath221 and all other incoming messages are in @xmath211 , we check whether @xmath222 or @xmath223 . if @xmath224 , then the check node sends the xor of the other incoming messages except @xmath195 to @xmath225 .",
    "if @xmath226 , then the check node sends the xor of the other incoming messages except @xmath195 plus one to @xmath225 . in this case",
    ", the check node @xmath23 is also no longer useful , so we can remove this check node from the graph .",
    "the procedure above continues until all erasures are filled in , or no erasures are filled in the current iteration .",
    "different from the message - passing decoding algorithm for ldpc codes , where in each iteration both variable nodes and check nodes are processed only once , here , we process variable nodes once but check nodes twice in each iteration . if all erasures are filled in , @xmath21 is the binary vector labeled on the variable nodes . in this case",
    ", if @xmath227 , then @xmath11 is the only element in @xmath207 , and we can get @xmath131 by calculating @xmath228    if there are still some unknown erasures , we enumerate all the possible values in @xmath207 for the integer @xmath11 .",
    "usually , @xmath229 is small . for a specific @xmath11",
    ", it leads to a feasible solution @xmath120 if    \\(1 ) given @xmath230 , with the message - passing procedure above , all the erasures can be filled in .",
    "\\(2 ) @xmath21 is balanced , namely , the numbers of ones and zeros are equal for the variable nodes .",
    "\\(3 ) let @xmath231 .",
    "then @xmath11 is the minimal integer in @xmath232 subject to @xmath233 is balanced .",
    "we say that a word @xmath36 with erasures is uniquely decodable if and only if there exists @xmath234 that leads to a feasible solution , and for all such integers @xmath11 they result in the unique solution @xmath131 .",
    "the following simple example is provided for the purpose of demonstrating the decoding process .",
    "based on fig .",
    "[ fig_decodinggraph ] , we have a codeword @xmath235 , which is transmitted over an erasure channel .",
    "we assume that the received word is @xmath236 .    in the first round of the decoding",
    ", we have @xmath237.\\ ] ]    considering the @xmath238nd check node , we can update @xmath207 as @xmath239    considering the @xmath240nd check node , we can continue updating @xmath207 as @xmath241    based on ( 3 ) , we can fill @xmath242 for the @xmath243th and @xmath244th variable nodes .",
    "finally , we get @xmath245 and @xmath246 .",
    "after iterations in the message - passing algorithm for decoding balanced ldpc codes.,width=364 ]    regarding to the decoding algorithm described above , there are two important issues that need to consider , including the decoding complexity of the algorithm and its performance .",
    "first , the decoding complexity of the algorithm strongly depends on the size of @xmath207 when it finishes iterations .",
    "[ fig_inversionset ] simulates the average size of the inversion set @xmath207 for decoding three balanced ldpc codes .",
    "it shows that when the crossover probability is lower than a threshold , the size of @xmath207 is smaller than a constant with a very high probability . in this case",
    ", the decoding complexity of the balanced ldpc code is very close to the decoding complexity of the original unbalanced ldpc code .",
    ".,width=364 ]    another issue is about the performance of the decoding algorithm for balanced ldpc codes . in particular , we want to figure out the cost of additional redundancy in correcting the inversion of the first @xmath11 bits when @xmath11 is unknown . in fig .",
    "[ fig_erasure_error ] , it presents the word error rate of balanced ldpc codes and the corresponding original unbalanced ldpc codes for different block lengths .",
    "it is interesting to see that as the block length increases , the balanced ldpc codes and the original unbalanced ldpc codes have almost the same performance , that is , the cost of correcting the inversion of the first @xmath11 bits is ignorable .      in this subsection , we study and analyze the decoding of balanced ldpc codes for symmetric channels , including binary symmetric channels ( bsc ) and awgn ( additive white gaussian noise ) channels .",
    "different from binary erasure channels ( bec ) , here we are not able to determine a small set that definitely includes the integer @xmath11",
    ". instead , we want to figure out the most possible values for @xmath11 . before presenting our decoding algorithm ,",
    "we first introduce belief propagation algorithm for decoding ldpc codes .",
    "belief propagation @xcite , where messages are passed iteratively across a factor graph , has been widely studied and recommended for the decoding of ldpc codes . in each iteration , each variable node passes messages ( probabilities ) to all the adjacent check nodes and then each check node passes messages ( beliefs ) to all the adjacent variable nodes .",
    "specifically , let @xmath247 be the message passed from a variable node @xmath0 to a check node @xmath23 at the @xmath248th round of the algorithm , and let @xmath249 be the message from a check node @xmath23 to a variable node @xmath0 .",
    "at the first round , @xmath250 is the log - likelihood of the node @xmath0 conditioned on its observed value , i.e. , @xmath251 for variable @xmath252 and its observation @xmath253 .",
    "this value is denoted by @xmath254",
    ". then the iterative update procedures can be described by the following equations @xmath255 @xmath256 where @xmath257 is the set of check nodes that connect to variable node @xmath0 and @xmath258 is the set of variable nodes that connect to check node @xmath23 . in practice",
    ", the belief - propagation algorithm stops after a certain number of iterations or until the passed likelihoods are close to certainty .",
    "typically , for a bsc with crossover probability @xmath12 , the log - likelihood @xmath259 for each variable node @xmath0 is a constant depending on @xmath12 .",
    "let @xmath252 be the variable on @xmath0 and let @xmath253 be its observation , then @xmath260    let us consider the decoding of balanced ldpc codes .",
    "assume @xmath197 is a codeword of a balanced ldpc code , obtained by inverting the first @xmath11 bits of a codeword @xmath120 in a ldpc code @xmath116 .",
    "the erroneous word received by the decoder is @xmath261 for an alphabet @xmath262 .",
    "for example , @xmath263 for bsc channels , and @xmath264 for awgn channels . here , we consider a symmetric channel , i.e. , a channel for which there exists a permutation @xmath265 of the output alphabet @xmath262 such that ( 1 ) @xmath266 , and ( 2 ) @xmath267 for all @xmath268 , where @xmath269 is the probability of observing @xmath253 when the input bit is @xmath252 .",
    "the biggest challenge of decoding a received word @xmath261 is lacking of the location information about where the inversion happens , i.e. , the integer @xmath11 .",
    "we let @xmath270 for all @xmath138 . a simple idea is to search all the possibilities for the integer @xmath11 from @xmath4 to @xmath271 , i.e , decoding all the words @xmath272 separately .",
    "assume their decoding outputs based on belief propagation are @xmath273 then the final output of the decoder is @xmath274 such that @xmath275 is maximized .",
    "the drawback of this method is its high computational complexity , which is about @xmath13 times the complexity of decoding the original unbalanced ldpc code . to reduce computational complexity",
    ", we want to estimate the value of @xmath11 in a simpler and faster way , even sacrificing a little bit of performance on bit error rate .",
    "the idea is that when we are using belief propagation to decode a group of words @xmath198 , some information can be used to roughly compare their goodness , namely , their distances to the nearest codewords . to find such information , given each word @xmath276 ( here , we denote it as @xmath36 for simplicity ) , we run belief propagation for @xmath248 rounds ( iterations ) , where @xmath248 is very small , e.g. , @xmath277 .",
    "there are several ways of estimating the goodness of @xmath36 , and we introduce one of them as follows .    given a word @xmath36 , we define @xmath278 where @xmath279 is the set of all the variable nodes , @xmath258 is the set of neighbors of a check node @xmath23 , and @xmath247 is the message passed from a variable node @xmath0 to a check node @xmath23 at the @xmath248th round of the belief - propagation algorithm . roughly , @xmath280 is a measurement of the number of correct parity checks for the current assignment in belief propagation ( after @xmath281 iterations ) .",
    "for instance , @xmath282 for a binary symmetric channel . in this expression",
    ", @xmath283 is a constant , @xmath284 is the number of redundancies , and @xmath285 is the number of ones in @xmath286 , i.e. , the number of unsatisfied parity checks .",
    "generally , the bigger @xmath287 is , the more likely @xmath288 is .",
    "so we can get the most likely @xmath11 by calculating @xmath289 then we decode @xmath290 as the final output .",
    "however , the procedure requires to calculate @xmath287 with @xmath156 .",
    "the following theorem shows that the task of computing all @xmath287 with @xmath156 can be finished in linear time if @xmath248 is a small constant .",
    "the task of computing all @xmath287 with @xmath156 can be finished in linear time if @xmath248 is a small constant .",
    "first , we calculate @xmath291 .",
    "based on the belief - propagation algorithm described above , it can be finished in @xmath292 time . in this step ,",
    "we save all the messages including @xmath254 , @xmath293 , @xmath294 for all @xmath295 and @xmath296 .",
    "when we calculate @xmath297 , the only change on the inputs is @xmath298 , where @xmath6 is the first variable node ( the sign of @xmath298 is flipped ) . as a result , we do not have to calculate all @xmath254 , @xmath293 , @xmath294 for all @xmath295 and @xmath296 .",
    "instead , we only need to update those messages that are related with @xmath298 .",
    "it needs to be noted that the number of messages related to @xmath298 has an exponential dependence on @xmath248 , so the value of @xmath248 should be small . in this case ,",
    "based on the calculation of @xmath299 , @xmath297 can be calculated in a constant time .",
    "similarly , each of @xmath287 with @xmath300 can be obtained iteratively in a constant time .",
    "based on the process above , we can compute all @xmath287 with @xmath156 in @xmath292 time .    to increase the success rate of decoding",
    ", we can also create a set of most likely values for @xmath11 , denoted by @xmath301 .",
    "@xmath302 consists of at most @xmath303 local maximums with the highest values of @xmath304 .",
    "here , we say that @xmath305 is a local maximum if and only if @xmath306 note that @xmath307 , where @xmath308 is the global maximum as defined above .",
    "if @xmath309 , for all @xmath310 , we decode @xmath311 separately and choose the output with the maximum likelihood as the final output of the decoder .",
    "it is easy to see that the the above modified belief - propagation algorithm for balanced ldpc codes has asymptotically the same decoding complexity as the belief - propagation algorithm for ldpc codes , that is , @xmath83 .        in fig .",
    "[ fig_errorword ] , it shows the performance of the above algorithm for decoding balanced ldpc codes under bsc and the performance of belief propagation algorithm for the original ldpc codes .",
    "from which , we see that when @xmath277 and @xmath312 , the performance gap between balanced @xmath313 ldpc code and unbalanced @xmath313 ldpc code is very small .",
    "this comparison implies that the cost of correcting the inversion of the first @xmath11 bits ( when @xmath11 is unknown ) is small for ldpc codes .",
    "let us go back the scheme of balanced modulation .",
    "the following examples give the log - likelihood of each variable node when the reading process is based on hard decision and soft decision , respectively .",
    "based on them , we can apply the modified propagation algorithm in balanced modulation .",
    "if the reading process is based on hard decision , then it results in a binary symmetric channel with crossover probability @xmath12 . in this case , let @xmath253 be the observation on a variable node @xmath0 , the log - likelihood for @xmath0 is @xmath314    if the reading process is based on soft decision , then we can approximate cell - level distributions by gaussian distributions , which are characterized by @xmath15 parameters @xmath110 .",
    "these parameters can be obtained based on the cell - level vector @xmath315 , following the steps in subsection [ subsection_soft ] . in this case , if the input of the decoder is @xmath36 , then the log - likelihood of the @xmath11th variable node @xmath0 is @xmath316 where @xmath317 is the current level of the @xmath11th cell . if the input of the decoder is @xmath276 ( we do nt have to care about its exact value ) , then the log - likelihood of the @xmath11th variable node @xmath0 is @xmath318 for all @xmath147 .",
    "constructing balanced error - correcting codes is more difficult than constructing normal error - correcting codes .",
    "a question is : is it possible to design some schemes that achieve similar performances with balanced modulation and have simple error - correcting code constructions ? with this motivation , we propose a variant of balanced modulation , called partial - balanced modulation .",
    "the main idea is to construct an error - correcting code whose codewords are partially balanced , namely , only a certain segment of each codeword is balanced .",
    "when reading information from a block , we adjust the reading threshold to make this segment of the resulting word being balanced or being approximately balanced .",
    "one way of constructing partial - balanced error - correcting codes is shown in fig .",
    "[ fig_particalbalance ] . given an information vector @xmath114 of @xmath10 bits (",
    "@xmath10 is even ) , according to knuth s observation @xcite , there exists an integer @xmath11 with @xmath319 such that inverting the first @xmath11 bits of @xmath114 results in a balanced word @xmath320 .",
    "since our goal is to construct a codeword that is partially balanced , it is not necessary to present @xmath11 in a balanced form .",
    "now , we use @xmath321 denote the binary representation of length @xmath322 for @xmath11 . to further correct potential errors , we consider @xmath323 $ ] as the information part and add extra parity - check bits by applying a systematic error - correcting code , like bch code , reed - solomon code , etc . as a result",
    ", we obtain a codeword @xmath324 $ ] where @xmath325 is the redundancy part . in this codeword",
    ", @xmath320 is balanced , @xmath326 $ ] is not balanced .    note that in most data - storage applications , the bit error rate of a block is usually very small .",
    "the application of modulation schemes can further reduce the bit error rate .",
    "hence , the number of errors in real applications is usually much smaller than the block length . in this case",
    ", the total length of @xmath326 $ ] is smaller or much smaller than the code dimension @xmath10 .",
    "as the block length @xmath13 becomes large , like one thousand , the reading threshold determined by partial - balanced modulation is almost the same as the one determined by balanced modulation .",
    "one assumption that we made is that all the cells in the same block have similar noise properties . to make this assumption being sound",
    ", we can reorder the bits in @xmath324 $ ] such that the @xmath10 cells of storing @xmath320 is ( approximately ) randomly distributed among all the @xmath13 cells .",
    "compared to balanced modulation , partial - balanced modulation can achieve almost the same performance , and its code construction is much easier ( the constraints on the codewords are relaxed ) . in the following two examples ,",
    "it compares the partial - balanced modulation scheme with the traditional one based on a fixed threshold .",
    "let us consider a nonvolatile memory with block length @xmath327 . to guarantee the data reliability",
    ", each block has to correct @xmath328 errors if the reading process is based on a fixed reading threshold .",
    "assume @xmath329 primitive bch code is applied for correcting errors , then the data rate ( defined by the ratio between the number of available information bits and the block length ) is @xmath330    for the block discussed in the previous example , we assume that it only needs to correct @xmath244 errors based on partial - balanced modulation . in this case , we can apply @xmath331 primitive bch code for correcting errors , and the data rate is @xmath332 which is much higher than the one obtained in the previous example .",
    "the reading / decoding process of partial - balanced modulation is straightforward .",
    "first , the reading threshold @xmath40 is adjusted such that among the cells corresponding to @xmath114 there are @xmath333 cells or approximately @xmath333 cells with higher levels than @xmath40 .",
    "based on this reading threshold @xmath40 , the whole block is read as a binary word @xmath36 , which can be further decoded as @xmath323 $ ] if the total number of errors is well bounded .",
    "then we obtain the original message @xmath114 by inverting the first @xmath11 bits of @xmath320 .",
    "in order to maximize the storage capacity of nonvolatile memories , multi - level cells ( mlcs ) are used , where a cell of @xmath334 discrete levels can store @xmath335 bits @xcite .",
    "flash memories with 4 and 8 levels have been used in products , and mlcs with @xmath336 levels have been demonstrated in prototypes",
    ". for pcms , cells with @xmath15 or more levels have been in development .",
    "the idea of balanced modulation and partial - balanced modulation can be extended to multi - level cells .",
    "for instance , if each cell has @xmath15 levels , we can construct a balanced code in which each codeword has the same number of @xmath4s , @xmath9s , @xmath238s , and @xmath240s .",
    "when reading data from the block , we adjust three reading thresholds such that the resulting word also has the same number of @xmath4s , @xmath9s , @xmath238s , and @xmath240s .",
    "the key question is how to construct balanced codes or partial - balanced codes for an alphabet size @xmath337 .",
    "a simple approach of constructing balanced codes for a nonbinary case is to consider the message as the rank of its codeword among all its permutations , based on the lexicography order .",
    "if the message is @xmath338 , then the codeword length @xmath13 is the minimum integer such that @xmath339 and @xmath340 the following examples are provided for demonstrating the encoding and decoding processes .",
    "assume the message is @xmath341 of length @xmath342 and @xmath343 .",
    "since @xmath344 , we can convert @xmath114 to a balanced word @xmath21 of length @xmath345 and alphabet size @xmath343 .",
    "let @xmath346 denote the set that consists of all the balanced words of length @xmath345 and alphabet size @xmath343 . to map @xmath114 into a word in @xmath346",
    ", we write @xmath114 into the decimal form @xmath347 and let @xmath206 be the rank of @xmath21 in @xmath346 based on the lexicographical order .",
    "let us consider the first symbol of @xmath21 . in @xmath346 , there are totally @xmath348 sequences starting with @xmath4 , or @xmath9 , or @xmath238",
    ". since @xmath349 , the first symbol in @xmath21 would be @xmath9 , then we update @xmath206 as @xmath350 , which is the rank of @xmath21 among all the sequences starting with @xmath9 .",
    "let us consider the second symbol of @xmath21 .",
    "there are totally @xmath351 sequences starting with @xmath342 , and it is larger than @xmath206 , so the second symbol of @xmath21 is @xmath4 .    repeating this process , we can convert @xmath114 into a balanced word @xmath352 .",
    "we use the same notations as the above example . given @xmath352 , it is easy to calculate its rank in @xmath346 based on the lexicographical order ( via enumerative source coding @xcite )",
    ". it is @xmath353 where @xmath354 is the number of @xmath21 s permutations starting with @xmath4 , @xmath355 is the number of @xmath356 permutations starting with @xmath357 , ...    then from @xmath206 , we can get its binary representation @xmath341 . in @xcite , ryabko and",
    "matchikina showed that if the length of @xmath21 is @xmath13 , then we can get the message @xmath114 in @xmath358 time .",
    "the above approach is simple and information efficient , but the encoding is not computationally fast .",
    "an alternative approach is to generalize knuth s idea to the nonbinary case due to its operational simplicity .",
    "generally , assume that we are provided a word @xmath359 with @xmath360 and @xmath361 , our goal is to generalize knuth s idea to make @xmath114 being balanced .",
    "let us consider a simple case , @xmath362 . given a word @xmath363 , we let @xmath364 with @xmath365 denote the number of @xmath11s in @xmath114",
    ". to balance all the cell levels , we first balance the total number of @xmath4s and @xmath9s , such that @xmath366 .",
    "it also results in @xmath367 . to do this",
    ", we can treat @xmath4 and @xmath9 as an identical state and treat @xmath238 and @xmath240 as another identical state .",
    "based on knuth s idea , there always exists an integer @xmath11 such that by operating on the first @xmath11 symbols ( @xmath368 , @xmath369 , @xmath370 , @xmath371 ) it yields @xmath366 .",
    "we then consider the subsequence consisting of @xmath4s and @xmath9s , whose length is @xmath372 . by applying knuth s idea",
    ", we can make this subsequence being balanced .",
    "similarly , we can also balance the subsequence consisting of @xmath238s and @xmath240s .",
    "consequently , we convert any word in @xmath373 into a balanced word . in order to decode this word , three additional integers of length at most @xmath374 need to be stored , indicating the locations of having operations .",
    "the following example is constructed for the purpose of demonstrating this procedure .",
    "assume @xmath375 , we convert it into a balanced word with the following steps :    \\(1 ) by operating the first @xmath15 symbols in @xmath114 , it yields @xmath376 , where @xmath377 .",
    "\\(2 ) considering the subsequence of @xmath4s and @xmath9s , i.e. , the underlined part in @xmath378 . by operating the first bit of this subsequence @xmath379 , it yields @xmath380 , where @xmath381 .",
    "\\(3 ) considering the subsequence of @xmath4s and @xmath9s , i.e. , the underlined part in @xmath382 . by operating the first @xmath4 bit of this subsequence @xmath383 , it yields @xmath382 , which is balanced .",
    "to recover @xmath384 from @xmath385 ( the inverse process ) , we need to record the three integers @xmath386 $ ] whose binary lengths are @xmath387 $ ]",
    ".    it can be observed that the procedure above can be easily generalized for any @xmath388 with @xmath389 . if @xmath390 with @xmath391 , then the number of bits to store the integers ( locations ) is @xmath392    for instance , if @xmath393 and @xmath394 , then @xmath395 and it requires @xmath396 bits to represent the locations .",
    "these bits can be stored in @xmath397 cells without balancing .",
    "in fact , the above idea can be generalized for an arbitrary @xmath337 .",
    "for instance , when @xmath343 , given an binary word @xmath398 , there exists an integer @xmath11 such that @xmath399 has exactly @xmath400 @xmath4s or @xmath400 @xmath9s . without loss of generality",
    ", we assume that it has exactly @xmath400 @xmath4s , then we can further balance the subsequence consisting of @xmath9s and @xmath238s . finally , we can get a balanced word with alphabet size @xmath240 .",
    "more generally , we have the following result .    given an alphabet size @xmath401 with two integers @xmath283 and @xmath402 ,",
    "we divide all the levels into @xmath402 groups , denoted by @xmath403 , @xmath404 , ... , @xmath405 .",
    "given any word @xmath406 , there exists an integer @xmath11 such that @xmath407 has exactly @xmath408 symbols in one of the first @xmath409 groups .",
    "let us denote all the groups as @xmath410 .",
    "given a sequence @xmath114 , we use @xmath411 denote the number of symbols in @xmath114 that belong to @xmath412 .",
    "furthermore , we let @xmath413 denote the number of symbols in @xmath414 that belong to @xmath412 .",
    "it is easy to see that @xmath415 for all @xmath416 , where @xmath417 .",
    "we prove that that there exists @xmath418 such that @xmath419 or @xmath420 by contradiction .",
    "assume this statement is not true , then either @xmath421 or @xmath422 for all @xmath423 .",
    "so if @xmath424 , we can get @xmath425 for all @xmath426 iteratively . similarly ,",
    "if @xmath427 , we can get @xmath428 for all @xmath426 iteratively .",
    "both cases contradict with the fact that @xmath429 .",
    "note that the number of symbols in @xmath407 that belong to @xmath412 changes by at most @xmath9 if we increase @xmath11 by one .",
    "so if there exists @xmath418 such that @xmath419 or @xmath420 , there always exists an integer @xmath11 such that @xmath407 has exactly @xmath408 symbols in @xmath412 .",
    "this completes the proof .",
    "based on the above result , given any @xmath334 , we can always split all the levels into two groups and make them being balanced ( the number of symbols belonging to a group is proportional to the number of levels in that group ) .",
    "then we can balance the levels in each group .",
    "iteratively , all the levels will be balanced . in order to recover the original message ,",
    "it requires roughly @xmath430 bits for storing additional information when @xmath400 is large .",
    "if we store this additional information as a prefix using a shorter balanced code , then we get a generalized construction of knuth s code .",
    "if we follow the steps in section [ section_bal_variant ] by further adding parity - check bits , then we get a partial - balanced code with error - correcting capability , based on which we can implement partial - balanced modulation for multiple - level cells .    now ,",
    "if we have a code that uses ` full ' sets of balanced codewords , then the redundancy is @xmath431 bits .",
    "so given an alphabet size @xmath334 , the redundancy of the above method is about @xmath432 times as high as that of codes that uses ` full ' sets of balanced codewords .",
    "for @xmath433 , we list these factors as follows : @xmath434 @xmath435 it shows that as @xmath334 increases , the above method becomes less information efficient . how to construct balanced codes for a nonbinary alphabet in a simple , efficient and computationally fast way is still an open question",
    "it is even more difficult to construct balanced error - correcting codes for nonbinary alphabets .",
    "in this paper , we introduced balanced modulation for reading / writing in nonvolatile memories .",
    "based on the construction of balanced codes or balanced error - correcting codes , balanced modulation can minimize the effect of asymmetric noise , especially those introduced by cell - level drifts .",
    "hence , it can significantly reduce the bit error rate in nonvolatile memories .",
    "compared to the other schemes , balanced modulation is easy to be implemented in the current memory systems and it does not require any assumptions about the cell - level distributions , which makes it very practical .",
    "furthermore , we studied the construction of balanced error - correcting codes , in particular , balanced ldpc codes .",
    "it has very efficient encoding and decoding algorithms , and it is more efficient than prior construction of balanced error - correcting codes .",
    "n. mielke , t. marquart , n. wu , j. kessenich , h. belgal , e. schares , f. trivedi , e. goodness , and l. r. nevill ,  bit error rate in nand flash memories , \" in _ ieee international reliability physics symposium _ , pp .",
    "919 , 2008 ."
  ],
  "abstract_text": [
    "<S> this paper presents a practical writing / reading scheme in nonvolatile memories , called balanced modulation , for minimizing the asymmetric component of errors . </S>",
    "<S> the main idea is to encode data using a balanced error - correcting code . </S>",
    "<S> when reading information from a block , it adjusts the reading threshold such that the resulting word is also balanced or approximately balanced . </S>",
    "<S> balanced modulation has suboptimal performance for any cell - level distribution and it can be easily implemented in the current systems of nonvolatile memories . </S>",
    "<S> furthermore , we studied the construction of balanced error - correcting codes , in particular , balanced ldpc codes . </S>",
    "<S> it has very efficient encoding and decoding algorithms , and it is more efficient than prior construction of balanced error - correcting codes .    </S>",
    "<S> balanced modulation , balanced ldpc codes , dynamic reading thresholds . </S>"
  ]
}