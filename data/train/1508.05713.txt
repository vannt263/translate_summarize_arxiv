{
  "article_text": [
    "_ multilevel data _ consist of units of analysis of different type which are hierarchically clustered . in a strictly nested data structure , the term _ levels _ represents the different types of unit of analysis , i.e.  the various types of grouping ;",
    "in particular , the most detailed level is called the first ( or the lowest ) level .",
    "a meaningful example of multilevel data comes from studies on educational achievement , in which pupils , teachers , classrooms , schools , district , and so on , are clustered one within the other , and they might all be units of analysis , each described by own variables .",
    "hierarchical data often occur also in social sciences : economists and political scientists frequently work with data measured at multiple levels in which individuals are nested in geographic divisions , institutions or groups , and so forth .",
    "furthermore , other particular structures of data can be thought as multilevel : the repeated measurements over time on an individual , the respondents to the same interviewer and also subjects within a particular study among those of a meta - analysis can be considered groups of observations , and , consequently , be treated as multilevel data .",
    "the idea behind modelling multilevel data is that living environments affect individual behaviours , and contextual effects are due to social interactions within an environment .",
    "in general , individuals can influence and be influenced by various type of contexts : spatial , temporal , organizational and socio - economic - cultural . as  @xcite put it ,",
    " the more individuals share common experiences due to closeness in space and/or in time , the more they are similar , or , to a certain extent , duplications of each other \" ; in other words , performances of pupils in the same classroom tend to be more similar than those from a different classroom because of sharing contexts .",
    "this is one of the reasons why the specificity of multilevel data can not be ignored , because the observations within one group are not independent of each other , as traditional models require .",
    "if standard statistical analyses , which generally assume independent observations , are performed on multilevel data ( the so - called _ naive pooling _",
    "strategy ) , results may be misleading .",
    "inference in multilevel models usually relies upon maximum likelihood methods ( see for example @xcite , @xcite and @xcite ) that mostly use asymptotic approximations for the construction of test statistics and estimation of variances .",
    "if the sample size is not large enough , the asymptotic approximation does not hold and can lead to incorrect inferences . by using bootstrap methods , under some regularity conditions ,",
    "it is possible to obtain a more accurate approximation of the distribution of the statistics .",
    "the original bootstrap procedure has been studied in detail by @xcite for independent and identically distributed ( i.i.d . )",
    "an extensive discussion of bootstrap methods for a variety of statistical models and for different data structures can be found in @xcite , and in particular for the multilevel structure in @xcite and @xcite . in the case of hierarchical data three general bootstrap approaches are available and well established : the parametric bootstrap , the residual bootstrap and the cases bootstrap .",
    "the aim of the paper is twofold : first , we review and test the finite size performance of the three bootstrap schemes for multilevel data by means of a simulation study ; second , we propose a wild bootstrap procedure for multilevel data .",
    "the wild bootstrap does not assume homoscedasticity and , for this reason , can reveal appropriate for inference robust to heteroscedasticity of unknown form .",
    "the paper is organized as follows .",
    "section [ sec : boot ] presents the three bootstrap schemes for multilevel models . in section [ sec : wild ] we introduce the wild bootstrap procedure for the linear regression model and extend it to the case of hierarchical data .",
    "section [ sec : mc ] presents a monte carlo study that compares all the methods under different scenarios .",
    "finally , section [ sec : concl ] contains the conclusions .",
    "resampling schemes for multilevel models have to take into account the hierarchical structure of data . hence",
    ", the classic bootstrap procedures need to be adapted .",
    "the main bootstrap approaches for a multilevel model are discussed for example in  @xcite and @xcite ) :    1 .   the parametric bootstrap ( resamples from the fitted distribution of the error processes ) 2 .   the residual bootstrap ( resamples residuals from the fitted model ) 3 .   the cases bootstrap ( resamples entire cases )    the schemes differ in the underlying assumptions .",
    "we illustrate them by considering the following two - level model that includes @xmath0 level-1 covariates with fixed coefficients ( @xmath1 ) and @xmath2 covariates with random coefficients ( @xmath3 ) @xmath4 with @xmath5 , @xmath6 $ ] and @xmath7^{{\\scriptscriptstyle \\mathrm{t } } } \\sim \\text{nid}\\big(\\mathbf{0},\\boldsymbol{\\sigma}\\big)$ ] , where the variance - covariance matrix of the random effects has the following form @xmath8.\\ ] ] moreover , it is assumed that the random effects for the group j , the vectors @xmath9 , and the within - group errors , @xmath10 , are independent .",
    "finally , we denote by @xmath11 the ( restricted ) maximum likelihood estimates of the parameters of the model ( [ eq : general model ] ) .",
    "the parametric bootstrap assumes that the covariates are fixed and that both the model and the error distributions are correctly specified .",
    "compared to the other two approaches , such scheme has the strongest requirements . in practice , the parametric bootstrap for model ( [ eq : general model ] ) generates resamples as follows :    1 .",
    "draw @xmath12 elements @xmath13 from the estimated distribution of level-1 errors , @xmath14 , where @xmath15 is the total sample size ; 2 .   draw @xmath16 ( p+1)-vectors of elements @xmath17 from the estimated distribution of the random effects , @xmath18 ; 3 .",
    "generate the bootstrap responses as @xmath19 4 .",
    "compute the bootstrap value @xmath20 on the generated sample ; 5 .",
    "repeat steps @xmath21 b times as to obtain b sets of bootstrap replications of the parameters .    as remarked above",
    ", the parametric bootstrap is not robust with respect to any deviation from the normality assumption on the error terms so that severe problems can occur in such cases .",
    "the residual bootstrap was introduced in the multilevel framework by @xcite ; it treats the covariates as fixed and assumes that the model specification is correct .",
    "no distributional assumptions on error terms are required but only variance homogeneity among groups . in the classic linear regression framework ,",
    "the scheme resamples with replacements from the residuals of the fit .",
    "the implementation of this procedure in a multilevel model leads to a distortion because the residuals are _ shrunken _ towards zero so that the true variability of the residuals is not reproduced in the resamples @xcite .",
    "therefore , it is necessary to reflate the _",
    "shrunken _ residuals .",
    "the procedure generates bootstrap samples as follows :    1 .",
    "compute level-2 and level-1 _ shrunken _ residuals from model ( [ eq : general model ] ) , respectively @xmath22 @xmath23 where @xmath24 is the ml estimate of the block - diagonal variance - covariance matrix of the whole random - effects matrix @xmath25^{{\\scriptscriptstyle \\mathrm{t}}}$ ] ; both level-1 and level-2 residuals must be centered , since in the multilevel model their mean is not zero ; 2 .",
    "reflate the ( centered ) residuals , that is , consider a transformation @xmath26 such that @xmath27 .",
    "in other words , we need to achieve that estimates of the variance obtained by means of the _ shrunken _ residuals equal the maximum likelihood estimates obtained from the model ; otherwise , the procedure would lead to downward biased estimates of the variance parameters . for level-2 residuals",
    "we have @xmath28 one possible choice of @xmath29 is @xmath30 where @xmath31 and @xmath32 are the cholesky decompositions of @xmath33 and @xmath34 respectively .",
    "the same procedure is applied to level-1 residuals ; 3 .",
    "draw with replacement @xmath16 vectors @xmath17 from the set of reflated level-2 residuals , @xmath35 ; 4 .",
    "draw with replacement @xmath12 elements @xmath13 from the set of reflated level-1 residuals @xmath36 ; 5 .",
    "generate the bootstrap responses as @xmath19 6 .",
    "compute bootstrap values @xmath20 on the generated sample ; 7 .   repeat steps @xmath37 b times as to obtain b bootstrap replications of the parameters .    since",
    ", it does not rely on any distributional assumptions , the residual bootstrap is robust with respect to non - normality of the error processes . by means of a simulation study on a two - level model with @xmath38 errors ,",
    "@xcite show that the empirical coverage of bootstrap confidence intervals is better for the residual bootstrap than for the parametric bootstrap ; also , they show that the most important improvements concern the estimates of random parameters .      the cases bootstrap for the linear regression model was proposed in @xcite under the name _",
    "pairs bootstrap_. of the three bootstrap procedures for multilevel model reviewed here , the cases bootstrap has the least restrictive assumptions : it assumes that only the hierarchical dependency in the data is correctly specified and considers the covariates as random variables .",
    "the procedure resamples entire cases as follows :    1 .   draw with replacement @xmath16 units from the set of numbers @xmath39 ; any drawn index @xmath40 is associated to a whole level-2 unit @xmath41 ; 2 .   for each selected level-2 unit @xmath41 , @xmath42 , draw with replacement a bootstrap sample @xmath43 of size @xmath44 ; 3 .",
    "compute the bootstrap value @xmath20 on the generated sample ; 4 .   repeat steps @xmath45 b times as to obtain b bootstrap replications of the parameters .",
    "the scheme of the cases bootstrap described above resamples both level-1 and level-2 units . however , whether this makes sense depends on the nature of the data",
    ". there may be instances in which it is correct to resample only level-1 ( or level-2 ) units .",
    "for instance , when level-2 units are individuals and level-1 units are repeated measures , it is appropriate to resample only level-2 units ; then , for each level-2 unit drawn all the associated level-1 units enter the resample . on the contrary ,",
    "if level-2 units are countries or time points and level-1 units are individuals , it is more appropriate to resample only level-1 units within countries ( or time points ) . for further discussion on the matter see @xcite . the cases bootstrap ( appropriately implemented )",
    "provides consistent estimators under heteroscedasticity at the price of less efficient estimators than the parametric and the residual bootstrap @xcite .",
    "the wild bootstrap is a technique aimed to obtain consistent estimators for the covariance matrix of the coefficients of a regression model when the errors are heteroscedastic .",
    "it was developed by @xcite following suggestions in @xcite and @xcite .",
    "further evidences and refinements are provided in @xcite and @xcite .",
    "consider the classic linear regression model @xmath46 for @xmath47 .",
    "the disturbances @xmath48 are assumed to be mutually independent and to have zero mean , but they are allowed to be heteroscedastic .",
    "moreover , the covariates are assumed to be strictly exogenous .",
    "+ in the homoscedastic case , the variance of the residuals is proportional to @xmath49 , where @xmath50 is the @xmath51-th diagonal element of the orthogonal projection matrix @xmath52 .",
    "this suggests to replace the heteroscedastic residuals @xmath53 with @xmath54 in order to reduce the bias of the variance estimator , as we use to do in the homoscedastic case by using the unbiased ols estimator .",
    "these are two of the _ heteroskedasticity consistent covariance matrix estimator _",
    "( hccme ) forms considered in @xcite , that @xcite refers to as hc@xmath55 and hc@xmath56 respectively .",
    "we omit to mention the other forms of hccme since , as is shown in @xcite and @xcite , hc@xmath55 and hc@xmath56 outperform the others in terms of power and size of the tests ; instead the two forms in ( [ eq : hc ] ) can not be ranked , although in some simulation experiments hc@xmath56 has shown the least distortion ( see for example @xcite ) .",
    "the wild bootstrap procedure tries to recover the unknown form of heteroscedasticity of the errors by means of the following bootstrap data - generating process : @xmath57 where @xmath58 is the vector of estimated regression coefficient , @xmath59 is one of the variants of hccme ( such as those in ( [ eq : hc ] ) ) where the residuals have been transformed and the @xmath60 ( for @xmath47 ) are mutually independent errors drawn from an auxiliary distribution with zero mean and unit variance . while @xcite suggests the following asymmetric two - point distribution for the @xmath60 @xmath61 @xcite mentions , instead , the distribution @xmath62 based on the evidence of the simulation study , @xcite recommend the auxiliary distribution @xmath63 rather than other versions .",
    "for further discussions on this choice , see also  @xcite and @xcite .",
    "the wild bootstrap procedure is as follows :    1 .",
    "draw @xmath64 independent values , @xmath60 , for @xmath47 , from an auxiliary distribution with zero mean and unit variance such as @xmath65 and @xmath63 ; 2 .   generate the bootstrap samples according to eq .",
    "( [ eq : bootsample ] ) 3 .",
    "compute the bootstrap value @xmath20 on the generated sample @xmath66 ; 4 .   repeat steps @xmath45 b times as to obtain b bootstrap replications of the parameters .",
    "note that also the pairs bootstrap , called cases bootstrap in multilevel models ( subsection [ subsec : cases ] ) , is used to overcome the problem of heteroscedasticity of unknown form .",
    "however , @xcite shows that the version of wild bootstrap with @xmath63 in ( [ eq : f2 ] ) recommended in @xcite , provides better numerical performance in terms of false rejection probability and power of a test than both other versions of wild bootstrap and the pairs bootstrap . given these results for regression models",
    ", we expect that the wild bootstrap behaves similarly when applied to multilevel data .",
    "however , to our knowledge , this technique has never been implemented and used in a multilevel framework .",
    "hence , we provide a modified version of the wild bootstrap that could be useful in cases of hierarchical and heteroscedastic data . the next subsection is devoted to this matter .",
    "now , we adapt the procedure presented above to the case of hierarchical data",
    ". consider the classic multilevel model in eq .",
    "( [ eq : general model ] ) but for the ( @xmath67 ) response of the generic group @xmath68 : @xmath69 for all @xmath70 .",
    "note that the wild bootstrap procedure requires the disturbances to be mutually independent .",
    "however , in the multilevel framework the compound error terms of two generic units in the group @xmath68 , @xmath71 and @xmath72 , are not independent by definition . instead , the error terms corresponding to the whole generic group @xmath68 , @xmath73 , are mutually independent .",
    "therefore , handling the vectorial form of the multilevel model ( [ eq : mod_vector ] ) , rather than the univariate form ( [ eq : mod ] ) , allows from one hand to put oneself in the same situation of the classic wild bootstrap procedure , and , from another hand , to take into account the intra - class correlation of hierarchical data .",
    "+ denoting with @xmath74 the @xmath68-th diagonal block of the orthogonal projection matrix associated to the design matrix @xmath75 , the hccme expressions in ( [ eq : hc ] ) become @xmath76 where the vector of the residuals for the @xmath68-th group is computed as @xmath77 and the operator `` @xmath78 '' denotes the hadamard ( or entrywise ) product .",
    "we suggest to implement the wild bootstrap for a multilevel model as follows :    1 .",
    "draw @xmath68 independent values , @xmath79 , for @xmath80 , from an auxiliary distribution with zero mean and unit variance such as @xmath65 and @xmath63 ; 2 .   generate the bootstrap samples @xmath81 where the transformed residuals @xmath82 are as in ( [ eq : hc2 ] ) ; 3 .   compute the bootstrap value @xmath20 on the generated sample ; 4 .   repeat steps @xmath45 b times as to obtain b bootstrap replications of the parameters .",
    "in this section we present the results of a monte carlo study that compares the three bootstrap procedures described above ( section [ sec : boot ] ) with the adapted wild bootstrap procedure for multilevel data ( section [ subsec : wild_multi ] ) . here",
    ", the wild bootstrap is implemented with @xmath65 as in eq .",
    "( [ eq : f1 ] ) as auxiliary distribution and hc@xmath55 as in eq .",
    "( [ eq : hc2 ] ) as hccme form .",
    "further , we study the behaviour of the wild bootstrap with different choices of auxiliary distributions and hccme forms . consider the following two - level model @xmath83 for level-1 units @xmath84 and level-2 units @xmath70 . in this study ,",
    "the clusters contain the same number of level-2 units , that is @xmath85 for all @xmath68 .",
    "the true values chosen for the regression coefficients are @xmath86 and @xmath87 and the @xmath88 s are simulated from a standard normal distribution .    in order to assess the finite size performance of the bootstrap schemes in presence of non - constant variance we generate samples with both homoscedastic and heteroscedastic level-1 errors , @xmath10 . to this aim , we define @xmath89 and set @xmath90 for all @xmath91 for generating homoscedastic data , and @xmath92 for obtaining heteroscedastic data .",
    "hence , the variance of level-1 error terms is @xmath93 , where @xmath94 for all @xmath51 and @xmath68 . also , we control for deviations from normality by adopting two different error distributions . in the first case ,",
    "we draw @xmath12 values of @xmath95 and , for each @xmath70 , we draw a sample @xmath96 from the bivariate normal distribution : @xmath97 \\sim n\\bigg(\\left[\\begin{array}{c } 0 \\\\ 0 \\end{array}\\right ] , \\left[\\begin{array}{cc } \\sigma^2_{u0}=2 & \\sigma_{u01}=0.5\\\\ \\sigma_{u01}=0.5 & \\sigma^2_{u1}=2\\\\                                                   \\end{array}\\right]\\bigg).\\ ] ] as for the non gaussian case , we draw @xmath12 values of @xmath98 a from @xmath99 distribution and , for each @xmath70 , we draw a sample @xmath100 from the bivariate normal distribution @xmath101 \\sim   n\\bigg(\\left[\\begin{array}{c } 0 \\\\ 0                        \\end{array}\\right ] , \\left[\\begin{array}{cc } 1 & 0.5\\\\ 0.5 & 1\\\\                                                   \\end{array}\\right]\\bigg);\\ ] ] then , we set @xmath102 and @xmath103 so that both random effects have marginal @xmath104-distribution with mean 0 , variances @xmath105 and @xmath106 equal to 2 and covariance @xmath107 equal to 0.5 .    in the study",
    ", we vary also the group size @xmath64 and the number of groups @xmath16 as follows : @xmath108    note that settings 1 and 2 differ in the number of groups whereas settings 2 and 4 differ in the group size . for each setting",
    ", we simulate 500 datasets from model ( [ eq : mod ] ) , and for each dataset we compute restricted maximum likelihood estimates of the parameters .",
    "the number of bootstrap replications is @xmath109 , hence we obtain @xmath110 replications of the parameters , @xmath111 .",
    "finally , we derive 95% bootstrap confidence intervals @xcite by sorting the bootstrap replications and taking the following two percentiles @xmath112\\ ] ] with @xmath113 .",
    "as measures of performance we take the empirical coverage of the confidence interval and its average length .",
    "table  [ tab : scheme ] summarizes the scenarios of the simulation study indicating the tables of the results for each case .",
    ".summary of the scenarios of the monte carlo study . [ cols=\"<,<,<\",options=\"header \" , ]      distributions of the bootstrap replications for the within - group variance @xmath114 for two samples with heteroscedastic gaussian errors : ( left ) small sample size ( @xmath115 , @xmath116 ; ( right ) big sample size ( @xmath117 , @xmath118.,title=\"fig:\",width=264,height=264 ]   distributions of the bootstrap replications for the within - group variance @xmath114 for two samples with heteroscedastic gaussian errors : ( left ) small sample size ( @xmath115 , @xmath116 ; ( right ) big sample size ( @xmath117 , @xmath118.,title=\"fig:\",width=264,height=264 ]    distributions of the bootstrap replications for the covariance between the random slope and the random intercept @xmath107 for two samples with heteroscedastic gaussian errors : ( left ) small sample size ( @xmath115 , @xmath116 ; ( right ) big sample size ( @xmath117 , @xmath118.,title=\"fig:\",width=264,height=264 ] distributions of the bootstrap replications for the covariance between the random slope and the random intercept @xmath107 for two samples with heteroscedastic gaussian errors : ( left ) small sample size ( @xmath115 , @xmath116 ; ( right ) big sample size ( @xmath117 , @xmath118.,title=\"fig:\",width=264,height=264 ]",
    "in this paper we have investigated the performance of three well established bootstrap schemes for multilevel models : the parametric bootstrap , the residual bootstrap and the cases bootstrap .",
    "also , we have introduced a modified version of the wild bootstrap procedure which is particularly suitable to hierarchical data .",
    "we have assessed the finite size performances of the four bootstrap schemes by means of a monte carlo study where we have varied sample size , error distribution and error variance .",
    "both the cases bootstrap and the wild bootstrap do not require homoscedasticity and do not make distributional assumptions on the error processes .",
    "still , the performance of the two schemes is very different in terms of coverage and length of confidence intervals .",
    "in fact , except for some specific instances , the cases bootstrap has the worst performance of all the four bootstrap schemes , no matter the sample size or the kind of errors . on the contrary , for big",
    "sample sizes the wild bootstrap outperforms the three competitors in all the scenarios considered including the gaussian homoscedastic case .",
    "this is especially true as far as estimation of variance components is concerned .",
    "in fact , in case of estimation of regression coefficients , both the parametric and the residual bootstrap behave quite well and are robust with respect to non - gaussianity and heteroscedasticity .",
    "the estimation of level-1 variance @xmath114 , instead , is more problematic : the parametric bootstrap performs very poorly when the assumptions of normality and homoscedasticity are violated ; in these cases , the residual bootstrap , behaves better than the parametric bootstrap but it is still outperformed by the wild bootstrap in all the scenarios , with the most dramatic worsening in the heteroscedastic case .    in conclusion",
    ", we advocate the use of the proposed version of the wild bootstrap in a multilevel framework especially when the validity of the assumptions underlying the model is questionable , as well as when the sample is sufficiently large ."
  ],
  "abstract_text": [
    "<S> in this paper we study the performance of the most popular bootstrap schemes for multilevel data . also , we propose a modified version of the wild bootstrap procedure for hierarchical data structures . </S>",
    "<S> the wild bootstrap does not require homoscedasticity or assumptions on the distribution of the error processes . </S>",
    "<S> hence , it is a valuable tool for robust inference in a multilevel framework . </S>",
    "<S> we assess the finite size performances of the schemes through a monte carlo study . </S>",
    "<S> the results show that for big sample sizes it always pays off to adopt an agnostic approach as the wild bootstrap outperforms other techniques . </S>",
    "<S> + 0.2 mm _ keywords : _ multilevel model ; wild bootstrap , heteroscedasticity ; cases bootstrap .    </S>",
    "<S> the wild bootstrap for multilevel models lucia modugno and simone giannerini department of statistical sciences    university of bologna    via belle arti , 41 - 40126 bologna , italy    lucia.modugno@unibo.it    simone.giannerini@unibo.it </S>"
  ]
}