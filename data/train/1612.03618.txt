{
  "article_text": [
    "to answer users changing requirements , software systems must continuously evolve  @xcite . having developers to understand a program s source code which may include thousands of lines of code , and focus on those parts on which they want to perform their maintenance activities , is the main reason of 60% to 90% of the overall software maintenance and evolution costs  @xcite .",
    "this is mainly due to the fact that original developers of the software system may no longer be available in the team , and thus , any maintenance tasks in this phase can be highly error prone .",
    "hence , program comprehension and understanding the rationale behind the code are the most critical and time consuming steps for developers during software maintenance and evolution  @xcite , being that they spend substantial efforts on reading and finding relative parts of the code rather than applying the modification  @xcite .",
    "however , using _",
    "code summaries _ can be a solution to this difficulty  @xcite .",
    "a code summary is a brief description about the functionality and the purpose of a section of the source code .",
    "code summaries can help programmers find the relevant parts of the source code to their maintenance tasks much easier and faster  @xcite .",
    "mcburney et  al .",
    "@xcite pointed out that the code authors use more development details and low level implementation informations .",
    "meanwhile , readers are those who want to understand the code ; therefore , they must be able to deduce the concepts from the low level details . ignoring the way which a reader would write a summary is the most important defect in the existing source code summarization approaches .",
    "_ crowdsourcing _ is a novel problem - solving approach which is a way to outsource different tasks to a crowd of people through open call ( e.g. , via the internet ) instead of traditional suppliers  @xcite . in recent years",
    ", crowdsourcing has attracted significant attentions to support a wide range of software engineering activities like requirements engineering , design , coding , testing , and evolution and maintenance  @xcite .",
    "however , to the bests of our knowledge , using a crowd of developers to write summaries for a piece of a code is a novel idea in the context of program comprehension which we will present in this article .",
    "more specifically , here we explain our crowdsourcing platform , named _ crowdsummarizer _ , that applies the concepts of crowdsourcing , gamification , and natural language processing to motivate developers to write high level summaries for the methods of a java program .",
    "furthermore , crowdsummarizer continuously learns a set of weights and sentence templates from the set of methods and their corresponding summaries which have been collected from the crowd so far , and uses them to also automatically generate the summaries .",
    "this helps developers to save time and not necessarily wait for the crowd to write summaries for their methods .",
    "we have implemented crowdsummarizer as a web - based game as well as an eclipse plugin that not only automatically generates natural language summaries for the methods of a java program , but also submits those methods to crowdsummarizer s website for the summarization by the crowd .",
    "we have used this implementation in an empirical study with 149 developers of various levels of experience to generate summaries for 128 methods with different properties from 11 widely used open - source java applications .",
    "the results of the study showed that crowdsummarizer is applicable for developers to use it in practice .",
    "in addition , the results of another empirical study performed with the help of 14 experts illustrated that crowdsummarizer can automatically generate accurate and comprehensible summaries .    our main contributions of this article include :    1 .   presenting a novel approach for generating natural language summaries for a java program and its methods using a topic modelling approach and power of the crowd .",
    "2 .   developing a crowdsourcing platform which uses the gamification elements to encourage users engagement .",
    "evaluation of the applicability and usefulness of crowdsummarizer platform as well as the quality of our automatically generated summaries .",
    "a complete implementation of our approach for java language as an eclipse plug - in .",
    "the remainder of this article is organized as follows .",
    "we rst provide a motivating example , used through- out this article ( section [ motivating - example ] ) .",
    "we then introduce the details of crowdsummarizer technique ( section [ proposed_approach ] ) and its implementation ( section [ sec : impl ] ) .",
    "we describe an example which crowdsummarizer try to solve it ( section [ exp ] ) .",
    "next , we present two empirical evaluation to evaluate the applicability of the crowdsummarizer platform , and different aspects of summaries generated for the 78 java methods from the 11 open - source java applications ( section [ sec : eval ] ) . finally , we discuss several observations on collected summaries from the crowdsummarizer ( section [ discussion ] ) ; compare the technique with related work ( section [ sec : relatedwork ] ) ; and conclude ( section [ sec : conclusion ] ) .",
    "we clarify the problem that crowdsummarizer aims to tackle using an example .",
    "suppose a novice developer has been asked to apply changes to a program which she has no prior background about its source code .",
    "for instance , suppose she has been asked to add the following new feature to the _ _ jedit _ _ editor which is currently 117 kloc , and includes 555 java files and 7161 methods : _  support for advanced mouse buttons and mouse shortcuts \" _",
    "( feature request # 476 ) .",
    "the first step to make the above change is to have a relatively good understanding of the program s source code which is written by other developers who may have left the team .",
    "the source code documentation is often one of the possible solutions which can help mitigate the burden of this problem .",
    "however , it is often missing or outdated , and also time consuming to read . reading the entire source code in detail or skimming through it are two other extreme approaches for comprehending the program .",
    "nevertheless , they are time consuming and imprecise , respectively  @xcite .",
    "code summarization is a middle tactic that mediates between the two tactics by generating high level descriptions about the elements of a program , and can result in a better understanding of the code in a shorter period of time  @xcite .",
    "figure  [ fig : example ] represents a sample code snippet together with its summary .",
    "we address the issue of source code summarization as following :    _ given a java program , automatically discover the list of latent topics in the program , classify the methods of the the program into these topics and generate descriptions about relations between the topics and the program s methods .",
    "_    specifically , the problem of method summarization :    _ given the signature and body for the method @xmath0 , automatically generate sentences describe the high level action of the method from readers ( i.e. a person who did nt write the code ) perspective . _",
    "before delving into the details of crowdsummarizer , we first provide an overview of the approach .",
    "as can be seen in figure  [ fig : overall - process ] , the proposed approach has two main components to automatically generate summaries for a java program : ( i ) the _ lda _ ( _ latent dirichlet allocation _ ) component to extract latent topics in a java program , and to classify its methods into those topics ( figure  [ fig : overall - process](b ) ) , and ( ii ) the crowdsourcing component to generate natural language summaries for each method ( figure  [ fig : overall - process](c ) ) .",
    "the crowdsourcing component , which is the main focus of this article , constitutes two subcomponents .",
    "the first subcomponent ( figure  [ fig : overall - process](d ) ) utilizes a web - based game to get the summaries for each method from the crowd and to generate its results ( the _ active _ use of the approach ) .",
    "meanwhile , the second subcomponent ( figure  [ fig : overall - process](e ) ) generates automated natural language summaries for each method by using the information which has been gained so far from the naming conventions and the linguistic knowledge as well as the summaries derived from the crowd ( the _ passive _ use of the approach ) .",
    "the aim of this phase is to automatically generate the list of latent topics in a java program , and to classify the methods of that program into those topics .",
    "this would help developers to get a high level view about that program and the distribution of the methods to find out which methods work on a same concept ( i.e. topics ) .",
    "for this purpose , we apply the lda technique  @xcite as the topic modelling approach to extract topics .",
    "lda  @xcite is a generative statistical topic modeling technique used to extract and define latent topics present in a set of documents and classify documents as a mixture of a finite set of topics by association between each meaningful word in the document and one of these topics .",
    "the lda technique has advantages in modularity and extensibility compared to other information retrieval approaches like _ lsi _ ( _ latent semantic indexing _ )",
    "@xcite , and this is the fact that led us to employ it for code summarization . figure  [ fig : mapping ] describes three parameters which must be identified to apply lda model .        to implement the lda component of crowdsummarizer , we used the _ mallet _ s eclipse plug - in .",
    "one of the most important and challenging parameters for constructing the lda model is identifying the total number of latent topics which is called t. however , choosing the number of topics in the lda model is as difficult as choosing the dimensionality reduction parameter in lsi . in the both cases",
    "the size of corpus and the size of each document are significant factors . although , the automated algorithms are working on estimating the appropriate value , but the most common solution to this problem is varying the number of topics to get the best classification from the domain experts viewpointsmaskeri2008mining .",
    "depends on the number of documents in the document collection , researches indicated a value for t in the range of 50 to 300 . here",
    "are examples of the most commonly used and successful values for different sizes of the document collection .",
    "t=100 for d < = 20,000 and t=300 for 30,000 < d < 40,000 . studies for identifying the number of topics for collections greater than 50,000 is still ongoing  @xcite . from the 32 open - source java programs ( table [ tab : number - of - methods ] )",
    ", we analysed that the average number of methods in the java programs is about 10,000 ( min = 318 and max = 39,747 ) .",
    "thus , the t value for a java programs is often less than 100 and it is a function of the number of methods in that program .      the term crowdsourcing is a combination of the terms  crowd \" and  outsourcing \" .",
    "the crowdsourcing approach is a novel problem - solving technique that aims to outsource different tasks to a crowd of people through the open call ( e.g. , via the internet ) instead of traditional suppliers  @xcite .",
    "crowdsourcing has been applied in a wide range of researches , such as social networks  @xcite , mobile  @xcite , health  @xcite , and etc .",
    "these tasks often can not be solved or are difficult to be processed by computers , but are simple enough to be performed by workers .    in recent years",
    ", crowdsourcing has attracted significant attentions to support a wide range of software engineering activities to like requirements engineering , design , coding , software testing and maintenance  @xcite .",
    "examples of the platforms that are specifically used in software engineering field are topcoder , utest , appstori , bountify which are working in software development , software testing mobile application development , respectively  @xcite .",
    "as mentioned earlier , code summarization helps developers to have a general understanding of a source code in a shorter period of time , particularly when it is a complex one and includes thousands of lines of code .",
    "nonetheless , source codes often suffer from the lack of proper comments , documentation , and summaries , since manually creating them requires a lot of effort , and developers are often hesitant to perform it .",
    "consequently , automated code summarization approaches , such as  @xcite , have been introduced in literature .",
    "however , as will be discussed in section  [ sec : relatedwork ] , they pose some limitations like the limited length of the methods they can summarize , or they can only summarize some special aspects of a program ( e.g. , the contexts or the roles of methods ) .",
    "hence , to mitigate these problems , we propose to use the power of the crowd by adapting the crowdsourcing technique for code summarization .",
    "more specifically , we developed the crowdsummarizer platform with which developers can decompose a java program into its methods , and submit those methods to a website .",
    "next , a crowd of developers would write summaries for those methods , and the results are then presented to the user . to save user s time and to give them some initial results , as will be discussed later in section  [ sec : automatic_summary ] , crowdsummarizer",
    "also automatically generates summaries for those methods with the help of the knowledge it has learned so far .    in order to develop a crowdsourcing platform",
    "we must identified the three main components of a crowdsourcing system defined by  @xcite :    * the crowd ( workers ) : any developer can participate and supposed to write summaries for the methods and evaluating other summaries and in return he will get points , badges and prizes . * the requester : a person who post a code to the platform and wants other to write summaries for the code . *",
    "process : type : delegation a task to the crowd of users .",
    "call : open call .",
    "medium : the internet .",
    "figure [ fig : crowd - process ] shows a typical crowedsourcing process . after broadcasting a method from a requester , workers(developers ) are asked to write summaries for that method and submit their answers on the platform .",
    "examining solutions carefully to make decision to accept the answers is one of the important steps in this process . as discussed earlier , although gamification makes users to write high quality summaries , but to discourage users from writing unrelated comments , we added an evaluation part to the platform which works by giving positive or negative feedbacks to summaries ( the way that stackoverflow does voting answers ) .",
    "we show methods with correspondent summaries(to prevent personal biases we do nt display authors of the summaries ) to developers and ask them if summaries are related to the method or not . using this mechanism ,",
    "unrelated summaries will be removed automatically by identifying summaries with negative feedbacks .",
    "we consider a point mechanism to encourage users to evaluate summaries .        with respect to the above discussion , the most fundamental issue and the key requirement in our work is to get people to take part in crowdsourcing and have a sheer number of users to write a summary for a piece of the code . in some cases ,",
    "the workers join to a platform because of their personal interest , altruism or maybe just because of they believe in you .",
    "however , how to be sure about the quality of the work outcome ? it has been a weakness of crowdsourcing methodology due to its open participation model  @xcite . to mitigate this weakness , motivation of the workers",
    "is of a great importance .",
    "although , task characteristics and granularity have also impact on worker s motivation , but there are two kinds of motivations : intrinsic and extrinsic  @xcite .",
    "feeling competent and creative , having fun , volunteering projects and achieving social recognition are examples of intrinsic motivation , while financial payoffs , such as gift cards is extrinsic motivation .",
    "researches indicated that the combination of these two factors will increase the participation .",
    "one of the great drivers for increasing intrinsic motivation and engaging users in a crowdsourced task is _ gamification _",
    "@xcite which is discussed in the following .",
    "gamification is a neologism from the word  game \" and embraces the concept of using the game design thinking and mechanisms in non - game contexts in order to make them more fun and engaging  @xcite .",
    "gamification makes people to enjoy their pastime while performing the crowdsourced tasks . to this end , as mentioned above , to motivate developers to engage in writing summaries for the methods submitted to the crowdsummarizer s website , we designed and implemented a web - based game as follows ( see  @xcite for a demonstration of this game )",
    ".    any developers who registers in the crowdsummarizer platform can be a player in the game , can earn points , and move up to the top players list .",
    "this game includes eight levels which starts with summarizing simpler methods , and then continues with summarizing harder ones in the next levels .",
    "evaluating submitted answers carefully to decide whether or not an answer should be accepted is an important step in any crowdsourcing process . therefore , we added an evaluation step to the game which randomly shows a number of methods together with their submitted summaries to players , and allows them to _ upvote _ or _ downvote _ other players summaries . to prevent personal biases ,",
    "we hide the names of the authors of those summaries . in this way",
    ", irrelevant summaries will be removed automatically by identifying summaries with negative votes . to motivate",
    "further the developers to engage in the game , players must reach at least the level # 4 of the game to be allowed to push their own code for summarization to the crowd . moreover , we used the following different types of gamification elements in our platform to make the game more fun and motivating :    * _ points _ : it is the core element used in almost any gamified system as rewarding mechanism for quantitative number of fulfilled enumerable tasks that informs users about more valuable tasks .",
    "with respect to its difficulty , each method has a point that if a player write a summary for it , she would get it .",
    "moreover , the first three players who summarize a method would receive double points .",
    "we randomly select several methods as starred methods which have extra points .",
    "evaluating other players summaries , and also having summaries with high upvotes can also increase the total points .",
    "obviously , having summaries with downvotes can decrease the total points . to prevent players from worthless evaluations of others summaries",
    ", we use a trap mechanism and a fake account to identify cheaters . *",
    "_ leaderboards _ : researches on gamification indicated that ranking systems are very effective in motivating players  @xcite .",
    "thus , we employed two different leaderboards in our game : a _ global _ leaderboard and a _ local _ leaderboard .",
    "the former shows the competition amongst all the players ( figure  [ fig : leaderboard ] ) , while the latter just displays the players who are in that player s programming experience level .",
    "we also present encouraging statements to players like `` hurry up , writing 2 summaries will shift you up to the second place in the global leaderboard . '' , `` you missed your place in the local leaderboard .",
    "it is the time to get it back . '' , `` good job ! '' , or ``",
    "keep on ! '' . * _ badges _ : players get different tagged images as badges based on their performance in the game ( ( figure  [ fig : leaderboard ] ) ) . for example",
    ", a player with the highest upvotes will get the ",
    "good summarizer `` badge .",
    "example of other badges are ' ' quick summarizer `` , ' ' newbie `` , ' ' adventure `` , ' ' explorer `` , ' ' superstar \" , and etc .",
    "* _ levels _ : generally , levels indicate where players stand in a game  @xcite .",
    "users will pass 8 levels according to their points in a non - linear form .",
    "we use progress bar which shows the percentage of completeness of the level as well as levels to show player s own advancement . to increase the attractiveness of the game",
    ", we considered a title for each level .",
    "for example ,  starting to see the light \" ,  middle of the way \" , and  monster slayer \" for levels # 1 , # 4 , and # 8 respectively . * _ mystery boxes _ : we show the players a mystery box with a random gift ( e.g. , point , badge , etc . ) in levels # 2 , # 5 , and # 7 to motivate them to play further . * _ avatars _ : representing players with an avatar can increase their engagements  @xcite .",
    "thus , if a player has set an avatar in _ _ gravatar _ _ , we would use it in our game ( figure figure  [ fig : profile ] shows the user s profile . ) .",
    "results indicated that points and leaderboards are the two most common and successful affordances which employed in crowdsourcing contexts with homogeneous contributions  @xcite . despite all these elements and the positive results which gamification has in the crowdsourcing process , but",
    "there is still a risk .",
    "using too much of these elements may makes workers just concentrate on receiving points and getting higher ranks in the leaderboards rather than performing the summarization task .",
    "however , we are trying to stop getting displaced scores by using evaluation and trap mechanisms .",
    "we have described so far in this section that users of the crowdsummarizer platform submit their desired methods of a java program as code summarization tasks to our web - based game , and a set of players submit their own summaries for those methods , and the summaries are then evaluated by another set of players . verifying tasks done by the crowd",
    "is one of the challenges in any crowdsourcing platforms that we addressed it in our approach by the crowd itself .",
    "afterwards , users can choose different kinds of outputs from the collected summaries .",
    "currently , crowdsummarizer supports the following three kinds of outputs :    * _ summary with the highest upvotes : _ with respect to the number of upvotes and downvotes of submitted summaries for a given method , a summary is chosen . * _ summary with the highest similarity with the given method : _ a summary that has the most common keywords with the given method is selected ( see equation   in section  [ sec : compweights ] ) . * _ merged summaries : _ this extracts the common concepts amongst the submitted summaries .",
    "users also have the option to access each submitted summary if needed .      in the previous section",
    ", we used the crowdsummarizer platform in an active form to get the summaries from a number of players .",
    "however , in this section , we look into this platform as a passive component .",
    "more specifically , crowdsummarizer continuously learns a set of weights and sentence templates from the set of methods and their corresponding summaries which have been collected from the crowd so far , and uses them to automatically generate summaries for new methods .",
    "this helps developers to get some initial results from the platform , and to not necessarily wait for the crowd to write summaries for their methods . in the following ,",
    "we describe the steps that are followed to generate automated summaries .",
    "mcburney et  al .",
    "@xcite pointed out that the source code and the readers summaries are more similar than the source code and the authors summaries .",
    "authors use more development details and low level implementation informations .",
    "meanwhile , readers are those who want to understand the code ; therefore , they must be able to deduce the concepts from the low level details .",
    "so the ultimate goal of source code summarization approaches must be generating summaries that are more similar to summaries that a reader would write .",
    "the aim of this step is to assign weights to different parts of a method ( e.g. , method s name and parameters ) with respect to the frequency of their use in the summaries collected so far by the crowdsummarizer platform .",
    "these weights are then used to automatically generate a summary for a given method .",
    "overall process of computing keyword weights is shown in figure [ fig : weight process ] .",
    "the output of this process is a set of keyword weights which will be used in automatically generating summary for a method .",
    "similar to other approaches which are based on linguistic information , the quality of our results are significantly affected by meaningless identifiers .",
    "thus , our approach produces better results when meaningful identifers are used , and naming conventions and style guidelines are followed . additionally , like other natural language processing systems",
    ", we apply several general preprocessing steps to refine the data set and to prepare it for the next analysis tasks :    * _ tokenization : _ this step tokenizes a sentence into its constituent words . * _ splitting : _ as readers use method keywords in their summaries and these keywords usually follow certain coding conventions , we had to split these words .",
    "we implemented the splitter introduced in  @xcite which is based on common coding styles , such as camel cases , punctuation , numbers , underscores , and so on .",
    "for example , the term  printmp3filecontent \" would be splitted into the  print \" ,  mp \" ,  3 \" ,  file \" , and  content \" terms",
    ". however , for the java programs properly following the coding standards , performance of a simple camelcase is adequate  @xcite . * _ expanding abbreviations : _ abbreviations ( e.g. ,  pntr \" and  ptr \" ) must be expanded and turned into the complete words ( e.g. , ",
    "pointer \" ) to increase consistency .",
    "we use the _ amap _ approach  @xcite to automatically identify and expand abbreviations . * _ transforming to lowercases : _ we make all the words case - insensitive to increase consistency . * _ correcting the spelling of words : _ we noticed in our evaluations of crowdsummarizer that spelling errors are quite common in collected summaries .",
    "some users correct spelling errors using browser s spell checkers(e.g .",
    "the way that google does spelling correction  @xcite ) , and some do nt .",
    "hence , we use the spelling corrector provided by p. norvig to fix the errors .",
    "the core of all the spell checkers is a big text file which consists of about a million words from several public domains .",
    "using probability theory the algorithm chooses the most likely spelling correction for a word . * _ removing stopwords : _ as an important step in preprocessing the data set , we removed common english language stop words like  the \" ,  but \" ,  a \" ,  or \" , and so on . * _ stemming : _ stemming is the process of reducing derived words into their common word stem or root .",
    "an example of stemming is transforming the terms  cat \" ,  cats \" , and  kittens \" to the term  cat \" .",
    "there are different stemming algorithms , such as snowball s stemmer , lancaster s stemmer , porter s stemmer and wordnet s lemmatizer , that reduce words to their morphological root .",
    "we use _ _ wordnet lemmatizer _",
    "_ for this purpose .",
    "we carried out the above steps to extract the keywords of each method @xmath0 , and each of its submitted summaries @xmath1 , called @xmath2 and @xmath3 , respectively .",
    "thus , for a method @xmath0 , the common keywords between that method and its corresponding summary @xmath1 can be computed as follows :    @xmath4    @xmath5 is the set of all the synonyms of the words in @xmath2 .",
    "we used the _ _ wordnet _ _ lexical database to find the synonyms of each word .",
    "for example , suppose the words  calculate \" in the name ,  bike \" in the parameters list , and  copy \" in the body of a method . while summarizing that method , some developers might have used exactly the same words , while others might have used their synonyms like  compute \" ,  bicycle \" , and  duplicate \" , respectively .",
    "consequently , these pairs of words ( i.e. , (  calculate \" ,  compute \" ) , (  bike \" ,  bicycle \" ) , and (  copy \" ,  duplicate \" ) ) must be considered the same when we calculate the degrees of importance of different parts of a method to be present in its corresponding summary .",
    "hence , we take into account the synonyms of words to increase the precision of results .    to compute the weight of each word in the set of @xmath6 ,",
    "we first calculate the weight of that word in that method and each of its summaries in the following way :    @xmath7    @xmath8    then , for each word in the @xmath6 , we compute a normalized weight , which means the rate of using the method words in a summary , as follows :    @xmath9    next , @xmath10 is the average of normalized weights for the keyword @xmath11 amongst all the summaries submitted for a method .",
    "after this , we map each keyword to various parts of the methods to see which parts are more frequently used in the summaries .    in our evaluations of crowdsummarizer with 149 developers of various levels of experience ( see section  [ sec : eval ] ) , we noticed that various properties of methods impact on the weights of different code parts .",
    "thus , we categorised the methods based on the following metrics :    * _ length of lines _ : small(3 < = loc < = 20 ) , medium ( 20 < = loc < = 70 ) , large ( loc > = 70 ) * _ length of parameter lists _ : none , 1 < = no .",
    "parameters < = 3 , 3 < no . parameters . * _ type of return value _ : vector , boolean , numbers ( integer , float and etc . ) , string ( char or an array of chars ) , object and etc . * _ methods with the highest fan - in _ : methods which are called the most . * _ methods with the highest fan - out _ : methods which call too many methods . * _ the type of work that it does _ ( _ _ method stereotype__@xcite ) : interacting , command and collaborator methods . * _ static methods_.    additionally , we noticed that developers mainly consider the following parts of a method , in the following order of importance , when they write their summaries :    1 .",
    "method s name and return type , 2 .   parameters , 3 .   ending units ( e.g. , _ return _ statements , _ printout _ statements , etc . ) , 4 .   method invocations , 5 .   branches ( i.e. , _ if _ and _ switch _ statements ) , 6 .   loops ( i.e. , _ for _ , _ while _ , and _ do - while _ statements ) , 7 .",
    "assignments , 8 .   local variables , and 9 .",
    "error handlings ( e.g. , _ try - catch _ , _ exception _ , _ throw _ , etc . ) .",
    "keywords in the method are tagged with the above ordered list ( i.e. if a keywords belongs to both _",
    "method name _ and _ local variable _ , we count it in _ method name _ area ) , using abstract syntax tree(ast ) . finally , we have an average weight for each of these items according to different properties of methods which we discussed earlier .",
    "table  [ tab : weights ] shows the weights of the three categories of methods .    if a method belongs to different categories we calculate average weight for its different code areas .",
    "so far , we have keyword weights for the different portions of the method for different kinds of the methods .",
    "the goal of this step is to select the most important keywords for describing a method . in information retrieval ,",
    "( _ term frequency inverse document frequency _ )  @xcite , is a numerical statistic that reflects how important a word is to a document in a corpus .",
    "the first part(i.e . _",
    "tf _ ) gives us importance of a word in a document by counting the number of times that the word occurs in the document .",
    "the latter is about the words which appear in the large number of documents , so it seems that these are not important for this specific document  @xcite . in the other words ,",
    "the goal is to give the high weights to the rare words and the low weights to the frequent words .",
    "the _ tf idf _ factor is widely used in natural language text processing and also in text summarization  @xcite .",
    "however , the problem with using it in code summarization is that it treats the source code as a plain text , and hence , the words in different parts of a method are treated equally .",
    "for example , the words in the method signature are treated the same as the words in a _ while _ loop .",
    "however , we discussed in the previous section that developers distinguish between various parts of a method . to address this issue",
    ", we also consider the weight factor computed in the previous step .",
    "more specifically , the importance of a term @xmath12 , in a method @xmath0 , in the program @xmath13 can be computed using the semicode displayed in listing [ lst : importance ] .    ....",
    "calcimportanc(term t , method m , program p ) {    tf = the number of occurrences of t in m ;    n = the number of methods in p ;    df= the number of methods in p which t occurs in ;    idf = log ( n / df ) ;    tf - idf= ( 1 + log tf)*idf ;    weight = getweightfromweightsdb(t , m ) ;    importance = tf - idf * weight ;    return importance } int getweightfromweightsdb(term t , method m ) {    methodcategory = identifymethodcategory(m):// which category is this method belongs to according to method properties .",
    "termarea = identifytermareainmethod(t);// which 9 area is this term belongs to    return ( weight(methodcategory , termarea ) ) ; } ....    in short , based on the observation that we had on the length of the crowd summaries(see section [ discussion ] ) , the number of keywords selected for the summary of a method is related to the complexity of that method  @xcite .",
    "the last step of our approach is to automatically generate the summaries of methods in the form of natural language sentences . for this purpose ,",
    "we use a number of templates that were extracted from the summaries written by the crowd in the crowdsummarizer platform for different kinds of methods .",
    "for instance , it was observed in our evaluations that developers in 90% of the time use the terms  till \" or  until \" instead of the java keyword _ while _ in their summaries . as another example , the methods that return a value of type _ boolean _",
    ", in 86% of cases has the term  check \" in their summaries .",
    "if the method has a list of parameters , for example _ v1 , v2 _ and _ v3 _ , users write just the last index of variable in their summaries ( i.e. three parameters ) . for conditions , _ while , if , case , for _ and etc . , instead of operators , like = = , ! = , < and > , the words _ equal _ , _ not _ _ equal _ , _",
    "smaller_(lower , less than ) and _ greater_(higher , bigger ) are used , respectively .",
    "there is a great deal of this information which we used to generate templates for each portions of the method .",
    "the further details about the templates are shown in figure  [ fig : templates ] .",
    "the crowdsummarizer approach introduced in this article is fully automated and is implemented as an eclipse plugin as well as a web - based game which is implemented in _",
    "python_. the crowdsummarizer s eclipse plugin takes a java program as input and automatically outputs the hierarchical structure of the latent topics in that program ( see section  [ sec : topic - model ] ) as well as the natural language summaries generated automatically for the methods of that program ( see section  [ sec : automatic_summary ] ) . furthermore , upon user s request , it submits those methods to crowdsummarizer s web - based game for the summarization by the crowd ( see section  [ sec : crowdsourcing ] ) .",
    "a demonstration of our implementations of crowdsummarizer is available online  @xcite .",
    "in this section , we explore an example of automatically generating a summary for a specific method . consider the method @xmath14 from the application jasperreports ( see figure  [ fig : example - method ] ) .",
    "at first we perform preprocessing steps discussed in section  [ sec : automatic_summary ] to refine the method keywords . now for each of the refined keywords we must compute its importance factor(see listing [ lst : importance ] ) .",
    "we run javapaser on this method to extract each area which each keyword belong to .",
    "additionally , we consider the properties of the method(see section  [ sec : automatic_summary ] ) to identify the method category .",
    "this method has no attribute list and 7 code lines . using the program call graph",
    "we understand that this method is kind of _ collaborator _ method which called so many times by the other methods .",
    "thus we use the average weights for the method keywords using these two kinds of data .",
    "the next step is to select the top - n keywords . as we discussed in section",
    "[ sec : automatic_summary ] and section [ length ] the lengths of the summaries are affected by the method complexity .",
    "we compute its complexity by considering method lines , conditional statements and etc .",
    "@xcite which results the value 5 for this method .",
    "therefore , we select the following top 5 keywords to generate the summary :    1 .",
    "_ get icon _ : method name 2 .",
    "_ icon = = null _ : branches 3 .",
    "_ get resource _ : method invocation 4 .",
    "_ try catch _ : exception mechanism 5 .",
    ". icon _ : ending unit    we use the templates for each code area and put the sentences together to generate a paragraph for describing the method . the fully combined summary is shown in figure  [ fig : example - summary ] .    ,",
    "the crowdsummarizer platform was evaluated by two user study experiments .",
    "the first one evaluates the applicability of the crowdsourcing approach for code summarization ( section  [ sec : eval : csapplicability ] ) , while the second one evaluates the quality of automatically generated summaries ( section  [ sec : eval : csresultsquality ] ) .",
    "the main research question that this empirical study intends to answer is  whether the crowdsummarizer platform is applicable and motivating for developers to use it in practice ? \"      [ [ methodology . ] ] methodology .",
    "+ + + + + + + + + + + +    at the end of the game , we asked participants to fill out a questionnaire which consisted of two parts .",
    "the first part included the questions about the applicability and usefulness of the game in practice , and the ways in which our proposed approach could be improved .",
    "however , the second part was about opinions about source code summarization and different factors impact on it .    [",
    "[ selecting - of - methods . ] ] selecting of methods .",
    "+ + + + + + + + + + + + + + + + + + + + +    we collected about 4000 summaries for 128 different methods , with an average of 19 summaries for each method . to increase the generalizability of the results , the methods were selected from 11 different applications from various domains ( e.g. , text editors , multimedia , games , etc . ) of different sizes ( including 318 to 12793 methods ) .",
    "moreover , from each application , a set of methods with various properties were chosen ( e.g. , number of lines of code , number of parameters , type of return values , etc . ) .",
    "see table [ tab : lenght_method ] for more details .",
    "[ [ participants . ] ] participants .",
    "+ + + + + + + + + + + + +    to answer the above research question , we asked 149 developers , with an average of 5.29 years of programming experience , to play the crowdsummarizer s web - based game .",
    "the details are shown in table [ tab : number - of - participants-1 ] .",
    "[ [ metrics . ] ] metrics .",
    "+ + + + + + + +    questions are kinds of multiple choice questions which we assigned a values to the answers as higher value for stronger performance and preferred answer .",
    "[ [ crowdsummarizer - applicability - results . ] ] crowdsummarizer applicability results .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    table [ tab : applicability ] summarizes the feedbacks developers gave us at the end of the game about the crowdsummarizer platform .",
    "as can be understood from these results , crowdsummarizer is applicable and motivating for developers to use it in practice .",
    "in addition , users answers to open - ended question also reflected their positive feeling about the crowdsummarizer game .",
    "here is some answers :    _ \" first of all i want to say that gamification elements such as , badges , points and etc . , had increased attractiveness of the game we were playing and are strength of the projects . _    _ _    even with making these elements more complicated , you can attract more fans . \"",
    "`` the strategic plan of the site is very good and provocative .",
    "try to improve scoring mechanism . ''",
    "although , we got more positives responses , but there are still rooms for improvement in some aspects of the approach .",
    "for instance , users felt that the evaluation part of the game was a little boring .",
    "|p7cm|c|c|c|c|c|s| & + questions & 1 & 2 & 3 & 4 & 5 & avg + how enjoyable is it to play?(1=least , 5=most ) & 10 & 13 & 30 & 41 & 55 & 3.79 + how easy / difficult is it to play?(1=most difficult , 5=easiest ) & 9 & 16 & 49 & 52 & 23 & 3.42 + how successful was the website in encouraging you to summarize the codes?(1=poor,5=excellent ) & 7 & 12 & 19 & 42 & 69 & 4.03 + how successful was the website in showing the importance of code summarization?(1=poor,5=excellent ) & 10 & 14 & 54 & 41 & 30 & 3.44 + how successful was the website in enhancing your code summarizatoin skill?(1=poor,5=excellent ) & 10 & 13 & 42 & 49 & 35 & 3.57 +    [ [ participants - opinions - about - source - code - summarization . ] ] participants opinions about source code summarization .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    questions and related answers about source code summarization from participants viewpoints are shown in table [ tab : questionnaire_results_opinion_1 ] and table [ tab : questionnaire_results_opiopn_2 ] .",
    "|p10cm|s| questions & average point + how important do you think it is to summarize a code?(1=not important,5=very important ) & 3.85 + to what degree should contextual information about a method such as its callers be included in summaries of the code?(1=not important , 5=highly included ) & 3.26 + to what extent can the file structure of the source code ( i.e quality of the code ) affect the quality of summarization?(1=not important,5=highly affective ) & 3.46 + how similar should the text in summaries be to the text and keywords in the source code like method names ? ( 1=not similar,5=very similar ) & 3.7 +        this empirical study is conducted to answer the following research questions about the automatically generated summaries :    * what is the quality of crowdsummarizer s generated summaries in terms of _ accuracy _ , _ comprehensibility _ , and _ experts satisfaction _ ?",
    "* are the results of crowdsummarizer better than existing code summarization approaches ?    in the first research question , _ accuracy _ means how accurate the latent topics are extracted from the program and how accurate the methods are tagged with those topics ; _ comprehensibility _ indicates how understandable the generated summaries are for developers ; and _ experts satisfaction _",
    "measures to what extent the developers are satisfied with the automatically generated summaries .",
    "[ [ methodology.-1 ] ] methodology .",
    "+ + + + + + + + + + + +    our evaluation process to answer the two research questions has three phase :    1 .   to measure the accuracy of results",
    ", we gave the participants 3 java programs from the first experiment together with 10 topmost topics and 10 methods tagged with those topics from each program .",
    "we asked them to go through the program and then evaluate the accuracy of the lda output .",
    "2 .   afterwards , to measure the comprehensibility and satisfiability of results , we gave our experts 12 randomly selected methods from the java programs used in the first study to 1 ) read the methods , and 2 ) write summary in their own words for each one , then , we displayed the summaries generated automatically by our approach for each method and 3 ) asked them to evaluate generated summary by answering the questions about comprehensibility and satisfiability of the results .",
    "3 .   to answer the second research question",
    ", we compared the results of our approach with the results of the _ eye - tracking _",
    "approach  @xcite which is the closest work to ours .",
    "as we mentioned in previous step , we asked our recruited experts to write their own summaries for 12 randomly selected methods from our java programs .",
    "next , we compared the keywords extracted by our approach and by the eye - tracking approach to the keywords chosen by the experts in terms of _ precision _ , _ recall _ , _ f - score _ , and _",
    "overall accuracy_.    [ [ selecting - of - programs - and - methods . ] ] selecting of programs and methods .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we selected ( randomly ) 78 methods from the same java applications that we used in the first study .",
    "users were assigned to see the 12 methods of the 78 methods available .",
    "we also randomly selected the 3 of these 11 applications for each participant to evaluate lda output .",
    "[ [ participants.-1 ] ] participants .",
    "+ + + + + + + + + + + + +    we recruited 14 expert developers who were different from those who participated in the first study ( section  [ sec : eval : csapplicability ] ) .",
    "all of them are graduate students from the computer engineering department at sharif university of technology and isfahan university of technology with an average of 5.5 years experience in java programming , 8 years in general programming and industry experience , ranging between 1 and 7 years ( see table [ tab : number - of - participants-2 ] ) .",
    "[ [ metrics - and - test . ] ] metrics and test .",
    "+ + + + + + + + + + + + + + + + +    the first research question consists of three multiple choice questions which we assigned a values to the answers as higher value for stronger performance and preferred answer . for the second research question we compared the keywords extracted by our approach and by the eye - tracking approach to the keywords chosen by the experts .",
    "using this , we were able to compare the two approaches in terms of _ precision _ , _ recall _ , _ f - score _ , and _ overall accuracy _ , which are computed as follows :    @xmath15    @xmath16    @xmath17    in which @xmath18 are keywords extracted from the summary which is the output of the summarization approach and @xmath19 are keywords extracted from human expert s summaries .",
    "nenkova et  al .",
    "@xcite assert that recall is more effective in the evaluations of summaries than the precision . in the case using computing precision , perhaps some of the sentences returned by the approach are good enough , although they have not been chosen by the gold standard summary .",
    "human judges often disagree on what the top n% most important sentences are in a document . on the other hand , recall measures the overlap with already observed sentence choices . in other words , a precision value equal to one means that all the terms in the peer summary are relevant , though there could be relevant terms missing . on the other hand",
    ", a recall value equal to one means that the peer summary contains all the relevant terms , though it could also contain some irrelevant terms .",
    "hence , there are some quality compromises between precision and recall that f - score is used to handle these problems .    as sridhara discussed in her paper  @xcite , there are two other factors in addition to the accuracy that must be computed for evaluating a generating summary approach ; content adequacy and conciseness . however we can equivalent these factors to precision and recall , respectively .    finally , the _ overall accuracy _ , that indicates the rate of correctly extracted keywords , and is computed as follows : @xmath20 in which , _ tp _ ( _ true positives _ ) is the number of keywords correctly extracted by the approach ; _ tn _ ( _ true negatives _ ) is the number of keywords correctly not extracted by the approach ; _ fp _ ( _ false positives _ ) is the number of keywords incorrectly extracted by the approach ; and _ fn _ ( _ false negatives _ ) is the number of keywords incorrectly not extracted by the approach .",
    "this section presents the results of the evaluation of a user experiment in which subjects are asked to write summaries for a set of methods and assess the quality of our generated summaries .",
    "[ [ quantitative - results . ] ] quantitative results .",
    "+ + + + + + + + + + + + + + + + + + + + +    figures  [ fig : results]-[fig : results ] illustrate the results of empirical evaluations of the quality of crowdsummarizer s automatically generated summaries .",
    "as can be seen in these figures , most of the experts participated in our study were satisfied with the quality of generated summaries in terms of accuracy and comprehensibility .",
    "additionally , as indicated in figure  [ fig : results ] , crowdsummarizer outperforms the eye - tracking approach in terms of precision , recall , f - score , and overall accuracy .",
    "this finding indicates that the different areas in the different kinds of methods must have different weights according to the users priorities .",
    "[ [ qualitative - results . ] ] qualitative results .",
    "+ + + + + + + + + + + + + + + + + + + +    this section reports participants opinions about automatically generated summaries .    _  the automated summaries are well defined for simple and illustrative methods .",
    "the sentences are all intelligently produced and the length of summery is appropriate .",
    "but it should be noted that for big and complicated methods the sentences are not such intelligently made and we see the actual variables and code lines in summary while we expect to see more user friendly words and shorter sentences in summary text . \" _    _  the summaries explained the function parameters and variables well , but explaining the purpose of the methods can be improved . \" _",
    "_  the summarizer produces short explanations about each method .",
    "the summary s length seems adequate to me , moreover the input and output declarations are understandable . also the text defines each function call clearly which helped me understand the relations between several functions .",
    "however i did not feel comfortable about condition description template , it is so much similar to the code . \" _",
    "there are several factors that may potentially affect the validity of the results of this experiment .",
    "this section provides a description of these factors .",
    "[ [ internal - validity . ] ] internal validity .",
    "+ + + + + + + + + + + + + + + + + +    the main threat in this part is the distribution of participants over the methods .",
    "we addressed this threat by assigning methods from different programs to participants randomly .",
    "as the second point , implementation of swum is another factor which influence on the generated summaries .",
    "[ [ external - validity ] ] external validity + + + + + + + + + + + + + + + + +    the main threat to external validity concerns the programs and the methods had been selected and it may be deducted that our summariztion approach is prominent for a set of determined methods .",
    "we minimized this threat by selecting 78 methods from 11 applications across different domains and different sizes .",
    "also , stress , human errors and fatigue are effective factors that decrease reliability of the results .",
    "we addressed this threat by selecting the great number of participants from a diverse range of experience with at least 1 years of experience .",
    "[ [ construct - validity ] ] construct validity + + + + + + + + + + + + + + + + + +    the main source for a threat to construct validity is that we need well - defined measures to compare the effectiveness of different source code summarization approaches .",
    "we used the standard measures used in the summarization literature  @xcite  @xcite , such as _ precision _ , _ recall _ , _ accuracy _ , _ content adequacy _ and _ conciseness_. all the summaries used in the second study are generated by the crowdsummarizer tool for the methods from the open - source java applications used in the other approaches .",
    "[ [ replicability ] ] replicability + + + + + + + + + + + + +    the natural language templates used generating summaries , the data collection , the experimental materials , including the subjects background questionnaires , experiment questionnaires are available online  @xcite .",
    "here , we explain our experiences and lessons learned during the crowdsourcing process .      as evidenced by the results , for the 4000 summary in initial examination of the crowdsummarizer , developers select the number of keywords in their summaries based on the method complexity , not just length of the method . as an example",
    ", they used 6 keywords(as average ) in their summaries for a method with 41 keywords , and 7 keywords(as average ) for a method with 242 keywords .",
    "meanwhile , 14 keywords is an average for the number of keywords in the summaries for a method with length of 87 keywords ( table [ tab : lenght_method ] ) .",
    "the main difference that affects on the length of summaries of the method with 87 keywords and the method with 242 keywords is in conditional statements that the former has which includes three _ for _ loops , one _ while _ loop and two _ switch _ statements .      specially , we computed a factor _ summary and method overlap(smo ) _ as follows : @xmath21    where @xmath22 , @xmath2 and @xmath23 are the sets of the terms extracted from the summary @xmath1 , method @xmath0 and synonym set of method @xmath0 , respectively .",
    "the measure has a value between [ 0 , 1 ] , that a higher value shows more use of method keywords in summaries .",
    "indeed , based on  @xcite , we expect that if a summaries get a higher @xmath24 value it will get more acceptance from the developers .",
    "we observed that , methods with more than 2 parameters and methods with the highest fan - out have the highest @xmath24 values .",
    "in addition , table [ tab : smo ] shows that , although , people with less programming experience use more method keywords in their summaries , but there is no obvious relationship between @xmath24 measure and developer s programming experience(i.e .",
    "programmers in the all levels of experience use the method words in their summaries with the close rate . )",
    "this section will cover the related works on source code summarization as well as code documentation using the crowdsourcing concept .",
    "the most related work to crowdsummarizer is the eye - tracking approach  @xcite which is an improvement of the technique proposed by haiduc et  al .",
    "@xcite for extracting the most relevant keywords from a method by applying the text retrieval technique vsm tf - idf .",
    "this approach uses an eye - tracking system to get data about the keywords that programmers view as important while summarizing a method .",
    "however , this approach has some drawbacks like the limited length for the methods it can summarize , the few numbers of people who participated in its study , and fatigue which affects the eye tracking results .",
    "g. sridhara  @xcite uses a number of heuristics in his phd thesis to automatically generate a natural language description about just those program statements of a method that implement a particular behavior .",
    "thus , unlike our approach , it does not generate summaries for the whole method .",
    "rastkar et  al .",
    "@xcite proposed a different approach to improve productivity of developers in maintenance phase by generating summaries for cross - cutting concern in source code .",
    "the summaries describe parts of a concern and its interaction with other concerns .",
    "moreno et  al .",
    "@xcite presented a different approach to generate natural language summaries for java classes based on the class s stereotype and heuristics .",
    "the purpose of this approach is to give information about the class s responsibilities and not the relationship with other classes .",
    "a similar work based on stereotypes and static analysis is introduced by abid et  al .",
    "@xcite for generating summaries for c++ methods .",
    "the methods stereotypes in this approach are identified by the approach  @xcite .    describing high level actions using topic modelling approaches",
    "are also considered in  @xcite and  @xcite .",
    "eddy et  al .",
    "@xcite replicated and expanded the approach proposed by haiduc et  al .",
    "@xcite by introducing hirarchical pachinko allocation model(hpam ) , as a new topic modelling technique .",
    "mcburney et  al .",
    "@xcite proposed an approach to extract topics in source code using program s call graph and a topic modelling approach named hierarchical document topic model ( hdtm ) .",
    "a recent work in  @xcite helps programmers understand the role a method plays in a program .",
    "in particular , it summarizes the context of a method , like how it is called or its output is used .",
    "consequently , it does not summarize the method itself .",
    "there are other works which generate descriptions for other software artifacts , such as bug reports  @xcite and execution traces  @xcite .",
    "we tried to tackle the restrictions of existing approaches by using the power of the crowd as the source of valuable information to generate summaries , as well as using the lda technique to extract latent topics in a program .",
    "crowdsourcing has attracted significant recent attentions to support a wide range of software engineering activities , such as requirement , design , coding , testing and evolution and maintenance . here , we briefly discussed crowd software documentation that is the closest to our work .",
    "jiau and yang  @xcite enhanced inequality of documentation based on object oriented inheritance using documentation reuse . conducting an empirical study on the three java apis in stack overflow showed their approach feasibility .",
    "pawlik et  al .",
    "@xcite conducted a case study using a python library for scientific computing called numpy .",
    "the case study highlighted benefits of using crowdsourcing in software documentation as well as considerations in planning , organizing and implementing crowdsourcing for software documentation .",
    "parnin et  al .",
    "@xcite showed that question and answer websites , such as stack overflow can be used for creating software documentation by using api functionality discussions and code examples .",
    "as it turns out , stack overflow is one of the best sources for creating code documentation , however , no consensus has developed around generating a natural language high quality summary for a method .",
    "the key difference between our approach ( as well as other summarization approaches ) and these existing approaches is that documentation techniques , such as javadocs  @xcite work on combining short paragraphs attached to each method to create a code document and ignore the way that this short paragraphs are created ( manual ( i.e. human written ) or automatically ) , while code summarization techniques generate descriptions about a piece of a code ( i.e. the short paragraph itself ) . indeed , the code summaries can be considered as the main components of the program document .",
    "in addition , one of the challenges of evaluating code summarization techniques is the cost of the empirical studies involving users assessing different intrinsic quality attributes of summaries .",
    "the crowdsourced - based summaries represent a good starting point to build a benchmark or gold set that allows to perform a quantitative , intrinsic assessment of those quality attributes would facilitate and reduce the cost of of evaluating code summarization techniques",
    "this article introduced crowdsummarizer , a novel approach for automated generation of natural language summaries for java programs and their methods . to this end , crowdsummarizer employs the concepts of crowdsourcing , gamification , and natural language processing .",
    "furthermore , it applies the lda technique to identify the latent topics in a java program , and to classify its methods into those topics .",
    "we have implemented crowdsummarizer as an eclipse plugin that works with a web - based code summarization game that can be played by the crowd .",
    "the results of an empirical study conducted by 149 developers with different levels of experience illustrated that crowdsummarizer is applicable and motivating for developers to use it in practice .",
    "moreover , the results of another empirical study done with the help of 14 experts indicated that developers are satisfied with the quality of automatically generated summaries in terms of accuracy and comprehensibility . in future , crowdsummarizer can be easily extended to include other programming languages like c++ as well .",
    "in addition , we plan to work on other text retrieval techniques to extract keywords from the method .",
    "we also intend to generate natural language summaries for classes using the crowd and the crowdsummarizer .",
    "finally , we want to use dynamic analysis in combination of static and linguistic information .",
    "the authors would like to thank dr .",
    "dave binkley for providing identifier splitting . finally , they would also like thank the 149 participant who spent time for assessing the crowdsummarizer platform and all the 14 subjects who participated in the user study experiment .",
    "a.  j. ko , b.  myers , m.  j. coblenz , h.  h. aung , _",
    "et  al . _ , `` an exploratory study of how developers seek , relate , and collect relevant information during software maintenance tasks , '' _ ieee transactions on software engineering _ , vol .",
    "32 , no .  12 , pp .  971987 , 2006 .",
    "s.  haiduc , j.  aponte , l.  moreno , and a.  marcus , `` on the use of automated text summarization techniques for summarizing source code , '' in _ proceedings of the 17th working conference on reverse engineering _ , pp .  3544 , ieee , 2010 .",
    "e.  linstead , p.  rigor , s.  bajracharya , c.  lopes , and p.  baldi , `` mining concepts from code with probabilistic topic models , '' in _ proceedings of the 22nd international conference on automated software engineering _ , pp .  461464 , acm , 2007 .",
    "c.  forlines , s.  miller , l.  guelcher , and r.  bruzzi , `` crowdsourcing the future : predictions made with a social network , '' in _ proceedings of the 32nd conference on human factors in computing systems _ , pp .  36553664 , acm , 2014 .",
    "p.  rodeghero , c.  mcmillan , p.  w. mcburney , n.  bosch , and s.  dmello , `` improving automated source code summarization via an eye - tracking study of programmers , '' in _ proceedings of the 36th international conference on software engineering _ , pp .  390401 , acm , 2014 .",
    "o.  feyisetan , e.  simperl , m.  van  kleek , and n.  shadbolt , `` improving paid microtasks through gamification and adaptive furtherance incentives , '' in _ proceedings of the 24th international conference on world wide web _ , pp .  333343 , acm , 2015 .",
    "l.  guerrouj , p.  galinier , y .- g .",
    "guhneuc , g.  antoniol , and m.  di  penta , `` tris : a fast and accurate identifiers splitting and expansion algorithm , '' in _ proceedings of the 19th working conference on reverse engineering _ , pp .  103112 , ieee , 2012 .    e.  hill , z.  p. fry , h.  boyd , g.  sridhara , y.  novikova , l.  pollock , and k.  vijay - shanker , `` amap : automatically mining abbreviation expansions in programs to enhance software maintenance tools , '' in _ proceedings of the 5th international working conference on mining software repositories _ , pp .",
    "7988 , acm , 2008 .    c.  whitelaw , b.  hutchinson , g.  y. chung , and g.  ellis , `` using the web for language independent spellchecking and autocorrection , '' in _ proceedings of the conference on empirical methods in natural language processing _ , pp .  890899 , association for computational linguistics , 2009 .",
    "n.  dragan , m.  l. collard , and j.  i. maletic , `` using method stereotype distribution as a signature descriptor for software systems , '' in _ proceedings of the 25th international conference on software maintenance _ , pp .",
    "567570 , ieee , 2009 .",
    "s.  scalabrino , m.  linares - vsquez , d.  poshyvanyk , and r.  oliveto , `` improving code readability models with textual features , '' in _ proceedings of the 24st international conference on program comprehension _ , ieee , 2016 .",
    "a.  nenkova , s.  maskey , and y.  liu , `` automatic summarization , '' in _ proceedings of the 49th annual meeting of the association for computational linguistics _ , p.  3",
    ", association for computational linguistics , 2011 .",
    "g.  sridhara , e.  hill , d.  muppaneni , l.  pollock , and k.  vijay - shanker , `` towards automatically generating summary comments for java methods , '' in _ proceedings of the 25th international conference on automated software engineering _ , pp .  4352 , acm , 2010 .",
    "s.  rastkar , g.  c. murphy , and a.  w. bradley , `` generating natural language summaries for crosscutting source code concerns , '' in _ proceedings of the 27th international conference on software maintenance _ , pp .  103112 , ieee , 2011 .",
    "l.  moreno , j.  aponte , g.  sridhara , a.  marcus , l.  pollock , and k.  vijay - shanker , `` automatic generation of natural language summaries for java classes , '' in _ proceedings of the 21st international conference on program comprehension _ , pp .",
    "2332 , ieee , 2013 .",
    "n.  j. abid , n.  dragan , m.  l. collard , and j.  i. maletic , `` using stereotypes in the automatic generation of natural language summaries for c++ methods , '' in _ proceedings of the 19th international conference on software maintenance and evolution _ , pp .",
    "561565 , ieee , 2015 .",
    "b.  p. eddy , j.  robinson , n.  kraft , j.  c. carver , _",
    "et  al . _ ,",
    "`` evaluating source code summarization techniques : replication and expansion , '' in _ proceedings of the 21st international conference on program comprehension _ , pp .",
    "1322 , ieee , 2013 .",
    "w. mcburney , c.  liu , c.  mcmillan , and t.  weninger , `` improving topic model source code summarization , '' in _ proceedings of the 22nd international conference on program comprehension _",
    ", pp .  291294 , acm , 2014 .",
    "s.  rastkar , g.  c. murphy , and g.  murray , `` summarizing software artifacts : a case study of bug reports , '' in _ proceedings of the 32nd international conference on software engineering _ , pp .  505514 , acm , 2010 .",
    "a.  hamou - lhadj and t.  lethbridge , `` summarizing the content of large traces to facilitate the understanding of the behaviour of a software system , '' in _ proceedings of the 14th international conference on program comprehension _ , pp .  181190 , ieee , 2006 .",
    "a.  pawlik , j.  segal , h.  sharp , and m.  petre , `` crowdsourcing scientific software documentation : a case study of the numpy documentation project , '' _ computing in science & engineering _ , vol .",
    "17 , no .  1 ,",
    "pp .  2836 , 2015 .",
    "is an assistant professor at the sharif university of technology .",
    "before , he was a post - doctoral fellow at the university of lugano , switzerland .",
    "abbas holds a phd from the university of waterloo , canada .",
    "his research interests focus on software evolution , mining software repositories , and recommendation systems in software engineering .",
    "contact him at heydarnoori@sharif.edu ."
  ],
  "abstract_text": [
    "<S> one of the first steps to perform most of the software maintenance activities , such as updating features or fixing bugs , is to have a relatively good understanding of the program s source code which is often written by other developers . a code summary is a description about a program s entities ( e.g. , its methods ) which helps developers have a better comprehension of the code in a shorter period of time . </S>",
    "<S> however , generating code summaries can be a challenging task . to mitigate this problem , in this article </S>",
    "<S> , we introduce _ crowdsummarizer _ , a code summarization platform that benefits from the concepts of crowdsourcing , gamification , and natural language processing to automatically generate a high level summary for the methods of a java program . </S>",
    "<S> we have implemented crowdsummarizer as an eclipse plugin together with a web - based code summarization game that can be played by the crowd . </S>",
    "<S> the results of two empirical studies that evaluate the applicability of the approach and the quality of generated summaries indicate that crowdsummarizer is effective in generating quality results . </S>"
  ]
}