{
  "article_text": [
    "multilayer neural networks have achieved state - of - the - art performances in image recognition  @xcite , speech recognition , and even natural language processing  @xcite .",
    "this impressive success is based on a simple powerful stochastic gradient descent ( sgd ) algorithm  @xcite , and its variants .",
    "this algorithm estimates gradients of an error function based on mini - batches of an entire dataset .",
    "gradient noises caused by mini - batches help exploration of parameter space to some extent .",
    "the parameter space is highly non - convex for a typical deep network training , and finding a good path for sgd to improve generalization ability of deep neural networks is thus challenging  @xcite .",
    "as found in standard spin glass models of neural networks  @xcite , a non - convex error surface should be accompanied by exponentially many local minima , which hides the ( isolated ) global minima and thus makes any local search algorithms easily get trapped . in addition , the error surface structure of deep networks might behave similarly to random gaussian error surface  @xcite , which demonstrates that critical points ( defined as zero - gradient points ) of high error have a large number of negative eigenvalues of the corresponding hessian matrix .",
    "consistent with this theoretical study , empirical studies on deep network training  @xcite showed that sgd is slowed down by a proliferation of saddle points with many negative curvatures and even plateaus ( eigenvalues close to zero in many directions ) .",
    "the prevalence of saddle points poses an obstacle to attain better generalization properties for a deep network , especially for sgd based on first - order optimization , while computational complexity of second - order optimization relying on hessian - vector products does not scale well in training large deep networks  @xcite .",
    "many heuristic strategies were proposed to overcome the difficulty sgd encounters .",
    "for example , adding noise to gradients corresponds to randomly perturbing the @xmath0-spin interaction spherical glass model by adding an external magnetic field  @xcite .",
    "regularization techniques such as dropout  @xcite can also be explained in this framework , although it relies on unrealistic assumptions  @xcite from a practical deep network perspective ( e.g. , input independence of active paths from input to output ) .",
    "another strategy is the use of local entropy  @xcite to bias sgd towards flat regions on the error surface , where a low test error is reached .",
    "the deep network shaped by the parameters in the flatter regions is less prone to over - fitting .    in this paper , we show another heuristic strategy to overcome the plateaus obstacle for sgd learning .",
    "we call this strategy reinforced backpropagation ( r - backprop ) , which provides a new effective strategy to use the gradient information , i.e. , not only the current gradient information but also the previous gradient information during training are used to update model parameters , with the property that the previous gradient information is used with a reinforcement probability that grows with the number of iterations",
    ". the growth of the reinforcement probability is characterized by two different time scales : one is at the mini - batch level , and the other is at the epoch level , which we shall describe in detail in the following sections .",
    "the excellent performance of r - backprop is verified first on training a toy fully - connected deep network model to learn a simple non - linear mapping generated by a two - layer feedforward network , and then on a benchmark handwritten digits dataset  @xcite , in comparison to both standard backpropagation ( backprop )  @xcite and state - of - the - art algorithm adam  @xcite .",
    "we consider a toy deep network model with @xmath1 layers of fully - connected feedforward architecture .",
    "each layer has @xmath2 neurons ( so - called width of layer @xmath3 ) .",
    "we define the input as @xmath4-dimensional vector @xmath5 , and the weight matrix @xmath6 specifies the symmetric connections between layer @xmath3 and layer @xmath7 .",
    "the same connections are used to backpropagate the error during training .",
    "a bias parameter can also be incorporated into the weight matrix by assuming an additional constant input .",
    "the output at the final layer is expressed as : @xmath8 where @xmath9 is an element - wise sigmoid function for neurons at layer @xmath3 , defined as @xmath10 .",
    "the network is trained to learn the target mapping generated randomly as @xmath11 , where the input is generated from a standard normal distribution with zero mean and unit variance , and the target label @xmath12 is generated according to the non - linear mapping @xmath13 , in which each entry of the data - generating matrix @xmath14 follows independently a standard normal distribution as well .",
    "the deep network is trained to learn this non - linear mapping from a set of examples .",
    "we generate a total of @xmath15 examples , in which the first @xmath16 examples are used for training and the last @xmath16 examples are used for testing to evaluate the generalization ability of the learned model .",
    "in simulations , we use deep network architecture of @xmath17 layers to learn the target non - linear mapping , in which the network is thus specified by @xmath18-@xmath19-@xmath20-@xmath21 , with @xmath4 indicating the dimension of the input data and @xmath22 the dimension of the output .",
    "we first introduce the standard backprop  @xcite for training the deep network defined in sec .",
    "we use quadratic loss function defined as @xmath23 , where @xmath24 denotes a vector ( matrix ) transpose operation , and @xmath25 defines the difference between the target and actual outputs as @xmath26 . to backpropagate the error",
    ", we also define two associated quantities : one is the state of neurons at @xmath3-th layer defined by @xmath27 ( e.g. , @xmath28 , @xmath29 ) , and the other is the weighted input to neurons at @xmath3-th layer defined by @xmath30 .",
    "accordingly , we define two related gradient vectors :    [ grad ] @xmath31    which will be used to derive the propagation equation based on the chain rule . it is straightforward to derive @xmath32 , where @xmath33 indicates the element - wise multiplication , and @xmath34 is the derivative of the non - linear transfer function with respect to its argument . by applying the chain rule , we obtain the weight update equation for the top layer as @xmath35 where @xmath36 is the learning rate , and the remaining part is the gradient information , which indicates how a small perturbation to the weight affects the change of the error computed at the top ( output ) layer .    to update the weight parameters at lower layers , we first derive the propagating equations for gradient vectors as follows :    [ backprop ] @xmath37    where @xmath38 . using the above backpropagation equation ,",
    "the weight at lower layers is updated as : @xmath39 where @xmath38 .",
    "the neuron state used to update the weight parameters comes from a forward pass from the input vector to the output vector at the top layer . a forward pass combined with a backward propagation of the error",
    "forms the standard backprop widely used in training deep networks given the labeled data  @xcite . to improve the training efficiency ,",
    "one usually divides the entire large dataset into a set of mini - batches , each of which is used to get the average gradients across the examples within that mini - batch .",
    "one epoch corresponds to a sweep of the full dataset .",
    "the learning time is thus measured in unit of epoch . for one epoch , the weight is actually updated for @xmath40 times ( @xmath41 is the size of a mini - batch ) .    in the above standard backprop ,",
    "only current gradients are used to update the weight matrix . therefore in a non - convex optimization , the backpropation gets easily stalled by the plateaus or saddle points on the error surface , and is hard to escape from these regions . to avoid the expensive second - order methods",
    ", we conjecture that the history of gradient information contains additional information about the landscape of the error surface , which can also be used to update the weight matrix , and might drive the learning dynamics towards dense regions with nice generalization properties .",
    "the dense region containing many good solutions can be accessed by maximizing a local entropy around some location in high dimensional parameter space , as observed previously in other studies of deep network training  @xcite . to enable sgd to use previous gradient information ,",
    "we define a stochastic process for gradients at each learning step as follows : @xmath42 where @xmath43 denotes the gradient estimated from the average over examples within the current mini - batch for specific weight @xmath44 , and correspondingly @xmath45 contains information about the history of the evolving gradients .",
    "@xmath46 is a value close to but smaller than one , which is updated at the epoch level , i.e. , @xmath46 decays very slowly as epoch increases .",
    "therefore the current gradient has an increasing probability to be reinforced by the previous gradients , and retains its current value otherwise .",
    "as @xmath47 grows , previous gradients are accumulated and affect the current update of model parameters with a probability approaching one .",
    "this fluctuation caused by the stochastic reinforcement may help the learning dynamics to escape from plateaus or bad - quality regions of the error surface at earlier learning stage . at the later stage ,",
    "the learning dynamics may be attracted by the dense region with nice generalization properties ( low test error ) , because the accumulated gradient information may give a strong bias towards the good region if the dynamics approaches it .",
    "this good region is expected to be flat on the loss landscape  @xcite , and contains atypical solutions to the non - convex deep neural network training  @xcite .",
    "we will test this intuitive interpretation by extensive training simulations of a toy deep learning model .",
    "( [ rbp ] ) is a very simple way to re - use the previous gradient information , and thus forms the key component of the r - backprop .",
    "in addition to eq .",
    "( [ rbp ] ) , we also introduce two time scales to control the dynamics for the reinforcement probability .",
    "the first time scale is given by @xmath48 , and the second time scale is set by @xmath49 for the exponential decay of @xmath50 , where @xmath51 refers to the learning time in unit of epoch .",
    "@xmath52 is usually fixed to a value very close to one .",
    "we show a typical trace of the reinforcement probability and @xmath46 in fig .",
    "[ reprob ] , and will test effects of hyper - parameters @xmath53 on training dynamics in sec .",
    "note that by setting @xmath54 , one recovers the standard backprop . in simulations , we use decaying learning rate @xmath55 , where @xmath56 and @xmath57 , but the lowest learning rate is allowed to be @xmath58 .    to show the efficiency of r - backprop , we also compare its performance with that of state - of - the - art stochastic optimization algorithm , namely adaptive moment estimation ( adam )  @xcite .",
    "adam performs a running average of gradients and their second raw moments , which are used to adaptively change the learning step - size .",
    "we use heuristic parameters of adam given in ref .",
    "@xcite , except that @xmath59 with the lowest value set to @xmath60 .",
    "large @xmath61 as we use in r - backprop does not work in the current setting for adam .    ) as a function of iterations .",
    "the inset shows exponential decay of @xmath46 ( @xmath62 ) .",
    "note that the learning time is measured in unit of epoch in the inset . ]",
    "we first compare backprop with r - backprop in performance .",
    "we use a @xmath63-layer deep network architecture as @xmath64-@xmath65-@xmath66-@xmath67 .",
    "training examples are divided into mini - batches of size @xmath68 . in simulations",
    ", we use the parameters @xmath69 , unless otherwise specified .",
    "although the chosen parameters are not optimal to achieve the best performance , we still observe the outstanding performance of r - backprop . in fig .",
    "[ comprbp ] ( a ) , we compare standard backprop with r - backprop .",
    "we clearly see that the test performance is finally improved at @xmath64-th epoch by a significant amount ( about @xmath70 ) . meanwhile , the training error is also significantly lower than that of backprop .",
    "a salient feature of r - backprop is that , in the intermediate stage , the reinforcement strategy guides sgd to escape from possible plateau regions of high error surrounding saddle points , and finally reach a region of very nice generalization properties .",
    "this process is indicated by the temporary peak in both training error and test error for r - backprop .",
    "remarkably , even before or after this peak , there are a few small but significant fluctuations in both training and test errors .",
    "these fluctuations are assumed to be key characteristics of r - backprop , caused by a probabilistic reinforcement of the gradient information .",
    "this procedure guides sgd to explore the huge dimensional parameter space more carefully .",
    "we conjecture that the previous gradients contain information about the non - convex structure of the parameter space , and can be re - used in a well - designed stochastic way at the early stage of learning ( see fig .",
    "[ reprob ] ) .",
    "but at the later stage , the sgd approaches the good region of better generalization capabilities , and in this case , the reinforcement strategy will accelerate the learning process .    compared to state - of - the - art adam ,",
    "r - backprop still improves the final test performance by a significant amount ( about @xmath71 , see fig .",
    "[ comprbp ] ( b ) ) .",
    "note that adam is able to decrease both training error and test error very quickly , but for the current setting , the decrease becomes slow after about @xmath72 epochs .",
    "in contrast , r - backprop keeps decreasing both errors by a more significant amount than adam , despite the presence of slightly significant fluctuations .",
    "a closer inspection of the later stage reveals that the excellent performance of r - backprop may be ascribed to the stochastic fluctuations introduced by the reinforcement probability .",
    "another key feature of fig .",
    "[ comprbp ] ( b ) is that , a region in the parameter space with low training error does not generally have low test error .",
    "the training error reached by r - backprop is clearly higher than that of adam , but the network architecture learned by r - backprop has nicer generalization property .",
    "this observation is consistent with recent study of maximizing local entropy in deep networks  @xcite .",
    "training examples .",
    "note that the test performance is improved by @xmath70 , compared with backprop , and by @xmath71 , compared with adam .",
    ", title=\"fig : \" ] .05 cm   training examples .",
    "note that the test performance is improved by @xmath70 , compared with backprop , and by @xmath71 , compared with adam .",
    ", title=\"fig : \" ] .05 cm    we then study the effects of reinforcement parameters @xmath53 on the learning performance , as shown in fig .  [ epara ] .",
    "if the exponential decay rate @xmath49 is large , r - backprop over - fits the data rapidly at around @xmath73 epochs .",
    "this is because , @xmath46 decays rapidly from @xmath52 , and thus a stochastic fluctuation at earlier stage of learning is strongly suppressed , which limits severely the exploration ability of r - backprop in the high - dimensional parameter space . in this case",
    ", r - backprop is prone to get stuck by bad regions with poor generalization performances .",
    "however , maintaining the identical small decay rate , we tune the initial value of @xmath46 , and find that a larger value of @xmath52 leads to a smaller test error ( inset of fig .",
    "[ epara ] ) . for relatively large values of @xmath52 ,",
    "the learning performance is not radically different .",
    "we also study the effects of training data size ( @xmath16 ) on the learning performances of all three algorithms compared in this paper .",
    "clearly , we see from fig .",
    "[ esamp ] , the test error decreases with the training data size as expected .",
    "r - backprop outperforms the standard backprop , and even adam .",
    "finally , we evaluate the test performance of r - backprop on mnist dataset .",
    "the mnist handwritten digit dataset contains @xmath74 training images and an extra @xmath75 images for testing .",
    "each image is one of ten handwritten digits ( @xmath76 to @xmath77 ) with @xmath78 pixels .",
    "therefore the input dimension is @xmath79 . for simplicity ,",
    "we choose the network structure as @xmath80-@xmath64-@xmath66-@xmath67 , with mini - batch size of @xmath68 for sgd . to save the simulation time",
    ", we show the performance only on @xmath81 training images .",
    "[ mnist ] shows that r - backprop improves significantly over backprop , reaching a similar test performance to that of adam .",
    "r - backprop achieves a test error of @xmath82 , compared to @xmath83 for backprop , and @xmath84 for adam .",
    "the test error is averaged over five independent runs ( different sets of training and test examples ) .",
    ", @xmath49 ) on the learning performance for r - backprop based on @xmath81 training examples .",
    "the inset is an enlarged view for the later stage ( the worst performance with ( @xmath85,@xmath60 ) is omitted for comparison ) .",
    ", title=\"fig : \" ] .05 cm     .05 cm     training examples , compared with backprop and adam . , title=\"fig : \" ] .05 cm",
    "in this paper , we propose a new type of effective strategy to guide sgd to avoid the plateau problem in typical non - convex error surface of deep neural networks .",
    "this strategy takes into account previous gradient information when updating current weight matrix during standard backprop .",
    "it introduces a stochastic fluctuation to current gradients , and this fluctuation comes from previous memory of the error surface structure .",
    "hence this fluctuation is essentially different from an independently random noise added to the gradient during the learning process  @xcite .",
    "r - backprop seems to work under a similar mechanism to maximizing a local entropy around some location in high dimensional parameter space  @xcite , because r - backprop is able to cross barriers on the error surface and reach a region with better generalization properties , and this region was conjectured to be typically wide , and have possibly a higher error than the global minimum . by maximizing the local entropy ,",
    "the entropy - driven sgd proposed in the recent work  @xcite requires additional markovian chain monte carlo sampling to evaluate the gradient of local entropy .",
    "in contrast , our method is much more less expensive in computational cost , and thus can be scalable to modern deep network training .",
    "this is because r - backprop uses only gradient information , requiring less computer memory . in current",
    "setting , its performance is comparable to or even better than that of adam , which requires one - fold more computer memory to store the uncentered variance of the gradients .",
    "it is very interesting to evaluate the performance of r - backprop on more complicated deep network model and complex datasets .    instead of using only the current gradient information at each learning step as in standard backprop",
    ", we apply the reinforcement strategy to guide the normal sgd towards good - quality regions of parameter space . to some extent ,",
    "r - backprop may be able to avoid vanishing or exploding gradient problem typical in training a very deep network  @xcite .",
    "in addition , it may take effect in recurrent neural network training  @xcite .",
    "although r - backprop is proved to be an effective strategy to explore the extremely huge parameter space , it remains an open question how the structure of the error surface is connected to the efficiency of r - backprop .",
    "therefore theoretical understanding of the intrinsic structure of the error surface is still an extremely challenging problem in future studies .",
    "thanks dr .",
    "alireza goudarzi for a lunch discussion which later triggered h.h .",
    "to have the idea of this work .",
    "this work was supported by the program for brain mapping by integrated neurotechnologies for disease studies ( brain / minds ) from japan agency for medical research and development , amed , and by riken brain science institute .",
    "alex krizhevsky , ilya sutskever , and geoffrey  e. hinton .",
    "imagenet classification with deep convolutional neural networks . in p.",
    "bartlett , f.c.n .",
    "pereira , c.j.c .",
    "burges , l.  bottou , and k.q .",
    "weinberger , editors , _ advances in neural information processing systems 25 _ , pages 11061114 , 2012 .",
    "xavier glorot and yoshua bengio . understanding the difficulty of training deep feedforward neural networks . in yee",
    "w. teh and d.  m. titterington , editors , _ proceedings of the thirteenth international conference on artificial intelligence and statistics ( aistats-10 ) _ , volume  9 , pages 249256 , 2010 .",
    "carlo baldassi , christian borgs , jennifer  t. chayes , alessandro ingrosso , carlo lucibello , luca saglietti , and riccardo zecchina . unreasonable effectiveness of learning neural networks : from accessible states and robust ensembles to basic algorithmic schemes .",
    ", 113(48):e7655e7662 , 2016 .",
    "carlo baldassi , alessandro ingrosso , carlo lucibello , luca saglietti , and riccardo zecchina .",
    "subdominant dense clusters allow for simple learning and high computational performance in neural networks with discrete synapses .",
    ", 115:128101 , 2015 ."
  ],
  "abstract_text": [
    "<S> standard error backpropagation is used in almost all modern deep network training . </S>",
    "<S> however , it typically suffers from proliferation of saddle points in high - dimensional parameter space . </S>",
    "<S> therefore , it is highly desirable to design an efficient algorithm to escape from these saddle points and reach a good parameter region of better generalization capabilities , especially based on rough insights about the landscape of the error surface . here , we propose a simple extension of the backpropagation , namely reinforced backpropagation , which simply adds previous first - order gradients in a stochastic manner with a probability that increases with learning time . </S>",
    "<S> extensive numerical simulations on a toy deep learning model verify its excellent performance . </S>",
    "<S> the reinforced backpropagation can significantly improve test performance of the deep network training , especially when the data are scarce . </S>",
    "<S> the performance is even better than that of state - of - the - art stochastic optimization algorithm called adam , with an extra advantage of less computer memory required . </S>"
  ]
}