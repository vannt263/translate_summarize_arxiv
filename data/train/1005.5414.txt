{
  "article_text": [
    "in many situations , the cost of computing the value of a function @xmath0 is very high , because either the analytic expression of the function is extremely complex or the value is the result of a costly experiment .",
    "for example , @xmath0 could be the level of toxicity as a reaction to different doses of certain drugs , the output of a chemical experiment , or the survival time of a patient undergoing a certain treatment . therefore the function can be computed only at a limited number of points .",
    "one standard way to choose these points is via some monte carlo randomization .",
    "different possibilities arise : points could be sampled totally at random or some stratification could be used .",
    "when properly carried out , stratification is known to improve the performance of estimators .",
    "the purpose of this paper is to qualify the above statement in some relevant cases and compare different sampling stratifications according to some suitable criteria",
    ".    often the object of interest is some functional of @xmath1 such as its supremum or integral .",
    "monte carlo estimation of such functionals is the subject of a very large number of papers . in most cases",
    "some regularity of the function @xmath0 is assumed ; see , for example , @xcite . under some regularity conditions it is often reasonable to estimate the entire function and then use a plug - in method to estimate the functional . when no regularity is assumed for @xmath0",
    ", then it may be more reasonable to estimate the functional directly .    given a measurable space @xmath2 , let @xmath3 be a measurable function @xmath0 . in order to estimate @xmath4",
    "we can draw a sample @xmath5 of @xmath6 points in @xmath7 and use the estimator @xmath8 .",
    "alternatively we can sample the @xmath9 s by resorting to some stratification .",
    "ermakov , zhiglyavski and kondratovich @xcite , kondratovich and zhigljavsky @xcite and zhigljavsky and ilinskas @xcite prove that , if we consider two partitions of @xmath7 , one of which is a refinement of the other , and we sample in proportion to the measure of each element of the partition , then the more refined partition produces a stochastically larger estimator of the supremum . since these estimators are almost surely smaller than @xmath10 ( hence biased ) and consistent , the stochastically larger one performs better .",
    "thus , the more we stratify , the better the estimator we obtain .    in our paper we extend this result and show that the stochastic comparison for estimators of the supremum holds also when observations are censored , that is , when for a sample of pairs of random variables @xmath11 we only know whether @xmath12 or not",
    ". in applications , there may be situations where exact evaluation of @xmath13 at a given point is difficult or expensive , whereas a comparison of @xmath13 to a given constant @xmath14 is ( at least for most values of @xmath14 ) much easier .",
    "for example , if @xmath13 represents a lifetime , it may be easier to see if it has exceeded a certain value , rather than wait to obtain the exact value @xmath13 itself .",
    "this amounts to censoring .    when we want to estimate the integral @xmath15 of the function @xmath0 , then it is easy to construct an unbiased estimator of @xmath15 by using different stratified samples .",
    "unbiasedness of these estimators implies that the comparison criterion can not be the stochastic order , as used for the maximum .    in much of the literature estimators",
    "are compared in terms of a given loss function , which may be arbitrary .",
    "typically the loss function is quadratic , so the criterion is the mean square error , that is , the variance , when the estimator is unbiased .",
    "more generally , it may be possible to find comparison criteria that are valid for large classes of loss functions ; for instance , all losses of the type @xmath16 , where @xmath17 is an estimator of @xmath15 and @xmath18 , or even the class of all convex loss functions .",
    "the use of the entire class of convex loss functions in inference goes back at least to @xcite and @xcite .",
    "similar ideas were later used by berger @xcite , kozek @xcite , lin and mousa @xcite , eberl @xcite , bai and durairajan @xcite , and petropoulos and kourouklis @xcite .",
    "a comparison of the performance of different estimators , with respect to all convex loss functions , can be achieved by considering the convex order .",
    "comparison of experiments in terms of the convex order traces back to @xcite .",
    "it is well known that stratification reduces the variance of estimators of @xmath15 , but , as will be shown below , stratification does not necessarily reduce @xmath19 $ ] , for @xmath20 , which implies that , even if stratification is useful in @xmath21 , it may be counterproductive in @xmath22 .",
    "we will show that in some circumstances stratified sampling is better not just in @xmath21 , but in terms of the convex order , which in turn implies that it is better in @xmath23 for every @xmath18 .",
    "this is the case when observations are censored , the function @xmath0 is univariate and monotone , or the function is multivariate and monotone and the sampling is independent across coordinates .",
    "papageorgiou @xcite shows the computational advantage of using randomized methods to compute the integral of monotone @xmath24-variate functions , and shows how this depends on @xmath24 .",
    "our results also hold when the function @xmath0 can only be observed with noise ; for instance , when @xmath0 is observed as the outcome of some experiment . moreover , our regularity assumptions on the function @xmath0 are rather non - restrictive : measurability when estimating the maximum , boundedness when observations are censored , and sometimes monotonicity when estimating the integral .",
    "we emphasize that , in our framework , evaluation of @xmath0 by experiment is the costly part and any precalculations , such as those required for computing strata and sampling from the conditional distributions in strata , even if computer - time consuming , are considered to have a relatively negligible cost .",
    "the paper is organized as follows .",
    "section  [ se : notation ] fixes notation and reviews various properties of stochastic orders and certain dependence structures .",
    "section  [ se : supcensor ] compares estimators of the supremum of a function , considering also the case of censored observations .",
    "section  [ se : integralcensor ] compares estimators of integrals : first a variance comparison is shown to hold in general , even when observations are affected by errors .",
    "then a counterexample is provided for a non - quadratic loss function . then censored observations are considered and a comparison in terms of the convex order is proved in this case",
    "finally , monotone functions are examined . in the univariate case",
    ", a convex order comparison holds . in the multivariate case , this is true under some additional conditions on the stratification and on the dependence of the underlying random vector .",
    "numerical examples can be found in @xcite .",
    "in this paper a probability space @xmath25 is assumed in the background .",
    "the _ stochastic order _",
    "@xmath26 , the _ convex order _",
    "@xmath27 , the _ increasing convex order _",
    "@xmath28 , and the _ majorization order _",
    "@xmath29 are defined as follows ( see , e.g. , @xcite ) .",
    "given two random vectors @xmath30 , we say that @xmath31 if @xmath32 \\le \\mathbb{e}[\\phi(\\mathbf{x})]\\ ] ] for all non - decreasing functions @xmath33 .",
    "we say that @xmath34 if ( [ eq : ephixephiy ] ) holds for all convex functions @xmath33 and @xmath35 if ( [ eq : ephixephiy ] ) holds for all non - decreasing convex functions @xmath33 .",
    "it is well known that @xmath31 iff @xmath36 for all increasing sets @xmath37 , where we call a set _ increasing _ if its indicator function is non - decreasing . in the case of univariate random variables",
    "@xmath38 , the above inequality becomes @xmath39 for all @xmath40 .",
    "it is well known that @xmath41 implies @xmath42 = \\mathbb{e}[y]$ ] and @xmath43 \\le { \\operatorname{var}}[y]$ ] .",
    "the statement @xmath31 depends only on the marginal laws @xmath44 and @xmath45 , so sometimes we write @xmath46 , and analogously for @xmath27 and @xmath28 .",
    "given two vectors @xmath47 , @xmath48 , we write @xmath49 if @xmath50 where @xmath51 is the decreasing rearrangement of @xmath52 , and analogously for @xmath53 . the relation @xmath49 holds if and only if there exists an @xmath54 doubly stochastic matrix @xmath55 such that @xmath56 .    a function @xmath57 is called schur convex or schur concave if @xmath49 implies @xmath58 or @xmath59 , respectively .",
    "if @xmath60 is convex then @xmath61 is schur convex .",
    "a random vector @xmath62 is _ associated _ if for all non - decreasing functions @xmath63 we have @xmath64 \\ge 0 $ ] .",
    "recall that a subset @xmath65 is a _ lattice _ if it is closed under componentwise maximum @xmath66 and minimum @xmath67 .",
    "a random vector @xmath62 is _ multivariate totally positive of order @xmath68 _ ( mtp@xmath69 ) if its support is a lattice and its density @xmath70 with respect to some product measure on @xmath71 satisfies @xmath72 for all @xmath73 .",
    "mtp@xmath74 implies association . also , any vector having independent components is mtp@xmath74 .",
    "let @xmath75 be a random variable with values in some measurable space @xmath2 with non - atomic law @xmath76 .",
    "a finite sequence @xmath77 of subsets of @xmath7 is called an _ ordered partition _ of @xmath7 if @xmath78 for @xmath79 , @xmath80 , and @xmath81 . for the sake of brevity in the sequel , whenever we say `` partition '' we mean `` ordered partition . ''    here we consider partitions @xmath77 of @xmath7 , where the sets @xmath82 are measurable and such that for @xmath83 we have @xmath84 for some @xmath85 satisfying @xmath86 .",
    "we say that such a partition @xmath87 of @xmath7 and a partition @xmath88 of @xmath89 are associated if the cardinalities @xmath90 of the sets @xmath91 satisfy @xmath92 for @xmath83 .",
    "we then have @xmath93 the notation @xmath94 means that @xmath95 is one of the sets @xmath82 that comprise @xmath87 and , given @xmath94 , we let @xmath96 denote the corresponding set @xmath91 in @xmath97 such that ( [ eq : pbb * ] ) holds .    given two partitions @xmath88 and @xmath98 of @xmath99 , we write @xmath100 ; that is , that @xmath97 is a refinement of @xmath101 when every set in @xmath101 is the union of sets in @xmath97 .",
    "we will use the same order @xmath102 for partitions of @xmath7 .",
    "clearly , if @xmath103 and @xmath87 are partitions of @xmath7 , each of which can be associated to some partition of @xmath99 , then @xmath104 implies that there exist partitions @xmath101 and @xmath97 associated to @xmath103 and @xmath87 , respectively , satisfying @xmath100 .",
    "call @xmath105 the finest partition of @xmath99 and @xmath106 the coarsest partition of @xmath99 .",
    "then @xmath107 for all @xmath97 , and for any partition @xmath108 of @xmath7 associated to @xmath109 we have @xmath110 .    for a partition @xmath87 and @xmath94 , let @xmath111 denote the conditional law of @xmath75 given @xmath112 .",
    "let @xmath113 be random variables with law @xmath111 with @xmath114 independent .",
    "let @xmath115 be measurable , and define @xmath116 where the subscript @xmath117 indicates that @xmath118 will be used to estimate the ( essential ) supremum of the function @xmath0",
    ".    given a random variable @xmath75 with values in @xmath119 , let @xmath120 .",
    "it is clear that for any choice of partition @xmath87 , @xmath121 .",
    "the following result compares two estimators of type @xmath118 .",
    "since both estimators underestimate @xmath122 , the stochastically larger one is preferable .",
    "this theorem , which goes back to @xcite and @xcite , can also be found in @xcite , theorem  3.4 .",
    "[ th : maxgeneral ] if @xmath123 , then @xmath124 .",
    "a short proof of theorem  [ th : maxgeneral ] , different from the one in the @xcite , can be found in the .    as mentioned in the section [ se : int ] ,",
    "data are not always observed exactly in many practical situations , but may be censored for various reasons , including budget constraints .",
    "we extend now the comparison result of theorem  [ th : maxgeneral ] to the case of censored observations .",
    "let @xmath115 be bounded ; without loss of generality , we take @xmath125 for all @xmath126 . in this section",
    "we assume that , for a sample of points of the type @xmath127 $ ] , we are allowed to observe only the value of @xmath14 and whether @xmath128 .    for any partition @xmath87 with associated partition @xmath129 , let @xmath130 , @xmath94 and @xmath131 be independent random variables with law @xmath111 and the uniform distribution on @xmath132 $ ] , respectively , and",
    "let @xmath133 when @xmath134 we set @xmath135 .",
    "the letter c in the subscript @xmath136 indicates censored data .",
    "it is clear that @xmath137 , so the estimator @xmath138 underestimates @xmath122 .",
    "[ th : imax ] if @xmath104 , then @xmath139 .",
    "below , when we write @xmath140 without specifying @xmath95 , we mean that @xmath94 corresponds in the sense of ( [ eq : pbb * ] ) to the set @xmath141 , which contains the index @xmath142 . for any @xmath143,$ ] we may calculate the distribution function of @xmath144 at @xmath14 by writing @xmath145 hence , conditionally on @xmath146 , @xmath147 , @xmath148 , using the fact that the @xmath149 s are uniform , we obtain : @xmath150\\\\[-8pt ] & & \\quad= \\sum_{r\\subset n}\\prod_{j\\in r}\\bigl(t\\wedge f(v_{j}^{b})\\bigr)\\prod_{j\\notin r}\\bigl(1- f(v_{j}^{b})\\bigr)\\nonumber \\\\ & & \\quad= \\sum_{h_{1}=1}^{|b_{1}^{*}|}\\dots\\sum_{h_{b}=1}^{|b_{b}^{*}|}\\mathop{\\sum_{r \\subset n}}_{\\forall i,|r\\cap b_i^{*}|=h_i } \\prod_{j \\in r}\\bigl(t\\wedge f(v_{j}^{b})\\bigr)\\prod_{j\\notin r}\\bigl(1- f(v_{j}^{b})\\bigr).\\nonumber\\end{aligned}\\ ] ] taking expectation we obtain the unconditional distribution , @xmath151 let @xmath152\\,{\\mathrm{d}}p_{u|{b}}(v).\\end{aligned}\\ ] ] if @xmath153 is a union of disjoint sets @xmath154 , then @xmath155    if @xmath104 , then @xmath156 to see this , observe that ( [ eq : qcqb ] ) implies that the vector on the left - hand side above is obtained from the one on the right by multiplying it by the @xmath54 doubly stochastic matrix @xmath55 , which is block diagonal where the @xmath157th block is the @xmath158 matrix with all entries equal to @xmath159 .",
    "therefore , by the schur concavity of the function @xmath160 , we have @xmath161    for every @xmath162 and for every partition @xmath163 associated to a partition @xmath164 of @xmath165 , we have @xmath166 . therefore , @xmath167 since @xmath168 is consistent for @xmath122 as @xmath169 , we have that @xmath170 and @xmath171 are consistent , too .",
    "with the subscript @xmath172 standing for integral , let @xmath173 where the variables @xmath174 are independent copies of a random variable @xmath175 having mean @xmath176 and finite variance , independent of the variables @xmath140 . clearly @xmath177 and @xmath178",
    "are both unbiased estimators of @xmath179=\\int f(u)\\,{\\mathrm{d}}\\mathbb{p}$ ] when @xmath180 is finite , and @xmath177 is the special case of @xmath178 when the error has zero variance ; that is , there is no measurement error .",
    "the following result is well known when the error has zero variance ( see , e.g. , @xcite , section  4.3 ) . we extend it to a more general case , relevant when the evaluation of @xmath0 is the result of an experiment .",
    "[ th : interror ] if @xmath104 , then @xmath181 \\le { \\operatorname{var}}[w_{{\\operatorname{ie}}}^{\\mathcal{c}}]$ ] .",
    "the proof of theorem  [ th : interror ] can be found in the .",
    "it follows immediately from theorem  [ th : interror ] that @xmath182 \\le { \\operatorname{var}}[w_{{\\operatorname{ie}}}^{\\mathcal{d}}]$ ] , hence , in particular , @xmath183 \\le { \\operatorname{var}}[w_{{\\operatorname{i}}}^{\\mathcal{d}}]$ ] .",
    "the following counterexample shows , nevertheless , that , even when the function is observed without error , @xmath184 ; that is , domination in the convex order does not hold . in the counterexample we consider the absolute error ,",
    "that is , ( @xmath185 ) , rather than mean square error , ( @xmath186 ) .",
    "[ counterexample ] let @xmath187 $ ] and @xmath75 have a uniform distribution on @xmath132 $ ] .",
    "furthermore , let @xmath188 , @xmath189 , a_2=(1/2,1]$ ] .",
    "define @xmath190}(u ) + 2i_{(1/2,3/4]}(u ) + 6i_{(3/4,1]}(u).\\ ] ]    then @xmath191 takes the values @xmath192 with probabilities @xmath193 , respectively .",
    "the variable @xmath194 , based on one random observation from each of the above intervals @xmath195 , takes the values 3 and 5 each with probability @xmath196 .",
    "therefore , @xmath197=4=\\mathbb{e}[w_{{\\operatorname{i}}}^{\\mathcal{d}}]$ ] .",
    "we have @xmath198 = { \\operatorname{var}}[w_{{\\operatorname{i}}}^{\\mathcal{a } } ] = 1 $ ] , but for the convex function @xmath199 we have @xmath200 = \\mathbb{e}|w_{{\\operatorname{i}}}^{\\mathcal{d}}-4| = 2 \\frac{2}{16}+2 \\frac{4}{16}=\\frac{12}{16 } < 1 = \\mathbb{e}|w_{{\\operatorname{i}}}^{\\mathcal{a}}-4| = \\mathbb{e}[\\psi(w_{{\\operatorname{i}}}^{\\mathcal{a}})].\\ ] ]    a more general example can be constructed as follows . consider a partition @xmath108 associated to the finest partition @xmath109 of @xmath99 . split @xmath201 into two measurable subsets @xmath202 such that @xmath203",
    "consider now a function @xmath0 defined as follows : @xmath204 for all @xmath205 we have @xmath206 = 0 $ ] and @xmath207 = \\cases { 1 , & \\quad for $ i=1$,\\cr 0 , & \\quad for $ i \\neq 1$. } \\ ] ] hence @xmath208=\\mathbb{e}[(w_{{\\operatorname{i}}}^{\\mathcal{a}})^{2 } ] = \\frac{1}{n^{2}}.\\ ] ] moreover , if @xmath209 are i.i.d .",
    "copies of @xmath75 , @xmath210 = { \\operatorname{var}}\\biggl[\\frac{1}{n } \\sum_{j=1}^{n } f(v_{j})\\biggr ] = \\frac{1}{n^{2 } } \\sum_{j=1}^{n } { \\operatorname{var}}[f(v_{j } ) ] = \\frac { 1}{n^{2 } } = { \\operatorname{var}}[w_{{\\operatorname{i}}}^{\\mathcal{a}}].\\ ] ]    analogously @xmath211 = \\cases { 1 , & \\quad for $ i=1$,\\cr 0 , & \\quad for $ i \\neq 1$. } \\ ] ] therefore @xmath212}=\\frac{1}{n}.\\ ] ] for any square integrable random variable @xmath213 we have @xmath214}$ ] and the inequality is strict if @xmath213 is not almost surely constant .",
    "hence @xmath215 } = \\sqrt{\\mathbb{e}[(w_{{\\operatorname{i}}}^{\\mathcal{a}})^{2 } ] } = \\mathbb{e}|w_{{\\operatorname{i}}}^{\\mathcal{a}}|   = \\frac{1}{n}.\\ ] ]    example  [ counterexample ] proves that the convex order does not hold in general between estimators @xmath177 and @xmath216 when @xmath217 .",
    "nevertheless , in the following subsections we show that under some natural conditions comparisons in the convex order are possible .      keeping the notation and spirit of section  [ se : supcensor ] ,",
    "consider a function @xmath0 such that @xmath125 for all @xmath218 .",
    "assume that for a sample of points of the type @xmath127 $ ] we are allowed to observe only the value of @xmath14 and whether @xmath219 let @xmath220 note that @xmath221 is an unbiased estimator of @xmath222 $ ] , as @xmath223 & = & \\frac{1}{n } \\sum_{b \\in\\mathcal{b}}\\sum_{j \\in b^{*}}\\mathbb{p}\\bigl(t_{j}\\le f(v_{j}^{b})\\bigr ) = \\frac{1}{n } \\sum_{b \\in \\mathcal{b}}\\sum_{j \\in b^{*}}\\int_{\\mathfrak{u } } \\int_0 ^ 1 i_{\\{t \\le f(u)\\}}\\,{\\mathrm{d}}t\\,{\\mathrm{d}}p_{u|b}(u ) \\\\ & = & \\sum_{b \\in \\mathcal{b}}\\frac{|b^{*}|}{n } \\int_{\\mathfrak{u } } f(u)\\,{\\mathrm{d}}p_{u|b}(u)=\\sum_{b \\in \\mathcal{b}}\\mathbb{p}(b)\\mathbb{e}[f(u)\\mid u\\in b ] \\\\ & = & \\mathbb{e}[f(u)].\\end{aligned}\\ ] ]    [ th : censint ] if @xmath104 , then @xmath224 .    by a result in @xcite ( see also @xcite , sections 12.f and 15.e ) if @xmath225 where @xmath226 are independent bernoulli variables with parameters @xmath227 , and @xmath228 , then @xmath229 define @xmath230 and @xmath231 if @xmath232 , then @xmath233 so @xmath234 and invoking ( [ eq : karnov ] ) completes the proof .",
    "notice that in the case of censored observations , the comparison holds in the convex order , whereas in the case of perfect observation , a variance comparison holds , but example  [ counterexample ] shows that comparisons in the convex order do not .      in the rest of this subsection the space @xmath7 is totally ordered and , without loss of generality , we choose @xmath235 $ ] . for subsets @xmath236 and @xmath237 of the real line ,",
    "we write @xmath238 if @xmath239 for every @xmath240 and @xmath241 .",
    "we call a partition @xmath77 of @xmath7 monotone if @xmath242 .",
    "[ th : increasinginterror ] let @xmath87 and @xmath103 be monotone partitions of @xmath7 and let @xmath104",
    ". if @xmath0 is non - decreasing , then @xmath243    to prove theorem  [ th : increasinginterror ] we will apply the following lemma .    [",
    "le : partmon1 ] let @xmath244 and @xmath245 be random variables such that @xmath246 , and let @xmath247 and @xmath248 be independent copies of @xmath244 and @xmath245 , respectively .",
    "let @xmath249 be an integer - valued random variable , independent of all @xmath250 and @xmath248 , satisfying @xmath251 for some integer @xmath252 and having an integer - valued expectation , @xmath253 = k$ ] . then @xmath254    since @xmath255 we may construct i.i.d .",
    "pairs @xmath256 with @xmath257 for all @xmath258 .",
    "we adopt the usual convention that if @xmath259 then @xmath260 . first note that , by wald s lemma , @xmath261   = \\mathbb{e}\\biggl [ \\sum_{j=1}^k \\xi_{j } + \\sum_{j = k+1}^{m } \\eta_{j}\\biggr].\\ ] ] therefore ( see , e.g. , @xcite , theorem  1.5.3 ) it suffices to show that @xmath262 let @xmath33 be an increasing convex function and set @xmath263.\\ ] ] note that @xmath264\\ ] ] and @xmath265=\\mathbb{e}\\biggl[\\phi\\biggl(\\sum_{j=1}^k\\xi_{j}+\\sum_{j = k+1}^{m}\\eta_{j}\\biggr)\\biggr].\\ ] ] thus we have to show that @xmath266 $ ] . since @xmath253=k$ ]",
    ", this follows readily by jensen s inequality , once we prove that @xmath267 is a convex function .",
    "the following part of the proof follows ideas of ross and schechner @xcite . setting @xmath268 we have @xmath269-\\mathbb{e}[\\phi(\\eta_{k+1}+s_k)].\\ ] ]",
    "since @xmath33 is convex , and @xmath270 , the function @xmath271-\\mathbb{e}[\\phi(\\eta_{k+1}+s_k)\\mid s_k = s]\\ ] ] is decreasing in @xmath272 . now",
    "note that @xmath273 because @xmath274 . hence @xmath275",
    "$ ] is increasing in @xmath276 , thus proving that @xmath277 is convex , as required .",
    "proof of theorem  [ th : increasinginterror ] since @xmath278 and @xmath279 are monotone partitions satisfying @xmath217 , there exist @xmath280 such that @xmath281 as the union above may be formed by taking the union of two consecutive sets at a time , it suffices to prove ( [ eq : increasinginterror ] ) for the case where @xmath282 , @xmath283 , @xmath284 for @xmath285 , and @xmath286 for @xmath287 .    in this case",
    "we have @xmath288 , \\\\",
    "w_{{\\operatorname{ie}}}^{\\mathcal{c } } & = & \\frac{1}{n}\\biggl[\\sum_{c \\neq c_{m } } \\sum_{j\\in c^ { * } } f(v_{j}^{c } ) +   \\sum_{j\\in c_{m}^ { * } } f(v_{j}^{c_{m } } ) + \\sum_{j\\in n } \\varepsilon_{j}\\biggr].\\end{aligned}\\ ] ] note that @xmath289 where @xmath249 is binomially distributed with parameters @xmath290 it is easy to see that if two variables are ordered by the convex order ( see ( [ eq : ephixephiy ] ) ) and we add the same independent variable to each one , to wit , @xmath291 , then the convex order is preserved .",
    "this fact and lemma  [ le : partmon1 ] now yield ( [ eq : increasinginterror ] ) .      in this section",
    "we extend the results in section [ suse : uni ] to the multivariate case .",
    "when we consider multivariate monotone functions , stratifying can still yield improvement in the convex order , but some restrictions are needed , both on the distribution of the random vector used for sampling and on the stratifying partitions .",
    "more specifically , we consider estimation of an integral with respect to a random vector whose components are independent and under a stratification that preserves independence on each set of the partition .",
    "the result we prove below actually only requires that the random vector have an mtp@xmath74 distribution ( independence being a particular case of it ) and that the stratification preserves mtp@xmath74 .",
    "let @xmath292^d \\rightarrow [ 0,1]$ ] be non - decreasing in each variable and let @xmath293 be a random vector taking values in @xmath132^d$ ] with a non - atomic distribution .",
    "our goal is to show that the estimate of @xmath294 $ ] improves by refining stratifications as follows .",
    "recalling the definitions in section [ se : notation ] , start with a partition @xmath295 of @xmath132^d$ ] such that for some @xmath157 the distribution @xmath296 is associated .",
    "then split @xmath297 into @xmath298 and @xmath299 , where @xmath236 is an increasing set .",
    "lemma  [ le : multconvexint ] below shows that the new partition obtained by this splitting achieves a better estimator of the integral in terms of the convex order and theorem  [ th : multconvexintgen ] provides some conditions for its application .",
    "[ th : multconvexintgen ] consider a partition @xmath300 of @xmath132^{d}$ ] where each @xmath301 is a lattice .",
    "let @xmath87 be a partition obtained by a sequence of refinements @xmath302 , such that for @xmath303 the partition @xmath304 is obtained from @xmath305 by splitting one set of @xmath305 , say @xmath306 , into @xmath307 and @xmath308 , where @xmath309^d\\dvtx a_{k } \\le x_j\\ } $ ] for some @xmath310 $ ] and some @xmath311 .",
    "if @xmath293 is mtp@xmath74 on @xmath132^{d}$ ] and @xmath292^d \\rightarrow [ 0,1]$ ] is non - decreasing , then @xmath312 .    as mentioned earlier",
    ", independence is a particular ( and in our framework the most important ) case of mtp@xmath69 .",
    "independence makes simulation of a multivariate random vector easy , even when conditioned on an interval , since the strata can be constructed by knowing only the quantiles of the marginal distributions .",
    "if the cost of simulation is negligible relative to the cost of evaluating @xmath0 , then even rejective sampling can be used , once the strata are defined .",
    "the proof of theorem [ th : multconvexintgen ] is preceded by the following lemmas .    [",
    "le : assoc ] if @xmath293 is an associated random vector , and @xmath236 is an increasing set , then @xmath313 conversely , if ( [ eq : assocst ] ) holds for every increasing set @xmath236 , then @xmath293 is associated .    first note that ( [ eq : assocst ] ) is equivalent to @xmath314 holding for all increasing sets @xmath37 .",
    "the latter inequality is easily seen to be equivalent to @xmath315 \\ge [ \\mathbb{p}(\\mathbf{u } \\in a ) -\\mathbb{p } ( \\mathbf{u } \\in a \\cap g ) ] \\mathbb{p } ( \\mathbf{u } \\in   g).\\ ] ] by simple cancelation this inequality is equivalent to @xmath316 which is equivalent to association of the random vector @xmath293 by , e.g. , shaked @xcite .",
    "[ le : multconvexint ] consider a partition @xmath300 of @xmath132^d$ ] such that for some @xmath297 the distribution @xmath317 is associated .",
    "let @xmath236 be an increasing set and let @xmath318 . if @xmath292^d \\rightarrow [ 0,1]$ ] is non - decreasing , then @xmath319",
    ".    with @xmath320 and @xmath321 , lemma  [ le : assoc ] yields @xmath322 .",
    "the monotonicity of @xmath0 implies @xmath323 , and lemma  [ le : partmon1 ] now proves the claim , applying arguments as in the proof of theorem  [ th : increasinginterror ] .",
    "the following result can be found in @xcite .    [",
    "le : mtp ] if an mtp@xmath69 vector @xmath293 takes values in a lattice of which @xmath153 is a sublattice , then @xmath324 is mtp@xmath69 and hence associated .",
    "the following corollary is obvious , and only requires the fact that the intersection of sublattices is a lattice .",
    "[ cor : mtp ] if an mtp@xmath69 vector @xmath293 takes values in some lattice , and @xmath153 , @xmath236 and @xmath325 , are all sublattices , then both @xmath326 and @xmath327 are mtp@xmath69 , and hence also associated .",
    "proof of theorem  [ th : multconvexintgen ] we first prove by induction that @xmath328 are mtp@xmath69 for all @xmath329 and @xmath330 . for @xmath331",
    "this follows from lemma [ le : mtp ] and the assumptions that @xmath293 is mtp@xmath69 and that @xmath332 are sublattices of @xmath132^d$ ] . assuming the statement true for @xmath333 , to verify that it is true for @xmath334 we need only show that @xmath335 and @xmath336 are mtp@xmath69 , which follows from lemma [ le : mtp ] , thus completing the induction .",
    "hence , again using lemma [ le : mtp ] , @xmath337 is associated .",
    "since @xmath338 is increasing , lemma  [ le : multconvexint ] now yields @xmath339 , and , therefore , the theorem .",
    "a sequence of partitions as in theorem  [ th : multconvexintgen ] can be generated as follows : start with the whole space @xmath132^d$ ] , then split it into boxes by repeatedly subdividing one element of the partition by an intersection with some @xmath236 and @xmath325 . in @xmath132",
    "^ 2 $ ] , the resulting partition forms a tiling of the square by rectangles . note that from the first step , a sequence of partitions created using @xmath236 as above has at least one line that crosses the whole square from side to side .",
    "therefore the tiling of figure  [ fi : tiling ] is not attainable by such a sequence .",
    "finally , recall that the hypothesis of mtp@xmath74 includes as a particular case the uniform distribution on @xmath132^{d}$ ] , so theorem  [ th : multconvexintgen ] applies to the estimation of the integral @xmath340 on @xmath132^{d}$ ] , or any lattice .    [ se : appendix ]",
    "[ le : supremumxi ] given a partition @xmath97 of @xmath99 , consider a collection of independent random variables @xmath341 , @xmath342 , @xmath343 , with those indexed by the same element @xmath344 of the partition being identically distributed .    for @xmath100 ,",
    "let @xmath345 with @xmath346 and @xmath347 be a collection of independent random variables with the mixture distribution @xmath348    then @xmath349    let @xmath350 for @xmath342 and @xmath351 for @xmath346 .",
    "we claim that @xmath352 to see this , observe that ( [ eq : lxibc ] ) implies that the vector on the left - hand side above is obtained from the one on the right by multiplying it by the @xmath54 doubly stochastic matrix @xmath55 , which is block diagonal where the @xmath157th block is the @xmath158 matrix with all entries equal to @xmath159 .",
    "hence , by the schur concavity of the function @xmath353 , we have @xmath354 which is equivalent to ( [ eq : maxxi ] ) .    proof of theorem  [ th : maxgeneral ] let @xmath97 and @xmath101 be partitions associated with @xmath87 and @xmath103 , respectively , satisfying @xmath100 , and let @xmath355 and @xmath356 be collections of independent random variables with distributions @xmath357 then ( [ eq : lxibc ] ) holds ( law of total probability ) , and the result follows by lemma  [ le : supremumxi ] .",
    "proof of theorem  [ th : interror ] in what follows we consider conditional expectation with respect to a partition .",
    "though the notion is standard , specifically , by @xmath358 $ ] , we mean the random variable that takes values @xmath359 $ ] with probability @xmath360 .",
    "then @xmath361 & = & \\mathbb{e}\\bigl[\\{f(u ) + \\varepsilon - \\mathbb{e}[f(u)+ \\varepsilon \\vert\\mathcal{b}]\\}^2 \\vert\\mathcal{b}\\bigr ] \\\\ & = & \\mathbb{e}\\bigl[\\{f(u ) + \\varepsilon - \\mathbb{e}[f(u)\\vert\\mathcal{b}]\\}^2\\vert\\mathcal{b}\\bigr]\\end{aligned}\\ ] ] is a random variable taking values @xmath362 $ ] with probability @xmath360 , and @xmath363\\bigr ] & = & \\sum_{b\\in \\mathcal{b}}\\frac{|b^{*}|}{n } \\mathbb{e}\\bigl[\\bigl(f(u ) + \\varepsilon -\\overline{f}_{b}\\bigr)^2\\mid",
    "u \\in b\\bigr ] \\\\ & = & \\frac{1}{n}\\sum_{b\\in \\mathcal{b } } |b^{*}| \\mathbb{e}\\bigl[\\bigl(f(v_1^b ) + \\varepsilon -\\overline{f}_{b}\\bigr)^2\\bigr ] \\\\ & = & \\frac{1}{n } { \\operatorname{var}}\\biggl[\\sum_{b\\in \\mathcal{b } } \\sum_{j \\in b_{i}^ { * } } f(v_{j}^{b } ) + \\varepsilon^{b}_{j}\\biggr]\\\\ & = & n { \\operatorname{var}}[w_{{\\operatorname{ie}}}^{\\mathcal{b}}].\\end{aligned}\\ ] ]    if @xmath364 , then for any random variable @xmath213 , say , @xmath365 \\ge { \\operatorname{var}}[\\mathbb{e}[y | \\mathcal{c}]]$ ] by jensen s inequality , and now the usual variance decomposition of @xmath213 ( see , e.g. , @xcite , theorem  13.3.1 ) implies @xmath366 \\le \\mathbb{e}[{\\operatorname{var}}[y | \\mathcal{c}]]$ ] .",
    "therefore @xmath367\\bigr ] \\le \\mathbb{e}\\bigl[{\\operatorname{var}}[f(u ) + \\varepsilon \\vert \\mathcal{c}]\\bigr],\\ ] ] and hence @xmath368 = \\frac{1}{n}\\mathbb{e}\\bigl[{\\operatorname{var}}[f(u ) + \\varepsilon \\vert \\mathcal{b}]\\bigr ] \\le \\frac{1}{n}\\mathbb{e}\\bigl[{\\operatorname{var}}[f(u ) + \\varepsilon \\vert \\mathcal{c}]\\bigr ] = { \\operatorname{var}}[w_{{\\operatorname{ie}}}^{\\mathcal{c}}].\\ ] ]",
    "we thank abram kagan for sparking our curiosity in the topic with a simple version of theorem  [ th : maxgeneral ] , erich novak for an important bibliographical reference , and pierpaolo brutti for his help with r. we are indebted to the editor , an associate editor and three referees for their accurate reading of the paper and their helpful comments . the work of yosef rinott",
    "is partially supported by the israel science foundation grant no .",
    "the work of marco scarsini is partially supported by miur - cofin .",
    "blackwell , d. ( 1951 ) .",
    "comparison of experiments . in _ proceedings of the second berkeley symposium on mathematical statistics and probability , 1950 _ 93102 .",
    "berkeley and los angeles , ca : california univ . press .",
    "goldstein , l. , rinott , y. and scarsini , m. ( 2010 ) .",
    "stochastic comparisons of stratified sampling techniques for some monte carlo estimators .",
    "technical report .",
    "available at http://arxiv.org/abs/1005.5414v1[arxiv:1005.5414v1 ] [ math.st ] .",
    "kondratovich , m. and zhigljavsky , a. ( 1998 ) .",
    "comparison of independent and stratified sampling schemes in problems of global optimization . in _",
    "monte carlo and quasi - monte carlo methods 1996 ( salzburg ) _ 292299 .",
    "new york : springer ."
  ],
  "abstract_text": [
    "<S> we compare estimators of the ( essential ) supremum and the integral of a function @xmath0 defined on a measurable space when @xmath0 may be observed at a sample of points in its domain , possibly with error . </S>",
    "<S> the estimators compared vary in their levels of stratification of the domain , with the result that more refined stratification is better with respect to different criteria . </S>",
    "<S> the emphasis is on criteria related to stochastic orders . </S>",
    "<S> for example , rather than compare estimators of the integral of @xmath0 by their variances ( for unbiased estimators ) , or mean square error , we attempt the stronger comparison of convex order when possible . for the supremum , the criterion is based on the stochastic order of estimators </S>",
    "<S> .    [ section ] [ theorem]corollary [ theorem]lemma [ theorem]proposition [ theorem]acknowledgement [ theorem]algorithm [ theorem]axiom [ theorem]case [ theorem]claim [ theorem]fact [ theorem]conclusion [ theorem]condition [ theorem]conjecture [ theorem]criterion [ theorem]definition [ theorem]example [ theorem]exercise [ theorem]notation [ theorem]problem [ theorem]remark [ theorem]solution [ theorem]summary    , </S>"
  ]
}