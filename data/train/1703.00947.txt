{
  "article_text": [
    "the study of chemical reaction networks is an essential component of the emerging fields of systems and synthetic biology @xcite .",
    "traditionally chemical reaction networks were modeled in the deterministic setting , where the dynamics is represented by a set of ordinary differential equations ( odes ) or partial differential equations ( pdes ) . in the study of intracellular chemical reactions , some chemical species are present in low copy numbers .",
    "since the behavior of individual molecules is best described by a stochastic process , in the low molecular copy number regime , the copy numbers of the molecular species itself is better modeled by a stochastic process than by odes @xcite . only in the limit of large molecular copy numbers ,",
    "one expects the deterministic models to be accurate @xcite .",
    "while our work in this paper is focused on biochemical reaction networks as primary examples , we emphasize that the mathematical framework of reaction networks can also be used to describe a wide range of other phenomena in fields such as epidemiology @xcite and ecology @xcite .",
    "suppose @xmath0 is a parameter ( like ambient temperature , cell - volume , atp concentration etc . ) that influences the rate of firing of reactions .",
    "let @xmath1 be the @xmath0-dependent markov process representing the reaction dynamics , and suppose that for some real - valued function @xmath2 and observation time @xmath3 , our output of interest is @xmath4 .",
    "this output is a random variable and we are interested in determining the sensitivity of its expectation @xmath5 w.r.t .",
    "infinitesimal changes in the parameter @xmath0 .",
    "we define this sensitivity value , denoted by @xmath6 , as the partial derivative @xmath7 determining these parametric - sensitivity values are useful in many applications , such as , understanding network design and its robustness properties @xcite , identifying critical reaction components , inferring model parameters @xcite and fine - tuning a system s behavior @xcite .    generally the sensitivities of the form can not be directly evaluated , but instead , they need to be estimated with monte carlo simulations of the dynamics @xmath1 .",
    "many methods have been developed for this task @xcite , but they all rely on exact simulations of @xmath1 that can be performed using schemes such as gillespie s _ stochastic simulation algorithm _ ( ssa ) @xcite .",
    "this severely constrains the computational feasibility of these sensitivity estimation methods because these exact simulations become highly impractical if the rate of occurrence of reactions is high @xcite , which is typically the case .",
    "the main difficulty is that that exact simulation schemes keep track of each reaction event which is very time - consuming . to avoid this problem ,",
    "tau - leaping methods have been developed that proceed by combining many reaction - firings over small time intervals @xcite in such a way that insignificant stochastic effects are discarded in favor of computational speed .",
    "tau - leap methods haven been shown to produce good approximations of the reaction dynamics , at a small fraction of the computational cost of exact simulations @xcite .",
    "their accuracy has also been investigated theoretically in many papers @xcite .",
    "our goal in this paper is to develop a method that leverages the accuracy and computational efficiency of tau - leap methods for the purpose of estimating sensitivity values of the form .",
    "our method , called _ tau bernoulli path algorithm _ ( @xmath8bpa ) , works with any underlying tau - leap simulation scheme and it is based on a novel integral representation of parameter sensitivity @xmath6 that we derive in this paper .",
    "we provide computational examples that show that using @xmath8bpa we can often _ trade - off _ a small amount of bias for large savings in the overall computational costs for sensitivity estimation .",
    "we prove that the bias incurred by @xmath8bpa depends on the step - size in the same way as the bias of the tau - leap scheme chosen for simulations .",
    "moreover if we substitute the tau - leap simulations in @xmath8bpa with the exact ssa generated simulations , then we recover a new unbiased method for sensitivity estimation that is similar to the method in @xcite . for the sake of comparison",
    ", we also propose the _ tau - leap versions _ of certain commonly used finite - difference estimators ( see @xcite ) that approximate the infinitesimal derivative in by a finite - difference ( see ) .",
    "such estimators are computationally faster than @xmath8bpa but they suffer from two sources of bias ( finite - differencing and tau - leap approximations ) unlike @xmath8bpa which only incurs bias from the latter source .",
    "our examples indicate that the biases from these two sources often pile on top of each other , making these finite - difference estimators much more inaccurate in comparison to @xmath8bpa .",
    "this paper is organized as follows . in section [ sec : prelim ] we formally describe the stochastic model for reaction dynamics and the sensitivity estimation problem .",
    "we also discuss the existing sensitivity estimation methods , introduce the tau - leap simulation schemes and explain the rationale for using such simulations in sensitivity estimation .",
    "the main results of this paper including the description of our novel tau - leap sensitivity estimation method @xmath8bpa is contained in section [ sec : mainres ] . in section [ sec : num_examples ] we provide computational examples to compare our method with other methods and finally in section [ sec : conc ] we conclude and provide directions for future research .",
    "consider a reaction network with @xmath9 species and @xmath10 reactions .",
    "we describe its kinetics by a continuous time markov process whose state at any time is a vector in the non - negative integer orthant @xmath11 comprising of the molecular counts of all the @xmath9 species .",
    "the state evolves due to transitions caused by the firing of reactions .",
    "we suppose that when the state is @xmath12 , the rate of firing of the @xmath13-th reaction is given by the _ propensity _ function @xmath14 and the corresponding state - displacement is denoted by the stoichiometric vector @xmath15 .",
    "there are several ways to represent the markov process @xmath16 that describes the reaction kinetics under these assumptions .",
    "we can specify the generator ( see chapter 4 in @xcite ) of this process by the operator @xmath17 where @xmath18 is any bounded real - valued function on @xmath11 .",
    "alternatively we can express the markov process directly by its random time - change representation ( see chapter 7 in @xcite ) @xmath19 where @xmath20 is a family of independent unit rate poisson processes .",
    "since the process @xmath16 is markovian , it can be equivalently specified by writing the _ kolmogorov forward equation _ for the evolution of its probability distribution @xmath21 at each state @xmath12 : @xmath22 this set of _ coupled _ ordinary differential equations ( odes ) is termed as the _ chemical master equation _ ( cme ) in the biological literature @xcite .",
    "as the number of odes in this set is typically infinite , the cme is nearly impossible to solve directly , except in very restrictive cases .",
    "a common strategy is to estimate its solution using _ pathwise _ simulations of the process @xmath23 using monte carlo schemes such as gillespie s ssa @xcite , the _ next reaction method _ @xcite , the _ modified next reaction method _ @xcite , and so on .",
    "while these schemes are easy to implement , they become computationally infeasible for even moderately large nertworks , because they account for each and every reaction event . to resolve this issue ,",
    "tau - leaping methods have been developed which will be described in greater detail in section [ tau_leap_methods ] .",
    "we now assume that each propensity function @xmath24 depends on a real - valued system parameter @xmath0 . to emphasize this dependence we write the rate of firing of the @xmath13-th reaction at state @xmath12 as @xmath25 instead of @xmath14 .",
    "let @xmath26 be the markov process representing the reaction dynamics with these parameter - dependent propensity functions . as stated in section [ sec : intro ] , for a function @xmath27 and an observation time @xmath28 , our goal is to determine the sensitivity value @xmath29 defined by .",
    "this value can not be computed directly for most examples of interest and so we need to find ways of estimating it using simulations of the process @xmath26 .",
    "such simulation - based sensitivity estimation methods work by specifying the construction of a random variable @xmath30 whose expected value is  close \" to the true sensitivity value @xmath6 , i.e. @xmath31 once such a construction is available , a large number ( say @xmath32 ) of independent realizations @xmath33 of this random variable @xmath30 are obtained and the sensitivity is estimated by computing their empirical mean @xmath34 as @xmath35 this estimator @xmath34 is a random variable with mean and variance @xmath36 respectively . for a large sample size @xmath32 ,",
    "the distribution of @xmath37 is approximately gaussian with mean @xmath38 and variance @xmath39 , due to the central limit theorem .",
    "the _ standard deviation _",
    "@xmath40 , which is the square root of the variance , measures the _ statistical spread _ of the estimator @xmath41 , that is inversely proportional to its _",
    "statistical precision_. to safeguard against the possibility of different sample realizations producing very different estimates , the sample size @xmath32 must be large enough to ensure that @xmath40 is small relative to @xmath38 . if this holds , then @xmath34 is a reliable estimator for the true sensitivity value @xmath6 because it is very likely to assume a value close to its mean @xmath42 which in turn is close to @xmath6 ( see ) . in practice",
    "both @xmath38 and @xmath40 are unknown , but we can estimate them as @xmath43 and @xmath44    the performance of any sensitivity estimation method ( say @xmath45 ) depends on the following three key metrics that are based on the properties of random variable @xmath30 :    1 .   the _ bias",
    "_ @xmath46 , which is the error incurred by the approximation .",
    "the _ variance _ @xmath47 of random variable @xmath30 .",
    "3 .   the _ computational cost _",
    "@xmath48 of generating one sample of @xmath30    the bias @xmath49 can be positive or negative , and its absolute value @xmath50 can be seen as the upper - bound on the statistical accuracy that can be achieved with method @xmath45 by increasing the sample size @xmath32 @xcite . as mentioned before , the square - root of the variance @xmath51 measures the statistical precision of the method @xmath45 which determines the number of samples @xmath32 that is needed to produce a reliable estimate .",
    "the computational cost @xmath48 is the cpu time required for constructing one realization of @xmath30 , and hence the total cost of the estimation procedure with @xmath32 samples is @xmath52 .",
    "the goal of a good estimation method is to simultaneously minimize the three quantities @xmath50 , @xmath51 and @xmath48 .",
    "this creates various conflicts and trade - offs among the existing sensitivity estimation methods as we now discuss .",
    "a sensitivity estimation method @xmath45 is called _ biased _ if @xmath53 .",
    "the most commonly used biased methods are the _ finite - difference schemes _ which approximate the infinitesimal derivative in the definition of parameter sensitivity ( see ) by a finite - difference of the form @xmath54 for a small perturbation @xmath18 .",
    "the processes @xmath55 and @xmath56 represent the markovian reaction dynamics with values of the sensitive parameter set to @xmath0 and @xmath57 respectively .",
    "these two processes can be simulated independently @xcite but it is generally better to couple them in order to reduce the variance of the associated estimator .",
    "we briefly review two such coupling strategies called _ common reaction paths _ ( crp )",
    "@xcite and _ coupled finite differences _",
    "( cfd ) @xcite .    replacing each @xmath58 by @xmath59 in we obtain the random time - change representation of the @xmath0-dependent process",
    "@xmath55 as @xmath60 where @xmath61 is the initial state and @xmath62 is a family of independent unit rate poisson processes . here each @xmath63 captures the intermittency in the firing times of reaction @xmath13 .",
    "one can regard @xmath63 as specifying the _ reaction path _ for the @xmath13-th reaction . in crp , the process @xmath64 is coupled to process @xmath55 by assigning it the same reaction path for each reaction . in other words , the random time - change representation @xmath56 is given by @xmath65 where the @xmath63-s are the same as in .",
    "in cfd , the processes @xmath55 and @xmath66 are also coupled by their random time - change representations , in such a way that they share many common reactions .",
    "this is achieved using the split - coupling defined as @xmath67   ds\\right ) \\zeta_k \\\\",
    "\\label{cfd2 } \\",
    "\\textnormal { and } \\qquad x_{\\theta + h } ( t ) & = x_0 + \\sum_{k = 1}^k y_k \\left ( \\int_{0}^t \\lambda_k ( x_\\theta(s ) , \\theta ) \\wedge \\lambda_k ( x_{\\theta + h}(s ) , \\theta + h )     ds\\right ) \\zeta_k \\notag \\\\ & + \\sum_{k = 1}^k y^{(2)}_k \\left (   \\int_{0}^t \\left [ \\lambda_k ( x_{\\theta+h}(s ) , \\theta+h ) - \\lambda_k ( x_\\theta(s ) , \\theta ) \\wedge \\lambda_k ( x_{\\theta + h}(s ) , \\theta + h )   \\right ]   ds\\right ) \\zeta_k , \\end{aligned}\\ ] ] where @xmath68 and @xmath69 is again family of independent unit rate poisson processes .",
    "the finite - difference approximation for the true sensitivity value can be expressed as the expectation @xmath70 of the following random variable @xmath71 the three metrics ( bias , variance and computational cost ) based on this random variable define the performance of crp and cfd . since both these methods estimate the same quantity @xmath72 , they have the same bias ( i.e. @xmath73 ) . however in many cases it is found that the cfd coupling is _",
    "tighter _ than the crp coupling , resulting in a lower variance of @xmath74 ( i.e. @xmath75 ) ( see @xcite ) . for each realization of @xmath74 ,",
    "both crp and cfd require simulation of a coupled trajectory @xmath76 in the time interval @xmath77 $ ] .",
    "the computational costs of such a simulation is roughly @xmath78 , where @xmath79 is the cost of _ exactly _ simulating the process @xmath55 using gillespie s ssa @xcite or a similar method .",
    "is usually smaller for cfd in comparison to crp ( i.e. @xmath80 ) , because the cfd coupling is such that if @xmath81 for some @xmath82 , then this equality will hold for the remaining time - interval @xmath83 $ ] , allowing us to directly set @xmath84 without completing the simulation in the interval @xmath83 $ ] . ]",
    "finite - difference schemes introduce a bias in the estimate whose size is proportional to the perturbation value @xmath18 ( i.e. @xmath85 ) , but the constant of proportionality can be quite large in many cases , leading to significant errors even for small values of @xmath18 @xcite .",
    "unfortunately we can not circumvent this problem by choosing a very small @xmath18 because the variance is proportional to @xmath86 ( i.e. @xmath87 ) .",
    "therefore if a very small @xmath18 is selected , the variance will be enormous and the sample - size @xmath32 required to produce a statistically precise estimate will be very large , imposing a heavy computational burden on the estimation procedure @xcite .",
    "this trade - off between bias and variance is the main drawback of finite - difference schemes and there does not exist a strategy for selecting @xmath18 that optimally balances these two quantities . note that unlike bias and variance , the computational cost of generating a sample ( i.e. @xmath88 or @xmath89 ) does not change significantly with @xmath18 , thereby ensuring that as @xmath18 varies , the total computational burden varies linearly with the required number of samples @xmath32 .",
    "apart from finite - difference schemes , there exists another biased method @xcite that approximates the sensitivity value as @xmath90 which is obtained by replacing the output @xmath91 with its _ average _ value in the time interval @xmath92 $ ] .",
    "such an averaging is performed to _ regularize _ the sensitivity value , so that it can be estimated using _ pathwise - differentiation_. here the parameter @xmath93 is the half - width of the _ regularizing window_. it determines the bias and affects the variance in the same way as parameter @xmath18 for finite - difference schemes , which implies that this method also has similar trade - offs as the finite - difference schemes .      a sensitivity estimation method @xmath45",
    "is called _ unbiased _ if @xmath94 .",
    "the main advantage of unbiased methods is that the estimation can in principle be made as accurate as possible by increasing the sample size @xmath32 .",
    "the first unbiased method for sensitivity estimation is called the _ likelihood ratio _ ( lr ) method ( or the _ girsanov transformation _ method ) @xcite , which works by estimating the @xmath0-derivative of the probability distribution of @xmath55 . the lr method is easy to implement and the computation cost of generating each sample is roughly @xmath79  the cost of _ exact _ simulation of the process @xmath55 .",
    "the main issue with lr is that generally the variance of its associated random variable @xmath30 is very large ( i.e. @xmath95 ) , as has been observed numerically @xcite and also investigated theoretically in a recent paper @xcite . due to this large variance , lr method becomes infeasible for most examples of interest , as the number of samples needed to obtain a statistically precise estimate is very high .    with this in mind",
    ", we now discuss a couple of new unbiased methods that are based on an explicit formula for parameter sensitivity that we now present .",
    "let @xmath96 be the markov process representing reaction dynamics and let @xmath97 denote its successive jump times starting with @xmath98 . for any state @xmath99 and time",
    "@xmath100 define @xmath101 which is essentially the image of @xmath2 under the markovian semigroup associated with process @xmath55 at time @xmath102 .",
    "let @xmath103 and for any @xmath104 define @xmath105 theorem 2.3 in @xcite shows that @xmath6 exactly satisfies with the random variable @xmath106 defined by @xmath107 note that @xmath108 contains a contribution at each jump time @xmath109 ( before time @xmath3 ) of process @xmath55 and this contribution is given by the function @xmath110 which does not have an analytical formula for most examples . hence in order to use this result for sensitivity estimation",
    ", we need to estimate all these contributions using _ additional _ paths of the process @xmath55 .",
    "this is accomplished in @xcite using a scheme called _ auxiliary path algorithm_(apa ) that estimates these quantities in parallel using a small number @xmath111 of additional paths in such a way that the overall estimate remains unbiased . in comparison to the other unbiased method lr",
    ", the computational cost of generating each sample for apa is much higher ( i.e. @xmath112 ) but at the same time its variance is much lower ( i.e. @xmath113 ) . in @xcite",
    "many examples are provided where apa outperforms lr , because the benefit of lower variance more than compensates for the disadvantage of higher computational cost per sample .",
    "the main drawback of apa is that it tries to estimate _ all _ the unknown quantities of the form @xmath114 that appear in , which is very difficult because their number is proportional to the number of jumps of the process @xmath55 in the time interval @xmath77 $ ] , which can be very large even for small networks . in @xcite a new method is proposed that overcomes this problem by _ randomly selecting _ a small number of these quantities and estimating them using additional paths , without introducing a bias in the estimate .",
    "this method is called _ poisson path algorithm _ ( ppa ) because the selection mechanism is based on the values of certain poisson random variables that are generated  on the run \" .",
    "due to this extra randomness , the sample variance for ppa is generally greater than apa ( i.e. @xmath115 ) but the computational cost for realizing each sample is much lower ( i.e. @xmath116 ) .",
    "moreover in comparison to apa , ppa is far easier to implement and has lower memory requirements , making it an attractive unbiased method for sensitivity estimation . in @xcite",
    "it is shown using many examples that for a given level of statistical accuracy , ppa can be more efficient than lr and also the finite - difference schemes cfd and crp .",
    "the computational cost of generating each sample in ppa is roughly @xmath117 , where @xmath111 is a small number that upper - bounds the expected number of unknown quantities that will be estimated using additional paths .",
    "for both apa and ppa , the parameter @xmath111 serves as a _ trade - off _ factor between the computational cost and the variance - as @xmath111 increases , the cost also increases but the variance decreases .",
    "however note that both these methods remain unbiased for any choice of @xmath111 .",
    "the foregoing trade - off relationships for the existing sensitivity estimation methods are summarized in table [ tab1:tradeoff ] .",
    ".trade - off relationships among the bias @xmath118 , variance @xmath119 and the computational cost @xmath120 for existing sensitivity estimation methods . here",
    "@xmath18 is the perturbation size for finite - difference schemes @xcite , @xmath93 is the regularization half - width for the pathwise differentiation method @xcite and @xmath111 quantifies the number of auxiliary paths for apa @xcite and ppa @xcite .",
    "the cost of _ exactly _ simulating the underlying process is @xmath79 . [",
    "cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "estimation of parameter sensitivities for stochastic reaction networks in an important and difficult problem . the main source of difficulty is that all the estimation methods rely on exact simulations of the reaction dynamics performed using gillespie s ssa @xcite or its variants @xcite .",
    "it is well - known that these simulation algorithms are computationally very demanding as they track each and every reaction event which can be very cumbersome .",
    "this issue represents the main bottleneck in the use of sensitivity analysis for systems modeled as stochastic reaction networks .",
    "the aim of this paper is to develop a method , called _ tau bernoulli path algorithm _ ( @xmath8bpa ) , that feasibly deals with this issue by requiring only approximate tau - leap simulations of the reaction dynamics , and still providing provably accurate estimates for the sensitivity values .",
    "this method is based on an explicit integral representation for parameter sensitivity that was derived from the formula given in @xcite .",
    "furthermore , by replacing the tau - leap simulation scheme in @xmath8bpa with an exact simulation scheme like ssa , we obtain a new unbiased method ( called ebpa ) for sensitivity estimation , that can serve as the natural limit of @xmath8bpa when the step - size @xmath8 gets smaller and smaller .    using computational examples we compare @xmath8bpa with our proposed tau - leap versions of the finite - difference schemes @xcite that are commonly employed for sensitivity estimation .",
    "we find that even though @xmath8bpa is typically _ slower _ than these tau - leap finite - difference schemes , it is usually more accurate .",
    "this is primarily because the two sources of bias ( finite - difference and tau - leap approximations ) often pile on top of each other , thereby compromising the accuracy of an estimate .",
    "this makes @xmath8bpa an appealing method for sensitivity analysis of stochastic reaction networks , where the exact dynamical simulations are computationally infeasible and tau - leap approximations become necessary .",
    "as we argue in section [ using_tau_leap_methods ] , tau - leap simulations provide a natural way to _ trade - off _ estimator bias with gains in computational speed .",
    "therefore it would be of fundamental importance to extend the ideas in this paper and try to _ maximize _ the computational gains from tau - leap simulations while sacrificing the _ minimum _ amount of accuracy . in this context",
    ", we now mention two possible directions for future research .",
    "the method we proposed here , @xmath8bpa , can work with any underlying tau - leap simulation scheme , but for simplicity we examined it with the most basic tau - leap scheme i.e. an explicit euler method with a constant ( deterministic ) step - size and poissonian reaction firings @xcite .",
    "as this tau - leap scheme has several drawbacks ( see @xcite ) , it is very likely that @xmath8bpa can yield much better results if a more sophisticated tau - leap scheme is employed , possibly with random step - sizes @xcite , or with binomial leaps @xcite or using implicit step - size selection @xcite .",
    "we shall explore these issues in a future paper .",
    "another promising direction would be to devise a _",
    "multilevel _ version of @xmath8bpa , where estimators are constructed for a range to @xmath8-values , and are suitably coupled to simultaneously reduce the overall estimator s bias and variance @xcite .",
    "in this section we provide the proofs of the main results in this paper , namely , theorems [ thm : main ] and [ thm - tau - conv ] .",
    "+    let @xmath121 be the filtration generated by the process @xmath122 and let @xmath109 be its @xmath123-th jump time for @xmath124 .",
    "we define @xmath98 for convenience .",
    "since the process @xmath122 is constant between consecutive jump times we can write @xmath125 where @xmath126 and the last equality holds due to linearity of the expectation operator and the fact that @xmath127 if @xmath128 .",
    "given @xmath129 and @xmath130 , the distribution of the random variable @xmath131 has the _ cumulative density function _ given by @xmath132 this shows that for any continuous function @xmath133 we have @xmath134 however using integration by parts we get @xmath135_{s = 0}^{s = t - u } + \\int_{0}^{t - u } e^ { -\\lambda_0(y,\\theta)s }   g(s)ds \\\\ & = - e^{-\\lambda_0(y,\\theta)(t - u ) } \\int_{0}^{t -u } g(s)ds+ \\int_{0}^{t - u } e^ { -\\lambda_0(y,\\theta)s }   g(s)ds .\\end{aligned}\\ ] ] substituting this expression in equation we get @xmath136 taking @xmath137 for all @xmath138 gives us @xmath139 therefore @xmath140 and equation implies that @xmath141    we mentioned in section [ subsec : unbiasedmethods ] that the sensitivity value @xmath142 can be expressed as the expectation of the random variable @xmath108 defined by .",
    "using this fact along with we obtain @xmath143 since @xmath110 is given by we have @xmath144 relation with @xmath145 shows that given @xmath146 and @xmath147 , the following holds @xmath148 therefore @xmath149 since @xmath150 for all @xmath151 . substituting this expression in implies that @xmath152 this completes the proof of this result .",
    "for each @xmath153 define @xmath154 by @xmath155 without loss of generality , we can assume that there exists a @xmath156 such that @xmath157 then due to lemma [ lem - phi - ass123 ] we obtain @xmath158 } |h_k(x , t ) - g_k(x , t)| & \\leq \\partial \\lambda_k(x ) c c_1(p , t,\\alpha_1 ) \\left((1 + \\|x\\|^{\\xi(p ) } ) + ( 1+\\|x+\\zeta_k\\|^{\\xi(p ) } ) \\right ) \\tau _ { \\textnormal{max } } ^\\gamma \\\\   & \\leq c^2 c_1(p , t,\\alpha_1 ) ( 1 + \\|x\\|^{p } ) \\left((1 + \\|x\\|^{\\xi(p ) } ) + ( 1+\\|x+\\zeta_k\\|^{\\xi(p ) } ) \\right ) \\tau _ { \\textnormal{max } } ^\\gamma\\\\ & \\leq c_0(p ) c^2 c_1(p , t,\\alpha_1 ) \\left(1 + \\|x\\|^{(p+\\xi(p))}\\right ) \\tau _ { \\textnormal{max } } ^\\gamma , \\end{aligned}\\ ] ] where @xmath159 is a constant that depends only on @xmath160 as well as @xmath161 . lemma [ lem - phi - ass123 ] also shows that @xmath162 } |h_k(x , t)| & \\leq \\partial \\lambda_k(x ) c c_3(p , t,\\alpha_1 ) \\left ( ( 1 + \\|x\\|^p ) + ( 1+\\|x+\\zeta_k\\|^p ) \\right)\\\\ & \\leq c_1(p ) c^2 c_3(p , t,\\alpha_1 ) ( 1 + \\|x\\|^{2p } ) \\end{aligned}\\ ] ] and @xmath163 } |g_k(x ,",
    "t)| \\leq c_1(p ) c^2 c_2(p , t ) ( 1 + \\|x\\|^{2p}),\\ ] ] where @xmath164 is again a constant that depends only on @xmath160 and @xmath161 .    from and lemma [ lem - phi - ass123 ] it follows that @xmath165 } |\\e(h_k(z_{\\alpha_0,\\beta_0}(x_0,t),t ) ) - \\e(h_k(x(t),t))|   \\leq c_1(p ) c^2 c_3(p , t,\\alpha_1 ) c_1(2p , t,\\alpha_0 ) \\left(1 + \\|x_0\\|^{\\xi(2p)}\\right ) \\tau _ { \\textnormal{max } } ^\\gamma.\\ ] ] moreover from , we get @xmath166 and hence using assumption 2 , we obtain @xmath167 }",
    "\\e(|h_k(x(t),t)-g_k(x(t),t)| ) \\leq c_0(p ) c^2 c_1(p , t,\\alpha_1 ) c_2(p+\\xi(p),t ) \\left(1 + \\|x_0\\|^{p + \\xi(p)}\\right ) \\tau _ { \\textnormal{max } } ^\\gamma.\\ ] ]            d.  anderson and t.  kurtz .",
    "continuous time markov chain models for chemical reaction networks . in h.  koeppl , g.  setti , m.  di  bernardo , and d.  densmore , editors , _ design and analysis of biomolecular circuits_. springer - verlag , 2011 .              c.  r. bruno a.  walther , joslin l.  moore .",
    "the concepts of bias , precision and accuracy , and their use in testing the performance of species richness estimators , with a literature review of estimator performance .",
    ", 28(6):815829 , 2005 .",
    "s.  n. ethier and t.  g. kurtz . .",
    "wiley series in probability and mathematical statistics : probability and mathematical statistics .",
    "john wiley & sons inc .",
    ", new york , 1986 .",
    "characterization and convergence ."
  ],
  "abstract_text": [
    "<S> we consider the important problem of estimating parameter sensitivities for stochastic models of reaction networks that describe the dynamics as a continuous - time markov process over a discrete lattice . </S>",
    "<S> these sensitivity values are useful for understanding network properties , validating their design and identifying the pivotal model parameters . </S>",
    "<S> many methods for sensitivity estimation have been developed , but their computational feasibility suffers from the critical bottleneck of requiring time - consuming monte carlo simulations of the exact reaction dynamics . to circumvent this problem one needs to devise methods that speed up the computations while suffering acceptable and quantifiable loss of accuracy . </S>",
    "<S> we develop such a method by first deriving a novel integral representation of parameter sensitivity and then demonstrating that this integral may be approximated by any convergent tau - leap method . </S>",
    "<S> our method is easy to implement , works with any tau - leap simulation scheme and its accuracy is proved to be similar to that of the underlying tau - leap scheme . </S>",
    "<S> we demonstrate the efficiency of our methods through numerical examples . </S>",
    "<S> we also compare our method with the tau - leap versions of certain finite - difference schemes that are commonly used for sensitivity estimations . </S>",
    "<S> +    [ section ] [ theorem]lemma [ theorem]condition [ theorem]proposition [ theorem]remark [ theorem]definition [ theorem]hypothesis [ theorem]corollary [ theorem]example [ theorem]description [ theorem]assumption        </S>",
    "<S> |    * keywords : * parameter sensitivity ; reaction networks ; markov process ; tau - leap simulations + * mathematical subject classification ( 2010 ) : * 60j22 ; 60j27 ; 60h35 ; 65c05 . </S>"
  ]
}