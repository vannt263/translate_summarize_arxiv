{
  "article_text": [
    "our general problem is to restore an image @xmath0 from its corrupted linear measurements in the form of @xmath1 , where @xmath2 is a linear operator and @xmath3 is some noise .",
    "examples of such recovery include image denoising ( @xmath2 equals the identity operator @xmath4 ) , super - resolution ( @xmath2 is a downsampling operator ) , image deblurring ( @xmath2 is a blurring operator ) , compressive imaging recovery ( @xmath2 is a compressed sensing operator ) , as well as medical imaging recovery ( @xmath2 can be a downsampled fourier or a radon operator , for example ) .",
    "this paper restores the image @xmath0 by computing its sparse representation under a learned dictionary . following the approach pioneered in @xcite , we numerically form a dictionary that sparsely represents each and all the overlapping _ patches _ of @xmath0 .",
    "given such a dictionary @xmath5 , we reconstruct the image patches by finding their sparse coefficients and then recover the image from the patches .",
    "we address an open issue regarding _ whole  image _ recovery : the large number of overlapping patches lead to a large number of free coefficients in the recovery , which can cause overfitting and slow computation .",
    "this issue has limited most of the patch - based methods ( with a few exceptions we shall review below ) to the `` local '' or `` nearly local '' kinds of image processing tasks such as denoising , inpainting , deblurring , and super - resolution .",
    "for these tasks , one or a few patches can be processed at a time , independently of the majority of the remaining patches , thus avoiding the overfitting issue . we , however , consider the more difficult `` global '' kind of task such as compressive sensing recovery , where each piece of the measurements encodes the whole image and thus it is either impossible or very ineffective to process one or a few patches at a time",
    ".    bearing this issue in mind , we _ do not _ process either one patch at a time or all the overlapping patches at once , but instead we process one subset of _ non - overlapping , covering _ patches at a time .",
    "( covering means that the subset of patches covers all the pixels of the image . )",
    "each time , we process this subset of patches and obtain a recovery of the whole image . after we process multiple different subsets of _ non - overlapping , covering _ patches , we obtain multiple whole - image recoveries , whose average is taken to eliminate the grid artifact that might exist in the individual ones .",
    "this simple strategy is surprisingly effective .",
    "computationally , the different subsets of patches can be processed in parallel , and we found using merely five different subsets is enough to remove the grid artifact . for each subset ,",
    "the corresponding @xmath6 minimization problem is rather small : if @xmath7 patches are used , it only has roughly 1/64 of the free variables that one would have if all the overlapping patches are processed at once .",
    "qualitatively , the averaged recovery has a higher psnr than other state - of - the - art approaches that address the overfitting issue by applying either online optimization or incorporating additional image structures .",
    "we also introduce a fast algorithm for learning the dictionary @xmath5 , which plays a vital role in both our proposed recovery method and others . here , @xmath5 can be pre - learned from a set of similar images , and then either fixed during the recovery or iteratively updated in adaptive to the image under recovery . following @xcite , after recovering an image , we update the dictionary to fit the recovered image by solving an @xmath6-regularized model .",
    "we introduce an algorithm to update dictionary @xmath5 and sparse coefficient @xmath8 alternatively .",
    "unlike existing algorithms ( e.g. @xcite ) , it does not exactly minimize over either @xmath5 or @xmath8 , yet it decreases the energy very fast and provably converges to a stationary solution .",
    "our code and several demos can be downloaded from our websites . before giving more details of our approach and its numerical results , we first review the related literature .",
    "various methods have been developed to restore an image from its corrupted and/or incomplete measurements .",
    "one popular class of recovery methods are based on sparse coding and dictionary such as those in @xcite .",
    "we say a signal @xmath9 is sparse ( or approximately sparse ) under a dictionary @xmath10 if @xmath11 ( or @xmath12 ) and @xmath13 has only a few nonzeros .",
    "many types of signals can be sparsely represented by some dictionary .",
    "for example , natural images are approximately sparse under dictionaries based on various wavelet , curvelet , shearlet , and other transforms .",
    "suppose @xmath14 has a sparse representation under a dictionary @xmath5 .",
    "then given @xmath5 and linear measurements @xmath15 , one can recover @xmath14 through sparsely coding @xmath14 via solving @xmath16 where @xmath17 counts the nonzero number of its argument and is often approximated by @xmath18 for tractable computation , and @xmath19 is a parameter corresponding to @xmath3 . once a solution @xmath20 of is obtained , the original signal @xmath14 can be estimated by @xmath21 .",
    "the dictionary @xmath5 can be either predetermined or learned from a set of training data .",
    "predetermined dictionaries , such as orthogonal or overcomplete wavelets , curvelets , and discrete cosine transforms ( dct ) , can have advantages of fast implementation over a learned one .",
    "assuming easy availability of training datasets , however , it has been demonstrated ( e.g. , in @xcite ) that a learned dictionary can better adapt to natural signals and improve the recovery quality .    for natural images , existing methods such as mod @xcite and ksvd @xcite",
    "learn a dictionary @xmath5 to sparsely represent the patches of an image , rather than the whole image itself .",
    "in other words , the size of dictionary atoms is the same as that of the image patches , for example , @xmath22 or @xmath7 . to denoise an image @xmath0 with a patch - size dictionary",
    ", the pioneering work @xcite denoises each of the overlapping patches of @xmath0 via sparse coding and then estimates @xmath0 as the average of all the denoised patches together with the observed noisy image .",
    "this patch - based method was then extended to compressed sensing mri  a whole - image recovery problem  in @xcite , which starts from a rough estimate of @xmath0 , then simultaneously updates dictionary @xmath5 and sparse coefficients of all overlapping patches , and finally averages all the recovered patches to estimate @xmath0 .",
    "dong et al . in @xcite use local dictionaries to sparsely represent local patches and incorporate additional local auto - regression ( ar ) and non - local similarity ( nls ) terms to reduce overfitting and improve recovery results .",
    "their model was demonstrated effective on image debluring and super - resolution .",
    "these and their follow - up works ( e.g. , @xcite ) use overlapping patches since tiling non - overlapping patches can cause visible grid artifact along the patch boundaries , which is avoided by using overlapping patches .      due to a lack of analytic structures , it can be computationally demanding to learn a dictionary .",
    "one of the most popular algorithms for dictionary learning is ksvd @xcite : @xmath23 where @xmath24 is the training dataset , @xmath25 denotes the euclidean norm , @xmath26 is a parameter to control sparsity , and @xmath27 is the @xmath28th column of @xmath5 .",
    "ksvd attempts to solve by alternatively updating @xmath8 and @xmath5 in a certain way .",
    "the objective is monotonically non - increasing and the denoising and inpainting performances are very good , but the convergence to a stationary point is not guaranteed .",
    "furthermore , it is slow as it performs svd to update @xmath5 and exact minimization to update every @xmath29 in each iteration .",
    "another popular method is the online dictionary learning ( olm ) @xcite , which , via an online update approach , attempts to solve @xmath30 where @xmath31 is a convex relaxation of @xmath17 , and @xmath32 is a tuning parameter to balance data fitting and sparsity level .",
    "olm alternatively updates @xmath8 and @xmath5 as follows .",
    "when @xmath5 is fixed , it randomly picks a batch of columns of @xmath33 and applies sparse coding to each selected column . letting @xmath34",
    "be the index set of all previously selected samples and @xmath35 contain their sparse coefficients , the method then updates @xmath5 to the solution of @xmath36 , where @xmath37 denotes the submatrix consisting of all columns of @xmath33 indexed by @xmath34 .",
    "the above two steps are then repeated until convergence .",
    "the algorithm often runs faster than ksvd , and its efficiency relies on the assumption that all training samples have the same distribution . assuming that the training data admits bounded probability with a compact support and @xmath38 is uniformly positive definite , it is shown that the iterate sequence asymptotically satisfies the first - order optimality condition of .",
    "the global convergence of the iterate sequence is still open .",
    "we refer the interested readers to the review paper @xcite for other dictionary learning methods .",
    "in addition , more complicated models have been proposed to learn dictionaries for specific tasks ; see @xcite for example .",
    "we do not intend to consider those models and will keep our focus on in this paper .",
    "this paper makes the following contributions :    * we propose a simple , novel method that recovers a whole image by applying sparse coding to its patches .",
    "in addition to the traditional denoising , inpainting , and deblurring tasks , the method can be applied to recovering an image from its whole - image linear measurements , which arise in the applications of compressive sensing and medical imaging .",
    "the method is simple and can include additional energy terms and constraints , as well as to be embedded in more complicated imaging applications .",
    "we want to emphasize that our method recovers the whole image at a time and is different from local recovery methods such as those in @xcite which process image patches one by one . * along with the method , we introduce a numerical algorithm for dictionary learning that is fast and has provable convergence to a stationary point .",
    "the algorithm is based on our recent work on block proximal gradient update in @xcite .",
    "compared to the existing algorithms , the proposed algorithm has a low per - iteration cost and converges fast .",
    "* we provide matlab codes for three different imaging tasks that are ( i ) inpainting : fill in image missing pixels ; ( ii ) compressive sensing recovery : recover an image from its undersampled linear measurements ; ( iii ) image deblurring : restore a clean image from its blurs . on these tasks , our codes",
    "compare favorably to total variation ( tv ) methods , as well as those from @xcite using overlapping patches and learned dictionaries .",
    "the rest of the paper is organized as follows . in section [ sec : rec ] , we give a new model for recovering an image from its linear measurements , and also discuss how to improve recovery results .",
    "section [ sec : alg ] applies a block proximal gradient method to and makes a new dictionary learning algorithm .",
    "numerical results are reported in section [ sec : numerical ] , and finally section [ sec : conclusion ] concludes the paper .",
    "given a patch - size dictionary @xmath5 , we aim at recovering an image @xmath0 from its corrupted linear measurements @xmath1 , where @xmath2 is a linear operator and @xmath3 is some noise .",
    "the case of @xmath39 has been considered in the pioneering work @xcite , which alternatively performs sparse coding to denoise every patch and takes average over all overlapping denoised patches together with the observed noisy image . throughout the discussion in the remaining part of the paper , we assume that a generic image has size @xmath40 and training patches to be @xmath41 . the dictionary @xmath5 has @xmath42 atoms , and all of them are vectors in @xmath43 dimensional space .",
    "keep in mind that an @xmath44 matrix is equivalent to an @xmath45 vector under matlab s ` reshape ` operation .",
    "hence , we will use a matrix and its reshaped vector interchangeably .",
    "for example , a dictionary atom can be regarded as either a vector of length @xmath46 or an @xmath41 patch .",
    "motivated by @xcite , we exactly represent an image by @xmath47 where @xmath48 is an operator taking the @xmath49-th patch , @xmath50 is the adjoint of @xmath48 , and @xmath51 contains a subset of patches covering all the pixels of @xmath0 , ensuring that @xmath52 is invertible .",
    "note that @xmath52 is diagonal , and thus its inverse can be implemented in a pixel - by - pixel manner .",
    "if every patch @xmath53 in @xmath51 has a sparse representation under @xmath5 , i.e. , @xmath54 for a sparse vector @xmath55 , then the above representation can be written as @xmath56 using this representation , we make the following weighted @xmath6 model : @xmath57 where @xmath58 is a weight vector for @xmath59 , @xmath60 is the noise level determined by @xmath3 , and `` @xmath61 '' denotes component - wise product .",
    "equivalently , one can consider the unconstrained model : @xmath62 where @xmath63 is a parameter corresponding to @xmath60 . upon solving or",
    ", one can use @xmath64 to estimate @xmath0 .",
    "our models are similar to that in @xcite : @xmath65 \\hspace{1cm}+\\text{ar}({{\\bf y}})+\\text{nls}({{\\bf y } } ) , \\end{array}\\ ] ] where @xmath34 denotes the set of all overlapping patches , @xmath63 is a parameter balancing sparsity and data fitting , @xmath66 is a given local dictionary used to represent the @xmath49-th patch , and @xmath67 and @xmath68 are two regularization terms corresponding to local auto - regression and non - local similarity",
    ". the local dictionaries are often incomplete ( i.e. , fewer columns than rows ) .",
    "similar to non - overlapping patches ( see next paragraph ) , non - completeness of local dictionaries and ar and nls terms can reduce variable freedom and increase recoverability of",
    ". however , the use of more dictionaries and complicated regularization terms makes more difficult to solve than our models .",
    "one question is how to choose @xmath51 , the subset of covering patches , such that or work well for recovering @xmath0 .",
    "we let @xmath51 be a subset of non - overlapping , covering patches and focus on the unconstrained model .",
    "figure [ fig : overlap ] compares the two approaches . in this test , we set @xmath39 and @xmath69 with @xmath70 , and we compared with two different @xmath51 s . in figure",
    "[ fig : overlap ] , the left image uses all overlapping patches , and the right image uses one subset of non - overlapping , covering patches .",
    "we see that with all patches produces much worse result than that with non - overlapping @xmath51 .",
    "we want to emphasize here that our results do not counter the intuition that using more patches should give better recovery .",
    "the results in table [ table : avg ] of section [ sec : numerical ] demonstrate that using more different subsets of non - overlapping , covering patches can consistently improve the recovered image quality .",
    "the phenomenon in figure [ fig : overlap ] can be explained as follows . using all the overlapping patches in or introduces too many unknowns to decide .",
    "the @xmath6 minimization typically needs @xmath71 or more measurements to recover an @xmath26-sparse signal of length @xmath72 .",
    "suppose that the @xmath55 corresponding to each patch has at least @xmath73 nonzeros and all the @xmath74 overlapping patches are used .",
    "then vector @xmath20 has @xmath75 entries out of which at least @xmath76 are nonzeros . on the other hand , we have at most @xmath77 measurements , not sufficiently many to reach @xmath78 . _ therefore , unless more constraints or regularizations on @xmath20 are introduced to help ( see for instance ) , we can not use all the patches . _    [ cols=\"^,^ \" , ]     next , we compare algorithm [ alg : rec ] with two different dictionaries and algorithm [ alg : adp ] on the four images shown in figure [ fig : orig ] .",
    "all of these images were unrelated to the learned dictionary @xmath5 . to show the effectiveness of",
    ", we also included a tv - based method for the first two @xmath2 s and an overlapping patch - based method for the third kind of @xmath2 in the comparison .",
    "the tv - based method solves @xmath79 where @xmath80 denotes tv semi - norm , and the overlapping patch - based method solves .",
    "we employed tval3 ( version beta2.4 ) @xcite to solve , and its default settings were used .",
    "the model was solved by the algorithm in @xcite , and its code was available online from the authors webpage .",
    "we set its maximum number of iterations to @xmath81 , which was sufficiently large to make the algorithm to solve to a high accuracy . in their code , the second group of local dictionaries were used , and we tuned the parameters ` par.tau ` and ` par.c1 ` while all the other parameters were set to their default values . for color images , each of rgb channels was recovered independently .    for @xmath82 , we tested @xmath83 , and for @xmath84 , we tested @xmath85 . for each tested image , we chose three different partitions , whose upper - left corner patches were @xmath86 , @xmath87 , and @xmath88 , respectively .",
    "the same three partitions were used in both algorithms [ alg : rec ] and [ alg : adp ] .",
    "table [ table : mc ] lists the average results of five independent trials by the compared methods for @xmath82 , table [ table : cs ] for @xmath84 and table [ table : blur ] for image deblurring . from the results",
    ", we see that algorithm [ alg : rec ] works better with learned @xmath5 than dct except for the castle image when @xmath2 is ` average ` blurring operator and @xmath89 .",
    "our method with learned @xmath5 is consistently better for @xmath82 and much better for @xmath84 than tv - based model . for both blurring operators ,",
    "our method is better than that in @xcite for solving except when noise level @xmath89 , the latter performs better on the boat image for ` average ` and the castle image for both ` average ` and ` motion ` .",
    "in addition , algorithm [ alg : adp ] with adaptively updated dictionary makes improvement over algorithm [ alg : rec ] in all cases except for the castle and boat images when @xmath2 is ` average ` blurring operator and @xmath89 .",
    "the improvement usually increases as sr increases .",
    "it is reasonable since higher srs give cleaner images , which further generate better dictionaries .",
    "we provide open source codes on our websites and welcome the interested reader to try it on more datasets .      + castle & 26.16 & 24.58 & * 26.37 * & 25.05 & 29.30 & 27.41 & * 29.51 * & 27.88 + lena & 31.40 & 28.57 & * 31.70 * & 29.07 & 35.33 & 31.98 & * 35.44 * & 32.43 + plane & 32.66 & 29.17 & * 33.46 * & 30.31 & 37.43 & 32.62 & * 38.56 * & 33.53 + boat & 28.49 & 25.79 & * 29.14 * & 26.70 & 31.86 & 29.05 & * 32.48 * & 30.00 +   + castle & 26.09 & 24.57 & * 26.23 * & 24.99 & 29.22 & 27.30 & * 29.47 * & 27.68 + lena & 31.02 & 28.50 & * 31.22 * & 28.91 & 34.49 & 31.64 & * 34.81 * & 31.96 + plane & 32.29 & 29.18 & * 32.54 * & 30.11 & 36.84 & 32.58 & * 37.54 * & 33.02 + boat & 28.31 & 25.82 & * 28.63 * & 26.62 & 31.67 & 28.88 & * 32.28 * & 29.70 +   + castle & 25.85 & 24.47 & * 25.98 * & 24.81 & 28.76 & 27.02 & * 29.00 * & 27.15 + lena & 30.34 & 28.25 & * 30.53 * & 28.47 & 33.21 & 30.96 & * 33.41 * & 30.77 + plane & 31.81 & 29.06 & * 32.03 * & 29.50 & 35.67 & 32.18 & * 36.27 * & 31.57 + boat & 27.78 & 25.62 & * 28.07 * & 26.30 & 30.75 & 28.36 & * 31.30 * & 28.90 +      + castle & 22.37 & 29.50 & 28.62 & * 29.56 * & 28.69 & 23.24 & 33.28 & 33.06 & * 34.26 * & 31.71 + lena & 26.00 & 33.01 & 32.05 & * 33.04 * & 32.38 & 27.88 & 37.34 & 36.43 & * 37.58 * & 35.14 + plane & 27.88 & 37.27 & 34.60 & * 37.62 * & 33.74 & 28.66 & 40.98 & 39.63 & * 41.55 * & 35.35 + boat & 23.36 & 31.45 & 30.14 & * 31.54 * & 30.70 & 24.64 & 34.79 & 34.11 & * 35.31 * & 33.92 +   + castle & 22.03 & 26.39 & 25.99 & * 26.47 * & 25.42 & 22.91 & 27.39 & 26.43 & * 27.62 * & 26.85 + lena & 25.85 & 29.41 & 29.02 & * 29.60 * & 28.86 & 27.63 & 30.37 & 29.10 & * 31.16 * & 30.89 + plane & 27.64 & 31.84 & 30.89 & * 32.00 * & 29.91 & 28.36 & 34.18 & 31.78 & * 34.49 * & 31.74 + boat & 23.27 & 27.86 & 27.17 & * 27.95 * & 27.18 & 24.51 & 28.93 & 27.62 & * 29.17 * & 28.67 +   + castle & 21.77 & 24.10 & 24.14 & 23.92 & * 24.93 * & 22.60 & 24.95 & 24.29 & 25.02 & * 25.30 *",
    "+ lena & 25.44 & 27.49 & 27.02 & * 27.55 * & 27.25 & 26.95 & 29.61 & 28.64 & * 29.65 * & 28.33 + plane & 26.95 & 30.24 & 29.03 & * 30.39 * & 28.13 & 27.54 & 32.50 & 30.57 & * 32.83 * & 29.01 + boat & 22.99 & 25.34 & 25.20 & 25.13 & * 25.81 * & 24.13 & 26.66 & 25.62 & * 26.75 * & 26.70 +",
    "dictionary learning has been popularly applied to image denoising , super - resolution , classification and feature extraction .",
    "various algorithms have been proposed for learning dictionaries to achieve different goals . in this paper , we focus on whole - image recovery and develop novel methods for learning dictionaries and then recovering images quickly and faithfully .",
    "our algorithm not only has low per - iteration complexity and also converges fast . in the algorithm , using non - overlapping patches and averaging across different subsets of patches greatly reduce the variable freedom and are critical for fast and successful recovery .                                  , _ a database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics _ , in computer vision , 2001 .",
    "iccv 2001 .",
    "eighth ieee international conference on , vol .  2 , ieee , 2001 , pp .",
    "416423 .    ,",
    "_ classification and clustering via dictionary learning with structured incoherence and shared features _",
    ", in computer vision and pattern recognition ( cvpr ) , 2010 ieee conference on , ieee , 2010 , pp",
    ".  35013508 .",
    ", _ a block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion _",
    ", siam journal on imaging sciences , 6 ( 2013 ) , pp",
    ".  17581789 ."
  ],
  "abstract_text": [
    "<S> various algorithms have been proposed for dictionary learning . among those for image processing , many use _ image patches _ to form dictionaries . </S>",
    "<S> this paper focuses on whole - image recovery from corrupted linear measurements . </S>",
    "<S> we address the open issue of representing an image by _ overlapping _ patches : the overlapping leads to an excessive number of dictionary coefficients to determine . </S>",
    "<S> with very few exceptions , this issue has limited the applications of image - patch methods to the `` local '' kind of tasks such as denoising , inpainting , cartoon - texture decomposition , super - resolution , and image deblurring , for which one can process a few patches at a time . </S>",
    "<S> our focus is global imaging tasks such as compressive sensing and medical image recovery , where the whole image is encoded together , making it either impossible or very ineffective to update a few patches at a time .    </S>",
    "<S> our strategy is to divide the sparse recovery into multiple subproblems , each of which handles a subset of non - overlapping patches , and then the results of the subproblems are averaged to yield the final recovery . </S>",
    "<S> this simple strategy is surprisingly effective in terms of both quality and speed .    </S>",
    "<S> in addition , we accelerate computation of the learned dictionary by applying a recent block proximal - gradient method , which not only has a lower per - iteration complexity but also takes fewer iterations to converge , compared to the current state - of - the - art . </S>",
    "<S> we also establish that our algorithm globally converges to a stationary point . </S>",
    "<S> numerical results on synthetic data demonstrate that our algorithm can recover a more faithful dictionary than two state - of - the - art methods .    </S>",
    "<S> combining our whole - image recovery and dictionary - learning methods , we numerically simulate image inpainting , compressive sensing recovery , and deblurring . </S>",
    "<S> our recovery is more faithful than those of a total variation method and a method based on overlapping patches . </S>",
    "<S> our matlab code is competitive in terms of both speed and quality .    </S>",
    "<S> yangyang xu    wotao yin </S>"
  ]
}