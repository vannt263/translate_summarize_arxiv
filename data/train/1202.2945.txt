{
  "article_text": [
    "statistical inference in general state space hidden markov models ( hmm ) involves computation of the _ posterior distribution _ of a  set @xmath0 $ ] of state variables conditional on a record @xmath1 of observations .",
    "this distribution will , in the following , be denoted by @xmath2 where the dependence of this measure on the observed values @xmath3 is implicit .",
    "the posterior distribution can be expressed in closed - form only in very specific cases , principally , when the state space model is linear and gaussian or when the state space of the hidden markov chain is a finite set . in the vast majority of cases ,",
    "nonlinearity or non - gaussianity render analytic solutions intractable @xcite .",
    "this limitation has led to an increase of interest in alternative computational strategies handling more general state and measurement equations without constraining a priori the behavior of the posterior distributions . among these , _ sequential monte carlo _",
    "( smc ) _ methods _ play a central role .",
    "smc methods  in which the _ sequential importance sampling _ and _ sampling importance resampling _ methods proposed by @xcite and @xcite , respectively , are combined  refer to a class of algorithms approximating a _ sequence of probability distributions _",
    ", defined on a _ sequence of probability spaces _ , by updating recursively a set of random _ particles _ with associated nonnegative _",
    "importance weights_. the smc methodology has emerged as a key tool for approximating state posterior distribution flows in general state space models ; see @xcite for general introductions as well as theoretical results for smc methods and @xcite for applications of smc within a variety of scientific fields .",
    "the recursive formulas generating the _ filter distributions _ @xmath4 ( short - hand notation for @xmath5 ) and the _ joint smoothing distributions _",
    "@xmath6 are closely related ; thus , executing the standard smc scheme in the filtering mode provides , as a by - product , approximations of the joint smoothing distributions .",
    "more specifically , the branches of the genealogical tree associated with the historical evolution of the filtering particles up to time step @xmath7 form , when combined with the corresponding importance weights of these filtering particles , a weighted sample approximating the joint smoothing distribution @xmath6 ; see @xcite , section 3.4 , for details . from these paths , one may readily obtain a weighted sample targeting the fixed lag or fixed interval smoothing distribution by extracting the required subsequence of states while retaining the weights .",
    "this appealingly simple scheme can be used successfully for estimating the joint smoothing distribution for small values of @xmath7 or any marginal smoothing distribution @xmath8 , with @xmath9 , when @xmath10 and @xmath7 are close ; however , when @xmath7 is large and @xmath11 , the associated particle approximations are inaccurate since the genealogical tree degenerates gradually as the interacting particle system evolves @xcite .    in this article , we thus give attention to more sophisticated approaches and consider instead the _ forward filtering backward smoothing _",
    "( ffbsm ) _ algorithm _ and the _ forward filtering backward simulation _ ( ffbsi ) _",
    "sampler_. these algorithms share some similarities with the baum ",
    "welch algorithm for finite state space models and the kalman filter - based smoother and simulation smoother for linear gaussian state space models @xcite . in the ffbsm algorithm ,",
    "the particle weights obtained when approximating the filter distributions in a forward filtering pass are modified in a backward pass ; see @xcite .",
    "the ffbsi algorithm simulates , conditionally independently given the particles and particle weights produced in a similar forward filtering pass , state trajectories being approximately distributed according to the joint smoothing distribution ; see @xcite .    the computational complexity of the ffbsm algorithm when used for estimating marginal fixed interval smoothing distributions or of the original formulation of the ffbsi sampler grows ( in most situations ) as the square of the number @xmath12 of particles multiplied by the time horizon @xmath7 . to alleviate this potentially very large computational cost ,",
    "some methods using intricate data structures for storing the particles have been developed ; see , for example ,  @xcite .",
    "these algorithms have a complexity of order @xmath13 and are thus amenable to practical applications ; however , this reduction in complexity comes at the cost of introducing some level of approximation .    in this paper ,",
    "a modification of the original ffbsi algorithm is presented .",
    "the proposed scheme has a complexity that grows only _ linearly _ in @xmath12 and does not involve any numerical approximation techniques .",
    "this algorithm may be seen as an alternative to a recent proposal by @xcite which is based on the so - called _ two - filter algorithm _ @xcite .",
    "the smoothing weights computed in the backward pass of the ffbsm algorithm at a given time instant @xmath10 ( or the law of the ffbsi algorithm ) are statistically dependent on all forward filtering pass particles and weights computed before and after this time instant .",
    "this intricate dependence structure makes the analysis of the resulting particle approximation challenging ; up to our best knowledge , only a single consistency result is available in  @xcite , but its proof is plagued by a ( subtle ) mistake that seems difficult to correct .",
    "therefore , very little is known about the convergence of the schemes under consideration , and the second purpose of this paper is to fill this gap . in this contribution , we focus first on finite time horizon approximations . given a finite time horizon @xmath7 , we derive _ exponential deviation inequalities _ stating that the probability of obtaining , when replacing @xmath14 by the corresponding ffbsm or ffbsi estimator , a monte carlo error exceeding a  given @xmath15 is bounded by a quantity of order @xmath16 where @xmath17 is positive constant depending on @xmath7 as well as the target function under consideration . the obtained inequalities , which are presented in theorem [ thm : hoeffding - ffbs ] ( ffbsm ) and corollary  [ cor : hoeffding - ffbsi ] ( ffbsi ) , hold for any given number @xmath12 of particles and are obtained by combining a novel backward error decomposition with an adaptation of the hoeffding inequality to statistics expressed as ratios of random variables .",
    "we then consider the asymptotic ( as the number  @xmath12 of particles tends to infinity ) regime and establish a central limit theorem ( clt ) with rate @xmath18 and with an explicit expression of the asymptotic variance ; see theorem [ thm : ffbs - clt ] .",
    "the proof of our clt relies on a technique , developed gradually in @xcite , which is based on a clt for triangular arrays of dependent random variables ; however , since we are required to take the complex dependence structure of the smoothing weights into account , our proof is significantly more involved than in the standard filtering framework considered in the mentioned works .",
    "the second part of the paper is devoted to time uniform results , and we here study the behavior of the particle - based marginal smoothing distribution approximations as the time horizon @xmath7 tends to infinity . in this setting , we first establish , under the assumption that the markov transition kernel  @xmath19 of the latent signal is strongly mixing ( assumption [ assum : strong - mixing - condition ] ) , time uniform deviation bounds of the type described above which hold for any particle population size @xmath12 and where the constant @xmath17 is _ independent _ of @xmath7 ; see theorem [ theo : hoeffding - uniform ] .",
    "this result may seem surprising , and the nonobvious reason for its validity stems from the fact that the underlying markov chain forgets , when evolving conditionally on the observations , its initial conditions in the forward _ as well as _ the backward directions . finally , we prove ( see theorem [ theo : clt - uniform ] ) , under the same uniform mixing assumption , that the asymptotic variance of the clt for the particle - based marginal smoothing distribution approximations remains bounded as @xmath7 tends to infinity .",
    "the uniform mixing assumption in assumption [ assum : strong - mixing - condition ] points typically to applications where the state space of the latent signal is compact ; nevertheless , in the light of recent results on filtering stability @xcite one may expect the geometrical contraction of the backward kernel to hold for a significantly larger class of nonuniformly mixing models ( see @xcite for examples from , e.g. , financial economics ) . but even though the geometrical mixing rate is supposed to be constant in this more general case , applying the mentioned results will yield a bound of contraction containing a multiplicative constant depending highly on the initial distributions as well as the observation record under consideration .",
    "since there are currently no available results describing this dependence , applying such bounds to the instrumental decomposition used in the proof of theorem [ thm : hoeffding - ffbs ] seems technically involved .",
    "recently , @xcite managed to derive _ qualitative _ time average convergence results for standard ( bootstrap - type ) particle filters under a mild tightness assumption being satisfied also in the noncompact case when the hidden chain is geometrically ergodic . even though this technique does not ( on the contrary to our approach ) supply a rate of convergence , it could possibly be adopted to our framework in order to establish time average convergence of the particle - based marginal smoothing distribution approximations in a noncompact setting .",
    "the paper is organized as follows . in section [ sec : ffbs ] , the ffbsm algorithm and the ffbsi sampler are introduced . an exponential deviation inequality for the fixed interval joint smoothing distribution is derived in section [ sec : exponentialffbs ] , and a clt is established in section [ sec : cltffbs ] . in section [ sec : timeuniformexponentialffbs ] , time uniform exponential bounds on the error of the ffbsm marginal smoothing distribution estimator are computed under the mentioned mixing condition on the kernel @xmath19 .",
    "finally , under the same mixing condition , an explicit bound on the asymptotic variance of the marginal smoothing distribution estimator is derived in section [ sec : timeuniformcltffbs ] .      for any sequence @xmath20 and any pair of integers @xmath21",
    ", we denote @xmath22 .",
    "we assume in the following that all random variables are defined on a common probability space @xmath23 .",
    "the sets @xmath24 and @xmath25 are supposed to be polish spaces and we denote by @xmath26 and @xmath27 the associated borel @xmath28-algebras .",
    "@xmath29 denotes the set of all bounded @xmath30-measurable functions from @xmath24 to @xmath31 . for any measure  @xmath32 on @xmath33 and any @xmath32-integrable function @xmath34 ,",
    "we set @xmath35 . two measures @xmath32 and @xmath36",
    "are said to be _ proportional _ ( written @xmath37 ) if they differ only by a normalization constant .",
    "a kernel @xmath38 from @xmath33 to @xmath39 is a mapping from @xmath40 into @xmath41 $ ] such that , for each @xmath42 , @xmath43 is a nonnegative , bounded , and measurable function on @xmath24 , and , for each @xmath44 , @xmath45 is a measure on @xmath27 . for @xmath46 and @xmath44 , denote by @xmath47",
    "; we will sometimes also use the abridged notation @xmath48 instead of @xmath49 . for a measure @xmath50 on @xmath33",
    ", we denote by @xmath51 the measure on @xmath39 defined by , for any @xmath42 , @xmath52 .",
    "consider now a possibly nonlinear state space model , where the _ state process _",
    "@xmath53 is a markov chain on the state space @xmath33 .",
    "even though  @xmath54 is not necessarily a temporal index , we will often refer to this index as `` time . ''",
    "we denote by @xmath55 and @xmath19 the initial distribution and transition kernel , respectively , of this process .",
    "the state process is assumed to be hidden but partially observed through the _ observations _",
    "@xmath56 which are @xmath25-valued random variables being conditionally independent given the latent state sequence @xmath57 ; in addition , there exists a @xmath28-finite measure @xmath58 on @xmath39 and a nonnegative transition density function @xmath59 on @xmath60 such that @xmath61}{\\mathbb{p } _ { } [ y_t \\in a   | x_t ] } } = \\int_a g(x_t , y ) \\lambda({d}y)$ ] for all @xmath42 .",
    "the mapping @xmath62 is referred to as the _ likelihood function _ of the state given an observed value @xmath63 .",
    "the kernel @xmath19 as well as the transition density @xmath59 are supposed to be known . in the setting of this paper ,",
    "we assume that we have access to a record of arbitrary but fixed observations @xmath64 $ ] , and our main task is to estimate the posterior distribution of ( different subsets of ) the state vector @xmath65 given these observations . for any @xmath66 , we denote by @xmath67 ( where the dependence on @xmath68 is implicit ) the likelihood function of the state @xmath69 given the observation @xmath68 .    for simplicity , we consider a _ fully dominated _ state space model for which there exists a @xmath28-finite measure @xmath50 on @xmath70 such that , for all @xmath44 , @xmath71 has a transition probability density @xmath72 with respect to  @xmath73 . for notational simplicity ,",
    "@xmath74 will sometimes be replaced by @xmath75 .    for any initial distribution @xmath55 on @xmath33 and any @xmath76 , denote by @xmath2 the posterior distribution of the state vector @xmath77 given the observations @xmath3 . for lucidity",
    ", the dependence of @xmath2 on the initial distribution  @xmath55 is omitted .",
    "assuming that @xmath78 , this distribution may be expressed as , for all @xmath79 , @xmath80 in the expression above , the dependence on the observation sequence is implicit . if @xmath81 , we use @xmath8 ( the marginal smoothing distribution at time  @xmath10 ) as shorthand for @xmath82 .",
    "if @xmath83 , we denote by @xmath84 the filtering distribution at time  @xmath10 .",
    "conditionally on the observations @xmath3 , the state sequence @xmath85 is a time inhomogeneous markov chain .",
    "this property remains true in the _ time - reversed _ direction .",
    "denote by @xmath86 the so - called _ backward kernel _ given by , for any probability measure @xmath87 on @xmath33 , @xmath88 the posterior distribution @xmath14 may be expressed as , for any integers @xmath89 , @xmath90 and any @xmath91 , @xmath92 therefore , the joint smoothing distribution may be computed recursively , backward in time , according to @xmath93      as mentioned in the , the method proposed by @xcite for approximating the smoothing distribution is a two pass procedure . in the forward pass , particle approximations @xmath94 of the filter distributions @xmath95",
    "are computed recursively for all time steps from @xmath96 up to @xmath97 . the filter distribution flow",
    "@xmath98 satisfies the forward recursion @xmath99 for @xmath100 , with @xmath101 being the unity function @xmath102 on @xmath24 . in terms of smc , each filter distribution @xmath95 is approximated by means of a set of particles @xmath103 and associated importance weights @xmath104 according to @xmath105 having produced , using methods described in section [ section : apf ] below , a sequence of such weighted samples @xmath106 , @xmath107 , an approximation of the smoothing distribution is constructed in a backward pass by replacing , in ( [ eq : smoothing : backw_decomposition ] ) , the filtering distribution by its particle approximation .",
    "this yields @xmath108 for any @xmath91 .",
    "the approximation above can be computed recursively in the backward direction according to @xmath109 now , by definition , @xmath110 and inserting this expression into ( [ eq : smoothing : backw_decomposition_sample ] ) gives @xmath111 of @xmath112 , where @xmath113 and @xmath114 the estimator @xmath115 is impractical since the cardinality of its support grows exponentially with the number @xmath116 of time steps ; nevertheless , it plays a  key role in the theoretical developments that follow .",
    "a more practical approximation of this quantity will be defined in the next section .",
    "when the dimension of the input space is moderate , the computational cost of evaluating the estimator can be reduced to @xmath117 by using the _ fast multipole method _ as suggested in @xcite ; note , however , that this method involves approximations that introduce some bias . on the other hand , in certain specific scenarios , such as discrete markov chains with sparse transition matrices over large state spaces ,",
    "the complexity can even be reduced to @xmath118 without any truncation ; see @xcite .",
    "the estimator  ( [ eq : forward - filtering - backward - smoothing ] ) may be understood alternatively by noting that the normalized smoothing weights define a probability distribution on the set @xmath119 of trajectories associated with an inhomogeneous markov chain .",
    "indeed , consider , for @xmath120 , the markov transition matrix @xmath121 given by @xmath122 for @xmath107 , denote by @xmath123 the @xmath28-algebra generated by the observations from time @xmath124 to time @xmath7 as well as the particles and importance weights produced in the forward pass up to time @xmath54 .",
    "the transition probabilities defined in ( [ eq : definition - transition - matrix - w ] ) induce an inhomogeneous markov chain @xmath125 evolving backward in time as follows . at time @xmath7 , the random index @xmath126 is drawn from the set @xmath127 such that @xmath126 takes the value @xmath128 with a probability proportional to @xmath129 . at time @xmath130 and given that the index @xmath131 was drawn at time step @xmath132 , the index @xmath133 is drawn from the set @xmath134 such that @xmath133 takes the value @xmath135 with probability @xmath136 .",
    "the joint distribution of @xmath137 is therefore given by , for @xmath138 , @xmath139 = \\frac{{\\ensuremath{\\omega_{t}^{j_t}}}}{{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{t}}}{\\ensuremath { \\omega_{t}^ { ( ) } } } } } \\lambda_t^n(j_t , j_{t-1 } ) \\cdots \\lambda_0^n(j_1 , j_0 ) .\\ ] ] thus , and this is a key observation , the ffbs estimator ( [ eq : forward - filtering - backward - smoothing ] ) of the joint smoothing distribution may be written as the conditional expectation @xmath140}{\\mathbb{e } _ { } [ h ( { \\ensuremath{\\xi_{0}^{j_0 } } } , \\dots , { \\ensuremath{\\xi_{t}^{j_t } } } )   | { \\mathcal{f}_{t}^{n } } ] } } , \\qquad   h \\in{\\mathcal{f}_{\\mathrm{b}}({\\mathbb{x}}^{t+1 } ) } .\\ ] ] we may therefore construct an unbiased estimator of the ffbs estimator by drawing , conditionally independently given @xmath141 , @xmath12 paths of @xmath142 of the inhomogeneous markov chain introduced above and then forming the ( practical ) estimator @xmath143 this practical estimator was introduced in @xcite ( algorithm 1 , page 158 ) . for ease of notation , we have here simulated @xmath12 replicates of the backward , index - valued markov chain , but it would of course also be possible to sample a  number of paths that is either larger or smaller than @xmath12 .",
    "the estimator @xmath144 may be seen as a rao ",
    "blackwellized version of @xmath145 .",
    "the variance of the latter is increased , but the gain in computational complexity is significant .",
    "the associated algorithm is referred in the sequel to as the forward filtering backward simulation ( ffbsi ) algorithm . in section [ sec : timeuniformexponentialffbs ] , forgetting properties of the inhomogeneous backward chain will play a key role when establishing time uniform stability properties of the proposed smoothing algorithm .",
    "the computational complexity for sampling a single path of @xmath137 is @xmath146 ; therefore , the overall computational effort spent when estimating @xmath147 using the ffbsi sampler is @xmath148 . following @xcite",
    ", this complexity can be reduced further to @xmath149 by means of the fast multipole method ; however , here again computational work is gained at the cost of introducing additional approximations .",
    "we are now ready to describe one of the main contributions of this paper , namely a novel version of the ffbsi algorithm that can be proved to reach linear computational complexity under appropriate assumptions . at the end of the filtering phase of the ffbsi algorithm , all weighted particle samples @xmath150 , @xmath151 , are available , and it remains to sample efficiently index paths @xmath152 under the distribution ( [ eq : distribution - non - homogeneous ] ) .",
    "when the transition kernel @xmath153 is bounded from above in the sense that @xmath154 for all @xmath155 , the paths can be simulated recursively backward in time using the following accept  reject procedure .",
    "as in the standard ffbsi algorithm , the recursion is initiated by sampling @xmath156 multinomially with probabilities proportional to @xmath157 .",
    "for @xmath158 , let  @xmath159 the smallest @xmath28-field containing @xmath141 and @xmath160 ; then in order to draw @xmath161 conditionally on @xmath162 , we draw , first , an index proposal  @xmath163 taking the value @xmath164 with a probability proportional to  @xmath165 and , second , an independent uniform random variable @xmath166 on @xmath167 $ ]",
    ". then we set @xmath168 if @xmath169 ; otherwise , we reject the proposed index and make another trial . to create samples of size @xmath170 from a  multinomial distribution on a set of @xmath12 elements at lines 1 and 6 , algorithm  [ alg : smooth ]",
    "relies on an efficient procedure described in appendix [ subsec : multisampling ] that requires @xmath171 elementary operations ; see proposition [ prop : multisample ] . using this technique , the computational complexity of algorithm [ alg : smooth ] can be upper - bounded as follows .",
    "[ alg : samp1]sample @xmath156 multinomially with probabilities proportional to @xmath172 @xmath173 @xmath174 size(l ) [ alg : updatem ] [ alg : samp2 ] sample @xmath175 multinomially with probabilities proportional to@xmath104 sample @xmath176 independently and uniformly over @xmath167 $ ] @xmath177 @xmath178 @xmath179 @xmath180    for the bootstrap particle filter as well as the fully adapted auxiliary particle filter ( see section [ section : apf ] for precise descriptions of these smc filters ) , it is possible to derive an asymptotic expression for the number of simulations required at line  8 of algorithm [ alg : smooth ] even if the kernel @xmath181 is not bounded from below .",
    "the following result is obtained using theory derived in the coming section .",
    "[ prop : complexityboostrap ] assume that the transition kernel is bounded from above , @xmath182 for all @xmath183 .",
    "at each iteration @xmath184 , let  @xmath185 be the number of simulations required in the accept  reject procedure of algorithm  [ alg : smooth ] .",
    "* for the bootstrap auxiliary filter , @xmath186 converges in probability to @xmath187 as @xmath12 goes to infinity . * in the fully adapted case , @xmath188 converges in probability to @xmath189 as @xmath12 goes to infinity .",
    "= 0.2em plus 0.05em minus 0.02em a sufficient condition for ensuring finiteness of @xmath190 and @xmath191 is that@xmath192 @xmath193 for all @xmath194 .    if the transition kernel satisfies stronger mixing conditions , it is possible to derive an upper - bound on the computational complexity of the ffbsi for any auxiliary particle filter , that is ,  the total number of computations ( and not only the total number of simulations ) .",
    "note that this result is not limited to the bootstrap and the fully adapted cases .",
    "[ prop : complexity ] assume that the transition kernel is bounded from below and above , that is ,  @xmath195 for all @xmath196 .",
    "let @xmath197 denote the number of elementary operations required in algorithm [ alg : smooth ] .",
    "then , there exists a constant @xmath198 such that such that @xmath199 \\leq k n t \\sigma_+ / \\sigma_- $ ] .",
    "the proofs of propositions [ prop : complexityboostrap ] and [ prop : complexity ] involve theory developed in the coming section and are postponed to section [ sec : complexity : proofs ] .    before concluding this section on reduced complexity ,",
    "let us mention that efficient smoothing strategies have been considered by @xcite using quasi - monte carlo methods .",
    "the smoother ( restricted to be one - dimensional ) presented in this work has a complexity that grows quadraticly in the number of particles @xmath12 ; nevertheless , since the variance of the same decays as @xmath200 ( or faster ) thanks to the use of quasi - random numbers , the method is equivalent to methods with complexity growing linearly in @xmath12 [ since the standard monte carlo variance is @xmath201 .",
    "this solution is of course attractive ; we are however not aware of extensions of this approach to multiple dimensions .",
    "it remains to describe in detail how to produce sequentially the weighted samples @xmath202 , @xmath203 , which can be done in several different ways ( see @xcite and the references therein ) .",
    "still , most algorithms may be formulated within the unifying framework of the _ auxiliary particle filter _ described in the following .",
    "let @xmath204 be i.i.d .",
    "random variables such that @xmath205 and set @xmath206 .",
    "the weighted sample @xmath207 then targets the initial filter @xmath208 in the sense that @xmath209 estimates @xmath210 for @xmath100 . in order to describe the sequential structure of the auxiliary particle filter , we proceed inductively and assume that we have at hand a weighted sample @xmath211 targeting @xmath212 in the same sense",
    "next , we aim at simulating new particles from the target @xmath213 defined as @xmath214 in order to produce an updated particle sample approximating the subsequent filter @xmath95 . following @xcite ,",
    "this may be done by considering the _ auxiliary _ target distribution @xmath215 on the product space @xmath216 equipped with the product @xmath28-algebra @xmath217 . by construction",
    ", @xmath213 is the marginal distribution of  @xmath218 with respect to the particle index .",
    "therefore , we may approximate the target distribution @xmath213 on @xmath70 by simulating from the auxiliary distribution and then discarding the indices . more specifically , we first simulate pairs @xmath219 of indices and particles from the instrumental distribution @xmath220 on the product space @xmath221 , where @xmath222 are so - called _ adjustment multiplier weights _ and @xmath223 is a markovian _ proposal _ transition kernel . in the sequel , we assume for simplicity that @xmath224 has , for any @xmath225 , a density @xmath226 with respect to the reference measure @xmath50 . for each draw @xmath227 , @xmath228 , we compute the importance weight @xmath229 such that @xmath230 , and associate it to the corresponding particle position @xmath231 . finally , the indices @xmath232 are discarded whereupon @xmath233 is taken as an approximation of @xmath95 .",
    "the simplest choice , yielding to the so - called _ bootstrap particle filter algorithm _ proposed by @xcite , consists of setting , for all @xmath44 , @xmath234 and @xmath235 .",
    "a more appealing  but often computationally costly  choice consists of using the adjustment weights @xmath236 , @xmath44 , and the proposal transition density @xmath237 in this case , the auxiliary particle filter is referred to as _ fully adapted_. other choices are discussed in @xcite and @xcite .",
    "in this section , the convergence of the ffbs and ffbsi algorithms are studied . for these two algorithms ,",
    "nonasymptotic hoeffding - type deviation inequalities and clts are obtained .",
    "we also introduce a decomposition , serving as a basis for most results obtained in this paper , of the error @xmath238 and some technical conditions under which the results are derived .    for any function @xmath239",
    ", we define by @xmath240 and @xmath241 the supremum and oscillator norms , respectively . denote @xmath242 and consider the following assumptions where @xmath7 is the time horizon which can be either a finite integer or infinity .",
    "[ assum : bound - likelihood ] for all @xmath243 , @xmath244 and @xmath245 .",
    "define for @xmath66 the importance weight functions @xmath246    [ assum : borne - ffbs ]  @xmath247 and @xmath248 .",
    "the latter assumption is rather mild ; it holds in particular under assumption [ assum : bound - likelihood ] for the bootstrap filter ( @xmath249 and @xmath250 ) and is automatically fulfilled in the fully adapted case ( @xmath251 ) .",
    "the coming proofs are based on a decomposition of the joint smoothing distribution that we introduce below . for @xmath252 and @xmath253 , define the kernel @xmath254 $ ] by @xmath255 and set @xmath256 . by construction , for every @xmath257 , the joint smoothing distribution may be expressed as @xmath258 } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ l_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } .\\ ] ] this expression extends the classical forward  backward decomposition to the joint smoothing distribution ; here @xmath259 plays the role of the so - called backward variable .",
    "this suggests to decompose the error @xmath260 as the following telescoping sum : @xmath261 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{0 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{0 } } } } } } } } [ l_{0,t}(\\cdot,{\\mathbf{1 } } ) ] } - \\frac { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{0 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{0 } } } } } } } } [ l_{0,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{0 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{0 } } } } } } } } [ l_{0,t}(\\cdot,{\\mathbf{1 } } ) ] } \\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\sum_{t=1}^{t } \\biggl\\ { \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ l_{t , t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ l_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } - \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } \\biggr\\ } .\\hspace*{-16pt}\\nonumber\\end{aligned}\\ ] ] the first term on rhs of the decomposition above can be easily dealt with since @xmath262 is a weighted empirical distribution associated to i.i.d .",
    "random variables .    to cope with the terms in the sum of the rhs in ( [ eq : decomp_smooth ] ) ,",
    "we introduce some kernels ( depending on the _ past _ particles ) that stress the dependence with respect to  the _ current _ particules .",
    "more precisely , @xmath263 $ ] is expressed as @xmath264 = { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t } } } } } } } } [ { \\mathcal l}^n_{t , t}(\\cdot , h ) ] = \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\gamma_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\gamma^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\gamma}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\gamma^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\gamma^{n,\\mathrm{a}}_{t } } } } } } } } [ { \\mathcal l}^n_{t , t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\gamma_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\gamma^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\gamma}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\gamma^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\gamma^{n,\\mathrm{a}}_{t } } } } } } } } ( { \\mathbf{1 } } ) } , \\ ] ] where the random kernels @xmath265 $ ] are defined by : for all @xmath266 , and @xmath267 , @xmath268 and @xmath269 we stress that the kernels @xmath270 depend on the particles and weights @xmath271 , @xmath272 , through the particle approximations @xmath273 of the filter distributions .",
    "when proving the clt for the ffbs algorithm , it will be crucial to establish that for any @xmath253 , @xmath274 converges ( see lemma  [ lem : limlg ] below ) , as the number @xmath12 of particles tends to infinity , to a deterministic function @xmath275 given by @xmath276 in the sequel , the case @xmath277 will be of particular importance ; in that case , @xmath278 does not depend on @xmath279 , yielding @xmath280 for all @xmath281 . using these functions , the difference appearing in the sum in ( [ eq : decomp_smooth ] ) may then be rewritten as @xmath282 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ l_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } - \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } \\hspace*{-25pt}\\\\ & & \\qquad   = \\frac{1 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\gamma_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\gamma^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\gamma}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\gamma^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\gamma^{n,\\mathrm{a}}_{t } } } } } } } } [ { \\mathcal l}^n_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } \\biggl ( { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\gamma_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\gamma^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\gamma}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\gamma^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\gamma^{n,\\mathrm{a}}_{t } } } } } } } } [ { \\mathcal l}^n_{t , t}(\\cdot , h ) ] - \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\gamma_{t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\gamma^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\gamma}^{n}_{t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\gamma^{n,\\mathrm{t}}_{t } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\gamma^{n,\\mathrm{a}}_{t } } } } } } } } [ { \\mathcal l}^n_{t , t}(\\cdot,{\\mathbf{1 } } ) ] \\biggr)\\hspace*{-25pt } \\\\ & & \\qquad   = \\frac{n^{-1 } \\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{\\ell } } } , h)}{n^{-1 } \\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } { \\mathcal l}_{t , t}({\\ensuremath{\\xi_{t}^{\\ell } } } , { \\mathbf{1 } } ) } , \\nonumber\\hspace*{-25pt}\\end{aligned}\\ ] ] where the kernel @xmath283 $ ] is defined by , for @xmath44 , @xmath284 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } { \\mathcal l}^n_{t , t}(x,{\\mathbf{1 } } ) .\\ ] ] similarly to @xmath274 , the functions @xmath285 depend on the past particles ; it will however be shown ( see lemma [ lem : limlg ] below ) that @xmath286 converges to the deterministic function given by , for @xmath44 , @xmath287 the key property of this decomposition is stated in the following lemma .",
    "[ lem : gsttiszeromean ] assume that assumptions [ assum : bound - likelihood][assum : borne - ffbs ] hold for some @xmath288 .",
    "then , for any @xmath289 , the variables @xmath290 are , conditionally on the @xmath28-field @xmath291 , i.i.d.with zero mean .",
    "moreover , there exists a constant @xmath292 ( that may depend on @xmath54 and @xmath7 ) such that , for all @xmath293 , @xmath294 , and @xmath295 , @xmath296    by construction , all pairs of particles and weights of the weighted sample @xmath297 are i.i.d .  conditionally on the @xmath28-field @xmath291 .",
    "this implies immediately that the variables @xmath298 are also i.i.d.conditionally on the same @xmath28-field @xmath291 .",
    "we now show that @xmath299 = 0 $ ] . using the definition of @xmath300 and the fact that @xmath301 $ ] and @xmath302 $ ] are @xmath291-measurable , we have @xmath303}{\\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{1}}},h )   | { \\mathcal{f}_{t-1}^{n } } ] } } \\\\ & & \\qquad = { \\ifthenelse{\\equal{}{}}{\\mathbb{e } [ { \\ensuremath{\\omega_{t}^{1 } } } { \\mathcal l}^n_{t , t}(x , h )   | { \\mathcal{f}_{t-1}^{n } } ] } { \\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } } { \\mathcal l}^n_{t , t}(x , h )   | { \\mathcal{f}_{t-1}^{n } } ] } } - \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } { \\ifthenelse{\\equal{}{}}{\\mathbb{e } [ { \\ensuremath{\\omega_{t}^{1 } } } { \\mathcal l}^n_{t , t}(x,{\\mathbf{1 } } )   | { \\mathcal{f}_{t-1}^{n } } ] } { \\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } } { \\mathcal l}^n_{t , t}(x,{\\mathbf{1 } } )   | { \\mathcal{f}_{t-1}^{n } } ] } } , \\end{aligned}\\ ] ] which is equal to zero provided that the relation @xmath304}{\\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } } { \\mathcal l}^n_{t , t}({\\ensuremath{\\xi_{t}^{1}}},h )   | { \\mathcal{f}_{t-1}^{n } } ] } } = \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}})}\\ ] ] holds for any @xmath100 .",
    "we now turn to the proof of ( [ eq : espconda ] ) .",
    "note that for any @xmath46 , @xmath305}{\\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } } f({\\ensuremath{\\xi_{t}^{1 } } } )   | { \\mathcal{f}_{t-1}^{n } } ] } } & = & \\frac{\\sum _ { \\ell=1}^n { \\ensuremath{\\omega_{t-1}^{\\ell } } } \\int{m}({\\ensuremath{\\xi_{t-1}^{\\ell } } } , { d}x ) g_t(x ) f(x)}{\\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t-1}^{\\ell } } } { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\vartheta_{t } } { \\vartheta_{t}({\\ensuremath{\\xi_{t-1}^{\\ell } } } ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}({\\ensuremath{\\xi_{t-1}^{\\ell } } } ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}({\\ensuremath{\\xi_{t-1}^{\\ell}}})}}{\\mathrm{erreur } } } } } } \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { m}(\\cdot , g_t f ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } .\\nonumber\\end{aligned}\\ ] ] it turns out that ( [ eq : espconda ] ) is a consequence of ( [ eq : technique ] ) with @xmath306 , but since @xmath307 is in general different from @xmath308 , we have to prove directly that @xmath309 = { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { m}(\\cdot , g_t { \\mathcal l}_{t , t}^n(\\cdot , h ) ) ] .\\ ] ] write @xmath310 \\nonumber \\\\ & & \\qquad = { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{t}}}{\\ensuremath { \\omega_{t}^{()}}}}^{-1 } \\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t-1}^{\\ell } } } { \\int\\cdots\\int}\\ensuremath{m } ( { \\ensuremath{\\xi_{t-1}^{\\ell}}},x_t ) g_t(x_t ) \\biggl(\\prod_{u=1}^{t } { \\mathrm{b } _ { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{u-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{u-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{u-1 } } } } } } } } } } ( x_u , { d}x_{u-1 } ) \\biggr)\\\\ & & \\hphantom{\\qquad = { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{t}}}{\\ensuremath { \\omega_{t}^{()}}}}^{-1 } \\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t-1}^{\\ell } } } { \\int\\cdots\\int } } { } \\times l_{t , t}({\\ifthenelse{\\equal{}{}}{\\ensuremath{{x}_{0:t } } } { \\ensuremath{x^}_{0:t } } } , h ) \\,{d}x_t.\\nonumber\\end{aligned}\\ ] ] to simplify the expression in the rhs , we will use the two following equalities : @xmath311 the first relation is derived directly from the definition @xmath312 of the backward kernel , the second is a recursive expression of @xmath313 which is straightforward from the definition ( [ eq : deflt ] ) .",
    "now , ( [ eq : backrelat ] ) and ( [ eq : recurl ] ) allow for writing @xmath314 by plugging this expression into ( [ eq : technique1 ] ) , we obtain ( [ eq : cequonveut ] ) from which ( [ eq : espconda ] ) follows via ( [ eq : technique ] ) .",
    "finally , @xmath315 = 0 $ ] . it remains to check that the random variable @xmath316 is bounded .",
    "but this is immediate since @xmath317 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot , { \\mathbf{1 } } ) ] } { \\mathcal l}_{t , t}(\\cdot,{\\mathbf{1}})\\biggr|_{\\infty } \\nonumber\\hspace*{-30pt}\\\\[-8pt]\\\\[-8pt ] & \\leq&2 { \\ifthenelse{\\equal{}{}}{| { \\ensuremath{\\omega_{t } } } |_\\infty}{| { \\ensuremath{\\omega_{t}}}|^2_{\\infty } } } { \\ifthenelse{\\equal{}{}}{| { \\mathcal l}^n_{t , t}(\\cdot,{\\mathbf{1 } } ) |_\\infty}{| { \\mathcal l}^n_{t , t}(\\cdot,{\\mathbf{1}})|^2_{\\infty}}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } \\leq2 { \\ifthenelse{\\equal{}{}}{| { \\ensuremath{\\omega_{t } } } |_\\infty}{| { \\ensuremath{\\omega_{t}}}|^2_{\\infty } } } { \\ifthenelse{\\equal{}{}}{| l_{t , t}(\\cdot , { \\mathbf{1 } } ) |_\\infty}{| l_{t , t}(\\cdot , { \\mathbf{1}})|^2_{\\infty } } } { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } .\\hspace*{-30pt}\\nonumber\\end{aligned}\\ ] ]      we first establish a nonasymptotic deviation inequality . considering ( [ eq : definition - a ] ) , we are led to prove a hoeffding inequality for ratios . for this purpose , we use the following elementary lemma which will play a key role in the sequel . the proof is postponed to appendix  [ sec : proof : lem : inegessentielle ] .",
    "[ lem : inegessentielle ] assume that @xmath318 , @xmath319 and @xmath320 are random variables defined on the same probability space such that there exist positive constants @xmath321 , @xmath322 , @xmath292 and @xmath323 satisfying :    a.   @xmath324 , @xmath325-a.s .  and @xmath326 , @xmath325-a.s . , b.   for all @xmath327 and all @xmath328 , @xmath329\\leq b { e}^{-c n \\epsilon^2}$ ] , c.   for all @xmath327 and all @xmath328 , @xmath330\\leq b { e}^{-c n ( \\epsilon / m ) ^2}$ ] .",
    "then @xmath331    [ thm : hoeffding - ffbs ] assume that assumptions [ assum : bound - likelihood][assum : borne - ffbs ] hold for some @xmath288 .",
    "then , there exist constants @xmath332 and @xmath333 ( depending on @xmath7 ) such that for all  @xmath12 , @xmath334 , and all measurable functions @xmath295 , @xmath335 \\leq b { e}^{-c n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } } .\\ ] ] in addition , @xmath336 } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } .\\ ] ]    as a by - product , theorem [ thm : hoeffding - ffbs ] provides an exponential inequality for the particle approximation of the filter . for any @xmath337 ,",
    "define the function @xmath338 by @xmath339 . by construction , @xmath340 and @xmath341 . with this notation , equation  ( [ eq : hoeffding-1 ] )",
    "may be rewritten as @xmath342 \\leq b { e}^{-c n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } } .\\ ] ] an inequality of this form was first obtained by @xcite ( see also @xcite , chapter  7 ) .",
    "we prove ( [ eq : hoeffding-1 ] ) by induction on @xmath7 using the decomposition ( [ eq : decomp_smooth ] ) .",
    "assume that ( [ eq : hoeffding-1 ] ) holds at time @xmath343 , for @xmath344 .",
    "let @xmath295 and assume without loss of generality that @xmath345 .",
    "then ( [ eq : smooth : recursion ] ) implies that @xmath346 = 0 $ ] and the first term of the decomposition ( [ eq : decomp_smooth ] ) thus becomes @xmath347 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{0 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{0 } } } } } } } } [ l_{0,t}(\\cdot , { \\mathbf{1 } } ) ] } = \\frac{n^{-1}\\sum_{i=0}^n \\frac{{d}{\\chi}}{{d}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}}({\\ensuremath{\\xi_{0}^{i } } } ) g_0({\\ensuremath{\\xi_{0}^{i } } } ) l_{0,t}({\\ensuremath{\\xi_{0}^{i}}},h)}{n^{-1 } \\sum_{\\ell=0}^n \\frac{{d}{\\chi}}{{d}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}}({\\ensuremath{\\xi_{0}^{\\ell } } } ) g_0({\\ensuremath{\\xi_{0}^{\\ell}}})l_{0,t}({\\ensuremath{\\xi_{0}^{\\ell}}},{\\mathbf{1 } } ) } , \\ ] ] where @xmath204 are i.i.d .",
    "random variables with distribution @xmath348 .",
    "we obtain an exponential inequality for ( [ eq : initialrecurinegexpo ] ) by applying lemma [ lem : inegessentielle ] with @xmath349 . } \\ ] ] condition is trivially satisfied and conditions and follow from the hoeffding inequality for i.i.d .  variables .    by ( [ eq : decomp_smooth ] ) and ( [ eq : definition - a ] ) , it is now enough to establish an exponential inequality for @xmath350 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ l_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } - \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t-1|t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t-1|t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t-1|t-1 } } } } } } } [ l_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } = \\frac{n^{-1 } \\sum_{\\ell = 1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{\\ell}}},h)}{n^{-1 } \\sum _ { \\ell=1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } { \\mathcal l}_{t , t}({\\ensuremath{\\xi_{t}^{\\ell}}},{\\mathbf{1 } } ) } , \\hspace*{-25pt}\\ ] ] where @xmath266 . for that purpose ,",
    "we use again lemma [ lem : inegessentielle ] with @xmath351 } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } . } \\ ] ] by considering the lhs of ( [ eq : relation0 ] ) , @xmath352 , verifying condition in lemma [ lem : inegessentielle ] . by lemma [ lem : gsttiszeromean ] ,",
    "hoeffding s inequality implies that there exist constants @xmath322 and @xmath292 such that for all @xmath12 , @xmath334 , and all measurable function @xmath295 , @xmath353\\\\ & & \\qquad = { \\mathbb{e}}\\biggl[\\mathbb{p}\\biggl [ \\biggl|n^{-1}\\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{\\ell}}},h ) \\biggr| \\geq\\epsilon\\big|{\\mathcal{f}_{t-1}^{n}}\\biggr ] \\biggr ] \\leq b { e}^{-c n \\epsilon^2/{\\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h)}}}},\\end{aligned}\\ ] ] verifying condition in lemma [ lem : inegessentielle ] . it remains to verify condition .",
    "since the pairs of particles and weights of the weighted sample @xmath354 are i.i.d .",
    "conditionally on @xmath291 , hoeffding s inequality implies that @xmath355 \\biggr| \\geq\\epsilon\\biggr ] \\leq b { e}^{-cn \\epsilon^2 } .\\ ] ] moreover , by ( [ eq : technique ] ) , ( [ eq : lone ] ) , and the definition ( [ eq : deflt ] ) , we have @xmath356 - b \\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad = \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } - \\frac { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}_{t-1,t}(\\cdot , { \\mathbf{1 } } ) ] } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } = \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( h ) } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } , \\nonumber\\end{aligned}\\ ] ] with @xmath357 { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}}(\\cdot ) / { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}})$ ] . to obtain an exponential deviation inequality for ( [ eq : relat2 ] )",
    ", we apply again lemma [ lem : inegessentielle ] with @xmath358 by using the inequality @xmath359 we obtain the bound @xmath360 which verifies condition . now , since @xmath361 and @xmath362 , the induction assumption implies that conditions and are satisfied for @xmath363 and  @xmath364 .",
    "hence , lemma [ lem : inegessentielle ] shows that @xmath365 - b \\biggr| > \\epsilon\\biggr ] \\leq b { e}^{-c n \\epsilon^2 } .\\ ] ] finally , ( [ eq : relat0 ] ) and ( [ eq : relat1 ] ) ensure that condition in lemma [ lem : inegessentielle ] is satisfied and an exponential deviation inequality for ( [ eq : relation0 ] ) follows .",
    "the proof of ( [ eq : hoeffding-1 ] ) is complete .",
    "the last statement ( [ eq : lgn - unnormalised - l ] ) of the theorem is a consequence of ( [ eq : relat0 ] ) and ( [ eq : relat1 ] ) .",
    "the exponential inequality of theorem [ thm : hoeffding - ffbs ] may be more or less immediately extended to the ffbsi estimator .",
    "[ cor : hoeffding - ffbsi ] under the assumptions of theorem [ thm : hoeffding - ffbs ] there exist constants @xmath332 and @xmath366 ( depending on @xmath7 ) such that for all @xmath12 , @xmath334 , and all measurable functions @xmath367 , @xmath368 \\leq b { e}^{-c n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h)}}}},\\ ] ] where @xmath369 is defined in ( [ eq : ffbsi : estimator ] ) .    using ( [ eq : espcond ] ) and the definition of @xmath370 , we may write @xmath371}{\\mathbb{e } _ { } [ h ( { \\ensuremath{\\xi_{0}^{j_0}}},\\dots,{\\ensuremath{\\xi_{t}^{j_t } } } )   | { \\mathcal{f}_{t}^{n } } ] } } \\bigr ] , \\end{aligned}\\ ] ] which implies ( [ eq : hoeffding-2 ] ) by the hoeffding inequality and ( [ eq : hoeffding-1 ] ) .",
    "we now extend the theoretical analysis of the forward - filtering backward - smoothing estimator ( [ eq : smoothing : backw_decomposition_sample ] ) to a clt .",
    "consider the following mild assumption on the proposal distribution .",
    "[ assum : bound - proposal - kernel ] @xmath372 and @xmath373 .",
    "clts for interacting particle models have been established in @xcite ; the application to these results to auxiliary particle filters is presented in  @xcite and @xcite , theorem 3.2 . here",
    ", we base our proof on techniques developed in  @xcite ( extending @xcite and @xcite ) . as noted in the previous section , it turns out crucial that @xmath286 converges to a deterministic function as @xmath374 .",
    "this convergence is stated in the following lemma .",
    "[ lem : limlg ] assume assumptions [ assum : bound - likelihood][assum : bound - proposal - kernel ] .",
    "then , for any @xmath100 and , @xmath375 where @xmath270 , @xmath376 , @xmath300 and @xmath377 are defined in ( [ eq : definition - ft ] ) , ( [ eq : definition - ft - lim ] ) , ( [ eq : definition - g ] ) and ( [ eq : definition - g - lim ] ) . moreover , there exists a constant @xmath292 ( that may depend on @xmath54 and @xmath7 ) such that for all @xmath293 , @xmath378 , and @xmath100 , @xmath379    proof of lemma [ lem : limlg ] let @xmath100 and @xmath380 . by plugging ( [ eq : backward - kernel ] ) with @xmath381 into the definition ( [ eq : definition - ft ] ) of @xmath382",
    ", we obtain immediately @xmath383 ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ \\ensuremath{m } ( \\cdot , x_t ) ] }   \\qquad \\mbox{with } h({\\ifthenelse{\\equal{}{}}{\\ensuremath{{x}_{0:t } } } { \\ensuremath{x^}_{0:t } } } ) { \\stackrel{\\mathrm{def}}{=}}\\ensuremath{m } ( x_{t-1 } , x_t ) l_{t , t}({\\ifthenelse{\\equal{}{}}{\\ensuremath{{x}_{0:t } } } { \\ensuremath{x^}_{0:t } } } , h ) .\\end{aligned}\\ ] ] the convergence of @xmath274 follows from theorem [ thm : hoeffding - ffbs ] .",
    "the proof of the convergence of @xmath384 follows the same lines .",
    "finally , the final statement of the lemma is derived from lemma [ lem : gsttiszeromean ] and the almost sure convergence of  @xmath286 to @xmath385 .",
    "now , we may state the clt with an asymptotic variance given by a finite sum of terms involving the limiting kernel @xmath377 .",
    "[ thm : ffbs - clt ] assume assumptions [ assum : bound - likelihood][assum : bound - proposal - kernel ] .",
    "then , for any @xmath386 , @xmath387 } } } { \\ifthenelse{\\equal{h}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t}[h ] } } } } ) \\ ] ] with @xmath388 } } } { \\ifthenelse{\\equal{h}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t}[h ] } } } } & { \\stackrel{\\mathrm{def}}{=}}&\\frac{{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}[{\\ensuremath{\\omega_{0}}}^2(\\cdot ) g_{0,t}^2(\\cdot , h)]}{{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}^2 [ { \\ensuremath{\\omega_{0}}}(\\cdot ) { \\mathcal l}_{0 , t}(\\cdot , { \\mathbf{1 } } ) ] } + \\sum_{t=1}^t \\frac { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ \\upsilon _ { t , t}(\\cdot , h ) ] { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ^2[{\\mathcal l}_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } ,   \\\\ \\label{eq : definition - upsilon } \\upsilon_{t , t}(\\cdot , h ) & { \\stackrel{\\mathrm{def}}{=}}&{\\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta_{t } } { \\vartheta_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{\\cdot}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}(\\cdot)}}{\\mathrm{erreur } } } } } \\int{\\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}(\\cdot , { d}x ) { \\ensuremath{\\omega_{t}}}^2(\\cdot , x ) g^2_{t , t}(x , h).\\end{aligned}\\ ] ]    without loss of generality , we assume that @xmath389 . we show that @xmath390 may be expressed as @xmath391 where the sequence of random vectors @xmath392 $ ] is asymptotically normal and @xmath393 $ ] converge in probability to a deterministic vector .",
    "the proof of ( [ eq : clt ] ) then follows from slutsky s lemma .",
    "actually , the decomposition ( [ eq : decomp_smooth_1 ] ) follows immediately from the backward decomposition  ( [ eq : decomp_smooth ] ) by setting , for @xmath394 , @xmath395 the convergence @xmath396 , \\\\",
    "w_{t , t}^n & { \\stackrel{\\mathrm{p}}{\\longrightarrow}}_{n \\to\\infty } & \\frac { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}_{t-1,t}(\\cdot , { \\mathbf{1 } } ) ] } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}})}\\end{aligned}\\ ] ] of @xmath397 $ ] to a deterministic vector is established immediately using  ( [ eq : lgn - unnormalised - l ] ) and noting that the initial particles @xmath398 are i.i.d .",
    "we devote the rest of the proof to showing that the sequence of random vectors @xmath399 $ ] is asymptotically normal . proceeding recursively in time ,",
    "we prove by induction over @xmath400 ( starting with @xmath401 ) that @xmath402 $ ] is asymptotically normal . more precisely , using the cramr ",
    "wold device , it is enough to show that for all scalars @xmath403 , @xmath404}}{\\ensuremath{\\sigma^2_{,r , t}[h ] } } } \\biggr ) , \\ ] ] where , for @xmath405 , @xmath406}}{\\ensuremath{\\sigma^2_{,0,t}[h ] } } } { \\stackrel{\\mathrm{def}}{=}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}[{\\ensuremath{\\omega_{0}}}^2 g_{0,t}^2(\\cdot , h ) ] , \\qquad   { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\sigma^2_{t , t}[h ] } } { \\ensuremath{\\sigma^2_{,t , t}[h ] } } } { \\stackrel{\\mathrm{def}}{=}}\\frac { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ \\upsilon_{t , t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } .\\ ] ] the case @xmath407 is elementary since the initial particles @xmath408 are i.i.d .",
    "assume now that ( [ eq : multivariate - clt - ffbs ] ) holds for some @xmath409 ; for all scalars @xmath410 , @xmath411}}{\\ensuremath{\\sigma^2_{,r , t}[h ] } } } \\biggr ) .\\ ] ] the sequence of random variable @xmath412 may be expressed as an additive function of a triangular array of random variables , @xmath413 where @xmath414 is defined in ( [ eq : definition - g ] ) .",
    "lemma [ lem : gsttiszeromean ] implies that @xmath415 = 0 $ ] , yielding @xmath416 = \\sum _ { r=0}^{t-1 } \\alpha_r v_{r , t}^n(h ) { \\stackrel{\\mathcal{d}}{\\longrightarrow}}_{n \\to\\infty } \\mathcal{n } \\biggl(0 , \\sum_{r=1}^{t-1 } \\alpha_r^2 { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\sigma^2_{r , t}[h ] } } { \\ensuremath{\\sigma^2_{,r , t}[h ] } } } \\biggr),\\ ] ] where the last limit follows by the induction assumption hypothesis ( [ eq : induction - assumption ] ) . by @xcite , theorem a.3 ,",
    "page 2360 , as the random variables @xmath417 are centered and conditionally independent given @xmath291 , ( [ eq : multivariate - clt - ffbs ] ) holds provided that the asymptotic smallness condition @xmath418 { \\stackrel{\\mathrm{p}}{\\longrightarrow}}_{n \\to\\infty } 0\\ ] ] holds for any @xmath334 and that the conditional variance converges : @xmath419}{\\mathbb{e } _ { } [ u_{n,\\ell}^2   | { \\mathcal{f}_{t-1}^{n } } ] } } { \\stackrel{\\mathrm{p}}{\\longrightarrow}}_{n \\to \\infty } { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\sigma^2_{t , t}[h ] } } { \\ensuremath{\\sigma^2_{,t , t}[h ] } } } .\\ ] ] lemma [ lem : gsttiszeromean ] implies that @xmath420 , verifying immediately the asymptotic smallness condition ( [ eq : triangular-3 ] ) . to conclude the proof , we thus only need to establish the convergence ( [ eq : triangular-2 ] ) of the asymptotic variance . via lemma",
    "[ lem : gsttiszeromean ] and straightforward computations , we conclude that @xmath421}{\\mathbb{e } _ { } [ u^2_{n,\\ell }   | { \\mathcal{f}_{t-1}^{n } } ] } } & = & { \\ifthenelse{\\equal{}{}}{\\mathbb{e } [   ( { \\ensuremath{\\omega_{t}^{1 } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{1}}},h ) ) ^2   | { \\mathcal{f}_{t-1}^{n } } ] } { \\mathbb{e } _ { } [   ( { \\ensuremath{\\omega_{t}^{1 } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{1}}},h ) ) ^2   | { \\mathcal{f}_{t-1}^{n } } ] } } \\nonumber \\\\ & = & \\int\\sum_{\\ell=1}^n \\frac{{\\ensuremath{\\omega_{t-1}^{\\ell } } } { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\vartheta_{t } } { \\vartheta_{t}({\\ensuremath{\\xi_{t-1}^{\\ell } } } ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}({\\ensuremath{\\xi_{t-1}^{\\ell } } } ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{\\ell}}}}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}({\\ensuremath{\\xi_{t-1}^{\\ell}}})}}{\\mathrm{erreur } } } } } { \\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}({\\ensuremath{\\xi_{t-1}^{\\ell } } } , { d}x ) } { \\sum_{j=1}^n { \\ensuremath{\\omega_{t-1}^{j } } } { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\vartheta_{t } } { \\vartheta_{t}({\\ensuremath{\\xi_{t-1}^{j } } } ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}({\\ensuremath{\\xi_{t-1}^{j } } } ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}({\\ensuremath{\\xi_{t-1}^{j}}})}}{\\mathrm{erreur } } } } } } ( { \\ensuremath{\\omega_{t}}}({\\ensuremath{\\xi_{t-1}^{\\ell}}},x ) g^n_{t , t}(x , h ) ) ^2\\hspace*{-20pt } \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\biggl(\\frac{{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{t-1}}}{\\ensuremath { \\omega_{t-1}^{()}}}}}{\\sum_{j=1}^n { \\ensuremath{\\omega_{t-1}^{j } } } { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\vartheta_{t } } { \\vartheta_{t}({\\ensuremath{\\xi_{t-1}^{j } } } ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}({\\ensuremath{\\xi_{t-1}^{j } } } ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{{\\ensuremath{\\xi_{t-1}^{j}}}}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}({\\ensuremath{\\xi_{t-1}^{j}}})}}{\\mathrm{erreur } } } } } } \\biggr ) \\biggl(\\frac{1}{{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{t-1}}}{\\ensuremath { \\omega_{t-1}^{()}}}}}\\sum_{\\ell=1}^n { \\ensuremath{\\omega_{t-1}^{\\ell } } } \\upsilon^n_{t , t}({\\ensuremath{\\xi_{t-1}^{\\ell}}},h ) \\biggr ) \\nonumber\\\\ & = & \\frac { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ \\upsilon^n_{t , t}(\\cdot , h ) ] } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) } , \\nonumber\\end{aligned}\\ ] ] where @xmath422 is defined in ( [ eq : defomega ] ) and @xmath423 ^ 2 .\\ ] ] the denominator in on rhs of ( [ eq : espcondu ] ) converges evidently in probability to  @xmath424 by theorem [ thm : hoeffding - ffbs ] . the numerator is more complex since @xmath425 depends on @xmath300 whose definition involves all the approximations @xmath426 of the past filters . to obtain its convergence , note",
    "that , by theorem [ thm : hoeffding - ffbs ] , @xmath427 as @xmath12 tends to infinity ; hence , it only remains to prove that @xmath428 { \\stackrel{\\mathrm{p}}{\\longrightarrow}}_{n \\to\\infty } 0 .\\ ] ] for that purpose , introduce the following notation : for all @xmath429 , @xmath430 , \\\\",
    "b_n(x ) & { \\stackrel{\\mathrm{def}}{= } } & { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta_{t } } { \\vartheta_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{\\cdot}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}(\\cdot)}}{\\mathrm{erreur } } } } } { \\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}(\\cdot , x ) ] .\\end{aligned}\\ ] ] applying fubini s theorem , @xmath431 = \\lim_{n \\to\\infty } \\int{\\mathbb{e}}[a_n(x ) ] \\,{d}x = 0 , \\ ] ] where the last equality is due to the generalized lebesgue convergence theorem @xcite , proposition 18 , page 270 , with @xmath432 $ ] and @xmath433 $ ] provided that the following conditions hold :    a.   for any @xmath434 , @xmath435 \\leq2 c^2 { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } { \\mathbb{e}}[b_n(x)]$ ] , b.   for any @xmath44 , @xmath436 = 0 $ ] , @xmath325-a.s . , c.   @xmath437 \\,{d}x=\\int\\lim_{n \\to\\infty } { \\mathbb{e}}[b_n(x ) ] \\,{d}x$ ]",
    ".    _ proof of _ .",
    "the bound follows directly from lemmas [ lem : limlg ] and [ lem : gsttiszeromean ] .",
    "_ proof of _ . using again lemmas [ lem : limlg ] and [ lem : gsttiszeromean ] , for any @xmath44 , @xmath438",
    "these two inequalities combined with @xmath439 allow for applying the lebesgue dominated convergence theorem , verifying condition .",
    "_ proof of _ .",
    "we have @xmath440 \\,{d}x & \\stackrel{\\mathrm{(a)}}{= } & \\lim _ { n \\to\\infty } { \\mathbb{e}}\\biggl [ { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } \\biggl ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta_{t } } { \\vartheta_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{\\cdot}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}(\\cdot)}}{\\mathrm{erreur } } } } } \\int { \\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}(\\cdot , x ) \\,{d}x \\biggr ) \\biggr ] \\\\ & \\stackrel{\\mathrm{(b)}}{= } & { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) \\stackrel{\\mathrm{(c)}}{= } \\int { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta_{t } } { \\vartheta_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{\\cdot}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}(\\cdot)}}{\\mathrm{erreur } } } } } { \\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}(\\cdot , x ) ) \\,{d}x \\\\ & \\stackrel{\\mathrm{(d)}}{= } & \\int\\lim_{n \\to\\infty } { \\mathbb{e } } [ { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta_{t } } { \\vartheta_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{\\cdot}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t}(\\cdot ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{\\cdot}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}(\\cdot)}}{\\mathrm{erreur}}}}}{\\ifthenelse{\\equal{}{}}{p_{t } } { \\ifthenelse{\\equal{}{fully}}{p^{\\star}_{t } } { \\ifthenelse{\\equal{}{smooth}}{\\tilde{r}_{t}}{\\mathrm{erreur}}}}}(\\cdot , x ) ) ] \\,{d}x\\\\ & = & \\int\\lim_{n \\to\\infty } { \\mathbb{e}}[b_n(x ) ] \\,{d}x , \\end{aligned}\\ ] ] where ( a ) and ( c ) are consequences of fubini s theorem and ( b ) and ( d ) follows from the @xmath441-convergence of @xmath442 to @xmath443 ( see theorem [ thm : hoeffding - ffbs ] ) with @xmath444 and @xmath445 .    thus , ( [ eq : intan ] ) holds , yielding that @xmath446 as @xmath12 tends to infinity .",
    "this in turn implies ( [ eq : technicos ] ) via the inequality @xmath447",
    "| \\leq\\int a_n(x ) \\,{d}x .\\ ] ] this establishes ( [ eq : multivariate - clt - ffbs ] ) and therefore completes the proof .    the weak convergence of @xmath448 for the ffbs algorithm implies more or less immediately the one of @xmath449 for the ffbsi algorithm .    under the assumptions of theorem",
    "[ thm : ffbs - clt ] , @xmath450\\\\[-8pt ] & & \\qquad { \\stackrel{\\mathcal{d}}{\\longrightarrow}}\\mathcal{n } \\bigl(0 , { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ^2 [ h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) ] + { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h)}{}}{\\ensuremath { \\gamma_{0:t|t}}}{\\ensuremath{\\gamma_{0:t|t}[h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) ] } } } { \\ifthenelse{\\equal{h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h)}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t}[h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) ] } } } } \\bigr ) .\\nonumber\\end{aligned}\\ ] ]    using ( [ eq : espcond ] ) and the definition of @xmath369 , we may write @xmath451}{\\mathbb{e } _ { } [ h ( { \\ensuremath{\\xi_{0}^{j_0 } } } , \\dots , { \\ensuremath{\\xi_{t}^{j_t } } } )   | { \\mathcal{f}_{t}^{n } } ] } } \\bigr ] \\\\ & & \\qquad\\quad { } + \\sqrt{n } \\bigl ( { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) \\bigr ) .\\end{aligned}\\ ] ] note that since @xmath152 are i.i.d.conditional on @xmath141 , ( [ eq : cltsi ] ) follows from ( [ eq : clt ] ) and direct application of @xcite , theorem a.3 , page 2360 , by noting that @xmath452}{\\mathbb{e } _ { } [ h ( { \\ensuremath{\\xi_{0}^{j_0}}},\\dots,{\\ensuremath{\\xi_{t}^{j_t } } } )   | { \\mathcal{f}_{t}^{n } } ] } } \\}^2|{\\mathcal{f}_{t}^{n}}\\bigr ] \\\\ & & \\qquad = \\bigl ( { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ h - { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) ] \\bigr)^2 { \\stackrel{\\mathrm{p}}{\\longrightarrow}}\\bigl ( { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } [ h - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{0:t|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0:t|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{0:t|t } } } } } } } ( h ) ] \\bigr)^2 .\\end{aligned}\\ ] ]",
    "most often , it is not required to compute the joint smoothing distribution but rather the marginal smoothing distributions  @xmath8 . considering ( [ eq : forward - filtering - backward - smoothing ] ) for a function @xmath367 that depends on the component  @xmath453 only , we obtain particle approximations of the marginal smoothing distributions by associating the set @xmath454 of particles with weights obtained by marginalizing the joint smoothing weights according to @xmath455 it is easily seen that these marginal weights may be recursively updated backward in time as @xmath456 in this section , we study the long - term behavior of the marginal fixed - interval smoothing distribution estimator . for that purpose",
    ", it is required to impose a type of mixing condition on the markov transition kernel ; see  @xcite and the references therein . for simplicity ,",
    "we consider elementary but strong conditions which are similar to the ones used in @xcite , chapter 7.4 , or @xcite , chapter 4 ; these conditions , which points to applications where the state space @xmath24 is compact , can be relaxed , but at the expense of many technical difficulties @xcite .",
    "[ assum : strong - mixing - condition ] there exist two constants @xmath457 , such that , for any @xmath155 , @xmath458 in addition , there exists a constant @xmath459 such that , @xmath460 and for all @xmath461 , @xmath462    assumption [ assum : strong - mixing - condition ] implies that @xmath463 ; in the sequel , we will consider without loss of generality that @xmath464 .",
    "note also that , under assumption [ assum : strong - mixing - condition ] , the average number of simulations required in the accept  reject mechanism per sample of the ffbsi algorithm is bounded by @xmath465 .",
    "the goal of this section consists in establishing , under the assumptions mentioned above , that the ffbs approximation of the _ marginal _ fixed interval smoothing probability satisfies an exponential deviation inequality with constants that are uniform in time and , under the same assumptions , that the variance of the clt is uniformly bounded in time .    for obtaining these results",
    ", we will need upper - bounds on @xmath300 and @xmath377 that are more precise than the ones stated in lemmas [ lem : gsttiszeromean ] and [ lem : limlg ] .",
    "for any function @xmath100 and @xmath466 , define the extension @xmath467 of @xmath367 to @xmath468 by @xmath469    [ lem : g - uniform ] assume that assumptions [ assum : bound - likelihood][assum : strong - mixing - condition ] hold with @xmath470 .",
    "let @xmath471 .",
    "then , for all @xmath54,@xmath7 , @xmath293 , and @xmath100 , @xmath472 where @xmath376 is defined in ( [ eq : definition - ft - lim ] ) and @xmath473 moreover , for all @xmath54 , @xmath474 , and @xmath100 , @xmath475    using ( [ eq : lone ] ) and ( [ eq : definition - g ] ) , @xmath476 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { \\mathcal l}^n_{t-1,t}(\\cdot,{\\mathbf{1 } } ) ] } .\\ ] ] to prove ( [ eq : time - unif - g ] ) , we will rewrite ( [ eq : expressiong ] ) and obtain an exponential bound by either using ergodicity properties of the `` a posteriori '' chain ( when @xmath477 ) , or by using ergodicity properties of the backward kernel ( when @xmath478 .",
    "assume first that @xmath477 .",
    "the quantity @xmath479 does not depend on @xmath279 so that by ( [ eq : definition - ft ] ) and definition ( [ eq : deflt ] ) of @xmath313 , @xmath480 now , by construction , for any @xmath481 , @xmath482 the relations ( [ eq : expressiong ] ) , ( [ eq : one ] ) and ( [ eq : two ] ) imply that @xmath483}{\\mu[{\\mathcal l}_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } - \\frac{\\mu'[{\\mathcal l}_{t , t}(\\cdot,{{\\pi_{s , t } h}})]}{\\mu ' [ { \\mathcal l}_{t , t}(\\cdot,{\\mathbf{1 } } ) ] } , \\label{eq : gn - t - inf - s}\\ ] ] where @xmath484 and @xmath485 is the nonnegative finite measure defined by @xmath486 now , for any finite measure @xmath487 on @xmath488 , the quantity @xmath489}{\\mu[{\\mathcal l}_{t , t}(\\cdot , { \\mathbf{1 } } ) ] } \\\\ & & \\qquad = \\frac{{\\int\\cdots\\int}\\mu({d}x_t ) \\prod_{u = t+1}^t { m}(x_{u-1},{d}x_u ) g_u(x_{u } ) h(x_s)}{{\\int\\cdots\\int}\\mu({d}x_t ) \\prod _ { u = t+1}^t { m}(x_{u-1 } , { d}x_u ) g_u(x_u ) } \\\\[2pt ] & & \\qquad = \\frac{{\\int\\cdots\\int}\\mu({d}x_t ) \\prod_{u = t+1}^s { m}(x_{u-1},{d}x_u ) g_u(x_{u } ) h(x_s ) { \\mathcal l}_{s , t}(x_s,{\\mathbf{1}})}{{\\int\\cdots\\int}\\mu({d}x_t ) \\prod_{u = t+1}^s { m}(x_{u-1},{d}x_u ) g_u(x_u ) { \\mathcal l}_{s , t}(x_s,{\\mathbf{1}})}\\end{aligned}\\ ] ] may be seen as the expectation of @xmath490 conditionally on @xmath491 , where @xmath69 is distributed according to @xmath492 . under the strong mixing condition ( assumption [ assum : strong - mixing - condition ] ) , it is shown in @xcite ( see also @xcite ) that , for any @xmath493 , any finite measure @xmath487 and @xmath485 on @xmath488 , any function @xmath100 , that @xmath494 & & \\quad   { } - \\frac{{\\int\\cdots\\int}\\mu'({d}x_t ) \\prod_{u = t+1}^s { m}(x_{u-1},{d}x_u ) g_u ( x_u ) h(x_s ) { \\mathcal l}_{s , t}(x_s,{\\mathbf{1}})}{{\\int\\cdots\\int}\\mu'({d}x_t ) \\prod_{u = t+1}^s { m}(x_{u-1},{d}x_u ) g_u ( x_u ) { \\mathcal l}_{s , t}(x_s,{\\mathbf{1 } } ) } \\biggr|\\\\ & & \\qquad \\leq\\rho^{s - t } { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } , \\end{aligned}\\ ] ] where @xmath495 is defined in ( [ eq : definition - rho ] ) .",
    "this shows ( [ eq : time - unif - g ] ) when @xmath54 is smaller than @xmath10 .",
    "consider now the case @xmath496 . by definition , @xmath497\\\\[-8pt ] & = & { \\int\\cdots\\int}{\\mathcal l}_{t , t}(x_t,{\\mathbf{1 } } ) \\prod_{u = s+1}^{t } { \\mathrm{b } _ { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{u-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{u-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{u-1 } } } } } } } } } } ( x_u , { d}x_{u-1 } ) h(x_s ) , \\nonumber\\end{aligned}\\ ] ] where the last expression is obtained from the following equality , valid for @xmath498 : @xmath499 moreover , combining ( [ eq : cequonveut ] ) and ( [ eq : cas2premiere ] ) , @xmath500\\\\ & & \\qquad   = { \\int\\cdots\\int } { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { d}u_{t-1 } ) m(u_{t-1},{d}x_t ) g_t(x_t ) { \\mathcal l}^n_{t , t}(x_t,{{\\pi_{s , t } h } } ) \\\\ & & \\qquad = { \\int\\cdots\\int } { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { d}u_{t-1 } ) m(u_{t-1},{d}x_t ) g_t(x_t ) { \\mathcal l}_{t , t}(x_t,{\\mathbf{1 } } ) \\\\ & & \\hphantom{\\qquad = { \\int\\cdots\\int } } { } \\times\\prod_{u = s+1}^t { \\mathrm{b } _ { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{u-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{u-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{u-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{u-1 } } } } } } } } } } ( x_u , { d}x_{u-1 } ) h(x_s ) .\\end{aligned}\\ ] ] by plugging this expression and ( [ eq : cas2premiere ] ) into ( [ eq : expressiong ] ) , we obtain @xmath501 with @xmath502 and @xmath503 being the nonnegative measure defined by @xmath504 g_t(x_t ) { \\mathcal l}_{t , t}(x_{t},{\\mathbf{1 } } ) { \\mathbf{1}}_a(x_{t } ) \\,{d}x_t .\\ ] ] under the uniform ergodicity condition ( assumption [ assum : strong - mixing - condition ] ) it holds , for any probability measure @xmath87 on @xmath488 , and any @xmath505 , @xmath506 thus , the transition kernel @xmath86 is uniformly doeblin with minorizing constant @xmath507 and the proof of ( [ eq : time - unif - g ] ) for @xmath508 follows .",
    "the last statement of the lemma follows from ( [ eq : time - unif - g ] ) and the almost - sure convergence @xmath509 for all @xmath44 , which was established in lemma [ lem : limlg ] .      under the strong mixing assumption [ assum : strong - mixing - condition ] , a time uniform deviation inequality for the _ marginal smoothing _ approximation can be derived using the exponentially decreasing bound on the quantity @xmath300 obtained in lemma [ lem : g - uniform ] .",
    "[ theo : hoeffding - uniform ] assume assumptions [ assum : bound - likelihood][assum : strong - mixing - condition ] hold with @xmath510 . then",
    ", there exist constants @xmath511 such that for all integers @xmath12 , @xmath10 , @xmath7 , with @xmath9 , and for all @xmath334 , @xmath512 & \\leq & b{e}^{-c n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } } , \\\\ \\label{eq : tu - hoeffding - smoothing - normalized-2 } { \\mathbb{p } } [ | { \\ifthenelse{\\equal{tilde}{}}{\\ensuremath{\\phi_{s|t}}}{\\ifthenelse{\\equal{tilde}{hat}}{\\ensuremath{\\phi^{n}_{s|t } } } { \\ifthenelse{\\equal{tilde}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{s|t } } } { \\ifthenelse{\\equal{tilde}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{s|t } } } } } } } ( h ) - { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\phi_{s|t}}}{\\ifthenelse{\\equal{}{hat}}{\\ensuremath{\\phi^{n}_{s|t } } } { \\ifthenelse{\\equal{}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{s|t } } } { \\ifthenelse{\\equal{}{tar}}{\\ensuremath{\\phi^{n , \\mathrm{t}}_{s|t } } } } } } } ( h ) | \\geq\\epsilon ] & \\leq & b{e}^{-c n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } } , \\end{aligned}\\ ] ] where @xmath513 and @xmath514 are defined in ( [ eq : smoothing : backw_decomposition_sample ] ) and ( [ eq : ffbsi : estimator ] ) .    letting @xmath97 in theorem [ theo : hoeffding - uniform ]",
    "provides , as a special case , the ( already known ) time uniform deviation inequality for the _ filter _ approximation ; however , the novelty of the bounds obtained here is that these confirm the stability of the ffbsm and ffbsi marginal smoothing approximations also when @xmath10 is fixed and @xmath7 tends to infinity ( see @xcite for further discussion ) .",
    "proof of theorem [ theo : hoeffding - uniform ] combining ( [ eq : lone ] ) with the definition ( [ eq : deflt ] ) and assumption [ assum : strong - mixing - condition ] yields , for all @xmath44 , @xmath515 let @xmath295 and assume without loss of generality that @xmath389 .",
    "then , ( [ eq : smooth : recursion ] ) implies that @xmath516 = 0 $ ] and the first term of the decomposition ( [ eq : decomp_smooth ] ) thus becomes @xmath517 } { { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{0}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{0 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{0 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{0 } } } } } } } } [ l_{0,t}(\\cdot , { \\mathbf{1 } } ) ] } = \\frac{n^{-1}\\sum_{i=0}^n \\frac{{d}{\\chi}}{{d}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}}({\\ensuremath{\\xi_{0}^{i } } } ) g_0({\\ensuremath{\\xi_{0}^{i } } } ) l_{0,t}({\\ensuremath{\\xi_{0}^{i}}},h)}{n^{-1 } \\sum_{\\ell= 0}^n \\frac{{d}{\\chi}}{{d}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\rho_{0}}}{\\ensuremath{\\check { \\rho}_{0}}}}}({\\ensuremath{\\xi_{0}^{\\ell } } } ) g_0({\\ensuremath{\\xi_{0}^{\\ell } } } ) l_{0,t}({\\ensuremath{\\xi_{0}^{\\ell}}},{\\mathbf{1 } } ) } , \\ ] ] where @xmath518 are i.i.d .",
    "random variables with distribution @xmath348 . noting that @xmath519 we obtain an exponential deviation inequality for ( [ eq : initialrecurinegexpo-1 ] ) by applying lemma [ lem : inegessentielle ] with @xmath520/{|{\\mathcal l}_{0,t}(\\cdot , h)|_{\\infty } } ,",
    "\\cr \\beta= { \\chi}(g_0 ) \\sigma_- / \\sigma_+ . }",
    "\\ ] ] here , condition is trivially satisfied and conditions and follow from the hoeffding inequality for i.i.d .  variables .    according to ( [ eq : decomp_smooth ] ) and ( [ eq : definition - a ] )",
    ", it is now required , for any @xmath521 , to derive an exponential inequality for @xmath522 note first that , using ( [ eq : majorationl ] ) , we have @xmath523 we use again lemma [ lem : inegessentielle ] with @xmath524 = { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } [ { m}(\\cdot , g_t ) ] / { \\ifthenelse{\\equal{hat}{}}{\\ensuremath{\\phi_{t-1}}}{\\ifthenelse{\\equal{hat}{hat}}{\\ensuremath{\\phi^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tilde}}{\\ensuremath{\\tilde{\\phi}^{n}_{t-1 } } } { \\ifthenelse{\\equal{hat}{tar}}{\\ensuremath{\\phi^{n,\\mathrm{t}}_{t-1 } } } { \\ifthenelse{\\equal{hat}{aux}}{\\ensuremath{\\phi^{n,\\mathrm{a}}_{t-1 } } } } } } } } ( { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } ) , \\cr \\beta= c_- / { \\ifthenelse{\\equal{}{}}{| { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur } } } } } |_\\infty}{| { \\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}}|^2_{\\infty } } } . }",
    "\\ ] ] assumption [ assum : strong - mixing - condition ] shows that @xmath525 and lemma [ lem : g - uniform ] shows that @xmath526 , where @xmath495 is defined in ( [ eq : definition - rho ] ) .",
    "therefore , condition   of lemma  [ lem : inegessentielle ] is satisfied and the hoeffding inequality gives @xmath527 & \\leq&{\\mathbb{e}}\\biggl [ \\mathbb{p}\\biggl [ \\biggl|n^{-1 } \\sum _ { \\ell= 1}^n ( { \\ensuremath{\\omega_{t}^{\\ell } } } - { \\ifthenelse{\\equal{}{}}{\\mathbb{e } [ { \\ensuremath{\\omega_{t}^{1 } } }   | { \\mathcal{f}_{t-1}^{n } } ] } { \\mathbb{e } _ { } [ { \\ensuremath{\\omega_{t}^{1 } } }   | { \\mathcal{f}_{t-1}^{n } } ] } } ) \\biggr| \\geq\\epsilon\\big|{\\mathcal{f}_{t-1}^{n}}\\biggr ] \\biggr]\\\\ & \\leq&2 \\exp ( -2",
    "n \\epsilon^2 / { \\ifthenelse{\\equal{2}{}}{| { \\ensuremath{\\omega_{t } } } |_\\infty}{| { \\ensuremath{\\omega_{t}}}|^2_{\\infty } } } ) , \\end{aligned}\\ ] ] establishing condition in lemma [ lem : inegessentielle ] .",
    "finally , lemma [ lem : g - uniform ] and the hoeffding inequality imply that @xmath528 & \\leq&{\\mathbb{e}}\\biggl [ \\mathbb{p}\\biggl [ \\biggl|n^{-1 } \\sum_{\\ell = 1}^n { \\ensuremath{\\omega_{t}^{\\ell } } } g^n_{t , t}({\\ensuremath{\\xi_{t}^{\\ell}}},{{\\pi_{s , t } h}})/{\\ifthenelse{\\equal{}{}}{| { \\mathcal l}_{t , t}(\\cdot,{\\mathbf{1 } } )   |_\\infty}{| { \\mathcal l}_{t , t}(\\cdot,{\\mathbf{1 } } ) |^2_{\\infty } } } \\biggr| \\geq\\epsilon\\big|{\\mathcal{f}_{t-1}^{n}}\\biggr ] \\biggr]\\\\ & \\leq&2 \\exp\\biggl ( - 2 \\frac{n \\epsilon^2}{{\\ifthenelse{\\equal{2}{}}{| { \\ensuremath{\\omega_{t } } } |_\\infty}{| { \\ensuremath{\\omega_{t}}}|^2_{\\infty } } } \\rho^{2|t - s| } { \\ifthenelse{\\equal{2}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{2}(h ) } } } } \\biggr ) = 2 \\exp\\biggl ( - 2 \\frac{n \\epsilon ^2}{{\\ifthenelse{\\equal{2}{}}{| { \\ensuremath{\\omega_{t } } } |_\\infty}{| { \\ensuremath{\\omega_{t}}}|^2_{\\infty } } } m^2 } \\biggr ) .\\end{aligned}\\ ] ] lemma [ lem : inegessentielle ] therefore yields @xmath529 so that @xmath530 a time uniform exponential deviation inequality for @xmath531 then follows from lemma [ lem : pasfor ] and the proof is complete .",
    "analogous to the result obtained in the previous section , a  time uniform bound on the asymptotic variance in the clt for the _ marginal smoothing _ approximations can , again under the strong mixing assumption  [ assum : strong - mixing - condition ] , be easily obtained from the exponentially decreasing bound on @xmath377 stated and proved in lemma [ lem : g - uniform ] for the quantity .",
    "[ theo : clt - uniform ] assume assumptions [ assum : bound - likelihood][assum : strong - mixing - condition ] hold with @xmath470 . then , for all @xmath532 , @xmath533 } } } { \\ifthenelse{\\equal{{{\\pi_{s , t } h}}}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t}[{{\\pi_{s , t } h } } ] } } } } \\leq\\biggl(\\frac{\\sigma_+}{\\sigma _ - } \\bigl ( 1 \\vee\\sup_{t \\geq1 } { |{\\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}}|_{\\infty } } \\bigr ) \\sup_{t \\geq0 } { |{\\ensuremath{\\omega_{t}}}|_{\\infty}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } \\biggr)^2 \\frac{1+\\rho ^2}{1-\\rho^2 } , \\ ] ] where @xmath534 } } } { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t } [ ] } } } } $ ] is defined in ( [ eq : expression - covariance ] ) .    in accordance with the results of the previous section , letting @xmath97 in the previous theorem",
    "provides a time uniform bound on the asymptotic variance for the _ filter _ approximation ; nevertheless , as mentioned previously , the situation of interest for us is when @xmath10 is fixed and @xmath7 goes to infinity .",
    "proof of theorem [ theo : clt - uniform ] combining ( [ eq : majorationl ] ) and ( [ eq : time - unif - g - lim ] ) with @xmath535 yields @xmath536 } \\leq\\biggl(\\frac{\\sigma_+}{\\sigma_-}{|{\\ensuremath{\\omega_{0}}}|_{\\infty}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h)}}}\\rho^s \\biggr)^2 .\\ ] ] moreover , by inserting , for any @xmath266 , the bound obtained in ( [ eq : time - unif - g - lim ] ) into the expression ( [ eq : definition - upsilon ] ) of @xmath537 we obtain @xmath538 } \\leq \\biggl(\\frac{\\sigma_+}{\\sigma_- } { |{\\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}}|_{\\infty}}{|{\\ensuremath{\\omega_{t}}}|_{\\infty}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } \\rho^{|t - s| } \\biggr)^2 .\\ ] ] finally , plugging the two bounds above into ( [ eq : expression - covariance ] ) gives @xmath533 } } } { \\ifthenelse{\\equal{{{\\pi_{s , t } h}}}{}}{\\ensuremath{\\gamma_{,0:t|t}}}{\\ensuremath { \\gamma_{,0:t|t}[{{\\pi_{s , t } h } } ] } } } } \\leq\\biggl(\\frac{\\sigma_+}{\\sigma_- } \\bigl ( 1 \\vee\\sup_{t \\geq1 } { |{\\ifthenelse{\\equal{}{}}{\\ifthenelse{\\equal{}{}}{\\vartheta_{t } } { \\vartheta_{t } ( ) } } { \\ifthenelse{\\equal{}{smooth}}{\\ifthenelse{\\equal{}{}}{\\tilde { \\vartheta}_{t}}{\\tilde{\\vartheta}_{t } ( ) } } { \\ifthenelse{\\equal{}{fully}}{\\ifthenelse{\\equal{}{}}{\\vartheta^ \\star_{t}}{\\vartheta^\\star_{t}()}}{\\mathrm{erreur}}}}}|_{\\infty } } \\bigr ) \\sup_{t \\geq 0 } { |{\\ensuremath{\\omega_{t}}}|_{\\infty}}{\\ifthenelse{\\equal{}{}}{\\ensuremath{\\operatorname{osc}(h ) } } { \\ensuremath{\\operatorname{osc}^{}(h ) } } } \\biggr)^2 \\biggl(\\sum_{t=0}^\\infty\\rho ^{2|t - s| } \\biggr ) , \\ ] ] which completes the proof .",
    "having at hand the theory established in the previous sections , we are now ready to present the proofs of propositions [ prop : complexityboostrap ] and  [ prop : complexity ] .",
    "proof of proposition [ prop : complexityboostrap ] the average number of simulations required to sample @xmath161 conditionally on @xmath162 is @xmath539 .",
    "hence , the number of simulations @xmath185 required to sample @xmath540 has conditional expectation @xmath541 = \\sum_{\\ell= 1}^n \\frac { \\sigma_+ { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{s}}}{\\ensuremath { \\omega_{s}^{()}}}}}{\\sum_{i = 1}^n { \\ensuremath{\\omega_{s}^{i } } } \\ensuremath { m}({\\ensuremath{\\xi_{s}^{i}}},{\\ensuremath{\\xi_{s+1}^{j_{s+1}^\\ell } } } ) } .\\ ] ] we denote @xmath542 $ ] and @xmath543 $ ] and write @xmath544 & = & \\sum_{i=1}^n { \\ensuremath{\\omega_{s+1|t}^{i}}}\\frac{\\sigma_+ { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{s}}}{\\ensuremath { \\omega_{s}^{()}}}}}{\\sum_{j=1}^n { \\ensuremath{\\omega_{s}^{j } } } \\ensuremath{m } ( { \\ensuremath{\\xi_{s}^{j } } } , { \\ensuremath{\\xi_{s+1}^{i } } } ) } \\\\ & = & \\sigma_+ { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{s}}}{\\ensuremath { \\omega_{s}^ { ( ) } } } } \\sum_{i=1}^n \\sum_{\\ell= 1}^n \\frac { { \\ensuremath{\\omega_{s+1|t}^{i } } } { \\ensuremath{\\omega_{s}^{\\ell } } } \\ensuremath{m}({\\ensuremath{\\xi_{s}^{\\ell } } } , { \\ensuremath{\\xi_{s+1}^{i}}})}{\\sum_{j=1}^n { \\ensuremath{\\omega_{s}^{j } } } \\ensuremath{m}({\\ensuremath{\\xi_{s}^{j } } } , { \\ensuremath{\\xi_{s+1}^{i } } } ) } \\times\\frac{1}{{\\ensuremath{\\omega_{s}^{\\ell } } } \\ensuremath{m}({\\ensuremath{\\xi_{s}^{\\ell } } } , { \\ensuremath{\\xi_{s+1}^{i } } } ) } \\\\ & = & \\sigma_+ { \\ifthenelse{\\equal{}{}}{\\ensuremath{\\omega_{s}}}{\\ensuremath { \\omega_{s}^ { ( ) } } } } \\sum_{i=1}^n \\sum_{\\ell= 1}^n { \\ensuremath{\\omega_{s : s+1|t}^{\\ell i } } } \\frac{1}{{\\ensuremath{\\omega_{s}^{\\ell } } } m({\\ensuremath{\\xi_{s}^{\\ell } } } , { \\ensuremath{\\xi_{s+1}^{i } } } ) } .\\end{aligned}\\ ] ] for the bootstrap particle filter , @xmath545 ; theorem [ thm : hoeffding - ffbs ] then implies that @xmath546 and @xmath547 besides , @xmath548 similarly , in the fully adapted case we have @xmath549 for all @xmath550 ; thus , @xmath551 and @xmath552 in both cases , the numerator can be bounded from above by @xmath553 if @xmath554 for all @xmath194 .",
    "proof of proposition [ prop : complexity ] fix a time step @xmath10 of the algorithm and denote by @xmath555 the number of elementary operations required for this step . for @xmath556 , let @xmath557 be the number of times that @xmath558 appears in list @xmath559 at time @xmath10 in the ` while ' loop .",
    "let also @xmath560 be the size of  @xmath559 ( i.e. , the value of @xmath561 at line 6 ) after @xmath562 iterations of the ` while ' loop , with @xmath563 . then , using proposition [ prop : multisample ] there exists a constant c such that @xmath564 as @xmath565 is a concave , increasing function , it holds by jensen s inequality that @xmath566 \\leq c \\sum_{u=0}^\\infty{\\mathbb{e}}[n_s^u ] \\biggl ( 1+\\log\\biggl(1 + \\frac { n}{{\\mathbb{e}}[n_s^u ] } \\biggr ) \\biggr ) .\\ ] ] besides , @xmath567 = \\sum_{k = 1}^n { \\mathbb{p}}(t_s^k \\geq u ) \\leq",
    "n \\biggl(1 - \\frac { \\sigma_-}{\\sigma_+ } \\biggr)^u\\ ] ] as @xmath507 is a lower bound on the acceptation probability .",
    "thus , @xmath566 \\leq c n \\sum_{u=0}^\\infty\\biggl(1-\\frac{\\sigma_-}{\\sigma_+ } \\biggr)^{u } \\biggl ( 1+\\log\\biggl(1+\\frac{1 } { ( 1-\\sigma_-/\\sigma_+ ) ^u } \\biggr ) \\biggr)\\leq \\frac{kn\\sigma_+}{\\sigma_- } .\\ ] ]",
    "write @xmath568 thus , @xmath569 from which the proof follows .",
    "[ lem : pasfor ] let @xmath570 be a triangular array of random variables such that there exist constants @xmath571 , @xmath572 , and @xmath495 with @xmath573 satisfying , for all @xmath561 , @xmath574 , and @xmath334 , @xmath575 then , there exist constants @xmath576 and @xmath577 such that , for any @xmath561 and @xmath334 , @xmath578        in this section , we describe and analyze an efficient multinomial sampling procedure , detailed in algorithm  [ alg : multisample ] . given a probability distribution @xmath584 on the set @xmath585 , it returns a sample of size @xmath561 of that distribution .",
    "compared to the procedure described in section 7.4.1 in @xcite , its main virtue is to be efficient for both large and small samples sizes : if @xmath586 , the complexity is @xmath587 , while if @xmath588 , the complexity is @xmath589 .",
    "the order statistics at line 5 and the permutation at line 6 can be sampled using @xmath591 operations ; see @xcite , chapter v and xiii . for",
    "each value of @xmath558 between @xmath592 and @xmath561 , denote by @xmath593 the number of times lines 1113 are executed .",
    "observe that line 18 is executed the same number of times , and thus the number of elementary operations required by call to algorithm  [ alg : multisample ] is @xmath594 . but the value of @xmath595 is increased during iteration @xmath558 by at least @xmath596 , and as the final value of @xmath595 is at most equal to @xmath12 , it holds that @xmath597 by convexity , @xmath598 which implies that @xmath599    @xmath600 @xmath601 sample an order statistics @xmath602 of an i.i.d .",
    "uniform distribution uniformly sample a permutation @xmath28 on @xmath603 @xmath604 @xmath605 @xmath606 @xmath607 @xmath608 @xmath609 @xmath610 @xmath611 @xmath612"
  ],
  "abstract_text": [
    "<S> computing smoothing distributions , the distributions of one or more states conditional on past , present , and future observations is a recurring problem when operating on general hidden markov models . </S>",
    "<S> the aim of this paper is to provide a foundation of particle - based approximation of such distributions and to analyze , in a common unifying framework , different schemes producing such approximations . in this setting , general convergence results , including exponential deviation inequalities and central limit theorems , are established . </S>",
    "<S> in particular , time uniform bounds on the marginal smoothing error are obtained under appropriate mixing conditions on the transition kernel of the latent chain . </S>",
    "<S> in addition , we propose an algorithm approximating the joint smoothing distribution at a cost that grows only linearly with the number of particles .    ,    ,    and    .    </S>"
  ]
}