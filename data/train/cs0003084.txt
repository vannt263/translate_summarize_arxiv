{
  "article_text": [
    "simple statistical models underlie many successful applications of speech and language processing .",
    "the most accurate document retrieval systems are based on unigram statistics . the acoustic model of virtually all speech recognition systems",
    "is based on stochastic finite state machines referred to as hidden markov models ( hmms ) .",
    "the language ( word sequence ) model of state - of - the - art large vocabulary speech recognition systems uses an @xmath0-gram model ( @xmath1$]th order markov model ) , where @xmath0 is typically 4 or less .",
    "two important features of these simple models are their trainability and scalability : in the case of language modelling , model parameters are frequently estimated from corpora containing up to @xmath2 words .",
    "these approaches have been extensively investigated and optimized for speech recognition , in particular , resulting in systems that can perform certain tasks ( e.g. , large vocabulary dictation from a cooperative speaker ) with a high degree of accuracy .",
    "more recently , similar statistical finite state models have been developed for spoken language processing applications beyond direct transcription to enable , for example , the production of structured transcriptions which may include punctuation or content annotation .    in this paper",
    "we discuss the development of trainable statistical models for extracting content from television and radio news broadcasts .",
    "in particular , we concentrate on _ named entity _ ( ne ) identification , a task which is reviewed in  [ sec : nereview ] .",
    "section  [ sec : framework ] outlines a general statistical framework for ne identification , based on an @xmath0-gram model over words and classes .",
    "we discuss two formulations of this basic approach .",
    "the first (  [ sec : form1 ] ) represents class information as a word attribute ; the second (  [ sec : form2 ] ) explicitly represents word - word and class - class transitions . in both cases",
    "we discuss the implementation of the model and present results using an evaluation framework based on north american broadcast news data . finally , in ",
    "[ sec : discussion ] , we discuss our work in the context of other approaches to ne identification in spoken language and outline some areas for future work .",
    "proper names account for around 9% of broadcast news output , and their successful identification would be useful for structuring the output of a speech recognizer ( through punctuation , capitalization and tokenization ) , and as an aid to other spoken language processing tasks , such as summarization and database creation .",
    "the task of ne identification involves identifying and classifying those words or word sequences that may be classified as proper names , or as certain other classes such as monetary expressions , dates and times .",
    "this is not a straightforward problem .",
    "while is clearly a date , and is a personal name , other strings , such as , and are more ambiguous .",
    "ne identification was formalized for evaluation purposes as part of the 5th message understanding conference , and the evaluation task definition has evolved since then . in this paper",
    "we follow the task definition specified for the recent broadcast news evaluation ( referred to as 4e ) sponsored by darpa and nist @xcite .",
    "this specification defined seven classes of named entity : three types of proper name ( ,  and ) two types of temporal expression (  and ) and two types of numerical expression (  and ) .",
    "according to this definition the following ne tags would be correct :    _ _   +   +   +   + _ _    is not tagged as a date , since only `` absolute '' time or date expressions are recognized ; is not tagged as a personal name , since it is part of a larger construct that refers to the prize .",
    "similarly , is not tagged as a location since it is part of a larger construct tagged as an organization .    both rule - based and statistical approaches have been used for ne identification . and adopted grammar - based approaches using specially constructed grammars , gazetteers of personal and company names , and higher level approaches such as name co - reference .",
    "some grammar - based systems have utilized a trainable component , such as the alembic system @xcite .",
    "the ltg system @xcite employed probabilistic partial matching , in addition to a non - probabilistic grammar and gazetteer look - up .    introduced a purely trainable system for ne identification , which is discussed in greater detail in .",
    "this approach was based on an ergodic hmm ( i.e. , an hmm in which every state is reachable from every state ) where the hidden states corresponded to ne classes , and the observed symbols corresponded to words .",
    "training was performed using an ne annotated corpus , so the state sequence was known at training time . thus likelihood maximization could be accomplished directly without need for the expectation - maximization ( em ) algorithm .",
    "the transition probabilities of this model were conditioned on both the previous state and the previous word , and the emission probabilities attached to each state could be regarded as a word - level bigram for the corresponding ne class .",
    "ne identification systems are evaluated using an unseen set of evaluation data : the hypothesised nes are compared with those annotated in a human - generated reference transcription . in this situation",
    "there are two possible types of error : _ type _ , where an item is tagged as the wrong kind of entity and _ extent _ , where the wrong number of word tokens are tagged .",
    "for example ,       has errors of both type and extent since the ground truth for this excerpt is    .",
    "these two error types each contribute @xmath3 to the overall error count , and precision ( ) and recall ( ) can be calculated in the usual way . a weighted harmonic mean ( ) ,",
    "sometimes called the f - measure @xcite , is often calculated as a single summary statistic : @xmath4 in a recent evaluation , using newswire text , the best performing system returned a  of 0.93 .",
    "although precision and recall are clearly informative measures , have criticized the use of , since it implicitly deweights missing and spurious identification errors compared with incorrect identification errors .",
    "they proposed an alternative measure , referred to as the slot error rate ( ) , that weights three types of identification error equally . where @xmath5 , @xmath6 , @xmath7 , and @xmath8 denote the numbers of correct , incorrect , missing , and spurious identifications . using this notation , precision and recall scores",
    "may be calculated as @xmath9 and @xmath10 , respectively . ]      a straightforward approach to identifying named entities in speech is to transcribe the speech automatically using a recognizer , then to apply a text - based ne identification method to the transcription .",
    "it is more difficult to identify nes from automatically transcribed speech compared with text , since speech recognition output is missing features that may be exploited by `` hard - wired '' grammar rules or by attachment to vocabulary items , such as punctuation , capitalization and numeric characters .",
    "more importantly , no speech recognizer is perfect , and spoken language is rather different from written language .",
    "although planned , low - noise speech ( such as dictation , or a news bulletin read from a script ) can be recognized with a word error rate ( ) of less than 10% , speech which is conversational , in a noisy ( or otherwise cluttered ) acoustic environment or from a different domain may suffer a  in excess of 40% .",
    "additionally , the natural unit seems to be the phrase , rather than the sentence , and phenomena such as disfluencies , corrections and repetitions are common .",
    "it could thus be argued that statistical approaches , that typically operate with limited context and very little notion of grammatical constructs , are more robust than grammar - based approaches .",
    "oppose this argument , and have developed a finite - state grammar - based approach for ne identification of broadcast news .",
    "however , this relied on large , carefully constructed lexica and gazetteers , and it is not clear how portable between domains this approach is .",
    "some further discussion of rule - based approaches follows in  [ sec : discussion ] .",
    "spoken ne identification was first demonstrated by , who applied the model of to the output of a broadcast news speech recognizer .",
    "an important conclusion of that work  supported by the experiments reported here  was that the error of an ne identifier degraded linearly with , with the largest errors due to missing and spuriously tagged names . since then several other researchers , including ourselves , have investigated the problem within the 4e evaluation framework .",
    "evaluation of spoken ne identification is more complicated than for text , since there will be speech recognition errors as well as ne identification errors ( i.e. , the reference tags will not apply to the same word sequence as the hypothesised tags ) .",
    "this requires a word level alignment of the two word sequences , which may be achieved using a phonetic alignment algorithm developed for the evaluation of speech recognizers @xcite .",
    "once an alignment is obtained , the evaluation procedure outlined above may be employed , with the addition of a third error type , _ content _ , caused by speech recognition errors .",
    "the same statistics (  and ) can still be used , with the three error types contributing equally to the error count .",
    "first , let @xmath11 denote a vocabulary and @xmath12 be a set of name classes . we consider that @xmath11 is similar to a vocabulary for conventional speech recognition systems ( i.e. , typically containing tens of thousands of words , and no case information or other characteristics ) . in what follows , @xmath12 contains the proper names , temporal and number expressions used in the 4e  evaluation described above . when there is no ambiguity , these named entities are referred to as `` name(s ) '' . as a convention here , a class  is included in @xmath12 for those words not belonging to any of the specified names . because each name may consist of one word or a sequence of words , we also include a marker  in @xmath12 , implying that the corresponding word is a part of the same name as the previous word .",
    "the following example is taken from a human - generated reference transcription for the 1997 4e broadcast news evaluation data :    @xmath13 @xmath14 @xmath15    the corresponding class sequence is       because and are considered two different names by the specification .",
    "class information may be interpreted as a word attribute ( the left model of figure  [ fig : ne_model ] ) .",
    "formally , we define a class - word token @xmath16 and consider a probability @xmath17 that generates a sequence of class - word tokens @xmath18 .",
    "alternatively , word - word and class - class transitions may be explicitly formulated ( the right model of figure  [ fig : ne_model ] ) .",
    "then we consider a probability @xmath19 that generates a sequences of words @xmath20 and a corresponding sequence of classes @xmath21 .",
    "the first approach is simple and analogous to conventional @xmath0-gram language modelling , however the performance is sub - optimal in comparison to the second approach , which is more complex and needs greater attention to the smoothing procedure .    for both formulations",
    ", we have performed experiments using data produced for the 4e  evaluation .",
    "the training data for this evaluation consisted of manually annotated transcripts of the 4e broadcast news acoustic training data ( broadcast in 199697 ) .",
    "this data contained approximately one million words ( corresponding to about 140 hours of audio ) .",
    "development was performed using the 1997 evaluation data ( 3 hours of audio broadcast in 1996 , about 32,000 words ) and evaluation results reported on the 1998 evaluation data ( 3 hours of audio broadcast in 1996 and 1998 , about 33,000 words ) .",
    "in this section , we describe an ne model based on direct word - word transitions , with class information treated as a word attribute .",
    "this approach suffers seriously from data sparsity .",
    "we briefly summarize why this is so .",
    "formulation  ( [ eq : form1 ] ) may be best viewed as a straightforward extension to standard @xmath0-gram language modelling . denoting @xmath22 , ( [ eq : form1 ] )",
    "is rewritten as @xmath23 and this is identical to the @xmath0-gram model widely used for large vocabulary speech recognition systems . because each token @xmath24 is treated independently , those having the same word but the different class ( e.g. , , , and ) are considered different members . using this formulation , class - class transitions are implicit .",
    "further it may be interpreted as a classical hmm , in which tokens @xmath25 correspond to states , with observations @xmath26 and @xmath27 generated from each @xmath25 .",
    "maximum likelihood estimates for model parameters can be obtained from the frequency count of each @xmath0-gram given text data annotated with name information . since the state sequence is known the forward - backward algorithm is not required .",
    "standard discounting and smoothing techniques may be applied .",
    "the search process is based on @xmath0-gram relations . given a sequence of words , @xmath20",
    ", the most probable sequence of names may be identified by tracing the viterbi path across the class - word trellis such that @xmath28 this process may be slightly elaborated by looking into a separate list of names that augments @xmath0-grams of @xmath29 tokens .",
    "further technical details of this formulation are in .      using the experimental setup described in ",
    "[ sec : framework ] , we estimated a back - off trigram language model that contained @xmath30 class - word tokens in a trigram vocabulary , with a further @xmath31 words modelled as unigram extensions .    a hand transcription ( provided by nist ) and four speech recognizer outputs ( three distributed by nist representing the range of systems that participated in the 1998 broadcast news transcription evaluation , and our own system @xcite )",
    "were automatically marked with nes , then scored against the human - generated reference transcription .",
    "the results are summarized in table  [ tb : eval1 ] .",
    "the combined  score was about 83% for a hand transcription .",
    "for recognizer outputs , the scores declined as  increased .",
    "as noted by other researchers ( e.g. , ) a linear relationship between the  and the ne identification scores is observed .",
    ".ne identification scores on 1998 4e evaluation data , using the ne model with implicit class transitions . a hand transcription and three recognizer outputs were provided by nist .",
    "the bottom row is by our own recognizer .  and  indicate word and slot error rates . , , and  denote recall , precision , and a combined precision&recall scores , respectively .",
    "this table contains further improvement since our participation in the 1998 4e evaluation . in this experiment , we used transcripts of broadcast news acoustic training data ( 199697 ) for ne model generation , but did not rely on external sources . [ cols=\">,^,^,^,^,^ \" , ]     although more complex in formulation , it is beneficial to model class - class transitions explicitly .",
    "consider again the phrase discussed in  [ sec : form1 ] . here",
    ", was correctly identified as although was not included in the vocabulary .",
    "it was identified using the product of conditional probabilities @xmath32 between and as well as the product @xmath33 between  and .",
    "there exists an alternative approach to decomposing the right side of equation  ( [ eq : form21 ] ) : @xmath34 theoretically , if the `` true '' conditional probability can be estimated , decompositions by  ( [ eq : form22 ] ) and by  ( [ eq : form26 ] ) should produce identical results .",
    "this ideal case does not occur , and various discounting and smoothing techniques will cause further differences between two decompositions .    in practice , the conditional probabilities on the right side of  ( [ eq : form26 ] )",
    "can be estimated in the same fashion as described in ",
    "[ sec : form1 ] : counting the occurrences of each token in annotated text data , then applying certain discounting and smoothing techniques .",
    "the adopted smoothing path for the current word probability was @xmath35 and a path for the current class probability was @xmath36 in the latter case , a slight approximation @xmath37 was made , since it was observed that @xmath38 did not contribute much when calculating the probability of @xmath26 in this manner .",
    "this second decomposition alone did not work as well as the initial decomposition . when applied to the 1997 hand transcription ,",
    "the  score declined by 8% absolute ( using , combined good - turing / absolute discounting , and back - off smoothing ) . in general , decomposition by  ( [ eq : form26 ] ) accurately tagged words that occurred frequently in the training data , but performed less well for uncommon words . crudely speaking , it calculated the distribution over classes for each word ; consequently it had reduced accuracy for uncommon words with less reliable probability estimates .",
    "decomposition by  ( [ eq : form22 ] ) makes a more balanced decision because it relies on the distribution over words for each class , and there are orders of magnitude fewer classes than words .",
    "the two decompositions can be combined by @xmath39 where @xmath40 refers to the initial method and @xmath41 the alternative .",
    "figure  [ fig : dual ] shows precision and recall scores for the mixture ( with factors @xmath42 ) of the two decompositions .",
    "it is observed that , for values of @xmath43 around @xmath3 , this modelling improved the precision without degrading the overall .",
    "we have described trainable statistical models for the identification of named entities in television and radio news broadcasts .",
    "two models were presented , both based on @xmath0-gram statistics .",
    "the first model  in which class information was implicitly modelled as a word attribute  was a straightforward extension of conventional language modelling .",
    "however , it suffered seriously from the problem of data sparsity , resulting in a sub - optimal performance ( a  score of 83% on a hand transcription ) .",
    "we addressed this problem in a second approach which explicitly modelled class - class and word - word transitions . with this approach",
    "the  score improved to 89% .",
    "these scores were based on a relatively small amount of training data ( one million words ) . like other language modelling problems , a simple way to improve",
    "the performance is to increase the amount of training data .",
    "have noted that there is a log - linear relation between the amount of training data and the ne identification performance ; our experiments indicate that the  score improves by a few percent for each doubling of the training data size ( between 0.1 and 1.0 million words ) .",
    "the development of the second model was motivated by the success of the approach of and .",
    "this model shares the same principle of an explicit , statistical model of class - class and word - word transitions , but the model formulation , and the discounting and smoothing procedures differ . in particular , the model presented here is a flat state machine , that is not readily interpretable as a two - level hmm architecture .",
    "our experience indicates that an appropriate choice and implementation of discounting / smoothing strategies is very important , since a more complex model structure is being trained with less data , compared with conventional language models for speech recognition systems .",
    "the overall results that we have obtained are similar to those of , but there are some differences which we can not immediately explain away . in particular , although the combined  scores were similar , reported balanced recall and precision , whereas we have consistently observed substantially higher precision and lower recall .    the models presented here were trained using a corpus of about one million words of text , manually annotated .",
    "no gazetteers , carefully - tuned lexica or domain - specific rules were employed ; the brittleness of maximum likelihood estimation procedures when faced with sparse training data was alleviated by automatic smoothing procedures .",
    "although the fact that an accurate ne model can be estimated from sparse training data is of considerable interest and import , it is clear that it would be of use to be able to incorporate much more information in a statistical ne identifier . to this end , we are investigating two basic approaches : the incorporation of prior information ; and unsupervised learning .",
    "the most developed uses of prior information for ne identification are in the form of the rule - based systems developed for the task .",
    "some initial work , carried out with rob gaizauskas and mark stevenson using a development of the system described by , has analysed the errors of rule - based and statistical approaches .",
    "this has indicated that there is a significant difference between the annotations produced by the two systems for the three classes of proper name .",
    "this leads us to believe that there is some scope for either merging the outputs of the two systems , or incorporating some aspects of the rule - based systems as prior knowledge in the statistical system .",
    "unsupervised learning of statistical ne models is attractive , since manual ne annotation of transcriptions is a labour intensive process .",
    "however , our preliminary experiments indicate that unsupervised training of ne models is not straightforward . using a model built from 0.1 million words of manually annotated text ,",
    "the rest of the training data was automatically annotated , and the process iterated .",
    "scores stayed at the same level ( around 73% ) regardless of iteration .",
    "finally , we note that the ne annotation models discussed here  and all other state - of - the - art approaches  act as a post - processor to a speech recognizer .",
    "hence the strong correlation between the  scores of the ne tagger and the  of the underlying speech recognizer is to be expected .",
    "the development of ne models that incorporate acoustic information such as prosody @xcite and confidence measures @xcite are future directions of interest .",
    "we have benefited greatly from cooperation and discussions with robert gaizauskas and mark stevenson .",
    "we thank bbn and mitre for the provision of manually - annotated training data .",
    "the evaluation infrastructure was provided by mitre , nist and saic .",
    "this work was supported by epsrc grant gr / m36717 .",
    "aberdeen , j. , burger , j. , day , d. , hirschman , l. , robinson , p. , & vilain , m. ( 1995 ) . : description of the alembic system used for muc-6 . in _ proceedings of the 6th message understanding conference ( muc-6 )",
    "_ , maryland , pp .   141155 .",
    "gotoh , y. & renals , s. ( 1999 ) .",
    "statistical annotation of named entities in spoken audio . in _ proceedings of the esca workshop : accessing information in spoken audio _ ,",
    "cambridge , pp .   4348 .",
    "( http://svr-www.eng.cam.ac.uk/~ajr/esca99/ ) .",
    "hobbs , j. , appelt , d. , bear , j. , israel , d. , kameyama , m. , stickel , m. , & tyson , m. ( 1997 ) .",
    ": a cascaded finite state transducer for extracting information from natural language text . in e.",
    "roche & y.  schabes ( eds . ) , _ finite state language processing _ , pp .   381406 . mit press .",
    "robinson , p. , brown , e. , burger , j. , chinchor , n. , douthat , a. , ferro , l. , & hirschman , l. ( 1999 ) .",
    "overview : information extraction from broadcast news . in _ proceedings of darpa broadcast news workshop _ , herndon , va , pp",
    ".   2730 ."
  ],
  "abstract_text": [
    "<S> this paper discusses the development of trainable statistical models for extracting content from television and radio news broadcasts . </S>",
    "<S> in particular we concentrate on statistical finite state models for identifying proper names and other _ named entities _ in broadcast speech . </S>",
    "<S> two models are presented : the first represents name class information as a word attribute ; the second represents both word - word and class - class transitions explicitly . </S>",
    "<S> a common @xmath0-gram based formulation is used for both models . </S>",
    "<S> the task of named entity identification is characterized by relatively sparse training data and issues related to smoothing are discussed . </S>",
    "<S> experiments are reported using the darpa / nist 4e evaluation for north american broadcast news .    </S>",
    "<S> ( 0,0 ) ( 0,0 )    * keywords : named entity ; information extraction ; language modelling * </S>"
  ]
}