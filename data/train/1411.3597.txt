{
  "article_text": [
    "consider the case where two correlated sources are observed separately by two non - cooperative encoders which communicate with one decoder .",
    "the decoder needs to reconstruct both sources and the distortions between the reconstructions and the corresponding sources should not exceed some given values .",
    "the general version of this problem has remained open for several decades , even under the assumption of memoryless sources . however , many special cases have been solved .",
    "when no distortion is allowed , this is the problem considered by slepian and wolf @xcite . their well - known result states that two discrete sources @xmath0 and @xmath1 can be losslessly reproduced if and only if    @xmath2    [ slepian_wolf_eq ]    where @xmath3 is the rate of the encoder observing @xmath0 and @xmath4 is the rate of the encoder observing @xmath1 . returning to the lossy case , the setting in which one of the variables is known to the decoder , is the original wyner - ziv problem @xcite .",
    "this setting was generalized to continuous alphabet sources by wyner @xcite .",
    "other examples include the source coding problem with side information of ahlswede - krner @xcite , where an arbitrary distortion is allowed for one of the sources and the other source should be reconstructed losslessly .",
    "berger and yeung @xcite considered a setting where one of the sources is to be perfectly reconstructed and the other source should be reconstructed with a distortion constraint ( their setting subsumes all previous examples ) .",
    "zamir and berger @xcite characterized the rate - distortion region in the high - snr limit .",
    "wagner and anantharan @xcite presented a new outer bound which is better than the previous outer bounds in the literature .",
    "recent results for specific sources and distortion measures include the works of wagner , tavildar , and viswanath @xcite , who determined the rate region for the quadratic gaussian multiterminal source coding problem , by showing that the berger - tung @xcite inner bound is tight .",
    "in addition , a characterization of the rate region under logarithmic loss was given by courtade and weissman @xcite .",
    "finally , a version of this problem , where both users and the decoder must operate with zero - delay , was considered by kaspi and merhav @xcite , who characterized the rate region in this case .    in @xcite",
    ", ziv presented a universal coding scheme for the single - user case .",
    "this scheme is composed of a uniform , one - dimensional quantizer with dither , followed by a noiseless variable - rate encoder ( entropy encoder ) .",
    "he showed that this scheme yields a rate that is , for every positive integer @xmath5 , no more than @xmath6 bits per sample higher than the best possible rate associated with the optimal @xmath5-dimensional quantizer .",
    "this result was later revisited and further developed by zamir and feder @xcite , @xcite , who also gave a redundancy upper bound which depends on the source distribution . however , their derivation of the global upper bound relies on the known formula of the single - user rate - distortion function .",
    "in addition , a dithered scheme for the multi - user setting , which is similarly to the scheme in this paper , was given in @xcite .",
    "redundancy upper bounds can be derived by bounding the difference between the dithered scheme rate region and the outer bound on the multi - user rate region given in @xcite .",
    "these bounds depend on the divergence between the source distribution and a gaussian distribution . as a result , they are not uniformly bounded ( for every source distribution ) in contrast to the bound of ziv and the bounds presented in this paper . in addition",
    ", only the redundancy of the sum of the rates can be upper bounded using the methods of @xcite .    in this paper",
    ", we investigate a generalized scheme for the multi - user setting . in this scheme ,",
    "each user uses dithered quantizer followed by universal slepian - wolf encoder .",
    "we show that the rates achieved by this scheme are no more than 0.754 bits per sample away from the boundary of the achievable rate region , for each user .",
    "this is done regardless of the characterization of the achievable region , which is , as mentioned before , unknown in general . as a direct consequence of these results ,",
    "inner and outer bounds on the achievable region are obtained . finally , similarly to the results of @xcite , it is straightforward to show that using multi - dimensional lattice quantizers instead of scalar ones would decrease the redundancy to about 0.5 bits per sample for high lattice dimension .",
    "the remainder of this paper is organized as follows . in section 2 , we present the problem formulation and give basic results regarding the performance of the dithered scheme . in section 3 ,",
    "we revisit the redundancy upper bound of @xcite . in section 4 ,",
    "we enhance the results of section 2 by adding an estimation stage to the dithered scheme .",
    "we conclude this work in section 5 .",
    "throughout the paper , random variables will be denoted by capital letters and their alphabets will be denoted by calligraphic letters .",
    "random vectors ( all of length @xmath5 ) will be denoted by capital letters in the bold face font .    in this section",
    ", we present the multi - user setting we deal with and describe the dithered coding scheme we use .",
    "then , we give upper bounds on the performance of this scheme , compared to the boundary of the optimal rate region .    we begin with defining the multi - user rate region .",
    "let @xmath7 be a continuous alphabet memoryless source , characterized by the joint probability density @xmath8 .",
    "we assume that @xmath8 has bounded support , i.e. , there exists @xmath9 such that @xmath10 if @xmath11\\times [ -a , a]$ ] . the reason for this assumption will be explained later .",
    "a rate pair @xmath12 is said to be @xmath13-achievable under the mean - square error distortion measure with respect to @xmath7 , if for every @xmath14 and sufficiently large @xmath5 , there exists a code of block length @xmath5 consisting of two encoders @xmath15 , @xmath16 @xmath17^n\\rightarrow i_{m_1},&{f}_2:[-a , a]^n\\rightarrow i_{m_2 } \\label{mt1}\\end{aligned}\\ ] ] and a decoder @xmath18 @xmath19^n\\times [ -a , a]^n \\label{mt2}\\end{aligned}\\ ] ] such that @xmath20 and @xmath21 where @xmath22 , @xmath23 .",
    "the set of @xmath13-achievable rate pairs , is denoted by @xmath24 .",
    "our scheme works as follows .",
    "we have two encoders @xmath25 , @xmath26 : @xmath27^n \\times [ -\\sqrt{3d_1},\\sqrt{3d_1}]\\rightarrow i_{\\tilde{m}_1},&\\tilde{f}_2:[-a , a]^n\\times [ -\\sqrt{3d_2},\\sqrt{3d_2}]\\rightarrow i_{\\tilde{m}_2}\\end{aligned}\\ ] ] and a decoder @xmath28 @xmath29\\times[-\\sqrt{3d_2},\\sqrt{3d_2}]\\rightarrow [ -a , a]^n\\times [ -a , a]^n.\\end{aligned}\\ ] ] each encoder @xmath30 , @xmath23 , uses a one - dimensional uniform quantizer @xmath31 , @xmath32 and a dither random variable ( rv ) @xmath33 , uniformly distributed over @xmath34 $ ] , to produce @xmath35 $ ] , where @xmath36 denotes a vector of dimension @xmath5 composed of @xmath5 repetitions of the same realization of @xmath33 . for convenience , the random variable @xmath37 and the random vector @xmath38 will be denoted by @xmath39 and @xmath40 , respectively .",
    "the dither rv s , @xmath41 and @xmath42 , are available to the respective encoders and to the decoder and are independent . as is shown in ( * ? ? ?",
    "* lemma 1 ) , @xmath43=d_i,&i\\in\\{1,2\\}\\end{aligned}\\ ] ] where the expectation is taken over @xmath33 .",
    "notice that the distortion is @xmath44 independently of @xmath45 and therefore the total distortion is also @xmath44 .",
    "after the quantization stage , the two encoders perform slepian - wolf encoding with a rate pair @xmath46 , for lossless compression of @xmath47 and @xmath48 . complying with eq .",
    "( [ slepian_wolf_eq ] ) , the rate pair @xmath49 satisfies        @xmath50    [ rr ]    where we used the following , for every value of @xmath5    @xmath51    to see why ( [ memoryless ] ) is true , consider the following chain @xmath52 where the second equality stems from the fact that @xmath53 and @xmath54 are memoryless given @xmath41 and @xmath42 and the third equality stems from the stationarity of the source . the same can be done for @xmath55 and @xmath56 .",
    "the rate region of eq .",
    "( [ rr ] ) is achievable for @xmath5 sufficiently large and it is denoted by @xmath57 .",
    "the interesting range of @xmath3 is @xmath58 $ ] since higher rate can always be reduced to this range .",
    "the same is true for @xmath4 .",
    "the universal decoder first decodes @xmath47 and @xmath48 ( correctly with high probability ) , and then subtracts the corresponding dithers to obtain the reconstruction vectors @xmath59 , @xmath60 : @xmath61 the universal slepian - wolf decoder is described in appendix a. the dithered coding scheme is presented in fig .",
    "+ _ remark_. the slepian - wolf mechanism can be applied , in general , to sources with countably - infinite alphabets . however",
    ", a universal slepian - wolf scheme for such sources is not known .",
    "trying to preserve universality in the case of infinite alphabets would require the assignment of infinite number of sequences into bins .",
    "thus , even the codebook generation does not seem to be feasible in this case .",
    "this is not surprising , considering the fact that even in the single - user case , diminishing redundancy can not be achieved for universal lossless coding of sources with infinite alphabets ( see , e.g. , @xcite ) .",
    "therefore , for the sake of universality , we assumed that the source alphabets have bounded supports so the outputs of the quantizers have finite alphabets . from the above , this assumption",
    "is also needed for the original single - user scheme of ziv @xcite .",
    "the inner and outer bounds on the achievable rate - distortion region , which are obtained as a direct consequence of theorems 1 - 4 below , are also valid , of course , for sources with unbounded support , as they do not depend on the universality .",
    "we begin with a simple result .    for any rate pair @xmath12 on the boundary of @xmath24 and any rate pair @xmath46 on the boundary of @xmath57 , with @xmath62 , we have @xmath63 where @xmath64 bits / sample .",
    "+ moreover , for any @xmath65 , there exists a rate pair @xmath66 such that @xmath67 [ the222 ]    we have @xmath68 where @xmath69 , @xmath70 are the outputs of the optimal encoders @xmath71 , @xmath72 , respectively , @xmath73 are the outputs of the optimal decoder @xmath18 , and @xmath74 .",
    "the last inequality can be obtained in the same way as in @xcite .",
    "the left - hand side is achievable for sufficiently large @xmath5 .",
    "therefore , for any rate pair @xmath66 , which lies on the straight line @xmath75 , we have @xmath76 moreover , if @xmath77 , we can always take @xmath78 and obtain : @xmath79 the same can be done , of course , when the roles of the two users are interchanged .",
    "this completes the proof .",
    "the following theorem suggests another result regarding the relation between the boundary of @xmath57 and that of @xmath24 .    for any rate pair @xmath46 on the boundary of @xmath57 , with @xmath62",
    ", there exists a rate pair @xmath74 such that : @xmath80 [ thestrong ]    notice that theorems 1 and 2 also provide outer bounds on @xmath24 .",
    "theorem 1 asserts that the straight line @xmath81 defines an outer bound for @xmath24 .",
    "in addition , theorem 2 bounds the distance between the boundary of @xmath57 and that of @xmath24 in each coordinate .",
    "the boundary of @xmath57 is , of course , an inner bound on @xmath24 .    before proving theorem 2",
    ", we first prove a simple auxiliary result regarding the source - coding problem where side information is available only to the encoders but not to the decoder .",
    "the setting is as follows .",
    "a rate pair @xmath46 is achievable for a memoryless source @xmath82 and some side information @xmath83 which depends statistically on @xmath84 through the joint probability distributions @xmath85 , if for any @xmath14 and sufficiently large @xmath5 , there exists a block code of length @xmath5 consisting of two encoders @xmath15 , @xmath16 @xmath86 and a decoder @xmath18 @xmath87 such that @xmath88 and @xmath89 the set of achievable rate pairs is denoted by @xmath90 .",
    "the regular slepian - wolf region ( without side information ) is denoted by @xmath91 .",
    "obviously , @xmath92 .",
    "we have the following lemma .",
    "any rate pair @xmath93 must satisfy the following constraint : @xmath94 therefore , side information available only to the encoders can not improve the performance if @xmath95 $ ] or @xmath96 $ ] .",
    "[ lem11 ]    the proof follows directly from the fact that even one encoder , which has access to @xmath97 , can not do better than @xmath98 , when the side information @xmath99 is not available to the decoder .",
    "the generalization of lemma 1 to our case where , in addition , a dither is available to the encoders and decoder , is straightforward",
    ". we can now prove theorem [ thestrong ] .",
    "assume that the optimal code @xmath100 , which achieves the rate pair @xmath12 , is known , and that the encoders of the dithered scheme , which transmit @xmath47 , @xmath48 at rates @xmath46 to the decoder , have access to @xmath101 , @xmath102 as side information . according to lemma 1",
    ", this side information does not change the fact that any rate pair @xmath66 must satisfy @xmath103 . consider the following auxiliary coding scheme : user @xmath104 compresses @xmath105 using @xmath106 bits , @xmath23 .",
    "then , the first user uses slepian - wolf coding to compress @xmath47 given @xmath107 into @xmath108 bits .",
    "the second user uses slepian - wolf coding to compress @xmath48 given @xmath109 into @xmath110 bits .",
    "the decoder , which has access to @xmath111 , first decodes @xmath47 , using @xmath107 .",
    "then , it decodes @xmath48 using @xmath109 .",
    "the rate pair of this scheme , @xmath46 , satisfies @xmath112 and @xmath113 the upper bounds on @xmath114 can be obtained in the same way as in @xcite . notice that the slepian - wolf coding part in the proof requires long blocks of @xmath115 .",
    "now , since @xmath116 , we can always find @xmath117 @xmath74 such that @xmath118 ( or higher and thus can be reduced to this range ) .",
    "using the auxiliary scheme above , the rate pair @xmath119 can be achieved .",
    "therefore , it can also be achieved by the dithered scheme , since @xmath62 ( or higher ) , and in this range the regions of the auxiliary scheme and the dithered scheme coincide .",
    "notice that any rate pair in @xmath57 can be achieved in practice by time - sharing the two edge points of @xmath57 .",
    "in this section , we revisit the proof of @xcite for the upper bound on @xmath120 .",
    "this is done for completeness and since we point and modify some of the steps in the next section .",
    "the result of this section involves only one source @xmath121 .",
    "the width of the quantization cell is denoted by @xmath122 .",
    "first , we show that for each coordinate @xmath123 , @xmath124 , @xmath125=0 .",
    "\\label{experror}\\end{aligned}\\ ] ] this follows from the following consideration : @xmath126&=&\\mathbb{e}\\left[x_{k}-\\hat{x}^{opt}_k\\right]+\\mathbb{e}\\left[z\\right]\\\\ & = & \\mathbb{e}\\left[x_{k}-\\hat{x}^{opt}_k\\right].\\end{aligned}\\ ] ] the distortion associated with @xmath127 is given by : @xmath128&=&\\text{var}\\{x_{k}-\\hat{x}^{opt}_k)\\ } + \\left(\\mathbb{e}\\left[x_{k}-\\hat{x}^{opt}_k\\right]\\right)^2\\\\ & \\geq&\\text{var}\\{x_{k}-\\hat{x}^{opt}_k\\}\\end{aligned}\\ ] ] where the inequality must be achieved by the optimal quantizer . otherwise , we could add a constant to @xmath129 to obtain @xmath130=0 $ ] and thus smaller total distortion , in contradiction to the optimality of the quantizer .",
    "we now rederive the upper bound on @xmath131 . using a method similar to @xcite , we show the following for the conditional entropy of each coordinate : @xmath132 where the second equality follows since @xmath133 and @xmath134 are independent . by definition : @xmath135 given @xmath136",
    ", @xmath137 is a discrete random variable taking values in @xmath138 .",
    "thus , @xmath139 where @xmath140 is the probability density function of @xmath137 given @xmath129 and @xmath134 . calculating : @xmath141 where @xmath142 is the probability density function of @xmath121 given @xmath129",
    ", @xmath143 is the probability density function of the continuous random variable @xmath144 given @xmath129 and @xmath145 denotes the convolution operation . substituting in eq .",
    "( [ disentropy22 ] ) , we have @xmath146 where in the fifth equality we used the independence of @xmath123 and @xmath134 and in the sixth equality we used the fact that @xmath147 .",
    "we have @xmath148 this completes the derivation of eq .",
    "( [ entropyvsmutual ] ) .",
    "now , we can upper bound @xmath149 in the following way .",
    "@xmath150\\right)\\\\ & \\leq&\\frac{1}{2}\\log \\left(2\\pi e \\displaystyle \\mathbb{e}\\left(x-\\hat{x}^{opt}_k+{z}\\right)^2\\right ) \\label{entropypower}\\end{aligned}\\ ] ] where in the first inequality we upper bounded the differential entropy by using the maximum - entropy property of the gaussian random variable and the second inequality is due to jensen . using these results , we can upper bound @xmath120 .",
    "@xmath151\\right ) \\\\&&\\nonumber",
    "- n h(z)\\\\ \\nonumber & \\leq&\\frac{n}{2}\\log \\left(2\\pi e \\displaystyle\\frac{1}{n}\\sum_{k=1}^n   \\mathbb{e}\\left[\\left(x_k-{\\hat{x}}^{opt}_k+{z}\\right)^2\\right]\\right)\\\\ \\nonumber & & -n\\log\\delta\\\\ \\nonumber & = & \\frac{n}{2}\\log \\left(2\\pi e \\displaystyle\\frac{1}{n }   \\mathbb{e}\\left\\|\\bold{x}-\\bold{\\hat{x}}^{opt}+\\bold{z}\\right\\|^2\\right)\\\\ \\nonumber & & -n\\log\\delta\\\\ \\nonumber & \\leq&\\frac{n}{2}\\log \\left(2\\pi e 2d\\right)-n\\log\\delta\\\\ \\nonumber & = & \\frac{n}{2}\\log \\left(2\\pi e 2d\\right)-\\displaystyle\\frac{n}{2}\\log(\\delta^2)\\\\ \\nonumber & = & \\frac{n}{2}\\log \\left(4\\pi e d\\right)-\\displaystyle\\frac{n}{2}\\log\\left(12d\\right)\\\\ & = & \\frac{n}{2}\\log \\left(\\displaystyle\\frac{\\pi e}{3}\\right ) \\label{upper_bound_derivation}\\end{aligned}\\ ] ] where the third inequality is due to jensen , and in the fourth we used the following . @xmath152 which stems from the independence of @xmath121 and @xmath134 .",
    "this completes the proof of the upper bound on @xmath120 .",
    "the goal of this section is to enhance the results of section 1 by improving the coding scheme described there .",
    "the idea is to decrease the distortion by adding an estimation stage at the decoder side .",
    "the new scheme works as follows . after producing @xmath153 and instead of just using them as outputs ,",
    "the decoder uses them to estimate each one of the source vectors @xmath154 .",
    "since the sources and the quantization process ( given @xmath134 ) are memoryless , the estimation can be done on a symbol - by - symbol basis .",
    "we begin with the following lemma :    for the multi - terminal setting described in section 1 , we have ( @xmath23 ) : @xmath155&=&\\mathbb{e}[x_i]\\\\ \\label{ey_variancew } \\mathbb{e}[(y_i-{z_i})^2]&=&\\mathbb{e}[{x_i}^2]+d_i\\\\ \\mathbb{e}[x_i(y_i-{z_i})]&=&\\mathbb{e}[x_i^2]\\\\ \\mathbb{e}\\left[(y_1-z_1)(y_2-z_2)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right]\\\\ \\mathbb{e}\\left[x_1(y_2-z_2)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right]\\\\ \\mathbb{e}\\left[x_2(y_1-z_1)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right]\\end{aligned}\\ ] ] [ lem22 ]    notice that the results above are true for each coordinate @xmath124 .",
    "the proof of lemma [ lem22 ] is given in appendix b.    the improved decoder described below requires the knowledge of the second - order statistics of the source .",
    "however , as lemma [ lem22 ] shows , these statistics can be estimated from @xmath156 , so universality can still be maintained .",
    "the decoder of the multi - terminal setting uses the optimal linear estimator , under the mmse criterion , of @xmath157 given @xmath158 .",
    "the estimation error is calculated by using the results of lemma [ lem22 ] . from now on , without loss of generality , we assume that @xmath159=\\mathbb{e}[x_2]=0 $ ] .",
    "the covariance matrix of @xmath160 $ ] is : @xmath161+d_1&\\mathbb{e}[x_1x_2]\\\\ \\mathbb{e}[x_1x_2]&\\mathbb{e}[x^2_2]+d_2 \\end{array } \\right)\\ ] ] and the inverse matrix is : @xmath162+d_2&-\\mathbb{e}[x_1x_2]\\\\ -\\mathbb{e}[x_1x_2]&\\mathbb{e}[x^2_1]+d_1 \\end{array } \\right)\\ ] ] the vector @xmath163 $ ] is given by : @xmath164=\\left ( \\begin{array}{l } \\mathbb{e}[x^2_1]\\\\ \\mathbb{e}[x_1x_2 ] \\end{array } \\right)\\ ] ] it can be shown by direct calculation that @xmath165 = \\displaystyle\\frac{1}{|\\lambda|}\\left(\\begin{array}{l }    \\mathbb{e}[x_1x_2]d_1 \\end{array}\\right)\\end{aligned}\\ ] ] therefore , the optimal linear estimator of @xmath0 given the vector @xmath166 is : @xmath167d_1 \\end{array}\\right)\\end{aligned}\\ ] ] the error of the optimal linear estimator is given by : @xmath168-\\mathbb{e}\\left[\\hat{x}_1 ^ 2\\right]\\end{aligned}\\ ] ] it is shown in appendix c that the estimation error takes the following form : @xmath169(\\mathbb{e}[x^2_2]+d_2)-\\mathbb{e}[x_1x_2]^2}{(\\mathbb{e}[x^2_1]+d_1)(\\mathbb{e}[x^2_2]+d_2)- \\mathbb{e}[x_1x_2]^2 } \\label{est_error}\\end{aligned}\\ ] ] remember that @xmath170 is the distortion of @xmath0 in the multi - terminal setting , where we add the above estimation stage after decoding @xmath171 .",
    "it can be easily seen that the fraction in the brackets is less than @xmath172 and thus @xmath173 as desired .",
    "the same can be done , of course , for @xmath1 .",
    "since the distortion of @xmath45 in the improved scheme is @xmath174 , we should compare the rate pair @xmath46 of this scheme , to the optimal rate pair @xmath12 which achieves @xmath175 .",
    "this fact immediately improves on the results of theorems 1 and 2 . revisiting the derivation of the upper bound for @xmath120 in eq .",
    "( [ upper_bound_derivation ] ) , it can be shown that ( @xmath23 ) : @xmath176 \\label{upperbound222}\\end{aligned}\\ ] ] by using the following : @xmath177 notice that when @xmath0 and @xmath1 are independent , @xmath178=0 $ ] and we have @xmath179+d_i } \\right)\\right ] \\label{upperbound333}\\end{aligned}\\ ] ] the maximum interesting value of @xmath174 is , of course , @xmath180 $ ] .",
    "this value is obtained for @xmath181 .",
    "it is not hard to see that the range of the upper bound in ( [ upperbound333 ] ) is @xmath182 $ ] and that it is a decreasing function of @xmath183 . for the high - snr limit , i.e. , @xmath184",
    ", it is well known that the redundancy is @xmath185 bits / sample ( cf .",
    "@xcite ) . we define ( @xmath23 ) : @xmath186\\end{aligned}\\ ] ] we can now state theorems 3 and 4 .",
    "these theorems are obtained by applying the generalized upper bound of eq .",
    "( [ upperbound222 ] ) , instead of ziv s upper bound on @xmath187 , in the proofs of theorem 1 and 2 .    for any rate pair @xmath12 on the boundary of @xmath24 and any rate pair @xmath46 on the boundary of @xmath188 , with @xmath62 ,",
    "we have @xmath189 moreover , for any @xmath77 , there exists a rate pair @xmath190 such that : @xmath191 [ the22 ]    for any rate pair @xmath46 on the boundary of @xmath188 , with @xmath62 , there exists a rate pair @xmath190 such that : @xmath192 [ thestrongimproved ]",
    "the authors are grateful to prof .",
    "rami zamir for useful discussions .",
    "in this appendix we describe the universal slepian - wolf decoder used in our coding scheme .",
    "the following results are similar to those of @xcite . for convenience ,",
    "we omit the notation of the conditioning on the dither variables @xmath41 and @xmath42 .",
    "the results below can be applied for any realization of these continuous variables .",
    "remember that our coding scheme , unlike the scheme presented in @xcite , requires only one realization of @xmath41 and @xmath42 in each round .",
    "we consider the slepian - wolf setting for two correlated memoryless sources @xmath193 .",
    "we assume that @xmath194 and @xmath195 , where @xmath196 and @xmath197 are finite alphabets .",
    "a @xmath198 source code is a block code of length @xmath5 consisting of two encoders @xmath15 , @xmath16 , @xmath199 and a decoder @xmath18 @xmath200 where @xmath201 , @xmath202 .",
    "the probability of error of the code is defined as @xmath203 we will prove the following result :    let @xmath46 be given . then , there exists a sequence of @xmath204 slepian - wolf source codes with probability of error @xmath205 as @xmath206 for every memoryless source that satisfies eq .",
    "( [ slepian_wolf_eq ] ) .    throughout the proof ,",
    "the cardinality of a set @xmath207 is denoted by @xmath208 .",
    "the empirical joint entropy @xmath209 and the empirical conditional entropy @xmath210 induced by the sequences @xmath211 , @xmath212 are defined as @xmath213 where @xmath214 , @xmath215 are the empirical joint and conditional distribution functions , respectively , induced by @xmath216 and @xmath217 ( see ( * ? ? ?",
    "11 ) ) .    to prove the theorem",
    ", we use the following random - binning mechanism :    * _ codebook generation : _ assign every @xmath218 to one of @xmath219 bins independently according to a uniform distribution on @xmath220 .",
    "similarly , randomly assign every @xmath221 to one of @xmath222 bins .",
    "reveal the assignments @xmath71 and @xmath72 to the encoders and the decoder . * _ encoding : _ user @xmath223 sends the index of the bin to which @xmath224 belongs , @xmath202 . *",
    "_ decoding : _ given the received index pair @xmath225 , the decoder uses the minimum joint entropy ( mje ) decoder : choose the pair @xmath226 which minimizes the empirical joint entropy induced by @xmath227 , @xmath228 .",
    "define the following events : @xmath229 where @xmath230 , @xmath231 , is the strongly typical set with respect to the source @xmath232 ( see ( * ? ? ?",
    "10.107 ) ) .",
    "remember that @xmath47 , @xmath48 , @xmath71 and @xmath72 are random . obviously , @xmath233 where @xmath234 , @xmath210 are the empirical conditional entropies induced by @xmath235 and @xmath236 , respectively .",
    "we have an error if there is another pair of sequences in the same bin such that the empirical joint entropy induced by this pair is smaller than the empirical joint entropy induced by @xmath171 .",
    "hence , @xmath237 where @xmath238 $ ] is the expected probability of error where the expectation is taken with respect to the random choice of the code .",
    "the first inequality follows from the fact that we treat @xmath239 as error event and the second inequality is due to the union bound .",
    "we first consider @xmath239 . by the asymptotic equipartition property ( aep ) , @xmath240 and hence for @xmath5 sufficiently large , @xmath241 . to bound @xmath242",
    ", we have @xmath243 where the set @xmath244 is defined as @xmath245 and the last equality simply follows from the definition of the random - binning coding scheme . using the method of types ( see ( * ? ? ?",
    "10 - 11 ) ) , we have @xmath246 where @xmath247 is the conditional type of @xmath248 given @xmath217 ( see ( * ? ? ?",
    "* chap . 10 ) ) .",
    "the second equality follows from the fact that the event @xmath249 depends only on the type @xmath247 . in the first inequality",
    ", we used the known upper bound on the size of the conditional type .",
    "the second inequality stems from the definition of @xmath244 . in the third inequality we used a known upper bound on the number of conditional types",
    "the last inequality follows since ( see ( * ? ? ?",
    "10 ) ) @xmath250 therefore , we have @xmath251 where in the second inequality we used eq .",
    "( [ appa1 ] ) .",
    "similarly , it can be shown that @xmath252 and @xmath253 hence , taking @xmath254 , @xmath255 and @xmath256 , we have @xmath257 , @xmath258 and @xmath259 for sufficiently large @xmath5 . since @xmath260 , there exists at least one universal code @xmath261 with @xmath262 .",
    "thus , we can construct a sequence of universal codes with @xmath205 , and the proof of achievability is complete .",
    "_ remark_. it can be shown that the universal decoder presented in the proof above also achieves the optimal error exponent .",
    "we now prove lemma [ lem22 ] . we first show that the random vector @xmath263 is equivalent to the random vector @xmath264 where @xmath265 , @xmath266 are independent of @xmath0 , @xmath1 and of each other and @xmath267 $ ] , @xmath23 .",
    "therefore , the dithered quantization process can be viewed as passing @xmath0 , @xmath1 through independent noisy memoryless channels @xmath268 and @xmath269 , respectively .",
    "we start with the following conditional probability distribution .",
    "@xmath270 where we have defined @xmath271 , @xmath272 .",
    "the equality stems from the fact that @xmath273 is independent of @xmath1 given @xmath0 and @xmath274 is independent of @xmath0 given @xmath1 , since @xmath275 are independent of @xmath7 .",
    "in addition , it can be easily seen that for every value of @xmath45 , @xmath276 is uniformly distributed over @xmath34 $ ] .",
    "therefore , @xmath276 is independent of @xmath45 and we have @xmath277 lemma [ lem22 ] follows directly from this result : @xmath278&=&\\mathbb{e}[x_i+n_i]&=&\\mathbb{e}[x_i]\\\\ \\mathbb{e}[(y_i-{z_i})^2]&=&\\mathbb{e}[(x_i+n_i)^2]&=&\\mathbb{e}[{x_i}^2]+d_i\\\\ \\mathbb{e}[x_i(y_i-{z_i})]&=&\\mathbb{e}[x_i(x_i+n_i)]&=&\\mathbb{e}[x_i^2]\\\\ \\mathbb{e}\\left[(y_1-z_1)(y_2-z_2)\\right]&=&\\mathbb{e}\\left[(x_1+n_1)(x_2+n_2)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right]\\\\ \\mathbb{e}\\left[x_1(y_2-z_2)\\right]&=&\\nonumber\\mathbb{e}\\left[x_1(x_2+n_2)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right]\\\\ \\mathbb{e}\\left[x_2(y_1-z_1)\\right]&=&\\mathbb{e}\\left[x_2(x_1+n_1)\\right]&=&\\mathbb{e}\\left[x_1x_2\\right ] \\end{array}\\ ] ]",
    "in this appendix we calculate the estimation error given in eq .",
    "( [ est_error ] ) .",
    "the optimal linear estimator of @xmath0 given the vector @xmath166 is : @xmath279d_1 \\end{array}\\right ) \\end{array}\\ ] ] where @xmath280+d_1)(\\mathbb{e}[x^2_2]+d_2)- \\mathbb{e}[x_1x_2]^2\\end{aligned}\\ ] ] the error of the optimal linear estimator is given by : @xmath281-\\mathbb{e}\\left[\\hat{x}_1 ^ 2\\right]\\end{aligned}\\ ] ] calculating the second term : @xmath282&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)^2\\mathbb{e}\\left[\\left(y_1-z_1 \\right)^2\\right]\\\\ \\nonumber&&+\\mathbb{e}[x_1x_2]^2d_1 ^ 2\\mathbb{e}\\left[\\left(y_2-z_2\\right)^2\\right]\\\\ \\nonumber&&+2\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\mathbb{e}[x_1x_2]d_1\\mathbb{e}\\left[\\left(y_1-z_1\\right)\\left(y_2-z_2\\right)\\right]\\\\ \\nonumber&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)^2\\left(\\mathbb{e}[x^2_1]+d_1\\right)\\\\ \\nonumber&&+\\mathbb{e}[x_1x_2]^2d_1 ^ 2\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\\\ \\nonumber&&+2\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\mathbb{e}[x_1x_2]^2d_1\\\\ \\nonumber&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)^2\\left(\\mathbb{e}[x^2_1]+d_1\\right)\\\\ \\nonumber&&+\\mathbb{e}[x_1x_2]^2d_1\\left(d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)+2\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right ) \\right)\\\\",
    "\\nonumber&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)^2\\left(\\mathbb{e}[x^2_1]+d_1\\right)\\\\ \\nonumber&&+\\mathbb{e}[x_1x_2]^2d_1\\left(2|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\\\ \\nonumber & = & \\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right ) \\nonumber\\left(\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\left(\\mathbb{e}[x^2_1]+d_1\\right)+\\mathbb{e}[x_1x_2]^2d_1\\right ) \\\\ \\nonumber&&+|\\lambda|\\mathbb{e}[x_1x_2]^2d_1\\\\",
    "\\nonumber&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right ) \\nonumber\\left(|\\lambda|\\left(\\mathbb{e}[x^2_1]+d_1\\right)-d_1|\\lambda|\\right ) \\\\ \\nonumber&&+|\\lambda|\\mathbb{e}[x_1x_2]^2d_1\\\\",
    "\\nonumber&=&\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right ) \\nonumber|\\lambda|\\mathbb{e}[x^2_1 ] \\\\",
    "\\nonumber&&+|\\lambda|\\mathbb{e}[x_1x_2]^2d_1\\\\ \\nonumber&=&|\\lambda|^2\\mathbb{e}[x^2_1 ] \\nonumber+|\\lambda|d_1\\left(\\mathbb{e}[x_1x_2]^2-\\mathbb{e}[x^2_1]\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\\\ \\nonumber&=&|\\lambda|^2\\mathbb{e}[x^2_1 ] \\nonumber-|\\lambda|d_1\\left(\\mathbb{e}[x^2_1]\\left(\\mathbb{e}[x^2_2]+d_2\\right)-\\mathbb{e}[x_1x_2]^2\\right)\\\\ & = & |\\lambda|^2\\mathbb{e}[x^2_1 ] -|\\lambda|d_1\\left(|\\lambda|-d_1\\left(\\mathbb{e}[x^2_2]+d_2\\right)\\right)\\end{aligned}\\ ] ] where in the second equality we used the results of lemma [ lem22 ] .",
    "therefore , we have @xmath283+d_2))\\right)}{|\\lambda|^2}\\\\ \\nonumber&=&d_1\\left(1-\\frac{d_1(\\mathbb{e}[x^2_2]+d_2)}{|\\lambda|}\\right)\\\\ \\nonumber&=&d_1\\left(1-\\frac{d_1(\\mathbb{e}[x^2_2]+d_2)}{(\\mathbb{e}[x^2_1]+d_1)(\\mathbb{e}[x^2_2]+d_2)- \\mathbb{e}[x_1x_2]^2}\\right)\\\\ & = & d_1\\frac{\\mathbb{e}[x^2_1](\\mathbb{e}[x^2_2]+d_2)-\\mathbb{e}[x_1x_2]^2}{(\\mathbb{e}[x^2_1]+d_1)(\\mathbb{e}[x^2_2]+d_2)- \\mathbb{e}[x_1x_2]^2}\\end{aligned}\\ ] ]    1 d.  slepian and j.  k.  wolf , `` noiseless coding of correlated information sources , '' _ ieee trans .",
    "theory _ , vol .",
    "19 , pp .  471480 , jul . 1973 .",
    "a.  d.  wyner and j.  ziv , `` the rate - distortion function for source coding with side information at the decoder , '' _ ieee trans .",
    "inform . theory _",
    "22 , pp .",
    "110 , jan . 1976 .",
    "a.  d.  wyner , `` the rate - distortion function for source coding with side information at the decoder - ii : general sources , '' _ inform .",
    "_ , vol.38 , pp .",
    "6080 , 1978 .",
    "r.  ahlswede and j.  krner , `` source coding with side information and a converse for degraded broadcast channels , '' _ ieee trans .",
    "inform . theory _",
    "21 , no .  6 , pp .",
    "629637 , nov .",
    ". t.  berger and r.  w.  yeung , `` multiterminal source encoding with one distortion criterion , '' _ ieee trans .  inform .",
    "theory _ , vol .",
    "35 , no .  2 , pp .  228236 ,",
    "r.  zamir and t.  berger , `` multiterminal source coding with high resolution , '' _ ieee trans .",
    "inf . theory _ ,",
    "45 , pp .",
    "106117 , jan . 1999 .",
    "a.  wagner and v.  anantharam , `` an improved outer bound for multiterminal source coding , '' _ ieee trans .",
    "inf . theory _ ,",
    "54 , no .  5 , pp .",
    "19191937 , may 2008 .",
    "a.  wagner , s.  tavildar , and p.  viswanath , `` rate region of the quadratic gaussian two - encoder source - coding problem , '' _ ieee trans .",
    "inf . theory _ ,",
    "54 , no .  5 , pp .  19381961 , may 2008 . t.  berger and s.  y.  tung , `` encoding of correlated analog sources , '' in _ proc .",
    "ussr joint workshop on information theory _",
    ", pp .  710 , 1975 . t.  a.  courtade and t.  weissman , `` multiterminal source coding under logarithmic loss , '' _ ieee trans .",
    "inform . theory _",
    "60 , pp .",
    "740761 , jan .",
    "y.  kaspi and n.  merhav , `` zero - delay and causal single - user and multi - user lossy source coding with decoder side information , '' _ ieee trans .",
    "inf . theory _ , vol .",
    "60 , no .  11 ,",
    "6931-6942 , nov .",
    "j.  ziv , `` on universal quantization , '' _ ieee trans .",
    "inform . theory _",
    "31 , pp.344347 , may 1985 .",
    "r.  zamir and m.  feder , `` on universal quantization by randomized uniform / lattice quantizer , '' _ ieee trans .",
    "inform . theory _",
    "38 , pp.428436 , mar .",
    "r.  zamir and m.  feder , `` information rates of pre / post filtered dithered quantizers , '' _ ieee trans .",
    "inform . theory _",
    "42 , pp .  13401353 , sept .",
    "j.  kieffer , `` a unified approach to weak universal source coding , '' _ ieee trans .",
    "inform . theory _",
    "24 , pp .",
    "674682 , nov .",
    "1978 . h.  gish and n.  j.  pierce , `` asymptotically efficient quantization , '' _ ieee trans .",
    "inform . theory _",
    "14 , pp .  676683 ,",
    ". i.  csiszar and j.  krner , `` towards a general theory of source networks , '' _ ieee trans .",
    "inform . theory _",
    ", vol .  26 , pp .  155165 , mar .",
    "t. m.  cover and j. a.  thomas , `` elements of information theory , '' , _ john wiley _ & _ sons , 2nd edition_."
  ],
  "abstract_text": [
    "<S> we consider the multi - user lossy source - coding problem for continuous alphabet sources . in a previous work , </S>",
    "<S> ziv proposed a single - user universal coding scheme which uses uniform quantization with dither , followed by a lossless source encoder ( entropy coder ) . in this paper , we generalize ziv s scheme to the multi - user setting . </S>",
    "<S> for this generalized universal scheme , upper bounds are derived on the redundancies , defined as the differences between the actual rates and the closest corresponding rates on the boundary of the rate region . </S>",
    "<S> it is shown that this scheme can achieve redundancies of no more than 0.754 bits per sample for each user . </S>",
    "<S> these bounds are obtained without knowledge of the multi - user rate region , which is an open problem in general . as a direct consequence of these results , </S>",
    "<S> inner and outer bounds on the rate - distortion achievable region are obtained . </S>",
    "<S> +   + * index terms : multi - terminal source coding , dithered quantization , universal source coding , scalar quantization , slepian - wolf coding . * </S>"
  ]
}