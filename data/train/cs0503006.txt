{
  "article_text": [
    "the binary erasure channel ( bec ) was introduced by elias @xcite in 1955 .",
    "it counts lost information bits as being `` erased '' with probabilities equal to @xmath0 .",
    "currently , the bec is widely used to model the internet transmission systems , in particular multicasting and broadcasting .    as a milestone , luby _ et .",
    "@xcite proposed the first realization of a class of erasure codes  lt codes , which are rateless and are generated on the fly as needed .",
    "however , lt - codes can not be encoded with constant cost if the number of collected output symbols is close to the number of input symbols . in @xcite",
    ", shokrollahi introduced the idea of raptor codes which adds an outer code to lt codes .",
    "raptor codes have been established in order to solve the error floors exhibited by the lt codes .    on the other hand ,",
    "low - density parity - check ( ldpc ) codes have been studied @xcite to @xcite for application to the bec .",
    "the iterative decoding algorithm , which is the same as gallager s soft - decoding algorithm @xcite , was implemented @xcite .",
    "capacity - achieving degree distributions for the binary erasure channel have been introduced in @xcite , @xcite and @xcite .",
    "finite - length analysis of ldpc codes over the bec was accomplished in @xcite . in that paper , the authors have proposed to use finite - length analysis to find good finite - length codes for the bec .    in this paper",
    ", we show the derivation of a new decoding algorithm to improve the performance of binary linear block codes on the bec .",
    "the algorithm can be applied to any linear block code and is not limited to ldpc codes . starting with superposition of the erased bits on the parity - check matrix , we review the performance of the iterative decoding algorithms , described in the literature , for the bec , principally the recovery algorithm and the guess algorithm  @xcite . in section [ sec:03 ]",
    ", we propose an improvement to the guess algorithm based on multiple guesses : the multi - guess algorithm and give a method to calculate the minimum number of guesses required in the decoding procedure . in this section",
    ", we also describe a new , non iterative decoding algorithm based on a gaussian - reduction method @xcite by processing the parity - check matrix . in section [ sec:04 ] ,",
    "we compare the performance of these algorithms for different codes using computer simulation . in section [ sec:05 ]",
    ", we discuss the application of these decoding algorithms for the internet .",
    "section [ sec:06 ] concludes the paper .",
    "let @xmath1 denote the parity - check matrix . considering an @xmath2 binary linear block code , we assume that the encoded sequence is @xmath3 . after being transmitted over the erasure channel with erasure probability @xmath4",
    ", the encoded sequence can be divided into the transmitted sub - sequence and the erased sub - sequence , denoted as @xmath5 and @xmath6 respectively , where @xmath7 .",
    "corresponding to the parity check matrix of the code , we can generate an erasure matrix @xmath8 ( @xmath9 ) which contains the positions of the erased bits in @xmath1 .",
    "then we denote the set of erased bits @xmath10 that participate in each parity check row by @xmath11 with @xmath12 standing for `` horizontal '' and the number of erased bits in @xmath13 is denoted by @xmath14 .",
    "similarly we define the set of checks in which bit @xmath15 participates , @xmath16 with @xmath17 standing for `` vertical '' , and the number of erased bits in @xmath18 is denoted by @xmath19 .",
    "let @xmath20 and @xmath21 . the matrix representation is shown in fig .",
    "[ fig:1 ] , where an `` x '' represents an erasure .    a matrix representation of the erased bits , width=144 ]      in @xcite , the message - passing algorithm was used for reliable communication over the bec at transmission rates arbitrarily close to channel capacity .",
    "the decoding algorithm succeeds if and only if the set of erasures do not cause stopping sets  @xcite . for completeness",
    ", this algorithm is briefly outlined below : + * recovery algorithm *    * _ step 1 _ generate the @xmath8 and obtain the @xmath22 . * _ step 2 _ for @xmath23 , if @xmath24 , we replace the value in the bit position @xmath10 with the xor of the unerased bits in that check equation .",
    "then we remove the erasure from the erasure matrix . * _ step 3 _ continue from step 2 until all the erased bits are solved or the decoding can not continue further .",
    "the decoder will fail if stopping sets exist .",
    "we can break the stopping sets by performing several `` guesses '' of the unsolved erased bits .",
    "this algorithm is called the guess algorithm  @xcite . +",
    "* guess algorithm *    * _ step 1 _ run the decoder with recovery algorithm until it fails due to stopping set(s ) . *",
    "_ step 2 _ in order to break the stopping set , when @xmath25 , we guess one of the erased symbols and update the erasure matrix @xmath8 and @xmath22 . * _ step 3 _ continue from step 1 until all the erased symbols are solved or the decoding can not continue further . if the decoder can not continue , declare a decoder failure and exit . * _ step 4 _ creat a list of @xmath26 solutions , where @xmath27 is the number of guesses made . from the list @xmath28 , @xmath29 ,",
    "pick the one that satisfies @xmath30 .",
    "obviously , compared to the recovery algorithm , the complexity of this algorithm increases with @xmath27 .",
    "usually , we limit the number of guesses to a small number @xmath31 . if after @xmath31 guesses , the decoding still can not be finished , a decoding failure is declared . for sparse codes with low - density @xmath1 , e. g. ldpc codes , the guess algorithm can improve the performance with @xmath32 guesses as shown in section [ sec:04 ] .",
    "the decoding algorithm is more efficient when the bits to be guessed are carefully chosen .",
    "these are termed `` crucial''bits .",
    "the crucial bits are chosen on the basis of the highest value of @xmath33 with the value of @xmath34 .",
    "for non - sparse linear codes , it is common to encounter more than 2 unsolved symbols in each row of @xmath8 after running the guess algorithm , due to the high - density of their parity check matrix . in these cases",
    ", we can not break the stopping set by guessing one erased symbol in a row only .",
    "more than 1 erased symbols at one time need to be guessed .",
    "we can calculate the minimum number of guesses before the decoding .",
    "consider the chosen erased symbols in each row as an erased group .",
    "let @xmath35 denote the set of rows with @xmath36 erasures , that is , @xmath37 .",
    "and @xmath38 is the set of rows which satisfies : + @xmath39 then @xmath40 where 1 accounts for the need for at least one `` crucial '' row .    when the guessing process stops , there are more than 2 erased symbols in each erased row .",
    "the rows that have more than two bits @xmath41 which do not participate in any other row ( i. e. @xmath42 ) can not be solved by other rows , and so at least one of these bits has to be guessed .",
    "so the minimum number of guesses equals to the number of all the independent guesses plus one more `` crucial '' guess to solve the other rows .    for the multi - guess algorithm ,",
    "a whole row is guessed .",
    "a crucial row @xmath43 is defined as follows :    1 .",
    "@xmath44 2 .",
    "@xmath45    the multi - guess algorithm is given below : + * multi - guess algorithm *    * _ step 1 _ run the decoder with guess algorithm until @xmath46 for @xmath47 . * _ step 2 _ evaluate the value of @xmath48 . if @xmath49 , the decoding declares a failure and exits .",
    "* _ step 3 _ group the rows with @xmath50 as @xmath35 , where @xmath23 . *",
    "_ step 4 _ find the `` crucial '' row and guess all erased bits in that row .",
    "( there will be at most @xmath51 guesses . )",
    "* _ step 5 _ guess one bit @xmath52 with @xmath53 in each of the independent rows , i.e. the rows in @xmath54 . * _ step 6 _ update @xmath8 , @xmath22 and @xmath55 .",
    "continue the decoding from step 3 to step 5 until all the erased bits are solved or the decoding can not continue further .",
    "the disadvantages of guess and multi - guess algorithms include the decoding complexity and the correctness of the results .",
    "the decoding complexity grows exponentially with the number of guesses .",
    "it is possible that the group guess declares a wrong value as the result of the decoder .",
    "although this kind of situation happens only when the value of @xmath4 is very small , it is still undesirable .",
    "let @xmath56 denote the received vector , where @xmath57 .",
    "we now devise a reduced complexity algorithm to decode the erased bits by solving the equation  [ eq:1 ] using the gaussian reduction method @xcite .",
    "@xmath58 according to @xcite , the optimal decoding is equivalent to solving the linear system , shown in the equation [ eq:1 ] .",
    "if the equation [ eq:1 ] has a unique solution , the optimal algorithm is possible .",
    "guassian reduction algorithm is considered as the optimal algorithm over the bec .",
    "we propose a reduced complexity guassian reduction algorithm  in - place algorithm @xcite by elimilating the column - permutations required",
    ". this algorithm is stated as follows : + * in - place algorithm *    * _ step 1 _ the codeword is received and @xmath59 are substituted in positions of erased bits in @xmath1 . starting with one of the erased symbols , @xmath60 , the first equation containing this symbol is flagged that it will be used for the solution of @xmath60 .",
    "this equation is subtracted from all other equations containing @xmath60 and not yet flagged to produce a new set of equations .",
    "the procedure repeats until either non flagged equations remain containing @xmath60 ( in which case a decoder failure is declared ) or no erased symbols remain that are not in flagged equations . *",
    "_ step 2 _ let @xmath61 be the erased symbols at the last flagged equations",
    ". in the latter case , starting with @xmath61 this equation is solved to find @xmath62 and this equation is unflagged .",
    "this coefficient is substituted back into the remaining flagged equations containing @xmath62 .",
    "the procedure now repeats with the second from last flagged eqaution now being solved for @xmath63 .",
    "this equation is unflagged and followed by back substitution of @xmath64 for @xmath63 in the remaining flagged equations .",
    "erasure correction using in - place algorithm , width=240 ]    a block schematic of the decoder is shown in fig.[fig:03 ] .",
    "the received bits are stored in the shift register with the erased bits being replaced by the unknown @xmath59 .",
    "the gaussian reduced equations are computed and used to define the connection of bit adders from the respective shift register stage to compute the outputs @xmath65 to @xmath66 .",
    "the non erased symbols contained in the shift register are switched directly through to the respective output so that the decoded codeword with no erased bits is present at the outputs @xmath65 through to @xmath66 .",
    "we evaluated the performance of the recovery algorithm with the lt codes with soliton distribution as described in @xcite and irregular ldpc codes .",
    "as shown in fig . [ fig:04 ] , the performance of irregular ldpc codes is significantly better than that of the lt codes for the same block length . as a consequance , we use ldpc codes to benchmark the remaining algorithms .",
    "performance of the lt codes and irregular ldpc codes with erasure probability = 0.2,width=240 ]    a particularly strong binary code and which has a sparse @xmath1 is the cyclic ldpc code ( 255,175 ) , which has a length of 255 bits after encoding of 175 information bits .",
    "since the parity - check polynomial of the ( 255,175 ) code is orthogonal on every bit position , the minimum hamming distance is @xmath67 , where @xmath68 denotes the number of ones per row in @xmath1  @xcite .",
    "the applicability of the decoding methods above depends on the error correcting code being used and specifically on the parity check matrix being used .",
    "the performance of this code for the recovery , the guess and the in - place algorithms is shown in fig . [ fig:06 ] in terms of the probability of decoder error ( fer ) as a function of the erasure probability for every transmitted bit .",
    "performance of the cyclic ldpc ( 255,175 ) with the guess , the multi - guess and the in - place algorithms , width=240 ]    performance of the cyclic ldpc ( 341,205 ) with the recovery , the guess , the multi - guess and the in - place algorithms , width=240 ]    due to its sparse parity check matrix , guess algorithm with less than 3 guesses can achieve more than 1 order of magnitude improvement compared to that of recovery algorithm . in addition , from fig . [ fig:06 ] , we also can see that the curve of guess algorithm is very close to the curve of in - place algorithm , which means guess algorithm is a `` near optimal decoding '' algorithm when it has a sparse parity check matrix .",
    "[ fig:07 ] shows the performance of the ( 341,205 ) ldpc code with the recovery , the guess , the multi - guess and the in - place algorithms . comparing these results of the recovery and guess algorithms ,",
    "the multi - guess algorithm can obtain the results by several orders of magnitude better .",
    "for example , when the erasure probability equals to 0.3 , the multi - guess algorithm with @xmath69 is one order of magnitude better than the recovery and guess algorithms , when @xmath70 , the multi - guess algorithm is 2 order2 of magnitude better than the recovery and the guess algorithms .",
    "as an optimal decoding algorithm , the in - place algorithm can achieve 4 orders of magnitude better than the recovery and the guess algorithm .    the ultimate performance of the in - place algorithm as a function of error correcting code is shown in fig .",
    "[ fig:6 ] for the example ( 255,175 ) code which can correct a maximum of 80 erased bits .",
    "[ fig:6 ] shows the probability density function of the number of erased bits short of the maximum correctable which is @xmath71 .",
    "the results were obtained by computer simulations .",
    "the probability of being able to correct only 68 bits , a shortfall of 12 bits , is @xmath72 .",
    "simulations indicate that on average 77.6 erased bits may be corrected for this code . in comparison",
    "the bch ( 255,178 ) code having similar rate is also shown in fig .",
    "[ fig:6 ] .",
    "the bch code has a similar rate but a higher minimum hamming distance of 22 ( compared to 17 ) .",
    "it can be seen that it has better performance than the ( 255,175 ) code but it has a less sparse parity check matrix and consequently it is less suitable for recovery algorithm and guess algorithm .",
    "moreover the average shortfall in erasures not corrected is virtually identical for the two codes .",
    "comparison of probability distribution of number of erased bits not corrected from maximum correctible (",
    "n - l ) for ( 255,175 ) code and bch ( 255,178 ) code , width=240 ]    the simulation results of using in - place algorithm for the ( 103,52 ) quadratic residue binary code @xcite are shown in fig . [ fig:7 ] .",
    "the minimum hamming distance for this code is 19 and the results are similar to that of the ( 255,178 ) bch code above .",
    "it is found from the simulations that on average 49.1 erasure bits are corrected ( out of a maximum of 51 ) and the average shortfall from the maximum is 1.59 bits .",
    "probability distribution of number of erased bits not corrected from maximum correctible (",
    "n - l ) for ( 103,52 ) code quadratic redisue code , width=240 ]    similarly the results for the extended bch ( 128,64 ) code is shown in fig .",
    "[ fig:8 ] .",
    "this code has a minimum hamming distance of 22 and has a similar probability density function to the other bch codes above . on average 62.39 erasure bits",
    "are corrected ( out of a maximum of 64 ) and the average shortfall is 1.61 bits from the maximum .",
    "probability distribution of number of erased bits not corrected from maximum correctible (",
    "n - l ) for ( 128,64 ) extended bch code , width=240 ]",
    "in multicast and broadcast information is transmitted in data packets with typical lengths from 30 bits to 1000 bits .",
    "these packets could define a symbol from a galois field @xcite , viz @xmath73 but with @xmath74 equal to 30 or more up to and beyond 1000 bits this is impracticable and it is more convenient to use a matrix approach with the packets forming the rows of the matrix and columns of bits encoded using an error correcting code . usually , but not essentially the same code would be used to encode each column of symbols .",
    "the matrix of symbols may be defined as :    [ cols= \" < , < , < \" , ]     there are a total of @xmath75 information symbols which encoded using the parity check equations of a selected code into a total number of transmitted symbols equal to @xmath76 .",
    "the symbols are transmitted in a series of packets with each packet corresponding to a row as indicated above .",
    "for example the row : @xmath77 is transmitted as a single packet .",
    "self contained codewords are encoded from each column of symbols . for example @xmath78",
    "form the information symbols of one codeword and the remaining symbols , @xmath79 are the parity symbols of that codeword . as a result of network congestion , drop outs , loss of radio links or other multifarious reasons not all of the transmitted packets are received .",
    "the effect is that some rows above are erased .",
    "the decoding procedure is that codewords are assemble from the received packets with missing symbols corresponding to missing packets marked as @xmath80 .",
    "for example , if the second packet only is missing above :    * the first received codeword corresponds to the first column above and is @xmath81 * the second codeword corresponding to the first column above and is @xmath82 and so on .",
    "all the algorithms stated in section 2 may be used to solve for the erased symbols @xmath83 in the first received codeword , and for the erased symbol @xmath84 in the second received codeword and so on up to the @xmath85th codeword ( column ) solving for @xmath86 .    as an example",
    ", the binary , extended @xmath87 bch code could be used to encode the information data .",
    "the packet length is chosen to be 100 bits , and the total transmission could consist of 128 transmitted packets ( 12,800 bits total ) containing 6,400 bits of information . on average as soon as any 66 packets from the original 128 packets have been received , the remaining 62 packets are treated as if they are erased .",
    "100 codewords are assembled , decoded with the erasures solved and the 6,400 bits of information retrieved .",
    "one advantage is that a user does not have to wait until the entire transmission has been received .",
    "in this paper , we presented different decoding algorithms of ldpc codes over the bec : recovery , guess , multi - guess and in - place algorithms .",
    "the multi - guess algorithm is an extension to guess algorithm , which can push the limit to break the stopping sets .",
    "we show that guess and multi - guess algorithms are parity - check matrix dependent . for the codes with sparse parity - check matrix , guess and multi - guess algorithms can be considered as `` near - optimal decoding methods '' . on the other hand ,",
    "in - place algorithm is not .",
    "it s an optimal method for the bec and able to correct @xmath88 erasures , where @xmath89 is a small positive integer .                      c. di , d. proietti , i. e. telatar , t. richardson , and r. urbanke , `` finite - length analysis of low - density parity - check codes on the binary erasure channel , '' _ ieee tran .",
    "inform . theory _",
    "1570  1579 , june 2002 .",
    "a. m. odlyzko , `` discrete logarithms in finite fields and their cyptographic significance , '' in advances in cyptology : proceeding of eurocrypt84 , t. beth , n. cot , and i. ingemarssen , eds .",
    "berlin , germany : springer - verlag , 1985 , vol .",
    "224  314 ."
  ],
  "abstract_text": [
    "<S> this paper investigates decoding of binary linear block codes over the binary erasure channel ( bec ) . of the current iterative decoding algorithms on this channel , we review the recovery algorithm and the guess algorithm . </S>",
    "<S> we then present a multi - guess algorithm extended from the guess algorithm and a new algorithm  the in - place algorithm . </S>",
    "<S> the multi - guess algorithm can push the limit to break the stopping sets . </S>",
    "<S> however , the performance of the guess and the multi - guess algorithm depend on the parity - check matrix of the code . </S>",
    "<S> simulations show that we can decrease the frame error rate by several orders of magnitude using the guess and the multi - guess algorithms when the parity - check matrix of the code is sparse . </S>",
    "<S> the in - place algorithm can obtain better performance even if the parity check matrix is dense . </S>",
    "<S> we consider the application of these algorithms in the implementation of multicast and broadcast techniques on the internet . </S>",
    "<S> using these algorithms , a user does not have to wait until the entire transmission has been received . </S>"
  ]
}