{
  "article_text": [
    "consider a sample @xmath5 we look for substitutes @xmath6 * * and * * @xmath7 of the sample mean vector and covariance matrix , that are resistant to atypical observations .",
    "we also want estimators that have a high efficiency for normal samples@xmath8 as a measure of robustness we consider not only the breakdown point but also the maximum expected kullback - leibler divergence between the estimator and the true value . under contamination .",
    "the most frequently employed estimators are not quite satisfactory in this respect .",
    "the minimum volume ellipsoid ( mve ) and the minimum covariance determinant ( mcd ) estimators ( rousseeuw 1985 ) are known to have a low efficiency .",
    "this efficiency can be increased by means of a one - step reweighting .",
    "croux and haesbroeck ( 1999 , tables vii and viii ) computed the finite - sample efficiencies of the reweighted mcd ; although they are much higher than for the raw  estimator , they are still low if one wants a high breakdown point .",
    "s - estimators ( davies 1987 ) with a monotonic weight function like the bisquare have a low efficiency for small @xmath9 rocke ( 1996 ) showed that their efficiency tends to one with increasing @xmath0 ; unfortunately , this advantage is paid for with a serious loss of robustness for large @xmath0 .",
    "we restrict ourselves to equivariant estimators . there",
    "exist many non - equivariant proposals ; but the comparison between equivariant and non - equivariant estimators is difficult .",
    "in particular , a non - equivariant estimator is more difficult to tune for a given efficiency , since the latter depends on the correlations .    among the published equivariant proposals ,",
    "there are four families of estimators with controllable efficiencies : non - monotonic s - estimators ( rocke 1996 ) , mm - estimators ( tatsuoka and tyler 2000 ) , @xmath2-estimators ( lopuhaa 1991 ) and the estimator proposed independently by stahel ( 1981 ) and donoho ( 1982 ) but their behavior for large dimensions has not been explored to date .",
    "we compare their behaviors employing different weight functions .",
    "a simulation study shows that the rocke and mm estimators , with an adequate weight function and an adequate tuning , can simultaneously attain high efficiency and high robustness .",
    "it will be seen below that if we have a good @xmath10 it is easy to find a good equivariant @xmath11 but the converse is not true .",
    "for this reason we shall put more emphasis on the estimation of the scatter matrix .",
    "since all the considered estimators are based on the iterative minimization of a non - convex function , the starting values are crucial .",
    "subsampling is the standard way to compute starting values ; but we shall see that a semi - deterministic equivariant procedure proposed by pea and prieto ( 2007 ) may yield both shorter computing times and better statistical performances .    in section [ secmesti ] we describe monotonic m - estimators ; section [ secminscale ] deals with estimators based on the minimization of a robust scale of mahalanobis distances .",
    "sections [ secmm ] and [ sec_stadono ] deal with mm and stahel - donoho estimators respectively . in section [ secrho ]",
    "we discuss the choice of the @xmath12function for mm- and @xmath13estimators .",
    "section [ seccomputing ] deals with computational details . in section [ secsimula ]",
    "the estimators are compared through a simulation study . in section [ secreal ]",
    "the estimators are applied to a real data set .",
    "finally section [ secconclu ] summarizes the results .",
    "section [ secappend ] is an appendix containing the full results of the simulations , the approximations for the tuning constants and some details on the rocke and the pea - prieto procedures .",
    "for @xmath14 and @xmath15 define the ( squared ) mahalanobis distance as @xmath16    let @xmath17 be a bounded nonincreasing weight function . then monotonic m - estimators ( maronna 1976 ) are defined as solutions of @xmath18 where for brevity we put @xmath19    the uniqueness of the solutions requires that @xmath20 be nondecreasing .",
    "unfortunately , this implies ( maronna , 1976 ) that the breakdown point is @xmath21 which makes these estimators unreliable except for small @xmath9 besides , this fact holds even if @xmath22 is known , while the asymptotic breakdown point of @xmath23 with known @xmath24 is 0.5 with an adequate @xmath25 this shows that the main problem to attain high robustness is the scatter matrix .",
    "for @xmath26 let @xmath27 be a robust scale . put @xmath28 a general family of estimators can be defined by @xmath29 where the condition @xmath30 rules out trivial solutions with @xmath31 .    if @xmath32 we have the minimum volume ellipsoid  ( mve ) estimator , and if @xmath33 is a trimmed mean , we have the minimum covariance determinant  ( mcd ) estimator , both proposed by rousseeuw ( 1985 ) .",
    "the first one is very robust , but has a null asymptotic efficiency ; the second is very popular , but its asymptotic efficiency is very low ; see ( paindaveine and van bever , 2014 ) and references therein , and its maximum contamination bias increases rapidly with @xmath0 ( agostinelli et al , 2015 , table 1 ) .",
    "the condition @xmath30 means that we estimate the shape  of the scatter .",
    "given the shape , the size  can easily estimated to yield consistency at the normal model ( maronna et al .",
    ", section 6.3.2 ) .",
    "a simple way is to put@xmath34 instead of the median , one could use more efficient scales , such as an m - scale , but exploratory simulations indicate that they do not yield better results .",
    "let @xmath35 be a scale m - estimator defined as solution of @xmath36 where @xmath37 controls the breakdown point , and @xmath38 $ ] is smooth and nondecreasing in @xmath39 with @xmath40 and @xmath41 then s - estimators ( davies 1987 ) are defined as solutions of ( [ defescamini ] ) with @xmath33 given by ( [ defmscale ] ) .    the maximum finite - sample replacement breakdown point is attained when @xmath42 and its value is equal to this @xmath43 see ( maronna et al .",
    ", 2006 , section 6.4.2 ) .",
    "a popular @xmath44 is the bisquare given by @xmath45{ccc}1-\\left (   1-d\\right )   ^{3 } & \\mathrm{if } & d\\leq1\\\\ 1 & \\mathrm{if } & d>1 .",
    "\\end{array } \\right .",
    "\\label{defibis}\\ ] ] note that the usual bisquare @xmath44 employed for regression is actually @xmath46 however , since we are dealing with the _ squared _ distances , we employ in ( [ defibis ] ) @xmath47    it is easy to show that s - estimators satisfy the estimating equations@xmath48 with @xmath49 that is , they satisfy the equations ( [ defmesti])-([defmesti2 ] ) which define monotonic m - estimators , with weight function @xmath49 here , since @xmath44 is bounded @xmath20 is not a nondecreasing function , and therefore this case is different from monotonic  m - estimators . in particular ,",
    "the breakdown point is not bounded by @xmath50 as shown by ( [ bdp - s ] ) .    for the bisquare , the weight function is@xmath51 ( where @xmath52 denotes the indicator ) , which is decreasing .",
    "it seems intuitive that the weights of the observations should decrease with their outlyingness .",
    "however it will be seen in the next section that monotonicity is not necessarily favorable .",
    "rocke ( 1996 ) showed that if @xmath17 is nonincreasing , the efficiency of the estimator tends to one when @xmath53 a similar result was derived by kent and tyler ( 1996 , page 1363 ) for their constrained m - estimators .",
    "table [ tabefisbis ] shows the efficiencies ( to be defined later ) of the bisquare s - estimator of scatter for normal @xmath0-dimensional data .",
    "[ c]cccccccc@xmath0 & 2 & 5 & 10 & 20 & 30 & 40 & 50 + efficiency & 0.427 & 0.793 & 0.930 & 0.976 & 0.984 & 0.990 & 0.992 +    however , it will be seen that the price for this increase in efficiency is a decrease in robustness .",
    "more precisely , although the breakdown point does not tend to zero with increasing @xmath1 the bias caused by contamination grows rapidly with @xmath9 this fact suggests that we need estimators with a controllable efficiency .",
    "but while in regression the efficiency has to be controlled to make it higher , here we need to prevent it from becoming too high .    based on the fact that for large @xmath0 the @xmath0-variate standard normal distribution @xmath54 is concentrated near  the spherical shell with radius @xmath55 rocke ( 1996 ) proposed estimators with non - monotonic weight functions .",
    "maronna et al . ( 2006 ) proposed a modification of rocke s biflat  function , namely@xmath56 \\mathrm{i}\\left (   1-\\gamma\\leq d\\leq1+\\gamma\\right )   \\label{rockeweight}\\ ] ] with@xmath57 where @xmath58 is the @xmath59-quantile of the @xmath60 distribution with @xmath0 degrees of freedom , and @xmath61 is small  to control the efficiency .    maronna et al ( 2006 , sec .",
    "6.8 ) dealt only with location .",
    "the performance of the respective scatter matrix will be studied below .",
    "@xmath62estimators were proposed by yohai and zamar ( 1988 ) to obtain robust regression estimators with controllable efficiency , and later lopuha ( 1991 ) employed the same approach for multivariate estimation .",
    "this approach requires two functions @xmath63 and @xmath64 for given @xmath65 call @xmath66 the solution of @xmath67    then the estimator minimizes the @xmath68-scale@xmath69    here @xmath70 where @xmath71 is chosen to regulate the efficiency .",
    "originally , @xmath2-estimators were proposed to obtain estimators with higher efficiency than s - estimators for small @xmath1 which required @xmath72 but for large @xmath0 we need @xmath73 in order to decrease the efficiency .",
    "mm - estimators were initially proposed by yohai ( 1987 ) to obtain regression estimators with a controllable efficiency . this approach has been used in the multivariate setting by lopuha ( 1992 ) and tatsuoka and tyler ( 2000 ) . here",
    "we give a simplified version of the latter .",
    "let @xmath74 be an initial very robust although possibly inefficient estimator .",
    "put@xmath75 and call @xmath33 the respective m - scale@xmath76    the estimator is defined by @xmath77 with @xmath78 such that@xmath79 where @xmath80 and the constant @xmath71 is chosen to control efficiency .",
    "it can be shown that the solution satisfies the equations @xmath81 with @xmath82    actually , it is not necessary to obtain the absolute minimum in ( [ defmm_min ] ) . as with regression mm - estimators ( yohai 1987 ) it is possible to show that any solution of ( [ defmm ] ) for with the objective function ( [ defmm_min ] ) is lower that for the initial estimator , has the same asymptotic behavior as the absolute minimum and has a breakdown point at least as high as the initial estimator .    like @xmath2-estimators ,",
    "mm estimators were originally proposed to obtain estimators with higher efficiency than s - estimators for small @xmath83 but here for large @xmath0 the constant has to chosen to prevent the efficiency becoming too high .",
    "let @xmath84 and @xmath85 be univariate location and dispersion statistics , e.g. , the median and mad . define for any @xmath86 the _ outlyingness _ @xmath87 : @xmath88 where the supremum is over @xmath89 with @xmath90 or equivalently over the spherical surface @xmath91 . here",
    "@xmath92 denotes @xmath93 .",
    "let @xmath17 ( the _ weight function _ ) be a positive function . the stahel ",
    "donoho estimator of location and scatter , @xmath94 is a weighted mean and covariance matrix , with weights @xmath95 .    if @xmath17 is continuous , and @xmath96 and @xmath97 are bounded for @xmath98 , the estimators have asymptotic breakdown point @xmath99 for all @xmath0 at continuous multivariate models , if @xmath100 and @xmath33 have asymptotic breakdown point @xmath99 ( see hampel et al.1986 ) .",
    "the finite - sample breakdown point was derived by tyler ( 1994 ) .",
    "maronna and yohai ( 1995 ) showed that these estimators have order @xmath101-consistency .",
    "their asymptotic distribution was given by zuo et al .",
    "( 2004 ) .",
    "maronna and yohai ( 1995 ) recommended a huber - type  @xmath102 however , further exploratory simulations indicate that better results are obtained with the weight function described in the next section .",
    "the numerical computation of these estimators is difficult .",
    "stahel ( 1981 ) proposed an approximate algorithm based on subsampling , the cost of which increases rapidly with @xmath0 .",
    "pea and prieto ( 2007 ) proposed a fast algorithm for outlier detection which combines the projections on a set of @xmath103 deterministic directions that are extrema of the kurtosis , and a set of random directions .",
    "although this method was originally meant for data analysis , it offers two further uses .",
    "first , the resulting projections can be employed to compute the stahel - donoho estimator ; second , the method yields a robust ( but probably inefficient ) estimator that can be used as a starting point for the iterative computing of the estimators described above .",
    "further details about this procedure are given in section [ seccomputing ]",
    "the most popular @xmath44 in robust methods seems to be the bisquare .",
    "yohai and zamar ( 1997 ) proposed a @xmath44 for regression with certain optimality properties . a simplified variant of this function is given by muler et al ( 2002 ) .",
    "its version for multivariate estimation has weight function    @xmath104{ccc}1 & \\mathrm{if } & d\\leq4\\\\ q\\left (   d\\right )   & \\mathrm{if } & 4<d\\leq9\\\\ 0 & \\mathrm{if } & d>9 \\end{array } \\right .   , \\label{optiweight}\\ ]",
    "]    where@xmath105 is such that @xmath17 is continuous and differentiable at @xmath106 and @xmath107 the respective @xmath44 function is@xmath108{ccc}d & \\mathrm{if } & d\\leq4\\\\ s\\left (   d\\right )   & \\mathrm{if } & 4<d\\leq9\\\\ 6.494 & \\mathrm{if } & d>9 \\end{array } \\right .   , \\ ] ] where@xmath109    figure [ figweigths ] shows the bisquare and optimal  weight functions , scaled with their respective tuning constants for the mm - estimator with 90% efficiency and @xmath110 .",
    "it is seen that the optimal  @xmath44 yields a smaller cutoff point .",
    "[ tbh ]    weights.eps",
    "all estimators described above are computed as iterative reweighted means and covariances , starting from an initial estimator . for s- ,",
    "@xmath62 and mm estimators this algorithm ensures that the objective function descends at each iteration . this need not happen with the rocke estimator , which has a non - monotonic weight function",
    ". maronna et al . ( 2006 , section 6.4.4 ) describe an algorithm which ensures attaining a local minimum .",
    "the ( approximate ) mve is computed with 1000 subsamples and using the improvement described in ( maronna et al . , 2006 ,",
    "section 6.7.3 ) .    since in all cases we attempt to minimize a non - convex function ,",
    "the initial estimator is an essential part of the procedure .",
    "the standard way to obtain a robust and equivariant starting point is subsampling .",
    "however , ensuring a high enough breakdown point with large @xmath0 may require an impractically large number of subsamples .",
    "besides , our experiments indicate that the breakdown point may be much lower than expected when @xmath111 is small  ( say , @xmath112 which is not uncommon with high - dimensional data sets . for these reasons",
    "we need a faster and more reliable starting point .",
    "pea and prieto ( 2007 ) proposed an equivariant and semi - deterministic procedure for outlier detection , based on finding directions that maximize or minimize the kurtosis of the respective projections , plus a set of random ",
    "specific directions  aimed at detecting outliers . here",
    "we employ this procedure ( which they call kurtosis plus specific directions , henceforth abbreviated as ksd ) as an estimator by itself . in the present",
    "setting it would not be competitive with the other estimators because its efficiency can not be tuned ( see table [ tabefikurto ] below ) , but we shall use it as an initial estimator competing with the sampling - based mve .",
    "there are no theoretical results on the breakdown point of ksd . however , the simulations in ( pea and prieto 2007 , table 4 ) suggest that it can yield reliable results even with 40% of outliers .",
    "a limited theoretical result is given in section [ secappend ] .",
    "given a starting point , the rocke estimator is computed iteratively as described in section 9.6.3 of ( maronna et al . , 2006 ) .",
    "the form of the weight function ensures that for normal data sets , most of the data have positive weights . since real data",
    "are seldom normal , it may happen that for data sets with large @xmath0 and low ratio @xmath111 the proportion of data with positive weights is small .",
    "if the data set is nearly collinear , this may cause @xmath113 to be ill - conditioned , which affects the computation of mahalanobis distances . for this reason ,",
    "if at the first iteration the number of data with positive weights is less than @xmath114 the tuning constant is enlarged until this number is @xmath115",
    "as a reference distribution we take the @xmath0-variate normal @xmath116 in order to measure the performance of a given estimator @xmath117 we need a measure of distance  between an estimator and the true value . recall that the kullback - leibler divergence between densities @xmath118 and @xmath119 is@xmath120    if both densities belong to the same parametric model with parameter vector @xmath121 :  @xmath122 then @xmath123 induces a distance  between parameters : @xmath124    in the normal family , for @xmath22 with known @xmath125 we have@xmath126    and for @xmath125 with known @xmath127 we have@xmath128    since all estimators are equivariant we may in the simulations take without loss of generality @xmath129 .",
    "each estimator is evaluated by @xmath130 monte carlo average of the kullback - leibler divergences @xmath131 given in ( [ dkl(mu)])-([dkl(sigma ) ] ) .",
    "we generate @xmath132 samples @xmath133}$ ] of size @xmath134 from @xmath135    the estimators compared are :    *  rocke with tuning constant @xmath136 see ( [ gama - alfa ] ) * mm with bisquare and optimal  @xmath137 with tuning constant @xmath71 ; see ( [ defmm ] ) * @xmath2 with bisquare and optimal  @xmath137 with tuning constant @xmath71 ; see([rho1 - 2 ] ) * stahel - donoho with weight function @xmath138 where @xmath139 is defined in ( [ optiweight ] )    for all estimators we employed both the mve and ksd estimators as starting values .",
    "the tuning constants were chosen to attain an efficiency of 0.9 ( see below ) .",
    "we add for completeness four other estimators with uncontrollable efficiency :    * the s - estimator ( s - e ) with @xmath140 in ( [ defmscale ] ) and biweight @xmath141 the optimal  @xmath44 yielded similar results .",
    "* the mve and ksd estimators . * the mcd with breakdown point ( [ bdp - s ] ) and one - step reweighting , computed with the code in the library libra ( verboven and hubert 2005 ) .",
    "all scatter estimators are corrected for size  by means of ( [ corretama ] ) , except for the mcd for which the code applies a consistency correction .",
    "call @xmath142 the sample covariance matrix . for each estimator",
    "@xmath113 we define@xmath143    the constants for each estimator are chosen to attain finite - sample efficiencies of 0.90 . to this end",
    "we computed for each estimator its tuning constants for @xmath144 with @xmath145 10 and 20 and @xmath0 between 5 and 50 , and then fitted the constants as functions of @xmath134 and @xmath0 .",
    "the simulation showed the efficiency can not be controlled in all cases , namely    * for @xmath146 the maximum efficiency of the rocke estimator is 0.876 for all @xmath61s , and is still lower for smaller @xmath0 .",
    "the explanation is that when @xmath61 tends to zero , the estimator does not tend to the covariance matrix unless @xmath0 is large enough .",
    "* the minimum efficiency of the @xmath2-estimators over all constants @xmath71 tends to one with increasing @xmath1 for both @xmath12functions . in particular , it is @xmath1470.95 for @xmath148 the reason is that when @xmath71 is small , the @xmath62scale approaches the m - scale , and therefore the @xmath62estimators approaches the s - estimator .",
    "table [ tabefikurto ] shows the efficiencies of the ksd estimator .",
    "[ c]llll@xmath0 & @xmath134 & scatter & location + & & & + & & & + & & & + & & & + & & & + & & & + & & & + & & & + & & & +    it seen that the efficiency depends heavily on the ratio @xmath111 and can be rather low for @xmath149      we deal first with shift contamination . for contamination rate @xmath150 let @xmath151.$ ] given @xmath152 we replace the first coordinate:@xmath153    the outlier size @xmath154 is varied between 1 and 12 in order to find the maximum @xmath155 the constant @xmath156 determines the scatter of the outliers .",
    "we employed the values @xmath157 and 0.2 , and @xmath158 and 0.5 .",
    "the simulations were run for @xmath159 5 ,  10 , 15 , 20 and 30 , and @xmath160 with @xmath161 10 and 20 .",
    "since the complete results are rather bulky , they are given in section [ sectablas ] .",
    "here we give the most important conclusions from them .",
    "examination of the tables shows that    * the price paid for the high efficiency of s - e is a large loss of robustness .",
    "* ksd is always better than mve as a starting estimator for mm and @xmath2 .",
    "* ksd is generally better than subsampling for s - d .",
    "* the optimal  @xmath44 is always better than the bisquare @xmath44 for both mm and @xmath2 * in all situations , the best estimators are mm and @xmath2 with optimal  @xmath137 rocke , and s - d , all starting from ksd . *",
    "although the results for @xmath158 and 0.5 are different , the comparisons among estimators are almost the same . *",
    "the relative performances of the estimators for location and scatter are similar . *",
    "the relative performances of the estimators for @xmath162 @xmath163 and @xmath164 are similar .    for these reasons",
    "we give in table [ tabresumen ] a reduced version of the results , for @xmath165 and @xmath166 and the maximum @xmath167s of the scatter estimators corresponding to mm and @xmath2 ( both with optimal  @xmath168 rocke and s - d , all starting from ksd . for completion",
    "we add s - e with ksd start , and the reweighted mcd .",
    "the results for estimators with efficiency less than 0.9 are shown in italics .",
    "[ c]cccccccc@xmath0 & @xmath169 & mm & @xmath2 & rocke & s - d & s - e & mcd + 5 & 0.1 & & & & & _ 1.09 _ & _ 1.99 _ + & 0.2 & & & & & _ 4.38 _ & _ 17.58 _ + & & & & & & _ 3.54 _ & _ 6.66 _ + & & & & & & _ 11.26 _ & _ 21.89 _ + & & & & & & _ 6.68 _ & _ 12.53 _ + & & & & & & _ 19.82 _ & _ 28.33 _ + & & & & & & _ 10.03 _ & _ 16.46 _ + & & & & & & _ 25.41 _ & _ 32.04 _ + & & & & & & _ 18.39 _ & _ 17.66 _ + & & & & & & _ 49.14 _ & _ 34.02 _ +    it is seen that    * the performance of s - d is competitive for @xmath170 but is poor for @xmath171 * for @xmath172 mm has the best overall performance . * for @xmath3 rocke has the best overall performance . *",
    "the mcd has a poor performance .",
    "figure [ figconta10_20_0 ] shows the values of @xmath167 as a function of the outlier size @xmath154 for some of the estimators in the case @xmath173 @xmath174 and @xmath175 here mm - opt  stands for mm with optimal @xmath44 .",
    "all estimators in the second panel start from ksd .",
    "[ tbh ]    conta_10_20_0.eps    the plot confirms the superiority of rocke+ksd .",
    "recently hubert et al , ( 2015 ) proposed two deterministic estimators , called dets and detmm , of which the latter has a tuneable efficiency .",
    "we compare it with rocke+sd .",
    "the nominal efficiency of detmm is chosen as 0.90 .",
    "the scenario is the same as above .",
    "however , since detmm is not equivariant , the model is now n@xmath176 where @xmath177 has unit diagonal elements and all non - diagonal elements equal to @xmath141 we chose the extreme cases @xmath178 and @xmath179 since both yield qualitatively similar results , we show in table [ tabsimudeter ] only the results from the first case .",
    "[ c]cccccccccc@xmath169 & @xmath156 & & & & + & & @xmath180 & 100 & 200 & 400 & & 100 & 200 & 400 + 0.1 & 0 & & & & & & & & + & & & & & & & & & + & 0.5 & rocke+ksd & & & & & & & + & & detmm & & & & & & & + 0.2 & 0 & rocke+ksd & & & & & & & + & & detmm & & & & & & & + & 0.5 & rocke+ksd & & & & & & & + & & detmm & & & & & & & +    the performance of detmm is clearly poor .",
    "we have not been able to find an explanation for this disappointing behavior .",
    "we compare the computing times of the rocke estimator with mve and ksd starts , and of detmm .",
    "the results are the average of 10 runs with normal samples , on a pc with intel tm12 duo cpu and 3.01 ghz .",
    "the values of @xmath134 were @xmath181 @xmath163 and @xmath182 with @xmath0 between 10 and 100 .",
    "the number of subsamples for the mve was made to increase slowly as @xmath183 table [ tabtiempos ] displays the results , where for brevity we show only the values for @xmath173 50 , 80 and 100 .",
    "[ c]ccccc@xmath0 & @xmath134 & rocke+mve & rocke+ksd & detmm + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & + & & & & +    it is seen that rocke+ksd is faster than detmm for @xmath184 and rocke+mve .",
    "however it is slower than detmm for @xmath185 this rapid increase in computing time is probably due to the optimization procedure employed by ksd , and may be improved upon by choosing a more efficient optimizer .",
    "we deal with the well - known wine data set , available at the uci machine learning repository : https://archive.ics.uci.edu/ml/datasets/wine , which has been employed as a benchmark data set for pattern recognition ; see e. g. ( aeberhard et al , 1994 ) , and consists of three classes with 13 variables .",
    "the estimators were applied to the data of class 3 , with @xmath186 and @xmath187 since ksd and mve yielded similar results as initial estimators , we show only the results corresponding to the former .",
    "figures [ figwine1 ] and [ figwine2 ] contain the qq - plots of the ( squared ) mahalanobis distances for the different estimators .",
    "[ tbh ]    figwine1.eps    [ tbh ]    figwine2.eps    rocke , mm  and detmm pinpoint respectively 8 , 6 and 5 possible outliers ; s - d seems to pinpoint an excessive number of possible outliers ; while s - e and @xmath2 behave like the classical estimator , showing no suspicious points",
    ". some subject - matter knowledge would be necessary to decide how atypical the suspicious points are .",
    "the rocke estimator has a controllable efficiency for @xmath188 with equal efficiencies , the rocke estimator with ksd start outperforms all its competitors for shift contamination its computing time is competitive for @xmath189 and can probably be improved upon . it can therefore be recommended for estimation with @xmath190 .    for @xmath191 we can recommend mm with optimal  @xmath44 and ksd start .",
    "tables [ tabsim05_10 ] to [ tabsim_3020 ] in this section contain the detailed results of the simulation . in each scenario , the smallest and next - to - smallest values",
    "are marked as bold and italic , respectively .",
    "this is done only for estimators with controllable efficiency ; in particular , rocke is not considered for @xmath172 for its efficiency in this case is less than 0.90 .",
    "one would expect the values for a given estimator to decrease when @xmath134 increases .",
    "however , in many cases this does not hold for the estimators based on the mve .",
    "we have re - run the simulations with a different seed , and also employed medians instead of means to rule out atypical cases , but this pattern appears nevertheless .",
    "we have not been able to find an explanation for this phenomenon .",
    "since it always affects the largest values , it does not influence the conclusions .",
    "[ c]cccccccccc@xmath156 & & start & & & + 0 & @xmath180 & & 25 & 50 & 100 & & 25 & 50 & 100 + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & +    [ c]rccccccccc@xmath156 & & start & & & + 0 & @xmath180 & & 25 & 50 & 100 & & 25 & 50 & 100 + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + 0.5 & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & + & & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + 0 & @xmath180 & & 50 & 100 & 200 & & 50 & 100 & 200 + & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . & mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 10.95 & 6.66 & 5.28 & & 1.87 & 1.20 & 0.94 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq & mve & & & & & & & + & mm - bisq .",
    "& ksd & & & & & & & + & mm - opt . &",
    "mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 5.43 & 2.70 & 1.72 & & 0.79 & 0.51 & 0.37 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + 0 & @xmath180 & & 50 & 100 & 200 & & 50 & 100 & 200 + & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . & mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . &",
    "mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & 12.20 & 10.07 & 9.08 & & 3.13 & 2.88 & 2.89 + & s - d & ksd & 34.59 & 7.94 & 7.09 & & 6.02 & 2.35 & 2.18 + & ksd & & & & & & & & + & mcd & & 26.45 & 21.89 & 17.84 & & 10.50 & 9.21 & 6.82 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq .",
    "& mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 22.33 & 18.35 & 15.85 & & 9.24 & 7.19 & 7.09 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 75 & 150 & 300 & & 75 & 150 & 300 + 0 & s - e & mve & 6.93 & 6.68 & 6.35 & & 1.03 & 1.17 & 1.22 + & s - e & ksd & 7.15 & 6.68 & 6.43 & & 0.99 & 1.16 & 1.21 + & mm - bisq . & mve & 5.47 & 5.65 & 5.65 & & 0.88 & 1.13 & 1.23 + & mm - bisq . &",
    "ksd & 5.19 & 5.17 & 5.15 & & 0.81 & 1.04 & 1.08 + & mm - opt . & mve & 3.83 & 2.92 & 2.55 & & 0.50 & 0.48 & 0.46 + & mm - opt . &",
    "ksd & *  3.33 * & 2.38 & 2.25 & & 0.46 & 0.38 & 0.41 + & @xmath2-bisq . & mve & 7.42 & 7.91 & 7.98 & & 1.20 & 1.56 & 1.68 + & @xmath2-bisq . &",
    "ksd & 7.93 & 7.85 & 7.73 & & 1.68 & 1.52 & 1.47 + & @xmath2-opt . & mve & 4.11 & 3.23 & 2.73 & & 0.55 & 0.59 & 0.48 + & @xmath2-opt . &",
    "ksd & 3.69 & 2.98 & 2.63 & & 0.51 & 0.49 & 0.48 + & rocke & mve & 3.80 & 2.58 & 2.04 & & _ 0.43 _ & _ 0.34 _ & 0.31 + & rocke & ksd & _ 3.67 _ & * 1.95 * & _ 1.44 _ & & * 0.36 * & * 0.27 * & * 0.23 * + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & 8.08 & 4.19 & 1.66 & & 0.69 & 0.53 & 0.31 + & mcd & & 13.71 & 12.53 & 10.51 & & 2.78 & 2.06 & 1.99 + & mve & & 8.44 & 5.09 & 3.19 & & 0.73 & 0.55 & 0.32 + 0.5 & s - e & mve & 7.83 & 6.38 & 5.73 & & 0.98 & 1.02 & 0.93 + & s - e & ksd & 6.59 & 5.68 & 5.26 & & 0.86 & 0.93 & 0.92 + & mm - bisq . &",
    "mve & 8.61 & 5.29 & 4.71 & & 1.09 & 0.89 & 0.9 + & mm - bisq . & ksd & 4.84 & 4.58 & 4.29 & & 0.71 & 0.81 & 0.8 + & mm - opt . &",
    "mve & 7.55 & 4.16 & 3.33 & & 0.91 & 0.62 & 0.55 + & mm - opt . & ksd & _ 3.55 _ & 2.79 & 2.48 & & 0.50 & 0.46 & 0.45 + & @xmath2-bisq . & mve & 8.37 & 6.36 & 6.23 & & 1.06 & 1.09 & 1.12 + & @xmath2-bisq . &",
    "ksd & 6.05 & 6.17 & 6.17 & & 0.87 & 1.05 & 1.11 + & @xmath2-opt . & mve & 7.36 & 4.08 & 3.28 & & 0.89 & 0.62 & 0.55 + & @xmath2-opt . &",
    "ksd & 3.87 & 2.93 & 2.56 & & 0.53 & 0.51 & 0.47 + & rocke & mve & 7.69 & 4.07 & 3.21 & & 0.92 & 0.60 & 0.52 + & rocke & ksd & 4.03 & _ 2.16 _ & _ 1.68 _ & & 0.47 & _ 0.35 _ & _ 0.31 _ + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & 7.32 & 2.66 & 1.66 & & 0.69 & 0.43 & 0.32 + & mcd & & 9.10 & 7.06 & 5.95 & & 1.30 & 1,19 & 0.99 + & mve & & 15.05 & 8.54 & 5.92 & & 1.53 & 1.09 & 0.86 +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 75 & 150 & 300 & & 75 & 150 & 300 + 0 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs . & 23.84 & 21.68 & 21.09 & & 6.90 & 6.68 & 6.99 + & s - d & ksd & 98.01 & 12.31 & 10.80 & & 12.54 & 3.97 & 3.74 + & ksd & & & & & & & & + & mcd & & 35.14 & 28.33 & 20.25 & & 13.28 & 10.30 & 8.06 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . & mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 30.80 & 22.85 & 17.43 & & 11.54 & 6.03 & 5.13 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 100 & 200 & 400 & & 100 & 200 & 400 + 0 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 23.11 & 16.46 & 12.85 & & 3.70 & 2.64 & 1.93 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . &",
    "mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 20.94 & 15.20 & 12.45 & & 3.41 & 2.42 & 1.86 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 100 & 200 & 400 & & 100 & 200 & 400 + 0 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & 34.50 & 32.90 & 31.81 & & 13.23 & 12.30 & 13.43 + & s - d & ksd & 92.02 & 17.09 & 15.55 & & 18.31 & 5.76 & 5.33 + & ksd & & & & & & & & + & mcd & & 39.35 & 32.04 & 25.62 & & 15.00 & 12.50 & 8.73 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . & mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & 17.34 & 13.67 & 12.44 & & & & + & ksd & & & & & & & & + & mcd & & 35.13 & 27.90 & 23.71 & & 13.99 & 10.24 & 7.70 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 150 & 300 & 600 & & 150 & 300 & 600 + 0 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq .",
    "& mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 22.47 & 17.66 & 12.42 & & 3.41 & 2.68 & 2.17 + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 19.46 & 16.35 & 12.34 & & 2.99 & 2.47 & 1.80 + & mve & & & & & & & & +    [ c]cccccccccc@xmath156 & & start & & & + & @xmath180 & & 150 & 300 & 600 & & 150 & 300 & 600 + 0 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . & mve & & & & & & & + & mm - bisq . &",
    "ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & & & & & & & + & mve & & & & & & & & + 0.5 & s - e & mve & & & & & & & + & s - e & ksd & & & & & & & + & mm - bisq . &",
    "mve & & & & & & & + & mm - bisq . & ksd & & & & & & & + & mm - opt . & mve & & & & & & & + & mm - opt . & ksd & & & & & & & + & @xmath2-bisq . & mve & & & & & & & + & @xmath2-bisq . & ksd & & & & & & & + & @xmath2-opt . & mve & & & & & & & + & @xmath2-opt . & ksd & & & & & & & + & rocke & mve & & & & & & & + & rocke & ksd & & & & & & & + & s - d & subs . & & & & & & & + & s - d & ksd & & & & & & & + & ksd & & & & & & & & + & mcd & & 42.37 & 29.51 & 22.62 & & 13.27 & 10.58 & 9.43 + & mve & & & & & & & & +              for the rocke estimator , the value of @xmath61 in ( [ gama - alfa ] ) which yields 90% efficiency is approximated for @xmath190 by @xmath198 with@xmath199{cccc}\\hline start & $ a$ & $ b$ & $ c$\\\\\\hline mve & 0.00436 & -0.5030 & 0.4214\\\\ ksd & 0.00216 & -1.0078 & 0.8156\\\\\\hline \\end{tabular } \\ \\ \\ ] ]          finally , for the stahel - donoho estimator the weight function is @xmath201 where the values of @xmath71 that yield 90% efficiency are given by @xmath202 with@xmath199{lccc}\\hline & $ a$ & $ b$ & $ c$\\\\\\hline \\multicolumn{1}{c}{subsampling } & \\multicolumn{1}{r}{5.116 } & 63.820 & \\multicolumn{1}{r}{2.213}\\\\ \\multicolumn{1}{c}{ksd } & \\multicolumn{1}{r}{6.564 } & 0.211 & \\multicolumn{1}{r}{24.286}\\\\\\hline \\end{tabular } \\ \\ \\ \\ ] ]        the ksd procedure is defined in the same way as the stahel - donoho estimator , but with a different set of directions .",
    "the population version is as follows .",
    "let @xmath204 be a random vector with distribution @xmath205 let @xmath206 be a set of directions @xmath207 with @xmath208",
    "let @xmath127 and @xmath209 be univariate robust location and scale estimators .",
    "the outlyingness of a point @xmath210 is defined as @xmath211 the location and scale estimators are defined as weighted means and covariance matrix with weights @xmath212 where @xmath213 is a nonincreasing function for @xmath214    for a sample , the estimator is defined as above with @xmath215 the empirical distribution . in the ( theoretical ) stahel - donoho estimator , @xmath216 is the set of all directions , and @xmath17 is a smooth function ; in actual practice , a finite set of directions obtained by subsampling is employed .",
    "the ksd procedure employs two sets of directions : @xmath217 .",
    "the first one is deterministic , and consists of a set of @xmath0 orthogonal directions maximizing the kurtosis of @xmath218 and @xmath219 directions minimizing it .",
    "the other is a set of random specific directions  obtained through a stratified sampling .",
    "we shall deal only with the first one .",
    "besides , @xmath17 is of hard rejection  type :  @xmath220 where @xmath59 depends on @xmath9    theoretical calculations with ksd seem extremely difficult , and for this reason we will limit ourselves to a very simplified case .",
    "we consider only the population case with point - mass contamination ; furthermore we assume that the uncontaminated data are elliptically distributed .",
    "it will be shown that if @xmath127 and @xmath209 have breakdown 0.5 , so has the ksd estimator .",
    "let @xmath221 be an elliptical distribution with fourth moments and consider the contaminated distribution @xmath222 with @xmath223 because of the estimator s equivariance it may be assumed that @xmath221 is radial , with zero means and identity covariance matrix , and that @xmath224 where @xmath225 are the elements of the canonical base and @xmath226 . put @xmath227 where @xmath228 is the first coordinate of @xmath229 the rotational symmetry implies that @xmath230 for all @xmath231 with @xmath208    we will show that the direction of the contamination , i.e. , @xmath232 is always included in the set .",
    "it is straightforward to show that the kurtosis of a projection @xmath218 under @xmath215 is @xmath233 where @xmath234 and@xmath235    it follows that @xmath236 depends on @xmath207 only through @xmath237.$ ] a laborious but straightforward calculation shows that the derivative of @xmath238 has the form @xmath239 where @xmath240 does not depend on @xmath152 and @xmath241    the location of the extrema depends only on the sign of @xmath242 although the result holds in general , to simplify the analysis we consider only the case @xmath243 . and we assume @xmath244 there are two cases . if @xmath245 then @xmath246 for @xmath247,$ ] and therefore @xmath248 is a minimizer of @xmath249 if @xmath250 there are maxima at @xmath251 and @xmath252 and therefore the set of maximizing directions contains @xmath253 and a set of orthogonal @xmath207 s which are orthogonal to @xmath253    it follows that @xmath254 note that @xmath255 and @xmath256 depend on @xmath152 but since @xmath257 they are bounded .",
    "therefore for @xmath154 large enough , @xmath258 will be larger than the cutoff value @xmath59 and will therefore have null weight .",
    "this finishes the proof .",
    "agostinelli , c. leung , a. , yohai , v.j . and zamar , r.h .. robust estimation of multivariate location and scatter in the presence of cellwise and casewise contamination",
    "doi 10.1007/s11749 - 015 - 0453 - 3 ( 2015 ) .",
    "rousseeuw p.j .",
    "multivariate estimation with high breakdown point . in : grossmann w. , pflug g. , vincze i. , and wertz w. ( eds . ) , mathematical statistics and applications , vol",
    "b , 283297 .",
    "reidel , dordrecht ( 1985 ) ."
  ],
  "abstract_text": [
    "<S> we deal with the equivariant estimation of scatter and location for @xmath0-dimensional data , giving emphasis to scatter . </S>",
    "<S> it is important that the estimators possess both a high efficiency for normal data and a high resistance to outliers , that is , a low bias under contamination . </S>",
    "<S> the most frequently employed estimators are not quite satisfactory in this respect . </S>",
    "<S> the minimum volume ellipsoid ( mve ) and minimum covariance determinant ( mcd ) estimators are known to have a very low efficiency . </S>",
    "<S> s - estimators with a monotonic weight function like the bisquare have a low efficiency for small @xmath1 and their efficiency tends to one with increasing @xmath0 . </S>",
    "<S> unfortunately , this advantage is paid for by a serious loss of robustness for large @xmath0 .    </S>",
    "<S> we consider four families of estimators with controllable efficiencies whose performance for moderate to large @xmath0 has not been explored to date : s - estimators with a non - monotonic weight function ( rocke 1996 ) , mm - estimators , @xmath2-estimators , and the stahel - donoho estimator . </S>",
    "<S> two types of starting estimators are employed : the mve computed through subsampling , and a semi - deterministic procedure proposed by pea and prieto ( 2007 ) for outlier detection .    </S>",
    "<S> a simulation study shows that the rocke estimator starting from the pea - prieto estimator and with an adequate tuning , can simultaneously attain high efficiency and high robustness for @xmath3 and the mm estimator can be recommended for @xmath0@xmath415 .    </S>",
    "<S> keywords : mm - estimator , tau - estimator , s - estimator , stahel - donoho estimator , kullback - leibler divergence . </S>"
  ]
}