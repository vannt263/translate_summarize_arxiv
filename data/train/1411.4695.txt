{
  "article_text": [
    "many real - world control problems can be classified as switching problems in the sense that the system subject to control is comprised of several different modes ( sometimes called subsystems ) and at each instant only one of the modes can be active .",
    "a basic example of such a system is a plant equipped with on - off actuators @xcite .",
    "the solution to such problems includes a _ switching schedule _ which determines the number of switching , the switching instants , and the order of the active subsystems .",
    "the developments in the field of optimal switching can be divided into different categories , two of which are nonlinear programming based methods and discretization based methods .",
    "nonlinear programming based methods utilize the gradient of the cost with respect to the switching instants to calculate local optimal switching times using nonlinear programming @xcite-@xcite . in these methods , the sequence of active subsystems , known as the _ mode sequence _ , is typically selected a priori . the problem",
    "is then simplified to determining the switching instants between the modes .",
    "discretization based methods , however , discretize the state and input space to end up with a finite number of choices @xcite . among the intelligent approaches to the problem ,",
    "genetic algorithm and neural networks were used in refs . @xcite and @xcite , respectively , to determine the optimal switching for one set of initial conditions .",
    "all the cited methods work only with a specific initial condition ; each time the initial condition is changed , a new set of computations needs to be performed to find the new optimal switching instants . in order to extend the validity of the results for different initial conditions within a pre - selected set , in @xcite",
    "a solution was found as the local optimum in the sense that it minimizes the worst possible cost for all trajectories starting in the selected initial states set .",
    "another drawback of majority of the methods , especially the nonlinear programming based methods , is the fact that they lead to an open loop solution .    on the other hand , approximate dynamic programming ( adp )",
    "has shown great potentials in solving conventional optimal control problems with infinite - horizon cost functions @xcite-@xcite and also with finite - horizon cost functions @xcite-@xcite .",
    "the backbone of the adp based methods is using bellman equation @xcite and approximating the mapping between the states of the system and the optimal control .",
    "these potentials motivated the author of this study to investigate the application of adp to _ switching _ problems in his phd research .",
    "this was done through developing solutions to problems with _ fixed mode sequence _ and _ fixed number of switching _",
    "@xcite , @xcite , problems with _ free mode sequence _ and _ controlled subsystems _",
    "@xcite , and also problems with _ free mode sequence _ and _ autonomous subsystems _",
    "the interesting feature of these developments is the fact that they provide approximate optimal solution for a vast domain of initial conditions .",
    "another advantage of these methods is their feedback nature .",
    "these developments , however , do not provide the designer with the ability of influencing , e.g. , decreasing the number of switching . for example , in the extreme case , the solutions proposed in @xcite and @xcite can lead to one switching at every single sampling time .",
    "such a switching frequency is impracticable in many applications .",
    "different tricks , however , are proposed in @xcite and @xcite for manipulating the switching frequency .",
    "these remedies lead to deviation of the solution from optimality and can potentially destabilize the system .",
    "moreover , these developments assume a cost function which is independent of the active mode , hence , the designer can not assign different costs ( or preferences ) to different modes .    in an independent study in utilizing adp for solving optimal switching problems",
    ", the authors of @xcite proposed a method for solving switching problems with finite - horizon cost functions .",
    "the proposed method , however , inherits the curse of dimensionality from dynamic programming , in the sense that , at each iteration of the learning process as many cost - to - go functions as the number of subsystems raised to the power of the iteration number should be learned .",
    "for example , for a three mode system , at 100th iteration , the number of functions subject to learning is @xmath0 .",
    "moreover , the proposed training algorithm is based on a selected initial state .",
    "another investigation for solving switching problems using adp was recently reported in @xcite with a different approach .",
    "however , initial conditions are assumed to be known a priori and the result does not admit penalizing each switching .",
    "these two points differentiate the work from this study .",
    "an idea for influencing ( decreasing ) the number of switching is incorporating a _ switching cost _ term in the cost function , for the purpose of penalizing each switching between the modes , @xcite .",
    "moreover , utilizing a cost function with mode dependent terms , i.e. , having a _ switching cost function _",
    ", leads to the desired feature of assigning different costs to different modes .",
    "these modifications , however , lead to a very important change in the characteristics and the nature of the solution .",
    "it is shown in this study that in case of penalizing each switching , the optimal cost - to - go becomes a function of the subsystem which was active at the _ previous _ time step , i.e. , the _ already _ active subsystem .",
    "consequently , the methods reported in @xcite-@xcite fail to provide solutions to problems with such cost functions .",
    "based on the developments in @xcite-@xcite , this study is aimed at developing a new switching method which admits the switching cost term and the switching cost function .",
    "this is the main contribution of this paper and is carried out through a new switching law , a new neural network ( nn ) structure as the function approximator , and a new parameter / weight update algorithm .",
    "afterwards , the continuity of the function subject to approximation is analyzed and certain changes in the selected nn form is proposed for satisfying the necessary condition for uniform approximation of the desired function . finally , the performance of the method is analyzed numerically in different examples .",
    "the closest study in the literature to the problem subject to this paper is @xcite .",
    "the differences are a ) a maximum number of switching needs to be assumed , b ) the state space needs to be discretized , and c ) the solution needs to be calculated numerically in @xcite . in this study , however , the number of switching is free , to be obtained such that the cost function is minimized , the state vector can change continuously , and the ( approximate ) solution is calculated in a closed form .",
    "the rest of this paper is organized as follows .",
    "the problem if formally presented in section ii and the proposed solution is detailed in section iii .",
    "section iv discusses the online implementation of the proposed method and section v includes the numerical analyses and simulations .",
    "finally , the conclusions are given in section vi .",
    "the dynamics of the @xmath1 autonomous modes / subsystems of a switching system can be modeled using @xmath2 where @xmath3 , @xmath4 , and positive integer @xmath5 is the dimension of the state vector @xmath6 .",
    "sub - index @xmath7 in @xmath6 represents the discrete time index and sub - index @xmath8 in @xmath9 represents the respective mode / subsystem . denoting the active mode at instant @xmath7 with @xmath10 , a _ switching schedule",
    "_ identifies @xmath11 .",
    "once a switching schedule is selected , the system can operate from the initial time @xmath12 to the fixed final time @xmath13 .",
    "the problem is defined as finding a switching schedule that minimizes the cost function given by @xmath14 cost function ( [ costfunction ] ) is composed of three type of terms .",
    "a ) piecewise convex function @xmath15 penalizes the error between the desired state value and the actual state value at the final time and is dependent on the active mode or configuration with which the operation of the system finishes , i.e. , @xmath16 .",
    "b ) piecewise convex function @xmath17 assigns different costs to the state error ( the difference between the actual value and the desired value for the state vector ) during the horizon and is dependent on the active mode during the horizon .",
    "c ) piecewise constant function @xmath18 represents the switching cost .",
    "each switching from mode @xmath19 to @xmath10 at time @xmath7 leads to the cost represented by @xmath20 , @xcite .",
    "therefore , @xmath21 . for notational consistency in ( [ costfunction ] ) , the already active mode before the start of the process , i.e. , before @xmath12 , is denoted with @xmath22 .",
    "[ rem1 ] functions @xmath23 and @xmath24 are assumed to be convex , @xmath25 .",
    "moreover , no assumption on the signs of the outputs of @xmath26 and @xmath27 , e.g. , being positive semi - definite , is made and the theory developed in this study admits negative costs , i.e. , rewards , as well .",
    "the method proposed in this study for solving the problem is based on approximating the _ optimal cost - to - go _ ,",
    "i.e. , the total cost from the current time to the final time , assuming the optimal decisions are made in selecting the modes for operating the system during the horizon .",
    "the optimal cost - to - go is sometimes called _ value function _ by some researchers .",
    "it is straightforward to see that the optimal cost - to - go is a function of the current state , i.e. , @xmath6 .",
    "since the final time is fixed , the cost - to - go will depend on the current time as well .",
    "in other words , having the same current state , but a different _ time - to - go _ , i.e. , different @xmath28 , may lead to a different cost - to - go @xcite , @xcite . note that , the dependency on @xmath28 is equivalent of dependency on @xmath7 , because , @xmath29 is fixed and known .",
    "an important observation for developing a solution to the problem defined in section [ problemformulation ] is the fact that the optimal cost - to - go also depends on the _ previous active subsystem _",
    ", i.e. , the subsystem which was active at the previous time , in problems with switching costs . the previous active subsystem , @xmath19 , is ` already ' active , hence , utilizing it at the current time step does not cause a switching cost , because @xmath30 . to see this dependency one may consider the difference between the following two example scenarios in controlling a switching system : a ) the previous active subsystem is the same as the subsystem that the controller wants to activate at the current time , and b ) having the same time @xmath7 and current state @xmath6 as in case a , the previous active subsystem is different than the one the controller wants to activate at the current time . comparing these two scenarios",
    "it is seen that the optimal cost - to - go will be different due to the required switching in scenario b and the respective incurred switching cost .",
    "hence , the solution and the optimal cost - to - go at each instant are dependent on the previous active subsystem , as well as on the current time and state . considering these dependencies",
    ", one may denoted the optimal cost - to - go with @xmath31 .",
    "note that the sub - index @xmath7 in @xmath32 corresponds to the time dependency of the optimal cost - to - go .    considering this concept ,",
    "it is seen that the initial condition on the active mode , that is the active mode / configuration right before the start of the operation , plays a role in the selection of @xmath33 , when a switching cost is incorporated . in other words , depending on what the already active mode / configuration before the start of the process is , i.e. , @xmath22 , the system may select a different @xmath33 . therefore ,",
    "as expected , the summation included in cost function ( [ costfunction ] ) contains @xmath22 .",
    "another way of looking at the dependency of the cost - to - go on the already active subsystem , is considering the active subsystem / mode as a _ state _ of the system . in this case",
    ", a new state vector @xmath34^t $ ] may be defined to represent the _ overall _ state of the system .",
    "this approach is also compatible with the physical way of looking at the modes as different _ configurations _ of the system .",
    "the active configuration , e.g. , the position of the gear stick in a manual transmission car , is a physical state of the system .",
    "[ rem_alreadyactivemode ] the ` already ' active mode should be differentiated from the ` current ' active mode at time @xmath7 .",
    "the former is the mode which was utilized at the ` previous ' time step and is denoted with @xmath19 , but , the latter is the mode which is going to be selected at the current time step to operate the system from @xmath7 to @xmath35 and is denoted with @xmath36 . following this terminology , the cost - to - go depends on the ` previous ' ( or the already active ) subsystem , not on the ` current ' subsystem .      the selected cost function , eq .",
    "( [ costfunction ] ) , leads to @xmath37 and @xmath38 where the _ optimal _ active mode at each instant @xmath39 is denoted with @xmath40 and the resulting optimal future states , calculated from ( [ dynamics ] ) , are denoted with @xmath41 .",
    "( [ costtogoformula ] ) can be formed as a recursive equation as @xmath42 where @xmath43 . by the bellman principle of optimality @xcite , one has @xmath44 moreover , the optimal mode @xmath45 , which is also a function of @xmath7 , @xmath6 , and @xmath19 , is given by @xmath46 in other words , @xmath45 is selected considering the following concerns :    * selecting @xmath45 leads to incurring the running cost of @xmath47 . *",
    "selecting @xmath45 leads to the next state vector being @xmath48 . *",
    "selecting @xmath45 leads to the fact that at the next step , the already active subsystem will be @xmath45 . *",
    "selecting @xmath45 may lead to some switching cost due to @xmath45 not being the same as the already active subsystem , which is @xmath19 .    the first concern in addressed through the inclusion of @xmath49 in the minimization of eq .",
    "( [ optimal_i_k ] ) .",
    "the second and third concerns are addressed through minimizing @xmath50 in the right hand side of eq .",
    "( [ optimal_i_k ] ) with respect to its both @xmath8s .",
    "the fourth concern , however , is addressed through the term @xmath51 subject to minimization in ( [ optimal_i_k ] ) .",
    "the existence of this term in eq .",
    "( [ optimal_i_k ] ) confirms the fact that the selection of each mode depends on the active mode at the previous step , as expected .",
    "the key to the solution of the problem is the fact that if the optimal cost - to - go function @xmath52 is calculated in a closed form for all @xmath53 then one can find the optimal @xmath45 in a _",
    "form in online operation , as seen in ( [ optimal_i_k ] ) .",
    "motivated by the development in the adp literature for conventional @xcite-@xcite and switching @xcite-@xcite problems , it is proposed to use a neural network ( nn ) as a function approximator for approximating the optimal cost - to - go function . selecting a linear - in - parameter nn ,",
    "the function is approximated within a compact set @xmath54 ( representing the domain of interest ) using @xmath55 where the selected smooth basis functions are given by @xmath56 , with @xmath57 being a positive integer denoting the number of neurons .",
    "unknown matrix @xmath58 , to be found using learning algorithms , is the _ weight _ matrix of the network at time step @xmath7 .",
    "note that the time - dependency of the optimal cost - to - go function is incorporated using a nn with time - dependent weights .",
    "moreover , the inputs to the basis functions correspond to the other dependencies of the function subject to approximation .    before proceeding to the training algorithm",
    ", there is a concern with the selected nn structure ( [ nn_structure1 ] ) that needs to be resolved .",
    "it should be noted that nns with continuous neurons are suitable for approximation of continuous functions @xcite , @xcite .",
    "otherwise , the approximation is not guaranteed to be uniform .",
    "looking at ( [ hjb2 ] ) , function @xmath59 may not be a continuous function versus @xmath19 .",
    "as a matter of fact , since @xmath19 belongs to a set of discrete integers , i.e. , @xmath60 , it will not change continuously , therefore , the cost - to - go function also does not continuously change versus @xmath19 , unless the system is comprised of only one mode .",
    "hence , the selected network structure given in ( [ nn_structure1 ] ) , with continuous basis functions @xmath61 is not desired and a new structure should be used for implementation of the proposed solution . to remedy the problem ,",
    "an innovative idea is proposed here , that is , using nns with @xmath19 dependent weights for incorporation of @xmath19-dependency of the function subject to approximation .",
    "let a new nn structure given by @xmath62 be used , where @xmath63 is the selected set of basis functions and @xmath64 , is the unknown weight matrix . using the form given by ( [ nn_structure2 ] )",
    ", the number of weights required to be trained will be multiplied by the number of subsystems , as compared to the case of using the nn form given by ( [ nn_structure1 ] ) .",
    "following this idea , it needs to be proved that each @xmath59 for every given @xmath19 and @xmath7 is a continuous function of @xmath6 . since",
    ", each one of such functions is being approximated using a different set of weights , denoted with @xmath65 , it can be looked at as if each function @xmath66 for every given @xmath7 and @xmath19 is being approximated using a separate nn denoted with @xmath67 .",
    "therefore , the proof of continuity versus @xmath6 suffices for having the desired uniform approximation capability for the nn structure given in ( [ nn_structure2 ] ) .",
    "theorem 1 proves the required continuity .",
    "while the main idea of the proof is adapted from @xcite , many changes are carried out to adapt the result for the cost - to - go function subject to the current study and to make the proof more rigorous .",
    "the optimal cost - to - go or value function for the problem of minimizing cost function ( [ costfunction ] ) with respect to dynamics ( [ dynamics ] ) is a continuous function of states in every compact set @xmath68 , if functions @xmath69 and @xmath70 are continuous .    _ proof _ : function @xmath71 is continuous by eq .",
    "( [ hjb1 ] ) and the continuity of @xmath72 .",
    "assuming continuity of @xmath73 , if it can be shown that function @xmath74 for all @xmath8s will be continuous , the proof is complete , by mathematical induction .",
    "let the scalar function @xmath75 be defined as @xmath76 and the piecewise constant function @xmath77 be given by @xmath78 it can be seen that function @xmath79 is identical to @xmath80 considering ( [ hjb2 ] ) , ( [ theorem1_eq1 ] ) , and ( [ theorem1_eq2 ] ) . therefore , continuity of @xmath81 for all @xmath39s completes the proof .",
    "let @xmath82 be any selected point in @xmath68 , for any given @xmath83 set @xmath84 select an open set @xmath85 such that @xmath82 belongs to the boundary of @xmath86 and limit @xmath87 exists , where @xmath88 denotes a vector norm .",
    "if @xmath89 , for every such @xmath86 , then there exists some open set @xmath90 containing @xmath82 such that @xmath91 is constant for all @xmath92 , because @xmath91 only assumes integer values . in this case",
    "the continuity of @xmath79 at @xmath93 follows from the fact that @xmath94 is continuous at @xmath93 , for every fixed @xmath95 , by composition .",
    "the reason is @xmath24 , @xmath96 , and @xmath97 are continuous functions and @xmath98 is a constant . finally , the continuity of the function subject to investigation at every @xmath99 , leads to the continuity of the function in @xmath68",
    ".    now assume @xmath100 , for some @xmath86 . from the continuity of @xmath101 for the given @xmath102 ,",
    "one has @xmath103 if it can be shown that , for every selected @xmath86 , one has @xmath104 then the continuity of @xmath105 versus @xmath106 follows , because from ( [ the1_eq4 ] ) and ( [ the1_eq5 ] ) one has @xmath107 and ( [ the1_eq6 ] ) leads to the continuity by definition @xcite . the proof that ( [ the1_eq5 ] ) holds is done by contradiction .",
    "assume that for some @xmath82 and some @xmath86 one has @xmath108 then , due to the continuity of both sides of ( [ the1_eq7 ] ) at @xmath82 for the fixed @xmath109 and @xmath102 , there exists an open set @xmath110 containing @xmath82 , such that @xmath111 inequality ( [ the1_eq8 ] ) implies that at points which are _ close enough _ to @xmath82 , one has @xmath112 .",
    "but , this contradicts eq .",
    "( [ the1_eq2 ] ) which implies that there always exists a point @xmath106 _ arbitrarily close _ to @xmath82 at which @xmath113 .",
    "therefore , equality ( [ the1_eq8 ] ) can not hold .",
    "now , assume that @xmath114 inequality ( [ the1_eq9 ] ) leads to @xmath115 .",
    "but , this is against ( [ the1_eq1 ] ) , hence , ( [ the1_eq9 ] ) also can not hold .",
    "therefore , ( [ the1_eq5 ] ) holds and hence , @xmath105 is continuous at every @xmath116 for every fixed @xmath83 .",
    "this completes the proof .",
    "selecting the nn structure , the next step is developing an algorithm for finding the unknown weights . using eqs .",
    "( [ hjb1 ] ) and ( [ hjb3 ] ) the training algorithm can be derived in a _",
    "backward _ fashion . considering ( [ hjb1 ] ) , unknown @xmath117 can be obtained , for example using least squares method , as shown in @xcite .",
    "once @xmath117 is found , eq .",
    "( [ hjb3 ] ) can be used for calculating @xmath118 . repeating this process",
    ", all the weights can be found from @xmath119 to @xmath12 .",
    "the training can be done either in a _",
    "form or in a _ sequential _ form .",
    "algorithm 1 details the batch training and algorithm 2 presents the training in the sequential form .",
    "* algorithm 1 - batch training *    step 1 : randomly select @xmath120 different state vectors @xmath121 } \\in \\omega , q \\in",
    ".. ,p\\right\\}$ ] , for @xmath120 being a large positive integer , where @xmath54 represents the domain of interest .",
    "step 2 : for @xmath122 to @xmath1 repeat step 3 .",
    "step 3 : find @xmath123 such that @xmath124 } ) \\approx \\psi(x^{[q]},j ) , \\forall q",
    "\\in \\left\\{1,2, .. ,p\\right\\}. \\label{alg1_eq1}\\ ] ]    step 4 : set @xmath125 .",
    "step 5 : for @xmath122 to @xmath1 repeat step 6 .",
    "step 6 : find @xmath126 such that @xmath127 } ) \\approx min_{i \\in \\mathcal{i } }   \\big ( q(x^{[q]},i ) + \\kappa(j , i ) + \\\\          { w_{k+1}^i}^t \\phi\\big(f_i(x^{[q]})\\big)\\big ) , \\forall q\\in \\left\\{1,2, ..",
    ",p\\right\\}. \\label{alg1_eq2 }      \\end{split}\\ ] ]    step 7 : set @xmath128 .",
    "go back to step 5 until @xmath12 .",
    "* algorithm 2 - sequential training *    step 1 : for @xmath122 to @xmath1 repeat step 2 .",
    "step 2 : select an initial guess on @xmath129 and repeat steps 3 and 4 until @xmath129 converges .",
    "step 3 : randomly select state vector @xmath116 , where @xmath54 represents the domain of interest .",
    "step 4 : train weight @xmath123 of neural network @xmath130 using input - target pair @xmath131 .",
    "step 5 : set @xmath125 .",
    "step 6 : for @xmath122 to @xmath1 repeat step 7 .",
    "step 7 : select an initial guess on @xmath132 and repeat steps 8 and 9 until @xmath132 converges .",
    "step 8 : randomly select state vector @xmath116 .",
    "step 9 : train @xmath126 using input - target pair @xmath133 .",
    "step 10 : set @xmath128 .",
    "go back to step 6 until @xmath12 .",
    "[ rem3 ] in order to have an idea of the computational load of the proposed method , one may consider the batch training form , algorithm 1 .",
    "the backward - in - time form of the algorithm resembles the solution to the conventional optimal control problem of discrete - time linear systems with quadratic cost functions , where , the riccati ( difference ) equation needs to be evaluated for @xmath29 time steps to find and store the time - varying solution , for all @xmath53 , @xcite .",
    "( [ alg1_eq1 ] ) resembles the final condition on the solution and eq .",
    "( [ alg1_eq2 ] ) resembles the riccati difference equation which takes the solution corresponding to @xmath134 and provides the solution for time @xmath7 .",
    "due to the nonlinearity and the hybrid nature of the problem subject to this study , a function approximator needs to be utilized and several sample state vectors need to be selected at each evaluation of eq .",
    "( [ alg1_eq2 ] ) , for example , to find the unknown parameters .",
    "however , it can be seen that the computational load of the algorithm grows _ linearly _ as the number of time steps increases .",
    "finally , before concluding this section , it should be noted that the selection of _ linear - in - parameter _ form for the nn , as done in ( [ nn_structure1 ] ) and ( [ nn_structure2 ] ) , is not required for the theory developed in this study to be valid .",
    "one can utilize _ multi - layer perceptrons _",
    ", with @xmath7 and @xmath19 dependent weights , for improving the approximation capability of the nn . in this case , for example ( [ nn_structure2 ] ) changes to @xmath135 where function @xmath136 denotes the nn mapping , with the first argument being the tunable weights of the nn and the second argument being its input .",
    "once the nn is trained , it can be used for online control of the switching system .",
    "the process involves feeding the current state @xmath6 and the already active subsystem @xmath19 to equation @xmath137 to find @xmath138 .",
    "note that , the minimization proposed in ( [ onlinescheduling ] ) is composed of comparing @xmath1 scalar values and selecting the @xmath95 corresponding to the least value . hence , the online _ global _ minimum can be easily found .",
    "the advantages of this method are numerous .",
    "firstly , the method provides a _ feedback _ solution , hence , it will be relatively robust toward uncertainties and disturbances .",
    "secondly , no restriction is enforced on the order of the active subsystems or on the number of switching .",
    "thirdly , unlike the nonlinear programming based methods @xcite-@xcite which give a local optimum , this method leads to an approximation of the global optimal solution .",
    "note that this feature holds if the training of the nn , itself , is not stuck in a local minimum , which with the selection of linear - in - parameter nn and using convex methods like least squares , the condition is fulfilled .",
    "fourthly , an important feature of this method is providing optimal switching for any initial condition @xmath139 as long as the resulting state trajectory lies in the domain on which the network is trained , i.e. , @xmath140 .",
    "the reason is the cost - to - go approximation is valid when the state belongs to @xmath68 .",
    "finally , the method provides a great deal of flexibility for implementation of different desired switching behaviors through admitting a general cost function with switching terms .",
    "two examples are selected for numerical investigation of the features of the proposed scheme .",
    "the source codes , in matlab , are available upon request .      as the first example , a scalar problem with two modes , given below , is selected , @xmath141 with the horizon of @xmath142 .",
    "for discretization of the continuous - time system , euler forward integration , with a sampling time of @xmath143 is selected which leads to @xmath144 .",
    "the selected cost function is @xmath145 where @xmath146 therefore , while the objective is bringing the state to close to zero , a cost of @xmath147 is assumed for each switching .",
    "hence , the controller should make a tradeoff between the cost due to the error in the state at the final time , and the cost due to switching .",
    "considering the subsystems dynamics , both are stable . comparing the derivatives of the state , however , subsystem 1 has a faster convergence rate when @xmath148 .",
    "but , when @xmath149 , subsystem 2 leads to a faster convergence of the state to the origin . therefore , assuming there was no switching cost , the optimal solution would have been    @xmath150    in comparing the neurocontroller results with eq .",
    "( [ ex1_optimalsol ] ) , it should be noted that eq .",
    "( [ ex1_optimalsol ] ) is , loosely speaking , a `` pointwise '' optimal active mode , in the sense that it does not account for the cost of switching .",
    "the basis functions were selected as polynomials @xmath151 , where @xmath152 .",
    "the accuracy of the approximation capability of the nn can be adjusted by the selection of the order of the polynomials .",
    "the training was done over the domain of @xmath153 $ ] in a sequential form and the weight were observed to converge in 1000 iterations .",
    "the resulting weight histories for the nn are plotted in fig .",
    "as expected , the weights are observed to be time - dependent , which represents the time - dependency of the cost - to - go .",
    "after training the neurocontroller , initial condition @xmath154 was simulated using the developed method , for both cases of @xmath155 and @xmath156 , i.e. , the initial active mode being either subsystem 2 or subsystem 1 .",
    "the results are given in fig .",
    "[ fig1 ] . considering the case of @xmath155 , the utilized mode in the initial 18 time steps is _ optimal _ based on eq .",
    "( [ ex1_optimalsol ] ) .",
    "moreover , once the state becomes less than 1 , if switching to mode 1 is eventually needed , i.e. , the switching cost is unavoidable , then the switching should happen immediately based on eq .",
    "( [ ex1_optimalsol ] ) , as done in fig .",
    "[ fig1].a .",
    "comparing the cost - to - go 0.187 corresponding to fig .",
    "[ fig1].a with the cost - to - go of staying with mode 2 without any switching , which turned out to be 1.15 , it is seen that the switching was required and the controller has provided optimal solution to the problem .",
    "such an argument can be made for @xmath156 as well to analyze its optimality .",
    "the cost - to - go of the schedule given in fig .",
    "[ fig1].b turned out to be 0.197 which is less than the cost - to - go of operating mode 1 for the entire time ( that is 0.297 ) .",
    "therefore , both switching , conducted in fig .",
    "[ fig1].b , were needed . comparing the switching times with eq .",
    "( [ ex1_optimalsol ] ) , the result given in fig .",
    "[ fig1].b is also optimal .",
    "note that the controller is able to provide optimal control for a vast number of initial conditions as long as the resulting state trajectory lies within @xmath68 . from the dynamics of the subsystems",
    "it can be seen that selecting any @xmath139 leads to @xmath157 .",
    "therefore , the trained network can optimally control any initial condition @xmath139 .",
    "the initial condition @xmath158 was selected next .",
    "the results are presented in fig .",
    "[ fig2 ] . while fig .",
    "[ fig2].a and comparing its cost - to - go , 0.146 , with the cost - to - go of no switching at all , 1.084 , show that the controller has optimally switched between the modes per eq .",
    "( [ ex1_optimalsol ] ) , an interesting observation can be made from fig .",
    "[ fig2].b .",
    "as seen in this figure , once the initial active mode is not `` pointwise '' optimal , but , the initial condition is not large enough such that switching to the pointwise optimal mode leads to an enough _ reward _ to cover the cost of switching , the controller stays with the initial mode and skips the switching .",
    "this can be confirmed by comparing the cost - to - go of the case of switching from mode 1 to mode 2 at the very beginning and switching back to mode 1 right when @xmath106 becomes smaller than 1 , which turned out to be 0.156 , with the cost of staying with mode 1 for the entire time , that is 0.155 . since the cost - to - go of the former case is more than that of the latter case , no switching was needed and the controller has optimally controlled the new initial condition .",
    "a very important feature of the solution is the fact that this method does not _ postpone _ switching instants , as the remedy proposed in @xcite does .",
    "if a switching is eventually needed , then it should happen at the _",
    "best _ time without spending time with operating the non - optimal mode .",
    "for example , in figs .",
    "[ fig1].a and [ fig2].a , where the initial active mode is 2 and a switching is eventually needed , the switching has happened right at the best time , i.e. , the time that the state became less than 1 .    finally , the initial condition @xmath159 is simulated for both the two initial active modes , and the results are depicted in fig . [ fig3 ] . considering the history of the active modes ,",
    "the neurocontroller has optimally controlled the system through either not switching at all , or switching immediately , considering the state histories .",
    "cc .,title=\"fig : \" ] +   + .,title=\"fig : \" ] +   +    cc .,title=\"fig : \" ] +   + .,title=\"fig : \" ] +   +    cc .,title=\"fig : \" ] +   + .,title=\"fig : \" ] +   +      a nonlinear second order system with three modes , simulated in @xcite and @xcite , is selected as the second example .",
    "the objective of this problem is controlling the fluid level in a two - tank setup .",
    "the fluid flow into the upper tank can be adjusted through a valve which has three positions : fully open , half open , and fully closed .",
    "each tank leaks fluid with a rate proportional to the square root of the height of the fluid in the respective tank . the upper tank leaks into the lower tank , and the lower tank leaks to the outside of the setup .",
    "representing the fluid height in the upper tank with scalar @xmath160 and in the lower tank with scalar @xmath161 , the dynamics of the state vector @xmath162^t$ ] are given by the following three modes , corresponding to the three positions of the valve , @xmath163 , \\\\",
    "\\mbox { }          \\dot{x}=f_2(x ) : = \\left [           \\begin{array}{l }              -\\sqrt{y}+0.5\\\\              \\sqrt{y}-\\sqrt{z}\\\\          \\end{array }          \\right ] , \\\\",
    "\\mbox { }          \\dot{x}=f_3(x ) : = \\left [           \\begin{array}{l }              -\\sqrt{y}+1\\\\              \\sqrt{y}-\\sqrt{z}\\\\          \\end{array }          \\right ] .",
    "\\end{split}\\ ] ]    the objective is forcing the fluid level in the lower tank , i.e. , @xmath161 , to track constant value @xmath164 . selecting",
    "the control horizon @xmath165 the problem was discretized using sampling time of @xmath166 , therefore @xmath167 .",
    "then , cost function ( [ costfunction ] ) was selected for evaluating the performance of the method in both decreasing the number of switching and also for assigning certain preferences in utilization of some modes .",
    "the basis functions for this example were selected as polynomials @xmath168 , where non - negative integers @xmath120 and @xmath169 are such that @xmath170 .",
    "this selection led to 45 neurons .",
    "domain @xmath171^t \\in \\re^2 : 0 \\leq y < 1 , 0 \\leq z",
    "< 0.8 \\}$ ] was used for the training and batch training scheme was selected , such that , at each stage 100 random states were selected based on algorithm 1 .    initially the following values were selected for the cost function @xmath172 with @xmath173 .",
    "as seen , such a cost function does not assign any cost to switching and does not differentiate between the modes .",
    "the training was observed to take almost 16 seconds , when @xmath174 , in a machine with cpu intel core i7 , 3.4 ghz running matlab 2013a .",
    "afterwards , initial condition @xmath175^t$ ] , simulated in @xcite and @xcite , was used to determine the optimal solution . selecting @xmath176 ,",
    "the results are given in fig .",
    "[ ex2_fig1 ] .",
    "the method did an excellent job controlling the fluid level of the lower tank by tracking the desired value .",
    "this perfect tracking was achievable , however , through high frequency switching between the three modes .",
    "next , the switching cost @xmath177 was used with terms given in ( [ example2_costterms1 ] ) .",
    "the training was re - done using the new cost function and the simulation results in controlling the same initial condition are shown in fig .",
    "[ ex2_fig2 ] .",
    "it is seen that the incorporated switching cost has effectively lowered the number of switching , compared with fig .",
    "[ ex2_fig1 ] .",
    "assigning higher cost to switching , like @xmath178 , further decreases the number of switching while tracking 0.5 , as shown in fig .",
    "[ ex2_fig3 ] .",
    "the application of switching costs for decreasing the number of switching resembles the idea utilized in @xcite and called _ threshold remedy _ , in which no switching cost was incorporated , and hence , the optimal cost - to - go was approximated as a standard function of only the state and the time , as in non - switching problems @xcite .",
    "the training also was done without including a switching cost . in online control process , however , a threshold , similar to the switching cost used in this study , was applied .",
    "this was done in the sense that , the reward of switching to another mode must be higher than a certain threshold in order for the controller to switch . while this remedy can help in certain conditions , the performance deviates as the threshold becomes large .",
    "the reason is , the threshold is not accounted for in the learning process and hence , the result given in @xcite is not optimal considering the applied threshold . to see this ,",
    "one may compare fig .",
    "[ ex2_fig3 ] with the results given in fig .",
    "[ ex2_fig8 ] , where the former is the result of the proposed method in this study with @xmath178 and the latter is the result obtained from @xcite with the equal threshold of 0.01 , in lieu of the switching cost .",
    "as seen , the tracking is much more accurate in fig .",
    "[ ex2_fig3 ] versus fig .",
    "[ ex2_fig8 ] . even considering the cost due to the extra switches in fig .",
    "[ ex2_fig3 ] , the cost - to - go corresponding to fig .",
    "[ ex2_fig3 ] turned out to be 0.340 which is less than the cost - to - go corresponding to fig .",
    "[ ex2_fig8 ] , i.e. , 0.468 .",
    "high threshold values can potentially lead to unreliability of the result of the method in @xcite .",
    "this problem does not exists with the method presented here due to the fact the the switching cost is incorporated in the derivation and the solution is optimal with respect to it .",
    "once the performance of the controller in applying switching costs is analyzed , the cost function terms @xmath179 and @xmath180 are modified to assign certain _ mode preferences _ in the operation of the system .",
    "the mode preference is using modes 2 and 3 more often _ during _ the operation and _ finishing _ the operation preferably with mode 1 .",
    "this was done through selecting the following cost function terms @xmath181 along with the switching cost @xmath20 given in ( [ example2_costterms1 ] ) with @xmath173 .",
    "note that the negative cost -10 assigned to @xmath182 provides the controller with rewards if the last active mode is 1 .",
    "also , the positive cost 0.01 assigned to @xmath183 penalizes the usage of mode 1 during the horizon .",
    "moreover , it should be noted that the method presented in this study does not require the cost function terms to be positive semi - definite , see remark [ rem1 ] .",
    "hence , one can select smooth functions with negative values as well as positive semi - definite functions .",
    "having trained the neurocontroller based on the new cost function terms , the results for controlling the same initial @xmath184 , with @xmath156 , are presented in fig .",
    "[ ex2_fig4 ] . comparing this figure with fig .",
    "[ ex2_fig1 ] , it is seen that the new controller has effectively decreased the number of instants that mode 1 is used . also , looking at the final active mode in fig .",
    "[ ex2_fig4 ] , the controller has been successful in finishing the operation with mode 1 , as desired . as another simulation , the cost function terms given in ( [ example2_costterms2 ] ) with the switching cost @xmath185",
    "is used for training the network and the simulation results are given in fig .",
    "[ ex2_fig6 ] .",
    "this figure demonstrates the capability of the method in both lowering the number of switching and assigning different preferences to utilization of different modes .",
    "next , the capability of the neurocontroller in controlling different initial conditions within @xmath68 is investigated .",
    "a new initial condition , namely @xmath186^t$ ] is utilizes as the last simulation and the last trained network ( without re - training ) is used for controlling it .",
    "the results , given in fig .",
    "[ ex2_fig7 ] , show the capability of the controller in controlling the new initial condition with the desired manner without any need for retraining . in order to furthermore evaluate this capability ,",
    "several different initial conditions are selected and the resulting histories for @xmath187 , which is the variable of interest , from simulating each of the initial conditions are presented in fig .",
    "[ ex2_fig10 ] . in these plots , initially @xmath188 is fixed at 0.2 and @xmath189 is changed from 0 to 1 in steps of 0.1 , and then , @xmath189 is fixed at 0.8 and @xmath188 is changed from 0 to 0.8 , in steps of 0.1 .",
    "the plots show that the controller has effectively controlled all these different initial conditions through tracking the desired constant value 0.5 , without re - training .",
    "finally , the closed - loop feature of the proposed method is evaluated in terms of its moderate robustness .",
    "a time - varying random disturbance is introduced after the training phase in the online operation and is assumed to be uniformly changing between 0 and 0.005 , acting as additive terms on both state elements . the resulting history for the variable of interest @xmath187 , is depicted in fig .",
    "[ ex2_fig11 ] through the solid plot . moreover , the history if the system was operated using an open loop solution",
    "is also included , through the dash plot in the same figure .",
    "as seen , the system operated in the open loop fashion , that is , when the mode sequence in fig .",
    "[ ex2_fig6 ] , which was calculated under no disturbance situation is applied , leads to instability of the system , but , the closed from solution handles the disturbance with a slight performance degradation in terms of a small steady state error .",
    "this demonstrates the desired feature of the proposed method .",
    "^t , \\kappa_0=0,$ ] and cost function terms given in eq .",
    "( [ example2_costterms1 ] ) . ]",
    "^t , \\kappa_0=0.001,$ ] and cost function terms given in eq .",
    "( [ example2_costterms1 ] ) . ]    ^t , \\kappa_0=0.01,$ ] and cost function terms given in eq .",
    "( [ example2_costterms1 ] ) . ]    ^t , \\kappa_0=0,$ ] and cost function terms given in eq .",
    "( [ example2_costterms1 ] ) with applied threshold @xmath190 proposed in @xcite . ]    ^t , \\kappa_0=0,$ ] and cost function terms given in eq .",
    "( [ example2_costterms2 ] ) . ]    ^t , \\kappa_0=0.0002,$ ] and cost function terms given in eq .",
    "( [ example2_costterms2 ] ) . ]    ^t , \\kappa_0 = 0.0002 $ ] , and cost function terms given in eq .",
    "( [ example2_costterms2 ] ) . ]    , and cost function terms given in eq .",
    "( [ example2_costterms2 ] ) . ]    ^t , \\kappa_0 = 0.0002 $ ] , and cost function terms given in eq .",
    "( [ example2_costterms2 ] ) . ]",
    "the problem of finding the optimal switching schedule between different modes of a dynamical system with a cost function which admits incorporation of switching costs as well as assigning different costs to different modes was investigated and the framework of approximate dynamics programming was used with the idea of approximating the optimal cost - to - go for solving it .",
    "it was shown that for such problems the cost - to - go function is not only a function of the current state and time , but also , a function of the subsystem which was active at the previous time step .",
    "it was shown that the developed technique can effectively provide ( approximate ) optimal solutions to the problems with different initial conditions in a feedback form .",
    "the real - time computational burden of the method is as small as evaluating as many scalar - valued functions as the number of subsystems .",
    "99 a. heydari , and s. n. balakrishnan , `` optimal orbit transfer with on - off actuators using a closed form optimal switching scheme , '' _ aiaa guidance , navigation , and control conference _ , boston , ma , 2013 .",
    "x. xu , and p. j. antsaklis , `` optimal control of switched systems via non - linear optimization based on direct differentiations of value functions , '' _ international journal of control _ , vol .",
    "75 ( 16/17 ) , pp . 1406 - 1426 , 2002 .",
    "x. xu , and p. j. antsaklis , `` optimal control of switched systems based on parameterization of the switching instants , '' _ ieee trans . on automatic control _ , vol .",
    "49 ( 1 ) , pp.2- 16 , 2004",
    ". m. egerstedt , y. wardi , and h. axelsson , `` transition - time optimization for switched - mode dynamical systems , '' _ ieee trans . on automatic control _ ,",
    "51 ( 1 ) , pp.110 - 115 , 2006 .",
    "h. axelsson , m. boccadoro , m. egerstedt , p. valigi , and y. wardi , `` optimal mode - switching for hybrid systems with varying initial states , '' _ nonlinear analysis : hybrid systems _ ,",
    "vol . 2 ( 3 ) , pp.765772 , 2008 .",
    "x. ding , a. schild , m. egerstedt , j. and lunze , `` real - time optimal feedback control of switched autonomous systems , '' proc .",
    "_ ifac conference on analysis and design of hybrid systems _ , pp.108 - 113 , 2009 .",
    "axelsson , h. , egerstedt , m. , wardi , y. , and vachtsevanos , g. , `` algorithm for switching - time optimization in hybrid dynamical systems , '' _ proc .",
    "ieee international symposium on intelligent control _ ,",
    "limassol , cyprus , 2005 .",
    "m. kamgarpoura , and c. tomlin , `` on optimal control of non - autonomous switched systems with a fixed mode sequence , '' _ automatica _ , vol .",
    "48 , pp.11771181 , 2012 .",
    "r. zhao , and s. li , `` switched system optimal control based on parameterizations of the control vectors and switching instant , '' proc .",
    "_ chinese control and decision conference _ , pp .",
    "3290 - 3294 , 2011 .",
    "m. sakly , a. sakly , m. majdoub , and m. benrejeb , `` optimization of switching instants for optimal control of linear switched systems based on genetic algorithms , '' proc .",
    "_ ifac int .",
    "intelligent control systems and signal processing _ , istanbul , 2009 .",
    "r. long , j. fu , l. zhang , `` optimal control of switched system based on neural network optimization , '' proc . _",
    "int . conference on intelligent computing _ ,",
    "pp.799 - 806 , 2008 .",
    "a. al - tamimi , f. l. lewis , and m. abu - khalaf , `` discrete - time nonlinear hjb solution using approximate dynamic programming : convergence proof , '' _ ieee trans .",
    "systems , man , and cybernetics - part b _ , vol .",
    "38 , 2008 , pp .",
    "943 - 949 .",
    "g. k. venayagamoorthy , r. g. harley , and d. c. wunsch , `` comparison of heuristic dynamic programming and dual heuristic programming adaptive critics for neurocontrol of a turbogenerator , '' _ ieee trans .",
    "neural netw .",
    "_ , vol . 13 ( 3 ) , pp .",
    "764 - 773 , 2002 .",
    "t. dierks , b. t. thumati , and s. jagannathan , `` optimal control of unknown affine nonlinear discrete - time systems using offline - trained neural networks with proof of convergence , '' _ neural networks _",
    "851 - 860 , 2009 .",
    "vrabie , d. and vamvoudakis , k.g . and",
    "lewis , f.l . , _ optimal adaptive control and differential games by reinforcement learning principles _ , iet control engineering series , institution of engineering and technology , 2013 .",
    "a. heydari , s. n. balakrishnan , `` fixed - final - time optimal control of nonlinear systems with terminal constraints , '' _ neural network _ ,",
    "61 - 71 , 2013 .",
    "a. heydari , s. n. balakrishnan , `` finite - horizon control - constrained nonlinear optimal control using single network adaptive critics , '' _ ieee transactions on neural networks and learning systems _ , vol .",
    "24 ( 1 ) , pp .",
    "145 - 157 , 2013 .",
    "f. wang , n. jin , d. liu , and q. wei , `` adaptive dynamic programming for finite - horizon optimal control of discrete - time nonlinear systems with @xmath191-error bound , '' _ ieee trans .",
    "neural netw .",
    "22 ( 1 ) , pp .",
    "24 - 36 , 2011 .",
    "a. heydari , s. n. balakrishnan , `` optimal switching and control of nonlinear switched systems using approximate dynamic programming , '' to appear in _ ieee transactions on neural networks and learning systems _ , 2014 .",
    "a. heydari , s. n. balakrishnan , `` optimal multi - therapeutic hiv treatment using a global optimal switching scheme , '' _ applied mathematics and computation _ , vol .",
    "7872 - 7881 , 2013 .",
    "a. heydari , s. n. balakrishnan , `` optimal switching between controlled subsystems with free mode sequence , '' submitted to _",
    "a. heydari , s. n. balakrishnan , `` optimal switching between autonomous subsystems , '' _ journal of the franklin institute _ ,",
    "2675 - 2690 , 2014 .    c. qin , h. zhang , y. luo , and b. wang , `` finite horizon optimal control of non - linear discrete - time switched systems using adaptive dynamic programming with @xmath191-error bound , '' _ international journal of systems science _ , 2013 .",
    "k. homik , m. stinchcombe , and h. white , `` multilayer feedforward networks are universal approximators , '' _ neural networks _ , vol .",
    "359 - 366 , 1989 .",
    "r. courant , and d. hilbert , `` methods of mathematical physics , '' vol i. wiley ( interscience ) , new york , p. 65"
  ],
  "abstract_text": [
    "<S> the problem of optimal switching between nonlinear autonomous subsystems is investigated in this study where the objective is not only bringing the states to close to the desired point , but also adjusting the switching pattern , in the sense of penalizing switching occurrences and assigning different preferences to utilization of different modes . </S>",
    "<S> the mode sequence is unspecified and a switching cost term is used in the cost function for penalizing each switching . </S>",
    "<S> it is shown that once a switching cost is incorporated , the optimal cost - to - go function depends on the already active subsystem , i.e. , the subsystem which was engaged in the previous time step . </S>",
    "<S> afterwards , an approximate dynamic programming based method is developed which provides an approximation of the optimal solution to the problem in a _ </S>",
    "<S> feedback _ form and for _ different initial conditions_. finally , the performance of the method is analyzed through numerical examples . </S>"
  ]
}