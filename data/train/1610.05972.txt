{
  "article_text": [
    "making detailed measurements of the temperature structure of the solar upper atmosphere is fundamental to constraining the coronal heating problem .",
    "recent work has suggested that many structures in the corona have relatively narrow distributions of temperatures ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "this result is difficult to reconcile with the parker nanoflare model of coronal heating @xcite .",
    "all theoretical calculations and numerical simulations indicate that magnetic reconnection occurs on spatial scales that are much smaller than can be observed with current instrumentation .",
    "this implies that observed temperature distributions should be broad ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) .    unfortunately , determining the temperature structure of the corona from remote sensing observations is difficult . in principal , measurements of individual emission line intensities",
    "should yield this information .",
    "the intensity , however , is a convolution of the temperature , density , and geometry along the line of sight and such observations must be inverted to yield the differential emission measure distribution ( dem ) .",
    "since the inversion is ill posed it is nt clear what to make of the solution . in their classic paper @xcite",
    "write `` consequently , in the derivation of thermal structure from spectral data , observational errors are always magnified and often to such an extent that the solution becomes meaningless . '' the inverse problem can be regularized so that the solution is less sensitive to error but this introduces additional assumptions that may have no physical basis @xcite .    in this paper",
    "we introduce the application of sparse bayesian inference to the differential emission measure inversion problem . here",
    "we are attempting to infer the temperature structure of the atmosphere through observations of optically thin emission lines , @xmath0 where @xmath1 is the observed intensity , @xmath2 is the relevant plasma emissivity , which is assumed to be known , and @xmath3 is the differential emission measure ( dem ) , which is a function of the electron density and path length along the line of sight . as has been done in many previous studies , we assume that the dem can be represented by a sum of simple basis functions . motivated by the `` relevance vector machine , '' a bayesian regression algorithm developed by @xcite , we adopt a prior that encodes a preference for solutions that utilize a minimum number of basis function .",
    "the important implication of this assumption is that the complexity of the inferred temperature distribution is determined primarily by the observations and their statistical significance and not by ad hoc assumptions about the solution .    to demonstrate the efficacy of this approach we have constructed a test library of 40 dems that cover the range of what we expect to observe in the solar corona . for each distribution",
    "we estimate the intensity and statistical uncertainty for a number of emission lines using the effective areas of the extreme ultraviolet imaging spectrometer ( eis , @xcite ) on the _ hinode _ mission .",
    "these intensities are used to attempt to recover the input dem .",
    "we show that our method outperforms another bayesian dem solver ( mcmc by @xcite ) , which assumes an uninformative prior for the weights .",
    "this paper is structured in the following way .",
    "we first consider the application of our bayesian framework to a linear `` toy problem '' that closely follows example regression problems that are often found in the literature ( e.g. , * ? ? ?",
    "this allows us to make a gentle introduction of the notation and to compare our approach with other established methods .",
    "we then consider the application of our approach to the dem inversion problem .",
    "in standard linear regression problems we wish to fit a set of @xmath4 observed data points ( @xmath5 ) to some smooth function with free parameters .",
    "we assume that the modeled data points ( @xmath6 ) can be written as the linear superposition of a set of specified basis functions @xmath7 and our task is to find the weights ( @xmath8 ) that `` best fit '' the data . in this paper",
    "we will assume that the basis functions are simple gaussians @xmath9\\ ] ] with a fixed width @xmath10 .",
    "anticipating the dem problem we will not assume that the positions of the basis functions ( @xmath11 ) lie on the available data points but are evenly spaced on a fixed domain .",
    "for a given set of data the optimal weights can be found by minimizing the familiar expression @xmath12 for which the optimal weights can be found by gradient descent or levenberg - marquardt ( e.g. , * ? ? ? * ) . also recall that we can cast this in matrix form @xmath13 where @xmath14 , which can be solved directly with @xmath15 or iteratively with gradient descent .",
    "the challenge is to allow for many degrees of freedom so that we can fit a wide variety of functions while not overfitting the data . to illustrate this , we generate 50 noisy data points from the @xmath16 function .",
    "the noise is drawn from a normal distribution with zero mean and a standard deviation of @xmath17 . as is shown in figure  [",
    "fig : toyprob ] , a model with with @xmath18 basis functions fits the data points perfectly , but is highly oscillatory .",
    "our intuition is that this model will not do a good job of predicting the values of new data points . indeed ,",
    "if we generate another 50 noisy data points we see that @xmath19 is about an order of magnitude larger for this new set .    the traditional approach to constraining such regression problems is penalized least squares , where we minimize a function of the form @xmath20 which can be solved with gradient descent or directly with @xmath21    the parameter @xmath22 balances the goodness of fit against the smoothness of the solution .",
    "it can be found by using some of the data ( the training data ) to infer the weights and the remainder of the data ( the test data ) to evaluate the goodness of fit .",
    "since the computational complexity of the problem is small , we can determine the value of @xmath22 that best fits the test data through a simple one - dimensional parameter search .",
    "figure  [ fig : toyprob ] illustrates this approach to the regression problem .",
    "this method works well when we have many data points and can easily divide them into training and test sets .",
    "unfortunately , for the dem problem we often have a limited number of observed intensities and this `` leave some out '' cross - validation technique is not useful .    by reformulating the problem using a bayesian framework",
    "we can achieve a similar result without resorting to cross - validation .",
    "we write bayes theorem as the product of a likelihood and a hierarchical prior @xmath23 the likelihood is the usual expression assuming normally distributed errors on the observations @xmath24.\\ ] ] for the prior on the weights we simply chose a cauchy distribution , @xmath25 we choose an uninformative prior for the hyperparameter @xmath26 , which implicitly assumes that the values for the weights will be only weakly dependent on the value of @xmath26 that we use .",
    "we recognize that there are techniques for optimizing the hyperparameters and we will return to this issue in the summary and discussion section .",
    "if we are interested in the distributions of the weights implied by the data and our choice of the posterior , we must generate samples from it .",
    "the standard approach to this is the metropolis - hastings algorithm @xcite . in the next section",
    "we will describe the application of a powerful new parallel sampling technique @xcite that we can apply to this problem .",
    "if we are only interested in the set of weights that maximize the posterior , we take the negative log of the posterior , discard all constant terms , and minimize @xmath27 which is similar to equation  [ eq : pls ] . this can be minimized using gradient descent .",
    "figure  [ fig : toyprob ] shows the solution assuming @xmath28 and using all 100 data points simultaneously in the optimization .",
    "we see that this approach also avoids overfitting the data , but by limiting the number of non - zero basis functions rather than by limiting the sum of the weights .",
    "the cauchy distribution encourages such sparse solutions because it has `` fat tails . '' to see how this comes about consider a simple case where three basis functions could be used to describe the data equally well . in the absence of a prior",
    ", the solution is likely to have weights of comparable magnitude , e.g. , @xmath29 , while we would like the solution to be as simple as possible , say @xmath30 . with the assumption of the cauchy prior",
    ", however , we have @xmath31 for @xmath32 and we see that we can encode this preference for models with a limited number of non - zero weights into the prior . since the temperature domain of the dem is not unambiguously determined by the data , this preference for sparse solutions is a useful property .",
    "we want emission measure to be inferred only when the observations imply that it is statistically significant .",
    "we note that this approach does nt eliminate any degeneracy among the solutions .",
    "several sets of weights ( e.g , 1,0,0 or 0,1,0 or 0,0,1 in our simple example ) could be nearly equally likely",
    ". it could also be that the numerical scheme used to explore the posterior has difficulty with such a multi - modal landscape .",
    "we will discuss the problem of degeneracy in more detail in the next section .",
    "a more sophisticated bayesian approach to sparsity has been formulated by @xcite , who called his method the relevance vector machine ( rvm ) . here",
    "the prior on the weights is assumed to be @xmath33^{1/2 }                \\exp\\left[-\\frac{\\alpha_m w_m^2}{2}\\right],\\ ] ] where there is a hyperparameter @xmath34 for each weight and the prior on each hyperparameter is assumed to be a gamma distribution .",
    "@xcite iteratively solves for the optimal set of weights and hyperparameters by alternating between maximizing the likelihood with fixed @xmath34 and maximizing the evidence ( the denominator of equation  [ eq : bayes ] ) with fixed @xmath8 .",
    "as the iteration proceeds , some of the @xmath34 s become large and these basis functions are pruned from the model . upon convergence",
    "we are typically left with a model that has only a few remaining basis functions .",
    "figure  [ fig : toyprob ] illustrates the application of this approach to our @xmath35 problem .",
    "the rvm solution is similar to that obtained using the cauchy prior , suggesting that this distribution is consistent with sparsity .",
    "the gamma function prior for @xmath34 makes the equivalent regularizing penalty proportional to @xmath36 ( @xcite , equation 33 ) , similar to what we obtain with the cauchy prior , so perhaps this is not surprising .        for the scale of problem that we are interested in ,",
    "the rvm is computationally efficient .",
    "unfortunately , the rvm allows for negative weights and can not be used for the emission measure problem since a negative emission measure has no physical meaning .",
    "the simple bayesian approach described by equations  [ eq : bayes ] and [ eq : log_pos ] , in contrast , is much more computationally expensive to implement , but it can easily accommodate the essential positive definite constraint on the weights .",
    "we close this section with a brief comment on mathematical rigor .",
    "it is clear that the further we stray from simple least - squares solutions the less certain we are that our mathematical assumptions will have their intended effect .",
    "we have certainly not proven that the cauchy prior will always lead to sparse solutions or that our assumptions about the hyper - parameter @xmath26 will not have some perverse consequence in some circumstances .",
    "similarly , @xcite has not proven that the iterative approach to the rvm always converges to the optimal solution ( for example , see section of 2.2 of @xcite for cases where the rvm fails to perform optimally ) .",
    "our feeling is that considering a wide variety of test problems is the easiest way of dealing with this lack of mathematical certainty .",
    "we now turn to the actual problem of interest , inferring the temperature structure of the solar atmosphere from observations of optically thin line emission .",
    "specifically , we wish to invert the equation @xmath37 for the line - of - sight differential emission measure distribution @xmath3 given a set of observed intensities ( @xmath1 ) , their associated statistical uncertainties ( @xmath38 ) , and the relevant plasma emissivites ( @xmath39 . this problem differs from the linear problem in that the function we wish to fit is not observed directly , but indirectly through the intensity .",
    "as discussed in the previous section , the solution should have several properties : since the density and path length are positive quantities , it must be positive definite ; since in many circumstances we will have only a limited number of observed intensities , it can not rely on cross validation methods for optimizing parameters ; and it should be sparse , inferring emission measure only at temperatures where there is a statistically significant reason to do so .",
    "as we will see , the bayesian approach that we applied to the linear problem satisfies all three of these properties .",
    "we assume that the product of the temperature and the dem can be represented as the weighted sum of known basis functions , @xmath40 the exponential weight is chosen so that the dem is positive definite",
    ". note that since the range of temperatures is large it is more efficient to integrate over intervals of constant log temperature using @xmath41 .",
    "putting the extra factor of @xmath42 on the right side of equation  [ eq : dem ] allows both the weights and the basis functions to have uniform magnitudes . for the basis functions we chose gaussians in @xmath43 , @xmath44.\\ ] ] for a given temperature domain",
    "we assume that the basis functions are equally spaced and that the width of each component is @xmath45 so that the width is automatically adjusted depending on the number of components .",
    "rcrrrrr mg v 276.579 & 5.45 & 2.06e-10 & 0.00 & 0.41 & 0.00 & 0.29 + mg vi 270.394 & 5.65 & 2.61e-10 & 0.00 & 0.32 & 0.00 & 1.79 + mg vii 280.737 & 5.80 & 1.38e-10 & 0.30 & 0.72 & 0.29 & 1.00 + si vii 275.368 & 5.80 & 2.24e-10 & 0.17 & 0.44 & 0.12 & 1.40 + fe ix 188.497 & 5.90 & 3.65e-10 & 1.72 & 0.74 & 1.37 & 1.26 + fe ix 197.862 & 5.90 & 6.44e-10 & 1.05 & 0.43 & 0.90 & 1.17 + fe x 184.536 & 6.05 & 1.54e-10 & 18.55 & 3.64 & 16.88 & 1.10 + si x 258.375 & 6.15 & 1.52e-10 & 62.36 & 5.65 & 62.28 & 1.00 + fe xi 180.401 & 6.15 & 3.98e-11 & 152.36 & 20.65 & 150.47 & 1.01 + fe xi 188.216 & 6.15 & 3.48e-10 & 76.93 & 4.84 & 75.87 & 1.01 + s x 264.233 & 6.15 & 2.16e-10 & 11.25 & 2.02 & 11.37 & 0.99 + fe xii 195.119 & 6.20 & 7.11e-10 & 209.69 & 5.48 &",
    "217.88 & 0.96 + fe xii 192.394 & 6.20 & 6.01e-10 & 67.57 & 3.41 & 70.20 & 0.96 + fe xiii 202.044 & 6.25 & 1.94e-10 & 115.64 & 7.68 & 120.15 & 0.96 + fe xiii 203.826 & 6.25 & 1.03e-10 & 174.43 & 12.90 & 182.51 & 0.96 + fe xiv 264.787 & 6.30 & 2.22e-10 & 243.24 & 9.07 & 245.37 & 0.99 + fe xiv 270.519 & 6.30 & 2.61e-10 & 124.92 & 5.94 & 125.95 & 0.99 + fe xiv 211.316 & 6.30 & 2.47e-11 & 456.62 & 41.82 & 459.89 & 0.99 + fe xv 284.160 & 6.35 & 9.54e-11 & 6114.98 & 66.95 & 6237.17 & 0.98 + s xiii 256.686 & 6.40 & 1.35e-10 & 517.05 & 17.22 & 526.64 & 0.98 + fe xvi 262.984 & 6.45 & 2.02e-10 & 1028.86 & 19.62 & 1057.81 & 0.97 + ca xiv 193.874 & 6.55 & 6.73e-10 & 246.54 & 6.13 & 259.09 & 0.95 + ar xiv 194.396 & 6.55 & 6.93e-10 & 70.62 & 3.23 & 75.22 & 0.94 + ca xv 200.972 & 6.65 & 2.95e-10 & 210.21 & 8.40 & 213.79 & 0.98 + ca xvi 208.604 & 6.70 & 3.98e-11 & 120.19 & 17.08 & 115.32 & 1.04 + ca xvii 192.858 & 6.75 & 6.25e-10 & 157.95 & 5.10 & 138.12 & 1.14 + aia 94 & 6.85 &  & 20.39 & 0.64 & 19.41 & 1.05 [ table : line_list ]    with these assumptions it is possible to integrate the emissivity over each basis function , @xmath46 and the calculation of each modeled intensity is reduced to a simple sum .",
    "the only differences between this problem and the problem discussed in the previous section are that the intensities are non - linear functions of the weights and , since spectroscopic instruments rarely have uniform sensitivity , each intensity has a uncertainty ( @xmath38 ) .",
    "the line - of - sight emission measures observed on the sun are typically large , @xmath47@xmath48 in an active region , for example @xcite .",
    "to bias the weights to the domain of interest we introduce a scaling factor into the basis functions so that a weight of zero corresponds to @xmath49 instead of 1 .",
    "further we modify the prior on the weights ( equation  [ eq : log_prior ] ) by mapping @xmath50 to @xmath51 .",
    "given a set of observed intensities and the corresponding atomic data , we can find the optimal values for the weights either by sampling the posterior ( equation  [ eq : bayes ] ) or minimizing the negative log - posterior ( equation [ eq : log_pos ] ) .",
    "unfortunately , finding global extrema in a high dimensional space is a formidable problem .",
    "our approach is to begin by sampling the posterior using the method introduced by @xcite and implemented by @xcite and @xcite , among others .",
    "this method differs from the traditional single monte carlo markov chain random walk method for sampling the posterior by utilizing an ensemble of walkers , potentially thousands of them , that can be updated in parallel .",
    "further , instead of using a proposal distribution with parameters that must be adjusted to achieve the desired acceptance ratio , updates to the chain are made using the current positions of pairs of walkers @xmath52 where @xmath53 is a random number from the distribution @xmath54 on the domain @xmath55 $ ] . in principle , @xmath56 is an adjustable parameter but the choice @xmath57 appears to work well in all applications @xcite .",
    "note that the pairs of walkers are shuffled on each iteration .",
    "we implemented this algorithm in a simple c code that was parallelized using openmp .",
    "we validated it by sampling from known posteriors , applying it to simple parameter estimation problems , such as fitting spectral profiles with a gaussian , and using it for the linear regression problem in the previous section .        to test our approach",
    "we need to create some dems and select a line list for our hypothetical observations . in figure",
    "[ fig : library_image ] we show the `` library '' of 40 test dems that we have devised .",
    "these functions are superpositions of gaussians that are either linear or logarithmic in temperature and range from narrow to very broad , representing the range of curves that have been found in previous studies ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "note that we have deliberately mismatched the widths of the dems in the library and the widths of the basis functions .",
    "to complement the dem library we select a series of emission lines that are observed with eis and that are typically used in temperature studies ( e.g. , * ? ? ?",
    "these lines are listed in table  [ table : line_list ] , where we also list the peak temperature of formation for the ion and the conversion from the radiance observed at the sun to photons detected by the instrument , which is needed to compute the statistical uncertainty for each intensity .",
    "this conversion factor is simply the product of the pre - flight effective area @xcite , the solid angle subtended by a pixel , and the exposure time .",
    "here we assume the use of the 1  slit and a 100s exposure time .    to augment the eis line list we use a calculated intensity for the 94  channel on the the atmospheric imaging assembly ( aia , @xcite ) .",
    "this channel can observe 93.932 , which peaks at about @xmath58 .",
    "we assume that we are using 94  images that have been processed to remove lower temperature emission ( see the appendix of @xcite ) .",
    "errors on the intensity are computed using the standard analysis routine ` aia_bp_estimate_error ` .    for all of our emissivity calculations we use the chianti atomic database version 8.0.1 @xcite assuming coronal abundances @xcite , a constant pressure of @xmath59@xmath60  k , and the default ionization fractions . for each emission line",
    "the emissivities of all lines with 0.5  are summed to create a composite response .",
    "we are now in a position to calculate the dems .",
    "to compute the intensities we convolve each distribution in the library with the emissivities for all of the eis lines and the aia 94  channel .",
    "we also compute the statistical uncertainty for each of the resulting intensities .",
    "for the prior we use @xmath28 .",
    "for the sampling we initialize 1,000 walkers with randomly selected weights on the interval @xmath61 $ ] and begin iterating . after a burn - in of @xmath62 accepted samples , the next @xmath63 proposed steps that are accepted are recorded to form the final sampling of the posterior .",
    "after each iteration we also recorded the highest value of the posterior and saved the corresponding set of weights .",
    "this procedure takes about 45min per dem on a standard 4-core 4ghz intel i7 processor with all four cores utilized .",
    "we will discuss how this algorithm could be made more efficient in the next section .    in figure",
    "[ fig : library_dist ] we show the distributions of the weights obtained for one of the dem calculations ( # 18 ) .",
    "the corresponding intensities are shown in table  [ table : line_list ] .",
    "unfortunately , these posterior distributions are not simple , single peaked functions , but have multiple peaks . as discussed in the previous section , multiple peaks are an inevitable consequence of having many basis functions .",
    "recall our simple example of having three degenerate basis functions where each could represent the data equally well .",
    "the posterior in this simple case would consist of approximately equal parts ( 1,0,0 ) , ( 0,1,0 ) , and ( 0,0,1 ) and the distribution for each weight would have a strong peak at 0 and a secondary peak at 1 .",
    "for the dem problem we have not specified so many basis functions that we expect to see such extreme degeneracy .",
    "still , multiple peaks are clearly present in the posterior distributions for many weights .    .",
    "]    ) and form an envelope on the emission measure distribution . ]",
    "so which weights do we use to compute the final dem ?",
    "the median and mean of the weight distributions are potentially problematic .",
    "the mode of the distribution , however , is generally well behaved . using these weights to compute the dem both reproduces the observed intensities and the input dem very closely . for each run",
    "we also used the walker with the highest value of the posterior as initial conditions for a gradient descent calculation . as is illustrated in figure  [ fig : library_evo ] ,",
    "the dems recovered using gradient descent generally matched those recovered using the mode of the posterior weight distribution . in all cases the weights obtained after gradient descent actually produced a higher value for the posterior than the mode , suggesting that using the mode is not optimal .",
    "for this reason we use the weights obtained from gradient descent to represent the recovered dem .",
    "we have performed this calculation for all of the dems in the library .",
    "some example dems are shown in figure  [ fig : library_dems ] .",
    "the summary of all of the calculations is presented in figure  [ fig : library_image ] . in almost all cases",
    "the input intensities are reproduced to within a few percent and the general properties of the input dem are also recovered and no emission measure is inferred far away from the peaks in the input distributions .",
    "we note that the excellent agreement between the recovered and actual dems is only achieved after a very long burn - in period ( recall that we accepted @xmath62 samples before collecting the samples for the posterior ) . for a burn - in of",
    "@xmath64 samples the mode of the posterior distribution resulted in a poor approximation of the input dem with finite weights for most of basis functions . for a burn - in of @xmath65 samples",
    "the recovered dems were generally close to the input dems but there were a number of spurious peaks .",
    "many of these peaks remained even after performing gradient descent .",
    "the sampling of the posterior is computationally expensive and one might wonder if it would be easier to simply select some random initial conditions and then do gradient descent .",
    "our experiments with this were not encouraging . in almost all cases the calculation converged to some local maximum far from the solution that we obtained through sampling .",
    "we note that we did not study this extensively .",
    "our intuition , however , is that the sampling is an invaluable aid in exploring a complex posterior in a high dimensional space and is worth the computational expense .    to provide a point of comparison for our calculations",
    "we have used another bayesian solver , the `` mcmc '' routine of @xcite , on each set of computed intensities in the dem library .",
    "here we use 20 temperature bins in @xmath43 and run 100 simulations on each dem .",
    "the resulting dems , which are summarized in figure  [ fig : library_image ] , also recovers the main features of each input distribution .",
    "we also see , however , that mcmc infers emission measure at temperatures far away from the main peaks in the input distributions .",
    "this is not surprising given the assumption of an uninformative prior over the weights .",
    "finally , we have also applied this technique to two sets of observed eis intensities .",
    "these results are summarized in figure  [ fig : observed ] .",
    "the sparse technique that we introduced here recovers the observed intensities as well as mcmc . since the dem library was constructed with these types of dems in mind ",
    "narrow dems for off - limb quiet sun and somewhat broader dems for active regions  it is not surprising that the algorithm can recover them .",
    "we have explored the application of sparse bayesian inference to the problem of determining the temperature structure of the solar corona . we have found that by adopting a cauchy distribution as a prior for the weights we can encode a preference for a sparse representation of the temperature distribution .",
    "thus we can use a rich set of basis functions and recover a wide variety of dems , while limiting the amount of spurious emission measure at other temperatures .",
    "we have also shown that a complex , high - dimensional posterior can be explored in detail using the parallel sampling technique of @xcite .",
    "the results from this sparse bayesian approach compare favorably to the results obtained from mcmc @xcite .",
    "as one would expect , the absence of any constraints on the weights in mcmc leads to considerable emission measure being inferred at temperatures away from the peaks in the input dems .",
    "there are two aspects of our algorithm that could be improved .",
    "first , we have not considered the optimization of the hyperparameters .",
    "the magnitude of the weight penalty ( @xmath26 in equation  [ eq : log_prior ] ) , the number of basis functions , and the widths of the basis functions , are left fixed . as mentioned in the discussion of the rvm in the previous section , one method for optimizing the hyperparameters",
    "is maximizing the evidence ( see chapter 18 of @xcite for more details ) .",
    "unfortunately , our non - linear representation of the dem makes the integration of the evidence analytically intractable .",
    "a linear representation of the dem would make many aspects of the problem simpler , but this would require an algorithm for optimizing the weights that incorporates the positive definite constraint .",
    "we conjecture that such an approach would be orders of magnitude faster than our current approach .",
    "we have limited our comparisons to mcmc .",
    "there have been many papers written on dem inversions , but a complete summary of techniques is well beyond the scope of this work .",
    "two recent efforts , however , directly address some of the issues that we have discussed in this paper . @xcite implement a penalized least squares algorithm ( equation  [ eq : pls ] ) where the hyperparmeter @xmath22 is adjusted using the statistical uncertainty in observations and the non - negativity constraint . as illustrated with our linear problem , this produces solutions that are smooth , but not necessarily sparse , and thus sensitive to the domain specified for the inversion .",
    "one typically chooses a temperature range that extends slightly beyond the temperature of formation of the coolest and hottest line that is observed .",
    "this is not a particularly controversial assumption and so this is not a major shortcoming .",
    "@xcite have implemented an algorithm with a weight penalty based on the l1 norm ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "@xcite do not address the optimization of the hyperparmeter on the weight penalty .",
    "they also use a l1 norm for the likelihood and it is not clear if this is consistent with the uncertainties of the observations . both @xcite and @xcite have tested their algorithms on a wide variety of input dems and they perform well .",
    "these algorithms are significantly faster than our sparse bayesian method .",
    "finally , we stress that our goals for the dem are relatively modest .",
    "in general , we simply wish to understand if structures in the solar atmosphere have narrow or broad temperature distributions .",
    "we also stress that no amount of mathematical machinery can replace the need for well - calibrated observations that contain emission lines that cover a wide range of temperatures .",
    "highly accurate atomic data is also a critical component of any effort to understand the temperature structure of the solar atmosphere ( e.g. , * ? ? ?",
    "this work was sponsored by the chief of naval research and nasa s hinode project .",
    "hinode is a japanese mission developed and launched by isas / jaxa , with naoj as domestic partner and nasa and stfc ( uk ) as international partners .",
    "candela , j.  q. 2004 , phd thesis , informatics and mathematical modelling , technical university of denmark , dtu , richard petersens plads , building 321 , dk-2800 kgs .",
    "lyngby , supervised by professor lars kai hansen"
  ],
  "abstract_text": [
    "<S> measuring the temperature structure of the solar atmosphere is critical to understanding how it is heated to high temperatures . unfortunately </S>",
    "<S> , the temperature of the upper atmosphere can not be observed directly , but must be inferred from spectrally resolved observations of individual emission lines that span a wide range of temperatures . </S>",
    "<S> such observations are `` inverted '' to determine the distribution of plasma temperatures along the line of sight . </S>",
    "<S> this inversion is ill - posed and , in the absence of regularization , tends to produce wildly oscillatory solutions . </S>",
    "<S> we introduce the application of sparse bayesian inference to the problem of inferring the temperature structure of the solar corona . within a bayesian framework a preference for solutions that utilize a minimum number of basis functions </S>",
    "<S> can be encoded into the prior and many ad hoc assumptions can be avoided . </S>",
    "<S> we demonstrate the efficacy of the bayesian approach by considering a test library of 40 assumed temperature distributions . </S>"
  ]
}