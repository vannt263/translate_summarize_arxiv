{
  "article_text": [
    "consider a statistician working on a problem @xmath0 in which a vector @xmath1 of real - valued outcomes is to be observed , and ",
    "prior to , i.e. without , observing @xmath2  the statistician s uncertainty is exchangeable , in the usual sense of being invariant under permutation of the order in which the outcomes are listed in @xmath2 .",
    "this situation has extremely broad real - world applicability , including ( but not limited to ) the analysis of a completely randomized controlled trial , in which participants  ideally , similar to elements of a population to which it is desired to generalize inferentially  are randomized .",
    "each participant is assigned either to a control group that receives the current best treatment , or an experimental group that receives a new treatment whose causal effect on one or more outcomes is of interest .",
    "this design , while extremely simple , has proven to be highly useful over the past 90 years , in fields as disparate as agriculture @xcite , medicine @xcite , and ( in contemporary usage ) @xmath3 testing in data science at massive scale @xcite .",
    "we use randomized controlled trials as a motivating example below , but we emphasize that they constitute only one of many settings to which the results of this paper apply .    focusing just on the experimental group in the randomized controlled trial , the exchangeability inherent in @xmath2 implies via de finetti s theorem @xcite that the statistician s state of information may be represented by the hierarchical model [ de - finetti - representation ] y_i f & f & f & ( f ) for @xmath4 , where @xmath5 is a cumulative distribution function ( cdf ) on @xmath6 and @xmath7 is a prior on the space of all such cdfs , i.e. , the infinite - dimensional probability simplex @xmath8 . note that ( [ de - finetti - representation ] ) has uniquely specified the likelihood in a bayesian nonparametric model for @xmath2 , and all that remains is specification of @xmath7 .",
    "speaking now more generally ( not just in the context of a randomized controlled trial ) , suppose that the nature of the problem @xmath0 enables the analyst to identify an alternative statistical problem @xmath9 in which & = g(p ) & & & g & g , where @xmath10 is a collection of transformations @xmath11 from one problem to another having the property that , without having seen any data , @xmath9 and @xmath0 are the _ exact same problem_. then the prior @xmath12 under @xmath9 must be the same as the prior @xmath13 under @xmath0 ! furthermore , since this holds for any @xmath14 , the result will be , as long as @xmath10 is endowed with enough structure , that there is one and only one prior @xmath13 , for use in @xmath0 , that respects the inherent invariance of the problem under study .",
    "bayes rule then implies that there is one and only one posterior distribution under @xmath0 .",
    "when this occurs , we say that the problem @xmath0 admits an _ optimal bayesian analysis_.    the logic underlying the above argument has been used to motivate and formalize the notion of noninformative priors for decades . indeed , in the special case where @xmath5 is parametric and @xmath10 is a group of transformations encoding invariance with respect to monotonically - transformed units of measurement , @xcite derived the resulting prior distribution .",
    "as another example , @xcite derived the prior distribution for the mean number of arrivals of a poisson process by using its characterization as a lvy counting process to specify an appropriate transformation group .",
    "notably , the resulting prior distribution is _ not _ the jeffreys prior , because the problem s invariance and corresponding transformation group are different .",
    "see @xcite for additional work on this subject .",
    "having studied this line of reasoning , it is natural to ponder its generality . in this paper",
    "we show that the argument can be made quite general  we prove that the argument s formal notions    a.   can be generalized to include _ approximately _ invariant priors in an @xmath15@xmath16 sense , and b.   can be extended to infinite - dimensional priors on spaces of functions .",
    "we focus on the setting described in ( [ de - finetti - representation ] ) and defer more general situations to future work . in this",
    "setting we derive a number of results , ultimately showing that the dirichlet process @xcite prior @xmath17 is an approximately invariant stochastic process for any cdf @xmath18 on @xmath6 .",
    "together with de finetti s theorem , this demonstrates that the posterior distribution @xmath19\\del{n , \\hat{f}_n } \\",
    ", , \\ ] ] where @xmath20 is the empirical cdf , corresponds in a certain sense to an optimal bayesian analysis ",
    "see section [ discussion ] for more on this point .",
    "not all approaches to noninformative priors are based on group invariance .",
    "perhaps the earliest approach can be traced back to @xcite , who proposed a principle of indifference under which , if all that is known about a quantity @xmath21 is that @xmath22 ( for some set @xmath23 of possible values ) , then the prior should be uniform on @xmath23 .",
    "suppose we take @xmath24 : the fact that @xmath25(0,1)$ ] is not consistent with @xmath26(0,1)$ ] for any monotonic nonlinear @xmath27 requires that the problem @xmath0 under study must uniquely identify the scale on which uniformity should hold for the principle to be valid  this was a major reason for the rise of non - bayesian theories of inference in the 19th century @xcite .",
    "@xcite has proposed a notion of noninformative priors that is defined by studying their effect on posterior distributions , and choosing priors that ensure that prior impact is minimized .",
    "@xcite has proposed the maximum entropy principle , which defines noninformative prior distributions via information - theoretic arguments .",
    "all of these notions are different , and applicable to problems where the corresponding notion of noninformativeness arise most naturally .",
    "most of the work on noninformative priors has focused on the parametric setting , in which the number of unknown quantities is finite . in contrast ,",
    "@xcite and @xcite have derived results on noninformative priors in dirichlet process mixture models .",
    "their notion of noninformativeness is completely different from our own , as it is a posteriori , i.e. , it involves examining the behavior of the posterior distribution under the priors studied .",
    "this makes their approach largely complementary to ours : in specifying priors , it is helpful to understand both the prior s effect on the posterior and the prior s behavior a priori without considering any data .",
    "here we study noninformative prior specification from a _ strictly a priori _ perspective .",
    "we do not consider the prior s effect on the posterior distribution .",
    "there is no data or discussion of computation .",
    "our motivation is a generalization of the following argument by @xcite .",
    "suppose that in the randomized controlled trial described above , the outcome @xmath28 of interest is binary .",
    "by de finetti s theorem , we know that @xmath29(\\theta_1)\\ ] ] is the unique likelihood for ( e.g. , the treatment group in ) this problem .",
    "suppose further that the statistician s state of information about @xmath30 external to the data set @xmath31 is what jaynes calls `` complete initial ignorance '' except for the fact that @xmath32 is such that @xmath33 jaynes argues that this state of information is equivalent to the statistician possessing complete initial ignorance about all possible rescaled and renormalized versions of @xmath34 , namely @xmath35 for all positive @xmath36 .",
    "jaynes shows that this leads uniquely to the haldane prior ( _ 1 ) & & & & ( _ 1 , _ 2 ) & , where @xmath37 .",
    "combining this result with the unique bernoulli likelihood under exchangeability , in our language jaynes has therefore identified an instance of optimal bayesian analysis . in what follows we ( a ) extend jaynes s argument to the multinomial setting with @xmath38 outcome categories for arbitrary finite @xmath38 and ( b )",
    "show how this generalization leads to a unique noninformative prior on @xmath8 .",
    "to begin our discussion , we first introduce the notion of an invariant distribution , which describes what we mean by the term noninformative .",
    "a density @xmath39 is _ invariant with respect to a transformation group _",
    "@xmath10 if for all @xmath40 $ ] with @xmath14 , and all measurable sets @xmath41 , @xmath42 \\dif g(\\v{\\theta } ) = \\int_a \\tilde{\\pi } ( \\v{\\theta } ) \\ , \\abs{\\frac{\\partial[g(\\v{\\theta})]}{\\partial(\\v{\\theta } )",
    "} } \\dif \\v{\\theta } \\ , , \\ ] ] where @xmath43}{\\partial(\\v{\\theta})}}$ ] is the jacobian of the transformation .",
    "note that in equation ( [ invariant-0 ] ) , if we were to instead take @xmath41 in the middle and right integrals to be @xmath44 , we would exactly get the classical integration by substitution formula , which under appropriate conditions is always true .",
    "we are interested in the inverse problem : given a set of transformations in @xmath10 , does there exist a unique @xmath13 satisfying ( [ invariant-0 ] ) ?    in a number of practically - relevant cases ,",
    "@xmath10 is uniquely specified by the context of the problem being studied .",
    "if this leads to a unique prior distribution @xmath13 , and when additionally a unique likelihood also arises , for example via exchangeability , an optimal bayesian analysis is possible , as defined in section [ introduction ] .",
    "it is often the case that the prior distributions that result from this line of reasoning are limits of conjugate families , making them easy to work with  this occurs in our results below , in which the corresponding posterior distributions are dirichlet .",
    "the above definition is intuitive , but not sufficiently general to be applicable to spaces of functions .",
    "there are multiple issues :    a.   in many cases , @xmath13 can not be taken to integrate to 1 , b.   probability distributions on spaces of functions do not always admit riemann - integrable densities , c.   @xmath10 may be defined via equivalence classes of transformations , leading to singular jacobians , and d.   infinite - dimensional measures that are non - normalizable are not well - behaved mathematically .    as a result",
    ", the above definition needs to be extended to a measure - theoretic setting .",
    "we call a transformation group @xmath10 acting on a measure space _ nonsingular _ if for @xmath14 with @xmath40 $ ] , we have @xmath45 , where @xmath46 denotes absolute continuity of measures .",
    "let @xmath10 be a nonsingular transformation group acting on a measure space .",
    "we say that a measure @xmath13 is _ invariant with respect to @xmath10 _ if for any @xmath14 with @xmath40 $ ] and for any measurable subset @xmath41 we have @xmath47 where @xmath48 is the domain of @xmath13 , @xmath49 is the indicator function of the set @xmath41 , and @xmath50 is the radon - nikodym derivative of @xmath13 with respect to @xmath12 .",
    "it can be seen by taking @xmath13 to be absolutely continuous with respect to the lebesgue measure that equation ( [ invariant-1 ] ) is a direct extension of equation ( [ invariant-0 ] ) .",
    "we would ultimately like to extend the above definition to the infinite - dimensional setting .",
    "doing so directly is challenging , because @xmath13 may be non - normalizable , in which case kolmogorov s consistency theorem and other analytic tools for infinite - dimensional probability measures do not apply . here",
    "we sidestep this problem by instead extending the definition of invariance to allow us to define a sequence of _ approximately _ invariant measures , which in our setting can be taken to be probability measures .",
    "to do so , two additional definitions are needed .",
    "let @xmath10 be a nonsingular transformation group acting on a measure space .",
    "we say that a sequence of measures @xmath51 is _",
    "@xmath15-invariant with respect to @xmath10 _ if for any @xmath14 with @xmath52 $ ] and each measurable subset @xmath41 , the inequality @xmath53 implies that @xmath54 where @xmath55 is the invariant measure under @xmath10 , @xmath56 is a function , @xmath57 implies that @xmath58 , and @xmath48 is the domain of @xmath59 for all @xmath15 .",
    "[ epsilon - invariant - process ] let @xmath60 be a sequence of stochastic processes , and let @xmath10 be a nonsingular transformation group",
    ". let @xmath61 be an arbitrary finite subset of the index set of the process , let @xmath62 be the finite - dimensional measure of @xmath63 under @xmath61 , and let @xmath64 be a finite - dimensional homomorphism of @xmath10 .",
    "we say that the sequence of processes @xmath63 is _ @xmath15-invariant _ if , for each @xmath61 , each @xmath65 with @xmath66 $ ] and each measurable subset @xmath41 , the inequality @xmath67 implies that @xmath68 where @xmath69 is the invariant measure under @xmath64 , @xmath70 is a function , @xmath57 implies that @xmath58 , @xmath71 is the domain of @xmath62 , and @xmath72 can be taken to be identical for all @xmath61",
    ".    definition [ epsilon - invariant - process ] has been explicitly chosen to formalize the notion of noninformativeness on a space of functions without constructing a non - normalizable infinite - dimensional measure .    to complete our assumptions , we need to specify @xmath10 .",
    "our definitions constitute a direct generalization of the transformation group used by jaynes to derive the haldane prior for @xmath73  see section [ introduction ] .",
    "[ group - functions ] let @xmath74{g \\ ! : s_\\infty \\goesto s_\\infty}\\ ] ] be a nonsingular group of measurable functions under composition acting on the infinite - dimensional simplex @xmath8 .",
    "[ group - vectors ] for non - negative integer @xmath38 and any vector @xmath75 of non - negative constants , let @xmath76 be a nonsingular group under composition acting on the @xmath38dimensional simplex @xmath77 , where each element @xmath14 represents an equivalence class of the transformations ( [ basic - transformation-1 ] ) .    note that @xmath78 is a @xmath38-dimensional homomorphism of @xmath79  we use this property in our proofs below .",
    "it can also readily be seen that for any @xmath11 , the constants @xmath80 are only determined up to proportionality .    for each @xmath81 and @xmath40 $ ] ,",
    "the radon - nikodym derivative of @xmath13 with respect to @xmath12 is @xmath82    let @xmath83 be lebesgue measure on the @xmath38-dimensional probability simplex , and define @xmath84 $ ] .",
    "note first that @xmath85 .",
    "note also that @xmath86 because the same transformation @xmath11 is used in defining @xmath12 and @xmath87 .",
    "then , note that @xmath88 and hence it suffices to consider the transformation @xmath11 applied to the lebesgue measure .",
    "consider an arbitrary hypercube @xmath89 .",
    "we have @xmath90 where @xmath91 are 1-dimensional lebesgue measures , for which we have that @xmath92 where @xmath93 $ ] is the 1-dimensional projection of the hypercube @xmath89 in dimension @xmath94 .",
    "consider now the transformation @xmath11 .",
    "we may decompose @xmath11 into @xmath95 and @xmath96 where d & : ( _ 1, .. ,_p ) ( c_1 _ 1, .. ,c_p _ p ) & n & : ( _ 1, .. ,_p ) .",
    "now consider the effect of @xmath95 and @xmath96 on @xmath91 .",
    "we have _ i [ d(b_i ) ] & = c_i(b_i - a_i ) & & & _ i [ n(b_i ) ] & = hence @xmath97 = \\frac{c_i(b_i - a_i)}{\\sum_{j=1}^p c_j(b_j - a_j ) } \\,.\\ ] ] therefore @xmath98 = \\prod_{i=1}^p \\frac{c_i(b_i - a_i)}{\\sum_{j=1}^p c_j(b_j - a_j)}\\ ] ] and we can compute the ratio @xmath99}{\\lambda(b ) } = \\prod_{i=1}^p \\frac{c_i(b_i - a_i)}{\\sum_{j=1}^p c_j(b_j - a_j ) } \\sbr{\\prod_{i=1}^p ( b_i - a_i)}^{-1 } = \\frac{\\prod_{i=1}^p c_i}{\\sbr{\\sum_{i=1}^p c_i(b_i - a_i)}^p } \\,.\\ ] ] this holds for all @xmath89 , hence the radon - nikodym derivative is just @xmath100 which is the desired result .",
    "since we are working with non - normalizable measures as improper priors , we can not rigorously talk about their probability densities .",
    "in many cases , such improper priors can be shown to be limits of families of conjugate priors for which the limiting posterior distribution is well - defined , making them usable in practice . to make our discussion of improper priors rigorous , we need the following definition .",
    "let @xmath13 be a measure on @xmath101 ( for @xmath38 a positive integer ) such that @xmath102 , where @xmath83 is lebesgue measure on @xmath101 .",
    "suppose that the radon - nikodym derivative of @xmath13 with respect to @xmath83 is riemann - integrable , and define a family of functions equal to the radon - nikodym derivative up to a proportionality constant .",
    "we call any function in this family a",
    "_ generalized density _ of @xmath13 .      in the following results",
    ", we will assume that @xmath103 is a probability vector of dimension @xmath104 .",
    "@xmath79 and @xmath78 will the transformation groups identified in definitions [ group - functions ] and [ group - vectors ] , respectively .",
    "@xmath105 will denote the dirichlet distribution under the alternative parametrization based on concentration parameter @xmath106 and mean probability vector @xmath18 .",
    "this is equivalent to the usual parameterization in terms of concentration vector @xmath107 by the identity @xmath108  we refer to this as the @xmath109 distribution .",
    "similarly , @xmath110 will refer to the dirichlet process with concentration parameter @xmath106 and mean function @xmath18 .",
    "we will refer to the improper priors defined via the limits as @xmath111 of @xmath105 and @xmath110 for arbitrary @xmath18 as @xmath112 and @xmath113 , respectively .",
    "we are now ready to introduce our first result .",
    "the argument below is a direct generalization of the line of reasoning in @xcite : the haldane prior obtained is a special case of our result for @xmath73 .",
    "[ epsilon - invariance ] among the class of measures that admit generalized densities , the measure @xmath13 with generalized density @xmath114 which we call @xmath112 , is the unique invariant measure under @xmath78 .",
    "an invariant measure @xmath13 under @xmath78 needs to satisfy the equation @xmath115 where @xmath77 is the @xmath38-dimensional simplex and @xmath116 $ ] for some @xmath81 . since @xmath13 is assumed to admit a generalized density , we can rewrite ( [ theorem-10 - 1 ] ) as a riemann integral .",
    "in addition , we substitute in the transformation and radon - nikodym derivative , and get @xmath117 this formula needs to hold for all measurable sets @xmath41 , and hence the functions inside the integrals need to be equal pointwise .",
    "this yields the functional equation @xmath118 which will be the main subject of further study .",
    "this is a multivariate functional equation that at first may appear fearsome , but is in fact solvable via elementary methods . to solve it , recognizing that ( [ functional - equation-1 ] ) must hold for all probability vectors @xmath103 and all vectors @xmath119 of positive constants @xmath80 , we set & = & & & _ i=1^p c_i = 1 , which yields @xmath120 then , by swapping @xmath80 for @xmath121 , ( [ functional - equation-2 ] ) rearranges into @xmath122 since the numerator is not a function of any @xmath121 , and it can easily be checked that all such generalized densities are valid solutions to the original equation . thus ( [ functional - equation-3 ] ) is the functional equation s unique solution and therefore the unique invariant measure under @xmath78 .",
    "the same technique used to solve the functional equation in theorem [ epsilon - invariance ] can be used to prove a much stronger result : if the functional equation is true approximately , its solutions will approximate those of the exact equation . in the next result",
    "we make use of the definition of _ stability _ of a functional equation due to hyers , ulam and rassias ",
    "see @xcite for details .",
    "[ stability ] suppose we have @xmath123 then & < , & & & & .    by repeating the technique from the previous proof",
    ", we have @xmath124 which can be rewritten @xmath125 where the last inequality is strict because @xmath38 is a positive integer . letting @xmath126 we get @xmath127 which is the stability result desired .",
    "this suffices to prove our result for the dirichlet distribution .",
    "[ dirichlet - epsilon - invariance ] @xmath128 is an @xmath15-invariant measure under @xmath78 for all @xmath18 .    by repeating the steps of theorem [ epsilon - invariance ] and combining them with corollary [ stability ]",
    ", we obtain that @xmath128 is @xmath15-invariant under @xmath78 if and only if it satisfies & < & & & & . substituting in @xmath128 , and choosing the constant @xmath129 of the generalized density @xmath55 to be the same as for the dirichlet",
    ", we get @xmath130 where @xmath131 are the components of probability vector @xmath18 , and this expression simplifies to @xmath132 since @xmath133 for all @xmath94 , the product is upper bounded by @xmath134 and lower bounded by @xmath135 .",
    "thus the inequality holds near zero if @xmath136 for all @xmath137 , and since @xmath138 we get that , as @xmath57 , we can choose @xmath16 such that @xmath58 .",
    "thus , @xmath128 is @xmath15-invariant for all @xmath18 .",
    "we now extend theorem [ dirichlet - epsilon - invariance ] to get an analogous result for the dirichlet process .",
    "[ dp - epsilon - invariance ] @xmath17 is an @xmath15-invariant process under @xmath79 for all @xmath18 .",
    "consider an arbitrary finite - dimensional index @xmath61 with corresponding homomorphism @xmath64 and finite - dimensional measure @xmath62 .",
    "it follows from theorem [ dirichlet - epsilon - invariance ] that @xmath62 is @xmath15-invariant with @xmath139 this inequality depends only on @xmath129 , so it suffices to show that this constant can be bounded by another constant that is not a function of @xmath38 and approaches 0 .",
    "@xmath129 is the inverse multivariate beta function , which is a ratio of gamma functions .",
    "it is well known that @xmath140 where @xmath141 is the euler - mascheroni constant .",
    "therefore , we have @xmath142 as @xmath57 . thus , for each @xmath15 , we can choose a @xmath16 to satisfy the required expressions under all finite - dimensional index sets , and @xmath17 is therefore an @xmath15-invariant process .",
    "we conclude our theoretical investigation with a conjecture : the @xmath15-invariance of all finite - dimensional distributions with a uniform @xmath16 should suffice for invariance with respect to the original group acting on the infinite - dimensional space .",
    "[ conjecture ] a stochastic process is an @xmath15-invariant process if and only if the measure of its sample paths is an @xmath15-invariant measure .",
    "one approach to attempting a proof would involve appropriately extending kolmogorov s consistency theorem to @xmath143-finite infinite - dimensional measures . this can be done , but the notions involved are quite technical ",
    "see @xcite for more details .",
    "to see how our results may be applied , consider again the randomized controlled trial of section [ introduction ] , and suppose now that the outcome @xmath144 for participant @xmath94 in the experimental group is categorical with @xmath38 levels .",
    "under exchangeability , a minor extension of de finetti s theorem for dichotomous outcomes then yields that the likelihood can be expressed as @xmath145(1 , \\v{\\theta } ) \\ , , \\ ] ] in which mn@xmath146 is the multinomial distribution with parameters @xmath147 and @xmath34 .",
    "theorem [ epsilon - invariance ] implies that , modulo inherent abuse of notation under improper priors , @xmath148(0)\\ ] ] is the unique prior that obeys the fundamental invariance possessed by the problem  namely , invariance with respect to all transformations of probability vectors that preserve normalization .",
    "thus we have extended jaynes s result for binomial outcomes to the multinomial setting , yielding another instance of optimal bayesian analysis .",
    "generalizing to the setting where @xmath2 is an exchangeable sequence of real - valued outcomes , de finetti s most general representation theorem implies that @xmath149 is the unique likelihood . if little is known about @xmath5 , and it is therefore approximately invariant under all measurable functions ",
    "i.e. under @xmath79 , see definition [ group - functions ]  the prior given by theorem [ dp - epsilon - invariance ] is @xmath150(\\eps , f_0 ) \\,.\\ ] ] by the usual conjugate updating in the dirichlet - process setting , the posterior on @xmath5 given @xmath31 with the prior in ( [ dp - eps - f0 ] ) is @xmath151 \\del{\\eps + n , \\frac{\\eps}{\\eps + n } f_0 + \\frac{n}{\\eps+n } \\hat{f}_n } \\ , , \\ ] ] in which @xmath152 is the empirical cdf based on @xmath31 . since @xmath15 may be taken as close to zero as one wishes , it is natural to regard @xmath19\\del{n , \\hat{f}_n}\\ ] ] as an instance of approximately optimal bayesian analysis under all @xmath15 .",
    "conjecture [ conjecture ] would strengthen this assertion ",
    "provided @xmath113 can be rigorously constructed as an infinite - dimensional @xmath143-finite measure , which is beyond the scope of this work .",
    "though the simplicity of this analysis may at first make it seem limited , its appeal comes from its extremely general ability to characterize uncertainty .",
    "see , e.g. , @xcite for an example of a @xmath153 analysis in two randomized controlled trials in e - commerce , one with sample sizes in the tens of millions .",
    "bayesian analysis can not proceed without the specification of a stochastic model  prior and sampling distribution  relating known quantities to unknown quantities : data to parameters .",
    "one of the great challenges of applied statistics is that the model is not necessarily uniquely determined by the context of the problem under study , giving rise to model uncertainty , which if not assessed and correctly propagated can cause badly calibrated and unreliable inference , prediction and decision  see , e.g. , @xcite .",
    "perhaps the simplest way to avoid model uncertainty is to recognize settings in which it does not exist  situations where broad and simple mathematical assumptions , rendered true by problem context , lead to unique posterior distributions .",
    "our term for this is _ optimal bayesian analysis_. it seems worthwhile ( a ) to catalog situations in which optimal analysis is possible and ( b ) to work to extend the list of such situations  theorems [ epsilon - invariance ] and [ dp - epsilon - invariance ] are two contributions to this effort .",
    "we are grateful to daniele venturi , yuanran zhu , and catherine brennan for their thoughts on differential equations , which we originally used in a much longer and more complicated proof of the solution of our functional equation .",
    "we are additionally grateful to juhee lee for her thoughts on prior specification , and to thanasis kottas for his thoughts on dirichlet processes .",
    "membership on this list does not imply agreement with the ideas expressed here , nor are any of these people responsible for any errors that may be present ."
  ],
  "abstract_text": [
    "<S> in a given problem , the bayesian statistical paradigm requires the specification of a prior distribution that quantifies relevant information , about the unknowns of main interest , external to the data . in cases where little such information is available </S>",
    "<S> , the problem under study may possess an invariance under a transformation group that encodes a lack of information , leading to a unique prior . </S>",
    "<S> previous successful examples of this idea have included location - scale invariance under linear transformation , multiplicative invariance of the rate at which events in a counting process are observed , and the derivation of the haldane prior for a bernoulli success probability . in this paper </S>",
    "<S> we show that this method can be extended in two ways : ( 1 ) to yield families of approximately invariant priors , and ( 2 ) to the infinite - dimensional setting , yielding families of priors on spaces of distribution functions . </S>",
    "<S> our results can be used to describe conditions under which a particular dirichlet process posterior arises from an optimal bayesian analysis , in the sense that invariances in the prior and likelihood lead to one and only one posterior distribution .    _ </S>",
    "<S> keywords : _ bayesian nonparametrics , dirichlet process , functional equation , hyers - ulam - rassias stability , improper prior , invariance , optimal bayesian analysis , transformation group . </S>"
  ]
}