{
  "article_text": [
    "calibration of a multiple camera system ( mcs ) is an essential step in many computer vision tasks such as slam ( simultaneous localization and map ) , surveillance , stereo and metrology @xcite .",
    "both the intrinsic and extrinsic parameters of the mcs are required to be estimated before the mcs can be used .",
    "the intrinsic parameters @xcite describe the internal camera geometric and optical characteristics of each camera in the mcs . in a rigid multiple camera system ( rmcs ) , the cameras are fixed to each other . the extrinsic parameters @xcite of a rmcs describe the relative pose ( the relative 3-d position and orientation , totally , six degrees of freedom ) between the cameras in the mcs .",
    "calibration methods of the intrinsic parameters of a camera are well established @xcite .",
    "calibration methods for the extrinsic parameters of a rmcs are also widely studied .",
    "for instance , maas proposed an automatic rmcs calibration technique with a moving reference bar which can be seen by all cameras @xcite .",
    "antone and teller developed an algorithm which recovers the relative poses of cameras by overlapping portions of the outdoor scene @xcite .",
    "baker and aloimonos presented rmcs calibration methods using calibration objects such as a wand with leds or a rigid board with known patterns @xcite .",
    "dornaika proposed a stereo rig self - calibration method by the monocular epipolar geometries and geometric constraints of a moving rmcs , in which only the feature correspondences between the monocular images of each camera are required @xcite .        in hand - eye calibration",
    ", it is demonstrated that when a sensor is mounted on a moving robot hand , the relationship between the sensor coordinate system and hand coordinate system can be calculated by the motion information of the hand and the sensor @xcite .",
    "one example of using kinematic information of the cameras for rmcs is discussed by caspi and irani @xcite , they indicated that if the cameras of a non - overlapping view rmcs are close to each other and share a same projection center , their recorded image sequences can be aligned effectively by the estimated transformations inside each image sequence .",
    "however , in some types of mcs , the relative poses between the cameras are not fixed , hence the calibration methods for the rmcs can not be used directly . in figure",
    "[ fig : robot ] , a novel application of limb pose estimation by attaching cameras on the arms of a robot is shown . on each arm of the robot ,",
    "two cameras are articulated to each other through the elbow joint of the arm . when the robot moves , the relative pose between the cameras may change , while , the coordinate of the elbow joint relative to each camera attached on the corresponding arm is invariant . in this paper ,",
    "such a type of mcs is named as articulated camera system ( acs ) .",
    "the joint of the elbow is named as the _ joint _ in the acs .",
    "acss can be easily found in the real world , such as camera systems attached on human , robots and animals . before using an acs",
    ", it has to be calibrated .",
    "however , there are still some unsolved problems : ( i ) in an acs with overlapping view , traditional calibration methods can not estimate the positions of the joints in the acs .",
    "( ii ) in a non - overlapping view acs , neither the positions of the joints in the acs nor the relative poses between the cameras in the acs can be estimated by traditional calibration methods .",
    "these considerations in mind motivate us to develop the technologies in this paper .",
    "the rest of this paper are organized as follows : section [ sec : overlap ] and [ sec : non_overlap ] analysis the constraints in a moving acs .",
    "the corresponding calibration methods are proposed .",
    "section [ sec : simulation ] and [ sec : real ] evaluate the proposed method by simulation and real experiment . in section [ sec : conclusion ] , a brief conclusion and the future plan are presented .",
    "+    suppose two rigid objects are articulated at joint o and two cameras ( camera a and b ) are fixed on the two rigid objects respectively ( see figure [ fig : articulate ] ) .",
    "let @xmath0 be the coordinate system of camera a , @xmath1 the coordinate system of camera b. suppose there are enough feature correspondences between the cameras so that the pose of @xmath0 and @xmath1 referring to the same coordinate system @xmath2 can be estimated",
    ". therefore , the relative pose between @xmath0 and @xmath1 is known .",
    "we want to find the position of o in the acs .",
    "let @xmath3 and @xmath4 be the euclidean transformation matrixes describe the @xmath0 and @xmath1 relative to @xmath2 , so that for any point @xmath5 : @xmath6                             \\left[\\begin{array}{c}\\bar{p}_w\\\\1\\end{array}\\right]\\ ] ] @xmath7                           \\left[\\begin{array}{c}\\bar{p}_w\\\\1\\end{array}\\right]\\ ] ] , where @xmath8 is the @xmath9 rotation matrix , @xmath10 is a @xmath11 vector , @xmath12 , @xmath13 and @xmath14 are the homogenous coordinates of the 3-d point @xmath5 relative to @xmath2 , @xmath0 and @xmath1 respectively , @xmath15 is a @xmath11 vector .    according to equations ( [ eq : h_aw ] ) and ( [ eq : h_bw ] ) : @xmath16 @xmath17 @xmath18 \\left[\\begin{array}{c }          \\bar{p}_a \\\\          1        \\end{array}\\right ] -   \\left[\\begin{array}{c c } \\mathbf{r}_{bw}^t & -\\mathbf{r}_{bw}^t t_{bw}\\\\ 0 & 1 \\end{array}\\right ] \\left[\\begin{array}{c }          \\bar{p}_b \\\\          1        \\end{array}\\right ] = 0\\ ] ] @xmath19 , where @xmath20 is the transpose of @xmath8 .",
    "suppose the acs performed @xmath21 transformations .",
    "let @xmath22 and @xmath23 be the euclidean transformation matrixes describe the @xmath0 and @xmath1 relative to @xmath2 after the @xmath24-th transformation of the acs . according to equation ( [ eq : papb ] ) : @xmath25    let @xmath26^t$ ] , where @xmath27 and @xmath28 are the coordinates of the joint o relative to @xmath0 and @xmath1 respectively .",
    "equation ( [ eq : oab ] ) can be rewritten as : @xmath29                           \\tilde{o } =                           ( \\mathbf{r}_{aw}^i)^t t_{aw}^i - ( \\mathbf{r}_{bw}^i)^t t_{bw}^i\\ ] ]    since camera a and b are fixed on the articulated rigid objects , @xmath30 is invariant during the transformation of the acs .",
    "the transformations ( @xmath31 , @xmath32 , @xmath33 and @xmath34 for @xmath35 $ ] ) of the camera coordinate systems are calculated by the projected image sequences .",
    "we propose that @xmath30 can be estimated by a least squares method , when the acs has moved to many different positions and captured enough samples of @xmath31 , @xmath32 , @xmath33 and @xmath34 .",
    "+ the above derivation shows that although the location of the joint @xmath36 in world coordinates is not constant , it equals @xmath37 or @xmath38 because the cameras can not move completely independent as they are connected with a joint .",
    "the joint location can be calculated by the 1d subspace intersection of the camera transformation matrices .",
    "in many situations , there is no overlapping view between the cameras in an acs . and the lack of common features makes the calibration method proposed in section [ sec : overlap ] become invalid ( see figure [ fig : non_overlap ] ) . moreover , since the relative pose between the cameras in the acs can not be estimated by the overlapping views , the calibration of the relative poses between the non - overlapping view cameras is also required . in this section ,",
    "a calibration method based on the ego - motion information of the cameras in an acs is discussed .",
    "let @xmath39 and @xmath40 be the coordinate systems of camera a and b respectively at the initial state ( time @xmath41 ) .",
    "suppose the acs performs @xmath21 transformations .",
    "since the coordinate of the joint o relative to camera a is fixed during the transformation of the acs . at time @xmath42 , we have : @xmath43{o}_{a}\\ ] ] , where @xmath44 is the euclidean transformation matrix of camera a at time @xmath24 relative to @xmath45 .",
    "@xmath46 and @xmath47 describe the orientation and origin of camera a at time @xmath24 relative to @xmath45 .",
    "also @xmath48 is the coordinate of point o at initial state relative to @xmath45 , and @xmath49 is the coordinate of point o at time @xmath24 relative to @xmath45 .",
    "if the position of the joint o relative to @xmath45 is fixed during the transformations of the acs , we have : @xmath50 , @xmath51 $ ] . for @xmath24-th transformation of the acs , according to equation ( [ eq : oai ] ) :    @xmath52{o}_{a}\\ ] ]    @xmath53    let @xmath54^t$ ] , @xmath55^t$ ] , we have : @xmath56    since the transformations ( @xmath57 and @xmath58 , @xmath59 $ ] ) of camera a can be calculated by the projected image sequence .",
    "we propose @xmath27 can be estimated by a least squares method .",
    "similarly , @xmath28 can also be estimated .",
    "therefore , @xmath48 and @xmath60 are recovered .",
    "if the different segments of the articulated camera system ( acs ) are connected by 1d rotational joints ( connected by point rotational joints ) and the acs can perform general transformations , the solution of the joint pose estimation is unique :    for the joint pose estimation method using special motion ( in section [ sec : special_motion ] ) .",
    "suppose the solution of the joint pose estimation is not unique , there must exist at least two different 3d points @xmath61 and @xmath62 satisfy equation ( [ eq : fixed_o ] ) .",
    "we have : @xmath63 and @xmath64 .",
    "therefore , any point @xmath65 will also satisfy equation ( [ eq : fixed_o ] ) , where @xmath66 is an arbitrary scalar . according to the definition of @xmath15 , @xmath15 is the point on the line passing through the points @xmath61 and @xmath62 .",
    "since @xmath15 satisfy equation ( [ eq : fixed_o ] ) represents that the position of the point @xmath5 relative to the camera in the acs is invariant during the transformation of the acs , it means the different segments of acs are connected by the 2d rotational axis instead of the 1d rotational joints .",
    "the position of the points on the 2d rotational axis relative to the camera in the acs is invariant during the transformation of the acs .",
    "however , it conflicts with the assumption .",
    "similarly , the uniqueness of the joint pose estimation method using overlapping views ( in section [ sec : overlap ] ) can also be verified .",
    "let @xmath67 be the euclidean transformation matrix between @xmath39 and @xmath40 , so that for any point @xmath5 :    @xmath68{p}_{a } = \\mathbf{h}_{ba}p_{a}\\ ] ]    , where @xmath13 and @xmath14 are the homogenous coordinate of point @xmath5 relative to @xmath39 and @xmath40 respectively . + the relative pose ( @xmath69 and @xmath70 ) between @xmath39 and @xmath40 is defined as : @xmath71 @xmath72    let @xmath73 be the coordinate of joint o at time @xmath24 relative to @xmath74 . since the coordinate of the joint o relative to camera b is invariant : @xmath75o_b \\nonumber\\\\ & = & \\left [ { { \\begin{array}{cc }   { \\mathbf{r}_b^i }   & { t_b^i }   \\\\   { 0 }   & { 1 }   \\\\ \\end{array } } } \\right]\\left [ { { \\begin{array}{cc }   \\mathbf{r}_{ba }   & t_{ba }   \\\\   { 0 }   & { 1 }   \\\\ \\end{array } } } \\right]o_{a } \\nonumber\\\\&=&\\left [ { { \\begin{array}{cc }   { \\mathbf{r}_b^i \\mathbf{r}_{ba } }   & \\mathbf{r}_b^i t_{ba } + t_b^i \\\\   { 0 }   & { 1 }   \\\\ \\end{array } } } \\right]o_{a}\\end{aligned}\\ ] ]    according to equations ( [ eq : oai ] ) and ( [ eq : ba_relation ] ) : @xmath76 \\left [ \\begin{array}{cc }   \\mathbf{r}_a^i & t_a^i\\\\   { 0 }   & { 1 }   \\\\ \\end{array }   \\right]o_{a } \\nonumber\\\\ & = & \\left [ { { \\begin{array}{cc }   \\mathbf{r}_{ba } { \\mathbf{r}}_a^i   & { \\mathbf{r}_{ba}t_a^i + { t_{ba}}}\\\\   { 0 }   & { 1}\\\\ \\end{array } } } \\right]{o}_{a}\\end{aligned}\\ ] ]    according to equations ( [ eq : ob1 ] ) and ( [ eq : ob1_ab ] ) : @xmath77\\left [ { { \\begin{array}{c }   \\bar{o}_a   \\\\   { 1 }   \\\\ \\end{array } } } \\right ] = \\left [ { { \\begin{array}{cc }   { \\mathbf{r}_{ba}\\mathbf{r}_a^i }   & \\mathbf{\\mathbf{r}}_{ba}t_a^i + { t_{ba}}\\\\   { 0 }   & { 1 }   \\\\ \\end{array } } } \\right]\\left [ { { \\begin{array}{c }   \\bar{o}_a   \\\\   { 1 }   \\\\ \\end{array } } } \\right]\\ ] ] @xmath78 = \\left [ { { \\begin{array}{cc }   { \\mathbf{r}_{ba}\\mathbf{r}_a^i \\bar{o}_a + \\mathbf{r}_{ba}t_a^i + t_{ba } } \\\\   { 1 }   \\\\ \\end{array } } } \\right]\\ ] ]    @xmath79    since @xmath27 can be estimated by the method discussed in section [ sec : recover_pose ] , the @xmath80 and @xmath81 can be estimated by a least square method , when the acs perform enough general motions .    in our simulation and real experiment ,",
    "the estimated @xmath82 is refined by a method discussed in @xcite .",
    "then the roll , pitch and yaw corresponding to the @xmath82 are estimated according to the definition of the rotation matrix @xcite .",
    "let @xmath83 , where @xmath84 @xmath85 and @xmath86 are the corresponding roll , pitch and yaw of @xmath80 , @xmath87 is a function from roll , pitch and yaw to the corresponding rotation matrix .",
    "then , the @xmath84 , @xmath85 , @xmath86 , @xmath81 and @xmath27 are optimized by minimizing the nonlinear error function : @xmath88 using a levenberg - marquardt method .",
    "finally , the @xmath82 is recovered from the optimized @xmath84 , @xmath85 and @xmath86 .",
    "the relative pose between the @xmath39 and @xmath40 is calculated by equations ( [ eq : r_define ] ) and ( [ eq : t_define ] ) .",
    "the non - overlapping view acs calibration method discussed above depends on the ego - motion information of the cameras in the acs . however , if the model of the scene is unknown , the estimated ego - translations of the cameras may be scaled by different unknown scale factors .",
    "these unknown scale factors must be considered in the extrinsic calibration process .",
    "+      let @xmath89 and @xmath90 be the true ego - translation of camera a and b in the world coordinate system , @xmath91 and @xmath92 be the estimated ego - translations of camera a and b found by an sfm method , @xmath93 and @xmath94 be the corresponding unknown scale factors .",
    "so that : @xmath95 @xmath96    let @xmath97 be the pose of the joint relative to @xmath0 calculated with the estimated motion .",
    "equation ( [ eq : oa_fixed_i ] ) can be rewritten as :    @xmath98    @xmath99    compare equation ( [ eq : scale_o ] ) with equation ( [ eq : oa_fixed_i ] ) , we have : @xmath100    let @xmath101 and @xmath102 be the extrinsic parameters calculated using the estimated motions and joint pose . equation ( [ eq : cst_non_overlap ] ) can be rewritten as :    @xmath103    according to equation ( [ eq : mu_a ] ) , ( [ eq : mu_b ] ) , ( [ eq : scale_o_mu ] ) and ( [ eq : scale_cst_non_overlap ] ) :    @xmath104    @xmath105",
    "let : @xmath106 @xmath107    equation ( [ eq : scale_cst_2 ] ) can be rewritten as : @xmath108    since the equations ( [ eq : scale_cst_3 ] ) and ( [ eq : cst_non_overlap ] ) are exactly the same , we have :    @xmath109    @xmath110    therefore :    @xmath111    @xmath112    where @xmath113 . equations ( [ eq : factor_r_pi ] ) and ( [ eq : factor_t_pi ] ) show that the estimated rotation matrix @xmath101 will be scaled by the relative scale factor ( the ratio of the scale factors of the cameras ) and the estimated relative translation will be scaled by the same scale factor of camera @xmath114 . in the next section , we will discuss the estimation of the relative scale factor .",
    "let @xmath115 , where @xmath8 is a @xmath116 rotation matrix and @xmath117 , @xmath118 is an unknown scale factor , @xmath119 is a @xmath120 unknown noise matrix .",
    "we want to recover @xmath8 and @xmath118 from @xmath121 . according to the definition",
    ", we have : @xmath122    where @xmath123 .",
    "let the singular value decomposition of @xmath87 be @xmath124 , where @xmath125 . as illustrated in appendix c of @xcite , @xmath84 can be approximated by :    @xmath126    now , let the singular value decomposition of @xmath127 be @xmath128 , since @xmath129 , we have :    @xmath130    @xmath131    @xmath132    combine equations ( [ eq : app_rotation ] ) , ( [ eq : u ] ) and ( [ eq : v ] ) , the rotation matrix @xmath84 can be recovered by :    @xmath133    when noise @xmath119 is not significant , @xmath134 , the scale factor @xmath118 can be estimated by the following approximation : @xmath135 @xmath136    in short , if we have enough samples of @xmath57 , @xmath137 , @xmath138 and @xmath139 we can find @xmath140 , @xmath101 and @xmath102(see section [ sec : model_scale ] ) . then using the above formulas , in particular , equation ( [ eq : recover_roation ] ) and ( [ eq : phi ] ) , we can also find the real rotation ( @xmath80 ) and the relative scale factor @xmath141 .",
    "+ let @xmath142 , where @xmath84 , @xmath85 and @xmath86 are the corresponding roll , pitch and yaw of @xmath80 , @xmath87 is a function from roll , pitch and yaw to the corresponding rotation matrix . in our simulation and real experiment ,",
    "the estimated @xmath84 , @xmath85 , @xmath86 , @xmath102 and @xmath141 can be optimized by minimizing the nonlinear error function : @xmath143 using a levenberg - marquardt method . if the pose of the joint is calibrated with known scale factor ( @xmath144 is known ) , the scale factor @xmath93 can be estimated by equation ( [ eq : scale_o_mu ] ) .",
    "the scale factor @xmath94 can be calculated by @xmath145 . finally , the @xmath80 is recovered from the optimized @xmath84 , @xmath85 and @xmath86 .",
    "the relative pose between the @xmath39 and @xmath40 is calculated by equations ( [ eq : r_define ] ) and ( [ eq : t_define ] ) . therefore , a non - overlapping view acs can also be calibrated using scaled motion information from each camera in it .",
    "in this section , the proposed calibration methods are evaluated with synthetic transformation data .",
    "* setup and notations : * in each test , one acs with 2 cameras and 1 joint is generated randomly .",
    "in which , @xmath146 meters , @xmath147 meters .",
    "the generated acs performs @xmath148 random transformations .",
    "* performance of the calibration method for acs with overlapping views : * in the first simulation , the proposed algorithm is tested 100 times .",
    "zero mean gaussian noise is added to the transformation data of the cameras . the configuration , input and output of our simulation system are list as table [ tab : cio1 ] .",
    "since we assume there are overlapping views between the two cameras , the relative pose between them can be estimated by many existing methods as discussed in section [ sec : introduction ] .",
    "only the performance of joint pose estimation is evaluated in our simulation .",
    "the error of joint estimation are computed by :    @xmath149    , where @xmath27 is the ground truth , @xmath97 is the estimated position of joint o relative to camera a. similarly , @xmath28 is the ground truth , @xmath150 is the estimated position of joint o relative to camera b. the corresponding results are shown in figure [ fig : joint ] .",
    "ll + no . of cameras in the acs & 2 + no . of joints in the acs & 1 + random transformations per test ( n ) & 30 + number of tests & 100 +   + rotations of cameras ( @xmath31 , @xmath32 ) & @xmath151 + translations of cameras ( @xmath33 , @xmath34 ) & @xmath151 +   +   +   +   +   +    [ cols=\"^,^ \" , ]",
    "in this paper , an acs calibration method is developed .",
    "both the simulation and real experiment show that the pose of the joint in an acs can be estimated robustly . when there is no overlapping view between the cameras in an acs , the joint pose and the relative pose between the cameras can also be calculated .",
    "the trajectory of an acs can be recovered after the acs is calibrated .",
    "the proposed calibration method requires only the image sequences recorded by the cameras in the acs .",
    "a scale factor estimation algorithm is proposed to deal with unknown scale factors in the estimated translation information of the cameras in an acs . in the real experiment ,",
    "the intrinsic and extrinsic parameters of the acs are calibrated using the same image sequences simultaneously .",
    "our future plan may focus on using an acs attached on different parts of human body to track the motion of the human .",
    "we foresee that if calibration of articulated cameras become a simple routine , researchers will find many novel and interesting applications for such a camera system ."
  ],
  "abstract_text": [
    "<S> multiple camera systems ( mcs ) have been widely used in many vision applications and attracted much attention recently . </S>",
    "<S> there are two principle types of mcs , one is the rigid multiple camera system ( rmcs ) ; the other is the articulated camera system ( acs ) . in a rmcs , the relative poses ( relative 3-d position and orientation ) between the cameras </S>",
    "<S> are invariant . </S>",
    "<S> while , in an acs , the cameras are articulated through movable joints , the relative pose between them may change . </S>",
    "<S> therefore , through calibration of an acs we want to find not only the relative poses between the cameras but also the positions of the joints in the acs .    </S>",
    "<S> although calibration methods for rmcs have been extensively developed during the past decades , the studies of acs calibration are still rare . in this paper , we developed calibration algorithms for the acs using a simple constraint : the joint is fixed relative to the cameras connected with it during the transformations of the acs . </S>",
    "<S> when the transformations of the cameras in an acs can be estimated relative to the same coordinate system , the positions of the joints in the acs can be calculated by solving linear equations . however , in a non - overlapping view acs , only the ego - transformations of the cameras and can be estimated . </S>",
    "<S> we proposed a two - steps method to deal with this problem . in both methods , </S>",
    "<S> the acs is assumed to have performed general transformations in a static environment . </S>",
    "<S> the efficiency and robustness of the proposed methods are tested by simulation and real experiments . in the real experiment , </S>",
    "<S> the intrinsic and extrinsic parameters of the acs are obtained simultaneously by our calibration procedure using the same image sequences , no extra data capturing step is required . </S>",
    "<S> the corresponding trajectory is recovered and illustrated using the calibration results of the acs . since the estimated translations of different cameras in an acs may scaled by different scale factors , a scale factor estimation algorithm is also proposed . to our knowledge </S>",
    "<S> , we are the first to study the calibration of acs . </S>"
  ]
}