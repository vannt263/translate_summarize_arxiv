{
  "article_text": [
    "hydraulic tomography ( ht ) is a method for characterizing the subsurface that consists of applying pumping in wells while aquifer pressure ( head ) responses are measured . using the data collected at various locations , important aquifer parameters ( e.g. , hydraulic conductivity and specific storage )",
    "are estimated .",
    "an example of such a technique is transient hydraulic tomography ( reviewed in  @xcite ) .",
    "oscillatory hydraulic tomography ( oht ) is an emerging technology for aquifer characterization that involves a tomographic analysis of oscillatory signals .",
    "here we consider that a sinusoidal signal of known frequency is imposed at an injection point and the resulting change in pressure is measured at receiver wells .",
    "consequently , these measurements are processed using a nonlinear inversion algorithm to recover estimates for the desired aquifer parameters .",
    "oscillatory hydraulic tomography has notable advantages over transient hydraulic tomography ; namely , a weak signal can be distinguished from the ambient noise and by using signals of different frequencies , we are able to extract additional information without having to drill additional wells .    using multiple frequencies for oht has the potential to improve the quality of the image .",
    "however , it involves considerable computational burden .",
    "solving the inverse problem , i.e. reconstructing the hydraulic conductivity field from pressure measurements , requires several application of the forward ( and adjoint ) problem for multiple frequencies . as we shall show in section  [ sec : application ] , solving the forward ( and adjoint ) problem involves the solution of shifted systems for multiple frequencies . for finely discretized grids , the cost of solving the system of equations corresponding to each frequency can be high to the extent that it might prove to be computationally prohibitive when many frequencies are used , for example , on the order of @xmath0 .",
    "the objective is to develop an approach in which the cost of solving the forward ( and adjoint ) problem for multiple frequencies is not significantly higher than the cost of solving the system of equations for a single frequency - in other words , the cost should depend only weakly on the number of frequencies .",
    "direct methods , such as sparse lu , cholesky or ldl@xmath1 factorization , are suited to linear systems in which the matrix bandwidth is small , so that the fill - in is somewhat limited .",
    "an additional difficulty that direct methods pose is that for solving a sequence of shifted systems , the matrix has to be re - factorized for each frequency , resulting in a considerable computational cost .",
    "by contrast , krylov subspace methods for shifted systems are particularly appealing since they exploit the shift - invariant property of krylov subspaces  @xcite to obtain approximate solutions for all frequencies by generating a single approximation space that is shift independent .",
    "several algorithms have been developed for dealing with shifted systems .",
    "some are based on lanczos recurrences for symmetric systems  @xcite ; others use the unsymmetric lanczos  @xcite , and some others use arnoldi iteration  @xcite . shifted systems also occur in several other applications such as control theory , time dependent partial differential equations , structural dynamics , and quantum chromodynamics ( see  @xcite and references therein ) . hence , several other communities can benefit from advances in efficient solvers for shifted systems .",
    "the krylov subspace method that we propose is closest in spirit to  @xcite .",
    "however , as we shall demonstrate , we have extended their solver significantly .    *",
    "contributions * : our major contributions can be summarized as follows :    * we have extended the flexible arnoldi algorithm discussed in  @xcite for shifted systems of the form @xmath2 to systems of the form @xmath3 for @xmath4 that employs multiple preconditioners of the form @xmath5 .",
    "in addition , we provide some analysis for the convergence of the solver . *",
    "when an iterative solver is used to apply the preconditioner , we derive an error analysis that gives us stopping tolerances for monitoring convergence without constructing the full residual . *",
    "our motivation for the need for fast solvers for shifted systems comes from oscillatory hydraulic tomography .",
    "we describe the key steps involved in inversion for oscillatory hydraulic tomography , and discuss how the computation of the jacobian can be accelerated by the use of the aforementioned fast solvers .    * limitations * : the focus of this work has been on the computational aspects of oscillatory hydraulic tomography .",
    "although the initial results are promising , several issues remain to be resolved for application to realistic problems of oscillatory hydraulic tomography .",
    "for example , we are inverting for the hydraulic conductivity assuming that the storage field is known . in practice ,",
    "the storage is also unknown and needs to be estimated from the data as well .",
    "moreover , simulating realistic conditions ( higher variance in the log conductivity field , and adding measurement noise in a realistic manner ) may significantly improve the performance with the addition of information from different frequencies .",
    "we will deal with these issues in another paper .",
    "the paper is organized as follows . in section",
    "[ sec : krylov ] , we discuss the krylov subspace methods for solving shifted linear systems of equations based on the arnoldi iteration using preconditioners that are also shifted systems . in section  [ sec : geneigen ] , we discuss the convergence of the iterative solver and its connection to the convergence of the eigenvalues of the generalized eigenvalue problem @xmath6 . in section",
    "[ sec : inexact ] , we discuss an error analysis when an iterative method is used to invert the preconditioner matrices . in section  [ sec : application ] , we discuss the basic constitutive equations in oht , which can be expressed as shifted linear system of equations and discuss the geostatistical method for solving inverse problems .",
    "finally , in section  [ sec : numerical ] we present some numerical results on systems of shifted systems and then discuss numerical results involving the inverse problem arising from oht .",
    "we observe significant speed - ups using our krylov subspace solver .",
    "the goal is to solve systems of equations of the form @xmath7    note that @xmath8 , for @xmath9 are ( in general ) complex shifts .",
    "we assume that none of these systems are singular .",
    "in particular , for our application , both @xmath10 and @xmath11 are stiffness and mass matrices respectively and are positive definite , but our algorithm only requires that they are invertible . by using a finite volume or",
    "lumped mass approach  @xcite , the mass matrices become diagonal but this assumption is not necessary .",
    "later , in sections  [ sec : forward ] and  [ sec : sensitivity ] , we will show how such equations arise in our applications .",
    "( 0,0 ) rectangle ( 10 , 10 ) ; ( a ) at ( 5,5 ) @xmath12 ; ( 10.5 , 0 ) rectangle ( 13.5 , 10 ) ; ( vm ) at ( 12 , 5 ) @xmath13 ; ( eq ) at ( 14.5 , 5 ) @xmath14 ; ( 15.5,0 ) rectangle ( 18.5 , 10 ) ; ( vm1 ) at ( 17,5 ) @xmath13 ; ( 18.7,0 ) rectangle ( 19,10 ) ; ( vm1 ) at ( 20,-0.5 ) @xmath15 ;    ( 20,10 ) ",
    "( 23 , 10 )  ( 23,7 ) ",
    "( 22.6 , 7 )  ( 20,9.6 ) ",
    "( 20 , 10 ) ; ( hm ) at ( 22,9 ) @xmath16 ;    ( 22.8,6.7 ) circle [ radius = 0.2 ] ; ( hm1 m ) at ( 24.3,5.6 ) @xmath17 ;    as a brief introduction , we review the krylov based iterative solvers for the system of equations @xmath18 . in particular , we describe the variants generated by arnoldi iteration , such as full orthogonalization method ( fom ) and generalized minimum residual method ( gmres ) .",
    "krylov solvers typically generate a sequence of orthonormal vectors @xmath19 that are orthonormal .",
    "these vectors form a basis for the krylov subspace : @xmath20 at the end of the @xmath21th iteration , a typical relation is obtained of the form ( see figure  [ fig : arnoldi ] ) , @xmath22 where , @xmath23 $ ] and @xmath24 , @xmath25 with @xmath26 and @xmath27 is an upper hessenberg matrix .",
    "then , an approximate solution to the system @xmath18 by searching for a solution of the form @xmath28 , where @xmath29 is chosen such that it minimizes the residual @xmath30 which , leads to gmres subproblem , @xmath31 or an oblique projection @xmath32 which leads to the fom subproblem @xmath33 as @xmath21 increases , the cost per iteration increases at least as @xmath34 and the memory costs increase as @xmath35@xcite .",
    "the standard remedies to reducing the number of iterations are 1 ) using an appropriate preconditioner , 2 ) truncating the orthogonalization in the arnoldi algorithm and 3 ) restarting the arnoldi algorithm periodically .",
    "an interesting property of the krylov subspaces is that they are shift - invariant . in other words , @xmath36 .",
    "therefore , the same krylov basis generated for the system @xmath37 can be effectively used to solve shifted systems of the form @xmath38 .",
    "the strategy for solving the shifted systems is therefore , to first generate a basis that is applicable to all systems , and then use the shift - invariant property ( for a detailed review , see @xcite and references therein ) to solve a smaller subproblem of the form   or  . the same idea can be extended to systems of the form   using a preconditioner of the form @xmath5",
    "@xcite , which solves for multiple shifted systems roughly at the cost of a single system",
    ". however , in practice , the number of iterations taken can often be large , especially for large matrices arising from realistic applications .    in order to minimize the number of iterations ,",
    "meerbergen  @xcite proposes a left preconditioner of the form @xmath39 that is factorized and inverted using a direct solver .",
    "the application of @xmath40 to a vector is , in general , not cheap but the spectrum of @xmath41 is often more favorable , which results in fast convergence of the krylov methods in just a few iterations  @xcite .",
    "this form of preconditioning has its roots in solving large - scale generalized eigenvalue problems and is known as _ cayley transformation _  @xcite . in  @xcite ,",
    "the authors provide some analysis for choosing the best value of @xmath42 that optimally preconditions all the systems .",
    "however , we observed that ( also , see  @xcite ) using a single preconditioner for all the systems may not yield optimal convergence for all systems .",
    "in  @xcite , the authors propose a flexible arnoldi method for shifted systems that uses different values of @xmath42 resulting in different preconditioners at each iteration .",
    "this can potentially reduce the number of iterations for all the shifted systems .",
    "before we describe our flexible algorithm in section  [ sec : flexibleprecond ] , we will derive the right preconditioned version of krylov subspace method for shifted systems .",
    "this serves two purposes - it motivates our algorithm , while clarifying some of the notation .      as mentioned earlier , we will review the right preconditioned version of the krylov subspace algorithm for shifted systems . following the approach in  @xcite , we solve the system of equations   using a shifted right preconditioner of the form @xmath43 @xmath44 for @xmath9 .",
    "we have the following identity that @xmath45    using the identity in equation  , we have the following shift - invariance property @xmath46 .",
    "note that @xmath47 is independent of @xmath48 .",
    "this shift - invariance property suggests an efficient algorithm for solving the system of equations  . there is a distinct advantage in using iterative solvers for shifted systems",
    "; the expensive step of constructing the basis for the krylov subspace is performed only once and using the shift - invariance property of the krylov subspace , the sub - problem for each shift in algorithm  [ alg : shiftedsolve ] can be computed at a relatively low cost .",
    "@xmath11 and a right hand side @xmath49 .",
    "compute @xmath50 and @xmath51 choose @xmath42 and factorize @xmath52 define the @xmath53 matrix @xmath54 .",
    "set @xmath55 .",
    "compute @xmath56 @xmath57 @xmath58 compute @xmath59 @xmath60 .",
    "if @xmath61 stop @xmath62    the algorithm proceeds as follows : first , we run @xmath21 steps of the arnoldi algorithm on the matrix @xmath63 with the starting vector @xmath49 to get a basis for the krylov subspace @xmath64 .",
    "this is summarized in algorithm  [ alg : arnoldi ] . at the end of @xmath21 steps of the arnoldi process , we construct two sets of vectors @xmath65 $ ] and @xmath66 $ ] , and an upper hessenberg matrix @xmath27 that satisfy the following relations ,    @xmath67    where , @xmath68 .",
    "multiplying the first equation by @xmath69 and adding it to the second equation gives us    @xmath70    in algorithm  [ alg : arnoldi ] , @xmath13 forms a basis for the krylov subspace @xmath71 .",
    "however , we seek solutions of the form @xmath72 ( with zero as the initial guess ) .",
    "now @xmath73 where @xmath74 is the space spanned by the vectors @xmath75 for @xmath76 . by minimizing the residual norm over all possible vectors in @xmath77",
    ", we obtain the generalized minimum residual ( gmres ) method for shifted systems , whereas by imposing the petrov - galerkin condition @xmath78 , we obtain the full orthogonalized method ( fom ) for shifted systems .",
    "this is summarized in algorithm  [ alg : shiftedsolve ] .",
    "it should be noted that the way we have described this algorithm , we need to store the vectors @xmath74 . in practice , this is not necessary .",
    "we chose to present it this way in order to have consistent notation with the flexible algorithm we will describe in subsection  [ sec : flexibleprecond ] .",
    "matrices @xmath10 and @xmath11 , a right hand side @xmath49 , @xmath79 choose @xmath42 , build @xmath52 and construct preconditioner .",
    "set @xmath80 .",
    "generate @xmath81 and @xmath74 using algorithm  [ alg : arnoldi ] .",
    "construct @xmath82 ( see equation  ) .",
    "fom : @xmath83 gmres : @xmath84 construct the approximate solution @xmath85 @xmath86 .    in  @xcite ,",
    "the spectrum of @xmath87 was analyzed and it was shown that the preconditioner @xmath88 is well suited only for values of frequencies @xmath48 near @xmath42 . however , the values of @xmath48 can be widely spread and a single preconditioner @xmath89 might not be a good choice for preconditioning all the systems . in section  [ sec :",
    "solverexperiments ] , we demonstrate an example in which a single preconditioner does not satisfactorily precondition all the systems . in  @xcite , the authors propose a flexible approach using a ( possibly ) different preconditioner at each iteration",
    ". we shall adopt this approach .",
    "we now describe our flexible krylov approach for solving shifted systems based on  @xcite which we have extended to the case @xmath90 .",
    "following  @xcite and  @xcite , we use a variant of gmres which allows a change in the preconditioner at each iteration . in algorithm  [ alg : arnoldi ] , we considered a fixed preconditioner of the form @xmath52 for a fixed @xmath42 .",
    "suppose we used a different preconditioner at each iteration of the form @xmath91 for @xmath76 , then instead of   we have , @xmath92 the algorithm is summarized in algorithm  [ alg : shiftedsolvemod ] . in this algorithm ,",
    "in addition to saving @xmath13 , we also save the matrix @xmath74 . if at every step in the flexible arnoldi algorithm we use the same value of @xmath42 , we are in the same position as in algorithm  [ alg : arnoldi ] .",
    "we have @xmath93 $ ] , @xmath94 and @xmath95 $ ] which satisfies @xmath96 .",
    "in addition , we also have the following relations    @xmath97    where , @xmath98 . multiplying   by @xmath99 and adding  , we obtain for @xmath4 @xmath100    @xmath11 and @xmath49 the right hand side , @xmath101 , @xmath50 and @xmath51 define the @xmath53 matrix @xmath102 .",
    "solve @xmath103 @xmath57 @xmath104 compute @xmath59 @xmath60 . if @xmath61 stop @xmath62    we are now in a position to derive a fom / gmres algorithm for shifted systems with flexible preconditioning .",
    "we search for solutions which are approximations of the form @xmath105 , which spans the columns of @xmath74 .",
    "strictly speaking , @xmath106 is no longer a krylov subspace . by minimizing the residual norm over all possible vectors in @xmath77",
    ", we obtain the flexible generalized minimum residual ( fgmres ) method for shifted systems , whereas by imposing the petrov - galerkin condition @xmath78 , we obtain the flexible full orthogonalized method ( ffom ) for shifted systems .",
    "this is summarized in algorithm  [ alg : shiftedsolvemod ] .",
    "the residuals can be computed as @xmath107    matrices @xmath10 and @xmath11 , vector @xmath49 , @xmath79 , set @xmath108 .",
    "choose @xmath109 .",
    "generate @xmath81 and @xmath74 using algorithm  [ alg : arnoldimod ] .",
    "construct @xmath110 ( see equation  ) .",
    "fom : @xmath111 gmres : @xmath112 construct the approximate solution as @xmath105 @xmath113      in algorithm  [ alg : arnoldimod ] , at each iteration we solve a system of the form @xmath115 for @xmath76 .",
    "this cost can be high if the dimension of the arnoldi subspace @xmath21 is large and a different preconditioner @xmath116 is used at every iteration .",
    "in practice , it is not necessary to form and factorize @xmath21 systems corresponding to different @xmath114 . in applications ,",
    "we only need choose a few different @xmath114 that cover the entire range of the parameters @xmath8 .",
    "this was also described in  @xcite .",
    "the system of equations   is solved using a direct solver and since only a few values of @xmath114 are chosen , the systems can be formed and factorized .",
    "thus , the computational cost will not be affected greatly even if the number of frequencies @xmath117 is large .",
    "let @xmath118 be the set of values that @xmath114 can take .",
    "in other words , we take @xmath119 distinct preconditioners . then , the first @xmath120 values of @xmath114 are assigned @xmath121 , the next @xmath122 values of @xmath114 are assigned @xmath123 and so on .",
    "we also have @xmath124 .",
    "as the dimension of the subspace @xmath21 increases , the computational and memory costs increase significantly . a well known solution to this problem is restarting .",
    "the old basis is discarded and the arnoldi algorithm is restarted on a new residual .",
    "however , for shifted systems , in order to preserve the shift - invariant property , one needs to ensure collinearity of the residuals of the shifted systems .",
    "for fom the residuals are naturally collinear and the arnoldi algorithm can be restarted by scaling each residual by some scalar that depends on the shift  @xcite . for gmres ,",
    "the approach used by  @xcite was extended to shifted systems with multiple preconditioners by  @xcite .",
    "we did not explore this issue further , and the reader is referred to  @xcite for further details .",
    "we start by computing the approximate eigenvalues and eigenvectors for the matrix @xmath125 . using estimates for approximate eigenvalues and eigenvectors",
    "we derive expressions for the convergence of the flexible algorithms .",
    "the approximate eigenvalues are called ritz values . for convenience",
    ", we drop the subscript on the shifted frequency , i.e. , use @xmath48 instead of @xmath8 where , @xmath9 .",
    "[ prop : ritz ] let @xmath74 , @xmath27 and @xmath126 be computed according to algorithm  [ alg : arnoldimod ] . calculate the eigenpairs of the generalized eigenvalue problem @xmath127 then , the ritz pair @xmath128 satisfy the petrov - galerkin condition  @xcite @xmath129    we first begin by manipulating equations   and  . eliminating @xmath74 from those equations and adding @xmath130 to both sides , we have @xmath131 now , consider the residual of the eigenvalue calculation for the @xmath132th eigenpair , where @xmath76 is    @xmath133    from which we can claim that @xmath134 and @xmath135 .",
    "in other words , they satisfy the petrov - galerkin   and are an approximate eigenpair of @xmath125 .",
    "furthermore , we define @xmath136 , which is the residual norm of the @xmath132th eigenvalue calculations . when the residual of the eigenvalue calculations @xmath137 is small , say machine precision , the ritz values are a good approximation to the eigenvalues .",
    "it is readily verified that the eigenvalues @xmath138 of @xmath139 ( and the generalized eigenvalue problem @xmath6 ) are related to the eigenvalues @xmath140 of @xmath125 by the relation @xmath141 .",
    "the importance of the convergence of ritz values to the convergence of the krylov subspace solver using fom can be established by the following result .",
    "[ prop : fom ] assume the requirements of proposition  [ prop : ritz ] .",
    "further , assume @xmath142 ( matrix of generalized eigenvectors , see  ) is invertible so that the generalized eigendecomposition @xmath143 exists .",
    "the residual using ffom satisfies the following inequality @xmath144 where , @xmath145 and @xmath137 is the residual norm of the eigenvalue calculation , defined above .",
    "we start by writing the residual in equation   @xmath146 since , for flexible fom for shifted systems @xmath147 , the first term in the above expression is zero and we have , @xmath148 now , using the generalized eigendecomposition in   @xmath149 .",
    "therefore , we have @xmath150",
    ". we can write this is as a sum of rank-@xmath151 vectors @xmath152 where , @xmath153 is the @xmath132-th canonical basis vector and @xmath154 is the @xmath132-th column of @xmath142 for @xmath76 . using the residual of the eigenvalue calculation @xmath155 in   and the expression derived above , @xmath156 where , @xmath157 .",
    "the proof follows from the properties of vector norms .",
    "the inequality   provides insight into the importance of the accuracy of approximate eigenpairs for the convergence of flexible fom for shifted systems .",
    "we follow the arguments in  @xcite . in particular , the residual is very small if @xmath158 , @xmath159 , @xmath160 or @xmath137 are small .",
    "we shall ignore the case that @xmath158 for further analysis , i.e. that the shifted system is almost exactly the preconditioned system .",
    "the eigenvalue residual norm @xmath137 being small implies that the ritz values are a good approximation to the eigenvalues of @xmath125 .",
    "this implies that all the eigenvalues in this interval have been computed fairly accurately .",
    "we now discuss when @xmath159 is large .",
    "when all the values of @xmath114 are equal to @xmath42 , the approximate eigenvalues @xmath161 of @xmath139 are related to approximate eigenvalues @xmath162 of the preconditioned system @xmath87 by the cayley transformation @xmath163 .",
    "therefore , @xmath159 is large only if @xmath164 .",
    "the term @xmath165 can be rewritten as @xmath166 .",
    "it is readily verified that @xmath167 is orthonormal to all other approximate eigenvectors @xmath168 and thus , @xmath165 can be interpreted as the component of the right hand side @xmath49 in the direction of the approximate eigenvector . in other words , @xmath165 is small when the solution @xmath169 has a small component in the direction of @xmath49 .",
    "the analysis for the convergence of flexible fom for shifted systems can be extended to flexible gmres as well .",
    "the following result bounds the difference in the residuals obtained from @xmath21 steps using flexible fom and flexible gmres .",
    "[ prop : gmres ] let @xmath74 , @xmath27 and @xmath126 be computed according to algorithm  [ alg : arnoldimod ] .",
    "further , from algorithm  [ alg : shiftedsolvemod ] we define the flexible fom quantities @xmath170 , residual @xmath171 and flexible gmres quantities @xmath172 , residual @xmath173 .",
    "further , assume that @xmath174 is invertible .",
    "we have the following inequality @xmath175 where , @xmath176 and @xmath177 .",
    "we begin by the following observation from equation   @xmath178 and @xmath179 next , we look at the solution to the gmres least squares problem which can be written as the normal equations @xmath180 this can be rewritten as @xmath181 in other words , the solution to the gmres subproblem is a rank - one perturbation of the fom subproblem . using the sherman - morrison identity @xmath182 then , the residual difference between fom and gmres can be bounded as @xmath183 the inequality   follows from the following observations @xmath184 and from   we have @xmath185 .",
    "if @xmath186 is large , then the difference between the two residuals can be large .",
    "this happens either when @xmath187 is large or @xmath174 is close to singular . in this case",
    ", flexible gmres can stagnate and further progress may not occur .",
    "we now discuss situations in which breakdown occurs , i.e. @xmath188 . if @xmath189 and @xmath16 is full rank , then it can be shown from equation   that @xmath190 and from equation  , it follows that @xmath191 .",
    "further , @xmath192 if and only if @xmath193 is the exact solution and @xmath194 is non - singular .",
    "the argument closely follows  @xcite and will not be repeated here .",
    "we observe that to compute vectors @xmath195 for @xmath196 in equation  , we have to invert matrices of the form @xmath116 .",
    "when the problem sizes are large , iterative methods may be necessary to invert such matrices , resulting in a variable preconditioning procedure in which a different preconditioning operator is applied at each iteration .",
    "more precisely , for @xmath76 , @xmath197 where , @xmath198 is the residual that results after the iterative solver has been terminated . to simplify the discussion , we assume that the termination criteria for the iterative solver is such that @xmath199 , for some @xmath200 .",
    "we closely follow the approach in  @xcite .",
    "the new flexible arnoldi relationship is now ,    @xmath201    where , @xmath202 $ ] and @xmath203 $ ] and @xmath204 is defined in equation  . by using inexact applications of the preconditioner , the vectors @xmath205 for @xmath206 are no longer the same vectors generated from algorithm  [ alg : arnoldimod ] . in particular",
    ", @xmath207 is no longer a krylov subspace generated by @xmath12 .",
    "however , by construction , @xmath13 is still an orthogonal matrix .",
    "having constructed the matrix @xmath208 , we seek approximate solutions spanned by the columns of @xmath208 , i.e. , solutions of the form @xmath209 .",
    "the true residual corresponding to the approximation solution @xmath209 can be computed as follows , @xmath210    the columns of the matrix @xmath211 are not computed in practice because they require an additional matrix - vector product with @xmath91 . as a result ,",
    "computing the true residual is expensive .",
    "however , in order to monitor the convergence of the iterative solver , we need bounds on the true residual . using such bounds",
    ", we can derive stopping criteria for the flexible krylov solvers for shifted systems with inexact preconditioning . to do this",
    ", we first derive bounds on the norm of inexact residual @xmath212 and a bound on the difference between the true and the inexact residual @xmath213 .",
    "a simple application of the triangle inequality for vector norms , leads us to the desired bounds on the true residual    the inexact residual @xmath214 defined as @xmath215 the expression for@xmath216 is similar to the exact residual @xmath212 ignoring the error due to early termination of the inner iterative solver , i.e. , @xmath217 .",
    "it is easy to verify that @xmath218 .",
    "we now derive an expression for the norm of the difference between the true and the inexact residuals ,    @xmath219    finally , the norm of the true residual @xmath220 can be bounded using the following relation @xmath221    this bound on the true residual , gives us a convenient expression to monitor the convergence of the iterative solver for each system , corresponding to a given shift @xmath8 .",
    "we can also derive specialized results for the flexible fom / gmres for shifted systems with inexact preconditioning .",
    "the approach used is and argument similar to  ( * ? ? ?",
    "* proposition 4.1 ) .",
    "let @xmath222 and @xmath223 be the true residual , respectively resulting from the flexible fom / gmres for shifted systems .",
    "we have the following error bounds    @xmath224    one of main results of the paper  @xcite is that they provide theory for why the residual norm due inexact preconditioning can be allowed to grow at the later outer iterations .",
    "in particular , they provide computable bounds for the monitoring the outer krylov solver residual when the termination criteria for the inner preconditioning is allowed to change at each iteration , from which efficient termination criteria can be derived .",
    "we have not pursued this issue and the reader is referred to  @xcite for further details .",
    "in this section , we briefly review the application of oscillatory hydraulic tomography and the geostatistical approach for solving the resulting inverse problem .",
    "the equations governing ground water flow through an aquifer for a given domain @xmath225 with boundary @xmath226 are given by ,    @xmath227    where @xmath228 [ l@xmath229 represents the specific storage and @xmath230 [ l / t ] represents the hydraulic conductivity .",
    "in the case of one source oscillating at a fixed frequency @xmath231 [ radians / t ] , @xmath232 is given by @xmath233 to model periodic simulations , we will assume the source to be a point source oscillating at a known frequency @xmath231 and peak amplitude @xmath234 at the source location @xmath235 .",
    "in the case of multiple sources oscillating at distinct frequencies , each source is modeled independently with its corresponding frequency as in  , and then combined to produce the total response of the aquifer .",
    "since the solution is linear in time , we assume the solution ( after some initial time has passed ) can be represented as @xmath236 where @xmath237 is the real part and @xmath238 is known as the phasor , is a function of space only and contains information about the phase and amplitude of the signal . assuming this solution , the equations   in the phasor domain are , @xmath239 the differential equation   along with the boundary conditions are discretized using fenics  @xcite by using standard linear finite elements . solving it for several frequencies results in system of shifted equations of the form @xmath240 where , @xmath10 and @xmath11 are the stiffness and mass matrices , respectively , that arise precisely from the discretization of  .",
    "the geostatistical approach ( described in the following papers  @xcite ) is one of the prevalent approaches for solving stochastic inverse problems .",
    "the idea is to represent the unknown field as the sum of a few deterministic low - order polynomials and a stochastic term that models small - scale variability .",
    "inference from the measurements is obtained by invoking the bayes theorem , through the posterior probability density function which is the product of two parts - likelihood of the measurements and the prior distribution of the parameters .",
    "let @xmath241 be the function to be estimated , here the log conductivity , and let it be modeled by a gaussian random field .",
    "after discretization , the field can be written as @xmath242 . here",
    "@xmath243 is a matrix of low - order polynomials , @xmath244 are a set of drift coefficients to be determined and @xmath245 is a covariance matrix with entries @xmath246 , and @xmath247 is a generalized covariance kernel  @xcite .",
    "the measurement equation can be written as , @xmath248 where @xmath249 represents the noisy measurements and @xmath250 is a random vector of observation error with mean zero and covariance matrix @xmath251 .",
    "the matrices @xmath251 , @xmath245 and @xmath243 are part of a modeling choice and more details to choose them can be obtained from the following references  @xcite .",
    "the operator @xmath252 is known as the parameter - to - observation map or _ measurement operator _ , with entries that are the coefficients of the oscillatory terms in the expression , @xmath253 where @xmath254 , is the location of the measurement sensor and @xmath255 , where @xmath256 is the number of measurement locations . at each measurement location ,",
    "two coefficients are measured for every frequency . in all",
    ", we have @xmath257 measurements , where @xmath117 is the number of frequencies .",
    "following the geostatistical method for quasi - linear inversion @xcite , we compute @xmath258 and @xmath259 corresponding to the maximum - a - posteriori probability which is equivalent to computing the solution to a weighted nonlinear least squares problem . to solve the optimization problem ,",
    "the gauss - newton algorithm is used . starting with an initial estimate for the field @xmath260",
    ", the procedure is described in algorithm  [ alg : quasi ] .",
    "compute the @xmath261 jacobian @xmath262 as , @xmath263 solve the system of equations ,    @xmath264    the update @xmath265 is computed by , @xmath266    repeat steps @xmath267 until the desired tolerance has been reached .",
    "( if necessary , add a line search ) .",
    "algorithm  [ alg : quasi ] requires , at each iteration , computation of the matrices @xmath268 and @xmath269 .",
    "since the prior covariance matrix @xmath245 is dense , a straightforward computation of @xmath268 can be performed in @xmath270 . however , for fine grids , i.e. , when the number of unknowns @xmath271 is large , storing @xmath245 can be expensive in terms of memory and computing @xmath268 can be computationally expensive . for regular equispaced grids and covariance kernels that are stationary or translation invariant , an fft based method can be used to reduce the storage costs of the covariance matrix @xmath245 to @xmath272 and cost of matrix - vector product to @xmath273 . for irregular grids ,",
    "the hierarchical matrix approach can be used to reduce the storage costs and cost of approximate matrix - vector product to @xmath273 for a wide variety of covariance kernels  @xcite .",
    "thus , in either situation , the cost for computing @xmath274 can be done in @xmath275 and the cost of computing @xmath269 is @xmath276 .",
    "computing the jacobian matrix @xmath277 at each iteration is often an expensive step . although explicit analytical expressions for the entries are nearly impossible , several approaches exist .",
    "one simple approach is to use finite differences , but this approach is expensive because it requires as many @xmath278 runs of the forward problem , i.e. one more than the number of parameters to be estimated . for large problems and on finely discretized grids , the number of unknowns can be quite large and so this procedure is not feasible .    to reduce the computational cost associated with calculating the sensitivity matrix we use the adjoint state method ( see for example ,  @xcite ) .",
    "this approach is exact and is computationally advantageous when the number of measurements is far smaller than the number of unknowns . for a complete derivation of the adjoint state equations for oscillatory hydraulic tomography , refer to  @xcite . for the type of measurements described in",
    ", the entries of the sensitivity matrix can calculated by the following expression for @xmath279 @xmath280 \\psi_{\\omega } + \\frac{\\partial k({\\textbf{x}})}{\\partial s_j } \\nabla \\phi \\cdot \\nabla \\psi_{\\omega}\\right )   \\right\\}d{\\textbf{x}}\\ ] ] since at measurement location corresponding to each frequency , two measurements are obtained from the coefficients of the oscillatory terms , so the jacobian matrix has @xmath281 entries where , @xmath282 . here , @xmath283 is the known as the _ adjoint solution _ that depends on the measurement location @xmath284 and the forcing frequency @xmath231 .",
    "it satisfies the following system of equations @xmath285 where , @xmath284 is the measurement location and @xmath231 is the particular frequency .",
    "the procedure for calculating the sensitivity matrix can thus be summarized as follows .",
    "\\1 . for a given field @xmath286 ,",
    "solve the forward problem for @xmath287 .",
    "2 . for each measurement and frequency @xmath231 , solve the adjoint problem for @xmath288 .",
    "3 . compute the integral in   to calculate the sensitivity .",
    "since   is evaluated for all @xmath289 for each measurement , the adjoint state method requires only @xmath290 forward model solves to compute the sensitivity matrix .",
    "thus , when the number of measurements is far fewer than the number of unknowns , the adjoint state method provides a much cheaper alternative for computing the entries of the jacobian matrix .",
    "this is typically the case in hydraulic tomography , where having several measurement locations is infeasible because it requires digging new wells .",
    "further , we realize that equation   takes the same form as equation   for multiple frequencies .",
    "thus , we can use the algorithms developed in section  [ sec : krylov ] to solve the system of equations   for as many right hand sides as measurements .",
    "it is possible to devise algorithms for multiple right hand sides in the context of shifted systems  @xcite but we will not adopt this approach .",
    "we present numerical results for the krylov subspace solvers and its application to oht . as mentioned before , we use the fenics software  @xcite to discretize the appropriate partial differential equations .",
    "we use the python interface to fenics , with ublassparse as the linear algebra back - end . for the direct solvers we use superlu  @xcite package that is interfaced by scipy whereas for the iterative solver we use an algebraic multigrid package pyamg  @xcite , with smoothed aggregation along with bicgstab iterative solver . in the following sections , for brevity , we only most results for fom solver but we observed similar results for the gmres method as well .",
    "this is also suggested by the result in proposition  [ prop : gmres ] .      in this section ,",
    "we present some of the results of the algorithms that we have described in section  [ sec : krylov ] .",
    "we now describe the test problem that we shall use for the rest of the section .",
    "we consider a @xmath291d aquifer in a rectangular domain with dirichlet boundary conditions on the boundaries .",
    "for the log - conductivity field @xmath292 , we consider a random field generated using an exponential covariance kernel @xmath293 using the algorithm described in @xcite .",
    "other parameters used for the model problem are summarized in table  [ tab : parameters ] .",
    "we choose @xmath0 frequencies evenly spaced between the minimum and maximum frequencies , which results in @xmath0 systems each of size @xmath294 .",
    ".parameters chosen for test problem [ cols=\"<,<,<\",options=\"header \" , ]",
    "we have presented a flexible krylov subspace algorithm for shifted systems of the form   that uses multiple shifted preconditioners of the form @xmath295 .",
    "the values of @xmath42 are chosen in order to improve convergence of the solver for all the shifted systems . the number of preconditioners chosen varies based on the distribution of the shifts .",
    "a good rule of thumb is that the systems having shift @xmath48 will converge faster if there a preconditioner with shift @xmath42 that is nearby @xmath48 .",
    "when the size of the linear systems is much larger , direct solvers are much more expensive . in such cases , preconditioning would be done using iterative solvers . the error analysis in section  [ sec : inexact ]",
    "provides insight into monitor approximate residuals without constructing the true residuals .",
    "one can naturally extend the ideas in this paper to systems with multiple shifts and multiple right hand sides using either block or deflation techniques .",
    "we applied the flexible krylov solver to an application problem that benefited significantly from fast solvers for shifted systems .",
    "in particular , oscillatory hydraulic tomography is a technique for aquifer characterization .",
    "however , since drilling observation wells to obtain measurements is expensive , one of the advantages of oscillatory hydraulic tomography is obtaining more informative measurements by pumping at different frequencies using the same pumping locations and measurement wells .",
    "in future studies we aim to study more realistic conditions for tomography , including a joint inversion for storage and conductivity",
    ". this would be ultimately beneficial to the practitioners .",
    "we envision that fast solvers for shifted systems would be beneficial for rapid aquifer characterization using oscillatory hydraulic tomography .",
    "the research in this work was funded by nsf award 0934596 , `` cmg collaborative research : subsurface imaging and uncertainty quantification '' and by nsf award 1215742 , `` collaborative research : fundamental research on oscillatory flow in hydrogeology . ''",
    "the authors would also like to thank their collaborators michael cardiff and warren barrash for useful discussions and the two anonymous reviewers for their insightful comments ."
  ],
  "abstract_text": [
    "<S> we discuss efficient solutions to systems of shifted linear systems arising in computations for oscillatory hydraulic tomography ( oht ) . </S>",
    "<S> the reconstruction of hydrogeological parameters such as hydraulic conductivity and specific storage using limited discrete measurements of pressure ( head ) obtained from sequential oscillatory pumping tests , leads to a nonlinear inverse problem . </S>",
    "<S> we tackle this using the quasi - linear geostatistical approach  @xcite . </S>",
    "<S> this method requires repeated solution of the forward ( and adjoint ) problem for multiple frequencies , for which we use flexible preconditioned krylov subspace solvers specifically designed for shifted systems based on ideas in  @xcite . </S>",
    "<S> the solvers allow the preconditioner to change at each iteration . </S>",
    "<S> we analyze the convergence of the solver and perform an error analysis when an iterative solver is used for inverting the preconditioner matrices . </S>",
    "<S> finally , we apply our algorithm to a challenging application taken from oscillatory hydraulic tomography to demonstrate the computational gains by using the resulting method . </S>"
  ]
}