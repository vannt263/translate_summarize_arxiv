{
  "article_text": [
    "the discrimination of visual texture has played an important role in computer vision and image analysis .",
    "although the ability of human beings for texture discrimination is apparently easy , the description by using texture methods has proven to be very complex .",
    "several methods have been proposed to characterize texture images .",
    "they are based on _ statistical analysis _ of the spatial distribution ( e.g. , co - occurrence matrices @xcite , local binary pattern @xcite and interaction map @xcite ) , _ stochastic models _",
    "( e.g. , markov random fields @xcite ) , _ spectral analysis _ ( e.g. , fourier descriptors @xcite , gabor filters @xcite and wavelets transform @xcite ) , _ structural models _",
    "( e.g. , mathematical morphology @xcite and geometrical analysis @xcite ) , and _ complexity analysis _ ( e.g. , fractal dimension @xcite ) .",
    "despite the fact they have thoroughly been studied , few methods are able to successfully discriminate the different texture patterns found in nature .    swarm systems or multi - agent systems , have been long applied in computer vision @xcite . in texture analysis , the swarm system can be found in a select group of approaches , such as deterministic the tourist walk @xcite , the ant colony @xcite , and the artificial crawler @xcite .",
    "the basic idea of the swarm algorithms consists of creating a system by means of the agent interaction , i.e. , a distributed agent system with parallel processing , and autonomous computing . in this paper",
    ", we propose a novel method for texture analysis based on the artificial crawler model @xcite .",
    "this swarm system consists of a population of agents , referred here to as artificial crawlers , that interact with each other and the environment , in this case an image .",
    "each artificial crawler occupies a pixel , and its goal is to move to the neighbor pixel of greater intensity .",
    "the agents store their current position in the image , and a correspondent energy that can wax or wane their lifespan depending on the energy consumption of the image .",
    "the population of artificial crawlers stabilizes after a certain number of iterations , i.e. , when there is no change in their spatial positions .    in the original swarm system @xcite the artificial crawlers",
    "only moves in direction of the maximum intensity , thus characterizing regions of high intensities in the image .",
    "however , in texture analysis , regions of low intensities are as important as regions of high intensities .",
    "therefore , we propose a new rule of movement that also moves artificial crawler agents in the direction of lower intensity .",
    "our approach differs from the original artificial crawler model in terms of movement : each agent is able to move to the higher altitudes , as well as to lower ones . to quantify the state of the swarm system after the stabilization",
    ", we propose to employ the bouligand - minkowski fractal dimension method @xcite .",
    "the fractal dimension method is widely used to characterize the roughness of a surface , which is related to the physical properties .",
    "we have conducted experiments in two datasets widely accepted in the literature of texture analysis .",
    "experimental results have shown that our method overcomes different state - of - the - art methods over vistex dataset .",
    "besides , our approach significantly improves the classification rate compared to the original artificial crawler method .",
    "the superior results rely on two facts : the fractal dimension estimation of the swarm system and the two rules of movement . on the one hand",
    ", the use of both rules of movement characterizes both regions of the texture image . on the other hand ,",
    "the fractal dimension improves the ability of discrimination obtained from the swarm system of artificial crawlers .",
    "moreover , the idea of the fractal dimension estimation can be used for other swarm systems .",
    "the main contributions of this paper are :    * a new rule of movement for the artificial crawler method .",
    "the original method fails to describe images because it moves the agents to higher intensities only .",
    "the proposed method describes images by using two rules of movement , i.e. , the swarm system finds the minima and maxima of images . * a new methodology to image description based on the energy information acquired from two rules of movement .",
    "although we can find the minima and maxima of images directly , the underlying idea is to characterize the path of movement during the evolution process . in this case",
    ", the energy information was considered the most important attribute due to its capacity of representing the interaction between the movement of agents and the environment . *",
    "to enhance the discriminatory power of our method , we use the energy information and the spatial position of each agent to estimate the fractal dimension of the image surface , in this paper is employed the fractal dimension of bouligand - minkowski .",
    "this paper is organized as follows . in section 2 ,",
    "we describe the artificial crawler model in details . in section 3",
    ", we present the basis for the fractal dimension and the bouligand - minkowski method .",
    "a new method for texture analysis based on fractal dimension of artificial crawlers is presented in section 4 .",
    "finally , in section 5 we report the experimental results , followed by the conclusion in section 6 .",
    "the texture method proposed in this study is based on the artificial crawler model proposed in @xcite .",
    "their agent - based model was first proposed in @xcite and then extended in @xcite . in order to describe this model ,",
    "let us consider an image which consists of a pair @xmath0 @xmath1 a finite set @xmath2 of pixels and a mapping @xmath3 that assigns to each pixel @xmath4 in @xmath2 a intensity @xmath5 $ ] .",
    "also , let us consider a neighborhood @xmath6 that consists of pixels @xmath7 whose euclidean distance between @xmath8 and @xmath7 is smaller or equal to @xmath9 ( 8-connected pixels ) : @xmath10    in image analysis , the artificial crawler model assumes that each agent occupies one pixel of the image . at each time",
    "@xmath11 , artificial crawler @xmath12 $ ] are characterized by two attributes .",
    "the first attribute @xmath13 holds the current level of energy .",
    "such energy can either wax or wane their lifespan according to energy consumption and influence of the environment .",
    "the second attribute @xmath14 is the current position of the artificial crawler in the image .",
    "the artificial crawlers act upon an environment . in images ,",
    "the environment is mapped as a 3d surface with different altitudes that correspond to gray values in z - axis .",
    "higher intensities pixels supply nutrients to the artificial crawlers ( increase its energy ) , while lower altitudes correspond to the land .",
    "figure [ fig : environment ] shows a textured image and the peaks and valleys where the artificial crawlers can increase or decrease its energy live .",
    "+    the @xmath15 artificial crawlers begin with equal energy @xmath16 and are placed at random on the surface ( pixels ) of the textured ]    then the evolution process starts following a set of specific rules .",
    "the aim of the artificial crawler is to move to areas of higher altitudes in order to absorb energy and sustain life .",
    "this way , the next step @xmath17 depends on the gray level of its neighbors according to equation [ eq : movements ] .",
    "first , the artificial crawler settles down if the gray level of its 8 neighbors are lower than itself ( figure [ fig : steps ] ( a ) ) .",
    "second , the artificial crawler moves to a specific pixel if there exist one of its 8 neighbors with unique higher intensity ( figure [ fig : steps ] ( b ) ) .",
    "third , if there exist more than one neighbor with higher intensity , an artificial crawler moves to the pixel that was already occupied by another artificial crawler in any time ( figure [ fig : steps ] ( c ) ) .",
    "otherwise , it moves to one of the pixels randomly .",
    "@xmath18    given the new position of the artificial crawler , the energy absorption from the environment is performed : @xmath19 where @xmath20 is the rate of absorption over the gray level of the current pixel @xmath21 .",
    "all artificial crawlers lose a unit of energy which means that the artificial crawler loses energy at each step if @xmath22 .",
    "for the default value of @xmath23 , it means that the artificial crawler loses energy if it goes to a pixel whose gray level is less than @xmath24 and gain energy otherwise .",
    "the energy is bounded by limit @xmath25 , i.e. if @xmath26 then @xmath27 .",
    "also , an artificial crawler keep living in the next generation whether its energy is higher than a certain threshold @xmath28 .",
    "after the energy absorption , the law of the jungle is performed . in this law ,",
    "an artificial crawler with higher energy eats up another with lower energy if they are in the same pixel , i.e. @xmath29 eats up @xmath30 if @xmath31 .",
    "this law is inspired in nature and assumes that the artificial crawlers with higher energy are more likely to reach the peaks of the environment .",
    "the evolution process converges to an equilibrium state when no further artificial crawlers are in movement ( they are dead or settled down ) . in the original method ,",
    "features are extracted by means of the number of artificial crawlers at each iteration and colonial properties .",
    "each texture image is represented by four curves of evolution : ( 1 ) curve of living artificial crawlers , ( 2 ) curve of settled artificial crawlers , ( 3 ) curve of colony formation at certain radius and ( 4 ) scale distribution of colonies .",
    "this representation has two major drawbacks : ( i ) the vector obtained is high - dimensional , which lead us to the curse of dimensionality and ( ii ) the extraction of this vector is very time - consuming due to the colony estimation .",
    "in 1977 , mandelbrot introduced a new mathematical concept to model natural phenomena , named fractal geometry @xcite .",
    "this formulation received a lot of attention due to its ability to describe irregular shapes and complex objects that euclidean geometry fails to analyze .",
    "in contrast , fractal geometry assumes that an object holds a non - integer dimension .",
    "thus , estimating the fractal dimension of an object is basically related to its complexity .",
    "the patterns are characterized in terms of space occupation and self - similarity at different scales .",
    "the interactive construction process of the von koch curve is a typical example of self - similarity of fractals @xcite .",
    "the first definition of dimension was proposed by the hausdorff - besicovitch measure @xcite , which provided the basis of the fractal dimension theory .",
    "he defined a dimension for point sets as a fraction greater than their topological dimension .",
    "formally , given @xmath32 , a geometrical set of points , the hausdoff - besicovitch dimension @xmath33 is calculated by :    @xmath34    where @xmath35 is the @xmath36-dimensional hausdorff measure ( in equation [ eq : hausdorff2 ] ) .",
    "@xmath37 \\label{eq : hausdorff2}\\ ] ]    where @xmath38 stands for the diameter in @xmath39 , i.e @xmath40 .    in image analysis",
    ", the use of the hausdoff - besicovitch definition may be impracticable @xcite .",
    "an alternative definition generalized from the topological dimension is commonly used . according to this definition ,",
    "the fractal dimension d of an object @xmath41 is : @xmath42 where @xmath43 stands for the number of objects of linear size @xmath44 needed to cover the whole object @xmath41 .",
    "there are a lot of algorithms to estimate the fractal dimension of objects or surfaces .",
    "the most known algorithms are : box - counting @xcite , differential box - counting @xcite , @xmath44-blanket @xcite , fractal model based on fractional brownian motion @xcite , power spectrum method @xcite , bouligand - minkowski @xcite among others ; as well as extensions of fractals , such as multifractals @xcite , multi - scale fractals @xcite and fractal descriptors @xcite .",
    "one of the most accurate methods to estimate the fractal dimension is the bouligand - minkowski method @xcite .",
    "the boulingand - minkowski fractal dimension @xmath45 depends on a symmetrical structuring element @xmath46 :    @xmath47    where @xmath48 is the bouligand - minkowski measure , @xmath44 is the radius of the element @xmath46 and @xmath49 is the volume of the dilation between element @xmath46 and boundary @xmath50 . to eliminate the explicit dependence on the element @xmath46 , a simplified version of the bouligand - minkowski fractal dimension can be described by using neighborhood techniques as :    @xmath51    for instance considering an object @xmath52 , the topological dimension @xmath53 and @xmath54 is a sphere of diameter @xmath44 .",
    "varying the radius @xmath44 , it estimates the fractal dimension based on the size of the influence area @xmath49 created by the dilation of @xmath41 by @xmath54 .",
    "in this section , we describe the proposed method , which is based on the fractal dimension of artificial crawlers .",
    "basically , our method can be divided into two parts : artificial crawlers are performed in the texture image and then the fractal dimension of these artificial crawlers is estimated .",
    "the next sections describe these steps of our method .",
    "although the original artificial crawler method achieves promising results , the idea of moving to pixels with higher intensities does not extract all the richness of textural pattern of the images . in the method proposed here ,",
    "the independent artificial crawler is also able to move to lower intensities ( valleys ) .",
    "it allows the model to take full advantage and capture the richness of details present in peaks and valleys of the images .    in the first step ,",
    "the artificial crawlers move to higher intensities as the original method .",
    "thus , artificial crawlers @xmath55 are obtained after the evolution process converges , where @xmath56 is the number of step needed to the system converges . throughout the paper , the artificial crawlers which move to higher intensities",
    "will be referred to as @xmath57 and this rule of movement will be referred to as @xmath58 .",
    "figure [ fig : maxmin ] shows an example of 1000 artificial crawlers using the rule of movement @xmath58 . although the image in figure [ fig : maxmin](a ) is an elaborate example we present how the agents find the maxima accordingly the @xmath58 rule .",
    "the green marks stand for the final position ( convergence ) of the live artificial crawler while the red ones represent the final position of the dead artificial crawlers .",
    "as we can see , the live artificial crawlers can achieve the highest intensities .",
    "the energy of these artificial crawlers implicitly stores all the information along the steps and this energy is important to represent the surface that the artificial crawler is emerged . as important as the live artificial crawler s , the dead ones aggregate information from the surface of the environment .         in figure",
    "[ fig : maxmin ] , we can observe that the original method only describes the peaks of a texture image .",
    "in addition , we propose to move artificial crawlers toward lower intensities . in this approach , artificial crawlers",
    "@xmath59 are randomly placed in the image with initial energy @xmath16 .",
    "then , the evolution process is modified so that the next step of an artificial crawler is to move towards the lower intensity ( equation [ eq : min ] ) .",
    "this rule of movement will be referred to throughout the paper as @xmath60 .",
    "@xmath61    an example of the artificial crawlers using the rule of movement @xmath60 can be seen in figure [ fig : maxmin ] ( b ) .",
    "again , green marks represent the final position of live artificial crawlers while red marks represent the dead artificial crawlers .",
    "these artificial crawlers complement the artificial crawlers that use the rule of movement @xmath58 , aggregating more information about the surface .    in the end of this step , we have two populations of @xmath15 artificial crawlers @xmath57 and @xmath62 which correspond to the artificial crawlers using rules of movement @xmath58 and @xmath60 , respectively .      in this section ,",
    "we describe how to quantify the population of artificial crawlers using the fractal dimension theory . to estimate the fractal dimension using the boulingand - minkowski method ,",
    "the population of artificial crawlers can be easily mapped onto a surface @xmath63 , by converting the position @xmath64 and the energy @xmath65 of each artificial crawler into a 3d point @xmath66 .",
    "the energy is important because it contain all the information of the artificial crawler steps .",
    "this mapping can be seen in figure [ fig : fractal_dilation ] ( a ) .",
    "we should note that the @xmath67 axis is the energy of the artificial crawler .",
    "the boulingand - minkowski method estimates the fractal dimension based on the size of the influence area @xmath68 created by the dilation of @xmath69 by a radius @xmath70 . thus varying the radius @xmath70 ,",
    "the fractal dimension of surface @xmath69 is given by :    @xmath71    where @xmath72 is the influence volume obtained through the dilation process of each point of @xmath69 using a sphere of radius @xmath70 : @xmath73    the dilation process is illustrated in figure [ fig : fractal_dilation ] .",
    "a group of artificial crawlers are mapped onto a 3d space , shown in figure [ fig : fractal_dilation ] ( a ) .",
    "each point of the 3d space is dilated by a sphere of radius @xmath70 ( figure [ fig : fractal_dilation ] ( b ) and ( c ) ) . as the value of radius @xmath70",
    "is increased , more collisions are observed among the dilated spheres .",
    "these collisions disturb the total influence volume @xmath72 , which is directly linked to the roughness of the surface .",
    "+    from the linear regression of the plot of @xmath74 , the boulingand - minkowski fractal dimension is computed by : @xmath75 where @xmath76 is the slope of the estimated line .",
    "although the fractal dimension provides a robust mathematical model , it describes each object by only one real value @xmath77 @xmath1 the fractal dimension .",
    "objects with distinct shapes can have the same fractal dimension , for instance , the very well know fractals : peano curve , dragon curve , julia set and the boundary of the mandelbrot set have the same hausdorff dimension equals to 2 . to overcome this characteristic the concept of multi - scale fractal dimension @xcite and the fractal descriptors @xcite was developed . in this way",
    ", the fractal dimension of the object is considered in different scales .",
    "it provides a rich shape descriptor that can be successful to discriminate shape and patterns @xcite .",
    "in @xcite it was demonstrate    in order to improve the discrimination power of our method , we use the entire curve @xmath72 instead of using only the fractal dimension : @xmath78 \\label{eq : vetor}\\ ] ] where @xmath79 is the rule of movement used by the artificial crawler and @xmath80 is the maximum radius .    considering that we have two rules of movement ,",
    "the final feature vector is composed by the concatenation of @xmath81 and @xmath82 according to equation [ eq : finalvector ] .",
    "the feature vectors @xmath81 and @xmath82 are obtained by using the fractal dimension estimation of acrawlers @xmath83 and @xmath84 after the stabilization , respectively . @xmath85",
    "\\label{eq : finalvector}\\ ] ]    the importance of using both rules is corroborated in figure [ fig : minmax1 ] .",
    "figures [ fig : minmax1 ] ( b ) and ( d ) show the feature vectors by using @xmath81 only , and figures [ fig : minmax1 ] ( c ) and ( e ) show the feature vectors by using @xmath82 only .",
    "an example of those feature vectors are obtained for four different image classes , as shown in figure [ fig : minmax1 ] ( a ) . for clarify",
    ", each class contains 10 samples .",
    "the classes d16 and d18 are discriminated using the rule of movement @xmath58 ( figure [ fig : minmax1 ] ( b ) ) , while the rule of movement @xmath60 is not able to discriminate those two classes accordingly ( figure [ fig : minmax1 ] ( c ) ) . on the other hand ,",
    "the classes d49 and d93 are only discriminated if the rule of movement @xmath60 is used ( figure [ fig : minmax1 ] ( e ) ) .",
    "these plots corroborate the importance of using both rules of movement for texture recognition .      in the proposed method , @xmath15 artificial crawlers",
    "are performed in the image of size @xmath86 pixels .",
    "the swarm system converges after @xmath87 steps , which leads to a computational complexity of @xmath88 . after stabilization",
    ", we propose to quantify the swarm system by means of the fractal dimension . to calculate the dilation process , the euclidean distance transform",
    "@xcite is a powerful and efficient tool .",
    "this transform calculates the distance between each point of the 3d space and the surface . several authors @xcite proposed algorithms for computing euclidean distance transform in linear time .",
    "the time complexity is linear in the number of points of the 3d space , which is @xmath89 @xmath1 @xmath86 is the size of the image and @xmath25 is the maximum energy of the agents .",
    "usually , the maximum energy @xmath25 is a small number ( e.g. in this work the maximum energy is @xmath90 ) .",
    "thus , we can ignore @xmath25 in the complexity , since @xmath91 in image applications .",
    "finally the computational complexity of the proposed method is stated as @xmath92 .",
    "let us discuss the best , worst and average case based on the number of steps of the swarm system .",
    "the best case considers that the swarm system converges in one step ( @xmath93 ) .",
    "thus , the computation complexity is @xmath94 . in the worst case ,",
    "the swarm system takes more than @xmath15 steps , however it is stopped in @xmath95 steps without the stabilization .",
    "the worst case leads to a complexity of @xmath96 .",
    "it is important to emphasize that the worst case rarely occurs , requiring a specific configuration of the texture image and even a random image does not produce this special case . in order to analyze the average case , we plot in figure [ fig : stepstoconverge ] the average number of steps needed to converge over 400 images .",
    "we can see that the two rules of movement @xmath60 and @xmath58 present similar behavior . also , the number of agents does not influence the number of steps to converge ( e.g.",
    "the difference of the average number os steps for @xmath97 and @xmath98 is only @xmath99 steps ) . given that @xmath100 for @xmath101 , the average case leads to a complexity which is very close to the best case , @xmath94 , and it is a good complexity in comparison to the complexities of gabor filters @xmath102 and co - occurrence matrices o(@xmath103 ) .     and @xmath58 .",
    "the average number of steps was averaged over 400 images . ]",
    "in order to evaluate the proposed method , experiments were carried out on image datasets of high variability .",
    "we first describe such datasets , the experiments to evaluate the parameters of our proposed method , and then the comparative results with the state - of - the - art methods .",
    "we performed experiments on the two most used image datasets of texture : brodatz and vistex .",
    "the brodatz album @xcite is the most known benchmark for evaluating texture methods .",
    "each class is composed by one image divided into ten non - overlapped samples .",
    "the samples have @xmath104 pixels with 256 gray levels . in this work ,",
    "a total of 40 classes with 10 samples per class were used .",
    "one example of each class is shown in figure [ fig : brodatz ] .",
    "pixels and 256 gray levels . ]    the vision texture @xmath1 vistex @xcite provides real - world textures under challenging conditions ( e.g. lighting and perspective ) .",
    "a total of 54 classes are available , each class containing 16 samples .",
    "the samples have @xmath105 pixels with 256 gray levels .",
    "figure [ fig : vistex ] presents one example of each class .     pixels and 256 gray levels . ]    in our experiments , linear discriminant analysis ( lda ) @xcite in a 10-fold cross - validation strategy was adopted in the task of classification . the lda method estimates a linear subspace in which the projection of the vectors presents larger variance inter - classes than the variance intra - classes .",
    "the 10-fold cross - validation strategy divides randomly the samples into 10 folds .",
    "each fold is used to test the classifier while the other nine folds are used to train the classifier .",
    "this process is repeated 10 times with each fold used once as testing data . to produce a single statistic ,",
    "the results of the 10 processes are averaged .",
    "the features used in this paper , and the parameter evaluation are in the next section .      in this section , we evaluate the three main parameters of our method : number of artificial crawlers @xmath15 , maximum energy @xmath25 and maximum radius @xmath80 of the fractal dimension .",
    "the other parameters were set according to @xcite , since their possible values do not affect the final success rate .",
    "each artificial crawler is born with initial energy @xmath106 , the survival threshold @xmath107 and the absorption rate @xmath23 .",
    "the success rates for the different number of artificial crawlers are shown in figure [ fig : n ] for both brodatz and vistex datasets .",
    "the number of artificial crawlers placed on the pixels were initially set to @xmath108 with a coverage rate of 5% , varying from @xmath108 to @xmath109 for the brodatz dataset and varying from @xmath108 to @xmath110 for the vistex dataset due to the size of the samples ( @xmath105 pixels ) .",
    "we can observe that the highest success rate was obtained for @xmath111 and @xmath112 for the brodatz and vistex , respectively .",
    "further , it was found that the combination of rules @xmath60 and @xmath58 significantly improve the success rate for all number of artificial crawlers in both datasets . also , the rule of going to the minimum intensity provides similar results to the original rule @xmath1 @xmath58 .",
    "these results suggest that the valleys and peaks are important to obtain a robust texture analysis .",
    "+   +    the maximum energy of the artificial crawlers is evaluated in the plot of the figure [ fig : n_energy_radius ] .",
    "figure [ fig : n_energy_radius ] ( c ) presents the results for the brodatz dataset while figure [ fig : n_energy_radius ] ( d ) shows the results for the vistex dataset .",
    "the maximum energy parameter was evaluated by the fact that it limits the artificial crawler energy and , consequently , can limit the fractal dimension space .",
    "however , the experimental results show that different values of maximum energy do not influence the success rate considerably .",
    "the highest success rate was obtained for @xmath113 using the brodatz dataset and for @xmath114 using the vistex dataset .",
    "it can be noted that the same behavior for the rules of movement was obtained here , with the combination of rules providing the highest success rates .    in the plot of figure",
    "[ fig : n_energy_radius ] , the maximum radius of the fractal dimension estimation is evaluated .",
    "as expected , the success rate increases as the radius increases and stabilizes after a certain radius .",
    "the maximum radius @xmath115 provided the highest success rate of @xmath116 for the brodatz dataset . for the vistex dataset ,",
    "a success rate of @xmath117 was obtained by the maximum radius @xmath118 . as the previous results",
    ", the combination of rules of movement provides the highest success rates .",
    "also , the rule @xmath60 provides similar results compared to the rule @xmath58 .",
    "using these plots , we can set the parameters of the proposed method for the brodatz dataset to @xmath111 , @xmath113 , @xmath119 .",
    "for the vistex dataset , the parameters are @xmath120 and @xmath121 , which are close to the best parameters for the brodatz dataset . for other datasets , we recommend using a number of agents @xmath15 between @xmath122 and @xmath123 of the number of pixels , @xmath124 and @xmath125 .      the proposed method , which is enriched by the fractal dimension estimation of artificial crawler , is compared to traditional texture methods , namely fourier descriptors @xcite , co - occurrence matrices @xcite , gabor filter @xcite , local binary pattern @xcite , and multi fractal spectrum @xcite .",
    "moreover , the texture method using the artificial crawlers proposed in @xcite was also used in this comparison .",
    "we considered the traditional implementation of each method and its parameter configuration as described below , which yields the best result .",
    "_ fourier descriptors _ : these descriptors are obtained from the fourier transform of the texture image .",
    "each descriptor is the sum of the spectrum values within a radius from the center .",
    "the best results were obtained by radius with increment by one .",
    "thus , for an image of @xmath126 pixels , 99 descriptors are obtained .",
    "more information about the fourier descriptors can be found in @xcite .",
    "_ co - occurrence matrices _ :",
    "they are computed by the joint probability distribution between pairs of pixels at a given distance and direction . in these experiments",
    ", we consider the distances from 1 to 5 pixels , and the angles @xmath127 , @xmath128 , @xmath129 and @xmath130 .",
    "energy and entropy were calculated from these matrices to compose a 40-dimensional feature vector @xcite .    _",
    "gabor filters _",
    ": it convolves an image by a bank of gabor filters ( i.e. , different scales and orientations ) . in the experiments ,",
    "a bank of 40 filters ( 8 rotations and 5 scales ) was used .",
    "the energy of each convolved image is used compose the feature vector ; in this case a 40-dimensional feature vector .",
    "additional information can be found in @xcite .",
    "_ artificial crawlers _ :",
    "@xmath15 artificial crawler , as those explained earlier , are performed in a texture image .",
    "four features vectors are then calculated : ( i ) the number of live artificial crawlers at each iteration , ( ii ) the number of settled artificial crawlers at each iteration , ( iii ) a histogram of the colony size formed by a certain radius and ( iv ) scale distribution of the colonies . finally , the four features vectors are concatenated to compose a single vector .",
    "a complete description of the original method can be found in @xcite .    _",
    "deterministic tourist walk _ :",
    "this method @xcite is an agent - based method that builds a joint probability distribution of transient and attractor sizes for different values of memory sizes and two walking rules . in the experiments below , we used memory sizes ranging from @xmath131 to @xmath132",
    ".    _ multi fractal spectrum _ : this method @xcite extracts the fractal dimension of three categorization of the   and three different angular resolutions @xmath133 @xmath1 @xmath134 : ( 8,1 ) , ( 16,2 ) and ( 24,3 ) .    in table",
    "[ tab : comparisonbrodatz ] we present the comparison of the texture methods on the brodatz dataset .",
    "the proposed method provided comparable results to the local binary patterns and superior results to the other state - of - the - art methods .",
    "though local binary patterns features perform slightly better than ours , the test also indicates that the proposed method significantly improves the success rate over the original artificial crawler , i.e. , from 89.75% to 99.25% . despite of the brodatz dataset is widely used for texture classification",
    ", it does not contains textures with changes in terms of lighting conditions and perspectives .",
    ".the experimental results for texture methods in the brodatz database . [ cols=\"^,^,^\",options=\"header \" , ]     [ tab : comparisonvistex ]",
    "in this paper we have proposed a new method based on artificial crawler and fractal dimension for texture classification .",
    "we have demonstrated how the feature vector extraction task can be improved by combining two rules of movement , instead of moving only for the maximum intensity of the neighbor pixels .",
    "moreover , a strategy using fractal dimension was proposed to characterize the path of movement performed by the artificial crawlers .",
    "the idea of our approach improves the ability of discrimination obtained from the swarm system of artificial crawlers .    although traditional methods of texture analysis ",
    "e.g. gabor filters , local binary patterns , and co - occurrence matrices  have provided satisfactory results , the method proposed here has proved to be superior for characterizing textures on the vistex dataset . on the brodatz album ,",
    "our method achieve the second place , being slightly inferior to the local binary pattern method .",
    "experiments on both datasets indicate that our method significantly improved the classification rate with regard to the original artificial crawler method . as future work",
    ", we believe that performance gains can be achieved by means of effective descriptors , for example for representing shape .",
    "w.n.g . acknowledges support from fapesp ( # 2010/08614 - 0 ) .",
    "b.b.m . is grateful to fapesp ( # 2011/02918 - 0 ) .",
    "o.m.b . gratefully acknowledges the financial support of cnpq ( national council for scientific and technological development , brazil ) ( grant # 308449/2010 - 0 and # 473893/2010 - 0 ) and fapesp ( the state of so paulo research foundation ) ( grant # 2011/01523 - 1 ) .",
    "b.  b. machado , w.  n. gonalves , o.  m. bruno , enhancing the texture attribute with partial differential equations : a case of study with gabor filters , in : proceedings of the 13th international conference on advanced concepts for intelligent vision systems , acivs11 , springer - verlag , berlin , heidelberg , 2011 , pp . 337348 .",
    "s.  g. mallat , http://dx.doi.org/10.1109/34.192463[a theory for multiresolution signal decomposition : the wavelet representation ] , ieee trans . pattern anal .",
    "11  ( 7 ) ( 1989 ) 674693 .",
    "http://dx.doi.org/10.1109/34.192463 [ ] .",
    "s.  arivazhagan , l.  ganesan , http://dx.doi.org/10.1016/s0167-8655(02)00390-2[texture classification using wavelet transform ] , pattern recogn . lett .",
    "24  ( 9 - 10 ) ( 2003 ) 15131521 .",
    "http://dx.doi.org/10.1016/s0167-8655(02)00390-2 [ ] .",
    "r.  billon , a.  ndlec , j.  tisseau , gesture recognition in flow based on pca analysis using multiagent system , in : proceedings of the international conference on advances in computer entertainment technology , acm international conference proceeding series , acm , 2008 , pp .",
    "139146 .",
    "h.  zheng , a.  wong , s.  nahavandi , hybrid ant colony algorithm for texture classification , in : the 2003 congress on evolutionary computation , cec 03 , piscataway , n.j . ,",
    "canberra , australia , 2003 , pp",
    ". 26482652 .",
    "d.  zhang , y.  q. chen , classifying image texture with artificial crawlers , in : proceedings of the ieee / wic / acm international conference on intelligent agent technology , iat 04 , ieee computer society , washington , dc , usa , 2004 , pp .",
    "446449 .",
    "m.  d.  c. joo b.  florindo , andr r.  backes , o.  m. bruno , a comparative study on multiscale fractal dimension descriptors , pattern recognition letters 33  ( 6 ) ( 2012 ) 798806 .",
    "http://dx.doi.org/10.1016/j.patrec.2011.12.016 [ ] .",
    "j.  ao  b.  forindo , e.  c.  p. mariana s.  sikora , o.  m. bruno , characterization of nanostructured material images using fractal descriptors , physica a : statistical mechanics and its applications 392  ( 7 ) ( 2013 ) 16941701 .",
    "[ ] .",
    "t.  saito , j .-",
    "toriwaki , new algorithms for euclidean distance transformation of an n - dimensional digitized picture with applications , pattern recognition 27  ( 11 ) ( 1994 ) 15511565 .",
    "http://dx.doi.org/10.1016/0031-3203(94)90133-3 [ ] .",
    "a.  meijster , j.  b. t.  m. roerdink , w.  h. hesselink , a general algorithm for computing distance transforms in linear time , in : mathematical morphology and its applications to image and signal processing , 2000 , pp .",
    "http://dx.doi.org/10.1007/0-306-47025-x_36 [ ] .",
    "s.  singh , m.  sharma , texture analysis experiments with meastex and vistex benchmarks , in : proceedings of the second international conference on advances in pattern recognition , icapr 01 , springer - verlag , london , uk , 2001 , pp .",
    "417424 .",
    "t.  ojala , m.  pietikinen , t.  menp , http://dx.doi.org/10.1109/tpami.2002.1017623[multiresolution gray - scale and rotation invariant texture classification with local binary patterns ] , ieee trans . pattern anal .",
    "24  ( 7 ) ( 2002 ) 971987 .",
    "http://dx.doi.org/10.1109/tpami.2002.1017623 [ ] .",
    "http://dx.doi.org/10.1109/tpami.2002.1017623    y.  xu , h.  ji , c.  fermller , http://dx.doi.org/10.1007/s11263-009-0220-6[viewpoint invariant texture description using fractal analysis ] , int .",
    "j. comput .",
    "vision 83  ( 1 ) ( 2009 ) 85100 . http://dx.doi.org/10.1007/s11263-009-0220-6 [ ] ."
  ],
  "abstract_text": [
    "<S> texture is an important visual attribute used to describe images . </S>",
    "<S> there are many methods available for texture analysis . </S>",
    "<S> however , they do not capture the details richness of the image surface . in this paper </S>",
    "<S> , we propose a new method to describe textures using the artificial crawler model . </S>",
    "<S> this model assumes that each agent can interact with the environment and each other . </S>",
    "<S> since this swarm system alone does not achieve a good discrimination , we developed a new method to increase the discriminatory power of artificial crawlers , together with the fractal dimension theory . </S>",
    "<S> here , we estimated the fractal dimension by the bouligand - minkowski method due to its precision in quantifying structural properties of images . </S>",
    "<S> we validate our method on two texture datasets and the experimental results reveal that our method leads to highly discriminative textural features . </S>",
    "<S> the results indicate that our method can be used in different texture applications . </S>"
  ]
}