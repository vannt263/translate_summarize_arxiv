{
  "article_text": [
    "rdf @xcite and sparql @xcite are increasingly being used to store and access semistructured data .",
    "an owl ontology @xcite is often used to enhance query answers with tuples implied by the ontology and data , and the owl 2 rl profile was specifically designed to allow for tractable rule - based query answering  @xcite . in practice , this often involves using a forward chaining procedure in which the _ materialisation _",
    "( i.e. , all consequences ) of the ontology and data is computed in a preprocessing step , allowing queries to be evaluated directly over the materialised triples .",
    "this technique is used by systems such as owlgres @xcite , webpie @xcite , oracle s rdf store @xcite , owlim se @xcite , and rdfox @xcite",
    ".    one disadvantage of materialisation is that the preprocessing step can be costly w.r.t .",
    "both the computation and storage of entailed triples .",
    "this problem is exacerbated when materialisation requires equality reasoning  that is , when the property is used to state equalities between resources .",
    "owl 2 rl / rdf ( * ? ? ?",
    "* section 4.3 ) axiomatises the semantics of using rules such as @xmath0 that , for each pair of equal resources @xmath1 and @xmath2 , ` copy ' all triples between @xmath1 and @xmath2 .",
    "it is well known that such ` copying ' can severely impact both the materialisation size and time @xcite ; what is less obvious is that the increase in computation time due to duplicate derivations may be even more serious ( see section  [ sec : motivation ] ) .    in order to address this problem",
    ", materialisation based systems often use some form of _ rewriting_a well - known technique for theorem proving with equality @xcite . in the owl 2 rl setting , rewriting consists of choosing one representative from each set of equal resources , and replacing all remaining resources in the set with the representative .",
    "variants of this idea have been implemented in many of the above mentioned systems , and they have been shown to be very effective on practical data sets @xcite .",
    "although the idea of rewriting is well known , ensuring its correctness ( i.e. , ensuring that the answer to an arbitrary sparql query is the same with and without rewriting ) is not straightforward . in this paper",
    "we identify two problems that , we believe , have been commonly overlooked in existing implementations .",
    "first , whenever a resource @xmath1 is rewritten in the data , @xmath1 must also be rewritten in the rules ; hence , the rule set can not be assumed to be fixed during the course of materialisation , which is particularly problematic if computation is paralellised .",
    "second , it is a common assumption that sparql queries can be efficiently evaluated over the materialisation by rewriting them , evaluating them over the rewritten triples , and then ` expanding ' the answer set ( i.e. , substituting all representative resources with equal ones in all possible ways ) .",
    "however , such an approach can be incorrect when sparql queries are evaluated under bag semantics , or when they contain builtin functions .",
    "we address both issues in this paper and make the following contributions . in section  [ sec : motivation ]",
    "we discuss the problems related to in more detail and show how they can lead to both increased computation costs and incorrect query answers .",
    "in section  [ sec : reasoning ] we present an algorithm that generalises owl 2 rl materialisation , can also handle swrl rules @xcite , rewrites rules as well as data triples , and is _ lock - free _ @xcite .",
    "the latter means that at least one thread always makes progress , ensuring that the system is less susceptible to adverse thread scheduling decisions and thus scales better to many threads . in section  [ sec : querying ] we show how to modify sparql query processing so as to guarantee correctness .",
    "finally , in section  [ sec : evaluation ] we present a preliminary evaluation of an implementation of our algorithms based on the open - source rdfox system .",
    "we show that rewriting can reduce the number of materialised triples by a factor of up to 7.8 , and can reduce materialisation time by a factor of up to 31.1 on a single thread , with the time saving being largely due to the elimination of duplicate derivations .",
    "our approach also parallelises computation very well , providing a speedup of up to 6.7 with eight physical cores , and up to 9.6 with 16 virtual cores .",
    "note , that datalog resoning is ptime complete in the size of the data and is thus deemed to be inherently sequential .",
    "due to space considerations , in this paper we have only been able to present a high level description of our algorithms ,",
    "* * owl 2 rl and rdf.**a _ term _ is a _ resource _",
    "( i.e. , a constant ) or a variable . unless otherwise stated ,",
    "@xmath3 , @xmath4 , @xmath5 , and @xmath6 are terms , and @xmath7 , @xmath8 , and @xmath9 are variables .",
    "an _ atom _ is a triple of terms @xmath10 called the _ subject _ , _ predicate _ , and _ object _ , respectively .",
    "a _ fact _ ( or _ triple _ ) is a variable - free atom .",
    "@xmath1 is an implication of the form , where @xmath11 is the _ head _ , @xmath12 is the _ body _ , and each variable in @xmath13 also occurs in @xmath14 .",
    "@xmath15 a _ program _",
    "@xmath16 is a finite set of rules , and @xmath17 is the _ materialisation _ of @xmath16 on a finite set of _ explicit _",
    "( i.e. , extensional or edb ) facts @xmath18 @xcite .",
    "two styles of owl 2 rl reasoning are known , corresponding to the rdf- and dl - style semantics of owl . in the rdf style",
    ", an ontology is represented using triples stored with the data in a single rdf graph , and a fixed ( i.e. , independent from the ontology ) set of rules is used to axiomatise the rdf - style semantics ( * ? ? ?",
    "* section 4.3 ) . while conceptually simple , this approach is inefficient because the fixed program contains complex joins . in the dl style ,",
    "the rules are derived from and depend on the ontology @xcite , but they are shorter and contain fewer joins .",
    "this approach is complete only if the ontology and the data satisfy conditions from section 3 of @xcite  an assumption commonly met in practice .",
    "rewriting can be used with either style of reasoning , but we will use the dl style in our examples and evaluation because the rules are more readable and their evaluation tends to be more efficient .",
    "in this section we discuss , by means of an example , the problems that the property poses to materialisation - based reasoners .",
    "the semantics of can be captured explicitly using program @xmath19 , consisting of rules  , which axiomatises as a congruence relation ( i.e. , an equivalence relation satisfying the replacement property ) .",
    "we call each set of resources all of which are equal to each other an -_clique_. @xmath20 owl 2 rl / rdf ( * ? ? ? * section 4.3 ) also makes symmetric and transitive , but those rules are redundant as they are instances of and .",
    "rules  can lead to the derivation of many equivalent triples , as we demonstrate using an example program @xmath21 containing rules  ; these correspond directly to swrl rules , but one could equally use slightly more complex rules obtained from owl 2 rl axioms .",
    "@xmath22 on @xmath23 , rule derives that is equal to and , and rules  then derive an triple for each of the nine pairs involving , , and .",
    "the total number of derivations , however , is much higher : we derive each triple once from rule , three times from rule , once from rule , , so we can map variable @xmath24 to in rule . ] and three times from rule ; thus , we get 66 derivations in total for the nine triples .",
    "analogously , rule derives that and are equal , and rules  derive the two triples 22 times in total .",
    "these triples lead to further inferences ; for example , from , rules and infer @xmath25 triples with subject or , and object , , or .",
    "each of these six triples is inferred three times from rule , once from rule , and three times from rule , so we get 36 derivations in total .",
    "thus , for each -clique of size @xmath26 , rules ",
    "derive @xmath27 triples via @xmath28 derivations .",
    "moreover , each triple @xmath10 with terms in -cliques of sizes @xmath29 , @xmath30 , and @xmath31 , respectively , is ` expanded ' to @xmath32 triples , each of which is derived @xmath33 times .",
    "this duplication of facts and derivations is a major source of inefficiency .    to reduce these numbers",
    ", we can choose a representative resource for each -clique and then _ rewrite _ all triples  that is , replace all resources with their representatives @xcite .",
    "for example , after applying rule , we can choose as the representative of , and , and , after applying rule , we can choose as the representative of and .",
    "the materialisation of @xmath21 then contains only the triple @xmath34 and , as we show in section  [ sec : reasoning ] , the number of derivations of triples drops from over 60 to just 6 .",
    "since triples can be derived continuously during materialisation , rewriting can not be applied as preprocessing ; moreover , to ensure that rewriting does not affect query answers , the resulting materialisation must be equivalent , modulo rewriting , to @xmath35^\\infty(\\efacts)$ ] .",
    "thus , we may need to continuously rewrite both triples and rules : rewriting only triples can be insufficient .",
    "for example , if we choose as the representative of , and , then rule will not be applicable , and we will fail to derive that is equal to . to the best of our knowledge ,",
    "no existing system implements rule rewriting ; certainly owlim se and oracle s rdf store do not , and so rewriting is _ not _ guaranteed to preserve query answers",
    ".    note that the problem is less acute when using a fixed rule set operating on ( the triple encoding of ) the ontology and data , but it can still arise if triples involve @xmath36 or @xmath37 resources ( with a fixed rule set , these are the only resources occurring in rule bodies ) .",
    "the algorithm by used in the rdfox system implements a fact - at - a - time version of the seminave algorithm @xcite : it initialises the set of facts @xmath38 with the input data @xmath18 , and then computes @xmath17 by repeatedly applying rules from @xmath16 to @xmath38 using @xmath39 threads until no new facts are derived .",
    "the objective of our approach is to adapt the rdfox algorithm to use rewriting and thus reduce both the size of @xmath38 and the time required to compute it , while ensuring that an arbitrary sparql query can be answered over the resulting facts as if the query were evaluated directly over @xmath40^\\infty(e)$ ] . to achieve this",
    ", we use a mapping @xmath41 that maps resources to their representatives . for @xmath42 a fact , a rule , or a set thereof , @xmath43 is obtained by replacing each resource @xmath1 in @xmath42 with @xmath44 ; moreover , @xmath45 is the _ expansion _ of @xmath38 with @xmath41 . to promote concurrency",
    ", we update @xmath41 in a lock - free way , using _ compare - and - set _ primitives to prevent thread interference .",
    "moreover , we do not lock @xmath41 when computing @xmath43 ; instead , we only require @xmath43 to be at least as current as @xmath42 just before the computation .",
    "for example , if @xmath41 is the identity as we start computing @xmath46 , and another thread makes @xmath47 the representative of @xmath48 , then @xmath49 , @xmath50 , @xmath51 , and @xmath52 are all valid results .",
    "we also maintain queues @xmath53 and @xmath54 of rewritten rules and resources , respectively , for which also use lock - free implementations as described by .    to extend the original rdfox algorithm with rewriting , we allow each thread to perform three different actions .",
    "first , a thread can extract a rule @xmath1 from the queue @xmath53 of rewritten rules and apply @xmath1 to the set of all facts @xmath38 , thus ensuring that changes to resources in rules are taken into account .",
    "second , a thread can rewrite outdated facts  that is , facts containing a resource that is not a representative of itself . to avoid iteration over all facts in @xmath38 ,",
    "the thread extracts a resource @xmath55 from the queue @xmath54 of unprocessed outdated resources , and uses indexes by to identify each fact @xmath56 containing @xmath55 .",
    "the thread then removes each such @xmath57 from @xmath38 , and it adds @xmath58 to @xmath38 .",
    "third , a thread can extract and process an unprocessed fact @xmath57 in @xmath38 . the thread first checks whether @xmath57 is outdated ( i.e. , whether @xmath59 ) ; if so , the thread removes @xmath57 from @xmath38 and adds @xmath58 to @xmath38 .",
    "if @xmath57 is not outdated but is of the form @xmath60 with @xmath61 , the thread chooses a representative of the two resources , updates @xmath41 , and adds the other resource to queue @xmath54 .",
    "the thread derives a contradiction if @xmath57 is of the form @xmath62 .",
    "otherwise , the thread processes @xmath57 by partially instantiating the rules in @xmath16 containing a body atom that matches @xmath57 , and applying such rules to @xmath38 as described by .",
    "rewriting rules is nontrivial : rdfox uses an index to efficiently identify rules matching a fact , and the index may need updating when @xmath41 changes . updating the index in parallel would be very complex , so we perform this operation serially : when all threads are waiting ( i.e. , when all facts have been processed ) , a single thread updates @xmath16 to @xmath63 , reindexes it , and inserts the updated rules ( if any ) into the queue @xmath53 of rules for reevaluation .",
    "this is obviously a paralellisation bottleneck , but our experiments have shown that the time used for this process is not significant when programs are of moderate size .",
    "parallel modification of @xmath38 can also be problematic , as the following example demonstrates : ( 1 )  thread a extracts a current fact @xmath57 ; ( 2 )  thread b updates @xmath41 and deletes an outdated fact @xmath64 ; and ( 3 )  thread a derives @xmath64 from @xmath57 and writes @xmath64 into @xmath38 , thus undoing the work of thread b. this could be solved via locking , but at the expense of parallelisation .",
    "thus , instead of physically removing facts from @xmath38 , we just mark them as outdated ; then , when matching the body atoms of partially instantiated rules , we simply skip all marked facts . all this can be done lock - free , and we can remove all marked facts in a postprocessing step .    theorem  [ thm : correctness ] states several important properties of our algorithm that , taken together , ensure the algorithm s correctness ; a detailed formalisation of the algorithm and a proof of the theorem are    theoremthmcorrectness[thm : correctness ] the algorithm terminates for each finite set of facts @xmath18 and program @xmath16 .",
    "let @xmath41 be the final mapping and let @xmath38 be the final set of unmarked facts .    1 .",
    "@xmath65 implies @xmath66that is , @xmath41 captures all equalities .",
    "@xmath56 implies @xmath67that is , @xmath38 is minimal .",
    "@xmath68^{\\infty}(\\efacts)}$]that is , @xmath38 and @xmath41 together represent @xmath69^{\\infty}(\\efacts)$ ] .",
    "table  [ tab : run ] shows six steps of an application of our algorithm to the example program @xmath21 from section [ sec : motivation ] on one thread .",
    "some resource names have been abbreviated for convenience , and @xmath70 abbreviates .",
    "the @xmath71 symbol identifies the last fact extracted from @xmath38 .",
    "facts are numbered for easier referencing , and their ( re)derivation is indicated on the right : @xmath72 or @xmath73 means that the fact was obtained from fact @xmath26 and rule @xmath53 or @xmath74 ; moreover , we rewrite facts immediately after merging resources , so @xmath75 identifies a rewritten version of fact @xmath26 , and @xmath76 means that a fact was marked outdated because fact @xmath26 caused @xmath41 to change .",
    "we start by extracting facts from @xmath38 and , in steps 1 and 2 , we apply rule @xmath53 to facts 2 and 3 to derive facts 4 and 5 , respectively . in step 3 , we extract fact 4 , merge into , mark facts 2 and 4 as outdated , and add their rewriting , facts 6 and 7 , to @xmath38 . in step 4",
    "we merge @xmath77 into @xmath78 , after which there are no further facts to process .",
    "mapping @xmath41 , however , has changed , so we update @xmath16 to contain rules and , and add them to the queue @xmath53 .",
    "@xmath79 in step 5 we evaluate the rules in queue @xmath53 , which introduces facts 9 and 10 . finally , in step 6",
    ", we rewrite into and mark facts 1 and 9 as outdated . at this point the algorithm terminates , making only six derivations in total , instead of more than 60 derivations when is axiomatised explicitly ( see section [ sec : motivation ] ) .",
    "given a set of facts @xmath38 and mapping @xmath41 , the expected answers to a sparql query @xmath80 are those obtained by evaluating @xmath80 in the expansion @xmath81 . evaluating @xmath80 on @xmath81 , however , forgoes any advantage of smaller joins obtained from evaluating @xmath80 on the succinct representation @xmath38 .",
    "thus , the question arises how @xmath80 can be evaluated on @xmath38 yielding the answers in @xmath81 whilst only necessary resources are expanded . to illustrate our strategy",
    ", we use our program @xmath21 from section [ sec : motivation ] : recall that , after we finish the materialisation of @xmath21 , we have @xmath82 for each @xmath83 and @xmath84 for each @xmath85 .",
    "firstly , we discuss query evaluation under sparql bag semantics where repeated answers matter . to this end , let @xmath86 on @xmath87 , query @xmath88 produces answers @xmath89 and @xmath90 , each of which is repeated three times  once for each match of @xmath91 to , , or . a nave evaluation of the normalised query @xmath92 on @xmath38 coupled with a post - hoc expansion under @xmath41 produces one occurrence of each @xmath93 and @xmath94 which is not the intended result ; this problem arises because the final expansion step does not take into account the number of times each binding of @xmath91 contributes to the result .",
    "we therefore modify the projection operator to output each projected answer as many times as there are resources in the projected -clique(s ) .",
    "thus , we answer @xmath88 as follows : we match the triple pattern of @xmath92 to @xmath38 as usual , obtaining one answer @xmath95 ; then , we project @xmath91 from @xmath96 and obtain three occurrences of @xmath93 since the -clique of @xmath78 is of size three ; finally , we expand each occurrence of @xmath93 to @xmath94 to obtain all six results .    secondly , we treat query evaluation in the presence of sparql builtin functions .",
    "let @xmath97 be as follows : @xmath98 on @xmath87 , query @xmath97 produces answers @xmath99 and @xmath100 ; in contrast , on @xmath38 , query @xmath101 yields only @xmath102 , which does not expand into @xmath103 because the strings `` obama '' and `` uspresident '' are not equal .",
    "our evaluation therefore expands answers _ before _ evaluating builtin functions .",
    "thus , we answer @xmath97 as follows : we match the triple pattern of @xmath101 to @xmath38 as usual , obtaining @xmath104 ; then , we expand @xmath105 to @xmath106 ; next , we evaluate the @xmath107 expression and extend @xmath105 and @xmath108 with the respective values for @xmath91 ; finally , we project @xmath109 to obtain @xmath102 and @xmath103 .",
    "since we have already expanded @xmath109 , we must not repeat the projected answers further ; instead , we output each projected answer only once to obtain the correct answer cardinalities .",
    "we have implemented our approach as an extension to rdfox , allowing the system to handle via rewriting ( rew ) or the axiomatisation ( ax ) from section [ sec : motivation ] .",
    "we then compared the performance of materialisation using these two approaches .",
    "in particular , we investigated the scalability of each approach with the number of threads , and we measured the effect that rewriting has on the number of derivations and materialised triples .    * * test data sets.**we used five test data sets , each consisting of an owl 2 dl ontology and a set of facts .",
    "the data sets were chosen because they contain axioms with the property leading to interesting inferences .",
    "four data sets were derived from real - world applications .",
    "* claros has been developed in an international collaboration between it experts and archaeology and classical art research institutions with the aim of integrating disparate cultural heritage databases .",
    "* dbpedia is a crowd - sourced community effort to extract structured information from wikipedia and make this information available on the web .",
    "* opencyc is an extensive ontology about general human knowledge .",
    "it contains hundreds of thousands of terms organised in a carefully designed ontology and can be used as the basis of a wide variety of intelligent applications .",
    "* uniprot is a subset of an extensive knowledge base about protein sequences and functional information .",
    "the ontologies of all data sets other than dbpedia are not in the owl 2 rl profile , so we first discarded all axioms outside owl 2 rl , and then we translated the remaining axioms into rules as described in @xcite .    our fifth data set was uobm @xcite  a synthetic data set that extends the well - known lubm @xcite benchmark .",
    "we did not use lubm because neither its ontology nor its data uses the property .",
    "the uobm ontology is also outside owl 2 rl ; however , instead of using its owl 2 rl subset , we used its _ upper bound _ @xcite ",
    "an unsound but complete owl 2 rl approximation of the original ontology ; thus , all answers that can be obtained from the original ontology can also be obtained from the upper bound , but not the other way around .",
    "efficient materialisation of the upper bound was critical for the work by , and it has proved to be challenging due to equality reasoning .",
    "the left - hand part of table [ tab : teststats ] summarises our test data sets : column ` rules ' shows the total number of rules , column ` sa - rules ' shows the number of rules containing the property in the head , and column ` triples before ' shows the number of triples before materialisation .    *",
    "* test setting.**we conducted our tests on a dell computer with 128  gb of ram and two xeon e5 - 2643 processors with a total of 8 physical and 16 virtual cores , running 64-bit fedora release 20 , kernel version 3.13.3 - 201 .",
    "we have not conducted warm and cold start tests separately since , as a main - memory system , the performance of rdfox should not be affected by the state of the operating system s buffers . for the ax tests , we extended the relevant program with the seven rules from section [ sec : motivation ] . in all cases we verified that the expansion of the rewritten triples is identical to the triples derived using the axiomatisation .",
    "# 2    [ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]     * * effect of rewriting on total work.**in order to see how rewriting affects the total amount of work , we materialised each test data set in both ax and rew modes while collecting statistics about the inference process ; the results are shown in the right - hand part of table [ tab : teststats ] . column ` triples after ' shows the number of triples after materialisation ; in the case of rew tests , we additionally show the number of unmarked triples ( i.e. , of triples relevant to query answering ) .",
    "column ` memory ' shows the total memory use as measured by rdfox s internal counters . column ` rule appl . ' shows the total number of times a rule has been applied to a triple , and column ` derivations ' shows the total number of derivations . column ` merged resources ' shows the number of resources that were replaced with representatives in the course of materialisation .",
    "finally , row ` factor ' shows the ratio between the respective values in the ax and the rew tests .",
    "as one can see , the reduction in the number of the derived triples is correlated with the number of rewritten constants : on uniprot there is no observable reduction since only five resources are merged ; however , equalities proliferate on opencyc and so rewriting is particularly effective . in all cases",
    "the numbers of marked triples are negligible , suggesting that our decision to mark , rather than delete triples does not have unexpected drawbacks .",
    "in contrast , the reduction in the number of rule applications and , in particular , of derivations is much more pronounced than the reduction in the number of derived triples .",
    "threads & & & & & & & & & + & sec & spd & sec & spd & & sec & spd & sec & spd & & sec & spd & sec & spd & + 1 & 2042.9 & 1.0 & 65.8 & 1.0 & 31.1 & 219.8&1.0&31.7 & 1.0 & 6.9&2093.7 & 1.0&119.9 & 1.0&17.5 + 2 & 969.7 & 2.1 & 35.2 & 1.9 & 27.6 & 114.6&1.9&17.6 & 1.8 & 6.5&1326.5 & 1.6 & 78.3 & 1.5&16.9 + 4 & 462.0 & 4.4 & 18.1 & 3.6 & 25.5 & 66.3 & 3.3&10.7 & 3.0 & 6.2 & 692.6 & 3.0 & 40.5 & 3.0&17.1 + 8 & 237.2 & 8.6 & 9.9 & 6.7 & 24.1 & 36.1 & 6.1 & 5.2 & 6.0 & 6.9 & 351.3 & 6.0 & 23.0 & 5.2&15.2 + 12 & 184.9 & 11.1&7.9 & 8.3 & 23.3 & 31.9 & 6.9 & 4.1 & 7.7 & 7.7 & 291.8 & 7.2 & 56.2 & 2.1 & 5.5 + 16 & 153.4 & 13.3&6.9 & 9.6 & 22.3 & 27.5 & 8.0 & 3.6 & 8.8 & 7.7 & 254.0 & 8.2 & 52.3 & 2.3 & 4.9 +   + test & & + threads & & & & & & + & sec&spd & sec & spd & & sec & spd & sec & spd & + 1 & 370.6 & 1.0&143.4 & 1.0 & 2.6&2696.7 & 1.0&1152.7 & 1.0 & 2.3 + 2 & 232.3 & 1.6 & 86.7 & 1.7 & 2.7&1524.6 & 1.8 & 599.6 & 1.9 & 2.5 + 4 & 129.2 & 2.9 & 46.5 & 3.1 & 2.8 & 813.3 & 3.3 & 318.3 & 3.6 & 2.6 + 8 & 74.7 & 5.0 & 25.1 & 5.7 & 3.0 & 439.9 & 6.1 & 177.7 & 6.5 & 2.5 + 12 & 61.0 & 6.1 & 19.9 & 7.2 & 3.1 & 348.9 & 7.7 & 152.7 & 7.6 & 2.3 + 16 & 61.9 & 6.0 & 17.1 & 8.4 & 3.6 & 314.4 & 8.6 & 137.9 & 8.4 & 2.3 +    * * effect of rewriting on materialisation times.**in order to see how rewriting affects materialisation times , we measured the wall - clock times needed to materialise our test data sets in ax and rew modes on 1 , 2 , 4 , 8 , 12 , and 16 threads . for each test",
    ", we report average wall - clock time over three runs .",
    "table [ tab : testtimes ] shows our test results ; column ` sec ' shows the materialisation time in seconds , column ` spd ' shows the speedup over the single - threaded version , and column ` @xmath110 ' shows the speedup of rew over ax .    as one can see from the table , rdfox parallelises computation exceptionally well not only in ax mode but also in the rew mode which uses our extended algorithm . when using the eight physical cores of our test server ,",
    "the speedup is consistently between six and seven , which suggests that the lock - free algorithms and data structures of rdfox are very effective .",
    "we believe that the more - than - linear speedup on claros is due to improved memory locality resulting in fewer cpu cache misses .",
    "the speedup continues to increase with hyperthreading , but is less pronounced : virtual cores do not provide additional execution resources , and so they mainly compensate for cpu stalls due to cache misses . the ax mode seems to scale better with the number of threads than the rew mode , and we believe this to be due to contention between threads while accessing the map @xmath41 .",
    "yet , the overall saved work compared to the ax mode , makes more than up for it . only opencyc in rew mode",
    "did not scale particularly well : opencyc contains many rules , so sequentially updating @xmath16 and the associated rule index when @xmath41 changes becomes a significant paralellisation bottleneck . finally , since the materialisation of claros with more than eight threads in rew mode takes less than ten seconds , these results are difficult to measure and are susceptible to skew .",
    "our results confirm that rewriting can significantly reduce materialisation times .",
    "rdfox was consistently faster in the rew mode than in the ax mode even on uniprot , where the reduction in the number of triples is negligible .",
    "this is due to the reduction in the number of derivations , mainly involving rules ( [ eq : eq1])([eq : eq5 ] ) , which is still significant on uniprot . in all cases ,",
    "the speedup of rewriting is typically much larger than the reduction in the number of derived triples ( cf .",
    "table [ tab : teststats ] ) , suggesting that the primary benefit of rewriting lies in less work needed to match the rules , rather than , as commonly thought thus far , in reducing the number of derived triples .",
    "this is consistent with the fact that the speedup of rewriting was not so pronounced on uniprot and uobm , where the reduction in the number of derivations was less significant .",
    "our analysis of the derivations that rdfox makes on uobm revealed that , due to the derived triples , the materialisation contains large numbers of resources connected by the property .",
    "this property is also symmetric and transitive so , for each pair of connected resources , the number of times each triple is derived by the transitivity rule is quadratic in the number of connected resources .",
    "this leads to a large number of duplicate derivations that do _ not _ involve equality .",
    "thus , although it is helpful , rewriting does not reduce the number of derivation in the same way as , for example , on claros , which explains the relatively modest speedup of rew over ax .",
    "in this paper we have investigated issues related to the use of rewriting in materialisation based owl 2 rl systems . we have presented algorithms that resolve these issues , and that can be effectively parallelised , and we have shown empirically that our approach can reduce reasoning times on practical data sets by orders of magnitude .",
    "horrocks , i. ; patel - schneider , p.  f. ; boley , h. ; tabet , s. ; grosof , b. ; and dean , m. 2004 . : a semantic web rule language combining owl and ruleml .",
    "ember submission . http://www.w3.org / submission / swrl/.            motik , b. ; nenov , y. ; piro , r. ; horrocks , i. ; and olteanu , d. 2014 .",
    "parallel materialisation of datalog programs in centralised , main - memory rdf systems . in _ proc .  of the 28th nat .",
    "conf .  on artificial intelligence ( aaai  14 ) _ , 129137 .",
    "aaai press ."
  ],
  "abstract_text": [
    "<S> rewriting is widely used to optimise reasoning in materialisation based owl 2 rl systems . </S>",
    "<S> we investigate issues related to both the correctness and efficiency of rewriting , and present an algorithm that guarantees correctness , improves efficiency , and can be effectively parallelised . </S>",
    "<S> our evaluation shows that our approach can reduce reasoning times on practical data sets by orders of magnitude . </S>"
  ]
}