{
  "article_text": [
    "uncovering cause - and - effect relationships remains an exciting challenge in many fields of applied science .",
    "for instance , identifying the causes of a disease in order to prescribe effective treatments is of primary importance in medical diagnosis @xcite ; locating the defects that could cause abrupt changes of the connectivity structure and adversely affect the performance of the system is a main objective in structural health monitoring @xcite .",
    "consequently , the problem of inferring causal relationships from observational data has attracted much attention in recent years  @xcite .",
    "identifying causal relationships in large - scale complex systems turns out to be a highly nontrivial task . as a matter of fact",
    ", a reliable test of causal relationships requires the effective determination of whether the cause - and - effect is real or is due to the secondary influence of other variables in the system .",
    "this , in principle , can be achieved by testing the relative independence between the potential cause and effect conditioned on all other variables in the system .",
    "such a method essentially demands the estimation of joint probabilities for ( very ) high dimensional variables from limited available data and suffers the curse of dimensionality . in practice , there are various approaches in statistics and information theory that aim at accomplishing the proper conditioning without the need of testing upon all remaining variables of the system at once  @xcite .",
    "the basic idea behind many such approaches originates from the classical pc - algorithm  @xcite , which repeatedly measures the relative independence between the cause and effect conditioned on combinations of the other variables . as an alternative",
    ", we recently developed a new entropy - based computational approach that infers the causal structure via a two - stage process , by first aggregatively discovering potential causal relationships and then progressively removing those ( from the stage ) that are redundant  @xcite .",
    "in almost all computational approaches for inferring causal structure , it is necessary to estimate the joint probabilities underlying the given process .",
    "large - scale data sets are commonly analyzed via discretization procedures , for instance using binning , ranking , and/or permutation methods  @xcite .",
    "these methods generally require fine - tuning of parameters and can be sensitive to noise . on the other hand , the time - evolution of a physical system can only be measured and recorded to a finite precision , resembling an approximation of the true underlying process .",
    "this finite resolution can be characterized by means of a finite set of symbols , yielding a discretization of the phase space .",
    "regardless of the nature and motivation of discretization , the precise impacts on the causal structure of the system is essentially unexplored . here",
    ", we investigate the symbolic description of a dynamical system and how it affects the resulting markov order and causal structures",
    ". such description , based on partitioning the phase space of the system , is also commonly known as symbolization .",
    "symbolization converts the original dynamics into a stochastic process supported on a finite sample space .",
    "focusing on the tent map for the simplicity , clarity and completeness of computation it allows  @xcite , we introduce numerical procedures to compute the joint probabilities of the stochastic process resulting from arbitrary partitioning of the phase space .",
    "furthermore , we develop causation entropy , an information - theoretic measure based on conditional mutual information as a mean to determine the markov order and ( temporal ) causal structure of such processes .",
    "we uncovered that a partitioning that maintains dynamic invariants of the system does not necessarily preserve its causal structure .",
    "on the other hand , both the markov order and causal structure depend nonmonotonically and , indeed , sensitively on the partitioning .",
    "a powerful method of analyzing nonlinear dynamical systems is to study their symbolic dynamics through some topological partition of the phase space  @xcite .",
    "the main idea characterizing symbolic dynamics is to represent the state of the system using symbols from a finite alphabet defined by the partition , rather than using a continuous variable of the original phase space . for more details ,",
    "we refer to @xcite .",
    "the issue of partitioning was shown to affect entropic computations in a nontrivial manner  @xcite and , as we will highlight in the paper , is also intricate and central to a general information - theoretic description of the system .",
    "consider a discrete dynamical system given by @xmath0 where @xmath1 represents the state of the system at time @xmath2 and the vector field @xmath3 governs the dynamic evolution of the states .",
    "a ( _ topological _ ) _ partition _ of the phase space @xmath4 is a finite collection @xmath5 of disjoint open sets whose closures cover @xmath4 , i.e. , @xmath6 the partition leads to the corresponding _",
    "symbolic dynamics_. in particular , for any trajectory @xmath7 of the original dynamics contained in the union of @xmath8 s , the partition yields a _ symbol sequence _ @xmath9 given by @xmath10 where @xmath11 is the indicator function defined as @xmath12 in other words ,",
    "the symbolic state @xmath13 is determined by the open set @xmath8 that contains the state @xmath14 .",
    "see fig .",
    "[ fig1 ] for a schematic illustration .",
    ", the trajectory @xmath15 leads to a symbol sequence @xmath16 .",
    ", scaledwidth=39.0% ]    in general , the same symbol sequence may result from distinct trajectories .",
    "if the partition is _ generating _ , then every symbol sequence corresponds to a unique trajectory @xcite .",
    "a special case is the so - called markov partition  @xcite , for which the transition from one symbolic state to another is independent of past states , analogous to a markov process . on the other hand , a generating partition is not necessarily markov  @xcite .",
    "the precise effects of partitioning on the symbolic dynamics remains an interesting and challenging problem , with recent progress in a few directions .",
    "focusing on the equivalence between the original and symbolic dynamics , bollt  _ et .",
    "_ studied the consequence of misplaced partitions on dynamical invariants  @xcite , while teramoto and komatsuzaki investigated topological change in the symbolic dynamics upon different choices of markov partitions  @xcite . on the other hand ,",
    "the degree of self - sufficiency of the symbolic dynamics , irrespective of the equivalence to the original dynamics , has started to gain increasing interest , focusing on information - theoretical measures such as information closure and prediction efficiency  @xcite .",
    "we here adopt a different perspective and study how causal structures emerge and/or change under different choices of partitioning .",
    "the symbolic description of a dynamical system leads naturally to an interpretation of such systems as stochastic processes @xcite .",
    "let @xmath17 be a measure space with borel field @xmath18 and probability measure @xmath19 such that @xmath20 $ ] and @xmath21 .",
    "furthermore , assume that @xmath19 is the unique ergodic invariant measure under the mapping @xmath22 , that is @xmath23 given the partitioning defined by eq .  , the symbol space ( alphabet ) @xmath24 is made of @xmath25 symbols ( alphabet letters ) , @xmath26 we can formally define a random variable @xmath27 as a measurable function @xmath28 with the probabilities given by @xmath29 this line of reasoning can be generalized to accommodate joint probabilities of arbitrary finite length , @xmath30 the probabilities in eqs .   and   are time - invariant because @xmath19 is invariant as assumed in eq .  . within this setting , @xmath31 denotes the probability that the symbolic state of the system ( at any time ) is equal @xmath32 , while @xmath33 is the probability of the current and next symbols being @xmath32 and @xmath34 , respectively .",
    "therefore , this framework defines a discrete stochastic process where the symbolic states are regarded as random variables whose stationary joint distributions are determined by eqs .   and  .",
    "we point out that the support of such a stochastic process associated with the symbolic dynamics * *  * * is commonly referred to as a shift space  @xcite .",
    "for a given symbolization of a dynamical system that originates from a chosen partitioning of the phase space , we are interested in defining and identifying a minimal set of past states that encode information about the current state @xmath35 .",
    "this will enable us to remove redundant information of the past when making efficient predictions about the future .      in view of the probabilistic interpretation of the symbol dynamics , we refer to a partition as markovian of order @xmath36 if the resulting stochastic process is markov order @xmath36 ; that is , if the symbolic state only depends on its past @xmath36 states rather than on the entire history .",
    "using the following notations @xmath37 a process is markov order @xmath36 if and only if the conditional probabilities satisfy @xmath38 for every choice of @xmath39 and no nonnegative integer smaller than @xmath36 fulfills this requirement .",
    "( when @xmath40 , we call the process an i.i.d . *",
    "*  * * process . ) in other words , information carried in the past states * *  * * is all conditionally redundant given information about the past @xmath36 states .",
    "on the other hand , there might be further redundancy in the information encoded in these @xmath36 states .",
    "in particular , let @xmath41 be a minimal set contained in the markov time indices for which @xmath42 holds for every @xmath39 .",
    "therefore for every proper subset @xmath43 of @xmath44 eq .",
    "( [ eq : causal ] ) does not hold .",
    "we refer to @xmath44 as the set of _ causal time parents _ of time @xmath2 .",
    "conditioning on the states with time indices given by @xmath44 , information of all other states becomes redundant .",
    "the states at time(s ) @xmath44 are the only ones that cause the current state , and therefore the set @xmath44 defines a causal structure of the symbolic dynamics .",
    "this can be viewed as a finer description than the markov order , which in turn allows for a more efficient encoding of the process .",
    "figure  [ fig2 ] illustrates the difference between markov order and causal structure of an example process .",
    ", although only three ( marked in red ) out of the four past time indices ( enclosed by dashed box ) are needed to render the current state ( green ) conditionally independent of the rest of the past .",
    "the set of causal time parents of @xmath2 is therefore @xmath45 in eq .  .",
    ", scaledwidth=50.0% ]      practical evaluation of joint probabilities is delicate for two reasons : first , numerical imperfections due to finite precision of the computing machines are unavoidable ; second , when the probabilities need to be estimated from finite data samples , estimation errors are inevitable .",
    "naturally , the appearance of such numerical and estimation errors will propagate into eqs .   and  , making it difficult to distinguish equalities from inequalities .",
    "these equations need to be examined for joint sequences , leading to an overwhelming number of ( heuristic ) decisions that need to be made .",
    "this , in turn , renders unreliable the direct determination of markov order and causal structure based on their respective formal definitions . from a statistical standpoint",
    ", it is preferable to base such determination on a minimal number of equations / decisions .",
    "appropriately defined information - theoretic measures fulfill this goal by collectively grouping the joint probabilities , therefore greatly reducing the number of equations / decisions .",
    "recall that shannon entropy is a quantitative measure of the uncertainty of a random variable . for a discrete random variable @xmath46 with probability mass function @xmath47 , its entropy is defined as  @xcite @xmath48 where @xmath49 is taken to be base @xmath50 throughout the paper .",
    "the mutual information between two random variables @xmath46 and @xmath51 is given by  @xcite @xmath52 mutual information measures the deviation from independence between @xmath46 and @xmath51 .",
    "it is generally nonnegative and equals zero if and only if @xmath46 and @xmath51 are independent .",
    "similarly , the conditional mutual information between @xmath46 and @xmath51 given @xmath53 is defined as  @xcite @xmath54 and it measures the reduction of uncertainty of @xmath46 ( @xmath51 ) due to @xmath51 ( @xmath46 ) given @xmath53 .",
    "conditional mutual information is nonnegative , and equals zero if and only if @xmath46 and @xmath51 are conditionally independent given @xmath53 .",
    "for a stationary stochastic process @xmath55 and a given set of time indices @xmath56 , we propose to define the ( temporal ) causation entropy ( cse ) from @xmath57 to @xmath2 to be @xmath58 being a conditional mutual information , causation entropy is always nonnegative .",
    "it is strictly positive if and only if uncertainty about the state @xmath35 is reduced due to the knowledge about @xmath59 .",
    "this occurs when the past states with time indices @xmath57 carry information about the current state at time @xmath2 .",
    "we remark that eq .",
    "( [ newdef ] ) is an adapted definition of causation beyond our previous work  @xcite  for a specific scenario , in the sense that direct causality is now intimately linked to causation entropy being strictly positive without the need of appropriately choosing the conditioning set .",
    "based on the definition of markov in eq .  , a stochastic process has markov order @xmath36 if and only if @xmath60 for the smallest possible nonnegative integer @xmath36 .",
    "algorithmically , we start by examining eq .   for @xmath40 . if it holds true , then the process is i.i.d . if not , we proceed with @xmath61 , until the equation is satisfied .",
    "the resulting value of @xmath36 is the markov order of the process . as a side remark",
    ", we note that there are other entropy - based approaches to determine the markov order  @xcite .",
    "now we discuss the inference of causal structure via causation entropy . given the definition of causal structure in eq .",
    ", it follows that a markov process of order @xmath36 has causal time parents @xmath44 if and only if @xmath62 where @xmath63 and no proper subset of @xmath44 fulfills the equation .",
    "computationally , it is generally infeasible to efficiently find the causal structure without additional assumptions about the underlying joint distributions . a general assumption , called the faithfulness or stability assumption , requires that the joint effect / cause is decomposable into individual components  @xcite .",
    "that is to say , for every @xmath64 , the contribution measured in terms of the conditional mutual information @xmath65 is non - vanishing for every @xmath66 that does not include @xmath67 or @xmath2 . under this assumption",
    ", we can show that the causal time parents @xmath44 form the minimal set of time indices that maximizes causation entropy  @xcite , i.e. , @xmath68 we refer to eq .",
    "( [ ocse ] ) to as the optimal causation entropy principle , which allows the transformation of the causal inference problem into a numerical optimization problem .",
    "algorithmically , we propose to infer the causal set @xmath44 via a two - stage iterative process , described as follows .",
    "the first stage , which we call aggregative discovery , starts by finding a time index @xmath69 which maximizes the mutual information @xmath70 provided that such mutual information is strictly positive .",
    "that is , @xmath71 then , at each subsequent step , a new time index @xmath72 is identified among the rest of the indices to maximize the conditional mutual information given the previously selected time indices , that is , @xmath73 such iterative process ends when the corresponding maximum conditional mutual information equals zero , and the outcome yields a set of time indices @xmath74 .",
    "then , in the second stage , we progressively remove time indices in @xmath66 that are redundant ( i.e. , do not belong to @xmath44 ) . in particular , we enumerate through the time indices in @xmath66 and remove each component @xmath75 for which @xmath76 every time a component is removed , the set @xmath66 is updated accordingly",
    ". the end of the process is then inferred as the set of causal time parents @xmath44 .",
    "we remark that the discovery and removal stages of our algorithm are reminiscent of the forward selection and backward elimination in regression analysis  @xcite . here , for the purpose of correct and consistent inference of markov order and causal structure , we have adopted conditional mutual information in our algorithm .",
    "@xcite .",
    "two practical considerations need to be taken into account for the inference of markov order and causal structure .",
    "first , the history of a variable needs to be truncated , i.e. , @xmath77 will be approximated by @xmath78 for some @xmath79 in eq .",
    "( regarding markov order ) and eqs .",
    "( [ eq : ocsef1]-[eq : ocsef2 ] ) ( regarding causal structure ) .",
    "in particular , such truncation leads to a partial fulfillment of both the markov requirement in eq .   and causal structure in eq .  .",
    "second , numerical and estimation errors generally render information - theoretic quantities such as the mutual information , conditional mutual information , and causation entropy nonzero ( and in particular , even negative  @xcite ) . in order to decide whether or not an estimate should be regarded as zero , one needs a threshold - selecting procedure  @xcite : an estimated quantity smaller than a predefined threshold will be considered vanishing .",
    "in this section we provide an application of our theoretical procedure in determining the markov order and causal structure of symbolic dynamics of the tent map . the primary reason why we have chosen the one - dimensional tent map as an example is twofold .",
    "first , the tent map is simple enough to allow explicit analytical computations of the entropic functionals of known probability distributions .",
    "such computations are not only useful for cross - checking numerical estimates , they also provide some insights into the information - theoretic measures employed in our investigation .",
    "second , regardless of its simple form , the tent map appears to serve as a rich test - bed for the investigation of how markov order and causal structure of a dynamical system are affected by the choice of symbolization .",
    "in fact , under symbolization , even a 1d map such as the tent map can be regarded quite complex from a topological standpoint  @xcite .",
    "finally , we remark that our computational framework can be applied to arbitrary unimodal maps .",
    "the tent map is a one - dimensional system given by @xmath80 where @xmath81\\rightarrow\\lbrack0,1]$ ] is defined as @xmath82 specifically , we shall discuss the manner in which different choices of the partitioning lead to ( qualitatively and quantitatively ) different symbolizations of the original dynamics with specific markov orders and causal structures . for the time being , we limit our investigation to a binary symbolic description of the dynamical map . consider a general binary partitioning of the phase space defined by the parameter @xmath83 , so that @xmath84\\}.\\ ] ] such partitioning allows us to represent a continuous trajectory by a sequence of binary symbols ( bits ) .",
    "we remark that * *  * * the choice of @xmath85 leads to a generating partition which gives rise to a symbolic dynamics that is topologically equivalent to the original system  @xcite .",
    "the unique ergodic invariant measure of the tent map can be found by solving the first equation in   ( also called a continuity equation ) for each subinterval of @xmath86 $ ] , leading to @xmath87)=b - a.\\ ] ] this immediately gives @xmath88 and @xmath89 . from eq .  , the joint probability of an arbitrary sequence of length @xmath90 is determined by @xmath91 where the intervals are defined by the preimages of @xmath92 and @xmath93 $ ] as @xmath94   : t^{l}\\left (   x\\right )   \\in\\left [   0\\text { , } \\alpha\\right ) \\right\\ }   , \\\\",
    "i_{l}^{\\left (   1\\right )   } \\overset{\\text{def}}{=}\\left\\ {   x\\in\\left [ 0,1\\right ]   : t^{l}\\left (   x\\right )   \\in\\left (   \\alpha\\text { , } 1\\right ] \\right\\ }   .",
    "\\end{cases } \\label{eq : preimage}\\ ] ] in other words , the initial conditions corresponding to a specific symbolic string of length @xmath95 are formed by a finite disjoint union of intervals .",
    "figure  [ fig4 ] shows an example of these intervals @xmath96 for @xmath97 and four levels @xmath98 .",
    "( green ) and @xmath99 ( red ) are defined by eq .   and are shown for levels @xmath98 for the choice of @xmath97 . in general , at each level @xmath100 , the subintervals start from @xmath101 and then alternate in between @xmath99 and @xmath101 .",
    "the relative ordering of the subintervals across levels can change for different values of @xmath102 , although they remain the same as shown in the picture for all @xmath103.,scaledwidth=59.0% ]    this offers a computationally feasible description with which joint probabilities can be calculated . from eq .",
    ", we obtain that for @xmath104 , @xmath105 , giving @xmath88 and @xmath89 as expected .",
    "for @xmath106 , we have @xmath107 .",
    "this gives the probabilities @xmath108 , @xmath109 , @xmath110 , and @xmath111 for all @xmath112 ( see also fig .",
    "[ fig4 ] ) . for general values of @xmath95",
    ", we proceed as follows .",
    "first , we define the level-@xmath100 preimages of @xmath102 to be @xmath113 ( @xmath114 ) , which are the roots of the equation @xmath115 for convenience , we sort @xmath113 in the ascending order of @xmath116 and , additionally , define @xmath117 and @xmath118 .",
    "then , the preimages sets of @xmath92 and @xmath93 $ ] as introduced in eq .",
    "can be explicitly computed as ( for every @xmath119 ) @xmath120 such preimages sets are subsequently used to calculate joint probabilities .",
    "note that for symbolic strings of length @xmath95 , both the total number of joint probabilities and the total number of intervals contributing to these probabilities equal @xmath121 .",
    "note that the joint probability of the symbol sequence @xmath122 depends on the particular choice of the partitioning point @xmath102 .",
    "however , the functional @xmath102-dependences of such probabilities remain the same for all @xmath102 values within intervals determined by the @xmath121 distinct roots @xmath123 of the equation @xmath124 , given by @xmath125    we emphasize that although the analytical expressions derived above are specialized to the tent map , the proposed procedure is , * *  * * in general , suitable for the computation of joint probabilities of arbitrary unimodal maps  @xcite .",
    "we numerically investigate the markov order of the stochastic processes arising from the symbolic dynamics of the tent map .",
    "recall from eqs .   and   that the markov order can be determined as the smallest nonnegative integer @xmath36 for which the causation entropy @xmath126 vanishes .",
    "the markov order reveals the length of the history that carries unique information about the present symbolic state of the system .",
    "figure  [ fig5 ] shows the causation entropy @xmath126 as a function of @xmath36 for a few choices of the partitioning point @xmath102 with values equal to @xmath127 , @xmath128 , @xmath129 , and @xmath130 , respectively . for each @xmath102 ,",
    "the causation entropy decreases in @xmath36 .",
    "such monotonic dependence of @xmath36 is in fact of general validity since for every @xmath131 , the difference of causation entropies @xmath132 can be expressed in terms of a conditional mutual information , which is nonnegative . on the other hand , the mutual information @xmath133 , @xmath134 , ...",
    ", @xmath135 generally increases in @xmath36 and saturates when the causation entropy reaches zero .",
    "results shown in fig .  [ fig5 ] suggest that markov orders can be different upon different choices of the partition point , yielding @xmath136 for @xmath137 , @xmath138 for @xmath139 , @xmath40 for @xmath85 , and @xmath140 for @xmath141 , respectively .",
    "such difference is remarkable given the relative small differences in the values of @xmath102 .",
    "how does the markov order depend on the partition point @xmath102 in general ?",
    "we address this question by computing the causation entropy @xmath126 in eq .   as a function of @xmath102 for a range of @xmath36 values , @xmath142 .",
    "the results are shown in fig .",
    "visually , the symbolic dynamics achieves markov order @xmath36 at the values of @xmath102 for which all curves beyond the @xmath143-th one reach zero .",
    "for example , fig .",
    "[ fig6 ] confirms the same markov orders for the @xmath102 values as shown in fig .",
    "interestingly , the markov order seems to depend sensitively on the choice of partitioning : a tiny bit of change in @xmath102 generally results in a ( large ) change in the markov order .",
    "this behavior is evident from the non - smooth and fractal appearance of the curves in fig .",
    "[ fig6 ] and , from the seemingly erratic manner in which they overlap and collapse .",
    "( a ) and mutual information @xmath144(b ) as functions of @xmath36 for various choices of @xmath102 .",
    "the results imply that the markov order of the symbolic dynamics of the tent map equals @xmath145 ( @xmath137 ) , @xmath146 ( @xmath139 ) , @xmath147 ( @xmath85 ) , and @xmath148 ( @xmath141 ) , respectively . in the numerical calculations , we approximate @xmath77 by its finite truncation @xmath149.,scaledwidth=85.0% ]",
    "having explored the influence of the location of the partition point @xmath102 , we ask : how do partition _ refinements _ affect the markov order ?",
    "we now extend our investigation to non - binary symbolic descriptions of the tent map .",
    "consider a _ map refinement _ of a given partitioning @xmath150  * ? ? ?",
    "* , which is given by the intersection of the original partition elements and their preimages under @xmath22 , as @xmath151 inspecting eq .   and the definition of markov order given by eq .",
    ", we conclude that if the markov order resulting from the original partition @xmath152 is @xmath36 , then the markov order upon the map - refinement partition @xmath153 equals @xmath154 if @xmath155 , and is less or equal to @xmath156 if @xmath157 ( see proof in the appendix ) .",
    "this result is numerically confirmed in fig .",
    "[ fig7](a ) for the tent map . in particular , for the original partition point @xmath85 , the markov order equals @xmath147 and map refinement increases it by @xmath156 while further map refinement does not change the order . on the other hand , for @xmath137 which yields markov order @xmath145 ,",
    "each map refinement decreases its order by @xmath156 until the order reaches @xmath156 .",
    "interestingly , the same does not hold true for _ arbitrary _ refinements of the partition .",
    "[ fig7](b ) shows that a general refinement can either increase , decrease , or maintain the markov order of the resulting process .",
    "there seems to be no predicable pattern for which the markov order changes upon arbitrary refinement .",
    "this behavior is further explored in fig .",
    "[ fig7](c ) , which shows that for a specific initial partition ( here @xmath137 ) , different locations of the new partition point generally result in different markov orders .",
    "once again , such behavior appears in an irregular pattern .",
    "( for @xmath158 ) are computed and shown for a range of @xmath102 values : @xmath83(a ) and @xmath159(b ) .",
    "vertical dashed lines in panel ( b ) mark four specific choices of @xmath102 : 0.444 , 0.47 , 0.5 , and 0.516 , respectively .",
    "a grayscale bar is shown below each plotting panel to visualize the numerically determined markov order as a function of @xmath102 , where a darker color corresponds to a higher markov order ( white corresponds to order @xmath147 ) . for each @xmath102 , the markov order",
    "is numerically determined as the smallest integer @xmath36 such that @xmath160.,scaledwidth=80.0% ]     while the new partition point varies from @xmath147 to @xmath156 . in all calculations , we truncated @xmath77 as @xmath161 .",
    "a grayscale bar in the bottom of ( c ) shows the numerically computed markov order as a function of @xmath102 , where a darker color corresponds to a higher markov order ( white corresponds to order @xmath147 ) . for each @xmath102 ,",
    "the corresponding markov order is computed as the smallest integer @xmath36 for which @xmath160.,title=\"fig:\",scaledwidth=80.0% ]   while the new partition point varies from @xmath147 to @xmath156 . in all calculations , we truncated @xmath77 as @xmath161 .",
    "a grayscale bar in the bottom of ( c ) shows the numerically computed markov order as a function of @xmath102 , where a darker color corresponds to a higher markov order ( white corresponds to order @xmath147 ) . for each @xmath102 ,",
    "the corresponding markov order is computed as the smallest integer @xmath36 for which @xmath160.,title=\"fig:\",scaledwidth=80.0% ]      finally , we turn to the causal structure of a symbolic dynamics , which provides a description of the process finer than the markov order .",
    "unlike the markov order , causal structure quantifies the minimal amount of the past history that is needed to mitigate the uncertainty about the present symbolic state .    for the tent map , the uncertainty of the symbolic state",
    "as measured by the entropy @xmath162 achieves its maximum at @xmath85 . including information of past states",
    "generally reduces the uncertainty , as shown in fig .",
    "[ fig8](a ) , except at @xmath85 , which is in fact a point for which the symbolic dynamics is topologically conjugate ( equivalent ) to the original one .",
    "the fact that the @xmath85 partition creates an i.i.d .",
    "process is interesting because from the dynamic equation of the system , states that are adjacent in time are intimately linked and expected to be causally related .",
    "an important conclusive message here is the following : partitioning of the phase space that results in a symbolic dynamics that is equivalent to the original dynamics can in fact yield a causal structure which differs significantly from that inferred from the form of the equations of the original system .",
    "recall that a process is markov of order @xmath36 if no further reduction is possible beyond the @xmath36-th past state .",
    "however , the extent to which uncertainty is reduced does not need to be monotonic in time indices .",
    "in other words , the immediate past does not necessarily encode the most amount of information about the present state .",
    "in fact , for several values @xmath102 ( e.g. , @xmath137 and @xmath139 ) , the difference between conditional entropy @xmath163 for consecutive @xmath36 s is not monotonically decreasing in @xmath36 [ fig .",
    "[ fig8](b ) ] , vertical spacing between curves ) . applying the ocse algorithms to infer the causal structure for these @xmath102 values , we confirmed the markov order previously computed , and more importantly , found that the relative importance of past time states are ordered in a non - monotonic manner , namely @xmath164 for @xmath137 ( markov order @xmath136 ) and @xmath165 for @xmath139 ( markov order @xmath138 )",
    ". we examine all values of @xmath102 in the interval @xmath86 $ ] in a uniform manner : @xmath166 , using a threshold value of @xmath167 for the causation entropy at the given @xmath102 .",
    "the results are shown in fig .",
    "in particular , we found several examples for which the markov order satisfies @xmath168 while the number of causal parents is strictly less than @xmath36 ( i.e. , certain markov time indices are skipped in the causal structure ) .     for values of @xmath169 , for the entire range of @xmath83(a ) and a subrange @xmath159(b ) .",
    "vertical dashed lines in both panels mark four specific choices of @xmath102 : 0.444 , 0.47 , 0.5 , and 0.516 , respectively .",
    ", scaledwidth=85.0% ]     is chosen from @xmath170 .",
    "for each @xmath102 we distinguish the first causal parent computed from the forward ( aggregative discovery ) step of the ocse algorithm ( light red ) , all causal parents of @xmath2 from the set @xmath171 ( gray ) , and noncausal components ( black ) . in all computations we used a threshold @xmath167 under which causation entropy is regarded as zero .",
    ", scaledwidth=90.0% ]",
    "symbolization is a common practice in data analysis : in the field of dynamical systems , it bridges topological dynamics and stochastic processes through partitioning / symbolization of the phase space ; in causality inference , it allows for the description of continuous random variables by discrete ones . symbolized data , in turn ,",
    "are not as demanding in terms of precision and are often considered more robust with respect to parameters and noise  @xcite .    motivated by the problem of uncovering causal structures from finite , discrete data , we investigated the symbolization of outputs from a simple dynamical system , namely the tent map .",
    "we provided a full description of the joint probabilities occurring from partitioning / symbolization of the phase space and investigated how markov order and causal structure can be determined from these probabilities in terms of causation entropy , an information - theoretical measure .",
    "we found that in general , partitioning of the phase space strongly influences the markov order and causal structure of the resulting stochastic process in an irregular manner which is difficult to classify and predict .",
    "in particular , a small change in the partition can lead to relatively large and unexpected changes in the resulting markov order and causal structure . to the best of our knowledge , this is the first attempt in the literature that aims at unravelling the intricate dependence of inferred causal structures of dynamical systems on their different symbolic descriptions analyzed in an information - theoretic setting .",
    "furthermore , although the effects of map refinements are well understood , it remains a main challenge to discover the exact consequences of arbitrary refinements . especially for this reason , we have left the application of our approach to more complex dynamical systems and/or experimental time - series data to future investigations .    on a different perspective",
    ", we note that although * *  * * finding partitions that preserve dynamical invariants ( i.e. , generating partitions ) are known to be a real challenge especially for * *  * * high - dimensional systems  @xcite , it is yet unclear whether or not such challenge remains when considering partitions that maintain markov order and/or causal structure .",
    "this venue of research can be especially interesting to explore given recent advances in many different perspectives on partitioning the phase space including adaptive binning  @xcite , ranking and permutation of variables @xcite , and nearest - neighbor statistics @xcite .",
    "finally , we remark that the non - uniqueness of symbolic descriptions of a system implies that important concepts such as the markov order and causal structure are not necessarily absolute concepts : rather , they unavoidably depend on the observational process , just like classical relativity of motion and quantum entanglement  @xcite .",
    "this , in turn , suggests the possibility of the causal structure of the very same system to be perceived differently , even given unlimited amount of data .",
    "the concept of causality , therefore , is observer - dependent .",
    "we thank dr .",
    "samuel  stanton from the united states army research office ( aro ) complex dynamics and systems program for his ongoing and continuous support .",
    "this work was funded by aro grant no .",
    "w911nf-12 - 1 - 0276 .",
    "we will prove that for a transformation @xmath22 that has a uniquely ergodic invariant probability measure @xmath19 , the markov order of the stochastic process resulting from a partition @xmath152 of the phase space decreases strictly by one under a map refinement of the partition unless the original markov order is less or equal to one .",
    "* definition : markov order of a partition . * consider a measure - preserving transformation @xmath3 on a compact metric space with a uniquely ergodic invariant probability measure @xmath19  @xcite .",
    "let @xmath172 be a measurable partition of the phase space that yields a stochastic process with time - invariant joint probabilities @xmath173 if such a process is markov of order @xmath36 , we define the markov order of the partition to be @xmath36 .      *",
    "definition : map refinement . *",
    "consider a measure - preserving transformation @xmath3 with a probability measure @xmath19 .",
    "the map refinement of a given measurable partition @xmath172 is defined as the partition @xmath174    * theorem ( markov order upon map refinement . ) * consider a measure - preserving transformation @xmath3 on a compact metric space with a uniquely ergodic invariant probability measure @xmath19 .",
    "let @xmath172 be a partition of @xmath4 and @xmath153 be its map refinement .",
    "suppose that the markov order of @xmath152 and @xmath153 are @xmath36 and @xmath175 , respectively .",
    "it follows that @xmath176 for @xmath157 , and @xmath177 when @xmath155._proof .",
    "_ we shall denote the probabilities resulting from the map refinement of @xmath152 as @xmath178 where @xmath179 .",
    "since every sequence @xmath180 is determined by some orbit @xmath181 of @xmath22 under the partition @xmath153 , it follows that @xmath182 if and only if @xmath183 . on the other hand",
    ", @xmath184 implies that @xmath185 .",
    "therefore @xmath186 in eq .   and @xmath187 for all sequences @xmath188 with nonvanishing probability .",
    "then , the theorem follows from applying eq .   to the definition of markov order given in eq .   rewritten using the product rule ( chain rule ) of conditional probability.@xmath189                              j. runge , j. heitzig , n. marwan , and j. kurths , _ quantifying causal coupling strength : a lag - specific measure for multivariate time series related to transfer entropy _ , phys .",
    "e * 86 * , 061121 ( 2012 ) .",
    "a. porta , l. faes , v. bari , a. marchi , t. bassani _ et .",
    "_ , _ effect of age on complexity and causality of the cardiovascular control : comparison between model - based and model - free approaches _ , plos one * 9 * e89463 ( 2014 ) .",
    "t. haruna and k. nakajima , _ symbolic transfer entropy rate is equal to transfer entropy rate for bivariate finite - alphabet stationary ergodic markov processes _ , the european physical journal b * 86 * , 1 ( 2013 ) .",
    "e. m. bollt , t. stanford , y .- c .",
    "lai , and k. zyczkowski , _ what symbolic dynamics do we get with a misplaced partition ? on the validity of threshold crossing analysis of chaotic time - series _ , physica * d154 * , 259 ( 2001 ) .",
    "a. porta , p. castiglioni , v. bari , t. bassani , a. marchi , a. cividjian , l. quintin , and m. di rienzo , _",
    "@xmath192-nearest - neighbor conditional entropy approach for the assessment of the short - term complexity of cardiovascular control _",
    "34 * , 17 ( 2013 ) ."
  ],
  "abstract_text": [
    "<S> identification of causal structures and quantification of direct information flows in complex systems is a challenging yet important task , with practical applications in many fields . </S>",
    "<S> data generated by dynamical processes or large - scale systems are often symbolized , either because of the finite resolution of the measurement apparatus , or because of the need of statistical estimation . by algorithmic </S>",
    "<S> application of causation entropy , we investigated the effects of symbolization on important concepts such as markov order and causal structure of the tent map . </S>",
    "<S> we uncovered that these quantities depend nonmontonically and , most of all , sensitively on the choice of symbolization . </S>",
    "<S> indeed , we show that markov order and causal structure do not necessarily converge to their original analog counterparts as the resolution of the partitioning becomes finer .    * * * although based on a simple mathematical model , our results shed new light on the challenging nature of causality inference . * </S>"
  ]
}