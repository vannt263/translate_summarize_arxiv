{
  "article_text": [
    "left - censored data is a characteristic of many datasets . in physical science applications",
    ", observations can be censored due to limit of detection and quantification in the measurements .",
    "for example , if a measurement device has a value limit on the lower end , the observations is recorded with the minimum value , even though the actual result is below the measurement range . in fact",
    ", many of the hiv studies have to deal with difficulties due to the lower quantification and detection limits of viral load assays @xcite . in social science studies , censoring may be implied in the nonnegative nature or defined through human actions .",
    "economic policies such as minimum wage and minimum transaction fee result in left - censored data , as quantities below the thresholds will never be observed . with advances in modern data collection ,",
    "high - dimensional data where the number of variables , p , exceeds the number of observations , n , are becoming more and more commonplace .",
    "hiv studies are usually complemented with observations about genetic signature of each patient , making the problem of finding the association between the number of viral loads and the gene expression values extremely high dimensional .",
    "hence , it is important to develop inferential methods for left - censored and high - dimensional data .",
    "a general approach to estimation of the unknown parameter @xmath2 in high dimensional settings , is given by the penalized m - estimator @xmath3 where @xmath4 is a loss function ( e.g. , the negative log - likelihood ) and @xmath5 is a penalty function with a tuning parameter @xmath6 .",
    "examples include but are not limited to the lasso , scad , mcp , etc .",
    "significant progress has been made towards understanding the estimation theory of penalized m - estimators with recent breakthroughs in quantifying the uncertainty of the obtained results .",
    "however , no general theory exists for high - dimensional estimation in the setting of left - censored data , not to mention for understanding their uncertainty .",
    "a few challenges of left - censored data are particularly difficult even in low - dimensional settings .",
    "left - censored models rarely obey particular distributional forms , preventing the use of likelihood theory and demanding for estimators that are semi - parametric in nature .",
    "for the same reasons , the estimators need to be robust to the presence of outliers in the design or model error .",
    "lastly , theoretical results can not be obtained using naive taylor expansions and require the development of novel concentration of measure results .    to bridge this gap",
    ", this paper proposes a new mechanism , named as _ smoothed estimating equations _ ( see ) and _ smoothed robust estimating equations _ ( sree ) , for construction of confidence intervals for low - dimensional components in high - dimensional left - censored models . for a high - dimensional parameter of interest @xmath7",
    ", we aim to provide confidence intervals @xmath8 for any of its coordinates @xmath9 while adapting to the left - censored nature of the problem .",
    "no distributional assumption will be made on the model error .",
    "t the proposed estimators and confidence intervals are thus semiparametric .",
    "the main challenge in such setting is the non - differentiability of many of semiparametric loss functions , e.g , the least absolute deviation ( lad ) loss . to handle this challenge , we apply a smoothing operation on the high dimensional estimating equations , so that the obtained see become smooth in the underlying @xmath10 .",
    "moreover , see are designed to handle high - dimensional model parameters and hence differ from the classical approaches of estimating equations .",
    "although we consider left - censored models , the proposed see equations are quite general and can apply to any non - differentiable loss function even with fully observed data . for example , they can provide valid confidence sets using penalized rank estimator with both convex and non - convex penalties .",
    "we establish theoretical asymptotic coverage for confidence intervals while allowing left - censoring and @xmath11 .",
    "moreover , for the estimators resulting from the see and sree equations , we provide delicate bahadur representation and establish the order of the residual term . under mild conditions , we show that the effects of censoring asymptotically disappear , a result that is novel and of independent interest even in low - dimensional setting .",
    "additionally , we establish a number of new uniform concentration of measure results particularly useful for many left - censored models .    to further broaden our framework we formally develop robust mallow s , schweppe s and hill - ryan s estimators that adapt to the unknown censoring .",
    "we believe these estimators to be novel even in low - dimensional setting .",
    "this generalizes the classical robust theory developed by @xcite .",
    "we point out that the see framework can be viewed as an extension of the de - biasing framework of @xcite .",
    "in particular , the confidence intervals resulting from the see estimator are asymptotically equivalent to the confidence intervals of de - biasing methods in the case of a smooth loss function and non - censored observations .",
    "however , sree confidence sets provide robust alternative to the naive de - biasing as the resulting inference procedures are robust to the distributional misspecifications , and most appropriate for applications with extremely skewed observations .",
    "given the prevalence of left - censored data , a large body of work in model estimation and inference has been dedicated to the topic .",
    "estimation in the left - censored models has been studied since the 1950 s .",
    "@xcite first proposed the model with a nonnegative constraint on the response variable , which is also known as the tobit - i model .",
    "later , @xcite proposed a maximum likelihood estimator where a data transformation model is considered , and then impose a class of distributions for the resulting model error . however , as zellner has noted @xcite , knowledge of the underlying data generating mechanism is seldom available , and thus models with parametric distributions may be subject to the distributional misspecification .",
    "@xcite , @xcite , and @xcite pioneered the development of robust inference procedures for the left - censored data , and relieved the assumption on model error distribution in prior work .",
    "@xcite introduced a lad estimator , whereas @xcite introduced robust estimators and inference based on maximum entropy principles .",
    "@xcite proposed an alternative robust two - step estimator , while @xcite and @xcite developed distribution free and rank - based tests .",
    "for these models , the common assumption is that @xmath12 .    for high - dimensional models , and with lasso being the cornerstone of achieving sparse estimators @xcite ,",
    "numerous efforts have been made on establishing finite sample risk oracle inequalities of penalized estimators ; examples include @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and@xcite .",
    "regarding censored data , @xcite offered a penalized version of powell s estimator .",
    "however , substantially smaller efforts have been made toward high - dimensional inference , namely confidence interval construction and statistical testing in the uncensored high - dimensional setting , not to mention in the censored high - dimensional setting .",
    "recently , @xcite , @xcite and @xcite have corrected the bias of high - dimensional regularized estimators by projecting its residual to a direction close to that of the efficient score .",
    "such technique , named de - biasing , is parallel to the bias correction of the nonparametric estimators in the semiparametric inference literature @xcite .",
    "@xcite considered an extension of this technique to generalized linear model , while @xcite and @xcite considered extensions to graphical models .",
    "@xcite developed a three - step bias correction technique for quantile estimation .",
    "for inference in censored high - dimensional linear models , to the best of our knowledge , there has been no prior work .",
    "it is worth pointing out that the main contribution of this paper is in understanding fundamental limits of semiparametric inference for left - censored models .      in section 2 ,",
    "we propose the smoothed estimating equations ( see ) for left - censored linear models . in section 3",
    ", we establish general results for confidence regions and the bahadur representation of the see estimator .",
    "we also emphasize on the new concentration of measure results , the building blocks of the main theorems . in section 4 ,",
    "we develop robust and left - censored mallow s , schweppe s and hill - ryan s estimators and present their theoretical analysis .",
    "section 5 provides numerical results on simulated and real data sets .",
    "we defer technical details to the supplementary materials .",
    "we begin by introducing a general modeling framework followed by highlighting the difficulty for directly applying existing inferential methods ( such are de - biasing , score , wald , etc . ) to the models with left - censored observations .",
    "finally , we propose a new mechanism , named smoothed estimating equations , to construct semi - parametric confidence regions in high - dimensions .",
    "we consider the problem of confidence interval construction where we observe a vector of responses @xmath13 and their censoring level @xmath14 together with covariates @xmath15 .",
    "the type of statistical inference under consideration is regular in the sense that it does not require model selection consistency .",
    "a characterization of such inference is that it does not require a uniform signal strength in the model .",
    "since ultra - high dimensional data often display heterogeneity , we advocate a robust confidence interval framework .",
    "we begin with the following latent regression model : @xmath16 where the response , @xmath17 , and the censoring level , @xmath18 , are observed and the vector @xmath19 is unknown .",
    "this model is often called the semi - parametric censored regression model , whenever the distribution of the error , @xmath20 , is not specified .",
    "we assume that @xmath21 are independent across @xmath22 and are independent of @xmath23 .",
    "matrix @xmath24 $ ] is the @xmath25 design matrix , with @xmath23 being the @xmath26 row .",
    "we also denote @xmath27 as the active set of variables and its cardinality by @xmath28 .",
    "we restrict our study to constant - censored model , also called type - i tobit model , where each entry of the censoring vector @xmath18 is the same . without loss of generality",
    ", we focus on the zero - censored model @xmath29 for the censored model but when @xmath12 , powell introduced a censored least absolute deviation loss ( clad ) , where @xmath30      although great progress has already been made in understanding the hypothesis testing in high - dimensions , directly applying existing methods to the case of left - censored observations might present a challenge .",
    "inference for robust losses in the presence of censoring is particularly difficult @xcite even in low - dimensional setting , and it is well known that left - censoring results do not extend from the results of fully observed data . a similar paradigm exists in high - dimensions .",
    "several problems are immediately evident .",
    "first , if observations are censored , there will hardly be a model error that belongs to the family of unimodal distributions .",
    "thus , it is necessary to make a method that works equally well with symmetric and asymmetric distributions . in other words ,",
    "a robust method is preferred over maximum likelihood or least squares approaches .",
    "second , the optimal inference function depends on the model censoring . in particular",
    ", population hessian matrix for the left - censored data does not have the simple form irrespective of the left - censoring .",
    "therefore , methods that ignore censoring will not be efficient ; vanilla de - biasing @xcite and @xcite can produce biased and conservative confidence intervals with much larger width .",
    "third , the model itself is non - linear and is not well approximated by an additive linear model .",
    "therefore , additive models , although very flexible do not apply to the problem we consider .",
    "although inference in high - dimensions that addresses the first concern has already been proposed and include an lad - based inferential procedure @xcite , a score based procedure @xcite and a quantile - based procedure @xcite , neither of these address the second challenge arriving from the left - censored nature of the data , hence can be highly inefficient .",
    "our estimator is motivated by the principles of estimating equations .",
    "we begin by observing that the true parameter vector @xmath31 satisfies the population system of equations @xmath32=0.\\ ] ] where @xmath33 for a class of suitable functions @xmath34 . for the clad loss @xmath35 and @xmath36 . in high - dimensional setting , where @xmath37 solving estimating equations @xmath38 has several drawbacks . in particular , for semi - parametric estimation and inference in model , the function @xmath39 is non - monotone as the loss is non - differentiable or non - convex .",
    "hence , the system above has multiple roots resulting in an estimator that is ill - posed . instead of solving the system directly ,",
    "we augment it by observing that , for a suitable choice of the matrix @xmath40 , @xmath31 also satisfies the system of equations @xmath41 + { \\boldsymbol { \\upsilon } } [ \\betab -\\betab^ * ] = 0.\\ ] ] to avoid difficulties with non - smoothness of @xmath39 , we propose to consider with a matrix @xmath42 , where the matrix @xmath43 is defined as @xmath44   , \\ ] ] for a smoothed vector @xmath45 defined as @xmath46 in the above display @xmath47 , for a suitable function @xmath48 and @xmath49 whereas , @xmath50 denotes the density of the model error .",
    "additionally , @xmath51 denotes expectation with respect to the random measure generated by the vectors @xmath52 . for the powel s clad loss , we observe that the smoothed vector takes the form @xmath53\\left(w_i(\\betab^*)\\right)^t ,    \\end{aligned}\\ ] ] where @xmath54 denotes the probability measure generated by the errors @xmath20 .",
    "this leads to @xmath55 @xmath56 and a matrix @xmath57 : = 2f_\\varepsilon(0 ) \\sigmab(\\betab^*).\\ ] ] to infer the parameter @xmath31 , we adapt a one - step approach .",
    "we can observe that solving see equations requires inverting the matrix @xmath58 , as we are looking for a solution @xmath2 that satisfies @xmath59 for low - dimensional problems , with @xmath60 , this can efficiently be done by considering an initial estimate @xmath61 and a sample plug - in estimate , @xmath62 , of @xmath63 , @xmath64 and sample estimate of @xmath65 , denoted with @xmath66 .",
    "however , when @xmath11 this is highly ineffective . instead , it is more efficient to directly estimate @xmath67 .",
    "let @xmath68 be an estimate of @xmath69 .",
    "then , the see estimator is defined as @xmath70    proposed see can be viewed as a high - dimensional extension of inference from estimating equations .",
    "although we consider a left - censored linear model , the proposed see methodology applies more broadly .",
    "for example , our framework includes loss functions based on ranks or non - convex loss functions for the fully observed data .",
    "for instance , the method in @xcite is based on inverting kkt conditions might not directly apply for the non - convex loss functions ( e.g. , cauchy loss ) or rank loss functions ( e.g. , log - rank loss ) .",
    "we will introduce the methodology for estimating each row of the matrix @xmath71 .",
    "for further analysis it is useful to define @xmath72 as a matrix composed of row vectors @xmath73 ; @xmath74 where @xmath75 the methodology is motivated by the following simple observation : @xmath76 where @xmath77 $ ] with @xmath78 and @xmath79 this motivates us to consider the following as an estimator for the inverse @xmath71 .",
    "let @xmath80 and @xmath81 denote the estimators of @xmath82 and @xmath83 , respectively .",
    "we will show that a simple plug - in lasso type estimator is sufficiently good for construction of confidence intervals .",
    "we propose to estimate @xmath82 , with the following @xmath84 penalized plug - in least squares regression , @xmath85 notice that this regression does not trivially share all the nice properties of the penalized least squares , as in this case the rows of the design matrix are not independent and identically distributed .",
    "an estimate of @xmath86 can then be defined through the estimate of the residuals @xmath87 we propose the plug - in estimate for @xmath88 as @xmath89 and a bias corrected estimate of @xmath86 defined as @xmath90 observe that the naive estimate @xmath91 does not suffice due to the bias carried over by the penalized estimate @xmath92 .",
    "lastly , the matrix estimate of @xmath71 , much in the same spirit as @xcite is defined with @xmath93    the proposed scale estimate can be considered as the censoring adaptive extension of the graphical lasso estimate of @xcite . certainly , there are alternative procedures for estimating @xmath71 with examples parallel to the dantzig selector .",
    "however , we believe , the choice of tuning parameters for such estimates will depend on the unknown sparsity of @xmath31 , thus will be especially difficult to choose in practice .      whenever the model considered is homoscedastic , i.e. , @xmath94 are identically distributed with a density function @xmath95 ( denoted whenever possible with @xmath96 ) , we propose a novel density estimator designed to be adaptive to the left - censoring in the observations . for a positive bandwidth sequence @xmath97",
    ", we define the density estimator of @xmath98 as @xmath99 of course , more elaborate smoothing schemes for the estimation of @xmath100 could be devised for this problem , but there seems to be no a priori reason to prefer an alternate estimator .    [ remark4 ] we will show that a choice of the bandwidth sequence satisfying @xmath101 suffices .",
    "however , we also propose an adaptive choice of the bandwidth sequence and consider @xmath102 such that @xmath103 for a constant @xmath104 . here , @xmath105 denotes the size of the estimated set of the non - zero elements of the initial estimator @xmath61 , i.e. , @xmath106 .      following the see principles ,",
    "the one - step solution is defined as an estimator , @xmath107    for the presentation of our coverage rates of the confidence interval and , we start with the bahadur representation .",
    "lemmas 1 - 6 ( presented below ) enable us to establish the following decomposition for the introduced one - step estimator @xmath108 , @xmath109 where the vector @xmath110 represents the residual component .",
    "we show that the residual vector s size is small uniformly and that the leading term is asymptotically normal .",
    "the theoretical guarantees required from an initial estimator @xmath61 is presented below .",
    "* condition ( i ) * : [ condition_i ] _ an initial estimate @xmath61 is such that for the left - censored model , irrespective of the density assumptions , the following three properties hold .",
    "there exists a sequence of positive numbers @xmath111 and @xmath112 such that @xmath113 when @xmath114 and @xmath115 , @xmath116 and @xmath117 . _",
    "@xmath84 penalized clad estimator studied in @xcite , under suitable conditions and a choice of the tuning parameter @xmath118 , satisfies the condition ( i ) with @xmath119 .",
    "results of @xcite can be extended to guarantee that @xmath120 and @xmath121  @xmath122 , under the same conditions ( proof is trivial extension of @xcite and is hence not provided ) .",
    "it is worth noting that the above condition does not assume model selection consistency of the initial estimator .    with the normality result of the proposed estimator @xmath123 ( as shown in theorem [ cor : ci ] , section [ sec : theory ] ) , we are now ready to present the confidence intervals .",
    "fix @xmath124 to be in the interval @xmath125 and let @xmath126 denote the @xmath127th standard normal percentile point .",
    "let @xmath128 be a fixed vector in @xmath129 .",
    "based on the results of section [ sec : theory ] , the standard studentized approach leads to a @xmath130 confidence interval for @xmath131 of the form @xmath132 where @xmath133 is defined in and @xmath134 with @xmath135 defined in , @xmath136 defined in and @xmath137 as defined in . in the above , for @xmath138 , the above confidence interval provides a coordinate - wise confidence interval for each @xmath139 , @xmath140 .",
    "notice that the above confidence interval is robust in a sense that it is asymptotically valid irrespective of the distribution of the error term @xmath20 .",
    "we begin theoretical analysis with the following decomposition of @xmath141 we can further decompose the last factor of the last term in as @xmath142 , $ ] where @xmath143.\\ ] ]    to characterize the behavior of individual terms in the decomposition above , we develop a sequence of results presented below that rely on a number of conditions that we explain below .",
    "we begin with a simple design assumption .",
    "* condition ( x ) * : [ condition_x ] _ there exists a bounded constant @xmath144 , such that @xmath145 , for all @xmath146 .",
    "moreover , @xmath23 s are i.i.d .",
    "random variables with @xmath147=1 $ ] , for all @xmath148 and @xmath149 .",
    "for some constant @xmath150 , @xmath151 and @xmath152 take value in interval @xmath153 $ ] , for all @xmath148 and all @xmath154 for a bounded set @xmath155 . _    the bound on @xmath156 is quite standard in high - dimensions @xcite .",
    "however , in many cases , if @xmath157 follows an unbounded distribution , we can approximate its distribution with a truncated one .",
    "next , we rely on a set of very mild model error assumptions .",
    "* condition ( e ) * : [ condition_e ] _ the error distribution @xmath158 has median 0 , and is everywhere continuously differentiable , with density @xmath96 , which is bounded above , @xmath159 , and below , @xmath160 .",
    "also , the density @xmath96 is bounded away from 0 at the origin , @xmath161 .",
    "furthermore , @xmath162 is also lipschitz continuous , @xmath163 moreover , the function @xmath164 \\leq k_1 z$ ] and is @xmath165 for @xmath166 near zero and @xmath167 uniformly in @xmath22 .",
    "_    the above assumption is the only condition we assign to the error distribution @xcite .",
    "we require the error density function to be with bounded first derivative .",
    "this excludes densities with unbounded first moment , but includes a class of distributions much larger than the gaussian .",
    "moreover , this assumption implies that @xmath168 are distributed much like the error @xmath94 , for @xmath2 close to @xmath31 and @xmath168 close to the censoring level @xmath169 .",
    "[ lemma0 ] suppose that the conditions * ( x ) * , * ( e ) * hold .",
    "consider the class of parameter spaces modeling sparse vectors with at most @xmath170 non - zero elements , @xmath171 where @xmath111 is a sequence of positive numbers .",
    "then , there exists a fixed constant @xmath172 ( independent of @xmath173 and @xmath174 ) , such that the process @xmath175 satisfies with probability @xmath176 .",
    "@xmath177 \\right| \\leq c",
    "\\left (   \\sqrt{\\frac {    r_n    t   \\sqrt{t }   \\log(n p /\\delta)}{n } }   \\bigvee \\frac {   t \\log(2n p /\\delta)}{n } \\right).\\ ] ]    the preceding lemma immediately implies strong approximation of the empirical process with its expected process , as long as @xmath111 , the estimation error , and @xmath170 , the size of the estimated set of the initial estimator , are sufficiently small .",
    "the power of the lemma [ lemma0 ] is that it holds uniformly for a class of parameter vectors enabling a wide range of choices for the initial estimator .",
    "apart from the condition on the design matrix @xmath157 and the error distribution , we need conditions on the censoring level of the model for further analysis .    * condition ( c ) * : [ condition_c ] _ there exists some constant @xmath178 , such that for all @xmath2 satisfying @xmath179 , @xmath180 where the @xmath181 operation is entry - wise maximization .",
    "_    the censoring level @xmath18 has a direct influence on the constant @xmath182 . in general , higher values for @xmath183 increase the number of censored data .",
    "the bounds for the coverage probability ( see theorem [ cor : fixed : ci ] ) do not depend on the censoring level @xmath18 .",
    "the fact that the censoring level does not directly appear in the results should be understood in the sense that the percentage of the censored data is important , not the censoring level .",
    "* condition ( cc ) * : [ condition_cc ] _ for some compatibility constant @xmath184 and all @xmath2 satisfying @xmath185@xmath186 @xmath187 , the following holds @xmath188(\\betab-\\betab^ * )   s_{\\betab^ * } .$ ] let @xmath189 be the smallest eigenvalue of @xmath190",
    ". then @xmath191 , for @xmath192 .",
    "additionally , @xmath189 is also strictly positive , with @xmath193 and assume @xmath194 .",
    "_    note that this compatibility factor does not impose any restrictions on the censoring of the model , i.e. , it is the same as the one introduced for linear models @xcite . observe that this condition does not impose distribution of @xmath195 to be gaussian or continuous .",
    "however , it requires that @xmath196 , the population covariance matrix , is at least invertible , a condition unavoidable even in linear models .",
    "next , we present a linearization result useful for further decomposition of the bahadur representation .",
    "[ lemma1 ] suppose that the conditions * ( x ) , * ( e ) * * hold . for all @xmath2 , such that @xmath197 , the following representation holds @xmath198 where @xmath199 is defined in .",
    "once the properties of the initial estimator are provided , such is condition * ( i ) * , lemma [ lemma1 ] can be used to linearize the population level difference of the functions @xmath200 and @xmath201 .",
    "together with lemma [ lemma0 ] , lemma [ lemma1 ] allows us to overpass the original highly discontinuous and non - convex loss function . utilizing lemma [ lemma1 ] , conditions * ( i)*-*(cc ) * and representation , the bahadur representation of @xmath123 becomes @xmath202 where @xmath203.\\ \\ \\ \\ \\ \\ \\end{aligned}\\ ] ]    we show that the last four terms of the right hand side above , each converges to @xmath169 asymptotically at a faster rate than the first term on the right hand side of . in order to establish such result , we need to control the scale estimator .",
    "we begin by introducing a basic condition .",
    "* condition ( @xmath204)*:[condition_pc ] _ parameters @xmath82 for all @xmath205 are bounded by @xmath206 , and such that @xmath207 , and @xmath208 , for all @xmath209 .",
    "moreover , @xmath210 is sub - exponential random vector , and @xmath211 .",
    "_    the preceding condition can be traced back to @xcite .",
    "it restricts the conditional mean of the column @xmath212 to be a function of at most @xmath213 other columns of the design matrix @xmath214 .",
    "however , the condition does not impose a particular distributional assumptions .",
    "the following two lemmas help to establish @xmath84 column bound of the corresponding precision matrix estimator .",
    "the first one provides properties of the estimator @xmath92 as defined in .",
    "although this estimator is obtained via lasso - type procedure , significant challenges arise in its analysis due to dependencies in the plug - in loss function .",
    "the design matrix of this problem does not have independent and identically distributed rows .",
    "we overcome these challenges by approximating the solution to the oracle one and without imposing any new conditioning of the design matrix .",
    "[ cor:2 ] let @xmath215 for a constant @xmath216 and let conditions * ( i ) * , * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold",
    ". then , @xmath218    this lemma implies that the precision matrix estimator has distinct limiting behaviors in terms of the magnitude of the censoring level .",
    "in particular , lemma [ cor:2 ] implies that @xmath219 inherits the rates available for fully observed linear models whenever @xmath220 is bounded away from zero .",
    "additionally , if all the data is censored , i.e. , whenever @xmath182 converges to zero at a rate faster than @xmath221 , the estimation error will explode .",
    "these results agree with the asymptotic results on consistency in left - censored and low - dimensional models ; however , they provide additional details through the exact rates of censoring that is allowed .",
    "for example , if the initial estimator is such that @xmath222 is of the order of @xmath223 , then the asymptotic result above matches those of linear models ( see theorem [ thm : clad_temp ] ) .",
    "the choice of the tuning parameter @xmath221 depends on the @xmath224 convergence rate of the initial estimator @xmath111 , and the size of its estimated non - zero set . however , we observe that whenever @xmath111 is such that @xmath225 and the sparsity of the initial estimator is such that @xmath226 , then the optimal choice of the tuning parameter is of the order of @xmath227 .",
    "in particular , any initial estimator that satisfies @xmath228 is sufficient for optimal rates at estimator in a model where @xmath229 and @xmath230 .",
    "the next result gives a bound on the variance of our @xmath92 estimator .",
    "[ lem : temp1 ] let @xmath215 for a constant @xmath216 and let conditions * ( i ) * , * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold . then , for @xmath205 and @xmath231 and @xmath232 defined in @xmath233    next is the main result on the properties of the proposed matrix estimator @xmath234 .",
    "[ lemma2 ] let the setup of lemma [ lem : temp1 ] hold .",
    "let @xmath235 be the estimator as in .",
    "then , for @xmath236 as in , we have @xmath237 moreover , @xmath238    lemma [ lemma2 ] provides easy to verify sufficient conditions for the consistency of a class of semiparametric estimators of the precision matrix for censored regression models . even in low - dimensional setting , this result appears to be new and highlights specific rate of convergence ( see theorem [ thm : clad_temp ] for more details ) .",
    "the one - step estimator @xmath123 relies crucially on the bias correction step that carefully projects the residual vector in the direction close to the most efficient score .",
    "the next result measures the uniform distance of such projection .",
    "[ lemma4 ] let the setup of lemma [ lem : temp1 ] hold . there exists a fixed constant @xmath172 ( independent of @xmath173 and @xmath174 ) , such that the process @xmath239 $ ] satisfies @xmath240 with probability @xmath176 and a constant @xmath241 defined in condition ( * e * ) .",
    "lemma [ lemma4 ] establishes a uniform tail probability bound for a growing supremum of an empirical process @xmath242 .",
    "it is uniform in @xmath243 and it is growing as supremum is taken over @xmath173 , possibly growing ( @xmath244 ) coordinates of the process .",
    "the proof of lemma  [ lemma4 ] is further challenged by the non - smooth components of the process @xmath242 itself and the multiplicative nature of the factors within it .",
    "it proceeds in two steps .",
    "first , we show that for a fixed @xmath243 the term @xmath245 is small . in the second step ,",
    "we devise a new epsilon net argument to control the non - smooth and multiplicative terms uniformly for all @xmath243 simultaneously .",
    "this is established by devising new representations of the process that allow for small size of the covering numbers . in conclusion",
    ", lemma  [ lemma4 ] establishes a uniform bound @xmath246 in .",
    "size of the remainder term in is controlled by the results of lemmas 1 - 6 and we provide details below .    [ cor : fixed : ci ] let @xmath215 for a constant @xmath216 and let conditions * ( i ) * , * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold . with @xmath247 , @xmath248    we first notice that the expression above requires @xmath249 , a condition frequently imposed in high - dimensional inference ( see @xcite for example ) .",
    "then , in the case of low - dimensional problems with @xmath250 and @xmath251 , we observe that whenever the initial estimator of rate @xmath111 , is in the order of @xmath252 , for a small constant @xmath253 , then @xmath254 .",
    "in particular , for a consistent initial estimator , i.e. @xmath255 we obtain that @xmath256 .",
    "for high - dimensional problems with @xmath257 and @xmath173 growing with @xmath174 , for all initial estimators of the order @xmath111 such that @xmath258 and @xmath259 we obtain that @xmath260 whenever @xmath261 , where @xmath262 .",
    "further discussion is relegated to the comments following theorem [ thm : clad_temp ] .",
    "next , we present the result on the asymptotic normality of the leading term of the bahadur representation .",
    "[ normality ] let @xmath215 for a constant @xmath216 and let conditions * ( i ) * , * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold .",
    "define @xmath263 .",
    "furthermore , assume @xmath264 denote @xmath262 . if @xmath100 , the density of @xmath20 at 0 is known , @xmath265_{jj}^{-\\frac{1}{2}}u_j \\xrightarrow[n , p , \\bar s\\rightarrow\\infty]{d } \\mathcal{n}\\left(0,\\frac{1}{4f(0)^2}\\right ) . \\ ] ]    a few remarks are in order .",
    "theorem [ normality ] implies that the effects of censoring asymptotically disappear .",
    "namely , the limiting distribution only becomes degenerate when the censoring rate asymptotically explodes , implying that no data is fully observed .",
    "however , in all other cases the limiting distribution is fixed and does not depend on the censoring level .",
    "density estimation is a necessary step in the semiparametric inference for left - censored models .",
    "below we present the result guaranteeing good qualities of density estimator proposed in .",
    "[ thm : f ] there exists a sequence @xmath266 such that @xmath267 and @xmath268 and @xmath269 .",
    "assume conditions * ( i ) * , * ( x ) * and * ( e ) * hold , then @xmath270    together with theorem [ normality ] we can provide the next result .",
    "[ cor1 ] with the choice of density estimator as in , under conditions of theorem [ normality ] and [ thm : f ] , the results of theorem [ normality ] continue to hold unchanged , i.e. , @xmath265_{jj}^{-\\frac{1}{2}}u_j \\cdot 2 \\widehat f(0 ) \\xrightarrow[n , p,\\bar s\\rightarrow\\infty]{d } \\mathcal{n}\\left(0,1\\right).\\end{aligned}\\ ] ]    observe that the result above is robust in the sense that the result holds regardless of the particular distribution of the model error .",
    "condition * ( e ) * only assumes minimal regularity conditions on the existence and smoothness of the density of the model errors . in the presence of censoring ,",
    "our result is unique as it allows @xmath11 , and yet it successfully estimates the variance of the estimation error .",
    "combining all the results obtained in previous sections we arrive at the main conclusions .",
    "[ cor : ci ] let @xmath215 for a constant @xmath216 and let conditions * ( i ) * , * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold .",
    "furthermore , assume @xmath271 for @xmath272 .",
    "denote @xmath262 .",
    "let @xmath273 and @xmath274 be defined in and .",
    "then , for all vectors @xmath138 and any @xmath275 , when @xmath276 we have @xmath277    the statements of theorems [ cor : fixed : ci ] and [ normality ] also hold in a uniform sense , and thus the confidence intervals are honest",
    ". in particular , the confidence interval @xmath278 does not suffer from the problems arising from the non  uniqueness of @xmath31 .",
    "we consider the set of parameters @xmath279 let @xmath280 be the distribution of the data under the model . then the following holds .",
    "[ cor : uniform : ci ] under the setup and assumptions of theorem [ cor : ci ] when @xmath281 @xmath282    previous results depend on a set of high - level conditions imposed on the initial estimate .",
    "moreover , rates depend on the initial estimator precisely and to better understand them we present here their summary when the initial estimator @xmath61 is chosen to be penalized clad estimator of @xcite .",
    "[ thm : clad_temp ] let @xmath61 be defined as in @xcite with a choice of the tuning parameter @xmath283 for a constant @xmath284 and independent of @xmath174 and @xmath173 .",
    "assume that @xmath285 , for @xmath286 with @xmath247 .",
    "\\(i ) suppose that conditions * ( x ) * , * ( e ) * , * ( c ) * , * ( cc ) * and * ( @xmath217 ) * hold .",
    "moreover , let @xmath287 for a constant @xmath216 .",
    "then @xmath288 ( ii ) for @xmath205 and @xmath231 and @xmath232 defined in @xmath289    \\(iii ) let @xmath135 defined in . then , for @xmath236 as in , we have @xmath237 moreover , @xmath290    \\(iv ) let @xmath123 be defined as in with @xmath135 defined in , @xmath136 defined in and @xmath137 as defined in .",
    "then , for @xmath286 with @xmath247 , the size of the residual term in is @xmath291    \\(v ) assume that @xmath292 , for @xmath293 with @xmath272 .",
    "let @xmath273 and @xmath274 be defined in and .",
    "then , for all vectors @xmath138 and any @xmath275 , when @xmath294 we have @xmath295    result ( i ) suggests that the rates of estimation match those of simple linear model as long as proportion of censored data is not equal 1 . in that sense ,",
    "our results are also efficient .",
    "moreover , result ( ii ) implies that the rates of estimation of the variance are slower by a factor of @xmath296 compared to the least squares method .",
    "this is also apparent in the result ( iii ) where the rate of convergence of the precision matrix is slower by a factor of @xmath297 , due to the non - standard dependency issues in the plug - in lasso estimator .",
    "lastly , results ( iv ) and ( v ) suggest that the confidence interval @xmath278 is asymptotically valid and that the coverage errors are of the order of @xmath298 whenever @xmath292 .",
    "classical results on inference for left - censored data , with @xmath60 , only imply that the error rates of the confidence interval is @xmath299 ; instead , we obtain a precise characterization of the size of the residual term .",
    "moreover , with @xmath11 the rates above match the optimal rates of inference for the absolute deviation loss ( see e.g. @xcite ) , indicating that our estimator is asymptotically efficient in the sense that the censoring asymptotically disappears .",
    "however , we impose slightly stronger dimensionality restrictions as for fully observed data @xmath300 is a sufficient condition",
    ". the additional condition @xmath292 can be thought of as a penalty to pay for being adaptive to left - censoring .",
    "this implies that a larger sample size needs to be employed for the results to be valid .",
    "however , this is not unexpected as censoring typically reduces the effective sample size .",
    "statistical models are seldom believed to be complete descriptions of how real data are generated ; rather , the model is an approximation that is useful , if it captures essential features of the data .",
    "good robust methods perform well even if the data deviates from the theoretical distributional assumptions .",
    "the best known example of this behavior is the outlier resistance and transformation invariance of the median .",
    "several authors have proposed one - step and k - step estimators to combine local and global stability , as well as a degree of efficiency under the target linear model @xcite .",
    "there have been considerable challenges in developing good robust methods for more general problems . to the best of our knowledge",
    ", there is no prior work that discusses robust one - step estimators for the case of left - censored models ( for either high or low dimensions ) .",
    "we propose here a family of doubly robust estimators that stabilize estimation in the presence of `` unusual '' design or model error distributions .",
    "observe that rarely follows distribution with light tail .",
    "namely , model can be reparametrized as @xmath301 where , @xmath302 and @xmath303 .",
    "hence @xmath304 will rarely follow light tailed distribution and it is in this regard very important to design estimators that are robust .",
    "we introduce mallow s , schweppe s and hill - ryan s estimators for left - censored models .      in this section",
    "we propose a doubly robust population system of equations @xmath305=0\\ ] ] with @xmath306 and @xmath307 where @xmath308 is an odd , nondecreasing and bounded function . throughout",
    "we assume that the function @xmath308 either has finitely many jumps or is differentiable with bounded first derivative .",
    "notice that when @xmath309 and @xmath310 , with @xmath308 being the sign function , we have @xmath311 of previous section .",
    "moreover , observe that for the weight functions @xmath312 and @xmath313 , both functions of @xmath314 , the true parameter vector @xmath31 satisfies the robust population system of equations above .",
    "appropriate weight functions @xmath315 and @xmath316 are chosen for particular efficiency considerations .",
    "points which have high leverage are considered `` dangerous '' , and should be downweighted by the appropriate choice of the weights @xmath317 . additionally , if the design has `` unusual '' points , the weights @xmath318 serve to downweight their effect in the final estimator .",
    "we augment the system above similarly as before and consider the system of equations @xmath319 + { \\boldsymbol { \\upsilon}}^r [ \\betab -\\betab^ * ] = 0,\\ ] ] for a suitable choice of the robust matrix @xmath320 .",
    "ideally , most efficient estimation can be achieved when the matrix @xmath321 is close to the influence function of the robust equations .    to avoid difficulties with non - smoothness of @xmath308",
    ", we propose to work with a matrix @xmath322 that is smooth enough and is robust simultaneously . to that end , observe @xmath323 for a suitable function @xmath324 and @xmath325 .",
    "we consider a smoothed version of the hessian matrix and work with @xmath326 for @xmath327\\ ] ] where @xmath50 denotes the density of the model error . to infer the parameter @xmath31",
    ", we adapt a one - step approach in solving the empirical counterpart of the population equations above .",
    "we name the empirical equations as _ smoothed robust estimating equations _ or sree in short . for a preliminary estimate",
    "we solve an approximation of the robust system of equations above and search for the @xmath2 that solves @xmath328    the particular form of the matrix @xmath329 depends on the choice of the weight functions @xmath315 and @xmath316 and the function @xmath308 . in particular , for the left - censored model @xmath330   & =   n^{-1 } \\sum_{i=1}^{n } q_i \\nabla_{\\betab^ * } \\ee_\\varepsilon \\left[\\psi \\left ( v_i ( y_i- \\max\\{0,x_i\\betab^*\\})\\right)\\right]\\ \\end{aligned}\\ ] ] leading to the following form @xmath331\\ ] ] whenever the function @xmath308 is differentiable . here",
    ", we denote @xmath332 as @xmath333 . in case of non - smooth @xmath308",
    ", @xmath334 should be interpreted as @xmath335 for @xmath336 $ ] .",
    "for example , if @xmath337 then @xmath338 is equal to @xmath339 and @xmath340 .",
    "here we provide specific definitions of new robust one - step estimates .",
    "we begin by defining a robust estimate of the precision matrix i.e. , @xmath341 .",
    "we design a robust estimator that preserves the `` downweight '' functions @xmath315 and @xmath316 as to stabilize the estimation in the presence of contaminated observations . for further analysis ,",
    "it is useful to define the matrix @xmath342 and @xmath343 @xmath344 with @xmath345^\\top$ ] and @xmath346 with @xmath347 for @xmath348 .",
    "when function @xmath308 does not have first derivative , we replace @xmath349 with @xmath350'$ ] . with this notation",
    ", we have @xmath351 and @xmath352 $ ] takes the form of a weighted covariance matrix .",
    "hence , to estimate the inverse @xmath353 , we project columns one onto the space spanned by the remaining columns . for @xmath354 , we define the vector @xmath355 as follows , @xmath356 also , we assume the vector @xmath357 is sparse with @xmath358 . thus , we propose the following as a robust estimate of the scale @xmath359 with @xmath360 and the normalizing factor @xmath361    estimator is a high - dimensional extension of hampel s ideas of approximating the inverse of the hessian matrix in a robust way , by allowing data specific weights to trim down the effects of the outliers . such weights can be stabilizing estimation in the presence of high proportion of censoring .",
    "@xcite compared the efficiency of the mallow s and schweppe s estimators to several others and found that they dominate in the case of linear models in low - dimensions .",
    "lastly , we arrive at a class of doubly robust one - step estimators , @xmath362    we propose a one - step left - censored mallow s estimator for left - censored high - dimensional regression by setting the weights to be @xmath363 , and @xmath364 for constants @xmath365 and @xmath366 , and with @xmath367 and @xmath368 . extending the work of @xcite ,",
    "it is easy to see that mallow s one - step estimator with @xmath369 and @xmath370 quantile of chi - squared distribution with @xmath371 improves a breakdown point of the initial estimator to nearly @xmath372 , by providing local stability of the precision matrix estimate .",
    "similarly , the one - step left - censored hill - ryan estimator is defined with @xmath373 and the one - step left - censored schweppe s estimator with @xmath374      similar to the concise version of bahadur representation presented in for the standard one - step estimator with @xmath309 and @xmath310 , we also have the expression for doubly robust estimator , @xmath375    next , we show that the leading component has asymptotically normal distribution and that the residual term is of smaller order . for simplicity of presentation we present results below with an initial estimator being penalized clad estimator with the choice of tuning parameter as presented in theorem [ thm : clad_temp ] .",
    "we introduce the following condition .",
    "* condition ( r@xmath204)*:[condition_rpc ] _ parameters @xmath376 for all @xmath205 are bounded , and such that @xmath377 for some @xmath378 .",
    "moreover , @xmath379 are sub - exponential random vectors .",
    "let @xmath318 and @xmath317 be functions such that @xmath380 and @xmath381 for positive constants @xmath382 and @xmath383 and @xmath384=0 $ ] .",
    "moreover , let @xmath308 be such that @xmath385 and @xmath386 .",
    "_    [ normality_r ] assume that @xmath387 , with @xmath388 and @xmath389 .",
    "define @xmath390 .",
    "let conditions * ( x ) * , * ( c ) * , * ( cc ) * , * ( r*@xmath204 * ) * and * ( e ) * hold and let @xmath391 for a constant @xmath216 .",
    "then , @xmath392_{jj}^{-\\frac{1}{2}}u_{j}^{\\mbox{r } } \\xrightarrow[n , p , s_{\\betab^*}\\rightarrow\\infty]{d } \\mathcal{n}\\left(0 , 1\\right).\\end{aligned}\\ ] ]    for the residual term we obtain the following statement .",
    "[ cor : fixed : ci : b ] let conditions * ( x ) * , * ( c ) * , * ( cc ) * , * ( r*@xmath204 * ) * and * ( e ) * hold and let @xmath391 for a constant @xmath216 .",
    "assume that @xmath387 , for @xmath393 with @xmath394 .",
    "let @xmath318 and @xmath317 be functions such that @xmath380 and @xmath381 for positive constants @xmath382 and @xmath383 .",
    "then , @xmath395    the estimation procedure described above is based on the initial estimator @xmath396 taken to be penalized clad .",
    "however , it is possible to show that a large family of sparsity encouraging estimator suffices . in particular",
    ", suppose that the initial estimator @xmath397 is such that @xmath398 and let for simplicity @xmath399",
    ". then results of theorem [ cor : fixed : ci : b ] extend to hold for the confidence interval defined as @xmath400 with @xmath274 as in . in particular , the error rates are of the order of @xmath401    when @xmath402 and @xmath403 , and all @xmath404 , previous result implies that the initial estimator need only to converge at a rate of @xmath405 for a small @xmath253 .    with the results above",
    ", we can now construct a @xmath130 confidence interval for @xmath406 of the form @xmath407 where @xmath408 is defined in , @xmath409 for some @xmath410 @xmath411 and @xmath412    constants @xmath382 and @xmath383 change with a choice of the robust estimator .",
    "for the mallow s and hill - ryan s , by lemma [ lemma2 ] , @xmath413 thus , the coverage probability of mallow s and hill - ryan s estimator is the same as that of the m - estimator .",
    "however , the coverage of the schweppe s estimator is slightly slower , as result of lemma [ lemma0 ] and lemma [ lemma2 ] imply @xmath414 together with theorem [ cor : fixed : ci ] , part ( b ) , we observe now a rate that is slower by a factor of @xmath415 , i.e. , the leading term is of the order of @xmath416 .",
    "the statements of theorem [ cor : fixed : ci : b ] also hold in a uniform sense .",
    "[ cor : uniform : ci : b ] under conditions of theorems [ normality_r ] and [ cor : fixed : ci : b ] , we have for mallow s and hill - ryan s estimator @xmath417 whereas for the schweppe s estimator @xmath418    this result implies that the residual term sizes depend on the type of weight functions chosen . due to",
    "the particular left - censoring , the ideal weights measuring concentration in the error or design depend on the unknown censoring .",
    "hence , we approximate these ideal weights with a plug - in estimators , and therefore obtain rates of convergence that are slightly slower than those of non - robust estimators .",
    "this implies that the robust confidence intervals require larger sample size to achieve the nominal level .",
    "[ cor : fixed : ci : b:1 ] under conditions of theorem [ normality_r ] and [ cor : fixed : ci : b ] , for all vectors @xmath138 and any @xmath275 , when @xmath294 and all @xmath419 we have that ( i ) whenever the interval is constructed using mallow s or hill - ryan s estimator and @xmath420 , the respective confidence intervals have asymptotic coverage @xmath421 ; ( ii ) whenever the interval is constructed using schweppe s estimator and @xmath422 , the respective confidence intervals have asymptotic coverage of @xmath421 .",
    "in this section , we present a number of numerical experiments from both high - dimensional , @xmath11 , and low - dimensional , @xmath60 , simulated settings .",
    "we implemented the proposed estimator in a number of different model settings .",
    "specifically , we vary the following parameters of the model .",
    "the number of observations , @xmath174 , is taken to be @xmath423 , while @xmath173 , the number of parameters , is taken to be @xmath424 or @xmath425 .",
    "the error of the model , @xmath20 , is generated from a number of distributions including : standard normal , student s @xmath170 with @xmath426 degrees of freedom , beta distribution with parameters @xmath427 and weibull distribution with parameters @xmath428 . in the case of the non - zero mean distributions ,",
    "we center the observations before generating the model .",
    "the parameter @xmath415 , the sparsity of @xmath31 , @xmath429 , is taken to be 3 , with all signal parameters taken to be @xmath430 and located as the first three coordinates . the @xmath25 design matrix , @xmath157 , is generated from a multivariate normal distribution @xmath431 .",
    "the mean @xmath432 is chosen to be vector of zero , and the censoring level @xmath18 is chosen to fix censoring proportion at @xmath433 .",
    "the covariance matrix , @xmath434 , of the distribution that @xmath157 follows , is taken to be the identity matrix or the toeplitz matrix such that @xmath435 for @xmath436 . in each case",
    ", we generated 100 samples from one of the settings described above and for each sample we calculated the 95% confidence interval obtained by using the algorithm described in steps 1 - 4 below .",
    "we also note that the optimization problem required to obtain the clad estimator is not convex .",
    "linear programming techniques used to obtain the solution is described in the following , @xmath437    1 .",
    "the penalization factor @xmath6 is chosen by the one - standard deviation rule of the cross validation , @xmath438 we move @xmath6 in the direction of decreasing regularization until it ceases to be true that @xmath439 .",
    "standard error for the cross - validation curve , @xmath440 , is defined as a sample standard error of the @xmath144 fold cross - validation statistics @xmath441 .",
    "they are calibrated using the censored lad loss as @xmath442 with @xmath443 denoting the clad estimator computed on all but the @xmath444-th fold of the data .",
    "2 .   the tuning parameter @xmath221 in each penalized @xmath224 regression ,",
    "is chosen by the one standard deviation rule ( as described above ) . in more details",
    ", @xmath221 is in the direction of decreasing regularization until it ceases to be true that @xmath445 for @xmath446 as the cross - validation parameter value .",
    "the cross - validation statistic is here defined as @xmath447 with @xmath448 denoting estimators computed on all but the @xmath444-th fold of the data .",
    "this choice leads to the conservative confidence intervals with wider than the optimal length .",
    "theoretically guided optimal choice is highly complicated and depends on both design distribution and censoring level concurrently .",
    "nevertheless , we show that one - standard deviation choice is very reasonable .",
    "3 .   whenever the density of the error term is unknown , we estimate @xmath100 , using the proposed estimator , with a constant @xmath449 . we compute the above estimator by splitting the sample into two parts :",
    "the first sample is used for computing @xmath61 and @xmath123 and the other sample is to compute the estimate @xmath137 .",
    "optimal value of @xmath450 is of special independent interest ; however , it is not the main objective of this work .",
    "4 .   obtain @xmath451 by plugging @xmath452 and @xmath137 into with @xmath6 and @xmath221 as specified in the steps above .",
    "the summary of the results is presented across dimensionality of the parameter vector .",
    "the _ low - dimensional regime _ are summarized in table [ tab : lowdim ] and figures [ fig:1 ] and [ fig:2 ] , whereas the _ high - dimensional regime _ are summarized in table [ tab : highdim ] and figures [ fig:3 ] and [ fig:4 ] .",
    "we report average coverage probability across the signal and noise variables independently , as the signal variables are more difficult to cover when compared to the noise variables .",
    "we consider a number of challenging settings .",
    "specifically , the censoring proportion is kept relatively high at @xmath433 , and our parameter space is large with @xmath453 and @xmath454 . in addition , we consider the case of error distribution being student with @xmath426 degrees of freedom , which is notoriously difficult to deal with in left - censored problems . in figures",
    "[ fig:3 ] and [ fig:4 ] , we illustrate boxplots of the width of the @xmath455 level confidence intervals across the simulated repetitions .",
    "we showcase the signal and the noise variables separately .",
    "table [ tab : lowdim ] and [ tab : highdim ] summarize average coverage probabilities of the constructed @xmath455 level confidence intervals for both low - dimensional and high - dimensional regime respectively .",
    "for the four error distributions , the observed coverage probabilities are approximately the same .",
    "however , we observe that our method is not insensitive to the heavy - tailed distributions ( student s @xmath456 ) , due to the large bias of the initial estimator .",
    "this bias results in larger interval widths especially in the signal variables . nevertheless , the coverage probability is not affected .",
    "the biggest advantage of our method is most clearly seen when the errors are asymmetric ( beta and weibull ) . in this case , our method has smaller interval width and smaller variance .",
    "symmetric distributions are very difficult to handle in left - censored models . however , when errors were symmetric ( normal ) , the coverage probabilities were extremely close to the nominal ones .",
    "the above cases evidently show that our method is robust to asymmetric distributions and does not lose efficiency when the errors are symmetric .     and toeplitz design with @xmath436 . , title=\"fig:\",width=264,height=188 ]   and toeplitz design with @xmath436 .",
    ", title=\"fig:\",width=264,height=188 ]     and identity design with @xmath436 .",
    ", title=\"fig:\",width=264,height=188 ]   and identity design with @xmath436 . ,",
    "title=\"fig:\",width=264,height=188 ]     and toeplitz design with @xmath436 . ,",
    "title=\"fig:\",width=264,height=188 ]   and toeplitz design with @xmath436 . ,",
    "title=\"fig:\",width=264,height=188 ]     and identity design .",
    ", title=\"fig:\",width=264,height=188 ]   and identity design . ,",
    "title=\"fig:\",width=264,height=188 ]    @nd1.1 * 3d1.2d1.1d3.2@ & & + ( lr)2 - 5 & & + ( lr)2 - 3(lr)4 - 5 & & & & + ( r)1 - 1(lr)2 - 2(lr)3 - 3 ( lr)4 - 4(lr)5 - 5 normal & 0.97 & 0.98 & 0.95 & 0.94 + student & 0.97 & 1 & 0.97 & 0.98 + beta & 0.94 & 1 & 0.98 & 0.97 + weibull & 0.98 & 0.98 & 0.94 & 0.98 +    @nd1.1 * 3d1.2d1.1d3.2@ & & + ( lr)2 - 5 & & + ( lr)2 - 3(lr)4 - 5 & & & & + ( r)1 - 1(lr)2 - 2(lr)3 - 3 ( lr)4 - 4(lr)5 - 5 normal & 0.92 & 0.96 & 0.97 & 0.95 + student & 0.96 & 0.98 & 0.96 & 0.98 + beta & 1 & 1 & 0.96 & 0.97 + weibull & 0.95 & 1 & 0.87 & 0.97 +      the objective of this study is to illustrate the performance of the proposed two - step estimator in characterizing the transcriptional signature of an early acute hiv infection .",
    "researchers have recently shown great interest in modeling viral load ( plasma hiv-1 rna copies ) data after initiation of a potent antiretroviral ( arv ) treatment .",
    "viral load is a measure of the amount of actively replicating virus and is used as a marker of disease progression among hiv - infected patients .",
    "however , the extent of viral expression and the underlying mechanisms of the persistence of hiv-1 in this viral reservoir have not been fully recovered .",
    "moreover , viral load measurements are often subject to left censoring due to a lower limit of quantification .",
    "we aim to find a pattern describing the interaction between the hiv virus and the gene expression values and can be useful for understanding the pathogenesis of hiv infection and for developing effective vaccines @xcite .",
    "we evaluated 48803 of illumina breadarray based gene expressions identified through a whole blood transcriptional , genome - wide analysis for association with acute hiv infection .",
    "each array on the humanht-12 v4 expression beadchip targets more than 31,000 annotated genes with more than 47,000 probes derived from the national center for biotechnology information reference sequence .",
    "this data set is part of the `` microarray quality control ii '' project , which is available from the gene expression omnibus database with accession number gse29429 .",
    "@cd13.1 * 2cd1.2 * 2ld1.1rd1.2@ & & + & & & & + ( lr)2 - 3 ( lr)5 - 6 & & & & & + ( lr)2 - 2(lr)3 - 3 ( lr)5 - 5(lr)6 - 6 & & ( -7.449 , -7.365 ) & & & ( -5.718 , -3.020 ) & + & & ( -0.432 , -0.345 ) & & & ( -0.365 , -0.164 ) & + & & ( -7.556 , -4.262 ) & & & ( -1.252 , -0.388 ) & + & & ( -2.234 , -2.146 ) & & & ( -1.532 , -0.599 ) & + & & ( -1.725 , -1.235 ) & & & ( -2.217 , -1.973 ) & + & & ( -0.898 , -0.732 ) & & & ( -7.563 , -0.200 ) & + & & ( -0.765 , -0.133 ) & & & ( -5.267 , -1.025 ) & + & & ( -0.651 , -0.424 ) & & & ( -1.023 , -0.787 ) & + & & ( -2.654 , -0.116 ) & & & ( -0.456 , -0.098 ) & + & & ( -4.901 , -2.457 ) & & & ( -0.955 , -0.191 ) & + & & ( -0.305 , -0.200 ) & & & ( -0.696 , -0.537 ) & + & & ( -0.238 , -0.048 ) & & & ( -0.263 , -0.204 ) & + & & ( -0.766 , -0.025 ) & & & ( -0.346 , -0.162 ) & + & & ( -0.578 , -0.477 ) & & & ( -0.566 , -0.011 ) & + & & ( -1.341 , -0.160 ) & & & ( -0.407 , -0.072 ) & + & & ( -0.285 , -0.194 ) & & & ( -0.385 , -0.209 ) & + & & ( -1.111 , -0.353 ) & & & ( 0.351 , -0.816 ) & +    58 acute hiv patients were recruited from locations in africa ( n=43 ) and the united states ( n=15 ) .",
    "we analyze the original data set containing subjects both from africa and the united states , with 186 males and females , whose viral loads are measured over a period of 24 weeks .",
    "patient samples were collected at study enrollment ( confirmed acute ) for all patients and at weeks 1 , 2 , 4 , 12 and 24 .",
    "subjects are from 18 to 66 years old .",
    "the current data set also contains genetic information of each participant over breadarray expression values of around 6000 genes on different chromosomes .",
    "weekly populations are analyzed separately .",
    "the sample size @xmath174 of each weekly data is around @xmath457 .",
    "we successfully applied our methodology to this data , despite the computational burden occurring with the extremely large amount of parameters .",
    "table [ tab:4a ] summarizes the confidence intervals concerning the treatment group .",
    "we found confidence intervals for all @xmath458 genes with only @xmath457 samples in weekly data .",
    "therefore , our method enables the discovery of a genetic biological pathways associated with the arv treatment of hiv positive patients . censoring level was 2% in week 1 , 5% in week 2 , 10% in week 4 , 70% in week 8 , 40% in week 12 and 50% in week 24 . for illustration purposes , we present the results only for the genes whose intervals did not contain zero , indicating their strong association with the viral loads measurements .",
    "we observe that a number of the genes with large significance have been associated with hiv in previous studies ; some , only very recently .",
    "mkl1 ( megakaryoblastic leukemia ( translocation ) 1 ) gene is known to play an important role in the expansion and/or persistence of hiv infected cells in patients @xcite .",
    "similarly , from table [ tab:4a ] , week 1 , we observe that mkl1 has a confidence interval far way from zero .",
    "our findings of week 1 also confirm that gene pkd1l1 has a significant confidence interval .",
    "the association of polycystic kidney disease 1 like 1 ( pkd1l1 ) with kidney disease makes the gene expression a possible indicator of hiv associated nephropathy .",
    "in fact , kidney disease is often a sign of accelerated hiv disease progression @xcite .",
    "in addition , as a member of atp - binding cassette ( abc ) drug transporters family , the gene abcd4 we identified in week 4 data has a potential important role in infectious diseases such as hiv-1 @xcite .",
    "moreover , the gene expression gpbp1l1 is a kind of gc - rich promoter binding protein , which is a region important for hiv-1 transcription and thereby its propagation @xcite .",
    "the above showcase the parallel discovery of our method to the newly established results in medicine , and provides evidence that our methods can be used to discover scientific findings in applications involving high - dimensional datasets .    in appendix",
    "a , we present proofs of the theorems 1 - 9 .",
    "the rest of the supplementary material contains proofs of the lemmas 1 - 6 .",
    "referenced citations are matching those of the main document .",
    "the proof of the theorem follows from the bounding residual terms in the bahadur representation with the help of lemma [ cor:2 ] - [ lemma4 ] .",
    "recall in lemma [ lemma4 ] , we showed that @xmath459 for the term @xmath460 , we have that @xmath461 by applying hlder s inequality and hoeffding s inequality along with lemma [ lemma2 ] .    for the term @xmath462 , we have @xmath463 by hlder s inequality and lemma [ lemma2 ] , where @xmath464 denotes the max row sum of matrix @xmath465 and @xmath466 denotes the maximum element in the matrix @xmath465 .",
    "lastly , for the only remainder term in , @xmath467 , we use hlder s inequality and lemma [ lemma2 ] , @xmath468    we begin the proof by noticing that @xmath469 recollect that by condition * ( e ) * , @xmath470 . additionally , we observe that in distribution , the term on the right hand side is equal to @xmath471 , with @xmath472 denoting an i.i.d .",
    "rademarcher sequence defined as @xmath473 .",
    "hence , it suffices to analyze the distributional properties of @xmath474 moreover , rademacher random variables are independent in distribution from @xmath475 .",
    "thus , we provide asymptotics of @xmath476 we begin by defining @xmath477 and we also define @xmath478 notice that @xmath479 s are independent from each other , since we assumed that each observation is independent in our design .",
    "we have @xmath480 moreover , @xmath481 since @xmath482 are independent from @xmath157 , @xmath483 in addition , also due to this fact , @xmath479 follows a symmetric distribution about @xmath169 .",
    "thus , @xmath484 where with a little abuse in notation we denote the density and distribution of @xmath485 to be @xmath486 and @xmath487 .",
    "observe that @xmath488 thus , @xmath489 now combining and , we have @xmath490 thereby , we arrive at the result @xmath491 with the fact that @xmath492 also , the covariance @xmath493 = \\ee \\left[\\frac{1}{n}\\sum_{i=1}^nw_{ij_1}(\\betab^*)w_{ij_2}(\\betab^*)\\right ] = \\sigmab(\\betab^*)_{j_1j_2}.\\ ] ]    therefore , we have the following conclusion , @xmath494_j\\xrightarrow{d } \\mathcal{n}\\left(0 , \\frac{1}{4f(0)^2}\\left[\\sigmab^{-1}(\\betab^*)\\sigmab(\\betab^*)\\left(\\sigmab^{-1}(\\betab^*)\\right)^\\top \\right]_{jj}\\right),\\ ] ] where @xmath149 .",
    "this gives @xmath495^{-\\frac{1}{2 } } \\left[\\frac{1}{2f(0)}\\sigmab^{-1}(\\betab^*)\\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\psi_i(\\betab^*)\\right]_j\\xrightarrow{d } \\mathcal{n}\\left(0 , \\frac{1}{4f(0)^2}\\right)\\end{aligned}\\ ] ]    notice that for two nonnegative real numbers @xmath496 and @xmath497 , it holds that @xmath498 we first make note of a result in the proof of theorem [ cor : ci ] , that @xmath499 let @xmath500_{jj}$ ] and @xmath501 . by condition * ( cc ) * , we have @xmath502 is bounded away from zero .",
    "then , @xmath503 is also bounded away from zero by , and so is @xmath504 , since we have @xmath505_{jj }   - \\left [ \\hat \\omegab(\\hat\\betab ) \\sigmab ( \\hat \\betab ) \\hat \\omegab(\\hat\\betab ) \\right]_{jj } \\leq \\left\\|",
    "\\hat \\omegab(\\hat\\betab ) \\sigmab ( \\hat \\betab ) \\hat \\omegab(\\hat\\betab ) - \\sigmab^{-1 } ( \\betab^*)\\right\\|_{\\max } = { \\mbox{\\scriptsize$\\ocal$}}_p \\left ( 1 \\right).\\end{aligned}\\ ] ] the rate above follows from in the proof of theorem [ cor : ci ] .",
    "notice the rate is of order smaller than the rate assumption in theorem [ cor : fixed : ci ] .",
    "thus , we can deduce that @xmath265_{jj}^{-\\frac{1}{2 } } - \\left [ \\sigmab^{-1}(\\betab^*)_{jj } \\right]^{-\\frac{1}{2 } } \\leq   c \\left\\|",
    "\\hat \\omegab(\\hat\\betab ) \\sigmab ( \\hat \\betab ) \\hat \\omegab(\\hat\\betab ) - \\sigmab^{-1 } ( \\betab^*)\\right\\|_{\\max}.\\end{aligned}\\ ] ] for some finite constant @xmath172 .",
    "applying slutsky theorem on with the inequality above , the desired result is obtained .",
    "we can rewrite the expression @xmath137 in as @xmath506 since @xmath507 \\right| = { \\mbox{\\scriptsize$\\ocal$}}_p(1)$ ] , we have @xmath508 using a similar argument and the fact that @xmath509 , we have @xmath510    now we work on the numerator of right hand side . specifically , let @xmath511 and @xmath512 , we look at the difference of the quantities below , @xmath513    we begin with term @xmath514 . by condition * ( e ) * , we have @xmath515 . by corollary [ lemma0 ]",
    ", we have @xmath516 which then brings us that @xmath514 is of order @xmath517 . for term @xmath518",
    ", we work out the expression @xmath519 next , we notice that for real numbers @xmath496 and @xmath497 , we have @xmath520 thus , we have @xmath521 to bound @xmath522 , we use similar techniques as with @xmath514 . notice that @xmath523 it is easy to see that @xmath524 shares the nice property of the density of @xmath94 .",
    "thus , @xmath525 is bounded by @xmath517 .",
    "then by hoeffding s inequality , we have that with probability approaching @xmath430 that @xmath522 is of @xmath517 .",
    "@xmath526 can be bounded in exactly the same steps .    finally , we are ready to put everything together that @xmath527 by applying slutsky theorem , the result follows directly , @xmath528    by multiplying and dividing the term @xmath100 , we can rewrite the term on the left hand side as @xmath265_{jj}^\\frac{1}{2}u_j \\cdot 2 \\widehat f(0 ) & = \\left[\\omegab(\\hat{\\betab } ) \\hat\\sigmab(\\hat{\\betab})\\omegab ( \\hat{\\betab})\\right]_{jj}^\\frac{1}{2}u_j \\cdot 2 f(0 ) \\frac{\\widehat f(0)}{f(0)}.\\end{aligned}\\ ] ] also , as a result of theorem [ thm : f ] , we have @xmath529 with condition * ( e ) * guarantees that @xmath100 is bounded away from @xmath169 .",
    "it also indicates that @xmath530 .",
    "finally , we apply slutsky s theorem and theorem [ normality ] , we have @xmath265_{jj}^\\frac{1}{2}u_j \\cdot 2 \\widehat f(0 ) \\xrightarrow[n , p , s_{\\betab^*}\\rightarrow\\infty]{d } \\mathcal{n}\\left(0,1\\right).\\end{aligned}\\ ] ]    the result of theorem [ cor : ci ] is a simple consequence of wald s device and results of corollary [ cor1 ] .",
    "the only missing link is an upper bound on @xmath531 first , observe that @xmath532 regarding term @xmath514 , observe that by lemma [ lemma2 ] it is equal to @xmath517 whenever @xmath533 is @xmath534 .",
    "this can be seen from the decomposition of @xmath535 , which reads , @xmath536    we notice that @xmath537 for , we have the following bound @xmath538 where @xmath464 denotes the max row sum of matrix @xmath465 and @xmath466 denotes the maximum element in the matrix @xmath465 . by lemma [ lemma0 ] ,",
    "we can easily bound the term above with @xmath539 . for , we start with the following term , @xmath540 applying hoeffding s inequality on this term , we have that with probability approaches @xmath430 , the term is bounded by @xmath541",
    ". then we bound term as following , @xmath542    term @xmath526 can be bounded using lemma [ lemma2 ] and the results from term @xmath522 , and turns out to be of order @xmath543",
    "lastly , by lemma [ lemma2 ] , term @xmath544 is of order @xmath545    putting the terms together , we have @xmath546 bounded by @xmath547 thus , @xmath533 is @xmath534 , and so can @xmath518 be shown similarly . the expression is then bounded as , @xmath548 which then completes the proof .",
    "the result of theorem [ cor : uniform : ci ] holds by observing that bahadur representations remain accurate uniformly in the sparse vectors @xmath549 ; hence , all the steps of theorem [ cor : fixed : ci ] apply in this case as well .    the proof for the result with initial estimator chosen as the penalized clad estimator of @xcite follows directly from lemma [ lemma0]-[lemma4 ] and theorem [ cor : fixed : ci]-[cor : ci ] with @xmath550 , @xmath551 and @xmath552 .",
    "due to the limit of space , we follow the line of the proof of theorem [ normality ] but only give necessary details when the proof is different .",
    "first , we observe that with a little abuse in notation @xmath553 thus it suffices to provide the asymptotic of @xmath554 moreover , observe that @xmath555 are necessarily bounded random variables ( see condition ( r@xmath556 ) .",
    "following similar steps as in theorem [ normality ] we obtain @xmath557 where in the last step we utilized hoeffding s inequality for bounded random variables .",
    "next , we focus on establishing an equivalent of lemma 2 but now for the doubly robust estimator . observe that @xmath558=n^{-1 } \\sum_{i=1}^n x_i^\\top \\ind\\ { x_i \\betab > 0\\ } q_i     \\ee_{\\varepsilon } \\biggl [ \\psi \\bigl(- v_i x_i ( \\betab^ * - \\betab ) - v_i \\varepsilon_i   \\bigl ) \\biggl].\\ ] ] moreover , whenever @xmath334 exists we have @xmath559     =   - v_i x_i ( \\betab^*-\\betab )    \\int_{-\\infty}^{\\infty } \\psi'(\\xi(u ) )",
    "f(u ) du.\\ ] ] for @xmath560 for some @xmath419 .",
    "when @xmath561 does nt exist we can decompose @xmath308 into a finite sum of step functions and then apply exactly the same technique on each of the step functions as in lemma 2 .",
    "hence , it suffices to discuss the differentiable case only .",
    "let us denote the rhs of with @xmath562 , i.e. @xmath563 next , we observe that by condition ( r@xmath556 ) , @xmath564 for a constant @xmath565 . with that the remaining steps of lemma 2 can be completed with @xmath434 replaced with @xmath566 .",
    "next , by observing the proofs of lemmas 3 , 4 and 5 we see that the proofs remain to hold under condition ( r@xmath556 ) , and with @xmath195 replaced with @xmath567 .",
    "the constants @xmath568 appearing in the simpler case will now be @xmath569 .",
    "however , the rates remain the same up to these constant changes .",
    "next , we discuss lemma 6 . for the case of doubly robust estimator @xmath570 of lemma 6",
    "takes the following form @xmath571\\ ] ] with @xmath572 .",
    "moreover , @xmath573 = f_i(\\deltab ) \\ee_{\\varepsilon } [ \\psi(v_i ( x_i \\deltab +   \\varepsilon_i ) ) ] : = \\tilde w_i(\\deltab)$ ] .",
    "we consider the same covering sequence as in lemma 6 .",
    "then , we observe @xmath574 furthermore , @xmath575 ^ 2 $ ] @xmath576 @xmath577 , providing the bound of @xmath514 equivalent to that of lemma 6 .",
    "term @xmath518 can be handled similarly as in lemma 6 .",
    "we illustrate the particular differences only in @xmath522 as others follows similarly .",
    "observe that @xmath578 for @xmath579 for some @xmath419 .",
    "next , we consider the decomposition @xmath580 = t_{211}^r(\\deltab ) + t_{212}^r(\\deltab)\\ ] ] for @xmath581 and @xmath582 @xmath583 and @xmath584\\ ] ] furthermore , we observe that the same techniques developed in lemma 6 apply to both of the terms of @xmath585 hence we only discuss the case of @xmath586 .",
    "we begin by considering the decomposition @xmath587 with @xmath588 and @xmath589\\ ] ] let us focus on the last expression as it is the most difficult one to analyze .",
    "observe that we are interested in the difference @xmath590 .",
    "we decompose this difference into four terms , two related to random variables and two related to the expectations .",
    "we handle them separately and observe that because of symmetry and monotonicity of the indicator functions once we can bound the difference of random variables we can repeat the arguments for the expectations .",
    "hence , we focus on @xmath591 first due to monotonicity of indicators and we have @xmath592 with @xmath593 as @xmath594 , @xmath595 can be handled in the same manner as @xmath522 of the proof of lemma 6 whereas @xmath596 .",
    "for @xmath597 it suffices to discuss the difference at the end of the right hand side of its expression .",
    "however , it is not difficult to see that @xmath598 with @xmath599 for the case of twice differentiable @xmath308 , @xmath600 for the case of once differentiable @xmath308 and @xmath601 for the case of non - differentiable functions @xmath308 . combining all the things together",
    "we observe that the rate of lemma 6 for the case of doubly robust estimators is of the order of @xmath602 with @xmath603 for once differentiable @xmath308 and @xmath604 for non - differentiable @xmath308 .    now , with equivalents of lemmas 1 - 6",
    "are established , we can use them to bound successive terms in the bahadur representation much like those of theorem 1 .",
    "details are ommitted due to space considerations .    for theorem [ cor : uniform",
    ": ci : b ] , the same line of the proof of theorem [ cor : uniform : ci ] applies , but only replace the matrix @xmath434 with the matrix @xmath605 .",
    "the result of the theorem then follows from the arguments in remark [ remark4 ] .",
    "uniformity of the obtained results is not compromised as the weight functions @xmath318 and @xmath317 only depend on the design matrix .",
    "let @xmath606}$ ] be the centers of the balls of radius @xmath607 that cover the set @xmath608 .",
    "such a cover can be constructed with @xmath609 ( see , for example * ? ? ?",
    "furthermore , let @xmath610 \\right]$ ] and let @xmath611 be a ball of radius @xmath612 centered at @xmath613 with elements that have the same support as @xmath613 . in what follows , we will bound @xmath614 using an @xmath615-net argument . in particular , using the above introduced notation , we have the following decomposition @xmath616 }   |\\mathbb{d}_n ( \\tilde \\deltab_k)|    } _ { t_1 }   +   \\underbrace {    \\max_{k \\in [ n_\\delta ] }    \\sup_{\\deltab \\in \\mathcal{b } ( \\tilde \\deltab_k , r_n\\xi_n ) }    | \\mathbb{d}_n ( \\deltab ) -   \\mathbb{d}_n ( \\tilde \\deltab_k)| } _ { t_2}. \\end{aligned}\\ ] ]      with a little abuse of notation we use @xmath618 to denote the density of @xmath619 for all @xmath22 .",
    "observe , @xmath620 = \\pp\\biggl ( x_i \\betab^ * \\leq x_i \\deltab        \\biggl).\\ ] ] let @xmath621 denote the probability on the right hand side of the previous equation , as a function of @xmath243",
    ". then @xmath622 }      \\abr {        n^{-1}\\sum_{i\\in[n ] }   z_{ik }   }    .",
    "$ ] note that @xmath623 = 0 $ ] and @xmath624       =         w_{i } ( \\tilde\\deltab_k )      - w_{i}^2 ( \\tilde\\deltab_k )       \\stackrel{(i)}{\\leq }       w_{i } ( \\tilde\\deltab_k )        \\stackrel{(ii)}{\\leq }        \\abr {    x_i\\tilde\\deltab_k      }    l_i\\rbr {    c_ix_i \\tilde\\deltab_k     }    \\stackrel{(iii)}{\\leq }    \\abr {     x_i \\tilde\\deltab_k      }    k_1\\quad \\rbr{c_i   \\in [ 0,1]}\\end{aligned}\\ ] ] where @xmath625 follows by dropping a negative term , @xmath626 follows by the mean value theorem and @xmath627 from the condition ( e ) .",
    "hence , we have that almost surely , @xmath628 for a constant @xmath629 . for a fixed @xmath444 , bernstein s inequality ( see , for example , section 2.2.2 of * ? ? ?",
    "* ) gives us @xmath630 } z_{ik } }    \\leq c\\rbr {    \\sqrt {      \\frac{f_{\\max}\\log(2/\\delta)}{n^2 }      \\sum_{i\\in[n ] }        \\abr {    x_i\\tilde\\deltab_k     }    }    \\bigvee \\frac { \\log(2/\\delta ) } { n }    } \\end{aligned}\\ ] ] with probability @xmath176 .",
    "observe that @xmath631 x \\tilde\\deltab_k   \\leq \\tilde\\deltab_k^\\top w(\\betab^*)^\\top w(\\betab^*)\\tilde\\deltab_k + 2 \\tilde\\deltab_k^\\top x^\\top x \\tilde\\deltab_k   $ ] .",
    "hence , @xmath632 }       \\abr {    x_i\\tilde\\deltab_k      }      & \\leq c   ^2 \\sqrt{n}\\sqrt{\\tilde\\deltab_k^\\top   w^\\top ( \\betab^*+\\tilde\\deltab_k ) w ( \\betab^*+\\tilde\\deltab_k )   \\tilde\\deltab_k } \\leq 2 c ^2 r_n \\sqrt{n}\\left(\\lambda_{\\max}^{1/2}(\\sigmab ( \\betab^ * ) ) \\vee1\\right),\\end{aligned}\\ ] ] where the line follows using the cauchy - schwartz inequality and inequality ( 58a ) of @xcite and lemma [ lemma2 ] . hence , with probability @xmath633 we have for all @xmath634",
    "that @xmath630}z_{ik } }    \\leq c\\rbr {    \\sqrt {      \\frac { r_n\\log(2/\\delta)}{n }    }    \\bigvee \\frac { \\log(2/\\delta)}{n } } .\\end{aligned}\\ ] ]    using the union bound over @xmath635 $ ] , with probability @xmath633 , we have @xmath636 let us now focus on bounding @xmath518 term .",
    "let @xmath637 for a fixed @xmath444 we have @xmath638 }      { q}_{i}(\\deltab )      - { q}_{i}(\\tilde\\deltab_k ) } : = t_{21}.\\end{aligned}\\ ] ]    let @xmath639 .",
    "observe that the density of @xmath640 is by condition ( * e * ) very close to the distribution of @xmath641 .",
    "moreover , @xmath642 where @xmath144 is a constant such that @xmath643 .",
    "hence , @xmath644}\\max_{i\\in[n ] }    \\sup_{\\deltab \\in \\mathcal{b}(\\tilde \\deltab_k , r_n\\xi_n ) }    \\abr {       x_i   \\deltab      -        x_i   \\tilde\\deltab_k    } \\leq       r_n\\xi_n\\sqrt{t } \\max_{i , j}|x_{ij}|    \\leq c      r_n\\xi_n      \\sqrt { t   }   = : \\tilde l_n,\\end{aligned}\\ ] ] for @xmath522 , we will use the fact that @xmath645 and @xmath646 are monotone functions in @xmath647 .",
    "therefore , @xmath648}\\bigg [       \\ind\\cbr{z_i \\geq    x_i   \\tilde\\deltab_k - \\tilde l_n }   -    \\pp\\sbr{z_i \\geq   x_i   \\tilde\\deltab_k + \\tilde l_n }   \\bigg ] \\\\ & \\leq n^{-1}\\sum_{i\\in[n]}\\bigg [       \\ind\\cbr{z_i \\geq    x_i   \\tilde\\deltab_k - \\tilde l_n } -    \\pp\\sbr{z_i \\geq   x_i   \\tilde\\deltab_k - \\tilde l_n   }    \\bigg ] \\\\ &",
    "\\ + n^{-1}\\sum_{i\\in[n]}\\bigg [       \\pp\\sbr{z_i \\geq   x_i   \\tilde\\deltab_k - \\tilde l_n } -    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k+ \\tilde l_n } \\bigg].\\end{aligned}\\ ] ] the first term in the display above can be bounded in a similar way to @xmath514 by applying bernstein s inequality and hence the details are omitted .",
    "for the second term , we have a bound @xmath649 , since @xmath650 , per condition ( * e * ) .",
    "therefore , with probability @xmath633 , @xmath651 a bound on @xmath518 now follows using a union bound over @xmath635 $ ] .",
    "we can choose @xmath652 , which gives us @xmath653 .",
    "with these choices , we obtain @xmath654 which completes the proof .",
    "we begin by rewriting the term @xmath655 , and aim to represent it through indicator functions .",
    "observe that @xmath656.\\end{aligned}\\ ] ] using the fundamental theorem of calculus , we notice that if @xmath657 , @xmath658 , where @xmath158 is the univariate distribution of @xmath94 .",
    "therefore , with expectation on @xmath20 , we can obtain an expression without the @xmath659 .",
    "@xmath660\\\\ & = \\left[n^{-1}\\sum_{i=1}^n x_i^\\top \\ind(x_i\\betab>0)\\cdot2f(u^*)x_i(\\betab^*-\\betab ) \\right ] : = \\lambda_n(\\betab)(\\betab^*-\\betab),\\end{aligned}\\ ] ] for some @xmath661 between 0 and @xmath662 , and where we have defined @xmath663.\\ ] ]    we then show a bound for @xmath664_{jk}\\right|$ ] , where we recall @xmath196 is defined as earlier , @xmath665 . by triangular inequality ,",
    "@xmath666 notice that @xmath667 $ ] .",
    "moreover , the original expresion is also smaller than or equal to @xmath668 .",
    "the term can be bounded by condition * ( x ) * and * ( e ) * , @xmath669 with the help of hlder s inequality , @xmath670 by triangular inequality and condition * ( e ) * we can further upper bound the right hand side with @xmath671 then we are ready to put terms together and obtain a bound for @xmath110",
    ". additionally , by condition * ( x ) * we have @xmath672 for @xmath197 and a constant @xmath172 .",
    "essentially , this proves that @xmath110 is not greater than a constant multiple of the difference between @xmath2 and @xmath31 .",
    "thus , we have as @xmath673 @xmath674    for the simplicity in notation we fix @xmath675 and denote @xmath676 with @xmath677 . the proof is composed of two steps : the first establishes a cone set and an event set of interest whereas the second proves the rate of the estimation error by certain approximation results .",
    "* step 1*. here we show that the estimation error @xmath678 belongs to the appropriate cone set with high probability .",
    "we introduce the loss function @xmath679 . the loss function above is convex in @xmath680 hence @xmath681 \\geq 0.\\ ] ] let @xmath682 .",
    "let @xmath683 .",
    "kkt conditions provide @xmath684 for all @xmath685 with @xmath686 . moreover , observe that @xmath687 for all @xmath688",
    "then , @xmath689   \\\\ & = \\sum_{j \\in s_1^c } \\deltab_j ( \\nabla_{\\gammab } l(\\hat \\betab ,   \\gammab)|_{\\gammab=\\gammab^ * + \\deltab } ) _ j   + \\sum_{j \\in s_1 } \\deltab_j ( \\nabla_{\\gammab } l(\\hat \\betab , \\gammab)|_{\\gammab=\\gammab^ * + \\deltab } ) _ j   + \\deltab^\\top ( -   \\nabla_{\\gammab } l(\\hat",
    "\\betab,\\gammab ) |_{\\gammab= \\gammab^ * } ) \\\\",
    "& \\leq   \\sum_{j \\in s_1^c } \\deltab_j ( - \\lambda_1 \\mbox{sgn}(\\gammab^*_j + \\deltab_j ) ) + \\lambda_1 \\sum_{j \\in s_1 } |\\deltab_j| + h^ * \\|\\deltab \\|_1 \\\\ & = \\sum_{j \\in s_1^c }   - \\lambda_1 |\\deltab_j|   +   \\sum_{j \\in s_1 }    \\lambda_1 |\\deltab_j|   +   h^ * \\|\\deltab_{s_1 } \\|_1   +   h^ * \\|\\deltab_{s_1^c } \\|_1   \\\\   & =   ( h^ * - \\lambda_1 )   \\|\\deltab_{s_1^c } \\|_1 + ( \\lambda_1 + h^ * ) \\|\\deltab_{s_1 } \\|_1.\\end{aligned}\\ ] ]          next , by lemma [ lemma0 ] we observe @xmath699 and similarly @xmath700 .",
    "recall that @xmath701 .",
    "let @xmath702 be defined as @xmath703 .",
    "then , by hlder s inequality @xmath704 \\right | \\\\ & \\qquad = \\ocal_p \\left ( k^3 k_\\gamma r_n^{1/2 } t^{3/4 } s_1 ( \\log p / n)^{1/2 } \\bigvee k^3 k_\\gamma t s_1 \\log p / n \\right)\\end{aligned}\\ ] ] and similarly @xmath705 . putting all the terms together we obtain @xmath706 .    next , we focus on the term @xmath707 .",
    "simple computation shows that for all @xmath708 , we have @xmath709 for @xmath710 .",
    "observe that the sequence @xmath711 across @xmath712 , is a sequence of independent random variables .",
    "as @xmath94 and @xmath23 are independent we have by the tower property @xmath713= \\ee_x \\left[x_{ik } \\ind\\ { x_i \\betab^ * > 0\\ }    \\ee_\\varepsilon [ \\zetab_{1,i}^ * ] \\right ] = 0 $ ] . moreover , as @xmath714 is sub - exponential random vector , by bernstein s inequality and union bound we have @xmath715 where @xmath716 .",
    "we pick @xmath18 to be @xmath717 , then we have with probability converging to @xmath430 that @xmath718 for some constant @xmath719 and @xmath182 . thus , with @xmath693 chosen as @xmath720 for some constant @xmath721 , we have that @xmath722 with probability converging to @xmath430 . more directly , with the condition on the penalty parameter @xmath693 , this implies that the event for the cone set to be true holds with high probability .    .",
    "we begin by a basic inequality @xmath723 guaranteed as @xmath724 minimizes the penalized loss . here and below in the rest of the proof",
    "we suppress the subscript @xmath430 and @xmath2 in the notation of @xmath725 and @xmath726 and use @xmath727 and @xmath728 instead and similarly @xmath729 and @xmath730 . rewriting the inequality above we obtain @xmath731    observe that @xmath732 $ ] .",
    "let @xmath733 $ ] .",
    "let @xmath734 be a matrix such that @xmath735 . from now on",
    "we only consider @xmath734 to mean @xmath736 and @xmath737 to mean @xmath738 .",
    "next , note that @xmath739 by the node - wise plug - in lasso problem .",
    "together with the above , we observe that then @xmath740 . hence",
    ", the basic inequality above becomes , @xmath741 with reordering the terms in the inequality above , we obtain @xmath742 \\mbox{for } \\qquad & \\delta_1=2 n^{-1 } \\varepsilon_1^{*\\top } \\left({w^{-}}^ * + \\ab^- \\right ) \\left ( \\hat \\gammab - \\gammab^*\\right ) , & \\\\ & \\delta_2 =   2 n^{-1 } \\gammab^{*\\top }   { w^{-}}^{*\\top } \\ab^- \\left ( \\hat \\gammab - \\gammab^*\\right),&\\\\ & \\delta_3 = n^{-1 }   \\left ( \\gammab^ * + \\hat \\gammab \\right)^\\top \\left ( \\ab^{-\\top } \\ab^- + 2w^{-*\\top } a^-\\right )   \\left ( \\gammab^ * - \\hat \\gammab \\right).&\\end{aligned}\\ ] ]    next , we observe that @xmath743 are bounded , mean zero random variables and hence @xmath744 . moreover @xmath745 is a sum of sub - exponential and bounded random variables , hence is sub - exponential .",
    "thus , utilizing the above and results of step 1 we obtain @xmath746 @xmath747",
    "lastly , observe that @xmath748 moreover , as @xmath749 belongs to the cone @xmath750 by step 1 , by convexity arguments it is easy to see that @xmath751 belongs to the same cone .",
    "together with hlder s inequality we obtain @xmath752\\ ] ] utilizing lemma [ lemma0 ] now provides @xmath753\\ ] ] where @xmath754 is such that @xmath755 .",
    "moreover , observe that if @xmath693 is chosen to be larger than the upper bound of @xmath754 .",
    "putting all the terms together we obtain @xmath756 where the last inequality holds as @xmath757 for @xmath758 .    moreover , by condition * ( c ) * and step 1 we have that the left hand side is bigger than or equal to @xmath759 , allowing us to conclude @xmath760 holds with probability approaching one .",
    "let @xmath761 for short .",
    "condition * ( @xmath217 ) * and * ( cc ) * together imply that now we have @xmath762 solving for @xmath763 in the above inequality we obtain @xmath764            its multiplying term can be decomposed as following @xmath774 where @xmath775 denotes entry wise multiplication between two vectors .",
    "the reason we have to spend such a great effort in separating the terms to bound this quantity is that we are dealing with a @xmath430-norm here , rather than an infinity - norm , which is bounded easily .",
    "we start with term @xmath776 .",
    "notice that @xmath777 by hlder s inequality and condition * ( x)*. moreover , by lemma [ lemma0 ] we can easily bound the term above with @xmath778 , with @xmath111 and @xmath170 as defined in condition * ( i)*.    for the term @xmath779 , we have @xmath780 observe , that the right hand side is upper bounded with @xmath781\\right |   \\end{aligned}\\ ] ] by condition ( * x)*. utilizing lemma [ lemma0 ] , lemma [ cor:2 ] and condition ( @xmath204 ) together we obtain @xmath782 for the chosen @xmath221 . combining bounds for the terms @xmath776 and @xmath779",
    ", we obtain @xmath783    next , we bound @xmath784 .",
    "if we rewrite the inner product in summation form , we have @xmath785 notice that @xmath786 is a bounded random variable and such that @xmath787 .",
    "we then apply hoeffding s inequality for bounded random variables , to obtain @xmath788    we begin by first establishing that @xmath789 . in the case",
    "when the penalty part @xmath790 happens to be @xmath169 , which means @xmath791 , the worst case scenario is that the regression part , @xmath792 also results in @xmath169 , i.e. @xmath793 we show that these terms can not be equal to zero simultaneously , since this forces @xmath794 , which is not true .",
    "thus , @xmath795 is bounded away from 0 .    in order to show results about the matrices @xmath796 and @xmath797 , we first provide a bound on the @xmath798 and @xmath799 .",
    "this is critical , since the magnitude of @xmath800 is determined by @xmath799 . to derive the bound on the @xmath799 s",
    ", we have to decompose the terms very carefully and put a bound on each one of them .",
    "recall definitions of @xmath767 and @xmath88 in we have @xmath801 moreover , by the karush - kuhn - tucker conditions of problem we have @xmath802 , which in turn enables a representation @xmath803 by definition we have that @xmath804 for which we have @xmath81 as an estimate .",
    "the @xmath83 and @xmath81 carry information about the magnitude of the values in @xmath71 and @xmath796 respectively .",
    "we next break down @xmath83 and @xmath81 into parts related to difference between @xmath805 and @xmath806 , which we know how to control .",
    "thus , we have the following decomposition , @xmath807    the task now boils down to bounding each one of the terms @xmath808 and @xmath809 , independently .",
    "term @xmath808 is now bounded by lemma [ lem : temp1 ] and is in order of @xmath810 regarding term @xmath809 , we first point out one result due to the karush - kuhn - tucker conditions of ( 6 ) , @xmath811 for the term @xmath809 , we then have @xmath812 since by lemma [ cor:2 ] we have @xmath813 putting all the pieces together , we have shown that rate @xmath814      [ proof of lemma [ lemma4 ] ] for the simplicity of the proof we introduce some additional notation .",
    "let @xmath817 , and @xmath818.\\ ] ] observe that @xmath819 and hence @xmath820 .",
    "the term we wish to bound then can be expressed as @xmath821 for @xmath822 denoting the following quantity @xmath823\\ ] ] and @xmath824    let @xmath606}$ ] be centers of the balls of radius @xmath607 that cover the set @xmath608 .",
    "such a cover can be constructed with @xmath609 ( see , for example * ? ? ?",
    "furthermore , let @xmath611 be a ball of radius @xmath612 centered at @xmath613 with elements that have the same support as @xmath613 .",
    "in what follows , we will bound @xmath825 using an @xmath615-net argument . in particular",
    ", using the above introduced notation , we have the following decomposition @xmath826 } \\sup_{\\deltab \\in \\mathcal{b } ( \\tilde \\deltab_k , r_n\\xi_n ) } \\norm { \\mathbb{v}_n ( \\deltab)}_\\infty \\\\ & \\leq \\underbrace {    \\max_{k \\in [ n_\\delta ] }    \\norm{\\mathbb{v}_n ( \\tilde \\deltab_k)}_\\infty     } _ { t_1 }   +   \\underbrace {    \\max_{k \\in [ n_\\delta ] }    \\sup_{\\deltab \\in \\mathcal{b } ( \\tilde \\deltab_k , r_n\\xi_n ) }    \\norm { \\mathbb{v}_n ( \\deltab ) -   \\mathbb{v}_n ( \\tilde \\deltab_k)}_\\infty } _ { t_2}. \\end{aligned}\\ ] ]    observe that the term @xmath514 arises from discretization of the sets @xmath827 . to control it",
    ", we will apply the tail bounds for each fixed @xmath618 and @xmath444 .",
    "the term @xmath518 captures the deviation of the process in a small neighborhood around the fixed center @xmath828 . for those deviations we will provide covering number arguments . in the remainder of the proof , we provide details for bounding @xmath514 and @xmath518 .",
    "we first bound the term @xmath514 in .",
    "let @xmath829 .",
    "we are going to decouple dependence on @xmath830 and @xmath94 . to that end , let @xmath831 }      -      \\rbr {         f_i ( \\zero ) g_i(\\zero ) -          \\ee \\left [ f_i ( \\zero ) g_i(\\zero )   | x_i \\right ] } }    \\\\ \\intertext{and }    \\tilde z_{ijk }   & =       a_{ij}(\\betab^ * + \\tilde\\deltab_k )      \\rbr {       \\ee \\left [ f_i ( \\tilde\\deltab_k ) g_i(\\tilde\\deltab_k )   | x_i \\right ]        -       \\ee \\left [ f_i ( \\zero ) g_i(\\zero )   | x_i \\right ]      }      \\\\      & -      \\ee\\sbr {           a_{ij}(\\betab^ * + \\tilde\\deltab_k )      \\rbr {        f_i ( \\tilde\\deltab_k ) g_i(\\tilde\\deltab_k ) -       f_i ( \\zero ) g_i(\\zero )   }      } .\\end{aligned}\\ ] ]    with a little abuse of notation we use @xmath96 to denote the density of @xmath94 for all @xmath22 .",
    "observe that @xmath832 = f_i (   \\deltab ) \\pp(\\varepsilon_i",
    "\\leq x_i   \\deltab)$ ] .",
    "we use @xmath833 to denote the right hand side of the previous equation .    then @xmath834 }      \\max_{j \\in [ p ] }      \\abr {        n^{-1}\\sum_{i\\in[n ] } \\rbr{z_{ijk } + \\tilde z_{ijk } } } \\leq       \\underbrace {      \\max_{k \\in [ n_\\delta ] }      \\max_{j \\in [ p ] }      \\abr {        n^{-1}\\sum_{i\\in[n ] } z_{ijk }      } } _ { t_{11 } }   +      \\underbrace {      \\max_{k \\in [ n_\\delta ] }      \\max_{j \\in [ p ] }          \\abr {        n^{-1}\\sum_{i\\in[n ] }   \\tilde z_{ijk }       } } _ { t_{12}}.\\end{aligned}\\ ] ] note that @xmath835 } ] = 0 $ ] and @xmath836 } ] \\\\     & =       a_{ij}^2(\\betab^ * + \\tilde\\deltab_k )    \\big (      w_i ( \\tilde\\deltab_k )      - w_i^2 ( \\tilde\\deltab_k )   +       w_i (   \\zero )      - w_i^2 (   \\zero )          \\\\      & \\qquad\\qquad\\qquad\\qquad\\qquad\\qquad-      2 \\rbr{w_i ( \\zero ) \\vee w_i(\\tilde\\deltab_k ) }      +       2 w_i\\rbr {   \\tilde\\deltab_k }        w_i\\rbr { \\zero }        \\big ) \\\\    & \\stackrel{(i)}{\\leq } a_{ij}^2(\\betab^ * + \\tilde\\deltab_k )    \\rbr {      w_i ( \\tilde\\deltab_k )      +      w_i ( \\zero )      -      2 \\rbr{w_i (   \\zero ) \\vee w_i ( \\tilde\\deltab_k ) }    }   \\\\    & \\stackrel{(ii)}{\\leq } a_{ij}^2(\\betab^ * + \\tilde\\deltab_k )    f_i ( \\tilde \\deltab_k )    \\abr {    x_i   \\tilde\\deltab_k    }    f\\rbr {   \\eta_ix_i   \\tilde\\deltab_k }    \\quad \\rbr{\\eta_i \\in [ 0,1 ] } \\\\    & \\stackrel{(iii)}{\\leq } a_{ij}^2(\\betab^",
    "* + \\tilde\\deltab_k )     f_i ( \\tilde \\deltab_k )    \\abr {     x_i   \\tilde\\deltab_k    }    f_{\\max}\\end{aligned}\\ ] ] where @xmath625 follows by dropping a negative term , @xmath626 follows by the mean value theorem , and @xmath627 from the assumption that the conditional density is bounded stated in condition  * ( e)*.    furthermore , conditional on @xmath837}$ ] we have that almost surely .",
    "we will work on the event @xmath839 , j \\in [ p ] }      |a_{ij}(\\betab^ * + \\tilde \\deltab_k ) -\\sigmab^{-1}_{ij } ( \\betab^ * ) | \\leq c_n } ,   \\end{aligned}\\ ] ] which holds with probability at @xmath176 using lemma [ lemma2 ] . for a fixed @xmath209 and @xmath444 bernstein s inequality ( see , for example , section 2.2.2 of * ? ? ?",
    "* ) gives us @xmath630 } z_{ijk } }    \\leq c\\rbr {    \\sqrt {      \\frac{f_{\\max}\\log(2/\\delta)}{n^2 }      \\sum_{i\\in[n]}a_{ij}^2(\\betab^ * + \\tilde\\deltab_k )      \\abr{x_i   \\tilde\\deltab_k }    }    \\bigvee \\frac{\\max_{i\\in[n],j\\in[p]}|a_{ij}(\\betab^ * + \\tilde\\deltab_k)|}{n }    \\log(2/\\delta )    } \\end{aligned}\\ ] ] with probability @xmath176 .",
    "on the event @xmath840 @xmath632}a_{ij}^2(\\betab^ * + \\tilde\\deltab_k )      \\abr{x_i   \\tilde\\deltab_k }       &",
    "\\leq c_n^2\\sqrt{\\tilde\\deltab_k^\\top   w(\\betab^*+\\tilde\\deltab_k ) w^\\top(\\betab^*+\\tilde\\deltab_k)\\tilde\\deltab_k } \\leq ( 1+o_p(1))c_n^2 r_n\\lambda_{\\max}^{1/2}(\\sigmab ( \\betab^*)),\\end{aligned}\\ ] ] where the line follows using the cauchy - schwartz inequality and inequality ( 58a ) of @xcite and lemma [ lemma2 ] . combining all of the results above , with probability @xmath633 we have that @xmath630}z_{ijk } }",
    "\\leq c\\rbr {    \\sqrt {      \\frac{c_n^2r_n\\log(2/\\delta)}{n }    }    \\bigvee \\frac{c_n\\log(2/\\delta)}{n } } .\\end{aligned}\\ ] ] using the union bound over @xmath841 $ ] and @xmath635 $ ] , with probability @xmath633 , we have @xmath842 we deal with the term @xmath843 in a similar way . for a fixed @xmath444 and @xmath209 , conditional on the event",
    "@xmath840 we apply bernstein s inequality to obtain @xmath844}\\tilde z_{ijk } } \\leq c \\rbr { \\sqrt{\\frac{c_n^2r_n^2\\log(2/\\delta)}{n } }   \\bigvee \\frac{c_n\\log(2/\\delta)}{n}}\\ ] ] with probability @xmath176 , since on the event @xmath845 in we have that @xmath846 and @xmath847 where in the last step we utilized condition ( * e * ) with @xmath848 .",
    "the union bound over @xmath635 $ ] , and @xmath841 $ ] , gives us @xmath849 with probability at least @xmath633 . combining the bounds on @xmath850 and @xmath843 , with probability @xmath851 , we have @xmath852 since @xmath853 .",
    "let us now focus on bounding @xmath518 term .",
    "note that @xmath854 for some @xmath855 between @xmath856 and @xmath31 .",
    "let @xmath857 and @xmath858 let @xmath859 $ ]",
    ". for a fixed @xmath209 , and @xmath444 we have @xmath860 is upper bounded with @xmath861 }      \\mathbb{q}_{ij}(\\deltab )      -          \\mathbb{q}_{ij}(\\tilde\\deltab_k ) } }     _ { t_{21 } }    +     \\underbrace {    \\sup_{\\deltab \\in \\mathcal{b}(\\tilde \\deltab_k , r_n\\xi_n ) }    \\abr {      n^{-1}\\sum_{i\\in[n ] }      w_{ij}(\\deltab )      -        \\ee\\sbr {          w_{ij}(\\deltab )        }    }    } _ { t_{22}}.\\end{aligned}\\ ] ]    we will deal with the two terms separately .",
    "let @xmath862 @xmath863 observe that the distribution of @xmath640 is the same as the distribution of @xmath864 due to the condition ( * e * ) .",
    "moreover , @xmath865 where @xmath144 is a constant such that @xmath643 .",
    "hence ,    @xmath866}\\max_{i\\in[n ] }    \\sup_{\\deltab \\in \\mathcal{b}(\\tilde \\deltab_k , r_n\\xi_n ) }    \\abr {       x_i   \\deltab      -        x_i   \\tilde\\deltab_k    } \\leq       r_n\\xi_n\\sqrt{t } \\max_{i , j}|x_{ij}|    \\leq c      r_n\\xi_n      \\sqrt { t   }   = : \\tilde l_n.\\end{aligned}\\ ] ]    for @xmath522 , we will use the fact that @xmath645 and @xmath646 are monotone function in @xmath647 .",
    "therefore , @xmath867}\\bigg [    \\abr{a_{ij}(\\betab^ * ) } \\big (    \\ind\\cbr{z_i \\leq    x_i   \\tilde\\deltab_k + \\tilde l_n}-    \\ind\\cbr{-x_i\\betab^ * \\leq   x_i   \\tilde\\deltab_k   - \\tilde l_n}-    \\ind\\cbr{z_i \\leq   x_i   \\tilde\\deltab_k } \\\\    &    +    \\ind\\cbr{-x_i\\betab^ * \\leq   x_i   \\tilde\\deltab_k   }    -    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k - \\tilde l_n}+    \\pp\\sbr{-x_i \\betab^ * \\leq x_i   \\tilde\\deltab_k+ \\tilde l_n } \\\\    &   +    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k } -    \\pp\\sbr{-x_i \\betab^*\\leq   x_i   \\tilde\\deltab_k   } \\big ) \\bigg ] \\end{aligned}\\ ] ] furthermore , by adding and substracting appropriate terms we can decompose the right hand side above into two terms . the first , @xmath868}\\bigg [    \\abr{a_{ij}(\\betab^ * ) } \\big (    \\ind\\cbr{z_i \\leq    x_i   \\tilde\\deltab_k + \\tilde l_n}-    \\ind\\cbr { -z_i \\betab^*\\leq   x_i   \\tilde\\deltab_k - \\tilde l_n }   -     \\ind\\cbr{z_i \\leq   x_i   \\tilde\\deltab_k } \\\\    &   +    \\ind\\cbr{-x_i\\betab^ * \\leq   x_i   \\tilde\\deltab_k   }     -    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k + \\tilde l_n}+    \\pp\\sbr{-x_i \\betab^ * \\leq x_i   \\tilde\\deltab_k- \\tilde l_n}\\\\    &   +    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k } -    \\pp\\sbr{-x_i \\betab^*\\leq   x_i   \\tilde\\deltab_k   } \\big ) \\bigg ] \\end{aligned}\\ ] ] and the second @xmath869}\\bigg [    \\abr{a_{ij}(\\betab^ * ) } \\big (    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k + \\tilde l_n}-    \\pp\\sbr{-x_i \\betab^ * \\leq x_i   \\tilde\\deltab_k- \\tilde l_n } \\\\    &   -    \\pp\\sbr{z_i \\leq   x_i   \\tilde\\deltab_k - \\tilde l_n}+    \\pp\\sbr{-x_i \\betab^ * \\leq x_i   \\tilde\\deltab_k+ \\tilde l_n } \\big ) \\bigg].\\end{aligned}\\ ] ] the first term in the display above can be bounded in a similar way to @xmath514 by applying bernstein s inequality and hence the details are omitted . for the second term",
    "we have a bound @xmath870 , since @xmath871 by the definition of @xmath872 and lemma [ lemma2 ] and @xmath873 . in the last inequality we used the fact that @xmath874 .",
    "therefore , with probability @xmath633 , @xmath875 a bound on @xmath526 is obtain similarly to that on @xmath522 .",
    "the only difference is that we need to bound @xmath876 , for @xmath877 and @xmath419 , instead of @xmath878 .",
    "observe that @xmath879 .",
    "moreover , by construction @xmath880 is a continuous , differentiable and convex function of @xmath2 and is bounded away from zero by lemma [ lemma2 ] .",
    "additionally , @xmath881 is a convex function of @xmath2 as a set of solutions of a minimization of a convex function over a convex constraint is a convex set .",
    "moreover , @xmath882 is a bounded random variable according to lemma [ lemma2 ] .",
    "hence , @xmath883 , for a large enough constant @xmath884 .",
    "therefore , for a large enough constant @xmath172 we have @xmath885 a bound on @xmath518 now follows using a union bound over @xmath841 $ ] and @xmath635 $ ] .",
    "crawford , d. c. , zheng , n. , speelmon , e. c. , stanaway , i. , rieder , m. j. , nickerson , d. a. , mcelrath , m. j. , lingappa , j. ( 2009 ) .",
    "an excess of rare genetic variation in abce1 among yorubans and african - american individuals with hiv-1 .",
    "_ genes and immunity _ , 10(8):pp .",
    "715 - 721 .",
    "fouts , t. r. et al .",
    "balance of cellular and humoral immunity determines the level of protection by hiv vaccines in rhesus macaque models of hiv infection .",
    "_ proceedings of the national academy of sciences_,112(9):pp .",
    "992 - 999 .",
    "javanmard , a. and montanari , a. ( 2014 ) .",
    "hypothesis testing in high - dimensional regression under the gaussian random design model : asymptotic theory .",
    "_ information theory , ieee transactions on _ , 60(10 ) : pp .",
    "6522 - 6554 .",
    "maldarelli , f. , wu , x. , su , l. , simonetti , f. r. , shao , w. , hill , s. , spindler , j. , ferris , a. l. , mellors , j. w. , kearney , m. f. , coffin , j. m. , hughes , s. h. ( 2014 ) .",
    "specific hiv integration sites are linked to clonal expansion and persistence of infected cells .",
    "_ science ( new york , n.y . ) _ , 345(6193):pp .",
    "179 - 183 .",
    "negahban , s. n. , ravikumar , p. , wainwright , m. j. and yu , b. ( 2012 ) . a unified framework for high - dimensional analysis of m - estimators with decomposable regularizers .",
    "_ statistical science _ , 27(4):pp .",
    "538 - 557 .",
    "sawaya b , khalili k , amini s. j. ( 1998 ) .",
    "transcription of the human immunodeficiency virus type 1 ( hiv-1 ) promoter in central nervous system cells : effect of yb-1 on expression of the hiv-1 long terminal repeat .",
    "_ journal of general virology _ , 79(2):pp .",
    "239 - 246 .",
    "swenson , l.c . ,",
    "cobb , b. , geretti , a.m , et al .",
    "comparative performances of hiv-1 rna load assays at low viral load levels : results of an international collaboration .",
    "_ tang y - w , ed .",
    "journal of clinical microbiology _ , 52(2):pp .",
    "517 - 523 .",
    "wainwright , m. j. ( 2009 ) .",
    "sharp thresholds for high - dimensional and noisy sparsity recovery using @xmath887-constrained quadratic programming ( lasso ) . _",
    "ieee transactions on information theory _ , 55(5):pp .",
    "2183 - 2202 .",
    "zellner , a. , ( 1996 ) .",
    "bayesian method of moments ( bmom ) analysis of mean and regression models . _",
    "lee , j.c . ,",
    "johnson , w.o . ,",
    "zellner , a .. modelling and prediction honoring seymour geisser , springer , new york _ , pp .",
    "61 - 72 .",
    "zhang , c. h. and zhang , s. s. ( 2014 ) .",
    "confidence intervals for low dimensional parameters in high - dimensional linear models .",
    "_ journal of royal statistical society .",
    "series b. statistical methodology _ , 76(1):pp .",
    "217 - 242 .",
    "zhao , y. , brown , b. m. and wang , y - g .",
    "( 2014 ) . smoothed rank - based procedure for censored data . _",
    "electronic journal of statistics _ , 8(2):pp .",
    "2953 - 2974 ."
  ],
  "abstract_text": [
    "<S> this paper develops robust confidence intervals in high - dimensional and left - censored regression . </S>",
    "<S> type - i censored regression models are extremely common in practice , where a competing event makes the variable of interest unobservable . </S>",
    "<S> however , techniques developed for entirely observed data do not directly apply to the censored observations . in this paper , we develop smoothed estimating equations that augment the de - biasing method , such that the resulting estimator is adaptive to censoring and is more robust to the misspecification of the error distribution . we propose a unified class of robust estimators , including mallow s , schweppe s and hill - ryan s one - step estimator . in the ultra - high - dimensional setting , where the dimensionality can grow exponentially with the sample size , we show that as long as the preliminary estimator converges faster than @xmath0 , the one - step estimator inherits asymptotic distribution of fully iterated version . </S>",
    "<S> moreover , we show that the size of the residuals of the bahadur representation matches those of the simple linear models , @xmath1  that is , the effects of censoring asymptotically disappear . </S>",
    "<S> simulation studies demonstrate that our method is adaptive to the censoring level and asymmetry in the error distribution , and does not lose efficiency when the errors are from symmetric distributions . </S>",
    "<S> finally , we apply the developed method to a real data set from the maqc - ii repository that is related to the hiv-1 study . </S>"
  ]
}