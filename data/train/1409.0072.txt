{
  "article_text": [
    "networks have received increasing attention in the last decade . in our `` information - rich '' world , questions pertaining to network reconstruction and network analysis have become crucial for the understanding of complex systems . in particular , the analysis of molecular networks has gained significant interest due to the recent explosion of publicly available high - throughput biological data .",
    "another example are social networks , which are social structures made up of individuals , the nodes , tied by one or more specific types of interdependencies , the edges ( e.g. friendship ) .",
    "in this context , identifying and analysing network structures from measured data become key questions .    to mathematically represent networks",
    ", we use the standard graph - theoretical notation @xmath0 , where @xmath1 is the set of nodes , @xmath2 is the set of edges , and @xmath3\\right\\}_{i , j=1,\\ldots , n}$ ] is the corresponding @xmath4 by @xmath4 weighted adjacency matrix , with @xmath5\\neq0 $ ] when there is a link from @xmath6 to @xmath7 , and @xmath5=0 $ ] when there is no link from @xmath6 to @xmath7 . in the classic state - space form , we usually write @xmath8 @xmath9 is the state vector containing the state ( normally physical quantity ) of the system .",
    "@xmath10 is the weighted adjacency matrix reflecting the direct causal relations between the state variables , @xmath11 , and @xmath12 is a vector of @xmath13 inputs .",
    "this work assumes that @xmath14 states are measured . without loss of generality ,",
    "the output equation can be written as @xmath15 , where @xmath16 $ ] , @xmath17 is the @xmath18 identity matrix , and @xmath19 is the @xmath20 matrix of zeros .",
    "hence , the first @xmath21 elements of the state vector @xmath22 are exactly the measured variables in the system , and the remaining @xmath23 state variables are unmeasured  hidden \" states .",
    "the zero structure of the @xmath24 and @xmath25 matrices exactly describe the structure of the network , and the values of these matrices encode the dynamics of the system .",
    "finding the matrices @xmath26 and @xmath27 , however , can be a difficult problem in the presence of hidden states ( @xmath14 ) .",
    "even with just one hidden state , the realisation problem becomes ill - posed ; a transfer function will have many state space realisations , which may suggest entirely different network structures for the system .",
    "this is true even if it is known that the true system is , in fact , a minimal realisation of the identified transfer function . as a result , failure to explicitly acknowledge the presence and the ambiguity in network structure caused hidden states can lead to a deceptive and erroneous process for network discovery .",
    "motived by this , we developed a new theory for network inference that reflected the effects of hidden states in a network  @xcite .",
    "it introduced a new representation for lti systems called dynamical structure functions ( dsf ) .",
    "dsf capture information at an intermediate level between transfer function and state space representation ( see figure  [ fig : math ] ) .",
    "specifically , dynamical structure functions not only encode structural information at the measurement level , but also contain some information about hidden states . in @xcite , we proposed some guidelines for the design of an experimental data - acquisition protocol which allows the collection of data containing sufficient information for the network structure reconstruction problem to become solvable .",
    "using dynamical structure functions as a means to solve the network reconstruction problem , the following aspects need to be considered :        first ( see ( a ) in figure  [ fig : math ] ) , the properties of a dynamical structure function and its relationship with the transfer function associated with the same system were precisely established  @xcite .",
    "second ( see ( b ) in figure  [ fig : math ] ) , an efficient method to reconstruct networks in the presence of noise and nonlinearities was developed  @xcite . in this method , steady - state ( resp .",
    "time - series data ) can be used to reconstruct the boolean ( resp . dynamical network )",
    "structure of the system ( see  @xcite for more details ) .",
    "third ( see ( c ) in figure  [ fig : math ] ) , once the dynamical structure function is obtained , an algorithm for constructing a minimal order state - space realisation of such function needs to be developed .",
    "this third point is the main contribution of this paper . in an application ,",
    "this provides an estimate of the complexity of the system by determining the minimal number of hidden states in the system .",
    "for example , in the context of biology it helps understand the number of unmeasured molecules in a particular pathway : a low number of hidden states means that most molecules in that pathway have been identified and measured , showing a good understanding of the system ; while a large number shows that there are still many unmeasured variables , suggesting that new experiments should be carried out to better characterise that pathway .    for a given dynamical structure function ,",
    "the major contributions of this paper are :    * it explicitly characterises the _ direct _ causal information between measured states and between measured states and inputs ; * it introduces a number of new concepts such as hidden observability and controllability ; * it extends the results in @xcite by considering the minimal realisation problem of more general classes of dynamical structure functions .    the notation in this",
    "paper is standard . for a matrix @xmath28 , @xmath5 \\in \\mathbb{r}$ ] denotes the element in the @xmath29 row and @xmath30 column , @xmath31 \\in \\mathbb{r}^{1 \\times n}$ ] denotes its @xmath29 row , @xmath32",
    "\\in \\mathbb{r}^{m \\times 1}$ ] denotes its @xmath30 column , and @xmath33 $ ] denotes the submatrix of @xmath26 defined by the rows @xmath34 to @xmath35 and the columns @xmath36 to @xmath37 . for a column vector @xmath38 ,",
    "@xmath39 $ ] denotes its @xmath29 element .",
    "we denote @xmath40 \\in \\mathbb{r}^{1 \\times n}$ ] .",
    "furthermore , @xmath41 denotes the identity matrix of size @xmath42 .",
    "consider the following linear system ( we put a superscript @xmath43 indicating the original system ) @xmath44 & = &     \\left[\\begin{array}{cc}{a}^o_{11}&{a}^o_{12}\\\\{a}^o_{21}&{a}^o_{22}\\end{array}\\right]\\left[\\begin{array}{c}{y}\\\\{z}\\end{array}\\right ]     + \\left[\\begin{array}{c } { b}^o_{1}\\\\{b}^o_{2}\\end{array}\\right]{u } \\\\",
    "{ y } & = &     \\left[\\begin{array}{cc}{i}_p&{0}\\end{array}\\right]\\left[\\begin{array}{c}{y}\\\\{z}\\end{array}\\right ] ,     \\end{array}\\ ] ] where @xmath45 is the full state vector , @xmath46 is a partial measurement of the state , @xmath47 are the @xmath48 `` hidden '' states , and @xmath49 is the control input . in this work",
    "we restrict our attention to situations where output measurements constitute partial state information , i.e. , @xmath50 .",
    "it is well known that the transfer function of this system can be defined by @xmath51(si - a^o)^{-1}b^o$ ] .",
    "dynamical structure functions can be uniquely determined by state - space realisations .",
    "it is more involved comparing with the definition of a transfer function @xcite .    taking the laplace transforms of the signals in  ( [ eq : lti ] ) yields @xmath52 & = & \\left[\\begin{array}{cc}{a}^o_{11}&{a}^o_{12}\\\\{a}^o_{21}&{a}^o_{22}\\end{array}\\right]\\left[\\begin{array}{c}{y}\\\\{z}\\end{array}\\right ] + \\left[\\begin{array}{c } { b}^o_{1}\\\\{b}^o_{2}\\end{array}\\right]{u }       \\end{array}\\ ] ] where @xmath53 , @xmath54 , and @xmath55 are the laplace transforms of @xmath56 , @xmath47 , and @xmath57 , respectively . solving for @xmath54",
    "gives @xmath58 substituting this last expression of @xmath54 into  ( [ eq : ltilaplace ] ) then yields @xmath59 where @xmath60 and @xmath61 .    now , let @xmath62 be a diagonal matrix formed of the diagonal terms of @xmath63 on its diagonal , i.e. , @xmath64 .",
    "subtracting @xmath65 from both sides of , we obtain : @xmath66 note that @xmath67 is a matrix with zeros on its diagonal .",
    "we thus have : @xmath68 where @xmath69 and @xmath70 note that @xmath71 has zero on the diagonal . given the system in  ( [ eq : lti ] ) , @xmath72 $ ] denotes the _ dynamical structure functions _ of the system .",
    "next we shall explore some properties of @xmath73 $ ] .",
    "one of the most important properties is that the dynamical structure functions capture the _ direct _ causal relations between measured states @xmath74 .",
    "[ th : qp ] given a dynamical system  ( [ eq : lti ] ) and its associated dynamical structure functions @xmath72 $ ] with @xmath62 constructed as explained above ( see - ) , the following conditions must hold @xmath75    see appendix  [ sec : appendixa ] .",
    "this proposition reveals an important property of dynamical structure functions : they encode the direct causal relations between observed variables , i.e. , @xmath76~,\\forall i\\neq j$ ] .",
    "these relations can not be revealed by transfer functions .",
    "[ ex1 ] consider a network with the structure depicted in fig .",
    "[ fig : ex1 ] .",
    "the linear state - space representation of this network is given by @xmath77 following the definitions in and , the corresponding dynamical structure functions @xmath72 $ ] are @xmath78    , @xmath79 , and @xmath80 ) and two hidden states ( blue states @xmath81 and @xmath82 ) . * ( b ) * the corresponding dynamical structure functions . ]    from proposition  [ th : qp ] , we can check that : @xmath83      in general , @xmath84 and @xmath85 carry more information than @xmath86 .",
    "this can be seen from the equality @xmath87 .",
    "however , @xmath84 and @xmath85 carry less information than the state - space model ( see  @xcite and figure  [ fig : problems ] ) .",
    "this leads to the problem of realisation of @xmath72 $ ] , similar to the problem of realisation of @xmath88 . basically , just like the fact that there are infinite state - space realisations that give the same transfer function ( realisation problem ( 1 ) and set red in figure  [ fig : problems ] ) , there are an infinite state - space realisations that give the same @xmath72 $ ] ( realisation problem ( 2 ) and set magenta in figure  [ fig : problems ] ) .",
    "a system @xmath89)$ ] is a realisation of @xmath72 $ ] if that @xmath90 gives @xmath72 $ ] from eq .",
    "and eq .  .",
    "we say that a realisation @xmath89)$ ] of @xmath91 is @xmath92-minimal if this realisation corresponds to a minimal realisation of @xmath92 .",
    "we say that a realisation @xmath90 of @xmath73 $ ] is @xmath72$]-minimal if this realisation of @xmath72 $ ] has the smallest order .",
    "let a system @xmath90 have the following form @xmath93 be a realisation of @xmath73 $ ] . in this subsection",
    ", we shall introduce properties of minimal realisations of @xmath73 $ ] and all the proofs in this subsection can be found in appendix  [ sec : appendixa ] . .",
    "[ lemma : tra ] let @xmath94 be a realisation of @xmath73 $ ] ( eq .  ) and consider a linear transformation mapping @xmath95 to @xmath96 , @xmath97 is also a realisation of @xmath73 $ ] for any @xmath98 with the following form @xmath99 for any invertible matrix @xmath100 .    according to the above proposition",
    ", one can apply linear transformations to the hidden states without changing the dynamical structure function .",
    "similar to minimal realisation of transfer functions , based on proposition  [ lemma : tra ] we can define the following hidden observability and controllability concepts .    given a realisation @xmath90 of @xmath73 $ ]",
    ", we say it is hidden observable if and only if @xmath101 $ ] is observable .    given a realisation @xmath90 of @xmath73 $ ]",
    ", we say it is hidden controllable if and only if @xmath102\\right]$ ] is controllable .    from these two definitions",
    ", we can show that if a realisation @xmath90 is @xmath73$]-minimal then it is both hidden observable and controllable .",
    "linear transformations of the form @xmath98 in eq .",
    "do not change the hidden observability and hidden controllability of a system .",
    "[ th : hidden ] if a realisation @xmath90 of @xmath73 $ ] is minimal , then it is hidden observable and hidden controllable .",
    "it is easy to show by contradiction .",
    "@xmath103    note that a realisation @xmath90 of @xmath73 $ ] can be hidden observable and hidden controllable and not necessarily @xmath73-$ ] minimal .",
    "[ th : obserable ] if a system @xmath90 is hidden observable , then it is observable .    based on the above proposition , we can show the following corollary .    given a minimal realisation @xmath90 of @xmath73 $ ] ,",
    "then the order of this realisation is equal to the order of @xmath104 if and only if @xmath90 is controllable .",
    "from here on , the paper assumes that the dynamical structure functions @xmath73 $ ] and the transfer function @xmath91 are known , and the original state - space realisation   is unknown .",
    "we then proceed to search for a minimal realisation of @xmath73 $ ] . just like the minimal realisation of a transfer function , the underlying principle to find a @xmath72$]-minimal realisation is to search for a realisation with the minimal number of hidden states .",
    "the rest of the paper aims to solve the following problem .",
    "[ prob : main ] _ [ _ * minimal @xmath73 $ ] realisation * _ ] _ given a dynamical structure function @xmath73 $ ] , find a minimal realisation @xmath105)$ ] of @xmath73 $ ] .    from the above definitions ,",
    "the order of a minimal structural realisation of @xmath73 $ ] is always higher or equal to that of a minimal realisation of a transfer function @xmath104 .",
    "note that the original transfer matrices @xmath106 $ ] can not be reconstructed from the dynamical structure function @xmath72 $ ] since there is no information regarding the diagonal proper transfer function matrix @xmath62 .",
    "hence , choosing an arbitrary diagonal proper transfer function matrix @xmath107 leads to an arbitrary @xmath108 $ ] from the following equation @xmath109= [ ( s{i } - { r}){q } + { r},(s{i}-{r}){p}],\\ ] ] which is obtained from reversing the steps in equations  ( [ eq : q ] ) and  ( [ eq : p ] ) . note that , in general , @xmath108 $ ] will be different from @xmath106 $ ] .",
    "a realisation of @xmath108 $ ] is given by @xmath110=[{a}_{11},{b}_1]+{a}_{12}(s{i}-{a}_{22})^{-1}[{a}_{21},{b}_2]\\ ] ] where @xmath24 and @xmath25 are state - space matrices , structured similarly to equation  ( [ eq : lti ] ) .",
    "again , this realisation is , in general , different from  ( [ eq : lti ] ) , since it is not possible to recover  ( [ eq : lti ] ) from @xmath72 $ ] alone .",
    "any realisation of @xmath73 $ ] can be obtained from eq .",
    "and eq .  .    the idea for solving problem  [ prob : main ] is to use a state - space realisation approach to find an @xmath111 that minimises the order of @xmath112 $ ]",
    "such realisation is also a @xmath72 $ ] minimal realisation .",
    "mathematically , the problem can be reformulated according to finding such @xmath111 @xmath113,\\ ] ] where deg is the mcmillan degree @xcite and @xmath114 is the set of all proper diagonal transfer matrices with dimension @xmath21 ( the number of measured states ) that admits a diagonal realisation .",
    "this is equivalent to finding @xmath115 from the following equation @xmath116+[{r},{0}]\\right\\}.\\ ] ] this non - convex optimisation is , in general , hard to solve directly .",
    "note that a random choice of a proper diagonal transfer function matrix @xmath107 is likely to result in additional zeros in @xmath117 $ ] .",
    "[ prop : control ] if @xmath117 $ ] has a zero , then for any realisation @xmath118)$ ] obtained from eq .",
    ", @xmath119 $ ] is not controllable .",
    "see appendix  [ sec : appendixa ] .",
    "@xmath103    proposition  [ prop : control ] shows that these additional zeros in @xmath117 $ ] lead to unnecessary uncontrollable modes in the realisation @xmath118)$ ] which means that @xmath118)$ ] is not a minimal realisation of @xmath73 $ ]",
    ".    there might be many choices for @xmath111 that minimise the order of minimal realisations of @xmath120 $ ] .",
    "after solving the problem in eq .",
    "( [ eq : d ] ) and obtaining a minimal realisation of @xmath73 $ ] , we can use proposition  [ lemma : tra ] to find other minimal realisations of @xmath73 $ ] .",
    "next , we shall convert the optimisation in eq .   into a simpler form that explores the structure of the optimisation . to start , let @xmath121 and note that there is an one - to - one map between @xmath122 and @xmath114 .",
    "[ prop : convert ] for any @xmath123 $ ] with full normal row rank , the following equality holds @xmath124+[{r}~{0}]\\right\\}\\nonumber\\\\ & = \\min_{n\\in\\mathcal{e}_p } ~\\text{deg } \\left\\{n[i-{q},~{p}]\\right\\}-p.\\end{aligned}\\ ] ]    see appendix  [ se : appb ] .    from the above proposition ,",
    "the next section shall focus on solving @xmath125\\}.\\ ] ]",
    "this section proposes an algorithm to solve the optimisation in eq .  .",
    "it follows that @xmath126\\right\\}=\\text{deg}\\left\\{n\\right\\}+\\text{deg}\\left\\{[i-{q},{p}]\\right\\}\\nonumber\\\\ & -\\text{$\\#$ of cancelled zeros of $ [ i - q , p]$ by cascading } \\nonumber\\\\   & - \\text{$\\#$ of cancelled poles of $ [ i - q , p]$ by cascading}. \\label{eq : degree}\\end{aligned}\\ ] ] next , we shall derive conditions on @xmath127 for cancelling zeros and poles of @xmath123 $ ] .    [ ass:1 ] assume that @xmath123 $ ] only has simple poles and does not have the same poles and zeros .",
    "since @xmath128 are strictly proper , a minimal realisation of @xmath129 $ ] has the following form : @xmath130 . when @xmath123 $ ] has @xmath131 simple poles , gilbert s realisation @xcite gives @xmath132=\\sum_{i=1}^l \\frac{{k}_i}{s-\\lambda_i}+\\lim_{s\\rightarrow\\infty}[i-{q},{p}],\\ ] ] where @xmath133 $ ] and has rank @xmath134 , since we are assuming that @xmath129 $ ] has simple poles .",
    "consider the following matrix decomposition for @xmath135 : @xmath136 where @xmath137 and @xmath138 . then @xmath139 , @xmath140 , @xmath141 and @xmath142=[i,0]$ ] .",
    "similarly , @xmath127 is a diagonal transfer matrix with its minimal realisation @xmath143 . without loss of generality ,",
    "assume the matrix @xmath144 is diagonal ( otherwise , a linear transform can diagonalise @xmath145 without changing @xmath127 ) .",
    "a minimal realisation of a diagonal transfer matrix can be obtained from a composition of gilbert realisations of all transfer functions on the diagonal .",
    "let @xmath146=c_m(si - a_m)^{-1}b_m$ ] where @xmath147 is the minimal realisation of the the @xmath148 transfer function on the diagonal .",
    "then a minimal realisation of @xmath42 has the form @xmath149 , ~b_2=\\text{diag } [ b_1,~\\ldots,~b_k],\\nonumber\\\\ & c_2=\\text{diag } [ c_1,~\\ldots,~c_k],\\label{eq : realisationofn}\\end{aligned}\\ ] ] ( with @xmath150 , where @xmath151 is the mcmillan degree of @xmath127 ) . in the following results , let @xmath152 be the boolean operator which maps a matrix / vector to a boolean one .",
    "[ thm : cancelz ] under assumption  [ ass:1 ] , if a zero @xmath153 of @xmath123 $ ] ( with direction @xmath154 ) is cancelled by cascading a system @xmath155 , then @xmath156(s)$ ] has a pole at @xmath153 for any @xmath6 such that @xmath157\\neq0 $ ] .",
    "if a zero of @xmath123 $ ] , say @xmath153 , is cancelled by cascading a system @xmath158 , then the realisation of the cascaded system @xmath159 $ ] loses controllability .    in this case",
    ", it follows that there exists a nonzero vector @xmath160 $ ] such that @xmath161 \\end{bmatrix}=0.\\ ] ] this leads to    * @xmath162 which indicates that @xmath163 is an eigenvector of @xmath144 corresponding to @xmath153 .",
    "* @xmath164 \\end{bmatrix}=0.\\ ] ]    notice that , @xmath165 \\end{bmatrix } & \\begin{bmatrix } { i } & -({a}_1-s{i})^{-1}b_1 \\\\ 0 & { i } \\end{bmatrix}\\\\   & = \\begin{bmatrix } { a}_1-s{i } & 0\\\\ c_1 & { [ i - q(s),p(s ) ] } \\end{bmatrix},\\end{aligned}\\ ] ] and , since @xmath153 is not a pole of @xmath166 $ ] , it follows from eq .   that @xmath167}=0\\ ] ] by definition , @xmath153 is a zero of @xmath168}$ ] if there exists a @xmath154 such that @xmath169}=0,\\ ] ] by comparing eqs .",
    "( [ eq : reqs ] ) and  ( [ eq : zero ] ) we conclude that @xmath170 is the vector associated with the zero direction of @xmath171}$ ] .",
    "then , it also follows that @xmath172 since @xmath173 in eq .",
    "are diagonal matrices for all @xmath13 , then without loss of generality @xmath174 if @xmath173 has an eigenvalue as @xmath153 .",
    "since @xmath175 also has a block diagonal structure , we have @xmath176\\\\ & = \\left[b_1[:,1],~b_2[:,1 ] , \\ldots,~ b_k[:,1]\\right].\\end{aligned}\\ ] ] this implies that the @xmath30 nonzero elements in @xmath154 corresponds to a nonzero element in @xmath177 $ ] which further implies that @xmath153 is a pole of @xmath156(s)$ ] , the @xmath30 transfer function on the diagonal of @xmath127 .",
    "@xmath103    [ thm : cancelp ] under assumption  [ ass:1 ] , if a pole @xmath153 of @xmath129 $ ] is cancelled by cascading a system @xmath155 , then@xmath178 where @xmath179 is defined in eq .  .",
    "if a pole of @xmath123 $ ] , say @xmath153 , is cancelled by @xmath158 , then the realisation of the cascade @xmath180 $ ] loses observability . in this case , it follows that there exists a nonzero vector @xmath181^t$ ] such that @xmath182 the first equation in eq .",
    "shows that @xmath183 is an eigenvector of @xmath184 corresponding to @xmath153 .",
    "since @xmath184 is diagonal , we can directly compute @xmath185 .",
    "therefore we have @xmath186 noticing that @xmath187 from eq .  , that @xmath188 and that @xmath189 is not a pole of @xmath127 , we obtain @xmath190@xmath103    based on theorem  [ thm : cancelp ] , we have the following corollary .",
    "[ coro : cancelp ] if a pole @xmath153 of @xmath129 $ ] is cancelled by cascading a system @xmath155 , then @xmath156(s)$ ] has a zero at @xmath153 for any @xmath6 such that @xmath191\\neq0 $ ] .    in summary",
    ", designing @xmath111 to cancel any pole @xmath153 of @xmath129 $ ] is equivalent to imposing that eq .   holds .",
    "the boolean structure of @xmath179 , @xmath192 imposes constraints on the diagonal terms in @xmath127 for cancelling the poles of @xmath123 $ ] .      following the derivations and analysis of the previous section",
    ", we shall propose an algorithm to directly answer the question in problem  [ prob : main ] : given @xmath194 $ ] , what is the maximal number of poles that can be cancelled by left multiplication of @xmath195 , bearing in mind that @xmath196 ?",
    "recall from eq .   that @xmath197\\right\\}=\\text{deg}\\left\\{n\\right\\}+\\text{deg}\\left\\{[i - q , p]\\right\\}\\nonumber\\\\ & -\\text{$\\#$ of cancelled zeros of $ [ i - q , p]$ by cascading}\\nonumber\\\\   & - \\text{$\\#$ of cancelled poles of $ [ i - q , p]$ by cascading } , \\end{aligned}\\ ] ] since the @xmath198\\right\\}$ ] is known and fixed ,",
    "let @xmath199 $ ] then the optimisation problem in above equation becomes @xmath200$}\\nonumber\\\\ & - \\text{$\\#$ of cancelled poles of $ [ i - q , p]$}+\\text{deg}\\left\\{n\\right\\}\\}.\\end{aligned}\\ ] ] note that any @xmath201 can be written as @xmath202 where @xmath203 and @xmath204 are coprime factors for all @xmath205 .",
    "then @xmath206 where @xmath207 for all @xmath7 .",
    "next , we shall propose how to design @xmath204 and @xmath208 based on theorems  [ thm : cancelz ] and  [ thm : cancelp ] .    to minimise the above cost function",
    ", we are aiming to have maximal number of zeros of @xmath123 $ ] as poles of some diagonal elements in @xmath127 from theorem  [ thm : cancelz ] , since this a ) will not increase the mcmillan degree of @xmath209 and b ) gives more degrees of freedom in zeros of @xmath127 to cancel the poles of @xmath123 $ ] ( and therefore minimise the mcmillan degree of the cascaded system ) , since the number of zeros in @xmath210(s)$ ] equals the number of its poles .",
    "moreover , to cancel one pole @xmath153 of @xmath123 $ ] , corollary  [ coro : cancelp ] requires that @xmath156(s)$ ] has a zero at @xmath153 if @xmath191\\neq0 $ ] . assuming the sparsity of @xmath211 is @xmath212 ( @xmath213 ) , this",
    "would then lead to an increase of the degree of @xmath127 by @xmath212 since @xmath42 is a diagonal transfer matrix with every element in @xmath214 .",
    "based on the analysis above and theorems  [ thm : cancelz ] and  [ thm : cancelp ] , to maximise the the number of poles in @xmath123 $ ] that can be cancelled , one should a ) design poles of @xmath42 to cancel all the zeros of @xmath123 $ ] and b ) use the degrees of freedom in designing zeros of @xmath42 to cancel as many poles of @xmath123 $ ] .    the next question is then how to solve the optimisation problem in b ) once a ) is done . technically , we can use table  [ table : example ] , which is generated as follows .",
    "column @xmath7 corresponds to the @xmath29 place on the diagonal of the to - be - designed @xmath127 and the rows are the poles of @xmath123 $ ] , @xmath215 , in any order .",
    "the intersection of the @xmath29 row and the @xmath30 column is a boolean value corresponding to @xmath211 , the boolean map of the corresponding direction of the @xmath29 pole .",
    "it is @xmath134 if we require the @xmath30 element of @xmath127 to have a zero at @xmath215 to cancel the @xmath29 pole @xmath215 of @xmath123 $ ] .",
    "hence , table  [ table : example ] shows the requirements to cancel each of the poles as expressed in eq .  .",
    ".table for computing the maximum number of pole - zero cancellations . [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     solve the following optimisation problem @xmath216 where , @xmath217 is the binary element in the @xmath29 row and @xmath30 column of table  [ table : example1 ] . by solving the above optimisation ,",
    "the optimal solution is @xmath218 .",
    "hence , the dimension of @xmath26 is @xmath219 .",
    "there are several optimal solutions .",
    "choose , for example , the solution @xmath220 .",
    "then @xmath221\\ ] ] where @xmath222 are nonzero parameters .",
    "if @xmath223 , then @xmath224&=n^*[i - q , p]\\\\ & = \\begin{bmatrix } \\frac{s+3}{s } & 0 & 0 & \\frac{1}{s } & 0 \\\\ \\frac{-1}{s(s+2 ) } & \\frac{(s+1)^2}{s(s+2 ) } & 0 & 0 & \\frac{s+1}{s^2 + 2s}\\\\ 0 & \\frac{-1}{s^2 + 2s } & \\frac{s+4}{s } & 0 & 0   \\end{bmatrix},\\end{aligned}\\ ] ] which gives @xmath225=\\begin{bmatrix } -3 & 0 & 0 & 1 & 0 \\\\ \\frac{1}{s+2 } & \\frac{-1}{s+2 } & 0 & 0 & \\frac{s+1}{s+2}\\\\ 0 & \\frac{-1}{s+2 } & -4 & 0 & 0   \\end{bmatrix}.\\ ] ] with @xmath226   .\\ ] ]    find a minimal realisation of @xmath108 $ ] and obtain the corresponding @xmath227 matrices : @xmath228&= \\begin{bmatrix } -3 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 1\\\\ 0 & 0 & -4 & 0 & 0   \\end{bmatrix},\\\\ { a}_{12}&= \\begin{bmatrix } 0 & 0\\\\ 1 & 0\\\\ 0 & 1 \\end{bmatrix } , a_{22}=\\begin{bmatrix } -2 & 0\\\\ 0 & -2 \\end{bmatrix},\\\\ [ { a}_{21}~{b}_2]&=\\begin{bmatrix } 1 & -1 & 0 & 0 & -1\\\\ 0 & -1 & -1 & 0 & 0   \\end{bmatrix}.\\end{aligned}\\ ] ] hence , a minimal realisation has the following form : @xmath229    note that , as mentioned in step 3 , there are several solutions to @xmath193 .",
    "for example , chosing of the solution @xmath230 would have lead to a different @xmath193",
    ". however , ultimately all optimal solutions have @xmath227 matrices of the same dimension .",
    "this paper presented an algorithm for obtaining a minimal order realisation of a given dynamical structure function .",
    "this provided a way to estimate the complexity of systems by determining the minimal number of hidden states in networks .",
    "this can help understand the minimal number of unknown states interacting in a particular network .",
    "1 k. zhou , j. doyle and k. glover , prentice hall , 1996 .",
    "j. gonalves and s. warnick , `` necessary and sufficient conditions for dynamical structure reconstruction of lti networks '' , ieee transactions on automatic control , 53(7 ) : 1670 - 1674 , 2008 .",
    "y. yuan , g. stan , s. warnick and j. gonavles , `` minimal dynamical structure realisations with application to network reconstruction from data , '' ieee conference on decision and control , 2009 .",
    "y. yuan , g. stan , s. warnick and j. gonavles , `` robust dynamical network structure reconstruction , '' special issue on system biology , automatica , 47(6 ) : 1230 - 1235 , 2011 .",
    "s. skogestad and i. postlethwaite , wiley,1996 .",
    "e. g. gilbert , `` controllability and observability in multivariable control systems , '' j.s.i.a.m . control series a , 1 : 128 - 151 , 1963 .",
    "e. balas and e. zemel , `` an algorithm for large zero - one knapsack problems , '' operations research , vol .",
    "1130 - 1154 , 1980 .",
    "c. godsil and g. royal , new york : springer - verlag , 2001 . i. bomze , m. budinich , p. pardalos and m. pelillo , `` the maximum clique problem '' , handbook of combinatorial optimization , 1999 .",
    "j. robson , `` finding a maximum independent set , '' journal of algorithms , 7:425 - 440 , 1986 .",
    "* [ proposition  [ th : qp ] ] * eq",
    ".   is directly obtained from the definition of @xmath231 : @xmath232 since the proofs of eq .   and",
    "are very similar , we focus on eq .   only . in the following ,",
    "we use the fact that for any square matrix @xmath233 , if @xmath234 when @xmath235 , then @xmath236 . from the definition of @xmath71 in , @xmath237 and @xmath238 ,",
    "when @xmath239 .",
    "hence , @xmath240 , in which @xmath241 is a matrix polynomial of @xmath242 , whose largest degree is @xmath243 . finally , multiplying by @xmath242 on both sides and taking the limit as @xmath242 goes to @xmath244 results in eq .  .",
    "a similar argument can be used to prove eq .  .@xmath103",
    "* [ proposition  [ lemma : tra ] ] * partition @xmath26 and @xmath27 according to the following form @xmath245 from this partition , we have that @xmath246 we can then directly compute @xmath108 $ ] for the transformed system and verify that such transformation will preserve @xmath73 $ ] ( the details of the rest of the proof are omitted).@xmath103    * [ proposition  [ th : obserable ] ] * from the popov - belevitch - hautus ( pbh ) rank test  @xcite , a matrix pair @xmath247 is observable iff @xmath248 for all @xmath249 .",
    "if a realisation is hidden observable , then it implies that the pair @xmath250 is observable from its definition , i.e. , @xmath251 hence @xmath252 which concludes the proof . @xmath103    * [ proposition  [ prop : control ] ] * if @xmath253 is a zero of @xmath254 $ ] with direction @xmath255 , by definition of zeros of a transfer function @xcite , @xmath256\\big|_{s = z_0}=0.\\ ] ] recall the definition of @xmath257 $ ] @xmath258 let @xmath259 , then we have @xmath260 where eq",
    ".   is obtained from the definition .",
    "we can rewrite @xmath261\\begin{bmatrix } z_0i - a_{11 } & -a_{12 } & b_1\\\\ -a_{21 } & z_0i - a_{22 } & b_2 \\end{bmatrix}=0,\\ ] ] which means that @xmath262 $ ] is not controllable.@xmath103",
    "the proof of proposition  [ prop : convert ] will be divided into several steps .",
    "start by rewriting eq .",
    "( [ eq : rrealization ] ) as @xmath263= ( s{i}-{r})[i-{q},{p}].\\ ] ] for any @xmath264 , and corresponding @xmath201 , and any @xmath73 $ ] , define @xmath265\\triangleq [ i,0]-n[i - q , p].\\ ] ] let @xmath266 be the normal row rank of @xmath267 $ ] and consider the smith - mcmillan of @xmath267=u(s)m(s)v(s)$ ] , where @xmath268 are unimodular matrices in @xmath242 , and @xmath269 where @xmath270 divides @xmath271 and @xmath272 divides @xmath273 for any @xmath274 .",
    "let @xmath275 be the smallest integer that @xmath276 , which means that polynomial @xmath242 exactly divides polynomial @xmath277 ( otherwise @xmath278 ) .",
    "rewrite eq .",
    "( [ eq : rrealization ] ) as @xmath263= ( s{i}-{r})[i-{q},{p}].\\ ] ] then , for any @xmath264 , and corresponding @xmath201 , and any @xmath73 $ ] , @xmath280=n[i - q , p ] & = ( i - r / s)[i - q , p]\\\\   & = [ i - w / s , v / s ] . \\end{aligned}\\ ] ] it follows that @xmath281\\}=\\text{deg}\\{[sx , sy]\\}=\\text{deg}\\{s[x , y]\\}.\\end{aligned}\\ ] ] rewrite the expression of @xmath282 $ ] as @xmath283&=su(s)m(s)v(s ) \\triangleq u(s)m'(s)v(s),\\end{aligned}\\ ] ] where @xmath284 since @xmath285=\\sum_{i=1}^q\\text{deg}[\\beta_i(s)],\\ ] ] and @xmath286 for all @xmath7 then @xmath287&=\\sum_{i=1}^q\\text{deg}[\\beta_i(s)]-q+j-1\\nonumber\\\\ & = \\text{deg}[x , y]-q+j-1\\nonumber\\\\ & = \\text{deg}[i - x , y]-q+j-1\\nonumber \\\\ & = \\text{deg}n[i - q , p]-q+j-1 .",
    "\\label{eq : jj}\\end{aligned}\\ ] ] based on the above analysis , we can reformulate the optimisation on the left - hand side of eq .   into the following form @xmath288&=\\min_{n\\in\\mathcal{e}_p } \\text{deg}[sx , sy]\\nonumber\\\\ & = \\min_{n\\in\\mathcal{e}_p}\\{\\text{deg}n[i - q , p]-q+j-1\\}. \\label{eq : n}\\end{aligned}\\ ] ] @xmath103    the above optimisation is hard to solve since both @xmath289 $ ] , @xmath290 and @xmath6 depend on the choice of @xmath42 .",
    "however , we will show next that an @xmath291 that minimises @xmath289 $ ] is also a solution to eq .  .",
    "such @xmath291 results in @xmath292 and @xmath293 .",
    "the remaining part of the proof will use notation and content from sections  [ se:4.1 ] and  [ se:4.2 ] .",
    "hence , the reader is expected to have read these sections before continuing .",
    "first , we shall discuss why an optimal @xmath193 guarantees @xmath292 and then that it also guarantees @xmath293 . from eqs .",
    "( [ eq : nnew1 ] ) and  ( [ eq : nnew2 ] ) @xmath280&=\\text{diag}\\left\\{\\frac{sd_1-n_1}{sd_1},\\ldots,\\frac{sd_p - n_p}{sd_p}\\right\\}[i - q , p]\\nonumber\\\\ & = \\frac{1}{s}\\text{diag}\\left\\{\\frac{\\hat{n}_1}{d_1},\\ldots,\\frac{\\hat{n}_p}{d_p}\\right\\}[i - q , p ] \\label{eq : guarantee}\\end{aligned}\\ ] ]      let@xmath294&= i-\\frac{1}{s}\\text{diag}\\left\\{\\frac{\\hat{n}^*_1}{d^*_1},\\ldots,\\frac{\\hat{n}^*_p}{d^*_p}\\right\\}[i - q , p]\\\\ & = \\frac{1}{s}\\left(si-\\text{diag}\\left\\{\\frac{\\hat{n}^*_1}{d^*_1},\\ldots,\\frac{\\hat{n}^*_p}{d^*_p}\\right\\}[i - q , p]\\right)\\label{eq : xystar}\\end{aligned}\\ ] ] from the design process , if @xmath123 $ ] has a zero at @xmath295 , then it would be cancelled by designing @xmath193 .",
    "@xmath193 is not designed have a zero at @xmath295 unless it was used to cancel poles in @xmath295 of @xmath123 $ ] .",
    "then @xmath296=\\frac{1}{s}\\text{diag}\\left\\{\\frac{\\hat{n}^*_1}{d^*_1},\\ldots,\\frac{\\hat{n}^*_p}{d^*_p}\\right\\}[i - q , p]$ ] in which @xmath297 $ ] does not have a zero at @xmath295 .",
    "next , we show that @xmath298 $ ] does not have a zero at @xmath295 . otherwise , there would exist a @xmath299 such that @xmath300\\right)\\right\\vert_{s=0}=0\\\\ & \\left .",
    "\\rightarrow v^t\\left(\\left\\{\\text{diag}\\frac{\\hat{n}^*_1}{d^*_1},\\ldots,\\frac{\\hat{n}^*_p}{d^*_p}\\right\\}[i - q , p]\\right)\\right\\vert_{s=0}=0,\\end{aligned}\\ ] ] which would lead to @xmath297 $ ] having a zero at @xmath295 and a contradiction .",
    "then @xmath301 $ ] does not have any zero at @xmath295 , and therefore @xmath292 from a similar analysis using smith - mcmillan form .",
    "@xmath103      from eq .  , to show that @xmath301 $ ] has full normal rank , it is equivalent to show that @xmath302= si-\\text{diag}\\left\\{\\frac{\\hat{n}^*_1}{d^*_1},\\ldots,\\frac{\\hat{n}^*_p}{d^*_p}\\right\\}[i - q , p]$ ] has a full normal rank .",
    "since @xmath297 $ ] does not have a zero at @xmath295 , then it has full rank . at @xmath303",
    ", we have that @xmath304\\right)\\right\\vert_{s=0}=p.\\ ] ] hence , the normal rank of @xmath302=p$ ] .",
    "therefore , with @xmath193 defined in  ( [ eq : np ] ) , @xmath293 in eq .",
    "( [ eq : jj]).@xmath103    in summary , @xmath193 obtained in algorithm  [ alg : iqpzero ] minimises not only eq .   but also eq .  .",
    "this completes the proof of proposition  [ prop : convert ] since @xmath193 , @xmath292 and @xmath293 minimise eq .  ."
  ],
  "abstract_text": [
    "<S> motivated by the fact that transfer functions do not contain structural information about networks , dynamical structure functions were introduced to capture causal relationships between measured nodes in networks . from the dynamical structure functions , a ) we show that the actual number of hidden states can be larger than the number of hidden states estimated from the corresponding transfer function ; b ) we can obtain partial information about the true state - space equation , which can not in general be obtained from the transfer function . </S>",
    "<S> based on these properties , this paper proposes algorithms to find minimal realisations for a given dynamical structure function . </S>",
    "<S> this helps to estimate the minimal number of hidden states , to better understand the complexity of the network , and to identify potential targets for new measurements .     </S>",
    "<S> have been published in @xcite . </S>",
    "<S> ye yuan and jorge gonalves acknowledge the support from epsrc through ep / i03210x/1 , ep / g066477/1 . ]    ,    and    network reconstruction , linear system theory . </S>"
  ]
}