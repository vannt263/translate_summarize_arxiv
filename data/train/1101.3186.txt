{
  "article_text": [
    "since the @xmath0s , physicists have constructed particle colliders to study the building blocks of matter , where technological advances , as well as experimental discoveries , have resulted in the construction of bigger and more powerful accelerators . in most cases the next generation collider operates at a higher energy frontier or intensity than the previous one .",
    "this feature is displayed in figure  [ fig : history ] , which shows the last @xmath1 years in particle physics , where the clear trend to higher energies is visible in both hadron  hadron and @xmath2 colliders  @xcite .    at the end of the first decade of the @xmath3 century",
    ", the focus is firmly on the large hadron collider ( lhc ) at cern , which operates mainly as a @xmath4 collider , currently at a centre  of  mass energy of @xmath5  tev , where the first significant physics results are now emerging  @xcite . at the same time",
    ", a generation of other high energy physics ( hep ) experiments are concluding their data taking and winding up their physics programmes .",
    "these include h1 and zeus at the world s only @xmath6 collider hera ( data taking ended july @xmath7 ) , babar at the @xmath2 collider at slac ( ended april @xmath8 ) and the tevatron @xmath9 experiments d and cdf , who are now due to stop data taking in september @xmath10  @xcite .",
    "the belle experiment also recently concluded data taking at the kek @xmath2 collider , where upgrades are now ongoing until 2012  @xcite .",
    "the experimental data from these experiments still has much to tell us from the ongoing analyses that remain to be completed , but it may also contain things we do not yet know about .",
    "the scientific value of long term analysis was examined in a recent survey by the parse - insight project  @xcite , where around @xmath11 of over a thousand hep physicists regarded data preservation as very important or even crucial . moreover , the data from in particular the hera and tevatron experiments are unique in terms of the initial state particles and are unlikely to be superseded anytime soon , even considering such future projects as the lhec  @xcite .",
    "l18.5pc        it would therefore be prudent for such experiments to envisage some form of conservation of their respective data sets . however , hep has little or no tradition or clear current model of long term preservation of data in a meaningful and useful way .",
    "it is likely that the majority of older hep experiments have in fact simply lost the data : misplaced , accidentally deleted , or if still existing only in some unusable state .",
    "the preservation of and supported long term access to the data is generally not part of the planning , software design or budget of a hep experiment and for the few known preserved hep data examples , in general the exercise has not been a planned initiative by the collaboration but a push by knowledgeable people , usually at a later date .",
    "the distribution of the data complicates the task , with potential headaches arising from ageing hardware where the data themselves are stored , as well as from unmaintained and outdated software , which tends to be under the control of the ( defunct ) experiments rather than the associated hep computing centres .    to address this issue in a systematic way",
    ", a study group on data preservation and long term analysis in high energy physics , dphep , was formed at the end of @xmath8  @xcite .",
    "the aims of the study group include to confront the data models , clarify the concepts , set a common language , investigate the technical aspects , and to compare with other fields such as astrophysics and those handling large data sets .",
    "the experiments babar , belle , bes - iii , clas , cleo , cdf , d , h1 and zeus and the associated computing centres at desy ( germany ) , fermilab ( usa ) , ihep ( china ) , jlab ( usa ) , kek ( japan ) and slac ( usa ) are all represented in dphep .",
    "r17.0pc        a series of workshops  @xcite have taken place over the last two years , beginning at desy in january @xmath12 and most recently at kek in july @xmath13 .",
    "the study group is officially endorsed with a mandate by the international committee for future accelerators , icfa  @xcite and the first dphep recommendations were published in @xmath12 , summarising the initial findings and setting out future working directions  @xcite .",
    "the aims of the study group have also been presented to a wider physics audience via seminars , conferences and publications in periodicals  @xcite .",
    "the role of the dphep study group is to provide international coordination of data preservation efforts in high energy physics and to provide a set of recommendations for past , present and future hep experiments .    in the following ,",
    "the physics case for data preservation is examined , followed by the different models for data preservation identified by the study group .",
    "current inter - experimental data preservation initiatives are then presented , followed by some words on governance and structures , before finally concluding with an outlook and summary of future working directions .",
    "the motivation behind data preservation in hep should have its roots in physics .",
    "one of the main assumptions concerning experimental hep data is that older data will always be superseded by that from the next generation experiment , usually at the next energy frontier .",
    "however , this is not always the case as illustrated by the two following recent , notable examples of analysis of older hep data .",
    "the re - analysis of the jade experimental @xmath2 data from the petra collider ( desy , @xmath14@xmath15 ) , using a refined theoretical input , state of the art simulation and new anlaysis techniques has lead to a significant improvement in the determination of the strong coupling , in an energy range that is still unique  @xcite .",
    "the running of the strong coupling , in agreement with the qcd prediction demonstrates the concept of asymptotic freedom  @xcite , as illustrated in figure  [ fig : past ]  ( left ) , where the results from a similar analysis by the aleph experiment  @xcite are also shown .",
    "a search for the production and non  standard decay of a higgs boson in the lep collider data ( cern , @xmath16@xmath17 ) was recently published by the aleph collaboration  @xcite , where a possible four tau final state is investigated , resulting from the decays of two intermediate pseudoscalars produced via a next  to  minimal supersymmetric standard model ( nmssm ) higgs decay  @xcite .",
    "for such a model , and for a pseudoscalar mass @xmath18  gev , higgs masses @xmath19  gev are excluded at @xmath20 confidence level , as illustrated in figure  [ fig : past ]  ( right ) .",
    "examples of recently published analyses using older hep data . left : meaurements of the strong coupling , @xmath21 from an event shape analysis of jade data at various centre  of  mass energies , @xmath22 .",
    "the full and dashed lines indicate the result from the jade nnlo analysis  @xcite .",
    "the results from a recent nnlo analysis of aleph data are also shown  @xcite .",
    "right : observed and expected limits from aleph on the combined production cross section times branching ratio in the search for the process @xmath23 , as a function of higgs boson mass , @xmath24  @xcite . ]     examples of recently published analyses using older hep data . left : meaurements of the strong coupling , @xmath21 from an event shape analysis of jade data at various centre  of  mass energies , @xmath22 .",
    "the full and dashed lines indicate the result from the jade nnlo analysis  @xcite .",
    "the results from a recent nnlo analysis of aleph data are also shown  @xcite .",
    "right : observed and expected limits from aleph on the combined production cross section times branching ratio in the search for the process @xmath23 , as a function of higgs boson mass , @xmath24  @xcite . ]    as discussed in section  [ sec : intro ] , the @xmath6 data from the hera collider are themselves a unique achievement , and in many analyses the dominant error on the measurement is due to the current theoretical uncertainties .",
    "figure  [ fig : physcase ]  ( left ) shows a variety of @xmath25 measuements , as well as the current world average , where it can be seen that for the latest h1 measurements the theoretical uncertainty domainates the error . in a situation that mirrors the above jade analysis , it is hoped that at some point in the future a better theoretical prediction , including higher order corrections , will be available inviting the re  analysis of the accurate hera data .",
    "a similar situation arose recently with the extraction of the strong coupling using event shape variables by the opal collaboration , where higher order calculations triggered an improved analysis  @xcite .    the majority of the hadron ",
    "hadron particle physics performed at the tevatron will eventually be taken over by the lhc , as the amount of @xmath4 collision data at a higher centre  of  mass energy increases . however , the @xmath9 collision data taken by the tevatron experiments will still be more sensitive to the gluon parton density function ( pdf ) at high bjorken @xmath26 for some time , where the production cross section for central jets at high @xmath27 is substantially larger at the tevatron compared to at the lhc  @xcite .",
    "a comparison of inclusive jet production cross section predictions from the tevatron and the lhc is shown in figure  [ fig : physcase ]  ( right )  @xcite .",
    "examples of analyses of current hep data with potential future impact .",
    "left : recent determinations of the strong coupling @xmath25 from a variety of experiments compared to the @xmath12 world average  @xcite .",
    "right : a comparison of the predicted inclusive jet production cross sections at the tevatron and the lhc , as a function of @xmath28  @xcite .",
    "]     examples of analyses of current hep data with potential future impact .",
    "left : recent determinations of the strong coupling @xmath25 from a variety of experiments compared to the @xmath12 world average  @xcite .",
    "right : a comparison of the predicted inclusive jet production cross sections at the tevatron and the lhc , as a function of @xmath28  @xcite . ]",
    "another assumption is that the physics potential is exhausted at the end of the experimental programme .",
    "however , the available person power usually decreases rapidly towards the end of an experiment , which results in @xmath29@xmath30 of the publications being finalised at a later stage , when an archival mode of analysis is performed .",
    "this scenario is < true of the lep papers , where the publication timeline exhibits a long tail extending well beyond the end of data taking  @xcite .",
    "indeed , the above mentioned higgs analysis is part of this tail .",
    "interestingly , the predicted publication timescale for the remaining babar analyses also shows the same feature  @xcite .",
    "drawing on these examples , several scenarios exist where the preservation of experimental hep data would be of benefit to the particle physics community : an extension of the existing physics programme may be necessary to ensure the long term completion of ongoing analysis ; it may be favourable to re - do previous measurements to achieve an increased precision : reduced systematic errors may be possible via new and improved theoretical calculations ( mc models ) or newly developed analysis techniques ; preserving old data sets may allow the possiblility to make new measurements at energies and processes where no other data are available ( or will become available in the future ) ; finally , if new phenomena are found in new data at the lhc or some other future collider , it may be useful or even mandatory to go back , if possible , and verify such results using older data .",
    "the resurrection of the jade anlaysis chain to perform the analyses described above , carried out in the late @xmath31 s many years after the end of data taking , proved to be an eventful exercise and often a subject of luck rather than careful planning  @xcite .",
    "the general status of the lep data , which was recorded as recently as the year @xmath17 , is a concern , despite the continued paper output .",
    "a recent review of the status of the data of the four experiments identified that efforts are needed to ensure long term access  @xcite .",
    "the implementation of a data preservation model as early as possible in the lifetime of an experiment may greatly increase the likelihood of success , minimise the effort and ease the use of the data in the final years of the collaboration .    in order to identify different models of data preservation , first an important question",
    "must be asked : what is hep data ?",
    "the data themselves , the digital information in the event files and in databases , are only a small part of the complete picture : data preservation is not just about the data !",
    "indeed , discussions within the dphep study group suggest for pre  lhc experiments a total of between on half and a few pb of data should be preserved , such that today s computing centres are , at least by volume arguments , able to store the data s of tb of data per day , or up to @xmath32  pb per year . ] .",
    "in addition , the various software ( simulation , reconstruction , analysis , user ) must be considered .",
    "concerning documentation , publications of data analysis or detector studies may be in journals , on spires or arxiv , in hepdata or some other database , and may take the form of full papers , notes , manuals or slides .",
    "many types of internal meta - data may also exist .",
    "the unique expertise of collaboration members is also at risk , as the person power associated to the experiment decreases . by planning a transition of the collaboration structure to something more suited to an archival mode , this particular loss",
    "may be minimised ( see section [ sec : governance ] ) .",
    "the different data preservation models established by dphep are summarised in table  [ tab : models ] , organised in levels of increasing benefit , which comes with increasing complexity and cost .",
    "each level is associated with use cases , and the preservation model adopted by an experiment should reflect the level of analysis expected to be available in the future . more details on each of the preservation levels is given in the first dphep publication  @xcite .",
    ".[tab : models ] various data preservation models , listed in order of increasing complexity .",
    "subsequent models are inclusive : e.g. model 4 also includes the steps and use cases of models 1,2 and 3 . [ cols=\"<,<\",options=\"header \" , ]     past experiences with old hep data like those described in section  [ sec : physcase ] indicate that the definition of the data should include all the necessary ingredients to retrieve and understand it in order to perform new analyses and that a complete re ",
    "analysis is only possible when all the ingredients can be accounted for . only with the full flexibility",
    "does the full potential of the data remain , equivalent to the dphep level @xmath33 data preservation .",
    "accordingly , the majority of participating experiments in the study group plan for a level @xmath33 preservation programme , although different approaches are employed concerning how this goal can be achieved .",
    "although a level @xmath34 preservation model , to provide additonal documentation , is considered the simplest , this still requires some , often substantial , activity by the experiment .",
    "the hera collaborations , as well as babar , are all currently involved in dedicated efforts to safeguard and streamline the available documentation concerning their respective experiments .",
    "a level @xmath35 preservation , to the conserve the experimental data in simplfied format , is considered to be unsuitable for high level analysis , lacking the depth to allow , for example , detailed systematic studies to be performed .",
    "however , such a format is ideal of education and outreach purposes , which many experiments in the study group are also actively interested in ( see section [ sec : outreach ] ) .",
    "since the formation of dphep , and especially after the initial findings of the group were published , the activities and models of the experiments have aligned to a certain degree and joint initiatives have been launched , related to all four data preservation levels .",
    "these projects are described in the following .      for data preservation to be truely useful , not only the data themselves must be preserved , but also the ability to perform some kind of meaningful operation on them . in the case of hep , this means preserving the software and environment employed to analyse the data ( level @xmath36 preservation model ) , or if the reconstruction software is also included , a model where the data or monte carlo maybe reproduced ( level @xmath33 preservation model ) . while freezing the software in the current state is an option",
    ", experience has shown that this strategy would sustain analysis capability for only a limited amount of time , as well as introducing limitations by design . in order to preserve analysis capabilities for longer periods",
    "it would be beneficial to migrate to the latest software versions and technologies for as long as possible . given the pace of technological changes , concerning multi ",
    "core cpu design , changing storage models and system architechtures , as well the dependence on infrastructures such as the grid or clouds , and their associated protocols , this is a challenging prospect@xcite .",
    "it would therefore be beneficial to have a framework to automatically test and validate the software and data of an experiment against changes and upgrades to the environment , as well as changes to the experimental software .",
    "as such a framework would examine many facets common to several current hep experiments interested in a more complete data preservation model , the development of a generic validation suite is favourable . a test version of such a suite , which includes automated software build tools and data validation , is currently implemented at desy - it , in co - ooperation with the hera experiments@xcite . the scheme , which is illustrated in figure  [ fig : validation ] is realised using a virtual environment capable of hosting an arbitrary number of virtual machine images , where the inputs to the images are separated into three catagories : experimental software , external software and operating system .",
    "an image is built with different configurations of operating systems and the relevant software , and pre - defined tests are then performed to detect migration problems and incoherence , as well as identifying the reasons behind them .",
    "such a framework is by design expandable and able to host and validate the requirements from multiple experiments . a full version of the validation suite",
    "may now be implemented at desy - it , to safeguard the hera data for the long term .     a sketch of the proposed experimental software validation scheme at desy - it . ]      as well as the afforementioned individual documentation efforts , global information infrastructures in hep may be beneficial to the data preservation project . inspire  @xcite , the successor to spires , is an existing third - party information system for hep , and is thus ideally situated to provide external management of experimental documentation . as well as many overall improvements  @xcite with respect to the ageing spires system , the inspire project is preparing for the ingestion of much more high  level information in addition to the scientific papers themselves .",
    "these additions range from simple , documented information from the experiments about a given analysis , through wikis and news - forums , to even the data themselves , in a storage model where controlled access is possible . in a collaboration with the h1 experiment , inspire will trial a few projects such as the hosting of h1 internal notes , and the linking of paper histories to publication records .",
    "this idea enables the presentation of the full history of a scientific result , from the initial conference presentations and papers , through internal talks and notes , to a final submitted and refereed publication .",
    "another major advantage of such a scheme is that the responsibility of hosting the information passes from a defunct experiment to an active environment .",
    "an example of a new inspire publication record  @xcite is shown in figure  [ fig : inspire ] , where additional information would appear as an extra tab , which may , if desired , be only visible to collaboration members .",
    "there are clearly many possibilities for the experiments and inspire to work together , and more fruitful collaborations are expected via the dphep study group .      the development of a hep data format for outreach and education , equivalent to the dphep level @xmath35 data preservation model , is an attractive proposition . in most cases",
    "such a project would run in parallel to preserving the full re  analysis potential .",
    "in recent years there is a notably increased global effort to improve the overall level of education in particle physics and to provide access to hep to more people than ever before .",
    "websites such as _ teilchenwelt _  @xcite or _ quarknet _",
    "@xcite , as well as the _ lhc@home",
    "_ project  @xcite , help further the public understanding of science .",
    "tutorials using a simplified format of real hep data would be the next logical step , presented as hep data with associated pedagogical exercises .",
    "such a scheme has started within the babar collaboration  @xcite and following recent discussions within dphep about common data formats , a true , global hep data portal for outreach purposes seems possible .",
    "the belle collaboration also have an outreach programme , _ b  lab _ , aimed at high school students , which uses real experimental data  @xcite .",
    "the challenge of releasing such formats to the public domain is to provide useful open access of hep data beyond the walls of the original collaboration .",
    "there are however , many issues to consider , such as control of the data , correctness and reputation of the experiment , not to mention a lack of portability and the typical state of the documentation within the collaboration . the implications of open access need to be considered by the collaboration and the importance of a coherent strategy and presentation of the hep data when it is published must be emphasised .",
    "an example of the new record layout for papers in the inspire database  @xcite .",
    "an additional tab is foreseen for internal information , visible only to the author and/or collaboration . ]",
    "the transition to a data preservation model should be planned in advance of the projected end date of an experiment .",
    "an early preparation is needed and sufficient resources should be provided in order to maintain the capability to re - investigate such older data samples . however , the additional resources are estimated to be rather small in comparison to the person power allocated during the running period of an experiment .",
    "typically , a surge of @xmath35@xmath36 ftes for @xmath35@xmath36 years , followed by steady @xmath37@xmath38 fte per year per experiment is required for the implementation of a level @xmath36 or @xmath33 preservation model , which should be compared to @xmath39@xmath40 ftes per experiment for many years .",
    "therefore , the data preservation cost estimates represent typically much less than @xmath41 of the original investment , for a potential @xmath29@xmath30 increase in physics output .    the future structure of a collaboration should also be considered by hep experiments .",
    "if the transition to a long term analysis model is begun too late the experimental organisation also risks being left in an undefined state .",
    "in particular , the scientific supervision of the preserved data sets and decisions regarding authorship and access to data , affecting potential outreach projects , may benefit from a restructuring of the collaboration towards the final years .",
    "the presence and influence of dphep may facilitate this transition , as an interface to global hep solutions and as an aid to form common policy and standards .",
    "support for the dphep initiative has been expressed by cern , desy , fermilab , ihep and slac , as well as a variety of hep committees .",
    "the lightweight structure of dphep and its interfaces is illustrated in figure  [ fig : dphepstructure ] .",
    "representatives from the laboratories , the experiments and the computing centres , who are officially appointed by their organisations , are present , with one individual appointed by icfa to take chairmanship of the group .",
    "the organisation receives input from an advisory board , representing all stakeholders , and continues to ultimately report to icfa .",
    "the consolidation and continuation of the international cooperation within dphep is essential to the success and viability of the the data preservation effort .     a sketch describing the structure and interactions of the dphep study group . ]",
    "the collection of high energy physics data represents a significant investment and physics cases can be made to demonstate the potential for scientific results beyond the lifetime of a collaboration .",
    "however , until recently no coherent strategy existed regarding long term access of hep data and an international study group , dphep , was formed to address this issue in a systematic way . given the current experimental situation , data preservation efforts in hep are timely , and large laboratories should define and install data preservation projects in order to avoid catastrophic loss of data once major collaborations come to an end .",
    "the preservation of the full analysis capability of experiments , including the reconstruction and simulation software , is recommended in order to achieve a flexible and meaningful preservation model .",
    "such a project requires a strategy and well  identified resources , but provides additional research at particularly low cost , enhancing the return on the initial investment in the experimental facilities .",
    "the efforts of the group are best performed within the common organisation at the international level dphep , through which there is a unique opportunity to build a coherent structure for the future .",
    "common requirements on data preservation are now evolving via dphep into inter  experimental r&d projects , optimising the development effort and potentially improving the degree of standardisation in hep computing in the longer term .",
    "the next dphep workshop is at fermilab in may 2011 and a second publication is expected shortly from the group , describing the current projects in more detail and providing recommendations and guidelines for future hep experiments .",
    "99      a selection of lhc review talks available here : _ conference on lhc first data , ann arbor , december 2010 _ http://www.umich.edu/  mctp / lhc2010 , jan .",
    "11 2011 http://www.fnal.gov/pub/today/archive_2011/today11-01-11.html                  d.  m.  south 2009 data preservation and long term analysis in high energy physics _ proc .",
    "44th rencontres de moriond on qcd and high energy interactions ( la thuile ) _ eds  .",
    "aug _ et al_. ( hanoi : th gii ) p  415 ( _ preprint _",
    "arxiv:0907.1586 )        s.  bethke _ et al_. [ jade collaboration ] 2009 study of moments of event shapes and a determination of @xmath42 using @xmath2 annihilation data from jade _ eur .",
    "c * 60 * 181 ; erratum 2009 _ eur .",
    "c * 62 * 451 ( _ preprint _",
    "arxiv:0810.2933 ) s.  bethke _ et al_. [ jade collaboration ] 2009 determination of the strong coupling @xmath42 from hadronic event shapes and nnlo qcd predictions using jade data _ eur .",
    "phys . j. _",
    "c * 64 * 351 ( _ preprint _",
    "arxiv:0810.1389 )    d.  j.  gross , f.  wilczek 1973 ultraviolet behavior of nonabelian gauge theories _ phys .",
    "lett . _ * 30 * 1343 h.  d.  politzer 1973 reliable perturbative results for strong interactions ? _ phys .",
    "lett . _ * 30 * 1346    g.  dissertori _ et al_. 2008 first determination of the strong coupling constant using nnlo predictions for hadronic event shapes in @xmath2 annihilations",
    "_ j. high energy phys . _ * 0802 * 040 ( _ preprint _",
    "arxiv:0712.0327 )      r.  dermisek and j.  f.  gunion 2005 escaping the large fine tuning and little hierarchy problems in the next to minimal supersymmetric model and @xmath43 decays _ phys .",
    "lett . _ * 95 * 041801 ( _ preprint _ hep - ph/0502105 ) r.  dermisek and j.  f.  gunion 2007 the nmssm solution to the fine  tuning problem , precision electroweak constraints and the largest lep higgs event excess _ phys . rev .",
    "d _ * 76 * 095006 ( _ preprint _",
    "arxiv:0705.4387 )    r.  kogler 2010 jet production at low and high @xmath44 and determination of the strong coupling @xmath45 at h1 _ proc .",
    "18th international workshop on deep inelastic scattering and related subjects , dis 2010 ( florence ) _ _ preprint _",
    "m.  wobisch 2008 parton distributions from @xmath48 , @xmath49- and jet production at the tevatron , presented talk at _ physics at the terascale school on parton distribution functions ( desy - zeuthen )",
    "_ + https://indico.desy.de/conferencedisplay.py?confid=1031"
  ],
  "abstract_text": [
    "<S> data from high  energy physics ( hep ) experiments are collected with significant financial and human effort and are in many cases unique . at the same time </S>",
    "<S> , hep has no coherent strategy for data preservation and re  use , and many important and complex data sets are simply lost . in a period of a few years , several important and unique experimental programs will come to an end , including those at hera , the b  factories and at the tevatron . </S>",
    "<S> an inter - experimental study group on hep data preservation and long - term analysis ( dphep ) was formed and a series of workshops were held to investigate this issue in a systematic way . the physics case for data preservation and </S>",
    "<S> the preservation models established by the group are presented , as well as a description of the transverse global projects and strategies already in place . </S>"
  ]
}