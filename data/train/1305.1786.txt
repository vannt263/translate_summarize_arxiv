{
  "article_text": [
    "since the advent of compressed sensing ( cs ) almost 10 years ago  @xcite , many works have treated the problem of inserting this theory into an appropriate quantization scheme .",
    "this step is indeed mandatory for transmitting , storing and even processing any compressively acquired information , and more generally for sustaining the embedding of the cs principle in sensor design .    in its most popular version ,",
    "cs provides uniform theoretical guarantees for stably recovering any sparse ( or compressible ) signal at a sensing rate proportional to the signal intrinsic dimension ( _ i.e. _ , its _ sparsity _ level ) @xcite . in this context",
    ", scalar quantization of compressive measurements has been considered along two main directions .    first , under a high - resolution quantization assumption , _ i.e. _ ,",
    "when the number of bits allocated to encode each measurement is high , the quantization impact is often modeled as a mere additive gaussian noise whose variance is adjusted to the quantization @xmath0-distortion @xcite . in short , under this high - rate model , the cs stability guarantees under additive gaussian noise , _",
    "i.e. _ , as derived from the @xmath1 instance optimality  @xcite , are used to bound the reconstruction error obtained from quantized observations .",
    "variants of these works handle quantization saturation @xcite , prequantization noise @xcite , @xmath2-distortion models ( @xmath3 ) for improved reconstruction in oversampled regimes @xcite , optimize the high - resolution quantization procedure  @xcite or integrate more evolved @xmath4-quantization models departing from scalar pcm quantization  @xcite .",
    "second , and more recently , extreme 1-bit quantization recording only the sign of the compressive measurement , _",
    "i.e. _ , an information encoded in a single bit , has been considered  @xcite .",
    "new guarantees have been developed to tackle the non - linear nature of the sign operation thanks to the replacement of the _ restricted isometric property _ ( rip ) by the quasi - isometric _ binary @xmath5-stable embedding _",
    "( b@xmath5se )  @xcite , or to more general characterization of the binary embedding of sets based on their gaussian mean width  @xcite . in this context ,",
    "iterative methods such as the _ binary iterative hard thresholding _",
    "@xcite or linear programming optimization @xcite have been introduced for estimating the 1-bit sensed signal .",
    "this work proposes a general procedure for handling the reconstruction of sparse signals observed according to a standard non - uniform scalar quantization of the compressive measurements .",
    "the novelty of this scheme is its ability to handle any resolution level , from 1-bit to high - resolution , in a progressive fashion .",
    "conversely to the bayesian approach of  @xcite , our method relies on a generalization of the _ iterative hard thresholding _ ( iht ) @xcite that we simply called _ quantized iterative hard thresholding_. actually , qiht reduces to biht for 1-bit sensing and it converges to iht at high resolution .    [ [ conventions ] ] conventions + + + + + + + + + + +    most of domain dimensions ( _ e.g. _ , @xmath6 , @xmath7 ) are denoted by capital roman letters .",
    "vectors and matrices are associated to bold symbols while lowercase light letters are associated to scalar values .",
    "the @xmath8 component of a vector @xmath9 is @xmath10 or @xmath11 .",
    "the identity matrix is @xmath12 .",
    "the set of indices in @xmath13 is @xmath14=\\{1,\\,\\cdots , d\\}$ ] .",
    "scalar product between two vectors @xmath15 reads @xmath16 ( using the transposition @xmath17 ) , while the hadamard product @xmath18 is such that @xmath19 . for any @xmath20",
    ", @xmath21 represents the @xmath2-norm such that @xmath22 with @xmath23 and @xmath24 .",
    "the @xmath25 `` norm '' is @xmath26 , where @xmath27 is the cardinality operator and @xmath28 $ ] . for @xmath29",
    "$ ] , @xmath30 ( or @xmath31 ) denotes the vector ( resp .",
    "the matrix ) obtained by retaining the components ( resp .",
    "columns ) of @xmath32 ( resp .",
    "@xmath33 ) belonging to @xmath34 $ ] .",
    "the operator @xmath35 is the hard thresholding operator setting all the coefficients of a vector to 0 but those having the @xmath36 strongest amplitudes .",
    "the set of canonical @xmath36-sparse vectors in @xmath37 is @xmath38 while @xmath39 denotes the set of vectors whose support is @xmath40 $ ] .",
    "moreover , @xmath41 and @xmath42 with @xmath43 the @xmath44-sphere in @xmath37 .",
    "finally , @xmath45 is the characteristic function on @xmath46 , @xmath47 equals @xmath48 if @xmath49 is positive and @xmath50 otherwise , latexmath:[$(\\lambda)_+ = ( \\lambda +    @xmath49 on @xmath52 and @xmath53 , respectively , with all these operators being applied component wise onto vectors .",
    "the _ iterative hard thresholding _ ( iht ) algorithm has been introduced for iteratively reconstructing a sparse or compressible signal @xmath54 from compressible observations @xmath55 , where @xmath56 is the sensing matrix and @xmath57 stands for a possible observational noise with bounded energy @xmath58 .",
    "iht is an alternative to the _ basis pursuit denoise _ (",
    "bpdn ) method  @xcite which aims at solving a global convex minimization promoting a @xmath59-sparse data prior model under the constraint of reproducing the compressive observation .",
    "assuming that @xmath60 is @xmath36-sparse in the canonical basis @xmath61 , _",
    "i.e. _ , @xmath62 , the iht algorithm is designed to approximately solve the ( lasso - type ) problem@xmath63 it proceeds by computing the following recursion@xmath64,{\\vspace{0mm}}\\tag{\\footnotesize \\bf iht } \\end{aligned}\\ ] ] where @xmath65 , and @xmath66 must satisfy @xmath67 for guaranteeing convergence  @xcite .    in other words , at each iteration , starting from the previous estimation @xmath68 , the fidelity function @xmath69 is decreased by a gradient descent step with gradient @xmath70 , followed by a `` projection '' on @xmath71 accomplished by the hard thresholding @xmath35 .    in  @xcite",
    ", it is shown that if @xmath72 respects the _ restricted isometry property _ ( rip ) of order @xmath73 with radius @xmath74 , which means that for all @xmath75 , @xmath76 , then , at iteration @xmath77 , the reconstruction error satisfies @xmath78 .",
    "for the sake of simplicity , let us consider a unit @xmath36-sparse signal @xmath79 observed through the following quantized compressed sensing ( qcs ) model@xmath80,{\\vspace{0mm}}\\ ] ] where @xmath81 is the sensing matrix and @xmath82 the quantization operator defined at a _ resolution _ of @xmath83-bits per measurement , _",
    "i.e. _ , with no further encoding treatment , @xmath84 requires a total of @xmath85 bits . in this work",
    ", we will not consider any prequantization noise in .",
    "the quantization @xmath82 is assumed optimal with respect to the distribution of each component of @xmath86 . in particular , by considering only random gaussian matrices @xmath87 , _",
    "i.e. _ , where each matrix entry follows @xmath88 , we have @xmath89 and we adjust @xmath82 to an optimal @xmath83-bits gaussian quantizer minimizing the quantization distortion , _ e.g. _ , using a lloyd - max optimization  @xcite .",
    "this provides a set of thresholds @xmath90 ( with @xmath91 ) defining @xmath92 quantization bins @xmath93 , and a set of levels @xmath94 such that @xmath95 = { q}_k\\ \\leftrightarrow\\ \\lambda \\in { \\mathcal}r_k,{\\vspace{0mm}}\\ ] ] with @xmath96 and @xmath97 $ ] with @xmath98 .",
    "notice that this qcs model includes 1-bit cs scheme since @xmath99 = { q}_0\\,{{\\rm sign}\\,}(\\lambda)$ ] with @xmath100 .",
    "in this section , we propose a generalization of the iht algorithm taking into account the particular nature of the scalar quantization model introduced in sec .  [",
    "sec : framework ] .",
    "the idea is to enforce the consistency of the iterates with the quantized observations .",
    "this is first achieved by defining an appropriate cost measuring deviation from quantization consistency .",
    "given @xmath101 and using the levels and thresholds associated to @xmath82 , we first define@xmath102 with @xmath103 .",
    "equivalently , given @xmath104 $ ] , @xmath105 .",
    "the non - zero terms are therefore determined by the thresholds lying between @xmath49 and @xmath106 , _",
    "i.e. _ , for which @xmath107 .",
    "interestingly , @xmath108 since @xmath109 for all @xmath110 $ ] .",
    "then , our quantization consistency function between two vectors @xmath111 reads@xmath112    this cost , which is convex with respect to @xmath9 , has two interesting limit cases .",
    "first , for @xmath113 , it reduces to the cost on which relies the _ binary iterative hard thresholding _ algorithm ( biht ) adapted to 1-bit cs  @xcite . in this context",
    ", the sum in has only one term ( for @xmath114 ) and @xmath115 . up to a normalization by @xmath116 ,",
    "this is the @xmath59-sided norm minimized by biht which vanishes when @xmath117 , with @xmath118 defined in sec .",
    "[ sec : framework ] .     as a function of @xmath119 for @xmath120 ( @xmath121 ) and @xmath122 .",
    "( dashed curve ) plot of @xmath123.,title=\"fig : \" ] +    second , in the high resolution limit when @xmath124 , @xmath125 tends to @xmath126 .",
    "indeed , in this case @xmath127 and , the sum in tends to @xmath128 this asymptotic quadratic behavior of @xmath129 is illustrated in fig .",
    "[ fig : j - trend ] .    given the quantization consistency cost @xmath130",
    ", we can now formulate a generalization of for estimating a @xmath36-sparse signal @xmath131 observed by the model : @xmath132 with @xmath133)$ ] .",
    "following the procedure determining the iht algorithm from ( sec .",
    "[ sec : noisy - compr - sens ] ) , our aim is to find an iht variant which minimizes the quantization inconsistency , as measured by @xmath134 , instead of the quadratic cost @xmath135 .",
    "this is done by first determining a _ subgradient _ of the convex but non - smooth function @xmath134  @xcite .",
    "a quick calculation shows that a subdifferential of @xmath136 with respect to @xmath106 reads @xmath137 where @xmath138 , @xmath139 , and @xmath140 and @xmath141 are the bin indices of @xmath142 and @xmath143 respectively . from the definition of the @xmath144 , the sum simplifies to @xmath145 .",
    "therefore , a subgradient of @xmath146 with respect to @xmath9 reads simply @xmath147 , so that a subgradient of @xmath148 with respect to @xmath9 corresponds to @xmath149 .",
    "therefore , from this last ingredient , we define the _ quantized iterative hard thresholding algorithm _ ( qiht ) by the recursion @xmath150,\\tag{\\footnotesize \\bf qiht }   \\end{aligned}\\ ] ] where @xmath151 and @xmath152 is set hereafter .",
    "despite successful simulations of sparse signal recovery from quantized measurements ( see sec .  [",
    "sec : experiments ] ) , we were not able to prove the stability and the convergence of the qiht algorithm yet . however , there exist a certain number of promising properties suggesting the existence of such a result .",
    "the first one comes from a limit case analysis . except for the normalizing factor @xmath152 , qiht at 1-bit ( @xmath113 ) reduces to biht @xcite .",
    "moreover , when @xmath124 , @xmath153 \\simeq { \\boldsymbol}z$ ] for @xmath154 and we recover the iht algorithm .",
    "these limit cases are consistent with the previous observations made above on the asymptotic behaviors of @xmath130 in these two cases .",
    "second , as for the modified subspace pursuit algorithm  @xcite , qiht is designed for improving the quantization consistency of the current iterate with the quantized observations . for the moment",
    ", the importance of this improvement can only be understood in 1-bit .",
    "given @xmath155 , when @xmath156 and with high probability on the drawing of a random gaussian matrix @xmath87 , @xmath157 if @xmath158 for all @xmath159  @xcite .",
    "actually , it is shown in appendix  [ sec : angul - dist - bounds ] that if no more than @xmath160 components differ between @xmath161 and @xmath162 , then , with high probability on @xmath72 , @xmath163 for @xmath164 .",
    "we understand then the beneficial impact of any increase of consistency between @xmath165 and @xmath84 at each qiht iteration .",
    "third , the adjustment of @xmath152 , which is decisive for qiht efficiency , leads also to some interesting observations .",
    "extensive simulations not presented here pointed us that , for @xmath166 , @xmath167 seems to be a universal rule of efficiency at any bit rate .",
    "interestingly , this setting was already characterized for iht where @xmath168 if the sensing matrix respects the rip property with radius @xmath169  @xcite . since @xmath170 is rip for @xmath171 as soon as @xmath172",
    "this is equivalent to impose @xmath173 .    at the other extreme ,",
    "the rule @xmath174 is also consistent with the following 1-bit analysis . in @xcite",
    ", it is shown that the mapping @xmath175 respects an interesting property that we arbitrary call _ _ sign product embedding _ _ are studied . ]",
    "( spe ) :    [ def : bpe - def - unif ] given @xmath176 , there exist two constants @xmath177 such that , if @xmath178 , then , with a probability higher than @xmath179 , @xmath180 satisfies @xmath181 with @xmath182 .",
    "when @xmath9 is fixed , the condition on @xmath6 is relaxed to @xmath183 .    when @xmath72 respects , we simply write that @xmath72 is spe@xmath184 .",
    "when @xmath9 is fixed , we say that @xmath72 is locally spe@xmath184 on @xmath9 .",
    "this spe property leads to an interesting phenomenon .",
    "[ prop:1-bit - thresholding - guarantee - unif ] given @xmath185 and let @xmath186 be a matrix respecting the local spe@xmath187 on @xmath60 for some @xmath176 . then , given @xmath188 = { q}_0\\,{{\\rm sign}\\,}({\\boldsymbol}\\phi { \\boldsymbol}x)$ ] , the vector @xmath189 satisfies @xmath190 .",
    "let us define @xmath191 , @xmath192 , and @xmath193 with @xmath194 .",
    "then @xmath195 is also the best @xmath36-term approximation @xmath196 , so that @xmath197 .",
    "therefore , since @xmath198 and @xmath72 is spe@xmath187 , @xmath199 , using @xmath200 with @xmath201 .",
    "this proposition shows that a single hard thresholding of @xmath202 already provides a good estimation of @xmath60 . actually , from the condition on @xmath6 for reaching the local spe",
    ", we deduce that @xmath203 .",
    "this is quite satisfactory for such a simple @xmath60 estimation and it suggests setting @xmath174 in qiht for @xmath113 where @xmath195 is related to @xmath204 .",
    "noticeably , it has been recently observed in @xcite that @xmath205 is actually solution of @xmath206 for which there exists the weaker error bound @xmath207 when @xmath60 is fixed  @xcite .",
    "+    an extensive set of simulations has been designed for evaluating the efficiency of qiht in comparison with two other methods more suited to high - resolution quantization , namely , iht and bpdn .",
    "our objective is to show that qiht provides better quality results at least at small quantization levels .",
    "for all experiments , we set @xmath208 , @xmath209 and the @xmath36-sparse signals were generated by choosing their supports uniformly at random amongst the @xmath210 available ones , while their non - zero coefficients were drawn uniformly at random on the sphere @xmath211 . for each algorithm , @xmath212 initial such sparse vectors were generated and the reconstruction method was tested for @xmath213 and for @xmath214 , _",
    "i.e. _ , approximately fixing @xmath215 . for each experimental condition ,",
    "the quantized @xmath6-dimensional measurement vectors @xmath216 was generated as in with a random sensing matrix @xmath87 and according to an optimal lloyd - max @xmath83-bits quantizer @xmath82 ( sec .",
    "[ sec : framework ] ) .",
    "iht and qiht iterations were both stopped at step @xmath217 as soon as @xmath218 or if @xmath219 .",
    "the bpdn algorithm was solved with the spgl1 matlab toolbox  @xcite . in iht and qiht ,",
    "signal sparsity @xmath36 was assumed known and both were set with @xmath220 .",
    "this fits the iht condition @xmath221 mentioned in sec .",
    "[ sec : qiht - analysis ] by assuming that the rip radius @xmath169 behaves like @xmath222 , which is a common assumption in cs .",
    "for bpdn , the noise energy was given by an oracle installing bpdn in the best reconstruction scenario , _",
    "i.e. _ , @xmath223 .",
    "whatever the reconstruction method , given an initial signal @xmath224 and its reconstruction @xmath225 , the reconstruction quality was measured by @xmath226 .",
    "in other words , we focus here on a good `` angular '' estimation of the signals , adopting therefore a common metric for @xmath227 and for @xmath113 , where amplitude information is lost .",
    "finally , for each method and each couple of @xmath228 , the snr was averaged over the 100 test signals and expressed in db .",
    "[ fig : qiht_iht_bpdn_comp ] gathers the snr performances of the 3 methods as a function of @xmath229 .",
    "qiht outperforms both bpdn and iht for the selected scenarios , especially for low bit quantizers . at high resolution ,",
    "the gain between qiht and iht decreases as expected from the limit case analysis of qiht .",
    "we can also notice that , first , there is almost no quality difference between qiht at @xmath113 and @xmath230 .",
    "this could be due to a non - optimality of the lloyd - max quantizer with respect to qiht reconstruction error minimization .",
    "second , bpdn and iht asymptotically present the `` @xmath231db per bit '' gain , while qiht hardly exhibits such behavior only when @xmath232 .    finally , in order to test prop .",
    "[ prop:1-bit - thresholding - guarantee - unif ] , the snr reached by the single thresholding solution @xmath195 is plotted in dashed in fig  [ fig : qiht_iht_bpdn_comp]-right . despite its poor behavior",
    "compared to qiht at @xmath113 , it outperforms bpdn at high @xmath233 with a @xmath234db at @xmath235 .",
    "a curve fitting ( no shown here ) shows that this snr increases a bit faster than @xmath236 .",
    "we have introduced the qiht algorithm as a generalization of the biht and iht algorithms aiming at enforcing consistency with quantized observations at any bit resolution . in particular",
    ", we showed that the almost obvious inclusion of the quantization operator in the iht recursion is actually related to the implicit minimization of a particular inconsistency cost @xmath134 .",
    "this function generalizes the one - sided @xmath59 cost of biht and asymptotically converges to the quadratic fidelity minimized by iht .",
    "there is still a hard work to be performed in order to prove qiht convergence and stability .",
    "however , the different ingredients defining it , as @xmath134 , deserve independent analysis extending previous @xmath48-bit embeddings developed in  @xcite .",
    "the relation is induced by the following theorem and by its subsequent corollary  [ cor : angul - bounds - almost ] .",
    "these use the normalized _ hamming distance _ between two strings @xmath237 defined by @xmath238 , where @xmath239 is the xor operation such that @xmath240 equals 0 if @xmath241 and 1 otherwise . for shortening the notations , we define also @xmath242 for @xmath243 .        first ,",
    "notice that if @xmath250 , there exists a @xmath251 $ ] with @xmath252 such that @xmath253 .",
    "let @xmath254_r$ ] be the set of subsets of @xmath254 $ ] whose size is bigger than @xmath255 . using a union bound argument , we have @xmath256_r,\\ \\exists\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}a ) =   { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}b),\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\| > \\delta\\ \\big]\\nonumber \\\\    & \\leq \\bigcup_{{\\mathcal}t\\subset [ m]_r } \\mathbb p\\big[\\ \\exists\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}a ) =   { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}b),\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\| > \\delta\\ \\big ] .",
    "\\label{eq : un - bound - anysubset}\\end{aligned}\\ ] ] we know from ( * ? ? ?",
    "* theorem 2 ) that , as soon as @xmath257 the random generation of @xmath258 fullfils @xmath259\\ \\leq\\ \\eta,\\ ] ] with @xmath260 . therefore , for a given @xmath261_r$ ] and by setting @xmath262 , _",
    "i.e. _ , the matrix obtained by restricting @xmath72 to the rows indexed in @xmath263 , we have @xmath264 , @xmath265 and @xmath266 \\leq \\eta\\ ] ] if @xmath267 .    under the same condition on @xmath6 , and observing that , for @xmath268 ,",
    "@xmath269_r| = \\sum_{k=0}^r { m \\choose m - k } \\leq ( r+1 ) { m \\choose    r}\\leq ( r+1 ) ( e m / r)^r$ ] , provides @xmath270_r,\\ \\exists\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}a ) =   { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}b),\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\| > \\delta\\ \\big ] \\leq ( r+1 ) ( \\tfrac{e m}{r})^r\\,\\eta.\\ ] ]    analyzing the complementary event and redefining @xmath271 , we get finally @xmath272\\\\ & = \\ \\mathbb",
    "p\\big[\\ \\forall\\ , { \\mathcal}t\\subset [ m]_r,\\ \\forall\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}a ) =   { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}b),\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\|\\leq \\delta\\ \\big ] \\geq 1 - \\eta,\\end{aligned}\\ ] ] as soon as @xmath273    0 in @xcite , theorem 2 shows that the random generation of @xmath87 fullfils @xmath274\\ \\geq\\ 1-\\eta\\ ] ] as soon as @xmath275 therefore , for any given @xmath261 $ ] , we have @xmath276\\\\ & \\leq\\ \\mathbb p\\big[\\ \\exists\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\|\\leq \\delta,\\   \\exists\\,i\\in [ m]:\\   \\varphi_i({\\boldsymbol}a ) = \\varphi_i({\\boldsymbol}b)\\big ]    \\leq\\ \\eta.\\end{aligned}\\ ] ] let @xmath254_r$ ] be the set of subsets of @xmath254 $ ] whose size is bigger than @xmath255 . since , for @xmath268 , @xmath269_r| = \\sum_{k=0}^r { m \\choose m - k } \\leq ( r+1 ) { m \\choose    r}\\leq ( r+1 ) ( e m / r)^r$ ] , a union bound provides @xmath270_r,\\ \\exists\\ , { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\|\\leq \\delta,\\   \\exists\\,i\\in { \\mathcal}t:\\   \\varphi_i({\\boldsymbol}a ) = \\varphi_i({\\boldsymbol}b)\\ \\big ]   \\leq ( r+1 ) ( \\tfrac{em}{r})^r\\eta,\\ ] ] under the same condition on @xmath6 . analyzing the complementary event and simplifying slightly the condition",
    ", we get @xmath277_r,\\ \\forall { \\boldsymbol}a , { \\boldsymbol}b\\in\\sigma^*_k:\\ { \\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}a)={\\boldsymbol}\\varphi_{{\\mathcal}t}({\\boldsymbol}b)\\ \\rightarrow\\ \\|{\\boldsymbol}a-{\\boldsymbol}b\\|\\leq \\delta\\ \\big ] \\leq 1 - \\eta,\\end{aligned}\\ ] ] as soon as @xmath278 since for any @xmath279 such that @xmath280 , there exists one set @xmath281 $ ] such that @xmath282 , the result follows ."
  ],
  "abstract_text": [
    "<S> in this work , we show that reconstructing a sparse signal from quantized compressive measurement can be achieved in an unified formalism whatever the ( scalar ) quantization resolution , _ </S>",
    "<S> i.e. _ , from 1-bit to high resolution assumption . </S>",
    "<S> this is achieved by generalizing the _ iterative hard thresholding _ ( iht ) algorithm and its binary variant ( biht ) introduced in previous works to enforce the consistency of the reconstructed signal with respect to the quantization model . the performance of this algorithm , simply called _ quantized _ iht ( qiht ) , is evaluated in comparison with other approaches ( _ e.g. _ , iht , _ basis pursuit denoise _ ) for several quantization scenarios . </S>"
  ]
}