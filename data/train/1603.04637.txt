{
  "article_text": [
    "many applications deal with multivariate functions @xmath9 which are smooth in the sense that certain weak derivatives @xmath10 exist and are square - integrable , functions from a",
    "_ sobolev space_.    which derivatives @xmath10 of @xmath9 are known to be existent and square - integrable highly depends on the actual problem .",
    "classically , @xmath11 covers the range of all vectors in @xmath12 with @xmath13 for some @xmath14 .",
    "the corresponding sobolev space is called _ isotropic sobolev space of smoothness @xmath14_. for instance , the solutions of elliptic partial differential equations in general and poisson s equation in particular , have this form . they typically appear in electrostatics or continuum mechanics .    but often @xmath9 is known to satisfy a stronger smoothness condition : derivatives @xmath10 for each @xmath15 with @xmath16 exist and are square - integrable .",
    "this is typically the case , if @xmath9 is a tensor product of @xmath17-times differentiable functions of one variable : @xmath18 .",
    "we say that @xmath9 is from a _ sobolev space of dominating mixed smoothness @xmath17_. for example , solutions of the electronic schrdinger equation are of this form .",
    "+ we are concerned with the numerical integration of such functions and refer to @xcite and @xcite for a treatise on elliptic partial differential equations and their connection with sobolev spaces and to @xcite for further information about electronic wave functions .",
    "more precisely , we want to use linear quadrature rules to approximate the integral @xmath19 of integrable , real valued functions @xmath9 in @xmath2 real variables , with a particular interest in functions with dominating mixed smoothness @xmath17 .",
    "a linear _ quadrature rule _ , _ algorithm _ or _",
    "@xmath20 is given by a finite number @xmath4 of weights @xmath21 and nodes @xmath22 , and the rule @xmath23 all these numbers and vectors can be deterministic or random variables . since @xmath4 counts the number of function values computed by @xmath20 , it is a measure for the cost of @xmath20 , commonly referred to as _ information cost _ of the algorithm .",
    "the error of @xmath20 associated with the integration of @xmath9 is @xmath24 .",
    "we are interested in sequences @xmath25 of quadrature rules whose error decreases fast with respect to growing information cost @xmath4 . in this sense ,",
    "numerical integration of functions with dominating mixed smoothness @xmath17 is significantly easier than the integration of functions with isotropic smoothness @xmath17 , especially if the number @xmath2 of variables is large : it turns out that the convergence order @xmath26 can be achieved for the expected error , while @xmath27 is the best possible rate in the isotropic case . + from now on , for the sake of distinction , we will use @xmath17 as a parameter for isotropic smoothness and @xmath28 as a parameter for dominating mixed smoothness .",
    "the smoothness parameters @xmath28 and @xmath17 and the dimension @xmath2 are arbitrary natural numbers , with the single condition that @xmath8 .",
    "but they are considered to be fixed in the sense that any constant in this thesis is merely a constant with respect to the information cost @xmath4 and may depend on @xmath29 and @xmath2 .",
    "+ let us end this introductory section with an outline of the thesis .",
    "we start with a brief compilation of the definitions and fundamental properties of the above mentioned sobolev spaces . in section  [ basicquadrulesection ]",
    ", we will present a familiy of deterministic quadrature rules for the integration of compactly supported , continuous functions . among those rules",
    "is frolov s algorithm , which will be examined in section [ frolovsrulesection ] . with respect to the information cost @xmath4",
    ", its integration error for functions @xmath9 with dominating mixed smoothness @xmath28 and compact support in the open unit cube @xmath30 is bounded above by a constant multiple of @xmath3 times the corresponding norm of @xmath9 .",
    "the order @xmath3 is optimal . for functions with support in @xmath30 and isotropic smoothness",
    "@xmath17 the order @xmath31 is achieved , which is also optimal .    in section  [ randomdilationsection ]",
    ", we will add random dilations to frolov s algorithm and examine the integration error of the resulting algorithm for the same types of functions .",
    "we will see that in both cases the random dilations improve the order of the algorithm s error by @xmath32 in expectation , while not changing it in the worst case .",
    "the additional random shift introduced in section [ randomshiftsection ] makes the algorithm unbiased and , in case of functions with dominating mixed smoothness @xmath28 and compact support in @xmath30 , further improves the order of its expected error by a logarithmic term .",
    "section [ transformationsection ] shows that the condition of having support in @xmath30 can be dropped by applying a suitable change of variables to the above algorithms .",
    "the resulting algorithms satisfy the error bounds from above for any function on @xmath33^d$ ] with dominating mixed smoothness @xmath28 or isotropic smoothness @xmath17 . beyond that",
    ", the change of variables preserves unbiasedness .",
    "for natural numbers @xmath28 and @xmath2 the sobolev space @xmath34 of dominating mixed smoothness @xmath28 is the real vector space @xmath35 of @xmath2-variate , real valued functions , equipped with the scalar product @xmath36 the scalar product induces the norm @xmath37    it is known that @xmath34 is a hilbert space and its elements can be considered to be continuous functions . in this thesis , the fourier transform is the unique continuous linear operator @xmath38 satisfying @xmath39 for integrable @xmath40 and @xmath41 .",
    "the space @xmath34 contains exactly those functions @xmath42 with @xmath43 for the fourier transform @xmath44 of @xmath9 and the weight function @xmath45 in terms of its fourier transform , the norm of @xmath46 is given by @xmath47    analogously , the isotropic sobolev space @xmath48 of smoothness @xmath14 is @xmath49 equipped with the scalar product @xmath50 and its induced norm @xmath51 .",
    "for @xmath15 , we will frequently use the abbreviation @xmath52 .",
    "the space @xmath48 is a hilbert space , too . in the following",
    ", we will assume that @xmath17 is greater than @xmath53 .",
    "then @xmath48 also consists of continuous functions , exactly those functions @xmath42 with @xmath54 for the fourier transform @xmath44 of @xmath9 and the weight function @xmath55 in terms of its fourier transform , the norm of @xmath56 is given by @xmath57    furthermore , let @xmath58 be the real vector space of all continuous real valued functions with compact support in @xmath59 .",
    "the spaces @xmath60^d)}}$ ] and @xmath61^d)}}$ ] of functions in @xmath34 or @xmath48 with compact support in the unit cube are subspaces of @xmath58 .",
    "they can also be considered as subspaces of the hilbert space @xmath62^d)}}}= { \\left\\{f\\in l^2([0,1]^d ) \\mid { d}^\\alpha   f \\in",
    "l^2([0,1]^d ) \\text { for every } \\alpha \\in { \\left\\{0,\\dots , r\\right\\}}^d\\right\\ } } , \\ ] ] equipped with the scalar product @xmath63^d)}}}= \\sum\\limits_{\\alpha \\in { \\left\\{0,\\dots , r\\right\\}}^d }   { \\left\\langle{d}^\\alpha f,{d}^\\alpha g\\right\\rangle_{l^2([0,1]^d ) } }   , \\ ] ] or the hilbert space @xmath64^d)}}}= { \\left\\{f\\in l^2([0,1]^d )   \\mid { d}^\\alpha f \\in l^2([0,1]^d ) \\text { for } \\alpha   \\in { \\ensuremath{\\mathbb{n}}}_0^d\\text { with } { \\left|\\alpha\\right|}\\leq s\\right\\ } } , \\ ] ] with the scalar product @xmath65^d)}}}= \\sum\\limits_{{\\left|\\alpha\\right|}\\leq s }   { \\left\\langle{d}^\\alpha f,{d}^\\alpha g\\right\\rangle_{l^2([0,1]^d ) } }   .\\ ] ]",
    "we introduce a family of deterministic and linear quadrature rules .",
    "this family is fundamental to our studies .",
    "all the algorithms to be presented are based on the following definition",
    ".    * algorithm .",
    "* let @xmath66 be invertible and @xmath67 be a vector in @xmath59 .",
    "we define @xmath68 for any admissible input function @xmath69 .",
    "we call @xmath67 _ shift parameter _ and denote by @xmath70 the algorithm @xmath71 for shift parameter @xmath72 .",
    "the matrix @xmath73 is the transpose of the inverse of @xmath74 . for now",
    ", @xmath74 can be any invertible matrix .",
    "but later on , it will be a fixed matrix @xmath75 multiplied with a number @xmath76 and a _ dilation matrix _",
    "@xmath77 for a _ dilation parameter _ @xmath78 .",
    "the dilation parameter @xmath78 and shift parameter @xmath79 are also arbitrary .",
    "as we go along , they will be chosen as independent random variables @xmath80 and @xmath81 that are uniformly distributed in @xmath82^d$ ] and @xmath33^d$ ] , respectively .",
    "+ the rule @xmath71 adds up the values of @xmath9 at the lattice points @xmath83 , @xmath84 , in the corner of each parallelepiped @xmath85^d\\right)}\\right)}$ ] weighted with the volume @xmath86 of this parallelepiped .",
    "the value @xmath87 hence can be thought of as a riemann sum of @xmath9 over @xmath59 with respect to the partition @xmath88^d\\right)}\\mid m\\in{\\ensuremath{\\mathbb{z}}}^d\\right\\}}$ ] .",
    "+ admissible input functions are , for instance , functions @xmath9 with compact support . for such functions",
    "the above sum is a finite sum . to integrate @xmath9 , the algorithm @xmath71 uses the nodes @xmath89 , where @xmath84 is a lattice point in the compact set @xmath90 of volume @xmath91 . here",
    ", @xmath92 is the lebesgue measure in @xmath59 .",
    "the indicated volume is the approximate number of function values computed by @xmath71 . in particular , the number of nodes of @xmath93 for growing @xmath94 is of order @xmath95 .",
    "the following simple lemma gives an exact upper bound , see  @xcite for other bounds .",
    "[ anlemma ] suppose @xmath96 is supported in an axis - parallel cube of edge length @xmath97 .",
    "for any invertible matrix @xmath66 , @xmath79 and @xmath94 the quadrature rule @xmath93 uses at most @xmath98 function values of @xmath9 .    by assumption , @xmath9 has compact support in @xmath99^d+x_0 $ ] for some @xmath100 .",
    "the number of computed function values is the number of points @xmath84 for which @xmath101 is in @xmath102 and hence bounded by the size of @xmath103^d+x_0\\right\\}}\\\\ & = { \\left\\{m\\in{\\ensuremath{\\mathbb{z}}}^d \\mid m+\\left(v - as^\\top x_0\\right)\\in \\frac{al}{2}\\cdot s^\\top [ -1,1]^d\\right\\ } } .\\end{split}\\ ] ] since @xmath104 for @xmath105^d$ ] , @xmath106^d\\right\\}}\\ ] ] and @xmath107 . with @xmath108",
    "we get the estimate of lemma  [ anlemma ] .",
    "the error of this algorithm for integration on @xmath58 can be expressed in terms of the fourier transform .",
    "[ errorlemma ] for any invertible matrix @xmath66 , @xmath79 and @xmath109 @xmath110    the function @xmath111 is continuous with compact support .",
    "hence , the poisson summation formula and an affine linear substitution @xmath112 yield @xmath113 if the latter series converges absolutely , see @xcite .",
    "if not , the stated inequality is obvious .",
    "this proves the statement , since @xmath114 .",
    "it is known how to choose the matrix @xmath74 in the rule @xmath71 to get a good deterministic quadrature rule on @xmath60^d)}}$ ] .",
    "let the matrix @xmath115 satisfy the following three conditions :    * @xmath75 is invertible , * @xmath116 , for any @xmath117 , * for any @xmath118 the box @xmath119 $ ] with volume @xmath120 contains at most @xmath121 lattice points @xmath122 , @xmath84 ,    where @xmath119={\\left\\{z\\in{\\ensuremath{\\mathbb{r}}}^d\\mid z_j   \\text { is inbetween of } x_j\\text { and } y_j\\text { for } j=1,\\dots , d\\right\\}}$ ] .",
    "such a matrix shall be called a _",
    "frolov matrix_. property ( b ) says that for @xmath123 every point of the lattice @xmath124 but zero lies in the set @xmath125 of all vectors @xmath126 with @xmath127 , the complement of a hyperbolic cross .",
    "this graphic shows the lattice @xmath124 for @xmath128 , @xmath129 and the frolov matrix @xmath130 except zero , every lattice point lies inside @xmath131 .",
    "it is known that one can construct such a matrix @xmath75 in the following way .",
    "let @xmath132 $ ] be a polynomial of degree @xmath2 with leading coefficient 1 which is irreducible over @xmath133 and has @xmath2 different real roots @xmath134",
    ". then the matrix @xmath135 has the desired properties , as shown in @xcite and @xcite . in arbitrary dimension",
    "@xmath2 we can choose @xmath136 , see @xcite or @xcite , but there are many other possible choices . for example , if @xmath2 is a power of two , we can set @xmath137 , where @xmath138 is the chebyshev polynomial of degree @xmath2 , see @xcite",
    ". then the roots of @xmath139 are explicitly given by @xmath140 for @xmath141 .",
    "+ from now on , let @xmath75 be an arbitrary but fixed , @xmath2-dimensional frolov matrix .",
    "constants may depend on the choice of @xmath75 .",
    "* algorithm . * for any natural number @xmath4 , we consider the quadrature rule @xmath142 from section [ basicquadrulesection ] with shift parameter zero .",
    "this deterministic algorithm is usually referred to as _",
    "algorithm_.    for input functions @xmath9 with support in @xmath33^d$ ] the number of function values computed by @xmath143 is of order @xmath4 . to be precise ,",
    "lemma [ anlemma ] says that @xmath143 uses at most @xmath144 function values of @xmath9 .",
    "k.k.frolov has already seen in 1976 that the algorithm @xmath143 is optimal on @xmath60^d)}}$ ] in the sense of order of convergence .",
    "it satisfies the following error bound .",
    "[ frolovboundtheorem ] there is some @xmath145 such that for every @xmath146 and @xmath147^d)}}$ ] @xmath148^d ) } } } .\\ ] ]    see also @xcite and @xcite or my bachelor thesis for a proof of this error bound and its optimality .",
    "in fact , this error bound holds uniformly for @xmath149 for any @xmath150^d$ ] and @xmath151^d$ ] , which is the statement of theorem  [ mixthmworstcase ] in section  [ randomdilationsection1 ] .",
    "theorem [ frolovboundtheorem ] is only a special case . + but frolov s algorithm is also optimal among deterministic quadrature rules on @xmath61^d)}}$ ] in the sense of order of convergence .",
    "it satisfies :    [ frolovboundisotheorem ] there is some @xmath145 such that for every @xmath146 and @xmath152^d)}}$ ] @xmath153^d ) } } .\\ ] ]    this is a special case of theorem  [ isothmworstcase ] in section  [ randomdilationsection1 ] .",
    "see @xcite for a proof of the optimality of this order .",
    "we study the impact of random dilations on frolov s algorithm @xmath143 .    * algorithm . * for any natural number @xmath4 and shift parameter @xmath79 we consider the method @xmath154 from section [ basicquadrulesection ] with a dilation parameter @xmath80 that is uniformly distributed in the box @xmath82^d$ ] .    for input functions @xmath9 from @xmath61^d)}}$ ] or @xmath60^d)}}$ ]",
    "the information cost of @xmath154 is roughly between @xmath155 and @xmath156 .",
    "more precisely , it uses at most @xmath157 function values of @xmath9 . +      in the worst case , the error of this method has the same order of convergence like frolov s algorithm , both for @xmath60^d)}}$ ] and @xmath61^d)}}$ ] .",
    "[ mixthmworstcase ] there is a constant @xmath145 such that for any shift parameter @xmath79 , @xmath146 and @xmath147^d)}}$ ] @xmath158^d } { \\left|q_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } \\leq\\ , c \\ ,   n^{-r }   \\ , ( \\log n)^\\frac{d-1}{2 } \\ , { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d ) } } } .\\end{split}\\ ] ]    let @xmath149 be an arbitrary realization of the algorithm @xmath154 under consideration . by lemma  [ errorlemma ] and hlder s inequality , @xmath159",
    "we first prove that the first factor in this product is bounded above by a constant multiple of @xmath160 .",
    "+ consider the auxiliary set @xmath161 for @xmath162 and @xmath163 .",
    "the domain @xmath164 of summation is the disjoint union of all @xmath165 over @xmath162 .",
    "+ for @xmath166 , the points @xmath167 in @xmath168 satisfy @xmath169 .",
    "but the second property of the frolov matrix @xmath75 yields @xmath170 for any @xmath117 . hence , @xmath165 is empty for @xmath166 . for @xmath171 ,",
    "any @xmath172 satisfies @xmath173 and hence @xmath174 .",
    "because of the third property of the frolov matrix , we obtain @xmath175 that yields @xmath176 this is the desired estimate , since @xmath177 .",
    "+ we now show that the second factor in the above inequality is bounded above by a constant multiple of @xmath178^d)}}}^2 $ ] .",
    "this proves the theorem .    for @xmath126",
    "we have @xmath179 the function @xmath180 has compact support in the parallelepiped @xmath181^d$ ] .",
    "consider the set @xmath182 of all @xmath183 for which @xmath184^d\\right)}$ ] has a nonempty intersection with @xmath181^d$ ] .",
    "then @xmath185^d\\right)}\\right|^2\\\\ & \\leq \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 } \\sum\\limits_{k\\in j_n }   \\left|\\langle g_\\alpha , e^{2\\pi i\\langle m,\\cdot \\rangle}\\rangle_{l^2\\left(k+[0,1]^d\\right)}\\right|^2 .\\end{split}\\ ] ] thus we obtain @xmath186^d\\right)}\\right|^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 } \\sum\\limits_{\\alpha\\in{\\left\\{0,\\dots , r\\right\\}}^d }   \\sum\\limits_{k\\in j_n } \\vert g_\\alpha\\vert_{l^2\\left(k+[0,1]^d\\right)}^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 }   \\sum\\limits_{\\alpha\\in{\\left\\{0,\\dots , r\\right\\}}^d } { \\left\\vertg_\\alpha\\right\\vert_{l^2({\\ensuremath{\\mathbb{r}}}^d)}}^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right| } } \\sum\\limits_{\\alpha\\in{\\left\\{0,\\dots , r\\right\\}}^d }   { \\left\\vertd^\\alpha f\\right\\vert_{l^2({\\ensuremath{\\mathbb{r}}}^d)}}^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right| } } { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d)}}}^2 .\\end{split}\\ ] ] since both @xmath187 and @xmath188 are of order @xmath4 , their ratio is bounded by a constant and the above inequality yields the statement .    [ isothmworstcase ] there is a constant @xmath145 such that for any shift parameter @xmath79 , @xmath189 and @xmath152^d)}}$ ] @xmath158^d } { \\left|q_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } \\leq\\ , c \\",
    ",   n^{-s / d } \\ , { \\left\\vertf\\right\\vert_{{h^s}([0,1]^d ) } } .\\end{split}\\ ] ]    let @xmath149 be an arbitrary realization of the algorithm @xmath154 under consideration . by lemma  [ errorlemma ] and hlder s inequality , @xmath190 the first factor in this product is bounded above by a constant multiple of @xmath191 : since @xmath192 we have @xmath193 where this last series converges for @xmath194 .",
    "we show that the second factor in the above inequality is bounded above by a constant multiple of @xmath195^d)}}^2 $ ] .",
    "this proves the theorem .    for any @xmath126 we have",
    "@xmath196    the function @xmath180 has compact support in the parallelepiped @xmath181^d$ ] . again consider the set @xmath182 of all @xmath183 for which @xmath184^d\\right)}$ ] has a nonempty intersection with @xmath181^d$ ] .",
    "+ we have the estimate @xmath197^d\\right)}\\right|^2\\\\ & \\leq \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 } \\sum\\limits_{k\\in j_n }   \\left|\\langle g_\\alpha , e^{2\\pi i\\langle m,\\cdot \\rangle}\\rangle_{l^2\\left(k+[0,1]^d\\right)}\\right|^2 .\\end{split}\\ ] ] thus we obtain @xmath198^d\\right)}\\right|^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 } \\sum\\limits_{{\\left|\\alpha\\right| } \\leq s}\\ , \\sum\\limits_{k\\in j_n } \\vert g_\\alpha\\vert_{l^2\\left(k+[0,1]^d\\right)}^2 = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right|}^2 } \\sum\\limits_{{\\left|\\alpha\\right| } \\leq s }   { \\left\\vertg_\\alpha\\right\\vert_{l^2({\\ensuremath{\\mathbb{r}}}^d)}}^2\\\\ & = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right| } } \\sum\\limits_{{\\left|\\alpha\\right| } \\leq s }   { \\left\\vertd^\\alpha f\\right\\vert_{l^2({\\ensuremath{\\mathbb{r}}}^d)}}^2 = \\frac{{\\left|j_n\\right|}}{{\\left|\\det(n^{1/d}\\hat{u}b)\\right| } } { \\left\\vertf\\right\\vert_{{h^s}([0,1]^d)}}^2 .\\end{split}\\ ] ] since both @xmath187 and @xmath188 are of order @xmath4 , their ratio is bounded by a constant and the above inequality yields the statement .      in expectation ,",
    "the random dilations improve the order of the error of frolov s algorithm by @xmath32 for both @xmath60^d)}}$ ] and @xmath61^d)}}$ ] .",
    "these results are based on the following general error bound for continuous functions with compact support .",
    "recall that @xmath125 is the set of all @xmath126 with @xmath127 .",
    "[ keyprop ] there is a constant @xmath145 such that for every @xmath189 , shift parameter @xmath79 and @xmath199 @xmath200    thanks to lemma  [ errorlemma ] and the monotone convergence theorem we have @xmath201 since each @xmath202 is uniformly distributed in the box @xmath203 $ ] with volume @xmath204 , this series equals @xmath205 } \\frac{{\\left|\\mathcal{f}f(x)\\right|}}{\\prod_{j=1}^d { \\left|n^{1/d}(bm)_j\\right| } } \\ , { { \\rm d}}x \\\\ & \\leq \\frac{1}{\\left(2^{1/d}-1\\right)^d }   \\sum\\limits_{m\\in{\\ensuremath{\\mathbb{z}}}^d\\setminus{\\left\\{0\\right\\}}}\\ , \\int\\limits_{[n^{1/d}bm,(2n)^{1/d}bm ] }   \\frac{{\\left|\\mathcal{f}f(x)\\right|}}{\\prod_{j=1}^d 2^{-1/d}{\\left|x_j\\right| } } \\ , { { \\rm d}}x\\\\ & = \\frac{2}{\\left(2^{1/d}-1\\right)^d}\\cdot \\int_{{\\ensuremath{\\mathbb{r}}}^d }   \\frac{{\\left|\\mathcal{f}f(x)\\right|}}{\\prod_{j=1}^d { \\left|x_j\\right|}}\\cdot   { \\left|{\\left\\{m\\in{\\ensuremath{\\mathbb{z}}}^d\\setminus{\\left\\{0\\right\\}}\\mid x\\in [ n^{1/d}bm,(2n)^{1/d}bm]\\right\\}}\\right| } \\ , { { \\rm d}}x \\end{split}\\ ] ] @xmath206\\right\\}}\\right|}\\ , { { \\rm d}}x    .\\end{split}\\ ] ] thanks to the properties of the frolov matrix @xmath75 , if @xmath207 , the latter set is empty and otherwise contains no more than @xmath208 points .",
    "thus , we arrive at @xmath209 and the theorem is proven .",
    "additional differentiability properties of the function @xmath199 result in decay properties of its fourier transform @xmath44 .",
    "this leads to estimates of the integral @xmath210 .",
    "hence , the general upper bound for the error of @xmath211 in theorem [ keyprop ] adjusts to the differentiability of @xmath9 .",
    "two such examples are functions from @xmath212 and @xmath213 .",
    "[ intlemmamix ] there is some @xmath145 such that for each @xmath146 and @xmath214^d)}}$ ] @xmath215^d ) } } } .\\ ] ]    applying hlder s inequality and a linear substitution @xmath216 to the above integral , we get @xmath217 with @xmath218 being the set of all @xmath41 with @xmath219 .",
    "it it thus sufficient to prove that the integral @xmath220 is bounded by a constant multiple of @xmath221 . + again",
    "consider the auxiliary set @xmath222 \\leq|x_j|<2^{\\beta_j},1\\leq j\\leq d\\}$ ] for @xmath162 and the set @xmath223 .",
    "similar to the proof of theorem [ mixthmworstcase ] , the domain @xmath224 of integration is the disjoint union of all @xmath165 over @xmath162 , where @xmath225 , if @xmath226 , and otherwise the integrand is bounded above by @xmath227 for @xmath228 .",
    "on the other hand , @xmath229\\right ) \\leq n^{-1}\\cdot |\\det b|^{-1}\\cdot 2^d\\cdot 2^{|\\beta| } .\\end{split}\\ ] ] like in the proof of theorem [ mixthmworstcase ] , we obtain @xmath230 where the constant is finite , since @xmath177 .",
    "combining theorem  [ keyprop ] and lemma  [ intlemmamix ] yields :    [ mixthm ] there is a constant @xmath145 such that for every @xmath146 , shift parameter @xmath79 and @xmath147^d)}}$ ] @xmath231^d ) } } } .\\ ] ]    if , however , the integrand is from the space @xmath61^d)}}\\subseteq{\\ensuremath{c_c({\\ensuremath{\\mathbb{r}}}^d)}}$ ] , the following lemma holds .",
    "[ intlemmaiso ] there is some @xmath145 such that for each @xmath189 and @xmath232^d)}}$ ] @xmath233^d ) } } .\\ ] ]    like in lemma  [ intlemmamix ] , we apply hlder s inequality and get @xmath234^d)}}^2 , \\end{split}\\ ] ] for some @xmath235 . since @xmath236 for @xmath237 , the set @xmath125 is a subset of @xmath238 and the latter integral in the above integral",
    "is less than @xmath239 for some @xmath240 , since @xmath241 .    in this case , combining theorem  [ keyprop ] and lemma  [ intlemmaiso ] yields :    [ isothm ] there is a constant @xmath145 such that for every @xmath189 , shift parameter @xmath79 and @xmath152^d)}}$ ] @xmath242^d ) } } .\\end{split}\\ ] ]    we remark that the frolov properties of the matrix @xmath75 are not needed to get this estimate on @xmath61^d)}}$ ] , although they are essential for the upper bound on @xmath60^d)}}$ ] from theorem  [ mixthm ] . as seen in the proof of lemma  [ intlemmaiso ] and contrarily to lemma  [ intlemmamix ]",
    ", we do not need that the lattice points of @xmath243 lie in @xmath125 , but only that they lie in the bigger set @xmath244 .",
    "for example , the identity matrix would do .",
    "but if @xmath75 is a frolov matrix , @xmath149 works universally for @xmath212 and @xmath213 .",
    "furthermore , the frolov properties of @xmath75 prevent extremely large jumps of the number of nodes of @xmath245 for small changes of the dilation parameter @xmath150^d$ ] .",
    "now we also choose the shift parameter @xmath67 in @xmath154 at random .    * algorithm . * for any natural number @xmath4 we consider the method @xmath246 from section [ basicquadrulesection ] with independent dilation parameter @xmath80 , uniformly distributed in @xmath82^d$ ] , and shift parameter @xmath81 , uniformly distributed in @xmath33^d$ ] .    for input functions @xmath9 from @xmath61^d)}}$ ] or @xmath60^d)}}$ ] the information cost of the method @xmath246 is again of order @xmath4 .",
    "+ the first advantage of this method is its unbiasedness .    [",
    "munbiased ] let @xmath66 be an invertible matrix . for any @xmath247 ,",
    "the method @xmath248 satisfies @xmath249 in particular , the method @xmath246 is well - defined and unbiased on @xmath250 .    by the monotone convergence theorem , @xmath251^d } { \\left|f\\left ( s^{-\\top}(m+x ) \\right)\\right| } \\ , { { \\rm d}}x \\\\ & = \\sum\\limits_{m\\in{\\ensuremath{\\mathbb{z}}}^d}\\ \\int_{s^{-\\top}{\\left(m+[0,1]^d\\right ) } }   { \\left|f(y)\\right| } \\ , { { \\rm d}}y = \\int_{{\\ensuremath{\\mathbb{r}}}^d } { \\left|f(y)\\right| } \\ , { { \\rm d}}y\\ , < \\infty .\\end{split}\\ ] ] the series @xmath252 hence converges absolutely almost surely and is dominated by the integrable function @xmath253",
    ". we can thus apply lebesgue s dominated convergence theorem to get @xmath254^d } f\\left ( s^{-\\top}(m+x ) \\right ) \\ , { { \\rm d}}x\\\\ & = \\sum\\limits_{m\\in{\\ensuremath{\\mathbb{z}}}^d}\\ \\int_{s^{-\\top}{\\left(m+[0,1]^d\\right ) } }   f(y ) \\ , { { \\rm d}}y = \\int_{{\\ensuremath{\\mathbb{r}}}^d } f(y ) \\ , { { \\rm d}}y = i_d(f ) , \\end{split}\\ ] ] for the expected value of the general algorithm at @xmath9 .",
    "+ for the method @xmath246 , fubini s theorem yields @xmath255 as claimed . in particular , @xmath256 is almost surely absolutely convergent .",
    "the worst case error of this method , too , has the order @xmath257 on @xmath60^d)}}$ ] and @xmath31 on @xmath61^d)}}$ ] .",
    "this is a direct consequence of theorem  [ mixthmworstcase ] and theorem  [ isothmworstcase ] .",
    "[ mixthmworstcase2 ] there is some @xmath145 such that for any @xmath146 and @xmath147^d)}}$ ] @xmath258^d\\times[0,1]^d } { \\left|q_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } \\leq\\ , c \\",
    ",   n^{-r }   \\ , ( \\log n)^\\frac{d-1}{2 } \\ , { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d ) } } } .\\end{split}\\ ] ]    [ isothmworstcase2 ] there is some @xmath145 such that for any @xmath189 and @xmath152^d)}}$ ] @xmath258^d\\times[0,1]^d } { \\left|q_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } \\leq\\ , c \\ ,   n^{-s / d } \\ , { \\left\\vertf\\right\\vert_{{h^s}([0,1]^d ) } } .\\end{split}\\ ] ]    the second advantage of this method is the slightly better convergence order of its expected error on @xmath60^d)}}$ ] . as proven by mario ullrich in @xcite , the expected error @xmath259 of @xmath246 in @xmath214^d)}}$ ] is bounded above by a constant multiple of @xmath260^d)}}}$ ] instead of a constant multiple of @xmath261^d)}}}$ ] .",
    "the proof even shows that the quantity @xmath262 satisfies this bound .",
    "this is a stronger statement , as implied by hlder s inequality .",
    "+ in lemma  [ errorlemma ] , the absolute error of @xmath71 for integration on @xmath58 was expressed in terms of the fourier transform .",
    "the same can be done for the expected quadratic error of @xmath248 .",
    "[ errorlemma2 ] for any invertible matrix @xmath66 and @xmath263 we have @xmath264    since the expected value of @xmath265 is @xmath19 , we have @xmath266 the algorithm @xmath87 considered as a function of @xmath151^d$ ] is a finite sum of functions @xmath267 in @xmath268^d\\right)}$ ] and hence itself in @xmath268^d\\right)}$ ] .",
    "parseval s identity states @xmath269^d)}}^2",
    "= \\sum\\limits_{m\\in{\\ensuremath{\\mathbb{z}}}^d}{\\left|{\\left\\langleq_s^{{\\left(\\cdot\\right)}}(f),e^{2\\pi i { \\left\\langlem,\\cdot\\right\\rangle}}\\right\\rangle_{l^2([0,1]^d)}}\\right|}^2 .\\end{split}\\ ] ] for each index @xmath84 we have the equality @xmath270^d ) } } & = { \\left|\\det s\\right|}^{-1 } \\sum\\limits_{k\\in{\\ensuremath{\\mathbb{z}}}^d } \\int_{[0,1]^d } f\\left(s^{-\\top}(k+v)\\right)\\ , e^{-2\\pi i { \\left\\langlem , v\\right\\rangle}}{{\\rm d}}v\\\\ & = { \\left|\\det s\\right|}^{-1 } \\int_{{\\ensuremath{\\mathbb{r}}}^d } f\\left(s^{-\\top}v\\right)\\ , e^{-2\\pi i { \\left\\langlem , v\\right\\rangle}}{{\\rm d}}v\\\\ & = \\int_{{\\ensuremath{\\mathbb{r}}}^d } f\\left(v\\right)\\ , e^{-2\\pi i { \\left\\langlesm , v\\right\\rangle}}{{\\rm d}}v\\\\ & = \\mathcal{f}f(sm ) .\\end{split}\\ ] ] we arrive at @xmath271 which is what had to be proven .    now follows an analogue of theorem  [ keyprop ] for expected quadratic errors .",
    "like before , the general error bound for continuous functions with compact support adjusts to additional smoothness properties .",
    "[ keyprop2 ] there is some @xmath145 such that for every @xmath189 and @xmath199 @xmath272    by lemma  [ errorlemma2 ] and the monotone convergence theorem , @xmath273 since each @xmath202 is uniformly distributed in the box @xmath203 $ ] with volume @xmath274 , this series equals @xmath205 } \\frac{{\\left|\\mathcal{f}f(x)\\right|}^2}{\\prod_{j=1}^d { \\left|n^{1/d}(bm)_j\\right| } } \\ , { { \\rm d}}x \\\\ & \\leq \\frac{1}{\\left(2^{1/d}-1\\right)^d }   \\sum\\limits_{m\\in{\\ensuremath{\\mathbb{z}}}^d\\setminus{\\left\\{0\\right\\}}}\\ , \\int\\limits_{[n^{1/d}bm,(2n)^{1/d}bm ] }   \\frac{{\\left|\\mathcal{f}f(x)\\right|}^2}{\\prod_{j=1}^d 2^{-1/d}{\\left|x_j\\right| } } \\ , { { \\rm d}}x\\\\ & = \\frac{2}{\\left(2^{1/d}-1\\right)^d}\\cdot \\int_{{\\ensuremath{\\mathbb{r}}}^d }   \\frac{{\\left|\\mathcal{f}f(x)\\right|}^2}{\\prod_{j=1}^d { \\left|x_j\\right|}}\\cdot   { \\left|{\\left\\{m\\in{\\ensuremath{\\mathbb{z}}}^d\\setminus{\\left\\{0\\right\\}}\\mid x\\in [ n^{1/d}bm,(2n)^{1/d}bm]\\right\\}}\\right| } \\ , { { \\rm d}}x\\\\ & = \\frac{2}{\\left(2^{1/d}-1\\right)^d}\\cdot \\int_{{\\ensuremath{\\mathbb{r}}}^d }   \\frac{{\\left|\\mathcal{f}f(x)\\right|}^2}{\\prod_{j=1}^d { \\left|x_j\\right|}}\\cdot   { \\left|{\\left\\{m\\in{\\ensuremath{\\mathbb{z}}}^d\\setminus{\\left\\{0\\right\\}}\\mid bm\\in \\left[\\frac{x}{(2n)^{1/d}},\\frac{x}{n^{1/d}}\\right]\\right\\}}\\right|}\\ , { { \\rm d}}x    .\\end{split}\\ ] ] thanks to the properties of the frolov matrix @xmath75 , if @xmath207 , the latter set is empty and otherwise contains no more than @xmath208 points .",
    "thus , we arrive at @xmath275 and the theorem is proven .",
    "finally , we can prove the stated upper bound for the expected quadratic error of the method @xmath246 .",
    "[ mixthm2 ] there is some @xmath145 such that for every @xmath146 and @xmath147^d)}}$ ] @xmath276^d ) } } } .\\ ] ]    if @xmath277 is the constant of theorem  [ keyprop2 ] , we have the upper bound @xmath278 for the expected quadratic error . + since @xmath279 for @xmath237",
    ", we obtain the estimate @xmath280^d ) } } } .\\ ] ] which proves the theorem .",
    "the method @xmath246 is also optimal for @xmath61^d)}}$ ] .",
    "this can be derived from theorem  [ keyprop2 ] using the same short argument from the proof of theorem  [ mixthm2 ] .",
    "the upper bound for @xmath259 is also a direct consequence of theorem  [ isothm ] .",
    "[ isothm2 ] there is some @xmath145 such that for every @xmath189 and @xmath152^d)}}$ ] @xmath281^d ) } } .\\ ] ]    see @xcite for a proof of the optimality of this order .",
    "we can transform the above methods @xmath143 and @xmath246 such that their errors satisfy the same upper bounds for the full spaces @xmath0^d)}}}$ ] and @xmath7^d)}}}$ ] , that the original algorithms satisfy for the subspaces @xmath60^d)}}$ ] and @xmath61^d)}}$ ] .",
    "this is done by a standard method , which was already used in @xcite to transform frolov s deterministic algorithm .",
    "it preserves the unbiasedness of the algorithm @xmath246 .    to that end",
    "let @xmath282 be an infinitely differentiable function such that @xmath283 , @xmath284 and @xmath285 is a diffeomorphism .",
    "for example , we can choose @xmath286 for @xmath287 .",
    "like @xmath288 also @xmath289 is infinitely differentiable and apparently satisfies @xmath283 and @xmath284 . since the derivative of @xmath289 is strictly positive on @xmath290 , it is strictly increasing and a bijection of @xmath290 and its inverse function is smooth .",
    "if @xmath20 is any linear quadrature formula for integration on the unit cube with nodes @xmath295^d$ ] and weights @xmath296 , where @xmath297 , we define the transformed quadrature formula @xmath298 by choosing the nodes and weights to be @xmath299 thus , @xmath300 for @xmath79 and invertible @xmath66 takes the form @xmath301 for any input function @xmath302^d\\to { \\ensuremath{\\mathbb{r}}}$ ] . note that @xmath303 is zero for any index @xmath84 with @xmath304^d$ ] .",
    "* algorithms . * for any @xmath189 we consider the transformed versions @xmath305 and @xmath306 of the algorithms @xmath143 and @xmath246 from section [ frolovsrulesection ] and section [ randomshiftsection ] .",
    "these algorithms are well defined for any input function @xmath302^d\\to{\\ensuremath{\\mathbb{r}}}$ ] .",
    "the information costs of @xmath305 and @xmath306 are of order @xmath4 . by lemma [ anlemma ] , they are at most @xmath157 .",
    "let @xmath308^d)$ ] . by the change of variables theorem ,",
    "@xmath309 is also integrable on @xmath33^d$ ] and satisfies @xmath310 for any realization @xmath311 of @xmath306 .",
    "this yields @xmath312 by proposition  [ munbiased ] .",
    "[ mschlangebounds ] there is some @xmath145 such that for every @xmath146 and @xmath313^d)}}}$ ] @xmath314^d ) } } } \\quad \\text{and}\\\\ \\sup\\limits_{(u , v)\\in[1,2^{1/d}]^d\\times[0,1]^d } { \\left|\\widetilde{q}_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } & \\leq\\ , c \\ ,   n^{-r}\\ ,",
    "( \\log n)^\\frac{d-1}{2 } \\ , { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d ) } } } .\\end{split}\\ ] ]      since @xmath318 for @xmath319 , we have @xmath320^d}=0 $ ] for each @xmath321 and hence @xmath322^d)}}$ ] for any @xmath313^d)}}}$ ] . +",
    "that implies the estimates @xmath323^d ) } } } , \\\\",
    "\\sup\\limits_{(u , v)\\in[1,2^{1/d}]^d\\times[0,1]^d } { \\left|\\widetilde{q}_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } & = \\sup\\limits_{(u , v)\\in[1,2^{1/d}]^d\\times[0,1]^d } { \\left| q_{n^{1/d}\\hat{u}b}^v(f_0)-i_d(f_0)\\right|}\\\\ & \\leq c \\cdot n^{-r } ( \\log n)^\\frac{d-1}{2 } \\cdot { \\left\\vertf_0\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d ) } } } , \\end{split}\\ ] ] if @xmath145 is the maximum of the constants of theorem  [ mixthm2 ] and corollary  [ mixthmworstcase2 ] . that proves the statement , since there is some @xmath324 such that every @xmath313^d)}}}$ ] satisfies @xmath325^d)}}}\\leq c_0\\ , { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d)}}}$ ] .",
    "this can be proven as follows .",
    "the partial derivatives of @xmath326 take the form @xmath327 for @xmath328 , where @xmath329 is a finite sum of finite products of terms @xmath330 with @xmath331 and does not depend on @xmath9 .",
    "it is therefore continuous and bounded by some @xmath332 .      using these facts , we get @xmath333^d)}}^2 & \\leq \\left(\\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1,\\hdots,\\alpha_d }   { \\left\\vert(d^\\beta f \\circ \\psi ) \\cdot s_{\\alpha,\\beta}\\right\\vert_{l^2([0,1]^d)}}\\right)^2\\\\ & \\leq \\left(\\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1,\\hdots,\\alpha_d }   c_{\\alpha,\\beta } \\cdot{\\left\\vertd^\\beta f \\circ \\psi\\right\\vert_{l^2([0,1]^d)}}\\right)^2\\\\ & \\leq ( r+1)^d\\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1 , \\hdots,\\alpha_d } c_{\\alpha,\\beta}^2 \\cdot{\\left\\vertd^\\beta f \\circ \\psi\\right\\vert_{l^2([0,1]^d)}}^2\\\\ & = ( r+1)^d\\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1,\\hdots,\\alpha_d }   c_{\\alpha,\\beta}^2 \\int_{(0,1)^d } |d^\\beta f ( \\psi ( x))|^2 \\,\\mathrm{d}x\\\\ & = ( r+1)^d\\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1,\\hdots,\\alpha_d }   c_{\\alpha,\\beta}^2 \\int_{\\psi\\left((0,1)^d\\right ) } |d^\\beta f ( \\psi ( \\psi^{-1}(x))|^2   \\cdot |d\\psi^{-1}(x)| \\ , \\mathrm{d}x\\\\ & \\leq ( r+1)^d\\sup\\limits_{x\\in(0,1)^d } |d\\psi^{-1}(x)|   \\sum\\limits_{\\beta_1,\\hdots,\\beta_d=0}^{\\alpha_1,\\hdots,\\alpha_d } c_{\\alpha,\\beta}^2   \\cdot { \\left\\vertd^\\beta f\\right\\vert_{l^2([0,1]^d)}}^2 \\end{split}\\ ] ] @xmath334^d)}}}^2\\ , \\end{split}\\ ] ] for some @xmath335 and @xmath336^d)}}}^2 = \\sum\\limits_{\\alpha\\in\\{0,1,\\hdots , r\\}^d}{\\left\\vertd^\\alpha f_0\\right\\vert_{l^2([0,1]^d)}}^2 \\leq \\tilde{c } \\ , { \\left\\vertf\\right\\vert_{{h^{r,{\\rm mix}}([0,1]^d)}}}^2 , \\ ] ] if @xmath337 is the sum of the constants @xmath338 for @xmath339 .",
    "[ mschlangebounds2 ] there is some @xmath145 such that for every @xmath189 and @xmath340^d)}}}$ ] @xmath341^d ) } } \\quad \\text{and}\\\\ \\sup\\limits_{(u , v)\\in[1,2^{1/d}]^d\\times[0,1]^d } { \\left|\\widetilde{q}_{n^{1/d}\\hat{u}b}^v(f)-i_d(f)\\right| } & \\leq\\ , c \\ ,",
    "n^{-s / d } \\ , { \\left\\vertf\\right\\vert_{{h^s}([0,1]^d ) } } .\\end{split}\\ ] ]    the optimality of this order of convergence of the expected error on @xmath7^d)}}}$ ] was already stated by n.s.bakhvalov in 1962 , see @xcite .",
    "a proof can be found in @xcite .",
    "the optimality of the upper bound of theorem  [ mixthm2 ] for arbitrary dimensions can be derived from bakhvalov s result for the one - dimensional case .",
    "+ since the transformed version @xmath305 of frolov s deterministic algorithm is a particular realization of the method @xmath306 , theorem  [ mschlangebounds ] and [ mschlangebounds2 ] imply the following error bounds .",
    "it is also not hard to see , that the error bounds for @xmath154 from theorem  [ mixthmworstcase ] , [ isothmworstcase ] , [ mixthm ] and [ isothm ] on the classes @xmath60^d)}}$ ] and @xmath61^d)}}$ ] are inherited by the method @xmath344 on the classes @xmath0^d)}}}$ ] and @xmath7^d)}}}$ ] in the same way .",
    "+ to sum up , both the expected error and the worst case error of the method @xmath306 have an optimal rate of convergence on both @xmath0^d)}}}$ ] and @xmath7^d)}}}$ ] .",
    "in addition , the method is unbiased .",
    "it is also worth stressing that the algorithm is universal : it does not depend on the smoothness @xmath28 or @xmath17 of the input function in any way and hence no prior knowledge of it is needed to run @xmath306 .",
    "nonetheless , the convergence rate of its error perfectly adjusts to that smoothness .",
    "the same is valid for the algorithms @xmath305 and @xmath344 ."
  ],
  "abstract_text": [
    "<S> we are concerned with the numerical integration of functions from the sobolev space @xmath0^d)}}}$ ] of dominating mixed smoothness @xmath1 over the @xmath2-dimensional unit cube .    in @xcite </S>",
    "<S> , k.k.frolov introduced a deterministic quadrature rule whose worst case error has the order @xmath3 with respect to the number @xmath4 of function evaluations . </S>",
    "<S> this is known to be optimal . in @xcite , </S>",
    "<S> 39 years later , erich novak and me introduced a randomized version of this algorithm using @xmath2 random dilations . </S>",
    "<S> we showed that its error is bounded above by a constant multiple of @xmath5 in expectation and by @xmath3 almost surely . </S>",
    "<S> the main term @xmath6 is again optimal and it turns out that the very same algorithm is also optimal for the isotropic sobolev space @xmath7^d)}}}$ ] of smoothness @xmath8 </S>",
    "<S> . we also added a random shift to this algorithm to make it unbiased . </S>",
    "<S> just recently , mario ullrich proved in @xcite that the expected error of the resulting algorithm on @xmath0^d)}}}$ ] is even bounded above by @xmath6 . </S>",
    "<S> this thesis is a review of the mentioned upper bounds and their proofs .         +    ' '' ''    ' '' ''    * on the randomization of frolov s algorithm for multivariate integration *    masterarbeit    zur erlangung des akademischen grades    master of science ( m.sc . )    </S>",
    "<S> i m studiengang mathematik    friedrich - schiller - universitt jena    fakultt fr mathematik und informatik    eingereicht von david krieg    geboren am 08.07.1991 in wrzburg    betreuer : prof.dr.erich novak    jena , 04.02.2016 </S>"
  ]
}