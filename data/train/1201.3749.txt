{
  "article_text": [
    "the chemical master equation ( cme ) is the most basic mathematical description of stochastic biomolecular reaction networks @xcite .",
    "the cme is a generally infinite - dimensional linear differential equation .",
    "it characterizes the temporal development of the probabilities that the network is in any of its possible configurations , where the different configurations are characterized by the molecular copy numbers of the network s chemical species .",
    "due to its infinite dimension , the cme is usually not directly solvable , not even with numerical methods .",
    "a recent breakthrough in the numerical treatment of the cme was the establishment of the finite state projection ( fsp ) method by munsky and khammash @xcite .",
    "they showed that it is possible to compute a good approximation to the real solution by projecting the cme to a suitable finite subdomain of the network s state space , and solving the resulting finite - dimensional linear differential equation on that domain .",
    "nevertheless , the fsp approach still yields very high - dimensional models which are computationally expensive to simulate , even for small biochemical networks .",
    "the efficient simulation of the cme is an area of active research , and recently other simulation methods have been developed that can also be used for larger networks @xcite .    despite this progress ,",
    "the direct simulation of the cme remains a computational bottleneck for common model analysis tasks in systems biology .",
    "it is especially problematic for tasks which require the repeated simulation of the model using different parameter values , for example identifiability analysis , parameter estimation , or model sensitivity analysis .",
    "thereby , while a single or a few evaluations of a cme model with the fsp or other approaches may still be computationally feasible , the necessity of many repeated simulations will quickly render higher - level analysis tasks infeasible .",
    "mathematical methods that approximate the behaviour of a high - dimensional original model through a low - dimensional reduced model are a common way to deal with complex models . especially for linear differential equations ,",
    "model order reduction is a well established field and several methods to compute reduced order models are available @xcite .",
    "note that the step of generating a reduced model is usually computationally more expensive than a single or even a few simulations of the original high - dimensional model .",
    "but the simulation of the resulting reduced models is frequently orders of magnitude faster than the solution of the original model .",
    "so , model reduction is worth the effort if many repeated simulations are to be expected .",
    "unfortunately , for analysis tasks which require the repeated model simulation with different parameters , classical model reduction methods are not helpful . with these methods ,",
    "the reduced model depends on specific parameter values in the original model , and the reduction needs to be redone for different parameter values .",
    "thus , for the mentioned analysis tasks , the model reduction process would have to be repeated for each new parameter value , and no gain in computational efficiency would typically be possible .",
    "while classical model reduction techniques have been applied to the cme in the past @xcite , they are not so suitable for parametric analysis tasks .",
    "fortunately , model reduction methods where parameters from the original model are retained as adjustable parameters also in the reduced model are now being developed .",
    "these methods allow to compute a reduced model which uses the same parameters as the original model , and where the reduced model can directly be simulated with any choice of parameter values @xcite .",
    "the purpose of this paper is to introduce the application of these parametric model reduction methods to finite - state approximations of the chemical master equation , and to show possible usage scenarios of such an approach .",
    "the structure is as follows . in the following section ,",
    "we introduce some background and notation concerning the modelling of chemical reaction networks and parametric model order reduction .",
    "we also show how the parametric model order reduction methods can in fact be applied to the cme .",
    "afterwards , we apply the reduction technique on two reaction network models and corresponding parametric analysis tasks .",
    "we start with some preparatory background on the chemical master equation ( cme ) and parametric model order reduction .",
    "this serves in particular to fix the notation used throughout the remainder of the article .",
    "then the application of parametric model order reduction to the cme is introduced .",
    "the structure of a biochemical reaction network is characterized completely by the list of involved species , denoted as @xmath0 , and the list of reactions , denoted as @xmath1 where @xmath2 is the number of reactions in the network , and the factors @xmath3 and @xmath4 are the stoichiometric coefficients of the reactant and product species , respectively @xcite .",
    "the net change in the amount of species @xmath5 occuring through reaction @xmath6 is given by @xmath7 reversible reactions can always be written in the form by splitting the forward and reverse path into two separate irreversible reactions .    for a stochastic network model ,",
    "the variables of interest are the probabilities that the network is in any of the possible states which are characterized by the molecular copy numbers of the individual species @xmath0 .",
    "we denote the molecular copy number of @xmath8 by @xmath9 \\in \\mathbb{n}_0 $ ] .",
    "then , the state variables of the stochastic model are given by the real numbers @xmath10 = x_1 , [ x_2 ] = x_2 , \\dotsc , [ x_n ] = x_n \\textnormal { at time } t ) , \\end{aligned}\\ ] ] for @xmath11 , @xmath12 .",
    "as a short - hand notation for , we write @xmath13 , with @xmath14 .    the transitions from one state to another are determined by chemical reactions according to .",
    "the changes in the molecule numbers are described by the stoichiometric reaction vectors @xmath15 to avoid needlessly complicated cases , we assume @xmath16 for @xmath17 .",
    "the probabilities of the network being in any of the possible states @xmath18 evolve over time , and their evolution is governed by the chemical master equation ( cme ) as derived by @xcite . from a given molecular state @xmath18 , one can compute the propensity @xmath19 that reaction @xmath6 takes place according to the law of mass action as @xmath20 where @xmath21 is the vector of reaction rate constants , which are model parameters depending on the physical properties of the molecules involved in the reactions .",
    "the propensities are related to the probability that reaction @xmath6 will occur in a short time interval of length @xmath22 when the system is in state @xmath18 : @xmath23 $ } \\mid [ x ] = x ) = { \\nu}_j(x,{\\theta } ) dt + { \\scriptstyle\\mathcal{o}}(dt ) .",
    "\\end{aligned}\\ ] ]    taking the possible transitions and the corresponding reaction propensities together yields the chemical master equation ( cme ) , a linear differential equation where the variables are the probabilities that the system is in each of the possible molecular states @xmath18 : @xmath24 for @xmath14 .",
    "the cme is subject to an initial condition @xmath25 for @xmath26 .    despite being linear ,",
    "the cme is hard to solve numerically .",
    "this is due to the problem that the state space is for most systems infinite - dimensional , since all possible states @xmath14 of the reaction network must in general be considered . instead of directly solving the cme ,",
    "a number of alternative approaches to study the stochastic dynamics of biochemical reaction networks have been suggested .",
    "the most common approach is to generate a simulated realization of the stochastic process described by the reaction network , using for example the gillespie algorithm @xcite . in this approach , the probabilities @xmath13 for the possible system states",
    "are obtained from many simulated realizations . however , since this requires a large number of realizations , it is computationally expensive .    as a more direct approach , munsky and khammash @xcite have proposed the finite state projection ( fsp ) , where the cme is solved on a finite subset of the state space . here , this subset is denoted by @xmath27 , and is defined as @xmath28 where the @xmath29 are the system states for which the probabilities are computed in the projected model .",
    "the underlying assumption is that the probabilities for other states will be very low on the time scale of interest  otherwise the fsp may not yield good approximations to the solution of the cme .",
    "in particular we assume the time interval of interest to be given by @xmath30 $ ] for final time @xmath31 .",
    "the probabilities for the states @xmath29 in @xmath27 are written in the vector @xmath32 approximating @xmath33 at the finite number of states @xmath27 : @xmath34^d.\\ ] ] the equation to be solved with the fsp approximation is @xmath35 where @xmath36 is the matrix of state transition propensities , and @xmath37 is a vector of initial probabilities for the states in @xmath27 . the elements of the matrix @xmath38 are computed as @xmath39 we will frequently omit the parameter dependence of the solution ( and other parametric quantities ) .",
    "hence the solution @xmath32 , as abbreviation of @xmath40 , of is an approximation to the solution @xmath13 of the orginal cme on the domain @xmath27 .",
    "munsky and khammash @xcite have also derived an upper bound on the error between the solution @xmath32 computed via the fsp , and the solution of the original cme @xmath13 on @xmath27 .    here , we consider in addition an output vector @xmath41 defined by @xmath42 with @xmath43 .",
    "examples for relevant outputs are the probability that the molecular copy numbers are in a certain domain @xmath44 , which is achieved by the row vector output matrix @xmath45 defined by @xmath46 if @xmath47 , otherwise @xmath48 , with @xmath49 , or the expected molecular copy numbers , given by @xmath50 i.e.  @xmath51 with @xmath52 .",
    "the basic motivation for the model reduction presented here is that we are interested in parametric analysis of the model , where the model has to be solved many times with different values for the parameters @xmath53 . due to the typical high dimensions of the matrix @xmath38 ,",
    "already a single simulation is computationally expensive , and analysis tasks requiring many repeated simulations are often computationally infeasible .",
    "thus , the primary goal is to derive a reduced model which is rapidly solvable and provides an approximation @xmath54 to the output @xmath55 , potentially without any consideration of the original state vector @xmath32 .",
    "model order reduction of parametric problems is a very active research field in systems theory , engineering and applied mathematics .",
    "we refer to @xcite and references therein for more information on the topic .    here",
    ", we apply the reduction technique for parametric problems presented in @xcite adopted to our notation .",
    "it is based on two biorthogonal global projection matrices @xmath56 with @xmath57 and @xmath58 , where @xmath59 is the dimension of the reduced model .",
    "the matrix @xmath60 is assumed to span a space that approximates the system state variation for all parameters and times .",
    "the construction of such matrices will be detailed in the next subsection .",
    "the gain of computational efficiency in repeated simulations comes from a separation of the simulation task into a computationally expensive `` offline '' phase and a computationally cheap `` online '' phase . in the offline phase ,",
    "suitable projection matrices @xmath60 and @xmath61 are computed without fixing specific parameter values . with the projection matrices , a reduced model with the same free parameters as the original model",
    "is computed . in the online phase ,",
    "the reduced model is simulated with the actually chosen parameter values , which is typically several orders of magnitude faster than the simulation of the original model . for analysis tasks with repeated simulations",
    ", only the online phase has to be repeated for different choices of the parameter values , yielding an overall gain in computational efficiency .",
    "the reduction technique assumes a separable parameter dependence of the full system matrices and the initial condition .",
    "this means , we assume that there exist a suitable small constant @xmath62 , parameter independent components @xmath63 } \\in { \\mathbb{r}}^{d \\times d}$ ] and parameter dependent scalar coefficient functions @xmath64}_a({\\theta})$ ] for @xmath65 such that @xmath66}_a({\\theta } ) a^{[q]}\\ ] ] and similarly for the system matrix @xmath45 and initial condition @xmath67 .",
    "we assume that @xmath68 stems from some domain @xmath69 of admissible parameters . in the next step ,",
    "the reduced component matrices and initial conditions are determined by @xmath70 } : = w^t a^{[q ] } v , \\quad   c_r^{[q ] } : = c^{[q ] } v , \\quad    p_{0r}^{[q]}:= w^t p_0^{[q]}.\\ ] ] for @xmath71",
    ". the resulting quantities @xmath72}$ ] , @xmath73}$ ] , and @xmath74}$ ] are @xmath59-dimensional vectors or matrices and independent of the high dimension @xmath75 .",
    "the basis computation and the computation of these reduced system components is performed once and parameter - independently in the offline - phase .",
    "then , in the online - phase , for any new parameter @xmath53 the reduced system matrices and the initial condition are assembled by @xmath76}({\\theta})a_r^{[q]}\\ ] ] and similarly for @xmath77 and @xmath78 .",
    "the low dimensional reduced system that remains to be solved is @xmath79 from the reduced state @xmath80 , an approximate state for the full system can be reconstructed at any desired time by @xmath81 .",
    "also the difference between the approximated output @xmath54 and the output @xmath55 of the original model can be bounded by so called error estimators .",
    "a - posteriori error bounds for the reduced systems as considered here are given in @xcite .",
    "different methods for the computation of the projection bases @xmath60 and @xmath61 exist . in systems theory , methods like balanced truncation , hankel - norm approximation or moment matching are applied , that approximate the input - output behaviour of a linear time - invariant system @xcite .",
    "the resulting reduced models can be applied for varying input signals .",
    "extensions to parametric problems exist , e.g. @xcite . as we do not have varying inputs in the problem studied here , we consider snapshot - based approaches to be more suitable .",
    "this means , the projection bases are constructed by solution snapshots , i.e. special solutions computed for selected parameter values .",
    "the generation of projection matrices @xmath60 and @xmath61 must be done in such a way , that they are globally well approximating the system states over the parameter and time domain . a possible way to achieve",
    "this is the pod - greedy algorithm , which has been introduced in @xcite and is meanwhile a standard procedure in reduced basis methods @xcite .",
    "the algorithm makes use of a repeated proper orthogonal decomposition ( pod ) of trajectories @xmath82\\rightarrow { \\mathbb{r}}^d$ ] , which for our purposes can be defined as @xmath83 intuitively , @xmath84 is a state space vector representing the single dominant mode that minimizes the squared mean projection error .",
    "computationally , this minimization task is solved by a reformulation as a suitable eigenvalue problem .",
    "consider the correlation matrix @xmath85 . then",
    ", @xmath86 is an eigenvector corresponding to the largest eigenvalue @xmath87 of @xmath45 , i.e. , @xmath88 . for additional theoretical and computational details on pod",
    "we refer to @xcite .",
    "we further require a finite subset of parameters @xmath89 , that are used in the basis generation process . as error indicator",
    "@xmath90 we use the projection error of the full system trajectory on the reduced space spanned by the orthonormal columns of @xmath60 , i.e. @xmath91 the pod - greedy procedure which is given in the pseudo - code below , starts with an arbitrary orthonormal initial basis @xmath92 and performs an incremental basis extension .",
    "the algorithm repeatedly identifies the currently worst resolved parameter ( a ) , orthogonalizes the corresponding full trajectory with the current reduced space ( b ) , computes a pod of the error trajectory ( c ) , and inserts the dominant mode into the basis ( d ) .",
    "function @xmath93 pod - greedy@xmath94    1 .",
    "@xmath95 2 .   while @xmath96 1 .",
    "@xmath97 2 .",
    "@xmath98 3 .",
    "@xmath99 4 .   @xmath100 $ ] 5 .",
    "@xmath101 3 .",
    "end while    note that the algorithm is implemented such that the simulation of the full model , yielding @xmath40 in , is only performed once for each @xmath53 in the training set @xmath102 .    for concluding the basis generation , we set @xmath103 .",
    "this satisfies the biorthogonality condition @xmath104 , as @xmath60 has orthonormal columns by construction . in practice",
    "the time - integrals in are realized by a finite sampling of the time interval .",
    "a theoretical underpinning for the pod - greedy algorithm has recently been provided by the analysis of convergence rates @xcite .",
    "this is based on the approximation - theoretical notion of the _ kolmogorov @xmath105-width @xmath106 _ of a given set @xmath107 , which quantifies how well the set can be approximated by arbitrary @xmath108-dimensional linear subspaces of @xmath109 .",
    "the convergence statement for the case of exponential convergence then can be summarized as follows : if the set of solutions @xmath110 , { \\theta}\\in { \\mathcal{p}}\\ } \\subset { \\mathbb{r}}^d$ ] is compact and has an exponentially decaying kolmogorov @xmath105-width @xmath111 for some @xmath112 and all @xmath113 , then the error sequence @xmath114 generated by the pod - greedy procedure ( cf . the definition in step 2 .",
    "in the pseudo code ) also decays with an exponential rate , @xmath115 with suitable constants @xmath116 depending on @xmath117 .",
    "thus , if the set of solutions can be approximated by linear subspaces with an exponentially decaying error term , then the pod - greedy algorithm will in fact find an approximation with an exponentially decaying error term , though possibly with suboptimal parameters in the error bound .",
    "extensions of the pod - greedy algorithm exist , e.g. allowing more than one mode per extension step , performing adaptive parameter and time - interval partitioning , or enabling training - set adaptation @xcite .      in this section ,",
    "we describe how to apply the reduction method for parametrized models presented in the previous section to fsp models for the chemical master equation .",
    "as discussed in the previous section , the first step in the proposed reduction method is a decomposition of the @xmath75-dimensional system matrix @xmath38 as in .",
    "such a decomposition is possible for the case of mass action reaction propensities , as defined in , or generalized mass action , as recently suggested for the chemical master equation @xcite . in this case , the length of the parameter vector @xmath53 is equal to the number of reactions @xmath2 , and we decompose @xmath38 into @xmath2 terms as @xmath118 } + \\dotsm + { \\theta}_m a^{[m]}.\\ ] ] hence , concerning the notation given before , we have @xmath119 components @xmath63}$ ] and coefficient functions @xmath120}({\\theta})={\\theta}_q$ ] .",
    "each matrix @xmath63}$ ] in this decomposition comes from just the transition propensities corresponding to reaction @xmath121 , and is defined by @xmath122}_{ii } & = - \\prod_{k=1}^n ( x^{(i)}_{k})^{{\\sigma}_{kq } } \\\\",
    "a^{[q]}_{ij } & = \\left\\lbrace      \\begin{aligned }        \\prod_{k=1}^n ( x^{(j)}_{k})^{{\\sigma}_{kq } } & \\textnormal { if } x^{(j ) } = x^{(i ) } + v_q \\\\        0 & \\textnormal { otherwise}.      \\end{aligned }      \\right .",
    "\\end{aligned}\\ ] ] more generally , such a decomposition is also possible if reaction rate propensities can be decomposed into the product of two terms , with the first term depending on parameters only , and the second term on molecule numbers only .",
    "this case is for example encountered when the temperature - dependance of the reaction rate constant is relevant , and the temperature @xmath123 is a variable parameter in the arrhenius equation @xmath124 . since the output matrix @xmath45 and",
    "the initial condition @xmath67 are usually not depending on parameters in this framework , a decomposition of @xmath45 and @xmath67 is not considered .",
    "the situation is more difficult for reaction propensities involving for example rational terms with parameters in the denominator .",
    "the denominator parameters can not be included in the reduced order model by the decomposition outlined in and .",
    "if variations in these parameters are however not relevant to the planned analysis , then they can be set to their nominal value , and the decomposition can directly be done as described above .",
    "alternatively , approximation steps can be performed , such as taylor series expansion or empirical interpolation @xcite , that generate an approximating parameter - separable expansion .",
    "in this section , we present the study of two example networks with the proposed model reduction method . with these examples ,",
    "the applicability of the reduced modeling approach especially for analysis tasks requiring repeated simulations with different parameter values is illustrated .",
    "the first network is a bistable genetic toggle switch , where cells may switch randomly between two states , based on the model in @xcite . for this network ,",
    "the problem of parameter estimation with a reduced model is studied .",
    "the second network is a second - order genetic oscillator , based on @xcite , where we perform a sensitivity analysis over a wide parameter range .",
    "the genetic toggle switch considered here is an ovarian follicle switch model from @xcite .",
    "it is a system of two genes which activate each other .",
    "the switch is modelled as a reaction network with two species @xmath125 , @xmath126 , representing the gene products .",
    "the network reactions are specified in table  [ tab : switch - model ] .",
    ".list of reactions and reaction propensity functions for the follicle switch model @xcite .",
    "nominal parameter values are @xmath127 , @xmath128 , @xmath129 , @xmath130 , @xmath131 , @xmath132 , @xmath133 . [ cols=\"^,^,^ \" , ]     the network model in table  [ tab : oscillator - model ] shows oscillations only in a stochastic description .",
    "the deterministic model has a unique asymptotically stable equilibrium point , but in a stochastic model , fluctuations may push the molecular numbers beyond a certain threshold , inducing a dynamical response along a slow manifold , which corresponds to one oscillatory period @xcite . depending on the noise level , such responses will be initiated more or less often , corresponding to a more or less regular oscillatory pattern .",
    "the system is truncated to the rectangle @xmath134 , which contains the relevant system states for the parameter ranges of interest .",
    "similarly as in the switch example , the reaction propensity expressions contain rational terms in the parameters @xmath135 , @xmath136 , and @xmath137 .",
    "these three can not be decomposed directly , so we do the decomposition described in the methods section for the other five parameters only . with this decomposition",
    ", the truncated cme for the genetic oscillator can be written as @xmath138 } + k_3 a^{[2 ] } + k_4 a^{[3 ] } + k_5 a^{[4 ] } + k_7 a^{[5]}\\bigr ) p(t),\\ ] ] where @xmath139}$ ] , @xmath140 are of dimension @xmath141 .",
    "the initial condition for is chosen as a uniform distribution over the rectangle @xmath142 : @xmath143 the time scale of interest for the model in is for @xmath144 . at the end of the interval",
    ", the probability distribution seems to approach a steady state .",
    "some state plots are given in figure [ fig : oscill - state - plots ] .",
    "one observes a significant effect of the parameter @xmath145 on the amplitude of the oscillations .",
    "the simulation time for the detailed model was in average 7.3 minutes on a dell desktop computer with 3.2 ghz dual - core intel 4 processor and 1 gb ram , without including the computation time for the construction of the state transition matrix @xmath38 .",
    "of the oscillator cme model for parameter values @xmath146 ( upper row ) and @xmath147 ( lower row ) at times @xmath148 from left to right . ]      for the basis generation , the parameter @xmath145 was assumed to vary within the interval @xmath149 $ ] .",
    "a reduced basis with the pod - greedy algorithm was computed from a training set of 30 logarithmically equidistant parameters over the parameter domain ( figure  [ fig : oscillator_sensitivity ] ) . as in the switch example",
    ", the target accuracy was chosen as @xmath150 , and the initial basis was chosen from the initial condition @xmath151 .",
    "the pod - greedy algorithm produces a basis of 109 vectors , with an overall computation time of 16.5 hours on the hardware as in the previous subsection .",
    "the first 20 basis vectors are shown in figure  [ fig : oscillator - basis ] .",
    "it is apparent that several of the basis vectors are directly included in order to reproduce the different amplitudes of oscillations that will occur under variations of the parameter @xmath145 .",
    "the error decay curve is shown in figure  [ fig : oscillator - error - decay ] , displaying an exponential error decay as also observed for the switch example .            with the reduced basis @xmath152",
    ", we can construct a reduced parametric model for the cme of the oscillator as @xmath153}_r + a^{[o]}_r ) p_r(t ) \\\\",
    "p_{r}(0 ) & = v{^\\mathrm{t}}p(0 ) ,    \\end{aligned}\\ ] ] with @xmath154}_r = v{^\\mathrm{t}}a^{[3 ] } v \\in { \\mathbb{r}}^{109\\times 109}$ ] and @xmath155}_r = v{^\\mathrm{t}}\\bigl(k_1 a^{[1 ] } + k_3 a^{[2 ] } + k_5 a^{[4 ] } + k_7 a^{[5]}\\bigr ) v \\in { \\mathbb{r}}^{109 \\times 109}$ ] .",
    "note that since only @xmath145 has been varied in the reduction process , the other parameters are no longer present as parameters in the reduced model , but just take their nominal values .",
    "while the same basis @xmath60 could be used to construct another reduced model where all parameters are retained , it is unlikely that this other model will be a good approximation of the original one for varying values of the other parameters .      as an application of the reduced order parametric model obtained in the previous section , we study the variations of oscillatory amplitude over a parameter range .",
    "specifically , we consider 200 equally spaced values for the parameter @xmath145 in the interval @xmath156 $ ] and compute the probability that the amount of @xmath126 is larger than 100 : @xmath157 with @xmath158 the final time of the simulation .",
    "the results are shown in figure  [ fig : oscillator_sensitivity ] and show a clear decay of oscillatory amplitude for increasing values of @xmath145 . due to the significant time savings from the reduced model ,",
    "this sensitivity curve can be computed with a high resolution",
    ".     predicted from the reduced model .",
    "red dots are validation results from a simulation of the original model .",
    "triangles on the parameter axis indicate parameter values which were used in the construction of the reduced basis . ]    to evaluate the quality of the reduced model , we also computed the probability   using the original model at two points within the considered interval for the parameter @xmath145 .",
    "as shown in figure  [ fig : oscillator_sensitivity ] , the results from the original model are in perfect agreement with the predictions from the reduced model at these points . since the points at which the original model was evaluated in this experiment were not part of the training set ( shown as triangles on the parameter axis in figure  [ fig : oscillator_sensitivity ] ) , this shows that it is in fact possible to extrapolate the reduced model to parameter values that were not used to construct the basis .",
    "in this paper , we have introduced the application of parametric model reduction methods to finite - state approximations of the chemical master equation .",
    "we have also presented two case studies where these methods are applied to cme models of different networks in order to make parametric analysis tasks computationally efficient . by this , it has become clear that parametric model reduction methods are a very useful tool for the analysis of stochastic biochemical reaction network described by the cme .",
    "especially analysis tasks where many repeated simulations of a network with different parameter values are required can profit significantly from parametric model reduction .",
    "this includes for example sensitivity analysis or parameter optimization tasks such as identifiability analysis or estimation .",
    "moreover , the significant speedup of the simulation for the reduced model allows an interactive exploration of the network s dynamics within the parameter space within a suitable graphical user interface .",
    "this contribution is just a first step in the application of parametric model reduction methods to the cme .",
    "one particularly important aspect that we have not discussed here is the computation of error estimates for certifying that the simulation output of the reduced model is within some tolerance of the corresponding simulation output of the original model . to maintain computational efficiency",
    ", the error estimation should be done without actually simulating the original model .",
    "error estimation methods have been developed for parametric model reduction of generic models @xcite , but tighter estimates could likely be obtained by taking into account the special structure of the cme models .",
    "recent work for example refined the previous generic error bounds for stable models @xcite .",
    "sw and bh conceived of the study , performed the study , and wrote the manuscript .",
    "both authors read and approved the final manuscript .",
    "we thank wolfgang halter for programming support in the oscillator case study .",
    "the authors would like to thank the german research foundation ( dfg ) for financial support of the project within the cluster of excellence in simulation technology at the university of stuttgart .",
    "bh also acknowledges the baden - wrttemberg stiftung ggmbh for funding .",
    "this work was also supported by the german research foundation ( dfg ) within the funding programme open access publishing ."
  ],
  "abstract_text": [
    "<S> [ [ background ] ] background : + + + + + + + + + + +    stochastic biochemical reaction networks are commonly modelled by the chemical master equation , and can be simulated as first order linear differential equations through a finite state projection . due to the very high state space dimension of these equations , </S>",
    "<S> numerical simulations are computationally expensive . </S>",
    "<S> this is a particular problem for analysis tasks requiring repeated simulations for different parameter values . </S>",
    "<S> such tasks are computationally expensive to the point of infeasibility with the chemical master equation .    </S>",
    "<S> [ [ results ] ] results : + + + + + + + +    in this article , we apply parametric model order reduction techniques in order to construct accurate low - dimensional parametric models of the chemical master equation . these surrogate models can be used in various parametric analysis task such as identifiability analysis , parameter estimation , or sensitivity analysis . as biological examples , we consider two models for gene regulation networks , a bistable switch and a network displaying stochastic oscillations .    [ [ conclusions ] ] conclusions : + + + + + + + + + + + +    the results show that the parametric model reduction yields efficient models of stochastic biochemical reaction networks , and that these models can be useful for systems biology applications involving parametric analysis problems such as parameter exploration , optimization , estimation or sensitivity analysis .    </S>",
    "<S> [ 1995/12/01 ] </S>"
  ]
}