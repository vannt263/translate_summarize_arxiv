{
  "article_text": [
    "when the number of stocks in a portfolio is large and the number of available ( relevant ) observations in the historical time series of returns is limited  which is essentially a given for short - horizon quantitative trading strategies  the sample covariance matrix ( scm ) is badly singular .",
    "this makes portfolio optimization  _",
    "e.g. _ , sharpe ratio maximization  challenging as it requires the covariance matrix to be invertible .",
    "a standard method for circumventing this difficulty is to employ factor models , which , instead of computing scm for a large number of stocks , allow to compute a factor covariance matrix ( fcm ) for many fewer risk factors .",
    "however , the number of relevant risk factors itself can be rather large . _ e.g. _",
    ", in a ( desirably ) granular industry classification ( ic ) , the number of industries can be in 3 digits for a typical ( liquid ) trading universe . then",
    ", even the sample fcm can be singular .",
    "in ( kakushadze , 2015c ) a simple idea is set forth : model fcm itself via a factor model , and repeat this process until the remaining fcm is small enough and can be computed .",
    "in fact , at the end of this process we may even end up with a single factor , for which  fcm \" is simply its variance .",
    "this construction  termed as  russian - doll \" risk models ( kakushadze , 2015c )  dramatically reduces the number of or altogether eliminates the factors for which ( off - diagonal ) fcm must be computed .",
    "the  catch \" is that at each successive step we must : i ) identify the risk factors ; and ii ) compute the specific ( idiosyncratic ) risk ( isr ) and fcm consistently .    identifying the risk factors in the russian - doll construction",
    "is facilitated by using a binary industry classification : using bics as an illustrative example , industries serve as the risk factors for sub - industries ; sectors  there are only 10 of them  serve as the risk factors for industries ; and  if need be  the  market \" serves as the sole risk factor for sectors .",
    "correctly computing isr and fcm is more nontrivial : the algorithms for this are generally deemed proprietary .",
    "one method in the  lore \" is to use a cross - sectional linear regression , where the returns are regressed over a factor loadings matrix ( flm ) , and fcm is identified with the ( serial ) covariance matrix of the regression coefficients , whereas isr squared is identified with the ( serial ) variance of the regression residuals .",
    "however , as discussed in ( kakushadze , 2015c ) , generally this does not satisfy a nontrivial requirement ( which is often overlooked in practice ) that the factor model reproduce the historical in - sample total variance .    in this paper",
    "we share a complete algorithm and source code for building what we refer to as  heterotic \" risk models .",
    "it is based on a simple observation that , if we use principal components ( pcs ) as flm , the aforementioned total variance condition is automatically satisfied . unfortunately , the number of useful pcs is few as it is limited by the number of observations , and they also tend to be unstable out - of - sample ( as they are based on off - diagonal covariances ) , with the first pc being most stable .",
    "we circumvent this by building flm from the first pcs of the blocks ( sub - matrices ) of the sample correlation matrix . ] corresponding to  in the bics language  the sub - industries .",
    "_ i.e. _ , if there are @xmath3 stocks and @xmath4 sub - industries , flm is @xmath5 , and in each column the elements corresponding to the tickers in that sub - industry are proportional to the first pc of the corresponding block , with all other elements vanishing .",
    "the total variance condition is automatically satisfied .",
    "then , applying the russian - doll construction yields a nonsingular factor model covariance matrix , which , considering it sizably adds value in sharpe ratio optimization for certain intraday mean - reversion alphas we backtest , appears to be stable out - of - sample .",
    "heterotic risk models are based on our proprietary know - how .",
    "we hope sharing it with the investment community encourages organic custom risk models building .",
    "this paper is organized as follows . in section [ sec2 ]",
    "we briefly review some generalities of factor models and discuss in detail the total variance condition . in section [ sub.pc ]",
    "we discuss the pc approach and an algorithm for fixing the number of pc factors , with the r source code in appendix [ app.a ] .",
    "we discuss heterotic risk models in detail in section [ sec.het ] , with the complete russian - doll embedding in section [ sec.rd ] and the r source code in appendix [ app.b ] . in section [ sec.horse ]",
    "we run a horse race of intraday mean - reversion alphas via i ) weighted regressions and ii ) optimization using heterotic risk models . for optimization with homogeneous linear constrains and ( liquidity / position ) bounds",
    "we use the r source code in appendix [ app.c ] .. ] we briefly conclude in section [ sec.conc ] .",
    "in a multi - factor risk model , a sample covariance matrix @xmath6 for @xmath3 stocks , @xmath7 , which is computed based on a time series of stock returns @xmath8 ( _ e.g. _ , daily close - to - close returns ) , is modeled via a constructed covariance matrix @xmath9 given by @xmath10 where @xmath11 is the kronecker delta ; @xmath9 is an @xmath12 matrix ; @xmath13 is the specific risk ( a.k.a .",
    "idiosyncratic risk ) for each stock ; @xmath14 is an @xmath5 factor loadings matrix ; and @xmath15 is a @xmath16 factor covariance matrix , @xmath17 , where @xmath18 . _",
    "i.e. _ , the random processes @xmath19 corresponding to @xmath3 stock returns are modeled via @xmath3 random processes @xmath20 ( specific risk ) together with @xmath4 random processes @xmath21 ( factor risk ) : @xmath22 when @xmath23 , where @xmath24 is the number of observations in each time series , the sample covariance matrix @xmath6 is singular with @xmath25 nonzero eigenvalues .",
    "in contrast , assuming all @xmath26 and @xmath15 is positive - definite , then @xmath9 is automatically positive - definite ( and invertible ) .",
    "furthermore , the off - diagonal elements of @xmath6 typically are not expected to be too stable out - of - sample . on the contrary",
    ", the factor model covariance matrix @xmath9 is expected to be much more stable as the number of risk factors , for which the factor covariance matrix @xmath15 needs to be computed , is @xmath18 .",
    "the prime aim of a risk model is to predict the covariance matrix out - of - sample as precisely as possible , including the out - of - sample total variances .",
    "however , albeit this requirement is often overlooked in practical applications , a well - built factor model had better reproduce the in - sample total variances .",
    "that is , we require that the factor model total variance @xmath27 coincide with the in - sample total variance @xmath28 : @xmath29 _ a priori _ this gives @xmath3 conditions for @xmath30 unknowns @xmath13 and @xmath15 , so we need additional assumptions conditions we can impose on @xmath9 , @xmath31 in terms of out - of - sample unstable @xmath6 , @xmath31 .",
    "note that the variances @xmath28 typically are much more stable . ] to compute @xmath13 and @xmath15 .",
    "one such assumption ",
    "_ intuitively _  is that the total risk should be attributed to the factor risk to the greatest extent possible , _",
    "i.e. _ , the part of the total risk attributed to the specific risk should be minimized .",
    "one way to formulate this requirement mathematically is via least squares .",
    "first , mimicking ( [ upsilon ] ) , we decompose the stock returns @xmath8 via a linear model @xmath32 here the residuals @xmath33 are _ not _ the same as @xmath20 in ( [ upsilon ] ) ; in particular , generally the covariance matrix @xmath34 is not diagonal ( see below ) .",
    "we can require that @xmath35 where @xmath36 , and the minimization is w.r.t .",
    "this produces a weighted linear regression .",
    "] with the regression weights @xmath37 .",
    "so , what should these weights be ?      while choosing unit weights @xmath38 might appear as the simplest thing to do , this suffers from a shortcoming .",
    "intuitively it is clear that  _ on average _  the residuals @xmath33 are larger for more volatile stocks , so the regression with unit weights would produce skewed results .",
    "this can be readily rectified using nontrivial regression weights .",
    "natural \" choice is @xmath39 .",
    "in fact , we have a regression with unit weights : @xmath40 where @xmath41 , @xmath42 , and @xmath43 on average are expected to be much more evenly distributed compared with @xmath33  we have scaled away the volatility skewness via rescaling the returns , factor loadings and residuals by @xmath44 .",
    "so , we are now modeling the sample _ correlation _ matrix @xmath45 ( note that @xmath46 , while @xmath47 for @xmath31 ) ( @xmath48 labels the observations in the time series and in the above notations the index @xmath49 takes @xmath24 values ) are the time series of the stock returns based on which the sample covariance matrix @xmath6 is computed ( so @xmath50 , where the variance is serial ) , then @xmath51 is the sample covariance matrix for the  normalized \" returns @xmath52 , _",
    "i.e. _ , @xmath53 , where @xmath54 and @xmath55 are serial . ] via another factor model matrix @xmath56 where @xmath57 , and @xmath58 . the solution to ( [ lin.unit ] ) is given by ( in matrix notation ) @xmath59 { \\widetilde r}\\\\   & & q \\equiv { \\widetilde \\omega}\\left({\\widetilde \\omega}^t~{\\widetilde\\omega}\\right)^{-1}{\\widetilde\\omega}^t\\end{aligned}\\ ] ] where @xmath60 is a projection operator : @xmath61 .",
    "consequently , we have : @xmath62 \\psi \\left[1 - q^t\\right]\\\\   & & { \\widetilde \\omega}~\\phi~{\\widetilde \\omega}^t = { \\widetilde \\omega}~\\mbox{cov}\\left(f , f^t\\right){\\widetilde \\omega}^t = q~\\psi~q^t\\end{aligned}\\ ] ] note that the matrix @xmath63 is not diagonal",
    ". however , the idea here is to identify @xmath64 with the diagonal part of @xmath63 : @xmath65 \\psi \\left[1 - q^t\\right]\\right)_{ii}\\ ] ] and we have @xmath66 note that @xmath67 defined via ( [ xi ] ) are automatically positive ( nonnegative , to be precise  see below ) .",
    "however , we must satisfy the conditions ( [ tot.risk ] ) , which reduce to @xmath68 and imply @xmath69 the @xmath3 conditions ( [ t ] ) are not all independent .",
    "thus , we have @xmath70 .",
    "the conditions ( [ t ] ) are nontrivial .",
    "they are not satisfied for an arbitrary factor loadings matrix @xmath71 .",
    "however , there is a simple way of satisfying these conditions , to wit , by building @xmath71 from the principal components of the correlation matrix @xmath51 .",
    "let @xmath72 , @xmath73 be the @xmath3 principal components of @xmath51 forming an orthonormal basis @xmath74 such that the eigenvalues @xmath75 are ordered decreasingly : @xmath76 .",
    "more precisely , some eigenvalues may be degenerate . for simplicity  and",
    "this is not critical here  we will assume that all positive eigenvalues are non - degenerate .",
    "however , we can have multiple null eigenvalues .",
    "typically , the number of nonvanishing eigenvalues is @xmath25 , where , as above , @xmath24 is the number of observations in the stock return time series .",
    "we can readily construct a factor model with @xmath77 : @xmath78 then the factor covariance matrix @xmath79 and we have @xmath80 so @xmath81",
    ". see appendix [ app.b ] for the r code including the following algorithm .",
    "when @xmath82 we have @xmath83 , which is singular .. we are assuming @xmath84 , which ( up to computational precision ) is the case if there are no n / as in the stock return times series . ] therefore , we must have @xmath85 .",
    "so , how do we determine @xmath86 ? and is there @xmath87 other than the evident answer @xmath88 ?",
    "here we can do a lot of complicated , even convoluted things .",
    "or we can take a pragmatic approach and come up with a simple heuristic . here",
    "is one simple algorithm that does a very decent job at fixing @xmath4 .",
    "the idea here is simple .",
    "it is based on the observation that , as @xmath4 approaches @xmath25 , @xmath89 goes to 0 ( _ i.e. _ , less and less of the total risk is attributed to the specific risk , and more and more of it is attributed to the factor risk ) , while as @xmath4 approaches 0 , @xmath90 goes to 1 ( _ i.e. _ , less and less of the total risk is attributed to the factor risk , and more and more of it is attributed to the specific risk ) .",
    "so , as a rough cut , we can think of @xmath86 and @xmath87 as the maximum / minimum values of @xmath4 such that @xmath91 and @xmath92 , where @xmath93 and @xmath94 are some desired bounds on the fraction of the contribution of the specific risk into the total risk .",
    "_ e.g. _ , we can set @xmath95 and @xmath96 . in practice",
    ", we actually need to fix the value of @xmath4 , not @xmath86 and @xmath87 , especially that for some preset values of @xmath93 and @xmath94 we may end up with @xmath97 .",
    "however , the above discussion aids us in coming up with a simple heuristic definition for what @xmath4 should be . here",
    "is one : @xmath98 _ i.e. _ , we take @xmath4 for which @xmath99 ( which monotonically decreases with increasing @xmath4 ) is closest to 1 .",
    "this simple algorithm works pretty well in practical applications . is skewed ; typically , @xmath100 has a tail at higher values , while @xmath101 has a tail at lower values , and the distribution is only roughly log - normal .",
    "so @xmath4 is not ( the floor / cap of ) @xmath102 , but somewhat higher , albeit close to it .",
    "see table [ table.prin.comp ] and figure 1 for an illustrative example . ]",
    "an evident limitation of the principal component approach is that the number of risk factors is limited by @xmath25 . if long lookbacks are unavailabe / undesirable , as , _",
    "e.g. _ , in short - holding quantitative trading strategies , then typically @xmath103 .",
    "yet , the number of the actually relevant underlying risk factors can be substantially greater than @xmath25 , and most of these risk factors are missed by the principal component approach . in this regard , we can ask : can we use other than the first @xmath25 principal components to build a factor model ?",
    "the answer , prosaically , is that , without some additional information , it is unclear what to do with the principal components with null eigenvalues .",
    "they simply do not contribute to any sample factor covariance matrix .",
    "however , not all is lost .",
    "there is a way around this difficulty .",
    "without long lookbacks , the number of risk factors based on principal components is limited . however , risk factors based on a granular enough industry classification can be plentiful . furthermore , they are independent of the pricing data and , in this regard , are insensitive to the lookback .",
    "in fact , typically they tend to be rather stable out - of - sample as companies seldom jump industries , let alone sectors .    for terminological definiteness",
    ", here we will use the bics nomenclature for the levels in the industry classification , albeit this is not critical here .",
    "also , bics has three levels  sector @xmath104 industry @xmath104 sub - industry \" ( where  sub - industry \" is the most granular level ) .",
    "the number of levels in the industry hierarchy is not critical here either .",
    "so , we have : @xmath3 stocks labeled by @xmath105 ; @xmath4 sub - industries labeled by @xmath106 ; @xmath107 industries labeled by @xmath108 ; and @xmath109 sectors labeled by @xmath110 .",
    "more generally , we can think of such groupings as  clusters \" .",
    "sometimes , loosely , we will refer to such cluster based factors as  industry \" factors .",
    "the binary property implies that each stock belongs to one and only one sub - industry , industry and sector ( or , more generally , cluster ) .",
    "let @xmath111 be the map between stocks and sub - industries , @xmath112 be the map between sub - industries and industries , and @xmath113 be the map between industries and sectors : @xmath114 the nice thing about the binary property is that the clusters ( sub - industries , industries and sectors ) can be used to identify blocks ( sub - matrices ) in the correlation matrix @xmath51 .",
    "_ e.g. _ , at the most granular level , for sub - industries , the binary matrix @xmath115 defines such blocks .",
    "thus , the sum @xmath116 , where @xmath117 is an arbitrary @xmath3-vector , is the same as @xmath118 , where @xmath119 is the set of tickers in the sub - industry @xmath120 .",
    "these blocks are the backbone of the following construction .          for the sake of completeness ,",
    "let us discuss an evident generalization .",
    "above in ( [ ind.pc ] ) we took the binary map between the tickers and sub - industries and augmented it with the first principal components of the corresponding blocks in the sample correlation matrix .",
    "instead of taking only the first principal component , we can take the first @xmath140 principal components for each block labeled by the sub - industry @xmath120 ( @xmath141 ) .",
    "then we have @xmath142 risk factors labeled by pairs @xmath143 , where for a given value of @xmath120 we have @xmath144 ( with @xmath145 ) .",
    "the factor loadings matrix reads : @xmath146_i^{(i)}\\ ] ] where @xmath125 is the @xmath147 matrix whose columns are the first @xmath148 principal components ( with eigenvalues @xmath149^{(i)}$ ] ) of the @xmath126 matrix @xmath127 ( as above , @xmath128_{ij } \\equiv \\psi_{ij}$ ] , @xmath129 , and @xmath130_i^{(i)}~[u(a)]_i^{(j ) } = \\delta_{ij}$ ] , @xmath150 . ) in order to have nonvanishing specific risks , it is necessary that we take @xmath151 ( @xmath24 is the number of observations in the time series ) .",
    "we then have @xmath152^{(i)}~ \\left([u(g(i))]^{(i)}_i\\right)^2\\right]\\delta_{ij } + \\nonumber\\\\   & & \\,\\,\\,\\,\\,\\,\\,+\\sum_{i\\in d(g(i))}~\\sum_{j\\in d(g(j ) ) } [ u(g(i))]_i^{(i)}~[u(g(j))]_j^{(j)}\\times\\nonumber\\\\   & & \\,\\,\\,\\,\\,\\,\\,\\times\\sum_{k\\in j(g(i))}~ \\sum_{l\\in j(g(j ) ) } [ u(g(i))]_k^{(i ) } ~\\psi_{kl}~ [ u(g(j))]_l^{(j)}\\end{aligned}\\ ] ] and ( as in the case above with all @xmath153 ) automatically @xmath139",
    ".      the above construction might look like a free lunch , but it is not .",
    "let us start with the @xmath153 case ( first principal components only ) .",
    "for short lookbacks , the number of risk factors typically is too large : @xmath4 can easily be greater than @xmath25 , so .",
    "] @xmath154 is singular . in general ,",
    "the sample factor covariance matrix is singular if @xmath155 .",
    "we will deal with this issue below via the nested russian - doll risk model construction .",
    "this issue is further exacerbated in the multiple principal component construction ( with at least some @xmath156 ) as the number of risk factors @xmath157 is even larger .",
    "this too can be dealt with via the russian - doll construction .",
    "however , there is yet another caveat pertinent to using multiple principal components , irrespective of whether the factor covariance matrix is singular or not .",
    "the principal components are based on off - diagonal elements of @xmath51 and tend to be unstable out - of - sample , the first principal component typically being the most stable .",
    "so , for the sake of simplicity , below we will focus on the case with only first principal components .",
    "as discussed above , the sample factor covariance matrix @xmath15 is singular if the number of factors @xmath4 is greater than @xmath25 .",
    "the simple idea behind the russian - doll construction is to model such @xmath15 itself via yet another factor model matrix @xmath158 ( as opposed to computing it as a sample covariance matrix of the risk factors @xmath21 ) : , @xmath159 , @xmath160 , _ etc . _ to avoid confusion with @xmath9 , @xmath161 , @xmath15 , _ etc . _ ] @xmath162 where @xmath163 is the specific risk for the  normalized \" factor return @xmath164 ; @xmath165 , @xmath106 , @xmath108 is the corresponding factor loadings matrix ; and @xmath166 is the factor covariance matrix for the underlying risk factors @xmath167 , @xmath108 , where we assume that @xmath168 .",
    "if the smaller factor covariance matrix @xmath166 is still singular , we model it via yet another factor model with fewer risk factors , and so on  until the resulting factor covariance matrix is nonsingular .",
    "if , at the final stage , we are left with a single factor , then the resulting @xmath169 factor covariance matrix is automatically nonsingular ",
    "it is simply the sample variance of the remaining factor .        for the sake of completeness , above we included the step where the sample factor covariance matrix @xmath206 for the sectors is further approximated via a 1-factor model @xmath207 .",
    "if @xmath206 computed via ( [ theta.1 ] ) is nonsingular , then this last step can be omitted , so at the last stage we have @xmath109 factors ( as opposed to a single factor ) .",
    ", where @xmath208 ; ( ii ) for the industries @xmath209 , where @xmath210 ; ( iii ) for the sectors @xmath211 , where @xmath212 ; and ( iv ) for the  market \" @xmath213 , where @xmath214 .",
    "] similarly , if we have enough observations to compute the sample covariance matrix @xmath166 for the industries , we can stop at that stage . finally , note that in the above construction we are guaranteed to have @xmath215 , @xmath216 , @xmath217 and @xmath218 ( with the last equality occurring only for single - ticker sub - industries and not posing a problem",
    " see below ) .",
    "is nonsingular .",
    "indeed , for an arbitrary @xmath3-vector @xmath117 we have @xmath219 unless @xmath220 , @xmath221 , where @xmath222 . for such @xmath117 we have @xmath223 , where @xmath224 , @xmath225 , @xmath226 , and we have taken into account that by construction @xmath158 ( and its sub - matrix with @xmath227 ) is positive - definite , and also that @xmath228 , @xmath229 .",
    "more on this below . ] in appendix [ app.b ] we give the r code for building heterotic risk models .",
    "the model covariance matrix is given by @xmath9 defined in ( [ gamma.rd ] ) .",
    "for completeness , let us present it in the ",
    "canonical \" form : @xmath230 where @xmath231 where @xmath67 is defined in ( [ xi.rd ] ) ,",
    "@xmath232 is defined in ( [ u.rd ] ) , @xmath158 is defined in ( [ gamma.prime.rd ] ) , and we use the star superscript in the our factor covariance matrix @xmath233 ( which is nonsingular ) to distinguish it from the sample factor covariance matrix @xmath15 ( which is singular ) .    in many applications , such as portfolio optimization",
    ", one needs the inverse of the matrix @xmath234 .",
    "when we have no single - ticker sub - industries , the inverse is given by ( in matrix notation ) @xmath235 however , when there are some single - ticker sub - industries , the corresponding @xmath236 , @xmath229 ( @xmath237 ) , so ( [ gamma.inv ] )  breaks \" .",
    "happily , there is an easy  fix \" .",
    "this is because for such tickers the specific risk and factor risk are _",
    "indistinguishable_. recall that @xmath228 , @xmath229 , and @xmath238 , @xmath226 ( @xmath224 ) .",
    "we can rewrite @xmath9 via @xmath239 where : @xmath240 for @xmath221 ; @xmath241 for @xmath229 with arbitrary @xmath242 , @xmath243 ; @xmath244 if @xmath245 or @xmath246 or @xmath247 ; and @xmath248 for @xmath226 .",
    "( here we have taken into account that @xmath249 , @xmath229 . )",
    "now we can invert @xmath234 via @xmath250 note that , due to the factor model structure , to invert the @xmath12 matrix @xmath234 , we only need to invert two @xmath16 matrices @xmath251 and @xmath252 .",
    "if there are no single - ticker sub - industries , then @xmath253 itself has a factor model structure and involves inverting two @xmath254 matrices , one of which has a factor model structure , and so on .",
    "so , suppose we have built a complete heterotic risk model .",
    "how do we know it adds value ? _ i.e. _ , how do we know that the off - diagonal elements of the factor model covariance matrix @xmath9 are stable out - of - sample to the extent that they add value .",
    "we can run a horse race .",
    "there are many ways of doing this . here",
    "is one . for a given trading universe",
    "we compute some expected returns , _",
    "e.g. _ , based on overnight mean - reversion .",
    "we can construct a trading portfolio by using our heterotic risk model covariance matrix in the optimization whereby we maximize the sharpe ratio ( subject to the dollar neutrality constraint ) .",
    "on the other hand , we can run the same optimization with a diagonal sample covariance matrix @xmath255 subject to neutrality ( via linear homogeneous constraints ) w.r.t .",
    "the underlying heterotic risk factors ( plus dollar neutrality ) .",
    "in fact , optimization with such diagonal covariance matrix and subject to such linear homogeneous constraints is equivalent to a weighted cross - sectional regression with the loadings matrix ( over which the expected returns are regressed ) identified with the factor loadings matrix ( augmented by the intercept , _",
    "i.e. _ , the unit vector , for dollar neutrality ) and the regression weights identified with the inverse sample variances @xmath256 ( see ( kakushadze , 2015a ) for details ) .",
    "so , we will refer to the horse race as between optimization ( using the heterotic risk model ) and weighted regression ( with the aforementioned linear homogeneous constraints ) .",
    "let @xmath257 be the time series of stock prices , where @xmath105 labels the stocks , and @xmath258 labels the trading dates , with @xmath259 corresponding to the most recent date in the time series",
    ". the superscripts @xmath260 and @xmath261 ( unadjusted open and close prices ) and @xmath262 and @xmath263 ( open and close prices fully adjusted for splits and dividends ) will distinguish the corresponding prices , so , _",
    "e.g. _ , @xmath264 is the unadjusted close price .",
    "@xmath265 is the unadjusted daily volume ( in shares ) .",
    "also , for each date @xmath49 we define the overnight return as the previous - close - to - open return : @xmath266 this return will be used in the definition of the expected return in our mean - reversion alpha",
    ". we will also need the close - to - close return @xmath267 an out - of - sample ( see below ) time series of these returns will be used in constructing the heterotic risk model and computing , among other things , the sample variances @xmath28 . also note that all prices in the definitions of @xmath268 and @xmath269 are fully adjusted .",
    "we assume that : i ) the portfolio is established at the open ( or adjusted @xmath270 ) , is used in computing the expected return ( via @xmath268 ) and as the establishing fill price . ] with fills at the open prices @xmath271 ; ii ) it is liquidated at the close on the same day ",
    "so this is a purely intraday alpha  with fills at the close prices @xmath264 ; and iii ) there are no transaction costs or slippage  our aim here is not to build a realistic trading strategy , but to test that our heterotic risk model adds value to the alpha .",
    "the p&l for each stock @xmath272\\ ] ] where @xmath273 are the _ dollar _ holdings .",
    "the shares bought plus sold ( establishing plus liquidating trades ) for each stock on each day are computed via @xmath274 .      for the sake of simplicity , we select our universe based on the average daily dollar volume ( addv ) defined via ( note that @xmath275 is out - of - sample for each date @xmath49 ) : @xmath276 we take @xmath277 ( _ i.e. _ , one month ) , and then take our universe to be the top 2000 tickers by addv . to ensure that we do not inadvertently introduce a universe selection bias",
    ", we rebalance monthly ( every 21 trading days , to be precise ) . _",
    "i.e. _ , we break our 5-year backtest period ( see below ) into 21-day intervals , we compute the universe using addv ( which , in turn , is computed based on the 21-day period immediately preceding such interval ) , and use this universe during the entire such interval",
    ". we do have the survivorship bias as we take the data for the universe of tickers as of 9/6/2014 that have historical pricing data on http://finance.yahoo.com ( accessed on 9/6/2014 ) for the period 8/1/2008 through 9/5/2014 .",
    "we restrict this universe to include only u.s .",
    "listed common stocks and class shares ( no otcs , preferred shares , _ etc . _ ) with bics sector , industry and sub - industry assignments as of 9/6/2014 . however , as discussed in detail in section 7 of ( kakushadze , 2015a ) , the survivorship bias is not a leading effect in such backtests .",
    "we run our simulations over a period of 5 years ( more precisely , 1260 trading days going back from 9/5/2014 , inclusive ) .",
    "the annualized return - on - capital ( roc ) is computed as the average daily p&l divided by the intraday investment level @xmath278 ( with no leverage ) and multiplied by 252 . the annualized sharpe ratio ( sr )",
    "is computed as the daily sharpe ratio multiplied by @xmath279 .",
    "cents - per - share ( cps ) is computed as the total p&l divided by the total shares traded .",
    "we will always require that our portfolio be dollar neutral : @xmath280 we will further require neutrality @xmath281 with the three different incarnations for the loadings matrix @xmath282 ( for each trading day @xmath49 , so we omit the index @xmath49 ) in ( [ load.pc ] ) and ( [ load.het ] ) are computed for each trading date @xmath49 ( as opposed to , say , every 21 days  see below ) ; in ( [ load.sub ] ) they change only with the universe ( every 21 days).[fn.load ] ] defined via : @xmath283 here @xmath284 are the first @xmath285 principal components ( with the eigenvalues @xmath286 ) in ( [ load.pc ] ) does not affect the regression residuals below .",
    "] of the sample correlation matrix @xmath51 . for each date",
    "@xmath49 we take @xmath287 trading days as our lookback ( _ i.e. _ , the number of observations ) in the out - of - sample time series of close - to - close ( see ( [ c2c.ret ] ) ) returns @xmath288 ( based on which we compute the sample covariance ( correlation ) matrix @xmath289 ( @xmath290 ) for each @xmath49 ) , so the number of the nonvanishing eigenvalues @xmath291 is @xmath292 , and we take @xmath293 .",
    "further , the map @xmath111 between tickers and sub - industries is defined in ( [ g.map ] ) , and @xmath4 is the number of sub - industries . ) we deliberately take @xmath294 as opposed to @xmath295 ( see below ) . note that with ( [ load.sub ] ) the intercept is subsumed in @xmath282 as we have @xmath296 , so ( [ dn ] ) is automatic . ] finally , the vector @xmath232 in ( [ load.het ] ) is defined in ( [ u.rd ] ) .    for each date labeled by @xmath49 , we run cross - sectional regressions of the overnight ( see ( [ c2o.ret ] ) )",
    "returns @xmath268 over the corresponding loadings matrix , call it @xmath297 ( with indices suppressed ) , which has 3 different incarnations : i ) for principal components , @xmath297 is an @xmath298 matrix , whose first column in the intercept ( unit @xmath3-vector ) , and the remaining columns are populated by @xmath282 defined in ( [ load.pc ] ) ; ii ) for sub - industries , the elements of @xmath297 are the same as @xmath282 defined in ( [ load.sub ] ) ; and iii ) for heterotic risk factors , @xmath297 is an @xmath299 matrix , whose first column in the intercept ( unit @xmath3-vector ) , and the remaining columns are populated by @xmath282 defined in ( [ load.het ] ) .",
    "we take the regression weights to be @xmath300 . more precisely , to avoid unnecessary variations in the weights @xmath37 ( as such variations could result in unnecessary overtrading ) , we do not recompute @xmath37 daily but every 21 trading days , same as with the trading universe .    in the cases",
    "i)-iii ) above , we compute the residuals @xmath301 of the weighted regression and the dollar holdings @xmath273 via ( we use matrix notation and suppress indices ) : @xmath302\\\\   & & h_{is } \\equiv -{\\widetilde e}_{is } ~ { i\\over\\sum_{j=1}^n \\left|{\\widetilde e}_{js}\\right|}\\end{aligned}\\ ] ] where @xmath303 , we have dollar neutrality ( [ dn ] ) , having 0 cross - sectional means , which in turn is due to the intercept either being included ( the cases i ) and iii ) ) , or being subsumed in the loadings matrix @xmath297 ( the case ii ) ) . ] and @xmath304 ( the total _ intraday _ dollar investment level ( long plus short ) , which is the same for all dates @xmath49 ) .    the simulation results are given in table [ table2 ] and p&ls for the 3 cases i)-iii ) are plotted in figure 2 . for comparison purposes  and to alley any potential concerns that the results in table [ table2 ] may not hold for realistic position bounds , in table [ table3 ] we give the simulation results for the same cases i)-iii ) above with the strict bounds @xmath305 so not more than 1% of each stock s addv is bought or sold .",
    "we use the bounded regression algorithm and the r source code of ( kakushadze , 2015b ) to run these simulations .",
    "expectedly , the liquidity bounds ( [ liq ] ) lower roc and cps while improving sr , but in the same fashion for all 3 weighted regression alphas i)-iii ) . the results in tables",
    "[ table2 ] and [ table3 ] confirm our prior intuitive argument that the sub - industries outperform the principal components simply because they are more numerous .",
    "the heterotic risk factors outperform the sub - industries",
    ". however , this is largely an artifact of defining @xmath282 as in ( [ load.sub ] ) .",
    "if we take @xmath295 instead ( and augment the regression loadings matrix @xmath297 with the intercept for dollar neutrality ) , we will get ( without the bounds ( [ liq ] )  the results with the bounds are similar ) : roc = 51.62% , sr = 13.45 , cps = 2.26 . ]",
    "if we compute @xmath282 in ( [ load.pc ] ) and ( [ load.het ] ) every 21 trading days ( instead of daily  see fn .",
    "[ fn.load ] ) , the difference is very slight .",
    "_ e.g. _ , for the heterotic risk factors computed every 21 days ( with no bounds ) we get : roc = 51.66% , sr = 13.42 , cps = 2.26 .",
    "finally , let us also mention that , in the weighted regressions ii ) and iii ) , the dollar holdings for the tickers in the single - ticker sub - industries are automatically null .",
    "this is _ not _ the case for optimized alphas ( see below ) .",
    "generally , if single - ticker ( or small ) sub - industries are undesirable , one can  prune \" the industry hierarchy tree by merging ( single - ticker and/or small ) sub - industries at the industry level .      as mentioned above ,",
    "our goal is to determine whether the heterotic risk model construction adds value by comparing the simulated performance of the weighted regression alphas above to the simulated performance of the optimized alphas ( via maximizing the sharpe ratio ) based on the same expected returns @xmath268 . in maximizing the sharpe ratio",
    ", we use the heterotic risk model covariance matrix @xmath9 given by ( [ gamma.rd ] ) , which we compute every 21 trading days ( same as for the universe ) . for each date",
    "( we omit the index @xmath49 ) we maximize the sharpe ratio subject to the dollar neutrality constraint : @xmath306 the solution is given by @xmath307\\ ] ] where @xmath308 is the inverse of @xmath234 ( see subsection [ sub.inv ] ) , and the overall normalization constant @xmath309 ( this is a mean - reversion alpha ) is fixed via the requirement that @xmath310 note that ( [ h.opt ] ) satisfies the dollar neutrality constraint ( [ d.n.opt ] ) .",
    "the simulation results are given in table [ table2 ] in the bottom row .",
    "the p&l plot for this optimized alpha is included in figure 2 .",
    "for the same reasons as in the case of weighted regression alphas , in the bottom row of table [ table3 ] we give the simulation results for the same optimized alpha with the strict liquidity bounds ( [ liq ] ) . and",
    "[ table3 ] at the final stage the heterotic risk factors are the ( 10 ) bics sectors : there are enough ( 20 ) observations in the time series .",
    "the 1-factor model gives almost the same results .",
    "] we use the optimization algorithm for maximizing the sharpe ratio subject to linear homogeneous constraints and bounds discussed in ( kakushadze , 2015a ) .. it is similar to the source code of ( kakushadze , 2015b ) for the bounded regression . ] also , in the second rows in tables [ table2 ] and [ table3 ] we have included the simulation results for the optimized alpha where in the optimization we use the risk factor model covariance matrix @xmath9 based on the principal components discussed in section [ sub.pc ] . , where @xmath137 is defined in ( [ pc ] ) , and @xmath4 is determined via the algorithm of section [ sub.fix.k ] . for the @xmath277 trading day lookback in our backtests ,",
    "the value of @xmath4 fixed by this algorithm turns out to be @xmath311 . ] from our simulation results in tables [ table2 ] and [ table3 ] it is evident that the heterotic risk model predicts off - diagonal elements of the covariance matrix ( that is , correlations ) out - of - sample rather well . indeed , using it in",
    "the optimization sizably improves roc , sr and cps compared with the weighted regressions with all three loadings i)-iii ) above .",
    "the heterotic risk model construction we discuss in this paper is based on a  heterosis \" of : i ) granularity of an industry classification ; ii ) diagonality of the principal component factor covariance matrix for any sub - cluster of stocks ; and iii ) dramatic reduction of the size of the factor covariance matrix in the russian - doll construction .",
    "this is a powerful approach , as is evident from the horse race we ran above .",
    "naturally , one may wonder if we can extend our construction to risk models which do not include any statistical risk factors ( _ i.e. _ , principal components ) or include other non - binary factors such as style factors .",
    "a key simplifying feature in the heterotic construction is that the industry classification , which is used as the backbone ( and is augmented with the principal components to satisfy the conditions ( [ tot.risk ] ) ) , is binary .",
    "once non - binary risk factors are included , it is more nontrivial to compute the specific risk and the factor covariance matrix ( such that ( [ tot.risk ] ) are satisfied ) . however , there exist proprietary algorithms for dealing with this , which are outside of the scope of this paper .",
    "we hope to make these algorithms a public knowledge elsewhere .",
    "one final remark concerns purely statistical risk models based on principal components .",
    "albeit their market share is rather limited , it is unclear why a portfolio manager would be willing to pay for such models considering that they are straightforward to build in - house , especially now that we have provided the source code for constructing them .",
    "one argument is that using option implied volatility ( which is available only for optionable stocks ) to model stock volatility should work better , and if a portfolio manager does not possess the implied volatility data or the know - how for incorporating it into a statistical risk model , he or she would be better off simply buying one from a provider .",
    "however , this argument appears to be thin , at best .",
    "nowadays , with ever - shortening lookbacks , it is unclear if the implied volatility indeed adds any value when the risk model is used in actual portfolio optimization for actual alphas . in this regard",
    "a new study would appear to be warranted . in any event , as we saw above , heterotic risk models outperform principal component risk models by a significant margin , so one can build heterotic risk models in - house ( instead of buying less powerful statistical models ) now that this know - how is in the public domain .",
    "the only data needed to construct a heterotic risk model is : i ) adjusted close prices ; and ii ) a granular enough binary industry classification , such as gics , bics , icb , _ etc .",
    "_ most quantitative traders already have this data in - house .",
    "so , we hope this paper further encourages / aids organic custom risk model building .",
    "in this appendix we give the r ( r package for statistical computing , http://www.r-project.org ) source code for building a purely statistical risk model ( principal components ) based on the algorithm we discuss in section [ sub.pc ] , including the algorithm for fixing the number of factors @xmath4 in section [ sub.fix.k ] .",
    "the code below is essentially self - explanatory and straightforward .",
    "it consists of a single function .",
    "the input is : i ) , an @xmath312 matrix of returns ( _ e.g. _ , daily close - to - close returns ) , where @xmath3 is the number of tickers , @xmath313 is the number of observations in the time series ( _ e.g. _ , the number of trading days ) , and the ordering of the dates is immaterial ; and ii ) , where for ( default ) the risk factors are computed based on the principal components of the sample correlation matrix @xmath51 , whereas for they are computed based on the sample covariance matrix @xmath6 .",
    "the output is a list : is the specific risk @xmath13 ( not the specific variance @xmath314 ) , is the factor loadings matrix @xmath315 , is the factor covariance matrix @xmath15 ( with the normalization ( [ flm.pc ] ) for the factor loadings matrix , @xmath79 ) , is the factor model covariance matrix @xmath316 , and is the matrix @xmath317 inverse to @xmath9 .",
    "in this appendix we give the r source code for building the heterotic risk model based on the algorithm we discuss in section [ sub.het.rd ] .",
    "the code below is essentially self - explanatory and straightforward as it simply follows the formulas in section [ sub.het.rd ] .",
    "it consists of a single function .",
    "the input is : i ) , an @xmath312 matrix of returns ( _ e.g. _ , daily close - to - close returns ) , where @xmath3 is the number of tickers , @xmath313 is the number of observations in the time series ( _ e.g. _ , the number of trading days ) , and the ordering of the dates is immaterial ; ii ) is a list whose length _ a priori _ is arbitrary , and its elements are populated by the binary matrices ( with rows corresponding to tickers , so is @xmath3 ) corresponding to the levels in the input binary industry classification hierarchy in the order of decreasing granularity ( so , in the bics case is the @xmath5 matrix @xmath115 ( sub - industries ) , is the @xmath318 matrix @xmath319 ( industries ) , and is the @xmath320 matrix @xmath321 ( sectors ) , where the map @xmath111 is defined in ( [ g.map ] ) ( tickers to sub - industries ) , @xmath322 ( tickers to industries ) , and @xmath323 ( tickers to sectors ) , with the map @xmath112 ( sub - industries to industries ) defined in ( [ s.map ] ) , and the map @xmath113 ( industries to sectors ) defined in ( [ w.map ] ) ) ; iii ) , where for at the final step we have a single factor (  market \" ) , while for ( default ) the factors correspond to the least granular level in the industry classification hierarchy ; and iv ) , where for the tickers corresponding to the single - ticker clusters at the most granular level in the industry classification hierarchy ( in the bics case this would be the sub - industry level ) are dropped altogether , while for ( default ) the output universe is the same as the input universe .",
    "the output is a list : is the specific risk @xmath13 ( not the specific variance @xmath314 ) , is the factor loadings matrix @xmath315 , is the factor covariance matrix @xmath15 , is the factor model covariance matrix @xmath316 , and is the matrix @xmath317 inverse to @xmath9 .",
    "in this appendix we give the r source code for the optimization algorithm with linear homogeneous constraints and position bounds we use in section [ sub.opt ] .",
    "this code is similar to the code for the bounded regression algorithm discussed in detail in ( kakushadze , 2015b ) with one important difference , so our discussion here will be brief .",
    "the entry function is .",
    "the of are : , which is the @xmath3-vector of stock returns ( for a given date ) ; , a matrix whose columns are the coefficients of the homogeneous constraints , so is @xmath3 ( _ e.g. _ , if the sole constraint is the dollar neutrality constraint , then is an @xmath324 matrix with unit elements ) ; , which is the @xmath12 inverse factor model covariance matrix @xmath317 ; , which is the @xmath3-vector of the upper bounds @xmath325 on the weights @xmath326 ( see below ) ; , which is the @xmath3-vector of the lower bounds @xmath327 on the weights @xmath326 ; and , which is the desired precision with which the output weights @xmath326 , the @xmath3-vector of which returns , must satisfy the normalization condition @xmath328 . here",
    "the weights are defined as @xmath329 ( the dollar holdings over the total investment level ) .",
    "see ( kakushadze , 2015b ) for more detail .",
    "wherever the context so requires , the masculine gender includes the feminine and/or neuter , and the singular form includes the plural and _ vice versa_. the author of this paper (  author \" ) and his affiliates including without limitation quantigic@xmath2 solutions llc (  author s affiliates \" or  his affiliates \" ) make no implied or express warranties or any other representations whatsoever , including without limitation implied warranties of merchantability and fitness for a particular purpose , in connection with or with regard to the content of this paper including without limitation any code or algorithms contained herein (  content \" ) .",
    "the reader may use the content solely at his / her / its own risk and the reader shall have no claims whatsoever against the author or his affiliates and the author and his affiliates shall have no liability whatsoever to the reader or any third party whatsoever for any loss , expense , opportunity cost , damages or any other adverse effects whatsoever relating to or arising from the use of the content by the reader including without any limitation whatsoever : any direct , indirect , incidental , special , consequential or any other damages incurred by the reader , however caused and under any theory of liability ; any loss of profit ( whether incurred directly or indirectly ) , any loss of goodwill or reputation , any loss of data suffered , cost of procurement of substitute goods or services , or any other tangible or intangible loss ; any reliance placed by the reader on the completeness , accuracy or existence of the content or any other effect of using the content ; and any and all other adversities or negative effects the reader might encounter in using the content irrespective of whether the author or his affiliates is or are or should have been aware of such adversities or negative effects .    the r code included in appendix [ app.a ] , appendix [ app.b ] and appendix [ app.c ] hereof is part of the copyrighted r code of quantigic@xmath2 solutions llc and is provided herein with the express permission of quantigic@xmath2 solutions llc .",
    "the copyright owner retains all rights , title and interest in and to its copyrighted source code included in appendix [ app.a ] , appendix [ app.b ] and appendix [ app.c ] hereof and any and all copyrights therefor .",
    "black , f. , jensen , m. and scholes , m. ( 1972 ) the capital asset pricing model : some empirical tests . in : jensen , m. ( ed . )",
    "_ studies in the theory of capital markets_. new york , ny : praeger publishers , pp .",
    "79 - 121 .",
    "connor , g. and korajczyk , r. ( 2010 ) factor models in portfolio and asset pricing theory . in : guerard jr , j.b .",
    "( ed . ) _ handbook of portfolio construction : contemporary applications of markowitz techniques_. new york , ny : springer , pp .",
    "401 - 418 .",
    "forni , m. , hallin , m. , lippi , m. and reichlin , l. ( 2005 ) the generalized dynamic factor model : one - sided estimation and forecasting .",
    "_ journal of the american statistical association _",
    "100(471 ) : 830 - 840 .",
    "mukherjee , d. and mishra , a.k .",
    "( 2005 ) multifactor capital asset pricing model under alternative distributional specification .",
    "ssrn working papers series , http://ssrn.com/abstract=871398 ( december 29 , 2005 ) .",
    "treynor , j.l .",
    "( 1999 ) towards a theory of market value of risky assets . in : korajczyk , r. ( ed . ) _ asset pricing and portfolio performance : models , strategy , and performance metrics .",
    "_ london : risk publications .",
    ".first column : the number of principal components @xmath4 ; last column : @xmath99 defined in ( [ g ] ) ; min , 1st quartile , median , mean , 3rd quartile and max refer to the corresponding quantities for the ratio @xmath330 ( specific variance over total variance ) .",
    "the number of observations ( days ) in the time series is @xmath331 .",
    "the number of ( randomly selected ) stocks is @xmath332 .",
    "all quantities are rounded to 3 digits .",
    "the value of @xmath4 fixed via ( [ k ] ) is @xmath333 .",
    "see figure 1 for a density plot . [ cols= \" < , < , < , < , < , < , < , < \" , ]"
  ],
  "abstract_text": [
    "<S> we give a complete algorithm and source code for constructing what we refer to as heterotic risk models ( for equities ) , which combine : i ) granularity of an industry classification ; ii ) diagonality of the principal component factor covariance matrix for any sub - cluster of stocks ; and iii ) dramatic reduction of the factor covariance matrix size in the russian - doll risk model construction . </S>",
    "<S> this appears to prove a powerful approach for constructing out - of - sample stable short - lookback risk models . </S>",
    "<S> thus , for intraday mean - reversion alphas based on overnight returns , sharpe ratio optimization using our heterotic risk models sizably improves the performance characteristics compared to weighted regressions based on principal components or industry classification . </S>",
    "<S> we also give source code for : a ) building statistical risk models ; and ii ) sharpe ratio optimization with homogeneous linear constraints and position bounds .    * heterotic risk models *    zura kakushadze@xmath0@xmath1 solutions llc , and a full professor at free university of tbilisi . </S>",
    "<S> email : zura@quantigic.com ]    _ </S>",
    "<S> @xmath0 quantigic@xmath2 solutions llc _    _ 1127 high ridge road # 135 , stamford , ct 06905 solutions llc , the website or any of their other affiliates . </S>",
    "<S> the title of this paper is inspired by the heterotic string theory , with no substantive connection therewith . ] _    </S>",
    "<S> _ @xmath1 free university of tbilisi , business school & school of physics _    </S>",
    "<S> _ 240 , david agmashenebeli alley , tbilisi , 0159 , georgia _    ( april 30 , 2015 ) </S>"
  ]
}