{
  "article_text": [
    "item response theory ( irt ) models are frequently used in modeling dichotomous data from educational tests , since they allow separate assessment of the ability of examinees and effectiveness of the test items .",
    "a typical one - parameter irt model is of the form @xmath0 where @xmath1 indicates the ability of the @xmath2th person ; @xmath3 indicates the difficulty of the @xmath4th test item ; the item response variable @xmath5 could be either 0 or 1 , corresponding to whether the @xmath4th test item taken by the @xmath2th person is answered correctly or not ; and the item characteristic curve , @xmath6 , is a cumulative distribution function ( c.d.f . ) from a continuous distribution .",
    "when @xmath7 is the standard logistic c.d.f . , the one - parameter irt model ( [ it-11 ] ) becomes the famous rasch model @xmath8 if @xmath9 , where @xmath10 is the standard normal c.d.f .",
    ", then @xmath11 defines the one - parameter normal ogive or probit model .",
    "we will focus on the former model in the paper , for reasons to be discussed later , although analysis of the probit model is actually easier and can be done with a simplified version of the methodology developed here .",
    "the development of item response theory from the classical point of view owes much to the pioneering work of @xcite , rasche ( @xcite ) and their colleagues . among the many noteworthy contributions are @xcite and @xcite .    in classical irt",
    ", it is assumed that the @xmath5 are independent , given the person s ability @xmath1 and the difficulty levels @xmath3 .",
    "this is often referred to as the _ local independence _ assumption .",
    "there are situations in which this assumption is violated .",
    "one such is computer adaptive testing , wherein the selection of the next test item typically depends specifically on the previous questions and answers .",
    "the situation is less clear with what is studied herein , metametrics educational assessment program called computer adaptive instruction and testing ( cait ) . with cait",
    ", a test pool of articles is selected for the student based on an estimate of his / her current ability ; the student selects an article from this pool and the test questions ( described later ) are then generated before reading commences .",
    "thus , in the environment of the cait , the possible violation in the local independence would arise from sources such as article selection by the student and test questions related to the same article so that overall understanding of the article could affect all answers ; in this paper , such possible effects will be called _",
    "test effects_. other factors that could cause violation of the local independence include health status and emotional status of the student on a given day ; these will be referred to as _",
    "daily effects_. in the metametrics scenario , there had been no previous demonstration of the violation of the local independence through the presence of test effects or daily effects , and there was a considerable interest in establishing such presence for possible enhancement of current models .",
    "pioneering papers that addressed the local dependence were stout ( @xcite , @xcite ) , who introduced the essential dimensionality and the essential independence of a collection of test items , and @xcite , who considered the conditional dependence within identified subsets of items by allowing random effects in the analysis .",
    "more recent work in this direction is testlet response theory modeling , proposed by @xcite .",
    "they defined the testlet as a subset of items ; for example , they defined a reading comprehensive section in the sat as the testlet .",
    "they then modified the classic irt models by including a random effect term to represent the common factor affecting the responses in the testlet .",
    "another approach to handle the local dependence is by the introduction of markov structure , such as @xcite where the conjunctive irt kernel was introduced .",
    "a more recent paper concerned is @xcite , where they modified the rasch model by allowing the conditional probability of a response to an item to depend on the answer of a previous item .    for the modeling in this paper ,",
    "the random effect approach will be followed .",
    "indeed , two levels of random effects will be introduced to model the daily effects and test effects , respectively .",
    "another essential generalization of the irt model lies in their applicability to analyze longitudinal data , that is , to deal with scenarios in which an individual is tested repeatedly over time ; then , the interest typically centers on the growth of an ability of the individual .",
    "embretson ( @xcite ) and marvelde et al . (",
    "@xcite ) presented a multidimensional rasch model to represent the change of an ability as an initial ability and one or more modifiabilities .",
    "based on the belief that a person s ability growth would be increasing over time , @xcite , @xcite and johnson and raudenbush ( @xcite ) used linear or polynomial regression of the time variable to measure the growth of an ability ; their analysis required the same time span and testing points for all examinees .",
    "@xcite modeled the transition of a voting preference as a first - order markov process , where they assumed voting preference changes from the previous time point to a new point by a random shock ; this work did not incorporate a time trend . @xcite",
    "supposed that changes in a voting preference were subject to discrete agent - specific regime changes and modeled the indicator of the preference regime changes as a first - order markov process .",
    "bartolucci , pennoni and vittadini ( @xcite ) analyzed test scores in mathematics observed over 3 years for public and private middle school students by a multilevel latent markov rasch model , where they described the dynamic transition of different levels of the individual ability also via a first - order markov process .",
    "our approach to the longitudinal issue is based on a new class of dynamic linear models ( dlm s ) [ see west and harrison ( @xcite ) for background on dlm s ] .",
    "the literature on dlm s or state space models , in the framework considered here of longitudinal binomial data , includes , for example , @xcite , @xcite and czado and song ( @xcite ) and the last three papers mentioned in the previous paragraph .",
    "our models are distinguished from the literature by simultaneously allowing for the following features : ( i ) observations at variable and irregular time points ; ( ii )  continuously changing ability , but with incorporation of knowledge concerning trends ( e.g. , increasing ability over time ) in a nondogmatic way ( thus accommodating , say , a drop in reading ability over a summer vacation ) ; ( iii )  an analysis that is either individual or hierarchical across a group of individuals , the latter allowing for `` borrowing strength '' in estimates of certain overall parameters ; ( iv )  either a retrospective analysis based on the full data or a real - time analysis and prediction for an individual based on the data to date .",
    "moreover , we consider the case in which the test item difficulties are nominally specified , as in cait , where the test items are often computer - generated and have theoretically determined difficulties .",
    "the actual item difficulties are quite uncertain , however , this uncertainty is also accommodated in our analysis .",
    "previous papers that introduced random effects for item parameters include sinharay , johnson and williamson ( @xcite ) and deboeck ( @xcite ) .",
    "the model developed in this paper is motivated by cait testing , as developed by metametrics inc .",
    "the main applied goals are as follows :    * the original goal is to assess the appropriateness of the local independence assumption for this type of data .",
    "this evolves into the goal of better understanding the nature of the daily and test effects . *",
    "a second goal is to understand the growth in ability of students , by retrospectively producing the estimated growth trajectories of their latent abilities in the study . *",
    "a third goal is to enable on - line prediction of one s ability ( based solely on data obtained up to that point ) , to enable a better assignment of reading materials to match his / her ability and to enable teachers to better assist students .",
    "the data considered is from a school district in mississippi and consisted of 1983 students who registered over two years in a cait reading test program conducted by metametrics inc .",
    "the students were in different grades and entered and left the program at different times between 2007 and 2009 .",
    "individuals took tests on different days and had different time lapses between tests .",
    "because of the long periods of testing , a fully adaptive model accommodating continual changes in ability is needed .",
    "the data was generated during sessions in which a student read an article selected from a large bank of available articles .",
    "the articles in this bank had been assigned text complexity measured in lexiles , using the lexile receptive analyzer @xmath12 , a software developed by metametrics inc . to evaluate the semantic and syntactic complexity of a text .",
    "the lexile measure represents either an individual s reading ability or the complexity of a text .",
    "the scale for lexiles ranges from 0 to 1800 , with 0 indicating no reading ability and 1800 being the maximum .",
    "a session begins like this : a student selects from a generated list of articles having lexile complexities in a range targeted to the current estimate of the student s ability .",
    "for the selected article , a subset of words from the article are eligible to be _",
    "clozed _ , that is , removed and replaced by a blank .",
    "the computer , following a prescribed protocol , randomly selects a sample of the eligible words to be clozed and presents the article to the student with these words clozed .",
    "when a blank is encountered while reading the article , the student clicks it and then the true removed word along with three incorrect options called foils is presented . as with the target word , the foils are selected randomly according to a prescribed protocol .",
    "the student selects a word to fill in the blank from the four choices and an immediate feedback is provided in the form of the correct answer .",
    "the dichotomous items produced by this procedure are called `` auto - generated - cloze '' items .",
    "they are single - use items generated at the time of an encounter between a student and an article .",
    "if another student selects that same article to read , a new set of target words and foils is selected .",
    "although it is not strictly impossible for an individual item to be taken by more than one student , such an occurrence is highly improbable . as a consequence , it is not feasible to obtain data - based estimates of item calibration parameters .    instead , the difficulties of the items generated for an encounter between a student and an article can be modeled as a sample from an ensemble of item difficulties associated with the article .",
    "the text complexity in lexiles provides a theoretical value for the ensemble mean .",
    "an estimated student ability in combination with assumptions about the ensemble allows calculation of a predicted success rate for the encounter .",
    "a comparison of the observed success rate with predicted , aggregated over many encounters , provides a basis for assessing the viability of the assumptions incorporated into the model .",
    "the predicted success rates in table 1 in @xcite include the assumption that the mean of the ensemble of item difficulties for an article is given by its theoretical text complexity .",
    "the agreement with observed success rates supports that assumption .",
    "although metametrics data is typically presented in lexile units , there is a simple linear transformation from lexiles to logit units .",
    "we will utilize the more common logit units for all data and results in this paper . note that this also motivates the use of the logistic irt model in this paper  to preserve compatibility with the metametrics data .",
    "because of the complexity of the model considered ( and of the testbed data set ) , as well as the need to incorporate prior information into the model , the analysis will be carried out using bayesian methodology and markov chain monte carlo ( mcmc ) computational techniques .",
    "a side benefit of using these methodologies is that all uncertainties in all quantities are combined in the overall assessment of inferential uncertainty .",
    "the mcmc procedure utilizes a novel combination of gibbs sampling together with a block sampling scheme involving forward filtering and backward sampling .    in section  [ sec2 ]",
    "we formally describe the proposed models to capture the dynamic changes in a person s ability as well as the local dependence between item responses .",
    "section  [ sec3 ] presents the mcmc strategy to carry out the statistical inference .",
    "section  [ sec4 ] tests the methodology on some simulated examples ( where the truth is known ) .",
    "section  [ sec5 ] applies the proposed models to the metametrics data set .",
    "section  [ sec6 ] draws conclusions from both statistical and psychological sides , and points out some directions for future studies .",
    "this section formally introduces the proposed one - parameter dir model .",
    "although the focus is on generalizing one - parameter irt models , it would be straightforward to similarly generalize two - parameter or three - parameter irt models .      in a typical one - parameter irt model ( [ it-11 ] ) ,",
    "the index of the item response @xmath5 indicates the correctness of the @xmath2th person s answer to the @xmath4th question in a single test .",
    "consider the more involved situation in which the individual completes a series of tests within a given day and over different days .",
    "thus , the item response variable is @xmath13 , which corresponds to the correctness of the answer of the @xmath4th item in the @xmath14th test on the @xmath15th day taken by the @xmath2th person . here , @xmath16 ; @xmath17 ; @xmath18 ; and @xmath19 .",
    "likewise , let @xmath20 represent the difficulty level of the @xmath4th item in the @xmath14th test at the @xmath15th day taken by the @xmath2th person . as described in the , we model the test difficulties as being nominally specified , but with uncertainty .",
    "thus , we write @xmath21 where @xmath22 indicates the ensemble mean difficulty for the items in the @xmath14th test taken by the @xmath2th person on the @xmath15th day , and @xmath23 is the random deviation from this ensemble mean difficulty for the @xmath4th item within the @xmath14th test . in the scenario",
    "we consider , the value of @xmath22 is assumed to be known , from the theoretical analysis of text complexity , while it is assumed that @xmath23 is a normal distribution with zero mean and specified variance @xmath24 from the test design in the cait testing , which is denoted as @xmath25 .",
    "as mentioned in the , we will also incorporate a term of daily random effects , @xmath26 , as well as a term of test random effects , @xmath27 , to account for the possible local dependence factors when person @xmath2 takes several tests during day @xmath15 .",
    "it is assumed that @xmath28 and , letting @xmath29 denote the vector of test random effects on day @xmath15 for individual @xmath2 , that @xmath30 , with differing and unknown precision parameters @xmath31 and @xmath32 for each individual @xmath2 . here @xmath33 is an @xmath34 identity matrix .",
    "the multivariate normal distribution for @xmath35 is actually a singular multivariate normal distribution because it is conditioned on the sum of the day s test effects being zero , done to remove any possibility of confounding with the daily random effects .",
    "( in analysis and computation , this singular multivariate normal distribution is replaced by the corresponding lower - dimensional nonsingular multivariate normal distribution . )    finally , at the observation level , the dichotomous test data is modeled as @xmath36 where @xmath37 represents the @xmath2th person s ability on day @xmath15 ; we are thus assuming that a person s ability is constant over a given day , although there could be random fluctuations captured by the @xmath26 and @xmath27 .",
    "letting @xmath7 be the logistic c.d.f .",
    ", as previously discussed , results in @xmath38 \\\\[-8pt ] \\nonumber & & \\qquad=\\frac{\\exp(\\theta_{i , t}-a_{i , t , s}+\\varphi_{i , t}+\\eta_{i , t , s}+\\varepsilon _ { i , t , s , l } ) } { 1+\\exp(\\theta_{i , t}-a_{i , t , s}+\\varphi_{i , t}+\\eta_{i , t , s}+\\varepsilon _ { i , t , s , l } ) }   .\\end{aligned}\\ ] ]      as mentioned in the , both parametric growth models and markov chain models have been utilized in contexts similar to that of this paper .",
    "here we combine these ideas , through a generalization of dynamic linear models , to model an individual s ability growth trajectory over time .",
    "the proposed model is @xmath39 which has three terms , modeling how current ability , @xmath37 for the @xmath2th person on the @xmath15th day , relates to past ability and other factors .",
    "the first term is simply ability at the previous time point , @xmath40 .",
    "the second term is a parametric growth model . here",
    "@xmath41 can be thought of as the average growth rate of the @xmath2th person s ability over time and @xmath42 is the time lapse between the person s @xmath15th test day and @xmath43th test day but truncated by a pre - specified maximum time interval @xmath44 , that is , @xmath45 ; thus , @xmath46 would reflect the ability growth over the given time interval if the growth was indeed linear . however , this growth is truncated at @xmath44 ( chosen herein to be 14 days ) , reflecting the fact that , when on vacation , the student s ability may not be growing .",
    "furthermore , the growth rate often declines as ability increases ( indeed ability typically eventually plateaus ) , so that a linear growth model is often unsuitable when @xmath37 becomes large .",
    "the `` correction factor , '' @xmath47 in ( [ irt-13 ] ) , compensates for this effect , slowing down the linear growth as the ability level becomes larger .",
    "@xmath48 is the parameter controlling the rate of this adjustment , and could be known or unknown . in our testbed example , @xmath48 is known , based on experiments conducted at metametrics [ hanlon et al .",
    "( @xcite ) ] . in principle",
    ", @xmath48 should be individual - specific , but it is distinguishable from @xmath41 only as the individual s ability level is reaching maturation ; our investigation of ability growth in the testbed data focuses on early age students , so only the @xmath41 are made individual - specific .    as in all dynamic linear models ,",
    "the third term , @xmath49 in ( [ irt-13 ] ) , represents the random component of the change in the @xmath2th person s ability on the @xmath15th day .",
    "we assume it is @xmath50 , where @xmath51 is unknown .",
    "note that this presumes that the random component of a person s ability change has the variance proportional to the time period between test days .",
    "note , also , that we suppose that @xmath51 is common across individuals . the reason for this is clear from ( [ irt-12 ] ) ,",
    "in which @xmath52 have individual - specific @xmath31 ; there would be a substantial risk of confounding in the likelihood between @xmath31 s and @xmath53 if the time lapse between tests for the student were equally spaced .",
    "it is possible to rewrite ( [ irt-13 ] ) as a first - order markov process , and this is beneficial for computational reasons .",
    "indeed , letting @xmath54 and @xmath55 , the system equation ( [ irt-13 ] ) becomes @xmath56 where @xmath57 , and this is in the form of a standard dynamic linear model .",
    "( note that @xmath41 and @xmath51 need to be known for this reduction . )      to sum up , the one - parameter dir model is constructed in two levels as follows : @xmath58 where @xmath59 , @xmath60 , @xmath61 , @xmath62 , and @xmath63 , with the @xmath22 , @xmath48 , @xmath64 , @xmath44 and @xmath65 being known and @xmath37 , @xmath41 , @xmath51 , @xmath31 and @xmath66 being unknown .",
    "in this section the bayesian methods that will be used for statistical inference in dir models are described .",
    "computation is based on a gibbs sampling scheme , in conjunction with forward filtering and backward sampling .",
    "prior distributions in a bayesian analysis must be specified carefully , but they can be either evidence - based priors , reflecting scientific knowledge of the system under study , or they can be objective priors , reflecting a lack of such knowledge but possessing good overall properties  for example , good frequentist properties [ see , e.g. , @xcite ] ; a  mix of both will be used in the analysis herein .",
    "specification of evidence - based priors is , of course , context dependent and , here , will be done within the context of the metametrics testbed application .",
    "a natural choice of the prior distribution for an individual s initial latent ability , @xmath67 , is @xmath68 where @xmath69 and @xmath70 are the mean and the variance , on a logit scale , of the population ( @xmath71 ) to which the individual @xmath2 belongs  for instance , the individual s grade in school for the testbed application . for the average growth rate @xmath41 in system equation ( [ irt-13 ] ) ,",
    "the natural objective prior is a constant prior ( since @xmath41 is a linear parameter ) , but we constrain @xmath41 to be positive , reflecting the belief that there is a positive learning rate ; thus , we choose the prior @xmath72 although @xmath51 is a scale parameter , it occurs at the system - level of the two - stage model and , hence , the usual scale objective prior ( @xmath73 ) would result in an improper posterior ; the computationally simplest adjustment is to use @xmath74 , which does result in a proper posterior .",
    "similarly , for the scale parameters @xmath31 and @xmath66 we utilize the objective priors @xmath75 and @xmath76 . a natural alternative would be to try to `` borrow information '' across individuals , by utilizing gamma hyperpriors for the @xmath31 s and @xmath66 s .",
    "this complicates the computation , however , and does not seem necessary for the testbed application .      to facilitate the use of gibbs sampling techniques in computation , we utilize a mixture of normals representation of the logistic distribution",
    ". from andrews and mallow ( @xcite ) , if @xmath77 has a logistic distribution with location parameter 0 and scale @xmath78 ( @xmath79 , one can write the density as @xmath80\\pi(\\nu ) \\,d\\nu,\\ ] ] where @xmath81 has the kolmogorov ",
    "smirnov ( k  s ) density @xmath82 note that the density in square brackets in ( [ log - density ] ) is @xmath83 . by using the idea of data augmentation from @xcite",
    ", we consider the latent variable @xmath84 for each response variable @xmath13 , where @xmath85 and define @xmath86 if @xmath87 and @xmath88 otherwise .",
    "it is then easy to show that @xmath89 , so that the introduction of the latent variables @xmath84 will not alter the model ( except that there are now formally many more unknown parameters ) .",
    "as @xmath90 , it can be marginalized out in the distribution of @xmath84 , resulting in @xmath91 . therefore , the one - parameter dir models ( [ irt-12 ] ) and ( [ irt-13 ] ) can be rewritten , with latent variables @xmath92 , as @xmath93 y_{i , t , s , l } & = & \\theta_{i , t}-a_{i , t , s}+\\varphi_{i , t}+ \\eta_{i , t , s}+\\xi_{i , t , s , l } , \\label{sm-12 } \\\\[-2pt ] \\nu_{i , t , s , l}&\\sim & \\mbox{k -- s distribution } , \\label{sm-13}\\end{aligned}\\ ] ] where @xmath59 , @xmath61 , @xmath94 , and @xmath95 with @xmath96 .    define @xmath97 , where @xmath98 for @xmath16 ; @xmath99 and @xmath100 ; @xmath101 , @xmath102 and @xmath103 for @xmath19 , @xmath104 , @xmath105 and @xmath106 ; @xmath107 for @xmath108 , @xmath16 ; @xmath109 for @xmath110 , @xmath105 and @xmath106 and @xmath111 . then the joint posterior density of @xmath112 , @xmath77 , @xmath113 , @xmath114 , @xmath115 , @xmath116 , @xmath81 and @xmath51 given the data @xmath117 , in the one - parameter dir model , is proportional to @xmath118 & & \\hspace*{-4pt}\\qquad\\propto \\biggl\\{\\prod_{i=1}^n\\pi ( \\theta_{i,0})\\pi(c_i)\\pi(\\delta_i)\\pi ( \\tau_i ) \\biggr\\}\\pi(\\phi ) \\biggl\\{\\prod_{i=1}^n \\prod_{t=1}^{t_i } \\prod _ { s=1}^{s_{i , t}}\\prod_{l=1}^{k_{i , t , s } } \\pi(\\nu_{i , t , s , l } ) \\biggr\\ } \\nonumber \\\\[-2pt ] & & \\hspace*{-4pt}\\qquad\\quad{}\\times \\biggl\\{\\prod_{i=1}^n \\prod _ { t=1}^{t_i } \\prod _ { s=1}^{s_{i , t}}\\prod_{l=1}^{k_{i , t , s } } \\bigl(i\\{y_{i , t , s , l}>0\\}i\\{x_{i , t , s , l}=1\\}\\nonumber\\\\ & & \\hspace*{-4pt}\\hspace*{87pt}{}\\qquad\\quad+i\\{y_{i , t , s ,",
    "l}\\leq0\\}i \\{x_{i , t , s , l}=0\\ } \\bigr ) \\nonumber\\\\[-2pt ] & & \\hspace*{-4pt}\\hspace*{81pt}\\qquad\\quad{}\\times   \\sqrt{\\frac{\\psi_{i , t , s , l}}{2\\pi}}\\nonumber \\\\[-9pt ] \\\\[-9pt ] \\nonumber & & \\hspace*{-4pt}\\hspace*{81pt}\\quad\\qquad{}\\times\\exp\\biggl(-\\frac{\\psi _ { i , t , s , l}(y_{i , t , s , l}- \\theta_{i , t}+a_{i , t , s}-\\varphi_{i , t}-\\eta_{i , t , s})^2}{2}\\biggr)\\\\[-2pt ] & & \\hspace*{-4pt}\\hspace*{190pt}\\qquad\\quad{}\\times i\\biggl\\ { \\eta_{i , t , s_{i , t}}=-\\sum_{s=1}^{s_{i , t}-1 } \\eta_{i , t , s}\\biggr\\ } \\biggr\\ } \\nonumber\\\\ & & \\hspace*{-4pt}\\qquad\\quad{}\\times   \\biggl\\{\\prod_{i=1}^n \\prod _ { t=1}^{t_i}\\biggl(\\frac{\\tau_i}{2 \\pi } \\biggr)^{{(s_{i , t}-1)}/{2}}\\exp\\biggl(-\\frac{\\tau_i{\\eta _ { i , t}^{*\\prime}}\\sigma_{i , t}^{-1}\\eta_{i , t}^*}{2}\\biggr ) \\biggr\\ } \\nonumber\\\\ & & \\hspace*{-4pt}\\qquad\\quad{}\\times\\biggl\\ { \\prod _ { i-1}^n \\prod _ { t=1}^{t_i}\\sqrt{\\frac{\\delta_i}{2\\pi}}\\exp\\biggl(- \\frac{\\delta_i\\varphi_{i , t}^2}{2}\\biggr ) \\biggr\\ } \\nonumber \\\\ & & \\hspace*{-4pt}\\qquad\\quad{}\\times   \\biggl\\{\\prod_{i=1}^n \\prod _ { t=1}^{t_i } \\sqrt\\frac{\\phi}{2\\pi\\delta_{i , t}}\\exp \\biggl(-\\frac{\\phi\\{\\theta_{i , t}-\\theta_{i , t-1}-c_i(1-\\rho\\theta _ { i , t-1})\\delta_{i , t}^{+}\\}^2}{2\\delta_{i , t}}\\biggr ) \\biggr\\ } , \\nonumber\\end{aligned}\\ ] ] where @xmath119 and @xmath120 is the indicator function equal to @xmath121 if the random variable @xmath122 is contained in the set @xmath123 ; @xmath124 , @xmath125 , @xmath126 , @xmath127 , @xmath128 are the priors specified in the previous subsection , and @xmath129 is the k  s density defined at the beginning of this subsection .",
    "this is a proper posterior under very mild conditions ; see appendix  [ appc ] .",
    "computation is done by a mcmc scheme that samples from the posterior ( [ sm-14 ] ) via a block gibbs sampling scheme , utilizing the forward filtering and backward sampling algorithm at a key point .",
    "the steps of the algorithm are given in appendix  [ appa ] .    from the mcmc samples , statistical inferences are straightforward .",
    "for example , an estimate and @xmath130 credible interval for the latent ability trait @xmath37 can be formed from the median , @xmath131 , and @xmath132 empirical quantiles of the corresponding mcmc realizations . in examples ,",
    "these will be graphed as a function of @xmath15 so that the adaptive nature of the model is apparent .",
    "in this section a simulated example is used to illustrate the inferences from the proposed one - parameter dir models and to study their properties , primarily from a frequentist perspective .",
    "the simulation examines the model s behavior for multiple individuals taking a series of tests that are scheduled during different time periods .",
    "in particular , suppose there are 10 individuals and each individual has taken tests on 50 different days .",
    "thus , @xmath133 and @xmath134 , for @xmath135 . during each distinctive test day , the individual takes four tests ; thus , @xmath136 for @xmath137 , @xmath135 .",
    "each test consists of 10 items , so that @xmath138 for @xmath139 , @xmath140 and @xmath141 . for",
    "the @xmath2th person , the time lapse between two different tests is assumed to be a function of the @xmath15th day , that is , @xmath142 , for @xmath135 , @xmath143 and @xmath144 , for @xmath145 . finally , the unknown values of parameters in the models are chosen as follows :    * @xmath146 , and the corresponding standard deviation of the random component @xmath49 in system equation ( [ irt-13 ] ) is @xmath147 .",
    "* @xmath148 , where each element in the vector @xmath113 corresponds to the @xmath2th person s average growth rate , respectively , for @xmath135 .",
    "* @xmath149,where each element in the vector @xmath150 corresponds to the precision parameter of daily random effects for the @xmath2th person , respectively , @xmath135 .",
    "* @xmath151,where each element in the vector @xmath114 corresponds to the precision parameter of test random effects for the @xmath2th person , respectively , @xmath135 .",
    "according to the observation equation ( [ irt-12 ] ) , we then simulated values for the unknown variables and set the test difficulties , @xmath22 , to be @xmath152 , where @xmath153 is a random variable with uniform distribution on ( @xmath154 ) .",
    "the values of @xmath23 were drawn from @xmath155 and the value of @xmath156 is used in the test design for metametrics . finally , we chose @xmath157 , which is the value estimated by metametrics in their studies [ @xcite ] .    from dichotomous data obtained from the simulation ,",
    "the bayesian machinery from section  [ sec3 ] was used in estimating the model parameters in ( [ irt-12 ] ) and ( [ irt-13 ] ) . figure  [ fig-22 ] shows estimates of the ability trajectory for the @xmath121st , @xmath158rd , @xmath159th and @xmath160th individuals .",
    "the red dots in the figures correspond to the estimated posterior median of the ability @xmath37 at the @xmath15th day for the @xmath2th person , and the red dashed lines give the 2.5% and 97.5% quantile trajectories of @xmath37 , for @xmath137 .",
    "the black dots are the real abilities at the @xmath15th day for the @xmath2th person in the simulation .",
    "the third trajectory is typical of what is expected in terms of increasing ability , and is smoothly handled by the bayesian machinery .",
    "the other three trajectories are highly nonmonotonic ; the bayesian estimates err in trying to be increasing ( as they are designed to do ) , but do adapt to the nonmonotonicity when the evidence becomes strong enough .",
    "one method of evaluating the success of the inferential scheme is to evaluate the percentage of time that the true ability , @xmath37 , is contained in the @xmath130 credible interval of estimated ability for each individual .",
    "for the ten individuals , these estimated coverages were @xmath161 , @xmath161 , @xmath162 , @xmath162 , @xmath161 , @xmath161 , @xmath163 , @xmath161 , @xmath161 and @xmath164 , which produce an overall estimated coverage of @xmath165 .",
    "thus , while the inferential method is bayesian , it seems to be yielding sets that have good frequentist coverage .        , @xmath166 and @xmath167 , for @xmath135 with the simulated data . ]    to summarize the results for the @xmath41 s , @xmath168 s and @xmath169 s , we compare their true values with the corresponding estimated values in figure  [ fig-23 ] . in these plots ,",
    "the black bar represents the 95% credible interval of the posterior distribution .",
    "the blue plus stands for the estimated posterior median and the red cross is the true value in the simulation .",
    "moreover , the estimated posterior median of @xmath170 is @xmath171 and its 95% credible interval is @xmath172 $ ] .",
    "note that the true values of the @xmath41 s , @xmath168 s , @xmath169 s and @xmath51 are all contained in the 95% credible intervals except @xmath173 ; thus , the empirical coverage for these parameters is @xmath174 .",
    "in this section we apply the dir model to the testbed metametrics data .",
    "a sample of @xmath175 individuals from the data base of students in certain elementary schools in mississippi is considered here ; the differing characteristics of the students are described in appendix [ appb ] .",
    "the primary focus is study of the goals mentioned in section  [ sec1.2 ] .",
    "first consider retrospective estimation of the reading ability for an individual , utilizing all the data recorded for that individual .",
    "figure  [ fig-31 ] presents the resulting growth trajectories for the @xmath158rd , @xmath176th , @xmath177th and @xmath175th individuals studied . in figure [ fig-31 ]",
    "the red dots are the posterior median estimates of each individual ability and the red dashes correspond to the @xmath131 and @xmath132 quantiles of the posterior distributions of the abilities , while the green dots correspond to estimates of an individual s abilities obtained by solving the equation that the expectation of expected score for a person s ability is equivalent to the observed score ; these can roughly be thought of as the raw test scores put on the same scale as the @xmath37 .",
    "the most interesting feature of these growth trajectories is that , while indeed there typically does appear to be overall growth in ability , this growth need not be monotone . in particular , when there is a large time gap between subsequent tests , the ability appears to drop for some individuals .",
    "one natural explanation is that , during vacations , a student may not read and could actually lose ability .",
    "another possible explanation is that the student has become less adept at implementation of cait after a long break.=-1    s , @xmath169 s and @xmath41 s with the metametrics data set . ]",
    "figure  [ fig-24 ] gives the summaries of the posterior distributions of the standard deviations of test random effects , @xmath168 s , the standard deviations of the daily random effects , @xmath169 s , and the average growth rates , @xmath41 s , for @xmath178 .",
    "moreover , the estimated posterior median of @xmath170 is @xmath179 and its 95% credible interval is @xmath180 $ ] .    figures  [ fig-24](a ) and ( b ) show that the standard deviations of two random effects are almost all quite large with 95% credible intervals well separated from zero .",
    "recall that these were included in the model to account for a possible lack of the local independence ; the evidence is thus strong that the local independence is , indeed , not tenable for this data and that both types of random effects are present .",
    "the consistency of the standard deviations of the random effects across individuals is somewhat surprising , but lends credence to the notion that random effect modeling of the local dependence is fruitful .      in on - line estimation of reading ability ,",
    "essentially the same model is used , but , at each time point , only the data up to that time is utilized .",
    "instead of having @xmath170 unknown , however , we utilize @xmath181 , the estimate arising from the retrospective analysis ; @xmath170 can not be effectively estimated in an on - line mode .    applying the bayesian methodology yields on - line posterior median ability estimates , as well as the @xmath131 and @xmath132 quantiles of the posterior distribution of abilities for the @xmath175 individuals being studied",
    "; these are the purple dots and and dashed purple lines in figure  [ fig-41 ] , shown for the @xmath158rd , @xmath176th , @xmath177th and @xmath175th individuals .",
    "again , the green dots show the raw score estimates of each individual ability at each time point , and the red dots are the retrospective estimates discussed earlier . in these figures",
    "we also include , as blue dots , the ability estimates obtained from the current methodology of metametrics , which is a partial bayesian procedure .",
    "as expected , the on - line ability estimates are much more variable than the retrospective estimates .",
    "sometimes , the on - line estimates seem to be somewhat more variable than the current metametrics estimates ( the blue dots ) .",
    "this is because at each online estimation point , the current methodology of metametrics uses a very tight prior ( arising from the previous data ) for the student s ability .",
    "while we do not know the truth here , it is plausible that the retrospective red dots are our best guesses as to the true abilities , and we can then judge how well the various on - line procedures are doing relative to these best guesses .",
    "our on - line estimates are generally closer to these retrospective estimates than the current metametrics estimates ( the 12th individual being the interesting exception ) . in fact , the average mean squared error of our on - line estimates relative to the retrospective estimates is @xmath182 , while the average mean squared error of the current metametrics estimates is @xmath183 .",
    "if we do view the retrospective estimates ( red dots ) as surrogates for the truth , it is interesting to see how often these fall outside the on - line uncertainty bands ( purple lines ) .",
    "this happened very rarely ; individual @xmath177 in figure  [ fig-41 ] was one case in which this sometimes happened .",
    "one final observation from figure [ fig-41 ] is that the current metametric estimates usually are lower than our on - line estimates of the person s reading ability .",
    "the evidence of violation of the local dependence assumption in cait situations is generally strong , and use of test and daily random effects to model the local dependence seems to be necessary and successful .",
    "embedding a dynamic linear model framework for an individual s ability trajectory within the logistic irt structure provides a powerful and individually adaptive method for dealing with longitudinal testing data .",
    "the retrospective dir model analysis seems excellent for assessing actual ability trajectories and , hence , is of considerable use in understanding population behavior , such as the frequently observed drops in ability after a long pause in testing .",
    "the on - line dir analysis provides real - time ability estimates for assignments of material at the right difficulty level and other possible educational goals .",
    "a key advantage of the bayesian framework adopted is that uncertainty in all unknowns can be built into the model ( e.g. , uncertainty in the difficulty of the random test items ) , and uncertainty of the estimates is available for all inferences . also",
    ", prior information ( e.g. , knowledge about ability distributions over the population and knowledge that general growth in ability is expected ) can be built into the analysis , in a nondogmatic fashion that allows the data to overrule the prior .",
    "many extensions are possible , such as the already mentioned extension to two - parameter and three - parameter irt models .",
    "if one also had data for individuals over a period of many years  including years near the maturation point in one s reading ability  it would be possible to include individual - specific @xmath184 in the model .",
    "the mcmc scheme that will be used to sample from the posterior ( [ sm-14 ] ) is a block gibbs sampling scheme , utilizing the forward filtering and backward sampling algorithm at a key point . because of the block gibbs sampling scheme",
    ", we need only specify the conditional distributions of a block of variables given the data and other unknown variables .      given @xmath112 , @xmath115 , @xmath116 and @xmath81 ,",
    "the latent variables @xmath92 are sampled from @xmath185 where @xmath186 means the normal distribution truncated at the left by zero , while @xmath187 is the normal distribution truncated at the right by zero and @xmath96 . sampling from truncated normals is fast and easy .",
    "the latent ability vector @xmath188 , for each individual , is typically high - dimensional with highly correlated coordinates , so sampling of the variables would appear to be highly challenging . to overcome this roadblock ,",
    "the proposed model is transformed so that @xmath1 could be block sampled  within a gibbs sampling step conditional on the other parameters  by the highly efficient forward filtering and backward sampling algorithm .    to see this , consider @xmath51 , @xmath113 , @xmath77 , @xmath115 , @xmath116 and @xmath81 as given ( the gibbs sampling step ) .",
    "define @xmath189 and utilize the formulation of the model in ( [ irt-14 ] ) .",
    "then , the ( conditional ) one - parameter dir model fits the framework of dynamic linear models [ @xcite ] , that  is , @xmath190 where @xmath191 , @xmath192 with @xmath96 . as indicated in @xcite ,",
    "the forward filtering and backward sampling algorithm to block update each vector @xmath1 proceeds as follows .    since @xmath193 and @xmath194 , the conditional prior for @xmath195 is @xmath196 .",
    "define information available on the @xmath15th day for the @xmath2th person as @xmath197 we claim that the posterior distribution of @xmath198 is then @xmath199 which can be verified by induction as follows .",
    "assume that , on the @xmath43th day , the posterior of @xmath200 , given @xmath201 , is @xmath202 .",
    "and it is easy to see this assumption is true when @xmath203 .",
    "then , from the system equation , it is easy to establish that @xmath204 is a prior for @xmath198 , where @xmath205 and @xmath206 .",
    "therefore , we have @xmath207 then , at the @xmath15th day , the posterior distribution of @xmath198 is as ( [ sq-11 ] ) , where @xmath208 and @xmath209 .",
    "the above updating procedure is called forward filtering and after it is complete and all quantities , that is , @xmath210 and @xmath211 are saved , we can begin the backward sampling of @xmath198 . for the time @xmath212 , we sample @xmath198 directly from @xmath213 . as the time from @xmath214 to @xmath215 , at each time we draw @xmath198 from @xmath216 where @xmath217 and @xmath218 .",
    "this follows from @xmath219 thus , for @xmath220 , we set @xmath221 and each vector @xmath222 is sampled as a whole block , noticing that @xmath223      when @xmath112 and @xmath51 are given , the full conditional distribution of @xmath41 is the truncated normal distribution @xmath224      when @xmath112 , @xmath115 , @xmath114 , @xmath77 and @xmath81 are given , if @xmath225 , then the full conditional distribution of @xmath226 is the multivariate normal distribution @xmath227 where @xmath228 , @xmath229 , @xmath230 where @xmath231 is a @xmath232-dimensional column vector with each element being 1 and @xmath233 .",
    "when @xmath234 , @xmath235 .      when @xmath116 is given , the full conditional distribution of @xmath32 is the gamma distribution @xmath236      when @xmath112 , @xmath116 , @xmath150 , @xmath77 and @xmath81 are given , the full conditional distribution of @xmath26 is the normal distribution @xmath237      when @xmath115 is given , the full conditional distribution of @xmath238 is the gamma distribution @xmath239      when @xmath240 is given , the full conditional distribution of @xmath51 is the gamma distribution @xmath241      given @xmath77 , @xmath112 , @xmath115 and @xmath116 , the full conditional distribution of @xmath242 is proportional to @xmath243 which is not in closed form .",
    "so we shall resort to a metropolis ",
    "hastings scheme to sample this distribution .",
    "a suitable proposal for sample @xmath81 is the k  s distribution itself .",
    "thus , we first sample @xmath81 from the k  s distribution whose density is defined in ( [ ks-11 ] ) .",
    "then , we let @xmath244 where , given @xmath77 , @xmath112 , @xmath115 and @xmath116 , @xmath245 and @xmath246 indicates the @xmath246th iteration step in mcmc .",
    "the gibbs sampling starts at  [ a-11 ] , with initial values for @xmath247 , @xmath248 , @xmath249 , @xmath250 , @xmath251 , @xmath252 , @xmath253 and @xmath254 , and then loops through  [ a-12 ] until the mcmc has converged .",
    "the initial values chosen in the applications were @xmath255 , @xmath256 , @xmath257 , @xmath258 , @xmath259 , @xmath260 , @xmath261 and @xmath262 , where we used `` @xmath263 '' here to indicate that each element of the corresponding vector or set has the same value `` @xmath264 '' .",
    "the convergence was evaluated informally by looking at trace plots , and was found to obtain at most after 30,000 of 50,000 iterations in the examples .",
    "twenty - five individuals from the metametrics data base are studied in detail ; the characteristics of the data for these individuals are described in table  [ characteristics ] .",
    "@ld3.0d3.0d2.0cd3.0c@ & & & & & & + no .  1 & 147 & 73 & 8 & 425 & 105 & 4 + no .  2 & 162 & 64 & 9 & 317 & 102 & 2 + no .  3 & 118 & 77 & 4 & 321 & 87 & 2 + no .  4 & 93 & 53 & 4 & 525 & 147 & 2 + no .  5 & 114 & 89 & 3 & 625 & 109 & 2 + no .  6 & 157 & 57 & 29 & 420 & 116 & 2 + no .",
    "7 & 153 & 63 & 7 & 420 & 97 & 2 + no .  8 & 60 & 50 & 5 & 324 & 168 & 6 + no .  9 & 135 & 53 & 7 & 424 & 93 & 2 + no .  10 & 137 & 54 & 6 & 417 & 219 & 1 + no .  11 & 214 & 100 & 11 & 318 & 108 & 2 + no .  12 & 113 & 76 & 4 & 416 & 45 & 2 + no .  13 & 95 & 65 & 4 & 414 & 113 & 2 + no .  14 & 116 & 57 & 6 & 517 & 107 & 2 + no .  15 & 155 & 71 & 9 & 420 & 107 & 1 + no .  16 & 247 & 76 & 13 & 319 & 113 & 2 + no .  17 & 254 & 76 & 12 & 318 & 107 & 2 + no .  18 & 304 & 53 & 31 & 312 & 49 & 2 + no .  19 & 167 & 83 & 5 & 323 & 58 & 2 + no .  20 & 101 & 68 & 9 & 423 & 117 & 2 + no .  21 & 88 & 58 & 9 & 323 & 110 & 2 + no .  22 & 220 & 96 & 8 & 223 & 104 & 3 + no .  23 & 80 & 66 & 6 & 225 & 93 & 6 + no .  24 & 105 & 60 & 6 & 624 & 62 & 3 + no .  25 & 218 & 74 & 12 & 325 & 113 & 2 +",
    "suppose @xmath265 and , for @xmath16 , @xmath266 and @xmath267 for at least two days @xmath268 with at least two of the tests on each of the two days having at least one 0 and one 1 observation",
    ". then the posterior density of the dir model is proper .",
    "we first give some needed lemmas that may be of independent interest for proving posterior propriety in other logistic modeling scenarios .",
    "proofs of these lemmas are given in appendix a of @xcite .",
    "[ lem-11 ] for any three real numbers @xmath269 , @xmath270 and @xmath271 , @xmath272    [ lem-12 ] for @xmath273 , @xmath274 , @xmath275 with some constant @xmath232 .",
    "[ lem-13 ] for @xmath273 , @xmath274 , @xmath276 with some constant @xmath232 .",
    "[ lem-14 ] for @xmath277 , @xmath278 where @xmath279 and we have dropped the label @xmath2 in the subscripts for @xmath64 , @xmath41 , @xmath69 and @xmath70 .",
    "[ lem-15 ] for @xmath277 , @xmath280 with @xmath281 and @xmath282 defined in lemma  [ lem-14 ] .    in proving posterior propriety , it is easiest to work with the posterior density without the data augmentation , namely , @xmath283 } { 1+\\exp(\\theta_{i , t}-a_{i , t , s}+\\varphi_{i , t}+\\eta_{i , t , s}+\\varepsilon _ { i , t , s , l})}\\nonumber\\hspace*{-32pt}\\\\ & & \\hspace*{196pt}{}\\times i\\biggl\\{\\eta_{i , t , s_{i , t}}=-\\sum_{s=1}^{s_{i , t}-1 } \\eta_{i , t , s}\\biggr\\ } \\biggr\\ } \\nonumber\\hspace*{-32pt } \\\\ & & \\qquad\\times   \\biggl\\{\\prod_{i=1}^n \\prod _ { t=1}^{t_i } \\sqrt\\frac{\\phi}{2\\pi\\delta_{i , t}}\\exp \\biggl(-\\frac{\\phi\\{\\theta_{i , t}-\\theta_{i , t-1}-c_i(1-\\rho\\theta_{i , t-1 } ) \\delta_{i , t}^+\\}^2}{2\\delta_{i , t } } \\biggr ) \\biggr\\ } .\\hspace*{-32pt } \\nonumber\\end{aligned}\\ ] ] noting that @xmath284 } { 1+\\exp(\\theta_{i , t}-a_{i , t , s}+\\varphi_{i , t}+\\eta_{i , t , s}+\\varepsilon _ { i , t , s , l } ) } \\leq1 , \\ ] ] an upper bound on the posterior density can be found by dropping all terms except the 0 and 1 test observations in the assumed tests for each individual",
    ". utilizing lemma  [ lem-11 ] for each pair of observations 0 and 1 then results in the following upper bound on the posterior density ( [ eqn-119 ] ) : @xmath285 ignoring multiplicative constants , and integrating out all the @xmath23 , ( [ eqn - a11 ] ) has an upper bound of @xmath286 we only consider here the `` least information '' case in which ; the more general case can be done similarly .",
    "then @xmath287 , @xmath288 , @xmath289 , and @xmath290 . using this in ( [ eqn-13 ] ) and integrating out all other @xmath116 except for @xmath291 and @xmath292 and all @xmath115 except for @xmath293 and @xmath294 , results in the expression @xmath295",
    "next integrate out over @xmath66 , @xmath291 and @xmath296 using lemma  [ lem-12 ] , resulting in the upper bound ( again ignoring multiplicative constants ) @xmath297 next integrate out @xmath31 , @xmath293 and @xmath294 using lemma  [ lem-13 ] .",
    "the resulting upper bound on  ( [ eqn-14 ] ) is @xmath298 integrating out all the @xmath37 except the @xmath299 results in the expression @xmath300 \\\\[-8pt ] \\nonumber & & \\hspace*{136pt}\\qquad{}+\\phi v_{g_{j_i } } \\prod_{t=1}^{t_i ' } \\bigl(1-c_i\\rho\\delta_{i , t}^+\\bigr)^2\\biggr ) \\biggr)^{1/2 } \\\\ & & { } \\qquad\\times \\exp\\biggl(-\\biggl(\\phi\\biggl(\\theta_{i , t_i'}-\\mu_{g_{j_i}}\\prod _ { t=1}^{t_i'}\\bigl(1-c_i\\rho\\delta_{i , t}^+\\bigr)\\nonumber\\\\ & & \\hspace*{53pt}\\qquad\\quad{}-\\sum_{t=1}^{t_i ' } c_i\\delta_{i , t}^+\\prod_{i = t+1}^{t_i'}\\bigl(1-c_i\\rho \\delta_{i , t}^+\\bigr)\\biggr)^2\\biggr)\\nonumber\\\\ & & \\qquad\\quad{}\\bigg/\\biggl(2\\biggl(\\sum_{t=1}^{t_i ' } \\delta_{i , t}\\prod_{i = t+1}^{t_i'}\\bigl(1-c_i\\rho\\delta_{i , t}^+\\bigr)^2+\\phi v_{g_{j_i } } \\prod_{t=1}^{t_i ' } \\bigl(1-c_i\\rho\\delta_{i , t}^+\\bigr)^2\\biggr)\\biggr ) \\biggr ) \\biggr\\ } .",
    "\\nonumber\\end{aligned}\\ ] ] finally , defining @xmath301 using lemma  [ lem-15 ] to integrate out all @xmath299 and @xmath41 , except for two individuals , and then using lemma [ lem-14 ] for the remaining variables of ( [ eqn-112 ] ) , it follows that the integral is finite , completing the proof .",
    "the research of xiaojing wang was part of her dissertation at the department of statistical science , duke university .",
    "the authors are grateful to jack stenner , hal burdick , carl swartz and sean hanlon at metametrics inc . for valuable discussions , and to the editor , associate editor and referees for numerous suggestions that significantly improved the paper ."
  ],
  "abstract_text": [
    "<S> item response theory ( irt ) models have been widely used in educational measurement testing . </S>",
    "<S> when there are repeated observations available for individuals through time , a dynamic structure for the latent trait of ability needs to be incorporated into the model , to accommodate changes in ability . </S>",
    "<S> other complications that often arise in such settings include a violation of the common assumption that test results are conditionally independent , given ability and item difficulty , and that test item difficulties may be partially specified , but subject to uncertainty . </S>",
    "<S> focusing on time series dichotomous response data , a new class of state space models , called dynamic item response ( dir ) models , is proposed . </S>",
    "<S> the models can be applied either retrospectively to the full data or on - line , in cases where real - time prediction is needed . </S>",
    "<S> the models are studied through simulated examples and applied to a large collection of reading test data obtained from metametrics , inc .    , </S>"
  ]
}