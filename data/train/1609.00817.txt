{
  "article_text": [
    "in the problem of multi - instance learning , the data is given as bags of instances , i.e. , each data sample has multiple instances .",
    "an example of multi - instance data is the medical image data . in medical imaging problem , an medical image",
    "is usually divided to small regions , and each region is a instance of this image .",
    "thus when the image is processed , we call the image a bag of instances @xcite .",
    "an another example is the audio single date . in the problem of audio single processing problem ,",
    "a sequence of audio single is usually split into a set of short frames , and each frame is regard as a instance , while the sequence itself is treated as a bag of instances @xcite .",
    "we investigate the problem of retrieving multi - instance bags from a database .",
    "the inessential components are the representation of the bag , and the calculation of the similarity/ dissimilarity between two bags of instances .",
    "currently , the most popular method to represent a bag of instances to use a multi - instance dictionary .",
    "the instances of a bag is mapped to the dictionary , and the similarity between the instances of the bag and the dictionary is calculated and normalized to a histogram .",
    "the most important part of this representation method is to learn a multi - instance dictionary @xcite . to calculate the dissimilarity between two bags",
    ", we can calculate a distance between two histograms .",
    "currently , existing works have show the most effective distance metric to compare a pair of histograms is earth mover s distance ( emd ) @xcite .",
    "emd treats the bins of a histogram as a set of supplies of earth , and the bins of another histogram as a set of demands of earth .",
    "it moves the earth from the bins of supplies to the bins of demands .",
    "the minimize amounts of moved earth weighted by some ground distances is calculated as emd .",
    "compared to some other histogram distance metric , emd has the ability to cross - bin similarities , thus yields better comparison results .    currently , there are many existing works proposed to learn the multi - instance dictionary .",
    "the simplest method is to perform a @xmath0-clustering to a set of training instances @xcite .",
    "some more complex learning methods use the dictionary to represent bags , and minimize the classification errors of the bags to learn the dictionary @xcite .",
    "the disadvantages of these methods are of two folds when it is applied to the retrieval problem based on emd .    1 .",
    "the existing methods of dictionary learning ignores the emd comparison of histograms .",
    "a dictionary which is optimal to the minimization of classification errors is not necessarily optimal for the retrieval problem based on emd distance metric . up to now",
    ", there is no theoretical proof or experimental study to show that a classification error minimization based dictionary learning method can obtain a emd - comparison based bag - histogram comparison .",
    "the existing methods use all the training bags simultaneously to optimize the dictionary .",
    "if the size of the training set is large , the optimization process can be very time - consuming . in some cases , it is even unacceptable when the big data is considered .",
    "to solve these problems , we propose to learn an optimal multi - instance dictionary specifically for the emd based histogram comparison .",
    "we also propose that the optimization of this learning process should be efficient , and we choose the stochastic optimization method .",
    "this method does not use all the training bags simultaneously , but use the training bags one by one in an iterative algorithm . in each iteration , only one training bag is input to the algorithm , and thus avoids the time - consuming process of processing all the training bags .",
    "the proposed method takes a triplets of multi - instance bags , which are one basic bag , one positive bag and one negative bag .",
    "the positive bag belongs to the same class as the basic bag , but the negative bag belongs to a different class from the basic bag .",
    "the three bags are represented by a multi - instance dictionary and normalized to three histograms .",
    "then we use the emd distance metric to calculate the dissimilarity between the basic histogram and the negative histogram , and the dissimilarity between the basic histogram and the positive histogram .",
    "moreover , we argue that the first distance should be larger than the seconde distance plus a margin amount , since we hope the distance to the negative histogram is bigger than that to the positive histogram . we also define a hinge loss to learn the dictionary when this condition does not hold .",
    "moreover , we derive that the emd between two histograms is a linear weighted combination of the bins of the histograms .",
    "we learn the dictionary by updating the dictionary instances to minimize the hinge loss and the squared @xmath1 norm of the dictionary instances .",
    "the following parts of this paper is organized in the following forms . in section [ sec : back ] we introduce the backgrounds of this work , including the multi - instance dictionary representation , the emd , and the stochastic optimization framework . in section [ sec : method ] , the proposed dictionary learning method is modeled , optimized , and an iterative algorithm is derived . in section [ sec : exp ] , the proposed method is evaluated in the application of multi - instance bag retrieval . in section [ sec : conclu ] , the conclusion of this paper is given .",
    "in this section , we give some brief introduction to the relevant background knowledge of our work .",
    "our work is a novel multi - instance dictionary learning method for emd metric , and it is based on the maximization of large margins and stochastic learning technology . thus we introduce the backgrounds of the multi - instance dictionary learning , the emd metric , the large margin learning , and the stochastic learning .",
    "suppose we have a pattern recognition problem , and the input data is multi - instance data .",
    "each data sample is given as a bag of multiple instances , @xmath2 , where @xmath3 is @xmath4-dimensional feature vector of the @xmath5-th instance of the bag , and @xmath6 is the number of instances of the bag .",
    "for example , in the problem of image representation , we can use the bag - of - words method to represent an image .",
    "the image is split to many small patches , and each patch is treated as an instance , while the image is a bag of instances .",
    "to represent a bag of instances , we can use a multi - instance dictionary .",
    "the dictionary is a set of @xmath7 instances , denoted as @xmath8 , where @xmath9 is the @xmath4-dimensional feature vector of @xmath10-th dictionary instance .",
    "then we can quantize the bag of instances to the dictionary , and use the quantization histogram as the bag - level feature vector of the bag . to obtain the histogram",
    ", we calculate the normalized similarities between the bag and dictionary instances , and concatenate them ,    @xmath11^\\top , \\end{aligned}\\ ] ]    where @xmath12 is the quantization histogram of @xmath13 given @xmath14 as the dictionary , and @xmath15 is the normalized similarity between @xmath13 and the @xmath10-th dictionary instance @xmath9 . to calculate the normalized similarity @xmath15",
    ", we first calculate the original similarity @xmath16 as the summation of the instance similarities between the instances of @xmath13 and @xmath9 measured by a gaussian kernel function ,    @xmath17    where @xmath18 is the bandwidth parameter of the kernel function . beside the summation measure of the similarities",
    ", we may also use the maximum measure or some other measures . the normalized similarity @xmath15",
    "is defined using the original similarity measures as    @xmath19    where @xmath20 is the normalization term . using the bag - level features",
    ", we can train classifiers to predict class labels . for example , chen et al .",
    "@xcite and fu et al .",
    "@xcite proposed to represent the bags to bag - level features and train support vector machine for classification problems .      in many applications ,",
    "we need to compare the dissimilarity between two histograms .",
    "for example , in the nearest neighbor classification problem , we need to search the nearest neighbors of a test data sample from the database first , and then assign the labels of the neighbors to the test point . the most effective distance measure to compare a pair of histograms",
    "is the emd .",
    "suppose we have two histograms @xmath21^\\top$ ] and @xmath22^\\top$ ] of @xmath7 bins , where @xmath23 and @xmath24 are the @xmath10-th bins of @xmath25 and @xmath26 respectively . to calculate the emd between @xmath25 and @xmath26",
    ", we consider the bins of @xmath25 as supplies of earth , and bins of @xmath26 as demands of earth .",
    "we move earth from supplies to the demands .",
    "the distance of moving a unit of earth from @xmath23 to @xmath27 is denoted as @xmath28 , and the amount of earth moved from @xmath23 to @xmath27 is denoted as @xmath29 .",
    "the overall emd of moving the earth of @xmath25 to @xmath26 is given as the summation of the moved earth weighted by the bin - to - bin distances ,    @xmath30    some constraints are imposed to the amounts of moved earth ,    @xmath31    these constrains define a search space for the amounts of earth , and the final emd is the minimum overall moved earth with regard to the amounts of earth in this space . to obtain the emd",
    ", we need to solve the following minimization problem to solve the amounts of bin - to - bin moving of earth ,    @xmath32    this is the constrained linear programming problem .      for many learning problems ,",
    "the training data is large , thus the training process can be very time - time consuming .",
    "one way to solve this problem is to using the stochastic learning strategy . in this strategy , instead of using all the training data samples simultaneously , we use the training data samples one by one .",
    "recently , a novel stochastic optimization method is proposed to learn multi - kernel similarity function @xcite .",
    "each input is a triplet of data samples @xmath33 , composed of a base data sample @xmath34 , a positive data sample @xmath35 which is from the same class as @xmath34 , and a negative data sample @xmath36 which is from a different class from @xmath34 .",
    "given a parametric similarity function @xmath37 , it is argued that the similarity between @xmath34 and @xmath35 should be larger than that between @xmath34 and @xmath36 plus a marginal amount of one ,    @xmath38    the corresponding hinge loss function of this argument is    @xmath39    in an iterative algorithm , in current iteration with the a training triplet @xmath40 , the stochastic optimization problem of updating @xmath41 is given as follows ,    @xmath42    where @xmath43 is the solution of @xmath41 of previous iteration , and @xmath44 is minimized to respect the previous solution .",
    "@xmath45 is minimized to utilize the current training triplet .",
    "@xmath46 is a tradeoff parameter between the first term and the second term .",
    "in this section , we will introduce a novel stochastic learning method of multi - instance dictionary for emd measure . to represent multi - instance bags , we proposed to learn a multi - instance dictionary , @xmath47 .",
    "to this end , we use a stochastic learning strategy in an iterative algorithm . in the @xmath48-th iteration",
    ", we have a training triplet of bags , @xmath49 , where @xmath50 is a base bag , @xmath51 is its @xmath5-th instance , and @xmath6 is the number of instances of @xmath13 .",
    "@xmath52 is a positive bag , it belongs to the same class as @xmath13 , @xmath53 is its @xmath5-th instance , and @xmath54 is the number of instances of the positive bag .",
    "@xmath55 is a negative bag , it belongs to a different class from @xmath13 , @xmath56 is its @xmath5-th instance , and @xmath57 is the number of instances of the negative bag . using the multi - instance dictionary , @xmath14 we represent the bags of @xmath40 as histograms of quantization ,    @xmath58^\\top,\\\\ & { { \\textbf{g}}}= [ g_1 , \\cdots , g_m]^\\top , and\\\\ & { { \\textbf{u}}}= [ u_1 , \\cdots , u_m]^\\top,\\\\ \\end{aligned}\\ ] ]    where @xmath25 is the histogram of @xmath13 , @xmath26 is the histogram of @xmath59 , and @xmath60 is the histogram of @xmath61 .",
    "@xmath23 is the @xmath10-th bin of @xmath25 , and it is defined as    @xmath62    @xmath63 and @xmath64 are defined in similar ways .    to compare the distance between @xmath13 and @xmath59 , we calculate the emd between their histograms , @xmath25 and @xmath26 .",
    "the emd between them is defined as ,    @xmath65    where @xmath29 is the amount of earth moved from @xmath10-th bin of @xmath25 , @xmath23 , to the @xmath0-th bin of the @xmath26 , @xmath27 .",
    "we define a moved earth amount matrix , @xmath66 \\in r^{m\\times m}$ ] , with its @xmath67-th element @xmath29 , and a vector representation of the matrix @xmath68 , where @xmath69 is an operator converting the matrix @xmath70 into a vector by concatenating the columns of the matrix to one long column .",
    "similarly , we also define a distance matrix @xmath71 \\in \\mathbb{r}^{m\\times m}$ ] , and its corresponding vector @xmath72 . in this wey",
    ", we can rewrite @xmath73 as follows ,    @xmath74    we also define a matrix for each of the constraints in ( [ equ : z ] ) .",
    "for the constraint @xmath75 , we define @xmath76 with only its @xmath10-th row containing elements of ones , while all other elements zeros , so that ,    @xmath77    similarly , we define @xmath78 with only its @xmath0-th column containing elements of ones , while all other elements zeros , and    @xmath79    combining constraints of ( [ equ : hconstr ] ) and ( [ equ : gcosntr ] ) into matrix form , we have    @xmath80    where @xmath81 , and @xmath82 . in ( [ equ : constraint ] ) , there are @xmath83 variables , but only @xmath84 constraints .",
    "thus we have only @xmath84 basic variables , and @xmath85 nonbasic variables .",
    "we split the vector @xmath69 into vector of basic variables , @xmath86 , and vector of nonbasic variables , @xmath87 .",
    "@xmath88 and @xmath72 is also split in a similar way , and we have @xmath89 , @xmath90 , @xmath91 , @xmath92 and    @xmath93 \\begin{bmatrix } vec(f)_b\\\\ vec(f)_{nb } \\end{bmatrix }   = { { \\boldsymbol{\\alpha}}}\\rightarrow \\left [ 0~\\omega_b~\\omega_{nb}\\right ] \\begin{bmatrix } z\\\\ vec(f)_b\\\\ vec(f)_{nb } \\end{bmatrix }   = \\begin{bmatrix } 0\\\\ { { \\boldsymbol{\\alpha}}}\\end{bmatrix } , \\\\ & [ 1~-vec(d)_b^\\top~-vec(d)_{nb}^\\top ] \\begin{bmatrix } z\\\\ vec(f)_b\\\\ vec(f)_{nb } \\end{bmatrix } = \\begin{bmatrix } 0\\\\ { { \\boldsymbol{\\alpha}}}\\end{bmatrix}. \\end{aligned}\\ ] ]    we further combine the first and second lines of ( [ equ : constraint1 ] ) to one single equation of matrices as follows ,    @xmath94    we further have    @xmath95    substituting ( [ equ : h ] ) back to ( [ equ : constraint2 ] ) , we have    @xmath96 vec(f)_{nb } = vec(d)_b^\\top\\omega_b^{-1}{{\\boldsymbol{\\alpha}}}\\end{aligned}\\ ] ]    please note that the optimal solution of @xmath70 will obtained when @xmath97 , thus we can rewrite ( [ equ : constraint3 ] ) as    @xmath98^\\top \\\\ & = { { \\boldsymbol{\\beta}}}[h_1,\\cdots , h_m , g_1 , \\cdots , g_m]^\\top\\\\ & = \\sum_{j=1}^m \\beta_j h_{j } + \\sum_{k=1}^m \\beta_{m+k } g_k \\end{aligned}\\ ] ]    where @xmath99 \\in \\mathbb{r}^{2 m } $ ] . in a similar way , we can also have the emd between @xmath25 and @xmath60 as    @xmath100    to learn the optimal dictionary , we proposed that the edm between the histograms of @xmath13 and @xmath61 , @xmath101 , should be larger than the edm between the histograms of @xmath13 and @xmath59 , @xmath73 , plus a margin amount @xmath102    @xmath103    its corresponding loss function is    @xmath104    where @xmath105 is defined as    @xmath106    to learn the optimal dictionary , we propose to minimize this loss function regard to the dictionary .    * remark *",
    ": please note that in our work , we use the triplets of histograms as training data .",
    "each triplet contains a basic histogram , a positive histogram , and a negative histogram .",
    "but in the final objective , the basic histogram has vanished in ( [ equ : conditiion ] ) .",
    "the loss function is only the function of the bins of the positive and negative .",
    "moreover , we also propose to make solution of each dictionary instance as simple as possible , and to minimize the squared @xmath1 norm of @xmath9 .",
    "thus the minimization problem of the updating of the dictionary instances is    @xmath107    to minimize this problem , we first fix @xmath108 to update @xmath105 and @xmath109 and @xmath110 , and then use the gradient descent algorithm to update @xmath9 one by one . the sub - gradient function of @xmath111 with regard to @xmath112 is    @xmath113    the updating rule of @xmath112 is    @xmath114    where @xmath115 is the descent step , and its value is decided by cross - validation . using this stochastic updating rule",
    ", we can design an iterative algorithm to learn the dictionary for emd based histogram comparison as in algorithm [ alg : overall ] .",
    "initialize @xmath108 ;    in put one new training triplet , @xmath116 .",
    "update @xmath109 and @xmath110 ,    @xmath117    update @xmath27 and @xmath118 for @xmath119 ,    @xmath120    update @xmath105 ,    @xmath121    calculate the sub - gradient function for @xmath119 ,    @xmath113    update @xmath112 for @xmath119 ,    @xmath122    * output * : @xmath123 .",
    "in the experiments , we evaluate the proposed method for the problem of multi - instance data retrieval .",
    "we use three data sets in our experiment .",
    "they are the digital database for screening mammography ( ddsm ) @xcite , and the semeval-2010 task 8 data set @xcite .    in the ddsm data set @xcite , there are 2620 cases of three classes , which is normal , cancer , and benign .",
    "each case has two images of screening mammography , which is the images of the left breast and the right breast . to represent each case",
    ", we divide the two images to small regions and extract sift and pixel features from each region .",
    "thus each case contains a number of regions , and each region is treated as an instance .    the semeval-2010 task 8",
    "data set is a data set for relation classification of words @xcite . in this data",
    "set , each data sample is a sentence , and in this sentence , two works are tagged as label words . the problem is to predict the relation between these two words .",
    "this dat set contains 10,717 examples of 9 different classes of relation types , which are content - container , cause - effect , component - whole , entity - origin , entity - destination , instrument - agency , message - topic , member - collection , and product - producer .",
    "moreover , one more relation type is also considered , which is the other type .",
    "thus there are totally ten types .",
    "each example contains multiple works , and we treat each work as an instance , thus it is a multi - instance data classification problem .",
    "we represent the words using its word embedding features , and its position embedding with regard to the two target words .",
    "given a data set , we use the ten - fold cross - validation experimental protocol to conduct the experiment @xcite .",
    "the entire data set is split into ten folds with the same size , and we use each of them as a query set in turn .",
    "the remaining nine folds are combined and used as a database set . given a query data sample , we want to retrieve the data samples of a database of the same class .",
    "the retrieval is based on emd - based comparison .",
    "we first represent each data sample as a histogram , and then calculate the emd between the query histogram and each histogram of the data samples of a database .",
    "to evaluate the retrieval performance , we use the recall - precision curve @xcite , and the receiver operating characteristic curve @xcite . given a query , the retrieval system returns a number of database samples .",
    "the number of data samples which are in the returned list and also belong to the same class as the query is defined as true positive .",
    "the number of the other data samples in the returned list is defined as false positive .",
    "the number of data samples which belong to the same class as the query but not in the returned list is defined as the false negative .",
    "the recall and precision is defined accordingly ,    @xmath124    if we change the number of the returned database samples , we will have different pairs of recall and precision values . by plotting these pairs in one single figure ,",
    "we can obtain the recall - precision curve . a good retrieval system can give a recall - precision curve close to the top - right corner of the figure .    in the returned list of a query ,",
    "the number of samples which are from different classes from the query is defined as the true negative",
    ". the true positive rate and the false positive rate are defined as follows ,    @xmath125    similar to the recall - precision curve , we can also obtain different pairs of true  positive  rate and false  positive  rate by changing the size of returned list .",
    "also , by plotting these pairs in one single figure , we can have the receiver operating characteristic curve , and a receiver operating characteristic curve which is close to the top - left corner of the figure is preferred .      in the experiments , we compare the proposed method with some other multi - instance dictionary learning methods . to make the comparison fair",
    ", we use these dictionary learning methods to learn the dictionaries over the database set , and then represent the data samples as histograms .",
    "the histograms are compared by using the emd and ranked .",
    "the compared dictionary learning methods are listed as follows ,    * max - margin multiple - instance dictionary learning ( mmd ) @xcite , * domain transfer multi - instance dictionary learning ( dtd ) @xcite , * multiple - instance learning via embedded instance selection ( miles ) @xcite , and * multiple instance learning with instance selection ( milis ) @xcite .",
    "the experimental results of the compared methods over the are given in the figure [ fig : ddsm ] .",
    "we can clearly see that that the proposed method outperforms all the other methods significantly . as shown in the the recall - precision figure of the figure [ fig : ddsm ] ,",
    "the recall - precision curve of the proposed method , sd - emd , is much more closer to the top - left corner than the other methods .",
    "this is not surprising because in the retrieval system , the emd measure is used as distance measure , and only the sd - emd method optimize the dictionary according to the emd .",
    "the other methods ignores the emd measure in their training process . from the receiver operating characteristic curve of the figure [ fig : ddsm ]",
    ", it is also observed that the curve of sd - emd is more closer to the top - right corner than all than other methods .",
    "this is strong evidence that the novel method works better than other methods .",
    "+   +      the recall - precision curve and the receiver operating characteristic curve of the experiments over the semeval-2010 task 8 data set are shown in [ fig : semeval ] .",
    "again , we observed that the proposed method , sd - emd , outperforms all the compared methods over the semeval-2010 task 8 data set .",
    "this means that the proposed emd based dictionary learning method not only works well over the medical image data , but also has good performances over the natural language processing problems .",
    "in this paper , we discuss the problem of representing multi - instance data sample by using the dictionary .",
    "the bags of instances are represented as histograms and the emd is used to compare histograms . in this paper ,",
    "for the first time , we proposed to learn emd - optimal dictionary .",
    "we proposed a novel learning framework to train the dictionary by using the stochastic optimization method .",
    "the proposed method shows its advantage over the existing dictionary learning methods .",
    "in this paper , we use the large margin as the loss function to model the problem . in the future",
    ", we will consider using more complex loss functions of multivariate performance measures @xcite .",
    "moreover , we will also consider using bayesian network to represent the histograms and learn the parameters of bayesian network for emd based comparison @xcite . in the future",
    ", we will also applied the proposed method to various applications , including multimedia technology @xcite , information security @xcite , computer vision @xcite , medical imaging @xcite , etc .",
    "beecks , c. , uysal , m. , seidl , t. : earth mover s distance vs. quadratic form distance : an analytical and empirical comparison . in : proceedings - 2015 ieee international symposium on multimedia , ism 2015 , pp . 233236 ( 2016 )    chen , t.c . ,",
    "chen , y.y .",
    ", ma , t.c . , chen , l.g .",
    ": design and implementation of cubic spline interpolation for spike sorting microsystems . in : 2011 ieee international conference on acoustics , speech and signal processing ( icassp ) , pp",
    ". 16411644 .",
    "ieee ( 2011 )    chen , t.c . ,",
    "ma , t.c . ,",
    "chen , y.y . ,",
    "chen , l.g .",
    ": low power and high accuracy spike sorting microprocessor with on - line interpolation and re - alignment in 90 nm cmos process . in : 2012 annual international conference of the ieee engineering in medicine and biology society , pp .",
    "44854488 . ieee ( 2012 )    chen , t.t . , liu , c. , ding , x.m . , zou , h. , shen , q. , liu , y. : a multi - instance multi - label learning algorithm based on feature selection . in : proceedings - 2015 10th international conference on broadband and wireless computing , communication and applications , bwcca 2015 , pp .",
    "587590 ( 2016 )      chen , y.h . ,",
    "chen , t.c .",
    ", ma , t.c . , lee , t.h . , chen , l.g .",
    ", et  al . : sub - microwatt knn classifier for implantable closed - loop epileptic neuromodulation system . in : proceedings of the 2009 international symposium on bioelectronics and bioinformatics , p.  13 .",
    "rmit university , school of electrical and computer engineering ( 2009 )    clarkson , e. , cushing , j. : shannon information and receiver operating characteristic analysis for multiclass classification in imaging .",
    "journal of the optical society of america a : optics and image science , and vision * 33*(5 ) , 930937 ( 2016 )    fan , x. , malone , b. , yuan , c. : finding optimal bayesian network structures with constraints learned from data . in : proceedings of the 30th annual conference on uncertainty in artificial intelligence ( uai-14 ) , pp .",
    "200209 ( 2014 )              hendrickx , i. , kim , s.n . , kozareva , z. , nakov , p. ,   saghdha , d. , pad , s. , pennacchiotti , m. , romano , l. , szpakowicz , s. : semeval-2010 task 8 : multi - way classification of semantic relations between pairs of nominals . in : proceedings of the workshop on semantic evaluations : recent achievements and future directions , pp .",
    "9499 . association for computational linguistics ( 2009 )    huo , j. , gao , y. , yang , w. , yin , h. : abnormal event detection via multi - instance dictionary learning .",
    "lecture notes in computer science ( including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics ) * 7435 lncs * , 7683 ( 2012 )      ju , c.c . , liu , t.m . , chen , y.h . ,",
    "lee , k.b . ,",
    "cheng , c.y . ,",
    "chao , h.t . ,",
    "wang , c.m .",
    ", wu , t.h . ,",
    "lin , t.a . ,",
    "chou , h.l .",
    ", et  al . :",
    "a 1.94 mm 2 , 38.17 mw dual vp8/h .",
    "264 full - hd encoder / decoder lsi for social network services ( sns ) over smart - phones . in : solid state circuits conference ( a - sscc ) , 2012 ieee asian , pp . 1316 .",
    "ieee ( 2012 )      king , d.r . , li , w. , squiers , j.j . ,",
    "mohan , r. , sellke , e. , mo , w. , zhang , x. , fan , w. , dimaio , j.m . ,",
    "thatcher , j.e . : surgical wound debridement sequentially characterized in a porcine burn model with multispectral imaging .",
    "burns * 41*(7 ) , 14781487 ( 2015 )    li , j.y . , li , j.h . , shui - cheng , y. : multi - instance learning using information entropy theory for image retrieval . in : proceedings - 17th ieee international conference on computational science and engineering , cse 2014 , jointly with 13th ieee international conference on ubiquitous computing and communications , iucc 2014 , 13th international symposium on pervasive systems , algorithms , and networks , i - span 2014 and 8th international conference on frontier of computer science and technology , fcst 2014 , pp .",
    "17271733 ( 2015 )    li , w. , mo , w. , zhang , x. , lu , y. , squiers , j.j . , sellke , e.w . , fan , w. , dimaio , j.m . ,",
    "thatcher , j.e . : burn injury diagnostic imaging device s accuracy improved by outlier detection and removal . in : spie defense+ security ,",
    ". 947,206947,206 . international society for optics and photonics ( 2015 )    li , w. , mo , w. , zhang , x. , squiers , j.j . , lu , y. , sellke , e.w . , fan , w. , dimaio , j.m . ,",
    "thatcher , j.e . :",
    "outlier detection and removal improves accuracy of machine learning approach to multispectral burn diagnostic imaging .",
    "journal of biomedical optics * 20*(12 ) , 121,305121,305 ( 2015 )    liang , r.z . , shi , l. , wang , h. , meng , j. , wang , j.j.y . ,",
    "sun , q. , gu , y. : optimizing top precision performance measure of content - based image retrieval by learning similarity function . in : pattern recognition ( icpr ) , 2016 23st international conference on .",
    "ieee ( 2016 )    liang , r.z .",
    ", xie , w. , li , w. , wang , h. , wang , j.j.y . ,",
    "taylor , l. : a novel transfer learning method based on common space mapping and weighted domain matching . in : tools with artificial intelligence ( ictai ) , 2016 ieee 28th international conference on .",
    "ieee ( 2016 )      liu , x. , wang , j. , yin , m. , edwards , b. , xu , p. : supervised learning of sparse context reconstruction coefficients for data representation and classification .",
    "neural computing and applications pp . 19 ( 2015 )    lobel , h. , vidal , r. , soto , a. : learning shared , discriminative , and compact representations for visual recognition .",
    "ieee transactions on pattern analysis and machine intelligence * 37*(11 ) , 22182231 ( 2015 )    ma , t.c . , chen , t.c . ,",
    "chen , l.g .",
    ": design and implementation of a low power spike detection processor for 128-channel spike sorting microsystem . in : 2014 ieee international conference on acoustics , speech and signal processing ( icassp ) , pp .",
    "38893892 . ieee ( 2014 )    mo , w. , mohan , r. , li , w. , zhang , x. , sellke , e.w . , fan , w. , dimaio , j.m . ,",
    "thatcher , j.e . :",
    "the importance of illumination in a non - contact photoplethysmography imaging system for burn wound assessment . in : spie bios , pp .",
    "93,030m93,030 m .",
    "international society for optics and photonics ( 2015 )    nabavi , s. , beck , a. : earth mover s distance for differential analysis of heterogeneous genomics data . in : 2015 ieee global conference on signal and",
    "information processing , globalsip 2015 , pp .",
    "963966 ( 2016 )    rose , c. , turi , d. , williams , a. , wolstencroft , k. , taylor , c. : web services for the ddsm and digital mammography research .",
    "lecture notes in computer science ( including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics ) * 4046 lncs * , 376383 ( 2006 )      tong , j. , schreier , p. , guo , q. , tong , s. , xi , j. , yu , y. : shrinkage of covariance matrices for linear signal estimation using cross - validation .",
    "ieee transactions on signal processing * 64*(11 ) , 29652975 ( 2016 )    vanwinckelen , g. , tragante  do o , v. , fierens , d. , blockeel , h. : instance - level accuracy versus bag - level accuracy in multi - instance learning .",
    "data mining and knowledge discovery * 30*(2 ) , 313341 ( 2016 )      wang , h. , wang , j. : an effective image representation method using kernel classification . in : 2014 ieee 26th international conference on tools with artificial intelligence ( ictai 2014 ) , pp .",
    "853858 ( 2014 )    wang , j. , wang , h. , zhou , y. , mcdonald , n. : multiple kernel multivariate performance learning using cutting plane algorithm . in : systems ,",
    "man , and cybernetics ( smc ) , 2015 ieee international conference on , pp .",
    "ieee ( 2015 )    wang , j. , zhou , y. , duan , k. , wang , j.j.y .",
    ", bensmail , h. : supervised cross - modal factor analysis for multiple modal data classification . in : systems , man , and cybernetics ( smc ) , 2015 ieee international conference on , pp .",
    "ieee ( 2015 )        wang , x. , kambhamettu , c. : gender classification of depth images based on shape and texture analysis . in",
    ": global conference on signal and information processing ( globalsip ) , 2013 ieee , pp .",
    "10771080 . ieee ( 2013 )      wang , x. , ly , v. , lu , g. , kambhamettu , c. : can we minimize the influence due to gender and race in age estimation ? in : machine learning and applications ( icmla ) , 2013 12th international conference on , vol .  2 , pp .",
    "309314 . ieee ( 2013 )      wu , j.h .",
    ", tang , l.b . ,",
    "zhao , b.j . , deng , c.w .",
    ", li , j.t .",
    ": visual dictionary and online multi - instance learning based object tracking .",
    "xi tong gong cheng yu dian zi ji shu / systems engineering and electronics * 37*(2 ) , 428435 ( 2015 )                yan , z. , zhan , y. , peng , z. , liao , s. , shinagawa , y. , zhang , s. , metaxas , d. , zhou , x. : multi - instance deep learning : discover discriminative local anatomies for bodypart recognition .",
    "ieee transactions on medical imaging * 35*(5 ) , 13321343 ( 2016 )    ying , p. , liu , j. , lu , h. : dictionary learning based superpixels clustering for weakly - supervised semantic segmentation . in : proceedings - international conference on image processing , icip , vol .",
    "2015-december , pp .",
    "42584262 ( 2015 )      zhang , p. , su , w. : statistical inference on recall , precision and average precision under random selection . in : proceedings - 2012 9th international conference on fuzzy systems and knowledge discovery , fskd 2012 , pp . 13481352 ( 2012 )"
  ],
  "abstract_text": [
    "<S> dictionary plays an important role in multi - instance data representation . </S>",
    "<S> it maps bags of instances to histograms . </S>",
    "<S> earth mover s distance ( emd ) is the most effective histogram distance metric for the application of multi - instance retrieval . </S>",
    "<S> however , up to now , there is no existing multi - instance dictionary learning methods designed for emd based histogram comparison . to fill this gap </S>",
    "<S> , we develop the first emd - optimal dictionary learning method using stochastic optimization method . in the stochastic learning framework </S>",
    "<S> , we have one triplet of bags , including one basic bag , one positive bag , and one negative bag . </S>",
    "<S> these bags are mapped to histograms using a multi - instance dictionary . </S>",
    "<S> we argue that the emd between the basic histogram and the positive histogram should be smaller than that between the basic histogram and the negative histogram . </S>",
    "<S> base on this condition , we design a hinge loss . by minimizing this hinge loss and some regularization terms of the dictionary </S>",
    "<S> , we update the dictionary instances . </S>",
    "<S> the experiments over multi - instance retrieval applications shows its effectiveness when compared to other dictionary learning methods over the problems of medical image retrieval and natural language relation classification .    </S>",
    "<S> example.eps    gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}