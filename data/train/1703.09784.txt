{
  "article_text": [
    "textures play important roles in multimedia applications , such as understanding and generation of multimedia content .",
    "texture synthesis and generation have also been extensively investigated in the past years  @xcite . before the revival of deep learning ,",
    "researchers mainly used example - based approaches to synthesize textures . in these methods , new textures with similar appearances to existing samples can be produced . with the development of deep learning , more methods for texture generation",
    "have been proposed by learning from the training data .",
    "however , there is no visual perceptual information involved in this process , whereas humans commonly use perceptual attributes , such as texture roughness , coarseness and directionality , to describe textures .",
    "moreover , the majority of deep learning based methods can only generate images of low quality .",
    "thus , it is desired to develop a new way for generating high - quality textures based on human perceptual descriptions ; for example , the new generation method should be able to produce textures with strong directionality or less regularity as required by the user .",
    "convolutional neural network ( cnn ) , which was inspired by the mechanism of visual cortex , has shown great superiority in latest studies  @xcite  @xcite . with the aid of deep convolutional networks ,",
    "researchers have made breakthroughs in many classical computer vision tasks .",
    "for example , in the imagenet large scale visual recognition challenge , the performance of computer algorithms even surpassed human s  @xcite .",
    "consequently , researchers have been investigating different approaches based on cnn for image generation  @xcite  @xcite  @xcite .",
    "goodfellow et al .",
    "proposed a generative adversarial framework ( gan )  @xcite and produced excellent results in many image generation tasks .",
    "however , the generated samples were still in low resolution and far from being perfect . in order to generate more realistic images , wang and gupta factorized the image generation process and proposed a joint model consisting of style and structure generative adversarial networks  @xcite .",
    "experimental results in  @xcite suggested that a great gain could be obtained through this factoring trick for generating realistic indoor scenes .",
    "all these work indicates that it is a promising practice to exploit joint convolutional neural networks and adversarial training schemes for generating high - quality images .",
    "in addition to generating natural images , another question is what we can generate from semantics or high - level descriptions .",
    "many efforts have been made regarding this topic .",
    "karpathy et al . proposed a fragment embedding method in 2014  @xcite , which was essentially a bidirectional retrieval scheme , as the desired image must exist in the image database .",
    "yan et al .",
    "modeled images as composite of foreground and background and developed a layered generative model  @xcite .",
    "their method shows promising results in the tasks of attribute - conditioned image reconstruction and completion . nevertheless , the quality of generated images is still not good enough for texture perception study .",
    "the contribution of this paper is a new joint model that combines perceptual feature regression and adversarial schemes for generating textures based on perceptual descriptions . unlike existing conditional generative adversarial networks ( cgan )  @xcite ,",
    "in which the discriminative model need to estimate the joint distribution of condition vectors with samples and can not always provide enough information for the generator to adjust parameters , in our new model , perceptual feature regression can supervise the generator to produce textures in consistence with human visual system .",
    "thus , the discriminative model is assisted by the perceptual regression model and therefore released from the inaccurate estimation of joint distributions .",
    "furthermore , the perceptual model is able to supply more information to the generator and guide it to produce texture with enough details , which lead to high - quality output texture images .",
    "textures have attracted widespread attention in the research field of visual perception and computer vision .",
    "rao et al . identified the perceptual features people used to classify the textures and also established the correlation between semantic attributes and textures  @xcite , which showed the importance of perceptual features for understanding texture images .",
    "meanwhile , texture synthesis and texture generation have been active research areas for many years .",
    "shin et al . proposed a pixel - based method for texture synthesis with non - parametric sampling  @xcite , and wei proposed an efficient algorithm using tree - structured vector quantization for realistic texture synthesis , which required only a sample texture as input  @xcite .",
    "these studies normally concern on example based texture synthesis , whereas our work focuses on generating textures according to user - defined perceptual attributes .",
    "deep learning models , particularly deep convolutional neural networks , have achieved great success in texture analysis due to their strong learning capability .",
    "texture synthesis based on cnn is a new research topic  @xcite , which has produced promising results .",
    "these results suggest that this topic deserves more research devotion . in  @xcite , gatys combined the conceptual framework of spatial summary statistics on feature responses with the feature space of a convolutional neural network , and the goal is to generate textures from a given source image .",
    "ulyanov also trained feed - forward generation networks to generate multiple samples of the same texture with arbitrary sizes  @xcite . in this manner",
    ", the representation of the given image can be learned by the convolutional networks , and the new samples can be generated from the networks .",
    "goodfellow  @xcite proposed a generative adversarial framework that could estimate generative models via an adversarial process , in which a generative model @xmath0 and a discriminative model @xmath1 were simultaneously trained .",
    "the generative model is responsible for capturing the data distribution , and the discriminative model is used to estimate the probability that a sample comes from the training data rather than @xmath0 .",
    "the training procedure for @xmath0 is to maximize the probability of @xmath1 making a mistake .",
    "it has been proven that gan can be used to generate realistic images from uniformly distributed random noise  @xcite .",
    "furthermore , gan was extended as cgan for conditional image generation by mirza and osindero  @xcite , where both models @xmath0 and @xmath1 received an additional vector of information as condition . this vector might contain information about the class of the training example .",
    "cgan has been successfully applied in digit and face image generation  @xcite , whereas we are interested in generating textures with given perceptual attributes .",
    "inspired by previous works , this paper proposes a joint model , which combines the perceptual feature regression and adversarial training scheme for perception driven texture generation . since the perceptual regression model can provide additional information for the generator in the adversarial scheme ,",
    "the proposed model is able to generate high - quality textures .",
    "in this section , we first introduce the overall architecture of the proposed joint model for perception driven texture generation .",
    "then we provide details on the network design and initialization .",
    "human observers essentially use perceptual features for texture description , e.g. regularity and repetitiveness  @xcite .",
    "according to  @xcite , there are 12 prominent perceptual features for human to perceive a texture . in practice",
    ", human can not only perceive these features from a texture but also imagine a texture from these perceptual descriptions .",
    "for example , textures with weak or strong directionality can be easily depicted in human mind ; in contrast , no computer algorithm is able to generate texture from these descriptions . therefore we designed a joint deep model in order to achieve such a goal .",
    "as shown in fig .",
    "[ fig:4 ] , the overall architecture includes three parts : a perceptual feature regression model , a conditional generative model , and a discriminative model . the generative model is responsible for conditional texture generation , whereas the discriminative model is used to distinguish whether the generated texture is from the training sample distribution , and the perceptual model can drive the generative model to produce textures possessing certain attributes .    inspired by the success of the inception - v3 model  @xcite , which reached 3.46% top-5 error rate and even surpassed human performance in the 2015 imagenet large scale visual recognition challenge(ilsvrc ) , we use inception - v3 for our perceptual feature regression .",
    "first we change the activation function of the final output layer and auxiliary units to @xmath2 , as our perceptual features are scaled in the range between -0.9 and 0.9 .",
    "the reason for scaling the range is to avoid the saturation of the output neurons .",
    "furthermore , @xmath2 is much easier to be trained than @xmath3  @xcite .",
    "second , we change the cross entropy loss of softmax to the quadratic loss .",
    "then we train the modified inception - v3 model using our texture database for perceptual feature prediction . in the following sections , we call the modified inception - v3 as the perceptual model .    in the cgan framework",
    ", the discriminator needs to figure out the union distribution of the condition and samples .",
    "the distinguishing task is relatively difficult , and the discriminator can not supply enough information for the generator to justify its parameters . in our model",
    ", we use the perceptual model to impose perceptual constraints on the generator ; this can provide additional information for the generator to produce certain perceived textures .",
    "we use @xmath0 , @xmath1 , and @xmath4 to represent the generative , discriminative and perceptual model , respectively .",
    "then the loss of @xmath1 can be defined as : @xmath5 where @xmath6 represents a training example , @xmath7 is the corresponding perceptual feature vector , @xmath8 is one or zero , indicating whether @xmath9 is a real pair , and @xmath10 is the number of training examples .",
    "the quadratic loss for @xmath4 is defined as : @xmath11 the loss of @xmath0 contains two parts : one from @xmath1 , and the other from @xmath4 ; the definition is : @xmath12 where @xmath13 is a tradeoff parameter , @xmath14 is a random noise vector , @xmath4 is preliminarily trained , and @xmath0 and @xmath1 are trained in an adversarial scheme . in this manner ,",
    "the discriminator makes the generator produce realistic textures , and the perceptual model makes the generated textures possess certain perceptual attributes .",
    "+      in this subsection , we first introduce the initialization scheme for our deep networks , and then present strategies for the design of certain part of the network .",
    "inspired by  @xcite , we initialize weights of one layer of the proposed network by formulation @xmath15=2/n$ ] . in most cases ,",
    "we only consider the back propagation situation , so @xmath10 represents the number of units that can be reached by one input neuron , and @xmath16 represents the weight in convolutional or fully connected layer .",
    "relu is used as the activation function in the network , since it can reduce the gradient vanishing effect and make the model learn fast .",
    "however , we would like the output of the generator to be limited in a certain range , because an image always has limited pixel values .",
    "the discriminator should yield a probability result , which indicates whether an image comes from the real training samples .",
    "accordingly , we use @xmath2 as the activation function in the output layer of the generative model , and @xmath3 in the discriminative model .",
    "thus , we adopt different initialization strategies for the output layer . in order to keep the gradient variance , when the activation function is @xmath2 , we initialize the weights using the truncated normal distribution with the standard deviation @xmath17 . in contrast",
    ", we use @xmath18 as the deviation when the activation function is @xmath3 . here",
    ", we assume that the weights are initialized independently , and the bias is initialized with zero .",
    "in particular , if the number of units decreases too much in the output layer , we slightly reduce the deviation of weights to avoid the output becoming too saturated in the forward case",
    ". we will introduce more details about the network design in section 4 .",
    "it should be noted that , in the fully connected layer , the initialization strategy can be easily analyzed .",
    "however , it becomes complicated in the convolutional layers .",
    "we may take the 1-d convolutional operation as an example , and it can be easily extended to the high dimensional case .",
    "we use @xmath10 to represent the number of units , which can propagate its gradient to certain input unit .",
    "when the number of input units becomes very large , we can calculate an average value for @xmath10 .",
    "we define a universal formulation : @xmath19 where @xmath20 represents the maximal integer no larger than @xmath21 , @xmath22 represents the kernel size , and @xmath23 represents the step size .",
    "eq   illustrates a period of the convolutional operation .",
    "each line in eq   calculates the number of units that can be reached by certain input unit .",
    "the period begins with the @xmath24 input unit .",
    "the length of the cycle is @xmath23 .",
    "from eq  , we can get the average value of @xmath10 for general situation : @xmath25 we use the average value of @xmath10 to calculate the deviation of @xmath16 for initialization . to extend this to the two dimensional situation",
    ", we simply expand @xmath22 and @xmath23 to two dimensions .",
    "this scheme is used to initialize our networks through all experiments .    in order to emphasize the importance of perceptual features for texture generation",
    ", we stretch the perceptual feature vector to 800 dimensions via a fully connected layer .",
    "the random noise vector is drawn uniformly from a 200 dimensional space ranging from -1 to 1 .",
    "the reason for using these specific dimensions is explained as follows . a random noise vector with 200 dimensions",
    "can be significantly varied to generate diverse textures given certain perceptual features . in theory , if we change each dimension of the random noise vector with step of 0.1 , we can obtain @xmath26 different vectors .",
    "this is a large enough space for variant texture appearance .",
    "in addition , textures with the same perceptual feature vector have similar appearances . in the above analysis",
    ", we demonstrate that the covariance shift can be avoided by certain initialization strategy in the forward and backward view . in the fully connected layers for stretching perceptual features",
    ", we simply consider the forward propagation .",
    "thus , we make @xmath10 represent the number of units in the input layer . consequently , the stretched perceptual features own similar variance as the original .",
    "let @xmath27 represent the random variable .",
    "then its variance is @xmath28=1/3 $ ] . recall that the perceptual features are scaled to the range between -0.9 and 0.9 .",
    "let @xmath29 represent one perceptual feature , and we use the following equation for scaling : @xmath30 through this transformation , the resulted @xmath31 owns variance of @xmath32 .",
    "since the stretching layer is initialized by using the forward principle , the variance of the stretched features is also approximately @xmath32 .",
    "the result is that the variance of the random noise is three times larger than that of the stretched perceptual features .",
    "hence if we want the perceptual features to play the same role as random noise in the generating task , we should make the number of the output units in the stretching layer three times larger than that of the random noise . in this work we therefore set the number to 800 , and we can let the perceptual features dominate the generating procedure .",
    "in our experiments , we use the perceptual texture database ( ptd ) , in which there are 450 textures with corresponding 12-d perceptual features  @xcite .",
    "the textures in ptd have a resolution of @xmath33 , and the 12-d perceptual features include contrast , repetitiveness , granularity , randomness , roughness , density , directionality , structural complexity , coarseness , regularity , orientation and uniformity . however , since 450 textures are still too few to train a deep neural network , we expand the examples in the following way",
    ". first , we crop each texture into 81 textures of size @xmath34 ; the step used for cropping is 8 .",
    "second , we resize the resulted textures to @xmath35 . regarding perceptual features , we let the resulted textures have same values as their original ones .",
    "we eventually obtain 36450 examples of size @xmath35 , and we use 36000 among them to train our models .",
    "the remaining textures are left as the validation set .",
    "it should be noted that it is reasonable to make the resulted 81 textures have the same perceptual features as their originals .",
    "first , the textures in ptd are isotropic ; a @xmath34 region can cover most area of the original texture and can therefor keep original perceptual characteristics .",
    "second , resizing the @xmath34 texture to @xmath35 does not cause obviously blurring effect .      since our perceptual model was modified from inception - v3",
    ", we did not need to train it from scratch .",
    "the preliminary trained inception - v3 on imagenet can be found in  @xcite . since our perceptual model only differed from inception - v3 in the output layer and loss definition , we initialized the output layer with truncated gaussian noise , and the other layers",
    "were reloaded from preliminary trained inception - v3 model .",
    "then we fine - tuned the perceptual model with initial learning rate 0.001 .",
    "the rmsprop method was used for gradient descent  @xcite .",
    "we ran the optimization algorithm for 50000 iterations .",
    "the process is illustrated in fig .",
    "[ fig : step4_curves](a ) . finally , the euclidean loss converged to 0.01161 , and the final evaluation error was 0.0039 .",
    "since the perceptual features have 12 attributes , the standard error deviation for each attribute in average can be calculated : @xmath36 this means that we can accurately predict the perceptual features for one texture with very small deviation . based on this observation",
    ", we can make a basic assumption here : if the generated textures have certain perceptual attributes , it should be correctly perceived by the perceptual model .",
    "we use the preliminary trained perceptual model as an accessory of the whole generative framework .",
    "+      to generate realistic textures , we must design a reasonable network structure .",
    "the kernel size is a vital factor for generating high - quality images . in the experiments",
    ", we found that if we set the kernel size too small , i.e. 3 , the generated textures owned more details but looked too crude . if the kernel size was too large , i.e. 7 , the generated textures looked more smooth , but with less details . eventually , we used @xmath37 kernels for convolution or inverse convolution in our discriminative and generative models .",
    "we also tried to fuse kernels of different size for generating textures with more details and global information .",
    "however , it did not produce good results .",
    "since one part of the input to the generative model was drawn from random noise ( the other part is the perceptual feature vector ) , there were infinitely many training examples in practice .",
    "thus we used the adam  @xcite method for optimization .",
    "we optimized the generative model twice after each optimization for the discriminative model .",
    "we made each batch contain 60 training examples .",
    "the tradeoff parameter @xmath13 was set as 10 . in the end",
    ", we ran 266000 optimization iterations .",
    "the training process is illustrated in fig .",
    "[ fig : step4_curves](b)(c)(d ) .",
    "two experiments were designed after the models were trained .",
    "first , we fed real perceptual features in our database with different random noise to the generative model .",
    "the generated textures are shown in fig .",
    "[ fig : step4_generated_textures ] .",
    "second , we manually edited some perceptual features and used them to generate textures .",
    "it should be emphasized that the manually edited or handcrafted perceptual features were based on existing perceptual features , i.e. only certain perceptual feature was set to three different values : 0.9 , 0 , -0.9 , whereas the others were kept the same as the existing ones . in fig .",
    "[ fig : step4_handcrafted_textures ] , we only provide six results due to the limited space , but more results are provided in the supplementary materials . as an example , we can see from the first column of fig .  [",
    "fig : step4_handcrafted_textures ] , when we decrease the perceptual feature value of directionality from 0.9 to -0.9 , the textures gradually lose the overall direction .",
    "these results indicate that the proposed method is able to generate desired textures by varying certain perceptual attributes .",
    "we propose a novel deep network model for perception driven texture generation . in the proposed model ,",
    "a perceptual regression component is integrated with the generative framework , which drives the produced textures possessing certain perceptual attributes .",
    "this perceptual regression model partially releases the discriminative model s workload , and can supply more information for the generator to produce better perceived texture .",
    "experimental results show that the jointed models are able to generate realistic texture from given perceptual attributes .",
    "we attribute this success to the fact that if the generated texture is realistic enough , it should have the potentiality to be correctly perceived by the preliminary trained deep network .",
    "it should be noted that the perceptual features are not independent from each other .",
    "if we change one perceptual attribute arbitrarily , the remaining relevant features might also need to be changed to fit the real distribution . in the future work",
    ", we will design an auxiliary model for generating correct perceptual feature vectors ; in this way we may simply provide an existing perceptual feature vector and the desired value for certain attribute , and the tool can generate a suitable input perceptual feature vector .",
    "alexey badalov , irene cheng , claudio silva , and anup basu , `` an in - place texture synthesis technique for memory constrained multimedia applications , '' in _ ieee international conference on multimedia and expo _ , 2011 , pp .",
    "kevin jarrett , koray kavukcuoglu , yann lecun , et  al .",
    ", `` what is the best multi - stage architecture for object recognition ?",
    ", '' in _ 2009 ieee 12th international conference on computer vision_. ieee , 2009 , pp .",
    "21462153 .",
    "alexey dosovitskiy , jost tobias  springenberg , and thomas brox , `` learning to generate chairs with convolutional neural networks , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2015 , pp .",
    "15381546 .",
    "ian goodfellow , jean pouget - abadie , mehdi mirza , bing xu , david warde - farley , sherjil ozair , aaron courville , and yoshua bengio , `` generative adversarial nets , '' in _ advances in neural information processing systems _ , 2014 , pp",
    ". 26722680 .",
    "nalini bhushan , a  ravishankar rao , and gerald  l lohse , `` the texture lexicon : understanding the categorization of visual texture terms and their relationship to texture images , '' , vol .",
    "2 , pp . 219246 , 1997 .",
    "li - yi wei and marc levoy , `` fast texture synthesis using tree - structured vector quantization , '' in _ proceedings of the 27th annual conference on computer graphics and interactive techniques_. acm press / addison - wesley publishing co. , 2000 , pp .",
    "479488 .",
    "jun liu , junyu dong , xiaoxu cai , lin qi , and mike chantler , `` visual perception of procedural textures : identifying perceptual dimensions and predicting generation models , '' , vol .",
    "10 , no . 6 , pp .",
    "e0130335 , 2015 .",
    "kaiming he , xiangyu zhang , shaoqing ren , and jian sun , `` delving deep into rectifiers : surpassing human - level performance on imagenet classification , '' in _ proceedings of the ieee international conference on computer vision _ , 2015 , pp ."
  ],
  "abstract_text": [
    "<S> this paper investigates a novel task of generating texture images from perceptual descriptions . </S>",
    "<S> previous work on texture generation focused on either synthesis from examples or generation from procedural models . </S>",
    "<S> generating textures from perceptual attributes have not been well studied yet . meanwhile , </S>",
    "<S> perceptual attributes , such as directionality , regularity and roughness are important factors for human observers to describe a texture . in this paper , we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation , while only random noise and user - defined perceptual attributes are required as input . in this model , a preliminary trained convolutional neural network is essentially integrated with the adversarial framework , which can drive the generated textures to possess given perceptual attributes . </S>",
    "<S> an important aspect of the proposed model is that , if we change one of the input perceptual features , the corresponding appearance of the generated textures will also be changed . </S>",
    "<S> we design several experiments to validate the effectiveness of the proposed method . </S>",
    "<S> the results show that the proposed method can produce high quality texture images with desired perceptual properties .    </S>",
    "<S> l    texture generation , perceptual features , adversarial training , regression , neural networks </S>"
  ]
}