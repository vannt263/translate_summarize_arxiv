{
  "article_text": [
    "query log analysis has received extensive research attention nowadays , since the exploitation of user feedbacks from query log has been proven to be an effective and non - intrusive method to improve search quality .",
    "search engine has been recording user click through information all the time , which can be represented as a bipartite graph .",
    "the bipartite graph refers to query and url in most cases .",
    "an edge connects a query and a url and the edge value generally corresponds to the click frequency .",
    "many query log analysis models are based on the click graph , in that a certain url has been clicked by different queries ( issued by users ) and hence provides the information about the relevance of url , query and user .",
    "a query can be represented as a vector in which each dimension corresponds to the edge value between the query and a url .",
    "traditional models make use of the raw click frequency ( the number of clicks or users ) between a query and a url , which suffers from two problems : first , raw click frequency does not favor unpopular queries or urls ; moreover , ranking models based on raw click frequency often favor already frequently clicked urls because of inherent bias of clicks  @xcite .",
    "therefore it is worth to research on how to improve the representation of click graph before developing any analysis method . to leverage",
    "the influence of highly clicked urls , an entropy - biased model in  @xcite has been proposed to address the disadvantages of raw click frequency by weighting the raw click frequency with _ inverse query frequency _ ( iqf ) , under the assumption that less clicked urls are more relevant to a given query than heavily clicked ones .",
    "the inverse query frequency is inspired by _",
    "inverse document frequency _",
    "( idf ) in text retrieval , and  @xcite incorporates inverse query frequency into user frequency in the same manner as tf - idf does .",
    "although there are many interpretations  @xcite about why tf - idf has proved to be extraordinary robust in text retrieval , utilizing user click frequency in the same manner as tf - idf may not be appropriate in the context of user click graph .",
    "different from content - aware text retrieval , the click through information is the implicit feedback from users in that each click denotes a potential association between a query and a url .",
    "a click tends to be more informative than the case in text mining , since a document could contain much irrelevant information .",
    "therefore , our observation is that user frequency and inverse query frequency should be treated differently during query representation in the context of click graph .",
    "consistent with the assumption that less clicked urls tend to be more relevant to a given query , the inverse query frequency should be more informative than user frequency according to our observation .",
    "moreover , if inverse query frequency can be considered as a global property of each url on click graph , it is intuitive to develop the global consistency model for query representation , which utilizes user frequency and the global weight of url on user click graph in a consistent way to achieve better performance , as described in this paper .",
    "the contribution of this paper lies in : 1 ) we observe that the global nature of the url plays a central role for query representation on user click graph ; 2 ) a new scheme called _ inverse url frequency _ ( iuf ) is presented to specify the global weight of each url on click graph , and result shows that iuf is superior to iqf in the context of global consistency on click graph ; 3 ) we define the rules for achieving global consistency on click graph , and develop the framework of global consistency model for query representation .",
    "the rest of this paper is organized as follows : the related works are introduced in section  [ sec : rl ] , and we illustrate global consistency on click graph in section  [ sec : gcongraph ] .",
    "various query representation models are presented in section  [ sec : queryrepresent ] , while section  [ sec : datacollection ] and section  [ sec : exp ] presents the experimental analysis about the performance of different models under query similarity .",
    "conclusion is made in section  [ sec : conclusion ] .",
    "extensive research has been conducted on click graphs to exploit implicit feedback  @xcite .",
    "frequently studied topics include agglomerative clustering  @xcite , query clustering for url recommendation  @xcite , query suggestion  @xcite , which used hitting time to generate semantic consistent suggestions , and rare query suggestion  @xcite . moreover ,  @xcite worked on query classification through increasing the amount of training data by semi - supervised learning on the click graph instead of enriching feature representation",
    ". while there are works studying different aspects of user click information ,  @xcite revealed that the click probability of a webpage is influenced by its position on the result page .",
    "the sequential nature of user clicks has been considered in  @xcite , whereas @xcite combined both the click and skip information from users . in addition , having noticed that click graphs are very sparse and the click frequency follows the power law ,  @xcite made use of co - click information for document annotation .",
    "random walk has been applied to click graphs  @xcite to improve the performance of image retrieval .",
    "@xcite also employed random walk to smooth the click graph to tackle the sparseness issue .",
    "in contrast , less work has been carried out on the study of query representation on click graphs .",
    "@xcite represented each query as a point in a high dimensional space , with each dimension corresponding to a distinct url .",
    "@xcite introduced the query - set based model for document representation using query terms as features for summarizing the clicked webpages .",
    "the entropy - biased model for query representation has been proposed  @xcite to replace raw click frequency on the click graph .",
    "it assumed that less clicked urls are more effective in representing a given query than heavily clicked ones .",
    "thus , the raw click frequency was weighed by the inverse query frequency of the url . however , the entropy - biased model utilized raw click frequency and inverse query frequency in the same manner as tf - idf does , which may not be appropriate in the context of click graph .",
    "this is because user click information is content - ignorant while text retrieval is content - aware .",
    "our work is closely related to  @xcite , while our contribution is to study how to combine the raw click frequency and the global weight of url in a consistent way for query representation .",
    "the user click graph is generally regarded as a bipartite graph . in this paper",
    ", we consider a bipartite graph evolves query and url : g = ( q @xmath0 d , e ) , where the query set q and document ( url ) set d are connected by edges in e. suppose there are m queries and n documents in total , the bipartite graph can be represented as a rank m@xmath1n matrix c , with the entry ( i , j ) as the edge value of ( @xmath2 , @xmath3 ) . in most cases , the edge value corresponds to the raw click frequency @xmath4 between query @xmath2 and document ( url ) @xmath3 , which is the number of times the users click on @xmath3 when @xmath3 is presented to the users as a result for query @xmath2 .",
    "thus , a query @xmath2 can be represented as a row vector of c , and a document ( url ) @xmath5 corresponds to a column vector of c.    .preliminaries and notations [ cols=\"^,<\",options=\"header \" , ]     [ tab : length - pagerank ]    the average precisions of different models on personalized pagerank are very close compared with the performance on cosine or jaccard similarities , instead it is the behavior of each model that draws our attention . with more steps walked on the click graph",
    ", the result approaches to the stationary distribution .",
    "when the jumping constant @xmath6 , as indicated in figure  [ fig : pagerank](a ) , the global consistency model ( ufw - iqf ) experiences a significant drop of average precision at step 2 , while the behavior of other models follows the convention with better precision at step 2 . if the jumping constant @xmath7 which implies an extremely low rate of propagation on the graph , and the first step becomes the dominant factor since the result varies little in subsequent steps .",
    "as shown in figure  [ fig : pagerank](b ) , the average precision of each model is determined by the first step .",
    "the personalized pagerank reveals the nature of those different models : for the global consistency model , most of the relevant queries have already been retrieved during the first step , while subsequent steps are needed for other models to retrieve the most relevant results with a reasonable jumping constant . in other words ,",
    "the conventional models need a proper propagation rate to walk on the click graph in order to achieve the best performance , while within global consistency model , the best results are closely clung to the initial preferred vertex without much propagation . in table",
    "[ tab : length - pagerank ] , we also listed the average length of results at rank 10 with personalized pagerank , we observe that on one hand , a smaller jumping constant ( lower propagation rate ) favors long tail results within each model , since the propagation on the graph is heading to the queries with larger transition probability which tend to be the popular short tail queries ; on the other hand , the global consistency model ( ufw - iqf ) demonstrates the superiority of boosting long tail queries over other models despite of different jumping constants .",
    "in this paper we propose a novel model for query representation on user click graph , which is based on the observation that for a certain query , the global nature of urls is more informative than local user frequency .",
    "the global consistency model identifies the inverse query frequency from previous work as a global property of the url , based on which we suggests a more effective scheme called inverse url frequency which further considers the similarities among queries for global nature capturing . besides , we formalize the framework of utilizing user frequency in tune with the global nature of the url .",
    "the global consistency model consistently demonstrates better performance over current models for query representation under popular query similarities , in terms of better precision and long tail result boost .",
    "hence many query log analysis tasks can benefit from this query representation model .",
    "this work is supported by the national natural science foundation of china ( grant nos .",
    "61103185 , 61073118 and 61003247 ) , the start - up foundation of nanjing normal university ( grant no .",
    "2011119xgq0072 ) , natural science foundation of the higher education institutions of jiangsu province , china ( grant no .",
    "11kjb520009 ) , the 9th six talents peak project of jiangsu province ( grant no .",
    "dzxx-043 ) , and major program of national natural science foundation of jiangsu province ( grant no .",
    "bk2011005 ) ."
  ],
  "abstract_text": [
    "<S> extensive research has been conducted on query log analysis . </S>",
    "<S> a query log is generally represented as a bipartite graph on a query set and a url set . </S>",
    "<S> most of the traditional methods used the raw click frequency to weigh the link between a query and a url on the click graph . in order to address the disadvantages of raw click frequency </S>",
    "<S> , researchers proposed the entropy - biased model , which incorporates raw click frequency with inverse query frequency of the url as the weighting scheme for query representation . in this paper , we observe that the inverse query frequency can be considered a global property of the url on the click graph , which is more informative than raw click frequency , which can be considered a local property of the url . based on this insight </S>",
    "<S> , we develop the global consistency model for query representation , which utilizes the click frequency and the inverse query frequency of a url in a consistent manner . </S>",
    "<S> furthermore , we propose a new scheme called inverse url frequency as an effective way to capture the global property of a url . </S>",
    "<S> experiments have been conducted on the aol search engine log data . </S>",
    "<S> the result shows that our global consistency model achieved better performance than the current models . </S>"
  ]
}