{
  "article_text": [
    "aerial alice is flying in a surveillance plane high over hostile harry s territory .",
    "she wishes to relay her observations of harry s troop movements back to base - station bob over @xmath0 channel uses of an awgn channel with variance @xmath1 .",
    "harry obviously wishes to jam alice s transmissions .",
    "however , both alice s transmission energy and harry s jamming energy are constrained  they have access to energy sources of @xmath2 and @xmath3 joules respectively .- capacities '' exist . ]",
    "harry already knows _",
    "_ message _ alice wants to transmit ( after all , he knows the movements of his own troops ) , and also _ roughly how _",
    "she ll transmit it ( _ i.e. _ , her _ communication protocol / code _ , having recently captured another surveillance drone ) but he does nt know _ exactly how _",
    "she ll transmit it ( _ i.e. _ , her _ codeword _",
    " for instance , alice could choose to focus her transmit power on some random subset of the @xmath0 channel uses ) .",
    "further , since alice s transmissions are very quick , harry has no time to tune his jamming strategy to alice s actual codeword  he can only jam based on his prior knowledge of alice s code , and her message . different frequencies ",
    "these together could comprise her codeword .",
    "given such a strategy , since harry does nt know alice s codeword , he is unable to make his jamming strategy depend explicitly on the codeword alice actually transmits . ]    even in such an adverse jamming setting we demonstrate that alice can communicate with bob at a rate equalling @xmath4 as long as @xmath5 .",
    "note that this equals the capacity of an awgn with noise parameter equal to @xmath6  this means that no `` smarter '' jamming strategy exists for harry than simply behaving like awgn with variance @xmath7 .",
    "if @xmath8 no positive rate is possible since harry can `` spoof '' by transmitting a fake message using the same strategy as alice ",
    "bob is unable to distinguish between the real and fake transmissions .",
    "the model considered in this work is essentially a special type of arbitrarily varying channel ( avc ) for which , to the best of our knowledge , the capacity has not been characterized before in the literature .",
    "the notion of avcs was first introduced by blackwell _",
    "et al . _",
    "@xcite , to capture communication models wherein channel have unknown parameters that may vary arbitrarily during the transmission of a codeword .",
    "the case when both the transmitter and the jammer operate under constraints ( analogous to the quadratic constraints in this work ) has also been considered  @xcite . for",
    "an extensive survey on avcs the reader may refer to the excellent survey  @xcite and the references therein .",
    "the class of avcs over discrete alphabets has been studied in great detail in the literature  @xcite .",
    "however , less is known about avcs with continuous alphabets .",
    "the bulk of the work on continuous alphabet avcs ( outlined below in this section ) focuses on quadratically - constrained avcs .",
    "this is also the focus of our work .",
    "it is important to stress several features of the model considered in this work , and the differences with prior work :    * to generate her codeword from her message , alice is allowed to use private randomness ( known only to her _ a priori _ , but not to harry _ or _ bob .",
    "this is in contrast to the _ deterministic encoding _ strategies often considered in the information theory / coding theory literature , wherein the codeword is a deterministic function of the message . *",
    "everything bob knows about alice s transmission _ a priori _ , harry also knows .",
    "this is in contrast to the _ randomized encoding _ model also considered in the literature ( see for instance  @xcite ) , in which it is critical that alice and bob share _ common randomness _ that is unknown to harry . *",
    "the jammer is already aware of alice s message .",
    "this is one important difference in our model , from the model in the work closest to ours , that of  @xcite . *",
    "the jammer has no extra knowledge of the codeword being transmitted than what he has already gleaned from his knowledge of alice s code and her message .",
    "this is in contrast to the _ omniscient adversary _ often considered in the coding theory literature .",
    "these model assumptions are equivalent to requiring public stochastic codes with small maximum error of probability against an oblivious adversary .",
    "several papers also operate under _ some _ of these assumptions , but as far as we know , none examines the scenario where _ all _ these constraints are active .",
    "the literature on _ sphere packing _ focuses on an avc model wherein zero - error probability of decoding is required ( or , equivalently , when the probability ( over alice s codeword and harry s jamming actions ) of bob s decoding error is required to equal zero ) .",
    "inner and outer bounds were obtained by blachman  @xcite . like several other zero - error communication problems ( including shannon s classic work  @xcite ) characterization of the optimal throughput possible is challenging , and in general still an open problem .",
    "other related models include :    * the _ vector gaussian avc _  @xcite . as in the `` usual '' vector gaussian channels ,",
    "optimal code designs require `` waterfilling '' . *",
    "the _ per - sequence / universal _ coding schemes in  @xcite . * the _ correlated / myopic _ jammers in  @xcite , wherein jammers obtain a noisy version of alice s transmission and base their jamming strategy on this . * the _ joint source - channel coding , and coding with feedback _ models considered by baar  @xcite . * several other avc variants , including _ dirty paper coding _ , in  @xcite .    we summarize some of the results mentioned above in table  [ tab : comparisonavc ] .    [ cols=\"^,^,^\",options=\"header \" , ]      in this paper",
    "we study the capacity of a quadratic constrained avc with stochastic encoder under the attack of a malicious adversary who knows the transmitted message but is oblivious to the actual transmitted codewords .",
    "let the input and output of the channel are denoted by the random variables @xmath9 and @xmath10 where @xmath11 .",
    "then , formally , the channel is defined as follows @xmath12 where @xmath13 is the channel state chosen by a malicious adversary and @xmath14 is gaussian random variable . here",
    "we assume that the noise @xmath15 is independent over different uses of channel .",
    "the channel input is subjected to a peak power constraint as follows @xmath16 and the permissible state sequences are those satisfying @xmath17 the problem setup is depicted pictorially in figure  [ fig : problemsetup - noisycase ] .     but not to the transmitted codeword @xmath18 . ]    a _ code with stochastic encoder _",
    "@xmath19 of block - length @xmath0 consists of a set of encoders that are denoted by a random variable @xmath20 and a deterministic decoder @xmath21 where @xmath22 denote for an error and @xmath23 is the number of messages is an integer . ] .",
    "each encoder @xmath24 is constructed by a set of codewords @xmath25 from @xmath26 .    here in this paper",
    ", we focus on the _ maximum probability of error_. first , for a fixed jamming vector @xmath27 , let us define the probability of error given that the message @xmath28 has been sent as follows @xmath29.\\ ] ] then the maximum probability of error for a fixed @xmath27 is defined by @xmath30 now the _ capacity _ for the above channel can be stated as in definition  [ def : capacity ] .",
    "[ def : capacity ] the capacity @xmath31 of an avc with stochastic encoder under the quadratic transmit constraint @xmath32 and jamming constraint @xmath7 is the supremum over the set of real numbers such that for every @xmath33 and sufficiently large @xmath0 there exist codes with stochastic encoder @xmath19 that satisfies the following conditions .",
    "first , for the number of messages @xmath34 encoded by the code we have @xmath35 . moreover , each codeword satisfies the quadratic constraint   and finally for the code we have @xmath36",
    "the main results of the paper , stated in theorem  [ thm : capacityavc - noiseless ] and its corollary .",
    "[ thm : capacityavc - noisy ] the capacity of a quadratic - constrained avc channel under the maximum probability of error criterion with transmit constraint @xmath32 and jamming constraint @xmath7 and additive gaussian noise of power @xmath1 is given by @xmath37    the result of theorem  [ thm : capacityavc - noisy ] matches the result of stochastic encoder over discrete alphabets @xcite , ( * ? ? ?",
    "* theorem  7 ) , in which it is shown that for the _ average _ probability of error criterion , using a stochastic encoder does nt increase the capacity .",
    "because the number of possible adversarial actions here is uncountably large , the technique of @xcite , which relies on taking a union bound over at most exponential - sized set of possible adversarial actions , does not work .",
    "[ thm : capacityavc - noiseless ] the capacity of a quadratic - constrained avc under the maximum probability of error criterion with transmit constraint @xmath32 and jamming constraint @xmath7 is given by @xmath38",
    "in this section , we present the proof of theorem  [ thm : capacityavc - noisy ] and its corollary .",
    "the proof of the converse parts of theorem  [ thm : capacityavc - noisy ] is stated in section  [ sec : avc - noisy - proof - converse ] . for the achievability part of theorem  [ thm : capacityavc - noisy ]",
    ", we claim that the same _ minimum distance decoder _ proposed in @xcite to achieve the capacity for the average probability of error criterion , which is given by @xmath39 also achieves the capacity for the maximum probability of error criterion .",
    "note that in order to show the suprimum over @xmath27 subject to of @xmath40 goes to zero it is sufficient to show that for every message @xmath28 the suprimum over @xmath27 subject to of @xmath41 goes to zero .    to communicate , alice ( the transmitter ) randomly picks a codebook @xmath42 and fixes it .",
    "the codebook @xmath42 comprises @xmath43 codewords @xmath44 , @xmath45 and @xmath46 , each chosen uniformly at random and independently from a sphere of radius @xmath47 as it is shown in figure  [ fig : stochastic_codebook_avc ] ( caption ( a ) ) .",
    "then , the @xmath28th row of the codebook , i.e. , @xmath48 , is assigned to the @xmath28th message . in order to transmit the message @xmath28",
    ", the encoder randomly picks a codeword from the @xmath28th row of the codebook and sends it over the channel .",
    "the encoder chooses one of the @xmath49 codewords randomly from the @xmath28th row of the above table .",
    "( b ) assuming that the codeword @xmath44 is sent , in our model an error occurs if the ml decoder declares @xmath50 for some @xmath51 .",
    "note that there is no error if the decoder declares another codeword from the @xmath28th row .",
    "]    now , given that the message @xmath28 has been transmitted , the error probability @xmath41 of an stochastic code used over a quadratic - constrained avc under the use of the minimum distance decoder ( defined by ) equals @xmath52 \\nonumber\\\\ = & { \\mathbb{p}}_{t } { \\mathbb{p}}_{v } \\big [ \\| { \\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v}}-{\\boldsymbol{x}}(j , t ' ) \\|^{2 } \\nonumber\\\\ & \\quad\\leq \\| { \\boldsymbol{s}}+{\\boldsymbol{v } } \\|^{2 } \\ ; \\text{for some $ i\\neq j$ and $ t'$ } \\big ] \\nonumber\\\\ \\stackrel{}{= } & { \\mathbb{p}}_t { { \\mathbb{p}}}_{v } \\big [ \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t ) + { \\boldsymbol{s } } + { \\boldsymbol{v } } \\rangle \\ge np \\nonumber\\\\ & \\quad + \\langle { \\boldsymbol{x}}(i , t ) , { \\boldsymbol{s } } + { \\boldsymbol{v}}\\rangle\\ ; \\text{for some $ j\\neq i$ and $ t'$ } \\big].\\end{aligned}\\ ] ] where @xmath53 is a uniformly distributed random variable defined over the set @xmath54 .",
    "figure  [ fig : stochastic_codebook_avc ] ( caption ( b ) ) pictorially demonstrates the decoding errors at the decoder .",
    "the main step in proving the achievability part of theorem  [ thm : capacityavc - noisy ] consists in asserting the doubly exponential probability bounds which is stated in lemma  [ lem : codeprop_doublyexpprob_noisy ] .",
    "[ lem : codeprop_doublyexpprob_noisy ] let @xmath55 in which @xmath56 and @xmath57 be a random codebook comprises of independent random vectors @xmath58 each uniformly distributed on the @xmath0-dimensional sphere of radius @xmath47 .",
    "first , fix a vector @xmath59 .",
    "then for every @xmath60 and for sufficiently large @xmath0 if @xmath61 we have @xmath62 \\geq k e^{-n\\delta_{1 } } \\bigg]\\\\ & \\leq \\exp \\big ( -(k\\log{2}-10 ) \\exp((\\delta_{0}-\\delta_{1})n ) \\big).\\end{aligned}\\ ] ]      [ lem : smallperturbation_s - noisyavc ] for a fixed jamming vector @xmath27 , for sufficiently small @xmath63 , and for every @xmath60 , there exists a codebook @xmath64 of rate @xmath65 comprises of vectors @xmath66 of size @xmath47 with @xmath67 and @xmath68 which performs well over the avc defined in section  [ sec : probstatementavc ] for all @xmath69 , i.e. , it satisfies @xmath70 \\nonumber\\\\ & < k\\exp(-n\\delta_{1})\\end{aligned}\\ ] ] for all @xmath69 .    for a particular @xmath27 , instead of ,",
    "let us assume that the code @xmath42 satisfies a stronger condition @xmath71 \\nonumber\\\\ & < k\\exp(-n\\delta_{1 } ) .",
    "\\end{aligned}\\ ] ] then it can be verified that for all @xmath69 the code @xmath42 satisfies where @xmath27 is replaced by @xmath72 . to show this let @xmath73 where @xmath74 is an arbitrary unit vector and @xmath75 $ ] .",
    "hence for all @xmath69 we can write @xmath76 \\nonumber\\\\ & = { { \\mathbb{p}}}_{t } { \\mathbb{p}}_v \\big [ \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v } } \\rangle + \\rho \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{u } } \\rangle \\nonumber\\\\ & \\hspace{17pt } \\geq np+\\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s } } + { \\boldsymbol{v } } \\rangle \\nonumber\\\\ & \\hspace{46pt } + \\rho \\langle { \\boldsymbol{x}}(i , t ) , { \\boldsymbol{u } } \\rangle \\ ; \\mathrm{for\\ ; some}\\ ; j\\neq i \\ ; \\mathrm{and}\\ ; t ' \\big ] \\nonumber\\\\ & \\le { { \\mathbb{p}}}_{t } { \\mathbb{p}}_v \\big [ \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v } } \\rangle +   \\varepsilon\\sqrt{np } \\nonumber\\\\ & \\hspace{17pt } \\geq np+\\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s } } + { \\boldsymbol{v } } \\rangle \\nonumber\\\\ & \\hspace{46pt } -\\varepsilon\\sqrt{np } \\ ; \\mathrm{for\\ ; some}\\ ; j\\neq i \\ ; \\mathrm{and}\\ ; t ' \\big ] \\nonumber\\\\ & \\stackrel{\\text{(a)}}{\\le } k\\exp(-n\\delta_1),\\end{aligned}\\ ] ] where ( a ) follows from .    now , in lemma  [ lem : codeprop_doublyexpprob_noisy ] we can use the stronger error requirement to show that there exists a code which satisfies .",
    "this stronger requirement results in a rate loss , but as @xmath77 goes to zero the rate loss due to that vanishes . by the above argument",
    ", we know that this code satisfies for all @xmath69 and we are done .    finally , lemma  [ lem : codebookexistence - noisy ] shows the existence of a good codebook for the quadratic constrained avc problem with stochastic encoder which have been introduced in section  [ sec : probstatement - scalaravc ] and hence completes the proof of theorem  [ thm : capacityavc - noisy ] .",
    "[ lem : codebookexistence - noisy ] for every @xmath78 and @xmath79 there exist a codebook @xmath80 of rate @xmath81 comprises of vectors @xmath66 of size @xmath47 with @xmath67 and @xmath68 such that for every vector @xmath27 and every transmitted message @xmath28 we have @xmath82 \\nonumber\\\\ & < k\\exp(-n\\delta_{1 } ) .",
    "\\end{aligned}\\ ] ]    for any fixed codebook @xmath83 , let us explicitly mention to the dependency of the error probability on @xmath42 by defining @xmath84 .",
    "then in order to prove the assertion of lemma we can equivalently show that @xmath85 > 0.\\ ] ] however , by using lemma  [ lem : smallperturbation_s - noisyavc ] , it is not necessary to check for all @xmath27 but only for those belonging to an @xmath77-net - net is a set of points in a metric space such that each point of the space is within distance @xmath77 of some point in the set . ]",
    "@xmath86 that covers @xmath87 .",
    "hence , we can write @xmath88 \\nonumber\\\\ & \\hspace{30pt }   = 1-{\\mathbb{p}}_{{\\mathcal{c}}^ * } \\left [ \\exists{\\boldsymbol{s}}\\in\\chi_n,\\exists i \\:\\:\\ : e_{{\\mathcal{c}}^ * } ( { \\boldsymbol{s } } , i ) \\ge ke^{-n\\delta_1 } \\right ] \\nonumber\\\\ & \\hspace*{30pt } \\stackrel{\\text{(a)}}{\\ge } 1 - \\sum_{{\\boldsymbol{s}}\\in \\chi_n } \\sum_{i=1}^{e^{nr } } { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\left [ e_{{\\mathcal{c}}^ * } ( { \\boldsymbol{s } } , i ) \\ge ke^{-n\\delta_1 } \\right],\\end{aligned}\\ ] ] where ( a ) follows from the union bound .",
    "now , note that to bound @xmath89 one might cover @xmath87 by a hypercube of edge size @xmath90 ; see figure  [ fig : nu_dense_subset_covering ] .",
    "so we can write @xmath91 . then , by using lemma  [ lem : codeprop_doublyexpprob_noisy ] we have @xmath88 \\nonumber\\\\ & \\hspace{30pt } \\ge 1- \\left ( \\frac{2\\sqrt{n\\lambda}}{\\varepsilon } \\right)^n   \\times e^{nr}\\times \\exp\\left ( -k ' e^{n(\\delta_0-\\delta_1 ) } \\right),\\end{aligned}\\ ] ] where , assuming @xmath92 , the right hand side goes to @xmath93 as @xmath0 goes to infinity and this completes the proof of lemma .",
    "the converse of theorem  [ thm : capacityavc - noisy ] follows by combining two different upper bounds on the capacity .",
    "the first bound follows by observing that if the randomness of the stochastic encoder is also shared with the decoder we can achieve higher rates . so by using result of @xcite for randomized codes , we have the following upper bound on the capacity of an avc with stochastic encoder @xmath94    now , it only remains to show that @xmath95 for @xmath96 where we use a similar argument to @xcite ( also see @xcite ) . to this end , we show that the adversary can fool the decoder and make it confused . because @xmath96 , the adversary can use a stochastic encoder @xmath97 with the same probabilistic characteristic of @xmath98 where we assume that @xmath98 and @xmath97 are independent . then for any decoder @xmath99 and for any @xmath100 we can write @xmath101   \\\\ & \\hspace{75pt }   = { \\mathbb{p}}\\left [ \\phi \\left ( \\psi(j)+\\psi'(i ) + { \\boldsymbol{v } }",
    "\\right ) \\neq i \\right ] \\\\ & \\hspace{75pt }   = 1-{\\mathbb{p}}\\left [ \\phi \\left ( \\psi(j)+\\psi'(i ) + { \\boldsymbol{v } } \\right ) = i \\right ] \\\\ & \\hspace{75pt }   \\ge 1-{\\mathbb{p}}\\left [ \\phi \\left ( \\psi(j)+\\psi'(i ) + { \\boldsymbol{v } } \\right ) \\neq j \\right].\\end{aligned}\\ ] ] hence we have @xmath102 \\\\ & \\ge \\frac{1}{m^2 } \\sum_{i , j=1}^{m } \\big [ { \\mathbb{p}}\\left [ \\phi \\left ( \\psi(i)+\\psi'(j ) + { \\boldsymbol{v } } \\right ) \\neq i \\right ] \\\\ & \\quad + { \\mathbb{p}}\\left [ \\phi \\left ( \\psi(j)+\\psi'(i ) + { \\boldsymbol{v } } \\right ) \\neq j \\right ] \\big ] \\\\ & \\ge \\frac{1}{m^2 } \\frac{m(m-1)}{2}\\\\ & \\ge \\frac{1}{4},\\end{aligned}\\ ] ] where @xmath103 .",
    "this shows that @xmath104 \\ge \\frac{1}{4},\\ ] ] which means there exists at least a @xmath105 such that @xmath106\\ge \\frac{1}{4}$ ] and this completes the proof .",
    "[ fact : probupperbound ] for two events @xmath107 and @xmath108 we can write @xmath109 = { \\mathbb{p } } [ \\mathcal{a}\\cap(\\mathcal{b}\\cup\\bar{\\mathcal{b } } ) ]      \\le { \\mathbb{p } } [ \\mathcal{b } ] + { \\mathbb{p } } [ \\mathcal{a}\\cap \\bar{\\mathcal{b } } ] .\\ ] ]      [ lem : csiszarnar - lem - a1 ] let @xmath110 be arbitrary r.v.s and @xmath111 be arbitrary function with @xmath112 , @xmath113",
    ". then the condition @xmath114\\leq a \\:\\:\\:\\ :",
    "\\mathrm{a.s.},\\:\\:\\:\\:\\:\\ : i=1,\\ldots , l,\\ ] ] implies that @xmath115 \\leq \\exp\\left(-l(\\tau\\log2-a)\\right).\\ ] ]    [ lem : bounddotproduct ] let the random vector @xmath116 be uniformly distributed on the @xmath0-dimensional unit sphere . then for every vector @xmath74 on this sphere and any @xmath117",
    ", we have @xmath118 \\leq 2(1-\\alpha^{2})^{\\frac{(n-1)}{2}}.\\ ] ]      to derive the doubly exponential bound stated in the lemma , we use lemma  [ lem : csiszarnar - lem - a1 ] . to this end",
    "let us define the functions @xmath121 for @xmath46 as follows @xmath122.\\end{aligned}\\ ] ] now , by using the functions @xmath121 , the probability expression in the statement of lemma can be written as follows @xmath123 \\geq k e^{-n\\delta_{1 } } \\bigg ] \\nonumber\\\\ & = { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\bigg [ \\frac{1}{e^{n\\delta_0 } } \\sum_{t=1}^{e^{n\\delta_0 } } { \\mathbb{p}}_{v } \\big [ \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t ) + { \\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\geq p \\nonumber\\\\ & \\quad\\quad + \\langle { \\boldsymbol{x}}(i , t ) , { \\boldsymbol{s } } + { \\boldsymbol{v } } \\rangle \\ ; \\mathrm{for}\\ ; \\mathrm{some}\\ ; \\mathrm{j}\\neq \\mathrm{i}\\ ; \\mathrm{and}\\ ; t '   \\big ] \\geq k e^{-n\\delta_{1 } } \\bigg ] \\nonumber\\\\ & = { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\bigg [ \\frac{1}{e^{n\\delta_0 } } \\sum_{t=1}^{e^{n\\delta_0 } } f_t\\left({\\boldsymbol{x}}(i,1),\\ldots,{\\boldsymbol{x}}(i , t ) \\right ) \\ge k e^{-n\\delta_{1 } } \\bigg].\\end{aligned}\\ ] ] in order to bound we use lemma  [ lem : csiszarnar - lem - a1 ] . to this end",
    ", we have to bound the expected values of the functions @xmath121 .",
    "so we proceed as follows @xmath124 \\nonumber\\\\ & = { \\mathbb{e}}_{{\\mathcal{c}}^ * } \\bigg [ { \\mathbb{p}}_{v } \\big [ \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t ) + { \\boldsymbol{s } } + { \\boldsymbol{v}}\\rangle \\nonumber\\\\ & \\quad\\geq p+\\langle { \\boldsymbol{x}}(i , t ) , { \\boldsymbol{s}}\\rangle + \\langle { \\boldsymbol{x}}(i , t ) , { \\boldsymbol{v}}\\rangle \\nonumber\\\\ & \\quad \\ : \\text{for some $ j\\neq i$ and $ t'$ } \\big ] \\bigg| { \\boldsymbol{x}}(i,1),\\ldots,{\\boldsymbol{x}}(i , t-1 ) \\bigg ] \\nonumber\\\\ & \\stackrel{\\text{(a)}}{= } { \\mathbb{p}}_{v } \\bigg [ { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ \\bigcup_{(j , t'):\\ :",
    "j\\neq i } \\big\\ { \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle   \\nonumber\\\\ & \\quad \\geq p+\\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\big\\ } \\big ] \\bigg ] \\nonumber\\\\ & \\stackrel{\\text{(b)}}{\\leq }   { { \\mathbb{p}}}_{v }   { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ \\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v } } \\rangle\\leq -\\delta_{2 }   \\big ] \\nonumber\\\\ & \\quad + { \\mathbb{p}}_{v } \\bigg [ { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ \\bigcup_{(j , t ' ) : \\ : j\\neq i } \\big\\ { \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\nonumber\\\\ & \\quad \\geq p + \\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\big\\ } , \\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle > -\\delta_{2 } \\big ] \\bigg],\\end{aligned}\\ ] ] where ( a ) follows because @xmath58 are independent random variables so the conditioning can be removed and also using the fact that for an event @xmath107 we have @xmath125={\\mathbb{p}}_{{\\mathcal{c}}^*}{\\mathbb{p}}_v[\\mathcal{a}]$ ] and ( b ) follows from fact  [ fact : probupperbound ] .",
    "now , for @xmath126 , by using fact  [ fact : probupperbound ] we can bound the first term of as follows @xmath127 \\nonumber\\\\ & \\leq { \\mathbb{p}}_{v } \\big [ \\| { \\boldsymbol{s}}+{\\boldsymbol{v } } \\|^2 \\geq \\| { \\boldsymbol{s } } \\|^2 + \\sigma^2+\\delta_{2 } \\big ] \\nonumber\\\\ & \\quad + { \\mathbb{p}}_{v } { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ \\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\le -\\delta_{2 } , \\nonumber\\\\ & \\hspace{60pt } \\| { \\boldsymbol{s}}+{\\boldsymbol{v } } \\|^2 <",
    "\\| { \\boldsymbol{s } } \\|^2 + \\sigma^2+\\delta_{2 } \\big ] \\nonumber\\\\ & \\leq { \\mathbb{p}}_{v } \\big [ \\| { \\boldsymbol{s}}+{\\boldsymbol{v } } \\|^2 \\geq \\| { \\boldsymbol{s } } \\|^2 + \\sigma^2+\\delta_{2 } \\big ] \\nonumber\\\\ & \\quad + { \\mathbb{p}}_{v } { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ |\\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle| \\geq \\delta_{2 } , \\nonumber\\\\ & \\hspace{60pt } \\| { \\boldsymbol{s}}+{\\boldsymbol{v } } \\|^2 < \\| { \\boldsymbol{s } } \\|^2 + \\sigma^2+\\delta_{2 } \\big].\\end{aligned}\\ ] ] first note that @xmath128 . then , since @xmath129 is a sequence of i.i.d . gaussian random variables @xmath130",
    ", the first term of can be bounded as follows @xmath131 \\nonumber\\\\ & = { \\mathbb{p}}\\big [ \\|{\\boldsymbol{v } } \\|^{2}+2\\langle{\\boldsymbol{s}},{\\boldsymbol{v}}\\rangle > \\sigma^{2}+\\delta_{2 } \\big ] \\nonumber\\\\ & \\stackrel{\\text{(a)}}{\\leq } { \\mathbb{p } } [ \\langle{\\boldsymbol{s}},{\\boldsymbol{v}}\\rangle\\geq \\eta ]   + { \\mathbb{p } } [ \\|{\\boldsymbol{v}}\\|^{2}+2\\eta > \\sigma^{2}+\\delta_{2 } ] \\nonumber\\\\ & \\stackrel{\\text{(b)}}{=}{\\mathbb{p}}\\left [ \\langle{\\boldsymbol{u}},{\\boldsymbol{v}}\\rangle\\geq \\frac{\\eta } { \\| { \\boldsymbol{s } } \\| } \\right ] + { \\mathbb{p}}\\big [ \\|{\\boldsymbol{v}}\\|^2 > \\sigma^{2}+\\delta_{2 } - 2\\eta \\big],\\end{aligned}\\ ] ] where ( a ) follows from fact  [ fact : probupperbound ] for @xmath132 and in ( b ) we define @xmath133 . because @xmath74 is a unitary vector it is straightforward to show that @xmath134 .",
    "hence the first term in can be bounded as follows @xmath135 = q\\left ( \\frac{\\sqrt{n}\\eta}{\\sigma \\|{\\boldsymbol{s}}\\| } \\right )      \\le \\frac{1}{2 } \\exp { \\left ( - \\frac{\\eta^2 n}{2\\sigma^2 \\lambda }   \\right)},\\ ] ] where in the above equation we have used the approximation @xmath136 . in order to bound the second term in note that @xmath137 has the chi - squared distribution with @xmath0 degree of freedom . then by using ( * ? ? ?",
    "* lemma  1 ) we can bound the second term of as follows @xmath138 \\nonumber\\\\ & \\hspace{20pt } \\le \\exp\\left ( -\\frac{1}{2}\\left [ 1+\\frac{\\delta_2 - 2\\eta}{\\sigma^2}-\\sqrt{1 + 2\\frac{\\delta_2 - 2\\eta}{\\sigma^2 } } \\right ] n \\right ) \\nonumber\\\\ & \\hspace{20pt } = \\exp(-\\xi n ) , \\ ] ] where @xmath139 $ ] is a positive quantity if @xmath140 .",
    "now it remains to bound the second term of . to this end",
    "let us write @xmath146 \\\\ & = \\int_{0}^{\\| { \\boldsymbol{s}}\\|^2 + \\sigma^{2}+\\delta_{2}}{{\\mathbb{p}}}_{v}{{\\mathbb{p}}}_{{\\mathcal{c}}^ * } \\big [ |\\langle { \\boldsymbol{x}}(i , t),{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle| > \\delta_{2 } \\ : \\big|    \\\\ & \\hspace{160pt }   \\|{\\boldsymbol{s}}+{\\boldsymbol{v}}\\|^{2}=r \\big ] df(r ) \\end{aligned}\\ ] ] where @xmath147 $ ] .",
    "then we can write @xmath146 \\\\ & = \\int_{0}^{\\| { \\boldsymbol{s } } \\|^2 + \\sigma^{2 } + \\delta_{3 } } { \\mathbb{p}}_{v } { \\mathbb{p}}_{{\\mathcal{c}}^ * } \\big [ \\langle { \\boldsymbol{x}}(i , t),\\frac{{\\boldsymbol{s}}+{\\boldsymbol{v}}}{\\|{\\boldsymbol{s}}+{\\boldsymbol{v}}\\|}\\rangle > \\frac{\\delta_{2}}{\\sqrt{r } } \\big| \\\\ & \\hspace{160pt } \\| { \\boldsymbol{s } } + { \\boldsymbol{v } } \\|^{2 } = r \\big ] df(r)\\\\ & \\stackrel{\\text{(a)}}{\\leq } { { \\mathbb{p}}}_{u}{{\\mathbb{p}}}_{\\breve{{\\mathcal{c}}}^ * } \\left [ \\langle \\breve{{\\boldsymbol{x}}}(i , t ) , { \\boldsymbol{u } } \\rangle > \\frac{\\delta_{2}/\\sqrt{p } } { \\sqrt { \\|{\\boldsymbol{s}}\\|^2 + \\sigma^{2}+\\delta_{2 } } } \\right]\\end{aligned}\\ ] ] where @xmath148 , @xmath149 , and ( a ) is true because evaluating the term inside the integration for the point @xmath150 can only increase the probability term .",
    "next , it follows that @xmath151 \\nonumber\\\\ & = \\int { \\mathbb{p}}_{\\breve{{\\mathcal{c}}}^ * } \\left[\\langle \\breve{{\\boldsymbol{x}}}(i , t),{\\boldsymbol{u}}\\rangle > \\frac{\\delta_{2}/\\sqrt{p}}{\\sqrt { \\|{\\boldsymbol{s}}\\|^2 + \\sigma^{2}+\\delta_{2 } } } \\big| { \\boldsymbol{u}}={\\boldsymbol{u } } \\right ] f_{{\\boldsymbol{u}}}({\\boldsymbol{u}})d{\\boldsymbol{u } } \\nonumber\\\\ & \\stackrel{\\text{(a)}}{\\leq } \\int 2\\left(1-\\frac{{{\\delta}_{2}}^{2 } /p}{\\|{\\boldsymbol{s}}\\|^2+\\sigma^{2}+{\\delta}_{2 } } \\right)^{\\frac{n-1}{2}}f_{{\\boldsymbol{u}}}({\\boldsymbol{u}})d{\\boldsymbol{u } } \\nonumber\\\\ & = 2\\left(1-\\frac{{{\\delta}_{2}}^{2}/p}{\\|{\\boldsymbol{s}}\\|^2+\\sigma^{2}+{\\delta}_{2 } } \\right)^{\\frac{n-1}{2 } } \\nonumber\\\\ & \\stackrel{\\text{(b)}}{\\leq } 2\\exp\\left(-\\frac{n-1}{2}\\frac{{{\\delta}_{2}}^{2 } /p}{\\|{\\boldsymbol{s}}\\|^2+\\sigma^{2}+{\\delta}_{2 } } \\right)\\end{aligned}\\ ] ] where ( a ) follows from lemma  [ lem : bounddotproduct ] and ( b ) follows from the inequality @xmath152 for @xmath153 .",
    "finally , by combining , , , , and we can bound the first term in as follows @xmath154 \\leq \\nonumber\\\\ & \\quad 2\\exp\\left(-\\frac{n-1}{2}\\frac{{{\\delta}_{2}}^{2}/p}{\\|{\\boldsymbol{s}}\\|^2+\\sigma^{2}+{\\delta}_{2 } } \\right)+e^{-n\\xi}+\\frac{1}{2}e^{-\\frac{n{\\eta}^2}{2{\\sigma}^2\\lambda}}. \\end{aligned}\\ ] ]    now we bound the second term in as follows .",
    "suppose @xmath107 denotes for the event @xmath155 and let @xmath156 .",
    "then for the second term of , we note that @xmath157 \\nonumber\\\\ & \\stackrel{(a)}{\\leq }   { \\mathbb{p}}_{v } \\left [ \\|{\\boldsymbol{s}}+{\\boldsymbol{v}}\\|^2 \\ge \\|{\\boldsymbol{s}}\\|^2 + \\sigma^2+\\delta_2 \\right ] \\nonumber\\\\ & + { \\mathbb{p}}_{v{\\mathcal{c}}^ * } \\bigg [ \\bigcup_{\\begin{subarray}{c } ( j , t ' ) : \\\\",
    "j\\neq i \\end{subarray } } \\big\\ { \\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle   \\geq p + \\phi \\big\\ } , \\mathcal{a } , \\mathcal{b }   \\bigg ] \\nonumber\\\\ & \\stackrel{(b)}{\\leq }   e^{-n\\xi } + \\frac{1}{2}e^{-\\frac{n\\eta^2}{2\\sigma^2\\lambda } } \\nonumber\\\\ & + \\sum_{(j , t ' ) : \\ : j\\neq i } { \\mathbb{p}}_{v{\\mathcal{c}}^ * } \\left[\\langle { \\boldsymbol{x}}(j , t'),{\\boldsymbol{x}}(i , t)+{\\boldsymbol{s}}+{\\boldsymbol{v}}\\rangle \\geq p + \\phi , \\mathcal{a } , \\mathcal{b } \\right ] , \\nonumber\\end{aligned}\\ ] ] where ( a ) follows from fact  [ fact : probupperbound ] and we use @xmath108 to denote the event @xmath158 . the first two terms in ( b ) follow from , , and while the third term is a result of the union bound .",
    "let us define the unit vectors @xmath159 and @xmath160 .",
    "then we note that @xmath157 \\nonumber\\\\ & \\stackrel{\\text{(a)}}{\\le } e^{-n\\xi } + \\frac{1}{2}e^{-\\frac{n\\eta^2}{2\\sigma^2\\lambda } } \\nonumber\\\\ & \\quad + \\sum_{(j , t ' ) : \\ : j\\neq i } { \\mathbb{p}}_{u\\breve{{\\mathcal{c}}}^ * } \\bigg [ \\langle \\breve{{\\boldsymbol{x}}}(j , t ' ) , { \\boldsymbol{u } } \\rangle \\nonumber\\\\ & \\hspace{85pt } \\ge \\frac{p+\\phi}{\\sqrt{p } \\sqrt{p+\\|{\\boldsymbol{s}}+{\\boldsymbol{v}}\\|^2 + 2\\phi } } \\big| \\mathcal{a } , \\mathcal{b } \\bigg ] \\nonumber\\\\ & \\stackrel{\\text{(b)}}{\\le } e^{-n\\xi } + \\frac{1}{2}e^{-\\frac{n\\eta^2}{2\\sigma^2\\lambda } } \\nonumber\\\\ & \\quad + \\sum_{(j , t ' ) : \\ : j\\neq i } { \\mathbb{p}}_{u\\breve{{\\mathcal{c}}}^ * } \\bigg [ \\langle \\breve{{\\boldsymbol{x}}}(j , t ' ) , { \\boldsymbol{u } } \\rangle \\nonumber\\\\ & \\hspace{85pt } \\ge \\frac{p-\\delta_2}{\\sqrt{p } \\sqrt{p+\\lambda + \\sigma^2+\\delta_2 -2\\delta_2 } }   \\bigg ] \\nonumber\\end{aligned}\\ ] ] where in ( a ) we use the fact that @xmath161 \\le { \\mathbb{p}}[\\mathcal{e}|\\mathcal{a},\\mathcal{b}]$ ] and ( b ) follows because by substituting @xmath162 and @xmath163 the probability term in front of the summation in ( a ) can only increase ; this implies that we can remove the conditioning with respect to events @xmath107 and @xmath108 .",
    "now , by applying lemma  [ lem : bounddotproduct ] , we can further bound the second term of as follows @xmath164 \\nonumber\\\\ & \\le e^{-n\\xi } + \\frac{1}{2}e^{-\\frac{n\\eta^2}{2\\sigma^2\\lambda } } \\nonumber\\\\ & \\quad + 2e^{n(r+\\delta_0 ) } \\left(1-\\frac{p-\\delta'_2}{p+\\lambda + \\sigma^2 -\\delta_2 } \\right)^{\\frac{n-1}{2 } } \\nonumber\\\\ & \\le e^{-n\\xi } + \\frac{1}{2}e^{-\\frac{n\\eta^2}{2\\sigma^2\\lambda } } \\nonumber\\\\ & \\quad + 2e^{n(r+\\delta_0 ) + \\frac{n-1}{2 } \\log { \\left(1-\\frac{p-\\delta'_2}{p+\\lambda + \\sigma^2 -\\delta_2 } \\right ) } } , \\end{aligned}\\ ] ] where @xmath165 .",
    "finally , by combining and we can write the following bound for the expectation of functions @xmath121 @xmath166 \\nonumber\\\\ & \\le 2\\exp\\left(-\\frac{n-1}{2}\\frac{{{\\delta}_{2}}^{2}/p}{\\|{\\boldsymbol{s}}\\|^2+\\sigma^{2}+{\\delta}_{2 } } \\right)+ 2e^{-n\\xi } + e^{-\\frac{n{\\eta}^2}{2{\\sigma}^2\\lambda } } \\nonumber\\\\ & \\quad+ 2e^{n(r+\\delta_0 ) + \\frac{n-1}{2 } \\log { \\left(1-\\frac{p-\\delta'_2}{p+\\lambda + \\sigma^2 -\\delta_2 } \\right ) } } .\\end{aligned}\\ ] ] by making some more assumptions on @xmath167 , @xmath168 , @xmath169 , @xmath170 , and introducing @xmath171 , we can simplify the upper bounds on the expected values of functions @xmath121 as follows @xmath166 \\nonumber\\\\ & \\stackrel{\\text{(a)}}{\\leq } 2\\exp{\\left(-n\\frac{1}{16}{(\\frac{\\delta_{2}-2\\eta}{\\sigma^2})}^2 \\right ) } + \\exp{\\left(-\\frac{n\\eta^2}{2\\sigma^2\\lambda}\\right)}\\\\ & \\quad + 2\\exp{\\left(-(\\frac{n-1}{2})\\frac{\\delta_{2}^2/p}{2{({\\|{\\boldsymbol{s}}\\|}^2+\\sigma ^2)}}\\right ) } + 2\\exp{(-n\\delta_{1})}\\\\ & \\stackrel{\\text{(b)}}{\\leq } 2\\exp{(-n\\delta_{1 } ) } + \\exp{(-n\\delta_1 ) } + 2\\exp{(-n\\delta_1 ) } + 2\\exp{(-n\\delta_{1})}\\\\ & \\le 10\\exp{(-n\\delta_1)}\\end{aligned}\\ ] ] where ( a ) follows by remark  [ rmrk : lemdublyexp_noisy_bound_xi ] , assuming @xmath172 , and choosing @xmath173 ( b ) follows by assuming the conditions @xmath174 , @xmath175 , and @xmath176 .",
    "then by applying lemma  [ lem : csiszarnar - lem - a1 ] and choosing @xmath177 and @xmath178 we have @xmath179 \\big ] \\geq k e^{-n\\delta_{1 } } \\bigg ] \\nonumber\\\\ & \\le \\exp\\left(-\\exp(n\\delta_0 ) \\big ( k\\log{2}\\exp(-n\\delta_1)-10\\exp(-n\\delta_1 ) \\big ) \\right ) \\nonumber\\\\ & = \\exp\\big ( -(k\\log{2}-10 ) \\exp(n(\\delta_0-\\delta_1 ) ) \\big).\\end{aligned}\\ ] ] by assuming @xmath60 we obtain the desired doubly exponential bound , hence we are done ."
  ],
  "abstract_text": [
    "<S> in this work we study an arbitrarily varying channel ( avc ) with quadratic power constraints on the transmitter and a so - called `` oblivious '' jammer ( along with additional awgn ) under a _ maximum probability of error _ criterion , and no private randomness between the transmitter and the receiver . </S>",
    "<S> this is in contrast to similar avc models under the _ average probability of error _ criterion considered in  @xcite , and models wherein common randomness is allowed  @xcite  these distinctions are important in some communication scenarios outlined below .    </S>",
    "<S> we consider the regime where the jammer s power constraint is smaller than the transmitter s power constraint ( in the other regime it is known no positive rate is possible ) . for this regime </S>",
    "<S> we show the existence of stochastic codes ( with _ no common randomness _ between the transmitter and receiver ) that enables reliable communication at the same rate as when the jammer is replaced with awgn with the same power constraint . </S>",
    "<S> this matches known information - theoretic outer bounds . </S>",
    "<S> in addition to being a stronger result than that in  @xcite ( enabling recovery of the results therein ) , our proof techniques are also somewhat more direct , and hence may be of independent interest . </S>"
  ]
}