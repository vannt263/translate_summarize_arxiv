{
  "article_text": [
    "it has been difficult to read the recent financial news without finding mention of collateralized debt obligations ( cdo s ) . these financial instruments",
    "provide ways of aggregating risk from a large number of sources and reselling it in a number of parts , each part having different risk - reward characteristics . notwithstanding the role of cdo s in the recent market meltdown , the near future will no doubt see the financial engineering community continuing to develop structured investment vehicles like cdo s .",
    "unfortunately , computational challenges in this area are formidable .",
    "the main types of these assets have several common problematic features :    * they pool a large number of assets * they tranche the losses .",
    "the `` problematic '' nature of this combination is that the trancheing procedure is nonlinear ; and as is usual , the effect of a nonlinear transformation on a high - dimensional system is often difficult to understand .",
    "ideally , one would like a theory which gives , if not explicit answers , at least some guidance .",
    "lacking theory , one is often forced to search for models which are computationally feasible , structurally robust , and which can be reasonably well - fitted to data .",
    "we here consider a _ large deviations _ ( cf .",
    "@xcite ) analysis of certain aspects of synthetic cdo s .",
    "the theory of large deviations is a collection of ideas which are often useful in studying rare events .",
    "the rare events of interest here involve losses in ( and hence pricing of ) investment - grade ( senior or super - senior ) tranches of synthetic cdo s .",
    "we would like to see how far we can take a rigorous analysis when we use mathematical tools , viz . , large deviations , which are designed expressly to study rare events .",
    "the theory of large deviations usually gives a very refined analysis of rare events ( more refined , for example , than one based on mean - variance calculations ) ; what does this analysis look like for cdo s ?",
    "in the course of our analysis , we will see that large deviations theory provides a natural framework for studying large amounts of idiosyncratic randomness .",
    "moreover , the theory of large deviations provides a way to compare rare events and see how they transform .",
    "we believe this to be an important component of a larger analysis of cdo s , particularly in cases where correlation comes from only a few sources ( we will pursue a simple form of this idea in subsection [ s : correlated ] ) . in a sequel to this paper we will consider the more challenging case of a heterogeneous pool of assets .",
    "this is not the first attempt to apply large deviations to structured finance .",
    "losses in pools of large assets like cdo s have been considered in @xcite , @xcite , and @xcite ( see also @xcite for another application of large deviations to finance ) .",
    "moreover , effects of tranching have been considered in @xcite and @xcite , both of which discuss saddlepoint effects of tranching once the distribution of the loss process is known .",
    "our interest is to identify , as much as possible , exact asymptotic formulae for the price of the cdo by focussing on the effects of large amounts of idiosyncratic randomness .",
    "we find that if we interpret the loss process as an occupation measure , _",
    "sanov s theorem _ suggests how to proceed .",
    "furthermore , it allows us to develop something of a bottom - up analysis which directly connects the cdo price to the default probababilities of the underlying bonds .",
    "it also naturally leads to a number of calculations which reflect the _ dynamics _ of the default probabilities ( as opposed to a snapshot of the default probabilities at expiry ) .",
    "finally , the _ ab initio _ nature of our calculations bears note and the comments at the beginning of section [ s : has ] . ] . a number of models , such as the generalized poission loss model @xcite , the hawkes process @xcite and others ( cf .",
    "@xcite ) , which successfully capture some of the complexity of cdo s have been developed and implemented .",
    "our approach is limited to investment - grade tranches , and hopefully will complement some of these models and contribute to their study .",
    "a standard review of credit default swaps and synthetic cdo s will help us fix notation , which comes from @xcite .",
    "let s fix underlying probability triple @xmath0 , where @xmath1 represents the risk - neutral probability measure and @xmath2 is the associated expectation operator ..      a credit default swap ( cds ) is a contract between a _ protection seller _ and a _ protection buyer _ based on the default of a reference bond ( a _ name _ ) .",
    "under the contract , the protection seller pays the protection buyer @xmath3 ( the _ notional _ ) when the bond defaults ( a nonnegative random time @xmath4 ) , as long as this default occurs before the expiry of the contract ( time @xmath5 ) .",
    "this is the _ protection leg _ of the contract . in return",
    ", the protection buyer pays the protection seller a premium @xmath6 at a finite collection @xmath7 of times ( such that @xmath8 for all @xmath9 until the default occurs .",
    "this is the _ premium _ leg of the contract ; see figure [ fig : cds ] .        to write this mathematically , define the loss process @xmath10 for all @xmath11 ( of course then @xmath12 for @xmath13 ) .",
    "the present value of the protection and premium legs are thus @xmath14 where @xmath15 is the riskless interest rate and @xmath16 are measurable maps from @xmath17 to @xmath18 ; thus the expectations make sense . ] .",
    "the value of @xmath6 is defined by requiring that the expectation of these two legs agree ( under the risk - neutral measure ) .",
    "it is an easy step to modify this notation to construct a synthetic cdo .",
    "consider @xmath19 credit default swaps ( each one on a different name ) .",
    "each cds has notional value @xmath20 , and the default of the @xmath21-th name occurs at a random nonnegative time @xmath22 .",
    "notional _ loss process is thus @xmath23 for all @xmath11 ( as in our above discussion of credit default swaps , @xmath24 for @xmath13 ) .",
    "note that @xmath25 for all @xmath26 .",
    "attachment _ and _ detachment _ points @xmath27 and @xmath28 in @xmath29 $ ] such that @xmath30 .",
    "we then define the _ tranched _ loss process @xmath31 as @xmath32 for all @xmath11 .",
    "the protection and premium legs of a synthetic cdo are basically given by replacing the loss process @xmath33 in a credit default swap with @xmath34 .",
    "namely , define @xmath35 @xmath36 is the present value of the premium leg ( where @xmath37 are the premiums ) and @xmath38 is the present value of the protection leg .",
    "the protection leg thus makes payments when defaults occur , as long as at least @xmath27 ( in percent ) of the names have already defaulted , and only as long as no more than @xmath28 ( in percent ) of the names have defaulted .",
    "these payments are proportioned so that they add up to at most @xmath3 .",
    "the premium payments , on the other hand , are made only on the proportion of names which are still insured ( i.e. , which have not yet defaulted ) .",
    "the premium @xmath37 should then be given by equating the risk - neutral expectation of two legs ; i.e. , @xmath39}{{\\mathbb{e}}[{\\textbf{p}^{\\text{prem}}}_n]}.\\ ] ] note that @xmath40 is measurable for each @xmath11 . since @xmath41 is a continuous transformation of @xmath40 , it is also measurable .",
    "since @xmath42 , @xmath43 , and @xmath34 is nondecreasing , @xmath38 and @xmath44 both take values in @xmath29 $ ] .",
    "moreover , the measurability of @xmath34 implies that @xmath38 and @xmath44 are measurable .",
    "thus both @xmath45 $ ] and @xmath46 $ ] are well - defined , finite , and nonnegative .",
    "our goal is to evaluate @xmath37 when @xmath19 is large .",
    "this will be accomplished in .     and",
    "let s now think about the sources of randomness in the names .",
    "each name is affected by its own _ idiosyncratic _",
    "randomness and by _ systemic _ randomness ( which affects all of the names ) .",
    "assumedly , the systemic randomness , which corresponds to macroeconomic factors , is _ low - dimensional _ compared to the number of names .",
    "for example , there may be only a handful of macroeconomic factors which affect a pool of many thousands of names .",
    "we can capture this functionality as @xmath48 where the @xmath49 and @xmath50 are all independent random variables , and @xmath51 is some appropriate set in the product space of the sets where the @xmath52 s and @xmath50 take values . since we want the defaults to be identically distributed , we may furthermore assume that the @xmath52 s are identically distributed .",
    "our interest is to understand the implications of the structural model .",
    "we are not so much concerned with specific models for the @xmath52 s , the @xmath50 , or the set @xmath51 but rather the structure of the rare losses in the investment - grade tranches .",
    "we would also like to avoid , as much as possible , a detailed analysis of the parts of since in practice what we have available to carry out pricing calculations is the price of credit default swaps for the individual names ; i.e. ( after a transformation ) , @xmath53 .",
    "thus we ca nt with certainty get our hands on the details of",
    ". there may in fact be several models of the type which lead to the same `` price '' for the rare events involved in an investment - grade tranche .",
    "if we can understand more about the structure of rare events in these tranches , we can understand which aspects of are important ( and then try to calibrate specific models using that insight ) .",
    "regardless of the details of , we can make some headway .",
    "the notional loss at time @xmath54 will be given by @xmath55 the definition of an investment - grade tranche is that @xmath56 is small .",
    "guided by chebychev s inequality , lets define @xmath57 \\qquad \\text{and}\\qquad \\sigma^{(n ) } { \\overset{\\text{def}}{=}}\\sqrt{{\\mathbb{e}}\\left[\\left(l^{(n)}_{t-}-\\mu^{(n)}\\right)^2\\right]}.\\ ] ] if @xmath58 , chebychev s inequality gives us that @xmath59 in order for this to be small , we would like that @xmath60 be small ; this is the point of pooling . for any fixed value of @xmath61",
    ", the conditional law of @xmath62 given that @xmath63 is the variance of @xmath64 ; thus the conditional variance of @xmath62 given that @xmath63 is at most of order @xmath65 .",
    "hopefully , when we reinsert the systemic randomness , the variance of @xmath66 will still be small , and we will indeed have an investment - grade tranche .",
    "in fact , we can do better than chebychev s inequality . by again conditioning on @xmath50",
    ", we can write that @xmath67\\ ] ] thus the tranche will be investment - grade if @xmath68 is small for `` most '' values of @xmath61 ( see remark [ r : systemic ] ) . as mentioned above , however , we know the law of @xmath62 conditioned on @xmath50 .",
    "namely , @xmath69 this then clearly motivates a natural two - step approach .",
    "our first step is to condition on the value of the systemic randomness ( which we may think of as fixing a `` state of the world '' or a `` regime '' ) and concentrate on how rare events occur due to idiosyncratic randomness ( i.e. , to effectively _ suppress _ the systemic randomness ) .",
    "it will turn out that this is in itself a fairly involved calculation .",
    "nevertheless , it is connected with a classic problem in large deviations theory_sanov",
    "s theorem_. with this in hand , we should then be able to return to the original problem and average over the systemic randomness ( in subsection [ s : correlated ] ) .",
    "some of the finer details of these effects of correlation will appear in sequels to this paper . here",
    "we will restrict our interest in the effects of correlation to a very simple model ( which is hopefully nevertheless illustrative ) .",
    "define @xmath70 $ ] and endow @xmath71 with its usual topology under which it is polish and its usual ordering ; with the usual topology and ordering .",
    "@xmath71 is the collection of nonnegative real numbers and a non - real `` point '' , which we label as @xmath72 .",
    "define @xmath73\\to i$ ] as @xmath74 for @xmath75 , and define @xmath76 .",
    "then @xmath77 is a bijection .",
    "the topology and ordering of @xmath71 is that given by pushing the topology and ordering of @xmath78 $ ] forward through @xmath77 . thus @xmath71 is polish and in fact compact",
    "] each of the default times is an @xmath71-valued random variable .",
    "since we want to consider a countable collection of default times , we will take our event space to be @xmath79 and , @xmath80 is the borel sigma - algebra of subsets of @xmath81 , and @xmath82 is the collection of probability measures on @xmath83 . ]",
    "we will take @xmath84 . fix next @xmath85",
    "; we will want all of the names to be identically distributed with common law @xmath86 . to reflect our initial working assumption that the names are independent , we now let the risk neutral probability @xmath87 be defined by requiring that @xmath88 for all @xmath89 and all @xmath90 .",
    "we also define , in the usual way , @xmath91 .",
    "\\qquad t\\in i\\ ] ] in principle , one can recover @xmath92 from prices of credit default swaps .",
    "our setup includes both the merton model and the reduced form model .",
    "for the reduced form model , let @xmath93 be the hazard rate and set @xmath94",
    "\\qquad t\\in ( 0,\\infty)\\ ] ] and let @xmath92 have density @xmath95 . on the other hand , for the merton model with stock volatility @xmath96 , risk - neutral drift @xmath97 , initial valuation @xmath98 , and bankruptcy barrier @xmath99 , we would have @xmath100 .",
    "\\qquad t\\in ( 0,\\infty)\\ ] ] again define @xmath92 by integrating @xmath95 .",
    "we can then rewrite the notional loss process as @xmath101}(\\tau_n ) = \\nu^{(n)}[0,t]\\ ] ] where @xmath102 is empirical distribution of the @xmath22 s ; i.e. , @xmath103 we point out that @xmath102 is a random element of @xmath104 ( i.e. , a random measure is a measurable map from @xmath71 to @xmath104 , each map @xmath105 is a measurable map from @xmath17 to @xmath104 .",
    "thus for each @xmath19 , the map @xmath106 is a measurable map from @xmath17 to @xmath107 .",
    "recalling the definition of the weak topology as integration against continuous bounded functions , we then see that the map @xmath108 is continuous and thus measurable as a map from @xmath107 to @xmath104 .",
    "hence @xmath102 is indeed a @xmath104-valued random variable . ] ) .",
    "this formulation is the starting point for our analysis and will lead to several insights .",
    "in particular , the ( weak ) law of large numbers implies that for each @xmath109 , @xmath110 more generally , @xmath102 tends to @xmath86 ( in the prohorov topology on @xmath104 ) ; for every @xmath111 , @xmath112 where @xmath113 is the prohorov metric @xcite .",
    "consider now an investment - grade tranche ; i.e. , a senior or super - senior tranche .",
    "the attachment point for such a tranche should be set so that it is unlikely to suffer any defaults ; i.e. , it is unlikely that @xmath38 is nonzero .",
    "clearly @xmath114 and comparing this with , we see that a tranche will be investment - grade if and only an obvious requirement holds :    [ a : ig ] we assume that @xmath115    in this case , the valuation of such a tranche should depend in large part on how `` rare '' it is that @xmath116 .",
    "as @xmath19 becomes large , means that in fact it becomes less and less likely that @xmath116 .",
    "note also that since @xmath117 , this assumption implies that @xmath118 .",
    "this is natural ; if @xmath119 , then all defaults must have occurred before @xmath5 , essentially precluding the possibility of constructing an investment - grade tranche .",
    "combining our comments after about the structure of @xmath38 and , we have that @xmath120 hence for an investment - grade tranche , @xmath45 $ ] is small if it is unlikely that @xmath121 ( in other words , we do nt have any competition between `` big '' values of @xmath38 and `` small '' sets ) .",
    "note also that implies that @xmath122 ( in probability ) so that in fact @xmath123 = \\sum_{t\\in { \\mathcal{t } } } e^{-{\\textsf{r}}t}.\\ ] ] in other words , if losses are unlikely , all of the premiums will most likely be paid .",
    "thus the nontrivial part of @xmath37 comes from the protection leg , whose value is small .",
    "let s now step into the world of large deviations , which tells us how to study rare events .",
    "the asymptotics of @xmath102 is exactly the subject of _ sanov s _",
    "theorem @xcite , which states that @xmath102 has a large deviations principle with rate function given by relative entropy with respect to @xmath86 ; i.e. , with rate function @xmath124 informally , for any @xmath125 , @xmath126.\\ ] ] since large deviations is not in the mainstream of financial mathematics ( see , however , @xcite ) we have summarized some of its foundations in subsection [ s : ld ] . combining with sanov s theorem , we conjecture that for large @xmath19 @xmath127 \\le { \\mathbb{p}}\\left\\{\\nu^{(n)}[0,t)>\\alpha\\right\\ } \\overset{n\\nearrow \\infty}{\\asymp } \\exp\\left[-n { \\mathfrak{i}}(\\alpha)\\right]\\ ] ] where @xmath128 although this looks intimidating ( it is an infinite - dimensional minimization problem ) , in fact it has an easy solution and an explicit minimizer . for @xmath129 and @xmath129 in @xmath29",
    "$ ] , define @xmath130    [ p : explicit ] we have that @xmath131 where @xmath132)\\frac{1-\\alpha}{1-f(t-)}\\ ] ] for all @xmath133 .",
    "the proof of this is given section [ s : proofs ] .",
    "in fact , the formula for @xmath134 is what we would expect from considering only @xmath62 .",
    "we can think of @xmath62 as counting the normalized number of heads in a collection of i.i.d .",
    "coin flips , where the probability of heads ( i.e. , defaults before time @xmath5 ) for each coin is @xmath135 .",
    "the likelihood that the normalized number of heads is approximately @xmath27 is given , via sanov s theorem , by relative entropy of a coin flip with bias @xmath27 with respect to a coin with bias @xmath135 ( see the comments after theorem [ t : measurechange ] ) .",
    "we are almost ready to state our main theorem .",
    "we need one last assumption .",
    "[ a : density ] we assume that @xmath136 for all @xmath137 .    in other words , @xmath92 can not be flat to the left of @xmath5 .",
    "thus @xmath138 is positive ( viz . , for @xmath137 , @xmath139 ) ; this is natural , since if @xmath140 , then there is no possibility of any defaults by time @xmath5 .",
    "secondly , if @xmath92 is flat right before @xmath5 , then any defaults by time @xmath5 must in fact have occurred earlier , so we can effectively reduce the time interval of interest to a smaller one . by disallowing such a flat , we ensure that there is some likelihood of defaults right before @xmath5 , allowing us to carry out a quantitative analysis of @xmath66 right before time @xmath5 ( see the proof of lemma [ l : ttimes ] ) .",
    "the goal of this paper is to formalize the asymptotics conjectured above .",
    "set @xmath141 in light of assumption [ a : ig ] , the second formula ensures that @xmath142 .",
    "[ t : main ] we have that @xmath143 = \\frac{e^{-{\\textsf{r}}t}\\exp\\left[-{\\varkappa}\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\right]}{n^{3/2}(\\beta-\\alpha)\\sqrt{2\\pi\\alpha(1-\\alpha)}}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)f(t-)(1-f(t-))}{(\\alpha - f(t-))^2 } \\right.\\\\ \\left .",
    "+ \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha(1-f(t-))}{\\alpha - f(t- ) } + { \\mathcal{e}}(n)\\rb \\exp\\left[-n { \\mathfrak{i}}(\\alpha)\\right ] \\end{gathered}\\ ] ] where @xmath144 .",
    "we can recognize a number of effects here .",
    "firstly , the @xmath145 term reflects the fact that while by assumption losses in the cdo are unlikely , the least unlikely way for them to occur is right before expiry .",
    "the term @xmath146 in the denominator reflects the tranche width ; note that we are looking at large @xmath19-approximations here ; if we were to first take asymptotics as the tranche width tends to zero , we would probably capture some different effects ( but we expect that the exponentially small entropy term would still appear ) .",
    "the @xmath147 reflects something like a gaussian correction term ( it directly comes from the calculations of section [ s : proofs ] ) .",
    "the @xmath148 is a combination of two things .",
    "part of it ( @xmath149 ) also comes from the gaussian correction .",
    "the rest ( @xmath19 ) comes from the actual size of the protection leg payments @xmath38 once the attachment point has been reached .",
    "the unsightly term @xmath150 comes from an unavoidable granularity in our problem ; the loss process can only take on values in @xmath151 .",
    "we expect this granularity to disappear if the notional loss takes on a continuum of values",
    ". this would be the case , for example , with random recoveries ( cf .",
    "@xcite ) . of course , by taking @xmath27 to be a multiple of @xmath20 , we can make this granularity disappear  at the cost of making our calculations look more restrictive than they actually are .",
    "finally , we explicitly point out that our analysis is _",
    "asymptotic _ as the number @xmath19 of names becomes large .",
    "we can not say anything specific about any finite @xmath19 .",
    "this is analogous to the law of large numbers ; the law of large numbers can not , for example , give information about any finite number of coin flips , but rather is useful in framing one s thoughts when one has `` many '' coin flips .",
    "combining and theorem [ t : main ] , we see that the asymptotic behavior of the premium @xmath37 is given by @xmath152}{{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\sum_{t\\in { \\mathcal{t } } } e^{-{\\textsf{r}}t}\\rb ( \\beta-\\alpha)\\sqrt{2\\pi\\alpha(1-\\alpha)}}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)f(t-)(1-f(t-))}{(\\alpha - f(t-))^2}\\right.\\\\ & \\qquad \\left .",
    "+ \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha(1-f(t-))}{\\alpha - f(t- ) }   + { \\mathcal{e}}'(n)\\rb \\exp\\left[-n { \\mathfrak{i}}(\\alpha)\\right ] \\end{aligned}\\ ] ] where @xmath153 .    to close this section , we plot some `` theoretical '' prices as a function of the number @xmath19 . by `` theoretical '' ,",
    "we mean the quantity @xmath154}{n^{3/2}\\sqrt{\\alpha(1-\\alpha)}}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)f(t-)(1-f(t-))}{(\\alpha - f(t-))^2 } \\right.\\\\ \\left.+\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha(1-f(t-))}{\\alpha - f(t-)}\\rb \\exp\\left[-n { \\mathfrak{i}}(\\alpha)\\right ] \\end{gathered}\\ ] ] we have here set @xmath155 in and have removed the prefactor @xmath156     for several values of @xmath27,width=480,height=288 ]      we can now introduce a simple model of correlation without too much trouble .",
    "assume that @xmath50 takes values in a finite set @xmath81 .",
    "fix @xmath157 such that @xmath158 and @xmath159 for all @xmath160 ; we will assume that @xmath50 takes on the value @xmath61 with probability @xmath161 .",
    "we can think of the set @xmath81 as the collection of possible states of the world .",
    "if we believe in , we should then be in the previous case if we condition on the various values of @xmath50 .",
    "to formalize this , fix a @xmath162 .",
    "fix a probability measure @xmath1 such that @xmath163 for all @xmath90 .    to adapt the previous calculations to this case",
    ", we need the analogue of assumptions [ a : ig ] and [ a : density ] .",
    "namely , we need that @xmath164 and also that @xmath165,x)<\\mu([0,t],x)$ ] for all @xmath137 and all @xmath160 .",
    "[ r : systemic ] the requirement that @xmath164 is a particularly unrealistic one .",
    "it means that the tranche losses will be rare for _ all _ values of the systemic parameter . in any truly applicable model",
    ", the losses will come from a combination of bad values of the systemic parameter and from tail events in the pool of idiosyncratic randomness ( i.e. , we need to balance the size of @xmath68 against the distribution of @xmath50 ) .",
    "one can view our effort here as study which focusses primarily on tail events in the pool of idiosyncratic randomness . any structural model which attempts to study losses due to",
    "both idiosyncratic and systemic randomness will most likely involve calculations which are similar in a number of ways to ours here .",
    "we will explore this issue elsewhere .    for each @xmath160",
    ", define @xmath166 then @xmath143 = \\frac{e^{-{\\textsf{r}}t}}{n^{3/2}(\\beta-\\alpha)\\sqrt{2\\pi\\alpha(1-\\alpha)}}\\sum_{x\\in { \\mathsf{x}}}\\left(\\exp\\left[-{\\varkappa}_x\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\right]\\right.\\\\ \\times \\left.{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)\\mu([0,t),x)\\left(1-\\mu([0,t),x)\\right)}{\\left(\\alpha-\\mu([0,t),x)\\right)^2 } + \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha\\left(1-\\mu([0,t),x)\\right)}{\\alpha-\\mu([0,t),x ) } + { \\mathcal{e}}(n)\\rb \\right.\\\\ \\left.\\times \\exp\\left[-n \\hbar(\\alpha,\\mu([0,t),x))\\right]p(x)\\right ) \\end{gathered}\\ ] ] where @xmath167 for all @xmath160 .",
    "similarly we have that @xmath168\\right.\\\\ \\left .",
    "\\times { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)\\mu([0,t),x)\\left(1-\\mu([0,t),x)\\right)}{\\left(\\alpha-\\mu([0,t),x)\\right)^2}+\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha\\left(1-\\mu([0,t),x)\\right)}{\\alpha-\\mu([0,t),x ) }   + { \\mathcal{e}}'(n)\\rb\\right.\\\\ \\left.\\times \\exp\\left[-n \\hbar(\\alpha,\\mu([0,t),x))\\right]p(x)\\right ) \\end{gathered}\\ ] ] where @xmath169 for all @xmath160 .",
    "if we further assume that there is a unique @xmath170 such that @xmath171 , we furthermore have that @xmath172 & = \\frac{e^{-{\\textsf{r}}t}}{n^{3/2}(\\beta-\\alpha)\\sqrt{2\\pi\\alpha(1-\\alpha)}}\\exp\\left[-{\\varkappa}_{x^*}\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\right]\\\\ & \\qquad \\times { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)\\mu([0,t),x^*)\\left(1-\\mu([0,t),x^*)\\right)}{\\left(\\alpha-\\mu([0,t),x^*)\\right)^2 }   + \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha\\left(1-\\mu([0,t),x^*)\\right)}{\\alpha-\\mu([0,t),x^ * ) } + { \\mathcal{e}}(n)\\rb \\\\ & \\qquad \\times \\exp\\left[-n \\hbar(\\alpha,\\mu([0,t),x^*))\\right]p(x^*)\\\\ s_n & = \\frac{1}{n^{3/2}}\\frac{e^{-{\\textsf{r}}t}}{{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\sum_{t\\in { \\mathcal{t } } } e^{-{\\textsf{r}}t}\\rb ( \\beta-\\alpha)\\sqrt{2\\pi\\alpha(1-\\alpha)}}\\exp\\left[-{\\varkappa}_{x^*}\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\right]\\\\ & \\qquad \\times { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{\\alpha(1-\\alpha)\\mu([0,t),x^*)\\left(1-\\mu([0,t),x^*)\\right)}{\\left(\\alpha-\\mu([0,t),x^*)\\right)^2}+\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{\\alpha\\left(1-\\mu([0,t),x^*)\\right)}{\\alpha-\\mu([0,t),x^ * ) }   + { \\mathcal{e}}'(n)\\rb\\\\ & \\qquad \\times \\exp\\left[-n \\hbar(\\alpha,\\mu([0,t),x^*))\\right]p(x^ * ) \\end{aligned}\\ ] ] where @xmath144 and @xmath153 .",
    "note that we can use this methodology to approximately study gaussian correlations .",
    "fix a positive @xmath173 and define @xmath174 for @xmath175 ; set @xmath176 .",
    "define @xmath177dt \\qquad x\\in { \\mathbb{r}}\\ ] ] as the standard gaussian cumulative distribution function .",
    "define @xmath178 if we have a pool of @xmath19 names with common probability of default @xmath179 by time @xmath5 and we want to consider a gaussian copula with correlation @xmath180 ( the case @xmath181 can be dealt with similarly ) , we would take the @xmath182 s such that @xmath183 this is related to the calculations of @xcite and @xcite ; those calculations are asymptotically related to our calculations .",
    "we shall explore the connection with these two papers elsewhere .",
    "we note , by way of contrast with @xcite and @xcite , that our efforts give a good picture of the _ dynamics _ of the loss process prior to expiry .",
    "we also note that our model of is entirely comfortable with non - gaussian correlation .",
    "note also that one could also ( by discretization ) allow the systemic parameter @xmath50 to be path - valued .",
    "we shall here give a very short summary of the main ideas of large deviations ; see @xcite for a comprehensive treatment . the basic observation behind the theory",
    "is that a sum of exponentials behaves like largest - growing exponential .",
    "for example , @xmath184 here `` @xmath185 '' means `` having the same exponential growth '' ; in other words , @xmath186 if @xmath187 .",
    "_ laplace asymptotics",
    "_ extends this to integrals .",
    "this is a relevant place to start the study of rare events if we consider a collection @xmath188 of random variables whose laws are of the form @xmath189dx \\qquad a\\in { \\mathscr{b}}({\\mathbb{r}})\\ ] ] for some @xmath190 and some normalization constant @xmath191 ( e.g. , if we take @xmath192 and @xmath193 , then @xmath194 will be a normal random variable with mean @xmath98 and variance @xmath195 ) . if we assume that @xmath196 has nice enough growth properties ( so that the integrals in are well - defined and @xmath191 has subexpontial growth ) , then laplace asymptotics states that @xmath197\\ ] ] for `` nice '' enough sets @xmath51 . by taking @xmath198 , we see that we must have that @xmath199 . if this minimum is achieved at a single point @xmath200 , then by taking @xmath51 as the complement of a neighborhood of @xmath200 we have that @xmath201 in probability , so @xmath202 is a rare event for any nice enough set @xmath51 not containing @xmath200 .",
    "one of the main aspects of large deviations theory is something of an inverse problem .",
    "can we have even without ?",
    "in some cases , yes . fix @xmath203 and consider the limiting rate of growth of the logarithmic moment generating function ; we have that @xmath204\\right ] = \\lim_{n\\to \\infty}\\frac1n\\ln \\int_{x\\in { \\mathbb{r}}}c_n\\exp\\left[n{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\theta x-\\phi(x)\\rb\\right]dx = \\sup_{x\\in { \\mathbb{r}}}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\theta x-\\phi(x)\\rb.\\ ] ] the key realization is that the right - hand side is the _ legendre - fenchel transform _ of @xmath196 , and that if @xmath196 has nice convexity properties , we can recover @xmath196 from @xmath205 by taking the legendre - fenchel transform again ; i.e. , @xmath206 the strength of this chain of arguments is that the moment generating function is well - defined ( but of course possibly infinite ) regardless of whether @xmath194 is discrete or continuous .",
    "it even makes sense when @xmath194 takes values in an infinite - dimensional topological linear space @xmath81 if we replace multiplication by @xmath97 with the action of a linear functional on @xmath81 .",
    "the rigorous definition of a large deviations principle is as follows @xcite .",
    "we say that @xmath207 ( which we now assume to take values in a topological space @xmath81 ) has a large deviations principle with rate function @xmath208 $ ] if the following three requirements hold :    * for every @xmath209 , @xmath210 is a compact subset of @xmath81 . * for every open subset @xmath211 of @xmath81 , @xmath212 * for every closed subset @xmath92 of @xmath81 , @xmath213    returning to our focus , which is sanov s theorem applied to , we have that for any @xmath214 ( the dual of @xmath104 ) , @xmath215\\right ] = \\ln \\int_{t\\in i}e^{\\phi(t)}\\mu(dt)\\ ] ] and we can then show that @xmath216 this suggests that indeed we should have as interpreted as a large deviations principle ( sanov s theorem ) .",
    "one of the things which naturally occurs in proofs of large deviations principles is a _ measure change _ under which the unlikely event becomes more likely  the cost of this change of measure is exactly the desired exponential rate of decay ( see @xcite ) .",
    "let s see what this looks like in our situation ( see @xcite for a more complete motivation of measure changes in large deviations ) .",
    "define @xmath217}(t)\\qquad t\\in i\\ ] ] ( note that since @xmath218 , @xmath219 , so @xmath220 ) .",
    "it is easy to verify that @xmath221 thus @xmath222 is the extremal in the variational representation for @xmath223 ( if we allow ourselves to extend the supremum over @xmath224 to the collection of bounded measurable functions ; it turns out that this is allowable ) . in our analysis of @xmath102 of , @xmath222 will naturally give us an optimal way to `` tilt '' our original probability measure so that it becomes likely that @xmath225 .",
    "the penalty for doing this is exactly @xmath226 .",
    "[ t : measurechange ] we have that @xmath227 = i_ne^{-n{\\mathfrak{i}}(\\alpha)}\\ ] ] for all positive integers @xmath19 , where @xmath228\\chi_{\\{\\gamma_n>0\\}}\\right]\\ ] ] where in turn @xmath229 \\qquad a\\in { \\mathscr{f}}\\\\ \\gamma_n&= \\sum_{n=1}^n { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\chi_{[0,t)}(\\tau_n)-\\alpha\\rb = n(l_{t-}^{(n)}-\\alpha)\\end{aligned}\\ ] ] under @xmath230 , @xmath231 are independent and identically distributed with common law @xmath232",
    ".    set @xmath233 then @xmath227 = \\frac{{\\mathbb{e}}\\left[{\\textbf{p}^{\\text{prot}}}_n \\exp\\left[-\\gamma_n\\right]\\exp\\left[\\gamma_n\\right]\\right]}{{\\mathbb{e}}\\left[\\exp\\left[\\gamma_n\\right]\\right]}{\\mathbb{e}}\\left[\\exp\\left[\\gamma_n\\right]\\right].\\ ] ] note that @xmath234&= \\exp\\left[\\sum_{n=1}^n\\ln \\frac{d\\tilde \\mu^*_\\alpha}{d\\mu}(\\tau_n)\\right ] = \\prod_{n=1}^n \\frac{d\\tilde \\mu^*_\\alpha}{d\\mu}(\\tau_n ) \\\\",
    "{ \\mathbb{e}}\\left[\\exp\\left[\\gamma_n\\right]\\right]&= e^{-n{\\mathfrak{i}}(\\alpha)}{\\mathbb{e}}\\left[\\prod_{n=1}^n \\frac{d\\tilde \\mu^*_\\alpha}{d\\mu}(\\tau_n)\\right ] = e^{-n{\\mathfrak{i}}(\\alpha ) } \\end{aligned}\\ ] ] ( these equalities in fact reflect some of the basic properties of large deviations measure transformations and are intimately related with the fact that @xmath222 solves the variational problem associated with @xmath223 ) .",
    "we also clearly have that @xmath235\\right]}{{\\mathbb{e}}\\left[\\exp\\left[\\gamma_n\\right]\\right]}\\\\ = \\frac{{\\mathbb{e}}\\left[\\chi_a\\exp\\left[n\\int_{t\\in i}\\phi^*_\\alpha(t)\\nu^{(n)}(dt)\\right]\\right]}{{\\mathbb{e}}\\left[\\exp\\left[n\\int_{t\\in i}\\phi^*_\\alpha(t)\\nu^{(n)}(dt)\\right]\\right ] } = \\tilde { \\mathbb{p}}_n(a)\\ ] ] for all @xmath236 .",
    "the properties of @xmath230 are clear from the explicit formula .",
    "we next check that @xmath237   -\\frac{\\alpha}{f(t- ) } \\alpha - \\ln \\frac{1-\\alpha}{1-f(t-)}(1-\\alpha)\\rb\\\\ = n\\ln \\frac{\\alpha}{f(t- ) } { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\nu^{(n)}[0,t)-\\alpha\\rb + n \\ln \\frac{1-\\alpha}{1-f(t-)}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\nu^{(n)}[t,\\infty]-(1-\\alpha)\\rb = { \\varkappa}\\gamma_n . \\end{gathered}\\ ] ] finally , we see that @xmath38 is nonzero only if @xmath238 ; we have explicitly included this in the expression for @xmath239 .",
    "we note here that @xmath240 = \\tilde \\mu^*_\\alpha[0,t)=\\alpha\\qquad \\text{and}\\qquad \\tilde { \\mathbb{e}}_n\\left[\\left(l^{(n)}_{t-}-\\alpha\\right)^2\\right ] = \\frac{\\alpha(1-\\alpha)}{n^2}\\le \\frac{1}{4n^2},\\ ] ] so by chebychev s inequality , we have that @xmath241 for every @xmath111 . in other words , @xmath62 tends to the attachment point @xmath27 under the sequence @xmath242 of probability measures and thus loss is not a rare event under @xmath230 as @xmath243 .",
    "we also note that we need to understand the appropriate change of measure for the empirical measure @xmath102 ( as opposed to the change of measure for the empirical sum @xmath62 ) since @xmath38 involves the dynamics of the loss process ( and not just the probability of loss ) .",
    "where do we now stand ?",
    "if we can show that @xmath239 has no exponential growth or decay ( comparable to @xmath244 ) then we have successfully identified the asymptotic behavior of @xmath45 $ ] ; we will have decomposed it into an exponentially small part and a prefactor which is of order 1 as @xmath243 .",
    "our goal now is to organize our thoughts about the prefactor , and in particular to actually extract the asymptotics of theorem [ t : main ] ; i.e. , to `` do the math '' .    looking at the expression for @xmath239 , we see that the dominant part of @xmath239 will be where @xmath245 is order ] 1 ; if @xmath246 , then @xmath247 $ ] will be very small so the contribution to @xmath239 will be negligible ( recall here that @xmath38 is bounded ) .",
    "this suggests we organize the formula for @xmath239 based on the values of @xmath245 .",
    "note that the range of @xmath245 when it is positive is @xmath248 .",
    "for each @xmath19 , let @xmath249 $ ] be such that @xmath250\\ ] ] on @xmath251 .",
    "then we have that @xmath252\\right].\\ ] ] it turns out that @xmath253 has very nice asymptotics .    [ l : hasymp ] for all @xmath19 , we have that @xmath254 where @xmath255    we will prove this in section [ s : has ] .    the next step is to understand the distribution of @xmath245 .",
    "[ l : probasymp ] we have that @xmath256 for all @xmath19 and all @xmath257 , where @xmath258    we will prove this in section [ s : proofs ] . using this result , we can now start our proof of theorem [ t : main ] .",
    "set @xmath259{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{e^{-{\\varkappa}}}{(1-e^{-{\\varkappa}})^2 } + \\frac{{\\lceil n\\alpha \\rceil}-n\\alpha}{1-e^{-{\\varkappa}}}\\rb \\end{aligned}\\ ] ] we thus expect that @xmath260 we then claim that @xmath261 .",
    "as a preliminary to showing this , let s recall some calculations about geometric series . for @xmath262 and each positive integer @xmath21 , @xmath263 differentiating with respect to @xmath264",
    ", we get that @xmath265 let s bound the error terms in these expressions . note that @xmath266 . for @xmath262 we have that @xmath267\\rb \\frac{\\exp\\left[-\\frac{\\lambda}{2}(n+1)\\right]}{\\lambda\\left(1-e^{-\\lambda}\\right)^2 } \\\\ & \\le 2e^{-1 } \\frac{\\exp\\left[-\\frac{\\lambda}{2}(n+1)\\right]}{\\lambda\\left(1-e^{-\\lambda}\\right)^2 } \\end{aligned}\\ ] ] and similarly @xmath268}{\\lambda\\left(1-e^{-\\lambda}\\right)^2}\\\\ \\le 2 e^{-1}\\frac{\\exp\\left[-\\frac{\\lambda}{2}(n+1)\\right]}{\\lambda\\left(1-e^{-\\lambda}\\right)^2}.\\ ] ] observe now that @xmath269 for all @xmath89 .",
    "combining things and recalling that @xmath142 , we see that for all @xmath89 , @xmath270\\\\ & = \\sum_{j={\\lceil n\\alpha \\rceil}}^{\\lfloor n\\alpha + n^{1/4}\\rfloor}(j - n\\alpha)\\exp\\left[-{\\varkappa}(j - n\\alpha)\\right]\\\\ & = \\sum_{j=0}^{\\lfloor n\\alpha + n^{1/4}\\rfloor-{\\lceil n\\alpha \\rceil}}(j+{\\lceil n\\alpha \\rceil}-n\\alpha)\\exp\\left[-{\\varkappa}(j+{\\lceil n\\alpha \\rceil}-n\\alpha)\\right]\\\\ & = \\exp\\left[-{\\varkappa}({\\lceil n\\alpha \\rceil}-n\\alpha)\\right]{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\sum_{j=0}^{\\lfloor n\\alpha + n^{1/4}\\rfloor-{\\lceil n\\alpha \\rceil}}j e^{-{\\varkappa}j } + \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\sum_{j=0}^{\\lfloor n\\alpha + n^{1/4}\\rfloor-{\\lceil n\\alpha \\rceil}}e^{-{\\varkappa}j}\\rb \\\\ & = \\exp\\left[-{\\varkappa}({\\lceil n\\alpha \\rceil}-n\\alpha)\\right]{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{e^{-{\\varkappa}}}{(1-e^{-{\\varkappa}})^2 } + \\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\frac{1}{1-e^{-{\\varkappa } } } + { \\mathcal{e}}_3(n)\\rb \\end{aligned}\\ ] ] where @xmath271}{{\\varkappa}\\left(1-e^{-{\\varkappa}}\\right)^2}.\\ ] ] as a consequence , we furthermore have that @xmath272}{{\\varkappa}\\left(1-e^{-{\\varkappa}}\\right)^2}\\\\   \\le \\frac{{\\varkappa}\\left(e^{-{\\varkappa}}+1-e^{-{\\varkappa}}\\right ) + 4e^{-1}}{{\\varkappa}\\left(1-e^{-{\\varkappa}}\\right)^2 } \\le \\frac{4e^{-1}(1+{\\varkappa})}{{\\varkappa}\\left(1-e^{-{\\varkappa}}\\right)^2}. \\end{gathered}\\ ] ] from , we have that @xmath273 so @xmath274    we can finally prove our desired result .",
    "we have that @xmath275 where @xmath276 \\\\ \\tilde { \\mathcal{e}}_2(n)&{\\overset{\\text{def}}{=}}\\sum_{\\substack{s\\in { \\mathcal{s}}_n\\\\s\\le n^{1/4}}}\\frac{h_n(s)e^{-{\\varkappa}s}{\\mathcal{e}}_2(s , n)}{\\sqrt{2\\pi n\\alpha(1-\\alpha ) } } \\\\ \\tilde { \\mathcal{e}}_3(n)&{\\overset{\\text{def}}{=}}\\frac{e^{-{\\textsf{r}}t}}{\\beta-\\alpha}\\sum_{\\substack{s\\in { \\mathcal{s}}_n\\\\s\\le n^{1/4}}}\\frac{se^{-{\\varkappa}s}{\\mathcal{e}}_1(s , n)}{n^{3/2}\\sqrt{2\\pi \\alpha(1-\\alpha)}}\\\\ \\tilde { \\mathcal{e}}_4(n)&{\\overset{\\text{def}}{=}}\\frac{e^{-{\\textsf{r}}t}}{\\beta-\\alpha}\\frac{\\exp\\left[-{\\varkappa}\\left({\\lceil n\\alpha \\rceil}-n\\alpha\\right)\\right]{\\mathcal{e}}_3(n)}{n^{3/2}\\sqrt{2\\pi \\alpha(1-\\alpha)}}\\end{aligned}\\ ] ] then there is a @xmath277 such that @xmath278 for all @xmath89 .",
    "furthermore , we can fairly easily see that there is a @xmath279 such that @xmath280 for all @xmath89 ( note from and that @xmath281 is uniformly bounded in @xmath19 ) .",
    "combine things together to get the stated result .",
    "[ r : comments ] several comments are in order about the analysis of this section .",
    "firstly , we re - emphasize that we first identified the law of @xmath62 and then studied the law of @xmath66 right before @xmath5 . for investment - grade tranches ,",
    "only this last part of @xmath66 should be of interest . for an investment - grade tranche",
    ", losses in general should be rare events ; losses significantly before expiry should be _ very _ rare events .",
    "this would follow from a detailed analysis of the measure transformation of section [ s : tilt ] .",
    "secondly , our analysis here suggests that in more realistic models ( i.e. , not i.i.d .",
    "names ) , the first order of business should be a thorough study of the law of @xmath62 .",
    "this is somewhat appealing ; by time @xmath5 , various transients will assumedly have died out , and some sort of macroscopic analysis may be available .",
    "the third point of interest is the asymptotics of lemma [",
    "l : probasymp ] .",
    "this does _ not _ directly reflect a poisson distribution for @xmath62 .",
    "a number of other studies of cdo s have modelled the loss process as a poisson process ; an interesting question would thus be to try to find a limiting regime of our calculations which leads to poisson statistics .",
    "finally , it would not be hard to use the measure change of section [ s : tilt ] and calculations similar to those of this section to compute the expected loss given default .",
    "we will leave that to the reader .",
    "we here prove lemma [ l : hasymp ] .",
    "to do so , we need to develop a clear picture of the dynamics of @xmath66 .",
    "we note that the calculations of this section , though technical , provide a _",
    "direct _ link to the distribution of the default times .",
    "first of all , we recall that the definition of @xmath31 implies that @xmath31 is nonzero only where @xmath66 exceeds @xmath27 ; since @xmath66 is nondecreasing , this will in fact be an interval .",
    "set @xmath282 a typical graph of @xmath31 is given in figure [ fig : typ ] .",
    "next note that on @xmath251 , @xmath283\\cap[0,t)}e^{-{\\textsf{r}}s}d{\\bar l}^{(n)}_s.\\ ] ] if @xmath284 for some @xmath257 , where @xmath285 , then ( recall the second line of ) @xmath286 and @xmath287 ; thus @xmath62 is close to @xmath27 .",
    "hence @xmath288 ( at least if @xmath289 ) and @xmath290 should be close to @xmath5 ; it should only take a short amount of time for @xmath66 to increase the extra distance ( which is at most @xmath291 ) past @xmath27 .    [",
    "l : ttimes ] we have that @xmath292\\chi_{\\{\\gamma_n = s\\}}=0.\\ ] ]    let s rigorously put all of these thoughts together .",
    "assume that @xmath293 and @xmath294",
    ". then @xmath295 and @xmath296 .",
    "hence @xmath297\\cap [ 0,t)}e^{-{\\textsf{r}}s}d{\\bar l}^{(n)}_s = e^{-{\\textsf{r}}t}\\left({\\bar l}^{(n)}_{t-}-{\\bar l}^{(n)}_{\\tau^\\alpha_n-}\\right ) + \\int_{s\\in [ \\tau^\\alpha_n , t)}\\left(e^{-{\\textsf{r}}s}-e^{-{\\textsf{r}}t}\\right ) d{\\bar l}^{(n)}_s.\\ ] ] note that @xmath298 thus @xmath297\\cap [ 0,t)}e^{-{\\textsf{r}}s}d{\\bar l}^{(n)}_s = \\frac{e^{-{\\textsf{r}}t}}{\\beta-\\alpha}\\frac{\\gamma_n}{n } + { \\textsc{\\tiny e}}_n\\ ] ] where @xmath299 if @xmath300 , then @xmath301 .",
    "thus @xmath302 similarly , @xmath303 ( we use here the fact that @xmath304 and that @xmath305 for all @xmath306 ) . combining things , we get that @xmath307 on @xmath308 if @xmath289 .",
    "we then have    for @xmath257 such that @xmath285 , we have that @xmath309}{\\frac{\\gamma_n}{n}}\\chi_{\\{\\gamma_n = s\\ } } \\le e^{{\\textsf{r}}t}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{1}{t } + { \\textsf{r}}\\rb { \\mathbb{e}}_n[t-\\tau^\\alpha_n|\\gamma_n]\\chi_{\\{\\gamma_n = s\\}}\\ ] ] if @xmath289 .",
    "combine , the preceding calculations , and lemma [ l : ttimes ] .",
    "we now need to prove lemma [ l : ttimes ] .",
    "this is a moderately complex step .",
    "the first problem is that by conditioning on @xmath245 , we are conditioning on the value of @xmath66 near the _ endpoint _ of the interval @xmath310 of interest .",
    "the second problem is that we have a large amount of randomness ; @xmath66 can be decomposed into @xmath19 ( independent ) processes , one corresponding to each name .",
    "we shall resolve these issues by using the martingale problem to decompose @xmath66 into a ( reverse - time ) zero - mean martingale and a term of bounded variation .",
    "we will use a martingale inequality to show that the martingale part is small .",
    "thus the behavior of @xmath66 near @xmath5 will be given by the bounded - variation part , which we can analyze via straightforward calculations .",
    "define now @xmath311}(t-\\tau_n ) \\qquad t\\in [ 0,t)\\ ] ] for each positive integer @xmath21 ( note that the @xmath312 s are right - continuous ) . also define @xmath313 for all @xmath314 .",
    "observe that @xmath315 for all @xmath316 $ ] .",
    "let s now localize in time .",
    "let @xmath317 be such that @xmath318 ; assumption [ a : density ] ensures that this is possible . for all @xmath319",
    "$ ] , define @xmath320 ( essentially , @xmath321 is the integral of the hazard function ) . for future reference",
    ", we calculate that for any @xmath314 , @xmath322}(\\tau_n).\\ ] ] note that by definition of @xmath323 , @xmath324 for all @xmath325 ; thus @xmath326 is well - defined , finite , right - continuous , and it has left - hand limits .",
    "[ l : wmx ] for every @xmath327 , @xmath328 is a @xmath230-zero - mean - martingale with respect to @xmath329\\}$ ] ; i.e. , for @xmath330 , @xmath331=m^{(n)}_s$ ] .",
    "fix @xmath21 as specified .",
    "clearly @xmath328 is adapted to @xmath329\\}$ ] . by , we have that @xmath326 is also bounded , so @xmath332 is @xmath230-integrable for each @xmath319 $ ] .",
    "we next compute some transition probabilities .",
    "fix @xmath333 and @xmath334 in @xmath335 $ ] such that @xmath336 . then @xmath337\\subset ( s,\\infty]$ ] , so @xmath338 ; hence @xmath312 is nonincreasing .",
    "this implies that @xmath339    fix @xmath340 and @xmath341 . from",
    ", we immediately have that @xmath342 a similar computation which also uses the definition of @xmath312 gives us that @xmath343 a final computation ( again using the definition of @xmath312 ) gives us that @xmath344    with some manipulations , and using the fact that the @xmath312 s are @xmath230-independent , we get that @xmath345 since @xmath346 , @xmath347 thus the expressions on the right of are well - defined .",
    "proceeding , we compute that @xmath348 = \\frac{\\tilde { \\mathbb{p}}_n\\{\\tau_n < t - t\\}}{\\tilde { \\mathbb{p}}_n\\{\\tau_n < t - s\\}}{z^{(n)}}_s\\ ] ] and hence and @xmath232 agree on @xmath349 . ]",
    "@xmath350-{z^{(n)}}_s = \\frac{\\tilde { \\mathbb{p}}_n\\{\\tau_n < t - t\\}-\\tilde { \\mathbb{p}}_n\\{\\tau_n < t - s\\}}{\\tilde { \\mathbb{p}}_n\\{\\tau_n < t - s\\}}{z^{(n)}}_s = \\frac{f((t - t)-)-f((t - s)-)}{f((t - s)-)}{z^{(n)}}_s.\\ ] ]    again fix @xmath333 and @xmath334 in @xmath335 $ ] such that @xmath336 . for each positive integer @xmath351 , define @xmath352 for @xmath353 . using ,",
    "we can write that @xmath354 where @xmath355-{z^{(n)}}_{r^m_k}\\rb \\qquad \\text{and}\\qquad { \\mathcal{m}}_m = \\sum_{k=0}^{m-1}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}{z^{(n)}}_{r^m_{k+1}}-\\tilde { \\mathbb{e}}_n\\left[{z^{(n)}}_{r^m_{k+1}}\\big|{\\mathscr{g}}_{r^m_k}\\right]\\rb.\\ ] ] for @xmath356 , @xmath357 = \\tilde { \\mathbb{e}}_n\\left[{\\mathcal{m}}_m\\chi_c\\right]=0.\\ ] ]    we now need to show that @xmath230-a.s .",
    ", @xmath358 this will require a bit of care .",
    "we first rewrite @xmath359 as a integral ; @xmath360 where @xmath361 for all @xmath362 and @xmath363 .",
    "defining @xmath364 for all @xmath365 $ ] and @xmath363 , we thus have that @xmath366 for all @xmath362 and @xmath363 . for @xmath362 , @xmath367 ; thus @xmath368 and the @xmath369 s are all uniformly bounded .",
    "it is fairly easy to see that @xmath370}(t')\\ ] ] for all @xmath362 and all @xmath363 .",
    "thus by dominated convergence , @xmath371}(\\tau_n)df_r,\\ ] ] and follows .    taking the limit in , we now have that @xmath372=0,\\ ] ] which is the martingale property . finally , since @xmath373 , we have that @xmath328 is zero - mean .",
    "let s now recombine things .",
    "set @xmath374 for @xmath314 .",
    "note that @xmath375 we next rewrite @xmath290 as a stopping time with respect to @xmath376 .",
    "set @xmath377 then , then @xmath378 and @xmath379 .",
    "assume next that @xmath380 .",
    "since @xmath66 is piecewise - constant and right - continuous , we must have that @xmath300 . at time @xmath290",
    ", we have that @xmath381 and @xmath301 ; see figure [ fig : typ ] .",
    "since @xmath66 takes values only in @xmath151 , we have that @xmath382 and @xmath383 .",
    "thus @xmath384 , as claimed . ]",
    "furthermore , @xmath386 is a @xmath376-stopping time .    it will help to truncate @xmath386 at @xmath323 ; set @xmath387 ; this is also a @xmath376-stopping time and @xmath388 .",
    "thus @xmath389 if @xmath238 , then @xmath116 , and since @xmath390 , we have that @xmath391 and consequently @xmath392    let s now use the fact that @xmath393 to bound @xmath394 . as we pointed out in the proof of lemma [ l : wmx ] , the @xmath312 s are nonincreasing . also , @xmath395 .",
    "thus for @xmath396 ( which implies that @xmath397 ) , we have the following string of inequalities .",
    "@xmath398 where we have defined @xmath399 for all @xmath400 .",
    "note that @xmath401 , and , thanks to assumption [ a : density ] , @xmath402 for @xmath400 .",
    "thus @xmath403 if @xmath404 .    we begin by taking conditional expectations of .",
    "note that @xmath245 is @xmath405-measurable ( see ) .",
    "we have @xmath406\\chi_{\\{\\gamma_n>0\\ } } \\le \\frac{2}{\\alpha}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\gamma_n^+ + \\frac{1}{n } + \\tilde { \\mathbb{e}}_n\\left[\\left|\\tilde m^{(n)}_{\\tilde { \\varrho}^\\alpha_n}\\right|\\bigg| { \\mathscr{g}}_0\\right]\\rb .\\ ] ] by jensen s inequality , @xmath407\\le \\tilde { \\mathbb{e}}_n\\left[\\left(\\tilde m^{(n)}_{\\tilde { \\varrho}^\\alpha_n}\\right)^2\\bigg| { \\mathscr{g}}_0\\right]^{1/2}\\ ] ] @xmath230-a.s .",
    "we can now use optional sampling ; @xmath408 \\le \\tilde { \\mathbb{e}}_n\\left[\\left(\\tilde m^{(n)}_{t_2^*}\\right)^2\\bigg| { \\mathscr{g}}_0\\right ] = \\frac{1}{n^2}\\sum_{n=1}^n \\tilde { \\mathbb{e}}_n\\left[\\left(m^{(n)}_{t_2^*}\\right)^2\\bigg| { \\mathscr{g}}_0\\right]\\\\ \\le \\frac{3}{n^2}\\sum_{n=1}^n { \\left\\ { } \\newcommand{\\rb}{\\right\\}}\\tilde { \\mathbb{e}}_n\\left[\\left({z^{(n)}}_{t_2^*}\\right)^2\\bigg| { \\mathscr{g}}_0\\right]+\\tilde { \\mathbb{e}}_n\\left[\\chi^2_{\\{\\tau_n < t\\}}\\bigg| { \\mathscr{g}}_0\\right ] + \\tilde { \\mathbb{e}}_n\\left[\\left(a^{(n)}_{t^*}\\right)^2\\bigg| { \\mathscr{g}}_0\\right]\\rb\\\\ \\le \\frac{3}{n}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}2 + \\frac{1}{f^2((t - t^*)-)}\\rb   \\end{gathered}\\ ] ] @xmath230-a.s .",
    "we have used here the fact that the @xmath328 s are independent , the explicit formula for @xmath328 , and . summarizing thus far",
    ", we have that @xmath406\\chi_{\\{\\gamma_n>0\\}}\\le \\frac{2}{\\alpha}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\left(l^{(n)}_{t-}-\\alpha\\right)^+ + \\frac{1}{n }   + \\sqrt{\\frac{3}{n}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}2 + \\frac{1}{f^2((t - t^*)-)}\\rb } \\rb\\ ] ] @xmath230-a.s . as we pointed out earlier , @xmath409",
    ", so by iterated conditioning , we next have that @xmath410\\chi_{\\{\\gamma_n>0\\}}\\le \\frac{2}{\\alpha}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\gamma_n^+ + \\frac{1}{n }   + \\sqrt{\\frac{3}{n}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}2 + \\frac{1}{f^2((t - t^*)-)}\\rb}\\rb\\ ] ]    fix now @xmath411 . if @xmath412 , then in fact @xmath413 . on the other hand , if @xmath414 , then @xmath415 thus @xmath416 hence @xmath417 \\le { \\varepsilon}+ t \\frac{\\tilde { \\mathbb{e}}_n\\left[{\\mathfrak{f}}\\left(\\tilde { \\varrho}^\\alpha_n\\right)\\chi_{\\{\\gamma_n>0\\}}\\bigg| l^{(n)}_{t-}\\right]}{{\\mathfrak{f}}({\\varepsilon } ) } \\\\ \\le { \\varepsilon}+ \\frac{2t}{\\alpha{\\mathfrak{f}}({\\varepsilon})}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\gamma_n^+ + \\frac{1}{n } + \\sqrt{\\frac{3}{n}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}2 + \\frac{1}{f^2((t - t^*)-)}\\rb}\\rb \\end{gathered}\\ ] ] @xmath230-a.s .",
    "in other words , @xmath418\\chi_{\\{\\gamma_n = s\\}}\\le   { \\varepsilon}+ \\frac{2t}{\\alpha{\\mathfrak{f}}({\\varepsilon})}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\frac{1}{n^{3/4 } } + \\frac{1}{n } + \\sqrt{\\frac{3}{n}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}2 + \\frac{1}{f^2((t - t^*)-)}\\rb } \\rb.\\ ] ] let @xmath243 and then let @xmath419 .",
    "we here give the deferred proofs .    to begin , recall stirling s formula .",
    "let @xmath420 be defined by @xmath421 for all @xmath422 ; then @xmath423 .",
    "then for any @xmath424 , @xmath425 where @xmath426 let s now use stirling s formula .",
    "we have @xmath427 thus @xmath428 where @xmath429 . to find the asymptotics of @xmath430",
    ", we first let @xmath431 be such that @xmath432 then there is a @xmath433 such that @xmath434 for all @xmath435 . again using stirling s formula",
    ", we have that @xmath436\\\\ & \\qquad \\times \\frac{1}{\\sqrt{\\left(1+\\frac{s}{\\alpha n}\\right)\\left(1-\\frac{s}{n(1-\\alpha)}\\right)}}\\times \\frac{1+\\tilde { \\mathcal{e}}_1(n\\alpha)}{{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n\\alpha+s)\\rb{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n(1-\\alpha)-s)\\rb } \\\\ & = \\exp\\left[-\\tilde { \\mathcal{e}}_4(s , n)\\right]\\frac{1}{\\sqrt{\\left(1+\\frac{s}{\\alpha n}\\right)\\left(1-\\frac{s}{n(1-\\alpha)}\\right)}}\\\\ & \\qquad \\times \\frac{1+\\tilde { \\mathcal{e}}_1(n\\alpha)}{{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n\\alpha+s)\\rb{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n(1-\\alpha)-s)\\rb } \\end{aligned}\\ ] ] where @xmath437    let s now combine things together .",
    "we have that @xmath438 where @xmath439\\frac{1}{\\sqrt{\\left(1+\\frac{s}{\\alpha n}\\right)\\left(1-\\frac{s}{n(1-\\alpha)}\\right)}}\\\\ & \\qquad \\times\\frac{1+\\tilde { \\mathcal{e}}_1(n\\alpha)}{{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n\\alpha+s)\\rb{\\left\\ { } \\newcommand{\\rb}{\\right\\}}1+\\tilde { \\mathcal{e}}_1(n(1-\\alpha)-s)\\rb}. \\end{aligned}\\ ] ] note that if @xmath440 , then @xmath441 thus if @xmath440 , then for @xmath19 large enough @xmath442 the claimed statement follows .",
    "let s now start to prove proposition [ p : explicit ] .",
    "first , define @xmath443 for all @xmath444 $ ] .",
    "[ l : hear ] we have that @xmath445 where @xmath446 is given by .",
    "fix @xmath447 such that @xmath448 . if @xmath449 is not absolutely continuous with respect to @xmath86 , then @xmath450 ; thus we assume that @xmath449 is absolutely continuous with respect to @xmath86 .",
    "define @xmath451 then @xmath95 is convex on @xmath452 . recall that assumptions [ a : density ] and [ a : ig ] imply that @xmath453 .",
    "thus we can write ( using jensen s inequality ) that @xmath454\\int_{t\\in [ t,\\infty]}f\\left(\\frac{d\\mu'}{d\\mu}(t)\\right)\\frac{\\mu(dt)}{\\mu[t,\\infty ] } \\\\ \\ge \\mu[0,t)f\\left(\\int_{t\\in [ 0,t)}\\frac{d\\mu'}{d\\mu}(t)\\frac{\\mu(dt)}{\\mu[0,t)}\\right ) + \\mu[t,\\infty]f\\left(\\int_{t\\in [ t,\\infty]}\\frac{d\\mu'}{d\\mu}(t)\\frac{\\mu(dt)}{\\mu[t,\\infty]}\\right ) \\\\ = \\mu[0,t)f\\left(\\frac{\\mu'[0,t)}{\\mu[0,t)}\\right ) + \\mu[t,\\infty]f\\left(\\frac{\\mu'[t,\\infty]}{\\mu[t,\\infty]}\\right ) = \\hbar(\\mu'[0,t),\\mu[0,t ) ) . \\end{gathered}\\ ] ] we have equality here if and only if @xmath86-a.s . @xmath455}(t),\\ ] ] which holds if and only if @xmath456 .",
    "collecting things together , we have the claimed result .    in light of lemma",
    "[ l : hear ] , we need to show that @xmath457 to do this , we observe from that @xmath458 is differentiable and that @xmath459 for all @xmath460 . thus @xmath461",
    "if @xmath462 .",
    "assumption [ a : ig ] then gives us .",
    "combining our arguments , we get the claimed result .",
    "we here verify that @xmath38 is measurable .",
    "let @xmath463 be the collection of nondecreasing functions @xmath464 $ ] which are right - continuous and have left - hand limits and for which @xmath465 for @xmath13 .",
    "for @xmath447 and @xmath26 , define @xmath466 $ ] for @xmath26 and @xmath467 for @xmath13 .",
    "in particular , @xmath468 .",
    "it is clear that @xmath469 and is a bijection ( note that @xmath470 ; this allows us to recover @xmath471 when writing down the inverse of @xmath472 ) .",
    "we can then topologize @xmath463 by pushing the topology of @xmath104 forward through @xmath472 ; thus @xmath472 is continuous .",
    "we also note that @xmath473 converges to @xmath474 if and only if @xmath475 for all points @xmath476 at which @xmath477 is continuous .",
    "thus @xmath66 is a @xmath463-valued random variable .",
    "we next define @xmath478 as @xmath479 for all @xmath480 .",
    "thus @xmath481 . by the above characterization of convergence in @xmath463",
    ", we see that @xmath482 is continuous ; thus @xmath31 is also a @xmath463-valued random variable . finally , define @xmath483 as @xmath484 for all @xmath474 ( we define the @xmath485 integral as a lebesgue - stieltjes integral )",
    ". then @xmath486 .",
    "we claim that @xmath38 is measurable ( from @xmath463 to @xmath18 ) .",
    "let @xmath487)$ ] be such that @xmath488 for @xmath489 and @xmath490 for @xmath26 . for each positive integer @xmath21 and each @xmath474 ,",
    "set @xmath491 clearly @xmath492 is continuous .",
    "furthermore , by dominated convergence , @xmath493 for each @xmath477 ( i.e. , pointwise on @xmath463 ) .",
    "being the pointwise limit of continuous functions , @xmath494 is thus measurable .",
    "huyn pham .",
    "some applications and methods of large deviations in finance and insurance . in _",
    "paris - princeton lectures on mathematical finance 2004 _ , volume 1919 of _ lecture notes in math .",
    "_ , pages 191244 .",
    "springer , berlin , 2007 ."
  ],
  "abstract_text": [
    "<S> we use the theory of large deviations to study the pricing of investment - grade tranches of synthetic cdo s . in this paper , we consider a simplified model which will allow us to introduce some of the concepts and calculations . </S>"
  ]
}