{
  "article_text": [
    "one of the main methods of distribution of the free ( open source ) software is via http and/or ftp downloads .",
    "such software is usually replicated on different servers reducing load on individual servers and improving client latency .",
    "unfortunately some problems are associated with this method of distribution , to name a few :    1 .",
    "incomplete or outdated mirrors @xcite 2 .",
    "absence of tools needed to locate nearest , best mirror server .",
    "`` slashdot - effect '' - after the new version of software is announced the main server is overloaded for a long period of time .",
    "this prevents proper update of the mirror servers .",
    "intelligent replication of the software can solve first and the third problem .",
    "parallel download from the multiple mirror servers saturating the available bandwidth can be used to resolve the second one .",
    "commercial content distribution networks ( f.e .",
    "akamai @xcite ) are using ip multicasting for data transmission between replica nodes .",
    "theirs networks are of the order of hundred thousand hosts and both nodes and network infrastructure are maintained by cdn .",
    "unfortunately ip multicast suffers from a number of technical problems and the administrative burden of maintenance .",
    "these problems prevent it from forming a global infrastructure .",
    "it ca nt be widely used now as a transport layer for the global mesh of replicas .    on the other side",
    "there is a longstanding internet convention that large or popular sites are widely replicated , usually voluntearly .",
    "this process is known as `` mirroring '' .",
    "software for replication of www and ftp content exists for years - e.g. gnu wget @xcite , mirror @xcite and rsync @xcite .",
    "recently some formalization of this process has taken place with organization of uk mirror service @xcite , aarnet2 mirror archive @xcite etc .",
    "while the old volunteer based mirroring services are operated on a best - effort basis , these new mirrors operate under service level agreements with guaranteed levels of availability .",
    "mirror servers are updated using the standard client - server model with client pulling data from the server .",
    "we propose a method of content distribution in the server - server ( or p2p ) model that performs much better then standard client - server approach .    in the next section",
    "we will review previous work done on the subject , in the third section will introduce our algorithm , in the forth will describe the simulation setup , in section five we will evaluate different heuristics and in the last section we will present conclusions and formulate future development areas .",
    "dispersity routing split the transfer of information over multiple network paths to provide enhanced reliability and performance .",
    "one of the first papers on the subject was the paper of maxemchuk @xcite .",
    "usage of erasure codes in bulk data transfers in multicasting environments was introduced in paper of byers et all @xcite .",
    "they used a notion of `` digital fountain '' - case when servers are transmitting encoded parts of data independently , and client can receive as much data as its bandwidth permits .",
    "one of the best known applications based on this idea is opencola swarmcast @xcite .",
    "it can be used as a content distribution media but it was designed so that best performance is achieved at download of one huge file at the presence of large number of clients . streaming media distribution based on the multiple description coding was proposed in the work of apostolopoulos and others @xcite .",
    "they subdivided stream into 2 independent parts , each of them can be either played individually ( with degraded quality ) or used to reconstruct initial file .",
    "these 2 streams can be transmitted independently and from different servers .",
    "the yoid project @xcite was probably the best effort of creating transport layer for a global cdn .",
    "unfortunately it stoped at the stage of architectural white paper .",
    "a wast literature exists on replica placement in the content distribution networks ( see f.e .",
    "@xcite and @xcite and references therein ) .",
    "this problem is connected to the data distribution in the p2p environments , and inspired this work .    to the best of our knowledge",
    ", this paper is the first one exploring the problem of data distribution in the unicast networks in many - to - many architecture .",
    "in this section we will introduce a simple model of data distribution in the server - server network .",
    "internet topology has been studied in different papers @xcite-@xcite since 1997 . the main output from these papers that is relevant to us ,",
    "is that internet topology can not be modelled as a tree , but should be modelled as a more complicated graph .",
    "it was shown @xcite that hop count between autonomous systems ( as ) is in good correlation with point - to - point measured bandwidth .",
    "papers @xcite states that performance of some of the mirror servers do not depend on this property .",
    "that analysis can not be extended to the more general case , due to the large number of valuable parameters not included in the study .",
    "let assume that we do know the network topology @xmath0 ( hop count between as @xmath1 and as @xmath2 ) and we do know location of each of the @xmath3 nodes ( replicas ) in this network .",
    "total amount of data to be downloaded by each replica is @xmath4 .",
    "as soon as client downloads all data it becomes server and can start transmitting data to any other client on the network .",
    "let s assume that we have @xmath5 servers already .",
    "then we can write the following proportionality for the bandwidth of the client @xmath2 :    @xmath6    in the capaciated version of this problem we have upper limits on @xmath7 - bandwidth consumption during download is limited by @xmath8 ( client side ) and bandwidth available from the server @xmath2 is limited by @xmath9 ( server side ) .",
    "then proportionality ( [ 1 ] ) is transformed in to following equation :    @xmath10    where @xmath11 is the hypothetical function giving point - to - point bandwidth between nodes @xmath1 and @xmath2 .",
    "this equation provides us with 2 clues on what can be done in oder to maximize bandwidth of the system at the shortest time : + a ) client should be selected so that @xmath7 is maximal ( in order to increase number of servers as fast as possible ) .",
    "+ b ) download process should proceed from multiple servers to one client ( in oder to reach @xmath8 ) and to the multiple clients from one server ( in oder to reach @xmath9 ) .",
    "on one hand we can have not enough severs to saturate download limit of all clients and on another we can have not enough clients to consume all free bandwidth of the servers .",
    "then we can estimate total bandwidth of the system to be    @xmath12    there are two distinct cases in the evolution of the system : + a ) when @xmath13 ( initial phase ) and + b ) @xmath14 ( final phase ) .    for",
    "the simplicity let us assume that @xmath15 and @xmath16 for all hosts .",
    "then total bandwidth at time @xmath17 can be written as :    @xmath18    and    @xmath19    where @xmath20 - time when maximum bandwidth is reached and amount of data servers can transmit per time equals to amount of data clients can receive . please note that integral only roughly estimates amount of servers at @xmath17 .",
    "another , and better , approximation of ( [ second ] ) is @xmath21 or bandwidth of the system at @xmath22 .",
    "then @xmath23 - time when the system will be filled , can be found from the following equation :    @xmath24    or @xmath25    so we see that the time is proportional to the @xmath4 and that @xmath26 and @xmath27 should be of the same order of magnitude .",
    "we should also try to maximize @xmath28 or @xmath7 and @xmath29 at any given time .",
    "then the formal algorithm is the following : when there is any bandwidth left on the server side , new client is selected so that @xmath7 is maximal , or @xmath30 is minimal .",
    "clients can connect to the servers until they reaches @xmath8 .",
    "let us provide a simple example clarifying why subdividing @xmath4 into smaller parts and transmitting them individually should give good results .",
    "we subdivide data into two equal parts and subdivide our replica mesh into submeshes @xmath31 and @xmath29 so that mesh characteristics as the same .",
    "hop count distribution should be equal , and nodes nearest to the root server in each group , should be located at the same distance . then root server starts sending parts @xmath32 and @xmath33 to the 2 nearest nodes in the meshes .",
    "both parts will be uploaded at @xmath34 .",
    "after download is complete these 2 sub - meshes can act as independent networks , with possible small degradation of connectivity .",
    "they will be filled after @xmath35 ( see ( [ time ] ) ) .",
    "then they will start filling each other : if @xmath36 they will fill each other at time @xmath37 , in other case that will happen at @xmath38 .",
    "so the system will be filled approximately 2 times faster compared to ( [ time ] ) .",
    "having in mind this example one can believe that time of data propagation will be reduced after subdivision of data .",
    "we will explore this approach in our simulation .",
    "for our simulation we choose generated networks of 100 nodes in 3 different topologies . with the `` line '' topology we have 4 clusters of 25 nodes that are randomly connected within cluster ( with average distance of 4 hops ) .",
    "nodes from neighbour clusters are connected by 9 hops on average , nodes that have one cluster in between 12 and 2 clusters  15 hops .    in `` triangle '' topology nodes within cluster",
    "are randomly connected with average distance of 4 , node is connected to any node in other clusters with average distance of 12 hops .    in `` random '' topology nodes",
    "are connected randomly with average distance of 10 .",
    "all these topologies have average distance of 10 hops .",
    "it was shown in @xcite that most of the characteristics of the internet structures ( like hop distance between ases and router fanout ) obey power - law .",
    "we will not use these empirical law in our simulation , as replica placement can obey somewhat different laws or no laws at all .",
    "bandwidth between two nodes is inversely proportional to hop distance with 25 % of random noise and varies from 1.5 mbps to 20 kbps .",
    "amount of data to be distributed is 5 gb - around the size of modern linux distribution .",
    "node selection is performed using algorithm proposed in previous section . during simulation",
    "we include 5% of random noise to bandwidth between nodes .",
    "all simulated activity was subdivided in time slots of 1 minute , during that interval nodes were only downloading and no node status updates were made .      in oder to compare our results we choose algorithm used in cdns to locate position of replica / cache .",
    "this algorithm is called greedy - global and with minimal modifications can be used in our simulation .",
    "this modified method can be formulated the following way : we select replica one - by - one , at each step we choose one of the nodes so , that if replica is placed there , the resulting network overhead is minimized .",
    "greedy global heuristics can be modified to suit better p2p distribution .",
    "network overhead is characterized by the following cost function : @xmath39 where sum runs over all client nodes and @xmath40 is minimal distance from the client to the server .",
    "our algorithm is slightly different from regular cdn gg algorithm , as request rate and object popularity are not relevant in out case .",
    "this approach selects best location for @xmath5 replicas between @xmath3 nodes ( @xmath41 ) under steady load from the clients .",
    "one would expect that such algorithm can give good performance in our model as well , because when new node becomes server , our mesh have `` ideal '' replica placement .",
    "when the difference between cost at step @xmath42 ( k replicas ) and at step @xmath43 ( k+1 replica ) becomes small we can assume that there are enough `` perfectly '' placed replicas and we can start assigning clients based on our best client approach in the submeshes belonging to each replica server .",
    "this algorithm resembles current practice of assigning `` authoritative '' mirrors for each geographical location and redirecting clients to them .",
    "we will use both pure greedy global and greedy global / best client algorithms in our simulation .",
    "we can describe current `` best - practice '' method of data distribution in the mesh of replicas as the following procedure :    1 .",
    "client tries to find the nearest mirror server with required data and start download process .",
    "2 .   if none is available , it reaches master server .",
    "if master server is full , it waits till master server becomes free or some nearby server gets all data .",
    "we do not compare this method to ours , as according to our estimates , it will perform worth then greedy global .",
    "each test was run 100 times and data shown on figures is average .",
    "different lines corresponds to data being subdivided into 2 , 4 , 8 , 16 and 32 parts or not subdivided at all .",
    "( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' , `` triangle '' and `` random '' topologies correspondingly , title=\"fig:\",width=207 ]    it can be easily seen from figure 1 and table 1 , that subdividing data into smaller chunks and transmitting them independently indeed improve system performance .",
    "our results are almost independent on the topology , this means that algorithm will perform equally well in real - life .",
    "time required to fill the system is only slightly larger ( @xmath44 ) for 16 then for 32 subparts for all topologies .",
    "this can greatly reduce network overhead of the real system .",
    "results for the simulation with the greedy global algorithm are presented on figure 2 . for the sake of space we present figures only for the `` line '' topology .",
    "as one can see the main disadvantage of this heuristics is prolonged start of exponential growth .",
    "this is caused by the first client selection .",
    "usually the first selected client is one with nearly the worst connectivity to the root server , as opposed to the best client method , where the first client is the nearest one .",
    "we provide more data on the time required to fill system in table 1 .",
    "please note that we include not only pure greedy global but also greedy global + best client .",
    "we switch from greedy to best client algorithm when the cost of new placement ( [ gg ] ) is more then 70% , 80% and 90% of the previous .",
    "( right ) vs time in `` line '' topology for the greedy global heuristics.,title=\"fig:\",width=207 ]   ( right ) vs time in `` line '' topology for the greedy global heuristics.,title=\"fig:\",width=207 ]    @xmath45    one can easily see that best client outperforms all algorithms by 200% for some topologies / parts and by 60% for another",
    ".      our results can be quite sensitive to the load balancing policy .",
    "we looked at 4 different policies when selecting client with the same cost function ( [ 1 ] ) for the given chunk of data :    1 .",
    "client that downloaded less of the given part .",
    "2 .   client that downloaded more of the given part .",
    "3 .   client that downloaded less totally .",
    "client that downloaded more totally .",
    "results for different topologies and number of parts are presented in the table 2 .",
    "they show that time to fill is practically independent from the load - balancing policy .",
    "this means that current state of the system can be known only to the level of node ( i.e. node being client or server for the given part ) .",
    ".comparison of time to fill for different topologies , number of subparts and load balancing policies [ cols=\"^,^ , > , > , > , > \" , ]",
    "we propose a method of content distribution in the server - server ( or p2p ) model that performs much better then standard client - server approach .",
    "data to be downloaded from the server is subdivided into given number of parts .",
    "as soon as client downloads subpart completely it becomes server and can start transmitting it to any other client on the network .",
    "when there is any bandwidth left on the server side , new client is selected so that @xmath7 is maximal , or @xmath30 is minimal .",
    "clients can connect to the servers until they reaches @xmath8 .",
    "we perform simulation for different topologies and compare our heuristic with modified greedy global and greedy global + best client algorithms .",
    "we show that our method outperforms another algorithms by 200% for some topologies / number of parts and by 60% for another .",
    "our results are almost independent on the topology , so algorithm may perform equally well in real - life .",
    "it was shown that subdividing data into smaller chunks and transmitting them independently indeed improve system performance .",
    "we also found that time required to fill the system is only slightly larger ( @xmath44 ) for 16 than for 32 subparts .",
    "subdividing into smaller number of parts can greatly reduce network and computational overhead of the real system .",
    "we explore different load - balancing policies and find that time to fill does not depend on them .",
    "this means that current state of the system can be known only to the level of node ( i.e. node being client or server for the given part ) .",
    "we also tried to estimate impact of `` free - loaders '' . in oder to do that we varied download limit , and find that if servers are transmitting at least twice the size of download , time required to fill the system remains almost the same .",
    "this means that our replica mesh may indeed withstand `` slashdot effect '' .",
    "we are planing to develop decentralized algorithm that will use main results of this paper",
    ". it will be interesting to specifically check how many freeloaders can be in the mesh simultaneously and do not degrade performance of decentralized algorithm .",
    "one should check that our system performs well in real internet topology . for the completeness we should also include simulation results for the current `` best - practice '' method of data distribution in replica",
    "meshes .",
    "hamilton , m. and novikov , a. ,  ftp mirror tracker : first steps towards urn  , computer communications , 24(2 ) , february 2001 .",
    "@xmath46url : http://www.akamai.com/@xmath47 akamai web site .",
    "@xmath46url : http://www.gnu.org / software / wget/@xmath47 gnu wget",
    "homepage @xmath46url : http://sunsite.org.uk / packages / mirror/@xmath47 mirror homepage .",
    "@xmath46url : http://rsync.samba.org/@xmath47 rsync homepage @xmath46url : http://www.mirror.ac.uk/@xmath47 uk mirror service @xmath46url : http://www.aarnet.edu.au / projects/@xmath47 aarnet2 mirror archive n.f .",
    "maxemchuk , dispersity routing in store and forward networks , ph.d .",
    "thesis , university of pennsylvania , may 1975 .",
    "j. byers , m. luby , and m. mitzenmacher , accessing multiple mirror sites in parallel : using tornado codes to speed up downloads , in infocom 99 , apr . 1999 .",
    "@xmath46url : http://sourceforge.net / projects / swarmcast/@xmath47 swarmcast project j. apostolopoulos et al . , on multiple description streaming with content delivery networks , in infocom , june 2002 .",
    "@xmath46url : http://www.icir.org / yoid/@xmath47 yoid project home page    j. kangasharju et al . , object replication strategies in content distribution networks . in proceedings of wcw01",
    ": web caching and content distribution workshop , boston , ma , june 2001 .",
    "p. radoslavov etc al , topology - informed internet replica placement . in proceedings of wcw01 : web caching and content distribution workshop , boston , ma , june 2001 .",
    "r. govindan and a. reddy , `` an analysis of inter - domain topology and route stability , '' proc .",
    "ieee infocom , 1997 . + v. paxson .",
    "why we do nt know how to simulate the internet . in proceedings of the 1997 winter simulation conference , atlanta ga , u.s.a . , dec .",
    "1997 . c. faloutsos , m. faloutsos , p. faloutsos , `` on power - law relationships of the internet topology , '' proc . of acm sigcomm ,",
    "p. mcmanus , a passive system for server selection within mirrored resource environments using as path length heuristics .",
    "@xmath46url : http://proximate.appliedtheory.com/@xmath47 a. myers , p. dinda , and h. zhang",
    ". performance characteristics of mirror servers on the internet .",
    "technical report cmu - cs-98 - 157 , carnegie mellon university , july 1998 .",
    "+ n. natarajan , k. m. hanna , and b.n .",
    "levine `` an evaluation of mirror server performance stability '' submitted for publication ."
  ],
  "abstract_text": [
    "<S> we propose centralized algorithm of data distribution in the unicast p2p networks . </S>",
    "<S> good example of such networks are meshes of www and ftp mirrors . </S>",
    "<S> simulation of data propagation for different network topologies is performed and it is shown that proposed method performs up to 200% better then common approaches . </S>"
  ]
}