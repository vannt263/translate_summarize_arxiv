{
  "article_text": [
    "this article considers questions from bayesian statistics in an infinite dimensional setting , for example in function spaces .",
    "we assume our state space to be a general separable banach space @xmath6 . while in the finite - dimensional setting , the prior and posterior distribution of such statistical problems can typically be described by densities w.r.t .",
    "the lebesgue measure , such a characterisation is no longer possible in the infinite dimensional spaces we consider here : it can be shown that no analogue of the lebesgue measure exists in infinite dimensional spaces .",
    "one way to work around this technical problem is to replace lebesgue measure with a gaussian measure on @xmath7 , _",
    "i.e. _  with a borel probability measure  @xmath3 on @xmath7 such that all finite - dimensional marginals of @xmath3 are ( possibly degenerate ) normal distributions . using a fixed , centred ( mean - zero ) gaussian measure @xmath8 as a reference measure",
    ", we then assume that the distribution of interest , @xmath9 , has a density with respect to @xmath3 : @xmath10 measures @xmath9 of this form arise naturally in a number of applications , including the theory of conditioned diffusions @xcite and the bayesian approach to inverse problems  @xcite . in these settings",
    "there are many applications where @xmath11 is a locally lipschitz continuous function and it is in this setting that we work .",
    "our interest is in defining the concept of `` most likely '' functions with respect to the measure @xmath9 , and in particular the _ maximum a posteriori _ estimator in the bayesian context",
    ". we will refer to such functions as map estimators throughout .",
    "we will define the concept precisely and link it to a problem in the calculus of variations , study posterior consistency of the map estimator in the bayesian setting , and compute it for a number of illustrative applications .    to motivate the form of map estimators considered here we consider the case where @xmath12 is finite dimensional and the prior @xmath3 is gaussian @xmath13 .",
    "this prior has density @xmath14 with respect to the lebesgue measure where @xmath15 denotes the euclidean norm .",
    "the probability density for @xmath9 with respect to the lebesgue measure , given by  , is maximised at minimisers of @xmath16 where @xmath17 .",
    "we would like to derive such a result in the infinite dimensional setting .    the natural way to talk about map estimators in the infinite dimensional",
    "setting is to seek the centre of a small ball with maximal probability , and then study the limit of this centre as the radius of the ball shrinks to zero . to this end , let @xmath18 be the open ball of radius @xmath19 centred at @xmath20 . if there is a functional @xmath21 , defined on @xmath22 , which satisfies @xmath23 then @xmath21 is termed the _ onsager - machlup _ functional @xcite . for any fixed @xmath24 , the function @xmath25 for which the above limit is",
    "maximal is a natural candidate for the map estimator of @xmath9 and is clearly given by minimisers of the onsager - machlup function . in the finite dimensional case",
    "it is clear that @xmath21 given by is the onsager - machlup functional .",
    "from the theory of infinite dimensional gaussian measures @xcite it is known that copies of the gaussian measure @xmath3 shifted by @xmath26 are absolutely continuous w.r.t .",
    "@xmath3 itself , if and only if @xmath26 lies in the cameron - martin space @xmath27 ; furthermore , if the shift direction @xmath26 is in @xmath22 , then shifted measure  @xmath28 has density @xmath29 in the finite dimensional example , above , the cameron - martin norm of the gaussian measure @xmath3 is the norm  @xmath30 and it is easy to verify that   holds for all @xmath31 . in the infinite dimensional case ,",
    "it is important to keep in mind that   only holds for @xmath32 .",
    "similarly , the relation   only holds for @xmath33 . in our application ,",
    "the cameron - martin formula   is used to bound the probability of the shifted ball @xmath34 from equation  .",
    "( for an exposition of the standard results about small ball probabilities for gaussian measures we refer to  @xcite ; see also @xcite for related material . )",
    "the main technical difficulty that is encountered stems from the fact that the cameron - martin space  @xmath22 , while being dense in  @xmath7 , has measure zero with respect to  @xmath3 .",
    "an example where this problem can be explicitly seen is the case where @xmath3 is the wiener measure on @xmath35 ; in this example @xmath22 corresponds to a subset of the sobolov space  @xmath36 , which has indeed measure zero w.r.t .",
    "wiener measure .",
    "our theoretical results assert that despite these technical complications the situation from the finite - dimensional example , above , carry over to the infinite dimensional case essentially without change . in theorem  [ t :",
    "om ] we show that the onsager - machlup functional in the infinite dimensional setting still has the form  , where @xmath30 is now the cameron - martin norm associated to  @xmath9 ( using @xmath37 for @xmath38 ) , and in corollary  [ c : mapmin ] we show that the map estimators for @xmath9 lie in the cameron - martin space  @xmath22 and coincide with the minimisers of the onsager - machlup functional  @xmath21 .    in the second part of the paper , we consider the inverse problem of estimating an unknown function @xmath0 in a banach space @xmath7 , from a given observation @xmath39 , where @xmath40 here @xmath41 is a possibly nonlinear operator , and @xmath42 is a realization of an @xmath43-valued centred gaussian random variable with known covariance @xmath44 . a prior probability measure @xmath45",
    "is put on @xmath0 , and the distribution of @xmath46 is given by , with @xmath42 assumed independent of @xmath0 . under appropriate conditions on @xmath3 and @xmath47 ,",
    "bayes theorem is interpreted as giving the following formula for the radon - nikodym derivative of the posterior distribution @xmath4 on @xmath48 with respect to @xmath3 : @xmath49 where @xmath50 derivation of bayes formula for problems with finite dimensional data , and @xmath42 in this form , is discussed in @xcite . clearly , then",
    ", bayesian inverse problems with gaussian priors fall into the class of problems studied in this paper , for potentials @xmath51 given by which depend on the observed data @xmath1 . when the probability measure @xmath9 arises from the bayesian formulation of inverse problems , it is natural to ask whether the map estimator is close to the truth underlying the data , in either the small noise or large sample size limits .",
    "this is a form of bayesian posterior consistency , here defined in terms of the map estimator only .",
    "we will study this question for finite observations of a nonlinear forward model , subject to gaussian additive noise .",
    "the paper is organized as follows :    * in section  [ s : bayes ] we detail our assumptions on @xmath51 and @xmath3 ; * in section  [ s : map ] we give conditions for the existence of an onsager - machlup functional @xmath21 and show that the map estimator is well - defined as the minimiser of this functional ; * in section  [ s : consistency ] we study the problem of bayesian posterior consistency by studying limits of onsager - machlup minimisers in the small noise and large sample size limits ; * in section  [ sec : fm ] we study applications arising from data assimilation for the navier - stokes equation , as a model for what is done in weather prediction ; * in section  [ sec : cd ] we study applications arising in the theory of conditioned diffusions .",
    "we conclude the introduction with a brief literature review .",
    "we first note that map estimators are widely used in practice in the infinite dimensional context @xcite .",
    "we also note that the functional @xmath21 in resembles a tikhonov - phillips regularization of the minimisation problem for @xmath51 @xcite , with the cameron - martin norm of the prior determining the regularization . in the theory of classical non - statistical inversion , formulation via",
    "tikhonov - phillips regularization leads to an infinite dimensional optimization problem and has led to deeper understanding and improved algorithms .",
    "our aim is to achieve the same in a probabilistic context .",
    "one way of defining a map estimator for @xmath9 given by is to consider the limit of parametric map estimators : first discretize the function space using @xmath52 parameters , and then apply the finite dimensional argument above to identify an onsager - machlup functional on @xmath53 . passing to the limit @xmath54 in the functional provides a candidate for the limiting onsager - machlup functional .",
    "this approach is taken in @xcite for problems arising in conditioned diffusions . unfortunately , however",
    ", it does not necessarily lead to the correct identification of the onsager - machlup functional as defined by .",
    "the reason for this is that the space on which the onsager - mahlup functional is defined is smoother than the space on which small ball probabilities are defined .",
    "small ball probabilities are needed to properly define the onsager - machlup functional in the infinite dimensional limit .",
    "this means that discretization and use of standard numerical analysis limit theorems can , if incorrectly applied , use more regularity than is admissible in identifying the limiting onsager - mahlup functional .",
    "we study the problem directly in the infinite dimensional setting , without using discretization , leading , we believe , to greater clarity . adopting the infinite dimensional perspective for map estimation has been widely studied for diffusion processes @xcite and related stochastic pdes @xcite ; see @xcite for an overview .",
    "our general setting is similar to that used to study the specific applications arising in the papers @xcite . by working with small ball properties of gaussian measures , and assuming that @xmath51 has natural continuity properties , we are able to derive results in considerable generality .",
    "there is a recent related definition of map estimators in @xcite , with application to density estimation in @xcite . however , whilst the goal of minimising @xmath21 is also identified in @xcite , the proof in that paper is only valid in finite dimensions since it implicitly assumes that the cameron - martin norm is @xmath55a.s .",
    "finite . in our specific application to fluid mechanics",
    "our analysis demonstrates that widely used _ variational methods _ @xcite may be interpreted as map estimators for an appropriate bayesian inverse problem and , in particular , that this interpretation , which is understood in the atmospheric sciences community in the finite dimensional context , is well - defined in the limit of infinite spatial resolution .",
    "posterior consistency in bayesian nonparametric statistics has a long history @xcite .",
    "the study of posterior consistency for the bayesian approach to inverse problems is starting to receive considerable attention .",
    "the papers @xcite are devoted to obtaining rates of convergence for linear inverse problems with conjugate gaussian priors , whilst the papers @xcite study non - conjugate priors for linear inverse problems .",
    "our analysis of posterior consistency concerns nonlinear problems , and finite data sets , so that multiple solutions are possible .",
    "we prove an appropriate weak form of posterior consistency , without rates , building on ideas appearing in @xcite .",
    "our form of posterior consistency is weaker than the general form of bayesian posterior consistency since it does not concern fluctuations in the posterior , simply a point ( map ) estimator .",
    "however we note that for linear gaussian problems there are examples where the conditions which ensure convergence of the posterior mean ( which coincides with the map estimator in the linear gaussian case ) also ensure posterior contraction of the entire measure @xcite .",
    "throughout this paper we assume that @xmath56 is a separable banach space and that @xmath3 is a centred gaussian ( probability ) measure on @xmath7 with cameron - martin space @xmath27 .",
    "the measure @xmath9 of interest is given by   and we make the following assumptions concerning the _ potential _  @xmath51 .    [ a : asp1 ] the function @xmath11 satisfies the following conditions :    * for every @xmath57 there is an @xmath58 , such that for all @xmath59 , @xmath60 * @xmath51 is locally bounded from above , _",
    "i.e. _  for every @xmath61 there exists @xmath62 such that , for all @xmath59 with @xmath63 we have @xmath64 * @xmath51 is locally lipschitz continuous , _",
    "i.e. _ for every @xmath61 there exists @xmath65 such that for all @xmath66 with @xmath67 we have @xmath68    assumption  [ a : asp1](i ) ensures that the expression   for the measure @xmath9 is indeed normalizable to give a probability measure ; the specific form of the lower bound is designed to ensure that application of the fernique theorem ( see @xcite or  @xcite ) proves that the required normalization constant is finite .",
    "assumption  [ a : asp1](ii ) enables us to get explicit bounds from below on small ball probabilities and assumption  [ a : asp1](iii ) allows us to use continuity to control the onsager - machlup functional .",
    "numerous examples satisfying these condition are given in the references  @xcite .",
    "finally , we define a function  @xmath69 by @xmath70 we will see in section  [ s : map ] that @xmath21 is the onsager - machlup functional .",
    "[ r : mean ] we close with a brief remark concerning the definition of the onsager - machlup function in the case of non - centred reference measure @xmath71 . shifting coordinates by @xmath72 it is possible to apply the theory based on centred gaussian measure @xmath3 , and then undo the coordinate change .",
    "the relevant onsager - machlup functional can then be shown to be @xmath73",
    "in this section we prove two main results . the first , theorem [ t : om ] , establishes that @xmath21 given by is indeed the onsager - machlup functional for the measure @xmath9 given by",
    ". then theorem  [ t : map ] and corollary [ c : mapmin ] , show that the map estimators , defined precisely in definition  [ d : map ] , are characterised by the minimisers of the onsager - machlup functional .    for @xmath74 ,",
    "let @xmath18 be the open ball centred at @xmath20 with radius  @xmath19 in  @xmath7 .",
    "let @xmath75 be the mass of the ball  @xmath76 .",
    "we first define the map estimator for @xmath9 as follows :    [ d : map ] let @xmath77 any point @xmath78 satisfying @xmath79 , is a map estimator for the measure @xmath9 given by  .",
    "we show later on ( theorem  [ t : map ] ) that a strongly convergent subsequence of @xmath80 exists and its limit , that we prove to be in @xmath22 , is a map estimator and also minimises the onsager - machlup functional @xmath21 .",
    "corollary  [ c : mapmin ] then shows that any map estimator @xmath81 as given in definition  [ d : map ] lives in @xmath22 as well , and minimisers of @xmath21 characterise all map estimators of @xmath9 .",
    "one special case where it is easy to see that the map estimator is unique is the case where @xmath51 is linear , but we note that , in general , the map estimator can not be expected to be unique . to achieve uniqueness , stronger conditions on @xmath51 would be required .",
    "we first need to show that @xmath21 is the onsager - machlup functional for our problem :    [ t : om ] let assumption  [ a : asp1 ] hold .",
    "then the function @xmath21 defined by   is the onsager - machlup functional for  @xmath9 , _",
    "i.e. _  for any @xmath82",
    "we have @xmath83    note that @xmath84 is finite and positive for any @xmath85 by assumptions  [ a : asp1](i),(ii ) together with the fernique theorem and the positive mass of all balls in @xmath7 , centred at points in @xmath22 , under gaussian measure @xcite .",
    "the key estimate in the proof is the following consequence of proposition  3 in section  18 of  @xcite : @xmath86 this is the key estimate in the proof since it transfers questions about probability , naturally asked on the space @xmath7 of full measure under @xmath3 , into statements concerning the cameron - martin norm of @xmath3 , which is almost surely infinite under @xmath3 .",
    "we have @xmath87 by assumption  [ a : asp1 ] ( iii ) , for any @xmath88 @xmath89 where @xmath90 with @xmath91 . therefore ,",
    "setting @xmath92 and @xmath93 , we can write @xmath94 now , by , we have @xmath95 with @xmath96 as @xmath97 .",
    "thus @xmath98 similarly we obtain @xmath99 with @xmath100 as @xmath97 and deduce that @xmath101 inequalities and give the desired result .",
    "we note that similar methods of analysis show the following :    let the assumptions of theorem  [ t : om ] hold . then for any @xmath102 @xmath103",
    "where @xmath104 .",
    "noting that we consider @xmath9 to be a probability measure and hence @xmath105 with @xmath104 , arguing along the lines of the proof of the above theorem gives @xmath106 with @xmath107 ( where @xmath108 is as in definition  [ a : asp1 ] ) and @xmath109 as @xmath110 .",
    "the result then follows by taking @xmath111 and @xmath112 as @xmath97 .",
    "[ p : prop ] suppose assumptions  [ a : asp1 ] hold",
    ". then the minimum of @xmath113 is attained for some element @xmath114 .",
    "the existence of a minimiser of @xmath21 in @xmath22 , under the given assumptions , is proved as theorem 5.4 in @xcite ( and as theorem 2.7 in @xcite in the case that @xmath51 is non - negative ) .",
    "the rest of this section is devoted to a proof of the result that map estimators can be characterised as minimisers of the onsager - machlup functional  @xmath21 ( theorem  [ t : map ] and corollary  [ c : mapmin ] ) .",
    "[ t : map ] suppose that assumptions  [ a : asp1 ] ( ii ) and ( iii ) hold .",
    "assume also that there exists an @xmath115 such that @xmath116 for any @xmath59 .",
    "* let @xmath117 .",
    "there is a @xmath118 and a subsequence of @xmath119 which converges to @xmath120 strongly in @xmath7 .",
    "* the limit @xmath120 is a map estimator and a minimiser of @xmath21 .",
    "the proof of this theorem is based on several lemmas .",
    "we state and prove these lemmas first and defer the proof of theorem  [ t : map ] to the end of the section where we also state and prove a corollary characterising the map estimators as minimisers of onsager - machlup functional .",
    "[ l : limg0 ] let @xmath121 . for any centred gaussian measure @xmath3 on a separable banach space @xmath7",
    "we have @xmath122 where @xmath123 and @xmath124 is a constant independent of @xmath26 and @xmath125 .",
    "we first show that this is true for a centred gaussian measure on @xmath53 with the covariance matrix @xmath126 $ ] in basis @xmath127 , where @xmath128 .",
    "let @xmath129 , and @xmath130 .",
    "define @xmath131 and with @xmath132 the ball of radius @xmath125 and centre @xmath26 in @xmath53 .",
    "we have @xmath133 for any @xmath134 and where @xmath135 is a centred gaussian measure on @xmath53 with the covariance matrix @xmath136 $ ] ( noting that @xmath137 ) . by anderson s inequality for the infinite dimensional spaces ( see theorem 2.8.10 of @xcite ) we have @xmath138 and therefore @xmath139 and since @xmath140 is arbitrarily small the result follows for the finite - dimensional case .    to show the result for an infinite dimensional separable banach space @xmath7 , we first note that @xmath141 , the orthogonal basis in the cameron - martin space of @xmath7 for @xmath3 , separates the points in @xmath7 , therefore @xmath142 is an injective map from @xmath7 into @xmath143 .",
    "let @xmath144 and @xmath145 then , since @xmath3 is a radon measure , for the balls @xmath146 and @xmath147 , for any @xmath148 , there exists large enough @xmath149 such that the cylindrical sets @xmath150 and @xmath151 satisfy @xmath152 and @xmath153 for @xmath154 @xcite , where @xmath155 denotes the symmetric difference .",
    "let @xmath156 and @xmath157 and for @xmath158 , @xmath154 large enough so that @xmath159 .",
    "with @xmath160 we have @xmath161 since @xmath162 and @xmath163 converge to zero as @xmath164 , the result follows .",
    "[ l : limg0-ne ] suppose that @xmath165 , @xmath166 and @xmath167 converges weakly to @xmath26 in @xmath7 as @xmath168 .",
    "then for any @xmath57 there exists @xmath19 small enough such that @xmath169    let @xmath170 be the covariance operator of @xmath3 , and @xmath171 the eigenfunctions of @xmath170 scaled with respect to the inner product of @xmath22 , the cameron - martin space of @xmath3 , so that @xmath172 forms an orthonormal basis in @xmath22 .",
    "let @xmath173 be the corresponding eigenvalues and @xmath129 .",
    "since @xmath167 converges weakly to @xmath174 in @xmath7 as @xmath168 , @xmath175 and as @xmath165 , for any @xmath176 , there exists @xmath149 sufficiently large and @xmath177 sufficiently small such that @xmath178 where @xmath179 . by ( [ e : wcx ] ) , for @xmath180 small enough we have @xmath181 and therefore @xmath182 let @xmath183 map @xmath26 to @xmath184 , and consider @xmath185 to be defined as in ( [ e : defj0n ] ) .",
    "having ( [ e : la ] ) , and choosing @xmath186 such that @xmath187 , for any @xmath188 we can write @xmath189 as @xmath176 was arbitrary , the constant in the last line of the above equation can be made arbitrarily small , by making @xmath19 sufficiently small and @xmath52 sufficiently large . having this and arguing in a similar way to the final paragraph of proof of lemma  [ l : limg0 ] , the result follows .",
    "[ c : limg0-ne ] suppose that @xmath190 .",
    "then @xmath191    [ l : limg0-wc ] consider @xmath166 and suppose that @xmath167 converges weakly and not strongly to @xmath192 in @xmath7 as @xmath168 .",
    "then for any @xmath57 there exists @xmath19 small enough such that @xmath169    since @xmath167 converges weakly and not strongly to @xmath192 , we have @xmath193 and therefore for @xmath194 small enough there exists @xmath195 such that @xmath196 for any @xmath197 .",
    "let @xmath198 , @xmath199 and @xmath200 , @xmath201 , be defined as in the proof of lemma [ l : limg0-ne ] . since @xmath202 as @xmath168",
    ", @xmath203 also , as for @xmath3-almost every @xmath204 , @xmath205 and @xmath206 is an orthonormal basis in @xmath207 ( closure of @xmath208 in @xmath209 ) @xcite , we have @xmath210 now , for any @xmath176 , let @xmath149 large enough such that @xmath211 .",
    "then , having ( [ e : wcx0 ] ) and ( [ e : l2b ] ) , one can choose @xmath212 small enough and @xmath213 large enough so that for @xmath214 and @xmath215 @xmath216 therefore , letting @xmath185 and @xmath217 be defined as in the proof of lemma  [ l : limg0-ne ] , we can write @xmath218 if @xmath214 is small enough so that @xmath219 . having this and arguing in a similar way to the final paragraph of proof of lemma  [ l : limg0 ] , the result follows .    having these preparations in place , we can give the proof of theorem  [ t : map ] .",
    "( _ of theorem  [ t : map ] _ )",
    "i ) we first show @xmath220 is bounded in @xmath7 . by assumption  [ a : asp1].(ii ) for any @xmath61 there",
    "exists @xmath62 such that @xmath221 for any @xmath0 satisfying @xmath222 ; thus @xmath223 may be assumed to be a non - decreasing function of @xmath224 .",
    "this implies that @xmath225 we assume that @xmath226 and then the inequality above shows that @xmath227 noting that @xmath163 is independent of @xmath19 .",
    "we also can write @xmath228 which implies that for any @xmath20 and @xmath121 @xmath229 now suppose @xmath220 is not bounded in @xmath7 , so that for any @xmath230 there exists @xmath231 such that @xmath232 ( with @xmath233 as @xmath234 ) . by ( [ e : j0 ] ) ,",
    "( [ e : zx1 ] ) and definition of @xmath235 we have @xmath236 implying that for any @xmath237 and corresponding @xmath235 @xmath238 this contradicts the result of lemma  [ l : limg0 ] ( below ) for @xmath231 small enough .",
    "hence there exists @xmath239 such that @xmath240 therefore there exists a @xmath241 and a subsequence of @xmath242 which converges weakly in @xmath7 to @xmath241 as @xmath97 .    now , suppose either    * there is no strongly convergent subsequence of @xmath220 in @xmath7 , or * if there is one , its limit @xmath174 is not in @xmath22 .",
    "let @xmath243 .",
    "each of the above situations imply that for any positive @xmath244 , there is a @xmath245 such that for any @xmath246 , @xmath247    we first show that , @xmath174 has to be in @xmath22 . by definition of @xmath248",
    "we have ( for @xmath249 ) @xmath250 supposing @xmath165 , in lemma  [ l : limg0-ne ] we show that for any @xmath57 there exists @xmath19 small enough such that @xmath251 hence choosing @xmath252 in ( [ e : fringe ] ) such that @xmath253 , and setting @xmath254 , from ( [ e : zd - contra ] ) , we get @xmath255 which is a contradiction .",
    "we therefore have @xmath118 .",
    "now , knowing that @xmath256 , we can show that the @xmath248 converges strongly in @xmath7 .",
    "suppose not .",
    "then for @xmath257 the hypotheses of lemma  [ l : limg0-wc ] are satisfied .",
    "again choosing @xmath252 in ( [ e : fringe ] ) such that @xmath253 , and setting @xmath254 , from lemma  [ l : limg0-wc ] and ( [ e : zd - contra ] ) , we get @xmath258 which is a contradiction .",
    "hence there is a subsequence of @xmath220 converging strongly in @xmath7 to @xmath118 .",
    "\\ii ) let @xmath259 ; existence is assured by theorem  [ t : om ] . by assumption  [ a : asp1 ] ( iii )",
    "we have @xmath260 with @xmath261 and @xmath262 . therefore , since @xmath51 is continuous on @xmath7 and @xmath263 in x , @xmath264 suppose @xmath220 is not bounded in @xmath22 or if it is , it only converges weakly ( and not strongly ) in @xmath22 .",
    "then @xmath265 and hence for small enough @xmath19 , @xmath266 .",
    "therefore for the centered gaussian measure @xmath3 , since @xmath267 we have @xmath268 this , since by definition of @xmath248 , @xmath269 and hence @xmath270 implies that @xmath271 in the case where @xmath220 converges strongly to @xmath174 in @xmath22 , by the cameron - martin theorem we have @xmath272 and then by an argument very similar to the proof of theorem  18.3 of @xcite one can show that @xmath273 and ( [ e : bzsup ] ) follows again in a similar way .",
    "therefore @xmath274 is a map estimator of measure @xmath9 .",
    "it remains to show that @xmath174 is a minimiser of @xmath21 .",
    "suppose @xmath174 is not a minimiser of @xmath21 so that @xmath275 .",
    "let @xmath276 be small enough so that in the equation before ( [ e : jlims ] ) @xmath277 for any @xmath278 and therefore @xmath279 let @xmath280 .",
    "we have @xmath281 and this by ( [ e : bzmin ] ) and ( [ e : bzsup ] ) implies that @xmath282 which is a contradiction , since by definition of @xmath248 , @xmath283 for any @xmath121 .",
    "[ c : mapmin ] under the conditions of theorem  [ t : map ] we have the following :    * any map estimator , given by definition  [ d : map ] , minimises the onsager - machlup functional @xmath21 . * any @xmath284 which minimises the onsager - machlup functional @xmath21 , is a map estimator for measure @xmath9 given by .",
    "* let @xmath81 be a map estimator .",
    "by theorem  [ t : map ] we know that @xmath285 has a subsequence which strongly converges in @xmath7 to @xmath120 .",
    "let @xmath286 be the said subsequence .",
    "then by ( [ e : bzsup ] ) one can show that @xmath287 by the above equation and since @xmath81 is a map estimator , we can write @xmath288 then corollary  [ c : limg0-ne ] implies that @xmath289 , and supposing that @xmath81 is not a minimiser of @xmath21 would result in a contradiction using an argument similar to last paragraph of the proof of the above theorem . *",
    "note that the assumptions of theorem  [ t : map ] imply those of theorem  [ t : om ] .",
    "since @xmath120 is a minimiser of @xmath21 as well , by theorem  [ t : om ] we have @xmath290 then we can write @xmath291 the result follows by definition  [ d : map ] .",
    "the structure , where @xmath3 is gaussian , arises in the application of the bayesian methodology to the solution of inverse problems . in that context",
    "it is interesting to study _ posterior consistency _ : the idea that the posterior concentrates near the truth which gave rise to the data , in the small noise or large sample size limits ; these two limits are intimately related and indeed there are theorems that quantify this connection for certain linear inverse problems @xcite .    in this section",
    "we describe the bayesian approach to nonlinear inverse problems , as outlined in the introduction .",
    "we assume that the data is found from application of @xmath47 to the truth @xmath292 with additional noise : @xmath293 the posterior distribution @xmath4 is then of the form and in this case it is convenient to extend the onsager - machlup functional @xmath21 to a mapping from @xmath294 to @xmath295 , defined as @xmath296    we study posterior consistency of map estimators in both the small noise and large sample size limits .",
    "the corresponding results are presented in theorems [ t : j_n ] and  [ t : j ] , respectively .",
    "specifically we characterize the sense in which the map estimators concentrate on the truth underlying the data in the small noise and large sample size limits .",
    "let us denote the exact solution by @xmath292 and suppose that as data we have the following @xmath52 random vectors @xmath297 with @xmath298 and @xmath299 independent identically distributed random variables .",
    "thus , in the general setting , we have @xmath300 , @xmath301 and @xmath44 a block diagonal matrix with @xmath302 in each block .",
    "we have @xmath52 independent observations each polluted by @xmath303 noise , and we study the limit @xmath54 . corresponding to this set of data and",
    "given the prior measure @xmath304 we have the following formula for the posterior measure on @xmath0 : @xmath305 here , and in the following , we use the notation @xmath306 , and @xmath307 : by corollary [ c : mapmin ] map estimators for this problem are minimisers of @xmath308 our interest is in studying properties of the limits of minimisers @xmath309 of @xmath310 , namely the map estimators corresponding to the preceding family of posterior measures .",
    "we have the following theorem concerning the behaviour of @xmath309 when @xmath164 .",
    "[ t : j ] assume that @xmath311 is lipschitz on bounded sets and @xmath312 .",
    "for every @xmath313 , let @xmath314 be a minimiser of @xmath310 given by .",
    "then there exists a @xmath315 and a subsequence of @xmath316 that converges weakly to @xmath317 in @xmath22 , almost surely . for any such @xmath317 we have @xmath318 .",
    "we describe some preliminary calculations useful in the proof of this theorem , then give lemma  [ l : j_n ] , also useful in the proof , and finally give the proof itself .",
    "we first observe that , under the assumption that @xmath2 is lipschitz on bounded sets , assumptions  [ a : asp1 ] hold for @xmath51 .",
    "we note that @xmath319 hence @xmath320 define @xmath321 we have @xmath322",
    "[ l : j_n ] assume that @xmath311 is lipschitz on bounded sets .",
    "then for fixed @xmath323 and almost surely , there exists @xmath314 such that @xmath324    we first observe that , under the assumption that @xmath2 is lipschitz on bounded sets and because for a given @xmath52 and fixed realisations @xmath325 there exists an @xmath61 such that @xmath326 , assumptions  [ a : asp1 ] hold for @xmath51 . since @xmath327 the result follows by proposition  [ p : prop ] .    we may now prove the posterior consistency theorem . from onwards",
    "the proof is an adaptation of the proof of theorem 2 of @xcite .",
    "we note that , the assumptions on limiting behaviour of measurement noise in @xcite are stronger : property ( 9 ) of @xcite is not assumed here for our @xmath328 . on the other hand a frequentist approach is used in @xcite , while here since @xmath328 is coming from a bayesian approach , the norm in the regularisation term is stronger ( it is related to the cameron - martin space of the gaussian prior ) .",
    "that is why in our case asking what if @xmath292 is not in @xmath22 and only in @xmath7 , is relevant and is answered in corollary [ c : utrx ] below .    _",
    "( of theorem [ t : j ] ) _ by definition of @xmath309 we have @xmath329 therefore @xmath330 using young s inequality ( see lemma 1.8 of @xcite , for example ) for the last term in the right - hand side we get @xmath331 taking expectation and noting that the @xmath332 are independent , we obtain @xmath333 where @xmath334 .",
    "this implies that @xmath335 and @xmath336 1 ) we first show using that there exist @xmath315 and a subsequence @xmath337 of @xmath338 such that @xmath339 let @xmath340 be a complete orthonormal system for @xmath22 .",
    "then @xmath341 therefore there exists @xmath342 and a subsequence @xmath343 of @xmath344 , such that @xmath345 . now considering @xmath346 and using the same argument",
    "we conclude that there exists @xmath347 and a subsequence @xmath348 of @xmath343 such that @xmath349 . continuing similarly",
    "we can show that there exist @xmath350 and @xmath351 such that @xmath352 for any @xmath201 and as @xmath353 . therefore @xmath354 we need to show that @xmath355 .",
    "we have , for any @xmath356 , @xmath357 therefore @xmath355 and @xmath358 .",
    "we can now write for any nonzero @xmath359 @xmath360 now for any fixed @xmath57 we choose @xmath149 large enough so that @xmath361 and then @xmath362 large enough so that @xmath363 this demonstrates that @xmath364 as @xmath353 .",
    "\\2 ) now we show almost sure existence of a convergent subsequence of @xmath365 . by we",
    "have @xmath366 in probability as @xmath353 .",
    "therefore there exists a subsequence @xmath367 of @xmath365 such that @xmath368 now by we have @xmath369 in probability as @xmath353 and hence there exists a subsequence @xmath370 of @xmath367 such that @xmath371 converges weakly to @xmath317 in @xmath22 almost surely as @xmath353 .",
    "since @xmath22 is compactly embedded in @xmath7 , this implies that @xmath372 in @xmath7 almost surely as @xmath353 .",
    "the result now follows by continuity of @xmath2 .    in the case",
    "that @xmath373 ( and not necessarily in @xmath22 ) , we have the following weaker result :    [ c : utrx ] suppose that @xmath2 and @xmath309 satisfy the assumptions of theorem [ t : j ] , and that @xmath373 .",
    "then there exists a subsequence of @xmath374 converging to @xmath375 almost surely .    for any @xmath57 , by density of @xmath22 in @xmath7",
    ", there exists @xmath359 such that @xmath376 .",
    "then by definition of @xmath309 we can write @xmath377 therefore , dropping @xmath378 in the left - hand side , and using young s inequality we get @xmath379 by local lipschitz continuity of @xmath2 , @xmath380 , and therefore taking the expectations and noting the independence of @xmath332 we get @xmath381 implying that @xmath382 since the @xmath112 is obviously positive and @xmath140 was arbitrary , we have @xmath383 .",
    "this implies that @xmath384 in probability .",
    "therefore there exists a subsequence of @xmath385 which converges to @xmath375 almost surely .",
    "consider the case where as data we have the random vector @xmath386 for @xmath313 and with @xmath292 again as the true solution and @xmath387 , @xmath201 , gaussian random vectors in @xmath388 .",
    "thus , in the preceding general setting , we have @xmath389 and @xmath390 . rather than having @xmath52 independent observations , we have an observation noise scaled by small @xmath391 converging to zero . for this data and",
    "given the prior measure @xmath3 on @xmath0 , we have the following formula for the posterior measure : @xmath392 by the result of the previous section , the map estimators for the above measure are the minimisers of @xmath393 our interest is in studying properties of the limits of minimisers of @xmath310 as @xmath54 .",
    "we have the following almost sure convergence result .",
    "[ t : j_n ] assume that @xmath311 is lipschitz on bounded sets , and @xmath312 .",
    "for every @xmath313 , let @xmath314 be a minimiser of @xmath394 given by .",
    "then there exists a @xmath315 and a subsequence of @xmath316 that converges weakly to @xmath317 in @xmath22 , almost surely . for any such @xmath317 we have @xmath318 .",
    "the proof is very similar to that of theorem  [ t : j ] and so we only sketch differences .",
    "we have @xmath395 letting @xmath396 we hence have @xmath397 .",
    "for this @xmath328 the result of lemma  [ l : j_n ] holds true , using an argument similar to the large sample size case .",
    "the result of theorem  [ t : j_n ] carries over as well .",
    "indeed , by definition of @xmath309 , we have @xmath398 therefore @xmath399 using young s inequality for the last term in the right - hand side we get @xmath400 taking expectation we obtain @xmath401 this implies that @xmath402 and @xmath403 having ( [ e : eglim0 ] ) and ( [ e : eun_bd0 ] ) , and with the same argument as the proof of theorem  [ t : j ] , it follows that there exists a @xmath315 and a subsequence of @xmath338 that converges weakly to @xmath317 in @xmath22 almost surely , and for any such @xmath317 we have @xmath318 .    as in the large sample size case , here also if we have @xmath373 and we do not restrict the true solution to be in the cameron - martin space @xmath22 , one can prove , in a similar way to the argument of the proof of corollary  [ c : utrx ] , the following weaker convergence result :    [ c : utrx0 ] suppose that @xmath2 and @xmath309 satisfy the assumptions of theorem [ t : j_n ] , and that @xmath373 . then there exists a subsequence of @xmath374 converging to @xmath375 almost surely .",
    "in this section we present an application of the methods presented above to filtering and smoothing in fluid dynamics , which is relevant to data assimilation applications in oceanography and meteorology .",
    "we link the map estimators introduced in this paper to the variational methods used in applications @xcite , and we demonstrate posterior consistency in this context .",
    "we consider the 2d navier - stokes equation on the torus @xmath404 with periodic boundary conditions : @xmath405 here @xmath406 is a time - dependent vector field representing the velocity , @xmath407 is a time - dependent scalar field representing the pressure , @xmath408 is a vector field representing the forcing ( which we assume to be time - independent for simplicity ) , and @xmath409 is the viscosity .",
    "we are interested in the inverse problem of determining the initial velocity field @xmath0 from pointwise measurements of the velocity field at later times .",
    "this is a model for the situation in weather forecasting where observations of the atmosphere are used to improve the initial condition used for forecasting . for simplicity",
    "we assume that the initial velocity field is divergence - free and integrates to zero over @xmath410 , noting that this property will be preserved in time .",
    "define @xmath411 and @xmath412 as the closure of @xmath413 with respect to the @xmath414 norm .",
    "we define the map @xmath415 to be the leray - helmholtz orthogonal projector ( see @xcite ) .",
    "given @xmath416 , define @xmath417 . then an orthonormal basis for @xmath412",
    "is given by @xmath418 , where @xmath419 for @xmath420 .",
    "thus for @xmath421 we may write @xmath422 where , since @xmath0 is a real - valued function , we have the reality constraint @xmath423 . using the fourier decomposition of @xmath0",
    ", we define the fractional sobolev spaces @xmath424 with the norm @xmath425 , where @xmath426 . if @xmath427 , the stokes operator , then @xmath428 .",
    "we assume that @xmath429 for some @xmath430 .",
    "let @xmath431 , for @xmath432 , and define @xmath433 be the set of pointwise values of the velocity field given by @xmath434 where @xmath435 is some finite set of point in @xmath410 with cardinality @xmath436 .",
    "note that each @xmath437 depends on @xmath0 and we may define @xmath438 by @xmath439 .",
    "we let @xmath440 be a set of random variables in @xmath441 which perturbs the points @xmath442 to generate the observations @xmath443 in @xmath441 given by @xmath444 we let @xmath445 , the accumulated data up to time @xmath446 , with similar notation for @xmath447 , and define @xmath448 by @xmath449 .",
    "we now solve the inverse problem of finding @xmath0 from @xmath450 .",
    "we assume that the prior distribution on @xmath0 is a gaussian @xmath451 , with the property that @xmath452 and that the observational noise @xmath453 is i.i.d .  in @xmath454 ,",
    "independent of @xmath0 , with @xmath455 distributed according to a gaussian measure @xmath456 .",
    "if we define @xmath457 then under the preceding assumptions the bayesian inverse problem for the posterior measure @xmath4 for @xmath48 is well - defined and is lipschitz in @xmath1 with respect to the hellinger metric ( see @xcite ) .",
    "the onsager - machlup functional in this case is given by @xmath458 we are in the setting of subsection  [ ssec : sn ] , with @xmath391 and @xmath459 . in the applied literature",
    "approaches to assimilating data into mathematical models based on minimising @xmath460 are known as _ variational methods _ , and sometimes as 4dvar @xcite .",
    "illustration of posterior consistency in the fluid mechanics application .",
    "the three curves given are the relative error of the map estimator @xmath317 in reproducing the truth , @xmath461 ( solid ) , the relative error of the map @xmath462 in reproducing @xmath463 ( dashed ) , and the relative error of @xmath462 with respect to the observations @xmath1 ( dash - dotted).,scaledwidth=80.0% ]    we now describe numerical experiments concerned with studying posterior consistency in the case @xmath464 .",
    "we let @xmath465 noting that if @xmath466 , then @xmath467 almost surely for all @xmath468 ; in particular @xmath421 . thus @xmath452 as required .",
    "the forcing in @xmath469 is taken to be @xmath470 , where @xmath471 and @xmath472 with @xmath473 the canonical skew - symmetric matrix , and @xmath474 .",
    "the dimension of the attractor is determined by the viscosity parameter @xmath409 . for the particular forcing used",
    "there is an explicit steady state for all @xmath475 and for @xmath476 this solution is stable ( see @xcite , chapter 2 for details ) . as @xmath409 decreases the flow becomes increasingly complex and we focus subsequent studies of the inverse problem on the mildly chaotic regime which arises for @xmath477 .",
    "we use a time - step of @xmath478 .",
    "the data is generated by computing a true signal solving the navier - stokes equation at the desired value of @xmath409 , and then adding gaussian random noise to it at each observation time .",
    "furthermore , we let @xmath479 and take @xmath480 , so that @xmath481 .",
    "we take @xmath482 spatial observations at each observation time .",
    "the observations are made at the gridpoints ; thus the observations include all numerically resolved , and hence observable , wavenumbers in the system .",
    "since the noise is added in spectral space in practice , for convenience we define @xmath483 and present results in terms of @xmath484 .",
    "the same grid is used for computing the reference solution and for computing the map estimator .    figure  [ fig : post_cons ] illustrates the posterior consistency which arises as the observational noise strength @xmath464 .",
    "the three curves shown quantify : ( i ) the relative error of the map estimator @xmath317 compared with the truth , @xmath461 ; ( ii ) the relative error of @xmath462 compared with @xmath463 ; and ( iii ) the relative error of @xmath462 with respect to the observations @xmath1 .",
    "the figure clearly illustrates theorem  [ t : j_n ] , via the dashed curve for ( ii ) , and indeed shows that the map estimator itself is converging to the true initial condition , via the solid curve ( i ) , as @xmath485 . recall that the observations approach the true value of the initial condition , mapped forward under @xmath2 , as @xmath464 , and note that the dashed and dashed - dotted curves shows that the image of the map estimator under the forward operator @xmath2 , @xmath462 , is closer to @xmath486 than @xmath1 , asymptotically as @xmath464",
    "in this section we consider the map estimator for conditioned diffusions , including bridge diffusions and an application to filtering / smoothing .",
    "we identify the onsager - machlup functional governing the map estimator in three different cases .",
    "we demonstrate numerically that this functional may have more than one minimiser .",
    "furthermore , we illustrate the results of the consistency theory in section  [ s : consistency ] using numerical experiments .",
    "subsection  [ ssec : un ] concerns the unconditioned case , and includes the assumptions made throughout .",
    "subsections  [ ssec : bd ] and [ ssec : fs ] describe bridge diffusions and the filtering / smoothing problem respectively .",
    "finally , subsection  [ ssec : ne ] is devoted to numerical experiments for an example in filtering / smoothing .      for simplicity",
    "we restrict ourselves to scalar processes with additive noise , taking the form @xmath487 if we let @xmath409 denote the measure on @xmath488;{\\mathbb{r}}\\bigr)$ ] generated by the stochastic differential equation ( sde ) given in  , and @xmath489 the same measure obtained in the case @xmath490 , then the girsanov theorem states that @xmath491 with density @xmath492 if we choose an @xmath493 with @xmath494 , then an application of it s formula gives @xmath495 and using this expression to remove the stochastic integral we obtain @xmath496 thus , the measure @xmath409 has a density with respect to the gaussian measure @xmath489 and takes the form   with @xmath497 and @xmath498 : we have @xmath499 where @xmath500 is defined by @xmath501 and @xmath502          under these assumptions , we see that @xmath509 given by satisfies assumptions  [ a : asp1 ] and , indeed , the slightly stronger assumptions made in theorem  [ t : map ] . let @xmath510 $ ] denote the space of absolutely continuous functions on @xmath511 $ ] .",
    "then the cameron - martin space @xmath512 for @xmath489 is @xmath513\\bigm| \\int_0^t \\bigl|v'(s)\\bigr|^2\\,ds<\\infty    \\mbox { and } v(0)=0\\bigr\\}\\ ] ] and the cameron - martin norm is given by @xmath514 where @xmath515    the mean of @xmath489 is the constant function @xmath516 and so , using remark  [ r : mean ] , we see that the onsager - machlup functional for the unconditioned diffusion is thus @xmath517 given by @xmath518 together , theorems [ t : om ] and  [ t : map ] tell us that this functional attains its minimum over @xmath519 defined by @xmath520\\bigm| \\int_0^t \\bigl|v'(s)\\bigr|^2\\,ds<\\infty      \\mbox { and } v(0)=u^-\\bigr\\}.\\ ] ] furthermore such minimisers define map estimators for the unconditioned diffusion  , _",
    "i.e. _  the most likely paths of the diffusion .",
    "we note that the regularity of minimisers for @xmath521 implies that the map estimator is @xmath522 , whilst sample paths of the sde are not even differentiable .",
    "this is because the map estimator defines the centre of a tube in @xmath7 which contains the most likely paths .",
    "the centre itself is a smoother function than the paths .",
    "this is a generic feature of map estimators for measures defined via density with respect to a gaussian in infinite dimensions .      in this subsection",
    "we study the probability measure generated by solutions of , conditioned to hit @xmath523 at time @xmath524 so that @xmath525 , and denote this measure @xmath9 .",
    "let @xmath3 denote the brownian bridge measure obtained in the case @xmath490 . by applying the approach to determining bridge diffusion measures in @xcite",
    "we obtain , from , the expression @xmath526    since @xmath523 is fixed we now define @xmath527 by @xmath528 and then takes again the form .",
    "the cameron - martin space for the ( zero mean ) brownian bridge is @xmath529\\bigm| \\int_0^t \\bigl|v'(s)\\bigr|^2\\,ds<\\infty      \\mbox { and } v(0)=v(t)=0\\bigr\\}\\ ] ] and the cameron - martin norm is again @xmath530 .",
    "the onsager - machlup function for the unconditioned diffusion is thus @xmath531 given by @xmath532 where @xmath72 , given by @xmath533 for all @xmath534 $ ] , is the mean of @xmath3 and @xmath535\\bigm| \\int_0^t \\bigl|v'(s)\\bigr|^2\\,ds<\\infty      \\mbox { and } v(0)=u^- , u(t)=u^+ \\bigr\\}.\\ ] ] the map estimators for  @xmath9 are found by minimising @xmath536 over  @xmath537 .",
    "we now consider conditioning the measure @xmath409 on observations of the process @xmath0 at discrete time points .",
    "assume that we observe @xmath538 given by @xmath539 where @xmath540 and the @xmath541 are independent identically distributed random variables with @xmath542 .",
    "let @xmath543 denote the @xmath43-valued gaussian measure @xmath544 and let @xmath545 denote the @xmath43-valued gaussian measure @xmath546 where @xmath547 is defined by @xmath548 recall @xmath489 and @xmath409 from the unconditioned case and define the measures @xmath549 and @xmath550 on @xmath551 as follows .",
    "the measure @xmath552 is defined to be an independent product of @xmath489 and @xmath553 , whilst @xmath554 . then @xmath555 with constant of proportionality depending only on @xmath1 .",
    "clearly , by continuity , @xmath556 and hence @xmath557 applying the conditioning lemma 5.3 in @xcite then gives @xmath558 thus we define @xmath559 the cameron - martin space is again @xmath512 and the onsager - machlup functional is thus @xmath560 , given by @xmath561 the map estimator for this setup is , again , found by minimising the onsager - machlup functional  @xmath562 .",
    "the only difference between the potentials @xmath509 and @xmath563 , and thus between the functionals @xmath521 for the unconditioned case and @xmath562 for the case with discrete observations , is the presence of the term @xmath564 . in the euler - lagrange equations describing the minima of  @xmath562 , this term leads to dirac distributions at the observation points @xmath565 and it transpires that , as a consequence , minimisers of @xmath562 have jumps in their first derivates at @xmath566 .",
    "this effect can be clearly seen in the local minima of  @xmath562 shown in figure  [ fig : smooth - minima ] .",
    "illustration of the problem of local minima of @xmath21 for the smoothing problem with a small number of observations .",
    "the process @xmath567 starts at @xmath568 and moves in a double - well potential with stable equilibrium points at @xmath569 and @xmath570 .",
    "two observations of the process are indicated by the two black circles .",
    "the curves correspond to four different local minima of the functional @xmath562 for this situation . ]    for the experiments we generate a random `` signal '' by numerically solving the sde  , using the euler - maruyama method , for a double - well potential  @xmath571 given by @xmath572 with diffusion constant @xmath573 and initial value @xmath574 . from the resulting solution @xmath567 we generate random observations",
    "@xmath575 using  . then we implement the onsager - machlup functional  @xmath562 from equation   and use numerical minimisation , employing the broyden - fletcher - goldfarb - shanno method ( see  @xcite ; we use the implementation found in the gnu scientific library  @xcite ) , to find the minima of @xmath562 .",
    "the same grid is used for numerically solving the sde and for approximating the values of  @xmath562 .",
    "the first experiment concerns the problem of local minima of @xmath562 . for small number of observations",
    "we find multiple local minima ; the minimisation procedure can converge to different _ local _ minima , depending on the starting point of the optimisation .",
    "this effect makes it difficult to find the map estimator , which is the _ global _ minimum of @xmath562 , numerically .",
    "the problem is illustrated in figure  [ fig : smooth - minima ] , which shows four different local minima for the case of @xmath576 observations . in the presence of local minima",
    ", some care is needed when numerically computing the map estimator .",
    "for example , one could start the minimisation procedure with a collection of different starting points , and take the best of the resulting local minima as the result .",
    "one would expect this problem to become less pronounced as the number of observations increases , since the observations will `` pull '' the map estimator towards the correct solution , thus reducing the number of local minima .",
    "this effect is confirmed by experiments : for larger numbers of observations our experiments found only one local minimum .",
    "illustration of posterior consistency for the smoothing problem in the small - noise limit .",
    "the marked points correspond the maximum - norm distance between the true signal @xmath577 and the map estimator @xmath578 with @xmath579 evenly spaced observations .",
    "the map @xmath580 is the projection of the path onto the observation points .",
    "the solid line is a fitted curve of the form  @xmath581 . ]",
    "the second experiment concerns posterior consistency of the map estimator in the small noise limit .",
    "here we use a fixed number  @xmath473 of observations of a fixed path of  , but let the variance @xmath582 of the observational noise @xmath541 converge to  @xmath192 .",
    "noting that the exact path of the sde , denoted by @xmath577 in  , has the regularity of a brownian motion and therefore the observed path is not contained in the cameron - martin space  @xmath583 , we are in the situation described in corollary [ c : utrx0 ] .",
    "our experiments indicate that we have @xmath584 as @xmath585 , where @xmath578 denotes the map estimator corresponding to observational variance  @xmath582 , confirming the result of corollary  [ c : utrx0 ] .",
    "as discussed above , for small values of @xmath586 one would expect the minimum of @xmath562 to be unique and indeed experiments where different starting points of the optimisation procedure were tried did not find different minima for small  @xmath19 .",
    "the result of a simulation with @xmath579 is shown in figure  [ fig : smooth - noise ] .",
    "illustration of posterior consistency for the smoothing problem in the large sample size limit .",
    "the marked points correspond the supremum - norm distance between the true signal @xmath317 and the map estimator @xmath587 with @xmath473 evenly spaced observations .",
    "the solid line give a fitted curve of the form @xmath588 ; the exponent @xmath589 was found numerically .",
    "]    finally , we perform an experiment to illustrate posterior consistency in the large sample size limit : for this experiment we still use one fixed path @xmath577 of the sde  . then , for different values of  @xmath473 , we generate observations @xmath590 using   at equidistantly spaced times @xmath565 , for fixed @xmath591 , and then determine the @xmath35 distance of the resulting map estimate @xmath592 to the exact path  @xmath577 .",
    "as discussed above , for large values of @xmath473 one would expect the minimum of @xmath562 to be unique and indeed experiments where different starting points of the optimisation procedure were tried did not find different minima for large  @xmath473 .",
    "the situation considered here is not covered by the theoretical results from section  [ s : consistency ] , but the results of the numerical experiment , shown in figure  [ fig : smooth - data ] indicate that posterior consistency still holds ."
  ],
  "abstract_text": [
    "<S> we consider the inverse problem of estimating an unknown function @xmath0 from noisy measurements @xmath1 of a known , possibly nonlinear , map @xmath2 applied to  @xmath0 . </S>",
    "<S> we adopt a bayesian approach to the problem and work in a setting where the prior measure is specified as a gaussian random field  @xmath3 . </S>",
    "<S> we work under a natural set of conditions on the likelihood which imply the existence of a well - posed posterior measure , @xmath4 . under these conditions </S>",
    "<S> we show that the _ maximum a posteriori _ ( map ) estimator is well - defined as the minimiser of an onsager - machlup functional defined on the cameron - martin space of the prior ; thus we link a problem in probability with a problem in the calculus of variations . </S>",
    "<S> we then consider the case where the observational noise vanishes and establish a form of bayesian posterior consistency for the map estimator . </S>",
    "<S> we also prove a similar result for the case where the observation of @xmath5 can be repeated as many times as desired with independent identically distributed noise . </S>",
    "<S> the theory is illustrated with examples from an inverse problem for the navier - stokes equation , motivated by problems arising in weather forecasting , and from the theory of conditioned diffusions , motivated by problems arising in molecular dynamics . </S>"
  ]
}