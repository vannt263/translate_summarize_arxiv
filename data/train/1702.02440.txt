{
  "article_text": [
    "uncertainty relations have been of interest in quantum mechanics since heisenberg first proposed them in a thought experiment in the early 20th century @xcite .",
    "later theoretical developments put uncertainty in terms of entropy @xcite and recently there has been a great deal of activity in looking at extending the relations to include more than two observables @xcite .",
    "more recently still , experimental work has validated these multi - observable predictions @xcite @xcite .",
    "multi - observable entropic uncertainty relations are generally in the form : @xmath0 where @xmath1 is a measure of entropy , @xmath2 is a set of quantum measurements , and @xmath3 is some non - negative bound based on the measurements and density operator @xmath4 of the measured system .    one such measure of uncertainty , and the measure used in the analysis provided below , is the special case of the rnyi entropy , the shannon entropy .",
    "the shannon entropy is defined as :    @xmath5    where , in this context , @xmath6 is the probability of measuring a quantum system in a particular state . in the analysis below , we measure the shannon entropy of a measurement on a prepared quantum system by looking at the probabilities of finding that system in each of the possible states .",
    "an example shannon entropy of single measurement on a prepared quantum system , taken from the seminal work on finding an experimental basis for multi - measurement theory by xing et al .",
    "@xcite , can be seen below :    [ cols=\"^,^\",options=\"header \" , ]     the james - stein estimator is one of the most fantastic results in statistical - mathematics .",
    "the james - stein estimator shows that simultaneous estimation of three or more independent parameters is inadmissible using the standard , least - squares , estimator@xcite . in the case of the entropies measurements made on a system ,",
    "the least squares estimator is : @xmath7 where @xmath1 is the entropy of a measurement , where @xmath8 is a vector of the entropies associated with each measurement , and @xmath9 is the least squares estimator . in this case , the best estimate of a parameter is the parameter itself . from the example from the table above , the least squares estimation of the entropy parameter would be @xmath10 .",
    "however , when simultaneous estimation of three or more independent parameters is made , as in the case of looking at the entropies of multi - measurement discussed below , the best estimate of the parameters involves james - stein estimation . in other words ,",
    "when the above vector @xmath11 is three or more dimensions , an alternative estimator must be used .",
    "to find the total entropy of multi - measurement you must sum the associated entropies of the individual measurements made .",
    "the literature thus far has assumed the least squares estimator dealt with above . in terms of the least squares estimator",
    ", we would say : thus : @xmath12 however , stein has shown the least squares estimator is inadmissible when dealing with the average of statistics across more than 3 measurements .",
    "the james - stein estimator applies a factor to the measurements which , paradoxically , reduces the total bayes risk across all of the measurements .",
    "let @xmath8 be a vector of observations of length , @xmath13 . in this case , @xmath8",
    "would be made up of the entropies associated with a measurement on the same initial state .",
    "a better estimate of the true value of the vector @xmath8 would be found by applying the james - stein factor to the entropy associated with each of the measurements .",
    "the improved estimator would be @xmath14 after applying the above factor , the measured entropies would be shrunk towards zero with the remarkable result that the sum of the entropies would better correspond with reality .",
    "in this section we offer an analysis of the above theory as applied to experimental multi - measurement data .",
    "chart reproduced from data collected from the ground - breaking work in entropic multi - measurement by xing et al .",
    "the experimental work done compared the theoretical and experimental sums of shannon entropies across three measurements on the same initial states .",
    "two initial states are shown .",
    "the authors attributed the difference between experiment and theoretical model to the decoherence effect .",
    "the theoretical predictions in these case are : @xmath15 for the @xmath16 initial state and @xmath17 for the @xmath18 initial state , where @xmath19 is a parameter to be varied .",
    "the james - stein shrinkage of the entropies goes a very small way to explaining this delta .",
    "we can see from figure 2 and figure 3 that applying the james - stein estimator to the above measurements shrinks the experimental result towards the theoretical prediction in a small but significant way .",
    "alternatively , we might want to build the james - stein estimator into our theoretical models in which case we would say that under james - stein estimation the theoretical prediction has been stretched towards the experimental findings .",
    "we have shown that the theoretical prediction for entropic uncertainty relations with multi - measurements is improved by taking into account the james - stein estimation .",
    "it is of note that the entropy across multi measurement is best estimated when the entropy of each individual measurement takes into account the entropies of the other measurements in the multi - measurement relationship . as with all james - stein estimation",
    ", it should be taken into consideration that the entropy of each measurement is not necessarily improved by the shrinkage factor but the sum of those entropies necessarily is .",
    "appreciating the james - stein effect also means that the theoretic entropy lower bounds could be increased to accommodate this new understanding .",
    "for example , the multi - measurement theoretical lower bounds found by liu et al . should be increased by the james - stein shrinkage factor .",
    "liu et al . found a generalized bound on the entropic uncertainty relations for more than two measurements . for n observables , liu et .",
    "al found that the state independent uncertainty relation @xcite : @xmath20 applying the james - stein factor , the new equation for the total entropy of measurements across a state is : @xmath21 in the above case , the standard estimator for the standard deviation should be used , @xmath22    the state of the measured system has its von neumann entropy denoted by @xmath23 and @xmath13 is the number of observables .",
    "we also note an interesting extension will be the case where , from ( 5 ) : @xmath24 in this case , the estimate will tend to 0 and might offer a different view on the wavefunction collapse and measurement problem .",
    "this note has shown an improved bound for entropic uncertainty relations for multiple measurements in terms of theory and experimental findings and shows an interesting new use case for the james - stein estimator in physical theory .",
    "i would like to thank xing - yu pan and heng fan for kindly providing the data for the analysis .",
    "i would also like to thank joy christian and seb boissier for help navigating the world of academia .",
    "s.  l. y .- c . c. j .- d .",
    "y. h. f. x .- y .",
    "p. jian  xing , yu - ran  zhang , `` experimental testing of entropic uncertainty relations with multiple measurements in pure diamond , '' _ arxiv pre - print _ , no .  https://arxiv.org/abs/1510.03514 , 2015 .    wenchao ma , bin chen , ying liu , mengqi wang , xiangyu ye , fei kong , fazhan shi , shao - ming fei , jiangfeng du , `` experimental demonstration of uncertainty relations for the triple components of angular momentum '' , _ arxiv pre - print _ , no .",
    "https://arxiv.org/abs/1611.04775 , 2015 ."
  ],
  "abstract_text": [
    "<S> this note shows how to apply the james - stein estimator to the case of entropic uncertainty relations of more than two observables . </S>",
    "<S> a better result is found compared to applying the ordinary estimator and we find a more optimal model compared with experimental data . </S>",
    "<S> the theoretical bounds for entropic relations for more than two observables are shown to be be improved . </S>"
  ]
}