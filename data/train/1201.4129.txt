{
  "article_text": [
    "financial time series present an important characteristic known as volatility which can be defined / measured in different ways but it is not directly observable . a common approach , but not unique , is to define the volatility as the conditional standard deviation ( or the conditional variance ) of the process and use heteroskedastic models to describe it .",
    "arch - type models , proposed by @xcite , constitute one of the main classes of econometric models used for representing the dynamic evolution of volatilities .",
    "another popular one is the class of stochastic volatility ( sv ) models ( see , @xcite and references therein ) . in both cases , arch - type and sv models ,",
    "the stochastic process @xmath6 can be written as @xmath7 where @xmath8 is a sequence of independent identically distributed ( i.i.d . )",
    "random variables , with zero mean and variance equal to one , and @xmath9 , where @xmath10 denotes the sigma field generated by the past informations until time @xmath11 .",
    "an important difference between these two classes is that , for arch - type models , @xmath12 or @xmath13 , while for sv models @xmath14 , where @xmath15 is a sequence of latent variables , independent of @xmath8 .",
    "therefore , the volatility of a sv process is specified as a latent variable which is not directly observable and this can make the estimation challenging , which is a known drawback of this class of models .    by arch - type models we mean",
    "not only the arch@xmath16 model , proposed by @xcite , where @xmath17 ( which characterizes the volatility as a function of powers of past observed values , consequently , the volatility can be observed one - step ahead ) , but also the several generalizations that were lately proposed to properly model the dynamics of the volatility . among the generalizations of the arch model",
    "are the generalized arch ( garch ) processes , proposed by @xcite , and the exponential garch ( egarch ) processes , proposed by @xcite .",
    "these models are given , respectively , by and below by setting @xmath18 .",
    "the usual definition of @xmath19 for a garch(@xmath20 ) model , namely , @xmath21 is obtained from by letting @xmath22 and @xmath23 , where @xmath24 and @xmath25 .",
    "arch , garch and egarch are all short memory models . among the generalizations that capture the effects of long - memory characteristic in the conditional variance",
    "are the fractionally integrated garch ( figarch ) , proposed by @xcite , and the fractionally integrated egarch ( fiegarch ) , introduced by @xcite . for a figarch@xmath1 , @xmath19",
    "is given by @xmath26\\sigma_{t}^2 =   \\omega + \\bigg(1 -   \\sum_{j=1}^q \\beta_j\\mathcal{b}^k - \\bigg[1 -   \\sum_{k=1}^p\\phi_k\\mathcal{b}^k\\bigg](1-\\mathcal{b})^{d}\\bigg)x_t^2 ,   \\quad \\mbox{for all } t\\in \\mathds{z},\\ ] ] while for a fiegarch@xmath1 , @xmath19 is defined through the relation , @xmath27\\big)\\nonumber\\\\    & : =    \\omega+\\frac{\\alpha(\\mathcal{b})}{\\beta(\\mathcal{b})}(1-\\mathcal{b})^{-d}g(z_{t-1 } ) ,    \\quad \\mbox{for all } t\\in \\mathds{z},\\label{fiegarch}\\end{aligned}\\ ] ] where @xmath28 is the backward shift operator defined by @xmath29 , for all @xmath30 , and @xmath31 is the operator defined by its maclaurin series expansion as , @xmath32 with @xmath33 the gamma function .",
    "fiegarch models have not only the capability of modeling clusters of volatility ( as in the arch and garch models ) and capturing its asymmetry ( as in the egarch models ) but they also take into account the characteristic of long memory in the volatility ( as in the figarch models , with the advantage of been weakly stationary if @xmath34 ) . besides non - stationarity ( in the weak sense ) , another drawback of the figarch@xmath1 models is that we must have @xmath35 and the polynomial coefficients in its definition must satisfy some restrictions so the conditional variance will be positive .",
    "fiegarch@xmath1 models do not have this problem since the variance is defined in terms of the logarithm function .",
    "some authors argue that the long memory behavior observed in the sample autocorrelation and periodogram functions of financial time series could actually be caused by the non - stationarity property . according to @xcite",
    ", long range behavior could be just an artifact due to structural changes .",
    "on the other hand , @xcite also argue that , when modeling return series with large sample size , considering a single garch model is unfeasible and that the best alternative would be to update the parameter values along the time . as an alternative to the traditional heteroskedastic models , @xcite presents a regime switching model that , combined with heavy tailed distributions , presents the long memory characteristic .",
    "it is our belief that fiegarch models are a competitive alternative for modeling large sample sized data , especially because they avoid parameter updating .",
    "also , as we prove in this work , fiegarch processes are weakly stationary if and only if @xmath36 and hence , non - stationarity can be easily identified .",
    "moreover , @xcite analyze the daily returns of the tunisian stock market and rule out the random walk hypothesis . according to the authors",
    ", the rejection of this hypothesis seems to be due to substantial non - linear dependence and not to non - stationarity in the return series and , after comparing several arch - type models they concluded that a stationary fiegarch model provides the best fit for the data .",
    "furthermore , @xcite presents a sub period investigation of long memory and structural changes in volatility .",
    "the authors consider fiegarch models to examine the long run persistence of stock return volatility for 23 developing markets for the period of january 2000 to october 2007 .",
    "no clear evidence that long memory characteristic could be attributed to structural changes in volatility was found .",
    "although , in practice , often a simple fiegarch@xmath1 model with @xmath37 suffices to fully describe financial time series ( for instance , @xcite and @xcite , consider fiegarch@xmath38 models and @xcite considers fiegarch@xmath39 models ) , there are evidences that for some financial time series higher values of @xmath40 and @xmath41 are in fact necessary ( @xcite,@xcite,@xcite ) . in this work we present a theoretical study on the main properties of fiegarch@xmath1 processes , for any @xmath42 .",
    "one of the contributions of the paper is to extend , for any @xmath40 and @xmath41 , the results already known in the literature for @xmath43 or @xmath44 . in particular , we provide the expressions for the asymmetry and kurtosis measures of fiegarch@xmath1 process , for all @xmath45 .",
    "these results extends the one in @xcite where only the case @xmath46 and @xmath47 was considered and only the kurtosis measure was derived .    another contribution of this work is the arfima representation of @xmath2 , when @xmath6 is a fiegarch process , which is derived in the paper .",
    "this results is very useful in model identification and parameter estimation since the literature of arfima models is well developed ( see @xcite and references therein ) and , to the best of our knowledge , this result is absent in the literature .    to derive the properties of @xmath2",
    ", we first investigate the conditions for the existence of power series representation for @xmath48^{-1}(1-z)^{-d}$ ] and the behavior of the coefficients in this representation .",
    "this study is fundamental not only for simulation purposes but also to draw conclusions on the autocorrelation and spectral density functions decay of the non - observable process @xmath4 and the observable one @xmath2 .",
    "we also provide a recurrence formula to calculate the coefficients of the series expansion of @xmath49 , for any @xmath45 .",
    "this recurrence formula allows to easily simulate fiegarch processes .",
    "the fact that @xmath4 is an arfima@xmath50 process and the result that any fiegarch process is a martingale difference with respect to the natural filtration @xmath51 , where @xmath52 , are applied to obtain the @xmath5-step ahead forecast for the processes @xmath0 and @xmath53 .",
    "we also present the @xmath5-step ahead forecast for both @xmath4 and @xmath2 processes , with their respective mean square error forecast . to the best of our knowledge , formal proofs for these expressions",
    "are not given in the literature of fiegarch@xmath1 processes .",
    "we also present a simulation study including generation , estimation and forecasting features of fiegarch models . despite the fact that the quasi - likelihood is one of the most applied methods in non - linear process estimation , asymptotic results for fiegarch processes are still an open question ( see @xcite ) .",
    "therefore , we consider here a simulation study to investigate the finite sample performance of the estimator .",
    "since it is expected that , the better the fit , the better the forecasting , we also investigate the fitted models forecasting performance .",
    "the paper is organized as follows : section [ fiesection ] presents the formal definition of fiegarch process and its theoretical properties .",
    "we give a recurrence formula to obtain the coefficients in the power series expansion of the polynomial that describes the volatility and we show their asymptotic properties .",
    "the autocovariance and spectral density functions of the processes @xmath4 and @xmath2 are also presented and analyzed .",
    "the asymmetry and kurtosis measures of any stationary fiegarch process are also presented .",
    "section [ forecastingsection ] presents the theoretical results regarding the forecasting .",
    "section [ simulationsection ] presents a monte carlo simulation study including the generation of fiegarch time series , estimation of the model parameters and the forecasting based on the fitted model .",
    "section [ analysisobserved ] presents the analysis of an observed time series and the comparison of the forecasting performance for different arch - type and radial basis models .",
    "section [ conclusions ] concludes the paper .",
    "in this section we present the _ fractionally integrated exponential generalized autoregressive conditional heteroskedastic _ process ( fiegarch ) .",
    "this class of processes , introduced by @xcite , describes not only the volatility varying on time and the volatility clusters ( known as arch / garch effects ) but also the volatility long - range dependence and its asymmetry .    here , we present some results related to the existence , stationarity and ergodicity for these processes .",
    "we analyze the autocorrelation and the spectral density functions decay for both @xmath4 and @xmath2 processes .",
    "conditions for the existence of a series expansion for the polynomial that describes the volatility are given and a recurrence formula to calculate the coefficients of this expansion is presented .",
    "we also discuss the coefficients asymptotic behavior .",
    "we observe that if @xmath0 is a fiegarch@xmath1 process then @xmath4 is an arfima@xmath50 process and we prove that , under mild conditions , @xmath2 is an arfima@xmath3 process with correlated innovations .",
    "we present the expression for the kurtosis and the asymmetry measures for any stationary fiegarch@xmath1 process .    throughout the paper , given @xmath54 ,",
    "@xmath55 means that @xmath56 , for some @xmath57 , as @xmath58 ; @xmath59 means that @xmath60 , as @xmath58 ; @xmath61 means that @xmath62 , as @xmath58 .",
    "we also say that @xmath63 , as @xmath64 , if for any @xmath65 , there exists @xmath66 such that @xmath67 , for all @xmath68 .",
    "also , given any set @xmath69 , @xmath70 corresponds to the set @xmath71 and @xmath72 is the indicator function defined as @xmath73 , if @xmath74 , and 0 , otherwise .    from now on , let @xmath31 be the operator defined by its maclaurin series expansion as , @xmath75 where @xmath33 is the gamma function , @xmath28 is the backward shift operator defined by @xmath29 , for all @xmath30 , and the coefficients @xmath76 are such that @xmath77 and @xmath78 , for all @xmath79 .",
    "note that expression is valid only for non - integer values of @xmath80 .",
    "when @xmath81 , @xmath31 is merely the difference operator @xmath82 iterated @xmath80 times .",
    "also , one observe that , upon replacing @xmath80 by @xmath83 , the operator @xmath84 has the same binomial expansion as the polynomial given in , that is    @xmath85    where @xmath86 , for all @xmath87 .",
    "moreover , @xmath88 , as @xmath89 ( see @xcite ) .",
    "therefore , @xmath90 , as @xmath91 goes to infinity .",
    "suppose that @xmath92 is a sequence of independent and identically distributed ( i.i.d . )",
    "random variables , with zero mean and variance equal to one .",
    "let @xmath93 and @xmath94 be the polynomials of order @xmath40 and @xmath41 defined , respectively , by    @xmath95    with @xmath96 .",
    "we assume that @xmath97 , if @xmath98 , and that @xmath93 and @xmath94 have no common roots .",
    "these conditions assure that the operator @xmath99 is well defined .",
    "[ definitionfie ] let @xmath0 be the stochastic process defined as @xmath100 where @xmath101 and @xmath102 is defined by @xmath103,\\quad \\mbox { for all }      t\\in\\mathds{z } , \\",
    "\\mbox { with } \\theta , \\gamma \\in \\mathds{r}.\\ ] ] then @xmath0 is a _ fractionally integrated _ egarch _ process _ , denoted by fiegarch@xmath1 .",
    "figure [ fiegsim ] presents samples from fiegarch@xmath38 processes , with @xmath104 observations , considering two different underlying distributions .",
    "to obtain these samples we consider definition [ definitionfie ] and two different distributions for @xmath105 .",
    "for this simulation we set @xmath106 , @xmath107 , @xmath108 , @xmath109 and @xmath110 .",
    "these are the parameter values of the fiegarch model fitted to the bovespa index log - returns in section [ analysisobserved ] .",
    "figures [ fiegsim ] ( a ) - ( c ) consider @xmath111 and show , respectively , the time series @xmath112 , the conditional variance @xmath113 and the logarithm of the conditional variance @xmath114 .",
    "figures [ fiegsim ] ( d ) - ( e ) show the same time series as in figures [ fiegsim ] ( a ) - ( c ) when the distribution for @xmath105 is the generalized error distribution ( ged ) , with tail - thickness parameter @xmath115 .",
    "note that , in definition [ definitionfie ] , no conditions on the parameter @xmath80 are imposed .",
    "necessary and sufficient conditions on the parameter @xmath80 , to guarantee the existence of the stochastic process @xmath4 , satisfying , are discussed in the sequel .",
    "also notice that when @xmath44 , we obtain the well known egarch process .    for practical purpose ,",
    "it is important to observe that slightly different definitions of fiegarch processes are found in the literature .",
    "usually it is easy to show that , under certain conditions , the different definitions are equivalent to .",
    "for instance , @xcite defines the conditional variance of a fiegarch process through the equation @xmath116(1-\\mathcal{b})^d\\ln(\\sigma_t^2 ) = a + \\sum_{i=0}^{p}[\\psi_i|z_{t-1-i}|+\\gamma_i z_{t-1-i}].\\ ] ] this is the definition considered , for instance , in the software s - plus ( see @xcite ) and it is equivalent to whenever @xmath117 , @xmath118 $ ] , @xmath119 , @xmath120 , @xmath121 and @xmath122 for all @xmath123 .",
    "this equivalence is mentioned in @xcite and a detailed proof is provided in @xcite . in @xcite only the case @xmath46 and @xmath124 is considered and @xmath4 is defined as @xmath125 + \\gamma^ * z_{t-1 } , \\quad \\mbox{for all } t\\in\\mathds{z},\\ ] ] where @xmath8 is a gaussian white noise process with variance equal to one .",
    "this is the definition considered , for instance , in the g@rch package version 4.0 of @xcite .",
    "notice that , by setting @xmath126 , @xmath127 and @xmath128 , is equivalent to if and only if the equality @xmath129 holds .",
    "we observe that the theory presented here can be easily adapted to a more general framework than ( which uses the same notation as in @xcite ) by considering @xmath130 where @xmath131 and @xmath132 are real , nonstochastic , scalar sequences for which the process @xmath4 is well defined , @xmath133 is white noise process with variance not necessarily equal to one and @xmath102 is any measurable function . in particular , theorems [ n1 ] and [ n2 ] below , which are stated and proved in @xcite ,",
    "assume that @xmath134 is given by ( the notation was adapted to reflect the one used in this work ) , with @xmath8 and @xmath102 as in definition [ definitionfie ] .",
    "although is more general than , in practice the applicability of the model is somewhat limited given that the parameter estimation is far more complicated when compared to the model .",
    "notice that the function @xmath102 can be rewritten as @xmath135 this expression clearly shows the asymmetry in response to positive and negative returns . also , it is easy to see that @xmath102 is non - linear if @xmath136 and the asymmetry is due to the values of @xmath137 . while the parameter @xmath138 , also known in the literature as _ leverage parameter _ , shows the return s sign effect , the parameter @xmath139 denotes the return s magnitude effect . therefore , the model is able to capture the fact that a negative return usually results in higher volatility than a positive one .",
    "proposition [ prop1 ] below presents the properties of the stochastic process @xmath140 . although the proof is straightforward , these properties are extremely important to prove the results stated in the sequel .",
    "[ prop1 ] let @xmath92 be a sequence of i.i.d .",
    "random variables , with @xmath141 .",
    "let @xmath140 be defined by and assume that @xmath138 and @xmath139 are not both equal to zero .",
    "then @xmath140 is a strictly stationary and ergodic process . if @xmath142 , then @xmath140 is also weakly stationary with zero mean ( therefore a white noise process ) and variance @xmath143 given by @xmath144 ^ 2 + 2\\ , \\theta \\ ,",
    "\\gamma \\ , \\mathds{e}(z_0|z_0|).\\ ] ]    see @xcite .    theorem [ n1 ] below provides a criterion for stationarity and ergodicity of egarch ( fiegarch ) processes . as pointed out by @xcite ,",
    "the stationarity and ergodicity criterion in theorem [ n1 ] is exactly the same as for a general linear process with finite variance innovations .",
    "obviously , different definitions of @xmath49 in will lead to different conditions for the criterion in theorem [ n1 ] to hold . in @xcite",
    "it is stated that , in many applications , an arma process provides a parsimonious parametrization for @xmath145 . in this case , @xmath49 is defined as @xmath48^{-1}$ ] , @xmath146 , where @xmath93 and @xmath94 are the polynomials given in , leading to an egarch@xmath147 process . for this model ,",
    "the criterion in theorem [ n1 ] holds whenever the roots of @xmath94 are outside the closed disk @xmath148 .",
    "we shall later discuss the condition for the criterion in theorem [ n1 ] to hold when @xmath145 is defined by , leading to a fiegarch@xmath1 process .",
    "[ n1 ] define @xmath149 , @xmath6 and @xmath8 by @xmath150;\\label{neeq2 }    \\end{aligned}\\ ] ] where @xmath131 and @xmath151 are real , nonstochastic , scalar sequences , and assume that @xmath138 and @xmath139 do not both equal zero .",
    "then @xmath152 , @xmath153 and @xmath154 are strictly stationary and ergodic and @xmath155 is covariance stationary if and only if @xmath156 . if @xmath157 , then @xmath158 almost surely . if @xmath156 , then for @xmath159 , @xmath160 $ ] , and @xmath161 .",
    "see theorem 2.1 in @xcite .",
    "theorem [ n2 ] shows the existence of the @xmath162th moment for the random variables @xmath163 and @xmath19 , defined by - , when @xmath164 and the distribution of @xmath105 is the generalized error distribution ( ged ) .",
    "[ n2 ] define @xmath165 by - , and assume that @xmath138 and @xmath139 do not both equal zero .",
    "let @xmath8 be i.i.d .",
    "ged with mean zero , variance one , and tail - thickness parameter @xmath166 , and let @xmath167 .",
    "then @xmath152 and @xmath153 possess finite , time - invariant moments of arbitrary order .",
    "further , if @xmath168 , conditioning information at time 0 drops out of the forecast @xmath162th moments of @xmath169 and @xmath170 , as @xmath171 : @xmath172 = 0 \\quad \\mbox{and}\\\\      \\underset{t\\to\\infty}{\\mathrm{plim } } & \\big [ \\mathds{e}(e^{-r\\omega_t/2}|x_t|^{r}\\big|z_0,z_{-1},z_{-2 } , \\cdots ) - \\mathds{e}(e^{-r\\omega_t/2}|x_t|^{r})\\big ] = 0,\\\\    \\end{aligned}\\ ] ] where @xmath173 denotes the limit in probability .",
    "see theorem 2.2 in @xcite .    from now on , let @xmath49 be the polynomial defined by @xmath174 where @xmath93 and @xmath94 are defined in . since it is assumed that @xmath94 has no roots in the closed disk @xmath175 , and also @xmath93 and @xmath94 have no common roots , the function @xmath176 is analytic in the open disc @xmath177 ( if @xmath178 , in the closed disk @xmath179 ) .",
    "therefore , it has a unique power series representation and can be rewritten , equivalently , as @xmath180 notice that , with this definition we obtain a particular case of parametrization .",
    "theorem [ convorder ] below gives the convergence order of the coefficients @xmath181 , as @xmath91 goes to infinity .",
    "this theorem is important for two reasons .",
    "first , it provides an approximation for @xmath181 , as @xmath182 , and this result plays an important role when choosing the truncation point in the series representation for simulation purposes .",
    "second , and most important , the asymptotic representation provided in this theorem plays the key role to establish the necessary condition for square summability of @xmath183 .",
    "more specifically , from theorem [ convorder ] one concludes that @xmath184 if and only if @xmath34 and @xmath185 whenever @xmath186 .",
    "[ convorder ] let @xmath49 be the polynomial defined by .",
    "then , for all @xmath187 , the coefficients @xmath181 satisfy @xmath188 consequently , @xmath189 , as @xmath91 goes to infinity .",
    "denote @xmath190 by @xmath191 .",
    "since @xmath94 has no roots in the closed disk @xmath192 , one has @xmath193 from expressions , and it follows that @xmath194z^k.\\ ] ] from , one has @xmath195 in particular , @xmath196 .",
    "moreover , since @xmath197 , as @xmath198 , it follows that for all @xmath199 , there exists @xmath200 , such that , for a given @xmath201 and for all @xmath202 , @xmath203 for all @xmath204 and @xmath205 .",
    "hence , for @xmath91 sufficiently large , @xmath206 notice that , since @xmath88 , as @xmath207 , one can choose @xmath208 such that @xmath209 , for all @xmath210 and @xmath211 .",
    "consequently , @xmath212 however , @xmath213 and @xmath88 , as @xmath214 .",
    "so , we have @xmath215 it follows that @xmath216 and @xmath217 , as @xmath218 .",
    "hence , @xmath189 , as @xmath219 , which concludes the proof .",
    "proposition [ coefficientsfiegarch ] presents a recurrence formula for calculating the coefficients @xmath181 , for all @xmath30 .",
    "this formula is used to generate the fiegarch time series in the simulation study presented in section [ simulationsection ] .",
    "[ coefficientsfiegarch ] let @xmath49 be the polynomial defined by .",
    "the coefficients @xmath181 , for all @xmath187 , are given by @xmath220 where the coefficients @xmath76 , for all @xmath30 , are given in and @xmath221    let @xmath49 be defined by .",
    "consequently , @xmath222 by defining @xmath223 as in expression , for all @xmath30 , and upon considering expression , observing that @xmath224 , the right hand side of expression can be rewritten as @xmath225\\sum_{k=0}^{\\infty}\\lambda_{d , k}z^k      =      \\sum_{k=0}^{\\infty}\\bigg[\\sum_{i=0}^{k}\\lambda_{d , i}\\bigg(-\\sum_{j=0}^{k - i}\\beta_{j}^*\\delta_{d , k - i - j}\\bigg)\\bigg]z^k\\nonumber\\\\      & = \\sum_{k=0}^{\\infty}\\bigg[\\lambda_{d , k}-\\sum_{i=0}^{k-1}\\lambda_{d , i}\\sum_{j=0}^{k - i}\\beta_{j}^*\\delta_{d , k - i - j}\\bigg]z^k .",
    "\\end{aligned}\\ ] ]    now , by setting @xmath226 as in expression , for all @xmath30 , from expression one concludes that the equality holds if and only if , @xmath227 therefore , expression holds .",
    "it is easy to see that by replacing the coefficients @xmath181 , given by , in the expression , for all @xmath228 , we get @xmath229 , which completes the proof .",
    "the applicability of theorem [ n1 ] to long memory models was briefly mentioned ( without going into details ) in @xcite .",
    "corollary [ strictstatfiegarch ] below is a direct application of theorem [ convorder ] and provides a simple condition for the criterion in theorem [ n1 ] to hold when @xmath145 is defined by , which leads to a long memory model whenever @xmath117 .",
    "[ strictstatfiegarch ] let @xmath0 be a _",
    "_ fiegarch__@xmath1 process , given in definition [ definitionfie ] . if @xmath36 , @xmath4 is stationary ( weakly and strictly ) , ergodic and the random variable @xmath134 is almost surely finite , for all @xmath230 .",
    "moreover , @xmath0 and @xmath149 are strictly stationary and ergodic processes .",
    "let @xmath183 be defined by and rewrite as .",
    "observe that , by theorem [ convorder ] , the condition @xmath36 implies that @xmath231 .",
    "therefore , the results follow from theorem [ n1 ] by taking @xmath232 , for all @xmath233 , and @xmath234 , for all @xmath235 .",
    "the square summability of @xmath183 implies that the process @xmath4 is stationary ( weakly and strictly ) , ergodic and the random variable @xmath134 is almost surely finite , for all @xmath230 ( see theorem [ n1 ] ) .",
    "now , since @xmath140 is a white noise ( proposition [ prop1 ] ) , it follows immediately that @xmath4 is an arfima@xmath50 process ( for details on arfima processes see , for instance , @xcite , @xcite ) .",
    "this result is very useful , not only for forecasting purposes ( see section [ forecastingsection ] ) but also , to conclude the following properties    * if @xmath236 , the autocorrelation function of the process @xmath4 is such that @xmath237 where @xmath238 , and the spectral density function of the process @xmath4 is such that @xmath239 ^ 2\\!\\lambda^{-2d } , \\quad \\mbox{as }",
    "\\    \\lambda \\to 0,\\ ] ] where @xmath240 is given in ; * if @xmath241 and @xmath242 , for @xmath243 , the process @xmath4 is invertible , that is , @xmath244\\bigg|^{r}\\bigg ) = 0 , \\quad \\mbox{for all } \\quad 0 < r \\leq 2,\\ ] ] where @xmath245    the proof of * p1 * can be found in @xcite , theorem 13.2.2 . regarding * p2 * , in the literature one usually find that an arfima@xmath1 process is invertible for @xmath246 ( see , for instance , @xcite , theorem 13.2.2 ) .",
    "however , @xcite already proved that this range can be extended to @xmath247 , for an arfima@xmath248 and , more recently , @xcite show that this result actually holds for any arfima@xmath1 .",
    "corollary [ strictstatfiegarch ] shows that @xmath6 and @xmath249 are strictly stationary and ergodic processes .",
    "however , as mentioned in @xcite , this does not imply weakly stationarity when the random variable @xmath250 , for @xmath230 , is such that either its mean or its variance is not finite .",
    "theorem [ n2 ] considers the ged function and proves the existence of the moment of order @xmath251 , for the random variables @xmath163 and @xmath19 , for all @xmath230 , when the process @xmath4 is defined in terms of a square summable sequence of coefficients .",
    "corollary [ estacionar ] below applies the result of theorem [ convorder ] to state a simple condition so that theorem [ n2 ] holds for fiegarch@xmath1 processes .",
    "[ estacionar ] let @xmath0 be a _",
    "_ fiegarch__@xmath1 process , given in definition [ definitionfie ] .",
    "assume that @xmath138 and @xmath139 are not both equal to zero and that @xmath92 is a sequence of i.i.d .",
    "_ _ ged__@xmath252 random variables , with @xmath253 , zero mean and variance equal to one . if @xmath36 , then @xmath254 and @xmath255 , for all @xmath256 and @xmath251 .",
    "let @xmath183 be defined by and rewrite as .",
    "define @xmath232 , for all @xmath233 , and @xmath234 , for all @xmath257 .",
    "observe that , from theorem [ convorder ] , @xmath36 implies @xmath258 .",
    "therefore , the assumptions of theorem [ n2 ] hold and the results follow .    as a consequence of corollary [ estacionar ] , if @xmath36 and @xmath259 is a sequence of i.i.d .",
    "ged@xmath252 random variables , with @xmath253 , zero mean and variance equal to one , then @xmath260 ( consequently , @xmath261 ) and both , the asymmetry ( @xmath262 ) and kurtosis ( @xmath263 ) measures of @xmath264 exist .",
    "now , since @xmath265 , for all @xmath251 ( it follows from the independence of @xmath266 and @xmath250 ) , @xmath267 and @xmath268 , the measures @xmath262 and @xmath263 can be rewritten as @xmath269^{3/2}}=\\frac{\\mathds{e}(\\sigma_t^3)\\mathds{e}(z_t^3)}{\\big[\\mathds{e}(\\sigma_t^2)\\big]^{3/2 } } \\quad \\mbox{and } \\quad k_x : =    \\frac{\\mathds{e}(x_t^4)}{\\big[\\mathds{e}(x_t^2)\\big]^2}=\\frac{\\mathds{e}(\\sigma_t^4)\\mathds{e}(z_t^4)}{\\big[\\mathds{e}(\\sigma_t^2)\\big]^2 } ,    \\quad \\mbox{for all } t\\in\\mathds{z}.\\ ] ]    an expression for @xmath263 ( as a function of the fiegarch model parameters ) was already given in @xcite by assuming that @xmath8 is a gaussian white noise with variance equal to one , @xmath117 , @xmath46 , @xmath124 and by defining @xmath4 through expression . according , with that definition",
    ", it can be shown that @xmath263 can be written as @xmath270 ^ 2 } , \\quad \\mbox{with } \\left\\ { \\begin{array}{l }      g(z_{t } ) = \\theta z_{t } +   \\gamma[|z_{t}| - \\sqrt{2/\\pi } ] , \\quad t\\in\\mathds{z}\\\\      \\lambda_j = \\displaystyle\\sum_{i=0}^{j-1 }      \\frac{\\gamma(i+d)}{\\gamma(i+1)\\gamma(d)}\\beta^{j - i-1 } , \\quad j \\in      \\mathds{n}^ * \\mbox { and } d > 0 .",
    "\\end{array } \\right.\\ ] ] in proposition [ kurtosisasymmetry ] bellow we consider stationary fiegarch@xmath1 processes ( therefore , @xmath34 ) with @xmath4 defined by and show that a similar expression holds for any @xmath45 .",
    "we do not impose that @xmath8 is a gaussian white noise since corollary [ strictstatfiegarch ] shows that the asymmetry and kurtosis measures exist for a larger class of fiegarch models .",
    "[ kurtosisasymmetry ] let @xmath0 be a stationary _ _",
    "fiegarch__@xmath1 process , given in definition [ definitionfie ] . if @xmath271 , the asymmetry measure of @xmath272 is given by @xmath273^{3/2}}\\ ] ] and , if @xmath274 , the kurtosis measure of @xmath272 is given by @xmath275 ^ 2},\\ ] ] where @xmath181 are given in and @xmath102 is defined by .",
    "let @xmath0 be any stationary fiegarch@xmath1 process and @xmath49 be the polynomial defined by .",
    "notice that , since @xmath140 is a sequence of i.i.d .",
    "random variables , from it follows that @xmath276 from the fact that @xmath266 and @xmath250 are independent random variables one has @xmath277 thus , given @xmath278 , @xmath279 if and only if @xmath280 and @xmath281 are both finite . therefore , if @xmath271 ( analogously , @xmath274 ) , the asymmetry ( analogously , the kurtosis ) measure exists , and expression converges , for any @xmath282 ( analogously , @xmath283 ) .",
    "upon replacing in we conclude the proof .",
    "figure [ kurtosis ] shows the theoretical value of the kurtosis measure , as a function of the parameter @xmath80 , for any fiegarch@xmath38 process , with gaussian noise and parameters @xmath107 , @xmath108 , @xmath284 and ( a ) @xmath110 ( b ) @xmath285 .",
    "the parameter values considered in figure [ kurtosis ] ( a ) are the same ones ( except for @xmath80 ) considered in figure [ fiegsim ] ( a ) . for the specific model considered in figure [ fiegsim ] , @xmath106 and",
    "the theoretical value of the kurtosis measure is 5.6733 .",
    "the sample kurtosis value of the simulated time series presented in figure [ fiegsim ] ( a ) is 5.3197 , which is very close to the theoretical one .",
    "it is easy to see that , while in figure [ kurtosis ] ( a ) the kurtosis values increase exponentially as @xmath80 increases , in figure [ kurtosis ] ( b ) the kurtosis values decrease for @xmath286 and increase for @xmath287 .",
    "although @xmath4 is an arfima process , in practice it can not be directly observed and frequently , knowing its characteristics may not be sufficient for model identification and estimation purposes . on the other hand , @xmath0 is an observable process and so is @xmath2 . by noticing that , from , one can rewrite @xmath288 and",
    "now it is clear that the properties of @xmath4 are useful to characterize the process @xmath2 .",
    "this approach was already considered in the literature for parameter estimation purposes .",
    "for instance , @xcite and @xcite consider models such that @xmath163 can be written as in , but @xmath266 can have a more general definition than . while @xcite consider maximum likelihood and whittle s method of estimation in the class of exponential volatility models , especially the egarch ones ,",
    "@xcite consider different semiparametric estimators of the memory parameter in general signal plus noise models . in both cases , to obtain an estimator by whittle s method , the authors consider the spectral density function of @xmath2 .    in",
    "what follows , we focus our attention in the case where @xmath163 can be written as in , and @xmath266 is defined through the expression and we present some properties of the process @xmath2 . in particular , we show that , under mild conditions , this process also has an arfima representation . to the best of our knowledge",
    "no formal proofs of these results are given in the literature of fiegarch@xmath1 processes , especially the arfima@xmath3 representation of @xmath2 .",
    "[ arfimafieg ] let @xmath0 be a _",
    "_ fiegarch__@xmath1 process , given in definition [ definitionfie ] . if @xmath289 ^ 2)<\\infty$ ] and @xmath36 , then the process @xmath2 is well defined and it is stationary ( weakly and strictly ) and ergodic . moreover ,",
    "the autocovariance function of @xmath2 is given by @xmath290 where @xmath291 is given in and @xmath292 .",
    "assume that @xmath289 ^ 2 ) < \\infty$ ] and @xmath36 .",
    "let @xmath293 be given by and rewrite as .",
    "observe that @xmath289 ^ 2 ) < \\infty$ ] implies @xmath294 and thus @xmath295 is finite with probability one , for all @xmath233 .",
    "since @xmath36 , it follows that @xmath134 is finite with probability one , for all @xmath233 ( see corollary [ strictstatfiegarch ] ) .",
    "therefore , @xmath296 is finite with probability one , for all @xmath233 , and hence the stochastic process @xmath2 is well defined .",
    "the strict stationarity and ergodicity of @xmath2 follow immediately from the measurability of @xmath297 and the i.i.d .",
    "property of @xmath92 ( see @xcite ) . to prove that @xmath2 is also weakly stationary notice that @xmath289 ^ 2 ) < \\infty$ ] implies @xmath298 , @xmath299 implies @xmath300 ( see corollary [ strictstatfiegarch ] ) and the independence of @xmath301 implies that @xmath302 and @xmath134 are independent random variables . hence , @xmath303    to complete the proof it remains to show that the autocovariance function @xmath304 , for all @xmath305 , is given by expression . from the definition of @xmath296",
    ", it follows that @xmath306 theorem [ n1 ] shows that @xmath307 from the independence of the random variables @xmath308 , for all @xmath233 , and from expression , we have @xmath309 where @xmath310 . since @xmath311 , with @xmath312 , one concludes that @xmath313 by replacing these results on expression we conclude that the autocovariance function of @xmath2 is given by .",
    "figure [ covfie ] ( a ) presents the theoretical autocovariance function of the process @xmath2 , where @xmath272 is a fiegarch@xmath38 process , with the same parameter values considered in figures [ fiegsim ] and [ spectral ] .",
    "figure [ covfie ] ( b ) shows the sample autocovariance function of the time series @xmath314 , where @xmath315 is the simulated time series presented in figure [ fiegsim ] .",
    "figure [ covfie ] ( c ) presents the sample autocovariance function of the time series @xmath316 , where @xmath317 is the bovespa index log - returns time series ( see section [ analysisobserved ] ) . by comparing the three graphs in figure [ covfie ] ,",
    "one concludes that all three functions present a similar behavior . since the sample autocovariance function is an estimator of the theoretical autocovariance function , it is expected that their graphics will have the same behavior .",
    "the similarity between the decay in the graphs in figure [ covfie ] ( b ) and ( c ) indicates that a fiegarch model seems appropriate for fitting the bovespa index log - returns time series .",
    "[ example1 ] theorem [ arfimafieg ] provides the expression for the autocorrelation function of @xmath2 .",
    "the spectral density function of the process @xmath2 is given by ( see @xcite ) @xmath318,\\end{aligned}\\ ] ] where @xmath240 is given in , @xmath319 , @xmath320 is the real part of @xmath321 and @xmath322 . as an illustration , figure [ spectral ] ( a ) shows the spectral density function of the process @xmath2 , where @xmath323 is any fiegarch@xmath38 process with @xmath106 , @xmath324 , @xmath108 , @xmath109 and @xmath325 , assuming @xmath326 ( dashed line ) and @xmath327 ( continuous line ) .",
    "the corresponding values of @xmath291 , @xmath328 and @xmath329 , used in the computation of @xmath330 , are given in table [ values ] .",
    "figure [ spectral ] ( b ) shows the periodogram function of the time series @xmath314 , where @xmath315 is the simulated time series presented in figure [ fiegsim ] ( a ) , with @xmath331 .",
    "figure [ spectral ] ( c ) shows the periodogram function of the time series @xmath332 , where @xmath333 is the bovespa index log - returns time series .",
    "figure [ spectral ] ( a ) indicates that the probability distribution of @xmath105 may not be evident from the periodogram function given the similarity between the graphs of @xmath330 . the small difference on the values of @xmath330 for @xmath331 and @xmath327 is explained by the fact that the values of @xmath291 , @xmath328 and @xmath334 are relatively close for @xmath331 and @xmath335 as shown in table [ values ] .",
    "moreover , one observes that the graphs in figure [ spectral ] ( b ) and ( c ) present similar behavior , indicating that a fiegarch model may be adequate to fit the data . on the other hand , figure [ spectral ] ( a ) shows evidence that the underlying probability distribution of @xmath333 may not be the same as @xmath336 .",
    "in fact , we apply the two - sample kolmogorov - smirnov test to verify the hypothesis that @xmath337 and @xmath338 have the same probability distribution .",
    "we also apply the test to the standardized versions of @xmath337 and @xmath338 ( that is , we subtracted the sample mean and divided by the sample standard deviation ) .",
    "in the first case the test rejects the null hypothesis ( @xmath339 , test statistic = 0.2208 , @xmath340 ) . in the second case ( standardized version )",
    "the test did not reject the null hypothesis ( @xmath339 , test statistic = 0.0285 , @xmath341 ) .    to further investigate whether the correct probability distribution of @xmath105 can be identified through the periodogram function we consider the same time series @xmath315 as in figure [ spectral ] ( b ) and perform the kolmogorov - smirnov hypothesis test as described in @xcite ,",
    "pages 339 - 342 , considering both cases @xmath342 and @xmath343 .",
    "recall that    * the null hypothesis of the test is that @xmath296 has spectral density function @xmath330 ; * the testing procedure consists on ploting the kolmogorov - smirnov boundaries @xmath344 and the function @xmath345 defined as @xmath346 with @xmath347 , @xmath348 and @xmath349\\bigg [    \\sum_{k=1}^m\\frac{i_{\\ln(\\mbox{\\tiny$x$}_t^2)}(\\omega_k)}{f_{\\ln(\\mbox{\\tiny$x$}_t^2)}(\\omega_k)}\\bigg]^{-1}\\!\\!\\!\\!\\!\\!\\ ! , \\quad",
    "\\quad \\mbox{with } \\quad \\omega_k = \\frac{2k\\pi}{n } , \\,\\ , k\\in\\{1,\\cdots , m\\},\\ ] ] where @xmath350 is the integer part of @xmath351 and @xmath352 is the time series sample size ; * the null hypothesis is rejected if @xmath353 exits the boundaries for some @xmath354 .",
    "the results of the tests are given in figure [ cpgram ] , where @xmath355 and @xmath356 denote the values of @xmath353 obtained , respectively , when assuming @xmath331 and @xmath327 . from figures [ cpgram ] ( a ) and ( b )",
    "one concludes that the kolmogorov - smirnov test does not reject the null hypothesis in both cases .",
    "this result was expected given the small difference between the values of @xmath330 , shown in figure [ spectral ] ( a ) . in fact , by comparing figures [ cpgram ] ( a ) and ( b ) , one observes no visible difference between those graphs .",
    "figure [ cpgram ] ( c ) confirms that the difference is too small to be noticed since @xmath357 , for all @xmath358 .",
    "this shows that , for the fiegarch process considered in example [ example1 ] , the correct probability distribution of @xmath105 can not be identified through the periodogram function , given that the kolmogorov - smirnov hypothesis test failed to reject the null hypothesis when it was false .    to conclude this section we present the following theorem which shows that , under mild conditions , @xmath2 is an arfima@xmath3 process with correlated innovations .",
    "this results is very useful in model identification and parameter estimation since the literature of arfima models is well developed ( see @xcite and references therein ) .",
    "let @xmath0 be a _ _ fiegarch__@xmath1 process , given in definition [ definitionfie ] .",
    "suppose @xmath359 and @xmath289 ^ 2)<\\infty$ ] .",
    "then @xmath2 is an _ _",
    "arfima__@xmath3 process given by @xmath360 where @xmath361 is a stochastic process with zero mean and autocovariance function @xmath362 given by @xmath363 with @xmath364 defined by @xmath365 @xmath291 given in , @xmath366 , @xmath367 given in and @xmath368 .",
    "let @xmath0 be a fiegarch process . from expressions",
    "and we have @xmath369 where @xmath370 in particular , if @xmath371 , we have @xmath372 and @xmath373 , for all @xmath233 .    now",
    ", suppose that @xmath289 ^ 2)<\\infty$ ] . since @xmath301 is a sequence of i.i.d .",
    "random variables and @xmath374 ^ 2)]^{1/2}$ ] , one concludes that @xmath375 , for all @xmath233 . therefore , @xmath376 and @xmath377 .",
    "consequently , @xmath378 , for all @xmath233 .",
    "let @xmath379 be defined by expression .",
    "assume , for the moment , that @xmath380 , for all @xmath233 .",
    "it follows that @xmath381 since @xmath140 is a white noise process we have @xmath382 which does not depend on @xmath233 . from the independence of the random variables",
    "@xmath250 , for all @xmath230 , one has @xmath383 and @xmath384 where @xmath385 does not depend on @xmath233 .",
    "also , from the independence of the random variables @xmath386 , for all @xmath233 , we have @xmath387 which does not depend on @xmath233 .",
    "therefore , all four terms in expression do not depend on @xmath233 and expression holds . now , to validate expression we only need to show that @xmath388 , for all @xmath233 . notice that , since @xmath389 , it follows that @xmath390 . upon replacing @xmath391 in one obtains @xmath392 by hypothesis , @xmath289 ^ 2)<\\infty$ ] and @xmath393 .",
    "it follows that @xmath394 and @xmath395 .",
    "we also know that @xmath396 . in order to show that @xmath397 , notice that @xmath398 and , since @xmath399 and @xmath394 , from hlder s inequality , we have @xmath141 and @xmath400 . then from it follows that @xmath401 where @xmath402 . by using the fact that @xmath403 , for all @xmath404",
    ", one concludes that @xmath405<\\infty    \\ \\mbox { and } \\",
    "\\big|\\mathds{e}(|z_t|\\ln(z_t^2))\\big| \\leq    \\frac{1}{2}\\left[\\mathds{e}(z_t^2 ) +    \\mathds{e}(\\ln(z_t^2))\\right]<\\infty.\\ ] ] hence @xmath406 and , consequently , @xmath407 and @xmath408 .",
    "therefore , the result follows .",
    "let @xmath0 be a fiegarch@xmath1 process , given in definition [ definitionfie ] , and @xmath112 a time series obtained from this process . in this section , we prove that @xmath0 is a martingale difference with respect to the filtration @xmath51 , where @xmath13 , and we provide the @xmath5-step ahead forecast for the process @xmath0 .",
    "since the process @xmath4 , defined by , has an arfima@xmath50 representation , the @xmath5-step ahead forecasting for this process and its mean square error value can be easily obtained ( for instance , see @xcite and @xcite ) .",
    "this fact is used to provide an @xmath5-step ahead forecast for @xmath2 and the mean square error of forecasting .",
    "we also consider the fact that @xmath409 , for all @xmath233 , to provide an @xmath5-step ahead forecast for both processes , @xmath410 and @xmath411 , based on the predictions obtained from the process @xmath4 .",
    "the notation used in this section is introduced below .",
    "let @xmath412 , for @xmath233 , denote any random variable defined here . in the sequel we consider the following notation :    * we use the symbol `` ^ '' to denote the @xmath5-ahead step forecast defined in terms of the conditional expectation , that is , @xmath413 .",
    "notice that this is the best linear predictor in terms of mean square error value .",
    "the symbols `` ~ '' and `` v '' are used to denote alternative estimators ( e.g. @xmath414 and @xmath415 ) ; * for simplicity of notation , for the @xmath5-step ahead forecast of @xmath416 , we write @xmath417 instead of @xmath418 ( analogously for `` ~ '' and `` v '' ) ; * we follow the approach usually considered in the literature and denote the @xmath5-ahead step forecast @xmath419 as @xmath420 instead of @xmath421 . if necessary , to avoid confusion , we will denote the square of @xmath422 as @xmath423 ( analogously for `` ~ '' and `` v '' ) .",
    "the following lemma shows that a fiegarch@xmath1 process is a martingale difference with respect to @xmath51 .",
    "this result is useful in the proof of lemma [ predictors ] that presents the @xmath5-step ahead forecast of @xmath424 , for a fixed value of @xmath425 and all @xmath426 , and the @xmath427-step ahead forecast of @xmath428 , given @xmath429 .",
    "[ fiemd ] let @xmath0 be a _",
    "_ fiegarch__@xmath1 process , given in definition [ definitionfie ] and @xmath430 .",
    "then the process @xmath0 is a martingale difference with respect to @xmath51 .    from definition",
    ", @xmath266 is a @xmath10-measurable function .",
    "moreover , for all @xmath233 , @xmath431 and @xmath432 therefore , the process @xmath0 is a martingale difference with respect to @xmath433 .",
    "[ predictors ] let @xmath0 be a stationary _ _",
    "fiegarch__@xmath1 process , given by definition [ definitionfie ] .",
    "then , for any fixed @xmath425 , the @xmath5-step ahead forecast of @xmath424 , for all @xmath434 and the @xmath427-step ahead forecast of @xmath428 , given @xmath429 , are , respectively , @xmath435 and @xmath436 .    from lemma [ fiemd ] ,",
    "a fiegarch@xmath1 process is a martingale difference .",
    "it follows that @xmath437 , for all @xmath434 . from definition ,",
    "therefore , the @xmath427-step ahead forecast of @xmath428 , given @xmath429 , is @xmath439 .",
    "moreover , if @xmath440 , for all @xmath233 , then this is the best forecast value in mean square error sense .    to obtain the @xmath5-step ahead forecast for @xmath441 , notice that @xmath266 and @xmath250 are independent and so are @xmath19 and @xmath442 , for all @xmath233 .",
    "moreover , @xmath443 , for all @xmath434 .",
    "it follows that @xmath444 while for arch / garch models , @xmath445 can be easily calculated , for fiegarch processes , what is easy to derive is the expression for the @xmath5-step ahead forecast for the process @xmath4 , for any @xmath446 .",
    "the expressions for @xmath447 and for the mean square error of forecast are given in proposition [ hstepaheadx ] .",
    "we shall use this result to discuss the properties of the predictor obtained by considering @xmath448 , for all @xmath434 .",
    "[ hstepaheadx ] let @xmath0 be a _",
    "_ fiegarch__@xmath1 process , given by definition [ definitionfie ] .",
    "then the @xmath5-step ahead forecast @xmath449 of @xmath450 , given @xmath451 , @xmath452 , is given by @xmath453 moreover , the mean square error forecast is equal to zero , if @xmath454 , and it is given by @xmath455 ^ 2\\big )      = \\sigma^2_g\\sum_{k=0}^{h-2}\\lambda_{d , k}^2 , \\quad \\mbox{if } h \\geq 2,\\ ] ] where @xmath456 ^ 2)$ ] is given in .",
    "let @xmath457 .",
    "note that @xmath458 , for all @xmath459 , and @xmath460 , for all @xmath461 . by ,",
    "one has @xmath462 and expression follows .    since @xmath450 is a function of @xmath463 and @xmath140",
    "is a sequence of i.i.d .",
    "random variables with zero mean and variance @xmath464 ^ 2)$ ] , we conclude that @xmath465 ^ 2\\big)=    \\mathds{e}\\bigg(\\bigg[\\sum_{k=0}^{h-2}\\lambda_{d , k}\\,g(z_{n+h-1-k})\\bigg]^2\\bigg)=\\sigma^2_g\\sum_{k=0}^{h-2}\\lambda_{d , k}^2 ,    \\quad \\mbox{if } h \\geq 2,\\ ] ] and zero if @xmath466 .    in practice , @xmath445 can not be easily calculated for fiegarch models and thus , a common approach is to predict @xmath467 through the relation @xmath468 , with @xmath469 defined by , for all @xmath434 . as a consequence , a @xmath5-step ahead forecast for @xmath441",
    "is defined as @xmath470 and a naive estimator for @xmath471 is obtained by letting @xmath472 from expressions and , it is obvious that @xmath473 is a biased estimator for @xmath471 , whenever @xmath474 .",
    "proposition [ msfexsq ] gives the mean square error forecast for the @xmath5-step ahead forecast of @xmath471 , defined through expression .",
    "[ msfexsq ] let @xmath475 , for all @xmath434 , be the @xmath5-step ahead forecast of @xmath471 , given the filtration @xmath476 , defined by expression .",
    "then the mean square error forecast is given by @xmath477 ^ 2\\big ) =    \\sigma^2_g\\sum_{k=0}^{h-2}\\lambda_{d , k}^2 +    \\mathds{e}\\big(\\big[\\ln(z_{n+h}^2)\\big]^2\\big ) , \\quad \\mbox{where $ \\sigma^2_g      : = \\mathds{e}\\big([g(z_0)]^2\\big)$}.\\ ] ]    by expression , @xmath478 , for all @xmath434 .",
    "thus , from expression and from proposition [ hstepaheadx ] , we have @xmath479 ^ 2\\big )      & =      \\mathds{e}\\big(\\big[\\hspace{-1pt}\\ln(x_{n+h}^2)-\\ln(\\hat{\\sigma}_{n+h}^2)\\big]^2\\big)=      \\mathds{e}\\big(\\big[\\hspace{-1pt}\\ln(\\sigma_{n+h}^2)+\\ln(z_{n+h}^2)-\\ln(\\hat{\\sigma}_{n+h}^2)\\big]^2\\big)\\nonumber\\\\      & = \\mathds{e}\\bigg(\\bigg[\\sum_{k=0}^{h-2}\\lambda_{d , k}\\,g(z_{n+h-1-k})+\\ln(z_{n+h}^2)\\bigg]^2\\bigg).\\,\\label{exp3 }    \\end{aligned}\\ ] ] by expanding the right hand side of expression and using the fact that @xmath92 is a sequence of i.i.d . random variables , the proposition follows immediately .",
    "if the values of @xmath163 and @xmath266 are known only for @xmath480 then the @xmath5-step ahead forecast @xmath481 of @xmath450 , is approximated by @xmath482 and , by definition , the same approximation follows for @xmath483 .",
    "it is easy to see that , in this case , the mean square error of forecast values for the processes @xmath4 and @xmath2 are given , respectively , by @xmath484 ^ 2\\big )      & = \\sigma^2_g\\bigg(\\ , \\sum_{k=0}^{h-2}\\lambda_{d , k}^2\\      + \\hspace{-5pt}\\sum_{k = n+h-1}^{\\infty}\\hspace{-10pt}\\lambda_{d , k}^2\\bigg ) ,      \\quad      \\mbox { and}\\\\      \\quad \\displaystyle      \\mathds{e}\\big(\\big[\\ln(x_{n+h}^2)-\\check\\ln(x_{n+h}^2)\\big]^2\\big ) & =      \\sigma^2_g\\bigg(\\ , \\sum_{k=0}^{h-2}\\lambda_{d , k}^2\\      + \\hspace{-5pt}\\sum_{k = n+h-1}^{\\infty}\\hspace{-10pt}\\lambda_{d , k}^2\\bigg ) +      \\mathds{e}(\\left[\\ln(z_{n+h}^2)\\right]^2,\\quad \\mbox { for all } h>0 .",
    "\\end{aligned}\\ ] ]    from jensen s inequality , one concludes that @xmath485 so that @xmath486 , for all @xmath434 .",
    "in fact , from and , we have @xmath487    another @xmath5-step ahead predictor for @xmath467 can be defined as follows .",
    "consider an order 2 taylor s expansion of the exponential function and write @xmath488\\exp\\big{\\{}\\mathds{e}(\\ln(\\sigma_{n+h}^2)|\\mathcal{f}_{n})\\big{\\ } } \\nonumber\\\\    & \\ , + \\frac{1}{2}\\left[\\ln(\\sigma_{n+h}^2 ) -    \\mathds{e}(\\ln(\\sigma_{n+h}^2)|\\mathcal{f}_{n})\\right]^2\\exp\\big{\\{}\\mathds{e}(\\ln(\\sigma_{n+h}^2)|\\mathcal{f}_{n})\\big{\\ } }    + r_{n+h } , \\quad \\mbox { for all } h>0 , \\label{sigmataylor}\\end{aligned}\\ ] ] from expression , a natural choice is to define a @xmath5-step ahead predictor for @xmath467 as @xmath489 ^ 2)\\exp\\big{\\{}\\mathds{e}(\\ln(\\sigma_{n+h}^2)|\\mathcal{f}_{n})\\big{\\}},\\end{aligned}\\ ] ] for all @xmath434 .    from expressions , and",
    "one concludes that @xmath490 and @xmath491 are related through the equation @xmath492    since @xmath493 is a @xmath494-measurable random variable , for all @xmath233 , we have @xmath495 . from equation , we easily conclude that , for all @xmath496 , @xmath497 therefore , the relation between the bias for the estimators @xmath490 and @xmath491 is given by @xmath498    in section [ simulationsection ] we analyze the performance of @xmath499 through a monte carlo simulation study .",
    "in this section we present a monte carlo simulation study to analyze the performance of quasi - likelihood estimator and also the forecasting on fiegarch@xmath1 processes .",
    "six different models are considered and , from now on , they shall be referred to as model m@xmath500 , for @xmath501 . for all models",
    "we assume that the distribution of @xmath105 is the generalized error distribution ( ged ) with tail - thickness parameter @xmath502 ( since @xmath503 the tails are heavier than the gaussian distribution ) .",
    "the set of parameters considered in this study is the same as in @xcite and @xcite , except for models m5 and m6 ( see table [ simpar ] ) .",
    "while model m5 considers @xmath504 , which is close to the non - stationary region ( @xmath505 ) , model m6 considers @xmath506 and @xmath507 . for comparison",
    ", we shall consider for model m6 the same parameter values as in model m3 ( obviously , with the necessary adjustments regarding @xmath508 and @xmath509 ) .",
    "we also present here the @xmath5 step - ahead forecast , for @xmath510 , for the conditional variance of simulated fiegarch processes .      to generate samples from fiegarch@xmath1 processes we proceed as described in steps * dgp1 * - * dgp3 * below . notice that , while step 1 only needs to be repeated for each model , steps 2 and 3 must be repeated for each model and each replication .",
    "the parameters value consider in this simulation study are given in table [ simpar ] . for each model",
    "we consider @xmath511 replications , with sample size @xmath512 .",
    "* dgp1 : * apply the recurrence formula given in proposition [ coefficientsfiegarch ] , to obtain the coefficients of the polynomial @xmath513 , defined by . for",
    "this simulation study the infinite sum is truncated at @xmath514 . to select the truncation point @xmath350 we consider theorem [ convorder ] and the results presented in table [ lambdacoeffsim ] .    from theorem [ convorder ]",
    ", we have , @xmath515 and we conclude that @xmath516 and @xmath517 , as @xmath91 goes to infinity .",
    "however , the speed of the convergence varies from model to model , as we show in table [ lambdacoeffsim ] . for simplicity , in this table , let @xmath518 and @xmath519 be defined as @xmath520    table [ lambdacoeffsim ] presents the values of the coefficients @xmath181 , given in proposition [ coefficientsfiegarch ] , for @xmath521 100 ; 1,000 ; 5,000 ; 10,000 ; 20,000 ; 50,000 ; 100,000@xmath522 , for each simulated model m@xmath500 , @xmath523 . note that , for @xmath524 5,000 , the coefficient values decrease slowly .",
    "we also report in table [ lambdacoeffsim ] @xmath525 and @xmath526 values for the correspondent @xmath181 value .",
    "note that , for @xmath52710,000 ; 50,000 ; 100,000@xmath522 , the value @xmath525 is very close to zero , for all models . also notice that , while @xmath526 converges to 1 faster for model m1 than for the other models .    * dgp2 : * set @xmath528 , with @xmath115 , and obtain an i.i.d .",
    "sample @xmath529 .",
    "* dgp3 : * by considering definition [ definitionfie ] and the equality in , the sample @xmath530 is obtained through the relation @xmath531    for parameter estimation and forecasting we shall consider sub - samples from these time series , with size @xmath532 .",
    "the sub - samples of size @xmath104 correspond to the last 2,000 values of the generated time series ( after removing the last 50 values which are used only to compare the out - of - sample forecasting performance of the models ) .",
    "the value @xmath533 is the approximated size of the observed time series considered in @xcite .",
    "the value @xmath534 was chosen to analyze the estimators asymptotic properties .      in this study",
    "we consider the quasi - likelihood method to estimate the parameters of fiegarch models for the simulated time series .",
    "given any time series @xmath112 , this method assumes that @xmath535 , for all @xmath233 , is normally distributed .",
    "the vector of unknown parameters is denoted by @xmath536 and the estimator @xmath537 of @xmath538 is the value that maximizes @xmath539 , \\!.\\label{pseudolike}\\ ] ]    since the processes @xmath540 and @xmath541 are unknown , we need to consider a set @xmath542 of initial conditions in order to start the recursion and to obtain the random variable @xmath134 , for @xmath543 .",
    "then we use these estimated values to solve . for this simulation study we assume , as initial conditions , @xmath544 , @xmath545 and @xmath546 , whenever @xmath547 , where @xmath548 is the sample variance of @xmath112 .",
    "this is the initial set suggested by @xcite .",
    "the random variables @xmath134 , for @xmath549 , are then estimated upon considering the set @xmath542 of initial conditions and the known values @xmath112 .",
    "the infinite sum in the polynomial @xmath49 is truncated at @xmath550 , where @xmath352 is the available sample size .      for any model ,",
    "let @xmath551 denotes the estimate of @xmath552 in the @xmath91-th replication , where @xmath553 , @xmath511 and @xmath552 is any vector parameter given in table [ simpar ] . to access the performance of quasi - likelihood procedure we calculate the mean @xmath554 , the standard deviation ( @xmath555 ) , the bias ( @xmath556 ) , the mean absolute error ( @xmath557 ) and the mean square error ( @xmath558 ) values , defined by @xmath559 where @xmath560 , for @xmath553 .",
    "table [ resultssim ] summarizes the results on the parameter estimation procedure .",
    "figures [ figm1 ] - [ figm6 ] present the kernel distribution of the parameter estimators for each considered model when @xmath561 .",
    "these graphs help to illustrate the results presented in table [ resultssim ] .",
    "+     +     +    by observing figures [ figm1 ] - [ figm6 ] , it is easy to see that , for most estimates , the density function is approximately symmetric .",
    "for some parameters , we notice the presence of possible outliers , see for instance the graphs for the parameters @xmath80 ( in particular , models m2 , m3 and m4 ) , @xmath562 ( model m2 ) and @xmath563 ( in particular , models m1 and m2 ) , with @xmath564 and @xmath565 .",
    "although the graphs for @xmath533 and @xmath566 are similar , one observes that , as expected , the observations tend to concentrate closer to the mean when @xmath566 .    from table [ resultssim ]",
    "we conclude that , given the models complexity , the quasi - likelihood method performs relatively well .",
    "since model m2 presents more parameters than the other models , which implies a higher dimension maximization problem , one would expect that the quasi - likelihood method would present the worst performance in this case .",
    "however , in terms of @xmath557 or @xmath558 values , the estimation results for model m2 ( @xmath567 , @xmath568 and @xmath569 ) , m3 ( @xmath567 , @xmath570 and @xmath124 ) , m4 ( @xmath571 , @xmath106 and @xmath124 ) and m6 ( @xmath572 , @xmath570 and @xmath573 ) are similar ( except for the parameter @xmath80 in model m6 ) and the quasi - likelihood method performs better for model m2 ( except for the parameter @xmath80 ) than for models m1 ( @xmath574 , @xmath575 and @xmath124 ) and m5 ( @xmath572 , @xmath504 and @xmath124 ) .",
    "table [ resultssim ] also indicates that the quasi - likelihood procedure may perform better for @xmath46 and @xmath576 than for @xmath577 and @xmath507 ( we shall investigate this in a future work ) .",
    "this conclusion is based on the fact that models m3 and m6 have the same parameter values ( with the necessary adjustments in @xmath508 and @xmath509 ) and all parameters , except @xmath578 , were better estimated in model m3 than m6 .    by comparing the @xmath557 and @xmath558 values , given in table [ resultssim ] ,",
    "we conclude that the worst performance occurs for models m1 and m5 ( in particular , see the estimation results for @xmath578 , @xmath562 and @xmath563 , @xmath579 and @xmath580 ) .",
    "this outcome is explained by the fact that the parameter @xmath80 is very close to the non - stationary region for model m5 and , for model m1 , not only @xmath581 but also @xmath575 , which implies a more complex model with stronger long - range dependence .",
    "the small @xmath556 values indicate that , for all parameters , the mean estimated value is very close to the true value .",
    "although for @xmath582 the standard deviation of several estimates is high if compared with the mean estimated value , as expected , the estimators performance improves as the sample size increases .      to obtain the predicted values , for each replication of model m@xmath500 , with @xmath583 , and each sub - sample @xmath530 , with @xmath584 , we repeat steps * f1 * - * f5 * below .",
    "* f1 : * replace the true parameters values @xmath585 by the estimated ones , namely , @xmath586 , and use the recurrence formula given in proposition [ coefficientsfiegarch ] to calculate the corresponding coefficients @xmath587 .",
    "* f2 : * obtain the time series @xmath588 ( which corresponds to the residuals of the fitted model ) and @xmath589 . to do so ,",
    "let @xmath590 , whenever @xmath591 , and calculate @xmath266 and @xmath592 recursively as follows : @xmath593\\bigg\\ }   \\quad \\mbox { and   } \\quad   z_t = \\frac{x_t}{\\sigma_t},\\ ] ] for all @xmath594 .",
    "* f3 : * in expression , replace @xmath595 and @xmath596 by their respective sample estimates , and obtain an estimate @xmath597 for @xmath291 given by @xmath598 ^ 2 + 2 \\ , \\hat\\theta\\,\\hat\\gamma \\left[\\frac{1}{n}\\sum_{t=1}^nz_t|z_t|\\right].\\ ] ]    * f4 : * by considering expressions and , obtain the predicted values @xmath599 , @xmath600 where @xmath601 \\bigg\\ } , \\quad \\mbox{for all } \\ ,   h>0,\\ ] ] with @xmath602 .",
    "* f5 : * based on the fact that @xmath603 , set @xmath604 , for all @xmath434 .      in what follows",
    "we discuss the simulation results related to forecasting based on the fitted fiegarch models . to access the models forecast performance , during the generating process",
    ", we create 50 extra values for each simulated time series .",
    "those values are used here to compare with the @xmath5-step ahead forecast , for @xmath510 .",
    "table [ forecasting ] presents the mean over @xmath605 simulated values of @xmath606 and @xmath607 obtained from model m@xmath500 , for each @xmath608 , and the corresponding @xmath5-step ahead predicted values @xmath609 , for @xmath610 , forecasting origin @xmath611 and sub - samples @xmath612 .",
    "this table also reports the mean square error ( @xmath558 ) of forecast , defined as @xmath613 where @xmath511 is the number of replications , @xmath614 denotes the true value of @xmath606 ( or @xmath607 ) and @xmath615 is the predicted value obtained in the @xmath91-th replication , for @xmath616 , based on the model fitted to the sub - sample with size @xmath352 .",
    "notice that , due to the small magnitude of the sample means , all values in table [ forecasting ] are multiplied by 100 .    from table [ forecasting ]",
    "( see also figure [ figforecast ] below ) conclude that ,    * when we consider @xmath606 , the predicted values are relatively close to the simulated ones , which is indicated by the small @xmath558 values , for all models and any @xmath617 ; * the @xmath558 value increases as @xmath5 increases .",
    "this result is expected and it is theoretically explained in proposition [ hstepaheadx ] which shows that @xmath465 ^ 2\\big )      = \\sigma^2_g\\sum_{k=0}^{h-2}\\lambda_{d , k}^2 \\overset{h \\to        \\infty}{\\longrightarrow } \\sigma^2_g\\sum_{k=0}^{\\infty}\\lambda_{d , k}^2,\\ ] ] where @xmath456 ^ 2)$ ] is given in ; * when we consider @xmath607 , the @xmath558 is usually high , if compared to the mean simulated and mean predicted values .",
    "therefore , we conclude that @xmath618 is a poor estimator for @xmath441 .",
    "this result is not a surprise since the main purpose of fiegarch models is to estimate the logarithm of the conditinal variance of the process and not the process itself ; * as expected , in all cases , the models forecasting performance improves as @xmath352 increases .",
    "notice , however , that the difference in the @xmath558 values , from @xmath533 to @xmath566 , is small ( recall that the values are multiplied by 100 ) .",
    "this is so because the coefficients @xmath181 converges to zero , as @xmath91 goes to infinity .",
    "therefore , it is expected that , for some @xmath619 and any @xmath620 , using the last @xmath350 or the last @xmath621 known values to calculate the @xmath5-step ahead forecast value for the process will not considerably change the results .",
    "figure [ figforecast ] shows the mean taken over 1,000 replications for :    * the simulated values @xmath606 and @xmath607 obtained from model m@xmath500 , for each @xmath622 , @xmath611 and @xmath623 ; * the one - step ahead forecast values @xmath624 ( denoted in the graphs by @xmath625 ) , for @xmath626 , @xmath627 and @xmath623 .",
    "the predictor @xmath628 is obtained directly from the sub - sample @xmath112 , by following steps * f1 * -*f5 * ( this figure only reports the graphs for the case @xmath566 ) .",
    "the remaining predicted values @xmath629 are calculated by updating the forecasting origin from @xmath611 to @xmath630 , that is , by introducing the observations @xmath631 , one at a time , and following steps * f2 * -*f5 * ; * the @xmath5-step ahead forecast values considering the predictors @xmath632 and @xmath633 ( denoted in the graphs by @xmath634 ) .",
    "these values are obtained by following steps * f1 * -*f5 * with forecasting origin @xmath611 ( without update ) .",
    "for all graphs the size of the sub - sample used for parameter estimation and forecasting is @xmath635 .",
    "the dashed lines in figure [ figforecast ] correspond to the limiting constants @xmath636 and @xmath637 , for @xmath622 , described in the sequel .",
    "+    from figure [ figforecast ] we observe that , for all models , the means for the one - step ahead forecast values @xmath638 , show the same behavior over the time as the means for the true values @xmath639 , where @xmath640 , @xmath611 and @xmath641 .",
    "as expected , due to the error carried from the parameter estimation ( specially , from the distribution misspecification ) , we observe a small forecasting bias , which decreases as @xmath5 increases .",
    "the decrease in the forecasting bias , as the forecasting origin is updated , can be attributed to the fact that we start the recurrence formula ( step * f2 * ) assuming @xmath642 and as the new observations @xmath643 are introduced , the constant @xmath644 is replaced by its sample estimate ( step * f3 * ) , which provides more accurate values for @xmath645 as @xmath646 increases ( @xmath647 ) .",
    "regarding the @xmath5-step ahead predictors @xmath648 and @xmath649 , figure [ figforecast ] shows that the estimation bias is higher if we consider the former one .",
    "this figure also shows that , for all models , the predicted value converges to a constant as @xmath5 increases .",
    "this is expected since the @xmath5-step ahead predictor is defined in terms of the conditional expectation .",
    "in fact , from expression , @xmath650 converges to @xmath651 as @xmath5 goes to infinity , where @xmath652 denotes the parameter @xmath578 for model m@xmath500 and hence , from expression , @xmath653 for each @xmath523 and @xmath350 sufficiently large .",
    "the values of @xmath652 ( also given in table [ simpar ] ) , @xmath636 and @xmath637 , for @xmath654 and @xmath523 , are presented in table [ values2 ] .",
    "upon comparing the values of @xmath636 and @xmath637 , given in table [ values2 ] ( also reported in figure [ figforecast ] as @xmath655 and @xmath656 ) , for each @xmath657 , respectively , with the limits @xmath658 and @xmath659 ( see figure [ figforecast ] ) , we conclude that these values are close to each other , for all models . a small difference between @xmath636 and @xmath660 ( respectively , @xmath637 and @xmath661 ) is expected since the former one is calculated using the true parameter values while @xmath650 is obtained by considering the estimates for the parameter .",
    "this section presents the analysis of the so paulo stock exchange index ( bovespa index or ibovespa ) log - return time series .",
    "we consider the fiegarch model , fully described in this paper , and we compare its forecasting performance with other arch - type models . the total number of observations for the ibovespa time series is @xmath662 .",
    "we consider the first 1717 observations to fit the models and we reserve the last 20 ones to compare with the out - of - sample forecast .",
    "figure [ figibov1 ] ( a ) presents ibovespa time series @xmath663 , in the period of january/1995 to december/2001 .",
    "we observe a strong decay in the index value close to @xmath664 ( that is , january 15 , 1999 ) .",
    "this period is characterized by the real ( the brazilian currency ) devaluation .",
    "figures [ figibov1 ] ( b ) and ( c ) present , respectively , the ibovespa log - return time series , @xmath333 , and the square of the log - return time series , @xmath665 , in the same period .",
    "observe that the log - return series presents the stylized facts of financial time series such as apparent stationarity , mean around zero and clusters of volatility .",
    "also , in figure [ figibov2 ] we observe that , while the log - return series presents almost no correlation , the sample autocorrelation of the square of the log - return series assumes high values for several lags , pointing to the existence of heteroskedasticity and possibly long memory .",
    "notice that the periodogram of @xmath332 , presented in figure [ spectral ] ( c ) , also indicates possibly long - memory in the conditional variance . regarding the histogram and the qq - plot",
    ", we observe that the distribution of the log - return series seems approximately symmetric and leptokurtic .    to investigate whether the stationarity property holds for the time series",
    "@xmath333 we apply the runs test ( or wald - wolfwitz test ) , as described in @xcite . due to the magnitude of the data we multiply the time series values by 100 before applying the test .",
    "the p - values for the test considering the moments of order the values of @xmath666 are too close to zero and the test always returns the same p - value as @xmath667 .",
    "] @xmath668 are reported in figure [ grtest ] . for comparison ,",
    "this figure also shows the p - values of the test applied to the simulated time series presented in figure [ fiegsim ] .",
    "notice that , for all @xmath668 the test does not reject the null hypothesis of stationarity .    .",
    "the dashed line corresponds to p - value = 0.05.,scaledwidth=50.0% ]    to analyze if the ergodicity property holds for the time series @xmath333 we perform the test described in @xcite . for comparison",
    ", we also apply this test to the simulated time series ( only for sample size @xmath533 ) considered in section [ simulationsection ] .",
    "the test results are given in table [ ergodicitytest ] .",
    "the reported values are the proportion of p - values smaller than 0.05 and 0.10 in a total of 100 repetitions of step 3 of the algorithm 1 given in @xcite .",
    "moreover , for the simulated time series , the values in table [ ergodicitytest ] correspond to the mean taken over 1,000 replications .",
    "notice that the proportion of p - values smaller than 0.05 ( equivalently , 0.10 ) is always higher for the simulated time series ( known to be ergodic ) then for the observed time series . given that the proportion of p - values smaller than 0.05 and 0.10 is close to the expected , we conclude that the ergodicity property holds for @xmath333 .",
    "the analysis of the sample autocorrelation function suggests an arma@xmath669-fiegarch@xmath670 model . while an arma model accounts for the correlation among the log - returns , a fiegarch model take into account the long memory ( in the conditional variance ) and the heteroskedasticity characteristics of the time series . to select the best arma@xmath669-fiegarch@xmath670 model for the data we initially considered all possible models with @xmath671 and @xmath672 and applied the quasi - likelihood method to estimate the unknown parameters .",
    "then we eliminate the models with correlated residuals and selected the best models , with respect to the log - likelihood , bayesian ( bic ) , akaike ( aic ) and hannan - quinn ( hqc ) information criteria ( in this step three models were selected ) .",
    "the models order and the corresponding aic , bic and hqc values are reported in table [ aic ] .",
    "boldface indicates that the model was the best with respect to the corresponding the criterion .",
    "as shown in table [ aic ] , the values of the selection criteria did not vary much amongst the tested models so we choose the most parsimonious one , namely , arma(0,1)-fiegarch@xmath38 . we compare the forecasting performance of this model with other arch - type models and with a radial basis function model . for this comparison",
    "the order of the arma@xmath669 part of the model was not changed , that is , we fixed @xmath673 and @xmath674 for all arch - type models .",
    "the egarch@xmath675 model was set to have the same values for @xmath676 and @xmath677 as the fiegarch model so we could investigate the influence of the long memory parameter @xmath80 . for the garch(@xmath678 ) model we choose the smallest values of @xmath676 and @xmath677 for which the residuals of the model are not correlated .",
    "the same was done for the arch@xmath679 model ( which resulted in @xmath680 ) .",
    "the arch(1 ) model was presented only for comparison .",
    "the estimated coefficients for the arch - type models are given in table [ allmodels ] , with the corresponding log - likelihood value .",
    "notice that , the fiegarch model fitted to this time series present the same parameters values as model m4 considered in the simulated study in section [ simulationsection ] .    to fit a radial basis model to the data ( no exogenous variables are considered ) we assume that @xmath681 can be written as",
    "( see @xcite , @xcite ) @xmath682 with @xmath683 , for some @xmath577 , @xmath684 , @xmath685 and @xmath268 . under these assumptions , @xmath686 and @xmath687 , for all @xmath233 .",
    "therefore , we use neural networks @xmath688 and @xmath689 to approximate , respectively , @xmath690 and @xmath691 , and obtain @xmath692 where @xmath693 ^ 2\\bigg\\ } \\quad \\mbox{\\normalsize and } \\quad   \\boldsymbol{\\hat w}_2 = \\mbox{arg min}\\bigg\\{\\frac{1}{n - p}\\sum_{t = p+1}^n\\big[\\hat\\varepsilon_t^2 - \\psi_{n}(\\boldsymbol{y}_{t-1 } ; \\boldsymbol{w})\\big]^2\\bigg\\},\\]]with @xmath694 , for all @xmath695 . in both cases ,",
    "we consider one hidden layer containing @xmath696 neurons , for some @xmath697 , that is , @xmath698 with @xmath699 , @xmath700 , @xmath701 , @xmath702 , @xmath703 the euclidean norm , @xmath704 and @xmath705 , for any @xmath706 and @xmath707 .    to obtain a @xmath5-step ahead predictor for @xmath708 given @xmath317 , we observe that , for all @xmath233 , @xmath709 therefore , @xmath710 , for some @xmath711 . thus ,",
    "once @xmath379 and @xmath712 are estimated , the predictors @xmath713 and @xmath714 can be obtained recursively as @xmath715 where @xmath716 , with @xmath717 , whenever @xmath718 .",
    "tables [ allmodelsmae ] and [ allmodelsmae2 ] present some statistics to access the out - of - sample forecasting performance , respectively , of arch - type and radial basis models .",
    "the values in these tables correspond to the mean absolute error ( @xmath557 ) , the mean percentage error ( @xmath719 ) and the maximum absolute error ( @xmath720 ) of forecast , respectively defined as @xmath721 where , @xmath722 , for @xmath723 and @xmath724 , is the @xmath5-step ahead forecast error .",
    "note that , when considering the arma combined with arch - type models , from the arma(0,1 ) part of the models , @xmath725 , where @xmath726 , for all @xmath233 . since we define",
    "@xmath727 and @xmath19 is @xmath10-measurable , for all @xmath233 , by elementary calculations we conclude that , @xmath728 and @xmath729 , for all @xmath446 , with @xmath730 . for egarch and fiegarch models , @xmath731 is replaced by @xmath732 , given in expression , and @xmath733 , where @xmath449 is defined in proposition [ hstepaheadx ] .    from table [ allmodelsmae ]",
    "we conclude that , given its high @xmath719 value , the arma(0,1)-arch(1 ) does not fit the data well . in fact , the square of the residuals from this model are still correlated and we use the model only for comparison .",
    "the arma(0,1)-arch(6 ) model performed similar to the arma(0,1)-garch(1,1 ) model , in terms of both , @xmath557 and @xmath720 values , presenting a higher @xmath719 value .",
    "however , the latter is more parsimonious .",
    "although the log - likelihood value is higher ( and the @xmath720 value is smaller ) for the arma(0,1)-egarch(0,1 ) model , the @xmath557 and the @xmath719 values are smaller for the arma(0,1)-garch(0,d,1 ) model .",
    "overall , the arma(0,1)-fiegarch(0,d,1 ) performs slightly better than the other models .",
    "the fact that all models present a similar perfomance confirms the following , already known in the literature .",
    "* in practice , arch@xmath16 models perform relatively well for most applications . * garch@xmath147 models are more parsimonious than the arch ones .",
    "for instance , notice that similar results were obtained here by considering an arch@xmath734 model and a garch@xmath735 model .",
    "* for egarch@xmath147 models the conditional variance is defined in terms of the logarithm function and less ( usually none ) restrictions have to be imposed during parameter estimation",
    ". moreover , egarch models are not necessarily more parsimonious than arch / garch ones since it also carries information on the returns asymmetry ( @xmath138 and @xmath139 parameters ) .",
    "* fiegarch@xmath1 models can describe not only the same characteristics as arch , garch and egarch models do , but also the long - memory in the volatility .",
    "also , the performance of all models will be very similar if the volatility presents high persistence .",
    "for instance , notice that for the arch@xmath734 model @xmath736 , for the garch@xmath735 model @xmath737 and for the egarch model @xmath738 , which imply high persistence in the volatility .",
    "moreover , for the fiegarch model , we found @xmath106 with standard error equal to 0.0810 , which indicates that the parameter @xmath80 is statistically different from zero and thus , there is evidence of long - memory in the volatility . *",
    "given their definition , it is expected that egarch and fiegarch models will provide better forecasts for @xmath739 than for @xmath740 and , consequently , for @xmath741 .    from table [ allmodelsmae2 ] we observe that    * in terms of @xmath557 or @xmath720 , both radial basis and arch - type ( see table [ allmodelsmae ] ) models have a similar performance",
    ". in this case , arch - type models seem a better choice given the smaller number of parameter to be estimated ; * for each @xmath40 there exists at least one @xmath696 for which the @xmath719 value for the radial basis model is much smaller then any arch - type models .",
    "however , given the similarity regarding @xmath557 , the small @xmath719 values only indicate that radial basis models provide a better forecast for observations too close to zero .",
    "here we show complete mathematical proofs for the stationarity , the ergodicity , the conditions for the causality and invertibility properties , the autocorrelation and spectral density functions decay and the convergence order for the polynomial coefficients that describe the volatility for any fiegarch@xmath742 process .",
    "we prove that if @xmath0 is a fiegarch@xmath1 process and @xmath743 ^ 2)<\\infty$ ] , then @xmath2 is an arfima@xmath3 process with correlated innovations .",
    "expressions for the kurtosis and the asymmetry measures of any stationary fiegarch@xmath1 process were also provided .",
    "we also prove that if @xmath0 is a fiegarch@xmath1 process then it is a martingale difference with respect to the filtration @xmath51 , where @xmath13 .",
    "the @xmath5-step ahead forecast for the processes @xmath0 , @xmath4 and @xmath2 are given with their respective mean square error forecast . since @xmath744 can not be easily calculated for fiegarch models , we also discuss some alternative estimators for the @xmath5-step ahead forecast of @xmath740 , for all @xmath434 .",
    "we present a monte carlo simulation study showing how to perform the generation , the estimation and the forecasting of six different fiegarch models .",
    "the parameter selection of these six models are related to the real time series analyzed in @xcite .",
    "parameter estimation was performed by considering the well known quasi - likelihood method .",
    "we conclude that , given the complexity of fiegarch models , the quasi - likelihood method performs relatively well , which is indicated by the small @xmath556 , @xmath557 and @xmath558 values for the estimates .",
    "regarding the @xmath5-step ahead forecast for the processes @xmath149 and @xmath745 , we observe that the mean square error of forecast decreases as the sample size increases . however , while the conditional variance is well estimated , which is indicated by the small @xmath557 values , the estimator @xmath746 , which is an approximation for @xmath747 , does not perform well in predicting @xmath441 .",
    "this result is expected since the purpose of the model is to forecast the logarithm of the conditional variance and not the process @xmath0 itself .",
    "finally , we present the analysis of the so paulo stock exchange index ( bovespa index or ibovespa ) log - return time series .",
    "we compared the forecasting performance of fiegarch models , fully described in this paper , with other arch - type models .",
    "all models presented a similar performance which was attributed to the fact that the arch , garch and egarch models indicated high persistence in the volatility .",
    "we also compared the forecasting performance of arch - type with radial basis models .",
    "given the similarity regarding the mean ( and maximum ) absolute error of forecast we conclude that both classes show a similar forecasting performance . comparing the mean percentage error of forecasts we concluded that radial basis models provide a better forecast for observations too close to zero .",
    "lopes was partially supported by cnpq - brazil , by capes - brazil , by inct em _ matemtica _ and by pronex _ probabilidade e processos estocsticos _ - e-26/170.008/2008 -apq1 .",
    "prass was supported by cnpq - brazil .",
    "the authors are grateful to the ( brazilian ) national center of super computing ( cesup - ufrgs ) for the computational resources .",
    "s. saadi , d. gandhi , s. dutta , testing for nonlinearity and modeling volatility in emerging capital markets : the case of tunisia , international journal of theoretical and applied finance , 9(7 ) ( 2006 ) 1021 - 1050 .",
    "jayasuriya , a sub period analysis of long memory in stock return volatility for emerging markets , 9th global conference on business and economics proceedings , cambridge university , u.k . , ( 2009 ) 1 - 31 .",
    "lopes , long - range dependence in mean and volatility : models , estimation and forecasting , in : v. sidoravicius and m.e .",
    "vares ( eds . ) , in and out of equilibrium 2 ( progress in probability ) , birkhuser , boston , 2008 , 60 , pp .",
    "497 - 525 , .",
    "d. straumann , t. mikosch , quasi - maximum - likelihood estimation in conditionally heteroskedastic time series : a stochastic recurrence equations approach , the annals of statistics , 34(5 ) ( 2006 ) 2449 - 2495 ."
  ],
  "abstract_text": [
    "<S> here we present a theoretical study on the main properties of fractionally integrated exponential generalized autoregressive conditional heteroskedastic ( fiegarch ) processes . </S>",
    "<S> we analyze the conditions for the existence , the invertibility , the stationarity and the ergodicity of these processes . </S>",
    "<S> we prove that , if @xmath0 is a fiegarch@xmath1 process then , under mild conditions , @xmath2 is an arfima@xmath3 , that is , an autoregressive fractionally integrated moving average process . </S>",
    "<S> the convergence order for the polynomial coefficients that describes the volatility is presented and results related to the spectral representation and to the covariance structure of both processes @xmath2 and @xmath4 are also discussed . </S>",
    "<S> expressions for the kurtosis and the asymmetry measures for any stationary fiegarch@xmath1 process are also derived . </S>",
    "<S> the @xmath5-step ahead forecast for the processes @xmath0 , @xmath4 and @xmath2 are given with their respective mean square error forecast . </S>",
    "<S> the work also presents a monte carlo simulation study showing how to generate , estimate and forecast based on six different fiegarch models . </S>",
    "<S> the forecasting performance of six models belonging to the class of autoregressive conditional heteroskedastic models ( namely , arch - type models ) and radial basis models is compared through an empirical application to brazilian stock market exchange index . + </S>",
    "<S> * keywords : * long - range dependence , volatility , stationarity , ergodicity , fiegarch processes .    </S>",
    "<S> * msc ( 2000 ) * : 60g10 , 62g05 , 62g35 , 62m10 , 62m15 , 62m20 </S>"
  ]
}