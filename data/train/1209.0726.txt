{
  "article_text": [
    "this paper , we study the problem of random number generation from i.i.d . sources , which is the most fundamental and important source model . many real sources can be well approximated by this model , and the algorithms developed based on this model can be further generalized in generating random bits from more sophisticated models , like markov chains @xcite , or more generally , approximately stationary ergodic processes @xcite .    the problem of random number generation dates back to von neumann @xcite in 1951 who considered the problem of simulating an unbiased coin by using a biased coin with unknown probability .",
    "he observed that when one focuses on a pair of coin tosses , the events @xmath2 and @xmath3 have the same probability ( @xmath4 is for ` head ' and @xmath5 is for ` tail ' ) ; hence , @xmath2 produces the output symbol @xmath6 and @xmath3 produces the output symbol @xmath7 .",
    "the other two possible events , namely , @xmath8 and @xmath9 , are ignored , namely , they do not produce any output symbols .",
    "more efficient algorithms for generating random bits from a biased coin were proposed by hoeffding and simons @xcite , elias @xcite , stout and warren @xcite and peres @xcite .",
    "elias @xcite was the first to devise an optimal procedure in terms of the information efficiency , namely , the expected number of unbiased random bits generated per coin toss is asymptotically equal to the entropy of the biased coin .",
    "in addition , knuth and yao @xcite presented a simple procedure for generating sequences with arbitrary probability distributions from an unbiased coin ( the probability of @xmath4 and @xmath5 is @xmath10 ) .",
    "han and hoshi @xcite generalized this approach and considered the case where the given coin has an arbitrary known bias .    in this paper",
    ", we consider the problem of generating random bits from a loaded die as a natural generalization of generating random bits from a biased coin .",
    "there is some related work : in @xcite , dijkstra considered the opposite question and showed how to use a biased coin to simulate a fair die . in @xcite , juels et al",
    ". studied the problem of simulating random bits from loaded dice , and their algorithm can be treated as the national generalization of elias s algorithm . however , for a number of known beautiful algorithms , like peres s algorithm @xcite , we still do not know how to generalize them for larger alphabets ( loaded dice ) .    in addition , we notice that most existing works for biased coins take a fixed number of coin tosses as the input and they generate a variable number of random bits . in some occasions",
    ", the opposite question seems more reasonable and useful : given a biased coin , how to generate a prescribed number of random bits with as a few as possible coin tosses ?",
    "hence , we want to create a function @xmath11 that maps the sequences in a dictionary @xmath12 , whose lengthes may be different , to binary sequences of the same length .",
    "this dictionary @xmath12 is complete and prefix - free .",
    "that means for any infinite sequence , it has exactly one prefix in the dictionary . to generate random bits , we read symbols from the source until the current input sequence matches one in the dictionary .    for completeness",
    ", in this paper , we first present some of the existing algorithms that generate random bits from an arbitrary biased coin in section [ section_coin_existing ] , including the von neumann scheme , elias algorithm and peres algorithm .",
    "then in section [ section_coin_generalization ] , we present a universal scheme for transforming an arbitrary algorithm for @xmath0-faced coins to generate random bits from the general source of an @xmath1-sided die , hence enabling the application of existing algorithms to general sources . in section [ section_coin_kbits ] , we study approaches of efficiently generating a required number of random bits from an arbitrary biased coin and achieving the information - theoretic upper bound on efficiency . finally , we provide the concluding remarks in section [ section_coin_conclusion ] .",
    "in 1951 , von neumann @xcite considered the problem of random number generation from biased coins and described a simple procedure for generating an independent unbiased binary sequence @xmath13 from an input sequence @xmath14 .",
    "his original procedure is described as follows : for an input sequence , we divide all the bits into pairs @xmath15 and apply the following mapping to each pair @xmath16 where @xmath17 denotes the empty sequence . by concatenating the outputs of all the pairs",
    ", we can get a binary sequence , which is independent and unbiased .",
    "the von neumann scheme is computationally ( very ) fast , however , its information efficiency is far from being optimal . here",
    ", the information efficiency is defined by the expected number of random bits generated per input symbol .",
    "let @xmath18 with @xmath19 be the probabilities of getting h and t , then the probability for a pair of input bits to generate one output bit ( not a @xmath17 ) is @xmath20 , hence the information efficiency is @xmath21 , which is @xmath22 at @xmath23 and less elsewhere .      in 1972",
    ", elias @xcite proposed an optimal ( in terms of information efficiency ) algorithm as a generalization of the von neumann scheme .",
    "elias s method is based on the following idea : the possible @xmath24 binary input sequences of length @xmath25 can be partitioned into classes such that all the sequences in the same class have the same number of h s and t s .",
    "note that for every class , the members of the class have the same probability to be generated .",
    "for example , let @xmath26 , we can divide the possible @xmath27 input sequences into @xmath28 classes : @xmath29    now , our goal is to assign a string of bits ( the output ) to each possible input sequence , such that any two possible output sequences @xmath30 and @xmath31 with the same length ( say @xmath32 ) , have the same probability to be generated , which is @xmath33 for some @xmath34 .",
    "the idea is that for any given class we partition the members of the class to sets of sizes that are a power of 2 , for a set with @xmath35 members ( for some @xmath36 ) we assign binary strings of length @xmath36 .",
    "note that when the class size is odd we have to exclude one member of this class .",
    "we now demonstrate the idea by continuing the example above .    in the example",
    "above , we can not assign any bits to the sequence in @xmath37 , so if the input sequence is hhhh , the output sequence should be @xmath17 ( denoting the empty sequence ) .",
    "there are @xmath38 sequences in @xmath39 and we assign the binary strings as follows : @xmath40 @xmath41 similarly , for @xmath42 , there are @xmath43 sequences that can be divided into a set of @xmath38 and a set of @xmath0 : @xmath44 @xmath45 @xmath46    in general , for a class with @xmath47 members that were not assigned yet , assign @xmath48 possible output binary sequences of length @xmath49 to @xmath48 distinct unassigned members , where @xmath50 .",
    "repeat the procedure above for the rest of the members that were not assigned .",
    "when a class has an odd number of members , there will be one and only one member assigned to @xmath17 .",
    "given a binary input sequence @xmath51 of length @xmath25 , using the method above , the output sequence can be written as a function of @xmath51 , denoted by @xmath52 , called the elias function . in @xcite ,",
    "ryabko and matchikina showed that the elias function of an input sequence of length @xmath25 ( that is generated by a biased coin with two faces ) is computable in @xmath53 time .",
    "in 1992 , peres @xcite demonstrated that iterating the original von neumann scheme on the discarded information can asymptotically achieve optimal information efficiency .",
    "let us define the function related to the von neumann scheme as @xmath54 .",
    "then the iterated procedures @xmath55 with @xmath56 are defined inductively .",
    "given an input sequence @xmath57 , let @xmath58 denote all the integers @xmath59 for which @xmath60 , then @xmath55 is defined as @xmath61    note that on the righthand side of the equation above , the first term corresponds to the random bits generated with the von neumann scheme , the second and third terms relate to the symmetric information discarded by the von neumann scheme .",
    "for example , when the input sequence is @xmath62 , the output sequence based on the von neumann scheme is @xmath63 but based on the peres scheme , we have the output sequence @xmath64 which is @xmath65 , longer than that generated by the von neumann scheme .",
    "finally , we can define @xmath55 for sequences of odd length by @xmath66    surprisingly , this simple iterative procedure achieves the optimal information efficiency asymptotically",
    ". the computational complexity and memory requirements of this scheme are substantially smaller than those of the elias scheme .",
    "however , the generalization of this scheme to the case of an @xmath1-sided die with @xmath67 is still unknown .",
    "let us denote @xmath68 as a scheme that generates independent unbiased sequences from any biased coins ( with unknown probabilities ) .",
    "such @xmath69 can be the von neumann scheme , the elias scheme , the peres scheme , or any other scheme .",
    "let @xmath51 be a sequence of biased coin tosses of length @xmath25 , then a property of @xmath69 is that for any @xmath70 and @xmath71 with @xmath72 , we have @xmath73=p[\\psi(x)=y'],\\ ] ] i.e. , two output sequences of equal length have equal probability .",
    "this observation leads to the following property for @xmath69 .",
    "it says that given the numbers of h s and t s , the number of sequences yielding a binary sequence @xmath30 equals the number of sequences yielding @xmath31 when @xmath30 and @xmath31 have the same length .",
    "it further implies that given the condition of knowing the number of h s and t s in the input sequence , the output sequence of @xmath69 is still independent and unbiased .",
    "this property is due to the linear independence of probability functions of the sequences with different numbers of h s and t s .    _",
    "@xcite_[lemma_coin ] let @xmath74 be the subset of @xmath75 consisting of all sequences with @xmath76 appearances of h and @xmath77 appearances of t such that @xmath78 .",
    "let @xmath79 denote the set @xmath80 .",
    "then for any @xmath70 and @xmath71 with @xmath72 , we have @xmath81",
    "in this section , we propose a universal scheme for generalizing all the existing algorithms for biased coins such that they can deal with loaded dice with more than two sides .",
    "there is some related work : in @xcite , dijkstra considered the opposite question and showed how to use a biased coin to simulate a fair die . in @xcite , juels et al",
    ". studied the problem of simulating random bits from loaded dice , and their algorithm can be treated as the generalization of elias s algorithm . however , for a number of known beautiful algorithms , like peres s algorithm , we still do not know how to generalize them for larger alphabets ( loaded dice ) .",
    "we propose a universal scheme that is able to generalize all the existing algorithms , including elias s algorithm and peres s algorithm .",
    "compared to the other generalizations , this scheme is universal and easier to implement , and it preserves the optimality of the original algorithm on information efficiency .",
    "the brief idea of this scheme is that given a loaded die , we can convert it into multiple binary sources and apply existing algorithms to these binary sources separately .",
    "this idea seems natural , but not obvious .",
    "let us start from a simple example : assume we want to generate random bits from a sequence @xmath82 , which is produced by a @xmath83-sided die .",
    "now , we write each symbol ( die roll ) into a binary representation of length two ( h for 1 and t for 0 ) , so @xmath84    hence , @xmath51 can be represented as @xmath85    only collecting the first bits of all the symbols yields an independent binary sequence @xmath86 collecting the second bits following t , we get another independent binary sequence @xmath87 note that although both @xmath88 and @xmath89 are independent sequences individually , @xmath90 and @xmath89 are correlated with each other , since the length of @xmath89 is determined by the content of @xmath88 .",
    "let @xmath69 be any function that generates random bits from a fixed number of coin tosses , such as elias s algorithm and peres s algorithm .",
    "we see that both @xmath91 and @xmath92 are sequences of random bits .",
    "but we do not know whether @xmath91 and @xmath92 are independent of each other since @xmath90 and @xmath89 are correlated .",
    "one of our main contributions is to show that concatenating them together , i.e. , @xmath93 still yields a sequence of random bits .      generally , given a sequence of symbols generated from an @xmath1-sided",
    "die , written as @xmath94 with the number of states ( sides ) @xmath67 , we want to convert it into a group of binary sequences . to do this ,",
    "we create a binary tree , called a binarization tree , in which each node is labeled with a binary sequence of h and t. see fig .",
    "[ fig_prefixtree ] as an instance of binarization tree for the above example .",
    "given the binary representations of @xmath95 for all @xmath96 , the path of each node in the tree indicates a prefix , and the binary sequence labeled at this node consists of all the bits ( h or t ) following the prefix in the binary representations of @xmath97 ( if it exists ) .",
    "given the number of sides @xmath1 of a loaded die , the depth of the binarization tree is @xmath98 . at the beginning ,",
    "the binarization tree is a complete binary tree of depth @xmath99 in which each node is labeled with an empty string , then we process all the input symbols @xmath97 one by one . for the @xmath36th symbol , namely @xmath95 ,",
    "its binary representation is of length @xmath100 .",
    "we add its first bit to the root node .",
    "if this bit is t , we add its second bit to the left child , otherwise we add its second bit to the right child ... repeating this process until all the @xmath100 bits of @xmath95 are added along a path in the tree .",
    "finally , we can get the binarization tree of @xmath51 by processing all the symbols in @xmath51 , i.e. , @xmath97 .",
    "[ lemma3_0 ] given the binarization tree of a sequence @xmath101 , we can reconstruct @xmath51 uniquely .    the construction of @xmath51 from its binarization tree can be described as follows : at first , we read the first bit ( h or t ) from the root ( once we read a bit , we remove it from the current sequence ) .",
    "if it is t , we read the first bit of its left child ; if it is h , we read the first bit of its right child ... finally we reach a leaf , whose path indicates the binary representation of @xmath102 .",
    "repeating this procedure , we can continue to obtain @xmath103 .",
    "let @xmath104 denote the set consisting of all the binary sequences of length at most @xmath99 , i.e. , @xmath105 given @xmath106 , let @xmath107 denote the binary sequence labeled on a node corresponding to a prefix @xmath108 in the binarization tree , then we get a group of binary sequences @xmath109 for any function @xmath69 that generates random bits from a fixed number of coin tosses , we can generate random bits from @xmath51 by calculating @xmath110 where @xmath111 is the concatenation of @xmath112 and @xmath113 .",
    "we call this method as the generalized scheme of @xmath69 .",
    "we show that the generalized scheme works for any binary algorithm @xmath69 such that it can generate random bits from an arbitrary @xmath1-sided die .",
    "[ theorem3 ] let @xmath69 be any function that generates random bits from a fixed number of coin tosses .",
    "given a sequence @xmath101 with @xmath114 generated from an @xmath1-sided die , the generalized scheme of @xmath69 generates an independent and unbiased sequence .",
    "the proof of this theorem will be given in the next subsection .",
    "[ stream_lemma3_1 ] let @xmath115 with @xmath116 be the binary sequences labeled on the binarization tree of @xmath101 as defined above .",
    "assume @xmath117 is a permutation of @xmath107 for all @xmath116 , then there exists exactly one sequence @xmath118 such that it yields a binarization tree that labels @xmath119 with @xmath116 .",
    "based on @xmath119 with @xmath116 , we can construct the corresponding binarization tree and then create the sequence @xmath120 in the following way ( if it exists ) . at first , we read the first bit ( h or t ) from the root ( once we read a bit , we remove it from the current sequence ) .",
    "if it is t , we read the first bit of its left child ; if it is h , we read the first bit of its right child ... finally we reach a leaf , whose path indicates the binary representation of @xmath121 . repeating this procedure",
    ", we continue to obtain @xmath122 .",
    "hence , we are able to create the sequence @xmath123 if it exists .",
    "it can be proved that the sequence @xmath120 can be successfully constructed if and only the following condition is satisfied : for any @xmath124 , @xmath125 where @xmath126 counts the number of t s in @xmath51 and @xmath127 counts the number of h s in @xmath51 .",
    "obviously , the binary sequences @xmath115 with @xmath116 satisfy the above condition .",
    "permuting them into @xmath119 with @xmath116 does not violate this condition .",
    "hence , we can always construct a sequence @xmath128 , which yields @xmath119 with @xmath116 .",
    "this completes the proof .",
    "now , we divide all the possible input sequences in @xmath129 into classes .",
    "two sequences @xmath130 are in the same class if and only if the binary sequences obtained from @xmath51 and @xmath120 are permutations with each other , i.e. , @xmath117 is a permutation of @xmath107 for all @xmath116 . here",
    ", we use @xmath131 to denote the set consisting of all such classes .",
    "[ lemma3_2 ] all the sequences in a class @xmath132 have the same probability of being generated .    based on the probability distribution of each die roll @xmath133",
    ", we can get a group of conditional probabilities , denoted as @xmath134 where @xmath135 is the conditional probability of generating a die roll @xmath95 such that in its binary representation the bit following a prefix @xmath108 is @xmath136 .",
    "note that @xmath137 for all @xmath138 . for example , if @xmath139 , then @xmath140    it can be proved that the probability of generating a sequence @xmath141 equals @xmath142 where @xmath126 counts the number of t s in @xmath51 and @xmath127 counts the number of h s in @xmath51 .",
    "this probability keeps unchanged when we permute @xmath107 to @xmath117 for all @xmath138 .",
    "this implies that all the elements in @xmath143 have the same probability of being generated .",
    "[ lemma3_3 ]",
    "let @xmath69 be any function that generates random bits from a fixed number of coin tosses .",
    "given @xmath144 for all @xmath116 , we define @xmath145 @xmath146 if @xmath147 for all @xmath116 ,",
    "i.e. , @xmath148 and @xmath149 have the same length , then for all @xmath132 , @xmath150 i.e. , @xmath151 and @xmath152 have the same size .",
    "we prove that for any @xmath153 , if @xmath154 for all @xmath155 and @xmath156 , then @xmath157 if this statement is true , we can obtain the conclusion in the lemma by replacing @xmath148 with @xmath149 one by one for all @xmath116 .    in the class @xmath143 ,",
    "assume @xmath158 .",
    "let us define @xmath159 as the subset of @xmath160 consisting of all the permutations of @xmath161 .",
    "we also define @xmath162 @xmath163 according to lemma [ lemma_coin ] , if @xmath69 can generate random bits from an arbitrary biased coin , then @xmath164 this implies that all the elements in @xmath165 and those in @xmath166 are one - to - one mapping .    based on this result",
    ", we are ready to show that the elements in @xmath151 and those in @xmath152 are one - to - one mapping : for any sequence @xmath51 in @xmath151 , we get a series of binary sequences @xmath115 with @xmath116 . given @xmath167 with @xmath168",
    ", we can find a ( one - to - one ) mapping of @xmath161 in @xmath166 , denoted by @xmath169 .",
    "here , @xmath169 is a permutation of @xmath170 . according to lemma [ stream_lemma3_1 ] , there exists exactly one sequence @xmath128 such that it yields @xmath171 . right now",
    ", we see that for any sequence @xmath51 in @xmath151 , we can always find its one - to - one mapping @xmath120 in @xmath152 , which implies that @xmath157    this completes the proof .    based on the lemma above , we get theorem [ theorem3 ] .    * theorem [ theorem3 ] . *",
    "_ let @xmath69 be any function that generates random bits from a fixed number of coin tosses .",
    "given a sequence @xmath101 with @xmath114 generated from an @xmath1-sided die , the generalized scheme of @xmath69 generates an independent and unbiased sequence .",
    "_    in order to prove that the binary sequence generated is independent and unbiased , we show that for any two sequences @xmath172 , they have the same probability to be generated .",
    "hence , each binary sequence of length @xmath32 can be generated with probability @xmath33 for some @xmath34 .",
    "first , we let @xmath173 be the function of the generalized scheme of @xmath69 , then we write @xmath174=\\sum_{g\\in \\mathbb{g}}p[f(x)=y_1,x\\in g].\\ ] ]    according to lemma [ lemma3_2 ] , all the elements in @xmath143 have the same probability of being generated .",
    "hence , we denote this probability as @xmath175 , and the formula above can written as @xmath174=\\sum_{g\\in \\mathbb{g}}p_{g}|\\{x\\in g , f(x)=y_1\\}|.\\ ] ]    let @xmath176 be the sequence of bits generated from the node corresponding to @xmath108 for all @xmath138 , then @xmath177 .",
    "we get that @xmath178 $ ] equals @xmath179 @xmath180 where @xmath181 if and only if @xmath182 , otherwise it is zero .",
    "similarly , @xmath183 $ ] equals @xmath184 @xmath185    if @xmath186 for all @xmath116 , then based on lemma [ lemma3_3 ] , we can get @xmath187 @xmath188    substituting it into the expressions of @xmath178 $ ] and @xmath183 $ ] shows @xmath174=p[f(x)=y_2].\\ ] ]    so we can conclude that for any binary sequences of the same length , they have the same probability of being generated .",
    "furthermore , we can conclude that the bits generated are independent and unbiased .",
    "this completes the proof .      in this subsection",
    ", we show that the universal scheme keeps the optimality of original algorithms , i.e. , if the binary algorithm is asymptotically optimal , like elias s algorithm or peres s algorithm , its generalized version is also asymptotically optimal . here",
    ", we say an algorithm is asymptotically optimal if and only if the number of random bits generated per input symbol is asymptotically equal to the entropy of an input symbol .",
    "[ stream_theorem4 ] given an @xmath1-sided die with probability distribution @xmath189 , let @xmath25 be the number of symbols ( dice rolls ) used in the generalized scheme of @xmath69 and let @xmath32 be the number of random bits generated . if @xmath69 is asymptotically optimal , then the generalized scheme of @xmath69 is also asymptotically optimal , that means @xmath190}{n}=h(\\rho),\\ ] ] where @xmath191 is the entropy of the @xmath1-sided die .",
    "we prove this by induction .",
    "using the same notations as above , we have the depth of the binarization tree @xmath192 . if @xmath193 , i.e. , @xmath194 , the algorithm is exactly @xmath69 .",
    "hence , it is asymptotically optimal on efficiency .",
    "now , assume that the conclusion holds for any integer @xmath195 , we show that it also holds for the integer @xmath99 .",
    "since the length-@xmath196 binary representations of @xmath197 start with @xmath7 , the probability for a symbol starting with @xmath7 is @xmath198 in this case , the conditional probability distribution of these symbols is @xmath199    similarly , let @xmath200 then the conditional probability distribution of the symbols starting with @xmath6 is @xmath201    when @xmath25 is large enough , the number of symbols starting with @xmath7 approaches @xmath202 and the number of symbols starting with @xmath6 approaches @xmath203 . according to our assumption for @xmath195 , the total number of random bits generated approaches @xmath204 @xmath205 which equals @xmath206    this completes the proof .",
    "most existing works on random bits generation from biased coins aim at maximizing the expected number of random bits generated from a fixed number of coin tosses . falling into this category , peres s scheme and elias s scheme are asymptotically optimal for generating random bits .",
    "however , in these methods , the number of random bits generated is a random variable . in some occasions , we prefer to generate a prescribed number of random bits , hence it motivates us an opposite question : fixing the number of random bits to generate , i.e. , @xmath32 bits , how can we minimize the expected number of coin tosses ?",
    "this question is equally important as the original one , since in many applications a prescribed number of random bits are required while the source is usually a stream of coin tosses instead of a sequence of fixed length .",
    "but the existing study on this question is very limited .    to generate @xmath32 random bits , we are always able to make use of the existing schemes with fixed input length and variable output length like peres s scheme or elias s scheme .",
    "for example , we can keep reading @xmath25 tosses ( h or t ) for several times and concatenate their outputs until the total number of random bits generated is slightly larger than @xmath32 . however , if @xmath25 is small , this approach is less information efficient . if @xmath25 is large , this approach may generate too many extra random bits , which can be treated as a waste . in this section",
    ", we propose an algorithm to generate exactly @xmath32 random bits efficiently .",
    "it is motivated by the elias s scheme .",
    "it can be proved that this algorithm is asymptotically optimal , namely , the expected number of coin tosses required per random bit generated is asymptotically equal to one over the entropy of the biased coin .",
    "it is not easy to generate @xmath32 random bits directly from a biased coin with very high information efficiency .",
    "our approach of achieving this goal is to generate random bits iteratively  we first produce @xmath207 random bits , where @xmath1 is a variable number that is equal to or close to @xmath32 with very high probability . in next step , instead of trying to generate @xmath32 random bits , we try to generate @xmath208 random bits ... we repeat this procedure until generating total @xmath32 random bits .",
    "how can we generate @xmath1 random bits from a biased coin such that @xmath1 is variable number that is equal to or very close to @xmath32 ?",
    "our idea is to construct a group of disjoint prefix sets , denoted by @xmath209 , such that ( 1 ) all the sequences in a prefix set @xmath210 with @xmath211 have the same probability of being generated , and ( 2 ) @xmath212 form a stopping set , namely , we can always get a sequence in @xmath213 ( or with probability almost @xmath6 ) when keeping reading tosses from a biased coin .",
    "for example , we can let @xmath214 then @xmath215 forms a stopping set , which is complete and prefix - free .    in the scheme , we let all the sequences in @xmath210 for all @xmath211 have the same probability , i.e.",
    ", @xmath210 consists of sequences with the same number of h s and t s .",
    "we select criteria carefully such that @xmath216 is slightly larger than @xmath217 .",
    "similarly as elias s original scheme , we assign output binary sequences to all the members in @xmath210 for all @xmath211 .",
    "let @xmath47 be the number of members that were not assigned yet in a prefix set , then @xmath48 possible output binary sequences of length @xmath49 are assigned to @xmath48 distinct unassigned members , where @xmath218 if @xmath219 and @xmath50 if @xmath220 .",
    "we repeat the procedure above for the rest of the members that were not assigned .",
    "the above method generates @xmath1 random bits for some @xmath1 with @xmath221 .",
    "it is easy to see that the above method never generates a binary sequence longer than @xmath32 .",
    "we only need to prove that for any binary sequences @xmath222 , they have the same probability of being generated .",
    "let @xmath11 denote the function corresponding to the above method .",
    "then @xmath223=\\sum_{i=1}^wp[x\\in s_i ] p[f(x)=y|x\\in s_i].\\ ] ] given @xmath224 , we have @xmath225=p[f(x)=y'|x\\in s_i]$ ] , which supports our claim that any two binary sequences of the same length have the same probability of being generated .    the next question is how to construct such prefix sets @xmath226 .",
    "let us first consider the construction of their union , i.e. , the stopping set @xmath213 .",
    "given a biased coin , we design an algorithm that reads coin tosses and stops the reading until it meets the first input sequence that satisfies some criterion . for instance , let @xmath76 be the number of @xmath4 s and @xmath77 be the number of @xmath5 s in the current input sequence , one possible choice is to read coin tosses until we get the first sequence such that @xmath227 . such an input sequence is a member in the stopping set @xmath213 . however , this criterion is not the best one that we can have , since it will introduce too many iterations to generate @xmath32 random bits . to reduce the number of iterations ,",
    "we hope that the size of each prefix set , saying @xmath210 , is slightly larger than @xmath217 . as a result , we use the following stopping set : @xmath228 later , we will show that the selection of such a stopping set can make the number of iterations very small .",
    "now we divide all the sequences in the stopping set @xmath213 into different classes , i.e. , the prefix sets @xmath226 , such that each prefix set consists of the sequences with the same number of h s and t s .",
    "assume @xmath74 is a nonempty prefix set that consists of sequences with @xmath76 h s and @xmath77 t s , then @xmath229 where @xmath230 is the set consisting of all the sequences with @xmath76 h s and @xmath77 t s .",
    "according to the stopping set constructed above , we have @xmath231 @xmath232 where @xmath233 is the number of @xmath4 s in @xmath234 without considering the last symbol and @xmath235 is the number of @xmath4 s in @xmath234 without considering the last symbol .",
    "so if the last symbol of @xmath234 is @xmath4 , then @xmath236 ; if the last symbol of @xmath234 is @xmath5 , then @xmath237 .",
    "according to the expression of @xmath74 , we see that the sequences in a prefix set are not prefixes of sequences in another prefix set .",
    "furthermore , we can prove that the size of each prefix set is at least @xmath217 .",
    "[ bias_lemma_1 ] if @xmath238 , then @xmath239 .    without loss of generality , we assume that @xmath240 , hence , @xmath241",
    ". it also implies @xmath242 . to prove @xmath239 ,",
    "we show that @xmath74 includes all the sequences @xmath243 ending with @xmath4 .",
    "if @xmath243 ending with @xmath4 does not belong to @xmath74 , then @xmath244 from which , we can get @xmath245 it further implies that all the sequences @xmath243 ending with @xmath5 are also not members in @xmath74 .",
    "so @xmath74 is empty .",
    "it is a contradiction .",
    "the number of sequences @xmath243 ending with @xmath4 is @xmath246 so the size of @xmath74 is at least @xmath217 if @xmath238 .",
    "this completes the proof .",
    "based on the construction of prefix sets , we can get an algorithm @xmath247 for generating @xmath1 random bits with @xmath221 , described as follows .",
    "= 0.5em    * algorithm @xmath248 *    * input : * a stream of biased coin tosses .",
    "* output : * @xmath1 bits with @xmath221 .    *",
    "( 1 ) * reading coin tosses until there are @xmath76 h s and @xmath77 t s for some @xmath76 and @xmath77 such that @xmath249 * ( 2 ) * let @xmath51 denote the current input sequence of coin tosses . if the last coin toss is @xmath4 , we let @xmath236 ; otherwise , we let @xmath237 . we remove this coin toss from @xmath51 if @xmath250 * ( 3 )",
    "* let @xmath251 denote the elias s function for generating random bits from a fixed number of coin tosses .",
    "a fast computation of @xmath251 was provided by ryabko and matchikina in @xcite .",
    "the output of the algorithm @xmath252 is @xmath253 or the last @xmath32 bits of @xmath253 if @xmath253 is longer than @xmath32 .",
    "according to lemma [ bias_lemma_1 ] , we can easily get the following conclusion .",
    "[ bias_corollary_2 ] the algorithm @xmath254 generates @xmath1 random bits for some @xmath1 with @xmath221 , and @xmath255 with probability at least @xmath256 .    the sequence generated by @xmath254 is independent and unbiased .",
    "this conclusion is immediate from lemma [ bias_lemma_1 ] .",
    "assume that the input sequence @xmath257 for some @xmath36 with @xmath211 , then the probability of @xmath255 is @xmath258 which is at least @xmath256 based on the fact that @xmath259 . since this conclusion is true for all @xmath210 with @xmath211 , we can claim that @xmath255 with probability at least @xmath256 .    since the algorithm @xmath254 generates @xmath1 random bits for some @xmath1 with @xmath221 from an arbitrary biased coin , we are able to generate @xmath32 bits iteratively : after generating @xmath1 random bits , we apply the algorithm @xmath260 for generating @xmath208 bits . repeating this procedure",
    ", the total number of random bits generated will converge to @xmath32 very quickly .",
    "we call this scheme as an iterative scheme for generating @xmath32 random bits .    to generate @xmath32 random bits , we do not want to iterate @xmath254 too many times .",
    "fortunately , in the following theorem , we show that in our scheme the expected number of iterations is upper bounded by a constant @xmath0 .",
    "the expected number of iterations in the iterative scheme for generating @xmath32 random bits is at most @xmath0 .    according to corollary [ bias_corollary_2 ]",
    ", @xmath254 generates @xmath255 random bits with probability at least @xmath256 .",
    "hence , the scheme stops at each iteration with probability more than @xmath256 .",
    "following this fact , the result in the theorem is immediate .      in this subsection ,",
    "we study the information efficiency of the iterative scheme and show that this scheme is asymptotically optimal .",
    "given a biased coin with probability @xmath261 being @xmath4 , let @xmath25 be the number of coin tosses used by the algorithm @xmath254 , then @xmath262}{k}\\leq \\frac{1}{h(p)}.\\ ] ]    we consider the probability of having an input sequence of length at least @xmath25 , denote as @xmath263 .",
    "in this case , we can write @xmath264 , where @xmath76 is the number of h s and @xmath77 is the number of t s . according to the construction of the stopping set , @xmath265 or we can write it as @xmath266    hence",
    ", we get an upper bound for @xmath267 , which is @xmath268    note that if @xmath269 , then @xmath270 is a nondecreasing function of @xmath25 .    according to the symmetry of our criteria",
    ", we can get @xmath271    for convenience , we write @xmath272 then @xmath273 and @xmath274 is also a nondecreasing function of @xmath25 .",
    "now , we are ready to calculate the expected number of coin tosses required , which equals @xmath275 & = & \\sum_{n=1}^{\\infty } ( p_n - p_{n+1 } ) n=\\sum_{n=1}^{\\infty}p_n\\label{equ_lemma1_5}\\\\ & \\leq & \\sum_{n=1}^{\\frac{k}{h(p)}(1+\\epsilon)}p_n+ \\sum_{n=\\frac{k}{h(p)}(1+\\epsilon)}^{\\infty}q_n+\\sum_{n=2\\frac{k}{h(p)}(1+\\epsilon)}^\\infty q_n , \\nonumber\\end{aligned}\\ ] ] where @xmath276 is a small constant . in the rest",
    ", we study the upper bounds for all the three terms when @xmath25 is large enough .    for the first term , we have @xmath277    now let us consider the second term @xmath278    using the stirling bounds on factorials yields @xmath279 where @xmath280 is the binary entropy function . hence , following ( [ equ_lemma1_1 ] ) , we can get @xmath281    when @xmath282 , we can write @xmath283 which implies that @xmath284 for some @xmath285 . so there exists an @xmath286 such that for @xmath287 , @xmath288 .    by the weak law for the binomial distribution ,",
    "given any @xmath289 and @xmath290 , there is an @xmath291 such that for @xmath292 , with probability at least @xmath293 there are @xmath36",
    "s among the @xmath25 coin tosses such that @xmath294 .",
    "letting @xmath295 and @xmath282 gives @xmath296 for any @xmath290 when @xmath297 .",
    "so for any @xmath290 , when @xmath32 is large enough , we have @xmath298    to calculate the third term , we notice that @xmath274 decays very quickly as @xmath25 increase when @xmath299 . in this case , @xmath300    when @xmath299 , we have @xmath301 this implies that when @xmath25 is large enough , @xmath302 .",
    "let us define a constant @xmath303 such that @xmath304 and @xmath305 .",
    "then for all @xmath299 , when @xmath32 is large enough , @xmath306    therefore , given any @xmath290 , when @xmath32 is large enough , the value of the third term @xmath307    substituting ( [ equ_lemma1_2 ] ) , ( [ equ_lemma1_3 ] ) , and ( [ equ_lemma1_4 ] ) into ( [ equ_lemma1_5 ] ) yields that for any @xmath276 and @xmath290 , if @xmath32 is large enough , we have @xmath308\\leq \\frac{k}{h(p)}(1+\\epsilon)(1+\\delta)+ \\frac{1-\\alpha}{p-\\alpha}\\delta,\\ ] ] with @xmath309 .",
    "then it is easy to get that @xmath310}{k}\\leq \\frac{1}{h(p)}.\\ ] ] this completes the proof .    given a biased coin with probability @xmath261 being h , let @xmath25 be the number of coin tosses required to generate @xmath32 random bits in the iterative scheme , then @xmath310}{k}= \\frac{1}{h(p)}.\\ ] ]    first , we prove that @xmath311}{k}\\geq \\frac{1}{h(p)}$ ] .",
    "let @xmath312 be the input sequence , then @xmath310h(p)}{h(x)}=1.\\ ] ]    shannon s theory tells us that it is impossible to extract more than @xmath313 random bits from @xmath51 , i.e. , @xmath314 .",
    "so @xmath315}{k}\\geq \\frac{1}{h(p)}.\\ ] ]    to get the conclusion in the theorem , we only need to show that @xmath310}{k}\\leq\\frac{1}{h(p)}.\\ ] ]    to distinguish the @xmath25 in this theorem and the one in the previous theorem , we use @xmath316 denote the number of coin tosses required to generate @xmath32 random bits in the iterative scheme and let @xmath317 denote the number of coin tosses required by @xmath254 .",
    "let @xmath318 be the probability for @xmath254 generating @xmath1 random bits with @xmath221 .",
    "then we have that @xmath319=e[n_{(k)}^{\\phi}]+\\sum_{m=0}^k p_m e[n_{(k - m)}].\\ ] ]    according to the algorithm , @xmath320 and @xmath321\\leq e[n_{(k)}]$ ] .",
    "substituting them into the equation above gives @xmath322\\leq e[n_{(k)}^{\\phi}]+\\frac{1}{2 } e[n_{(k)}],\\ ] ] i.e. , @xmath323\\leq 2 e[n_{(k)}^{\\phi}]$ ] .",
    "now , we divide the second term in ( [ equ_lemma2_1 ] ) into two parts such that @xmath322\\leq e[n_{(k)}^{\\phi}]+\\sum_{m=0}^{k-\\epsilon k } p_m e[n_{(k - m)}]+ \\sum_{m = k-\\epsilon k}^k p_m e[n_{(k - m)}],\\ ] ] for a constant @xmath276 . in which , @xmath324\\leq ( \\sum_{m=0}^{k-\\epsilon k } p_m)2 e[n_{(k)}^{\\phi}],\\ ] ] @xmath325\\leq 2e[n_{(\\epsilon k)}^{\\phi}].\\ ] ]    hence @xmath326\\leq e[n_{(k)}^{\\phi}]+   ( \\sum_{m=0}^{k-\\epsilon k } p_m)2 e[n_{(k)}^{\\phi } ] + 2e[n_{(\\epsilon k)}^{\\phi}].\\ ] ]    given @xmath32 ,",
    "all the possible input sequences are divided into @xmath327 prefix sets @xmath226 , where @xmath327 can be an infinite number .",
    "given an input sequence @xmath224 for @xmath211 , we are considering the probability for @xmath254 generating a sequence of length @xmath1 .    in our algorithm , @xmath328 .",
    "assume @xmath329 where @xmath330 and @xmath331 .",
    "given the condition @xmath224 , we have @xmath332 so given any @xmath290 , when @xmath32 is large enough , we have @xmath333 although we reach this conclusion for @xmath224 , this conclusion holds for any @xmath210 with @xmath334 .",
    "hence , we are able to remove this constrain that @xmath224 .    according to the previous lemma , for any @xmath290 ,",
    "when @xmath32 is large enough , we have @xmath335}{\\epsilon k}\\leq \\frac{1}{h(p)}+\\delta,\\ ] ] @xmath336}{k}\\leq \\frac{1}{h(p)}+\\delta.\\ ] ]    substituting ( [ equ_lemma2_2 ] ) , ( [ equ_lemma2_3 ] ) , and ( [ equ_lemma2_5 ] ) into ( [ equ_lemma2_4 ] ) gives us @xmath322\\leq k(\\frac{1}{h(p)}+\\delta)(1 + 2\\delta ) + 2 k\\epsilon(\\frac{1}{h(p)}+\\delta).\\ ] ] from which , we obtain @xmath337}{k}=\\lim_{k\\rightarrow \\infty}\\frac{e[n_{(k)}]}{k}\\leq \\frac{1}{h(p)}.\\ ] ] this completes the proof .",
    "the theorem above shows that the iterative scheme is asymptotically optimal , i.e. , the expected number of coin tosses for generating @xmath32 random bits approaches the information theoretic bound by below when @xmath32 becomes large .",
    "in this paper , we have presented a universal scheme that transforms an arbitrary algorithm for @xmath0-faced coins to generate random bits from general @xmath1-sided dice , hence enabling the application of existing algorithms to general sources .",
    "although a similar question has been studied before , as in @xcite , their solution can only be applied to a specified algorithm , i.e. , elias s algorithm .",
    "the second contribution of this paper is an efficient algorithm for generating a prescribed number of random bits from an arbitrary biased coin . in many applications ,",
    "this is a natural way of considering the problem of random bits generation from biased coins , but it is not well studied in the literature .",
    "this problem is similar to the one studied in universal variable - to - fixed length codes , which are used to parse an infinite sequence into variable - length phases .",
    "each phase is then encoded into a fixed number of bits . in @xcite ,",
    "lawrence devised a variable - to - fixed length code for the class of binary memoryless sources ( biased coins ) , which is based on pascal s triangle ( so is our algorithm ) .",
    "tjalkens and willems @xcite modified lawrence s algorithm as a more natural and simple implementation , and they showed that the rate of the resulting code converges asymptotically optimally fast to the source entropy .",
    "these universal variable - to - fixed length codes are probably capable to generate random bits asymptotically in some ( week ) sense , namely , the random bits generated in this way are not perfect , and they can not satisfy the typical requirement based on statistical distance ( widely used in computer science ) ."
  ],
  "abstract_text": [
    "<S> in this paper , we present a universal scheme for transforming an arbitrary algorithm for biased @xmath0-face coins to generate random bits from the general source of an @xmath1-sided die , hence enabling the application of existing algorithms to general sources . in addition , we study approaches of efficiently generating a prescribed number of random bits from an arbitrary biased coin . </S>",
    "<S> this contrasts with most existing works , which typically assume that the number of coin tosses is fixed , and they generate a variable number of random bits .    random number generation , biased coins , loaded dice . </S>"
  ]
}