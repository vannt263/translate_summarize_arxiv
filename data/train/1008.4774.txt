{
  "article_text": [
    "tensor networks are becoming increasingly popular as a tool to represent wave - functions of quantum many - body systems .",
    "their success is based on the ability to efficiently describe the ground state of a broad class of local hamiltonians on the lattice .",
    "tensor network states are used both as a variational ansatz to numerically approximate ground states and as a theoretical framework to characterize and classify quantum phases of matter .",
    "examples of tensor network states for one dimensional systems include the matrix product state@xcite ( mps ) , which results naturally from both wilson s numerical renormalization group@xcite and white s density matrix renormalization group@xcite ( dmrg ) and is also used as a basis for simulation of time evolution;@xcite the tree tensor network@xcite ( ttn ) , which follows from coarse - graining schemes where the spins are blocked hierarchically ; and the multi - scale entanglement renormalization ansatz@xcite ( mera ) , which results from a renormalization group procedure known as entanglement renormalization.@xcite for two dimensional lattices , there are generalizations of these three tensor network states , namely projected entangled pair states@xcite ( peps ) , 2d ttn@xcite and 2d mera,@xcite respectively . as variational anstze , peps and 2d mera are particularly interesting since they can be used to address large two - dimensional lattices , including systems of frustrated spins@xcite and interacting fermions,@xcite where monte carlo techniques fail due to the sign problem .",
    "a many - body hamiltonian @xmath2 may be invariant under certain transformations , which form a group of symmetries.@xcite the symmetry group divides the hilbert space of the theory into symmetry sectors labeled by quantum numbers or conserved charges . on a lattice one can distinguish between _ space _ symmetries , which correspond to some permutation of the sites of the lattice , and _ internal _ symmetries , which act on the vector space of each site .",
    "an example of space symmetry is invariance under translations by some unit cell , which leads to conservation of momentum .",
    "an example of internal symmetry is _ su_(2 ) invariance , e.g. spin isotropy in a quantum spin model .",
    "an internal symmetry can in turn be _ global _ , if it transforms the space of each of the lattice sites according to the same transformation ( e.g. a spin independent rotation ) ; or _ local _ , if each lattice site is transformed according to a different transformation ( e.g. a spin - dependent rotation ) , as it is in the case of gauge symmetric models .",
    "a global internal _",
    "su_(2 ) symmetry gives rise to conservation of total spin . by targetting a specific symmetry sector during a calculation , computational costs",
    "can often be significantly reduced while explicitly preserving the symmetry .",
    "it is therefore not surprising that symmetries play an important role in numerical approaches .    in tensor",
    "network approaches , the exploitation of global internal symmetries has a long history , especially in the context of mps.@xcite both abelian and non - abelian symmetries have been thoroughly incorporated into dmrg code and have been exploited to obtain computational gains .",
    "symmetries have also been used in more recent proposals to simulate time evolution with mps , e.g. with the time evolving block decimation ( tebd ) algorithm and variations thereof , often collectively referred to as time - dependent dmrg .    when considering symmetries , it is important to notice that an mps is a trivalent tensor network .",
    "that is , in an mps each tensor has at most three indices .",
    "the clebsch ",
    "gordan coefficients@xcite ( or coupling coefficients ) of a symmetry group are also trivalent , and this makes incorporating the symmetry into a mps by considering symmetric tensors particularly simple .",
    "in contrast , tensor network states with a more elaborated network of tensors , such as mera or peps , consist of tensors having a larger number of indices . in this case a more general formalism is required in order to exploit the symmetry . as explained in ref .",
    ", a generic symmetric tensor can be decomposed into a _",
    "degeneracy _ part , which contains all degrees of freedom not determined by symmetry , and a _ structural _ part , which is completely determined by symmetry and can be further decomposed as a trivalent network of clebsch  gordan coefficients .",
    "the use of symmetric tensors in more complex tensor networks has also been discussed in refs .  .",
    "in particular , ref .   has shown that under convenient conditions ( injectivity ) , a peps that represents a symmetric state can be represented with symmetric tensors , generalizing similar results for mps obtained in ref .  .",
    "notice that these studies are not concerned with how to decompose symmetric tensors so as to computationally exploit the symmetry .",
    "on the other hand , exploitation of @xmath1 symmetry for computational gain in the context of peps was reported in ref .  , although no implementation details were provided .",
    "finally , several aspects of _ local _ internal symmetries in tensor networks algorithms have been addressed in refs .  .",
    "the purpose of this paper is to address , in considerable detail and at a pedagogical level , several practical aspects of the exploitation of global internal symmetries not covered in ref .  .",
    "for concreteness we will concentrate on the u(1 ) symmetry , but extending our results to any abelian group is straightfoward .",
    "a similar analysis of non - abelian groups will be considered in ref .  .",
    "the paper is organized in sections as follows .",
    "section [ sec : tensor ] contains a review of the tensor network formalism and introduces the nomenclature and diagrammatical representation of tensors used in the rest of the paper .",
    "it also describes a set @xmath3 of primitives for manipulating tensor networks , consisting of manipulations that involves a single tensor ( permutation , fusion and splitting of the indices of a tensor ) and matrix operations ( multiplication and factorization ) .",
    "section [ sec : symmetry ] reviews basic notions of representation theory of the abelian group @xmath1 .",
    "the action of the group is analysed first on a single system , where @xmath1 symmetric states and @xmath1 invariant operators are decomposed in a compact , canonical manner .",
    "this canonical form allows us to identify the degrees of freedom which are not constrained by the symmetry .",
    "the action of the group is then also analysed on the tensor product of two hilbert spaces and , finally , on the tensor product of a finite number of spaces .",
    "section [ sec : symtn ] explains how to incorporate the @xmath1 symmetry into a generic tensor network algorithm , by considering @xmath1 invariant tensors in a canonical form , and by adapting the set @xmath3 of primitives for manipulating tensor networks .",
    "these include the multiplication of two @xmath1 invariant matrices in their canonical form , which is at the core of the computational savings obtained by exploiting the symmetry in tensor network algorithms .",
    "section [ sec : mera ] illustrates the practical exploitation of the @xmath1 symmetry in a tensor network algorithm by presenting mera calculations of the ground state and low energy states of two quantum spin chain models .",
    "section [ sec : conclusions ] contain some conclusions .",
    "the canonical form offers a more compact description of @xmath1 invariant tensors , and leads to faster matrix multiplications and factorizations . however , there is also an additional cost associated with mantaining an invariant tensor in its canonical form while reshaping ( fusing and/or splitting ) its indices . in some situations ,",
    "this cost may offset the benefits of using the canonical form .",
    "in the appendix we discuss a scheme to lower this additional cost in tensor network algorithms that are based on iterating a sequence of transformations .",
    "this is achieved by identifying , in the manipulation of a tensor , operations which only depend on the symmetry .",
    "such operations can be _ precomputed _ once at the beginning of a simulation .",
    "their result , stored in memory , can be re - used at each iteration of the simulation .",
    "the appendix describes two such specific precomputation schemes .",
    "in this section we review background material concerning the formalism of tensor networks , without reference to symmetry . we introduce basic definitions and concepts , as well as the nomenclature and graphical representation for tensors , tensor networks , and their manipulations , that will be used throughout the paper .     of rank @xmath4 and components @xmath5 .",
    "the tensor is represented by a shape ( circle ) with @xmath4 emerging lines corresponding to the @xmath4 indices @xmath6 .",
    "notice that the indices emerge in counterclockwise order .",
    "( ii ) graphical representation of tensors with rank @xmath7 and @xmath8 , corresponding to a complex number @xmath9 , a vector @xmath10 and a matrix @xmath11 , respectively.[fig : tensor],width=302 ]      a tensor @xmath12 is a multidimensional array of complex numbers @xmath13 .",
    "rank _ of tensor @xmath12 is the number @xmath4 of indices .",
    "for instance , a rank - zero tensor ( @xmath14 ) is a complex number .",
    "similarly , rank - one ( @xmath15 ) and rank - two ( @xmath16 ) tensors represent vectors and matrices , respectively .",
    "the _ size _ of an index @xmath17 , denoted @xmath18 , is the number of values that the index takes , @xmath19 .",
    "the size of a tensor @xmath12 , denoted @xmath20 , is the number of complex numbers it contains , namely @xmath21 .",
    "it is convenient to use a graphical representation of tensors , as introduced in fig .",
    "[ fig : tensor ] , where a tensor @xmath12 is depicted as a circle ( more generally some shape , e.g. a square ) and each of its indices is represented by a line emerging from it . in order to specify",
    "which index corresponds to which emerging line , we follow the prescription that the lines corresponding to indices @xmath22 emerge in counterclockwise order . unless stated otherwise , the first index will correspond to the line emerging at nine oclock ( or the first line encoutered while proceeding counterclockwise from nine oclock ) .",
    "two elementary ways in which a tensor @xmath12 can be transformed are by _ permuting _ and _ reshaping _ its indices .",
    "a _ permutation _ of indices corresponds to creating a new tensor @xmath23 from @xmath12 by simply changing the order in which the indices appear , e.g. @xmath24 on the other hand , a tensor @xmath12 can be _ reshaped _ into a new tensor @xmath23 by ` fusing ' and/or ` splitting ' some of its indices .",
    "for instance , in @xmath25 tensor @xmath23 is obtained from tensor @xmath12 by fusing indices @xmath26 and @xmath27 together into a single index @xmath28 of size @xmath29 that runs over all pair of values of @xmath30 and @xmath31 , i.e. @xmath32 , whereas in @xmath33 tensor @xmath12 is recovered from @xmath23 by splitting index @xmath28 of @xmath23 back into indices @xmath30 and @xmath31 .",
    "the permutation and reshaping of the indices of a tensor have a straighforward graphical representation ; see fig .  [",
    "fig : tensorman ] .",
    "permutation of indices @xmath30 and @xmath31 .",
    "@xmath34 fusion of indices @xmath30 and @xmath31 into @xmath35 ; splitting of index @xmath36 into @xmath30 and @xmath31.[fig : tensorman],width=302 ]     and @xmath37 into a new matrix @xmath12 ( ii ) graphical representation of an example of the contraction of two tensors @xmath38 and @xmath37 into a new tensor @xmath12 .",
    "[ fig : multiply1],width=226 ]      given two matrices @xmath38 and @xmath37 with components @xmath39 and @xmath40 , we can multiply them together to obtain a new matrix @xmath12 , @xmath41 with components @xmath42 by summing over or _ contracting _",
    "index @xmath30 .",
    "the multiplication of matrices @xmath38 and @xmath37 is represented graphically by connecting together the emerging lines of @xmath38 and @xmath37 corresponding to the contracted index , as shown in fig .  [",
    "fig : multiply1](i ) .",
    "matrix multiplication can be generalized to tensors .",
    "for instance , given tensors @xmath38 and @xmath37 with components @xmath43 and @xmath44 , we can define a tensor @xmath12 with components @xmath45 given by @xmath46 again the multiplication of two tensors can be graphically represented by connecting together the lines corresponding to indices that are being contracted ( indices @xmath30 and @xmath31 in eq .",
    "[ eq : multiply ] ) ; see fig .  [",
    "fig : multiply1](ii ) .",
    "the multiplication of two tensors can be broken down into a sequence of elementary steps to transform the tensors into matrices , multiply the matrices , and transform the resulting matrix into a tensor .",
    "next we describe these steps for the contraction given in eq .",
    "[ eq : multiply ] .",
    "they are illustrated in fig .",
    "[ fig : multiply2 ] .    1 .",
    "_ permute _ the indices of tensor @xmath38 in such a way that the indices to be contracted , @xmath30 and @xmath31 , appear in the last positions and in a given order , e.g. @xmath47 ; similarly , permute the indices of @xmath37 so that the indices to be contracted , again @xmath30 and @xmath31 , appear in the first positions and in the same order @xmath47 : @xmath48 2",
    ".   _ reshape _ tensor @xmath49 into a matrix @xmath50 by fusing into a single index @xmath51 all the indices that are not going to be contracted , @xmath52 , and into a single index @xmath53 all indices to be contracted , @xmath54 .",
    "similarly , reshape tensor @xmath55 into a matrix @xmath56 with indices @xmath57 and @xmath58 , @xmath59 3 .",
    "_ multiply _ matrices @xmath50 and @xmath56 to obtain a matrix @xmath60 , with components @xmath61 4 .",
    "_ reshape _ matrix @xmath60 into a tensor @xmath23 by splitting indices @xmath52 and @xmath58 , @xmath62 5 .   _ permute _ the indices of @xmath23 into the order in which they appear in @xmath12 ,",
    "@xmath63    we note that breaking down a multiplication of two tensors into elementary steps is not necessary  one can simply implement the contraction of eq .",
    "[ eq : multiply ] as a single process . however , it is often more convenient to compose the above elementary steps since , for instance , in this way one can use existing linear algebra libraries for matrix multiplication .",
    "in addition , it can be seen that the leading computational cost in multiplying two large tensors is not changed when decomposing the contraction in the above steps . in sec .",
    "[ sec : symtn : discussion ] this subject will be discussed in more detail for @xmath1 invariant tensors .",
    ".[fig : multiply2],width=302 ]       according to a singular value decomposition .",
    "( ii ) factorization of a rank-4 tensor @xmath12 according to one of several possible singular value decompositions .",
    "[ fig : decompose],width=226 ]    a matrix @xmath12 can be factorized into the product of two ( or more ) matrices in one of several canonical forms .",
    "for instance , the _ singular value decomposition _",
    "@xmath64 factorizes @xmath12 into the product of two unitary matrices @xmath65 and @xmath66 , and a diagonal matrix @xmath37 with non - negative diagonal elements @xmath67 known as the _ singular values _ of @xmath12 , see fig .",
    "[ fig : decompose](i ) . on the other hand ,",
    "the _ eigenvalue _ or _ spectral decomposition _ of a square matrix @xmath12 is of the form @xmath68 where @xmath69 is an invertible matrix whose columns encode the eigenvectors @xmath70 of @xmath12 , @xmath71 @xmath72 is the inverse of @xmath69 , and @xmath73 is a diagonal matrix , with the eigenvalues @xmath74 on its diagonal .",
    "other useful factorizations include the lu decomposition , the qr decomposition , etc .",
    "we refer to any such decomposition generically as a _",
    "matrix factorization_.    a tensor @xmath12 with more than two indices can be converted into a matrix in several ways , by specifying how two join its indices into two subsets . after specifying how tensor @xmath12 is to be regarded as a matrix , we can factorize @xmath12 according to any of the above matrix factorizations , as illustrated in fig .",
    "[ fig : decompose](ii ) for a singular value decomposition .",
    "this requires first permuting and reshaping the indices of @xmath12 to form a matrix , then decomposing the later , and finally restoring the open indices of the resulting matrices into their original form by undoing the reshapes and permutations .      a _ tensor network _",
    "@xmath75 is a set of tensors whose indices are connected according to a network pattern , e.g. fig .",
    "[ fig : tn ] .    given a tensor network @xmath75",
    ", a single tensor @xmath12 can be obtained by contracting all the indices that connect the tensors in @xmath75 . here ,",
    "the indices of tensor @xmath12 correspond to the open indices of the tensor network @xmath75 .",
    "we then say that the network @xmath75 is a tensor network decomposition of @xmath12 .",
    "one way to obtain @xmath12 from @xmath75 is through a sequence of contractions involving two tensors at a time , fig .",
    "[ fig : tn ] .    .",
    "( ii ) tensor @xmath12 of which the tensor network @xmath75 could be a representation .",
    "( iii ) tensor @xmath12 can be obtained from @xmath75 through a sequence of contractions of pairs of tensors .",
    "shading indicates the two tensors to be multiplied together at each step.[fig : tn],width=264 ]    from a tensor network decomposition @xmath75 for a tensor @xmath12 , another tensor network decomposition for the same tensor @xmath12 can be obtained in many ways .",
    "one possibility is to replace two tensors in @xmath75 with the tensor resulting from contracting them together , as is done in each step of fig .",
    "[ fig : tn](ii ) .",
    "another way is to replace a tensor in @xmath75 with a decomposion of that tensor ( e.g. with a singular value decomposition ) . in this paper , we will be concerned with manipulations of a tensor network that , as in the case of multiplying two tensors or decomposing a tensor , can be broken down into a sequence of operations from the following list :    1 .",
    "permutation of the indices of a tensor , eq .",
    "[ eq : permute ] .",
    "reshape of the indices of a tensor , eqs .",
    "[ eq : fuse]-[eq : split ] .",
    "multiplication of two matrices , eq .",
    "[ eq : mmultiply ] .",
    "decomposition of a matrix ( e.g. singular value decomposition or spectral decomposition ) .",
    "these operations constitute a set @xmath3 of _ primitive _",
    "operations for tensor network manipulations ( or , at least , for the type of manipulations we will be concerned with ) .    in section [ sec : symtn ]",
    "we will discuss how this set @xmath3 of primitive operations can be generalized to tensors that are symmetric under the action of the group @xmath1 .",
    "as mentioned in the introduction , tensor networks are used as a means to represent the wave - function of certain quantum many - body systems on a lattice .",
    "let us consider a lattice @xmath76 made of @xmath77 sites , each described by a complex vector space @xmath78 of dimension @xmath28 . a generic pure state @xmath79 of @xmath76",
    "can always be expanded as @xmath80 where @xmath81 labels a basis @xmath82 of @xmath78 for site @xmath83 .",
    "tensor @xmath84 , with components @xmath85 , contains @xmath86 complex coefficients .",
    "this is a number that grows exponentially with the size @xmath77 of the lattice .",
    "thus , the representation of a _ generic _ pure state @xmath79 is _",
    "inefficient_. however , it turns out that an _ efficient _ representation of _ certain _ pure states can be obtained by expressing tensor @xmath84 in terms of a tensor network .",
    "[ fig : tns ] shows several popular tensor network decompositions used to approximately describe the ground states of local hamiltonians @xmath87 of lattice models in one or two spatial dimensions .",
    "the open indices of each of these tensor networks correspond to the indices @xmath88 of tensor @xmath84 .",
    "notice that all the tensor networks of fig .",
    "[ fig : tns ] contain @xmath89 tensors .",
    "if @xmath90 is the rank of the tensors in one of these tensor networks , and @xmath91 is the size of their indices , then the tensor network depends on @xmath92 complex coefficients . for a fixed value of @xmath91",
    "this number grows linearly in @xmath77 , and not exponentially .",
    "it therefore does indeed offer an efficient description of the pure state @xmath79 that it represents .",
    "of course only a subset of pure states can be decomposed in this way .",
    "such states , often referred to as tensor network states , are used as variational anstze , with the @xmath92",
    "complex coefficients as the variational parameters .    given a tensor network state ,",
    "a variety of algorithms ( see e.g. refs .  - ) are used for tasks such as : ( @xmath17 ) computation of the expectation value @xmath93 of a local observable @xmath94 , ( @xmath95 ) optimization of the variational parameters so as to minimize the expectation value of the energy @xmath96 , or ( @xmath97 ) simulation of time evolution , e.g. @xmath98 .",
    "these tasks are accomplished by manipulating tensor networks .    on most occasions ,",
    "all required manipulations can be reduced to a sequence of primitive operations in the set @xmath3 introduced in sec .  [ sec : tensor : tn ] .",
    "thus , in order to adapt the tensor network algorithms of e.g. refs .  - to the presence of a symmetry , we only need to modify the set @xmath3 of primitive tensor network operations .",
    "this will be done in sec .",
    "[ sec : symtn ] .",
    "matrix product state ( mps ) , @xmath34 tree tensor network ( ttn ) , @xmath99 multi - scale entanglement renormalization ansatz ( mera ) .",
    "examples of tensor network states for 2d systems : @xmath100 projected entangled - pair state peps , @xmath101 2d ttn .",
    "( 2d mera not depicted).[fig : tns],width=302 ]        by decorating the lines of a tensor network @xmath75 with arrows ( fig .",
    "[ fig : arrow](ii ) ) , this can be regarded as a composition of linear maps  namely one linear map for each tensor in @xmath75 . while arrows might be of limited relevance in the absence of a symmetry , they will play an important role when we consider symmetric tensors since they specify how the group acts on each index of a given tensor .     with one incoming index and two outgoing indices , denoted by incoming and outgoing arrows respectively .",
    "( ii ) a tensor network @xmath75 with directed links can be interpreted as a linear map between incoming and outgoing spaces ( of the incoming and outgoing indices ) obtained by composing the linear maps associated with each of the tensors in @xmath75.[fig : arrow],width=264 ]",
    "in this section we review basic background material concerning the representation theory of the group @xmath1 .",
    "we first consider the action of @xmath1 on a vector space @xmath78 , which decomposes into the direct sum of ( possibly degenerate ) irreducible representations .",
    "we then consider vectors of @xmath78 that are symmetric ( invariant or covariant ) under the action of @xmath1 , as well as linear operators that are @xmath1 invariant .",
    "then we consider the action of @xmath1 on the tensor product of two vector spaces , and its generalization to the tensor product of an arbitrary number of vector spaces .",
    "let @xmath78 be a finite dimensional space and let @xmath115 label a set of linear transformations @xmath116 , @xmath117 that are a unitary representation of the group @xmath1 .",
    "that is @xmath118 then @xmath78 decomposes as the direct sum of ( possibly degenerate ) one - dimensional irreducible representations ( or _ irreps _ ) of @xmath1 , @xmath119 where @xmath120 is a subspace of dimension @xmath121 , made of @xmath122 copies of an irrep of u(1 ) with charge @xmath123 .",
    "we say that irrep @xmath124 is @xmath122-fold degenerate and that @xmath125 is the degeneracy space . for concreteness , in this paper",
    "we identify the integer charge @xmath124 as labelling the number of particles ( another frequent identification is with the @xmath126 component of the spin , in which case semi - integer numbers may be considered ) .",
    "the representation of group @xmath1 is generated by the particle number operator @xmath127 , @xmath128 where @xmath129 is a projector onto the subspace @xmath125 of particle number @xmath124 , and the vectors @xmath130 , @xmath131 are an orthonormal basis of @xmath125 . in terms of @xmath127 , the transformations @xmath132 read @xmath133 it then follows from eq .",
    "[ eq : eigen ] that @xmath134 the dual basis @xmath135 is transformed by the _ dual representation _ of @xmath1 , with elements @xmath136 , as @xmath137    * example 1 : * consider a two - dimensional space @xmath78 that decomposes as @xmath138 , where the irreps @xmath139 and @xmath140 are non - degenerate ( i.e. @xmath141 ) .",
    "then the orthogonal vectors @xmath142 form a basis of @xmath78 . in column vector notation ,",
    "@xmath143 the particle number operator @xmath127 and transformation @xmath132 read @xmath144    * example 2 : * consider a four - dimensional space @xmath78 that decomposes as @xmath145 , where @xmath146 and @xmath147 , so that now irrep @xmath148 is two - fold degenerate .",
    "let @xmath149 form a basis of @xmath150 . in column vector notation , @xmath151 the particle number operator @xmath127 and transformation @xmath132 read @xmath152      in this work we are interested in states and operators that have a simple transformation rule under the action of @xmath1 .",
    "a pure state @xmath153 is _ symmetric _ if it transforms as @xmath154 the case @xmath155 corresponds to an _ invariant _ state , @xmath156 , which transforms trivially under @xmath1 , whereas for @xmath157 the state is _ covariant _ , with @xmath158 being multiplied by a non - trivial phase @xmath159 .",
    "notice that a symmetric state @xmath158 is an eigenstate of @xmath127 : that is , it has a well - defined particle number @xmath124 .",
    "@xmath158 can thus be expanded in terms of a basis of the relevant subspace @xmath125 , @xmath160    a linear operator @xmath161 is invariant if it commutes with the generator @xmath127 , @xmath162 = 0 ,      \\label{eq : commutator}\\ ] ] or equivalently if it commutes with the action of the group , @xmath163 it follows that @xmath12 decomposes as ( _ schur s lemma _ ) @xmath164 where @xmath165 is a @xmath166 matrix that acts on the subspace @xmath125 in eq .",
    "[ eq : decov ] .",
    "notice that the operator @xmath12 in eq .",
    "[ eq : schur ] transforms vectors with a well defined particle number @xmath124 into vectors with the same particle number .",
    "that is , @xmath1 invariant operators _ conserve particle number_.    * example 1 revisited : * in example 1 above , symmetric vectors must be proportional to either @xmath167 or @xmath168 .",
    "an invariant operator @xmath169 is of the form @xmath170    * example 2 revisited : * in example 2 above , a symmetric vector @xmath158 must be of the form @xmath171 where @xmath172 . an invariant operator",
    "@xmath173 is of the form @xmath174 where @xmath175 corresponds to the @xmath176 central block and @xmath177 .",
    "the above examples illustrate that the symmetry imposes constraints on vectors and operators . by using an eigenbasis @xmath178 of the particle number operator @xmath127 ,",
    "these constraints imply the presence of the zeros in eqs .",
    "[ eq : ex1rev]-[eq : ex2rev2 ] .",
    "thus , a reduced number of complex coefficients is required in order to describe @xmath1 symmetric vectors and operators . as we will discuss in sec .",
    "[ sec : symtn ] , performing manipulations on symmetric tensors can also result in a significant reduction in computational costs .",
    "let @xmath179 and @xmath180 be two spaces that carry representations of @xmath1 , as generated by particle number operators @xmath181 and @xmath182 , and let @xmath183 be their decompositions as a direct sum of ( possibly degenerate ) irreps .",
    "let us also consider the action of @xmath1 on the tensor product @xmath184 as generated by the _ total particle number operator _",
    "@xmath185 that is , implemented by unitary transformations @xmath186    the space @xmath187 also decomposes as the direct sum of ( possibly degenerate ) irreps , @xmath188 here the subspace @xmath189 , with total particle number @xmath190 , corresponds to the direct sum of all products of subspaces @xmath191 and @xmath192 such that @xmath193 , @xmath194    for each subspace @xmath189 in eq .",
    "[ eq : decovab ] we introduce a _ coupled _ basis @xmath195 , @xmath196 where each vector @xmath197 corresponds to the tensor product @xmath198 of a unique pair of vectors @xmath199 and @xmath200 , with @xmath201 .",
    "let table @xmath202 , with components @xmath203 encode this one - to - one correspondence .",
    "notice that each component of @xmath202 is either a zero or a one .",
    "then @xmath204 for later reference , we notice that @xmath202 can be decomposed into two pieces .",
    "the first piece expresses a basis @xmath205 of @xmath187 in terms of the basis @xmath206 of @xmath179 and the basis @xmath207 of @xmath180 .",
    "this assignment occurs as in the absence of the symmetry , where one creates a composed index @xmath35 by running fast over index @xmath31 , as for example in eq .",
    "[ eq : fuse ] .",
    "the second piece is a permutation of basis elements that reorganizes them according to their total particle number @xmath190 .",
    "finally , the product basis can be expressed in terms of the coupled basis @xmath208 with @xmath209    * example 3 : * consider the case where both @xmath179 and @xmath180 correspond to the space of example 1 , that is @xmath210 and @xmath211 , where @xmath212 , @xmath213 , @xmath214 , and @xmath215 all have dimension one",
    ". then @xmath187 corresponds to the space in example 2 , namely @xmath216 where @xmath217 the coupled basis @xmath218 reads , @xmath219 where we emphasize that the degeneracy index @xmath220 takes two possible values for @xmath221 , i.e. @xmath222 , since there are two states @xmath223 with @xmath224 .",
    "the components @xmath225 of the tensor @xmath202 that encodes this change of basis all zero except for @xmath226      the action of @xmath1 on the three - fold tensor product @xmath227 as generated by the total particle number operator @xmath228 induces a decomposition @xmath229 in terms of irreps @xmath230 which we can now relate to @xmath231 , @xmath232 and @xmath233 . for example , we can first consider the product @xmath234 and then the product @xmath235 , and use two tables @xmath202 to relate at each step the coupled basis with the product basis , as discussed in the previous section .",
    "similarly we could consider the action of @xmath1 on four tensor products , and so on .    in particular we will be interested in a lattice @xmath76 made of @xmath77 sites with vector space @xmath236 , where for simplicity we assumed that each site @xmath237 is described by the same finite dimensional vector space @xmath78 ( see sec .",
    "[ sec : tensor : tnstates ] ) . given a particle number operator @xmath127 defined on each site",
    ", we can consider the action of @xmath1 generated by the total particle number operator @xmath238 which corresponds to unitary transformations @xmath239}_{\\varphi } \\equiv e^{-{\\mathrm{i}}\\hat{n}\\varphi } = ( e^{-{\\mathrm{i}}\\hat{n}\\varphi})^{\\otimes l } = \\left ( \\hat{w}_{\\varphi } \\right)^{\\otimes l}.\\ ] ] the tensor product space @xmath236 decomposes as @xmath240 and we denote by @xmath241 the particle number basis in @xmath236 .",
    "we say that a lattice model is @xmath1 symmetric if its hamiltonian @xmath242 commutes with the action of the group .",
    "that is , @xmath243 = 0 \\label{eq : ham0}\\ ] ] or equivalently , @xmath244    one example of a @xmath1 symmetric model is the hardcore bose hubbard model , with hamiltonian @xmath245 where we consider periodic boundary conditions ( by identifying sites @xmath246 and @xmath247 ) and @xmath248 are hardcore bosonic creation and annihilation operators respectively . in terms of the basis introduced in example 1 ,",
    "these operators are defined as @xmath249 to see that @xmath250 commutes with the action of the group we first observe that for two sites @xmath251 = 0,\\ ] ] from which it readily follows that @xmath252 = 0 $ ] .",
    "notice that the chemical potential term @xmath253 also commutes with the rest of the hamiltonian .",
    "the ground state @xmath254 of @xmath250 in a particular subspace @xmath255 or particle number sector can be turned into the absolute ground state by tuning the chemical potential @xmath256 .",
    "this fact can be used to find the ground state @xmath254 of any particle number sector through an algorithm that can only minimize the expectation value of @xmath250 .",
    "however , we will later see that the use of symmetric tensors in the context of tensor network states will allow us to directly minimize the expectation value of @xmath250 in a given particle number sector by restricting the search to states @xmath257 with the desired particle number @xmath258 .",
    "finally , by making the identifications @xmath259 where @xmath260 are the pauli matrices @xmath261 one can map @xmath250 to the spin-@xmath262 xxz quantum spin chain @xmath263 where we have ignored terms proportional to @xmath264 and @xmath265 . in particular , for @xmath266 we obtain the quantum xx spin chain @xmath267 and for @xmath268 , the quantum heisenberg spin chain @xmath269 in sec .",
    "[ sec : mera ] , the quantum spin models ( [ eq : xx ] ) and ( [ eq : xxx ] ) will be used to benchmark the performance increase resulting from use of symmetries in tensor networks algorithms .",
    "in this section we consider @xmath1 symmetric tensors and tensor networks . we explain how to decompose @xmath1 symmetric tensors in a compact , canonical form that exploits their symmetry .",
    "we then discuss how to adapt the set @xmath3 of primitives for tensor network manipulations in order to work in this form .",
    "we also analyse how working in the canonical form affects computational costs .",
    "let @xmath12 be a rank-@xmath4 tensor with components @xmath5 .",
    "as in sec .",
    "[ sec : tensor : linear ] , we regard tensor @xmath12 as a linear map between the vector spaces @xmath108}$ ] and @xmath109}$ ] ( [ eq : inout ] ) .",
    "this implies that each index is either an incoming or outgoing index . on each space @xmath270}$ ] , associated with index @xmath271 , we introduce a particle number operator @xmath272 that generates a unitary representation of @xmath1 given by matrices @xmath273 , @xmath115 . in the following , we use @xmath274 to denote the complex conjugate of @xmath275 .",
    "let us consider the action of @xmath1 on the space @xmath276 } \\otimes \\mathbb{v}^{[i_2 ] } \\otimes \\cdots \\otimes   \\mathbb{v}^{[i_k ] }      \\label{eq : prodspace}\\ ] ] given by @xmath277 where @xmath278 that is , @xmath279 acts differently depending on whether index @xmath271 is an incoming or outgoing index of @xmath12 .",
    "we then say that tensor @xmath12 , with components @xmath280 , is @xmath1 _ invariant _ if it is invariant under the transformation of eq .",
    "[ eq : xtrans ] , @xmath281 for all @xmath115 .",
    "this is depicted in fig .",
    "[ fig : invariant ] .",
    "* example 4 : * a @xmath1 invariant vector @xmath158that is , a vector with @xmath282 and components @xmath283 in the subspace @xmath284 corresponding to vanishing particle number @xmath155 ( cf .",
    "[ eq : npsi2])fulfills @xmath285 in accordance with eq .",
    "[ eq : npsi1 ] , as shown in fig .",
    "[ fig : invariant ] .    * example 5 : * a @xmath1 invariant matrix @xmath12 , eq .",
    "[ eq : schur ] , fulfills @xmath286 in accordance with eq .",
    "[ eq : commutator2 ] , see fig .",
    "[ fig : invariant ] .    .",
    "( ii ) constraint fulfilled by a _",
    "u_(1 ) invariant matrix .",
    "it follows from schur s lemma that the matrix is block - diagonal in particle number .",
    "( iii ) constraint fulfilled by a rank - three tensor with one incoming index and two outgoing indices.[fig : invariant],title=\"fig:\",width=302 ] +    * example 6 : * tensor @xmath12 in eq .",
    "[ eq : tabc ] , with components @xmath110 where @xmath287 and @xmath30 are outgoing indices and @xmath31 is an incoming index , is @xmath1 invariant if @xmath288 for all @xmath115 , see fig .",
    "[ fig : invariant ] .",
    "further , we say that a tensor @xmath289 , with components @xmath290 , is @xmath1 _ covariant _ if under the transformation of eq .",
    "[ eq : xtrans ] it simply aquires a non - trivial phase @xmath159 , @xmath291 for all @xmath115 .    * example 7 : * a @xmath1 covariant vector @xmath158that is , one which satisfies @xmath292 for some @xmath157 , and has nonzero components @xmath293 only in the relevant subspace @xmath120 ( cf .",
    "[ eq : npsi2])fulfills @xmath294 in accordance with eq .",
    "[ eq : npsi1 ] .",
    "covariant vector @xmath289 , with some non - vanishing particle number @xmath157 . under the action of @xmath1 on its index , the covariant vector @xmath289 acquires a phase @xmath159 .",
    "( ii ) the @xmath1 covariant vector @xmath289 , with components @xmath295 , can be represented by a @xmath1 invariant matrix @xmath12 with components @xmath296 , where @xmath17 is a trivial index ( @xmath297 ) with charge @xmath124 .",
    "[ fig : covariant],title=\"fig:\",width=302 ] +    notice that we can describe the rank-@xmath4 covariant tensor @xmath289 above by a rank-@xmath298 invariant tensor @xmath12 with components @xmath299 this is built from @xmath289 by just adding an extra incoming index @xmath17 , where index @xmath17 has fixed particle number @xmath124 and no degeneracy ( i.e. , @xmath17 is associated to a trivial space @xmath103 } \\cong \\mathbb{c}$ ] ) .",
    "we refer to both _",
    "invariant _ and _ covariant _ tensors as _ symmetric _ tensors . by using the above construction",
    ", in this work we will represent all @xmath1 symmetric tensors by means of @xmath1 invariant tensors .",
    "in particular , we represent the non - trivial components @xmath293 of the covariant vector @xmath300 in eqs .",
    "[ eq : npsi1]-[eq : npsi2 ] as an invariant matrix @xmath12 of size @xmath301 with components @xmath302 .",
    "consequently , from now on , we will mostly consider only invariant tensors .",
    "let us now write a tensor @xmath12 in a particle number basis on each factor space in eq .",
    "[ eq : prodspace ] .",
    "that is , each index @xmath303 , @xmath304 , @xmath305 , @xmath306 is decomposed into a particle number index @xmath124 and a degeneracy index @xmath307 , @xmath308 , @xmath309 , @xmath305 , @xmath310 , and @xmath311 here , for each set of particle numbers @xmath312 we regard @xmath313 as a tensor with components @xmath314 .",
    "let @xmath315 and @xmath316 denote the sum of particle numbers corresponding to incoming and outgoing indices , @xmath317 the condition for a non - vanishing tensor of the form @xmath313 to be invariant under @xmath1 , eq .",
    "[ eq : xtrans ] , is simply that the sum of incoming particle numbers equals the sum of outgoing particle numbers .",
    "therefore , a @xmath1 invariant tensor @xmath12 satisfies @xmath318 ( we use the direct sum symbol @xmath319 to denote that the different tensors @xmath320 are supported on orthonormal subspaces of the tensor product space of eq .  [",
    "eq : prodspace ] . ) in components , the above expression reads , @xmath321 here , @xmath322 implements particle number conservation : if @xmath323 , then all components of @xmath324 must vanish .",
    "this generalizes the block structure of @xmath1 invariant matrices in eq .",
    "[ eq : schur ] ( where @xmath325 is denoted @xmath326 ) to tensors of arbitrary rank @xmath4 . the canonical decomposition in eq .",
    "[ eq : tcanon ] is important , in that it allows us to identify the degrees of freedom of tensor @xmath12 that are not determined by the symmetry .",
    "expressing tensor @xmath12 in terms of the tensors @xmath327 with @xmath328 ensures that we store @xmath12 in the most compact possible way .    notice that the canonical form of eq .",
    "[ eq : tcanon ] is a particular case of the canonical form presented in eq .",
    "15 of ref .   for more general ( possibly non - abelian )",
    "symmetry groups . there ,",
    "a symmetric tensor was decomposed into _ degeneracy _ tensors ( analogous to tensors @xmath320 in eq .",
    "[ eq : tcanon ] ) and structural tensors ( generalizing the term @xmath322 in eq .  [",
    "eq : tcanon ] ) which can in general be expanded as a trivalent network of clebsch  gordan ( or coupling ) coefficients of the symmetry group . in the case of non - abelian groups , where some irreps have dimension larger than one , the structural tensors are highly non - trivial . however , for the group @xmath1 discussed in this paper ( as for any other abelian group ) all irreps are one - dimensional and the structural tensors are always reduced to a simple expression such as @xmath322 in eq .",
    "[ eq : tcanon ] .",
    "( nevertheless , in the appendix we will resort to a more elaborate decomposition of the structural tensors in order to further exploit the symmetry during tensor network manipulations of iterative algorithms . )     made of @xmath1 invariant tensors represents a @xmath1 invariant tensor @xmath12 .",
    "this is seen by means of two equalities .",
    "the first equality is obtained by inserting resolutions of the identity @xmath329 on each index connecting two tensors in @xmath75 .",
    "the second equality follows from the fact that each tensor in @xmath75 is @xmath1 invariant .",
    "[ fig : symtn],title=\"fig:\",width=302 ] +      in sec .",
    "[ sec : tensor : linear ] we saw that a tensor network @xmath75 where each line has a direction ( represented with an arrow ) can be interpreted as a collection of linear maps composed into a single linear map @xmath12 of which @xmath75 is a tensor network decomposition . by introducing a particle number operator on the vector space associated to each line of @xmath75 , we can define a unitary representation of @xmath1 on each index of each tensor in @xmath75 .",
    "then we say that @xmath75 is a @xmath1 invariant tensor network if all its tensors are @xmath1 invariant .",
    "notice that , by construction , if @xmath75 is a @xmath1 invariant tensor network , then the resulting linear map @xmath12 is also @xmath1 invariant .",
    "this is illustrated in fig .",
    "[ fig : symtn ] .    more generally , we can consider a @xmath1 symmetric tensor network , made of tensors that are @xmath1 symmetric ( that is , either invariant or covariant ) . recall , however , that any covariant tensor can be represented as an invariant tensor by adding an extra index ( [ eq : tq ] ) .",
    "therefore without loss of generality we can restrict our attention to invariant tensor networks .      as discussed in sec .",
    "[ sec : tensor : tnstates ] , a tensor network @xmath75 can be used to describe certain pure states @xmath330 of a lattice @xmath76 .",
    "if @xmath75 is a @xmath1 symmetric tensor network then it will describe a pure state @xmath158 that has a well - defined total particle number @xmath258 .",
    "that is , a @xmath1 symmetric pure state @xmath331 in this way we can obtain a more refined version of popular tensor network states such as mps , ttn , mera , peps , etc . as a variational ansatz , a symmetric tensor network state is more constrained than a regular tensor network state , and consequently it can represent less states @xmath79 .",
    "however , it also depends on less parameters .",
    "this implies a more economical description , as well as the possibility of reducing computational costs during its manipulation .",
    "the rest of this section is devoted to explaining how one can achieve a reduction in computational costs .",
    "this is based on storing and manipulating @xmath1 invariant tensors expressed in the canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] .",
    "we next explain how to adapt the set @xmath3 of four primitive operations for tensor network manipulation discussed in sect [ sec : tensor : tn ] , namely permutation and reshaping of indices , matrix multiplication , and factorization .      given",
    "a @xmath1 invariant tensor @xmath12 expressed in the canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] , permuting two of its indices is straightfoward .",
    "it is achieved by swapping the position of the two particle numbers of @xmath320 involved , and also the corresponding degeneracy indices .",
    "for instance , if the rank-@xmath332 tensor @xmath12 of eq .",
    "[ eq : tabc ] is @xmath1 invariant and has components @xmath333 when expressed in the particles number basis @xmath334 , @xmath335 , @xmath336 , then tensor @xmath23 of eq .",
    "[ eq : permute ] , obtained from @xmath12 by permuting the last two indices , has components @xmath337    notice that since we only need to permute the components of those @xmath338 such that @xmath339 , implementing the permutation of indices requires les computational time than a regular index permutation .",
    "this is shown in fig .",
    "[ fig : permfuse ] , corresponding to a permutation of indices using matlab .",
    "the indices of a @xmath1 invariant tensor can be reshaped ( fused or split ) in a similar manner to those of a regular tensor . however , maintaining the convenient canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] requires additional steps .",
    "two adjacent indices can be fused together using the table @xmath202 of eq .",
    "[ eq : u1fuse ] , which is a sparse tensor made of ones and zeros .",
    "similarly an index can be split into two adjacent indices by using its inverse , the sparse tensor @xmath340 of eq .",
    "[ eq : u1split ] .",
    "* example 8 :* let us consider again the rank-@xmath332 tensor @xmath12 of eq .",
    "[ eq : tabc ] with components given by eq .",
    "[ eq : tabcsym ] , where @xmath287 and @xmath30 are outgoing indices and @xmath31 is an incoming index .",
    "we can fuse outgoing index @xmath30 and incoming index @xmath31 into an ( e.g. incoming ) index @xmath28 , obtaining a new tensor @xmath23 with components @xmath341 where @xmath342 .",
    "[ the sign in front of @xmath343 comes from the fact that @xmath28 is an incoming index and @xmath30 an outgoing index . ]",
    "the components of @xmath23 are in one - to - one correspondence with those of @xmath12 and follow from the transformation @xmath344 where only the case @xmath345 needs to be considered . to complete the example ,",
    "let us assume that index @xmath287 is described by the vector space @xmath346 with degeneracies @xmath347 , @xmath348 and @xmath349 ; index @xmath30 is described by a vector space @xmath350 without degeneracies , that is @xmath351 ; and index @xmath31 is described by a vector space @xmath352 also without degeneracies , @xmath351 .",
    "then @xmath353 and eq .  [ eq : tabcfuse ] amounts to @xmath354 where we notice that tensor @xmath355 is a matrix as in eq .",
    "[ eq : ex2rev2 ] .",
    "similarly , we can split incoming index @xmath28 of tensor @xmath23 back into outgoing index @xmath30 and incoming index @xmath31 of tensor @xmath12 according to @xmath356 which , again , is non - trivial only for @xmath357 and @xmath358 .",
    "this example illustrates that fusing and splitting indices while maintaining the canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] requires more work than reshaping regular indices . indeed , after taking indices @xmath30 and @xmath31 into @xmath359 by listing all pairs of values @xmath360",
    ", we still need to reorganize the resulting basis elements according to their particle number @xmath361 .",
    "although this can be done by following the simple table given by @xmath202 , it may add significantly to the overall computational cost associated with reshaping a tensor .",
    "for instance , fig .",
    "[ fig : permfuse ] shows that , when using matlab , fusing indices of invariant tensors can be more expensive than fusing indices of regular tensors .",
    ", as a function of the size of the indices .",
    "all four indices of @xmath12 have the same size @xmath362 , and therefore the tensor contains @xmath363 coefficients .",
    "the figures compare the time required to perform these operations using a regular tensor and a @xmath1 invariant tensor , where in the second case each index contains 5 different values of the particle number @xmath124 ( each with degeneracy @xmath28 ) and the canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] is used .",
    "the upper figure shows the time required to permute two indices : for large @xmath28 , exploiting the symmetry of a @xmath1 invariant tensor by using the canonical form results in shorter computation times .",
    "the lower figure shows the time required to fuse two adjacent indices . in this case , maintaining the canonical form requires more computation time .",
    "notice that in both figures the asymptotic cost scales as @xmath364 , or the size of @xmath12 , since this is the number of coefficients which need to be rearranged .",
    "we note that the fixed - cost overheads associated with symmetric manipulations could potentially vary substantially with choice of programming language , compiler , and machine architecture .",
    "the results given here show the performance of the authors matlab implementation of @xmath1 symmetry .",
    "[ fig : permfuse],width=302 ]      by permuting and reshaping the indices of a @xmath1 invariant tensor , we can convert it into a @xmath1 invariant matrix @xmath365 , or simply @xmath366 where @xmath367 . in components ,",
    "matrix @xmath12 reads @xmath368 where @xmath369 and @xmath370 .",
    "in particular , similar to the discussion in sec .",
    "[ sec : tensor : multiply ] for regular tensors , the multiplication of two tensors invariant under the action of @xmath1 can be reduced to the multiplication of two @xmath1 invariant matrices .",
    "let @xmath38 and @xmath37 be two @xmath1 invariant matrices , with canonical forms @xmath371 their product @xmath41 , eq .  [ eq : mmultiply ] , is then another matrix @xmath12 which is also block diagonal , @xmath372 such that each block @xmath326 is obtained by multiplying the corresponding blocks @xmath373 and @xmath374 , @xmath375    eqs .",
    "[ eq : mcanon ] and [ eq : trsblock ] make evident the potential reduction of computational costs that can be achieved by manipulating @xmath1 invariant matrices in their canonical form .",
    "first , a reduction in memory space follows from only having to store the diagonal blocks in eq .",
    "[ eq : mcanon ] .",
    "second , a reduction in computational time is implied by just having to multiply blocks in eq .",
    "[ eq : trsblock ] .",
    "this is illustrated in the following example    * example 9 :* consider a @xmath1 invariant matrix @xmath12 which is a linear map in a space @xmath78 that decomposes into @xmath376 irreps @xmath125 , each of which has the same degeneracy @xmath377 .",
    "that is , @xmath12 is a square matrix of dimensions @xmath378 , and with the block - diagonal form of eq .",
    "[ eq : mcanon ] .",
    "since there are @xmath376 blocks @xmath326 and each block has size @xmath379 , the @xmath1 invariant matrix @xmath12 contains @xmath380 coefficients . for comparison ,",
    "a regular matrix of the same size contains @xmath381 coefficients , a number greater by a factor of @xmath376 .",
    "let us now consider multiplying two such matrices .",
    "we use an algorithm that requires @xmath382 computational time to multiply two matrices of size @xmath383 . the cost of performing @xmath376 multiplications of @xmath379 blocks in eq .",
    "[ eq : trsblock ] scales as @xmath384 .",
    "in contrast the cost of mutiplying two regular matrices of the same size scales as @xmath385 , requiring @xmath386 times more computational time .",
    "[ fig : multsvd ] shows a comparison of computation times when multiplying two matrices with matlab , for both @xmath1 symmetric and regular matrices .",
    "are considered .",
    "the figures compare the time required to perform these operations using regular matrices and @xmath1 invariant matrices , where for the @xmath1 matrices each index contains 5 different values of the particle number @xmath124 , each with degeneracy @xmath28 , and the canonical form of eqs .",
    "[ eq : mcanon]-[eq : mcanon2 ] is used .",
    "that is , each matrix decomposes into @xmath387 blocks of size @xmath379 . for large @xmath28 , exploiting the block diagonal form of @xmath1 invariant matrices results in shorter computation time for both multiplication and singular value decomposition . the asymptotic cost scales with @xmath28 as @xmath388 , while the size of the matrices grows as @xmath389 .",
    "we note that the fixed - cost overheads associated with symmetric manipulations could potentially vary substantially with choice of programming language , compiler , and machine architecture .",
    "the results given here show the performance of the authors matlab implementation of @xmath1 symmetry .",
    "[ fig : multsvd],title=\"fig:\",width=302 ] +      the factorization of a @xmath1 invariant matrix @xmath12 , eq .",
    "[ eq : mcanon ] , can also benefit from the block - diagonal structure .",
    "consider , for instance , the singular value decomposition @xmath390 of eq .",
    "[ eq : singular ] . in this case",
    "we can obtain the matrices @xmath391 by performing the singular value decomposition of each block @xmath326 independently , @xmath392    the computational savings are analogous to those described in example 9 above for the multiplication of matrices .",
    "[ fig : multsvd ] also shows a comparison of computational times required to perform a singular value decomposition on @xmath1 invariant and regular matrices using matlab .",
    "in this section we have seen that @xmath1 invariant tensors can be written in the canonical form of eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] , and that this canonical form is of interest because it offers a compact description in terms of only those coefficients which are not constrained by the symmetry .",
    "we have also seen that maintaining the canonical form during tensor manipulations adds some computational overhead when reshaping ( fusing or splitting ) indices , but reduces computation time when permuting indices ( for sufficiently large tensors ) and when multiplying or factorizing matrices ( for sufficiently large matrix sizes ) .",
    "the cost of reshaping and permuting indices is proportional to the size @xmath20 of the tensors , whereas the cost of multiplying and factorizing matrices is a larger power of the matrix size , for example @xmath393 .",
    "the use of the canonical form when manipulating large tensors therefore results in an overall reduction in computation time , making it a very attractive option in the context of tensor network algorithms .",
    "this is exemplified in the next section , where we apply the mera to study the ground state of quantum spin models with a @xmath1 symmetry .    on the other hand ,",
    "the cost of maintaining invariant tensors in the canonical form becomes more relevant when dealing with smaller tensors . in the next section",
    "we will also see that in some situations , this additional cost may significantly reduce , or even offset , the benefits of using the canonical form . in this event , and in the specific context of algorithms where the same tensor manipulations are iterated many times , it is possible to significantly decrease the additional cost by _ precomputing _ the parts of the tensor manipulations that are repeated on each iteration .",
    "precomputation schemes are described in more detail in the appendices .",
    "their performance is illustrated in the next section .",
    "sites , made of two layers of disentanglers @xmath394 and isometries @xmath395 and a top tensor @xmath396.[fig : mera],width=302 ]",
    "in previous sections we have described a strategy to incorporate a @xmath1 symmetry into tensors , tensor networks , and their manipulations . to further illustrate how the strategy works in practice , in this section we consider its implementation in the context of the multi - scale entanglement renormalization ansatz , or mera .",
    "[ fig : mera ] shows a mera that represent states @xmath330 of a lattice @xmath76 made of @xmath397 sites ( see sec .  [",
    "sec : tensor : tnstates ] ) . recall that the mera is made of layers of isometric tensors , known as disentanglers @xmath394 and isometries @xmath395 , that implement a coarse - graining transformation . in this particular scheme ,",
    "isometries map three sites into one and the coarse - graining transformation reduces the @xmath397 sites of @xmath76 into two sites using two layers of tensors . a collection of states on these two sites is then encoded in a top tensor @xmath396 , whose upper index @xmath398 is used to label @xmath399 states @xmath400 .    in this section we will consider a mera analogous to that of fig .  [ fig : mera ] but with @xmath401 layers of disentanglers and isometries , which we will use to describe states on a lattice @xmath76 made of @xmath402 sites .",
    "we will use this variational ansatz to obtain an approximation to the ground state and first excited states of two quantum spin chains that have a global internal @xmath1 symmetry , namely the spin-@xmath403 quantum xx chain of eq .",
    "[ eq : xx ] and the spin-@xmath403 antiferromagnetic quantum heisenberg chain of eq .",
    "[ eq : xxx ] . each spin-1/2 degree of freedom of the chain is described by a vector space spanned by two orthonormal states @xmath404 . here",
    "we will represent them by the states @xmath405 corresponding to zero and one particles , as in example 1 of sec .",
    "[ sec : symmetry : irreps ] . for computational convenience",
    ", we will consider a lattice @xmath76 where each site contains two spins , or states , @xmath406 .",
    "therefore each site of @xmath76 is described by a space @xmath407 , where @xmath146 and @xmath147 , as in example 2 of sec .",
    "[ sec : symmetry : irreps ] .",
    "thus , a lattice @xmath76 made of @xmath77 sites corresponds to a chain of @xmath408 spins . in such a system ,",
    "the total particle number @xmath258 ranges from @xmath409 to @xmath408 .",
    "[ equivalently , the @xmath126-component of the total spin @xmath410 ranges from @xmath411 to @xmath77 , with @xmath412 .",
    "a @xmath1 invariant version of the mera , or @xmath1 mera for short , is obtained by simply considering @xmath1 invariant versions of each isometric tensors , namely the disentanglers @xmath394 , isometries @xmath395 , and top tensor @xmath396 .",
    "this requires assigning a particle number operator to each index of the mera .",
    "each open index of the first layer of disentanglers corresponds to one site of @xmath76 .",
    "the particle number operator on any such index is therefore given by the quantum spin model under consideration .",
    "we can characterize the particle number operator by two vectors @xmath413 and @xmath414a list of the different values the particle number takes and the degeneracy associated with each such particle number , respectively . in the case of the vector space @xmath78 for each site of @xmath76 described above , @xmath415 $ ] and @xmath416 $ ] . for the open index of the tensor @xmath396 at the very top the mera ,",
    "the assignment of charges is also straighforward .",
    "for instance , to find an approximation to the ground state and first seven excited states of the quantum spin model with particle number @xmath258 , we choose @xmath417 $ ] and @xmath418 $ ] . [ in particular , a vanishing @xmath410 corresponds to @xmath419 . ]    for each of the remaining indices of the mera , the assignment of the pair @xmath420 needs careful consideration and a final choice may only be possible after numerically testing several options and selecting the one which produces the lowest expectation value of the energy .",
    "table [ table : degdist ] shows the assignment of particle numbers and degeneracies made to represent the ground state and several excited states in a system of @xmath421 sites ( that is , @xmath422 spins ) with total particle number @xmath423 [ or @xmath424 .",
    "notice that at level @xmath376 of the mera ( @xmath425 ) each index effectively corresponds to a block of @xmath426 sites of @xmath76 .",
    "therefore having exactly @xmath427 particles in a block of @xmath427 sites corresponds to a density of @xmath247 particle per site of @xmath76 .",
    "the assigned particle numbers of table [ table : degdist ] , namely @xmath428 $ ] for level @xmath376 , then correspond to allowing for fluctuations of up to two particle with respect to the average density .",
    "the sum of corresponding degeneracies @xmath429 $ ] gives the bond dimension @xmath91 , which in the example is @xmath430 .    .",
    "example of particle number assignment in a u(1 ) mera for @xmath431 sites ( or @xmath422 spins ) .",
    "the total bond dimension is @xmath432 . [",
    "table : degdist ] [ cols=\"^,^,^ \" , ]     more generally , a generic abelian group will be characterised by a set of charges @xmath433 . when fusing two such sets of charges @xmath434 and @xmath435 , each charge @xmath436",
    "is combined with its counterpart @xmath437 according to the fusion rule of the relevant subgroup . once again",
    ", this behaviour may be encoded in a single fusion map @xmath202 and its inverse @xmath340 .",
    "the formalism presented in this paper is therefore directly applicable to any abelian group .    _",
    "acknowledgements : _ the authors thank ian p. mcculloch for fruitful discussions . support from the australian research council ( apa , ff0668731 , dp0878830 , dp1092513 ) is acknowledged .",
    "we have seen that the use of the canonical form given in eqs .",
    "[ eq : tcanon]-[eq : tcanon2 ] to represent @xmath1 invariant tensors can potentially lead to substantial reductions in memory requirements and in calculation time .",
    "we also pointed out , however , that there is an additional cost in maintaining an invariant tensor in its canonical form , and that this is associated with the reshaping ( fusing and/or splitting ) of its indices . in some situations",
    "this additional cost may significantly reduce , or even offset , the benefits of using the canonical form .    in this appendix",
    "we investigate techniques for reducing this additional cost in the context of iterative tensor network algorithms .",
    "many of the algorithms discussed in sec .",
    "[ sec : tensor : tnstates ] are iterative algorithms , repeating the same sequence of tensor network manipulations many times over .",
    "examples include algorithms which compute tensor network approximations to the ground state by minimizing the expectation value of the energy , or by simulating evolution in imaginary time , with each iteration yielding an increasingly accurate approximation to the ground state of the system .    the goal of this appendix is to identify calculations which depend only on the symmetry group , and are independent of the variational coefficients of such algorithms . where these calculations are repeated in each iteration of the algorithm",
    ", we can effectively eliminate the associated computational cost by performing them only once , either during or prior to the first iteration of the algorithm , and then storing and reusing these _ precomputed _ results in subsequent iterations .",
    "we will illustrate this procedure by considering the precomputation of a series of operations applied to a single tensor @xmath438 .    to do this ,",
    "we begin by revisiting the fusion and splitting tables of sec .",
    "[ sec : symmetry : tp ] and introducing a graphical representation of these objects .",
    "we then introduce a convenient decomposition of a symmetric tensor into a matrix accompanied by multiple fusion and/or splitting tensors , and linear maps @xmath439 that map one such decomposition into another .",
    "these linear maps are independent of the coefficients of the tensor being reorganized , and consequently they are precisely the objects which can be precomputed in order to quicken an iterative algorithm at the expense of additional memory cost .",
    "finally we describe two specific precomputation schemes , differing in what is precomputed and in how the precomputed data is utilized during the execution of the algorithm , in order to illustrate the trade off between the amount of memory needed to store the precomputation data and the associated computational speedup which may be obtained . in practice ,",
    "the nature of the specific implementation employed will depend on available computational resources .      in describing how we can precompute repeated manipulations of this tensor @xmath438",
    ", we will find it useful to employ diagrammatic representations of the fusion and splitting tables @xmath202 and @xmath340 introduced in sec .",
    "[ sec : symmetry : tp ] .",
    "these tables implement a linear map between a pair of indices and their fusion product , and thus can be understood as trivalent tensors having two input legs and one output leg ( or vice versa ) in accordance with sec .",
    "[ sec : tensor : linear ] .",
    "we choose to represent them graphically as shown in fig .",
    "[ fig : u1fuse](i ) , where the arrow within the circle always points toward the coupled index .     and the splitting tensor @xmath340 .",
    "( ii ) the tensors @xmath202 and @xmath340 are unitary , and thus yield the identity when contracted pairwise as shown .",
    "( iii ) a fusion tensor decomposed into two parts .",
    "the first part ( indicated by a circle with an arrow ) performs the tensor product of input irreps , @xmath440 .",
    "the result is an index that labels pairs @xmath441 .",
    "the second part ( indicated by a rectangle ) is a permutation that associates each pair @xmath441 with a unique @xmath442 , corresponding to a vector of the coupled basis of @xmath187.,width=302 ]    the linear maps @xmath202 and @xmath340 are unitary , and consequently we impose that the tensors of fig .",
    "[ fig : u1fuse](i ) must satisfy the identities given in fig .  [",
    "fig : u1fuse](ii ) , corresponding to unitarity under the action of the conjugation operation employed in diagrammatic tensor network notation ( vertical reflection of a tensor and the complex conjugation of its components , typically denoted @xmath443 ) .",
    "our notation also reflects the property , first noted in section [ sec : symmetry : tp ] , that @xmath202 and @xmath340 may be decomposed into two pieces ( fig .",
    "[ fig : u1fuse](iii ) ) . for the fusion tensor",
    ", we identify the first piece ( represented by a circle containing an arrow ) with the creation of a composed index using the manner we would employ in the absence of symmetry ( [ eq : fuse ] ) . the second piece , represented by the small square , permutes the basis elements of the composed index , reorganizing them according to total particle number .",
    "the two components of the splitting tensor are then uniquely defined by consistency with the process of conjugation for the diagrammatic representation of tensors , and with the unitarity condition of fig .",
    "[ fig : u1fuse](ii ) .",
    "these requirements have an important consequence .",
    "suppose the first part of @xmath202 implements @xmath444 by iterating rapidly over the values of @xmath30 and more slowly over the values of @xmath31 , and @xmath30 lies clockwise of @xmath31 on the graphical representation of @xmath202 .",
    "this then means that on the graphical representation of @xmath340 which implements @xmath445 , index @xmath30 must lie _",
    "_ counter__clockwise of @xmath31 .",
    "it is therefore vitally important to distinguish between the splitting tensor and a rotated depiction of the fusing tensor . to this end",
    "we require that when using this diagrammatic notation , all tensors ( with the exception of the fusion and splitting tensors ) must be drawn with only downward - going legs , as seen for example in fig .",
    "[ fig : treedeco ] , though the legs are still free to carry either incoming or outgoing arrows as before .",
    "having components @xmath446 .",
    "the tree @xmath447 is comprised of a matrix @xmath69 as the root node , four splitting tensors as internal nodes , and @xmath448 as its leaf indices .",
    "no incoming or outgoing arrows are indicated on the indices in the figure , as the decomposition is valid for any such assignment of directional arrows.,width=196 ]        we find it convenient to decompose a rank-@xmath4 , @xmath1 invariant tensor @xmath12 , having components @xmath451 , as a binary tree tensor network @xmath447 consisting of a matrix @xmath69 which we will call the _ root node _ , and of @xmath452 splitting tensors @xmath340 as branching _ internal nodes _ , with the _ leaf _ indices of tree @xmath447 corresponding to the indices @xmath22 of tensor @xmath12",
    ". we refer to decomposition @xmath447 as a tree decomposition of @xmath12 .",
    "[ fig : treedeco ] shows an example of tree decomposition for a rank-6 tensor .",
    "it is of the form @xmath453 where @xmath454 are the internal indices of the tree .",
    "the same tensor @xmath12 may be decomposed as a tree in many different ways , corresponding to different choices of the fusion tree . as an example we show some different , but equivalent , decompositions of a rank-4 tensor in fig .",
    "[ fig : treedeco2 ] .",
    "different choices @xmath449 of tree decomposition for tensor @xmath12 will lead to different matrices representations @xmath450 of the same tensor . finally , fig .",
    "[ fig : treedeco3 ] shows how to obtain the tree decompositions from @xmath455 by introducing an appropriate resolution of the identity , constructed from pairs of fusion operators @xmath202 and splitting operators @xmath340 in accordance with fig .",
    "[ fig : u1fuse](ii ) .",
    "the representation of a tensor @xmath438 by means of a tree decomposition is particularly useful because many tensor network algorithms may be understood as a sequence of operations carried out on tensors reduced to matrix form .",
    "for example , tensor network algorithms such as mps , mera , and peps consist primarily of ( i ) tensor network contractions , and ( ii ) tensor decompositions . in sec .  [",
    "sec : tensor : tn ] , we argued that all such operations may be reduced to matrix multiplications , matrix decompositions , and a set of primitive operations @xmath3 .",
    "when tensors are updated in these algorithms they are typically created as matrices , to which operations from @xmath456 are then applied , and when they are decomposed or contracted with other tensors , this once again may take place with the tensor in matrix form .",
    "any such matrix form may always be understood as the matrix component of an appropriate tree decomposition @xmath447 of tensor @xmath438 , where the sequence of operations required to reshape tensor @xmath438 to matrix @xmath457 corresponds to the contents of the shaded area in fig .",
    "[ fig : treedeco3 ] .     are obtained by contracting the tensor with an appropriate resolution of the identity on its indices , selected according to the desired choice of the fusion tree @xmath447 . in each instance , evaluation of the contents of the shaded region yields the appropriate matrix @xmath457.,width=264 ]     can be reorganized into another matrix @xmath458 by means of fusion tensors , splitting tensors , and the permutation of indices .",
    "these operations define a one to one linear map @xmath439 that acts to reorganize the coefficients of @xmath459 .",
    "@xmath439 does not depend on the coefficients of @xmath459 , but solely on the sequence of operations performed .",
    ", width=207 ]      suppose now that we have a tensor @xmath438 in matrix form @xmath460 , which is associated with a particular choice of tree decomposition @xmath461 , and we wish to transform it into another matrix form @xmath462 , corresponding to another tree decomposition @xmath463 . as indicated , this process may frequently arise during the application of many common tensor network algorithms .",
    "the new matrix @xmath458 can be obtained from @xmath459 by means of a series of reshaping ( splitting / fusing ) and permuting operations , as indicated in fig .",
    "[ fig : mtom ] , and this series of operations may be understood as defining a map @xmath439 : @xmath464 the map @xmath439 is a linear map which depends only on the tree structure of @xmath461 and @xmath463 , and is independent of the coefficients of @xmath459 .",
    "moreover @xmath439 is unitary , and it follows from the construction of fusing and splitting tensors and the behaviour of permutation of indices ( which serves to relocate the coefficients of a tensor ) that @xmath439 simply reorganizes the coefficients of @xmath459 into the coefficients of @xmath458 in a one - to - one fashion .    therefore , one way to compute the matrix @xmath458 from matrix @xmath459 is by first computing the linear map @xmath439 , which is independent of the specific coefficients in tensor @xmath12 , and by then applying it to @xmath459 .",
    "the observation that the map @xmath439 is independent of the specific coefficients in @xmath459 is particularly useful in the context of iterative tensor network algorithms .",
    "it implies that , although the coefficients in @xmath460 will change from iteration to iteration , the linear map @xmath439 in eq .  [ eq : gamma ] remains unchanged .",
    "it is therefore possible to calculate the map @xmath439 once , during the first iteration of the simulation , and then to store it in memory and re - use it during subsequent iterations .",
    "we refer to such a strategy as a _ precomputation scheme_. fig .",
    "[ fig : precompute ] contrasts the program flow of a generic iterative tensor network algorithm with and without precomputation of the transformations @xmath439 .",
    "using such a precomputation scheme a significant speed - up of simulations can be obtained , at the price of storing potentially large amounts of precomputed data ( as a single iteration of the algorithm may require the application of many different transformations @xmath439 ) .",
    "there therefore necessarily exists a trade - off between the amount of speed - up which can be obtained and the memory requirement which this entails . in this section",
    "we describe two different precomputation schemes .",
    "the first one fully precomputes and stores all maps @xmath439 , and is relatively straightforward to implement .",
    "this results in the maximal increase in simulation speed , but implementation requires a large amount of memory . the second scheme only partially precomputes the maps @xmath439 , resulting in a moderate speed - up of simulations , but with memory requirements which are also similarly more modest .        as noted in sec .",
    "[ app : gammamap ] of this appendix , applying the map @xmath439 to a matrix @xmath459 simply reorganizes its coefficients to produce the matrix @xmath458 .",
    "moreover , if the indices of matrices @xmath460 and @xmath462 are fused to yield vectors @xmath465 and @xmath466 then the map @xmath439 may be understood as a permutation matrix , and this in turn may be concisely represented as a string of integers @xmath467 such that entry @xmath17 of @xmath468 is given by entry @xmath469 of vector @xmath465 . because all of the elements from which @xmath439 is composed are sparse , unitary , and composed entirely of zeros and ones , the permutation to which @xmath439 corresponds may be calculated at a total cost of only @xmath470 , where",
    "@xmath471 counts only the elements of @xmath460 which are not fixed to be zero by the symmetry constraints of eq .",
    "[ eq : tcanon ] .",
    "in essence , for each element of the vector @xmath465 one identifies the corresponding number and degeneracy indices @xmath472 on each leg @xmath473 of matrix @xmath460 .",
    "one can then read down the figure , applying each table @xmath202 or @xmath340 in turn to identify the corresponding labels @xmath474 on the intermediate legs , until finally the corresponding labels on the indices of @xmath462 are obtained .",
    "there is then a further 1:1 mapping from each set of labels @xmath475 , @xmath476 on @xmath462 to the corresponding entry in @xmath466 , completing the definition of @xmath439 as a map from @xmath465 to @xmath466 .    storing the map @xmath439 for a transformation such as the one shown in fig .",
    "[ fig : mtom ] imposes a memory cost of @xmath470 .",
    "the application of this map also incurs a computational cost of @xmath470 , but computational overhead is saved in not having to reconstruct the map @xmath439 on every iteration of the algorithm .     and on the open indices of the network , as in shown in ( ii ) .",
    "the residual fusion and splitting operations , depicted as an arrow in a circle , simply perform the basic tensor product operation and its inverse , ( [ eq : fuse])-([eq : split ] ) as described in ( iii).,width=264 ]      the @xmath477 memory cost incurred in the previous scheme can be significant for large matrices .",
    "however , we may reduce this cost by replacing the single permutation @xmath439 employed in that scheme with multiple smaller operations which may also be precomputed . in this approach @xmath459",
    "is retained in matrix form rather than being reshaped into a vector , and we precompute permutations to be performed on its rows and columns .",
    "first , we decompose all the the fusion and splitting tensors into two pieces in accordance with fig .",
    "[ fig : u1fuse](iii ) . next , we recognise that any permutations applied to one or more legs of a fusion or splitting tensor may always be written as a single permutation applied to the coupled index ( fig .",
    "[ fig : partial](i ) ) .",
    "we use this to replace all permutations on the intermediate indices of the diagram with equivalent permutations acting only on the indices of @xmath459 and the open indices , as shown for a simple example in fig .",
    "[ fig : partial](ii ) . the residual fusion and splitting operations , depicted by just a circle enclosing an arrow ,",
    "then simply carry out fusion and splitting of indices as would be performed in the absence of symmetry ( [ eq : fuse])-([eq : split ] ) .",
    "these operations are typically far faster than their symmetric counterparts as they do not need to sort the entries of their output indices according to particle number .      1 .",
    "permuting the rows and columns of @xmath459 using the precomputed net permutations which act on the legs of @xmath460 .",
    "2 .   performing any elementary ( non - symmetric ) splitting , permuting of indices , and fusing operations , as described by the grey - shaded region in fig .",
    "[ fig : partial](ii ) .",
    "3 .   permuting the rows and columns of the resulting matrix , using the precomputed net permutations which act on the open legs of fig .",
    "[ fig : partial](ii ) .    when matrix @xmath459 is defined compactly , as in ( [ eq : tcanon ] ) , so that elements which are identically zero by symmetry are not explicitly stored , a tensor @xmath438 is constructed from multiple blocks identified by @xmath1 charge labels on their indices ( @xmath478 in eq .",
    "[ eq : tcanon ] ) . under these conditions",
    "the elementary splitting , fusing and permutation operations of step 2 above are applied to each individual block , but some additional computational overhead is incurred in determining the necessary rearrangements of these blocks arising out of the actions performed .",
    "this rearrangement may be computed on the fly , or may also be precomputed as a mapping between the arrangement of blocks in @xmath460 and that in @xmath462 .",
    "the memory required to store the precomputation data in this scheme is dominated by the size of the net permutations collected on the matrix indices , and is therefore of @xmath479 .",
    "the overall cost of obtaining @xmath458 from @xmath459 is once again of @xmath477 , but is in general higher than the previous scheme as this cost now involves two complete permutations of the matrix coefficients , as well as a reorganisation of the block structure of @xmath460 which may possibly be computed at runtime .",
    "nevertheless , in situations where memory constraints are significant , partial precomputation schemes of this sort may be preferred .",
    "73 m. fannes , b. nachtergaele , and r. werner , commun .",
    "* 144 * , 443 ( 1992 ) .",
    "s. ostlund and s. rommer , phys .",
    "lett . , * 75 * , 3537 ( 1995 ) .",
    "d. perez - garcia , f. verstraete , m.m .",
    "wolf , and j.i .",
    "cirac , quantum inf .",
    "* 7 * , 401 ( 2007 ) .",
    "wilson , rev .",
    "* 47 * , 773 ( 1975 ) .",
    "white , phys .",
    "lett . , * 69 * , 2863 ( 1992 ) .",
    "white , phys .",
    "b , * 48 * , 10345 ( 1993 ) .",
    "u. schollwck , rev .",
    "phys . , * 77 * , 259 ( 2005 ) .",
    "mcculloch , arxiv:0804.2509v1 [ cond-mat.str-el ] ( 2008 ) . g. vidal , phys . rev .",
    ", * 91 * , 147902 ( 2003 ) . g. vidal , phys . rev . lett . , * 93 * , 040502 ( 2004 ) .",
    "a. j. daley , c. kollath , u. schollwck , and g. vidal , j. stat .",
    "exp . , p04005 ( 2004 ) .",
    "s. r. white and a. e. feiguin , phys .",
    "lett . , * 93 * , 076401 ( 2004 ) .",
    "u. schollwck , j. phys .",
    ", * 74s * , 246 ( 2005 ) . g. vidal , phys .",
    "lett . , * 98 * , 070201 ( 2007 ) .",
    "y. shi , l .- m . duan and g. vidal , phys .",
    "a , * 74 * , 022320 ( 2006 ) . g. vidal , phys .",
    "* 99 * , 220405 ( 2007 ) .",
    "g. vidal , phys .",
    "lett . , * 101 * , 110501 ( 2008 ) .",
    "g. evenbly and g. vidal , phys .",
    "b , * 79 * , 144108 ( 2009 ) .",
    "v. giovannetti , s. montangero , and r. fazio , phys .",
    ", * 101 * , 180503 ( 2008 ) . r.n.c .",
    "pfeifer , g. evenbly , and g. vidal , phys .",
    "rev . a , * 79 * , 040301(r ) ( 2009 ) . g. vidal , in _ understanding quantum phase transitions _ , edited by l. d. carr ( taylor & francis , boca raton , 2010 ) ( in press )",
    ". f. verstraete , and j. i. cirac , arxiv : cond - mat/0407066v1 ( 2004 ) . g. sierra and m.a .",
    "martin - delgado , arxiv : cond - mat/9811170v3 ( 1998 ) .",
    "t. nishino and k. okunishi , j. phys .",
    "jpn . , * 67 * , 3066 , 1998 . y. nishio , n. maeshima , a. gendiar , and t. nishino , arxiv : cond - mat/0401115 .",
    "v. murg , f. verstraete , and j. i. cirac , phys .",
    "a , * 75 * , 033605 ( 2007 ) .",
    "j. jordan , r. orus , g. vidal , f. verstraete , and j. i. cirac , phys .",
    "lett . , * 101 * , 250602 ( 2008 ) .",
    "gu , m. levin , and x .-",
    "wen , phys .",
    "b , * 78 * , 205116 ( 2008 ) . h. c. jiang , z. y. weng , and t. xiang , phys .",
    "lett . , * 101 * , 090603 ( 2008 ) .",
    "z. y. xie , h. c. jiang , q. n. chen , z. y. weng , and t. xiang , phys .",
    "lett . , * 103 * , 160601 ( 2009 ) .",
    "v. murg , f. verstraete , and j. i. cirac , phys .",
    "b , * 79 * , 195119 ( 2009 ) . l. tagliacozzo , g. evenbly , and g. vidal , phys .",
    "b , * 80 * , 235127 ( 2009 ) .",
    "v. murg , o. legeza , r. m. noack , and f. verstraete , arxiv:1006.3095v1 [ cond-mat.str-el ] ( 2006 ) . g. evenbly and g. vidal , phys .",
    "b , * 81 * , 235102 ( 2010 ) .",
    "g. evenbly and g. vidal , new j. phys .",
    ", * 12 * , 025007 ( 2010 ) .",
    "m. aguado and g. vidal , phys .",
    "lett . , * 100 * , 070404 ( 2008 ) .",
    "l. cincio , j. dziarmaga , and m. m. rams phys .",
    "lett . , * 100 * , 240603 ( 2008 ) .",
    "g. evenbly and g. vidal , phys .",
    "lett . , * 102 * , 180406 ( 2009 ) .",
    "r. koenig , b.w .",
    "reichardt , and g. vidal , phys .",
    "b , * 79 * , 195123 ( 2009 ) .",
    "g. evenbly and g. vidal , phys .",
    "lett . , * 104 * , 187203 ( 2010 ) .",
    "p. corboz , g. evenbly , f. verstraete , and g. vidal , phys .",
    "a , * 81 * , 010303(r ) ( 2010 ) . c. v. kraus , n. schuch , f. verstraete , and j. i. cirac , phys .",
    "a , * 81 * , 052338 ( 2010 ) . c. pineda , t. barthel , and j. eisert , phys .",
    "a , * 81 * , 050303(r ) ( 2010 ) .",
    "p. corboz and g. vidal , phys .",
    "b , * 80 * , 165129 ( 2009 ) .",
    "t. barthel , c. pineda , and j. eisert , phys .",
    "a , * 80 * , 042333 ( 2009 ) .",
    "shi , s .- h .",
    "li , j .- h . zhao , and h .- q .",
    "zhou , arxiv:0907.5520v1 [ cond-mat.str-el ] ( 2009 ) .",
    "li , q .- q .",
    "shi , h .- q .",
    "zhou , arxiv:1001.3343v1 [ cond-mat.supr-con ] ( 2010 ) .",
    "p. corboz , r. orus , b. bauer , and g. vidal , phys .",
    "b , * 81 * , 165104 ( 2010 ) . i. pizorn and f. verstraete , phys . rev .",
    "b , * 81 * , 245110 ( 2010 ) . z .-",
    "gu , f. verstraete , and x .-",
    "wen , arxiv:1004.2563v1 [ cond-mat.str-el ] ( 2010 )",
    ". j. f. cornwell , _ group theory in physics _ ( academic press , san diego , 1997 ) .",
    "s. ramasesha , s. k. pati , h. r. krishnamurthy , z. shuai , and j. l. bredas , phys.rev .",
    "b , * 54 * , 7598 ( 1996 ) .",
    "g. sierra and t. nishino , nucl .",
    "phys . , * b495 * , 505 ( 1997 ) .",
    "w. tatsuaki , phys .",
    "e , * 61 * , 3199 ( 2000 ) .",
    "i. p. mcculloch and m. gulacsi , europhys .",
    "* 57 * , 852 ( 2002 ) .",
    "a.j . daley , s. r. clark , d. jaksch , and p. zoller , phys .",
    "rev . a , * 72 * , 043618(2005 ) .",
    "s. bergkvist , i. mcculloch , and a. rosengren , phys .",
    "a , * 74 * , 053419 ( 2006 ) . s. pittel and n. sandulescu , phys .",
    "c , * 73 * , 014301 ( 2006 ) .",
    "i. mcculloch , j. stat .",
    "mech . , p10014 ( 2007 ) .",
    "i. danshita , j. e. williams , c. a. r. s de melo , and c. w. clark , phys .",
    "a , * 76 * , 043606(2007 ) .",
    "d. perez - garcia , m. m. wolf , m. sanz , f. verstraete , and j. i. cirac , phys .",
    ", * 100 * , 167202 ( 2008 ) .",
    "m. sanz , m. m. wolf , d. perez - garcia , and j. i. cirac , phys .",
    "a , * 79 * , 042308 ( 2009 ) .",
    "d. muth , b. schmidt , and m. fleischhauer , arxiv:0910.1749v3 [ quant - ph ] ( 2010 ) .",
    "r. v. mishmash and l. d. carr , math .",
    "* 80 * , 732 ( 2009 ) .",
    "s. singh , h .- q .",
    "zhou , and g. vidal , new j. phys .",
    ", * 12 * , 033029 ( 2010 ) .",
    "z. cai , l. wang , x.c .",
    "xie , and y. wang , phys .",
    "a , * 81 * , 043602 ( 2010 ) . s. singh , r.n.c .",
    "pfeifer , and g. vidal , arxiv:0907.2994v1 [ cond-mat.str-el ] ( 2009 ) .",
    "d. perez - garcia , m. sanz , c.e .",
    "gonzalez - guillen , m.m .",
    "wolf , and j.i .",
    "cirac , new j. phys . , * 12 * , 025010 ( 2010 ) .",
    "zhao , z.y .",
    "xie , q.n .",
    "chen , z.c .",
    "wei , j.w .",
    "cai , and t. xiang , phys .",
    "b , * 81 * , 174411 ( 2010 ) .",
    "n. schuch , i. cirac , and d. perez - garcia , arxiv:1001.3807v2 [ quant - ph ] ( 2010 ) .",
    "b. swingle and x .- g .",
    "wen , arxiv:1001.4517v1 [ cond-mat.str-el ] ( 2010 ) .",
    "x. chen , b. zeng , z .- c .",
    "gu , i. l. chuang , and x .-",
    "wen , arxiv:1003.1774v1 [ cond-mat.str-el ] ( 2010 ) . l. tagliacozzo and g. vidal , arxiv:1007.4145v1 [ cond-mat.str-el ] ( 2010 ) .",
    "s. singh et al . , in preparation ."
  ],
  "abstract_text": [
    "<S> tensor network decompositions offer an efficient description of certain many - body states of a lattice system and are the basis of a wealth of numerical simulation algorithms . in a recent paper [ arxiv:0907.2994v1 ] </S>",
    "<S> we discussed how to incorporate a global internal symmetry , given by a compact , completely reducible group @xmath0 , into tensor network decompositions and algorithms . here </S>",
    "<S> we specialize to the case of abelian groups and , for concreteness , to a @xmath1 symmetry , often associated with particle number conservation . </S>",
    "<S> we consider tensor networks made of tensors that are invariant ( or covariant ) under the symmetry , and explain how to decompose and manipulate such tensors in order to exploit their symmetry . in numerical calculations , </S>",
    "<S> the use of @xmath1 symmetric tensors allows selection of a specific number of particles , ensures the exact preservation of particle number , and significantly reduces computational costs . </S>",
    "<S> we illustrate all these points in the context of the multi - scale entanglement renormalization ansatz . </S>"
  ]
}