{
  "article_text": [
    "decentralized optimization has recently been receiving significant attention due to the emergence of large - scale distributed algorithms in machine learning , signal processing , and control applications for wireless communication networks , power networks , and sensor networks ; see , for example , @xcite . a central generic problem in such applications",
    "is decentralized resource allocation for a multiagent system , where the agents collectively solve an optimization problem in the absence of full knowledge about the overall problem structure . in such settings ,",
    "the agents are allowed to communicate to each other some relevant estimates so as to learn the information needed for an efficient global resource allocation .",
    "the decentralized structure of the problem is reflected in the agents local view of the underlying communication network , where each agent exchanges messages only with its neighbors .    in recent literature on control and optimization ,",
    "an extensively studied decentralized resource allocation problem is one where the system objective function @xmath3 is given as a sum of local objective functions , i.e. , @xmath4 where @xmath5 is known only to agent @xmath6 ; see , for example  @xcite . in this case",
    ", the objective function is separable across the agents , but the agents are coupled through the resource allocation vector @xmath7 . each agent maintains and updates its own copy of the allocation / decision vector @xmath7 , while trying to estimate an optimal decision for the system problem .",
    "another decentralized resource allocation problem is the one where the system objective function @xmath3 may not admit a natural decomposition of the form @xmath8 , and the resource allocation vector @xmath9 is distributed among the agents , where each agent @xmath6 is responsible for maintaining and updating only a coordinate ( or a part ) @xmath10 of the whole vector @xmath7 .",
    "such decentralized problems have been considered in  @xcite ( see also the textbook  @xcite ) . in the preceding work ,",
    "decentralized approaches converge when the agents are using weighted averaging , or when certain contraction conditions are satisfied .",
    "recently , li and marden @xcite have proposed a different algorithm with local updates , where each agent @xmath6 keeps estimates for the variables @xmath11 , @xmath12 , that are controlled by all the other agents in the network .",
    "the convergence of this algorithm relies on some contraction properties of the iterates .",
    "note that all the aforementioned algorithms were developed for offline optimization problems .",
    "our proposed algorithm * oda - ps * is closest to recent papers @xcite .",
    "the papers proposed a decentralized algorithm for online convex optimization which is very similar to * oda - ps * in a sense that they also introduce online subgradient estimations in primal @xcite or dual @xcite space into information aggregation using push - sum . in these papers ,",
    "the agents share a common decision set in @xmath13 , the objective functions are separable across the agents at each time ( i.e. , @xmath14 for all @xmath15 ) , and the regret is analyzed in terms of each agent s own copy of the whole decision vector @xmath16 .",
    "moreover , an additional assumption is made in @xcite that the objective functions are strongly convex .",
    "the paper is organized as follows . in section  [",
    "sec : problem ] , we formalize the problem and describe how the agents interact . in section  [ sec : basicregret ] , we provide an online decentralized dual - averaging algorithm in a generic form and establish a basic regret bound which can be used later for particular instantiations , namely , for the two algorithms * oda - c * and * oda - ps*. these algorithms are analyzed in sections  [ sec : algo - regret ] , where we establish @xmath0 regret bounds under mild assumptions . in section",
    "[ sec : sim ] , we demonstrate our analysis by simulations on a sensor network .",
    "we conclude the paper with some comments in section  [ sec : conclusion ] .",
    "* notation : *",
    "consider a multiagent system ( network ) consisting of @xmath17 agents , indexed by elements of the set @xmath18 $ ] .",
    "each agent @xmath19 takes actions in an action space @xmath20 , which is a closed and bounded interval of the real line .",
    "being a compact convex subset of a multidimensional space @xmath13 ; we mainly stick to the scalar case for simplicity . ]",
    "the communication among agents in the network is governed by either one of the two following models :    1 .",
    "an undirected connected graph @xmath21 : if agents @xmath6 and @xmath22 are connected by an edge ( which we denote by @xmath23 ) , then they may exchange information with one another .",
    "thus , each agent @xmath19 may directly communicate only with the agents in its neighborhood @xmath24 .",
    "note that agent @xmath6 is always contained in its own neighborhood .",
    "time - varying digraphs @xmath25 , for @xmath26 : if there exists a directed link from agent @xmath22 to @xmath6 at time @xmath15 ( which we denote by @xmath27 ) , agent @xmath22 may send its information to agent @xmath6 .",
    "we use the notation @xmath28 and @xmath29 to denote the in and out neighbors of agent @xmath6 at time @xmath15 , respectively .",
    "that is , @xmath30 @xmath31 in this case , we assume that there always exists a self - loop @xmath32 for all agent @xmath19 . therefore , agent @xmath6 is always contained in its own neighborhood . also , we use @xmath33 to denote the out degree of node @xmath6 at time @xmath15 .",
    "i.e. , @xmath34 we assume @xmath35-strong connectivity of the graphs @xmath36 with some scalar @xmath37 , i.e. , a graph with the following edge set @xmath38 is strongly connected for every @xmath26 .",
    "the network interacts with an environment according to the protocol shown in figure  [ fig : ogo ] .",
    "we leave the details of the signal generation process vague for the moment , except to note that the signals received by all agents at time @xmath15 may depend on all the information available up to time @xmath15 ( including @xmath39 , as well as all of the local information exchanged in the network ) .",
    "moreover , the environment may be adaptive , i.e. , the choice of the function @xmath40 may depend on all of the data generated by the network up to time @xmath15 .",
    "let us denote the network action at time @xmath15 by @xmath41 we consider the _ network regret _ : @xmath42 is the difference between the total cost incurred by the network at time @xmath1 and the smallest total cost that could have been achieved with a single action in @xmath43 in hindsight ( i.e. , with perfect advance knowledge of the sequence @xmath44 ) and without any restriction on the communication between the agents .",
    "the problem is to design the rule ( or policy ) each agent @xmath19 should use to determine its action @xmath45 based on the local information available to it at time @xmath15 , such that the regret in is ( a ) sublinear as a function of the time horizon @xmath1 and ( b ) exhibits `` reasonable '' dependence on the number of agents @xmath17 and on the topology of the communication graphs .",
    "we now introduce a generic algorithm for solving the decentralized online optimization problem defined in section [ sec : problem ] .",
    "the algorithm uses the dual - averaging subgradient method of nesterov @xcite as an optimization subroutine .",
    "we now present a basic regret bound that can be used for any generic algorithm of the form ( [ eqn : gdyn1])-([eqn : gdyn2 ] ) under the following assumption :    [ assume : lipschitz ] all functions @xmath46 are lipschitz continuous with a constant @xmath47 : @xmath48    [ thm : main ] let @xmath49 , @xmath19 , be the sequences of the agents primal iterates , let @xmath50 with @xmath51 be the sequence of the agents local updates , and let @xmath52 be generated as @xmath53 then , under assumption [ assume : lipschitz ] , the _ network regret _",
    "@xmath54 in ( [ eq : regret ] ) can be upper - bounded in terms of @xmath55 and @xmath56 as @xmath57 where @xmath58 is the diameter of the set  @xmath20 , and @xmath59 .    since @xmath60 is a continuous function on the compact set @xmath43 , @xmath61 by the weierstrass theorem .",
    "we can write @xmath62 where the second step follows from convexity of @xmath40 , while the last step uses the fact that all @xmath46 are @xmath47-lipschitz .",
    "we have the following for the first term in : @xmath63 where the equality follows from the definition of @xmath64 in ( [ eq : net - ac ] ) and @xmath65 .",
    "the second term in   can be further expanded as @xmath66 now , from relation ( [ eq : xu ] ) we obtain @xmath67 therefore , by ( * ? ? ?",
    "* lemma  3 ) , we can write @xmath68 for the second term on the right - hand side of , we have @xmath69 combining the estimates in eqs .  - and taking the supremum over all @xmath70 , we get the desired result .  @xmath71",
    "we now introduce a decentralized online optimization algorithm which uses a circulation - based framework for its dual update rule .",
    "we refer to this algorithm as * oda - c * ( online dual averaing with circulation - based communication ) .",
    "* oda - c * uses the network model ( g1 ) for its communication .",
    "fix a vector @xmath72 of positive weights and a nonnegative @xmath73 matrix @xmath74 , such that @xmath75 only if @xmath76 , satisfying the following symmetry condition : @xmath77 then , * oda - c * uses the following instantiation of the update rules in ( [ eqn : gdyn1])-([eqn : gdyn2 ] ) :    @xmath78\\label{eqn : dyn1}\\\\ \\xb_i(t+1 ) & = \\pi_{\\sx^n}^{\\psi } \\left(\\zb_i(t+1),\\alpha(t)\\right),\\label{eqn : dyn2}\\ ] ]    where @xmath79 represents a vector of messages transmitted by agent @xmath22 to agent @xmath6 , provided that @xmath76 .",
    "the dual update rule is inspired by the state dynamics proposed by li and marden @xcite , whereas the primal update rule is exactly what one has in nesterov s scheme  @xcite .    to complete the description of the algorithm",
    ", we must specify the update policies @xmath80 and the messages @xmath81 .",
    "we assume that all agents receive a complete description of @xmath40 .",
    "agent @xmath6 then computes @xmath82,~t\\ge 0.\\end{aligned}\\ ] ] and feeds this signal back into the dynamics ( [ eqn : dyn1 ] ) .",
    "note , however , that the execution of the algorithm will not change if the agents never directly learn the full function @xmath40 , nor even the full gradient @xmath83 , but instead receive the local gradient signal @xmath84 .",
    "the messages @xmath85 take the form @xmath86 for all @xmath15 and all agents @xmath87 .",
    "let @xmath88 our regret analysis rests on the following simple but important fact :    [ lm : mean_field ] the weighted sum @xmath89 evolves according to the linear dynamics @xmath90 where @xmath91 .",
    "we observe that the relation in   holds regardless of the choices of decisions @xmath92 and @xmath93 .",
    "moreover , we point out that if @xmath94 , then the combination of and will reduce to a centralized online variant of nesterov s scheme  @xcite .",
    "let @xmath95 denote the @xmath73 matrix with entries @xmath96_{ij } = v^k_{j\\to i}(t ) - v^k_{i \\to j}(t)$ ] . then @xmath97_{ij}\\right\\ }   \\\\      & = \\bz^k(t ) + u_k(t ) + \\tr [ \\tilde{m}v^k(t)],\\end{aligned}\\ ] ] where @xmath98 is an @xmath99 matrix with entries @xmath100 .",
    "since @xmath98 is a symmetric matrix , by , and @xmath95 is skew - symmetric , @xmath101 = 0 $ ] , so we obtain .",
    "@xmath71    we now particularize the bound in theorem [ thm : main ] to this scenario under the following additional assumption :    [ assume : lipgrad ] all functions @xmath46 are differentiable and have lipschitz continuous gradients with constant @xmath102 : @xmath103    [ thm : local_grad_signals ] under assumptions  [ assume : lipschitz][assume : lipgrad ] , the regret of any algorithm of the form ( [ eqn : dyn1])-([eqn : dyn2 ] ) , and with @xmath55 computed according to , can be upper - bounded as follows : @xmath104    the terms on the right - hand side of the bound in theorem [ thm : main ] can be further estimated as follows . since each @xmath105 is @xmath47-lipschitz , @xmath106 it remains to estimate term ( e3 ) in theorem [ thm : main ] .",
    "to that end , we write @xmath107 where we have exploited the fact that the gradients of all @xmath46 are @xmath102-lipschitz .    now , by construction , @xmath108 where the last step follows from the fact that the map @xmath109 is @xmath110-lipschitz ( see , e.g. , ( * ? ? ? * lemma  1 ) ) . substituting these estimates into the bound in theorem [ thm : main ]",
    ", we get the result .",
    "@xmath71    [ cor : regret_bound ]",
    "suppose that the policies for computing @xmath80 and @xmath111 are such that , for all @xmath15 and for any sequence @xmath112 , @xmath113 for some finite constant @xmath114 ( which may depend on @xmath17 and on other problem parameters ) .",
    "then , the regret of the algorithm ( [ eqn : dyn1])-([eqn : dyn2 ] ) is bounded by @xmath115\\sum^t_{t=1}\\alpha(t-1 ) + \\frac{c}{\\alpha(t)}.      \\end{aligned}\\ ] ]    in particular , if we choose @xmath116 for @xmath117 , then the regret is @xmath0 : @xmath118 \\sqrt{t } + c\\sqrt{t+1 } .\\end{aligned}\\ ] ]      the conditions we have imposed on the pair @xmath119 are equivalent to saying that @xmath74 is the transition probability matrix of a reversible random walk on @xmath120 with invariant distribution @xmath72 @xcite .",
    "[ lem : disagree ] for the policy in - we have @xmath121 for every @xmath26 , where @xmath122 is of the vector @xmath123 , and where @xmath124 denotes the spectral gap of @xmath74 @xcite , i.e. , @xmath125    from @xmath126 thus , we upper - bound the quantity on the right - hand side .    from , we can rewrite the dynamics as @xmath127 by unrolling the dynamics and from time 0 to @xmath15 and recalling that @xmath128 for all @xmath6 , we obtain : @xmath129 we have @xmath130 note that @xmath131 . from ( [ eqn : zvec2 ] ) and ( [ eqn : zslr ] ) , we have @xmath132    by the properties of markov matrices  @xcite , for any @xmath123 , @xmath133 therefore , @xmath134 from relations ( [ eqn : dyn ] ) and ( [ eqn : right ] ) , we obtain @xmath135 where assumption  [ assume : lipschitz ] is used in the last inequality . from this and relation ,",
    "we obtain @xmath136 .",
    "@xmath71    by combining theorem [ thm : local_grad_signals ] and lemma [ lem : disagree ] , we can now provide a regret bound for * oda - c * :    [ thm : linear_ave ] @xmath137    with @xmath138 result follows .",
    "we now introduce another decentralized online optimization algorithm which uses the push - sum communication protocol for its dual update rule .",
    "we refer to this algorithm as * oda - ps * ( online dual averaing with push - sum based communication ) .",
    "* oda - ps * uses the network model ( g2 ) for its communication .      for * oda - ps",
    "* , each agent @xmath6 maintains an additional scalar sequence @xmath139 .",
    "then , this algorithm particularizes the update rule in ( [ eqn : gdyn1])-([eqn : gdyn2 ] ) as    @xmath140_{ij } w_j(t)\\label{eqn : algo1}\\\\ z_i^k(t+1 ) = ~ & n\\delta_i^ku_i(t ) + \\sum_{j=1}^n [ a(t)]_{ij } z_j^k(t ) , ~k\\in [ n]\\label{eqn : algo2}\\\\ \\xb_i(t+1 ) = ~ & \\pi^\\psi_{\\sx^n}\\paren{\\frac{\\zb_i(t+1)}{w_i(t+1)},\\a(t)}\\label{eqn : algo3}\\end{aligned}\\ ] ]    where the weight matrix @xmath141 is defined by the out - degrees of the in - neighbors , i.e. , @xmath142_{ij } = \\left\\ { \\begin{array}{ll } 1/d_j(t ) & \\text{whenever } j \\in \\nin(t)\\\\ 0 & \\text{otherwise . } \\end{array } \\right.\\ ] ] the matrix @xmath141 is column stochastic by construction .",
    "note that the above update rules are based on a simple broadcast communication .",
    "each agent @xmath6 broadcasts ( or _ pushes _ ) the quantities @xmath143 and @xmath144 to all of the nodes in its out - neighborhood @xmath145 .",
    "then , in - each agent simply _ sums _ all the received messages to obtain @xmath146 and @xmath147 . the update rule can be executed locally .    to complete the description of the algorithm",
    ", we must specify the update policies @xmath80 . as in * oda - c",
    "* , we assume that the signal agent @xmath6 gets from the environment at time @xmath15 is simply the @xmath6-th coordinate of the gradient of @xmath40 at the agent s primal variable @xmath148 .",
    "thus , we define : @xmath149,~t\\ge 0,\\ ] ] i.e. , the update performed by agent @xmath6 at time @xmath15 is the simply the @xmath6-th coordinate of the gradient of @xmath40 at the agent s primal variable @xmath148 .",
    "we assume that each agent @xmath6 initializes its updates with @xmath150 and @xmath151 , while @xmath152 can be any arbitrary value in @xmath153 .",
    "we also recall that the local action of agent @xmath6 at time @xmath15 is given by the @xmath6th coordinate of @xmath148 , i.e. , @xmath154 for notational convenience , let us denote the products of the weight matrices @xmath155 by @xmath156 , i.e. , @xmath157 also , we denote @xmath158      for the regret analysis , we first study the dynamics of the dual iterates @xmath159 and its `` mean field '' @xmath160 in the following lemma . we remind that @xmath161 and @xmath162.\\end{aligned}\\ ] ]    [ lem : zbar ] let @xmath128 for all @xmath19 .    *",
    "the weighted sum @xmath163 evolves according to the linear dynamics @xmath164 where @xmath165 . * for any @xmath166 $ ] , the iterates in ( [ eqn : algo2 ] ) evolve according to the following dynamics @xmath167_{ik } u_k(s).\\ ] ]    * from relation ( [ eqn : algo2 ] ) , we have for all @xmath168 $ ] @xmath169_{ij}z_j^k(t)\\right]\\\\ = & ~u_k(t ) + \\frac{1}{n}\\sum_{j=1}^n z_j^k(t)\\sum_{i=1}^n[a(t)]_{ij}\\\\ = & ~u_k(t ) + \\bar{z}^k(t),\\end{aligned}\\ ] ] where the last equality follows from the column - stochasticity of the matrix @xmath141 .",
    "the desired result follows by stacking up the scalar relation above over @xmath170 .",
    "* by stacking up the equation ( [ eqn : algo2 ] ) over @xmath6 , we have for all @xmath26 and @xmath168 $ ] @xmath171 by unrolling this equation from time 0 to @xmath15 , we obtain @xmath172 where the equalities follows from @xmath173 and the initial condition @xmath128 for all @xmath19 .",
    "we get the desired result by taking the @xmath6-th component of this vector .",
    "@xmath71    we now particularize the bound in theorem [ thm : main ] in this scenario under the additional assumption on the lipschitz continuous gradients ( assumption [ assume : lipgrad ] in section [ sec : algo - regret ] ) .",
    "[ thm:4 ] under assumptions [ assume : lipschitz]-[assume : lipgrad ] , the regret of the algorithm ( [ eqn : algo1])-([eqn : algo3 ] ) with the local update @xmath174 of agent @xmath6 computed according to ( [ eqn : policy1 ] ) can be upper - bounded as follows : for all @xmath175 , @xmath176    since the definition of @xmath55 in * oda - ps * ( cf .",
    "eq . ) coincides with that in * oda - c * ( cf .",
    ", we can reuse all the derivations in the proof of theorem [ thm : local_grad_signals ] except for the network - wide disagreement term : @xmath177 where the last inequality follows from the @xmath110-lipschitzian property of the map @xmath109 ( * ? ? ?",
    "* lemma  1 ) .",
    "@xmath71      we now show that the network - wide disagreement term in theorem [ thm:4 ] is indeed upper - bounded by some constant . for doing this , we first restate a lemma from @xcite .",
    "[ lem : no ] let the graph sequence @xmath178 be @xmath35-strongly connected",
    ". then the following statements are valid .",
    "* there is a sequence @xmath179 of stochastic vectors such that the matrix difference @xmath180 for @xmath181 decays geometrically , i.e. , for all @xmath182 $ ] .",
    "@xmath183_{ij}-\\phi_i(t ) } \\le",
    "\\beta\\t^{t - s } \\quad \\text{for all } t \\ge s \\ge 0,\\ ] ] where we can always choose @xmath184 if in addition each @xmath36 is regular , we may choose @xmath185 or @xmath186 whenever @xmath187 .",
    "* the quantity @xmath188_i}\\ ] ] satisfies @xmath189 moreover , if the graphs @xmath36 are regular , we have @xmath190 .",
    "the next lemma provides an upper - bound for @xmath191 .",
    "[ lem : network ] let the sequences @xmath192 and @xmath193 be generated according to the algorithm ( [ eqn : algo1])-([eqn : algo2 ] ) . recall that @xmath194 .",
    "then , we have for all @xmath26 , @xmath195 where the constants @xmath196 , @xmath197 and @xmath198 are as defined in lemma [ lem : no ] .    from the definitions of @xmath159 , @xmath160 and @xmath199",
    ", we have @xmath200 thus , we can upper - bound the quantity on the right - hand side .    by inspecting equation ( [ eqn : algo1 ] ) , it is easy to see that for any @xmath19 and @xmath26 , we have @xmath201_{i\\ell } w_i(0 ) = \\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell}.\\ ] ] from this and lemma [ lem : zbar ] , we have the following chain of relations : @xmath202_{ik}u_k(s)}{\\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell } } - \\sum_{s=0}^{t-1}u_k(s)\\nonumber\\\\ ~= & \\sum_{s=0}^{t-1}u_k(s)\\frac{\\sum_{\\ell=1}^n[a(t-1:s+1)]_{ik}-\\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell}}{\\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell}}\\nonumber\\\\ ~\\le & \\sum_{s=0}^{t-1}u_k(s ) \\bigg(\\frac{\\sum_{\\ell=1}^n\\left([a(t-1:s+1)]_{ik}-\\phi_i(t-1)\\right)}{\\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell } } \\nonumber\\\\ ~ & + \\frac{\\sum_{\\ell=1}^n\\left(\\phi_i(t-1)-[a(t-1:0)]_{i\\ell}\\right)}{\\sum_{\\ell=1}^n[a(t-1:0)]_{i\\ell}}\\bigg ) \\nonumber\\\\ ~\\le & \\sum_{s=0}^{t-1}u_k(s ) \\frac{\\beta\\t^{t - s-2}+\\beta\\theta^{t-1}}{\\gamma},\\end{aligned}\\ ] ] where the inequalities follow from adding and subtracting @xmath203 and from lemma [ lem : no ] . from relation ( [ eqn : policy1 ] )",
    ", we have @xmath204 combining this and the fact that @xmath205 for all @xmath206 , we further have @xmath207 substituting this estimate in relation , we get the desired result .",
    "@xmath71    by combining theorem [ thm:4 ] and lemma [ lem : network ] , we can now provide the regret bound of * oda - ps * :    [ thm : linear_ave2 ] @xmath208 where the constants @xmath196 , @xmath197 and @xmath198 are as defined in lemma [ lem : no ] .    by jensen s inequality ,",
    "we have @xmath209 hence , using lemma [ lem : network ] , we can estimate the network - wide disagreement term as follows : @xmath210 thus , the conditions of corollary [ cor : regret_bound ] with this modified network - wide agreement hold with @xmath211 and the stated result follows .",
    "consider the problem of estimating some target vector @xmath212 using measurements from a network of @xmath17 sensors .",
    "each sensor @xmath6 is in charge of estimating a subvector @xmath213 of @xmath7 , where @xmath214 and @xmath215 is some very large number .",
    "an example includes the localization of multiple targets , where in this case @xmath212 becomes a stacked vector of all target locations .",
    "when there are a number of spatially dispersed targets , we can certainly benefit from distributed sensing .",
    "the sensors are assumed to have a linear model of @xmath216 , where @xmath217 and @xmath218 . at each time @xmath15 , each sensor @xmath19 estimates its portion @xmath219 of the target vector @xmath212 , and then takes a measurement @xmath220 , which is corrupted by observation error and possibly by modeling error .",
    "we assume all sources of errors can be represented as an additive noise , i.e. , @xmath221 where @xmath222 with @xmath223 is a stacked vector of all @xmath224 s and @xmath225 , where @xmath226 is the noise covariance matrix .",
    "the regret is computed with respect to the least - squares estimate of the target locations at time @xmath1 , i.e. , @xmath227 where @xmath228 and we set @xmath229 $ ] .    for * oda - c * , we experiment with a @xmath230 node cycle graph whose communication topology is given as : @xmath231 we set @xmath232 , @xmath233 for all @xmath6 , and @xmath234 if @xmath23 . for * oda - ps * , we experiment with a time - varying sequence of digraphs with @xmath230 nodes whose communication topology is changing periodically with period @xmath235 .",
    "the graph sequence is , therefore , @xmath235-strongly connected . in figure",
    "[ fig : graph ] , we depict the repetition of the 3 corresponding graphs . the averaging matrices @xmath141 ( cf .",
    "can be determined accordingly .",
    "we ran our algorithms once for each @xmath236 $ ] .",
    "that is , for a given @xmath1 , the iterates in the algorithms are updated from @xmath237 to @xmath238 .",
    "we used step size @xmath239 for both algorithms .    ]     vs. iterations for online distributed active sensing using * oda - c * ( left ) and * oda - ps * ( right ) [ fig : sensing],title=\"fig : \" ]   vs. iterations for online distributed active sensing using * oda - c * ( left ) and * oda - ps * ( right ) [ fig : sensing],title=\"fig : \" ]    in figure [ fig : sensing ] , we depict the average regret @xmath240 over time @xmath1 of the distributed sensing problem when * oda - c * and * oda - ps * are used , respectively .",
    "it shows that the regret is sublinear for both algorithms and the average @xmath240 goes to zero as the time increases .",
    "we have studied an online optimization problem in a multiagent network .",
    "we proposed two decentralized variants of nesterov s primal - dual algorithm , namely , * oda - c * using circulation - based dynamics for time - invariant networks and * oda - ps * using broadcast - based push - sum protocol for time - varying networks .",
    "we have established a generic regret bound and provided its refinements for certain information exchange policies .",
    "the regret is shown to grow as @xmath0 when the step size is @xmath241 . for * oda - c * , the bound is valid for a static connectivity graph and a row - stochastic matrix of weights @xmath242 $ ] which is reversible with respect to a strictly positive probability vector @xmath243 . for * oda - ps * , the bound is valid for a uniformly strongly connected sequence of digraphs and column - stochastic matrices of weights @xmath141 whose components are based on the out - degrees of neighbors .",
    "simulation results on a sensor network exhibit the desired theoretical properties of the two algorithms .",
    "a.  martinoli , f.  mondada , g.  mermoud , n.  correll , m.  egerstedt , a.  hsieh , l.  parker , and k.  stoy , _ distributed autonomous robotic systems_. 1em plus 0.5em minus 0.4emspringer tracts in advanced robotics , springer - verlag , 2013 .",
    "chang , a.  nedi , and a.  scaglione , `` distributed constrained optimization by consensus - based primal - dual perturbation method , '' _ ieee transactions on automatic control _",
    "59 , pp . 15241538 , 2014 .",
    "s.  s. ram , a.  nedi , and v.  v. veeravalli , `` distributed stochastic subgradient projection algorithms for convex optimization , '' _ journal of optimization theory and applications _ ,",
    "147 , pp . 516545 , 2010 .",
    "k.  tsianos , s.  lawlor , and m.  rabbat , `` consensus - based distributed optimization : practical issues and applications in large - scale machine learning , '' in _",
    "50th allerton conference on communication , control , and computing _ , 2012 , pp .",
    "15431550 .",
    "d.  jakovetic , j.  xavier , and j.  moura , `` cooperative convex optimization in networked systems : augmented lagrangian algorithms with directed gossip communication , '' _ ieee transactions on signal processing _ , vol .",
    "59 , pp . 38893902 , 2011 .",
    "j.  tsitsiklis , d.  bertsekas , and m.  athans , `` distributed asynchronous deterministic and stochastic gradient optimization algorithms , '' _ ieee transactions on automatic control _ ,",
    "31 , pp . 803812 , 1986 .",
    "f.  benezit , v.  blondel , p.  thiran , j.  tsitsiklis , and m.  vetterli , `` weighted gossip : distributed averaging using non - doubly stochastic matrices , '' in _ ieee international symposium on information theory proceedings ( isit ) _ , 2010 , pp .",
    "1753  1757 .",
    "m.  akbari , b.  gharesifard , and t.  linder , `` distributed subgradient - push online convex optimization on time - varying directed graphs , '' in _",
    "52nd allerton conference on communication , control , and computing _ , 2014 , pp .",
    "264269 .",
    "j.  c. duchi , a.  agarwal , and m.  j. wainwright , `` dual averaging for distributed optimization : convergence analysis and network scaling , '' _ ieee transactions on automatic control _ , vol .",
    "592606 , 2012 ."
  ],
  "abstract_text": [
    "<S> we consider a decentralized online convex optimization problem in a network of agents , where each agent controls only a coordinate ( or a part ) of the global decision vector . </S>",
    "<S> for such a problem , we propose two decentralized variants ( * oda - c * and * oda - ps * ) of nesterov s primal - dual algorithm with dual averaging . in * oda - c * , to mitigate the disagreements on the primal - vector updates , the agents implement a generalization of the local information - exchange dynamics recently proposed by li and marden @xcite over a static undirected graph . in * oda - ps * , the agents implement the broadcast - based push - sum dynamics @xcite over a time - varying sequence of uniformly connected digraphs . </S>",
    "<S> we show that the regret bounds in both cases have sublinear growth of @xmath0 , with the time horizon @xmath1 , when the stepsize is of the form @xmath2 and the objective functions are lipschitz - continuous convex functions with lipschitz gradients . </S>",
    "<S> we also implement the proposed algorithms on a sensor network to complement our theoretical analysis . </S>"
  ]
}