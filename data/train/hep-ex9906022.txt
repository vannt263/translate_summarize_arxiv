{
  "article_text": [
    "in the standard model , the flavor - changing neutral - current decays  and  are forbidden at tree level . denotes both @xmath4 and @xmath5 mesons . ] at the one - loop level , the decays are gim- and helicity - suppressed .",
    "thus the branching ratios are expected to be very small .",
    "lepton - family - number violating decays such as  are strictly forbidden .",
    "however , extensions of the standard model allow for both flavor - changing neutral currents and lepton - family - number violation , so detection of such dilepton decays could be taken as evidence for new physics  @xcite .",
    "previous experiments  @xcite have quoted limits of order @xmath6 to @xmath7 for several such decays . in this paper",
    "we describe an experiment that places limits between a few times @xmath8 and @xmath7 on the branching ratios for the decays ,  , and .",
    "experiment 789 was carried out in the meson east beam line at the fermi national accelerator laboratory , where a beam of 800 gev/@xmath0 protons was delivered to a fixed target of either gold or beryllium .",
    "the spectrometer , shown in figure  [ fig : spectrometer ] , was optimized for two - body final states with pair rapidity near zero in the center - of - mass system .",
    "its main components were a silicon - strip vertex detector ( ssd ) just after the target , a copper beam dump , two dipole bending magnets ( sm12 and sm3 ) , three stations of drift chambers and hodoscopes , a sampling calorimeter , and a muon - identification station located at the end of the spectrometer .",
    "the ring - imaging cherenkov detector was not used in this analysis .",
    "the target apparatus was installed in the beam vacuum .",
    "table  [ target_table ] gives the dimensions of the targets used for this analysis .",
    "the targets were much wider than the beam in the @xmath9 ( horizontal ) dimension but were narrow in the @xmath10 ( vertical ) dimension .",
    "the target centers were located at @xmath11  cm . here , the @xmath12 axis is the direction of the incident proton beam , and the origin of the right - handed coordinate system is centered at the upstream end of the sm12 yoke .",
    "beam intensity was measured using both an ion chamber and a secondary - emission monitor ,  sem , located upstream of the target .",
    "the fraction of beam striking the target was determined using an interaction monitor ,  amon , which was a scintillation - counter telescope perpendicular to the beam and viewed the target through a hole in the shielding cave .",
    "the targeting fraction varied from 30% to 40% depending on the running conditions ( see  @xcite for details ) .",
    "the ssd was located just downstream of the target and consisted of two arms , each containing eight planes of detectors ( see figure  [ fig : ssdpic ] ) .",
    "each 5-cm by 5-cm plane was a 300-@xmath13m - thick silicon - strip detector with 50-@xmath13 m strip pitch .",
    "the planes were arranged in two arms to cover vertical angles from 20 to 60  mr above and below the beam .",
    "each plane had one of three orientations , y , u , or v , with rotations about the @xmath12 axis of @xmath14 , @xmath15 , or @xmath16 , respectively .",
    "the sequence of orientations in each arm was y  u  y  v  y  u  y  v , proceeding downstream .",
    "a total of 8,544  strips were instrumented with amplifiers  @xcite , discriminators  @xcite , and latches  @xcite having @xmath1730-ns effective time resolution . to minimize secondary interactions , thermal fluctuations , and radiation - induced detector degradation , the ssd containment volume was temperature - controlled with a @xmath18c helium fill .",
    "table  [ ssdtab ] gives the configuration of the ssd planes .",
    "one 1-mm - thick scintillator , of dimensions 5  @xmath195  cm , was placed at the downstream end of each arm and was used for triggering .",
    "a water - cooled copper beam dump was located inside the sm12 magnet ( see figure  [ fig : beamdump ] ) .",
    "it prevented noninteracting primary protons and secondary particles of low transverse momentum from entering the downstream spectrometer .",
    "the tapered dump and the baffles on the inside walls of sm12 defined the spectrometer aperture .",
    "the two dipole magnets , sm12 and sm3 , served to focus charged particles of momenta within a desired range onto the downstream detectors .",
    "the magnetic fields of both magnets were carefully mapped with the fermilab ziptrack  @xcite , and the resulting profiles of the field were used in the data analysis .",
    "sm12 was a 1200-ton , 14.5-m - long , open - aperture dipole magnet .",
    "the horizontal aperture was tapered to provide a gradually decreasing magnetic field . at an operating current of 900  a",
    ", sm12 provided a vertical transverse impulse ( @xmath20 ) of 1.6  gev/@xmath0 , optimal for studying a decaying into two charged particles .",
    "the second bending magnet , sm3 , was located between tracking stations 1 and 2 .",
    "it was a 3.4-m - long , open - aperture magnet and provided a 0.91  gev/@xmath0 vertical @xmath20 impulse .",
    "it deflected charged particles in the opposite direction as sm12 , focusing them onto the subsequent detectors . in combination with the drift chambers sm3 provided momentum analysis for charged particles .",
    "three drift - chamber tracking stations were used to determine charged - particle trajectories through the spectrometer .",
    "each station consisted of three pairs of chambers , with the chambers in each pair offset by half a drift cell to resolve the  left - right \" tracking ambiguity .",
    "each pair was oriented in one of three views , y , u , and v , at @xmath14 , @xmath21 , and @xmath22 with respect to the @xmath10  axis .",
    "the drift gas was a 50/50 mixture of argon and ethane , with a 0.7% admixture of ethyl alcohol .",
    "each sense wire was connected to its own time - to - digital converter to measure the drift time of the ionization electrons .",
    "at operating voltages around 2000  v , the drift velocities averaged about 50  @xmath13m / ns .",
    "hodoscope planes at each tracking station provided fast coarse tracking information used in the trigger .",
    "stations 1 and 3 had both x and y hodoscope planes ( designated hy1 , hx1 , hy3 , hx3 ) , while station 2 had only a y plane ( hy2 ) .",
    "each hodoscope plane consisted of two half - planes of scintillation counters , whose light was collected using lucite light guides glued to hamamatsu  r329 photomultiplier tubes .",
    "sampling calorimeters were used to identify electrons and hadrons ( see figure  [ fig : cal ] ) .",
    "the electromagnetic section consisted of four lead / scintillator layers , e1 , e2 , e3 , and e4 , with thickness of 2 , 5 , 5 , and 6 radiation lengths , respectively .",
    "the total thickness of the electromagnetic section was 0.81 interaction length .",
    "each layer had separate left ( @xmath23 ) and right ( @xmath24 ) sections which were divided into twelve modules in @xmath10 .",
    "each of the resulting 96 modules was read out individually , with the analog signal from the scintillator converted to a digital signal using an 8-bit quadratic adc  @xcite .",
    "the hadronic section consisted of two iron / scintillator layers , h1 and h2 , of 2.14 and 5.84 interaction lengths respectively .",
    "the left and right segments of each were divided into thirteen modules in @xmath10 , giving a total of 52 modules .",
    "for details regarding the calibration of the calorimeters see @xcite .",
    "the muon station , located at the downstream end of the spectrometer , contained three planes of proportional - tube arrays and two planes of hodoscopes , interspersed with shielding .",
    "the proportional tubes , used in the trigger processor and for off - line muon identification , consisted of two planes of horizontal cells , pty1 and pty2 , for @xmath10 determination and one of vertical cells , ptx , measuring the @xmath9 coordinate .",
    "each plane was made of a series of two - layer aluminum extrusions , each containing fifteen 2.54  cm  @xmath25  2.54  cm cells .",
    "the layers were offset by half a cell width from each other .",
    "the cells were read out with latches , so no timing information was recorded .",
    "the gas mixture used was the same as in the drift chambers .",
    "the muon hodoscopes were used both for triggering and for particle identification .",
    "there were two planes , hy4 and hx4 , providing @xmath10 and @xmath9 information respectively .",
    "the calorimeter and additional zinc , lead , and concrete shielding comprised 16 interaction lengths of material between station 3 and the muon station .",
    "in addition , concrete absorbers interspersed among the muon detectors added approximately 5 more interaction lengths of shielding .",
    "the data - acquisition system  @xcite was based on the nevis laboratories data transport system  @xcite .",
    "event information from the front - end crates was buffered into multiport memory modules and supplied to the trigger processor  @xcite ( described in section  [ trigproc ] ) before readout to the vme - based archiving system , which recorded data on four exabyte 8200 tape drives .",
    "the system was capable of streaming approximately 1  mb / s to tape .",
    "once per spill , scalers were read out to record trigger rates and beam - intensity information with and without system deadtime .",
    "e789 utilized a three - level trigger system .",
    "level-1 triggers based on hodoscope information were ored together to form the trigger fan in ( tfi ) signal .",
    "events satisfying tfi were latched and fed to the  dc logic \" system , in which further logical requirements were imposed . in the dc logic , information from slower spectrometer components , such as the calorimeter , could be included .",
    "events satisfying the dc logic requirements produced the trigger generator output ( tgo ) signal , which vetoed the fast latch reset , preserving hit information for readout to the trigger processor . finally , the trigger processor examined hit patterns in the wire chambers , hodoscopes , calorimeter , muon detectors , and silicon detectors to enhance the fraction of events in the desired decay channels that contained decay vertices downstream of the target .",
    "events satisfying all three levels of trigger were written to tape .",
    "in addition , at each trigger level , some events were prescaled and forced through to the next level .",
    "the tfi had three main components , designed to trigger on pairs of charged particles from the target .",
    "the main pair trigger , @xmath26 , required at least two triple hodoscope coincidences in hy1 , hy2 , and hy3 , each corresponding to a different charged - particle trajectory from the target .",
    "as shown in figure  [ fig : matrix ] , these  trigger matrix \" coincidences were implemented as a look - up table , using fast ecl ram , that provided four independent output signals corresponding to hodoscope roads to the left or right of the @xmath12 axis and passing above or below the beam dump .",
    "at least two of these four outputs needed to fire to satisfy @xmath26 .    to allow sufficient redundancy for hodoscope and trigger efficiencies to be determined off - line ,",
    "additional triggers were implemented using majority logic on combinations of the six hodoscope planes hx1 , hy2 , hy3 , hx3 , hy4 , and hx4 .",
    "these were designated @xmath27 and @xmath28 .",
    "the notation @xmath27 represents a logical and of @xmath29 with @xmath30 .",
    "the component @xmath29 required that at least @xmath31 of hx1 , hy2 , hx4 and hy4 had hits to the left of the @xmath12 axis .",
    "likewise @xmath30 required at least @xmath31 from the same group to have hits on the right side .",
    "the trigger @xmath28 imposed a similar requirement except that planes hx1 , hy2 , hx3 , and hy3 were used . in the run with sm12 current set to 1000  a ,",
    "@xmath31 was set to 3 .",
    "it was changed to 4 in the 900a run .",
    "the dc logic , the second - level trigger , incorporated information from slower detectors whose use at the tfi stage would have imposed excessive deadtime . to reject tracks missing the ssd planes , signals from the scintillators behind the ssd arms , @xmath32 and @xmath33 , were required at this stage .",
    "veto signals ( @xmath34 and @xmath35 ) , formed by counting the number of hit counters in the hodoscopes hx1 and hx3 , were used to veto high - multiplicity events .",
    "the dc logic also included particle - identification components based on the calorimeter and the muon station .",
    "the various logic combinations were ored together to form the tgo signal .",
    "the dc logic event - identification requirements caused differences in acceptance for various types of events .",
    "the dimuon tgo component ( @xmath36 ) required that @xmath37 and @xmath38 be satisfied , that is , that two counters in each of the muon hodoscopes hx4 and hy4 register a hit .",
    "the calorimeter provided a sum of analog signals from the dynodes of the e2 and e3 photomultiplier tubes which was sensitive to electrons , and another sum based on signals from h1 , h2 , e1 and e4 for hadrons .",
    "each sum was discriminated with a low and a high threshold separately .",
    "the low threshold was set for detecting single particles and the high threshold for two - particle events .",
    "the discriminated signals @xmath39 , @xmath40 , @xmath41 , and @xmath42 represented the low and the high thresholds for the electromagnetic and hadronic energy sums respectively .",
    "table  [ trigtab ] lists the various logical combinations that together formed tgo .",
    "as shown in table  [ trigextab ] , the dc logic requirements reduced the trigger rate significantly relative to tfi .      if an event satisfied one of the dc logic triggers , the trigger processor then searched for tracks from the target using the drift - chamber information .",
    "only wire positions were used at this stage .",
    "track hypotheses were formed from hits in the y drift chambers in stations 1 , 2 , and 3 , masked by hodoscope and calorimeter or proportional - tube hits .",
    "these potential target tracks were then projected to the ssd , and used to identify ssd hits in the @xmath10-@xmath12 view for ssd trackfinding .",
    "ssd tracks formed from the masked hits were subjected to the requirement that the impact - parameter be more than 51  @xmath13 m from the center of the target , designed for finding tracks coming from @xmath43 decays occurring downstream of the target .",
    "the chosen tracks were then combined in up - down pairs to form vertices .",
    "a cut of 0.10  cm was made on the location of the vertex in @xmath12 to further increase the likelihood that the event contained a downstream decay .",
    "the trigger processor reduced the trigger rate by about an order of magnitude below the tgo rate .",
    "the triggers after processor ( tap ) was dominated by the dihadron trigger . during the  dedicated dilepton \" running period ,",
    "the dihadron trigger was prescaled by a factor of 32 and the proton intensity was increased to enhance the dilepton sensitivity .",
    "table  [ trigextab ] gives the average rates per spill for protons on target , tfi , tgo , and tap .",
    "data was taken initially with sm12 set at 1000 a and two different target materials for studying the nuclear dependence of proton - induced charm production  @xcite .",
    "subsequently data was collected at 900 a because of improved acceptance for detecting charm decay at this setting .",
    "three data sets are included in this analysis : 1000a - au , 900a - au , and 900a - be .",
    "each set was processed separately and each yielded an independent normalization signal in the  mode .",
    "( the latter part of the 900a - au sample , for which the dihadron trigger was prescaled as just described , is referred to as the dedicated - dilepton run , but it shared a common normalization signal with the rest of the 900a - au sample . )",
    "table  [ datatab ] gives the total number of protons on target for each sample , the number of @xmath44 counts .",
    "@xmath45 is _ true _ when the system is able to accept data .",
    "@xmath46 is thus a measure of the _ live time _ of the data acquisition and was typically about 50% . ]",
    "( number of live - time - corrected counts in the targeting monitor ) , and the number of triggers recorded on tape .",
    "to determine the branching ratios for , , and , we need the total number of @xmath43s produced , as measured by the decay mode @xmath47 , as well as the detection efficiency for each decay mode :    @xmath48    here @xmath49 is the number of @xmath50 events seen , @xmath51 is the number of  events , @xmath52 is the efficiency for observing a @xmath50 event , @xmath53 is the efficiency for observing a  event , @xmath54 ) @xmath55 is the branching ratio for decay  @xcite , and @xmath56 is the relative efficiency . using  as a normalization mode allowed partial cancellation of many common correction factors in the efficiency ratio .",
    "with a total nuclear inelastic cross section per nucleon of 17  mb for beryllium and an inclusive production cross section of @xmath57b at @xmath58  gev @xcite , a branching ratio @xmath59 of @xmath60 implies a search for one normalization event per ten thousand interactions . in this experiment , with an average decay distance of @xmath61  mm ( corresponding to an average momentum of 56  gev/@xmath0 ) , precise reconstruction of the decay vertex in the ssd",
    "is a powerful tool to separate decays from background processes that occur in the target .",
    "the ssd allowed precise reconstruction of the decay distance and the impact parameter for each track .",
    "the impact parameter could be used to eliminate tracks from the target and thus reduce the background significantly .      in the first pass of data processing particle trajectories in both the downstream spectrometer and the ssd",
    "were reconstructed from the raw data .",
    "downstream track reconstruction began by finding hit clusters in the drift chambers .",
    "track segments formed in stations 2 and 3 were projected to station 1 for confirmation that the track came from the target and not the beam dump .",
    "an 18-plane ( 3 stations with 6 chambers each ) least - squares fit was performed .",
    "the track momentum was determined from the bend angle through sm3 .",
    "the momentum resolution of the spectrometer was found to be @xmath62 = @xmath63 , where @xmath64 is the momentum of a track and @xmath65 is the statistical uncertainty .",
    "the track was then traced back iteratively through sm12 , through the ssd , to the target . on the first iteration",
    "the track was traced from sm3 to the @xmath12 location of the target center .",
    "candidate tracks falling within an aperture of @xmath66  cm from the target center in @xmath9 and @xmath10 were kept . in subsequent iterations ,",
    "the track parameters were adjusted so that the track traced back to the target center .",
    "after downstream tracking , all track segments in the ssd were reconstructed . in each of the ssd arms ,",
    "the four y planes were used first .",
    "the preliminary @xmath10-@xmath12 tracks were then employed to define windows in the u and v planes for selecting hits that were used to form ssd tracks in the @xmath9-@xmath12 view . those ssd tracks with enough hits in the y , u and v views were fit to straight lines in three dimensions .",
    "the resolution of the impact parameter in @xmath10 was determined to be @xmath67 m .    for each event",
    ", each opposite - sign pair of downstream tracks was reconstructed as though they decayed from a single parent through each of the decay modes , , , and . for at least one of these modes ,",
    "the resulting invariant mass was required to fall within a 500  mev/@xmath68 window extending from 1.65  gev/@xmath68 to 2.15  gev/@xmath68 .",
    "in addition , events were required to have at least one opposite - sign pair of ssd tracks that formed a vertex with @xmath12 location outside a @xmath69  mm window centered at the target .",
    "since the resolution of the vertex in @xmath12 was about 0.7 mm , this requirement rejected a significant fraction of the dihadron events originated from the target but still retained about 50% of the @xmath4 decays .",
    "this pass provided a four - to - one data reduction from the raw data .      in this pass , to further reduce the number of unwanted ssd tracks , the @xmath10 hits , @xmath10-@xmath12 and @xmath9-@xmath12 angles of the ssd tracks were required to be within @xmath70 cm , @xmath71  mr and @xmath72  mr respectively from the projections of the downstream tracks at the ssd .",
    "figures  [ fig : yssdmatch ] and [ fig : yxangmatch ] show the matching in @xmath10 and in track angles respectively , before the cuts , for events with only one ssd track in either arm .",
    "the matched ssd tracks , one from each arm , were combined to form pairs .",
    "the  was minimized for each pair by adjusting the vertex location and the track orientation .",
    "the downstream tracks were then iteratively traced back to the decay vertex as determined by the ssds to improve the resolution of the track angles .",
    "the requirement on the invariant mass of the event was tightened to a 200  mev/@xmath68 window about the mass ( 1.864  gev/@xmath68  @xcite ) for at least one of the modes .",
    "this second pass provided another factor of five reduction of the data set .",
    "the alignment of the ssd was refined in this pass .",
    "the change in the alignment constants was insignificant .",
    "at this point , some of the events still contained multiple vertices that resulted either from multiple pairs of downstream tracks or from multiple ssd tracks matching a single downstream track .",
    "events were then excluded if more than four ssd tracks matched either downstream track or more than ten vertices were reconstructed . to select the proper vertex in the surviving events ,",
    "the quality of each vertex was evaluated using nine parameters .",
    "the value of each parameter was converted to a probability , with the overall probability taken as the product of the nine probabilities .",
    "the nine parameters were :    * @xmath73 for reconstructing each ssd track .",
    "( _ 2 parameters _ ) * @xmath73 for the ssd vertex - constrained fit .",
    "( _ 1 parameter _ ) * @xmath10-angle match between each downstream track and its ssd track .",
    "( _ 2 parameters _ ) * @xmath9-angle match between each downstream track and its ssd track .",
    "( _ 2 parameters _ ) * @xmath73 for the position difference between the projection of each downstream track and the ssd hit at each ssd plane . (",
    "_ 2 parameters _ )    events with only one ssd track in an arm were used to obtain the standard deviations of the distributions for the @xmath9 and @xmath10 angle matching , as 0.95  mr and 0.25  mr respectively .",
    "only the vertex with the highest overall probability , along with the associated ssd tracks and downstream tracks , was employed in the subsequent analysis .    in the final stage of event selection , a fully reconstructed event consisted of one opposite - sign pair of ssd tracks that matched one pair of downstream tracks .",
    "the most effective variable to optimize the  signal was the impact parameter of each ssd track with respect to the target center in @xmath10 before the vertex - constrained fit .",
    "incorrectly reconstructed events often contained at least one track originating in the target that was thus reconstructed with small impact parameter .",
    "in addition , a cut was made on the lifetime  significance , defined as the ratio of the @xmath12 location of the vertex to the average decay distance of the @xmath43 in the laboratory frame , @xmath74 .",
    "tables  [ mumucuts ] ,  [ eecuts ] and [ muecuts ] summarize the requirements on the impact  parameter and lifetime  significance for all data sets .",
    "electrons and hadrons were identified using the calorimeter . the identification procedure included two requirements : first ,",
    "that energy deposited in the calorimeter match a track , and second , that the profile of the energy deposition in the calorimeter be consistent with either a hadron or an electron .    for each event , the adc counts of all calorimeter modules were converted to energy .",
    "the reconstructed particle trajectory was then projected through each layer of the calorimeter . at each layer , the energies deposited in the module on the trajectory and in its nearest neighbors were summed .",
    "a correction was applied for attenuation of scintillation light in the @xmath9 ( readout ) direction .",
    "if the track had no other track within two modules at each longitudinal layer , it was considered isolated and its total energy as well as the  em fraction \" was recorded .",
    "the em fraction is the amount of energy deposited in the electromagnetic portion of the calorimeter divided by the total deposited energy .",
    "the energy resolution of the calorimeter was derived from the ratio of the deposited energy in the calorimeter to the magnetically - measured momentum of isolated tracks ( @xmath75 ) .",
    "distributions were energy - dependent with various mean and @xmath65 .",
    "these differences were taken into account in the analysis as described in @xcite . ] for the hadronic part of the calorimeter , the resolution was @xmath65/@xmath40 = -0.018 + 0.91/@xmath76 .",
    "the energy resolution of the electromagnetic calorimeter was measured to be @xmath65/@xmath40 = -0.04 + 0.79/@xmath76 .    for an isolated track ,",
    "the particle associated with the track was labeled as an electron if the em fraction was @xmath77 and the @xmath75 of the track was within 2.58@xmath65 from the mean of the @xmath75 distribution for that energy bin .",
    "a separate study , using @xmath78 decays from data collected in an adjacent running period , found this cut to be @xmath79 efficient  @xcite .",
    "for hadrons , the em fraction was required to be less than 0.7 and the 2.58@xmath65 @xmath75 cut was used .",
    "if two non - muon tracks shared at least one module ( which happened quite rarely ) , they could often be identified using the energy deposition in each section ( em and hadronic ) of the calorimeter separately . the procedure for identifying the overlapping tracks",
    "is described in @xcite .",
    "muon identification depended primarily on the muon station .",
    "a track was projected to the muon station and each detector plane was checked to see if there were hits in momentum - dependent hit windows .",
    "the windows , 3@xmath65 wide , were determined from fits to residual distributions with respect to the projected track . for a track to be categorized as a muon candidate , hits matching the projected track were required in both muon hodoscope planes and in at least two proportional - tube planes .",
    "the hodoscopes had a time resolution better than one 19-ns accelerator - rf bucket . requiring them to have hits dramatically reduced the number of out - of - time tracks .",
    "in addition to the muon station , the calorimeter was also employed for muon identification .",
    "99.99% of muons under 100  gev/@xmath0 left less than 35% of their energy in the calorimeter .",
    "if a track passed the muon hit criteria and had @xmath75 greater than 35% , it was tagged as ambiguous but still counted as a potential muon . the most likely mechanism for muons to have high @xmath75 was for them to overlap with a non - muon track in the calorimeter .",
    "to remove fake dimuon events due to a non - muon overlapping with a muon , an isolation requirement was applied . in this case , each track in the reconstructed dimuon was required to have unique muon - hodoscope hits and no more than one proportional - tube plane could contribute a shared hit .",
    "it is necessary to calculate the ratio of ( acceptance @xmath25 efficiency ) for each dilepton decay to that for the normalization decay .",
    "this relative acceptance depends on both the kinematics and particle types in each decay mode .",
    "while track - reconstruction efficiencies cancel in the ratio , trigger and particle - identification efficiencies do not and are determined as described below .",
    "the monte carlo ( mc ) program , incorporating trigger and particle - id information , was used to generate events in each dilepton mode as well as the normalization mode .",
    "the mc used the same alignment constants and magnetic field maps as the data analysis .",
    "multiple scattering including non - gaussian tails was also included in the simulation .",
    "detector efficiencies were included , and noise hits in the silicon detectors ( extracted from data ) were added to each generated event .",
    "the production of @xmath43 by an 800-gev proton beam was simulated with a longitudinal fractional - momentum ( @xmath80 ) distribution of the form @xmath81",
    "the transverse - momentum ( @xmath82 ) distribution was characterized as @xmath83 with @xmath84  @xcite .",
    "each two - body @xmath4 decay was generated with a uniform angular distribution in the rest frame of the @xmath4 .",
    "after boosting to the laboratory frame , the decay products ( @xmath85 ) were traced through the simulated geometry of the spectrometer .",
    "kaon decay was also included in the monte carlo .",
    "each event that passed the geometric restrictions was required to satisfy the trigger as modeled for the decay of interest .",
    "figure  [ fig : mcptxfpz ] shows the generated and accepted distributions in @xmath82 , @xmath80 , and momentum of the @xmath4 in the laboratory frame at 900  a. with the kinematics of each decay properly modeled , the acceptances were calculated using 40,000 monte carlo events that passed the geometric cuts for each mode .",
    "muons were identified primarily using the muon hodoscopes and proportional tubes .",
    "the efficiency of each proportional - tube plane was determined separately from data and then included in the monte carlo simulation .",
    "each muon selected for the efficiency study satisfied the muon identification requirements as described in section  [ muid ] .",
    "this study determined the average efficiencies of the proportional - tube planes to be 95% , 98% , and 95% for y1 , x , and y2 respectively .",
    "the only component of the dimuon trigger that was not included in the dihadron trigger was the requirement of hits in at least two of the four quadrants ( upper - left , upper - right , lower - left , and lower - right ) in both hx4 and hy4 .",
    "determining the dimuon efficiency thus required an unbiased study of the muon - hodoscope efficiencies .",
    "a muon sample was chosen by selecting events that satisfied the calorimeter trigger and included at least one reconstructed muon , selected by requiring hits in at least two of the three proportional - tube planes and at least one muon hodoscope plane .",
    "the window for finding the hodoscope hit was identical to the momentum - dependent window of the nearest proportional - tube plane .",
    "the requirement of a muon hodoscope plane , whose timing had single - bucket resolution , assured that the muon was indeed associated with the triggered event .",
    "the efficiency of each hodoscope plane was then determined by recording the fraction of events for which the hodoscope that was not used in the muon - selection process fired .",
    "the efficiencies of hx4 and hy4 were determined to be 95% and 92% respectively , independent of muon momentum .",
    "these efficiencies were then included in the mc simulation .    to avoid misidentification from overlapping tracks , an isolation criterion using the proportional tubes was applied .",
    "the trigger requirement already isolated the tracks such that the additional proportional - tube isolation criterion reduced the efficiency by only 7% while reducing the background significantly .",
    "the overall dimuon efficiency was 36% at 900  a and 50% at 1000  a.      the efficiency of detecting the  decay relative to that for the dilepton modes is dominated by the efficiency of the @xmath42 trigger component , which required a significant amount of energy deposited in the calorimeter .",
    "an unbiased sample of events passing the tfi trigger was employed for studying the @xmath42 efficiency . each event in this  prescaled - tfi \" sample had two hadron tracks with a reconstructed @xmath86 invariant mass in a 500-mev/@xmath68 window about the mass .",
    "the momentum range of the selected events was similar to that of the accepted  events .",
    "the fraction of the prescaled - tfi events that fired the dihadron trigger was then plotted as a function of the total momentum in 2  gev/@xmath0 bins .",
    "figure  [ fig : hhturnon ] shows the efficiency of the dihadron trigger as a function of momentum and the fit thereto by a third - order polynomial .",
    "this efficiency curve was then input to the monte carlo .",
    "the average dihadron trigger efficiency for  events that passed the geometric acceptance of the mc was 55% at 900  a and 58% at 1000  a.    the energy deposition of hadrons in each section of the calorimeter was also included in the mc simulation . to enhance the certainty of hadron identification",
    ", the em fraction of the mc events was required to be less than 70% .",
    "this cut accepted over 92% of hadrons .",
    "furthermore , the @xmath75 of the particle was required to fall within @xmath872.58@xmath65 of the mean .",
    "kaon decay before station 4 could cause the event to be misidentified or could cause the reconstructed invariant mass to drop out of the mass window .",
    "about 20% of  events were lost due to kaon decay .",
    "the trigger efficiency for the decay  relative to  was dominated by the @xmath40 trigger component . as discussed in section  [ dclogic ] , @xmath40",
    "was used for finding dielectron events while @xmath39 was used for single - electron events . the same prescaled - tfi sample used for the dihadron - trigger - efficiency study",
    "was used to determine the efficiency of the @xmath40 trigger .",
    "the energy - sum signal of layers e2 and e3 , e@xmath88 , was digitized by an adc for off - line study .",
    "an efficiency curve as a function of the e@xmath88-adc count was determined and then included in the monte carlo .",
    "data events with an em fraction greater than 0.95 and with tracks isolated in the calorimeter were used to determine the energy deposited in e2 and e3 as a function of momentum .",
    "when an electron was generated from the  decay , the energy that the electron deposited in the e2 and e3 calorimeter layers was generated based on the momentum - dependent ( e2+e3)/@xmath64 distribution .",
    "once the e2+e3 energy stored was determined , an adc count was generated according to the e@xmath88-to - adc curve .",
    "figure  [ fig : eeturnon ] shows the dielectron efficiency as a function of the monte - carlo generated momentum .",
    "the final trigger efficiency for  events that passed the monte carlo geometric cuts was determined to be 60% for both 900a and 1000a runs .      to find the efficiency for  relative to , we used the techniques and tools developed for the  and  efficiency analyses . to adapt to a single - muon event , we used a simple 2-hodoscope requirement for the trigger , and demanded 2 out of 3 proportional - tube planes to have hits .",
    "the single electron was treated in a similar manner as the dielectron , the only difference being that the low - energy threshold ( see section [ eeeff ] ) required a different trigger - efficiency - to - adc mapping . as in the dielectron case ,",
    "the generated electron was required to pass the geometric cuts of the monte carlo .",
    "figure  [ fig : elowturnon ] shows the turn - on curve for the single - electron trigger as a function of the monte - carlo generated momentum .",
    "the resulting single - electron efficiency was 48% , and the single - muon efficiency was 74% , yielding a combined efficiency of 36% for the 900a and 1000a runs .",
    "an event was labeled as a  candidate if it was reconstructed as a dihadron event , satisfied the dihadron trigger , and passed the impact - parameter and proper - lifetime requirements that were applied to the dilepton decay .",
    "there was no mechanism to distinguish kaons from pions .",
    "however , by monte carlo simulation we determined that the invariant - mass distribution of  events with incorrect particle assignments was much wider than that with the correct assignments , 7.1 times as wide for the 900a data sets and 5.4 times as wide for the 1000a set ( see figure  [ fig : mcmass ] ) . for each event ,",
    "the invariant mass was thus computed once as @xmath89 and once as @xmath90 .",
    "the invariant - mass distribution was then fit to a quadratic polynomial for the background and a double gaussian in the signal region .",
    "the standard deviation and normalization were allowed to vary for the narrow gaussian , but the width and relative height of the wide gaussian were constrained to the monte carlo values .",
    "this condition ensured that the numbers of events under the two gaussian distributions be identical .",
    "in addition , both gaussians were required to have the same mean mass .",
    "the fit was performed using paw  @xcite .",
    "the covariance matrix for the width and normalization of the narrow gaussian was then used to find the absolute error associated with the number of reconstructed  decays .",
    "tables  [ mumunorm ] , [ eenorm ] , and [ muenorm ] give the mean mass , the mass resolution and the total number of  events without any mass cut for each data set .",
    "each data set listed in table  [ datatab ] was analyzed independently . when the impact - parameter and lifetime - significance cuts ( see tables  [ mumucuts ] ,  [ eecuts ] and [ muecuts ] ) were applied to the dilepton data sample , as shown in figures  [ fig : au900mumu]-[fig : be900mue ] ,",
    "no event was found in the signal region , defined as the interval in dilepton invariant mass within which the signal events were counted .",
    "this interval was @xmath91@xmath65 wide and centered at the mean of the @xmath86 invariant mass of the corresponding normalization sample .",
    "since the mass resolution depended on the final - state particles , a different @xmath65 was used for each dilepton decay as computed by mc and tabulated in table  [ relwidth ]",
    ".      tables  [ tabdkpieff ] through  [ tabdmueeff ] give the various contributions to the acceptance@xmath25efficiency for the normalization mode and each signal mode , together with their errors as estimated in section  [ systematic ] below .",
    "for each dilepton mode the 900a - au , 900a - au - dedicated - dilepton , 900a - be , and 1000a - au data sets were combined to give the branching ratio @xmath92 where @xmath93 runs over the three data sets , @xmath94 is the number of counts in the signal region in the dilepton - invariant - mass distribution , @xmath95 is the efficiency for the dilepton mode given in tables  [ tabdmumueff ] ,  [ tabdeeeff ] and [ tabdmueeff ] relative to that for the normalization mode in table  [ tabdkpieff ] , and @xmath96 is the number of observed @xmath86 events in the signal region .    with",
    "no signal observed , the upper limit on the branching ratio was determined using the monte carlo method .",
    "a series of branching ratios were calculated according to equation  ( [ branch ] ) . for each calculation",
    "the expected number of counts in the signal region , @xmath94 , was determined from poisson statistics .",
    "specifically , @xmath97 was distributed as @xmath98 with @xmath99 being the actual number of signal counts seen in the data .",
    "the quantities @xmath100 , and @xmath59 were each treated as a gaussian distribution with the same mean and error used in equation  ( [ branch1 ] ) .",
    "a minimum of @xmath101 events were generated for each calculation . from the distribution of the calculated branching ratios ,",
    "an upper limit on the branching ratio at the 90% confidence level was established . by this method ,",
    "upper limits on the branching ratios , at the 90% confidence level , of @xmath1 for , @xmath2 for  and @xmath3 for  were obtained .",
    "we have also employed the method of cousins and feldman  @xcite , as advocated by the particle data group  @xcite , for the case in which no signal and no background are observed . in this approach ,",
    "the upper limits on the branching ratio at the 90% confidence level , corresponding to 2.44 events , are @xmath102 for , @xmath103 for  and @xmath104 for  decay .",
    "these results are about 10% worse than those found by the monte carlo technique .",
    "table  [ results ] summarizes the single - event sensitivity of our experiment and the upper limits for the @xmath50 decays as determined with the monte carlo approach and the cousins - feldman method .",
    "it should be noted that the uncertainties in @xmath105 , and @xmath59 are not taken into account in the cousins - feldman method ; hence , we favor the monte carlo method for determining upper limits .",
    "our  and  limits are comparable to those set by cleo  @xcite , whereas the  result is about a factor of four worse than those of beatrice  @xcite and fnal e771  @xcite .",
    "various systematic errors could affect the results in the branching - ratio determination .",
    "we follow reference  @xcite in discussing the effect of systematic errors on an upper - limit calculation .",
    "the uncertainties associated with the @xmath20 and @xmath80 distributions used in the mc simulation contribute to the error in the relative efficiency .",
    "this effect was studied by varying each parameter of the @xmath20 and @xmath80 parametrizations by @xmath106@xmath65 .",
    "the worst case was the variation in @xmath80 , resulting in a shift in the absolute efficiency of @xmath107 .",
    "however , in each case the efficiency of the dilepton mode relative to the normalization mode varied much less , only @xmath108 .",
    "the temporal variation of the dimuon , dihadron , dielectron , and @xmath109-trigger efficiencies was investigated by subdividing the samples into independent data sets .",
    "as shown in tables  [ tabdkpieff]-[tabdmueeff ] , the variations are small .",
    "the impact - parameter and lifetime - significance cuts , varied by @xmath871@xmath65 , did not have any significant effect on the relative efficiencies .",
    "three rare or forbidden decays , , , and , have been searched for , and no evidence has been found for any of these decays .",
    "new upper limits on the branching ratio at the 90% confidence level are @xmath1 for , @xmath2 for  and @xmath3 for decay . for comparison ,",
    "the best published limits on these decays are @xmath110 for  @xcite , @xmath111 for  @xcite , and @xmath112 for  @xcite .",
    "our limits for and  are the best to date .",
    "these limits , however , are still many orders of magnitude from the levels at which these processes might be expected to occur .",
    "we thank the staffs of fermilab and the los alamos and lawrence berkeley national laboratories for their support .",
    "this work was supported by the director , office of science , office of high energy and nuclear physics , of the u.s .",
    "department of energy under contract no .",
    "de - ac03 - 76sf00098 , the national science foundation , and the national science council of the republic of china ."
  ],
  "abstract_text": [
    "<S> we present the results of a search for the three neutral charm decays , , , and . </S>",
    "<S> this study was based on data collected in experiment 789 at the fermi national accelerator laboratory using 800 gev/@xmath0 proton - au and proton - be interactions . </S>",
    "<S> no evidence is found for any of the decays . </S>",
    "<S> upper limits on the branching ratios , at the 90% confidence level , of @xmath1 for , @xmath2 for and @xmath3 for  are obtained . </S>"
  ]
}