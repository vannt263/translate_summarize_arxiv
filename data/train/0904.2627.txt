{
  "article_text": [
    "protein sequence alignment is one of the most fundamental techniques in biological research .",
    "since the early methods have been proposed@xcite , techniques for protein sequence alignment have made a huge progress toward the detection of very weak homology@xcite .",
    "today , most advanced methods incorporate some kind of information obtained from multiple sequence alignments in terms of sequence profiles@xcite or position - specific scoring matrices ( pssm ) . in sequence profiles ,",
    "such as used in psi - blast@xcite , scores for amino acid substitutions are made to be position - specific so that subtle evolutionary signals can be embedded in each site@xcite . this in turn makes homology search more sensitive .",
    "profile hidden markov models ( hmm)@xcite further elaborate the sequence profile methods so that deletions and insertions are also made position - specific . although powerful , these methods do have some limitations . the profile methods ( including profile hmms )",
    "assume that each position in a profile is independent of other positions which makes it difficult to incorporate long - range correlation among different sites .",
    "the importance of long - range correlations is evident when one takes into account the tertiary structure of a protein in which residues far apart along the sequence are in contact to define the specific native structure . in practice , one can supplement a plain sequence profile with some structural information as in three - dimensional ( 3d ) profile@xcite or threading@xcite , but such combined approaches remain inherently _ ad hoc_. in case of profile hmms , it is extremely difficult , if not impossible , to employ such an approach since the inclusion of site - site correlations , both short - range and long - range , may break the probabilistic framework of the model .    in order to incorporate long - range correlations into an hmm - like model in a well - defined manner , we present in this paper the theoretical formulation of a model based on conditional random fields ( crf)@xcite .",
    "various crf - based models have been successfully applied to many problems in biological domains including pairwise protein sequence alignment@xcite , gene prediction@xcite , and protein conformation sampling@xcite , to name a few .",
    "crfs share many of the advantages of hmms while being able to handle site - site correlations . in the context of profile crfs",
    ", we need to distinguish two types of site - site correlations .",
    "one is the correlations within the sequence which is to be aligned to a crf model ; the other is those among the sites within the model . the profile crf model proposed in this paper",
    "has no limitations for incorporating the both types of correlations , although some approximations are necessary for the latter type in practical applications . without the model sites correlations ,",
    "the profile crf model may be regarded as a generalization of the profile hmm . unlike profile hmms",
    ", profile crfs can incorporate many kinds features of the sequence in terms of feature functions . with the model sites correlations ,",
    "the profile crf model may be regarded as a generalization of the self - consistent molecular field theory of finkelstein and reva@xcite , which , in turn , is a generalization of the ising model in one - dimension ( 1d ) .    in this paper , we first present the model structure of the profile crf , provide some examples of possible feature functions , and derive some approximations for treating long - range correlations between model sites .",
    "next , we present algorithms for computing partition functions , marginal probabilities , and optimal alignments , followed by methods for parameter learning based on multiple sequence alignments . since our purpose here is to present the formulation and algorithms , actual implementation of the method and experimentation thereof are left for future studies .",
    "nevertheless , we believe that the method presented here should serve as a firm basis for the analysis of protein sequences and structures .",
    "we model a protein family ( or a multiple sequence alignment ) in an analogous manner as profile hmms@xcite ( fig .",
    "[ fig : model ] ) . a profile crf model @xmath0 is formally defined as a tuple of four components : @xmath1 where @xmath2 is the _ length _ of the model @xmath0",
    ", @xmath3 is a set of _ states",
    "_ indexed by _",
    "model sites _ @xmath4 .",
    "for each site @xmath5 ( @xmath6 ) , there are a _ matching state _",
    "@xmath7 , an _ insertion state _ @xmath8 , and a _ deletion state _ @xmath9 . for @xmath10",
    ", there are only one matching state @xmath11 and one insertion state @xmath12 ; for @xmath13 , there is only one matching state @xmath14 .",
    "the matching states at the termini @xmath11 and @xmath14 are also called _",
    "start state _ and _ end state _",
    ", respectively , for the reason that will be apparent in the following .",
    "the model sites with @xmath15 may be regarded as the core sites of the protein family .",
    "the third component , @xmath16 , is a set of _ feature functions _ which are associated with model states ( @xmath17 ) .",
    "each feature function maps an amino acid sequence and its site indexes to a real number depending on model sites .",
    "the last component , @xmath18 , is a set of parameters or _ external fields _ , each of which is associated with a feature function in @xmath16 .",
    "together with feature functions , the external fields are used for evaluating alignments between the model and amino acid sequences .",
    "the details of these terms will be clarified below . in a profile crf model , the feature functions must be given _ a priori _ and the values of external fields are learned from a multiple sequence alignment ( msa ) .",
    "the objective is to align a protein sequence @xmath19 ( called _ target sequence _ ) to the model .",
    "an alignment between a target sequence @xmath20 and a crf model is an ordered sequence of pairs of target sites and model states ( called site - state pairs in the following ) : @xmath21 where @xmath22 .",
    "the pair @xmath23 reads as `` the target site @xmath24 is matched to the model state @xmath25 . ''",
    "it is assumed that if @xmath26 and @xmath27 and @xmath28 , then @xmath29 .",
    "an alignment always starts at the start state and ends at the end state so that the pairs @xmath30 and @xmath31 are fixed in any alignments . in an alignment ,",
    "not all transitions from one site - state pair to another are possible .",
    "allowed transitions are listed in table [ tab : transition ] and depicted in fig .",
    "[ fig : model ] by arrows .",
    ".allowed transitions of site - state pairs . @xmath24 and @xmath5 indicate a site of a target sequence and a site of a crf model , respectively . [ cols= \" < , <",
    ", < \" , ]     [ tab : transition ]    by convention , the match to a delete state @xmath32 means that the deletion resides between the @xmath24-th and @xmath33-th positions of the sequence .",
    "for example , an alignment of an 8-residue target sequence to an @xmath34 profile crf model might be given as @xmath35 as can be inferred from this example , @xmath36 indicates that the @xmath24-th residue matches the @xmath5-th core site of the model , @xmath37 indicates that there is an insertion at the @xmath24-th site in the target sequence , and @xmath32 indicates that there is a deletion between @xmath24-th and @xmath33-th sites of the target sequence . in terms of ordinary sequence alignment , the alignment in eq .",
    "( [ eq : ali2 ] ) may be expressed as @xmath38 where the ` @xmath39 ' signs in the upper and lower rows indicate insertions ( corresponding to @xmath8 ) and deletions ( @xmath9 ) in the model sites .",
    "alignments are evaluated in terms of a set of feature functions @xmath40 .",
    "three types of feature functions are distinguished , namely , singlet feature functions @xmath41 , doublet feature functions @xmath42 , and pairwise feature functions @xmath43 .",
    "the singlet feature function ( sff ) @xmath41 is a real - valued function representing some feature @xmath44 of the target sequence when @xmath45 ; the doublet feature function ( dff ) @xmath42 is also a real - valued function representing some feature @xmath46 when @xmath47 and @xmath48 . here , @xmath49 is the _ predecessor _ of @xmath24 defined as @xmath50 in general , @xmath44 may depend on @xmath51 and @xmath46 may depend on @xmath51 and @xmath52 .",
    "the singlet and doublet feature functions are called local or short - ranged since the former represents interactions at one model site and the latter , interactions between two adjacent model sites for which transitions are allowed . the pairwise feature function ( pff ) @xmath53 , representing some feature @xmath54 , is defined for @xmath45 and @xmath55 . while singlet and doublet feature functions are local , pairwise feature functions are non - local in the sense that @xmath51 and @xmath52 can be any pair of the model states , not necessarily those for which direct transitions are allowed .",
    "each of singlet , doublet or pairwise feature functions is coupled with a parameter called an external field : @xmath56 for @xmath57 , @xmath58 for @xmath59 , and @xmath60 for @xmath61 .",
    "that is , @xmath62 .",
    "the product of a feature function and its coupled external field yields the score of the corresponding feature when a particular target site is aligned to a model state .",
    "for example , the product @xmath63 is the score of the feature @xmath44 when the target site @xmath24 is aligned to the model site @xmath51 . in the formulation of crf ,",
    "it is convenient to employ an analogy to statistical physics .",
    "thus , the negative total score of an alignment is interpreted as the total energy , and the normalization factor for the conditional probability of alignments as the partition function of the target sequence .",
    "given an alignment between the model and the sequence , the total energy of an alignment @xmath64 is defined by @xmath65\\\\ - \\sum_{\\{i < j\\}}\\sum_{\\gamma}\\nu_{y_i , y_j}^{\\gamma}u_{y_i , y_j}^{\\gamma}(\\mathbf{x},i , j)\\end{gathered}\\ ] ] where the summation over @xmath66 means summing along the alignment @xmath67 ( there can be multiple occurrences of the same index @xmath24 due to the matching to deletion states ) ; the double summation for @xmath68 is also similarly defined .",
    "the partition function of this system is thus given by @xmath69\\ ] ] where the summation is over all possible alignments , and @xmath70 is the temperature ( in energy unit ) .",
    "the conditional probability of obtaining a particular alignment @xmath71 for a given @xmath20 is @xmath72}{z(\\mathbf{x},\\theta)}\\ ] ] which is also called the likelihood of the alignment in the following .",
    "the log - likelihood is defined by @xmath73 from here on , we assume @xmath74 unless otherwise stated .",
    "the derivatives of the log - likelihood with respect to the parameters , @xmath75 , are useful both for parameter learning and for deriving approximations . for singlet terms",
    ", they are given as @xmath76\\ ] ] where @xmath77 is kronecker s delta and @xmath78 is the marginal probability that @xmath24-th site of the target sequence is aligned to the state @xmath51 of the model , i.e. , @xmath45 .",
    "similarly for the doublet terms , @xmath79    \\end{gathered}\\ ] ] where @xmath80 is the marginal probability that @xmath81 and @xmath82 . finally for the pairwise terms , @xmath83\\end{gathered}\\ ] ] where @xmath84 is the marginal probability that @xmath45 and @xmath55 . either when parameters are optimal for a given alignment or when the alignment is optimal for given parameters , we have @xmath85 .      although we are focused on the formulation of the profile crf model , it is instructive to provide some concrete examples for feature functions",
    ". it should be stressed , however , that the actual selection of feature functions will require careful experimentation to maximize the effectiveness of the profile crf framework .",
    "[ [ singlet - feature - functions . ] ] singlet feature functions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    singlet feature functions represent compatibility measures between a model state and a target sequence .",
    "it may depend on the whole target sequence as well as on single amino acid residues .",
    "one simple sff may be such that @xmath86 where @xmath87 is one of the 20 standard amino acid residue types .",
    "it is implicitly assumed that this feature function is defined only when @xmath88 .",
    "the same assumption applies throughout the following discussion .",
    "if the target sequence is accompanied by its pssm , the above sff ( eq . [ eq : singlet1 ] ) can be generalized as @xmath89 where @xmath90 is the value of the pssm for residue type @xmath87 at site @xmath24 .",
    "sffs can also depend on multiple sites of the target sequence .",
    "for example , let us partition amino acid residues into either hydrophobic ( 1 ) or hydrophilic ( 0 ) .",
    "let @xmath91 be a binary word encoding@xcite function of the 7-residue sub - sequence @xmath92 .",
    "then , the sff @xmath93 may enhance insertions at highly hydrophilic regions of the target sequence .",
    "similarly , the sff @xmath94 may enhance the matching at @xmath44-helical regions since the binary pattern 0011011 is typical in @xmath44 helices .",
    "there are @xmath95 types of binary words for 7-residue segments , and we can incorporate all of these in a single profile crf model .    if either predicted or observed structural information is available for the target sequence , we may define , for example , @xmath96 where @xmath97 indicates the secondary structure of site @xmath24 .    [ [ doublet - feature - functions . ] ] doublet feature functions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    doublet feature functions represent the feasibility of transitions from one site - state pair to another .",
    "one trivial example is those that do not depend on the target sequence at all .",
    "for example , the dff @xmath98 may be regarded as a feature representing a gap ( insertion ) opening .",
    "similar sequence - independent dffs can be defined for all the allowed state transitions .",
    "of course , dffs can be made to be target sequence - dependent .",
    "take the binary word encoding example again .",
    "for example , the following dff @xmath99 may help to suppress deletions at @xmath44-helical regions , since the pattern 001101 is typical in @xmath44-helices in which deletions are less likely to occur .",
    "[ [ pairwise - feature - functions . ] ] pairwise feature functions . + + + + + + + + + + + + + + + + + + + + + + + + + + +    with pairwise feature functions , it is possible to incorporate some kind of correlations between two states that are not directly connected by transitions .",
    "such correlations are most easily grasped in the context of the tertiary structure of a protein .",
    "suppose that there is a known structure in a protein family to be modeled as a profile crf , and that structure contains a pair of contacting residues which correspond to the matching states @xmath7 and @xmath100 .",
    "we may define @xmath101 where @xmath87 and @xmath102 are amino acid residue types .",
    "we can define different pffs for different kinds of interactions such as hydrogen bonds , salt bridges , hydrophobic contacts , etc .",
    "also , sequence - dependence may be made more complex .",
    "we can combine contacts with binary word encoding , for example .",
    "if there are no pairwise terms , exact partition functions and exact optimal alignments for profile crf models can be computed efficiently by dynamic programming just as in profile hmms . with pairwise terms present , however , the computation of exact solutions is intractable . in order to make computations feasible",
    ", we need to make some approximations .",
    "more specifically , we will derive a bethe approximation , which is further simplified to a mean - field approximation .",
    "observe , first , that the pairwise terms can be rearranged as @xmath103 when the alignment is optimal , we have @xmath104 ( eq . [ eq : dnu ] ) , hence the following : @xmath105 using this relation , the pairwise terms are arranged as @xmath106 where @xmath107 is the renormalized singlet feature function defined by @xmath108 the conditional marginal probability @xmath109 is defined by @xmath110 using @xmath107 and introducing a coupled external field @xmath111 , let us define a tentative total energy : @xmath112.\\end{gathered}\\ ] ] by calculating the log - likelihood ( eq . [ eq : ll ] ) based on this energy and its derivative with respect to @xmath111 ( eq . [ eq : dlambda ] ) , and enforcing the optimality condition @xmath113 , we have @xmath114 substituting this relation into eq .",
    "( [ eq : bethe1 ] ) , we have @xmath115 therefore , the pairwise energy terms can be converted into renormalized singlet energy terms as long as the alignment is optimal . for non - optimal alignments , we approximate the total energy by @xmath116 with @xmath117 .",
    "the renormalized singlet feature function ( eq . [ eq : bethe ] ) explicitly accounts for the pairwise joint probability , and hence it may be called a bethe or quasi - chemical approximation .",
    "furthermore , if we assume two alignment sites are independent , we can decouple the joint marginal probability as @xmath118 this is a mean - field approximation . substituting this into eqs .",
    "( [ eq : condmarge],[eq : bethe ] ) , we have the following mean - field energy : @xmath119 an advantage of this approximation is that we need not to compute the joint marginal probabilities . by using either the bethe ( eq . [ eq : ubethe ] ) or the mean - field ( eq . [ eq : umfa ] ) approximations ,",
    "the energy of the alignment is expressed as @xmath120.\\end{gathered}\\ ] ] note that there are apparently no external field parameters for the renormalized sffs ( @xmath121 ) ; they are included in the definitions ( eqs .",
    "[ eq : ubethe ] , [ eq : umfa ] ) .",
    "since the mean - field feature functions are effectively singlet feature functions , we can apply the standard procedure for learning and alignment , provided that the mean - fields are known .",
    "of course , the mean - fields are not known in advance so that we need to obtain the partition function by an iterative procedure .",
    "that is ,    1 .",
    "arbitrarily set @xmath122 .",
    "2 .   calculate the partition function and marginal probabilities based on the previously calculated @xmath122 .",
    "3 .   based on the partition function and marginal probabilities in the previous step , update @xmath121 by eq .",
    "( [ eq : ubethe ] ) or eq .",
    "( [ eq : umfa ] ) .",
    "4 .   iterate steps 2 and 3 until convergence .",
    "the algorithms for computing the partition function and marginal probabilities are a subject of the next section .",
    "the partition function ( eq . [ eq : pfunc ] ) and marginal probabilities can be calculated efficiently by dynamic programming ( or transfer matrix method ) . in this section",
    ", we assume that pairwise terms are approximated as renormalized sffs ( eqs .",
    "[ eq : ubethe ] , [ eq : umfa ] ) , and they are treated as ordinary sffs .",
    "first we define the transfer matrix : @xmath123\\ ] ] where @xmath124 , @xmath70 is the temperature , and @xmath125 the partition function ( eq . [ eq : pfunc ] ) is then expressed as @xmath126 where the summation is over all possible model states of each residue of the target sequence . in order to compute the partition function eq .",
    "( [ eq : pfunct ] ) , we define an auxiliary function @xmath127 where @xmath128 and @xmath129 , @xmath130 .",
    "@xmath127 is the partition function of the sub - sequence @xmath131 where its termini @xmath24 and @xmath132 are fixed to the model states @xmath133 and @xmath134 , respectively .",
    "these conditions are given as @xmath135 by the construction of the model , the following boundary conditions hold in particular : @xmath136 the partition function @xmath137 is given as @xmath138 based on the boundary condition eq .",
    "( [ eq : bc_faux ] ) , the following forward recurrence equations for @xmath139 hold for @xmath140 and @xmath141 : @xmath142 @xmath143 @xmath144 it is understood that the terms involving non - existent states and/or incompatible state transitions ( e.g , @xmath145 , etc . ) are ignored .",
    "similarly , together with the boundary condition eq .",
    "( [ eq : bc_baux ] ) , the backward recurrence equations are given for @xmath146 and @xmath147 as @xmath148 @xmath149 @xmath150 for convenience , let us define the forward auxiliary function @xmath151 and the backward auxiliary function @xmath152 by @xmath153 using @xmath154 and @xmath155 , and @xmath156 , we can calculate marginal probabilities .",
    "the joint marginal probability is obtained as @xmath157 in particular , when @xmath158 and @xmath159 , we have @xmath160 similarly , for states with allowed transitions @xmath51 and @xmath52 ( table [ tab : transition ] ) , @xmath161 using these marginal probabilities , the renormalized sffs for pairwise terms ( eqs .",
    "[ eq : ubethe ] , [ eq : umfa ] ) can be computed .",
    "the optimal alignment for a given model and a target sequence is the one that yields the minimum energy , which corresponds to the free energy of the system at zero temperature ( @xmath162 ) .",
    "the recurrence equations for the optimal alignment can be derived as the zero - temperature limit of the forward recurrence equations using the following formula@xcite : @xmath163 = \\max_{i}a_i.\\ ] ] that is , if we define a function @xmath164,\\ ] ] the energy of the optimal alignment @xmath165 is given by @xmath166 more concretely , we first set the boundary condition @xmath167 and apply the zero - temperature limit to the both sides of the forward recurrence equations for @xmath168 ( eqs . [ eq : faux1][eq : faux3 ] ) , we have @xmath169,\\\\        [ a_{i-1}(i_{k-1 } ) + e_{i}(i_{k-1},m_{k})],\\\\        [ a_{i-1}(i_{k-1 } ) + e_{i}(d_{k-1},m_{k})]\\};\\end{gathered}\\ ] ] @xmath170,\\\\        [ a_{i-1}(i_k ) + e_{i}(i_{k},i_{k})],\\\\        [ a_{i-1}(d_k ) + e_{i}(d_{k},i_{k})]\\};\\end{gathered}\\ ] ] @xmath171,\\\\        [ a_{i}(i_{k-1 } ) + e_{i}(i_{k-1},d_{k})],\\\\        [ a_{i}(d_{k-1 } ) + e_{i}(d_{k-1},d_{k})]\\}.\\end{gathered}\\ ] ] by tracing back the site - state pairs that yield the optimal values of @xmath172 at each step , we can find the optimal alignment @xmath173 .",
    "[ [ global - optimization - of - parameters . ] ] global optimization of parameters .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the parameters of a profile crf are the set of external fields @xmath56 , @xmath174 and @xmath60 ( of course , we need to specify the feature functions to start to with ) .",
    "the input for parameter learning is a multiple sequence alignment ( msa ) of a protein family , from which the model architecture must be somehow specified `` by hand . '' in this process , we need to specify which columns of the msa correspond to matching states . after the columns of matching states",
    "are determined , matching , insertion and deletion states can be assigned to each column of each sequence in the msa .",
    "after the model architecture has been determined , the learning can be done by maximizing the likelihood using the sequences of the input msa .",
    "let these alignments be @xmath175 where @xmath176 is the index of sequences .",
    "the joint log - likelihood is given by @xmath177.\\end{gathered}\\ ] ] since the total energy is a linear function of the parameters , and @xmath178 is the free energy of the system which is always convex , the total log - likelihood is also a convex function of the parameters .",
    "this implies that we can obtain the globally optimal parameter sets by gradient - based methods . in practice , minimizing the bare log - likelihood may results in over - fitting of the parameters to the training set .",
    "therefore , we define an alternative objective function @xmath179 which includes prior probability density of the parameters for regularization : @xmath180 where @xmath181 is a gaussian prior : @xmath182 \\prod_{\\beta , s',s}\\exp\\left[-\\frac{(\\mu_{s',s}^{\\beta})^2}{2(\\sigma_{s',s}^{\\beta})^2}\\right]\\\\ \\times \\prod_{\\gamma , s , s'}\\exp\\left[-\\frac{(\\nu_{s , s'}^{\\beta})^2}{2(\\sigma_{s , s'}^{\\gamma})^2}\\right].\\end{gathered}\\ ] ] here , the hyper - parameters @xmath183 , @xmath184 and @xmath185 are the ( expected ) standard deviations of the corresponding external fields , and must be specified _ a priori _ ( however , if we use a hierarchical bayes model , these hyper - parameters can be automatically adjusted based on the training data ) . since we can calculate the gradient of this log - likelihood , it is possible to use gradient - based optimization techniques .",
    "since @xmath179 ( eq . [ eq : llbayes ] ) is still convex , the globally optimal parameters are guaranteed to be found by gradient descent methods .",
    "[ [ bayesian - learning . ] ] bayesian learning .",
    "+ + + + + + + + + + + + + + + + + +    it is also possible to apply the bayesian learning framework@xcite .",
    "that is , instead of using a single , globally optimal parameter set , we can use a set of suboptimal parameters to make robust predictions . from bayes formula",
    ", we have @xmath186 p(\\theta).\\ ] ] using this equation , a bayesian alignment for the target sequence @xmath20 may be selected so as to maximize the following probability : @xmath187 suboptimal parameters may be obtained by markov chain monte carlo simulations in the @xmath18-space , using @xmath188 as the `` energy '' of the system . since the gradients of the log - likelihood can be computed , a hybrid monte carlo method is also at our disposal for efficient sampling .",
    "we can also employ hierarchical bayes learning which can automatically adjust the the hyper - parameters for the prior , @xmath183 and @xmath189 , based on the training set@xcite .",
    "in this paper , we have formulated the profile crf to model protein families with possible long - range correlations such as structural information .",
    "the profile crf model is clearly an extension of both the molecular field theory of finkelstein and reva ( fr theory)@xcite and the profile hmm@xcite , and hence an integration of these . here",
    ", we shall discuss the relationship of the present model with these two earlier models .",
    "the fr theory is particularly focused on 3d structures of proteins .",
    "accordingly , its model is explicitly represented in the 3d space as a set of lattice points .",
    "the lattice points mostly correspond to residues in secondary structure elements ( sses ) , and these points may be regarded as `` match '' states in the present framework . the fr model does not allow gaps within each sse , only insertions are allowed in the regions between two sses .",
    "the energy functions ( @xmath190 feature functions ) are physics - based ones , and the parameters are not optimized to fit some training data , but obtained from physical experiments . therefore , the fr models are more suitable for studying physical aspects of protein folding and structure prediction , but less so for more general - purpose sequence analysis .",
    "nevertheless , almost all the theoretical foundations of the fr theory such as calculation of partition functions , marginal probabilities , mean - field approximations , but except for parameter learning , are shared by profile crfs .",
    "after all , the both models are extensions of the 1d ising model .",
    "the analogy between 1d ising model and a more general sequence alignment problem was pointed out by miyazawa@xcite , which was further extended to the problem of sequence - structure alignment with a mean - field approximation@xcite .",
    "later , koike _ _ et al.__@xcite applied this analogy to compute partition functions and marginal probabilities in protein structure comparison with the bethe approximation . by complementing the fr theory with these techniques ,",
    "the alignment algorithm can be made more general , and one such generalization is the profile crf model .",
    "the improvements made by profile crfs on the fr theory are thus clear : more general treatment of model states , possible insertions and deletions at any sites , and parameter learning based on msa .",
    "profile hmms , being a class of generative models , need to calculate the joint probability of alignment @xmath191 while profile crfs , being a class of discriminative model , directly calculates the conditional probability @xmath192 . in special cases , with the definition of the conditional probability @xmath193 in mind",
    ", we may regard @xmath137 as @xmath194 and @xmath195 $ ] as @xmath191 . more specifically ,",
    "if we define only the following feature functions ( and no others ) with appropriate values for external fields , we can construct a crf that is equivalent to a given hmm :    1 .",
    "define singlet feature functions @xmath196 for matching and insertion states as in eq .",
    "( [ eq : singlet1 ] ) . for deletion states , just define a constant sff ( always equal to 1 ) .",
    "2 .   define sequence - independent feature functions @xmath197 for each transitions as in eq .",
    "( [ eq : doublet1 ] ) .",
    "3 .   set the singlet external fields as @xmath198 ( @xmath199 : the emission probability of the hmm ) .",
    "4 .   set the doublet external fields as @xmath200 ( @xmath201 : transition probability of the hmm ) .",
    "however , this equivalence breaks down as soon as we incorporate other feature functions into profile crfs since the boltzmann factor @xmath195 $ ] may no longer satisfy a condition of probability measure ( i.e. , normalization to 1 ) .",
    "thus , hmms are a very special class of crfs .    in summary",
    ", we have presented the profile crf model .",
    "this model is flexible enough to accommodate almost any features of target sequences including pssm , local sequence patterns , and even long - range correlations .",
    "it can also incorporate various features of a modeled protein family such as local structures and long - range pairwise interactions .",
    "although concrete implementations are yet to be done , we expect this model to be a useful alternative to conventional methods for analyzing and understanding protein sequences and structures .",
    "the author thanks drs .",
    "takeshi kawabata , ryotaro koike , kengo kinoshita and motonori ota for their valuable comments on the first draft of this manuscript .",
    "altschul , s.  f. , madden , t.  l. , schaffer , a.  a. , zhang , j. , zhang , z. , miller , w. , and lipman , d.  l. gapped blast and psi - blast : a new generation of protein database search programs .",
    ", 33893402 , 1997 .",
    "do , c. , gross , s. , and batzoglou , s. : discriminative training for protein sequence alignment . in _ proceedings of the tenth annual international conference on computational molecular biology ( recomb 2006 ) _",
    ", 160174 , , 2006 .",
    "finkelstein , a.  v. and reva , b.  a. a search for the most stable folds of protein chains : i. application of a self - consistent molecular field theory to a problem of protein three - dimensional structure prediction .",
    ", 387397 , 1996 .",
    "finkelstein , a.  v. and reva , b.  a. a search for the most stable folds of protein chains : ii .",
    "computation of stable architectures of beta - proteins using a self - consistent molecular field theory .",
    ", 399411 , 1996 ."
  ],
  "abstract_text": [
    "<S> a statistical model of protein families , called profile conditional random fields ( crfs ) , is proposed . </S>",
    "<S> this model may be regarded as an integration of the profile hidden markov model ( hmm ) and the finkelstein - reva ( fr ) theory of protein folding . </S>",
    "<S> while the model structure of the profile crf is almost identical to the profile hmm , it can incorporate arbitrary correlations in the sequences to be aligned to the model . </S>",
    "<S> in addition , like in the fr theory , the profile crf can incorporate long - range pairwise interactions between model states via mean - field - like approximations . </S>",
    "<S> we give the detailed formulation of the model , self - consistent approximations for treating long - range interactions , and algorithms for computing partition functions and marginal probabilities . </S>",
    "<S> we also outline the methods for the global optimization of model parameters as well as a bayesian framework for parameter learning and selection of optimal alignments . </S>"
  ]
}