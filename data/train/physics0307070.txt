{
  "article_text": [
    "the level 3 data acquistion system ( l3daq )  @xcite transports detector component data located in vme readout crates to the processing nodes of the level 3 trigger filtering farm . at a rate of 1khz",
    ", sixty - three vme crates must be read out for each event , each containing 1 - 20  kb of data distributed among vme modules .",
    "the total event size is approximately 250 kilobytes .",
    "as shown in figure [ fig : hardware ] , the system is built around a single cisco 6509@xcite ethernet switch .",
    "a schematic of the communication and data flow in the system is shown in figure  [ fig : dataflow ] .",
    "all nodes in the system are based on commodity computers and run the linux operating system .",
    "tcp / ip sockets implemented via the ace  @xcite c++ network and utility library are used for all communication and data transfers .",
    "the supervisor process provides the interface between the main d0 run control ( coor ) and the l3daq system . when a new run is configured , the supervisor passes run and general trigger information to the rm and passes the coor - provided l3 filter configuration to the io / evb process on relevant farm nodes , where it is cached and passed on to the level 3 filter processes .",
    "a single - board computer ( sbc ) in each vme crate reads out the vme modules and sends the data to one or more farm nodes specified by routing instructions received from the routing master ( rm ) process .",
    "an event builder ( evb ) process on each farm node builds a complete event from the received event fragments and makes it available to level 3 trigger filter processes .",
    "the sbcs are single - board computers with dual 100  mb / s ethernet interfaces and a vme - to - pci interface .",
    "an expansion slot is occupied by a digital - i / o ( dio ) module , used to coordinate the readout of vme modules over the vme user ( j3 ) backplane . a custom kernel driver on the sbc handles interrupt requests from the dio module which are triggered by readout requests from the crate - specific electronics . on each readout",
    "request the kernel module performs the vme data transfers and stores the event fragment in one of several buffers in kernel - memory .    a user - level process on the sbc receives route information from the routing master in the form of route tags that contain a unique event identifier ( l3 transfer number ) and the indices of the farm nodes to which that event should be sent .",
    "if the route tag s l3 transfer number matches that of the transfer number embedded within the head event fragment in the kernel buffers , the event fragment is sent to the specified farm nodes . an event builder process ( evb ) on each farm node collates the event fragments received from sbcs into complete events , keyed by l3 transfer number . for each event the evb receives an expected - crate list from the rm in order to determine when an event is complete .",
    "complete events are placed in shared memory event buffers for processing by the level 3 filter processes .",
    "the evb routinely informs the rm of the number of available event buffers that it has , so that the rm will not route an event to a farmnode unless the event can be processed immediately .",
    "the routing master program executes on an sbc in a special vme crate which contains a hardware interface to the d0 trigger framework ( tfw ) .",
    "the tfw provides trigger information and the l3 transfer number for each event and allows the rm to asynchronously disable the firing of triggers . for each event",
    "the rm program chooses a node for processing based on the run configuration , the trigger information , and the number of available buffers in the set of nodes configured to process the type of event .",
    "a node is chosen in a round - robin fashion from amongst the set of nodes with the most free buffers .",
    "if the number of available free buffers is too low , the rm instructs the tfw to disable triggers so that the farm nodes have time to catch up .    to avoid dropped packets in the main switch ,",
    "data flow is limited by setting the tcp / ip receive window size on the farmnodes .",
    "the window size is set such that the product of the number of connection sources and the receive window size is smaller than the switch s per - port output buffer memory .",
    "the dzero level 3 data acquistion system has been built from commercially available hardware : single board vme computers , ethernet switches , and pcs .",
    "the software components rely upon high level programming languages ; the linux operating system ; widely - used , open libraries ; and standard networking protocols .",
    "the system has performed reliably since commissioning in may 2002 .",
    "additional details are availble from the references  @xcite .",
    "9 proceedings of the ieee npss real time conference , montreal , canada , may 2003 , rt-105 . `` the dzero level 3 data acquistion system '' , to be published in _ ieee transactions on nuclear science_. http://www.cisco.com/ http://www.cs.wustl.edu/schmidt/ace.html"
  ],
  "abstract_text": [
    "<S> the dzero experiment located at fermilab has recently started runii with an upgraded detector . </S>",
    "<S> the runii physics program requires the data acquisition to readout the detector at a rate of 1 khz . </S>",
    "<S> events fragments , totaling 250 kb , are readout from approximately 60 front end crates and sent to a particular farm node for level 3 trigger processing . </S>",
    "<S> a scalable system , capable of complex event routing , has been designed and implemented based on commodity components : vmic 7750 single board computers for readout , a cisco 6509 switch for data flow , and close to 100 linux - based pcs for high - level event filtering . </S>"
  ]
}