{
  "article_text": [
    "since the seminal paper @xcite , association rule and frequent itemset mining received a lot of attention . by comparing five well - known association rule algorithms ( i.e. , apriori @xcite , charm @xcite , fp - growth @xcite , closet @xcite , and magnumopus @xcite ) using three real - world data sets and the artificial data set from ibm almaden , zheng et al .",
    "@xcite found out that the algorithm performance on the artificial data sets are very different from their performance on real - world data sets . thus there is a great need to use real - world data sets as benchmarks .",
    "however , organizations usually hesitate to provide their real - world data sets as benchmarks due to the potential disclosure of private information .",
    "there have been two different approaches to this problem .",
    "the first is to disturb the data before delivery for mining so that real values are obscured while preserving statistics on the collection .",
    "some recent work @xcite investigates the tradeoff between private information leakage and accuracy of mining results .",
    "one problem related to the perturbation based approach is that it can not always fully preserve individual s privacy while achieving precision of mining results .    the second approach to address",
    "this problem is to generate synthetic basket data sets for benchmarking purpose by integrating characteristics from real - world basket data sets that may have influence on the software performance .",
    "the frequent sets and their supports ( defined as the number of transactions in the basket data set that contain the items ) can be considered to be a reasonable summary of the real - world data set . as observed by calders @xcite , association rules for basket data set",
    "can be described by frequent itemsets .",
    "thus it is sufficient to consider frequent itemsets only .",
    "ramesh et al .",
    "@xcite recently investigated the relation between the distribution of discovered frequent set and the performance of association rule mining .",
    "it suggests that the performance of association rule mining method using the original data set should be very similar to that using the synthetic one compatible with the same frequent set mining results .    informally speaking , in this approach , one first mines frequent itemsets and their corresponding supports from the real - world basket data sets .",
    "these frequent itemset support constraints are used to generate the synthetic ( mock ) data set which could be used for benchmarking . for this approach",
    ", private information should be deleted from the frequent itemset support constraints or from the mock database .",
    "the authors of @xcite investigate the problem whether there exists a data set that is consistent with the given frequent itemsets and frequencies and show that this problem is * np*-complete .",
    "the frequency of each frequent itemset can be taken as a constraint over the original data set .",
    "the problem of inverse frequent set mining then can be translated to a linear constraint problem .",
    "linear programming problems can be commonly solved today in hundreds or thousands of variables and constraints .",
    "however , the number of variables and constraints in this scenario is far beyond hundreds or thousands ( e.g. , @xmath0 , where @xmath1 is the number of items ) .",
    "hence it is impractical to apply linear programming techniques directly .",
    "recently , the authors of @xcite investigated a heuristic method to generate synthetic basket data set using the frequent sets and their supports mined from the original basket data set . instead of applying linear programming directly on all the items , it applies graph - theoretical results to decompose items into independent components and then apply linear programming on each component .",
    "one potential problem here is that the number of items contained in some components may be still too large ( especially when items are highly correlated each other ) , which makes the application of linear programming infeasible .",
    "the authors of @xcite proposed a method to generate basket data set for benchmarking when the length distributions of frequent and maximal frequent itemset collections are available . though the generated synthetic data set preserves the length distributions of frequent patterns",
    ", one serious limitation is that the size of transaction databases generated is much larger than that of original database while the number of items generated is much smaller .",
    "we believe the sizes of items and transactions are two important parameters as they may significantly affect the performance of association rule mining algorithms .    instead of using the exact inverse frequent itemset mining approach",
    ", we propose an approach to construct transaction databases which have the same size as the original transaction database and which are approximately consistent with the given frequent itemset constraints .",
    "these approximate transaction databases are sufficient for benchmarking purpose . in this paper",
    ", we consider the complexity problem , the approximation problem , and privacy issues for this approach .",
    "we first introduce some terminologies .",
    "@xmath2 is the finite set of items .",
    "a transaction over @xmath2 is defined as a pair @xmath3 where @xmath4 is a subset of @xmath2 and tid is a natural number , called the transaction identifier .",
    "a transaction database @xmath5 over @xmath2 is a finite set of transactions over @xmath2 . for an item set @xmath6 and a transaction @xmath7",
    ", we say that @xmath7 contains @xmath4 if @xmath8 .",
    "the support of an itemset @xmath4 in a transaction database @xmath5 over @xmath2 is defined as the number of transactions @xmath9 in @xmath5 that contains @xmath4 , and is denoted @xmath10 .",
    "the frequency of an itemset @xmath4 in a transaction database @xmath5 over @xmath2 is defined as @xmath11 calders @xcite defined the following problems that are related to the inverse frequent itemset mining .",
    "freqsat    _ instance _ : an item set @xmath2 and a sequence @xmath12 , @xmath13 , @xmath14 , @xmath15 , where @xmath16 are itemsets and @xmath17 are nonnegative rational numbers , for all @xmath18 .",
    "_ question _ : does there exist a transaction database @xmath5 over @xmath2 such that @xmath19 for all @xmath18 ?",
    "ffreqsat ( fixed size freqsat )    _ instance _ : an integer @xmath20 , an item set @xmath2 , and a sequence @xmath12 , @xmath13 , @xmath14 , @xmath15 , where @xmath16 are itemsets and @xmath17 are nonnegative rational numbers , for all @xmath18 .",
    "_ question _ : does there exist a transaction database @xmath5 over @xmath2 such that @xmath5 contains @xmath20 transactions and @xmath19 for all @xmath18 ?",
    "fsuppsat    _ instance _ : an integer @xmath20 , an item set @xmath2 , and a sequence @xmath21 , @xmath22 , @xmath14 , @xmath23 , where @xmath16 are itemsets and @xmath24 are nonnegative integers , for all @xmath18 .",
    "_ question _ : does there exist a transaction database @xmath5 over @xmath2 such that @xmath5 contains @xmath20 transactions and @xmath25 for all @xmath18 ?    obviously , the problem fsuppsat is equivalent to the problem ffreqsat .",
    "calders @xcite showed that freqsat is * np*-complete and the problem fsuppsat is equivalent to the intersection pattern problem * ip * : given an @xmath26 matrix @xmath27 with integer entries , do there exist sets @xmath28 such that @xmath29 $ ] ?",
    "though it is known that * ip * is * np*-hard , it is an open problem whether * ip * belongs to * np*.    in this paper , we will consider the problem of generating transaction databases that approximately satisfy the given frequent itemset support constraints . section [ appcom ] discusses the computational complexity of approximating transaction databases . section [ appsection ] proposes an algorithm to approximately generate a approximate transaction database . section [ privacysec ] discusses privacy issues and section [ relatedsec ] .",
    "finally , section [ consection ] draws conclusions .",
    "though it is an interesting problem to study whether there exists a size @xmath20 transaction database that satisfies a set of given frequency constraints , it is sufficient for benchmarking purpose to construct a transaction database that is approximately at the size of @xmath20 and that approximately satisfies the set of given frequency constraints . thus we define the following problem .",
    "approsuppsat _ instance _ : an integer @xmath20 , an item set @xmath2 , and a sequence @xmath21 , @xmath22 , @xmath14 , @xmath23 , where @xmath16 are itemsets and @xmath24 are nonnegative integers , for all @xmath18 .",
    "_ question _ : does there exist a transaction database @xmath5 of @xmath30 transactions over @xmath2 such that @xmath31 and @xmath32 for all @xmath18 ?",
    "note that in the above definition , the approximation errors are based on the parameter @xmath33 instead of @xmath20 since for most applications , @xmath33 is small and @xmath20 is bigger .",
    "indeed , @xmath20 could be at the exponential order of @xmath33 . for performance testing purpose , it is not meaningful to use @xmath20 as the parameter in these situations .",
    "it also straightforward to show that the problem approsuppsat is equivalent to the following problem : given an integer @xmath20 , an item set @xmath2 , and a sequence @xmath34 , decide whether there exists a transaction database @xmath5 over @xmath2 with @xmath20 transactions and @xmath35 for all @xmath18 .    in the following",
    "we show that approsuppsat is * np*-complete .",
    "note that for the non - approximate version fsuppsat of this problem , we do not know whether it is in * np*.    [ smallmodel ] approsuppsat @xmath36 .",
    "* proof*. since the size of the transaction database is @xmath20 which might be exponential in the size of the instance input description , it is not possible to guess a transaction database in polynomial time and check whether it satisfies the constraints . in the following , we use other techniques to show that the problem is in * np*.",
    "let @xmath2 be the collection of item sets and @xmath21 , @xmath22 , @xmath14 , @xmath23 be the sequence of support constraints .",
    "assume that @xmath37 .",
    "let @xmath38 be an enumeration of the @xmath0 subsets of @xmath2 ( in particular , let @xmath39 and @xmath40 ) , and @xmath41 , @xmath42 , @xmath43 be @xmath0 variables corresponding to these itemsets .",
    "assume that a transaction database @xmath5 with @xmath44 transactions contains @xmath45 itemset @xmath46 for each @xmath47 and @xmath5 approximately satisfies the support constraints @xmath21 , @xmath22 , @xmath14 , @xmath23 .",
    "then there exists an integer @xmath48 such that the following equations ( [ leqa ] ) hold for some integer values @xmath49 , @xmath50 , @xmath42 , @xmath51 .",
    "similarly , if there is an integer @xmath48 and an integer solution to the equations ( [ leqa ] ) , then there is a transaction database @xmath5 with @xmath44 transactions that approximately satisfies the support constraints @xmath21 , @xmath42 , @xmath23 .",
    "@xmath52 where @xmath48 is a large enough integer . in another word ,",
    "if the given instance of the approsuppsat problem is satisfiable , then the equations ( [ leqa ] ) have an integer solution .",
    "that is , the solution space for the equation ( [ leqa ] ) is a non - empty convex polyhedron . a simple argument",
    "could then be used to show that there is an extreme point @xmath53 ( not necessarily an integer point ) on this convex polyhedron that satisfies the following property :    * there are at most @xmath54 non - zero values among the variables @xmath55 , @xmath42 , @xmath56 , @xmath50 , @xmath42 , @xmath51 .",
    "let @xmath57 $ ] be the closest integer to @xmath58 for @xmath59 and @xmath60 be the transaction database that contains @xmath61 copies of the itemset @xmath46 for each @xmath47 .",
    "then @xmath60 contains @xmath62 transactions and @xmath32 for all @xmath18 .    in another word",
    ", the given instance of the approsuppsat problem is satisfiable if and only if there exist itemsets @xmath63 and an integer sequence @xmath64 such that the transaction database @xmath5 consisting of @xmath65 copies of itemset @xmath46 for each @xmath66 witnesses the satisfiability .",
    "thus approsuppsat@xmath67 which completes the proof of lemma .",
    "[ apphard ] approsuppsat is * np*-hard .",
    "* the proof is based on an amplification of the reduction in the * np*-hardness proof for freqsat in @xcite which is alike the one given for 2sat in @xcite . in the following ,",
    "we reduce the * np*-complete problem 3-colorability to approsuppsat . given a graph @xmath68 , @xmath69 is 3-colorable if there exists a 3-coloring function @xmath70 such that for each edge @xmath71 in @xmath72 we have @xmath73 .",
    "for the graph @xmath68 , we construct an instance @xmath74 of approsuppsat as follows .",
    "let @xmath75 , and @xmath76 for some large @xmath77 ( note that we need @xmath78 for the constant @xmath48 we will discuss later ) .",
    "let the itemset @xmath79 and the @xmath33 support constraints are defined as follows . for each vertex @xmath80 : @xmath81 , support(\\{g_v\\})=[\\frac{n}{3 } ] , \\\\",
    "support(\\{b_v\\})=[\\frac{n}{3}],\\\\ support(\\{r_v , g_v\\})=0 , support(\\{r_v , b_v\\})=0,\\\\ support(\\{g_v , b_v\\})=0 .",
    "\\end{array}\\ ] ] for each edge",
    "@xmath82 : @xmath83 in the following , we show that there is a transaction database @xmath5 satisfying this approsuppsat problem if and only if @xmath69 is 3-colorable .",
    "suppose that @xmath84 is a 3-coloring of @xmath69 .",
    "let @xmath9 be a transaction defined by letting @xmath85 where @xmath86 let transactions @xmath87 and @xmath88 be defined by colorings @xmath89 and @xmath90 resulting from cyclically rearranging the colors @xmath91 in the coloring @xmath84 .",
    "let the transaction database @xmath5 consist of @xmath92 $ ] copies of each of the transaction @xmath93 , and @xmath88 ( we may need to add one or two additional copies of @xmath94 if @xmath95\\not = n$ ] ) .",
    "then @xmath5 satisfies the approsuppsat problem @xmath74 .",
    "suppose @xmath5 is a transaction database satisfying the approsuppsat problem @xmath74 .",
    "we will show that there is a transaction @xmath9 in @xmath5 from which a 3-coloring of @xmath69 could be constructed .",
    "let @xmath96 be the collection of itemsets defined as @xmath97 that is , @xmath96 is the collection of itemset that should have @xmath98 support according to the support constraints .",
    "since @xmath5 satisfies @xmath74 , for each @xmath99 , @xmath100 is approximately satisfied .",
    "thus there is a constant @xmath101 such that at most @xmath102 transactions in @xmath5 contain an itemset in @xmath96 .",
    "let @xmath103 be the transaction database obtained from @xmath5 by deleting all transactions that contain itemsets from @xmath96 .",
    "then @xmath103 contains at least @xmath104 transactions .    for each vertex @xmath80 , we say that a transaction @xmath7 in @xmath5 does not contain @xmath105 if @xmath106 does not contain any items from @xmath107 . since @xmath5 satisfies @xmath74 , for each @xmath80 , approximately one third of the transactions contain @xmath108 ( @xmath109 , @xmath110 , respectively ) .",
    "thus there is a constant @xmath111 such that at most @xmath112 transactions in @xmath5 do not contain some vertex @xmath80 . in another word",
    ", there are at least @xmath113 transactions @xmath106 in @xmath5 such that @xmath106 contains @xmath105 for all @xmath80 .",
    "let @xmath114 be the transaction database obtained from @xmath103 by deleting all transactions @xmath106 such that @xmath106 does not contain some vertex @xmath80 .",
    "the above analysis shows that @xmath114 contains at least @xmath115 transactions .",
    "let @xmath116 .",
    "then we have @xmath117 by the assumption of @xmath77 at the beginning of this proof , we have @xmath118 . for any transaction @xmath106 in @xmath114 , we can define a coloring @xmath84 for @xmath69 by letting @xmath119 by the definition of @xmath114 , the coloring @xmath84 is defined unambiguously . that is , @xmath69 is 3-colorable .",
    "this completes the proof for * np*-hardness of approsuppsat .",
    "[ npcompletetheorem ] approsuppsat is * np*-complete .",
    "* this follows from lemma [ smallmodel ] and lemma [ apphard ] .",
    "we showed that the problem approsuppsat is * np*-hard . in the proof of lemma [ apphard ]",
    ", we use the fact that the number @xmath20 of transactions of the target basket database is larger than the multiplication of the number @xmath33 of support constraints and the approximate error @xmath120 ( that is , @xmath20 is in the order of @xmath121 ) . in practice",
    ", the number @xmath20 may not be larger than @xmath122",
    ". then one may wonder whether the problem is still * np*-complete .",
    "if @xmath20 is very small , for example , at the order of @xmath120 , then obviously , the problem approsuppsat becomes trivial since one can just construct the transaction database as the collection of @xmath20 copies of the itemset @xmath2 ( that is , the entire set of items ) .",
    "this is not a very interesting case since if @xmath20 is at the order of @xmath33 , one certainly does not want the approximate error to be at the order of @xmath20 also .",
    "a reasonable problem could be that one defines a constant number @xmath123 to replace the approximate error @xmath120 .",
    "then the proof in lemma [ apphard ] shows that the problem approsuppsat with approximate error @xmath123 ( instead of @xmath120 ) is still * np*-complete if @xmath124 .",
    "tighter bounds could be achieved if weighted approximate errors for different support constraints are given .",
    "in this section , we design and analyze a linear program based algorithm to approximate the * np*-complete problem approsuppsat .",
    "let @xmath125 be the collection of items , @xmath20 be the number of transactions in the desired database @xmath5 , and @xmath21 , @xmath22 , @xmath14 , @xmath23 be the sequence of support constraints . according to the proof of lemma [ smallmodel ] ,",
    "if this instance of approsuppsat is solvable , then there is a transaction database @xmath5 , consisting of at most @xmath54 itemsets @xmath126 , that satisfies these constraints .",
    "let @xmath127 be variables representing the numbers of duplicated copies of these itemsets in @xmath5 respectively .",
    "that is , @xmath5 contains @xmath45 copies of @xmath46 for each @xmath128 . for all @xmath66 and @xmath129 , let @xmath130 and @xmath131 be variables with the property that @xmath132 and @xmath133 then we have @xmath134 and the above given approsuppsat instance",
    "could be formulated as the following question .",
    "@xmath135 subject to for @xmath136 .",
    "the condition set ( [ lpc3 ] ) contains the nonlinear equation @xmath132 and the nonlinear condition specified in ( [ lpc1 ] ) .",
    "thus in order to approximate the given approsuppsat instance using linear program techniques , we need to convert these conditions to linear conditions .",
    "we first use characteristic arrays of variables to denote the unknown itemsets @xmath63 . for any itemset @xmath6 ,",
    "let the @xmath1-ary array @xmath137 be the characteristic array of @xmath4 .",
    "that is , the @xmath128-th component @xmath138=1 $ ] if and only if @xmath139 .",
    "let @xmath140 , @xmath42 , @xmath141 be a collection of @xmath142 variables taking values from @xmath143 , representing the characteristic arrays of @xmath126 respectively .",
    "in order to convert the condition specified in ( [ lpc1 ] ) to linear conditions .",
    "we first use inner product constraints to represent the condition @xmath144 . for two characteristic arrays @xmath145 and @xmath146 , their inner product is defined as @xmath147\\cdot\\chi_2[1 ] + \\cdots+\\chi_1[t]\\cdot\\chi_2[t]$ ] .",
    "it is straightforward to show that for two itemsets @xmath148 , we have @xmath149 and @xmath150 if and only if @xmath8 .",
    "now the following conditions in ( [ lpeq1 ] ) will guarantee that the condition in ( [ lpc1 ] ) is satisfied .",
    "@xmath151 for all @xmath66 , @xmath129 , and @xmath152 .",
    "the geometric interpretation of this condition is as follows .",
    "if we consider @xmath153 as a point in the 2-dimensional space @xmath154 shown in figure [ config1 ] , then @xmath155 defines points below the line passing the points @xmath156 and @xmath157 , and @xmath158 defines the points above the line passing through the points @xmath159 and @xmath157 .",
    "thus @xmath160 if and only if @xmath161 . that is ,",
    "@xmath160 if and only if @xmath144 .",
    "the nonlinear equations @xmath132 can be converted to the following conditions consisting of inequalities .",
    "@xmath162 for all @xmath66 and @xmath129 .",
    "the constant @xmath20 is used in the inequalities due to the fact that @xmath163 for all @xmath129 . the geometric interpretation for the above inequalities",
    "is described in the following . if we consider @xmath164 as a point in a 3-dimensional space @xmath165 shown in figure [ fig1 ] , then    1 .",
    "@xmath166 defines the plane passing through points @xmath167 , @xmath168 , and @xmath169 ; thus @xmath170 guarantees that @xmath171 if @xmath172 .",
    "[ cond2 ] @xmath173 defines the points above the plane passing through points @xmath167 , @xmath174 , and @xmath169 .",
    "this condition together with the condition @xmath175 guarantees that @xmath176 when @xmath160 .",
    "3 .   @xmath177 defines the points below the plane passing through points @xmath178 , and @xmath169 . this condition together with the condition @xmath175 guarantees that @xmath179",
    "when @xmath160 . together with the condition [ cond2 ] , we have @xmath180 when @xmath160 .        * note * : for the reason of convenience , we introduced the intermediate variables @xmath131 . in order to improve the linear program performance",
    ", we may combine the conditions ( [ lpeq1 ] ) and ( [ lpeq2 ] ) to cancel the variables @xmath131 .",
    "thus the integer programming formulation for the given approsuppsat instance is as follows .",
    "@xmath181 subject to conditions ( [ lpeq1 ] ) , ( [ lpeq2 ] ) , and for @xmath136 .",
    "we first solve the linear relaxation of this integer program .",
    "that is , replace the second equation in the condition ( [ lpeq1 ] ) by @xmath182 and replace the third equation in the condition ( [ lpeq3 ] ) by @xmath183 let @xmath184 denote an optimal solution to this relaxed linear program .",
    "there are several ways to construct an integer solution @xmath185 from @xmath186 .",
    "let @xmath187 denote the optimal value of @xmath188 for a given approsuppsat instance @xmath4 and @xmath189 be the corresponding value for the computed integer solution .",
    "for an approximation algorithm , one may prefer to compute a number @xmath190 such that @xmath191 theorem [ npcompletetheorem ] shows that it is * np*-hard to approximate the approsuppsat by an additive polynomial factor .",
    "thus @xmath189 is not in the order of @xmath120 in the worst case for any polynomial time approximation algorithms , and it is not very interesting to analyze the worst case for our algorithm .    in the following ,",
    "we first discuss two simple naive rounding methods to get an integer solution @xmath185 from @xmath186 .",
    "we then present two improved randomized and derandomized rounding methods .",
    "construct an integer solution @xmath193 by rounding @xmath192 to their closest integers , rounding @xmath194 to their almost closest integers so that @xmath195 , and computing @xmath196 , and @xmath197 according to their definitions .",
    "that is , for each @xmath129 and @xmath152 set @xmath198 for the rounding of @xmath194 , first round @xmath199 to their closest integers @xmath200 $ ] .",
    "then randomly add / subtract @xmath201 s to / from these values according to the value of @xmath202 until @xmath195 .    from the construction ,",
    "it is clear that @xmath185 is a feasible solution of the integer program .",
    "the rounding procedure will introduce the following errors to the optimal solution :    1 .   by rounding @xmath203 , the values in @xmath204 change .",
    "thus the values in @xmath205 will change .",
    "thus the values in @xmath206 will be different from the values in @xmath207 .",
    "2 .   by rounding @xmath208 , the values of @xmath206 will change also .",
    "construct an integer solution @xmath193 by rounding @xmath209 to @xmath98 or @xmath194 and computing the other values according to their definitions or relationships .",
    "that is , first round @xmath199 to their closest integers @xmath200 $ ] .",
    "then randomly add / subtract @xmath201 s to / from these values according to the value of @xmath202 until @xmath195 .",
    "now round @xmath209 as follows .",
    "let @xmath210 @xmath211 s could be computed by setting @xmath212 the values of @xmath213 and @xmath214 can be derived from @xmath211 easily . we still need to further update the values of @xmath215 by using the current values of @xmath214 since we need to satisfy the requirements @xmath132 .    from the construction ,",
    "it is clear that @xmath185 is a feasible solution of the integer program .",
    "the rounding procedure will introduce the following errors to the optimal solution :    1 .   by rounding @xmath216",
    ", we need to update the values of @xmath214 , which again leads to the update of values of @xmath215 .",
    "2 .   by rounding @xmath208 , the values in @xmath206 will change also .",
    "for quite a few * np*-hard problems that are reduced to integer programs , naive round methods remain to be the ones with best known performance guarantee .",
    "our methods 1 and 2 are based on these naive rounding ideas . in last decades , randomization and derandomization methods ( see , e.g. , @xcite ) have received a great deal of attention in algorithm design . in this paradigm for algorithm design , a randomized algorithm is first designed , then the algorithm is `` derandomized '' by simulating the role of the randomization in critical places in the algorithm . in this section , we will design a randomized and derandomized rounding approach to obtain an integer solution @xmath185 from @xmath186 with performance of at least the expectation .",
    "it is done by the method of conditional probabilities .    in rounding method 1",
    ", we round @xmath192 to its closest integer . in a random rounding @xcite",
    ", we set the value of @xmath213 to @xmath201 with probability @xmath192 and to @xmath98 with probability @xmath217 ( independent of other indices ) .    in rounding method 2",
    ", we round @xmath209 to the closest value among @xmath98 and @xmath218 . in a random rounding @xcite",
    ", we set the value of @xmath215 to @xmath218 with probability @xmath219 and to @xmath98 with probability @xmath220 ( independent of other indices ) .",
    "a random rounding approach produces integer solutions with an expected value @xmath221 for @xmath222 .",
    "an improved rounding approach ( derandomized rounding ) produces integer solutions with @xmath222 guaranteed to be no larger than the expected value @xmath221 . in the following ,",
    "we illustrate our method for the random rounding based on the rounding methods 1 and 2 .    *",
    "randomized and derandomized rounding of @xmath209 .",
    "* we determine the value of an additional variable in each step .",
    "suppose that @xmath223 has already been determined , and we want to determine the value of @xmath224 with @xmath225 .",
    "we compute the conditional expectation for @xmath222 of this partial assignment first with @xmath224 set to zero , and then again with it set to @xmath226 .",
    "if we set @xmath224 according to which of these values is smaller , then the conditional expectation at the end of this step is at most the conditional expectation at the end of the previous step .",
    "this implies that at the end of the rounding , we get at most the original expectation .    in the following ,",
    "we show how to compute the conditional expectation . at the beginning of each step , assume that for all entries @xmath227 in @xmath228 , @xmath229 has been determined already and we want to determine the value of @xmath224 for @xmath225 in this step .    in order to compute the conditional expectation of @xmath222",
    ", we first compute the probability @xmath230 $ ] for all @xmath231 . for each @xmath129 , let @xmath232 if @xmath233 , then we have @xmath234 and @xmath230=1 $ ] .",
    "otherwise , continue with the following computation . by regarding @xmath219 as the probability that @xmath209 takes the value @xmath235 , we know that with at least probability @xmath219 we have @xmath144 . however , the actual probability may be larger since other entries @xmath236 with @xmath237 may contribute items to @xmath211 , which may lead to the inclusion of @xmath238 in @xmath211 .",
    "first we define the following sets . @xmath239 and @xmath240 for each @xmath241 , let @xmath242",
    "then the probability @xmath230 $ ] can be approximated as @xmath243= \\frac{x^*_{i , j}}{\\bar{x}_j } + \\left(1-\\frac{x^*_{i , j}}{\\bar{x}_j}\\right ) \\sum_{k\\in u'_{i , j } } p(i , j , k).\\ ] ] note that we say that we approximate the probability @xmath230 $ ] since in the computation , we assume that @xmath244= \\frac{x^*_{i',j}}{\\bar{x}_j}$ ] for other @xmath245 which may not be true . if necessary , we can improve the approximation by iteration .",
    "that is , repeat the above procedure for several rounds and , in each round , use the approximated probabilities for @xmath244 $ ] from the previous round .",
    "if sufficient rounds are repeated , the probability will converge in the end .",
    "since we have the probabilities @xmath230 $ ] for all @xmath231 now , it is straightforward to compute the conditional expectation of @xmath246 .",
    "the expected value for @xmath247 is @xmath248 - s_i.\\ ] ]    * randomized and derandomized rounding of @xmath192 .",
    "* we determine the value of an additional variable in each step .",
    "suppose that @xmath249 has already been determined , and we want to determine the value of @xmath250 with @xmath251 .",
    "we compute the conditional expectation for @xmath222 of this partial assignment first with @xmath252 set to zero , and then again with it set to @xmath201 .",
    "if we set @xmath250 according to which of these values is smaller , then the conditional expectation at the end of this step is at most the conditional expectation at the end of the previous step .",
    "this implies that at the end of the rounding , we get at most the original expectation .    according to our analysis in the randomized and derandomized rounding of @xmath209 , it is sufficient to compute the probability @xmath230 $ ] for all @xmath253",
    ". assume @xmath125 and @xmath254 , @xmath42 , @xmath255 .",
    "set @xmath243= \\hat{u}_{j , i_1}\\times\\cdots\\times\\hat{u}_{j , i_{|i_i|}}\\ ] ] where @xmath256 for @xmath257 .",
    "using @xmath230 $ ] , one can compute the conditional expectation of @xmath222 as in the case for rounding of @xmath209 .      in the integer linear program formulation of our problem , we have @xmath258 variables @xmath259 , @xmath54 variables @xmath260 , @xmath261 variables @xmath130 , @xmath261 variables @xmath131 , and @xmath33 variables @xmath247 . in total",
    ", we have @xmath262 variables .",
    "there are @xmath263 constraints in the condition ( [ lpeq1 ] ) , @xmath264 constraints in the condition ( [ lpeq1 ] ) , and @xmath265 constraints in the condition ( [ lpeq3 ] ) .",
    "thus we have @xmath266 constraints in total .",
    "the rounding , randomized , and derandomized rounding algorithms could be finished in @xmath267 steps .",
    "thus the major challenge is to solve the relaxed continuous variables linear program . according to @xcite ,",
    "hundreds of thousands of continuous variables are regularly solved .",
    "thus our approximation algorithm are efficient when @xmath33 and @xmath1 takes reasonable values .",
    "wang , wu , and zheng @xcite considered general information disclosure in the process of mock database generation . in this section ,",
    "we discuss privacy disclosures in synthetic transaction databases .",
    "confidential information in transaction databases may be specified as a collection of itemsets and their corresponding support ( frequency ) intervals .",
    "let @xmath268 be a set defined as follows .",
    "@xmath269 we say that a ( synthetic ) transaction database @xmath5 does not disclose confidential information specified in @xmath268 if one can not infer that @xmath270 for all @xmath271 .",
    "similarly , we say that a support constraint set @xmath272 does not disclose confidential information specified in @xmath268 if for each element @xmath271 , there is a transaction database @xmath273 that satisfies all support constraints in @xmath274 and @xmath275.\\ ] ]    for the synthetic transaction database generation , there are two scenarios for potential private information disclosure . in the first scenario ,",
    "the database owner uses the following procedure to generate the synthetic transaction database :    1 .",
    "use a software package to mine the real - world transaction database to get a set of itemset support ( frequency ) constraints ; 2 .",
    "use a software package based on our linear program methods to generate a synthetic transaction database @xmath5 from the support ( frequency ) constraints ; 3 .",
    "release the synthetic transaction database @xmath5 to the public .    in this scenario ,",
    "the mined support ( frequency ) constraints are not released to the public and only the synthetic transaction database is released . in this case , it is straightforward to protect the confidential information specified in @xmath268 .",
    "the database owner proceeds according to the above steps until step @xmath276 . before releasing the synthetic transaction database @xmath5",
    ", he can delete the confidential information as follows .",
    "* for each @xmath277 , chooses a random number @xmath278 , where @xmath20 is the total number of transactions .",
    "we distinguish the following two cases : 1 .",
    "if @xmath279 , then chooses a random series of @xmath280 transactions @xmath281 that do not contain the itemset @xmath238 , and modify these transactions to contain the itemset @xmath238 .",
    "if @xmath282 , then chooses a random series of @xmath283 transactions @xmath281 that contain the itemset @xmath238 , and modify these transactions in a random way so that they do not contain the itemset @xmath238 .    after the above process , the resulting transaction database contains no confidential information specified in @xmath268 and the database owner is ready to release it .    in the second scenario ,",
    "the database owner uses the following procedure to generate the synthetic transaction database :    1 .",
    "use a software package to mine the real - world transaction database to get a set of itemset support ( frequency ) constraints ; 2 .   release the support ( frequency ) constraints to the public ; 3 .",
    "a customer who has interest in a synthetic transaction database generates a synthetic transaction database @xmath5 from the published support ( frequency ) constraints using a software package based on our linear program methods .    in this scenario ,",
    "the mined support ( frequency ) constraints are released to the public directly . thus the database owner wants to make sure that no confidential information specified in @xmath268 is contained in these support ( frequency ) constraints . without loss of generality",
    ", we assume that there is a single element @xmath284 in @xmath268 and the mined support constraints are @xmath285 .",
    "@xmath274 contains the confidential information @xmath284 if and only if for each transaction database @xmath5 which is consistent with @xmath274 , we have @xmath286 $ ] . in another word",
    ", @xmath274 does not contain the confidential information @xmath284 if and only if there exists an integer @xmath287 with @xmath288 or @xmath289 such that @xmath290 is consistent .",
    "that is , there is a transaction database @xmath5 that satisfies all support constraints in @xmath290 . in the following ,",
    "we show that there is even no efficient way to approximately decide whether a given support constraint set contains confidential information .",
    "we first define the problem formally .",
    "approprivacy    _ instance _ : an integer @xmath20 , an item set @xmath2 , a support constraint set @xmath291 , @xmath14 , @xmath292 , and a set @xmath293    _ question _ : for all transaction database @xmath5 of @xmath20 transactions over @xmath2 with @xmath294 for all @xmath18 , do we have @xmath295 $ ] for all @xmath296 ?",
    "if the answer is yes , we write @xmath297 .    by theorem [ npcompletetheorem ] , we have the following result .",
    "similar * np*-hardness results for exact frequency constraints inference have been obtained in @xcite .",
    "[ prinp ] approprivacy is co*np*-complete .",
    "* proof . *",
    "@xmath298 if and only if there is a transaction database @xmath5 and an index @xmath299 such that @xmath5 satisfies @xmath300 or @xmath5 satisfies @xmath301 approximately .",
    "thus the theorem follows from theorem [ npcompletetheorem ] .",
    "thus there is no efficient way for the database owner to decide whether a support constraint set @xmath274 leaks confidential information specified in @xmath268 . in practice , however , we can use the linear program based approximation algorithms that we have discussed in section [ appsection ] to compute the confidence level about private information leakage as follows .    1 .",
    "convert the condition @xmath302 to an integer linear program in the format of ( [ lpeq3 ] ) .",
    "note that the condition `` @xmath303 '' is equivalent to the existential clause @xmath304 .",
    "thus it is straightforward to convert it to integer linear program conditions .",
    "2 .   let the confidence level be @xmath305 .",
    "the smaller @xmath84 , the higher confidence . in the ideal case of @xmath306",
    ", we have found an itemset transaction database @xmath5 that witnesses that no confidential information specified by @xmath307 is leaked in @xmath274 .    if the database owner thinks that the confidence value @xmath305 obtained in the above procedure is too larger ( thus confidence level is too low ) .",
    "he may use the following procedure to delete potential confidential information from the support constraint set .    1 .",
    "let @xmath128 be the number that maximizes @xmath308 .",
    "2 .   modify the value @xmath309 to be a random value .",
    "3 .   approximately revise support constraint values in @xmath274 to make it consistent .",
    "for example , to make it satisfy the monotonic rule .",
    "since it is * np*-hard to determine whether a support constraint set is consistent , we can only revise the set @xmath274 to be approximately consistent .",
    "it should be noted that after the above process , the resulting support constraint set may become inconsistent .",
    "thus in the next round , the value @xmath305 may be larger .",
    "if that happens , the larger value @xmath84 does not interpret as the privacy confidence level .",
    "instead , it should be interpreted as an indicator for inconsistency of the support constraint set .",
    "thus the above privacy deletion procedure should only be carried out one time .",
    "we should note that even if the confidence level is higher , ( that is , @xmath305 is small ) , there is still possibility that the confidential information specified by @xmath307 is leaked in theory .",
    "that is , for each transaction database @xmath5 that satisfies the constraints @xmath274 , we have @xmath310 $ ] .",
    "however , no one may be able to recover this information since it is * np*-hard to infer this fact .",
    "support constraint inference has been extensively studied by calders in @xcite .",
    "it would be interesting to consider conditional privacy - preserving synthetic transaction database generations .",
    "that is , we say that no private information is leaked unless some hardness problems are solved efficiently .",
    "this is similar to the methodologies that are used in public key cryptography .",
    "for example , we believe that rsa encryption scheme is secure unless one can factorize large integers .    in our case , we may assume that it is hard on average to efficiently solve integer linear programs .",
    "based on this assumption , we can say that unless integer linear programs could be solved efficiently on average , no privacy specified in @xmath268 is leaked by @xmath274 if the computed confidence level @xmath305 is small .",
    "privacy preserving data mining has been a very active research topic in the last few years .",
    "there are two general approaches mainly from privacy preserving data mining framework : data perturbation and the distributed secure multi - party computation approach .",
    "as the context of this paper focuses on data perturbation for single site , we will not discuss the multi - party computation based approach for distributed cases ( see @xcite for a recent survey ) .",
    "agrawal and srikant , in @xcite , first proposed the development of data mining techniques that incorporate privacy concerns and illustrated a perturbation based approach for decision tree learning .",
    "agrawal and agrawal , in @xcite , have provided a expectation - maximization ( em ) algorithm for reconstructing the distribution of the original data from perturbed observations .",
    "they provide information theoretic measures to quantify the amount of privacy provided by a randomization approach .",
    "recently , huang et al . in @xcite , investigated how correlations among attributes affect the privacy of a data set disguised via the random perturbation scheme and proposed methods ( pca based and mle based ) to reconstruct original data .",
    "the objective of all randomized based privacy - preserving data mining @xcite is to prevent the disclosure of confidential individual values while preserving general patterns and rules .",
    "the idea of these randomization based approaches is that the distorted data , together with the distribution of the random data used to distort the data , can be used to generate an approximation to the original data values while the distorted data does not reveal private information , and thus is _ safe _ to use for mining .",
    "although privacy preserving data mining considers seriously how much information can be inferred or computed from large data made available through data mining algorithms and looks for ways to minimize the leakage of information , however , the problem how to quantify and evaluate the tradeoffs between data mining accuracy and privacy is still open @xcite .    in the context of privacy preserving association rule mining , there have also been a lot of active researches . in @xcite ,",
    "the authors considered the problem of limiting disclosure of sensitive rules , aiming at selectively hiding some frequent itemsets from large databases with as little impact on other , non - sensitive frequent itemsets as possible .",
    "the idea was to modify a given database so that the support of a given set of sensitive rules decreases below the minimum support value .",
    "similarly , the authors in @xcite presented a method for selectively replacing individual values with unknowns from a database to prevent the discovery of a set of rules , while minimizing the side effects on non - sensitive rules .",
    "the authors studied the impact of hiding strategies in the original data set by quantifying how much information is preserved after sanitizing a data set @xcite .",
    "the authors , in @xcite , studied the problem of mining association rules from transactions in which the data has been randomized to preserve privacy of individual transactions .",
    "one problem is it may introduce some false association rules .",
    "the authors , in @xcite , investigated distributed privacy preserving association rule mining .",
    "though this approach can fully preserve privacy , it works only for distributed environment and needs sophisticated protocols ( secure multi - party computation based @xcite ) , which makes it infeasible for our scenario .",
    "have proposed a general framework for privacy preserving database application testing by generating synthetic data sets based on some a - priori knowledge about the production databases @xcite .",
    "the general a - priori knowledge such as statistics and rules can also be taken as constraints of the underlying data records . the problem investigated in this paper",
    "can be thought as a simplified problem where data set here is binary one and constraints are frequencies of given frequent itemsets .",
    "however , the techniques developed in @xcite are infeasible here as the number of items are much larger than the number of attributes in general data sets .",
    "in this paper , we discussed the general problems regarding privacy preserving synthetic transaction database generation for benchmark testing purpose .",
    "in particular , we showed that this problem is generally * np*-hard .",
    "approximation algorithms for both synthetic transaction database generation and privacy leakage confidence level approximation have been proposed .",
    "these approximation algorithms include solving a continuous variable linear program . according to @xcite ,",
    "linear problems having hundreds of thousands of continuous variables are regularly solved .",
    "thus if the support constraint set size is in the order of hundreds of thousands , then these approximation algorithms are efficient on regular pentium - based computers . if more constraints are necessary , then more powerful computers are needed to generate synthetic transaction databases .",
    "r.  agrawal , t.  imilienski , and a.  swami .",
    "mining association rules between sets of items in large databases . in _ proc . of acm",
    "sigmod international conference on management of database _ , pages 207216 , 1993 .",
    "a.  evfimievski , j.  gehrke , and r.  srikant .",
    "limiting privacy breaches in privacy preserving data mining . in : _",
    "the 22nd acm sigmod - sigact - sigart symposium on principles of database system ( pods ) _ , pages 211222 , 2003 .",
    "a.  evfimievski , r.  srikant , r.  agrawal , and j.  gehrke .",
    "privacy preserving mining of association rules . in : _",
    "8th acm sigkdd international conference on knowledge discovery and data mining _ , pages 217228 , edmonton , canada , 2002 .",
    "m.  kantarcioglu and c.  clifton .",
    "privacy preserving distributed mining of association rules on horizontally partitioned data . in : _ proc .",
    "acm sigmod workshop on research issues on data mining and knowledge discovery _ ,",
    "pages 2431 , 2002 .",
    "h.  kargupta , s.  datta , q.  wang , and k.  sivakumar . on the privacy preserving properties of random data perturbation techniques . in : _",
    "3rd international conference on data mining _ , pages 99 - 106 , 2003 .",
    "g.  ramesh , w.  maniatty , and m.  zaki .",
    "feasible itemset distributions in data mining : theory and application . in : _",
    "22nd acm sigmod - sigact - sigart symposium on principles of database systems ( pods ) _ , pages 284295 , 2003 .",
    "d.  shmoys . computing near - optimal solutions to combinatorial optimization problems .",
    "_ dimacs series in discrete mathematics and theoretical computer science : combinatorial optimization _ , pages 355398 .",
    "ams press , 1995 .",
    "y.  wang , x.  wu , and y.  zheng .",
    "privacy preserving data generation for database application performance testing . in : _ proc .",
    "1st int . conf . on trust and privacy in digital business",
    "( trustbus 04 , together with dexa ) _ , lecture notes in computer science 3184 , pages 142 - 151 , 2004 , springer - verlag .",
    "x.  wu , y.  wu , y.  wang , and y.  li .",
    "privacy aware market basket data set generation : a feasible approach for inverse frequent set mining . in : _",
    "proc . of the 5th siam international conference on data mining _ , april 2005 .",
    "z.  zheng , r.  kohavi , and l.  mason .",
    "real world performance of association rule algorithms . in _ proc . of the acm - sigkdd international conference on knowledge discovery and data mining _ , pages 401406 .",
    "acm press , 2001 ."
  ],
  "abstract_text": [
    "<S> in order to generate synthetic basket data sets for better benchmark testing , it is important to integrate characteristics from real - life databases into the synthetic basket data sets . </S>",
    "<S> the characteristics that could be used for this purpose include the frequent itemsets and association rules . </S>",
    "<S> the problem of generating synthetic basket data sets from frequent itemsets is generally referred to as inverse frequent itemset mining . in this paper , we show that the problem of approximate inverse frequent itemset mining is * np*-complete . </S>",
    "<S> then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining , and discuss privacy issues related to the synthetic basket data set . </S>",
    "<S> in particular , we propose an approximate algorithm to determine the privacy leakage in a synthetic basket data set .    </S>",
    "<S> keywords : data mining , privacy , complexity , inverse frequent itemset mining </S>"
  ]
}