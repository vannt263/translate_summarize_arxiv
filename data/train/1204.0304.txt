{
  "article_text": [
    "distributed optimization of a sum of convex functions has applications in a variety of scenarios , including sensor networks , source localization , and robust estimation , and has been intensively studied in recent years , see e.g.  @xcite .",
    "most of these works build on consensus - based dynamics  @xcite to design discrete - time algorithms that find the solution of the optimization problem . a recent exception",
    "are the works  @xcite that deal with continuous - time strategies on undirected networks .",
    "this paper furthers contributes to this body of work by studying continuous - time algorithms for distributed optimization in directed scenarios .    the unidirectional information flow among agents characteristic of directed networks often leads to significant technical challenges when establishing convergence and robustness properties of coordination algorithms .",
    "the results of this paper provide one more example in support of this assertion for the case of continuous - time consensus - based distributed optimization .",
    "this is somewhat surprising given that , for consensus , the same dynamics works for both undirected connected graphs and strongly connected , weight - balanced directed graphs , see e.g. ,  @xcite .",
    "the contributions of this paper are the following .",
    "we first show that the solutions of the optimization problem of a sum of locally lipschitz convex functions over a directed graph ( or digraph ) correspond to the saddle points of an aggregate objective function that depends on the graph topology through its laplacian .",
    "this function is convex in its first argument and linear in the second .",
    "moreover , its gradient is distributed when the graph is undirected .",
    "our second step is then to study the convergence properties of the saddle - point dynamics and establish its asymptotic correctness when the original functions are locally lipschitz ( i.e. , not necessarily differentiable ) and convex , extending the results available in the literature  @xcite for continuously differentiable , strictly convex functions .",
    "next , we consider the optimization problem over digraphs .",
    "we first provide an example of a strongly connected , weight - balanced digraph where the distributed version of the saddle - point dynamics does not converge .",
    "this motivates us to introduce a generalization of the dynamics that incorporates a design parameter .",
    "we show that , when the original functions are differentiable and convex with globally lipschitz gradients , the design parameter can be appropriately chosen so that the resulting dynamics asymptotically converge to the set of minimizers of the objective function on any strongly connected and weight - balanced digraph .",
    "our technical approach combines notions and tools from set - valued stability analysis , algebraic graph theory , and convex analysis .",
    "we start with notational conventions .",
    "let @xmath0 and @xmath1 denote the set of reals and nonnegative reals , respectively .",
    "we let @xmath2 denote the euclidean norm on @xmath3 .",
    "we let @xmath4 , @xmath5 , and @xmath6 denote the identity matrix in @xmath7 . for @xmath8 and @xmath9",
    ", @xmath10 is their kronecker product .",
    "a function @xmath11 , with @xmath12 , @xmath13 closed and convex , is _ concave - convex _ if it is concave in its first argument and convex in the second one .",
    "a _ saddle point _",
    "@xmath14 of @xmath15 satisfies @xmath16 for all @xmath17 and @xmath18 .",
    "a set - valued map @xmath19 takes elements of @xmath20 to subsets of  @xmath20 .",
    "we present basic notions from algebraic graph theory  @xcite . a _ directed graph _ , or _ digraph _",
    ", is a pair @xmath21 , where @xmath22 is the ( finite ) vertex set and @xmath23 is the edge set .",
    "a digraph is _ undirected _ if @xmath24 anytime @xmath25 .",
    "we refer to an undirected digraph as a _",
    "graph_. a path is an ordered sequence of vertices such that any pair of vertices appearing consecutively is an edge .",
    "a digraph is _ strongly connected _ if there is a path between any pair of distinct vertices . for a graph , this notion is referred to as _ connected_. a _ weighted digraph _ is a triplet @xmath26 , where @xmath27 is a digraph and @xmath28 is the _ adjacency matrix _ , satisfying @xmath29 if @xmath30 and @xmath31 , otherwise . the weighted out - degree and in - degree of @xmath32 , @xmath33 , are respectively , @xmath34 and @xmath35 . the _ weighted out - degree matrix _",
    "@xmath36 is diagonal with @xmath37 , for @xmath38 .",
    "the _ laplacian _",
    "matrix is @xmath39 .",
    "note that @xmath40 .",
    "if @xmath41 is strongly connected , then zero is a simple eigenvalue of @xmath42 .",
    "@xmath43 is undirected if @xmath44 and _ weight - balanced _ if @xmath45 , for all @xmath46 .",
    "the following three notions are equivalent : ( i ) @xmath43 is weight - balanced , ( ii ) @xmath47 , and ( iii ) @xmath48 is positive semidefinite , see e.g. ,  ( * ? ? ?",
    "* theorem  1.37 ) . if @xmath43 is weight - balanced and strongly connected , then zero is a simple eigenvalue of @xmath49 .",
    "any undirected graph is weight - balanced .",
    "we recall some notions from nonsmooth analysis  @xcite .",
    "a function @xmath50 is _ locally lipschitz _ at @xmath51 if there exists a neighborhood @xmath52 of @xmath53 and @xmath54 such that latexmath:[$ |f(y)-f(z)|\\leq c_x    locally lipschitz on @xmath20 if it is locally lipschitz at @xmath56 for all @xmath57 and _ globally lipschitz _ on @xmath58 if for all @xmath59 there exists @xmath60 such that @xmath61 denotes the set of points where @xmath15 fails to be differentiable , the _",
    "generalized gradient _ of @xmath15 is @xmath62 where @xmath63 is any set of measure zero and @xmath64 denotes convex hull .    [ le : gradient_properties ] let @xmath50 be a locally lipschitz function at @xmath65 .",
    "then the set - valued map @xmath66 is upper semicontinuous and locally bounded at @xmath67 and moreover , @xmath68 is nonempty , compact , and convex .    for @xmath69 and @xmath70 ,",
    "we let @xmath71 denote the generalized gradient of @xmath72 . similarly , for @xmath57 , we let @xmath73 denote the generalized gradient of @xmath74 .",
    "a _ critical point _",
    "@xmath67 of @xmath15 satisfies @xmath75 .",
    "a function @xmath50 is _ regular _ at @xmath76 if for all @xmath77 the right directional derivative of @xmath15 , in the direction of @xmath78 , exists at @xmath79 and coincides with the generalized directional derivative of @xmath15 at @xmath80 in the direction of  @xmath81 , see  @xcite for definitions of these notions .",
    "a convex and locally lipschitz function at @xmath79 is regular  ( * ? ? ?",
    "* proposition  2.3.6 ) .",
    "[ le : finite_sum_gen ] let @xmath82 be locally lipschitz at @xmath83 .",
    "then @xmath84 , and equality holds if @xmath85 is regular for @xmath86 ( here , the summation of sets is the set of points of the form @xmath87 , with @xmath88 ) .",
    "a locally lipschitz and convex function @xmath89 satisfies , for all @xmath90 and @xmath91 , the _ first - order condition _ of convexity , @xmath92 the notion of cocoercivity  @xcite plays a key role in our technical approach later .",
    "for @xmath93 , a locally lipschitz function @xmath89 is @xmath94-_cocoercive _ if , for all @xmath95 and @xmath96 , @xmath97 , @xmath98 the next result  ( * ? ? ?",
    "* lemma  6.7 ) characterizes cocoercive differentiable convex functions .",
    "[ prop : coco_nes_suff ] let @xmath15 be a differentiable convex function .",
    "then , @xmath99 is globally lipschitz with constant @xmath100 iff @xmath15 is @xmath101-cocoercive .      here",
    ", we recall some background on set - valued dynamical systems following  @xcite .",
    "a continuous - time set - valued dynamical system on @xmath102 is a differential inclusion @xmath103 where @xmath104 and @xmath105 is a set - valued map .",
    "a solution to this dynamical system is an absolutely continuous curve @xmath106\\rightarrow { \\mathsf{x}}$ ] which satisfies   almost everywhere .",
    "the set of equilibria of   is denoted by @xmath107 .    [",
    "le : solution ] for @xmath108 upper semicontinuous with nonempty , compact , and convex values , there exists a solution to   from any initial condition .",
    "the lasalle invariance principle is helpful to establish the asymptotic convergence of systems of the form  .",
    "a set @xmath109 is _ weakly positively invariant _ under   if , for each @xmath110 , there exists at least one solution of   starting from @xmath56 entirely contained in @xmath111 .",
    "similarly , @xmath112 is _ strongly positively invariant _ under   if , for each @xmath110 , all solutions of   starting from @xmath56 are entirely contained in @xmath111 .",
    "finally , the _ set - valued lie derivative _ of a differentiable function @xmath113 with respect to @xmath114 at @xmath67 is @xmath115 .",
    "[ th : lasalle ] let @xmath109 be strongly positively invariant under   and @xmath116 a continuously differentiable function .",
    "suppose the evolutions of   are bounded and @xmath117 or @xmath118 , for all @xmath119 .",
    "let @xmath120 .",
    "then any solution @xmath121 , @xmath122 , starting in @xmath111 converges to the largest weakly positively invariant set @xmath123 contained in @xmath124 .",
    "when @xmath125 is a finite collection of points , then the limit of each solution equals one of them .",
    "consider a network composed by @xmath126 agents @xmath127 whose communication topology is described by a strongly connected digraph @xmath43 .",
    "an edge @xmath128 represents the fact that @xmath32 can receive information from @xmath129 . for each @xmath130 , let @xmath131 be locally lipschitz and convex , and only available to agent @xmath32 .",
    "the network objective is to solve @xmath132 in a distributed way .",
    "let @xmath133 denote the estimate of agent @xmath134 about the value of the solution to   and let @xmath135 .",
    "next , we provide an alternative formulation of  .    [",
    "le : equiv - ftilde ] let @xmath136 be the laplacian of @xmath43 and define @xmath137 .",
    "the problem   on @xmath20 is equivalent to the following problem on @xmath138 , @xmath139    the proof follows by noting that ( i ) @xmath140 for all @xmath57 and ( ii ) since @xmath43 is strongly connected , @xmath141",
    "if and only if @xmath142 , for some @xmath57 .    the formulation   is appealing because it brings together the estimates of each agent about the value of the solution to the original optimization problem .",
    "note that @xmath143 is locally lipschitz and convex .",
    "moreover , from lemma  [ le : finite_sum_gen ] , the elements of its generalized gradient are of the form @xmath144 where @xmath145 , for @xmath146 .",
    "since @xmath147 is convex and the constraints in   are linear , the constrained optimization problem is feasible  @xcite .    the next result introduces a function which corresponds to the lagrangian function associated to the constrained optimization problem   plus an additional quadratic term that vanishes if the agreement constraint is satisfied .",
    "interestingly , the saddle points of this function correspond to the solutions of the constrained optimization problem , as we show next .",
    "[ prop : equiv - f ] let @xmath43 be strongly connected and weight - balanced , and define @xmath148 by @xmath149 then @xmath150 is locally lipschitz and convex in its first argument and linear in its second , and    1 .",
    "if @xmath151 is a saddle point of @xmath152 , then so is @xmath153 , for any @xmath154 .",
    "if @xmath155 is a saddle point of @xmath152 , then @xmath156 is a solution of  .",
    "if @xmath157 is a solution of  , then there exists @xmath158 with @xmath159 such that @xmath155 is a saddle point of @xmath152 .",
    "first , note that for @xmath43 weight - balanced , @xmath160 is positive semi - definite .",
    "since the sum of convex functions is convex , one deduces that @xmath150 is convex in its first argument . by inspection ,",
    "@xmath152 is linear in its second argument .",
    "the statement  ( i ) is immediate . to show  ( ii ) , using that @xmath43 is strongly connected",
    ", one can see that the saddle points of  @xmath152 are of the form @xmath161 with @xmath162 , @xmath163 , and @xmath164 .",
    "the last inclusion implies that there exist @xmath165 , @xmath166 , such that @xmath167 .",
    "noting that @xmath168 we deduce @xmath169 . as a result , using lemma  [ le : finite_sum_gen ] , @xmath157 is a solution of  .",
    "finally , ( iii ) follows by noting @xmath170 and the fact that @xmath171 implies that there exists @xmath172 with @xmath159 , yielding that @xmath173 is a saddle point of  @xmath152 .",
    "here , we review the continuous - time solution to the optimization problem proposed in  @xcite for undirected graphs . if @xmath43 is undirected , the gradient of @xmath152 in   is distributed over @xmath43 . given proposition  [ prop : equiv - f ] , it is natural to consider the saddle - point dynamics of  @xmath152 to solve  ,    [ eq : ct - laplacian - optimization ] @xmath174    note that   is a set - valued dynamical system . using lemmas  [ le : gradient_properties ] and  [ le : solution ]",
    ", one can guarantee the existence of solutions .",
    "moreover , from proposition  [ prop : equiv - f ] , if @xmath175 is an equilibrium of  , then @xmath157 is a solution to  . according to  @xcite ,",
    "the dynamics   leads the network to agree on a global minimum of  @xmath89 for the case when  @xmath43 is undirected and  @xmath89 is both strictly convex and the sum of differentiable convex functions .",
    "we extend here this result to the case when @xmath43 is undirected and  @xmath89 is the sum of locally lipschitz convex functions .",
    "the proof is also useful later to illustrate the challenges in solving the distributed optimization problem over directed graphs .    [",
    "theorem : dis_opt ] let @xmath43 be a connected graph and consider the optimization problem  , where each @xmath85 , @xmath176 is locally lipschitz and convex .",
    "then , the projection onto the first component of any trajectory of   asymptotically converges to the set of solutions to  .",
    "moreover , if @xmath15 has a finite number of critical points , the limit of the projection onto the first component of each trajectory is a solution of  .    for convenience ,",
    "we denote the dynamics   by @xmath177 .",
    "let @xmath178 be a solution of  .",
    "by proposition  [ prop : equiv - f](iii ) , there exists @xmath158 such that @xmath179 .",
    "first , note that given any initial condition @xmath180 , the set @xmath181 is strongly positively invariant under  .",
    "consider then the function @xmath182 , @xmath183 the function @xmath184 is smooth .",
    "let us examine its set - valued lie derivative . for each @xmath185",
    ", there exists @xmath186 , with @xmath187 , such that @xmath188 since @xmath152 is convex in its first argument and @xmath189 , using the first - order condition of convexity  , we deduce @xmath190 . on the other hand",
    ", the linearity of @xmath152 in its second argument implies that @xmath191 .",
    "therefore , @xmath192 .",
    "since the equilibria of @xmath193 are the saddle points of @xmath152 , we deduce that @xmath194 .",
    "since @xmath195 is arbitrary , we conclude @xmath196 . as a by - product , the trajectories of   are bounded .",
    "consequently , all assumptions of the set - valued version of the lasalle invariance principle , cf .",
    "theorem  [ th : lasalle ] , are satisfied .",
    "this result then implies that any trajectory of   starting from an initial condition @xmath197 converges to the largest weakly positively invariant set @xmath125 in @xmath198 .",
    "our final step consists of characterizing @xmath125 .",
    ". then @xmath200 , i.e. , @xmath201 define now @xmath202 by @xmath203 . note that @xmath204 is convex in its first argument and linear in its second , and that it has the same saddle points as @xmath150 . as a result , @xmath205 , or equivalently , @xmath206 . combining this with",
    ", we have @xmath207 and @xmath208 , i.e. , @xmath209 is solution to  .",
    "since @xmath125 is weakly positively invariant , there exists at least a solution of   starting from @xmath210 that remains in @xmath211 .",
    "this implies that , along the solution , the components of @xmath212 remain in agreement , i.e. , @xmath213 with @xmath214 a solution of  . applying @xmath215 on both sides of @xmath216 , we deduce @xmath217 .",
    "lemma  [ lemma : flow - in - critical ] then implies that @xmath218 , i.e. , @xmath219 and thus @xmath220 .",
    "finally , if the set of equilibria is finite , the last statement holds true .",
    "the work  @xcite studies saddle - point dynamics and guarantees asymptotic convergence to a saddle point when the function s hessian in one argument is positive definite and the function is linear in the other . such result , however , can not be applied to establish theorem  [ theorem : dis_opt ] because the generality of the hypotheses on  @xmath89 mean that  @xmath152 might not satisfy these conditions .",
    "instead , our proof shows that a careful study of the invariance properties of the flow yields the desired result .",
    "here , we consider the optimization problem   on digraphs . when @xmath43 is directed , the gradient of @xmath152 defined in   is no longer distributed over @xmath43 because it contains terms that involve @xmath221 and hence requires agents to receive information from its in - neighbors . in fact",
    ", the dynamics  , which is distributed over @xmath43 , does no longer correspond to the saddle - point dynamics of @xmath152 .",
    "nevertheless , it is natural to study whether   enjoys the same convergence properties as in the undirected setting ( as , for instance , is the case in the agreement problem  @xcite ) .",
    "surprisingly , this turns out not to be the case , as shown in section  [ se : surprise ] .",
    "this result motivates the introduction in section  [ se : the - right - one ] of an alternative provably correct dynamics on weight - balanced directed graphs .      here , we provide an example of a strongly connected , weight - balanced digraph on which   fails to converge . for convenience , we let @xmath222 denote the set of agreement configurations .",
    "our construction relies on the following result .",
    "[ lemma : necessary_linear_directed ] let @xmath43 be a strongly connected digraph and @xmath223 , @xmath86 . then @xmath224 is stable under   iff , for any nonzero eigenvalue @xmath225 of the laplacian @xmath226 , one has @xmath227 .    by assumption ,",
    "the dynamics   is linear with matrix @xmath228 and has @xmath224 as equilibria .",
    "the eigenvalues of the matrix are of the form @xmath229 , with @xmath225 an eigenvalue of @xmath230 ( because the eigenvalues of a kronecker product are just the product of the eigenvalues of the corresponding matrices ) .",
    "since @xmath231 , each eigenvalue of @xmath230 is an eigenvalue of @xmath226 .",
    "finally , @xmath232 , from which the result follows .",
    "it is not difficult to construct examples of convex functions that have zero contribution to the linearization of   around the solution .",
    "therefore , such systems can not be convergent if they fail the criterium identified in lemma  [ lemma : necessary_linear_directed ] .",
    "the next example shows that this criterium can fail even for strongly connected weight - balanced digraphs .",
    "[ example : counter ] consider the strongly connected , weight - balanced digraph with @xmath233 as adjacency matrix .",
    "note that @xmath234 is an eigenvalue of the laplacian .",
    "since @xmath235 , lemma  [ lemma : necessary_linear_directed ] implies that   fails to converge .      here ,",
    "given the result in section  [ se : surprise ] , we introduce an alternative continuous - time distributed dynamics for strongly connected weight - balanced digraphs . for reasons that will be made clear later in remark  [ remark : diff_assumption ] ,",
    "we restrict our attention to the case when the functions @xmath236 , @xmath176 are continuously differentiable .",
    "let @xmath237 and consider the dynamics    [ eq : ct - laplacian - optimization - new ] @xmath238    the existence of solutions is guaranteed by lemmas  [ le : gradient_properties ] and  [ le : solution ] .",
    "we first show that appropriate choices of @xmath239 allow to circumvent the problem raised in lemma  [ lemma : necessary_linear_directed ] .",
    "[ lemma : necessary_linear_directed - new ] let @xmath43 be a strongly connected and weight - balanced digraph and @xmath240 , @xmath166 . if @xmath241 , then @xmath224 is asymptotically stable under  .    when all @xmath242 , @xmath176 , are identically zero , the dynamics   is linear and has @xmath224 as equilibria .",
    "consider the coordinate transformation from @xmath243 to @xmath244 , with @xmath245 to be chosen later .",
    "the dynamics can be rewritten as @xmath246 consider the candidate lyapunov function @xmath247 .",
    "its lie derivative is the quadratic form defined by the matrix @xmath248 select @xmath249 now satisfying @xmath250 ( this equation has a real solution if @xmath251 ) .",
    "then , @xmath252 each eigenvalue @xmath253 of @xmath254 is of the form @xmath255 , where @xmath256 is an eigenvalue of @xmath49 .",
    "since @xmath43 is strongly connected and weight - balanced , @xmath257 is positive semidefinite with a simple eigenvalue at zero , and hence @xmath258 . by the lasalle invariance principle",
    ", the solutions of   from any initial condition @xmath259 , asymptotically converge to the set @xmath260 . to conclude the result",
    ", we need to show that @xmath261 .",
    "this follows from noting that , for @xmath262 , @xmath263 implies that @xmath264 and @xmath265 , i.e. , @xmath266 .",
    "the reason behind the introduction of the parameter @xmath239 in   comes from the following observation : if one tries to reproduce the proof of theorem  [ theorem : dis_opt ] for a digraph , one encounters indefinite terms of the form @xmath267 in the lie derivative of @xmath184 , invalidating it as a lyapunov function .",
    "however , the proof of lemma  [ lemma : necessary_linear_directed - new ] shows that an appropriate choice of @xmath239 , together with a suitable change of coordinates , makes the quadratic form defined by the identity matrix a valid lyapunov function .",
    "we next build on these observations to establish our main result : the dynamics   solves in a distributed way the optimization problem   on strongly connected weight - balanced digraphs .",
    "[ theorem : dis_opt - directed ] let @xmath43 be a strongly connected , weight - balanced digraph and consider the optimization problem  , where each @xmath268 , @xmath38 , is convex and differentiable with globally lipschitz continuous gradient .",
    "let @xmath100 be the lipschitz constant of @xmath269 and define @xmath270 by @xmath271 where @xmath272 denotes the non - zero eigenvalue with smallest absolute value .",
    "then , there exists @xmath273 with @xmath274 such that , for all @xmath275 , the projection onto the first component of any trajectory of   with @xmath276 asymptotically converges to the set of solutions of  . moreover , if @xmath15 has a finite number of critical points , the limit of the projection onto the first component of each trajectory is a solution of  .    for convenience ,",
    "we denote the dynamics   by @xmath277 .",
    "note that the equilibria of @xmath278 are precisely the set of saddle points of @xmath152 in  .",
    "let @xmath178 be a solution of  .",
    "first , note that given any initial condition @xmath180 , the set @xmath279 defined by   is invariant under the evolutions of  . by proposition  [ prop : equiv - f](i ) and",
    "( iii ) , there exists @xmath280 .",
    "consider the function @xmath281 , @xmath282 where @xmath283 and @xmath284 satisfies @xmath250 .",
    "this function is quadratic , hence smooth .",
    "next , we consider its lie derivative along @xmath278 on @xmath285 . for @xmath286 ,",
    "let @xmath287 where @xmath288 is given by  .",
    "this equation can be written as @xmath289 where @xmath254 is given by  .",
    "note that @xmath290 .",
    "thus , after substituting for @xmath291 , we have @xmath292 where @xmath293 each eigenvalue of @xmath294 is of the form @xmath295 where @xmath296 is an eigenvalue of @xmath49 . using the cocoercivity of @xmath147 ,",
    "we can upper bound @xmath297 as , @xmath298 where @xmath100 is the lipschitz constant for the gradient of @xmath147 .    since @xmath299 , we have @xmath300 and hence it is enough to establish that  @xmath301 is negative semidefinite on the subspace @xmath302 . using the fact that @xmath303 is invertible , we can express @xmath301 as @xmath304 noting that @xmath305 is invariant under @xmath306 ( i.e. , @xmath307 ) , all we need to check is that the matrix @xmath308 is negative semidefinite on @xmath305 .",
    "clearly , @xmath309 is negative definite . on the other hand , on @xmath310 ,",
    "@xmath311 is an eigenvalue of @xmath312 with multiplicity @xmath313 and eigenspace generated by vectors of the form @xmath314 and @xmath315 , with @xmath316 .",
    "however , on @xmath317 , @xmath311 is an eigenvalue of @xmath312 with multiplicity @xmath318 and eigenspace generated by vectors of the form @xmath314 .",
    "moreover , on @xmath317 , the eigenvalues of @xmath319 are @xmath320 with multiplicity @xmath321 and @xmath311 with multiplicity @xmath322 . therefore , using weyl s theorem  ( * ? ? ?",
    "* theorem 4.3.7 ) , we deduce that the nonzero eigenvalues of the sum @xmath323 are upper bounded by @xmath324 . from   and the definition of @xmath325 in  , we conclude that the nonzero eigenvalues of  @xmath326 are upper bounded by @xmath327 .",
    "it remains to show that there exists @xmath328 with @xmath329 such that for all @xmath330 we have @xmath331 .",
    "for @xmath332 small enough , @xmath333 , since @xmath334 .",
    "furthermore , @xmath335 .",
    "hence , the existence of @xmath336 follows from the mean value theorem",
    ". therefore we conclude @xmath337 . as a by - product , the trajectories of   are bounded .",
    "consequently , all assumptions of the lasalle invariance principle are satisfied and its application yields that any trajectory of   starting from an initial condition @xmath197 converges to the largest positively invariant set @xmath211 in @xmath338 . note that if @xmath339 , then @xmath340 . from the discussion above ,",
    "we know @xmath341 is generated by vectors of the form @xmath314 , and hence this implies that @xmath342 , @xmath343 , and @xmath344 , from where we deduce that @xmath212 is also a solution to  . finally , for @xmath345 ,",
    "an argument similar to the one in the proof of theorem  [ theorem : dis_opt ] establishes @xmath346 .",
    "if the set of equilibria is finite , convergence to a point is also guaranteed .",
    "figure  [ fig : sim ] illustrates the result of theorem  [ theorem : dis_opt - directed ] for the network of example  [ example : counter ] .    [ ] [ rr ] [ rr][rr]@xmath347 [ rr][rr]@xmath348    [ rr][rr]@xmath349 [ rr][rr]@xmath350    [ rr][rr]@xmath351 [ rr][rr]@xmath352 [ rr][rr]@xmath353 [ rr][rr]@xmath354 [ rr][rr]@xmath355 [ rr][rr]@xmath356 [ rr][rr]@xmath357    [ rr][rr]@xmath358 [ rr][rr]@xmath359 [ rr][rr]@xmath360    [ rr][rr ] [ rr][rr ] [ rr][rr ] [ rr][rr ] [ rr][rr ] [ rr][rr ] [ rr][rr ]    [ remark : diff_assumption ] our simulations suggests that the convergence result in theorem  [ theorem : dis_opt - directed ] holds true for any locally lipschitz objective function .",
    "however , our proof can not be reproduced for this case because it would rely on the generalized gradient being globally lipschitz which , by proposition  [ prop : coco_diff ] , would imply that the function is differentiable .    according to theorem  [ theorem : dis_opt - directed ] , the parameter @xmath239 is determined by @xmath361 as @xmath362 . in turn , one can observe from   that the range of suitable values for @xmath249 increases with higher network connectivity and smaller variability of the gradient of the objective function . from a control design viewpoint ,",
    "it is reasonable to choose the value of @xmath249 that yields the smallest @xmath239 while satisfying the conditions of the theorem statement .",
    "it is worth noticing that the discretization of   for undirected graphs ( performed in  @xcite for the case of continuously differentiable , strictly convex functions ) and   for weight - balanced digraphs gives rise to different discrete - time optimization algorithms from the ones considered in  @xcite .",
    "we have studied the distributed optimization of a sum of convex functions over directed networks using consensus - based dynamics .",
    "somewhat surprisingly , we have established that the convergence results established in the literature for undirected networks do not carry over to the directed scenario .",
    "nevertheless , our analysis has allowed us to introduce a slight generalization of the saddle - point dynamics of the undirected case which incorporates a design parameter .",
    "we have proved that , for appropriate parameter choices , this dynamics solves the distributed optimization problem for differentiable convex functions with globally lipschitz gradients on strongly connected and weight - balanced digraphs .",
    "our technical approach relies on a careful combination of notions from stability analysis , algebraic graph theory , and convex analysis .",
    "future work will focus on the extension of the convergence results to locally lipschitz functions in the weight - balanced directed case and to general digraphs , the incorporation of local and global constraints , the design of distributed algorithms that allow the network to agree on an optimal value of the design parameter , the discretization of the algorithms , and the study of the potential connections with dynamic consensus strategies .",
    "10    m.  rabbat and r.  nowak , `` distributed optimization in sensor networks , '' in _ symposium on information processing of sensor networks _ ,",
    "( berkeley , ca ) , pp .  2027 , apr .",
    "a.  nedic and a.  ozdaglar ,",
    "`` distributed subgradient methods for multi - agent optimization , '' _ ieee transactions on automatic control _ , vol .",
    "54 , no .  1 ,",
    "pp .  4861 , 2009 .",
    "p.  wan and m.  d. lemmon , `` event - triggered distributed optimization in sensor networks , '' in _",
    "symposium on information processing of sensor networks _ ,",
    "( san francisco , ca ) , pp .  4960 , 2009 .",
    "a.  nedic , a.  ozdaglar , and p.  a. parrilo , `` constrained consensus and optimization in multi - agent networks , '' _ ieee transactions on automatic control _ , vol .",
    "55 , no .  4 , pp .",
    "922938 , 2010 .",
    "b.  johansson , m.  rabi , and m.  johansson , `` a randomized incremental subgradient method for distributed optimization in networked systems , '' _ siam journal on control and optimization _ , vol .",
    "20 , no .  3 , pp .",
    "11571170 , 2009 .",
    "m.  zhu and s.  martnez , `` on distributed convex optimization under inequality and equality constraints , '' _ ieee transactions on automatic control _ , vol .",
    "57 , no .  1 ,",
    "pp .  151164 , 2012 .",
    "r.  olfati - saber , j.  a. fax , and r.  m. murray , `` consensus and cooperation in networked multi - agent systems , '' _ proceedings of the ieee _",
    "95 , no .  1 , pp .  215233 , 2007 .",
    "w.  ren and r.  w. beard , _ distributed consensus in multi - vehicle cooperative control_. communications and control engineering , springer , 2008 .",
    "f.  bullo , j.  corts , and s.  martnez , _ distributed control of robotic networks_. applied mathematics series , princeton university press , 2009 .",
    "electronically available at http:/@xmath363/coordinationbook.info .",
    "m.  mesbahi and m.  egerstedt , _ graph theoretic methods in multiagent networks_. applied mathematics series , princeton university press , 2010 .",
    "j.  n. tsitsiklis , d.  p. bertsekas , and m.  athans , `` distributed asynchronous deterministic and stochastic gradient optimization algorithms , '' _ ieee transactions on automatic control _ ,",
    "31 , no .  9 , pp .  803812 , 1986 .",
    "j.  wang and n.  elia , `` control approach to distributed optimization , '' in _ allerton conf .  on communications , control and computing _ , ( monticello , il ) , pp",
    ".  557561 , oct .",
    "j.  wang and n.  elia , `` a control perspective for centralized and distributed convex optimization , '' in _ ieee conf .  on decision and control",
    "_ , ( orlando , florida ) , pp .  38003805 , 2011 .",
    "r.  t. rockafellar , _",
    "convex analysis_. princeton landmarks in mathematics and physics , princeton , nj : princeton university press , 1997 .",
    "reprint of 1970 edition .",
    "f.  h. clarke , _ optimization and nonsmooth analysis_. canadian mathematical society series of monographs and advanced texts , wiley , 1983 .    e.  g. golshtein and n.  v. tretyakov , _ modified lagrangians and monotone maps in optimization_. new york : wiley , 1996 .",
    "j.  corts , `` discontinuous dynamical systems - a tutorial on solutions , nonsmooth analysis , and stability , '' _ ieee control systems magazine _ , vol .  28 , no .  3 , pp .",
    "3673 , 2008 .",
    "s.  boyd and l.  vandenberghe , _",
    "convex optimization_. cambridge university press , 2004 .",
    "d.  feijer and f.  paganini , `` stability of primal - dual gradient dynamics and applications to network optimization , '' _ automatica _ , vol .",
    "46 , pp .  19741981 , 2010 .",
    "k.  arrow , l.  hurwitz , and h.  uzawa , _ studies in linear and non - linear programming_. stanford , california : stanford university press , 1958 .",
    "r.  a. horn and c.  r. johnson , _ matrix analysis_. cambridge university press , 1985 .",
    "a.  bacciotti and f.  ceragioli , `` stability and stabilization of discontinuous systems and nonsmooth lyapunov functions , '' _ esaim : control , optimisation & calculus of variations _ ,",
    "vol .  4 , pp .",
    "361376 , 1999 .",
    "the next result shows that the differentiability hypothesis of proposition  [ prop : coco_nes_suff ] can not be relaxed .",
    "let @xmath50 be a locally lipschitz function and has a globally lipschitz generalized gradient map  @xcite .",
    "take @xmath364 and let us show that @xmath68 is a singleton . since  @xmath89 is differentiable almost everywhere , there exists a sequence of points @xmath365 , where @xmath15 is differentiable such that @xmath366 . using the set - valued lipschitz property of @xmath367",
    ", we have @xmath368 where @xmath100 is the lipschitz constant and @xmath369 is the ball centered at @xmath370 of radius one .",
    "hence , any element @xmath371 can be written as @xmath372 , where @xmath373 is a unit vector in @xmath374 .",
    "now , taking the limit , @xmath375 .",
    "hence the generalized gradient is singleton - valued .",
    "differentiability follows now from the set - valued lipschitz condition .",
    "[ lemma : flow - in - critical ] let @xmath50 be locally lipschitz and convex , and let @xmath376 be a minimizer of @xmath89 . then , the only solution of @xmath377 starting from @xmath378 is @xmath379 , for all @xmath380 .",
    "we reason by contradiction .",
    "assume @xmath381 is not identically @xmath376 .",
    "since @xmath89 is monotonically nonincreasing along the gradient flow , the trajectory must stay in the set of minimizers of  @xmath89 , and hence @xmath382 is constant .",
    "let @xmath383 be the smallest time such that @xmath384 .",
    "using  ( * ? ? ?",
    "* lemma  1 ) , we have @xmath385 , for all @xmath386 . in particular , for @xmath387 , we get @xmath388 , which is a contradiction ."
  ],
  "abstract_text": [
    "<S> this paper studies the continuous - time distributed optimization of a sum of convex functions over directed graphs . </S>",
    "<S> contrary to what is known in the consensus literature , where the same dynamics works for both undirected and directed scenarios , we show that the consensus - based dynamics that solves the continuous - time distributed optimization problem for undirected graphs fails to converge when transcribed to the directed setting . </S>",
    "<S> this study sets the basis for the design of an alternative distributed dynamics which we show is guaranteed to converge , on any strongly connected weight - balanced digraph , to the set of minimizers of a sum of convex differentiable functions with globally lipschitz gradients . </S>",
    "<S> our technical approach combines notions of invariance and cocoercivity with the positive definiteness properties of graph matrices to establish the results . </S>"
  ]
}