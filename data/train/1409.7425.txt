{
  "article_text": [
    "in many optimization problems , one is given a ( say , geometric ) input , and one is interested in computing the minimum of a function over this input .",
    "such a function can be , for example , the minimum cost clustering of the input , the price of a minimum spanning tree , the radius of the smallest enclosing disk , the closest pair distance , and many other functions .",
    "often for such optimization problems it is possible to construct a decision procedure , which given a query value can decide whether the query is smaller or larger than the minimum of the function .",
    "naturally , one would like to use this decider to perform a binary search to compute the minimum . however , often this is inherently not possible as the set of possible solutions is a real interval .",
    "instead one must identify a set of critical values at which the function changes . naturally , searching over these values",
    "directly can be costly as often the number of such critical values is much larger than the desired running time .",
    "instead one attempts to perform an implicit search over them .",
    "one of the most powerful techniques to solve optimization problems efficiently in computational geometry , using such an implicit search , is the technique of megiddo @xcite .",
    "it is relatively complicated , as it involves implicitly extracting values from a simulation of a parallel decision procedure ( often a parallel sorting algorithm ) .",
    "for this reason it is inherently not possible for parametric search to lead to algorithms which run faster than @xmath3 time .",
    "nevertheless , it is widely used in designing efficient geometric optimization algorithms , see @xcite .",
    "luckily , in many cases one can replace parametric search by simpler techniques ( see prune - and - search below for example ) and in particular , it can be replaced by randomization , see the work by van oostrum and veltkamp @xcite .",
    "another example of replacing parametric search by randomization is the new simplified algorithm for the frchetdistance @xcite .",
    "surprisingly , sometimes these alternative techniques can actually lead to linear time algorithms .",
    "[ [ linear - time - algorithms . ] ] linear time algorithms .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    there seems to be three main ways to get linear time algorithms for geometric optimization problems ( exact or approximate ) :    * coreset / sketch*. one can quickly extract a compact sketch of the input that contains the desired quantity ( either exactly or approximately ) . as an easy example , consider the problem of computing the axis parallel bounding box of a set of points - an easy linear scan suffices .",
    "there is by now a robust theory of what quantities one can extract a coreset of small size for , such that one can do the ( approximate ) calculation on the coreset , where usually the coreset size depends only on the desired approximation quality .",
    "this leads to many linear time algorithms , from shape fitting @xcite , to @xmath4-approximate @xmath0-center / median / mean clustering @xcite in constant dimension , and many other problems @xcite .",
    "the running times of the resulting algorithms are usually @xmath5 .",
    "the limitation of this technique is that there are problems for which there is no small sketch , from clustering when the number of clusters is large , to problems where there is no sketch at all @xcite  for example , for finding the closest pair of points one needs all the given input and no sketching is possible .",
    "* prune and search*. here one prunes away a constant fraction of the input , and continues the search recursively on the remaining input .",
    "the paramount example of such an algorithm is the linear time median finding algorithm , however , one can interpret many of the randomized algorithms in computational geometry as pruning algorithms @xcite .",
    "for example , linear programming in constant dimension in linear time @xcite , and its extension to -type problems @xcite . intuitively ,",
    "-type problems include low dimensional convex programming ( a standard example is the smallest enclosing ball of a point set in constant dimension ) .",
    "however , surprisingly , such problems also include problems that are not convex in nature  for example , deciding if a set of ( axis parallel ) rectangles can be pierced by three points is an -type problem .",
    "other examples of prune - and - search algorithms that work in linear time include    computing an ear in a triangulation of a polygon @xcite ,    searching in sorted matrices @xcite , and    ham - sandwich cuts in two dimensions @xcite",
    ".    of course , there are many other examples of using prune and search with running time that is super - linear .",
    "* grids . *",
    "rabin @xcite used randomization , the floor function , and hashing to compute the closest pair of a set of points in the plane , in expected linear time .",
    "et  al . _",
    "@xcite presented a simplified version of this algorithm , and smid provides a survey of algorithms on closest pair problems @xcite . a prune and search variant of this algorithm",
    "was suggested by khuller and matias @xcite .",
    "of course , the usage of grids and hashing to perform approximate point - location is quite common in practice . by itself , this is already sufficient to break lower bounds in the comparison model , for example for @xmath0-center clustering @xcite . the only direct extension of rabin s algorithm the authors are aware of is the work by har - peled and mazumdar @xcite showing a linear time @xmath6-approximation to the smallest ball containing @xmath0 points ( out of @xmath7 given points ) .",
    "there is some skepticism of algorithms using the floor function , since schnhage@xcite showed how to solve a complete problem , in polynomial time , using the floor function in the real model  the trick being packing many numbers into a single word ( which can be arbitrarily long in the model , and still each operation on it takes only constant time ) .",
    "note , that as rabin s algorithm does not do any such packing of numbers ( i.e. , its computation model is considerably more restricted ) , this criticism does not seem to be relevant in the case of this algorithm and its relatives .    in this paper , we present a new technique that combines together all of the above techniques to yield linear time approximation algorithms .    [",
    "[ nets . ] ] nets .",
    "+ + + + +    given a point set @xmath8 , an @xmath9-net @xmath10 of @xmath8 is a subset of @xmath8 that represents well the structure of @xmath8 in resolution @xmath9 .",
    "formally , we require that for any point in @xmath8 there is a net point in distance at most @xmath9 from it , and no two net points are closer than @xmath9 to each other , see section  [ sec : compnets ] for a formal definition .",
    "thus , nets provide a sketch of the point - set as far as distances that are @xmath9 or larger .",
    "nets are a useful tool in presenting point - sets hierarchically . in particular , computing nets of different resolutions and linking between different levels , leads to a tree like data - structure that can be used to facilitate many tasks , see for example the net - tree @xcite for such a data - structure for doubling metrics .",
    "nets can be defined in any metric space , but in euclidean space a grid can sometimes provide an equivalent representation .",
    "in particular , net - trees can be interpreted as an extension of ( compressed ) quadtrees to more abstract settings .",
    "computing nets is closely related to @xmath0-center clustering .",
    "specifically , gonzalez  @xcite shows how to compute an approximate net that has @xmath0 points in @xmath11 time , which is also a @xmath6-approximation to the @xmath0-center clustering .",
    "this was later improved to @xmath12 time , for low dimensional euclidean space @xcite , if @xmath0 is sufficiently small ( using grids and hashing ) .",
    "har - peled and mendel showed how to preprocess a point set in a metric space with constant doubling dimension , in @xmath13 time , such that an ( approximate ) @xmath9-net can be extracted in ( roughly ) linear time in the size of the net .      in this paper , we consider problems of the following form : given a set @xmath8 of weighted points in @xmath14 , one wishes to solve an optimization problem whose solution is one of the pairwise distances of @xmath8 ( or `` close '' to one of these values ) .",
    "problems of this kind include computing the optimal @xmath0-center clustering , or the length of the @xmath0thedge in the @xmath2of @xmath8 , and many others .",
    "specifically , we are interested in problems for which there is a fast approximate decider .",
    "that is , given a value @xmath15 we can , in linear time , decide if the desired value is ( approximately ) smaller than @xmath9 or larger than @xmath9 .",
    "the goal is then to use this decider to approximate the optimum solution in linear time . as a first step towards a linear time approximation algorithm for such problems , we point out that one can compute nets in linear time in @xmath14 ,",
    "see section  [ sec : compnets ] .    however , even if we could implicitly search over the critical values ( which we can not ) then we still would require a logarithmic number of calls to the decider which would yield a running time of @xmath3 , as the number of critical values is at least linear ( and usually polynomial ) .",
    "so instead we use the return values of the decision procedure as we search to thin out the data so that future calls to the decision procedure become successively cheaper .",
    "however , we still can not search over the critical values ( since there are too many of them ) and so we also introduce random sampling in order to overcome this .",
    "[ [ outline - of - the - new - technique . ] ] outline of the new technique .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the new algorithm works by randomly sampling a point and computing the distance to its nearest neighbor .",
    "let this distance be @xmath9 .",
    "next , we use the decision procedure to decide if we are in one of the following three cases .",
    "if @xmath9 is too small then we zoom out to a resolution of @xmath9 by computing an @xmath9-net and continuing the computation on the net instead of on the original point - set .",
    "that is , we net the point - set into a smaller point - set , such that one can solve the original problem ( approximately ) on this smaller sketch of the input",
    ".    * prune . *",
    "if @xmath9 is too large then we remove all points whose nearest neighbor is further than @xmath9 away ( of course , this implies we should only consider problems for which such pruning does not affect the solution ) .",
    "that is , we isolate the optimal solution by pruning away irrelevant data  this is similar in nature to what is being done by prune - and - search algorithms .",
    "the value of @xmath9 is the desired approximation .",
    "we then continue recursively on the remaining data . in either case ,",
    "the number of points being handled ( in expectation ) goes down by a constant factor and thus the overall expected running time is linear .",
    "[ [ significance - of - results . ] ] significance of results .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    our basic framework is presented in a general enough manner to cover , and in many cases greatly simplify , many problems for which linear time algorithms had already been discovered . at the same time the framework provides new linear time algorithms for a large collection of problems , for which previously no linear time algorithm was known .",
    "the framework should also lead to algorithms for many other problems which are not mentioned .    at a conceptual level",
    "the basic algorithm is simple enough ( with its basic building blocks already having efficient implementations ) to be highly practical from an implementation standpoint . perhaps more importantly , with increasing shifts toward large data sets algorithms with super linear running time",
    "can be impractical .",
    "additionally , our framework seems amenable to distributed implementation in frameworks like mapreduce .",
    "indeed , every iteration of our algorithm breaks the data into grid cells , a step that is similar to the map phase .",
    "in addition , the aggressive thinning of the data by the algorithm guarantees that after the first few iterations the algorithm is resigned to working on only a tiny fraction of the data .",
    "[ [ significance - of - the - netting - step . ] ] significance of the netting step .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    without the net stage , our framework is already sufficient to solve the closest - pair problem , and in this specific case , the algorithm boils down to the one provided by khuller and matias @xcite .",
    "this seems to be the only application of the new framework where the netting is not necessary . in particular",
    ", the wide applicability of the framework seems to be the result of the netting step .",
    "[ [ framework - and - results . ] ] framework and results .",
    "+ + + + + + + + + + + + + + + + + + + + + +    we provide a framework that classifies which optimization problems can be solved using the new algorithm .",
    "we get the following new algorithms ( all of them have an expected linear running time , for any fixed @xmath16 ) :    * @xmath0-center clustering * ( section  [ sec : k : center ] ) .",
    "we provide an algorithm that @xmath6-approximates the optimal @xmath0-center clustering of a point set in @xmath14 .",
    "unlike the previous algorithm @xcite that was restricted to @xmath17 , the new algorithm works for any value of @xmath0 .",
    "this new algorithm is also simpler .    *",
    "@xmath0thsmallest distance * ( section  [ sec : k : th : distance ] ) . in the distance selection problem , given a set of points in @xmath14 , one would like to compute the @xmath0thsmallest distance defined by a pair of points of @xmath8 .",
    "it is believed that such exact distance selection requires @xmath18 time in the worst case @xcite , even in the plane ( in higher dimensions the bound deteriorates ) .",
    "we present an @xmath19 time algorithm that @xmath4-approximates the @xmath0thsmallest distance .",
    "previously , bespamyatnikh and segal @xcite presented @xmath20 time algorithm using a well - separated pairs decomposition ( see also @xcite ) .    given two sets of points @xmath8 and @xmath21 with a total of @xmath7 points , using the same approach , we can @xmath4-approximate the @xmath0thsmallest distance in a bichromatic set of distances @xmath22{0cm}{0.4cm}}\\right . } } \\right\\}}$ ] , and in particular , we can compute exactly the closest bichromatic pair between @xmath8 and @xmath23 .    intuitively , the mechanism behind distance selection underlines many optimization problems , as it ( essentially ) performs a binary search over the distances induced by a set of points . as such ,",
    "being able to do approximate distance selection in linear time should lead to faster approximation algorithms that perform a similar search over such distances .    * the @xmath0thsmallest @xmath1-nearest neighbor distance * ( section  [ sec : k : smallest : m : n : n ] ) . for a set @xmath24 of @xmath7 points , and a point @xmath25 , its in @xmath8 is the @xmath1thclosest point to @xmath26 in @xmath27 . in particular",
    ", let @xmath28 denote this distance . here , consider the set of these distances defined for each point of @xmath8 ; that is , @xmath29 .",
    "we can approximate the @xmath0th smallest number in this set in linear time .    * exact nearest neighbor distances * ( section  [ sec : f : n : n ] ) .",
    "for the special case where @xmath30 , one can turn the above approximation into an exact computation of the @xmath0thnearest neighbor distance with only a minor post processing grid computation .    as an application , when @xmath31 , one can compute in linear time , exactly , the furthest nearest neighbor distance ; that is , the nearest neighbor distance of the point whose nearest neighbor is furthest away .",
    "this measure can be useful , for example , in meshing applications where such a point is a candidate for a region where the local feature size is large and further refinement is needed .",
    "we are unaware of any previous work directly on this problem , although one can compute this quantity by solving the all - nearest - neighbor problem , which can be done in @xmath32 time @xcite .",
    "this is to some extent the `` antithesis '' to rabin s algorithm for the closest pair problem , and it is somewhat surprising that it can also be solved in linear time .    * the @xmath0thlongest @xmath2edge * ( section  [ sec : longest : mst ] ) . given a set @xmath8 of @xmath7 points in @xmath14 , we can @xmath4-approximate , in @xmath19 time , the @xmath0thlongest edge in the @xmath2of @xmath8 .    * smallest ball with a monotone property * ( section  [ sec : min : cluster ] ) .",
    "consider a property defined over a set of points , @xmath8 , that is monotone ; that is , if @xmath33 has this property then @xmath23 must also have this property .",
    "consider such a property that can be easily checked , for example , ( i ) whether the set contains @xmath0 points , or ( ii ) if the points are colored , whether all colors are present in the given point set .",
    "given a point set @xmath8 , one can @xmath4-approximate , in @xmath34 time , the smallest radius ball @xmath35 , such that @xmath36 has the desired property .",
    "for example , we get a linear time algorithm to approximate the smallest ball enclosing @xmath0 points of @xmath8 . the previous algorithm for this problem",
    "@xcite was significantly more complicated .",
    "furthermore , we can approximate the smallest ball such that all colors appear in it ( if the points are colored ) , or the smallest ball such that at least @xmath37 different colors appear in it , etc .",
    "more generally , the kind of monotone properties supported are _",
    "sketchable _ ; that is , properties for which there is a small summary of a point - set that enables one to decide if the property holds , and furthermore , given summaries of two disjoint point sets , the summary of the union point - set can be computed in constant time .",
    "we believe that formalizing this notion of sketchability is a useful abstraction .",
    "see section  [ sec : sketchable ] for details .    *",
    "smallest connected component with a monotone property * ( section  [ sec : min : cluster : c ] ) .",
    "consider the connected components of the graph where two points are connected if they are distance at most @xmath9 from each other .",
    "using our techniques , one can approximate , in linear time , the smallest @xmath9 such that there is a connected component of this graph for which a required sketchable property holds for the points in this connected component .    as an application , consider ad hoc wireless networks . here",
    ", we have a set @xmath8 of @xmath7 nodes and their locations ( say in the plane ) , and each node can broadcast in a certain radius @xmath9 ( the larger the @xmath9 the higher the energy required , so naturally we would like to minimize it ) .",
    "assume there are two special nodes .",
    "it is natural to ask for the minimum @xmath9 , such that there is a connected component of the above graph that contains both nodes .",
    "that is , these two special nodes node can send message to each other , by message hopping ( with distance at most @xmath9 at each hop ) .",
    "we can approximate this connectivity radius in linear time .    * clustering for a monotone property * ( section  [ sec : cluster : monotone ] ) .",
    "imagine that we want to break the given point - set into clusters , such that the maximum diameter of a cluster is minimized ( as in @xmath0-center clustering ) , and furthermore , the points assigned to each cluster comply with some sketchable monotone property .",
    "we present a @xmath38-approximation algorithm for these types of problems , that runs in @xmath34 time .",
    "this includes lower bounded clustering ( i.e. , every cluster must contain at least @xmath39 points ) , for which the authors recently presented an @xmath40 approximation algorithm @xcite .",
    "one can get a @xmath6-approximation using network flow , but the running is significantly worse @xcite . see section  [ sec : cluster : monotone : examples ] for examples of clustering problems that can be approximated using this algorithm .    * connectivity clustering for a monotone property * ( section  [ sec : cluster : spanning ] ) .",
    "consider the problem of computing the minimum @xmath9 , such that each connected component ( of the graph where points in distance at most @xmath9 from each other are adjacent ) has some sketchable monotone property .",
    "we approximate the minimum @xmath9 for which this holds in linear time .",
    "an application of this for ad hoc networks is the following  we have a set @xmath8 of @xmath7 wireless clients , and some of them are base stations ; that is , they are connected to the outside world .",
    "we would like to find the minimum @xmath9 , such that each connected component of this graph contains a base station .",
    "* closest pair and smallest non - zero distance * ( section  [ sec : closest : non : zero : dist ] ) . given a set of points in @xmath14 ,",
    "consider the problem of finding the smallest non - zero distance defined by these points .",
    "this problem is an extension of the closest pair distance , as there might be many identical points in the given point set .",
    "we provide a linear time algorithm for computing this distance _ exactly _ , which follows easily from our framework .",
    "[ [ high - probability . ] ] high probability .",
    "+ + + + + + + + + + + + + + + + +    finally , we show in section  [ sec : high : prob ] how to modify our framework such that the linear running time holds with high probability .",
    "since there is very little elbow room in the running time when committed to linear running time , this extension is quite challenging , and requires several new ideas and insights .",
    "see section  [ sec : high : prob ] for details .",
    "[ [ paper - organization . ] ] paper organization .",
    "+ + + + + + + + + + + + + + + + + + +    we describe how to compute nets in section  [ sec : prelim ] , and how to remove faraway points efficiently in section  [ sec : point : removal ] .",
    "we define the abstract framework , and describe and analyze the new approximation algorithm , in section  [ sec : framework ] .",
    "we describe the applications in section  [ sec : applications ] .",
    "we show how to modify the framework to achieve linear running time with high probability in section  [ sec : high : prob ] .",
    "we conclude in section  [ sec : conclusions ] .",
    "[ sec : prelim ]      the of an interval @xmath41 \\subseteq { { \\rm i\\!\\hspace{-0.025em } r}}^{+}$ ] is @xmath42 .",
    "[ def : net ] for a point set @xmath8 in a metric space with a metric @xmath43 , and a parameter @xmath15 , an @xmath9- of @xmath8 is a subset @xmath44 , such that    for every @xmath45 , @xmath46 , we have that @xmath47 , and    for all @xmath25 , we have that @xmath48 .    intuitively , an @xmath9-net represents @xmath8 in resolution @xmath9 .",
    "[ def : grid : stuff ] for a real positive number @xmath49 and a point @xmath50 , define @xmath51 to be the grid point @xmath52 .",
    "we call @xmath49 the or of the @xmath53 . observe that @xmath53 partitions @xmath14 into cubes , which are grid . the grid cell of @xmath26 is uniquely identified by the integer point @xmath54{0.0cm}{0.38cm}}\\ !         { \\left\\lfloor { { { \\mathsf{p}}}_1/\\delta } \\right\\rfloor } , \\ldots , { \\left\\lfloor { { { \\mathsf{p}}}_d/\\delta } \\right\\rfloor}}\\right)}$ ] .    for a number @xmath55 ,",
    "let @xmath56 denote the set of grid cells in distance @xmath57 from @xmath26 , which is the of @xmath26 .",
    "note , that the neighborhood also includes the grid cell containing @xmath26 itself , and if @xmath58 then @xmath59 .",
    "see figure on the right .",
    "[ sec : compnets ]    there is a simple algorithm for computing @xmath9-nets .",
    "namely , let all the points in @xmath8 be initially unmarked . while there remains an unmarked point , @xmath26 , add @xmath26 to @xmath60 , and mark it and all other points in distance @xmath61 from @xmath26 ( i.e. we are scooping away balls of radius @xmath9 ) . by using grids and hashing one can modify this algorithm to run in linear time .",
    "the following is implicit in previous work @xcite , and we include it here for the sake of completeness , and does not work in this settings , as the number of clusters it can handle is limited to @xmath62 .",
    "lemma  [ lemma : net ] has no such restriction . ]",
    " it was also described by the authors in @xcite .",
    "[ lemma : net ] given a point set @xmath63 of size @xmath7 and a parameter @xmath15 , one can compute an @xmath9-net for @xmath8 in @xmath12 time .",
    "let @xmath64 denote the grid in @xmath14 with side length @xmath65 .",
    "first compute for every point @xmath66 the grid cell in @xmath64 that contains @xmath26 ; that is , @xmath67 .",
    "let @xmath68 denote the set of grid cells of @xmath64 that contain points of @xmath8 .",
    "similarly , for every cell @xmath69 we compute the set of points of @xmath8 which it contains .",
    "this task can be performed in linear time using hashing and bucketing assuming the floor function can be computed in constant time .",
    "specifically , store the @xmath70 values in a hash table , and in constant time hash each point into its appropriate bin .    scan the points of @xmath8 one at a time , and let @xmath26 be the current point . if @xmath26 is marked then move on to the next point . otherwise , add @xmath26 to the set of net points , @xmath60 , and mark it and each point @xmath71 such that @xmath72 .",
    "since the cells of @xmath56 contain all such points , we only need to check the lists of points stored in these grid cells . at the end of this procedure every point is marked .",
    "since a point can only be marked if it is in distance @xmath61 from some net point , and a net point is only created if it is unmarked when visited , this implies that @xmath60 is an @xmath9-net .",
    "as for the running time , observe that a grid cell , @xmath73 , has its list scanned only if @xmath73 is in the neighborhood of some created net point . as @xmath74",
    ", there are only @xmath75 cells which could contain a net point @xmath26 such that @xmath76 .",
    "furthermore , at most one net point lies in a single cell since the diameter of a grid cell is strictly smaller than @xmath9 .",
    "therefore each grid cell had its list scanned @xmath75 times .",
    "since the only real work done is in scanning the cell lists and since the cell lists are disjoint , this implies an @xmath12 running time overall .",
    "observe that the closest net point , for a point @xmath25 , must be in one of its neighborhood s grid cells . since every grid cell can contain only a single net point , it follows that in constant time per point of @xmath8 , one can compute each point s nearest net point .",
    "we thus have the following .    [ cor : valid ] for a set @xmath63 of @xmath7 points , and a parameter @xmath77 , one can compute , in linear time , an @xmath9-net of @xmath8 , and furthermore , for each net point the set of points of @xmath8 for which it is the nearest net point .    in the following ,",
    "a is a point that is assigned a positive integer weight . for any subset @xmath78 of a weighted point set @xmath8 , let @xmath79 denote the number of points in @xmath78 and",
    "let @xmath80 denote the total weight of @xmath78 .",
    "in particular , corollary  [ cor : valid ] implies that for a weighted point set one can compute the following quantity in linear time .",
    "[ algorithm : net ] [ algorithm : net ] given a weighted point set @xmath63 , let @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{p}}}\\right)}}$ ] denote an @xmath9-net of @xmath8 , where the weight of each net point @xmath26 is the total sum of the weights of the points assigned to it .",
    "we slightly abuse notation , and also use @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{p}}}\\right)}}$ ] to designate the algorithm computing this net , which has linear running time .",
    "[ sec : point : removal ]    for a given point @xmath25 , let @xmath82 denote the nearest neighbor of @xmath26 in @xmath83 , and the distance to it , respectively .",
    "the quantity @xmath84 can be computed ( naively ) in linear time by scanning the points . for a set of points @xmath8 , and a parameter @xmath9 , let @xmath85 denote the set of points ; that is , it is the set of all points @xmath25 , such that the nearest - neighbor of @xmath26 in @xmath86 is at least distance @xmath9 away ( i.e. , @xmath87 ) .",
    "similarly , @xmath88 is the set of points ; that is , all points @xmath25 , such that @xmath89 .",
    "[ algorithm : delete ] [ lemma : delete ] given a weighted set @xmath63 of @xmath7 points , and a distance @xmath90 , in @xmath91 time , one can compute the sets @xmath92 and @xmath93 .",
    "let @xmath94    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } }       \\index{algorithm!delfar@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } } } }    } } \\xspace}({\\ell } , { \\mathsf{p}})$ ] denote the algorithm which computes these sets and returns @xmath92 .    build a grid where every cell has diameter @xmath95 , for some constant @xmath96 .",
    "clearly any point @xmath25 such that @xmath97 ( i.e. , a far point ) must be in a grid cell by itself .",
    "therefore to determine all such `` far '' points only grid cells with singleton points in them need to be considered .",
    "for such a point @xmath98 , to determine if @xmath99 , one checks the points stored in all grid cells in distance @xmath100 from it .",
    "if @xmath98 has no such close neighbor , we mark @xmath98 for inclusion in @xmath85 . by the same arguments as in lemma  [ lemma : net ] ,",
    "the number of such cells is @xmath75 .",
    "again by the arguments of lemma  [ lemma : net ] every non - empty grid cell gets scanned @xmath75 times overall , and so the running time is @xmath12 . finally , we copy all the marked ( resp .",
    "unmarked ) points to @xmath93 ( resp .",
    "@xmath92 ) .",
    "the algorithm @xmath94    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } }       \\index{algorithm!delfar@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } } } }    } } \\xspace}({\\ell } , { \\mathsf{p}})$ ] then simply returns @xmath92 .",
    "[ sec : framework ]      let @xmath8 and @xmath23 be two sets of weighted points in @xmath14 ( of the same weight ) .",
    "the set @xmath23 is a of @xmath8 , if @xmath23 can be constructed by moving each point of @xmath8 by distance at most @xmath49 ( and not altering its weight ) .",
    "formally , there is an onto mapping @xmath101 , such that    for @xmath25 , we have that @xmath102 , and    for any @xmath103 , we have that @xmath104 .    note that for a ( potentially weighted ) point set @xmath21 , @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({\\delta , { \\mathsf{w}}}\\right)}}$ ] is a @xmath49-translation of @xmath21 .",
    "[ def : decider ] given a function @xmath105 , we call a procedure , @xmath106{redviolet}{\\texttt{\\bf{{decider}}}}}}\\index{algorithm!{decider}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{decider}}}}}}}}}}\\xspace}$ ] , a for @xmath107 , if for any @xmath108 and @xmath77 , @xmath106{redviolet}{\\texttt{\\bf{{decider}}}}}}\\index{algorithm!{decider}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{decider}}}}}}}}}}\\xspace}(r , x)$ ] returns one of the following :    @xmath109 $ ] , where @xmath39 is some real number ,    @xmath110 , or    @xmath111 .",
    "[ def : n : d : p ] an instance of a consists of a pair @xmath112 , where @xmath113 is a set of @xmath7 distinct weighted points is a multiset can also be handled .",
    "see remark  [ rem : multi ] .",
    "] , and @xmath114 is the of the given instance ( of size @xmath12 ) and consists of the relevant parameters for the problem . for a fixed , the task is to evaluate a function @xmath115 , defined over such input pairs , that has the following properties :    : there exists an @xmath12 time @xmath116-decider for @xmath117 , for some _ constant _ @xmath116 .    :",
    "let @xmath23 be any @xmath49-translation of @xmath21 .",
    "then @xmath118 .    : if @xmath119 then @xmath120 , where @xmath121 is the set of @xmath9-close points , and @xmath122 is an updated context which can be computed in @xmath12 time .",
    "if we are interested in a @xmath4-approximation , then @xmath123 . in this case , we require that the running time of the provided @xmath124)-decider ( i.e. , the property above ) is @xmath125 , for some constant @xmath126 .",
    "this covers all the applications presented in this paper .",
    "our analysis still holds even if the decider has a different running time , but the overall running time might increase by a factor of @xmath127 , see lemma  [ lemma : result:1 ] @xmath128 for details .      [",
    "sec : kcenter ]    as a concrete example of an , consider the problem of @xmath0-center clustering .",
    "let @xmath21 be a set of points in @xmath14 , and let @xmath129 be an integer parameter .",
    "find a set of @xmath130 such that the maximum distance of a point of @xmath21 to its nearest center in @xmath131 is minimized , and @xmath132 .",
    "specifically , the function of interest , denoted by @xmath133 , is the radius of the optimal @xmath0-center clustering of @xmath21 .",
    "we now show that satisfies the properties of an .",
    "[ lemma : decider:1 ] the following relations between @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right|}$ ] and @xmath133 hold :    if we have @xmath135    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right| } \\leq k$ ] then @xmath136 .    if @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right|}\\allowbreak > k$ ] then @xmath137 .",
    "\\(a ) observe that if @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right|}\\leq k$ ] , then , by definition , the set of net points of @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right)}}$ ] are a set of @xmath138 centers such that all the points of @xmath21 are in distance strictly less than @xmath9 from these centers .",
    "\\(b ) if @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right| } > k$ ] then @xmath21 must contain a set of @xmath139 points whose pairwise distances are all at least @xmath9 . in particular any solution to with radius @xmath140 would not be able to cover all these @xmath139 points with only @xmath0 centers .",
    "[ lemma : k : center : wbdp ] an instance @xmath141 of satisfies the properties of definition  [ def :",
    "n : d : p ] ; that is , is a @xmath38- , for any @xmath142 .",
    "we need to verify the required properties , see definition  [ def : n : d : p ] @xmath143 .",
    "we need to describe a decision procedure for clustering . to this end , given a distance @xmath9 , the decider first calls @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right)}}$ ] , see algorithm  [ algorithm : net ] @xmath144 .",
    "if we have @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r , { \\mathsf{w}}}\\right ) } } } \\right| }          \\leq k$ ] , then by lemma  [ lemma : decider:1 ] the answer `` @xmath136 '' can be returned .",
    "otherwise , call @xmath81    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({(2+{\\varepsilon}/2)r , { \\mathsf{w}}}\\right)}}$ ] .",
    "if @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({(2+{\\varepsilon}/2)r , { \\mathsf{w}}}\\right ) } } } \\right|}\\leq k$ ] , then , by lemma  [ lemma : decider:1 ] , we have @xmath145 and `` @xmath146 $ ] '' is returned . otherwise @xmath134    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({(2+{\\varepsilon}/2)r , { \\mathsf{w}}}\\right ) } } } \\right| } > k$ ] , and lemma  [ lemma : decider:1 ] implies that the answer `` @xmath147 '' can be returned by the decider .    observe that if @xmath23 is a @xmath49-translation of @xmath21 , then a point and its respective center in a @xmath0-center clustering of @xmath21 each move by distance at most @xmath49 in the transition from @xmath21 to @xmath23 . as such , the distance between a point and its center changes by at most @xmath148 by this process .",
    "this argument also works in the other direction , implying that the @xmath0-center clustering radius of @xmath21 and @xmath23 are the same , up to an additive error of @xmath148 .",
    "it suffices to show that if @xmath136 then @xmath149 .",
    "now , if @xmath136 then any point of @xmath21 whose neighbors are all @xmath150 away must be a center by itself in the optimal @xmath0-center solution , as otherwise it would be assigned to a center @xmath151 away . similarly , any point assigned to it would be assigned to a point @xmath152 away . therefore , for any point @xmath153",
    "whose nearest neighbor is at least distance @xmath9 away , @xmath154 . repeating this observation implies the desired result .",
    "the context update ( and computing @xmath121 and @xmath155 ) can by done in linear time using , see lemma  [ lemma : delete ] @xmath156 .",
    "[ sec : linear ]     [ algorithm : ndp : alg ]    [ figure : a : algorithm ]    we now describe the general algorithm which given a @xmath116- , @xmath112 , and an associated target function , @xmath107 , computes in linear time a @xmath157 spread interval containing @xmath158 . in the following ,",
    "let denote the given @xmath116-decider , where @xmath159 is some parameter .",
    "also , let denote the context updater associated with the given problem , see definition  [ def : n : d : p ] . both and run in linear time . the algorithm for bounding the optimum value of an is shown in figure  [ figure : a : algorithm ] .",
    "[ rem : zero ] for the sake of simplicity of exposition we assume that @xmath160 .",
    "the case when @xmath161 can be handled with an additional check of the context in the algorithm .",
    "however , since all our applications have @xmath160 we choose to make this simplifying assumption .",
    "[ rem : multi ] note that the algorithm of figure  [ figure : a : algorithm ] can be modified to handle inputs where @xmath21 is a multiset ( namely , two points can occupy the same location ) .",
    "specifically , it must be ensured that the distance computed in line  [ line : rad ] is not zero , as this is required for the call to .",
    "this can be remedied ( in linear time ) by first grouping all the duplicates of the point sampled in line  [ line : gen : random ] into a single weighted point ( with the sum of the weights ) before calling line  [ line : rad ] .",
    "this can be done by computing a net for a radius that is smaller than ( say ) half the smallest non - zero distance . how to compute this distance",
    "is described in section  [ sec : closest : non : zero : dist ] .",
    "a of the algorithm is an iteration where gets called .",
    "a is one where gets called .",
    "note that the only other type of iteration is the one where the algorithm returns .",
    "[ lemma : remove ] let @xmath8 be a point set .",
    "a @xmath162-net of @xmath8 , for any @xmath142 , can contain at most half the points of @xmath163 .",
    "consider any point @xmath26 in @xmath163 which became one of the net points .",
    "since @xmath164 , a disk of radius @xmath165 centered at @xmath26 must contain another point @xmath98 from @xmath163 ( indeed , @xmath164 only if its distance from its nearest neighbor in @xmath8 is at most @xmath165 ) .",
    "moreover , @xmath98 can not become a net point since it is too close to @xmath26 . now",
    "if we place a ball of radius @xmath165 centered at each point of @xmath163 which became a net point , then these balls will be disjoint because the pairwise distance between net points is @xmath166 .",
    "therefore each point of @xmath163 which became a net point can charge to at least one point of @xmath163 which did not make it into the net , such that no point gets charged twice .",
    "[ lemma : time ] given an instance @xmath112 of an , the algorithm @xmath167    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } }       \\index{algorithm!{ndpalg}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } } } }    } } \\xspace}({\\mathsf{w } } , { \\gamma})$ ] runs in expected @xmath12 time .",
    "in each iteration of the while loop the only non - trivial work done is in computing @xmath168 , the two calls to , and the one call to either or .",
    "it has already been shown that all of these can be computed in @xmath169 time .",
    "hence the total running time for the algorithm is @xmath170 , where @xmath0 denotes the last ( incomplete ) iteration of the while loop .",
    "so consider the beginning of iteration @xmath171 of the while loop .",
    "let the points in @xmath172 be labeled @xmath173 in increasing order of their nearest neighbor distance in @xmath172 .",
    "let @xmath174 be the index of the point chosen in line  [ line : gen : random ] and let @xmath175 and @xmath176 be the subset of the points with index @xmath177 and index @xmath178 , respectively .",
    "now since a point is randomly picked in line  [ line : gen : random ] , with probability @xmath179 , @xmath180 $ ] .",
    "lets call this event a .",
    "we have @xmath181 for a successful iteration .    since @xmath171 is not the last iteration of the while loop , either or",
    "must get called . if @xmath94    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } }       \\index{algorithm!delfar@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{delfar } } } } } } }    } } \\xspace}({\\ell}_i ,      { \\mathsf{w}}_{i-1})$ ] gets called ( i.e. line  [ line : delete ] ) then by lemma  [ lemma : delete ] , all of @xmath175 gets removed .",
    "so suppose gets called ( i.e. line  [ line : net ] ) . in this case",
    "lemma  [ lemma : remove ] implies that the call to removes at least @xmath182 points .    therefore , for any iteration @xmath171",
    ", at least @xmath183 points get removed .",
    "if an iteration is successful then @xmath184 .",
    "in particular , @xmath185{0cm}{0.4cm}}\\right . } } \\right ] } } \\geq { \\left| { { \\mathsf{w}}_{i-1 } } \\right|}/16 $ ] .",
    "now , @xmath186 and as such @xmath187{0cm}{0.4cm}}\\right . } } \\right]}}\\leq ( 15/16 )      { \\left| { { \\mathsf{w}}_{i-1 } } \\right|}$ ] .    therefore , for @xmath188 , @xmath189{0cm}{0.4cm}}\\ !",
    "{ \\left| { { \\mathsf{w}}_i } \\right| } } \\right ] } }         =         { \\mathop{\\mathbf{e}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.8cm}}\\ ! { \\mathop{\\mathbf{e}}\\!{\\left [ { { \\left| { { \\mathsf{w}}_i } \\right| } { \\,\\left|\\ , { { \\mathsf{w}}_{i-1 } } { \\rule[-.2cm]{0cm}{0.4cm}}\\right . } } \\right ] } }          } \\right ] } }         \\leq         { \\mathop{\\mathbf{e}}\\!{\\left [ { \\frac{15}{16}{\\left| { { \\mathsf{w}}_{i-1 } } \\right| } } \\right ] } }         =         \\frac{15}{16 } { \\mathop{\\mathbf{e}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}\\ ! { \\left| { { \\mathsf{w}}_{i-1 } } \\right| } } \\right]}}.      \\end{aligned}\\ ] ] hence , by induction on @xmath190 , @xmath191{0.0cm}{0.39cm}}\\ ! { \\left| { { \\mathsf{w}}_i         } \\right| } } \\right ] } } \\leq ( 15/16)^i { \\left| { { \\mathsf{w}}_0 } \\right|}$ ] and",
    "so , in expectation , the running time is bounded by @xmath192}}}\\right ) }         =         o{\\!\\left({\\sum_{i=0}^{i = k-1 } { \\mathop{\\mathbf{e}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}{\\left| { { \\mathsf{w}}_i } \\right| } } \\right]}}}\\right ) }         =         o{\\!\\left({\\sum_{i=0}^{i = k-1 } ( 15/16)^i { \\left| { { \\mathsf{w}}_0 } \\right|}}\\right ) }         =         o{\\!\\left({{\\left| { { \\mathsf{w}}_0 } \\right| } { \\rule[-.2cm]{0cm}{0.4cm}}\\ ! } \\right)}.",
    "\\end{aligned}\\ ] ]    [ [ correctness . ] ] correctness .",
    "+ + + + + + + + + + + +    the formal proof of correctness is somewhat tedious , but here is the basic idea : at every iteration , either far points are being thrown away ( and this does not effect the optimal value ) , or we net the points .",
    "however , the net radius being used is always significantly smaller than the optimal value , and throughout the algorithm execution the radii of the nets being used grow exponentially . as such , the accumulated error in the end is proportional to the radius of the last net computation before termination , which itself is also much smaller than the optimal value .    before proving that returns a bounded spread interval containing @xmath193 ,",
    "several helper lemmas will be needed . for notational ease ,",
    "in the rest of this section , we use @xmath194 as shorthand for @xmath195 .",
    "[ lemma : double ] suppose that is called in iteration @xmath190 of the while loop ( i.e. , line  [ line : net ] in figure  [ figure : a : algorithm ] @xmath196 ) .",
    "then for any iteration @xmath197 we have , @xmath198 .",
    "consider the beginning of iteration @xmath174 of the while loop .",
    "the current set of points , @xmath199 , are a subset of the net points of a @xmath200-net ( it is a subset since line  [ line : delete ] and line  [ line : net ] might have been executed in between rounds @xmath190 and @xmath174 ) .",
    "therefore , being a net , the distance between any two points of @xmath199 is @xmath201 , see definition  [ def : net ] @xmath202 . in particular",
    ", this means that for any point @xmath26 of @xmath199 , we have @xmath203 .",
    "[ lemma : translation ] for @xmath204 , we have @xmath205 .",
    "let @xmath206 be the set of indices of the net iterations up to ( and including ) the @xmath190thiteration .",
    "similarly , let @xmath207 be the set of iterations where get called .",
    "if was called in the @xmath174thiteration , then @xmath208 is a @xmath209-translation of @xmath199 and so by the property , @xmath210 .",
    "on the other hand , if gets called in the @xmath174thiteration , then @xmath211 by the property .",
    "let @xmath212 , we have that @xmath213{0cm}{0.4cm}}{\\ensuremath{f}}({\\mathsf{w}}_j)-             { \\ensuremath{f}}({\\mathsf{w}}_{j-1 } ) }   \\right|}\\\\          &         =         \\sum_{j \\in i } { \\left| { { \\rule[-.2cm]{0cm}{0.4cm}}{\\ensuremath{f}}({\\mathsf{w}}_j)-             { \\ensuremath{f}}({\\mathsf{w}}_{j-1 } ) }   \\right| } + \\sum_{j \\in \\overline{i } }          { \\left| { { \\rule[-.2cm]{0cm}{0.4cm}}{\\ensuremath{f}}({\\mathsf{w}}_j)- { \\ensuremath{f}}({\\mathsf{w}}_{j-1 } ) }   \\right| }          \\\\         & \\leq         \\sum_{j \\in i } 6{\\ell}_j + \\sum_{j \\in \\overline{i } } 0         \\leq          6 { \\ell}_m \\sum_{j=0}^\\infty \\frac{1}{3^j }         \\leq         9 { \\ell}_m         \\leq          9 { \\ell}_i ,      \\end{aligned}\\ ] ] by lemma  [ lemma : double ] .",
    "the following lemma testifies that the radii of the nets computed by the algorithm are always significantly smaller than the value we are trying to approximate .",
    "[ lemma : induction ] for any iteration @xmath190 of the while loop such that gets called , we have @xmath214 , where @xmath215",
    ".    the proof will be by induction .",
    "let @xmath216 be the indices of the iterations of the while loop in which gets called . for the base case , observe that in order for to get called , we must have @xmath217 .",
    "however , since this is the first iteration in which is called it must be that @xmath218 ( since for all previous iterations must have been called ) .",
    "so now suppose that @xmath219 for all @xmath220 .",
    "if a call to is made in iteration @xmath221 then again @xmath222 .",
    "thus , by lemma  [ lemma : translation ] and induction , we have @xmath223 if @xmath224 . this in turn is equivalent to @xmath225 , which is true by definition .",
    "setting @xmath226 , results in @xmath227 , and by lemma  [ lemma : induction ] , for all @xmath190 that correspond to a net iteration , @xmath228 . by lemma  [ lemma : translation ] , for any net iteration @xmath190 , we have @xmath229{0cm}{0.4cm}}{\\ensuremath{f}}({\\mathsf{w}}_i ) - { \\ensuremath{f}}({\\mathsf{w}}_0 ) }   \\right| } \\leq      9{\\ell}_i \\leq { \\ensuremath{f}}({\\mathsf{w}}_0 ) / 3 .\\end{aligned}\\ ] ] in particular , we conclude that @xmath230 for any iteration @xmath190 .",
    "we thus get the following .",
    "[ cor : same:1 ] for @xmath231 , and any @xmath190 , we have :    @xmath232 @xmath233 .    if @xmath234 $ ] then @xmath235 $ ] @xmath236 $ ] .    if @xmath237 then @xmath238 .",
    "[ lemma : summary:1 ] for @xmath231 , given an instance @xmath239 of a @xmath116- , @xmath167    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } }       \\index{algorithm!{ndpalg}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } } } }    } } \\xspace}({\\mathsf{w } } , { \\gamma})$ ] returns an interval @xmath240 $ ] containing @xmath241 , where @xmath242{0.0cm}{0.38cm}}[x',y']}\\right ) } } \\leq 4 \\max { \\!\\left ( {         { \\varphi } , { { c_{\\mathrm{net}}}}}\\right)}$ ] .",
    "consider the iteration of the while loop at which terminates , see figure  [ figure : a : algorithm ] @xmath196 .",
    "if line  [ line : bounded1x ] or line  [ line : bounded1y ] get executed at this iteration , then the interval @xmath243 $ ] was computed by the @xmath116-decider , and has spread @xmath244 . as such , by corollary  [ cor : same:1 ] , the returned interval @xmath240 = [ x/2 , 2y]$ ] contains the optimal value , and its spread is @xmath245 .",
    "a similar argumentation holds if line  [ line : bounded3 ] gets executed .",
    "indeed , the returned interval contains the desired value , and its spread is @xmath246 .",
    "[ lemma : result:1 ] given an instance of a @xmath116-defined by a set of @xmath7 points in @xmath14 , one can get a @xmath116-approximation to its optimal value , in @xmath247 expected time , where @xmath248 is the running of the procedure , and @xmath249 .",
    "if @xmath123 , for some @xmath250 , ( i.e. , is @xmath4-decider ) , then one can compute a @xmath124)-approximation to the optimal value , and the expected running time is @xmath251 .",
    "let @xmath112 be the given @xmath116-instance , and let be the corresponding @xmath116-decider .",
    "by lemma  [ lemma : time ] and lemma  [ lemma : summary:1 ] , in expected @xmath12 time , one can get a bounded spread interval @xmath252 $ ] , for some constant @xmath126 such that @xmath253 , such that @xmath254 $ ] . if @xmath255 then we are done .",
    "otherwise , perform a binary search over this interval .",
    "specifically , for @xmath256 , let @xmath257 and let @xmath258 .",
    "now perform a binary search over the @xmath259 s using .",
    "if any of the calls returns an interval @xmath260 $ ] that contains the optimal value , then @xmath261 and so @xmath262 can be returned as the desired @xmath116-approximation . otherwise , if @xmath263 or @xmath264 the binary search moves left or right , respectively . in the end",
    ", the search ends up with an interval @xmath265 which must contain the optimal value , and again , its spread is @xmath116 , and it thus provide the required approximation .    the running time is dominated by the calls to the decider procedure ( we are assuming here that @xmath266 ) . clearly , the number of calls to the decider performed by this algorithm is @xmath267 , if @xmath268 . otherwise , if @xmath123 , then @xmath269 since @xmath270 , for @xmath271 , as can be easily verified .",
    "[ theo : result : eps ] given an instance of a @xmath116-defined by a set of @xmath7 points in @xmath14 , one can get @xmath116-approximate the optimal value , in expected @xmath272 time , assuming @xmath273",
    ".    for the case @xmath274 , given an @xmath4-decider , with running time @xmath125 , one can @xmath124)-approximate , in @xmath275 expected time , the given @xmath4- , where @xmath126 is some constant .",
    "lemma  [ lemma : result:1 ] readily implies the first half . as for the second half , lemma",
    "[ lemma : result:1 ] implies that one can get a @xmath4-approximation in expected @xmath276 time .",
    "however , by using the same procedure as in the proof of lemma  [ lemma : result:1 ] but with exponentially decreasing values for @xmath16 in the binary search , a factor of @xmath277 can be avoided . this is a standard idea and was also used by aronov and har - peled @xcite .",
    "let @xmath106{redviolet}{\\texttt{\\bf{{decider}}}}}}\\index{algorithm!{decider}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{decider}}}}}}}}}}\\xspace}_{{\\varepsilon}}$ ] be our @xmath4-decider .",
    "if @xmath16 is set to any constant ( say 1 ) , then by lemma  [ lemma : time ] and lemma  [ lemma : summary:1 ] , in expected linear time , one can get a bounded spread interval @xmath252 $ ] , for some @xmath278 , such that @xmath279 $ ] .",
    "set @xmath280 and @xmath281 .",
    "the algorithm now proceeds in rounds , doing the following in the @xmath190thround :    assume that in the beginning of the @xmath190thiteration , we know that @xmath282{0cm}{0.4cm}}\\right ] } ,             \\qquad \\text { where } \\qquad             y_i = { \\left({1+{\\varepsilon}_{i-1}}\\right ) } x_{i-1}.          \\end{aligned}\\ ] ] if @xmath283 , then we found the desired approximation , and the algorithm stops .",
    "set @xmath284 and @xmath285 .",
    "@xmath286{redviolet}{\\texttt{\\bf{{decider}}}}}}\\index{algorithm!{decider}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{decider}}}}}}}}}}\\xspace}_{{\\varepsilon}_i}(m_i , { \\mathsf{w } } ,          { \\gamma})$ ] , see definition  [ def : decider ] @xmath287 .",
    "there are three possibilities :    if @xmath288 `` @xmath289 '' , then set @xmath290 $ ] .",
    "if @xmath288 `` @xmath291 '' , then set @xmath292 $ ] .    if @xmath288 `` @xmath293 $ ] '' , then set @xmath294 .",
    "@xmath295 .    in each round",
    ", the algorithm computes an interval of spread @xmath296 that contains @xmath297 , and @xmath298    since the main bottleneck in each iteration is calling @xmath106{redviolet}{\\texttt{\\bf{{decider}}}}}}\\index{algorithm!{decider}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{decider}}}}}}}}}}\\xspace}_{{\\varepsilon}_i}$ ] , which runs in @xmath299 time , the total running time is bounded by , @xmath300 since the sum behaves like a geometric series and the last term is @xmath125 .",
    "[ sec : applications ]    we now show that theorem  [ theo : result : eps ] can be applied to a wide array of problems . in order to apply it , one need to show that the given problem meets the requirements of an .",
    "[ sec : k : center ]    since computing a @xmath0-center clustering is an problem ( lemma  [ lemma : k : center : wbdp ] ) , plugging this into theorem  [ theo : result : eps ] , immediately yields a constant factor approximation to @xmath0-center in linear time .",
    "it is easy to convert such an approximation to a @xmath6-approximation using a grid , see har - peled @xcite .",
    "thus we get the following .",
    "[ theo : k : center:2 ] given a set @xmath8 of @xmath7 points in @xmath14 , and a parameter @xmath0 , @xmath301 , one can compute a @xmath6-approximation to the optimal @xmath0-center clustering of @xmath8 in ( expected ) linear time .    a result similar to theorem  [ theo :",
    "k : center:2 ] was already known for the case @xmath302 @xcite , and the above removes this restriction .",
    "in addition , the new algorithm and its analysis are both simpler than the previous algorithm .",
    "[ sec : k : th : distance ]    [ claim : change ] let @xmath78 and @xmath303 be subsets of @xmath304 of size @xmath7 , such that @xmath303 is obtained by taking each value in @xmath78 and increasing or decreasing it by less than @xmath49 .",
    "let @xmath305 and @xmath306 be the @xmath0thsmallest values in @xmath78 and @xmath303 , respectively",
    ". then @xmath307 .",
    "suppose for contradiction that @xmath308 . if @xmath309 then @xmath303 has at least @xmath310 values strictly larger than @xmath311 which implies @xmath78 has at least @xmath310 values strictly larger than @xmath305 .",
    "similarly if @xmath312 then @xmath303 has at least @xmath0 values strictly smaller than @xmath313 which implies @xmath78 has at least @xmath0 values strictly smaller than @xmath305 .",
    "[ lemma : k : dist ] let @xmath8 be a weighted point set in @xmath14 , and let @xmath129 be an integer parameter .",
    "let @xmath314 denote the multi - set of pairwise distances determined by @xmath8 .",
    "is viewed as @xmath1 unit weight points when determining the values of @xmath314 . for simplicity",
    "we assume that the @xmath0th distance in @xmath8 is not zero ( i.e. it is determined by two distinct points ) . ]",
    "given an instance @xmath315 the problem asks you to output the @xmath0thsmallest distance in @xmath314 .",
    "given such an instance , one can @xmath4-approximate the @xmath0thsmallest distance in ( expected ) time @xmath316 .",
    "let @xmath317 be the function that returns the @xmath0th smallest distance .",
    "we prove that this function is an @xmath4-(see definition  [ def : n : d : p ] @xmath143 ) .",
    "given @xmath9 and @xmath16 , build a grid where every cell has diameter @xmath318 , and store the points of @xmath8 in this grid .",
    "now , for any non - empty grid cell @xmath319 , let @xmath320 be the total weight of points in @xmath321 , and register this weight with all the grid cells in distance at most @xmath9 from it ( i.e. , @xmath322 ) .",
    "let @xmath323 denote the total weight registered with a cell @xmath319 ( which includes its own weight ) .",
    "any point in @xmath319 determines @xmath324 distances to other points in @xmath322 .",
    "therefore the total number of distances between points in @xmath319 and points in @xmath322 is @xmath325{0cm}{0.4cm}}{{\\omega}_{{\\mathsf{n}}}{\\!\\left({{\\box}}\\right ) } } - 1}\\right)}$ ] .",
    "summing this over all cells ( and dividing by @xmath6 to avoid double counting ) gives the quantity @xmath326{0cm}{0.4cm}}{{\\omega}_{{\\mathsf{n}}}{\\!\\left({{\\box}}\\right ) } }                 - 1}\\right)}.          \\end{aligned}\\ ] ] note , that the count @xmath327 includes all distances which are @xmath57 , and no distances @xmath328 .",
    "so let the desired @xmath0thdistance be denoted by @xmath329 .",
    "thus , if @xmath330 then @xmath331 . similarly , if @xmath332 then @xmath333 .",
    "therefore , to build a @xmath4-decider for distance @xmath9 , we run the above counting procedure on @xmath334 and @xmath335 , and let @xmath336 and @xmath337 be the two counts computed , respectively .",
    "there are three cases :    if @xmath338 then @xmath339 , and return this result .    if @xmath340 then @xmath341 , then @xmath342 $ ] , and this interval has spread @xmath343",
    ". the decider returns that this interval contains the desired value .",
    "the only remaining possibility is that @xmath344 , and the decider returns this .",
    "the running time of this decision procedure is @xmath316 .    since the distance between any pair of points changes by at most @xmath148 in a @xmath49-translation",
    ", the lipschitz condition holds by claim  [ claim : change ] .    by assumption ,",
    "the @xmath0thsmallest distance is determined by two distinct weighted points @xmath26 and @xmath98 .",
    "clearly these points are not in @xmath155 since @xmath345 .",
    "so consider any point @xmath346 .",
    "since removing @xmath347 does not remove the distance @xmath348 from the set of remaining distances , all that is needed is to show how to update @xmath0 . clearly , @xmath347 contributes @xmath349 distances , all of value @xmath150 , to @xmath350 , and @xmath351 pairwise distances of value zero .",
    "thus , after removing @xmath347 from @xmath21 , the new context is @xmath352 .",
    "the algorithm of lemma  [ lemma : k : dist ] also works ( with minor modifications ) if we are interested in the @xmath0thdistance between two sets of points ( i.e. , the bipartite version )",
    ".    given two sets @xmath8 and @xmath23 of points in @xmath14 , of total size @xmath7 , and parameters @xmath0 and @xmath142 , one can @xmath4-approximate , in expected @xmath19 time , the following :    the @xmath0thsmallest bichromatic distance .",
    "formally , this is the smallest @xmath0thnumber in the multiset @xmath353{0cm}{0.4cm}}\\right . } } \\right\\}}$ ] .    the closest bichromatic pair between @xmath8 and @xmath23 .      [ sec : k : smallest : m : n : n ]    for a set @xmath24 of @xmath7 points , and a point @xmath25 , its in @xmath8 is the @xmath1thclosest point to @xmath26 in @xmath27 .",
    "in particular , let @xmath28 denote this distance . here",
    ", consider the multiset of these distances defined for each point of @xmath8 ; that is , @xmath354 .",
    "interestingly , for any @xmath1 , we can approximate the @xmath0thsmallest number in this set in linear time .    in order to use",
    ", one need to generalize the problem to the case of weighted point sets .",
    "specifically , a point @xmath26 of weight @xmath355 is treated as @xmath355 distinct points at the same location . as such",
    ", the set @xmath356 from the above is actually a multiset containing @xmath355 copies of the value @xmath28 .",
    "[ theo : k : th : m : nn ] let @xmath21 be a set of @xmath7 weighted points in @xmath14 , and @xmath357 parameters .",
    "then one can @xmath4-approximate , in expected @xmath34 time , the @xmath0thsmallest @xmath1-nearest neighbor distance in @xmath21 .",
    "formally , the algorithm @xmath4-approximates the @xmath0thsmallest number in the multiset @xmath358    we establish the required properties , see definition  [ def : n : d : p ] @xmath143 .",
    "let @xmath359 denote the desired quantity .",
    "we first need a @xmath4-decider for this problem . to this end , given @xmath360 and @xmath21 as input , create a grid with cells of diameter @xmath361 , and mark for each point of @xmath21 all the grid cells in distance at most @xmath9 from it .",
    "each non - empty grid cell has a count of the total weight of the points in distance at most @xmath9 from it .",
    "thus , each point of @xmath21 can compute the total weight of all points which are approximately in distance at most @xmath9 from it .",
    "now , a point @xmath153 , can decide in constant time if ( approximately ) @xmath362 .",
    "if the number of points which declare @xmath362 ( where a point @xmath26 is counted @xmath355 times ) is greater than @xmath0 then the distance @xmath9 is too large , and if it is smaller than @xmath0 than @xmath9 is too small .",
    "being slightly more careful about the details ( as was done in the proof of lemma  [ lemma : k : dist ] ) one can verify this leads to a @xmath4-decider for this problem .",
    "clearly the lipschitz property holds in this case , as @xmath49-translation only changes inter - point distances by at most an additive term of @xmath148 .",
    "we need to show that @xmath0 can be updated properly for a weighted point @xmath26 whose nearest neighbor is further away than @xmath363 . if @xmath364 then we are throwing away @xmath355 points , all with @xmath365 , and so @xmath0 should be update to @xmath366 when @xmath26 is removed . similarly ,",
    "if @xmath367 then all the points @xmath26 corresponds to have @xmath368 larger than the threshold , and @xmath0 does not have to be updated .    plugging this into theorem  [ theo : result : eps ] implies the desired result .",
    "theorem  [ theo : k : th : m : nn ] can be easily extended to work in the bichromatic case .",
    "that is , there are two point sets @xmath8 and @xmath23 , and we are interested in the @xmath1thnearest neighbor of a point @xmath25 in the set @xmath23 .",
    "it is easy to verify that the same time bounds of theorem  [ theo : k : th : m : nn ] hold in this case .    in particular , setting @xmath369 and @xmath30 in the bichromatic case , the computed distance will be the minimum radius of the balls needed to be placed around the points of @xmath23 to cover all the points of @xmath8 ( or vice versa ) .",
    "[ sec : f : n : n ]    using theorem  [ theo : k : th : m : nn ] with @xmath30 and @xmath370 , results in a @xmath6-approximation , in @xmath12 time , to the of @xmath8 .",
    "we now show how this can be converted into an exact solution .",
    "so we have a quantity @xmath9 that is larger than the @xmath0thnearest neighbor distance , but at most twice larger .",
    "we build a grid with a cell diameter being @xmath371 .",
    "clearly , any point whose nearest neighbor distance is at least the @xmath0thnearest neighbor distance must be the only point in its grid cell .",
    "for each such point @xmath26 , we compute its distance to all the points stored in its neighborhood @xmath56 , by scanning the list of points associated with these cells .",
    "this computes for these `` lonely '' points their exact nearest neighbor distance .",
    "the @xmath0thsmallest nearest neighbor distance will then be the @xmath372thlargest distance computed .",
    "clearly , every cell s list of points get scanned a constant number of times , so overall the running time is linear .",
    "we summarize the result .    for a point",
    "set @xmath8 , the , is the maximum distance of a point of @xmath8 , from the remaining points .",
    "formally , it is @xmath373 .",
    "let @xmath8 be a set of @xmath7 points in @xmath14 .",
    "for an integer @xmath0 , @xmath374 , one can compute exactly , in expected linear time , the @xmath0thnearest neighbor distance in @xmath8 . in particular , setting @xmath31 , one can compute the furthest nearest neighbor distance exactly , in expected linear time .",
    "[ sec : longest : mst ]    the net computation provides a natural way to partition the data into clusters , and leads to a fast clustering algorithm .",
    "one alternative partition scheme is based on distance connectivity .",
    "[ def : connectivity ] for a set of points @xmath8 and a number @xmath77 , let @xmath375 be the of @xmath8 .    specifically , it is a partition of @xmath8 into connected components of the @xmath2of @xmath8 after all edges strictly longer than @xmath9 are removed from it ( alternatively , these are the connected components of the intersection graph where we replace every point of @xmath8 by a disk of radius @xmath376 centered at that point ) , see figure on the right .",
    "consider two partitions @xmath377 of @xmath8 .",
    "the partition @xmath378 is a refinement of @xmath379 , denoted by @xmath380 , if for any set @xmath381 , there exists a set @xmath382 such that @xmath383 .",
    "[ lemma : longest : edge : partition ] given a set @xmath63 , and parameters @xmath9 and @xmath16 , one can compute , in @xmath316 time , a partition @xmath378 , such that @xmath384 .    build a grid with every cell having diameter @xmath361 . for every point in @xmath8 mark all the cells in distance @xmath376 from it .",
    "that takes @xmath19 time .",
    "next , for every marked cell create a node @xmath305 , and let @xmath385 be the resulting set of nodes .",
    "next , create a bipartite graph @xmath386 connecting every node of @xmath385 , to all the points of @xmath8 marking its corresponding grid cell .",
    "now , compute the connected components in @xmath387 , and for each connected component extract the points of @xmath8 that belong to it . clearly , the resulting partition @xmath378 of @xmath8 , is such that any two points in distance @xmath57 are in the same set ( since for such points there must be a grid cell in distance @xmath388 from both ) .",
    "similarly , if the distance between two subsets @xmath389 is at least @xmath390 , then they are in different connected components of @xmath378 . in particular , in order for @xmath356 and @xmath391 to be in the same component",
    ", there must exists points @xmath108 and @xmath392 which marked the same grid cell .",
    "however , such a grid cell would need to be in distance at most @xmath376 from both @xmath393 and @xmath394 , implying @xmath395 , a contradiction .",
    "thus , this is the desired partition .",
    "clearly , this takes @xmath19 time overall .",
    "[ theo : m : s : t : k : edge ] given a set of @xmath7 points @xmath8 in @xmath14 , and parameters @xmath0 and @xmath16 , one can output , in expected @xmath316 time , a @xmath4-approximation to the @xmath0thlongest ( or @xmath0th shortest ) edge in the @xmath2of @xmath8 .",
    "consider the cost function @xmath396 which returns the @xmath0thlongest edge of the @xmath2of @xmath8 .",
    "it is easy to verify that @xmath396 is the minimum @xmath9 such that @xmath375 has @xmath0 connected components . for the sake of simplicity of exposition ,",
    "we assume all the pairwise distances of points in @xmath8 are distinct .",
    "we need to fill - in / verify the properties of definition  [ def : n : d : p ] @xmath143 :    the @xmath124)-decider for @xmath397 uses the algorithm of lemma  [ lemma : longest : edge : partition ] .",
    "specifically , for a specified @xmath77 , compute a partition @xmath378 , such that @xmath398 .",
    "now , if @xmath378 has @xmath138 connected components , then @xmath399 . similarly , if @xmath378 has @xmath400 connected components , then @xmath401 . by calling on two values , and using slightly smaller @xmath16 ,",
    "it is straightforward to get the desired @xmath4-decider , as was done in lemma  [ lemma : k : dist ] @xmath402 .",
    "let @xmath403 be the complete graph defined on @xmath404 , where @xmath404 is some @xmath49-translation @xmath8 .",
    "for the sake of simplicity of exposition , we consider @xmath404 and @xmath8 to be multi - sets of the same cardinality ( i.e. , @xmath405 ) .",
    "let @xmath406 ( resp .",
    "@xmath407 ) be the edges in the @xmath2of @xmath387 ( resp .",
    "@xmath403 ) sorted by increasing order by their weight .",
    "( note , that some of these edges might have length @xmath408 . )    observe that the graph having @xmath409 as edges , under the weight function induced by @xmath410 , it is a forest with @xmath411 connected components . as such , we have that @xmath412 , since , by the correctness of the kruskal algorithm , the first @xmath190 edges of the @xmath2form such a forest with the maximum weight edge being minimum ( among all such forests ) . as such , we have that @xmath413 a symmetric argument implies that @xmath414 .",
    "setting @xmath415 , we have that @xmath416 , as desired .",
    "consider a point @xmath153 , such that @xmath417 , and @xmath418 .",
    "this implies that all the @xmath2edges adjacent to @xmath26 are of distance @xmath150 .",
    "assume there are @xmath174 such edges , and observe that removing these edges creates @xmath419 connected components of the @xmath2 , such that each connected component is of distance @xmath150 from each other ( indeed , otherwise , one of the removed edges should not be in the @xmath2 , as can be easily verified ) .",
    "thus , if we delete @xmath26 , and recompute the @xmath2 , we will get @xmath174 new edges that replace the deleted edges , all of these edges are of length @xmath150 . that is , deleting @xmath26 , and decreasing @xmath0 by one",
    ", ensures that the target value remains the same in the pruned instance .",
    "this establish that @xmath396 is an @xmath4- , and by plugging this into theorem  [ theo : result : eps ] , we get the desired result .        [",
    "sec : sketchable ]    let @xmath8 be a finite ground set of elements , and let @xmath420 be a family of subsets of @xmath8 .",
    "then @xmath421 is an if for any @xmath422 and any @xmath423 , such that @xmath383 , we have that @xmath424 .",
    "such a set system is a , if for any set @xmath425 there exists a constant size @xmath426 such that :    for any @xmath427 that are disjoint , @xmath428 can be computed from @xmath426 and @xmath429 in @xmath75 time .",
    "there is a membership oracle for the set system based on the sketch .",
    "that is , there is a procedure @xmath430 such that given the sketch of a subset @xmath426 , @xmath431 returns whether @xmath432 or not , in @xmath75 time .",
    "an example for such a sketchable family , is the set system @xmath433 , where @xmath425 is in @xmath420 if @xmath434 . here",
    "the sketch of the set is simply the number of elements in the set , and combining two sketches @xmath426 and @xmath429 is adding the numbers to get @xmath435 ( for @xmath436 )",
    ".    we will be interested in two natural problems induced by such a family :    smallest cluster  find the smallest set in the family with certain properties , and    min - max clustering ",
    "find disjoint sets in the family such that they cover the original set , and the maximum price of these sets is minimized .",
    "note it is not necessary for the descriptions to have @xmath75 size or the oracle to run in @xmath75 time , however , assuming otherwise will affect the running time of if it is used to solve a problem involving a sketchable family .",
    "consider associating a positive @xmath0-dimensional vector @xmath437 with each point @xmath25 ( a vector is if it is non - zero , and all its coordinates are non - negative ) .",
    "a is an inequality of the form @xmath438 , where the coefficients @xmath439 are all non - negative .",
    "for such a linear inequality , consider the set system @xmath440 , where a set @xmath23 is in @xmath420 if the linear inequality holds for the vector @xmath441 . clearly , this family is a sketchable family , the sketch being the sum of the vectors associated with the points of the set ( here @xmath0 is assumed to be a constant ) .",
    "it is easy to verify that sketchable families are closed under finite intersection .",
    "specifically , given a collection of @xmath1 such positive inequalities , the family of sets such that their sketch vector complies with all these inequalities is a sketchable family ( of course , checking if a set , given its sketch , is in the family naively would take @xmath442 time ) .",
    "as a concrete application , consider the scenario where every element in @xmath8 has @xmath443 attributes .",
    "one might be interested in subsets , where each set has at least a total sum of @xmath444 unit for the first two attributes , and a total sum of @xmath6 units for the last two attributes .    of course",
    ", in general , a membership oracle for the attributes space that has the property that if @xmath445 is valid then @xmath446 is also valid , for any positive @xmath447 , would define a sketchable family . as a concrete example , consider the non - linear ( and not convex ) condition that the sum of at least two attributes is larger than @xmath444 .",
    "clearly , this defines a sketchable family .",
    "clearly the above definition of sketchable family is very general and widely applicable .",
    "next , we show how can be used to approximate certain objectives over sketchable families .",
    "[ sec : min : cluster ]    we now consider the problem of minimizing the cluster size of a subset of a given point set subject to inclusion in a sketchable family .",
    "specifically , we consider the case when the cluster is defined by a ball of radius @xmath9 or when the cluster is defined by a connected component of @xmath375 for a radius @xmath9 .",
    "note that as a ball or component grows both the cluster size and inclusion of the set of points ( in the cluster ) in the sketchable @xmath420 are monotone properties .",
    "this correspondence is what allows us to apply our general framework .    for a set of @xmath7 points @xmath63 , and a sketchable family @xmath440 , one can @xmath4-approximate , in expected @xmath316 time , the radius of the smallest ball , @xmath35 , such that @xmath448 .",
    "let @xmath449 be the radius of the smallest ball @xmath35 in @xmath14 such that @xmath450 .",
    "we claim that @xmath451 is an , see definition  [ def : n : d : p ] @xmath143 ) .",
    "the and properties readily hold for @xmath451 .    as for property ,",
    "given @xmath9 and @xmath142 , construct a grid with cells of diameter @xmath452 , and register each point of @xmath8 in all the grid cells in distance at most @xmath9 from it .",
    "if there is a ball , @xmath35 , of radius @xmath9 such that @xmath453 then the set of points registered with the grid cell containing the center of this ball will be a superset of @xmath36 and hence the set is in @xmath420 , by the upward closed property of sketchable families .",
    "moreover , the set registered at this grid cell requires a ball of radius at most @xmath454 ( centered at any point in this grid cell ) to cover it .",
    "thus , the decision procedure simply checks the set of points associated with each grid cell to see whether or not it is in @xmath420 .",
    "the definition of sketchable families implies this can be done in linear time in the total sizes of these sets ( i.e. , @xmath19 ) .",
    "furthermore , if there is no ball of radius @xmath390 whose point set is in @xmath420 then the decision procedure would fail to find such a cell . thus , this is a @xmath4-decision procedure , and its running time is @xmath19 .    plugging this into the algorithm of theorem  [ theo : result : eps ] implies the result .",
    "the following is a sample of what the above theorem implies .",
    "we can @xmath4-approximate , in @xmath34 time , the following problems for a set of @xmath7 points in @xmath14 :    the smallest ball containing @xmath0 points of @xmath8 .",
    "the points of @xmath8 are weighted and we are given a threshold @xmath39 .",
    "compute the smallest ball containing points of weight at least @xmath39 .    if the points of @xmath8 are colored by @xmath0 colors , the smallest ball containing points of @xmath8 , such that they are colored by at least @xmath37 different colors .",
    "( thus , one can find the smallest non - monochromatic ball [ @xmath455 , and the smallest ball having all colors [ @xmath456 . )",
    "the running time is @xmath457 , as the sketch here is a @xmath0-dimensional vector .",
    "[ sec : min : cluster : c ]    note that @xmath375 is a monotone partition as @xmath9 increases , and it is natural to ask what is the minimum @xmath9 , for which there is a connected component in @xmath375 that is in a sketchable family .",
    "[ theo : min : cluster : mst ] for a set of @xmath7 points @xmath63 , and a sketchable family @xmath458 , one can @xmath4-approximate , in expected @xmath316 time , the minimum @xmath9 , such that there is a connected component in @xmath375 that is in @xmath420 .",
    "the target function @xmath459 is the smallest @xmath9 such that @xmath375 contains a set that is in @xmath420 .",
    "let @xmath460 .",
    "the algorithm first check if any of the input points by themselves have the desired property , if so then @xmath461 and the algorithm returns @xmath408 .",
    "( for the case that @xmath8 is a multiset , see remark  [ rem : multi ] @xmath462 . ) as such",
    ", we can assume that @xmath463 , and furthermore , by corollary  [ cor : same:1 ] ( c ) , @xmath464 is always non - zero during the algorithm execution .",
    "again , we need to verify the properties of definition  [ def : n : d : p ] @xmath143 for @xmath464 :    one can @xmath4-approximate the connected components of @xmath375 , using the algorithm of lemma  [ lemma : longest : edge : partition ] , and for each approximate connected component , use their sketch to decide if any of them is in @xmath420 .",
    "if so , return that @xmath9 is larger than the optimal value , otherwise return that it is too small .",
    "clearly , this is @xmath4-decider that works in @xmath19 time .",
    "let @xmath465 .",
    "by the definition of @xmath451 , there exists @xmath0 , such that @xmath466 .",
    "now , arguing as in the proof of theorem  [ theo : m : s : t : k : edge ] @xmath467 , implies that @xmath451 has the desired property .",
    "consider a point @xmath153 , such that @xmath417 , and @xmath468 .",
    "now , @xmath26 by itself can not have the desired property , as this would imply that @xmath469 .",
    "this implies that in @xmath470 the point @xmath26 is by itself ( and not in any cluster that is in @xmath420 ) . as such ,",
    "throwing @xmath26 away does not change the target function .",
    "formally , @xmath471 .    plugging this into theorem  [ theo : result : eps ] implies the result .",
    "one natural application for theorem  [ theo : min : cluster : mst ] , is for ad hoc wireless networks . here",
    ", we have a set @xmath8 of @xmath7 nodes and their locations ( say in the plane ) , and each node can broadcast in a certain radius @xmath9 ( the larger the @xmath9 the higher the energy required , so naturally we would like to minimize it ) .",
    "it is natural now to ask for the minimum @xmath9 such that one of the connected components in the resulting ad hoc network has some desired property .",
    "for example , in @xmath19 time , we can @xmath4-approximate the smallest @xmath9 such that :    one of the connected components of @xmath375 contains half the points of @xmath8 , or more generally if the points are weighted , that one of connected component contains points of total weight at least @xmath39 , for a prespecified @xmath39 .",
    "if the points are colored , the desired connected component contains all the colors ( for example , each color represent some fraction of the data , and the cluster can recover the data if all the pieces are available ) , or at least two colors , or more generally a different requirement on each color .      [",
    "sec : cluster : monotone ]    we are given a sketchable family @xmath472 , and a cost function @xmath473 .",
    "we are interested in finding disjoint sets @xmath474 , such that    @xmath475 , and    @xmath476 is minimized .",
    "we will refer to the partition realizing the minimum as the of @xmath8 .",
    "let @xmath8 be a set of points in @xmath14 , and let @xmath472 be a sketchable family .",
    "for a set @xmath477 , let @xmath478 be the radius of the smallest ball centered at a point of and enclosing @xmath21 .",
    "one can @xmath38-approximate , in expected @xmath19 time , the min - max clustering under @xmath479 of @xmath8 .",
    "that is , one can cover @xmath8 by a set of balls , and assign each point of @xmath8 to one of these balls , such that the set of points assigned to each ball is in @xmath420 , and the maximum radius of any of these balls is a @xmath38-approximation to the minimum radius used by any such cover .",
    "[ theo : cluster : min : max ]    let @xmath480 be the optimal partition with radius @xmath481 , and consider an @xmath9-net @xmath10 for @xmath482 , computed using corollary  [ cor : valid ] .",
    "consider a point @xmath483 , and let @xmath484 $ ] be the set of points of @xmath8 assigned to @xmath26 by the nearest net - point assignment .",
    "next , consider the cluster @xmath485 that contains it .",
    "clearly , @xmath486 , and the distance of @xmath26 from all other net points in @xmath10 is at least @xmath487 .",
    "it follows that @xmath488 $ ] , and since @xmath477 , it follows that @xmath484 \\in { \\mathcal{f}}$ ] .    a @xmath489-decider for this problem works by computing the @xmath490-net @xmath10 , and for each @xmath483 , checking the sketchable property for the set @xmath484 $ ] .",
    "it is easy to verify that the properties of definition  [ def : n : d : p ] @xmath143 hold in this case . in particular , throwing a far away isolated point corresponds to a cluster that already fulfill the monotone property , and it is too far away to be relevant .",
    "namely , computing @xmath481 is an and so plugging this into theorem  [ theo : result : eps ] implies the result .",
    "[ sec : cluster : monotone : examples ]    if the required sketchable property is that every cluster contains at least @xmath0 points , then theorem  [ theo : cluster : min : max ] approximates the problem .",
    "that is , one has to cover the points by balls , such that every cluster ( i.e. , points assigned to a ball ) contains at least @xmath0 points .",
    "the price of this clustering is the radius of the largest ball used .",
    "a @xmath6-approximation to this problem is known via the usage of flow @xcite but the running time is super quadratic .",
    "recently , the authors showed a similar result to theorem  [ theo : cluster : min : max ] with running time ( roughly ) @xmath32 @xcite .",
    "this paper also shows that this problem can not be approximated to better than ( roughly ) @xmath491 even for points in the plane .",
    "let @xmath8 be a set of points in @xmath14 , and let @xmath0 and @xmath142 be parameters .",
    "one can @xmath38-approximate the lower bounded center clustering in @xmath19 time .",
    "one can plug - in any sketchable family into theorem  [ theo : cluster : min : max ] .",
    "for example , if the points have @xmath0 colors , we can ask for the min - max radius clustering , such that every cluster contains ( i ) all colors , ( ii ) at least two different colors , or ( iii ) a different requirement on each color , etc .    as another concrete example , consider that we have @xmath7 customers in the plane , and each customer is interested in @xmath0 different services ( i.e. , there is a @xmath0-dimensional vector associated with each customer specifying his / her demand ) .",
    "there are @xmath37 types of service centers that can be established , but each such center type requires a minimum level of demand in each of these @xmath0 categories ( i.e. , each type is specified by a minimum demand @xmath0-dimensional vector , and a set of customers can be the user base for such a service center if the sum of their demands vector is larger than this specification ) .",
    "the problem is to partition the points into clusters ( of minimum maximum radius ) , such that for every cluster there is a valid service center assigned to it .",
    "clearly , this falls into the framework of theorem  [ theo : cluster : min : max ] , and can be @xmath38-approximated in @xmath492 time .",
    "[ sec : cluster : spanning ]    one can get a similar result to theorem  [ theo : cluster : min : max ] for the connectivity version of clustering of @xmath8 .",
    "formally , a set of points @xmath493 is if @xmath21 is contained in some set of @xmath375 . given a sketchable family @xmath494 , a partition @xmath378 of @xmath8 is an if all the sets in @xmath378 are in @xmath420 , and are @xmath9-valid .",
    "[ theo : cluster : connected ] let @xmath8 be a set of points in @xmath14 , and let @xmath472 be a sketchable family .",
    "one can @xmath4-approximate @xmath481 , in expected @xmath19 time , where @xmath481 is the minimum value such that there is a @xmath481-connected clustering of @xmath8 .",
    "let @xmath464 be the target function in this case .",
    "we verify the properties of definition  [ def : n : d : p ] @xmath143 :    given @xmath9 , we use lemma  [ lemma : longest : edge : partition ] to compute a partition @xmath378 of @xmath8 such that @xmath495 .",
    "if the sketchable property holds for each cluster of @xmath378 , then return that @xmath9 is too large , otherwise return that it is too small . as for",
    "the quality of this decider , observe that if the optimal partition has a cluster @xmath21 that uses points from two different clusters of @xmath378 , than @xmath21 is not @xmath9-valid , as otherwise these two points would be in the same cluster of @xmath378 ( namely , @xmath496 ) .",
    "follows easily by arguing as in theorem  [ theo : m : s : t : k : edge ] @xmath467 .",
    "if an isolated point exists , then it can be thrown away because the cluster of original points it corresponds to , is a valid cluster that can be used in the final clustering , and it does not interact with any other clusters .    plugging this into theorem  [ theo : result : eps ] now implies the result .",
    "a nice application of theorem  [ theo : cluster : connected ] is for ad hoc networks .",
    "again , we have a set @xmath8 of @xmath7 wireless clients , and some of them are base stations ; that is , they are connected to the outside world .",
    "we would like to find the minimum @xmath9 , such that each connected component of @xmath375 contains a base station .",
    "[ sec : closest : non : zero : dist ]    given a point set @xmath8 , it was already shown in section  [ sec : f : n : n ] that , with a small amount of post processing , can be used to compute the closest pair distance exactly in expected linear time . if one allows @xmath8 to contain duplicate points ( i.e. @xmath8 is a multiset ) then a couple modifications to @xmath167    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } }       \\index{algorithm!{ndpalg}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{ndpalg } } } } } } } }    } } \\xspace}$ ] must be made .",
    "first modify the algorithm so that for the selected point @xmath26 it finds the closest point to @xmath26 that has non - zero distance from it .",
    "secondly , we modify ( see lemma  [ lemma : delete ] @xmath156 ) so that if a net point corresponds to several copies of the same point then it is being treated as a single point . with these two modifications , the above algorithm works verbatim , and we get the following .",
    "[ lemma : non : zero ] let @xmath8 be a multiset of weighted points in @xmath14 .",
    "then one can solve the problem _ exactly _ for @xmath8 , in expected linear time .",
    "in particular , if @xmath8 contains no duplicates then this corresponds to computing the closest pair distance .",
    "interestingly , the algorithm of lemma  [ lemma : non : zero ] is a prune - and - search algorithm , as the net stage never gets executed .",
    "observe , that it is not hard to extend the algorithm of golin _",
    "et  al . _",
    "@xcite to solve this variant , and the result of lemma  [ lemma : non : zero ] is included in the paper only for the sake of completeness . in particular , the resulting ( simplified ) algorithm is similar to the algorithm of khuller and matias @xcite .",
    "[ sec : high : prob ] in section  [ sec : framework ] , we presented an algorithm ( , see figure  [ figure : a : algorithm ] @xmath196 ) that provides a constant factor approximation to a wide variety of problems in expected linear time . here",
    "we present an extension of that algorithm that runs in linear time with high probability .",
    "our algorithm works by computing a quantity that is not directly related to the problem at hand ( but in linear time ! ) , and then relating this quantity to the desired quantity , enabling us to compute it in linear time .",
    "specifically , the resulting algorithm is somewhat counterintuitive and bizarre . as such , to make the algorithm description more accessible to the reader , we introduce the basic ideas in section  [ sec : h : p : introduction ] and sketch the algorithm in section  [ sec : motivation ] .",
    "we describe the algorithm in detail in section  [ sec : high : prob : algorithm ] , and analyze it in section  [ sec : high : prob : analysis ] .",
    "[ sec : h : p : introduction ]    [ [ notation . ] ] notation .",
    "+ + + + + + + + +    see table  [ table : notation ] for a summary of the notation used in this part of the paper . as it is sufficient for our purposes , for simplicity in this section @xmath8",
    "will always be an unweighted points set , i.e. @xmath497 . the algorithm can be easily extended to handle the weighted case .",
    "@xmath84 & @xmath498 &    distance from @xmath26 to its nearest neighbor in @xmath86 .",
    "+ @xmath499 & &    distance of @xmath26 to its @xmath190thnearest neighbor in @xmath500 .     + @xmath501 & @xmath502{0cm}{0.4cm}}\\right . } } \\right\\}}$ ] &    multi - set of distances between points in @xmath503 and nearest neighbors in @xmath8 .     + @xmath504 & @xmath505{0cm}{0.4cm}}\\right . } } \\right\\}}$ ] &    multi - set of distances between point in @xmath503 and their @xmath190thnearest neighbors in @xmath8 .",
    "+ @xmath506 & &    value of rank @xmath507 in @xmath501 , for some @xmath508 $ ] .",
    "+ @xmath509 & &    value of rank @xmath507 in @xmath504 , for some @xmath508 $ ] .",
    "+    [ table : notation ]      [ [ sample - in - the - middle . ] ] sample in the middle .",
    "+ + + + + + + + + + + + + + + + + + + + +    observe that if one could sample a nearest neighbor distance that lies in the interval @xmath510 $ ] for some fixed constant @xmath511 , then we are done . indeed , for each iteration of for which the sampled distance was near the middle , it is guaranteed that the algorithm either terminates or removes a constant fraction of the points . as such it is sufficient to present an algorithm which returns a value from this range with probability @xmath512 , for some sufficiently large constant @xmath73 , where @xmath513 .",
    "for the rest of this section we therefore focus on the problem of computing such an approximate middle nearest neighbor distance , in linear time , with high probability . to turn into an algorithm which runs in linear time with high probability , we replace line  [ line : gen : random ] and line  [ line : rad ] in figure  [ figure : a : algorithm ] @xmath196 with this new subroutine .",
    "[ [ sampling - for - the - median . ] ] sampling for the median .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    the problem with the random sampling from @xmath514 done in , is that though , with good probability , the sampled distance lies near the middle , it does not do so with high probability .",
    "this is the same problem one is faced when performing the standard basic randomized median selection . for median selection one known solution",
    "is rather than randomly sampling a pivot , to instead take a sufficiently large random sample , and take the median of the random sample as the pivot .",
    "this pivot is good with high probability @xcite , and it is this result we wish to mimic .    [ [ the - challenge . ] ] the challenge .",
    "+ + + + + + + + + + + + + +    given the above discussion , the natural solution to finding a good middle value from @xmath514 , would be to sample multiple values from @xmath514 , and then take the median . by the chernoff inequality ,",
    "if one samples at least a logarithmic number of values from a set of @xmath7 values ( @xmath514 in our case ) then , with high probability , the median of the sample will lie near the median of the entire set .",
    "( see lemma  [ lemma : high : prob ] @xmath515 for a formal statement and proof of this observation . )",
    "the problem with this approach is that sampling @xmath516 values from @xmath514 takes @xmath517 time ( at least naively ) .",
    "specifically , while the sampling is easy , computing the associated values requires @xmath518 time per sampled point ( note this is not a problem for median selection as there we are sampling values directly rather than points from which values are determined ) .    therefore , we instead not only take a sample from which to select our median value , but also a sample from which we will determine what these values are .",
    "namely , for each point in a @xmath519 sized random sample , compute it s nearest neighbor in a second @xmath520 sized sample , and then take the median of the computed values . though this approach takes @xmath521 time",
    ", we need to somehow use it to compute the desired quantity , which we describe how to do next .",
    "[ sec : motivation ]    we describe the algorithm here informally  the exact details are provided in section  [ sec : high : prob : algorithm ] .",
    "we take a logarithmic sized sample , @xmath503 , from @xmath8 , and we are interested in computing the median value in @xmath501 , see table  [ table : notation ] . as computing @xmath501 itself takes @xmath522 time ( at least naively ) , instead we compute @xmath523 , where @xmath524 is a second @xmath525 sized sample .",
    "consider a point @xmath526 .",
    "first observe that since @xmath527 , @xmath528 ( for most of the points in @xmath8 this inequality is strict and would be @xmath529 ) .",
    "however , as @xmath530 , with high probability , at least one of @xmath26 s @xmath531 closest points in @xmath8 will be in @xmath524 ( formally shown in lemma  [ lemma : est : log : dist ] ) . therefore , with high probability , for each point @xmath526 we get a bounded value @xmath532 $ ] , where @xmath533 .",
    "for the purpose of building intuition , for now lets assume that @xmath534 .",
    "in other words , assume that one could take a logarithmic sample from @xmath535 in linear time .",
    "as usual taking the median of these values is a good approximation for the median value in @xmath535 , so assume that we have computed @xmath536 .",
    "we next compare @xmath537 to @xmath538 by calling an appropriate decider .",
    "there are two possible cases .",
    "assume that @xmath539 , where @xmath540 .",
    "since @xmath541 , this implies that @xmath542 $ ] ( and we know the value of @xmath537 ) .",
    "for example , this happens if the points of @xmath63 are roughly uniformly distributed .",
    "this gives us a @xmath543 spread interval containing @xmath538 .",
    "that is , @xmath544 , and so it suffices to sample a median value from within this range .",
    "now if the distances we are concerned with are all larger than @xmath545 then we can compute a net with slightly smaller radius , say @xmath546 , to `` remove '' all smaller distances .",
    "then since we are only concerned with distances smaller than @xmath537 we can throw these points into a grid with cell diameter roughly @xmath537 , and in this grid the distances we care about will be between net points that are either in adjacent cells or within the same cell .",
    "however , since the spacing between points in the net is at least @xmath547 , there can be at most @xmath548 points per cell ( and in this paper we assume @xmath549 is a constant ) .",
    "hence computing a nearest neighbor distance for a single point to the net , if this distance is smaller than @xmath537 , takes only @xmath550 time per point .",
    "thus , it is now possible to quickly estimate @xmath84 , for a single sample point @xmath26 , and therefor we can compute the desired median .",
    "[ sec : justright ]    assume that @xmath551 ; that is , the computed value @xmath537 is way bigger than the value we are trying to compute .",
    "so , consider any point @xmath25 and look at the distance to its @xmath0thnearest neighbor , i.e. @xmath552 .",
    "now imagine placing concentric adjacent rings around @xmath26 of increasing radius , each with width @xmath553 ( the rings stop at radius @xmath552 ) . by the pigeon hole principle",
    "one of these rings must contain no points from @xmath8 .",
    "in particular , if one instead used the value @xmath554 then at least half the points of @xmath8 would have an empty ring of width @xmath554 around them , and the inner ball of the ring would contain at most @xmath0 points ( actually at most @xmath555 ) . since these rings occur before the @xmath0thnearest neighbors , the different connected components in the connectivity clustering @xmath556 containing these points have size @xmath138 ( see definition  [ def : connectivity ] @xmath557 ) .",
    "this is good news , as at least half the points are in small clusters of @xmath60 , and from lemma  [ lemma : longest : edge : partition ] these components can be computed efficiently . in particular ,",
    "if a point is in a component of size @xmath558 then its nearest neighbor can be computed in @xmath559 time by scanning its connected component in @xmath60 .",
    "since a large fraction of the points are in such components we can sample from these components , quickly compute nearest neighbors , and return the median .",
    "the problem is that these components could be too small , namely just a single point , in which case one must look outside a point s component in @xmath60 to compute its nearest neighbor .",
    "we are not stuck yet however , as thus far we have not taken into account the distribution of @xmath8 . our assumption that @xmath560 implies",
    "that at least half the points have their nearest neighbor closer than the width of the rings we considered , i.e. half the points are in non - trivial components in @xmath60 . by carefully fine - tuning the constants",
    ", one can guarantee that the set of points that are in small components that are also non - trivial components is a constant fraction of the points of @xmath8 .",
    "as such , we can find the median nearest neighbor distance for these points by random sampling , which is exactly what we needed .",
    "[ sec : toosmall ]    our purpose is to approximate @xmath561 , for some constant @xmath39 bounded away from @xmath408 and @xmath444 . to this end",
    ", we would like to sample @xmath516 values from @xmath538 and compute the median .",
    "since this is too slow , instead we sample from @xmath562 and compute the median .",
    "if the points are roughly uniformly distributed , @xmath563 $ ] and we can use nets and grids to efficiently sample distances in this bounded spread interval .",
    "otherwise a constant fraction of the points must be in small but non - trivial clusters in a connectivity clustering of the points .",
    "as such , computing nearest neighbor distances for these points can be done efficiently by scanning their respective components , thus leading to the desired middle value .",
    "[ algorithm : midnn ]    [ figure : high : prob ]      [ sec : high : prob : algorithm ]    we now present the algorithm in full detail . specifically , let denote the new algorithm for computing a value in @xmath564 $ ] , for some fixed constant @xmath565 . in section  [ sec",
    ": f : n : n ] it was shown how to convert a constant factor approximation to such a value into an exact value . hence , computing a constant factor approximation to a value in @xmath566 in linear time , with high probability , suffices for our purposes .",
    "the full algorithm is shown in figure  [ figure : high : prob ] . before analyzing the algorithm",
    ", we first define several subroutines that it employs .",
    "[ algorithm : decider : rank ]      given a point set @xmath8 and a distance @xmath9 , the decision procedure @xmath567    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } }       \\index{algorithm!deciderm@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } } } }    } } \\xspace}({\\mathsf{p } } , r , \\alpha)$ ] decides if the @xmath37thnearest neighbor distance in @xmath514 is smaller than @xmath9 , larger than @xmath9 , or roughly equal to it , where @xmath568 .",
    "this decider is implicitly described in theorem  [ theo : k : th : m : nn ] , but a simpler decider suffices , which we describe here in detail for the sake of clarity . to this end , throw the points of @xmath8 into a grid with cell diameter @xmath9 .",
    "now , for every point @xmath25 , let @xmath569 be the number of the points in @xmath56 , not including @xmath26 itself . clearly @xmath569 can be computed in constant time ( given we",
    "have first recorded the number of points in each non - empty grid cell ) .",
    "now , we compute the count @xmath570 in @xmath571 time . now , if @xmath572 the procedure returns that @xmath9 is smaller than the @xmath37thnearest - neighbor distance . similarly ,",
    "if @xmath573 , then the @xmath37thnearest - neighbor distance must be at most @xmath574 . in this case , by also computing the count for the distance @xmath574 , one will be able to either return a constant spread interval that contained the desired distance , or that this distance is strictly larger than @xmath9 . thus yielding the required decider .",
    "[ sec : estimate ]    given a set @xmath8 of @xmath7 points in @xmath14 , take two random samples from @xmath8 , a sample @xmath503 of size @xmath519 and a sample @xmath524 of size @xmath525 , and compute @xmath575 .",
    "this can be done in @xmath12 time , by scanning all of @xmath524 for each point in @xmath503 to compute the set of distances @xmath523 .",
    "next , compute value of rank @xmath576 in this set .",
    "we denote this algorithm by @xmath577    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{est{}log{}dist } } } } } }       \\index{algorithm!{est{}log{}dist}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{est{}log{}dist } } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] , and it is shown in figure  [ figure : med ] .",
    "[ algorithm : est : log : dist ]    [ figure : med ]      [ sec : logarithmicalg ]    the subroutine used by ( i.e. line  [ line : log : spread ] in figure  [ figure : high : prob ] @xmath578 ) handles the case when the desired middle nearest neighbor distance lies in a poly - logarithmic spread interval .",
    "the analysis of can be found in section  [ sec : logarithmic ] . in the following ,",
    "@xmath8 is a set of unweighted points such that @xmath579\\subseteq [ r , r]$ ] , for some values @xmath580 , where @xmath581 .",
    "( note , in the following , when sampling from a set @xmath524 we treat it as a set of @xmath582 points . )",
    "[ algorithm : spread ] [ algorithm : log : n : n ]     compute @xmath583    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({r/8 , { \\mathsf{p}}}\\right)}}$ ] .    throw the points of @xmath524 into a grid of sidelength @xmath584 .    @xmath585 random sample from @xmath524 of @xmath586 points .",
    "let @xmath587 be an approximation to the set @xmath588 .",
    "specifically , for each point @xmath589 look within @xmath590 for its nearest neighbor , see definition  [ def : grid : stuff ] @xmath591 . if such a neighbor is found record this distance ( which might be zero if @xmath26 is of weight @xmath592 ) and if no neighbor is found set this value to @xmath593 .",
    "let @xmath25 be the point that corresponds to the number of rank @xmath594 in @xmath587 .",
    "return @xmath84 .",
    "[ sec : smallalg ]    the subroutine , used by ( i.e. line  [ line : small ] in figure  [ figure : high : prob ] ) , handles the case when the desired middle nearest neighbor distance is considerably smaller than the value sampled by .",
    "this corresponds , intuitively , to the situation where the input is mainly clustered in tiny clusters .",
    "the analysis of is delegated to section  [ sec : small ] .",
    "[ algorithm : small : comp ] [ algorithm : small ] the algorithm works as follows :    computes a partition @xmath60 , such that @xmath595 in linear time , using the algorithm of lemma  [ lemma : longest : edge : partition ] @xmath596 , where @xmath597 , where @xmath598 and @xmath513 .",
    "identify the components of @xmath60 which are neither singletons nor contain more than @xmath599 points , where @xmath600 is a sufficiently large constant .",
    "collect all the points in these components into a set of points @xmath503 ( this set is not empty ) .    take a random sample @xmath601 of @xmath602 points from @xmath503 , where @xmath603 is a sufficiently large constant .",
    "for each point in @xmath601 , compute its nearest neighbor in @xmath8 by scanning the non - trivial connected component in @xmath60 that contains it .",
    "let @xmath587 be this set of numbers .",
    "return the median value in @xmath587 .",
    "[ sec : high : prob : analysis ]      the following lemma is by now standard , and we include its proof for the sake of completeness .",
    "[ lemma : high : prob ] let @xmath503 be a set of @xmath7 real numbers , constants @xmath604 , @xmath605 , and a parameter @xmath606 .",
    "let @xmath601 be a random sample of size @xmath37 picked ( with repetition and uniformly ) from @xmath503 .",
    "then , the element of rank @xmath607 in @xmath601 has rank in the interval @xmath608{0cm}{0.4cm}}\\right]}$ ] in the original set @xmath503 , with probability @xmath609 .",
    "in particular , for @xmath610 , this holds with probability @xmath611 .",
    "let @xmath612 be the number of values in @xmath601 of rank @xmath613 in @xmath503 .",
    "similarly , let @xmath614 be the number of values in @xmath601 of rank @xmath615 in @xmath503 .",
    "clearly @xmath616{0.0cm}{0.38 cm } } } \\right ] } } =      ( 1-\\delta)\\alpha t$ ] and @xmath617{0.0cm}{0.38cm}}y_r } \\right ] } } =      ( 1+\\delta)\\alpha t$ ] .",
    "observe that if @xmath618 then the element of rank @xmath607 in @xmath601 has rank in @xmath503 in the interval @xmath619{0cm}{0.4cm}}\\right]}$ ] , as desired . by the chernoff inequality @xcite",
    ", we have that @xmath620{0cm}{0.4cm}}y_l > \\alpha t } \\right ] } }         & =         { \\mathop{\\mathbf{pr}}\\!{\\left [ { y_l > \\frac { \\alpha t}{\\mu_l } \\mu_l } \\right ] } }         =          { \\mathop{\\mathbf{pr}}\\!{\\left [ { y_l > \\frac { \\alpha t}{(1 - \\delta)\\alpha t } \\mu_l } \\right ] } }         \\leq         { \\mathop{\\mathbf{pr}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}y_l > ( 1+\\delta ) \\mu_l } \\right ] } }         \\\\ &         \\leq         \\exp { \\!\\left ( { - \\frac { \\delta^2}{4 } \\mu_l } \\right ) }         \\leq         \\exp { \\!\\left ( { - \\frac { \\delta^2 } { 8 } \\alpha t } \\right ) } ,      \\end{aligned}\\ ] ] as @xmath621 . arguing as above",
    ", the other bad possibility is that @xmath620{0cm}{0.4cm}}y_r < \\alpha t } \\right ] } }         & \\leq          { \\mathop{\\mathbf{pr}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}y_r < \\frac { \\alpha t } { \\mu_r } \\mu_r } \\right ] } }         =         { \\mathop{\\mathbf{pr}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}y_r < \\frac { \\alpha t } { ( 1+\\delta)\\alpha t }             \\mu_r } \\right ] } }         \\\\ &         \\leq         { \\mathop{\\mathbf{pr}}\\!{\\left [ { { \\rule[-.2cm]{0cm}{0.4cm}}y_r < { \\!\\left({1-\\frac{\\delta}{2}}\\right ) } \\mu_r } \\right ] } }         \\leq         \\exp{\\!\\left ( { - \\frac{\\delta^2}{8}\\mu_r}\\right ) } \\leq         \\exp{\\!\\left ( { - \\frac{\\delta^2}{8}\\alpha t}\\right)}.      \\end{aligned}\\ ] ]      [ sec : est : log : dist : analysis ]    [ lemma : est : log : dist ] let @xmath8 be a set of @xmath7 points in @xmath14 . let @xmath165 be the distance returned by executing @xmath577    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{est{}log{}dist } } } } } }       \\index{algorithm!{est{}log{}dist}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{est{}log{}dist } } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] , see figure  [ figure : med ] @xmath622 . with high probability , we have the following :    for all points @xmath25 , the set @xmath623 has at most @xmath624 points , where    @xmath625 ,    @xmath524 is the random sample used by , and    @xmath626 is the ball of radius @xmath627 centered at @xmath26 .    let @xmath378 be a clustering of @xmath8 such that @xmath628 , as computed by the algorithm of lemma  [ lemma : longest : edge : partition ] @xmath596 , for @xmath629 .",
    "then , at least @xmath630 of the points of @xmath8 are in clusters of @xmath378 that contain at most @xmath1 points .",
    "@xmath631 .",
    "\\(a ) fix a point @xmath25 , and consider a ball @xmath35 centered at @xmath26 whose interior contains exactly @xmath632 points of @xmath8 .",
    "the probability that a random point from @xmath8 hits @xmath35 is @xmath633 . as such , the probability that all the points of @xmath524 miss it is at most @xmath634 , implying the claim , if @xmath635 is sufficiently large .",
    "\\(b ) by lemma  [ lemma : high : prob ] , for @xmath636 sufficiently large , we have that @xmath165 is in the range @xmath637{0cm}{0.4cm}}\\right]}$ ] , and this holds with high probability . that is , for at least @xmath630 points of @xmath8 have @xmath638 , and let @xmath23 be this set of points . for every point @xmath639",
    ", we have that the ball @xmath640 contains at most @xmath1 points of @xmath8 , by ( a ) . partitioning @xmath35 into equal radius rings of width @xmath641",
    ", one of them must be empty of points of @xmath8 .",
    "in particular , no cluster of @xmath642 can contain points on both sides of this ring , see figure on the right .",
    "as such , at least @xmath630 of the points of @xmath8 are in clusters of @xmath378 that contain at most @xmath1 points .",
    "\\(c ) follows immediately from ( b ) , as @xmath643 .",
    "[ rem : easyout ] in line  [ line : easyout ] in algorithm @xmath644    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } }       \\index{algorithm!midnn@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] we return @xmath165 as our approximate middle nearest neighbor distance if @xmath567    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } }       \\index{algorithm!deciderm@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } } } }    } } \\xspace}$ ] returned @xmath645 . by lemma  [ lemma : est : log : dist ] ( c ) we then know that @xmath646 with high probability and so @xmath165 is a valid approximation . in the unlikely event that @xmath647 , one simply runs @xmath644    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } }       \\index{algorithm!midnn@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] again .",
    "this event can be determined with the call @xmath567    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } }       \\index{algorithm!deciderm@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{deciderm } } } } } } }    } } \\xspace}({\\mathsf{p } } , { \\ell},1/8)$ ] .",
    "[ sec : logarithmic ]    during an execution of @xmath644    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } }       \\index{algorithm!midnn@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] , @xmath648    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{lowspread } } } } } }       \\index{algorithm!{lowspread}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{lowspread } } } } } } } }    } } \\xspace}({\\mathsf{p } } , r , r)$ ] gets called ( see algorithm  [ algorithm : spread ] ) only if the interval @xmath649 $ ] contains the values @xmath650 .",
    "let @xmath8 be a point set in @xmath14 of size @xmath7 .",
    "given @xmath651 , such that ( i ) @xmath652 , and ( ii ) @xmath653 $ ] , then @xmath648    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{lowspread } } } } } }       \\index{algorithm!{lowspread}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{lowspread } } } } } } } }    } } \\xspace}({\\mathsf{p } } , r ,      r)$ ] runs in @xmath12 time , and returns a value which is a @xmath75-approximation to some nearest neighbor distance @xmath654 $ ] , with high probability , for some point @xmath25 .",
    "set @xmath655 . using the notation from ,",
    "see algorithm  [ algorithm : spread ] @xmath656 , let @xmath583    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } }       \\index{algorithm!net@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{net } } } } } } }    } } \\xspace}{\\!\\left({\\delta , { \\mathsf{p}}}\\right)}}$ ] and @xmath601 the @xmath586 size sample from @xmath524 . by lemma  [ lemma :",
    "high : prob ] , with high probability @xmath657{0cm}{0.4cm}}\\right]}{\\rule[-.3cm]{0cm}{0.8cm}}$ ] , and assume that this is the case . since @xmath524 is an @xmath49-net of @xmath8 , by claim  [ claim : change ] , this changes distances by at most @xmath148 , which implies that @xmath658{0cm}{0.4cm}}\\right ] }         \\subseteq          { \\left [ { \\frac{1}{2}{{\\mathtt{d}}_{1/2}{\\!\\left({{\\mathsf{p}}}\\right ) } } , \\ , 2             { { \\mathtt{d}}_{3/4}{\\!\\left({{\\mathsf{p}}}\\right ) } } } { \\rule[-.2cm]{0cm}{0.4cm}}\\right ] }         \\subseteq { \\left [ { \\frac{r}{2 } , 2r } { \\rule[-.2cm]{0cm}{0.4cm}}\\right]}.      \\end{aligned}\\ ] ] by assumption .    in particular , this implies that all the relevant distances from the computation of this median value are in the range @xmath659 $ ] . as such , when computing the median it is allowable to not compute precisely values outside this interval , as done by the algorithm",
    "this implies that indeed returns the value @xmath660 , which is the desired approximation .    as for the running time , observe that @xmath524 is an @xmath49-net , and an open ball with this radius around any point must be empty of any other net point . in particular ,",
    "for any point @xmath661 , the maximum number of other points that can be in @xmath590 is @xmath662 .",
    "therefore , for a point @xmath589 , computing @xmath663 takes polylogarithmic time ( using linear time preprocessing and a grid ) .",
    "thus , overall , computing the set of distances @xmath664 takes polylogarithmic time , since @xmath665 .",
    "hence , the overall running time is @xmath666 .      [",
    "sec : small ]    the call to @xmath667    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{smallcomp } } } } } }       \\index{algorithm!{smallcomp}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{smallcomp } } } } } } } }    } } \\xspace}({\\ell } , { \\mathsf{p}})$ ] by computes a point @xmath25 , such that @xmath668{0cm}{0.4cm}}\\right]}$ ] .",
    "the procedure succeeds and its running time is @xmath12 , with high probability , where @xmath513 .    computing the components of @xmath60 takes linear time , and given @xmath60 , computing @xmath503 takes linear time . for each point in the sample @xmath601 , it takes @xmath669 time to compute its nearest neighbor since one only has to scan the point s @xmath670 sized connected component in @xmath60 . since @xmath671",
    ", computing the nearest neighbor distances and taking the median takes polylogarithmic time overall .",
    "now , @xmath667    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{{smallcomp } } } } } }       \\index{algorithm!{smallcomp}@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{{smallcomp } } } } } } } }    } } \\xspace}({\\ell } , { \\mathsf{p}})$ ] is called by only if the following conditions holds :    @xmath672 .",
    "namely , at least half of the points of @xmath8 have their nearest neighbor in their own cluster in @xmath673 , where @xmath674 .",
    "let @xmath675 be the set of these points .",
    "let @xmath378 be the partition of @xmath8 computed by .",
    "we have that @xmath676 . by lemma",
    "[ lemma : est : log : dist ] ( b ) , at least @xmath677 of the points of @xmath8 are in clusters of @xmath378 that contain at most @xmath1 points ( note , that some of these points might be a cluster containing only a single point ) .",
    "let @xmath678 be the set of these points .    as such , @xmath679 .",
    "namely , at least @xmath680 of the points of @xmath8 , are in small clusters and these clusters have strictly more than one point .",
    "furthermore , @xmath681 , and we conclude that @xmath682 .",
    "now , by lemma  [ lemma : high : prob ] , with high probability , the returned value is in the range @xmath683 , which implies that the returned value is in the range @xmath684 , as desired .",
    "the analysis in the previous section implies the following .",
    "[ lemma : high : prob : summary ] given a set @xmath63 of @xmath7 points , @xmath644    { { { \\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } }       \\index{algorithm!midnn@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{midnn } } } } } } }    } } \\xspace}({\\mathsf{p}})$ ] computes , a value @xmath393 , such that there is a value of @xmath685 in the interval @xmath686 $ ] , where @xmath96 is a constant .",
    "the running time bound holds with high probability .    as shown in section  [ sec",
    ": f : n : n ] , given a constant factor approximation to some nearest neighbor distance , we can compute the corresponding nearest neighbor distance exactly in linear time using a grid computation .",
    "let denote the algorithm that performs this additional linear time step after running . as argued above , replacing line  [ line : gen : random ] and line  [ line : rad ] in figure  [ figure : a : algorithm ] @xmath196 with `` @xmath687{redviolet}{\\texttt{\\bf{midnnexact}}}}}\\index{algorithm!midnnexact@{{{\\textcolor[named]{redviolet}{\\texttt{\\bf{midnnexact}}}}}}}}}\\xspace } ( { \\mathsf{p}}_{i-1 } ) $ ] '' , turns into an algorithm that runs in linear time with high probability .",
    "we thus have the following analogue of theorem  [ theo : result : eps ] .    for a constant @xmath688 , given an instance of a @xmath116-defined by a set of @xmath7 points in @xmath14 , with a @xmath116-decider with ( deterministic or high - probability ) running time @xmath12",
    ", one can get a @xmath116-approximation to its optimal value , in @xmath689 time , with high probability .",
    "similarly , for @xmath690 , given an instance of a @xmath691-defined by a set of @xmath7 points in @xmath14 , with a @xmath4-decider having ( deterministic , or high probability ) running time @xmath125 , then one can @xmath4-approximate the optimal value for this , in @xmath125 time , with high probability .",
    "all the applications of section  [ sec : applications ] can be modified so that their running time bound holds not only in expectation , but also with high probability .",
    "note , that the above high probability guarantee is in the size of the input . as such , in later iterations of the algorithm ,",
    "when the input size of the subproblem is no longer polynomial in @xmath7 ( say , the subproblem size is @xmath550 ) , the high probability guarantee is no longer meaningful .    fortunately , this is a minor technicality  once the subproblem size drops below @xmath692 , the remaining running time of is @xmath12 , with high probability .",
    "this follows by a simple direct argument  by the chernoff inequality , after @xmath693 iterations , with high probability at least @xmath694 iterations are successful , see the proof of lemma  [ lemma : time ] for details . after this number of successful iterations",
    ", the algorithm terminates .",
    "this implies that the remaining running time is @xmath12 , with high probability , once the subproblem size is @xmath695 .    as such",
    ", our new high - probability algorithm is needed only in the initial `` heavy '' iterations of the algorithm , until the subproblem size drops below @xmath695 .",
    "[ sec : conclusions ]    there is still a lot of further research to be done in investigating this technique .",
    "for example , looking into the implementation of this new algorithm in both standard settings and distributed settings ( e.g. , mapreduce ) . additionally , since now one can do approximate distance selection in linear time , maybe now one can get a speed up for other algorithms that do ( not necessarily point based ) distance selection .",
    "our framework provides a new way of looking at distance based optimization problems , in particular through the lens of nets .",
    "we know how to compute nets efficiently for doubling metrics and it seems one can compute approximate nets in near linear time for planar graphs .",
    "for example , it seems the new technique implies that approximate @xmath0-center clustering in planar graphs can be done in near linear time .",
    "this provides fertile ground for future research .",
    "another interesting open problem arising out of the high probability linear time algorithm is the following : given sets @xmath8 and @xmath503 in @xmath14 , of size @xmath7 and @xmath696 , respectively , how long does it take to approximate the values in the set @xmath501 ( i.e. , for each point of @xmath503 we approximate its nearest - neighbor in @xmath8 ) .",
    "this problem can be easily solved in @xmath32 time .",
    "the open question is whether it is possible solve this problem in linear time .",
    "the algorithm in this paper implies that we can compute exactly a value ( of a specified rank ) in this set in @xmath12 time ( even if @xmath697 is of size @xmath7 ) .",
    "we currently have an algorithm with running time @xmath698 for approximating @xmath501 .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] , http://www.uiuc.edu/~sariel[s .",
    "har - peled ] , and http://www.cs.uiowa.edu/~kvaradar/[k .",
    "r. varadarajan ] . http://cs.uiuc.edu/~sariel/papers/01/fitting/[approximating extent measures of points ] . , 51(4):606635 , 2004 .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] , http://www.uiuc.edu/~sariel[s .",
    "har - peled ] , and k.  varadarajan .",
    "geometric approximation via coresets . in j.",
    "e. goodman , http://www.math.nyu.edu/~pach[j .",
    "pach ] , and e.  welzl , editors , _ combinatorial and computational geometry _ , math .",
    "research inst . pub .",
    "cambridge , 2005 .",
    "http://compgeom.cs.uiuc.edu/~jeffe/[j .",
    "erickson ] .",
    "http://compgeom.cs.uiuc.edu/~jeffe/pubs/relative.html[on the relative complexities of some geometric problems ] . in _ proc",
    "7th canad .",
    "_ _ _ , pages 8590 , 1995 .",
    "http://www.uiuc.edu/~sariel[s .",
    "har - peled ] and a.  kushal .",
    "coresets for @xmath0-median and @xmath0-means clustering ] . in _ proc .",
    "21st annu .",
    "_ _ _ , pages 126134 , 2005 .",
    "http://www.uiuc.edu/~sariel[s .",
    "har - peled ] and s.  mazumdar .",
    "http://cs.uiuc.edu/~sariel/research/papers/03/kcoreset/[coresets for @xmath0-means and @xmath0-median clustering and their applications ] . in _ proc .",
    "36th annu .",
    "acm sympos .",
    "theory comput .",
    "_ _ _ , pages 291300 , 2004 .",
    "http://www.uiuc.edu/~sariel[s .",
    "har - peled ] and b.  raichel . the frchet distance revisited and extended . in _ proc .",
    "27th annu .",
    "_ _ _ , pages 448457 , 2011 .",
    "/ papers/10/frechet3d/.      http://www.uiuc.edu/~sariel[s .",
    "har - peled ] and b.  raichel . http://cs.uiuc.edu/~sariel/papers/12/aggregate/[net and prune : a linear time algorithm for euclidean distance problems ] . in _ proc .",
    "45th annu .",
    "acm sympos .",
    "theory comput .",
    "_ _ _ , pages 605614 , 2013 .",
    "r.  krauthgamer and j.  r. lee .",
    "navigating nets : simple algorithms for proximity search . in _ proc .",
    "15th acm - siam sympos . discrete algs .",
    "_ _ _ , pages 798807 . society for industrial and applied mathematics , 2004 .",
    "j.  salowe .",
    "parametric search . in j.",
    "e. goodman and http://cs.smith.edu/~orourke/[j .",
    "orourke ] , editors , _ handbook of discrete and computational geometry _ , chapter  37 , pages 683698 .",
    "crc press llc , boca raton , fl , 1997 .",
    "http://www.math.tau.ac.il/~michas[m .",
    "sharir ] and e.  welzl .",
    "a combinatorial bound for linear programming and related problems . in _ proc .",
    "9th sympos .",
    "aspects comput .",
    "volume 577 of _ lect .",
    "notes in comp .",
    "_ , pages 569579 .",
    "springer - verlag , 1992 ."
  ],
  "abstract_text": [
    "<S> we provide a general framework for getting expected linear time constant factor approximations ( and in many cases s ) to several well known problems in computational geometry , such as @xmath0-center clustering and farthest nearest neighbor . </S>",
    "<S> the new approach is robust to variations in the input problem , and yet it is simple , elegant and practical . in particular , many of these well studied problems which fit easily into our framework , either previously had no linear time approximation algorithm , or required rather involved algorithms and analysis . </S>",
    "<S> a short list of the problems we consider include farthest nearest neighbor , @xmath0-center clustering , smallest disk enclosing @xmath0 points , @xmath0thlargest distance , @xmath0thsmallest @xmath1-nearest neighbor distance , @xmath0th heaviest edge in the @xmath2and other spanning forest type problems , problems involving upward closed set systems , and more . </S>",
    "<S> finally , we show how to extend our framework such that the linear running time bound holds with high probability .    </S>",
    "<S> net and prune : a linear time algorithm for euclidean distance problems    work on this paper was partially supported by nsf af awards ccf-0915984 and ccf-1217462 . </S>",
    "<S> the full updated version of this paper is available online @xcite . a preliminary version of this paper appeared in stoc 2012 @xcite .    </S>",
    "<S> this work is supported by the national science foundation , under    author s addresses : s. har - peled , department of computer science ; university of illinois ; 201 n. goodwin avenue ; urbana , il , 61801 , usa ; ; http://illinois.edu/\\string~sariel . b. raichel , department of computer science ; university of illinois ; 201 n. goodwin avenue ; urbana , il , 61801 , usa ; 2uiuc.edu ; http://illinois.edu/\\string~raichel2 . </S>"
  ]
}