{
  "article_text": [
    "the problem of recognizing acoustic environments is known as the problem of audio scene classification and it is one of the most difficult task in the general context of computational auditory scene analysis ( casa ) @xcite .",
    "this classification task is of primary importance in the domain of machine listening since it is strongly related to the context in which the acquisition device capturing the audio scene lives .",
    "typically , in order to get some context awareness , a machine , say a smart - phone or any mobile electronic device , should be able to predict the environment in which it currently resides .",
    "the main goal is to help the machine adapting itself to the context of the user ( for instance by automatically turning off the ring tone in some situations ) .",
    "such awareness can be brought through vision or audio scene analysis .",
    "while most of the efforts have focused on vision , there is now a growing interest of environment recognition based on audio modality .",
    "audio scene classification is a very complex problem since a recording related to a given location can be potentially composed of a very large amount of single sound events while only few of these events provide some information on the scene of the recording .",
    "more specifically , an audio scene is associated to a recording taken at a given location and this location is expected to generate some acoustic events that make it distinguishable from other audio scenes .",
    "these discriminative acoustic events may be produced by different phenomena and they may have a very large variability .",
    "hence , the recent works on audio scene classification have devoted much efforts on designing methods and algorithms for automatically extracting audio features that capture the specificities of these events .",
    "the natural hope is that the designed features are still able to capture the discriminative power of a given audio event .",
    "for instance , following its success in speech recognition , one of the most prominent features that has been considered for audio scene recognition are mel - frequency cepstral coefficients ( mfcc ) @xcite .",
    "these features are typically used in conjunction with different machine learning techniques in order to capture the variations that help in discriminating scenes .",
    "for instance , @xcite consider a gaussian mixture model for estimating the distribution of the mfcc coefficients , while @xcite have proposed a sparse feature learning approach for capturing relevant mfcc coefficients .",
    "in addition to mfcc , several kinds of features have also been evaluated for solving this problem of audio scene recognition .",
    "@xcite proposed an ensemble of time - frequency features obtained from a matching pursuit decomposition of the audio signal .",
    "recently , @xcite have considered a large set of features , including spectral , energy - based and voicing - related features .",
    "another family of relevant features can be obtained from mfcc by considering recursive quantitative analyzing ( rqa ) as introduced by @xcite .",
    "rqa has the advantage to allow the analysis of recurrent behaviour in the mfcc coefficients over time .",
    "according to the recent d - case challenge on audio scene recognition @xcite , combining mfcc features with rqa features extracted from mfcc yield to an highly efficient set of features .",
    "another trend aims at building higher - level features from the time - frequency representations of the audio scene . in this context , @xcite have investigated methods for automatically extracting spatio - temporal patches that are discriminative of the audio scene . typically , these patches are obtained through a non - negative matrix factorization of a time - frequency representation . @xcite",
    "have followed similar ideas but instead of considering nmf they employed a probabilistic model denoted as probabilistic latent component analysis . likewise , other works propose features , like texture - based features that are directly computed from time - frequency representations @xcite .    in this paper , we follow this trend and propose a novel feature for automatic recognition of audio scene .",
    "the main originality of the proposed feature is the use of histogram of gradients ( hog ) on time - frequency representations .",
    "these hog features have been genuinely introduced for human detection in images @xcite but we strongly believe that their properties make them highly valuable for extracting relevant features based on time - frequency representation ( tfr ) . indeed ,",
    "while mfcc can also be considered as features extracted from a time - frequency ( tf ) representation , they essentially capture non - linear information on the power spectrum of the signal .",
    "instead , histogram of gradients of a tf representation provides information on the spectral power direction of variation .",
    "for instance , if an audio scene has been obtained in a bus that it is accelerating or decelerating , we expect the _ chirp _ effect present in the tfr to be captured and better discriminated by the histogram of gradients representation , than by mfcc .",
    "this property will be empirically illustrated in the sequel and it provides rationale that for audio scene recognition the novel feature we present is strongly relevant .",
    "algorithms for audio scene recognition have to be validated and evaluated on some datasets . in order to make comparisons of different designs of features including signal processing set - ups or different learning techniques possible",
    ", these datasets should be publicly available .",
    "the recent d - case challenge @xcite is an excellent initiative of this kind although its number of examples is limited ( @xmath2 for the publicly available examples ) .",
    "hence , another contribution we present is a new dataset for audio scene recognition .",
    "it is based on about @xmath1 minutes of recording on different locations ( up to @xmath0 ) .",
    "this dataset is publicly available and we expect that it will become one of the standard benchmarks for audio scene recognition .    the paper is organized as follows : we first describe the pipeline we propose for extracting our novel hog - based feature . then , as one of our contribution is also to introduce a novel benchmark dataset , we carefully detail all the datasets we considered for evaluating our feature and its competitors as well as the experimental protocol we employed for the comparisons .",
    "extensive experimental analyses have been carried out and they show that our hog - based feature achieves state - of - the - art performances on all datasets . as we advocate result reproducibility ,",
    "all the codes used for this work will be made publicly available on the author s website .",
    "this section describes the feature extraction pipeline we propose for analyzing audio scene signals .",
    "we first provide the big picture before detailing each part of the flowchart .",
    "the features we propose for recognizing audio scenes are based on some specific information extracted from a time - frequency representation ( tfr ) of the signal .",
    "after the tfr image has been computed , it is processed so as to attenuate some spurious noises that may hinder relevant information related to high - energy time - frequency structures .",
    "afterwards , the resulting processed time - frequency representation image is used as input of our histogram of gradients feature extraction . in a nutshell ,",
    "the idea of histogram of gradients is to locally analyze the direction of energy s variation in the time - frequency representation . as detailed in the sequel ,",
    "the local hog informations over the whole tf image are combined in order to generate the final feature vector .",
    "the dimension of this vector depends on the number of bin in the ( local ) histogram and on how all the local histograms are pooled together in order to form the final feature vector .",
    "the block diagram of this feature extraction scheme is illustrated in figure [ fig : block ] .",
    "each block of this diagram is discussed in the next paragraphs .",
    "= [ draw= colorsubsection , drop shadow , line width= 0.05 cm , rectangle , minimum height=2.5em , minimum width=10em , rounded corners , top color= white , bottom color = chaptercolortwo!20 ] = [ draw= colorsubsection , line width= 0.05 cm , drop shadow , rectangle , minimum height=2em , minimum width=8em , rounded corners , top color= white , bottom color = chaptercolortwo!20 ] = [ draw= red!50!black!50 , line width= 0.05 cm , drop shadow , rectangle , minimum height=2em , minimum width=8em , rounded corners , top color= white , bottom color = red!50!black!20 ]    ( sig ) audio signal ; ( cqt )    constant - q transform    ; ( sig )  ( cqt ) ; ( filter )    cqt image processing    ; ( cqt ) ",
    "( filter ) ; ( hog )    hog representation    ; ( filter )  ( hog ) ; ( pool )    pooling    ; ( hog )  ( pool ) ; ( features )    features    ; ( pool )  ( features ) ;      because of their non - stationary nature , sounds are typically represented on a short - time power frequency representation , which idea is to capture the power spectrum of the signal on a varying short local window .",
    "a large part of the literature on sound recognitizion problems use such time - frequency representations of sound . depending on the task at hand , they either consider wavelet - based @xcite , mfcc - based @xcite or short - time fourier - based representations @xcite . in this work , we do not depart from this widely adopted framework and choose to represent the signal according to a constant - q transform @xcite .",
    "contrarily to a short - time fourier transform , this transform provides a frequency analysis on a log - scale which makes it more adapted to sound and music representations @xcite .",
    "once this tfr has been computed , we now have an image that can be processed as such .",
    "in order to obtain a processing system independent of the signal length and sampling frequency , as well as the cqt parameters , we have chosen to resize all tfrs to a @xmath3 image .",
    "this resizing is performed on the cqt matrix by means of a bicubic interpolation .",
    "hence , the image we obtain is not exactly equivalent to a cqt with a total of @xmath4 frequency bins but it preserves the time - frequency structures of the audio scene as one can see in figure [ fig : toychirp ] .",
    "then , depending on the tfr images , some image processing tools can be used so as to enhance relevant time - frequency structures . in our work , because we have few prior knowledge on the signal noise , we have just applied a mean filtering so as to smooth the tfr image . our goal with this smoothing is to reduce strong local variations in the image that will tend to produce high gradients , which may be not relevant for audio scene recognition .",
    "the size of the average kernel for mean filtering can be considered then as an hyperparameter of the feature extraction scheme and its influence will be investigated in the experimental analysis .",
    "histogram of gradients have been originally introduced by @xcite for human detection in images .",
    "our main objective in this feature extraction stage is to capture the shape of some time - frequency structures in the hope that such structures are relevant for characterizing an audio scene . from works in computer vision @xcite ,",
    "it is now well acknowledged that local shape information can be described through gradient intensity and orientations .",
    "histograms of gradients basically provide information about the occurrence of gradient orientations in a localized region of the images . hence , they are able to characterize shapes in that regions .",
    "two main approaches have been proposed for computing hog in images @xcite and they are both based on the following steps :    1 .",
    "compute the gradient of the tf image 2 .   compute angles of all pixel gradients 3 .",
    "split images into non - overlapping cells 4 .",
    "count the occurrence of gradient orientations in a given cell 5 .",
    "eventually normalize each cell histogram according to histogram norm of neighboring cells .",
    "variants on this theme are essentially based on whether the gradient orientations are bidirectional or not , whether the magnitude of the gradient is taken into account in the counting and on how normalization factors are computed within block of neighboring cells . for this work",
    ", we have used the implementation in the _ vlfeat _ toolbox @xcite .",
    "_ vlfeat _ is an open - source computer vision toolbox that includes the major functionalities of the most popular computer vision and pattern recognition algorithms . in particular ,",
    "it implements several histogram - based feature extraction algorithms including sift @xcite and hog . for more details , we refer the reader to @xcite and @xcite and to the _ vlfeat _ hog tutorial .    as an illustration",
    ", we depict in figure [ fig : toychirp ] the @xmath3 mean filtered image of a linear chirp s cqt transform , as well as the resulting histogram of gradients we obtain for each @xmath5 cell with @xmath6 gradient orientations . from the right panel , we remark that the hog representation properly captures the directions of power spectrum s variation along the high - energy chirp signal .",
    "however , we can also note that several spurious cells depict non - zero histogram of gradients ( top and right bottom parts of the image ) .",
    "they are essentially due to presence of small variations of gradient in low - energy time - frequency structure in the cq transform , inducing non - zero gradients .",
    "however , these noisy cells can be easily recognized as having an almost flat histogram , denoting thus the presence of multiple orientations of gradient in the cells .",
    "note that in our feature extraction scheme , we have not considered any pre - processing and post - processing strategies for handling these spurious cells , they are taken into account as they are into the hog features .    after having computed the histogram of gradients in the images , we are left with a representation composed of histograms in all cells .",
    "if we concatenate all these histograms for yielding the final feature vector , we obtain a vector whose dimension is large ( number of cells @xmath7 number of orientations in the histogram ) . in the example in figure [ fig : toychirp ] , cells are sized @xmath8 pixels , this results in vector of dimension @xmath9 , @xmath10 being the total number of cells .",
    "of course , this dimensionality may further increase if we choose to reduce cell s size or increase the number of orientations in the histogram computation . depending on the number of audio scene examples ,",
    "it thus may be beneficial to reduce the dimensionality of the problem for instance by pooling the histograms of gradients .",
    "pooling consists in combining the responses of a feature extraction algorithm computed at nearby locations .",
    "the underlying idea is to summarize local features into another feature ( of lower dimensionality ) that is expected to keep relevant information over the neighborhood .",
    "the pooling helps in getting a more robust information .",
    "this technique is a step commonly considered with success in modern visual recognition algorithms @xcite . in our case",
    ", pooling histograms over neighboring cells aims at building new histograms that capture information on time - frequency structures which may be larger than a cell or that have been slightly translated in time or frequency . in this work",
    ", we will investigate several forms of time - frequency region pooling ( see figure [ fig : pooling ] ) , while the pooling operation will be kept fixed as an averaging operator .",
    "we will consider the following poolings :    * marginalized pooling over time : for this pooling , we average all histograms along the time axis of the tfr representation .",
    "this results in a feature vector which has lost all temporal information .",
    "* marginalized pooling over frequency : in this case , the averaging is performed over the frequency axis .",
    "hence , all frequency informations of the hog are now merged into a single one . * block - size pooling : pooling is performed on nearby cells with the size of the neighorhood being user - defined .    the vector resulting from the concatenation of the pooled histograms forms now the feature vector that will be used for learning the audio scene classifier .",
    "now that we have explained how the hog on time - frequency representation feature is obtained , we want to discuss some properties of these hog features and their advantages over features like mfcc for audio scene characterization .",
    "our initial objective was to design features that is able to characterize some time - frequency structures that occur in a time - frequency representation . by construction , since we bin the orientations when counting a given gradient , the histogram of gradients is invariant to rotation if this rotation is smaller than the bin size . in our case",
    ", rotation would correspond to a small rotation of a time - frequency structure leading then to a change of orientation of its gradients .",
    "such a situation may occur for instance in audio scenes capturing a moving object , like a bus or a car .",
    "indeed , variations of a bus s acceleration induce variations of steepness in the time - frequency structure related to the sound of that bus . owing to the binning of the gradient orientation",
    ", the hog feature will be invariant to these variations .",
    "furthermore , as we build an histogram from a cell of pixels and then average them over a larger region , our pooled histogram of gradient is invariant to translation over that region of pooling .    compared to classical features like mfcc used for audio applications , hog - based features present several benefits .",
    "for instance , they are , by construction , invariant to small time and frequency translations .",
    "but most interestingly , they bring information that are not provided by other power - spectrum based features , namely local direction of variation of power spectrum . as an illustration of this point",
    ", we will compare the features obtained , by mfcc and the hog - based approach on two linear chirps , one with increasing frequency and the other one with a decreasing frequency , but both covering the same frequency range .",
    "our experimental results will show that bag of sole mfcc will fail in fully capturing the discriminative information brought by these signals at the contrary of the features we propose .",
    "we provide in this section some details about the datasets we have considered for evaluating the feature we propose . description of the classifier we used as well as the experimental protocol are also given .",
    "resizing and a @xmath11 average filtering.,title=\"fig:\",width=226 ]   +    resizing and a @xmath11 average filtering.,title=\"fig:\",width=226 ]     for evaluating our features , we have created a toy problem which highlights the ability or the failure of studied features ( including hog and competitors ) in capturing power spectrum s direction of variation . as such , we have created a binary classification problem where signals from each class are composed of a localized linear chirp , respectively of increasing and decreasing frequency , defined as @xmath12}(t ) \\cos\\big(2 \\pi ( a t + b ) t \\big ) + n(t)\\ ] ] with @xmath13 $ ] and @xmath14 is a centered gaussian noise of standard deviation @xmath15 , @xmath16 , @xmath17 for the class @xmath18 , @xmath19 , @xmath20 for the class @xmath21 and @xmath22}(t)$ ] a function which value is @xmath23 when @xmath24 and @xmath25 otherwise .",
    "we have set @xmath26 and @xmath27 .",
    "figure [ fig : locchirp ] depicts the cq transform of representative samples of both classes .",
    "one can notice the localized spectral contents of the chirps .      for the purpose of a challenge ,",
    "a dataset providing environmental sound recordings has been recently released by @xcite .",
    "each example in the dataset consists of a @xmath28-second audio scene , which has been captured at one of the @xmath29 following locations  : _ bus , busy street , office , open air market , park , quiet street , restaurant , supermarket , tube , tubestation_. recording has occurred at a rate of @xmath30 khz and the number of examples available is @xmath2 with @xmath29 examples per class .",
    "note that , the challenge s organisers have only made available the development dataset      this dataset ] has been collected in the early @xmath31 by ma et al .",
    "@xcite at the east anglia university .",
    "it provides environmental sounds coming from @xmath29 different locations : _ bar , beach , bus , car , football match , laundrette , lecture , office , railstation and street . _",
    "the length of each recording is @xmath32 minutes and it has been recorded at a frequency of @xmath33 hz .",
    "similarly to the _ d - case _ dataset , we have split the recording in @xmath28-second audio scene examples .",
    "hence , we have only @xmath6 examples per class for this dataset .",
    "this dataset we make publicly available goes beyond the above ones in terms of volume and number of locations .",
    "recordings have been performed using a galaxy s3 smartphone equipped with android by means of the _ hi - q mp3 recorder _ application .",
    "while such an equipment may be considered as poor , we believe that the resulting recordings would be similar to those obtained for real applications where cheap and ubiquitous microphones are more likely to be used .",
    "the sampling frequency we have used is @xmath34 hz and the recording is saved as a mp3 file with a bitrate of @xmath35 kbps .",
    "when transformed into raw audio signals , they have been downsampled to @xmath36 hz .",
    "overall , about @xmath1 minutes of audio scene have been recorded .",
    "they took place from december 2012 to june 2014 . for a given class ,",
    "recordings occured at several days of that period .",
    "the dataset is composed of @xmath0 classes and audio scenes forming a given class have been recorded at different locations .",
    "note that in order to reduce temporal dependencies in our dataset , recordings usually last @xmath23 minute but in some locations , their durations can reach up to @xmath29 minutes . again in order to be consistent with the _ d - case _ challenge , each example is composed of a @xmath28-second audio scene .",
    "the 30-sec examples have been obtained by splitting a given signal into 30-second segments without overlapping .",
    "a summary of the dataset is given in table [ tab : rouen ] and figure [ fig : cqtrouen ] presents some samples of cqt for @xmath37 different audio scenes .",
    "the plots in this figure show typical characteristics of an audio scene of the class .",
    "for instance , in the _ bus _ s cqt , we can note the low - frequency line related to the bus s acceleration and deceleration . in the _ kid game hall _",
    "scene , we see some high - frequency structures induced by kid screams .",
    ".summary of the litis rouen audio scene dataset [ cols=\"<,^\",options=\"header \" , ]     [ tab : confmatrirouen ]    as one of our main contribution in this paper is to introduce a novel audio scene dataset , we discuss in the sequel our findings regarding this dataset .    in table",
    "[ tab : block ] , we have shown that mean average precision , obtained as an average over @xmath38 trials , is @xmath39 .",
    "table [ tab : confmatrirouen ] presents the normalized sum of all confusion matrices obtained from these @xmath38 training / test splits .",
    "they have been obtained using the best performing hog feature  : namely the one with signed and unsigned orientations , without normalization factors of the histograms and fully pooled over time , the hog being obtained with cell size of @xmath6 , @xmath6 bins of the orientations and no average filtering .",
    "the average precision obtained from this matrix is @xmath40 and it is different to the mean average precision over the @xmath38 runs as presented in table [ tab : block ] .    from table [ tab : confmatrirouen ] , we can first note a group of conveyances _ plane _ , _ bus _ , _ car _ , _ train _ and _ high - speed train _ that are precisely recognized ( with precisions above @xmath4130@xmath4260@xmath43240@xmath4496classes are _ kid game hall _ and _ billiard pool hall_. figure  [ fig : babbleshort ] shows examples of cqt and hog representation of these audio scenes . in these plots , the short time - frequency structures appearing around @xmath31 hz correspond to shouts and impacting balls .",
    "+  ( bus )   +           +  ( car )   +          +  ( plane )              +  ( kid game hall )   +           +  ( billiard pool hall )   +             +  ( train station hall )   +           +  ( pedestrian street )   +    we can also notice a group of scenes that seems difficult to distinguish as seen in fig .",
    "[ fig : walkingpeople ] : the ones in which some people are walking , namely _ pedestrian street _ , _ market _ , _ train station hall _ , _ quiet street _ and _",
    "shop_. these confusions are easily understandable .",
    "for instance , the main difference between a quiet street and pedestrian street would be the number of people walking in the scene .",
    "such a difference is hardly taken into account by our hog feature .    despite the good skills exhibited by the proposed hog features ,",
    "the latter remarks show that there are still rooms for improvement , by addressing the issues raised by classes that are mixed .",
    "we believe that these classes show the needs for features ( that can still be based on hog ) capturing discriminative short - time events that come in complement to our `` global '' features .",
    "the problem of classifying audio scene is currently a hot topic in the computational auditory scene analysis domain . for this specific problem ,",
    "we have introduced in this paper a novel feature that seems to be very promising at capturing relevant discriminative informations .",
    "the main block of the feature we proposed has been initially proposed in the computer vision domain , namely histogram of gradients .",
    "our novel feature has been obtained by computing histogram of gradients of a constant q - transform followed by an appropriate pooling .",
    "we have experimentally proved that these histograms of gradients were useful for capturing specific characteristics present in a time - frequency representation that classical features such as mfcc can not encode namely the local variation of power spectrum .",
    "then , our experimental results on real datasets clearly show that our features achieve state - of - the - art classification performances on several datasets .",
    "while our hog - based feature is globally efficient , the overall pipeline for audio scene classification still lacks in discriminating some difficult classes . in order to further improve the scheme ,",
    "some efforts are still needed .",
    "our future researches focus on improving discriminative ability of hog - based feature by working on the pooling strategy . the supervised learning paradigm may also be improved by taking into account an hierarchical taxonomy of the classes .",
    "we plan to investigate this taxonomy by learning it directly from the data .",
    "j.  aucouturier , b.  defreville , and f.  pachet , `` the bag - of - frame approach to audio pattern recognition : a sufficient model for urban soundscapes but not for polyphonic music , '' _ journal of the acoustical society of america _ , vol .",
    "122 , no .  2 ,",
    "pp . 881891 , 2007 .",
    "hu , w.  liu , and w.  jiang , `` combining frame and segment based models for environmental sound classification , '' in _ proceedings of 13th annual conference of the international speech communication association _ , 2012 .",
    "k.  lee , z.  hyung , and j.  nam , `` acoustic scene classification using sparse feature learning and event based pooling , '' in _ ieee workshop on applications of signal processing to audio and acoustics _ , 2013 .",
    "j.  geiger , b.  schuller , and g.  rigoll , `` large - scale audio feature extraction and svm for acoustic scene classification , '' in _ ieee workshop on applications of signal processing to audio and acoustics _",
    ", 2013 .",
    "g.  roma , w.  nogueira , and p.  herrera , `` recurrence quantification analysis features for environmental sound recognition , '' in _ ieee workshop on applications of signal processing to audio and acoustics _ , 2013 .",
    "d.  giannoulis , e.  benetos , d.  stowell , m.  rossignol , and m.  lagrange , `` detection and classification of acoustic scenes and events : an ieee aasp challenge , '' in _ ieee workshop on applications of signal processing to audio and acoustics _ , 2013 .",
    "e.  benetos , m.  lagrange , and s.  dixon , `` characterisation of acoustic scenes using a temporally - constrained shift - invariant model , '' in _ proceedings of the fifteenth international conference on digital audio effects _ , 2012 .",
    "j.  dennis , h.  tran , and e.  chng , `` image feature representation of the subband power distribution for robust sound event classification , '' _ ieee trans on audio , speech and language processing _ ,",
    "21 , no .  2 ,",
    "pp . 367377 , 2013 .",
    "n.  dalal and b.  triggs , `` histograms of oriented gradients for human detection , '' in _ computer vision and pattern recognition , 2005 .",
    "cvpr 2005 .",
    "ieee computer society conference on _ , vol .",
    "1.1em plus 0.5em minus 0.4emieee , 2005 , pp . 886893 .",
    "j.  cheng , y.  sun , and l.  ji , `` a call - independent and automatic acoustic system for the individual recognition of animals : a novel model using four passerines , '' _ pattern reco _ , vol .",
    "43 , no .  11 , pp . 38463852 , 2010 .",
    "p.  felzenszwalb , r.  grishick , d.  mcallester , and d.  ramanan , `` object detection with discriminatively trained part based models , '' _ ieee trans . on pattern analysis and machine",
    "intelligence _ ,",
    "32 , no .",
    "16271645 , 2010 ."
  ],
  "abstract_text": [
    "<S> this paper addresses the problem of audio scenes classification and contributes to the state of the art by proposing a novel feature . </S>",
    "<S> we build this feature by considering histogram of gradients ( hog ) of an audio scene time - frequency representation . </S>",
    "<S> contrarily to classical audio features like mfcc , we make the hypothesis that histograms of gradients are able to encode some relevant informations in a time - frequency representation : namely , the local direction of variation ( in time and frequency ) of the signal spectral power . </S>",
    "<S> in addition , in order to gain more invariance and robustness , histograms of gradients are locally pooled . </S>",
    "<S> we have evaluated the relevance of the novel feature by comparing its performances with state - of - the - art competitors , on several datasets , including a novel one that we provide , as part of our contribution . </S>",
    "<S> this dataset , that we make publicly available , involves @xmath0 classes and contains about @xmath1 minutes of audio scene recordings . </S>",
    "<S> we thus believe that it may be the next standard dataset for evaluating audio scene classification algorithms . </S>",
    "<S> our comparison results clearly show that the hog - based features outperform its competitors .    </S>",
    "<S> histogram of gradients ; time - frequency representation ; audio scene ; mfcc ; support vector machines </S>"
  ]
}