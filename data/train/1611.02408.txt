{
  "article_text": [
    "the standard variant of model predictive control ( mpc )  @xcite relies on the principle of _ certainty equivalence _ : at every sampling time a nominal control performance objective is optimized subject to dynamic model equations as well as control and state constraints over a finite prediction horizon under the assumption that there are neither state estimation errors , nor external disturbances , nor any kind of model plant mismatches present , although all these errors and disturbances are the reason why a feedback controller is needed in the first place .",
    "after the mpc controller sends its first control input to the real process , the next optimization problem is solved by using the latest state estimate in order to close the loop .",
    "the success of such certainty equivalent model predictive controllers , also in industrial applications  @xcite , is to a large part due to the availability of fast and reliable real - time optimal control problem solvers  @xcite . during the last years algorithms as well as mature automatic code generation based software",
    "have been developed , which can solve nonlinear model predictive control problems online and within sampling times in the milli- and microsecond range  @xcite .",
    "although one might argue that standard mpc and its more traditional variants do not attempt to achieve a tradeoff between nominal performance as well as learning objectives , many other controllers , which implement such tradeoffs , have a longer history .",
    "in fact , during the last 50 years , there have been many suggestions on how to develop controllers that implement such a tradeoff between control performance and learning .",
    "one of the pioneers of the so - called dual control problem is a.  feldbaum , who published a whole series of seminal papers on this topic  @xcite .",
    "feldbaum s original dual control problem formulation is based on an optimization problem that minimizes the expected control performance , typically a least - squares tracking term , under the assumption that the accuracy of the parameter estimates depends on the information content of future state measurements .",
    "unfortunately , explicit solutions for this original problem formulation of the dual control problem have so far only been found for very simple problems with one state variable .",
    "numerical algorithms for solving the dual control problem in higher dimensional spaces , e.g. , based on approximate dynamic programming , turn out to be rather expensive  @xcite . for an overview about other attempts to solve the dual control problem approximately by using techniques from the field of adaptive control the reader",
    "is referred to the overview articles  @xcite .",
    "as mentioned above , earlier or more traditional variants of mpc usually do not analyze learning objectives explicitly .",
    "however , during the last decade this situation has changed and , especially in recent years , there have appeared a significant number of articles about mpc variants that incorporate additional learning terms in order to achieve better future state and parameter estimates .",
    "for example , in  @xcite it is suggested to augment the standard mpc objective by an additional term that penalizes an approximation of the variance of future state estimates .",
    "this can be implemented by augmenting the model equations with an extended kalman filter that can be used to predict the variance of future state and parameter estimates in a linear approximation .",
    "similar extensions of mpc with learning terms have been proposed in  @xcite , which augment the nominal mpc objective with optimal experiment design objectives that penalize the predicted variance of the system parameters . in recent years there have appeared a number of articles on persistently exciting mpc  @xcite , which all discuss different ways to excite model predictive controllers in order to improve the accuracy of future state and parameter estimates .",
    "an even more recent trend is to extend the concept of application oriented optimal experiment design  @xcite by associated terms in the objective or constraints of an mpc problem  @xcite .",
    "moreover , a recent paper on self - reflective model predictive control  @xcite proposes a model predictive controller that minimizes a prediction of its own expected loss of control performance in the presence of measurement noise .",
    "notice that all these developments are closely related to the research on output - feedback mpc  @xcite .",
    "for example , in @xcite it is suggested to augment the dynamic system with a differential equation that implements a state estimator and then use methods from the field of robust mpc to robustly control the coupled system of the controller and estimator .",
    "this leads on the one hand to a rigorous framework for bounding or approximating the influence of the state estimator in mpc but , on the other hand , using robust tube based mpc methods also adds another layer of complexity to a potentially nonlinear dynamics that is already challenging to solve .",
    "a rather apparent drawback of all the above reviewed model predictive control schemes with additional learning objectives is that they are based on introducing additional , typically matrix - valued hyperstates , which are needed for predicting the accuracy of future state and parameter estimates .",
    "this leads to an optimal control problem that is from a numerical computation perspective much more difficult to solve than the corresponding optimal control problem without learning terms .",
    "unfortunately , real - time algorithms , which exploit the structure of the model predictive control problems with additional learning terms , are , as far as the authors are aware , not available to date ",
    "let alone implementations and software for solving these problems reliably .",
    "therefore , a principal goal of this paper is to develop a real - time algorithm that can exploit the structure of such problems . here",
    ", we focus on the self - reflective model predictive control formulation , which has been proposed in  @xcite and which is based on augmenting a nominal mpc objective with an economic optimal experiment design criterion  @xcite . however , the methods in this paper can also be extended for most of the other integrated experiment design mpc methods that have been reviewed above .",
    "the main contribution of this paper is the development of a novel real - time algorithm for model predictive control with additional learning objectives . in order to avoid confusion ,",
    "we mention here that the formulation of such augmented mpc problems is not an original contribution of this paper , since there are many articles about how to formulate such problems as reviewed above .",
    "the main motivation of this paper is based on the fact that the practical intention of adding a ( small ) correction term for the purpose of learning is , at least in most applications that are known to the authors , to obtain a refinement of an existing model based control scheme .",
    "a major change of the properties of a standard mpc scheme is usually not intended when such learning refinements are added .",
    "however , at the current status of research adding such a small correction term for the purpose of learning means  at least based on the authors numerical experience  an increase of computation time in the order of a factor of @xmath0 compared to standard mpc , if one of the above reviewed augmented mpc formulations is implemented by using a generic optimal control problem solver . from a practical perspective such an increase of run - time is hardly acceptable and might in fact be the main reason why mpc controllers with additional learning objectives , as developed during the last decade , are not yet used more widely in the process control industry . in order to remedy this situation",
    ", the current paper develops a tailored algorithm that can solve the self - reflective mpc problem within a sampling time that amounts to less than four times the sampling time of an associated certainty - equivalent real - time mpc scheme  @xcite .",
    "the corresponding implementation is based on an extension of the automatic code generation tools that are implemented by using casadi  @xcite and acado toolkit  @xcite , which can be used to implement self - reflective mpc schemes with a sampling time of less than a millisecond .",
    "we use the symbol @xmath1 to denote the set of positive semi - definite @xmath2 matrices .",
    "similarly , @xmath3 denotes the set of positive definite @xmath2 matrices . throughout this paper , the symbol @xmath4",
    "is used as a running index , which , by convention , always runs from @xmath5 to @xmath6 .",
    "for example , if we write a discrete - time system in the form @xmath7 then this means  if not explicitly stated otherwise  that this equation should hold for all @xmath4 .",
    "this section introduces notation and reviews an existing real - time algorithm for standard , certainty equivalent mpc , which is the basis for the developments in this paper .",
    "standard nonlinear mpc  @xcite solves at each sampling time an optimization problem of the form @xmath8 \\mathrm{s.t . }",
    "& \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\ , , & x_0 & = & y   \\\\[0.1 cm ] \\underline u & \\leq & u_k \\ ; \\leq \\ ; \\overline u \\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] based on the current ( potentially inaccurate ) state estimate @xmath9 , sends the first control input @xmath10 to the real process , and waits for the next state estimate before the loop is repeated . here",
    ", @xmath11 denotes the state , @xmath12 the control , @xmath13 a three - times lipschitz - continuously differentiable right - hand side function , which satisfies @xmath14 , and @xmath15 control bounds with @xmath16 , i.e. , such that slater s constraint qualification is satisfied . for simplicity of presentation",
    ", we assume that the stage and terminal cost @xmath17 are convex quadratic tracking terms with given positive semi - definite weighting matrices @xmath18 and @xmath19 .",
    "however , the considerations in this paper can be extended easily for the case that @xmath20 and @xmath21 are more general economic objective terms , as long as all functions are three - times lipschitz - continuously differentiable .    notice that practical system are often modeled by continuous - time differential equations . however , there exist mature tools from the field of direct optimal control , which can be used to discretize continuous - time optimal control problems leading to a finite dimensional nonlinear programming problem of the above form  @xcite .",
    "more general mpc problem formulations additionally comprise state constraints as well as terminal regions  @xcite , which are however not analyzed in this paper .",
    "the reason for this decision is that state constraints least without further to infeasibility , if uncertainties are present . as the goal of this paper is on the one hand to analyze the influence of random measurement errors , but , on the other hand , is not about robust mpc , state constraints are not considered .",
    "notice that a robustification with respect to state constraints can be taken into account by applying the output - feedback mpc based framework  @xcite , which leads however to a much more complex problem formulation , which can be expected to lead to significantly larger computation times than the methods presented in the current paper .",
    "real - time gauss - newton type algorithms for nonlinear mpc  @xcite are divided into a _ preparation phase _ and a _",
    "feedback phase_. during the preparation phase , the function @xmath22 and its derivatives @xmath23 are evaluated at the predicted state trajectory @xmath24 and control input @xmath25 .",
    "modern real - time mpc implementations are using advanced algorithmic differentiation methods for evaluating these derivatives efficiently and with high precision  @xcite .",
    "once the state measurement @xmath9 becomes available , the feedback phase starts . during this feedback phase , the quadratic programming problem @xmath26 \\mathrm{s.t .",
    "} & \\left\\ { \\begin{array}{l } \\delta x_0 = y - x_0 \\\\[0.1 cm ] \\delta x_{k+1 } = a(x_k , u_k ) \\delta x_k + b(x_k , u_k ) \\delta u_k + f(x_k , u_k ) - x_{k+1 } \\\\[0.1 cm ] \\underline u \\leq u_k + \\delta u_k \\leq \\overline u \\end{array } \\right .",
    "\\end{array}\\end{aligned}\\ ] ] is solved recalling that @xmath20 and @xmath21 are assumed to be convex quadratic forms .",
    "next , the updated control @xmath27 is sent out to the process .",
    "the remaining states and controls are shifted in time and updated as follows : @xmath28 \\forall k \\in \\ { 0 , \\ldots , n-2 \\ } , \\ ; \\ ; u_{k } & \\leftarrow & u_{k+1 } + \\delta u_{k+1 } \\ , , & \\text{and } & u_{n-1 } & \\leftarrow & u_{n-1 } + \\delta u_{n-1 } \\ , .",
    "\\notag \\end{array}\\end{aligned}\\ ] ] notice that there are many variants of the above scheme . for example , in  @xcite it is suggested to prepare the linear algebra operations that are needed for solving the qp by applying a condensing based approach that eliminates the optimization variable @xmath29 explicitly .",
    "this leads to a smaller but more dense qp to be solved in the feedback phase .",
    "a theoretical analysis as well as stability proofs of the above real - time algorithm for nonlinear mpc under mild additional assumptions can be found in  @xcite .",
    "the above real - time algorithm is often applied in combination with active set methods , which can be used for solving the qp   efficiently .",
    "for example , in  @xcite online variants of active set methods for linear and nonlinear mpc are proposed , which use tailored hot - start methods in order to further speed - up the computation time during the feedback step . however",
    ", other nonlinear mpc implementations , such as  @xcite , use an interior point method based framework . here",
    ", the main idea is to introduce the modified state cost @xmath30 \\ ; , \\ ] ] where @xmath31 is a barrier parameter .",
    "now , problem   can be approximated by an equality - constrained nlp of the form @xmath32 \\mathrm{s.t .",
    "} & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\ , , & x_0 & = & y \\ ; , \\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] which is equivalent to problem   for the limit @xmath33 ( see  @xcite for a proof ) .",
    "the numerical advantage of this nlp is that it does not contain inequalities .",
    "a corresponding real - time scheme proceeds analogous to section  [ sec::rti ] , but the difference is that the stage cost @xmath34 is at every sampling time replaced by a second taylor order expansion at the previous iterate in order to obtain a real - time newton - type method that solves equality - constrained qps in the feedback phase . as the band - structure of this qp can be exploited easily , this leads to an algorithm with complexity @xmath35 , which is fortunate if @xmath36 is large  @xcite .",
    "however , a drawback of the interior - point method based real - time scheme compared to active set methods is that hot - starts are more difficult to implement .",
    "this is due to the fact that the parameter @xmath37 has to be adjusted during the iterations .",
    "details about how to implement an associated line - search and how to adjust the tuning parameter @xmath37 during the iterations can be found in  @xcite .",
    "finally , notice that both the active - set as well as the interior - point method based real - time algorithm have in common that they do not solve problem   to optimality , but merely apply one gauss - newton or interior point iteration per sampling time .",
    "in practical applications the state of a system can often not be measured directly and has to be estimated from measurements . throughout this paper ,",
    "the measurements are assumed to satisfy the equation @xmath38 where @xmath39 is a given matrix , @xmath40 the random measurement error , and @xmath41 the actual measurement . in a more general situation",
    ", the dependence of @xmath42 on @xmath43 could also be nonlinear or additionally depend on @xmath44 , but the following considerations can be extended easily for this more general case .",
    "an additional complication is that the dynamic system itself may be affected by process noise , @xmath45 i.e. , the variables @xmath46 are random variables that can not be predicted . in the following",
    "we assume that the first and second order moments of @xmath47 and @xmath48 , denoted by @xmath49 and @xmath50 , are given , @xmath51 moreover , @xmath48 and @xmath47 are assumed to have bounded support such that @xmath52 as well as @xmath53 for a given radius @xmath54 . in the introduction",
    "a large number of extensions of mpc has been reviewed , which all attempt to include additional terms in the objective or constraints of the mpc controller in order take the accuracy of future state estimates into account when optimizing the control input .",
    "the construction of these additional terms uses ideas from the field of optimal experiment design as reviewed next .",
    "optimal experiment design is a rather mature technology and we refer to the text book  @xcite for a general overview . as this paper is about dynamic system ,",
    "it is focussed on an optimal experiment design problem formulation that has been analyzed in  @xcite . here",
    ", the main idea is to introduce an extended kalman filter in order to predict the variance matrix of future state estimates , which is based on the discrete - time riccati recursion is invertible , as we assume that @xmath55 is positive definite . ]",
    "@xmath56 & = & a(x_k , u_k ) \\left [ \\sigma_k -   \\sigma_k c^{\\mathsf{t}}\\left ( c \\sigma_k c^{\\mathsf{t}}+ v \\right)^{-1 } c \\sigma_k \\right]a(x_k , u_k)^{\\mathsf{t}}+ w \\ ,",
    ". \\end{array } \\hspace{-0.3cm}\\end{aligned}\\ ] ] this recursion is started with the variance @xmath57 of the current state estimate @xmath9 , where @xmath58 denotes the true ( but unknown ) initial state .",
    "notice that in our context , the derivative function @xmath59 is evaluated at the predicted states and control @xmath60 , as we use the extended kalman filter to predict the variances @xmath61 of future state estimates without knowing the future measurements @xmath42 yet .",
    "this is in contrast to the traditional way of applying the extended kalman filter in the context of estimation , where the measurements @xmath42 are already available and can thus be used to first update the state estimate and then evaluate @xmath59 at the state estimate rather than at the predicted state .    in the next step",
    ", a scalar experiment design criterion @xmath62 can be used to penalize large variances @xmath61 in the mpc objective . in this paper",
    "we focus on a particular design criterion based on the weighted a - criterion , @xmath63 , @xmath64 , but in principle also other criteria such as a weighted determinant or maximum eigenvalue ( d- and e - criterion ) can be used as scalar measures of the size of @xmath61 .",
    "the following mpc problem formulation with additional learning objective has ( in a very similar form ) for the first time been proposed in  @xcite : @xmath65 \\mathrm{s.t . } & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\",
    ", , & x_0 & = & y   \\\\[0.1 cm ] \\sigma_{k+1 } & = & f(x_k , u_k , \\sigma_k ) \\ , , & \\sigma_0 & = & \\hat \\sigma \\ ; .",
    "\\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] in the above mpc formulation , the matrix - valued weights @xmath64 can be used to tradeoff between the optimal experiment design objective and the nominal control objective : roughly , small values for the @xmath66s lead to better nominal tracking performance while larger values typically lead to more excitation for the purpose of learning . however , tuning these weighting matrices by hand may be cumbersome and is , to a certain extent , ambiguous .",
    "an alternative is to automatically compute more natural tradeoff weights by using the self - reflective model predictive control scheme  @xcite that is reviewed next .      as measurement errors and process noise",
    "can not be predicted , they cause an inevitable loss of control performance when compared to an utopia feedforward controller , which can predict all future measurement errors and process noise .",
    "self - reflective mpc  @xcite is a controller that minimizes the sum of its nominal performance and a second order approximation of its own expected future loss of optimality compared to an utopia feedback controller that can predict everything . in order to outline the corresponding online optimization problem formulation ,",
    "the functions @xmath67 \\\\[0.16 cm ] y(x , u,\\omega ) & = & b(x , u)^{\\mathsf{t}}p b(x , u ) + \\nabla_{uu}^2 \\left[l_\\tau(x , u ) + \\lambda^{\\mathsf{t}}f(x , u ) \\right ] \\\\[0.16 cm ] z(x , u,\\omega ) & = & a(x , u)^{\\mathsf{t}}p a(x , u ) + \\nabla_{xx}^2 \\left[l_\\tau(x , u ) + \\lambda^{\\mathsf{t}}f(x , u ) \\right ] \\\\[0.16 cm ] \\phi(x , u,\\omega ) & = & x(x , u,\\omega)^{\\mathsf{t}}y(x , u,\\omega)^{-1 } x(x , u,\\omega ) \\end{array}\\end{aligned}\\ ] ] as well as @xmath68 z(x , u,\\omega ) - \\phi(x , u,\\omega ) \\end{array } \\right)^{\\mathsf{t}}\\quad \\text{and } \\quad m(x ) = \\left ( \\begin{array}{c } x^{\\mathsf{t}}p_n \\\\ p_n \\end{array } \\right)^{\\mathsf{t}}\\notag\\end{aligned}\\ ] ] are introduced . here ,",
    "the functions @xmath69 and @xmath70 are defined for all @xmath71 all @xmath72 , and all @xmath73 \\in \\mathbb r \\times \\mathbb s_+^{n_x}$ ] .",
    "notice that the evaluation of the functions @xmath74 and @xmath75 requires the computation of second order derivatives of the hamiltonian function @xmath76 .",
    "although there exist efficient second order algorithmic differentiation schemes  @xcite , the computation of these derivatives is expensive .",
    "also notice that the function @xmath77 is strictly convex for any @xmath78 .",
    "thus , it follows from the second order optimality conditions for problem  , in this case a discrete - time variant of pontryagin s maximum principle  @xcite , that the second order derivative of the hamiltonian @xmath79 is a positive definite function in the neighborhood of a solution of  .",
    "consequently , @xmath80 is a positive definite ( and thus invertible ) matrix function in this neighborhood .",
    "now , self - reflective mpc solves at each sampling time an optimization problem of the form @xmath81 \\mathrm{s.t . } & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\",
    ", , & x_0 & = & y \\\\[0.1 cm ] \\sigma_{k+1 } & = & f(x_k , u_k , \\sigma_k ) \\ , , & \\sigma_0 & = & \\hat \\sigma \\\\[0.1 cm ] \\omega_k & = & g(x_k , u_k,\\omega_{k+1 } )   \\ , , & \\omega_n & = & m(x_n ) \\ ; .",
    "\\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] at this point , one might argue that the optimization problem   is very similar to problem   in the sense that if we set @xmath82 and @xmath83 in problem   the objective functions of the two problems coincide .",
    "however , notice that in the self - reflective problem   the weights @xmath82 are non - trivial functions of @xmath43 and @xmath44 and require the computation of the ancillary backward recursion for the variables @xmath84 , i.e. , the tradeoff between the nominal tracking performance and the additive learning term is optimized .",
    "notice that the term @xmath85 approximates the self - reflective mpc controller s own inherent expected loss of optimality in the presence of measurement errors and process noise up to terms of order @xmath86 , as established in  @xcite ; see also  @xcite for a dicussion and interpretation of this term in the context of unconstrained linear stochastic control .",
    "other advantages of the self - reflective mpc formulation as well as general economic optimal experiment design criteria are discussed in  @xcite .",
    "unfortunately , solving the integrated experiment design based mpc problem   is much more expensive than solving the nominal mpc formulation  .",
    "one reason for this increase in complexity is that problem   comprises @xmath87 state variables assuming that the symmetry of the matrix - valued state @xmath61 is exploited .",
    "the complexity of solving the self - reflective optimization problem   is even worse , as this problem comprises @xmath88 states assuming again that symmetry is already exploited .",
    "another reason is that the forward propagation of the variance matrices @xmath61 involves the evaluation of the derivative functions @xmath59 and @xmath89 of @xmath22 , which is often much more expensive than a nominal evaluation of @xmath22 .",
    "the backward propagation of the state @xmath84 in the self - reflective mpc problem   requires second derivatives of @xmath22 , which is expensive , too .",
    "moreover , the stage costs of both   as well as   are non - convex while the stage cost of   consists of a convex tracking term and , optionally , an additive self - concordant and strictly convex barrier function . as if these numerical issues would not be enough , problem   comes along with the additional complication that the term @xmath85 couples the forward states with index @xmath90 , namely @xmath43 and @xmath61 , with the backward state , namely @xmath91 , with index @xmath92 .",
    "this destroys the separability of the objective function and renders existing real - time mpc algorithms not directly applicable , as these existing methods rely on the separability of the objective function . from a process control",
    "engineering perspective one might argue that the main motivation for adding a learning term in the mpc objective is ( if this is intended at all ) that small corrections , usually in the form of minor excitations from the nominal path , are induced in order to improve future state estimates .",
    "however , if adding this minor correction comes along with major numerical difficulties and a huge increase in terms of computation time , its usefulness must be assessed critically . therefore , the goal of this paper is to develop a tailored real - time algorithm based on the self - reflective mpc problem  , which addresses the above mentioned numerical challenges in such a way that only a moderate increase in computation time is encountered when adding the learning term to the mpc objective .",
    "the hope is that this will help to promote a wider use of integrated experiment design based mpc formulations in practical and industrial process control applications .",
    "this section develops a real - time algorithm for self - reflective mpc based on the optimization problem  .",
    "the following parametric optimization problem can be interpreted as a linearly perturbed version of the original nlp  : @xmath93 \\mathrm{s.t . } & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\",
    ", , & x_0 & = & y \\ ; .",
    "\\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] here , the parameter vector @xmath94 can be used to scale the perturbation .",
    "clearly , for a given @xmath95 the cost for solving optimization problem   can be expected to be basically the same as the cost for solving the nlp  , as an additional linear term in the objective hardly adds numerical difficulties . in order to avoid confusion at this point ,",
    "it is mentioned that the method presented here should not be mixed up with the so - called _ modifier adaption method _",
    "@xcite , although one might argue that the parameter @xmath95 could be interpreted as a `` modifier '' that corrects the stage cost .",
    "however , in the context of the modifier adaption method , the correction of the objective is added in order to correct model - plant mismatches and @xmath95 is updated based on measurements of the objective gradient and constraints violation .",
    "in contrast to this approach , the intention of the presented framework is different , as we intend to perturb the gradient of the stage cost in order to improve the future state estimates while unstructured model - plant mismatches are beyond the scope of the current paper . in order to establish a connection between problem   and the self - reflective mpc controller   the following auxiliary function",
    "is introduced : @xmath96 & & \\mathrm{s.t . } & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\",
    ", , \\\\[0.1 cm ] \\sigma_{k+1 } & = & f(x_k , u_k , \\sigma_k ) \\ , , \\\\[0.1 cm ] \\omega_k & = & g(x_k , u_k,\\omega_{k+1 } )   \\ , , & \\omega_n & = & m(x_n ) \\ ; . \\end{array } \\right .",
    "\\end{array}\\end{aligned}\\ ] ] next , the equivalence of the optimization problems   and   can be established under the following conditions .",
    "[ lem::equivalence ] let @xmath22 be a three - times lipschitz - continuously differentiable function , @xmath97 and @xmath98 , and let @xmath99 be a regular local minimizer of the self - reflective optimization problem  . if @xmath100 is sufficiently small , then the function @xmath101 is differentiable in a neighborhood of @xmath102 and the gradient of @xmath101 with respect to @xmath25 is lipschitz continuous . moreover ,",
    "if we set @xmath103 , then @xmath104 is a regular local minimizer of the optimization problem  .    _",
    "_ let us introduce the auxiliary function @xmath105 & \\mathrm{s.t .",
    "} & \\left\\ { \\begin{array}{rclrcl } x_{k+1 } & = & f(x_k , u_k ) \\ ; .",
    "\\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] such that problem   can be written in the form @xmath106 .",
    "the fact that @xmath101 is lipschitz - differentiable with respect to @xmath25 follows from the fact that @xmath22 is assumed to be three - times lipschitz - continuously differentiable and the assumption that @xmath100 is sufficiently small , which implies that the function @xmath107 is invertible in the neighborhood of a regular minimizer as established in  @xcite .",
    "moreover , @xmath108 is three times continuously differentiable in @xmath25 .",
    "consequently , the first order necessary optimality condition @xmath109 must be satisfied , which implies that @xmath102 is a stationary point of problem",
    ". moreover , as @xmath77 is a strictly convex function and @xmath14 , the hessian matrix @xmath110 is positive definite , which in turn implies that @xmath111 is positive definite , too , for sufficiently small @xmath100 .",
    "this follows from the fact that @xmath108 is three times continuously differentiable .",
    "thus , @xmath102 is a regular local minimizer of the optimization problem @xmath112 which is the statement of the lemma .",
    "notice that lemma  [ lem::equivalence ] is only a technical intermediate result , which is in this form not useful yet , as it relies on the availability of the ( in a real - time context not available ) optimal solution @xmath102 of the optimization problem   in order to compute the optimal perturbation vector @xmath95 .",
    "however , the main idea of the current paper is to develop a real - time algorithm that computes gradient updates of the form @xmath113 at a suitable real - time control iterate @xmath25 rather than computing the optimal perturbation vector @xmath114 .",
    "before we analyze this idea in more detail , the following section first focusses on an algorithm for evaluating this gradient efficiently and in real - time mode .      in order to develop an efficient algorithm for evaluating the gradient of the function @xmath101 ,",
    "it is convenient to introduce the stacked notation @xmath115 \\omega_k & = & { \\mathrm{vec}\\left(\\omega_k\\right ) } , & \\mathcal g(\\kappa_k,\\omega_{k+1},u_k ) & = & { \\mathrm{vec}\\left(g(x_k , u_k,\\omega_{k+1})\\right ) } \\\\[0.5 cm ] & & & \\mathcal l ( \\kappa_k , \\omega_{k+1 } , u_k ) & = & \\frac{1}{2}\\mathrm{tr}\\left ( \\phi(x_k , u_k,\\omega_{k+1 } ) \\sigma_k \\right ) \\ ; , \\end{array}\\end{aligned}\\ ] ] where the function `` @xmath116 '' stacks all independent components of a matrix into a vector exploiting symmetry whenever possible . by using this notation",
    "the function @xmath101 can be written in the more compact form @xmath117 & & \\mathrm{s.t . } & \\left\\ { \\begin{array}{rclrcl } \\kappa_{k+1 } & = & \\mathcal f ( \\kappa_k , u_k ) \\",
    ", , \\\\[0.1 cm ] \\omega_k & = & \\mathcal g(\\kappa_k,\\omega_{k+1},u_k ) \\",
    ", , & \\omega_n & = & \\mathcal m(\\kappa_n ) \\ ; .",
    "\\end{array } \\right . \\end{array}\\end{aligned}\\ ] ] a four - sweep algorithm for computing the gradient of @xmath101 for a given input vector @xmath25 is outlined in algorithm  1 .    ' '' ''     + * algorithm 1 : four - sweep algorithm for updating the perturbation vector @xmath95 . *",
    "+    ' '' ''     + * input : * control vector @xmath25 ; initial state @xmath118 and initial variance @xmath119 . +",
    "* four - sweeps ( with @xmath4 ) : * +    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 .",
    "_ nominal forward sweep . _ set @xmath120 $ ] and iterate forwards @xmath121 2 .",
    "_ nominal backward sweep . _ set @xmath122 and iterate backwards @xmath123 3 .",
    "_ adjoint forward sweep . _ set @xmath124 and iterate forwards @xmath125 4",
    ".   _ adjoint backward sweep . _ set @xmath126 and iterate backwards @xmath127 5 .",
    "_ final evaluation of the gradient .",
    "_ set @xmath128 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    * output : * the perturbation vector @xmath129^{\\mathsf{t}}$ ] .",
    "+    ' '' ''    notice that algorithm  1 proposes a mixed forward - backward algorithmic differentiation scheme that exploits the particular structure of the function @xmath101 .",
    "the derivation of this algorithm exploits the concept of duality in linear programming as summarized in the following theorem .",
    "if @xmath22 is three times continuously differentiable , then algorithm  1 returns the gradient vector @xmath130 .    _",
    "proof . _ the directional forward derivative @xmath131 of the function @xmath101 in direction @xmath132 can be found by solving the following first order linear variation of problem  : @xmath133 \\begin{array}{cl } \\underset{\\delta \\kappa , \\delta \\omega}{\\min } & \\sum_{k=0}^{n-1 } \\left ( \\begin{array}{c } \\nabla_{\\kappa } \\mathcal l ( \\kappa_k , \\omega_{k+1 } , u_k ) \\\\",
    "\\nabla_{\\omega } \\mathcal l ( \\kappa_k , \\omega_{k+1 } , u_k ) \\\\",
    "\\nabla_{u } \\mathcal l ( \\kappa_k , \\omega_{k+1 } , u_k ) \\end{array } \\right)^{\\mathsf{t}}\\left ( \\begin{array}{c } \\delta \\kappa_k \\\\ \\delta \\omega_{k+1 } \\\\",
    "\\delta u_k \\end{array } \\right ) \\\\[0.2 cm ] \\mathrm{s.t . } & \\left\\ { \\begin{array}{rcl } \\delta \\kappa_0 & = & 0 \\ , , \\\\[0.1 cm ] \\delta \\kappa_{k+1 } & = & \\nabla_{\\kappa } \\mathcal f ( \\kappa_k , u_k ) ^{\\mathsf{t}}\\delta \\kappa_k + \\nabla_{u } \\mathcal f ( \\kappa_k , u_k ) ^{\\mathsf{t}}\\delta u_k \\ , , \\\\[0.1 cm ] \\delta \\omega_n & = & \\nabla \\mathcal m(\\kappa_n)^{\\mathsf{t}}\\delta \\kappa_{n } \\ ; , \\\\[0.1 cm ] \\delta \\omega_k & = & \\left ( \\begin{array}{c } \\nabla_{\\kappa } \\mathcal g ( \\kappa_k , \\omega_{k+1 } , u_k )",
    "\\\\ \\nabla_{\\omega } \\mathcal g ( \\kappa_k , \\omega_{k+1 } , u_k ) \\\\",
    "\\nabla_{u } \\mathcal g ( \\kappa_k , \\omega_{k+1 } , u_k ) \\end{array } \\right)^{\\mathsf{t}}\\left ( \\begin{array}{c } \\delta \\kappa_k \\\\ \\delta \\omega_{k+1 } \\\\ \\delta u_k \\end{array } \\right ) \\ , .",
    "\\end{array } \\right .",
    "\\end{array } \\end{array}\\end{aligned}\\ ] ] by writing out the first order optimality conditions of the above linear programming problem , explicit expressions for the multiplies @xmath134 as well as @xmath135 are found .",
    "they are given by the recursion in step  3 and  4 of algorithm  1 . moreover , since problem   is a linear programming problem , there is no duality gap , i.e. , the objective values of the primal and dual objectives coincide , @xmath136 \\sum_{k=1}^{n-1 } \\delta u_k^{\\mathsf{t}}\\left [ \\nabla_{u } \\mathcal l ( \\kappa_k , \\omega_{k+1 } , u_k ) - \\nabla_{u } \\mathcal g ( \\kappa_k , \\omega_{k+1 } , u_k ) a_k - \\nabla_{u } \\mathcal f ( \\kappa_k , u_k ) b_{k+1 } \\right ] \\ ; . \\end{array } \\notag\\end{aligned}\\ ] ] as this equation holds for all directions @xmath132 , a comparison of coefficients yields @xmath130 , as stated by the theorem .",
    "a real - time iteration scheme for self - reflective mpc is obtained by implementing the following steps in a loop .    1 .",
    "compute the gradient @xmath137 by using algorithm  1 . 2 .",
    "collect new measurements and use an extended kalman filter to update @xmath9 .",
    "3 .   compute a local minimizer @xmath138 of the optimization problem  .",
    "4 .   send the solution @xmath139 to the process .",
    "5 .   shift all variables , @xmath140 , @xmath141 , @xmath142 , and @xmath143 . 6 .",
    "update the variance matrix @xmath144 .",
    "notice that in the above scheme , the perturbation vector @xmath95 is updated in the preparation phase in step  1 , i.e. , before the actual measurement arrives .",
    "this is motivated by the fact that the computation of this gradient is usually the most expensive step and therefore done before the feedback phase , step  2 - 4 .",
    "notice that variants of the above scheme might refine step  3 and solve a quadratic approximation of in order to further speed - up the feedback time , which leads to a scheme that is similar to the standard real - time algorithms in sections  [ sec::rti ] and  [ sec::ip ] .",
    "however , before we discuss such variants , let us first analyze , why the above real - time scheme can be expected to be contractive at all .",
    "for this aim , we introduce the auxiliary function is not strictly convex in @xmath145 ) introduces a slight abuse of notation in the sense that this paper uses local optimization algorithms only . in the context of this paper , should be read as `` @xmath146 is the local minimizer that is found by initializing the local solver in a neighborhood of the solution @xmath102 of ' ' . ]",
    "@xmath147 notice that lemma  [ lem::equivalence ] implies that the solution @xmath102 of the self - reflective optimization problem   is a fix - point of the function @xmath148 , @xmath149 .",
    "moreover , the update from step  3 of the above outlined real - time procedure can be written in the form @xmath150 thus , the proposed algorithm can be interpreted as a real - time variant of a fixed point iteration .",
    "now , a contractivity condition can be established by using banach s fixed point theorem .",
    "[ thm::contraction ] let all the conditions from lemma  [ lem::equivalence ] be satisfied and let the current iterate @xmath25 for the control input be in a neighborhood of @xmath102 .",
    "the update from step  3 of the proposed real - time scheme contracts linearly , i.e. , we have @xmath151 with contraction constant @xmath152 .",
    "_ lemma  [ lem::equivalence ] assumes that the local minimizer @xmath102 is regular .",
    "consequently , the optimization problem   is regular for all @xmath25 in a sufficiently small neighborhood of @xmath102 . by using a standard result from parametric nonlinear programming  @xcite",
    ", this implies that the map @xmath148 is locally lipschitz continuous with respect to the perturbation gradient , @xmath153 for all @xmath154 in a neighborhood of @xmath102 .",
    "next , we can use that the gradient @xmath155 is lipschitz continuous , which implies @xmath156 since @xmath101and consequently also the lipschitz constant of @xmath155is of order @xmath157 .",
    "thus , we have @xmath158 with @xmath159 , i.e. , the update contracts if @xmath100 is sufficiently small .    as any other gradient based optimization method ,",
    "also the performance of the above outlined real - time scheme can be improved further by implementing a pre - conditioner  @xcite . in this paper ,",
    "the optimization problem   is solved once offline at the steady - state .",
    "the corresponding hessian matrix , @xmath160 , or a suitable approximation of this matrix , can be used to scale the optimization variable @xmath25 offline in order to improve the contraction rate of the proposed real - time scheme . as mentioned above , another improvement of the above real - time scheme refines step  3 by solving a quadratic approximation of at every sampling time instead of solving this problem to optimality . in this case",
    ", the evaluation of all gradients can be done in the preparation step , as explained in section  [ sec::rti ] .",
    "a discussion of why contractivity of the real - time iterates is enough to ensure nominal local closed - loop stability of the corresponding mpc controller for exact state measurements and under mild regularity assumptions can be found in  @xcite .",
    "however , in the context of this paper , we need to make the additional assumption that the system is locally observable such that the extended kalman filter yields bounded variance matrices of order @xmath161 ; see also  @xcite for an overview of how to analyze the closed loop - stability of mpc - ekf cascades .",
    "this paper analyzes a controllable chemical reaction , where the discrete - time right - hand side function @xmath162 is given in the form of the solution of the differential equation system @xmath163 z(0,x , u ) & = & x \\ ; , \\notag\\end{aligned}\\ ] ] which has to be evaluated numerically , e.g. , by using a runge - kutta integrator .",
    "the given constant @xmath164 denotes the discrete - time step - size . the differential states @xmath165 and @xmath166 denote the concentrations of three substances , which react with each other . for simplicity of presentation , the corresponding reaction constants @xmath167 and @xmath168 as well as the dilution rate @xmath169 are assumed to be given . the feeding rates @xmath170 and @xmath171 are control inputs , which can be used to adjust the inflow of the substances .",
    "we assume that only the concentration @xmath172 can be measured , @xmath173^{\\mathsf{t}}$ ] .",
    "the variance of the measurement error is given by @xmath174 .",
    "a summary of all model parameters can be found in table  [ tab : parameters ] .",
    ".[tab : parameters]parameter values . [ cols=\"<,^,^\",options=\"header \" , ]     the computation of the perturbation vector update takes approximately @xmath175s , which corresponds to about @xmath176 of the overall cpu time needed for one real - time step of the proposed self - reflective mpc algorithm .",
    "a standard mpc controller without learning terms needs @xmath177s per real - time step , as such a standard controller needs to implement basically the same operations except for the perturbation vector update .",
    "given the fact that solving the original self - reflective optimization problem   with a generic optimal control solver takes more than @xmath178 times longer than the standard mpc problem , the above run - times must be considered as a major improvement compared to the state - of - the - art , although one might still argue that an increase of a factor @xmath179-@xmath180 in terms of run - time for adding a self - reflective learning term correction is still a lot .",
    "the case study in this paper has only three states and must be considered a small - scale example .",
    "thus , there arises the question how the proposed real - time algorithm performs for larger scale examples .",
    "although we do not present such larger case studies in detail as part of this paper , preliminary numerical experiments indicate that also for larger problems one real - time step of the proposed algorithm takes approximately three to four times longer than a standard real - time mpc step , i.e. , also for larger problems a relatively moderate increase in run - time is observed if the additive self - reflective learning term is taken into account .",
    "such a behavior can also be expected from our theoretical considerations in the sense that both the standard mpc real - time step applied to a problem formulation without learning term as well as algorithm  1 have a complexity of order @xmath181 recalling that @xmath182 denotes the state dimension and @xmath36 the horizon length.@xmath183",
    "this paper has proposed a novel real - time algorithm for integrated experiment design mpc .",
    "this algorithm improves the run - time performance compared to existing generic real - time mpc algorithms by orders of magnitude , as it is capable of exploiting the particular structure of mpc problems with additional learning terms .",
    "a particular focus of this paper has been on self - reflective mpc , a controller whose objective is to minimize the sum of a nominal tracking term and the expected loss of optimality of its own performance in the presence of random process noise and measurement errors .",
    "lemma  [ lem::equivalence ] has established that such self - reflective model predictive controllers are equivalent to a standard mpc problem with affinely perturbed objective function as long as the perturbation vector is chosen to be equal to the gradient of the expected loss of optimality . as this affinely perturbed mpc problem",
    "can be solved as fast as standard mpc problems without learning terms , the only additional cost is the cost of computing or approximating the optimal perturbation vector .",
    "a four - sweep algorithm for computing this perturbation vector approximately and in real - time has been proposed in algorithm  1 .",
    "the properties of the associated overall real - time scheme for self - reflective mpc have been analyzed in theorem  [ thm::contraction ] and have been illustrated numerically by applying it to a nonlinear predator - prey - feeding control problem .",
    "for the presented case study , one real - time step takes @xmath184s , approximately three times more than a standard real - time mpc step without learning perturbation .",
    "however , compared to existing generic real - time mpc methods applied to the self - reflective problem this amounts to a moderate increase in run - time that may be acceptable in practice , if the additional learning terms leads  as in the presented example  to a significantly improved overall control performance in the presence of measurement errors and process noise .",
    "this research was supported by national natural science foundation china , , as well as shanghaitech university , grant - nr .  .",
    "99      j.  andersson , j.  akesson , m.  diehl .",
    "casadi : a symbolic package for automatic differentiation and optimal control . in _ recent advances in algorithmic differentiation _ ,",
    "volume 87 of the series lecture notes in computational science and engineering , p.  297307",
    ", 2012 .",
    "bock , m.  diehl , d.b .",
    "leineweber , and j.p .",
    "direct multiple shooting method for real - time optimization of nonlinear dae processes . in f.",
    "allgwer and a.  zheng , editors , _ nonlinear predictive control _ , volume  26 of _ progress in systems theory _ , pages 246267 , basel boston berlin , 2000 .",
    "birkhuser .",
    "m.  diehl , h.g .",
    "bock , j.p .",
    "schlder , r.  findeisen , z.  nagy , and f.  allgwer .",
    "eal - time optimization and nonlinear model predictive control of processes governed by differential - algebraic equations",
    ". journal of process control , 12(4):577585 , 2002 .",
    "larsson , m.  annergren , h.  hjalmarsson , c.r .",
    "rojas , x.  bombois , a.  mesbah , p. moden .",
    "model predictive control with integrated experiment design for output error systems . in proceedings of the 2013 european control conference ( ecc ) ,",
    "37903795 , july , 2013 .",
    "j.  mattingley and s.  boyd . automatic code generation for real - time convex optimization .",
    "convex optimization in signal processing and communications , y. eldar and d. palomar , eds .",
    ", cambridge university press , 2009 .",
    "a. mesbah , x. bombois , m. forgione , h. hjalmarsson , p.m.j .",
    "van den hof .",
    "least costly losed - loop performance diagnosis and plant re - identification .",
    "international journal of control , 88(11):22642276 , 2015 .",
    "r.  quirynen , b.  houska , m.  vallerio , d.  telen , f.  logist , j.  van impe , m.  diehl .",
    "symmetric algorithmic differentiation based exact hessian sqp method and software for economic mpc . in proceedings of the ieee conference on decision and control ( cdc ) , 27522757 , 2014 .",
    "d.  telen , b.  houska , f.  logist , e.  van derlinden , m.  diehl , j.  van impe . optimal experiment design under process noise using riccati differential equations",
    ". journal of process control , 23:613629 , 2013 ."
  ],
  "abstract_text": [
    "<S> this paper is about a real - time model predictive control ( mpc ) algorithm for a particular class of model based controllers , whose objective consists of a nominal tracking objective and an additional learning objective . here </S>",
    "<S> , the construction of the learning term is based on economic optimal experiment design criteria . </S>",
    "<S> it is added to the mpc objective in order to excite the system from time - to - time on purpose in order to improve the accuracy of the state and parameter estimates in the presence of incomplete or noise affected measurements . </S>",
    "<S> a particular focus of this paper is on so - called self - reflective model predictive control schemes , which have the property that the additional learning term can be interpreted as the expected loss of optimality of the controller in the presence of random measurement errors . </S>",
    "<S> the main contribution of this paper is a formulation - tailored algorithm , which exploits the particular structure of self - reflective mpc problems in order to speed - up the online computation . </S>",
    "<S> it is shown that , in contrast to generic state - of - the - art optimal control problem solvers , the proposed algorithm can solve the self - reflective optimization problems with reasonable additional computational effort and in real - time . </S>",
    "<S> the advantages of the proposed real - time scheme are illustrated by applying the algorithm to a nonlinear process control problem in the presence of measurement errors and process noise .    </S>",
    "<S> optimal control , optimal experiment design , model predictive control </S>"
  ]
}