{
  "article_text": [
    "neurons generate signals by weighting and combining input spike trains from presynaptic neuron populations .",
    "the number of possible signals which can be read out this way from a given spike - train ensemble is maximal if these spike trains span an orthogonal basis , i.e.  if they are uncorrelated @xcite . if they are correlated , the amount of information which can be encoded in the spatio - temporal structure of these spike trains is limited .",
    "in addition , correlations impair the ability of readout neurons to decode information reliably in the presence of noise .",
    "this is often discussed in the context of _ rate coding _ : for @xmath0 uncorrelated spike trains , the signal - to - noise ratio of the compound spike - count signal can be enhanced by increasing the population size @xmath0 . in the presence of correlations , however , the signal - to - noise ratio is bounded @xcite .",
    "the same reasoning holds for any other linear combination of spike trains , also for those where exact spike timing matters ( for example for the coding scheme presented in * ? ? ?",
    "thus , the robustness of neuronal responses against noise critically depends on the level of correlated activity within the presynaptic neuron population .",
    "several studies suggested that correlated neural activity could be beneficial for information processing : spike - train correlations can modulate the gain of postsynaptic neurons and thereby constitute a gating mechanism ( for a review , see * ? ? ?",
    "coherent spiking activity might serve as a means to bind elementary representations into more complex objects @xcite .",
    "information represented by correlated firing can be reliably sustained and propagated through feedforward subnetworks ( synfire chains ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . whether correlated firing has to be considered favorable or not largely depends on the underlying hypothesis , the type of correlation ( e.g.  the time scale or the affected frequency band ) or which subpopulations of neurons are involved .",
    "most ideas suggesting a functional benefit of correlated activity rely on the existence of an asynchronous ground state. spontaneously emerging correlations , i.e.  correlations which are not triggered by internal or external events , would impose a serious challenge to many of these hypotheses .",
    "functionally relevant synfire activity , for example , can not be guaranteed in the presence of correlated background input from the embedding network @xcite .",
    "it is therefore  from several perspectives  important to understand the origin of uncorrelated activity in neural networks .",
    "it has recently been shown that spike trains of neighboring cortical neurons can indeed be highly uncorrelated @xcite .",
    "similar results have been obtained in several theoretical studies @xcite . from an anatomical point of view , this observation is puzzling : in general , neurons in finite networks share a certain fraction of their presynaptic sources .",
    "in particular for neighboring neurons , the overlap between presynaptic neuron populations is expected to be substantial .",
    "this feedforward picture suggests that such presynaptic overlap gives rise to correlated synaptic input and , in turn , to correlated response spike trains .",
    "a number of theoretical studies showed that shared - input correlations are only weakly transferred to the output side as a consequence of the nonlinearity of the spike - generation dynamics @xcite .",
    "unreliable spike transmission due to synaptic failure can further suppress the correlation gain @xcite .",
    "in @xcite , we demonstrated that spike - train correlations in finite - size recurrent networks are even smaller than predicted by the low correlation gain of pairs of neurons with nonlinear spike - generation dynamics .",
    "we concluded that this suppression of correlations must be a result of the recurrent network dynamics . in this article , we compare correlations observed in feedforward networks to correlations measured in systems with an intact feedback loop .",
    "we refer to the reduction of correlations in the presence of feedback as `` decorrelation '' .",
    "different mechanisms underlying such a dynamical decorrelation have been suggested in the recent past .",
    "asynchronous states in recurrent neural networks are often attributed to chaotic dynamics @xcite .",
    "in fact , networks of nonlinear units with random connectivity and balanced excitation and inhibition typically exhibit chaos @xcite . the high sensitivity to noise may however question the functional relevance of such systems ( @xcite ; cf .",
    ", however , @xcite ) . @xcite and @xcite demonstrated that asynchronous irregular firing can also emerge in networks with stable dynamics .",
    "employing an analytical framework of correlations in recurrent networks of binary neurons @xcite , the balance of excitation and inhibition has recently been proposed as another decorrelation mechanism @xcite : in large networks , fluctuations of excitation and inhibition are in phase .",
    "positive correlations between excitatory and inhibitory input spike trains lead to a negative component in the net input correlation which can compensate positive correlations caused by shared input .    in the present study",
    ", we demonstrate that dynamical decorrelation is a fundamental phenomenon in recurrent systems with negative feedback .",
    "we show that negative feedback alone is sufficient to efficiently suppress correlations . even in purely inhibitory networks ,",
    "shared - input correlations are compensated by feedback .",
    "a balance of excitation and inhibition is thus not required .",
    "the underlying mechanism can be understood by means of a simple linear model .",
    "this simplifies the theory and helps to gain intuition , but it also confirms that low correlations can emerge in recurrent networks with stable , non - chaotic dynamics .    the suppression of pairwise spike - train correlations by inhibitory feedback is reflected in a reduction of population - rate fluctuations .",
    "the main effect described in this article can therefore be understood by studying the dynamics of the macroscopic population activity (  ) .",
    "this approach leads to a simple mathematical description and emphasizes that the described decorrelation mechanism is a general phenomenon which may occur not only in neural networks but also in other ( biological ) systems with inhibitory feedback . in",
    ", we first illustrate the decorrelation effect for random networks of @xmath0 leaky integrate - and - fire ( lif ) neurons with inhibitory or excitatory - inhibitory coupling . by means of simulations ,",
    "we show that low - frequency spike - train correlations , and , hence , population - rate fluctuations are considerably smaller than expected given the amount of shared input . as shown in , the suppression of population - rate fluctuations by inhibitory feedback can readily be understood in the framework of a simple one - dimensional linear model with negative feedback .",
    "extends this result to a two - population system with excitatory - inhibitory coupling . here , a simple coordinate transform exposes the inherent negative feedback loop as the underlying cause of the fluctuation suppression in inhibition - dominated networks .",
    "the population - rate models used in and are sufficient to understand the basic mechanism underlying the decorrelation .",
    "they do , however , not describe how feedback in cortical networks affects the detailed structure of pairwise correlations . in",
    ", we therefore compute self - consistent population averaged correlations for a random network of @xmath0 linear excitatory and inhibitory neurons . by determining the parameters of the linear network",
    "analytically from the lif model , we show that the predictions of the linear model are  for a wide and realistic range of parameters  in excellent agreement with the results of the lif network model . in",
    ", we make clear that the active decorrelation in random lif networks relies on the feedback of the ( sub)population averaged activity but not on the precise microscopic structure of the feedback signal . in , we discuss the consequences of this work in a broader context and point out limitations and possible extensions of the presented theory .",
    "contains details on the lif network model , the derivation of the linear model from the lif dynamics and the derivation of population - rate spectra and population averaged correlations in the framework of the linear model .",
    "it is meant as a supplement ; the basic ideas and the main results can be extracted from .",
    "in a recurrent neural network of size @xmath0 , each neuron @xmath1 $ ] receives in general inputs from two different types of sources : external inputs @xmath2 representing the sum of afferents from other brain areas , and local inputs resulting from the recurrent connectivity within the network .",
    "depending on their origin , external inputs @xmath3 and @xmath4 to different neurons @xmath5 and @xmath6 can be correlated or not . throughout this manuscript",
    ", we ignore correlations between these external sources , thereby ensuring that correlations within the network activity arise from the local connectivity alone and are not imposed by external inputs @xcite .",
    "the local inputs feed the network s spiking activity @xmath7 back to the network ( we refer to spike train @xmath8 , the @xmath5th component of the column vector @xmath9 [ the superscript `` @xmath10 '' denotes the transpose ] , as a sum over delta - functions centered at the spike times @xmath11 : @xmath12 ; the abstract quantity ` spike train ' can be considered as being derived from the observable quantity ` spike count ' @xmath13 , the number of spikes occurring in the time interval @xmath14 , by taking the limit @xmath15 : @xmath16 ) .",
    "the structure and weighting of this feedback can be described by the network s connectivity matrix @xmath17 ( see a ) . in a finite network ,",
    "the local connectivity typically gives rise to overlapping presynaptic populations : in a random ( erds - rnyi ) network with connection probability @xmath18 , for example , each pair of postsynaptic neurons shares , on average , @xmath19 presynaptic sources . for a network size of , say , @xmath20 and a connection probability @xmath21",
    ", this corresponds to a fairly large number of @xmath22 identical inputs . for other network structures ,",
    "the amount of shared input may be smaller or larger .",
    "due to this presynaptic overlap , each pair of neurons receives , to some extent , correlated input ( even if the external inputs are uncorrelated ) .",
    "one might therefore expect that the network responses @xmath23 are correlated as well . in this article , we show that , in the presence of negative feedback , the effect of shared input caused by the structure of the network is compensated by its recurrent dynamics .      to illustrate the effect of shared input and its suppression by the recurrent dynamics",
    ", we compare the spike response @xmath7 of a recurrent random network ( _ feedback scenario _ ; a , c , e ) of @xmath0 lif neurons to the case where the feedback is cut and replaced by a spike - train ensemble @xmath24 , modeled by @xmath0 independent realizations of a stationary poisson point process ( _ feedforward scenario _ ; b , d , f ) .",
    "the rate of this poisson process is identical to the time and population averaged firing rate in the intact recurrent system . in both the feedback and the feedforward case , the ( local ) presynaptic spike trains are fed to the postsynaptic population according to the same connectivity matrix @xmath17",
    "therefore , not only the in - degrees and the synaptic weights but also the shared - input statistics are exactly identical .    for realistic size @xmath0 and connectivity @xmath18 , asynchronous states of random neural networks @xcite exhibit spike - train correlations which are small but not zero ( compare raster displays in c and d",
    "; see also * ? ? ?",
    "although the presynaptic spike trains are , by construction , independent in the feedforward case ( d ) , the resulting response correlations , and , hence , the population - rate fluctuations , are substantially stronger than those observed in the feedback scenario ( compare f and e ) . in other words : a theory which is exclusively based on the amount of shared input but neglects the details of the presynaptic spike - train statistics can significantly overestimate correlations and population - rate fluctuations in recurrent neural networks .    the same effect can be observed in lif networks with both purely inhibitory and mixed excitatory - inhibitory coupling ( ) . to demonstrate this quantitatively , we focus on the fluctuations of the population averaged activity @xmath25 . its power - spectrum ( or auto - correlation , in the time domain ) @xmath26\\left(\\omega\\right)}|^2      = \\frac{1}{n^2}\\left[\\sum_{i=1}^n",
    "a_i(\\omega ) + \\sum_{i=1,j\\ne{}i}^n c_{ij}(\\omega)\\right ]    \\end{aligned}\\end{aligned}\\ ] ] is determined both by the power - spectra ( auto - correlations ) @xmath27 of the individual spike trains and the cross - spectra ( cross - correlations ) @xmath28 ( @xmath29 ) of pairs of spike trains ( throughout the article , we use capital letters to represent quantities in frequency [ fourier ] space ; represents the fourier transform of the spike train @xmath30 ) .",
    "we observe that the spike - train power - spectra @xmath31 ( and auto - correlations ) are barely distinguishable in the feedback and in the feedforward case ( not shown here ; the main features of the spike - train auto - correlation are determined by the average single - neuron firing rate and the refractory mechanism ; both are identical in the feedback and the feedforward scenario ) .",
    "the differences in the population - rate spectra @xmath32 are therefore essentially due to differences in the spike - train cross - spectra @xmath33 . in other words ,",
    "the fluctuations in the population activity serve as a measure of pairwise spike - train correlations @xcite : small ( large ) population averaged spike - train correlations are accompanied by small ( large ) fluctuations in the population rate ( see lower panels in c  f ) .",
    "the power - spectra @xmath32 of the population averaged activity reveal a feedback - induced suppression of the population - rate variance at low frequencies up to several tens of hertz .",
    "for the examples shown in , this suppression spans more than three orders of magnitude for the inhibitory and more than one order of magnitude for the excitatory - inhibitory network .",
    "the suppression of low - frequency fluctuations does not critically depend on the details of the network model . as shown in , it can ,",
    "for example , be observed for both networks with zero rise - time synapses ( @xmath34-shaped synaptic currents ) and short delays and for networks with delayed low - pass filtering synapses ( @xmath35-shaped synaptic currents ) . in the latter case ,",
    "the suppression of fluctuations is slightly more restricted to lower frequencies ( @xmath36 ) . here",
    ", the fluctuation suppression is however similarly pronounced as in networks with instantaneous synapses .    in c , d ,",
    "the power - spectra of the population activity converge to the mean firing rate at high frequencies .",
    "this indicates that the spike trains are uncorrelated on short time scales . for instantaneous @xmath34-synapses ,",
    "neurons exhibit an immediate response to excitatory input spikes @xcite .",
    "this fast response causes spike - train correlations on short time scales .",
    "hence , the compound power at high frequencies is increased . in a recurrent system , this effect is amplified by reverberating simultaneous excitatory spikes . therefore , the high - frequency power of the compound activity is larger in the feedback case ( b ) . note that this high - frequency effect is absent in networks with more realistic low - pass filtering synapses ( c , d ) and in purely inhibitory networks ( a ) .",
    "synaptic delays and slow synapses can promote oscillatory modes in certain frequency bands @xcite , thereby leading to peaks in the population - rate spectra in the feedback scenario which exceed the power in the feedforward case ( see peaks at @xmath37 in c , d ) .",
    "note that , in the feedforward case , the local input was replaced by a stationary poisson process , whereas in the recurrent network ( feedback case ) the presynaptic spike trains exhibit oscillatory modes . by replacing the feedback by an inhomogeneous poisson process with a time dependent intensity which is identical to the population rate in the recurrent network",
    ", we found that these oscillatory modes are neither suppressed nor amplified by the recurrent dynamics , i.e.  the peaks in the resulting power - spectra have the same amplitude in the feedback and in the feedforward case ( data not shown here ) . at low frequencies , however ,",
    "the results are identical to those obtained by replacing the feedback by a homogeneous poisson process ( i.e.  to those shown in ; see ) . in the present study",
    ", we mainly focus on these low - frequency effects .",
    "the observation that the suppression of low - frequency fluctuations is particularly pronounced in networks with purely inhibitory coupling indicates that inhibitory feedback may play a key role for the underlying mechanism . in the following subsection",
    ", we will demonstrate by means of a one - dimensional linear population model that , indeed , negative feedback alone leads to an efficient fluctuation suppression .",
    "neurons in a @xmath38 time interval . in both the feedback and the feedforward scenario , the neuron population @xmath39 is driven by the same realization @xmath40 of an uncorrelated white - noise ensemble ; local input is fed to the population through the same connectivity matrix @xmath17 .",
    "the in - degrees , the synaptic weights and the shared - input statistics are thus exactly identical in the two scenarios . in the feedback case ( a ) ,",
    "local presynaptic spike - trains are provided by the network s",
    "response @xmath7 , i.e.  the pre- ( c ) and postsynaptic spike - train ensembles ( e ) are identical . in the feedforward scenario ( b ) , the local presynaptic spike - train population is replaced by an ensemble of @xmath0 independent realizations @xmath41 of a poisson point process ( d ) .",
    "its rate is identical to the time- and population - averaged firing rate in the feedback case .",
    "see and for details on network models and parameters .",
    ", title=\"fig : \" ]     ( * a*,*b * ) and low - pass synapses with @xmath42 ( * c*,*d * ) .",
    "power - spectra @xmath43 of population rates @xmath44 for the feedback ( black ) and the feedforward case ( gray ; cf .  ) .",
    "see and for details on network models and parameters . in c and d ,",
    "local synaptic inputs are modeled as currents @xmath45 with @xmath35-function shaped kernel @xmath46 with time constant @xmath47 ( @xmath48 denotes heaviside function ) .",
    "( excitatory ) synaptic weights are set to @xmath49 ( see for details ) .",
    "simulation time @xmath50 .",
    "single - trial spectra smoothed by moving average ( frame size @xmath51).,title=\"fig : \" ]      average pairwise correlations can be extracted from the spectrum of the compound activity , provided the single spike - train statistics ( auto - correlations ) is known ( see previous section ) . as",
    "the single spike - train statistics is identical in the feedback and in the feedforward scenario , the mechanism underlying the decorrelation in recurrent networks can be understood by studying the dynamics of the population averaged activity . in this and in the next subsection ( )",
    ", we will consider the linearized dynamics of random networks composed of homogeneous subpopulations of lif neurons .",
    "the high - dimensional dynamics of such systems can be reduced to low - dimensional models describing the dynamics of the compound activity ( for details , see ) .",
    "note that this reduction is exact for networks with homogeneous out - degree ( number of outgoing connections ) .",
    "for the networks studied here ( random networks with homogeneous in - degree ) , it serves as a sufficient approximation ( in a network of size @xmath0 where each connection is randomly and independently realized with probability @xmath18 [ erds - rnyi graph ] , the [ binomial ] in- and out - degree distributions become very sharp for large @xmath0 [ relative to the mean in / out - degree ] ; both in- and out - degree are therefore approximately constant across the population of neurons ) . in this subsection",
    ", we will first study networks with purely inhibitory coupling . in",
    ", we will investigate the effect of mixed excitatory - inhibitory connectivity .",
    "consider a random network of @xmath0 identical neurons with connection probability @xmath18 .",
    "each neuron @xmath52 receives @xmath53 randomly chosen inputs from the local network with synaptic weights @xmath54 .",
    "in addition , the neurons are driven by external uncorrelated gaussian white noise @xmath2 with amplitude @xmath55 , i.e.   and . for small input fluctuations",
    ", the network dynamics can be linearized .",
    "this linearization is based on the averaged response of a single neuron to an incoming spike and describes the activity of an individual neuron @xmath5 by an abstract fluctuating quantity @xmath56 which is defined such that within the linear approximation its auto- and cross - correlations fulfill the same linearized equation as the spiking model in the low - frequency limit . consequently , also the low - frequency fluctuations of the population spike rate are captured correctly by the reduced model up to linear order .",
    "this approach is equivalent to the treatment of finite - size fluctuations in spiking networks ( * ? ?",
    "* see , e.g. ) . for details",
    "see . for large @xmath0 ,",
    "the population averaged activity can hence be described by a one - dimensional linear system @xmath57*h)(t)\\ ] ] with linear kernel @xmath58 , effective coupling strength @xmath59 and the population averaged noise @xmath60}$ ] ( see and b ) . the coupling strength @xmath61 represents the integrated linear response of the neuron population to a small perturbation in the input rate of a single presynaptic neuron . for a population of lif neurons ,",
    "its relation to the synaptic weight @xmath62 ( psp amplitude ) is derived in and .",
    "the normalized kernel @xmath58 ( with @xmath63 ) captures the time course of the linear response .",
    "it is determined by the single - neuron properties ( e.g.  the spike - initiation dynamics @xcite ) , the properties of the synapses ( e.g.  synaptic weights and time constants @xcite ) and the properties of the input ( e.g.  excitatory vs.  inhibitory input @xcite ) . for many real and model neurons ,",
    "the linear population - rate response exhibits low - pass characteristics @xcite . for illustration ( ) , we consider a 1st - order low - pass filter , i.e.  an exponential impulse response @xmath64 with time constant @xmath65 ( cutoff frequency @xmath66 ; see a , light gray curve in e ) .",
    "the results of our analysis are however independent of the choice of the kernel @xmath58 .",
    "the auto - correlation of the external noise is parametrized by the effective noise amplitude @xmath67 .",
    "given the simplified description , the suppression of response fluctuations by negative feedback can be understood intuitively : consider first the case where the neurons in the local network are unconnected ( a ; no feedback , @xmath68 ) . here , the response @xmath69 ( a@xmath70 ) is simply a low - pass filtered version of the external input @xmath71 ( a@xmath72 ) , resulting in an exponentially decaying response auto - correlation ( d ; light gray curve ) and a drop in the response power - spectrum at the cutoff frequency @xmath73 ( e ) . at low frequencies , @xmath69 and @xmath71",
    "are in phase ; they are correlated . in the presence of negative feedback ( b ) , the local input @xmath74 ( b@xmath75 ) and the low - frequency components of the external input @xmath71 ( b@xmath72 ) are anticorrelated .",
    "they partly cancel out , thereby reducing the response fluctuations @xmath69 ( b@xmath70 ) . the auto - correlation function and the power - spectrum",
    "are suppressed ( d , e ; black curves ) . due to the low - pass characteristics of the system , mainly the low - frequency components of the external drive @xmath71",
    "are transferred to the output side and , in turn , become available for the feedback signal .",
    "therefore , the canceling of input fluctuations and the resulting suppression of response fluctuations are most efficient at low frequencies .",
    "consequently , the auto - correlation function is sharpened ( see inset in d ) .",
    "the cutoff frequency of the system is increased ( e ; black curve ) .",
    "this effect of negative feedback is very general and well known in the engineering literature .",
    "it is employed in the design of technical devices , like , e.g. , amplifiers @xcite .",
    "as the zero - frequency power is identical to the integrated auto - correlation function , the suppression of low - frequency fluctuations is accompanied by a reduction in the auto - correlation area ( d ; black curve ) . note that the suppression of fluctuations in the feedback case is not merely a result of the additional inhibitory noise source provided by the local input , but follows from the precise temporal alignment of the local and the external input . to illustrate this , let s consider the case where the feedback channel is replaced by a feedforward input @xmath76 ( c ) which has the same auto - statistics as the response @xmath69 in the feedback case ( b@xmath70 ) but is uncorrelated to the external drive @xmath71 . in this case , external input fluctuations ( c@xmath72 ) are not canceled by the local input @xmath77 ( c@xmath75 ) . instead , the local feedforward input acts as an additional noise source which leads to an increase in the response fluctuations ( c@xmath70 ) .",
    "the response auto - correlation and power - spectrum ( d , e ; dark gray curves ) are increased .",
    "compared to the unconnected case ( e ; light gray curve ) , the cutoff frequency remains unchanged .     of a linear system with impulse response @xmath58 ( 1st - order low - pass , cutoff frequency @xmath78 ) to gaussian white noise input @xmath71 with amplitude @xmath79 for three local - input scenarios .",
    "* a * ( light gray ) : no feedback ( local input @xmath80 ) .",
    "* b * ( black ) : negative feedback ( @xmath81 ) with strength @xmath82 .",
    "the fluctuations of the weighted local input @xmath77 ( b@xmath75 ) are anticorrelated to the external drive @xmath71 ( b@xmath72 ) .",
    "* c * ( dark gray ) : feedback in b is replaced by uncorrelated feedforward input @xmath76 with the same auto - statistics as the response @xmath69 in b@xmath70 .",
    "the local input @xmath83\\left(t\\right)}$ ] is constructed by assigning a random phase @xmath84 to each fourier component @xmath85\\left(\\omega\\right)}$ ] of the response in b@xmath70 .",
    "fluctuations in c@xmath75 and c@xmath72 are uncorrelated . * a*,*b*,*c * : network sketches . * a@xmath72*,*b@xmath72*,*c@xmath72 * : external input @xmath71 . * a@xmath75*,*b@xmath75*,*c@xmath75 * : weighted local input @xmath86 . * a@xmath70*,*b@xmath70*,*c@xmath70 * : responses @xmath69 . * d*,*e * : response auto - correlation functions ( d ) and power - spectra ( e ) for the three cases shown in a , b , c ( same gray coding as in a , b , c ; inset in d : normalized auto - correlations ) .",
    ", title=\"fig : \" ]    the feedback induced suppression of response fluctuations can be quantified by comparing the response power - spectra @xmath87 } = \\frac{\\bar{\\rho}^2|h(\\omega)|^2}{|1+{\\bar{w}}{}h(\\omega)|^2}\\ ] ] and @xmath88 } = |h(\\omega)|^2({\\bar{w}}^2c_{rr}(\\omega)+\\bar{\\rho}^2)\\ ] ] in the feedback ( b ) and the feedforward case ( c ) , respectively ( see ) . here , @xmath89 and @xmath90 denote the fourier transforms of the response fluctuations in the feedback and the feedforward scenario , respectively , @xmath91 the transfer function ( fourier transform of the filter kernel @xmath58 ) of the neuron population , and @xmath92}$ ] the average across noise realizations .",
    "we use the power ratio @xmath93 as a measure of the relative fluctuation suppression caused by feedback . for low frequencies ( @xmath94 ) and strong effective coupling @xmath95",
    ", the power ratio decays as @xmath96 ( see a ) : the suppression of population - rate fluctuations is promoted by strong negative feedback . in line with the observations in , this suppression is restricted to low frequencies ; for high frequencies ( @xmath97 , i.e.  @xmath98 ) , the power ratio @xmath99 approaches @xmath100 .",
    "note that the power ratio is independent of the amplitude @xmath101 of the population averaged external input @xmath71 .",
    "therefore , even if we dropped the assumption of the external inputs @xmath102 being uncorrelated , i.e.  if @xmath103}\\ne{}0 $ ] for @xmath29 , the power ratio remained the same . for correlated external input , the power @xmath101 of the population average @xmath71 is different from @xmath104 .",
    "the suppression factor @xmath99 , however , is not affected by this .",
    "moreover , it is straightforward to show that the power ratio is , in fact , independent of the shape of the external - noise spectrum @xmath105}$ ] . the same result is obtained for any type of external input ( e.g.  colored noise or oscillating inputs ) .     on the effective coupling strength @xmath61 ( solid curves : full solutions ; dashed lines : strong - coupling approximations ) .",
    "the power ratio @xmath106 represents the ratio between the low - frequency population - rate power in the recurrent networks ( * a * : b ; * b * : a , b ) and in networks where the feedback channels are replaced by uncorrelated feedforward input ( * a * : c ; * b * , black : c , d ; * b * , gray : d ) . dotted curves in * b * depict power ratio of the sum modes @xmath107 and @xmath108 ( see text ) .",
    "b : balance factor @xmath109 . , title=\"fig : \" ]    for low frequencies , the transfer function @xmath91 approaches unity ( @xmath110 ) ; the exact shape of the kernel @xmath58 becomes irrelevant .",
    "in particular , the cutoff frequency ( or time constant ) of a low - pass kernel has no effect on the zero - frequency power ( integral correlation ) and the zero - frequency power ratio @xmath106 ( ) .",
    "therefore , the suppression of low - frequency fluctuations does not critically depend on the exact choice of the neuron , synapse or input model .",
    "the same reasoning applies to synaptic delays : replacing the kernel @xmath58 by a delayed kernel @xmath111 leads to an additional phase factor @xmath112 in the transfer function @xmath91 . for sufficiently small frequencies ( long time scales ) ,",
    "this factor can be neglected ( @xmath113 ) .    for networks with purely inhibitory feedback ,",
    "the absolute power of the population rate decreases monotonously with increasing coupling strength @xmath61 .",
    "as we will demonstrate in and , this is qualitatively different in networks with mixed excitatory and inhibitory coupling @xmath114 and @xmath115 , respectively : here , the fluctuations of the compound activity increase with @xmath61 .",
    "the power ratio @xmath99 , however , still decreases with @xmath61 .      in the foregoing subsection",
    ", we have shown that negative feedback alone can efficiently suppress population - rate fluctuations and , hence , spike - train correlations .",
    "so far , it is unclear whether the same reasoning applies to networks with mixed excitatory and inhibitory coupling . to clarify this",
    ", we now consider a random network composed of a homogeneous excitatory and inhibitory subpopulation @xmath116 and @xmath117 of size @xmath118 and @xmath119 , respectively .",
    "each neuron receives @xmath120 excitatory and @xmath121 inhibitory inputs from @xmath116 and @xmath117 with synaptic weights @xmath122 and @xmath123 , respectively .",
    "in addition , the neurons are driven by external gaussian white noise .",
    "as demonstrated in , linearization and averaging across subpopulations leads to a two - dimensional system @xmath124*h)(t)\\ ] ] describing the linearized dynamics of the subpopulation averaged activity @xmath125 . here , @xmath126 denotes the subpopulation averaged external uncorrelated white - noise input with correlation functions @xmath127}=\\bar{\\rho}_p^2\\delta_{pq}\\delta(\\tau)$ ] ( @xmath128 , @xmath129 ) , and @xmath58 a normalized linear kernel with @xmath130 .",
    "the excitatory and inhibitory subpopulations are coupled through an effective connectivity matrix @xmath131 with effective weight @xmath132 and balance parameter @xmath133 .    the two - dimensional system / represents a recurrent system with both positive and negative feedback connections ( a ) . by introducing new coordinates",
    "@xmath134 and @xmath135 , @xmath136 , we obtain an equivalent representation of / , @xmath137*h \\right)(t )     \\,,\\ ] ] describing the dynamics of the sum and difference activity @xmath138 and @xmath139 , respectively , i.e.  the in- and anti - phase components of the excitatory and inhibitory subpopulations ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "the new coupling matrix @xmath140 reveals that the sum mode @xmath138 is subject to self - feedback ( @xmath141 ) and receives feedforward input from the difference mode @xmath139 ( @xmath142 ) .",
    "all remaining connections are absent ( @xmath143 ) in the new representation ( see b ) .",
    "the correlation functions of the external noise in the new coordinates are given by @xmath127}=\\bar{\\rho}_{pq}^2\\delta(\\tau)$ ] with @xmath144 ( @xmath145 ) .",
    "the feedforward coupling is positive ( @xmath146 ) : an excitation surplus ( @xmath147 ) will excite all neurons in the network , an excitation deficit ( @xmath148 ) will lead to global inhibition . in inhibition dominated regimes with @xmath149 , the self - feedback of the sum activity @xmath138 is effectively negative ( @xmath150 ) .",
    "the dynamics of the sum rate in inhibition - dominated excitatory - inhibitory networks is therefore qualitatively similar to the dynamics in purely inhibitory networks ( ) . as shown below , the negative feedback loop exposed by the transform leads to an efficient relative suppression of population - rate fluctuations ( if compared to the feedforward case ) .",
    "mathematically , the coordinate transform corresponds to a _ schur decomposition _ of the dynamics : any recurrent system of type ( with arbitrary coupling matrix @xmath151 ) can be transformed to a system with a triangular coupling matrix ( see e.g. * ? ? ?",
    "the resulting coupling between the different schur modes can be ordered so that there are only connections from modes with lower index to modes with the same or larger index . in this sense , the resulting system has been termed feedforward @xcite .",
    "the original coupling matrix @xmath151 is typically not normal , i.e.  @xmath152 .",
    "its eigenvectors do not form an orthogonal basis . by performing a gram - schmidt orthonormalization of the eigenvectors , however , one can obtain a ( normalized ) orthogonal basis , a schur basis .",
    "our new coordinates correspond to the amplitudes ( the time evolution ) of two orthogonal schur modes .",
    "the spectra @xmath153 , @xmath154 , @xmath155 and @xmath156 of the subpopulation averaged rates @xmath157 , @xmath158 and the sum mode @xmath107 , respectively , are derived in .",
    "in contrast to the purely inhibitory network ( see ) , the population - rate fluctuations of the excitatory - inhibitory network increase monotonously with increasing coupling strength @xmath61 . for strong coupling , @xmath159 approaches @xmath160 from below with @xmath161 .",
    "close to the critical point ( @xmath162 ) , the rate fluctuations become very large ; diverges . increasing the amount of inhibition by increasing @xmath163",
    ", however , leads to a suppression of these fluctuations . in the limit @xmath164 , @xmath159 and",
    "approach the spectrum of the unconnected network . for strong coupling ( @xmath165 ) ,",
    "the ratio @xmath166 approaches @xmath167 : the fluctuations of the population averaged excitatory firing rate exceed those of the inhibitory population by a factor @xmath167 ( independently of @xmath91 and @xmath168 ) .    similarly",
    "to the strategy we followed in the previous subsections , we will now compare the population - rate fluctuations of the feedback system , or equivalently , to the case where the feedback channels are replaced by feedforward input with identical auto - statistics .",
    "a straight - forward implementation of this is illustrated in c : here , the excitatory and inhibitory feedback channels @xmath169 and @xmath170 are replaced by uncorrelated feedforward inputs @xmath171 and @xmath172 , respectively .",
    "the schur representation of this scenario is depicted in d. according to , the fourier transforms of the response fluctuations of this system read @xmath173    \\,.\\ ] ] with @xmath174 , and using @xmath175 , @xmath176 , @xmath177 , we can express the spectrum @xmath178 of the sum activity in the feedforward case in terms of the spectra @xmath153 and @xmath154 of the feedback system ( see eq .  ) .",
    "for strong coupling ( @xmath165 ) , the zero - frequency component ( @xmath179 ) becomes @xmath180 thus , for strong coupling , the zero - frequency power ratio @xmath181 reveals a relative suppression of the population - rate fluctuations in the feedback system which is proportional to @xmath182 ( see b ; black dashed line ) .",
    "the power ratio @xmath183 for arbitrary weights @xmath61 is depicted in b ( black dotted curve ) . for a network at the transition point",
    "@xmath184 , equals @xmath185 . increasing the level of inhibition by increasing @xmath163 leads to a decrease in the power ratio : in the limit @xmath164 , approaches @xmath186 monotonously .",
    "above , we suggested that the negative self - feedback of the sum mode @xmath187 , weighted by @xmath188 ( b ) , is responsible for the fluctuation suppression in the recurrent excitatory - inhibitory system .",
    "here , we test this by considering the case where this feedback loop is opened and replaced by uncorrelated feedforward input @xmath189 , weighted by @xmath188 , while the feedforward input from the difference mode @xmath190 , weighted by @xmath191 , is left intact ( see d ) . as before , we assume that the auto - statistics of @xmath189 is identical to the auto - statistics of @xmath187 as obtained in the feedback case , i.e.  @xmath192 . according to the schur representation of the population dynamics / , the fourier transform of the sum mode of this modified system",
    "is given by @xmath193 with @xmath194 given in and @xmath195 , we obtain the power ratio @xmath196 its zero - frequency component @xmath197 is shown in b ( gray dotted curve ) . for strong coupling ,",
    "the power ratio decays as @xmath198 ( gray dashed line in b ) .",
    "thus , the ( relative ) power in the recurrent system is reduced by strengthening the negative self - feedback loop , i.e.  by increasing @xmath199 .",
    "so far , we have presented results for the subpopulation averaged firing rates @xmath200 and @xmath201 and the sum mode @xmath138 .",
    "the spectrum of the compound rate @xmath202 $ ] , i.e.  the activity averaged across the entire population , reads @xmath203\\right )     \\,.\\ ] ] in the feedforward scenario depicted in c , the spectrum of the compound rate @xmath204 ( with @xmath205 ) is given by @xmath206 for strong coupling , the corresponding low - frequency power ratio @xmath207 ( black solid curve in b ) exhibits qualitatively the same decrease @xmath208 as the sum mode .    to summarize the results of this subsection : the population dynamics of a recurrent network with mixed excitatory and inhibitory coupling can be mapped to a two - dimensional system describing the dynamics of the sum and the difference of the excitatory and inhibitory subpopulation activities .",
    "this equivalent representation uncovers that , in inhibition dominated networks ( @xmath209 ) , the sum activity is subject to negative self - feedback .",
    "thus , the dynamics of the sum activity in excitatory - inhibitory networks is qualitatively similar to the population dynamics of purely inhibitory networks ( see ) . indeed",
    ", the comparison of the compound power - spectra of the intact recurrent network and networks where the feedback channels are replaced by feedforward input reveals that the ( effective ) negative feedback in excitatory - inhibitory networks leads to an efficient suppression of population - rate fluctuations .",
    "the results presented in the previous subsections describe the fluctuations of the compound activity .",
    "pairwise correlations @xmath210}$ ] between the ( centralized ) spike trains @xmath211}$ ] are outside the scope of such a description . in this subsection",
    ", we consider the same excitatory - inhibitory network as in and present a theory for the population averaged spike - train cross - correlations . in general",
    ", this is a hard problem . to understand the structure of cross - correlations ,",
    "it is however sufficient to derive a relationship between the cross- and auto - covariances in the network , because the latter can , to good approximation , be understood in mean - field theory .",
    "the integral of the auto - covariance function of spiking lif neurons can be calculated by fokker - planck formalism @xcite . to determine the relation between the cross - covariance and the auto - covariance",
    ", we replace the spiking dynamics by a reduced linear model whose covariances , to linear order , obey the same relation .",
    "we present the full derivation in .",
    "there , we first derive an approximate linear relation between the auto- and cross - covariance functions @xmath212 and @xmath213 , respectively , of the lif network .",
    "a direct solution of this equation is difficult . in the second step ,",
    "we therefore show that there exists a linear stochastic system with activity @xmath214 whose correlations @xmath215 and @xmath216 fulfill the same equation as the original lif model .",
    "this reduced model can be solved in the frequency domain by standard fourier methods .",
    "its solution allows us , by construction , to determine the relation between the integral cross - covariances @xmath217 and the integral auto - covariances @xmath218 up to linear order .",
    "as we are interested in the covariances averaged over many pairs of neurons , we average the resulting set of @xmath0 linear self - consistency equations for the covariance matrix in the frequency domain @xmath219 over statistically identical pairs of neurons and many realizations of the random connectivity ( see ) .",
    "this yields a four - dimensional linear system describing the population averaged variances @xmath220 and @xmath221 of the excitatory and inhibitory subpopulations , and the covariances @xmath222 and @xmath223 for unconnected excitatory - excitatory and inhibitory - inhibitory neuron pairs , respectively ( note that we use the terms `` variance '' and `` covariance '' to describe the _ integral _ of the auto- and cross - correlation function , respectively ; in many other studies , they refer to the zero - lag correlation functions instead ) .",
    "the dependence of the variances and covariances on the coupling strength @xmath61 , obtained by numerically solving , is shown in .",
    "we observe that the variances @xmath220 and @xmath221 of excitatory and inhibitory neurons are barely distinguishable ( a ) . with the approximation @xmath224 , explicit expressions can be obtained for the covariances ( thick dashed curves e ) : @xmath225 the deviations from the full solutions ( thin solid curves in e ) , i.e.  for @xmath226 , are small . in the reduced model , both the external input and the spiking of individual neurons",
    "contribute to an effective noise .",
    "as the fluctuations in the reduced model depend linearly on the amplitude @xmath227 of this noise , the variances @xmath228 and covariances @xmath229 ( @xmath129 ) can be expressed in units of the noise variance @xmath230 .",
    "consequently , the correlation coefficients @xmath231 are independent of @xmath230 ( see ) .",
    "the analytical form of the result shows that the correlations are smaller than expected given the amount of shared input a pair of neurons receives : the quantity @xmath232 in the first line is the contribution of shared input to the covariance . for strong coupling @xmath165 ,",
    "the prefactor @xmath233 causes a suppression of this contribution .",
    "its structure is typical for a feedback system , similar to the solution of the one - population or the solution of the two - population model .",
    "the term @xmath234 in the denominator represents the negative feedback of the compound rate .",
    "the prefactor @xmath235 in the second line of is again due to the feedback and suppresses the contribution of the factor @xmath236 , which represents the effect of direct connections between neurons .",
    "our results are consistent with a previous study of the decorrelation mechanism : in @xcite , the authors considered how correlations scale with the size @xmath0 of the network where the synaptic weights are chosen as @xmath237 . as a result ,",
    "the covariance @xmath232 in caused by shared input is independent of the network size , while the feedback @xmath238 scales  to leading order  as @xmath239 ( see ) .",
    "consequently , the first line in scales as @xmath240 .",
    "the same scaling holds for the second line in , explaining the decay of correlations as @xmath240 found in @xcite .",
    "the first line in is identical for any pair of neurons .",
    "the second line is positive for a pair of excitatory neurons and negative for a pair of inhibitory neurons . in other words ,",
    "excitatory neurons are more correlated than inhibitory ones .",
    "together with the third line in , this reveals a peculiar correlation structure : @xmath241 ( b , e ) . for strong coupling @xmath165 ,",
    "the difference between the excitatory and inhibitory covariance is .",
    "the difference decreases as the level @xmath163 of inhibition is increased , i.e.  the further the network is in the inhibition dominated regime , away from the critical point @xmath184 .     in a linearized homogeneous network with excitatory - inhibitory coupling . *",
    "a * : spike - train variances @xmath220 ( black ) and @xmath221 ( gray ) of excitatory and inhibitory neurons .",
    "* b * : spike - train covariances @xmath242 ( black solid ) , @xmath243 ( dark gray solid ) and @xmath244 ( light gray solid ) for excitatory - excitatory , excitatory - inhibitory and inhibitory - inhibitory neuron pairs in the recurrent network , respectively , and shared - input contribution @xmath232 ( black dotted curve ; feedforward case ) .",
    "* c * : decomposition of the total input covariance @xmath245 ( light gray ) into shared - input covariance @xmath232 ( black ) and weighted spike - train covariance @xmath246 ( dark gray ) .",
    "covariances in a , b and c are given in units of the noise variance @xmath230 . *",
    "d * : input - correlation coefficient @xmath247 in the recurrent network ( black solid curve ) . in the feedforward case , the input - correlation coefficient is identical to the network connectivity @xmath18 ( horizontal dotted line ) . *",
    "e * : spike - train correlation coefficients @xmath248 ( black ) , @xmath249 ( dark gray ) and @xmath250 ( solid light gray curve ) for excitatory - excitatory , excitatory - inhibitory and inhibitory - inhibitory neuron pairs , respectively .",
    "thick dashed curves represent approximate solutions assuming @xmath251 . *",
    "f * : low - frequency ( lf ) power ratios @xmath35 ( black ) , @xmath252 ( dark gray ) , @xmath253 ( solid light gray ) for the population rate @xmath69 and the excitatory and inhibitory subpopulation rates @xmath200 and @xmath201 , respectively .",
    "the lf power ratio represents the ratio between the lf spectra in the recurrent network and for the case where the feedback channels are replaced by feedforward input with @xmath254 ( cf .",
    "thick dashed curves in f show power ratios obtained by assuming that the auto - correlations are identical in the feedback and the feedforward scenario ( see main text ) .",
    "vertical dotted lines mark the stability limit of the linear model ( see ) .",
    "a  f : @xmath255 , @xmath21 , @xmath256 , @xmath257 , @xmath258 , @xmath259 .",
    ", title=\"fig : \" ]    to understand the suppression of shared - input correlations in recurrent excitatory - inhibitory networks , consider the correlation between the local inputs",
    "@xmath260_{k / l}$ ] of a pair of neurons @xmath261 , @xmath262 .",
    "the input - correlation coefficient @xmath263}/\\sqrt{{\\text{var}_{}\\left[i_k\\right]}{\\text{var}_{}\\left[i_l\\right]}}$ ] can be expressed in terms of the averaged spike - train covariances : @xmath264 } = c^{\\text{in}}_\\text{shared } + c^{\\text{in}}_\\text{corr}\\\\          a^{\\text{in}}&= { \\text{var}_{}\\left[i_k\\right ] } = \\epsilon^{-1 } { \\bar{w}}^2 \\left ( \\frac{1}{n_{\\text{e } } } + \\frac{{\\bar{g}}^2}{n_{\\text{i } } } \\right ) a + c^{\\text{in}}_\\text{corr}\\\\      \\text{with}\\quad &      c^{\\text{in}}_\\text{corr } = { \\bar{w}}^2 ( c_{{\\text{e}}{\\text{e } } } - 2 { \\bar{g}}c_{{\\text{e}}{\\text{i } } } + { \\bar{g}}^2 c_{{\\text{i}}{\\text{i } } } )            \\end{aligned}\\end{aligned}\\ ] ] ( see : the input covariance @xmath245 equals the average quantity @xmath265 given in , the input variance @xmath266 is given by as @xmath267 ) . the term @xmath232 represents the contribution due to the spike - train variances of the shared presynaptic neurons ( see ) .",
    "this contribution is always positive ( provided the network architecture is consistent with dale s law ; see @xcite ) . in a purely feedforward scenario with uncorrelated presynaptic sources",
    ", @xmath232 is the only contribution to the input covariance of postsynaptic neurons .",
    "the resulting response correlation for this feedforward case is much larger than in the feedback system ( b , black dotted curve ) .",
    "the correlation coefficient between inputs to a pair of neurons in the feedforward case is identical to the network connectivity @xmath18 ( horizontal dotted curve in d ; see * ? ? ?",
    "in an inhibition dominated recurrent network , spike - train correlations between pairs of different source neurons contribute the additional term @xmath246 , which is negative and of similar absolute value as the shared - input contribution @xmath232 .",
    "thus , the two terms @xmath232 and @xmath246 partly cancel each other ( see c ) . in consequence , the resulting input correlation coefficient @xmath247 is smaller than @xmath18 ( see d ; here : @xmath21 ) .",
    "the correlations in a purely inhibitory network can be obtained from by replacing @xmath268 , taking into account the negative sign of @xmath269 in @xmath270 and setting @xmath271 and @xmath272 : @xmath273 for finite coupling strength @xmath274 , this expression is negative .",
    "the contributions of shared input and spike - train correlations to the input correlation are given by @xmath275 and @xmath276 , respectively ( see and ) .",
    "using , we can directly verify that @xmath277 , because pairwise correlations @xmath278 are negative , leading to a partial cancellation @xmath279 : the right hand side is smaller in magnitude by a factor of @xmath280 compared to each individual contribution .",
    "hence , as in the network with excitation and inhibition , shared - input correlations are partly canceled by the contribution due to presynaptic pairwise spike - train correlations . in the feedforward scenario with zero presynaptic spike - train correlations , in contrast , the response correlations are determined by shared input alone and are therefore increased .",
    "the suppression of shared - input correlations in the feedback case is what we call decorrelation in the current work . in purely inhibitory networks ,",
    "this decorrelation is caused by weakly negative pairwise correlations .",
    "for sufficiently strong negative feedback , correlations are smaller in absolute value as compared to the feedforward case .",
    "the absolute value of these anti - correlations is bounded by @xmath281 .",
    "the similarity in the results obtained for purely inhibitory networks and excitatory - inhibitory networks demonstrates that the suppression of pairwise correlations and population - activity fluctuations is a generic phenomenon in systems with negative feedback .",
    "it does not rely on an internal balance between excitation and inhibition .    as discussed in ,",
    "the suppression of correlations in the recurrent network is accompanied by a reduction of population - activity fluctuations . with",
    "the population averaged correlations , the power of the population activity @xmath69 reads @xmath282    \\,.\\ ] ] in , we showed that the population - activity fluctuations are amplified if the local input in the recurrent system is replaced by feedforward input from independent excitatory and inhibitory populations ( see c ) .",
    "this manipulation corresponds to a neglect of correlations @xmath243 between excitatory and inhibitory neurons .",
    "all remaining correlations ( @xmath220 , @xmath221 , @xmath242 , @xmath244 ) are preserved . with the resulting response auto- and cross - correlations @xmath283 and @xmath284 given by",
    ", the power of the population activity becomes @xmath285 for large effective coupling @xmath61 , the power ratio @xmath286 decays as @xmath182 ( black curve in f ) .",
    "note that the power ratio @xmath35 derived here is indistinguishable from the one we obtained in the framework of the population model in ( black solid curve in b ) .",
    "although the derivation of the macroscopic model in is qualitatively different from the one leading to the population averaged correlations described here , the two models are consistent : they describe one and the same system and lead to identical power ratios .",
    "the fluctuation suppression is not only observed at the level of the entire network , i.e.  for the population activity @xmath69 , but also for each individual subpopulation @xmath116 and @xmath117 , i.e.  for the subpopulation averaged activities @xmath200 and @xmath201 . the derivation of the corresponding power ratios @xmath252 and @xmath253 is analog to the one described above . as a result of the correlation structure @xmath287 in the feedback system ( see b ) , the power of the inhibitory population activity is smaller than the power of the excitatory population activity . in consequence , @xmath288 ( gray curves in f ) .    in and ,",
    "the auto - correlations are scaled by @xmath240 , while the cross - correlations enter with a prefactor of order unity . for large @xmath0",
    ", one may therefore expect that the suppression of population - activity fluctuations is essentially mediated by pairwise correlations . in the recurrent system , however , the cross - correlations @xmath289 ( @xmath290 ) are of order @xmath281 ( see and ) .",
    "it is therefore a priori not clear whether the fluctuation suppression is indeed dominated by pairwise correlations . in our framework",
    ", one can explicitly show that the auto - correlation is irrelevant : replacing the auto - correlation @xmath283 in by the average auto - correlation @xmath291 of the intact feedback system has no visible effect on the resulting power ratio ( dashed curves in f ) .",
    "the difference in the spectra of the population activities @xmath292 and @xmath293 is therefore essentially caused by the cross - correlations .",
    "the absolute population - activity fluctuations in purely inhibitory and in excitatory - inhibitory networks show a qualitatively different dependence on the synaptic coupling @xmath61 , in agreement with the previous sections . in networks with excitation and inhibition , the correlation coefficient increases with increasing synaptic coupling ( see e ) .",
    "hence , the population - activity fluctuations grow with increasing coupling strength . in purely inhibitory networks ,",
    "in contrast , the pairwise spike - train correlation decreases monotonously with increasing magnitude of the coupling strength @xmath61 , see . in consequence , the population - activity fluctuations decrease .",
    "the underlying reason is that , in the inhibitory network , the power of the population activity is directly proportional to the covariance of the input currents , which is actively suppressed , as shown above . for excitatory - inhibitory networks ,",
    "these two quantities are not proportional ( compare and ) due to the different synaptic weights appearing in the input covariance .",
    "to compare our theory to simulations of spiking lif networks , we need to determine the effect of a synaptic input on the response activity of the neuron model . to this end",
    ", we employ the fokker - planck theory of the lif model ( see ) . in this context , the steady state of the recurrent network is characterized by the mean @xmath294 and the standard deviation @xmath295 of the total synaptic input . both @xmath294 and @xmath295",
    "depend on the steady - state firing rate in the network .",
    "the steady - state firing rate can be determined in a self - consistent manner @xcite as the fixed point of the firing rate approximation .",
    "the approximation predicts the firing rate to sufficient accuracy of about @xmath296 ( see a ) .",
    "we then obtain an analytical expression of the low - frequency transfer which relates the fluctuation @xmath297 of a synaptic input to neuron @xmath5 to the fluctuation of neuron @xmath5 s response firing rate to linear order , so that @xmath298 .",
    "this relates the postsynaptic potential @xmath299 in the lif model to the effective linear coupling @xmath300 in our linear theory .",
    "the functional relation @xmath301 can be derived in analytical form by linearization of about the steady - state working point .",
    "note that @xmath301 depends on @xmath294 and @xmath295 and , hence , on the steady - state firing rate in the network .",
    "the derivation outlined in constitutes an extension of earlier work @xcite to quadratic order in @xmath62 .",
    "the results agree well with those obtained by direct simulation for a large range of synaptic amplitudes ( see ) .",
    "b compares the population averaged correlation coefficients @xmath302 obtained from the linear reduced model , see , and simulations of lif networks .",
    "note that the absolute value of the noise amplitude @xmath227 in the reduced model does not influence the correlation coefficient @xmath302 , as both quantities @xmath278 and @xmath228 depend linearly on @xmath230 .",
    "theory and simulation agree well for synaptic weights up to @xmath303 . for larger synaptic amplitudes ,",
    "the approximation of the effective linear transfer for a single neuron obtained from the fokker - planck theory deviates from its actual value ( see b ) .",
    "c shows that the cancellation of the input covariance in the lif network is well explained by the theory .",
    "previous work @xcite suggested that positive correlations between excitatory and inhibitory inputs lead to a negative component in the input correlation which , in turn , suppresses shared - input correlations .",
    "the mere existence of positive correlations between excitatory and inhibitory inputs is however not sufficient . to explain the effect , it is necessary to take the particular correlation structure @xmath304 into account . to illustrate this ,",
    "consider the case where the correlation structure is destroyed by replacing all pairwise correlations in the input spike - train ensemble by the overall population average ( homogenization of correlations ) .",
    "the resulting response correlations ( upper gray curve in b ) are derived in , eq .  .",
    "in simulations of lif networks , we study the effect of homogenized spike - train correlations by first recording the activity of the intact recurrent network , randomly reassigning the neuron type ( @xmath305 or @xmath306 ) to each recorded spike train , and feeding this activity into a second population of neurons . compared to the intact recurrent network ,",
    "the response correlations are significantly larger ( b ) .",
    "the contribution of homogenized spike - train correlations to the input covariance @xmath245 ( see ) is given by .",
    "for positive spike - train correlations @xmath307 , this contribution is greater or equal zero ( zero for @xmath184 ) .",
    "hence , it can not compensate the ( positive ) shared - input contribution @xmath232 ( see c ) . in consequence ,",
    "input correlations , output correlations and , in turn , population - rate fluctuations ( d ) can not be suppressed by homogeneous positive correlations in the input spike - train ensemble .",
    "canceling of shared - input correlations requires either negative spike - train correlations ( as in purely inhibitory networks ) or a heterogeneity in correlations across different pairs of neurons ( e.g.  @xmath304 ) .",
    "( psp amplitude ) in a recurrent excitatory - inhibitory network ( feedback system , fb ) and in a population of unconnected neurons receiving randomized feedforward input ( feedforward system , ff ) from neurons in the recurrent network .",
    "average presynaptic firing rates and shared - input structure are identical in the two systems . in the ff case ,",
    "the average correlations between presynaptic spike - trains are homogenized ( i.e.  @xmath308 ) as a result of the random reassignment of presynaptic neuron types .",
    "the mapping of the lif dynamics to the linear reduced dynamics ( ) relates the psp amplitude @xmath62 to the effective coupling strength @xmath301 by , as shown in b. * a * : average firing rates @xmath309 in the fb ( black up - triangles : excitatory neurons ; gray down - triangles : inhibitory neurons ) and in the ff system ( open circles ) .",
    "analytical prediction ( gray curve ) .",
    "* b * : spike - train correlation coefficients @xmath248 ( black up - triangles ) , @xmath249 ( gray squares ) and @xmath250 ( gray down - triangles ) for excitatory - excitatory , excitatory - inhibitory , and inhibitory - inhibitory neuron pairs , respectively , in the fb system . analytical prediction ( gray curves ) .",
    "spike - train correlation coefficient @xmath310 ( open circles ) in the ff system with homogenized presynaptic spike - train correlations .",
    "analytical prediction ( underlying gray curve ) .",
    "* c * : shared - input ( @xmath232 ; black up - triangles ) and spike - correlation contribution @xmath246 ( fb : gray down - triangles ; ff : open circles ) to the input correlation @xmath245 ( normalized by @xmath311 ) . analytical predictions . *",
    "d * : low - frequency ( lf ) power ratio of the compound activity .",
    "vertical dotted lines in a  d mark the stability limit of the linear model ( see ) .",
    "@xmath312 , @xmath255 , @xmath256 , @xmath257 .",
    "size of postsynaptic population in the ff case : @xmath313 .",
    "simulation time : @xmath50 .",
    ", title=\"fig : \" ]      in the previous subsections , we quantified the suppression of population - rate fluctuations in recurrent networks by comparing the activity in the intact recurrent system ( feedback scenario ) to the case where the feedback is replaced by feedforward input with some predefined statistics ( feedforward scenario ) .",
    "we particularly studied the effect of neglecting the auto - statistics of the compound feedback , ( the structure of ) correlations within the feedback ensemble and/or correlations between the feedback and the external input . in all cases",
    ", we observed a significant amplification of population - activity fluctuations in the feedforward scenario . in this subsection",
    ", we further investigate the role of different types of feedback manipulations by means of simulations of lif networks with excitatory - inhibitory coupling .",
    "to this end , we record the spiking activity of the recurrent network ( feedback case ) , apply different types of manipulations to this activity ( described in detail below ) and feed this modified activity into a second population of identical ( unconnected ) neurons ( feedforward case ) . as before , the connectivity structure ( in - degrees , shared - input structure , synaptic weights ) is exactly identical in the feedback and the feedforward case .    in , we show that the low - frequency fluctuations of the population rate @xmath44 of the spiking model are captured by the reduced model @xmath69 presented in the previous subsections . to verify that the theory based on excitatory and inhibitory population rates is indeed sufficient to explain the decorrelation mechanism , we first consider the case where the sender identities of the presynaptic spike train are randomly shuffled .",
    "a shows the power - spectrum of the population activity recorded in the original network ( fb ) as well as the spectra obtained after shuffling spike - train identities within the excitatory and inhibitory subpopulations separately ( shuff2d ) , or across the entire network ( shuff1d ) .",
    "as shuffling of neuron identities does not change the population rates , all three compound spectra are identical .",
    "b shows the response power - spectra of the neuron population receiving the shuffled spike trains .",
    "shuffling within the subpopulations ( shuff2d ) preserves the population - specific fluctuations and average correlations .",
    "the effect on the response fluctuations is negligible ( compare black and light gray curves in b ) . in particular",
    ", the power of low - frequency fluctuations remains unchanged ( c ) .",
    "this result confirms that population models which take excitatory and inhibitory activity separately into account are sufficient to explain the observations .",
    "shuffling of spike - train identities across subpopulations ( shuff1d ) , in contrast , causes an increase in the population fluctuations by about one order of magnitude ( b , c ; dark gray ) .",
    "this outcome is in agreement with the result obtained by homogenizing pairwise correlations ( see ) and demonstrates that the excitatory and inhibitory subpopulation rates have to be conserved to explain the observed fluctuation suppression .",
    "the shuffling experiments and the results of the linear model in the previous subsections suggest that the precise temporal structure of the _ population averaged _ activities within homogeneous subpopulations is essential for the suppression of population - rate fluctuations . preserving the exact structure of individual spike trains",
    "is not required .",
    "this is confirmed by simulation experiments where new sender identities were randomly reassigned for each individual presynaptic spike ( rather than for each spike train ; data not shown ) .",
    "this operation destroys the structure of individual spike trains but preserves the compound activities .",
    "the results are similar to those reported here .",
    "so far , it is unclear how sensitive the fluctuation - suppression mechanism is to perturbations of the temporal structure of the population rates . to address this question , we replaced the excitatory and inhibitory spike trains in the feedback ensemble by independent realizations of inhomogeneous poisson processes ( poissi ) with intensities given by the measured excitatory and inhibitory population rates @xmath314 and @xmath315 of the recurrent network , respectively .",
    "note that the compound rates of a single realization of this new spike - train ensemble are similar but not identical to the original population rates @xmath314 , @xmath315 ( in each time window @xmath316 , the resulting spike count is a random number drawn from a poisson distribution with mean and variance proportional to @xmath314 and @xmath315 , respectively ) .",
    "although the compound spectrum of the resulting local input is barely distinguishable from the compound spectrum of the intact recurrent system ( d ; black and dark gray curves ) , the response spectra are very different : replacing the feedback ensemble by inhomogeneous poisson processes leads to a substantial amplification of low - frequency fluctuations ( e ; compare black and dark gray curves ) .",
    "the effect is as strong as if the temporal structure of the population rates was completely ignored , i.e.  if the feedback channels were replaced by realizations of homogeneous poisson processes with constant rates ( poissh ; light gray curves in d , e ) .",
    "this result indicates that the precise temporal structure of the population rates is essential and that even small deviations can significantly weaken the fluctuation - suppression mechanism .",
    "the results of the poisson experiments can be understood by considering the effect of the additional noise caused by the stochastic realization of individual spikes .",
    "considering the auto - correlation , a poisson spike - train ensemble with rate profile @xmath317 is equivalent to a sum of the rate profile and a noise term resulting from the stochastic ( poissonian ) realization of spikes , @xmath318 . here , @xmath319 denotes a gaussian white noise with auto - correlation @xmath320 } = { \\bm{1 } } \\delta(s)$ ] and the mean firing rate .",
    "the response fluctuations of the population driven by the rate modulated poisson activity are , to linear approximation , given by @xmath321 . inserting @xmath322",
    ", we obtain an additional noise term @xmath323 in the spectrum @xmath324 which explains the increase in power compared to the spectrum @xmath325 of the recurrent network . as a generalization of the poisson model , one may replace the noise amplitude @xmath326 by some arbitrary prefactor @xmath55 . in simulation experiments , we observed a gradual amplification of the population - rate fluctuations with increasing noise amplitude @xmath55 ( data not shown ) .     of input spike - train ensembles .",
    "* b*,*e * : power - spectra @xmath293 of population - response rates .",
    "* c*,*f * : low - frequency ( lf ; @xmath100@xmath327 ) power ratio @xmath35 ( increase in lf power relative to the unperturbed case [ fb ] ; logarithmic scaling ) .",
    "note that in a , the compound - input spectra ( fb , shuff1d , shuff2d ) are identical . in d ,",
    "the input spectra for the intact recurrent network ( fb ) and the inhomogeneous - poisson case ( poissi ) are barely distinguishable .",
    "see and for details on the network model and parameters .",
    "simulation time @xmath50 .",
    "single - trial spectra smoothed by moving average ( frame size @xmath51 ) .",
    ", title=\"fig : \" ]",
    "we have shown that negative feedback in recurrent neural networks actively suppresses low - frequency fluctuations of the population activity and pairwise correlations .",
    "this mechanism allows neurons to fire more independently than expected given the amount of shared presynaptic input .",
    "we demonstrated that manipulations of the feedback statistics , e.g.  replacing feedback by uncorrelated feedforward input , can lead to a significant amplification of response correlations and population - rate fluctuations .",
    "the suppression of correlations and population - rate fluctuations by feedback can be observed in networks with both purely inhibitory and mixed excitatory - inhibitory coupling . in purely inhibitory networks ,",
    "the effect can be understood by studying the role of the effective negative feedback experienced by the compound activity . in networks of excitatory and inhibitory neurons ,",
    "a change of coordinates , technically a schur decomposition , exposes the underlying feedback structure : the sum of the excitatory and inhibitory activity couples negatively to itself if the network is in an inhibition dominated regime ( which is required for its stability ; ( see e.g. * ? ? ? * ) ) .",
    "this negative feedback suppresses fluctuations in a similar way as in purely inhibitory networks .",
    "the fluctuation suppression becomes more efficient the further the network is brought into the inhibition dominated regime , away from the critical point of equal recurrent excitation and inhibition ( @xmath328 ) .",
    "having identified negative feedback as the underlying cause of small fluctuations and correlations , we can rule out previous explanations based on a balance between ( correlated ) excitation and inhibition @xcite .",
    "we presented a self - consistent theory for the average pairwise spike - train correlations which illuminates that the suppression of population - rate fluctuations and the suppression of pairwise correlations are two expressions of the same effect : as the single spike - train auto - covariance is the same in the feedforward and the feedback case , the suppression of population - rate fluctuations implies smaller correlations .",
    "our theory enables us to identify the cancellation of input correlations as a hallmark of small spike - train correlations .    in previous studies , shared presynaptic input",
    "has often been considered a main source of correlation in recurrent networks ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "recently , @xcite suspected that correlations between excitatory and inhibitory neurons and the fast tracking of external input by the excitatory and the inhibitory population are responsible for an active decorrelation .",
    "we have demonstrated here that the mere fact that excitatory and inhibitory neurons are correlated is not sufficient to suppress shared - input correlations .",
    "rather , we find that the spike - train correlation structure in networks of excitatory and inhibitory networks arranges such that their overall contribution to the covariance between the summed inputs to a pair of neurons becomes negative , canceling partly the effect of shared inputs .",
    "this cancellation becomes more precise the stronger the negative compound feedback @xmath329 is .",
    "in homogeneous networks where excitatory and inhibitory neurons receive statistically identical input , the particular structure of correlations is @xmath241 .",
    "it can further be shown that this structure of correlations is preserved in the limit of large networks @xmath330",
    "( @xmath331 ) . for non - homogeneous synaptic connectivity ,",
    "if the synaptic amplitudes depend on the type of the target neuron ( i.e. @xmath332 or @xmath333 ) , the structure of correlations may be different .",
    "still , the correlation structure arranges such that shared input correlation is effectively suppressed .",
    "formally , this can be seen from a self - consistency equation similar to our equation .",
    "the study by @xcite has shown that correlations are suppressed in the limit of infinitely large networks of binary neurons receiving randomly drawn inputs from a common external population .",
    "its argument rests on the insight that the population - activity fluctuations in a recurrent balanced network follow the fluctuations of the external common population .",
    "an elegant scaling consideration for infinitely large networks @xmath330 with vanishing synaptic efficacy @xmath334 shows that this fast tracking becomes perfect in the limit .",
    "this allows to determine the zero - lag pairwise correlations caused by the external input .",
    "the analysis methods and the recurrent networks presented here differ in several respects from these previous results : we study networks of a finite number of spiking model neurons .",
    "the neurons receive uncorrelated external input , so that correlations are due to the local recurrent connectivity among neurons , not due to tracking of the common external input @xcite .",
    "moreover , we consider homogeneous connectivity where synaptic weights depend only on the type of the presynaptic neuron ( as , e.g. , in * ? ? ?",
    "* ) , resulting in a correlation structure @xmath335 .",
    "for such connectivity , networks of binary neurons with uncorrelated external input exhibit qualitatively the same correlation structure as reported here ( results not shown ) .    in purely inhibitory networks ,",
    "the decorrelation occurs in an analog manner as in excitatory - inhibitory networks .",
    "as only a single population of neurons is available here , population averaged spike - train correlations @xmath244 are negative .",
    "this negative contribution compensates the positive contribution of shared input .",
    "the structure of integrated spike - train covariances in networks constitutes an experimentally testable prediction .",
    "note , however , that the prediction obtained in the current work rests on two simplifying assumptions : identical internal dynamics of excitatory and inhibitory neurons and homogeneous connectivity ( i.e.  @xmath336 , @xmath337 ; see ) . for such networks ,",
    "the structure of correlations is given by @xmath304 .",
    "further , the relation between subthreshold membrane - potential fluctuations and spike responses is the same for both neuron types .",
    "consequently , the above correlation structure can be observed not only at the level of spike trains but also for membrane potentials , provided the assumptions hold true . a recent experimental study @xcite reports neuron - type specific cross - correlation functions in the barrel cortex of behaving mice , both for spike trains and membrane potentials .",
    "it is however difficult to assess the integral correlations from the published data .",
    "a direct test of our predictions requires either a reanalysis of the data or a theory predicting the entire correlation functions .",
    "the raw ( unnormalized ) ii and ei spike - train correlations in @xcite are much more pronounced than the ee correlations ( fig.6 in * ? ? ?",
    "this seems to be in contradiction to our results .",
    "note , however , that the firing rates of excitatory and inhibitory neurons are very different in @xcite . in our study , in contrast , the average firing rates of excitatory and inhibitory neurons are identical as a consequence of the assumed network homogeneity .",
    "future theoretical work is needed to generalize our model to networks with heterogeneous firing rates and non - homogeneous connectivity .",
    "recent results on the dependence of the correlation structure on the connectivity may prove useful in this endeavor @xcite .",
    "correlations in spike - train ensembles play a crucial role for the en- and decoding of information .",
    "a set of uncorrelated spike trains provides a rich dynamical basis which allows readout neurons to generate a variety of responses by tuning the strength and filter properties of their synapses @xcite . in the presence of correlations ,",
    "the number of possible readout signals is limited .",
    "moreover , spike - train correlations impair the precision of such readout signals in the presence of noise .",
    "consider , for example , a linear combination @xmath338 of @xmath0 presynaptic spike trains with arbitrary ( linear ) filter kernels @xmath339 ( e.g.  synaptic filters ) . in a realistic scenario ,",
    "the individual spike trains @xmath8 typically vary across trials @xcite . to understand how robust the resulting readout signal @xmath340 is against this spike - train variability , let s consider the variability of its fourier transform @xmath341\\left(\\omega\\right)}=\\sum_{i=1}^{n}s_i(\\omega)h_i(\\omega)$ ] . assuming homogeneous spike - train statistics , @xmath342 } & & \\text{(mean)}\\\\      v(\\omega)&:={\\text{e}_{i}\\left[|s_i(\\omega)-s(\\omega)|^2\\right ] } & & \\text{(variance)}\\\\      c(\\omega)&:={\\text{e}_{i \\neq j}\\left[\\left(s_i(\\omega)-s(\\omega)\\right)\\left(s_j(\\omega)-s(\\omega)\\right){^\\ast}\\right ] } & & \\text{(covariance ) }",
    "\\ , ,    \\end{aligned}\\end{aligned}\\ ] ] the ( squared ) signal - to - noise ratio of the readout signal @xmath343 is given by @xmath344}|^2}{{\\text{e}_{}\\left[|y(\\omega)-{\\text{e}_{}\\left[y(\\omega)\\right]}|^2\\right ] } }    = \\frac{|s|^2 |\\bar{h}_1|^2}{n^{-1}(1-\\kappa ) v \\bar{h}_2       + \\kappa v |\\bar{h}_1|^2 }    \\,.\\ ] ] here , @xmath345 denotes the spike - train coherence .",
    "the coefficients @xmath346}$ ] and @xmath347}$ ] represent the 1st- and 2nd - order filter statistics . for uncorrelated spike trains , i.e.  @xmath348 , and @xmath349",
    ", the signal - to - noise ratio @xmath350 grows unbounded with the population size @xmath0 .",
    "thus , even for noisy spike trains ( @xmath351 ) , the compound signal @xmath340 can be highly reliable if the population size @xmath0 is sufficiently large . in the presence of correlations , @xmath352 , however , @xmath350 converges towards a constant value @xmath353 as @xmath0 grows . even for large populations ,",
    "the readout signal remains prone to noise .",
    "these findings constitute a generalization of the results reported for population - rate coding , i.e.  sums of unweighted spike counts ( see e.g. * ? ? ?",
    "* ; * ? ? ?",
    "the above arguments illustrate that the same reasoning applies to coding schemes which are based on the spatio - temporal structure of spike patterns .    in a previous study @xcite",
    ", we demonstrated that active decorrelation in recurrent networks is a necessary prerequisite for a controlled propagation of synchronous volleys of spikes in embedded feedforward subnetworks ( synfire chains ; ): a synfire chain receiving background input from a finite population of independent poisson sources amplifies the resulting shared - input correlations , thereby leading to spontaneous synchronization within the chain ( b ) .",
    "a distinction between these spurious synchronous events and those triggered by an external stimulus is impossible .",
    "the synfire chain loses its asynchronous ground state @xcite .",
    "a synfire chain receiving background inputs from a recurrent network , in contrast , is much more robust . here ,",
    "shared - input correlations are actively suppressed by the recurrent - network dynamics .",
    "synchronous events can be triggered by external stimuli in a controlled manner ( a ) .",
    "layers , layer width @xmath354 ) receiving background input from an excitatory - inhibitory network ( * a * , cf .",
    "c ) or from a finite pool of excitatory and inhibitory poisson processes ( * b * , cf .",
    "average input firing rates , in - degrees and amount of shared input are identical in both cases . neurons of the first synfire layer ( neuron ids @xmath355 ) are stimulated by current pulses at times @xmath356 and @xmath357 .",
    "each neuron in layer @xmath358 $ ] receives inputs from all @xmath359 neurons in the preceding layer @xmath360 ( synaptic weights @xmath361 , spike transmission delays @xmath362 ) , and @xmath363 and @xmath364 excitatory and inhibitory background inputs , respectively , randomly drawn from the presynaptic populations .",
    "neurons in the first layer @xmath365 receive @xmath366 and @xmath364 excitatory and inhibitory background inputs , respectively .",
    "note that there is no feedback from the synfire chain to the embedding network .",
    "see for network parameters .",
    ", title=\"fig : \" ]    apart from the spontaneous synchronization illustrated in , decorrelation by inhibition might solve another problem arising in embedded synfire structures : in the presence of feedback connections between the synfire chain and the embedding background network , synchronous spike volleys can excite ( high - frequency ) oscillatory modes in the background network which , in turn , interfere with the synfire dynamics and prevent a robust propagation of synchronous activity within the chain ( synfire explosion , see * ? ? ?",
    "* ; * ? ? ?",
    "the decorrelation mechanism we refer to in our work is efficient only at low frequencies .",
    "it can not prevent the build - up of these oscillations .",
    "@xcite demonstrated that the synfire explosion can be suppressed by adding inhibitory neurons to each synfire layer ( shadow inhibition ) which diffusely project to neurons in the embedding network , thereby weakening the impact of synfire activity on the embedding network .    in the present work we focus on the integral of the correlation function , nurtured by our interest in the low - frequency fluctuations .",
    "an analog treatment can however easily be performed for the zero - lag correlations .",
    "in contrast to infinite networks with sparse connectivity ( @xmath367 , @xmath368 ) , in the case of finite networks , pairs of neurons must be distinguished according to whether they are synaptically connected or not in order to arrive at a self - consistent theory for the averaged correlations . providing explicit expressions for correlations between connected and unconnected neurons , the current work provides the tools to relate experimentally observed spiking correlations to the underlying synaptic connectivity .",
    "the quantification of pairwise correlations is a necessary prerequisite to understand how correlation sensitive synaptic plasticity rules , like spike - timing dependent plasticity @xcite , interact with the recurrent network dynamics @xcite .",
    "existing theories quantifying correlations employ stochastic neuron models and are limited to purely excitatory networks @xcite . here",
    ", we provide an analytical equivalence relation between a reduced linear model and spiking integrate - and - fire neurons describing fluctuations correctly up to linear order .",
    "a formally similar approach has been employed earlier to study delayed cumulative inhibition in spiking networks @xcite .",
    "we show that the correlations observed in recurrent networks in the asynchronous irregular regime are quantitatively captured for realistic synaptic coupling with postsynaptic potentials of up to about @xmath369 .",
    "the success of this approach can be explained by the linearization of the neural threshold units by the afferent noise experienced in the asynchronous regime . for linear",
    "neural dynamics , the second - order description of fluctuations is closed @xcite .",
    "we exploit this finding by applying perturbation theory to the fokker - planck description of the integrate - and - fire neuron to obtain the linear input - output transfer at low frequencies @xcite , thereby determining the effective coupling in our linear model .",
    "the scope of the theory presented in the current work is limited mainly by three assumptions .",
    "the first is the use of a linear theory which exhibits an instability as soon as a single eigenvalue of the effective connectivity matrix assumes a positive real part .",
    "this ultimately happens when increasing the synaptic coupling strength , because the eigenvalues of the random connectivity matrix are located in a circle centered in the left half of the complex plain with a radius given by the square root of the variance of the matrix elements @xcite .",
    "nonlinearities , like those imposed by strictly positive firing rates , prevent such unbounded growth ( or decay ) by saturation . for nonlinear rate models with sigmoidal transfer functions it has been shown that the activity of recurrent random networks of such units makes a transition to chaos at the point where the linearized dynamics would loose stability @xcite",
    ". however , this point of transition is sharp only in the limit of infinitely large networks . from the population averaged firing rate and the pairwise correlations averaged over pairs of neurons considered in we can not conclude whether or not a transition to chaos occurs in the spiking network . in simulations and in the linearized reduced model",
    ", we could however observe that the distribution of pairwise correlations broadens when approaching the point of instability .",
    "future work needs to examine this question in detail , e.g.  by considering measures related to the lyapunov exponent .",
    "recently developed semi - analytical theories accounting for nonlinear neural features @xcite may be helpful to answer this question .",
    "the second limiting factor of the current theory is the use of a perturbative approach to quantify the response of the integrate - and - fire model .",
    "although the steady - state firing rate of the network is found as the fixed point of the nonlinear self - consistency equation , the response to a synaptic fluctuation is determined up to linear order in the amplitude of the afferent rate fluctuation , which is only valid for sufficiently small fluctuations . for",
    "larger input fluctuations , nonlinear contributions to the neural response can become more important @xcite . also for strong synaptic coupling ,",
    "deviations from our theory are to be expected .",
    "thirdly , the employment of fokker - planck theory to determine the steady - state firing rate and the response to incoming fluctuations assumes uncorrelated presynaptic firing with poisson statistics and synaptic amplitudes which are vanishingly small compared to the distance between reset and threshold . for larger synaptic amplitudes ,",
    "the fokker - planck theory becomes approximate and deviations are expected @xcite .",
    "this can be observed in a , showing a deviation between the self - consistent firing rate and the analytical prediction at about @xmath370 . in this work",
    ", we obtained a sufficiently precise self - consistent approximation of the correlation coefficient @xmath302 by relating the random recurrent network of spiking neurons in the asynchronous irregular state to a reduced linear model which obeys the same relation between @xmath278 and @xmath228 up to linear order .",
    "this reduced linear model , however , does not predict the absolute values of the variance @xmath228 and covariance @xmath278 .",
    "the variance @xmath228 of the lif model , for example , is dominated by nonlinear effects , such as the reset mechanism after each action potential .",
    "previous work @xcite has shown that the single spike - train statistics can be approximated in the diffusion approximation if the recurrent firing rate in the network is determined by mean - field theory .",
    "one may therefore extend our approach and determine the integral auto - correlation function as @xmath371 with the fano factor @xmath372 ( see * ? ? ?",
    "* ) . for a renewal process and long observation times ,",
    "the fano factor is given by @xmath373 @xcite .",
    "the coefficient of variation @xmath374 can be obtained from the diffusion approximation of the membrane - potential dynamics ( * ? ? ?",
    "* app.a.1 ) .",
    "the covariance @xmath278 can then be determined by .",
    "another possibility is the use of a refractory - density approach @xcite .",
    "the spike - train correlation as a function of the time lag is an experimentally accessible measure .",
    "future theoretical work should therefore also focus on the temporal structure of correlations in recurrent networks , going beyond zero - lag correlations @xcite and the integral measures studied in the current work .",
    "this would allow to compare the theoretical predictions to direct experimental observations in a more detailed manner .",
    "moreover , the relative spike timing between pairs of neurons is a decisive property for hebbian learning @xcite in recurrent networks , as implemented by spike timing - dependent plasticity @xcite , and suspected to play a role for synapse formation and elimination @xcite .",
    "the simulation experiments performed in this work revealed that the suppression of correlations is vulnerable to certain types of manipulations of the feedback loop",
    ". one particular biological source of additional variability in the feedback loop is probabilistic vesicle release at synapses @xcite . in feedforward networks",
    ", such unreliable synaptic transmission has been shown to decrease the transmission of correlations by pairs of neurons @xcite .",
    "stochastic synaptic release is very similar to the replacement of the population activity in the feedback branch by a rate modulated poisson processes that conserves the population rate . in these simulations we observed an increase of correlations due to the additional noise caused by the stochastic poisson realization .",
    "future work should investigate more carefully which of the two opposing effects of probabilistic release on correlations dominates in recurrent networks .",
    "the results of our study do not only shed light on the decorrelation of spiking activity in recurrent neural networks .",
    "they also demonstrate that a standard modeling approach in theoretical neuroscience is problematic : when studying the dynamics of a local neural network ( e.g.  a `` cortical column '' ) , it is a common strategy to replace external inputs to this neural population @xmath375 by spike - train ensembles with some predefined statistics , e.g.  by stationary poisson processes .",
    "most neural systems , however , exhibit a high degree of recurrence .",
    "nonlocal input to the population @xmath375 , i.e.  input from other brain areas , therefore has to be expected to be shaped by the activity within @xmath375 .",
    "the omission of these feedback loops can lead to qualitatively wrong predictions of the population statistics .",
    "the analytical results for the correlation structure of recurrent networks presented in this study provide the means to a more realistic specification of such external activity .",
    "in the present study , we consider two types of sparsely connected random networks : networks with purely inhibitory coupling ( `` i networks '' ) and networks with both excitatory and inhibitory interactions ( `` ei networks '' ) .",
    "to illustrate the main findings of this study and to test the predictions of the linear model described in , both architectures were implemented as networks of leaky integrate - and - fire ( lif ) neurons .",
    "the model details and parameters are reported in and , respectively .",
    "all network simulations were carried out with nest ( http://www.nest-initiative.org[www.nest-initiative.org ] ) .",
    "* populations & one ( inhibitory network ) or two ( excitatory - inhibitory network ) + * connectivity & random , fixed in - degrees + * neuron & leaky integrate - and - fire ( lif ) + * synapse & current based , delta - shaped postsyn .  currents with constant amplitudes + * input & uncorrelated gaussian white noise currents + * * * * *       + * name & * elements & * size + @xmath306 & lif & @xmath376 +    + * name & * elements & * size + @xmath305 & lif & @xmath377 + @xmath306 & lif & @xmath378 + * * * * * *       + * source & * target & * pattern + @xmath306 & @xmath306 & random convergent @xmath379 , delay @xmath380 , weight @xmath54 +    + * source & * target & * pattern + @xmath305 & @xmath305 & random convergent @xmath379 , delay @xmath380 , weight @xmath62 + @xmath305 & @xmath306 & random convergent @xmath379 , delay @xmath380 , weight @xmath62 + @xmath306 & @xmath305 & random convergent @xmath381 , delay @xmath380 , weight @xmath382 + @xmath306 & @xmath306 & random convergent @xmath381 , delay @xmath380 , weight @xmath382 + * * * * * *     * type & leaky integrate - and - fire ( lif ; * ? ? ? * ) + * description & dynamics of membrane potential @xmath383 ( @xmath1 $ ] ) : * *    * spike emission at times @xmath384 with @xmath385 * subthreshold dynamics : * @xmath386 if @xmath387 $ ] * reset + refractoriness : @xmath388 if @xmath389 $ ]     + & exact integration @xcite with temporal resolution @xmath390 + & initial membrane - potential distribution at @xmath391 : uniform between @xmath392 and @xmath393 +     * type & current synapse with @xmath34-shaped postsyn .  currents ( pscs ) + * description & input current of neuron @xmath5 : @xmath394 + & static synaptic weights @xmath299 ( see connectivity ) + * *     * type & uncorrelated gaussian white noise @xmath395 ( for @xmath1 $ ] ) + * description & mean @xmath396}$ ] , auto - correlation @xmath397 } = \\mu_{\\text{ext}}^2 + \\eta^2 { \\tau_{\\text{m}}}\\delta_{ij } \\delta(\\tau)$ ] + & in discrete time @xmath398 , @xmath399 piecewise constant within time interval @xmath390 , value drawn independently for each time point from a normal distribution with zero mean and standard deviation @xmath400 + *",
    "*     * name & * value & * description + @xmath366 & @xmath401 ( inhibitory network ) & in - degree + & @xmath402 ( e - i network ) & excitatory in - degree + @xmath18 & @xmath403 & network connectivity + @xmath404 & @xmath405 ( e - i network ) & relative size of inhibitory subpopulation + * * *     * name & * value & * description + @xmath406 & @xmath407 & membrane resistance + @xmath408 & @xmath409 & membrane time constant + @xmath410 & @xmath411 & refractory period + @xmath412 & @xmath413 & reset potential + @xmath393 & @xmath414 & spike threshold + * * *     * name & * value & * description + @xmath62 & @xmath415 & epsp amplitude + @xmath416 & @xmath417 ( e - i network ) & relative ipsp amplitude + @xmath380 & @xmath418 & synaptic delay + * * *     * name & * value & * description + @xmath419 & @xmath420 & mean external gwn input + @xmath55 & @xmath421 & sd of external gwn input + * * *     * name & * value & * description + @xmath422 & @xmath423 or @xmath424 & simulation time + @xmath390 & @xmath418 & time resolution + * * *      in this section we show how the dynamics of the spiking network can be reduced to an effective linear model whose fluctuations , by construction , fulfill the same relationship as the original system up to linear order .",
    "we first outline the major steps of this reduction , and then provide the formal derivation .",
    "we make use of the observation that the effect of a single synaptic impulse on the output activity of a neuron is typically small .",
    "writing the response spike train of a neuron as a functional of the history of all incoming impulses therefore allows us to perform a linearization with respect to each of the afferent spike trains .",
    "formally , this corresponds to a volterra expansion up to linear order , the generalization of a taylor series to functionals . in , we perform this linearization explicitly for the example of the lif model .",
    "this determines how the linear response kernel depends on the parameters of the lif model . the linear dependence on the input leads to an approximate convolution equation linearly connecting the auto- and the cross - correlation functions in the network .",
    "as this equation is complicated to solve directly , we introduce a reduced linear model obeying the same convolution equation .",
    "the reduced linear model can be solved by standard fourier methods and yields an explicit form for the covariance matrix in the frequency domain .",
    "the diagonal and off - diagonal elements of the @xmath425 dimensional covariance matrix @xmath219 in correspond to the power - spectra of individual neurons and the cross - spectra of individual neuron pairs , respectively . as , in this linear approximation",
    ", both the auto- and the cross - covariances are proportional to the variance of the driving noise , the resulting correlation coefficients are independent of the noise amplitude ( see ) . as shown in and , the suppression of fluctuations in recurrent networks is most pronounced at low frequencies .",
    "it is therefore sufficient to restrict the discussion to the zero - frequency limit @xmath426 .",
    "note that the zero - frequency variances and covariances correspond to the integrals of the auto- and cross - correlation functions in the time domain . in this limit",
    ", we may combine the two different sources of fluctuations caused by the spiking of the neurons and by external input to the network into a single source of white noise with variance @xmath230 .    in general ,",
    "the spiking activity @xmath8 of neuron @xmath5 at time @xmath427 is determined by the entire history @xmath428 of the activity of all neurons @xmath429 in the network up to time @xmath427 .",
    "formally , this dependence can be expressed by a functional @xmath430.\\ ] ] the subscript @xmath427 in @xmath431 indicates that @xmath432 ( causality ) . in the following , we will use the abbreviation @xmath433\\equiv{}g^i_{t}[{{\\bm{s}}}(t^{\\prime})]$ ] .",
    "the effect of a single synaptic input on the state of a neuron is typically small .",
    "we therefore approximate the influence of an incoming spike train on the activity of the target neuron up to linear order .",
    "the sensitivity of neuron @xmath5 s activity to the input from neuron @xmath261 can be expressed by the functional derivative of @xmath434 with respect to input spike train @xmath435 : @xmath436}{\\delta s_k({t^{\\prime \\prime } } ) }     = \\lim_{\\epsilon \\rightarrow 0 } \\frac{1}{\\epsilon }     \\left(g_t^i[{{\\bm{s}}}+\\epsilon\\ , \\delta(\\circ-{t^{\\prime \\prime}})\\ , { \\mathbf{e}}_{k}]-g_{t}^{i}[{{\\bm{s}}}]\\right).\\ ] ] it represents the response of the functional to a single @xmath34-shaped perturbation in input channel @xmath261 at time @xmath437 , normalized by the perturbation amplitude @xmath18 . in",
    ", @xmath438 denotes the unity vector with elements @xmath439 and @xmath440 for all @xmath441 . by introducing the vector @xmath442 of spike trains with the @xmath261-th component set to zero , @xmath433",
    "$ ] can be approximated by @xmath443   \\simeq\\sum_{k=1}^{n}\\int_{-\\infty}^{t}\\frac{\\delta g_t^i[{{\\bm{s}}}_{\\hat{k}}]}{\\delta s_{k}({t^{\\prime \\prime } } ) } \\ , s_k({t^{\\prime \\prime}})\\ , d{t^{\\prime \\prime}}.\\ ] ] eq .",
    "is a volterra expansion up to linear order , the formal extension of a taylor expansion of a function of @xmath0 variables to a functional , truncated after the linear term . with the linearized dynamics , the pairwise spike - train cross - correlation function between two neurons @xmath5 and @xmath444 is given by @xmath445\\,\\tilde{s}_j(t)\\right\\rangle _ { { { \\bm{s}}}}\\\\      & = \\sum_{k=1}^n \\int_{-\\infty}^{t+\\tau } \\left\\langle \\frac{\\delta          g_{t+\\tau}^i [ { { \\bm{s}}}_{\\hat{k } } ] } { \\delta s_k({t^{\\prime \\prime } } ) } \\ ,        \\left\\langle s_k ( { t^{\\prime \\prime } } ) \\ , \\tilde{s}_j(t ) \\right\\rangle_{s_k }      \\right\\rangle _ { { { \\bm{s}}}\\backslash s_k } \\ , d{t^{\\prime \\prime}}\\qquad(\\forall{}\\tau>0 ) .",
    "\\end{aligned}\\end{aligned}\\ ] ] note that is valid only for positive time lags @xmath446 , because for @xmath447 a possible causal influence of @xmath448 on @xmath449 is not expressed by the functional . here",
    ", @xmath450 denotes the average across the ensemble of realizations of spike trains in the stationary state of the network ( e.g.  the ensemble resulting from different initial conditions ) , and @xmath451 the centralized ( zero mean ) spike train . in the last line in , the average @xmath452",
    "is split into the average @xmath453 across all realizations of spike trains excluding @xmath435 and the average @xmath454 across all realizations of @xmath435 .",
    "note that the latter does not affect the functional derivative because it is , by construction , independent of the actual realization of @xmath455 .",
    "a consistent approximation up to linear order is equivalent to the assumption that for all @xmath6 the linear dependence of the functional on @xmath449 is completely contained in the respective derivative with respect to @xmath449 .",
    "dependencies beyond linear order include higher - order derivatives and are neglected in this approximation .",
    "this is equivalent to neglecting the dependence of @xmath456}{\\delta s_k({t^{\\prime \\prime}})}$ ] on @xmath457 for any @xmath458 .",
    "hence , we can average the inner term over @xmath455 and @xmath457 separately . in the stationary state",
    ", this correlation can only depend on @xmath459 and equals the auto- or the cross - correlation function : @xmath460 the pairwise spike - train correlation function is therefore given by @xmath461}{\\delta s_k({t^{\\prime \\prime } } ) } \\right\\rangle _ { { \\bm{s}}}\\,\\begin{cases } a_k({t^{\\prime \\prime}}-t ) & \\text{for }",
    "k = j\\\\ c_{kj}({t^{\\prime \\prime}}-t ) & \\text{for } k\\neq j \\end{cases } \\qquad(\\forall{}\\tau>0),\\end{aligned}\\ ] ] where we used the fact that @xmath462 \\rangle_{{{\\bm{s}}}\\backslash s_k } = \\langle f[s_{\\hat{k } } ] \\rangle_{{\\bm{s}}}$ ] for any functional @xmath463 that does not depend on @xmath455 .",
    "the average of the functional derivative has the intuitive meaning of a response kernel with respect to a @xmath34-shaped perturbation of input @xmath455 at time @xmath437 .",
    "averaged over the realizations of the stationary network activity this response can only depend on the relative time @xmath464 . in a homogeneous random network ,",
    "the input statistics ( number of synaptic inputs and synaptic weights ) and the parameters of the internal dynamics are identical for each cell , so that the temporal shape @xmath58 of the response kernel can be assumed to be the same for all neurons .",
    "the synaptic coupling strength from neuron @xmath261 to neuron @xmath5 determines the prefactor @xmath465 : @xmath466}{\\delta s_k({t^{\\prime \\prime } } ) } \\right\\rangle_{{\\bm{s}}}. \\label{eq : functional_derivative_kernel}\\end{aligned}\\ ] ] in this notation , the linear equation connecting the auto - correlations @xmath467 and the cross - correlations @xmath468 takes the form @xmath469    our aim is to find a simpler model which is equivalent to the lif dynamics in the sense that it fulfills the same equation .",
    "let s @xmath470 denote the vector of dynamic variables of this reduced model .",
    "analog to the original model , we define the cross - correlation for @xmath471 and @xmath446 as @xmath472 \\ , \\tilde{u}_j(t ) \\right\\rangle_{{\\bm{u}}}.\\label{eq : correlation_r}\\end{aligned}\\ ] ] the simplest functional @xmath473 $ ] consistent with equation is linear in @xmath474 .",
    "since we require equivalence only with respect to the ensemble averaged quantities , i.e. @xmath475 , the reduced activity and therefore @xmath473 $ ] can contain a stochastic element which would disappear after averaging .",
    "the linear functional @xmath476 & = & \\sum_{k=1}^n w_{ik } \\int_{-\\infty}^t h(t-{t^\\prime } ) \\ , u_k({t^\\prime } ) \\",
    ", d{t^\\prime}+ z_i ( t ) \\label{eq : effective_reduced_model}\\end{aligned}\\ ] ] with a pairwise uncorrelated , centralized white noise @xmath477 ( @xmath478 ) fulfills the requirement , since for @xmath446 and @xmath479 @xmath480 this equation has the same form as , so both models , within the linear approximation , exhibit an identical relationship between the auto- and cross - covariances .",
    "the physical meaning of the noise @xmath319 is the variance caused by the spiking of the neurons .",
    "the auto - correlation function of a spike train of rate @xmath481 has a @xmath34-peak of weight @xmath481 .",
    "the reduced model exhibits such a @xmath34-peak if we set @xmath482 .",
    "a related approach has been pursued before ( see sec .  3.5 in * ? ? ?",
    "* ) to determine the auto - correlation of the population averaged firing rate .",
    "this similarity will be discussed in detail below .",
    "so far , we considered a network without external drive , i.e. all spike trains @xmath483 originated from within the network . if the network is driven by external input , each neuron receives , in addition , synaptic input @xmath484 from neurons outside the network .",
    "we assume uncorrelated external drive @xmath485 . in the reduced model",
    ", this input constitutes a separate source of noise : @xmath486 & = & \\sum_{k=1}^n w_{ik } ( u_k \\ast h ) + ( y_i \\ast h_{iy } ) + z_i ( t ) \\label{eq : effective_reduced_model_external}.\\end{aligned}\\ ] ] here , @xmath487 denotes the convolution and @xmath488 the response kernel with respect to an external input . for simplicity ,",
    "let s assume that the shape of these kernels is identical for all pairs of pre- and postsynaptic sources , i.e.  @xmath489 . if we further absorb the synaptic amplitude of the external drive in the strength of the noise @xmath490 , the linearized dynamics can be written in matrix notation @xmath491*h)(t ) + { \\bm{z}}(t)\\ ] ] with @xmath492 .",
    "the reduced model can be solved directly by means of fourier transform : @xmath493^{-1 } ( h(\\omega ) { \\bm{y}}(\\omega ) + { \\bm{z}}(\\omega ) ) .",
    "\\label{eq : solution_u}\\end{aligned}\\ ] ] the full covariance matrix follows by averaging over the sources of noise @xmath494 and @xmath495 as @xmath496^{-1}[\\mathbf{1}-{{\\bm{w}}}^t h(-\\omega)]^{-1}.\\label{eq : covariance_matrix}\\end{aligned}\\ ] ] the diagonal elements of @xmath497 represent the auto - covariances , the off - diagonal elements the cross - covariances .",
    "both are proportional to the driving noise @xmath498 .",
    "this is consistent with which is a linear relationship between the cross- and auto - covariances .    for networks which can be decomposed into homogeneous subpopulations ,",
    "the @xmath0 dimensional system can be further simplified by population averaging .",
    "consider , for example , a homogeneous random network with purely inhibitory coupling .",
    "assume that the neurons are randomly connected with probability @xmath18 and coupling strength @xmath499 .",
    "the average number of in / outputs per neuron ( in / out - degree ) is thus given by @xmath53 . by introducing the population averaged external input @xmath500}$ ] , the averaged spiking noise @xmath501}$ ] , and the effective coupling strength @xmath502 , the dynamics of the population averaged activity becomes @xmath503 }    = \\left(\\left[\\sum_j { \\text{e}_{i}\\left[w_{ij}\\right ] } u_j+{\\text{e}_{i}\\left[y_i\\right ] }      \\right]*h\\right)(t ) + { \\text{e}_{i}\\left[z_i(t)\\right ] }    = ( [ -{\\bar{w}}u+y]*h)(t ) + z(t )    \\,.\\ ] ] here we assumed that @xmath504}$ ] is independent of the presynaptic neuron @xmath6 and can be replaced by @xmath505 .",
    "note that this replacement is exact for networks with homogeneous out - degree , i.e.  if the number of outgoing connections is identical for each neuron @xmath6 . for large random networks with",
    "binomially distributed out - degrees ( e.g.  erds - rnyi networks or random networks with constant in - degree ) , serves as an approximation .    to relate our approach to the treatment of finite - size fluctuations in @xcite , consider the population - averaged dynamics of a single population with mean firing rate @xmath481 .",
    "we set @xmath506 for all single neuron noises @xmath507 in order for the reduced model s auto - covariances to reproduce the @xmath34-peak of the spiking dynamics . in the population averaged dynamics , this leads to the variance of the noise @xmath508 given by @xmath509 .",
    "this agrees with the variance of the population rate in @xcite .",
    "therefore , the dynamics of the population averaged quantity @xmath510 in agrees with the earlier definition of a population averaged firing rate @xmath511 for the spiking network @xcite .",
    "in equation , two distinct sources of noise appear : the noise due to external uncorrelated activity @xmath512 and the noise @xmath513 which is required to obtain the @xmath34-peak of the auto - correlation functions of the reduced model .",
    "the qualitative results of and , however can be understood with an even simpler model . as we are mainly concerned with the low - frequency fluctuations ,",
    "we only need a model that has the same limit @xmath514 . as we normalized the kernel so that @xmath179 we can combine both sources of noise and require @xmath515 in in the zero frequency limit .",
    "hence , in and , we consider the model @xmath516",
    "\\ast h)(t ) \\label{eq : linearized_dynamics_lowomega}\\end{aligned}\\ ] ] with a pairwise uncorrelated centralized white noise @xmath517 } = \\rho^2 \\delta_{ij } \\delta(\\tau)$ ] to explain the suppression of fluctuations at low frequencies .    as a second example , consider a random network composed of an excitatory and an inhibitory subpopulation @xmath116 and @xmath117 with population sizes @xmath118 and @xmath518 , respectively .",
    "assume that each neuron receives excitatory and inhibitory inputs from @xmath116 and @xmath117 with coupling strengths @xmath122 and @xmath123 , respectively , and probability @xmath18 , such that the average excitatory and inhibitory in / out - degrees are given by @xmath53 and @xmath519 , respectively .",
    "the dynamics of the subpopulation averaged activities @xmath520 is given by with subpopulation averaged noise @xmath521 and @xmath522 and effective coupling @xmath523 here , @xmath59 denotes the effective coupling strength , @xmath524 the effective balance parameter and @xmath525}$ ] and @xmath526}$ ] the ( sub)population averaged external and spiking sources of noise , respectively . again , the reduction of the @xmath0-dimensional linear dynamics to the two - dimensional dynamics is exact if the out - degrees are constant within each subpopulation .",
    "as before , both sources of noise can be combined into a single source of noise , if the we are only interested in the low - frequency behavior of the model , leading to the dynamics with the effective coupling .",
    "the linear theory is only valid in the domain of its stability , which is determined by the eigenvalue spectrum of the effective coupling matrix @xmath151 .",
    "for random coupling matrices , the eigenvalues are located within a circle with a radius equal to the square root of the variance of the matrix entries @xcite @xmath527 } } = w \\sqrt{n\\epsilon ( 1-\\epsilon ) ( 1+\\gamma g^2)}$ ] .",
    "writing the effective dynamics for the exponential kernel as a differential equation @xmath528 , the eigenvalues of the right hand side matrix @xmath529 are confined to a circle centered at @xmath530 in the complex plain with radius @xmath527}}$ ] . given @xmath531 }",
    "> 1 $ ] , eigenvalues might exist which have a positive real part , leading to unstable dynamics .",
    "this condition is indicated by the vertical dotted lines in a - f and b - d near @xmath532 . beyond this line ,",
    "the linear model predicts an explosive growth of fluctuations . in the lif - network model , an unbounded growth",
    "is avoided by the nonlinearities of the single - neuron dynamics .",
    "we now perform the formal linearization for a network of @xmath0 lif neurons @xmath52 .",
    "a similar approach has been employed in previous studies to understand the population dynamics in these networks @xcite .",
    "we consider the input @xmath533 received by neuron @xmath5 from the local network , where @xmath449 denotes the spike train of the neuron @xmath6 projecting to neuron @xmath5 with synaptic weight @xmath299 .",
    "given the time dependent firing rate @xmath534 of each afferent , and assuming small correlations and small synaptic weights , the total input to neuron @xmath5 can be replaced by a gaussian white noise with mean @xmath535 and variance @xmath536 , @xmath537 where @xmath6 sums over all synaptic inputs .",
    "@xmath538 denotes the amplitude of the postsynaptic potential evoked by synapse @xmath539 .",
    "@xmath540 is the membrane time constant of the model . in the stationary state , the firing rate of each afferent",
    "is well described by the constant time average @xmath541}$ ] .",
    "the working point at which we perform the linearization of the neural response is then given by analog equations as , resulting in a constant mean @xmath542 and variance @xmath543 .",
    "if the amplitude of each postsynaptic potential is small compared to the distance of the membrane potential to threshold , the dynamics of the lif model can be approximated by a diffusion process , employing fokker - planck theory @xcite .",
    "the stationary firing rate of the neuron is then given by @xcite @xmath544 with the reset voltage @xmath545 , the threshold voltage @xmath546 and the refractory time @xmath547 .",
    "in homogeneous random networks , the stationary rate ( a ) is the same for all neurons .",
    "it is determined in a self - consistent manner @xcite as the fixed point of .",
    "the stationary mean @xmath548 and variance @xmath549 are determined by the stationary rate . to determine the kernel we need to consider how a @xmath34-shaped deflection in the input to this neuron at time point @xmath550 affects its output up to linear order in the amplitude of the fluctuation . in the stationary state",
    ", we may set @xmath551 .",
    "it is therefore sufficient to focus on the effect of a single fluctuation @xmath552 we therefore ask how the density of spikes per time @xmath553 \\rangle_{{{\\bm{s}}}\\backslash s_k}$ ] of neuron @xmath5 , averaged over different realizations of the remaining inputs to neuron @xmath5 , changes in response to the fluctuation of the presynaptic neuron @xmath261 in the limit of vanishing amplitude @xmath554 .",
    "this kernel @xmath555 is identical to the impulse response of the neuron and can directly be measured in simulation by trial averaging over many responses to the given @xmath34-deflection in the input ( see a ) . for the theory of low - frequency fluctuations , we only need the integral of the kernel , also known as the dc susceptibility , @xmath556 the second equality follows from the equivalence of the integral of the impulse response and the step response in linear approximation @xcite . following from ,",
    "both mean and variance are perturbed as @xmath557 and @xmath558 in response to a step @xmath554 in the afferent rate @xmath559 .",
    "moreover , we used the chain rule @xmath560 .",
    "the variation of the afferent firing rate hence co - modulates the mean and the variance and both modulations need to be taken into account to derive the neural response @xcite .",
    "although the finite amplitude of postsynaptic potentials has an effect on the response properties @xcite , the integral response is rather insensitive to the granularity of the noise @xcite .",
    "we therefore employ the diffusion approximation to linearize the dynamics of the lif neuron around its working point characterized by the mean @xmath561 and the variance @xmath549 of the total synaptic input . in , we evaluate the partial derivatives of @xmath562 with respect to @xmath561 and @xmath563 using .",
    "first , observe that by chain rule @xmath564 .",
    "we then again make use of the chain rule @xmath565 .",
    "analog expressions hold for the derivative with respect to @xmath566 .",
    "the first derivative yields @xmath567 , the one with respect to @xmath568 follows analogously , but with a negative sign .",
    "we further observe that @xmath569 and @xmath570 with @xmath571 . taken together",
    ", we obtain the explicit result for @xmath572 note that the modulation of @xmath573 results in a contribution to @xmath465 that is linear in @xmath574 , whereas the modulation of @xmath575 causes a quadratic dependence on @xmath574 .",
    "this expression therefore presents an extension to the integral response presented in @xcite .",
    "b shows the comparison of the analytical expression and direct simulation .",
    "the agreement is good over a large range of synaptic amplitudes @xmath576 \\,{\\text{mv}}$ ] in the case of constant background noise caused by small synaptic amplitudes ( here @xmath577 for excitation and @xmath578 for inhibition ) . for background noise caused by stronger impulses ,",
    "the deviations are expected to grow @xcite .",
    "of a lif neuron caused by an incoming spike event of postsynaptic amplitude @xmath579 . *",
    "b * : integral @xmath580 of the firing rate deflection shown in a as a function of the postsynaptic amplitude @xmath574 ( simulation : black dots ; analytical approximation : gray curve ) .",
    "the neuron receives constant synaptic background input with @xmath581 , @xmath582 , and rates @xmath583 , @xmath584 resulting in a first and second moment @xmath585 and @xmath586 .",
    "simulation results are obtained by averaging over @xmath402 trials of @xmath587 duration each with @xmath588 input impulses on average . for further parameters of the neuron model ,",
    ", title=\"fig : \" ]      the recurrent linear neural dynamics defined in the previous section is conveniently solved in the fourier domain .",
    "the driving external gaussian white noise @xmath589 is mapped to the response @xmath590 by means of the transfer matrix @xmath591 . according to",
    ", it is given by @xmath592 .",
    "the covariance matrix in the frequency domain , the spectral matrix , thus reads @xmath593}= { { \\bm{t}}}(\\omega ) \\rho^2 { { { \\bm{1}}}}{{\\bm{t}}}(\\omega){^\\ast}\\ , , \\label{eq : rate_spectrum}\\ ] ] where we used @xmath594 } = \\rho^2 { { { \\bm{1}}}}$ ] and the expectation operator @xmath92}$ ] represents an average over noise realizations . to identify the effect of recurrence on the network dynamics , we replace the local feedback input by a feedforward input @xmath322 with spectral matrix @xmath595 .",
    "the resulting response firing rate is given by @xmath596 .",
    "assuming that the feedforward input @xmath322 is uncorrelated to the external noise source @xmath589 ( @xmath597 ) yields a response spectrum @xmath598 }    = |h|^2 \\left({{\\bm{w}}}{{\\bm{c}}}_{qq}{{\\bm{w}}}{^\\ast}+ \\rho^2 { { { \\bm{1}}}}\\right )    \\ , .",
    "\\label{eq : power_spectrum_feed_forward_uncorr}\\ ] ]      in the fourier domain , the solution of the mean - field dynamics of the inhibitory network is @xmath599 .",
    "the power - spectrum @xmath600}$ ] hence becomes @xmath601 using the spectrum of the noise @xmath602 } = \\rho^2 $ ] .",
    "we compare this power - spectrum to the case where the feedback loop is opened , i.e.  where the recurrent input is replaced by feedforward input with unchanged auto - statistics @xmath603 , but which is uncorrelated to the external input @xmath604 .",
    "the resulting power - spectrum is given by as @xmath605 .      in a homogeneous random network of excitatory and inhibitory neurons ,",
    "the population averaged activity can be solved in the schur basis introduced in @xmath606 with @xmath607 and @xmath608 .",
    "the power of the population rate therefore is @xmath609 the fluctuations of the excitatory and the inhibitory population follow as @xmath610 so the power - spectra are @xmath611    replacing the recurrent input of the sum activity @xmath187 by activity @xmath189 with the same auto - statistics , but which is uncorrelated to the remaining input into @xmath187 ( d ) results in the fluctuations @xmath612 the power - spectrum of the sum activity therefore becomes @xmath613\\ , .",
    "\\end{aligned}\\end{aligned}\\ ] ]    if , alternatively , the excitatory and the inhibitory feedback terms @xmath169 and @xmath170 are replaced by uncorrelated feedforward input @xmath171 and @xmath172 with power - spectra @xmath614 and @xmath615 ( c , d ) , the spectrum of the sum activity reads @xmath616 .",
    "\\end{aligned}\\end{aligned}\\ ] ] the limit for inhibition dominated networks with @xmath617 can be obtained from this and the former expressions by taking @xmath618 and assuming strong coupling @xmath619 .      in this subsection",
    ", we derive a self - consistency equation for the covariances in a recurrent network .",
    "we start from ( we drop the superscript @xmath510 of @xmath620 for brevity ) multiply by @xmath621 from left and its transpose from right to obtain @xmath622 we assume a recurrent network of @xmath623 excitatory and @xmath624 inhibitory neurons , in which each neuron receives @xmath366 excitatory inputs of weight @xmath269 and @xmath364 inhibitory inputs of weight @xmath625 drawn randomly from the presynaptic pool of neurons . to obtain a theory for the variances and covariances at zero frequency ( with @xmath626 )",
    "we may abbreviate @xmath627 by @xmath628 . for a population averaged theory",
    ", we need to replace in the variances @xmath629 of an individual neuron by the population average and replace the covariance @xmath630 for a given pair of neurons @xmath631 by the average over pairs that are statistically equivalent to @xmath632 . for a pair @xmath631 of neurons",
    "we will show that the set of equivalent pairs depends on the current realization of the connectivity since unconnected pairs are not equivalent to connected ones .",
    "therefore it is necessary to first average the covariance matrix over statistically equivalent neuron pairs given a fixed connectivity and to subsequently average over all possible realizations of the connectivity .",
    "the latter will be denoted as @xmath633}$ ] . for compactness of the notation , first we perform the averaging for the general case , where neuron @xmath5 belongs to population @xmath634 and neuron @xmath6 to population @xmath512 .",
    "we denote by @xmath635 , @xmath636 the sets of neuron indices belonging to populations @xmath634 and @xmath512 , respectively . subsequently replacing @xmath634 and @xmath512 by all possible combinations",
    "@xmath637 , we obtain the averaged self - consistency equations for the network .",
    "we denote the number of incoming connections to a neuron of type @xmath634 from the population of neurons of type @xmath512 as @xmath638 and the strength of a synaptic coupling as @xmath639 . rewriting the self - consistency equation explicitly with indices yields",
    "@xmath640 the last equation shows that for a connected pair @xmath631 of neurons ( @xmath641 or @xmath642 ) either of the first two sums contains a contribution @xmath643 or @xmath644 proportional to the variance of the projecting neuron .",
    "we therefore need to perform the averaging separately for connected and for unconnected pairs of neurons .",
    "we use the notation @xmath645 }     \\label{eq : c_conn_avg}\\ ] ] for the average covariance over pairs of neurons of types @xmath646 with a connection from neuron @xmath647 to neuron @xmath648 , where @xmath649 is the number neuron pairs connected in this way .",
    "an arrow to the right , @xmath650 , denotes a connection from neuron @xmath5 to neuron @xmath6 .",
    "note that we use the same letter @xmath278 for the population averaged covariances and for the covariances of individual pairs .",
    "the distinction can be made by the indices : @xmath651 throughout indexes a single neuron , @xmath652 identifies one of the populations @xmath653 .",
    "we denote the covariance averaged over unconnected pairs as @xmath654 }     \\ , .",
    "\\label{eq : c_unconn_avg}\\ ] ] we further use @xmath655 } \\label{eq : a_avg}\\ ] ] for the integrated variance averaged over all neurons of type @xmath634 . connected and the unconnected averaged covariances differ by the term proportional to the variance of the projecting neuron , as mentioned above @xmath656 as a consequence , we can express all quantities in terms of the averaged variance and the covariance averaged over unconnected pairs .",
    "we now proceed to average the integrated variance over population @xmath634 .",
    "since there are no self - connections in the network , we do not need to distinguish two cases here .",
    "replacing @xmath657 on the right hand side of , the first term of contributes @xmath658 }     = { \\text{e}_{{{\\bm{w}}}}\\left [ \\frac{1}{n_x } \\sum_{i \\in { \\mathcal{x } } } \\left ( \\sum_{k \\in { \\mathcal{e } } } w_{ik } c_{ki } + \\sum_{k \\in { \\mathcal{i } } } w_{ik } c_{ki } \\right ) \\right ] }     \\label{eq : a_avg_term_i }     \\\\",
    "\\nonumber    & = & \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xz } w_{xz } c_{z \\rightarrow x }     = \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xz } w_{xz } ( c_{z { \\not\\rightleftarrows}x } + w_{xz } a_{z } )    \\,.\\end{aligned}\\ ] ] from the second to the third step we used that the sum over @xmath261 ( @xmath262 ) yields non - zero contributions only if neuron @xmath261 ( @xmath262 ) connects to neuron @xmath5 .",
    "this happens in @xmath659 ( @xmath660 ) cases with the coupling weight @xmath661 ( @xmath662 ) .",
    "therefore the covariance averaged over connected pairs appears on the right hand side . in the last line we used the relation to express the connected covariance in terms of the variance and the covariance over unconnected pairs .",
    "the second term in is identical because of the symmetry @xmath663 . up to here , the structure of the network only entered in terms of the in - degree of the neurons .",
    "the contribution of the third term follows from a similar calculation @xmath664 }",
    "\\label{eq : a_avg_term_iii } \\\\",
    "\\nonumber    & = & { \\text{e}_{{{\\bm{w}}}}\\left [ \\frac{1}{n_x } \\sum_{i \\in { \\mathcal{x } } } \\left ( \\sum_{k \\neq l \\in { \\mathcal{e}}\\vee { \\mathcal{i } } } w_{ik } c_{kl } w_{il } + \\sum_{k \\in { \\mathcal{e}}\\vee { \\mathcal{i } } } w_{ik}^2 c_{kk } \\right ) \\right ] } \\\\",
    "\\nonumber    & = & \\sum_{u , v \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xu } k_{xv } w_{xu } w_{xv } \\left ( \\frac{k_{wu}}{n_u}(c_{v { \\leftarrow}u } - c_{v { \\not\\rightleftarrows}u } ) + \\frac{k_{uv}}{n_v}(c_{v { \\rightarrow}u } - c_{v { \\not\\rightleftarrows}u } ) + c_{v { \\not\\rightleftarrows}u } \\right)\\\\ \\nonumber     & + & \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xz } w_{xz}^2 a_z \\\\ \\nonumber      & = & \\sum_{u , v \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xu } k_{xv } w_{xu } w_{xv } c_{vu } + \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xz } w_{xz}^2 a_z    \\,.\\end{aligned}\\ ] ] from the second to the third step we assumed that among the @xmath665 pairs of neurons @xmath666 projecting to neuron @xmath5 , the fraction @xmath667 has a connection @xmath668 .",
    "these pairs contribute with the connected covariance .",
    "the connections in opposite direction contribute the other term of similar structure .",
    "we ignore multiple and reciprocal connections here , assuming the connection probability is low .",
    "we introduce the shorthand @xmath289 for the covariance averaged over all neuron pairs including connected and unconnected pairs @xmath669 this is the covariance which is observed on average when picking a pair of neurons of type @xmath634 and @xmath512 randomly . in this step , beyond the in - degree , the structure of the network entered through the expected number of connections between two populations .",
    "taken all three terms together , we arrive at @xmath670 the averaged covariances follow by similar calculations . here",
    "we only need to calculate the average over unconnected pairs @xmath631 given by , because the connected covariance follows from .",
    "the first sum in contributes @xmath671 }     \\label{eq : c_avg_term_i } \\\\",
    "\\nonumber      & = & \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } k_{xz } w_{xz } c_{zy},\\end{aligned}\\ ] ] where due to the absence of a direct connection between @xmath5 and @xmath6 , the term linear in the coupling and proportional to the variance is absent . from the symmetry @xmath672 it follows that the second term corresponds to an exchange of @xmath634 and @xmath512 in the last expression .",
    "the third sum in follows from an analog calculation as before @xmath673 } \\label{eq : c_avg_term_iii } \\\\",
    "\\nonumber    & = & \\sum_{z \\in \\{{\\text{e } } , { \\text{i}}\\ } } w_{xz } w_{yz } \\frac{k_{xz}k_{yz}}{n_z } a_z + c_{xy,\\text{corr } }    \\,.\\end{aligned}\\ ] ] in summary , the contributions from and together result in the self - consistency equation for the covariance @xmath674 we now simplify the expressions by assuming that the in - degree of a neuron and the incoming synaptic amplitudes do not depend on the type of the neuron , i.e. that excitatory and inhibitory neurons receive statistically the same input .",
    "formally this means that we need to replace @xmath675 by @xmath676 , the number of incoming connections from population @xmath512 and @xmath677 by @xmath678 , the coupling strength of a projection from a neuron of type @xmath512 .",
    "the covariance @xmath679 then has two distinct contributions , @xmath680 that depends on the type of neurons @xmath681 , and @xmath682 that does not .",
    "in particular @xmath265 and @xmath683 do not depend on @xmath684 and we omit their subscripts in the following .",
    "the variances fulfill @xmath685 the covariances satisfy @xmath686 the disjoint part @xmath680 determines the difference between the covariances for pairs of neurons of different type . using the parameters @xmath687 , @xmath688 , @xmath689 , @xmath690 ,",
    "the explicit form is @xmath691 therefore , also the covariances in the network obey the relation @xmath692 i.e. the mixed covariance can be eliminated and is given by the arithmetic mean of the covariances between neurons of same type . in matrix representation with the vector @xmath693 ,",
    "the self - consistency equation is @xmath694 the self consistent covariance can then be obtained by solving the system of linear equations @xmath695 the numerical solution shows that the variances for excitatory and inhibitory neurons are approximately the same , as depicted in a. in the following we therefore assume @xmath696 and then solve for the covariances . with the abbreviation @xmath697 , the third and fourth line yields the equation for the covariances @xmath698 \\label{eq : c_ex_in } \\\\",
    "\\nonumber    & + & kw ( c_{{\\text{e}}{\\not\\rightleftarrows}{\\text{e } } } - \\gamma g c_{{\\text{i}}{\\not\\rightleftarrows}{\\text{i } } } ) ( 1 - kw ( 1-\\gamma g ) )    + kw ( 1-\\gamma g ) \\begin{cases }       c_{{\\text{e}}{\\not\\rightleftarrows}{\\text{e } } } & \\text{for } \\ ; { \\text{e}}{\\text{e}}\\\\       c_{{\\text{i}}{\\not\\rightleftarrows}{\\text{i } } } & \\text{for } \\ ; { \\text{i}}{\\text{i}}\\end{cases}\\end{aligned}\\ ] ] the structure of the equation suggests to introduce the linear combination @xmath699 which satisfies @xmath700 we solve for @xmath222 and @xmath223 and insert for @xmath701 to obtain the covariances as @xmath702 + kw m\\\\    & = & g \\frac{(kw)^2}{(1 - kw ( 1 - \\gamma g))^2 } a\\\\ \\nonumber    & + & 2 \\frac{kw ( 1-\\gamma g)}{1 - kw ( 1-\\gamma g ) } a \\begin{cases }      \\frac{kw}{n_{\\text{e } } } & \\text{for } \\ ; { \\text{e}}{\\text{e}}\\\\        \\frac{-k \\gamma w g}{n_{\\text{i } } } & \\text{for } \\ ; { \\text{i}}{\\text{i}}\\end{cases }    \\ , .    \\ ] ] the covariance @xmath703 between unconnected neurons can be related to the covariance between the incoming currents this pair of neurons receives . expressing the self - consistency in terms of the covariances",
    "averaged over connected and unconnected pairs uncovers the connection @xmath704\\\\",
    "\\nonumber    & - & ( kw)^2 \\left [ \\frac{1}{n_{\\text{e } } } a_{\\text{e}}+ \\frac{(\\gamma g)^2}{n_{\\text{i } } } a_{\\text{i}}+ c_{{\\text{e}}{\\text{e } } } - 2 \\gamma g c_{{\\text{e}}{\\text{i } } } + ( \\gamma g)^2 c_{{\\text{i}}{\\text{i } } } \\right ]    \\,.\\end{aligned}\\ ] ] this self - consistency equation yields the argument , why the shared - input correlation @xmath705 cancels the contribution @xmath246 due to spike - train correlations in the covariance to the input currents ( see c , d )",
    ". rewriting in terms of these quantities results in @xmath706     \\label{eq : input_cov_suppression } \\\\",
    "\\nonumber    & = &   k w \\left [ c^\\text{in}_\\text{shared}/(kw)^2 + c^{\\text{in}}_\\text{corr}/(kw)^2 \\right ]    \\,.\\end{aligned}\\ ] ] if a self - consistent solution with small correlation @xmath707 which typically is @xmath708 ( for the parameters in , @xmath709 becomes larger than @xmath100 for @xmath710 )",
    ". the first term in the bracket is proportional to the contribution of shared input , the second term is due to correlations among pairs of different neurons .",
    "each of these terms is of order @xmath711 . due to the prefactor @xmath709",
    ", however , the sum of the two terms needs to be of order @xmath712 to fulfill the equation .",
    "hence , the terms must have different signs to cause the mutual cancellation .    to illustrate how the correlation structure is affected by feedback ,",
    "let us now consider the case where the feedback activity is perturbed ( `` feedforward scenario '' ) .",
    "we start from and , again , only consider the fluctuations at zero frequency , @xmath713    first , we consider a manipulation that preserves the single - neuron statistics @xmath714 , @xmath715 and the pairwise correlations @xmath242 , @xmath244 within each subpopulation , but neglects correlations @xmath243 between excitatory and inhibitory neurons .",
    "formally , this corresponds to the block diagonal correlation matrix @xmath716 here , we have replaced the individual entries of the correlation matrix by the corresponding subpopulation averaged correlations .",
    "the calculation of the response auto- and cross - correlation @xmath283 and @xmath284 is similar as for the expressions and , with the difference that terms containing @xmath243 are absent : @xmath717    as an alternative type of feedback manipulation , we assume that all correlations are equal , irrespective of the neuron type . to this end , we replace all spike correlations by the population average @xmath718 .",
    "thus , the covariance matrix reads @xmath719 the calculation follows the one leading to the expressions and and results in @xmath720",
    "we thank the three reviewers for their constructive comments ."
  ],
  "abstract_text": [
    "<S> correlations in spike - train ensembles can seriously impair the encoding of information by their spatio - temporal structure . </S>",
    "<S> an inevitable source of correlation in finite neural networks is common presynaptic input to pairs of neurons . </S>",
    "<S> recent studies demonstrate that spike correlations in recurrent neural networks are considerably smaller than expected based on the amount of shared presynaptic input . here </S>",
    "<S> , we explain this observation by means of a linear network model and simulations of networks of leaky integrate - and - fire neurons . </S>",
    "<S> we show that inhibitory feedback efficiently suppresses pairwise correlations and , hence , population - rate fluctuations , thereby assigning inhibitory neurons the new role of active decorrelation . </S>",
    "<S> we quantify this decorrelation by comparing the responses of the intact recurrent network ( feedback system ) and systems where the statistics of the feedback channel is perturbed ( feedforward system ) . </S>",
    "<S> manipulations of the feedback statistics can lead to a significant increase in the power and coherence of the population response . </S>",
    "<S> in particular , neglecting correlations within the ensemble of feedback channels or between the external stimulus and the feedback amplifies population - rate fluctuations by orders of magnitude . </S>",
    "<S> the fluctuation suppression in homogeneous inhibitory networks is explained by a negative feedback loop in the one - dimensional dynamics of the compound activity . </S>",
    "<S> similarly , a change of coordinates exposes an effective negative feedback loop in the compound dynamics of stable excitatory - inhibitory networks . </S>",
    "<S> the suppression of input correlations in finite networks is explained by the population averaged correlations in the linear network model : in purely inhibitory networks , shared - input correlations are canceled by negative spike - train correlations . in excitatory - inhibitory networks , </S>",
    "<S> spike - train correlations are typically positive . here , the suppression of input correlations is not a result of the mere existence of correlations between excitatory ( e ) and inhibitory ( i ) neurons , but a consequence of a particular structure of correlations among the three possible pairings ( ee , ei , ii ) .      the spatio - temporal activity pattern generated by a recurrent neuronal network can provide a rich dynamical basis which allows readout neurons to generate a variety of responses by tuning the synaptic weights of their inputs . </S>",
    "<S> the repertoire of possible responses and the response reliability become maximal if the spike trains of individual neurons are uncorrelated . </S>",
    "<S> spike - train correlations in cortical networks can indeed be very small , even for neighboring neurons . </S>",
    "<S> this seems to be at odds with the finding that neighboring neurons receive a considerable fraction of inputs from identical presynaptic sources constituting an inevitable source of correlation . in this article </S>",
    "<S> , we show that inhibitory feedback , abundant in biological neuronal networks , actively suppresses correlations . </S>",
    "<S> the mechanism is generic : it does not depend on the details of the network nodes and decorrelates networks composed of excitatory and inhibitory neurons as well as purely inhibitory networks . </S>",
    "<S> for the case of the leaky integrate - and - fire model , we derive the correlation structure analytically . the new toolbox of formal linearization and a basis transformation exposing the feedback component is applicable to a range of biological systems . </S>",
    "<S> we confirm our analytical results by direct simulations .    * </S>",
    "<S> correspondence to : * + tom tetzlaff + inst .  of neuroscience and medicine ( inm-6 ) + computational and systems neuroscience + research center jlich + d-52425 jlich + germany + t.tetzlaff@fz-juelich.de + </S>"
  ]
}