{
  "article_text": [
    "we consider the case of a cluster of flexible power consumers , where _ flexibility _ is understood as the possibility for each consumer in the cluster to change her consumption depending on the electricity price and on her personal preferences .",
    "there are many examples of methods to schedule the consumption of individual price - responsive loads ( see , e.g. , @xcite ) .",
    "the portfolio of flexible consumers is managed by a retailer or _ aggregator _ , which bids in a wholesale electricity market on behalf of her customers .",
    "we consider the case where such a market accepts complex bids , consisting of a series of price - energy bidding curves , consumption limits , and maximum pick - up and drop - off rates . in this paper",
    ", we present a data - driven methodology for determining the complex bid that best represents the reaction of the pool of flexible consumers to the market price .",
    "the contributions of this paper are fourfold .",
    "the first contribution corresponds to the methodology itself : _ we propose a novel approach to capture the price - response of a pool of flexible consumers in the form of a market bid using price - consumption data .",
    "_ in this work , the price is given as the result of a competitive market - clearing process , and we have access to it only from historical records .",
    "this is in contrast to some previous works , where the price is treated as a control variable to be decided by the aggregator or retailer . in @xcite , for example , the relationship between price and consumption is first modeled by a finite impulse response ( fir ) function as in @xcite and peak load reduction is achieved by modifying the price .",
    "similar considerations apply to the works of @xcite , where a bilevel representation of the problem is used : the lower - level problem optimizes the household consumption based on the broadcast electricity price , which is determined by the upper - level problem to maximize the aggregators / retailer s profit .",
    "another series of studies concentrate on estimating price - energy bids for the participation of different types of flexible loads in the wholesale electricity markets , for example , time - shiftable loads @xcite , electric vehicles @xcite and thermostatically - controlled loads @xcite .",
    "contrary to these studies , our approach is data - driven and does not require any assumption about the nature of the price - responsive loads in the aggregation .",
    "the second contribution lays in the estimation procedure : _ we develop an inverse optimization framework that results in a bilevel optimization problem_. from a methodological point of view , our approach builds on the inverse optimization scheme introduced in @xcite , but with several key differences .",
    "first , we let the measured solution be potentially non - optimal , or even non - feasible , for the targeted optimization problem as in @xcite and @xcite .",
    "moreover , we extend the concept of inverse optimization to a problem where the estimated parameters may depend on a set of features and are also allowed to be in the constraints , and not only in the objective function .",
    "third , _ we study heuristic solution methods to reduce the computing times resulting from the consideration of large datasets of features for the model estimation .",
    "_ we do not solve the resulting bilevel programming problem to optimality but instead we obtain an approximate solution by penalizing the violation of complementarity constraints following a procedure inspired by the work of  @xcite .",
    "finally , _ we test the proposed methodology using data from a real - world experiment _ that was conducted as a part of the _ olympic peninsula project _ @xcite .",
    "in this section , we describe the methodology to determine the optimal market bid for a pool of price - responsive consumers .",
    "the estimation procedure is cast as a bilevel programming problem , where the upper level seeks to minimize a norm of the estimation error , in particular , the absolute difference between the measured consumption and the estimated one , while the lower level ensures that the estimated consumption is optimal , given the reconstructed bid parameters and the electricity price .",
    "the lower - level problem models the price - response of the pool of consumers in the form of a market bid , whose parameters are determined by the upper - level problem .",
    "the bid is given by @xmath0 , which consists of the marginal utility corresponding to each bid block @xmath1 , the maximum load pick - up and drop - off rates ( analogues to the ramp - up and -down limits of a power generating unit ) , the minimum power consumption , and the maximum power consumption , at time @xmath2 , in that order .",
    "the utility is defined as the benefit that the pool of users obtains from consuming a certain amount of electricity .",
    "the marginal utility @xmath3 at time @xmath4 is formed by @xmath5 blocks , where all blocks have equal size , spanning from the minimum to the maximum allowed consumption . in other words ,",
    "the size of each block is @xmath6 .",
    "furthermore , we assume that the marginal utility is monotonically decreasing as consumption increases , i.e. , @xmath7 for all times @xmath4 .",
    "finally , the total consumption at time @xmath4 is given by the sum of the minimum power demand plus the consumption linked to each bid block , namely , @xmath8 .",
    "typically , the parameters of the bid may change across the hours of the day , the days of the week , the month , the season , or any other indicator variables related to the time .",
    "moreover , the bid can potentially depend on some external variables such as temperature , solar radiation , wind speed , etc .",
    "indicator variables and external variables , often referred to as _ features _ , can be used to explain more accurately the parameters of the market bid that best represents the price - response of the pool of consumers .",
    "this approach is potentially useful in practical applications , as numerous sources of data can help better explain the consumers price - response .",
    "we consider the @xmath9 external variables or features , named @xmath10 for @xmath11 , to be affinely related to the parameters defining the market bid by a coefficient @xmath12 .",
    "this affine dependence can be enforced in the model by letting @xmath13 , @xmath14 , @xmath15 , @xmath16 , and @xmath17 .",
    "the affine coefficients @xmath18,@xmath19 , @xmath20 , @xmath21 and @xmath22 , and the intercepts @xmath23 enter the model of the pool of consumers ( the lower - level problem ) as parameters , together with the electricity price .",
    "the objective is to maximize consumers welfare , namely , the difference between the total utility and the total payment :    [ eq : orig ] @xmath24 where @xmath25 is the consumption assigned to the utility block @xmath1 during the time @xmath4 , @xmath3 is the marginal utility obtained by the consumer in block @xmath1 and time @xmath4 , and @xmath26 is the price of the electricity during time @xmath4 . for notational purposes ,",
    "let @xmath27 .",
    "the problem is constrained by    llr & _ t + _ b x_b , t - _ t-1 - _ b x_b , t-1 r^u_t & t _ -1    [ eq : prim1 ] + & _ t-1 + _ b x_b , t-1 - _ t- _ b x_b , t r^d_t & t _",
    "-1  [ eq : prim2 ] + & x_b , t & b , t   [ eq : prim3 ] + & x_b , t 0 & b , t .",
    "[ eq : prim4 ]    equations and impose a limit on the load pick - up and drop - off rates , respectively .",
    "the set of equations defines the size of each utility block to be equally distributed between the maximum and minimum power consumptions .",
    "constraint enforces the consumption pertaining to each utility block to be positive .",
    "note that , by definition , the marginal utility is decreasing in @xmath28 ( @xmath7 ) , so one can be sure that the first blocks will be filled first .",
    "we denote the dual variables associated with each set of primal constraints as @xmath29 and @xmath30 .",
    "problem is linear , hence it can be equivalently recast as the following set of kkt conditions @xcite , where  are the stationary conditions and  enforce complementarity slackness :    [ eq : kkt ]    llr & -_2^u + _",
    "2^d -_b,1 + _",
    "b,1 = a_b,1 - p_1  b [ eq : stat1 ] + &",
    "_ t^u -_t+1^u - _ t^d + _",
    "t+1^d -_b , t + _ b , t = a_b , t - p_t + &  b , t _ -1 [ eq : stat2 ] + & _ t^u - _ t^d -_b , t + _ b , t = a_b , t - p_t  b [ eq : stat3 ] + & _ t + _ b x_b , t - _ t-1 - _ b x_b , t-1 r^u_t _ t^u 0 + &   t _ -1 [ eq : comp1 ] + & _ t-1 + _ b x_b , t-1 -_t- _ b x_b , tr^d_t _ t^d 0 + &   t _ -1 [ eq : comp2 ] + & x_b , t",
    "_ b , t 0 b , t [ eq : comp6 ] + & 0 x_b , t _",
    "b , t 0   b , t .[eq : comp7 ]      given a time series of price - consumption pairs @xmath31 , the inverse problem consists in estimating the value of the parameters @xmath32 defining the objective function and the constraints of the lower - level problem   such that the optimal consumption @xmath33 resulting from this problem is as close as possible to the measured consumption @xmath34 in terms of a certain norm .",
    "the parameters of the lower - level problem @xmath32 form , in turn , the market bid that best represents the price - response of the pool .    in mathematical terms",
    ", the inverse problem can be described as a minimization problem :    [ eq : kktobj_lin1 ]    @xmath35 { \\underline{p}_{t } + \\sum_{b \\in \\mathcal{b } } x_{b , t } - x_{t}^{meas } } \\label{eq : kktobj}\\end{aligned}\\ ] ]    subject to @xmath36    constraints are the upper - level constraints , ensuring that the estimated marginal utility must be monotonically decreasing .",
    "constraints correspond to the kkt conditions of the lower - level problem .",
    "notice that the upper - level variables @xmath32 , which are parameters in the lower - level problem , are also implicitly constrained by the optimality conditions   of this problem , i.e. , by the fact that @xmath25 must be optimal for  .",
    "this guarantees , for example , that the minimum power consumption be positive and equal to or smaller than the maximum power consumption ( @xmath37 ) .",
    "furthermore , the maximum pick - up rate is naturally constrained to be equal to or greater than the negative maximum drop - off rate ( @xmath38 ) .",
    "having said that , in practice , we need to ensure that these constraints are fulfilled for all possible realizations of the external variables and not only for the ones observed in the past .",
    "we achieved this by enforcing the robust counterparts of these constraints @xcite .",
    "an example is provided in the appendix .",
    "parameter @xmath39 represents the weight of the estimation error at time @xmath4 in the objective function .",
    "these weights have a threefold purpose .",
    "firstly , if the inverse optimization problem is applied to estimate the bid for the day - ahead market , the weights could represent the cost of balancing power at time @xmath4 .",
    "in such a case , consumption at hours with a higher balancing cost would weigh more and consequently , would be fit better than that occurring at hours with a lower balancing cost .",
    "secondly , the weights can include a forgetting factor to give exponentially decaying weights to past observations .",
    "finally , a zero weight can be given to missing or wrongly measured observations .",
    "the absolute value of the residuals can be linearized by adding two extra nonnegative variables , and by replacing the objective equation with the following linear objective function plus two more constraints , namely , and :    [ eq : kktobj_lin ] @xmath40 subject to @xmath41    in the optimum , and when @xmath42 , and imply that @xmath43 if @xmath44 , else @xmath45 . by using this reformulation of the absolute value , the weights could also reflect whether the balancing costs are symmetric or skewed",
    ". in the latter case , there would be different weights for @xmath46 and @xmath47 .",
    "the estimation problem   is non - linear due to the complementarity constraints of the kkt conditions of the lower - level problem .",
    "there are several ways of dealing with these constraints , for example , by using a non - linear solver @xcite , by recasting them in the form of disjunctive constraints @xcite , or by using sos1 variables @xcite . in any case ,",
    "problem   is to solve and the computational time grows exponentially with the number of complementarity constraints .",
    "our numerical experiments showed that , for realistic applications involving multiple time periods and/or numerous features , none of these solution methods were able to provide a good solution to problem   in a reasonable amount of time . to tackle this problem in an effective manner",
    ", we propose the following two - step solution strategy , inspired by @xcite :    step 1 : : :     solve a linear relaxation of the mathematical program with    equilibrium constraints   by penalizing violations of the    complementarity constraints .",
    "step 2 : : :    fix the parameters defining the constraints of the lower - level    problem  , i.e. ,    @xmath48    and @xmath22 , at the values estimated    in step 1 . then , recompute the parameters defining the utility    function , @xmath3 and @xmath49 . to this    end , we make use of the primal - dual reformulation of the    price - response model   @xcite .    both steps are further described in the subsections below .",
    "note that the obtained solution does not guarantee optimality , and it is only proved to work satisfactorily in practice ( see the case study in section  [ sec : studycase ] ) .",
    "the so - called penalty method is a convex ( linear ) relaxation of a mathematical programming problem with equilibrium constraints , whereby the complementarity conditions of the lower - level problem , that is , problem  , are moved to the objective function of the upper - level problem .",
    "thus , we penalize the sum of the dual variables of the inequality constraints of problem   and their slacks , where the slack of a",
    " @xmath50\"-constraint is defined as the difference between its right - hand and left - hand sides , in such a way that the slack is always nonnegative .",
    "for example , the slack of the constraint relative to the maximum pick - up rate   is defined as @xmath51 , and analogously for the rest of the constraints of the lower - level problem .",
    "the penalization can neither ensure that the complementarity constraints are satisfied , nor that the optimal solution of the inverse problem is achieved . instead ,",
    "with the penalty method , we obtain an approximate solution . in the case study of section  [ sec : studycase ] , nonetheless , we show that this solution performs notably well .    after relaxing the complementarity constraints  , the objective function of the estimation problem writes as :    [ eq : penalization ] @xmath52  = 13 , with the variables being @xmath53 , subject to the following constraints :    ll & ( [ eq : inv1])-([eq : inv3 ] ) , ( [ eq : prim1])-([eq : prim4 ] ) , ( [ eq : stat1])-([eq : stat3 ] ) + & _",
    "t^u , _ t^d 0 t _ -1 [ eq : dualfeas1 ] + & _ b , t,_b , t 0   b , t [ eq : dualfeas2 ] .",
    "the objective function of the relaxed estimation problem is composed of two terms .",
    "the first term represents the weighted sum of the absolute values of the deviations of the estimated consumption from the measured one .",
    "the second term , which is multiplied by the penalty term @xmath54 , is the sum of the dual variables of the constraints of the consumers price - response problem plus their slacks .",
    "note that summing up the slacks of the constraints of the consumers price - response problem eventually boils down to summing up the right - hand sides of such constraints .",
    "the weights of the estimation errors ( @xmath55 ) also multiply the penalization terms . thus , the model weights violations of the complementarity constraints in the same way as the estimations errors are weighted .",
    "objective function is subject to the auxiliary constraints modeling the absolute value of estimation errors ( [ eq : inv1])([eq : inv2 ] ) ; the upper - level - problem constraints imposing monotonically decreasing utility blocks ; and the primal and dual feasibility constraints of the lower - level problem , ( [ eq : prim1])([eq : prim4 ] ) , ( [ eq : stat1])([eq : stat3 ] ) , and ( [ eq : dualfeas1])([eq : dualfeas2 ] ) .    the penalty parameter @xmath54 should be tuned carefully .",
    "we use cross - validation to this aim , as described in the case study ; we refer to section [ sec : studycase ] for further details .    finding the optimal solution to problem   is computationally cheap , because it is a linear programming problem . on the other hand ,",
    "the optimal solution to this problem might be significantly different from the one that we are actually looking for , which is the optimal solution to the original estimation problem  .",
    "furthermore , the solution to   depends on the user - tuned penalization parameter @xmath54 , which is given as an input and needs to be decided beforehand .      in this subsection",
    ", we elaborate on the second step of the strategy we employ to estimate the parameters of the market bid that best captures the price - response of the cluster of loads . recall that this strategy has been briefly outlined in the introduction of section  [ sec : solution ] .",
    "the ultimate purpose of this additional step is to re - estimate or refine the parameters characterizing the utility function of the consumers price - response model  , namely , @xmath56 and the coefficients @xmath18 . in plain words , we want to improve the estimation of these parameters with respect to the values that are directly obtained from the relaxed estimation problem  . with this aim in mind , we fix the parameters defining the constraints of the cluster s price - response problem   to the values estimated in step 1 , that is , to the values obtained by solving the relaxed estimation problem  . therefore , the bounds @xmath57 and the maximum pick - up and drop - off rates @xmath58 are now treated as given parameters in this step .",
    "consequently , the only upper - level variables that enter the lower - level problem  , namely , the intersects @xmath56 of the various blocks defining the utility function and the linear coefficients @xmath18 , appear in the objective function of problem  .",
    "this will allow us to formulate the utility - refining problem as a linear programming problem .",
    "indeed , consider the primal - dual optimality conditions of the consumers price - response model  , that is , the primal and dual feasibility constraints and the strong duality condition .",
    "these conditions are also necessary and sufficient for optimality due to the linear nature of this model .",
    "we determine the ( possibly approximate ) block - wise representation of the measured consumption at time @xmath4 , @xmath59 , which we denote by @xmath60 and is given as a sum of @xmath61 blocks of size @xmath62 each .",
    "in particular , we define @xmath63 as follows : @xmath64 where each @xmath65 is determined such that the blocks with higher utility are filled first .",
    "now we replace @xmath28 in the primal - dual reformulation of   with @xmath60 .",
    "consequently , the primal feasibility constraints are ineffective and can be dropped .    once @xmath28 has been replaced with @xmath60 in the primal - dual reformulation of   and the primal feasibility constraints",
    "have been dropped , we solve an optimization problem ( with the utility parameters @xmath66 and @xmath18 as decision variables ) that aims to minimize the weighted duality gap , as in @xcite .",
    "for every time period @xmath4 in the training data set , we obtain a contribution ( @xmath67 ) to the total duality gap ( @xmath68 ) , defined as the difference between the dual objective function value at time @xmath4 minus the primal objective function value at time @xmath4 .",
    "this allows us to find close - to - optimal solutions for the consumers price - response model  .",
    "thus , in the case when the duality gap is equal to zero , the measured consumption , if feasible , would be optimal in  . in the case",
    "when the duality gap is greater than zero , the measured consumption would not be optimal . intuitively , we attempt to find values for the parameters defining the block - wise utility function such that the measured consumption is as optimal as possible for problem  .    hence , the utility - refining problem consists in minimizing the sum of weighted duality gaps    [ eq : primdual ]    l  _ t w_t_t .",
    "[ eq : obj_ref ]    note that we assign different weights to the duality gaps accrued in different time periods , in a way analogous to what we do with the absolute value of residuals in .",
    "objective function is subject to    llr & _ b a_b,1x_b,1^m - p_1_b x_b,1 + _ 1 = _ b ( ) _ b,1 & [ eq : objectivesprimdual ] + & _ b a_b , tx_b , t^m - p_t_b x_b , t + _ t = _ b ( ) _ b , t + & + & ( r^u_t - _ t + _ t-1 ) _ t^u + ( r^d_t + _ t - _ t-1 ) _",
    "t^d  t _ -1 [ eq : objectivesprimdual2 ] & + & - [ eq : stat_refine ] & + & a_b , t a_b+1,t t [ eq : monotref ] + & _ t^u , _",
    "t^d 0   t _ -1 [ eq : feasref1 ] + & ^_t,^_t,_b , t , _ b , t 0 t [ eq : feasref2 ]    the set of constraints constitutes the relaxed strong duality conditions , which express that the objective function of the original problem at time @xmath4 , previously formulated in equation , plus the duality gap at time @xmath4 , denoted by @xmath67 , must be equal to the objective function of its dual problem also at time @xmath4 .",
    "equation works similarly , but for @xmath69 .",
    "the constraints relative to the dual of the original problem are grouped in .",
    "constraint requires that the estimated utility be monotonically decreasing .",
    "finally , constraints and impose the non - negative character of dual variables .",
    "the proposed methodology to estimate the market bid that best captures the price - response of a pool of flexible consumers is tested using data from a real - life case study .",
    "the data relates to the olympic peninsula experiment , which took place in washington and oregon states between may 2006 and march 2007 @xcite .",
    "the electricity price was sent out every fifteen minutes to 27 households that participated in the experiment .",
    "the price - sensitive controllers and thermostats installed in each house decided when to turn on and off the appliances , based on the price and on the house owner s preferences .",
    "for the case study , we use hourly measurements of load consumption , broadcast price , and observed weather variables , specifically , outside temperature , solar irradiance , wind speed , humidity , dew point and wind direction .",
    "moreover , we include 0/1 feature variables to indicate the hour of the day , with one binary variable per hour ( from 0 to 23 ) , and one per day of the week ( from 0 to 6 ) .",
    "a sample of the dataset is shown in figure [ fig : pricetempsep ] , where the load is plotted in the upper plot , the price in the middle plot , and the load versus the outside temperature and the dew point in the bottom plots .",
    "the lines depicted in the bottom plots represent the linear relationship between the pairs of variables , and these are negative in both cases .",
    "the high variability in the price is also noteworthy : from the 1st to the 8th of december , the standard deviation of the price is 5.6 times higher than during the rest of the month ( $ @xmath70/mwh versus $ @xmath71/mwh ) .      to test the quality of the market bid estimated by the proposed methodology",
    ", we quantify and assess the extent to which such a bid is able to _ predict _ the consumption of the cluster of price - responsive loads . for the evaluation , we compare two versions of the inverse optimization scheme proposed in this paper with the auto - regressive model with exogenous inputs ( arx ) described in @xcite . note that this time series model was also applied by @xcite to the same data set of the olympic peninsula project .",
    "all in all , we benchmark three different models :    * arx * , : :    which stands for auto - regressive model with exogenous inputs @xcite .",
    "this is the type of prediction model used in @xcite and @xcite .",
    "the    consumption @xmath33 is modeled as a linear combination of    past values of consumption up to lag @xmath72 ,    @xmath73 ,    and other explanatory variables    @xmath74 .    in mathematical terms , an arx model can be expressed as    @xmath75    with @xmath76 and    @xmath77 is the variance . *",
    "simple inv * : :    this benchmark model consists in the utility - refining problem    presented in section [ sec : refine ] , where the parameters of maximum    pick - up and drop - off rates and consumption limits are computed from    past observed values of consumption in a simple manner : we set the    maximum pick - up and drop - off rates to the maximum values taken on by    these parameters during the last seven days of observed data .",
    "all the    features are used to explain the variability in the block - wise    marginal utility function of the pool of price - responsive consumers :    outside temperature , solar radiation , wind speed , humidity , dew point ,    pressure , and hour and week - day indicators . for this model",
    ", we use    b=12 blocks of utility .",
    "this benchmark is inspired from the more    simplified inverse optimization scheme presented in @xcite and    @xcite ( note , however , that neither @xcite , nor @xcite consider the    possibility of leveraging auxiliary information , i.e. , features , to    better explain the data , unlike we do for the problem at hand ) .",
    "* inv * : :    this corresponds to the inverse optimization scheme with features that    we propose , which runs following the two - step estimation procedure    described in section  [ sec : solution ] with b=12 blocks of utility . here",
    "we only use the outside temperature and hourly indicator variables as    features .",
    "we re - parametrize weights @xmath55 with respect to    a single parameter , called forgetting factor , and denoted as    @xmath78 , in the following manner :    @xmath79 for    @xmath80 and @xmath81 being the total    number of periods .",
    "the variable @xmath82 indicates whether    the observation was correctly measured ( @xmath83 ) or not    ( @xmath84 ) .",
    "parameter @xmath85 indicates how rapidly    the weight drops ( how rapidly the model forgets )",
    ". when    @xmath86 , the weight of the observations is either 1 or 0    depending on the variable @xmath82 .",
    "as @xmath85    increases , the recent observations weight comparatively more than the    old ones .",
    "in this subsection we validate the benchmarked models and assess their performance during the test month of december 2006 .    for the sake of simplicity ,",
    "we assume the price and the features to be known for the past and also for the future . it is worth noticing , though , that the proposed methodology need not a prediction of the electricity price when used for bidding in the market and not for predicting the aggregated consumption of a cluster of loads .",
    "this is so because the market bid expresses the desired consumption of the pool of loads for any price that clears the market .",
    "the same can not be said , however , for prediction models of the type of arx , which would need to be used in combination with extra tools , no matter how simple they could be , for predicting the electricity price and for optimizing under uncertainty in order to generate a market bid .",
    "there are two parameters that need to be chosen before testing the models : the penalty parameter @xmath54 and the forgetting factor @xmath85 .",
    "we seek a combination of parameters such that the prediction error is minimized .",
    "we achieve this by validating the models with past data , in a rolling - horizon manner , and with different combinations of the parameters @xmath54 and @xmath85 .",
    "the results are shown in figure [ fig : interaction ] .",
    "the mape is shown on the y - axis against the penalty @xmath54 in the x - axis , with the different lines corresponding to different values of the forgetting factor @xmath85 . from this plot",
    ", it can be seen that a forgetting factor of @xmath87 or @xmath88 yields a better performance than when there is no forgetting factor at all ( @xmath86 ) , or when this is too high ( @xmath89 ) .",
    "we conclude that selecting @xmath90 and @xmath87 results in the best performance of the model , in terms of the mape .     and",
    "@xmath85 , to be used during december . ]",
    "once the different models have been validated , we proceed to test them . for this purpose , we first set the cross - validated input parameters to @xmath90 and @xmath87 , and then , predict the load for the next day of operation in a rolling - horizon manner . in order to mimic a real - life usage of these models",
    ", we estimate the parameters of the bid on every day of the test period at 12:00 using historical values from three months in the past .",
    "then , as if the market were cleared , we input the price of the day - ahead market ( 13 to 36 hours ahead ) in the consumers price - response model , obtaining a forecast of the consumption . finally , we compare the predicted versus the actual realized consumption and move the rolling - horizon window to the next day repeating the process for the rest of the test period .",
    "similarly , the parameters of the arx model are re - estimated every day at 12:00 , and predictions are made for 13 to 36 hours ahead .",
    "results for a sample of consecutive days , from the 10th to the 13th of december , are shown in figure [ fig : predicted ] .",
    "the actual load is displayed in a continuous solid line , while the load predictions from the various benchmarked models are shown with different types of markers .",
    "first , note that the _ simple inv _ model is clearly under - performing compared to the other methodologies , in terms of prediction accuracy .",
    "recall that , in this model , the maximum and minimum load consumptions , together with the maximum pick - up and drop - off rates , are estimated from historical values and assumed to remain constant along the day , independently of the external variables ( the features ) .",
    "this basically leaves the utility alone to model the price - response of the pool of houses , which , judging from the results , is not enough .",
    "the arx model is able to follow the load pattern to a certain extent .",
    "nevertheless , it is not able to capture the sudden decreases in the load during the night time or during the peak hours in the morning .",
    "the proposed model ( _ inv _ ) features a considerably much better performance .",
    "it is able to follow the consumption pattern with good accuracy .",
    "the performance of each of the benchmarked models during the whole month of december is summarized in table [ tab : errors ] .",
    "the first column shows the mean absolute error ( mae ) , the second column provides the root mean square error ( rmse ) , and the third column collects the mean absolute percentage error ( mape ) .",
    "the three performance metrics lead to the same conclusions : that the price - response models we propose , i.e. , _ inv _ , perform better than the arx model and the _ simple inv _ model .",
    "the results collated in table [ tab : errors ] also yield an interesting conclusion : that the electricity price is not the main driver of the consumption of the pool of houses and , therefore , is not explanatory enough to predict the latter .",
    "we conclude this after seeing the performance of the _ simp inv _ , which is not able to follow the load just by modeling the price - consumption relationship by means of an utility function .",
    "the performance is remarkably enhanced when proper estimations of the maximum pick - up and drop - off rates and the consumptions bounds are employed .",
    ".performance measures for the three benchmarked models during december . [ cols=\"^,^,^,^ \" , ]     [ tab : errors2 ]    by means of cross - validation  @xcite , we find that the user - tuned parameters yielding the best performance vary over the year . for september , the best combination is @xmath91 , @xmath86 , while for march it is @xmath91 , @xmath87 .",
    "the optimized penalization parameter @xmath54 turns out to be higher in september and march than in december .",
    "this penalization parameter is highly related to the actual flexibility featured by the pool of houses .",
    "indeed , for a high enough value of the penalty ( say @xmath92 for this case study ) , violating the complementarity conditions associated with the consumers price - response model   is relatively highly penalized .",
    "hence , at the optimum , the slacks of the complementarity constraints in the relaxed estimation problem   will be zero or close to zero .",
    "when this happens , it holds at the optimum that @xmath93 and @xmath94 .",
    "the resulting model is , therefore , equivalent to a linear model of the features , fit by least weighted absolute errors .",
    "when the best performance is obtained for a high value of @xmath54 , it means that the pool of houses does not respond so much to changes in the price . on the other hand , as the best value for the penalization parameter @xmath54 decreases towards zero , the pool becomes more price - responsive : the maximum pick - up and drop - off rates and the consumption limits leave more room for the aggregated load to change depending on the price .    because the penalization parameter is the lowest during december ,",
    "we conclude that more flexibility is observed during this month than during september or march .",
    "the reason could be that december is the coldest of the months studied , with a recorded temperature that is on average 9.4@xmath95c lower , and it is at times of cold whether when the electric water heater is used the most .",
    "we consider the market - bidding problem of a pool of price - responsive consumers .",
    "these consumers are , therefore , able to react to the electricity price , e.g. , by shifting their consumption from high - price hours to lower - price hours .",
    "the total amount of electricity consumed by the aggregation has to be purchased in the electricity market , for which the aggregator or the retailer is required to place a bid into such a market .",
    "traditionally , this bid would simply be a forecast of the load , since the load has commonly behaved inelastically .",
    "however , in this paper , we propose to capture the price - response of the pool of flexible loads through a more complex , but still quite common market bid that consists of a stepwise marginal utility function , maximum load pick - up and drop - off rates , and maximum and minimum power consumption , in a manner analogous to the energy offers made by power producers .",
    "we propose an original approach to estimate the parameters of the bid based on inverse optimization and bi - level programming .",
    "furthermore , we use auxiliary variables to better explain the parameters of the bid . the resulting non - linear problem is relaxed to a linear one , the solution of which depends on a penalization parameter .",
    "this parameter is chosen by cross - validation , proving to be adequate from a practical point of view .",
    "for the case study , we used data from the olympic peninsula project to asses the performance of the proposed methodology .",
    "we have shown that the estimated bid successfully models the price - response of the pool of houses , in such a way that the mean absolute percentage error incurred when using the estimated market bid for predicting the consumption of the pool of houses is kept in between 14% and 22% for all the months of the test period .",
    "we envision two possible avenues for improving the proposed methodology .",
    "the first one is to better exploit the information contained in a large dataset by allowing for non - linear dependencies between the market - bid parameters and the features .",
    "this could be achieved , for example , by the use of b - splines .",
    "the second one has to do with the development of efficient solution algorithms capable of solving the exact estimation problem within a reasonable amount of time , instead of the relaxed one .",
    "this could potentially be accomplished by decomposition and parallel computation .",
    "r.  halvgaard , n.  poulsen , h.  madsen , and j.  jorgensen , `` economic model predictive control for building climate control in a smart grid , '' _ innovative smart grid technologies ( isgt ) , 2012 ieee pes _ , pp . 16 , 2012 .",
    "mohsenian - rad and a.  leon - garcia , `` optimal residential load control with price prediction in real - time electricity pricing environments , '' _ ieee transactions on smart grid _ ,",
    "1 , no .  2 , pp . 120133 , 2010 .",
    "o.  corradi , h.  ochsenfeld , h.  madsen , and p.  pinson , `` controlling electricity consumption by forecasting its response to varying prices , '' _ ieee transactions on power systems _ , vol .",
    "28 , no .  1 ,",
    "pp . 421429 , 2013 .",
    "m.  zugno , j.  m. morales , p.  pinson , and h.  madsen , `` a bilevel model for electricity retailers participation in a demand response market environment , '' _ energy economics _ , vol .",
    "182  197 , mar . 2013 .",
    "c.  chen , s.  kishore , and l.  snyder , `` an innovative rtp - based residential power scheduling scheme for smart grids , '' in _ 2011 ieee international conference on acoustics , speech and signal processing ( icassp ) _ , 2011 , pp .",
    "59565959 .",
    "g.  e.  asimakopoulou , a.  g.  vlachos and n.  d.  hatziargyriou , `` hierarchical decision making for aggregated energy management of distributed resources , '' _ power systems , ieee transactions on _ , vol .",
    "30 , no .  6 , pp .",
    "32553264 , nov .",
    "2015 .",
    "m.  gonzalez  vaya and g.  andersson , `` optimal bidding strategy of a plug - in electric vehicle aggregator in day - ahead electricity markets under uncertainty , '' _ power systems , ieee transactions on _ , vol .",
    "30 , no .  5 ,",
    "pp . 23752385 , sep .",
    "s.  li , w.  zhang , j.  lian , and k.  kalsi , `` market - based coordination of thermostatically controlled loads ",
    "part i : a mechanism design formulation , '' _ power systems , ieee transactions on _ , in press , 2015 .",
    "e.  m.  l. beale and j.  a. tomlin , `` special facilities in a general mathematical programming system for non - convex problems using ordered sets of variables , '' _ operations research _ , vol .  69 , pp . 447454 , 1970 .",
    "next we show how to formulate robust constraints to ensure that the estimated minimum consumption be always equal to or lower than the estimated maximum consumption . at all times , and for all plausible realizations of the external variables , we want to make sure that : @xmath96            following the same reasoning , one can obtain the set of constraints that guarantees the non - negativity of the lower bound and consistent maximum pick - up and drop - off rates .",
    "we leave the exposition and explanation of these constraints out of this paper for brevity ."
  ],
  "abstract_text": [
    "<S> this paper deals with the market - bidding problem of a cluster of price - responsive consumers of electricity . </S>",
    "<S> we develop an inverse optimization scheme that , recast as a bilevel programming problem , uses price - consumption data to estimate the complex market bid that best captures the price - response of the cluster . </S>",
    "<S> the complex market bid is defined as a series of marginal utility functions plus some constraints on demand , such as maximum pick - up and drop - off rates . </S>",
    "<S> the proposed modeling approach also leverages information on exogenous factors that may influence the consumption behavior of the cluster , e.g. , weather conditions and calendar effects . </S>",
    "<S> we test the proposed methodology for a particular application : forecasting the power consumption of a small aggregation of households that took part in the olympic peninsula project . </S>",
    "<S> results show that the price - sensitive consumption of the cluster of flexible loads can be largely captured in the form of a complex market bid , so that this could be ultimately used for the cluster to participate in the wholesale electricity market .    </S>",
    "<S> saez - gallego : a data - driven bidding model for a cluster of price - responsive consumers of electricity    smart grid , demand response , electricity markets , inverse optimization , bilevel programming </S>"
  ]
}