{
  "article_text": [
    "finding patterns in large astronomical databases and grouping the data into different classes has become an important task in recent years , one that must be done in an automated fashion given the massive amounts of sky survey data currently being collected and stored .",
    "traditional methods such as looking at large sky plates and identifying galaxies and clusters by eye are no longer feasible . within statistical pattern recognition",
    "there are two traditional approaches to data classification : supervised statistical classification and unsupervised learning ( clustering ) . in the supervised approach",
    "one is given a batch of training data containing labeled examples from each of the known classes of interest .",
    "these examples are used to learn a decision function which partitions the feature space into disjoint regions , each associated with one of the classes .",
    "typical decision function structures used in practice are neural networks , decision trees , and prototype - based classifiers . once the decision function is learned it can be used to automatically classify new examples . the supervised learning of the decision function can be slow and generally requires off - line training .",
    "moreover , enough labeled examples from each of the classes are required to learn an accurate decision function that adequately separates data into the different classes . however , extracting labeled examples from a large database is a time consuming and expensive process , generally requiring hand labeling by human experts .",
    "alternatively , unsupervised learning , or clustering , techniques assign data to groups without any need for supervising examples . in these approaches ,",
    "the grouping is chosen so that the data examples belonging to each cluster are `` as similar as possible '' and so that examples from different clusters are `` as dissimilar as possible '' .",
    "this notion of similarity is quantified through a mathematical clustering objective function , one which relies on the choice of a distance measure defined on the feature space , e.g. the sum - of - squared - errors criterion .",
    "mixture models @xcite are one form of model - based clustering .",
    "they produce probabilistic , or soft , assignments of data points to each of the mixture components , or clusters .",
    "the nature and quality of the learned groupings obtained via unsupervised clustering critically depends upon the choice of clustering distance measure and also on the number of clusters to be learned , which must be specified as part of the algorithm .",
    "there are currently no generally agreed upon approaches for choosing these parameters in unsupervised learning .",
    "furthermore , without supervising examples , there are no guarantees that the chosen parameters are consistent with the learning of clusters that correspond to the ground truth classes in the data .    in recent years , seeking to overcome the disadvantages of both supervised and unsupervised learning , _ semisupervised learning _",
    "techniques have been proposed , e.g. @xcite , @xcite , @xcite .",
    "these methods learn based on a batch of data that consists of both labeled _ and _ unlabeled examples . on the one hand , appropriate use of unlabeled examples , in addition to labeled ones , can help to better learn the `` shapes '' of each of the classes ( i.e. , the class - conditional density functions ) @xcite , @xcite . on the other hand , use of some labeled examples can potentially help to guide unsupervised clustering methods toward solutions that capture the ground truth classes in the data @xcite , @xcite .",
    "in nearly all prior semisupervised work it has been assumed that the number of classes present in the database is known and that there are labeled examples from each of these classes .",
    "however , for scientific domains , especially those with massive data collections , this assumption may not be very reasonable .",
    "there are several reasons why the presence of some classes within a given data set may be unknown .",
    "first , there may be uncertainty associated with the measurement process .",
    "as one example , suppose the data was measured by a new device or one whose operation ( e.g. , measurement sensitivity ) is imprecisely known . if the device s sensitivity or dynamic range is greater than was supposed , it may record measurements corresponding to unanticipated events or objects .",
    "second , in some cases , the set of known classes is inferred by surveying or sampling a subset of the collected database . however , if there are millions of data samples ,",
    "it is only practical to sample a very small data subset  if 99 % of a database remains unsurveyed , it is quite possible that important content ( such as some classes ) may be missed . finally , the set of known classes reflects the currently accepted scientific hypotheses for a given domain .",
    "unknown classes may be present in the data because the current theory is wrong or incomplete .",
    "in fact , we may go so far as to say that the assumption that a collected database is composed of a fixed ( known ) set of classes is in some way inconsistent with the scientific method ",
    "one is guaranteed to find what one is looking for , i.e. , known classes , rather than what may actually be present in the data .    in recent work @xcite ,",
    "@xcite the problem of new class discovery in mixed labeled / unlabeled data sets was formally proposed .",
    "the authors recognized that , within a mixed labeled / unlabeled data set , unknown classes will consist of clusters or groups that are _ purely unlabeled_. the authors proposed a special mixture modeling technique tailored for discovering the cluster / group structure in the data and , in particular , the unknown classes . in their approach , individual mixture components either represent data from known classes , in which case they own some labeled samples , or they represent unknown classes , in which case they own purely unlabeled data subsets .",
    "their learning approaches were demonstrated to be very effective at identifying purely unlabeled clusters @xcite or _ nearly _ purely unlabeled ones @xcite in partially labeled data sets .",
    "such clusters represent _ putative _ unknown classes .",
    "their approach was further demonstrated to improve the overall accuracy of the mixture modeling solution .    in this work ,",
    "we consider the problem of galaxy classification , based on sky survey data , with several unknown classes present in the data .",
    "for this domain , we evaluate both @xcite and a new approach which we propose here , one that is applicable to class discovery for neural network - based ( nn ) classifiers . in section 2",
    ", we describe the data sets and data preparation . in section 3",
    ", we review @xcite , @xcite and also introduce a class discovery approach for nn classifiers . in section 3 ,",
    "we also describe several performance criteria , each capturing different aspects of the class discovery problem . in section 4",
    ", we present our experimental results .",
    "finally , the paper concludes with a summary and some discussion .",
    "in our experiments we used two data sets , each with over 5000 data points .",
    "the first was data from @xcite ( henceforth denoted as esolv after the eso - lv catalog of @xcite ) which has been used previously in several studies of automated classification methods @xcite .",
    "the second data set consisted of sdss early release data @xcite , composed of over 50000 objects of various types .",
    "@xcite performed one of the earliest attempts at morphological classification of galaxies using neural networks .",
    "their data set consisted of 13 input features derived from images of galaxies which were then used to classify the galaxies into five classes : e , s0 , sa + sb , sc + sd , and irr .",
    "we used their input data set of 5217 galaxies .",
    "the features in this data set are described in @xcite .",
    "@xcite describes the use of this data set for galaxy classification using ensembles of neural networks . for our studies we eliminated one of the features , @xmath1 , which is the error in an ellipse fit to b isophotes",
    "this feature had very small variance and equaled zero for approximately 80% of the objects .",
    "thus , we used 12 of the 13 features in the original data set .",
    "we also used a data set with an order of magnitude more objects than the esolv data .",
    "the sdss data consists of 54007 objects drawn from seven different classes .",
    "each object is described by a total of six features : photometric values in u , g , r , i , and z , and the redshift of each object .",
    "tables [ tab : esolv ] and [ tab : sdss ] summarize the properties of the data sets we used . for each class",
    "the tables show the number of objects in the class , the percentage of total objects that class represents , and the type of object in the class .",
    "crrl 0 & 466 & 8.93 & e + 1 & 851 & 16.3 & s0 + 2 & 2403 & 46.1 & sa + sb + 3 & 1132 & 21.7 & sc + sd + 4 & 365 & 7.00 & irregular +    crrl 0 & 229 & 0.42 & unknown spectrum + 1 & 6049 & 11.2 & stellar spectrum + 2 & 41930 & 77.6 & galaxy spectrum + 3 & 4409 & 8.16 & quasar spectrum + 4 & 237 & 0.44 & high z quasar spectrum + 5 & 130 & 0.24 & sky spectrum + 6 & 1023 & 1.89 & late type star +    for our experiments , we treated one or two of the classes as being unknown , withholding from use during model learning the label for every data example from each of the unknown classes . for data from all other classes , we retained the labels for a randomly selected subset ( roughly 10% of the points from these classes521 examples for the esolv data and 5400 examples for the sdss data )",
    "the random selection was performed in a `` stratified '' fashion , ensuring that the number of labeled examples from each known class is in proportion to the mass , or frequency of occurrence , of the class . in this way",
    ", we obtained a data set containing both labeled and unlabeled examples , and with all labels missing from one or two classes .",
    "this is precisely the data scenario proposed and addressed in @xcite and @xcite .",
    "we used two algorithms to classify the data and perform class discovery , a mixture model and a backpropagation algorithm .",
    "these approaches are described in detail below .",
    "this subsection reviews the work in @xcite , @xcite .",
    "there are three main contributions in these works : 1 ) the problem of new class discovery in mixed labeled / unlabeled data was proposed ; 2 ) a mixture model was proposed for this scenario , one that incorporates a realistic labeling mechanism .",
    "this model has built into it the competing hypotheses that a data sample may come from known or unknown / outlier groups .",
    "thus , this model naturally yields _ a posteriori _",
    "probabilities for these hypotheses , as well as the standard _ a posteriori _ probabilities on the known classes ( now conditioned on a known class hypothesis ) ; 3 ) methods for learning the mixture model from given data were proposed in @xcite , @xcite . in these approaches ,",
    "individual mixture components learn to represent either known or unknown class data .",
    "we next review @xcite , @xcite in more detail .",
    "consider a data set @xmath2 , where @xmath3 @xmath4 is the labeled subset and @xmath5 is the unlabeled subset . here , @xmath6 is a feature vector and @xmath7 is a class label from the set of known classes @xmath8 .",
    "this mixed data scenario was considered previously in e.g. @xcite , @xcite , @xcite . unlike these works , a key element in @xcite ,",
    "@xcite summarized here , is that the fact that a sample is unlabeled is treated _ as observed data_. accordingly , we redefine @xmath9 , where now @xmath10 and @xmath11 . here",
    "the new random observation @xmath12 is introduced , taking on values indicating a sample is either labeled or missing the label . if a sample is labeled , then it is known the sample originates from one of the known classes . on the other hand ,",
    "if the sample is unlabeled , then there are two sources of uncertainty .",
    "first , under the assumption that there may be unknown classes present , it is unknown whether or not the given sample originates from a known class .",
    "second , conditioned on its belonging to one of the known classes , the class of origin for the sample is unknown . in @xcite ,",
    "a mixture model was proposed that explains all the observed data , including the presence or absence of a label .",
    "two types of mixture components were posited , differing in the mechanism they use for generating label presence / absence .",
    "`` predefined ''",
    "components generate both labeled and unlabeled data and assume labels are missing at random .",
    "these components represent the known classes .",
    "`` non - predefined '' components only generate unlabeled data  thus , in localized regions , they capture data subsets that are purely unlabeled . _ such subsets may represent an outlier distribution or new classes_. an example is shown in figure 1 , with labeled data denoted by a single number , the class , and with unlabeled data denoted by ` u ' followed by the ground truth class of origin .    [",
    "fig : fig1 ]    the 2-d data points were generated according to a gaussian mixture with 5 components .",
    "for this example , all points originating from the same component come from the same class , i.e. classes `` own '' either one or multiple mixture components . in this example , class two consists of two components , with the other classes consisting of single components .",
    "note that for the known classes , it appears in fig . 1 ( and is the case ) that labels are missing at random , while for the unknown classes ( class 4 in this case ) , labels are deterministically ( always ) missing . this is consistent with an expert labeler who randomly selects a subset of data from the known classes and is unable to label any data from unknown classes . in @xcite and @xcite ,",
    "mixture models were proposed that were tailored to this data scenario . in this work ,",
    "we have applied the approach in @xcite , summarized next .",
    "_ notation _",
    "let @xmath13 , @xmath14 denote the @xmath15th mixture component .",
    "let @xmath16 denote the subset of `` predefined '' components , with the remaining subset denoted @xmath17 .",
    "let @xmath18 be a random variable defined over the @xmath19 known classes , with @xmath20 the class label paired with @xmath21 .",
    "let @xmath22 denote the prior probability for component @xmath15 , @xmath23 the parameter set specifying component @xmath15 s ( component - conditional ) joint feature density , and let @xmath24 $ ] denote this density .",
    "we also introduce a new class set @xmath25 , consisting of the set @xmath8 plus a value @xmath26 , used to indicate that a sample is unlabeled . with respect to the class set @xmath27 , every sample",
    "is now labeled , with the unlabeled samples taking on the label values ` u ' .",
    "we suppose a different random label generator , conditioned on each mixture component , i.e. @xmath28 . in summary ,",
    "the model is based on the parameter set @xmath29 .",
    "* hypothesis for random generation of the data *    this model @xcite hypothesizes that each sample from @xmath30 is generated independently , based on @xmath31 , according to the following stochastic generation process :    \\i ) randomly select a component @xmath32 according to @xmath33 .",
    "\\ii ) randomly select a vector @xmath21 according to @xmath34 and a label @xmath35 according to @xmath36 .    *",
    "joint data likelihood *    the log of the joint data likelihood associated with this model is @xmath37 where @xmath38 . the model parameters @xmath31 can be chosen to maximize the log - likelihood ( [ newlik ] ) via the expectation - maximization ( em ) algorithm ( e.g. @xcite ) .",
    "since the derivation of these em equations is standard , their exposition is herein omitted .",
    "this model does not explicitly discover new class components , i.e. mixture components that are purely unlabeled .",
    "however , suppose that , for a given component @xmath32 , we have that @xmath39 and @xmath40 is also significantly greater than the _ average _ value @xmath41 . in this case , the fraction of unlabeled data owned by the component is unusually high .",
    "we categorize these components as `` nonpredefined '' , i.e. @xmath42 .",
    "such components are putative unknown class components .",
    "all other components are categorized as `` predefined '' , representing known class data . to summarize",
    ", we have the following strategy for class discovery / outlier detection in mixed data : 1 ) learn a mixture model to maximize the log likelihood ( [ newlik ] ) ; 2 ) for each component , declare it `` nonpredefined '' if @xmath43 ; otherwise , declare it `` predefined '' . here , @xmath44 is a suitably chosen threshold . in practice , we declare a component `` nonpredefined '' when its value @xmath40 is closer to @xmath45 than to the average value , i.e. , we choose @xmath46 .",
    "we have found this choice for @xmath44 to give reasonable results for a variety of experimental conditions ( for different data sets and for different fractions of labeled data ) .    _ statistical inferences from the model _    after applying this thresholding operation to each component , the resulting model is naturally applied to address several inference tasks : 1 ) standard classification of a given sample to one of the known classes ; and 2 ) known vs. unknown class discrimination . for classification to known classes , for a given sample @xmath21 , we compute the _ a posteriori _",
    "probabilities    @xmath47 = \\frac{\\sum\\limits_{k \\in { \\cal c}_{\\rm pre } } \\alpha_k f(\\underline{x } | \\theta_k ) ( \\frac{\\beta_{c|k}}{1 - \\beta_{u|k}})}{\\sum\\limits_{k \\in { \\cal c } _ { \\rm pre } } \\alpha_k f(\\underline{x } | \\theta_k ) } , c \\in { \\cal p}_c.\\end{aligned}\\ ] ]    these can be used in a maximum _ a posteriori _ ( map ) class decision rule .    in order to discriminate between the hypotheses that an unlabeled sample originates from a known versus an unknown class , we need the _ a posteriori _ probability that the given feature vector is generated by a nonpredefined component .",
    "this is given by @xmath48 =   \\frac{\\sum\\limits_{k \\in { \\bar{\\cal c}}_{\\rm pre } } \\alpha_k   f(\\underline { x } | \\theta_k ) \\beta_{u|k}}{\\sum\\limits_k",
    "\\alpha_k   f(\\underline{x } | \\theta_k ) \\beta_{u|k}}\\end{aligned}\\ ] ]    _ new class discovery _",
    "while the em learning assumes that the number of mixture components @xmath49 is fixed and known , in practice this size must be estimated .",
    "model order selection is a difficult and pervasive problem , with several criteria proposed @xcite and no consensus on the right one . in our class discovery setting , the importance of accurate model order selection can not be overstated  _ the nonpredefined components in the validated solution will be taken as candidates for new classes _ , to be forwarded to a domain expert for further study .",
    "accurate model order selection is thus important for successful new class discovery . here , as in @xcite , @xcite the bayesian information criterion ( bic ) @xcite is applied .",
    "the bic model selection criterion is written in the form @xmath50 with @xmath51 the number of free parameters in the @xmath49-component model and @xmath52 the data length .",
    "the first term is the penalty on model complexity , with the second term the negative log - likelihood .",
    "we applied bic in a `` wrapper - based '' model selection approach ; i.e. , we built models for increasing @xmath49 , evaluated each in terms of bic , and selected the model with minimum cost .    while any clustering",
    "/ mixture modeling technique can in principle be used to discover unknown classes , standard methods do not have any special impetus for finding label - free ( or largely label - free ) clusters .",
    "by contrast , the log likelihood ( [ newlik ] ) and the likelihood function used in @xcite both encourage solutions with nonpredefined components , when such components are warranted by the presence of unknown classes in the data . in ( [ newlik ] ) , it is the @xmath53 term which provides the impetus for forming these unknown classes , since this term approaches its maximum value ( @xmath54 ) in the nonpredefined component case .",
    "the mixture modeling approach provides several inference capabilities when dealing with mixed labeled / unlabeled data sets and possibly unknown classes : 1 ) it allows one to infer whether or not a given sample belongs to one of the known classes ; 2 ) it identifies purely unlabeled mixture components / clusters , which are reasonably treated as putative unknown classes or , at any rate , components of unknown classes ; 3 ) conditioned on a known class hypothesis for a given sample , the model can infer from which known class the sample originates ( i.e. , the usual classification inference capability ) .",
    "while the mixture modeling approach is naturally suited to new class discovery given mixed labeled / unlabeled data , neural network ( nn ) classifiers do not appear to be predisposed to making these inferences .",
    "neural networks are generally trained using a purely supervised approach , with class labels provided for every example in the training set .",
    "thus , in general , unlabeled samples play no role in the training  given a mixed labeled / unlabeled data set , the nn training will discard all the examples from unknown classes , or , perhaps worse , erroneously impute and use known class labels for this unknown class data .",
    "accordingly , the neural network is only explicitly trained to discriminate between the known classes  it is not trained to distinguish known from unknown classes . while it thus appears that neural networks do not possess any class discovery inference capability , we next suggest an approach that give nns at least a weak form of this capability .    the neural network algorithm we used is a basic backpropagation algorithm available with the weka machine learning package @xcite .",
    "we used the default configuration consisting of a three layer network ( input , hidden , and output ) .",
    "the number of input nodes was @xmath55 , one node for each input feature .",
    "there were @xmath56 output nodes , one for each known class .",
    "the number of hidden nodes was calculated according to @xmath57 . for the esolv data we used 12 nodes in the input layer corresponding to the 12 input features , eight nodes in the hidden layer , and four in the output layer . for the sdss data we used five input layer nodes , five hidden layer nodes , and six output layer nodes .",
    "_ decision confidence _",
    "suppose the neural network produces ( soft ) discriminant function outputs @xmath58 for each of the known classes @xmath59 .",
    "let @xmath60 . with this choice , we have @xmath61 and @xmath62 , i.e. @xmath63 is a probability mass function defined on the known classes .",
    "one principled measure of uncertainty in these soft decisions is the shannon entropy @xmath64 .",
    "if @xmath65 is greater than a preset threshold , we can declare that the sample @xmath21 does not convincingly belong to any of the known classes , i.e. it is declared an unknown class sample .",
    "this approach , based on a measure of the classifier s degree of indecision , is the one we have taken in imparting the neural network with some class discovery inference capability .",
    "other measures of the classifier s degree of indecision are also possible",
    ".      there are three error measures which we have used to evaluate the class discovery approaches .",
    "they are defined as follows :    * criterion 1 : misclassification rate in deciding between `` known '' and `` unknown '' class hypotheses*.    this criterion was evaluated for both the mixture model and neural network approaches . for the mixture model",
    ", the classification decisions were made using a maximum _ a posteriori _ probability rule , based on ( [ inf2 ] ) .",
    "for the neural network , the decisions were made based on thresholding of the neural network s entropy measure , as discussed earlier .",
    "the error rate was measured over the unlabeled portion of the data set ( which consisted of both known and unknown class data ) , i.e. it was estimated as the fraction of unlabeled samples that were misclassified .",
    "* criterion 2 : misclassification rate within `` putative '' unknown classes *    the first criterion simply measures how effective an algorithm is at identifying the subset of ( unlabeled ) samples that come from new , i.e. unknown classes .",
    "if there is a single unknown class present in the data , then this is all that is required . however , suppose that there are multiple unknown classes present .",
    "then , in addition to identifying the subset of samples from unknown classes , one would also like to identify the the individual classes which comprise this unknown class subset .",
    "in other words , one would like to identify the underlying cluster ( group ) structure within the unknown class data .",
    "the mixture modeling approach directly models the unknown and , separately , the known class data by a mixture of components ( clusters ) .",
    "each such cluster can be viewed as a putative unknown class .",
    "a measure of the accuracy of this clustering is the unknown class label purity of these clusters . in particular , suppose one of the learned nonpredefined clusters owns ( in a map sense ) 20 samples that are ground - truth from unknown class a , 30 samples from unknown class b , and 35 unlabeled samples that in fact belong to known classes .",
    "the most populous unknown class in the cluster is b. all samples in the cluster that do not possess label b are reasonably counted as errors .",
    "one can sum these errors over all nonpredefined clusters and divide by the total number of samples owned by all nonpredefined clusters .",
    "this is the fraction of samples that in effect have been erroneously assigned to individual nonpredefined clusters .",
    "note that this criterion is only well - defined when the model finds at least one non - predefined component .",
    "* criterion 3 : known class error rate *    if a sample belongs to a known class , then we certainly will be interested in identifying to which known class it belongs . accordingly , we can define an error fraction measured over the known class data .",
    "several such criteria are possible . here",
    ", we counted an error if an unlabeled sample that is from a known class is assigned to the wrong known class .",
    "for the mixture model , a map classification rule based on the probabilities ( [ inf1 ] ) was used .",
    "all three of the above criteria require various forms of ground truth label information for the unlabeled data subset  criterion 1 requires a ground truth known / unknown class indication for all the data , criterion 2 requires knowledge of unknown class labels for all the data , and criterion 3 requires knowledge of all known class labels .",
    "since in practice one would not have this information ( by definition , no labels are known for data from unknown classes ) , these criteria can only be used for model evaluation / validation . in practice ,",
    "other information sources or expert knowledge would be needed in order to assess the quality of , or to confirm , the model inferences .",
    "we also note that the second criterion can only be evaluated for the mixture model , since the neural network approach does not attempt to partition the estimated unknown class data into smaller groups .",
    "we evaluated the mixture model and neural network on both the esolv and sdss data sets . for sdss , we constrained mixture component variances to be at least 0.1 in order to avoid an observed tendency for the learning to find singular solutions ( zero variance ) , as well as solutions with very small variances along some dimensions . for both the mixture model and the neural network there are `` operating parameters '' whose choices affect the class discovery inference performance . for the mixture model ,",
    "we need to select the model order , i.e. the number of components . this choice will clearly affect the ability to identify unknown class components .",
    "for example , if an unknown class has a small mass , one or more components will only be `` deployed '' for its representation if the model has many components . likewise ,",
    "if the unknown class has a very large mass ( and significant within - class variation ) , quite a few components may be needed to represent it well . for the neural network",
    ", the choice of the entropy threshold affects performance .",
    "we have performed several experimental evaluations of the mixture model and neural network , based on different approaches for choosing these operating parameters . in one set of experiments , shown for the esolv and sdss data",
    "sets in tables [ tab : etf ] and [ tab : stf ] , we picked both the mixture order ( over the range 10 to 80 ) and the nn s entropy threshold ( by an exhaustive search ) to maximize criterion 1 performance .",
    "note that these approaches can not be used in practice since , in performing the model selection , these methods require evaluating a cost ( criterion 1 ) that depends on knowledge of the unknown class labels . however , this experiment does allow a comparison of best - case performances achieved by the mixture and neural network approaches .",
    "for the mixture model , we have also applied bic - based selection as described earlier .",
    "this approach is wholly unsupervised , and thus feasible in practice .",
    "tables [ tab : etf ] and [ tab : stf ] show the results for the esolv data and the sdss data using the best ( lowest ) value for criterion 1 .",
    "the first column shows the classes that were treated as unknown for that series of runs .",
    "the value of `` ncomp '' is the number of components used by the mixture model corresponding to the best value of criterion 1 , while `` nonpre '' is the number of nonpredefined components used by that model .",
    "the remaining columns under `` mixture model '' list error fractions for the three criteria discussed above . under `` neural network ''",
    "we list the value of criterion 1 , the only error measure evaluated for the neural network .",
    "the last column shows the percentage change in the criterion 1 value between the neural network and the mixture model , with a negative value indicating a lower criterion 1 error for the mixture model compared to the neural network .",
    "the bracketed values at the bottom of each column are the average values ( across all experiments ) over that column . for the moment",
    "we will restrict discussion to the criterion 1 performance . tables [ tab : etf ] and [ tab : stf ] show that , with both methods optimized for criterion 1 performance , significantly better inference accuracy is achieved by the mixture - based approach . for the esolv data we find an average decrease in criterion 1 error of @xmath66 and a maximum decrease of @xmath67 . for the sdss data we find an average decrease in criterion 1 error of @xmath0 and a maximum decrease of @xmath68 .",
    "this is not especially surprising , since the mixture is learned using the unknown class data ( but without use of the labels ) , while the neural network is only trained on labeled known class data .    in tables",
    "[ tab : emdl ] and [ tab : smdl ] , we compare the neural network , again with the threshold optimized for criterion 1 , against the mixture model , but with the order now selected based on the bic criterion .",
    "since the neural network decision making threshold is optimized based on knowledge of the unknown class labels while the mixture model and its order are chosen without use of this information , this comparison is not a fair one . however , in practice unsupervised order selection will be required .",
    "thus , this comparison does give insight into the loss in accuracy attributable to the use of , generally suboptimal , but practically feasible model order selection techniques .",
    "as tables [ tab : emdl ] and [ tab : smdl ] show , the criterion 1 error for the mixture model is now higher in 5 of 9 cases for the esolv data and is the same or higher in 5 of 13 cases for the sdss data . for the esolv data we find an average @xmath69 increase in error , while for the sdss data we find an average @xmath66 decrease in error , compared to the neural network .",
    "figure 2 shows a plot of the number of components in the best performing mixture model as a function of the fraction of objects in the unknown classes , for the esolv data .",
    "there is a clear trend toward a larger number of components needed to describe data sets where the unknown classes make up a larger mass fraction of the total data set .",
    "one point , with classes 0 and 2 as the unknown classes , is well described by an unexpectedly small number of components ( 13 ) .",
    "this is discussed below .",
    "a similar trend is not evident in the sdss data .",
    "the sdss data are dominated by two classes ( 1 and 2 ) which together represent over 88% of the data .",
    "[ fig : fig2 ]    figures 3 and 4 show plots of the value of the criterion 1 error as a function of the number of components in the mixture model for two different unknown class combinations .",
    "these plots reflect the information in figure 2 in a different way .",
    "when the unknown classes represent a relatively small mass fraction of the total number of objects in the data set , the minimum value of criterion 1 is found at a relatively moderate number of components . for example , this is evident in the figure for unknown class 4 .",
    "conversely , as seen in figure 2 , if the unknown classes comprise a large fraction of the total number of objects in the data set , then a larger number of components is needed to explain the data and the minimum value of criterion 1 is found at a correspondingly higher number of components .",
    "note that in figure 4 criterion 1 remains static over a range of model orders ( for unknown class 0 , over the range 10 - 20 components ) .",
    "this is due to the fact that the performance only changes at discrete points , where additional nonpredefined components are introduced . in this case",
    ", no nonpredefined components were introduced until @xmath49 increased beyond 20 .",
    "[ fig : fig3 ]    [ fig : fig4 ]    figures 5 and 6 show the criterion 1 error as a function of the number of mixture model components for the sdss data .",
    "again we see the criterion 1 error remaining pretty much static until the model order @xmath49 reaches 25 to 35 components . at this point",
    "nonpredefined components are added to the model allowing further decrease in the criterion 1 error .",
    "[ fig : fig5 ]    [ fig : fig6 ]    the sdss data contains approximately ten times the number of data points as the esolv data .",
    "the mixture model approach generally requires a larger number of components to describe the sdss data set . on average 34 components",
    "were required to describe the esolv data using the best model by criterion 1 , while 61 components were needed to describe the sdss data . using bic to determine the best model required on average 61 components for the esolv data and 71 for the sdss data .",
    "ccclllllr 0 & 27 & 1 & 0.08859 & 0.7275 & 0.3742 & & 0.09923 & -10.7 + 1 & 42 & 1 & 0.1717 & 0.9036 & 0.3220 & & 0.1810 & -5.1 + 2 & 70 & 16 & 0.3797 & 0.5510 & 0.3083 & & 0.4883 & -22.2 + 3 & 48 & 5 & 0.2183 & 0.7482 & 0.3249 & & 0.2408 & -9.3 + 4 & 14 & 1 & 0.05110 & 0.5178 & 0.4221 & & 0.07773 & -34.3 + 0 1 & 16 & 4 & 0.1399 & 0.5588 & 0.3276 & & 0.2805 & -50.3 + 0 2 & 13 & 3 & 0.4553 & 0.6466 & 0.2140 & & 0.6109 & -25.5 + 0 3 & 39 & 4 & 0.3179 & 0.8479 & 0.2524 & & 0.3403 & -6.6 + 0 4 & 34 & 2 & 0.1463 & 0.7702 & 0.3573 & & 0.1770 & -17.3 + & @xmath70&@xmath71&@xmath72&@xmath73&@xmath74&&@xmath75&@xmath76 +    ccclllllr 0 & 49 & 0 & 0.004711 & na & 0.06145 & & 0.004711 & 0 + 1 & 47 & 5 & 0.03319 & 0.2091 & 0.04596 & & 0.1244 & -73.3 + 2 & 28 & 20 & 0.03377 & 0.006797 & 0.1117 & & 0.1344 & -74.9 + 3 & 69 & 4 & 0.02181 & 0.1703 & 0.007064 & & 0.09071 & -76.0 + 4 & 47 & 0 & 0.004876 & na & 0.06421 & & 0.004876 & 0 + 5 & 68 & 0 & 0.002675 & na & 0.06290 & & 0.002675 & 0 + 6 & 74 & 1 & 0.01187 & 0.3382 & 0.08020 & & 0.02105 & -43.6 + 0 1 & 79 & 5 & 0.04074 & 0.2434 & 0.03501 & & 0.1292 & -68.5 + 0 2 & 33 & 20 & 0.03393 & 0.01153 & 0.09026 & & 0.8673 & -96.1 + 0 3 & 80 & 5 & 0.02483 & 0.2059 & 0.06232 & & 0.09542 & -73.9 + 0 4 & 66 & 1 & 0.009176 & na & 0.07416 & & 0.009587 & -4.3 + 0 5 & 77 & 1 & 0.005719 & 0.6518 & 0.09580 & & 0.007386 & -22.6 + 0 6 & 76 & 1 & 0.01559 & 0.4553 & 0.06439 & & 0.02576 & -39.5 + & @xmath77&@xmath78&@xmath79&@xmath80&@xmath81&&@xmath82&@xmath83 +    ccclllllr 0 & 60 & 7 & 0.1530 & 0.9206 & 0.3991 & & 0.09923 & 54.2 + 1 & 53 & 10 & 0.2619 & 0.8672 & 0.3345 & & 0.1810 & 44.7 + 2 & 63 & 11 & 0.4327 & 0.7428 & 0.3149 & & 0.4883 & -11.4 + 3 & 54 & 6 & 0.2564 & 0.8896 & 0.3067 & & 0.2408 & 6.5 + 4 & 67 & 7 & 0.1033 & 0.6137 & 0.4373 & & 0.07773 & 32.9 + 0 1 & 69 & 13 & 0.1902 & 0.6203 & 0.3184 & & 0.2805 & -32.2 + 0 2 & 57 & 8 & 0.5253 & 0.7985 & 0.2091 & & 0.6109 & -14.0 + 0 3 & 62 & 11 & 0.3394 & 0.8542 & 0.2369 & & 0.3403 & -0.3 + 0 4 & 62 & 7 & 0.2004 & 0.7726 & 0.3684 & & 0.1770 & 13.2 + & @xmath84&@xmath85&@xmath86&@xmath87&@xmath88&&@xmath75&@xmath89 +    ccclllllr 0 & 70 & 0 & 0.004711 & na & 0.1100 & & 0.004711 & 0 + 1 & 63 & 5 & 0.1044 & 0.5353 & 0.03800 & & 0.1244 & -16.1 + 2 & 67 & 24 & 0.09999 & 0.03841 & 0.09737 & & 0.1344 & -25.7 + 3 & 74 & 5 & 0.02273 & 0.06070 & 0.1053 & & 0.09071 & -74.9 + 4 & 76 & 0 & 0.004876 & na & 0.1060 & & 0.004876 & 0 + 5 & 80 & 1 & 0.002921 & 0.5389 & 0.1178 & & 0.002675 & 9.2 + 6 & 71 & 3 & 0.02732 & 0.6661 & 0.1066 & & 0.02105 & 29.8 + 0 1 & 66 & 5 & 0.09434 & 0.4886 & 0.03388 & & 0.1292 & -27.0 + 0 2 & 79 & 30 & 0.1128 & 0.02745 & 0.06373 & & 0.8673 & -87.0 + 0 3 & 74 & 5 & 0.03306 & 0.1450 & 0.10390 & & 0.09542 & -65.4 + 0 4 & 61 & 1 & 0.009505 & 0.5297 & 0.1121 & & 0.009587 & -0.9 + 0 5 & 71 & 1 & 0.006275 & 0.6044 & 0.1116 & & 0.007386 & -15.0 + 0 6 & 71 & 3 & 0.02732 & 0.6661 & 0.1066 & & 0.02576 & 6.1 + & @xmath90&@xmath91&@xmath92&@xmath93&@xmath94&&@xmath82&@xmath95 +",
    "as can be seen from the results presented above we are , in general , able to achieve a significantly lower criterion 1 error value when using unlabeled data to augment the labeled data .",
    "overall , we obtained a @xmath96 ( listed in table [ tab : etf ] as the fraction @xmath97 not as the percent ) criterion 1 error for esolv data and a @xmath98 error for sdss data when using criterion 1 as the model selection method .",
    "when using bic for model selection we obtained @xmath99 error for esolv data and @xmath100 error for sdss data .",
    "the percentage change column of table [ tab : etf ] shows that on average the mixture models reduced the criterion 1 error for esolv data by @xmath66 , but this reduction was as high as @xmath67 when classes 0 and 1 were unknown .",
    "table [ tab : stf ] similarly shows an average @xmath0 reduction in criterion 1 error for sdss data with a @xmath68 reduction when classes 0 and 2 were unknown .",
    "a @xmath66 reduction in error for the esolv data implies an extra 1043 out of 5217 objects were correctly classified by the mixture model compared to the neural network . for the sdss data a @xmath0 error reduction implies an additional 30784 out of 54007 objects were correctly classified by the mixture model .",
    "our study is the first to apply semisupervised learning to astronomical data , and the first , to our knowledge , to use a data set as large as 50000 points .",
    "this is an important test of the methodology because of the vast amount of astronomical data freely available today , most of which is unlabeled . demonstrating that our methods work with large astronomical data sets",
    "was a primary goal of this work .",
    "nevertheless , there are a number of factors that influence the reliability of the proposed method and what level of error can be achieved .",
    "the results in tables 3 - 6 demonstrate the importance of the model order selection technique .",
    "bic - based selection fares well on the sdss data , achieving substantially better average criterion 1 results than the neural network optimized for criterion 1 and only modestly worse results than the mixture model optimized for criterion 1 ( 0.02 vs. 0.04 average error rates ) .",
    "however , there is a significant average performance gap between the two mixture approaches on the esolv data ( 0.22 vs. 0.27 ) and the bic - selected mixture is only comparable to the neural network on esolv ( 0.273 vs. 0.277 average error rates ) .",
    "it is possible that a better model order selection technique could improve the mixture results on esolv .",
    "one artifact of optimizing the mixture for criterion 1 is that , on average , smaller models are selected , compared with the mixtures selected by bic . for esolv on average 34 components were selected by the former approach , while on average 61 components were selected by the latter .",
    "furthermore , an average of 4.1 nonpredefined components were used with criterion 1 model selection while an average of 8.9 were used with bic .",
    "for the sdss data an average of 61 components , including 4.8 nonpredefined components , were selected using criterion 1 . finding the best sdss model by bic we needed on average 71 components , including 6.4 nonpredefined components . while we learned models with up to 80 components , in some cases for the sdss data the best models were using close to 80 components .",
    "this suggests it may be reasonable to evaluate solutions with even more components .",
    "while the mean number of components selected by bic was greater than that selected according to criterion 1 , the variance in the number of selected components is much greater for selection according to criterion 1 .",
    "this is consistent with the results in figure 2 , which indicate that , for best criterion 1 performance , the number of components is significantly correlated with the mass of the unknown classes ( which varies greatly since the classes are far from equally likely ) .",
    "this further means that , in some cases , when the mass of the unknown classes is large , criterion 1 selects more components than bic .",
    "for example , for the esolv data , class 2 occurs @xmath101 of the time .",
    "when this class is taken as unknown , bic selected 63 components , while criterion 1 selected 70 .",
    "another factor that influences model accuracy is the fact that the learning objective function @xmath102 is multimodal , with significant potential for finding suboptimal local maxima , rather than the global maximum . at each model order",
    ", we generated several solutions based on different initializations and picked the one with greatest log - likelihood .",
    "however , there is anecdotal evidence in our results that we may only be finding locally optimal solutions at each model order . referring back to figure 2",
    "we see that the best model for unknown classes 0 2 contains only 13 mixture components .",
    "this clearly is not in keeping with the trend that more mixture components are needed to explain the data with larger mass fraction of unknown classes .",
    "it appears in this case that a particularly good solution was found .",
    "this likewise suggests that , at other orders , suboptimal , local maximum solutions were found .",
    "the criterion 2 error is a measure of how well the algorithm can classify objects within the newly found classes .",
    "this is a very hard problem because we are asking the algorithm to do two things .",
    "first , determine if some mixture components ( the nonpredefined components ) are needed to describe objects that do not fit into the existing known class structure .",
    "second , partition these objects correctly between the unknown class components .",
    "this second step is effectively looking for substructure in the newly discovered classes .    for the esolv data we found on average about a @xmath103 criterion 2 error compared with about a @xmath104 error for the sdss data when using criterion 1 model selection .",
    "similarly , we find about @xmath105 error for the esolv data and @xmath106 error for sdss data when using bic model selection .",
    "the values of na for criterion 2 error for some of the sdss experiments reflect models where there were no nonpredefined components ; in this case the error measure is undefined .",
    "note that , in all these cases , the unknown classes had very small mass , which explains why no nonpredefined components were found .",
    "in particular , class 0 and class 4 collectively comprise less than @xmath107 of the sdss data .",
    "thus , when these classes are missing , we would not expect to find nonpredefined components in the solution unless both 1 ) there are more than 100 components in the model and 2 ) the model criterion selects a solution of this size .",
    "the criterion 3 error measures how well the model can assign objects to known classes .",
    "for this we obtained about a @xmath108 error for esolv data and @xmath109 error for sdss data using criterion 1 model selection .",
    "when using bic model selection we obtained @xmath110 error for esolv data and @xmath111 error for sdss data .",
    "we find the overall results presented here very promising .",
    "the tests done here have demonstrated the efficacy of the class discovery problem and approaches . however , more work will be required to develop a mature technology for highly reliable new class discovery .",
    "we would like to thank the nasa applied information systems research program for supporting us in this effort under contract nas5 - 02098 .",
    "one of the authors ( db ) would like to thank ofer lahav for supplying the eso - lv data ."
  ],
  "abstract_text": [
    "<S> in recent years , automated , supervised classification techniques have been fruitfully applied to labeling and organizing large astronomical databases . </S>",
    "<S> these methods require off - line classifier training , based on labeled examples from each of the ( known ) object classes . in practice , only a small batch of labeled examples , hand - labeled by a human expert , may be available for training . </S>",
    "<S> moreover , there may be _ no _ labeled examples for some classes present in the data , i.e. the database may contain several _ </S>",
    "<S> unknown classes_. unknown classes may be present due to 1 ) uncertainty in or lack of knowledge of the measurement process , 2 ) an inability to adequately `` survey '' a massive database to assess its content ( classes ) , and/or 3 ) an incomplete scientific hypothesis . in recent </S>",
    "<S> work , new class discovery in mixed labeled / unlabeled data was formally posed , with a proposed solution based on mixture models . in this work </S>",
    "<S> we investigate this approach , propose a competing technique suitable for class discovery in neural networks , and evaluate both methods for classification and class discovery on several astronomical data sets . </S>",
    "<S> our results demonstrate up to a @xmath0 reduction in classification error compared to a standard neural network classifier that uses only labeled data . </S>"
  ]
}